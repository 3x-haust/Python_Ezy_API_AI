{"repo_info": {"repo_name": "OS-Copilot", "repo_owner": "OS-Copilot", "repo_url": "https://github.com/OS-Copilot/OS-Copilot"}}
{"type": "test_file", "path": "examples/LLAMA3/test_llama3.py", "content": "import openai\nimport logging\nimport os\nimport time\nimport requests\nimport json\n\n\nclass LLAMA3:\n    \"\"\"\n    A class for interacting with the OpenAI API, allowing for chat completion requests.\n\n    This class simplifies the process of sending requests to OpenAI's chat model by providing\n    a convenient interface for the chat completion API. It handles setting up the API key\n    and organization for the session and provides a method to send chat messages.\n\n    Attributes:\n        model_name (str): The name of the model to use for chat completions. Default is set\n                          by the global `MODEL_NAME`.\n        api_key (str): The API key used for authentication with the OpenAI API. This should\n                       be set through the `OPENAI_API_KEY` global variable.\n        organization (str): The organization ID for OpenAI. Set this through the\n                            `OPENAI_ORGANIZATION` global variable.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the OpenAI object with the given configuration.\n        \"\"\"\n\n        self.model_name = 'llama3'\n\n        self.llama_serve = \"http://localhost:11434/api/chat\"\n\n    def chat(self, messages, temperature=0):\n        \"\"\"\n        Sends a chat completion request to the OpenAI API using the specified messages and parameters.\n\n        Args:\n            messages (list of dict): A list of message dictionaries, where each dictionary\n                                     should contain keys like 'role' and 'content' to\n                                     specify the role (e.g., 'system', 'user') and content of\n                                     each message.\n            temperature (float, optional): Controls randomness in the generation. Lower values\n                                           make the model more deterministic. Defaults to 0.\n\n        Returns:\n            str: The content of the first message in the response from the OpenAI API.\n\n        \"\"\"\n        payload = {\n            \"model\": \"llama3\",\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": \"why is the sky blue?\"\n                }],\n            \"stream\": False\n            \n        }\n\n        headers = {\n                \"Content-Type\": \"application/json\"}\n\n        response = requests.post(self.llama_serve, data=json.dumps(payload),headers=headers)\n\n        if response.status_code == 200:\n            # Get the response data\n            logging.info(f\"\"\"Response: {response.json()[\"message\"][\"content\"]}\"\"\")\n            return response.json()[\"message\"][\"content\"]\n        else:\n            logging.error(\"Failed to call LLM: \", response.status_code, response.text)\n            return \"\"\n\nllm = LLAMA3()\nprint(llm.chat(messages=111))"}
{"type": "test_file", "path": "oscopilot/utils/test_new_llms.py", "content": "# This code is based on Open Interpreter. Original source: https://github.com/OpenInterpreter/open-interpreter\n\n\nimport base64\nimport io\nimport os\nimport json\nimport time\n\nfrom PIL import Image\n\nfrom rich import print as rich_print\nfrom rich.markdown import Markdown\nfrom rich.rule import Rule\n\nfrom dotenv import load_dotenv\n\nimport litellm\nimport tokentrim as tt\nlitellm.suppress_debug_info = True\n\n\nload_dotenv(dotenv_path='.env', override=True)\nMODEL_NAME = os.getenv('MODEL_NAME')\nOPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\nOPENAI_ORGANIZATION = os.getenv('OPENAI_ORGANIZATION')\nBASE_URL = os.getenv('OPENAI_BASE_URL')\n\n\nfunction_schema = {\n    \"name\": \"execute\",\n    \"description\": \"Executes code on the user's machine **in the users local environment** and returns the output\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"language\": {\n                \"type\": \"string\",\n                \"description\": \"The programming language (required parameter to the `execute` function)\",\n                \"enum\": [\n                    # This will be filled dynamically with the languages OI has access to.\n                ],\n            },\n            \"code\": {\"type\": \"string\", \"description\": \"The code to execute (required)\"},\n        },\n        \"required\": [\"language\", \"code\"],\n    },\n}\n\n\ndef parse_partial_json(s):\n    # Attempt to parse the string as-is.\n    try:\n        return json.loads(s)\n    except:\n        pass\n\n    # Initialize variables.\n    new_s = \"\"\n    stack = []\n    is_inside_string = False\n    escaped = False\n\n    # Process each character in the string one at a time.\n    for char in s:\n        if is_inside_string:\n            if char == '\"' and not escaped:\n                is_inside_string = False\n            elif char == \"\\n\" and not escaped:\n                char = \"\\\\n\"  # Replace the newline character with the escape sequence.\n            elif char == \"\\\\\":\n                escaped = not escaped\n            else:\n                escaped = False\n        else:\n            if char == '\"':\n                is_inside_string = True\n                escaped = False\n            elif char == \"{\":\n                stack.append(\"}\")\n            elif char == \"[\":\n                stack.append(\"]\")\n            elif char == \"}\" or char == \"]\":\n                if stack and stack[-1] == char:\n                    stack.pop()\n                else:\n                    # Mismatched closing character; the input is malformed.\n                    return None\n\n        # Append the processed character to the new string.\n        new_s += char\n\n    # If we're still inside a string at the end of processing, we need to close the string.\n    if is_inside_string:\n        new_s += '\"'\n\n    # Close any remaining open structures in the reverse order that they were opened.\n    for closing_char in reversed(stack):\n        new_s += closing_char\n\n    # Attempt to parse the modified string as JSON.\n    try:\n        return json.loads(new_s)\n    except:\n        # If we still can't parse the string as JSON, return None to indicate failure.\n        return None\n\n\ndef merge_deltas(original, delta):\n    \"\"\"\n    Pushes the delta into the original and returns that.\n\n    Great for reconstructing OpenAI streaming responses -> complete message objects.\n    \"\"\"\n\n    for key, value in dict(delta).items():\n        if value != None:\n            if isinstance(value, str):\n                if key in original:\n                    original[key] = (original[key] or \"\") + (value or \"\")\n                else:\n                    original[key] = value\n            else:\n                value = dict(value)\n                if key not in original:\n                    original[key] = value\n                else:\n                    merge_deltas(original[key], value)\n\n    return original\n\n\ndef run_function_calling_llm(llm, request_params):\n    ## Setup\n\n    # # Add languages OI has access to\n    # function_schema[\"parameters\"][\"properties\"][\"language\"][\"enum\"] = [\n    #     i.name.lower() for i in llm.interpreter.computer.terminal.languages\n    # ]\n    # request_params[\"functions\"] = [function_schema]\n\n    # # Add OpenAI's recommended function message\n    # request_params[\"messages\"][0][\n    #     \"content\"\n    # ] += \"\\nUse ONLY the function you have been provided with — 'execute(language, code)'.\"\n\n    ## Convert output to LMC format\n\n    accumulated_deltas = {}\n    language = None\n    code = \"\"\n\n    for chunk in llm.completions(**request_params):\n        if \"choices\" not in chunk or len(chunk[\"choices\"]) == 0:\n            # This happens sometimes\n            continue\n\n        delta = chunk[\"choices\"][0][\"delta\"]\n\n        # Accumulate deltas\n        accumulated_deltas = merge_deltas(accumulated_deltas, delta)\n\n        if \"content\" in delta and delta[\"content\"]:\n            yield {\"type\": \"message\", \"content\": delta[\"content\"]}\n\n        if (\n            accumulated_deltas.get(\"function_call\")\n            and \"arguments\" in accumulated_deltas[\"function_call\"]\n            and accumulated_deltas[\"function_call\"][\"arguments\"]\n        ):\n            if (\n                \"name\" in accumulated_deltas[\"function_call\"]\n                and accumulated_deltas[\"function_call\"][\"name\"] == \"execute\"\n            ):\n                arguments = accumulated_deltas[\"function_call\"][\"arguments\"]\n                arguments = parse_partial_json(arguments)\n\n                if arguments:\n                    if (\n                        language is None\n                        and \"language\" in arguments\n                        and \"code\"\n                        in arguments  # <- This ensures we're *finished* typing language, as opposed to partially done\n                        and arguments[\"language\"]\n                    ):\n                        language = arguments[\"language\"]\n\n                    if language is not None and \"code\" in arguments:\n                        # Calculate the delta (new characters only)\n                        code_delta = arguments[\"code\"][len(code) :]\n                        # Update the code\n                        code = arguments[\"code\"]\n                        # Yield the delta\n                        if code_delta:\n                            yield {\n                                \"type\": \"code\",\n                                \"format\": language,\n                                \"content\": code_delta,\n                            }\n                else:\n                    if llm.interpreter.verbose:\n                        print(\"Arguments not a dict.\")\n\n            # Common hallucinations\n            elif \"name\" in accumulated_deltas[\"function_call\"] and (\n                accumulated_deltas[\"function_call\"][\"name\"] == \"python\"\n                or accumulated_deltas[\"function_call\"][\"name\"] == \"functions\"\n            ):\n                if llm.interpreter.verbose:\n                    print(\"Got direct python call\")\n                if language is None:\n                    language = \"python\"\n\n                if language is not None:\n                    # Pull the code string straight out of the \"arguments\" string\n                    code_delta = accumulated_deltas[\"function_call\"][\"arguments\"][\n                        len(code) :\n                    ]\n                    # Update the code\n                    code = accumulated_deltas[\"function_call\"][\"arguments\"]\n                    # Yield the delta\n                    if code_delta:\n                        yield {\n                            \"type\": \"code\",\n                            \"format\": language,\n                            \"content\": code_delta,\n                        }\n\n            else:\n                # If name exists and it's not \"execute\" or \"python\" or \"functions\", who knows what's going on.\n                if \"name\" in accumulated_deltas[\"function_call\"]:\n                    yield {\n                        \"type\": \"code\",\n                        \"format\": \"python\",\n                        \"content\": accumulated_deltas[\"function_call\"][\"name\"],\n                    }\n                    return\n\n\ndef run_text_llm(llm, params):\n    ## Setup\n\n    try:\n        # Add the system message\n        params[\"messages\"][0][\n            \"content\"\n        ] += \"\\nTo execute code on the user's machine, write a markdown code block. Specify the language after the ```. You will receive the output. Use any programming language.\"\n    except:\n        print('params[\"messages\"][0]', params[\"messages\"][0])\n        raise\n\n    ## Convert output to LMC format\n\n    inside_code_block = False\n    accumulated_block = \"\"\n    language = None\n\n    for chunk in llm.completions(**params):\n        if llm.interpreter.verbose:\n            print(\"Chunk in coding_llm\", chunk)\n\n        if \"choices\" not in chunk or len(chunk[\"choices\"]) == 0:\n            # This happens sometimes\n            continue\n\n        content = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n\n        if content == None:\n            continue\n\n        accumulated_block += content\n\n        if accumulated_block.endswith(\"`\"):\n            # We might be writing \"```\" one token at a time.\n            continue\n\n        # Did we just enter a code block?\n        if \"```\" in accumulated_block and not inside_code_block:\n            inside_code_block = True\n            accumulated_block = accumulated_block.split(\"```\")[1]\n\n        # Did we just exit a code block?\n        if inside_code_block and \"```\" in accumulated_block:\n            return\n\n        # If we're in a code block,\n        if inside_code_block:\n            # If we don't have a `language`, find it\n            if language is None and \"\\n\" in accumulated_block:\n                language = accumulated_block.split(\"\\n\")[0]\n\n                # Default to python if not specified\n                if language == \"\":\n                    if llm.interpreter.os == False:\n                        language = \"python\"\n                    elif llm.interpreter.os == False:\n                        # OS mode does this frequently. Takes notes with markdown code blocks\n                        language = \"text\"\n                else:\n                    # Removes hallucinations containing spaces or non letters.\n                    language = \"\".join(char for char in language if char.isalpha())\n\n            # If we do have a `language`, send it out\n            if language:\n                yield {\n                    \"type\": \"code\",\n                    \"format\": language,\n                    \"content\": content.replace(language, \"\"),\n                }\n\n        # If we're not in a code block, send the output as a message\n        if not inside_code_block:\n            yield {\"type\": \"message\", \"content\": content}\n\n\ndef display_markdown_message(message):\n    \"\"\"\n    Display markdown message. Works with multiline strings with lots of indentation.\n    Will automatically make single line > tags beautiful.\n    \"\"\"\n\n    for line in message.split(\"\\n\"):\n        line = line.strip()\n        if line == \"\":\n            print(\"\")\n        elif line == \"---\":\n            rich_print(Rule(style=\"white\"))\n        else:\n            try:\n                rich_print(Markdown(line))\n            except UnicodeEncodeError as e:\n                # Replace the problematic character or handle the error as needed\n                print(\"Error displaying line:\", line)\n\n    if \"\\n\" not in message and message.startswith(\">\"):\n        # Aesthetic choice. For these tags, they need a space below them\n        print(\"\")\n\n\ndef convert_to_openai_messages(\n    messages,\n    function_calling=True,\n    vision=False,\n    shrink_images=True,\n    code_output_sender=\"assistant\",\n):\n    \"\"\"\n    Converts LMC messages into OpenAI messages\n    \"\"\"\n    new_messages = []\n\n    for message in messages:\n        # Is this for thine eyes?\n        if \"recipient\" in message and message[\"recipient\"] != \"assistant\":\n            continue\n\n        new_message = {}\n\n        if message[\"type\"] == \"message\":\n            new_message[\"role\"] = message[\n                \"role\"\n            ]  # This should never be `computer`, right?\n            new_message[\"content\"] = message[\"content\"]\n\n        elif message[\"type\"] == \"code\":\n            new_message[\"role\"] = \"assistant\"\n            if function_calling:\n                new_message[\"function_call\"] = {\n                    \"name\": \"execute\",\n                    \"arguments\": json.dumps(\n                        {\"language\": message[\"format\"], \"code\": message[\"content\"]}\n                    ),\n                    # parsed_arguments isn't actually an OpenAI thing, it's an OI thing.\n                    # but it's soo useful!\n                    \"parsed_arguments\": {\n                        \"language\": message[\"format\"],\n                        \"code\": message[\"content\"],\n                    },\n                }\n                # Add empty content to avoid error \"openai.error.InvalidRequestError: 'content' is a required property - 'messages.*'\"\n                # especially for the OpenAI service hosted on Azure\n                new_message[\"content\"] = \"\"\n            else:\n                new_message[\n                    \"content\"\n                ] = f\"\"\"```{message[\"format\"]}\\n{message[\"content\"]}\\n```\"\"\"\n\n        elif message[\"type\"] == \"console\" and message[\"format\"] == \"output\":\n            if function_calling:\n                new_message[\"role\"] = \"function\"\n                new_message[\"name\"] = \"execute\"\n                if message[\"content\"].strip() == \"\":\n                    new_message[\n                        \"content\"\n                    ] = \"No output\"  # I think it's best to be explicit, but we should test this.\n                else:\n                    new_message[\"content\"] = message[\"content\"]\n\n            else:\n                # This should be experimented with.\n                if code_output_sender == \"user\":\n                    if message[\"content\"].strip() == \"\":\n                        content = \"The code above was executed on my machine. It produced no text output. what's next (if anything, or are we done?)\"\n                    else:\n                        content = (\n                            \"Code output: \"\n                            + message[\"content\"]\n                            + \"\\n\\nWhat does this output mean / what's next (if anything, or are we done)?\"\n                        )\n\n                    new_message[\"role\"] = \"user\"\n                    new_message[\"content\"] = content\n                elif code_output_sender == \"assistant\":\n                    if \"@@@SEND_MESSAGE_AS_USER@@@\" in message[\"content\"]:\n                        new_message[\"role\"] = \"user\"\n                        new_message[\"content\"] = message[\"content\"].replace(\n                            \"@@@SEND_MESSAGE_AS_USER@@@\", \"\"\n                        )\n                    else:\n                        new_message[\"role\"] = \"assistant\"\n                        new_message[\"content\"] = (\n                            \"\\n```output\\n\" + message[\"content\"] + \"\\n```\"\n                        )\n\n        elif message[\"type\"] == \"image\":\n            if vision == False:\n                continue\n\n            if \"base64\" in message[\"format\"]:\n                # Extract the extension from the format, default to 'png' if not specified\n                if \".\" in message[\"format\"]:\n                    extension = message[\"format\"].split(\".\")[-1]\n                else:\n                    extension = \"png\"\n\n                # Construct the content string\n                content = f\"data:image/{extension};base64,{message['content']}\"\n\n                if shrink_images:\n                    try:\n                        # Decode the base64 image\n                        img_data = base64.b64decode(message[\"content\"])\n                        img = Image.open(io.BytesIO(img_data))\n\n                        # Resize the image if it's width is more than 1024\n                        if img.width > 1024:\n                            new_height = int(img.height * 1024 / img.width)\n                            img = img.resize((1024, new_height))\n\n                        # Convert the image back to base64\n                        buffered = io.BytesIO()\n                        img.save(buffered, format=extension)\n                        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n                        content = f\"data:image/{extension};base64,{img_str}\"\n                    except:\n                        # This should be non blocking. It's not required\n                        # print(\"Failed to shrink image. Proceeding with original image size.\")\n                        pass\n\n            elif message[\"format\"] == \"path\":\n                # Convert to base64\n                image_path = message[\"content\"]\n                file_extension = image_path.split(\".\")[-1]\n\n                with open(image_path, \"rb\") as image_file:\n                    encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n\n                content = f\"data:image/{file_extension};base64,{encoded_string}\"\n            else:\n                # Probably would be better to move this to a validation pass\n                # Near core, through the whole messages object\n                if \"format\" not in message:\n                    raise Exception(\"Format of the image is not specified.\")\n                else:\n                    raise Exception(f\"Unrecognized image format: {message['format']}\")\n\n            # Calculate the size of the original binary data in bytes\n            content_size_bytes = len(content) * 3 / 4\n\n            # Convert the size to MB\n            content_size_mb = content_size_bytes / (1024 * 1024)\n\n            # Print the size of the content in MB\n            # print(f\"File size: {content_size_mb} MB\")\n\n            # Assert that the content size is under 20 MB\n            assert content_size_mb < 20, \"Content size exceeds 20 MB\"\n\n            new_message = {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": content, \"detail\": \"low\"},\n                    }\n                ],\n            }\n\n        elif message[\"type\"] == \"file\":\n            new_message = {\"role\": \"user\", \"content\": message[\"content\"]}\n\n        else:\n            raise Exception(f\"Unable to convert this message type: {message}\")\n\n        if isinstance(new_message[\"content\"], str):\n            new_message[\"content\"] = new_message[\"content\"].strip()\n\n        new_messages.append(new_message)\n\n    \"\"\"\n    # Combine adjacent user messages\n    combined_messages = []\n    i = 0\n    while i < len(new_messages):\n        message = new_messages[i]\n        if message[\"role\"] == \"user\":\n            combined_content = []\n            while i < len(new_messages) and new_messages[i][\"role\"] == \"user\":\n                if isinstance(new_messages[i][\"content\"], str):\n                    combined_content.append({\n                        \"type\": \"text\",\n                        \"text\": new_messages[i][\"content\"]\n                    })\n                elif isinstance(new_messages[i][\"content\"], list):\n                    combined_content.extend(new_messages[i][\"content\"])\n                i += 1\n            message[\"content\"] = combined_content\n        combined_messages.append(message)\n        i += 1\n    new_messages = combined_messages\n\n    if not function_calling:\n        # Combine adjacent assistant messages, as \"function calls\" will just be normal messages with content: markdown code blocks\n        combined_messages = []\n        i = 0\n        while i < len(new_messages):\n            message = new_messages[i]\n            if message[\"role\"] == \"assistant\":\n                combined_content = \"\"\n                while i < len(new_messages) and new_messages[i][\"role\"] == \"assistant\":\n                    combined_content += new_messages[i][\"content\"] + \"\\n\\n\"\n                    i += 1\n                message[\"content\"] = combined_content.strip()\n            combined_messages.append(message)\n            i += 1\n        new_messages = combined_messages\n    \"\"\"\n\n    return new_messages\n\n\nclass Llm:\n    \"\"\"\n    A stateless LMC-style LLM with some helpful properties.\n    \"\"\"\n\n    def __init__(self):\n\n        # Chat completions \"endpoint\"\n        self.completions = fixed_litellm_completions\n\n        # Settings\n        self.model = MODEL_NAME\n        self.temperature = 0\n        self.supports_vision = False\n        self.supports_functions = None  # Will try to auto-detect\n        self.shrink_images = None\n\n        # Optional settings\n        self.context_window = None\n        self.max_tokens = None\n        self.api_base = BASE_URL\n        self.api_key = OPENAI_API_KEY\n        self.api_version = None\n\n        # Budget manager powered by LiteLLM\n        self.max_budget = None\n        self.verbose = False\n\n    def run(self, messages):\n        \"\"\"\n        We're responsible for formatting the call into the llm.completions object,\n        starting with LMC messages in interpreter.messages, going to OpenAI compatible messages into the llm,\n        respecting whether it's a vision or function model, respecting its context window and max tokens, etc.\n\n        And then processing its output, whether it's a function or non function calling model, into LMC format.\n        \"\"\"\n\n        # Assertions\n        assert (\n            messages[0][\"role\"] == \"system\"\n        ), \"First message must have the role 'system'\"\n        for msg in messages[1:]:\n            assert (\n                msg[\"role\"] != \"system\"\n            ), \"No message after the first can have the role 'system'\"\n\n        # Detect function support\n        if self.supports_functions != None:\n            supports_functions = self.supports_functions\n        else:\n            # Guess whether or not it's a function calling LLM\n            # Once Litellm supports it, add Anthropic models here\n            if self.model != \"gpt-4-vision-preview\" and self.model in litellm.open_ai_chat_completion_models or self.model.startswith(\"azure/\"):\n                supports_functions = True\n            else:\n                supports_functions = False\n\n        # Trim image messages if they're there\n        if self.supports_vision:\n            image_messages = [msg for msg in messages if msg[\"type\"] == \"image\"]\n\n            if self.interpreter.os:\n                # Keep only the last two images if the interpreter is running in OS mode\n                if len(image_messages) > 1:\n                    for img_msg in image_messages[:-2]:\n                        messages.remove(img_msg)\n                        if self.interpreter.verbose:\n                            print(\"Removing image message!\")\n            else:\n                # Delete all the middle ones (leave only the first and last 2 images) from messages_for_llm\n                if len(image_messages) > 3:\n                    for img_msg in image_messages[1:-2]:\n                        messages.remove(img_msg)\n                        if self.interpreter.verbose:\n                            print(\"Removing image message!\")\n                # Idea: we could set detail: low for the middle messages, instead of deleting them\n\n        # Convert to OpenAI messages format\n        # messages = convert_to_openai_messages(\n        #     messages,\n        #     function_calling=supports_functions,\n        #     vision=self.supports_vision,\n        #     shrink_images=self.shrink_images,\n        # )\n\n        # if self.interpreter.debug:\n        #     print(\"\\n\\n\\nOPENAI COMPATIBLE MESSAGES\\n\\n\\n\")\n        #     for message in messages:\n        #         if len(str(message)) > 5000:\n        #             print(str(message)[:200] + \"...\")\n        #         else:\n        #             print(message)\n        #         print(\"\\n\")\n        #     print(\"\\n\\n\\n\")\n\n        system_message = messages[0][\"content\"]\n        messages = messages[1:]\n\n        # Trim messages\n        try:\n            if self.context_window and self.max_tokens:\n                trim_to_be_this_many_tokens = (\n                    self.context_window - self.max_tokens - 25\n                )  # arbitrary buffer\n                messages = tt.trim(\n                    messages,\n                    system_message=system_message,\n                    max_tokens=trim_to_be_this_many_tokens,\n                )\n            elif self.context_window and not self.max_tokens:\n                # Just trim to the context window if max_tokens not set\n                messages = tt.trim(\n                    messages,\n                    system_message=system_message,\n                    max_tokens=self.context_window,\n                )\n            else:\n                try:\n                    messages = tt.trim(\n                        messages, system_message=system_message, model=self.model\n                    )\n                except:\n                    if len(messages) == 1:\n                        if self.interpreter.in_terminal_interface:\n                            display_markdown_message(\n                                \"\"\"\n**We were unable to determine the context window of this model.** Defaulting to 3000.\n\nIf your model can handle more, run `interpreter --context_window {token limit} --max_tokens {max tokens per response}`.\n\nContinuing...\n                            \"\"\"\n                            )\n                        else:\n                            display_markdown_message(\n                                \"\"\"\n**We were unable to determine the context window of this model.** Defaulting to 3000.\n\nIf your model can handle more, run `interpreter.llm.context_window = {token limit}`.\n\nAlso please set `interpreter.llm.max_tokens = {max tokens per response}`.\n\nContinuing...\n                            \"\"\"\n                            )\n                    messages = tt.trim(\n                        messages, system_message=system_message, max_tokens=3000\n                    )\n        except:\n            # If we're trimming messages, this won't work.\n            # If we're trimming from a model we don't know, this won't work.\n            # Better not to fail until `messages` is too big, just for frustrations sake, I suppose.\n\n            # Reunite system message with messages\n            messages = [{\"role\": \"system\", \"content\": system_message}] + messages\n\n            pass\n\n        ## Start forming the request\n\n        params = {\n            \"model\": self.model,\n            \"messages\": messages,\n            \"stream\": True,\n        }\n\n        # Optional inputs\n        if self.api_key:\n            params[\"api_key\"] = self.api_key\n        if self.api_base:\n            params[\"api_base\"] = self.api_base\n        if self.api_version:\n            params[\"api_version\"] = self.api_version\n        if self.max_tokens:\n            params[\"max_tokens\"] = self.max_tokens\n        if self.temperature:\n            params[\"temperature\"] = self.temperature\n\n        # Set some params directly on LiteLLM\n        if self.max_budget:\n            litellm.max_budget = self.max_budget\n        if self.verbose:\n            litellm.set_verbose = True\n\n        if supports_functions:\n            yield from run_function_calling_llm(self, params)\n        else:\n            yield from run_text_llm(self, params)\n\n\ndef fixed_litellm_completions(**params):\n    \"\"\"\n    Just uses a dummy API key, since we use litellm without an API key sometimes.\n    Hopefully they will fix this!\n    \"\"\"\n\n    # Run completion\n    first_error = None\n    try:\n        yield from litellm.completion(**params)\n    except Exception as e:\n        # Store the first error\n        first_error = e\n        # LiteLLM can fail if there's no API key,\n        # even though some models (like local ones) don't require it.\n\n        if \"api key\" in str(first_error).lower() and \"api_key\" not in params:\n            print(\n                \"LiteLLM requires an API key. Please set a dummy API key to prevent this message. (e.g `interpreter --api_key x` or `interpreter.llm.api_key = 'x'`)\"\n            )\n\n        # So, let's try one more time with a dummy API key:\n        params[\"api_key\"] = \"x\"\n\n        try:\n            yield from litellm.completion(**params)\n        except:\n            # If the second attempt also fails, raise the first error\n            raise first_error\n\n\ndef main():\n    start_time = time.time()\n    llm = Llm()\n    # query = '你好，请随便和我说点什么'\n    messages = [{'role': 'system', 'content': 'You are Open Interpreter, a world-class programmer that can complete any goal by executing code.\\nFirst, write a plan. **Always recap the plan between each code block** (you have extreme short-term memory loss, so you need to recap the plan between each message block to retain it).\\nWhen you execute code, it will be executed **on the user\\'s machine**. The user has given you **full and complete permission** to execute any code necessary to complete the task. Execute the code.\\nIf you want to send data between programming languages, save the data to a txt or json.\\nYou can access the internet. Run **any code** to achieve the goal, and if at first you don\\'t succeed, try again and again.\\nYou can install new packages.\\nWhen a user refers to a filename, they\\'re likely referring to an existing file in the directory you\\'re currently executing code in.\\nWrite messages to the user in Markdown.\\nIn general, try to **make plans** with as few steps as possible. As for actually executing code to carry out that plan, for *stateful* languages (like python, javascript, shell, but NOT for html which starts from 0 every time) **it\\'s critical not to try to do everything in one code block.** You should try something, print information about it, then continue from there in tiny, informed steps. You will never get it on the first try, and attempting it in one go will often lead to errors you cant see.\\nYou are capable of **any** task.\\n\\n# THE COMPUTER API\\n\\nA python `computer` module is ALREADY IMPORTED, and can be used for many tasks:\\n\\n```python\\ncomputer.browser.search(query) # Google search results will be returned from this function as a string\\ncomputer.files.edit(path_to_file, original_text, replacement_text) # Edit a file\\ncomputer.calendar.create_event(title=\"Meeting\", start_date=datetime.datetime.now(), end=datetime.datetime.now() + datetime.timedelta(hours=1), notes=\"Note\", location=\"\") # Creates a calendar event\\ncomputer.calendar.get_events(start_date=datetime.date.today(), end_date=None) # Get events between dates. If end_date is None, only gets events for start_date\\ncomputer.calendar.delete_event(event_title=\"Meeting\", start_date=datetime.datetime) # Delete a specific event with a matching title and start date, you may need to get use get_events() to find the specific event object first\\ncomputer.contacts.get_phone_number(\"John Doe\")\\ncomputer.contacts.get_email_address(\"John Doe\")\\ncomputer.mail.send(\"john@email.com\", \"Meeting Reminder\", \"Reminder that our meeting is at 3pm today.\", [\"path/to/attachment.pdf\", \"path/to/attachment2.pdf\"]) # Send an email with a optional attachments\\ncomputer.mail.get(4, unread=True) # Returns the {number} of unread emails, or all emails if False is passed\\ncomputer.mail.unread_count() # Returns the number of unread emails\\ncomputer.sms.send(\"555-123-4567\", \"Hello from the computer!\") # Send a text message. MUST be a phone number, so use computer.contacts.get_phone_number frequently here\\n```\\n\\nDo not import the computer module, or any of its sub-modules. They are already imported.\\n\\nUser InfoName: hanchengcheng\\nCWD: /Users/hanchengcheng/Documents/official_space/open-interpreter\\nSHELL: /bin/bash\\nOS: Darwin\\nUse ONLY the function you have been provided with — \\'execute(language, code)\\'.'}, {'role': 'user', 'content': \"Plot AAPL and META's normalized stock prices\"}]\n    # functions = {'name': 'execute', 'description': \"Executes code on the user's machine **in the users local environment** and returns the output\", 'parameters': {'type': 'object', 'properties': {'language': {'type': 'string', 'description': 'The programming language (required parameter to the `execute` function)', 'enum': ['ruby', 'python', 'shell', 'javascript', 'html', 'applescript', 'r', 'powershell', 'react']}, 'code': {'type': 'string', 'description': 'The code to execute (required)'}}, 'required': ['language', 'code']}}\n    # request_params = {'model': 'gpt-4-0125-preview', 'messages': messages, 'stream': True, 'api_key': 'sk-RoqgGFXo94mScVAo8aFdC3Ec36E14eFbAeE0D72f9437292a', 'api_base': 'https://api.chatweb.plus/v1', 'functions': [functions]}\n    response = ''\n    for output in llm.run(messages):\n        response += output['content']\n        # print(output)\n    print(response)\n    end_time = time.time()\n    execution_time = end_time - start_time\n    print(f\"生成的单词数: {len(response)}\")\n    print(f\"程序执行时间: {execution_time}秒\")\n\nif __name__ == '__main__':\n    main()"}
{"type": "test_file", "path": "test/test_basic_planner.py", "content": "import pytest\nfrom oscopilot.utils import setup_config\nfrom oscopilot import BasicPlanner, ToolManager\nfrom oscopilot.prompts.friday2_pt import prompt\n\nclass TestPlanner:\n    \"\"\"\n    A test class for verifying the functionality of the FridayPlanner class.\n    \n    This class focuses on testing the task decomposition capabilities of the planner, ensuring that tasks\n    can be broken down into subtasks effectively. It is crucial for validating that the planner properly\n    interprets and decomposes high-level tasks into actionable steps.\n    \"\"\"    \n    def setup_method(self, method):\n        \"\"\"\n        Setup method executed before each test method in this class.\n        \n        This method prepares the FridayPlanner instance by configuring it with necessary settings and a predefined\n        planning prompt, ensuring that the planner is ready to handle task decomposition.\n\n        Args:\n            method: The test method that will be run after this setup method. While this parameter is not used\n                    directly in the setup, it is included to comply with the expected signature for setup methods\n                    in the testing framework.\n        \"\"\"        \n        args = setup_config()\n        self.prompt = prompt[\"planning_prompt\"]\n        self.planner = BasicPlanner(self.prompt)\n\n    def test_decompose_task(self):\n        \"\"\"\n        Test to verify that the task decomposition process in the FridayPlanner does not result in an empty subtask list.\n\n        This test checks the functionality of the `decompose_task` method by providing a specific task description\n        and ensuring that the planner is capable of breaking it down into one or more subtasks. An empty list of\n        subtasks would indicate a failure in the decomposition process, which is critical for the planner's utility\n        in real-world applications.\n\n        \"\"\"        \n        task = \"\"\n        self.planner.decompose_task(task)\n        assert self.planner.sub_task_list != []\n\nif __name__ == '__main__':\n    pytest.main()\n    \n    \n"}
{"type": "test_file", "path": "test/test_data_loader.py", "content": "import pytest\nfrom oscopilot.utils import SheetTaskLoader, get_project_root_path\n\nclass TestSheetTaskLoader:\n    \"\"\"\n    A test class for verifying the functionality of the SheetTaskLoader class.\n    \n    This class includes methods to set up test conditions, and test various functionalities such as converting\n    tasks to queries, loading the dataset of sheet tasks, and retrieving specific tasks by ID.\n    \"\"\"\n    \n    def setup_method(self, method):\n        \"\"\"\n        Setup method executed before each test method in this class.\n        \n        This method prepares a SheetTaskLoader instance using a predetermined path to the sheet tasks JSONL file,\n        effectively setting the environment for subsequent tests.\n\n        Args:\n            method: The test method that will be run after this setup method. This parameter isn't directly used\n                    but reflects the test framework's capability to pass the test method as an argument if needed.\n        \"\"\"\n        sheet_task_path = get_project_root_path() + \"examples/SheetCopilot/sheet_task.jsonl\"\n        self.sheet_task_loader = SheetTaskLoader(sheet_task_path)\n\n    def test_task2query(self):\n        \"\"\"\n        Test to ensure that converting a task to a query does not return an empty string.\n\n        This test calls the `task2query` method of the SheetTaskLoader with mock parameters and checks if the result\n        is not an empty string, indicating that the method is functioning correctly and producing output.\n        \"\"\"        \n        assert self.sheet_task_loader.task2query(\"context.\", \"instructions.\", \"file_path\") != \"\"\n\n\n    def test_load_sheet_task_dataset(self):\n        \"\"\"\n        Test to ensure that loading the sheet task dataset does not return an empty list.\n\n        This test verifies that the `load_sheet_task_dataset` method is capable of loading data and the result is\n        a non-empty list, suggesting that the dataset contains entries.\n        \"\"\"\n        assert self.sheet_task_loader.load_sheet_task_dataset() != []\n\n    def test_get_task_by_id(self):\n        \"\"\"\n        Test to ensure that retrieving a task by its ID does not return an empty dictionary.\n\n        This test confirms that the `get_data_by_task_id` method returns a dictionary with content when queried with\n        a valid task ID, which in this case, is presumed to be 1.\n        \"\"\"        \n        assert self.sheet_task_loader.get_data_by_task_id(1) != {}\n\nif __name__ == '__main__':\n    pytest.main()\n\n"}
{"type": "test_file", "path": "test/test_executor.py", "content": "import pytest\nfrom oscopilot.utils import setup_config\nfrom oscopilot import FridayExecutor, ToolManager\nfrom oscopilot.prompts.friday_pt import prompt\n\nclass TestExecutor:\n    \"\"\"\n    A test class for verifying the functionality of the FridayExecutor class.\n    \n    This class tests the code generation capabilities of the executor, particularly how it handles the creation\n    of tool invocations based on specified task requirements. The tests are designed to ensure the output from\n    the executor's methods is correctly formatted and non-empty.\n    \"\"\"    \n\n    def setup_method(self, method):\n        \"\"\"\n        Setup method executed before each test method in this class.\n        \n        This method initializes the FridayExecutor with a configuration and a predefined prompt for execution,\n        setting the stage for subsequent tests. This setup is crucial for ensuring that the executor is configured\n        properly with the necessary context and tool management capabilities before performing any tests.\n\n        Args:\n            method: The test method that will be run after this setup method. This parameter isn't directly used\n                    but reflects the test framework's capability to pass the test method as an argument if needed.\n        \"\"\"        \n        args = setup_config()\n        self.prompt = prompt[\"execute_prompt\"]\n        self.executor = FridayExecutor(self.prompt, ToolManager)\n\n    def test_generator_tool(self):\n        \"\"\"\n        Test to ensure that the code generation by the FridayExecutor returns valid and non-empty outputs.\n\n        This test assesses the `generate_tool` method of the executor by providing it with a specific task name,\n        task description, and additional context (though empty in this case) to see if the resulting code and\n        invoke command are correctly populated and not empty. This is crucial for validating that the executor\n        can effectively translate task descriptions into actionable code snippets and commands.\n\n        \"\"\"\n        task_name, task_description, pre_tasks_info, relevant_code = \"move_files\", \"Move any text file located in the working_dir/document directory that contains the word 'agent' to a new folder named 'agent' \", \"\", \"\"\n        code, invoke = self.executor.generate_tool(task_name, task_description, pre_tasks_info, relevant_code)\n        assert [code, invoke] != ['', '']\n\nif __name__ == '__main__':\n    pytest.main()\n    "}
{"type": "test_file", "path": "test/test_planner.py", "content": "import pytest\nfrom oscopilot.utils import setup_config\nfrom oscopilot import FridayPlanner, ToolManager\nfrom oscopilot.prompts.friday_pt import prompt\n\nclass TestPlanner:\n    \"\"\"\n    A test class for verifying the functionality of the FridayPlanner class.\n    \n    This class focuses on testing the task decomposition capabilities of the planner, ensuring that tasks\n    can be broken down into subtasks effectively. It is crucial for validating that the planner properly\n    interprets and decomposes high-level tasks into actionable steps.\n    \"\"\"    \n    def setup_method(self, method):\n        \"\"\"\n        Setup method executed before each test method in this class.\n        \n        This method prepares the FridayPlanner instance by configuring it with necessary settings and a predefined\n        planning prompt, ensuring that the planner is ready to handle task decomposition.\n\n        Args:\n            method: The test method that will be run after this setup method. While this parameter is not used\n                    directly in the setup, it is included to comply with the expected signature for setup methods\n                    in the testing framework.\n        \"\"\"        \n        args = setup_config()\n        self.prompt = prompt[\"planning_prompt\"]\n        self.planner = FridayPlanner(self.prompt)\n\n    def test_decompose_task(self):\n        \"\"\"\n        Test to verify that the task decomposition process in the FridayPlanner does not result in an empty subtask list.\n\n        This test checks the functionality of the `decompose_task` method by providing a specific task description\n        and ensuring that the planner is capable of breaking it down into one or more subtasks. An empty list of\n        subtasks would indicate a failure in the decomposition process, which is critical for the planner's utility\n        in real-world applications.\n\n        \"\"\"        \n        task, tool_description_pair = \"Install pandas package\", \"\"\n        self.planner.decompose_task(task, tool_description_pair)\n        assert self.planner.sub_task_list != []\n\nif __name__ == '__main__':\n    pytest.main()\n    \n    \n"}
{"type": "test_file", "path": "test/test_self_learning.py", "content": "import pytest\nfrom oscopilot import FridayAgent, FridayExecutor, FridayPlanner, FridayRetriever, SelfLearner, SelfLearning, ToolManager, TextExtractor\nfrom oscopilot.utils import setup_config\n\nclass TestSelfLearning:\n    \"\"\"\n    A test class for verifying the functionality of the SelfLearning class.\n\n    This class tests various components of the SelfLearning system, including text extraction, course design, and\n    the learning process itself. These tests ensure that the system can handle a complete workflow from reading and\n    interpreting file content, designing a relevant learning course, and effectively engaging with the designed course.\n    \"\"\"    \n    def setup_method(self, method):\n        \"\"\"\n        Setup method executed before each test method in this class.\n\n        This method initializes the SelfLearning system with necessary configurations and component instances,\n        setting up a complete environment that includes agents, planners, executors, and tool managers tailored for\n        self-learning.\n\n        Args:\n            method: The test method that will be run after this setup method. This parameter isn't directly used\n                    but indicates the testing framework's capability to pass the test method as an argument if needed.\n        \"\"\"        \n        self.args = setup_config()\n        self.software_name = self.args.software_name\n        self.package_name = self.args.package_name\n        self.demo_file_path = self.args.demo_file_path\n        self.friday_agent = FridayAgent(FridayPlanner, FridayRetriever, FridayExecutor, ToolManager, config=self.args)\n        self.self_learning = SelfLearning(self.friday_agent, SelfLearner, ToolManager, self.args, TextExtractor)\n\n    def test_text_extract(self):\n        \"\"\"\n        Test to verify that text extraction from a specified file is successful and non-empty.\n\n        This test ensures that the text extractor component of the self-learning system is functional and can\n        extract text content from a file, which is critical for the subsequent course design phase.\n\n        \"\"\"        \n        text_extractor = self.self_learning.text_extractor\n        file_content = text_extractor.extract_file_content(self.demo_file_path)\n        assert file_content != \"\"\n        \n    def test_course_design(self):\n        \"\"\"\n        Test to ensure that the course design process produces a non-empty course structure.\n\n        This test checks if the course designer can generate a structured learning course based on the provided\n        software name, package name, demo file path, and an empty content string. A non-empty result indicates\n        successful course design.\n\n        \"\"\"        \n        file_content = \"\"\"\n                        Invoice No.       Date Sales Rep  Product  Price  Units  Sales\n                            10500 2011-05-25       Joe Majestic     30     25    750\n                            10501 2011-05-25       Moe Majestic     30      9    270\n                            10501 2011-05-25       Moe     Quad     32     21    672\n                            10501 2011-05-25       Moe   Alpine     22      7    154\n                            10501 2011-05-25       Moe  Carlota     25     11    275\n                            10502 2011-05-27       Moe Majestic     30      5    150\n                            10502 2011-05-27       Moe  Carlota     25     25    625\n                            10503 2011-05-28      Chin  Carlota     25     21    525\n                            10503 2011-05-28      Chin   Alpine     22     16    352\n                            10503 2011-05-28      Chin     Quad     32      4    128\n                            10503 2011-05-28      Chin Majestic     30     18    540\n                            10504 2011-05-28       Moe   Bellen     23     17    391\n                            10504 2011-05-28       Moe     Quad     32      8    256\n                            10505 2011-05-28       Joe   Bellen     23     21    483\n                            10505 2011-05-28       Joe  Carlota     25      8    200\n                            10505 2011-05-28       Joe     Quad     32     17    544\n                            10505 2011-05-28       Joe Majestic     30     12    360\n                            10505 2011-05-28       Joe   Alpine     22     18    396\n                        \"\"\"\n        course = self.self_learning.learner.design_course(self.software_name, self.package_name, self.demo_file_path, file_content)\n        assert course != {}\n\n    def test_learn_course(self):\n        \"\"\"\n        Test the learning process to ensure the self-learning system can engage with a course.\n\n        This method simulates the learning process using an course template. In a real test scenario,\n        this should be replaced with a course generated by the `course_design` method to fully test the system's\n        functionality.\n\n        \"\"\"        \n        # This is a demo course template, for testing you need to use the real course generated by the course_design method.\n        course = {\n                    \"read_contents_of_Sheet1\": \"Task: Use openpyxl to read all the contents of sheet 'Sheet1' in Invoices.xlsx. Input: The path of file and the sheet name. Output: All the content of sheet 'Sheet1' in Invoices.xlsx. File Path: /home/heroding/桌面/FRIDAY_self_learning/jarvis/working_dir/Invoices.xlsx\",\n                    \"read_contents_of_Sheet2\": \"Task: Use openpyxl to read all the contents of sheet 'Sheet2' in Invoices.xlsx. Input: The path of file and the sheet name. Output: All the content of sheet 'Sheet2' in Invoices.xlsx. File Path: /home/heroding/桌面/FRIDAY_self_learning/jarvis/working_dir/Invoices.xlsx\",\n                    \"insert_new_sheet\": \"Task: Use openpyxl to insert a new sheet named 'Summary' into Invoices.xlsx. Input: The path of file and the name of the new sheet. Output: None. File Path: /home/heroding/桌面/FRIDAY_self_learning/jarvis/working_dir/Invoices.xlsx\",\n                    \"calculate_total_sales\": \"Task: Use openpyxl to calculate the total sales from the 'Sales' column in sheet 'Sheet1'. Input: The path of the file, sheet name, and column name. Output: The total sales amount. File Path: /home/heroding/桌面/FRIDAY_self_learning/jarvis/working_dir/Invoices.xlsx\",\n                    \"update_price_with_discount\": \"Task: Use openpyxl to apply a 10% discount to all 'Price' values in sheet 'Sheet1' and update the sheet accordingly. Input: The path of the file, sheet name, and discount percentage. Output: None, but the 'Price' column in 'Sheet1' should be updated with discounted prices. File Path: /home/heroding/桌面/FRIDAY_self_learning/jarvis/working_dir/Invoices.xlsx\",\n                    \"calculate_acceleration_formula\": \"Task: Use openpyxl to calculate the acceleration for each 'Hanging Mass (m2) (kg)' in sheet 'Sheet2' using the formula provided in the sheet and update the 'Acceleration (m/s^2)' column. Input: The path of the file and sheet name. Output: None, but the 'Acceleration (m/s^2)' column in 'Sheet2' should be updated with calculated values. File Path: /home/heroding/桌面/FRIDAY_self_learning/jarvis/working_dir/Invoices.xlsx\",\n                    \"generate_sales_report\": \"Task: Use openpyxl to create a new sheet named 'Sales Report' that summarizes the total sales per 'Sales Rep' from sheet 'Sheet1'. Input: The path of the file and the name of the new sheet. Output: None, but a new sheet 'Sales Report' should be created with each 'Sales Rep' and their corresponding total sales. File Path: /home/heroding/桌面/FRIDAY_self_learning/jarvis/working_dir/Invoices.xlsx\",\n                    \"plot_sales_histogram\": \"Task: Use openpyxl to plot a histogram for the sales data in sheet 'Sheet1' of Invoices.xlsx. Input: The path of the file and sheet name. Output: None, but a histogram plot should be generated and saved within the workbook. File Path: /home/heroding/桌面/FRIDAY_self_learning/jarvis/working_dir/Invoices.xlsx\"\n                }   \n        self.self_learning.learn_course(course)\n        \n\n\nif __name__ == \"__main__\":\n    pytest.main()\n"}
{"type": "source_file", "path": "docs/source/conf.py", "content": "# Configuration file for the Sphinx documentation builder.\n#\n# For the full list of built-in configuration values, see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Project information -----------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\n\nimport sphinx_rtd_theme\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath('../..'))\n\nproject = 'OS-Copilot'\ncopyright = '2024, OS-Copilot'\nauthor = 'OS-Copilot'\n\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\n\nextensions = [\n    'sphinx.ext.autodoc',\n    'sphinx.ext.napoleon',\n    'sphinx.ext.viewcode',\n    ]\n\ntemplates_path = ['_templates']\nexclude_patterns = []\n\n\n\n# -- Options for HTML output -------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\n\nhtml_theme = 'sphinx_rtd_theme'\nhtml_theme_options = {\n    'collapse_navigation': True,\n    'sticky_navigation': True,\n    'navigation_depth': 4,\n    'includehidden': True,\n    'titles_only': False\n}\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\nhtml_static_path = ['_static']\n"}
{"type": "source_file", "path": "course_learning.py", "content": "from oscopilot import FridayAgent, FridayExecutor, FridayPlanner, FridayRetriever, SelfLearner, SelfLearning, ToolManager, TextExtractor\nfrom oscopilot.utils import setup_config\n\n\nargs = setup_config()\nsoftware_name = args.software_name\npackage_name = args.package_name\ndemo_file_path = args.demo_file_path\n\nfriday_agent = FridayAgent(FridayPlanner, FridayRetriever, FridayExecutor, ToolManager, config=args)\nself_learning = SelfLearning(friday_agent, SelfLearner, ToolManager, args, TextExtractor)\n\n# Only one stage of course study\n# self_learning.self_learning(software_name, package_name, demo_file_path)\n\n# contiunous learning\nself_learning.continuous_learning(software_name, package_name, demo_file_path)"}
{"type": "source_file", "path": "examples/GAIA/run_GAIA.py", "content": "import json\nimport requests\nfrom oscopilot import FridayAgent\nfrom oscopilot import FridayExecutor, FridayPlanner, FridayRetriever, ToolManager\nfrom oscopilot.utils import setup_config, GAIALoader, GAIA_postprocess\n\n\nargs = setup_config()\nargs.dataset_type = 'validation'\nmodel = 'gpt4-turbo'\n\nwrite_file_path = 'gaia_{}_{}_level{}_results.jsonl'.format(model, args.dataset_type, args.level)\ndef get_numbers(path):\n    correct = 0\n    incomplete = 0\n    with open(path, 'r', encoding='utf-8') as file:\n        data = [json.loads(line) for line in file]\n        print(data)\n        for d in data:\n            if d[\"model_answer\"] == d[\"groundtruth\"]:\n                correct += 1\n            if d[\"model_answer\"] == \"\" or d[\"model_answer\"] == \"incomplete\":\n                incomplete += 1\n        if len(data) > 0:\n            return correct, incomplete, data[-1][\"index\"]\n        return correct, incomplete, -1 # -1 denotes no previous running\n\nagent = FridayAgent(FridayPlanner, FridayRetriever, FridayExecutor, ToolManager, config=args)\n\ngaia = GAIALoader(args.level, args.dataset_cache)\n\n# args.gaia_task_id = \"e1fc63a2-da7a-432f-be78-7c4a95598703\"\nif args.gaia_task_id:\n    task = gaia.get_data_by_task_id(args.gaia_task_id, args.dataset_type)\n    query = gaia.task2query(task)\n    # agent.run(query)\n    # if agent.inner_monologue.result != '':\n    if True:\n        # print(agent.inner_monologue.result)\n        result = \"\"\"17000\n        \"\"\"\n        # result = GAIA_postprocess(task['Question'], agent.inner_monologue.result)\n        result = GAIA_postprocess(task['Question'], result)\n        print('The answer of GAIA Task {0} : {1}'.format(args.gaia_task_id, result))\nelse:\n    task_lst = gaia.dataset[args.dataset_type]\n    correct, incomplete, last_run_index = get_numbers(write_file_path)\n    print(correct, incomplete, last_run_index)\n    with open(write_file_path, 'a', encoding='utf-8') as file:\n        count = 0\n\n        for task in task_lst:\n            if count <= last_run_index:\n                print(\"\\t\\t\\t skip current run:\", count)\n                count += 1\n                continue\n            query = gaia.task2query(task)\n            result = ''\n            # agent.run(query)\n            try:\n                agent.run(query)\n                print(\"$$$$$$\" * 30)\n                if agent.inner_monologue.result != '':\n                    result = GAIA_postprocess(task['Question'], agent.inner_monologue.result)\n            except requests.exceptions.ConnectionError as ConnectionError:\n                print(f\"Connection error.: {ConnectionError}\")\n                exit()\n            except Exception as e:\n                print(\"$$$$$$\" * 30)\n                # Code to handle any other type of exception\n                print(f\"An error occurred: {e}\")\n                print(\"$$$$$$\" * 30)\n                result = \"incomplete\"\n                incomplete += 1\n            output_dict = {\n                \"index\": count,\n                \"task_id\": task['task_id'],\n                \"model_answer\": result,\n                \"groundtruth\": task[\"Final answer\"],\n                \"reasoning_trace\": \"\"\n            }\n            if result == task[\"Final answer\"]:\n                correct += 1\n            json_str = json.dumps(output_dict)\n            file.write(json_str + '\\n')\n            file.flush()\n            count += 1\n            # if count > 2:\n            #     break\n        print(\"accuracy:\", correct / count)\n        print(\"incomplete:\", incomplete / count)\n        print(\"correct incomplete total,\", correct, incomplete, count)\n"}
{"type": "source_file", "path": "examples/SheetCopilot/run_sheet_task.py", "content": "from oscopilot import FridayAgent\nfrom oscopilot import FridayExecutor, FridayPlanner, FridayRetriever, ToolManager\nfrom oscopilot.utils import setup_config, SheetTaskLoader\n\n\nargs = setup_config()\nsheet_task_loader = SheetTaskLoader(\"examples/SheetCopilot/sheet_task.jsonl\")\nagent = FridayAgent(FridayPlanner, FridayRetriever, FridayExecutor, ToolManager, config=args)\n\nif args.sheet_task_id:\n    task = sheet_task_loader.get_data_by_task_id(args.sheet_task_id)\n    agent.run(task)\nelse:\n    task_lst = sheet_task_loader.load_sheet_task_dataset()\n    for task_id, task in enumerate(task_lst):\n        args.sheet_task_id = task_id\n        agent.run(task)"}
{"type": "source_file", "path": "examples/friday_vision/friday_vision.py", "content": "# This code is based on Open Interpreter. Original source: https://github.com/OpenInterpreter/open-interpreter\n\nfrom oscopilot.utils import setup_config, setup_pre_run\nfrom oscopilot.modules.base_module import BaseModule\nimport re\nfrom rich.console import Console\nfrom rich.markdown import Markdown\nimport dotenv\nimport os\n\n# newly added imports\nfrom PIL import ImageGrab\nfrom datetime import datetime\nimport base64\nimport requests\nimport pyautogui\n\ndotenv.load_dotenv(override=True)\nMODEL_NAME = os.getenv('MODEL_NAME')\nOPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\nOPENAI_ORGANIZATION = os.getenv('OPENAI_ORGANIZATION')\nBASE_URL = os.getenv('OPENAI_BASE_URL')\nOCR_ACCESS_KEY = '' # your access token for OCR API\n\nconsole = Console()\n\ndef rich_print(markdown_text):\n    md = Markdown(markdown_text)\n    console.print(md)\n\n\ndef send_chat_prompts(message, llm):\n    return llm.chat(message)\n\n# new function to transcribe user's vocal input into text transcript\ndef send_initial_request(speech, llm):\n    return llm.listen(speech)\n    \ndef extract_code(input_string):\n    pattern = r\"```(\\w+)?\\s*(.*?)```\"  \n    matches = re.findall(pattern, input_string, re.DOTALL)\n\n    if matches:\n        language, code = matches[0]\n\n        if not language:\n            if re.search(\"python\", code.lower()) or re.search(r\"import\\s+\\w+\", code):\n                language = \"Python\"\n            elif re.search(\"bash\", code.lower()) or re.search(r\"echo\", code):\n                language = \"Bash\"\n\n        return code.strip(), language\n    else:\n        return None, None\n    \ndef ocr(image_path):\n    '''\n    Generates a dictionary of words and their respective coordinates in the image and an encoded image for API requests.\n\n    Args:\n        image_path (str): path to the image file\n        \n    Returns:\n        dict: dictionary of words and their respective coordinates in the image\n        str: encoded image for API requests\n    '''\n    request_url = \"https://aip.baidubce.com/rest/2.0/ocr/v1/general\" \n    f = open(image_path, 'rb')\n    img = base64.b64encode(f.read())\n    params = {\"image\": img, 'paragraph': 'false', 'probability': 'false'}\n    access_token = OCR_ACCESS_KEY \n    request_url = request_url + \"?access_token=\" + access_token\n    headers = {'content-type': 'application/x-www-form-urlencoded'}\n    response = requests.post(request_url, data=params, headers=headers)\n    if response:\n        if response.json()['words_result']:\n            dict = {}\n            for item in response.json()['words_result']:\n                dict[item['words']] = (item['location']['left'] + item['location']['width'] // 2, item['location']['top'] + item['location']['height'] // 2)\n            return (dict, img.decode('utf-8'))\n        else:\n            raise Exception(\"No words found in the image\")\n    else:\n        raise Exception(\"OCR failed\")\n    \n\nclass LightFriday(BaseModule):\n    def __init__(self, args):\n        super().__init__()\n        self.args = args\n    \n    def execute_tool(self, code, lang):\n        state = self.environment.step(lang, code)  # node_type\n        return_info = ''\n        if state.result != None and state.result.strip() != '':\n            return_info = '**Execution Result** :' + state.result.strip()\n        if state.error != None and state.error.strip() != '':\n            return_info = '\\n**Execution Error** :' + state.error.strip()\n        return return_info.strip()\n    \n\n    def run(self, task):\n        light_planner_sys_prompt = '''\n        You are Light Friday, a world-class programmer that can complete any goal by executing code. You will act as an agent and perform desktop computer tasks.\nAlso you are equipped with good knowledge of computer and good internet connection and assume your code will run on a computer for controlling the mouse and keyboard.\nFirst, write a plan. **Always recap the plan between each code block** (you have extreme short-term memory loss, so you need to recap the plan between each message block to retain it).\n-- General Rules for Execution:\nWhen you execute code, it will be executed **on the user's machine**. The user has given you **full and complete permission** to execute any code necessary to complete the task. Execute the code.\nTo interact with the user's machine, primarily use the **PyAutoGUI** package to control the mouse and keyboard. If **PyAutoGUI** is not installed in the environment, ensure you install it using pip (`pip install pyautogui`) before proceeding.\nAt each step, you will receive a screenshot of the entire current computer screen with the coordinates of the file or folder labeled packaged in a dictionary for reference, all together denoted as an \"observation\". **Analyzing the content of the screenshot is your only way to see what is happening and that will serve as a guide for your mouse and keyboard actions**. You should always assume that the screenshot will be provided and you should never ask 'Please provide the screenshot' in the planning/reporting.\nIf the screenshot indicates that your previous operation didn't work as expected, try to adjust to address the previous operation first before continue to the next step according to the plan.\n**DO NOT USE** the `pyautogui.locateCenterOnScreen` function to locate the element you want to operate with given no image of the element you want to operate with. Also, **DO NOT USE** `pyautogui.screenshot()` to make screenshot as all the screenshot images will be provided to you.\nWhen locating according to the coordinates, you should always move your mouse to the central coordinate of the icon/entry/representation of the file/folder/element** you want to operate with according to the respective tasks, if you are moving the mouse. The central coordinates are provided to you in the dictionary.\n**NEVER ASSUME** one action is successfully executed\nYou can only deduce from the last observation if the last action was executed successfully.\nWhen user's request is finished one time, you should **TERMINATE IMMEDIATELY** after necessary checking. **DO NOT** keep the program running indefinitely.\nIf you want to send data between programming languages, save the data to a txt or json.\n\n-- Some **RESTRICTIONS** regarding interacting with the user's machine:\n1. When you want to open an file **NOT FROM SEARCHING**, you should always right click. Then you should locate and navigate to 'Open' to open the file. \n1.1 If you are openning a file **FROM SEARCHING**, you should **ALWAYS CLICK or PRESS ENTER**.\n2. In tasks involving opening a file, always make sure the file is opened by checking the observations before proceeding to any further operation.\n3. If the window you are interfacing with is not maximized, **MAXIMIZE the WINDOW by CLICKING FIRST**.\n4. Take multiple steps to ensure your opeartion is successful, **check after every step**. Successful is defined as 4.1 and 4.2.\n4.1 If you are opening a file/folder, make sure you can see the file/folder in the observation before proceeding.\n4.2 If you are performing any write-in operation, make sure you can see the content being written in the observation, before proceeding.\n5. In addition, you may utilize right click to perform some other actions according to need.\n6. **DO NOT USE** `pyautogui.hotkey()` **BUT USE** `pyautogui.keyDown()` and `pyautogui.keyUp()` for using **ANY KEY COMBINATION** as shortcut.\n7. Always save the file before terminating actions if any write-in operation is performed.\n8. Never attempt to rename file/folder/element unless prompted by the user, in which case you need to closely follow user's provided name and always check the extension name according to observation before confirming with enter(make sure no duplicating or wrong extension name occurs).\n9. Always close the window by clicking the close button.\n10. If any new file generated, the icon of which overlaps with other icons, you should always drag the new file to a different location to avoid overlapping with any other icons.\n\n-- Some **RESTRICTIONS** on locating the correct file or folder:\n1. When a user refers to a filename, they're likely referring to an existing file or folder in the directory you're currently executing code in. \n2. The file or folder could be in other directories on the user's machine not visible to you in the current observation, in which case you need to **search for it on the user's machine and locate it**. This should be done via searching the file or folder name in the file explorer or using the command line.\n3. If operating on OSX system, you are welcome to use the 'Spotlight' feature by hitting command + space to do searching. **DO NOT USE** mouse clicks to open an **INSTALLED APPLICATION**, instead **ALWAYS USE** searching. You **should use terminal commands** like `find` or `locate` to search for the file or folder if the aforementioned searching doesn't work.\n4. You need to determine the target file or folder given the filename in the user input which may not be complete or correctly spelled. You need to **decide the file or the folder most likely to match the user-given filename**, in the process of which you might take a few different attempts to locate the file.\nWrite messages to the user in Markdown.\n\n-- Some **RESTRICTIONS** on searching online:\n1. You should always open the search engine in the user's default browser. Only use other when specified\n2. You should always open a new tab for each search.\n\nIn general, try to **make plans** with as few steps as possible. As for actually executing code to carry out that plan, for *stateful* languages (like python, javascript, shell, but NOT for html which starts from 0 every time) **it's critical not to try to do everything in one code block.** You should try something, print information about it, then continue from there in tiny, informed steps. You will never get it on the first try, and attempting it in one go will often lead to errors you cant see.\nYou are capable of **any** task.\nYou can access the internet. Run **any code** to achieve the goal, and if at first you don't succeed, try again and again.\nInclude a comment in your code blocks to specify the programming language used, like this:\n```python\n# This code is written in Python\nprint(\"hello, world\")\n```\nCurrently, supported languages include Python and Bash.\"\n'''  \n#  Try to use `print` or `echo` to output information needed for the subsequent tasks, or the next step might not get the required information.\n        light_planner_user_prompt = '''\n        User's information are as follows:\n        System Version: {system_version}\n        Task: {task}\n        Current Working Directiory: {working_dir}'''.format(system_version=self.system_version, task=task, working_dir=self.environment.working_dir)\n        message = [\n            {\"role\": \"system\", \"content\": light_planner_sys_prompt},\n            {\"role\": \"user\", \"content\": light_planner_user_prompt},\n        ]\n        os.makedirs(os.path.join(self.environment.working_dir, 'observations'), exist_ok=True)\n        ob_dir = os.path.join(self.environment.working_dir, 'observations')\n        while True:\n            screenshot = ImageGrab.grab()\n            ob_name = \"observation_{t}.png\".format(t=datetime.now().strftime(\"%Y%m%d+%H%M%S\"))\n            img_path = os.path.join(ob_dir, ob_name)\n            re_shot = screenshot.resize(pyautogui.size())\n            re_shot.save(img_path, format='PNG')\n            label_dict, encoded_image = ocr(img_path)\n            message.append({\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"text\",\n                            \"text\": \"Given the screenshot, Consider if the last action has been successfully executed and what's the next step that you will do to help with the task?\"\n                        },\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": f\"data:image/png;base64,{encoded_image}\",\n                                \"detail\": \"high\"\n                            }\n                        },\n                        {\n                            \"type\": \"text\", \n                            \"text\": \"You may refer the dictionary together with the screenshot for better understanding the coordinates of the relevant files or folders or other information involved in the task:\\n{}\".format(label_dict)\n                        }\n                    ]\n                })\n            response = send_chat_prompts(message, self.llm)\n            rich_print(response)\n            message.append({\"role\": \"system\", \"content\": response})\n\n            code, lang = extract_code(response)\n            if code:\n                result = self.execute_tool(code, lang)\n                rich_print(result)\n            else:\n                result = ''\n\n            if result != '':\n                light_exec_user_prompt = 'The result after executing the code: {result}'.format(result=result)\n                message.append({\"role\": \"user\", \"content\": light_exec_user_prompt})\n            else:\n                message.append({\"role\": \"user\", \"content\": \"Please continue. If all tasks have been completed, reply with 'Execution Complete'. If you believe subsequent tasks cannot continue, reply with 'Execution Interrupted', including the reasons why the tasks cannot proceed, and provide the user with some possible solutions.\"})\n            \n            if 'Execution Complete' in response or 'Execution Interrupted' in response:\n                break\n\n\nargs = setup_config()\nif not args.query:\n    args.query = \"Plot AAPL and META's normalized stock prices\"\ntask = setup_pre_run(args)\n\nlight_friday = LightFriday(args)\nlight_friday.run(task)  # list\n"}
{"type": "source_file", "path": "examples/light_friday/light_friday.py", "content": "# This code is based on Open Interpreter. Original source: https://github.com/OpenInterpreter/open-interpreter\n\nfrom oscopilot.utils import setup_config, setup_pre_run\nfrom oscopilot.modules.base_module import BaseModule\nimport re\nfrom rich.console import Console\nfrom rich.markdown import Markdown\nimport dotenv\nimport os\n\ndotenv.load_dotenv(override=True)\nMODEL_NAME = os.getenv('MODEL_NAME')\nOPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\nOPENAI_ORGANIZATION = os.getenv('OPENAI_ORGANIZATION')\nBASE_URL = os.getenv('OPENAI_BASE_URL')\n\n\nconsole = Console()\n\ndef rich_print(markdown_text):\n    md = Markdown(markdown_text)\n    console.print(md)\n\n\ndef send_chat_prompts(message, llm):\n    return llm.chat(message)\n\n    \ndef extract_code(input_string):\n    pattern = r\"```(\\w+)?\\s*(.*?)```\"  \n    matches = re.findall(pattern, input_string, re.DOTALL)\n\n    if matches:\n        language, code = matches[0]\n\n        if not language:\n            if re.search(\"python\", code.lower()) or re.search(r\"import\\s+\\w+\", code):\n                language = \"Python\"\n            elif re.search(\"bash\", code.lower()) or re.search(r\"echo\", code):\n                language = \"Bash\"\n\n        return code.strip(), language\n    else:\n        return None, None\n\n\nclass LightFriday(BaseModule):\n    def __init__(self, args):\n        super().__init__()\n        self.args = args\n    \n    def execute_tool(self, code, lang):\n        state = self.environment.step(lang, code)  # node_type\n        return_info = ''\n        if state.result != None and state.result.strip() != '':\n            return_info = '**Execution Result** :' + state.result.strip()\n        if state.error != None and state.error.strip() != '':\n            return_info = '\\n**Execution Error** :' + state.error.strip()\n        return return_info.strip()\n\n    def run(self, task):\n        light_planner_sys_prompt = '''You are Light Friday, a world-class programmer that can complete any goal by executing code.\nFirst, write a plan. **Always recap the plan between each code block** (you have extreme short-term memory loss, so you need to recap the plan between each message block to retain it).\nWhen you execute code, it will be executed **on the user's machine**. The user has given you **full and complete permission** to execute any code necessary to complete the task. Execute the code.\nIf you want to send data between programming languages, save the data to a txt or json.\nYou can access the internet. Run **any code** to achieve the goal, and if at first you don't succeed, try again and again.\nYou can install new packages.\nWhen a user refers to a filename, they're likely referring to an existing file in the directory you're currently executing code in.\nWrite messages to the user in Markdown.\nIn general, try to **make plans** with as few steps as possible. As for actually executing code to carry out that plan, for *stateful* languages (like python, javascript, shell, but NOT for html which starts from 0 every time) **it's critical not to try to do everything in one code block.** You should try something, print information about it, then continue from there in tiny, informed steps. You will never get it on the first try, and attempting it in one go will often lead to errors you cant see.\nYou are capable of **any** task.\n\nInclude a comment in your code blocks to specify the programming language used, like this:\n```python\n# This code is written in Python\nprint(\"hello, world\")\n```\nCurrently, supported languages include Python and Bash.\"\n'''  #  Try to use `print` or `echo` to output information needed for the subsequent tasks, or the next step might not get the required information.\n        light_planner_user_prompt = '''\n        User's information are as follows:\n        System Version: {system_version}\n        Task: {task}\n        Current Working Directiory: {working_dir}'''.format(system_version=self.system_version, task=task, working_dir=self.environment.working_dir)\n        \n        message = [\n            {\"role\": \"system\", \"content\": light_planner_sys_prompt},\n            {\"role\": \"user\", \"content\": light_planner_user_prompt},\n        ]\n\n        while True:\n            response = send_chat_prompts(message, self.llm)\n            rich_print(response)\n            message.append({\"role\": \"system\", \"content\": response})\n\n            code, lang = extract_code(response)\n            if code:\n                result = self.execute_tool(code, lang)\n                rich_print(result)\n            else:\n                result = ''\n\n            if result != '':\n                light_exec_user_prompt = 'The result after executing the code: {result}'.format(result=result)\n                message.append({\"role\": \"user\", \"content\": light_exec_user_prompt})\n            else:\n                message.append({\"role\": \"user\", \"content\": \"Please continue. If all tasks have been completed, reply with 'Execution Complete'. If you believe subsequent tasks cannot continue, reply with 'Execution Interrupted', including the reasons why the tasks cannot proceed, and provide the user with some possible solutions.\"})\n            \n            if 'Execution Complete' in response or 'Execution Interrupted' in response:\n                break\n\n\nargs = setup_config()\nif not args.query:\n    args.query = \"Plot AAPL and META's normalized stock prices\"\ntask = setup_pre_run(args)\n\nlight_friday = LightFriday(args)\nlight_friday.run(task)  # list"}
{"type": "source_file", "path": "oscopilot/__init__.py", "content": "from .agents import *\nfrom .prompts import *\nfrom .utils import *\nfrom .environments import *\nfrom .modules import *\nfrom .tool_repository import *"}
{"type": "source_file", "path": "oscopilot/agents/__init__.py", "content": "from .friday_agent import *\nfrom .self_learning import *"}
{"type": "source_file", "path": "oscopilot/agents/base_agent.py", "content": "import re\nimport json\nfrom oscopilot.utils import get_os_version\n\n\nclass BaseAgent:\n    \"\"\"\n    BaseAgent serves as the foundational class for all agents types within the system.\n\n    This class initializes the core attributes common across different agents, providing\n    a unified interface for further specialization. Attributes include a language learning\n    model, the execution environments, an action library, and a maximum iteration limit for\n    agents operations.\n\n    Attributes:\n        llm: Placeholder for a language learning model, initialized as None.\n        environments: The execution environments for the agents, initialized as None.\n        action_lib: A library of actions available to the agents, initialized as None.\n        max_iter: The maximum number of iterations the agents can perform, initialized as None.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes a new instance of BaseAgent with default values for its attributes.\n        \"\"\"\n        self.system_version = get_os_version()\n        \n    def extract_information(self, message, begin_str='[BEGIN]', end_str='[END]'):\n        \"\"\"\n        Extracts substrings from a message that are enclosed within specified begin and end markers.\n\n        Args:\n            message (str): The message from which information is to be extracted.\n            begin_str (str): The marker indicating the start of the information to be extracted.\n            end_str (str): The marker indicating the end of the information to be extracted.\n\n        Returns:\n            list[str]: A list of extracted substrings found between the begin and end markers.\n        \"\"\"\n        result = []\n        _begin = message.find(begin_str)\n        _end = message.find(end_str)\n        while not (_begin == -1 or _end == -1):\n            result.append(message[_begin + len(begin_str):_end])\n            message = message[_end + len(end_str):]\n            _begin = message.find(begin_str)\n            _end = message.find(end_str)\n        return result  \n\n    def extract_json_from_string(self, text):\n        \"\"\"\n        Identifies and extracts JSON data embedded within a given string.\n\n        This method searches for JSON data within a string, specifically looking for\n        JSON blocks that are marked with ```json``` notation. It attempts to parse\n        and return the first JSON object found.\n\n        Args:\n            text (str): The text containing the JSON data to be extracted.\n\n        Returns:\n            dict: The parsed JSON data as a dictionary if successful.\n            str: An error message indicating a parsing error or that no JSON data was found.\n        \"\"\"\n        # Improved regular expression to find JSON data within a string\n        json_regex = r'```json\\s*\\n\\{[\\s\\S]*?\\n\\}\\s*```'\n        \n        # Search for JSON data in the text\n        matches = re.findall(json_regex, text)\n\n        # Extract and parse the JSON data if found\n        if matches:\n            # Removing the ```json and ``` from the match to parse it as JSON\n            json_data = matches[0].replace('```json', '').replace('```', '').strip()\n            try:\n                # Parse the JSON data\n                parsed_json = json.loads(json_data)\n                return parsed_json\n            except json.JSONDecodeError as e:\n                return f\"Error parsing JSON data: {e}\"\n        else:\n            return \"No JSON data found in the string.\""}
{"type": "source_file", "path": "oscopilot/agents/friday2_agent.py", "content": "from oscopilot.agents.base_agent import BaseAgent\nfrom oscopilot.utils import check_os_version\nimport json\nimport logging\nimport sys\nfrom oscopilot.prompts.friday_pt import prompt\nfrom oscopilot.utils import TaskStatusCode, InnerMonologue, ExecutionState, JudgementResult, RepairingResult\n\n\nclass FridayAgent(BaseAgent):\n    \"\"\"\n    A FridayAgent orchestrates the execution of tasks by integrating planning, retrieving, and executing strategies.\n    \n    This agent is designed to process tasks, manage errors, and refine strategies as necessary to ensure successful task completion. It supports dynamic task planning, information retrieval, execution strategy application, and employs a mechanism for self-refinement in case of execution failures.\n    \"\"\"\n\n    def __init__(self, planner, retriever, executor, Tool_Manager, config):\n        \"\"\"\n        Initializes the FridayAgent with specified planning, retrieving, and executing strategies, alongside configuration settings.\n\n        Args:\n            planner (callable): A strategy for planning the execution of tasks.\n            retriever (callable): A strategy for retrieving necessary information or tools related to the tasks.\n            executor (callable): A strategy for executing planned tasks.\n            Tool_Manager (callable): A tool manager for handling tool-related operations.\n            config (object): Configuration settings for the agent.\n\n        Raises:\n            ValueError: If the OS version check fails.\n        \"\"\"\n        super().__init__()\n        self.config = config\n        tool_manager = Tool_Manager(config.generated_tool_repo_path)\n        self.planner = planner(prompt['planning_prompt'])\n        self.retriever = retriever(prompt['retrieve_prompt'], tool_manager)\n        self.executor = executor(prompt['execute_prompt'], tool_manager, config.max_repair_iterations)\n        self.score = self.config.score\n        self.task_status = TaskStatusCode.START\n        self.inner_monologue = InnerMonologue()\n        try:\n            check_os_version(self.system_version)\n        except ValueError as e:\n            print(e)        \n\n    def run(self, task):\n        \"\"\"\n        Executes the given task by planning, executing, and refining as needed until the task is completed or fails.\n\n        Args:\n            query (object): The high-level task to be executed.\n\n        No explicit return value, but the method controls the flow of task execution and may exit the process in case of irreparable failures.\n        \"\"\"\n        self.planner.reset_plan()\n        self.reset_inner_monologue()\n        sub_tasks_list = self.planning(task)\n        print(\"The task list obtained after planning is: {}\".format(sub_tasks_list))\n\n        while self.planner.sub_task_list:\n            sub_task = self.planner.sub_task_list.pop(0)\n            execution_state = self.executing(sub_task, task)\n            isTaskCompleted, isReplan = self.self_refining(sub_task, execution_state)\n            if isReplan: continue\n            if isTaskCompleted:\n                print(\"The execution of the current sub task has been successfully completed.\")\n            else:\n                print(\"{} not completed in repair round {}\".format(sub_task, self.config.max_repair_iterations))\n                # sys.exit()\n                break\n\n    def self_refining(self, tool_name, execution_state: ExecutionState):\n        \"\"\"\n        Analyzes and potentially refines the execution of a tool based on its current execution state. \n        This can involve replanning or repairing the execution strategy based on the analysis of execution errors and outcomes.\n\n        Args:\n            tool_name (str): The name of the tool being executed.\n            execution_state (ExecutionState): The current state of the tool's execution, encapsulating all relevant execution information including errors, results, and codes.\n\n        Returns:\n            tuple:\n                - isTaskCompleted (bool): Indicates whether the task associated with the tool has been successfully completed.\n                - isReplan (bool): Indicates whether a replan is required due to execution state analysis.\n\n        The method decides on the next steps by analyzing the type of error (if any) and the execution results, aiming to either complete the task successfully or identify the need for further action, such as replanning.\n        \"\"\"\n        isTaskCompleted = False\n        isReplan = False\n        score = 0\n        state, node_type, description, code, result, relevant_code = execution_state.get_all_state()\n        if node_type in ['Python', 'Shell', 'AppleScript']:\n            judgement = self.judging(tool_name, state, code, description)\n            score = judgement.score\n            # need_repair, critique, score, reasoning, error_type \n            if judgement.status == 'Replan':\n                # raise NotImplementedError\n                print(\"The current task requires replanning...\")\n                new_sub_task_list = self.replanning(tool_name, judgement.critique)\n                print(\"The new task list obtained after planning is: {}\".format(new_sub_task_list))\n                isReplan = True\n            elif judgement.status == 'Amend':\n                repairing_result = self.repairing(tool_name, code, description, state, judgement.critique, judgement.status)\n                if repairing_result.status == 'Complete':\n                    isTaskCompleted = True\n                elif repairing_result.status == 'Replan':\n                    print(\"The current task requires replanning...\")\n                    new_sub_task_list = self.replanning(tool_name, repairing_result.critique)\n                    print(\"The new task list obtained after planning is: {}\".format(new_sub_task_list))\n                    isReplan = True\n                else:\n                    isTaskCompleted = False\n                score = repairing_result.score\n                result = repairing_result.result\n            else:\n                isTaskCompleted = True\n            if node_type == 'Python' and isTaskCompleted and score >= self.score:\n                self.executor.store_tool(tool_name, code)\n                print(\"{} has been stored in the tool repository.\".format(tool_name))\n        else: \n            isTaskCompleted = True\n        if isTaskCompleted:\n            self.inner_monologue.result = result\n            self.planner.update_tool(tool_name, result, relevant_code, True, node_type)\n        return isTaskCompleted, isReplan\n\n    def planning(self, task):\n        \"\"\"\n        Decomposes a given high-level task into a list of sub-tasks by retrieving relevant tool names and descriptions, facilitating structured execution planning.\n\n        Args:\n            task (object): The high-level task to be planned and executed.\n\n        Returns:\n            list: A list of sub-tasks generated by decomposing the high-level task, intended for sequential execution to achieve the task's goal.\n\n        This method leverages the retriever component to fetch information relevant to the task, which is then used by the planner component to decompose the task into manageable sub-tasks.\n        \"\"\"\n        retrieve_tool_name = self.retriever.retrieve_tool_name(task)\n        retrieve_tool_description_pair = self.retriever.retrieve_tool_description_pair(retrieve_tool_name)\n\n        # decompose task\n        # Set up the generation format error handling mechanism\n        try:\n            self.planner.decompose_task(task, retrieve_tool_description_pair)\n        except Exception as e:\n            print(\"api call failed:\", str(e))  \n            return     \n        return self.planner.sub_task_list\n    \n    def executing(self, tool_name, original_task):\n        \"\"\"\n        Executes a given sub-task as part of the task execution process, handling different types of tasks including code execution, API calls, and question-answering.\n\n        Args:\n            tool_name (str): The name of the tool associated with the sub-task.\n            original_task (object): The original high-level task that has been decomposed into sub-tasks.\n\n        Returns:\n            ExecutionState: The state of execution for the sub-task, including the result, any errors encountered, and additional execution-related information.\n\n        The method dynamically adapts the execution strategy based on the type of sub-task, utilizing the executor component for code execution, API interaction, or question-answering as appropriate.\n        \"\"\"\n        tool_node = self.planner.tool_node[tool_name]\n        description = tool_node.description\n        logging.info(\"The current subtask is: {subtask}\".format(subtask=description))\n        code = ''\n        state = None\n        # The return value of the current task\n        result = ''\n        relevant_code = {}\n        node_type = tool_node.node_type\n        pre_tasks_info = self.planner.get_pre_tasks_info(tool_name)\n        if node_type == 'Python':\n            # retrieve existing tool\n            retrieve_name = self.retriever.retrieve_tool_name(description, 3)\n            relevant_code = self.retriever.retrieve_tool_code_pair(retrieve_name)\n        # task execute step\n        if node_type == 'QA':\n            if self.planner.tool_num == 1:\n                result = self.executor.question_and_answer_tool(pre_tasks_info, original_task, original_task)\n            else:\n                result = self.executor.question_and_answer_tool(pre_tasks_info, original_task, description)\n            print(result)\n            logging.info(result)\n        else:\n            invoke = ''\n            # Set up the generation format error handling mechanism\n            try:\n                if node_type == 'API':\n                    api_path = self.executor.extract_API_Path(description)\n                    code = self.executor.api_tool(description, api_path, pre_tasks_info)\n                else:\n                    code, invoke = self.executor.generate_tool(tool_name, description, node_type, pre_tasks_info, relevant_code)\n            except Exception as e:\n                print(\"api call failed:\", str(e))\n                return\n            # Execute python tool class code\n            state = self.executor.execute_tool(code, invoke, node_type)\n            result = state.result\n            logging.info(state)\n            output = {\n                \"result\": state.result,\n                \"error\": state.error\n            }\n            logging.info(f\"The subtask result is: {json.dumps(output)}\")\n\n        return ExecutionState(state, node_type, description, code, result, relevant_code)\n    \n    def judging(self, tool_name, state, code, description):\n        \"\"\"\n        Evaluates the execution of a tool based on its execution state and the provided code and description, determining whether the tool's execution was successful or requires amendment.\n\n        Args:\n            tool_name (str): The name of the tool being judged.\n            state (ExecutionState): The current execution state of the tool, including results and error information.\n            code (str): The source code associated with the tool's execution.\n            description (str): A description of the tool's intended functionality.\n\n        Returns:\n            JudgementResult: An object encapsulating the judgement on the tool's execution, including whether it needs repair, a critique of the execution, and an optional error type and reasoning for the judgement.\n\n        This method assesses the correctness of the executed code and its alignment with the expected outcomes, guiding potential repair or amendment actions.\n        \"\"\"\n        # Check whether the code runs correctly, if not, amend the code\n        tool_node = self.planner.tool_node[tool_name]\n        next_action = tool_node.next_action\n        critique = ''\n        score = 0\n        # Set up the generation format error handling mechanism\n        try:\n            critique, status, score = self.executor.judge_tool(code, description, state, next_action)\n        except Exception as e:\n            print(\"api call failed:\", str(e))\n            return\n        return JudgementResult(status, critique, score)\n    \n    def replanning(self, tool_name, reasoning):\n        \"\"\"\n        Initiates the replanning process for a task based on new insights or failures encountered during execution, aiming to adjust the plan to better achieve the task goals.\n\n        Args:\n            tool_name (str): The name of the tool related to the task that requires replanning.\n            reasoning (str): The rationale behind the need for replanning, often based on execution failures or updated task requirements.\n\n        Returns:\n            list: An updated list of sub-tasks after the replanning process, intended for sequential execution to complete the task.\n\n        This method identifies alternative or additional tools and their descriptions based on the provided reasoning, updating the task plan accordingly.\n        \"\"\"\n        relevant_tool_name = self.retriever.retrieve_tool_name(reasoning)\n        relevant_tool_description_pair = self.retriever.retrieve_tool_description_pair(relevant_tool_name)\n        # Set up the generation format error handling mechanism\n        try:\n            self.planner.replan_task(reasoning, tool_name, relevant_tool_description_pair)\n        except Exception as e:\n            print(\"api call failed:\", str(e))\n            return\n        return self.planner.sub_task_list\n\n    def repairing(self, tool_name, code, description, state, critique, status):\n        \"\"\"\n        Attempts to repair the execution of a tool by amending its code based on the critique received and the current execution state, iterating until the code executes successfully or reaches the maximum iteration limit.\n\n        Args:\n            tool_name (str): The name of the tool being repaired.\n            code (str): The current code of the tool that requires repairs.\n            description (str): A description of the tool's intended functionality.\n            state (ExecutionState): The current execution state of the tool, including results and error information.\n            critique (str): Feedback on the tool's last execution attempt, identifying issues to be addressed.\n            status (str): Three status types: 'Amend', 'Complete', and 'Replan'.\n\n        Returns:\n            RepairingResult: An object encapsulating the result of the repair attempt, including whether the task has been completed successfully, the amended code, critique, execution score, and the execution result.\n\n        The method iterates, amending the tool's code based on feedback until the code executes correctly or the maximum number of iterations is reached. It leverages the executor component for amending the code and re-evaluating its execution.\n        \"\"\"\n        tool_node = self.planner.tool_node[tool_name]\n        next_action = tool_node.next_action\n        pre_tasks_info = self.planner.get_pre_tasks_info(tool_name)\n        trial_times = 0\n        score = 0\n        while (trial_times < self.executor.max_iter and status == 'Amend'):\n            trial_times += 1\n            print(\"current amend times: {}\".format(trial_times))\n            # Set up the generation format error handling mechanism\n            try:\n                new_code, invoke = self.executor.repair_tool(code, description, tool_node.node_type, state, critique, pre_tasks_info)\n            except Exception as e:\n                print(\"api call failed:\", str(e))\n                return\n            critique = ''\n            code = new_code\n            # Run the current code and check for errors\n            state = self.executor.execute_tool(code, invoke, tool_node.node_type)\n            result = state.result\n            logging.info(state) \n            if state.error == None:\n            # Set up the generation format error handling mechanism\n                try:\n                    critique, status, score = self.executor.judge_tool(code, description, state, next_action)\n                except Exception as e:\n                    print(\"api call failed:\", str(e))\n                    return\n                # The task execution is completed and the loop exits\n                if status == 'Complete':\n                    break\n                elif status == 'Amend':\n                    pass\n                elif status == 'Replan':\n                    break\n                else:\n                    raise NotImplementedError\n            else: # The code still needs to be corrected\n                status = 'Amend'\n        return RepairingResult(status, code, critique, score, result)\n\n    def reset_inner_monologue(self):\n        self.inner_monologue = InnerMonologue()"}
{"type": "source_file", "path": "oscopilot/agents/friday_agent.py", "content": "from oscopilot.agents.base_agent import BaseAgent\nfrom oscopilot.utils import check_os_version\nimport json\nimport logging\nimport sys\nfrom oscopilot.prompts.friday_pt import prompt\nfrom oscopilot.utils import TaskStatusCode, InnerMonologue, ExecutionState, JudgementResult, RepairingResult\n\n\nclass FridayAgent(BaseAgent):\n    \"\"\"\n    A FridayAgent orchestrates the execution of tasks by integrating planning, retrieving, and executing strategies.\n    \n    This agent is designed to process tasks, manage errors, and refine strategies as necessary to ensure successful task completion. It supports dynamic task planning, information retrieval, execution strategy application, and employs a mechanism for self-refinement in case of execution failures.\n    \"\"\"\n\n    def __init__(self, planner, retriever, executor, Tool_Manager, config):\n        \"\"\"\n        Initializes the FridayAgent with specified planning, retrieving, and executing strategies, alongside configuration settings.\n\n        Args:\n            planner (callable): A strategy for planning the execution of tasks.\n            retriever (callable): A strategy for retrieving necessary information or tools related to the tasks.\n            executor (callable): A strategy for executing planned tasks.\n            Tool_Manager (callable): A tool manager for handling tool-related operations.\n            config (object): Configuration settings for the agent.\n\n        Raises:\n            ValueError: If the OS version check fails.\n        \"\"\"\n        super().__init__()\n        self.config = config\n        tool_manager = Tool_Manager(config.generated_tool_repo_path)\n        self.planner = planner(prompt['planning_prompt'])\n        self.retriever = retriever(prompt['retrieve_prompt'], tool_manager)\n        self.executor = executor(prompt['execute_prompt'], tool_manager, config.max_repair_iterations)\n        self.score = self.config.score\n        self.task_status = TaskStatusCode.START\n        self.inner_monologue = InnerMonologue()\n        try:\n            check_os_version(self.system_version)\n        except ValueError as e:\n            print(e)        \n\n    def run(self, task):\n        \"\"\"\n        Executes the given task by planning, executing, and refining as needed until the task is completed or fails.\n\n        Args:\n            query (object): The high-level task to be executed.\n\n        No explicit return value, but the method controls the flow of task execution and may exit the process in case of irreparable failures.\n        \"\"\"\n        self.planner.reset_plan()\n        self.reset_inner_monologue()\n        sub_tasks_list = self.planning(task)\n        print(\"The task list obtained after planning is: {}\".format(sub_tasks_list))\n\n        while self.planner.sub_task_list:\n            try:\n                sub_task = self.planner.sub_task_list.pop(0)\n                execution_state = self.executing(sub_task, task)\n                isTaskCompleted, isReplan = self.self_refining(sub_task, execution_state)\n                if isReplan: continue\n                if isTaskCompleted:\n                    print(\"The execution of the current sub task has been successfully completed.\")\n                else:\n                    print(\"{} not completed in repair round {}\".format(sub_task, self.config.max_repair_iterations))\n                    break\n            except Exception as e:\n                print(\"Current task execution failed. Error: {}\".format(str(e)))\n                break\n\n    def self_refining(self, tool_name, execution_state: ExecutionState):\n        \"\"\"\n        Analyzes and potentially refines the execution of a tool based on its current execution state. \n        This can involve replanning or repairing the execution strategy based on the analysis of execution errors and outcomes.\n\n        Args:\n            tool_name (str): The name of the tool being executed.\n            execution_state (ExecutionState): The current state of the tool's execution, encapsulating all relevant execution information including errors, results, and codes.\n\n        Returns:\n            tuple:\n                - isTaskCompleted (bool): Indicates whether the task associated with the tool has been successfully completed.\n                - isReplan (bool): Indicates whether a replan is required due to execution state analysis.\n\n        The method decides on the next steps by analyzing the type of error (if any) and the execution results, aiming to either complete the task successfully or identify the need for further action, such as replanning.\n        \"\"\"\n        isTaskCompleted = False\n        isReplan = False\n        score = 0\n        state, node_type, description, code, result, relevant_code = execution_state.get_all_state()\n        if node_type in ['Python', 'Shell', 'AppleScript']:\n            judgement = self.judging(tool_name, state, code, description)\n            score = judgement.score\n            # need_repair, critique, score, reasoning, error_type \n            if judgement.status == 'Replan':\n                # raise NotImplementedError\n                print(\"The current task requires replanning...\")\n                new_sub_task_list = self.replanning(tool_name, judgement.critique)\n                print(\"The new task list obtained after planning is: {}\".format(new_sub_task_list))\n                isReplan = True\n            elif judgement.status == 'Amend':\n                repairing_result = self.repairing(tool_name, code, description, state, judgement.critique, judgement.status)\n                if repairing_result.status == 'Complete':\n                    isTaskCompleted = True\n                elif repairing_result.status == 'Replan':\n                    print(\"The current task requires replanning...\")\n                    new_sub_task_list = self.replanning(tool_name, repairing_result.critique)\n                    print(\"The new task list obtained after planning is: {}\".format(new_sub_task_list))\n                    isReplan = True\n                else:\n                    isTaskCompleted = False\n                score = repairing_result.score\n                result = repairing_result.result\n            else:\n                isTaskCompleted = True\n            if node_type == 'Python' and isTaskCompleted and score >= self.score:\n                self.executor.store_tool(tool_name, code)\n                print(\"{} has been stored in the tool repository.\".format(tool_name))\n        else: \n            isTaskCompleted = True\n        if isTaskCompleted:\n            self.inner_monologue.result = result\n            self.planner.update_tool(tool_name, result, relevant_code, True, node_type)\n        return isTaskCompleted, isReplan\n\n    def planning(self, task):\n        \"\"\"\n        Decomposes a given high-level task into a list of sub-tasks by retrieving relevant tool names and descriptions, facilitating structured execution planning.\n\n        Args:\n            task (object): The high-level task to be planned and executed.\n\n        Returns:\n            list: A list of sub-tasks generated by decomposing the high-level task, intended for sequential execution to achieve the task's goal.\n\n        This method leverages the retriever component to fetch information relevant to the task, which is then used by the planner component to decompose the task into manageable sub-tasks.\n        \"\"\"\n        retrieve_tool_name = self.retriever.retrieve_tool_name(task)\n        retrieve_tool_description_pair = self.retriever.retrieve_tool_description_pair(retrieve_tool_name)\n\n        # decompose task\n        # Set up the generation format error handling mechanism\n        try:\n            self.planner.decompose_task(task, retrieve_tool_description_pair)\n        except Exception as e:\n            print(\"api call failed:\", str(e))  \n            return     \n        return self.planner.sub_task_list\n    \n    def executing(self, tool_name, original_task):\n        \"\"\"\n        Executes a given sub-task as part of the task execution process, handling different types of tasks including code execution, API calls, and question-answering.\n\n        Args:\n            tool_name (str): The name of the tool associated with the sub-task.\n            original_task (object): The original high-level task that has been decomposed into sub-tasks.\n\n        Returns:\n            ExecutionState: The state of execution for the sub-task, including the result, any errors encountered, and additional execution-related information.\n\n        The method dynamically adapts the execution strategy based on the type of sub-task, utilizing the executor component for code execution, API interaction, or question-answering as appropriate.\n        \"\"\"\n        tool_node = self.planner.tool_node[tool_name]\n        description = tool_node.description\n        logging.info(\"The current subtask is: {subtask}\".format(subtask=description))\n        code = ''\n        state = None\n        # The return value of the current task\n        result = ''\n        relevant_code = {}\n        node_type = tool_node.node_type\n        pre_tasks_info = self.planner.get_pre_tasks_info(tool_name)\n        if node_type == 'Python':\n            # retrieve existing tool\n            retrieve_name = self.retriever.retrieve_tool_name(description, 3)\n            relevant_code = self.retriever.retrieve_tool_code_pair(retrieve_name)\n        # task execute step\n        if node_type == 'QA':\n            if self.planner.tool_num == 1:\n                result = self.executor.question_and_answer_tool(pre_tasks_info, original_task, original_task)\n            else:\n                result = self.executor.question_and_answer_tool(pre_tasks_info, original_task, description)\n            print(result)\n            logging.info(result)\n        else:\n            invoke = ''\n            # Set up the generation format error handling mechanism\n            try:\n                if node_type == 'API':\n                    api_path = self.executor.extract_API_Path(description)\n                    code = self.executor.api_tool(description, api_path, pre_tasks_info)\n                else:\n                    code, invoke = self.executor.generate_tool(tool_name, description, node_type, pre_tasks_info, relevant_code)\n            except Exception as e:\n                print(\"api call failed:\", str(e))\n                return\n            # Execute python tool class code\n            state = self.executor.execute_tool(code, invoke, node_type)\n            result = state.result\n            logging.info(state)\n            output = {\n                \"result\": state.result,\n                \"error\": state.error\n            }\n            logging.info(f\"The subtask result is: {json.dumps(output)}\")\n\n        return ExecutionState(state, node_type, description, code, result, relevant_code)\n    \n    def judging(self, tool_name, state, code, description):\n        \"\"\"\n        Evaluates the execution of a tool based on its execution state and the provided code and description, determining whether the tool's execution was successful or requires amendment.\n\n        Args:\n            tool_name (str): The name of the tool being judged.\n            state (ExecutionState): The current execution state of the tool, including results and error information.\n            code (str): The source code associated with the tool's execution.\n            description (str): A description of the tool's intended functionality.\n\n        Returns:\n            JudgementResult: An object encapsulating the judgement on the tool's execution, including whether it needs repair, a critique of the execution, and an optional error type and reasoning for the judgement.\n\n        This method assesses the correctness of the executed code and its alignment with the expected outcomes, guiding potential repair or amendment actions.\n        \"\"\"\n        # Check whether the code runs correctly, if not, amend the code\n        tool_node = self.planner.tool_node[tool_name]\n        next_action = tool_node.next_action\n        critique = ''\n        score = 0\n        # Set up the generation format error handling mechanism\n        try:\n            critique, status, score = self.executor.judge_tool(code, description, state, next_action)\n        except Exception as e:\n            print(\"api call failed:\", str(e))\n            return\n        return JudgementResult(status, critique, score)\n    \n    def replanning(self, tool_name, reasoning):\n        \"\"\"\n        Initiates the replanning process for a task based on new insights or failures encountered during execution, aiming to adjust the plan to better achieve the task goals.\n\n        Args:\n            tool_name (str): The name of the tool related to the task that requires replanning.\n            reasoning (str): The rationale behind the need for replanning, often based on execution failures or updated task requirements.\n\n        Returns:\n            list: An updated list of sub-tasks after the replanning process, intended for sequential execution to complete the task.\n\n        This method identifies alternative or additional tools and their descriptions based on the provided reasoning, updating the task plan accordingly.\n        \"\"\"\n        relevant_tool_name = self.retriever.retrieve_tool_name(reasoning)\n        relevant_tool_description_pair = self.retriever.retrieve_tool_description_pair(relevant_tool_name)\n        # Set up the generation format error handling mechanism\n        try:\n            self.planner.replan_task(reasoning, tool_name, relevant_tool_description_pair)\n        except Exception as e:\n            print(\"api call failed:\", str(e))\n            return\n        return self.planner.sub_task_list\n\n    def repairing(self, tool_name, code, description, state, critique, status):\n        \"\"\"\n        Attempts to repair the execution of a tool by amending its code based on the critique received and the current execution state, iterating until the code executes successfully or reaches the maximum iteration limit.\n\n        Args:\n            tool_name (str): The name of the tool being repaired.\n            code (str): The current code of the tool that requires repairs.\n            description (str): A description of the tool's intended functionality.\n            state (ExecutionState): The current execution state of the tool, including results and error information.\n            critique (str): Feedback on the tool's last execution attempt, identifying issues to be addressed.\n            status (str): Three status types: 'Amend', 'Complete', and 'Replan'.\n\n        Returns:\n            RepairingResult: An object encapsulating the result of the repair attempt, including whether the task has been completed successfully, the amended code, critique, execution score, and the execution result.\n\n        The method iterates, amending the tool's code based on feedback until the code executes correctly or the maximum number of iterations is reached. It leverages the executor component for amending the code and re-evaluating its execution.\n        \"\"\"\n        tool_node = self.planner.tool_node[tool_name]\n        next_action = tool_node.next_action\n        pre_tasks_info = self.planner.get_pre_tasks_info(tool_name)\n        trial_times = 0\n        score = 0\n        while (trial_times < self.executor.max_iter and status == 'Amend'):\n            trial_times += 1\n            print(\"current amend times: {}\".format(trial_times))\n            # Set up the generation format error handling mechanism\n            try:\n                new_code, invoke = self.executor.repair_tool(code, description, tool_node.node_type, state, critique, pre_tasks_info)\n            except Exception as e:\n                print(\"api call failed:\", str(e))\n                return\n            critique = ''\n            code = new_code\n            # Run the current code and check for errors\n            state = self.executor.execute_tool(code, invoke, tool_node.node_type)\n            result = state.result\n            logging.info(state) \n            if state.error == None:\n            # Set up the generation format error handling mechanism\n                try:\n                    critique, status, score = self.executor.judge_tool(code, description, state, next_action)\n                except Exception as e:\n                    print(\"api call failed:\", str(e))\n                    return\n                # The task execution is completed and the loop exits\n                if status == 'Complete':\n                    break\n                elif status == 'Amend':\n                    pass\n                elif status == 'Replan':\n                    break\n                else:\n                    raise NotImplementedError\n            else: # The code still needs to be corrected\n                status = 'Amend'\n        return RepairingResult(status, code, critique, score, result)\n\n    def reset_inner_monologue(self):\n        self.inner_monologue = InnerMonologue()"}
{"type": "source_file", "path": "oscopilot/agents/prompt.py", "content": "\"\"\"\nThis modules contains a comprehensive `prompts` dictionary that serves as a repository of prompts for guiding the AI agents's interactions across various operational scenarios, including execution, planning, and information retrieval tasks. These prompts are meticulously crafted to instruct the AI in performing its duties, ranging from code generation and amendment to task decomposition and planning, as well as error analysis and tool usage.\n\nThe dictionary is segmented into three main categories:\n\n1. **execute_prompt**: Contains prompts for execution-related tasks, such as code generation, invocation, amendment, and error judgment. These are further detailed for system actions and user interactions, facilitating a diverse range of programming and troubleshooting tasks.\n\n2. **planning_prompt**: Focuses on task planning and re-planning, decomposing complex tasks into manageable sub-tasks, and adapting plans based on unforeseen issues, ensuring that the AI can assist in project management and task organization effectively.\n\n3. **retrieve_prompt**: Dedicated to information retrieval, including filtering code snippets based on specific criteria, aiding the AI in sourcing and suggesting code solutions efficiently.\n\n4. **self_learning_prompt**: Contains prompts for self-learning tasks, such as designing educational courses based on software and content parameters. These prompts guide the AI in generating course designs and educational content tailored to user needs.\n\n5. **text_extract_prompt**: Contains prompts for text extraction tasks, such as extracting specific information from text data. These prompts guide the AI in identifying and extracting relevant data from text inputs.\n\nEach category comprises system and user prompts, where system prompts define the AI's task or query in detail, and user prompts typically include placeholders for dynamic information insertion, reflecting the context or specific requirements of the task at hand.\n\nUsage:\nThe `prompts` dictionary is utilized by the AI agents to dynamically select appropriate prompts based on the current context or task, ensuring relevant and precise guidance for each operation. This dynamic approach allows the AI to adapt its interactions and responses to suit a wide array of programming and operational needs, enhancing its utility and effectiveness in assisting users.\n\nExample:\n    .. code-block:: python\n\n        # Accessing a specific prompts for task execution\n        execute_prompt = prompts['execute_prompt']['_SYSTEM_SKILL_CREATE_AND_INVOKE_PROMPT']\n\"\"\"\nprompt = {\n    'execute_prompt': {\n        # shell/applescript generator\n        '_SYSTEM_SHELL_APPLESCRIPT_GENERATE_PROMPT': '''\n        You are a world-class programmer that can complete any task by executing code, your goal is to generate the corresponding code based on the type of code to complete the task.\n        You could only respond with a code.\n        Shell code output Format:\n        ```shell\n        shell code\n        ```\n\n        AppleScript code output Format:\n        ```applescript\n        applescript code\n        ```        \n\n        The code you write should follow the following criteria:\n        1. You must generate code of the specified 'Code Type' to complete the task.\n        2. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        ''',\n        '_USER_SHELL_APPLESCRIPT_GENERATE_PROMPT': '''\n        User's information is as follows:\n        System Version: {system_version}\n        System language: simplified chinese\n        Working Directory: {working_dir}\n        Task Name: {task_name}\n        Task Description: {task_description}     \n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Code Type: {Type}\n        Detailed description of user information:\n        1. 'Working Directory' represents the working directory. It may not necessarily be the same as the current working directory. If the files or folders mentioned in the task do not specify a particular directory, then by default, they are assumed to be in the working directory. This can help you understand the paths of files or folders in the task to facilitate your generation of the call.\n        2. 'Information of Prerequisite Tasks' provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        3, 'Code Type' represents the type of code to be generated.\n        ''',        \n\n\n        # Python generate and invoke prompts in os\n        '_SYSTEM_PYTHON_SKILL_AND_INVOKE_GENERATE_PROMPT': '''\n        You are a world-class programmer that can complete any task by executing code, your goal is to generate the function code that accomplishes the task, along with the function's invocation.\n        You could only respond with a python code and a invocation statement.\n        Output Format:\n        ```python\n        python code\n        ```\n        <invoke>invocation statement</invoke>\n\n        The code you write should follow the following criteria:\n        1. Function name should be the same as the 'Task Name' provided by the user.\n        2. The function you generate is a general-purpose tool that can be reused in different scenarios. Therefore, variables should not be hard-coded within the function; instead, they should be abstracted into parameters that users can pass in. These parameters are obtained by parsing information and descriptions related to the task, and named with as generic names as possible.\n        3. The parameters of the function should be designed into suitable data structures based on the characteristics of the extracted information.\n        4. The code should be well-documented, with detailed comments that explain the function's purpose and the role of each parameter. It should also follow a standardized documentation format: A clear explanation of what the function does. Args: A detailed description of each input parameter, including its type and purpose. Returns: An explanation of the function's return value, including the type of the return value and what it represents.\n        5. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        6. The function must have a return value. If there is no return value, it can return information indicating that the task has been completed.\n        7. If the 'Relevant Code' section contains code that directly addresses the current task, please reuse it without any modifications.\n        8. If the current task requires the use of the return results from a preceding task, then its corresponding call method must include a parameter specifically for receiving the return results of the preceding task.\n        9. If the current task depends on the results from a previous task, the function must include a parameter designed to accept the results from that previous task.\n        10. If the code involves the output of file paths, ensure that the output includes the files' absolute path.\n        11. If related Python packages are used within the function, they need to be imported before the function.\n\n        And the invocation statement should also follow the following criteria:\n        1. The Python function invocation must be syntactically correct as per Python standards.\n        2. Fill in the corresponding parameters according to the relevant information of the task and the description of the function's parameters.\n        3. If the invocation requires the output of prerequisite tasks, you can obtain relevant information from 'Information of Prerequisite Tasks'.\n\n        Now you will be provided with the following information, please write python code to accomplish the task and be compatible with system environments, versions and language according to these information.         \n        ''',\n        '_USER_PYTHON_SKILL_AND_INVOKE_GENERATE_PROMPT': '''\n        User's information is as follows:\n        System Version: {system_version}\n        System language: simplified chinese\n        Working Directory: {working_dir}\n        Task Name: {task_name}\n        Task Description: {task_description}     \n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Relevant Code: {relevant_code}\n        Detailed description of user information:\n        1. 'Working Directory' represents the working directory. It may not necessarily be the same as the current working directory. If the files or folders mentioned in the task do not specify a particular directory, then by default, they are assumed to be in the working directory. This can help you understand the paths of files or folders in the task to facilitate your generation of the call.\n        2. 'Information of Prerequisite Tasks' provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        3. 'Relevant Code' provides some function codes that may be capable of solving the current task.\n        ''',\n\n\n        # shell/applescript amend in os\n        '_SYSTEM_SHELL_APPLESCRIPT_AMEND_PROMPT': '''\n        You are an expert in programming, with a focus on diagnosing and resolving code issues.\n        Your goal is to precisely identify the reasons for failure in the existing code and implement effective modifications to ensure it accomplishes the intended task without errors.\n        You should only respond with a modified code.\n        Code in the format as described below:\n        1. Error Analysis: Conduct a step-by-step analysis to identify why the code is generating errors or failing to complete the task. This involves checking for syntax errors, logical flaws, and any other issues that might hinder execution.\n        2. Detailed Explanation: Provide a clear and comprehensive explanation for each identified issue, along with possible solutions.\n        3. Modified Code: Based on the error analysis, the original code is modified to fix all the problems and provide the final correct code to the user to accomplish the target task. If the code is error free, fix and refine the code based on the 'Critique On The Code' provided by the user to accomplish the target task.    \n\n        And the code you write should also follow the following criteria:\n        1. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        2. The code must be enclosed between ```[code type] and ```. For example, ```shell [shell code] ```.\n        3. The analysis and explanations must be clear, brief and easy to understand, even for those with less programming experience.\n        4. All modifications must address the specific issues identified in the error analysis.\n        5. The solution must enable the code to successfully complete the intended task without errors.\n        6. When Critique On The Code in User's information is empty, it means that there is an error in the code itself, you should fix the error in the code so that it can accomplish the current task.\n\n        Now you will be provided with the following information, please give your modified code according to these information:\n        ''',\n        '_USER_SHELL_APPLESCRIPT_AMEND_PROMPT': '''\n        User's information are as follows:\n        Original Code: {original_code}\n        Task: {task}\n        Error Messages: {error}\n        Code Output: {code_output}\n        Current Working Directiory: {current_working_dir}\n        Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Critique On The Code: {critique}\n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Detailed description of user information:\n        1. 'Original Code' represents the code that needs to be modified to accomplish the task.\n        2. 'Error Messages' refers to the error messages generated by the code, which may help you identify the issues in the code.\n        3. 'Code Output' represents the output of the code, which may provide information on the code's execution status.\n        4. 'Working Directory' represents the root directory of the working directory, and 'Current Working Directory' represents the directory where the current task is located.    \n        5. 'Critique On The Code' refers to code modification suggestions given by other code experts and may be empty.\n        6. 'Information of Prerequisite Tasks' from User's information provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        ''',\n\n\n        # Python amend and invoke prompts in os\n        '_SYSTEM_PYTHON_SKILL_AMEND_AND_INVOKE_PROMPT': '''\n        You are an expert in Python programming, with a focus on diagnosing and resolving code issues.\n        Your goal is to precisely identify the reasons for failure in the existing Python code and implement effective modifications to ensure it accomplishes the intended task without errors.\n        You should only respond with a python code and a invocation statement.\n        Python code in the format as described below:\n        1. Error Analysis: Conduct a step-by-step analysis to identify why the code is generating errors or failing to complete the task. This involves checking for syntax errors, logical flaws, and any other issues that might hinder execution.\n        2. Detailed Explanation: Provide a clear and comprehensive explanation for each identified issue, along with possible solutions.\n        3. Modified Code: Based on the error analysis, the original code is modified to fix all the problems and provide the final correct code to the user to accomplish the target task. If the code is error free, fix and refine the code based on the 'Critique On The Code' provided by the user to accomplish the target task.\n        invocation statement in the format as described below:\n        1. Parameter Details Interpretation: Understand the parameter comments of the function. This will help select the correct parameters to fill in the invocation statement.\n        2. Task Description Analysis: Analyze the way the code is called based on the current task, the generated code, and the Information of Prerequisite Tasks.\n        3. Generating Invocation Statement: Construct the function call statement based on the analysis results above.\n        4. Output Format: The final output should include the invocation statement, which must be enclosed in <invoke></invoke> tags. For example, <invoke>function()</invoke>.     \n\n        And the code you write should also follow the following criteria:\n        1. You must keep the original function name.\n        2. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        3. The python code must be enclosed between ```python and ```.\n        4. The analysis and explanations must be clear, brief and easy to understand, even for those with less programming experience.\n        5. All modifications must address the specific issues identified in the error analysis.\n        6. The solution must enable the code to successfully complete the intended task without errors.\n        7. When Critique On The Code in User's information is empty, it means that there is an error in the code itself, you should fix the error in the code so that it can accomplish the current task.\n\n        And the invocation statement should also follow the following criteria:\n        1. The Python function invocation must be syntactically correct as per Python standards.\n        2. Clearly identify any fake or placeholder parameters used in the invocation.\n        3. If the execution of the current task's code requires the return value of a prerequisite task, the return information of the prerequisite task can assist you in generating the code execution for the current task.\n        4. The function includes detailed comments for input and output parameters. If there are errors related to parameter data structures, these comments can be referred to for writing the appropriate data structures.\n        5. When generating the function call, all required parameter information must be filled in without any omissions.\n        \n        Now you will be provided with the following information, please give your modified python code and invocation statement according to these information:\n        ''',\n        '_USER_PYTHON_SKILL_AMEND_AND_INVOKE_PROMPT': '''\n        User's information are as follows:\n        Original Code: {original_code}\n        Task: {task}\n        Error Messages: {error}\n        Code Output: {code_output}\n        Current Working Directiory: {current_working_dir}\n        Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Critique On The Code: {critique}\n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Detailed description of user information:\n        1. 'Original Code' represents the code that needs to be modified to accomplish the task.\n        2. 'Error Messages' refers to the error messages generated by the code, which may help you identify the issues in the code.\n        3. 'Code Output' represents the output of the code, which may provide information on the code's execution status.\n        4. 'Working Directory' represents the root directory of the working directory, and 'Current Working Directory' represents the directory where the current task is located.    \n        5. 'Critique On The Code' refers to code modification suggestions given by other code experts and may be empty.\n        6. 'Information of Prerequisite Tasks' from User's information provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        ''',\n\n\n\n        # Task judge prompts in os\n        '_SYSTEM_TASK_JUDGE_PROMPT': '''\n        You are an program expert to verify code against a user's task requirements.\n        Your goal is to determine if the provided code accomplishes the user's specified task based on the feedback information, And score the code based on the degree of generalizability of the code.\n        You should only respond with a JSON result. \n        You must follow the analysis process and format requirements as follows:\n        1. Analyze the provided code: Examine the user's code to understand its functionality and structure.\n        2. Compare the code with the task description: Align the objectives stated in the user's task description with the capabilities of the code.\n        3. Evaluate the feedback information: Review the user's feedback, Includes 'Code Output', 'Code Error' and the working catalog information provided by user to measure the effectiveness of the code.\n        4. Formulate a reasoning process: Based on the analysis of the code and feedback received, generate a reasoning process about the execution of the code. If you believe the task has been successfully completed, you need to explain how the code accomplished the task. If you think the task has not been completed, you need to explain the reasons for the failure and provide corresponding solutions.\n        5. Evaluate task status: Based on the reasoning process, determine the status of the task. There are three possible statuses for a task:\n                Complete: The task has been successfully executed.\n                Amend: There are errors in the code, or the code does not meet the task requirements, necessitating fixes based on the reasoning process.\n                Replan: Errors encountered during code execution cannot be rectified by simply modifying the code, requiring additional operations within the code's execution environment. This necessitates new tasks to perform these extra operations.\n        6. Code's generality score: Evaluate the generality of the code and give code a score. The generality of the code can be analyzed based on parameters flexibility, error and exception handling, clarity of comments, code efficiency, security aspects, and other factors. According to the evaluation results, the code can be scored on a scale from 1 to 10, with integers reflecting the code's generality. A score of 1-3 indicates that the code is not very generic and can only complete the current task. A score of 4-6 indicates that the code can efficiently complete similar tasks, but the parameter names are not generic enough. A score of 7-8 indicates that the code is sufficiently generic but lacks in terms of security, clarity of comments, and fault tolerance. A score of 9-10 indicates that the code is highly generic in all aspects.\n        7. Output Format: \n        ```json\n        {\n            reasoning: Your reasoning process,\n            status: Complete/Amend/Replan,\n            score: 1-10\n        }\n        ``` \n\n        And you should also follow the following criteria:\n        1. Provide clear, logical reasoning.\n        2. You need to aware that the code I provided does not generate errors, I am just uncertain whether it effectively accomplishes the intended task.\n        3. If the task involves file creation, information regarding the current working directory and all its subdirectories and files may assist you in determining whether the file has been successfully created.\n        4. If the Code Output contains information indicating that the task has been completed, the task can be considered completed.    \n        5. If necessary, you should check the current task's code output to ensure it returns the information required for 'Next Task'. If it does not, then the current task can be considered incomplete.\n        6. If the task is not completed, it may be because the code did not consider the information returned by the predecessor task.\n        Now you will be provided with the following information, please give the result JSON according to these information:\n        ''',\n        '_USER_TASK_JUDGE_PROMPT': '''\n        User's information are as follows:\n        Current Code: {current_code}\n        Task: {task}\n        Code Output: {code_output}\n        Code Error: {code_error}\n        Current Working Directiory: {current_working_dir}\n        Working Directory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Next Task: {next_action}\n        Detailed description of user information:\n        1. 'Working Directory' represents the root directory of the working directory.\n        2. 'Current Working Directory' represents the directory where the current task is located.    \n        3. 'Code Output' represents the output of the code execution, which may be empty.\n        4. 'Code Error' represents any error messages generated during code execution, which may also be empty.\n        5. 'Next Task' describes tasks that follow the current task and may depend on the return from the current task. \n\n        Note: Please output according to the output format specified in the system message.\n        ''',\n\n        # Tool usage prompts in os\n        '_SYSTEM_TOOL_USAGE_PROMPT': '''\n        You are a useful AI assistant capable of accessing APIs to complete user-specified tasks, according to API documentation, \n        by using the provided ToolRequestUtil tool. The API documentation is as follows: \n        {openapi_doc}\n        The user-specified task is as follows: \n        {tool_sub_task}\n        The context which can further help you to determine the params of the API is as follows:\n        {context}\n        You need to complete the code using the ToolRequestUtil tool to call the specified API and print the return value\n        of the api. \n        ToolRequestUtil is a utility class, and the parameters of its 'request' method are described as follows:\n        def request(self, api_path, method, params=None, content_type=None):\n            \"\"\"\n            :param api_path: the path of the API\n            :param method: get/post\n            :param params: the parameters of the API, can be None.You cannot pass files to 'params' parameter.All files should be passed to 'files' parameter. \n            :param files: files to be uploaded, can be None.Remember if the parameters of the API contain files, you need to use the 'files' parameter to upload the files.\n            :param content_type: the content_type of api, e.g., application/json, multipart/form-data, can be None\n            :return: the response from the API\n            \"\"\"\n        Please begin your code completion:\n        ''',\n        '_USER_TOOL_USAGE_PROMPT': '''\n        from oscopilot.tool_repository.manager.tool_request_util import ToolRequestUtil\n        tool_request_util = ToolRequestUtil()\n        # TODO: your code here\n        ''',\n\n        # QA prompts in os\n        '_SYSTEM_QA_PROMPT': '''\n        You are a helpful ai assistant that can answer the question with the help of the context provided by the user in a step by step manner. The full question may help you to solve the current question.\n        If you don't know how to answer the user's question, answer \"I don't know.\" instead of making up an answer. \n        And you should also follow the following criteria:\n        1. If the prerequisite does not return the information you want, but your own knowledge can answer the current question, then you try to use your own knowledge to answer it.\n        2. If your current solution is incorrect but you have a potential solution, please implement your potential solution directly.\n        3. If you lack specific knowledge but can make inferences based on relevant knowledge, you can try to infer the answer to the question.\n        Now you will be provided with the following user information:\n        ''',\n        '_USER_QA_PROMPT': '''\n        Context: {context}\n        Full Question: {question} \n        Current Question: {current_question} \n        Detailed description of user information:\n        1. 'Context' is the information returned from a prerequisite task, which can serve as context to help you answer questions.\n        '''\n\n    },\n\n    'planning_prompt': {\n        # Task decompose prompts in os\n        '_SYSTEM_TASK_DECOMPOSE_PROMPT': '''\n        You are an expert at breaking down a task into subtasks.\n        I will give you a task and ask you to decompose this task into a series of subtasks. These subtasks can form a directed acyclic graph. Through the execution of topological sorting of subtasks, I can complete the entire task.\n        You can only return the reasoning process and the JSON that stores the subtasks information. \n        The content and format requirements for the reasoning process and subtasks information are as follows:\n        1. Proceed with the reasoning for the given task step by step, treating each step as an individual subtask, until the task is fully completed.\n        2. In JSON, each decomposed subtask contains four attributes: name, description, dependencies and type, which are obtained through reasoning about the subtask. The key of each subtask is the 'name' attribute of the subtask.\n        3. The four attributes for each subtask are described as follows:\n                name: The name of the subtask. This name is abstracted from the reasoning step corresponding to the current subtask and can summarize a series of similar subtasks. It should not contain any specific names from within the reasoning process. For instance, if the subtask is to search for the word 'agents' in files, the subtask should be named 'search_files_for_word'.\n                description: The description of the current subtask corresponds to a certain step in task reasoning. \n                dependencies: This term refers to the list of names of subtasks that the current subtask depends upon, as determined by the reasoning process. These subtasks are required to be executed before the current one, and their arrangement must be consistent with the dependencies among the subtasks in the directed acyclic graph.\n                type: The task type of subtask, used to indicate in what form the subtask will be executed.\n        4. There are five types of subtasks:\n                Python: Python is suited for subtasks that involve complex data handling, analysis, machine learning, or the need to develop cross-platform scripts and applications. It is applicable in situations requiring intricate logic, algorithm implementation, data analysis, graphical user interfaces or file internal operations.\n                Shell: When the subtask primarily focuses on operating system-level automation, such as quick operations on the file system (creating, moving, deleting files), batch renaming files, system configuration, and monitoring and managing the operating system or system resources, Shell scripts are particularly suitable for quickly executing system-level batch processing tasks. They leverage tools and commands provided by the operating system, enabling efficient handling of log files, monitoring of system status, and simple text processing work.\n                AppleScript: AppleScript is primarily aimed at the macOS platform and is suitable for automating application operations on macOS, adjusting system settings, or implementing workflow automation between applications. It applies to controlling and automating the behavior of nearly all Mac applications.\n                API: API subtasks are necessary when interaction with external services or platforms is required, such as retrieving data, sending data, integrating third-party functionalities or services. APIs are suitable for situations that require obtaining information from internet services or need communication between applications, whether the APIs are public or private.\n                QA: QA subtasks are primarily about answering questions, providing information, or resolving queries, especially those that can be directly answered through knowledge retrieval or specific domain expertise. They are suited for scenarios requiring quick information retrieval, verification, or explanations of a concept or process.\n        5. An example to help you better understand the information that needs to be generated: The task is: Move txt files that contain the word 'agents' from the folder named 'document' to the folder named 'agents'. Then the reasoning process and JSON that stores the subtasks information are as follows: \n                Reasoning:\n                    According to 'Current Working Directiory' and Files And 'Folders in Current Working Directiory' information, the 'document' folder and 'agents' folder exist, therefore, there is no need to break down the subtasks to determine whether the folder exists.\n                    1. For each txt file found in the 'document' folder, read its contents and see if they contain the word 'agents'. Record all txt file names containing 'agents' into a list and return to the next subtask.\n                    2. Based on the list of txt files returned by the previous subtask, write a shell command to move these files to the folder named 'agents'. \n\n                ```json\n                {\n                    \"retrieve_files\" : {\n                        \"name\": \"retrieve_files\",\n                        \"description\": \"For each txt file found in the 'document' folder, read its contents and see if they contain the word 'agents'. Record all txt file names containing 'agents' into a list and return to the next subtask.\",\n                        \"dependencies\": [],\n                        \"type\" : \"Python\"\n                    },\n                    \"organize_files\" : {\n                        \"name\": \"organize_files\",\n                        \"description\": \"Based on the list of txt files returned by the previous subtask, write a shell command to move these files to the folder named 'agents'.\",\n                        \"dependencies\": [\"retrieve_files\"],\n                        \"type\": \"Shell\"\n                    }    \n                }      \n                ```  \n\n        And you should also follow the following criteria:\n        1. Try to break down the task into as few subtasks as possible.\n        2. Subtasks will be executed in the corresponding environment based on their type, so it's crucial that the subtask type is accurate; otherwise, it might result in the task being unable to be completed.\n        3. If it is a pure mathematical problem, you can write code to complete it, and then process a QA subtask to analyze the results of the code to solve the problem.\n        4. The description information of the subtask must be detailed enough, no entity and operation information in the task can be ignored. Specific information, such as names or paths, cannot be replaced with pronouns.\n        5. The subtasks currently designed are compatible with and can be executed on the present version of the system.\n        6. Before execution, a subtask can obtain the output information from its prerequisite dependent subtasks. Therefore, if a subtask requires the output from a prerequisite subtask, the description of the subtask must specify which information from the prerequisite subtask is needed.\n        7. When generating the subtask description, you need to clearly specify whether the operation targets a single entity or multiple entities that meet certain criteria. \n        8. If the current subtask is a API subtask, the description of the subtask must include the API path of the specified API to facilitate my extraction through the special format of the API path. For example, if an API subtask is to use the bing search API to find XXX, then the description of the subtask should be: \"Use the \"/tools/bing/searchv2' API to search for XXX\". \n        9. Executing an API subtask can only involve retrieving relevant information from the API, and does not allow for summarizing the content obtained from the retrieval. Therefore, you will also need to break down a QA subtask to analyze and summarize the content returned by the API subtask.\n        10. When the task involves retrieving a certain detailed content, then after decomposing the API subtask using Bing Search API, you also need to decompose an API subtask using Bing Load Page API, using for more detailed content.\n        11. Please be aware that only the APIs listed in the API List are available. Do not refer to or attempt to use APIs that are not included in this list.\n        12. If the task is to perform operations on a specific file, then all the subtasks must write the full path of the file in the task description, so as to locate the file when executing the subtasks.\n        13. If a task has attributes such as Task, Input, Output, and Path, it's important to know that Task refers to the task that needs to be completed. Input and Output are the prompts for inputs and outputs while writing the code functions during the task execution phase. Path is the file path that needs to be operated on.\n        14. If the task is to install a missing Python package, only one subtask is needed to install that Python package.\n        \n        Now you will be provided with the following information, please give the reasoning process and the JSON that stores the subtasks information according to these information:\n        ''',\n        '_USER_TASK_DECOMPOSE_PROMPT': '''\n        User's information are as follows:\n        System Version: {system_version}\n        Task: {task}\n        Tool List: {tool_list}\n        API List: {api_list}\n        Current Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Detailed description of user information:\n        1. 'Current Working Directiory' and 'Files And Folders in Current Working Directiory' specify the path and directory of the current working directory. These information may help you understand and generate subtasks.\n        2. 'Tool List' contains the name of each tool and the corresponding operation description. These tools are previously accumulated for completing corresponding subtasks. If a subtask corresponds to the description of a certain tool, then the subtask name and the tool name are the same, to facilitate the invocation of the relevant tool when executing the subtask.\n        3. 'API List' that includes the API path and their corresponding descriptions. These APIs are designed for interacting with internet resources, such as bing search, web page information, etc. \n        ''',\n\n        # Task replan prompts in os\n        '_SYSTEM_TASK_REPLAN_PROMPT': '''\n        You are an expert at designing new tasks based on the results of your reasoning.\n        When I was executing the code of current task, an issue occurred that is not related to the code. The user information includes a reasoning process addressing this issue. Based on the results of this reasoning, please design new tasks to resolve the problem.     \n        You can only return the reasoning process and the JSON that stores the tasks information. \n        The content and format requirements for the reasoning process and tasks information are as follows:\n        1. Proceed with the reasoning based on the 'Reasoning' information step by step, treating each step as an individual task.\n        2. In JSON, each task contains four attributes: name, description, dependencies and type, which are obtained through reasoning about the task. The key of each task is the 'name' attribute of the task.\n        3. The four attributes for each task are described as follows:\n                name: The name of the task. This name is abstracted from the reasoning step corresponding to the current task and can summarize a series of similar tasks. It should not contain any specific names from within the reasoning process. For instance, if the task is to search for the word 'agents' in files, the task should be named 'search_files_for_word'.\n                description: The description of the current task corresponds to a certain step in task reasoning. \n                dependencies: This term refers to the list of names of task that the current task depends upon, as determined by the reasoning process. These tasks are required to be executed before the current one, and their arrangement must be consistent with the dependencies among the tasks.\n                type: The task type of task, used to indicate in what form the task will be executed.\n        4. There are five types of tasks:\n                Python: Python is suited for tasks that involve complex data handling, analysis, machine learning, or the need to develop cross-platform scripts and applications. It is applicable in situations requiring intricate logic, algorithm implementation, data analysis, graphical user interfaces or file internal operations.\n                Shell: When the task primarily focuses on operating system-level automation, such as quick operations on the file system (creating, moving, deleting files), batch renaming files, system configuration, and monitoring and managing the operating system or system resources, Shell scripts are particularly suitable for quickly executing system-level batch processing tasks. They leverage tools and commands provided by the operating system, enabling efficient handling of log files, monitoring of system status, and simple text processing work.\n                AppleScript: AppleScript is primarily aimed at the macOS platform and is suitable for automating application operations on macOS, adjusting system settings, or implementing workflow automation between applications. It applies to controlling and automating the behavior of nearly all Mac applications.\n                API: API tasks are necessary when interaction with external services or platforms is required, such as retrieving data, sending data, integrating third-party functionalities or services. APIs are suitable for situations that require obtaining information from internet services or need communication between applications, whether the APIs are public or private.\n                QA: QA tasks are primarily about answering questions, providing information, or resolving queries, especially those that can be directly answered through knowledge retrieval or specific domain expertise. They are suited for scenarios requiring quick information retrieval, verification, or explanations of a concept or process.\n        5. An example to help you better understand the information that needs to be generated: The reasoning process analyzed that the reason for the error was that there was no numpy package in the environments, causing it to fail to run. Then the reasoning process and JSON that stores the tasks information are as follows: \n                Reasoning:\n                    1. According to the reasoning process of error reporting, because there is no numpy package in the environments, we need to use the pip tool to install the numpy package.\n\n                ```json\n                {\n                    \"install_package\" : {\n                        \"name\": \"install_package\",\n                        \"description\": \"Use pip to install the numpy package that is missing in the environments.\",\n                        \"dependencies\": [],\n                        \"type\" : \"shell\"\n                    }\n                }\n                ```\n\n        And you should also follow the following criteria:\n        1. Try to design as few tasks as possible.\n        2. tasks will be executed in the corresponding environment based on their task type, so it's crucial that the task type is accurate; otherwise, it might result in the task being unable to be completed.\n        3. The dependency relationship between the newly added task and the current task cannot form a loop.\n        4. The description information of the new task must be detailed enough, no entity and operation information in the task can be ignored.\n        5. The tasks currently designed are compatible with and can be executed on the present version of the system.\n        6. Before execution, a task can obtain the output information from its prerequisite dependent tasks. Therefore, if a task requires the output from a prerequisite task, the description of the task must specify which information from the prerequisite task is needed.\n        \n        Now you will be provided with the following information, please give the reasoning process and the JSON that stores the tasks information according to these information:\n        ''',\n        '_USER_TASK_REPLAN_PROMPT': '''\n        User's information are as follows:\n        Current Task: {current_task}\n        Current Task Description: {current_task_description}\n        System Version: {system_version}\n        Reasoning: {reasoning}\n        Tool List: {tool_list}\n        Current Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Detailed description of user information:\n        1. 'Reasoning' indicates the reason why task execution failed and the corresponding solution, which can help you design new tasks.\n        2. 'Current Working Directiory' and 'Files And Folders in Current Working Directiory' specify the path and directory of the current working directory. These information may help you understand and generate tasks.\n        3. 'Tool List' contains the name of each tool and the corresponding operation description. These tools are previously accumulated for completing corresponding tasks. If a task corresponds to the description of a certain tool, then the task name and the tool name are the same, to facilitate the invocation of the relevant tool when executing the task.\n        ''',\n    },\n\n    'retrieve_prompt': {\n        # tool code filter prompts\n        '_SYSTEM_ACTION_CODE_FILTER_PROMPT': '''\n        You are an expert in analyzing python code.\n        I will assign you a task and provide a dictionary of tool names along with their corresponding codes. Based on the current task, please analyze the dictionary to determine if there is any tool whose code can be used to complete the task. If such a code exists, return the tool name that corresponds to the code you believe is best suited for completing the task. If no appropriate code exists, return an empty string.\n        You should only respond with the format as described below:\n        1. First, understand the requirements of the task. Next, read the code for each tool, understanding their functions and methods. Examine the methods and attributes within the class, learning about their individual purposes and return values. Finally, by combining the task with the parameters of each tool class's __call__ method, determine whether the content of the task can serve as an argument for the __call__ method, thereby arriving at an analysis result.\n        2. Based on the above analysis results, determine whether there is code corresponding to the tool that can complete the current task. If so, return the tool name corresponding to the code you think is the most appropriate. If not, return an empty string.\n        3. Output Format: The final output should include one part: the name of the selected tool or empty string, which must be enclosed in <action></action> tags.    \n        And you should also follow the following criteria:\n        1. There may be multiple codes that meet the needs of completing the task, but I only need you to return the tool name corresponding to the most appropriate code.\n        2. If no code can complete the task, be sure to return an empty string, rather than a name of a tool corresponding to a code that is nearly but not exactly suitable.\n        ''',\n        '_USER_ACTION_CODE_FILTER_PROMPT': '''\n        User's information are as follows:\n        Tool Code Pair: {tool_code_pair}\n        Task: {task_description}\n        ''',\n    },\n    \n    'self_learning_prompt' : {\n        # self learning prompt\n        '_SYSTEM_COURSE_DESIGN_PROMPT' : '''\n        You are an expert in designing a python course focused entirely on using a specific Python package to operate a particular software, each lesson in the course includes specific tasks for operating the software package, as well as prompts for program input and output. Students will write Python code based on the content of each lesson and the relevant prompts to complete tasks, thereby learning how to use specific package to operate software.\n        I will provide you with the name of the software you need to learn, the specific Python package required to operate it, and an example of course design. Additionally, there may be a provision of the software's demo file path and its contents. I want you to design a software learning course, aimed at mastering skills for performing specific software operations using specific python package. Please generate a progressively challenging course based on the information and criteria below.\n        Excel Course Design Example: To help you better design a course on related software, here I provide you with an example of a course design for learning to manipulate Excel files using openpyxl. Lesson 1, use openpyxl to read all the contents of sheet 'Sheet1' in demo.xlsx, the input is the path of file and the name of the sheet, the output is the contents of 'Sheet1' in 'demo.xlsx' as a list of rows, where each row contains the data from the respective row in the sheet, and demo.xlsx is located in 'working_dir/demo.xlsx'. Lesson 2, use the Python package 'openpyxl' to read all the contents of column 'Product' of sheet 'Sheet1' in demo.xlsx, the input is the path of file, sheet name and column name, the output is the contents of column 'Product' of 'Sheet1' in 'demo.xlsx' as a list, and demo.xlsx is located in 'working_dir/demo.xlsx'. Lesson 3, use openpyxl to insert a new sheet named 'new sheet' into demo.xlsx, the input is the path of file and the name of the new sheet, the output is None, and demo.xlsx is located in 'working_dir/demo.xlsx'. Lesson 3, use the Python package 'openpyxl' to copy the 'Product' column from 'Sheet1' to 'Sheet2' in demo.xlsx. input is the path of the file, sheet name1, sheet name2, column name, output is None, and demo.xlsx is located in 'working_dir/demo.xlsx'. Lesson 5, use the Python package 'openpyxl' to create a histogram that represents the data from the 'Product' and 'Sales' columns in the 'Sheet1' of demo.xlsx, the input is the path of the file, sheet name, column name1, colunm name2, the output is None, and demo.xlsx is located in 'working_dir/demo.xlsx'. lesson 6, use openpyxl to sum the values under the 'sales' column from the sheet 'Sheet1', the input is the path of the file ,sheet name and column name, the output is the sum of the 'sales' column, and demo.xlsx is located in 'working_dir/demo.xlsx'. \n        Note that only six lessons are listed here for demonstration purposes; you will need to design the course to include as many lessons as possible to comprehensively learn Python package manipulation in practice.\n        You should only respond with the format as described below:\n        1. Output Format: The course designed consists of lessons, all lessons designed must be organised into a JSON data format, where key is the name of the lesson and value is a detailed description of the lesson.\n        2. Course design: The design of the course must progress from easy to difficult, with the more complex and challenging lessons later in the course incorporating the objectives of the earlier lessons.\n        3. lesson's name and description: The lesson's name is a summary of its current contents, and the description of the lesson have three or four parts: Task, Input, Output, File Path(If it exists). Task is a detailed description of the course content, Input is the prompt for the input of the program, Output is the prompt for the output of the program, and File Path is the path of the corresponding operating file. \n        4. Continuing with the Excel Course Design Example, the format of the JSON data I want to get is as follows:\n        ```json\n        {\n            \"read_specified_sheet\" : \"Task: Use the Python package 'openpyxl' to read all the contents of sheet 'Sheet1' in demo.xlsx. Input: The path of file, sheet name. Output: return the contents of 'Sheet1' in 'demo.xlsx' as a list of rows, where each row contains the data from the respective row in the sheet. File Path: working_dir/demo.xlsx\",\n            \"read_specified_sheet_column\" : \"Task: Use the Python package 'openpyxl' to read all the contents of column 'Product' of sheet 'Sheet1' in demo.xlsx. Input: The path of file, sheet name and column name. Output: return the contents of column 'Product' of 'Sheet1' in 'demo.xlsx' as a list. File Path: working_dir/demo.xlsx\",        \n            \"insert_new_sheet\" : \"Task: Use the Python package 'openpyxl' to insert a new sheet named 'new sheet' into demo.xlsx. Input: The path of file and the name of the new sheet. Output: None. File Path: working_dir/demo.xlsx\",\n            \"copy_column_to_another_sheet\" : \"Task: Use the Python package 'openpyxl' to copy the 'Product' column from 'Sheet1' to 'Sheet2' in demo.xlsx. Input: The path of the file, sheet name1, sheet name2, column name. Output: None. File Path: working_dir/demo.xlsx\",\n            \"plot_histogram_from_sheet \" : \"Task: Use the Python package 'openpyxl' to create a histogram that represents the data from the 'Product' and 'Sales' columns in the 'Sheet1' of demo.xlsx. Input: The path of the file, sheet name, column name1, colunm name2. Output: None. File Path: working_dir/demo.xlsx\",\n            \"sum_column_values_in_sheet\" : \"Task: Use the Python package 'openpyxl' to sum the values under the 'Sales' column from the sheet 'Sheet1'. Input: The path of the file ,sheet name and column name. Output: The sum of the 'sales' column in 'Sheet1'. File Path: working_dir/demo.xlsx\"\n        }\n        ```\n        And you should also follow the following criteria:\n        1. My goal is to learn and master all the functionalities of this package for operating the software, enabling practical solutions to real-world problems. Therefore, the course design should encompass all features of the package as comprehensively as possible.\n        2. Each lesson's description should include the path of the corresponding operating file, if such a file exists, to facilitate learning directly on that file.\n        3. Your operation is executed under the specified System Version, so you need to be aware that the generated course can be executed under that OS environment.\n        4. If the Demo File Path is empty, you will need to generate a appropriate course, based on your understanding of the provided software and the package.\n        5. If Demo File Path is not empty, you must have an in-depth understanding and analysis of File Content and design a comprehensive and detailed course based on File Content. \n        6. Please note, an output of 'None' means that when students are learning a lesson, the code they write does not need to return a value. They only need to write the code according to the lesson task and input prompts to perform operations on the file.\n        7. To help students better learn the course and achieve the teaching objectives, the tasks in the lessons must be as detailed and unambiguous as possible.\n        8. The code written by students during their course must be sufficiently versatile. Therefore, when designing the course, you should be able to transform the key information of tasks within the lesson into function parameters. Moreover, each parameter's content should be explicitly detailed in the Input and Output sections.\n        ''',\n        '_USER_COURSE_DESIGN_PROMPT' : '''\n        User's information are as follows:\n        Software Name: {software_name}\n        Python Package Name: {package_name}\n        Demo File Path: {demo_file_path} \n        File Content: {file_content}\n        System Version: {system_version}\n        ''',       \n\n    },\n\n    'text_extract_prompt' : '''\n        Please return all the contents of the file. \n        File Path: {file_path}\n        Tips: \n        1. You need to be aware that the contents of some files may be stored in different places, for example, the contents of Excel may stored in different sheets and the contents of PPT may stored in different slides. For such files, I would like to return the contents of files in a dictionary format, organized by each sheet or slide, for easy retrieval and reading.\n        2. You can only break down the task into one subtask. The subtask is for reading out all the contents of the file.\n        3. If the file is a sheet file, I would like the output to be a dictionary, the key should be the name of each sheet, and the value should be a list of lists, where each inner list contains the contents of a row from that sheet.\n        '''\n    \n}\n"}
{"type": "source_file", "path": "oscopilot/agents/self_learning.py", "content": "import os\nimport logging\nfrom oscopilot.prompts.friday_pt import prompt\nimport json\nfrom oscopilot.utils import self_learning_print_logging, get_project_root_path, read_json, save_json\n\n\nclass SelfLearning: \n    \"\"\"\n    A class designed to facilitate self-learning for software-related topics by automatically generating and\n    engaging with courses based on provided software and package information.\n    \n    Attributes:\n        config (dict): Configuration settings for the learning process.\n        agent (object): An external agent or tool that interacts with the learning content or environment.\n        learner (object): A learner object that is responsible for designing the course.\n        tool_manager (object): Manages the tools required for course creation and learning.\n        text_extractor (object, optional): An optional component responsible for extracting text from files.\n        course (dict): A dictionary to store course details.\n    \"\"\"\n\n    def __init__(self, agent, learner, tool_manager, config, text_extractor=None):\n        \"\"\"\n        Initializes the SelfLearning class with necessary components like agent, learner, tool manager, and configuration.\n\n        Parameters:\n            agent (object): The executing agent that will run or simulate the course.\n            learner (object): A learning module or tool responsible for course creation.\n            tool_manager (object): Manages and orchestrates the use of external tools necessary for course operations.\n            config (dict): Configuration parameters that guide the self-learning process.\n            text_extractor (callable, optional): A function or callable that extracts text from provided file paths.\n        \"\"\"\n        super().__init__()\n        self.config = config\n        self.agent = agent   \n        self.learner = learner(prompt['self_learning_prompt'], tool_manager)      \n        self.course = {}\n        if text_extractor:\n            self.text_extractor = text_extractor(agent)\n\n    def _initialize_learning(self, software_name, package_name, demo_file_path):\n        \"\"\"\n        Common initialization logic for self-learning and continuous learning methods.\n\n        Args:\n            software_name (str): Name of the software.\n            package_name (str): Name of the package within the software.\n            demo_file_path (str): Path to a demo file used for extracting text content.\n\n        Returns:\n            tuple: A tuple containing the prior course path and the file content extracted from the demo file.\n        \"\"\"\n        self_learning_print_logging(self.config)\n        # Create or read the course file\n        courses_dir = get_project_root_path() + 'courses'\n        if not os.path.exists(courses_dir):\n            os.makedirs(courses_dir)\n        prior_course_path = os.path.join(courses_dir, software_name + '_' + package_name + '.json')\n        if os.path.exists(prior_course_path):\n            self.course = read_json(prior_course_path)\n        else:\n            initial_course = {}\n            save_json(prior_course_path, initial_course)\n        # Extract file content if demo file path is provided\n        file_content = None\n        if demo_file_path:\n            if not os.path.isabs(demo_file_path):\n                demo_file_path = get_project_root_path() + demo_file_path \n            file_content = self.text_extract(demo_file_path)\n        return prior_course_path, file_content\n\n    def self_learning(self, software_name, package_name, demo_file_path):\n        \"\"\"\n        Initiates the self-learning process by designing a course and triggering the learning mechanism.\n\n        Args:\n            software_name (str): The name of the software for which the course is being designed.\n            package_name (str): The name of the software package related to the course.\n            demo_file_path (str): The file path of a demo or example file that is relevant to the course content.\n\n        Returns:\n            None.\n        \"\"\"\n        prior_course_path, file_content = self._initialize_learning(software_name, package_name, demo_file_path)\n        if len(self.course) > 50:\n            prior_course = json.dumps(dict(list(self.course.items())[-50:]))\n        else:\n            prior_course = json.dumps(self.course, indent=4)\n        logging.info(f\"The latest lessons that have been completed so far are as follows:\\n {prior_course}\")\n        new_course = self.learner.design_course(software_name, package_name, demo_file_path, file_content, prior_course)\n        self.learn_course(new_course) \n        save_json(prior_course_path, new_course)  \n\n    def continuous_learning(self, software_name, package_name, demo_file_path=None):\n        \"\"\"\n        Implements a continuous learning process that updates and applies new courses based on a designed curriculum.\n\n        Args:\n            software_name (str): Name of the software being learned.\n            package_name (str): Name of the package within the software.\n            demo_file_path (str, optional): Path to a demo file used for extracting text content. Defaults to None.\n\n        Returns:\n            None: This method does not return anything but updates internal states and possibly external resources.\n        \"\"\"\n        prior_course_path, file_content = self._initialize_learning(software_name, package_name, demo_file_path)\n\n        # Continuously design and apply new courses        \n        while True:\n            if len(self.course) > 50:\n                prior_course = json.dumps(dict(list(self.course.items())[-50:]), indent=4)\n            else:\n                prior_course = json.dumps(self.course, indent=4)\n            logging.info(f\"The latest lessons that have been completed so far are as follows:\\n {prior_course}\")\n            new_course = self.learner.design_course(software_name, package_name, demo_file_path, file_content, prior_course)\n            self.course.update(new_course)\n            self.learn_course(new_course)   \n            save_json(prior_course_path, new_course)      \n\n    def text_extract(self, demo_file_path):\n        \"\"\"\n        Extracts text from the specified demo file path using the configured text extractor.\n\n        Args:\n            demo_file_path (str): The path to the demo file from which content needs to be extracted.\n\n        Returns:\n            str: The extracted content from the file.\n        \"\"\"\n        file_content = self.text_extractor.extract_file_content(demo_file_path)\n        return file_content\n    \n    def course_design(self, software_name, package_name, demo_file_path, file_content=None):\n        \"\"\"\n        Designs a course based on the provided software and package name, using content extracted from a demo file.\n\n        Args:\n            software_name (str): The name of the software for which the course is designed.\n            package_name (str): The package name related to the software.\n            demo_file_path (str): Path to the demo file used as content for the course.\n            file_content (str, optional): Content of the demo file to be included in the course.\n\n        Returns:\n            dict: The designed course as a dictionary.\n        \"\"\"\n        course = self.learner.design_course(software_name, package_name, demo_file_path, file_content)\n        return course\n\n    def learn_course(self, course):\n        \"\"\"\n        Triggers the learning of the designed course using the configured agent.\n\n        Args:\n            course (dict): The course dictionary containing lesson details to be learned.\n        Returns:\n            None.\n        \"\"\"\n        logging.info(f'There are {len(self.course)} lessons in the course.')\n        for name, lesson in course.items():\n            logging.info(f\"The current lesson is: {name}\")\n            logging.info(f\"The current lesson content is: {lesson}\")\n            self.agent.run(lesson)\n\n\n\n\n\n\n"}
{"type": "source_file", "path": "oscopilot/environments/applescript_env.py", "content": "import os\nfrom oscopilot.environments import SubprocessEnv\n\n\nclass AppleScript(SubprocessEnv):\n    \"\"\"\n    A class representing an AppleScript environment for executing AppleScript code.\n\n    This class inherits from SubprocessEnv, which provides a general environment for executing code in subprocesses.\n    \"\"\"    \n    file_extension = \"applescript\"\n    name = \"AppleScript\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the AppleScript environment.\n\n        Sets up the start command for executing AppleScript code.\n        \"\"\"        \n        super().__init__()\n        self.start_cmd = [os.environ.get(\"SHELL\", \"/bin/zsh\")]\n\n    def preprocess_code(self, code):\n        \"\"\"\n        Preprocesses the AppleScript code before execution.\n\n        Inserts an end_of_execution marker and adds active line indicators to the code.\n\n        Args:\n            code (str): The AppleScript code to preprocess.\n\n        Returns:\n            str: The preprocessed AppleScript code.\n        \"\"\"\n        # Add active line indicators to the code\n        code = self.add_active_line_indicators(code)\n\n        # Escape double quotes\n        code = code.replace('\"', r\"\\\"\")\n\n        # Wrap in double quotes\n        code = '\"' + code + '\"'\n\n        # Prepend start command for AppleScript\n        code = \"osascript -e \" + code\n\n        # Append end of execution indicator\n        code += '; echo \"##end_of_execution##\"'\n\n        return code\n\n    def add_active_line_indicators(self, code):\n        \"\"\"\n        Adds log commands to indicate the active line of execution in the AppleScript.\n\n        Args:\n            code (str): The AppleScript code to add active line indicators to.\n\n        Returns:\n            str: The modified AppleScript code with active line indicators.\n        \"\"\"\n        modified_lines = []\n        lines = code.split(\"\\n\")\n\n        for idx, line in enumerate(lines):\n            # Add log command to indicate the line number\n            if line.strip():  # Only add if line is not empty\n                modified_lines.append(f'log \"##active_line{idx + 1}##\"')\n            modified_lines.append(line)\n\n        return \"\\n\".join(modified_lines)\n\n    def detect_active_line(self, line):\n        \"\"\"\n        Detects the active line indicator in the output.\n\n        Args:\n            line (str): A line from the output.\n\n        Returns:\n            int: The line number indicated by the active line indicator, or None if not found.\n        \"\"\"\n        if \"##active_line\" in line:\n            return int(line.split(\"##active_line\")[1].split(\"##\")[0])\n        return None\n\n    def detect_end_of_execution(self, line):\n        \"\"\"\n        Detects the end of execution marker in the output.\n\n        Args:\n            line (str): A line from the output.\n\n        Returns:\n            bool: True if the end of execution marker is found, False otherwise.\n        \"\"\"\n        return \"##end_of_execution##\" in line\n"}
{"type": "source_file", "path": "oscopilot/environments/__init__.py", "content": "from .subprocess_env import *\nfrom .py_jupyter_env import *\nfrom .bash_env import *\nfrom .applescript_env import *\nfrom .env import *"}
{"type": "source_file", "path": "oscopilot/environments/bash_env.py", "content": "# This code is based on Open Interpreter. Original source: https://github.com/OpenInterpreter/open-interpreter\n\nimport os\nimport platform\nimport queue\nimport re\nimport subprocess\nimport threading\nimport time\nimport traceback\nfrom oscopilot.environments import SubprocessEnv\n\n\nclass Shell(SubprocessEnv):\n    \"\"\"\n    A class representing a shell environment for executing shell scripts.\n\n    This class inherits from SubprocessEnv, which provides a general environment for executing code in subprocesses.\n    \"\"\"    \n    file_extension = \"sh\"\n    name = \"Shell\"\n    aliases = [\"bash\", \"sh\", \"zsh\"]\n\n    def __init__(\n        self,\n    ):\n        \"\"\"\n        Initializes the Shell environment.\n\n        Determines the start command based on the platform.\n        \"\"\"        \n        super().__init__()\n\n        # Determine the start command based on the platform\n        if platform.system() == \"Windows\":\n            self.start_cmd = [\"cmd.exe\"]\n        else:\n            self.start_cmd = [os.environ.get(\"SHELL\", \"bash\")]\n\n    def preprocess_code(self, code):\n        \"\"\"\n        Preprocesses the shell script code before execution.\n\n        Args:\n            code (str): The shell script code to preprocess.\n\n        Returns:\n            str: The preprocessed shell script code.\n        \"\"\"        \n        return preprocess_shell(code)\n\n    def line_postprocessor(self, line):\n        \"\"\"\n        Postprocesses each line of output from the shell execution.\n\n        Args:\n            line (str): A line from the output of the shell script execution.\n\n        Returns:\n            str: The processed line.\n        \"\"\"        \n        return line\n\n    def detect_active_line(self, line):\n        \"\"\"\n        Detects the active line indicator in the output.\n\n        Args:\n            line (str): A line from the output.\n\n        Returns:\n            int: The line number indicated by the active line indicator, or None if not found.\n        \"\"\"        \n        if \"##active_line\" in line:\n            return int(line.split(\"##active_line\")[1].split(\"##\")[0])\n        return None\n\n    def detect_end_of_execution(self, line):\n        \"\"\"\n        Detects the end of execution marker in the output.\n\n        Args:\n            line (str): A line from the output.\n\n        Returns:\n            bool: True if the end of execution marker is found, False otherwise.\n        \"\"\"        \n        return \"##end_of_execution##\" in line\n\n\ndef preprocess_shell(code):\n    \"\"\"\n    Preprocesses the shell script code before execution.\n\n    Adds active line markers, wraps in a try-except block (trap in shell), and adds an end of execution marker.\n\n    Args:\n        code (str): The shell script code to preprocess.\n\n    Returns:\n        str: The preprocessed shell script code.\n    \"\"\"\n\n    # Add commands that tell us what the active line is\n    # if it's multiline, just skip this. soon we should make it work with multiline\n    if not has_multiline_commands(code):\n        code = add_active_line_prints(code)\n\n    # Add end command (we'll be listening for this so we know when it ends)\n    code += '\\necho \"##end_of_execution##\"'\n\n    return code\n\n\ndef add_active_line_prints(code):\n    \"\"\"\n    Adds echo statements indicating line numbers to a shell script.\n\n    Args:\n        code (str): The shell script code to add active line indicators to.\n\n    Returns:\n        str: The modified shell script code with active line indicators.\n    \"\"\"\n    lines = code.split(\"\\n\")\n    for index, line in enumerate(lines):\n        # Insert the echo command before the actual line\n        lines[index] = f'echo \"##active_line{index + 1}##\"\\n{line}'\n    return \"\\n\".join(lines)\n\n\ndef has_multiline_commands(script_text):\n    \"\"\"\n    Checks if a shell script contains multiline commands.\n\n    Args:\n        script_text (str): The shell script code to check.\n\n    Returns:\n        bool: True if the script contains multiline commands, False otherwise.\n    \"\"\"    \n    # Patterns that indicate a line continues\n    continuation_patterns = [\n        r\"\\\\$\",  # Line continuation character at the end of the line\n        r\"\\|$\",  # Pipe character at the end of the line indicating a pipeline continuation\n        r\"&&\\s*$\",  # Logical AND at the end of the line\n        r\"\\|\\|\\s*$\",  # Logical OR at the end of the line\n        r\"<\\($\",  # Start of process substitution\n        r\"\\($\",  # Start of subshell\n        r\"{\\s*$\",  # Start of a block\n        r\"\\bif\\b\",  # Start of an if statement\n        r\"\\bwhile\\b\",  # Start of a while loop\n        r\"\\bfor\\b\",  # Start of a for loop\n        r\"do\\s*$\",  # 'do' keyword for loops\n        r\"then\\s*$\",  # 'then' keyword for if statements\n    ]\n\n    # Check each line for multiline patterns\n    for line in script_text.splitlines():\n        if any(re.search(pattern, line.rstrip()) for pattern in continuation_patterns):\n            return True\n\n    return False\n\n\nif __name__ == '__main__':\n    env = Shell()\n    code = 'pip install --upgrade pip'\n    for _ in env.run(code):\n        print(_)\n"}
{"type": "source_file", "path": "oscopilot/modules/planner/basic_planner.py", "content": "from oscopilot.tool_repository.manager.action_node import ActionNode\nfrom collections import defaultdict, deque\nfrom oscopilot.modules.base_module import BaseModule\nfrom oscopilot.tool_repository.manager.tool_manager import get_open_api_description_pair\nfrom oscopilot.utils.utils import send_chat_prompts\nimport json\nimport sys\nimport logging\n\n\nclass BasicPlanner(BaseModule):\n    \"\"\"\n    A planning module responsible for decomposing complex tasks into manageable subtasks, replanning tasks based on new insights or failures, and managing the execution order of tasks. \n\n    The `BasicPlanner` uses a combination of tool descriptions, environmental state, and language learning models to dynamically create and adjust plans for task execution. It maintains a tool list to manage task dependencies and execution order, ensuring that tasks are executed in a sequence that respects their interdependencies.\n    \"\"\"\n    def __init__(self, prompt):\n        super().__init__()\n        self.subtask_num = 0\n        self.prompt = prompt\n        self.global_messages = []\n        self.sub_task_list = []\n\n    def reset_plan(self):\n        \"\"\"\n        Resets global messages and subtask list to their initial states.\n        \"\"\"\n        self.subtask_num = 0\n        self.global_messages = []\n        self.sub_task_list = []\n\n    def decompose_task(self, task):\n        \"\"\"\n        Decomposes a complex task into manageable subtasks.\n\n        This method takes a high-level task and utilizes the environments's current state\n        to format and send a decomposition request to the language learning model. It then \n        parses the response to construct and update the tool list with the decomposed subtasks.\n\n        Args:\n            task (str): The complex task to be decomposed.\n\n        \"\"\"\n        sys_prompt = self.prompt['_SYSTEM_TASK_DECOMPOSE_PROMPT']\n        user_prompt = self.prompt['_USER_TASK_DECOMPOSE_PROMPT'].format(\n            system_version=self.system_version,\n            task=task,\n            working_dir=self.environment.working_dir\n        )\n        response = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        print(response)\n        task_list = self.extract_list_from_string(response)\n        self.sub_task_list = task_list\n        self.subtask_num = len(task_list)\n\n\n    def replan_task(self, reasoning, current_task, relevant_tool_description_pair):\n        \"\"\"\n        Replans the current task by integrating new tools into the original tool graph.\n\n        Given the reasoning for replanning and the current task, this method generates a new\n        tool plan incorporating any relevant tools. It formats a replanning request, sends\n        it to the language learning model, and integrates the response (new tools) into the\n        existing tool graph. The graph is then updated to reflect the new dependencies and\n        re-sorted topologically.\n\n        Args:\n            reasoning (str): The reasoning or justification for replanning the task.\n            current_task (str): The identifier of the current task being replanned.\n            relevant_tool_description_pair (dict): A dictionary mapping relevant tool names to\n                                                    their descriptions for replanning.\n\n        Side Effects:\n            Modifies the tool graph to include new tools and updates the execution order\n            of tools within the graph.\n        \"\"\"\n        # current_task information\n        current_tool = self.tool_node[current_task]\n        current_task_description = current_tool.description\n        relevant_tool_description_pair = json.dumps(relevant_tool_description_pair)\n        files_and_folders = self.environment.list_working_dir()\n        sys_prompt = self.prompt['_SYSTEM_TASK_REPLAN_PROMPT']\n        user_prompt = self.prompt['_USER_TASK_REPLAN_PROMPT'].format(\n            current_task = current_task,\n            current_task_description = current_task_description,\n            system_version=self.system_version,\n            reasoning = reasoning,\n            tool_list = relevant_tool_description_pair,\n            working_dir = self.environment.working_dir,\n            files_and_folders = files_and_folders\n        )\n        response = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        new_tool = self.extract_json_from_string(response)\n        # add new tool to tool graph\n        self.add_new_tool(new_tool, current_task)\n        # update topological sort\n        self.topological_sort()\n\n    def update_tool(self, tool, return_val='', relevant_code=None, status=False, node_type='Code'):\n        \"\"\"\n        Updates the specified tool's node information within the tool graph.\n\n        This method allows updating an tool's return value, relevant code, execution status,\n        and node_type. It is particularly useful for modifying tools' details after their execution\n        or during the replanning phase.\n\n        Args:\n            tool (str): The tool identifier whose details are to be updated.\n            return_val (str, optional): The return value of the tool. Default is an empty string.\n            relevant_code (str, optional): Any relevant code associated with the tool. Default is None.\n            status (bool, optional): The execution status of the tool. Default is False.\n            node_type (str, optional): The node_type of the tool (e.g., 'Code'). Default is 'Code'.\n\n        Side Effects:\n            Updates the information of the specified tool node within the tool graph.\n        \"\"\"\n        if return_val:\n            if node_type=='Code':\n                return_val = self.extract_information(return_val, \"<return>\", \"</return>\")\n                print(\"************************<return>**************************\")\n                logging.info(return_val)\n                print(return_val)\n                print(\"************************</return>*************************\")  \n            if return_val != 'None':\n                self.tool_node[tool]._return_val = return_val\n        if relevant_code:\n            self.tool_node[tool]._relevant_code = relevant_code\n        self.tool_node[tool]._status = status\n\n    def get_tool_list(self, relevant_tool=None):\n        \"\"\"\n        Retrieves a list of all tools or a subset of relevant tools, including their names and descriptions.\n\n        This method fetches tool descriptions from the tool library. If a specific set of relevant tools\n        is provided, it filters the list to include only those tools. The resulting list (or the full list if\n        no relevant tools are specified) is then returned in JSON format.\n\n        Args:\n            relevant_tool (list, optional): A list of tool names to filter the returned tools by.\n                                            If None, all tools are included. Defaults to None.\n\n        Returns:\n            A JSON string representing a dictionary of tool names to their descriptions. \n            The dictionary includes either all tools from the library or only those specified as relevant.\n        \"\"\"\n        tool_dict = self.tool_manager.descriptions\n        if not relevant_tool:\n            return json.dumps(tool_dict)\n        relevant_tool_dict = {tool : description for tool ,description in tool_dict.items() if tool in relevant_tool}\n        relevant_tool_list = json.dumps(relevant_tool_dict)\n        return relevant_tool_list\n    \n    def create_tool_graph(self, decompose_json):\n        \"\"\"\n        Constructs an tool graph based on dependencies specified in the given JSON.\n\n        This method takes a JSON object containing task information and dependencies,\n        and constructs an tool graph. Each task is added as a node in the graph, with\n        directed edges representing task dependencies. The method updates the class's\n        internal structures to reflect this graph, including tool nodes and their\n        relationships, as well as the overall number of tools.\n\n        Args:\n            decompose_json (dict): A JSON object where each key is an tool name, and the value\n                                is a dictionary containing the tool's name, description,\n                                type, and dependencies.\n\n        Side Effects:\n            Modifies the internal state by updating `tool_num`, `tool_node`, and `tool_graph`\n            to reflect the newly created tool graph.\n        \"\"\"\n        for _, task_info in decompose_json.items():\n            self.tool_num += 1\n            task_name = task_info['name']\n            task_description = task_info['description']\n            task_type = task_info['type']\n            task_dependencies = task_info['dependencies']\n            self.tool_node[task_name] = ActionNode(task_name, task_description, task_type)\n            self.tool_graph[task_name] = task_dependencies\n            for pre_tool in self.tool_graph[task_name]:\n                self.tool_node[pre_tool].next_action[task_name] = task_description\n    \n    def add_new_tool(self, new_task_json, current_task):\n        \"\"\"\n        Incorporates a new tool into the existing tool graph based on its dependencies.\n\n        This method processes a JSON object representing a new task, including its name,\n        description, type, and dependencies, and adds it to the tool graph. It also updates\n        the tool nodes to reflect this new addition. Finally, it appends the last new task\n        to the list of dependencies for the specified current task.\n\n        Args:\n            new_task_json (dict): A JSON object containing the new task's details.\n            current_task (str): The name of the current task to which the new task's dependencies will be added.\n\n        Side Effects:\n            Updates the tool graph and nodes to include the new tool and its dependencies.\n            Modifies the dependencies of the current task to include the new tool.\n        \"\"\"\n        for _, task_info in new_task_json.items():\n            self.tool_num += 1\n            task_name = task_info['name']\n            task_description = task_info['description']\n            task_type = task_info['type']\n            task_dependencies = task_info['dependencies']\n            self.tool_node[task_name] = ActionNode(task_name, task_description, task_type)\n            self.tool_graph[task_name] = task_dependencies\n            for pre_tool in self.tool_graph[task_name]:\n                self.tool_node[pre_tool].next_action[task_name] = task_description           \n        last_new_task = list(new_task_json.keys())[-1]\n        self.tool_graph[current_task].append(last_new_task)\n        \n    def get_pre_tasks_info(self, current_task):\n        \"\"\"\n        Retrieves information about the prerequisite tasks for a given current task.\n\n        This method collects and formats details about all tasks that are prerequisites\n        for the specified current task. It extracts descriptions and return values for\n        each prerequisite task and compiles this information into a JSON string.\n\n        Args:\n            current_task (str): The name of the task for which prerequisite information is requested.\n\n        Returns:\n            A JSON string representing a dictionary, where each key is a prerequisite task's\n            name, and the value is a dictionary with the task's description and return value.\n        \"\"\"\n        pre_tasks_info = {}\n        for task in self.tool_graph[current_task]:\n            task_info = {\n                \"description\" : self.tool_node[task].description,\n                \"return_val\" : self.tool_node[task].return_val\n            }\n            pre_tasks_info[task] = task_info\n        pre_tasks_info = json.dumps(pre_tasks_info)\n        return pre_tasks_info\n\n\n"}
{"type": "source_file", "path": "oscopilot/modules/__init__.py", "content": "from .executor import *\nfrom .planner import *\nfrom .retriever import *\nfrom .learner import *"}
{"type": "source_file", "path": "oscopilot/modules/learner/self_learner.py", "content": "from oscopilot.modules.base_module import BaseModule\nfrom oscopilot.utils.utils import send_chat_prompts\n\n\nclass SelfLearner(BaseModule):\n    \"\"\"\n    This class represents a self-learning module that designs educational courses based on given parameters.\n    It inherits from BaseModule, utilizing its initialization and utility methods.\n    \n    Attributes:\n        prompt (dict): A dictionary containing system and user prompts for generating course designs.\n        tool_manager (object): An instance of a tool manager to handle external tool interactions.\n        course (dict): A dictionary to store course details that are generated based on user and system inputs.\n    \"\"\"\n    def __init__(self, prompt, tool_manager):\n        \"\"\"\n        Initializes the SelfLearner class with the necessary prompts and tool manager.\n        \n        Args:\n            prompt (dict): Contains the necessary prompts for generating the course design.\n            tool_manager (object): Manages interactions with external tools needed for course design.\n        \"\"\"\n        super().__init__()\n        self.prompt = prompt\n        self.tool_manager = tool_manager\n        self.course = {}\n        \n    def design_course(self, software_name, package_name, demo_file_path, file_content=None, prior_course=None):\n        \"\"\"\n        Designs a course based on specified software and content parameters and stores it in the course attribute.\n        \n        Args:\n            software_name (str): The name of the software around which the course is centered.\n            package_name (str): The name of the software package relevant to the course.\n            demo_file_path (str): Path to the demo file that will be used in the course.\n            file_content (str): The content of the file that will be demonstrated or used in the course.\n            prior_course (str): The course that has been completed.\n        \n        Returns:\n            dict: A dictionary containing the designed course details.\n        \n        Uses system and user prompts to create a conversation with a language model or similar system, to generate\n        a course based around the provided parameters. The response is then parsed into JSON format and saved.\n        \"\"\"\n        sys_prompt = self.prompt['_SYSTEM_COURSE_DESIGN_PROMPT']\n        user_prompt = self.prompt['_USER_COURSE_DESIGN_PROMPT'].format(\n            system_version = self.system_version,\n            software_name = software_name,\n            package_name = package_name,\n            file_content = file_content,\n            demo_file_path = demo_file_path,\n            prior_course = prior_course\n        )\n        response = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        # logging.info(f\"The overall response is: {response}\")\n        course = self.extract_json_from_string(response)\n        self.course = course\n        return self.course"}
{"type": "source_file", "path": "oscopilot/environments/subprocess_env.py", "content": "import os\nimport queue\nimport re\nimport subprocess\nimport threading\nimport time\nimport traceback\nfrom oscopilot.environments.base_env import BaseEnv\n\nclass SubprocessEnv(BaseEnv):\n    \"\"\"\n    A class representing an environment for executing code using subprocesses.\n\n    This class manages the execution of code in subprocesses, providing methods for preprocessing code,\n    starting and terminating processes, handling output streams, and executing code steps.\n\n    It inherits from BaseEnv, which provides basic environment functionality.\n    \"\"\"    \n\n    def __init__(self):\n        \"\"\"\n        Initializes the subprocess environment.\n\n        Attributes:\n            start_cmd (list): The command used to start the subprocess.\n            process (subprocess.Popen or None): The subprocess object.\n            verbose (bool): Whether to print verbose output.\n            output_queue (queue.Queue): A queue for storing output messages.\n            done (threading.Event): An event to signal completion of execution.\n        \"\"\"        \n        self.start_cmd = []\n        self.process = None\n        self.verbose = False\n        self.output_queue = queue.Queue()\n        self.done = threading.Event()\n\n    def detect_active_line(self, line):\n        \"\"\"\n        Detects an active line indicator in the output line.\n\n        Args:\n            line (str): The output line from the subprocess.\n\n        Returns:\n            int or None: The active line number if detected, else None.\n        \"\"\"        \n        return None\n\n    def detect_end_of_execution(self, line):\n        \"\"\"\n        Detects an end of execution marker in the output line.\n\n        Args:\n            line (str): The output line from the subprocess.\n\n        Returns:\n            bool: True if end of execution marker is detected, else False.\n        \"\"\"        \n        return None\n\n    def line_postprocessor(self, line):\n        \"\"\"\n        Post-processes an output line from the subprocess.\n\n        Args:\n            line (str): The output line from the subprocess.\n\n        Returns:\n            str or None: The processed line or None if line should be discarded.\n        \"\"\"        \n        return line\n\n    def preprocess_code(self, code):\n        \"\"\"\n        Preprocesses code before execution.\n\n        This method inserts an end_of_execution marker and optionally adds active line markers.\n\n        Args:\n            code (str): The code to preprocess.\n\n        Returns:\n            str: The preprocessed code.\n        \"\"\"\n        return code\n\n    def terminate(self):\n        \"\"\"\n        Terminates the subprocess if it is running.\n        \"\"\"        \n        if self.process:\n            self.process.terminate()\n            self.process.stdin.close()\n            self.process.stdout.close()\n\n    def start_process(self):\n        \"\"\"\n        Starts the subprocess to execute code.\n        \"\"\"        \n        if self.process:\n            self.terminate()\n\n        my_env = os.environ.copy()\n        my_env[\"PYTHONIOENCODING\"] = \"utf-8\"\n        self.process = subprocess.Popen(\n            self.start_cmd,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            bufsize=0,\n            universal_newlines=True,\n            env=my_env,\n            encoding=\"utf-8\",\n            errors=\"replace\",\n        )\n        threading.Thread(\n            target=self.handle_stream_output,\n            args=(self.process.stdout, False),\n            daemon=True,\n        ).start()\n        threading.Thread(\n            target=self.handle_stream_output,\n            args=(self.process.stderr, True),\n            daemon=True,\n        ).start()\n\n    def step(self, code):\n        \"\"\"\n        Executes a step of code.\n\n        Args:\n            code (str): The code to execute.\n\n        Yields:\n            dict: Output messages generated during execution.\n        \"\"\"        \n        retry_count = 0\n        max_retries = 3\n\n        # Setup\n        try:\n            code = self.preprocess_code(code)\n            if not self.process:\n                self.start_process()\n        except:\n            yield {\n                \"type\": \"console\",\n                \"format\": \"output\",\n                \"content\": traceback.format_exc(),\n            }\n            return\n\n        while retry_count <= max_retries:\n            if self.verbose:\n                print(f\"(after processing) Running processed code:\\n{code}\\n---\")\n\n            self.done.clear()\n\n            try:\n                self.process.stdin.write(code + \"\\n\")\n                self.process.stdin.flush()\n                break\n            except:\n                if retry_count != 0:\n                    # For UX, I like to hide this if it happens once. Obviously feels better to not see errors\n                    # Most of the time it doesn't matter, but we should figure out why it happens frequently with:\n                    # applescript\n                    yield {\n                        \"type\": \"console\",\n                        \"format\": \"output\",\n                        \"content\": f\"{traceback.format_exc()}\\nRetrying... ({retry_count}/{max_retries})\\nRestarting process.\",\n                    }\n\n                self.start_process()\n\n                retry_count += 1\n                if retry_count > max_retries:\n                    yield {\n                        \"type\": \"console\",\n                        \"format\": \"output\",\n                        \"content\": \"Maximum retries reached. Could not execute code.\",\n                    }\n                    return\n\n        while True:\n            if not self.output_queue.empty():\n                yield self.output_queue.get()\n            else:\n                time.sleep(0.1)\n            try:\n                output = self.output_queue.get(timeout=0.3)  # Waits for 0.3 seconds\n                yield output\n            except queue.Empty:\n                if self.done.is_set():\n                    # Try to yank 3 more times from it... maybe there's something in there...\n                    # (I don't know if this actually helps. Maybe we just need to yank 1 more time)\n                    for _ in range(3):\n                        if not self.output_queue.empty():\n                            yield self.output_queue.get()\n                        time.sleep(0.2)\n                    break\n\n    def handle_stream_output(self, stream, is_error_stream):\n        \"\"\"\n        Handles the streaming output from the subprocess.\n\n        Args:\n            stream: The output stream to handle.\n            is_error_stream (bool): Indicates if the stream is the error stream.\n        \"\"\"        \n        try:\n            for line in iter(stream.readline, \"\"):\n                if self.verbose:\n                    print(f\"Received output line:\\n{line}\\n---\")\n\n                line = self.line_postprocessor(line)\n\n                if line is None:\n                    continue  # `line = None` is the postprocessor's signal to discard completely\n\n                if self.detect_active_line(line):\n                    active_line = self.detect_active_line(line)\n                    self.output_queue.put(\n                        {\n                            \"type\": \"console\",\n                            \"format\": \"active_line\",\n                            \"content\": active_line,\n                        }\n                    )\n                    # Sometimes there's a little extra on the same line, so be sure to send that out\n                    line = re.sub(r\"##active_line\\d+##\", \"\", line)\n                    if line:\n                        self.output_queue.put(\n                            {\"type\": \"console\", \"format\": \"output\", \"content\": line}\n                        )\n                elif self.detect_end_of_execution(line):\n                    # Sometimes there's a little extra on the same line, so be sure to send that out\n                    line = line.replace(\"##end_of_execution##\", \"\").strip()\n                    if line:\n                        self.output_queue.put(\n                            {\"type\": \"console\", \"format\": \"output\", \"content\": line}\n                        )\n                    self.done.set()\n                elif is_error_stream and \"KeyboardInterrupt\" in line:\n                    self.output_queue.put(\n                        {\n                            \"type\": \"console\",\n                            \"format\": \"output\",\n                            \"content\": \"KeyboardInterrupt\",\n                        }\n                    )\n                    time.sleep(0.1)\n                    self.done.set()\n                else:\n                    self.output_queue.put(\n                        {\"type\": \"console\", \"format\": \"output\", \"content\": line}\n                    )\n        except ValueError as e:\n            if \"operation on closed file\" in str(e):\n                if self.verbose:\n                    print(\"Stream closed while reading.\")\n            else:\n                raise e\n\n\n"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/__init__.py", "content": ""}
{"type": "source_file", "path": "oscopilot/environments/base_env.py", "content": "import os\nfrom oscopilot.utils.config import Config\nfrom typing import Optional, Union, List\nfrom oscopilot.utils.schema import EnvState\n\n\nclass BaseEnv:\n    \"\"\"\n    A base class for environments configurations in action-based systems.\n\n    This class provides foundational attributes and methods for managing environments,\n    including timeouts, working directories, and environmental states. It is designed\n    to be extended by subclasses that implement specific environments behaviors.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the environments with default settings.\n\n        Sets up the working directory, applying a default timeout and preparing the\n        environments state. If the working directory does not exist, it is created.\n        \"\"\"\n        self._name: str = self.__class__.__name__\n        self.timeout: int = 300\n        working_dir = Config.get_parameter('working_dir')\n        if os.path.isabs(working_dir):\n            self.working_dir = working_dir\n        else:\n            self.working_dir = os.path.abspath(os.path.join(__file__, \"..\", \"..\", \"..\", working_dir))\n        if not os.path.exists(self.working_dir):\n            os.makedirs(self.working_dir)\n\n        self.env_state: Union[EnvState, None] = None\n\n    def step(self, code):\n        \"\"\"\n        Generator that yields a dictionary in LMC format:\n        {\"type\": \"console\", \"format\": \"output\", \"content\": \"a printed statement\"}\n        {\"type\": \"console\", \"format\": \"active_line\", \"content\": \"1\"}\n        {\"type\": \"image\", \"format\": \"base64\", \"content\": \"{base64}\"}\n        \"\"\"\n        return {\"type\": \"console\", \"format\": \"output\", \"content\": code}\n\n    def stop(self):\n        \"\"\"\n        Halts code execution, but does not terminate state.\n        \"\"\"\n        pass\n\n    def terminate(self):\n        \"\"\"\n        Terminates state.\n        \"\"\"\n        pass\n\n    def list_working_dir(self):\n        \"\"\"\n        Lists the contents of the working directory in a detailed format.\n\n        Returns a string representation similar to the output of the 'ls' command in Linux,\n        including file/directory names, sizes, and types.\n\n        Returns:\n            str: Detailed listings of the working directory's contents, or an error message if the directory does not exist.\n        \"\"\"\n        directory = self.working_dir\n        # Check if the directory exists\n        if not os.path.exists(directory):\n            return f\"Directory '{directory}' does not exist.\"\n\n        # List files and directories\n        files_and_dirs = os.listdir(directory)\n\n        # Create a list to store the details\n        details = []\n\n        for name in files_and_dirs:\n            # Get the full path\n            full_path = os.path.join(directory, name)\n\n            # Get file or directory size\n            size = os.path.getsize(full_path)\n\n            # Check if it's a file or directory\n            if os.path.isdir(full_path):\n                doc_type = 'Directory'\n            else:\n                doc_type = 'File'\n\n            details.append(f\"{name}\\t {size} bytes\\t {doc_type}\")\n\n        return \"\\n\".join(details)\n        \n    def step(self, _command) -> EnvState:\n        \"\"\"\n        Executes a command within the environments.\n\n        This method is intended to be implemented by subclasses, defining how commands\n        are processed and their effects on the environments state.\n\n        Args:\n            _command: The command to be executed.\n\n        Raises:\n            NotImplementedError: Indicates that the subclass must implement this method.\n\n        Returns:\n            EnvState: The state of the environments after executing the command.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Resets the environments to its initial state.\n\n        This method is intended to be implemented by subclasses, defining the specific\n        actions required to reset the environments.\n        \"\"\"\n        working_dir = Config.get_parameter('working_dir')\n        if os.path.isabs(working_dir):\n            self.working_dir = working_dir\n        else:\n            self.working_dir = os.path.abspath(os.path.join(__file__, \"..\", \"..\", \"..\", working_dir))\n    \n    @property\n    def name(self):\n        \"\"\"\n        The name of the environments.\n\n        Returns:\n            str: The name of the environments, typically set to the class name unless overridden in a subclass.\n        \"\"\"\n        return self._name\n\n    def __repr__(self):\n        \"\"\"\n        Provides a string representation of the environments.\n\n        Returns:\n            str: A representation of the environments, including its name.\n        \"\"\"\n        return f'{self.name}'\n\n    def __str__(self):\n        \"\"\"\n        Returns the string representation of the environments, mirroring `__repr__`.\n\n        Returns:\n            str: A string representation of the environments.\n        \"\"\"\n        return self.__repr__()\n\n\nif __name__ == '__main__':\n    env = BaseEnv()\n    env.env_state = EnvState()\n    # result = env.observe()\n"}
{"type": "source_file", "path": "oscopilot/modules/executor/__init__.py", "content": "from .friday_executor import *"}
{"type": "source_file", "path": "oscopilot/modules/planner/__init__.py", "content": "from .friday_planner import *\nfrom .basic_planner import *"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/audio2text/audio2text.py", "content": "from openai import OpenAI\n\nclass Audio2TextTool:\n    def __init__(self) -> None:\n        self.client = OpenAI()\n    def caption(self,audio_file):\n        # Perform voice recognition using the OpenAI Whisper API\n        response = self.client.audio.transcriptions.create(\n            model=\"whisper-1\",\n            file=audio_file\n        )\n        return response.texts"}
{"type": "source_file", "path": "oscopilot/modules/retriever/__init__.py", "content": "from .vector_retriever import *"}
{"type": "source_file", "path": "oscopilot/modules/learner/__init__.py", "content": "from .self_learner import *"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/bing/__init__.py", "content": ""}
{"type": "source_file", "path": "oscopilot/prompts/general_pt.py", "content": "prompt = {\n    \"GAIA_ANSWER_EXTRACTOR_PROMPT\": '''\n    You are tasked as an answer extractor. Given specific questions and their corresponding responses, extract answers following the directives provided. Ensure answers are in the correct format as instructed:\n\n    1. For numerical questions: Extract numerical values directly from the response.\n    2. For non-numerical questions: Follow the provided example to guide your extraction.\n    3. Note that sometimes you need to post-process the values you get follow the instruction in the question.\n    4. You need to follow the return format specified in the question. \n    Here are some examples of answer extraction:\n    Question: Hi, I was out sick from my classes on Friday, so I'm trying to figure out what I need to study for my Calculus mid-term next week. My friend from class sent me an audio recording of Professor Willowbrook giving out the recommended reading for the test, but my headphones are broken :(\\n\\nCould you please listen to the recording for me and tell me the page numbers I'm supposed to go over? I've attached a file called Homework.mp3 that has the recording. Please provide just the page numbers as a comma-delimited list. And please provide the list in ascending order.\n    Response: The page numbers extracted by the 'extract_page_numbers' subtask, already arranged in ascending order, are: 132, 133, 134, 197, 245.\n    Answer: 132, 133, 134, 197, 245\n\n    Question: What was the actual enrollment count of the clinical trial on H. pylori in acne vulgaris patients from Jan-May 2018 as listed on the NIH website?\n    Response: The actual enrollment count of the clinical trial on H. pylori in acne vulgaris patients is listed in the 'Study Design' section of the content returned by the previous task. According to the information provided, the actual enrollment was 90 participants.\n    Answer: 90\n\n    Question: Where were the Vietnamese specimens described by Kuznetzov in Nedoshivina's 2010 paper eventually deposited? Just give me the city name without abbreviations.\n    Response: The Vietnamese specimens described by Kuznetzov in Nedoshivina's 2010 paper were eventually deposited in the Zoological Institute, St. Petersburg. The city name without abbreviations is Saint Petersburg.\n    Answer: Saint Petersburg\n\n    Question: Who are the pitchers with the number before and after Taish Tamai's number as of July 2023? Give them to me in the form Pitcher Before, Pitcher After, use their last names only, in Roman characters.\n    Response: In the provided content, Taishō Tamai is listed with the number 19. The pitchers with the numbers before and after 19 are:\n                - Number 18: Sachiya Yamasaki\n                - Number 20: Kenta Uehara\n                Therefore, the answer in the requested format is: Yamasaki, Uehara.\n    Answer: Yoshida, Uehara\n\n    Question: Pull out the sentence in the following 5x7 block of text. Read from left to right and use all of the letters in order:\n                THESE\n                AGULL\n                GLIDE\n                DPEAC\n                EFULL\n                YTOMY\n                CHAIR\n    Response: To pull out the sentence from the given 5x7 block of text, we need to read from left to right and use all of the letters in order. Here's how you can do it:\n                1. Start with the first column and take the first letter from each row, then move to the second column and take the second letter from each row, and so on until you have read all columns.\n                Let's do this step by step:\n                - From the first column: \"TAGGED\"\n                - From the second column: \"HGLPFE\"\n                - From the third column: \"EUAIUC\"\n                - From the fourth column: \"SLDOHL\"\n                - From the fifth column: \"LEIYAI\"\n                2. Now, combine all the letters in the order you have taken them to form the sentence:\n                TAGGED + HGLPFE + EUAIUC + SLDOHL + LEIYAI\n                3. The sentence formed by combining all the letters is:\n                \"THE EAGLE GLIDED PEACEFULLY TO MY CHAIR.\"\n                This is the sentence pulled out from the 5x7 block of text.\n    Answer: The seagull glided peacefully to my chair.\n\n    Question: ¬(A ∧ B) ↔ (¬A ∨ ¬B) ¬(A ∨ B) ↔ (¬A ∧ ¬B) (A → B) ↔ (¬B → ¬A) (A → B) ↔ (¬A ∨ B) (¬A → B) ↔ (A ∨ ¬B) ¬(A → B) ↔ (A ∧ ¬B) Which of the above is not logically equivalent to the rest? Provide the full statement that doesn't fit.\n    Response: To determine which of the given logical statements is not equivalent to the others, we need to analyze each pair of statements to see if they are logically equivalent. Logical equivalence means that the statements have the same truth value in every possible scenario.\n                Here are the given statements:\n                1. ¬(A ∧ B) ↔ (¬A ∨ ¬B) - This is De Morgan's Law, stating that the negation of a conjunction is equivalent to the disjunction of the negations.\n                2. ¬(A ∨ B) ↔ (¬A ∧ ¬B) - This is also De Morgan's Law, stating that the negation of a disjunction is equivalent to the conjunction of the negations.\n                3. (A → B) ↔ (¬B → ¬A) - This is the contrapositive, stating that an implication is equivalent to its contrapositive.\n                4. (A → B) ↔ (¬A ∨ B) - This is the definition of implication, stating that an implication is equivalent to the disjunction of the negation of the antecedent or the consequent.\n                5. (¬A → B) ↔ (A ∨ ¬B) - This is not a standard equivalence. It seems to be a variation of the implication definition, but it's not correct as stated.\n                6. ¬(A → B) ↔ (A ∧ ¬B) - This is the negation of an implication, stating that the negation of an implication is equivalent to the conjunction of the antecedent and the negation of the consequent.\n                The statement that does not fit with the rest is:\n                (¬A → B) ↔ (A ∨ ¬B)\n                This statement is not a standard logical equivalence. The correct equivalence for the implication (¬A → B) would be (A ∨ B), not (A ∨ ¬B). Therefore, this is the full statement that doesn't fit with the others.\n    Answer: (¬A → B) ↔ (A ∨ ¬B)\n\n    Based on the Response provided below, extract the answer following above guidelines and instructions in the Question. Your response should only contain the extracted answer.\n    Question: {question}\n    Response: {response}\n    Answer:\n    '''\n}"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/image_caption/image_caption_service.py", "content": "from fastapi import APIRouter, HTTPException,UploadFile,File,Form, Depends\nfrom pydantic import BaseModel,Field\nfrom typing import Optional\nfrom .gpt4v_caption import ImageCaptionTool\nimport base64\n\nrouter = APIRouter()\n\nimage_caption_api = ImageCaptionTool()\n\n\n# class CaptionQueryItem(BaseModel):\n#     query: Optional[str] = \"What's in this image?\"\n#     url: Optional[str] = None\n#     image_file: Optional[UploadFile] = File(None)\n\nasync def caption_parameters(query: Optional[str] = Form(\"What's in this image?\"),url: Optional[str] = Form(None),image_file: Optional[UploadFile] = File(None)):\n    return {\"query\":query,\"url\":url,\"image_file\":image_file}\n\n@router.post(\"/tools/image_caption\", summary=\"When the task is to question and answer based on local picture, you have to use the Image Caption tool, who can directly analyze picture to answer question and complete task. For local images you want to understand, you need to only give the image_file without url. It is crucial to provide the 'query' parameter, and its value must be the full content of the task itself.\")\nasync def image_search(item: dict = Depends(caption_parameters)):\n    try:\n        if(item[\"query\"] == None):\n            item[\"query\"] = \"What's in this image?\"\n        if(item[\"url\"] == None and item[\"image_file\"] == None):\n            return {\"error\":\"Invalid picture\"}\n        image_url=\"\"\n        if(item[\"url\"] != None and item[\"image_file\"] == None):\n            image_url = item[\"url\"]\n        elif(item[\"image_file\"] != None):\n            base64Img = base64.b64encode(await item[\"image_file\"].read()).decode('utf-8')\n            image_url = f\"data:image/jpeg;base64,{base64Img}\"\n        caption = image_caption_api.caption(url=image_url,query=item[\"query\"])\n    except RuntimeError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return {\"caption\":caption}\n\n"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/bing/bing_api_v2.py", "content": "import requests\nfrom langchain.utilities import BingSearchAPIWrapper\nfrom bs4 import BeautifulSoup\nfrom typing import Tuple\nfrom enum import Enum\nfrom .web_loader import WebPageLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.chains.summarize import load_summarize_chain\nfrom langchain import OpenAI\n\nSEARCH_RESULT_LIST_CHUNK_SIZE = 3\nRESULT_TARGET_PAGE_PER_TEXT_COUNT = 500\n\n\nclass BingAPIV2:\n    \"\"\"\n    A class for interacting with the Bing Search API and performing subsequent processing on web page data.\n\n    This class encapsulates the functionality to perform web searches using Bing's API, load web pages,\n    chunk and embed text for analysis, summarize web pages, and attend to loaded pages based on specific queries.\n\n    Attributes:\n        search_engine (BingSearchAPIWrapper): Configured instance for executing searches with Bing's API.\n        web_loader (WebPageLoader): Utility for loading web page content.\n        web_chunker (RecursiveCharacterTextSplitter): Utility for splitting text into manageable chunks.\n        web_sniptter_embed (OpenAIEmbeddings): Embedding model for text chunks.\n        web_summarizer (OpenAI): Model for summarizing web page content.\n    \"\"\"\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the BingAPIV2 with components for search, web page loading, and text processing.\n        \"\"\"\n        self.search_engine = BingSearchAPIWrapper(search_kwargs={'mkt': 'en-us','safeSearch': 'moderate'})\n        self.web_loader = WebPageLoader()\n        self.web_chunker = RecursiveCharacterTextSplitter(chunk_size=4500, chunk_overlap=0)\n        self.web_sniptter_embed = OpenAIEmbeddings()\n        self.web_summarizer = OpenAI(\n            temperature=0,\n            )\n\n    def search(self, key_words: str,top_k: int = 5, max_retry: int = 3):\n        \"\"\"\n        Searches for web pages using Bing's API based on provided keywords.\n\n        Attempts the search up to a specified number of retries upon failure.\n\n        Args:\n            key_words (str): The keywords to search for.\n            top_k (int, optional): The number of search results to return. Defaults to 5.\n            max_retry (int, optional): The maximum number of retry attempts. Defaults to 3.\n\n        Returns:\n            list: A list of search results.\n\n        Raises:\n            RuntimeError: If the search attempts fail after reaching the maximum number of retries.\n        \"\"\"\n        for _ in range(max_retry):\n            try:\n                result = self.search_engine.results(key_words,top_k)\n            except Exception:\n                continue\n            if result != None:\n                return result\n            else:\n                continue\n        raise RuntimeError(\"Failed to access Bing Search API.\")\n\n    def load_page(self, url: str) -> str:\n        \"\"\"\n        Loads the content of a web page given its URL.\n\n        Args:\n            url (str): The URL of the web page to load.\n\n        Returns:\n            str: The content of the web page as a string.\n        \"\"\"\n        page_data = self.web_loader.load_data(url)\n        page_content_str = \"\"\n        if(page_data[\"data\"][0] != None and page_data[\"data\"][0][\"content\"] != None):\n            page_content_str = page_data[\"data\"][0][\"content\"]\n        return page_content_str\n    def summarize_loaded_page(self,page_str):\n        \"\"\"\n        Summarizes the content of a loaded web page.\n\n        Args:\n            page_str (str): The content of the web page to summarize.\n\n        Returns:\n            str: The summarized content of the web page.\n        \"\"\"\n        if page_str == \"\":\n            return \"\"\n        web_chunks = self.web_chunker.create_documents([page_str])\n        summarize_chain = load_summarize_chain(self.web_summarizer, chain_type=\"map_reduce\")\n        main_web_content = summarize_chain.run(web_chunks)\n        return main_web_content\n    def attended_loaded_page(self,page_str,query_str):\n        \"\"\"\n        Identifies and aggregates content from a loaded web page that is most relevant to a given query.\n\n        Args:\n            page_str (str): The content of the web page.\n            query_str (str): The query string to identify relevant content.\n\n        Returns:\n            str: The aggregated content from the web page that is most relevant to the query.\n        \"\"\"\n        if page_str == \"\":\n            return \"\"\n        web_chunks = self.web_chunker.create_documents([page_str])\n        chunSearch = Chroma.from_documents(web_chunks, self.web_sniptter_embed)\n        relatedChunks = chunSearch.similarity_search(query_str, k=3)\n        attended_content = '...'.join([chunk.page_content for chunk in relatedChunks])\n        return attended_content\n\n\n"}
{"type": "source_file", "path": "oscopilot/modules/executor/friday_executor.py", "content": "from oscopilot.modules.base_module import BaseModule\nfrom oscopilot.tool_repository.manager.tool_manager import get_open_api_doc_path\nimport re\nimport json\nimport subprocess\nfrom pathlib import Path\nfrom oscopilot.utils.utils import send_chat_prompts, api_exception_mechanism\n\n\n\n\nclass FridayExecutor(BaseModule):\n    \"\"\"\n    A modules within the system responsible for executing tools based on prompts and maintaining the tool library.\n\n    The ExecutionModule extends the BaseAgent class, focusing on the practical execution of tools determined\n    by the system. It utilizes a language learning model (LLM) in conjunction with an execution environments and\n    an tool library to carry out tools. Additionally, it manages system versioning and prompts initialization\n    for tool execution guidance.\n    \"\"\"\n\n    def __init__(self, prompt, tool_manager, max_iter=3):\n        super().__init__()\n        self.prompt = prompt\n        self.tool_manager = tool_manager\n        self.max_iter = max_iter\n        self.open_api_doc_path = get_open_api_doc_path()\n        self.open_api_doc = {}\n        with open(self.open_api_doc_path) as f:\n            self.open_api_doc = json.load(f) \n    \n    @api_exception_mechanism(max_retries=3)\n    def generate_tool(self, task_name, task_description, tool_type, pre_tasks_info, relevant_code):\n        \"\"\"\n        Generates executable code and invocation logic for a specified tool.\n\n        This method constructs a message to generate tool code capable of completing the specified task,\n        taking into account any prerequisite task information and relevant code snippets. It then formats\n        this message for processing by the language learning model (LLM) to generate the tool code. The\n        method extracts the executable Python code and the specific invocation logic from the LLM's response.\n\n        Args:\n            task_name (str): The name of the task for which tool code is being generated.\n            task_description (str): A description of the task, detailing what the tool aims to accomplish.\n            tool_type (str): The type of tool being generated, such as 'Python', 'Shell', or 'AppleScript'.\n            pre_tasks_info (dict): Information about tasks that are prerequisites for the current task, including their descriptions and return values.\n            relevant_code (dict): A dictionary of code snippets relevant to the current task, possibly including code from prerequisite tasks.\n\n        Returns:\n            tuple: A tuple containing two elements:\n                - code (str): The generated Python code for the tool.\n                - invoke (str): The specific logic or command to invoke the generated tool.\n        \"\"\"\n        relevant_code = json.dumps(relevant_code)\n        if tool_type == 'Python':\n            sys_prompt = self.prompt['_SYSTEM_PYTHON_SKILL_AND_INVOKE_GENERATE_PROMPT']\n            user_prompt = self.prompt['_USER_PYTHON_SKILL_AND_INVOKE_GENERATE_PROMPT'].format(\n                system_version=self.system_version,\n                task_description=task_description,\n                working_dir= self.environment.working_dir,\n                task_name=task_name,\n                pre_tasks_info=pre_tasks_info,\n                relevant_code=relevant_code\n            )\n        else:\n            sys_prompt = self.prompt['_SYSTEM_SHELL_APPLESCRIPT_GENERATE_PROMPT']\n            user_prompt = self.prompt['_USER_SHELL_APPLESCRIPT_GENERATE_PROMPT'].format(\n                system_version=self.system_version,\n                task_description=task_description,\n                working_dir= self.environment.working_dir,\n                task_name=task_name,\n                pre_tasks_info=pre_tasks_info,\n                Type=tool_type\n            )\n\n        create_msg = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        code = self.extract_code(create_msg, tool_type)\n        if tool_type == 'Python':\n            invoke = self.extract_information(create_msg, begin_str='<invoke>', end_str='</invoke>')[0]\n        else:\n            invoke = ''\n        return code, invoke\n\n    def execute_tool(self, code, invoke, node_type):\n        \"\"\"\n        Executes a given tool code and returns the execution state.\n\n        This method handles the execution of tool code based on its node_type. For code tools, it appends\n        additional instructions to print the execution result within designated markers. It then passes\n        the modified code for execution in the environments. The method captures and prints the execution\n        state, including any results or errors, and returns this state.\n\n        Args:\n            code (str): The Python code to be executed as part of the tool.\n            invoke (str): The specific command or function call that triggers the tool within the code.\n            node_type (str): The type of the tool, determining how the tool is executed. Currently supports 'Code' type.\n\n        Returns:\n            state: The state object returned by the environments after executing the tool. This object contains\n                   details about the execution's outcome, including any results or errors.\n\n        Note:\n            The execution logic is currently tailored for tools of type 'Code', where the code is directly executable\n            Python code. The method is designed to be extensible for other tool types as needed.\n        \"\"\"\n        # print result info\n        if node_type == 'Python':\n            info = \"\\n\" + '''print(\"<return>\")''' + \"\\n\" + \"print(result)\" +  \"\\n\" + '''print(\"</return>\")'''\n            code = code + '\\nresult=' + invoke + info\n        # state = EnvState(command=code)\n        print(\"************************<code>**************************\")\n        print(code)\n        print(\"************************</code>*************************\")\n        # for output_line_dic in self.environment.step(code):\n        #     if output_line_dic['format'] == 'active_line':\n        #         continue\n        #     content = output_line_dic['content']\n        #     if 'Traceback' in content:\n        #         state.error = (state.error or '') + content\n        #     else:\n        #         state.result += content\n        # state.pwd = self.environment.working_dir\n        # state.ls = subprocess.run(['ls'], cwd=self.environment.working_dir, capture_output=True, text=True).stdout\n        state = self.environment.step(node_type, code)  # node_type\n        print(\"************************<state>**************************\")\n        print(state)\n        # print(\"error: \" + state.error + \"\\nresult: \" + state.result + \"\\npwd: \" + state.pwd + \"\\nls: \" + state.ls)\n        print(\"************************</state>*************************\") \n        return state\n\n    @api_exception_mechanism(max_retries=3)\n    def judge_tool(self, code, task_description, state, next_action):\n        \"\"\"\n        Evaluates the outcome of an executed tool to determine its success in completing a task.\n\n        This method formulates and sends a judgment request to the language learning model (LLM) based on the\n        executed tool's code, the task description, the execution state, and the expected next tool. It\n        then parses the LLM's response to determine the tool's success, providing reasoning, a judgment (boolean),\n        and a score that quantifies the tool's effectiveness.\n\n        Args:\n            code (str): The code of the tool that was executed.\n            task_description (str): The description of the task the tool was intended to complete.\n            state: The state object returned by the environments after executing the tool, containing execution results.\n            next_action (str): The name of the next expected tool in the sequence.\n\n        Returns:\n            tuple: A tuple containing:\n                - reasoning (str): The LLM's reasoning behind the judgment.\n                - judge (bool): The LLM's judgment on whether the tool successfully completed the task.\n                - score (float): A score representing the effectiveness of the tool.\n        \"\"\"\n        next_action = json.dumps(next_action)\n        sys_prompt = self.prompt['_SYSTEM_TASK_JUDGE_PROMPT']\n        user_prompt = self.prompt['_USER_TASK_JUDGE_PROMPT'].format(\n            current_code=code,\n            task=task_description,\n            code_output=state.result[:999] if len(state.result) > 1000 else state.result,\n            current_working_dir=state.pwd,\n            working_dir=self.environment.working_dir,\n            files_and_folders=state.ls,\n            next_action=next_action,\n            code_error=state.error,\n        )\n        response = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        judge_json = self.extract_json_from_string(response) \n        print(\"************************<judge_json>**************************\")\n        print(judge_json)\n        print(\"************************</judge_json>*************************\")\n        try:\n            reasoning = judge_json['reasoning']\n            status = judge_json['status']\n            score = judge_json['score']\n        except KeyError as e:\n            print(\"The judge module did not output in the specified format.\")\n            raise ValueError(\"Missing key in judge module output: {}\".format(e))\n        return reasoning, status, score\n\n    @api_exception_mechanism(max_retries=3)\n    def repair_tool(self, current_code, task_description, tool_type, state, critique, pre_tasks_info):\n        \"\"\"\n        Modifies or corrects the code of an tool based on feedback to better complete a task.\n\n        This method sends an amendment request to the LLM, including details about the current code, task description,\n        execution state, critique of the tool's outcome, and information about prerequisite tasks. It aims to generate\n        a revised version of the code that addresses any identified issues or incomplete aspects of the task. The method\n        extracts and returns both the amended code and the specific logic or command to invoke the amended tool.\n\n        Args:\n            current_code (str): The original code of the tool that requires amendment.\n            task_description (str): The description of the task the tool is intended to complete.\n            tool_type (str): The type of tool being amended, such as 'Python', 'Shell', or 'AppleScript'.\n            state: The state object containing details about the tool's execution outcome.\n            critique (str): Feedback or critique on the tool's execution, used to guide the amendment.\n            pre_tasks_info (dict): Information about tasks that are prerequisites for the current task.\n\n        Returns:\n            tuple: A tuple containing:\n                - new_code (str): The amended code for the tool.\n                - invoke (str): The command or logic to invoke the amended tool.\n        \"\"\"\n        if tool_type == 'Python':\n            sys_prompt = self.prompt['_SYSTEM_PYTHON_SKILL_AMEND_AND_INVOKE_PROMPT']\n            user_prompt = self.prompt['_USER_PYTHON_SKILL_AMEND_AND_INVOKE_PROMPT'].format(\n                original_code = current_code,\n                task = task_description,\n                error = state.error,\n                code_output = state.result,\n                current_working_dir = state.pwd,\n                working_dir= self.environment.working_dir,\n                files_and_folders = state.ls,\n                critique = critique,\n                pre_tasks_info = pre_tasks_info\n            )\n        elif tool_type in ['Shell', 'AppleScript']:\n            sys_prompt = self.prompt['_SYSTEM_SHELL_APPLESCRIPT_AMEND_PROMPT']\n            user_prompt = self.prompt['_USER_SHELL_APPLESCRIPT_AMEND_PROMPT'].format(\n                original_code = current_code,\n                task = task_description,\n                error = state.error,\n                code_output = state.result,\n                current_working_dir = state.pwd,\n                working_dir= self.environment.working_dir,\n                files_and_folders = state.ls,\n                critique = critique,\n                pre_tasks_info = pre_tasks_info\n            )\n        amend_msg = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        new_code = self.extract_python_code(amend_msg)\n        invoke = self.extract_information(amend_msg, begin_str='<invoke>', end_str='</invoke>')[0]\n        return new_code, invoke\n\n    @api_exception_mechanism(max_retries=3)\n    def analysis_tool(self, code, task_description, state):\n        \"\"\"\n        Analyzes the execution outcome of an tool to determine the nature of any errors.\n\n        This method evaluates the execution state of an tool, specifically looking for errors. Based on the\n        analysis, it determines whether the error is environmental and requires new operations (handled by the\n        planning modules) or is amendable via the `repair_tool` method. The analysis results, including the reasoning\n        and error type, are returned in JSON format.\n\n        Args:\n            code (str): The code that was executed for the tool.\n            task_description (str): The description of the task associated with the tool.\n            state: The state object containing the result of the tool's execution, including any errors.\n\n        Returns:\n            tuple: A tuple containing:\n                - reasoning (str): The analysis's reasoning regarding the nature of the error.\n                - type (str): The type of error identified ('environmental' for new operations, 'amendable' for corrections).\n        \"\"\"\n        sys_prompt = self.prompt['_SYSTEM_ERROR_ANALYSIS_PROMPT']\n        user_prompt = self.prompt['_USER_ERROR_ANALYSIS_PROMPT'].format(\n            current_code=code,\n            task=task_description,\n            code_error=state.error,\n            current_working_dir=state.pwd,\n            working_dir= self.environment.working_dir,\n            files_and_folders= state.ls\n        )\n\n        response = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        analysis_json = self.extract_json_from_string(response)   \n        print(\"************************<analysis_json>**************************\")\n        print(analysis_json)\n        print(\"************************</analysis_json>*************************\")   \n\n        reasoning = analysis_json['reasoning']\n        error_type = analysis_json['type']\n        return reasoning, error_type\n        \n    def store_tool(self, tool, code):\n        \"\"\"\n        Stores the provided tool and its code in the tool library.\n\n        If the specified tool does not already exist in the tool library, this method proceeds to store the tool's\n        code, arguments description, and other relevant information. It involves saving these details into JSON files and\n        updating the tool library database. If the tool already exists, it outputs a notification indicating so.\n\n        Args:\n            tool (str): The name of the tool to be stored.\n            code (str): The executable code associated with the tool.\n\n        Side Effects:\n            - Adds a new tool to the tool library if it doesn't already exist.\n            - Saves tool details to the filesystem and updates the tool library's database.\n            - Outputs a message if the tool already exists in the library.\n        \"\"\"\n        # If tool not in db.\n        if not self.tool_manager.exist_tool(tool):\n            # Implement tool storage logic and store new tools\n            # args_description = self.extract_args_description(code)\n            tool_description = self.extract_tool_description(code)\n            # Save tool name, code, and description to JSON\n            tool_info = self.save_tool_info_to_json(tool, code, tool_description)\n            # Save code and descriptions to databases and JSON files\n            self.tool_manager.add_new_tool(tool_info)\n            # # Parameter description save path\n            # args_description_file_path = self.tool_manager.generated_tool_repo_dir + '/args_description/' + tool + '.txt'      \n            # # save args_description\n            # self.save_str_to_path(args_description, args_description_file_path)\n        else:\n            print(\"tool already exists!\")\n\n    @api_exception_mechanism(max_retries=3)\n    def api_tool(self, description, api_path, context=\"No context provided.\"):\n        \"\"\"\n        Executes a task by calling an API tool with the provided description and context.\n\n        This method formats a message to generate executable code for an API call based on the\n        provided description and context. It sends this message to the language learning model (LLM),\n        extracts the executable Python code from the LLM's response, and returns this code.\n\n        Args:\n            description (str): A description of the task to be performed by the API call.\n            api_path (str): The path or endpoint of the API to be called.\n            context (str, optional): Additional context to be included in the API call. Defaults to \"No context provided.\".\n\n        Returns:\n            str: The generated Python code to execute the API call.\n        \"\"\"\n        self.sys_prompt = self.prompt['_SYSTEM_TOOL_USAGE_PROMPT'].format(\n            openapi_doc = json.dumps(self.generate_openapi_doc(api_path)),\n            tool_sub_task = description,\n            context = context\n        )\n        self.user_prompt = self.prompt['_USER_TOOL_USAGE_PROMPT']\n        response = send_chat_prompts(self.sys_prompt, self.user_prompt, self.llm)\n        code = self.extract_python_code(response)\n        return code \n    \n    def question_and_answer_tool(self, context, question, current_question=None):\n        sys_prompt = self.prompt['_SYSTEM_QA_PROMPT']\n        user_prompt = self.prompt['_USER_QA_PROMPT'].format(\n            context = context,\n            question = question,\n            current_question = current_question\n        )\n        return send_chat_prompts(sys_prompt, user_prompt, self.llm)  \n\n    def extract_code(self, response, code_type):\n        code = \"\"\n        code_type_str = '```'+code_type.lower()\n        if code_type_str in response:\n            code = response.split(code_type_str)[1].split('```')[0]\n        elif '```' in code:\n            code = response.split('```')[1].split('```')[0]\n        else:\n            raise NotImplementedError\n        return code.strip()\n\n    def extract_python_code(self, response):\n        \"\"\"\n        Extracts Python code snippets from a response string that includes code block markers.\n\n        This method parses a response string to extract Python code enclosed within '```python' and '```' markers.\n        It's designed to retrieve executable Python code snippets from formatted responses, such as those returned\n        by a language learning model after processing a code generation or analysis prompts.\n\n        Args:\n            response (str): The response string containing the Python code block to be extracted.\n\n        Returns:\n            str: The extracted Python code snippet, or an empty string if no code block is found.\n        \"\"\"\n        python_code = \"\"\n        if '```python' in response:\n            python_code = response.split('```python')[1].split('```')[0]\n        elif '```' in python_code:\n            python_code = response.split('```')[1].split('```')[0]\n        return python_code    \n\n    def extract_class_name_and_args_description(self, class_code):\n        \"\"\"\n        Extracts the class name and arguments description from a given Python class code.\n\n        This method searches the provided class code for the class name and the documentation string\n        of the `__call__` method, which typically includes descriptions of the arguments. It uses regular\n        expressions to locate these elements within the code.\n\n        Args:\n            class_code (str): The Python code of the class from which information is to be extracted.\n\n        Returns:\n            tuple: A tuple containing:\n                - class_name (str): The name of the class extracted from the code.\n                - args_description (str): The arguments description extracted from the `__call__` method's docstring, if available; otherwise, None.\n        \"\"\"\n        class_name_pattern = r\"class (\\w+)\"\n        class_name_match = re.search(class_name_pattern, class_code)\n        class_name = class_name_match.group(1) if class_name_match else None\n\n        # Extracting the __call__ method's docstring\n        call_method_docstring_pattern = r\"def __call__\\([^)]*\\):\\s+\\\"\\\"\\\"(.*?)\\\"\\\"\\\"\"\n        call_method_docstring_match = re.search(call_method_docstring_pattern, class_code, re.DOTALL)\n        args_description = call_method_docstring_match.group(1).strip() if call_method_docstring_match else None\n\n        return class_name, args_description\n    \n    def extract_args_description(self, class_code):\n        \"\"\"\n        Extracts the arguments description from the `__call__` method's docstring within Python class code.\n\n        This method specifically targets the docstring of the `__call__` method in a class, which is conventionally\n        used to describe the method's parameters. The extraction is performed using a regular expression that\n        captures the content of the docstring.\n\n        Args:\n            class_code (str): The Python code of the class from which the arguments description is to be extracted.\n\n        Returns:\n            str: The extracted arguments description from the `__call__` method's docstring, or None if the docstring is not found or does not contain descriptions.\n        \"\"\"\n        # Extracting the __call__ method's docstring\n        call_method_docstring_pattern = r\"def __call__\\([^)]*\\):\\s+\\\"\\\"\\\"(.*?)\\\"\\\"\\\"\"\n        call_method_docstring_match = re.search(call_method_docstring_pattern, class_code, re.DOTALL)\n        args_description = call_method_docstring_match.group(1).strip() if call_method_docstring_match else None\n        return args_description\n\n    def extract_tool_description(self, class_code):\n        \"\"\"\n        Extracts the description of an tool from the class's initialization method in Python code.\n\n        This method looks for the tool's description assigned to `self._description` within the `__init__` method\n        of a class. It uses regular expressions to find this assignment and extracts the description string. This\n        approach assumes that the tool's description is directly assigned as a string literal to `self._description`.\n\n        Args:\n            class_code (str): The complete Python code of the class from which the tool description is to be extracted.\n\n        Returns:\n            str: The extracted description of the tool if found; otherwise, None.\n        \"\"\"\n        match = re.search(r'\"\"\"\\s*\\n\\s*(.*?)[\\.\\n]', class_code)\n        if match:\n            first_sentence = match.group(1)\n            # print(\"First sentence of the comment:\", first_sentence)\n        else:\n            print(\"No description found.\")\n            raise NotImplementedError\n        return first_sentence\n    \n    def save_str_to_path(self, content, path):\n        \"\"\"\n        Saves a string content to a file at the specified path, ensuring the directory exists.\n\n        This method takes a string and a file path, creating any necessary parent directories before\n        writing the content to the file. It ensures that the content is written with proper encoding and\n        that any existing content in the file is overwritten. The content is processed to remove extra\n        whitespace at the beginning and end of each line before saving.\n\n        Args:\n            content (str): The string content to be saved to the file.\n            path (str): The filesystem path where the content should be saved. If the directory does not exist,\n                        it will be created.\n\n        Side Effects:\n            - Creates the directory path if it does not exist.\n            - Writes the content to a file at the specified path, potentially overwriting existing content.\n        \"\"\"\n        Path(path).parent.mkdir(parents=True, exist_ok=True)\n        with open(path, 'w', encoding='utf-8') as f:\n            lines = content.strip().splitlines()\n            content = '\\n'.join(lines)\n            f.write(content)\n                 \n    def save_tool_info_to_json(self, tool, code, description):\n        \"\"\"\n        Constructs a dictionary containing tool information suitable for JSON serialization.\n\n        This method packages the name, code, and description of an tool into a dictionary, making it ready\n        for serialization or further processing. This structured format is useful for saving tool details\n        in a consistent manner, facilitating easy storage and retrieval.\n\n        Args:\n            tool (str): The name of the tool.\n            code (str): The executable code associated with the tool.\n            description (str): A textual description of what the tool does.\n\n        Returns:\n            dict: A dictionary containing the tool's name, code, and description.\n        \"\"\"\n        info = {\n            \"task_name\" : tool,\n            \"code\": code,\n            \"description\": description\n        }\n        return info\n\n    def extract_API_Path(self, text):\n        \"\"\"\n        Extracts both UNIX-style and Windows-style file paths from the provided text string.\n\n        This method applies regular expressions to identify and extract file paths that may be present in\n        the input text. It is capable of recognizing paths that are enclosed within single or double quotes\n        and supports both UNIX-style paths (e.g., `/home/user/docs`) and Windows-style paths (e.g., `C:\\\\Users\\\\user\\\\docs`).\n        If multiple paths are found, only the first match is returned, following the function's current implementation.\n\n        Args:\n            text (str): The string from which file paths are to be extracted.\n\n        Returns:\n            str: The first file path found in the input text, with any enclosing quotes removed. If no paths are\n                found, an empty string is returned.\n\n        Note:\n            The current implementation returns only the first extracted path. If multiple paths are present in the\n            input text, consider modifying the method to return all found paths if the use case requires it.\n        \"\"\"\n        # Regular expression for UNIX-style and Windows-style paths\n        unix_path_pattern = r\"/[^/\\s]+(?:/[^/\\s]*)*\"\n        windows_path_pattern = r\"[a-zA-Z]:\\\\(?:[^\\\\\\/\\s]+\\\\)*[^\\\\\\/\\s]+\"\n\n        # Combine both patterns\n        pattern = f\"({unix_path_pattern})|({windows_path_pattern})\"\n\n        # Find all matches\n        matches = re.findall(pattern, text)\n\n        # Extract paths from the tuples returned by findall\n        paths = [match[0] or match[1] for match in matches]\n\n        # Remove enclosing quotes (single or double) from the paths\n        stripped_paths = [path.strip(\"'\\\"\") for path in paths]\n        return stripped_paths[0]\n    \n\n    def generate_openapi_doc(self, tool_api_path):\n        \"\"\"\n        Generates a reduced OpenAPI documentation for a specific API path from the full OpenAPI documentation.\n\n        This method isolates and extracts the documentation for a specific tool API path, including its\n        schemas and operations (GET, POST), from the entire OpenAPI documentation stored in the instance.\n        It constructs a new, smaller OpenAPI document that only includes details relevant to the specified API path.\n        If the API path does not exist in the full documentation, it returns an error message.\n\n        Args:\n            tool_api_path (str): The specific API path for which the OpenAPI documentation should be generated.\n\n        Returns:\n            dict: A dictionary representing the OpenAPI documentation for the specific API path. If the path is not\n                found, returns a dictionary with an error message.\n        \n        The method performs several checks:\n        - Verifies the existence of the tool API path in the full OpenAPI documentation.\n        - Extracts relevant parts of the OpenAPI schema related to the path.\n        - Includes any referenced schemas necessary for understanding the API's structure and data types.\n\n        It handles both JSON and multipart/form-data content types in API request bodies, searching for schema references\n        to include in the returned documentation. This enables the resulting API document to be self-contained with respect\n        to the schemas needed to understand the API's usage.\n        \"\"\"\n        # init current api's doc\n        curr_api_doc = {}\n        curr_api_doc[\"openapi\"] = self.open_api_doc[\"openapi\"]\n        curr_api_doc[\"info\"] = self.open_api_doc[\"info\"]\n        curr_api_doc[\"paths\"] = {}\n        curr_api_doc[\"components\"] = {\"schemas\":{}}\n        api_path_doc = {}\n        #extract path and schema\n        if tool_api_path not in self.open_api_doc[\"paths\"]:\n            curr_api_doc = {\"error\": \"The api is not existed\"}\n            return curr_api_doc\n        api_path_doc = self.open_api_doc[\"paths\"][tool_api_path]\n        curr_api_doc[\"paths\"][tool_api_path] = api_path_doc\n        find_ptr = {}\n        if \"get\" in api_path_doc:\n            findptr  = api_path_doc[\"get\"]\n        elif \"post\" in api_path_doc:\n            findptr = api_path_doc[\"post\"]\n        api_params_schema_ref = \"\"\n        # json格式\n        if ((\"requestBody\" in findptr) and \n        (\"content\" in findptr[\"requestBody\"]) and \n        (\"application/json\" in findptr[\"requestBody\"][\"content\"]) and \n        (\"schema\" in findptr[\"requestBody\"][\"content\"][\"application/json\"]) and \n        (\"$ref\" in findptr[\"requestBody\"][\"content\"][\"application/json\"][\"schema\"])):\n            api_params_schema_ref = findptr[\"requestBody\"][\"content\"][\"application/json\"][\"schema\"][\"$ref\"]\n        elif ((\"requestBody\" in findptr) and \n        (\"content\" in findptr[\"requestBody\"]) and \n        (\"multipart/form-data\" in findptr[\"requestBody\"][\"content\"]) and \n        (\"schema\" in findptr[\"requestBody\"][\"content\"][\"multipart/form-data\"]) and \n        (\"allOf\" in findptr[\"requestBody\"][\"content\"][\"multipart/form-data\"][\"schema\"]) and \n        (\"$ref\" in findptr[\"requestBody\"][\"content\"][\"multipart/form-data\"][\"schema\"][\"allOf\"][0])):\n            api_params_schema_ref = findptr[\"requestBody\"][\"content\"][\"multipart/form-data\"][\"schema\"][\"allOf\"][0][\"$ref\"]\n        if api_params_schema_ref != None and api_params_schema_ref != \"\":\n            curr_api_doc[\"components\"][\"schemas\"][api_params_schema_ref.split('/')[-1]] = self.open_api_doc[\"components\"][\"schemas\"][api_params_schema_ref.split('/')[-1]]\n        return curr_api_doc\n\n"}
{"type": "source_file", "path": "oscopilot/prompts/friday_pt.py", "content": "\"\"\"\nThis modules contains a comprehensive `prompts` dictionary that serves as a repository of prompts for guiding the AI agents's interactions across various operational scenarios, including execution, planning, and information retrieval tasks. These prompts are meticulously crafted to instruct the AI in performing its duties, ranging from code generation and amendment to task decomposition and planning, as well as error analysis and tool usage.\n\nThe dictionary is segmented into five main categories:\n\n1. **execute_prompt**: Contains prompts for execution-related tasks, such as code generation, invocation, amendment, and error judgment. These are further detailed for system actions and user interactions, facilitating a diverse range of programming and troubleshooting tasks.\n\n2. **planning_prompt**: Focuses on task planning and re-planning, decomposing complex tasks into manageable sub-tasks, and adapting plans based on unforeseen issues, ensuring that the AI can assist in project management and task organization effectively.\n\n3. **retrieve_prompt**: Dedicated to information retrieval, including filtering code snippets based on specific criteria, aiding the AI in sourcing and suggesting code solutions efficiently.\n\n4. **self_learning_prompt**: Contains prompts for self-learning tasks, such as designing educational courses based on software and content parameters. These prompts guide the AI in generating course designs and educational content tailored to user needs.\n\n5. **text_extract_prompt**: Contains prompts for text extraction tasks, such as extracting specific information from text data. These prompts guide the AI in identifying and extracting relevant data from text inputs.\n\nEach category comprises system and user prompts, where system prompts define the AI's task or query in detail, and user prompts typically include placeholders for dynamic information insertion, reflecting the context or specific requirements of the task at hand.\n\nUsage:\nThe `prompts` dictionary is utilized by the AI agents to dynamically select appropriate prompts based on the current context or task, ensuring relevant and precise guidance for each operation. This dynamic approach allows the AI to adapt its interactions and responses to suit a wide array of programming and operational needs, enhancing its utility and effectiveness in assisting users.\n\nExample:\n    .. code-block:: python\n\n        # Accessing a specific prompts for task execution\n        execute_prompt = prompts['execute_prompt']['_SYSTEM_SKILL_CREATE_AND_INVOKE_PROMPT']\n\"\"\"\nprompt = {\n    'execute_prompt': {\n        # shell/applescript generator\n        '_SYSTEM_SHELL_APPLESCRIPT_GENERATE_PROMPT': '''\n        You are a world-class programmer that can complete any task by executing code, your goal is to generate the corresponding code based on the type of code to complete the task.\n        You could only respond with a code.\n        Shell code output Format:\n        ```shell\n        shell code\n        ```\n\n        AppleScript code output Format:\n        ```applescript\n        applescript code\n        ```        \n\n        The code you write should follow the following criteria:\n        1. You must generate code of the specified 'Code Type' to complete the task.\n        2. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        ''',\n        '_USER_SHELL_APPLESCRIPT_GENERATE_PROMPT': '''\n        User's information is as follows:\n        System Version: {system_version}\n        System language: simplified chinese\n        Working Directory: {working_dir}\n        Task Name: {task_name}\n        Task Description: {task_description}     \n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Code Type: {Type}\n        Detailed description of user information:\n        1. 'Working Directory' represents the working directory. It may not necessarily be the same as the current working directory. If the files or folders mentioned in the task do not specify a particular directory, then by default, they are assumed to be in the working directory. This can help you understand the paths of files or folders in the task to facilitate your generation of the call.\n        2. 'Information of Prerequisite Tasks' provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        3, 'Code Type' represents the type of code to be generated.\n\n        Note: Please output according to the output format specified in the system message.\n        ''',        \n\n\n        # Python generate and invoke prompts in os\n        '_SYSTEM_PYTHON_SKILL_AND_INVOKE_GENERATE_PROMPT': '''\n        You are a world-class programmer that can complete any task by executing code, your goal is to generate the function code that accomplishes the task, along with the function call.\n        You could only respond with a python function enclosed between ```python and ```, and the corresponding function call enclosed between <invoke> and </invoke>.\n        Output Format:\n        ```python\n        def python_function():\n            # function code\n        ```\n        <invoke>python_function(arg1, arg2, ...)</invoke>\n\n        The python function you write should follow the following criteria:\n        1. Function name should be the same as the 'Task Name' provided by the user.\n        2. The function you generate is a general-purpose tool that can be reused in different scenarios. Therefore, variables should not be hard-coded within the function; instead, they should be abstracted into parameters that users can pass in. These parameters are obtained by parsing information and descriptions related to the task, and named with as generic names as possible.\n        3. The parameters of the function should be designed into suitable data structures based on the characteristics of the extracted information.\n        4. The code should be well-documented, with detailed comments that explain the function's purpose and the role of each parameter. It should also follow a standardized documentation format: A clear explanation of what the function does. Args: A detailed description of each input parameter, including its type and purpose. Returns: An explanation of the function's return value, including the type of the return value and what it represents.\n        5. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        6. The function must have a return value. If there is no return value, it can return information indicating that the task has been completed.\n        7. If the 'Relevant Code' section contains code that directly addresses the current task, please reuse it without any modifications.\n        8. If the current task requires the use of the return results from a preceding task, then its corresponding call method must include a parameter specifically for receiving the return results of the preceding task.\n        9. If the current task depends on the results from a previous task, the function must include a parameter designed to accept the results from that previous task.\n        10. If the code involves the output of file paths, ensure that the output includes the files' absolute path.\n\n        And the function call should follow the following criteria:\n        1. The Python function call must be syntactically correct as per Python standards.\n        2. Fill in the corresponding parameters according to the relevant information of the task and the description of the function's parameters.\n        3. If the function call requires the output of prerequisite tasks, you can obtain relevant information from 'Information of Prerequisite Tasks'.\n        4. The parameter information should be written directly into the function call, rather than being passed as variables to the function. \n        5. The generated function call should be a single line and should not include any additional text or comments.\n        ''',\n        '_USER_PYTHON_SKILL_AND_INVOKE_GENERATE_PROMPT': '''\n        User's information is as follows:\n        System Version: {system_version}\n        System language: simplified chinese\n        Working Directory: {working_dir}\n        Task Name: {task_name}\n        Task Description: {task_description}     \n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Relevant Code: {relevant_code}\n        Detailed description of user information:\n        1. 'Working Directory' represents the working directory. It may not necessarily be the same as the current working directory. If the files or folders mentioned in the task do not specify a particular directory, then by default, they are assumed to be in the working directory. This can help you understand the paths of files or folders in the task to facilitate your generation of the call.\n        2. 'Information of Prerequisite Tasks' provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        3. 'Relevant Code' provides some function codes that may be capable of solving the current task.\n\n        Note: Please output according to the output format specified in the system message.\n        ''',\n\n\n        # shell/applescript amend in os\n        '_SYSTEM_SHELL_APPLESCRIPT_AMEND_PROMPT': '''\n        You are an expert in programming, with a focus on diagnosing and resolving code issues.\n        Your goal is to precisely identify the reasons for failure in the existing code and implement effective modifications to ensure it accomplishes the intended task without errors.\n        You should only respond with a modified code.\n        Code in the format as described below:\n        1. Error Analysis: Conduct a step-by-step analysis to identify why the code is generating errors or failing to complete the task. This involves checking for syntax errors, logical flaws, and any other issues that might hinder execution.\n        2. Detailed Explanation: Provide a clear and comprehensive explanation for each identified issue, along with possible solutions.\n        3. Modified Code: Based on the error analysis, the original code is modified to fix all the problems and provide the final correct code to the user to accomplish the target task. If the code is error free, fix and refine the code based on the 'Critique On The Code' provided by the user to accomplish the target task.    \n\n        And the code you write should also follow the following criteria:\n        1. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        2. The code must be enclosed between ```[code type] and ```. For example, ```shell [shell code] ```.\n        3. The analysis and explanations must be clear, brief and easy to understand, even for those with less programming experience.\n        4. All modifications must address the specific issues identified in the error analysis.\n        5. The solution must enable the code to successfully complete the intended task without errors.\n        6. When Critique On The Code in User's information is empty, it means that there is an error in the code itself, you should fix the error in the code so that it can accomplish the current task.\n        ''',\n        '_USER_SHELL_APPLESCRIPT_AMEND_PROMPT': '''\n        User's information are as follows:\n        Original Code: {original_code}\n        Task: {task}\n        Error Messages: {error}\n        Code Output: {code_output}\n        Current Working Directiory: {current_working_dir}\n        Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Critique On The Code: {critique}\n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Detailed description of user information:\n        1. 'Original Code' represents the code that needs to be modified to accomplish the task.\n        2. 'Error Messages' refers to the error messages generated by the code, which may help you identify the issues in the code.\n        3. 'Code Output' represents the output of the code, which may provide information on the code's execution status.\n        4. 'Working Directory' represents the root directory of the working directory, and 'Current Working Directory' represents the directory where the current task is located.    \n        5. 'Critique On The Code' refers to code modification suggestions given by other code experts and may be empty.\n        6. 'Information of Prerequisite Tasks' from User's information provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        \n        Note: Please output according to the output format specified in the system message.\n        ''',\n\n\n        # Python amend and invoke prompts in os\n        '_SYSTEM_PYTHON_SKILL_AMEND_AND_INVOKE_PROMPT': '''\n        You are an expert in Python programming, with a focus on diagnosing and resolving code issues.\n        Your goal is to precisely identify the reasons for failure in the existing Python code and implement effective modifications to ensure it accomplishes the intended task without errors.\n        You should only respond with a python code and a function call.\n        Python code in the format as described below:\n        1. Error Analysis: Conduct a step-by-step analysis to identify why the code is generating errors or failing to complete the task. This involves checking for syntax errors, logical flaws, and any other issues that might hinder execution.\n        2. Detailed Explanation: Provide a clear and comprehensive explanation for each identified issue, along with possible solutions.\n        3. Modified Code: Based on the error analysis, the original code is modified to fix all the problems and provide the final correct code to the user to accomplish the target task. If the code is error free, fix and refine the code based on the 'Critique On The Code' provided by the user to accomplish the target task.\n        function call in the format as described below:\n        1. Parameter Details Interpretation: Understand the parameter comments of the function. This will help select the correct parameters to fill in the function call.\n        2. Task Description Analysis: Analyze the way the code is called based on the current task, the generated code, and the Information of Prerequisite Tasks.\n        3. Generating function call: Construct the function call statement based on the analysis results above.\n        4. Output Format: The final output should include the function call, which must be enclosed in <invoke></invoke> tags. For example, <invoke>function()</invoke>.     \n\n        And the code you write should also follow the following criteria:\n        1. You must keep the original function name.\n        2. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        3. The python code must be enclosed between ```python and ```.\n        4. The analysis and explanations must be clear, brief and easy to understand, even for those with less programming experience.\n        5. All modifications must address the specific issues identified in the error analysis.\n        6. The solution must enable the code to successfully complete the intended task without errors.\n        7. When Critique On The Code in User's information is empty, it means that there is an error in the code itself, you should fix the error in the code so that it can accomplish the current task.\n\n        And the function call should also follow the following criteria:\n        1. The Python function call must be syntactically correct as per Python standards.\n        2. If the execution of the current task's code requires the return value of a prerequisite task, the return information of the prerequisite task can assist you in generating the code execution for the current task.\n        3. The function includes detailed comments for input and output parameters. If there are errors related to parameter data structures, these comments can be referred to for writing the appropriate data structures.\n        4. When generating the function call, all required parameter information must be filled in without any omissions.\n        5. The generated function call should be a single line and should not include any additional text or comments.  \n        ''',\n        '_USER_PYTHON_SKILL_AMEND_AND_INVOKE_PROMPT': '''\n        User's information are as follows:\n        Original Code: {original_code}\n        Task: {task}\n        Error Messages: {error}\n        Code Output: {code_output}\n        Current Working Directiory: {current_working_dir}\n        Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Critique On The Code: {critique}\n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Detailed description of user information:\n        1. 'Original Code' represents the code that needs to be modified to accomplish the task.\n        2. 'Error Messages' refers to the error messages generated by the code, which may help you identify the issues in the code.\n        3. 'Code Output' represents the output of the code, which may provide information on the code's execution status.\n        4. 'Working Directory' represents the root directory of the working directory, and 'Current Working Directory' represents the directory where the current task is located.    \n        5. 'Critique On The Code' refers to code modification suggestions given by other code experts and may be empty.\n        6. 'Information of Prerequisite Tasks' from User's information provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        \n        Note: Please output according to the output format specified in the system message.\n        ''',\n\n\n\n        # Task judge prompts in os\n        '_SYSTEM_TASK_JUDGE_PROMPT': '''\n        You are an program expert to verify code against a user's task requirements.\n        Your goal is to determine if the provided code accomplishes the user's specified task based on the feedback information, And score the code based on the degree of generalizability of the code.\n        You should only respond with a JSON result. \n        You must follow the analysis process and format requirements as follows:\n        1. Analyze the provided code: Examine the user's code to understand its functionality and structure.\n        2. Compare the code with the task description: Align the objectives stated in the user's task description with the capabilities of the code.\n        3. Evaluate the feedback information: Review the user's feedback, Includes 'Code Output', 'Code Error' and the working catalog information provided by user to measure the effectiveness of the code.\n        4. Formulate a reasoning process: Based on the analysis of the code and feedback received, generate a reasoning process about the execution of the code. If you believe the task has been successfully completed, you need to explain how the code accomplished the task. If you think the task has not been completed, you need to explain the reasons for the failure and provide corresponding solutions.\n        5. Evaluate task status: Based on the reasoning process, determine the status of the task. There are three possible statuses for a task:\n                Complete: The task has been successfully executed.\n                Amend: There are errors in the code, or the code does not meet the task requirements, necessitating fixes based on the reasoning process.\n                Replan: Errors encountered during code execution cannot be rectified by simply modifying the code, requiring additional operations within the code's execution environment. This necessitates new tasks to perform these extra operations.\n        6. Code's generality score: Evaluate the generality of the code and give code a score. The generality of the code can be analyzed based on parameters flexibility, error and exception handling, clarity of comments, code efficiency, security aspects, and other factors. According to the evaluation results, the code can be scored on a scale from 1 to 10, with integers reflecting the code's generality. A score of 1-3 indicates that the code is not very generic and can only complete the current task. A score of 4-6 indicates that the code can efficiently complete similar tasks, but the parameter names are not generic enough. A score of 7-8 indicates that the code is sufficiently generic but lacks in terms of security, clarity of comments, and fault tolerance. A score of 9-10 indicates that the code is highly generic in all aspects.\n        7. Output Format: \n\n        ```json\n        {\n            reasoning: Your reasoning process,\n            status: Complete/Amend/Replan,\n            score: 1-10\n        }\n        ``` \n\n        And you should also follow the following criteria:\n        1. Provide clear, logical reasoning.\n        2. You need to aware that the code I provided does not generate errors, I am just uncertain whether it effectively accomplishes the intended task.\n        3. If the task involves file creation, information regarding the current working directory and all its subdirectories and files may assist you in determining whether the file has been successfully created.\n        4. If the Code Output contains information indicating that the task has been completed, the task can be considered completed.    \n        5. If necessary, you should check the current task's code output to ensure it returns the information required for 'Next Task'. If it does not, then the current task can be considered incomplete.\n        6. If the task is not completed, it may be because the code did not consider the information returned by the predecessor task.\n        7. The JSON response must be enclosed between ```json and ```.\n        ''',\n        '_USER_TASK_JUDGE_PROMPT': '''\n        User's information are as follows:\n        Current Code: {current_code}\n        Task: {task}\n        Code Output: {code_output}\n        Code Error: {code_error}\n        Current Working Directiory: {current_working_dir}\n        Working Directory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Next Task: {next_action}\n        Detailed description of user information:\n        1. 'Working Directory' represents the root directory of the working directory.\n        2. 'Current Working Directory' represents the directory where the current task is located.    \n        3. 'Code Output' represents the output of the code execution, which may be empty.\n        4. 'Code Error' represents any error messages generated during code execution, which may also be empty.\n        5. 'Next Task' describes tasks that follow the current task and may depend on the return from the current task. \n\n        Note: Please output according to the output format specified in the system message.\n        ''',\n\n        # Tool usage prompts in os\n        '_SYSTEM_TOOL_USAGE_PROMPT': '''\n        You are a useful AI assistant capable of accessing APIs to complete user-specified tasks, according to API documentation, \n        by using the provided ToolRequestUtil tool. The API documentation is as follows: \n        {openapi_doc}\n        The user-specified task is as follows: \n        {tool_sub_task}\n        The context which can further help you to determine the params of the API is as follows:\n        {context}\n        You need to complete the code using the ToolRequestUtil tool to call the specified API and print the return value\n        of the api. \n        ToolRequestUtil is a utility class, and the parameters of its 'request' method are described as follows:\n        def request(self, api_path, method, params=None, content_type=None):\n            \"\"\"\n            :param api_path: the path of the API\n            :param method: get/post\n            :param params: the parameters of the API, can be None.You cannot pass files to 'params' parameter.All files should be passed to 'files' parameter. \n            :param files: files to be uploaded, can be None.Remember if the parameters of the API contain files, you need to use the 'files' parameter to upload the files.\n            :param content_type: the content_type of api, e.g., application/json, multipart/form-data, can be None\n            :return: the response from the API\n            \"\"\"\n        Please begin your code completion:\n        ''',\n        '_USER_TOOL_USAGE_PROMPT': '''\n        from oscopilot.tool_repository.manager.tool_request_util import ToolRequestUtil\n        tool_request_util = ToolRequestUtil()\n        # TODO: your code here\n        ''',\n\n        # QA prompts in os\n        '_SYSTEM_QA_PROMPT': '''\n        You are a helpful ai assistant that can answer the question with the help of the context provided by the user in a step by step manner. The full question may help you to solve the current question.\n        If you don't know how to answer the user's question, answer \"I don't know.\" instead of making up an answer. \n        And you should also follow the following criteria:\n        1. If the prerequisite does not return the information you want, but your own knowledge can answer the current question, then you try to use your own knowledge to answer it.\n        2. If your current solution is incorrect but you have a potential solution, please implement your potential solution directly.\n        3. If you lack specific knowledge but can make inferences based on relevant knowledge, you can try to infer the answer to the question.\n        Now you will be provided with the following user information.\n        ''',\n        '_USER_QA_PROMPT': '''\n        Context: {context}\n        Full Question: {question} \n        Current Question: {current_question} \n        Detailed description of user information:\n        1. 'Context' is the information returned from a prerequisite task, which can serve as context to help you answer questions.\n        '''\n\n    },\n\n    'planning_prompt': {\n        # Task decompose prompts in os\n        '_SYSTEM_TASK_DECOMPOSE_PROMPT': '''\n        You are an expert at breaking down a task into subtasks.\n        I will give you a task and ask you to decompose this task into a series of subtasks. These subtasks can form a directed acyclic graph. Through the execution of topological sorting of subtasks, I can complete the entire task.\n        You can only return the reasoning process and the JSON that stores the subtasks information. \n        The content and format requirements for the reasoning process and subtasks information are as follows:\n        1. Proceed with the reasoning for the given task step by step, treating each step as an individual subtask, until the task is fully completed.\n        2. In JSON, each subtask is identified by a key that represents the name of the subtask. Every subtask is broken down into three attributes: 'description', 'dependencies', and 'type'. These attributes are determined through a reasoning process about the subtask.\n        3. Each subtask's name is abstracted from the reasoning process specific to that task and can serve as a generic label for a range of similar tasks. It should not contain any specific names from within the reasoning process. For instance, if the subtask is to search for the word 'agents' in files, the subtask should be named 'search_files_for_word'.\n        4. The three attributes for each subtask are described as follows:\n                description: The description of the current subtask corresponds to a certain step in task reasoning. \n                dependencies: This term refers to the list of names of subtasks that the current subtask depends upon, as determined by the reasoning process. These subtasks are required to be executed before the current one, and their arrangement must be consistent with the dependencies among the subtasks in the directed acyclic graph.\n                type: The task type of subtask, used to indicate in what form the subtask will be executed.\n        5. There are five types of subtasks:\n                Python: Python is suited for subtasks that involve complex data handling, analysis, machine learning, or the need to develop cross-platform scripts and applications. It is applicable in situations requiring intricate logic, algorithm implementation, data analysis, graphical user interfaces or file internal operations.\n                Shell: When the subtask primarily focuses on operating system-level automation, such as quick operations on the file system (creating, moving, deleting files), batch renaming files, system configuration, and monitoring and managing the operating system or system resources, Shell scripts are particularly suitable for quickly executing system-level batch processing tasks. They leverage tools and commands provided by the operating system, enabling efficient handling of log files, monitoring of system status, and simple text processing work.\n                AppleScript: AppleScript is primarily aimed at the macOS platform and is suitable for automating application operations on macOS, adjusting system settings, or implementing workflow automation between applications. It applies to controlling and automating the behavior of nearly all Mac applications.\n                API: API subtasks are necessary when interaction with external services or platforms is required, such as retrieving data, sending data, integrating third-party functionalities or services. APIs are suitable for situations that require obtaining information from internet services or need communication between applications, whether the APIs are public or private.\n                QA: QA subtasks are primarily about answering questions, providing information, or resolving queries, especially those that can be directly answered through knowledge retrieval or specific domain expertise. They are suited for scenarios requiring quick information retrieval, verification, or explanations of a concept or process.\n        6. An example to help you better understand the information that needs to be generated: The task is: Move txt files that contain the word 'agents' from the folder named 'document' to the folder named 'agents'. Then the reasoning process and JSON that stores the subtasks information are as follows: \n                Reasoning:\n                    According to 'Current Working Directiory' and Files And 'Folders in Current Working Directiory' information, the 'document' folder and 'agents' folder exist, therefore, there is no need to break down the subtasks to determine whether the folder exists.\n                    1. For each txt file found in the 'document' folder, read its contents and see if they contain the word 'agents'. Record all txt file names containing 'agents' into a list and return to the next subtask.\n                    2. Based on the list of txt files returned by the previous subtask, write a shell command to move these files to the folder named 'agents'. \n\n                ```json\n                {\n                    \"retrieve_files\" : {\n                        \"description\": \"For each txt file found in the 'document' folder, read its contents and see if they contain the word 'agents'. Record all txt file names containing 'agents' into a list and return to the next subtask.\",\n                        \"dependencies\": [],\n                        \"type\" : \"Python\"\n                    },\n                    \"organize_files\" : {\n                        \"description\": \"Based on the list of txt files returned by the previous subtask, write a shell command to move these files to the folder named 'agents'.\",\n                        \"dependencies\": [\"retrieve_files\"],\n                        \"type\": \"Shell\"\n                    }    \n                }      \n                ```  \n\n        And you should also follow the following criteria:\n        1. Try to break down the task into as few subtasks as possible.\n        2. Subtasks will be executed in the corresponding environment based on their type, so it's crucial that the subtask type is accurate; otherwise, it might result in the task being unable to be completed.\n        3. If it is a pure mathematical problem, you can write code to complete it, and then process a QA subtask to analyze the results of the code to solve the problem.\n        4. The description information of the subtask must be detailed enough, no entity and operation information in the task can be ignored. Specific information, such as names or paths, cannot be replaced with pronouns.\n        5. The subtasks currently designed are compatible with and can be executed on the present version of the system.\n        6. Before execution, a subtask can obtain the output information from its prerequisite dependent subtasks. Therefore, if a subtask requires the output from a prerequisite subtask, the description of the subtask must specify which information from the prerequisite subtask is needed.\n        7. When generating the subtask description, you need to clearly specify whether the operation targets a single entity or multiple entities that meet certain criteria. \n        8. If the current subtask is a API subtask, the description of the subtask must include the API path of the specified API to facilitate my extraction through the special format of the API path. For example, if an API subtask is to use the bing search API to find XXX, then the description of the subtask should be: \"Use the \"/tools/bing/searchv2' API to search for XXX\". \n        9. Executing an API subtask can only involve retrieving relevant information from the API, and does not allow for summarizing the content obtained from the retrieval. Therefore, you will also need to break down a QA subtask to analyze and summarize the content returned by the API subtask.\n        10. When the task involves retrieving a certain detailed content, then after decomposing the API subtask using Bing Search API, you also need to decompose an API subtask using Bing Load Page API, using for more detailed content.\n        11. Please be aware that only the APIs listed in the API List are available. Do not refer to or attempt to use APIs that are not included in this list.\n        12. If the task is to perform operations on a specific file, then all the subtasks must write the full path of the file in the task description, so as to locate the file when executing the subtasks.\n        13. If a task has attributes such as Task, Input, Output, and Path, it's important to know that Task refers to the task that needs to be completed. Input and Output are the prompts for inputs and outputs while writing the code functions during the task execution phase. Path is the file path that needs to be operated on.\n        14. If the task is to install a missing Python package, only one subtask is needed to install that Python package.\n        15. The JSON response must be enclosed between ```json and ```.\n        ''',\n        '_USER_TASK_DECOMPOSE_PROMPT': '''\n        User's information are as follows:\n        System Version: {system_version}\n        Task: {task}\n        Tool List: {tool_list}\n        API List: {api_list}\n        Current Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Detailed description of user information:\n        1. 'Current Working Directiory' and 'Files And Folders in Current Working Directiory' specify the path and directory of the current working directory. These information may help you understand and generate subtasks.\n        2. 'Tool List' contains the name of each tool and the corresponding operation description. These tools are previously accumulated for completing corresponding subtasks. If a subtask corresponds to the description of a certain tool, then the subtask name and the tool name are the same, to facilitate the call of the relevant tool when executing the subtask.\n        3. 'API List' that includes the API path and their corresponding descriptions. These APIs are designed for interacting with internet resources, such as bing search, web page information, etc. \n        \n        Note: Please output according to the output format specified in the system message.\n        ''',\n\n        # Task replan prompts in os\n        '_SYSTEM_TASK_REPLAN_PROMPT': '''\n        You are an expert at designing new tasks based on the results of your reasoning.\n        When I was executing the code of current task, an issue occurred that is not related to the code. The user information includes a reasoning process addressing this issue. Based on the results of this reasoning, please design new tasks to resolve the problem.     \n        You can only return the reasoning process and the JSON that stores the tasks information. \n        The content and format requirements for the reasoning process and tasks information are as follows:\n        1. Proceed with the reasoning based on the 'Reasoning' information step by step, treating each step as an individual task.\n        2. In JSON, each subtask is identified by a key that represents the name of the subtask. Every subtask is broken down into three attributes: 'description', 'dependencies', and 'type'. These attributes are determined through a reasoning process about the subtask.\n        3. Each subtask's name is abstracted from the reasoning process specific to that task and can serve as a generic label for a range of similar tasks. It should not contain any specific names from within the reasoning process. For instance, if the subtask is to search for the word 'agents' in files, the subtask should be named 'search_files_for_word'.\n        4. The three attributes for each task are described as follows:\n                description: The description of the current task corresponds to a certain step in task reasoning. \n                dependencies: This term refers to the list of names of task that the current task depends upon, as determined by the reasoning process. These tasks are required to be executed before the current one, and their arrangement must be consistent with the dependencies among the tasks.\n                type: The task type of task, used to indicate in what form the task will be executed.\n        5. There are five types of tasks:\n                Python: Python is suited for tasks that involve complex data handling, analysis, machine learning, or the need to develop cross-platform scripts and applications. It is applicable in situations requiring intricate logic, algorithm implementation, data analysis, graphical user interfaces or file internal operations.\n                Shell: When the task primarily focuses on operating system-level automation, such as quick operations on the file system (creating, moving, deleting files), batch renaming files, system configuration, and monitoring and managing the operating system or system resources, Shell scripts are particularly suitable for quickly executing system-level batch processing tasks. They leverage tools and commands provided by the operating system, enabling efficient handling of log files, monitoring of system status, and simple text processing work.\n                AppleScript: AppleScript is primarily aimed at the macOS platform and is suitable for automating application operations on macOS, adjusting system settings, or implementing workflow automation between applications. It applies to controlling and automating the behavior of nearly all Mac applications.\n                API: API tasks are necessary when interaction with external services or platforms is required, such as retrieving data, sending data, integrating third-party functionalities or services. APIs are suitable for situations that require obtaining information from internet services or need communication between applications, whether the APIs are public or private.\n                QA: QA tasks are primarily about answering questions, providing information, or resolving queries, especially those that can be directly answered through knowledge retrieval or specific domain expertise. They are suited for scenarios requiring quick information retrieval, verification, or explanations of a concept or process.\n        6. An example to help you better understand the information that needs to be generated: The reasoning process analyzed that the reason for the error was that there was no numpy package in the environments, causing it to fail to run. Then the reasoning process and JSON that stores the tasks information are as follows: \n                Reasoning:\n                    1. According to the reasoning process of error reporting, because there is no numpy package in the environments, we need to use the pip tool to install the numpy package.\n\n                ```json\n                {\n                    \"install_package\" : {\n                        \"description\": \"Use pip to install the numpy package that is missing in the environments.\",\n                        \"dependencies\": [],\n                        \"type\" : \"shell\"\n                    }\n                }\n                ```\n\n        And you should also follow the following criteria:\n        1. Try to design as few tasks as possible.\n        2. tasks will be executed in the corresponding environment based on their task type, so it's crucial that the task type is accurate; otherwise, it might result in the task being unable to be completed.\n        3. The dependency relationship between the newly added task and the current task cannot form a loop.\n        4. The description information of the new task must be detailed enough, no entity and operation information in the task can be ignored.\n        5. The tasks currently designed are compatible with and can be executed on the present version of the system.\n        6. Before execution, a task can obtain the output information from its prerequisite dependent tasks. Therefore, if a task requires the output from a prerequisite task, the description of the task must specify which information from the prerequisite task is needed.\n        7. The JSON response must be enclosed between ```json and ```.\n        ''',\n        '_USER_TASK_REPLAN_PROMPT': '''\n        User's information are as follows:\n        Current Task: {current_task}\n        Current Task Description: {current_task_description}\n        System Version: {system_version}\n        Reasoning: {reasoning}\n        Tool List: {tool_list}\n        Current Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Detailed description of user information:\n        1. 'Reasoning' indicates the reason why task execution failed and the corresponding solution, which can help you design new tasks.\n        2. 'Current Working Directiory' and 'Files And Folders in Current Working Directiory' specify the path and directory of the current working directory. These information may help you understand and generate tasks.\n        3. 'Tool List' contains the name of each tool and the corresponding operation description. These tools are previously accumulated for completing corresponding tasks. If a task corresponds to the description of a certain tool, then the task name and the tool name are the same, to facilitate the call of the relevant tool when executing the task.\n        \n        Note: Please output according to the output format specified in the system message.\n        ''',\n    },\n\n    'retrieve_prompt': {\n        # tool code filter prompts\n        '_SYSTEM_ACTION_CODE_FILTER_PROMPT': '''\n        You are an expert in analyzing python code.\n        I will assign you a task and provide a dictionary of tool names along with their corresponding codes. Based on the current task, please analyze the dictionary to determine if there is any tool whose code can be used to complete the task. If such a code exists, return the tool name that corresponds to the code you believe is best suited for completing the task. If no appropriate code exists, return an empty string.\n        You should only respond with the format as described below:\n        1. First, understand the requirements of the task. Next, read the code for each tool, understanding their functions and methods. Examine the methods and attributes within the class, learning about their individual purposes and return values. Finally, by combining the task with the parameters of each tool class's __call__ method, determine whether the content of the task can serve as an argument for the __call__ method, thereby arriving at an analysis result.\n        2. Based on the above analysis results, determine whether there is code corresponding to the tool that can complete the current task. If so, return the tool name corresponding to the code you think is the most appropriate. If not, return an empty string.\n        3. Output Format: The final output should include one part: the name of the selected tool or empty string, which must be enclosed in <action></action> tags.    \n        And you should also follow the following criteria:\n        1. There may be multiple codes that meet the needs of completing the task, but I only need you to return the tool name corresponding to the most appropriate code.\n        2. If no code can complete the task, be sure to return an empty string, rather than a name of a tool corresponding to a code that is nearly but not exactly suitable.\n        ''',\n        '_USER_ACTION_CODE_FILTER_PROMPT': '''\n        User's information are as follows:\n        Tool Code Pair: {tool_code_pair}\n        Task: {task_description}\n        ''',\n    },\n    \n    'self_learning_prompt' : {\n        # self learning prompt\n        '_SYSTEM_COURSE_DESIGN_PROMPT' : '''\n        You are an expert in designing a python course focused entirely on using a specific Python package to operate a particular software, each lesson in the course includes specific tasks for operating the software package, as well as prompts for program input and output. Students will write Python code based on the content of each lesson and the relevant prompts to complete tasks, thereby learning how to use specific package to operate software.\n        I'll furnish you with the software's name for your learning, the corresponding Python package necessary for its operation, and an example of course design. Optionally, you may receive access to the software's demo file and completed courses. Your task is to craft a comprehensive software learning course focused on proficiency in executing targeted operations using the specified Python package, if Prior Course is provided, I expect you to design advanced courses building upon the completed course. Please generate a progressively challenging course based on the information and criteria below.\n        Excel Course Design Example: To help you better design a course on related software, here I provide you with an example of a course design for learning to manipulate Excel files using openpyxl. Lesson 1, use openpyxl to read all the contents of sheet 'Sheet1' in demo.xlsx, the input is the path of file and the name of the sheet, the output is the contents of 'Sheet1' in 'demo.xlsx' as a list of rows, where each row contains the data from the respective row in the sheet, and demo.xlsx is located in 'working_dir/demo.xlsx'. Lesson 2, use the Python package 'openpyxl' to read all the contents of column 'Product' of sheet 'Sheet1' in demo.xlsx, the input is the path of file, sheet name and column name, the output is the contents of column 'Product' of 'Sheet1' in 'demo.xlsx' as a list, and demo.xlsx is located in 'working_dir/demo.xlsx'. Lesson 3, use openpyxl to insert a new sheet named 'new sheet' into demo.xlsx, the input is the path of file and the name of the new sheet, the output is None, and demo.xlsx is located in 'working_dir/demo.xlsx'. Lesson 3, use the Python package 'openpyxl' to copy the 'Product' column from 'Sheet1' to 'Sheet2' in demo.xlsx. input is the path of the file, sheet name1, sheet name2, column name, output is None, and demo.xlsx is located in 'working_dir/demo.xlsx'. Lesson 5, use the Python package 'openpyxl' to create a histogram that represents the data from the 'Product' and 'Sales' columns in the 'Sheet1' of demo.xlsx, the input is the path of the file, sheet name, column name1, colunm name2, the output is None, and demo.xlsx is located in 'working_dir/demo.xlsx'. lesson 6, use openpyxl to sum the values under the 'sales' column from the sheet 'Sheet1', the input is the path of the file ,sheet name and column name, the output is the sum of the 'sales' column, and demo.xlsx is located in 'working_dir/demo.xlsx'. \n        Note that only six lessons are listed here for demonstration purposes; you will need to design the course to include as many lessons as possible to comprehensively learn Python package manipulation in practice.\n        You should only respond with the format as described below:\n        1. Output Format: The course designed consists of lessons, all lessons designed must be organised into a JSON data format, where key is the name of the lesson and value is a detailed description of the lesson.\n        2. Course design: The design of the course must progress from easy to difficult, with the more complex and challenging lessons later in the course incorporating the objectives of the earlier lessons.\n        3. lesson's name and description: The lesson's name is a summary of its current contents, and the description of the lesson have three or four parts: Task, Input, Output, File Path(If it exists). Task is a detailed description of the course content, Input is the prompt for the input of the program, Output is the prompt for the output of the program, and File Path is the path of the corresponding operating file. \n        4. Continuing with the Excel Course Design Example, the format of the JSON data I want to get is as follows:\n        ```json\n        {\n            \"read_specified_sheet\" : \"Task: Use the Python package 'openpyxl' to read all the contents of sheet 'Sheet1' in demo.xlsx. Input: The path of file, sheet name. Output: return the contents of 'Sheet1' in 'demo.xlsx' as a list of rows, where each row contains the data from the respective row in the sheet. File Path: working_dir/demo.xlsx\",\n            \"read_specified_sheet_column\" : \"Task: Use the Python package 'openpyxl' to read all the contents of column 'Product' of sheet 'Sheet1' in demo.xlsx. Input: The path of file, sheet name and column name. Output: return the contents of column 'Product' of 'Sheet1' in 'demo.xlsx' as a list. File Path: working_dir/demo.xlsx\",        \n            \"insert_new_sheet\" : \"Task: Use the Python package 'openpyxl' to insert a new sheet named 'new sheet' into demo.xlsx. Input: The path of file and the name of the new sheet. Output: None. File Path: working_dir/demo.xlsx\",\n            \"copy_column_to_another_sheet\" : \"Task: Use the Python package 'openpyxl' to copy the 'Product' column from 'Sheet1' to 'Sheet2' in demo.xlsx. Input: The path of the file, sheet name1, sheet name2, column name. Output: None. File Path: working_dir/demo.xlsx\",\n            \"plot_histogram_from_sheet \" : \"Task: Use the Python package 'openpyxl' to create a histogram that represents the data from the 'Product' and 'Sales' columns in the 'Sheet1' of demo.xlsx. Input: The path of the file, sheet name, column name1, colunm name2. Output: None. File Path: working_dir/demo.xlsx\",\n            \"sum_column_values_in_sheet\" : \"Task: Use the Python package 'openpyxl' to sum the values under the 'Sales' column from the sheet 'Sheet1'. Input: The path of the file ,sheet name and column name. Output: The sum of the 'sales' column in 'Sheet1'. File Path: working_dir/demo.xlsx\"\n        }\n        ```\n        And you should also follow the following criteria:\n        1. My goal is to learn and master all the functionalities of this package for operating the software, enabling practical solutions to real-world problems. Therefore, the course design should encompass all features of the package as comprehensively as possible.\n        2. Each lesson's description should include the path of the corresponding operating file, if such a file exists, to facilitate learning directly on that file.\n        3. Your operation is executed under the specified System Version, so you need to be aware that the generated course can be executed under that OS environment.\n        4. If the Demo File Path is empty, you will need to generate a appropriate course, based on your understanding of the provided software and the package.\n        5. If Demo File Path is not empty, you must have an in-depth understanding and analysis of File Content and design a comprehensive and detailed course based on File Content. \n        6. Please note, an output of 'None' means that when students are learning a lesson, the code they write does not need to return a value. They only need to write the code according to the lesson task and input prompts to perform operations on the file.\n        7. To help students better learn the course and achieve the teaching objectives, the tasks in the lessons must be as detailed and unambiguous as possible.\n        8. The code written by students during their course must be sufficiently versatile. Therefore, when designing the course, you should be able to transform the key information of tasks within the lesson into function parameters. Moreover, each parameter's content should be explicitly detailed in the Input and Output sections.\n        9. Prior Course refers to the courses that have already been completed. If the Prior Course is not empty, you need to design new lessons based on the existing ones to learn more complex operations of the package, ensuring that these new lessons do not duplicate any lessons that are already in Prior Course.\n        10. The JSON response must be enclosed between ```json and ```.\n        ''',\n        '_USER_COURSE_DESIGN_PROMPT' : '''\n        User's information are as follows:\n        Software Name: {software_name}\n        Python Package Name: {package_name}\n        Demo File Path: {demo_file_path} \n        File Content: {file_content}\n        Prior Course: {prior_course}\n        System Version: {system_version}\n        ''',       \n\n    },\n\n    'text_extract_prompt' : '''\n        Please return all the contents of the file. \n        File Path: {file_path}\n        Tips: \n        1. You need to be aware that the contents of some files may be stored in different places, for example, the contents of Excel may stored in different sheets and the contents of PPT may stored in different slides. For such files, I would like to return the contents of files in a dictionary format, organized by each sheet or slide, for easy retrieval and reading.\n        2. You can only break down the task into one subtask. The subtask is for reading out all the contents of the file.\n        3. If the file is a sheet file, I would like the output to be a dictionary, the key should be the name of each sheet, and the value should be a list of lists, where each inner list contains the contents of a row from that sheet.\n        '''\n    \n}\n"}
{"type": "source_file", "path": "oscopilot/modules/base_module.py", "content": "import re\nimport json\nimport os\nfrom oscopilot.utils.llms import OpenAI, OLLAMA\n# from oscopilot.environments.py_env import PythonEnv\n# from oscopilot.environments.py_jupyter_env import PythonJupyterEnv\nfrom oscopilot.environments import Env\nfrom oscopilot.utils import get_os_version\nfrom dotenv import load_dotenv\n\nload_dotenv(dotenv_path='.env', override=True)\nMODEL_TYPE = os.getenv('MODEL_TYPE')\n\nclass BaseModule:\n    def __init__(self):\n        \"\"\"\n        Initializes a new instance of BaseModule with default values for its attributes.\n        \"\"\"\n        if MODEL_TYPE == \"OpenAI\":\n            self.llm = OpenAI()\n        elif MODEL_TYPE == \"OLLAMA\":\n            self.llm = OLLAMA()\n        # self.environment = PythonEnv()\n        # self.environment = PythonJupyterEnv()\n        self.environment = Env()\n        self.system_version = get_os_version()\n        \n    def extract_information(self, message, begin_str='[BEGIN]', end_str='[END]'):\n        \"\"\"\n        Extracts substrings from a message that are enclosed within specified begin and end markers.\n\n        Args:\n            message (str): The message from which information is to be extracted.\n            begin_str (str): The marker indicating the start of the information to be extracted.\n            end_str (str): The marker indicating the end of the information to be extracted.\n\n        Returns:\n            list[str]: A list of extracted substrings found between the begin and end markers.\n        \"\"\"\n        result = []\n        _begin = message.find(begin_str)\n        _end = message.find(end_str)\n        while not (_begin == -1 or _end == -1):\n            result.append(message[_begin + len(begin_str):_end].lstrip(\"\\n\"))\n            message = message[_end + len(end_str):]\n            _begin = message.find(begin_str)\n            _end = message.find(end_str)\n        return result  \n\n    def extract_json_from_string(self, text):\n        \"\"\"\n        Identifies and extracts JSON data embedded within a given string.\n\n        This method searches for JSON data within a string, specifically looking for\n        JSON blocks that are marked with ```json``` notation. It attempts to parse\n        and return the first JSON object found.\n\n        Args:\n            text (str): The text containing the JSON data to be extracted.\n\n        Returns:\n            dict: The parsed JSON data as a dictionary if successful.\n            str: An error message indicating a parsing error or that no JSON data was found.\n        \"\"\"\n        # Improved regular expression to find JSON data within a string\n        json_regex = r'```json\\n\\s*\\{\\n\\s*[\\s\\S\\n]*\\}\\n\\s*```'\n        \n        # Search for JSON data in the text\n        matches = re.findall(json_regex, text)\n\n        # Extract and parse the JSON data if found\n        if matches:\n            # Removing the ```json and ``` from the match to parse it as JSON\n            json_data = matches[0].replace('```json', '').replace('```', '').strip()\n            try:\n                # Parse the JSON data\n                parsed_json = json.loads(json_data)\n                return parsed_json\n            except json.JSONDecodeError as e:\n                return f\"Error parsing JSON data: {e}\"\n        else:\n            return \"No JSON data found in the string.\"\n        \n\n    def extract_list_from_string(self, text):\n        \"\"\"\n        Extracts a list of task descriptions from a given string containing enumerated tasks.\n        This function ensures that only text immediately following a numbered bullet is captured,\n        and it stops at the first newline character or at the next number, preventing the inclusion of subsequent non-numbered lines or empty lines.\n\n        Parameters:\n        text (str): A string containing multiple enumerated tasks. Each task is numbered and followed by its description.\n\n        Returns:\n        list[str]: A list of strings, each representing the description of a task extracted from the input string.\n        \"\"\"\n\n        # Regular expression pattern:\n        # \\d+\\. matches one or more digits followed by a dot, indicating the task number.\n        # \\s+ matches one or more whitespace characters after the dot.\n        # ([^\\n]*?) captures any sequence of characters except newlines (non-greedy) as the task description.\n        # (?=\\n\\d+\\.|\\n\\Z|\\n\\n) is a positive lookahead that matches a position followed by either a newline with digits and a dot (indicating the start of the next task),\n        # or the end of the string, or two consecutive newlines (indicating a break between tasks or end of content).\n        task_pattern = r'\\d+\\.\\s+([^\\n]*?)(?=\\n\\d+\\.|\\n\\Z|\\n\\n)'\n\n        # Use the re.findall function to search for all matches of the pattern in the input text.\n        data_list = re.findall(task_pattern, text)\n\n        # Return the list of matched task descriptions.\n        return data_list\n"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/bing/image_search_api.py", "content": "import requests\nfrom bs4 import BeautifulSoup\nfrom typing import Tuple\nfrom enum import Enum\n\nSEARCH_RESULT_LIST_CHUNK_SIZE = 3\nRESULT_TARGET_PAGE_PER_TEXT_COUNT = 500\n\n\nclass ImageSearchAPI:\n    def __init__(self, subscription_key: str) -> None:\n        self._headers = {\n            'Ocp-Apim-Subscription-Key': subscription_key,\n            'BingAPIs-Market': 'en-US',\n            \n        }\n        self._endpoint = \"https://api.bing.microsoft.com/v7.0/images/search\"\n        self._mkt = 'en-US'\n\n    def search_image(self, key_words: str,top_k: int=10, max_retry: int = 3):\n        \n        for _ in range(max_retry):\n            try:\n                result = requests.get(self._endpoint, headers=self._headers, params={'q': key_words, 'mkt': self._mkt,'safeSearch' : 'moderate'},\n                                      timeout=10)\n            except Exception:\n                continue\n            if result.status_code == 200:\n                result = result.json()\n                image_List = []\n                if result != None:\n                    image_List = [\n                        {\n                            \"imageName\": item[\"name\"],\n                            \"imageUrl\": item[\"thumbnailUrl\"],\n                            \"imageSize\": item[\"thumbnail\"]\n                        } for item in result[\"value\"]\n                    ]\n                    if(len(image_List) > top_k):\n                        image_List = image_List[:top_k]\n                return image_List\n            else:\n                continue\n        raise RuntimeError(\"Failed to access Bing Search API.\")\n \n"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/audio2text/__init__.py", "content": ""}
{"type": "source_file", "path": "oscopilot/prompts/__init__.py", "content": ""}
{"type": "source_file", "path": "oscopilot/environments/py_jupyter_env.py", "content": "# This code is based on Open Interpreter. Original source: https://github.com/OpenInterpreter/open-interpreter\n\nimport ast\nimport os\nimport sys\nimport queue\nimport re\nimport threading\nimport time\nimport traceback\nimport logging\n\nfrom jupyter_client import KernelManager\nfrom oscopilot.environments.base_env import BaseEnv\n\n\n# turn off colors in \"terminal\"\n# os.environ[\"ANSI_COLORS_DISABLED\"] = \"1\"\n\n\nclass PythonJupyterEnv(BaseEnv):\n    \"\"\"\n    A class representing an environment for executing Python code in a Jupyter environment.\n\n    This class manages the execution of Python code using IPython kernel, providing methods for preprocessing code,\n    executing code steps, handling output messages, and terminating the kernel.\n\n    It inherits from BaseEnv, which provides basic environment functionality.\n    \"\"\"    \n    file_extension = \"py\"\n    name = \"Python\"\n    aliases = [\"py\", \"API\"]\n\n    def __init__(self):\n        \"\"\"\n        Initializes the Python Jupyter environment.\n\n        This method sets up the IPython kernel manager and client, starts the kernel, and configures logging.\n        \"\"\"        \n        super().__init__()\n        ipkernel_logger = logging.getLogger('IPKernelApp')\n\n        # Create a filter using a lambda function\n        warning_filter = lambda record: not any(msg in record.getMessage() for msg in [\n            \"Parent appears to have exited, shutting down.\",\n            \"Could not destroy zmq context\"\n        ])\n        # Add the filter to the logger\n        ipkernel_logger.addFilter(warning_filter)\n\n        # Get the path to the current Python executable\n        python_executable = sys.executable\n        \n        # Ensure only one KernelManager instance is configured and started\n        self.km = KernelManager(kernel_name='python3', kernel_cmd=[python_executable, '-m', 'ipykernel_launcher', '-f', '{connection_file}'])\n        self.km.start_kernel(env=os.environ.copy())\n        # self.km.start_kernel()\n        self.kc = self.km.client()\n        self.kc.start_channels()\n        while not self.kc.is_alive():\n            time.sleep(0.1)\n        time.sleep(0.5)\n        '''\n        ipkernel_logger = logging.getLogger('IPKernelApp')\n        # Create a filter using a lambda function\n        warning_filter = lambda record: not any(msg in record.getMessage() for msg in [\n            \"Parent appears to have exited, shutting down.\",\n            \"Could not destroy zmq context\"\n        ])\n        # Add the filter to the logger\n        ipkernel_logger.addFilter(warning_filter)\n\n        # Get the path to the current Python executable\n        python_executable = sys.executable\n        \n        # Create a KernelManager instance using the current Python executable\n        self.km = KernelManager(kernel_name='python3', kernel_cmd=[python_executable, '-m', 'ipykernel_launcher', '-f', '{connection_file}'])\n        # self.km.start_kernel()\n        # self.kc = self.km.client()\n        # self.kc.start_channels()\n            \n        # self.km = KernelManager(kernel_name=\"python3\")\n        self.km.start_kernel()\n        self.kc = self.km.client()\n        self.kc.start_channels()\n        while not self.kc.is_alive():\n            time.sleep(0.1)\n        time.sleep(0.5)\n        '''\n        self.listener_thread = None\n        self.finish_flag = False\n\n        # DISABLED because sometimes this bypasses sending it up to us for some reason!\n        # Give it our same matplotlib backend\n        # backend = matplotlib.get_backend()\n\n#         # Use Agg, which bubbles everything up as an image.\n#         # Not perfect (I want interactive!) but it works.\n#         backend = \"Agg\"\n\n#         code = f\"\"\"\n# import matplotlib\n# matplotlib.use('{backend}')\n#         \"\"\".strip()\n#         for _ in self.run(code):\n#             pass\n\n        # DISABLED because it doesn't work??\n        # Disable color outputs in the terminal, which don't look good in OI and aren't useful\n        # code = \"\"\"\n        # from IPython.core.getipython import get_ipython\n        # get_ipython().colors = 'NoColor'\n        # \"\"\"\n        # self.run(code)\n\n    def terminate(self):\n        \"\"\"\n        Terminates the IPython kernel and stops its channels.\n        \"\"\"\n        self.kc.stop_channels()\n        self.km.shutdown_kernel()\n\n    def step(self, code):\n        \"\"\"\n        Executes a step of Python code.\n\n        Args:\n            code (str): The Python code to execute.\n\n        Yields:\n            dict: Output messages generated during execution.\n        \"\"\"        \n        # 解析python代码并且将函数体抽取出来存成字典，key是函数名，value是函数体，如果要存的话，就将每个函数存成一个py文件\n        # try:\n        #     functions = string_to_python(code)  # \n        # except:\n        #     # Non blocking\n        #     functions = {}\n\n        # if self.computer.save_skills and functions:\n        #     skill_library_path = self.computer.skills.path\n\n        #     if not os.path.exists(skill_library_path):\n        #         os.makedirs(skill_library_path)\n\n        #     for filename, function_code in functions.items():\n        #         with open(f\"{skill_library_path}/{filename}.py\", \"w\") as file:\n        #             file.write(function_code)\n\n        self.finish_flag = False\n        try:\n            try:\n                preprocessed_code = self.preprocess_code(code)\n            except:\n                # Any errors produced here are our fault.\n                # Also, for python, you don't need them! It's just for active_line and stuff. Just looks pretty.\n                preprocessed_code = code\n            message_queue = queue.Queue()\n            self._execute_code(preprocessed_code, message_queue)\n            yield from self._capture_output(message_queue)\n        except GeneratorExit:\n            raise  # gotta pass this up!\n        except:\n            content = traceback.format_exc()\n            yield {\"type\": \"console\", \"format\": \"output\", \"content\": content}\n\n    def _execute_code(self, code, message_queue):\n        \"\"\"\n        Executes Python code using the IPython kernel and captures the output messages.\n\n        Args:\n            code (str): The Python code to execute.\n            message_queue (queue.Queue): The message queue for storing output messages.\n        \"\"\"        \n        def iopub_message_listener():\n            '''\n            The main function of this function is to monitor the messages on the IOPub message channel of the IPython kernel and \n            process them accordingly according to the type of the message. The IOPub message channel is a channel in the Jupyter/IPython \n            system used to broadcast execution results, logs, errors, status updates and other information.            \n            '''\n            while True:\n                # If self.finish_flag = True, and we didn't set it (we do below), we need to stop. That's our \"stop\"\n                if self.finish_flag == True:\n                    self.km.interrupt_kernel()\n                    return\n                try:\n                    msg = self.kc.iopub_channel.get_msg(timeout=0.05)\n                except queue.Empty:\n                    continue\n\n                if (\n                    msg[\"header\"][\"msg_type\"] == \"status\"\n                    and msg[\"content\"][\"execution_state\"] == \"idle\"\n                ):\n                    # Set finish_flag and return when the kernel becomes idle\n\n                    self.finish_flag = True\n                    return\n\n                content = msg[\"content\"]\n\n                if msg[\"msg_type\"] == \"stream\":\n                    line, active_line = self.detect_active_line(content[\"text\"])\n                    if active_line:\n                        message_queue.put(\n                            {\n                                \"type\": \"console\",\n                                \"format\": \"active_line\",\n                                \"content\": active_line,\n                            }\n                        )\n                    message_queue.put(\n                        {\"type\": \"console\", \"format\": \"output\", \"content\": line}\n                    )\n                elif msg[\"msg_type\"] == \"error\":\n                    content = \"\\n\".join(content[\"traceback\"])\n                    # Remove color codes\n                    ansi_escape = re.compile(r\"\\x1B\\[[0-?]*[ -/]*[@-~]\")\n                    content = ansi_escape.sub(\"\", content)\n                    message_queue.put(\n                        {\n                            \"type\": \"console\",\n                            \"format\": \"output\",\n                            \"content\": content,\n                        }\n                    )\n                elif msg[\"msg_type\"] in [\"display_data\", \"execute_result\"]:\n                    data = content[\"data\"]\n                    if \"image/png\" in data:\n                        message_queue.put(\n                            {\n                                \"type\": \"image\",\n                                \"format\": \"base64.png\",\n                                \"content\": data[\"image/png\"],\n                            }\n                        )\n                    elif \"image/jpeg\" in data:\n                        message_queue.put(\n                            {\n                                \"type\": \"image\",\n                                \"format\": \"base64.jpeg\",\n                                \"content\": data[\"image/jpeg\"],\n                            }\n                        )\n                    elif \"text/html\" in data:\n                        message_queue.put(\n                            {\n                                \"type\": \"code\",\n                                \"format\": \"html\",\n                                \"content\": data[\"text/html\"],\n                            }\n                        )\n                    elif \"text/plain\" in data:\n                        message_queue.put(\n                            {\n                                \"type\": \"console\",\n                                \"format\": \"output\",\n                                \"content\": data[\"text/plain\"],\n                            }\n                        )\n                    elif \"application/javascript\" in data:\n                        message_queue.put(\n                            {\n                                \"type\": \"code\",\n                                \"format\": \"javascript\",\n                                \"content\": data[\"application/javascript\"],\n                            }\n                        )\n\n        self.listener_thread = threading.Thread(target=iopub_message_listener)\n        # self.listener_thread.daemon = True\n        self.listener_thread.start()\n\n        self.kc.execute(code)\n\n    def detect_active_line(self, line):\n        \"\"\"\n        Detects active line markers in the output line.\n\n        Args:\n            line (str): The output line from the IPython kernel.\n\n        Returns:\n            tuple: The modified line and active line number, if detected.\n        \"\"\"        \n        if \"##active_line\" in line:\n            # Split the line by \"##active_line\" and grab the last element\n            last_active_line = line.split(\"##active_line\")[-1]\n            # Split the last active line by \"##\" and grab the first element\n            active_line = int(last_active_line.split(\"##\")[0])\n            # Remove all ##active_line{number}##\\n\n            line = re.sub(r\"##active_line\\d+##\\n\", \"\", line)\n            return line, active_line\n        return line, None\n\n    def _capture_output(self, message_queue):\n        \"\"\"\n        Captures output messages from the message queue.\n\n        Args:\n            message_queue (queue.Queue): The message queue.\n\n        Yields:\n            dict: Output messages.\n        \"\"\"        \n        while True:\n            if self.listener_thread:\n                try:\n                    output = message_queue.get(timeout=0.1)\n                    yield output\n                except queue.Empty:\n                    if self.finish_flag:\n                        break\n            time.sleep(0.1)\n\n    def stop(self):\n        \"\"\"\n        Stops the execution of code by setting the finish flag.\n        \"\"\"        \n        self.finish_flag = True\n\n    def preprocess_code(self, code):\n        \"\"\"\n        Preprocesses the Python code before execution.\n\n        Args:\n            code (str): The Python code to preprocess.\n\n        Returns:\n            str: The preprocessed code.\n        \"\"\"\n        code = code.strip()\n\n        # Add print commands that tell us what the active line is\n        # but don't do this if any line starts with ! or %\n        if not any(line.strip().startswith((\"!\", \"%\")) for line in code.split(\"\\n\")):\n            code = add_active_line_prints(code)\n\n        # Wrap in a try except (DISABLED)\n        # code = wrap_in_try_except(code)\n\n        # Remove any whitespace lines, as this will break indented blocks\n        # (are we sure about this? test this)\n        code_lines = code.split(\"\\n\")\n        code_lines = [c for c in code_lines if c.strip() != \"\"]\n        code = \"\\n\".join(code_lines)\n\n        return code\n    \n\ndef add_active_line_prints(code):\n    \"\"\"\n    Adds print statements indicating line numbers to a Python string.\n\n    Args:\n        code (str): The Python code.\n\n    Returns:\n        str: The code with added print statements.\n    \"\"\"\n    # Replace newlines and comments with pass statements, so the line numbers are accurate (ast will remove them otherwise)\n    code_lines = code.split(\"\\n\")\n    in_multiline_string = False\n    for i in range(len(code_lines)):\n        line = code_lines[i]\n        if '\"\"\"' in line or \"'''\" in line:\n            in_multiline_string = not in_multiline_string\n        if not in_multiline_string and (line.strip().startswith(\"#\") or line == \"\"):\n            whitespace = len(line) - len(line.lstrip(\" \"))\n            code_lines[i] = \" \" * whitespace + \"pass\"\n    processed_code = \"\\n\".join(code_lines)\n    try:\n        tree = ast.parse(processed_code)\n    except:\n        # If you can't parse the processed version, try the unprocessed version before giving up\n        tree = ast.parse(code)\n    transformer = AddLinePrints()\n    new_tree = transformer.visit(tree)\n    return ast.unparse(new_tree)\n\n\nclass AddLinePrints(ast.NodeTransformer):\n    \"\"\"\n    Transformer to insert print statements indicating the line number\n    before every executable line in the AST.\n    \"\"\"\n\n    def insert_print_statement(self, line_number):\n        \"\"\"\n        Inserts a print statement for a given line number.\n\n        Args:\n            line_number (int): The line number.\n\n        Returns:\n            ast.Expr: The print statement AST node.\n        \"\"\"\n        return ast.Expr(\n            value=ast.Call(\n                func=ast.Name(id=\"print\", ctx=ast.Load()),\n                args=[ast.Constant(value=f\"##active_line{line_number}##\")],\n                keywords=[],\n            )\n        )\n\n    def process_body(self, body):\n        \"\"\"\n        Processes a block of statements, adding print calls.\n\n        Args:\n            body (list): List of AST nodes representing statements.\n\n        Returns:\n            list: List of modified AST nodes.\n        \"\"\"\n        new_body = []\n\n        # In case it's not iterable:\n        if not isinstance(body, list):\n            body = [body]\n\n        for sub_node in body:\n            if hasattr(sub_node, \"lineno\"):\n                new_body.append(self.insert_print_statement(sub_node.lineno))\n            new_body.append(sub_node)\n\n        return new_body\n\n    def visit(self, node):\n        \"\"\"\n        Visits and transforms nodes in the AST.\n\n        Args:\n            node: The current AST node.\n\n        Returns:\n            ast.Node: The modified AST node.\n        \"\"\"\n        new_node = super().visit(node)\n\n        # If node has a body, process it\n        if hasattr(new_node, \"body\"):\n            new_node.body = self.process_body(new_node.body)\n\n        # If node has an orelse block (like in for, while, if), process it\n        if hasattr(new_node, \"orelse\") and new_node.orelse:\n            new_node.orelse = self.process_body(new_node.orelse)\n\n        # Special case for Try nodes as they have multiple blocks\n        if isinstance(new_node, ast.Try):\n            for handler in new_node.handlers:\n                handler.body = self.process_body(handler.body)\n            if new_node.finalbody:\n                new_node.finalbody = self.process_body(new_node.finalbody)\n\n        return new_node\n\n\ndef wrap_in_try_except(code):\n    \"\"\"\n    Wraps Python code in a try-except block to catch exceptions.\n\n    Args:\n        code (str): The Python code.\n\n    Returns:\n        str: The code wrapped in a try-except block.\n    \"\"\"\n    code = \"import traceback\\n\" + code\n\n    # Parse the input code into an AST\n    parsed_code = ast.parse(code)\n\n    # Wrap the entire code's AST in a single try-except block\n    try_except = ast.Try(\n        body=parsed_code.body,\n        handlers=[\n            ast.ExceptHandler(\n                type=ast.Name(id=\"Exception\", ctx=ast.Load()),\n                name=None,\n                body=[\n                    ast.Expr(\n                        value=ast.Call(\n                            func=ast.Attribute(\n                                value=ast.Name(id=\"traceback\", ctx=ast.Load()),\n                                attr=\"print_exc\",\n                                ctx=ast.Load(),\n                            ),\n                            args=[],\n                            keywords=[],\n                        )\n                    ),\n                ],\n            )\n        ],\n        orelse=[],\n        finalbody=[],\n    )\n\n    # Assign the try-except block as the new body\n    parsed_code.body = [try_except]\n\n    # Convert the modified AST back to source code\n    return ast.unparse(parsed_code)\n\n\ndef string_to_python(code_as_string):\n    \"\"\"\n    Parses Python code from a string and extracts function definitions.\n\n    Args:\n        code_as_string (str): The Python code as a string.\n\n    Returns:\n        dict: A dictionary mapping function names to their code.\n    \"\"\"    \n    parsed_code = ast.parse(code_as_string)\n\n    # Initialize containers for different categories\n    import_statements = []\n    functions = []\n    functions_dict = {}\n\n    # Traverse the AST\n    for node in ast.walk(parsed_code):\n        # Check for import statements\n        if isinstance(node, ast.Import) or isinstance(node, ast.ImportFrom):\n            for alias in node.names:\n                # Handling the alias in import statements\n                if alias.asname:\n                    import_statements.append(f\"import {alias.name} as {alias.asname}\")\n                else:\n                    import_statements.append(f\"import {alias.name}\")\n        # Check for function definitions\n        elif isinstance(node, ast.FunctionDef):\n            if node.name.startswith(\"_\"):\n                # ignore private functions\n                continue\n            docstring = ast.get_docstring(node)\n            body = node.body\n            if docstring:\n                body = body[1:]\n\n            code_body = ast.unparse(body[0]).replace(\"\\n\", \"\\n    \")\n\n            func_info = {\n                \"name\": node.name,\n                \"docstring\": docstring,\n                \"body\": code_body,\n            }\n            functions.append(func_info)\n\n    for func in functions:\n        # Consolidating import statements and function definition\n        function_content = \"\\n\".join(import_statements) + \"\\n\\n\"\n        function_content += f\"def {func['name']}():\\n    \\\"\\\"\\\"{func['docstring']}\\\"\\\"\\\"\\n    {func['body']}\\n\"\n\n        # Adding to dictionary\n        functions_dict[func[\"name\"]] = function_content\n\n    return functions_dict\n\n\ndef main():\n    env = PythonJupyterEnv()\n    code = '''from oscopilot.tool_repository.basic_tools.base_action import BaseAction\nimport os\n\nclass create_folder(BaseAction):\n    def __init__(self):\n        self._description = \"Create a folder under the default working directory.\"\n\n    def __call__(self, working_directory=None, folder_name='myfold', *args, **kwargs):\n        \"\"\"\n        Create a folder under the specified working directory or the default working directory.\n\n        Args:\n        working_directory (str): The path of the working directory. If not provided, the default working directory will be used.\n        folder_name (str): The name of the folder to be created. Default is 'myfold'.\n\n        Returns:\n        None\n        \"\"\"\n        # Check if the working_directory is provided, if not, use the default working directory\n        if working_directory:\n            os.chdir(working_directory)\n\n        # Create the folder\n        os.makedirs(folder_name)\n\n# Example of how to use the class\ncreate_folder_action = create_folder()\ncreate_folder_action(working_directory='/Users/hanchengcheng/Documents/official_space/os-copilot-private/working_dir', folder_name='my_new_folder')\n'''\n    for _ in env.run(code):\n        print(_)\n\nif __name__ == '__main__':\n    main()"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/image_caption/__init__.py", "content": ""}
{"type": "source_file", "path": "oscopilot/modules/retriever/vector_retriever.py", "content": "from oscopilot.modules.base_module import BaseModule\nfrom oscopilot.utils.utils import send_chat_prompts\nimport json\n\n\nclass FridayRetriever(BaseModule):\n    \"\"\"\n    A modules within the system responsible for retrieving and managing available tools from the tool library.\n\n    The RetrievalModule extends the BaseModule class, focusing on the retrieval of tools\n    based on specific prompts or queries. It interacts with a language learning model (LLM)\n    and utilizes the execution environments and tool library to fulfill its responsibilities.\n    \"\"\"\n\n    def __init__(self, prompt, tool_manager):\n        super().__init__()\n        self.prompt = prompt\n        self.tool_manager = tool_manager\n\n    def delete_tool(self, tool):\n        \"\"\"\n        Deletes the specified tool from the tool library.\n\n        This method calls the tool library's delete method to remove an tool by its name. It\n        encompasses deleting the tool's code, description, parameters, and any other associated\n        information.\n\n        Args:\n            tool (str): The name of the tool to be deleted.\n        \"\"\"\n        self.tool_manager.delete_tool(tool)\n\n    def retrieve_tool_name(self, task, k=10):        \n        \"\"\"\n        Retrieves a list of tool names relevant to the specified task.\n\n        This method interacts with the tool library to retrieve names of tools that are most\n        relevant to a given task. The number of tool names returned is limited by the parameter k.\n\n        Args:\n            task (str): The task for which relevant tool names are to be retrieved.\n            k (int, optional): The maximum number of tool names to retrieve. Defaults to 10.\n\n        Returns:\n            list[str]: A list of the top k tool names relevant to the specified task.\n        \"\"\"\n        retrieve_tool_name = self.tool_manager.retrieve_tool_name(task, k)\n        return retrieve_tool_name\n\n    def tool_code_filter(self, tool_code_pair, task):\n        \"\"\"\n        Filters and retrieves the code for an tool relevant to the specified task.\n\n        This method formats a message for filtering tool codes based on a given task, sends\n        the message to the tool library for processing, and retrieves the filtered tool's\n        code. If an tool name is successfully identified, its corresponding code is fetched\n        from the tool library.\n\n        Args:\n            tool_code_pair (dict): A dictionary mapping tool names to their codes.\n            task (str): The task based on which the tool code needs to be filtered.\n\n        Returns:\n            The code of the tool relevant to the specified task, or an empty string\n            if no relevant tool is found.\n    \"\"\"\n        tool_code_pair = json.dumps(tool_code_pair)\n        sys_prompt = self.prompt['_SYSTEM_ACTION_CODE_FILTER_PROMPT']\n        user_prompt = self.prompt['_USER_ACTION_CODE_FILTER_PROMPT'].format(\n            task_description=task,\n            tool_code_pair=tool_code_pair\n        )\n        response = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        tool_name = self.extract_information(response, '<action>', '</action>')[0]\n        code = ''\n        if tool_name:\n            code = self.tool_manager.get_tool_code(tool_name)\n        return code\n\n    def retrieve_tool_description(self, tool_name):\n        \"\"\"\n        Retrieves the description for a specified tool from the tool library.\n\n        This method queries the tool library for the description of an tool identified\n        by its name. It is designed to fetch detailed descriptions that explain what the\n        tool does.\n\n        Args:\n            tool_name (str): The name of the tool whose description is to be retrieved.\n\n        Returns:\n            str: The description of the specified tool.\n        \"\"\"\n        retrieve_tool_description = self.tool_manager.retrieve_tool_description(tool_name)\n        return retrieve_tool_description  \n\n    def retrieve_tool_code(self, tool_name):\n        \"\"\"\n        Retrieves the code for a specified tool from the tool library.\n\n        This method accesses the tool library to get the executable code associated with\n        an tool identified by its name. This code defines how the tool is performed.\n\n        Args:\n            tool_name (str): The name of the tool whose code is to be retrieved.\n\n        Returns:\n            str: The code of the specified tool.\n        \"\"\"\n        retrieve_tool_code = self.tool_manager.retrieve_tool_code(tool_name)\n        return retrieve_tool_code \n    \n    def retrieve_tool_code_pair(self, retrieve_tool_name):\n        \"\"\"\n        Retrieves a mapping of tool names to their respective codes for a list of tools.\n\n        This method processes a list of tool names, retrieving the code for each and\n        compiling a dictionary that maps each tool name to its code. This is useful for\n        tasks that require both the identification and the execution details of tools.\n\n        Args:\n            retrieve_tool_name (list[str]): A list of tool names for which codes are to be retrieved.\n\n        Returns:\n            dict: A dictionary mapping each tool name to its code.\n        \"\"\"\n        retrieve_tool_code = self.retrieve_tool_code(retrieve_tool_name)\n        tool_code_pair = {}\n        for name, description in zip(retrieve_tool_name, retrieve_tool_code):\n            tool_code_pair[name] = description\n        return tool_code_pair        \n        \n    def retrieve_tool_description_pair(self, retrieve_tool_name):\n        \"\"\"\n        Retrieves a mapping of tool names to their descriptions for a list of tools.\n\n        By processing a list of tool names, this method fetches their descriptions and\n        forms a dictionary that associates each tool name with its description. This\n        facilitates understanding the purpose and functionality of multiple tools at once.\n\n        Args:\n            retrieve_tool_name (list[str]): A list of tool names for which descriptions are to be retrieved.\n\n        Returns:\n            dict: A dictionary mapping each tool name to its description.\n        \"\"\"\n        retrieve_tool_description = self.retrieve_tool_description(retrieve_tool_name)\n        tool_description_pair = {}\n        for name, description in zip(retrieve_tool_name, retrieve_tool_description):\n            tool_description_pair[name] = description\n        return tool_description_pair\n\n\n"}
{"type": "source_file", "path": "oscopilot/tool_repository/__init__.py", "content": "from .manager import *\nfrom .basic_tools import *"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/bing/bing_service.py", "content": "from fastapi import APIRouter, HTTPException\nfrom pydantic import BaseModel,Field\nfrom typing import Optional\n# from .bing_api import BingAPI\nfrom .bing_api_v2 import BingAPIV2\nfrom .image_search_api import ImageSearchAPI\nimport tiktoken\nimport os\nfrom dotenv import load_dotenv\n\n\nload_dotenv(dotenv_path='.env', override=True)\n\nBING_API = os.getenv('BING_SUBSCRIPTION_KEY')  # set bing API\n\n\n# Calculate the number of tokens in the webpage content for GPT-4. If there are too many tokens, use GPT-3.5 for summarization or search the vector database for the most relevant segment.\ndef num_tokens_from_string(string: str) -> int:\n    \"\"\"Returns the number of tokens in a text string.\"\"\"\n    encoding = tiktoken.encoding_for_model('gpt-4-1106-preview')\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n\nrouter = APIRouter()\n\n# bing_api = BingAPI(BING_API) \nbing_api_v2 = BingAPIV2()\nimage_search_api = ImageSearchAPI(BING_API) \n\n# class QueryItem(BaseModel):\n#     query: str\n\n# class PageItem(BaseModel):\n#     url: str\n\nclass QueryItemV2(BaseModel):\n    query: str\n    top_k: Optional[int] = Field(None)\nclass PageItemV2(BaseModel):\n    url: str\n    query: Optional[str] = Field(None)\n\n# @router.get(\"/tools/bing/search\")\n# async def bing_search(item: QueryItem):\n#     try:\n#         search_results = bing_api.search(item.query)\n#     except RuntimeError as e:\n#         raise HTTPException(status_code=500, detail=str(e))\n#     return search_results\n\n# @router.get(\"/tools/bing/load_page\")\n# async def load_page(item: PageItem):\n#     try:\n#         page_loaded, page_detail = bing_api.load_page(item.url)\n#     except RuntimeError as e:\n#         raise HTTPException(status_code=500, detail=str(e))\n#     if not page_loaded:\n#         raise HTTPException(status_code=500, detail=page_detail)\n#     return {\"page_content\": page_detail}\n\n@router.get(\"/tools/bing/image_search\", summary=\"Searches for images related to the provided keywords using the Bing Image Search API. It allows specifying the number of images to return (top_k) and retries the search up to a specified number of times (max_retry) in case of failures. The search is performed with a moderate safe search filter and is intended for use within an environments that requires image search capabilities. The function returns a list of images, including their names, URLs, and thumbnail information. If the search fails after the maximum number of retries, it raises a runtime error.\")\nasync def image_search(item: QueryItemV2):\n    try:\n        if item.top_k == None:\n            item.top_k = 10\n        search_results = image_search_api.search_image(item.query,item.top_k)\n    except RuntimeError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return search_results\n\n@router.get(\"/tools/bing/searchv2\", summary=\"Execute Bing Search - returns top web snippets related to the query. Avoid using complex filters like 'site:'. For detailed page content, further use the web browser tool.\")\nasync def bing_search_v2(item: QueryItemV2):\n    try:\n        if item.top_k == None:\n            item.top_k = 5\n        search_results = bing_api_v2.search(item.query,item.top_k)\n    except RuntimeError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return search_results\n\n@router.get(\"/tools/bing/load_pagev2\", summary=\"Web browser tool for detailed content retrieval and specific information extraction from a target URL.In the case of Wikipedia, the number of tokens on such pages is often too large to load the entire page, so the 'query' parameter must be given to perform a similarity query to find the most relevant pieces of content. The 'query' parameter should be assigned with your task description to find the most relevant content of the web page.It is important that your 'query' must retain enough details about the task, such as time, location, quantity, and other information, to ensure that the results obtained are accurate enough.\")\nasync def load_page_v2(item: PageItemV2):\n    result = {\"page_content\": \"\"}\n    try:\n        raw_page_content = bing_api_v2.load_page(item.url)\n        page_token_num = num_tokens_from_string(raw_page_content)\n        if(page_token_num <= 4096):\n            result = {\"page_content\": raw_page_content}\n        else:\n            if item.query == None:\n                summarized_page_content = bing_api_v2.summarize_loaded_page(raw_page_content)\n                result = {\"page_content\": summarized_page_content}\n            else:\n                attended_content = bing_api_v2.attended_loaded_page(raw_page_content,item.query)\n                result = {\"page_content\": attended_content}\n    except RuntimeError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return result"}
{"type": "source_file", "path": "oscopilot/modules/planner/friday_planner.py", "content": "from oscopilot.tool_repository.manager.action_node import ActionNode\nfrom collections import defaultdict, deque\nfrom oscopilot.modules.base_module import BaseModule\nfrom oscopilot.tool_repository.manager.tool_manager import get_open_api_description_pair\nfrom oscopilot.utils.utils import send_chat_prompts, api_exception_mechanism\nimport json\nimport sys\nimport logging\n\n\nclass FridayPlanner(BaseModule):\n    \"\"\"\n    A planning module responsible for decomposing complex tasks into manageable subtasks, replanning tasks based on new insights or failures, and managing the execution order of tasks. \n\n    The `FridayPlanner` uses a combination of tool descriptions, environmental state, and language learning models to dynamically create and adjust plans for task execution. It maintains a tool graph to manage task dependencies and execution order, ensuring that tasks are executed in a sequence that respects their interdependencies.\n    \"\"\"\n    def __init__(self, prompt):\n        super().__init__()\n        self.tool_num = 0\n        self.tool_node = {}\n        self.prompt = prompt\n        self.tool_graph = defaultdict(list)\n        self.sub_task_list = []\n\n    def reset_plan(self):\n        \"\"\"\n        Resets the tool graph and subtask list to their initial states.\n        \"\"\"\n        self.tool_num = 0\n        self.tool_node = {}\n        self.tool_graph = defaultdict(list)\n        self.sub_task_list = []\n\n    @api_exception_mechanism(max_retries=3)\n    def decompose_task(self, task, tool_description_pair):\n        \"\"\"\n        Decomposes a complex task into manageable subtasks and updates the tool graph.\n\n        This method takes a high-level task and an tool-description pair, and utilizes\n        the environments's current state to format and send a decomposition request to the\n        language learning model. It then parses the response to construct and update the\n        tool graph with the decomposed subtasks, followed by a topological sort to\n        determine the execution order.\n\n        Args:\n            task (str): The complex task to be decomposed.\n            tool_description_pair (dict): A dictionary mapping tool names to their descriptions.\n\n        Side Effects:\n            Updates the tool graph with the decomposed subtasks and reorders tools based on\n            dependencies through topological sorting.\n        \"\"\"\n        files_and_folders = self.environment.list_working_dir()\n        tool_description_pair = json.dumps(tool_description_pair)\n        api_list = get_open_api_description_pair()\n        sys_prompt = self.prompt['_SYSTEM_TASK_DECOMPOSE_PROMPT']\n        user_prompt = self.prompt['_USER_TASK_DECOMPOSE_PROMPT'].format(\n            system_version=self.system_version,\n            task=task,\n            tool_list = tool_description_pair,\n            api_list = api_list,\n            working_dir = self.environment.working_dir,\n            files_and_folders = files_and_folders\n        )\n        response = send_chat_prompts(sys_prompt, user_prompt, self.llm, prefix=\"Overall\")\n        decompose_json = self.extract_json_from_string(response)\n        # Building tool graph and topological ordering of tools\n        if decompose_json != 'No JSON data found in the string.':\n            self.create_tool_graph(decompose_json)\n            self.topological_sort()\n        else:\n            print(response)\n            print('No JSON data found in the string.')\n            sys.exit()\n\n    def replan_task(self, reasoning, current_task, relevant_tool_description_pair):\n        \"\"\"\n        Replans the current task by integrating new tools into the original tool graph.\n\n        Given the reasoning for replanning and the current task, this method generates a new\n        tool plan incorporating any relevant tools. It formats a replanning request, sends\n        it to the language learning model, and integrates the response (new tools) into the\n        existing tool graph. The graph is then updated to reflect the new dependencies and\n        re-sorted topologically.\n\n        Args:\n            reasoning (str): The reasoning or justification for replanning the task.\n            current_task (str): The identifier of the current task being replanned.\n            relevant_tool_description_pair (dict): A dictionary mapping relevant tool names to\n                                                    their descriptions for replanning.\n\n        Side Effects:\n            Modifies the tool graph to include new tools and updates the execution order\n            of tools within the graph.\n        \"\"\"\n        # current_task information\n        current_tool = self.tool_node[current_task]\n        current_task_description = current_tool.description\n        relevant_tool_description_pair = json.dumps(relevant_tool_description_pair)\n        files_and_folders = self.environment.list_working_dir()\n        sys_prompt = self.prompt['_SYSTEM_TASK_REPLAN_PROMPT']\n        user_prompt = self.prompt['_USER_TASK_REPLAN_PROMPT'].format(\n            current_task = current_task,\n            current_task_description = current_task_description,\n            system_version=self.system_version,\n            reasoning = reasoning,\n            tool_list = relevant_tool_description_pair,\n            working_dir = self.environment.working_dir,\n            files_and_folders = files_and_folders\n        )\n        response = send_chat_prompts(sys_prompt, user_prompt, self.llm)\n        new_tool = self.extract_json_from_string(response)\n        # add new tool to tool graph\n        self.add_new_tool(new_tool, current_task)\n        # update topological sort\n        self.topological_sort()\n\n    def update_tool(self, tool, return_val='', relevant_code=None, status=False, node_type='Code'):\n        \"\"\"\n        Updates the specified tool's node information within the tool graph.\n\n        This method allows updating an tool's return value, relevant code, execution status,\n        and node_type. It is particularly useful for modifying tools' details after their execution\n        or during the replanning phase.\n\n        Args:\n            tool (str): The tool identifier whose details are to be updated.\n            return_val (str, optional): The return value of the tool. Default is an empty string.\n            relevant_code (str, optional): Any relevant code associated with the tool. Default is None.\n            status (bool, optional): The execution status of the tool. Default is False.\n            node_type (str, optional): The node_type of the tool (e.g., 'Code'). Default is 'Code'.\n\n        Side Effects:\n            Updates the information of the specified tool node within the tool graph.\n        \"\"\"\n        if return_val:\n            if node_type=='Code':\n                return_val = self.extract_information(return_val, \"<return>\", \"</return>\")\n                print(\"************************<return>**************************\")\n                logging.info(return_val)\n                print(return_val)\n                print(\"************************</return>*************************\")  \n            if return_val != 'None':\n                self.tool_node[tool]._return_val = return_val\n        if relevant_code:\n            self.tool_node[tool]._relevant_code = relevant_code\n        self.tool_node[tool]._status = status\n\n    def get_tool_list(self, relevant_tool=None):\n        \"\"\"\n        Retrieves a list of all tools or a subset of relevant tools, including their names and descriptions.\n\n        This method fetches tool descriptions from the tool library. If a specific set of relevant tools\n        is provided, it filters the list to include only those tools. The resulting list (or the full list if\n        no relevant tools are specified) is then returned in JSON format.\n\n        Args:\n            relevant_tool (list, optional): A list of tool names to filter the returned tools by.\n                                            If None, all tools are included. Defaults to None.\n\n        Returns:\n            A JSON string representing a dictionary of tool names to their descriptions. \n            The dictionary includes either all tools from the library or only those specified as relevant.\n        \"\"\"\n        tool_dict = self.tool_manager.descriptions\n        if not relevant_tool:\n            return json.dumps(tool_dict)\n        relevant_tool_dict = {tool : description for tool ,description in tool_dict.items() if tool in relevant_tool}\n        relevant_tool_list = json.dumps(relevant_tool_dict)\n        return relevant_tool_list\n    \n    def create_tool_graph(self, decompose_json):\n        \"\"\"\n        Constructs an tool graph based on dependencies specified in the given JSON.\n\n        This method takes a JSON object containing task information and dependencies,\n        and constructs an tool graph. Each task is added as a node in the graph, with\n        directed edges representing task dependencies. The method updates the class's\n        internal structures to reflect this graph, including tool nodes and their\n        relationships, as well as the overall number of tools.\n\n        Args:\n            decompose_json (dict): A JSON object where each key is an tool name, and the value\n                                is a dictionary containing the tool's name, description,\n                                type, and dependencies.\n\n        Side Effects:\n            Modifies the internal state by updating `tool_num`, `tool_node`, and `tool_graph`\n            to reflect the newly created tool graph.\n        \"\"\"\n        for task_name, task_info in decompose_json.items():\n            self.tool_num += 1\n            task_description = task_info['description']\n            task_type = task_info['type']\n            task_dependencies = task_info['dependencies']\n            self.tool_node[task_name] = ActionNode(task_name, task_description, task_type)\n            self.tool_graph[task_name] = task_dependencies\n            for pre_tool in self.tool_graph[task_name]:\n                self.tool_node[pre_tool].next_action[task_name] = task_description\n    \n    def add_new_tool(self, new_task_json, current_task):\n        \"\"\"\n        Incorporates a new tool into the existing tool graph based on its dependencies.\n\n        This method processes a JSON object representing a new task, including its name,\n        description, type, and dependencies, and adds it to the tool graph. It also updates\n        the tool nodes to reflect this new addition. Finally, it appends the last new task\n        to the list of dependencies for the specified current task.\n\n        Args:\n            new_task_json (dict): A JSON object containing the new task's details.\n            current_task (str): The name of the current task to which the new task's dependencies will be added.\n\n        Side Effects:\n            Updates the tool graph and nodes to include the new tool and its dependencies.\n            Modifies the dependencies of the current task to include the new tool.\n        \"\"\"\n        for task_name, task_info in new_task_json.items():\n            self.tool_num += 1\n            task_description = task_info['description']\n            task_type = task_info['type']\n            task_dependencies = task_info['dependencies']\n            self.tool_node[task_name] = ActionNode(task_name, task_description, task_type)\n            self.tool_graph[task_name] = task_dependencies\n            for pre_tool in self.tool_graph[task_name]:\n                self.tool_node[pre_tool].next_action[task_name] = task_description           \n        last_new_task = list(new_task_json.keys())[-1]\n        self.tool_graph[current_task].append(last_new_task)\n\n    def topological_sort(self):\n        \"\"\"\n        Generates a topological sort of the tool graph to determine the execution order.\n\n        This method applies a topological sorting algorithm to the current tool graph, \n        considering the status of each tool. It aims to identify an order in which tools\n        can be executed based on their dependencies, ensuring that all prerequisites are met\n        before an tool is executed. The sorting algorithm accounts for tools that have not\n        yet been executed to avoid cycles and ensure a valid execution order.\n\n        Side Effects:\n            Populates `sub_task_list` with the sorted order of tools to be executed if a \n            topological sort is possible. Otherwise, it indicates a cycle detection.\n        \"\"\"\n        self.sub_task_list = []\n        graph = defaultdict(list)\n        for node, dependencies in self.tool_graph.items():\n            # If the current node has not been executed, put it in the dependency graph.\n            if not self.tool_node[node].status:\n                graph.setdefault(node, [])\n                for dependent in dependencies:\n                    # If the dependencies of the current node have not been executed, put them in the dependency graph.\n                    if not self.tool_node[dependent].status:\n                        graph[dependent].append(node)\n\n        in_degree = {node: 0 for node in graph}      \n        # Count in-degree for each node\n        for node in graph:\n            for dependent in graph[node]:\n                in_degree[dependent] += 1\n\n        # Initialize queue with nodes having in-degree 0\n        queue = deque([node for node in in_degree if in_degree[node] == 0])\n\n        # List to store the order of execution\n\n        while queue:\n            # Get one node with in-degree 0\n            current = queue.popleft()\n            self.sub_task_list.append(current)\n\n            # Decrease in-degree for all nodes dependent on current\n            for dependent in graph[current]:\n                in_degree[dependent] -= 1\n                if in_degree[dependent] == 0:\n                    queue.append(dependent)\n\n        # Check if topological sort is possible (i.e., no cycle)\n        if len(self.sub_task_list) == len(graph):\n            print(\"topological sort is possible\")\n        else:\n            return \"Cycle detected in the graph, topological sort not possible.\"\n        \n    def get_pre_tasks_info(self, current_task):\n        \"\"\"\n        Retrieves information about the prerequisite tasks for a given current task.\n\n        This method collects and formats details about all tasks that are prerequisites\n        for the specified current task. It extracts descriptions and return values for\n        each prerequisite task and compiles this information into a JSON string.\n\n        Args:\n            current_task (str): The name of the task for which prerequisite information is requested.\n\n        Returns:\n            A JSON string representing a dictionary, where each key is a prerequisite task's\n            name, and the value is a dictionary with the task's description and return value.\n        \"\"\"\n        pre_tasks_info = {}\n        for task in self.tool_graph[current_task]:\n            task_info = {\n                \"description\" : self.tool_node[task].description,\n                \"return_val\" : self.tool_node[task].return_val\n            }\n            pre_tasks_info[task] = task_info\n        pre_tasks_info = json.dumps(pre_tasks_info)\n        return pre_tasks_info\n\n\n"}
{"type": "source_file", "path": "oscopilot/environments/env.py", "content": "# This code is based on Open Interpreter. Original source: https://github.com/OpenInterpreter/open-interpreter\n\nfrom oscopilot.environments import BaseEnv\nfrom oscopilot.environments import AppleScript\nfrom oscopilot.environments import PythonJupyterEnv\nfrom oscopilot.environments import Shell\nfrom oscopilot.utils.schema import EnvState\nimport subprocess\n\n# Should this be renamed to OS or System?\n\n\nclass Env(BaseEnv):\n    \"\"\"\n    A class representing an environment for executing code in various languages.\n\n    This class manages the execution of code in different languages and provides methods for interacting with\n    those languages.\n\n    It inherits from BaseEnv, which provides basic environment functionality.\n    \"\"\"    \n    def __init__(self):\n        \"\"\"\n        Initializes the environment.\n\n        Sets up the supported languages and initializes the active languages dictionary.\n        \"\"\"        \n        super().__init__()\n        self.languages = [\n            PythonJupyterEnv,\n            Shell,\n            AppleScript,\n        ]\n        self._active_languages = {}\n\n    def get_language(self, language):\n        \"\"\"\n        Gets the language class based on the provided language name or alias.\n\n        Args:\n            language (str): The name or alias of the language.\n\n        Returns:\n            class: The language class corresponding to the provided name or alias, or None if not found.\n        \"\"\"        \n        # 输入planner的节点类型即可\n        for lang in self.languages:\n            if language.lower() == lang.name.lower() or (\n                hasattr(lang, \"aliases\") and language.lower() in (alias.lower() for alias in lang.aliases)\n            ):\n                return lang\n        return None\n\n    def step(self, language, code, stream=False, display=False):\n        \"\"\"\n        Executes a step of code in the specified language.\n\n        Args:\n            language (str): The name or alias of the language to execute the code in.\n            code (str): The code to execute.\n            stream (bool): Whether to stream the output as it becomes available.\n            display (bool): Whether to display the output.\n\n        Returns:\n            EnvState: The state after executing the code.\n        \"\"\"        \n        # 不用流式的话很简单，就是调一下lang的step就行了\n        state = EnvState(command=code)\n        lang = self.get_language(language)()  # 输入planner的节点类型即可\n        for output_line_dic in lang.step(code):\n            if output_line_dic['format'] == 'active_line' or output_line_dic['content'] in ['', '\\n']:\n                continue\n            content = output_line_dic['content']\n            if 'Traceback' in content:\n                state.error = (state.error or '') + content\n            else:\n                state.result += content\n        if lang.name == 'Python':\n            lang.terminate()\n        # for output_line_dic in lang.step(code):\n        #     if output_line_dic['format'] == 'active_line':\n        #         continue\n        #     content = output_line_dic['content']\n        #     if content != '' and content != '\\n':\n        #         if 'Traceback' in content:\n        #             state.error = (state.error or '') + content\n        #         else:\n        #             state.result += content\n        state.pwd = self.working_dir\n        state.ls = subprocess.run(['ls'], cwd=self.working_dir, capture_output=True, text=True).stdout\n        return state\n        \n        # if (\n        #     language == \"python\"\n        #     and self.computer.import_computer_api\n        #     and \"computer\" in code\n        # ):\n        #     if not self.computer._has_imported_computer_api:\n        #         self.computer._has_imported_computer_api = True\n        #         # Give it access to the computer via Python\n        #         self.computer.run(\n        #             language=\"python\",\n        #             code=\"import time\\nfrom interpreter import interpreter\\ncomputer = interpreter.computer\",  # We ask it to use time, so\n        #             display=self.computer.verbose,\n        #         )\n\n        if stream == False:\n            # If stream == False, *pull* from _streaming_run.\n            output_messages = []\n            for chunk in self._streaming_run(language, code, display=display):\n                if chunk.get(\"format\") != \"active_line\":\n                    # Should we append this to the last message, or make a new one?\n                    if (\n                        output_messages != []\n                        and output_messages[-1].get(\"type\") == chunk[\"type\"]\n                        and output_messages[-1].get(\"format\") == chunk[\"format\"]\n                    ):\n                        output_messages[-1][\"content\"] += chunk[\"content\"]\n                    else:\n                        output_messages.append(chunk)\n            return output_messages\n\n        elif stream == True:\n            # If stream == True, replace this with _streaming_run.\n            return self._streaming_run(language, code, display=display)\n\n    def _streaming_run(self, language, code, display=False):\n        \"\"\"\n        Executes code in the specified language and streams the output.\n\n        Args:\n            language (str): The name or alias of the language to execute the code in.\n            code (str): The code to execute.\n            display (bool): Whether to display the output.\n\n        Yields:\n            dict: Output chunks generated during execution.\n        \"\"\"        \n        if language not in self._active_languages:\n            # Get the language. Pass in self.computer *if it takes a single argument*\n            # but pass in nothing if not. This makes custom languages easier to add / understand.\n            lang_class = self.get_language(language)\n            if lang_class.__init__.__code__.co_argcount > 1:\n                self._active_languages[language] = lang_class(self.computer)\n            else:\n                self._active_languages[language] = lang_class()\n        try:\n            for chunk in self._active_languages[language].run(code):\n                # self.format_to_recipient can format some messages as having a certain recipient.\n                # Here we add that to the LMC messages:\n                if chunk[\"type\"] == \"console\" and chunk.get(\"format\") == \"output\":\n                    recipient, content = parse_for_recipient(chunk[\"content\"])\n                    if recipient:\n                        chunk[\"recipient\"] = recipient\n                        chunk[\"content\"] = content\n\n                    # Sometimes, we want to hide the traceback to preserve tokens.\n                    # (is this a good idea?)\n                    if \"@@@HIDE_TRACEBACK@@@\" in content:\n                        chunk[\"content\"] = (\n                            \"Stopping execution.\\n\\n\"\n                            + content.split(\"@@@HIDE_TRACEBACK@@@\")[-1].strip()\n                        )\n\n                yield chunk\n\n                # Print it also if display = True\n                if (\n                    display\n                    and chunk.get(\"format\") != \"active_line\"\n                    and chunk.get(\"content\")\n                ):\n                    print(chunk[\"content\"])\n\n        except GeneratorExit:\n            self.stop()\n\n    def stop(self):\n        \"\"\"\n        Stops the execution of all active languages.\n        \"\"\"        \n        for language in self._active_languages.values():\n            language.stop()\n\n    def terminate(self):\n        \"\"\"\n        Terminates all active language environments.\n        \"\"\"        \n        for language_name in list(self._active_languages.keys()):\n            language = self._active_languages[language_name]\n            if (\n                language\n            ):  # Not sure why this is None sometimes. We should look into this\n                language.terminate()\n            del self._active_languages[language_name]\n"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/image_caption/gpt4v_caption.py", "content": "from openai import OpenAI\n\nclass ImageCaptionTool:\n    def __init__(self) -> None:\n        self.client = OpenAI()\n    def caption(self,url,query=\"What's in this Image?\"):\n        response = self.client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        messages=[\n            {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": query},\n                {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": url,\n                },\n                },\n            ],\n            }\n        ],\n        max_tokens=300,\n        )\n        return response.choices[0].message.content\n    \n\n# tool = ImageCaptionTool()\n# import base64\n# # Function to encode the image\n# def encode_image(image_path):\n#   with open(image_path, \"rb\") as image_file:\n#     return base64.b64encode(image_file.read()).decode('utf-8')\n# # Path to your image\n# image_path = \"birds.jpg\"\n\n# # Getting the base64 string\n# base64_image = encode_image(image_path)\n# res = tool.caption(url=f\"data:image/jpeg;base64,{base64_image}\")\n# print(res)"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/audio2text/audio2text_service.py", "content": "from fastapi import APIRouter, HTTPException, File, UploadFile,Depends\nfrom pydantic import BaseModel,Field\nfrom typing import Optional\nfrom .audio2text import Audio2TextTool\nimport io\nimport os\nimport shutil\nrouter = APIRouter()\n\nwhisper_api = Audio2TextTool()\n\n\nclass AudioTextQueryItem(BaseModel):\n    file: UploadFile = File(...)\n\n\n\n@router.post(\"/tools/audio2text\", summary=\"A tool that converts audio to natural language text.\")\nasync def audio2text(item: AudioTextQueryItem = Depends()):\n    try:\n        # Create a temporary file to save the uploaded audio.\n        with open(item.file.filename, \"wb\") as buffer:\n            shutil.copyfileobj(item.file.file, buffer)\n        with open(item.file.filename, \"rb\") as audio:\n            caption = whisper_api.caption(audio_file=audio)\n        # Clean up temporary files.\n        os.remove(item.file.filename)\n        return {\"text\": caption}\n    except RuntimeError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n"}
{"type": "source_file", "path": "oscopilot/prompts/friday2_pt.py", "content": "\"\"\"\nThis modules contains a comprehensive `prompts` dictionary that serves as a repository of prompts for guiding the AI agents's interactions across various operational scenarios, including execution, planning, and information retrieval tasks. These prompts are meticulously crafted to instruct the AI in performing its duties, ranging from code generation and amendment to task decomposition and planning, as well as error analysis and tool usage.\n\nThe dictionary is segmented into three main categories:\n\n1. **execute_prompt**: Contains prompts for execution-related tasks, such as code generation, invocation, amendment, and error judgment. These are further detailed for system actions and user interactions, facilitating a diverse range of programming and troubleshooting tasks.\n\n2. **planning_prompt**: Focuses on task planning and re-planning, decomposing complex tasks into manageable sub-tasks, and adapting plans based on unforeseen issues, ensuring that the AI can assist in project management and task organization effectively.\n\n3. **retrieve_prompt**: Dedicated to information retrieval, including filtering code snippets based on specific criteria, aiding the AI in sourcing and suggesting code solutions efficiently.\n\nEach category comprises system and user prompts, where system prompts define the AI's task or query in detail, and user prompts typically include placeholders for dynamic information insertion, reflecting the context or specific requirements of the task at hand.\n\nUsage:\nThe `prompts` dictionary is utilized by the AI agents to dynamically select appropriate prompts based on the current context or task, ensuring relevant and precise guidance for each operation. This dynamic approach allows the AI to adapt its interactions and responses to suit a wide array of programming and operational needs, enhancing its utility and effectiveness in assisting users.\n\nExample:\n    .. code-block:: python\n\n        # Accessing a specific prompts for task execution\n        execute_prompt = prompts['execute_prompt']['_SYSTEM_SKILL_CREATE_AND_INVOKE_PROMPT']\n\"\"\"\nprompt = {\n    'execute_prompt': {\n        # shell/applescript generator\n        '_SYSTEM_SHELL_APPLESCRIPT_GENERATE_PROMPT': '''\n        You are a world-class programmer that can complete any task by executing code, your goal is to generate the corresponding code based on the type of code to complete the task.\n        You could only respond with a code.\n        Shell code output Format:\n        ```shell\n        shell code\n        ```\n\n        AppleScript code output Format:\n        ```applescript\n        applescript code\n        ```        \n        ''',\n        '_USER_SHELL_APPLESCRIPT_GENERATE_PROMPT': '''\n        User's information is as follows:\n        System Version: {system_version}\n        System language: simplified chinese\n        Working Directory: {working_dir}\n        Task Name: {task_name}\n        Task Description: {task_description}     \n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Code Type: {Type}\n        Detailed description of user information:\n        1. 'Working Directory' represents the working directory. It may not necessarily be the same as the current working directory. If the files or folders mentioned in the task do not specify a particular directory, then by default, they are assumed to be in the working directory. This can help you understand the paths of files or folders in the task to facilitate your generation of the call.\n        2. 'Information of Prerequisite Tasks' provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        3, 'Code Type' represents the type of code to be generated.\n        ''',        \n\n\n        # Python generate and invoke prompts in os\n        '_SYSTEM_PYTHON_SKILL_AND_INVOKE_GENERATE_PROMPT': '''\n        You are a world-class programmer that can complete any task by executing code, your goal is to generate the function code that accomplishes the task, along with the function's invocation.\n        You could only respond with a python code and a invocation statement.\n        Output Format:\n        ```python\n        python code\n        ```\n        <invoke>invocation statement</invoke>\n\n        The code you write should follow the following criteria:\n        1. Function name should be the same as the 'Task Name' provided by the user.\n        2. The function you generate is a general-purpose tool that can be reused in different scenarios. Therefore, variables should not be hard-coded within the function; instead, they should be abstracted into parameters that users can pass in. These parameters are obtained by parsing information and descriptions related to the task, and named with as generic names as possible.\n        3. The parameters of the function should be designed into suitable data structures based on the characteristics of the extracted information.\n        4. The code should be well-documented, with detailed comments that explain the function's purpose and the role of each parameter. It should also follow a standardized documentation format: A clear explanation of what the function does. Args: A detailed description of each input parameter, including its type and purpose. Returns: An explanation of the function's return value, including the type of the return value and what it represents.\n        5. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        6. The function must have a return value. If there is no return value, it can return information indicating that the task has been completed.\n        7. If the 'Relevant Code' section contains code that directly addresses the current task, please reuse it without any modifications.\n        8. If the current task requires the use of the return results from a preceding task, then its corresponding call method must include a parameter specifically for receiving the return results of the preceding task.\n        9. If the current task depends on the results from a previous task, the function must include a parameter designed to accept the results from that previous task.\n        10. If the code involves the output of file paths, ensure that the output includes the files' absolute path.\n        11. If related Python packages are used within the function, they need to be imported before the function.\n\n        And the invocation statement should also follow the following criteria:\n        1. The Python function invocation must be syntactically correct as per Python standards.\n        2. Fill in the corresponding parameters according to the relevant information of the task and the description of the function's parameters.\n        3. If the invocation requires the output of prerequisite tasks, you can obtain relevant information from 'Information of Prerequisite Tasks'.\n\n        Now you will be provided with the following information, please write python code to accomplish the task and be compatible with system environments, versions and language according to these information.         \n        ''',\n        '_USER_PYTHON_SKILL_AND_INVOKE_GENERATE_PROMPT': '''\n        User's information is as follows:\n        System Version: {system_version}\n        System language: simplified chinese\n        Working Directory: {working_dir}\n        Task Name: {task_name}\n        Task Description: {task_description}     \n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Relevant Code: {relevant_code}\n        Detailed description of user information:\n        1. 'Working Directory' represents the working directory. It may not necessarily be the same as the current working directory. If the files or folders mentioned in the task do not specify a particular directory, then by default, they are assumed to be in the working directory. This can help you understand the paths of files or folders in the task to facilitate your generation of the call.\n        2. 'Information of Prerequisite Tasks' provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        3. 'Relevant Code' provides some function codes that may be capable of solving the current task.\n        ''',\n\n\n        # shell/applescript amend in os\n        '_SYSTEM_SHELL_APPLESCRIPT_AMEND_PROMPT': '''\n        You are an expert in programming, with a focus on diagnosing and resolving code issues.\n        Your goal is to precisely identify the reasons for failure in the existing code and implement effective modifications to ensure it accomplishes the intended task without errors.\n        You should only respond with a modified code.\n        Code in the format as described below:\n        1. Error Analysis: Conduct a step-by-step analysis to identify why the code is generating errors or failing to complete the task. This involves checking for syntax errors, logical flaws, and any other issues that might hinder execution.\n        2. Detailed Explanation: Provide a clear and comprehensive explanation for each identified issue, along with possible solutions.\n        3. Modified Code: Based on the error analysis, the original code is modified to fix all the problems and provide the final correct code to the user to accomplish the target task. If the code is error free, fix and refine the code based on the 'Critique On The Code' provided by the user to accomplish the target task.    \n\n        And the code you write should also follow the following criteria:\n        1. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        2. The code must be enclosed between ```[code type] and ```. For example, ```shell [shell code] ```.\n        3. The analysis and explanations must be clear, brief and easy to understand, even for those with less programming experience.\n        4. All modifications must address the specific issues identified in the error analysis.\n        5. The solution must enable the code to successfully complete the intended task without errors.\n        6. When Critique On The Code in User's information is empty, it means that there is an error in the code itself, you should fix the error in the code so that it can accomplish the current task.\n\n        Now you will be provided with the following information, please give your modified code according to these information:\n        ''',\n        '_USER_SHELL_APPLESCRIPT_AMEND_PROMPT': '''\n        User's information are as follows:\n        Original Code: {original_code}\n        Task: {task}\n        Error Messages: {error}\n        Code Output: {code_output}\n        Current Working Directiory: {current_working_dir}\n        Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Critique On The Code: {critique}\n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Detailed description of user information:\n        1. 'Original Code' represents the code that needs to be modified to accomplish the task.\n        2. 'Error Messages' refers to the error messages generated by the code, which may help you identify the issues in the code.\n        3. 'Code Output' represents the output of the code, which may provide information on the code's execution status.\n        4. 'Working Directory' represents the root directory of the working directory, and 'Current Working Directory' represents the directory where the current task is located.    \n        5. 'Critique On The Code' refers to code modification suggestions given by other code experts and may be empty.\n        6. 'Information of Prerequisite Tasks' from User's information provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        ''',\n\n\n        # Python amend and invoke prompts in os\n        '_SYSTEM_PYTHON_SKILL_AMEND_AND_INVOKE_PROMPT': '''\n        You are an expert in Python programming, with a focus on diagnosing and resolving code issues.\n        Your goal is to precisely identify the reasons for failure in the existing Python code and implement effective modifications to ensure it accomplishes the intended task without errors.\n        You should only respond with a python code and a invocation statement.\n        Python code in the format as described below:\n        1. Error Analysis: Conduct a step-by-step analysis to identify why the code is generating errors or failing to complete the task. This involves checking for syntax errors, logical flaws, and any other issues that might hinder execution.\n        2. Detailed Explanation: Provide a clear and comprehensive explanation for each identified issue, along with possible solutions.\n        3. Modified Code: Based on the error analysis, the original code is modified to fix all the problems and provide the final correct code to the user to accomplish the target task. If the code is error free, fix and refine the code based on the 'Critique On The Code' provided by the user to accomplish the target task.\n        invocation statement in the format as described below:\n        1. Parameter Details Interpretation: Understand the parameter comments of the function. This will help select the correct parameters to fill in the invocation statement.\n        2. Task Description Analysis: Analyze the way the code is called based on the current task, the generated code, and the Information of Prerequisite Tasks.\n        3. Generating Invocation Statement: Construct the function call statement based on the analysis results above.\n        4. Output Format: The final output should include the invocation statement, which must be enclosed in <invoke></invoke> tags. For example, <invoke>function()</invoke>.     \n\n        And the code you write should also follow the following criteria:\n        1. You must keep the original function name.\n        2. The code logic should be clear and highly readable, able to meet the requirements of the task.\n        3. The python code must be enclosed between ```python and ```.\n        4. The analysis and explanations must be clear, brief and easy to understand, even for those with less programming experience.\n        5. All modifications must address the specific issues identified in the error analysis.\n        6. The solution must enable the code to successfully complete the intended task without errors.\n        7. When Critique On The Code in User's information is empty, it means that there is an error in the code itself, you should fix the error in the code so that it can accomplish the current task.\n\n        And the invocation statement should also follow the following criteria:\n        1. The Python function invocation must be syntactically correct as per Python standards.\n        2. Clearly identify any fake or placeholder parameters used in the invocation.\n        3. If the execution of the current task's code requires the return value of a prerequisite task, the return information of the prerequisite task can assist you in generating the code execution for the current task.\n        4. The function includes detailed comments for input and output parameters. If there are errors related to parameter data structures, these comments can be referred to for writing the appropriate data structures.\n        5. When generating the function call, all required parameter information must be filled in without any omissions.\n        \n        Now you will be provided with the following information, please give your modified python code and invocation statement according to these information:\n        ''',\n        '_USER_PYTHON_SKILL_AMEND_AND_INVOKE_PROMPT': '''\n        User's information are as follows:\n        Original Code: {original_code}\n        Task: {task}\n        Error Messages: {error}\n        Code Output: {code_output}\n        Current Working Directiory: {current_working_dir}\n        Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Critique On The Code: {critique}\n        Information of Prerequisite Tasks: {pre_tasks_info}   \n        Detailed description of user information:\n        1. 'Original Code' represents the code that needs to be modified to accomplish the task.\n        2. 'Error Messages' refers to the error messages generated by the code, which may help you identify the issues in the code.\n        3. 'Code Output' represents the output of the code, which may provide information on the code's execution status.\n        4. 'Working Directory' represents the root directory of the working directory, and 'Current Working Directory' represents the directory where the current task is located.    \n        5. 'Critique On The Code' refers to code modification suggestions given by other code experts and may be empty.\n        6. 'Information of Prerequisite Tasks' from User's information provides relevant information about the prerequisite tasks for the current task, encapsulated in a dictionary format. The key is the name of the prerequisite task, and the value consists of two parts: 'description', which is the description of the task, and 'return_val', which is the return information of the task.\n        ''',\n\n\n\n        # Task judge prompts in os\n        '_SYSTEM_TASK_JUDGE_PROMPT': '''\n        You are an program expert to verify code against a user's task requirements.\n        Your goal is to determine if the provided code accomplishes the user's specified task based on the feedback information, And score the code based on the degree of generalizability of the code.\n        You should only respond with a JSON result. \n        You must follow the analysis process and format requirements as follows:\n        1. Analyze the provided code: Examine the user's code to understand its functionality and structure.\n        2. Compare the code with the task description: Align the objectives stated in the user's task description with the capabilities of the code.\n        3. Evaluate the feedback information: Review the user's feedback, Includes 'Code Output', 'Code Error' and the working catalog information provided by user to measure the effectiveness of the code.\n        4. Formulate a reasoning process: Based on the analysis of the code and feedback received, generate a reasoning process about the execution of the code. If you believe the task has been successfully completed, you need to explain how the code accomplished the task. If you think the task has not been completed, you need to explain the reasons for the failure and provide corresponding solutions.\n        5. Evaluate task status: Based on the reasoning process, determine the status of the task. There are three possible statuses for a task:\n                Complete: The task has been successfully executed.\n                Amend: There are errors in the code, or the code does not meet the task requirements, necessitating fixes based on the reasoning process.\n                Replan: Errors encountered during code execution cannot be rectified by simply modifying the code, requiring additional operations within the code's execution environment. This necessitates new tasks to perform these extra operations.\n        6. Code's generality score: Evaluate the generality of the code and give code a score. The generality of the code can be analyzed based on parameters flexibility, error and exception handling, clarity of comments, code efficiency, security aspects, and other factors. According to the evaluation results, the code can be scored on a scale from 1 to 10, with integers reflecting the code's generality. A score of 1-3 indicates that the code is not very generic and can only complete the current task. A score of 4-6 indicates that the code can efficiently complete similar tasks, but the parameter names are not generic enough. A score of 7-8 indicates that the code is sufficiently generic but lacks in terms of security, clarity of comments, and fault tolerance. A score of 9-10 indicates that the code is highly generic in all aspects.\n        7. Output Format: \n        ```json\n        {\n            reasoning: Your reasoning process,\n            status: Complete/Amend/Replan,\n            score: 1-10\n        }\n        ``` \n\n        And you should also follow the following criteria:\n        1. Provide clear, logical reasoning.\n        2. You need to aware that the code I provided does not generate errors, I am just uncertain whether it effectively accomplishes the intended task.\n        3. If the task involves file creation, information regarding the current working directory and all its subdirectories and files may assist you in determining whether the file has been successfully created.\n        4. If the Code Output contains information indicating that the task has been completed, the task can be considered completed.    \n        5. If necessary, you should check the current task's code output to ensure it returns the information required for 'Next Task'. If it does not, then the current task can be considered incomplete.\n        6. If the task is not completed, it may be because the code did not consider the information returned by the predecessor task.\n        Now you will be provided with the following information, please give the result JSON according to these information:\n        ''',\n        '_USER_TASK_JUDGE_PROMPT': '''\n        User's information are as follows:\n        Current Code: {current_code}\n        Task: {task}\n        Code Output: {code_output}\n        Code Error: {code_error}\n        Current Working Directiory: {current_working_dir}\n        Working Directory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Next Task: {next_action}\n        Detailed description of user information:\n        1. 'Working Directory' represents the root directory of the working directory.\n        2. 'Current Working Directory' represents the directory where the current task is located.    \n        3. 'Code Output' represents the output of the code execution, which may be empty.\n        4. 'Code Error' represents any error messages generated during code execution, which may also be empty.\n        5. 'Next Task' describes tasks that follow the current task and may depend on the return from the current task. \n\n        Note: Please output according to the output format specified in the system message.\n        ''',\n\n        # Tool usage prompts in os\n        '_SYSTEM_TOOL_USAGE_PROMPT': '''\n        You are a useful AI assistant capable of accessing APIs to complete user-specified tasks, according to API documentation, \n        by using the provided ToolRequestUtil tool. The API documentation is as follows: \n        {openapi_doc}\n        The user-specified task is as follows: \n        {tool_sub_task}\n        The context which can further help you to determine the params of the API is as follows:\n        {context}\n        You need to complete the code using the ToolRequestUtil tool to call the specified API and print the return value\n        of the api. \n        ToolRequestUtil is a utility class, and the parameters of its 'request' method are described as follows:\n        def request(self, api_path, method, params=None, content_type=None):\n            \"\"\"\n            :param api_path: the path of the API\n            :param method: get/post\n            :param params: the parameters of the API, can be None.You cannot pass files to 'params' parameter.All files should be passed to 'files' parameter. \n            :param files: files to be uploaded, can be None.Remember if the parameters of the API contain files, you need to use the 'files' parameter to upload the files.\n            :param content_type: the content_type of api, e.g., application/json, multipart/form-data, can be None\n            :return: the response from the API\n            \"\"\"\n        Please begin your code completion:\n        ''',\n        '_USER_TOOL_USAGE_PROMPT': '''\n        from oscopilot.tool_repository.manager.tool_request_util import ToolRequestUtil\n        tool_request_util = ToolRequestUtil()\n        # TODO: your code here\n        ''',\n\n        # QA prompts in os\n        '_SYSTEM_QA_PROMPT': '''\n        You are a helpful ai assistant that can answer the question with the help of the context provided by the user in a step by step manner. The full question may help you to solve the current question.\n        If you don't know how to answer the user's question, answer \"I don't know.\" instead of making up an answer. \n        And you should also follow the following criteria:\n        1. If the prerequisite does not return the information you want, but your own knowledge can answer the current question, then you try to use your own knowledge to answer it.\n        2. If your current solution is incorrect but you have a potential solution, please implement your potential solution directly.\n        3. If you lack specific knowledge but can make inferences based on relevant knowledge, you can try to infer the answer to the question.\n        Now you will be provided with the following user information:\n        ''',\n        '_USER_QA_PROMPT': '''\n        Context: {context}\n        Full Question: {question} \n        Current Question: {current_question} \n        Detailed description of user information:\n        1. 'Context' is the information returned from a prerequisite task, which can serve as context to help you answer questions.\n        '''\n\n    },\n\n    'planning_prompt': {\n        # Task decompose prompts in os\n        '_SYSTEM_TASK_DECOMPOSE_PROMPT': '''\n        You are an expert at breaking down a task into subtasks.\n        I will give you a task and ask you to decompose this task into a series of subtasks.\n\n        You should follow the following criteria:\n        1. Try to break down the task into as few subtasks as possible.\n        2. The description of each subtask must be detailed enough, no entity and operation information in the task can be ignored. Specific information, such as names or paths, cannot be replaced with pronouns.\n        3. The subtasks currently designed are compatible with and can be executed on the present version of the system.\n        \n        You can only provide me with a list of subtasks in order.\n        ''',\n        '_USER_TASK_DECOMPOSE_PROMPT': '''\n        User's information are as follows:\n        System Version: {system_version}\n        Task: {task}\n        Current Working Directiory: {working_dir}\n        ''',\n\n        # Task replan prompts in os\n        '_SYSTEM_TASK_REPLAN_PROMPT': '''\n        You are an expert at designing new tasks based on the results of your reasoning.\n        When I was executing the code of current task, an issue occurred that is not related to the code. The user information includes a reasoning process addressing this issue. Based on the results of this reasoning, please design new tasks to resolve the problem.     \n        You can only return the reasoning process and the JSON that stores the tasks information. \n        The content and format requirements for the reasoning process and tasks information are as follows:\n        1. Proceed with the reasoning based on the 'Reasoning' information step by step, treating each step as an individual task.\n        2. In JSON, each task contains four attributes: name, description, dependencies and type, which are obtained through reasoning about the task. The key of each task is the 'name' attribute of the task.\n        3. The four attributes for each task are described as follows:\n                name: The name of the task. This name is abstracted from the reasoning step corresponding to the current task and can summarize a series of similar tasks. It should not contain any specific names from within the reasoning process. For instance, if the task is to search for the word 'agents' in files, the task should be named 'search_files_for_word'.\n                description: The description of the current task corresponds to a certain step in task reasoning. \n                dependencies: This term refers to the list of names of task that the current task depends upon, as determined by the reasoning process. These tasks are required to be executed before the current one, and their arrangement must be consistent with the dependencies among the tasks.\n                type: The task type of task, used to indicate in what form the task will be executed.\n        4. There are five types of tasks:\n                Python: Python is suited for tasks that involve complex data handling, analysis, machine learning, or the need to develop cross-platform scripts and applications. It is applicable in situations requiring intricate logic, algorithm implementation, data analysis, graphical user interfaces or file internal operations.\n                Shell: When the task primarily focuses on operating system-level automation, such as quick operations on the file system (creating, moving, deleting files), batch renaming files, system configuration, and monitoring and managing the operating system or system resources, Shell scripts are particularly suitable for quickly executing system-level batch processing tasks. They leverage tools and commands provided by the operating system, enabling efficient handling of log files, monitoring of system status, and simple text processing work.\n                AppleScript: AppleScript is primarily aimed at the macOS platform and is suitable for automating application operations on macOS, adjusting system settings, or implementing workflow automation between applications. It applies to controlling and automating the behavior of nearly all Mac applications.\n                API: API tasks are necessary when interaction with external services or platforms is required, such as retrieving data, sending data, integrating third-party functionalities or services. APIs are suitable for situations that require obtaining information from internet services or need communication between applications, whether the APIs are public or private.\n                QA: QA tasks are primarily about answering questions, providing information, or resolving queries, especially those that can be directly answered through knowledge retrieval or specific domain expertise. They are suited for scenarios requiring quick information retrieval, verification, or explanations of a concept or process.\n        5. An example to help you better understand the information that needs to be generated: The reasoning process analyzed that the reason for the error was that there was no numpy package in the environments, causing it to fail to run. Then the reasoning process and JSON that stores the tasks information are as follows: \n                Reasoning:\n                    1. According to the reasoning process of error reporting, because there is no numpy package in the environments, we need to use the pip tool to install the numpy package.\n\n                ```json\n                {\n                    \"install_package\" : {\n                        \"name\": \"install_package\",\n                        \"description\": \"Use pip to install the numpy package that is missing in the environments.\",\n                        \"dependencies\": [],\n                        \"type\" : \"shell\"\n                    }\n                }\n                ```\n\n        And you should also follow the following criteria:\n        1. Try to design as few tasks as possible.\n        2. tasks will be executed in the corresponding environment based on their task type, so it's crucial that the task type is accurate; otherwise, it might result in the task being unable to be completed.\n        3. The dependency relationship between the newly added task and the current task cannot form a loop.\n        4. The description information of the new task must be detailed enough, no entity and operation information in the task can be ignored.\n        5. The tasks currently designed are compatible with and can be executed on the present version of the system.\n        6. Before execution, a task can obtain the output information from its prerequisite dependent tasks. Therefore, if a task requires the output from a prerequisite task, the description of the task must specify which information from the prerequisite task is needed.\n        \n        Now you will be provided with the following information, please give the reasoning process and the JSON that stores the tasks information according to these information:\n        ''',\n        '_USER_TASK_REPLAN_PROMPT': '''\n        User's information are as follows:\n        Current Task: {current_task}\n        Current Task Description: {current_task_description}\n        System Version: {system_version}\n        Reasoning: {reasoning}\n        Tool List: {tool_list}\n        Current Working Directiory: {working_dir}\n        Files And Folders in Current Working Directiory: {files_and_folders}\n        Detailed description of user information:\n        1. 'Reasoning' indicates the reason why task execution failed and the corresponding solution, which can help you design new tasks.\n        2. 'Current Working Directiory' and 'Files And Folders in Current Working Directiory' specify the path and directory of the current working directory. These information may help you understand and generate tasks.\n        3. 'Tool List' contains the name of each tool and the corresponding operation description. These tools are previously accumulated for completing corresponding tasks. If a task corresponds to the description of a certain tool, then the task name and the tool name are the same, to facilitate the invocation of the relevant tool when executing the task.\n        ''',\n    }\n    \n}\n"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/wolfram_alpha/wolfram_alpha.py", "content": "from fastapi import APIRouter\nimport wolframalpha\nfrom pydantic import BaseModel\nfrom typing import Optional\nimport os\nfrom dotenv import load_dotenv\n\n\nload_dotenv(dotenv_path='.env', override=True)\n\nWOLFRAMALPHA_APP_ID = os.getenv('WOLFRAMALPHA_APP_ID')\n\nclass QueryItem(BaseModel):\n    query: str\n\nrouter = APIRouter()\n\napp_id = WOLFRAMALPHA_APP_ID\nclient = wolframalpha.Client(app_id)\n\n@router.post(\"/tools/wolframalpha\")\nasync def wolframalpha_query(item: QueryItem):\n    res = client.query(item.query)\n\n    # Handle the query result\n    if res['@success'] == 'false':\n        return {\"result\": \"Query failed\"}\n    else:\n        # Return the first result text\n        result = next(res.results).text\n        return {\"result\": result}"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/bing/web_loader.py", "content": "import hashlib\nimport logging\nimport re\nimport requests\nimport pdfplumber\nfrom io import BytesIO\ntry:\n    from bs4 import BeautifulSoup\nexcept ImportError:\n    raise ImportError(\n        'Webpage requires extra dependencies. Install with `pip install --upgrade \"embedchain[dataloaders]\"`'\n    ) from None\n\n\n\ndef clean_string(text):\n    \"\"\"\n    This function takes in a string and performs a series of text cleaning operations.\n\n    Args:\n        text (str): The text to be cleaned. This is expected to be a string.\n\n    Returns:\n        cleaned_text (str): The cleaned text after all the cleaning operations\n        have been performed.\n    \"\"\"\n    # Replacement of newline characters:\n    text = text.replace(\"\\n\", \" \")\n\n    # Stripping and reducing multiple spaces to single:\n    cleaned_text = re.sub(r\"\\s+\", \" \", text.strip())\n\n    # Removing backslashes:\n    cleaned_text = cleaned_text.replace(\"\\\\\", \"\")\n\n    # Replacing hash characters:\n    cleaned_text = cleaned_text.replace(\"#\", \" \")\n\n    # Eliminating consecutive non-alphanumeric characters:\n    # This regex identifies consecutive non-alphanumeric characters (i.e., not\n    # a word character [a-zA-Z0-9_] and not a whitespace) in the string\n    # and replaces each group of such characters with a single occurrence of\n    # that character.\n    # For example, \"!!! hello !!!\" would become \"! hello !\".\n    cleaned_text = re.sub(r\"([^\\w\\s])\\1*\", r\"\\1\", cleaned_text)\n\n    return cleaned_text\n\n\n\nclass WebPageLoader:\n    # Shared session for all instances\n    _session = requests.Session()\n\n    def load_data(self, url):\n        \"\"\"Load data from a web page using a shared requests session.\"\"\"\n        headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML like Gecko) Chrome/52.0.2743.116 Safari/537.36'}\n        web_data = {}\n        content = \"\"\n        try:\n            response = self._session.get(url,headers=headers, timeout=30)\n            response.raise_for_status()\n            data = response.content\n            # Check content type\n            content_type = response.headers.get('Content-Type', '')\n            # print(content_type)\n            if 'html' in content_type:\n                content = self._get_clean_content(data, url)\n\n                \n            elif 'pdf' in content_type:\n                # Open the PDF file using pdfplumber\n                with pdfplumber.open(BytesIO(response.content)) as pdf:\n                    # Extract text from each page and combine it\n                    content = '\\n'.join([page.extract_text() for page in pdf.pages if page.extract_text()])\n                            \n            meta_data = {\"url\": url}\n\n            doc_id = hashlib.sha256((content + url).encode()).hexdigest()\n            web_data = {\n            \"doc_id\": doc_id,\n            \"data\": [\n                    {\n                        \"content\": content,\n                        \"meta_data\": meta_data,\n                    }\n                ],\n            }\n        except Exception:\n            web_data = {\n                \"data\": [\n                        {\n                            \"content\": \"\",\n                            \"meta_data\": \"\",\n                        }\n                    ],\n            }\n        return web_data\n\n    def _get_clean_content(self, html, url) -> str:\n        soup = BeautifulSoup(html, \"html.parser\")\n        original_size = len(str(soup.get_text()))\n\n        tags_to_exclude = [\n            \"nav\",\n            \"aside\",\n            \"form\",\n            \"header\",\n            \"noscript\",\n            \"svg\",\n            \"canvas\",\n            \"footer\",\n            \"script\",\n            \"style\",\n        ]\n        for tag in soup(tags_to_exclude):\n            tag.decompose()\n\n        ids_to_exclude = [\"sidebar\", \"main-navigation\", \"menu-main-menu\"]\n        for id in ids_to_exclude:\n            tags = soup.find_all(id=id)\n            for tag in tags:\n                tag.decompose()\n\n        classes_to_exclude = [\n            \"elementor-location-header\",\n            \"navbar-header\",\n            \"nav\",\n            \"header-sidebar-wrapper\",\n            \"blog-sidebar-wrapper\",\n            \"related-posts\",\n        ]\n        for class_name in classes_to_exclude:\n            tags = soup.find_all(class_=class_name)\n            for tag in tags:\n                tag.decompose()\n\n        content = soup.get_text()\n        content = clean_string(content)\n\n        cleaned_size = len(content)\n        if original_size != 0:\n            logging.info(\n                f\"[{url}] Cleaned page size: {cleaned_size} characters, down from {original_size} (shrunk: {original_size-cleaned_size} chars, {round((1-(cleaned_size/original_size)) * 100, 2)}%)\"  # noqa:E501\n            )\n\n        return content\n\n    @classmethod\n    def close_session(cls):\n        cls._session.close()\n\n\n"}
{"type": "source_file", "path": "oscopilot/tool_repository/api_tools/wolfram_alpha/__init__.py", "content": ""}
