{"repo_info": {"repo_name": "pyodmongo", "repo_owner": "mauro-andre", "repo_url": "https://github.com/mauro-andre/pyodmongo"}}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/conftest.py", "content": "import pytest\nfrom pyodmongo import AsyncDbEngine, DbEngine\nfrom datetime import timezone, timedelta\n\n\nmongo_uri = \"mongodb://localhost:27017\"\ndb_name = \"pyodmongo_pytest\"\ntz_info = timezone(timedelta(hours=-3))\n\n\n@pytest.fixture\ndef async_engine():\n    yield AsyncDbEngine(mongo_uri=mongo_uri, db_name=db_name, tz_info=tz_info)\n\n\n@pytest.fixture\ndef engine():\n    return DbEngine(mongo_uri=mongo_uri, db_name=db_name, tz_info=tz_info)\n"}
{"type": "test_file", "path": "tests/test_async_aggregate.py", "content": "from pyodmongo import DbModel, AsyncDbEngine, Id\nfrom typing import ClassVar\nimport pytest_asyncio\nimport pytest\n\n\nclass Customer(DbModel):\n    name: str\n    email: str\n    _collection: ClassVar = \"customers\"\n\n\nclass Order(DbModel):\n    customer: Customer | Id\n    value: float\n    _collection: ClassVar = \"orders\"\n\n\nclass OrdersByCustomers(DbModel):\n    count: int\n    total_value: float\n    _collection: ClassVar = \"orders\"\n    _pipeline: ClassVar = [\n        {\n            \"$group\": {\n                \"_id\": \"$customer\",\n                \"count\": {\"$count\": {}},\n                \"total_value\": {\"$sum\": \"$value\"},\n            }\n        }\n    ]\n\n\n@pytest_asyncio.fixture()\nasync def drop_collections(async_engine):\n    await async_engine._db[Customer._collection].drop()\n    await async_engine._db[Order._collection].drop()\n    yield\n    await async_engine._db[Customer._collection].drop()\n    await async_engine._db[Order._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_pipeline_aggregate(drop_collections, async_engine):\n    customer_1 = Customer(name=\"Customer 1\", email=\"customer1@email.com\")\n    customer_2 = Customer(name=\"Customer 2\", email=\"customer2@email.com\")\n    customer_3 = Customer(name=\"Customer 3\", email=\"customer3@email.com\")\n    await async_engine.save_all([customer_1, customer_2, customer_3])\n    for n in range(1, 11):\n        await async_engine.save(Order(customer=customer_1, value=n))\n    for n in range(1, 5):\n        await async_engine.save(Order(customer=customer_2, value=n))\n    for n in range(1, 8):\n        await async_engine.save(Order(customer=customer_3, value=n))\n\n    objs = await async_engine.find_many(Model=OrdersByCustomers)\n    customer_1_aggregate: OrdersByCustomers = list(\n        filter(lambda x: x.id == customer_1.id, objs)\n    )[0]\n    customer_2_aggregate: OrdersByCustomers = list(\n        filter(lambda x: x.id == customer_2.id, objs)\n    )[0]\n    customer_3_aggregate: OrdersByCustomers = list(\n        filter(lambda x: x.id == customer_3.id, objs)\n    )[0]\n\n    assert customer_1_aggregate.count == 10\n    assert customer_1_aggregate.total_value == 55\n    assert customer_2_aggregate.count == 4\n    assert customer_2_aggregate.total_value == 10\n    assert customer_3_aggregate.count == 7\n    assert customer_3_aggregate.total_value == 28\n"}
{"type": "test_file", "path": "tests/test_async_crud_db.py", "content": "from pyodmongo import (\n    AsyncDbEngine,\n    MainBaseModel,\n    DbModel,\n    MainBaseModel,\n    DbResponse,\n    ResponsePaginate,\n    Id,\n    Field,\n)\nfrom pyodmongo.queries import eq, gte, gt, mount_query_filter, sort, elem_match\nfrom pyodmongo.engines.utils import consolidate_dict\nfrom pydantic import ConfigDict\nfrom typing import ClassVar\nfrom bson import ObjectId\nfrom datetime import datetime, UTC, timezone, timedelta\nimport pytz\nimport pytest\nimport pytest_asyncio\n\n\nclass MyClass(DbModel):\n    attr1: str\n    attr2: str\n    random_number: int | None = None\n    _collection: ClassVar = \"my_class_test\"\n\n\n@pytest_asyncio.fixture()\nasync def drop_collection(async_engine):\n    await async_engine._db[MyClass._collection].drop()\n    yield MyClass(attr1=\"attr_1\", attr2=\"attr_2\")\n    await async_engine._db[MyClass._collection].drop()\n\n\n@pytest_asyncio.fixture()\nasync def create_100_docs_in_db(async_engine):\n    obj_list = []\n    for n in range(1, 101):\n        obj_list.append(MyClass(attr1=\"Value 1\", attr2=\"Value 2\", random_number=n))\n    await async_engine.save_all(obj_list)\n\n\n@pytest.fixture()\ndef new_obj():\n    yield MyClass(attr1=\"attr_1\", attr2=\"attr_2\")\n\n\n@pytest.mark.asyncio\nasync def test_check_if_create_a_new_doc_on_save(\n    drop_collection, new_obj, async_engine\n):\n    result: DbResponse = await async_engine.save(new_obj)\n    assert ObjectId.is_valid(result.upserted_ids[0])\n    assert new_obj.id == result.upserted_ids[0]\n    assert isinstance(new_obj.created_at, datetime)\n    assert isinstance(new_obj.updated_at, datetime)\n    assert new_obj.created_at == new_obj.updated_at\n\n\n@pytest.mark.asyncio\nasync def test_create_and_delete_one(drop_collection, new_obj, async_engine):\n    result: DbResponse = await async_engine.save(new_obj)\n    assert result.upserted_ids is not None\n    id = result.upserted_ids[0]\n    query = MyClass.id == id\n    result: DbResponse = await async_engine.delete(\n        Model=MyClass, query=query, delete_one=True\n    )\n    assert result.deleted_count == 1\n\n\n@pytest.mark.asyncio\nasync def test_find_one(drop_collection, new_obj, async_engine):\n    result: DbResponse = await async_engine.save(new_obj)\n    id_returned = result.upserted_ids[0]\n    obj_found = await async_engine.find_one(MyClass, eq(MyClass.id, id_returned))\n\n    assert isinstance(obj_found, MyClass)\n    assert obj_found.id == id_returned\n\n\n@pytest.fixture()\ndef objs():\n    objs = [\n        MyClass(attr1=\"attr_1\", attr2=\"attr_2\"),\n        MyClass(attr1=\"attr_1\", attr2=\"attr_2\"),\n        MyClass(attr1=\"attr_1\", attr2=\"attr_2\"),\n        MyClass(attr1=\"attr_3\", attr2=\"attr_4\"),\n        MyClass(attr1=\"attr_3\", attr2=\"attr_4\"),\n        MyClass(attr1=\"attr_5\", attr2=\"attr_6\"),\n    ]\n    return objs\n\n\n@pytest.mark.asyncio\nasync def test_save_all_created(drop_collection, objs, async_engine):\n    await async_engine.save_all(objs)\n    assert all([ObjectId.is_valid(obj.id) for obj in objs])\n\n\n@pytest.mark.asyncio\nasync def test_update_on_save(drop_collection, objs, async_engine):\n    await async_engine.save_all(objs)\n    obj = MyClass(attr1=\"value_1\", attr2=\"value_2\")\n    response: DbResponse = await async_engine.save(obj, eq(MyClass.attr1, \"attr_3\"))\n\n    assert response.matched_count == 2\n    assert response.modified_count == 2\n    assert response.upserted_ids == {}\n\n\n@pytest.mark.asyncio\nasync def test_delete(drop_collection, objs, async_engine):\n    await async_engine.save_all(objs)\n    response: DbResponse = await async_engine.delete(\n        MyClass, eq(MyClass.attr1, \"attr_1\")\n    )\n    assert response.deleted_count == 3\n\n\n@pytest.mark.asyncio\nasync def test_find_many_without_paginate(\n    drop_collection, create_100_docs_in_db, async_engine\n):\n    obj_list_50 = await async_engine.find_many(\n        Model=MyClass, query=MyClass.random_number > 50\n    )\n    obj_list_100 = await async_engine.find_many(\n        Model=MyClass, query=MyClass.random_number > 0\n    )\n    assert len(obj_list_50) == 50\n    assert len(obj_list_100) == 100\n    assert all(isinstance(obj, MyClass) for obj in obj_list_100)\n\n\n@pytest.mark.asyncio\nasync def test_find_many_with_paginate(\n    drop_collection, create_100_docs_in_db, async_engine\n):\n    response_paginate: ResponsePaginate = await async_engine.find_many(\n        Model=MyClass,\n        query=gt(MyClass.random_number, 50),\n        paginate=True,\n        docs_per_page=10,\n    )\n    assert isinstance(response_paginate, ResponsePaginate)\n    assert response_paginate.docs_quantity == 50\n    assert len(response_paginate.docs) == 10\n\n\n@pytest.mark.asyncio\nasync def test_with_query_and_raw_query_none(\n    drop_collection, create_100_docs_in_db, async_engine\n):\n    all_obj = await async_engine.find_many(Model=MyClass)\n    assert len(all_obj) == 100\n\n\n@pytest.mark.asyncio\nasync def test_field_alias(async_engine):\n    class MyClass(DbModel):\n        first_name: str = Field(alias=\"firstName\", default=None)\n        second_name: str = Field(alias=\"secondName\", default=None)\n        third_name: str = None\n        _collection: ClassVar = \"alias_test\"\n\n    await async_engine._db[MyClass._collection].drop()\n\n    obj = MyClass(\n        first_name=\"First Name\", second_name=\"Second Name\", third_name=\"Third Name\"\n    )\n    expected_dict = {\n        \"_id\": None,\n        \"created_at\": None,\n        \"firstName\": \"First Name\",\n        \"secondName\": \"Second Name\",\n        \"third_name\": \"Third Name\",\n        \"updated_at\": None,\n    }\n    dict_to_save = consolidate_dict(obj=obj, dct={}, populate=False)\n    assert dict_to_save == expected_dict\n    await async_engine.save(obj)\n    obj_found = await async_engine.find_one(Model=MyClass)\n    assert obj == obj_found\n    await async_engine._db[MyClass._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_fields_alias_generator(async_engine):\n    def to_camel(string: str) -> str:\n        return \"\".join(word.capitalize() for word in string.split(\"_\"))\n\n    def to_lower_camel(string: str) -> str:\n        words = string.split(\"_\")\n        return \"\".join(words[:1] + [word.capitalize() for word in words[1:]])\n\n    class MyClass(DbModel):\n        first_name: str = None\n        second_name: str = None\n        third_name: str = None\n        _collection: ClassVar = \"alias_test\"\n        model_config = ConfigDict(alias_generator=to_lower_camel)\n\n    await async_engine._db[MyClass._collection].drop()\n\n    obj = MyClass(\n        first_name=\"First Name\", second_name=\"Second Name\", third_name=\"Third Name\"\n    )\n    dict_to_save = consolidate_dict(obj=obj, dct={}, populate=False)\n    expected_dict = {\n        \"_id\": None,\n        \"createdAt\": None,\n        \"firstName\": \"First Name\",\n        \"secondName\": \"Second Name\",\n        \"thirdName\": \"Third Name\",\n        \"updatedAt\": None,\n    }\n    assert dict_to_save == expected_dict\n    await async_engine.save(obj)\n    obj_found = await async_engine.find_one(Model=MyClass)\n    assert obj == obj_found\n    await async_engine._db[MyClass._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_find_many_with_zero_results(drop_collection, async_engine):\n    await async_engine.save(obj=drop_collection)\n    result = await async_engine.find_many(\n        Model=MyClass, query=MyClass.attr1 == \"value_that_not_exists\", paginate=True\n    )\n\n    assert result.page_quantity == 0\n    assert result.docs_quantity == 0\n    assert result.docs == []\n\n\n@pytest.mark.asyncio\nasync def test_find_one_with_zero_results(drop_collection, async_engine):\n    await async_engine.save(obj=drop_collection)\n    result = await async_engine.find_one(\n        Model=MyClass, query=eq(MyClass.attr1, \"value_that_not_exists\")\n    )\n\n    assert result is None\n\n\n@pytest.mark.asyncio\nasync def test_delete_one_type_error_when_query_is_not_comparison_or_logical_operator(\n    async_engine,\n):\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        await async_engine.delete(Model=MyClass, query=\"string\", delete_one=True)\n\n\n@pytest.mark.asyncio\nasync def test_delete_type_error_when_query_is_not_comparison_or_logical_operator(\n    async_engine,\n):\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        await async_engine.delete(Model=MyClass, query=\"string\")\n\n\n@pytest.mark.asyncio\nasync def test_save_type_error_when_query_is_not_comparison_or_logical_operator(\n    drop_collection, async_engine\n):\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        await async_engine.save(obj=drop_collection, query=\"string\")\n\n\n@pytest.mark.asyncio\nasync def test_find_one_type_error_when_query_is_not_comparison_or_logical_operator(\n    async_engine,\n):\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        await async_engine.find_one(Model=MyClass, query=\"string\")\n\n\n@pytest.mark.asyncio\nasync def test_find_many_type_error_when_query_is_not_comparison_or_logical_operator(\n    async_engine,\n):\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        await async_engine.find_many(Model=MyClass, query=\"string\")\n\n\nclass MyModelRegex(DbModel):\n    attr_1: str\n    attr_2: str = \"Default value\"\n    _collection: ClassVar = \"my_model_regex\"\n\n\n@pytest_asyncio.fixture\nasync def create_regex_collection(async_engine: AsyncDbEngine):\n    await async_engine._db[MyModelRegex._collection].drop()\n    obj_list = [\n        MyModelRegex(attr_1=\"Agroindústria\"),\n        MyModelRegex(attr_1=\"Agro-indústria\"),\n        MyModelRegex(attr_1=\"indústria agro\"),\n        MyModelRegex(attr_1=\"indústriaagro\"),\n    ]\n    await async_engine.save_all(obj_list=obj_list)\n    yield\n    await async_engine._db[MyModelRegex._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_find_regex(create_regex_collection, async_engine: AsyncDbEngine):\n    input_dict = {\"attr_1_in\": \"['/^ind[uúû]stria/i']\"}\n    query, _ = mount_query_filter(\n        Model=MyModelRegex, items=input_dict, initial_comparison_operators=[]\n    )\n    results = await async_engine.find_many(Model=MyModelRegex, query=query)\n    assert len(results) == 2\n\n\nclass AsDict1(DbModel):\n    attr_1: str\n    attr_2: str\n    attr_3: str\n    _collection: ClassVar = \"as_dict_1\"\n\n\nclass AsDict11(DbModel):\n    attr_2: str\n    attr_3: str\n    _collection: ClassVar = \"as_dict_1\"\n\n\nclass AsDict2(DbModel):\n    attr_4: str\n    as_dict_1: list[AsDict1 | Id]\n    _collection: ClassVar = \"as_dict_2\"\n\n\nclass AsDict22(DbModel):\n    attr_4: str\n    as_dict_1: list[AsDict11 | Id]\n    _collection: ClassVar = \"as_dict_2\"\n\n\n@pytest_asyncio.fixture\nasync def create_as_dict_find_dict_collection(async_engine: AsyncDbEngine):\n    await async_engine._db[AsDict1._collection].drop()\n    await async_engine._db[AsDict2._collection].drop()\n    yield\n    await async_engine._db[AsDict1._collection].drop()\n    await async_engine._db[AsDict2._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_find_as_dict(\n    create_as_dict_find_dict_collection, async_engine: AsyncDbEngine\n):\n    obj1 = AsDict1(attr_1=\"Obj 1\", attr_2=\"Obj 1\", attr_3=\"Obj 1\")\n    obj2 = AsDict1(attr_1=\"Obj 2\", attr_2=\"Obj 2\", attr_3=\"Obj 2\")\n    obj3 = AsDict1(attr_1=\"Obj 3\", attr_2=\"Obj 3\", attr_3=\"Obj 3\")\n    obj4 = AsDict1(attr_1=\"Obj 4\", attr_2=\"Obj 4\", attr_3=\"Obj 4\")\n    obj5 = AsDict1(attr_1=\"Obj 5\", attr_2=\"Obj 5\", attr_3=\"Obj 5\")\n    obj6 = AsDict1(attr_1=\"Obj 6\", attr_2=\"Obj 6\", attr_3=\"Obj 6\")\n    obj7 = AsDict1(attr_1=\"Obj 7\", attr_2=\"Obj 7\", attr_3=\"Obj 7\")\n    obj8 = AsDict1(attr_1=\"Obj 8\", attr_2=\"Obj 8\", attr_3=\"Obj 8\")\n    await async_engine.save_all([obj1, obj2, obj3, obj4, obj5, obj6, obj7, obj8])\n    obj9 = AsDict2(attr_4=\"Obj 9\", as_dict_1=[obj1, obj2])\n    obj10 = AsDict2(attr_4=\"Obj 10\", as_dict_1=[obj3, obj4])\n    obj11 = AsDict2(attr_4=\"Obj 11\", as_dict_1=[obj5, obj6])\n    obj12 = AsDict2(attr_4=\"Obj 12\", as_dict_1=[obj7, obj8])\n    await async_engine.save_all([obj9, obj10, obj11, obj12])\n\n    obj_list = await async_engine.find_many(Model=AsDict22, as_dict=True, populate=True)\n    assert len(obj_list) == 4\n    assert type(obj_list) is list\n    for dct in obj_list:\n        assert type(dct) == dict\n    obj_dict = await async_engine.find_one(Model=AsDict2, as_dict=True, populate=True)\n    assert type(obj_dict) == dict\n\n\nclass A(DbModel):\n    a1: str = \"A\"\n    _collection: ClassVar = \"a\"\n\n\nclass B(DbModel):\n    b1: A | Id\n    _collection: ClassVar = \"b\"\n\n\nclass C(DbModel):\n    b1: A | Id\n    b2: list[B | Id]\n    _collection: ClassVar = \"c\"\n\n\nclass D(DbModel):\n    d1: list[C | Id]\n    _collection: ClassVar = \"d\"\n\n\n@pytest_asyncio.fixture\nasync def create_find_dict_collection(async_engine: AsyncDbEngine):\n    await async_engine._db[A._collection].drop()\n    await async_engine._db[B._collection].drop()\n    await async_engine._db[C._collection].drop()\n    await async_engine._db[D._collection].drop()\n    yield\n    await async_engine._db[A._collection].drop()\n    await async_engine._db[B._collection].drop()\n    await async_engine._db[C._collection].drop()\n    await async_engine._db[D._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_recursive_reference_pipeline(\n    create_find_dict_collection, async_engine: AsyncDbEngine\n):\n    a1 = A()\n    a2 = A()\n    a3 = A()\n    a4 = A()\n    a5 = A()\n    a6 = A()\n    await async_engine.save_all([a1, a2, a3, a4, a5, a6])\n    b1 = B(b1=a3)\n    b2 = B(b1=a4)\n    b3 = B(b1=a5)\n    b4 = B(b1=a6)\n    await async_engine.save_all([b1, b2, b3, b4])\n    c1 = C(b1=a1, b2=[b1, b2])\n    c2 = C(b1=a2, b2=[b3, b4])\n    await async_engine.save_all([c1, c2])\n    d1 = D(d1=[c1, c2])\n    await async_engine.save(d1)\n\n    d: D = await async_engine.find_one(Model=D, populate=True)\n\n    assert d.d1[0].b2[0].b1.a1 == \"A\"\n\n\nclass ClassA(DbModel):\n    attr_1: str = \"A String 1\"\n    attr_2: str = \"A String 2\"\n    _collection: ClassVar = \"col_a\"\n\n\nclass ClassB(DbModel):\n    attr_3: str = \"A String 3\"\n    a: ClassA | Id\n    _collection: ClassVar = \"col_b\"\n\n\n@pytest_asyncio.fixture()\nasync def drop_collections_a_b(async_engine: AsyncDbEngine):\n    await async_engine._db[ClassA._collection].drop()\n    await async_engine._db[ClassB._collection].drop()\n    yield\n    await async_engine._db[ClassA._collection].drop()\n    await async_engine._db[ClassB._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_find_nested_field_query(\n    drop_collections_a_b, async_engine: AsyncDbEngine\n):\n    obj_a = ClassA()\n    await async_engine.save(obj=obj_a)\n    obj_b = ClassB(a=obj_a)\n    await async_engine.save(obj=obj_b)\n    query = eq(ClassB.a, obj_a.id)\n    result = await async_engine.find_many(Model=ClassB, query=query, populate=True)\n    assert result == [obj_b]\n\n\n@pytest.mark.asyncio\nasync def test_find_nested_field_mount_query(\n    drop_collections_a_b, async_engine: AsyncDbEngine\n):\n    obj_a = ClassA()\n    await async_engine.save(obj=obj_a)\n    obj_b = ClassB(a=obj_a)\n    await async_engine.save(obj=obj_b)\n    input_dict = {\"a\": obj_a.id}\n    query, _ = mount_query_filter(\n        Model=ClassB, items=input_dict, initial_comparison_operators=[]\n    )\n    result = await async_engine.find_many(Model=ClassB, query=query, populate=True)\n    assert result == [obj_b]\n\n\nclass ClassOne(DbModel):\n    attr_1: str = \"attr 1\"\n    _collection: ClassVar = \"class_one\"\n\n\nclass ClassTwoA(MainBaseModel):\n    attr_2_a: str = \"attr 2 A\"\n    class_one: list[ClassOne | Id] | None\n\n\nclass ClassTwoB(MainBaseModel):\n    attr_2_b: str = \"attr 2 B\"\n    class_two_a: ClassTwoA | None\n    class_two_a_list: list[ClassTwoA] | None\n\n\nclass ClassThree(DbModel):\n    attr_3: str = \"attr 3\"\n    class_two_b: ClassTwoB | None\n    class_two_b_list: list[ClassTwoB] | None\n    _collection: ClassVar = \"class_three\"\n\n\n@pytest_asyncio.fixture()\nasync def drop_collections_one_three(async_engine: AsyncDbEngine):\n    await async_engine._db[ClassOne._collection].drop()\n    await async_engine._db[ClassThree._collection].drop()\n    yield\n    await async_engine._db[ClassOne._collection].drop()\n    await async_engine._db[ClassThree._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_nested_list_objects(\n    drop_collections_one_three, async_engine: AsyncDbEngine\n):\n    obj_1 = ClassOne(attr_1=\"obj_1\")\n    obj_2 = ClassOne(attr_1=\"obj_2\")\n    obj_3 = ClassOne(attr_1=\"obj_3\")\n    obj_4 = ClassOne(attr_1=\"obj_4\")\n    obj_5 = ClassOne(attr_1=\"obj_5\")\n    obj_6 = ClassOne(attr_1=\"obj_6\")\n    obj_7 = ClassOne(attr_1=\"obj_7\")\n    obj_8 = ClassOne(attr_1=\"obj_8\")\n    await async_engine.save_all(\n        [obj_1, obj_2, obj_3, obj_4, obj_5, obj_6, obj_7, obj_8]\n    )\n    obj_9 = ClassTwoA(attr_2_a=\"obj_9\", class_one=[obj_1, obj_2])\n    obj_10 = ClassTwoA(attr_2_a=\"obj_10\", class_one=[obj_3, obj_4])\n    obj_11 = ClassTwoA(attr_2_a=\"obj_11\", class_one=[obj_5, obj_6])\n    obj_12 = ClassTwoA(attr_2_a=\"obj_12\", class_one=[obj_7, obj_8])\n    obj_13 = ClassTwoB(\n        attr_2_b=\"obj_13\", class_two_a=obj_9, class_two_a_list=[obj_9, obj_10]\n    )\n    obj_14 = ClassTwoB(\n        attr_2_b=\"obj_14\", class_two_a=obj_11, class_two_a_list=[obj_11, obj_12]\n    )\n    obj_15 = ClassThree(\n        attr_3=\"obj_15\", class_two_b=obj_13, class_two_b_list=[obj_13, obj_14]\n    )\n    await async_engine.save(obj_15)\n    obj_found = await async_engine.find_one(Model=ClassThree, populate=True)\n    assert obj_found.id == obj_15.id\n    assert obj_found.class_two_b.attr_2_b == \"obj_13\"\n\n\nclass MySortClass(DbModel):\n    attr_1: str\n    attr_2: int\n    attr_3: datetime\n    _collection: ClassVar = \"my_class_to_sort\"\n\n\n@pytest_asyncio.fixture()\nasync def drop_collection_for_test_sort(async_engine: AsyncDbEngine):\n    await async_engine._db[MySortClass._collection].drop()\n    yield\n    await async_engine._db[MySortClass._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_sort_query(drop_collection_for_test_sort, async_engine: AsyncDbEngine):\n    obj_list = [\n        MySortClass(\n            attr_1=\"Juliet\",\n            attr_2=100,\n            attr_3=datetime(year=2023, month=1, day=20, tzinfo=UTC),\n        ),\n        MySortClass(\n            attr_1=\"Albert\",\n            attr_2=50,\n            attr_3=datetime(year=2025, month=1, day=20, tzinfo=UTC),\n        ),\n        MySortClass(\n            attr_1=\"Zack\",\n            attr_2=30,\n            attr_3=datetime(year=2020, month=1, day=20, tzinfo=UTC),\n        ),\n        MySortClass(\n            attr_1=\"Charlie\",\n            attr_2=150,\n            attr_3=datetime(year=2027, month=1, day=20, tzinfo=UTC),\n        ),\n        MySortClass(\n            attr_1=\"Albert\",\n            attr_2=40,\n            attr_3=datetime(year=2025, month=1, day=20, tzinfo=UTC),\n        ),\n    ]\n    await async_engine.save_all(obj_list=obj_list)\n    sort_oprator = sort((MySortClass.attr_1, 1), (MySortClass.attr_2, 1))\n    result_many = await async_engine.find_many(Model=MySortClass, sort=sort_oprator)\n    assert result_many[0] == obj_list[4]\n    assert result_many[1] == obj_list[1]\n\n    sort_oprator = sort((MySortClass.attr_3, 1))\n    result_one = await async_engine.find_one(Model=MySortClass, sort=sort_oprator)\n    assert result_one == obj_list[2]\n\n    sort_oprator = [\"attr_3\", 1]\n    with pytest.raises(\n        TypeError,\n        match='sort argument must be a SortOperator from pyodmongo.queries. If you really need to make a very specific sort, use \"raw_sort\" argument',\n    ):\n        result_one = await async_engine.find_one(Model=MySortClass, sort=sort_oprator)\n\n    with pytest.raises(\n        TypeError,\n        match='sort argument must be a SortOperator from pyodmongo.queries. If you really need to make a very specific sort, use \"raw_sort\" argument',\n    ):\n        result_many = await async_engine.find_many(Model=MySortClass, sort=sort_oprator)\n\n\nclass ClassWithDate(DbModel):\n    name: str\n    date: datetime\n    _collection: ClassVar = \"class_with_date\"\n\n\n@pytest_asyncio.fixture()\nasync def drop_collection_class_with_date(async_engine: AsyncDbEngine):\n    await async_engine._db[ClassWithDate._collection].drop()\n    yield\n    await async_engine._db[ClassWithDate._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_save_and_retrieve_objs_with_datetime(\n    drop_collection_class_with_date, async_engine: AsyncDbEngine\n):\n    tz = timezone(timedelta(hours=-3))\n    date = datetime(\n        year=2024,\n        month=4,\n        day=24,\n        hour=23,\n        minute=0,\n        second=0,\n        tzinfo=tz,\n    )\n    obj = ClassWithDate(name=\"A name\", date=date)\n    await async_engine.save(obj)\n    query = (ClassWithDate.date >= datetime(2024, 4, 24, 22, 30, 0, tzinfo=tz)) & (\n        ClassWithDate.date <= datetime(2024, 4, 24, 23, 30, 0, tzinfo=tz)\n    )\n    obj_found: ClassWithDate = await async_engine.find_one(\n        Model=ClassWithDate, query=query\n    )\n    assert obj_found.date == date\n\n\nclass ModelEmbedded(MainBaseModel):\n    attr_1: str\n    attr_2: str\n\n\nclass ModelMain(DbModel):\n    attr_3: list[ModelEmbedded]\n    _collection: ClassVar = \"model_elem_match\"\n\n\n@pytest_asyncio.fixture()\nasync def drop_collection_for_elem_match(async_engine: AsyncDbEngine):\n    await async_engine._db[ModelMain._collection].drop()\n    yield\n    await async_engine._db[ModelMain._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_elem_match_in_db(\n    drop_collection_for_elem_match, async_engine: AsyncDbEngine\n):\n    obj_embedded_0 = ModelEmbedded(attr_1=\"one\", attr_2=\"one\")\n    obj_embedded_1 = ModelEmbedded(attr_1=\"two\", attr_2=\"two\")\n    obj_embedded_2 = ModelEmbedded(attr_1=\"one\", attr_2=\"two\")\n    obj_embedded_3 = ModelEmbedded(attr_1=\"two\", attr_2=\"one\")\n\n    obj_db_0 = ModelMain(attr_3=[obj_embedded_0, obj_embedded_1])\n    obj_db_1 = ModelMain(attr_3=[obj_embedded_2, obj_embedded_3])\n\n    await async_engine.save_all([obj_db_0, obj_db_1])\n    query_0 = (ModelMain.attr_3.attr_1 == \"one\") & (ModelMain.attr_3.attr_2 == \"two\")\n    result_0 = await async_engine.find_many(Model=ModelMain, query=query_0)\n    query_1 = elem_match(\n        ModelEmbedded.attr_1 == \"one\",\n        ModelEmbedded.attr_2 == \"two\",\n        field=ModelMain.attr_3,\n    )\n    result_1 = await async_engine.find_many(Model=ModelMain, query=query_1)\n    assert len(result_0) == 2\n    assert len(result_1) == 1\n"}
{"type": "test_file", "path": "tests/test_class.py", "content": "from pyodmongo import MainBaseModel, DbModel, Id\nfrom pyodmongo.models.db_field_info import DbField\nfrom pydantic import EmailStr, ValidationError\nfrom datetime import datetime\nfrom typing import ClassVar, Union\nimport pytest\n\n\ndef test_main_base_model():\n    class MainModel(MainBaseModel):\n        attr_1: int\n        attr_2: str\n        attr_3: Id | None\n\n    assert issubclass(MainModel, MainBaseModel)\n    assert isinstance(MainModel.attr_1, DbField)\n    assert isinstance(MainModel.attr_2, DbField)\n    obj = MainModel(attr_1=1, attr_2=\"one\", attr_3=None)\n    assert obj.attr_1 == 1\n    assert obj.attr_2 == \"one\"\n\n\ndef test_create_class():\n    class MyClass(DbModel):\n        _collection: ClassVar = \"myclass\"\n\n    assert issubclass(MyClass, DbModel)\n\n\ndef test_class_variable_db_model():\n    class MyClass(DbModel):\n        _collection: ClassVar = \"myclass\"\n\n    assert hasattr(MyClass, \"id\")\n    assert hasattr(MyClass, \"created_at\")\n    assert hasattr(MyClass, \"updated_at\")\n\n\ndef test_dbmodel_class_variables_type_annotation():\n    class MyClass(DbModel):\n        _collection: ClassVar = \"myclass\"\n\n    assert MyClass.model_fields[\"id\"].annotation == Union[Id, None]\n    assert MyClass.model_fields[\"created_at\"].annotation == Union[datetime, None]\n    assert MyClass.model_fields[\"updated_at\"].annotation == Union[datetime, None]\n\n\ndef test_class_inheritance():\n    class MyClassMain(DbModel):\n        attr_main: str\n        _collection: ClassVar = \"myclassmain\"\n\n    class MyClass1(MyClassMain):\n        attr_1: str\n        _collection: ClassVar = \"myclass1\"\n\n    class MyClass1_1(MyClass1):\n        attr_1_1: str\n        _collection: ClassVar = \"myclass1_2\"\n\n    class MyClass2(MyClassMain):\n        attr_2: str\n        _collection: ClassVar = \"myclass2\"\n\n    class MyClass2_2(MyClass2):\n        attr_2_2: str\n        _collection: ClassVar = \"myclass2_2\"\n\n    assert hasattr(MyClassMain, \"attr_main\")\n    assert not hasattr(MyClassMain, \"attr_1\")\n    assert not hasattr(MyClassMain, \"attr_1_1\")\n    assert not hasattr(MyClassMain, \"attr_2\")\n    assert not hasattr(MyClassMain, \"attr_2_2\")\n    assert hasattr(MyClass1, \"attr_main\")\n    assert hasattr(MyClass1, \"attr_1\")\n    assert not hasattr(MyClass1, \"attr_1_1\")\n    assert not hasattr(MyClass1, \"attr_2\")\n    assert not hasattr(MyClass1, \"attr_2_2\")\n    assert hasattr(MyClass1_1, \"attr_main\")\n    assert hasattr(MyClass1_1, \"attr_1\")\n    assert hasattr(MyClass1_1, \"attr_1_1\")\n    assert not hasattr(MyClass1_1, \"attr_2\")\n    assert not hasattr(MyClass1_1, \"attr_2_2\")\n    assert hasattr(MyClass2, \"attr_main\")\n    assert not hasattr(MyClass2, \"attr_1\")\n    assert not hasattr(MyClass2, \"attr_1_1\")\n    assert hasattr(MyClass2, \"attr_2\")\n    assert not hasattr(MyClass2, \"attr_2_2\")\n    assert hasattr(MyClass2_2, \"attr_main\")\n    assert not hasattr(MyClass2_2, \"attr_1\")\n    assert not hasattr(MyClass2_2, \"attr_1_1\")\n    assert hasattr(MyClass2_2, \"attr_2\")\n    assert hasattr(MyClass2_2, \"attr_2_2\")\n    assert hasattr(MyClassMain, \"id\")\n    assert hasattr(MyClassMain, \"created_at\")\n    assert hasattr(MyClassMain, \"updated_at\")\n    assert hasattr(MyClass1, \"id\")\n    assert hasattr(MyClass1, \"created_at\")\n    assert hasattr(MyClass1, \"updated_at\")\n    assert hasattr(MyClass1_1, \"id\")\n    assert hasattr(MyClass1_1, \"created_at\")\n    assert hasattr(MyClass1_1, \"updated_at\")\n    assert hasattr(MyClass2, \"id\")\n    assert hasattr(MyClass2, \"created_at\")\n    assert hasattr(MyClass2, \"updated_at\")\n    assert hasattr(MyClass2_2, \"id\")\n    assert hasattr(MyClass2_2, \"created_at\")\n    assert hasattr(MyClass2_2, \"updated_at\")\n\n\ndef test_fields_inheritance():\n    class MyClassMain(DbModel):\n        attr_main: str\n        _collection: ClassVar = \"myclassmain\"\n\n    class MyClass1(MyClassMain):\n        attr_1: str\n        _collection: ClassVar = \"myclass1\"\n\n    class MyClass1_1(MyClass1):\n        attr_1_1: str\n        _collection: ClassVar = \"myclass1_2\"\n\n    class MyClass2(MyClassMain):\n        attr_2: str\n        _collection: ClassVar = \"myclass2\"\n\n    class MyClass2_2(MyClass2):\n        attr_2_2: str\n        _collection: ClassVar = \"myclass2_2\"\n\n    assert \"id\" in MyClassMain.model_fields\n    assert \"created_at\" in MyClassMain.model_fields\n    assert \"updated_at\" in MyClassMain.model_fields\n    assert \"attr_main\" in MyClassMain.model_fields\n    assert \"attr_1\" not in MyClassMain.model_fields\n    assert \"attr_1_1\" not in MyClassMain.model_fields\n    assert \"attr_2\" not in MyClassMain.model_fields\n    assert \"attr_2_2\" not in MyClassMain.model_fields\n\n    assert \"id\" in MyClass1.model_fields\n    assert \"created_at\" in MyClass1.model_fields\n    assert \"updated_at\" in MyClass1.model_fields\n    assert \"attr_main\" in MyClass1.model_fields\n    assert \"attr_1\" in MyClass1.model_fields\n    assert \"attr_1_1\" not in MyClass1.model_fields\n    assert \"attr_2\" not in MyClass1.model_fields\n    assert \"attr_2_2\" not in MyClass1.model_fields\n\n    assert \"id\" in MyClass1_1.model_fields\n    assert \"created_at\" in MyClass1_1.model_fields\n    assert \"updated_at\" in MyClass1_1.model_fields\n    assert \"attr_main\" in MyClass1_1.model_fields\n    assert \"attr_1\" in MyClass1_1.model_fields\n    assert \"attr_1_1\" in MyClass1_1.model_fields\n    assert \"attr_2\" not in MyClass1_1.model_fields\n    assert \"attr_2_2\" not in MyClass1_1.model_fields\n\n    assert \"id\" in MyClass2.model_fields\n    assert \"created_at\" in MyClass2.model_fields\n    assert \"updated_at\" in MyClass2.model_fields\n    assert \"attr_main\" in MyClass2.model_fields\n    assert \"attr_1\" not in MyClass2.model_fields\n    assert \"attr_1_1\" not in MyClass2.model_fields\n    assert \"attr_2\" in MyClass2.model_fields\n    assert \"attr_2_2\" not in MyClass2.model_fields\n\n    assert \"id\" in MyClass2_2.model_fields\n    assert \"created_at\" in MyClass2_2.model_fields\n    assert \"updated_at\" in MyClass2_2.model_fields\n    assert \"attr_main\" in MyClass2_2.model_fields\n    assert \"attr_1\" not in MyClass2_2.model_fields\n    assert \"attr_1_1\" not in MyClass2_2.model_fields\n    assert \"attr_2\" in MyClass2_2.model_fields\n    assert \"attr_2_2\" in MyClass2_2.model_fields\n\n\ndef test_field_with_email_str():\n    class MyClass(DbModel):\n        attr_1: str\n        email: EmailStr\n\n    with pytest.raises(ValidationError):\n        obj = MyClass(attr_1=\"Value one\", email=\"shunda\")\n\n\ndef test_polymorphism():\n    class FirstClass(DbModel):\n        attr_1: str = \"one\"\n        attr_2: int = 2\n\n    class SecondClass(FirstClass):\n        attr_1: int = 1\n        attr_3: int = 3\n\n    obj_1 = FirstClass()\n    obj_2 = SecondClass()\n\n    assert obj_1.attr_1 == \"one\"\n    assert type(obj_1.attr_1) is str\n    assert obj_2.attr_1 == 1\n    assert type(obj_2.attr_1) is int\n\n\ndef test_empty_list_field():\n    class A(DbModel):\n        x: list[int]\n\n    A(x=[])\n"}
{"type": "test_file", "path": "tests/test_db_field_info.py", "content": "from pyodmongo import DbModel, Field, Id\nfrom typing import ClassVar\n\n\ndef test_model_fiels_are_corrects():\n    class Lv3(DbModel):\n        attr_lv3_one: str = Field(alias=\"attrLv3One\")\n        attr_lv3_two: str\n        _collection: ClassVar = \"lv3\"\n\n    class Lv2(DbModel):\n        attr_lv2_one: str = Field(alias=\"attrLv2One\")\n        attr_lv2_two: str\n        lv3: Lv3 | Id = Field(alias=\"lv3Alias\")\n        _collection: ClassVar = \"lv2\"\n\n    class Lv1(DbModel):\n        attr_lv1_one: str = Field(alias=\"attrLv1One\")\n        attr_lv1_two: str\n        lv2: Lv2 | Id\n        lv2_list: list[Lv2]\n        lv3_list_multi: list[Id | Lv2]\n        lv2_ref: Id | Lv3 = Field(alias=\"lv2Ref\")\n        lv3_list_ref: list[Lv3 | Id]\n        _collection: ClassVar = \"lv1\"\n\n    class Lv1Filho(Lv1):\n        lv1_filho_attr: str\n\n    assert Lv1Filho.attr_lv1_one.field_name == \"attr_lv1_one\"\n    assert Lv1Filho.attr_lv1_one.field_alias == \"attrLv1One\"\n    assert Lv1.lv2.lv3.attr_lv3_one.field_name == \"attr_lv3_one\"\n    assert Lv1.lv2.lv3.attr_lv3_one.field_alias == \"attrLv3One\"\n    assert Lv1.lv2.lv3.attr_lv3_one.path_str == \"lv2.lv3Alias.attrLv3One\"\n    assert Lv1Filho.lv2.lv3.attr_lv3_one.path_str == \"lv2.lv3Alias.attrLv3One\"\n    assert Lv1.attr_lv1_two.field_type is str\n    assert not Lv1.attr_lv1_two.by_reference\n    assert not Lv1.attr_lv1_two.is_list\n    assert not Lv1.attr_lv1_two.has_model_fields\n\n\ndef test_magic_methods_with_two_db_fields():\n    class TestMagic(DbModel):\n        a: str\n        b: str\n\n    assert type(TestMagic.a == TestMagic.a) is bool\n    assert type(TestMagic.a != TestMagic.a) is bool\n"}
{"type": "test_file", "path": "tests/test_dict_empty.py", "content": "from pyodmongo import DbModel, Id\n\n\ndef test_empty_dict():\n    class MyModel1(DbModel):\n        attr1: str | None\n        _collection = \"my_model_1\"\n\n    class MyModel2(DbModel):\n        attr2: str | None = None\n        attr2_list: list = []\n        my_model_1: MyModel1 | Id | None\n        _collection = \"my_model_2\"\n\n    class MyModel3(DbModel):\n        attr3: str | None\n        my_model_2: MyModel2 | Id | None\n        my_model_2_2: MyModel2 | Id | None\n        my_model_2_3: MyModel2 | Id | None\n        my_model_2_4: MyModel2 | Id | None\n        _collection = \"my_model_3\"\n\n    dct = {\n        \"attr3\": \"attr3\",\n        \"my_model_2\": {\n            \"attr2\": \"Escrito\",\n            \"attr2_list\": [{}, {}],\n            \"my_model_1\": {\"attr1\": {}},\n        },\n        \"my_model_2_2\": {\"my_model_1\": {}, \"attr2_list\": []},\n        \"my_model_2_3\": {},\n        \"my_model_2_4\": {\"attr2\": None, \"attr2_list\": [], \"my_model_1\": {}},\n    }\n    obj = MyModel3(**dct)\n    assert obj.model_dump() == {\n        \"attr3\": \"attr3\",\n        \"my_model_2\": {\n            \"id\": None,\n            \"created_at\": None,\n            \"updated_at\": None,\n            \"attr2\": \"Escrito\",\n            \"attr2_list\": [],\n            \"my_model_1\": {\n                \"id\": None,\n                \"created_at\": None,\n                \"updated_at\": None,\n                \"attr1\": None,\n            },\n        },\n        \"my_model_2_2\": {\n            \"attr2\": None,\n            \"id\": None,\n            \"created_at\": None,\n            \"updated_at\": None,\n            \"my_model_1\": None,\n            \"attr2_list\": [],\n        },\n        \"my_model_2_3\": None,\n        \"my_model_2_4\": {\n            \"id\": None,\n            \"created_at\": None,\n            \"updated_at\": None,\n            \"attr2\": None,\n            \"attr2_list\": [],\n            \"my_model_1\": None,\n        },\n        \"id\": None,\n        \"created_at\": None,\n        \"updated_at\": None,\n    }\n"}
{"type": "test_file", "path": "tests/test_db_index.py", "content": "from pyodmongo import DbModel, Field, DbEngine, AsyncDbEngine, MainBaseModel\nfrom pymongo import IndexModel, ASCENDING, DESCENDING\nfrom typing import ClassVar\nimport pytest\nimport pytest_asyncio\n\n\nclass MyClass(DbModel):\n    attr_0: str\n    attr_1: str = Field(index=True)\n    attr_2: str = Field(unique=True)\n    attr_3: str = Field(text_index=True)\n    attr_4: str = Field(index=True, text_index=True)\n    _collection: ClassVar = \"my_class\"\n    _default_language: ClassVar = \"portuguese\"\n\n\nclass MyClassWithoutDefaultLanguage(DbModel):\n    attr_0: str\n    attr_1: str = Field(index=True)\n    attr_2: str = Field(unique=True)\n    attr_3: str = Field(text_index=True)\n    attr_4: str = Field(index=True, text_index=True)\n    _collection: ClassVar = \"my_class_without_default_language\"\n\n\nclass MyClass2(DbModel):\n    attr_5: str\n    attr_6: str = Field(index=True)\n    _collection: ClassVar = \"my_class_2\"\n\n\n@pytest.fixture()\ndef sync_drop_collection(engine: DbEngine):\n    engine._db[MyClass._collection].drop()\n    yield\n    engine._db[MyClass._collection].drop()\n\n\n@pytest_asyncio.fixture()\nasync def async_drop_collection(async_engine: AsyncDbEngine):\n    await async_engine._db[MyClass._collection].drop()\n    yield\n    await async_engine._db[MyClass._collection].drop()\n\n\ndef test_index_unique_text_index():\n    assert MyClass.model_fields[\"attr_1\"].json_schema_extra.get(\"index\") or False\n    assert not MyClass.model_fields[\"attr_1\"].json_schema_extra.get(\"unique\") or False\n    assert (\n        not MyClass.model_fields[\"attr_1\"].json_schema_extra.get(\"text_index\") or False\n    )\n\n    assert not MyClass.model_fields[\"attr_2\"].json_schema_extra.get(\"index\") or False\n    assert MyClass.model_fields[\"attr_2\"].json_schema_extra.get(\"unique\") or False\n    assert (\n        not MyClass.model_fields[\"attr_2\"].json_schema_extra.get(\"text_index\") or False\n    )\n\n    assert not MyClass.model_fields[\"attr_3\"].json_schema_extra.get(\"index\") or False\n    assert not MyClass.model_fields[\"attr_3\"].json_schema_extra.get(\"unique\") or False\n    assert MyClass.model_fields[\"attr_3\"].json_schema_extra.get(\"text_index\") or False\n\n    assert MyClass.model_fields[\"attr_4\"].json_schema_extra.get(\"index\") or False\n    assert not MyClass.model_fields[\"attr_4\"].json_schema_extra.get(\"unique\") or False\n    assert MyClass.model_fields[\"attr_4\"].json_schema_extra.get(\"text_index\") or False\n\n\ndef test_check_index_field():\n    assert hasattr(MyClass, \"_init_indexes\")\n    assert len(MyClass._init_indexes) == 3\n    assert all(type(item) is IndexModel for item in MyClass._init_indexes)\n\n\ndef test_sync_check_index_in_db(sync_drop_collection, engine: DbEngine):\n    obj = MyClass(\n        attr_0=\"attr_0\",\n        attr_1=\"attr_1\",\n        attr_2=\"attr_2\",\n        attr_3=\"attr_3\",\n        attr_4=\"attr_4\",\n    )\n    result = engine.save(obj)\n    indexes_in_db = engine._db[MyClass._collection].index_information()\n    assert \"attr_0\" not in indexes_in_db\n    assert \"attr_1\" in indexes_in_db\n    assert \"attr_2\" not in indexes_in_db\n    assert \"attr_3\" not in indexes_in_db\n    assert \"attr_4\" in indexes_in_db\n    assert \"attr_3\" in indexes_in_db[\"texts\"][\"weights\"]\n    assert \"attr_4\" in indexes_in_db[\"texts\"][\"weights\"]\n\n\n@pytest.mark.asyncio\nasync def test_async_check_index_in_db(\n    async_drop_collection, async_engine: AsyncDbEngine\n):\n    obj = MyClass(\n        attr_0=\"attr_0\",\n        attr_1=\"attr_1\",\n        attr_2=\"attr_2\",\n        attr_3=\"attr_3\",\n        attr_4=\"attr_4\",\n    )\n    obj2 = MyClassWithoutDefaultLanguage(\n        attr_0=\"attr_0\",\n        attr_1=\"attr_1\",\n        attr_2=\"attr_2\",\n        attr_3=\"attr_3\",\n        attr_4=\"attr_4\",\n    )\n    await async_engine.save(obj)\n    await async_engine.save(obj2)\n    indexes_in_db = await async_engine._db[MyClass._collection].index_information()\n    indexes_in_db_2 = await async_engine._db[\n        MyClassWithoutDefaultLanguage._collection\n    ].index_information()\n\n    assert \"attr_0\" not in indexes_in_db\n    assert \"attr_1\" in indexes_in_db\n    assert \"attr_2\" not in indexes_in_db\n    assert \"attr_3\" not in indexes_in_db\n    assert \"attr_4\" in indexes_in_db\n    assert \"attr_3\" in indexes_in_db[\"texts\"][\"weights\"]\n    assert \"attr_4\" in indexes_in_db[\"texts\"][\"weights\"]\n    assert indexes_in_db[\"texts\"][\"default_language\"] == \"portuguese\"\n\n    assert \"attr_0\" not in indexes_in_db_2\n    assert \"attr_1\" in indexes_in_db_2\n    assert \"attr_2\" not in indexes_in_db_2\n    assert \"attr_3\" not in indexes_in_db_2\n    assert \"attr_4\" in indexes_in_db_2\n    assert \"attr_3\" in indexes_in_db_2[\"texts\"][\"weights\"]\n    assert \"attr_4\" in indexes_in_db_2[\"texts\"][\"weights\"]\n    assert indexes_in_db_2[\"texts\"][\"default_language\"] == \"english\"\n\n\ndef test_create_indexes_on_inheritance(sync_drop_collection, engine: DbEngine):\n    class InheritanceClass(MyClass):\n        attr_5: str = Field(index=True)\n\n    obj = InheritanceClass(\n        attr_0=\"attr_0\",\n        attr_1=\"attr_1\",\n        attr_2=\"attr_2\",\n        attr_3=\"attr_3\",\n        attr_4=\"attr_4\",\n        attr_5=\"attr_5\",\n    )\n\n    result = engine.save(obj)\n    indexes_in_db = engine._db[MyClass._collection].index_information()\n    assert \"attr_0\" not in indexes_in_db\n    assert \"attr_1\" in indexes_in_db\n    assert \"attr_2\" not in indexes_in_db\n    assert \"attr_3\" not in indexes_in_db\n    assert \"attr_4\" in indexes_in_db\n    assert \"attr_5\" in indexes_in_db\n    assert \"attr_3\" in indexes_in_db[\"texts\"][\"weights\"]\n    assert \"attr_4\" in indexes_in_db[\"texts\"][\"weights\"]\n\n\ndef test_create_indexes_on_two_inheritance(engine: DbEngine):\n    class MyClass3(MyClass, MyClass2):\n        attr_7: str = Field(index=True)\n\n    engine._db[MyClass._collection].drop()\n    obj = MyClass3(\n        attr_0=\"attr_0\",\n        attr_1=\"attr_1\",\n        attr_2=\"attr_2\",\n        attr_3=\"attr_3\",\n        attr_4=\"attr_4\",\n        attr_5=\"attr_5\",\n        attr_6=\"attr_6\",\n        attr_7=\"attr_7\",\n    )\n    result = engine.save(obj)\n    indexes_in_db = engine._db[MyClass._collection].index_information()\n    assert \"attr_0\" not in indexes_in_db\n    assert \"attr_1\" in indexes_in_db\n    assert \"attr_2\" not in indexes_in_db\n    assert \"attr_3\" not in indexes_in_db\n    assert \"attr_4\" in indexes_in_db\n    assert \"attr_5\" not in indexes_in_db\n    assert \"attr_6\" in indexes_in_db\n    assert \"attr_7\" in indexes_in_db\n    assert \"attr_3\" in indexes_in_db[\"texts\"][\"weights\"]\n    assert \"attr_4\" in indexes_in_db[\"texts\"][\"weights\"]\n    engine._db[MyClass._collection].drop()\n\n\ndef test_create_custom_indexes(engine: DbEngine):\n    class MyClassCustomIndex(DbModel):\n        attr_0: str = Field(default=None, index=True)\n        attr_1: str = Field(default=None)\n        _collection: ClassVar = \"my_class_custom_index\"\n        _indexes: ClassVar = [\n            IndexModel(\n                [(\"attr_0\", ASCENDING), (\"attr_1\", DESCENDING)],\n                name=\"attr_0_and_attr_1\",\n            )\n        ]\n\n    engine._db[MyClassCustomIndex._collection].drop()\n\n    obj = MyClassCustomIndex()\n    engine.save(obj)\n    indexes_in_db = engine._db[MyClassCustomIndex._collection].index_information()\n    assert \"attr_0_and_attr_1\" in indexes_in_db\n    assert \"attr_0\" not in indexes_in_db\n    assert \"attr_1\" not in indexes_in_db\n    assert len(indexes_in_db[\"attr_0_and_attr_1\"][\"key\"]) == 2\n    assert indexes_in_db[\"attr_0_and_attr_1\"][\"key\"][0] == (\"attr_0\", 1)\n    assert indexes_in_db[\"attr_0_and_attr_1\"][\"key\"][1] == (\"attr_1\", -1)\n\n    engine._db[MyClassCustomIndex._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_async_create_custom_indexes(async_engine: AsyncDbEngine):\n    class MyClassCustomIndex(DbModel):\n        attr_0: str = Field(default=None, index=True)\n        attr_1: str = Field(default=None)\n        _collection: ClassVar = \"my_class_custom_index\"\n        _indexes: ClassVar = [\n            IndexModel(\n                [(\"attr_0\", ASCENDING), (\"attr_1\", DESCENDING)],\n                name=\"attr_0_and_attr_1\",\n            )\n        ]\n\n    await async_engine._db[MyClassCustomIndex._collection].drop()\n\n    obj = MyClassCustomIndex()\n    await async_engine.save(obj)\n    indexes_in_db = await async_engine._db[\n        MyClassCustomIndex._collection\n    ].index_information()\n    assert \"attr_0_and_attr_1\" in indexes_in_db\n    assert \"attr_0\" not in indexes_in_db\n    assert \"attr_1\" not in indexes_in_db\n    assert len(indexes_in_db[\"attr_0_and_attr_1\"][\"key\"]) == 2\n    assert indexes_in_db[\"attr_0_and_attr_1\"][\"key\"][0] == (\"attr_0\", 1)\n    assert indexes_in_db[\"attr_0_and_attr_1\"][\"key\"][1] == (\"attr_1\", -1)\n\n    await async_engine._db[MyClassCustomIndex._collection].drop()\n\n\n@pytest_asyncio.fixture()\nasync def Model_for_recursive_tests(async_engine: AsyncDbEngine):\n    class PersistedLv2(DbModel):\n        attr_lv2_1: str = \"attr_lv2_1\"\n        attr_lv2_2: str = Field(default=\"attr_lv2_2\", index=True, unique=True)\n\n    class Persisted(MainBaseModel):\n        attr_p1: str = \"attr_p1\"\n        attr_p2: str = Field(default=\"attr_p2\", index=True, unique=True)\n        attr_lv2: PersistedLv2 = PersistedLv2()\n\n    class RecModelTest(DbModel):\n        attr_1: str = \"attr_1\"\n        attr_2: str = Field(default=\"attr_2\", index=True, unique=True)\n        attr_persisted: Persisted = Persisted()\n        attr_3: str = Field(default=\"attr_3\", index=True)\n        _collection: ClassVar = \"rec_model_test\"\n\n    await async_engine._db[RecModelTest._collection].drop()\n    yield RecModelTest\n    await async_engine._db[RecModelTest._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_index_creation_with_persisted_nested(\n    async_engine: AsyncDbEngine, Model_for_recursive_tests\n):\n    obj = Model_for_recursive_tests()\n    await async_engine.save(obj)\n    indexes_in_db = await async_engine._db[\n        Model_for_recursive_tests._collection\n    ].index_information()\n    assert \"attr_1\" not in indexes_in_db\n    assert \"attr_2\" in indexes_in_db\n    assert \"attr_3\" in indexes_in_db\n    assert \"attr_persisted\" not in indexes_in_db\n    assert \"attr_persisted.attr_p1\" not in indexes_in_db\n    assert \"attr_persisted.attr_p2\" in indexes_in_db\n    assert \"attr_persisted.attr_lv2.attr_lv2_2\" in indexes_in_db\n    assert \"attr_persisted.attr_lv2.attr_lv2_1\" not in indexes_in_db\n    assert indexes_in_db[\"attr_2\"].get(\"unique\")\n    assert not indexes_in_db[\"attr_3\"].get(\"unique\")\n    assert indexes_in_db[\"attr_persisted.attr_p2\"].get(\"unique\")\n    assert not indexes_in_db[\"attr_persisted.attr_lv2.attr_lv2_2\"].get(\"unique\")\n"}
{"type": "test_file", "path": "tests/test_engines.py", "content": "from typing import ClassVar\nimport pytest\nimport pytest_asyncio\nfrom pyodmongo import (\n    AsyncDbEngine,\n    DbEngine,\n    DbModel,\n    MainBaseModel,\n    DbResponse,\n    ResponsePaginate,\n    Id,\n    DbDecimal,\n    Field,\n)\nfrom pyodmongo.queries import in_\nfrom pydantic import BaseModel\nfrom bson import ObjectId\nfrom faker import Faker\nfrom decimal import Decimal\nfrom bson import Decimal128\nimport copy\nimport json\n\n\nfake = Faker()\n\n\n@pytest_asyncio.fixture\nasync def drop_db(async_engine: AsyncDbEngine, engine: DbEngine):\n    await async_engine._client.drop_database(\"pyodmongo_pytest\")\n    engine._client.drop_database(\"pyodmongo_pytest\")\n    yield\n    await async_engine._client.drop_database(\"pyodmongo_pytest\")\n    engine._client.drop_database(\"pyodmongo_pytest\")\n\n\n@pytest.mark.asyncio\nasync def test_save_all(async_engine: AsyncDbEngine, engine: DbEngine):\n    class MyClass0(DbModel):\n        attr_0: str = Field(index=True)\n        attr_1: int = Field(index=True)\n        _collection: ClassVar = \"my_class_0\"\n\n    class MyClass1(DbModel):\n        attr_2: str = Field(index=True)\n        attr_3: int = Field(index=True)\n        _collection: ClassVar = \"my_class_1\"\n\n    obj_0 = MyClass0(attr_0=\"zero\", attr_1=0)\n    obj_1 = MyClass0(attr_0=\"one\", attr_1=1)\n    obj_2 = MyClass1(attr_2=\"two\", attr_3=2)\n    obj_3 = MyClass1(attr_2=\"three\", attr_3=3)\n\n    response_0: dict[str, DbResponse] = await async_engine.save_all([obj_0, obj_2])\n    response_1: dict[str, DbResponse] = engine.save_all([obj_1, obj_3])\n\n    assert response_0[\"my_class_0\"].upserted_count == 1\n    assert response_0[\"my_class_0\"].upserted_ids[0] == obj_0.id\n    assert response_0[\"my_class_1\"].upserted_count == 1\n    assert response_0[\"my_class_1\"].upserted_ids[0] == obj_2.id\n    assert response_1[\"my_class_0\"].upserted_count == 1\n    assert response_1[\"my_class_0\"].upserted_ids[0] == obj_1.id\n    assert response_1[\"my_class_1\"].upserted_count == 1\n    assert response_1[\"my_class_1\"].upserted_ids[0] == obj_3.id\n\n    assert ObjectId.is_valid(obj_0.id)\n    assert ObjectId.is_valid(obj_1.id)\n    assert ObjectId.is_valid(obj_2.id)\n    assert ObjectId.is_valid(obj_3.id)\n\n    id_0 = copy.copy(obj_0.id)\n    id_1 = copy.copy(obj_1.id)\n    id_2 = copy.copy(obj_2.id)\n    id_3 = copy.copy(obj_3.id)\n\n    obj_0.attr_0 = \"zero_zero\"\n    obj_1.attr_0 = \"one_one\"\n    obj_2.attr_2 = \"two_two\"\n    obj_3.attr_2 = \"three_three\"\n\n    await async_engine.save_all([obj_1, obj_3])\n    engine.save_all([obj_0, obj_2])\n\n    assert obj_0.id == id_0\n    assert obj_1.id == id_1\n    assert obj_2.id == id_2\n    assert obj_3.id == id_3\n\n\n@pytest.mark.asyncio\nasync def test_save(async_engine: AsyncDbEngine, engine: DbEngine, drop_db):\n    class MyClass0(DbModel):\n        attr_0: str = Field(index=True)\n        attr_1: int = Field(index=True)\n        _collection: ClassVar = \"my_class_0\"\n\n    class MyClass1(DbModel):\n        attr_2: str = Field(index=True)\n        attr_3: int = Field(index=True)\n        _collection: ClassVar = \"my_class_1\"\n\n    obj_0 = MyClass0(attr_0=\"zero\", attr_1=0)\n    obj_1 = MyClass1(attr_2=\"two\", attr_3=2)\n\n    response_0: DbResponse = await async_engine.save(obj_0)\n    response_1: DbResponse = engine.save(obj_1)\n\n    assert obj_0.id == response_0.upserted_ids[0]\n    assert obj_1.id == response_1.upserted_ids[0]\n\n\n@pytest.mark.asyncio\nasync def test_find(async_engine: AsyncDbEngine, engine: DbEngine, drop_db):\n    class MyClass0(DbModel):\n        attr_0: str = Field(index=True)\n        attr_1: int = Field(index=True)\n        _collection: ClassVar = \"my_class_0\"\n\n    objs_0_49 = [MyClass0(attr_0=fake.name(), attr_1=n) for n in range(0, 50)]\n    objs_50_99 = [MyClass0(attr_0=fake.name(), attr_1=n) for n in range(50, 100)]\n\n    await async_engine.save_all(objs_0_49)\n    engine.save_all(objs_50_99)\n\n    obj_to_find_0_49: MyClass0 = copy.deepcopy(objs_0_49[24])\n    obj_to_find_50_99: MyClass0 = copy.deepcopy(objs_50_99[24])\n\n    obj_found_0_49 = await async_engine.find_one(\n        Model=MyClass0, query=MyClass0.id == obj_to_find_0_49.id\n    )\n    obj_found_50_49 = engine.find_one(\n        Model=MyClass0, query=MyClass0.id == obj_to_find_50_99.id\n    )\n\n    assert obj_found_0_49 == obj_to_find_0_49\n    assert obj_found_50_49 == obj_to_find_50_99\n\n    query_0 = (MyClass0.attr_1 > 10) & (MyClass0.attr_1 <= 20)\n    query_1 = (MyClass0.attr_1 > 60) & (MyClass0.attr_1 <= 70)\n\n    result_0: ResponsePaginate = await async_engine.find_many(\n        Model=MyClass0, query=query_0, paginate=True, current_page=2, docs_per_page=2\n    )\n    result_1: ResponsePaginate = engine.find_many(\n        Model=MyClass0, query=query_1, paginate=True, current_page=2, docs_per_page=2\n    )\n    assert result_0.current_page == 2\n    assert result_0.page_quantity == 5\n    assert result_0.docs_quantity == 10\n    assert len(result_0.docs) == 2\n    assert result_1.current_page == 2\n    assert result_1.page_quantity == 5\n    assert result_1.docs_quantity == 10\n    assert len(result_1.docs) == 2\n\n\n@pytest.mark.asyncio\nasync def test_delete(async_engine: AsyncDbEngine, engine: DbEngine, drop_db):\n    class MyClass0(DbModel):\n        attr_0: str = Field(index=True)\n        attr_1: int = Field(index=True)\n        _collection: ClassVar = \"my_class_0\"\n\n    objs_0_49 = [MyClass0(attr_0=fake.name(), attr_1=n) for n in range(0, 50)]\n    objs_50_99 = [MyClass0(attr_0=fake.name(), attr_1=n) for n in range(50, 100)]\n\n    await async_engine.save_all(objs_0_49)\n    engine.save_all(objs_50_99)\n\n    query_0 = (MyClass0.attr_1 >= 0) & (MyClass0.attr_1 < 10)\n    query_1 = (MyClass0.attr_1 >= 50) & (MyClass0.attr_1 < 60)\n\n    response_0: DbResponse = await async_engine.delete(\n        Model=MyClass0, query=query_0, delete_one=True\n    )\n    response_1: DbResponse = engine.delete(\n        Model=MyClass0, query=query_1, delete_one=True\n    )\n    assert response_0.deleted_count == 1\n    assert response_1.deleted_count == 1\n\n    find_result_0 = await async_engine.find_many(Model=MyClass0)\n    find_result_1 = engine.find_many(Model=MyClass0)\n    assert len(find_result_0) == 98\n    assert len(find_result_1) == 98\n\n    response_0: DbResponse = await async_engine.delete(Model=MyClass0, query=query_0)\n    response_1: DbResponse = engine.delete(Model=MyClass0, query=query_1)\n    assert response_0.deleted_count == 9\n    assert response_1.deleted_count == 9\n\n    find_result_0 = await async_engine.find_many(Model=MyClass0)\n    find_result_1 = engine.find_many(Model=MyClass0)\n\n    assert len(find_result_0) == 80\n    assert len(find_result_1) == 80\n\n\n@pytest.mark.asyncio\nasync def test_db_field_population(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    class MyClassA(DbModel):\n        attr_a_1: str\n        attr_a_2: str\n        _collection: ClassVar = \"my_class_a\"\n\n    class MyClassB(DbModel):\n        attr_b_1: str\n        attr_obj_a: MyClassA | Id\n        _collection: ClassVar = \"my_class_b\"\n\n    class MyClassC(DbModel):\n        attr_c_1: str\n        attr_obj_b: MyClassB | Id\n        _collection: ClassVar = \"my_class_c\"\n\n    obj_a = MyClassA(attr_a_1=\"value_a_1\", attr_a_2=\"value_a_2\")\n    engine.save(obj_a)\n    obj_b = MyClassB(attr_b_1=\"value_b_1\", attr_obj_a=obj_a)\n    await async_engine.save(obj_b)\n    obj_c = MyClassC(attr_c_1=\"value_c_1\", attr_obj_b=obj_b)\n    await async_engine.save(obj_c)\n\n    populate_db_fields = [MyClassC.attr_obj_b]\n    obj_found = await async_engine.find_one(\n        Model=MyClassC, populate=True, populate_db_fields=populate_db_fields\n    )\n    obj_c.attr_obj_b.attr_obj_a = obj_a.id\n    assert obj_found == obj_c\n\n\n@pytest.mark.asyncio\nasync def test_error_save_base_model(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    with pytest.raises(\n        TypeError,\n        match=\"The MyClassA class inherits from Pydantic's BaseModel class. Try switching to PyODMongo's MainBaseModel class\",\n    ):\n\n        class MyClassA(BaseModel):\n            a1: str = \"a1\"\n\n        class MyClassB(DbModel):\n            b1: str = \"b1\"\n            obj_a: MyClassA = MyClassA()\n            _collection: ClassVar = \"my_class_b\"\n\n        obj = MyClassB()\n        await async_engine.save(obj)\n        engine.save(obj)\n\n\n@pytest.mark.asyncio\nasync def test_list_of_empty_objects(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    class A(DbModel):\n        name: str = \"A Name\"\n        code: str = \"A Code\"\n        _collection: ClassVar = \"a\"\n\n    class B(MainBaseModel):\n        a: A | Id\n        code: str = \"B Code\"\n        cost: float = 100\n\n    class C(DbModel):\n        name: str = \"name_1\"\n        b_list: list[B] = []\n        _collection: ClassVar = \"c\"\n\n    obj_c = C()\n    engine.save(obj_c)\n    obj_found = await async_engine.find_one(Model=C, populate=True)\n    assert obj_found == obj_c\n\n\n@pytest.mark.asyncio\nasync def test_field_population_with_main_base_model(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    class S(DbModel):\n        s1: str = \"s1\"\n        _collection: ClassVar = \"s\"\n\n    class BC(DbModel):\n        b1: str = \"b1\"\n        s: S | Id\n        _collection: ClassVar = \"bc\"\n\n    class A(MainBaseModel):\n        a1: str = \"a1\"\n        bc: BC | Id\n\n    class P(DbModel):\n        p1: str = \"p1\"\n        a: A\n        _collection: ClassVar = \"p\"\n\n    class O(DbModel):\n        o1: str = \"o1\"\n        p: P | Id\n        _collection: ClassVar = \"o\"\n\n    obj_s = S()\n    await async_engine.save(obj_s)\n    obj_bc = BC(s=obj_s)\n    await async_engine.save(obj_bc)\n    obj_a = A(bc=obj_bc)\n    obj_p = P(a=obj_a)\n    engine.save(obj_p)\n    obj_o = O(p=obj_p)\n    engine.save(obj_o)\n\n    obj_found = engine.find_one(\n        Model=O, populate=True, populate_db_fields=[O.p, A.bc, BC.s]\n    )\n    assert obj_found == obj_o\n\n\n@pytest.mark.asyncio\nasync def test_db_model_init_with_missing_attribute_in_class(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    class A(DbModel):\n        a1: str = \"a1\"\n        a2: str = \"a2\"\n        _collection: ClassVar = \"a\"\n\n    class B(DbModel):\n        b1: str = \"b1\"\n        b2: str = \"b2\"\n        _collection: ClassVar = \"b\"\n\n    class A2(A):\n        a3: str = \"a3\"\n        a4: list[B | Id] = []\n\n    obj_b1 = B()\n    obj_b2 = B()\n    engine.save_all([obj_b1, obj_b2])\n    obj_a2 = A2()\n    await async_engine.save(obj_a2)\n    obj_found = await async_engine.find_one(Model=A)\n    assert obj_found\n\n\n@pytest.mark.asyncio\nasync def test_save_with_upsert(async_engine: AsyncDbEngine, engine: DbEngine, drop_db):\n    class A(DbModel):\n        attr_1: str\n        _collection: ClassVar = \"col_a\"\n\n    obj_0 = A(attr_1=\"A\")\n    obj_1 = A(attr_1=\"B\")\n    obj_2 = A(attr_1=\"C\")\n    obj_3 = A(attr_1=\"D\")\n\n    result_0 = engine.save_all([obj_0, obj_1])\n    result_1 = await async_engine.save_all([obj_2, obj_3])\n    assert result_0[\"col_a\"].upserted_count == 2\n    assert result_1[\"col_a\"].upserted_count == 2\n\n    updated_obj_0 = A(attr_1=\"E\")\n    updated_obj_1 = A(attr_1=\"F\")\n\n    result_0: DbResponse = engine.save(\n        updated_obj_0, query=A.attr_1 == \"E\", upsert=False\n    )\n    result_1: DbResponse = await async_engine.save(\n        updated_obj_1, query=A.attr_1 == \"F\", upsert=False\n    )\n    assert result_0.upserted_count == 0\n    assert result_1.upserted_count == 0\n\n    result_0: DbResponse = engine.save(\n        updated_obj_0, query=(A.attr_1 == \"A\") | (A.attr_1 == \"K\"), upsert=False\n    )\n    result_1: DbResponse = await async_engine.save(\n        updated_obj_1, query=(A.attr_1 == \"C\") | (A.attr_1 == \"D\"), upsert=False\n    )\n    assert result_0.modified_count == 1\n    assert result_0.upserted_count == 0\n    assert result_1.modified_count == 2\n    assert result_1.upserted_count == 0\n\n\n@pytest.mark.asyncio\nasync def test_save_nested_objects_with_none(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    class S(DbModel):\n        s_1: str = \"s_1\"\n        _collection: ClassVar = \"s\"\n\n    class BC(DbModel):\n        bc_1: str = \"bc_1\"\n        s: S | Id\n        _collection: ClassVar = \"bc\"\n\n    class A(MainBaseModel):\n        a: str | None = None\n        bc: BC | None = None\n        _collection: ClassVar = \"a\"\n\n    class BI(MainBaseModel):\n        bi_1: str = \"bi_1\"\n        a: A | None = None\n\n    class O(DbModel):\n        o_1: str = \"o_1\"\n        bi: BI | None = None\n        _collection: ClassVar = \"o\"\n\n    obj_s = S()\n    await async_engine.save(obj_s)\n\n    obj_bc = BC(s=obj_s)\n    await async_engine.save(obj_bc)\n\n    obj_a = A(bc=obj_bc)\n    obj_bi = BI(a=obj_a)\n\n    obj_1 = O()\n    obj_2 = O(bi=obj_bi)\n    await async_engine.save_all([obj_1, obj_2])\n    obj_found = await async_engine.find_one(Model=O, populate=True, query=O.bi == None)\n    assert obj_found == obj_1\n\n\n@pytest.mark.asyncio\nasync def test_find_one_and_find_many_with_pipeline(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    class A(DbModel):\n        attr_a: str\n        _collection: ClassVar = \"a\"\n\n    class B(DbModel):\n        attr_b: str\n        a: A | Id\n        _collection: ClassVar = \"b\"\n\n    obj_a_1 = A(attr_a=\"a_1\")\n    obj_a_2 = A(attr_a=\"a_2\")\n    obj_a_3 = A(attr_a=\"a_3\")\n    await async_engine.save_all([obj_a_1, obj_a_2, obj_a_3])\n    obj_b_1 = B(attr_b=\"b_1\", a=obj_a_1)\n    obj_b_2 = B(attr_b=\"b_2\", a=obj_a_2)\n    obj_b_3 = B(attr_b=\"b_3\", a=obj_a_3)\n    engine.save_all([obj_b_1, obj_b_2, obj_b_3])\n\n    obj_b_1_found, obj_b_2_found, obj_b_3_found = await async_engine.find_many(Model=B)\n    assert obj_b_1_found.a == obj_b_1.a.id == obj_a_1.id\n    assert obj_b_2_found.a == obj_b_2.a.id == obj_a_2.id\n    assert obj_b_3_found.a == obj_b_3.a.id == obj_a_3.id\n\n    pipeline = [\n        {\"$lookup\": {\"from\": \"a\", \"localField\": \"a\", \"foreignField\": \"_id\", \"as\": \"a\"}},\n        {\"$set\": {\"a\": {\"$arrayElemAt\": [\"$a\", 0]}}},\n    ]\n    obj_b_2_found, obj_b_3_found = await async_engine.find_many(\n        Model=B, query=in_(B.attr_b, [\"b_2\", \"b_3\"]), pipeline=pipeline\n    )\n    assert obj_b_2_found == obj_b_2\n    assert obj_b_3_found == obj_b_3\n    assert obj_b_2_found.a.id == obj_b_2.a.id == obj_a_2.id\n    assert obj_b_3_found.a.id == obj_b_3.a.id == obj_a_3.id\n\n\n@pytest.mark.asyncio\nasync def test_save_with_populate(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    class A(DbModel):\n        attr_a: str\n        _collection: ClassVar = \"a\"\n\n    class B(DbModel):\n        attr_b: str\n        a: A | Id\n        _collection: ClassVar = \"b\"\n\n    obj_a_1 = A(attr_a=\"a_1\")\n    obj_a_2 = A(attr_a=\"a_2\")\n    obj_a_3 = A(attr_a=\"a_3\")\n    await async_engine.save(obj_a_1)\n    await async_engine.save_all([obj_a_2, obj_a_3])\n    obj_b_1 = B(attr_b=\"b_1\", a=obj_a_1)\n    obj_b_2 = B(attr_b=\"b_2\", a=obj_a_2)\n    obj_b_3 = B(attr_b=\"b_3\", a=obj_a_3)\n    await async_engine.save(obj_b_1)\n    await async_engine.save_all([obj_b_2, obj_b_3])\n    obj_b_1_found, obj_b_2_found, obj_b_3_found = await async_engine.find_many(Model=B)\n    assert obj_b_1_found.a == obj_b_1.a.id == obj_a_1.id\n    assert obj_b_2_found.a == obj_b_2.a.id == obj_a_2.id\n    assert obj_b_3_found.a == obj_b_3.a.id == obj_a_3.id\n\n    await async_engine.save(obj_b_1, populate=True)\n    await async_engine.save_all([obj_b_2, obj_b_3], populate=True)\n    obj_b_1_found, obj_b_2_found, obj_b_3_found = await async_engine.find_many(Model=B)\n    assert obj_b_1_found.a.id == obj_b_1.a.id == obj_a_1.id\n    assert obj_b_2_found.a.id == obj_b_2.a.id == obj_a_2.id\n    assert obj_b_3_found.a.id == obj_b_3.a.id == obj_a_3.id\n\n\n@pytest.mark.asyncio\nasync def test_save_with_decimal(\n    async_engine: AsyncDbEngine, engine: DbEngine, drop_db\n):\n    class Product(DbModel):\n        name: str = \"Product Name\"\n        price: DbDecimal\n        prices: list[DbDecimal]\n        is_available: bool = True\n        _collection: ClassVar = \"products\"\n\n    number_1 = DbDecimal(\"10.123456\", 2)\n    number_2 = DbDecimal(10.123456, 2)\n    number_3 = DbDecimal(\"10.123456\").to_scale(2)\n    number_4 = DbDecimal(10.123456).to_scale(2)\n    assert number_1 == number_2 == number_3 == number_4\n    obj_1 = Product(price=number_1, prices=[number_1, number_2, number_3, number_4])\n    obj_2 = Product(price=number_2, prices=[number_1, number_2, number_3, number_4])\n    obj_3 = Product(price=number_3, prices=[number_1, number_2, number_3, number_4])\n    obj_4 = Product(price=number_4, prices=[number_1, number_2, number_3, number_4])\n    assert obj_1 == obj_2 == obj_3 == obj_4\n    await async_engine.save_all([obj_1, obj_2, obj_3, obj_4])\n    objs = await async_engine.find_many(Model=Product)\n    assert len(objs) == 4\n    assert objs == [obj_1, obj_2, obj_3, obj_4]\n\n    obj_5 = Product(\n        price=25.56, prices=[12.5, \"46.18\", DbDecimal(25.56, 2), DbDecimal(\"46.18\")]\n    )\n    await async_engine.save(obj_5)\n    query = Product.price > 24.56\n    objs = await async_engine.find_many(Model=Product, query=query)\n    assert len(objs) == 1\n    assert objs[0] == obj_5\n    obj_5 = objs[0]\n\n    query = in_(Product.price, [12.5, \"46.18\", DbDecimal(25.56, 2), DbDecimal(\"46.18\")])\n    assert query.value == [\n        Decimal128(\"12.5\"),\n        Decimal128(\"46.18\"),\n        Decimal128(\"25.56\"),\n        Decimal128(\"46.18\"),\n    ]\n\n    assert obj_5.model_dump() == {\n        \"id\": obj_5.id,\n        \"created_at\": obj_5.created_at,\n        \"updated_at\": obj_5.updated_at,\n        \"name\": \"Product Name\",\n        \"price\": Decimal(\"25.55999999999999872102307563181967\"),\n        \"prices\": [\n            Decimal(\"12.5\"),\n            Decimal(\"46.18\"),\n            Decimal(\"25.56\"),\n            Decimal(\"46.18\"),\n        ],\n        \"is_available\": True,\n    }\n    assert json.loads(obj_5.model_dump_json()) == {\n        \"id\": obj_5.id,\n        \"created_at\": obj_5.created_at.isoformat(),\n        \"updated_at\": obj_5.updated_at.isoformat(),\n        \"name\": \"Product Name\",\n        \"price\": 25.56,\n        \"prices\": [\n            12.5,\n            46.18,\n            25.56,\n            46.18,\n        ],\n        \"is_available\": True,\n    }\n\n    with pytest.raises(ValueError, match=\"Invalid decimal type\"):\n        error_attr = DbDecimal({\"key\": \"value\"})\n"}
{"type": "test_file", "path": "tests/test_fastapi.py", "content": "from fastapi import FastAPI\nfrom fastapi.testclient import TestClient\nfrom pyodmongo import DbModel\n\napp = FastAPI()\n\n\nclass Model1(DbModel):\n    attr1: str = None\n    attr2: str\n\n\nclass Model2(Model1):\n    attr3: str\n    attr4: str = None\n\n\n@app.post(\"/\", response_model=Model2)\nasync def read_main(input_obj: Model2):\n    return input_obj\n\n\nclient = TestClient(app)\n\n\ndef test_response_model_and_output_obj():\n    json_body = {\n        \"attr2\": \"Value 2\",\n        \"attr3\": \"Value 3\",\n    }\n    response = client.post(url=\"/\", json=json_body)\n    assert response.status_code == 200\n    assert response.json() == {\n        \"id\": None,\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"attr1\": None,\n        \"attr2\": \"Value 2\",\n        \"attr3\": \"Value 3\",\n        \"attr4\": None,\n    }\n"}
{"type": "test_file", "path": "tests/test_id_model.py", "content": "from pyodmongo import Id, DbModel\n\n\ndef test_id_model():\n    class MyClass(DbModel):\n        my_id: Id\n\n    obj = MyClass(my_id=None)\n    assert obj.my_id == None\n"}
{"type": "test_file", "path": "tests/test_model_init_functions.py", "content": "from pyodmongo import DbModel, Id\nfrom typing import ClassVar\nfrom pydantic import BaseModel\nfrom pyodmongo.services.model_init import field_annotation_infos\n\n\ndef test_field_with_list_of_unions():\n    class MyFirstClass(BaseModel):\n        attr_first: str = None\n        _collection: ClassVar = \"my_first_class\"\n\n    class MyClass(BaseModel):\n        email: str = None\n        mfc0: Id = None\n        mfc1: list[MyFirstClass | None | Id] | None = None\n\n    for field, field_info in MyClass.model_fields.items():\n        db_field_info = field_annotation_infos(field=field, field_info=field_info)\n"}
{"type": "test_file", "path": "tests/test_object_id.py", "content": "import pytest\nfrom pyodmongo import DbModel\nfrom bson import ObjectId\nfrom typing import ClassVar\n\n\ndef test_object_id_to_string():\n    class MyClass(DbModel):\n        _collection: ClassVar = \"myclass\"\n\n    id_str = \"64e66f06ca15379cd00e6453\"\n    obj_dict_1 = {\"id\": id_str}\n    obj_dict_2 = {\"_id\": id_str}\n    obj_dict_3 = {\"id\": ObjectId(id_str)}\n    obj_dict_4 = {\"_id\": ObjectId(id_str)}\n\n    obj_1 = MyClass(**obj_dict_1)\n    obj_2 = MyClass(**obj_dict_2)\n    obj_3 = MyClass(**obj_dict_3)\n    obj_4 = MyClass(**obj_dict_4)\n\n    assert obj_1.id == id_str\n    assert type(obj_1.id) == str\n    assert obj_2.id == id_str\n    assert type(obj_2.id) == str\n    assert obj_3.id == id_str\n    assert type(obj_3.id) == str\n    assert obj_4.id == id_str\n    assert type(obj_4.id) == str\n\n\ndef test_insert_an_invalid_object_id():\n    class MyClass(DbModel):\n        _collection: ClassVar = \"myclass\"\n\n    id_str = \"123abc\"\n    obj_dict = {\"id\": id_str}\n    with pytest.raises(ValueError):\n        MyClass(**obj_dict)\n"}
{"type": "test_file", "path": "tests/test_project_pipeline.py", "content": "from pyodmongo import DbModel, Field, AsyncDbEngine\nfrom pydantic import ConfigDict\nfrom typing import ClassVar\nimport pytest_asyncio\nimport pytest\n\n\ndef to_lower_camel(string: str) -> str:\n    words = string.split(\"_\")\n    return \"\".join(words[:1] + [word.capitalize() for word in words[1:]])\n\n\nmongo_uri = \"mongodb://localhost:27017\"\ndb_name = \"pyodmongo_pytest\"\nengine = AsyncDbEngine(mongo_uri=mongo_uri, db_name=db_name)\n\n\nclass MyModel(DbModel):\n    name: str\n    age: int\n    one_name: str\n    other_name: str\n    _collection: ClassVar = \"my_model\"\n    # model_config = ConfigDict(alias_generator=to_lower_camel)\n\n\nclass MyModelRead(DbModel):\n    name: str\n    other_name: str\n    _collection: ClassVar = \"my_model\"\n\n\n@pytest_asyncio.fixture()\nasync def drop_collections():\n    await engine._db[MyModel._collection].drop()\n    yield\n    await engine._db[MyModel._collection].drop()\n\n\n@pytest.mark.asyncio\nasync def test_project_pipilene(drop_collections):\n    obj_my_model = MyModel(\n        name=\"A name\", age=10, one_name=\"One Name\", other_name=\"Other Name\"\n    )\n    await engine.save(obj_my_model)\n    obj_my_model_read = await engine.find_one(Model=MyModelRead)\n    assert obj_my_model_read.name == \"A name\"\n    assert obj_my_model_read.other_name == \"Other Name\"\n"}
{"type": "test_file", "path": "tests/test_pydantic_validators.py", "content": "from pyodmongo import DbModel\nfrom pydantic import field_validator, ConfigDict\nfrom typing import ClassVar\n\n\ndef test_single_field_validator():\n    class MyModel1(DbModel):\n        attr1: str\n        attr2: str\n        model_config = ConfigDict()\n        _collection: ClassVar = \"Vrau\"\n\n        @field_validator(\"attr2\")\n        def validate_attr2(cls, value):\n            return value + \"_mod\"\n\n    class MyModel2(MyModel1):\n        attr3: str\n        attr4: str\n\n    obj = MyModel1(attr1=\"value_one\", attr2=\"value_two\")\n    obj2 = MyModel2(\n        attr1=\"value_one_one\",\n        attr2=\"value_two_two\",\n        attr3=\"value_three\",\n        attr4=\"value_four\",\n    )\n\n    assert obj.attr2 == \"value_two_mod\"\n    assert obj2.attr2 == \"value_two_two_mod\"\n"}
{"type": "test_file", "path": "tests/test_reference_pipeline.py", "content": "from pyodmongo import DbModel, MainBaseModel, Id\nfrom pydantic import BaseModel, Field\nfrom typing import ClassVar\nfrom pyodmongo.services.reference_pipeline import (\n    resolve_reference_pipeline,\n    _paths_to_ref_ids,\n)\nimport pytest\n\n\ndef test_single_class_project_pipeline():\n    class A(DbModel):\n        a1: str\n        a2: str\n        _collection: ClassVar = \"a\"\n\n    expected = [\n        # {\n        #     \"$project\": {\n        #         \"_id\": True,\n        #         \"a1\": True,\n        #         \"a2\": True,\n        #         \"created_at\": True,\n        #         \"updated_at\": True,\n        #     }\n        # },\n    ]\n\n    assert (\n        resolve_reference_pipeline(cls=A, pipeline=[], populate_db_fields=None)\n        == expected\n    )\n\n\ndef test_simple_if_reference_pipeline_is_correct():\n    class A0(DbModel):\n        a01: str\n        _collection: ClassVar = \"a0\"\n\n    class A(DbModel):\n        a1: str\n        _collection: ClassVar = \"a\"\n\n    class B(DbModel):\n        b1: A | Id\n        b2: A0 | Id\n        _collection: ClassVar = \"b\"\n\n    class C(DbModel):\n        c1: list[B | Id]\n        _collection: ClassVar = \"c\"\n\n    expected = [\n        {\n            \"$lookup\": {\n                \"from\": \"b\",\n                \"localField\": \"c1\",\n                \"foreignField\": \"_id\",\n                \"as\": \"c1\",\n                \"pipeline\": [\n                    {\n                        \"$lookup\": {\n                            \"from\": \"a\",\n                            \"localField\": \"b1\",\n                            \"foreignField\": \"_id\",\n                            \"as\": \"b1\",\n                            \"pipeline\": [],\n                        }\n                    },\n                    {\"$set\": {\"b1\": {\"$arrayElemAt\": [\"$b1\", 0]}}},\n                    {\n                        \"$set\": {\n                            \"b1\": {\n                                \"$cond\": {\n                                    \"if\": {\n                                        \"$or\": [\n                                            {\"$eq\": [\"$b1\", None]},\n                                            {\"$eq\": [\"$b1\", {}]},\n                                        ]\n                                    },\n                                    \"then\": None,\n                                    \"else\": \"$b1\",\n                                }\n                            }\n                        }\n                    },\n                    {\n                        \"$lookup\": {\n                            \"from\": \"a0\",\n                            \"localField\": \"b2\",\n                            \"foreignField\": \"_id\",\n                            \"as\": \"b2\",\n                            \"pipeline\": [],\n                        }\n                    },\n                    {\"$set\": {\"b2\": {\"$arrayElemAt\": [\"$b2\", 0]}}},\n                    {\n                        \"$set\": {\n                            \"b2\": {\n                                \"$cond\": {\n                                    \"if\": {\n                                        \"$or\": [\n                                            {\"$eq\": [\"$b2\", None]},\n                                            {\"$eq\": [\"$b2\", {}]},\n                                        ]\n                                    },\n                                    \"then\": None,\n                                    \"else\": \"$b2\",\n                                }\n                            }\n                        }\n                    },\n                ],\n            }\n        }\n    ]\n    assert (\n        resolve_reference_pipeline(cls=C, pipeline=[], populate_db_fields=None)\n        == expected\n    )\n\n\ndef test_manual_pipeline():\n    class MyModel1(DbModel):\n        attr1: str\n        _collection: ClassVar = \"my_model_1\"\n\n    class MyModel2(DbModel):\n        attr2: str\n        my_model_1: MyModel1\n        _collection: ClassVar = \"my_model_2\"\n        _pipeline: ClassVar = [\"manual pipeline here\"]\n\n    assert MyModel1._pipeline == []\n    assert MyModel2._pipeline == [\"manual pipeline here\"]\n\n\ndef test_recursive_reference_pipeline():\n    class Zero(DbModel):\n        attr_0: str = \"Zero\"\n        _collection: ClassVar = \"col_0\"\n\n    class A(DbModel):\n        attr_1: str = \"One\"\n        zero_1: Zero | Id = Zero()\n        zero_2: Zero = Zero()\n        _collection: ClassVar = \"col_a\"\n\n    class B(MainBaseModel):\n        attr_2: str = \"Two\"\n        a1: A | Id = A()\n        a2: A = A()\n\n    class C(DbModel):\n        attr_3: str = \"Three\"\n        a: A | Id = A()\n        b: B = B()\n        _collection: ClassVar = \"col_c\"\n\n    assert resolve_reference_pipeline(cls=C, pipeline=[], populate_db_fields=None) == [\n        {\n            \"$lookup\": {\n                \"from\": \"col_a\",\n                \"localField\": \"a\",\n                \"foreignField\": \"_id\",\n                \"as\": \"a\",\n                \"pipeline\": [\n                    {\n                        \"$lookup\": {\n                            \"from\": \"col_0\",\n                            \"localField\": \"zero_1\",\n                            \"foreignField\": \"_id\",\n                            \"as\": \"zero_1\",\n                            \"pipeline\": [],\n                        }\n                    },\n                    {\"$set\": {\"zero_1\": {\"$arrayElemAt\": [\"$zero_1\", 0]}}},\n                    {\n                        \"$set\": {\n                            \"zero_1\": {\n                                \"$cond\": {\n                                    \"if\": {\n                                        \"$or\": [\n                                            {\"$eq\": [\"$zero_1\", None]},\n                                            {\"$eq\": [\"$zero_1\", {}]},\n                                        ]\n                                    },\n                                    \"then\": None,\n                                    \"else\": \"$zero_1\",\n                                }\n                            }\n                        }\n                    },\n                ],\n            }\n        },\n        {\"$set\": {\"a\": {\"$arrayElemAt\": [\"$a\", 0]}}},\n        {\n            \"$set\": {\n                \"a\": {\n                    \"$cond\": {\n                        \"if\": {\"$or\": [{\"$eq\": [\"$a\", None]}, {\"$eq\": [\"$a\", {}]}]},\n                        \"then\": None,\n                        \"else\": \"$a\",\n                    }\n                }\n            }\n        },\n        {\n            \"$lookup\": {\n                \"from\": \"col_a\",\n                \"localField\": \"b.a1\",\n                \"foreignField\": \"_id\",\n                \"as\": \"b.a1\",\n                \"pipeline\": [\n                    {\n                        \"$lookup\": {\n                            \"from\": \"col_0\",\n                            \"localField\": \"zero_1\",\n                            \"foreignField\": \"_id\",\n                            \"as\": \"zero_1\",\n                            \"pipeline\": [],\n                        }\n                    },\n                    {\"$set\": {\"zero_1\": {\"$arrayElemAt\": [\"$zero_1\", 0]}}},\n                    {\n                        \"$set\": {\n                            \"zero_1\": {\n                                \"$cond\": {\n                                    \"if\": {\n                                        \"$or\": [\n                                            {\"$eq\": [\"$zero_1\", None]},\n                                            {\"$eq\": [\"$zero_1\", {}]},\n                                        ]\n                                    },\n                                    \"then\": None,\n                                    \"else\": \"$zero_1\",\n                                }\n                            }\n                        }\n                    },\n                ],\n            }\n        },\n        {\"$set\": {\"b.a1\": {\"$arrayElemAt\": [\"$b.a1\", 0]}}},\n        {\n            \"$set\": {\n                \"b.a1\": {\n                    \"$cond\": {\n                        \"if\": {\n                            \"$or\": [{\"$eq\": [\"$b.a1\", None]}, {\"$eq\": [\"$b.a1\", {}]}]\n                        },\n                        \"then\": \"$$REMOVE\",\n                        \"else\": \"$b.a1\",\n                    }\n                }\n            }\n        },\n        {\n            \"$set\": {\n                \"b\": {\n                    \"$cond\": {\n                        \"if\": {\"$or\": [{\"$eq\": [\"$b\", None]}, {\"$eq\": [\"$b\", {}]}]},\n                        \"then\": None,\n                        \"else\": \"$b\",\n                    }\n                }\n            }\n        },\n        {\n            \"$lookup\": {\n                \"from\": \"col_0\",\n                \"localField\": \"b.a2.zero_1\",\n                \"foreignField\": \"_id\",\n                \"as\": \"b.a2.zero_1\",\n                \"pipeline\": [],\n            }\n        },\n        {\"$set\": {\"b.a2.zero_1\": {\"$arrayElemAt\": [\"$b.a2.zero_1\", 0]}}},\n        {\n            \"$set\": {\n                \"b.a2.zero_1\": {\n                    \"$cond\": {\n                        \"if\": {\n                            \"$or\": [\n                                {\"$eq\": [\"$b.a2.zero_1\", None]},\n                                {\"$eq\": [\"$b.a2.zero_1\", {}]},\n                            ]\n                        },\n                        \"then\": \"$$REMOVE\",\n                        \"else\": \"$b.a2.zero_1\",\n                    }\n                }\n            }\n        },\n        {\n            \"$set\": {\n                \"b.a2\": {\n                    \"$cond\": {\n                        \"if\": {\n                            \"$or\": [{\"$eq\": [\"$b.a2\", None]}, {\"$eq\": [\"$b.a2\", {}]}]\n                        },\n                        \"then\": \"$$REMOVE\",\n                        \"else\": \"$b.a2\",\n                    }\n                }\n            }\n        },\n        {\n            \"$set\": {\n                \"b\": {\n                    \"$cond\": {\n                        \"if\": {\"$or\": [{\"$eq\": [\"$b\", None]}, {\"$eq\": [\"$b\", {}]}]},\n                        \"then\": None,\n                        \"else\": \"$b\",\n                    }\n                }\n            }\n        },\n    ]\n\n\ndef test_main_base_model_usage_recommendation():\n    class Z(DbModel):\n        z1: str = \"z1\"\n        _collection: TypeError = \"z\"\n\n    class X(BaseModel):\n        x1: str = \"x1\"\n        x2: str = \"x2\"\n        z: Z | Id\n\n    with pytest.raises(\n        TypeError,\n        match=\"The X class inherits from Pydantic's BaseModel class. Try switching to PyODMongo's MainBaseModel class\",\n    ):\n        _paths_to_ref_ids(cls=X, paths=[], db_field_path=[], populate_db_fields=None)\n"}
{"type": "test_file", "path": "tests/test_queries.py", "content": "from pyodmongo import MainBaseModel, DbModel, Field, Id\nfrom pyodmongo.models.query_operators import QueryOperator\nfrom pydantic import BaseModel\nfrom typing import ClassVar\nfrom bson import ObjectId\nfrom datetime import datetime\nfrom pyodmongo.queries import (\n    eq,\n    gt,\n    gte,\n    in_,\n    lt,\n    lte,\n    ne,\n    nin,\n    text,\n    and_,\n    or_,\n    nor,\n    sort,\n    elem_match,\n    mount_query_filter,\n)\n\nimport pytest\nimport re\n\n\nclass Model1(DbModel):\n    a: str = Field(alias=\"aAlias\")\n    b: str\n    _collection: ClassVar = \"model_1\"\n\n\nclass Model2(DbModel):\n    c: str = Field(alias=\"cAlias\")\n    d: str\n    e: Model1 = Field(alias=\"eAlias\")\n    _collection: ClassVar = \"model_2\"\n\n\nclass Model3(DbModel):\n    f: Model2\n    g: Model2 | Id\n    _collection: ClassVar = \"model_3\"\n\n\ndef test_comparison_operators():\n    assert eq(Model3.f.e.a, \"value\").to_dict() == {\"f.eAlias.aAlias\": {\"$eq\": \"value\"}}\n    assert gt(Model3.f.id, \"64e8ef019af47dc6f91c5a48\").to_dict() == {\n        \"f._id\": {\"$gt\": ObjectId(\"64e8ef019af47dc6f91c5a48\")}\n    }\n    assert gt(Model3.f.e.id, \"64e8ef019af47dc6f91c5a48\").to_dict() == {\n        \"f.eAlias._id\": {\"$gt\": ObjectId(\"64e8ef019af47dc6f91c5a48\")}\n    }\n    assert gte(Model3.g, \"64e8ef019af47dc6f91c5a48\").to_dict() == {\n        \"g\": {\"$gte\": ObjectId(\"64e8ef019af47dc6f91c5a48\")}\n    }\n    assert in_(\n        Model3.g, [\"64e8ef019af47dc6f91c5a48\", \"64e8f1a5f1dae6703924546a\"]\n    ).to_dict() == {\n        \"g\": {\n            \"$in\": [\n                ObjectId(\"64e8ef019af47dc6f91c5a48\"),\n                ObjectId(\"64e8f1a5f1dae6703924546a\"),\n            ]\n        }\n    }\n    assert nin(Model3.g.e.b, [\"value_1\", \"value_2\"]).to_dict() == {\n        \"g.eAlias.b\": {\"$nin\": [\"value_1\", \"value_2\"]}\n    }\n    assert text(\"Text to find\").to_dict() == {\"$text\": {\"$search\": '\"Text to find\"'}}\n    assert lt(Model2.d, \"value_d\").to_dict() == {\"d\": {\"$lt\": \"value_d\"}}\n    assert lte(Model2.c, \"value_c\").to_dict() == {\"cAlias\": {\"$lte\": \"value_c\"}}\n\n\ndef test_logical_operators():\n    op1 = eq(Model3.f.e.a, \"value\")\n    op2 = gt(Model3.f.id, \"64e8ef019af47dc6f91c5a48\")\n    and_query = and_(op1, op2)\n    or_query = or_(op1, op2)\n    nor_query = nor(op1, op2)\n\n    assert and_query.to_dict() == {\n        \"$and\": [\n            {\"f.eAlias.aAlias\": {\"$eq\": \"value\"}},\n            {\"f._id\": {\"$gt\": ObjectId(\"64e8ef019af47dc6f91c5a48\")}},\n        ]\n    }\n    assert or_query.to_dict() == {\n        \"$or\": [\n            {\"f.eAlias.aAlias\": {\"$eq\": \"value\"}},\n            {\"f._id\": {\"$gt\": ObjectId(\"64e8ef019af47dc6f91c5a48\")}},\n        ]\n    }\n    assert nor_query.to_dict() == {\n        \"$nor\": [\n            {\"f.eAlias.aAlias\": {\"$eq\": \"value\"}},\n            {\"f._id\": {\"$gt\": ObjectId(\"64e8ef019af47dc6f91c5a48\")}},\n        ]\n    }\n\n\ndef test_mount_query_filter_with_invalid_field():\n    dict_input = {\"c_eq\": \"value1\", \"d_in\": '[\"abc\", \"xyz\"]', \"vrau_eq\": \"ddsff\"}\n    with pytest.raises(AttributeError):\n        query, _ = mount_query_filter(\n            Model=Model2, items=dict_input, initial_comparison_operators=[]\n        )\n\n\ndef test_mount_query_filter():\n    dict_input = {\n        \"id_eq\": \"64e8ef019af47dc6f91c5a48\",\n        \"g_in\": \"['64e8ef019af47dc6f91c5a48', '64e8f1a5f1dae6703924546a']\",\n    }\n    query, _ = mount_query_filter(\n        Model=Model3, items=dict_input, initial_comparison_operators=[]\n    )\n    assert query.to_dict() == {\n        \"$and\": [\n            {\"_id\": {\"$eq\": ObjectId(\"64e8ef019af47dc6f91c5a48\")}},\n            {\n                \"g\": {\n                    \"$in\": [\n                        ObjectId(\"64e8ef019af47dc6f91c5a48\"),\n                        ObjectId(\"64e8f1a5f1dae6703924546a\"),\n                    ]\n                }\n            },\n        ]\n    }\n\n\ndef test_mount_query_filter_inheritance():\n    class MainModel(DbModel):\n        attr_1: str = None\n        _collection: ClassVar = \"main_model\"\n\n    class SecondModel(MainModel):\n        attr_2: str = None\n\n    class ThirdModel(SecondModel):\n        attr_3: str = None\n\n    class FourthModel(ThirdModel, SecondModel):\n        attr_4: str = None\n\n    input_dict = {\n        \"attr_1_eq\": \"Value1\",\n        \"attr_2_eq\": \"Value2\",\n        \"attr_3_eq\": \"Value3\",\n        \"attr_4_eq\": \"Value4\",\n        \"attr_4_ne\": \"\",\n        \"attr_4_er\": \"Value_error\",\n    }\n    query, _ = mount_query_filter(\n        Model=FourthModel, items=input_dict, initial_comparison_operators=[]\n    )\n    expected_query_dict = {\n        \"$and\": [\n            {\"attr_1\": {\"$eq\": \"Value1\"}},\n            {\"attr_2\": {\"$eq\": \"Value2\"}},\n            {\"attr_3\": {\"$eq\": \"Value3\"}},\n            {\"attr_4\": {\"$eq\": \"Value4\"}},\n            {\"attr_4\": {\"$ne\": \"\"}},\n        ]\n    }\n\n    assert query.to_dict() == expected_query_dict\n\n\ndef test_mount_query_filter_is_not_inheritance():\n    class MainModel(BaseModel):\n        attr_1: str = None\n        _collection: ClassVar = \"main_model\"\n\n    class SecondModel(MainModel):\n        attr_2: str = None\n\n    class ThirdModel(SecondModel):\n        attr_3: str = None\n\n    class FourthModel(ThirdModel, SecondModel):\n        attr_4: str = None\n\n    input_dict = {\n        \"attr_1_eq\": \"Value1\",\n        \"attr_2_eq\": \"Value2\",\n        \"attr_3_eq\": \"Value3\",\n        \"attr_4_eq\": \"Value4\",\n    }\n    with pytest.raises(TypeError, match=\"Model must be a DbModel\"):\n        query, _ = mount_query_filter(\n            Model=FourthModel, items=input_dict, initial_comparison_operators=[]\n        )\n\n\ndef test_mount_query_filter_with_none_value():\n    class MainModel(DbModel):\n        attr_1: str = None\n        _collection: ClassVar = \"main_model\"\n\n    input_dict = {}\n    query, _ = mount_query_filter(\n        Model=MainModel, items=input_dict, initial_comparison_operators=[]\n    )\n    assert query is None\n\n\ndef test_mount_query_filter_with_regex():\n    class MyModel(DbModel):\n        attr1: str\n        attr2: str\n\n    input_dict_1 = {\"attr1_in\": \"['/^agr[oóôõ]s/i', 123, 'abc']\", \"attr2_eq\": \"123\"}\n    input_dict_2 = {\"attr1_in\": \"['/^agr[oóôõ]s/m', 123, 'abc']\", \"attr2_eq\": \"123\"}\n    input_dict_3 = {\"attr1_in\": \"['/^agr[oóôõ]s/s', 123, 'abc']\", \"attr2_eq\": \"123\"}\n\n    query_1, _ = mount_query_filter(\n        Model=MyModel, items=input_dict_1, initial_comparison_operators=[]\n    )\n    query_2, _ = mount_query_filter(\n        Model=MyModel, items=input_dict_2, initial_comparison_operators=[]\n    )\n    query_3, _ = mount_query_filter(\n        Model=MyModel, items=input_dict_3, initial_comparison_operators=[]\n    )\n    query_dct_1 = query_1.to_dict()\n    query_dct_2 = query_2.to_dict()\n    query_dct_3 = query_3.to_dict()\n    assert query_dct_1 == {\n        \"$and\": [\n            {\"attr1\": {\"$in\": [re.compile(\"^agr[oóôõ]s\", re.IGNORECASE), 123, \"abc\"]}},\n            {\"attr2\": {\"$eq\": 123}},\n        ]\n    }\n    assert query_dct_2 == {\n        \"$and\": [\n            {\"attr1\": {\"$in\": [re.compile(\"^agr[oóôõ]s\", re.MULTILINE), 123, \"abc\"]}},\n            {\"attr2\": {\"$eq\": 123}},\n        ]\n    }\n    assert query_dct_3 == {\n        \"$and\": [\n            {\"attr1\": {\"$in\": [re.compile(\"^agr[oóôõ]s\", re.DOTALL), 123, \"abc\"]}},\n            {\"attr2\": {\"$eq\": 123}},\n        ]\n    }\n\n\ndef test_mount_query_filter_with_data_types():\n    class MyClass(DbModel):\n        string_value: str\n        int_value: int\n        float_value: float\n        bool_value: bool\n        date_value: datetime\n        _collection: ClassVar = \"my_class\"\n\n    input_dct = {\n        \"string_value_eq\": \"AString\",\n        \"int_value_gt\": \"10\",\n        \"float_value_lte\": \"50.6\",\n        \"bool_value_eq\": \"True\",\n        \"date_value_lte\": \"2024-06-01\",\n    }\n    query_dct, _ = mount_query_filter(\n        Model=MyClass, items=input_dct, initial_comparison_operators=[]\n    )\n    assert query_dct.operators[0].value == \"AString\"\n    assert type(query_dct.operators[0].value) is str\n    assert query_dct.operators[1].value == 10\n    assert type(query_dct.operators[1].value) is int\n    assert query_dct.operators[2].value == 50.6\n    assert type(query_dct.operators[2].value) is float\n    assert query_dct.operators[3].value == True\n    assert type(query_dct.operators[3].value) is bool\n    assert query_dct.operators[4].value == datetime(2024, 6, 1)\n    assert type(query_dct.operators[4].value) is datetime\n\n\ndef test_logical_operator_inside_another():\n    query = and_(\n        or_(\n            eq(Model1.a, \"string_to_find_2\"),\n            eq(Model1.a, \"string_to_find_3\"),\n            and_(gt(Model1.b, \"value_b\"), gt(Model1.b, \"value_c\")),\n        ),\n        eq(Model1.a, \"string_to_find_1\"),\n    )\n    expected_dct = {\n        \"$and\": [\n            {\n                \"$or\": [\n                    {\"aAlias\": {\"$eq\": \"string_to_find_2\"}},\n                    {\"aAlias\": {\"$eq\": \"string_to_find_3\"}},\n                    {\"$and\": [{\"b\": {\"$gt\": \"value_b\"}}, {\"b\": {\"$gt\": \"value_c\"}}]},\n                ]\n            },\n            {\"aAlias\": {\"$eq\": \"string_to_find_1\"}},\n        ]\n    }\n    query_dct = query.to_dict()\n    assert query_dct == expected_dct\n\n\ndef test_sort_operator():\n    class MyNestedClass(MainBaseModel):\n        n: int\n\n    class MyClass(DbModel):\n        a: str\n        b: int\n        c: int\n        nested: MyNestedClass\n\n    sort_operator = sort(\n        (MyClass.nested.n, -1), (MyClass.b, 1), (MyClass.c, -1), (MyClass.a, 1)\n    )\n    assert sort_operator.to_dict() == {\n        \"nested.n\": -1,\n        \"b\": 1,\n        \"c\": -1,\n        \"a\": 1,\n    }\n\n    with pytest.raises(\n        ValueError, match=\"Only values 1 ascending and -1 descending are valid\"\n    ):\n        sort((MyClass.a, 2)).to_dict()\n\n\ndef test_mount_query_string_with_sort():\n    class MyClass(DbModel):\n        attr_1: str\n        attr_2: str\n        attr_3: str\n\n    input_dict = {\n        \"attr_1_eq\": \"attr 1\",\n        \"attr_2_in\": \"['value_1', 'value_2']\",\n        \"attr_3_gte\": \"10\",\n        \"_sort\": \"[['attr_1', 1], ['attr_2', -1]]\",\n    }\n\n    query, sort_operator = mount_query_filter(\n        Model=MyClass, items=input_dict, initial_comparison_operators=[]\n    )\n\n    assert query == and_(\n        eq(MyClass.attr_1, \"attr 1\"),\n        in_(MyClass.attr_2, [\"value_1\", \"value_2\"]),\n        gte(MyClass.attr_3, 10),\n    )\n    assert sort_operator == sort((MyClass.attr_1, 1), (MyClass.attr_2, -1))\n\n\ndef test_query_with_magic_methods():\n    class MyRefClass(DbModel):\n        attr_ref: str\n        _collection: ClassVar = \"my_ref_class\"\n\n    class MyMagicClass(DbModel):\n        attr_1: int\n        attr_2: int\n        attr_3: list[MyRefClass | Id]\n        _collection: ClassVar = \"my_magic_class\"\n\n    query_eq_magic_list = MyMagicClass.attr_3 == [\n        \"628b7e33e36332a5dc17a0f7\",\n        \"628b7e5de36332a5dc17a119\",\n    ]\n    query_eq_list = eq(\n        MyMagicClass.attr_3, [\"628b7e33e36332a5dc17a0f7\", \"628b7e5de36332a5dc17a119\"]\n    )\n\n    query_lt_magic = MyMagicClass.attr_1 < 123\n    query_lt = lt(MyMagicClass.attr_1, 123)\n    assert query_lt_magic == query_lt\n\n    query_lte_magic = MyMagicClass.attr_1 <= 123\n    query_lte = lte(MyMagicClass.attr_1, 123)\n    assert query_lte_magic == query_lte\n\n    query_eq_magic = MyMagicClass.attr_1 == 123\n    query_eq = eq(MyMagicClass.attr_1, 123)\n    assert query_eq_magic == query_eq\n\n    query_ne_magic = MyMagicClass.attr_1 != 123\n    query_ne = ne(MyMagicClass.attr_1, 123)\n    assert query_ne_magic == query_ne\n\n    query_gt_magic = MyMagicClass.attr_1 > 123\n    query_gt = gt(MyMagicClass.attr_1, 123)\n    assert query_gt_magic == query_gt\n\n    query_gte_magic = MyMagicClass.attr_1 >= 123\n    query_gte = gte(MyMagicClass.attr_1, 123)\n    assert query_gte_magic == query_gte\n\n    query_and_magic = ((MyMagicClass.attr_1 >= 100) | (MyMagicClass.attr_1 <= 200)) & (\n        MyMagicClass.attr_2 > 10\n    )\n    query_and = and_(\n        or_(gte(MyMagicClass.attr_1, 100), lte(MyMagicClass.attr_1, 200)),\n        gt(MyMagicClass.attr_2, 10),\n    )\n    assert query_and_magic == query_and\n\n    query_or_magic = (MyMagicClass.attr_1 == 100) & (MyMagicClass.attr_2 == 200) | (\n        MyMagicClass.attr_1 > 10\n    )\n    query_or = or_(\n        and_(eq(MyMagicClass.attr_1, 100), eq(MyMagicClass.attr_2, 200)),\n        gt(MyMagicClass.attr_1, 10),\n    )\n    assert query_or_magic == query_or\n\n\ndef test_elem_match():\n    class MyBaseModel(MainBaseModel):\n        attr_1: int\n        attr_2: str\n\n    class MyModel(DbModel):\n        attr_3: str\n        attr_4: list[MyBaseModel]\n\n    query = elem_match(\n        MyBaseModel.attr_1 == 1,\n        MyBaseModel.attr_2 == \"one\",\n        (MyBaseModel.attr_1 > 100) & (MyBaseModel.attr_1 < 200),\n        field=MyModel.attr_4,\n    )\n    query.to_dict() == {\n        \"attr_4\": {\n            \"$elemMatch\": {\n                \"attr_1\": {\"$eq\": 1},\n                \"attr_2\": {\"$eq\": \"one\"},\n                \"$and\": [{\"attr_1\": {\"$gt\": 100}}, {\"attr_1\": {\"$lt\": 200}}],\n            }\n        }\n    }\n\n\ndef test_mount_query_filter_with_elem_match():\n    class MyBaseModel(MainBaseModel):\n        attr_1: int\n        attr_2: str\n\n    class MyModel(DbModel):\n        attr_3: str\n        attr_4: list[MyBaseModel]\n        _collection: ClassVar = \"my_model\"\n\n    dict_input = {\"attr_3_eq\": \"value_3\"}\n    elem_match_operator = elem_match(\n        MyBaseModel.attr_1 == \"value_1\",\n        MyBaseModel.attr_2 == \"value_2\",\n        field=MyModel.attr_4,\n    )\n    query, _ = mount_query_filter(\n        Model=MyModel,\n        items=dict_input,\n        initial_comparison_operators=[elem_match_operator],\n    )\n    assert query.to_dict() == {\n        \"$and\": [\n            {\n                \"attr_4\": {\n                    \"$elemMatch\": {\n                        \"attr_1\": {\"$eq\": \"value_1\"},\n                        \"attr_2\": {\"$eq\": \"value_2\"},\n                    }\n                }\n            },\n            {\"attr_3\": {\"$eq\": \"value_3\"}},\n        ]\n    }\n\n\ndef test_to_dict_query_operator_default():\n    assert QueryOperator().to_dict() is None\n\n\ndef test_mount_query_filter_with_logical_operators():\n    class MyClass(DbModel):\n        attr_1: str\n        attr_2: int\n        attr_3: bool\n        _collection: ClassVar = \"my_class\"\n\n    dict_input = {\n        \"attr_3_eq\": \"true\",\n        \"_or\": \"{'attr_1_eq': 'value_1', 'attr_2_lte': '10'}\",\n    }\n    query, _ = mount_query_filter(Model=MyClass, items=dict_input)\n    assert query == and_(\n        eq(MyClass.attr_3, True),\n        or_(eq(MyClass.attr_1, \"value_1\"), lte(MyClass.attr_2, 10)),\n    )\n    assert query == (MyClass.attr_3 == True) & (\n        (MyClass.attr_1 == \"value_1\") | (MyClass.attr_2 <= 10)\n    )\n"}
{"type": "test_file", "path": "tests/test_sync_crud_db.py", "content": "from pyodmongo import (\n    DbEngine,\n    DbModel,\n    Id,\n    DbResponse,\n    ResponsePaginate,\n    Field,\n)\nfrom pyodmongo.queries import eq, gte, gt, sort\nfrom pyodmongo.engines.utils import consolidate_dict\nfrom pydantic import ConfigDict\nfrom typing import ClassVar\nfrom bson import ObjectId\nfrom datetime import datetime, UTC, timezone, timedelta\nimport pytz\nimport pytest\n\nmongo_uri = \"mongodb://localhost:27017\"\ndb_name = \"pyodmongo_pytest\"\ndb = DbEngine(\n    mongo_uri=mongo_uri, db_name=db_name, tz_info=pytz.timezone(\"America/Sao_Paulo\")\n)\n\n\nclass MyClass(DbModel):\n    attr1: str\n    attr2: str\n    random_number: int | None = None\n    _collection: ClassVar = \"my_class_test\"\n\n\n@pytest.fixture()\ndef drop_collection():\n    db._db[MyClass._collection].drop()\n    yield MyClass(attr1=\"attr_1\", attr2=\"attr_2\")\n    db._db[MyClass._collection].drop()\n\n\n@pytest.fixture()\ndef create_100_docs_in_db():\n    obj_list = []\n    for n in range(1, 101):\n        obj_list.append(MyClass(attr1=\"Value 1\", attr2=\"Value 2\", random_number=n))\n    db.save_all(obj_list)\n\n\n@pytest.fixture()\ndef new_obj():\n    yield MyClass(attr1=\"attr_1\", attr2=\"attr_2\")\n\n\ndef test_check_if_create_a_new_doc_on_save(drop_collection, new_obj):\n    result: DbResponse = db.save(new_obj)\n    assert ObjectId.is_valid(result.upserted_ids[0])\n    assert new_obj.id == result.upserted_ids[0]\n    assert isinstance(new_obj.created_at, datetime)\n    assert isinstance(new_obj.updated_at, datetime)\n    assert new_obj.created_at == new_obj.updated_at\n\n\ndef test_create_and_delete_one(drop_collection, new_obj):\n    result: DbResponse = db.save(new_obj)\n    assert result.upserted_ids[0] is not None\n    id = result.upserted_ids[0]\n    query = eq(MyClass.id, id)\n    result: DbResponse = db.delete(Model=MyClass, query=query, delete_one=True)\n    assert result.deleted_count == 1\n\n\ndef test_find_one(drop_collection, new_obj):\n    result: DbResponse = db.save(new_obj)\n    id_returned = result.upserted_ids[0]\n    obj_found = db.find_one(MyClass, eq(MyClass.id, id_returned))\n\n    assert isinstance(obj_found, MyClass)\n    assert obj_found.id == id_returned\n\n\n@pytest.fixture()\ndef objs():\n    objs = [\n        MyClass(attr1=\"attr_1\", attr2=\"attr_2\"),\n        MyClass(attr1=\"attr_1\", attr2=\"attr_2\"),\n        MyClass(attr1=\"attr_1\", attr2=\"attr_2\"),\n        MyClass(attr1=\"attr_3\", attr2=\"attr_4\"),\n        MyClass(attr1=\"attr_3\", attr2=\"attr_4\"),\n        MyClass(attr1=\"attr_5\", attr2=\"attr_6\"),\n    ]\n    return objs\n\n\ndef test_save_all_created(drop_collection, objs):\n    db.save_all(objs)\n    assert all([ObjectId.is_valid(obj.id) for obj in objs])\n\n\ndef test_update_on_save(drop_collection, objs):\n    db.save_all(objs)\n    obj = MyClass(attr1=\"value_1\", attr2=\"value_2\")\n    response: DbResponse = db.save(obj, eq(MyClass.attr1, \"attr_3\"))\n\n    assert response.matched_count == 2\n    assert response.modified_count == 2\n    assert response.upserted_ids == {}\n\n\ndef test_delete(drop_collection, objs):\n    db.save_all(objs)\n    response: DbResponse = db.delete(MyClass, eq(MyClass.attr1, \"attr_1\"))\n    assert response.deleted_count == 3\n\n\ndef test_find_many_without_paginate(drop_collection, create_100_docs_in_db):\n    obj_list_50 = db.find_many(Model=MyClass, query=gt(MyClass.random_number, 50))\n    obj_list_100 = db.find_many(Model=MyClass, query=gt(MyClass.random_number, 0))\n    assert len(obj_list_50) == 50\n    assert len(obj_list_100) == 100\n    assert all(isinstance(obj, MyClass) for obj in obj_list_100)\n\n\ndef test_find_many_with_paginate(drop_collection, create_100_docs_in_db):\n    response_paginate: ResponsePaginate = db.find_many(\n        Model=MyClass,\n        query=gt(MyClass.random_number, 50),\n        paginate=True,\n        docs_per_page=10,\n    )\n    assert isinstance(response_paginate, ResponsePaginate)\n    assert response_paginate.docs_quantity == 50\n    assert len(response_paginate.docs) == 10\n\n\ndef test_with_query_and_raw_query_none(drop_collection, create_100_docs_in_db):\n    all_obj = db.find_many(Model=MyClass)\n    assert len(all_obj) == 100\n\n\ndef test_field_alias():\n    class MyClass(DbModel):\n        first_name: str = Field(alias=\"firstName\", default=None)\n        second_name: str = Field(alias=\"secondName\", default=None)\n        third_name: str = None\n        _collection: ClassVar = \"alias_test\"\n\n    db._db[MyClass._collection].drop()\n\n    obj = MyClass(\n        first_name=\"First Name\", second_name=\"Second Name\", third_name=\"Third Name\"\n    )\n    expected_dict = {\n        \"_id\": None,\n        \"created_at\": None,\n        \"firstName\": \"First Name\",\n        \"secondName\": \"Second Name\",\n        \"third_name\": \"Third Name\",\n        \"updated_at\": None,\n    }\n    dict_to_save = consolidate_dict(obj=obj, dct={}, populate=False)\n    assert dict_to_save == expected_dict\n    db.save(obj)\n    obj_found = db.find_one(Model=MyClass)\n    assert obj == obj_found\n\n    db._db[MyClass._collection].drop()\n\n\ndef test_fields_alias_generator():\n    def to_camel(string: str) -> str:\n        return \"\".join(word.capitalize() for word in string.split(\"_\"))\n\n    def to_lower_camel(string: str) -> str:\n        words = string.split(\"_\")\n        return \"\".join(words[:1] + [word.capitalize() for word in words[1:]])\n\n    class MyClass(DbModel):\n        first_name: str = None\n        second_name: str = None\n        third_name: str = None\n        _collection: ClassVar = \"alias_test\"\n        model_config = ConfigDict(alias_generator=to_lower_camel)\n\n    db._db[MyClass._collection].drop()\n\n    obj = MyClass(\n        first_name=\"First Name\", second_name=\"Second Name\", third_name=\"Third Name\"\n    )\n    dict_to_save = consolidate_dict(obj=obj, dct={}, populate=False)\n    expected_dict = {\n        \"_id\": None,\n        \"createdAt\": None,\n        \"firstName\": \"First Name\",\n        \"secondName\": \"Second Name\",\n        \"thirdName\": \"Third Name\",\n        \"updatedAt\": None,\n    }\n    assert dict_to_save == expected_dict\n    db.save(obj)\n    obj_found = db.find_one(Model=MyClass)\n    assert obj == obj_found\n    db._db[MyClass._collection].drop()\n\n\ndef test_find_many_with_zero_results(drop_collection):\n    db.save(obj=drop_collection)\n    result = db.find_many(\n        Model=MyClass, query=eq(MyClass.attr1, \"value_that_not_exists\"), paginate=True\n    )\n\n    assert result.page_quantity == 0\n    assert result.docs_quantity == 0\n    assert result.docs == []\n\n\ndef test_find_one_with_zero_results(drop_collection):\n    db.save(obj=drop_collection)\n    result = db.find_one(\n        Model=MyClass, query=eq(MyClass.attr1, \"value_that_not_exists\")\n    )\n\n    assert result is None\n\n\ndef test_delete_one_type_error_when_query_is_not_comparison_or_logical_operator():\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        db.delete(Model=MyClass, query=\"string\", delete_one=True)\n\n\ndef test_delete_type_error_when_query_is_not_comparison_or_logical_operator():\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        db.delete(Model=MyClass, query=\"string\")\n\n\ndef test_save_type_error_when_query_is_not_comparison_or_logical_operator(\n    drop_collection,\n):\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        db.save(obj=drop_collection, query=\"string\")\n\n\ndef test_find_one_type_error_when_query_is_not_comparison_or_logical_operator():\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        db.find_one(Model=MyClass, query=\"string\")\n\n\ndef test_find_many_type_error_when_query_is_not_comparison_or_logical_operator():\n    with pytest.raises(\n        TypeError,\n        match='query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument',\n    ):\n        db.find_many(Model=MyClass, query=\"string\")\n\n\ndef test_find_with_populate():\n    class MyModel1(DbModel):\n        attr1: str\n        _collection: ClassVar = \"model1\"\n\n    class MyModel2(DbModel):\n        attr2: str\n        my_model_1: MyModel1 | Id\n        _collection: ClassVar = \"model2\"\n\n    db._db[MyModel1._collection].drop()\n    db._db[MyModel2._collection].drop()\n\n    obj_1 = MyModel1(attr1=\"attr_1\")\n    db.save(obj_1)\n    obj_2 = MyModel2(attr2=\"attr_2\", my_model_1=obj_1)\n    db.save(obj_2)\n\n    obj_found = db.find_one(Model=MyModel2, populate=True)\n    assert obj_found == obj_2\n    db._db[MyModel1._collection].drop()\n    db._db[MyModel2._collection].drop()\n\n\ndef test_find_without_populate():\n    class MyModel1(DbModel):\n        attr1: str\n        _collection: ClassVar = \"model1\"\n\n    class MyModel2(DbModel):\n        attr2: str\n        my_model_1: MyModel1 | Id\n        _collection: ClassVar = \"model2\"\n\n    db._db[MyModel1._collection].drop()\n    db._db[MyModel2._collection].drop()\n\n    obj_1 = MyModel1(attr1=\"attr_1\")\n    db.save(obj_1)\n    obj_2 = MyModel2(attr2=\"attr_2\", my_model_1=obj_1.id)\n    db.save(obj_2)\n\n    obj_found = db.find_one(Model=MyModel2)\n    assert obj_found == obj_2\n\n    db._db[MyModel1._collection].drop()\n    db._db[MyModel2._collection].drop()\n\n\nclass AsDict1(DbModel):\n    attr_1: str\n    _collection: ClassVar = \"as_dict_1\"\n\n\nclass AsDict2(DbModel):\n    attr_2: str\n    as_dict_1: list[AsDict1 | Id]\n    _collection: ClassVar = \"as_dict_2\"\n\n\n@pytest.fixture\ndef create_find_dict_collection():\n    db._db[AsDict1._collection].drop()\n    db._db[AsDict2._collection].drop()\n\n    obj1 = AsDict1(attr_1=\"Obj 1\")\n    obj2 = AsDict1(attr_1=\"Obj 2\")\n    db.save_all([obj1, obj2])\n    obj3 = AsDict2(attr_2=\"Obj 3\", as_dict_1=[obj1, obj2])\n    obj4 = AsDict2(attr_2=\"Obj 4\", as_dict_1=[obj2, obj1])\n    obj5 = AsDict2(attr_2=\"Obj 4\", as_dict_1=[obj2, obj1])\n    obj6 = AsDict2(attr_2=\"Obj 4\", as_dict_1=[obj2, obj1])\n    db.save_all([obj3, obj4, obj5, obj6])\n\n    yield\n    db._db[AsDict1._collection].drop()\n    db._db[AsDict2._collection].drop()\n\n\ndef test_find_as_dict(create_find_dict_collection):\n    obj_list = db.find_many(Model=AsDict2, as_dict=True, populate=True)\n    assert len(obj_list) == 4\n    assert type(obj_list) is list\n    for dct in obj_list:\n        assert type(dct) == dict\n    obj_dict = db.find_one(Model=AsDict2, as_dict=True, populate=True)\n    assert type(obj_dict) == dict\n\n\nclass MySortClass(DbModel):\n    attr_1: str\n    attr_2: int\n    attr_3: datetime\n    _collection: ClassVar = \"my_class_to_sort\"\n\n\n@pytest.fixture()\ndef drop_collection_for_test_sort():\n    db._db[MySortClass._collection].drop()\n    yield\n    db._db[MySortClass._collection].drop()\n\n\ndef test_sort_query(drop_collection_for_test_sort):\n    obj_list = [\n        MySortClass(\n            attr_1=\"Juliet\",\n            attr_2=100,\n            attr_3=datetime(year=2023, month=1, day=20, tzinfo=UTC),\n        ),\n        MySortClass(\n            attr_1=\"Albert\",\n            attr_2=50,\n            attr_3=datetime(year=2025, month=1, day=20, tzinfo=UTC),\n        ),\n        MySortClass(\n            attr_1=\"Zack\",\n            attr_2=30,\n            attr_3=datetime(year=2020, month=1, day=20, tzinfo=UTC),\n        ),\n        MySortClass(\n            attr_1=\"Charlie\",\n            attr_2=150,\n            attr_3=datetime(year=2027, month=1, day=20, tzinfo=UTC),\n        ),\n        MySortClass(\n            attr_1=\"Albert\",\n            attr_2=40,\n            attr_3=datetime(year=2025, month=1, day=20, tzinfo=UTC),\n        ),\n    ]\n    db.save_all(obj_list=obj_list)\n    sort_oprator = sort((MySortClass.attr_1, 1), (MySortClass.attr_2, 1))\n    result_many = db.find_many(Model=MySortClass, sort=sort_oprator)\n    assert result_many[0] == obj_list[4]\n    assert result_many[1] == obj_list[1]\n\n    sort_oprator = sort((MySortClass.attr_3, 1))\n    result_one = db.find_one(Model=MySortClass, sort=sort_oprator)\n    assert result_one == obj_list[2]\n\n    sort_oprator = [\"attr_3\", 1]\n    with pytest.raises(\n        TypeError,\n        match='sort argument must be a SortOperator from pyodmongo.queries. If you really need to make a very specific sort, use \"raw_sort\" argument',\n    ):\n        result_one = db.find_one(Model=MySortClass, sort=sort_oprator)\n\n    with pytest.raises(\n        TypeError,\n        match='sort argument must be a SortOperator from pyodmongo.queries. If you really need to make a very specific sort, use \"raw_sort\" argument',\n    ):\n        result_many = db.find_many(Model=MySortClass, sort=sort_oprator)\n\n\nclass ClassWithDate(DbModel):\n    name: str\n    date: datetime\n    _collection: ClassVar = \"class_with_date\"\n\n\n@pytest.fixture()\ndef drop_collection_class_with_date():\n    db._db[ClassWithDate._collection].drop()\n    yield\n    db._db[ClassWithDate._collection].drop()\n\n\ndef test_save_and_retrieve_objs_with_datetime(drop_collection_class_with_date):\n    tz = timezone(timedelta(hours=-3))\n    date = datetime(\n        year=2024,\n        month=4,\n        day=24,\n        hour=23,\n        minute=0,\n        second=0,\n        tzinfo=tz,\n    )\n    obj = ClassWithDate(name=\"A name\", date=date)\n    db.save(obj)\n    query = (ClassWithDate.date >= datetime(2024, 4, 24, 22, 30, 0, tzinfo=tz)) & (\n        ClassWithDate.date <= datetime(2024, 4, 24, 23, 30, 0, tzinfo=tz)\n    )\n    obj_found: ClassWithDate = db.find_one(Model=ClassWithDate, query=query)\n    assert obj_found.date == date\n"}
{"type": "test_file", "path": "tests/test_save_dict.py", "content": "from pydantic import BaseModel\nfrom pyodmongo import DbModel, Field, Id, MainBaseModel\nfrom typing import ClassVar\nfrom bson import ObjectId\nfrom pyodmongo.engines.utils import consolidate_dict\nimport pytest\n\n\ndef test_save_dict_is_correct():\n    class Lv3(DbModel):\n        attr_lv3_one: str = Field(alias=\"attrLv3One\")\n        attr_lv3_two: str\n        _collection: ClassVar = \"lv3\"\n\n    class Lv2(DbModel):\n        attr_lv2_one: str = Field(alias=\"attrLv2One\")\n        attr_lv2_two: str\n        lv3: Lv3 | Id = Field(alias=\"lv3Alias\")\n        _collection: ClassVar = \"lv2\"\n\n    class Lv1(DbModel):\n        attr_lv1_one: str = Field(alias=\"attrLv1One\")\n        attr_lv1_two: str\n        lv2: Lv2 | Id\n        lv2_list: list[Lv2]\n        lv2_list_ref: list[Id | Lv2]\n        lv3_ref: Id | Lv3 = Field(alias=\"lv3Ref\")\n        lv3_list_ref: list[Lv3 | Id]\n        _collection: ClassVar = \"lv1\"\n\n    class Lv1Son(Lv1):\n        lv1_son_attr: str\n\n    id_1 = \"64e8fe13e6dcc2a63c365df4\"\n    id_2 = \"64e8fe13e6dcc2a63c365df5\"\n    id_3 = \"64e8fe13e6dcc2a63c365df6\"\n    id_4 = \"64e8fe13e6dcc2a63c365df7\"\n    id_5 = \"64e8fe13e6dcc2a63c365df8\"\n\n    obj_lv3_1 = Lv3(\n        id=id_1, attr_lv3_one=\"valor_attr_lv3_one\", attr_lv3_two=\"valor_attr_lv3_two\"\n    )\n\n    obj_lv3_2 = Lv3(\n        id=id_2, attr_lv3_one=\"valor_attr_lv3_one\", attr_lv3_two=\"valor_attr_lv3_two\"\n    )\n\n    obj_lv_2_1 = Lv2(\n        id=id_3,\n        attr_lv2_one=\"valor_attr_lv2_one\",\n        attr_lv2_two=\"valor_attr_lv2_two\",\n        lv3=obj_lv3_1,\n    )\n\n    obj_lv_2_2 = Lv2(\n        id=id_4,\n        attr_lv2_one=\"valor_attr_lv2_one\",\n        attr_lv2_two=\"valor_attr_lv2_two\",\n        lv3=obj_lv3_2,\n    )\n\n    obj_lv1_son = Lv1Son(\n        id=id_5,\n        lv1_son_attr=\"value_lv1_son_attr\",\n        attr_lv1_one=\"value_attr_lv1_one\",\n        attr_lv1_two=\"value_attr_lv1_two\",\n        lv2=obj_lv_2_1,\n        lv2_list=[obj_lv_2_1, obj_lv_2_2],\n        lv2_list_ref=[obj_lv_2_1, obj_lv_2_2],\n        lv3_ref=obj_lv3_2,\n        lv3_list_ref=[obj_lv3_2, obj_lv3_1],\n    )\n\n    obj_lv3_1_expected_dict = {\n        \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n        \"attrLv3One\": \"valor_attr_lv3_one\",\n        \"attr_lv3_two\": \"valor_attr_lv3_two\",\n        \"created_at\": None,\n        \"updated_at\": None,\n    }\n\n    obj_lv_2_1_expected_dict = {\n        \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df6\"),\n        \"attrLv2One\": \"valor_attr_lv2_one\",\n        \"attr_lv2_two\": \"valor_attr_lv2_two\",\n        \"created_at\": None,\n        \"lv3Alias\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n        \"updated_at\": None,\n    }\n\n    obj_lv1_son_expected_dict = {\n        \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df8\"),\n        \"attrLv1One\": \"value_attr_lv1_one\",\n        \"attr_lv1_two\": \"value_attr_lv1_two\",\n        \"created_at\": None,\n        \"lv1_son_attr\": \"value_lv1_son_attr\",\n        \"lv2\": ObjectId(\"64e8fe13e6dcc2a63c365df6\"),\n        \"lv2_list\": [\n            {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df6\"),\n                \"attrLv2One\": \"valor_attr_lv2_one\",\n                \"attr_lv2_two\": \"valor_attr_lv2_two\",\n                \"created_at\": None,\n                \"lv3Alias\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n                \"updated_at\": None,\n            },\n            {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df7\"),\n                \"attrLv2One\": \"valor_attr_lv2_one\",\n                \"attr_lv2_two\": \"valor_attr_lv2_two\",\n                \"created_at\": None,\n                \"lv3Alias\": ObjectId(\"64e8fe13e6dcc2a63c365df5\"),\n                \"updated_at\": None,\n            },\n        ],\n        \"lv2_list_ref\": [\n            ObjectId(\"64e8fe13e6dcc2a63c365df6\"),\n            ObjectId(\"64e8fe13e6dcc2a63c365df7\"),\n        ],\n        \"lv3Ref\": ObjectId(\"64e8fe13e6dcc2a63c365df5\"),\n        \"lv3_list_ref\": [\n            ObjectId(\"64e8fe13e6dcc2a63c365df5\"),\n            ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n        ],\n        \"updated_at\": None,\n    }\n\n    assert (\n        consolidate_dict(obj=obj_lv3_1, dct={}, populate=False)\n        == obj_lv3_1_expected_dict\n    )\n    assert (\n        consolidate_dict(obj=obj_lv_2_1, dct={}, populate=False)\n        == obj_lv_2_1_expected_dict\n    )\n    assert (\n        consolidate_dict(obj=obj_lv1_son, dct={}, populate=False)\n        == obj_lv1_son_expected_dict\n    )\n\n    obj_lv3_1_expected_dict = {\n        \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"attrLv3One\": \"valor_attr_lv3_one\",\n        \"attr_lv3_two\": \"valor_attr_lv3_two\",\n    }\n    obj_lv_2_1_expected_dict = {\n        \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df6\"),\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"attrLv2One\": \"valor_attr_lv2_one\",\n        \"attr_lv2_two\": \"valor_attr_lv2_two\",\n        \"lv3Alias\": {\n            \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n            \"created_at\": None,\n            \"updated_at\": None,\n            \"attrLv3One\": \"valor_attr_lv3_one\",\n            \"attr_lv3_two\": \"valor_attr_lv3_two\",\n        },\n    }\n    obj_lv1_son_expected_dict = {\n        \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df8\"),\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"attrLv1One\": \"value_attr_lv1_one\",\n        \"attr_lv1_two\": \"value_attr_lv1_two\",\n        \"lv2\": {\n            \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df6\"),\n            \"created_at\": None,\n            \"updated_at\": None,\n            \"attrLv2One\": \"valor_attr_lv2_one\",\n            \"attr_lv2_two\": \"valor_attr_lv2_two\",\n            \"lv3Alias\": {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n                \"created_at\": None,\n                \"updated_at\": None,\n                \"attrLv3One\": \"valor_attr_lv3_one\",\n                \"attr_lv3_two\": \"valor_attr_lv3_two\",\n            },\n        },\n        \"lv2_list\": [\n            {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df6\"),\n                \"created_at\": None,\n                \"updated_at\": None,\n                \"attrLv2One\": \"valor_attr_lv2_one\",\n                \"attr_lv2_two\": \"valor_attr_lv2_two\",\n                \"lv3Alias\": {\n                    \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n                    \"created_at\": None,\n                    \"updated_at\": None,\n                    \"attrLv3One\": \"valor_attr_lv3_one\",\n                    \"attr_lv3_two\": \"valor_attr_lv3_two\",\n                },\n            },\n            {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df7\"),\n                \"created_at\": None,\n                \"updated_at\": None,\n                \"attrLv2One\": \"valor_attr_lv2_one\",\n                \"attr_lv2_two\": \"valor_attr_lv2_two\",\n                \"lv3Alias\": {\n                    \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df5\"),\n                    \"created_at\": None,\n                    \"updated_at\": None,\n                    \"attrLv3One\": \"valor_attr_lv3_one\",\n                    \"attr_lv3_two\": \"valor_attr_lv3_two\",\n                },\n            },\n        ],\n        \"lv2_list_ref\": [\n            {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df6\"),\n                \"created_at\": None,\n                \"updated_at\": None,\n                \"attrLv2One\": \"valor_attr_lv2_one\",\n                \"attr_lv2_two\": \"valor_attr_lv2_two\",\n                \"lv3Alias\": {\n                    \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n                    \"created_at\": None,\n                    \"updated_at\": None,\n                    \"attrLv3One\": \"valor_attr_lv3_one\",\n                    \"attr_lv3_two\": \"valor_attr_lv3_two\",\n                },\n            },\n            {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df7\"),\n                \"created_at\": None,\n                \"updated_at\": None,\n                \"attrLv2One\": \"valor_attr_lv2_one\",\n                \"attr_lv2_two\": \"valor_attr_lv2_two\",\n                \"lv3Alias\": {\n                    \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df5\"),\n                    \"created_at\": None,\n                    \"updated_at\": None,\n                    \"attrLv3One\": \"valor_attr_lv3_one\",\n                    \"attr_lv3_two\": \"valor_attr_lv3_two\",\n                },\n            },\n        ],\n        \"lv3Ref\": {\n            \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df5\"),\n            \"created_at\": None,\n            \"updated_at\": None,\n            \"attrLv3One\": \"valor_attr_lv3_one\",\n            \"attr_lv3_two\": \"valor_attr_lv3_two\",\n        },\n        \"lv3_list_ref\": [\n            {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df5\"),\n                \"created_at\": None,\n                \"updated_at\": None,\n                \"attrLv3One\": \"valor_attr_lv3_one\",\n                \"attr_lv3_two\": \"valor_attr_lv3_two\",\n            },\n            {\n                \"_id\": ObjectId(\"64e8fe13e6dcc2a63c365df4\"),\n                \"created_at\": None,\n                \"updated_at\": None,\n                \"attrLv3One\": \"valor_attr_lv3_one\",\n                \"attr_lv3_two\": \"valor_attr_lv3_two\",\n            },\n        ],\n        \"lv1_son_attr\": \"value_lv1_son_attr\",\n    }\n    assert (\n        consolidate_dict(obj=obj_lv3_1, dct={}, populate=True)\n        == obj_lv3_1_expected_dict\n    )\n    assert (\n        consolidate_dict(obj=obj_lv_2_1, dct={}, populate=True)\n        == obj_lv_2_1_expected_dict\n    )\n    assert (\n        consolidate_dict(obj=obj_lv1_son, dct={}, populate=True)\n        == obj_lv1_son_expected_dict\n    )\n\n\ndef test_save_dict_with_basemodel_reference():\n    class BaseModelClass(MainBaseModel):\n        attr_bm: str\n\n    class DbModelClass(DbModel):\n        attr_dbm: str\n        bm: BaseModelClass\n        _collection: ClassVar = \"db_model_class\"\n\n    obj = DbModelClass(attr_dbm=\"attr_dbm\", bm=BaseModelClass(attr_bm=\"attr_bm\"))\n\n    dct = consolidate_dict(obj=obj, dct={}, populate=False)\n    assert dct == {\n        \"_id\": None,\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"attr_dbm\": \"attr_dbm\",\n        \"bm\": {\"attr_bm\": \"attr_bm\"},\n    }\n\n\ndef test_field_with_union_more_than_two():\n    class MyFirstClass(DbModel):\n        attr_first: str = None\n        _collection: ClassVar = \"my_first_class\"\n\n    class MyClass(DbModel):\n        email: str = None\n        mfc: list[MyFirstClass | Id] | None = None\n        _collection: ClassVar = \"my_class\"\n\n    obj = MyClass(mfc=None)\n    dct = consolidate_dict(obj=obj, dct={}, populate=False)\n    assert dct == {\n        \"_id\": None,\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"email\": None,\n        \"mfc\": None,\n    }\n\n\ndef test_multiples_nested_references():\n    class MyType1(MainBaseModel):\n        attr_type_1: str = None\n\n    class MyType2(MainBaseModel):\n        attr_type_2: str = None\n\n    class MyType3(MainBaseModel):\n        attr_type_3: str = None\n\n    class DbMyType(DbModel):\n        attr_db: str = None\n        my_type: MyType1 | MyType2 | MyType3 | None = None\n        _collection: ClassVar = \"db_my_type\"\n\n    obj1 = DbMyType(my_type=MyType1())\n    obj2 = DbMyType(my_type=MyType2())\n    obj3 = DbMyType(my_type=MyType3())\n    dct1 = {\n        \"_id\": None,\n        \"attr_db\": None,\n        \"created_at\": None,\n        \"my_type\": {\"attr_type_1\": None},\n        \"updated_at\": None,\n    }\n    dct2 = {\n        \"_id\": None,\n        \"attr_db\": None,\n        \"created_at\": None,\n        \"my_type\": {\"attr_type_2\": None},\n        \"updated_at\": None,\n    }\n    dct3 = {\n        \"_id\": None,\n        \"attr_db\": None,\n        \"created_at\": None,\n        \"my_type\": {\"attr_type_3\": None},\n        \"updated_at\": None,\n    }\n\n    assert consolidate_dict(obj=obj1, dct={}, populate=False) == dct1\n    assert consolidate_dict(obj=obj2, dct={}, populate=False) == dct2\n    assert consolidate_dict(obj=obj3, dct={}, populate=False) == dct3\n\n\ndef test_list_of_ids_with_none():\n    class MyType1(DbModel):\n        attr_type_1: str = None\n        _collection: ClassVar = \"my_type1\"\n\n    class DbMyType(DbModel):\n        attr_db: str = None\n        my_type: list[MyType1 | Id] = None\n        _collection: ClassVar = \"db_my_type\"\n\n    obj = DbMyType()\n    dct_expected = {\n        \"_id\": None,\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"attr_db\": None,\n        \"my_type\": None,\n    }\n    assert consolidate_dict(obj=obj, dct={}, populate=False) == dct_expected\n\n    class DbMyType(DbModel):\n        attr_db: str = None\n        my_type: list[Id] = None\n        _collection: ClassVar = \"db_my_type\"\n\n    obj = DbMyType()\n    assert consolidate_dict(obj=obj, dct={}, populate=False) == dct_expected\n\n\ndef test_fields_with_reference():\n    class Model1(DbModel):\n        attr_1: str = None\n        ref_id: Id\n        list_ref_id: list[Id]\n        _collection: ClassVar = \"model1\"\n\n    class Model2(DbModel):\n        attr_2: str = None\n        ref_id: Model1 | Id\n        list_ref_id: list[Model1 | Id]\n        _collection: ClassVar = \"model2\"\n\n    id_1 = str(ObjectId())\n    id_2 = str(ObjectId())\n    id_3 = str(ObjectId())\n    obj_1 = Model1(ref_id=id_1, list_ref_id=[id_2, id_3])\n\n    id_4 = str(ObjectId())\n    id_5 = str(ObjectId())\n    id_6 = str(ObjectId())\n    obj_2 = Model2(ref_id=id_4, list_ref_id=[id_5, id_6])\n\n    dct_expected_1 = {\n        \"_id\": None,\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"attr_1\": None,\n        \"ref_id\": ObjectId(id_1),\n        \"list_ref_id\": [ObjectId(id_2), ObjectId(id_3)],\n    }\n\n    dct_expected_2 = {\n        \"_id\": None,\n        \"created_at\": None,\n        \"updated_at\": None,\n        \"attr_2\": None,\n        \"ref_id\": ObjectId(id_4),\n        \"list_ref_id\": [ObjectId(id_5), ObjectId(id_6)],\n    }\n    assert consolidate_dict(obj=obj_1, dct={}, populate=False) == dct_expected_1\n    assert consolidate_dict(obj=obj_2, dct={}, populate=False) == dct_expected_2\n\n\ndef test_basemodel_exception():\n    class PydanticModel(BaseModel):\n        att1: str = \"Attr 1\"\n\n    class PyodmongoModel(MainBaseModel):\n        att1: str = \"Attr 1\"\n\n    class DbModelClass(DbModel):\n        attr2: str = \"Attr 2\"\n        bm: PyodmongoModel = PyodmongoModel()\n        _collection: ClassVar = \"db_model_class\"\n\n    obj = DbModelClass()\n    consolidate_dict(obj=obj, dct={}, populate=False)\n    obj.bm = PydanticModel()\n    with pytest.raises(\n        TypeError,\n        match=\"The PydanticModel class inherits from Pydantic's BaseModel class. Try switching to PyODMongo's MainBaseModel class\",\n    ):\n        consolidate_dict(obj=obj, dct={}, populate=False)\n"}
{"type": "test_file", "path": "tests/test_sync_aggregate.py", "content": "from pyodmongo import DbModel, DbEngine, Id\nfrom typing import ClassVar\nimport pytest_asyncio\nimport pytest\n\nmongo_uri = \"mongodb://localhost:27017\"\ndb_name = \"pyodmongo_pytest\"\nengine = DbEngine(mongo_uri=mongo_uri, db_name=db_name)\n\n\nclass Customer(DbModel):\n    name: str\n    email: str\n    _collection: ClassVar = \"customers\"\n\n\nclass Order(DbModel):\n    customer: Customer | Id\n    value: float\n    _collection: ClassVar = \"orders\"\n\n\nclass OrdersByCustomers(DbModel):\n    count: int\n    total_value: float\n    _collection: ClassVar = \"orders\"\n    _pipeline: ClassVar = [\n        {\n            \"$group\": {\n                \"_id\": \"$customer\",\n                \"count\": {\"$count\": {}},\n                \"total_value\": {\"$sum\": \"$value\"},\n            }\n        }\n    ]\n\n\n@pytest.fixture()\ndef drop_collections():\n    engine._db[Customer._collection].drop()\n    engine._db[Order._collection].drop()\n    yield\n    engine._db[Customer._collection].drop()\n    engine._db[Order._collection].drop()\n\n\ndef test_pipeline_aggregate(drop_collections):\n    customer_1 = Customer(name=\"Customer 1\", email=\"customer1@email.com\")\n    customer_2 = Customer(name=\"Customer 2\", email=\"customer2@email.com\")\n    customer_3 = Customer(name=\"Customer 3\", email=\"customer3@email.com\")\n    engine.save_all([customer_1, customer_2, customer_3])\n    for n in range(1, 11):\n        engine.save(Order(customer=customer_1, value=n))\n    for n in range(1, 5):\n        engine.save(Order(customer=customer_2, value=n))\n    for n in range(1, 8):\n        engine.save(Order(customer=customer_3, value=n))\n\n    objs = engine.find_many(Model=OrdersByCustomers)\n    customer_1_aggregate: OrdersByCustomers = list(\n        filter(lambda x: x.id == customer_1.id, objs)\n    )[0]\n    customer_2_aggregate: OrdersByCustomers = list(\n        filter(lambda x: x.id == customer_2.id, objs)\n    )[0]\n    customer_3_aggregate: OrdersByCustomers = list(\n        filter(lambda x: x.id == customer_3.id, objs)\n    )[0]\n\n    assert customer_1_aggregate.count == 10\n    assert customer_1_aggregate.total_value == 55\n    assert customer_2_aggregate.count == 4\n    assert customer_2_aggregate.total_value == 10\n    assert customer_3_aggregate.count == 7\n    assert customer_3_aggregate.total_value == 28\n"}
{"type": "test_file", "path": "tests/test_version.py", "content": "import pydantic\nimport platform\nimport sys\nimport pymongo\nimport motor\nfrom pyodmongo import version\n\n\ndef test_version():\n    info = {\n        \"PyODMongo version\": \"__VERSION__\",\n        \"Pydantic version\": pydantic.version.VERSION,\n        \"Pymongo version\": pymongo.__version__,\n        \"Motor version\": motor._version.version,\n        \"Python version\": sys.version,\n        \"Platform\": platform.platform(),\n    }\n    response_expected = \"\\n\".join([f\"{key}: {value}\" for key, value in info.items()])\n    assert response_expected == version.response\n"}
{"type": "test_file", "path": "tests/test_verify_subclass.py", "content": "from pyodmongo.services.verify_subclasses import is_subclass\nfrom pyodmongo import DbModel, MainBaseModel\nfrom pyodmongo.models.query_operators import (\n    QueryOperator,\n    LogicalOperator,\n    _LogicalOperator,\n    ComparisonOperator,\n    ElemMatchOperator,\n)\n\n\ndef test_is_subclass():\n    assert is_subclass(class_to_verify=QueryOperator, subclass=QueryOperator) is True\n    assert is_subclass(class_to_verify=LogicalOperator, subclass=QueryOperator) is True\n    assert is_subclass(class_to_verify=_LogicalOperator, subclass=QueryOperator) is True\n    assert (\n        is_subclass(class_to_verify=ComparisonOperator, subclass=QueryOperator) is True\n    )\n    assert (\n        is_subclass(class_to_verify=ElemMatchOperator, subclass=QueryOperator) is True\n    )\n    assert is_subclass(class_to_verify=DbModel, subclass=QueryOperator) is False\n    assert is_subclass(class_to_verify=MainBaseModel, subclass=QueryOperator) is False\n"}
{"type": "source_file", "path": "coverage.py", "content": "import json\n\nwith open(\"coverage.json\", \"r\") as file:\n    coverage = json.load(file)\n    coverage_percentage_string = coverage[\"totals\"][\"percent_covered_display\"] + \"%\"\nwith open(\"htmlcov/coverage_badge.json\", \"w\") as file:\n    json.dump(\n        {\n            \"schemaVersion\": 1,\n            \"label\": \"Coverage\",\n            \"message\": coverage_percentage_string,\n            \"color\": \"green\",\n        },\n        file,\n        indent=4,\n    )\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/aggregation_async.py", "content": "from pyodmongo import DbModel, AsyncDbEngine, Id\nfrom typing import ClassVar\nimport asyncio\n\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Customer(DbModel):\n    name: str\n    email: str\n    _collection: ClassVar = \"customers\"\n\n\nclass Order(DbModel):\n    customer: Customer | Id\n    value: float\n    _collection: ClassVar = \"orders\"\n\n\nclass OrdersByCustomers(DbModel):\n    count: int\n    total_value: float\n    _collection: ClassVar = \"orders\"\n    _pipeline: ClassVar = [\n        {\n            \"$group\": {\n                \"_id\": \"$customer\",\n                \"count\": {\"$count\": {}},\n                \"total_value\": {\"$sum\": \"$value\"},\n            }\n        }\n    ]\n\n\nasync def main():\n    result: list[OrdersByCustomers] = await engine.find_many(Model=OrdersByCustomers)\n\n\nasyncio.run(main())\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/aggregation_sync.py", "content": "from pyodmongo import DbModel, DbEngine, Id\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Customer(DbModel):\n    name: str\n    email: str\n    _collection: ClassVar = \"customers\"\n\n\nclass Order(DbModel):\n    customer: Customer | Id\n    value: float\n    _collection: ClassVar = \"orders\"\n\n\nclass OrdersByCustomers(DbModel):\n    count: int\n    total_value: float\n    _collection: ClassVar = \"orders\"\n    _pipeline: ClassVar = [\n        {\n            \"$group\": {\n                \"_id\": \"$customer\",\n                \"count\": {\"$count\": {}},\n                \"total_value\": {\"$sum\": \"$value\"},\n            }\n        }\n    ]\n\n\nresult: list[OrdersByCustomers] = engine.find_many(Model=OrdersByCustomers)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/and_magic.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = (Product.price > 10) & (Product.price <= 50)\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/docs_release_notes.py", "content": "import re\nimport requests\nfrom datetime import datetime\nfrom pathlib import Path\nimport shutil\n\nrelease_notes_api_url = \"https://api.github.com/repos/mauro-andre/pyodmongo/releases\"\nrelease_notes = requests.get(url=release_notes_api_url).json()\n\nen_file_path = Path().absolute() / \".docs_tmp\" / \"en\" / \"release_notes.md\"\npt_file_path = Path().absolute() / \".docs_tmp\" / \"pt-BR\" / \"release_notes.md\"\n\n\ndef convert_text(input_text):\n    pattern = r\"(@[\\w-]+) in (\\S+)\"\n\n    def replace_link(match):\n        name = match.group(1)\n        url = match.group(2)\n        return f'<a href=\"{url}\" target=\"_blank\">{name}</a>'\n\n    converted_text = re.sub(pattern, replace_link, input_text)\n    return converted_text\n\n\nwith open(en_file_path, \"w\") as file:\n    file.write(\"# <center>Release notes</center> #\\n\\n\")\n    for release_note in release_notes:\n        name = release_note.get(\"name\")\n        published_at = datetime.fromisoformat(\n            release_note.get(\"published_at\")\n        ).strftime(\"%Y-%m-%d\")\n        body: str = release_note.get(\"body\")\n        body = convert_text(body)\n        body = body.replace(\"\\n\", \"\\n\\n\")\n        file.write(\"---\\n\")\n        file.write(f\"## {name} - {published_at}\\n\")\n        file.write(f\"{body}\\n\\n\")\n\nshutil.copy(en_file_path, pt_file_path)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/eq_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import eq\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = eq(Product.name, \"Box\")\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/elem_match_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, MainBaseModel, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import elem_match\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(MainBaseModel):\n    name: str\n    price: float\n    is_available: bool\n\n\nclass Order(DbModel):\n    code: str\n    products: list[Product]\n    _collection: ClassVar = \"orders\"\n\n\nquery = elem_match(Product.name == \"Box\", Product.price == 50, field=Order.products)\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/delete_sync.py", "content": "from pyodmongo import DbEngine, DbModel, DbResponse\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.price <= 100\n\nresponse: DbResponse = engine.delete(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/delete_one_async.py", "content": "from pyodmongo import AsyncDbEngine, DbModel, DbResponse\nfrom typing import ClassVar\nimport asyncio\n\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nasync def main():\n    query = Product.name == \"Box\"\n\n    response: DbResponse = await engine.delete(\n        Model=Product, query=query, delete_one=True\n    )\n\n\nasyncio.run(main())\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/embedded_basemodel.py", "content": "from pyodmongo import DbModel\nfrom pydantic import BaseModel\nfrom typing import ClassVar\n\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: str\n\n\nclass User(DbModel):\n    username: str\n    password: str\n    address: Address\n    _collection: ClassVar = \"users\"\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/find_one_async.py", "content": "from pyodmongo import AsyncDbEngine, DbModel\nfrom typing import ClassVar\nimport asyncio\n\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nasync def main():\n    query = Product.name == \"Box\"\n    box: Product = await engine.find_one(Model=Product, query=query)\n\n\nasyncio.run(main())\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/find_many_sync_paginate.py", "content": "from pyodmongo import DbEngine, DbModel, ResponsePaginate\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = (Product.price >= 50) & (Product.price < 100)\n\nresponse: ResponsePaginate = engine.find_many(\n    Model=Product, query=query, paginate=True, current_page=2, docs_per_page=100\n)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/fastapi.py", "content": "from fastapi import FastAPI, Request\nfrom pyodmongo import DbModel, AsyncDbEngine\nfrom pyodmongo.queries import mount_query_filter\nfrom typing import ClassVar\n\napp = FastAPI()\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass MyModel(DbModel):\n    attr1: str\n    attr2: str\n    attr3: int\n    _collection: ClassVar = \"my_model\"\n\n\n@app.get(\"/\", response_model=list[MyModel])\nasync def get_route(request: Request):\n    query, sort = mount_query_filter(\n        Model=MyModel,\n        items=request.query_params._dict,\n        initial_comparison_operators=[],\n    )\n    return await engine.find_many(Model=MyModel, query=query, sort=sort)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/lt_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import lt\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = lt(Product.price, 10)\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/gte_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import gte\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = gte(Product.price, 10)\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/eq_magic.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.name == \"Box\"\nbox: Product = engine.find_one(Model=Product, query=query)"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/lte_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import lte\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = lte(Product.price, 10)\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/gt_magic.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.price > 10\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/find_one_sync.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.name == \"Box\"\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/ne_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import ne\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = ne(Product.name, \"Box\")\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/find_many_async.py", "content": "from pyodmongo import AsyncDbEngine, DbModel\nfrom typing import ClassVar\nimport asyncio\n\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nasync def main():\n    query = (Product.price >= 50) & (Product.price < 100)\n\n    products: list[Product] = await engine.find_many(Model=Product, query=query)\n\n\nasyncio.run(main())\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/nin_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import nin\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = nin(Product.name, [\"Ball\", \"Box\", \"Toy\"])\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/delete_one_sync.py", "content": "from pyodmongo import DbEngine, DbModel, DbResponse\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.name == \"Box\"\n\nresponse: DbResponse = engine.delete(Model=Product, query=query, delete_one=True)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/or_magic.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = (Product.name == \"Box\") | (Product.price == 100)\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/save_sync.py", "content": "from pyodmongo import DbEngine, DbModel, DbResponse\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nbox = Product(name=\"Box\", price=\"5.99\", is_available=True)\n\nresponse: DbResponse = engine.save(box)\n"}
{"type": "source_file", "path": "pyodmongo/__init__.py", "content": "from .engines.engines import AsyncDbEngine, DbEngine\nfrom .models.db_model import DbModel, MainBaseModel\nfrom .models.id_model import Id\nfrom .models.db_decimal import DbDecimal\nfrom .models.paginate import ResponsePaginate\nfrom .models.responses import DbResponse\nfrom .models.fields import Field\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/save_async.py", "content": "from pyodmongo import AsyncDbEngine, DbModel, DbResponse\nfrom typing import ClassVar\nimport asyncio\n\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nbox = Product(name=\"Box\", price=\"5.99\", is_available=True)\n\n\nasync def main():\n    response: DbResponse = await engine.save(box)\n\n\nasyncio.run(main())\n"}
{"type": "source_file", "path": "pyodmongo/engines/utils.py", "content": "from pydantic import BaseModel\nfrom bson import ObjectId\nfrom ..models.id_model import Id\nfrom ..models.db_model import MainBaseModel\nfrom ..models.db_field_info import DbField\nfrom ..models.db_decimal import DbDecimal\nfrom ..services.reference_pipeline import resolve_reference_pipeline\nfrom ..services.verify_subclasses import is_subclass\nfrom decimal import Decimal\nfrom bson import Decimal128\n\n\ndef consolidate_dict(obj: MainBaseModel, dct: dict, populate: bool):\n    \"\"\"\n    Recursively consolidates the attributes of a Pydantic model into a dictionary,\n    handling nested models, list fields, and references appropriately based on the model's\n    field specifications.\n\n    Args:\n        obj (MainBaseModel): The PyODMongo model instance from which to extract data.\n        dct (dict): The dictionary into which data should be consolidated. This dictionary\n                    is modified in-place.\n\n    Returns:\n        dict: The modified dictionary with model data consolidated into it, including handling\n              of MongoDB ObjectId conversions and nested structures.\n\n    Description:\n        This function iterates over each field of the provided model instance, extracting the\n        value and associated metadata. Depending on whether the field contains model data,\n        is a list, or is a reference, the function appropriately processes the value to fit\n        MongoDB storage requirements, including converting to ObjectIds where necessary.\n        The function is recursive for nested models and lists of models.\n    \"\"\"\n    for field, field_info in obj.model_fields.items():\n        value = getattr(obj, field)\n        try:\n            db_field_info: DbField = getattr(obj.__class__, field)\n        except AttributeError:\n            if is_subclass(class_to_verify=obj.__class__, subclass=BaseModel):\n                raise TypeError(\n                    f\"The {obj.__class__.__name__} class inherits from Pydantic's BaseModel class. Try switching to PyODMongo's MainBaseModel class\"\n                )\n        alias = db_field_info.field_alias\n        has_model_fields = db_field_info.has_model_fields\n        is_list = db_field_info.is_list\n        by_reference = db_field_info.by_reference and not populate\n        if has_model_fields:\n            if value is None:\n                dct[alias] = None\n                continue\n            if not is_list:\n                if by_reference:\n                    try:\n                        dct[alias] = ObjectId(value.id)\n                    except AttributeError:\n                        dct[alias] = ObjectId(value)\n                else:\n                    dct[alias] = {}\n                    consolidate_dict(obj=value, dct=dct[alias], populate=populate)\n            else:\n                if by_reference:\n                    try:\n                        dct[alias] = [ObjectId(o.id) for o in value]\n                    except AttributeError:\n                        dct[alias] = [ObjectId(o) for o in value]\n                else:\n                    dct[alias] = []\n                    for v in value:\n                        obj_lst_elem = {}\n                        consolidate_dict(obj=v, dct=obj_lst_elem, populate=populate)\n                        dct[alias].append(obj_lst_elem)\n        else:\n            if db_field_info.field_type == Id and value is not None:\n                if is_list:\n                    dct[alias] = [ObjectId(o) for o in value if ObjectId.is_valid(o)]\n                else:\n                    dct[alias] = ObjectId(value) if ObjectId.is_valid(value) else value\n            elif (\n                db_field_info.field_type == Decimal\n                or db_field_info.field_type == DbDecimal\n            ) and value is not None:\n                if is_list:\n                    dct[alias] = [Decimal128(str(o)) for o in value]\n                else:\n                    dct[alias] = Decimal128(str(value))\n            else:\n                dct[alias] = value\n    return dct\n\n\ndef mount_base_pipeline(\n    Model,\n    query: dict,\n    sort: dict,\n    populate: bool,\n    pipeline: list | None,\n    populate_db_fields: list[DbField] | None,\n):\n    \"\"\"\n    Constructs a basic MongoDB aggregation pipeline based on the provided query, sort, and\n    model settings, optionally including reference population stages.\n\n    Args:\n        Model (type[Model]): The model class defining the MongoDB collection and its aggregation logic.\n        query (dict): MongoDB query dictionary to filter the documents.\n        sort (dict): Dictionary defining the sorting order of the documents.\n        populate (bool): Flag indicating whether to include reference population stages in the pipeline.\n\n    Returns:\n        list: The MongoDB aggregation pipeline configured with match, sort, and optionally population stages.\n\n    Description:\n        This function constructs a MongoDB aggregation pipeline using the provided model's\n        internal pipeline stages and the specified query and sort parameters. If 'populate' is\n        true, reference population stages defined in the model are included to resolve document\n        references as part of the aggregation process.\n    \"\"\"\n    match_stage = [{\"$match\": query}]\n    sort_stage = [{\"$sort\": sort}] if sort != {} else []\n    model_stage = Model._pipeline\n    if pipeline:\n        return match_stage + pipeline + sort_stage\n    if model_stage != []:\n        return match_stage + model_stage + sort_stage\n    if populate:\n        reference_stage = resolve_reference_pipeline(\n            cls=Model, pipeline=[], populate_db_fields=populate_db_fields\n        )\n        return match_stage + reference_stage + sort_stage\n    else:\n        return match_stage + sort_stage\n"}
{"type": "source_file", "path": "pyodmongo/engines/engines.py", "content": "from motor.motor_asyncio import AsyncIOMotorClient\nfrom pymongo import MongoClient, UpdateMany, DeleteOne, DeleteMany\nfrom pymongo.results import BulkWriteResult\nfrom datetime import datetime, timezone\nfrom bson import ObjectId\nfrom bson.codec_options import CodecOptions\nfrom ..models.db_model import DbModel\nfrom ..models.id_model import Id\nfrom ..models.responses import DbResponse\nfrom ..models.query_operators import QueryOperator\nfrom ..models.sort_operators import SortOperator\nfrom ..models.paginate import ResponsePaginate\nfrom ..models.db_field_info import DbField\nfrom typing import TypeVar, Type, Union\nfrom concurrent.futures import ThreadPoolExecutor\nfrom .utils import consolidate_dict, mount_base_pipeline\nfrom ..services.verify_subclasses import is_subclass\nfrom asyncio import gather\nfrom math import ceil\n\n\nModel = TypeVar(\"Model\", bound=DbModel)\n\n\nclass _Engine:\n    \"\"\"\n    Base class for database operations, providing common functionality for both synchronous and asynchronous engines.\n\n    Attributes:\n        _client (MongoClient): The MongoDB client.\n        _db (Database): The database instance.\n        _tz_info (timezone): The timezone information.\n    \"\"\"\n\n    def __init__(self, Client, mongo_uri, db_name, tz_info: timezone = None):\n        \"\"\"\n        Initialize the database engine.\n\n        Args:\n            Client (type): The MongoDB client class.\n            mongo_uri (str): The MongoDB URI.\n            db_name (str): The database name.\n            tz_info (timezone, optional): The timezone information. Defaults to None.\n        \"\"\"\n        self._client = Client(mongo_uri)\n        self._db = self._client[db_name]\n        self._tz_info = tz_info\n\n    def _query(self, query: QueryOperator, raw_query: dict) -> dict:\n        \"\"\"\n        Construct a query dictionary from a QueryOperator or a raw query.\n\n        Args:\n            query (QueryOperator): The query operator.\n            raw_query (dict): The raw query dictionary.\n\n        Returns:\n            dict: The constructed query dictionary.\n        \"\"\"\n        if not is_subclass(class_to_verify=query.__class__, subclass=QueryOperator):\n            raise TypeError(\n                'query argument must be a valid query operator from pyodmongo.queries. If you really need to make a very specific query, use \"raw_query\" argument'\n            )\n        raw_query = {} if not raw_query else raw_query\n        return query.to_dict() if query else raw_query\n\n    def _sort(self, sort: QueryOperator, raw_sort: dict) -> dict:\n        \"\"\"\n        Construct a sort dictionary from a SortOperator or a raw sort.\n\n        Args:\n            sort (QueryOperator): The sort operator.\n            raw_sort (dict): The raw sort dictionary.\n\n        Returns:\n            dict: The constructed sort dictionary.\n        \"\"\"\n        if sort and (type(sort) != SortOperator):\n            raise TypeError(\n                'sort argument must be a SortOperator from pyodmongo.queries. If you really need to make a very specific sort, use \"raw_sort\" argument'\n            )\n        raw_sort = {} if not raw_sort else raw_sort\n        return sort.to_dict() if sort else raw_sort\n\n    def _set_tz_info(self, tz_info: timezone):\n        \"\"\"\n        Set the timezone information.\n\n        Args:\n            tz_info (timezone): The timezone information.\n\n        Returns:\n            timezone: The set timezone information.\n        \"\"\"\n        return tz_info if tz_info else self._tz_info\n\n    def _update_many_operation(\n        self, obj: Type[Model], query_dict: dict, now, upsert: bool, populate: bool\n    ):\n        \"\"\"\n        Create an UpdateMany operation for bulk updates.\n\n        Args:\n            obj (DbModel): The database model object.\n            query_dict (dict): The query dictionary.\n            now (datetime): The current datetime.\n\n        Returns:\n            UpdateMany: The UpdateMany operation.\n        \"\"\"\n        dct = consolidate_dict(obj=obj, dct={}, populate=populate)\n        find_filter = query_dict or {\"_id\": ObjectId(dct.get(\"_id\"))}\n        dct[obj.__class__.updated_at.field_alias] = now\n        dct.pop(\"_id\")\n        dct.pop(obj.__class__.created_at.field_alias)\n        to_save = {\n            \"$set\": dct,\n            \"$setOnInsert\": {obj.__class__.created_at.field_alias: now},\n        }\n        return UpdateMany(filter=find_filter, update=to_save, upsert=upsert)\n\n    def _create_delete_operations_list(\n        self, query: QueryOperator, raw_query: dict, delete_one: bool\n    ):\n        \"\"\"\n        Create a list of delete operations.\n\n        Args:\n            query (QueryOperator): The query operator.\n            raw_query (dict): The raw query dictionary.\n            delete_one (bool): Flag to indicate whether to delete one or many documents.\n\n        Returns:\n            list: The list of delete operations.\n        \"\"\"\n        query = self._query(query=query, raw_query=raw_query)\n        if delete_one:\n            return [DeleteOne(filter=query)]\n        return [DeleteMany(filter=query)]\n\n    def _create_save_operations_list(\n        self,\n        objs: list[Type[Model]],\n        query: QueryOperator,\n        raw_query: dict,\n        upsert: bool,\n        populate: bool,\n    ):\n        \"\"\"\n        Create lists of indexes and save operations for bulk writes.\n\n        Args:\n            objs (list[DbModel]): The list of database model objects.\n            query (QueryOperator): The query operator.\n            raw_query (dict): The raw query dictionary.\n\n        Returns:\n            tuple: A tuple containing indexes, operations, and the current datetime.\n        \"\"\"\n        operations = {}\n        indexes = {}\n        query = self._query(query=query, raw_query=raw_query)\n        now = datetime.now(self._tz_info)\n        now = now.replace(microsecond=int(now.microsecond / 1000) * 1000)\n        for obj in objs:\n            obj: Model\n            operation = self._update_many_operation(\n                obj=obj, query_dict=query, now=now, upsert=upsert, populate=populate\n            )\n            collection_name = obj._collection\n            try:\n                operations[collection_name] += [operation]\n            except KeyError:\n                operations[collection_name] = [operation]\n\n            try:\n                obj_indexes = obj._indexes\n            except AttributeError:\n                obj_indexes = obj._init_indexes\n            indexes[collection_name] = obj_indexes\n        return indexes, operations, now\n\n    def _after_save(\n        self, result: BulkWriteResult, objs: list[Model], collection_name: str, now\n    ):\n        \"\"\"\n        Perform post-save operations.\n\n        Args:\n            result (BulkWriteResult): The bulk write result.\n            objs (list[DbModel]): The list of database model objects.\n            collection_name (str): The name of the collection.\n            now (datetime): The current datetime.\n        \"\"\"\n        objs_from_collection = list(\n            filter(lambda x: x._collection == collection_name, objs)\n        )\n        for index, obj_id in result.upserted_ids.items():\n            objs_from_collection[index].id = Id(obj_id)\n            objs_from_collection[index].created_at = now\n            objs_from_collection[index].updated_at = now\n\n    def _db_response(self, result: BulkWriteResult):\n        \"\"\"\n        Create a database response object from a bulk write result.\n\n        Args:\n            result (BulkWriteResult): The bulk write result.\n\n        Returns:\n            DbResponse: The database response object.\n        \"\"\"\n        return DbResponse(\n            acknowledged=result.acknowledged,\n            deleted_count=result.deleted_count,\n            inserted_count=result.inserted_count,\n            matched_count=result.matched_count,\n            modified_count=result.modified_count,\n            upserted_count=result.upserted_count,\n            upserted_ids=result.upserted_ids,\n        )\n\n    def _aggregate_cursor(\n        self,\n        Model: Type[Model],\n        pipeline,\n        tz_info: timezone,\n    ):\n        \"\"\"\n        Create an aggregation cursor with the specified pipeline and timezone information.\n\n        Args:\n            Model (DbModel): The database model class.\n            pipeline (list): The aggregation pipeline.\n            tz_info (timezone): The timezone information.\n\n        Returns:\n            CommandCursor: The aggregation cursor.\n        \"\"\"\n        tz_info = self._set_tz_info(tz_info=tz_info)\n        tz_aware = True if tz_info else False\n        collection = self._db[Model._collection].with_options(\n            codec_options=CodecOptions(tz_aware=tz_aware, tzinfo=tz_info)\n        )\n        return collection.aggregate(pipeline)\n\n    def _aggregate_pipeline(\n        self,\n        Model: Type[Model],\n        query: QueryOperator,\n        raw_query: dict,\n        sort: SortOperator,\n        raw_sort: dict,\n        populate: bool,\n        pipeline: list | None,\n        populate_db_fields: list[DbField] | None,\n    ) -> dict:\n        \"\"\"\n        Construct an aggregation pipeline.\n\n        Args:\n            Model (DbModel): The database model class.\n            query (QueryOperator): The query operator.\n            raw_query (dict): The raw query dictionary.\n            sort (SortOperator): The sort operator.\n            raw_sort (dict): The raw sort dictionary.\n            populate (bool): Flag to indicate whether to populate related documents.\n\n        Returns:\n            tuple: A tuple containing the pipeline, query, and sort dictionaries.\n        \"\"\"\n        query = self._query(query=query, raw_query=raw_query)\n        sort = self._sort(sort=sort, raw_sort=raw_sort)\n        return (\n            mount_base_pipeline(\n                Model=Model,\n                query=query,\n                sort=sort,\n                populate=populate,\n                pipeline=pipeline,\n                populate_db_fields=populate_db_fields,\n            ),\n            query,\n            sort,\n        )\n\n    def _add_paginate_to_pipeline(\n        self, pipeline: list, current_page: int, docs_per_page: int\n    ):\n        \"\"\"\n        Add pagination stages to the aggregation pipeline.\n\n        Args:\n            pipeline (list): The aggregation pipeline.\n            current_page (int): The current page number.\n            docs_per_page (int): The number of documents per page.\n        \"\"\"\n        max_docs_per_page = 1000\n        current_page = 1 if current_page <= 0 else current_page\n        docs_per_page = (\n            max_docs_per_page if docs_per_page > max_docs_per_page else docs_per_page\n        )\n        skip = (docs_per_page * current_page) - docs_per_page\n        skip_stage = [{\"$skip\": skip}]\n        limit_stage = [{\"$limit\": docs_per_page}]\n        pipeline += skip_stage + limit_stage\n\n\nclass AsyncDbEngine(_Engine):\n    \"\"\"\n    Asynchronous database engine class that extends the base engine to provide asynchronous operations.\n    \"\"\"\n\n    def __init__(self, mongo_uri, db_name, tz_info: timezone = None):\n        \"\"\"\n        Initialize the asynchronous database engine.\n\n        Args:\n            mongo_uri (str): The MongoDB URI.\n            db_name (str): The database name.\n            tz_info (timezone, optional): The timezone information. Defaults to None.\n        \"\"\"\n        super().__init__(\n            Client=AsyncIOMotorClient,\n            mongo_uri=mongo_uri,\n            db_name=db_name,\n            tz_info=tz_info,\n        )\n\n    async def save_all(\n        self,\n        obj_list: list[Model],\n        populate: bool = False,\n    ) -> dict[str, DbResponse]:\n        \"\"\"\n        Save a list of objects to the database.\n\n        Args:\n            obj_list (list[DbModel]): The list of database model objects.\n        \"\"\"\n        response = {}\n        indexes, operations, now = self._create_save_operations_list(\n            objs=obj_list, query=None, raw_query=None, upsert=True, populate=populate\n        )\n        for collection_name, index_list in indexes.items():\n            if index_list:\n                await self._db[collection_name].create_indexes(index_list)\n        for collection_name, operation_list in operations.items():\n            result: BulkWriteResult = await self._db[collection_name].bulk_write(\n                operation_list\n            )\n            self._after_save(\n                result=result, objs=obj_list, collection_name=collection_name, now=now\n            )\n            response[collection_name] = self._db_response(result=result)\n        return response\n\n    async def save(\n        self,\n        obj: Model,\n        query: QueryOperator = None,\n        raw_query: dict = None,\n        upsert: bool = True,\n        populate: bool = False,\n    ) -> DbResponse:\n        \"\"\"\n        Save a single object to the database.\n\n        Args:\n            obj (DbModel): The database model object.\n            query (QueryOperator, optional): The query operator. Defaults to None.\n            raw_query (dict, optional): The raw query dictionary. Defaults to None.\n\n        Returns:\n            DbResponse: The database response object.\n        \"\"\"\n        indexes, operations, now = self._create_save_operations_list(\n            objs=[obj],\n            query=query,\n            raw_query=raw_query,\n            upsert=upsert,\n            populate=populate,\n        )\n        collection_name = obj._collection\n        index_list = indexes[collection_name]\n        if index_list:\n            await self._db[collection_name].create_indexes(index_list)\n        operation_list = operations[collection_name]\n        result: BulkWriteResult = await self._db[collection_name].bulk_write(\n            operation_list\n        )\n        self._after_save(\n            result=result, objs=[obj], collection_name=collection_name, now=now\n        )\n        return self._db_response(result=result)\n\n    async def find_one(\n        self,\n        Model: Type[Model],\n        query: QueryOperator = None,\n        raw_query: dict = None,\n        sort: SortOperator = None,\n        raw_sort: dict = None,\n        populate: bool = False,\n        pipeline: list = None,\n        populate_db_fields: list[DbField] | None = None,\n        as_dict: bool = False,\n        tz_info: timezone = None,\n    ) -> Model:\n        \"\"\"\n        Find a single document in the database.\n\n        Args:\n            Model (DbModel): The database model class.\n            query (QueryOperator, optional): The query operator. Defaults to None.\n            raw_query (dict, optional): The raw query dictionary. Defaults to None.\n            sort (SortOperator, optional): The sort operator. Defaults to None.\n            raw_sort (dict, optional): The raw sort dictionary. Defaults to None.\n            populate (bool, optional): Flag to indicate whether to populate related documents. Defaults to False.\n            as_dict (bool, optional): Flag to return the result as a dictionary. Defaults to False.\n            tz_info (timezone, optional): The timezone information. Defaults to None.\n\n        Returns:\n            DbModel: The found database model object.\n        \"\"\"\n        pipeline, _, _ = self._aggregate_pipeline(\n            Model=Model,\n            query=query,\n            raw_query=raw_query,\n            sort=sort,\n            raw_sort=raw_sort,\n            populate=populate,\n            pipeline=pipeline,\n            populate_db_fields=populate_db_fields,\n        )\n        pipeline += [{\"$limit\": 1}]\n        cursor = self._aggregate_cursor(Model=Model, pipeline=pipeline, tz_info=tz_info)\n        if as_dict:\n            result = await cursor.to_list(length=None)\n        else:\n            result = [Model(**doc) async for doc in cursor]\n        try:\n            return result[0]\n        except IndexError:\n            return None\n\n    async def find_many(\n        self,\n        Model: Type[Model],\n        query: QueryOperator = None,\n        raw_query: dict = None,\n        sort: SortOperator = None,\n        raw_sort: dict = None,\n        populate: bool = False,\n        pipeline: list = None,\n        populate_db_fields: list[DbField] | None = None,\n        as_dict: bool = False,\n        tz_info: timezone = None,\n        paginate: bool = False,\n        current_page: int = 1,\n        docs_per_page: int = 1000,\n    ) -> Union[list[Model], ResponsePaginate]:\n        \"\"\"\n        Find multiple documents in the database.\n\n        Args:\n            Model (DbModel): The database model class.\n            query (QueryOperator, optional): The query operator. Defaults to None.\n            raw_query (dict, optional): The raw query dictionary. Defaults to None.\n            sort (SortOperator, optional): The sort operator. Defaults to None.\n            raw_sort (dict, optional): The raw sort dictionary. Defaults to None.\n            populate (bool, optional): Flag to indicate whether to populate related documents. Defaults to False.\n            as_dict (bool, optional): Flag to return the results as dictionaries. Defaults to False.\n            tz_info (timezone, optional): The timezone information. Defaults to None.\n            paginate (bool, optional): Flag to enable pagination. Defaults to False.\n            current_page (int, optional): The current page number. Defaults to 1.\n            docs_per_page (int, optional): The number of documents per page. Defaults to 1000.\n\n        Returns:\n            list[DbModel] or ResponsePaginate: The list of found database model objects or a paginated response.\n        \"\"\"\n        pipeline, query, _ = self._aggregate_pipeline(\n            Model=Model,\n            query=query,\n            raw_query=raw_query,\n            sort=sort,\n            raw_sort=raw_sort,\n            populate=populate,\n            pipeline=pipeline,\n            populate_db_fields=populate_db_fields,\n        )\n\n        async def _result():\n            cursor = self._aggregate_cursor(\n                Model=Model, pipeline=pipeline, tz_info=tz_info\n            )\n            if as_dict:\n                result = await cursor.to_list(length=None)\n            else:\n                result = [Model(**doc) async for doc in cursor]\n            return result\n\n        if not paginate:\n            return await _result()\n        self._add_paginate_to_pipeline(\n            pipeline=pipeline, current_page=current_page, docs_per_page=docs_per_page\n        )\n        cursor = self._aggregate_cursor(Model=Model, pipeline=pipeline, tz_info=tz_info)\n\n        async def _count():\n            kwargs = {\"hint\": \"_id_\"} if not query else {}\n            return await self._db[Model._collection].count_documents(\n                filter=query, **kwargs\n            )\n\n        result, count = await gather(_result(), _count())\n        page_quantity = ceil(count / docs_per_page)\n        return ResponsePaginate(\n            current_page=current_page,\n            page_quantity=page_quantity,\n            docs_quantity=count,\n            docs=result,\n        )\n\n    async def delete(\n        self,\n        Model: Type[Model],\n        query: QueryOperator = None,\n        raw_query: dict = None,\n        delete_one: bool = False,\n    ) -> DbResponse:\n        \"\"\"\n        Delete documents from the database.\n\n        Args:\n            Model (DbModel): The database model class.\n            query (QueryOperator, optional): The query operator. Defaults to None.\n            raw_query (dict, optional): The raw query dictionary. Defaults to None.\n            delete_one (bool, optional): Flag to delete a single document. Defaults to False.\n\n        Returns:\n            DbResponse: The database response object.\n        \"\"\"\n        operations = self._create_delete_operations_list(\n            query=query, raw_query=raw_query, delete_one=delete_one\n        )\n        collection_name = Model._collection\n        result: BulkWriteResult = await self._db[collection_name].bulk_write(operations)\n        return self._db_response(result=result)\n\n\nclass DbEngine(_Engine):\n    \"\"\"\n    Synchronous database engine class that extends the base engine to provide synchronous operations.\n    \"\"\"\n\n    def __init__(self, mongo_uri, db_name, tz_info: timezone = None):\n        \"\"\"\n        Initialize the synchronous database engine.\n\n        Args:\n            mongo_uri (str): The MongoDB URI.\n            db_name (str): The database name.\n            tz_info (timezone, optional): The timezone information. Defaults to None.\n        \"\"\"\n        super().__init__(\n            Client=MongoClient,\n            mongo_uri=mongo_uri,\n            db_name=db_name,\n            tz_info=tz_info,\n        )\n\n    def save_all(\n        self,\n        obj_list: list[Model],\n        populate: bool = False,\n    ) -> dict[str, DbResponse]:\n        \"\"\"\n        Save a list of objects to the database.\n\n        Args:\n            obj_list (list[DbModel]): The list of database model objects.\n        \"\"\"\n        response = {}\n        indexes, operations, now = self._create_save_operations_list(\n            objs=obj_list, query=None, raw_query=None, upsert=True, populate=populate\n        )\n        for collection_name, index_list in indexes.items():\n            if index_list:\n                self._db[collection_name].create_indexes(index_list)\n        for collection_name, operation_list in operations.items():\n            result: BulkWriteResult = self._db[collection_name].bulk_write(\n                operation_list\n            )\n            self._after_save(\n                result=result, objs=obj_list, collection_name=collection_name, now=now\n            )\n            response[collection_name] = self._db_response(result=result)\n        return response\n\n    def save(\n        self,\n        obj: Model,\n        query: QueryOperator = None,\n        raw_query: dict = None,\n        upsert: bool = True,\n        populate: bool = False,\n    ) -> DbResponse:\n        \"\"\"\n        Save a single object to the database.\n\n        Args:\n            obj (DbModel): The database model object.\n            query (QueryOperator, optional): The query operator. Defaults to None.\n            raw_query (dict, optional): The raw query dictionary. Defaults to None.\n\n        Returns:\n            DbResponse: The database response object.\n        \"\"\"\n        indexes, operations, now = self._create_save_operations_list(\n            objs=[obj],\n            query=query,\n            raw_query=raw_query,\n            upsert=upsert,\n            populate=populate,\n        )\n        collection_name = obj._collection\n        index_list = indexes[collection_name]\n        if index_list:\n            self._db[collection_name].create_indexes(index_list)\n        operation_list = operations[collection_name]\n        result: BulkWriteResult = self._db[collection_name].bulk_write(operation_list)\n        self._after_save(\n            result=result, objs=[obj], collection_name=collection_name, now=now\n        )\n        return self._db_response(result=result)\n\n    def find_one(\n        self,\n        Model: Type[Model],\n        query: QueryOperator = None,\n        raw_query: dict = None,\n        sort: SortOperator = None,\n        raw_sort: dict = None,\n        populate: bool = False,\n        pipeline: list = None,\n        populate_db_fields: list[DbField] | None = None,\n        as_dict: bool = False,\n        tz_info: timezone = None,\n    ) -> Model:\n        \"\"\"\n        Find a single document in the database.\n\n        Args:\n            Model (DbModel): The database model class.\n            query (QueryOperator, optional): The query operator. Defaults to None.\n            raw_query (dict, optional): The raw query dictionary. Defaults to None.\n            sort (SortOperator, optional): The sort operator. Defaults to None.\n            raw_sort (dict, optional): The raw sort dictionary. Defaults to None.\n            populate (bool, optional): Flag to indicate whether to populate related documents. Defaults to False.\n            as_dict (bool, optional): Flag to return the result as a dictionary. Defaults to False.\n            tz_info (timezone, optional): The timezone information. Defaults to None.\n\n        Returns:\n            DbModel: The found database model object.\n        \"\"\"\n        pipeline, _, _ = self._aggregate_pipeline(\n            Model=Model,\n            query=query,\n            raw_query=raw_query,\n            sort=sort,\n            raw_sort=raw_sort,\n            populate=populate,\n            pipeline=pipeline,\n            populate_db_fields=populate_db_fields,\n        )\n        pipeline += [{\"$limit\": 1}]\n        cursor = self._aggregate_cursor(Model=Model, pipeline=pipeline, tz_info=tz_info)\n        if as_dict:\n            result = list(cursor)\n        else:\n            result = [Model(**doc) for doc in cursor]\n        try:\n            return result[0]\n        except IndexError:\n            return None\n\n    def find_many(\n        self,\n        Model: Type[Model],\n        query: QueryOperator = None,\n        raw_query: dict = None,\n        sort: SortOperator = None,\n        raw_sort: dict = None,\n        populate: bool = False,\n        pipeline: list = None,\n        populate_db_fields: list[DbField] | None = None,\n        as_dict: bool = False,\n        tz_info: timezone = None,\n        paginate: bool = False,\n        current_page: int = 1,\n        docs_per_page: int = 1000,\n    ) -> Union[list[Model], ResponsePaginate]:\n        \"\"\"\n        Find multiple documents in the database.\n\n        Args:\n            Model (DbModel): The database model class.\n            query (QueryOperator, optional): The query operator. Defaults to None.\n            raw_query (dict, optional): The raw query dictionary. Defaults to None.\n            sort (SortOperator, optional): The sort operator. Defaults to None.\n            raw_sort (dict, optional): The raw sort dictionary. Defaults to None.\n            populate (bool, optional): Flag to indicate whether to populate related documents. Defaults to False.\n            as_dict (bool, optional): Flag to return the results as dictionaries. Defaults to False.\n            tz_info (timezone, optional): The timezone information. Defaults to None.\n            paginate (bool, optional): Flag to enable pagination. Defaults to False.\n            current_page (int, optional): The current page number. Defaults to 1.\n            docs_per_page (int, optional): The number of documents per page. Defaults to 1000.\n\n        Returns:\n            list[DbModel] or ResponsePaginate: The list of found database model objects or a paginated response.\n        \"\"\"\n        pipeline, query, _ = self._aggregate_pipeline(\n            Model=Model,\n            query=query,\n            raw_query=raw_query,\n            sort=sort,\n            raw_sort=raw_sort,\n            populate=populate,\n            pipeline=pipeline,\n            populate_db_fields=populate_db_fields,\n        )\n\n        def _result():\n            cursor = self._aggregate_cursor(\n                Model=Model, pipeline=pipeline, tz_info=tz_info\n            )\n            if as_dict:\n                result = list(cursor)\n            else:\n                result = [Model(**doc) for doc in cursor]\n            return result\n\n        if not paginate:\n            return _result()\n        self._add_paginate_to_pipeline(\n            pipeline=pipeline, current_page=current_page, docs_per_page=docs_per_page\n        )\n        cursor = self._aggregate_cursor(Model=Model, pipeline=pipeline, tz_info=tz_info)\n\n        def _count():\n            kwargs = {\"hint\": \"_id_\"} if not query else {}\n            return self._db[Model._collection].count_documents(filter=query, **kwargs)\n\n        with ThreadPoolExecutor() as executor:\n            future_result = executor.submit(_result)\n            future_count = executor.submit(_count)\n            result = future_result.result()\n            count = future_count.result()\n\n        page_quantity = ceil(count / docs_per_page)\n        return ResponsePaginate(\n            current_page=current_page,\n            page_quantity=page_quantity,\n            docs_quantity=count,\n            docs=result,\n        )\n\n    def delete(\n        self,\n        Model: Type[Model],\n        query: QueryOperator = None,\n        raw_query: dict = None,\n        delete_one: bool = False,\n    ) -> DbResponse:\n        \"\"\"\n        Delete documents from the database.\n\n        Args:\n            Model (DbModel): The database model class.\n            query (QueryOperator, optional): The query operator. Defaults to None.\n            raw_query (dict, optional): The raw query dictionary. Defaults to None.\n            delete_one (bool, optional): Flag to delete a single document. Defaults to False.\n\n        Returns:\n            DbResponse: The database response object.\n        \"\"\"\n        operations = self._create_delete_operations_list(\n            query=query, raw_query=raw_query, delete_one=delete_one\n        )\n        collection_name = Model._collection\n        result: BulkWriteResult = self._db[collection_name].bulk_write(operations)\n        return self._db_response(result=result)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/resolve_exemples.py", "content": "from pathlib import Path\nimport os\n\n\nclass Replace:\n    _exemples_folder = Path().absolute() / \"docs_utils_pre_build\" / \"examples\"\n\n    def __init__(self, folder_path: Path) -> None:\n        self.folder_path: Path = folder_path\n\n    def _all_exemples(self):\n        return list(\n            filter(lambda x: x.endswith(\".py\"), os.listdir(self._exemples_folder))\n        )\n\n    def _all_md_files_on_folder(self):\n        return list(filter(lambda x: x.endswith(\".md\"), os.listdir(self.folder_path)))\n\n    def resolve_replace(self):\n        file_names = self._all_md_files_on_folder()\n        examples = self._all_exemples()\n        for file_name in file_names:\n            file_path: Path = self.folder_path / file_name\n            with open(file=file_path, mode=\"r+\", encoding=\"utf-8\") as md_file:\n                current_md_content = md_file.read()\n                for exemple_name in examples:\n                    exemple_path: Path = self._exemples_folder / exemple_name\n                    with open(file=exemple_path, mode=\"r\", encoding=\"utf-8\") as py_file:\n                        content_py = py_file.read()\n                        current_md_content = current_md_content.replace(\n                            f\"__{exemple_name}__\", content_py\n                        )\n                md_file.seek(0)\n                md_file.write(current_md_content)\n                md_file.truncate()\n\n\nen_folder_path = Path().absolute() / \".docs_tmp\" / \"en\"\npt_folder_path = Path().absolute() / \".docs_tmp\" / \"pt-BR\"\n\nen_obj = Replace(folder_path=en_folder_path)\npt_obj = Replace(folder_path=pt_folder_path)\n\nen_obj.resolve_replace()\npt_obj.resolve_replace()\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/or_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import or_, eq\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = or_(eq(Product.name, \"Box\"), eq(Product.price, 100))\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/save_all_sync.py", "content": "from pyodmongo import DbEngine, DbModel, DbResponse\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nclass User(DbModel):\n    name: str\n    email: str\n    password: str\n    _collection: ClassVar = \"users\"\n\n\nobj_list = [\n    Product(name=\"Box\", price=\"5.99\", is_available=True),\n    Product(name=\"Ball\", price=\"6.99\", is_available=True),\n    User(name=\"John\", email=\"john@email.com\", password=\"john_pwd\"),\n]\n\n\nresponse: dict[str, DbResponse] = engine.save_all(obj_list)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/sort_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import sort\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.price >= 10\nmy_sort = sort((Product.name, 1), (Product.price, -1))\nbox: Product = engine.find_one(Model=Product, query=query, sort=my_sort)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/delete_async.py", "content": "from pyodmongo import AsyncDbEngine, DbModel, DbResponse\nfrom typing import ClassVar\nimport asyncio\n\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nasync def main():\n    query = Product.price <= 100\n\n    response: DbResponse = await engine.delete(Model=Product, query=query)\n\n\nasyncio.run(main())\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/db_model.py", "content": "from pyodmongo import DbModel\nfrom typing import ClassVar\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/embedded_mainbasemodel.py", "content": "from pyodmongo import DbModel, MainBaseModel\nfrom typing import ClassVar\n\n\nclass Address(MainBaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: str\n\n\nclass User(DbModel):\n    username: str\n    password: str\n    address: Address\n    _collection: ClassVar = \"users\"\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/in_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import in_\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = in_(Product.name, [\"Ball\", \"Box\", \"Toy\"])\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/indexes_advanced.py", "content": "from pyodmongo import DbModel\nfrom pymongo import IndexModel, ASCENDING, DESCENDING\nfrom typing import ClassVar\n\n\nclass Product(DbModel):\n    name: str\n    code: str\n    description: str\n    price: float\n    product_type: str\n    is_available: bool\n    _collection: ClassVar = \"products\"\n    _indexes: ClassVar = [\n        IndexModel([(\"name\", ASCENDING), (\"price\", DESCENDING)], name=\"name_and_price\"),\n        IndexModel([(\"product_type\", DESCENDING)], name=\"product_type\"),\n    ]\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/indexes.py", "content": "from pyodmongo import DbModel, Field\nfrom typing import ClassVar\n\n\nclass Product(DbModel):\n    name: str = Field(index=True)\n    code: str = Field(index=True, unique=True)\n    description: str = Field(text_index=True, default_language=\"english\")\n    price: float\n    product_type: str\n    is_available: bool\n    _collection: ClassVar = \"products\"\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/gte_magic.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.price >= 10\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/gt_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import gt\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = gt(Product.price, 10)\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/find_many_async_paginate.py", "content": "from pyodmongo import AsyncDbEngine, DbModel, ResponsePaginate\nfrom typing import ClassVar\nimport asyncio\n\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nasync def main():\n    query = (Product.price >= 50) & (Product.price < 100)\n\n    response: ResponsePaginate = await engine.find_many(\n        Model=Product, query=query, paginate=True, current_page=2, docs_per_page=100\n    )\n\n\nasyncio.run(main())\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/save_all_async.py", "content": "from pyodmongo import AsyncDbEngine, DbModel, DbResponse\nfrom typing import ClassVar\nimport asyncio\n\nengine = AsyncDbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nclass User(DbModel):\n    name: str\n    email: str\n    password: str\n    _collection: ClassVar = \"users\"\n\n\nobj_list = [\n    Product(name=\"Box\", price=\"5.99\", is_available=True),\n    Product(name=\"Ball\", price=\"6.99\", is_available=True),\n    User(name=\"John\", email=\"john@email.com\", password=\"john_pwd\"),\n]\n\n\nasync def main():\n    response: dict[str, DbResponse] = await engine.save_all(obj_list)\n\n\nasyncio.run(main())\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/find_many_sync.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = (Product.price >= 50) & (Product.price < 100)\n\nproducts: list[Product] = engine.find_many(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/lt_magic.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.price < 10\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/ne_magic.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.name != \"Box\"\nbox: Product = engine.find_one(Model=Product, query=query)"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/lte_magic.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = Product.price <= 10\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/nor_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import nor, eq\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = nor(eq(Product.name, \"Box\"), eq(Product.price, 100))\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/and_pyodmongo_queries.py", "content": "from pyodmongo import DbEngine, DbModel\nfrom typing import ClassVar\nfrom pyodmongo.queries import and_, gt, lte\n\nengine = DbEngine(mongo_uri=\"mongodb://localhost:27017\", db_name=\"my_db\")\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    _collection: ClassVar = \"products\"\n\n\nquery = and_(gt(Product.price, 10), lte(Product.price, 50))\nbox: Product = engine.find_one(Model=Product, query=query)\n"}
{"type": "source_file", "path": "docs_utils_pre_build/examples/reference.py", "content": "from pyodmongo import DbModel, Id\nfrom typing import ClassVar\n\n\nclass User(DbModel):\n    username: str\n    password: str\n    _collection: ClassVar = \"users\"\n\n\nclass Product(DbModel):\n    name: str\n    price: float\n    is_available: bool\n    user: User | Id\n    _collection: ClassVar = \"products\"\n"}
