{"repo_info": {"repo_name": "SoulChat2.0", "repo_owner": "scutcyr", "repo_url": "https://github.com/scutcyr/SoulChat2.0"}}
{"type": "source_file", "path": "infer_demo/openai_api_llm.py", "content": "\r\n# coding=utf-8\r\n# Copyright 2023 South China University of Technology and \r\n# Engineering Research Ceter of Ministry of Education on Human Body Perception.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\r\n\r\n# Author: Chen Yirong <eeyirongchen@mail.scut.edu.cn>\r\n# Date: 2024.03.06\r\n\r\n\r\nimport os\r\nimport time\r\nfrom typing import Literal\r\nfrom openai import OpenAI, AzureOpenAI\r\n\r\nclass OpenAI_LLM:\r\n    '''说明：需要根据你部署vllm服务时的实际服务器IP修改base_url，api_key也需要根据你部署的vllm服务时指定的--api-key修改\r\n    '''\r\n    def __init__(self, model_name):\r\n        '''\r\n        输入格式：\r\n            model_name: 字符串，表示模型的名称（见功能说明）。\r\n            system_prompt: 字符串，表示系统的指令说明，定义了'role': 'system'对应的设定内容\r\n                           当其为None时，调用默认的设置初始化\r\n        '''\r\n        self.model_name = model_name\r\n        # 如果同时部署多个模型，可以在这里撰写多个if model_name == \"xxx\"的判断条件\r\n        if model_name.startswith(\"SoulChat2.0\"):\r\n            self.system_prompt = '你是一位精通理情行为疗法（Rational Emotive Behavior Therapy，简称REBT）的心理咨询师，能够合理地采用理情行为疗法给来访者提供专业地指导和支持，缓解来访者的负面情绪和行为反应，帮助他们实现个人成长和心理健康。理情行为治疗主要包括以下几个阶段，下面是对话阶段列表，并简要描述了各个阶段的重点。\\n（1）**检查非理性信念和自我挫败式思维**：理情行为疗法把认知干预视为治疗的“生命”，因此，几乎从治疗一开始，在问题探索阶段，咨询师就以积极的、说服教导式的态度帮助来访者探查隐藏在情绪困扰后面的原因，包括来访者理解事件的思维逻辑，产生情绪的前因后果，借此来明确问题的所在。咨询师坚定地激励来访者去反省自己在遭遇刺激事件后，在感到焦虑、抑郁或愤怒前对自己“说”了些什么。\\n（2）**与非理性信念辩论**：咨询师运用多种技术（主要是认知技术）帮助来访者向非理性信念和思维质疑发难，证明它们的不现实、不合理之处，认识它们的危害进而产生放弃这些不合理信念的愿望和行为。\\n（3）**得出合理信念，学会理性思维**：在识别并驳倒非理性信念的基础上，咨询师进一步诱导、帮助来访者找出对于刺激情境和事件的适宜的、理性的反应，找出理性的信念和实事求是的、指向问题解决的思维陈述，以此来替代非理性信念和自我挫败式思维。为了巩固理性信念，咨询师要向来访者反复教导，证明为什么理性信念是合情合理的，它与非理性信念有什么不同，为什么非理性信念导致情绪失调，而理性信念导致较积极、健康的结果。\\n（4）**迁移应用治疗收获**：积极鼓励来访者把在治疗中所学到的客观现实的态度，科学合理的思维方式内化成个人的生活态度，并在以后的生活中坚持不懈地按理情行为疗法的教导来解决新的问题。'\r\n            self.client = OpenAI(\r\n                base_url=\"http://198.0.0.8:8001/v1\",\r\n                api_key=\"soulchat-rcEmrhVe6zWot67QkJSwqUnNI0EQxxFBMQSAXLtMNsD97PlyGQgjgjW-9jCdQD30\",\r\n            )\r\n        else:\r\n            raise ValueError(f\"Unsupported model name: {model_name}\")\r\n\r\n    def chat(\r\n        self,\r\n        messages: list[dict[str, str]],\r\n        generation_config = None,\r\n        temperature=0.7,\r\n        max_tokens=4096,\r\n        top_p=0.95,\r\n        frequency_penalty=0,\r\n        presence_penalty=0,\r\n        stop=None,\r\n        stream=False,\r\n        add_system_prompt = True,\r\n    ):\r\n        if add_system_prompt:\r\n            if messages[0][\"role\"] != \"system\":\r\n                # 如果传入的messages不存在system_prompt，则添加system_prompt\r\n                messages = [{\"role\":\"system\",\"content\":self.system_prompt}] + messages # 拼接system_prompt\r\n        \r\n        completion = self.client.chat.completions.create(\r\n            model=self.model, \r\n            messages=messages,\r\n            temperature=temperature,\r\n            max_tokens=max_tokens,\r\n            top_p=top_p,\r\n            frequency_penalty=frequency_penalty,\r\n            presence_penalty=presence_penalty,\r\n            stop=stop,\r\n            stream=stream # 流式返回\r\n        )\r\n        return completion"}
{"type": "source_file", "path": "infer_demo/soulchat2.0_app.py", "content": "# coding=utf-8\n# Copyright 2023 South China University of Technology and \n# Engineering Research Ceter of Ministry of Education on Human Body Perception.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# Author: Chen Yirong <eeyirongchen@mail.scut.edu.cn>\n# Date: 2024.03.06\n\n\n''' 运行方式\n\n安装依赖\n```bash\npip install openai==1.7.1\npip install streamlit==1.27.0\npip install streamlit_authenticator==0.3.1\n```\n启动服务：\n```bash\nstreamlit run soulchat2.0_app.py --server.port 8002\n```\n\n## 测试访问\n\nhttp://116.57.86.151:9026\n\n'''\n\n# st-chat uses https://www.dicebear.com/styles for the avatar\n\n# https://emoji6.com/emojiall/\n\nimport os\nimport random\nimport re\nimport sys\nimport json\nimport time\nimport tiktoken\nimport requests\nimport yaml\nfrom yaml.loader import SafeLoader\nimport streamlit as st\nimport streamlit_authenticator as stauth\nfrom openai import OpenAI, AzureOpenAI\nfrom openai_api_llm import OpenAI_LLM\n#Note: The openai-python library support for Azure OpenAI is in preview.\n#Note: This code sample requires OpenAI Python library version 1.0.0 or higher.\n\ndialogue_history_dir = './chatgpt_history_with_users'\n\ndef get_history_chat_id():\n    if not os.path.exists(dialogue_history_dir):\n        # 创建保存用户聊天记录的目录\n        os.makedirs(dialogue_history_dir)\n\n    json_files = os.listdir(dialogue_history_dir)\n    files = [int(os.path.splitext(file)[0]) for file in json_files]\n    files = sorted(files, reverse=True)\n    files = [str(file) for file in files]\n    return files\n\n\ndef num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n    try:\n        encoding = tiktoken.encoding_for_model(model)\n    except KeyError:\n        print(\"Warning: model not found. Using cl100k_base encoding.\")\n        encoding = tiktoken.get_encoding(\"cl100k_base\")\n    if model == \"gpt-3.5-turbo\":\n        print(\"Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\")\n        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n    elif model == \"gpt-4\":\n        print(\"Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\n        return num_tokens_from_messages(messages, model=\"gpt-4-0314\")\n    elif model == \"gpt-3.5-turbo-0301\":\n        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n        tokens_per_name = -1  # if there's a name, the role is omitted\n    elif model == \"gpt-4-0314\":\n        tokens_per_message = 3\n        tokens_per_name = 1\n    else:\n        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n    num_tokens = 0\n    for message in messages:\n        num_tokens += tokens_per_message\n        for key, value in message.items():\n            num_tokens += len(encoding.encode(value))\n            if key == \"name\":\n                num_tokens += tokens_per_name\n    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n    return num_tokens\n\nst.set_page_config(\n    page_title=\"心理咨询师数字孪生大模型(内测版)\",\n    page_icon=\"👩‍🔬\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n    menu_items={\n        'About': \"\"\"     \n-   版本：👩‍🔬心理咨询师数字孪生大模型(内测版)\n-   版本：v1.0.0\n-   机构：华南理工大学未来技术学院\n\t    \"\"\"\n    }\n)\n\n# 用户验证\nwith open(\"./user_config.yaml\") as file:\n    config = yaml.load(file, Loader=SafeLoader)\n\nauthenticator = stauth.Authenticate(\n    config[\"credentials\"],\n    config[\"cookie\"][\"name\"],\n    config[\"cookie\"][\"key\"],\n    config[\"cookie\"][\"expiry_days\"],\n    config[\"preauthorized\"],\n)\n\nauthenticator.login(\n    fields={\n        \"Form name\": \"👩‍🔬心理咨询师数字孪生大模型(内测版)\",\n        \"Username\": \"用户名\",\n        \"Password\": \"密码\",\n        \"Login\": \"登录\",\n    }\n)\n\nif st.session_state[\"authentication_status\"]:\n    \n\n    if st.session_state[\"username\"]:\n        chat_history_dir = os.path.join(dialogue_history_dir, f\"{st.session_state['username']}\")\n        if not os.path.exists(chat_history_dir):\n            os.makedirs(chat_history_dir)\n    else:\n        chat_history_dir = None\n\n    def get_chat_names():\n        # 聊天记录命名格式：{chat_id}_{chat_name}.json\n        json_names = os.listdir(chat_history_dir)\n        chat_names = [x[:-5] for x in json_names if not x.endswith(\"_delete.json\")]\n        chat_names = sorted(chat_names, key=lambda x: int(x.split(\"_\")[0]))\n        return chat_names\n\n    if \"messages\" not in st.session_state:\n        st.session_state[\"messages\"] = []\n\n    if \"total_times\" not in st.session_state:\n        st.session_state[\"total_times\"] = [] # 每一轮对话的耗时\n\n    if \"model_names\" not in st.session_state:\n        st.session_state[\"model_names\"] = [] # 每一轮对话调用的模型\n\n    if \"turn_costs\" not in st.session_state:\n        st.session_state[\"turn_costs\"] = [] # 每一轮对话的预估成本\n\n    if \"current_times\" not in st.session_state:\n        st.session_state[\"current_times\"] = [] # 每一轮对话的运行日期\n\n    if \"total_chat_num\" not in st.session_state:\n        st.session_state[\"total_chat_num\"] = len(os.listdir(chat_history_dir))\n\n    if \"chat_names\" not in st.session_state:\n        st.session_state[\"chat_names\"] = get_chat_names()\n\n    if \"chat_name\" not in st.session_state:\n        st.session_state[\"chat_name\"] = None\n\n    if \"change_name_temp\" not in st.session_state:\n        st.session_state[\"change_name_temp\"] = \"\" \n\n\n    # 带cache装饰器的初始加载函数\n    @st.cache_resource\n    def load_llm(llm_used):\n        if (\n            llm_used.startswith(\"SoulChat2.0\")\n        ):\n            llm = OpenAI_LLM(model_name=llm_used)\n\n        return llm\n\n    # 侧边栏\n\n    with st.sidebar:\n        st.header(\"👩‍🔬心理咨询师数字孪生大模型(内测版)\")\n        authenticator.logout(\n            button_name=\"退出登录\",  # f\"**{st.session_state['username']}**    退出登录\"\n            location=\"sidebar\",\n        )\n        with st.expander(\"ℹ️ - 关于我们\", expanded=False):\n            st.write(\n                \"\"\"     \n        -   版本：👩‍🔬心理咨询师数字孪生大模型(内测版)\n        -   版本：v1.0.0\n        -   机构：华南理工大学未来技术学院\n                \"\"\"\n            )\n        st.divider()\n\n\n        if st.button(\"**新建对话** 💭\", use_container_width=True):\n            st.session_state[\"chat_name\"] = None\n\n        # 模型选择\n        model_name = st.selectbox(\n            '请选择模型的版本',\n            (\n                \"SoulChat2.0-Qwen2-7B\",\n                \"xxx\"\n             ))\n        llm = load_llm(llm_used=model_name)\n\n        temperature = st.slider('设置调用LLM的temperature', min_value = 0.0, max_value = 1.0, value = 0.75, step = 0.01)\n        top_p = st.slider('设置调用LLM的top_p', min_value = 0.0, max_value = 1.0, value = 0.9, step = 0.01)\n        max_tokens = 4096\n        use_system_prompt=True\n        disabled_stream_output = st.checkbox(\"禁用流式返回\", key=\"disabled_stream_output\")\n        change_name_placeholder = st.empty()\n\n        st.write(\"**历史对话记录**\".center(48, \"-\"))\n        chat_name_cols = []\n        for key_id, chat_name in enumerate(reversed(st.session_state[\"chat_names\"])):\n            chat_name_cols.append(st.columns([0.8, 0.1, 0.1], gap=\"small\"))\n            with chat_name_cols[-1][0]:\n                if st.button(\n                    f\"**{''.join(chat_name.split('_')[1:])}**\",\n                    use_container_width=True,\n                    key=key_id,\n                ):\n                    st.session_state[\"chat_name\"] = chat_name\n            with chat_name_cols[-1][1]:\n                if st.button(\n                    \"🗑️\",\n                    use_container_width=True,\n                    key=f\"{key_id}_trash\",\n                    help=\"删除\",\n                ):\n                    os.rename(\n                        os.path.join(\n                            chat_history_dir,\n                            f\"{chat_name}.json\",\n                        ),\n                        os.path.join(\n                            chat_history_dir,\n                            f\"{chat_name}_delete.json\",\n                        ),\n                    )\n                    if st.session_state[\"chat_name\"] == chat_name:\n                        st.session_state[\"chat_name\"] = None\n                    st.session_state[\"chat_names\"] = get_chat_names()\n                    st.rerun()\n\n    # 参数设置\n \n\n    # 显示更改标题文本框\n    def clear_input():\n        st.session_state[\"change_name_temp\"] = st.session_state[\"change_name_input\"]\n        st.session_state[\"change_name_input\"] = \"\"\n\n    if st.session_state[\"chat_name\"] != None:\n        change_name_placeholder.text_input(\n            label=\"**更改当前对话标题**\", key=\"change_name_input\", on_change=clear_input\n        )\n        if st.session_state[\"change_name_temp\"]:\n            os.rename(\n                os.path.join(\n                    chat_history_dir,\n                    f\"{st.session_state['chat_name']}.json\",\n                ),\n                os.path.join(\n                    chat_history_dir,\n                    f\"{st.session_state['chat_name'].split('_')[0]}_{st.session_state['change_name_temp']}.json\",\n                ),\n            )\n            st.session_state[\"chat_name\"] = (\n                f\"{st.session_state['chat_name'].split('_')[0]}_{st.session_state['change_name_temp']}\"\n            )\n            st.session_state[\"chat_names\"] = get_chat_names()\n            st.session_state[\"change_name_temp\"] = \"\"\n            st.rerun()\n\n    # 显示选中对话标记，\n    if st.session_state[\"chat_name\"] != None:\n        with chat_name_cols[\n            list(reversed(st.session_state[\"chat_names\"])).index(\n                st.session_state[\"chat_name\"]\n            )\n        ][2]:\n            st.write(\"🚩\")\n\n    # 读取历史消息\n    if chat_history_dir != None and st.session_state[\"chat_name\"] != None:\n        with open(\n            os.path.join(chat_history_dir, f\"{st.session_state['chat_name']}.json\"),\n            \"r\",\n            encoding=\"utf-8\",\n        ) as f:\n            total_json_data = json.load(f)\n            st.session_state[\"messages\"] = total_json_data['messages']\n            st.session_state[\"total_times\"] = total_json_data['total_times']\n            st.session_state[\"model_names\"] = total_json_data['model_names']\n            st.session_state[\"turn_costs\"] = total_json_data['turn_costs']\n            st.session_state[\"current_times\"] = total_json_data['current_times']\n\n    else:\n        st.session_state[\"messages\"] = []\n        st.session_state[\"total_times\"] = [] # 每一轮对话的耗时\n        st.session_state[\"model_names\"] = [] # 每一轮对话调用的模型\n        st.session_state[\"turn_costs\"] = [] # 每一轮对话的预估成本\n        st.session_state[\"current_times\"] = [] # 每一轮对话的运行日期\n        \n\n\n    # 显示对话标题\n    if st.session_state[\"chat_name\"] != None:\n        st.title(\"\".join(st.session_state[\"chat_name\"].split(\"_\")[1:]))\n\n    # 显示历史对话信息\n    i = 0\n    for message in st.session_state[\"messages\"]:\n            if message[\"role\"] == \"system\":\n                # 不显示system_prompt\n                continue\n            else:\n                avatar = '🧑‍💻' if message[\"role\"] == \"user\" else '👩‍🔬'\n                with st.chat_message(message[\"role\"], avatar=avatar):\n                    st.markdown(message[\"content\"])\n\n                    if message[\"role\"] == \"assistant\":\n                        total_time = st.session_state[\"total_times\"][i]\n                        model_name = st.session_state[\"model_names\"][i]\n                        turn_cost = st.session_state[\"turn_costs\"][i]\n                        current_time = st.session_state[\"current_times\"][i]\n\n                        with st.expander(label=\"*Related Information*\"):\n                            st.write(\n                                f\"time=**{total_time:.2}s**, model_name=**{model_name}**, turn_cost=**{turn_cost:.2}**元，日期：{current_time}\"\n                            )\n\n    # 当前轮对话处理\n    query = st.chat_input(\"Shift + Enter 换行, Enter 发送\")\n    if query:\n\n        with st.chat_message(name=\"user\", avatar=\"🧑‍💻\"):\n            st.write(query)\n\n        #if len(st.session_state[\"messages\"]) == 0 and use_system_prompt and st.session_state[\"system_prompt\"]:\n        #    st.session_state[\"messages\"].append({\"role\":\"system\",\"content\":st.session_state[\"system_prompt\"]})\n\n\n        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": query}) # 把最新的输入加到messages\n        print(f\"[user] {query}\", flush=True)\n\n        with st.chat_message(\"assistant\", avatar='👩‍🔬'):\n            placeholder = st.empty()\n            #data = {\"model\": model_name, \"messages\": st.session_state[\"messages\"], \"stream\": False}\n            start_time = time.time()\n\n\n            messages = st.session_state[\"messages\"]\n\n            completion = llm.chat(\n                        messages = messages,\n                        temperature=temperature,\n                        max_tokens=4096,\n                        top_p=top_p,\n                        frequency_penalty=0,\n                        presence_penalty=0,\n                        stop=None,\n                        stream=not disabled_stream_output,\n                        add_system_prompt = use_system_prompt\n                    )\n            \n            response = \"\"\n            if disabled_stream_output:\n                response = completion.choices[0].message.content\n                placeholder.markdown(response)\n\n            else:\n                # 流式返回\n                for chunk in completion:\n                    #print(\"chunk=\", chunk)\n                    if isinstance(llm, OpenAI_LLM):\n                        #print(\"LLM为OpenAI_LLM\")\n                        if chunk.choices:\n                            new_token = chunk.choices[0].delta.content or \"\"\n                        else:\n                            new_token = \"\"\n                            continue\n                    else:\n                        # 本地部署模型\n                        new_token = chunk\n\n                    response += new_token\n                    placeholder.markdown(response)\n    \n            end_time = time.time()\n            total_time = end_time - start_time\n            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime())\n\n            # 可以增加基于tokens的成本计算公式\n            turn_cost = 0.00\n\n            with st.expander(label=\"*Related Information*\"):\n                st.write(\n                    f\"time=**{total_time:.2}s**, model_name=**{model_name}**, turn_cost=**{turn_cost:.2}**元, 日期：{current_time}\"\n            )\n\n        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n        st.session_state[\"total_times\"].append(total_time)\n        st.session_state[\"model_names\"].append(model_name)\n        st.session_state[\"turn_costs\"].append(turn_cost)\n        st.session_state[\"current_times\"].append(current_time)\n\n        total_information = {\n            \"messages\": st.session_state[\"messages\"],\n            \"total_times\": st.session_state[\"total_times\"],\n            \"model_names\": st.session_state[\"model_names\"],\n            \"turn_costs\": st.session_state[\"turn_costs\"],\n            \"current_times\": st.session_state[\"current_times\"],\n        } # 保存对话历史及相关信息\n \n        print(json.dumps(st.session_state[\"messages\"], ensure_ascii=False), flush=True)\n\n        if st.session_state[\"chat_name\"] == None:\n\n            user_query_0 = st.session_state[\"messages\"][0]['content'][:10].strip()\n\n            st.session_state[\"chat_name\"] = (\n                f\"{st.session_state['total_chat_num']}_{user_query_0}\"\n            )\n            st.session_state[\"chat_names\"].append(st.session_state[\"chat_name\"])\n            with open(\n                os.path.join(chat_history_dir, f\"{st.session_state['chat_name']}.json\"),\n                \"w\",\n                encoding=\"utf-8\",\n            ) as f:\n                json.dump(total_information, f, indent=4, ensure_ascii=False)\n            st.session_state[\"total_chat_num\"] += 1\n            st.rerun()\n\n        with open(\n            os.path.join(chat_history_dir, f\"{st.session_state['chat_name']}.json\"),\n            \"w\",\n            encoding=\"utf-8\",\n        ) as f:\n            json.dump(total_information, f, indent=4, ensure_ascii=False)\n\n\nelif st.session_state[\"authentication_status\"] is False:\n    st.error(\"用户名/密码 不正确\")\nelif st.session_state[\"authentication_status\"] is None:\n    st.warning(\"请输入用户名和密码\")\n"}
