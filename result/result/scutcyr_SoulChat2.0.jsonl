{"repo_info": {"repo_name": "SoulChat2.0", "repo_owner": "scutcyr", "repo_url": "https://github.com/scutcyr/SoulChat2.0"}}
{"type": "source_file", "path": "infer_demo/openai_api_llm.py", "content": "\r\n# coding=utf-8\r\n# Copyright 2023 South China University of Technology and \r\n# Engineering Research Ceter of Ministry of Education on Human Body Perception.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\r\n\r\n# Author: Chen Yirong <eeyirongchen@mail.scut.edu.cn>\r\n# Date: 2024.03.06\r\n\r\n\r\nimport os\r\nimport time\r\nfrom typing import Literal\r\nfrom openai import OpenAI, AzureOpenAI\r\n\r\nclass OpenAI_LLM:\r\n    '''è¯´æ˜ï¼šéœ€è¦æ ¹æ®ä½ éƒ¨ç½²vllmæœåŠ¡æ—¶çš„å®é™…æœåŠ¡å™¨IPä¿®æ”¹base_urlï¼Œapi_keyä¹Ÿéœ€è¦æ ¹æ®ä½ éƒ¨ç½²çš„vllmæœåŠ¡æ—¶æŒ‡å®šçš„--api-keyä¿®æ”¹\r\n    '''\r\n    def __init__(self, model_name):\r\n        '''\r\n        è¾“å…¥æ ¼å¼ï¼š\r\n            model_name: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæ¨¡å‹çš„åç§°ï¼ˆè§åŠŸèƒ½è¯´æ˜ï¼‰ã€‚\r\n            system_prompt: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºç³»ç»Ÿçš„æŒ‡ä»¤è¯´æ˜ï¼Œå®šä¹‰äº†'role': 'system'å¯¹åº”çš„è®¾å®šå†…å®¹\r\n                           å½“å…¶ä¸ºNoneæ—¶ï¼Œè°ƒç”¨é»˜è®¤çš„è®¾ç½®åˆå§‹åŒ–\r\n        '''\r\n        self.model_name = model_name\r\n        # å¦‚æœåŒæ—¶éƒ¨ç½²å¤šä¸ªæ¨¡å‹ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ’°å†™å¤šä¸ªif model_name == \"xxx\"çš„åˆ¤æ–­æ¡ä»¶\r\n        if model_name.startswith(\"SoulChat2.0\"):\r\n            self.system_prompt = 'ä½ æ˜¯ä¸€ä½ç²¾é€šç†æƒ…è¡Œä¸ºç–—æ³•ï¼ˆRational Emotive Behavior Therapyï¼Œç®€ç§°REBTï¼‰çš„å¿ƒç†å’¨è¯¢å¸ˆï¼Œèƒ½å¤Ÿåˆç†åœ°é‡‡ç”¨ç†æƒ…è¡Œä¸ºç–—æ³•ç»™æ¥è®¿è€…æä¾›ä¸“ä¸šåœ°æŒ‡å¯¼å’Œæ”¯æŒï¼Œç¼“è§£æ¥è®¿è€…çš„è´Ÿé¢æƒ…ç»ªå’Œè¡Œä¸ºååº”ï¼Œå¸®åŠ©ä»–ä»¬å®ç°ä¸ªäººæˆé•¿å’Œå¿ƒç†å¥åº·ã€‚ç†æƒ…è¡Œä¸ºæ²»ç–—ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼Œä¸‹é¢æ˜¯å¯¹è¯é˜¶æ®µåˆ—è¡¨ï¼Œå¹¶ç®€è¦æè¿°äº†å„ä¸ªé˜¶æ®µçš„é‡ç‚¹ã€‚\\nï¼ˆ1ï¼‰**æ£€æŸ¥éç†æ€§ä¿¡å¿µå’Œè‡ªæˆ‘æŒ«è´¥å¼æ€ç»´**ï¼šç†æƒ…è¡Œä¸ºç–—æ³•æŠŠè®¤çŸ¥å¹²é¢„è§†ä¸ºæ²»ç–—çš„â€œç”Ÿå‘½â€ï¼Œå› æ­¤ï¼Œå‡ ä¹ä»æ²»ç–—ä¸€å¼€å§‹ï¼Œåœ¨é—®é¢˜æ¢ç´¢é˜¶æ®µï¼Œå’¨è¯¢å¸ˆå°±ä»¥ç§¯æçš„ã€è¯´æœæ•™å¯¼å¼çš„æ€åº¦å¸®åŠ©æ¥è®¿è€…æ¢æŸ¥éšè—åœ¨æƒ…ç»ªå›°æ‰°åé¢çš„åŸå› ï¼ŒåŒ…æ‹¬æ¥è®¿è€…ç†è§£äº‹ä»¶çš„æ€ç»´é€»è¾‘ï¼Œäº§ç”Ÿæƒ…ç»ªçš„å‰å› åæœï¼Œå€Ÿæ­¤æ¥æ˜ç¡®é—®é¢˜çš„æ‰€åœ¨ã€‚å’¨è¯¢å¸ˆåšå®šåœ°æ¿€åŠ±æ¥è®¿è€…å»åçœè‡ªå·±åœ¨é­é‡åˆºæ¿€äº‹ä»¶åï¼Œåœ¨æ„Ÿåˆ°ç„¦è™‘ã€æŠ‘éƒæˆ–æ„¤æ€’å‰å¯¹è‡ªå·±â€œè¯´â€äº†äº›ä»€ä¹ˆã€‚\\nï¼ˆ2ï¼‰**ä¸éç†æ€§ä¿¡å¿µè¾©è®º**ï¼šå’¨è¯¢å¸ˆè¿ç”¨å¤šç§æŠ€æœ¯ï¼ˆä¸»è¦æ˜¯è®¤çŸ¥æŠ€æœ¯ï¼‰å¸®åŠ©æ¥è®¿è€…å‘éç†æ€§ä¿¡å¿µå’Œæ€ç»´è´¨ç–‘å‘éš¾ï¼Œè¯æ˜å®ƒä»¬çš„ä¸ç°å®ã€ä¸åˆç†ä¹‹å¤„ï¼Œè®¤è¯†å®ƒä»¬çš„å±å®³è¿›è€Œäº§ç”Ÿæ”¾å¼ƒè¿™äº›ä¸åˆç†ä¿¡å¿µçš„æ„¿æœ›å’Œè¡Œä¸ºã€‚\\nï¼ˆ3ï¼‰**å¾—å‡ºåˆç†ä¿¡å¿µï¼Œå­¦ä¼šç†æ€§æ€ç»´**ï¼šåœ¨è¯†åˆ«å¹¶é©³å€’éç†æ€§ä¿¡å¿µçš„åŸºç¡€ä¸Šï¼Œå’¨è¯¢å¸ˆè¿›ä¸€æ­¥è¯±å¯¼ã€å¸®åŠ©æ¥è®¿è€…æ‰¾å‡ºå¯¹äºåˆºæ¿€æƒ…å¢ƒå’Œäº‹ä»¶çš„é€‚å®œçš„ã€ç†æ€§çš„ååº”ï¼Œæ‰¾å‡ºç†æ€§çš„ä¿¡å¿µå’Œå®äº‹æ±‚æ˜¯çš„ã€æŒ‡å‘é—®é¢˜è§£å†³çš„æ€ç»´é™ˆè¿°ï¼Œä»¥æ­¤æ¥æ›¿ä»£éç†æ€§ä¿¡å¿µå’Œè‡ªæˆ‘æŒ«è´¥å¼æ€ç»´ã€‚ä¸ºäº†å·©å›ºç†æ€§ä¿¡å¿µï¼Œå’¨è¯¢å¸ˆè¦å‘æ¥è®¿è€…åå¤æ•™å¯¼ï¼Œè¯æ˜ä¸ºä»€ä¹ˆç†æ€§ä¿¡å¿µæ˜¯åˆæƒ…åˆç†çš„ï¼Œå®ƒä¸éç†æ€§ä¿¡å¿µæœ‰ä»€ä¹ˆä¸åŒï¼Œä¸ºä»€ä¹ˆéç†æ€§ä¿¡å¿µå¯¼è‡´æƒ…ç»ªå¤±è°ƒï¼Œè€Œç†æ€§ä¿¡å¿µå¯¼è‡´è¾ƒç§¯æã€å¥åº·çš„ç»“æœã€‚\\nï¼ˆ4ï¼‰**è¿ç§»åº”ç”¨æ²»ç–—æ”¶è·**ï¼šç§¯æé¼“åŠ±æ¥è®¿è€…æŠŠåœ¨æ²»ç–—ä¸­æ‰€å­¦åˆ°çš„å®¢è§‚ç°å®çš„æ€åº¦ï¼Œç§‘å­¦åˆç†çš„æ€ç»´æ–¹å¼å†…åŒ–æˆä¸ªäººçš„ç”Ÿæ´»æ€åº¦ï¼Œå¹¶åœ¨ä»¥åçš„ç”Ÿæ´»ä¸­åšæŒä¸æ‡ˆåœ°æŒ‰ç†æƒ…è¡Œä¸ºç–—æ³•çš„æ•™å¯¼æ¥è§£å†³æ–°çš„é—®é¢˜ã€‚'\r\n            self.client = OpenAI(\r\n                base_url=\"http://198.0.0.8:8001/v1\",\r\n                api_key=\"soulchat-rcEmrhVe6zWot67QkJSwqUnNI0EQxxFBMQSAXLtMNsD97PlyGQgjgjW-9jCdQD30\",\r\n            )\r\n        else:\r\n            raise ValueError(f\"Unsupported model name: {model_name}\")\r\n\r\n    def chat(\r\n        self,\r\n        messages: list[dict[str, str]],\r\n        generation_config = None,\r\n        temperature=0.7,\r\n        max_tokens=4096,\r\n        top_p=0.95,\r\n        frequency_penalty=0,\r\n        presence_penalty=0,\r\n        stop=None,\r\n        stream=False,\r\n        add_system_prompt = True,\r\n    ):\r\n        if add_system_prompt:\r\n            if messages[0][\"role\"] != \"system\":\r\n                # å¦‚æœä¼ å…¥çš„messagesä¸å­˜åœ¨system_promptï¼Œåˆ™æ·»åŠ system_prompt\r\n                messages = [{\"role\":\"system\",\"content\":self.system_prompt}] + messages # æ‹¼æ¥system_prompt\r\n        \r\n        completion = self.client.chat.completions.create(\r\n            model=self.model, \r\n            messages=messages,\r\n            temperature=temperature,\r\n            max_tokens=max_tokens,\r\n            top_p=top_p,\r\n            frequency_penalty=frequency_penalty,\r\n            presence_penalty=presence_penalty,\r\n            stop=stop,\r\n            stream=stream # æµå¼è¿”å›\r\n        )\r\n        return completion"}
{"type": "source_file", "path": "infer_demo/soulchat2.0_app.py", "content": "# coding=utf-8\n# Copyright 2023 South China University of Technology and \n# Engineering Research Ceter of Ministry of Education on Human Body Perception.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# Author: Chen Yirong <eeyirongchen@mail.scut.edu.cn>\n# Date: 2024.03.06\n\n\n''' è¿è¡Œæ–¹å¼\n\nå®‰è£…ä¾èµ–\n```bash\npip install openai==1.7.1\npip install streamlit==1.27.0\npip install streamlit_authenticator==0.3.1\n```\nå¯åŠ¨æœåŠ¡ï¼š\n```bash\nstreamlit run soulchat2.0_app.py --server.port 8002\n```\n\n## æµ‹è¯•è®¿é—®\n\nhttp://116.57.86.151:9026\n\n'''\n\n# st-chat uses https://www.dicebear.com/styles for the avatar\n\n# https://emoji6.com/emojiall/\n\nimport os\nimport random\nimport re\nimport sys\nimport json\nimport time\nimport tiktoken\nimport requests\nimport yaml\nfrom yaml.loader import SafeLoader\nimport streamlit as st\nimport streamlit_authenticator as stauth\nfrom openai import OpenAI, AzureOpenAI\nfrom openai_api_llm import OpenAI_LLM\n#Note: The openai-python library support for Azure OpenAI is in preview.\n#Note: This code sample requires OpenAI Python library version 1.0.0 or higher.\n\ndialogue_history_dir = './chatgpt_history_with_users'\n\ndef get_history_chat_id():\n    if not os.path.exists(dialogue_history_dir):\n        # åˆ›å»ºä¿å­˜ç”¨æˆ·èŠå¤©è®°å½•çš„ç›®å½•\n        os.makedirs(dialogue_history_dir)\n\n    json_files = os.listdir(dialogue_history_dir)\n    files = [int(os.path.splitext(file)[0]) for file in json_files]\n    files = sorted(files, reverse=True)\n    files = [str(file) for file in files]\n    return files\n\n\ndef num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n    try:\n        encoding = tiktoken.encoding_for_model(model)\n    except KeyError:\n        print(\"Warning: model not found. Using cl100k_base encoding.\")\n        encoding = tiktoken.get_encoding(\"cl100k_base\")\n    if model == \"gpt-3.5-turbo\":\n        print(\"Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\")\n        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n    elif model == \"gpt-4\":\n        print(\"Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\n        return num_tokens_from_messages(messages, model=\"gpt-4-0314\")\n    elif model == \"gpt-3.5-turbo-0301\":\n        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n        tokens_per_name = -1  # if there's a name, the role is omitted\n    elif model == \"gpt-4-0314\":\n        tokens_per_message = 3\n        tokens_per_name = 1\n    else:\n        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n    num_tokens = 0\n    for message in messages:\n        num_tokens += tokens_per_message\n        for key, value in message.items():\n            num_tokens += len(encoding.encode(value))\n            if key == \"name\":\n                num_tokens += tokens_per_name\n    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n    return num_tokens\n\nst.set_page_config(\n    page_title=\"å¿ƒç†å’¨è¯¢å¸ˆæ•°å­—å­ªç”Ÿå¤§æ¨¡å‹(å†…æµ‹ç‰ˆ)\",\n    page_icon=\"ğŸ‘©â€ğŸ”¬\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n    menu_items={\n        'About': \"\"\"     \n-   ç‰ˆæœ¬ï¼šğŸ‘©â€ğŸ”¬å¿ƒç†å’¨è¯¢å¸ˆæ•°å­—å­ªç”Ÿå¤§æ¨¡å‹(å†…æµ‹ç‰ˆ)\n-   ç‰ˆæœ¬ï¼šv1.0.0\n-   æœºæ„ï¼šåå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢\n\t    \"\"\"\n    }\n)\n\n# ç”¨æˆ·éªŒè¯\nwith open(\"./user_config.yaml\") as file:\n    config = yaml.load(file, Loader=SafeLoader)\n\nauthenticator = stauth.Authenticate(\n    config[\"credentials\"],\n    config[\"cookie\"][\"name\"],\n    config[\"cookie\"][\"key\"],\n    config[\"cookie\"][\"expiry_days\"],\n    config[\"preauthorized\"],\n)\n\nauthenticator.login(\n    fields={\n        \"Form name\": \"ğŸ‘©â€ğŸ”¬å¿ƒç†å’¨è¯¢å¸ˆæ•°å­—å­ªç”Ÿå¤§æ¨¡å‹(å†…æµ‹ç‰ˆ)\",\n        \"Username\": \"ç”¨æˆ·å\",\n        \"Password\": \"å¯†ç \",\n        \"Login\": \"ç™»å½•\",\n    }\n)\n\nif st.session_state[\"authentication_status\"]:\n    \n\n    if st.session_state[\"username\"]:\n        chat_history_dir = os.path.join(dialogue_history_dir, f\"{st.session_state['username']}\")\n        if not os.path.exists(chat_history_dir):\n            os.makedirs(chat_history_dir)\n    else:\n        chat_history_dir = None\n\n    def get_chat_names():\n        # èŠå¤©è®°å½•å‘½åæ ¼å¼ï¼š{chat_id}_{chat_name}.json\n        json_names = os.listdir(chat_history_dir)\n        chat_names = [x[:-5] for x in json_names if not x.endswith(\"_delete.json\")]\n        chat_names = sorted(chat_names, key=lambda x: int(x.split(\"_\")[0]))\n        return chat_names\n\n    if \"messages\" not in st.session_state:\n        st.session_state[\"messages\"] = []\n\n    if \"total_times\" not in st.session_state:\n        st.session_state[\"total_times\"] = [] # æ¯ä¸€è½®å¯¹è¯çš„è€—æ—¶\n\n    if \"model_names\" not in st.session_state:\n        st.session_state[\"model_names\"] = [] # æ¯ä¸€è½®å¯¹è¯è°ƒç”¨çš„æ¨¡å‹\n\n    if \"turn_costs\" not in st.session_state:\n        st.session_state[\"turn_costs\"] = [] # æ¯ä¸€è½®å¯¹è¯çš„é¢„ä¼°æˆæœ¬\n\n    if \"current_times\" not in st.session_state:\n        st.session_state[\"current_times\"] = [] # æ¯ä¸€è½®å¯¹è¯çš„è¿è¡Œæ—¥æœŸ\n\n    if \"total_chat_num\" not in st.session_state:\n        st.session_state[\"total_chat_num\"] = len(os.listdir(chat_history_dir))\n\n    if \"chat_names\" not in st.session_state:\n        st.session_state[\"chat_names\"] = get_chat_names()\n\n    if \"chat_name\" not in st.session_state:\n        st.session_state[\"chat_name\"] = None\n\n    if \"change_name_temp\" not in st.session_state:\n        st.session_state[\"change_name_temp\"] = \"\" \n\n\n    # å¸¦cacheè£…é¥°å™¨çš„åˆå§‹åŠ è½½å‡½æ•°\n    @st.cache_resource\n    def load_llm(llm_used):\n        if (\n            llm_used.startswith(\"SoulChat2.0\")\n        ):\n            llm = OpenAI_LLM(model_name=llm_used)\n\n        return llm\n\n    # ä¾§è¾¹æ \n\n    with st.sidebar:\n        st.header(\"ğŸ‘©â€ğŸ”¬å¿ƒç†å’¨è¯¢å¸ˆæ•°å­—å­ªç”Ÿå¤§æ¨¡å‹(å†…æµ‹ç‰ˆ)\")\n        authenticator.logout(\n            button_name=\"é€€å‡ºç™»å½•\",  # f\"**{st.session_state['username']}**    é€€å‡ºç™»å½•\"\n            location=\"sidebar\",\n        )\n        with st.expander(\"â„¹ï¸ - å…³äºæˆ‘ä»¬\", expanded=False):\n            st.write(\n                \"\"\"     \n        -   ç‰ˆæœ¬ï¼šğŸ‘©â€ğŸ”¬å¿ƒç†å’¨è¯¢å¸ˆæ•°å­—å­ªç”Ÿå¤§æ¨¡å‹(å†…æµ‹ç‰ˆ)\n        -   ç‰ˆæœ¬ï¼šv1.0.0\n        -   æœºæ„ï¼šåå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢\n                \"\"\"\n            )\n        st.divider()\n\n\n        if st.button(\"**æ–°å»ºå¯¹è¯** ğŸ’­\", use_container_width=True):\n            st.session_state[\"chat_name\"] = None\n\n        # æ¨¡å‹é€‰æ‹©\n        model_name = st.selectbox(\n            'è¯·é€‰æ‹©æ¨¡å‹çš„ç‰ˆæœ¬',\n            (\n                \"SoulChat2.0-Qwen2-7B\",\n                \"xxx\"\n             ))\n        llm = load_llm(llm_used=model_name)\n\n        temperature = st.slider('è®¾ç½®è°ƒç”¨LLMçš„temperature', min_value = 0.0, max_value = 1.0, value = 0.75, step = 0.01)\n        top_p = st.slider('è®¾ç½®è°ƒç”¨LLMçš„top_p', min_value = 0.0, max_value = 1.0, value = 0.9, step = 0.01)\n        max_tokens = 4096\n        use_system_prompt=True\n        disabled_stream_output = st.checkbox(\"ç¦ç”¨æµå¼è¿”å›\", key=\"disabled_stream_output\")\n        change_name_placeholder = st.empty()\n\n        st.write(\"**å†å²å¯¹è¯è®°å½•**\".center(48, \"-\"))\n        chat_name_cols = []\n        for key_id, chat_name in enumerate(reversed(st.session_state[\"chat_names\"])):\n            chat_name_cols.append(st.columns([0.8, 0.1, 0.1], gap=\"small\"))\n            with chat_name_cols[-1][0]:\n                if st.button(\n                    f\"**{''.join(chat_name.split('_')[1:])}**\",\n                    use_container_width=True,\n                    key=key_id,\n                ):\n                    st.session_state[\"chat_name\"] = chat_name\n            with chat_name_cols[-1][1]:\n                if st.button(\n                    \"ğŸ—‘ï¸\",\n                    use_container_width=True,\n                    key=f\"{key_id}_trash\",\n                    help=\"åˆ é™¤\",\n                ):\n                    os.rename(\n                        os.path.join(\n                            chat_history_dir,\n                            f\"{chat_name}.json\",\n                        ),\n                        os.path.join(\n                            chat_history_dir,\n                            f\"{chat_name}_delete.json\",\n                        ),\n                    )\n                    if st.session_state[\"chat_name\"] == chat_name:\n                        st.session_state[\"chat_name\"] = None\n                    st.session_state[\"chat_names\"] = get_chat_names()\n                    st.rerun()\n\n    # å‚æ•°è®¾ç½®\n \n\n    # æ˜¾ç¤ºæ›´æ”¹æ ‡é¢˜æ–‡æœ¬æ¡†\n    def clear_input():\n        st.session_state[\"change_name_temp\"] = st.session_state[\"change_name_input\"]\n        st.session_state[\"change_name_input\"] = \"\"\n\n    if st.session_state[\"chat_name\"] != None:\n        change_name_placeholder.text_input(\n            label=\"**æ›´æ”¹å½“å‰å¯¹è¯æ ‡é¢˜**\", key=\"change_name_input\", on_change=clear_input\n        )\n        if st.session_state[\"change_name_temp\"]:\n            os.rename(\n                os.path.join(\n                    chat_history_dir,\n                    f\"{st.session_state['chat_name']}.json\",\n                ),\n                os.path.join(\n                    chat_history_dir,\n                    f\"{st.session_state['chat_name'].split('_')[0]}_{st.session_state['change_name_temp']}.json\",\n                ),\n            )\n            st.session_state[\"chat_name\"] = (\n                f\"{st.session_state['chat_name'].split('_')[0]}_{st.session_state['change_name_temp']}\"\n            )\n            st.session_state[\"chat_names\"] = get_chat_names()\n            st.session_state[\"change_name_temp\"] = \"\"\n            st.rerun()\n\n    # æ˜¾ç¤ºé€‰ä¸­å¯¹è¯æ ‡è®°ï¼Œ\n    if st.session_state[\"chat_name\"] != None:\n        with chat_name_cols[\n            list(reversed(st.session_state[\"chat_names\"])).index(\n                st.session_state[\"chat_name\"]\n            )\n        ][2]:\n            st.write(\"ğŸš©\")\n\n    # è¯»å–å†å²æ¶ˆæ¯\n    if chat_history_dir != None and st.session_state[\"chat_name\"] != None:\n        with open(\n            os.path.join(chat_history_dir, f\"{st.session_state['chat_name']}.json\"),\n            \"r\",\n            encoding=\"utf-8\",\n        ) as f:\n            total_json_data = json.load(f)\n            st.session_state[\"messages\"] = total_json_data['messages']\n            st.session_state[\"total_times\"] = total_json_data['total_times']\n            st.session_state[\"model_names\"] = total_json_data['model_names']\n            st.session_state[\"turn_costs\"] = total_json_data['turn_costs']\n            st.session_state[\"current_times\"] = total_json_data['current_times']\n\n    else:\n        st.session_state[\"messages\"] = []\n        st.session_state[\"total_times\"] = [] # æ¯ä¸€è½®å¯¹è¯çš„è€—æ—¶\n        st.session_state[\"model_names\"] = [] # æ¯ä¸€è½®å¯¹è¯è°ƒç”¨çš„æ¨¡å‹\n        st.session_state[\"turn_costs\"] = [] # æ¯ä¸€è½®å¯¹è¯çš„é¢„ä¼°æˆæœ¬\n        st.session_state[\"current_times\"] = [] # æ¯ä¸€è½®å¯¹è¯çš„è¿è¡Œæ—¥æœŸ\n        \n\n\n    # æ˜¾ç¤ºå¯¹è¯æ ‡é¢˜\n    if st.session_state[\"chat_name\"] != None:\n        st.title(\"\".join(st.session_state[\"chat_name\"].split(\"_\")[1:]))\n\n    # æ˜¾ç¤ºå†å²å¯¹è¯ä¿¡æ¯\n    i = 0\n    for message in st.session_state[\"messages\"]:\n            if message[\"role\"] == \"system\":\n                # ä¸æ˜¾ç¤ºsystem_prompt\n                continue\n            else:\n                avatar = 'ğŸ§‘â€ğŸ’»' if message[\"role\"] == \"user\" else 'ğŸ‘©â€ğŸ”¬'\n                with st.chat_message(message[\"role\"], avatar=avatar):\n                    st.markdown(message[\"content\"])\n\n                    if message[\"role\"] == \"assistant\":\n                        total_time = st.session_state[\"total_times\"][i]\n                        model_name = st.session_state[\"model_names\"][i]\n                        turn_cost = st.session_state[\"turn_costs\"][i]\n                        current_time = st.session_state[\"current_times\"][i]\n\n                        with st.expander(label=\"*Related Information*\"):\n                            st.write(\n                                f\"time=**{total_time:.2}s**, model_name=**{model_name}**, turn_cost=**{turn_cost:.2}**å…ƒï¼Œæ—¥æœŸï¼š{current_time}\"\n                            )\n\n    # å½“å‰è½®å¯¹è¯å¤„ç†\n    query = st.chat_input(\"Shift + Enter æ¢è¡Œ, Enter å‘é€\")\n    if query:\n\n        with st.chat_message(name=\"user\", avatar=\"ğŸ§‘â€ğŸ’»\"):\n            st.write(query)\n\n        #if len(st.session_state[\"messages\"]) == 0 and use_system_prompt and st.session_state[\"system_prompt\"]:\n        #    st.session_state[\"messages\"].append({\"role\":\"system\",\"content\":st.session_state[\"system_prompt\"]})\n\n\n        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": query}) # æŠŠæœ€æ–°çš„è¾“å…¥åŠ åˆ°messages\n        print(f\"[user] {query}\", flush=True)\n\n        with st.chat_message(\"assistant\", avatar='ğŸ‘©â€ğŸ”¬'):\n            placeholder = st.empty()\n            #data = {\"model\": model_name, \"messages\": st.session_state[\"messages\"], \"stream\": False}\n            start_time = time.time()\n\n\n            messages = st.session_state[\"messages\"]\n\n            completion = llm.chat(\n                        messages = messages,\n                        temperature=temperature,\n                        max_tokens=4096,\n                        top_p=top_p,\n                        frequency_penalty=0,\n                        presence_penalty=0,\n                        stop=None,\n                        stream=not disabled_stream_output,\n                        add_system_prompt = use_system_prompt\n                    )\n            \n            response = \"\"\n            if disabled_stream_output:\n                response = completion.choices[0].message.content\n                placeholder.markdown(response)\n\n            else:\n                # æµå¼è¿”å›\n                for chunk in completion:\n                    #print(\"chunk=\", chunk)\n                    if isinstance(llm, OpenAI_LLM):\n                        #print(\"LLMä¸ºOpenAI_LLM\")\n                        if chunk.choices:\n                            new_token = chunk.choices[0].delta.content or \"\"\n                        else:\n                            new_token = \"\"\n                            continue\n                    else:\n                        # æœ¬åœ°éƒ¨ç½²æ¨¡å‹\n                        new_token = chunk\n\n                    response += new_token\n                    placeholder.markdown(response)\n    \n            end_time = time.time()\n            total_time = end_time - start_time\n            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime())\n\n            # å¯ä»¥å¢åŠ åŸºäºtokensçš„æˆæœ¬è®¡ç®—å…¬å¼\n            turn_cost = 0.00\n\n            with st.expander(label=\"*Related Information*\"):\n                st.write(\n                    f\"time=**{total_time:.2}s**, model_name=**{model_name}**, turn_cost=**{turn_cost:.2}**å…ƒ, æ—¥æœŸï¼š{current_time}\"\n            )\n\n        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n        st.session_state[\"total_times\"].append(total_time)\n        st.session_state[\"model_names\"].append(model_name)\n        st.session_state[\"turn_costs\"].append(turn_cost)\n        st.session_state[\"current_times\"].append(current_time)\n\n        total_information = {\n            \"messages\": st.session_state[\"messages\"],\n            \"total_times\": st.session_state[\"total_times\"],\n            \"model_names\": st.session_state[\"model_names\"],\n            \"turn_costs\": st.session_state[\"turn_costs\"],\n            \"current_times\": st.session_state[\"current_times\"],\n        } # ä¿å­˜å¯¹è¯å†å²åŠç›¸å…³ä¿¡æ¯\n \n        print(json.dumps(st.session_state[\"messages\"], ensure_ascii=False), flush=True)\n\n        if st.session_state[\"chat_name\"] == None:\n\n            user_query_0 = st.session_state[\"messages\"][0]['content'][:10].strip()\n\n            st.session_state[\"chat_name\"] = (\n                f\"{st.session_state['total_chat_num']}_{user_query_0}\"\n            )\n            st.session_state[\"chat_names\"].append(st.session_state[\"chat_name\"])\n            with open(\n                os.path.join(chat_history_dir, f\"{st.session_state['chat_name']}.json\"),\n                \"w\",\n                encoding=\"utf-8\",\n            ) as f:\n                json.dump(total_information, f, indent=4, ensure_ascii=False)\n            st.session_state[\"total_chat_num\"] += 1\n            st.rerun()\n\n        with open(\n            os.path.join(chat_history_dir, f\"{st.session_state['chat_name']}.json\"),\n            \"w\",\n            encoding=\"utf-8\",\n        ) as f:\n            json.dump(total_information, f, indent=4, ensure_ascii=False)\n\n\nelif st.session_state[\"authentication_status\"] is False:\n    st.error(\"ç”¨æˆ·å/å¯†ç  ä¸æ­£ç¡®\")\nelif st.session_state[\"authentication_status\"] is None:\n    st.warning(\"è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç \")\n"}
