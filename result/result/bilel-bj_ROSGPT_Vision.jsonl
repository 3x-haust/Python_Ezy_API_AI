{"repo_info": {"repo_name": "ROSGPT_Vision", "repo_owner": "bilel-bj", "repo_url": "https://github.com/bilel-bj/ROSGPT_Vision"}}
{"type": "source_file", "path": "rosgpt_vision/ROSGPT_Vision_Camera_Node.py", "content": "#!/usr/bin/env python3\n# This file is part of rosgpt-Vision package.\n#\n# Copyright (c) 2023 Anis Koubaa.\n# All rights reserved.\n#\n# This work is licensed under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0\n# International Public License. See https://creativecommons.org/licenses/by-nc-sa/4.0/ for details.\nimport os\n# import code library\nimport cv2\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom PIL import Image\nimport time\nimport argparse\nimport os\nimport time\nimport pygame\nimport pygame.camera\nfrom pygame.locals import *\nfrom nav2_msgs.action import NavigateToPose\nfrom rclpy.action import ActionClient\nimport yaml\nimport argparse\nfrom image_semantics import MiniGPT4\nfrom image_semantics import SAM\nfrom image_semantics import llava\n\n# initialization Variables\nllm_message = \" \"\nChat_GPT_feedback = \" \"\n\n# Parse the command-line arguments\nparser = argparse.ArgumentParser(description='RosGPT Vision')\nparser.add_argument('path_yaml', type=str, help='write a path of yaml file')\nargs = parser.parse_args()\n\n# import yaml file\nwith open(args.path_yaml, \"r\") as file:\n    yaml_data = yaml.safe_load(file)\nnode = yaml_data.get(\"ROSGPT_Vision_Camera_Node\")\ninput_path = node[\"Input_sequence\"]\nframes_folder = node[\"Output_video\"]       \nmode_input = node[\"choose_input\"]\n# make output frames folder\nos.makedirs(frames_folder, exist_ok=True)\n\n# The main class for ROS2\nclass ROSGPT_Vision_Camera_Node(Node):\n    def __init__(self):\n        super().__init__('ROSGPT_Vision_Camera_Node')\n        \n        self.publisher = self.create_publisher(String, 'Image_Description', 10)\n        self.subscription = self.create_subscription(\n            String,\n            'GPT_Consultation',\n            self.GPT_Consultation_received,\n            10\n        )\n        self.subscription       \n        self.name_model = node[\"Image_Description_Method\"]\n        self.action_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n        self.get_logger().info('Location Navigation Node is ready')\n\n    def GPT_Consultation_received(self, msg):\n        # print(\"Enter\")\n        global Chat_GPT_feedback\n        Chat_GPT_feedback = msg.data.lower()\n        print(\"Received Description \"+Chat_GPT_feedback)\n\n    def image_callback(self, img_path):\n        \n        global llm_message\n        img = img_path\n        if img is None:\n            self.get_logger().warn(\"Failed to read image from path: \")\n            return\n        # call a model\n        if self.name_model == 'MiniGPT4':\n            llm_message = MiniGPT4(img)\n        elif self.name_model == 'SAM':\n            llm_message = SAM(img)\n        elif self.name_model == 'llava':\n            llm_message = llava(img)\n\n        print(llm_message)\n        self.publisher.publish(String(data=f\"Generated_TEXT: {llm_message}\"))\n\n    def run(self, img_path):\n        self.image_callback(img_path)\n\n# important function to adapt the interaction text message\ndef wrap_text(text, font, max_width):\n    words = text.split(' ')\n    wrapped_lines = []\n    current_line = ''\n    for word in words:\n        if font.size(current_line + ' ' + word)[0] <= max_width:\n            current_line += ' ' + word\n        else:\n            wrapped_lines.append(current_line.lstrip())\n            current_line = word\n    wrapped_lines.append(current_line.lstrip())\n    return wrapped_lines\n# the main function\ndef main(args=None):\n    rclpy.init(args=args)\n    ROSGPT_Vision_Camera = ROSGPT_Vision_Camera_Node()\n\n    # Replace this with the path to your image or a method to capture an image from your robot's camera\n    # img_path = \"/home/anas/Anas_CODES/first_model/blind-man-stick-19833766.jpg\"\n    # ROSGPT_Vision_Camera.run(img_path)\n    # Initialize Pygame\n    pygame.init()\n    flag = 1\n    if mode_input == 'webcam':\n        pygame.camera.init()\n        # Set the desired display size\n        display_width = 1280\n        display_height = 720\n        # Get the list of available cameras\n        camera_list = pygame.camera.list_cameras()\n        if not camera_list:\n            raise Exception(\"No cameras found.\")\n        # Create a camera object\n        camera = pygame.camera.Camera(camera_list[0], (display_width, display_height))\n        # Start the camera\n        camera.start()\n        pygame.display.set_caption(\"Webcam Overlay\")\n        screen = pygame.display.set_mode((display_width, display_height))   \n        # Load the font for the overlay\n        font = pygame.font.SysFont(None, 30)\n        frame_index = 0\n        frame_counter = 0\n        start_time = time.time()\n        while True:\n            frame = camera.get_image()\n            # Display the rotated frame on the Pygame screen\n            screen.blit(frame, (0, 0))\n            if flag ==1:\n                # Overlay text on the frame\n                massage = str(llm_message)\n                overlay_box_width = max(400, len(massage) * 5)  # Limit the width to 400 pixels\n                overlay_box_height = 100#100\n                overlay_box_pos = (20, 60)#(display_width - overlay_box_width - 20, display_height - overlay_box_height - 20)\n                pygame.draw.rect(screen, (255, 255, 255), (*overlay_box_pos, overlay_box_width, overlay_box_height))\n                pygame.draw.rect(screen, (255, 0, 0), (*overlay_box_pos, overlay_box_width, overlay_box_height), 3)\n\n                # Wrap the text within the box width\n                wrapped_lines = wrap_text(massage, font, overlay_box_width - 20)\n                text_pos_y = overlay_box_pos[1] + 10\n                for line in wrapped_lines:\n                    text_surface = font.render(line, True, (0, 0, 0))\n                    text_pos = (overlay_box_pos[0] + 10, text_pos_y)\n                    screen.blit(text_surface, text_pos)\n                    text_pos_y += 30\n                ###########################################################\n                # Add the box above the \"Description\" box\n                description_box_width = 190\n                description_box_height = 50\n                description_box_pos = (overlay_box_pos[0], overlay_box_pos[1] - overlay_box_height + 50)\n                pygame.draw.rect(screen, (255, 0, 0), (*description_box_pos, description_box_width, description_box_height))\n\n                # Overlay text on the frame in the \"Description\" box\n                description_text = \"Scene Description\"\n                description_text_surface = font.render(description_text, True, (0, 0, 0))\n                description_text_pos = (description_box_pos[0] + 10, description_box_pos[1] + 10)\n                screen.blit(description_text_surface, description_text_pos)\n\n                #############################################################\n                # Define the arrow properties\n                arrow_color = (0, 0, 255)  # blue color\n                arrow_start = (200, 160)  # Arrow starting point (x horzontal ,y vertical) the origin is (0, 0) in the top left\n                arrow_end = (200, 210)#(x horzontal ,y vertical)\n                arrow_width = 15\n                ##############################################################\n                if massage != \" \":\n                    ###########################################################\n                    # Draw the arrow on the frame\n                    pygame.draw.line(screen, arrow_color, arrow_start, arrow_end, arrow_width)\n                    pygame.draw.polygon(screen, arrow_color, [\n                    (arrow_end[0] - 45, arrow_end[1]),#The bottom-left vertex\n                    (arrow_end[0], arrow_end[1] + 30),#The top vertex\n                    (arrow_end[0] + 45, arrow_end[1])#The bottom-right vertex\n                    ])\n                    ###########################################################\n                    # Overlay text on the frame\n                    massage_GPT = str(Chat_GPT_feedback)\n                    overlay_box_width = max(400, len(massage_GPT) * 5)\n                    overlay_box_height = 100\n                    overlay_box_pos_ = (20, 280)#260\n                    pygame.draw.rect(screen, (255, 255, 255), (*overlay_box_pos_, overlay_box_width, overlay_box_height))\n                    pygame.draw.rect(screen, (255, 0, 0), (*overlay_box_pos_, overlay_box_width, overlay_box_height), 3)\n\n                    # Wrap the text within the box width\n                    wrapped_lines_ = wrap_text(massage_GPT, font, overlay_box_width - 20)\n                    text_pos_y_ = overlay_box_pos_[1] + 10\n                    for line_ in wrapped_lines_:\n                        text_surface_ = font.render(line_, True, (0, 0, 0))\n                        text_pos_ = (overlay_box_pos_[0] + 10, text_pos_y_)\n                        screen.blit(text_surface_, text_pos_)\n                        text_pos_y_ += 30\n                    #############################################################\n                    # Add the box above the \"Description\" box\n                    description_box_width_ = 225\n                    description_box_height_ = 40\n                    description_box_pos_ = (20, 240)#20\n                    pygame.draw.rect(screen, (255, 0, 0), (*description_box_pos_, description_box_width_, description_box_height_))\n                    \n                    # Overlay text on the frame in the \"Description\" box\n                    description_text_ = \"GPT Consultation\"\n                    description_text_surface_ = font.render(description_text_, True, (0, 0, 0))\n                    description_text_pos_ = (description_box_pos_[0] + 10, description_box_pos_[1] + 10)\n                    screen.blit(description_text_surface_, description_text_pos_)\n            ##############################################################\n            pygame.display.update()\n            # Check for events\n            for event in pygame.event.get():\n                if event.type == QUIT:\n                    # Stop and quit Pygame\n                    camera.stop()\n                    pygame.quit()\n                    return\n\n            # dispaly caption ############################\n            current_time = time.time()\n            # if frame_counter % frame_interval == 0:\n            if current_time - start_time >= 10:\n                # resized_frame_ = cv2.resize(frame, (224, 224))\n                pixel_data = pygame.surfarray.array3d(frame)\n                # img = Image.fromarray(cv2.cvtColor(resized_frame_, cv2.COLOR_BGR2RGB))\n                img = Image.fromarray(pixel_data)\n                ROSGPT_Vision_Camera.run(img)\n                start_time = current_time\n                flag = 1\n\n            # if frame_counter % frame_interval_2 == 0:\n            #     flag = 0\n            # frame_counter += 1\n            # Delay to match video frame rate\n            # clock.tick(5)  # Adjust the value if necessary (e.g., 30 frames per second) \n            rclpy.spin_once(ROSGPT_Vision_Camera, timeout_sec=0.01)\n            # Save the frame to a file\n            frame_filename = f\"{frames_folder}/frame_{frame_index}.jpg\"\n            pygame.image.save(screen, frame_filename)\n            frame_index = frame_index + 1   \n\n    elif mode_input == 'video':\n        # Load the video using OpenCV\n        video_capture = cv2.VideoCapture(input_path)\n        # Set the desired display size\n        display_width = 1280#640 × 480\n        display_height = 720\n        # Create a Pygame display for video playback\n        screen = pygame.display.set_mode((display_width, display_height))\n        pygame.display.set_caption(\"Video Overlay\")\n        # Load the font for the overlay\n        font = pygame.font.SysFont(None, 30)\n        # Overlay message\n        frame_index = 0\n        is_playing = True  # Flag to indicate if the video is playing\n        frame_interval = int(video_capture.get(cv2.CAP_PROP_FPS)) * 10\n        frame_counter = 0\n        flag = 1\n        frame_interval_2 = int(video_capture.get(cv2.CAP_PROP_FPS)) * 15\n        clock = pygame.time.Clock()  # Pygame clock for delay\n        while video_capture.isOpened():\n            # Read a frame from the video if it is playing\n            if is_playing:\n                ret, frame = video_capture.read()\n                if not ret:\n                    break\n                # Rflagotate the frame to the left\n                rotated_frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n                rotated_frame = cv2.rotate(rotated_frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n                # Resize the frame to fit the display size\n                resized_frame = cv2.resize(rotated_frame, (display_width, display_height))\n\n                # Convert the frame to Pygame surface\n                frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n                frame_pygame = pygame.surfarray.make_surface(frame_rgb)\n\n                # Create a surface to hold the rotated frame with the correct aspect ratio\n                rotated_surface = pygame.Surface((display_height, display_width))\n                rotated_surface.blit(frame_pygame, (0, 0))\n\n                # Rotate the surface to properly display the frame\n                rotated_surface = pygame.transform.rotate(rotated_surface, 90)\n\n                # Display the rotated frame on the Pygame screen\n                screen.blit(rotated_surface, (0, 0))\n\n            if flag ==1:\n                # Overlay text on the frame\n                massage = str(llm_message)\n                overlay_box_width = max(400, len(massage) * 5)  # Limit the width to 400 pixels\n                overlay_box_height = 100\n                overlay_box_pos = (20, 60)\n                pygame.draw.rect(screen, (255, 255, 255), (*overlay_box_pos, overlay_box_width, overlay_box_height))\n                pygame.draw.rect(screen, (255, 0, 0), (*overlay_box_pos, overlay_box_width, overlay_box_height), 3)\n\n                # Wrap the text within the box width\n                wrapped_lines = wrap_text(massage, font, overlay_box_width - 20)\n                text_pos_y = overlay_box_pos[1] + 10\n                for line in wrapped_lines:\n                    text_surface = font.render(line, True, (0, 0, 0))\n                    text_pos = (overlay_box_pos[0] + 10, text_pos_y)\n                    screen.blit(text_surface, text_pos)\n                    text_pos_y += 30\n                # Add the box above the \"Description\" box\n                description_box_width = 190\n                description_box_height = 50\n                description_box_pos = (overlay_box_pos[0], overlay_box_pos[1] - overlay_box_height + 50)\n                pygame.draw.rect(screen, (255, 0, 0), (*description_box_pos, description_box_width, description_box_height))\n                # Overlay text on the frame in the \"Description\" box\n                description_text = \"Scene Description\"\n                description_text_surface = font.render(description_text, True, (0, 0, 0))\n                description_text_pos = (description_box_pos[0] + 10, description_box_pos[1] + 10)\n                screen.blit(description_text_surface, description_text_pos)\n                # Define the arrow properties\n                arrow_color = (0, 0, 255)  # blue color\n                arrow_start = (200, 160)  # Arrow starting point (x horzontal ,y vertical) the origin is (0, 0) in the top left\n                arrow_end = (200, 210)#(x horzontal ,y vertical)\n                arrow_width = 15\n                if massage != \" \":\n                    # Draw the arrow on the frame\n                    pygame.draw.line(screen, arrow_color, arrow_start, arrow_end, arrow_width)\n                    pygame.draw.polygon(screen, arrow_color, [\n                    (arrow_end[0] - 45, arrow_end[1]),#The bottom-left vertex\n                    (arrow_end[0], arrow_end[1] + 30),#The top vertex\n                    (arrow_end[0] + 45, arrow_end[1])#The bottom-right vertex\n                    ])\n                    # Overlay text on the frame\n                    massage_GPT = str(Chat_GPT_feedback)\n                    overlay_box_width = max(400, len(massage_GPT) * 5)\n                    overlay_box_height = 100\n                    overlay_box_pos_ = (20, 280)\n                    pygame.draw.rect(screen, (255, 255, 255), (*overlay_box_pos_, overlay_box_width, overlay_box_height))\n                    pygame.draw.rect(screen, (255, 0, 0), (*overlay_box_pos_, overlay_box_width, overlay_box_height), 3)\n                    # Wrap the text within the box width\n                    wrapped_lines_ = wrap_text(massage_GPT, font, overlay_box_width - 20)\n                    text_pos_y_ = overlay_box_pos_[1] + 10\n                    for line_ in wrapped_lines_:\n                        text_surface_ = font.render(line_, True, (0, 0, 0))\n                        text_pos_ = (overlay_box_pos_[0] + 10, text_pos_y_)\n                        screen.blit(text_surface_, text_pos_)\n                        text_pos_y_ += 30\n                    # Add the box above the \"Description\" box\n                    description_box_width_ = 225\n                    description_box_height_ = 40\n                    description_box_pos_ = (20, 240)#20\n                    pygame.draw.rect(screen, (255, 0, 0), (*description_box_pos_, description_box_width_, description_box_height_))\n                    # # Overlay text on the frame in the \"Description\" box\n                    description_text_ = \"GPT Consultation\"\n                    description_text_surface_ = font.render(description_text_, True, (0, 0, 0))\n                    description_text_pos_ = (description_box_pos_[0] + 10, description_box_pos_[1] + 10)\n                    screen.blit(description_text_surface_, description_text_pos_)\n\n            pygame.display.update()\n            # Check for events\n            for event in pygame.event.get():\n                if event.type == QUIT:\n                    # Stop and quit Pygame\n                    video_capture.release()\n                    pygame.quit()\n                    return\n            # dispaly caption \n            if frame_counter % frame_interval == 0:\n                resized_frame_ = cv2.resize(rotated_frame, (224, 224))\n                img = Image.fromarray(cv2.cvtColor(resized_frame_, cv2.COLOR_BGR2RGB))\n                ROSGPT_Vision_Camera.run(img)\n                flag = 1\n\n            if frame_counter % frame_interval_2 == 0:\n                flag = 0\n            frame_counter += 1\n\n            # Delay to match video frame rate\n            clock.tick(5)  # Adjust the value if necessary (e.g., 30 frames per second) \n\n            rclpy.spin_once(ROSGPT_Vision_Camera, timeout_sec=0.01)\n\n            # Save the frame to a file\n            frame_filename = f\"{frames_folder}/frame_{frame_index}.jpg\"\n            pygame.image.save(screen, frame_filename)\n            frame_index = frame_index + 1\n\n\n\n    ROSGPT_Vision_Camera.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"}
{"type": "source_file", "path": "rosgpt_vision/ROSGPT_Vision_GPT_Consultation_Node.py", "content": "#!/usr/bin/env python3\n# This file is part of rosgpt-Vision package.\n#\n# Copyright (c) 2023 Anis Koubaa.\n# All rights reserved.\n#\n# This work is licensed under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0\n# International Public License. See https://creativecommons.org/licenses/by-nc-sa/4.0/ for details.\n\nimport os\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom nav2_msgs.action import NavigateToPose\nfrom rclpy.action import ActionClient\nimport rclpy\nfrom std_msgs.msg import String\nimport yaml\nfrom langchain import OpenAI, ConversationChain\nimport argparse\n\nparser = argparse.ArgumentParser(description='RosGPT Vision')\nparser.add_argument('path_yaml', type=str, help='write a path of yaml file')\nargs = parser.parse_args()\n\nopenai_api_key = \"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\"#os.getenv('OPENAI_API_KEY') \n\n\nwith open(args.path_yaml, \"r\") as file:\n    yaml_data = yaml.safe_load(file)\n\nnode = yaml_data.get(\"GPT_Consultation_Node\")\n\ngpt_temperature = node[\"GPT_temperature\"]\nllm = OpenAI(openai_api_key=openai_api_key, temperature=gpt_temperature)\n\n\nclass GPT_Consultation(Node):\n    def __init__(self):\n        super().__init__('ROSGPT_Vision_GPT_Consultation_Node')\n        self.publisher = self.create_publisher(String, 'GPT_Consultation', 10)\n        \n        self.subscription = self.create_subscription(\n            String,\n            'Image_Description',\n            self.voice_cmd_callback,\n            10\n        )\n        self.action_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n        self.get_logger().info('Location Navigation Node is ready')\n\n    def voice_cmd_callback(self, msg):\n        TOFDI_description = msg.data.lower()\n        print(\"Received Description\"+TOFDI_description)\n        chatgpt_resposne = self.askGPT(TOFDI_description)\n        print(\"The chat responce is :\\n\",chatgpt_resposne)\n\n    def askGPT(self, text_command):\n        prompt = node[\"llm_prompt\"]\n        prompt = prompt+'\\nprompt: '+text_command\n        conversation = ConversationChain(llm=llm, verbose=False)\n        chatgpt_response = conversation.predict(input=prompt)\n        self.publisher.publish(String(data=f\"ChatGPT-4 Response: {chatgpt_response}\"))\n        return str(chatgpt_response)\n    \ndef main(args=None) -> None:\n    rclpy.init(args=args)\n    location_navigation_node = GPT_Consultation()\n\n    rclpy.spin(location_navigation_node)\n    location_navigation_node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"}
{"type": "source_file", "path": "rosgpt_vision/__init__.py", "content": "\n\n\n\n"}
{"type": "source_file", "path": "rosgpt_vision/install/_local_setup_util_ps1.py", "content": "# Copyright 2016-2019 Dirk Thomas\n# Licensed under the Apache License, Version 2.0\n\nimport argparse\nfrom collections import OrderedDict\nimport os\nfrom pathlib import Path\nimport sys\n\n\nFORMAT_STR_COMMENT_LINE = '# {comment}'\nFORMAT_STR_SET_ENV_VAR = 'Set-Item -Path \"Env:{name}\" -Value \"{value}\"'\nFORMAT_STR_USE_ENV_VAR = '$env:{name}'\nFORMAT_STR_INVOKE_SCRIPT = '_colcon_prefix_powershell_source_script \"{script_path}\"'\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = ''\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = ''\n\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\n\n\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')\n    parser.add_argument(\n        'additional_extension', nargs='?',\n        help='The additional file extension to be considered')\n    parser.add_argument(\n        '--merged-install', action='store_true',\n        help='All install prefixes are merged into a single location')\n    args = parser.parse_args(argv)\n\n    packages = get_packages(Path(__file__).parent, args.merged_install)\n\n    ordered_packages = order_packages(packages)\n    for pkg_name in ordered_packages:\n        if _include_comments():\n            print(\n                FORMAT_STR_COMMENT_LINE.format_map(\n                    {'comment': 'Package: ' + pkg_name}))\n        prefix = os.path.abspath(os.path.dirname(__file__))\n        if not args.merged_install:\n            prefix = os.path.join(prefix, pkg_name)\n        for line in get_commands(\n            pkg_name, prefix, args.primary_extension,\n            args.additional_extension\n        ):\n            print(line)\n\n    for line in _remove_ending_separators():\n        print(line)\n\n\ndef get_packages(prefix_path, merged_install):\n    \"\"\"\n    Find packages based on colcon-specific files created during installation.\n\n    :param Path prefix_path: The install prefix path of all packages\n    :param bool merged_install: The flag if the packages are all installed\n      directly in the prefix or if each package is installed in a subdirectory\n      named after the package\n    :returns: A mapping from the package name to the set of runtime\n      dependencies\n    :rtype: dict\n    \"\"\"\n    packages = {}\n    # since importing colcon_core isn't feasible here the following constant\n    # must match colcon_core.location.get_relative_package_index_path()\n    subdirectory = 'share/colcon-core/packages'\n    if merged_install:\n        # return if workspace is empty\n        if not (prefix_path / subdirectory).is_dir():\n            return packages\n        # find all files in the subdirectory\n        for p in (prefix_path / subdirectory).iterdir():\n            if not p.is_file():\n                continue\n            if p.name.startswith('.'):\n                continue\n            add_package_runtime_dependencies(p, packages)\n    else:\n        # for each subdirectory look for the package specific file\n        for p in prefix_path.iterdir():\n            if not p.is_dir():\n                continue\n            if p.name.startswith('.'):\n                continue\n            p = p / subdirectory / p.name\n            if p.is_file():\n                add_package_runtime_dependencies(p, packages)\n\n    # remove unknown dependencies\n    pkg_names = set(packages.keys())\n    for k in packages.keys():\n        packages[k] = {d for d in packages[k] if d in pkg_names}\n\n    return packages\n\n\ndef add_package_runtime_dependencies(path, packages):\n    \"\"\"\n    Check the path and if it exists extract the packages runtime dependencies.\n\n    :param Path path: The resource file containing the runtime dependencies\n    :param dict packages: A mapping from package names to the sets of runtime\n      dependencies to add to\n    \"\"\"\n    content = path.read_text()\n    dependencies = set(content.split(os.pathsep) if content else [])\n    packages[path.name] = dependencies\n\n\ndef order_packages(packages):\n    \"\"\"\n    Order packages topologically.\n\n    :param dict packages: A mapping from package name to the set of runtime\n      dependencies\n    :returns: The package names\n    :rtype: list\n    \"\"\"\n    # select packages with no dependencies in alphabetical order\n    to_be_ordered = list(packages.keys())\n    ordered = []\n    while to_be_ordered:\n        pkg_names_without_deps = [\n            name for name in to_be_ordered if not packages[name]]\n        if not pkg_names_without_deps:\n            reduce_cycle_set(packages)\n            raise RuntimeError(\n                'Circular dependency between: ' + ', '.join(sorted(packages)))\n        pkg_names_without_deps.sort()\n        pkg_name = pkg_names_without_deps[0]\n        to_be_ordered.remove(pkg_name)\n        ordered.append(pkg_name)\n        # remove item from dependency lists\n        for k in list(packages.keys()):\n            if pkg_name in packages[k]:\n                packages[k].remove(pkg_name)\n    return ordered\n\n\ndef reduce_cycle_set(packages):\n    \"\"\"\n    Reduce the set of packages to the ones part of the circular dependency.\n\n    :param dict packages: A mapping from package name to the set of runtime\n      dependencies which is modified in place\n    \"\"\"\n    last_depended = None\n    while len(packages) > 0:\n        # get all remaining dependencies\n        depended = set()\n        for pkg_name, dependencies in packages.items():\n            depended = depended.union(dependencies)\n        # remove all packages which are not dependent on\n        for name in list(packages.keys()):\n            if name not in depended:\n                del packages[name]\n        if last_depended:\n            # if remaining packages haven't changed return them\n            if last_depended == depended:\n                return packages.keys()\n        # otherwise reduce again\n        last_depended = depended\n\n\ndef _include_comments():\n    # skipping comment lines when COLCON_TRACE is not set speeds up the\n    # processing especially on Windows\n    return bool(os.environ.get('COLCON_TRACE'))\n\n\ndef get_commands(pkg_name, prefix, primary_extension, additional_extension):\n    commands = []\n    package_dsv_path = os.path.join(prefix, 'share', pkg_name, 'package.dsv')\n    if os.path.exists(package_dsv_path):\n        commands += process_dsv_file(\n            package_dsv_path, prefix, primary_extension, additional_extension)\n    return commands\n\n\ndef process_dsv_file(\n    dsv_path, prefix, primary_extension=None, additional_extension=None\n):\n    commands = []\n    if _include_comments():\n        commands.append(FORMAT_STR_COMMENT_LINE.format_map({'comment': dsv_path}))\n    with open(dsv_path, 'r') as h:\n        content = h.read()\n    lines = content.splitlines()\n\n    basenames = OrderedDict()\n    for i, line in enumerate(lines):\n        # skip over empty or whitespace-only lines\n        if not line.strip():\n            continue\n        try:\n            type_, remainder = line.split(';', 1)\n        except ValueError:\n            raise RuntimeError(\n                \"Line %d in '%s' doesn't contain a semicolon separating the \"\n                'type from the arguments' % (i + 1, dsv_path))\n        if type_ != DSV_TYPE_SOURCE:\n            # handle non-source lines\n            try:\n                commands += handle_dsv_types_except_source(\n                    type_, remainder, prefix)\n            except RuntimeError as e:\n                raise RuntimeError(\n                    \"Line %d in '%s' %s\" % (i + 1, dsv_path, e)) from e\n        else:\n            # group remaining source lines by basename\n            path_without_ext, ext = os.path.splitext(remainder)\n            if path_without_ext not in basenames:\n                basenames[path_without_ext] = set()\n            assert ext.startswith('.')\n            ext = ext[1:]\n            if ext in (primary_extension, additional_extension):\n                basenames[path_without_ext].add(ext)\n\n    # add the dsv extension to each basename if the file exists\n    for basename, extensions in basenames.items():\n        if not os.path.isabs(basename):\n            basename = os.path.join(prefix, basename)\n        if os.path.exists(basename + '.dsv'):\n            extensions.add('dsv')\n\n    for basename, extensions in basenames.items():\n        if not os.path.isabs(basename):\n            basename = os.path.join(prefix, basename)\n        if 'dsv' in extensions:\n            # process dsv files recursively\n            commands += process_dsv_file(\n                basename + '.dsv', prefix, primary_extension=primary_extension,\n                additional_extension=additional_extension)\n        elif primary_extension in extensions and len(extensions) == 1:\n            # source primary-only files\n            commands += [\n                FORMAT_STR_INVOKE_SCRIPT.format_map({\n                    'prefix': prefix,\n                    'script_path': basename + '.' + primary_extension})]\n        elif additional_extension in extensions:\n            # source non-primary files\n            commands += [\n                FORMAT_STR_INVOKE_SCRIPT.format_map({\n                    'prefix': prefix,\n                    'script_path': basename + '.' + additional_extension})]\n\n    return commands\n\n\ndef handle_dsv_types_except_source(type_, remainder, prefix):\n    commands = []\n    if type_ in (DSV_TYPE_SET, DSV_TYPE_SET_IF_UNSET):\n        try:\n            env_name, value = remainder.split(';', 1)\n        except ValueError:\n            raise RuntimeError(\n                \"doesn't contain a semicolon separating the environment name \"\n                'from the value')\n        try_prefixed_value = os.path.join(prefix, value) if value else prefix\n        if os.path.exists(try_prefixed_value):\n            value = try_prefixed_value\n        if type_ == DSV_TYPE_SET:\n            commands += _set(env_name, value)\n        elif type_ == DSV_TYPE_SET_IF_UNSET:\n            commands += _set_if_unset(env_name, value)\n        else:\n            assert False\n    elif type_ in (\n        DSV_TYPE_APPEND_NON_DUPLICATE,\n        DSV_TYPE_PREPEND_NON_DUPLICATE,\n        DSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS\n    ):\n        try:\n            env_name_and_values = remainder.split(';')\n        except ValueError:\n            raise RuntimeError(\n                \"doesn't contain a semicolon separating the environment name \"\n                'from the values')\n        env_name = env_name_and_values[0]\n        values = env_name_and_values[1:]\n        for value in values:\n            if not value:\n                value = prefix\n            elif not os.path.isabs(value):\n                value = os.path.join(prefix, value)\n            if (\n                type_ == DSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS and\n                not os.path.exists(value)\n            ):\n                comment = f'skip extending {env_name} with not existing ' \\\n                    f'path: {value}'\n                if _include_comments():\n                    commands.append(\n                        FORMAT_STR_COMMENT_LINE.format_map({'comment': comment}))\n            elif type_ == DSV_TYPE_APPEND_NON_DUPLICATE:\n                commands += _append_unique_value(env_name, value)\n            else:\n                commands += _prepend_unique_value(env_name, value)\n    else:\n        raise RuntimeError(\n            'contains an unknown environment hook type: ' + type_)\n    return commands\n\n\nenv_state = {}\n\n\ndef _append_unique_value(name, value):\n    global env_state\n    if name not in env_state:\n        if os.environ.get(name):\n            env_state[name] = set(os.environ[name].split(os.pathsep))\n        else:\n            env_state[name] = set()\n    # append even if the variable has not been set yet, in case a shell script sets the\n    # same variable without the knowledge of this Python script.\n    # later _remove_ending_separators() will cleanup any unintentional leading separator\n    extend = FORMAT_STR_USE_ENV_VAR.format_map({'name': name}) + os.pathsep\n    line = FORMAT_STR_SET_ENV_VAR.format_map(\n        {'name': name, 'value': extend + value})\n    if value not in env_state[name]:\n        env_state[name].add(value)\n    else:\n        if not _include_comments():\n            return []\n        line = FORMAT_STR_COMMENT_LINE.format_map({'comment': line})\n    return [line]\n\n\ndef _prepend_unique_value(name, value):\n    global env_state\n    if name not in env_state:\n        if os.environ.get(name):\n            env_state[name] = set(os.environ[name].split(os.pathsep))\n        else:\n            env_state[name] = set()\n    # prepend even if the variable has not been set yet, in case a shell script sets the\n    # same variable without the knowledge of this Python script.\n    # later _remove_ending_separators() will cleanup any unintentional trailing separator\n    extend = os.pathsep + FORMAT_STR_USE_ENV_VAR.format_map({'name': name})\n    line = FORMAT_STR_SET_ENV_VAR.format_map(\n        {'name': name, 'value': value + extend})\n    if value not in env_state[name]:\n        env_state[name].add(value)\n    else:\n        if not _include_comments():\n            return []\n        line = FORMAT_STR_COMMENT_LINE.format_map({'comment': line})\n    return [line]\n\n\n# generate commands for removing prepended underscores\ndef _remove_ending_separators():\n    # do nothing if the shell extension does not implement the logic\n    if FORMAT_STR_REMOVE_TRAILING_SEPARATOR is None:\n        return []\n\n    global env_state\n    commands = []\n    for name in env_state:\n        # skip variables that already had values before this script started prepending\n        if name in os.environ:\n            continue\n        commands += [\n            FORMAT_STR_REMOVE_LEADING_SEPARATOR.format_map({'name': name}),\n            FORMAT_STR_REMOVE_TRAILING_SEPARATOR.format_map({'name': name})]\n    return commands\n\n\ndef _set(name, value):\n    global env_state\n    env_state[name] = value\n    line = FORMAT_STR_SET_ENV_VAR.format_map(\n        {'name': name, 'value': value})\n    return [line]\n\n\ndef _set_if_unset(name, value):\n    global env_state\n    line = FORMAT_STR_SET_ENV_VAR.format_map(\n        {'name': name, 'value': value})\n    if env_state.get(name, os.environ.get(name)):\n        line = FORMAT_STR_COMMENT_LINE.format_map({'comment': line})\n    return [line]\n\n\nif __name__ == '__main__':  # pragma: no cover\n    try:\n        rc = main()\n    except RuntimeError as e:\n        print(str(e), file=sys.stderr)\n        rc = 1\n    sys.exit(rc)\n"}
{"type": "source_file", "path": "rosgpt_vision/install/_local_setup_util_sh.py", "content": "# Copyright 2016-2019 Dirk Thomas\n# Licensed under the Apache License, Version 2.0\n\nimport argparse\nfrom collections import OrderedDict\nimport os\nfrom pathlib import Path\nimport sys\n\n\nFORMAT_STR_COMMENT_LINE = '# {comment}'\nFORMAT_STR_SET_ENV_VAR = 'export {name}=\"{value}\"'\nFORMAT_STR_USE_ENV_VAR = '${name}'\nFORMAT_STR_INVOKE_SCRIPT = 'COLCON_CURRENT_PREFIX=\"{prefix}\" _colcon_prefix_sh_source_script \"{script_path}\"'\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = 'if [ \"$(echo -n ${name} | head -c 1)\" = \":\" ]; then export {name}=${{{name}#?}} ; fi'\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = 'if [ \"$(echo -n ${name} | tail -c 1)\" = \":\" ]; then export {name}=${{{name}%?}} ; fi'\n\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\n\n\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')\n    parser.add_argument(\n        'additional_extension', nargs='?',\n        help='The additional file extension to be considered')\n    parser.add_argument(\n        '--merged-install', action='store_true',\n        help='All install prefixes are merged into a single location')\n    args = parser.parse_args(argv)\n\n    packages = get_packages(Path(__file__).parent, args.merged_install)\n\n    ordered_packages = order_packages(packages)\n    for pkg_name in ordered_packages:\n        if _include_comments():\n            print(\n                FORMAT_STR_COMMENT_LINE.format_map(\n                    {'comment': 'Package: ' + pkg_name}))\n        prefix = os.path.abspath(os.path.dirname(__file__))\n        if not args.merged_install:\n            prefix = os.path.join(prefix, pkg_name)\n        for line in get_commands(\n            pkg_name, prefix, args.primary_extension,\n            args.additional_extension\n        ):\n            print(line)\n\n    for line in _remove_ending_separators():\n        print(line)\n\n\ndef get_packages(prefix_path, merged_install):\n    \"\"\"\n    Find packages based on colcon-specific files created during installation.\n\n    :param Path prefix_path: The install prefix path of all packages\n    :param bool merged_install: The flag if the packages are all installed\n      directly in the prefix or if each package is installed in a subdirectory\n      named after the package\n    :returns: A mapping from the package name to the set of runtime\n      dependencies\n    :rtype: dict\n    \"\"\"\n    packages = {}\n    # since importing colcon_core isn't feasible here the following constant\n    # must match colcon_core.location.get_relative_package_index_path()\n    subdirectory = 'share/colcon-core/packages'\n    if merged_install:\n        # return if workspace is empty\n        if not (prefix_path / subdirectory).is_dir():\n            return packages\n        # find all files in the subdirectory\n        for p in (prefix_path / subdirectory).iterdir():\n            if not p.is_file():\n                continue\n            if p.name.startswith('.'):\n                continue\n            add_package_runtime_dependencies(p, packages)\n    else:\n        # for each subdirectory look for the package specific file\n        for p in prefix_path.iterdir():\n            if not p.is_dir():\n                continue\n            if p.name.startswith('.'):\n                continue\n            p = p / subdirectory / p.name\n            if p.is_file():\n                add_package_runtime_dependencies(p, packages)\n\n    # remove unknown dependencies\n    pkg_names = set(packages.keys())\n    for k in packages.keys():\n        packages[k] = {d for d in packages[k] if d in pkg_names}\n\n    return packages\n\n\ndef add_package_runtime_dependencies(path, packages):\n    \"\"\"\n    Check the path and if it exists extract the packages runtime dependencies.\n\n    :param Path path: The resource file containing the runtime dependencies\n    :param dict packages: A mapping from package names to the sets of runtime\n      dependencies to add to\n    \"\"\"\n    content = path.read_text()\n    dependencies = set(content.split(os.pathsep) if content else [])\n    packages[path.name] = dependencies\n\n\ndef order_packages(packages):\n    \"\"\"\n    Order packages topologically.\n\n    :param dict packages: A mapping from package name to the set of runtime\n      dependencies\n    :returns: The package names\n    :rtype: list\n    \"\"\"\n    # select packages with no dependencies in alphabetical order\n    to_be_ordered = list(packages.keys())\n    ordered = []\n    while to_be_ordered:\n        pkg_names_without_deps = [\n            name for name in to_be_ordered if not packages[name]]\n        if not pkg_names_without_deps:\n            reduce_cycle_set(packages)\n            raise RuntimeError(\n                'Circular dependency between: ' + ', '.join(sorted(packages)))\n        pkg_names_without_deps.sort()\n        pkg_name = pkg_names_without_deps[0]\n        to_be_ordered.remove(pkg_name)\n        ordered.append(pkg_name)\n        # remove item from dependency lists\n        for k in list(packages.keys()):\n            if pkg_name in packages[k]:\n                packages[k].remove(pkg_name)\n    return ordered\n\n\ndef reduce_cycle_set(packages):\n    \"\"\"\n    Reduce the set of packages to the ones part of the circular dependency.\n\n    :param dict packages: A mapping from package name to the set of runtime\n      dependencies which is modified in place\n    \"\"\"\n    last_depended = None\n    while len(packages) > 0:\n        # get all remaining dependencies\n        depended = set()\n        for pkg_name, dependencies in packages.items():\n            depended = depended.union(dependencies)\n        # remove all packages which are not dependent on\n        for name in list(packages.keys()):\n            if name not in depended:\n                del packages[name]\n        if last_depended:\n            # if remaining packages haven't changed return them\n            if last_depended == depended:\n                return packages.keys()\n        # otherwise reduce again\n        last_depended = depended\n\n\ndef _include_comments():\n    # skipping comment lines when COLCON_TRACE is not set speeds up the\n    # processing especially on Windows\n    return bool(os.environ.get('COLCON_TRACE'))\n\n\ndef get_commands(pkg_name, prefix, primary_extension, additional_extension):\n    commands = []\n    package_dsv_path = os.path.join(prefix, 'share', pkg_name, 'package.dsv')\n    if os.path.exists(package_dsv_path):\n        commands += process_dsv_file(\n            package_dsv_path, prefix, primary_extension, additional_extension)\n    return commands\n\n\ndef process_dsv_file(\n    dsv_path, prefix, primary_extension=None, additional_extension=None\n):\n    commands = []\n    if _include_comments():\n        commands.append(FORMAT_STR_COMMENT_LINE.format_map({'comment': dsv_path}))\n    with open(dsv_path, 'r') as h:\n        content = h.read()\n    lines = content.splitlines()\n\n    basenames = OrderedDict()\n    for i, line in enumerate(lines):\n        # skip over empty or whitespace-only lines\n        if not line.strip():\n            continue\n        try:\n            type_, remainder = line.split(';', 1)\n        except ValueError:\n            raise RuntimeError(\n                \"Line %d in '%s' doesn't contain a semicolon separating the \"\n                'type from the arguments' % (i + 1, dsv_path))\n        if type_ != DSV_TYPE_SOURCE:\n            # handle non-source lines\n            try:\n                commands += handle_dsv_types_except_source(\n                    type_, remainder, prefix)\n            except RuntimeError as e:\n                raise RuntimeError(\n                    \"Line %d in '%s' %s\" % (i + 1, dsv_path, e)) from e\n        else:\n            # group remaining source lines by basename\n            path_without_ext, ext = os.path.splitext(remainder)\n            if path_without_ext not in basenames:\n                basenames[path_without_ext] = set()\n            assert ext.startswith('.')\n            ext = ext[1:]\n            if ext in (primary_extension, additional_extension):\n                basenames[path_without_ext].add(ext)\n\n    # add the dsv extension to each basename if the file exists\n    for basename, extensions in basenames.items():\n        if not os.path.isabs(basename):\n            basename = os.path.join(prefix, basename)\n        if os.path.exists(basename + '.dsv'):\n            extensions.add('dsv')\n\n    for basename, extensions in basenames.items():\n        if not os.path.isabs(basename):\n            basename = os.path.join(prefix, basename)\n        if 'dsv' in extensions:\n            # process dsv files recursively\n            commands += process_dsv_file(\n                basename + '.dsv', prefix, primary_extension=primary_extension,\n                additional_extension=additional_extension)\n        elif primary_extension in extensions and len(extensions) == 1:\n            # source primary-only files\n            commands += [\n                FORMAT_STR_INVOKE_SCRIPT.format_map({\n                    'prefix': prefix,\n                    'script_path': basename + '.' + primary_extension})]\n        elif additional_extension in extensions:\n            # source non-primary files\n            commands += [\n                FORMAT_STR_INVOKE_SCRIPT.format_map({\n                    'prefix': prefix,\n                    'script_path': basename + '.' + additional_extension})]\n\n    return commands\n\n\ndef handle_dsv_types_except_source(type_, remainder, prefix):\n    commands = []\n    if type_ in (DSV_TYPE_SET, DSV_TYPE_SET_IF_UNSET):\n        try:\n            env_name, value = remainder.split(';', 1)\n        except ValueError:\n            raise RuntimeError(\n                \"doesn't contain a semicolon separating the environment name \"\n                'from the value')\n        try_prefixed_value = os.path.join(prefix, value) if value else prefix\n        if os.path.exists(try_prefixed_value):\n            value = try_prefixed_value\n        if type_ == DSV_TYPE_SET:\n            commands += _set(env_name, value)\n        elif type_ == DSV_TYPE_SET_IF_UNSET:\n            commands += _set_if_unset(env_name, value)\n        else:\n            assert False\n    elif type_ in (\n        DSV_TYPE_APPEND_NON_DUPLICATE,\n        DSV_TYPE_PREPEND_NON_DUPLICATE,\n        DSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS\n    ):\n        try:\n            env_name_and_values = remainder.split(';')\n        except ValueError:\n            raise RuntimeError(\n                \"doesn't contain a semicolon separating the environment name \"\n                'from the values')\n        env_name = env_name_and_values[0]\n        values = env_name_and_values[1:]\n        for value in values:\n            if not value:\n                value = prefix\n            elif not os.path.isabs(value):\n                value = os.path.join(prefix, value)\n            if (\n                type_ == DSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS and\n                not os.path.exists(value)\n            ):\n                comment = f'skip extending {env_name} with not existing ' \\\n                    f'path: {value}'\n                if _include_comments():\n                    commands.append(\n                        FORMAT_STR_COMMENT_LINE.format_map({'comment': comment}))\n            elif type_ == DSV_TYPE_APPEND_NON_DUPLICATE:\n                commands += _append_unique_value(env_name, value)\n            else:\n                commands += _prepend_unique_value(env_name, value)\n    else:\n        raise RuntimeError(\n            'contains an unknown environment hook type: ' + type_)\n    return commands\n\n\nenv_state = {}\n\n\ndef _append_unique_value(name, value):\n    global env_state\n    if name not in env_state:\n        if os.environ.get(name):\n            env_state[name] = set(os.environ[name].split(os.pathsep))\n        else:\n            env_state[name] = set()\n    # append even if the variable has not been set yet, in case a shell script sets the\n    # same variable without the knowledge of this Python script.\n    # later _remove_ending_separators() will cleanup any unintentional leading separator\n    extend = FORMAT_STR_USE_ENV_VAR.format_map({'name': name}) + os.pathsep\n    line = FORMAT_STR_SET_ENV_VAR.format_map(\n        {'name': name, 'value': extend + value})\n    if value not in env_state[name]:\n        env_state[name].add(value)\n    else:\n        if not _include_comments():\n            return []\n        line = FORMAT_STR_COMMENT_LINE.format_map({'comment': line})\n    return [line]\n\n\ndef _prepend_unique_value(name, value):\n    global env_state\n    if name not in env_state:\n        if os.environ.get(name):\n            env_state[name] = set(os.environ[name].split(os.pathsep))\n        else:\n            env_state[name] = set()\n    # prepend even if the variable has not been set yet, in case a shell script sets the\n    # same variable without the knowledge of this Python script.\n    # later _remove_ending_separators() will cleanup any unintentional trailing separator\n    extend = os.pathsep + FORMAT_STR_USE_ENV_VAR.format_map({'name': name})\n    line = FORMAT_STR_SET_ENV_VAR.format_map(\n        {'name': name, 'value': value + extend})\n    if value not in env_state[name]:\n        env_state[name].add(value)\n    else:\n        if not _include_comments():\n            return []\n        line = FORMAT_STR_COMMENT_LINE.format_map({'comment': line})\n    return [line]\n\n\n# generate commands for removing prepended underscores\ndef _remove_ending_separators():\n    # do nothing if the shell extension does not implement the logic\n    if FORMAT_STR_REMOVE_TRAILING_SEPARATOR is None:\n        return []\n\n    global env_state\n    commands = []\n    for name in env_state:\n        # skip variables that already had values before this script started prepending\n        if name in os.environ:\n            continue\n        commands += [\n            FORMAT_STR_REMOVE_LEADING_SEPARATOR.format_map({'name': name}),\n            FORMAT_STR_REMOVE_TRAILING_SEPARATOR.format_map({'name': name})]\n    return commands\n\n\ndef _set(name, value):\n    global env_state\n    env_state[name] = value\n    line = FORMAT_STR_SET_ENV_VAR.format_map(\n        {'name': name, 'value': value})\n    return [line]\n\n\ndef _set_if_unset(name, value):\n    global env_state\n    line = FORMAT_STR_SET_ENV_VAR.format_map(\n        {'name': name, 'value': value})\n    if env_state.get(name, os.environ.get(name)):\n        line = FORMAT_STR_COMMENT_LINE.format_map({'comment': line})\n    return [line]\n\n\nif __name__ == '__main__':  # pragma: no cover\n    try:\n        rc = main()\n    except RuntimeError as e:\n        print(str(e), file=sys.stderr)\n        rc = 1\n    sys.exit(rc)\n"}
{"type": "source_file", "path": "setup.py", "content": "from setuptools import setup\nfrom glob import glob\nimport os\n\npackage_name = 'rosgpt_vision'\n\nsetup(\n    name=package_name,\n    version='0.0.1',\n    packages=[package_name],\n    data_files=[\n        ('share/ament_index/resource_index/packages', ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n        (os.path.join('share', package_name, 'webapp'), glob('webapp/*'))\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    author='Bilel Benjdira',\n    author_email='bilel.benjdira@gmail.com',\n    maintainer='Anas M. Ali',\n    maintainer_email='anasmagdyhxh@gmail.com',\n    keywords=['ROS', 'Vision Language Models'],\n    classifiers=[\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: Creative Commons Attribution-NonCommercial License (CC BY-NC)',\n        'Programming Language :: Python :: 3.10', #could work with other version. Tested with 3.10\n    ],\n    description='A ROS2 package to interact with images Natural Language ',\n    license='Creative Commons Attribution-NonCommercial (CC BY-NC)',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n            'ROSGPT_Vision_Camera_Node = rosgpt_vision.ROSGPT_Vision_Camera_Node:main',\n            'ROSGPT_Vision_GPT_Consultation_Node = rosgpt_vision.ROSGPT_Vision_GPT_Consultation_Node:main',\n        ],\n    },\n)\n"}
{"type": "source_file", "path": "rosgpt_vision/image_semantics.py", "content": "#!/usr/bin/env python3\n# This file is part of rosgpt-Vision package.\n#\n# Copyright (c) 2023 Anis Koubaa.\n# All rights reserved.\n#\n# This work is licensed under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0\n# International Public License. See https://creativecommons.org/licenses/by-nc-sa/4.0/ for details.\nimport os\nimport torch\nimport numpy as np\nfrom segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\nfrom transformers import AutoProcessor, Blip2ForConditionalGeneration\nimport numpy as np\nfrom minigpt4.common.config import Config\nfrom minigpt4.common.dist_utils import get_rank\nfrom minigpt4.common.registry import registry\nfrom minigpt4.conversation.conversation import Chat, CONV_VISION\nfrom minigpt4.datasets.builders import *\nfrom minigpt4.models import *\nfrom minigpt4.processors import *\nfrom minigpt4.runners import *\nfrom minigpt4.tasks import *\nimport argparse\nimport os\nimport random\nimport numpy as np\nimport torch\nimport torch.backends.cudnn as cudnn\nimport yaml\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport os\nfrom LLaVA.llava.conversation import conv_templates, SeparatorStyle\nfrom LLaVA.llava.utils import disable_torch_init\nfrom transformers import CLIPVisionModel, CLIPImageProcessor, StoppingCriteria\nfrom LLaVA.llava.model import *\nfrom LLaVA.llava.model.utils import KeywordsStoppingCriteria\n\n############################################################################\nwith open(\"/home/anas/ros2_ws/src/rosgpt_vision/rosgpt_vision/cfg/driver_phone_usage.yaml\", \"r\") as file:\n    yaml_data = yaml.safe_load(file)\n\nnode = yaml_data.get(\"ROSGPT_Vision_Camera_Node\")\nname_model = node[\"Image_Description_Method\"]\nllava_node = yaml_data.get(\"llava_parameters\")\nSAM_node = yaml_data.get(\"SAM_parameters\")\n############################################################################\nif name_model ==\"MiniGPT4\":\n    # Configration for MiniGPT-4\n    minGPT4_node = yaml_data.get(\"MiniGPT4_parameters\")\n    cfg_path = minGPT4_node[\"configuration\"]\n    # cfg_path = yaml_data.get(\"configuration\")\n    gpu_id = 0\n    args = argparse.Namespace(cfg_path=cfg_path, gpu_id=gpu_id, options=None) \n    cfg = Config(args)\n    model_config = cfg.model_cfg\n    model_config.device_8bit = gpu_id \n    model_cls = registry.get_model_class(model_config.arch)\n    model = model_cls.from_config(model_config).to('cuda:{}'.format(gpu_id))\n    vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n    vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n    chat = Chat(model, vis_processor, device='cuda:{}'.format(gpu_id))\n\nelif name_model ==\"SAM\":\n    # Configration for Caption any Thing\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    torch_dtype = torch.float16 if 'cuda' in device else torch.float32\n    model_type = 'vit_h'\n    checkpoint = SAM_node[\"weights_SAM\"]\n    # SAM initialization\n    model = sam_model_registry[model_type](checkpoint = checkpoint)\n    model.to(device)\n    predictor = SamPredictor(model)\n    mask_generator = SamAutomaticMaskGenerator(model)\n\n    processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n    captioning_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\",\n                                                                    device_map = \"sequential\", load_in_8bit = True)\n\nelif name_model ==\"llava\":\n    DEFAULT_IMAGE_TOKEN = \"<image>\"\n    DEFAULT_IMAGE_PATCH_TOKEN = \"<im_patch>\"\n    DEFAULT_IM_START_TOKEN = \"<im_start>\"\n    DEFAULT_IM_END_TOKEN = \"<im_end>\"\n    llama_version = llava_node[\"llama_version\"]\n\n    if llama_version == \"13B\":\n        model_name_ = \"/home/anas/Anas_CODES/LLaVA/LLaVA/13b_model\"\n    elif llama_version == \"7B\":\n        model_name_ = \"liuhaotian/LLaVA-Lightning-MPT-7B-preview\"\n    # Model\n    disable_torch_init()\n    model_name = os.path.expanduser(model_name_)\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    if \"mpt\" in model_name.lower():\n        model = LlavaMPTForCausalLM.from_pretrained(model_name, low_cpu_mem_usage=True, torch_dtype=torch.float16, use_cache=True).cuda()\n    else:\n        model = LlavaLlamaForCausalLM.from_pretrained(model_name, low_cpu_mem_usage=True, torch_dtype=torch.float16, use_cache=True).cuda()\n    image_processor = CLIPImageProcessor.from_pretrained(model.config.mm_vision_tower, torch_dtype=torch.float16)\n\n    mm_use_im_start_end = getattr(model.config, \"mm_use_im_start_end\", False)\n    tokenizer.add_tokens([DEFAULT_IMAGE_PATCH_TOKEN], special_tokens=True)\n    if mm_use_im_start_end:\n        tokenizer.add_tokens([DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN], special_tokens=True)\n\n    vision_tower = model.get_model().vision_tower[0]\n    if vision_tower.device.type == 'meta':\n        vision_tower = CLIPVisionModel.from_pretrained(vision_tower.config._name_or_path, torch_dtype=torch.float16, low_cpu_mem_usage=True).cuda()\n        model.get_model().vision_tower[0] = vision_tower\n    else:\n        vision_tower.to(device='cuda', dtype=torch.float16)\n    vision_config = vision_tower.config\n    vision_config.im_patch_token = tokenizer.convert_tokens_to_ids([DEFAULT_IMAGE_PATCH_TOKEN])[0]\n    vision_config.use_im_start_end = mm_use_im_start_end\n    if mm_use_im_start_end:\n        vision_config.im_start_token, vision_config.im_end_token = tokenizer.convert_tokens_to_ids([DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN])\n    image_token_len = (vision_config.image_size // vision_config.patch_size) ** 2\nelse:\n    print(\"Image_Description_Method is wronge\")\n\n\ndef llava(img):\n\n    query = node[\"Vision_prompt\"]\n    # query = \"Enter your query here\"\n    qs = query\n    if mm_use_im_start_end:\n        qs = qs + '\\n' + DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_PATCH_TOKEN * image_token_len + DEFAULT_IM_END_TOKEN\n    else:\n        qs = qs + '\\n' + DEFAULT_IMAGE_PATCH_TOKEN * image_token_len\n\n    if \"v1\" in model_name.lower():\n        conv_mode = \"llava_v1\"\n    elif \"mpt\" in model_name.lower():\n        conv_mode = \"mpt_multimodal\"\n    else:\n        conv_mode = \"multimodal\"\n\n    conv = conv_templates[conv_mode].copy()\n    conv.append_message(conv.roles[0], qs)\n    conv.append_message(conv.roles[1], None)\n    prompt = conv.get_prompt()\n    inputs = tokenizer([prompt])\n\n    image_tensor = image_processor.preprocess(img, return_tensors='pt')['pixel_values'][0]\n\n    input_ids = torch.as_tensor(inputs.input_ids).cuda()\n\n    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n    keywords = [stop_str]\n    stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n\n    temperature_ = llava_node[\"temperature_llava\"]\n\n    with torch.inference_mode():\n        output_ids = model.generate(\n            input_ids,\n            images=image_tensor.unsqueeze(0).half().cuda(),\n            do_sample=True,\n            temperature=temperature_,\n            max_new_tokens=1024,\n            stopping_criteria=[stopping_criteria])\n\n    input_token_len = input_ids.shape[1]\n    n_diff_input_output = (input_ids != output_ids[:, :input_token_len]).sum().item()\n    if n_diff_input_output > 0:\n        print(f'[Warning] {n_diff_input_output} output_ids are not the same as the input_ids')\n    outputs = tokenizer.batch_decode(output_ids[:, input_token_len:], skip_special_tokens=True)[0]\n    outputs = outputs.strip()\n    if outputs.endswith(stop_str):\n        outputs = outputs[:-len(stop_str)]\n    caption_massage = outputs.strip()\n    # print(outputs)\n    return caption_massage\n\n# Function for Caption any Thing\ndef SAM(img):\n    \n    # text_prompt = 'Question: Describe the state of driver?Answer:'\n    # text_prompt = yaml_data.get(\"Vision_prompt_SAM\")\n    text_prompt = node[\"Vision_prompt_SAM\"]\n    inputs = processor(img, text = text_prompt, return_tensors = \"pt\").to(device, torch_dtype)\n    out = captioning_model.generate(**inputs, max_new_tokens = 50)\n    caption_massage = processor.decode(out[0], skip_special_tokens = True).strip()\n    return caption_massage\n\n# Function for MiniGPT-4\ndef setup_seeds(config):\n    seed = config.run_cfg.seed + get_rank()\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    cudnn.benchmark = False\n    cudnn.deterministic = True\n\ndef MiniGPT4(img):\n    \n    chat_state = CONV_VISION.copy()\n    img_list = []\n    chat.upload_img(img, chat_state, img_list)\n    user_message = node[\"Vision_prompt\"]\n\n    temperature = minGPT4_node[\"temperature_miniGPT4\"]\n    chat.ask(user_message, chat_state)\n    print(\"#################Image_Description##########################################################\")\n    caption_massage = chat.answer(conv=chat_state,\n                        img_list=img_list,\n                        num_beams=1,\n                        temperature=temperature,\n                        max_new_tokens=300,\n                        max_length=2000)[0]  # 2000\n\n    return caption_massage\n"}
