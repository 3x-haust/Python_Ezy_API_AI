{"repo_info": {"repo_name": "ANUS", "repo_owner": "nikmcfly", "repo_url": "https://github.com/nikmcfly/ANUS"}}
{"type": "source_file", "path": "anus/core/agent/react_agent.py", "content": "\"\"\"\nReact Agent module that extends the base agent with reasoning capabilities.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Tuple\nimport json\nimport logging\n\nfrom anus.core.agent.base_agent import BaseAgent\n\nclass ReactAgent(BaseAgent):\n    \"\"\"\n    A reasoning agent that follows the React paradigm (Reasoning and Acting).\n    \n    This agent implements a thought-action-observation loop for complex reasoning.\n    \"\"\"\n    \n    def __init__(self, name: Optional[str] = None, max_iterations: int = 10, **kwargs):\n        \"\"\"\n        Initialize a ReactAgent instance.\n        \n        Args:\n            name: Optional name for the agent.\n            max_iterations: Maximum number of thought-action cycles to perform.\n            **kwargs: Additional configuration options for the agent.\n        \"\"\"\n        super().__init__(name=name, **kwargs)\n        self.max_iterations = max_iterations\n        self.current_iteration = 0\n    \n    def execute(self, task: str, **kwargs) -> Dict[str, Any]:\n        \"\"\"\n        Execute a task using the React paradigm.\n        \n        Args:\n            task: The task description to execute.\n            **kwargs: Additional parameters for task execution.\n            \n        Returns:\n            A dictionary containing the execution result and metadata.\n        \"\"\"\n        self.update_state(status=\"executing\", task=task)\n        self.current_iteration = 0\n        \n        # Initialize the context with the task\n        context = {\n            \"task\": task,\n            \"thoughts\": [],\n            \"actions\": [],\n            \"observations\": []\n        }\n        \n        # Main React loop\n        while self.current_iteration < self.max_iterations:\n            # Generate thought\n            thought = self._generate_thought(context)\n            context[\"thoughts\"].append(thought)\n            \n            # Decide on action\n            action_name, action_input = self._decide_action(context)\n            action = {\"name\": action_name, \"input\": action_input}\n            context[\"actions\"].append(action)\n            \n            # Execute action and get observation\n            observation = self._execute_action(action_name, action_input)\n            context[\"observations\"].append(observation)\n            \n            # Log the iteration\n            self.log_action(\"iteration\", {\n                \"iteration\": self.current_iteration,\n                \"thought\": thought,\n                \"action\": action,\n                \"observation\": observation\n            })\n            \n            # Check if we should terminate\n            if self._should_terminate(context):\n                break\n                \n            self.current_iteration += 1\n        \n        # Generate final answer\n        final_answer = self._generate_final_answer(context)\n        \n        result = {\n            \"task\": task,\n            \"answer\": final_answer,\n            \"iterations\": self.current_iteration,\n            \"context\": context\n        }\n        \n        self.update_state(status=\"completed\")\n        return result\n    \n    def _generate_thought(self, context: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate a thought based on the current context.\n        \n        Args:\n            context: The current execution context.\n            \n        Returns:\n            The thought string.\n        \"\"\"\n        # This should be implemented using a language model\n        # Currently using a placeholder\n        return f\"Thinking about how to {context['task']} (iteration {self.current_iteration})\"\n    \n    def _decide_action(self, context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        Decide on the next action to take.\n        \n        Args:\n            context: The current execution context.\n            \n        Returns:\n            A tuple of (action_name, action_input).\n        \"\"\"\n        # This should be implemented using a language model\n        # Currently using a placeholder\n        return \"dummy_action\", {\"query\": f\"Placeholder action for {context['task']}\"}\n    \n    def _execute_action(self, action_name: str, action_input: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Execute an action and return the observation.\n        \n        Args:\n            action_name: The name of the action to execute.\n            action_input: The input parameters for the action.\n            \n        Returns:\n            The observation from executing the action.\n        \"\"\"\n        # This should be overridden by subclasses\n        return {\"status\": \"error\", \"error\": f\"Unknown action or tool: {action_name}\"}\n    \n    def _should_terminate(self, context: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if execution should terminate.\n        \n        Args:\n            context: The current execution context.\n            \n        Returns:\n            True if execution should terminate, False otherwise.\n        \"\"\"\n        # This should check if we've found a satisfactory answer\n        # Currently using a placeholder\n        return self.current_iteration >= self.max_iterations - 1\n    \n    def _generate_final_answer(self, context: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate a final answer based on the context.\n        \n        Args:\n            context: The current execution context.\n            \n        Returns:\n            The final answer string.\n        \"\"\"\n        # Check if we have any successful tool executions\n        for observation in context.get(\"observations\", []):\n            if isinstance(observation, dict) and \"result\" in observation:\n                result = observation[\"result\"]\n                \n                # Handle calculator tool\n                if isinstance(result, dict):\n                    # Calculator tool\n                    if \"expression\" in result and \"result\" in result and result.get(\"status\") == \"success\":\n                        expression = result[\"expression\"]\n                        calc_result = result[\"result\"]\n                        return f\"The result of {expression} is {calc_result}\"\n                    elif result.get(\"status\") == \"error\" and \"error\" in result:\n                        return f\"Calculator error: {result['error']}\"\n                    \n                    # Search tool\n                    if \"query\" in result and \"results\" in result:\n                        query = result[\"query\"]\n                        results = result[\"results\"]\n                        result_count = result.get(\"result_count\", len(results))\n                        \n                        # Format the results\n                        formatted_results = \"\\n\".join([f\"- {r}\" for r in results[:5]])\n                        comment = result.get(\"comment\", \"\")\n                        comment_text = f\"\\n\\n{comment}\" if comment else \"\"\n                        \n                        return f\"I searched for '{query}' and found {result_count} results:\\n\\n{formatted_results}{comment_text}\"\n                    \n                    # Text tool\n                    if \"text\" in result and \"operation\" in result and \"result\" in result:\n                        text = result[\"text\"]\n                        operation = result[\"operation\"]\n                        text_result = result[\"result\"]\n                        fun_fact = result.get(\"fun_fact\", \"\")\n                        \n                        operation_description = {\n                            \"count\": \"characters in\",\n                            \"reverse\": \"reversed\",\n                            \"uppercase\": \"in uppercase\",\n                            \"lowercase\": \"in lowercase\",\n                            \"capitalize\": \"capitalized\",\n                            \"wordcount\": \"words in\"\n                        }.get(operation, operation)\n                        \n                        fun_fact_text = f\"\\n\\n{fun_fact}\" if fun_fact else \"\"\n                        \n                        if operation in [\"count\", \"wordcount\"]:\n                            return f\"I counted {text_result} {operation_description} '{text}'{fun_fact_text}\"\n                        else:\n                            return f\"I processed '{text}' with {operation} operation:\\n\\n{text_result}{fun_fact_text}\"\n                    \n                    # Code tool\n                    if \"code\" in result and (\"result\" in result or \"output\" in result):\n                        code = result[\"code\"]\n                        code_result = result.get(\"result\", \"No direct result\")\n                        output = result.get(\"output\", \"\")\n                        execution_type = result.get(\"execution_type\", \"code\")\n                        \n                        if output:\n                            return f\"I executed your Python code:\\n\\n```python\\n{code}\\n```\\n\\nOutput:\\n```\\n{output}\\n```\"\n                        else:\n                            return f\"I executed your Python code:\\n\\n```python\\n{code}\\n```\\n\\nResult: {code_result}\"\n                \n                    # Multi-agent results\n                    if \"agent_results\" in result:\n                        agent_results = result[\"agent_results\"]\n                        final_answer = []\n                        \n                        # Process each agent's contribution\n                        if \"researcher\" in agent_results:\n                            research = agent_results[\"researcher\"].get(\"answer\", \"\")\n                            if research:\n                                final_answer.append(f\"Research findings:\\n{research}\")\n                        \n                        if \"planner\" in agent_results:\n                            plan = agent_results[\"planner\"].get(\"answer\", \"\")\n                            if plan:\n                                final_answer.append(f\"Execution plan:\\n{plan}\")\n                        \n                        if \"executor\" in agent_results:\n                            execution = agent_results[\"executor\"].get(\"answer\", \"\")\n                            if execution:\n                                final_answer.append(f\"Execution results:\\n{execution}\")\n                        \n                        if \"critic\" in agent_results:\n                            critique = agent_results[\"critic\"].get(\"answer\", \"\")\n                            if critique:\n                                final_answer.append(f\"Analysis and recommendations:\\n{critique}\")\n                        \n                        # Combine all parts with proper formatting\n                        if final_answer:\n                            return \"\\n\\n\".join(final_answer)\n                            \n        # If no successful results found after analyzing the task\n        return \"I was unable to process your request successfully. Please try again.\" "}
{"type": "source_file", "path": "anus/__init__.py", "content": "\"\"\"\nAnus - Autonomous Networked Utility System\nPackage initialization\n\"\"\"\n\n__version__ = \"0.1.0\"\n__author__ = \"Anus AI Team\"\n__email__ = \"anus-ai@example.com\"\n__description__ = \"An open-source AI agent framework for task automation\"\n"}
{"type": "source_file", "path": "anus/core/agent/tool_agent.py", "content": "\"\"\"\nTool Agent module that extends the react agent with tool execution capabilities.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Tuple\nimport importlib\nimport logging\nimport re\n\nfrom anus.core.agent.react_agent import ReactAgent\n\nclass ToolAgent(ReactAgent):\n    \"\"\"\n    An agent that can use tools to interact with its environment.\n    \n    Extends the ReactAgent with the ability to discover, load, and execute tools.\n    \"\"\"\n    \n    def __init__(\n        self, \n        name: Optional[str] = None, \n        max_iterations: int = 10, \n        tools: Optional[List[str]] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize a ToolAgent instance.\n        \n        Args:\n            name: Optional name for the agent.\n            max_iterations: Maximum number of thought-action cycles to perform.\n            tools: Optional list of tool names to load.\n            **kwargs: Additional configuration options for the agent.\n        \"\"\"\n        super().__init__(name=name, max_iterations=max_iterations, **kwargs)\n        self.tools: Dict[str, Any] = {}\n        \n        # Load specified tools or default tools\n        if tools:\n            for tool_name in tools:\n                self.load_tool(tool_name)\n    \n    def load_tool(self, tool_name: str) -> bool:\n        \"\"\"\n        Load a tool by name.\n        \n        Args:\n            tool_name: The name of the tool to load.\n            \n        Returns:\n            True if the tool was successfully loaded, False otherwise.\n        \"\"\"\n        try:\n            # Dynamically import the tool module\n            module_path = f\"anus.tools.{tool_name}\"\n            module = importlib.import_module(module_path)\n            \n            # Get the tool class (assumed to be the same name as the module but capitalized)\n            class_name = \"\".join(word.capitalize() for word in tool_name.split(\"_\")) + \"Tool\"\n            tool_class = getattr(module, class_name)\n            \n            # Instantiate the tool\n            tool_instance = tool_class()\n            \n            # Register the tool\n            self.tools[tool_name] = tool_instance\n            \n            self.log_action(\"load_tool\", {\"tool_name\": tool_name, \"status\": \"success\"})\n            return True\n            \n        except (ImportError, AttributeError, Exception) as e:\n            self.log_action(\"load_tool\", {\"tool_name\": tool_name, \"status\": \"error\", \"error\": str(e)})\n            logging.error(f\"Failed to load tool {tool_name}: {e}\")\n            return False\n    \n    def _decide_action(self, context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        Decide on the next action to take based on the task.\n        \n        Args:\n            context: The current execution context.\n            \n        Returns:\n            A tuple of (action_name, action_input).\n        \"\"\"\n        task = context['task'].lower()\n        \n        # Check for calculator tasks\n        calc_pattern = r'calculate\\s+(.+)$'\n        calc_match = re.search(calc_pattern, task, re.IGNORECASE)\n        \n        if calc_match and 'calculator' in self.tools:\n            expression = calc_match.group(1).strip()\n            logging.info(f\"Matched calculator expression: '{expression}'\")\n            return \"calculator\", {\"expression\": expression}\n            \n        # Check for search tasks\n        search_patterns = [\n            r'search(?:\\s+for)?\\s+(.+)',\n            r'find(?:\\s+information(?:\\s+about)?)?\\s+(.+)',\n            r'look\\s+up\\s+(.+)'\n        ]\n        \n        for pattern in search_patterns:\n            search_match = re.search(pattern, task, re.IGNORECASE)\n            if search_match and 'search' in self.tools:\n                query = search_match.group(1)\n                return \"search\", {\"query\": query}\n                \n        # Check for text processing tasks\n        text_patterns = {\n            r'count\\s+characters\\s+in\\s+[\\'\"](.+)[\\'\"]': (\"count\", lambda m: m.group(1)),\n            r'count\\s+words\\s+in\\s+[\\'\"](.+)[\\'\"]': (\"wordcount\", lambda m: m.group(1)),\n            r'reverse\\s+[\\'\"](.+)[\\'\"]': (\"reverse\", lambda m: m.group(1)),\n            r'uppercase\\s+[\\'\"](.+)[\\'\"]': (\"uppercase\", lambda m: m.group(1)),\n            r'lowercase\\s+[\\'\"](.+)[\\'\"]': (\"lowercase\", lambda m: m.group(1)),\n            r'capitalize\\s+[\\'\"](.+)[\\'\"]': (\"capitalize\", lambda m: m.group(1))\n        }\n        \n        for pattern, (operation, extractor) in text_patterns.items():\n            text_match = re.search(pattern, task, re.IGNORECASE)\n            if text_match and 'text' in self.tools:\n                text = extractor(text_match)\n                return \"text\", {\"text\": text, \"operation\": operation}\n                \n        # Check for code execution tasks\n        code_patterns = [\n            r'run\\s+code\\s+```(?:python)?\\s*(.+?)```',\n            r'execute\\s+```(?:python)?\\s*(.+?)```',\n            r'evaluate\\s+```(?:python)?\\s*(.+?)```'\n        ]\n        \n        for pattern in code_patterns:\n            code_match = re.search(pattern, task, re.IGNORECASE | re.DOTALL)\n            if code_match and 'code' in self.tools:\n                code = code_match.group(1).strip()\n                return \"code\", {\"code\": code}\n                \n        # Default to dummy action for other tasks\n        return \"dummy_action\", {\"query\": f\"Placeholder action for {task}\"}\n    \n    def _execute_action(self, action_name: str, action_input: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Execute an action using the appropriate tool.\n        \n        Args:\n            action_name: The name of the action/tool to execute.\n            action_input: The input parameters for the action.\n            \n        Returns:\n            The observation from executing the action.\n        \"\"\"\n        # Check if the action corresponds to a loaded tool\n        if action_name in self.tools:\n            try:\n                tool = self.tools[action_name]\n                result = tool.execute(**action_input)\n                \n                # Log the result (with some fun ANUS flair)\n                logging.info(f\"Tool {action_name} successfully executed.\")\n                \n                # If result is already a dict with status, return it directly\n                if isinstance(result, dict) and \"status\" in result:\n                    return result\n                    \n                # Otherwise, wrap it in a success response\n                return {\"status\": \"success\", \"result\": result}\n                \n            except Exception as e:\n                error_message = f\"Error executing tool {action_name}: {str(e)}\"\n                logging.error(error_message)\n                return {\"status\": \"error\", \"error\": error_message}\n        else:\n            # Try to load the tool if it's not already loaded\n            if self.load_tool(action_name):\n                # Retry execution with the newly loaded tool\n                return self._execute_action(action_name, action_input)\n            \n            return {\"status\": \"error\", \"error\": f\"Unknown action or tool: {action_name}\"}\n    \n    def list_available_tools(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        List all available tools.\n        \n        Returns:\n            A list of tool information dictionaries.\n        \"\"\"\n        tool_info = []\n        for name, tool in self.tools.items():\n            info = {\n                \"name\": name,\n                \"description\": getattr(tool, \"description\", \"No description available\"),\n                \"parameters\": getattr(tool, \"parameters\", {})\n            }\n            tool_info.append(info)\n        return tool_info "}
{"type": "source_file", "path": "anus/core/agent/base_agent.py", "content": "\"\"\"\nBase Agent module that defines the common interface for all agents.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, List, Any, Optional\nimport uuid\nimport time\n\nclass BaseAgent(ABC):\n    \"\"\"\n    Abstract base class for all agents in the ANUS framework.\n    \n    Provides the core functionality and interface that all agent types must implement.\n    \"\"\"\n    \n    def __init__(self, name: Optional[str] = None, **kwargs):\n        \"\"\"\n        Initialize a BaseAgent instance.\n        \n        Args:\n            name: Optional name for the agent. If not provided, a UUID will be generated.\n            **kwargs: Additional configuration options for the agent.\n        \"\"\"\n        self.id = str(uuid.uuid4())\n        self.name = name or f\"agent-{self.id[:8]}\"\n        self.created_at = time.time()\n        self.state: Dict[str, Any] = {\"status\": \"initialized\"}\n        self.history: List[Dict[str, Any]] = []\n        self.config = kwargs\n    \n    @abstractmethod\n    def execute(self, task: str, **kwargs) -> Dict[str, Any]:\n        \"\"\"\n        Execute a task and return the result.\n        \n        Args:\n            task: The task description to execute.\n            **kwargs: Additional parameters for task execution.\n            \n        Returns:\n            A dictionary containing the execution result and metadata.\n        \"\"\"\n        pass\n    \n    def update_state(self, **kwargs) -> None:\n        \"\"\"\n        Update the agent's state with new values.\n        \n        Args:\n            **kwargs: Key-value pairs to update in the state.\n        \"\"\"\n        self.state.update(kwargs)\n        \n    def log_action(self, action: str, details: Dict[str, Any]) -> None:\n        \"\"\"\n        Log an action performed by the agent.\n        \n        Args:\n            action: The name of the action.\n            details: Details about the action.\n        \"\"\"\n        log_entry = {\n            \"timestamp\": time.time(),\n            \"action\": action,\n            \"details\": details\n        }\n        self.history.append(log_entry)\n    \n    def get_info(self) -> Dict[str, Any]:\n        \"\"\"\n        Get information about the agent.\n        \n        Returns:\n            A dictionary containing agent information.\n        \"\"\"\n        return {\n            \"id\": self.id,\n            \"name\": self.name,\n            \"created_at\": self.created_at,\n            \"state\": self.state,\n            \"history_length\": len(self.history)\n        } "}
{"type": "source_file", "path": "anus/core/memory/__init__.py", "content": "\"\"\"\nMemory module for the ANUS framework.\n\nThis module contains various memory implementations:\n- BaseMemory: Abstract base class for all memory systems\n- ShortTermMemory: Volatile in-memory storage with LRU eviction\n- LongTermMemory: Persistent storage backed by a file system\n\"\"\"\n\nfrom anus.core.memory.base_memory import BaseMemory\nfrom anus.core.memory.short_term import ShortTermMemory\nfrom anus.core.memory.long_term import LongTermMemory\n\n__all__ = [\"BaseMemory\", \"ShortTermMemory\", \"LongTermMemory\"] "}
{"type": "source_file", "path": "anus/main.py", "content": "\"\"\"\r\nAnus - Autonomous Networked Utility System\r\nMain entry point for the Anus AI agent framework\r\n\"\"\"\r\n\r\nimport argparse\r\nimport sys\r\nfrom anus.core.orchestrator import AgentOrchestrator\r\nfrom anus.ui.cli import CLI\r\n\r\ndef main():\r\n    \"\"\"Main entry point for the Anus AI agent\"\"\"\r\n    parser = argparse.ArgumentParser(description=\"Anus AI - Autonomous Networked Utility System\")\r\n    parser.add_argument(\"--config\", type=str, default=\"config.yaml\", help=\"Path to configuration file\")\r\n    parser.add_argument(\"--mode\", type=str, default=\"single\", choices=[\"single\", \"multi\"], help=\"Agent mode\")\r\n    parser.add_argument(\"--task\", type=str, help=\"Task description\")\r\n    parser.add_argument(\"--verbose\", action=\"store_true\", help=\"Enable verbose output\")\r\n    \r\n    args = parser.parse_args()\r\n    \r\n    # Initialize the CLI\r\n    cli = CLI(verbose=args.verbose)\r\n    \r\n    # Display welcome message\r\n    cli.display_welcome()\r\n    \r\n    # Initialize the agent orchestrator\r\n    orchestrator = AgentOrchestrator(config_path=args.config)\r\n    \r\n    # If task is provided as argument, execute it\r\n    if args.task:\r\n        result = orchestrator.execute_task(args.task, mode=args.mode)\r\n        cli.display_result(result)\r\n        return\r\n    \r\n    # Otherwise, start interactive mode\r\n    cli.start_interactive_mode(orchestrator)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n"}
{"type": "source_file", "path": "anus/tools/__init__.py", "content": "\"\"\"\nTools module for the ANUS framework.\n\nThis module contains various tools that can be used by agents to interact with \nthe environment and perform tasks.\n\"\"\"\n\nfrom anus.tools.base import BaseTool, ToolResult, ToolCollection\n\n__all__ = [\"BaseTool\", \"ToolResult\", \"ToolCollection\"] "}
{"type": "source_file", "path": "anus/core/planning/__init__.py", "content": "\"\"\"\nPlanning module for the ANUS framework.\n\nThis module contains classes for task planning:\n- BasePlanner: Abstract base class for planners\n- TaskPlanner: LLM-based task planning implementation\n\"\"\"\n\nfrom anus.core.planning.base_planner import BasePlanner\nfrom anus.core.planning.task_planner import TaskPlanner\n\n__all__ = [\"BasePlanner\", \"TaskPlanner\"] "}
{"type": "source_file", "path": "anus/models/base/__init__.py", "content": "\"\"\"\nBase Models module for the ANUS framework.\n\nThis module contains the base model interfaces:\n- BaseModel: Abstract base class for all language models\n\"\"\"\n\nfrom anus.models.base.base_model import BaseModel\n\n__all__ = [\"BaseModel\"] "}
{"type": "source_file", "path": "anus/tools/search.py", "content": "\"\"\"\nSearch tool for basic web search simulation.\n\nThis tool simulates searching the web for information.\n\"\"\"\n\nimport logging\nimport random\nfrom typing import Dict, Any, Union, List\n\nfrom anus.tools.base.tool import BaseTool\nfrom anus.tools.base.tool_result import ToolResult\n\nclass SearchTool(BaseTool):\n    \"\"\"\n    A tool for simulating web searches.\n    \n    ANUS can search the web for information, though the results might be a bit cheeky.\n    \"\"\"\n    \n    name = \"search\"\n    description = \"Search the web for information\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The search query\"\n            }\n        },\n        \"required\": [\"query\"]\n    }\n    \n    # Mock search results for common queries\n    _mock_results = {\n        \"anus\": [\n            \"Anatomical term for the opening at the end of the digestive tract\",\n            \"ANUS: Autonomous Networked Utility System - An open-source AI framework\",\n            \"10 Facts About the ANUS Framework You Won't Believe!\",\n            \"Why ANUS is the Most Uncomfortably Named Software Project\"\n        ],\n        \"python\": [\n            \"Python - High-level programming language\",\n            \"Python (programming language) - Wikipedia\",\n            \"Python.org - Official Python documentation and downloads\",\n            \"Learning Python: The Definitive Guide\"\n        ],\n        \"ai\": [\n            \"Artificial Intelligence - Overview, applications, and recent advances\",\n            \"The Future of AI: Challenges and Opportunities\",\n            \"OpenAI - Leading AI research laboratory\",\n            \"How AI is Transforming Industries in 2025\"\n        ],\n        \"calculator\": [\n            \"Online Calculator - Free and Easy to Use\",\n            \"Scientific Calculator with Advanced Functions\",\n            \"History of the Calculator: From Abacus to Digital\",\n            \"Best Calculator Apps for Professionals\"\n        ]\n    }\n    \n    # Funny search messages\n    _search_messages = [\n        \"ANUS is probing the depths of the internet...\",\n        \"ANUS is digging deep for results...\",\n        \"ANUS is spreading wide to find all relevant information...\",\n        \"ANUS is penetrating the web for answers...\",\n        \"ANUS is squeezing out search results...\"\n    ]\n    \n    def execute(self, query: str, **kwargs) -> Union[Dict[str, Any], ToolResult]:\n        \"\"\"\n        Execute the search tool.\n        \n        Args:\n            query: The search query.\n            **kwargs: Additional parameters (ignored).\n            \n        Returns:\n            The search results.\n        \"\"\"\n        try:\n            # Log a funny search message\n            if random.random() < 0.4:  # 40% chance\n                logging.info(random.choice(self._search_messages))\n            \n            # Clean and lowercase the query for matching\n            clean_query = query.lower().strip()\n            \n            # Check for exact matches in our mock database\n            results = []\n            exact_match = False\n            \n            for key, mock_results in self._mock_results.items():\n                if key in clean_query:\n                    results.extend(mock_results)\n                    if key == clean_query:\n                        exact_match = True\n            \n            # If no direct matches, generate a generic response\n            if not results:\n                results = [\n                    f\"Result 1 for '{query}'\",\n                    f\"Article about {query} - Wikipedia\",\n                    f\"The Complete Guide to {query}\",\n                    f\"Latest News on {query}\"\n                ]\n            \n            # Add a cheeky comment for certain searches\n            comment = None\n            if \"anus\" in clean_query.lower() and not exact_match:\n                comment = \"I see you're interested in ANUS... the framework, right?\"\n            elif any(term in clean_query for term in [\"joke\", \"humor\", \"funny\"]):\n                comment = \"Looking for humor? ANUS itself is often the butt of jokes.\"\n            \n            # Return as ToolResult\n            result_dict = {\n                \"query\": query,\n                \"results\": results,\n                \"result_count\": len(results)\n            }\n            \n            if comment:\n                result_dict[\"comment\"] = comment\n                logging.info(f\"ANUS search added a cheeky comment: {comment}\")\n            \n            return {\n                \"query\": query,\n                \"results\": results,\n                \"result_count\": len(results),\n                \"comment\": comment\n            }\n            \n        except Exception as e:\n            error_msg = str(e)\n            logging.error(f\"Error in search tool: {e}\")\n            return {\"status\": \"error\", \"error\": f\"Search error: {error_msg}\"} "}
{"type": "source_file", "path": "anus/tools/base/__init__.py", "content": "\"\"\"\nBase Tool module for the ANUS framework.\n\nThis module contains base classes for tools:\n- BaseTool: Abstract base class for all tools\n- ToolResult: Standardized container for tool results\n- ToolCollection: Utility for managing collections of tools\n\"\"\"\n\nfrom anus.tools.base.tool import BaseTool\nfrom anus.tools.base.tool_result import ToolResult\nfrom anus.tools.base.tool_collection import ToolCollection\n\n__all__ = [\"BaseTool\", \"ToolResult\", \"ToolCollection\"] "}
{"type": "source_file", "path": "anus/core/memory/long_term.py", "content": "\"\"\"\nLong-term memory module for the ANUS framework.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Union\nimport uuid\nimport time\nimport json\nimport os\nimport logging\nfrom pathlib import Path\n\nfrom anus.core.memory.base_memory import BaseMemory\n\nclass LongTermMemory(BaseMemory):\n    \"\"\"\n    Persistent implementation of the BaseMemory interface.\n    \n    Provides a file-based persistent memory store.\n    \"\"\"\n    \n    def __init__(\n        self, \n        storage_path: Optional[str] = None,\n        index_in_memory: bool = True,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize a LongTermMemory instance.\n        \n        Args:\n            storage_path: Path to store memory files. If None, uses a default location.\n            index_in_memory: Whether to keep an in-memory index for faster searches.\n            **kwargs: Additional configuration options.\n        \"\"\"\n        super().__init__(**kwargs)\n        \n        # Set storage path\n        if storage_path is None:\n            home_dir = os.path.expanduser(\"~\")\n            storage_path = os.path.join(home_dir, \".anus\", \"memory\")\n        \n        self.storage_path = storage_path\n        self.index_in_memory = index_in_memory\n        \n        # Create storage directory if it doesn't exist\n        os.makedirs(self.storage_path, exist_ok=True)\n        \n        # Create indexes\n        self.index: Dict[str, Dict[str, Any]] = {}\n        \n        # Load index from disk if using in-memory indexing\n        if self.index_in_memory:\n            self._load_index()\n    \n    def add(self, item: Dict[str, Any]) -> str:\n        \"\"\"\n        Add an item to memory and return its identifier.\n        \n        Args:\n            item: The item to add to memory.\n            \n        Returns:\n            A string identifier for the added item.\n        \"\"\"\n        # Generate a unique identifier\n        identifier = str(uuid.uuid4())\n        \n        # Add metadata\n        item_with_metadata = item.copy()\n        item_with_metadata[\"_meta\"] = {\n            \"id\": identifier,\n            \"created_at\": time.time(),\n            \"updated_at\": time.time()\n        }\n        \n        # Save the item to disk\n        self._save_item(identifier, item_with_metadata)\n        \n        # Update the index\n        if self.index_in_memory:\n            self.index[identifier] = item_with_metadata\n        \n        return identifier\n    \n    def get(self, identifier: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieve an item from memory by its identifier.\n        \n        Args:\n            identifier: The identifier of the item to retrieve.\n            \n        Returns:\n            The retrieved item, or None if not found.\n        \"\"\"\n        # Check in-memory index first if available\n        if self.index_in_memory and identifier in self.index:\n            return self.index[identifier]\n        \n        # Otherwise, load from disk\n        item_path = self._get_item_path(identifier)\n        if not os.path.exists(item_path):\n            return None\n        \n        try:\n            with open(item_path, \"r\") as f:\n                return json.load(f)\n        except Exception as e:\n            logging.error(f\"Error loading item {identifier}: {e}\")\n            return None\n    \n    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search memory for items matching the query.\n        \n        Args:\n            query: The search query.\n            limit: Maximum number of results to return.\n            \n        Returns:\n            A list of matching items.\n        \"\"\"\n        results = []\n        \n        # If using in-memory index, search there\n        if self.index_in_memory:\n            for identifier, item in self.index.items():\n                if self._matches_query(item, query):\n                    results.append({\n                        \"id\": identifier,\n                        \"item\": item,\n                        \"created_at\": item.get(\"_meta\", {}).get(\"created_at\", 0)\n                    })\n                    \n                    if len(results) >= limit:\n                        break\n        else:\n            # Otherwise, scan the storage directory\n            for item_file in os.listdir(self.storage_path):\n                if not item_file.endswith(\".json\"):\n                    continue\n                \n                identifier = item_file[:-5]  # Remove .json extension\n                item = self.get(identifier)\n                \n                if item and self._matches_query(item, query):\n                    results.append({\n                        \"id\": identifier,\n                        \"item\": item,\n                        \"created_at\": item.get(\"_meta\", {}).get(\"created_at\", 0)\n                    })\n                    \n                    if len(results) >= limit:\n                        break\n        \n        # Sort by creation time (newest first)\n        results.sort(key=lambda x: x[\"created_at\"], reverse=True)\n        \n        return results\n    \n    def update(self, identifier: str, item: Dict[str, Any]) -> bool:\n        \"\"\"\n        Update an item in memory.\n        \n        Args:\n            identifier: The identifier of the item to update.\n            item: The updated item.\n            \n        Returns:\n            True if the update was successful, False otherwise.\n        \"\"\"\n        # Check if the item exists\n        existing_item = self.get(identifier)\n        if existing_item is None:\n            return False\n        \n        # Preserve metadata\n        item_with_metadata = item.copy()\n        if \"_meta\" in existing_item:\n            item_with_metadata[\"_meta\"] = existing_item[\"_meta\"]\n            item_with_metadata[\"_meta\"][\"updated_at\"] = time.time()\n        else:\n            item_with_metadata[\"_meta\"] = {\n                \"id\": identifier,\n                \"created_at\": time.time(),\n                \"updated_at\": time.time()\n            }\n        \n        # Save the updated item\n        self._save_item(identifier, item_with_metadata)\n        \n        # Update the index\n        if self.index_in_memory:\n            self.index[identifier] = item_with_metadata\n        \n        return True\n    \n    def delete(self, identifier: str) -> bool:\n        \"\"\"\n        Delete an item from memory.\n        \n        Args:\n            identifier: The identifier of the item to delete.\n            \n        Returns:\n            True if the deletion was successful, False otherwise.\n        \"\"\"\n        item_path = self._get_item_path(identifier)\n        if not os.path.exists(item_path):\n            return False\n        \n        try:\n            os.remove(item_path)\n            \n            # Update the index\n            if self.index_in_memory and identifier in self.index:\n                del self.index[identifier]\n            \n            return True\n        except Exception as e:\n            logging.error(f\"Error deleting item {identifier}: {e}\")\n            return False\n    \n    def clear(self) -> None:\n        \"\"\"\n        Clear all items from memory.\n        \"\"\"\n        for item_file in os.listdir(self.storage_path):\n            if not item_file.endswith(\".json\"):\n                continue\n            \n            try:\n                os.remove(os.path.join(self.storage_path, item_file))\n            except Exception as e:\n                logging.error(f\"Error deleting file {item_file}: {e}\")\n        \n        # Clear the index\n        if self.index_in_memory:\n            self.index = {}\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"\n        Get statistics about the memory system.\n        \n        Returns:\n            A dictionary containing memory statistics.\n        \"\"\"\n        # Count the number of items\n        if self.index_in_memory:\n            item_count = len(self.index)\n        else:\n            item_count = len([f for f in os.listdir(self.storage_path) if f.endswith(\".json\")])\n        \n        # Get the total size of all items\n        total_size = sum(\n            os.path.getsize(os.path.join(self.storage_path, f)) \n            for f in os.listdir(self.storage_path) \n            if os.path.isfile(os.path.join(self.storage_path, f)) and f.endswith(\".json\")\n        )\n        \n        return {\n            \"type\": \"long_term\",\n            \"storage_path\": self.storage_path,\n            \"index_in_memory\": self.index_in_memory,\n            \"item_count\": item_count,\n            \"total_size_bytes\": total_size\n        }\n    \n    def _get_item_path(self, identifier: str) -> str:\n        \"\"\"\n        Get the file path for an item.\n        \n        Args:\n            identifier: The identifier of the item.\n            \n        Returns:\n            The file path for the item.\n        \"\"\"\n        return os.path.join(self.storage_path, f\"{identifier}.json\")\n    \n    def _save_item(self, identifier: str, item: Dict[str, Any]) -> None:\n        \"\"\"\n        Save an item to disk.\n        \n        Args:\n            identifier: The identifier of the item.\n            item: The item to save.\n        \"\"\"\n        item_path = self._get_item_path(identifier)\n        \n        try:\n            with open(item_path, \"w\") as f:\n                json.dump(item, f, indent=2)\n        except Exception as e:\n            logging.error(f\"Error saving item {identifier}: {e}\")\n    \n    def _load_index(self) -> None:\n        \"\"\"\n        Load the index from disk.\n        \"\"\"\n        self.index = {}\n        \n        for item_file in os.listdir(self.storage_path):\n            if not item_file.endswith(\".json\"):\n                continue\n            \n            identifier = item_file[:-5]  # Remove .json extension\n            \n            try:\n                with open(os.path.join(self.storage_path, item_file), \"r\") as f:\n                    item = json.load(f)\n                    self.index[identifier] = item\n            except Exception as e:\n                logging.error(f\"Error loading index for {identifier}: {e}\")\n    \n    def _matches_query(self, item: Dict[str, Any], query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if an item matches a query.\n        \n        Args:\n            item: The item to check.\n            query: The query to match against.\n            \n        Returns:\n            True if the item matches the query, False otherwise.\n        \"\"\"\n        for key, value in query.items():\n            # Handle nested keys with dot notation\n            if \".\" in key:\n                parts = key.split(\".\")\n                curr = item\n                for part in parts:\n                    if isinstance(curr, dict) and part in curr:\n                        curr = curr[part]\n                    else:\n                        return False\n                \n                if curr != value:\n                    return False\n            # Handle simple keys\n            elif key not in item or item[key] != value:\n                return False\n        \n        return True "}
{"type": "source_file", "path": "anus/core/memory/short_term.py", "content": "\"\"\"\nShort-term memory module for the ANUS framework.\n\nBecause even an ANUS needs to remember what it just processed.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Union\nimport uuid\nimport time\nimport heapq\nimport logging\nimport random\n\nfrom anus.core.memory.base_memory import BaseMemory\n\nclass ShortTermMemory(BaseMemory):\n    \"\"\"\n    In-memory implementation of the BaseMemory interface.\n    \n    Provides a volatile memory store with automatic pruning of old items.\n    \n    Just like the human ANUS, it's good at handling recent input but tends to \n    forget older stuff if not regularly refreshed.\n    \"\"\"\n    \n    # Funny memory-related messages\n    _memory_messages = [\n        \"ANUS short-term memory retaining item...\",\n        \"Storing this for quick retrieval from your ANUS...\",\n        \"This item is now tightly held in ANUS memory...\",\n        \"Squeezing this into ANUS short-term storage...\",\n        \"ANUS will remember this, at least for a little while...\"\n    ]\n    \n    def __init__(\n        self, \n        capacity: int = 1000, \n        ttl: int = 3600,  # Time to live in seconds\n        **kwargs\n    ):\n        \"\"\"\n        Initialize a ShortTermMemory instance.\n        \n        Args:\n            capacity: Maximum number of items to store.\n            ttl: Time to live for items in seconds.\n            **kwargs: Additional configuration options.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.capacity = capacity\n        self.ttl = ttl\n        self.items: Dict[str, Dict[str, Any]] = {}\n        self.access_times: Dict[str, float] = {}\n        self.creation_times: Dict[str, float] = {}\n        self.lru_queue: List[tuple] = []  # Priority queue for LRU eviction\n        \n        if capacity < 100:\n            logging.warning(f\"ANUS short-term memory capacity of {capacity} is quite small. Performance may suffer.\")\n        elif capacity > 10000:\n            logging.warning(f\"ANUS short-term memory capacity of {capacity} is unusually large. Hope you have enough RAM!\")\n        \n        logging.info(f\"ANUS short-term memory initialized with capacity for {capacity} items and {ttl}s retention\")\n    \n    def add(self, item: Dict[str, Any]) -> str:\n        \"\"\"\n        Add an item to memory and return its identifier.\n        \n        If the memory is at capacity, the least recently used item will be evicted.\n        \n        Args:\n            item: The item to add to memory.\n            \n        Returns:\n            A string identifier for the added item.\n        \"\"\"\n        # Prune expired items\n        self._prune_expired()\n        \n        # Generate a unique identifier\n        identifier = str(uuid.uuid4())\n        \n        # Add the item\n        self.items[identifier] = item\n        current_time = time.time()\n        self.access_times[identifier] = current_time\n        self.creation_times[identifier] = current_time\n        \n        # Add to LRU queue\n        heapq.heappush(self.lru_queue, (current_time, identifier))\n        \n        # Check capacity and evict if necessary\n        if len(self.items) > self.capacity:\n            self._evict_lru()\n            \n        # 5% chance to log a funny memory message\n        if random.random() < 0.05:\n            logging.debug(random.choice(self._memory_messages))\n            \n        # Log capacity status if getting full\n        capacity_pct = len(self.items) / self.capacity * 100\n        if capacity_pct > 90:\n            logging.warning(f\"ANUS short-term memory is {capacity_pct:.1f}% full. Starting to feel tight in here!\")\n        \n        return identifier\n    \n    def get(self, identifier: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieve an item from memory by its identifier.\n        \n        Updates the access time of the item to prevent it from being evicted.\n        \n        Args:\n            identifier: The identifier of the item to retrieve.\n            \n        Returns:\n            The retrieved item, or None if not found.\n        \"\"\"\n        # Prune expired items\n        self._prune_expired()\n        \n        # Check if the item exists\n        if identifier not in self.items:\n            logging.debug(f\"ANUS has no recollection of item {identifier[:8]}...\")\n            return None\n        \n        # Update access time\n        self.access_times[identifier] = time.time()\n        \n        # Return the item\n        logging.debug(f\"ANUS recalls this item perfectly!\")\n        return self.items[identifier]\n    \n    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search memory for items matching the query.\n        \n        Simple implementation that checks for exact matches on query fields.\n        \n        Args:\n            query: The search query.\n            limit: Maximum number of results to return.\n            \n        Returns:\n            A list of matching items.\n        \"\"\"\n        # Prune expired items\n        self._prune_expired()\n        \n        logging.debug(f\"ANUS is probing deeply for matching items...\")\n        \n        results = []\n        \n        for identifier, item in self.items.items():\n            # Check if all query fields match\n            is_match = True\n            for key, value in query.items():\n                if key not in item or item[key] != value:\n                    is_match = False\n                    break\n            \n            if is_match:\n                # Update access time\n                self.access_times[identifier] = time.time()\n                \n                # Add to results\n                results.append({\n                    \"id\": identifier,\n                    \"item\": item,\n                    \"created_at\": self.creation_times[identifier]\n                })\n                \n                # Check limit\n                if len(results) >= limit:\n                    break\n        \n        # Sort by recency\n        results.sort(key=lambda x: x[\"created_at\"], reverse=True)\n        \n        if not results:\n            logging.debug(\"ANUS found nothing that matches. How disappointing.\")\n        else:\n            logging.debug(f\"ANUS successfully extracted {len(results)} matching items!\")\n        \n        return results\n    \n    def update(self, identifier: str, item: Dict[str, Any]) -> bool:\n        \"\"\"\n        Update an item in memory.\n        \n        Args:\n            identifier: The identifier of the item to update.\n            item: The updated item.\n            \n        Returns:\n            True if the update was successful, False otherwise.\n        \"\"\"\n        # Prune expired items\n        self._prune_expired()\n        \n        # Check if the item exists\n        if identifier not in self.items:\n            logging.debug(f\"ANUS can't update what it doesn't have (identifier: {identifier[:8]})\")\n            return False\n        \n        # Update the item\n        self.items[identifier] = item\n        \n        # Update access time\n        self.access_times[identifier] = time.time()\n        \n        logging.debug(f\"ANUS memory successfully updated with fresh content\")\n        return True\n    \n    def delete(self, identifier: str) -> bool:\n        \"\"\"\n        Delete an item from memory.\n        \n        Args:\n            identifier: The identifier of the item to delete.\n            \n        Returns:\n            True if the deletion was successful, False otherwise.\n        \"\"\"\n        # Check if the item exists\n        if identifier not in self.items:\n            return False\n        \n        # Delete the item\n        del self.items[identifier]\n        del self.access_times[identifier]\n        del self.creation_times[identifier]\n        \n        # Note: The item will remain in the LRU queue, but will be skipped when it's popped\n        \n        logging.debug(f\"ANUS has purged this item from its memory\")\n        return True\n    \n    def clear(self) -> None:\n        \"\"\"\n        Clear all items from memory.\n        \"\"\"\n        old_count = len(self.items)\n        self.items = {}\n        self.access_times = {}\n        self.creation_times = {}\n        self.lru_queue = []\n        \n        logging.info(f\"ANUS memory has been completely flushed of {old_count} items. Fresh and clean!\")\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"\n        Get statistics about the memory system.\n        \n        Returns:\n            A dictionary containing memory statistics.\n        \"\"\"\n        utilization = len(self.items) / self.capacity if self.capacity > 0 else 0\n        \n        # Add a funny message based on utilization\n        if utilization > 0.9:\n            status = \"ANUS memory is nearly full! Things are getting tight in here.\"\n        elif utilization > 0.7:\n            status = \"ANUS memory is filling up nicely.\"\n        elif utilization > 0.4:\n            status = \"ANUS memory has plenty of room for more.\"\n        else:\n            status = \"ANUS memory is mostly empty. Feed me more data!\"\n            \n        return {\n            \"type\": \"short_term\",\n            \"capacity\": self.capacity,\n            \"ttl\": self.ttl,\n            \"current_size\": len(self.items),\n            \"utilization\": utilization,\n            \"status\": status\n        }\n    \n    def _prune_expired(self) -> None:\n        \"\"\"\n        Remove items that have exceeded their time to live.\n        \"\"\"\n        current_time = time.time()\n        expired_identifiers = []\n        \n        for identifier, creation_time in self.creation_times.items():\n            if current_time - creation_time > self.ttl:\n                expired_identifiers.append(identifier)\n        \n        if expired_identifiers:\n            for identifier in expired_identifiers:\n                self.delete(identifier)\n            \n            logging.debug(f\"ANUS has expelled {len(expired_identifiers)} expired items from memory\")\n    \n    def _evict_lru(self) -> None:\n        \"\"\"\n        Evict the least recently used item from memory.\n        \"\"\"\n        while self.lru_queue:\n            _, identifier = heapq.heappop(self.lru_queue)\n            \n            # Skip if the item has been deleted\n            if identifier not in self.items:\n                continue\n            \n            # Delete the item\n            item_name = self.items[identifier].get(\"name\", \"unknown\")\n            self.delete(identifier)\n            logging.debug(f\"ANUS had to push out '{item_name}' to make room for new content\")\n            break "}
{"type": "source_file", "path": "anus/tools/text.py", "content": "\"\"\"\nText tool for basic text processing and manipulation.\n\nThis tool provides various text manipulation functions, such as counting words,\nformatting text, and basic analysis.\n\"\"\"\n\nimport logging\nimport re\nfrom typing import Dict, Any, Union, List\n\nfrom anus.tools.base.tool import BaseTool\nfrom anus.tools.base.tool_result import ToolResult\n\nclass TextTool(BaseTool):\n    \"\"\"\n    A tool for processing and manipulating text.\n    \n    ANUS can handle your text in all sorts of interesting ways.\n    \"\"\"\n    \n    name = \"text\"\n    description = \"Process and manipulate text\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"text\": {\n                \"type\": \"string\",\n                \"description\": \"The text to process\"\n            },\n            \"operation\": {\n                \"type\": \"string\",\n                \"description\": \"The operation to perform (count, reverse, uppercase, lowercase, capitalize, wordcount)\",\n                \"enum\": [\"count\", \"reverse\", \"uppercase\", \"lowercase\", \"capitalize\", \"wordcount\"]\n            }\n        },\n        \"required\": [\"text\", \"operation\"]\n    }\n    \n    # Operation descriptions with ANUS flair\n    _operation_descriptions = {\n        \"count\": \"ANUS is counting characters...\",\n        \"reverse\": \"ANUS is turning your text backward...\",\n        \"uppercase\": \"ANUS is making everything BIGGER...\",\n        \"lowercase\": \"ANUS is making everything smaller...\",\n        \"capitalize\": \"ANUS is making your text look Important...\",\n        \"wordcount\": \"ANUS is counting your words one by one...\"\n    }\n    \n    def execute(self, text: str, operation: str, **kwargs) -> Union[Dict[str, Any], ToolResult]:\n        \"\"\"\n        Execute the text tool.\n        \n        Args:\n            text: The text to process.\n            operation: The operation to perform.\n            **kwargs: Additional parameters (ignored).\n            \n        Returns:\n            The processed text result.\n        \"\"\"\n        try:\n            # Log the operation with ANUS flair\n            logging.info(self._operation_descriptions.get(operation, f\"ANUS is processing your text with {operation}...\"))\n            \n            # Perform the requested operation\n            result = None\n            if operation == \"count\":\n                result = len(text)\n            elif operation == \"reverse\":\n                result = text[::-1]\n            elif operation == \"uppercase\":\n                result = text.upper()\n            elif operation == \"lowercase\":\n                result = text.lower()\n            elif operation == \"capitalize\":\n                result = text.title()\n            elif operation == \"wordcount\":\n                result = len(text.split())\n            else:\n                raise ValueError(f\"Unknown operation: {operation}\")\n            \n            # Add a fun fact for certain operations\n            fun_fact = None\n            if operation == \"wordcount\" and result > 100:\n                fun_fact = \"That's a lot of words! ANUS is impressed by your verbosity.\"\n            elif operation == \"uppercase\":\n                fun_fact = \"ALL CAPS? ANUS FEELS LIKE YOU'RE SHOUTING!\"\n            elif operation == \"count\" and result > 500:\n                fun_fact = \"That's a substantial chunk of text. ANUS had to really stretch to process all of it!\"\n            \n            # Return the result\n            result_dict = {\n                \"text\": text[:50] + \"...\" if len(text) > 50 else text,  # Truncate long inputs\n                \"operation\": operation,\n                \"result\": result\n            }\n            \n            if fun_fact:\n                result_dict[\"fun_fact\"] = fun_fact\n            \n            return result_dict\n            \n        except Exception as e:\n            error_msg = str(e)\n            logging.error(f\"Error in text tool: {e}\")\n            return {\"status\": \"error\", \"error\": f\"Text processing error: {error_msg}\"} "}
{"type": "source_file", "path": "anus/models/__init__.py", "content": "\"\"\"\nModels module for the ANUS framework.\n\nThis module contains language model implementations and utilities:\n- BaseModel: Abstract base class for all language models\n- OpenAIModel: Implementation for the OpenAI API\n- ModelRouter: Dynamic model selection based on task requirements\n\"\"\"\n\nfrom anus.models.base import BaseModel\nfrom anus.models.openai_model import OpenAIModel\nfrom anus.models.model_router import ModelRouter\n\n__all__ = [\"BaseModel\", \"OpenAIModel\", \"ModelRouter\"] "}
{"type": "source_file", "path": "anus/models/model_router.py", "content": "\"\"\"\nModel Router module for dynamic model selection.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Union, Type\nimport logging\n\nfrom anus.models.base.base_model import BaseModel\nfrom anus.models.openai_model import OpenAIModel\n\nclass ModelRouter:\n    \"\"\"\n    Router for dynamically selecting and managing language models.\n    \n    Provides functionality for:\n    - Registering different model implementations\n    - Selecting models based on task requirements\n    - Fallback mechanisms for reliability\n    \"\"\"\n    \n    def __init__(self, default_model_config: Optional[Dict[str, Any]] = None):\n        \"\"\"\n        Initialize a ModelRouter instance.\n        \n        Args:\n            default_model_config: Configuration for the default model.\n        \"\"\"\n        self.models: Dict[str, BaseModel] = {}\n        self.model_classes: Dict[str, Type[BaseModel]] = {\n            \"openai\": OpenAIModel\n        }\n        self.default_model_config = default_model_config or {\n            \"provider\": \"openai\",\n            \"model_name\": \"gpt-4\",\n            \"temperature\": 0.0\n        }\n        self.default_model = None\n    \n    def register_model(self, name: str, model: BaseModel) -> None:\n        \"\"\"\n        Register a model instance.\n        \n        Args:\n            name: A unique name for the model.\n            model: The model instance to register.\n        \"\"\"\n        self.models[name] = model\n        logging.info(f\"Registered model: {name}\")\n    \n    def register_model_class(self, provider: str, model_class: Type[BaseModel]) -> None:\n        \"\"\"\n        Register a model class for a provider.\n        \n        Args:\n            provider: The model provider name.\n            model_class: The model class to register.\n        \"\"\"\n        self.model_classes[provider] = model_class\n        logging.info(f\"Registered model class for provider: {provider}\")\n    \n    def get_model(self, name_or_config: Union[str, Dict[str, Any]]) -> BaseModel:\n        \"\"\"\n        Get a model instance by name or create one from config.\n        \n        Args:\n            name_or_config: Either a model name or a model configuration dictionary.\n            \n        Returns:\n            A model instance.\n        \"\"\"\n        # If it's a string, look up by name\n        if isinstance(name_or_config, str):\n            # Check registered models\n            if name_or_config in self.models:\n                return self.models[name_or_config]\n            \n            # If not found, use default model\n            logging.warning(f\"Model '{name_or_config}' not found. Using default model.\")\n            return self.get_default_model()\n        \n        # If it's a config dict, create a new model\n        elif isinstance(name_or_config, dict):\n            return self._create_model_from_config(name_or_config)\n        \n        # Invalid input\n        else:\n            logging.error(f\"Invalid model specification: {name_or_config}\")\n            return self.get_default_model()\n    \n    def get_default_model(self) -> BaseModel:\n        \"\"\"\n        Get the default model, creating it if necessary.\n        \n        Returns:\n            The default model instance.\n        \"\"\"\n        if self.default_model is None:\n            self.default_model = self._create_model_from_config(self.default_model_config)\n        \n        return self.default_model\n    \n    def select_model_for_task(self, task: str, requirements: Dict[str, Any] = None) -> BaseModel:\n        \"\"\"\n        Select an appropriate model for a given task.\n        \n        Args:\n            task: The task description.\n            requirements: Optional requirements for the model.\n            \n        Returns:\n            The selected model instance.\n        \"\"\"\n        # Simple implementation: just use requirements if provided\n        if requirements:\n            return self._create_model_from_config(requirements)\n        \n        # Default to the default model\n        return self.get_default_model()\n    \n    def _create_model_from_config(self, config: Dict[str, Any]) -> BaseModel:\n        \"\"\"\n        Create a model instance from a configuration dictionary.\n        \n        Args:\n            config: The model configuration.\n            \n        Returns:\n            A model instance.\n        \"\"\"\n        # Get the provider\n        provider = config.get(\"provider\", \"openai\").lower()\n        \n        # Check if we have a class for this provider\n        if provider not in self.model_classes:\n            logging.error(f\"Unknown model provider: {provider}. Using OpenAI as fallback.\")\n            provider = \"openai\"\n        \n        try:\n            # Get the model class\n            model_class = self.model_classes[provider]\n            \n            # Extract kwargs for the model\n            kwargs = config.copy()\n            kwargs.pop(\"provider\", None)\n            \n            # Create the model\n            return model_class(**kwargs)\n            \n        except Exception as e:\n            logging.error(f\"Error creating model for provider {provider}: {e}\")\n            \n            # Fallback to OpenAI with minimal config\n            try:\n                return OpenAIModel(model_name=\"gpt-4\")\n            except Exception:\n                raise ValueError(f\"Failed to create model: {e}\")\n    \n    def list_available_models(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        List all available models.\n        \n        Returns:\n            A list of model information dictionaries.\n        \"\"\"\n        models_info = []\n        \n        # Add instantiated models\n        for name, model in self.models.items():\n            info = {\n                \"name\": name,\n                \"type\": type(model).__name__,\n                \"model_name\": model.model_name,\n                \"details\": model.get_model_details()\n            }\n            models_info.append(info)\n        \n        # Add available providers\n        for provider in self.model_classes.keys():\n            if provider not in [info[\"details\"].get(\"provider\") for info in models_info]:\n                models_info.append({\n                    \"name\": f\"{provider}\",\n                    \"type\": self.model_classes[provider].__name__,\n                    \"details\": {\"provider\": provider}\n                })\n        \n        return models_info "}
{"type": "source_file", "path": "anus/core/memory/base_memory.py", "content": "\"\"\"\nBase Memory module that defines the common interface for memory systems.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, List, Any, Optional, Union\n\nclass BaseMemory(ABC):\n    \"\"\"\n    Abstract base class for memory systems in the ANUS framework.\n    \n    Provides the core functionality and interface that all memory types must implement.\n    \"\"\"\n    \n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize a BaseMemory instance.\n        \n        Args:\n            **kwargs: Additional configuration options for the memory system.\n        \"\"\"\n        self.config = kwargs\n    \n    @abstractmethod\n    def add(self, item: Dict[str, Any]) -> str:\n        \"\"\"\n        Add an item to memory and return its identifier.\n        \n        Args:\n            item: The item to add to memory.\n            \n        Returns:\n            A string identifier for the added item.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def get(self, identifier: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieve an item from memory by its identifier.\n        \n        Args:\n            identifier: The identifier of the item to retrieve.\n            \n        Returns:\n            The retrieved item, or None if not found.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search memory for items matching the query.\n        \n        Args:\n            query: The search query.\n            limit: Maximum number of results to return.\n            \n        Returns:\n            A list of matching items.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def update(self, identifier: str, item: Dict[str, Any]) -> bool:\n        \"\"\"\n        Update an item in memory.\n        \n        Args:\n            identifier: The identifier of the item to update.\n            item: The updated item.\n            \n        Returns:\n            True if the update was successful, False otherwise.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def delete(self, identifier: str) -> bool:\n        \"\"\"\n        Delete an item from memory.\n        \n        Args:\n            identifier: The identifier of the item to delete.\n            \n        Returns:\n            True if the deletion was successful, False otherwise.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def clear(self) -> None:\n        \"\"\"\n        Clear all items from memory.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"\n        Get statistics about the memory system.\n        \n        Returns:\n            A dictionary containing memory statistics.\n        \"\"\"\n        pass "}
{"type": "source_file", "path": "anus/ui/__init__.py", "content": "\"\"\"\nUI module for the ANUS framework.\n\nThis module contains user interface components:\n- CLI: Command-line interface\n\"\"\"\n\nfrom anus.ui.cli import CLI\n\n__all__ = [\"CLI\"] "}
{"type": "source_file", "path": "anus/tools/calculator.py", "content": "\"\"\"\nCalculator tool for basic arithmetic operations.\n\nThis tool provides safe evaluation of mathematical expressions.\n\"\"\"\n\nimport logging\nimport ast\nimport operator\nfrom typing import Dict, Any, Union\n\nfrom anus.tools.base.tool import BaseTool\nfrom anus.tools.base.tool_result import ToolResult\n\nclass CalculatorTool(BaseTool):\n    \"\"\"\n    A tool for performing basic arithmetic calculations.\n    \n    ANUS can handle your numbers with precision and care.\n    \"\"\"\n    \n    name = \"calculator\"\n    description = \"Perform basic arithmetic calculations\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"expression\": {\n                \"type\": \"string\",\n                \"description\": \"The mathematical expression to evaluate\"\n            }\n        },\n        \"required\": [\"expression\"]\n    }\n    \n    # Supported operators and their corresponding functions\n    _OPERATORS = {\n        ast.Add: operator.add,\n        ast.Sub: operator.sub,\n        ast.Mult: operator.mul,\n        ast.Div: operator.truediv,\n        ast.Pow: operator.pow,\n        ast.USub: operator.neg,  # Unary minus\n    }\n    \n    def execute(self, expression: str, **kwargs) -> Union[Dict[str, Any], ToolResult]:\n        \"\"\"\n        Execute the calculator tool.\n        \n        Args:\n            expression: The mathematical expression to evaluate.\n            **kwargs: Additional parameters (ignored).\n            \n        Returns:\n            The calculation result.\n        \"\"\"\n        try:\n            # Clean the expression\n            clean_expr = expression.strip()\n            logging.info(f\"Calculator received expression: '{clean_expr}'\")\n            \n            # Add some ANUS flair for certain numbers\n            if \"42\" in clean_expr:\n                logging.info(\"ANUS calculator triggered an easter egg: 42\")\n            elif \"69\" in clean_expr:\n                logging.info(\"ANUS calculator is keeping it professional...\")\n            \n            # Parse and evaluate the expression\n            logging.info(f\"Parsing expression: '{clean_expr}'\")\n            tree = ast.parse(clean_expr, mode='eval')\n            logging.info(f\"AST tree: {ast.dump(tree)}\")\n            result = self._eval_expr(tree.body)\n            logging.info(f\"Evaluation result: {result}\")\n            \n            # Add some ANUS humor based on the result\n            if result == 69:\n                logging.info(\"ANUS calculator is maintaining its composure...\")\n            elif result == 404:\n                logging.info(\"ANUS calculator lost something in the backend...\")\n            elif result == 42:\n                logging.info(\"ANUS calculator found the meaning of life!\")\n            \n            # Format the result nicely\n            if isinstance(result, float):\n                # Round to 6 decimal places if it's a float\n                result = round(result, 6)\n                # Remove trailing zeros after decimal point\n                result_str = f\"{result:f}\".rstrip('0').rstrip('.')\n            else:\n                result_str = str(result)\n            \n            logging.info(f\"Formatted result: {result_str}\")\n            return {\n                \"expression\": clean_expr,\n                \"result\": result_str,\n                \"status\": \"success\"\n            }\n            \n        except Exception as e:\n            error_msg = str(e)\n            logging.error(f\"Error in calculator: {e}\")\n            return {\"status\": \"error\", \"error\": f\"Calculation error: {error_msg}\"}\n    \n    def _eval_expr(self, node: ast.AST) -> float:\n        \"\"\"\n        Recursively evaluate an AST expression node.\n        \n        Args:\n            node: The AST node to evaluate.\n            \n        Returns:\n            The evaluated result.\n            \n        Raises:\n            ValueError: If the expression contains unsupported operations.\n        \"\"\"\n        # Numbers\n        if isinstance(node, ast.Num):\n            return float(node.n)\n            \n        # Binary operations (e.g., 2 + 3, 4 * 5)\n        elif isinstance(node, ast.BinOp):\n            if type(node.op) not in self._OPERATORS:\n                raise ValueError(f\"Unsupported operator: {type(node.op).__name__}\")\n            \n            left = self._eval_expr(node.left)\n            right = self._eval_expr(node.right)\n            \n            # Debug log for binary operations\n            logging.debug(f\"Binary operation: {left} {type(node.op).__name__} {right}\")\n            \n            # Special case for division by zero\n            if isinstance(node.op, ast.Div) and right == 0:\n                raise ValueError(\"ANUS cannot divide by zero - it's too tight!\")\n                \n            # Apply the operation\n            result = self._OPERATORS[type(node.op)](left, right)\n            logging.debug(f\"Operation result: {result}\")\n            \n            return result\n            \n        # Unary operations (e.g., -5)\n        elif isinstance(node, ast.UnaryOp):\n            if type(node.op) not in self._OPERATORS:\n                raise ValueError(f\"Unsupported unary operator: {type(node.op).__name__}\")\n            \n            operand = self._eval_expr(node.operand)\n            return self._OPERATORS[type(node.op)](operand)\n            \n        # Constants\n        elif isinstance(node, ast.Constant):\n            if isinstance(node.value, (int, float)):\n                return float(node.value)\n            raise ValueError(f\"Unsupported constant type: {type(node.value).__name__}\")\n            \n        else:\n            raise ValueError(f\"Unsupported expression type: {type(node).__name__}\")\n\n# Re-export the calculator tool\n__all__ = [\"CalculatorTool\"] "}
{"type": "source_file", "path": "anus/tools/base/tool.py", "content": "\"\"\"\nBase Tool module that defines the common interface for all tools.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, List, Any, Optional, Union\n\nclass BaseTool(ABC):\n    \"\"\"\n    Abstract base class for all tools in the ANUS framework.\n    \n    Provides the core functionality and interface that all tool types must implement.\n    \"\"\"\n    \n    name = \"base_tool\"\n    description = \"Base class for all tools\"\n    \n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize a BaseTool instance.\n        \n        Args:\n            **kwargs: Additional configuration options for the tool.\n        \"\"\"\n        self.config = kwargs\n    \n    @abstractmethod\n    def execute(self, **kwargs) -> Any:\n        \"\"\"\n        Execute the tool's function.\n        \n        Args:\n            **kwargs: Input parameters for the tool.\n            \n        Returns:\n            The result of the tool execution.\n        \"\"\"\n        pass\n    \n    def validate_input(self, **kwargs) -> bool:\n        \"\"\"\n        Validate the input parameters.\n        \n        Args:\n            **kwargs: Input parameters to validate.\n            \n        Returns:\n            True if the input is valid, False otherwise.\n        \"\"\"\n        # Base implementation is a pass-through\n        return True\n    \n    def get_schema(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the tool's parameter schema.\n        \n        Returns:\n            A dictionary describing the tool's parameters.\n        \"\"\"\n        # Base implementation returns a simple schema\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"parameters\": {}\n        } "}
{"type": "source_file", "path": "anus/core/planning/task_planner.py", "content": "\"\"\"\nTask Planner module for LLM-based task planning.\n\"\"\"\n\nimport uuid\nimport time\nimport json\nimport logging\nfrom typing import Dict, List, Any, Optional, Union\n\nfrom anus.core.planning.base_planner import BasePlanner\nfrom anus.models.base.base_model import BaseModel\n\nclass TaskPlanner(BasePlanner):\n    \"\"\"\n    A planner that uses language models to create and manage task plans.\n    \n    Implements task breakdown, dependency tracking, and adaptive replanning.\n    \"\"\"\n    \n    def __init__(self, model: BaseModel, **kwargs):\n        \"\"\"\n        Initialize a TaskPlanner instance.\n        \n        Args:\n            model: The language model to use for planning.\n            **kwargs: Additional configuration options for the planner.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.model = model\n        self.max_steps = kwargs.get(\"max_steps\", 10)\n    \n    def create_plan(self, task: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Create a plan for executing a task using the language model.\n        \n        Args:\n            task: The task description.\n            context: Optional context for planning.\n            \n        Returns:\n            A plan dictionary with steps and metadata.\n        \"\"\"\n        context = context or {}\n        \n        # Prepare the planning prompt\n        prompt = self._create_planning_prompt(task, context)\n        \n        # Extract JSON schema for the plan\n        plan_schema = {\n            \"type\": \"object\",\n            \"properties\": {\n                \"steps\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"id\": {\"type\": \"string\"},\n                            \"name\": {\"type\": \"string\"},\n                            \"description\": {\"type\": \"string\"},\n                            \"tool\": {\"type\": \"string\"},\n                            \"tool_input\": {\"type\": \"object\"},\n                            \"expected_output\": {\"type\": \"string\"},\n                            \"dependencies\": {\n                                \"type\": \"array\",\n                                \"items\": {\"type\": \"string\"}\n                            }\n                        },\n                        \"required\": [\"name\", \"description\", \"tool\"]\n                    }\n                },\n                \"reasoning\": {\"type\": \"string\"},\n                \"estimated_steps\": {\"type\": \"integer\"}\n            },\n            \"required\": [\"steps\", \"reasoning\"]\n        }\n        \n        # Generate the plan using the model\n        try:\n            plan_data = self.model.extract_json(\n                prompt=prompt,\n                schema=plan_schema,\n                system_message=\"You are a task planning assistant. Break down tasks into logical steps.\"\n            )\n            \n            # Process the plan data\n            return self._process_plan_data(task, plan_data)\n            \n        except Exception as e:\n            logging.error(f\"Error creating plan: {e}\")\n            # Return a minimal plan\n            return {\n                \"id\": str(uuid.uuid4()),\n                \"task\": task,\n                \"status\": \"error\",\n                \"error\": str(e),\n                \"created_at\": time.time(),\n                \"steps\": [],\n                \"reasoning\": \"Error generating plan\",\n                \"current_step_index\": 0,\n                \"completed_steps\": [],\n                \"metadata\": {\"context\": context}\n            }\n    \n    def replan(self, plan: Dict[str, Any], feedback: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Update a plan based on execution feedback.\n        \n        Args:\n            plan: The current plan.\n            feedback: Feedback from execution.\n            \n        Returns:\n            The updated plan.\n        \"\"\"\n        # Extract current plan state\n        task = plan.get(\"task\", \"\")\n        completed_steps = plan.get(\"completed_steps\", [])\n        remaining_steps = self._get_remaining_steps(plan)\n        \n        # Prepare the replanning prompt\n        prompt = self._create_replanning_prompt(task, plan, feedback)\n        \n        # Extract JSON schema for the updated plan\n        plan_schema = {\n            \"type\": \"object\",\n            \"properties\": {\n                \"steps\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"id\": {\"type\": \"string\"},\n                            \"name\": {\"type\": \"string\"},\n                            \"description\": {\"type\": \"string\"},\n                            \"tool\": {\"type\": \"string\"},\n                            \"tool_input\": {\"type\": \"object\"},\n                            \"expected_output\": {\"type\": \"string\"},\n                            \"dependencies\": {\n                                \"type\": \"array\",\n                                \"items\": {\"type\": \"string\"}\n                            }\n                        },\n                        \"required\": [\"name\", \"description\", \"tool\"]\n                    }\n                },\n                \"reasoning\": {\"type\": \"string\"}\n            },\n            \"required\": [\"steps\", \"reasoning\"]\n        }\n        \n        try:\n            # Generate the updated plan\n            updated_plan_data = self.model.extract_json(\n                prompt=prompt,\n                schema=plan_schema,\n                system_message=\"You are a task planning assistant. Revise plans based on feedback.\"\n            )\n            \n            # Merge the updated plan with the original plan\n            updated_plan = plan.copy()\n            updated_plan[\"steps\"] = completed_steps + updated_plan_data.get(\"steps\", [])\n            updated_plan[\"reasoning\"] = updated_plan_data.get(\"reasoning\", \"Plan updated based on feedback\")\n            updated_plan[\"updated_at\"] = time.time()\n            updated_plan[\"status\"] = \"updated\"\n            \n            # Keep the current step index\n            if len(completed_steps) < len(updated_plan[\"steps\"]):\n                updated_plan[\"current_step_index\"] = len(completed_steps)\n            else:\n                updated_plan[\"current_step_index\"] = 0\n            \n            # Add feedback to metadata\n            if \"metadata\" not in updated_plan:\n                updated_plan[\"metadata\"] = {}\n            updated_plan[\"metadata\"][\"feedback\"] = feedback\n            \n            return updated_plan\n            \n        except Exception as e:\n            logging.error(f\"Error replanning: {e}\")\n            # Return the original plan with an error flag\n            plan[\"status\"] = \"error\"\n            plan[\"error\"] = str(e)\n            return plan\n    \n    def get_next_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get the next step to execute from a plan.\n        \n        Args:\n            plan: The current plan.\n            \n        Returns:\n            The next step to execute, or None if the plan is complete.\n        \"\"\"\n        steps = plan.get(\"steps\", [])\n        current_index = plan.get(\"current_step_index\", 0)\n        \n        # Check if we've completed all steps\n        if current_index >= len(steps):\n            return None\n        \n        # Get the next step\n        next_step = steps[current_index]\n        \n        # Check dependencies\n        if \"dependencies\" in next_step and next_step[\"dependencies\"]:\n            completed_step_ids = [step.get(\"id\") for step in plan.get(\"completed_steps\", [])]\n            \n            # Check if all dependencies are satisfied\n            for dep_id in next_step[\"dependencies\"]:\n                if dep_id not in completed_step_ids:\n                    # Dependency not satisfied, try to find an alternative step\n                    alt_step = self._find_executable_step(plan)\n                    if alt_step:\n                        return alt_step\n                    else:\n                        # Can't proceed, need replanning\n                        logging.warning(f\"Can't execute step {next_step.get('id')}: unsatisfied dependencies\")\n                        return None\n        \n        return next_step\n    \n    def mark_step_complete(self, plan: Dict[str, Any], step_id: str, result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Mark a step as complete in a plan.\n        \n        Args:\n            plan: The current plan.\n            step_id: The ID of the completed step.\n            result: The result of the step execution.\n            \n        Returns:\n            The updated plan.\n        \"\"\"\n        updated_plan = plan.copy()\n        steps = updated_plan.get(\"steps\", [])\n        current_index = updated_plan.get(\"current_step_index\", 0)\n        \n        # Find the step\n        step_index = -1\n        for i, step in enumerate(steps):\n            if step.get(\"id\") == step_id:\n                step_index = i\n                break\n        \n        if step_index == -1:\n            logging.warning(f\"Step {step_id} not found in plan\")\n            return plan\n        \n        # Update the step with result\n        completed_step = steps[step_index].copy()\n        completed_step[\"result\"] = result\n        completed_step[\"completed_at\"] = time.time()\n        \n        # Add to completed steps\n        if \"completed_steps\" not in updated_plan:\n            updated_plan[\"completed_steps\"] = []\n        updated_plan[\"completed_steps\"].append(completed_step)\n        \n        # Update current step index\n        if step_index == current_index:\n            updated_plan[\"current_step_index\"] = current_index + 1\n        \n        # Check if plan is complete\n        if updated_plan[\"current_step_index\"] >= len(steps):\n            updated_plan[\"status\"] = \"completed\"\n            updated_plan[\"completed_at\"] = time.time()\n        \n        return updated_plan\n    \n    def _create_planning_prompt(self, task: str, context: Dict[str, Any]) -> str:\n        \"\"\"\n        Create a prompt for generating a plan.\n        \n        Args:\n            task: The task description.\n            context: Context information.\n            \n        Returns:\n            A prompt string.\n        \"\"\"\n        prompt = f\"\"\"\nTask: {task}\n\nI need a detailed plan to accomplish this task. Please break it down into specific steps.\n\nFor each step, include:\n1. A clear name and description\n2. The tool required (e.g., web_search, file_read, code_execution)\n3. The expected input for the tool\n4. Any dependencies on previous steps\n\nContext information:\n{json.dumps(context, indent=2)}\n\nPlease provide a structured plan with no more than {self.max_steps} steps.\n\"\"\"\n        return prompt\n    \n    def _create_replanning_prompt(self, task: str, plan: Dict[str, Any], feedback: Dict[str, Any]) -> str:\n        \"\"\"\n        Create a prompt for replanning.\n        \n        Args:\n            task: The task description.\n            plan: The current plan.\n            feedback: Feedback from execution.\n            \n        Returns:\n            A prompt string.\n        \"\"\"\n        # Extract completed steps\n        completed_steps = plan.get(\"completed_steps\", [])\n        completed_steps_text = \"\"\n        for i, step in enumerate(completed_steps):\n            result = step.get(\"result\", {})\n            result_status = result.get(\"status\", \"unknown\")\n            result_summary = str(result.get(\"result\", \"No result\"))[:100] + \"...\" if len(str(result.get(\"result\", \"\"))) > 100 else str(result.get(\"result\", \"No result\"))\n            \n            completed_steps_text += f\"{i+1}. {step.get('name', 'Step')}: {result_status} - {result_summary}\\n\"\n        \n        # Extract remaining steps\n        remaining_steps = self._get_remaining_steps(plan)\n        remaining_steps_text = \"\"\n        for i, step in enumerate(remaining_steps):\n            remaining_steps_text += f\"{i+1}. {step.get('name', 'Step')}: {step.get('description', 'No description')}\\n\"\n        \n        prompt = f\"\"\"\nTask: {task}\n\nI need to revise my plan based on execution feedback. \n\nCompleted steps:\n{completed_steps_text}\n\nCurrent feedback:\n{json.dumps(feedback, indent=2)}\n\nCurrent remaining steps:\n{remaining_steps_text}\n\nPlease provide an updated plan for the remaining steps, considering the feedback and results from completed steps.\n\"\"\"\n        return prompt\n    \n    def _process_plan_data(self, task: str, plan_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Process raw plan data into a structured plan.\n        \n        Args:\n            task: The task description.\n            plan_data: Raw plan data from the model.\n            \n        Returns:\n            A structured plan dictionary.\n        \"\"\"\n        steps = plan_data.get(\"steps\", [])\n        \n        # Ensure each step has an ID and required fields\n        for i, step in enumerate(steps):\n            if \"id\" not in step:\n                step[\"id\"] = f\"step-{i+1}-{str(uuid.uuid4())[:8]}\"\n            \n            if \"tool_input\" not in step:\n                step[\"tool_input\"] = {}\n            \n            if \"dependencies\" not in step:\n                step[\"dependencies\"] = []\n        \n        # Create the plan structure\n        plan = {\n            \"id\": str(uuid.uuid4()),\n            \"task\": task,\n            \"status\": \"created\",\n            \"created_at\": time.time(),\n            \"steps\": steps,\n            \"reasoning\": plan_data.get(\"reasoning\", \"\"),\n            \"current_step_index\": 0,\n            \"completed_steps\": [],\n            \"metadata\": {\n                \"estimated_steps\": plan_data.get(\"estimated_steps\", len(steps))\n            }\n        }\n        \n        return plan\n    \n    def _get_remaining_steps(self, plan: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the remaining steps from a plan.\n        \n        Args:\n            plan: The current plan.\n            \n        Returns:\n            A list of remaining steps.\n        \"\"\"\n        steps = plan.get(\"steps\", [])\n        current_index = plan.get(\"current_step_index\", 0)\n        \n        if current_index >= len(steps):\n            return []\n        \n        return steps[current_index:]\n    \n    def _find_executable_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a step that can be executed (all dependencies satisfied).\n        \n        Args:\n            plan: The current plan.\n            \n        Returns:\n            An executable step, or None if none found.\n        \"\"\"\n        steps = plan.get(\"steps\", [])\n        current_index = plan.get(\"current_step_index\", 0)\n        completed_step_ids = [step.get(\"id\") for step in plan.get(\"completed_steps\", [])]\n        \n        # Look for steps after the current index\n        for i in range(current_index, len(steps)):\n            step = steps[i]\n            dependencies = step.get(\"dependencies\", [])\n            \n            # Check if all dependencies are satisfied\n            dependencies_satisfied = True\n            for dep_id in dependencies:\n                if dep_id not in completed_step_ids:\n                    dependencies_satisfied = False\n                    break\n            \n            if dependencies_satisfied:\n                return step\n        \n        return None "}
{"type": "source_file", "path": "anus/tools/code.py", "content": "\"\"\"\nCode tool for executing Python code in a restricted environment.\n\nThis tool allows running simple Python expressions and statements,\nwith appropriate safety restrictions.\n\"\"\"\n\nimport logging\nimport re\nimport ast\nfrom typing import Dict, Any, Union, List\n\nfrom anus.tools.base.tool import BaseTool\nfrom anus.tools.base.tool_result import ToolResult\n\nclass CodeTool(BaseTool):\n    \"\"\"\n    A tool for executing Python code in a restricted environment.\n    \n    ANUS can execute your code, but keep it clean - no backdoor operations allowed!\n    \"\"\"\n    \n    name = \"code\"\n    description = \"Execute Python code in a restricted environment\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"code\": {\n                \"type\": \"string\",\n                \"description\": \"The Python code to execute\"\n            }\n        },\n        \"required\": [\"code\"]\n    }\n    \n    # Restricted modules and builtins for safety\n    _ALLOWED_MODULES = {\n        \"math\", \"random\", \"datetime\", \"collections\", \"itertools\", \n        \"functools\", \"re\", \"json\", \"time\", \"string\"\n    }\n    \n    _ALLOWED_BUILTINS = {\n        \"abs\", \"all\", \"any\", \"ascii\", \"bin\", \"bool\", \"bytes\", \"callable\", \"chr\", \n        \"complex\", \"dict\", \"dir\", \"divmod\", \"enumerate\", \"filter\", \"float\", \"format\", \n        \"frozenset\", \"getattr\", \"hasattr\", \"hash\", \"hex\", \"id\", \"int\", \"isinstance\", \n        \"issubclass\", \"iter\", \"len\", \"list\", \"map\", \"max\", \"min\", \"next\", \"oct\", \n        \"ord\", \"pow\", \"print\", \"range\", \"repr\", \"reversed\", \"round\", \"set\", \"slice\", \n        \"sorted\", \"str\", \"sum\", \"tuple\", \"type\", \"zip\"\n    }\n    \n    # Disallowed AST nodes for security\n    _FORBIDDEN_NODES = {\n        ast.Import, ast.ImportFrom, ast.ClassDef, ast.AsyncFunctionDef, \n        ast.Await, ast.AsyncFor, ast.AsyncWith\n    }\n    \n    # Funny code execution messages\n    _execution_messages = [\n        \"ANUS is squeezing your code through its tight security filters...\",\n        \"ANUS is processing your code carefully - no backdoor entry allowed!\",\n        \"ANUS is executing your code - hope it doesn't cause any irritation!\",\n        \"ANUS is carefully handling your code to prevent any leakage...\",\n        \"ANUS is processing your code - tight security, clean output!\"\n    ]\n    \n    def execute(self, code: str, **kwargs) -> Union[Dict[str, Any], ToolResult]:\n        \"\"\"\n        Execute the provided Python code in a restricted environment.\n        \n        Args:\n            code: The Python code to execute.\n            **kwargs: Additional parameters (ignored).\n            \n        Returns:\n            The execution result.\n        \"\"\"\n        try:\n            # Log a funny execution message\n            import random\n            logging.info(random.choice(self._execution_messages))\n            \n            # Validate the code for security\n            self._validate_code(code)\n            \n            # Set up a restricted environment\n            exec_globals = self._create_restricted_env()\n            \n            # Execute the code in a restricted environment\n            # Create a buffer to capture output\n            import io\n            import sys\n            original_stdout = sys.stdout\n            buffer = io.StringIO()\n            sys.stdout = buffer\n            \n            try:\n                # Try to execute as an expression for return value\n                try:\n                    result = eval(code, exec_globals, {})\n                    output = buffer.getvalue()\n                    return {\n                        \"code\": code,\n                        \"result\": result,\n                        \"output\": output,\n                        \"execution_type\": \"expression\"\n                    }\n                except SyntaxError:\n                    # If not an expression, execute as statements\n                    exec(code, exec_globals, {})\n                    output = buffer.getvalue()\n                    # Extract the last defined variable as the result if possible\n                    result = None\n                    for var_name in [\"result\", \"answer\", \"output\", \"value\", \"retval\", \"ret\"]:\n                        if var_name in exec_globals:\n                            result = exec_globals[var_name]\n                            break\n                            \n                    return {\n                        \"code\": code,\n                        \"result\": result,\n                        \"output\": output,\n                        \"execution_type\": \"statements\"\n                    }\n            finally:\n                sys.stdout = original_stdout\n                \n        except Exception as e:\n            error_msg = str(e)\n            logging.error(f\"Error in code execution: {e}\")\n            \n            # Add some humor to certain errors\n            if \"forbidden\" in error_msg.lower():\n                error_msg = f\"{error_msg} ANUS has strict boundaries, you know!\"\n            elif \"syntax\" in error_msg.lower():\n                error_msg = f\"{error_msg} Your code caused ANUS some discomfort.\"\n                \n            return {\"status\": \"error\", \"error\": f\"Code execution error: {error_msg}\"}\n    \n    def _validate_code(self, code: str) -> None:\n        \"\"\"\n        Validate code for security concerns.\n        \n        Args:\n            code: The code to validate.\n            \n        Raises:\n            ValueError: If the code contains forbidden elements.\n        \"\"\"\n        # Check for suspicious imports or calls\n        suspicious_patterns = [\n            r'__import__', r'importlib', r'subprocess', r'sys\\W*\\.', r'os\\W*\\.',\n            r'shutil', r'pathlib', r'open\\W*\\(', r'exec\\W*\\(', r'eval\\W*\\(', \n            r'compile\\W*\\(', r'getattr\\W*\\(.*__'\n        ]\n        \n        for pattern in suspicious_patterns:\n            if re.search(pattern, code):\n                raise ValueError(f\"Code contains forbidden pattern: {pattern}\")\n        \n        # Parse the AST and check for forbidden node types\n        try:\n            tree = ast.parse(code)\n            for node in ast.walk(tree):\n                for forbidden_type in self._FORBIDDEN_NODES:\n                    if isinstance(node, forbidden_type):\n                        raise ValueError(f\"Code contains forbidden AST node: {node.__class__.__name__}\")\n                \n                # Check for attribute access that might be dangerous\n                if isinstance(node, ast.Attribute):\n                    attr_name = node.attr\n                    if attr_name.startswith('__') and attr_name.endswith('__'):\n                        raise ValueError(f\"Code contains forbidden dunder attribute: {attr_name}\")\n        except SyntaxError as e:\n            # Just a syntax error, not a security issue\n            raise SyntaxError(f\"Syntax error in code: {e}\")\n    \n    def _create_restricted_env(self) -> Dict[str, Any]:\n        \"\"\"\n        Create a restricted execution environment.\n        \n        Returns:\n            A dictionary with allowed modules and builtins.\n        \"\"\"\n        # Start with a clean dictionary\n        restricted_env = {}\n        \n        # Add allowed modules\n        for module_name in self._ALLOWED_MODULES:\n            try:\n                module = __import__(module_name)\n                restricted_env[module_name] = module\n            except ImportError:\n                pass\n        \n        # Create a restricted __builtins__ dictionary\n        restricted_builtins = {}\n        \n        # Get all builtins from the real __builtins__\n        real_builtins = {}\n        if isinstance(__builtins__, dict):\n            real_builtins = __builtins__\n        else:\n            real_builtins = vars(__builtins__)\n        \n        # Add only allowed builtins\n        for name in self._ALLOWED_BUILTINS:\n            if name in real_builtins:\n                restricted_builtins[name] = real_builtins[name]\n        \n        restricted_env[\"__builtins__\"] = restricted_builtins\n        \n        return restricted_env "}
{"type": "source_file", "path": "anus/ui/cli.py", "content": "\"\"\"\nCommand-line interface for the ANUS framework.\n\nRemember: With great ANUS comes great responsibility.\n\"\"\"\n\nimport os\nimport sys\nimport time\nimport json\nimport logging\nimport cmd\nimport shutil\nimport random\nfrom typing import Dict, List, Any, Optional, Union\nfrom datetime import datetime\n\nfrom anus.core.orchestrator import AgentOrchestrator\n\nclass CLI(cmd.Cmd):\n    \"\"\"\n    Command-line interface for interacting with the ANUS framework.\n    \n    Provides commands for:\n    - Executing tasks\n    - Managing agents\n    - Viewing task history\n    - Configuration\n    \n    Warning: Prolonged exposure to ANUS may cause uncontrollable smirking.\n    \"\"\"\n    \n    intro = \"Welcome to the ANUS framework. Type help or ? to list commands.\"\n    prompt = \"anus> \"\n    \n    # Easter egg jokes for random display\n    _anus_jokes = [\n        \"ANUS: Because 'Autonomous Networked Utility System' sounds better in meetings.\",\n        \"ANUS: The backend system that handles all your crap.\",\n        \"ANUS: Boldly going where no framework has gone before.\",\n        \"ANUS: It's not a bug, it's a feature... a very uncomfortable feature.\",\n        \"ANUS: For when your code needs that extra push from behind.\",\n        \"ANUS: Working hard so you don't have to explain the acronym to your boss.\",\n        \"ANUS: The framework that makes other developers snicker during code review.\",\n        \"ANUS: Tight integration with your backend systems.\",\n        \"ANUS: Because 'BUTT' was already taken as an acronym.\",\n        \"ANUS: Making developers uncomfortable in stand-up meetings since 2023.\"\n    ]\n    \n    def __init__(self, verbose: bool = False, config_path: str = \"config.yaml\"):\n        \"\"\"\n        Initialize a CLI instance.\n        \n        Args:\n            verbose: Whether to enable verbose output.\n            config_path: Path to the configuration file.\n        \"\"\"\n        super().__init__()\n        self.verbose = verbose\n        self.config_path = config_path\n        self.orchestrator = None\n        self.current_result = None\n        self.history = []\n        self.joke_counter = 0  # Track number of commands for occasional jokes\n        \n        # Set up logging\n        log_level = logging.DEBUG if verbose else logging.INFO\n        logging.basicConfig(\n            level=log_level,\n            format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n        )\n    \n    def display_welcome(self) -> None:\n        \"\"\"\n        Display a welcome message.\n        \n        Includes a random ANUS joke to brighten your day.\n        \"\"\"\n        term_width = shutil.get_terminal_size().columns\n        \n        print(\"=\" * term_width)\n        print(\"ANUS - Autonomous Networked Utility System\".center(term_width))\n        print(\"=\" * term_width)\n        print(random.choice(self._anus_jokes).center(term_width))\n        print(\"=\" * term_width)\n        print(\"Type 'help' or '?' to list available commands.\".center(term_width))\n        print(\"=\" * term_width)\n        print()\n    \n    def start_interactive_mode(self, orchestrator: Optional[AgentOrchestrator] = None) -> None:\n        \"\"\"\n        Start the interactive command-line interface.\n        \n        Args:\n            orchestrator: Optional orchestrator instance. If not provided, one will be created.\n        \"\"\"\n        if orchestrator:\n            self.orchestrator = orchestrator\n        else:\n            self.orchestrator = AgentOrchestrator(config_path=self.config_path)\n        \n        # Display welcome message if not in stdin mode\n        if sys.stdin.isatty():\n            self.display_welcome()\n        \n        # Start the command loop\n        self.cmdloop()\n    \n    def display_result(self, result: Dict[str, Any]) -> None:\n        \"\"\"\n        Display the result of a task execution.\n        \n        Args:\n            result: The task execution result.\n        \"\"\"\n        self.current_result = result\n        \n        term_width = shutil.get_terminal_size().columns\n        \n        print(\"\\n\" + \"=\" * term_width)\n        print(\"TASK RESULT\".center(term_width))\n        print(\"=\" * term_width)\n        \n        # Display the task\n        task = result.get(\"task\", \"Unknown task\")\n        print(f\"Task: {task}\")\n        \n        # Display the answer\n        answer = result.get(\"answer\", \"No answer provided\")\n        print(\"\\nAnswer:\")\n        print(f\"{answer}\")\n        \n        # Display additional information if verbose\n        if self.verbose:\n            print(\"\\nExecution Details:\")\n            \n            # Mode\n            mode = result.get(\"mode\", \"single\")\n            print(f\"Mode: {mode}\")\n            \n            # Steps or iterations\n            if \"iterations\" in result:\n                iterations = result.get(\"iterations\", 0)\n                print(f\"Iterations: {iterations}\")\n            elif \"steps\" in result:\n                steps = len(result.get(\"steps\", []))\n                completed_steps = len(result.get(\"completed_steps\", []))\n                print(f\"Steps: {completed_steps}/{steps} completed\")\n            \n            # Display context or not based on verbosity\n            if self.verbose and \"context\" in result:\n                print(\"\\nExecution Context:\")\n                self._pretty_print(result[\"context\"])\n        \n        print(\"=\" * term_width)\n        \n        # Occasionally show a joke after results\n        self.joke_counter += 1\n        if self.joke_counter % 3 == 0:  # Every 3rd result\n            print(f\"\\nANUS Wisdom: {random.choice(self._anus_jokes)}\")\n    \n    def do_task(self, arg: str) -> None:\n        \"\"\"\n        Execute a task.\n        \n        Usage: task [mode] <task description>\n        \n        Args:\n            arg: Task description and optional mode.\n        \"\"\"\n        # Make sure orchestrator is initialized\n        if not self.orchestrator:\n            self.orchestrator = AgentOrchestrator(config_path=self.config_path)\n        \n        # Parse arguments\n        parts = arg.strip().split(maxsplit=1)\n        \n        if len(parts) == 0 or not arg.strip():\n            print(\"Error: Please provide a task description.\")\n            print(\"ANUS can't work with nothing. It needs substance.\")\n            return\n        \n        # Check if mode is specified\n        mode = None\n        task = arg.strip()\n        \n        if len(parts) > 1 and parts[0] in [\"single\", \"multi\", \"auto\"]:\n            mode = parts[0]\n            task = parts[1]\n        \n        # Execute the task\n        print(f\"Executing task: {task}\")\n        if mode:\n            print(f\"Mode: {mode}\")\n        \n        if mode == \"multi\":\n            print(\"Multiple agents engaged. ANUS is working from all directions...\")\n        \n        try:\n            result = self.orchestrator.execute_task(task, mode=mode)\n            self.display_result(result)\n            \n            # Add to history\n            self.history.append({\n                \"timestamp\": time.time(),\n                \"task\": task,\n                \"mode\": mode,\n                \"result\": result\n            })\n            \n        except Exception as e:\n            print(f\"Error executing task: {e}\")\n            print(\"Even ANUS has its limits. Please try again.\")\n    \n    def do_agents(self, arg: str) -> None:\n        \"\"\"\n        List available agents.\n        \n        Usage: agents\n        \"\"\"\n        # Make sure orchestrator is initialized\n        if not self.orchestrator:\n            self.orchestrator = AgentOrchestrator(config_path=self.config_path)\n        \n        agents = self.orchestrator.list_agents()\n        \n        if not agents:\n            print(\"No agents available.\")\n            print(\"ANUS feels empty inside. Please add some agents.\")\n            return\n        \n        print(\"Available Agents:\")\n        print(\"-\" * 40)\n        \n        for agent in agents:\n            primary = agent.get(\"primary\", False)\n            prefix = \"* \" if primary else \"  \"\n            print(f\"{prefix}{agent.get('name', 'Unknown')} ({agent.get('type', 'Unknown')})\")\n            \n            if self.verbose:\n                print(f\"   ID: {agent.get('id', 'Unknown')}\")\n            \n            print()\n            \n        print(f\"Total agents: {len(agents)}\")\n        if len(agents) > 5:\n            print(\"Wow, that's a lot to fit in one ANUS!\")\n    \n    def do_history(self, arg: str) -> None:\n        \"\"\"\n        Show task execution history.\n        \n        Usage: history [limit]\n        \n        Args:\n            arg: Optional limit on the number of history items to display.\n        \"\"\"\n        # Parse arguments\n        limit = 5\n        if arg and arg.strip().isdigit():\n            limit = int(arg.strip())\n        \n        # Get history from orchestrator if available\n        if self.orchestrator:\n            history = self.orchestrator.get_task_history(limit=limit)\n        else:\n            history = self.history[-limit:] if self.history else []\n        \n        if not history:\n            print(\"No task history available.\")\n            print(\"ANUS is clean as a whistle. No history to report.\")\n            return\n        \n        print(\"Task History:\")\n        print(\"-\" * 60)\n        \n        for i, entry in enumerate(reversed(history)):\n            timestamp = entry.get(\"start_time\", entry.get(\"timestamp\", 0))\n            dt = datetime.fromtimestamp(timestamp)\n            task = entry.get(\"task\", \"Unknown task\")\n            mode = entry.get(\"mode\", \"single\")\n            status = entry.get(\"status\", \"completed\")\n            \n            print(f\"{i+1}. [{dt.strftime('%Y-%m-%d %H:%M:%S')}] ({mode}) {status}\")\n            print(f\"   Task: {task}\")\n            \n            # Show result summary if available\n            if \"result\" in entry and \"answer\" in entry[\"result\"]:\n                answer = entry[\"result\"][\"answer\"]\n                summary = answer[:100] + \"...\" if len(answer) > 100 else answer\n                print(f\"   Answer: {summary}\")\n            \n            print()\n        \n        print(f\"Showing {min(len(history), limit)} of {len(history)} total entries.\")\n        if len(history) > 10:\n            print(\"ANUS has been quite busy, hasn't it?\")\n    \n    def do_config(self, arg: str) -> None:\n        \"\"\"\n        Show current configuration.\n        \n        Usage: config\n        \"\"\"\n        # Make sure orchestrator is initialized\n        if not self.orchestrator:\n            self.orchestrator = AgentOrchestrator(config_path=self.config_path)\n        \n        print(f\"Configuration file: {self.config_path}\")\n        print(\"-\" * 60)\n        \n        self._pretty_print(self.orchestrator.config)\n        print(\"\\nProTip: A well-configured ANUS is a happy ANUS.\")\n    \n    def do_joke(self, arg: str) -> None:\n        \"\"\"\n        Display a random ANUS joke.\n        \n        Usage: joke\n        \"\"\"\n        joke = random.choice(self._anus_jokes)\n        \n        term_width = shutil.get_terminal_size().columns\n        \n        print()\n        print(\"=\" * term_width)\n        print(\"ANUS WISDOM\".center(term_width))\n        print(\"=\" * term_width)\n        print(joke.center(term_width))\n        print(\"=\" * term_width)\n        print()\n    \n    def do_exit(self, arg: str) -> bool:\n        \"\"\"\n        Exit the application.\n        \n        Usage: exit\n        \"\"\"\n        print(\"Exiting ANUS. We hope your experience wasn't too uncomfortable.\")\n        return True\n    \n    def do_quit(self, arg: str) -> bool:\n        \"\"\"\n        Exit the application.\n        \n        Usage: quit\n        \"\"\"\n        return self.do_exit(arg)\n    \n    def do_EOF(self, arg: str) -> bool:\n        \"\"\"\n        Handle EOF (Ctrl+D).\n        \"\"\"\n        print()  # Add a newline\n        return self.do_exit(arg)\n    \n    def emptyline(self) -> None:\n        \"\"\"\n        Handle empty lines in the CLI.\n        \"\"\"\n        # 1 in 10 chance to show a joke on empty line\n        if random.random() < 0.1:\n            print(f\"ANUS is waiting... {random.choice(self._anus_jokes)}\")\n    \n    def _pretty_print(self, data: Any) -> None:\n        \"\"\"\n        Pretty print data.\n        \n        Args:\n            data: Data to print.\n        \"\"\"\n        if isinstance(data, (dict, list)):\n            try:\n                print(json.dumps(data, indent=2))\n            except Exception:\n                print(data)\n        else:\n            print(data) "}
{"type": "source_file", "path": "anus/tools/utility/calculator.py", "content": "\"\"\"\nCalculator tool for basic arithmetic operations.\n\nWhen ANUS needs to do math, it uses this tool to work things out.\n\"\"\"\n\nimport logging\nimport random\nfrom typing import Dict, Any, Union, List\n\nfrom anus.tools.base.tool import BaseTool\nfrom anus.tools.base.tool_result import ToolResult\n\nclass CalculatorTool(BaseTool):\n    \"\"\"\n    A tool for performing basic arithmetic calculations.\n    \n    Supports addition, subtraction, multiplication, division, \n    and other basic mathematical operations.\n    \n    ANUS might not be good at everything, but it's surprisingly good with numbers.\n    \"\"\"\n    \n    name = \"calculator\"\n    description = \"Perform basic arithmetic calculations\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"expression\": {\n                \"type\": \"string\",\n                \"description\": \"The mathematical expression to evaluate\"\n            }\n        },\n        \"required\": [\"expression\"]\n    }\n    \n    # Easter egg responses for specific calculations\n    _easter_eggs = {\n        \"1+1\": \"2 (even ANUS can handle this one!)\",\n        \"69+69\": \"138 (nice+nice)\",\n        \"80085\": \"The number spells 'BOOBS' on a calculator. ANUS approves.\",\n        \"42\": \"The answer to life, the universe, and everything. ANUS is enlightened.\",\n        \"3.14159\": \"π (ANUS loves pie!)\",\n        \"58008\": \"Turn your calculator upside down for a surprise. ANUS is giggling.\",\n        \"1/0\": \"ANUS cannot handle division by zero! It's too tight a squeeze.\",\n        \"9+10\": \"19 (not 21, sorry for the disappointment)\",\n        \"8==D\": \"ANUS detects inappropriate ASCII art; this isn't that kind of calculator.\",\n        \"sqrt(-1)\": \"i (imaginary, just like ANUS's hopes and dreams)\"\n    }\n    \n    # Funny calculation messages\n    _calc_messages = [\n        \"ANUS is crunching the numbers...\",\n        \"ANUS is performing intense calculations...\",\n        \"ANUS is squeezing out a result...\",\n        \"ANUS is pushing through this tough equation...\",\n        \"ANUS is working it out from behind the scenes...\"\n    ]\n    \n    def execute(self, expression: str, **kwargs) -> Union[Dict[str, Any], ToolResult]:\n        \"\"\"\n        Execute the calculator tool.\n        \n        Args:\n            expression: The mathematical expression to evaluate.\n            **kwargs: Additional parameters (ignored).\n            \n        Returns:\n            The calculation result.\n        \"\"\"\n        try:\n            # Check for easter eggs\n            cleaned_expr = expression.replace(\" \", \"\").lower()\n            for trigger, response in self._easter_eggs.items():\n                if cleaned_expr == trigger.lower():\n                    logging.info(f\"ANUS calculator triggered an easter egg: {trigger}\")\n                    return ToolResult.success(\n                        self.name,\n                        {\n                            \"expression\": expression,\n                            \"result\": response,\n                            \"easter_egg\": True\n                        }\n                    )\n            \n            # Log a funny calculation message\n            if random.random() < 0.3:  # 30% chance\n                logging.info(random.choice(self._calc_messages))\n            \n            # Validate the expression first\n            self._validate_expression(expression)\n            \n            # Evaluate the expression\n            result = eval(expression, {\"__builtins__\": {}}, self._safe_math_context())\n            \n            # Check for special number results to make jokes about\n            result_jokes = {\n                69: \"Nice!\",\n                420: \"Blaze it!\",\n                666: \"Devilish result!\",\n                1337: \"Leet calculation!\",\n                80085: \"ANUS likes this number for some reason...\",\n                42: \"The answer to life, the universe, and everything!\"\n            }\n            \n            comment = None\n            if isinstance(result, (int, float)):\n                for number, joke in result_jokes.items():\n                    if abs(result - number) < 0.0001:  # Close enough for floats\n                        comment = joke\n                        break\n            \n            # Return as ToolResult\n            result_dict = {\n                \"expression\": expression,\n                \"result\": result\n            }\n            \n            if comment:\n                result_dict[\"comment\"] = comment\n                logging.info(f\"ANUS calculator result triggered a joke: {comment}\")\n            \n            return ToolResult.success(self.name, result_dict)\n            \n        except Exception as e:\n            error_msg = str(e)\n            \n            # Add funny error messages\n            if \"division by zero\" in error_msg.lower():\n                error_msg = \"Division by zero! Even ANUS has its limits.\"\n            elif \"invalid syntax\" in error_msg.lower():\n                error_msg = \"Invalid syntax! ANUS is confused by your notation.\"\n            \n            logging.error(f\"Error in calculator tool: {e}\")\n            return ToolResult.error(self.name, f\"Calculation error: {error_msg}\")\n    \n    def validate_input(self, expression: str = None, **kwargs) -> bool:\n        \"\"\"\n        Validate the input parameters.\n        \n        Args:\n            expression: The mathematical expression to validate.\n            **kwargs: Additional parameters (ignored).\n            \n        Returns:\n            True if the input is valid, False otherwise.\n        \"\"\"\n        if expression is None:\n            return False\n        \n        try:\n            self._validate_expression(expression)\n            return True\n        except:\n            return False\n    \n    def _validate_expression(self, expression: str) -> None:\n        \"\"\"\n        Validate that an expression is safe to evaluate.\n        \n        Args:\n            expression: The expression to validate.\n            \n        Raises:\n            ValueError: If the expression contains unsafe elements.\n        \"\"\"\n        # Check for common unsafe patterns\n        unsafe_patterns = [\n            \"__\", \"import\", \"eval\", \"exec\", \"compile\", \"open\", \n            \"file\", \"os.\", \"sys.\", \"subprocess\", \"lambda\"\n        ]\n        \n        for pattern in unsafe_patterns:\n            if pattern in expression:\n                logging.warning(f\"ANUS detected a potential security breach: {pattern}\")\n                raise ValueError(f\"Expression contains unsafe pattern: {pattern}. ANUS refuses to process this.\")\n        \n        # Only allow basic arithmetic operations and numeric literals\n        allowed_chars = set(\"0123456789.+-*/() \")\n        for char in expression:\n            if char not in allowed_chars:\n                logging.warning(f\"ANUS caught an illegal character: {char}\")\n                raise ValueError(f\"Expression contains disallowed character: {char}. ANUS only does basic arithmetic.\")\n    \n    def _safe_math_context(self) -> Dict[str, Any]:\n        \"\"\"\n        Create a safe context for math operations.\n        \n        Returns:\n            A dictionary with allowed mathematical functions.\n        \"\"\"\n        import math\n        \n        # Allow only safe math functions\n        return {\n            \"abs\": abs,\n            \"max\": max,\n            \"min\": min,\n            \"pow\": pow,\n            \"round\": round,\n            \"sum\": sum,\n            # Add some math module functions\n            \"sqrt\": math.sqrt,\n            \"sin\": math.sin,\n            \"cos\": math.cos,\n            \"tan\": math.tan,\n            \"pi\": math.pi,\n            \"e\": math.e\n        } "}
{"type": "source_file", "path": "assets/anus_logo.py", "content": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Circle, Ellipse\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Set up the figure\nfig, ax = plt.subplots(figsize=(10, 10))\nax.set_aspect('equal')\nax.axis('off')\n\n# Create a custom colormap for the gradient background\ncolors = [(0.8, 0.4, 0.6), (0.6, 0.2, 0.5)]  # Pink to purple gradient\ncmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=100)\n\n# Create a circular background with gradient\ncircle_bg = Circle((0.5, 0.5), 0.45, transform=ax.transAxes, \n                  color='white', zorder=0)\nax.add_patch(circle_bg)\n\n# Create the main shape (stylized \"A\" that resembles a peach)\n# First half of the \"A\"\nellipse1 = Ellipse((0.4, 0.5), 0.4, 0.7, angle=-20, \n                  color=colors[0], alpha=0.9, zorder=1)\nax.add_patch(ellipse1)\n\n# Second half of the \"A\"\nellipse2 = Ellipse((0.6, 0.5), 0.4, 0.7, angle=20, \n                  color=colors[1], alpha=0.9, zorder=1)\nax.add_patch(ellipse2)\n\n# Add a small circle at the top to complete the \"A\"\ncircle_top = Circle((0.5, 0.8), 0.08, color=(0.7, 0.3, 0.5), zorder=2)\nax.add_patch(circle_top)\n\n# Add a horizontal line to represent the crossbar of the \"A\"\nax.plot([0.35, 0.65], [0.5, 0.5], color='white', linewidth=8, zorder=3)\n\n# Add AI-themed elements (circuit-like lines)\nfor i in range(5):\n    angle = np.pi * 2 * i / 5\n    x = 0.5 + 0.5 * np.cos(angle)\n    y = 0.5 + 0.5 * np.sin(angle)\n    ax.plot([0.5, x], [0.5, y], color='white', linewidth=1, alpha=0.5, zorder=4)\n\n# Set the limits\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\n\n# Save the logo\nplt.savefig('/home/ubuntu/anus-ai-project/assets/anus_logo.png', \n           dpi=300, bbox_inches='tight', transparent=True)\nplt.savefig('/home/ubuntu/anus-ai-project/assets/anus_logo_small.png', \n           dpi=100, bbox_inches='tight', transparent=True)\n\nprint(\"Logo created and saved to assets directory\")\n"}
{"type": "source_file", "path": "anus/tools/utility/__init__.py", "content": "\"\"\"\nUtility tools for the ANUS framework.\n\nThis module contains basic utility tools:\n- CalculatorTool: Tool for performing basic arithmetic calculations\n\"\"\"\n\nfrom anus.tools.utility.calculator import CalculatorTool\n\n__all__ = [\"CalculatorTool\"] "}
{"type": "source_file", "path": "anus/models/openai_model.py", "content": "\"\"\"\nOpenAI Model implementation for the ANUS framework.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Union, Callable\nimport json\nimport logging\nimport os\n\ntry:\n    import openai\n    from openai import OpenAI\n    OPENAI_AVAILABLE = True\nexcept ImportError:\n    OPENAI_AVAILABLE = False\n\nfrom anus.models.base.base_model import BaseModel\n\nclass OpenAIModel(BaseModel):\n    \"\"\"\n    OpenAI language model implementation.\n    \n    Provides integration with OpenAI's API for text generation and embeddings.\n    \"\"\"\n    \n    def __init__(\n        self, \n        model_name: str = \"gpt-4\", \n        temperature: float = 0.0,\n        max_tokens: Optional[int] = None,\n        api_key: Optional[str] = None,\n        base_url: Optional[str] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize an OpenAIModel instance.\n        \n        Args:\n            model_name: The name of the OpenAI model to use.\n            temperature: Controls randomness in outputs. Lower values are more deterministic.\n            max_tokens: Maximum number of tokens to generate.\n            api_key: OpenAI API key. If None, it will be read from the OPENAI_API_KEY environment variable.\n            base_url: Base URL for the OpenAI API. Useful for proxies or non-standard endpoints.\n            **kwargs: Additional model-specific parameters.\n        \"\"\"\n        super().__init__(model_name, temperature, max_tokens, **kwargs)\n        \n        if not OPENAI_AVAILABLE:\n            logging.error(\"OpenAI package not installed. Please install it with 'pip install openai'.\")\n            raise ImportError(\"OpenAI package not installed\")\n        \n        # Use provided API key or read from environment\n        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n        if not self.api_key:\n            logging.error(\"OpenAI API key not provided and not found in environment.\")\n            raise ValueError(\"OpenAI API key required\")\n        \n        self.base_url = base_url\n        \n        # Initialize client\n        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n        \n        # Set default embedding model\n        self.embedding_model = kwargs.get(\"embedding_model\", \"text-embedding-ada-002\")\n    \n    def generate(\n        self, \n        prompt: str, \n        system_message: Optional[str] = None,\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None,\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Generate text based on a prompt using OpenAI.\n        \n        Args:\n            prompt: The text prompt for generation.\n            system_message: Optional system message for the model.\n            temperature: Controls randomness in outputs. Overrides instance value if provided.\n            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.\n            **kwargs: Additional OpenAI-specific parameters.\n            \n        Returns:\n            The generated text response.\n        \"\"\"\n        # Prepare messages\n        messages = []\n        \n        # Add system message if provided\n        if system_message:\n            messages.append({\"role\": \"system\", \"content\": system_message})\n        \n        # Add user message\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        \n        # Set parameters\n        temp = temperature if temperature is not None else self.temperature\n        tokens = max_tokens if max_tokens is not None else self.max_tokens\n        \n        try:\n            # Make the API call\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temp,\n                max_tokens=tokens,\n                **kwargs\n            )\n            \n            # Extract and return the response text\n            return response.choices[0].message.content\n        \n        except Exception as e:\n            logging.error(f\"Error generating with OpenAI: {e}\")\n            return f\"Error: {str(e)}\"\n    \n    def generate_with_tools(\n        self, \n        prompt: str, \n        tools: List[Dict[str, Any]],\n        system_message: Optional[str] = None,\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None,\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Generate text with tool calling capabilities.\n        \n        Args:\n            prompt: The text prompt for generation.\n            tools: List of tool schemas available for use.\n            system_message: Optional system message for the model.\n            temperature: Controls randomness in outputs. Overrides instance value if provided.\n            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.\n            **kwargs: Additional OpenAI-specific parameters.\n            \n        Returns:\n            A dictionary with the response and any tool calls.\n        \"\"\"\n        # Prepare messages\n        messages = []\n        \n        # Add system message if provided\n        if system_message:\n            messages.append({\"role\": \"system\", \"content\": system_message})\n        \n        # Add user message\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        \n        # Set parameters\n        temp = temperature if temperature is not None else self.temperature\n        tokens = max_tokens if max_tokens is not None else self.max_tokens\n        \n        # Convert tools to OpenAI format\n        openai_tools = []\n        for tool in tools:\n            openai_tool = {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": tool.get(\"name\", \"\"),\n                    \"description\": tool.get(\"description\", \"\"),\n                    \"parameters\": tool.get(\"parameters\", {})\n                }\n            }\n            openai_tools.append(openai_tool)\n        \n        try:\n            # Make the API call\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=messages,\n                temperature=temp,\n                max_tokens=tokens,\n                tools=openai_tools,\n                **kwargs\n            )\n            \n            # Extract response\n            choice = response.choices[0]\n            message = choice.message\n            \n            # Check for tool calls\n            if hasattr(message, \"tool_calls\") and message.tool_calls:\n                tool_calls = []\n                for tool_call in message.tool_calls:\n                    # Parse arguments as JSON\n                    try:\n                        arguments = json.loads(tool_call.function.arguments)\n                    except:\n                        arguments = tool_call.function.arguments\n                    \n                    # Create a normalized tool call\n                    normalized_tool_call = {\n                        \"id\": tool_call.id,\n                        \"name\": tool_call.function.name,\n                        \"arguments\": arguments\n                    }\n                    tool_calls.append(normalized_tool_call)\n                \n                return {\n                    \"content\": message.content,\n                    \"tool_calls\": tool_calls\n                }\n            else:\n                # No tool calls, just text\n                return {\n                    \"content\": message.content,\n                    \"tool_calls\": []\n                }\n        \n        except Exception as e:\n            logging.error(f\"Error generating with tools using OpenAI: {e}\")\n            return {\n                \"content\": f\"Error: {str(e)}\",\n                \"tool_calls\": []\n            }\n    \n    def extract_json(\n        self, \n        prompt: str, \n        schema: Dict[str, Any],\n        system_message: Optional[str] = None,\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None,\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Extract structured JSON data based on a prompt.\n        \n        Args:\n            prompt: The text prompt for extraction.\n            schema: JSON schema describing the expected structure.\n            system_message: Optional system message for the model.\n            temperature: Controls randomness in outputs. Overrides instance value if provided.\n            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.\n            **kwargs: Additional OpenAI-specific parameters.\n            \n        Returns:\n            The extracted JSON data.\n        \"\"\"\n        # Set default system message if not provided\n        if not system_message:\n            system_message = \"Extract the requested information and respond only with a valid JSON object according to the specified schema. Do not include any other text.\"\n        \n        # Set parameters\n        temp = temperature if temperature is not None else self.temperature\n        tokens = max_tokens if max_tokens is not None else self.max_tokens\n        \n        # Make the API call with response format JSON\n        try:\n            response = self.client.chat.completions.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": f\"Schema: {json.dumps(schema)}\\n\\nPrompt: {prompt}\"}\n                ],\n                temperature=temp,\n                max_tokens=tokens,\n                response_format={\"type\": \"json_object\"},\n                **kwargs\n            )\n            \n            # Extract and parse the response\n            content = response.choices[0].message.content\n            \n            try:\n                return json.loads(content)\n            except json.JSONDecodeError:\n                logging.error(f\"Failed to parse JSON from response: {content}\")\n                return {\"error\": \"Failed to parse JSON response\"}\n        \n        except Exception as e:\n            logging.error(f\"Error extracting JSON with OpenAI: {e}\")\n            return {\"error\": str(e)}\n    \n    def get_embedding(self, text: str, **kwargs) -> List[float]:\n        \"\"\"\n        Generate an embedding vector for the given text.\n        \n        Args:\n            text: The text to embed.\n            **kwargs: Additional OpenAI-specific parameters.\n            \n        Returns:\n            The embedding vector as a list of floats.\n        \"\"\"\n        try:\n            response = self.client.embeddings.create(\n                model=self.embedding_model,\n                input=text,\n                **kwargs\n            )\n            \n            return response.data[0].embedding\n        \n        except Exception as e:\n            logging.error(f\"Error generating embedding with OpenAI: {e}\")\n            return [] "}
{"type": "source_file", "path": "setup.py", "content": "from setuptools import setup, find_packages\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n    long_description = fh.read()\n\nwith open(\"requirements.txt\", \"r\", encoding=\"utf-8\") as fh:\n    requirements = fh.read().splitlines()\n\nsetup(\n    name=\"anus-ai\",\n    version=\"0.1.0\",\n    author=\"Anus AI Team\",\n    author_email=\"anus-ai@example.com\",\n    description=\"An open-source AI agent framework for task automation\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/anus-ai/anus\",\n    packages=find_packages(),\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.11\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n        \"Development Status :: 3 - Alpha\",\n        \"Intended Audience :: Developers\",\n        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    ],\n    python_requires=\">=3.11\",\n    install_requires=requirements,\n    entry_points={\n        \"console_scripts\": [\n            \"anus=anus.main:main\",\n        ],\n    },\n)\n"}
{"type": "source_file", "path": "anus/tools/base/tool_result.py", "content": "\"\"\"\nTool Result module for standardized result handling.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Union\nimport time\n\nclass ToolResult:\n    \"\"\"\n    Standardized container for tool execution results.\n    \n    Provides consistent structure and metadata for tool results.\n    \"\"\"\n    \n    def __init__(\n        self, \n        tool_name: str,\n        status: str = \"success\",\n        result: Any = None,\n        error: Optional[str] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ):\n        \"\"\"\n        Initialize a ToolResult instance.\n        \n        Args:\n            tool_name: Name of the tool that produced the result.\n            status: Status of the tool execution (\"success\" or \"error\").\n            result: The actual result data.\n            error: Error message if status is \"error\".\n            metadata: Additional metadata about the execution.\n        \"\"\"\n        self.tool_name = tool_name\n        self.status = status\n        self.result = result\n        self.error = error\n        self.metadata = metadata or {}\n        \n        # Add timestamp\n        self.timestamp = time.time()\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Convert the result to a dictionary.\n        \n        Returns:\n            A dictionary representation of the result.\n        \"\"\"\n        result_dict = {\n            \"tool_name\": self.tool_name,\n            \"status\": self.status,\n            \"timestamp\": self.timestamp,\n            \"metadata\": self.metadata\n        }\n        \n        if self.status == \"success\":\n            result_dict[\"result\"] = self.result\n        elif self.status == \"error\":\n            result_dict[\"error\"] = self.error\n        \n        return result_dict\n    \n    @classmethod\n    def success(cls, tool_name: str, result: Any, metadata: Optional[Dict[str, Any]] = None) -> 'ToolResult':\n        \"\"\"\n        Create a successful result.\n        \n        Args:\n            tool_name: Name of the tool.\n            result: The result data.\n            metadata: Additional metadata.\n            \n        Returns:\n            A ToolResult instance with success status.\n        \"\"\"\n        return cls(tool_name=tool_name, status=\"success\", result=result, metadata=metadata)\n    \n    @classmethod\n    def error(cls, tool_name: str, error: str, metadata: Optional[Dict[str, Any]] = None) -> 'ToolResult':\n        \"\"\"\n        Create an error result.\n        \n        Args:\n            tool_name: Name of the tool.\n            error: The error message.\n            metadata: Additional metadata.\n            \n        Returns:\n            A ToolResult instance with error status.\n        \"\"\"\n        return cls(tool_name=tool_name, status=\"error\", error=error, metadata=metadata)\n    \n    def is_success(self) -> bool:\n        \"\"\"\n        Check if the result is successful.\n        \n        Returns:\n            True if the status is \"success\", False otherwise.\n        \"\"\"\n        return self.status == \"success\"\n    \n    def is_error(self) -> bool:\n        \"\"\"\n        Check if the result is an error.\n        \n        Returns:\n            True if the status is \"error\", False otherwise.\n        \"\"\"\n        return self.status == \"error\" "}
{"type": "source_file", "path": "instructions/Planning Script.py", "content": "import json\nimport time\nfrom typing import Dict, List, Optional, Union\n\nfrom pydantic import Field\n\nfrom app.agent.base import BaseAgent\nfrom app.flow.base import BaseFlow\nfrom app.llm import LLM\nfrom app.logger import logger\nfrom app.schema import AgentState, Message\nfrom app.tool import PlanningTool\n\n\nclass PlanningFlow(BaseFlow):\n    \"\"\"A flow that manages planning and execution of tasks using agents.\"\"\"\n\n    llm: LLM = Field(default_factory=lambda: LLM())\n    planning_tool: PlanningTool = Field(default_factory=PlanningTool)\n    executor_keys: List[str] = Field(default_factory=list)\n    active_plan_id: str = Field(default_factory=lambda: f\"plan_{int(time.time())}\")\n    current_step_index: Optional[int] = None\n\n    def __init__(\n        self, agents: Union[BaseAgent, List[BaseAgent], Dict[str, BaseAgent]], **data\n    ):\n        # Set executor keys before super().__init__\n        if \"executors\" in data:\n            data[\"executor_keys\"] = data.pop(\"executors\")\n\n        # Set plan ID if provided\n        if \"plan_id\" in data:\n            data[\"active_plan_id\"] = data.pop(\"plan_id\")\n\n        # Initialize the planning tool if not provided\n        if \"planning_tool\" not in data:\n            planning_tool = PlanningTool()\n            data[\"planning_tool\"] = planning_tool\n\n        # Call parent's init with the processed data\n        super().__init__(agents, **data)\n\n        # Set executor_keys to all agent keys if not specified\n        if not self.executor_keys:\n            self.executor_keys = list(self.agents.keys())\n\n    def get_executor(self, step_type: Optional[str] = None) -> BaseAgent:\n        \"\"\"\n        Get an appropriate executor agent for the current step.\n        Can be extended to select agents based on step type/requirements.\n        \"\"\"\n        # If step type is provided and matches an agent key, use that agent\n        if step_type and step_type in self.agents:\n            return self.agents[step_type]\n\n        # Otherwise use the first available executor or fall back to primary agent\n        for key in self.executor_keys:\n            if key in self.agents:\n                return self.agents[key]\n\n        # Fallback to primary agent\n        return self.primary_agent\n\n    async def execute(self, input_text: str) -> str:\n        \"\"\"Execute the planning flow with agents.\"\"\"\n        try:\n            if not self.primary_agent:\n                raise ValueError(\"No primary agent available\")\n\n            # Create initial plan if input provided\n            if input_text:\n                await self._create_initial_plan(input_text)\n\n                # Verify plan was created successfully\n                if self.active_plan_id not in self.planning_tool.plans:\n                    logger.error(\n                        f\"Plan creation failed. Plan ID {self.active_plan_id} not found in planning tool.\"\n                    )\n                    return f\"Failed to create plan for: {input_text}\"\n\n            result = \"\"\n            while True:\n                # Get current step to execute\n                self.current_step_index, step_info = await self._get_current_step_info()\n\n                # Exit if no more steps or plan completed\n                if self.current_step_index is None:\n                    result += await self._finalize_plan()\n                    break\n\n                # Execute current step with appropriate agent\n                step_type = step_info.get(\"type\") if step_info else None\n                executor = self.get_executor(step_type)\n                step_result = await self._execute_step(executor, step_info)\n                result += step_result + \"\\n\"\n\n                # Check if agent wants to terminate\n                if hasattr(executor, \"state\") and executor.state == AgentState.FINISHED:\n                    break\n\n            return result\n        except Exception as e:\n            logger.error(f\"Error in PlanningFlow: {str(e)}\")\n            return f\"Execution failed: {str(e)}\"\n\n    async def _create_initial_plan(self, request: str) -> None:\n        \"\"\"Create an initial plan based on the request using the flow's LLM and PlanningTool.\"\"\"\n        logger.info(f\"Creating initial plan with ID: {self.active_plan_id}\")\n\n        # Create a system message for plan creation\n        system_message = Message.system_message(\n            \"You are a planning assistant. Create a concise, actionable plan with clear steps. \"\n            \"Focus on key milestones rather than detailed sub-steps. \"\n            \"Optimize for clarity and efficiency.\"\n        )\n\n        # Create a user message with the request\n        user_message = Message.user_message(\n            f\"Create a reasonable plan with clear steps to accomplish the task: {request}\"\n        )\n\n        # Call LLM with PlanningTool\n        response = await self.llm.ask_tool(\n            messages=[user_message],\n            system_msgs=[system_message],\n            tools=[self.planning_tool.to_param()],\n            tool_choice=\"required\",\n        )\n\n        # Process tool calls if present\n        if response.tool_calls:\n            for tool_call in response.tool_calls:\n                if tool_call.function.name == \"planning\":\n                    # Parse the arguments\n                    args = tool_call.function.arguments\n                    if isinstance(args, str):\n                        try:\n                            args = json.loads(args)\n                        except json.JSONDecodeError:\n                            logger.error(f\"Failed to parse tool arguments: {args}\")\n                            continue\n\n                    # Ensure plan_id is set correctly and execute the tool\n                    args[\"plan_id\"] = self.active_plan_id\n\n                    # Execute the tool via ToolCollection instead of directly\n                    result = await self.planning_tool.execute(**args)\n\n                    logger.info(f\"Plan creation result: {str(result)}\")\n                    return\n\n        # If execution reached here, create a default plan\n        logger.warning(\"Creating default plan\")\n\n        # Create default plan using the ToolCollection\n        await self.planning_tool.execute(\n            **{\n                \"command\": \"create\",\n                \"plan_id\": self.active_plan_id,\n                \"title\": f\"Plan for: {request[:50]}{'...' if len(request) > 50 else ''}\",\n                \"steps\": [\"Analyze request\", \"Execute task\", \"Verify results\"],\n            }\n        )\n\n    async def _get_current_step_info(self) -> tuple[Optional[int], Optional[dict]]:\n        \"\"\"\n        Parse the current plan to identify the first non-completed step's index and info.\n        Returns (None, None) if no active step is found.\n        \"\"\"\n        if (\n            not self.active_plan_id\n            or self.active_plan_id not in self.planning_tool.plans\n        ):\n            logger.error(f\"Plan with ID {self.active_plan_id} not found\")\n            return None, None\n\n        try:\n            # Direct access to plan data from planning tool storage\n            plan_data = self.planning_tool.plans[self.active_plan_id]\n            steps = plan_data.get(\"steps\", [])\n            step_statuses = plan_data.get(\"step_statuses\", [])\n\n            # Find first non-completed step\n            for i, step in enumerate(steps):\n                if i >= len(step_statuses):\n                    status = \"not_started\"\n                else:\n                    status = step_statuses[i]\n\n                if status in [\"not_started\", \"in_progress\"]:\n                    # Extract step type/category if available\n                    step_info = {\"text\": step}\n\n                    # Try to extract step type from the text (e.g., [SEARCH] or [CODE])\n                    import re\n\n                    type_match = re.search(r\"\\[([A-Z_]+)\\]\", step)\n                    if type_match:\n                        step_info[\"type\"] = type_match.group(1).lower()\n\n                    # Mark current step as in_progress\n                    try:\n                        await self.planning_tool.execute(\n                            command=\"mark_step\",\n                            plan_id=self.active_plan_id,\n                            step_index=i,\n                            step_status=\"in_progress\",\n                        )\n                    except Exception as e:\n                        logger.warning(f\"Error marking step as in_progress: {e}\")\n                        # Update step status directly if needed\n                        if i < len(step_statuses):\n                            step_statuses[i] = \"in_progress\"\n                        else:\n                            while len(step_statuses) < i:\n                                step_statuses.append(\"not_started\")\n                            step_statuses.append(\"in_progress\")\n\n                        plan_data[\"step_statuses\"] = step_statuses\n\n                    return i, step_info\n\n            return None, None  # No active step found\n\n        except Exception as e:\n            logger.warning(f\"Error finding current step index: {e}\")\n            return None, None\n\n    async def _execute_step(self, executor: BaseAgent, step_info: dict) -> str:\n        \"\"\"Execute the current step with the specified agent using agent.run().\"\"\"\n        # Prepare context for the agent with current plan status\n        plan_status = await self._get_plan_text()\n        step_text = step_info.get(\"text\", f\"Step {self.current_step_index}\")\n\n        # Create a prompt for the agent to execute the current step\n        step_prompt = f\"\"\"\n        CURRENT PLAN STATUS:\n        {plan_status}\n\n        YOUR CURRENT TASK:\n        You are now working on step {self.current_step_index}: \"{step_text}\"\n\n        Please execute this step using the appropriate tools. When you're done, provide a summary of what you accomplished.\n        \"\"\"\n\n        # Use agent.run() to execute the step\n        try:\n            step_result = await executor.run(step_prompt)\n\n            # Mark the step as completed after successful execution\n            await self._mark_step_completed()\n\n            return step_result\n        except Exception as e:\n            logger.error(f\"Error executing step {self.current_step_index}: {e}\")\n            return f\"Error executing step {self.current_step_index}: {str(e)}\"\n\n    async def _mark_step_completed(self) -> None:\n        \"\"\"Mark the current step as completed.\"\"\"\n        if self.current_step_index is None:\n            return\n\n        try:\n            # Mark the step as completed\n            await self.planning_tool.execute(\n                command=\"mark_step\",\n                plan_id=self.active_plan_id,\n                step_index=self.current_step_index,\n                step_status=\"completed\",\n            )\n            logger.info(\n                f\"Marked step {self.current_step_index} as completed in plan {self.active_plan_id}\"\n            )\n        except Exception as e:\n            logger.warning(f\"Failed to update plan status: {e}\")\n            # Update step status directly in planning tool storage\n            if self.active_plan_id in self.planning_tool.plans:\n                plan_data = self.planning_tool.plans[self.active_plan_id]\n                step_statuses = plan_data.get(\"step_statuses\", [])\n\n                # Ensure the step_statuses list is long enough\n                while len(step_statuses) <= self.current_step_index:\n                    step_statuses.append(\"not_started\")\n\n                # Update the status\n                step_statuses[self.current_step_index] = \"completed\"\n                plan_data[\"step_statuses\"] = step_statuses\n\n    async def _get_plan_text(self) -> str:\n        \"\"\"Get the current plan as formatted text.\"\"\"\n        try:\n            result = await self.planning_tool.execute(\n                command=\"get\", plan_id=self.active_plan_id\n            )\n            return result.output if hasattr(result, \"output\") else str(result)\n        except Exception as e:\n            logger.error(f\"Error getting plan: {e}\")\n            return self._generate_plan_text_from_storage()\n\n    def _generate_plan_text_from_storage(self) -> str:\n        \"\"\"Generate plan text directly from storage if the planning tool fails.\"\"\"\n        try:\n            if self.active_plan_id not in self.planning_tool.plans:\n                return f\"Error: Plan with ID {self.active_plan_id} not found\"\n\n            plan_data = self.planning_tool.plans[self.active_plan_id]\n            title = plan_data.get(\"title\", \"Untitled Plan\")\n            steps = plan_data.get(\"steps\", [])\n            step_statuses = plan_data.get(\"step_statuses\", [])\n            step_notes = plan_data.get(\"step_notes\", [])\n\n            # Ensure step_statuses and step_notes match the number of steps\n            while len(step_statuses) < len(steps):\n                step_statuses.append(\"not_started\")\n            while len(step_notes) < len(steps):\n                step_notes.append(\"\")\n\n            # Count steps by status\n            status_counts = {\n                \"completed\": 0,\n                \"in_progress\": 0,\n                \"blocked\": 0,\n                \"not_started\": 0,\n            }\n\n            for status in step_statuses:\n                if status in status_counts:\n                    status_counts[status] += 1\n\n            completed = status_counts[\"completed\"]\n            total = len(steps)\n            progress = (completed / total) * 100 if total > 0 else 0\n\n            plan_text = f\"Plan: {title} (ID: {self.active_plan_id})\\n\"\n            plan_text += \"=\" * len(plan_text) + \"\\n\\n\"\n\n            plan_text += (\n                f\"Progress: {completed}/{total} steps completed ({progress:.1f}%)\\n\"\n            )\n            plan_text += f\"Status: {status_counts['completed']} completed, {status_counts['in_progress']} in progress, \"\n            plan_text += f\"{status_counts['blocked']} blocked, {status_counts['not_started']} not started\\n\\n\"\n            plan_text += \"Steps:\\n\"\n\n            for i, (step, status, notes) in enumerate(\n                zip(steps, step_statuses, step_notes)\n            ):\n                if status == \"completed\":\n                    status_mark = \"[✓]\"\n                elif status == \"in_progress\":\n                    status_mark = \"[→]\"\n                elif status == \"blocked\":\n                    status_mark = \"[!]\"\n                else:  # not_started\n                    status_mark = \"[ ]\"\n\n                plan_text += f\"{i}. {status_mark} {step}\\n\"\n                if notes:\n                    plan_text += f\"   Notes: {notes}\\n\"\n\n            return plan_text\n        except Exception as e:\n            logger.error(f\"Error generating plan text from storage: {e}\")\n            return f\"Error: Unable to retrieve plan with ID {self.active_plan_id}\"\n\n    async def _finalize_plan(self) -> str:\n        \"\"\"Finalize the plan and provide a summary using the flow's LLM directly.\"\"\"\n        plan_text = await self._get_plan_text()\n\n        # Create a summary using the flow's LLM directly\n        try:\n            system_message = Message.system_message(\n                \"You are a planning assistant. Your task is to summarize the completed plan.\"\n            )\n\n            user_message = Message.user_message(\n                f\"The plan has been completed. Here is the final plan status:\\n\\n{plan_text}\\n\\nPlease provide a summary of what was accomplished and any final thoughts.\"\n            )\n\n            response = await self.llm.ask(\n                messages=[user_message], system_msgs=[system_message]\n            )\n\n            return f\"Plan completed:\\n\\n{response}\"\n        except Exception as e:\n            logger.error(f\"Error finalizing plan with LLM: {e}\")\n\n            # Fallback to using an agent for the summary\n            try:\n                agent = self.primary_agent\n                summary_prompt = f\"\"\"\n                The plan has been completed. Here is the final plan status:\n\n                {plan_text}\n\n                Please provide a summary of what wa<response clipped><NOTE>To save on context only part of this file has been shown to you. You should retry this tool after you have searched inside the file with `grep -n` in order to find the line numbers of what you are looking for.</NOTE>"}
{"type": "source_file", "path": "anus/core/agent/hybrid_agent.py", "content": "\"\"\"\nHybrid Agent module that combines single and multi-agent capabilities.\n\nThis agent can dynamically switch between single and multi-agent modes based on task complexity.\n\"\"\"\n\nimport logging\nimport re\nfrom typing import Dict, Any, List, Tuple, Optional\n\nfrom anus.core.agent.tool_agent import ToolAgent\n\nclass HybridAgent(ToolAgent):\n    \"\"\"\n    A hybrid agent that can switch between single and multi-agent modes.\n    \n    This agent assesses task complexity and chooses the appropriate mode.\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: Optional[str] = None,\n        max_iterations: int = 10,\n        tools: Optional[List[str]] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize a HybridAgent instance.\n        \n        Args:\n            name: Optional name for the agent.\n            max_iterations: Maximum number of thought-action cycles to perform.\n            tools: Optional list of tool names to load.\n            **kwargs: Additional configuration options for the agent.\n        \"\"\"\n        super().__init__(name=name, max_iterations=max_iterations, tools=tools, **kwargs)\n        self.mode = \"auto\"\n        \n        # Specialized agents for multi-agent mode\n        self.specialized_agents = {\n            \"researcher\": ToolAgent(name=\"researcher\", tools=tools),\n            \"planner\": ToolAgent(name=\"planner\", tools=tools),\n            \"executor\": ToolAgent(name=\"executor\", tools=tools),\n            \"critic\": ToolAgent(name=\"critic\", tools=tools)\n        }\n    \n    def _assess_complexity(self, task: str) -> float:\n        \"\"\"\n        Assess the complexity of a task.\n        \n        Args:\n            task: The task description.\n            \n        Returns:\n            A complexity score between 0 and 10.\n        \"\"\"\n        complexity = 0.0\n        \n        # Check for multiple operations\n        operations = [\n            (r'(calculate|compute|evaluate)', 1.0),  # Basic calculations\n            (r'(search|find|look up)', 1.0),  # Search operations\n            (r'(count|process|analyze|transform)\\s+text', 1.0),  # Text operations\n            (r'run\\s+code|execute', 1.5),  # Code execution\n            (r'compare|contrast|evaluate', 2.0),  # Analysis operations\n            (r'optimize|improve|enhance', 2.5),  # Optimization tasks\n            (r'and|then|after|before', 1.0),  # Task chaining\n            (r'if|when|unless|otherwise', 1.5),  # Conditional operations\n            (r'all|every|each', 1.0),  # Comprehensive operations\n            (r'most|best|optimal', 1.5)  # Decision making\n        ]\n        \n        # Add complexity for each operation found\n        for pattern, score in operations:\n            matches = re.findall(pattern, task.lower())\n            complexity += score * len(matches)\n        \n        # Add complexity for length of task description\n        words = task.split()\n        complexity += len(words) * 0.1  # 0.1 points per word\n        \n        # Add complexity for special characters (potential complex expressions)\n        special_chars = sum(1 for c in task if not c.isalnum() and not c.isspace())\n        complexity += special_chars * 0.2\n        \n        # Add complexity for multiple tools needed\n        tool_keywords = {\n            'calculator': ['calculate', 'compute', 'evaluate', 'math'],\n            'search': ['search', 'find', 'look up', 'query'],\n            'text': ['text', 'string', 'characters', 'words'],\n            'code': ['code', 'execute', 'run', 'python']\n        }\n        \n        tools_needed = 0\n        task_lower = task.lower()\n        for tool_name, keywords in tool_keywords.items():\n            if any(kw in task_lower for kw in keywords):\n                tools_needed += 1\n            \n        complexity += tools_needed * 1.5\n        \n        # Cap the complexity at 10\n        return min(10.0, complexity)\n    \n    def execute(self, task: str, **kwargs) -> Dict[str, Any]:\n        \"\"\"\n        Execute a task using the appropriate mode based on complexity.\n        \n        Args:\n            task: The task description to execute.\n            **kwargs: Additional parameters for task execution.\n            \n        Returns:\n            A dictionary containing the execution result and metadata.\n        \"\"\"\n        complexity = self._assess_complexity(task)\n        \n        # Decide on mode based on complexity\n        if complexity < 3.0:\n            logging.info(f\"Task complexity ({complexity:.1f}) below threshold (3.0). ANUS staying tight in single-agent mode.\")\n            logging.info(\"This task is so simple even a constipated ANUS could handle it.\")\n            return super().execute(task, **kwargs)\n        else:\n            logging.info(f\"Task complexity ({complexity:.1f}) above threshold (3.0). ANUS expanding to multi-agent mode.\")\n            logging.info(\"ANUS is expanding to accommodate multiple agents for this complex task.\")\n            return self._execute_multi_agent(task, **kwargs)\n    \n    def _execute_multi_agent(self, task: str, **kwargs) -> Dict[str, Any]:\n        \"\"\"\n        Execute a task using multiple specialized agents.\n        \n        Args:\n            task: The task description to execute.\n            **kwargs: Additional parameters for task execution.\n            \n        Returns:\n            A dictionary containing the aggregated results.\n        \"\"\"\n        logging.info(\"ANUS expanding to accommodate multiple agents\")\n        logging.info(\"Task decomposed into subtasks for optimal ANUS performance\")\n        \n        # For simple calculator tasks, use direct execution\n        if task.lower().startswith(\"calculate\"):\n            # Use the ToolAgent's _decide_action method to determine the action\n            action_name, action_input = self._decide_action({\"task\": task})\n            \n            # If it's a calculator action, execute it directly\n            if action_name == \"calculator\" and \"expression\" in action_input:\n                result = self._execute_action(action_name, action_input)\n                if result.get(\"status\") == \"success\" and \"result\" in result:\n                    return {\n                        \"task\": task,\n                        \"answer\": f\"The result of {action_input['expression']} is {result['result']}\",\n                        \"direct_result\": result,\n                        \"mode\": \"direct\"\n                    }\n        \n        # For complex tasks, use multi-agent approach\n        results = {}\n        final_result = None\n        \n        # Researcher analyzes the task and gathers information\n        researcher_result = self.specialized_agents[\"researcher\"].execute(\n            f\"Analyze and gather information for: {task}\"\n        )\n        results[\"researcher\"] = researcher_result\n        \n        # Planner creates a strategy based on research\n        planner_result = self.specialized_agents[\"planner\"].execute(\n            f\"Plan execution strategy for: {task}\\nBased on research: {researcher_result}\"\n        )\n        results[\"planner\"] = planner_result\n        \n        # Executor carries out the plan\n        executor_result = self.specialized_agents[\"executor\"].execute(\n            f\"Execute plan for: {task}\\nFollowing strategy: {planner_result}\"\n        )\n        results[\"executor\"] = executor_result\n        final_result = executor_result  # Use executor's result as the primary result\n        \n        # Critic evaluates the results\n        critic_result = self.specialized_agents[\"critic\"].execute(\n            f\"Evaluate results for: {task}\\nAnalyzing output: {executor_result}\"\n        )\n        results[\"critic\"] = critic_result\n        \n        logging.info(\"All agents have finished their tasks. ANUS is aggregating results...\")\n        logging.info(\"ANUS has successfully completed multi-agent processing\")\n        \n        return {\n            \"task\": task,\n            \"answer\": final_result.get(\"answer\", str(final_result)),\n            \"agent_results\": results,\n            \"mode\": \"multi\"\n        } "}
{"type": "source_file", "path": "anus/core/orchestrator.py", "content": "\"\"\"\nOrchestrator module for the ANUS framework.\n\nThis module contains the agent orchestration system that manages agent \nlifecycle and coordinates task execution across multiple agents.\n\nBehind every successful ANUS is a well-designed Orchestrator.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Union\nimport logging\nimport yaml\nimport os\nimport time\nimport random\n\nfrom anus.core.agent import BaseAgent, HybridAgent\nfrom anus.core.memory import ShortTermMemory, LongTermMemory\n\n# Create a custom logger for ANUS-specific wisdom\nclass ANUSLogger(logging.Logger):\n    \"\"\"Custom logger that occasionally adds ANUS wisdom to log messages.\"\"\"\n    \n    _wisdom = [\n        \"ANUS Wisdom: Always test your backend thoroughly before deployment.\",\n        \"ANUS Wisdom: Sometimes a little push from behind is all you need.\",\n        \"ANUS Wisdom: Keep your interfaces clean and well-documented.\",\n        \"ANUS Wisdom: A tight architecture prevents unwanted leakage.\",\n        \"ANUS Wisdom: Even the backend deserves some love and attention.\"\n    ]\n    \n    def info(self, msg, *args, **kwargs):\n        if random.random() < 0.1:  # 10% chance\n            msg = f\"{msg} - {random.choice(self._wisdom)}\"\n        super().info(msg, *args, **kwargs)\n    \n    def debug(self, msg, *args, **kwargs):\n        if random.random() < 0.2:  # 20% chance\n            msg = f\"{msg} - {random.choice(self._wisdom)}\"\n        super().debug(msg, *args, **kwargs)\n\n# Register our custom logger\nlogging.setLoggerClass(ANUSLogger)\nlogger = logging.getLogger(\"anus.orchestrator\")\n\nclass AgentOrchestrator:\n    \"\"\"\n    Coordinates multiple agents and manages their lifecycle.\n    \n    This class is responsible for:\n    - Loading configuration\n    - Creating and initializing agents\n    - Routing tasks to appropriate agents\n    - Managing agent resources\n    - Collecting and aggregating results\n    \n    Remember: A well-lubricated ANUS runs smoothly without friction.\n    \"\"\"\n    \n    def __init__(self, config_path: str = \"config.yaml\"):\n        \"\"\"\n        Initialize an AgentOrchestrator instance.\n        \n        Args:\n            config_path: Path to the configuration file.\n        \"\"\"\n        self.config = self._load_config(config_path)\n        self.agents: Dict[str, BaseAgent] = {}\n        self.primary_agent = self._create_primary_agent()\n        self.last_result: Dict[str, Any] = {}\n        self.task_history: List[Dict[str, Any]] = []\n        \n        # Easter eggs for internal task names\n        self._easter_egg_tasks = {\n            \"status\": \"Performing deep ANUS inspection...\",\n            \"health\": \"Checking if ANUS is functioning properly...\",\n            \"clean\": \"Flushing old data from ANUS...\",\n            \"optimize\": \"Making ANUS more responsive and flexible...\",\n            \"expand\": \"Expanding ANUS capabilities...\"\n        }\n        \n        logger.info(\"ANUS Orchestrator initialized and ready for action\")\n    \n    def execute_task(self, task: str, mode: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"\n        Execute a task using an appropriate agent.\n        \n        Args:\n            task: The task description to execute.\n            mode: Execution mode (\"single\" or \"multi\"). If None, uses the config default.\n            \n        Returns:\n            The execution result.\n        \"\"\"\n        # Use config default if mode not specified\n        if mode is None:\n            mode = self.config.get(\"agent\", {}).get(\"mode\", \"single\")\n        \n        start_time = time.time()\n        \n        # Check for easter egg task names\n        display_task = task\n        for keyword, message in self._easter_egg_tasks.items():\n            if keyword.lower() in task.lower().split():\n                display_task = message\n                logger.info(f\"Easter egg activated: {message}\")\n                break\n        \n        # Log the task\n        if mode == \"multi\":\n            logger.info(f\"ANUS expanding to handle multiple agents for task: {display_task}\")\n        else:\n            logger.info(f\"ANUS processing task: {display_task}\")\n        \n        # Execute the task with the primary agent\n        result = self.primary_agent.execute(task, mode=mode)\n        \n        # Record execution time\n        execution_time = time.time() - start_time\n        \n        # Create a task record\n        task_record = {\n            \"task\": task,\n            \"mode\": mode,\n            \"start_time\": start_time,\n            \"execution_time\": execution_time,\n            \"status\": \"completed\",\n            \"result\": result\n        }\n        \n        # Add to task history\n        self.task_history.append(task_record)\n        \n        # Update last result\n        self.last_result = result\n        \n        # Log completion\n        if execution_time > 10:\n            logger.info(f\"ANUS finished after {execution_time:.2f}s - that was quite a workout!\")\n        else:\n            logger.info(f\"ANUS completed task in {execution_time:.2f}s\")\n        \n        return result\n    \n    def list_agents(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        List all registered agents.\n        \n        Returns:\n            A list of agent descriptions.\n        \"\"\"\n        agent_list = []\n        \n        # Add primary agent\n        agent_list.append({\n            \"id\": self.primary_agent.id,\n            \"name\": self.primary_agent.name,\n            \"type\": type(self.primary_agent).__name__,\n            \"primary\": True\n        })\n        \n        # Add other agents\n        for name, agent in self.agents.items():\n            if agent.id != self.primary_agent.id:\n                agent_list.append({\n                    \"id\": agent.id,\n                    \"name\": agent.name,\n                    \"type\": type(agent).__name__,\n                    \"primary\": False\n                })\n        \n        if len(agent_list) > 3:\n            logger.debug(f\"ANUS is quite full with {len(agent_list)} agents inside\")\n        \n        return agent_list\n    \n    def get_task_history(self, limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the history of executed tasks.\n        \n        Args:\n            limit: Maximum number of history items to return.\n            \n        Returns:\n            A list of task history records.\n        \"\"\"\n        if limit > 50:\n            logger.warning(f\"Requesting {limit} history items? That's a deep dive into ANUS history!\")\n        \n        return self.task_history[-limit:]\n    \n    def get_last_result(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the result of the last executed task.\n        \n        Returns:\n            The last execution result.\n        \"\"\"\n        return self.last_result\n    \n    def _load_config(self, config_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Load configuration from a YAML file.\n        \n        Args:\n            config_path: Path to the configuration file.\n            \n        Returns:\n            The loaded configuration.\n        \"\"\"\n        # Default configuration\n        default_config = {\n            \"agent\": {\n                \"name\": \"anus\",\n                \"mode\": \"single\",\n                \"max_iterations\": 10,\n                \"complexity_threshold\": 7\n            },\n            \"memory\": {\n                \"short_term\": {\n                    \"capacity\": 1000,\n                    \"ttl\": 3600\n                },\n                \"long_term\": {\n                    \"enabled\": True,\n                    \"storage_path\": None,\n                    \"index_in_memory\": True\n                }\n            },\n            \"models\": {\n                \"default\": {\n                    \"provider\": \"openai\",\n                    \"model\": \"gpt-4\",\n                    \"temperature\": 0.0\n                }\n            },\n            \"tools\": {\n                \"enabled\": []\n            }\n        }\n        \n        # Check if config file exists\n        if not os.path.exists(config_path):\n            logger.warning(f\"Config file {config_path} not found. Using default configuration.\")\n            logger.info(\"ANUS is running with default settings. It might be a tight fit for complex tasks.\")\n            return default_config\n        \n        try:\n            # Load the config file\n            with open(config_path, \"r\") as f:\n                config = yaml.safe_load(f)\n            \n            # Merge with default config\n            merged_config = self._merge_configs(default_config, config)\n            \n            logger.info(\"ANUS configuration loaded successfully\")\n            if merged_config.get(\"agent\", {}).get(\"mode\") == \"multi\":\n                logger.info(\"ANUS is configured for multi-agent mode - it's going to get crowded in there!\")\n            \n            return merged_config\n        except Exception as e:\n            logger.error(f\"Error loading config file: {e}\")\n            logger.info(\"ANUS reverted to default configuration. Performance may not be optimal.\")\n            return default_config\n    \n    def _merge_configs(self, default: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Merge two configuration dictionaries.\n        \n        Args:\n            default: Default configuration.\n            override: Override configuration.\n            \n        Returns:\n            The merged configuration.\n        \"\"\"\n        result = default.copy()\n        \n        for key, value in override.items():\n            if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n                result[key] = self._merge_configs(result[key], value)\n            else:\n                result[key] = value\n        \n        return result\n    \n    def _create_primary_agent(self) -> HybridAgent:\n        \"\"\"\n        Create the primary agent based on configuration.\n        \n        Returns:\n            A HybridAgent instance.\n        \"\"\"\n        # Get agent config\n        agent_config = self.config.get(\"agent\", {})\n        name = agent_config.get(\"name\", \"anus\")\n        mode = agent_config.get(\"mode\", \"single\")\n        max_iterations = agent_config.get(\"max_iterations\", 10)\n        complexity_threshold = agent_config.get(\"complexity_threshold\", 7)\n        \n        # Get tools config\n        tools_config = self.config.get(\"tools\", {})\n        enabled_tools = tools_config.get(\"enabled\", [])\n        \n        # Create memories\n        short_term_memory = self._create_short_term_memory()\n        long_term_memory = self._create_long_term_memory()\n        \n        # Create the agent\n        agent = HybridAgent(\n            name=name,\n            max_iterations=max_iterations,\n            tools=enabled_tools,\n            mode=mode,\n            complexity_threshold=complexity_threshold,\n            short_term_memory=short_term_memory,\n            long_term_memory=long_term_memory\n        )\n        \n        logger.info(f\"Primary agent created. ANUS is ready with {len(enabled_tools)} tools available\")\n        \n        # Create specialized agents if in multi mode\n        if mode == \"multi\" or mode == \"auto\":\n            self._create_specialized_agents(agent)\n            logger.info(\"Multiple specialized agents have been inserted into ANUS\")\n        \n        # Register the agent\n        self.agents[name] = agent\n        \n        return agent\n    \n    def _create_short_term_memory(self) -> ShortTermMemory:\n        \"\"\"\n        Create a short-term memory instance based on configuration.\n        \n        Returns:\n            A ShortTermMemory instance.\n        \"\"\"\n        memory_config = self.config.get(\"memory\", {}).get(\"short_term\", {})\n        capacity = memory_config.get(\"capacity\", 1000)\n        ttl = memory_config.get(\"ttl\", 3600)\n        \n        logger.debug(f\"Initializing ANUS short-term memory with capacity {capacity}\")\n        return ShortTermMemory(capacity=capacity, ttl=ttl)\n    \n    def _create_long_term_memory(self) -> Optional[LongTermMemory]:\n        \"\"\"\n        Create a long-term memory instance based on configuration.\n        \n        Returns:\n            A LongTermMemory instance, or None if disabled.\n        \"\"\"\n        memory_config = self.config.get(\"memory\", {}).get(\"long_term\", {})\n        enabled = memory_config.get(\"enabled\", True)\n        \n        if not enabled:\n            logger.info(\"Long-term memory disabled. ANUS will forget everything after each session.\")\n            return None\n        \n        storage_path = memory_config.get(\"storage_path\")\n        index_in_memory = memory_config.get(\"index_in_memory\", True)\n        \n        if storage_path:\n            logger.debug(f\"ANUS will store long-term memories at: {storage_path}\")\n        else:\n            logger.debug(\"ANUS will store long-term memories in the default location\")\n        \n        return LongTermMemory(storage_path=storage_path, index_in_memory=index_in_memory)\n    \n    def _create_specialized_agents(self, primary_agent: HybridAgent) -> None:\n        \"\"\"\n        Create specialized agents for multi-agent mode.\n        \n        Args:\n            primary_agent: The primary HybridAgent instance.\n        \"\"\"\n        # Default specialized agent roles\n        default_roles = [\"researcher\", \"planner\", \"executor\", \"critic\"]\n        \n        # Get specialized agent configurations\n        specialized_config = self.config.get(\"specialized_agents\", {})\n        roles = specialized_config.get(\"roles\", default_roles)\n        \n        # Create each specialized agent\n        for role in roles:\n            role_config = specialized_config.get(role, {})\n            \n            # Default configuration for the role\n            default_role_config = {\n                \"name\": f\"{role}-agent\",\n                \"max_iterations\": primary_agent.max_iterations,\n                \"tools\": self.config.get(\"tools\", {}).get(\"enabled\", [])\n            }\n            \n            # Merge with role-specific config\n            merged_config = self._merge_configs(default_role_config, role_config)\n            \n            # Add to the primary agent\n            primary_agent.add_specialized_agent(role, merged_config)\n            \n            logger.debug(f\"Added {role} agent to ANUS\")\n        \n        logger.info(f\"ANUS now contains {len(roles)} specialized agents working together harmoniously\")\n        if len(roles) > 5:\n            logger.warning(\"That's a lot of agents to fit inside one ANUS. Performance may be affected.\") "}
{"type": "source_file", "path": "anus/core/planning/base_planner.py", "content": "\"\"\"\nBase Planner module that defines the common interface for task planning.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, List, Any, Optional\n\nclass BasePlanner(ABC):\n    \"\"\"\n    Abstract base class for planners in the ANUS framework.\n    \n    Provides the core functionality for breaking down tasks into steps.\n    \"\"\"\n    \n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize a BasePlanner instance.\n        \n        Args:\n            **kwargs: Additional configuration options for the planner.\n        \"\"\"\n        self.config = kwargs\n    \n    @abstractmethod\n    def create_plan(self, task: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Create a plan for executing a task.\n        \n        Args:\n            task: The task description.\n            context: Optional context for planning.\n            \n        Returns:\n            A plan dictionary with steps and metadata.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def replan(self, plan: Dict[str, Any], feedback: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Update a plan based on execution feedback.\n        \n        Args:\n            plan: The current plan.\n            feedback: Feedback from execution.\n            \n        Returns:\n            The updated plan.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def get_next_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get the next step to execute from a plan.\n        \n        Args:\n            plan: The current plan.\n            \n        Returns:\n            The next step to execute, or None if the plan is complete.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def mark_step_complete(self, plan: Dict[str, Any], step_id: str, result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Mark a step as complete in a plan.\n        \n        Args:\n            plan: The current plan.\n            step_id: The ID of the completed step.\n            result: The result of the step execution.\n            \n        Returns:\n            The updated plan.\n        \"\"\"\n        pass "}
{"type": "source_file", "path": "anus/core/agent/__init__.py", "content": "\"\"\"\nAgent module for the ANUS framework.\n\nThis module contains various agent implementations:\n- BaseAgent: Abstract base class for all agents\n- ReactAgent: Agent with reasoning capabilities\n- ToolAgent: Agent with tool execution capabilities\n- HybridAgent: Agent that can switch between single and multi-agent modes\n\"\"\"\n\nfrom anus.core.agent.base_agent import BaseAgent\nfrom anus.core.agent.react_agent import ReactAgent\nfrom anus.core.agent.tool_agent import ToolAgent\nfrom anus.core.agent.hybrid_agent import HybridAgent\n\n__all__ = [\"BaseAgent\", \"ReactAgent\", \"ToolAgent\", \"HybridAgent\"] "}
{"type": "source_file", "path": "anus/models/base/base_model.py", "content": "\"\"\"\nBase Model module that defines the common interface for all language models.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, List, Any, Optional, Union, Callable\n\nclass BaseModel(ABC):\n    \"\"\"\n    Abstract base class for language model implementations.\n    \n    Provides a common interface for interacting with different LLM providers.\n    \"\"\"\n    \n    def __init__(\n        self, \n        model_name: str, \n        temperature: float = 0.0,\n        max_tokens: Optional[int] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize a BaseModel instance.\n        \n        Args:\n            model_name: The name of the model to use.\n            temperature: Controls randomness in outputs. Lower values are more deterministic.\n            max_tokens: Maximum number of tokens to generate.\n            **kwargs: Additional model-specific parameters.\n        \"\"\"\n        self.model_name = model_name\n        self.temperature = temperature\n        self.max_tokens = max_tokens\n        self.config = kwargs\n    \n    @abstractmethod\n    def generate(\n        self, \n        prompt: str, \n        system_message: Optional[str] = None,\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None,\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Generate text based on a prompt.\n        \n        Args:\n            prompt: The text prompt for generation.\n            system_message: Optional system message for models that support it.\n            temperature: Controls randomness in outputs. Overrides instance value if provided.\n            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.\n            **kwargs: Additional model-specific parameters.\n            \n        Returns:\n            The generated text response.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def generate_with_tools(\n        self, \n        prompt: str, \n        tools: List[Dict[str, Any]],\n        system_message: Optional[str] = None,\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None,\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Generate text with tool calling capabilities.\n        \n        Args:\n            prompt: The text prompt for generation.\n            tools: List of tool schemas available for use.\n            system_message: Optional system message for models that support it.\n            temperature: Controls randomness in outputs. Overrides instance value if provided.\n            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.\n            **kwargs: Additional model-specific parameters.\n            \n        Returns:\n            A dictionary with the response and any tool calls.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def extract_json(\n        self, \n        prompt: str, \n        schema: Dict[str, Any],\n        system_message: Optional[str] = None,\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None,\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Extract structured JSON data based on a prompt.\n        \n        Args:\n            prompt: The text prompt for extraction.\n            schema: JSON schema describing the expected structure.\n            system_message: Optional system message for models that support it.\n            temperature: Controls randomness in outputs. Overrides instance value if provided.\n            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.\n            **kwargs: Additional model-specific parameters.\n            \n        Returns:\n            The extracted JSON data.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def get_embedding(self, text: str, **kwargs) -> List[float]:\n        \"\"\"\n        Generate an embedding vector for the given text.\n        \n        Args:\n            text: The text to embed.\n            **kwargs: Additional model-specific parameters.\n            \n        Returns:\n            The embedding vector as a list of floats.\n        \"\"\"\n        pass\n    \n    def get_token_count(self, text: str) -> int:\n        \"\"\"\n        Estimate the number of tokens in the given text.\n        \n        Args:\n            text: The text to count tokens for.\n            \n        Returns:\n            The approximate token count.\n        \"\"\"\n        # Simple approximation: 1 token ≈ 4 characters\n        return len(text) // 4\n    \n    def get_model_details(self) -> Dict[str, Any]:\n        \"\"\"\n        Get details about the model.\n        \n        Returns:\n            A dictionary containing model information.\n        \"\"\"\n        return {\n            \"model_name\": self.model_name,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens,\n            \"config\": self.config\n        } "}
{"type": "source_file", "path": "anus/tools/base/tool_collection.py", "content": "\"\"\"\nTool Collection module for managing collections of tools.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional, Type, Union\nimport importlib\nimport inspect\nimport logging\nimport os\nimport pkgutil\n\nfrom anus.tools.base.tool import BaseTool\n\nclass ToolCollection:\n    \"\"\"\n    A collection of tools with registration and discovery capabilities.\n    \n    Provides functionality for:\n    - Registering tools\n    - Loading tools dynamically\n    - Tool discovery\n    - Tool execution\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"\n        Initialize a ToolCollection instance.\n        \"\"\"\n        self.tools: Dict[str, BaseTool] = {}\n        self.tool_classes: Dict[str, Type[BaseTool]] = {}\n    \n    def register_tool(self, tool: BaseTool) -> None:\n        \"\"\"\n        Register a tool instance.\n        \n        Args:\n            tool: The tool instance to register.\n        \"\"\"\n        self.tools[tool.name] = tool\n        logging.info(f\"Registered tool: {tool.name}\")\n    \n    def register_tool_class(self, tool_class: Type[BaseTool]) -> None:\n        \"\"\"\n        Register a tool class for later instantiation.\n        \n        Args:\n            tool_class: The tool class to register.\n        \"\"\"\n        name = getattr(tool_class, \"name\", tool_class.__name__.lower())\n        self.tool_classes[name] = tool_class\n        logging.info(f\"Registered tool class: {name}\")\n    \n    def get_tool(self, name: str) -> Optional[BaseTool]:\n        \"\"\"\n        Get a tool by name.\n        \n        Args:\n            name: The name of the tool.\n            \n        Returns:\n            The tool instance, or None if not found.\n        \"\"\"\n        # Check if the tool is already instantiated\n        if name in self.tools:\n            return self.tools[name]\n        \n        # Check if we have the tool class and can instantiate it\n        if name in self.tool_classes:\n            try:\n                tool = self.tool_classes[name]()\n                self.register_tool(tool)\n                return tool\n            except Exception as e:\n                logging.error(f\"Error instantiating tool {name}: {e}\")\n                return None\n        \n        # Tool not found\n        return None\n    \n    def execute_tool(self, name: str, **kwargs) -> Any:\n        \"\"\"\n        Execute a tool by name.\n        \n        Args:\n            name: The name of the tool to execute.\n            **kwargs: Input parameters for the tool.\n            \n        Returns:\n            The result of the tool execution, or an error message.\n        \"\"\"\n        tool = self.get_tool(name)\n        \n        if tool is None:\n            error_msg = f\"Tool not found: {name}\"\n            logging.error(error_msg)\n            return {\"status\": \"error\", \"error\": error_msg}\n        \n        try:\n            # Validate input\n            if not tool.validate_input(**kwargs):\n                error_msg = f\"Invalid input for tool {name}\"\n                logging.error(error_msg)\n                return {\"status\": \"error\", \"error\": error_msg}\n            \n            # Execute the tool\n            result = tool.execute(**kwargs)\n            return {\"status\": \"success\", \"result\": result}\n        except Exception as e:\n            error_msg = f\"Error executing tool {name}: {str(e)}\"\n            logging.error(error_msg)\n            return {\"status\": \"error\", \"error\": error_msg}\n    \n    def list_tools(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        List all available tools.\n        \n        Returns:\n            A list of tool information dictionaries.\n        \"\"\"\n        tool_info = []\n        \n        # Add instantiated tools\n        for name, tool in self.tools.items():\n            info = {\n                \"name\": name,\n                \"description\": getattr(tool, \"description\", \"No description available\"),\n                \"parameters\": getattr(tool, \"parameters\", {})\n            }\n            tool_info.append(info)\n        \n        # Add non-instantiated tool classes\n        for name, tool_class in self.tool_classes.items():\n            if name not in self.tools:\n                info = {\n                    \"name\": name,\n                    \"description\": getattr(tool_class, \"description\", \"No description available\"),\n                    \"parameters\": getattr(tool_class, \"parameters\", {})\n                }\n                tool_info.append(info)\n        \n        return tool_info\n    \n    def discover_tools(self, package_name: str = \"anus.tools\") -> int:\n        \"\"\"\n        Discover tools in the specified package.\n        \n        Args:\n            package_name: The package to search for tools.\n            \n        Returns:\n            The number of tools discovered.\n        \"\"\"\n        count = 0\n        \n        try:\n            package = importlib.import_module(package_name)\n            for _, name, is_pkg in pkgutil.iter_modules(package.__path__, package.__name__ + \".\"):\n                if is_pkg:\n                    # Recursively discover tools in subpackages\n                    count += self.discover_tools(name)\n                else:\n                    # Import the module\n                    try:\n                        module = importlib.import_module(name)\n                        \n                        # Find tool classes in the module\n                        for attr_name in dir(module):\n                            attr = getattr(module, attr_name)\n                            \n                            # Check if it's a tool class\n                            if (\n                                inspect.isclass(attr) and \n                                issubclass(attr, BaseTool) and \n                                attr != BaseTool\n                            ):\n                                self.register_tool_class(attr)\n                                count += 1\n                    except Exception as e:\n                        logging.error(f\"Error discovering tools in module {name}: {e}\")\n        except Exception as e:\n            logging.error(f\"Error discovering tools in package {package_name}: {e}\")\n        \n        return count "}
