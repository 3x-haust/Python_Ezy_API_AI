{"repo_info": {"repo_name": "crypto-hedge-fund", "repo_owner": "arhansuba", "repo_url": "https://github.com/arhansuba/crypto-hedge-fund"}}
{"type": "test_file", "path": "tests/test_agents.py", "content": "import unittest\nfrom unittest.mock import AsyncMock, patch\nimport sys\nimport os\n\n# Add the directory containing agents.py to the Python path\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n\nfrom src.agents import get_swap_instructions\n\nclass TestAgents(unittest.TestCase):\n    \n    @patch('agents.get_swap_instructions.ensure_session', new_callable=AsyncMock)\n    @patch('agents.get_swap_instructions.session.post', new_callable=AsyncMock)\n    async def test_get_swap_instructions_success(self, mock_post, mock_ensure_session):\n        # Arrange\n        mock_post.return_value.__aenter__.return_value.status = 200\n        mock_post.return_value.__aenter__.return_value.json = AsyncMock(return_value={\"data\": \"test\"})\n        \n        user_public_key = \"test_public_key\"\n        wrap_unwrap_sol = True\n        use_shared_accounts = False\n        quote_response = {\"quote\": \"test_quote\"}\n        compute_unit_price_micro_lamports = 1000\n        \n        # Act\n        result = await get_swap_instructions(user_public_key, wrap_unwrap_sol, use_shared_accounts, quote_response, compute_unit_price_micro_lamports)\n        \n        # Assert\n        self.assertEqual(result, {\"data\": \"test\"})\n        mock_ensure_session.assert_called_once()\n        mock_post.assert_called_once_with(\n            f\"{get_swap_instructions.base_url}/swap-instructions\",\n            json={\n                \"userPublicKey\": user_public_key,\n                \"wrapAndUnwrapSol\": wrap_unwrap_sol,\n                \"useSharedAccounts\": use_shared_accounts,\n                \"quoteResponse\": quote_response,\n                \"computeUnitPriceMicroLamports\": compute_unit_price_micro_lamports\n            }\n        )\n    \n    @patch('agents.get_swap_instructions.ensure_session', new_callable=AsyncMock)\n    @patch('agents.get_swap_instructions.session.post', new_callable=AsyncMock)\n    async def test_get_swap_instructions_error(self, mock_post, mock_ensure_session):\n        # Arrange\n        mock_post.return_value.__aenter__.return_value.status = 400\n        mock_post.return_value.__aenter__.return_value.text = AsyncMock(return_value=\"Error message\")\n        \n        user_public_key = \"test_public_key\"\n        wrap_unwrap_sol = True\n        use_shared_accounts = False\n        quote_response = {\"quote\": \"test_quote\"}\n        compute_unit_price_micro_lamports = 1000\n        \n        # Act\n        result = await get_swap_instructions(user_public_key, wrap_unwrap_sol, use_shared_accounts, quote_response, compute_unit_price_micro_lamports)\n        \n        # Assert\n        self.assertIsNone(result)\n        mock_ensure_session.assert_called_once()\n        mock_post.assert_called_once_with(\n            f\"{get_swap_instructions.base_url}/swap-instructions\",\n            json={\n                \"userPublicKey\": user_public_key,\n                \"wrapAndUnwrapSol\": wrap_unwrap_sol,\n                \"useSharedAccounts\": use_shared_accounts,\n                \"quoteResponse\": quote_response,\n                \"computeUnitPriceMicroLamports\": compute_unit_price_micro_lamports\n            }\n        )\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_jupiter_client.py", "content": "import pytest\nfrom aioresponses import aioresponses\nfrom src.executors.jupiter_client import JupiterClient, TOKEN_MINTS\n\n# Mock API responses\nMOCK_QUOTE_RESPONSE = {\n    \"inputMint\": TOKEN_MINTS['SOL'],\n    \"outputMint\": TOKEN_MINTS['USDC'],\n    \"inAmount\": \"1000000000\",  # 1 SOL\n    \"outAmount\": \"20000000\",   # 20 USDC\n    \"otherAmountThreshold\": \"19800000\",\n    \"swapMode\": \"ExactIn\",\n    \"slippageBps\": 50,\n    \"priceImpactPct\": \"0.1\",\n    \"routePlan\": []\n}\n\nMOCK_SWAP_RESPONSE = {\n    \"swapTransaction\": \"base64_encoded_transaction\",\n    \"lastValidBlockHeight\": 123456789\n}\n\nMOCK_INSTRUCTIONS_RESPONSE = {\n    \"instructions\": [\n        {\n            \"programId\": \"string\",\n            \"accounts\": [\"string\"],\n            \"data\": \"base64_string\"\n        }\n    ],\n    \"signers\": [\n        {\n            \"publicKey\": \"string\",\n            \"isSigner\": True\n        }\n    ],\n    \"address\": {\n        \"associatedTokenAddress\": \"string\"\n    }\n}\n\n@pytest.fixture\nasync def jupiter_client():\n    \"\"\"Create a JupiterClient instance for testing.\"\"\"\n    client = JupiterClient()\n    yield client\n    await client.close()\n\n@pytest.mark.asyncio\nasync def test_get_quote(jupiter_client):\n    \"\"\"Test getting a quote from Jupiter.\"\"\"\n    with aioresponses() as m:\n        # Mock the quote API endpoint\n        m.get(\n            f\"{jupiter_client.base_url}/quote?inputMint={TOKEN_MINTS['SOL']}&outputMint={TOKEN_MINTS['USDC']}&amount=1000000000&slippageBps=50&swapMode=ExactIn\",\n            payload=MOCK_QUOTE_RESPONSE\n        )\n\n        quote = await jupiter_client.get_quote(\n            input_mint=TOKEN_MINTS['SOL'],\n            output_mint=TOKEN_MINTS['USDC'],\n            amount=1000000000,\n            slippage_bps=50\n        )\n\n        assert quote is not None\n        assert quote['inputMint'] == TOKEN_MINTS['SOL']\n        assert quote['outputMint'] == TOKEN_MINTS['USDC']\n        assert quote['inAmount'] == \"1000000000\"\n        assert quote['outAmount'] == \"20000000\"\n\n@pytest.mark.asyncio\nasync def test_get_swap_transaction(jupiter_client):\n    \"\"\"Test getting swap transaction.\"\"\"\n    with aioresponses() as m:\n        # Mock the swap API endpoint\n        m.post(\n            f\"{jupiter_client.base_url}/swap\",\n            payload=MOCK_SWAP_RESPONSE\n        )\n\n        user_public_key = \"test_public_key\"\n        swap_tx = await jupiter_client.get_swap_transaction(\n            quote_response=MOCK_QUOTE_RESPONSE,\n            user_public_key=user_public_key\n        )\n\n        assert swap_tx is not None\n        assert swap_tx['swapTransaction'] == \"base64_encoded_transaction\"\n        assert swap_tx['lastValidBlockHeight'] == 123456789\n\n@pytest.mark.asyncio\nasync def test_get_swap_instructions(jupiter_client):\n    \"\"\"Test getting swap instructions.\"\"\"\n    with aioresponses() as m:\n        # Mock the swap-instructions API endpoint\n        m.post(\n            f\"{jupiter_client.base_url}/swap-instructions\",\n            payload=MOCK_INSTRUCTIONS_RESPONSE\n        )\n\n        user_public_key = \"test_public_key\"\n        instructions = await jupiter_client.get_swap_instructions(\n            quote_response=MOCK_QUOTE_RESPONSE,\n            user_public_key=user_public_key\n        )\n\n        assert instructions is not None\n        assert 'instructions' in instructions\n        assert 'signers' in instructions\n        assert 'address' in instructions\n\n@pytest.mark.asyncio\nasync def test_execute_swap(jupiter_client):\n    \"\"\"Test executing a complete swap.\"\"\"\n    with aioresponses() as m:\n        # Mock all required endpoints\n        m.get(\n            f\"{jupiter_client.base_url}/quote?inputMint={TOKEN_MINTS['SOL']}&outputMint={TOKEN_MINTS['USDC']}&amount=1000000000&slippageBps=50&swapMode=ExactIn\",\n            payload=MOCK_QUOTE_RESPONSE\n        )\n        m.post(\n            f\"{jupiter_client.base_url}/swap\",\n            payload=MOCK_SWAP_RESPONSE\n        )\n\n        result = await jupiter_client.execute_swap(\n            input_token='SOL',\n            output_token='USDC',\n            amount=\"1000000000\",\n            user_public_key=\"test_public_key\",\n            slippage_bps=50\n        )\n\n        assert result['success'] is True\n        assert result['input_token'] == 'SOL'\n        assert result['output_token'] == 'USDC'\n        assert result['amount_in'] == MOCK_QUOTE_RESPONSE['inAmount']\n        assert result['amount_out'] == MOCK_QUOTE_RESPONSE['outAmount']\n        assert result['tx_hash'] == MOCK_SWAP_RESPONSE['swapTransaction']\n\n@pytest.mark.asyncio\nasync def test_error_handling(jupiter_client):\n    \"\"\"Test error handling in the Jupiter client.\"\"\"\n    with aioresponses() as m:\n        # Mock failed quote request\n        m.get(\n            f\"{jupiter_client.base_url}/quote?inputMint={TOKEN_MINTS['SOL']}&outputMint={TOKEN_MINTS['USDC']}&amount=1000000000&slippageBps=50&swapMode=ExactIn\",\n            status=400,\n            body=\"Invalid request\"\n        )\n\n        quote = await jupiter_client.get_quote(\n            input_mint=TOKEN_MINTS['SOL'],\n            output_mint=TOKEN_MINTS['USDC'],\n            amount=1000000000,\n            slippage_bps=50\n        )\n\n        assert quote is None\n\n        # Test failed swap execution\n        result = await jupiter_client.execute_swap(\n            input_token='SOL',\n            output_token='USDC',\n            amount=\"1000000000\",\n            user_public_key=\"test_public_key\",\n            slippage_bps=50\n        )\n\n        assert result['success'] is False\n        assert 'error' in result\n\n@pytest.mark.asyncio\nasync def test_token_mint_resolution(jupiter_client):\n    \"\"\"Test token mint address resolution.\"\"\"\n    assert jupiter_client._get_token_mint('SOL') == TOKEN_MINTS['SOL']\n    assert jupiter_client._get_token_mint('USDC') == TOKEN_MINTS['USDC']\n    assert jupiter_client._get_token_mint('UNKNOWN') == 'UNKNOWN'\n\n@pytest.mark.asyncio\nasync def test_session_management(jupiter_client):\n    \"\"\"Test session management.\"\"\"\n    assert jupiter_client.session is None\n    \n    # Test session creation\n    await jupiter_client.ensure_session()\n    assert jupiter_client.session is not None\n    \n    # Test session reuse\n    original_session = jupiter_client.session\n    await jupiter_client.ensure_session()\n    assert jupiter_client.session is original_session\n    \n    # Test session closure\n    await jupiter_client.close()\n    assert jupiter_client.session is None"}
{"type": "source_file", "path": "src/config.py", "content": "# src/config.py\nimport os\nfrom typing import Dict, Optional\nfrom dataclasses import dataclass\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n@dataclass\nclass ChainConfig:\n    chain_id: str\n    name: str\n    rpc_url: str\n    native_token: str\n    block_time: float\n    explorer_url: str\n\n@dataclass\nclass LLMConfig:\n    provider: str\n    model: str\n    api_key: str\n    temperature: float = 0.7\n    max_tokens: int = 1000\n\n@dataclass\nclass TradingConfig:\n    max_position_size: float\n    risk_tolerance: float\n    min_confidence: float\n    slippage_tolerance: float = 0.01\n\n@dataclass\nclass GaiaNetConfig:\n    config_url: str\n\nclass Config:\n    # Chain configurations\n    CHAIN_CONFIGS = {\n        \"solana\": ChainConfig(\n            chain_id=\"solana\",\n            name=\"Solana\",\n            rpc_url=os.getenv(\"SOLANA_RPC_URL\", \"https://api.mainnet-beta.solana.com\"),\n            native_token=\"SOL\",\n            block_time=0.4,\n            explorer_url=\"https://solscan.io\"\n        ),\n        \"ethereum\": ChainConfig(\n            chain_id=\"ethereum\",\n            name=\"Ethereum\",\n            rpc_url=os.getenv(\"ETH_RPC_URL\", \"\"),\n            native_token=\"ETH\",\n            block_time=12,\n            explorer_url=\"https://etherscan.io\"\n        )\n    }\n\n    # LLM configurations\n    LLM_CONFIGS = {\n        \"openai\": LLMConfig(\n            provider=\"openai\",\n            model=\"gpt-4\",\n            api_key=os.getenv(\"OPENAI_API_KEY\", \"\")\n        ),\n        \"anthropic\": LLMConfig(\n            provider=\"anthropic\",\n            model=\"claude-3-opus-20240229\",\n            api_key=os.getenv(\"ANTHROPIC_API_KEY\", \"\")\n        ),\n        \"groq\": LLMConfig(\n            provider=\"groq\",\n            model=\"mixtral-8x7b-32768\",\n            api_key=os.getenv(\"GROQ_API_KEY\", \"\")\n        )\n    }\n\n    # DEX configurations by chain\n    DEX_CONFIGS = {\n        \"solana\": {\n            \"jupiter\": {\n                \"api_url\": \"https://quote-api.jup.ag/v6\",\n                \"api_key\": os.getenv(\"JUPITER_API_KEY\", \"\")\n            },\n            \"orca\": {\n                \"api_url\": \"https://api.orca.so\",\n            }\n        },\n        \"ethereum\": {\n            \"uniswap\": {\n                \"api_url\": \"https://api.uniswap.org/v2\",\n            },\n            \"sushiswap\": {\n                \"api_url\": \"https://api.sushi.com\",\n            }\n        }\n    }\n\n    # GaiaNet configuration\n    GAIANET_CONFIG = GaiaNetConfig(\n        config_url=\"https://raw.gaianet.ai/llama-3-8b-instruct/config.json\"\n    )\n\n    @staticmethod\n    def get_chain_config(chain_id: str) -> Optional[ChainConfig]:\n        return Config.CHAIN_CONFIGS.get(chain_id)\n\n    @staticmethod\n    def get_llm_config(provider: str) -> Optional[LLMConfig]:\n        return Config.LLM_CONFIGS.get(provider)\n\n    @staticmethod\n    def get_dex_config(chain_id: str, dex_name: str) -> Optional[Dict]:\n        chain_dexes = Config.DEX_CONFIGS.get(chain_id, {})\n        return chain_dexes.get(dex_name)\n\n    @staticmethod\n    def get_trading_config() -> TradingConfig:\n        return TradingConfig(\n            max_position_size=float(os.getenv(\"MAX_POSITION_SIZE\", \"10000\")),\n            risk_tolerance=float(os.getenv(\"RISK_TOLERANCE\", \"0.7\")),\n            min_confidence=float(os.getenv(\"MIN_CONFIDENCE\", \"0.7\"))\n        )\n\n    @staticmethod\n    def get_gaianet_config() -> GaiaNetConfig:\n        return Config.GAIANET_CONFIG"}
{"type": "source_file", "path": "src/agents.py", "content": "import sys\nimport os\nimport argparse\nimport asyncio\nfrom datetime import datetime, timedelta\nfrom typing import Annotated, Any, Dict, Sequence, TypedDict, List, Tuple\n\n# Add the src directory to the Python path\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n\nimport math\nimport operator\nfrom langchain_core.messages import BaseMessage, HumanMessage\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai.chat_models import ChatOpenAI\nfrom langgraph.graph import END, StateGraph\n\nfrom src.tools import calculate_bollinger_bands, calculate_intrinsic_value, calculate_macd, calculate_obv, calculate_rsi, search_line_items, get_financial_metrics, get_insider_trades, get_market_cap, get_prices, prices_to_df\n\nclass TradingAgent:\n    def __init__(self, capital: float, trading_pairs: List[str], risk_factor: float, dry_run: bool, interval: int, show_reasoning: bool):\n        self.capital = capital\n        self.trading_pairs = trading_pairs\n        self.risk_factor = risk_factor\n        self.dry_run = dry_run\n        self.interval = interval\n        self.show_reasoning = show_reasoning\n\n    async def run(self):\n        # Implement the trading logic here\n        pass\n\ndef parse_args() -> argparse.Namespace:\n    \"\"\"Parse command line arguments for the trading agent.\"\"\"\n    parser = argparse.ArgumentParser(description='Crypto Trading Agent')\n    \n    # Required arguments\n    parser.add_argument(\n        '--pairs', \n        nargs='+', \n        required=True,\n        help='Trading pairs to monitor (e.g., SOL BONK JUP)'\n    )\n    \n    parser.add_argument(\n        '--capital', \n        type=float, \n        required=True,\n        help='Initial capital in USDC'\n    )\n    \n    # Optional arguments\n    parser.add_argument(\n        '--risk', \n        type=float, \n        default=0.5,\n        help='Risk factor (0.0-1.0)'\n    )\n    \n    parser.add_argument(\n        '--interval', \n        type=int, \n        default=300,\n        help='Trading interval in seconds'\n    )\n    \n    parser.add_argument(\n        '--dry-run',\n        action='store_true',\n        help='Run in simulation mode without real trades'\n    )\n    \n    parser.add_argument(\n        '--show-reasoning',\n        action='store_true',\n        help='Show AI reasoning for trades'\n    )\n    \n    # Validate arguments\n    args = parser.parse_args()\n    validate_args(args)\n    \n    return args\n\ndef validate_args(args: argparse.Namespace):\n    \"\"\"Validate parsed arguments.\"\"\"\n    if args.capital <= 0:\n        raise ValueError(\"Capital must be positive\")\n        \n    if not 0 <= args.risk <= 1:\n        raise ValueError(\"Risk must be between 0 and 1\")\n        \n    if args.interval < 10:\n        raise ValueError(\"Interval must be at least 10 seconds\")\n        \n    for pair in args.pairs:\n        if pair not in ['SOL', 'BONK', 'JUP']:\n            raise ValueError(f\"Unsupported trading pair: {pair}\")\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    trading_agent = TradingAgent(\n        capital=args.capital,\n        trading_pairs=args.pairs,\n        risk_factor=args.risk,\n        dry_run=args.dry_run,\n        interval=args.interval,\n        show_reasoning=args.show_reasoning\n    )\n    asyncio.run(trading_agent.run())"}
{"type": "source_file", "path": "src/agents/base.py", "content": "# src/agents/base.py\nfrom typing import Dict, List, Optional\nfrom datetime import datetime\nimport logging\nfrom llm_client import GaiaLLM  # Ensure GaiaLLM is imported\n\nlogger = logging.getLogger(__name__)\n\nclass BaseAgent:\n    \"\"\"Base agent with core capabilities.\"\"\"\n    \n    def __init__(\n        self,\n        llm_config: Optional[Dict] = None,\n        memory_size: int = 1000,\n        objectives: List[str] = None\n    ):\n        \"\"\"Initialize base agent.\n        \n        Args:\n            llm_config: Configuration for LLM. If None, uses defaults.\n        \"\"\"\n        self.llm_config = llm_config or {}\n        self.llm = GaiaLLM()  # Initialize GaiaLLM without arguments\n        self.memory = MemoryState(size=memory_size)\n        self.objectives = objectives or []\n        self.last_thought = None\n        \n    async def think(self, context: Dict) -> Dict:\n        \"\"\"Core thinking process.\"\"\"\n        try:\n            # Format messages for LLM\n            messages = [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"\"\"You are an expert crypto trading AI assistant. \n                    Analyze market data and provide clear, actionable insights focused on:\n                    - Technical analysis\n                    - Risk assessment\n                    - Market sentiment\n                    - Trading opportunities\"\"\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Analyze the following market context and provide insights:\\n{context}\"\n                }\n            ]\n            \n            # Get LLM response\n            response = await self.llm.chat_completion(\n                messages=messages,\n                max_tokens=500,\n                temperature=0.7\n            )\n            \n            try:\n                thought = response[\"choices\"][0][\"message\"][\"content\"]\n                return {\n                    \"thought\": thought,\n                    \"timestamp\": datetime.now().isoformat()\n                }\n            except (KeyError, IndexError) as e:\n                logger.error(f\"Error parsing LLM response: {e}\")\n                return {\n                    \"error\": \"Failed to parse LLM response\",\n                    \"raw_response\": response,\n                    \"timestamp\": datetime.now().isoformat()\n                }\n                \n        except Exception as e:\n            logger.error(f\"Error in thinking process: {e}\")\n            return {\n                \"error\": str(e),\n                \"timestamp\": datetime.now().isoformat()\n            }\n            \n    async def close(self):\n        \"\"\"Cleanup resources.\"\"\"\n        if hasattr(self, 'llm'):\n            await self.llm.close()\n\n    async def learn(self, experience: Dict):\n        \"\"\"Learn from experience and update memory.\"\"\"\n        await self.memory.add({\n            'timestamp': datetime.now().isoformat(),\n            'type': 'experience',\n            'data': experience\n        })\n        \n        # Analyze experience for learning\n        analysis = await self.think({\n            'type': 'learning',\n            'experience': experience\n        })\n        \n        # Update objectives if needed\n        if analysis.get('update_objectives'):\n            self.objectives = self._update_objectives(analysis['update_objectives'])\n            \n    def _update_objectives(self, updates: List[str]) -> List[str]:\n        \"\"\"Update agent objectives based on learning.\"\"\"\n        current = set(self.objectives)\n        new = set(updates)\n        \n        # Keep important objectives, add new ones\n        return list(current.union(new))[:5]  # Keep top 5 objectives\n\nclass LLM:\n    \"\"\"Language Model interface for generating responses.\"\"\"\n    def __init__(self, model: str, api_key: str, temperature: float = 0.7):\n        self.model = model\n        self.api_key = api_key\n        self.temperature = temperature\n\n    async def generate(self, prompt: str, max_tokens: int = 500, temperature: float = 0.7) -> str:\n        # Simulate an API call to a language model\n        # Replace this with actual API call logic\n        return \"Simulated response based on the prompt.\"\n\nclass MemoryState:\n    \"\"\"Memory state management for the agent.\"\"\"\n    def __init__(self, size: int = 1000):\n        self.size = size\n        self.memory = []\n\n    async def add(self, entry: Dict):\n        \"\"\"Add a new entry to memory.\"\"\"\n        if len(self.memory) >= self.size:\n            self.memory.pop(0)  # Remove the oldest entry if memory is full\n        self.memory.append(entry)\n\n    def get_recent(self, n: int = 5) -> List[Dict]:\n        \"\"\"Get the most recent n entries from memory.\"\"\"\n        return self.memory[-n:]"}
{"type": "source_file", "path": "src/agents/__init__.py", "content": "# src/agents/__init__.py\nfrom .base import BaseAgent\nfrom .hedge_fund import HedgeFundAgent\nfrom .market_analyzer import MarketAnalyzer  # Ensure MarketAnalyzer is imported\n\n__all__ = [\n    \"BaseAgent\",\n    \"HedgeFundAgent\",\n    \"MarketAnalyzer\"  # Add MarketAnalyzer to __all__ if it needs to be publicly accessible\n]\n"}
{"type": "source_file", "path": "src/executors/jupiter_client.py", "content": "# src/executors/jupiter_client.py\nimport decimal\nimport aiohttp\nimport logging\nfrom typing import Dict, List, Optional, Union\nfrom decimal import Decimal\nfrom dataclasses import dataclass\n\nlogger = logging.getLogger(__name__)\n\nTOKEN_MINTS = {\n    'SOL': 'So11111111111111111111111111111111111111112',\n    'USDC': 'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v',\n    'BONK': 'DezXAZ8z7PnrnRJjz3wXBoRgixCa6xjnB7YaB1pPB263',\n    'JUP': 'JUPyiwrYJFskUPiHa9toL3DeNMzPARXD7wqBqkSwkcj'\n}\n\n@dataclass\nclass TokenMetrics:\n    \"\"\"Token metrics data class.\"\"\"\n    price: float\n    volume_24h: float\n    liquidity: float\n    holders: int\n    transactions_24h: int\n    error: Optional[str] = None\n\nclass TokenMetricsService:\n    \"\"\"Service for collecting token metrics.\"\"\"\n    \n    def __init__(self, jupiter_client):\n        \"\"\"Initialize with a JupiterClient instance.\"\"\"\n        self.jupiter = jupiter_client\n        self.default_quote_token = 'USDC'\n\n    async def get_token_metrics(self, token: str) -> TokenMetrics:\n        \"\"\"Get comprehensive metrics for a token.\"\"\"\n        try:\n            # Get price and derived metrics\n            price = await self.jupiter.get_price(token, self.default_quote_token)\n            if price is None:\n                raise Exception(\"Failed to get token price\")\n\n            # Get mock/default metrics for now\n            # TODO: Integrate with real data sources\n            metrics = TokenMetrics(\n                price=price,\n                volume_24h=0.0,  # Replace with real volume data\n                liquidity=0.0,   # Replace with real liquidity data\n                holders=0,       # Replace with real holder count\n                transactions_24h=0  # Replace with real transaction count\n            )\n            \n            return metrics\n\n        except Exception as e:\n            return TokenMetrics(\n                price=0.0,\n                volume_24h=0.0,\n                liquidity=0.0,\n                holders=0,\n                transactions_24h=0,\n                error=str(e)\n            )\n\n    async def get_multiple_token_metrics(\n        self, \n        tokens: List[str]\n    ) -> Dict[str, TokenMetrics]:\n        \"\"\"Get metrics for multiple tokens.\"\"\"\n        metrics = {}\n        for token in tokens:\n            metrics[token] = await self.get_token_metrics(token)\n        return metrics\n\nclass JupiterClient:\n    \"\"\"Jupiter Protocol API client.\"\"\"\n    \n    def __init__(self, use_mock: bool = True):\n        \"\"\"Initialize Jupiter client.\"\"\"\n        self.base_url = \"https://quote-api.jup.ag/v6\"\n        self.session = None\n        self.use_mock = use_mock\n\n    async def ensure_session(self):\n        \"\"\"Initialize aiohttp session.\"\"\"\n        if not self.session:\n            self.session = aiohttp.ClientSession(\n                headers={\n                    'Content-Type': 'application/json',\n                    'Accept': 'application/json'\n                }\n            )\n\n    async def close(self):\n        \"\"\"Close the session.\"\"\"\n        if self.session:\n            await self.session.close()\n            self.session = None\n\n    def _get_token_mint(self, token: str) -> str:\n        \"\"\"Get token mint address.\"\"\"\n        return TOKEN_MINTS.get(token.upper(), token)\n\n    async def get_quote(\n        self,\n        input_token: str,\n        output_token: str,\n        amount: Union[int, float, str],\n        slippage_bps: int = 50,\n        exact_out: bool = False\n    ) -> Optional[Dict]:\n        \"\"\"Get quote from Jupiter.\"\"\"\n        try:\n            await self.ensure_session()\n            \n            params = {\n                \"inputMint\": self._get_token_mint(input_token),\n                \"outputMint\": self._get_token_mint(output_token),\n                \"amount\": str(amount),\n                \"slippageBps\": slippage_bps,\n                \"swapMode\": \"ExactOut\" if exact_out else \"ExactIn\"\n            }\n            \n            async with self.session.get(f\"{self.base_url}/quote\", params=params) as response:\n                if response.status == 200:\n                    return await response.json()\n                else:\n                    error_text = await response.text()\n                    logger.error(f\"Quote error: {response.status} - {error_text}\")\n                    return None\n                    \n        except Exception as e:\n            logger.error(f\"Error getting quote: {e}\")\n            return None\n\n    async def get_swap_tx(\n        self,\n        quote_response: Dict,\n        user_public_key: str,\n        options: Optional[Dict] = None\n    ) -> Optional[Dict]:\n        \"\"\"Get swap transaction from Jupiter.\"\"\"\n        try:\n            await self.ensure_session()\n            \n            payload = {\n                \"quoteResponse\": quote_response,\n                \"userPublicKey\": user_public_key,\n                \"wrapAndUnwrapSol\": True,\n                \"useSharedAccounts\": True,\n                \"dynamicComputeUnitLimit\": True,\n                \"skipUserAccountsRpcCalls\": True,\n                \"prioritizationFeeLamports\": \"auto\"\n            }\n            \n            if options:\n                payload.update(options)\n            \n            async with self.session.post(f\"{self.base_url}/swap\", json=payload) as response:\n                if response.status == 200:\n                    return await response.json()\n                else:\n                    error_text = await response.text()\n                    logger.error(f\"Swap error: {response.status} - {error_text}\")\n                    return None\n                    \n        except Exception as e:\n            logger.error(f\"Error getting swap tx: {e}\")\n            return None\n\n    async def get_swap_instructions(\n        self,\n        quote_response: Dict,\n        user_public_key: str,\n        options: Optional[Dict] = None\n    ) -> Optional[Dict]:\n        \"\"\"Get swap instructions from Jupiter.\"\"\"\n        try:\n            await self.ensure_session()\n            \n            payload = {\n                \"quoteResponse\": quote_response,\n                \"userPublicKey\": user_public_key,\n                \"computeUnitPriceMicroLamports\": \"auto\",\n                \"dynamicComputeUnitLimit\": True\n            }\n            \n            if options:\n                payload.update(options)\n            \n            async with self.session.post(f\"{self.base_url}/swap-instructions\", json=payload) as response:\n                if response.status == 200:\n                    return await response.json()\n                else:\n                    error_text = await response.text()\n                    logger.error(f\"Instructions error: {response.status} - {error_text}\")\n                    return None\n                    \n        except Exception as e:\n            logger.error(f\"Error getting instructions: {e}\")\n            return None\n\n    async def execute_swap(\n        self,\n        input_token: str,\n        output_token: str,\n        amount: Union[int, float, str],\n        user_public_key: str,\n        slippage_bps: int = 50,\n        exact_out: bool = False\n    ) -> Dict:\n        \"\"\"Execute a swap through Jupiter.\"\"\"\n        try:\n            # Get quote\n            quote = await self.get_quote(\n                input_token=input_token,\n                output_token=output_token,\n                amount=amount,\n                slippage_bps=slippage_bps,\n                exact_out=exact_out\n            )\n            \n            if not quote:\n                raise Exception(\"Failed to get quote\")\n                \n            # Get swap transaction\n            swap_tx = await self.get_swap_tx(\n                quote_response=quote,\n                user_public_key=user_public_key,\n                options={\n                    \"dynamicSlippage\": {\n                        \"minBps\": max(10, slippage_bps // 2),\n                        \"maxBps\": slippage_bps\n                    }\n                }\n            )\n            \n            if not swap_tx:\n                raise Exception(\"Failed to get swap transaction\")\n                \n            return {\n                'success': True,\n                'input_token': input_token,\n                'output_token': output_token,\n                'amount_in': quote.get('inAmount'),\n                'amount_out': quote.get('outAmount'),\n                'price_impact': quote.get('priceImpactPct'),\n                'slippage': slippage_bps / 10000,  # Convert to decimal\n                'transaction': swap_tx\n            }\n            \n        except Exception as e:\n            logger.error(f\"Swap execution failed: {e}\")\n            return {\n                'success': False,\n                'error': str(e),\n                'input_token': input_token,\n                'output_token': output_token,\n                'amount': amount\n            }\n\n    async def get_price(\n        self,\n        token: str,\n        quote_token: str = 'USDC',\n        amount: str = \"1000000\"  # 1 USDC with 6 decimals\n    ) -> Optional[float]:\n        \"\"\"Get token price in terms of quote token.\"\"\"\n        try:\n            if self.use_mock:\n                # Return mock data for testing\n                mock_prices = {\n                    'SOL': 90.0,\n                    'BONK': 0.000012,\n                    'JUP': 1.20\n                }\n                return mock_prices.get(token.upper(), 0.0)\n\n            # Get quote for exact amount of quote token\n            quote = await self.get_quote(\n                input_token=quote_token,\n                output_token=token,\n                amount=amount,\n                slippage_bps=50\n            )\n            \n            if not quote:\n                logger.error(f\"Failed to get price quote for {token}\")\n                return None\n                \n            # Calculate price from quote\n            try:\n                in_amount = Decimal(quote['inAmount'])\n                out_amount = Decimal(quote['outAmount'])\n                \n                # Adjust for token decimals\n                in_decimals = 6 if quote_token == 'USDC' else 9\n                out_decimals = 9 if token == 'SOL' else 6\n                \n                price = float(in_amount / Decimal(10 ** in_decimals) / \n                            (out_amount / Decimal(10 ** out_decimals)))\n                \n                return price\n                \n            except (KeyError, ValueError, decimal.InvalidOperation) as e:\n                logger.error(f\"Error calculating price from quote: {e}\")\n                return None\n                \n        except Exception as e:\n            logger.error(f\"Error getting price for {token}: {e}\")\n            return None\n            \n    async def get_prices(\n        self,\n        tokens: List[str],\n        quote_token: str = 'USDC'\n    ) -> Dict[str, Optional[float]]:\n        \"\"\"Get prices for multiple tokens.\"\"\"\n        prices = {}\n        for token in tokens:\n            price = await self.get_price(token, quote_token)\n            prices[token] = price\n        return prices\n\n    async def get_token_volume(\n        self,\n        token: str,\n        quote_token: str = 'USDC'\n    ) -> Optional[float]:\n        \"\"\"Get 24h trading volume for token.\"\"\"\n        # TODO: Implement real volume fetching\n        if self.use_mock:\n            mock_volumes = {\n                'SOL': 150000000.0,\n                'BONK': 25000000.0,\n                'JUP': 5000000.0\n            }\n            return mock_volumes.get(token.upper(), 0.0)\n        return 0.0\n\n    async def get_token_liquidity(\n        self,\n        token: str,\n        quote_token: str = 'USDC'\n    ) -> Optional[float]:\n        \"\"\"Get total liquidity for token.\"\"\"\n        # TODO: Implement real liquidity fetching\n        if self.use_mock:\n            mock_liquidity = {\n                'SOL': 500000000.0,\n                'BONK': 50000000.0,\n                'JUP': 10000000.0\n            }\n            return mock_liquidity.get(token.upper(), 0.0)\n        return 0.0\n\n    async def get_market_depth(\n        self,\n        input_token: str,\n        output_token: str = \"USDC\",\n        test_sizes: list = [1000, 10000, 100000, 1000000]  # USDC amounts\n    ) -> Dict:\n        \"\"\"Get market depth by testing different trade sizes.\n        \n        Args:\n            input_token: Token to get depth for (e.g., 'SOL', 'BONK')\n            output_token: Quote token (defaults to USDC)\n            test_sizes: List of amounts to test for depth\n            \n        Returns:\n            Dictionary containing price and price impact for each test size\n        \"\"\"\n        depth_data = {}\n        \n        for size in test_sizes:\n            try:\n                # Convert size to USDC decimals (6)\n                size_in_decimals = str(int(size * 1_000_000))\n                \n                quote = await self.get_quote(\n                    input_token=input_token,\n                    output_token=output_token,\n                    amount=size_in_decimals\n                )\n                \n                if quote:\n                    # Calculate effective price and impact\n                    try:\n                        in_amount = Decimal(quote['inAmount'])\n                        out_amount = Decimal(quote['outAmount'])\n                        \n                        # Adjust for decimals\n                        in_decimals = 6 if input_token == 'USDC' else 9\n                        out_decimals = 6 if output_token == 'USDC' else 9\n                        \n                        effective_price = float(\n                            (in_amount / Decimal(10 ** in_decimals)) /\n                            (out_amount / Decimal(10 ** out_decimals))\n                        )\n                        \n                        depth_data[size] = {\n                            'price': effective_price,\n                            'price_impact': float(quote.get('priceImpactPct', 0)),\n                            'in_amount': str(in_amount),\n                            'out_amount': str(out_amount)\n                        }\n                    except (decimal.InvalidOperation, KeyError) as e:\n                        logger.error(f\"Error calculating metrics for size {size}: {e}\")\n                        continue\n                        \n            except Exception as e:\n                logger.error(f\"Error getting depth for size {size}: {e}\")\n                continue\n                \n        return depth_data\n\n    async def get_token_metrics(\n        self,\n        token: str,\n        quote_token: str = 'USDC'\n    ) -> TokenMetrics:\n        \"\"\"Get comprehensive token metrics including price, volume, and liquidity.\"\"\"\n        try:\n            # Get price\n            price = await self.get_price(token, quote_token)\n            if price is None:\n                raise Exception(\"Failed to get token price\")\n                \n            # Get market depth metrics\n            depth = await self.get_market_depth(token, quote_token)\n            \n            # Calculate volume and liquidity from depth data\n            total_volume = 0.0\n            total_liquidity = 0.0\n            \n            if depth:\n                # Use largest test size for liquidity estimate\n                max_size = max(depth.keys())\n                if max_size in depth:\n                    max_depth = depth[max_size]\n                    # Rough liquidity estimate based on max tested size\n                    total_liquidity = float(max_depth['in_amount']) / 1_000_000  # Convert from USDC decimals\n                    \n                # Calculate approximate 24h volume (mock for now)\n                total_volume = total_liquidity * 0.3  # Assume 30% daily turnover\n            \n            return TokenMetrics(\n                price=price,\n                volume_24h=total_volume,\n                liquidity=total_liquidity,\n                holders=0,  # Would need additional data source\n                transactions_24h=0,  # Would need additional data source\n                error=None\n            )\n            \n        except Exception as e:\n            logger.error(f\"Error getting token metrics: {e}\")\n            return TokenMetrics(\n                price=0.0,\n                volume_24h=0.0,\n                liquidity=0.0,\n                holders=0,\n                transactions_24h=0,\n                error=str(e)\n            )"}
{"type": "source_file", "path": "src/executors/jupiter.py", "content": "# src/executors/jupiter.py\nimport asyncio\nimport aiohttp\nimport logging\nfrom typing import Dict, Optional, Union\nfrom decimal import Decimal\nimport json\n\nlogger = logging.getLogger(__name__)\n\nclass JupiterExecutor:\n    \"\"\"Jupiter Protocol trade execution handler.\"\"\"\n    \n    def __init__(self, config: Optional[Dict] = None):\n        self.config = config or {}\n        self.base_url = \"https://quote-api.jup.ag/v6\"\n        self.session = None\n        self.slippage_bps = self.config.get('slippage_bps', 50)  # 0.5%\n        self.max_retries = self.config.get('max_retries', 3)\n        \n    async def ensure_session(self):\n        \"\"\"Ensure aiohttp session is initialized.\"\"\"\n        if not self.session:\n            self.session = aiohttp.ClientSession()\n\n    async def close(self):\n        \"\"\"Close the session.\"\"\"\n        if self.session:\n            await self.session.close()\n            self.session = None\n\n    async def execute_trade(\n        self,\n        input_token: str,\n        output_token: str,\n        amount: Union[int, float, str],\n        user_public_key: str,\n        exact_out: bool = False\n    ) -> Dict:\n        \"\"\"Execute a trade through Jupiter.\"\"\"\n        try:\n            await self.ensure_session()\n            \n            # Get quote\n            quote = await self.get_quote(\n                input_token=input_token,\n                output_token=output_token,\n                amount=str(amount),\n                slippage_bps=self.slippage_bps,\n                exact_out=exact_out\n            )\n            \n            if not quote:\n                raise Exception(\"Failed to get quote\")\n                \n            # Get swap transaction\n            swap_tx = await self.get_swap_transaction(\n                quote_response=quote,\n                user_public_key=user_public_key\n            )\n            \n            if not swap_tx:\n                raise Exception(\"Failed to get swap transaction\")\n                \n            # Execute swap\n            result = await self.execute_swap(swap_tx)\n            \n            return {\n                'success': True,\n                'input_token': input_token,\n                'output_token': output_token,\n                'amount_in': amount,\n                'amount_out': quote['outAmount'],\n                'price_impact': quote.get('priceImpactPct', '0'),\n                'tx_hash': result.get('txid'),\n                'executed_price': Decimal(quote['outAmount']) / Decimal(amount)\n            }\n            \n        except Exception as e:\n            logger.error(f\"Trade execution failed: {e}\")\n            return {\n                'success': False,\n                'error': str(e),\n                'input_token': input_token,\n                'output_token': output_token,\n                'amount_in': amount\n            }\n\n    async def get_quote(\n        self,\n        input_token: str,\n        output_token: str,\n        amount: str,\n        slippage_bps: int = 50,\n        exact_out: bool = False\n    ) -> Optional[Dict]:\n        \"\"\"Get quote from Jupiter.\"\"\"\n        try:\n            params = {\n                'inputMint': input_token,\n                'outputMint': output_token,\n                'amount': amount,\n                'slippageBps': slippage_bps,\n                'swapMode': 'ExactOut' if exact_out else 'ExactIn'\n            }\n            \n            async with self.session.get(f\"{self.base_url}/quote\", params=params) as response:\n                if response.status == 200:\n                    return await response.json()\n                else:\n                    error_text = await response.text()\n                    logger.error(f\"Quote error: {error_text}\")\n                    return None\n                    \n        except Exception as e:\n            logger.error(f\"Error getting quote: {e}\")\n            return None\n\n    async def get_swap_transaction(\n        self,\n        quote_response: Dict,\n        user_public_key: str\n    ) -> Optional[Dict]:\n        \"\"\"Get swap transaction from Jupiter.\"\"\"\n        try:\n            payload = {\n                'quoteResponse': quote_response,\n                'userPublicKey': user_public_key,\n                'wrapUnwrapSOL': True,\n                'useSharedAccounts': True,\n                'dynamicComputeUnitLimit': True,\n                'prioritizationFeeLamports': 'auto'\n            }\n            \n            async with self.session.post(\n                f\"{self.base_url}/swap\",\n                json=payload\n            ) as response:\n                if response.status == 200:\n                    return await response.json()\n                else:\n                    error_text = await response.text()\n                    logger.error(f\"Swap transaction error: {error_text}\")\n                    return None\n                    \n        except Exception as e:\n            logger.error(f\"Error getting swap transaction: {e}\")\n            return None\n\n    async def execute_swap(self, swap_tx: Dict) -> Dict:\n        \"\"\"Execute swap transaction with retry logic.\"\"\"\n        for attempt in range(self.max_retries):\n            try:\n                # Simulate execution (replace with actual blockchain submission)\n                tx_hash = \"simulated_tx_hash\"  # Replace with actual submission\n                \n                return {\n                    'success': True,\n                    'txid': tx_hash,\n                    'attempt': attempt + 1\n                }\n                \n            except Exception as e:\n                if attempt == self.max_retries - 1:\n                    logger.error(f\"Max retries reached for swap execution: {e}\")\n                    raise\n                    \n                wait_time = 2 ** attempt  # Exponential backoff\n                logger.warning(f\"Retry {attempt + 1}/{self.max_retries} in {wait_time}s\")\n                await asyncio.sleep(wait_time)\n\n    async def check_transaction_status(self, tx_hash: str) -> Dict:\n        \"\"\"Check status of a submitted transaction.\"\"\"\n        try:\n            # Replace with actual transaction status check\n            return {\n                'status': 'confirmed',\n                'confirmations': 32,\n                'slot': 123456789\n            }\n        except Exception as e:\n            logger.error(f\"Error checking transaction status: {e}\")\n            return {\n                'status': 'unknown',\n                'error': str(e)\n            }\n\n    async def simulate_swap(\n        self,\n        input_token: str,\n        output_token: str,\n        amount: str,\n        user_public_key: str\n    ) -> Dict:\n        \"\"\"Simulate swap to estimate costs and outcomes.\"\"\"\n        try:\n            # Get quote first\n            quote = await self.get_quote(\n                input_token=input_token,\n                output_token=output_token,\n                amount=amount\n            )\n            \n            if not quote:\n                raise Exception(\"Failed to get quote for simulation\")\n                \n            # Get swap transaction\n            swap_tx = await self.get_swap_transaction(\n                quote_response=quote,\n                user_public_key=user_public_key\n            )\n            \n            if not swap_tx:\n                raise Exception(\"Failed to get swap transaction for simulation\")\n                \n            return {\n                'success': True,\n                'input_amount': amount,\n                'output_amount': quote['outAmount'],\n                'price_impact': quote.get('priceImpactPct', '0'),\n                'minimum_output': quote.get('otherAmountThreshold', '0'),\n                'estimated_fees': {\n                    'network': swap_tx.get('prioritizationFeeLamports', 0),\n                    'platform': quote.get('platformFee', {'amount': '0'})['amount']\n                }\n            }\n            \n        except Exception as e:\n            logger.error(f\"Simulation failed: {e}\")\n            return {\n                'success': False,\n                'error': str(e)\n            }\n\n    def _validate_amounts(\n        self,\n        amount_in: Union[int, float, str],\n        min_amount: Union[int, float, str]\n    ) -> bool:\n        \"\"\"Validate trade amounts.\"\"\"\n        try:\n            amount_in_dec = Decimal(str(amount_in))\n            min_amount_dec = Decimal(str(min_amount))\n            \n            if amount_in_dec <= 0 or min_amount_dec <= 0:\n                return False\n                \n            if min_amount_dec > amount_in_dec:\n                return False\n                \n            return True\n            \n        except Exception:\n            return False"}
{"type": "source_file", "path": "src/llm_client.py", "content": "# src/llm_client.py\nimport aiohttp\nimport logging\nfrom typing import Dict, List, Optional, Any\nimport json\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nclass GaiaLLM:\n    \"\"\"GaiaNet LLM client for Llama 3.\"\"\"\n    \n    def __init__(self):\n        self.api_base = \"https://0xe7d21e1bd35163c0bcdc6d5ea8c23f3c277f2d17.us.gaianet.network/v1\"\n        self.session = None\n        self.retry_attempts = 3\n        self.default_system_message = \"\"\"You are an expert crypto trading AI assistant. \n        Analyze market data and provide clear, actionable insights. Focus on:\n        - Technical analysis\n        - Risk assessment\n        - Market sentiment\n        - Trading opportunities\"\"\"\n\n    async def ensure_session(self):\n        \"\"\"Initialize aiohttp session with proper headers.\"\"\"\n        if not self.session:\n            self.session = aiohttp.ClientSession(headers={\n                \"accept\": \"application/json\",\n                \"Content-Type\": \"application/json\"\n            })\n\n    async def close(self):\n        \"\"\"Close the session.\"\"\"\n        if self.session:\n            await self.session.close()\n            self.session = None\n\n    async def chat_completion(\n        self,\n        messages: List[Dict[str, str]],\n        max_tokens: int = 1000,\n        temperature: float = 0.7,\n    ) -> Dict[str, Any]:\n        \"\"\"Send a chat completion request to GaiaNet node.\"\"\"\n        try:\n            await self.ensure_session()\n            \n            # Ensure system message is present\n            if not any(msg.get('role') == 'system' for msg in messages):\n                messages.insert(0, {\n                    \"role\": \"system\",\n                    \"content\": self.default_system_message\n                })\n            \n            payload = {\n                \"messages\": messages,\n                \"max_tokens\": max_tokens,\n                \"temperature\": temperature,\n                \"model\": \"Meta-Llama-3-8B-Instruct-Q5_K_M\"\n            }\n            \n            url = f\"{self.api_base}/chat/completions\"\n            \n            for attempt in range(self.retry_attempts):\n                try:\n                    async with self.session.post(url, json=payload) as response:\n                        if response.status == 200:\n                            return await response.json()\n                        elif response.status == 404:\n                            # Fallback to simple completion if chat endpoint fails\n                            return await self._fallback_completion(messages)\n                        else:\n                            error_text = await response.text()\n                            logger.error(f\"API error: {response.status} - {error_text}\")\n                            \n                            if attempt == self.retry_attempts - 1:\n                                raise Exception(f\"API error: {response.status}\")\n                                \n                except aiohttp.ClientError as e:\n                    if attempt == self.retry_attempts - 1:\n                        raise\n                    logger.warning(f\"Attempt {attempt + 1} failed: {e}\")\n                    \n            raise Exception(\"Max retries exceeded\")\n\n        except Exception as e:\n            logger.error(f\"Chat completion error: {e}\")\n            raise\n\n    async def _fallback_completion(\n        self,\n        messages: List[Dict[str, str]]\n    ) -> Dict[str, Any]:\n        \"\"\"Fallback to basic completion if chat fails.\"\"\"\n        try:\n            # Combine messages into a single prompt\n            prompt = \"\\n\".join(msg['content'] for msg in messages)\n            \n            url = f\"{self.api_base}/completions\"\n            \n            payload = {\n                \"prompt\": prompt,\n                \"max_tokens\": 1000,\n                \"temperature\": 0.7,\n                \"model\": \"Meta-Llama-3-8B-Instruct-Q5_K_M\"\n            }\n            \n            async with self.session.post(url, json=payload) as response:\n                if response.status == 200:\n                    completion = await response.json()\n                    # Convert to chat format\n                    return {\n                        \"choices\": [{\n                            \"message\": {\n                                \"role\": \"assistant\",\n                                \"content\": completion['choices'][0]['text']\n                            }\n                        }]\n                    }\n                else:\n                    error_text = await response.text()\n                    logger.error(f\"Fallback completion error: {response.status} - {error_text}\")\n                    raise Exception(f\"Fallback completion failed: {response.status}\")\n\n        except Exception as e:\n            logger.error(f\"Fallback completion error: {e}\")\n            raise\n            \n    def _validate_messages(self, messages: List[Dict[str, str]]) -> bool:\n        \"\"\"Validate message format.\"\"\"\n        if not messages:\n            return False\n            \n        required_keys = {'role', 'content'}\n        valid_roles = {'system', 'user', 'assistant'}\n        \n        for msg in messages:\n            if not isinstance(msg, dict):\n                return False\n            if not all(key in msg for key in required_keys):\n                return False\n            if msg['role'] not in valid_roles:\n                return False\n            if not isinstance(msg['content'], str):\n                return False\n                \n        return True"}
{"type": "source_file", "path": "src/agents/hedge_fund.py", "content": "# src/agents/hedge_fund.py\nimport logging\nfrom typing import Dict, List, Optional\nfrom datetime import datetime\n\nfrom .base import BaseAgent\nfrom tools import CryptoDataTools\nfrom executors.jupiter_client import JupiterClient\n\nlogger = logging.getLogger(__name__)\n\nDEFAULT_MARKET_DATA = {\n    'price': 0.0,\n    'volume': 0.0,\n    'liquidity': 0.0,\n    'holders': 0,\n    'transactions': 0,\n    'error': 'Using default data due to API error'\n}\n\nclass HedgeFundAgent(BaseAgent):\n    \"\"\"Autonomous hedge fund agent.\"\"\"\n    \n    def __init__(\n        self,\n        initial_capital: float,\n        trading_pairs: List[str],\n        risk_tolerance: float = 0.7,\n        llm_config: Optional[Dict] = None\n    ):\n        super().__init__(llm_config)\n        self.initial_capital = initial_capital\n        self.trading_pairs = trading_pairs\n        self.risk_tolerance = risk_tolerance\n        \n        # Initialize components\n        self.data_tools = CryptoDataTools()\n        self.jupiter = JupiterClient()\n        \n        # Portfolio state\n        self.portfolio = {\n            'cash': initial_capital,\n            'positions': {},\n            'total_value': initial_capital\n        }\n        \n    async def analyze_market(self, tokens: List[str]) -> Dict:\n        \"\"\"Analyze market conditions for given tokens.\"\"\"\n        market_data = {}\n        \n        # Process each token individually\n        for token in tokens:\n            try:\n                # Get market data\n                metrics = await self.data_tools.get_token_metrics(token)\n                \n                market_data[token] = {\n                    'price': metrics.price if hasattr(metrics, 'price') else 0.0,\n                    'volume': metrics.volume if hasattr(metrics, 'volume') else 0.0,\n                    'liquidity': metrics.liquidity if hasattr(metrics, 'liquidity') else 0.0,\n                    'holders': metrics.holders if hasattr(metrics, 'holders') else 0,\n                    'transactions': metrics.transactions if hasattr(metrics, 'transactions') else 0\n                }\n            except Exception as e:\n                logger.error(f\"Error getting metrics for {token}: {e}\")\n                market_data[token] = DEFAULT_MARKET_DATA.copy()\n        \n        # Generate thought about market conditions\n        analysis = await self.think({\n            'type': 'market_analysis',\n            'data': market_data,\n            'portfolio': self.portfolio,\n            'timestamp': datetime.now().isoformat()\n        })\n\n        result = {\n            'market_data': market_data,\n            'analysis': analysis.get('thought', ''),\n            'timestamp': datetime.now().isoformat(),\n            'trades': []  # Initialize empty trades list\n        }\n\n        # Try to generate trades from analysis\n        try:\n            trades = await self.generate_trades_from_analysis(result)\n            result['trades'] = trades\n        except Exception as e:\n            logger.error(f\"Error generating trades: {e}\")\n            result['trades'] = []\n\n        return result\n\n    async def generate_trades_from_analysis(self, analysis: Dict) -> List[Dict]:\n        \"\"\"Generate trades based on market analysis.\"\"\"\n        trades = []\n        \n        for token, data in analysis['market_data'].items():\n            if data.get('error'):\n                continue  # Skip tokens with errors\n\n            # Default conservative position size (1% of portfolio)\n            position_size = self.portfolio['total_value'] * 0.01\n                \n            # Simple trading logic if LLM is not available\n            if data['price'] > 0:\n                price_24h_change = data.get('price_change_24h', 0)\n                \n                if price_24h_change > 5:  # 5% up\n                    trades.append({\n                        'token': token,\n                        'action': 'sell',\n                        'amount': position_size,\n                        'confidence': 0.6,\n                        'reasoning': f\"Price up {price_24h_change}% in 24h\"\n                    })\n                elif price_24h_change < -5:  # 5% down\n                    trades.append({\n                        'token': token,\n                        'action': 'buy',\n                        'amount': position_size,\n                        'confidence': 0.6,\n                        'reasoning': f\"Price down {price_24h_change}% in 24h\"\n                    })\n                    \n        return trades\n\n    async def generate_trades(self, analysis: Dict) -> List[Dict]:\n        \"\"\"Generate trading decisions based on analysis.\"\"\"\n        trades = []\n        \n        for token in self.trading_pairs:\n            token_data = analysis['market_data'].get(token, {})\n            if 'error' not in token_data:\n                # Get trade decision\n                decision = await self.think({\n                    'type': 'trade_decision',\n                    'token': token,\n                    'data': token_data,\n                    'analysis': analysis['analysis'],\n                    'portfolio': self.portfolio\n                })\n                \n                if decision.get('action') in ['buy', 'sell']:\n                    trades.append({\n                        'token': token,\n                        'action': decision['action'],\n                        'amount': self.calculate_trade_size(\n                            token,\n                            decision.get('confidence', 0.5),\n                            token_data\n                        ),\n                        'confidence': decision.get('confidence', 0.5),\n                        'reasoning': decision.get('reasoning', '')\n                    })\n        \n        return trades\n        \n    def calculate_trade_size(\n        self,\n        token: str,\n        confidence: float,\n        market_data: Dict\n    ) -> float:\n        \"\"\"Calculate trade size based on multiple factors.\"\"\"\n        # Base position size (% of portfolio)\n        max_position = self.portfolio['total_value'] * 0.2  # 20% max position\n        \n        # Scale by confidence\n        position_size = max_position * confidence\n        \n        # Scale by liquidity\n        liquidity = market_data.get('liquidity', 0)\n        if liquidity > 0:\n            # Limit to 10% of available liquidity\n            position_size = min(position_size, liquidity * 0.1)\n        \n        # Ensure we have enough cash for buys\n        if position_size > self.portfolio['cash']:\n            position_size = self.portfolio['cash']\n        \n        return position_size\n        \n    async def execute_trades(self, trades: List[Dict]) -> Dict:\n        \"\"\"Execute validated trades.\"\"\"\n        results = {}\n        \n        for trade in trades:\n            try:\n                # Execute trade through Jupiter\n                result = await self.jupiter.execute_trade(\n                    input_token=trade['token'],\n                    output_token='USDC',\n                    amount=trade['amount'],\n                    exact_out=trade['action'] == 'sell'\n                )\n                \n                if result['success']:\n                    # Update portfolio\n                    self.update_portfolio(trade, result)\n                    \n                results[trade['token']] = result\n                \n            except Exception as e:\n                logger.error(f\"Trade execution error: {e}\")\n                results[trade['token']] = {\n                    'success': False,\n                    'error': str(e)\n                }\n                \n        return results\n        \n    def update_portfolio(self, trade: Dict, result: Dict):\n        \"\"\"Update portfolio after successful trade.\"\"\"\n        token = trade['token']\n        amount = float(trade['amount'])\n        price = float(result['executed_price'])\n        \n        if trade['action'] == 'buy':\n            self.portfolio['cash'] -= amount * price\n            self.portfolio['positions'][token] = \\\n                self.portfolio['positions'].get(token, 0) + amount\n        else:\n            self.portfolio['cash'] += amount * price\n            self.portfolio['positions'][token] = \\\n                self.portfolio['positions'].get(token, 0) - amount\n            \n        # Update total value\n        self.calculate_total_value()\n        \n    def calculate_total_value(self):\n        \"\"\"Calculate total portfolio value.\"\"\"\n        total = self.portfolio['cash']\n        \n        for token, amount in self.portfolio['positions'].items():\n            # Get current price\n            try:\n                price = float(self.get_current_price(token))\n                total += amount * price\n            except Exception as e:\n                logger.error(f\"Error getting price for {token}: {e}\")\n                \n        self.portfolio['total_value'] = total\n        \n    async def get_current_price(self, token: str) -> float:\n        \"\"\"Get current token price.\"\"\"\n        try:\n            price = await self.jupiter.get_price(token)\n            return float(price) if price else 0.0\n        except Exception as e:\n            logger.error(f\"Error getting price for {token}: {e}\")\n            return 0.0"}
{"type": "source_file", "path": "src/agents/market_analyzer.py", "content": "# src/market_analyzer.py\nimport logging\nfrom typing import Dict, List, Optional, Union\nfrom dataclasses import dataclass\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\n\nfrom tools import CryptoDataTools\nfrom executors.jupiter_client import JupiterClient\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass MarketAnalysis:\n    \"\"\"Market analysis result structure.\"\"\"\n    token: str\n    price: float\n    volume_24h: float\n    price_change_24h: float\n    technical_indicators: Dict[str, float]\n    risk_metrics: Dict[str, float]\n    trading_signals: Dict[str, Union[str, float]]\n    liquidity_metrics: Dict[str, float]\n    timestamp: str\n\nclass MarketAnalyzer:\n    \"\"\"Advanced market analysis for crypto trading.\"\"\"\n    \n    def __init__(\n        self,\n        config: Optional[Dict] = None,\n        lookback_period: int = 100,\n        risk_free_rate: float = 0.03\n    ):\n        self.config = config or {}\n        self.lookback_period = lookback_period\n        self.risk_free_rate = risk_free_rate\n        self.data_tools = CryptoDataTools()\n        self.jupiter = JupiterClient()\n        \n    async def analyze_token(self, token: str) -> MarketAnalysis:\n        \"\"\"Perform comprehensive token analysis.\"\"\"\n        try:\n            # Get market data\n            metrics = await self.data_tools.get_token_metrics(token)\n            history = await self.data_tools.get_historical_prices(token, self.lookback_period)\n            liquidity = await self.get_liquidity_metrics(token)\n            \n            # Technical analysis\n            technical = self.calculate_technical_indicators(history)\n            \n            # Risk analysis\n            risk = self.calculate_risk_metrics(history, metrics)\n            \n            # Generate trading signals\n            signals = self.generate_trading_signals(\n                technical,\n                risk,\n                liquidity\n            )\n            \n            return MarketAnalysis(\n                token=token,\n                price=float(metrics.price),\n                volume_24h=float(metrics.volume),\n                price_change_24h=self.calculate_price_change(history),\n                technical_indicators=technical,\n                risk_metrics=risk,\n                trading_signals=signals,\n                liquidity_metrics=liquidity,\n                timestamp=datetime.now().isoformat()\n            )\n            \n        except Exception as e:\n            logger.error(f\"Error analyzing token {token}: {e}\")\n            raise\n            \n    def calculate_technical_indicators(self, history: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"Calculate technical analysis indicators.\"\"\"\n        try:\n            price_series = history['price']\n            \n            return {\n                'rsi': self.calculate_rsi(price_series),\n                'macd': self.calculate_macd(price_series)['histogram'],\n                'bollinger_position': self.calculate_bollinger_position(price_series),\n                'momentum': self.calculate_momentum(price_series),\n                'volatility': self.calculate_volatility(price_series)\n            }\n        except Exception as e:\n            logger.error(f\"Error calculating technical indicators: {e}\")\n            return {}\n\n    def calculate_risk_metrics(\n        self,\n        history: pd.DataFrame,\n        metrics: Dict[str, float]\n    ) -> Dict[str, float]:\n        \"\"\"Calculate risk metrics.\"\"\"\n        try:\n            returns = history['price'].pct_change().dropna()\n            \n            var = self.calculate_value_at_risk(returns)\n            sharp = self.calculate_sharpe_ratio(returns)\n            \n            return {\n                'value_at_risk': var,\n                'sharpe_ratio': sharp,\n                'volatility': returns.std() * np.sqrt(252),  # Annualized\n                'max_drawdown': self.calculate_max_drawdown(history['price']),\n                'liquidity_risk': self.calculate_liquidity_risk(metrics)\n            }\n        except Exception as e:\n            logger.error(f\"Error calculating risk metrics: {e}\")\n            return {}\n            \n    async def get_liquidity_metrics(self, token: str) -> Dict[str, float]:\n        \"\"\"Get liquidity-related metrics.\"\"\"\n        try:\n            depth_data = await self.jupiter.get_market_depth(token)\n            \n            return {\n                'depth_2_percent': depth_data.get('depth_2percent', 0),\n                'slippage_impact': depth_data.get('price_impact', 0),\n                'maker_volume': depth_data.get('maker_volume_24h', 0),\n                'taker_volume': depth_data.get('taker_volume_24h', 0)\n            }\n        except Exception as e:\n            logger.error(f\"Error getting liquidity metrics: {e}\")\n            return {}\n\n    def generate_trading_signals(\n        self,\n        technical: Dict[str, float],\n        risk: Dict[str, float],\n        liquidity: Dict[str, float]\n    ) -> Dict[str, Union[str, float]]:\n        \"\"\"Generate trading signals from analysis.\"\"\"\n        try:\n            # Combine indicators for signal\n            signal_strength = 0.0\n            \n            # Technical factors (40% weight)\n            if technical.get('rsi', 50) < 30:\n                signal_strength += 0.4  # Oversold\n            elif technical.get('rsi', 50) > 70:\n                signal_strength -= 0.4  # Overbought\n                \n            if technical.get('macd', 0) > 0:\n                signal_strength += 0.2\n            else:\n                signal_strength -= 0.2\n                \n            # Risk factors (30% weight)\n            risk_score = 0.3 * (1 - min(1, risk.get('value_at_risk', 0) / 0.1))\n            signal_strength += risk_score\n            \n            # Liquidity factors (30% weight)\n            liquidity_score = 0.3 * min(1, liquidity.get('depth_2_percent', 0) / 100000)\n            signal_strength += liquidity_score\n            \n            # Generate signal\n            if signal_strength > 0.3:\n                action = 'BUY'\n            elif signal_strength < -0.3:\n                action = 'SELL'\n            else:\n                action = 'HOLD'\n                \n            return {\n                'action': action,\n                'confidence': abs(signal_strength),\n                'signal_strength': signal_strength,\n                'risk_score': risk_score,\n                'liquidity_score': liquidity_score\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error generating trading signals: {e}\")\n            return {\n                'action': 'HOLD',\n                'confidence': 0,\n                'signal_strength': 0,\n                'risk_score': 0,\n                'liquidity_score': 0\n            }\n\n    # Technical Analysis Helper Methods\n    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> float:\n        \"\"\"Calculate Relative Strength Index.\"\"\"\n        try:\n            delta = prices.diff()\n            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n            \n            rs = gain / loss\n            rsi = 100 - (100 / (1 + rs))\n            return float(rsi.iloc[-1])\n        except Exception:\n            return 50.0\n\n    def calculate_macd(\n        self,\n        prices: pd.Series,\n        fast_period: int = 12,\n        slow_period: int = 26,\n        signal_period: int = 9\n    ) -> Dict[str, float]:\n        \"\"\"Calculate MACD (Moving Average Convergence Divergence).\"\"\"\n        try:\n            fast_ema = prices.ewm(span=fast_period, adjust=False).mean()\n            slow_ema = prices.ewm(span=slow_period, adjust=False).mean()\n            macd = fast_ema - slow_ema\n            signal = macd.ewm(span=signal_period, adjust=False).mean()\n            histogram = macd - signal\n            \n            return {\n                'macd': float(macd.iloc[-1]),\n                'signal': float(signal.iloc[-1]),\n                'histogram': float(histogram.iloc[-1])\n            }\n        except Exception:\n            return {'macd': 0, 'signal': 0, 'histogram': 0}\n\n    def calculate_bollinger_position(\n        self,\n        prices: pd.Series,\n        window: int = 20,\n        num_std: float = 2.0\n    ) -> float:\n        \"\"\"Calculate relative position within Bollinger Bands.\"\"\"\n        try:\n            rolling_mean = prices.rolling(window=window).mean()\n            rolling_std = prices.rolling(window=window).std()\n            \n            upper_band = rolling_mean + (rolling_std * num_std)\n            lower_band = rolling_mean - (rolling_std * num_std)\n            \n            # Position as percentage between bands\n            position = (prices.iloc[-1] - lower_band.iloc[-1]) / (upper_band.iloc[-1] - lower_band.iloc[-1])\n            return float(position)\n        except Exception:\n            return 0.5\n\n    def calculate_momentum(\n        self,\n        prices: pd.Series,\n        period: int = 14\n    ) -> float:\n        \"\"\"Calculate price momentum.\"\"\"\n        try:\n            return float(prices.pct_change(period).iloc[-1])\n        except Exception:\n            return 0.0\n\n    # Risk Analysis Helper Methods\n    def calculate_value_at_risk(\n        self,\n        returns: pd.Series,\n        confidence_level: float = 0.95\n    ) -> float:\n        \"\"\"Calculate Value at Risk.\"\"\"\n        try:\n            return float(np.percentile(returns, (1 - confidence_level) * 100))\n        except Exception:\n            return 0.0\n\n    def calculate_sharpe_ratio(\n        self,\n        returns: pd.Series\n    ) -> float:\n        \"\"\"Calculate Sharpe Ratio.\"\"\"\n        try:\n            excess_returns = returns - self.risk_free_rate/252\n            return float(np.sqrt(252) * excess_returns.mean() / returns.std())\n        except Exception:\n            return 0.0\n\n    def calculate_max_drawdown(self, prices: pd.Series) -> float:\n        \"\"\"Calculate Maximum Drawdown.\"\"\"\n        try:\n            rolling_max = prices.expanding(min_periods=1).max()\n            drawdown = (prices - rolling_max) / rolling_max\n            return float(drawdown.min())\n        except Exception:\n            return 0.0\n\n    def calculate_liquidity_risk(self, metrics: Dict[str, float]) -> float:\n        \"\"\"Calculate liquidity risk score.\"\"\"\n        try:\n            volume = float(metrics.get('volume', 0))\n            liquidity = float(metrics.get('liquidity', 0))\n            \n            if volume > 0:\n                return min(1.0, liquidity / volume)\n            return 1.0\n        except Exception:\n            return 1.0"}
{"type": "source_file", "path": "src/cognition/memory.py", "content": "# src/cognition/memory.py\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\nfrom dataclasses import dataclass\nimport logging\nfrom collections import deque\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass MemoryEntry:\n    \"\"\"Single memory entry.\"\"\"\n    timestamp: str\n    type: str  # 'trade', 'analysis', 'error', 'learning'\n    data: Dict[str, Any]\n    importance: float  # 0 to 1\n    metadata: Optional[Dict] = None\n\nclass MemorySystem:\n    \"\"\"Advanced memory system for autonomous trading agent.\"\"\"\n    \n    def __init__(\n        self,\n        max_size: int = 1000,\n        importance_threshold: float = 0.5,\n        consolidation_interval: int = 100\n    ):\n        self.max_size = max_size\n        self.importance_threshold = importance_threshold\n        self.consolidation_interval = consolidation_interval\n        \n        # Memory storage\n        self.short_term = deque(maxlen=100)  # Recent memories\n        self.long_term = deque(maxlen=max_size)  # Important memories\n        \n        # Performance metrics\n        self.metrics = {\n            'trades': [],\n            'win_rate': 0.0,\n            'avg_profit': 0.0,\n            'total_trades': 0\n        }\n        \n    async def add(self, entry_type: str, data: Dict[str, Any], metadata: Optional[Dict] = None) -> None:\n        \"\"\"Add new memory entry.\"\"\"\n        try:\n            # Calculate importance\n            importance = self._calculate_importance(entry_type, data)\n            \n            entry = MemoryEntry(\n                timestamp=datetime.now().isoformat(),\n                type=entry_type,\n                data=data,\n                importance=importance,\n                metadata=metadata\n            )\n            \n            # Add to short-term memory\n            self.short_term.append(entry)\n            \n            # Add to long-term if important\n            if importance >= self.importance_threshold:\n                self.long_term.append(entry)\n            \n            # Update metrics if trade memory\n            if entry_type == 'trade':\n                self._update_metrics(data)\n            \n            # Consolidate if needed\n            if len(self.short_term) >= self.consolidation_interval:\n                await self._consolidate_memories()\n                \n        except Exception as e:\n            logger.error(f\"Error adding memory: {e}\")\n            \n    def get_relevant_memories(\n        self,\n        context: Dict[str, Any],\n        limit: int = 5,\n        memory_types: Optional[List[str]] = None\n    ) -> List[MemoryEntry]:\n        \"\"\"Get memories relevant to current context.\"\"\"\n        scored_memories = []\n        \n        # Search both memory stores\n        memories = list(self.short_term) + list(self.long_term)\n        \n        for memory in memories:\n            if memory_types and memory.type not in memory_types:\n                continue\n                \n            relevance = self._calculate_relevance(memory, context)\n            scored_memories.append((relevance, memory))\n            \n        # Sort by relevance and deduplicate\n        sorted_memories = sorted(scored_memories, key=lambda x: x[0], reverse=True)\n        unique_memories = []\n        seen = set()\n        \n        for _, memory in sorted_memories:\n            memory_key = f\"{memory.timestamp}_{memory.type}\"\n            if memory_key not in seen:\n                unique_memories.append(memory)\n                seen.add(memory_key)\n                if len(unique_memories) >= limit:\n                    break\n                    \n        return unique_memories\n        \n    def get_recent_memories(self, limit: int = 10) -> List[MemoryEntry]:\n        \"\"\"Get most recent memories.\"\"\"\n        return list(self.short_term)[-limit:]\n        \n    def get_performance_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get agent performance metrics.\"\"\"\n        return self.metrics\n        \n    def _calculate_importance(self, entry_type: str, data: Dict[str, Any]) -> float:\n        \"\"\"Calculate memory importance score.\"\"\"\n        importance = 0.5  # Base importance\n        \n        if entry_type == 'trade':\n            # Important if large trade or significant profit/loss\n            trade_size = abs(float(data.get('size', 0)))\n            profit = float(data.get('profit', 0))\n            importance += min(0.3, trade_size / 10000)  # Size factor\n            importance += min(0.2, abs(profit) / 1000)  # Profit factor\n            \n        elif entry_type == 'error':\n            # Errors are usually important\n            importance += 0.3\n            \n        elif entry_type == 'analysis':\n            # Important if high confidence or risk\n            confidence = float(data.get('confidence', 0))\n            risk_score = float(data.get('risk_score', 0))\n            importance += 0.2 * confidence\n            importance += 0.2 * risk_score\n            \n        return min(1.0, importance)\n        \n    def _calculate_relevance(self, memory: MemoryEntry, context: Dict[str, Any]) -> float:\n        \"\"\"Calculate memory relevance to current context.\"\"\"\n        relevance = 0.0\n        \n        # Time relevance (more recent = more relevant)\n        time_diff = (datetime.now() - datetime.fromisoformat(memory.timestamp)).total_seconds()\n        time_factor = max(0, 1 - (time_diff / (24 * 3600)))  # 24 hour scale\n        relevance += 0.3 * time_factor\n        \n        # Context matching\n        if 'token' in context and context['token'] == memory.data.get('token'):\n            relevance += 0.3\n            \n        if 'type' in context and context['type'] == memory.type:\n            relevance += 0.2\n            \n        # Market condition similarity\n        if 'market_conditions' in context and 'market_conditions' in memory.data:\n            condition_match = self._compare_market_conditions(\n                context['market_conditions'],\n                memory.data['market_conditions']\n            )\n            relevance += 0.2 * condition_match\n            \n        return min(1.0, relevance)\n        \n    async def _consolidate_memories(self):\n        \"\"\"Consolidate and clean up memories.\"\"\"\n        try:\n            # Group similar memories\n            consolidated = []\n            groups = {}\n            \n            for memory in self.short_term:\n                key = f\"{memory.type}_{memory.data.get('token', '')}\"\n                if key not in groups:\n                    groups[key] = []\n                groups[key].append(memory)\n                \n            # Create consolidated memories\n            for group in groups.values():\n                if len(group) > 1:\n                    consolidated_data = self._merge_memory_data(group)\n                    importance = max(m.importance for m in group)\n                    \n                    consolidated.append(MemoryEntry(\n                        timestamp=datetime.now().isoformat(),\n                        type=group[0].type,\n                        data=consolidated_data,\n                        importance=importance\n                    ))\n                    \n            # Update memory stores\n            self.short_term.clear()\n            self.short_term.extend(consolidated)\n            \n        except Exception as e:\n            logger.error(f\"Error consolidating memories: {e}\")\n            \n    def _merge_memory_data(self, memories: List[MemoryEntry]) -> Dict[str, Any]:\n        \"\"\"Merge similar memory data.\"\"\"\n        merged = {}\n        for memory in memories:\n            for key, value in memory.data.items():\n                if key not in merged:\n                    merged[key] = []\n                if isinstance(value, (int, float)):\n                    merged[key].append(value)\n                else:\n                    merged[key] = value\n                    \n        # Average numerical values\n        for key, value in merged.items():\n            if isinstance(value, list) and value and isinstance(value[0], (int, float)):\n                merged[key] = sum(value) / len(value)\n                \n        return merged\n        \n    def _update_metrics(self, trade_data: Dict[str, Any]):\n        \"\"\"Update performance metrics.\"\"\"\n        self.metrics['total_trades'] += 1\n        self.metrics['trades'].append(trade_data)\n        \n        # Calculate win rate\n        if 'profit' in trade_data:\n            profit = float(trade_data['profit'])\n            if profit > 0:\n                self.metrics['win_rate'] = (\n                    (self.metrics['win_rate'] * (self.metrics['total_trades'] - 1) + 1) /\n                    self.metrics['total_trades']\n                )\n            else:\n                self.metrics['win_rate'] = (\n                    self.metrics['win_rate'] * (self.metrics['total_trades'] - 1) /\n                    self.metrics['total_trades']\n                )\n                \n        # Update average profit\n        profits = [float(t.get('profit', 0)) for t in self.metrics['trades']]\n        self.metrics['avg_profit'] = sum(profits) / len(profits) if profits else 0\n        \n    @staticmethod\n    def _compare_market_conditions(cond1: Dict[str, Any], cond2: Dict[str, Any]) -> float:\n        \"\"\"Compare similarity of market conditions.\"\"\"\n        try:\n            # Compare key metrics\n            metrics = ['trend', 'volatility', 'volume', 'sentiment']\n            matches = sum(\n                1 for m in metrics\n                if m in cond1 and m in cond2 and cond1[m] == cond2[m]\n            )\n            return matches / len(metrics)\n        except Exception:\n            return 0.0"}
{"type": "source_file", "path": "src/cognition/__init__.py", "content": ""}
{"type": "source_file", "path": "check_env.py", "content": "# check_env.py\nimport os\nimport sys\nimport ssl\nimport logging\nimport aiohttp\nimport asyncio\nfrom dotenv import load_dotenv\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nasync def check_jupiter_connection():\n    \"\"\"Test connection to Jupiter API.\"\"\"\n    url = \"https://quote-api.jup.ag/v6/price\"\n    params = {\n        \"inputMint\": \"So11111111111111111111111111111111111111112\",  # SOL\n        \"outputMint\": \"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\"  # USDC\n    }\n    \n    ssl_context = ssl.create_default_context()\n    connector = aiohttp.TCPConnector(ssl=ssl_context)\n    \n    async with aiohttp.ClientSession(connector=connector) as session:\n        try:\n            async with session.get(url, params=params) as response:\n                if response.status == 200:\n                    logger.info(\"✅ Jupiter API connection successful\")\n                    return True\n                else:\n                    logger.error(f\"❌ Jupiter API error: {response.status}\")\n                    return False\n        except Exception as e:\n            logger.error(f\"❌ Jupiter API connection failed: {e}\")\n            return False\n\nasync def check_gaianet_connection():\n    \"\"\"Test connection to GaiaNet API.\"\"\"\n    url = \"https://raw.gaianet.ai/llama-3-8b-instruct/config.json\"\n    \n    ssl_context = ssl.create_default_context()\n    connector = aiohttp.TCPConnector(ssl=ssl_context)\n    \n    async with aiohttp.ClientSession(connector=connector) as session:\n        try:\n            async with session.get(url) as response:\n                if response.status == 200:\n                    logger.info(\"✅ GaiaNet API connection successful\")\n                    return True\n                else:\n                    logger.error(f\"❌ GaiaNet API error: {response.status}\")\n                    return False\n        except Exception as e:\n            logger.error(f\"❌ GaiaNet API connection failed: {e}\")\n            return False\n\ndef check_environment():\n    \"\"\"Check if all required environment variables are set.\"\"\"\n    load_dotenv()\n    \n    required_vars = [\n        \"OPENAI_API_KEY\",\n        \"HELIUS_API_KEY\",\n        \"GAIANET_API_KEY\"\n    ]\n    \n    missing_vars = [var for var in required_vars if not os.getenv(var)]\n    \n    if missing_vars:\n        logger.error(f\"❌ Missing environment variables: {', '.join(missing_vars)}\")\n        return False\n    \n    logger.info(\"✅ Environment variables check passed\")\n    return True\n\nasync def main():\n    \"\"\"Run all environment checks.\"\"\"\n    logger.info(\"Running environment checks...\")\n    \n    checks = [\n        (\"Environment variables\", check_environment()),\n        (\"Jupiter API connection\", await check_jupiter_connection()),\n        (\"GaiaNet API connection\", await check_gaianet_connection())\n    ]\n    \n    all_passed = all(result for _, result in checks)\n    \n    if all_passed:\n        logger.info(\"✅ All checks passed! You can run the agent now.\")\n        return 0\n    else:\n        logger.error(\"❌ Some checks failed. Please fix the issues above.\")\n        return 1\n\nif __name__ == \"__main__\":\n    try:\n        exit_code = asyncio.run(main())\n        sys.exit(exit_code)\n    except KeyboardInterrupt:\n        logger.info(\"Check cancelled by user\")\n        sys.exit(1)\n    except Exception as e:\n        logger.error(f\"Unexpected error during checks: {e}\")\n        sys.exit(1)"}
{"type": "source_file", "path": "src/executors/__init__.py", "content": ""}
{"type": "source_file", "path": "src/__init__.py", "content": "# src/__init__.py\nfrom .tools import CryptoDataTools\nfrom .config import Config\n\n__version__ = \"0.1.0\"\n\n__all__ = [\n    \"CryptoDataTools\",\n    \"LiquidityAnalysis\",\n    \"Config\"\n]"}
{"type": "source_file", "path": "src/tools.py", "content": "# src/tools.py\nimport os\nimport logging\nfrom typing import Dict, Optional, List\nfrom dataclasses import dataclass\nimport aiohttp\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom executors.jupiter_client import JupiterClient\nfrom typing import Tuple\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass CryptoMetrics:\n    price: float\n    volume: float\n    liquidity: float\n    tvl: float\n    holders: int\n    transactions: int\n    circulating_supply: float\n    total_supply: float\n\nclass MarketAnalyzer:\n    \"\"\"Market analysis tools for crypto trading.\"\"\"\n    \n    def __init__(self):\n        self.data_tools = CryptoDataTools()\n        \n    async def get_token_metrics(self, token: str) -> Dict:\n        \"\"\"Get comprehensive token metrics with analysis.\"\"\"\n        try:\n            # Get base metrics\n            metrics = await self.data_tools.get_token_metrics(token)\n            \n            # Get historical data\n            history = await self.data_tools.get_historical_prices(token)\n            \n            # Perform technical analysis\n            analysis = self.analyze_market_data(history, metrics)\n            \n            return {\n                'metrics': metrics.__dict__,\n                'analysis': analysis,\n                'timestamp': datetime.now().isoformat()\n            }\n        except Exception as e:\n            logger.error(f\"Error analyzing token {token}: {e}\")\n            return {\n                'error': str(e),\n                'timestamp': datetime.now().isoformat()\n            }\n    \n    def analyze_market_data(\n        self,\n        history: pd.DataFrame,\n        metrics: CryptoMetrics\n    ) -> Dict:\n        \"\"\"Perform technical analysis on market data.\"\"\"\n        analysis = {}\n        \n        # Calculate price trends\n        if not history.empty:\n            analysis['price_trends'] = {\n                'sma_20': float(history['price'].rolling(20).mean().iloc[-1]),\n                'sma_50': float(history['price'].rolling(50).mean().iloc[-1]),\n                'current_price': float(history['price'].iloc[-1]),\n                'price_change_24h': self.calculate_price_change(history)\n            }\n            \n            # Add momentum indicators\n            analysis['momentum'] = {\n                'rsi': self.calculate_rsi(history['price']),\n                'macd': self.calculate_macd(history['price']),\n                'volatility': self.calculate_volatility(history['price'])\n            }\n        \n        # Add market health metrics\n        analysis['market_health'] = {\n            'liquidity_ratio': metrics.liquidity / metrics.volume if metrics.volume > 0 else 0,\n            'holder_concentration': self.calculate_holder_concentration(metrics),\n            'volume_stability': self.calculate_volume_stability(history) if not history.empty else 0\n        }\n        \n        return analysis\n    \n    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> float:\n        \"\"\"Calculate Relative Strength Index.\"\"\"\n        try:\n            delta = prices.diff()\n            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n            \n            rs = gain / loss\n            rsi = 100 - (100 / (1 + rs))\n            return float(rsi.iloc[-1])\n        except Exception:\n            return 50.0  # Neutral RSI on error\n            \n    def calculate_macd(\n        self,\n        prices: pd.Series,\n        fast_period: int = 12,\n        slow_period: int = 26\n    ) -> Dict[str, float]:\n        \"\"\"Calculate MACD indicators.\"\"\"\n        try:\n            exp1 = prices.ewm(span=fast_period, adjust=False).mean()\n            exp2 = prices.ewm(span=slow_period, adjust=False).mean()\n            macd = exp1 - exp2\n            signal = macd.ewm(span=9, adjust=False).mean()\n            \n            return {\n                'macd': float(macd.iloc[-1]),\n                'signal': float(signal.iloc[-1]),\n                'histogram': float(macd.iloc[-1] - signal.iloc[-1])\n            }\n        except Exception:\n            return {'macd': 0, 'signal': 0, 'histogram': 0}\n            \n    def calculate_volatility(self, prices: pd.Series, window: int = 20) -> float:\n        \"\"\"Calculate price volatility.\"\"\"\n        try:\n            returns = prices.pct_change()\n            return float(returns.std() * np.sqrt(window))\n        except Exception:\n            return 0.0\n            \n    def calculate_price_change(self, history: pd.DataFrame) -> float:\n        \"\"\"Calculate 24-hour price change percentage.\"\"\"\n        try:\n            if len(history) >= 24:\n                current_price = history['price'].iloc[-1]\n                past_price = history['price'].iloc[-24]\n                return ((current_price - past_price) / past_price) * 100\n            return 0.0\n        except Exception:\n            return 0.0\n            \n    def calculate_holder_concentration(self, metrics: CryptoMetrics) -> float:\n        \"\"\"Calculate holder concentration metric.\"\"\"\n        try:\n            # Simplified concentration metric\n            if metrics.circulating_supply > 0:\n                return metrics.holders / metrics.circulating_supply\n            return 0.0\n        except Exception:\n            return 0.0\n            \n    def calculate_volume_stability(self, history: pd.DataFrame) -> float:\n        \"\"\"Calculate volume stability metric.\"\"\"\n        try:\n            if 'volume' in history.columns:\n                volume_std = history['volume'].std()\n                volume_mean = history['volume'].mean()\n                return 1 - (volume_std / volume_mean) if volume_mean > 0 else 0\n            return 0.0\n        except Exception:\n            return 0.0\n\nclass CryptoDataTools:\n    def __init__(self, rpc_url: Optional[str] = None, config: Optional[Dict] = None):\n        \"\"\"Initialize CryptoDataTools with chain-specific configuration.\"\"\"\n        self.config = config or {}\n        self.rpc_url = rpc_url or os.getenv(\"RPC_URL\", \"https://api.mainnet-beta.solana.com\")\n        self.helius_api = \"https://api.helius.xyz/v0\"\n        self.helius_key = os.getenv(\"HELIUS_API_KEY\")\n        \n        # Initialize Jupiter client\n        self.jupiter = JupiterClient()\n        \n    async def __aenter__(self):\n        # Initialize Jupiter client\n        await self.jupiter.ensure_session()\n        return self\n        \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await self.jupiter.close()\n\n    async def get_token_metrics(self, token: str) -> CryptoMetrics:\n        \"\"\"Get comprehensive token metrics.\"\"\"\n        \n        \n        try:\n            # Get price and market data from Jupiter\n            price = await self.jupiter.get_price(token)\n            depth_data = await self.jupiter.get_market_depth(token)\n            \n            # Get on-chain data from Helius\n            chain_data = await self.fetch_helius_metrics(token)\n            \n            # Calculate effective liquidity from market depth\n            liquidity = self.calculate_effective_liquidity(depth_data)\n            \n            return CryptoMetrics(\n                price=float(price) if price else 0.0,\n                volume=depth_data.get(10000, {}).get('volume', 0.0),\n                liquidity=liquidity,\n                tvl=chain_data.get('tvl', 0.0),\n                holders=chain_data.get('holders', 0),\n                transactions=chain_data.get('transactions24h', 0),\n                circulating_supply=chain_data.get('circulating_supply', 0.0),\n                total_supply=chain_data.get('total_supply', 0.0)\n            )\n            \n        except Exception as e:\n            logger.error(f\"Error in get_token_metrics: {e}\")\n            raise\n\n    def calculate_effective_liquidity(self, depth_data: Dict) -> float:\n        \"\"\"Calculate effective liquidity from market depth data.\"\"\"\n        if not depth_data:\n            return 0.0\n            \n        # Use the largest test size that has less than 1% price impact\n        for size in sorted(depth_data.keys(), reverse=True):\n            if depth_data[size]['price_impact'] < 0.01:\n                return float(size)\n        \n        return float(min(depth_data.keys()))\n\n    async def get_historical_prices(\n        self,\n        token: str,\n        limit: int = 100\n    ) -> pd.DataFrame:\n        \"\"\"Get historical price data using Jupiter quotes.\"\"\"\n        prices = []\n        timestamps = []\n        \n        # Get current time\n        end_time = datetime.now()\n        time_step = timedelta(hours=1)\n        \n        for i in range(limit):\n            timestamp = end_time - (i * time_step)\n            try:\n                price = await self.jupiter.get_price(token)\n                if price:\n                    prices.append(float(price))\n                    timestamps.append(timestamp)\n            except Exception as e:\n                logger.error(f\"Error fetching historical price for {timestamp}: {e}\")\n                continue\n                \n        df = pd.DataFrame({\n            'price': prices,\n            'timestamp': timestamps\n        })\n        df.set_index('timestamp', inplace=True)\n        return df\n\n    async def fetch_helius_metrics(self, token: str) -> Dict:\n        \"\"\"Fetch token metrics from Helius.\"\"\"\n        if not self.helius_key:\n            logger.warning(\"No Helius API key provided\")\n            return {}\n            \n        try:\n            headers = {\n                \"Authorization\": f\"Bearer {self.helius_key}\",\n                \"Accept\": \"application/json\"\n            }\n            \n            async with aiohttp.ClientSession() as session:\n                url = f\"{self.helius_api}/token-metrics\"\n                params = {\"tokenAddress\": token}\n                \n                async with session.get(url, headers=headers, params=params) as response:\n                    if response.status == 200:\n                        data = await response.json()\n                        logger.info(f\"Successfully fetched Helius metrics for {token}\")\n                        return data\n                    else:\n                        error_text = await response.text()\n                        logger.error(f\"Helius API error: {response.status} - {error_text}\")\n                        return {}\n                    \n        except Exception as e:\n            logger.error(f\"Error fetching Helius metrics: {e}\")\n            return {}\n\n\n\ndef calculate_bollinger_bands(prices_df: pd.DataFrame, window: int = 20, num_std_dev: int = 2) -> Tuple[pd.Series, pd.Series]:\n    \"\"\"Calculate Bollinger Bands.\"\"\"\n    rolling_mean = prices_df['close'].rolling(window=window).mean()\n    rolling_std = prices_df['close'].rolling(window=window).std()\n    upper_band = rolling_mean + (rolling_std * num_std_dev)\n    lower_band = rolling_mean - (rolling_std * num_std_dev)\n    return upper_band, lower_band\n\ndef calculate_intrinsic_value(free_cash_flow: float, growth_rate: float, discount_rate: float, terminal_growth_rate: float, num_years: int) -> float:\n    \"\"\"Calculate intrinsic value using Discounted Cash Flow (DCF) model.\"\"\"\n    present_value = 0\n    for year in range(1, num_years + 1):\n        present_value += free_cash_flow * ((1 + growth_rate) ** year) / ((1 + discount_rate) ** year)\n    terminal_value = (free_cash_flow * (1 + growth_rate) ** num_years * (1 + terminal_growth_rate)) / (discount_rate - terminal_growth_rate)\n    intrinsic_value = present_value + terminal_value / ((1 + discount_rate) ** num_years)\n    return intrinsic_value\n\ndef calculate_macd(prices_df: pd.DataFrame, fast_period: int = 12, slow_period: int = 26, signal_period: int = 9) -> Tuple[pd.Series, pd.Series]:\n    \"\"\"Calculate MACD (Moving Average Convergence Divergence).\"\"\"\n    exp1 = prices_df['close'].ewm(span=fast_period, adjust=False).mean()\n    exp2 = prices_df['close'].ewm(span=slow_period, adjust=False).mean()\n    macd = exp1 - exp2\n    signal = macd.ewm(span=signal_period, adjust=False).mean()\n    return macd, signal\n\ndef calculate_obv(prices_df: pd.DataFrame) -> pd.Series:\n    \"\"\"Calculate On-Balance Volume (OBV).\"\"\"\n    obv = (np.sign(prices_df['close'].diff()) * prices_df['volume']).fillna(0).cumsum()\n    return obv\n\ndef calculate_rsi(prices_df: pd.DataFrame, period: int = 14) -> pd.Series:\n    \"\"\"Calculate Relative Strength Index (RSI).\"\"\"\n    delta = prices_df['close'].diff()\n    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n    rs = gain / loss\n    rsi = 100 - (100 / (1 + rs))\n    return rsi\n\ndef search_line_items(ticker: str, line_items: List[str], period: str = 'ttm', limit: int = 1) -> List[Dict]:\n    \"\"\"Search for specific financial line items.\"\"\"\n    # Placeholder implementation\n    return [{\"line_item\": item, \"value\": 1000} for item in line_items]\n\ndef get_financial_metrics(ticker: str, report_period: str = 'ttm', period: str = 'ttm', limit: int = 1) -> List[Dict]:\n    \"\"\"Get financial metrics for a given ticker.\"\"\"\n    # Placeholder implementation\n    return [{\"return_on_equity\": 0.15, \"net_margin\": 0.20, \"operating_margin\": 0.15, \"revenue_growth\": 0.10, \"earnings_growth\": 0.10, \"book_value_growth\": 0.10, \"current_ratio\": 1.5, \"debt_to_equity\": 0.5, \"free_cash_flow_per_share\": 5.0, \"earnings_per_share\": 6.0, \"price_to_earnings_ratio\": 25, \"price_to_book_ratio\": 3, \"price_to_sales_ratio\": 5}]\n\ndef get_insider_trades(ticker: str, end_date: str, limit: int = 5) -> List[Dict]:\n    \"\"\"Get insider trades for a given ticker.\"\"\"\n    # Placeholder implementation\n    return [{\"transaction_shares\": 1000, \"transaction_price\": 50.0} for _ in range(limit)]\n\ndef get_market_cap(ticker: str) -> float:\n    \"\"\"Get market capitalization for a given ticker.\"\"\"\n    # Placeholder implementation\n    return 1000000000.0\n\ndef get_prices(ticker: str, start_date: str, end_date: str) -> List[Dict]:\n    \"\"\"Get historical prices for a given ticker.\"\"\"\n    # Placeholder implementation\n    dates = pd.date_range(start=start_date, end=end_date, freq='D')\n    return [{\"date\": date.strftime('%Y-%m-%d'), \"close\": 100.0, \"volume\": 1000} for date in dates]\n\ndef prices_to_df(prices: List[Dict]) -> pd.DataFrame:\n    \"\"\"Convert list of price dictionaries to DataFrame.\"\"\"\n    return pd.DataFrame(prices).set_index('date')"}
