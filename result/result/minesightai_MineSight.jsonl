{"repo_info": {"repo_name": "MineSight", "repo_owner": "minesightai", "repo_url": "https://github.com/minesightai/MineSight"}}
{"type": "test_file", "path": "tests/test_data.py", "content": "\"\"\"\nTests for data processing functionality\n\"\"\"\nimport pytest\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom minesight.core.ai.data import DataProcessor\n\n@pytest.fixture\ndef sample_data():\n    \"\"\"Create sample data for testing\"\"\"\n    deposits = pd.DataFrame({\n        'latitude': np.random.uniform(-90, 90, 100),\n        'longitude': np.random.uniform(-180, 180, 100),\n        'elevation': np.random.uniform(0, 1000, 100),\n        'lithology': np.random.choice(['granite', 'basalt', 'schist'], 100),\n        'deposit': np.random.randint(0, 2, 100)\n    })\n    \n    features = pd.DataFrame({\n        'latitude': np.random.uniform(-90, 90, 1000),\n        'longitude': np.random.uniform(-180, 180, 1000),\n        'magnetic': np.random.normal(0, 1, 1000),\n        'gravity': np.random.normal(0, 1, 1000)\n    })\n    \n    return {'deposits': deposits, 'features': features}\n\n@pytest.fixture\ndef data_config():\n    \"\"\"Create sample data configuration\"\"\"\n    return {\n        'numerical_features': ['latitude', 'longitude', 'elevation', 'magnetic', 'gravity'],\n        'categorical_features': ['lithology'],\n        'label_column': 'deposit',\n        'binary_labels': True,\n        'test_size': 0.2,\n        'val_size': 0.2\n    }\n\ndef test_data_processor_initialization(tmp_path):\n    \"\"\"Test DataProcessor initialization\"\"\"\n    processor = DataProcessor(data_dir=tmp_path)\n    assert processor.data_dir == tmp_path\n    assert processor.cache_dir == tmp_path / \"cache\"\n    assert processor.cache_dir.exists()\n\ndef test_data_filtering(sample_data, data_config):\n    \"\"\"Test data filtering functionality\"\"\"\n    processor = DataProcessor(Path(\".\"))\n    \n    # Add filters\n    filters = {\n        'latitude': {'min': -45, 'max': 45},\n        'lithology': ['granite', 'basalt']\n    }\n    \n    filtered = processor._filter_data(sample_data['deposits'], filters)\n    \n    assert all(filtered['latitude'] >= -45)\n    assert all(filtered['latitude'] <= 45)\n    assert all(filtered['lithology'].isin(['granite', 'basalt']))\n\ndef test_feature_extraction(sample_data, data_config):\n    \"\"\"Test feature extraction\"\"\"\n    processor = DataProcessor(Path(\".\"))\n    \n    features = processor._extract_features(\n        sample_data['deposits'],\n        sample_data['features'],\n        data_config\n    )\n    \n    expected_feature_count = (\n        len(data_config['numerical_features']) +\n        len(processor._encode_categorical(\n            sample_data['deposits']['lithology'],\n            'lithology'\n        ))\n    )\n    \n    assert features.shape[1] == expected_feature_count\n\ndef test_data_splitting(sample_data, data_config):\n    \"\"\"Test data splitting functionality\"\"\"\n    processor = DataProcessor(Path(\".\"))\n    \n    X = processor._extract_features(\n        sample_data['deposits'],\n        sample_data['features'],\n        data_config\n    )\n    y = processor._extract_labels(sample_data['deposits'], data_config)\n    \n    splits = processor._split_data(X, y, data_config)\n    \n    assert 'train' in splits\n    assert 'val' in splits\n    assert 'test' in splits\n    \n    total_samples = len(X)\n    expected_test_size = int(total_samples * data_config['test_size'])\n    expected_val_size = int(total_samples * (1 - data_config['test_size']) * data_config['val_size'])\n    \n    assert len(splits['test']['X']) == expected_test_size\n    assert len(splits['val']['X']) == expected_val_size\n\ndef test_feature_scaling(sample_data, data_config):\n    \"\"\"Test feature scaling\"\"\"\n    processor = DataProcessor(Path(\".\"))\n    \n    X = processor._extract_features(\n        sample_data['deposits'],\n        sample_data['features'],\n        data_config\n    )\n    y = processor._extract_labels(sample_data['deposits'], data_config)\n    \n    splits = processor._split_data(X, y, data_config)\n    scaled_splits = processor._scale_features(splits, data_config)\n    \n    # Check if training data is scaled to mean=0 and std=1\n    train_mean = scaled_splits['train']['X'].mean(axis=0)\n    train_std = scaled_splits['train']['X'].std(axis=0)\n    \n    assert np.allclose(train_mean, 0, atol=1e-7)\n    assert np.allclose(train_std, 1, atol=1e-7)\n\ndef test_categorical_encoding(sample_data):\n    \"\"\"Test categorical variable encoding\"\"\"\n    processor = DataProcessor(Path(\".\"))\n    \n    encoded = processor._encode_categorical(\n        sample_data['deposits']['lithology'],\n        'lithology'\n    )\n    \n    assert len(encoded) == len(sample_data['deposits'])\n    assert len(np.unique(encoded)) == len(np.unique(sample_data['deposits']['lithology']))\n\ndef test_data_caching(tmp_path, sample_data, data_config):\n    \"\"\"Test data caching functionality\"\"\"\n    processor = DataProcessor(data_dir=tmp_path)\n    \n    # Process data first time\n    config_hash = hex(hash(str(sorted(data_config.items()))))[2:]\n    cache_path = processor.cache_dir / f\"processed_data_{config_hash}.pt\"\n    \n    assert not cache_path.exists()\n    \n    # Process and cache data\n    processed = processor._process_data(\n        sample_data['deposits'],\n        sample_data['features'],\n        data_config\n    )\n    \n    assert cache_path.exists()\n    \n    # Load from cache\n    cached = processor.load_and_process_data(data_config)\n    \n    assert all(\n        torch.allclose(cached[split]['features'], processed[split]['features'])\n        for split in ['train', 'val', 'test']\n    ) "}
{"type": "test_file", "path": "tests/test_performance.py", "content": "\"\"\"\nPerformance benchmark tests\n\"\"\"\nimport pytest\nimport torch\nimport time\nimport numpy as np\nfrom minesight.core.ai.models import MineralExplorationModel\nfrom minesight.core.ai.trainer import ModelTrainer\n\ndef measure_time(func):\n    \"\"\"Decorator to measure function execution time\"\"\"\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        return result, end - start\n    return wrapper\n\n@pytest.fixture\ndef large_dataset():\n    \"\"\"Create large dataset for performance testing\"\"\"\n    n_samples = 10000\n    n_features = 100\n    \n    return {\n        'train': {\n            'features': torch.randn(n_samples, n_features),\n            'labels': torch.randint(0, 2, (n_samples, 1)).float()\n        },\n        'val': {\n            'features': torch.randn(n_samples // 5, n_features),\n            'labels': torch.randint(0, 2, (n_samples // 5, 1)).float()\n        }\n    }\n\n@measure_time\ndef train_epoch(trainer, data, config):\n    \"\"\"Train one epoch\"\"\"\n    return trainer._train_epoch(\n        trainer._create_data_loader(data['train'], config['batch_size'], True),\n        torch.nn.BCEWithLogitsLoss(),\n        torch.optim.Adam(trainer.model.parameters(), lr=config['learning_rate'])\n    )\n\n@measure_time\ndef validate(trainer, data, config):\n    \"\"\"Validate model\"\"\"\n    return trainer._validate(\n        trainer._create_data_loader(data['val'], config['batch_size'], False),\n        torch.nn.BCEWithLogitsLoss()\n    )\n\ndef test_training_performance(large_dataset):\n    \"\"\"Test training performance\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Create model\n    model = MineralExplorationModel(\n        input_dim=large_dataset['train']['features'].shape[1],\n        hidden_dims=[512, 256, 128],\n        dropout=0.3\n    ).to(device)\n    \n    # Create trainer\n    trainer = ModelTrainer(model, device, Path(\".\"))\n    \n    # Training configuration\n    config = {\n        'batch_size': 128,\n        'learning_rate': 0.001\n    }\n    \n    # Measure training performance\n    loss, train_time = train_epoch(trainer, large_dataset, config)\n    \n    # Performance assertions\n    assert train_time < 10.0  # Training should take less than 10 seconds\n    \n    # Memory usage test\n    if device.type == 'cuda':\n        torch.cuda.synchronize()\n        memory_used = torch.cuda.max_memory_allocated() / 1024**2  # MB\n        assert memory_used < 1024  # Should use less than 1GB GPU memory\n\ndef test_inference_performance(large_dataset):\n    \"\"\"Test inference performance\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Create model\n    model = MineralExplorationModel(\n        input_dim=large_dataset['train']['features'].shape[1],\n        hidden_dims=[512, 256, 128],\n        dropout=0.3\n    ).to(device)\n    \n    # Measure inference time\n    start = time.time()\n    with torch.no_grad():\n        for _ in range(10):  # Test batch inference\n            _ = model(large_dataset['train']['features'].to(device))\n    end = time.time()\n    \n    inference_time = (end - start) / 10  # Average time per batch\n    \n    # Performance assertions\n    assert inference_time < 0.1  # Inference should take less than 100ms per batch\n\ndef test_data_loading_performance(large_dataset):\n    \"\"\"Test data loading performance\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Create trainer\n    model = MineralExplorationModel(\n        input_dim=large_dataset['train']['features'].shape[1]\n    ).to(device)\n    trainer = ModelTrainer(model, device, Path(\".\"))\n    \n    # Measure data loading time\n    start = time.time()\n    data_loader = trainer._create_data_loader(\n        large_dataset['train'],\n        batch_size=128,\n        shuffle=True\n    )\n    for _ in data_loader:\n        pass\n    end = time.time()\n    \n    loading_time = end - start\n    \n    # Performance assertions\n    assert loading_time < 5.0  # Data loading should take less than 5 seconds\n\ndef test_memory_efficiency():\n    \"\"\"Test memory efficiency\"\"\"\n    # Test with increasing dataset sizes\n    sizes = [1000, 10000, 100000]\n    memory_usage = []\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    for size in sizes:\n        # Create dataset\n        data = {\n            'train': {\n                'features': torch.randn(size, 100),\n                'labels': torch.randint(0, 2, (size, 1)).float()\n            }\n        }\n        \n        # Create model\n        model = MineralExplorationModel(input_dim=100).to(device)\n        \n        # Measure memory usage\n        if device.type == 'cuda':\n            torch.cuda.reset_peak_memory_stats()\n            _ = model(data['train']['features'].to(device))\n            torch.cuda.synchronize()\n            memory_used = torch.cuda.max_memory_allocated() / 1024**2\n        else:\n            memory_used = 0  # Skip memory test for CPU\n            \n        memory_usage.append(memory_used)\n    \n    if device.type == 'cuda':\n        # Check if memory usage scales linearly or better\n        ratios = [memory_usage[i+1] / memory_usage[i] for i in range(len(memory_usage)-1)]\n        assert all(ratio < 15 for ratio in ratios)  # Memory usage should not explode\n\ndef test_batch_size_impact():\n    \"\"\"Test impact of batch size on performance\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Create dataset\n    data = {\n        'train': {\n            'features': torch.randn(10000, 100),\n            'labels': torch.randint(0, 2, (10000, 1)).float()\n        }\n    }\n    \n    # Test different batch sizes\n    batch_sizes = [32, 64, 128, 256, 512]\n    training_times = []\n    \n    for batch_size in batch_sizes:\n        model = MineralExplorationModel(input_dim=100).to(device)\n        trainer = ModelTrainer(model, device, Path(\".\"))\n        \n        # Measure training time\n        config = {'batch_size': batch_size, 'learning_rate': 0.001}\n        _, time_taken = train_epoch(trainer, data, config)\n        training_times.append(time_taken)\n    \n    # Check if larger batch sizes are more efficient\n    assert min(training_times) == training_times[-1]  # Largest batch size should be fastest "}
{"type": "test_file", "path": "tests/test_models.py", "content": "\"\"\"\nTests for model architectures\n\"\"\"\nimport pytest\nimport torch\nfrom minesight.core.ai.models import (\n    MineralExplorationModel,\n    AutoEncoder,\n    VariationalAutoEncoder\n)\n\n@pytest.fixture\ndef input_data():\n    \"\"\"Create sample input data\"\"\"\n    return torch.randn(32, 10)  # batch_size=32, input_dim=10\n\ndef test_mineral_exploration_model(input_data):\n    \"\"\"Test MineralExplorationModel\"\"\"\n    model = MineralExplorationModel(\n        input_dim=10,\n        hidden_dims=[64, 32],\n        dropout=0.3\n    )\n    model.eval()\n    \n    with torch.no_grad():\n        outputs = model(input_data)\n    \n    assert 'features' in outputs\n    assert 'logits' in outputs\n    assert 'probability' in outputs\n    assert outputs['probability'].shape == (32, 1)\n    assert torch.all((outputs['probability'] >= 0) & (outputs['probability'] <= 1))\n\ndef test_autoencoder(input_data):\n    \"\"\"Test AutoEncoder\"\"\"\n    model = AutoEncoder(\n        input_dim=10,\n        hidden_dims=[64, 32],\n        latent_dim=16\n    )\n    model.eval()\n    \n    with torch.no_grad():\n        outputs = model(input_data)\n    \n    assert 'encoded' in outputs\n    assert 'decoded' in outputs\n    assert 'reconstruction_error' in outputs\n    assert outputs['decoded'].shape == input_data.shape\n    assert outputs['reconstruction_error'].shape == input_data.shape\n\ndef test_variational_autoencoder(input_data):\n    \"\"\"Test VariationalAutoEncoder\"\"\"\n    model = VariationalAutoEncoder(\n        input_dim=10,\n        hidden_dims=[64, 32],\n        latent_dim=16\n    )\n    model.eval()\n    \n    with torch.no_grad():\n        outputs = model(input_data)\n    \n    assert 'reconstruction' in outputs\n    assert 'mu' in outputs\n    assert 'log_var' in outputs\n    assert 'z' in outputs\n    assert outputs['reconstruction'].shape == input_data.shape "}
{"type": "test_file", "path": "tests/test_functional.py", "content": "\"\"\"\nFunctional tests for MineSight\n\"\"\"\nimport pytest\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom minesight.core.ai.models import (\n    MineralExplorationModel,\n    AutoEncoder,\n    VariationalAutoEncoder\n)\nfrom minesight.core.ai.data import DataProcessor\nfrom minesight.core.ai.trainer import ModelTrainer\nfrom minesight.core.optimization.distributed import DistributedTrainer\nfrom minesight.core.optimization.compression import (\n    ModelPruner,\n    ModelQuantizer,\n    KnowledgeDistiller\n)\n\n@pytest.fixture\ndef sample_data():\n    \"\"\"Create sample data for testing\"\"\"\n    # Create deposits data\n    deposits = pd.DataFrame({\n        'latitude': np.random.uniform(-90, 90, 100),\n        'longitude': np.random.uniform(-180, 180, 100),\n        'elevation': np.random.uniform(0, 1000, 100),\n        'lithology': np.random.choice(['granite', 'basalt', 'schist'], 100),\n        'deposit': np.random.randint(0, 2, 100)\n    })\n    \n    # Create features data\n    features = pd.DataFrame({\n        'latitude': np.random.uniform(-90, 90, 1000),\n        'longitude': np.random.uniform(-180, 180, 1000),\n        'magnetic': np.random.normal(0, 1, 1000),\n        'gravity': np.random.normal(0, 1, 1000)\n    })\n    \n    return {'deposits': deposits, 'features': features}\n\n@pytest.fixture\ndef config():\n    \"\"\"Create sample configuration\"\"\"\n    return {\n        'model': {\n            'input_dim': 10,\n            'hidden_dims': [64, 32],\n            'dropout': 0.3\n        },\n        'training': {\n            'batch_size': 32,\n            'epochs': 2,\n            'learning_rate': 0.001,\n            'optimizer': 'adam',\n            'loss': 'bce'\n        },\n        'data': {\n            'numerical_features': ['latitude', 'longitude', 'elevation', 'magnetic', 'gravity'],\n            'categorical_features': ['lithology'],\n            'label_column': 'deposit',\n            'binary_labels': True,\n            'test_size': 0.2,\n            'val_size': 0.2\n        }\n    }\n\ndef test_end_to_end_training(sample_data, config, tmp_path):\n    \"\"\"Test end-to-end training pipeline\"\"\"\n    # Save data\n    deposits_path = tmp_path / \"deposits.csv\"\n    features_path = tmp_path / \"features.csv\"\n    sample_data['deposits'].to_csv(deposits_path, index=False)\n    sample_data['features'].to_csv(features_path, index=False)\n    \n    # Initialize data processor\n    processor = DataProcessor(tmp_path)\n    \n    # Process data\n    data = processor.load_and_process_data(config['data'])\n    \n    # Create model\n    model = MineralExplorationModel(\n        input_dim=data['train']['features'].shape[1],\n        hidden_dims=config['model']['hidden_dims'],\n        dropout=config['model']['dropout']\n    )\n    \n    # Train model\n    trainer = ModelTrainer(\n        model=model,\n        device=\"cpu\",\n        output_dir=tmp_path\n    )\n    \n    history = trainer.train(\n        train_data=data['train'],\n        val_data=data['val'],\n        config=config['training']\n    )\n    \n    # Verify training results\n    assert 'train_loss' in history\n    assert 'val_loss' in history\n    assert len(history['train_loss']) == config['training']['epochs']\n    \n    # Test prediction\n    results = trainer.evaluate(data['test'])\n    assert 'predictions' in results\n    assert 'probabilities' in results\n    assert len(results['predictions']) == len(data['test']['features'])\n\ndef test_anomaly_detection(sample_data, config, tmp_path):\n    \"\"\"Test anomaly detection\"\"\"\n    # Initialize data processor\n    processor = DataProcessor(tmp_path)\n    \n    # Process data\n    data = processor.load_and_process_data(config['data'])\n    \n    # Create autoencoder\n    model = AutoEncoder(\n        input_dim=data['train']['features'].shape[1],\n        hidden_dims=[32, 16],\n        latent_dim=8\n    )\n    \n    # Train model\n    trainer = ModelTrainer(\n        model=model,\n        device=\"cpu\",\n        output_dir=tmp_path\n    )\n    \n    history = trainer.train(\n        train_data=data['train'],\n        val_data=data['val'],\n        config=config['training']\n    )\n    \n    # Test anomaly detection\n    results = trainer.evaluate(data['test'])\n    assert 'reconstruction_error' in results\n    assert len(results['reconstruction_error']) == len(data['test']['features'])\n\ndef test_pattern_recognition(sample_data, config, tmp_path):\n    \"\"\"Test pattern recognition\"\"\"\n    # Initialize data processor\n    processor = DataProcessor(tmp_path)\n    \n    # Process data\n    data = processor.load_and_process_data(config['data'])\n    \n    # Create VAE\n    model = VariationalAutoEncoder(\n        input_dim=data['train']['features'].shape[1],\n        hidden_dims=[32, 16],\n        latent_dim=8\n    )\n    \n    # Train model\n    trainer = ModelTrainer(\n        model=model,\n        device=\"cpu\",\n        output_dir=tmp_path\n    )\n    \n    history = trainer.train(\n        train_data=data['train'],\n        val_data=data['val'],\n        config=config['training']\n    )\n    \n    # Test pattern recognition\n    results = trainer.evaluate(data['test'])\n    assert 'z' in results  # Latent representations\n    assert 'reconstruction' in results\n    assert results['z'].shape[1] == 8  # Latent dimension\n\ndef test_distributed_training(sample_data, config, tmp_path):\n    \"\"\"Test distributed training\"\"\"\n    if torch.cuda.device_count() < 2:\n        pytest.skip(\"Need at least 2 GPUs for distributed training test\")\n    \n    # Initialize data processor\n    processor = DataProcessor(tmp_path)\n    \n    # Process data\n    data = processor.load_and_process_data(config['data'])\n    \n    # Create model function\n    def create_model():\n        return MineralExplorationModel(\n            input_dim=data['train']['features'].shape[1],\n            hidden_dims=config['model']['hidden_dims'],\n            dropout=config['model']['dropout']\n        )\n    \n    # Create training function\n    def train_fn(model, train_config, data_config):\n        trainer = ModelTrainer(\n            model=model,\n            device=train_config['device'],\n            output_dir=tmp_path\n        )\n        return trainer.train(\n            train_data=data['train'],\n            val_data=data['val'],\n            config=train_config\n        )\n    \n    # Initialize distributed trainer\n    distributed_trainer = DistributedTrainer(\n        model_fn=create_model,\n        train_fn=train_fn\n    )\n    \n    # Train model\n    distributed_trainer.train(\n        model_config=config['model'],\n        train_config=config['training'],\n        data_config=config['data']\n    )\n\ndef test_model_compression(sample_data, config, tmp_path):\n    \"\"\"Test model compression\"\"\"\n    # Initialize data processor\n    processor = DataProcessor(tmp_path)\n    \n    # Process data\n    data = processor.load_and_process_data(config['data'])\n    \n    # Create teacher model\n    teacher_model = MineralExplorationModel(\n        input_dim=data['train']['features'].shape[1],\n        hidden_dims=[128, 64, 32],\n        dropout=0.3\n    )\n    \n    # Train teacher model\n    trainer = ModelTrainer(\n        model=teacher_model,\n        device=\"cpu\",\n        output_dir=tmp_path\n    )\n    \n    trainer.train(\n        train_data=data['train'],\n        val_data=data['val'],\n        config=config['training']\n    )\n    \n    # Create compression config\n    compression_config = {\n        'student': {\n            'model_class': MineralExplorationModel,\n            'model_args': {\n                'input_dim': data['train']['features'].shape[1],\n                'hidden_dims': [32, 16],\n                'dropout': 0.2\n            }\n        },\n        'pruning': {\n            'method': 'l1_unstructured',\n            'amount': 0.3\n        },\n        'quantization': {},\n        'distillation': {\n            'temperature': 2.0,\n            'alpha': 0.5\n        }\n    }\n    \n    # Create and compress student model\n    student_model, distiller = create_compressed_model(\n        teacher_model,\n        compression_config\n    )\n    \n    # Test student model\n    results = trainer.evaluate(data['test'])\n    assert 'predictions' in results\n    assert 'probabilities' in results\n    \n    # Test model size reduction\n    teacher_size = sum(p.nelement() for p in teacher_model.parameters())\n    student_size = sum(p.nelement() for p in student_model.parameters())\n    assert student_size < teacher_size\n\ndef test_error_handling(sample_data, config, tmp_path):\n    \"\"\"Test error handling\"\"\"\n    # Test invalid data\n    invalid_data = sample_data['deposits'].copy()\n    invalid_data.loc[0, 'latitude'] = 1000  # Invalid latitude\n    \n    with pytest.raises(Exception):\n        processor = DataProcessor(tmp_path)\n        processor.validate_data(invalid_data)\n    \n    # Test invalid model configuration\n    invalid_config = config.copy()\n    invalid_config['model']['hidden_dims'] = []  # Invalid hidden dimensions\n    \n    with pytest.raises(Exception):\n        model = MineralExplorationModel(**invalid_config['model'])\n    \n    # Test training with invalid data\n    processor = DataProcessor(tmp_path)\n    data = processor.load_and_process_data(config['data'])\n    \n    model = MineralExplorationModel(\n        input_dim=data['train']['features'].shape[1],\n        hidden_dims=config['model']['hidden_dims'],\n        dropout=config['model']['dropout']\n    )\n    \n    trainer = ModelTrainer(\n        model=model,\n        device=\"cpu\",\n        output_dir=tmp_path\n    )\n    \n    invalid_data = {\n        'features': torch.randn(10, data['train']['features'].shape[1] + 1),\n        'labels': torch.randint(0, 2, (10, 1)).float()\n    }\n    \n    with pytest.raises(Exception):\n        trainer.train(\n            train_data=invalid_data,\n            val_data=data['val'],\n            config=config['training']\n        ) "}
{"type": "source_file", "path": "minesight/core/analysis/risk_analyzer.py", "content": "\"\"\"\nRisk analysis module for mineral exploration\n\"\"\"\nfrom typing import Dict, List, Optional\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import norm\nfrom dataclasses import dataclass\n\n@dataclass\nclass RiskFactors:\n    \"\"\"Risk factors configuration\"\"\"\n    GEOLOGICAL_WEIGHTS = {\n        \"fault_proximity\": 0.3,\n        \"structural_complexity\": 0.3,\n        \"deposit_uncertainty\": 0.4\n    }\n    \n    ENVIRONMENTAL_WEIGHTS = {\n        \"water_proximity\": 0.25,\n        \"protected_areas\": 0.35,\n        \"ecosystem_sensitivity\": 0.4\n    }\n    \n    TECHNICAL_WEIGHTS = {\n        \"depth_complexity\": 0.3,\n        \"infrastructure_access\": 0.4,\n        \"terrain_difficulty\": 0.3\n    }\n    \n    ECONOMIC_WEIGHTS = {\n        \"resource_grade\": 0.4,\n        \"extraction_cost\": 0.3,\n        \"market_volatility\": 0.3\n    }\n\nclass RiskAnalyzer:\n    \"\"\"Class for analyzing risks associated with mineral exploration sites\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the risk analyzer\"\"\"\n        self.risk_factors = RiskFactors()\n        \n    def analyze_site_risks(self,\n                          latitude: float,\n                          longitude: float,\n                          geological_features: pd.DataFrame,\n                          deposits: pd.DataFrame,\n                          properties: Optional[Dict] = None) -> Dict[str, float]:\n        \"\"\"\n        Analyze various risk factors for a potential mining site\n        \n        Args:\n            latitude: Site latitude\n            longitude: Site longitude\n            geological_features: DataFrame of geological features\n            deposits: DataFrame of mineral deposits\n            properties: Additional site properties\n            \n        Returns:\n            Dictionary with risk scores for different categories\n        \"\"\"\n        # Calculate individual risk components\n        geological_risk = self._assess_geological_risk(\n            latitude, longitude, geological_features, deposits\n        )\n        \n        environmental_risk = self._assess_environmental_risk(\n            latitude, longitude, properties\n        )\n        \n        technical_risk = self._assess_technical_risk(\n            latitude, longitude, properties\n        )\n        \n        economic_risk = self._assess_economic_risk(\n            deposits, properties\n        )\n        \n        # Calculate overall risk score\n        overall_risk = np.mean([\n            geological_risk,\n            environmental_risk,\n            technical_risk,\n            economic_risk\n        ])\n        \n        return {\n            \"overall_risk\": float(overall_risk),\n            \"geological_risk\": float(geological_risk),\n            \"environmental_risk\": float(environmental_risk),\n            \"technical_risk\": float(technical_risk),\n            \"economic_risk\": float(economic_risk)\n        }\n    \n    def _assess_geological_risk(self,\n                              latitude: float,\n                              longitude: float,\n                              geological_features: pd.DataFrame,\n                              deposits: pd.DataFrame) -> float:\n        \"\"\"Assess geological risks\"\"\"\n        # Calculate fault proximity risk\n        fault_risk = self._calculate_fault_proximity_risk(\n            latitude, longitude, geological_features\n        )\n        \n        # Calculate structural complexity\n        structural_risk = self._calculate_structural_complexity(\n            geological_features\n        )\n        \n        # Calculate deposit uncertainty\n        uncertainty_risk = self._calculate_deposit_uncertainty(\n            latitude, longitude, deposits\n        )\n        \n        # Combine risks using weights\n        weights = self.risk_factors.GEOLOGICAL_WEIGHTS\n        return (\n            weights[\"fault_proximity\"] * fault_risk +\n            weights[\"structural_complexity\"] * structural_risk +\n            weights[\"deposit_uncertainty\"] * uncertainty_risk\n        )\n    \n    def _assess_environmental_risk(self,\n                                 latitude: float,\n                                 longitude: float,\n                                 properties: Optional[Dict]) -> float:\n        \"\"\"Assess environmental risks\"\"\"\n        # Calculate water proximity risk\n        water_risk = self._calculate_water_proximity_risk(\n            latitude, longitude, properties\n        )\n        \n        # Calculate protected areas risk\n        protected_risk = self._calculate_protected_areas_risk(\n            latitude, longitude, properties\n        )\n        \n        # Calculate ecosystem sensitivity\n        eco_risk = self._calculate_ecosystem_sensitivity(\n            latitude, longitude, properties\n        )\n        \n        # Combine risks using weights\n        weights = self.risk_factors.ENVIRONMENTAL_WEIGHTS\n        return (\n            weights[\"water_proximity\"] * water_risk +\n            weights[\"protected_areas\"] * protected_risk +\n            weights[\"ecosystem_sensitivity\"] * eco_risk\n        )\n    \n    def _assess_technical_risk(self,\n                             latitude: float,\n                             longitude: float,\n                             properties: Optional[Dict]) -> float:\n        \"\"\"Assess technical risks\"\"\"\n        # Calculate depth complexity risk\n        depth_risk = self._calculate_depth_complexity_risk(properties)\n        \n        # Calculate infrastructure access risk\n        infrastructure_risk = self._calculate_infrastructure_risk(\n            latitude, longitude, properties\n        )\n        \n        # Calculate terrain difficulty risk\n        terrain_risk = self._calculate_terrain_risk(\n            latitude, longitude, properties\n        )\n        \n        # Combine risks using weights\n        weights = self.risk_factors.TECHNICAL_WEIGHTS\n        return (\n            weights[\"depth_complexity\"] * depth_risk +\n            weights[\"infrastructure_access\"] * infrastructure_risk +\n            weights[\"terrain_difficulty\"] * terrain_risk\n        )\n    \n    def _assess_economic_risk(self,\n                            deposits: pd.DataFrame,\n                            properties: Optional[Dict]) -> float:\n        \"\"\"Assess economic risks\"\"\"\n        # Calculate resource grade risk\n        grade_risk = self._calculate_grade_risk(deposits, properties)\n        \n        # Calculate extraction cost risk\n        cost_risk = self._calculate_extraction_cost_risk(properties)\n        \n        # Calculate market volatility risk\n        market_risk = self._calculate_market_risk(properties)\n        \n        # Combine risks using weights\n        weights = self.risk_factors.ECONOMIC_WEIGHTS\n        return (\n            weights[\"resource_grade\"] * grade_risk +\n            weights[\"extraction_cost\"] * cost_risk +\n            weights[\"market_volatility\"] * market_risk\n        )\n    \n    def _calculate_fault_proximity_risk(self,\n                                     latitude: float,\n                                     longitude: float,\n                                     geological_features: pd.DataFrame) -> float:\n        \"\"\"Calculate risk based on proximity to geological faults\"\"\"\n        if geological_features.empty:\n            return 0.5  # Default moderate risk when no data\n            \n        # Filter for fault features\n        faults = geological_features[\n            geological_features['feature_type'] == 'fault'\n        ]\n        \n        if faults.empty:\n            return 0.3  # Lower risk when no faults present\n            \n        # Calculate distances to all faults\n        distances = self._calculate_distances(\n            faults['latitude'].values,\n            faults['longitude'].values,\n            latitude,\n            longitude\n        )\n        \n        # Risk increases with proximity to faults\n        min_distance = np.min(distances)\n        return 1.0 - np.clip(min_distance / 10.0, 0.0, 1.0)  # Risk decreases up to 10km\n    \n    def _calculate_structural_complexity(self,\n                                      geological_features: pd.DataFrame) -> float:\n        \"\"\"Calculate risk based on structural complexity\"\"\"\n        if geological_features.empty:\n            return 0.5\n            \n        # Count different feature types\n        feature_counts = geological_features['feature_type'].value_counts()\n        \n        # More feature types indicate higher complexity\n        complexity = len(feature_counts) / 5.0  # Normalize by expected max types\n        return np.clip(complexity, 0.0, 1.0)\n    \n    def _calculate_deposit_uncertainty(self,\n                                    latitude: float,\n                                    longitude: float,\n                                    deposits: pd.DataFrame) -> float:\n        \"\"\"Calculate risk based on deposit uncertainty\"\"\"\n        if deposits.empty:\n            return 0.8  # High risk when no known deposits\n            \n        # Calculate distances to confirmed deposits\n        confirmed = deposits[deposits['is_confirmed']]\n        if confirmed.empty:\n            return 0.7  # High risk when no confirmed deposits\n            \n        distances = self._calculate_distances(\n            confirmed['latitude'].values,\n            confirmed['longitude'].values,\n            latitude,\n            longitude\n        )\n        \n        # Risk increases with distance to nearest confirmed deposit\n        min_distance = np.min(distances)\n        return np.clip(min_distance / 20.0, 0.0, 1.0)  # Risk increases up to 20km\n    \n    def _calculate_water_proximity_risk(self,\n                                     latitude: float,\n                                     longitude: float,\n                                     properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on proximity to water bodies\"\"\"\n        if not properties or 'water_distance_km' not in properties:\n            return 0.5\n            \n        distance = properties['water_distance_km']\n        return np.clip(1.0 - distance / 5.0, 0.0, 1.0)  # Risk decreases up to 5km\n    \n    def _calculate_protected_areas_risk(self,\n                                      latitude: float,\n                                      longitude: float,\n                                      properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on proximity to protected areas\"\"\"\n        if not properties or 'protected_distance_km' not in properties:\n            return 0.5\n            \n        distance = properties['protected_distance_km']\n        return np.clip(1.0 - distance / 10.0, 0.0, 1.0)  # Risk decreases up to 10km\n    \n    def _calculate_ecosystem_sensitivity(self,\n                                      latitude: float,\n                                      longitude: float,\n                                      properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on ecosystem sensitivity\"\"\"\n        if not properties or 'ecosystem_sensitivity' not in properties:\n            return 0.5\n            \n        sensitivity_map = {\n            'low': 0.2,\n            'moderate': 0.5,\n            'high': 0.8,\n            'critical': 1.0\n        }\n        \n        return sensitivity_map.get(\n            properties['ecosystem_sensitivity'].lower(),\n            0.5\n        )\n    \n    def _calculate_depth_complexity_risk(self,\n                                      properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on deposit depth and complexity\"\"\"\n        if not properties or 'depth_meters' not in properties:\n            return 0.5\n            \n        depth = properties['depth_meters']\n        return np.clip(depth / 1000.0, 0.0, 1.0)  # Risk increases with depth\n    \n    def _calculate_infrastructure_risk(self,\n                                    latitude: float,\n                                    longitude: float,\n                                    properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on infrastructure access\"\"\"\n        if not properties or 'infrastructure_distance_km' not in properties:\n            return 0.5\n            \n        distance = properties['infrastructure_distance_km']\n        return np.clip(distance / 50.0, 0.0, 1.0)  # Risk increases up to 50km\n    \n    def _calculate_terrain_risk(self,\n                              latitude: float,\n                              longitude: float,\n                              properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on terrain difficulty\"\"\"\n        if not properties or 'terrain_difficulty' not in properties:\n            return 0.5\n            \n        difficulty_map = {\n            'easy': 0.2,\n            'moderate': 0.5,\n            'difficult': 0.8,\n            'extreme': 1.0\n        }\n        \n        return difficulty_map.get(\n            properties['terrain_difficulty'].lower(),\n            0.5\n        )\n    \n    def _calculate_grade_risk(self,\n                            deposits: pd.DataFrame,\n                            properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on resource grade\"\"\"\n        if not properties or 'estimated_grade' not in properties:\n            return 0.5\n            \n        grade_map = {\n            'high': 0.2,\n            'medium': 0.5,\n            'low': 0.8,\n            'unknown': 1.0\n        }\n        \n        return grade_map.get(\n            properties['estimated_grade'].lower(),\n            0.5\n        )\n    \n    def _calculate_extraction_cost_risk(self,\n                                     properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on extraction costs\"\"\"\n        if not properties or 'extraction_cost_category' not in properties:\n            return 0.5\n            \n        cost_map = {\n            'low': 0.2,\n            'moderate': 0.5,\n            'high': 0.8,\n            'very_high': 1.0\n        }\n        \n        return cost_map.get(\n            properties['extraction_cost_category'].lower(),\n            0.5\n        )\n    \n    def _calculate_market_risk(self,\n                             properties: Optional[Dict]) -> float:\n        \"\"\"Calculate risk based on market conditions\"\"\"\n        if not properties or 'market_volatility' not in properties:\n            return 0.5\n            \n        volatility_map = {\n            'stable': 0.2,\n            'moderate': 0.5,\n            'volatile': 0.8,\n            'highly_volatile': 1.0\n        }\n        \n        return volatility_map.get(\n            properties['market_volatility'].lower(),\n            0.5\n        )\n    \n    def _calculate_distances(self,\n                           lat1: np.ndarray,\n                           lon1: np.ndarray,\n                           lat2: float,\n                           lon2: float) -> np.ndarray:\n        \"\"\"Calculate distances using Haversine formula\"\"\"\n        R = 6371  # Earth's radius in kilometers\n        \n        lat1_rad = np.radians(lat1)\n        lon1_rad = np.radians(lon1)\n        lat2_rad = np.radians(lat2)\n        lon2_rad = np.radians(lon2)\n        \n        dlat = lat2_rad - lat1_rad\n        dlon = lon2_rad - lon1_rad\n        \n        a = np.sin(dlat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2)**2\n        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n        \n        return R * c "}
{"type": "source_file", "path": "minesight/core/monitoring/monitor.py", "content": "\"\"\"\nReal-time monitoring and alerting system for mineral exploration\n\"\"\"\nfrom typing import Dict, List, Optional, Any\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport pandas as pd\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass AlertLevel(Enum):\n    \"\"\"Alert level definitions\"\"\"\n    INFO = \"info\"\n    WARNING = \"warning\"\n    CRITICAL = \"critical\"\n\n@dataclass\nclass Alert:\n    \"\"\"Alert definition\"\"\"\n    alert_id: str\n    timestamp: datetime\n    level: AlertLevel\n    category: str\n    message: str\n    location: Optional[Dict[str, float]] = None\n    metadata: Optional[Dict[str, Any]] = None\n\nclass MonitoringSystem:\n    \"\"\"Class for real-time monitoring and alerting\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the monitoring system\"\"\"\n        self.alerts = []\n        self.metrics = {}\n        self.thresholds = {\n            \"risk_score\": 0.7,\n            \"anomaly_threshold\": 2.0,\n            \"activity_gap_days\": 7,\n            \"resource_utilization\": 0.8\n        }\n    \n    def monitor_exploration_activities(self,\n                                    activities: List[Dict[str, Any]],\n                                    resources: Dict[str, Any],\n                                    risk_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Monitor ongoing exploration activities\n        \n        Args:\n            activities: List of current exploration activities\n            resources: Current resource status\n            risk_data: Current risk assessment data\n            \n        Returns:\n            Monitoring results and alerts\n        \"\"\"\n        # Check various monitoring aspects\n        risk_alerts = self._monitor_risks(risk_data)\n        activity_alerts = self._monitor_activities(activities)\n        resource_alerts = self._monitor_resources(resources)\n        anomaly_alerts = self._detect_anomalies(activities)\n        \n        # Update metrics\n        self._update_metrics(activities, resources, risk_data)\n        \n        # Combine all alerts\n        all_alerts = [\n            *risk_alerts,\n            *activity_alerts,\n            *resource_alerts,\n            *anomaly_alerts\n        ]\n        \n        # Sort alerts by timestamp and level\n        sorted_alerts = sorted(\n            all_alerts,\n            key=lambda x: (x.timestamp, x.level.value),\n            reverse=True\n        )\n        \n        return {\n            \"alerts\": [self._alert_to_dict(alert) for alert in sorted_alerts],\n            \"metrics\": self.metrics,\n            \"status_summary\": self._generate_status_summary()\n        }\n    \n    def _monitor_risks(self, risk_data: Dict[str, Any]) -> List[Alert]:\n        \"\"\"Monitor risk levels and generate alerts\"\"\"\n        alerts = []\n        timestamp = datetime.now()\n        \n        # Check overall risk\n        if risk_data.get(\"overall_risk\", 0) > self.thresholds[\"risk_score\"]:\n            alerts.append(Alert(\n                alert_id=f\"risk_{timestamp.timestamp()}\",\n                timestamp=timestamp,\n                level=AlertLevel.CRITICAL,\n                category=\"risk\",\n                message=f\"High overall risk detected: {risk_data['overall_risk']:.2f}\",\n                metadata={\"risk_scores\": risk_data}\n            ))\n        \n        # Check individual risk components\n        for risk_type in [\"geological\", \"environmental\", \"technical\", \"economic\"]:\n            risk_key = f\"{risk_type}_risk\"\n            if risk_data.get(risk_key, 0) > self.thresholds[\"risk_score\"]:\n                alerts.append(Alert(\n                    alert_id=f\"{risk_type}_{timestamp.timestamp()}\",\n                    timestamp=timestamp,\n                    level=AlertLevel.WARNING,\n                    category=\"risk\",\n                    message=f\"High {risk_type} risk detected: {risk_data[risk_key]:.2f}\"\n                ))\n        \n        return alerts\n    \n    def _monitor_activities(self, activities: List[Dict[str, Any]]) -> List[Alert]:\n        \"\"\"Monitor exploration activities and generate alerts\"\"\"\n        alerts = []\n        timestamp = datetime.now()\n        \n        # Check for inactive sites\n        for activity in activities:\n            last_update = activity.get(\"last_update\")\n            if last_update:\n                last_update = pd.to_datetime(last_update)\n                days_inactive = (timestamp - last_update).days\n                \n                if days_inactive > self.thresholds[\"activity_gap_days\"]:\n                    alerts.append(Alert(\n                        alert_id=f\"inactive_{timestamp.timestamp()}\",\n                        timestamp=timestamp,\n                        level=AlertLevel.WARNING,\n                        category=\"activity\",\n                        message=f\"Site inactive for {days_inactive} days\",\n                        location=activity.get(\"location\"),\n                        metadata={\"activity_id\": activity.get(\"id\")}\n                    ))\n        \n        # Check for overdue tasks\n        for activity in activities:\n            if activity.get(\"status\") == \"in_progress\":\n                if activity.get(\"end_date\"):\n                    end_date = pd.to_datetime(activity.get(\"end_date\"))\n                    if end_date < timestamp:\n                        alerts.append(Alert(\n                            alert_id=f\"overdue_{timestamp.timestamp()}\",\n                            timestamp=timestamp,\n                            level=AlertLevel.WARNING,\n                            category=\"activity\",\n                            message=\"Task is overdue\",\n                            location=activity.get(\"location\"),\n                            metadata={\"activity_id\": activity.get(\"id\")}\n                        ))\n        \n        return alerts\n    \n    def _monitor_resources(self, resources: Dict[str, Any]) -> List[Alert]:\n        \"\"\"Monitor resource utilization and generate alerts\"\"\"\n        alerts = []\n        timestamp = datetime.now()\n        \n        # Check resource utilization\n        for resource_type, details in resources.items():\n            utilization = details.get(\"utilization\", 0)\n            if utilization > self.thresholds[\"resource_utilization\"]:\n                alerts.append(Alert(\n                    alert_id=f\"resource_{timestamp.timestamp()}\",\n                    timestamp=timestamp,\n                    level=AlertLevel.WARNING,\n                    category=\"resource\",\n                    message=f\"High {resource_type} utilization: {utilization:.1%}\",\n                    metadata={\"resource_type\": resource_type}\n                ))\n        \n        # Check resource availability\n        for resource_type, details in resources.items():\n            if not details.get(\"available\", True):\n                alerts.append(Alert(\n                    alert_id=f\"unavailable_{timestamp.timestamp()}\",\n                    timestamp=timestamp,\n                    level=AlertLevel.CRITICAL,\n                    category=\"resource\",\n                    message=f\"{resource_type} is currently unavailable\",\n                    metadata={\"resource_type\": resource_type}\n                ))\n        \n        return alerts\n    \n    def _detect_anomalies(self, activities: List[Dict[str, Any]]) -> List[Alert]:\n        \"\"\"Detect anomalies in exploration data\"\"\"\n        alerts = []\n        timestamp = datetime.now()\n        \n        # Convert activities to DataFrame for analysis\n        if not activities:\n            return alerts\n            \n        df = pd.DataFrame(activities)\n        \n        # Check for unusual patterns in measurements\n        if \"measurements\" in df.columns:\n            measurements = np.array([\n                m.get(\"value\", 0)\n                for m in df[\"measurements\"].dropna()\n            ])\n            \n            if len(measurements) > 0:\n                mean = np.mean(measurements)\n                std = np.std(measurements)\n                \n                # Detect outliers\n                outliers = measurements[\n                    abs(measurements - mean) > self.thresholds[\"anomaly_threshold\"] * std\n                ]\n                \n                if len(outliers) > 0:\n                    alerts.append(Alert(\n                        alert_id=f\"anomaly_{timestamp.timestamp()}\",\n                        timestamp=timestamp,\n                        level=AlertLevel.WARNING,\n                        category=\"anomaly\",\n                        message=f\"Detected {len(outliers)} anomalous measurements\",\n                        metadata={\n                            \"mean\": float(mean),\n                            \"std\": float(std),\n                            \"outliers\": [float(x) for x in outliers]\n                        }\n                    ))\n        \n        return alerts\n    \n    def _update_metrics(self,\n                       activities: List[Dict[str, Any]],\n                       resources: Dict[str, Any],\n                       risk_data: Dict[str, Any]):\n        \"\"\"Update monitoring metrics\"\"\"\n        timestamp = datetime.now()\n        \n        # Activity metrics\n        total_activities = len(activities)\n        active_activities = sum(\n            1 for a in activities\n            if a.get(\"status\") == \"in_progress\"\n        )\n        completed_activities = sum(\n            1 for a in activities\n            if a.get(\"status\") == \"completed\"\n        )\n        \n        # Resource metrics\n        resource_utilization = {\n            r_type: details.get(\"utilization\", 0)\n            for r_type, details in resources.items()\n        }\n        \n        # Risk metrics\n        risk_levels = {\n            k: v for k, v in risk_data.items()\n            if k.endswith(\"_risk\")\n        }\n        \n        # Update metrics dictionary\n        self.metrics = {\n            \"timestamp\": timestamp,\n            \"activities\": {\n                \"total\": total_activities,\n                \"active\": active_activities,\n                \"completed\": completed_activities,\n                \"completion_rate\": completed_activities / total_activities if total_activities > 0 else 0\n            },\n            \"resources\": {\n                \"utilization\": resource_utilization,\n                \"availability\": {\n                    r_type: details.get(\"available\", True)\n                    for r_type, details in resources.items()\n                }\n            },\n            \"risks\": risk_levels\n        }\n    \n    def _generate_status_summary(self) -> Dict[str, Any]:\n        \"\"\"Generate overall status summary\"\"\"\n        if not self.metrics:\n            return {\n                \"status\": \"unknown\",\n                \"message\": \"No monitoring data available\"\n            }\n        \n        # Determine overall status\n        critical_alerts = sum(\n            1 for alert in self.alerts\n            if alert.level == AlertLevel.CRITICAL\n        )\n        warning_alerts = sum(\n            1 for alert in self.alerts\n            if alert.level == AlertLevel.WARNING\n        )\n        \n        if critical_alerts > 0:\n            status = \"critical\"\n            message = f\"{critical_alerts} critical alerts active\"\n        elif warning_alerts > 0:\n            status = \"warning\"\n            message = f\"{warning_alerts} warnings active\"\n        else:\n            status = \"normal\"\n            message = \"All systems normal\"\n        \n        return {\n            \"status\": status,\n            \"message\": message,\n            \"last_update\": self.metrics.get(\"timestamp\"),\n            \"active_alerts\": critical_alerts + warning_alerts\n        }\n    \n    def _alert_to_dict(self, alert: Alert) -> Dict[str, Any]:\n        \"\"\"Convert Alert object to dictionary\"\"\"\n        return {\n            \"alert_id\": alert.alert_id,\n            \"timestamp\": alert.timestamp.isoformat(),\n            \"level\": alert.level.value,\n            \"category\": alert.category,\n            \"message\": alert.message,\n            \"location\": alert.location,\n            \"metadata\": alert.metadata\n        } "}
{"type": "source_file", "path": "minesight/core/ai/model.py", "content": "import torch\nimport torch.nn as nn\nfrom typing import List, Dict, Any\nimport numpy as np\n\nclass MineralExplorationModel(nn.Module):\n    def __init__(self, input_features: int, hidden_dim: int = 256):\n        super(MineralExplorationModel, self).__init__()\n        \n        self.feature_extractor = nn.Sequential(\n            nn.Linear(input_features, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        \n        self.mineral_classifier = nn.Sequential(\n            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 4, 1),\n            nn.Sigmoid()\n        )\n        \n        self.confidence_estimator = nn.Sequential(\n            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 4, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        features = self.feature_extractor(x)\n        probability = self.mineral_classifier(features)\n        confidence = self.confidence_estimator(features)\n        \n        return {\n            \"probability\": probability,\n            \"confidence\": confidence\n        }\n\nclass MineralPredictor:\n    def __init__(self, model_path: str = None):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model = None\n        self.feature_processor = None\n        \n        if model_path:\n            self.load_model(model_path)\n\n    def load_model(self, model_path: str):\n        \"\"\"Load a trained model from disk\"\"\"\n        try:\n            checkpoint = torch.load(model_path, map_location=self.device)\n            self.model = MineralExplorationModel(\n                input_features=checkpoint['input_features'],\n                hidden_dim=checkpoint['hidden_dim']\n            )\n            self.model.load_state_dict(checkpoint['model_state_dict'])\n            self.model.to(self.device)\n            self.model.eval()\n        except Exception as e:\n            raise Exception(f\"Failed to load model: {str(e)}\")\n\n    def preprocess_features(self, location: Dict[str, float], geological_data: Dict[str, Any]) -> torch.Tensor:\n        \"\"\"Convert raw input data into model features\"\"\"\n        # TODO: Implement feature preprocessing\n        # This is a placeholder implementation\n        features = [\n            location['latitude'],\n            location['longitude'],\n            location.get('depth', 0.0),\n            # Add more features from geological_data\n        ]\n        return torch.tensor(features, dtype=torch.float32, device=self.device)\n\n    def predict(self, location: Dict[str, float], geological_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Make a prediction for a given location\"\"\"\n        if self.model is None:\n            raise Exception(\"Model not loaded\")\n\n        with torch.no_grad():\n            features = self.preprocess_features(location, geological_data)\n            predictions = self.model(features.unsqueeze(0))\n            \n            return {\n                \"probability\": predictions[\"probability\"].item(),\n                \"confidence\": predictions[\"confidence\"].item()\n            }\n\n    def batch_predict(self, locations: List[Dict[str, float]], geological_data: List[Dict[str, Any]]) -> List[Dict[str, float]]:\n        \"\"\"Make predictions for multiple locations\"\"\"\n        if self.model is None:\n            raise Exception(\"Model not loaded\")\n\n        with torch.no_grad():\n            features = torch.stack([\n                self.preprocess_features(loc, geo)\n                for loc, geo in zip(locations, geological_data)\n            ])\n            predictions = self.model(features)\n            \n            return [\n                {\n                    \"probability\": prob.item(),\n                    \"confidence\": conf.item()\n                }\n                for prob, conf in zip(\n                    predictions[\"probability\"],\n                    predictions[\"confidence\"]\n                )\n            ] "}
{"type": "source_file", "path": "minesight/core/ai/deep_learning.py", "content": "\"\"\"\nDeep learning analysis module for mineral exploration\n\"\"\"\nfrom typing import Dict, List, Any, Optional, Tuple\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport plotly.graph_objects as go\nfrom datetime import datetime\nfrom pathlib import Path\nimport json\n\nclass DeepLearningAnalyzer:\n    \"\"\"Class for advanced deep learning analysis of mineral exploration data\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer\"\"\"\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.scaler = StandardScaler()\n        self.output_dir = Path(\"visualizations\")\n        self.models_dir = Path(\"models\")\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.models_dir.mkdir(parents=True, exist_ok=True)\n        \n    def save_model(self,\n                  model: nn.Module,\n                  model_name: str,\n                  metadata: Optional[Dict[str, Any]] = None) -> Path:\n        \"\"\"\n        Save model and its metadata\n        \n        Args:\n            model: Neural network model to save\n            model_name: Name of the model\n            metadata: Optional metadata about the model\n            \n        Returns:\n            Path to saved model directory\n        \"\"\"\n        # Create model directory\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        model_dir = self.models_dir / f\"{model_name}_{timestamp}\"\n        model_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Save model state\n        model_path = model_dir / \"model.pt\"\n        torch.save(model.state_dict(), model_path)\n        \n        # Save scaler\n        scaler_path = model_dir / \"scaler.pkl\"\n        pd.to_pickle(self.scaler, scaler_path)\n        \n        # Save metadata\n        if metadata:\n            metadata_path = model_dir / \"metadata.json\"\n            with open(metadata_path, 'w') as f:\n                json.dump(metadata, f, indent=2)\n        \n        return model_dir\n    \n    def load_model(self,\n                  model: nn.Module,\n                  model_path: Path) -> Tuple[nn.Module, Dict[str, Any]]:\n        \"\"\"\n        Load model and its metadata\n        \n        Args:\n            model: Neural network model architecture\n            model_path: Path to model directory\n            \n        Returns:\n            Tuple of (loaded model, metadata)\n        \"\"\"\n        # Load model state\n        state_dict_path = model_path / \"model.pt\"\n        model.load_state_dict(torch.load(state_dict_path))\n        model.to(self.device)\n        \n        # Load scaler\n        scaler_path = model_path / \"scaler.pkl\"\n        self.scaler = pd.read_pickle(scaler_path)\n        \n        # Load metadata\n        metadata = {}\n        metadata_path = model_path / \"metadata.json\"\n        if metadata_path.exists():\n            with open(metadata_path, 'r') as f:\n                metadata = json.load(f)\n        \n        return model, metadata\n    \n    def get_available_models(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get list of available saved models\n        \n        Returns:\n            List of dictionaries containing model info\n        \"\"\"\n        models = []\n        \n        for model_dir in self.models_dir.glob(\"*\"):\n            if model_dir.is_dir():\n                model_info = {\n                    \"name\": model_dir.name,\n                    \"path\": str(model_dir),\n                    \"created\": datetime.fromtimestamp(\n                        model_dir.stat().st_ctime\n                    ).strftime(\"%Y-%m-%d %H:%M:%S\")\n                }\n                \n                # Add metadata if available\n                metadata_path = model_dir / \"metadata.json\"\n                if metadata_path.exists():\n                    with open(metadata_path, 'r') as f:\n                        model_info[\"metadata\"] = json.load(f)\n                \n                models.append(model_info)\n        \n        return sorted(models, key=lambda x: x[\"created\"], reverse=True)\n    \n    def filter_data(self, data: pd.DataFrame, filters: Dict[str, Any]) -> pd.DataFrame:\n        \"\"\"\n        Apply filters to input data\n        \n        Args:\n            data: Input DataFrame\n            filters: Dictionary of filter conditions\n            \n        Returns:\n            Filtered DataFrame\n        \"\"\"\n        filtered_data = data.copy()\n        \n        for column, condition in filters.items():\n            if column in filtered_data.columns:\n                if isinstance(condition, (list, tuple)):\n                    filtered_data = filtered_data[\n                        filtered_data[column].isin(condition)\n                    ]\n                elif isinstance(condition, dict):\n                    if \"min\" in condition:\n                        filtered_data = filtered_data[\n                            filtered_data[column] >= condition[\"min\"]\n                        ]\n                    if \"max\" in condition:\n                        filtered_data = filtered_data[\n                            filtered_data[column] <= condition[\"max\"]\n                        ]\n                else:\n                    filtered_data = filtered_data[\n                        filtered_data[column] == condition\n                    ]\n                    \n        return filtered_data\n    \n    def prepare_data(self,\n                    deposits: pd.DataFrame,\n                    features: pd.DataFrame,\n                    region: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"\n        Prepare data for deep learning analysis\n        \n        Args:\n            deposits: DataFrame of mineral deposits\n            features: DataFrame of geological features\n            region: Region bounds for analysis\n            \n        Returns:\n            Dictionary with prepared data\n        \"\"\"\n        # Filter data by region\n        deposits = self._filter_by_region(deposits, region)\n        features = self._filter_by_region(features, region)\n        \n        # Extract features\n        X = self._extract_features(deposits, features)\n        y = self._extract_labels(deposits)\n        \n        # Scale features\n        X_scaled = self.scaler.fit_transform(X)\n        \n        # Convert to tensors\n        X_tensor = torch.FloatTensor(X_scaled).to(self.device)\n        y_tensor = torch.FloatTensor(y).to(self.device)\n        \n        return {\n            \"X\": X_tensor,\n            \"y\": y_tensor,\n            \"n_features\": X.shape[1],\n            \"feature_names\": self._get_feature_names(deposits, features)\n        }\n    \n    def predict_deposits(self,\n                        model: nn.Module,\n                        input_data: Dict[str, Any],\n                        region: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"\n        Predict mineral deposits in the region\n        \n        Args:\n            model: Neural network model\n            input_data: Prepared input data\n            region: Region bounds for analysis\n            \n        Returns:\n            Dictionary with prediction results\n        \"\"\"\n        # Train model\n        model = self._train_model(model, input_data)\n        \n        # Generate grid points\n        grid_points = self._generate_grid_points(region)\n        grid_features = self._extract_features_for_grid(grid_points, input_data)\n        \n        # Make predictions\n        with torch.no_grad():\n            predictions = model(grid_features)\n            \n        # Calculate metrics\n        metrics = self._calculate_metrics(model, input_data)\n        \n        # Get feature importance\n        importance = self._calculate_feature_importance(\n            model,\n            input_data[\"feature_names\"]\n        )\n        \n        return {\n            \"analysis\": {\n                \"high_potential_areas\": self._identify_high_potential_areas(\n                    grid_points,\n                    predictions\n                ),\n                \"confidence_levels\": self._calculate_confidence_levels(predictions)\n            },\n            \"metrics\": metrics,\n            \"importance\": importance,\n            \"predictions\": [\n                {\n                    \"location\": point,\n                    \"probability\": float(prob),\n                    \"confidence\": float(conf)\n                }\n                for point, prob, conf in zip(\n                    grid_points,\n                    predictions[\"probability\"],\n                    predictions[\"confidence\"]\n                )\n            ]\n        }\n    \n    def extract_features(self,\n                        model: nn.Module,\n                        input_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Extract and analyze features using deep learning\n        \n        Args:\n            model: Neural network model\n            input_data: Prepared input data\n            \n        Returns:\n            Dictionary with feature analysis results\n        \"\"\"\n        # Train model\n        model = self._train_model(model, input_data)\n        \n        # Extract intermediate features\n        features = model.feature_extractor(input_data[\"X\"])\n        \n        # Analyze feature patterns\n        patterns = self._analyze_feature_patterns(features)\n        \n        # Calculate feature correlations\n        correlations = self._calculate_feature_correlations(\n            features,\n            input_data[\"feature_names\"]\n        )\n        \n        return {\n            \"analysis\": {\n                \"feature_patterns\": patterns,\n                \"feature_correlations\": correlations\n            },\n            \"metrics\": self._calculate_metrics(model, input_data),\n            \"importance\": self._calculate_feature_importance(\n                model,\n                input_data[\"feature_names\"]\n            ),\n            \"predictions\": []\n        }\n    \n    def recognize_patterns(self,\n                         model: nn.Module,\n                         input_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Recognize geological patterns using deep learning\n        \n        Args:\n            model: Neural network model\n            input_data: Prepared input data\n            \n        Returns:\n            Dictionary with pattern recognition results\n        \"\"\"\n        # Train model\n        model = self._train_model(model, input_data)\n        \n        # Extract features\n        features = model.feature_extractor(input_data[\"X\"])\n        \n        # Identify patterns\n        patterns = self._identify_patterns(features)\n        \n        # Analyze pattern significance\n        significance = self._analyze_pattern_significance(\n            patterns,\n            input_data[\"y\"]\n        )\n        \n        return {\n            \"analysis\": {\n                \"patterns\": patterns,\n                \"pattern_significance\": significance\n            },\n            \"metrics\": self._calculate_metrics(model, input_data),\n            \"importance\": self._calculate_feature_importance(\n                model,\n                input_data[\"feature_names\"]\n            ),\n            \"predictions\": []\n        }\n    \n    def detect_anomalies(self,\n                        model: nn.Module,\n                        input_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Detect geological anomalies using deep learning\n        \n        Args:\n            model: Neural network model\n            input_data: Prepared input data\n            \n        Returns:\n            Dictionary with anomaly detection results\n        \"\"\"\n        # Train model\n        model = self._train_model(model, input_data)\n        \n        # Calculate reconstruction error\n        features = model.feature_extractor(input_data[\"X\"])\n        reconstruction_error = self._calculate_reconstruction_error(\n            input_data[\"X\"],\n            features\n        )\n        \n        # Detect anomalies\n        anomalies = self._detect_anomalies_from_error(reconstruction_error)\n        \n        return {\n            \"analysis\": {\n                \"anomalies\": anomalies,\n                \"reconstruction_error\": reconstruction_error.tolist()\n            },\n            \"metrics\": self._calculate_metrics(model, input_data),\n            \"importance\": self._calculate_feature_importance(\n                model,\n                input_data[\"feature_names\"]\n            ),\n            \"predictions\": []\n        }\n    \n    def generate_visualizations(self,\n                              results: Dict[str, Any],\n                              region: Dict[str, float]) -> Dict[str, str]:\n        \"\"\"\n        Generate visualizations for analysis results\n        \n        Args:\n            results: Analysis results\n            region: Region bounds for analysis\n            \n        Returns:\n            Dictionary with visualization file paths\n        \"\"\"\n        visualizations = {}\n        \n        # Create prediction heatmap\n        if results[\"predictions\"]:\n            heatmap_path = self._create_prediction_heatmap(\n                results[\"predictions\"],\n                region\n            )\n            visualizations[\"prediction_heatmap\"] = str(heatmap_path)\n        \n        # Create feature importance plot\n        if results[\"importance\"]:\n            importance_path = self._create_feature_importance_plot(\n                results[\"importance\"]\n            )\n            visualizations[\"feature_importance\"] = str(importance_path)\n        \n        # Create additional visualizations based on analysis type\n        if \"patterns\" in results[\"analysis\"]:\n            pattern_path = self._create_pattern_visualization(\n                results[\"analysis\"][\"patterns\"]\n            )\n            visualizations[\"pattern_analysis\"] = str(pattern_path)\n            \n        if \"anomalies\" in results[\"analysis\"]:\n            anomaly_path = self._create_anomaly_visualization(\n                results[\"analysis\"][\"anomalies\"]\n            )\n            visualizations[\"anomaly_detection\"] = str(anomaly_path)\n        \n        return visualizations\n    \n    def _filter_by_region(self,\n                         data: pd.DataFrame,\n                         region: Dict[str, float]) -> pd.DataFrame:\n        \"\"\"Filter data by region bounds\"\"\"\n        return data[\n            (data[\"latitude\"] >= region[\"min_lat\"]) &\n            (data[\"latitude\"] <= region[\"max_lat\"]) &\n            (data[\"longitude\"] >= region[\"min_lon\"]) &\n            (data[\"longitude\"] <= region[\"max_lon\"])\n        ]\n    \n    def _extract_features(self,\n                         deposits: pd.DataFrame,\n                         features: pd.DataFrame) -> np.ndarray:\n        \"\"\"\n        Extract features from deposits and geological features\n        \n        Args:\n            deposits: DataFrame of mineral deposits\n            features: DataFrame of geological features\n            \n        Returns:\n            Array of extracted features\n        \"\"\"\n        # Geological features\n        geological_features = [\n            'lithology',\n            'structure',\n            'alteration',\n            'mineralization',\n            'geochemistry'\n        ]\n        \n        # Geophysical features\n        geophysical_features = [\n            'magnetic',\n            'gravity',\n            'electromagnetic',\n            'radiometric'\n        ]\n        \n        # Extract and combine features\n        feature_matrix = []\n        \n        for _, deposit in deposits.iterrows():\n            deposit_features = []\n            \n            # Get geological features near deposit\n            nearby_features = self._get_nearby_features(\n                deposit,\n                features,\n                radius_km=5\n            )\n            \n            # Add geological features\n            for feature in geological_features:\n                if feature in nearby_features.columns:\n                    deposit_features.extend(\n                        self._encode_geological_feature(\n                            nearby_features[feature].values\n                        )\n                    )\n                    \n            # Add geophysical features\n            for feature in geophysical_features:\n                if feature in nearby_features.columns:\n                    deposit_features.extend(\n                        self._encode_geophysical_feature(\n                            nearby_features[feature].values\n                        )\n                    )\n            \n            feature_matrix.append(deposit_features)\n        \n        return np.array(feature_matrix)\n    \n    def _extract_labels(self, deposits: pd.DataFrame) -> np.ndarray:\n        \"\"\"Extract labels for model training\"\"\"\n        # TODO: Implement label extraction\n        return np.array([])\n    \n    def _get_feature_names(self,\n                          deposits: pd.DataFrame,\n                          features: pd.DataFrame) -> List[str]:\n        \"\"\"Get list of feature names\"\"\"\n        # TODO: Implement feature name extraction\n        return []\n    \n    def _train_model(self,\n                    model: nn.Module,\n                    input_data: Dict[str, Any]) -> nn.Module:\n        \"\"\"\n        Train the neural network model\n        \n        Args:\n            model: Neural network model\n            input_data: Dictionary containing training data\n            \n        Returns:\n            Trained model\n        \"\"\"\n        X = input_data[\"X\"]\n        y = input_data[\"y\"]\n        \n        # Split data\n        X_train, X_val, y_train, y_val = train_test_split(\n            X, y, test_size=0.2, random_state=42\n        )\n        \n        # Define loss function and optimizer\n        criterion = nn.BCEWithLogitsLoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        \n        # Training parameters\n        n_epochs = 100\n        batch_size = 32\n        n_batches = len(X_train) // batch_size\n        \n        model.train()\n        for epoch in range(n_epochs):\n            total_loss = 0\n            \n            # Mini-batch training\n            for i in range(n_batches):\n                start_idx = i * batch_size\n                end_idx = start_idx + batch_size\n                \n                batch_X = X_train[start_idx:end_idx]\n                batch_y = y_train[start_idx:end_idx]\n                \n                # Forward pass\n                outputs = model(batch_X)\n                loss = criterion(outputs, batch_y)\n                \n                # Backward pass and optimize\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                \n                total_loss += loss.item()\n            \n            # Validation\n            if epoch % 10 == 0:\n                model.eval()\n                with torch.no_grad():\n                    val_outputs = model(X_val)\n                    val_loss = criterion(val_outputs, y_val)\n                model.train()\n        \n        return model\n    \n    def _generate_grid_points(self,\n                            region: Dict[str, float],\n                            resolution: float = 0.01) -> List[Dict[str, float]]:\n        \"\"\"\n        Generate grid points for prediction\n        \n        Args:\n            region: Region bounds\n            resolution: Grid resolution in degrees\n            \n        Returns:\n            List of grid points\n        \"\"\"\n        # Generate latitude and longitude ranges\n        lats = np.arange(\n            region['min_lat'],\n            region['max_lat'] + resolution,\n            resolution\n        )\n        lons = np.arange(\n            region['min_lon'],\n            region['max_lon'] + resolution,\n            resolution\n        )\n        \n        # Create grid points\n        grid_points = []\n        for lat in lats:\n            for lon in lons:\n                grid_points.append({\n                    'latitude': float(lat),\n                    'longitude': float(lon)\n                })\n        \n        return grid_points\n    \n    def _extract_features_for_grid(self,\n                                 grid_points: List[Dict[str, float]],\n                                 input_data: Dict[str, Any]) -> torch.Tensor:\n        \"\"\"Extract features for grid points\"\"\"\n        # TODO: Implement grid feature extraction\n        return torch.tensor([])\n    \n    def _calculate_metrics(self,\n                         model: nn.Module,\n                         input_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"\n        Calculate model performance metrics\n        \n        Args:\n            model: Neural network model\n            input_data: Dictionary containing validation data\n            \n        Returns:\n            Dictionary of metrics\n        \"\"\"\n        model.eval()\n        with torch.no_grad():\n            X = input_data[\"X\"]\n            y = input_data[\"y\"]\n            \n            # Get predictions\n            outputs = model(X)\n            predictions = torch.sigmoid(outputs)\n            \n            # Calculate metrics\n            metrics = {\n                \"accuracy\": self._calculate_accuracy(predictions, y),\n                \"precision\": self._calculate_precision(predictions, y),\n                \"recall\": self._calculate_recall(predictions, y),\n                \"f1_score\": self._calculate_f1_score(predictions, y),\n                \"auc_roc\": self._calculate_auc_roc(predictions, y)\n            }\n            \n        return metrics\n    \n    def _calculate_feature_importance(self,\n                                    model: nn.Module,\n                                    feature_names: List[str]) -> Dict[str, float]:\n        \"\"\"\n        Calculate feature importance using integrated gradients\n        \n        Args:\n            model: Neural network model\n            feature_names: List of feature names\n            \n        Returns:\n            Dictionary mapping feature names to importance scores\n        \"\"\"\n        model.eval()\n        importance_scores = {}\n        \n        # Get baseline (zero) input\n        baseline = torch.zeros_like(model.feature_extractor.input_layer.weight)\n        \n        # Calculate integrated gradients\n        for i, name in enumerate(feature_names):\n            # Create unit vector for this feature\n            unit_vector = torch.zeros_like(baseline)\n            unit_vector[:, i] = 1.0\n            \n            # Calculate gradients\n            integrated_grads = self._calculate_integrated_gradients(\n                model,\n                baseline,\n                unit_vector,\n                steps=50\n            )\n            \n            # Store importance score\n            importance_scores[name] = float(torch.mean(torch.abs(integrated_grads)))\n        \n        # Normalize scores\n        total = sum(importance_scores.values())\n        importance_scores = {\n            k: v/total for k, v in importance_scores.items()\n        }\n        \n        return importance_scores\n    \n    def _identify_high_potential_areas(self,\n                                     grid_points: List[Dict[str, float]],\n                                     predictions: Dict[str, torch.Tensor],\n                                     threshold: float = 0.7) -> List[Dict[str, Any]]:\n        \"\"\"\n        Identify areas with high mineral potential\n        \n        Args:\n            grid_points: List of grid points\n            predictions: Model predictions\n            threshold: Probability threshold for high potential\n            \n        Returns:\n            List of high potential areas\n        \"\"\"\n        high_potential_areas = []\n        \n        # Convert predictions to numpy\n        probs = predictions['probability'].cpu().numpy()\n        \n        # Find high probability points\n        high_prob_indices = np.where(probs > threshold)[0]\n        \n        # Cluster high probability points\n        if len(high_prob_indices) > 0:\n            # Extract coordinates\n            coords = np.array([\n                [grid_points[i]['latitude'], grid_points[i]['longitude']]\n                for i in high_prob_indices\n            ])\n            \n            # Perform DBSCAN clustering\n            from sklearn.cluster import DBSCAN\n            clustering = DBSCAN(\n                eps=0.05,  # ~5km at equator\n                min_samples=5\n            ).fit(coords)\n            \n            # Process clusters\n            unique_labels = set(clustering.labels_)\n            for label in unique_labels:\n                if label == -1:  # Skip noise points\n                    continue\n                    \n                # Get points in this cluster\n                cluster_mask = clustering.labels_ == label\n                cluster_coords = coords[cluster_mask]\n                cluster_probs = probs[high_prob_indices][cluster_mask]\n                \n                # Calculate cluster properties\n                area = {\n                    'center': {\n                        'latitude': float(np.mean(cluster_coords[:, 0])),\n                        'longitude': float(np.mean(cluster_coords[:, 1]))\n                    },\n                    'radius_km': float(self._calculate_cluster_radius(cluster_coords)),\n                    'max_probability': float(np.max(cluster_probs)),\n                    'mean_probability': float(np.mean(cluster_probs)),\n                    'point_count': int(np.sum(cluster_mask))\n                }\n                \n                high_potential_areas.append(area)\n        \n        return high_potential_areas\n\n    def _calculate_cluster_radius(self, coords: np.ndarray) -> float:\n        \"\"\"\n        Calculate approximate radius of a cluster in kilometers\n        \n        Args:\n            coords: Array of coordinates (latitude, longitude)\n            \n        Returns:\n            Radius in kilometers\n        \"\"\"\n        if len(coords) < 2:\n            return 0.0\n            \n        # Calculate center point\n        center = np.mean(coords, axis=0)\n        \n        # Calculate distances from center to all points\n        distances = [\n            self._haversine_distance(\n                center[0], center[1],\n                coord[0], coord[1]\n            )\n            for coord in coords\n        ]\n        \n        # Use 95th percentile as radius\n        return float(np.percentile(distances, 95))\n\n    def _calculate_confidence_levels(self,\n                                  predictions: Dict[str, torch.Tensor]) -> Dict[str, float]:\n        \"\"\"\n        Calculate confidence levels for predictions\n        \n        Args:\n            predictions: Model predictions\n            \n        Returns:\n            Dictionary of confidence metrics\n        \"\"\"\n        # Get probabilities\n        probs = predictions['probability'].cpu().numpy()\n        \n        # Calculate confidence metrics\n        confidence = {\n            'mean_confidence': float(np.mean(probs)),\n            'high_confidence_ratio': float(np.mean(probs > 0.8)),\n            'uncertainty': float(np.std(probs)),\n            'entropy': float(self._calculate_prediction_entropy(probs))\n        }\n        \n        return confidence\n\n    def _calculate_prediction_entropy(self, probabilities: np.ndarray) -> float:\n        \"\"\"\n        Calculate entropy of predictions as uncertainty measure\n        \n        Args:\n            probabilities: Array of prediction probabilities\n            \n        Returns:\n            Entropy value\n        \"\"\"\n        # Clip probabilities to avoid log(0)\n        probs = np.clip(probabilities, 1e-10, 1.0)\n        \n        # Calculate binary entropy\n        entropy = -np.mean(\n            probs * np.log2(probs) +\n            (1 - probs) * np.log2(1 - probs)\n        )\n        \n        return entropy\n\n    def analyze_spatial_patterns(self,\n                               predictions: Dict[str, Any],\n                               region: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze spatial patterns in predictions\n        \n        Args:\n            predictions: Prediction results\n            region: Region bounds\n            \n        Returns:\n            Dictionary with spatial analysis results\n        \"\"\"\n        # Extract prediction data\n        grid_points = predictions['grid_points']\n        probs = predictions['predictions']['probability']\n        \n        # Identify clusters\n        clusters = self._identify_high_potential_areas(\n            grid_points,\n            {'probability': torch.tensor(probs)}\n        )\n        \n        # Calculate spatial statistics\n        spatial_stats = {\n            'global_moran_i': self._calculate_global_moran_i(\n                grid_points,\n                probs\n            ),\n            'hotspots': self._identify_hotspots(\n                grid_points,\n                probs\n            ),\n            'directional_trends': self._analyze_directional_trends(\n                grid_points,\n                probs\n            )\n        }\n        \n        return {\n            'clusters': clusters,\n            'spatial_statistics': spatial_stats,\n            'region_summary': self._summarize_region(\n                clusters,\n                spatial_stats,\n                region\n            )\n        }\n\n    def _calculate_global_moran_i(self,\n                                grid_points: List[Dict[str, float]],\n                                values: np.ndarray) -> float:\n        \"\"\"Calculate Global Moran's I statistic\"\"\"\n        from scipy.spatial.distance import cdist\n        \n        # Calculate weights matrix (inverse distance)\n        coords = np.array([\n            [p['latitude'], p['longitude']]\n            for p in grid_points\n        ])\n        distances = cdist(coords, coords)\n        weights = 1 / (distances + 1e-10)  # Avoid division by zero\n        np.fill_diagonal(weights, 0)\n        \n        # Standardize values\n        z_values = (values - np.mean(values)) / np.std(values)\n        \n        # Calculate Moran's I\n        n = len(values)\n        w_sum = np.sum(weights)\n        \n        numerator = n * np.sum(weights * np.outer(z_values, z_values))\n        denominator = w_sum * np.sum(z_values ** 2)\n        \n        moran_i = numerator / denominator\n        \n        return float(moran_i)\n\n    def _identify_hotspots(self,\n                         grid_points: List[Dict[str, float]],\n                         values: np.ndarray,\n                         threshold: float = 2.0) -> List[Dict[str, Any]]:\n        \"\"\"\n        Identify statistically significant hotspots\n        \n        Args:\n            grid_points: List of grid points\n            values: Array of values\n            threshold: Z-score threshold\n            \n        Returns:\n            List of hotspots\n        \"\"\"\n        # Calculate local Getis-Ord Gi* statistic\n        from scipy.spatial.distance import cdist\n        \n        coords = np.array([\n            [p['latitude'], p['longitude']]\n            for p in grid_points\n        ])\n        \n        # Calculate weights (inverse distance)\n        distances = cdist(coords, coords)\n        weights = 1 / (distances + 1e-10)\n        np.fill_diagonal(weights, 0)\n        \n        # Standardize weights\n        weights = weights / np.sum(weights, axis=1)[:, np.newaxis]\n        \n        # Calculate Gi* statistic\n        value_mean = np.mean(values)\n        value_std = np.std(values)\n        \n        gi_star = np.sum(weights * values, axis=1) - value_mean\n        gi_star = gi_star / (value_std * np.sqrt(len(values) - 1))\n        \n        # Identify significant hotspots\n        hotspot_indices = np.where(gi_star > threshold)[0]\n        \n        hotspots = []\n        for idx in hotspot_indices:\n            hotspots.append({\n                'location': {\n                    'latitude': float(coords[idx, 0]),\n                    'longitude': float(coords[idx, 1])\n                },\n                'z_score': float(gi_star[idx]),\n                'value': float(values[idx])\n            })\n        \n        return hotspots\n\n    def _analyze_directional_trends(self,\n                                  grid_points: List[Dict[str, float]],\n                                  values: np.ndarray) -> Dict[str, float]:\n        \"\"\"\n        Analyze directional trends in the data\n        \n        Args:\n            grid_points: List of grid points\n            values: Array of values\n            \n        Returns:\n            Dictionary with directional analysis results\n        \"\"\"\n        coords = np.array([\n            [p['latitude'], p['longitude']]\n            for p in grid_points\n        ])\n        \n        # Calculate directional variograms\n        angles = [0, 45, 90, 135]  # Directions to analyze\n        trends = {}\n        \n        for angle in angles:\n            # Calculate variogram\n            variogram = self._calculate_directional_variogram(\n                coords,\n                values,\n                angle\n            )\n            \n            trends[f'angle_{angle}'] = {\n                'variogram': variogram,\n                'strength': float(np.max(variogram) - np.min(variogram)),\n                'range': float(self._estimate_variogram_range(variogram))\n            }\n        \n        # Find dominant direction\n        strengths = [trends[f'angle_{a}']['strength'] for a in angles]\n        dominant_angle = angles[np.argmax(strengths)]\n        \n        return {\n            'dominant_direction': dominant_angle,\n            'anisotropy_ratio': float(max(strengths) / (min(strengths) + 1e-10)),\n            'directional_analysis': trends\n        }\n\n    def _calculate_directional_variogram(self,\n                                       coords: np.ndarray,\n                                       values: np.ndarray,\n                                       angle: float,\n                                       tolerance: float = 22.5) -> np.ndarray:\n        \"\"\"Calculate variogram in a specific direction\"\"\"\n        # Convert angle to radians\n        angle_rad = np.radians(angle)\n        \n        # Calculate distances and angles between all points\n        dx = coords[:, np.newaxis, 0] - coords[np.newaxis, :, 0]\n        dy = coords[:, np.newaxis, 1] - coords[np.newaxis, :, 1]\n        \n        distances = np.sqrt(dx**2 + dy**2)\n        angles = np.arctan2(dy, dx)\n        \n        # Find pairs in the desired direction\n        angle_diff = np.abs(angles - angle_rad)\n        angle_diff = np.minimum(angle_diff, 2*np.pi - angle_diff)\n        direction_mask = angle_diff <= np.radians(tolerance)\n        \n        # Calculate variogram\n        value_diff = values[:, np.newaxis] - values[np.newaxis, :]\n        variogram = 0.5 * (value_diff**2 * direction_mask)\n        \n        # Average by distance\n        dist_bins = np.linspace(0, np.max(distances), 20)\n        variogram_values = np.zeros(len(dist_bins)-1)\n        \n        for i in range(len(dist_bins)-1):\n            mask = (distances >= dist_bins[i]) & (distances < dist_bins[i+1])\n            if np.any(mask & direction_mask):\n                variogram_values[i] = np.mean(variogram[mask & direction_mask])\n        \n        return variogram_values\n\n    def _estimate_variogram_range(self, variogram: np.ndarray) -> float:\n        \"\"\"Estimate the range of a variogram\"\"\"\n        # Find the distance where variogram reaches 95% of its sill\n        sill = np.max(variogram)\n        threshold = 0.95 * sill\n        \n        # Find first crossing of threshold\n        range_idx = np.where(variogram >= threshold)[0]\n        if len(range_idx) > 0:\n            return float(range_idx[0])\n        \n        return float(len(variogram))\n\n    def _summarize_region(self,\n                         clusters: List[Dict[str, Any]],\n                         spatial_stats: Dict[str, Any],\n                         region: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"\n        Generate summary of the region analysis\n        \n        Args:\n            clusters: Identified clusters\n            spatial_stats: Spatial statistics\n            region: Region bounds\n            \n        Returns:\n            Dictionary with region summary\n        \"\"\"\n        # Calculate region properties\n        region_width = self._haversine_distance(\n            region['min_lat'],\n            region['min_lon'],\n            region['min_lat'],\n            region['max_lon']\n        )\n        region_height = self._haversine_distance(\n            region['min_lat'],\n            region['min_lon'],\n            region['max_lat'],\n            region['min_lon']\n        )\n        \n        # Summarize findings\n        summary = {\n            'region_size': {\n                'width_km': float(region_width),\n                'height_km': float(region_height),\n                'area_km2': float(region_width * region_height)\n            },\n            'cluster_analysis': {\n                'cluster_count': len(clusters),\n                'total_area_km2': sum(c['radius_km']**2 * np.pi for c in clusters),\n                'mean_probability': np.mean([c['mean_probability'] for c in clusters]),\n                'max_probability': max(c['max_probability'] for c in clusters) if clusters else 0\n            },\n            'spatial_patterns': {\n                'spatial_autocorrelation': spatial_stats['global_moran_i'],\n                'hotspot_count': len(spatial_stats['hotspots']),\n                'dominant_direction': spatial_stats['directional_trends']['dominant_direction']\n            }\n        }\n        \n        return summary\n    \n    def _calculate_reconstruction_error(self,\n                                     input_data: torch.Tensor,\n                                     features: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Calculate reconstruction error for anomaly detection\n        \n        Args:\n            input_data: Original input data\n            features: Encoded features from autoencoder\n            \n        Returns:\n            Tensor of reconstruction errors\n        \"\"\"\n        # Get reconstructed data\n        reconstructed = self.model.decoder(features)\n        \n        # Calculate MSE for each sample\n        errors = torch.mean((input_data - reconstructed) ** 2, dim=1)\n        \n        return errors\n\n    def _detect_anomalies_from_error(self,\n                                   reconstruction_error: torch.Tensor,\n                                   threshold_percentile: float = 95) -> List[Dict[str, Any]]:\n        \"\"\"\n        Detect anomalies based on reconstruction error\n        \n        Args:\n            reconstruction_error: Tensor of reconstruction errors\n            threshold_percentile: Percentile to use as anomaly threshold\n            \n        Returns:\n            List of detected anomalies with metadata\n        \"\"\"\n        # Calculate threshold\n        threshold = np.percentile(\n            reconstruction_error.cpu().numpy(),\n            threshold_percentile\n        )\n        \n        # Find anomalies\n        anomaly_indices = torch.where(reconstruction_error > threshold)[0]\n        \n        # Create anomaly records\n        anomalies = []\n        for idx in anomaly_indices:\n            anomaly_score = float(reconstruction_error[idx])\n            \n            # Get feature contributions to anomaly\n            feature_contributions = self._calculate_feature_contributions(idx)\n            \n            # Create anomaly record\n            anomaly = {\n                \"index\": int(idx),\n                \"anomaly_score\": anomaly_score,\n                \"threshold\": float(threshold),\n                \"feature_contributions\": feature_contributions,\n                \"description\": self._generate_anomaly_description(\n                    anomaly_score,\n                    feature_contributions\n                )\n            }\n            anomalies.append(anomaly)\n        \n        return anomalies\n\n    def _calculate_feature_contributions(self,\n                                      anomaly_idx: int) -> Dict[str, float]:\n        \"\"\"\n        Calculate how much each feature contributes to the anomaly\n        \n        Args:\n            anomaly_idx: Index of the anomaly\n            \n        Returns:\n            Dictionary mapping feature names to contribution scores\n        \"\"\"\n        # Get original and reconstructed data for this sample\n        original = self.model.get_input(anomaly_idx)\n        reconstructed = self.model.get_reconstruction(anomaly_idx)\n        \n        # Calculate squared error for each feature\n        feature_errors = (original - reconstructed) ** 2\n        \n        # Normalize contributions\n        total_error = torch.sum(feature_errors)\n        contributions = feature_errors / total_error\n        \n        # Map to feature names\n        feature_contributions = {}\n        for i, name in enumerate(self.feature_names):\n            feature_contributions[name] = float(contributions[i])\n            \n        return feature_contributions\n\n    def _generate_anomaly_description(self,\n                                    anomaly_score: float,\n                                    feature_contributions: Dict[str, float]) -> str:\n        \"\"\"\n        Generate human-readable description of the anomaly\n        \n        Args:\n            anomaly_score: Overall anomaly score\n            feature_contributions: Dictionary of feature contributions\n            \n        Returns:\n            Description string\n        \"\"\"\n        # Sort features by contribution\n        sorted_features = sorted(\n            feature_contributions.items(),\n            key=lambda x: x[1],\n            reverse=True\n        )\n        \n        # Get top contributing features\n        top_features = sorted_features[:3]\n        \n        # Generate description\n        description = f\"Anomaly score: {anomaly_score:.2f}\\n\"\n        description += \"Main contributing features:\\n\"\n        \n        for feature, contribution in top_features:\n            description += f\"- {feature}: {contribution:.1%}\\n\"\n            \n        return description\n    \n    def _create_prediction_heatmap(self,\n                                 predictions: List[Dict[str, Any]],\n                                 region: Dict[str, float]) -> Path:\n        \"\"\"Create heatmap visualization of predictions\"\"\"\n        # Extract data\n        lats = [p['location']['latitude'] for p in predictions]\n        lons = [p['location']['longitude'] for p in predictions]\n        probs = [p['probability'] for p in predictions]\n        \n        # Create heatmap\n        fig = go.Figure(data=go.Densitymapbox(\n            lat=lats,\n            lon=lons,\n            z=probs,\n            radius=10,\n            colorscale='Viridis',\n            zmin=0,\n            zmax=1\n        ))\n        \n        # Update layout\n        fig.update_layout(\n            mapbox_style=\"stamen-terrain\",\n            mapbox=dict(\n                center=dict(\n                    lat=(region['min_lat'] + region['max_lat']) / 2,\n                    lon=(region['min_lon'] + region['max_lon']) / 2\n                ),\n                zoom=8\n            ),\n            title=\"Mineral Deposit Probability Heatmap\"\n        )\n        \n        # Save plot\n        output_path = self.output_dir / f\"prediction_heatmap_{datetime.now():%Y%m%d_%H%M%S}.html\"\n        fig.write_html(str(output_path))\n        return output_path\n    \n    def _create_feature_importance_plot(self,\n                                      importance: Dict[str, float]) -> Path:\n        \"\"\"Create feature importance visualization\"\"\"\n        # Sort features by importance\n        sorted_features = sorted(\n            importance.items(),\n            key=lambda x: x[1],\n            reverse=True\n        )\n        features, scores = zip(*sorted_features)\n        \n        # Create bar plot\n        fig = go.Figure(data=go.Bar(\n            x=scores,\n            y=features,\n            orientation='h'\n        ))\n        \n        # Update layout\n        fig.update_layout(\n            title=\"Feature Importance Analysis\",\n            xaxis_title=\"Importance Score\",\n            yaxis_title=\"Feature\",\n            height=max(400, len(features) * 25)\n        )\n        \n        # Save plot\n        output_path = self.output_dir / f\"feature_importance_{datetime.now():%Y%m%d_%H%M%S}.html\"\n        fig.write_html(str(output_path))\n        return output_path\n    \n    def _create_pattern_visualization(self,\n                                    patterns: List[Dict[str, Any]]) -> Path:\n        \"\"\"Create pattern analysis visualization\"\"\"\n        # Extract pattern data\n        pattern_names = [p['name'] for p in patterns]\n        pattern_strengths = [p['strength'] for p in patterns]\n        pattern_confidences = [p['confidence'] for p in patterns]\n        \n        # Create scatter plot\n        fig = go.Figure(data=go.Scatter(\n            x=pattern_strengths,\n            y=pattern_confidences,\n            mode='markers+text',\n            text=pattern_names,\n            textposition=\"top center\",\n            marker=dict(\n                size=10,\n                color=pattern_strengths,\n                colorscale='Viridis',\n                showscale=True\n            )\n        ))\n        \n        # Update layout\n        fig.update_layout(\n            title=\"Geological Pattern Analysis\",\n            xaxis_title=\"Pattern Strength\",\n            yaxis_title=\"Confidence Level\",\n            height=600\n        )\n        \n        # Save plot\n        output_path = self.output_dir / f\"pattern_analysis_{datetime.now():%Y%m%d_%H%M%S}.html\"\n        fig.write_html(str(output_path))\n        return output_path\n    \n    def _create_anomaly_visualization(self,\n                                    anomalies: List[Dict[str, Any]]) -> Path:\n        \"\"\"Create anomaly detection visualization\"\"\"\n        # Extract anomaly data\n        lats = [a['location']['latitude'] for a in anomalies]\n        lons = [a['location']['longitude'] for a in anomalies]\n        scores = [a['anomaly_score'] for a in anomalies]\n        descriptions = [a['description'] for a in anomalies]\n        \n        # Create scatter mapbox\n        fig = go.Figure(data=go.Scattermapbox(\n            lat=lats,\n            lon=lons,\n            mode='markers',\n            marker=dict(\n                size=10,\n                color=scores,\n                colorscale='RdYlBu_r',\n                showscale=True\n            ),\n            text=descriptions,\n            hoverinfo='text'\n        ))\n        \n        # Update layout\n        fig.update_layout(\n            mapbox_style=\"stamen-terrain\",\n            mapbox=dict(\n                center=dict(\n                    lat=np.mean(lats),\n                    lon=np.mean(lons)\n                ),\n                zoom=8\n            ),\n            title=\"Geological Anomalies\"\n        )\n        \n        # Save plot\n        output_path = self.output_dir / f\"anomaly_detection_{datetime.now():%Y%m%d_%H%M%S}.html\"\n        fig.write_html(str(output_path))\n        return output_path\n    \n    def _get_nearby_features(self,\n                           deposit: pd.Series,\n                           features: pd.DataFrame,\n                           radius_km: float) -> pd.DataFrame:\n        \"\"\"\n        Get geological features within a radius of a deposit\n        \n        Args:\n            deposit: Series containing deposit location\n            features: DataFrame of geological features\n            radius_km: Search radius in kilometers\n            \n        Returns:\n            DataFrame of nearby features\n        \"\"\"\n        # Calculate distances\n        distances = features.apply(\n            lambda x: self._haversine_distance(\n                deposit['latitude'],\n                deposit['longitude'],\n                x['latitude'],\n                x['longitude']\n            ),\n            axis=1\n        )\n        \n        # Filter features within radius\n        return features[distances <= radius_km]\n\n    def _haversine_distance(self,\n                          lat1: float,\n                          lon1: float,\n                          lat2: float,\n                          lon2: float) -> float:\n        \"\"\"\n        Calculate the great circle distance between two points\n        on the earth (specified in decimal degrees)\n        \"\"\"\n        # Convert decimal degrees to radians\n        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n        \n        # Haversine formula\n        dlat = lat2 - lat1\n        dlon = lon2 - lon1\n        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n        c = 2 * np.arcsin(np.sqrt(a))\n        \n        # Radius of earth in kilometers\n        r = 6371\n        \n        return c * r\n\n    def _encode_geological_feature(self, feature_values: np.ndarray) -> List[float]:\n        \"\"\"\n        Encode geological features into numerical values\n        \n        Args:\n            feature_values: Array of feature values\n            \n        Returns:\n            List of encoded feature values\n        \"\"\"\n        # One-hot encode categorical values\n        unique_values = np.unique(feature_values)\n        encoding = np.zeros(len(unique_values))\n        \n        for i, value in enumerate(unique_values):\n            encoding[i] = np.sum(feature_values == value)\n            \n        # Normalize\n        if len(encoding) > 0:\n            encoding = encoding / len(feature_values)\n            \n        return encoding.tolist()\n\n    def _encode_geophysical_feature(self, feature_values: np.ndarray) -> List[float]:\n        \"\"\"\n        Encode geophysical features into numerical values\n        \n        Args:\n            feature_values: Array of feature values\n            \n        Returns:\n            List of encoded feature values\n        \"\"\"\n        if len(feature_values) == 0:\n            return [0.0, 0.0, 0.0, 0.0]\n            \n        # Calculate statistical features\n        return [\n            float(np.mean(feature_values)),\n            float(np.std(feature_values)),\n            float(np.min(feature_values)),\n            float(np.max(feature_values))\n        ]\n\n    def _calculate_accuracy(self,\n                          predictions: torch.Tensor,\n                          targets: torch.Tensor) -> float:\n        \"\"\"Calculate binary classification accuracy\"\"\"\n        predictions = (predictions >= 0.5).float()\n        correct = (predictions == targets).float()\n        return float(torch.mean(correct))\n\n    def _calculate_precision(self,\n                           predictions: torch.Tensor,\n                           targets: torch.Tensor) -> float:\n        \"\"\"Calculate precision score\"\"\"\n        predictions = (predictions >= 0.5).float()\n        true_positives = torch.sum((predictions == 1) & (targets == 1))\n        predicted_positives = torch.sum(predictions == 1)\n        return float(true_positives / (predicted_positives + 1e-10))\n\n    def _calculate_recall(self,\n                         predictions: torch.Tensor,\n                         targets: torch.Tensor) -> float:\n        \"\"\"Calculate recall score\"\"\"\n        predictions = (predictions >= 0.5).float()\n        true_positives = torch.sum((predictions == 1) & (targets == 1))\n        actual_positives = torch.sum(targets == 1)\n        return float(true_positives / (actual_positives + 1e-10))\n\n    def _calculate_f1_score(self,\n                          predictions: torch.Tensor,\n                          targets: torch.Tensor) -> float:\n        \"\"\"Calculate F1 score\"\"\"\n        precision = self._calculate_precision(predictions, targets)\n        recall = self._calculate_recall(predictions, targets)\n        return 2 * (precision * recall) / (precision + recall + 1e-10)\n\n    def _calculate_auc_roc(self,\n                          predictions: torch.Tensor,\n                          targets: torch.Tensor) -> float:\n        \"\"\"Calculate Area Under ROC Curve\"\"\"\n        # Sort predictions and corresponding targets\n        sorted_pairs = sorted(zip(predictions.cpu().numpy(),\n                                targets.cpu().numpy()),\n                            key=lambda x: x[0],\n                            reverse=True)\n        sorted_preds, sorted_targets = zip(*sorted_pairs)\n        \n        # Calculate TPR and FPR at different thresholds\n        n_positive = sum(sorted_targets)\n        n_negative = len(sorted_targets) - n_positive\n        \n        tpr = 0\n        fpr = 0\n        auc = 0\n        \n        for i in range(len(sorted_targets)):\n            if sorted_targets[i] == 1:\n                tpr += 1\n            else:\n                fpr += 1\n                auc += tpr\n        \n        if n_positive * n_negative == 0:\n            return 0.5\n            \n        return auc / (n_positive * n_negative)\n\n    def _calculate_integrated_gradients(self,\n                                     model: nn.Module,\n                                     baseline: torch.Tensor,\n                                     input_vector: torch.Tensor,\n                                     steps: int = 50) -> torch.Tensor:\n        \"\"\"\n        Calculate integrated gradients for feature importance\n        \n        Args:\n            model: Neural network model\n            baseline: Baseline input (usually zeros)\n            input_vector: Input to analyze\n            steps: Number of steps for approximation\n            \n        Returns:\n            Integrated gradients tensor\n        \"\"\"\n        # Scale inputs\n        scaled_inputs = [baseline + (float(i) / steps) * (input_vector - baseline)\n                        for i in range(steps + 1)]\n        scaled_inputs = torch.stack(scaled_inputs)\n        \n        # Calculate gradients\n        scaled_inputs.requires_grad = True\n        outputs = model(scaled_inputs)\n        gradients = torch.autograd.grad(outputs.sum(), scaled_inputs)[0]\n        \n        # Calculate integral approximation\n        avg_gradients = torch.mean(gradients, dim=0)\n        integrated_gradients = (input_vector - baseline) * avg_gradients\n        \n        return integrated_gradients\n\n    def preprocess_data(self,\n                       data: pd.DataFrame,\n                       validation_schema: Optional[Dict[str, Any]] = None) -> pd.DataFrame:\n        \"\"\"\n        Preprocess and validate input data\n        \n        Args:\n            data: Input DataFrame\n            validation_schema: Optional schema for validation\n            \n        Returns:\n            Preprocessed DataFrame\n        \"\"\"\n        # Validate data if schema provided\n        if validation_schema:\n            self._validate_data(data, validation_schema)\n        \n        # Handle missing values\n        data = self._handle_missing_values(data)\n        \n        # Convert data types\n        data = self._convert_data_types(data)\n        \n        # Remove outliers\n        data = self._remove_outliers(data)\n        \n        # Feature engineering\n        data = self._engineer_features(data)\n        \n        return data\n\n    def _validate_data(self,\n                      data: pd.DataFrame,\n                      schema: Dict[str, Any]) -> None:\n        \"\"\"\n        Validate data against schema\n        \n        Args:\n            data: Input DataFrame\n            schema: Validation schema\n            \n        Raises:\n            ValueError: If validation fails\n        \"\"\"\n        # Check required columns\n        missing_cols = set(schema[\"required_columns\"]) - set(data.columns)\n        if missing_cols:\n            raise ValueError(f\"Missing required columns: {missing_cols}\")\n        \n        # Check data types\n        for col, dtype in schema[\"column_types\"].items():\n            if col in data.columns:\n                if not pd.api.types.is_dtype_equal(data[col].dtype, dtype):\n                    raise ValueError(\n                        f\"Column {col} has type {data[col].dtype}, expected {dtype}\"\n                    )\n        \n        # Check value ranges\n        for col, range_info in schema[\"value_ranges\"].items():\n            if col in data.columns:\n                if \"min\" in range_info:\n                    if data[col].min() < range_info[\"min\"]:\n                        raise ValueError(\n                            f\"Column {col} has values below minimum {range_info['min']}\"\n                        )\n                if \"max\" in range_info:\n                    if data[col].max() > range_info[\"max\"]:\n                        raise ValueError(\n                            f\"Column {col} has values above maximum {range_info['max']}\"\n                        )\n\n    def _handle_missing_values(self, data: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Handle missing values in data\n        \n        Args:\n            data: Input DataFrame\n            \n        Returns:\n            DataFrame with handled missing values\n        \"\"\"\n        # Make copy to avoid modifying original\n        data = data.copy()\n        \n        # For numerical columns\n        numerical_cols = data.select_dtypes(include=[np.number]).columns\n        for col in numerical_cols:\n            # Fill with median for numerical data\n            if data[col].isnull().any():\n                data[col] = data[col].fillna(data[col].median())\n        \n        # For categorical columns\n        categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n        for col in categorical_cols:\n            # Fill with mode for categorical data\n            if data[col].isnull().any():\n                data[col] = data[col].fillna(data[col].mode()[0])\n        \n        return data\n\n    def _convert_data_types(self, data: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Convert data types to appropriate types\n        \n        Args:\n            data: Input DataFrame\n            \n        Returns:\n            DataFrame with converted types\n        \"\"\"\n        # Make copy to avoid modifying original\n        data = data.copy()\n        \n        # Convert date columns\n        date_columns = [\n            col for col in data.columns\n            if any(date_str in col.lower() \n                  for date_str in ['date', 'time', 'timestamp'])\n        ]\n        for col in date_columns:\n            try:\n                data[col] = pd.to_datetime(data[col])\n            except:\n                pass\n        \n        # Convert categorical columns\n        categorical_columns = [\n            col for col in data.columns\n            if data[col].nunique() < 0.05 * len(data)  # Less than 5% unique values\n            and data[col].dtype == 'object'\n        ]\n        for col in categorical_columns:\n            data[col] = data[col].astype('category')\n        \n        return data\n\n    def _remove_outliers(self,\n                        data: pd.DataFrame,\n                        threshold: float = 3.0) -> pd.DataFrame:\n        \"\"\"\n        Remove statistical outliers from numerical columns\n        \n        Args:\n            data: Input DataFrame\n            threshold: Z-score threshold for outliers\n            \n        Returns:\n            DataFrame with outliers removed\n        \"\"\"\n        # Make copy to avoid modifying original\n        data = data.copy()\n        \n        # Only process numerical columns\n        numerical_cols = data.select_dtypes(include=[np.number]).columns\n        \n        for col in numerical_cols:\n            # Calculate z-scores\n            z_scores = np.abs((data[col] - data[col].mean()) / data[col].std())\n            \n            # Remove outliers\n            data = data[z_scores < threshold]\n        \n        return data\n\n    def _engineer_features(self, data: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Create engineered features\n        \n        Args:\n            data: Input DataFrame\n            \n        Returns:\n            DataFrame with additional engineered features\n        \"\"\"\n        # Make copy to avoid modifying original\n        data = data.copy()\n        \n        # Process geological features\n        if all(col in data.columns for col in ['lithology', 'structure']):\n            # Create geological complexity score\n            data['geological_complexity'] = self._calculate_geological_complexity(\n                data['lithology'],\n                data['structure']\n            )\n        \n        # Process geophysical features\n        geophysical_cols = [\n            'magnetic', 'gravity', 'electromagnetic', 'radiometric'\n        ]\n        present_cols = [col for col in geophysical_cols if col in data.columns]\n        \n        if present_cols:\n            # Create geophysical anomaly score\n            data['geophysical_anomaly'] = self._calculate_geophysical_anomaly(\n                data[present_cols]\n            )\n        \n        # Process spatial features\n        if all(col in data.columns for col in ['latitude', 'longitude']):\n            # Add distance to known deposits\n            data['nearest_deposit_distance'] = self._calculate_nearest_deposit_distance(\n                data['latitude'],\n                data['longitude']\n            )\n        \n        return data\n\n    def _calculate_geological_complexity(self,\n                                      lithology: pd.Series,\n                                      structure: pd.Series) -> pd.Series:\n        \"\"\"Calculate geological complexity score\"\"\"\n        # Convert to categorical if not already\n        lithology = lithology.astype('category')\n        structure = structure.astype('category')\n        \n        # Calculate complexity based on variety and relationships\n        complexity = (\n            lithology.cat.codes.astype(float) +\n            structure.cat.codes.astype(float)\n        ) / 2\n        \n        return complexity\n\n    def _calculate_geophysical_anomaly(self,\n                                     geophysical_data: pd.DataFrame) -> pd.Series:\n        \"\"\"Calculate geophysical anomaly score\"\"\"\n        # Standardize each measurement\n        standardized = (geophysical_data - geophysical_data.mean()) / geophysical_data.std()\n        \n        # Calculate combined anomaly score\n        anomaly_score = np.sqrt(np.mean(standardized ** 2, axis=1))\n        \n        return anomaly_score\n\n    def _calculate_nearest_deposit_distance(self,\n                                         latitude: pd.Series,\n                                         longitude: pd.Series) -> pd.Series:\n        \"\"\"Calculate distance to nearest known deposit\"\"\"\n        # Get known deposit locations\n        known_deposits = self._get_known_deposits()\n        \n        # Calculate distances to all known deposits\n        distances = pd.DataFrame({\n            'distance': [\n                min(\n                    self._haversine_distance(lat, lon, dep_lat, dep_lon)\n                    for dep_lat, dep_lon in zip(\n                        known_deposits['latitude'],\n                        known_deposits['longitude']\n                    )\n                )\n                for lat, lon in zip(latitude, longitude)\n            ]\n        })\n        \n        return distances['distance'] "}
{"type": "source_file", "path": "minesight/core/ai/training_strategies.py", "content": "\"\"\"\nAdvanced training strategies\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.cuda.amp import autocast, GradScaler\nfrom typing import Dict, Any, Optional, Callable\nimport numpy as np\nfrom pathlib import Path\nimport logging\n\nclass MixedPrecisionTrainer:\n    \"\"\"Trainer with mixed precision support\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 device: torch.device,\n                 output_dir: Path):\n        \"\"\"\n        Initialize trainer\n        \n        Args:\n            model: Neural network model\n            device: Computation device\n            output_dir: Output directory\n        \"\"\"\n        self.model = model.to(device)\n        self.device = device\n        self.output_dir = output_dir\n        self.scaler = GradScaler()\n        \n    def train_step(self,\n                   batch: Dict[str, torch.Tensor],\n                   optimizer: optim.Optimizer) -> Dict[str, float]:\n        \"\"\"\n        Training step with mixed precision\n        \n        Args:\n            batch: Batch of data\n            optimizer: Optimizer\n            \n        Returns:\n            Dictionary with losses\n        \"\"\"\n        optimizer.zero_grad()\n        \n        # Automatic mixed precision\n        with autocast():\n            outputs = self.model(batch['features'].to(self.device))\n            loss = self._compute_loss(outputs, batch)\n            \n        # Scale gradients\n        self.scaler.scale(loss).backward()\n        self.scaler.step(optimizer)\n        self.scaler.update()\n        \n        return {'loss': loss.item()}\n\nclass CurriculumTrainer:\n    \"\"\"Trainer with curriculum learning\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 device: torch.device,\n                 output_dir: Path,\n                 curriculum_fn: Callable):\n        \"\"\"\n        Initialize trainer\n        \n        Args:\n            model: Neural network model\n            device: Computation device\n            output_dir: Output directory\n            curriculum_fn: Function to get curriculum difficulty\n        \"\"\"\n        self.model = model.to(device)\n        self.device = device\n        self.output_dir = output_dir\n        self.curriculum_fn = curriculum_fn\n        \n    def train_epoch(self,\n                    data_loader: torch.utils.data.DataLoader,\n                    optimizer: optim.Optimizer,\n                    epoch: int) -> Dict[str, float]:\n        \"\"\"\n        Train one epoch with curriculum\n        \n        Args:\n            data_loader: Data loader\n            optimizer: Optimizer\n            epoch: Current epoch\n            \n        Returns:\n            Dictionary with losses\n        \"\"\"\n        total_loss = 0\n        \n        # Get current difficulty\n        difficulty = self.curriculum_fn(epoch)\n        \n        for batch in data_loader:\n            # Filter samples by difficulty\n            mask = self._get_difficulty_mask(batch, difficulty)\n            if mask.sum() == 0:\n                continue\n                \n            # Train on selected samples\n            loss = self._train_step(\n                {k: v[mask] for k, v in batch.items()},\n                optimizer\n            )\n            total_loss += loss['loss']\n            \n        return {'loss': total_loss / len(data_loader)}\n        \n    def _get_difficulty_mask(self,\n                           batch: Dict[str, torch.Tensor],\n                           difficulty: float) -> torch.Tensor:\n        \"\"\"Get mask for samples within current difficulty\"\"\"\n        # Example: mask based on feature complexity\n        complexity = self._compute_sample_complexity(batch['features'])\n        return complexity <= difficulty\n\nclass AdversarialTrainer:\n    \"\"\"Trainer with adversarial training\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 device: torch.device,\n                 output_dir: Path,\n                 epsilon: float = 0.01):\n        \"\"\"\n        Initialize trainer\n        \n        Args:\n            model: Neural network model\n            device: Computation device\n            output_dir: Output directory\n            epsilon: Perturbation size\n        \"\"\"\n        self.model = model.to(device)\n        self.device = device\n        self.output_dir = output_dir\n        self.epsilon = epsilon\n        \n    def train_step(self,\n                   batch: Dict[str, torch.Tensor],\n                   optimizer: optim.Optimizer) -> Dict[str, float]:\n        \"\"\"\n        Training step with adversarial examples\n        \n        Args:\n            batch: Batch of data\n            optimizer: Optimizer\n            \n        Returns:\n            Dictionary with losses\n        \"\"\"\n        # Generate adversarial examples\n        features = batch['features'].to(self.device)\n        features.requires_grad = True\n        \n        # Forward pass\n        outputs = self.model(features)\n        loss = self._compute_loss(outputs, batch)\n        \n        # Generate perturbation\n        loss.backward()\n        perturbation = self.epsilon * features.grad.sign()\n        \n        # Train on adversarial examples\n        adv_features = features + perturbation\n        adv_outputs = self.model(adv_features)\n        adv_loss = self._compute_loss(adv_outputs, batch)\n        \n        # Update model\n        optimizer.zero_grad()\n        adv_loss.backward()\n        optimizer.step()\n        \n        return {\n            'loss': loss.item(),\n            'adv_loss': adv_loss.item()\n        }\n\nclass MultiTaskTrainer:\n    \"\"\"Trainer for multi-task learning\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 device: torch.device,\n                 output_dir: Path,\n                 task_weights: Optional[Dict[str, float]] = None):\n        \"\"\"\n        Initialize trainer\n        \n        Args:\n            model: Neural network model\n            device: Computation device\n            output_dir: Output directory\n            task_weights: Weight for each task's loss\n        \"\"\"\n        self.model = model.to(device)\n        self.device = device\n        self.output_dir = output_dir\n        self.task_weights = task_weights or {}\n        \n    def train_step(self,\n                   batch: Dict[str, torch.Tensor],\n                   optimizer: optim.Optimizer) -> Dict[str, float]:\n        \"\"\"\n        Training step for multiple tasks\n        \n        Args:\n            batch: Batch of data\n            optimizer: Optimizer\n            \n        Returns:\n            Dictionary with losses\n        \"\"\"\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = self.model(batch['features'].to(self.device))\n        \n        # Compute loss for each task\n        losses = {}\n        total_loss = 0\n        \n        for task_name, task_weight in self.task_weights.items():\n            task_loss = self._compute_task_loss(\n                outputs[f'{task_name}_logits'],\n                batch[f'{task_name}_labels'].to(self.device)\n            )\n            losses[f'{task_name}_loss'] = task_loss.item()\n            total_loss += task_weight * task_loss\n            \n        # Update model\n        total_loss.backward()\n        optimizer.step()\n        \n        losses['total_loss'] = total_loss.item()\n        return losses\n\nclass ActiveLearningTrainer:\n    \"\"\"Trainer with active learning\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 device: torch.device,\n                 output_dir: Path,\n                 acquisition_fn: Callable):\n        \"\"\"\n        Initialize trainer\n        \n        Args:\n            model: Neural network model\n            device: Computation device\n            output_dir: Output directory\n            acquisition_fn: Function to select samples\n        \"\"\"\n        self.model = model.to(device)\n        self.device = device\n        self.output_dir = output_dir\n        self.acquisition_fn = acquisition_fn\n        \n    def select_samples(self,\n                      pool_data: Dict[str, torch.Tensor],\n                      n_samples: int) -> torch.Tensor:\n        \"\"\"\n        Select samples for labeling\n        \n        Args:\n            pool_data: Unlabeled data pool\n            n_samples: Number of samples to select\n            \n        Returns:\n            Indices of selected samples\n        \"\"\"\n        # Get model predictions\n        self.model.eval()\n        with torch.no_grad():\n            outputs = self.model(pool_data['features'].to(self.device))\n            \n        # Select samples using acquisition function\n        scores = self.acquisition_fn(outputs)\n        selected = torch.argsort(scores, descending=True)[:n_samples]\n        \n        return selected\n\nclass SelfTrainingTrainer:\n    \"\"\"Trainer with self-training for semi-supervised learning\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 device: torch.device,\n                 output_dir: Path,\n                 confidence_threshold: float = 0.95):\n        \"\"\"\n        Initialize trainer\n        \n        Args:\n            model: Neural network model\n            device: Computation device\n            output_dir: Output directory\n            confidence_threshold: Threshold for pseudo-labeling\n        \"\"\"\n        self.model = model.to(device)\n        self.device = device\n        self.output_dir = output_dir\n        self.confidence_threshold = confidence_threshold\n        \n    def generate_pseudo_labels(self,\n                             unlabeled_data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Generate pseudo-labels for unlabeled data\n        \n        Args:\n            unlabeled_data: Unlabeled data\n            \n        Returns:\n            Data with pseudo-labels\n        \"\"\"\n        self.model.eval()\n        with torch.no_grad():\n            outputs = self.model(unlabeled_data['features'].to(self.device))\n            \n        # Get confident predictions\n        probs = outputs['probability']\n        confidence = probs.max(dim=1)[0]\n        mask = confidence >= self.confidence_threshold\n        \n        # Create pseudo-labeled dataset\n        pseudo_labeled = {\n            'features': unlabeled_data['features'][mask],\n            'labels': probs[mask].argmax(dim=1)\n        }\n        \n        return pseudo_labeled "}
{"type": "source_file", "path": "minesight/core/ai/trainer.py", "content": "\"\"\"\nTraining and evaluation utilities for deep learning models\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom typing import Dict, List, Any, Optional, Tuple, Callable\nfrom pathlib import Path\nimport json\nfrom datetime import datetime\nimport logging\n\nclass ModelTrainer:\n    \"\"\"Model training and evaluation utility\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 device: torch.device,\n                 output_dir: Path):\n        \"\"\"\n        Initialize trainer\n        \n        Args:\n            model: Neural network model\n            device: Computation device\n            output_dir: Output directory for logs and checkpoints\n        \"\"\"\n        self.model = model\n        self.device = device\n        self.output_dir = output_dir\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Setup logging\n        self.logger = self._setup_logger()\n    \n    def train(self,\n              train_data: Dict[str, torch.Tensor],\n              val_data: Dict[str, torch.Tensor],\n              config: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Train model\n        \n        Args:\n            train_data: Training data\n            val_data: Validation data\n            config: Training configuration\n            \n        Returns:\n            Dictionary with training history\n        \"\"\"\n        # Create data loaders\n        train_loader = self._create_data_loader(\n            train_data,\n            config['batch_size'],\n            shuffle=True\n        )\n        val_loader = self._create_data_loader(\n            val_data,\n            config['batch_size'],\n            shuffle=False\n        )\n        \n        # Setup training\n        criterion = self._get_criterion(config['loss'])\n        optimizer = self._get_optimizer(\n            config['optimizer'],\n            config['learning_rate']\n        )\n        scheduler = self._get_scheduler(optimizer, config)\n        \n        # Training loop\n        best_val_loss = float('inf')\n        history = {\n            'train_loss': [],\n            'val_loss': [],\n            'metrics': []\n        }\n        \n        for epoch in range(config['epochs']):\n            # Train epoch\n            train_loss = self._train_epoch(\n                train_loader,\n                criterion,\n                optimizer\n            )\n            \n            # Validate\n            val_loss, metrics = self._validate(\n                val_loader,\n                criterion\n            )\n            \n            # Update learning rate\n            if scheduler is not None:\n                scheduler.step(val_loss)\n            \n            # Save best model\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                self._save_checkpoint(\n                    epoch,\n                    val_loss,\n                    metrics\n                )\n            \n            # Update history\n            history['train_loss'].append(train_loss)\n            history['val_loss'].append(val_loss)\n            history['metrics'].append(metrics)\n            \n            # Log progress\n            self.logger.info(\n                f\"Epoch {epoch+1}/{config['epochs']} - \"\n                f\"train_loss: {train_loss:.4f} - \"\n                f\"val_loss: {val_loss:.4f}\"\n            )\n        \n        return history\n    \n    def evaluate(self,\n                test_data: Dict[str, torch.Tensor]) -> Dict[str, Any]:\n        \"\"\"\n        Evaluate model\n        \n        Args:\n            test_data: Test data\n            \n        Returns:\n            Dictionary with evaluation results\n        \"\"\"\n        # Create data loader\n        test_loader = self._create_data_loader(\n            test_data,\n            batch_size=32,\n            shuffle=False\n        )\n        \n        # Evaluate\n        self.model.eval()\n        predictions = []\n        targets = []\n        \n        with torch.no_grad():\n            for batch in test_loader:\n                # Get predictions\n                outputs = self.model(batch['features'].to(self.device))\n                predictions.append(outputs['probability'].cpu())\n                targets.append(batch['labels'].cpu())\n        \n        # Concatenate results\n        predictions = torch.cat(predictions)\n        targets = torch.cat(targets)\n        \n        # Calculate metrics\n        results = {\n            'predictions': predictions.numpy(),\n            'targets': targets.numpy(),\n            'metrics': self._calculate_metrics(predictions, targets)\n        }\n        \n        return results\n    \n    def _train_epoch(self,\n                    train_loader: DataLoader,\n                    criterion: nn.Module,\n                    optimizer: optim.Optimizer) -> float:\n        \"\"\"Train one epoch\"\"\"\n        self.model.train()\n        total_loss = 0\n        \n        for batch in train_loader:\n            # Forward pass\n            outputs = self.model(batch['features'].to(self.device))\n            loss = criterion(\n                outputs['logits'],\n                batch['labels'].to(self.device)\n            )\n            \n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n        return total_loss / len(train_loader)\n    \n    def _validate(self,\n                 val_loader: DataLoader,\n                 criterion: nn.Module) -> Tuple[float, Dict[str, float]]:\n        \"\"\"Validate model\"\"\"\n        self.model.eval()\n        total_loss = 0\n        predictions = []\n        targets = []\n        \n        with torch.no_grad():\n            for batch in val_loader:\n                # Forward pass\n                outputs = self.model(batch['features'].to(self.device))\n                loss = criterion(\n                    outputs['logits'],\n                    batch['labels'].to(self.device)\n                )\n                \n                total_loss += loss.item()\n                predictions.append(outputs['probability'].cpu())\n                targets.append(batch['labels'].cpu())\n        \n        # Calculate metrics\n        predictions = torch.cat(predictions)\n        targets = torch.cat(targets)\n        metrics = self._calculate_metrics(predictions, targets)\n        \n        return total_loss / len(val_loader), metrics\n    \n    def _calculate_metrics(self,\n                         predictions: torch.Tensor,\n                         targets: torch.Tensor) -> Dict[str, float]:\n        \"\"\"Calculate evaluation metrics\"\"\"\n        # Convert to binary predictions\n        binary_preds = (predictions >= 0.5).float()\n        \n        # Calculate metrics\n        metrics = {\n            'accuracy': float(torch.mean((binary_preds == targets).float())),\n            'precision': float(self._calculate_precision(binary_preds, targets)),\n            'recall': float(self._calculate_recall(binary_preds, targets)),\n            'f1': float(self._calculate_f1(binary_preds, targets)),\n            'auc_roc': float(self._calculate_auc_roc(predictions, targets))\n        }\n        \n        return metrics\n    \n    def _calculate_precision(self,\n                           predictions: torch.Tensor,\n                           targets: torch.Tensor) -> float:\n        \"\"\"Calculate precision score\"\"\"\n        true_positives = torch.sum((predictions == 1) & (targets == 1))\n        predicted_positives = torch.sum(predictions == 1)\n        return true_positives / (predicted_positives + 1e-10)\n    \n    def _calculate_recall(self,\n                         predictions: torch.Tensor,\n                         targets: torch.Tensor) -> float:\n        \"\"\"Calculate recall score\"\"\"\n        true_positives = torch.sum((predictions == 1) & (targets == 1))\n        actual_positives = torch.sum(targets == 1)\n        return true_positives / (actual_positives + 1e-10)\n    \n    def _calculate_f1(self,\n                     predictions: torch.Tensor,\n                     targets: torch.Tensor) -> float:\n        \"\"\"Calculate F1 score\"\"\"\n        precision = self._calculate_precision(predictions, targets)\n        recall = self._calculate_recall(predictions, targets)\n        return 2 * (precision * recall) / (precision + recall + 1e-10)\n    \n    def _calculate_auc_roc(self,\n                          predictions: torch.Tensor,\n                          targets: torch.Tensor) -> float:\n        \"\"\"Calculate AUC-ROC score\"\"\"\n        # Sort predictions and targets\n        sorted_pairs = sorted(\n            zip(predictions.numpy(), targets.numpy()),\n            key=lambda x: x[0],\n            reverse=True\n        )\n        sorted_preds, sorted_targets = zip(*sorted_pairs)\n        \n        # Calculate TPR and FPR\n        n_positive = sum(sorted_targets)\n        n_negative = len(sorted_targets) - n_positive\n        \n        if n_positive * n_negative == 0:\n            return 0.5\n        \n        # Calculate AUC\n        tpr = 0\n        fpr = 0\n        auc = 0\n        \n        for i in range(len(sorted_targets)):\n            if sorted_targets[i] == 1:\n                tpr += 1\n            else:\n                fpr += 1\n                auc += tpr\n        \n        return auc / (n_positive * n_negative)\n    \n    def _create_data_loader(self,\n                          data: Dict[str, torch.Tensor],\n                          batch_size: int,\n                          shuffle: bool) -> DataLoader:\n        \"\"\"Create data loader\"\"\"\n        dataset = TensorDataset(\n            data['features'],\n            data['labels']\n        )\n        \n        return DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            num_workers=4,\n            pin_memory=True\n        )\n    \n    def _get_criterion(self, loss_name: str) -> nn.Module:\n        \"\"\"Get loss function\"\"\"\n        if loss_name == 'bce':\n            return nn.BCEWithLogitsLoss()\n        elif loss_name == 'mse':\n            return nn.MSELoss()\n        else:\n            raise ValueError(f\"Unknown loss function: {loss_name}\")\n    \n    def _get_optimizer(self,\n                      optimizer_name: str,\n                      learning_rate: float) -> optim.Optimizer:\n        \"\"\"Get optimizer\"\"\"\n        if optimizer_name == 'adam':\n            return optim.Adam(self.model.parameters(), lr=learning_rate)\n        elif optimizer_name == 'sgd':\n            return optim.SGD(\n                self.model.parameters(),\n                lr=learning_rate,\n                momentum=0.9\n            )\n        else:\n            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n    \n    def _get_scheduler(self,\n                      optimizer: optim.Optimizer,\n                      config: Dict[str, Any]) -> Optional[optim.lr_scheduler._LRScheduler]:\n        \"\"\"Get learning rate scheduler\"\"\"\n        if 'scheduler' not in config:\n            return None\n            \n        scheduler_config = config['scheduler']\n        scheduler_name = scheduler_config['name']\n        \n        if scheduler_name == 'reduce_on_plateau':\n            return optim.lr_scheduler.ReduceLROnPlateau(\n                optimizer,\n                mode='min',\n                factor=scheduler_config.get('factor', 0.1),\n                patience=scheduler_config.get('patience', 10),\n                verbose=True\n            )\n        elif scheduler_name == 'cosine':\n            return optim.lr_scheduler.CosineAnnealingLR(\n                optimizer,\n                T_max=config['epochs'],\n                eta_min=scheduler_config.get('min_lr', 0)\n            )\n        else:\n            raise ValueError(f\"Unknown scheduler: {scheduler_name}\")\n    \n    def _save_checkpoint(self,\n                        epoch: int,\n                        val_loss: float,\n                        metrics: Dict[str, float]):\n        \"\"\"Save model checkpoint\"\"\"\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': self.model.state_dict(),\n            'val_loss': val_loss,\n            'metrics': metrics\n        }\n        \n        path = self.output_dir / f\"checkpoint_epoch_{epoch}.pt\"\n        torch.save(checkpoint, path)\n        \n        # Save metrics\n        metrics_path = self.output_dir / f\"metrics_epoch_{epoch}.json\"\n        with open(metrics_path, 'w') as f:\n            json.dump(metrics, f, indent=2)\n    \n    def _setup_logger(self) -> logging.Logger:\n        \"\"\"Setup logging\"\"\"\n        logger = logging.getLogger('ModelTrainer')\n        logger.setLevel(logging.INFO)\n        \n        # Create handlers\n        console_handler = logging.StreamHandler()\n        file_handler = logging.FileHandler(\n            self.output_dir / f\"training_{datetime.now():%Y%m%d_%H%M%S}.log\"\n        )\n        \n        # Create formatter\n        formatter = logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        )\n        console_handler.setFormatter(formatter)\n        file_handler.setFormatter(formatter)\n        \n        # Add handlers\n        logger.addHandler(console_handler)\n        logger.addHandler(file_handler)\n        \n        return logger "}
{"type": "source_file", "path": "minesight/core/config.py", "content": "\"\"\"\nConfiguration management for MineSight\n\"\"\"\nfrom typing import Dict, Any, Optional\nfrom pathlib import Path\nimport yaml\nfrom pydantic import BaseModel, Field\nfrom dataclasses import dataclass\n\n@dataclass\nclass ModelConfig:\n    \"\"\"Model configuration\"\"\"\n    input_dim: int\n    hidden_dims: list[int] = Field(default_factory=lambda: [256, 128, 64])\n    dropout: float = 0.3\n    model_type: str = \"mineral\"  # One of: mineral, autoencoder, vae\n\n@dataclass\nclass TrainingConfig:\n    \"\"\"Training configuration\"\"\"\n    batch_size: int = 32\n    epochs: int = 100\n    learning_rate: float = 0.001\n    optimizer: str = \"adam\"\n    loss: str = \"bce\"\n    scheduler: Optional[Dict[str, Any]] = None\n\n@dataclass\nclass DataConfig:\n    \"\"\"Data configuration\"\"\"\n    data_dir: Path\n    deposits_file: str\n    features_file: str\n    cache_dir: Optional[Path] = None\n    numerical_features: list[str] = Field(default_factory=list)\n    categorical_features: list[str] = Field(default_factory=list)\n    label_column: str = \"deposit\"\n    binary_labels: bool = True\n    test_size: float = 0.2\n    val_size: float = 0.2\n    deposit_filters: Dict[str, Any] = Field(default_factory=dict)\n    feature_filters: Dict[str, Any] = Field(default_factory=dict)\n\nclass Config:\n    \"\"\"Configuration manager\"\"\"\n    \n    def __init__(self,\n                 config_path: Optional[Path] = None,\n                 **kwargs):\n        \"\"\"\n        Initialize configuration\n        \n        Args:\n            config_path: Path to YAML configuration file\n            **kwargs: Override configuration values\n        \"\"\"\n        # Load config\n        self.config = self._load_config(config_path)\n        \n        # Override with kwargs\n        self._update_config(kwargs)\n        \n        # Create sub-configs\n        self.model = ModelConfig(**self.config['model'])\n        self.training = TrainingConfig(**self.config['training'])\n        self.data = DataConfig(**self.config['data'])\n    \n    def _load_config(self, config_path: Optional[Path]) -> Dict[str, Any]:\n        \"\"\"Load configuration from file\"\"\"\n        # Default config\n        config = {\n            'model': {\n                'input_dim': 0,  # Must be set based on data\n                'hidden_dims': [256, 128, 64],\n                'dropout': 0.3,\n                'model_type': 'mineral'\n            },\n            'training': {\n                'batch_size': 32,\n                'epochs': 100,\n                'learning_rate': 0.001,\n                'optimizer': 'adam',\n                'loss': 'bce',\n                'scheduler': {\n                    'name': 'reduce_on_plateau',\n                    'factor': 0.1,\n                    'patience': 10\n                }\n            },\n            'data': {\n                'data_dir': 'data',\n                'deposits_file': 'deposits.csv',\n                'features_file': 'features.csv',\n                'cache_dir': 'cache',\n                'numerical_features': [],\n                'categorical_features': [],\n                'label_column': 'deposit',\n                'binary_labels': True,\n                'test_size': 0.2,\n                'val_size': 0.2,\n                'deposit_filters': {},\n                'feature_filters': {}\n            }\n        }\n        \n        # Load from file if provided\n        if config_path is not None:\n            with open(config_path) as f:\n                file_config = yaml.safe_load(f)\n                self._update_nested_dict(config, file_config)\n        \n        return config\n    \n    def _update_config(self, updates: Dict[str, Any]):\n        \"\"\"Update configuration with new values\"\"\"\n        for key, value in updates.items():\n            if key in self.config:\n                if isinstance(value, dict) and isinstance(self.config[key], dict):\n                    self._update_nested_dict(self.config[key], value)\n                else:\n                    self.config[key] = value\n    \n    def _update_nested_dict(self,\n                           base_dict: Dict[str, Any],\n                           update_dict: Dict[str, Any]):\n        \"\"\"Update nested dictionary\"\"\"\n        for key, value in update_dict.items():\n            if key in base_dict:\n                if isinstance(value, dict) and isinstance(base_dict[key], dict):\n                    self._update_nested_dict(base_dict[key], value)\n                else:\n                    base_dict[key] = value\n    \n    def save(self, path: Path):\n        \"\"\"Save configuration to file\"\"\"\n        with open(path, 'w') as f:\n            yaml.dump(self.config, f, default_flow_style=False)\n    \n    @classmethod\n    def from_file(cls, path: Path) -> 'Config':\n        \"\"\"Load configuration from file\"\"\"\n        return cls(config_path=path)\n    \n    def validate(self):\n        \"\"\"Validate configuration\"\"\"\n        # Validate model config\n        if self.model.input_dim <= 0:\n            raise ValueError(\"Model input dimension must be positive\")\n        \n        if not self.model.hidden_dims:\n            raise ValueError(\"Model must have at least one hidden layer\")\n        \n        if not 0 <= self.model.dropout < 1:\n            raise ValueError(\"Dropout must be between 0 and 1\")\n        \n        if self.model.model_type not in ['mineral', 'autoencoder', 'vae']:\n            raise ValueError(\"Invalid model type\")\n        \n        # Validate training config\n        if self.training.batch_size <= 0:\n            raise ValueError(\"Batch size must be positive\")\n        \n        if self.training.epochs <= 0:\n            raise ValueError(\"Number of epochs must be positive\")\n        \n        if self.training.learning_rate <= 0:\n            raise ValueError(\"Learning rate must be positive\")\n        \n        if self.training.optimizer not in ['adam', 'sgd']:\n            raise ValueError(\"Invalid optimizer\")\n        \n        if self.training.loss not in ['bce', 'mse']:\n            raise ValueError(\"Invalid loss function\")\n        \n        # Validate data config\n        if not self.data.data_dir.exists():\n            raise ValueError(f\"Data directory {self.data.data_dir} does not exist\")\n        \n        if not (self.data.data_dir / self.data.deposits_file).exists():\n            raise ValueError(f\"Deposits file {self.data.deposits_file} does not exist\")\n        \n        if not (self.data.data_dir / self.data.features_file).exists():\n            raise ValueError(f\"Features file {self.data.features_file} does not exist\")\n        \n        if not 0 < self.data.test_size < 1:\n            raise ValueError(\"Test size must be between 0 and 1\")\n        \n        if not 0 < self.data.val_size < 1:\n            raise ValueError(\"Validation size must be between 0 and 1\")\n        \n        if self.data.test_size + self.data.val_size >= 1:\n            raise ValueError(\"Test and validation sizes too large\") "}
{"type": "source_file", "path": "minesight/core/models/base_model.py", "content": "\"\"\"\nBase model for mineral prediction\n\"\"\"\nfrom typing import Dict, List, Any, Tuple\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\n\nclass BaseMineralModel:\n    \"\"\"Base class for mineral prediction models\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the model\"\"\"\n        self.model = RandomForestClassifier(\n            n_estimators=100,\n            max_depth=10,\n            random_state=42\n        )\n        self.scaler = StandardScaler()\n        self.feature_names = [\n            \"latitude\",\n            \"longitude\",\n            \"elevation\",\n            \"rock_type\",\n            \"geological_age\"\n        ]\n        \n    def preprocess_features(self, raw_data: Dict[str, Any]) -> np.ndarray:\n        \"\"\"\n        Preprocess raw input data into model features\n        \n        Args:\n            raw_data: Dictionary containing raw input data\n            \n        Returns:\n            Preprocessed feature array\n        \"\"\"\n        # Extract basic features\n        features = [\n            raw_data[\"latitude\"],\n            raw_data[\"longitude\"],\n            raw_data.get(\"elevation\", 0),\n            self._encode_rock_type(raw_data.get(\"rock_type\", \"unknown\")),\n            self._encode_geological_age(raw_data.get(\"geological_age\", \"unknown\"))\n        ]\n        \n        return np.array(features).reshape(1, -1)\n    \n    def _encode_rock_type(self, rock_type: str) -> float:\n        \"\"\"Simple encoding for rock types\"\"\"\n        rock_type_map = {\n            \"igneous\": 1.0,\n            \"sedimentary\": 2.0,\n            \"metamorphic\": 3.0,\n            \"unknown\": 0.0\n        }\n        return rock_type_map.get(rock_type.lower(), 0.0)\n    \n    def _encode_geological_age(self, age: str) -> float:\n        \"\"\"Simple encoding for geological ages\"\"\"\n        age_map = {\n            \"precambrian\": 1.0,\n            \"paleozoic\": 2.0,\n            \"mesozoic\": 3.0,\n            \"cenozoic\": 4.0,\n            \"unknown\": 0.0\n        }\n        return age_map.get(age.lower(), 0.0)\n    \n    def predict(self, features: Dict[str, Any]) -> Tuple[float, float]:\n        \"\"\"\n        Make a prediction for given features\n        \n        Args:\n            features: Dictionary of input features\n            \n        Returns:\n            Tuple of (probability, confidence)\n        \"\"\"\n        try:\n            # Preprocess features\n            X = self.preprocess_features(features)\n            \n            # Make prediction\n            probabilities = self.model.predict_proba(X)[0]\n            prediction = float(probabilities[1])  # Probability of positive class\n            \n            # Calculate confidence based on prediction certainty\n            confidence = abs(prediction - 0.5) * 2  # Scale to [0, 1]\n            \n            return prediction, confidence\n            \n        except Exception as e:\n            print(f\"Prediction error: {str(e)}\")\n            return 0.0, 0.0\n    \n    def train(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Train the model\n        \n        Args:\n            X: Feature matrix\n            y: Target labels\n        \"\"\"\n        # Scale features\n        X_scaled = self.scaler.fit_transform(X)\n        \n        # Train model\n        self.model.fit(X_scaled, y)\n    \n    def get_feature_importance(self) -> Dict[str, float]:\n        \"\"\"\n        Get feature importance scores\n        \n        Returns:\n            Dictionary mapping feature names to importance scores\n        \"\"\"\n        if not hasattr(self.model, 'feature_importances_'):\n            return {}\n            \n        importance_dict = {}\n        for name, importance in zip(self.feature_names, self.model.feature_importances_):\n            importance_dict[name] = float(importance)\n            \n        return importance_dict "}
{"type": "source_file", "path": "minesight/core/anomaly/anomaly_detector.py", "content": "\"\"\"\nIntelligent anomaly detection system for mineral exploration data\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Union\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom dataclasses import dataclass\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport torch\nimport torch.nn as nn\nfrom scipy import stats\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n@dataclass\nclass AnomalyScore:\n    \"\"\"Data class for anomaly scores\"\"\"\n    score: float\n    confidence: float\n    category: str\n    features: List[str]\n    timestamp: datetime\n    metadata: Optional[Dict[str, Any]] = None\n\nclass AutoEncoder(nn.Module):\n    \"\"\"Autoencoder for unsupervised anomaly detection\"\"\"\n    \n    def __init__(self, input_dim: int, encoding_dim: int = 10):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, encoding_dim * 2),\n            nn.ReLU(),\n            nn.Linear(encoding_dim * 2, encoding_dim),\n            nn.ReLU()\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(encoding_dim, encoding_dim * 2),\n            nn.ReLU(),\n            nn.Linear(encoding_dim * 2, input_dim),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nclass AnomalyDetector:\n    \"\"\"Intelligent anomaly detection system\"\"\"\n    \n    def __init__(self, config: Optional[Dict] = None):\n        \"\"\"\n        Initialize the anomaly detector\n        \n        Args:\n            config: Optional configuration dictionary\n        \"\"\"\n        self.config = config or {\n            \"isolation_forest\": {\n                \"contamination\": 0.1,\n                \"n_estimators\": 100,\n                \"random_state\": 42\n            },\n            \"autoencoder\": {\n                \"encoding_dim\": 10,\n                \"learning_rate\": 0.001,\n                \"epochs\": 100,\n                \"batch_size\": 32\n            },\n            \"thresholds\": {\n                \"zscore\": 3.0,\n                \"reconstruction_error\": 0.1,\n                \"isolation_score\": -0.5\n            }\n        }\n        \n        self.scaler = StandardScaler()\n        self.pca = PCA(n_components=0.95)  # Keep 95% variance\n        self.isolation_forest = IsolationForest(**self.config[\"isolation_forest\"])\n        self.autoencoder = None\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n    def train(self, data: pd.DataFrame):\n        \"\"\"\n        Train the anomaly detection models\n        \n        Args:\n            data: Training data\n        \"\"\"\n        if data.empty:\n            raise ValueError(\"Empty training data\")\n            \n        # Prepare data\n        X = self._prepare_data(data)\n        \n        # Train Isolation Forest\n        self.isolation_forest.fit(X)\n        \n        # Train Autoencoder\n        self._train_autoencoder(X)\n        \n    def detect_anomalies(self, data: Union[pd.DataFrame, Dict]) -> List[AnomalyScore]:\n        \"\"\"\n        Detect anomalies in the input data\n        \n        Args:\n            data: Input data for anomaly detection\n            \n        Returns:\n            List of anomaly scores\n        \"\"\"\n        if isinstance(data, dict):\n            data = pd.DataFrame([data])\n            \n        # Prepare data\n        X = self._prepare_data(data)\n        \n        # Get anomaly scores from different methods\n        scores = []\n        \n        # Statistical anomalies\n        stat_scores = self._detect_statistical_anomalies(X)\n        scores.extend(stat_scores)\n        \n        # Isolation Forest anomalies\n        if_scores = self._detect_isolation_forest_anomalies(X)\n        scores.extend(if_scores)\n        \n        # Autoencoder anomalies\n        ae_scores = self._detect_autoencoder_anomalies(X)\n        scores.extend(ae_scores)\n        \n        return self._combine_anomaly_scores(scores)\n        \n    def analyze_anomaly_patterns(self, anomalies: List[AnomalyScore]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze patterns in detected anomalies\n        \n        Args:\n            anomalies: List of detected anomalies\n            \n        Returns:\n            Dictionary with pattern analysis results\n        \"\"\"\n        if not anomalies:\n            return {}\n            \n        analysis = {\n            \"total_anomalies\": len(anomalies),\n            \"category_distribution\": {},\n            \"feature_importance\": {},\n            \"temporal_patterns\": {},\n            \"severity_distribution\": {}\n        }\n        \n        # Analyze category distribution\n        for anomaly in anomalies:\n            analysis[\"category_distribution\"][anomaly.category] = \\\n                analysis[\"category_distribution\"].get(anomaly.category, 0) + 1\n                \n        # Analyze feature importance\n        feature_counts = {}\n        for anomaly in anomalies:\n            for feature in anomaly.features:\n                feature_counts[feature] = feature_counts.get(feature, 0) + 1\n        analysis[\"feature_importance\"] = feature_counts\n        \n        # Analyze temporal patterns\n        timestamps = [a.timestamp for a in anomalies]\n        if timestamps:\n            analysis[\"temporal_patterns\"] = {\n                \"earliest\": min(timestamps),\n                \"latest\": max(timestamps),\n                \"peak_time\": max(timestamps, key=timestamps.count)\n            }\n            \n        # Analyze severity distribution\n        scores = [a.score for a in anomalies]\n        analysis[\"severity_distribution\"] = {\n            \"min\": min(scores),\n            \"max\": max(scores),\n            \"mean\": np.mean(scores),\n            \"std\": np.std(scores)\n        }\n        \n        return analysis\n        \n    def generate_anomaly_report(self, \n                              anomalies: List[AnomalyScore],\n                              output_path: Optional[str] = None) -> str:\n        \"\"\"\n        Generate comprehensive anomaly analysis report\n        \n        Args:\n            anomalies: List of detected anomalies\n            output_path: Optional output path for the report\n            \n        Returns:\n            Path to generated report\n        \"\"\"\n        if not output_path:\n            output_path = f\"anomaly_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n            \n        # Create report layout\n        fig = make_subplots(\n            rows=3,\n            cols=2,\n            subplot_titles=(\n                \"Anomaly Score Distribution\",\n                \"Category Distribution\",\n                \"Feature Importance\",\n                \"Temporal Pattern\",\n                \"Severity by Category\",\n                \"Anomaly Locations\"\n            )\n        )\n        \n        # Add visualizations\n        self._add_score_distribution(fig, anomalies, row=1, col=1)\n        self._add_category_distribution(fig, anomalies, row=1, col=2)\n        self._add_feature_importance(fig, anomalies, row=2, col=1)\n        self._add_temporal_pattern(fig, anomalies, row=2, col=2)\n        self._add_severity_by_category(fig, anomalies, row=3, col=1)\n        self._add_anomaly_locations(fig, anomalies, row=3, col=2)\n        \n        # Update layout\n        fig.update_layout(\n            height=1200,\n            showlegend=True,\n            title_text=\"Anomaly Detection Analysis Report\"\n        )\n        \n        # Save report\n        fig.write_html(output_path)\n        \n        return output_path\n        \n    def _prepare_data(self, data: pd.DataFrame) -> np.ndarray:\n        \"\"\"Prepare data for anomaly detection\"\"\"\n        # Select numerical columns\n        numerical_data = data.select_dtypes(include=[np.number])\n        \n        if numerical_data.empty:\n            raise ValueError(\"No numerical data available for anomaly detection\")\n            \n        # Scale data\n        X = self.scaler.fit_transform(numerical_data)\n        \n        # Apply PCA\n        X = self.pca.fit_transform(X)\n        \n        return X\n        \n    def _train_autoencoder(self, X: np.ndarray):\n        \"\"\"Train autoencoder model\"\"\"\n        # Initialize autoencoder\n        input_dim = X.shape[1]\n        self.autoencoder = AutoEncoder(\n            input_dim=input_dim,\n            encoding_dim=self.config[\"autoencoder\"][\"encoding_dim\"]\n        ).to(self.device)\n        \n        # Convert data to tensor\n        X_tensor = torch.FloatTensor(X).to(self.device)\n        \n        # Create data loader\n        dataset = torch.utils.data.TensorDataset(X_tensor, X_tensor)\n        dataloader = torch.utils.data.DataLoader(\n            dataset,\n            batch_size=self.config[\"autoencoder\"][\"batch_size\"],\n            shuffle=True\n        )\n        \n        # Initialize optimizer\n        optimizer = torch.optim.Adam(\n            self.autoencoder.parameters(),\n            lr=self.config[\"autoencoder\"][\"learning_rate\"]\n        )\n        \n        # Train autoencoder\n        self.autoencoder.train()\n        for epoch in range(self.config[\"autoencoder\"][\"epochs\"]):\n            total_loss = 0\n            for batch_X, _ in dataloader:\n                # Forward pass\n                reconstructed = self.autoencoder(batch_X)\n                loss = nn.MSELoss()(reconstructed, batch_X)\n                \n                # Backward pass\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                \n                total_loss += loss.item()\n            \n            avg_loss = total_loss / len(dataloader)\n            if epoch % 10 == 0:\n                print(f\"Epoch {epoch}, Average Loss: {avg_loss:.6f}\")\n\n    def _detect_statistical_anomalies(self, X: np.ndarray) -> List[AnomalyScore]:\n        \"\"\"Detect anomalies using statistical methods\"\"\"\n        anomalies = []\n        \n        # Calculate z-scores for each feature\n        z_scores = stats.zscore(X)\n        \n        # Find anomalies based on z-score threshold\n        threshold = self.config[\"thresholds\"][\"zscore\"]\n        anomaly_mask = np.abs(z_scores) > threshold\n        \n        for i in range(len(X)):\n            anomalous_features = np.where(anomaly_mask[i])[0]\n            if len(anomalous_features) > 0:\n                # Calculate anomaly score based on maximum z-score\n                max_zscore = np.max(np.abs(z_scores[i]))\n                score = 1 - (threshold / max_zscore) if max_zscore > threshold else 0\n                \n                anomalies.append(AnomalyScore(\n                    score=float(score),\n                    confidence=min(1.0, score * 1.5),  # Scale confidence based on score\n                    category=\"statistical\",\n                    features=[f\"feature_{j}\" for j in anomalous_features],\n                    timestamp=datetime.now(),\n                    metadata={\n                        \"z_scores\": z_scores[i].tolist(),\n                        \"threshold\": threshold\n                    }\n                ))\n        \n        return anomalies\n\n    def _detect_isolation_forest_anomalies(self, X: np.ndarray) -> List[AnomalyScore]:\n        \"\"\"Detect anomalies using Isolation Forest\"\"\"\n        anomalies = []\n        \n        # Get anomaly scores from Isolation Forest\n        scores = self.isolation_forest.score_samples(X)\n        predictions = self.isolation_forest.predict(X)\n        \n        # Find anomalies based on threshold\n        threshold = self.config[\"thresholds\"][\"isolation_score\"]\n        \n        for i in range(len(X)):\n            if predictions[i] == -1 or scores[i] < threshold:\n                # Calculate normalized anomaly score\n                score = 1 - (1 / (1 + np.exp(-scores[i])))\n                \n                # Identify contributing features using feature importances\n                feature_importances = self._get_feature_importances(X[i])\n                anomalous_features = [\n                    f\"feature_{j}\" for j, imp in enumerate(feature_importances)\n                    if imp > np.mean(feature_importances) + np.std(feature_importances)\n                ]\n                \n                anomalies.append(AnomalyScore(\n                    score=float(score),\n                    confidence=min(1.0, score * 1.2),  # Scale confidence based on score\n                    category=\"isolation_forest\",\n                    features=anomalous_features,\n                    timestamp=datetime.now(),\n                    metadata={\n                        \"isolation_score\": float(scores[i]),\n                        \"threshold\": threshold,\n                        \"feature_importances\": feature_importances.tolist()\n                    }\n                ))\n        \n        return anomalies\n\n    def _detect_autoencoder_anomalies(self, X: np.ndarray) -> List[AnomalyScore]:\n        \"\"\"Detect anomalies using Autoencoder\"\"\"\n        if self.autoencoder is None:\n            return []\n            \n        anomalies = []\n        \n        # Convert data to tensor\n        X_tensor = torch.FloatTensor(X).to(self.device)\n        \n        # Get reconstructions\n        self.autoencoder.eval()\n        with torch.no_grad():\n            reconstructed = self.autoencoder(X_tensor)\n        \n        # Calculate reconstruction errors\n        reconstruction_errors = nn.MSELoss(reduction='none')(X_tensor, reconstructed)\n        reconstruction_errors = reconstruction_errors.mean(dim=1).cpu().numpy()\n        \n        # Find anomalies based on reconstruction error threshold\n        threshold = self.config[\"thresholds\"][\"reconstruction_error\"]\n        \n        for i in range(len(X)):\n            if reconstruction_errors[i] > threshold:\n                # Calculate normalized anomaly score\n                score = min(1.0, reconstruction_errors[i] / (threshold * 2))\n                \n                # Calculate feature-wise reconstruction errors\n                feature_errors = nn.MSELoss(reduction='none')(\n                    X_tensor[i],\n                    reconstructed[i]\n                ).cpu().numpy()\n                \n                # Identify features with high reconstruction error\n                anomalous_features = [\n                    f\"feature_{j}\" for j, error in enumerate(feature_errors)\n                    if error > np.mean(feature_errors) + np.std(feature_errors)\n                ]\n                \n                anomalies.append(AnomalyScore(\n                    score=float(score),\n                    confidence=min(1.0, score * 1.3),  # Scale confidence based on score\n                    category=\"autoencoder\",\n                    features=anomalous_features,\n                    timestamp=datetime.now(),\n                    metadata={\n                        \"reconstruction_error\": float(reconstruction_errors[i]),\n                        \"threshold\": threshold,\n                        \"feature_errors\": feature_errors.tolist()\n                    }\n                ))\n        \n        return anomalies\n\n    def _combine_anomaly_scores(self, scores: List[AnomalyScore]) -> List[AnomalyScore]:\n        \"\"\"Combine anomaly scores from different methods\"\"\"\n        if not scores:\n            return []\n            \n        # Group scores by timestamp (assuming they're from the same data point)\n        grouped_scores = {}\n        for score in scores:\n            timestamp_key = score.timestamp.strftime(\"%Y%m%d%H%M%S\")\n            if timestamp_key not in grouped_scores:\n                grouped_scores[timestamp_key] = []\n            grouped_scores[timestamp_key].append(score)\n        \n        # Combine scores for each group\n        combined_scores = []\n        for timestamp_key, group_scores in grouped_scores.items():\n            # Calculate weighted average score\n            weights = {\n                \"statistical\": 0.3,\n                \"isolation_forest\": 0.3,\n                \"autoencoder\": 0.4\n            }\n            \n            total_score = 0\n            total_weight = 0\n            all_features = set()\n            combined_metadata = {}\n            \n            for score in group_scores:\n                weight = weights.get(score.category, 0.3)\n                total_score += score.score * weight\n                total_weight += weight\n                all_features.update(score.features)\n                combined_metadata[score.category] = score.metadata\n            \n            avg_score = total_score / total_weight if total_weight > 0 else 0\n            \n            # Calculate combined confidence\n            confidences = [score.confidence for score in group_scores]\n            combined_confidence = np.mean(confidences) * (1 + np.std(confidences))\n            \n            combined_scores.append(AnomalyScore(\n                score=float(avg_score),\n                confidence=float(min(1.0, combined_confidence)),\n                category=\"combined\",\n                features=sorted(list(all_features)),\n                timestamp=datetime.fromisoformat(timestamp_key),\n                metadata={\n                    \"component_scores\": {s.category: s.score for s in group_scores},\n                    \"component_confidences\": {s.category: s.confidence for s in group_scores},\n                    \"details\": combined_metadata\n                }\n            ))\n        \n        return sorted(combined_scores, key=lambda x: x.score, reverse=True)\n\n    def _get_feature_importances(self, sample: np.ndarray) -> np.ndarray:\n        \"\"\"Calculate feature importances for a sample\"\"\"\n        # Use PCA components as feature importance proxy\n        transformed = self.pca.transform(sample.reshape(1, -1))\n        components = self.pca.components_\n        \n        # Calculate feature contributions\n        contributions = np.abs(components.T.dot(transformed.T)).flatten()\n        \n        # Normalize contributions\n        return contributions / np.sum(contributions)\n        \n    def _add_score_distribution(self, fig, anomalies: List[AnomalyScore], row: int, col: int):\n        \"\"\"Add anomaly score distribution plot\"\"\"\n        scores = [a.score for a in anomalies]\n        confidences = [a.confidence for a in anomalies]\n        \n        # Create violin plot for score distribution\n        fig.add_trace(\n            go.Violin(\n                y=scores,\n                name=\"Anomaly Scores\",\n                box_visible=True,\n                meanline_visible=True,\n                fillcolor=\"lightblue\",\n                line_color=\"blue\"\n            ),\n            row=row,\n            col=col\n        )\n        \n        # Add scatter points for confidence\n        fig.add_trace(\n            go.Scatter(\n                y=confidences,\n                mode=\"markers\",\n                name=\"Confidence\",\n                marker=dict(\n                    color=\"red\",\n                    size=8,\n                    symbol=\"diamond\"\n                )\n            ),\n            row=row,\n            col=col\n        )\n        \n        # Update layout\n        fig.update_xaxes(title_text=\"Distribution\", row=row, col=col)\n        fig.update_yaxes(title_text=\"Score / Confidence\", row=row, col=col)\n\n    def _add_category_distribution(self, fig, anomalies: List[AnomalyScore], row: int, col: int):\n        \"\"\"Add category distribution plot\"\"\"\n        # Count anomalies by category\n        category_counts = {}\n        for anomaly in anomalies:\n            category_counts[anomaly.category] = category_counts.get(anomaly.category, 0) + 1\n        \n        categories = list(category_counts.keys())\n        counts = list(category_counts.values())\n        \n        # Create bar plot\n        fig.add_trace(\n            go.Bar(\n                x=categories,\n                y=counts,\n                marker_color=\"lightgreen\",\n                name=\"Categories\"\n            ),\n            row=row,\n            col=col\n        )\n        \n        # Add text annotations\n        for i, count in enumerate(counts):\n            fig.add_annotation(\n                x=categories[i],\n                y=count,\n                text=str(count),\n                showarrow=False,\n                yshift=10,\n                row=row,\n                col=col\n            )\n        \n        # Update layout\n        fig.update_xaxes(\n            title_text=\"Category\",\n            tickangle=45,\n            row=row,\n            col=col\n        )\n        fig.update_yaxes(title_text=\"Count\", row=row, col=col)\n\n    def _add_feature_importance(self, fig, anomalies: List[AnomalyScore], row: int, col: int):\n        \"\"\"Add feature importance plot\"\"\"\n        # Calculate feature frequencies\n        feature_counts = {}\n        for anomaly in anomalies:\n            for feature in anomaly.features:\n                feature_counts[feature] = feature_counts.get(feature, 0) + 1\n        \n        # Sort features by frequency\n        sorted_features = sorted(\n            feature_counts.items(),\n            key=lambda x: x[1],\n            reverse=True\n        )\n        \n        features = [f[0] for f in sorted_features]\n        counts = [f[1] for f in sorted_features]\n        \n        # Create horizontal bar plot\n        fig.add_trace(\n            go.Bar(\n                y=features,\n                x=counts,\n                orientation=\"h\",\n                marker_color=\"orange\",\n                name=\"Features\"\n            ),\n            row=row,\n            col=col\n        )\n        \n        # Add percentage labels\n        total_anomalies = len(anomalies)\n        for i, count in enumerate(counts):\n            percentage = (count / total_anomalies) * 100\n            fig.add_annotation(\n                x=count,\n                y=features[i],\n                text=f\"{percentage:.1f}%\",\n                showarrow=False,\n                xshift=10,\n                row=row,\n                col=col\n            )\n        \n        # Update layout\n        fig.update_xaxes(title_text=\"Frequency\", row=row, col=col)\n        fig.update_yaxes(title_text=\"Feature\", row=row, col=col)\n\n    def _add_temporal_pattern(self, fig, anomalies: List[AnomalyScore], row: int, col: int):\n        \"\"\"Add temporal pattern plot\"\"\"\n        timestamps = [a.timestamp for a in anomalies]\n        scores = [a.score for a in anomalies]\n        categories = [a.category for a in anomalies]\n        \n        # Create scatter plot\n        for category in set(categories):\n            category_indices = [i for i, c in enumerate(categories) if c == category]\n            category_times = [timestamps[i] for i in category_indices]\n            category_scores = [scores[i] for i in category_indices]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=category_times,\n                    y=category_scores,\n                    mode=\"markers+lines\",\n                    name=category,\n                    marker=dict(size=8),\n                    line=dict(width=1, dash=\"dot\")\n                ),\n                row=row,\n                col=col\n            )\n        \n        # Add trend line\n        if len(timestamps) > 1:\n            z = np.polyfit(\n                [t.timestamp() for t in timestamps],\n                scores,\n                1\n            )\n            p = np.poly1d(z)\n            \n            trend_times = [min(timestamps), max(timestamps)]\n            trend_scores = [\n                p(t.timestamp()) for t in trend_times\n            ]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=trend_times,\n                    y=trend_scores,\n                    mode=\"lines\",\n                    name=\"Trend\",\n                    line=dict(\n                        color=\"red\",\n                        width=2\n                    )\n                ),\n                row=row,\n                col=col\n            )\n        \n        # Update layout\n        fig.update_xaxes(\n            title_text=\"Time\",\n            tickangle=45,\n            row=row,\n            col=col\n        )\n        fig.update_yaxes(title_text=\"Anomaly Score\", row=row, col=col)\n\n    def _add_severity_by_category(self, fig, anomalies: List[AnomalyScore], row: int, col: int):\n        \"\"\"Add severity by category plot\"\"\"\n        # Group scores by category\n        category_scores = {}\n        for anomaly in anomalies:\n            if anomaly.category not in category_scores:\n                category_scores[anomaly.category] = []\n            category_scores[anomaly.category].append(anomaly.score)\n        \n        # Create box plot data\n        categories = []\n        scores = []\n        for category, category_scores in category_scores.items():\n            categories.extend([category] * len(category_scores))\n            scores.extend(category_scores)\n        \n        # Create box plot\n        fig.add_trace(\n            go.Box(\n                x=categories,\n                y=scores,\n                name=\"Severity\",\n                marker_color=\"purple\"\n            ),\n            row=row,\n            col=col\n        )\n        \n        # Add mean markers\n        for category in set(categories):\n            category_scores = [s for i, s in enumerate(scores) if categories[i] == category]\n            mean_score = np.mean(category_scores)\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=[category],\n                    y=[mean_score],\n                    mode=\"markers\",\n                    name=f\"{category} Mean\",\n                    marker=dict(\n                        color=\"red\",\n                        size=10,\n                        symbol=\"star\"\n                    ),\n                    showlegend=False\n                ),\n                row=row,\n                col=col\n            )\n        \n        # Update layout\n        fig.update_xaxes(\n            title_text=\"Category\",\n            tickangle=45,\n            row=row,\n            col=col\n        )\n        fig.update_yaxes(title_text=\"Severity Score\", row=row, col=col)\n\n    def _add_anomaly_locations(self, fig, anomalies: List[AnomalyScore], row: int, col: int):\n        \"\"\"Add anomaly locations plot\"\"\"\n        # Extract feature indices\n        all_features = set()\n        for anomaly in anomalies:\n            all_features.update(\n                int(f.split('_')[1]) for f in anomaly.features\n                if f.startswith('feature_')\n            )\n        \n        feature_indices = sorted(list(all_features))\n        max_feature_idx = max(feature_indices) if feature_indices else 0\n        \n        # Create heatmap data\n        heatmap_data = np.zeros((len(anomalies), max_feature_idx + 1))\n        \n        for i, anomaly in enumerate(anomalies):\n            for feature in anomaly.features:\n                if feature.startswith('feature_'):\n                    idx = int(feature.split('_')[1])\n                    if idx <= max_feature_idx:\n                        heatmap_data[i, idx] = anomaly.score\n        \n        # Create heatmap\n        fig.add_trace(\n            go.Heatmap(\n                z=heatmap_data,\n                x=[f\"F{i}\" for i in range(max_feature_idx + 1)],\n                y=[f\"A{i}\" for i in range(len(anomalies))],\n                colorscale=\"Viridis\",\n                showscale=True,\n                colorbar=dict(title=\"Score\")\n            ),\n            row=row,\n            col=col\n        )\n        \n        # Update layout\n        fig.update_xaxes(title_text=\"Feature Index\", row=row, col=col)\n        fig.update_yaxes(title_text=\"Anomaly Index\", row=row, col=col) "}
{"type": "source_file", "path": "minesight/core/analysis/analyzer.py", "content": "import numpy as np\nfrom typing import Dict, List, Any, Tuple\nfrom shapely.geometry import Point, Polygon\nimport pandas as pd\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\n\nclass MineralAnalyzer:\n    def __init__(self):\n        self.scaler = StandardScaler()\n        \n    def analyze_region(self, predictions: List[Dict[str, float]], \n                      locations: List[Dict[str, float]], \n                      geological_data: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Analyze predictions and geological data for a region\"\"\"\n        \n        # Convert predictions and locations to numpy arrays\n        pred_array = np.array([[p[\"probability\"], p[\"confidence\"]] for p in predictions])\n        loc_array = np.array([[l[\"latitude\"], l[\"longitude\"]] for l in locations])\n        \n        # Find high-potential clusters\n        clusters = self._find_potential_clusters(pred_array, loc_array)\n        \n        # Analyze geological correlations\n        correlations = self._analyze_geological_correlations(predictions, geological_data)\n        \n        # Generate recommendations\n        recommendations = self._generate_recommendations(clusters, correlations)\n        \n        return {\n            \"clusters\": clusters,\n            \"correlations\": correlations,\n            \"recommendations\": recommendations\n        }\n    \n    def _find_potential_clusters(self, predictions: np.ndarray, \n                               locations: np.ndarray) -> List[Dict[str, Any]]:\n        \"\"\"Find clusters of high-potential areas\"\"\"\n        # Combine predictions and locations\n        data = np.hstack([locations, predictions])\n        \n        # Scale the data\n        scaled_data = self.scaler.fit_transform(data)\n        \n        # Apply DBSCAN clustering\n        clustering = DBSCAN(eps=0.3, min_samples=5).fit(scaled_data)\n        \n        clusters = []\n        for label in set(clustering.labels_):\n            if label == -1:  # Skip noise points\n                continue\n                \n            mask = clustering.labels_ == label\n            cluster_data = data[mask]\n            \n            cluster_info = {\n                \"center\": {\n                    \"latitude\": float(np.mean(cluster_data[:, 0])),\n                    \"longitude\": float(np.mean(cluster_data[:, 1]))\n                },\n                \"avg_probability\": float(np.mean(cluster_data[:, 2])),\n                \"avg_confidence\": float(np.mean(cluster_data[:, 3])),\n                \"size\": int(np.sum(mask)),\n                \"points\": [\n                    {\n                        \"latitude\": float(lat),\n                        \"longitude\": float(lon),\n                        \"probability\": float(prob),\n                        \"confidence\": float(conf)\n                    }\n                    for lat, lon, prob, conf in cluster_data\n                ]\n            }\n            clusters.append(cluster_info)\n        \n        return clusters\n    \n    def _analyze_geological_correlations(self, predictions: List[Dict[str, float]], \n                                      geological_data: List[Dict[str, Any]]) -> Dict[str, float]:\n        \"\"\"Analyze correlations between predictions and geological features\"\"\"\n        correlations = {}\n        \n        # Extract probabilities\n        probs = np.array([p[\"probability\"] for p in predictions])\n        \n        # Analyze correlations with various geological features\n        for geo_data in geological_data:\n            for feature_type, feature_value in self._extract_features(geo_data).items():\n                if isinstance(feature_value, (int, float)):\n                    correlation = float(np.corrcoef(probs, feature_value)[0, 1])\n                    correlations[feature_type] = correlation\n        \n        return correlations\n    \n    def _extract_features(self, geological_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Extract numerical features from geological data\"\"\"\n        features = {}\n        \n        # Extract elevation if available\n        if \"elevation\" in geological_data:\n            features[\"elevation\"] = geological_data[\"elevation\"]\n            \n        # Count nearby deposits\n        if \"nearby_deposits\" in geological_data:\n            features[\"deposit_count\"] = len(geological_data[\"nearby_deposits\"])\n            \n        # Add more feature extraction logic here\n        \n        return features\n    \n    def _generate_recommendations(self, clusters: List[Dict[str, Any]], \n                                correlations: Dict[str, float]) -> List[str]:\n        \"\"\"Generate recommendations based on analysis results\"\"\"\n        recommendations = []\n        \n        # Sort clusters by potential\n        sorted_clusters = sorted(clusters, \n                               key=lambda x: x[\"avg_probability\"] * x[\"avg_confidence\"],\n                               reverse=True)\n        \n        # Recommend high-potential clusters\n        for i, cluster in enumerate(sorted_clusters[:3], 1):\n            recommendations.append(\n                f\"High-potential area {i} identified at \"\n                f\"({cluster['center']['latitude']:.4f}, {cluster['center']['longitude']:.4f}) \"\n                f\"with {cluster['size']} points and \"\n                f\"{cluster['avg_probability']*100:.1f}% average probability.\"\n            )\n            \n        # Analyze geological correlations\n        strong_correlations = {k: v for k, v in correlations.items() if abs(v) > 0.5}\n        for feature, correlation in strong_correlations.items():\n            direction = \"positive\" if correlation > 0 else \"negative\"\n            recommendations.append(\n                f\"Strong {direction} correlation ({correlation:.2f}) found with {feature}.\"\n            )\n            \n        return recommendations\n    \n    def calculate_risk_factors(self, location: Dict[str, float], \n                             geological_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Calculate risk factors for a potential mining site\"\"\"\n        risk_factors = {\n            \"geological_risk\": 0.0,\n            \"accessibility_risk\": 0.0,\n            \"environmental_risk\": 0.0\n        }\n        \n        # Geological risk factors\n        if geological_data.get(\"geological_features\"):\n            # Example risk calculations - would need to be refined based on actual data\n            features = geological_data[\"geological_features\"]\n            risk_factors[\"geological_risk\"] = self._calculate_geological_risk(features)\n            \n        # Accessibility risk factors\n        risk_factors[\"accessibility_risk\"] = self._calculate_accessibility_risk(\n            location, geological_data\n        )\n        \n        # Environmental risk factors\n        risk_factors[\"environmental_risk\"] = self._calculate_environmental_risk(\n            geological_data\n        )\n        \n        return risk_factors\n    \n    def _calculate_geological_risk(self, features: Dict[str, Any]) -> float:\n        \"\"\"Calculate geological risk based on features\"\"\"\n        # Placeholder implementation\n        # Would need to be implemented based on actual geological risk factors\n        return 0.5\n    \n    def _calculate_accessibility_risk(self, location: Dict[str, float], \n                                   geological_data: Dict[str, Any]) -> float:\n        \"\"\"Calculate accessibility risk based on location and terrain\"\"\"\n        # Placeholder implementation\n        # Would need to consider factors like:\n        # - Distance from infrastructure\n        # - Terrain difficulty\n        # - Climate conditions\n        return 0.5\n    \n    def _calculate_environmental_risk(self, geological_data: Dict[str, Any]) -> float:\n        \"\"\"Calculate environmental risk based on geological data\"\"\"\n        # Placeholder implementation\n        # Would need to consider factors like:\n        # - Proximity to protected areas\n        # - Water resources\n        # - Ecosystem sensitivity\n        return 0.5 "}
{"type": "source_file", "path": "minesight/core/ai/models.py", "content": "\"\"\"\nNeural network model architectures for mineral exploration\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom typing import Dict, List, Any, Optional, Tuple\n\nclass MineralExplorationModel(nn.Module):\n    \"\"\"Base model for mineral exploration\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 hidden_dims: List[int] = [256, 128, 64],\n                 dropout: float = 0.3):\n        \"\"\"\n        Initialize the model\n        \n        Args:\n            input_dim: Input feature dimension\n            hidden_dims: List of hidden layer dimensions\n            dropout: Dropout probability\n        \"\"\"\n        super().__init__()\n        \n        # Feature extractor\n        self.feature_extractor = FeatureExtractor(\n            input_dim,\n            hidden_dims,\n            dropout\n        )\n        \n        # Classifier\n        self.classifier = Classifier(\n            hidden_dims[-1],\n            dropout\n        )\n        \n        # Initialize weights\n        self.apply(self._init_weights)\n    \n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Forward pass\n        \n        Args:\n            x: Input tensor\n            \n        Returns:\n            Dictionary with predictions\n        \"\"\"\n        # Extract features\n        features = self.feature_extractor(x)\n        \n        # Get predictions\n        logits = self.classifier(features)\n        \n        return {\n            'features': features,\n            'logits': logits,\n            'probability': torch.sigmoid(logits)\n        }\n    \n    def _init_weights(self, module: nn.Module):\n        \"\"\"Initialize model weights\"\"\"\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n\nclass FeatureExtractor(nn.Module):\n    \"\"\"Feature extraction module\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 hidden_dims: List[int],\n                 dropout: float):\n        \"\"\"\n        Initialize feature extractor\n        \n        Args:\n            input_dim: Input feature dimension\n            hidden_dims: List of hidden layer dimensions\n            dropout: Dropout probability\n        \"\"\"\n        super().__init__()\n        \n        # Build layers\n        layers = []\n        dims = [input_dim] + hidden_dims\n        \n        for i in range(len(dims)-1):\n            layers.extend([\n                nn.Linear(dims[i], dims[i+1]),\n                nn.BatchNorm1d(dims[i+1]),\n                nn.ReLU(),\n                nn.Dropout(dropout)\n            ])\n        \n        self.layers = nn.Sequential(*layers)\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Forward pass\"\"\"\n        return self.layers(x)\n\nclass Classifier(nn.Module):\n    \"\"\"Classification module\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 dropout: float):\n        \"\"\"\n        Initialize classifier\n        \n        Args:\n            input_dim: Input feature dimension\n            dropout: Dropout probability\n        \"\"\"\n        super().__init__()\n        \n        self.layers = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(input_dim, 1)\n        )\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Forward pass\"\"\"\n        return self.layers(x)\n\nclass AutoEncoder(nn.Module):\n    \"\"\"Autoencoder for anomaly detection\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 hidden_dims: List[int] = [128, 64, 32],\n                 latent_dim: int = 16):\n        \"\"\"\n        Initialize autoencoder\n        \n        Args:\n            input_dim: Input feature dimension\n            hidden_dims: List of hidden layer dimensions\n            latent_dim: Latent space dimension\n        \"\"\"\n        super().__init__()\n        \n        # Encoder\n        encoder_dims = [input_dim] + hidden_dims + [latent_dim]\n        encoder_layers = []\n        \n        for i in range(len(encoder_dims)-1):\n            encoder_layers.extend([\n                nn.Linear(encoder_dims[i], encoder_dims[i+1]),\n                nn.BatchNorm1d(encoder_dims[i+1]),\n                nn.ReLU()\n            ])\n        \n        self.encoder = nn.Sequential(*encoder_layers)\n        \n        # Decoder\n        decoder_dims = [latent_dim] + hidden_dims[::-1] + [input_dim]\n        decoder_layers = []\n        \n        for i in range(len(decoder_dims)-1):\n            decoder_layers.extend([\n                nn.Linear(decoder_dims[i], decoder_dims[i+1]),\n                nn.BatchNorm1d(decoder_dims[i+1]),\n                nn.ReLU() if i < len(decoder_dims)-2 else nn.Tanh()\n            ])\n        \n        self.decoder = nn.Sequential(*decoder_layers)\n        \n        # Initialize weights\n        self.apply(self._init_weights)\n    \n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Forward pass\n        \n        Args:\n            x: Input tensor\n            \n        Returns:\n            Dictionary with encoded and decoded data\n        \"\"\"\n        # Encode\n        encoded = self.encoder(x)\n        \n        # Decode\n        decoded = self.decoder(encoded)\n        \n        return {\n            'encoded': encoded,\n            'decoded': decoded,\n            'reconstruction_error': F.mse_loss(decoded, x, reduction='none')\n        }\n    \n    def _init_weights(self, module: nn.Module):\n        \"\"\"Initialize model weights\"\"\"\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n\nclass VariationalAutoEncoder(nn.Module):\n    \"\"\"Variational autoencoder for pattern analysis\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 hidden_dims: List[int] = [128, 64],\n                 latent_dim: int = 32):\n        \"\"\"\n        Initialize VAE\n        \n        Args:\n            input_dim: Input feature dimension\n            hidden_dims: List of hidden layer dimensions\n            latent_dim: Latent space dimension\n        \"\"\"\n        super().__init__()\n        \n        # Encoder\n        encoder_dims = [input_dim] + hidden_dims\n        encoder_layers = []\n        \n        for i in range(len(encoder_dims)-1):\n            encoder_layers.extend([\n                nn.Linear(encoder_dims[i], encoder_dims[i+1]),\n                nn.BatchNorm1d(encoder_dims[i+1]),\n                nn.ReLU()\n            ])\n        \n        self.encoder = nn.Sequential(*encoder_layers)\n        \n        # Latent space\n        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n        \n        # Decoder\n        decoder_dims = [latent_dim] + hidden_dims[::-1] + [input_dim]\n        decoder_layers = []\n        \n        for i in range(len(decoder_dims)-1):\n            decoder_layers.extend([\n                nn.Linear(decoder_dims[i], decoder_dims[i+1]),\n                nn.BatchNorm1d(decoder_dims[i+1]),\n                nn.ReLU() if i < len(decoder_dims)-2 else nn.Tanh()\n            ])\n        \n        self.decoder = nn.Sequential(*decoder_layers)\n        \n        # Initialize weights\n        self.apply(self._init_weights)\n    \n    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Encode input to latent space\"\"\"\n        hidden = self.encoder(x)\n        return self.fc_mu(hidden), self.fc_var(hidden)\n    \n    def reparameterize(self,\n                      mu: torch.Tensor,\n                      log_var: torch.Tensor) -> torch.Tensor:\n        \"\"\"Reparameterization trick\"\"\"\n        std = torch.exp(0.5 * log_var)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n    \n    def decode(self, z: torch.Tensor) -> torch.Tensor:\n        \"\"\"Decode latent vector\"\"\"\n        return self.decoder(z)\n    \n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Forward pass\n        \n        Args:\n            x: Input tensor\n            \n        Returns:\n            Dictionary with VAE outputs\n        \"\"\"\n        # Encode\n        mu, log_var = self.encode(x)\n        \n        # Sample latent vector\n        z = self.reparameterize(mu, log_var)\n        \n        # Decode\n        recon = self.decode(z)\n        \n        return {\n            'reconstruction': recon,\n            'mu': mu,\n            'log_var': log_var,\n            'z': z\n        }\n    \n    def _init_weights(self, module: nn.Module):\n        \"\"\"Initialize model weights\"\"\"\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias) "}
{"type": "source_file", "path": "minesight/core/dashboard/dashboard.py", "content": "\"\"\"\nInteractive dashboard module for mineral exploration data visualization and analysis\n\"\"\"\nfrom typing import Dict, List, Optional, Any\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport json\nfrom pathlib import Path\n\nclass Dashboard:\n    \"\"\"Class for creating interactive dashboards\"\"\"\n    \n    def __init__(self, output_dir: str = \"dashboards\"):\n        \"\"\"\n        Initialize the dashboard\n        \n        Args:\n            output_dir: Directory for saving dashboard files\n        \"\"\"\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n    def create_exploration_dashboard(self,\n                                  deposits: pd.DataFrame,\n                                  geological_features: pd.DataFrame,\n                                  predictions: List[Dict[str, Any]],\n                                  risk_data: Dict[str, Any],\n                                  monitoring_data: Dict[str, Any]) -> str:\n        \"\"\"\n        Create comprehensive exploration dashboard\n        \n        Args:\n            deposits: DataFrame of mineral deposits\n            geological_features: DataFrame of geological features\n            predictions: List of prediction results\n            risk_data: Risk assessment data\n            monitoring_data: Monitoring metrics and alerts\n            \n        Returns:\n            Path to generated dashboard HTML\n        \"\"\"\n        # Create dashboard layout\n        fig = make_subplots(\n            rows=3, cols=2,\n            subplot_titles=(\n                'Mineral Deposits Map',\n                'Risk Assessment',\n                'Prediction Heatmap',\n                'Resource Utilization',\n                'Activity Timeline',\n                'Alert Distribution'\n            ),\n            specs=[\n                [{\"type\": \"mapbox\"}, {\"type\": \"polar\"}],\n                [{\"type\": \"mapbox\"}, {\"type\": \"bar\"}],\n                [{\"type\": \"scatter\"}, {\"type\": \"pie\"}]\n            ]\n        )\n        \n        # Add deposit map\n        self._add_deposit_map(fig, deposits, 1, 1)\n        \n        # Add risk radar chart\n        self._add_risk_chart(fig, risk_data, 1, 2)\n        \n        # Add prediction heatmap\n        self._add_prediction_map(fig, predictions, 2, 1)\n        \n        # Add resource utilization\n        self._add_resource_chart(\n            fig,\n            monitoring_data.get(\"metrics\", {}).get(\"resources\", {}),\n            2, 2\n        )\n        \n        # Add activity timeline\n        self._add_activity_timeline(\n            fig,\n            monitoring_data.get(\"metrics\", {}).get(\"activities\", {}),\n            3, 1\n        )\n        \n        # Add alert distribution\n        self._add_alert_chart(\n            fig,\n            monitoring_data.get(\"alerts\", []),\n            3, 2\n        )\n        \n        # Update layout\n        fig.update_layout(\n            height=1200,\n            width=1600,\n            title_text=\"Mineral Exploration Dashboard\",\n            showlegend=True,\n            template=\"plotly_dark\"\n        )\n        \n        # Save dashboard\n        output_path = self.output_dir / f\"dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n        fig.write_html(str(output_path))\n        \n        return str(output_path)\n    \n    def create_monitoring_dashboard(self,\n                                 monitoring_data: Dict[str, Any],\n                                 time_range: str = \"24h\") -> str:\n        \"\"\"\n        Create real-time monitoring dashboard\n        \n        Args:\n            monitoring_data: Monitoring metrics and alerts\n            time_range: Time range for metrics (24h, 7d, 30d)\n            \n        Returns:\n            Path to generated dashboard HTML\n        \"\"\"\n        # Create dashboard layout\n        fig = make_subplots(\n            rows=2, cols=2,\n            subplot_titles=(\n                'Alert Timeline',\n                'Resource Status',\n                'Activity Status',\n                'Risk Trends'\n            )\n        )\n        \n        # Add alert timeline\n        alerts = monitoring_data.get(\"alerts\", [])\n        alert_df = pd.DataFrame([\n            {\n                \"timestamp\": pd.to_datetime(alert[\"timestamp\"]),\n                \"level\": alert[\"level\"],\n                \"category\": alert[\"category\"]\n            }\n            for alert in alerts\n        ])\n        \n        if not alert_df.empty:\n            for level in [\"critical\", \"warning\", \"info\"]:\n                level_alerts = alert_df[alert_df[\"level\"] == level]\n                if not level_alerts.empty:\n                    fig.add_trace(\n                        go.Scatter(\n                            x=level_alerts[\"timestamp\"],\n                            y=[1] * len(level_alerts),\n                            mode=\"markers\",\n                            name=f\"{level.title()} Alerts\",\n                            marker=dict(\n                                size=10,\n                                symbol=\"diamond\",\n                                color={\n                                    \"critical\": \"red\",\n                                    \"warning\": \"orange\",\n                                    \"info\": \"blue\"\n                                }[level]\n                            )\n                        ),\n                        row=1, col=1\n                    )\n        \n        # Add resource status\n        resources = monitoring_data.get(\"metrics\", {}).get(\"resources\", {})\n        if resources:\n            fig.add_trace(\n                go.Bar(\n                    x=list(resources.get(\"utilization\", {}).keys()),\n                    y=list(resources.get(\"utilization\", {}).values()),\n                    name=\"Resource Utilization\"\n                ),\n                row=1, col=2\n            )\n        \n        # Add activity status\n        activities = monitoring_data.get(\"metrics\", {}).get(\"activities\", {})\n        if activities:\n            fig.add_trace(\n                go.Pie(\n                    labels=[\"Active\", \"Completed\", \"Pending\"],\n                    values=[\n                        activities.get(\"active\", 0),\n                        activities.get(\"completed\", 0),\n                        activities.get(\"total\", 0) - activities.get(\"active\", 0) - activities.get(\"completed\", 0)\n                    ],\n                    name=\"Activity Status\"\n                ),\n                row=2, col=1\n            )\n        \n        # Add risk trends\n        risks = monitoring_data.get(\"metrics\", {}).get(\"risks\", {})\n        if risks:\n            fig.add_trace(\n                go.Scatter(\n                    x=list(risks.keys()),\n                    y=list(risks.values()),\n                    mode=\"lines+markers\",\n                    name=\"Risk Levels\"\n                ),\n                row=2, col=2\n            )\n        \n        # Update layout\n        fig.update_layout(\n            height=800,\n            width=1200,\n            title_text=\"Real-time Monitoring Dashboard\",\n            showlegend=True,\n            template=\"plotly_dark\"\n        )\n        \n        # Save dashboard\n        output_path = self.output_dir / f\"monitoring_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n        fig.write_html(str(output_path))\n        \n        return str(output_path)\n    \n    def create_analysis_dashboard(self,\n                               feature_analysis: Dict[str, Any],\n                               time_analysis: Dict[str, Any]) -> str:\n        \"\"\"\n        Create analysis dashboard\n        \n        Args:\n            feature_analysis: Feature analysis results\n            time_analysis: Time series analysis results\n            \n        Returns:\n            Path to generated dashboard HTML\n        \"\"\"\n        # Create dashboard layout\n        fig = make_subplots(\n            rows=2, cols=2,\n            subplot_titles=(\n                'Feature Density',\n                'Feature Clusters',\n                'Discovery Trends',\n                'Exploration Intensity'\n            )\n        )\n        \n        # Add feature density plot\n        density = feature_analysis.get(\"density_metrics\", {})\n        if density:\n            fig.add_trace(\n                go.Bar(\n                    x=[\"Average\", \"Maximum\"],\n                    y=[\n                        density.get(\"avg_density\", 0),\n                        density.get(\"max_density\", 0)\n                    ],\n                    name=\"Feature Density\"\n                ),\n                row=1, col=1\n            )\n        \n        # Add cluster visualization\n        clusters = feature_analysis.get(\"cluster_analysis\", {}).get(\"clusters\", [])\n        if clusters:\n            cluster_sizes = [c.get(\"size\", 0) for c in clusters]\n            cluster_radii = [c.get(\"radius_km\", 0) for c in clusters]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=cluster_sizes,\n                    y=cluster_radii,\n                    mode=\"markers\",\n                    name=\"Feature Clusters\",\n                    marker=dict(\n                        size=10,\n                        color=cluster_sizes,\n                        colorscale=\"Viridis\",\n                        showscale=True\n                    )\n                ),\n                row=1, col=2\n            )\n        \n        # Add discovery trends\n        trends = time_analysis.get(\"discovery_trends\", {})\n        if trends.get(\"forecast\"):\n            dates = [f[\"date\"] for f in trends[\"forecast\"]]\n            values = [f[\"predicted_discoveries\"] for f in trends[\"forecast\"]]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=dates,\n                    y=values,\n                    mode=\"lines\",\n                    name=\"Discovery Forecast\"\n                ),\n                row=2, col=1\n            )\n        \n        # Add exploration intensity\n        intensity = time_analysis.get(\"exploration_intensity\", {})\n        if intensity.get(\"intensity_data\"):\n            dates = [d[\"date\"] for d in intensity[\"intensity_data\"]]\n            values = [d[\"intensity\"] for d in intensity[\"intensity_data\"]]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=dates,\n                    y=values,\n                    mode=\"lines\",\n                    name=\"Exploration Intensity\"\n                ),\n                row=2, col=2\n            )\n        \n        # Update layout\n        fig.update_layout(\n            height=800,\n            width=1200,\n            title_text=\"Analysis Dashboard\",\n            showlegend=True,\n            template=\"plotly_dark\"\n        )\n        \n        # Save dashboard\n        output_path = self.output_dir / f\"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n        fig.write_html(str(output_path))\n        \n        return str(output_path)\n    \n    def _add_deposit_map(self,\n                        fig: go.Figure,\n                        deposits: pd.DataFrame,\n                        row: int,\n                        col: int):\n        \"\"\"Add deposit map to dashboard\"\"\"\n        if not deposits.empty:\n            fig.add_trace(\n                go.Scattermapbox(\n                    lat=deposits[\"latitude\"],\n                    lon=deposits[\"longitude\"],\n                    mode=\"markers\",\n                    marker=dict(\n                        size=10,\n                        color=deposits[\"is_confirmed\"].map({True: \"green\", False: \"yellow\"}),\n                        symbol=\"circle\"\n                    ),\n                    text=deposits[\"mineral_type\"],\n                    name=\"Mineral Deposits\"\n                ),\n                row=row, col=col\n            )\n    \n    def _add_risk_chart(self,\n                       fig: go.Figure,\n                       risk_data: Dict[str, Any],\n                       row: int,\n                       col: int):\n        \"\"\"Add risk radar chart to dashboard\"\"\"\n        risk_types = [\n            \"geological_risk\",\n            \"environmental_risk\",\n            \"technical_risk\",\n            \"economic_risk\"\n        ]\n        \n        fig.add_trace(\n            go.Scatterpolar(\n                r=[risk_data.get(rt, 0) for rt in risk_types],\n                theta=[rt.replace(\"_risk\", \"\").title() for rt in risk_types],\n                fill=\"toself\",\n                name=\"Risk Assessment\"\n            ),\n            row=row, col=col\n        )\n    \n    def _add_prediction_map(self,\n                          fig: go.Figure,\n                          predictions: List[Dict[str, Any]],\n                          row: int,\n                          col: int):\n        \"\"\"Add prediction heatmap to dashboard\"\"\"\n        if predictions:\n            lats = [p[\"location\"][\"latitude\"] for p in predictions]\n            lons = [p[\"location\"][\"longitude\"] for p in predictions]\n            probs = [p[\"probability\"] for p in predictions]\n            \n            fig.add_trace(\n                go.Densitymapbox(\n                    lat=lats,\n                    lon=lons,\n                    z=probs,\n                    radius=20,\n                    colorscale=\"Viridis\",\n                    name=\"Predictions\"\n                ),\n                row=row, col=col\n            )\n    \n    def _add_resource_chart(self,\n                          fig: go.Figure,\n                          resources: Dict[str, Any],\n                          row: int,\n                          col: int):\n        \"\"\"Add resource utilization chart to dashboard\"\"\"\n        utilization = resources.get(\"utilization\", {})\n        if utilization:\n            fig.add_trace(\n                go.Bar(\n                    x=list(utilization.keys()),\n                    y=list(utilization.values()),\n                    name=\"Resource Utilization\"\n                ),\n                row=row, col=col\n            )\n    \n    def _add_activity_timeline(self,\n                             fig: go.Figure,\n                             activities: Dict[str, Any],\n                             row: int,\n                             col: int):\n        \"\"\"Add activity timeline to dashboard\"\"\"\n        if activities:\n            dates = pd.date_range(\n                end=datetime.now(),\n                periods=30,\n                freq=\"D\"\n            )\n            \n            completion_rate = activities.get(\"completion_rate\", 0)\n            trend = [completion_rate * (1 + 0.1 * i) for i in range(len(dates))]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=dates,\n                    y=trend,\n                    mode=\"lines\",\n                    name=\"Activity Trend\"\n                ),\n                row=row, col=col\n            )\n    \n    def _add_alert_chart(self,\n                        fig: go.Figure,\n                        alerts: List[Dict[str, Any]],\n                        row: int,\n                        col: int):\n        \"\"\"Add alert distribution chart to dashboard\"\"\"\n        if alerts:\n            alert_df = pd.DataFrame(alerts)\n            level_counts = alert_df[\"level\"].value_counts()\n            \n            fig.add_trace(\n                go.Pie(\n                    labels=level_counts.index,\n                    values=level_counts.values,\n                    name=\"Alert Distribution\"\n                ),\n                row=row, col=col\n            ) "}
{"type": "source_file", "path": "minesight/core/dashboard/process_dashboard.py", "content": "\"\"\"\nUnified process monitoring and visualization dashboard\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Union\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nfrom dataclasses import dataclass\nfrom pathlib import Path\nimport json\nimport asyncio\nimport logging\n\n@dataclass\nclass DashboardConfig:\n    \"\"\"Dashboard configuration\"\"\"\n    refresh_interval: int = 60  # seconds\n    max_history_points: int = 1000\n    alert_threshold: float = 0.7\n    visualization_theme: str = \"plotly_white\"\n    layout_config: Optional[Dict[str, Any]] = None\n    data_retention_days: int = 30\n    enable_real_time: bool = True\n    alert_levels: Dict[str, float] = None\n\n    def __post_init__(self):\n        if self.alert_levels is None:\n            self.alert_levels = {\n                \"critical\": 0.9,\n                \"warning\": 0.7,\n                \"info\": 0.5\n            }\n\nclass ProcessDashboard:\n    \"\"\"Unified process monitoring dashboard\"\"\"\n    \n    def __init__(self, config: Optional[DashboardConfig] = None):\n        \"\"\"\n        Initialize the process dashboard\n        \n        Args:\n            config: Optional dashboard configuration\n        \"\"\"\n        self.config = config or DashboardConfig()\n        self.data_history = []\n        self.alert_history = []\n        self.current_metrics = {}\n        self.last_update = None\n        self.logger = logging.getLogger(__name__)\n        self._monitoring_task = None\n        \n    async def start_monitoring(self):\n        \"\"\"Start real-time monitoring\"\"\"\n        if not self.config.enable_real_time:\n            return\n            \n        self._monitoring_task = asyncio.create_task(self._monitor_loop())\n        self.logger.info(\"Started real-time monitoring\")\n        \n    async def stop_monitoring(self):\n        \"\"\"Stop real-time monitoring\"\"\"\n        if self._monitoring_task:\n            self._monitoring_task.cancel()\n            try:\n                await self._monitoring_task\n            except asyncio.CancelledError:\n                pass\n            self._monitoring_task = None\n            self.logger.info(\"Stopped real-time monitoring\")\n            \n    async def _monitor_loop(self):\n        \"\"\"Real-time monitoring loop\"\"\"\n        while True:\n            try:\n                # Clean up old data\n                self._cleanup_old_data()\n                \n                # Update metrics\n                await self._update_metrics()\n                \n                # Check alerts\n                self._check_alerts()\n                \n                # Wait for next update\n                await asyncio.sleep(self.config.refresh_interval)\n                \n            except Exception as e:\n                self.logger.error(f\"Error in monitoring loop: {str(e)}\")\n                await asyncio.sleep(5)  # Wait before retrying\n        \n    def update_dashboard(self, \n                        process_data: Dict[str, Any],\n                        optimization_results: Optional[List[Dict[str, Any]]] = None,\n                        quality_metrics: Optional[Dict[str, Any]] = None,\n                        anomaly_alerts: Optional[List[Dict[str, Any]]] = None) -> None:\n        \"\"\"\n        Update dashboard with new data\n        \n        Args:\n            process_data: Current process data\n            optimization_results: Optional optimization results\n            quality_metrics: Optional quality metrics\n            anomaly_alerts: Optional anomaly alerts\n        \"\"\"\n        try:\n            # Update data history\n            self.data_history.append({\n                \"timestamp\": datetime.now(),\n                \"process_data\": process_data,\n                \"optimization_results\": optimization_results,\n                \"quality_metrics\": quality_metrics,\n                \"anomaly_alerts\": anomaly_alerts\n            })\n            \n            # Maintain history size\n            if len(self.data_history) > self.config.max_history_points:\n                self.data_history = self.data_history[-self.config.max_history_points:]\n            \n            # Update current metrics\n            self._update_current_metrics(process_data)\n            \n            # Process alerts\n            if anomaly_alerts:\n                self._process_alerts(anomaly_alerts)\n            \n            self.last_update = datetime.now()\n            self.logger.debug(\"Dashboard updated successfully\")\n            \n        except Exception as e:\n            self.logger.error(f\"Error updating dashboard: {str(e)}\")\n            \n    def generate_dashboard(self, output_path: Optional[str] = None) -> str:\n        \"\"\"\n        Generate interactive dashboard\n        \n        Args:\n            output_path: Optional output path for dashboard\n            \n        Returns:\n            Path to generated dashboard\n        \"\"\"\n        if not output_path:\n            output_path = f\"process_dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n            \n        try:\n            # Create dashboard layout\n            fig = make_subplots(\n                rows=3,\n                cols=2,\n                subplot_titles=(\n                    \"Process Performance Metrics\",\n                    \"Resource Utilization\",\n                    \"Quality Metrics\",\n                    \"Optimization Impact\",\n                    \"Anomaly Detection\",\n                    \"Alert History\"\n                ),\n                specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n                      [{\"type\": \"scatter\"}, {\"type\": \"bar\"}],\n                      [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]\n            )\n            \n            # Add performance metrics plot\n            self._add_performance_plot(fig, row=1, col=1)\n            \n            # Add resource utilization plot\n            self._add_resource_plot(fig, row=1, col=2)\n            \n            # Add quality metrics plot\n            self._add_quality_plot(fig, row=2, col=1)\n            \n            # Add optimization impact plot\n            self._add_optimization_plot(fig, row=2, col=2)\n            \n            # Add anomaly detection plot\n            self._add_anomaly_plot(fig, row=3, col=1)\n            \n            # Add alert history plot\n            self._add_alert_plot(fig, row=3, col=2)\n            \n            # Update layout\n            fig.update_layout(\n                height=1200,\n                width=1600,\n                showlegend=True,\n                title_text=\"Process Monitoring Dashboard\",\n                template=self.config.visualization_theme,\n                margin=dict(t=100, l=50, r=50, b=50)\n            )\n            \n            # Save dashboard\n            fig.write_html(\n                output_path,\n                include_plotlyjs=True,\n                full_html=True,\n                include_mathjax=False\n            )\n            \n            self.logger.info(f\"Dashboard generated successfully: {output_path}\")\n            return output_path\n            \n        except Exception as e:\n            self.logger.error(f\"Error generating dashboard: {str(e)}\")\n            raise\n            \n    def generate_summary_report(self) -> Dict[str, Any]:\n        \"\"\"\n        Generate summary report of current process state\n        \n        Returns:\n            Summary report dictionary\n        \"\"\"\n        try:\n            if not self.data_history:\n                return {}\n                \n            summary = {\n                \"timestamp\": datetime.now().isoformat(),\n                \"period\": {\n                    \"start\": self.data_history[0][\"timestamp\"].isoformat(),\n                    \"end\": self.data_history[-1][\"timestamp\"].isoformat()\n                },\n                \"metrics\": self._calculate_summary_metrics(),\n                \"alerts\": self._summarize_alerts(),\n                \"optimization\": self._summarize_optimization_results(),\n                \"quality\": self._summarize_quality_metrics(),\n                \"trends\": self._analyze_trends(),\n                \"status\": self._get_system_status()\n            }\n            \n            return summary\n            \n        except Exception as e:\n            self.logger.error(f\"Error generating summary report: {str(e)}\")\n            return {}\n            \n    def export_data(self, format: str = \"json\", output_path: Optional[str] = None) -> str:\n        \"\"\"\n        Export dashboard data\n        \n        Args:\n            format: Export format (\"json\" or \"csv\")\n            output_path: Optional output path\n            \n        Returns:\n            Path to exported data file\n        \"\"\"\n        if not output_path:\n            output_path = f\"dashboard_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{format}\"\n            \n        try:\n            if format == \"json\":\n                data = {\n                    \"history\": self.data_history,\n                    \"alerts\": self.alert_history,\n                    \"current_metrics\": self.current_metrics,\n                    \"last_update\": self.last_update.isoformat() if self.last_update else None\n                }\n                with open(output_path, \"w\") as f:\n                    json.dump(data, f, indent=2)\n                    \n            elif format == \"csv\":\n                df = pd.DataFrame(self.data_history)\n                df.to_csv(output_path, index=False)\n                \n            else:\n                raise ValueError(f\"Unsupported export format: {format}\")\n                \n            self.logger.info(f\"Data exported successfully: {output_path}\")\n            return output_path\n            \n        except Exception as e:\n            self.logger.error(f\"Error exporting data: {str(e)}\")\n            raise\n            \n    def _cleanup_old_data(self):\n        \"\"\"Clean up old data based on retention policy\"\"\"\n        if not self.data_history:\n            return\n            \n        cutoff_time = datetime.now() - timedelta(days=self.config.data_retention_days)\n        self.data_history = [\n            d for d in self.data_history\n            if d[\"timestamp\"] > cutoff_time\n        ]\n        self.alert_history = [\n            a for a in self.alert_history\n            if a[\"timestamp\"] > cutoff_time\n        ]\n        \n    async def _update_metrics(self):\n        \"\"\"Update real-time metrics\"\"\"\n        # TODO: Implement real-time metrics update\n        pass\n        \n    def _check_alerts(self):\n        \"\"\"Check for new alerts\"\"\"\n        if not self.current_metrics:\n            return\n            \n        for metric_type, metrics in self.current_metrics.items():\n            for metric_name, value in metrics.items():\n                # Check against alert thresholds\n                if value >= self.config.alert_levels[\"critical\"]:\n                    self._add_alert(\"critical\", f\"Critical {metric_name} in {metric_type}: {value:.2f}\")\n                elif value >= self.config.alert_levels[\"warning\"]:\n                    self._add_alert(\"warning\", f\"Warning {metric_name} in {metric_type}: {value:.2f}\")\n                elif value >= self.config.alert_levels[\"info\"]:\n                    self._add_alert(\"info\", f\"Info {metric_name} in {metric_type}: {value:.2f}\")\n                    \n    def _get_system_status(self) -> Dict[str, Any]:\n        \"\"\"Get current system status\"\"\"\n        if not self.current_metrics:\n            return {\"status\": \"unknown\"}\n            \n        # Calculate overall health score\n        health_scores = []\n        for metrics in self.current_metrics.values():\n            health_scores.extend(metrics.values())\n            \n        if not health_scores:\n            return {\"status\": \"unknown\"}\n            \n        avg_health = np.mean(health_scores)\n        \n        # Determine status\n        if avg_health >= 0.8:\n            status = \"healthy\"\n        elif avg_health >= 0.6:\n            status = \"warning\"\n        else:\n            status = \"critical\"\n            \n        return {\n            \"status\": status,\n            \"health_score\": float(avg_health),\n            \"last_update\": self.last_update.isoformat() if self.last_update else None,\n            \"metrics_count\": len(health_scores)\n        }\n        \n    def _update_current_metrics(self, process_data: Dict[str, Any]) -> None:\n        \"\"\"Update current process metrics\"\"\"\n        self.current_metrics = {\n            \"performance\": self._extract_performance_metrics(process_data),\n            \"resources\": self._extract_resource_metrics(process_data),\n            \"quality\": self._extract_quality_metrics(process_data)\n        }\n        \n    def _process_alerts(self, alerts: List[Dict[str, Any]]) -> None:\n        \"\"\"Process and store alerts\"\"\"\n        for alert in alerts:\n            if alert.get(\"severity\", 0) >= self.config.alert_threshold:\n                self.alert_history.append({\n                    \"timestamp\": datetime.now(),\n                    \"type\": alert.get(\"type\", \"unknown\"),\n                    \"severity\": alert.get(\"severity\", 0),\n                    \"message\": alert.get(\"message\", \"\"),\n                    \"details\": alert.get(\"details\", {})\n                })\n        \n    def _add_performance_plot(self, fig, row: int, col: int):\n        \"\"\"Add performance metrics visualization\"\"\"\n        if not self.data_history:\n            return\n            \n        # Prepare data\n        timestamps = [d[\"timestamp\"] for d in self.data_history]\n        metrics = [\"efficiency\", \"success_rate\", \"cost_effectiveness\"]\n        colors = [\"#2ecc71\", \"#3498db\", \"#e74c3c\"]\n        \n        # Add traces for each metric\n        for metric, color in zip(metrics, colors):\n            values = [\n                d[\"process_data\"].get(\"performance\", {}).get(metric, 0)\n                for d in self.data_history\n            ]\n            \n            # Calculate moving average\n            window = min(5, len(values))\n            ma_values = pd.Series(values).rolling(window=window).mean()\n            \n            # Add raw values\n            fig.add_trace(\n                go.Scatter(\n                    x=timestamps,\n                    y=values,\n                    name=metric.replace(\"_\", \" \").title(),\n                    mode=\"markers\",\n                    marker=dict(color=color, size=6),\n                    showlegend=True\n                ),\n                row=row,\n                col=col\n            )\n            \n            # Add trend line\n            fig.add_trace(\n                go.Scatter(\n                    x=timestamps,\n                    y=ma_values,\n                    name=f\"{metric.replace('_', ' ').title()} Trend\",\n                    mode=\"lines\",\n                    line=dict(color=color, width=2),\n                    showlegend=False\n                ),\n                row=row,\n                col=col\n            )\n        \n        # Update axes\n        fig.update_xaxes(title_text=\"Time\", row=row, col=col)\n        fig.update_yaxes(title_text=\"Value\", range=[0, 1], row=row, col=col)\n        \n    def _add_resource_plot(self, fig, row: int, col: int):\n        \"\"\"Add resource utilization visualization\"\"\"\n        if not self.data_history:\n            return\n            \n        # Prepare data\n        timestamps = [d[\"timestamp\"] for d in self.data_history]\n        resources = [\"cpu\", \"memory\", \"storage\", \"network\"]\n        colors = [\"#1abc9c\", \"#3498db\", \"#9b59b6\", \"#e67e22\"]\n        \n        # Add traces for each resource\n        for resource, color in zip(resources, colors):\n            values = [\n                d[\"process_data\"].get(\"resources\", {}).get(resource, 0)\n                for d in self.data_history\n            ]\n            \n            # Add area plot\n            fig.add_trace(\n                go.Scatter(\n                    x=timestamps,\n                    y=values,\n                    name=resource.title(),\n                    fill='tozeroy',\n                    line=dict(color=color, width=1),\n                    fillcolor=f\"rgba({int(color[1:3], 16)}, {int(color[3:5], 16)}, {int(color[5:7], 16)}, 0.2)\"\n                ),\n                row=row,\n                col=col\n            )\n            \n        # Add threshold line\n        fig.add_trace(\n            go.Scatter(\n                x=timestamps,\n                y=[0.8] * len(timestamps),  # 80% utilization threshold\n                name=\"Threshold\",\n                line=dict(color=\"red\", width=1, dash=\"dash\"),\n                showlegend=False\n            ),\n            row=row,\n            col=col\n        )\n        \n        # Update axes\n        fig.update_xaxes(title_text=\"Time\", row=row, col=col)\n        fig.update_yaxes(title_text=\"Utilization (%)\", range=[0, 1], row=row, col=col)\n        \n    def _add_quality_plot(self, fig, row: int, col: int):\n        \"\"\"Add quality metrics visualization\"\"\"\n        if not self.data_history:\n            return\n            \n        # Prepare data\n        timestamps = [d[\"timestamp\"] for d in self.data_history]\n        metrics = [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]\n        colors = [\"#27ae60\", \"#2980b9\", \"#8e44ad\", \"#d35400\"]\n        \n        for metric, color in zip(metrics, colors):\n            values = [\n                d.get(\"quality_metrics\", {}).get(metric, 0)\n                for d in self.data_history\n            ]\n            \n            # Calculate moving average\n            window = min(5, len(values))\n            ma_values = pd.Series(values).rolling(window=window).mean()\n            \n            # Add scatter plot with trend line\n            fig.add_trace(\n                go.Scatter(\n                    x=timestamps,\n                    y=values,\n                    name=metric.title(),\n                    mode=\"markers+lines\",\n                    marker=dict(color=color, size=6),\n                    line=dict(color=color, width=1)\n                ),\n                row=row,\n                col=col\n            )\n            \n            # Add moving average\n            fig.add_trace(\n                go.Scatter(\n                    x=timestamps,\n                    y=ma_values,\n                    name=f\"{metric.title()} MA\",\n                    mode=\"lines\",\n                    line=dict(color=color, width=2, dash=\"dash\"),\n                    showlegend=False\n                ),\n                row=row,\n                col=col\n            )\n            \n        # Update axes\n        fig.update_xaxes(title_text=\"Time\", row=row, col=col)\n        fig.update_yaxes(title_text=\"Score\", range=[0, 1], row=row, col=col)\n        \n    def _add_optimization_plot(self, fig, row: int, col: int):\n        \"\"\"Add optimization impact visualization\"\"\"\n        if not self.data_history:\n            return\n            \n        # Collect optimization results\n        impact_data = []\n        for data in self.data_history:\n            if data.get(\"optimization_results\"):\n                for result in data[\"optimization_results\"]:\n                    if \"impact\" in result:\n                        impact_data.append({\n                            \"timestamp\": data[\"timestamp\"],\n                            **result[\"impact\"]\n                        })\n        \n        if not impact_data:\n            return\n            \n        # Convert to DataFrame\n        df = pd.DataFrame(impact_data)\n        \n        # Calculate impact metrics\n        metrics = [\"efficiency_improvement\", \"cost_reduction\", \"quality_improvement\"]\n        colors = [\"#2ecc71\", \"#e74c3c\", \"#3498db\"]\n        \n        # Create grouped bar chart\n        x = list(range(len(df)))\n        width = 0.25\n        \n        for i, (metric, color) in enumerate(zip(metrics, colors)):\n            fig.add_trace(\n                go.Bar(\n                    x=[xi + i * width for xi in x],\n                    y=df[metric],\n                    name=metric.replace(\"_\", \" \").title(),\n                    marker_color=color,\n                    width=width\n                ),\n                row=row,\n                col=col\n            )\n            \n        # Update axes\n        fig.update_xaxes(\n            title_text=\"Optimization Index\",\n            ticktext=[d.strftime(\"%Y-%m-%d %H:%M\") for d in df[\"timestamp\"]],\n            tickvals=x,\n            tickangle=45,\n            row=row,\n            col=col\n        )\n        fig.update_yaxes(title_text=\"Impact Score\", range=[0, 1], row=row, col=col)\n        \n    def _add_anomaly_plot(self, fig, row: int, col: int):\n        \"\"\"Add anomaly detection visualization\"\"\"\n        if not self.data_history:\n            return\n            \n        # Prepare data\n        timestamps = []\n        scores = []\n        categories = []\n        \n        for data in self.data_history:\n            if data.get(\"anomaly_alerts\"):\n                for alert in data[\"anomaly_alerts\"]:\n                    timestamps.append(data[\"timestamp\"])\n                    scores.append(alert.get(\"score\", 0))\n                    categories.append(alert.get(\"category\", \"unknown\"))\n                    \n        if not timestamps:\n            return\n            \n        # Create scatter plot with color-coded categories\n        unique_categories = list(set(categories))\n        colors = [f\"#{hash(cat) % 0xFFFFFF:06x}\" for cat in unique_categories]\n        \n        for cat, color in zip(unique_categories, colors):\n            mask = [c == cat for c in categories]\n            cat_timestamps = [t for t, m in zip(timestamps, mask) if m]\n            cat_scores = [s for s, m in zip(scores, mask) if m]\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=cat_timestamps,\n                    y=cat_scores,\n                    name=cat.title(),\n                    mode=\"markers\",\n                    marker=dict(\n                        color=color,\n                        size=8,\n                        symbol=\"circle\"\n                    )\n                ),\n                row=row,\n                col=col\n            )\n            \n        # Add threshold line\n        fig.add_trace(\n            go.Scatter(\n                x=timestamps,\n                y=[self.config.alert_threshold] * len(timestamps),\n                name=\"Alert Threshold\",\n                line=dict(color=\"red\", width=1, dash=\"dash\")\n            ),\n            row=row,\n            col=col\n        )\n        \n        # Update axes\n        fig.update_xaxes(title_text=\"Time\", row=row, col=col)\n        fig.update_yaxes(title_text=\"Anomaly Score\", range=[0, 1], row=row, col=col)\n        \n    def _add_alert_plot(self, fig, row: int, col: int):\n        \"\"\"Add alert history visualization\"\"\"\n        if not self.alert_history:\n            return\n            \n        # Prepare data\n        df = pd.DataFrame(self.alert_history)\n        df[\"date\"] = pd.to_datetime(df[\"timestamp\"]).dt.date\n        \n        # Count alerts by date and level\n        alert_counts = df.groupby([\"date\", \"level\"]).size().unstack(fill_value=0)\n        \n        # Define colors for alert levels\n        colors = {\n            \"critical\": \"#e74c3c\",\n            \"warning\": \"#f1c40f\",\n            \"info\": \"#3498db\"\n        }\n        \n        # Create stacked bar chart\n        for level in [\"critical\", \"warning\", \"info\"]:\n            if level in alert_counts.columns:\n                fig.add_trace(\n                    go.Bar(\n                        x=alert_counts.index,\n                        y=alert_counts[level],\n                        name=level.title(),\n                        marker_color=colors.get(level),\n                    ),\n                    row=row,\n                    col=col\n                )\n                \n        # Update layout\n        fig.update_xaxes(\n            title_text=\"Date\",\n            tickangle=45,\n            row=row,\n            col=col\n        )\n        fig.update_yaxes(title_text=\"Alert Count\", row=row, col=col)\n        fig.update_layout(barmode=\"stack\")\n        \n    def _calculate_summary_metrics(self) -> Dict[str, float]:\n        \"\"\"Calculate summary metrics from history\"\"\"\n        if not self.data_history:\n            return {}\n            \n        summary = {}\n        \n        # Calculate averages for each metric\n        for metric_type in [\"performance\", \"resources\", \"quality\"]:\n            if metric_type in self.current_metrics:\n                for metric, value in self.current_metrics[metric_type].items():\n                    metric_values = [\n                        d[\"process_data\"].get(metric_type, {}).get(metric, 0)\n                        for d in self.data_history\n                    ]\n                    summary[f\"avg_{metric}\"] = float(np.mean(metric_values))\n                    summary[f\"std_{metric}\"] = float(np.std(metric_values))\n                    \n        return summary\n        \n    def _summarize_alerts(self) -> Dict[str, Any]:\n        \"\"\"Summarize alert history\"\"\"\n        if not self.alert_history:\n            return {}\n            \n        summary = {\n            \"total_alerts\": len(self.alert_history),\n            \"alert_types\": {},\n            \"severity_distribution\": {},\n            \"recent_alerts\": []\n        }\n        \n        # Count alert types\n        for alert in self.alert_history:\n            alert_type = alert[\"type\"]\n            severity = alert[\"severity\"]\n            \n            summary[\"alert_types\"][alert_type] = \\\n                summary[\"alert_types\"].get(alert_type, 0) + 1\n            summary[\"severity_distribution\"][severity] = \\\n                summary[\"severity_distribution\"].get(severity, 0) + 1\n        \n        # Get recent alerts\n        recent_alerts = sorted(\n            self.alert_history,\n            key=lambda x: x[\"timestamp\"],\n            reverse=True\n        )[:5]\n        \n        summary[\"recent_alerts\"] = [\n            {\n                \"timestamp\": alert[\"timestamp\"].isoformat(),\n                \"type\": alert[\"type\"],\n                \"severity\": alert[\"severity\"],\n                \"message\": alert[\"message\"]\n            }\n            for alert in recent_alerts\n        ]\n        \n        return summary\n        \n    def _summarize_optimization_results(self) -> Dict[str, Any]:\n        \"\"\"Summarize optimization results\"\"\"\n        results = []\n        for data in self.data_history:\n            if data.get(\"optimization_results\"):\n                results.extend(data[\"optimization_results\"])\n                \n        if not results:\n            return {}\n            \n        summary = {\n            \"total_optimizations\": len(results),\n            \"average_impact\": {},\n            \"success_rate\": 0.0,\n            \"resource_savings\": 0.0\n        }\n        \n        # Calculate average impact\n        impact_types = [\"efficiency\", \"cost\", \"quality\"]\n        for impact_type in impact_types:\n            values = [\n                r.get(\"impact\", {}).get(f\"{impact_type}_improvement\", 0)\n                for r in results\n            ]\n            summary[\"average_impact\"][impact_type] = float(np.mean(values))\n        \n        # Calculate success rate\n        successful = sum(1 for r in results if r.get(\"status\") == \"successful\")\n        summary[\"success_rate\"] = successful / len(results)\n        \n        # Calculate resource savings\n        savings = [\n            r.get(\"impact\", {}).get(\"resource_optimization\", 0)\n            for r in results\n        ]\n        summary[\"resource_savings\"] = float(np.mean(savings))\n        \n        return summary\n        \n    def _summarize_quality_metrics(self) -> Dict[str, Any]:\n        \"\"\"Summarize quality metrics\"\"\"\n        if not self.data_history:\n            return {}\n            \n        quality_data = [\n            d.get(\"quality_metrics\", {})\n            for d in self.data_history\n        ]\n        \n        if not quality_data:\n            return {}\n            \n        summary = {\n            \"average_metrics\": {},\n            \"trend_analysis\": {},\n            \"issue_summary\": {}\n        }\n        \n        # Calculate average metrics\n        metrics = [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]\n        for metric in metrics:\n            values = [\n                d.get(metric, 0)\n                for d in quality_data\n            ]\n            summary[\"average_metrics\"][metric] = float(np.mean(values))\n            \n            # Calculate trend\n            if len(values) > 1:\n                trend = np.polyfit(range(len(values)), values, 1)[0]\n                summary[\"trend_analysis\"][metric] = {\n                    \"slope\": float(trend),\n                    \"direction\": \"improving\" if trend > 0 else \"degrading\"\n                }\n        \n        # Summarize issues\n        for data in quality_data:\n            for issue in data.get(\"issues\", []):\n                issue_type = issue.get(\"type\", \"unknown\")\n                summary[\"issue_summary\"][issue_type] = \\\n                    summary[\"issue_summary\"].get(issue_type, 0) + 1\n                    \n        return summary\n        \n    def _analyze_trends(self) -> Dict[str, Any]:\n        \"\"\"Analyze trends in process data\"\"\"\n        if not self.data_history:\n            return {}\n            \n        trends = {\n            \"performance_trends\": self._analyze_performance_trends(),\n            \"resource_trends\": self._analyze_resource_trends(),\n            \"quality_trends\": self._analyze_quality_trends(),\n            \"anomaly_trends\": self._analyze_anomaly_trends()\n        }\n        \n        return trends\n        \n    def _analyze_performance_trends(self) -> Dict[str, Any]:\n        \"\"\"Analyze performance metric trends\"\"\"\n        if not self.data_history:\n            return {}\n            \n        trends = {}\n        metrics = [\"efficiency\", \"success_rate\", \"cost_effectiveness\"]\n        \n        for metric in metrics:\n            values = [\n                d[\"process_data\"].get(\"performance\", {}).get(metric, 0)\n                for d in self.data_history\n            ]\n            \n            if len(values) > 1:\n                trend = np.polyfit(range(len(values)), values, 1)[0]\n                trends[metric] = {\n                    \"slope\": float(trend),\n                    \"direction\": \"improving\" if trend > 0 else \"degrading\",\n                    \"current_value\": values[-1],\n                    \"change_rate\": float(trend / np.mean(values)) if np.mean(values) != 0 else 0\n                }\n                \n        return trends\n        \n    def _analyze_resource_trends(self) -> Dict[str, Any]:\n        \"\"\"Analyze resource utilization trends\"\"\"\n        if not self.data_history:\n            return {}\n            \n        trends = {}\n        resources = [\"cpu\", \"memory\", \"storage\", \"network\"]\n        \n        for resource in resources:\n            values = [\n                d[\"process_data\"].get(\"resources\", {}).get(resource, 0)\n                for d in self.data_history\n            ]\n            \n            if len(values) > 1:\n                trend = np.polyfit(range(len(values)), values, 1)[0]\n                trends[resource] = {\n                    \"slope\": float(trend),\n                    \"direction\": \"increasing\" if trend > 0 else \"decreasing\",\n                    \"current_utilization\": values[-1],\n                    \"change_rate\": float(trend / np.mean(values)) if np.mean(values) != 0 else 0\n                }\n                \n        return trends\n        \n    def _analyze_quality_trends(self) -> Dict[str, Any]:\n        \"\"\"Analyze quality metric trends\"\"\"\n        if not self.data_history:\n            return {}\n            \n        trends = {}\n        metrics = [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]\n        \n        for metric in metrics:\n            values = [\n                d.get(\"quality_metrics\", {}).get(metric, 0)\n                for d in self.data_history\n            ]\n            \n            if len(values) > 1:\n                trend = np.polyfit(range(len(values)), values, 1)[0]\n                trends[metric] = {\n                    \"slope\": float(trend),\n                    \"direction\": \"improving\" if trend > 0 else \"degrading\",\n                    \"current_value\": values[-1],\n                    \"change_rate\": float(trend / np.mean(values)) if np.mean(values) != 0 else 0\n                }\n                \n        return trends\n        \n    def _analyze_anomaly_trends(self) -> Dict[str, Any]:\n        \"\"\"Analyze anomaly detection trends\"\"\"\n        if not self.data_history:\n            return {}\n            \n        trends = {\n            \"anomaly_frequency\": {},\n            \"severity_trends\": {},\n            \"type_distribution\": {}\n        }\n        \n        # Analyze anomaly frequency\n        anomaly_counts = []\n        for data in self.data_history:\n            if data.get(\"anomaly_alerts\"):\n                anomaly_counts.append(len(data[\"anomaly_alerts\"]))\n            else:\n                anomaly_counts.append(0)\n                \n        if len(anomaly_counts) > 1:\n            trend = np.polyfit(range(len(anomaly_counts)), anomaly_counts, 1)[0]\n            trends[\"anomaly_frequency\"] = {\n                \"slope\": float(trend),\n                \"direction\": \"increasing\" if trend > 0 else \"decreasing\",\n                \"current_rate\": anomaly_counts[-1],\n                \"change_rate\": float(trend / np.mean(anomaly_counts)) if np.mean(anomaly_counts) != 0 else 0\n            }\n            \n        # Analyze severity trends\n        severity_values = []\n        for data in self.data_history:\n            if data.get(\"anomaly_alerts\"):\n                severities = [\n                    alert.get(\"severity\", 0)\n                    for alert in data[\"anomaly_alerts\"]\n                ]\n                severity_values.append(np.mean(severities))\n            else:\n                severity_values.append(0)\n                \n        if len(severity_values) > 1:\n            trend = np.polyfit(range(len(severity_values)), severity_values, 1)[0]\n            trends[\"severity_trends\"] = {\n                \"slope\": float(trend),\n                \"direction\": \"increasing\" if trend > 0 else \"decreasing\",\n                \"current_severity\": severity_values[-1],\n                \"change_rate\": float(trend / np.mean(severity_values)) if np.mean(severity_values) != 0 else 0\n            }\n            \n        # Analyze type distribution\n        type_counts = {}\n        for data in self.data_history:\n            if data.get(\"anomaly_alerts\"):\n                for alert in data[\"anomaly_alerts\"]:\n                    alert_type = alert.get(\"type\", \"unknown\")\n                    type_counts[alert_type] = type_counts.get(alert_type, 0) + 1\n                    \n        trends[\"type_distribution\"] = type_counts\n        \n        return trends\n        \n    def _extract_performance_metrics(self, data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Extract performance metrics from process data\"\"\"\n        metrics = {}\n        if \"performance\" in data:\n            perf_data = data[\"performance\"]\n            metrics = {\n                \"efficiency\": perf_data.get(\"efficiency\", 0.0),\n                \"success_rate\": perf_data.get(\"success_rate\", 0.0),\n                \"cost_effectiveness\": perf_data.get(\"cost_effectiveness\", 0.0),\n                \"throughput\": perf_data.get(\"throughput\", 0.0),\n                \"response_time\": perf_data.get(\"response_time\", 0.0)\n            }\n        return metrics\n        \n    def _extract_resource_metrics(self, data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Extract resource metrics from process data\"\"\"\n        metrics = {}\n        if \"resources\" in data:\n            res_data = data[\"resources\"]\n            metrics = {\n                \"cpu\": res_data.get(\"cpu_utilization\", 0.0),\n                \"memory\": res_data.get(\"memory_utilization\", 0.0),\n                \"storage\": res_data.get(\"storage_utilization\", 0.0),\n                \"network\": res_data.get(\"network_utilization\", 0.0)\n            }\n        return metrics\n        \n    def _extract_quality_metrics(self, data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Extract quality metrics from process data\"\"\"\n        metrics = {}\n        if \"quality\" in data:\n            quality_data = data[\"quality\"]\n            metrics = {\n                \"completeness\": quality_data.get(\"completeness\", 0.0),\n                \"accuracy\": quality_data.get(\"accuracy\", 0.0),\n                \"consistency\": quality_data.get(\"consistency\", 0.0),\n                \"timeliness\": quality_data.get(\"timeliness\", 0.0)\n            }\n        return metrics "}
{"type": "source_file", "path": "minesight/core/ai/advanced_models.py", "content": "\"\"\"\nAdvanced model architectures\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom typing import Dict, List, Any, Optional, Tuple\n\nclass TransformerModel(nn.Module):\n    \"\"\"Transformer model for mineral exploration\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 nhead: int = 4,\n                 num_layers: int = 2,\n                 dim_feedforward: int = 256,\n                 dropout: float = 0.1):\n        \"\"\"\n        Initialize transformer model\n        \n        Args:\n            input_dim: Input feature dimension\n            nhead: Number of attention heads\n            num_layers: Number of transformer layers\n            dim_feedforward: Feedforward dimension\n            dropout: Dropout probability\n        \"\"\"\n        super().__init__()\n        \n        # Feature embedding\n        self.embedding = nn.Linear(input_dim, dim_feedforward)\n        \n        # Transformer encoder\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=dim_feedforward,\n            nhead=nhead,\n            dim_feedforward=dim_feedforward * 2,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(\n            encoder_layer,\n            num_layers=num_layers\n        )\n        \n        # Output layers\n        self.fc = nn.Sequential(\n            nn.Linear(dim_feedforward, dim_feedforward // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(dim_feedforward // 2, 1)\n        )\n        \n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"Forward pass\"\"\"\n        # Embed features\n        x = self.embedding(x)\n        \n        # Add positional encoding if needed\n        if hasattr(self, 'pos_encoder'):\n            x = self.pos_encoder(x)\n        \n        # Transformer encoding\n        x = self.transformer(x)\n        \n        # Get predictions\n        logits = self.fc(x.mean(dim=1))  # Pool across sequence\n        \n        return {\n            'features': x,\n            'logits': logits,\n            'probability': torch.sigmoid(logits)\n        }\n\nclass EnsembleModel(nn.Module):\n    \"\"\"Ensemble of models for mineral exploration\"\"\"\n    \n    def __init__(self,\n                 models: List[nn.Module],\n                 weights: Optional[List[float]] = None):\n        \"\"\"\n        Initialize ensemble\n        \n        Args:\n            models: List of models\n            weights: Model weights (default: equal weights)\n        \"\"\"\n        super().__init__()\n        self.models = nn.ModuleList(models)\n        self.weights = weights or [1.0 / len(models)] * len(models)\n        \n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"Forward pass\"\"\"\n        outputs = []\n        features = []\n        \n        # Get predictions from each model\n        for model in self.models:\n            model_output = model(x)\n            outputs.append(model_output['logits'])\n            features.append(model_output['features'])\n        \n        # Weighted average of logits\n        logits = torch.zeros_like(outputs[0])\n        for w, o in zip(self.weights, outputs):\n            logits += w * o\n            \n        return {\n            'features': torch.stack(features, dim=1),  # [batch, n_models, features]\n            'logits': logits,\n            'probability': torch.sigmoid(logits),\n            'ensemble_outputs': outputs\n        }\n\nclass UncertaintyModel(nn.Module):\n    \"\"\"Model with uncertainty estimation\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 hidden_dims: List[int] = [256, 128, 64],\n                 dropout: float = 0.3,\n                 n_samples: int = 10):\n        \"\"\"\n        Initialize model\n        \n        Args:\n            input_dim: Input feature dimension\n            hidden_dims: List of hidden layer dimensions\n            dropout: Dropout probability\n            n_samples: Number of Monte Carlo samples\n        \"\"\"\n        super().__init__()\n        \n        # Feature extractor\n        layers = []\n        dims = [input_dim] + hidden_dims\n        \n        for i in range(len(dims)-1):\n            layers.extend([\n                nn.Linear(dims[i], dims[i+1]),\n                nn.BatchNorm1d(dims[i+1]),\n                nn.ReLU(),\n                nn.Dropout(dropout)\n            ])\n            \n        self.feature_extractor = nn.Sequential(*layers)\n        \n        # Output layers for mean and variance\n        self.mean_head = nn.Linear(hidden_dims[-1], 1)\n        self.var_head = nn.Linear(hidden_dims[-1], 1)\n        \n        self.n_samples = n_samples\n        self.dropout = dropout\n        \n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"Forward pass\"\"\"\n        if self.training:\n            return self._forward_train(x)\n        else:\n            return self._forward_eval(x)\n            \n    def _forward_train(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"Forward pass during training\"\"\"\n        features = self.feature_extractor(x)\n        mean = self.mean_head(features)\n        log_var = self.var_head(features)\n        \n        return {\n            'features': features,\n            'mean': mean,\n            'log_var': log_var,\n            'probability': torch.sigmoid(mean)\n        }\n        \n    def _forward_eval(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"Forward pass during evaluation (Monte Carlo Dropout)\"\"\"\n        self.train()  # Enable dropout\n        \n        means = []\n        vars = []\n        \n        # Multiple forward passes\n        for _ in range(self.n_samples):\n            features = self.feature_extractor(x)\n            means.append(self.mean_head(features))\n            vars.append(torch.exp(self.var_head(features)))\n            \n        # Calculate statistics\n        means = torch.stack(means, dim=0)\n        vars = torch.stack(vars, dim=0)\n        \n        mean = means.mean(dim=0)\n        uncertainty = (vars.mean(dim=0) + means.var(dim=0))\n        \n        self.eval()  # Restore eval mode\n        \n        return {\n            'mean': mean,\n            'uncertainty': uncertainty,\n            'probability': torch.sigmoid(mean),\n            'sample_means': means,\n            'sample_vars': vars\n        }\n\nclass MultiTaskModel(nn.Module):\n    \"\"\"Multi-task model for mineral exploration\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 task_configs: Dict[str, Dict[str, Any]],\n                 shared_dims: List[int] = [256, 128],\n                 task_dims: List[int] = [64, 32],\n                 dropout: float = 0.3):\n        \"\"\"\n        Initialize multi-task model\n        \n        Args:\n            input_dim: Input feature dimension\n            task_configs: Configuration for each task\n            shared_dims: Shared layer dimensions\n            task_dims: Task-specific layer dimensions\n            dropout: Dropout probability\n        \"\"\"\n        super().__init__()\n        \n        # Shared layers\n        shared_layers = []\n        dims = [input_dim] + shared_dims\n        \n        for i in range(len(dims)-1):\n            shared_layers.extend([\n                nn.Linear(dims[i], dims[i+1]),\n                nn.BatchNorm1d(dims[i+1]),\n                nn.ReLU(),\n                nn.Dropout(dropout)\n            ])\n            \n        self.shared_network = nn.Sequential(*shared_layers)\n        \n        # Task-specific networks\n        self.task_networks = nn.ModuleDict()\n        \n        for task_name, task_config in task_configs.items():\n            task_layers = []\n            dims = [shared_dims[-1]] + task_dims\n            \n            for i in range(len(dims)-1):\n                task_layers.extend([\n                    nn.Linear(dims[i], dims[i+1]),\n                    nn.BatchNorm1d(dims[i+1]),\n                    nn.ReLU(),\n                    nn.Dropout(dropout)\n                ])\n                \n            # Output layer\n            task_layers.append(\n                nn.Linear(dims[-1], task_config['output_dim'])\n            )\n            \n            self.task_networks[task_name] = nn.Sequential(*task_layers)\n            \n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"Forward pass\"\"\"\n        # Shared features\n        shared_features = self.shared_network(x)\n        \n        # Task-specific outputs\n        outputs = {}\n        \n        for task_name, task_network in self.task_networks.items():\n            task_output = task_network(shared_features)\n            outputs[f'{task_name}_logits'] = task_output\n            \n            if task_output.shape[-1] == 1:  # Binary classification\n                outputs[f'{task_name}_probability'] = torch.sigmoid(task_output)\n            else:  # Multi-class classification\n                outputs[f'{task_name}_probability'] = F.softmax(task_output, dim=-1)\n                \n        outputs['features'] = shared_features\n        \n        return outputs\n\nclass SelfAttentionModel(nn.Module):\n    \"\"\"Self-attention model for mineral exploration\"\"\"\n    \n    def __init__(self,\n                 input_dim: int,\n                 hidden_dim: int = 128,\n                 num_heads: int = 4,\n                 dropout: float = 0.3):\n        \"\"\"\n        Initialize self-attention model\n        \n        Args:\n            input_dim: Input feature dimension\n            hidden_dim: Hidden dimension\n            num_heads: Number of attention heads\n            dropout: Dropout probability\n        \"\"\"\n        super().__init__()\n        \n        self.input_projection = nn.Linear(input_dim, hidden_dim)\n        \n        # Multi-head self-attention\n        self.attention = nn.MultiheadAttention(\n            embed_dim=hidden_dim,\n            num_heads=num_heads,\n            dropout=dropout,\n            batch_first=True\n        )\n        \n        # Output layers\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n        \"\"\"Forward pass\"\"\"\n        # Project input\n        x = self.input_projection(x)\n        \n        # Self-attention\n        attended, attention_weights = self.attention(x, x, x)\n        \n        # Pool attention outputs\n        pooled = attended.mean(dim=1)\n        \n        # Get predictions\n        logits = self.fc(pooled)\n        \n        return {\n            'features': attended,\n            'attention_weights': attention_weights,\n            'logits': logits,\n            'probability': torch.sigmoid(logits)\n        } "}
{"type": "source_file", "path": "minesight/core/ai/data.py", "content": "\"\"\"\nData loading and preprocessing utilities\n\"\"\"\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom pathlib import Path\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nclass DataProcessor:\n    \"\"\"Data processing utility for mineral exploration\"\"\"\n    \n    def __init__(self,\n                 data_dir: Path,\n                 cache_dir: Optional[Path] = None):\n        \"\"\"\n        Initialize processor\n        \n        Args:\n            data_dir: Directory containing raw data\n            cache_dir: Optional directory for caching processed data\n        \"\"\"\n        self.data_dir = data_dir\n        self.cache_dir = cache_dir or data_dir / \"cache\"\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Initialize encoders\n        self.scalers = {}\n        self.label_encoders = {}\n    \n    def load_and_process_data(self,\n                            config: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Load and process data according to configuration\n        \n        Args:\n            config: Data processing configuration\n            \n        Returns:\n            Dictionary with processed data\n        \"\"\"\n        # Check cache\n        cache_path = self._get_cache_path(config)\n        if cache_path.exists():\n            return torch.load(cache_path)\n        \n        # Load raw data\n        deposits = self._load_deposits(config['deposits_file'])\n        features = self._load_features(config['features_file'])\n        \n        # Process data\n        processed_data = self._process_data(\n            deposits,\n            features,\n            config\n        )\n        \n        # Save to cache\n        torch.save(processed_data, cache_path)\n        \n        return processed_data\n    \n    def _load_deposits(self, filename: str) -> pd.DataFrame:\n        \"\"\"Load deposit data\"\"\"\n        path = self.data_dir / filename\n        \n        if path.suffix == '.csv':\n            return pd.read_csv(path)\n        elif path.suffix == '.parquet':\n            return pd.read_parquet(path)\n        else:\n            raise ValueError(f\"Unsupported file format: {path.suffix}\")\n    \n    def _load_features(self, filename: str) -> pd.DataFrame:\n        \"\"\"Load feature data\"\"\"\n        path = self.data_dir / filename\n        \n        if path.suffix == '.csv':\n            return pd.read_csv(path)\n        elif path.suffix == '.parquet':\n            return pd.read_parquet(path)\n        else:\n            raise ValueError(f\"Unsupported file format: {path.suffix}\")\n    \n    def _process_data(self,\n                     deposits: pd.DataFrame,\n                     features: pd.DataFrame,\n                     config: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Process raw data into model inputs\"\"\"\n        # Filter data\n        deposits = self._filter_data(deposits, config.get('deposit_filters', {}))\n        features = self._filter_data(features, config.get('feature_filters', {}))\n        \n        # Extract features\n        X = self._extract_features(deposits, features, config)\n        y = self._extract_labels(deposits, config)\n        \n        # Split data\n        splits = self._split_data(X, y, config)\n        \n        # Scale features\n        scaled_splits = self._scale_features(splits, config)\n        \n        # Convert to tensors\n        tensor_data = self._convert_to_tensors(scaled_splits)\n        \n        return tensor_data\n    \n    def _filter_data(self,\n                    data: pd.DataFrame,\n                    filters: Dict[str, Any]) -> pd.DataFrame:\n        \"\"\"Apply filters to data\"\"\"\n        filtered = data.copy()\n        \n        for column, condition in filters.items():\n            if column in filtered.columns:\n                if isinstance(condition, (list, tuple)):\n                    filtered = filtered[filtered[column].isin(condition)]\n                elif isinstance(condition, dict):\n                    if 'min' in condition:\n                        filtered = filtered[\n                            filtered[column] >= condition['min']\n                        ]\n                    if 'max' in condition:\n                        filtered = filtered[\n                            filtered[column] <= condition['max']\n                        ]\n                else:\n                    filtered = filtered[filtered[column] == condition]\n        \n        return filtered\n    \n    def _extract_features(self,\n                         deposits: pd.DataFrame,\n                         features: pd.DataFrame,\n                         config: Dict[str, Any]) -> np.ndarray:\n        \"\"\"Extract model features\"\"\"\n        # Get feature columns\n        numerical_features = config.get('numerical_features', [])\n        categorical_features = config.get('categorical_features', [])\n        \n        # Process numerical features\n        numerical_data = []\n        for col in numerical_features:\n            if col in deposits.columns:\n                numerical_data.append(deposits[col].values)\n            elif col in features.columns:\n                numerical_data.append(features[col].values)\n        \n        # Process categorical features\n        categorical_data = []\n        for col in categorical_features:\n            if col in deposits.columns:\n                encoded = self._encode_categorical(deposits[col], col)\n                categorical_data.append(encoded)\n            elif col in features.columns:\n                encoded = self._encode_categorical(features[col], col)\n                categorical_data.append(encoded)\n        \n        # Combine features\n        combined = np.column_stack(numerical_data + categorical_data)\n        \n        return combined\n    \n    def _extract_labels(self,\n                       deposits: pd.DataFrame,\n                       config: Dict[str, Any]) -> np.ndarray:\n        \"\"\"Extract labels\"\"\"\n        label_col = config['label_column']\n        \n        if config.get('binary_labels', True):\n            return (deposits[label_col] > 0).astype(float).values\n        else:\n            return deposits[label_col].values\n    \n    def _split_data(self,\n                    X: np.ndarray,\n                    y: np.ndarray,\n                    config: Dict[str, Any]) -> Dict[str, np.ndarray]:\n        \"\"\"Split data into train/val/test sets\"\"\"\n        # First split: train + val vs test\n        train_val_X, test_X, train_val_y, test_y = train_test_split(\n            X, y,\n            test_size=config.get('test_size', 0.2),\n            random_state=42\n        )\n        \n        # Second split: train vs val\n        train_X, val_X, train_y, val_y = train_test_split(\n            train_val_X,\n            train_val_y,\n            test_size=config.get('val_size', 0.2),\n            random_state=42\n        )\n        \n        return {\n            'train': {'X': train_X, 'y': train_y},\n            'val': {'X': val_X, 'y': val_y},\n            'test': {'X': test_X, 'y': test_y}\n        }\n    \n    def _scale_features(self,\n                       splits: Dict[str, Dict[str, np.ndarray]],\n                       config: Dict[str, Any]) -> Dict[str, Dict[str, np.ndarray]]:\n        \"\"\"Scale features\"\"\"\n        # Initialize scaler\n        scaler = StandardScaler()\n        \n        # Fit on training data\n        scaler.fit(splits['train']['X'])\n        \n        # Transform all splits\n        scaled_splits = {}\n        for split_name, split_data in splits.items():\n            scaled_splits[split_name] = {\n                'X': scaler.transform(split_data['X']),\n                'y': split_data['y']\n            }\n        \n        # Save scaler\n        self.scalers['feature_scaler'] = scaler\n        \n        return scaled_splits\n    \n    def _convert_to_tensors(self,\n                           splits: Dict[str, Dict[str, np.ndarray]]) -> Dict[str, Dict[str, torch.Tensor]]:\n        \"\"\"Convert numpy arrays to PyTorch tensors\"\"\"\n        tensor_data = {}\n        \n        for split_name, split_data in splits.items():\n            tensor_data[split_name] = {\n                'features': torch.FloatTensor(split_data['X']),\n                'labels': torch.FloatTensor(split_data['y'])\n            }\n        \n        return tensor_data\n    \n    def _encode_categorical(self,\n                          series: pd.Series,\n                          column_name: str) -> np.ndarray:\n        \"\"\"Encode categorical variable\"\"\"\n        if column_name not in self.label_encoders:\n            encoder = LabelEncoder()\n            encoded = encoder.fit_transform(series)\n            self.label_encoders[column_name] = encoder\n        else:\n            encoder = self.label_encoders[column_name]\n            encoded = encoder.transform(series)\n        \n        return encoded\n    \n    def _get_cache_path(self, config: Dict[str, Any]) -> Path:\n        \"\"\"Get cache file path based on configuration\"\"\"\n        # Create cache key from config\n        config_str = str(sorted(config.items()))\n        cache_key = hex(hash(config_str))[2:]\n        \n        return self.cache_dir / f\"processed_data_{cache_key}.pt\"\n    \n    def get_feature_names(self,\n                         config: Dict[str, Any]) -> List[str]:\n        \"\"\"Get list of feature names\"\"\"\n        names = []\n        \n        # Add numerical features\n        names.extend(config.get('numerical_features', []))\n        \n        # Add encoded categorical features\n        for col in config.get('categorical_features', []):\n            if col in self.label_encoders:\n                encoder = self.label_encoders[col]\n                names.extend([f\"{col}_{cls}\" for cls in encoder.classes_])\n        \n        return names\n    \n    def inverse_transform_features(self,\n                                 features: torch.Tensor) -> np.ndarray:\n        \"\"\"Convert scaled features back to original scale\"\"\"\n        if 'feature_scaler' in self.scalers:\n            return self.scalers['feature_scaler'].inverse_transform(\n                features.cpu().numpy()\n            )\n        return features.cpu().numpy()\n    \n    def decode_categorical(self,\n                         encoded: np.ndarray,\n                         column_name: str) -> List[str]:\n        \"\"\"Decode categorical variables back to original values\"\"\"\n        if column_name in self.label_encoders:\n            encoder = self.label_encoders[column_name]\n            return encoder.inverse_transform(encoded)\n        return encoded.tolist() "}
{"type": "source_file", "path": "minesight/core/analysis/time_series_analyzer.py", "content": "\"\"\"\nTime series analysis module for mineral exploration data\n\"\"\"\nfrom typing import Dict, List, Optional, Any\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom scipy import stats\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom sklearn.linear_model import LinearRegression\n\nclass TimeSeriesAnalyzer:\n    \"\"\"Class for analyzing temporal patterns in mineral exploration data\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the time series analyzer\"\"\"\n        pass\n        \n    def analyze_discovery_trends(self,\n                               deposits: pd.DataFrame,\n                               window_days: int = 30) -> Dict[str, Any]:\n        \"\"\"\n        Analyze mineral deposit discovery trends\n        \n        Args:\n            deposits: DataFrame of mineral deposits\n            window_days: Window size for trend analysis\n            \n        Returns:\n            Dictionary with trend analysis results\n        \"\"\"\n        if deposits.empty:\n            return {\n                \"total_discoveries\": 0,\n                \"discovery_rate\": 0.0,\n                \"trend_direction\": \"unknown\",\n                \"seasonal_pattern\": None,\n                \"forecast\": None\n            }\n            \n        # Convert dates to datetime if needed\n        if 'date_added' in deposits.columns:\n            deposits['date_added'] = pd.to_datetime(deposits['date_added'])\n        else:\n            return {\n                \"error\": \"No date information available\"\n            }\n            \n        # Sort by date\n        deposits = deposits.sort_values('date_added')\n        \n        # Calculate basic metrics\n        total_discoveries = len(deposits)\n        date_range = (deposits['date_added'].max() - deposits['date_added'].min()).days\n        discovery_rate = total_discoveries / max(date_range, 1)\n        \n        # Analyze trend\n        trend_direction = self._analyze_trend(deposits['date_added'])\n        \n        # Analyze seasonality\n        seasonal_pattern = self._analyze_seasonality(deposits['date_added'])\n        \n        # Generate forecast\n        forecast = self._forecast_discoveries(deposits, window_days)\n        \n        return {\n            \"total_discoveries\": total_discoveries,\n            \"discovery_rate\": float(discovery_rate),\n            \"trend_direction\": trend_direction,\n            \"seasonal_pattern\": seasonal_pattern,\n            \"forecast\": forecast\n        }\n    \n    def analyze_feature_evolution(self,\n                                features: pd.DataFrame,\n                                window_days: int = 30) -> Dict[str, Any]:\n        \"\"\"\n        Analyze evolution of geological features over time\n        \n        Args:\n            features: DataFrame of geological features\n            window_days: Window size for trend analysis\n            \n        Returns:\n            Dictionary with evolution analysis results\n        \"\"\"\n        if features.empty:\n            return {\n                \"total_features\": 0,\n                \"mapping_rate\": 0.0,\n                \"feature_type_trends\": {}\n            }\n            \n        # Convert dates to datetime if needed\n        if 'date_added' in features.columns:\n            features['date_added'] = pd.to_datetime(features['date_added'])\n        else:\n            return {\n                \"error\": \"No date information available\"\n            }\n            \n        # Calculate basic metrics\n        total_features = len(features)\n        date_range = (features['date_added'].max() - features['date_added'].min()).days\n        mapping_rate = total_features / max(date_range, 1)\n        \n        # Analyze trends by feature type\n        feature_type_trends = {}\n        for feature_type in features['feature_type'].unique():\n            type_features = features[features['feature_type'] == feature_type]\n            \n            trend_info = {\n                \"count\": len(type_features),\n                \"trend_direction\": self._analyze_trend(type_features['date_added']),\n                \"recent_activity\": self._analyze_recent_activity(\n                    type_features['date_added'],\n                    window_days\n                )\n            }\n            \n            feature_type_trends[feature_type] = trend_info\n            \n        return {\n            \"total_features\": total_features,\n            \"mapping_rate\": float(mapping_rate),\n            \"feature_type_trends\": feature_type_trends\n        }\n    \n    def analyze_exploration_intensity(self,\n                                   deposits: pd.DataFrame,\n                                   features: pd.DataFrame,\n                                   window_days: int = 30) -> Dict[str, Any]:\n        \"\"\"\n        Analyze exploration activity intensity\n        \n        Args:\n            deposits: DataFrame of mineral deposits\n            features: DataFrame of geological features\n            window_days: Window size for intensity analysis\n            \n        Returns:\n            Dictionary with intensity analysis results\n        \"\"\"\n        # Combine dates from both deposits and features\n        dates = []\n        \n        if not deposits.empty and 'date_added' in deposits.columns:\n            dates.extend(pd.to_datetime(deposits['date_added']))\n            \n        if not features.empty and 'date_added' in features.columns:\n            dates.extend(pd.to_datetime(features['date_added']))\n            \n        if not dates:\n            return {\n                \"total_activities\": 0,\n                \"activity_rate\": 0.0,\n                \"intensity_trend\": \"unknown\"\n            }\n            \n        dates = pd.Series(dates).sort_values()\n        \n        # Calculate basic metrics\n        total_activities = len(dates)\n        date_range = (dates.max() - dates.min()).days\n        activity_rate = total_activities / max(date_range, 1)\n        \n        # Analyze intensity trend\n        intensity_trend = self._analyze_trend(dates)\n        \n        # Calculate intensity over time\n        intensity_data = self._calculate_intensity(dates, window_days)\n        \n        return {\n            \"total_activities\": total_activities,\n            \"activity_rate\": float(activity_rate),\n            \"intensity_trend\": intensity_trend,\n            \"intensity_data\": intensity_data\n        }\n    \n    def _analyze_trend(self, dates: pd.Series) -> str:\n        \"\"\"Analyze trend direction in time series data\"\"\"\n        if len(dates) < 2:\n            return \"unknown\"\n            \n        # Convert dates to numeric values\n        numeric_dates = (dates - dates.min()).dt.total_seconds()\n        \n        # Fit linear regression\n        X = numeric_dates.values.reshape(-1, 1)\n        y = np.arange(len(dates)).reshape(-1, 1)\n        \n        model = LinearRegression()\n        model.fit(X, y)\n        \n        # Determine trend direction based on slope\n        slope = model.coef_[0][0]\n        \n        if slope > 0.1:\n            return \"increasing\"\n        elif slope < -0.1:\n            return \"decreasing\"\n        else:\n            return \"stable\"\n    \n    def _analyze_seasonality(self, dates: pd.Series) -> Optional[Dict[str, float]]:\n        \"\"\"Analyze seasonal patterns in time series data\"\"\"\n        if len(dates) < 12:  # Need at least a year of data\n            return None\n            \n        # Count occurrences by month\n        monthly_counts = dates.dt.month.value_counts()\n        \n        # Calculate relative frequencies\n        total = monthly_counts.sum()\n        monthly_frequencies = {\n            month: float(count / total)\n            for month, count in monthly_counts.items()\n        }\n        \n        return monthly_frequencies\n    \n    def _forecast_discoveries(self,\n                            deposits: pd.DataFrame,\n                            window_days: int) -> List[Dict[str, Any]]:\n        \"\"\"Generate discovery forecast\"\"\"\n        if len(deposits) < window_days:\n            return None\n            \n        # Create time series\n        ts = pd.Series(\n            index=deposits['date_added'],\n            data=1\n        ).resample('D').sum().fillna(0)\n        \n        # Fit exponential smoothing model\n        model = ExponentialSmoothing(\n            ts,\n            seasonal_periods=7,\n            trend='add',\n            seasonal='add'\n        ).fit()\n        \n        # Generate forecast\n        forecast_steps = window_days\n        forecast = model.forecast(forecast_steps)\n        \n        # Calculate confidence intervals\n        residuals = model.resid\n        std_resid = np.std(residuals)\n        z_value = stats.norm.ppf(0.975)  # 95% confidence interval\n        \n        forecast_data = []\n        for i, (date, value) in enumerate(forecast.items()):\n            forecast_data.append({\n                \"date\": date.strftime(\"%Y-%m-%d\"),\n                \"predicted_discoveries\": float(max(0, value)),\n                \"lower_bound\": float(max(0, value - z_value * std_resid)),\n                \"upper_bound\": float(value + z_value * std_resid)\n            })\n            \n        return forecast_data\n    \n    def _analyze_recent_activity(self,\n                               dates: pd.Series,\n                               window_days: int) -> Dict[str, float]:\n        \"\"\"Analyze recent activity levels\"\"\"\n        if dates.empty:\n            return {\n                \"recent_count\": 0,\n                \"activity_level\": 0.0\n            }\n            \n        # Calculate recent activity\n        cutoff_date = dates.max() - pd.Timedelta(days=window_days)\n        recent_count = sum(dates > cutoff_date)\n        \n        # Calculate activity level relative to overall average\n        total_days = (dates.max() - dates.min()).days\n        overall_rate = len(dates) / max(total_days, 1)\n        recent_rate = recent_count / window_days\n        \n        activity_level = recent_rate / overall_rate if overall_rate > 0 else 0\n        \n        return {\n            \"recent_count\": recent_count,\n            \"activity_level\": float(activity_level)\n        }\n    \n    def _calculate_intensity(self,\n                           dates: pd.Series,\n                           window_days: int) -> List[Dict[str, Any]]:\n        \"\"\"Calculate exploration intensity over time\"\"\"\n        if dates.empty:\n            return []\n            \n        # Create time series of daily counts\n        daily_counts = pd.Series(\n            index=dates,\n            data=1\n        ).resample('D').sum().fillna(0)\n        \n        # Calculate moving average\n        intensity = daily_counts.rolling(\n            window=window_days,\n            min_periods=1\n        ).mean()\n        \n        # Convert to list of dictionaries\n        intensity_data = []\n        for date, value in intensity.items():\n            intensity_data.append({\n                \"date\": date.strftime(\"%Y-%m-%d\"),\n                \"intensity\": float(value)\n            })\n            \n        return intensity_data "}
{"type": "source_file", "path": "minesight/core/optimization/deep_process_analyzer.py", "content": "import torch\nimport torch.nn as nn\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Any, Optional, Tuple\nfrom datetime import datetime\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport logging\n\n@dataclass\nclass AnalysisResult:\n    \"\"\"Analysis result from deep learning models\"\"\"\n    predictions: Dict[str, np.ndarray]\n    feature_importance: Dict[str, float]\n    confidence_scores: Dict[str, float]\n    patterns: List[Dict[str, Any]]\n    metrics: Dict[str, float]\n    timestamp: datetime\n\nclass ProcessEncoder(nn.Module):\n    \"\"\"Encoder network for process data\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int = 256):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.BatchNorm1d(hidden_size),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU(),\n            nn.BatchNorm1d(hidden_size // 2)\n        )\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.encoder(x)\n\nclass PerformancePredictor(nn.Module):\n    \"\"\"Performance prediction network\"\"\"\n    \n    def __init__(self, input_size: int, num_metrics: int = 6):\n        super().__init__()\n        self.predictor = nn.Sequential(\n            nn.Linear(input_size, input_size // 2),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(input_size // 2, num_metrics),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.predictor(x)\n\nclass AnomalyDetector(nn.Module):\n    \"\"\"Deep anomaly detection network\"\"\"\n    \n    def __init__(self, input_size: int, latent_size: int = 32):\n        super().__init__()\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, input_size // 2),\n            nn.ReLU(),\n            nn.BatchNorm1d(input_size // 2),\n            nn.Linear(input_size // 2, latent_size),\n            nn.ReLU()\n        )\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_size, input_size // 2),\n            nn.ReLU(),\n            nn.BatchNorm1d(input_size // 2),\n            nn.Linear(input_size // 2, input_size),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return encoded, decoded\n\nclass PatternDetector(nn.Module):\n    \"\"\"Pattern detection network with attention\"\"\"\n    \n    def __init__(self, input_size: int, num_heads: int = 4):\n        super().__init__()\n        \n        self.attention = nn.MultiheadAttention(\n            embed_dim=input_size,\n            num_heads=num_heads,\n            dropout=0.1\n        )\n        \n        self.pattern_classifier = nn.Sequential(\n            nn.Linear(input_size, input_size // 2),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(input_size // 2, 3)  # 3 pattern types\n        )\n        \n    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        # Apply self-attention\n        attended, attention_weights = self.attention(x, x, x)\n        \n        # Classify patterns\n        patterns = self.pattern_classifier(attended)\n        \n        return patterns, attention_weights\n\nclass DeepProcessAnalyzer:\n    \"\"\"Deep learning based process analyzer\"\"\"\n    \n    def __init__(self, input_size: int = 64):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.input_size = input_size\n        self.scaler = StandardScaler()\n        self.logger = logging.getLogger(__name__)\n        \n        # Initialize models\n        self.encoder = ProcessEncoder(input_size).to(self.device)\n        self.performance_predictor = PerformancePredictor(input_size // 2).to(self.device)\n        self.anomaly_detector = AnomalyDetector(input_size).to(self.device)\n        self.pattern_detector = PatternDetector(input_size // 2).to(self.device)\n        \n        # Training parameters\n        self.learning_rate = 0.001\n        self.batch_size = 32\n        self.num_epochs = 100\n        \n    def train(self, \n              training_data: pd.DataFrame,\n              validation_data: Optional[pd.DataFrame] = None):\n        \"\"\"\n        Train all deep learning models\n        \n        Args:\n            training_data: Training dataset\n            validation_data: Optional validation dataset\n        \"\"\"\n        try:\n            # Prepare data\n            X_train = self._prepare_features(training_data)\n            X_val = self._prepare_features(validation_data) if validation_data is not None else None\n            \n            # Train encoder\n            self._train_encoder(X_train, X_val)\n            \n            # Train performance predictor\n            self._train_predictor(X_train, X_val)\n            \n            # Train anomaly detector\n            self._train_anomaly_detector(X_train, X_val)\n            \n            # Train pattern detector\n            self._train_pattern_detector(X_train, X_val)\n            \n            self.logger.info(\"Successfully trained all models\")\n            \n        except Exception as e:\n            self.logger.error(f\"Error training models: {str(e)}\")\n            raise\n            \n    def analyze_process(self, process_data: pd.DataFrame) -> AnalysisResult:\n        \"\"\"\n        Analyze process data using trained models\n        \n        Args:\n            process_data: Process data to analyze\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        try:\n            # Prepare features\n            X = self._prepare_features(process_data)\n            X_tensor = torch.FloatTensor(X).to(self.device)\n            \n            # Get encoded representation\n            encoded = self.encoder(X_tensor)\n            \n            # Get performance predictions\n            predictions = self.performance_predictor(encoded)\n            \n            # Detect anomalies\n            _, reconstructed = self.anomaly_detector(X_tensor)\n            reconstruction_errors = torch.mean((X_tensor - reconstructed) ** 2, dim=1)\n            \n            # Detect patterns\n            patterns, attention_weights = self.pattern_detector(encoded)\n            \n            # Calculate feature importance\n            importance = self._calculate_feature_importance(\n                X_tensor,\n                encoded,\n                attention_weights\n            )\n            \n            # Calculate confidence scores\n            confidence = self._calculate_confidence_scores(\n                predictions,\n                reconstruction_errors,\n                patterns\n            )\n            \n            # Calculate metrics\n            metrics = self._calculate_analysis_metrics(\n                predictions,\n                reconstruction_errors,\n                patterns\n            )\n            \n            return AnalysisResult(\n                predictions=predictions.detach().cpu().numpy(),\n                feature_importance=importance,\n                confidence_scores=confidence,\n                patterns=self._convert_patterns(patterns, attention_weights),\n                metrics=metrics,\n                timestamp=datetime.now()\n            )\n            \n        except Exception as e:\n            self.logger.error(f\"Error analyzing process: {str(e)}\")\n            raise\n            \n    def _prepare_features(self, data: pd.DataFrame) -> np.ndarray:\n        \"\"\"Prepare features for deep learning models\"\"\"\n        if data is None:\n            return None\n            \n        # Select numerical columns\n        numerical_data = data.select_dtypes(include=[np.number])\n        \n        # Scale features\n        X = self.scaler.fit_transform(numerical_data)\n        \n        return X\n        \n    def _train_encoder(self, X_train: np.ndarray, X_val: Optional[np.ndarray]):\n        \"\"\"Train the process encoder\"\"\"\n        optimizer = torch.optim.Adam(self.encoder.parameters(), lr=self.learning_rate)\n        criterion = nn.MSELoss()\n        \n        X_train_tensor = torch.FloatTensor(X_train).to(self.device)\n        X_val_tensor = torch.FloatTensor(X_val).to(self.device) if X_val is not None else None\n        \n        for epoch in range(self.num_epochs):\n            # Training\n            self.encoder.train()\n            encoded = self.encoder(X_train_tensor)\n            loss = criterion(encoded, X_train_tensor)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            # Validation\n            if X_val_tensor is not None:\n                self.encoder.eval()\n                with torch.no_grad():\n                    val_encoded = self.encoder(X_val_tensor)\n                    val_loss = criterion(val_encoded, X_val_tensor)\n                    \n                if epoch % 10 == 0:\n                    self.logger.info(f\"Epoch {epoch}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss.item():.4f}\")\n                    \n    def _train_predictor(self, X_train: np.ndarray, X_val: Optional[np.ndarray]):\n        \"\"\"Train the performance predictor\"\"\"\n        optimizer = torch.optim.Adam(self.performance_predictor.parameters(), lr=self.learning_rate)\n        criterion = nn.MSELoss()\n        \n        X_train_tensor = torch.FloatTensor(X_train).to(self.device)\n        X_val_tensor = torch.FloatTensor(X_val).to(self.device) if X_val is not None else None\n        \n        for epoch in range(self.num_epochs):\n            # Training\n            self.performance_predictor.train()\n            encoded = self.encoder(X_train_tensor)\n            predictions = self.performance_predictor(encoded)\n            loss = criterion(predictions, X_train_tensor)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            # Validation\n            if X_val_tensor is not None:\n                self.performance_predictor.eval()\n                with torch.no_grad():\n                    val_encoded = self.encoder(X_val_tensor)\n                    val_predictions = self.performance_predictor(val_encoded)\n                    val_loss = criterion(val_predictions, X_val_tensor)\n                    \n                if epoch % 10 == 0:\n                    self.logger.info(f\"Epoch {epoch}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss.item():.4f}\")\n                    \n    def _train_anomaly_detector(self, X_train: np.ndarray, X_val: Optional[np.ndarray]):\n        \"\"\"Train the anomaly detector\"\"\"\n        optimizer = torch.optim.Adam(self.anomaly_detector.parameters(), lr=self.learning_rate)\n        criterion = nn.MSELoss()\n        \n        X_train_tensor = torch.FloatTensor(X_train).to(self.device)\n        X_val_tensor = torch.FloatTensor(X_val).to(self.device) if X_val is not None else None\n        \n        for epoch in range(self.num_epochs):\n            # Training\n            self.anomaly_detector.train()\n            encoded, decoded = self.anomaly_detector(X_train_tensor)\n            loss = criterion(decoded, X_train_tensor)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            # Validation\n            if X_val_tensor is not None:\n                self.anomaly_detector.eval()\n                with torch.no_grad():\n                    val_encoded, val_decoded = self.anomaly_detector(X_val_tensor)\n                    val_loss = criterion(val_decoded, X_val_tensor)\n                    \n                if epoch % 10 == 0:\n                    self.logger.info(f\"Epoch {epoch}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss.item():.4f}\")\n                    \n    def _train_pattern_detector(self, X_train: np.ndarray, X_val: Optional[np.ndarray]):\n        \"\"\"Train the pattern detector\"\"\"\n        optimizer = torch.optim.Adam(self.pattern_detector.parameters(), lr=self.learning_rate)\n        criterion = nn.CrossEntropyLoss()\n        \n        X_train_tensor = torch.FloatTensor(X_train).to(self.device)\n        X_val_tensor = torch.FloatTensor(X_val).to(self.device) if X_val is not None else None\n        \n        for epoch in range(self.num_epochs):\n            # Training\n            self.pattern_detector.train()\n            encoded = self.encoder(X_train_tensor)\n            patterns, _ = self.pattern_detector(encoded)\n            \n            # Generate pseudo-labels for self-supervised learning\n            labels = self._generate_pattern_labels(encoded)\n            loss = criterion(patterns, labels)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            # Validation\n            if X_val_tensor is not None:\n                self.pattern_detector.eval()\n                with torch.no_grad():\n                    val_encoded = self.encoder(X_val_tensor)\n                    val_patterns, _ = self.pattern_detector(val_encoded)\n                    val_labels = self._generate_pattern_labels(val_encoded)\n                    val_loss = criterion(val_patterns, val_labels)\n                    \n                if epoch % 10 == 0:\n                    self.logger.info(f\"Epoch {epoch}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss.item():.4f}\")\n                    \n    def _generate_pattern_labels(self, encoded: torch.Tensor) -> torch.Tensor:\n        \"\"\"Generate pseudo-labels for pattern detection\"\"\"\n        # Calculate temporal differences\n        diffs = torch.diff(encoded, dim=0)\n        \n        # Calculate pattern types based on differences\n        labels = torch.zeros(encoded.size(0), dtype=torch.long).to(self.device)\n        \n        # Assign labels based on difference patterns\n        labels[1:][torch.mean(diffs, dim=1) > 0.1] = 1  # Increasing pattern\n        labels[1:][torch.mean(diffs, dim=1) < -0.1] = 2  # Decreasing pattern\n        \n        return labels\n        \n    def _calculate_feature_importance(self,\n                                   X: torch.Tensor,\n                                   encoded: torch.Tensor,\n                                   attention_weights: torch.Tensor) -> Dict[str, float]:\n        \"\"\"Calculate feature importance scores\"\"\"\n        # Combine attention weights and encoding weights\n        importance = torch.mean(attention_weights, dim=0)\n        importance = importance * torch.norm(encoded, dim=1)\n        \n        # Normalize importance scores\n        importance = importance / torch.sum(importance)\n        \n        return {f\"feature_{i}\": float(imp) for i, imp in enumerate(importance)}\n        \n    def _calculate_confidence_scores(self,\n                                  predictions: torch.Tensor,\n                                  reconstruction_errors: torch.Tensor,\n                                  patterns: torch.Tensor) -> Dict[str, float]:\n        \"\"\"Calculate confidence scores for different components\"\"\"\n        confidence = {}\n        \n        # Prediction confidence\n        prediction_std = torch.std(predictions, dim=1)\n        confidence[\"predictions\"] = float(1.0 - torch.mean(prediction_std))\n        \n        # Anomaly detection confidence\n        confidence[\"anomaly\"] = float(1.0 - torch.mean(reconstruction_errors))\n        \n        # Pattern detection confidence\n        pattern_probs = torch.softmax(patterns, dim=1)\n        confidence[\"patterns\"] = float(torch.mean(torch.max(pattern_probs, dim=1)[0]))\n        \n        return confidence\n        \n    def _calculate_analysis_metrics(self,\n                                 predictions: torch.Tensor,\n                                 reconstruction_errors: torch.Tensor,\n                                 patterns: torch.Tensor) -> Dict[str, float]:\n        \"\"\"Calculate analysis quality metrics\"\"\"\n        metrics = {}\n        \n        # Prediction metrics\n        metrics[\"prediction_error\"] = float(torch.mean((predictions - torch.mean(predictions, dim=0)) ** 2))\n        \n        # Reconstruction metrics\n        metrics[\"reconstruction_error\"] = float(torch.mean(reconstruction_errors))\n        \n        # Pattern metrics\n        pattern_probs = torch.softmax(patterns, dim=1)\n        metrics[\"pattern_confidence\"] = float(torch.mean(torch.max(pattern_probs, dim=1)[0]))\n        \n        return metrics\n        \n    def _convert_patterns(self,\n                        patterns: torch.Tensor,\n                        attention_weights: torch.Tensor) -> List[Dict[str, Any]]:\n        \"\"\"Convert pattern outputs to interpretable format\"\"\"\n        pattern_types = [\"stable\", \"increasing\", \"decreasing\"]\n        pattern_probs = torch.softmax(patterns, dim=1)\n        \n        converted_patterns = []\n        for i in range(patterns.size(0)):\n            pattern_type = pattern_types[torch.argmax(pattern_probs[i]).item()]\n            confidence = float(torch.max(pattern_probs[i]))\n            \n            converted_patterns.append({\n                \"type\": pattern_type,\n                \"confidence\": confidence,\n                \"attention_weights\": attention_weights[i].detach().cpu().numpy().tolist(),\n                \"strength\": float(torch.norm(patterns[i]))\n            })\n            \n        return converted_patterns"}
{"type": "source_file", "path": "minesight/api/main.py", "content": "from fastapi import FastAPI, HTTPException, UploadFile, File, Query\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import FileResponse\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict, Optional, Any, Union\nimport numpy as np\nfrom minesight.core.models.base_model import BaseMineralModel\nfrom minesight.core.data.mineral_data import MineralDataset\nfrom minesight.visualization.map_visualizer import MapVisualizer\nfrom minesight.core.analysis.feature_analyzer import FeatureAnalyzer\nfrom minesight.core.analysis.risk_analyzer import RiskAnalyzer\nfrom minesight.core.analysis.time_series_analyzer import TimeSeriesAnalyzer\nfrom minesight.core.reporting.report_generator import ReportGenerator\nfrom minesight.core.data.exporter import DataExporter\nfrom minesight.core.data.importer import DataImporter\nfrom enum import Enum\nimport uvicorn\nfrom pathlib import Path\nfrom datetime import datetime\nfrom minesight.core.validation.data_validator import DataValidator\nimport rasterio\nimport pandas as pd\nfrom minesight.core.planning.exploration_planner import ExplorationPlanner\nfrom minesight.core.monitoring.monitor import MonitoringSystem, AlertLevel\nfrom minesight.core.dashboard.dashboard import Dashboard\nfrom minesight.core.ai.deep_learning import DeepLearningAnalyzer\nfrom minesight.core.ai.model import MineralExplorationModel\nfrom minesight.core.streaming.processor import DataStreamHandler\nimport asyncio\nfrom fastapi import WebSocket\nfrom fastapi import WebSocketDisconnect\nfrom minesight.core.recommendation.recommender import RecommendationEngine\nfrom minesight.core.quality.data_quality_monitor import DataQualityMonitor\nfrom minesight.core.anomaly.anomaly_detector import AnomalyDetector\nfrom minesight.core.recommendation.smart_recommender import SmartRecommender, ExplorationRecommendation\nfrom minesight.core.optimization.resource_optimizer import ResourceOptimizer, ResourceMetrics, OptimizationResult\nfrom minesight.core.optimization.process_optimizer import ProcessOptimizer, ProcessMetrics, OptimizationResult\nfrom minesight.core.quality.smart_quality_monitor import SmartQualityMonitor\nfrom minesight.core.optimization.smart_process_optimizer import SmartProcessOptimizer, ProcessPattern\nfrom minesight.core.optimization.smart_process_analyzer import SmartProcessAnalyzer, ProcessAnalysisMetrics\nfrom minesight.core.optimization.smart_process_monitor import SmartProcessMonitor, MonitoringConfig, ProcessState\nfrom minesight.core.optimization.deep_process_analyzer import DeepProcessAnalyzer, DeepProcessMetrics\n\napp = FastAPI(\n    title=\"MineSight API\",\n    description=\"AI-Powered Mineral Exploration Platform API\",\n    version=\"0.1.0\"\n)\n\n# Enable CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Initialize components\nmodel = BaseMineralModel()\ndataset = MineralDataset()\nvisualizer = MapVisualizer()\nanalyzer = FeatureAnalyzer()\nrisk_analyzer = RiskAnalyzer()\ntime_analyzer = TimeSeriesAnalyzer()\nexporter = DataExporter()\ndata_importer = DataImporter()\ndata_validator = DataValidator()\nplanner = ExplorationPlanner()\n\n# Initialize resource optimizer\nresource_optimizer = ResourceOptimizer()\n\n# Initialize process optimizer\nprocess_optimizer = SmartProcessOptimizer()\n\n# Initialize smart quality monitor\nquality_monitor = SmartQualityMonitor()\n\n# Initialize smart process components\nprocess_analyzer = SmartProcessAnalyzer()\nprocess_monitor = SmartProcessMonitor(\n    MonitoringConfig(\n        metrics_thresholds={\n            \"efficiency\": 0.8,\n            \"cost_effectiveness\": 0.7,\n            \"resource_utilization\": 0.75,\n            \"exploration_coverage\": 0.8,\n            \"success_rate\": 0.7,\n            \"risk_score\": 0.3\n        },\n        alert_thresholds={\n            \"efficiency\": 0.2,\n            \"cost_effectiveness\": 0.2,\n            \"resource_utilization\": 0.2,\n            \"exploration_coverage\": 0.2,\n            \"success_rate\": 0.2,\n            \"risk_score\": 0.2\n        },\n        monitoring_interval=60,  # 1 minute\n        optimization_interval=3600,  # 1 hour\n        max_deviation_tolerance=0.1,\n        min_confidence_threshold=0.7\n    )\n)\n\n# Load existing data\ntry:\n    dataset.load_data()\nexcept Exception as e:\n    print(f\"Warning: Could not load existing data: {str(e)}\")\n\n# Initialize monitoring system\nmonitoring_system = MonitoringSystem()\n\n# Initialize stream handler\nstream_handler = DataStreamHandler()\n\n# Initialize recommendation engine\nrecommendation_engine = RecommendationEngine()\n\n# Initialize anomaly detector\nanomaly_detector = AnomalyDetector()\n\n# Initialize smart recommender\nsmart_recommender = SmartRecommender()\n\n# Initialize deep process analyzer\ndeep_analyzer = DeepProcessAnalyzer(input_size=64)\n\nclass PredictionRequest(BaseModel):\n    \"\"\"\n    Request model for mineral prediction\n    \"\"\"\n    latitude: float = Field(..., ge=-90, le=90, description=\"Latitude in decimal degrees\")\n    longitude: float = Field(..., ge=-180, le=180, description=\"Longitude in decimal degrees\")\n    radius_km: float = Field(..., gt=0, le=100, description=\"Search radius in kilometers\")\n    rock_type: Optional[str] = Field(None, description=\"Type of rock formation\")\n    geological_age: Optional[str] = Field(None, description=\"Geological age of the formation\")\n    elevation: Optional[float] = Field(None, description=\"Elevation in meters\")\n\nclass PredictionResponse(BaseModel):\n    \"\"\"\n    Response model for mineral prediction\n    \"\"\"\n    location: Dict[str, float]\n    probability: float\n    confidence: float\n    features_used: List[str]\n    feature_importance: Dict[str, float]\n    recommendations: List[str]\n\nclass DepositData(BaseModel):\n    \"\"\"\n    Model for mineral deposit data\n    \"\"\"\n    latitude: float = Field(..., ge=-90, le=90)\n    longitude: float = Field(..., ge=-180, le=180)\n    mineral_type: str\n    is_confirmed: bool\n    properties: Optional[Dict] = None\n\nclass GeologicalFeature(BaseModel):\n    \"\"\"\n    Model for geological feature data\n    \"\"\"\n    latitude: float = Field(..., ge=-90, le=90)\n    longitude: float = Field(..., ge=-180, le=180)\n    feature_type: str\n    properties: Dict\n\nclass TrainingResponse(BaseModel):\n    \"\"\"\n    Response model for training operations\n    \"\"\"\n    success: bool\n    message: str\n    metrics: Optional[Dict[str, float]] = None\n\nclass VisualizationRequest(BaseModel):\n    \"\"\"\n    Request model for visualization\n    \"\"\"\n    latitude: float = Field(..., ge=-90, le=90, description=\"Center latitude\")\n    longitude: float = Field(..., ge=-180, le=180, description=\"Center longitude\")\n    radius_km: float = Field(..., gt=0, le=100, description=\"Search radius in kilometers\")\n    include_predictions: bool = Field(False, description=\"Whether to include prediction heatmap\")\n\nclass VisualizationResponse(BaseModel):\n    \"\"\"\n    Response model for visualization\n    \"\"\"\n    map_url: str\n    features_included: List[str]\n    center: Dict[str, float]\n    data_points: Dict[str, int]\n\nclass AnalysisRequest(BaseModel):\n    \"\"\"\n    Request model for feature analysis\n    \"\"\"\n    feature_type: Optional[str] = Field(None, description=\"Specific feature type to analyze\")\n    radius_km: float = Field(5.0, gt=0, le=100, description=\"Analysis radius in kilometers\")\n    min_samples: int = Field(3, ge=2, le=10, description=\"Minimum samples for clustering\")\n    eps_km: float = Field(2.0, gt=0, le=10, description=\"Maximum distance between samples in cluster\")\n\nclass AnalysisResponse(BaseModel):\n    \"\"\"\n    Response model for feature analysis\n    \"\"\"\n    density_metrics: Dict[str, float]\n    cluster_analysis: Dict[str, Any]\n    correlation_metrics: Dict[str, float]\n\nclass RiskAssessmentRequest(BaseModel):\n    \"\"\"\n    Request model for risk assessment\n    \"\"\"\n    latitude: float = Field(..., ge=-90, le=90, description=\"Site latitude\")\n    longitude: float = Field(..., ge=-180, le=180, description=\"Site longitude\")\n    properties: Optional[Dict[str, Any]] = Field(None, description=\"Additional site properties\")\n\nclass RiskAssessmentResponse(BaseModel):\n    \"\"\"\n    Response model for risk assessment\n    \"\"\"\n    overall_risk: float\n    geological_risk: float\n    environmental_risk: float\n    technical_risk: float\n    economic_risk: float\n    recommendations: List[str]\n\nclass TimeSeriesRequest(BaseModel):\n    \"\"\"\n    Request model for time series analysis\n    \"\"\"\n    window_days: int = Field(30, gt=0, le=365, description=\"Analysis window size in days\")\n    forecast_days: int = Field(90, gt=0, le=365, description=\"Number of days to forecast\")\n\nclass TimeSeriesResponse(BaseModel):\n    \"\"\"\n    Response model for time series analysis\n    \"\"\"\n    discovery_trends: Dict[str, Any]\n    feature_evolution: Dict[str, Any]\n    exploration_intensity: Dict[str, Any]\n    recommendations: List[str]\n\nclass ReportRequest(BaseModel):\n    \"\"\"\n    Request model for report generation\n    \"\"\"\n    latitude: float = Field(..., ge=-90, le=90, description=\"Site latitude\")\n    longitude: float = Field(..., ge=-180, le=180, description=\"Site longitude\")\n    include_visualizations: bool = Field(True, description=\"Whether to include visualizations\")\n    site_properties: Optional[Dict[str, Any]] = Field(None, description=\"Additional site properties\")\n\nclass ReportResponse(BaseModel):\n    \"\"\"\n    Response model for report generation\n    \"\"\"\n    report_path: str\n    summary: Dict[str, Any]\n\nclass ExportRequest(BaseModel):\n    \"\"\"\n    Request model for data export\n    \"\"\"\n    format: str = Field(\"json\", description=\"Export format (json, csv, excel)\")\n    filename: Optional[str] = Field(None, description=\"Optional custom filename\")\n\nclass ExportResponse(BaseModel):\n    \"\"\"\n    Response model for data export\n    \"\"\"\n    file_path: str\n    format: str\n    download_url: str\n\nclass DataType(str, Enum):\n    deposits = \"deposits\"\n    features = \"features\"\n    samples = \"samples\"\n\nclass ImportResponse(BaseModel):\n    file_path: str\n    data_type: str\n    row_count: int\n    columns: List[str]\n    preview: List[Dict[str, Any]]\n\nclass ValidationResponse(BaseModel):\n    \"\"\"\n    Response model for data validation\n    \"\"\"\n    is_valid: bool\n    errors: List[str]\n    warnings: List[str]\n    stats: Dict[str, Any]\n\nclass ValidationReportResponse(BaseModel):\n    \"\"\"\n    Response model for validation report\n    \"\"\"\n    report_path: str\n    summary: Dict[str, Any]\n\nclass PlanningRequest(BaseModel):\n    \"\"\"\n    Request model for exploration planning\n    \"\"\"\n    region: Dict[str, float]\n    available_resources: Dict[str, Any]\n    constraints: Optional[Dict[str, Any]] = None\n\nclass PlanningResponse(BaseModel):\n    \"\"\"\n    Response model for exploration planning\n    \"\"\"\n    tasks: List[Dict[str, Any]]\n    schedule: Dict[str, Any]\n    resource_allocation: Dict[str, List[str]]\n    costs: Dict[str, float]\n    timeline: List[Dict[str, Any]]\n\nclass DeepLearningRequest(BaseModel):\n    \"\"\"\n    Request model for deep learning analysis\n    \"\"\"\n    region: Dict[str, float] = Field(..., description=\"Region bounds for analysis\")\n    analysis_type: str = Field(..., description=\"Type of analysis to perform\")\n    model_params: Optional[Dict[str, Any]] = Field(None, description=\"Optional model parameters\")\n    data_filters: Optional[Dict[str, Any]] = Field(None, description=\"Optional data filters\")\n\nclass DeepLearningResponse(BaseModel):\n    \"\"\"\n    Response model for deep learning analysis\n    \"\"\"\n    analysis_results: Dict[str, Any]\n    model_metrics: Dict[str, float]\n    feature_importance: Dict[str, float]\n    predictions: List[Dict[str, Any]]\n    visualizations: Dict[str, str]\n\nclass Visualization3DRequest(BaseModel):\n    \"\"\"\n    Request model for 3D visualization\n    \"\"\"\n    visualization_type: str = Field(..., description=\"Type of visualization to create\")\n    region: Dict[str, float] = Field(..., description=\"Region bounds for visualization\")\n    include_dem: bool = Field(True, description=\"Whether to include terrain data\")\n    data_filters: Optional[Dict[str, Any]] = Field(None, description=\"Optional data filters\")\n    analysis_results: Optional[Dict[str, Any]] = Field(None, description=\"Optional analysis results\")\n    time_data: Optional[Dict[str, Any]] = Field(None, description=\"Optional time series data\")\n\nclass Visualization3DResponse(BaseModel):\n    \"\"\"\n    Response model for 3D visualization\n    \"\"\"\n    visualization_url: str\n    data_summary: Dict[str, Any]\n\nclass StreamRequest(BaseModel):\n    \"\"\"\n    Request model for stream operations\n    \"\"\"\n    stream_type: str = Field(..., description=\"Type of data stream\")\n    operation: str = Field(..., description=\"Operation to perform\")\n    data: Optional[Dict[str, Any]] = Field(None, description=\"Data for the operation\")\n    parameters: Optional[Dict[str, Any]] = Field(None, description=\"Operation parameters\")\n\nclass StreamResponse(BaseModel):\n    \"\"\"\n    Response model for stream operations\n    \"\"\"\n    success: bool\n    message: str\n    data: Optional[Dict[str, Any]] = None\n\nclass RecommendationRequest(BaseModel):\n    \"\"\"\n    Request model for recommendations\n    \"\"\"\n    region: Dict[str, float] = Field(..., description=\"Region bounds for recommendations\")\n    resource_data: Dict[str, Any] = Field(..., description=\"Available resource data\")\n    include_historical: bool = Field(False, description=\"Whether to include historical data\")\n\nclass RecommendationResponse(BaseModel):\n    \"\"\"\n    Response model for recommendations\n    \"\"\"\n    exploration_targets: List[Dict[str, Any]]\n    resource_allocation: List[Dict[str, Any]]\n    exploration_strategy: List[Dict[str, Any]]\n    optimal_timing: List[Dict[str, Any]]\n    summary: Dict[str, Any]\n\nclass QualityCheckRequest(BaseModel):\n    \"\"\"\n    Request model for data quality check\n    \"\"\"\n    data: Union[Dict[str, Any], List[Dict[str, Any]]]\n    data_type: str = Field(..., description=\"Type of data to check\")\n\nclass QualityCheckResponse(BaseModel):\n    \"\"\"\n    Response model for data quality check\n    \"\"\"\n    timestamp: str\n    data_type: str\n    metrics: Dict[str, float]\n    issues: List[str]\n    recommendations: List[str]\n\nclass QualityReportRequest(BaseModel):\n    \"\"\"\n    Request model for quality report generation\n    \"\"\"\n    start_time: Optional[datetime] = Field(None, description=\"Start time for report period\")\n    end_time: Optional[datetime] = Field(None, description=\"End time for report period\")\n\nclass QualityReportResponse(BaseModel):\n    \"\"\"\n    Response model for quality report\n    \"\"\"\n    generated_at: str\n    period: Dict[str, Optional[str]]\n    summary: Dict[str, Any]\n    trends: Dict[str, Any]\n    alerts: List[Dict[str, Any]]\n    recommendations: List[str]\n    visualizations: Dict[str, Any]\n\nclass AnomalyDetectionRequest(BaseModel):\n    \"\"\"\n    Request model for anomaly detection\n    \"\"\"\n    data: Union[Dict[str, Any], List[Dict[str, Any]]]\n    config: Optional[Dict[str, Any]] = None\n\nclass AnomalyDetectionResponse(BaseModel):\n    \"\"\"\n    Response model for anomaly detection\n    \"\"\"\n    anomalies: List[Dict[str, Any]]\n    analysis: Dict[str, Any]\n    report_url: Optional[str] = None\n\nclass SmartRecommendationRequest(BaseModel):\n    \"\"\"\n    Request model for smart recommendations\n    \"\"\"\n    exploration_data: Dict[str, Any] = Field(..., description=\"Current exploration data\")\n    historical_data: Dict[str, Any] = Field(..., description=\"Historical exploration data\")\n    current_state: Dict[str, Any] = Field(..., description=\"Current system state\")\n\nclass SmartRecommendationResponse(BaseModel):\n    \"\"\"\n    Response model for smart recommendations\n    \"\"\"\n    recommendations: List[Dict[str, Any]]\n    impact_analysis: Dict[str, Any]\n    confidence_metrics: Dict[str, float]\n\nclass ResourceOptimizationRequest(BaseModel):\n    \"\"\"\n    Request model for resource optimization\n    \"\"\"\n    current_resources: Dict[str, Any]\n    activities: List[Dict[str, Any]]\n    constraints: Optional[Dict[str, Any]] = None\n\nclass ResourceOptimizationResponse(BaseModel):\n    \"\"\"\n    Response model for resource optimization\n    \"\"\"\n    results: List[Dict[str, Any]]\n    improvements: Dict[str, Dict[str, float]]\n    recommendations: List[str]\n    confidence: float\n\nclass EfficiencyAnalysisRequest(BaseModel):\n    \"\"\"\n    Request model for efficiency analysis\n    \"\"\"\n    resource_data: Dict[str, Any]\n    time_period: str = \"30d\"\n\nclass EfficiencyAnalysisResponse(BaseModel):\n    \"\"\"\n    Response model for efficiency analysis\n    \"\"\"\n    efficiency_metrics: Dict[str, Dict[str, float]]\n    utilization_patterns: Dict[str, Any]\n    cost_analysis: Dict[str, Any]\n    optimization_opportunities: List[Dict[str, Any]]\n\nclass ResourcePredictionRequest(BaseModel):\n    \"\"\"\n    Request model for resource prediction\n    \"\"\"\n    historical_data: Dict[str, Any]\n    future_activities: List[Dict[str, Any]]\n    prediction_horizon: int = 30\n\nclass ResourcePredictionResponse(BaseModel):\n    \"\"\"\n    Response model for resource prediction\n    \"\"\"\n    resource_demands: Dict[str, List[float]]\n    capacity_requirements: Dict[str, Dict[str, float]]\n    risk_factors: Dict[str, Dict[str, float]]\n    recommendations: List[Dict[str, Any]]\n\nclass ResourceMonitoringRequest(BaseModel):\n    \"\"\"\n    Request model for resource monitoring\n    \"\"\"\n    current_state: Dict[str, Any]\n    optimal_allocation: Dict[str, Any]\n    thresholds: Optional[Dict[str, float]] = None\n\nclass ResourceMonitoringResponse(BaseModel):\n    \"\"\"\n    Response model for resource monitoring\n    \"\"\"\n    status: str\n    deviations: Dict[str, Any]\n    adjustments: Dict[str, Any]\n    alerts: List[Dict[str, Any]]\n\nclass ProcessOptimizationRequest(BaseModel):\n    \"\"\"\n    Request model for process optimization\n    \"\"\"\n    current_state: Dict[str, Any]\n    resources: Dict[str, Any]\n    activities: List[Dict[str, Any]]\n    constraints: Optional[Dict[str, Any]] = None\n\nclass ProcessOptimizationResponse(BaseModel):\n    \"\"\"\n    Response model for process optimization\n    \"\"\"\n    results: List[Dict[str, Any]]\n    improvements: Dict[str, Dict[str, float]]\n    recommendations: List[str]\n    confidence: float\n\nclass ProcessEfficiencyRequest(BaseModel):\n    \"\"\"\n    Request model for process efficiency analysis\n    \"\"\"\n    process_data: Dict[str, Any]\n    time_period: str = \"30d\"\n\nclass ProcessEfficiencyResponse(BaseModel):\n    \"\"\"\n    Response model for process efficiency analysis\n    \"\"\"\n    efficiency_metrics: Dict[str, Dict[str, float]]\n    performance_patterns: Dict[str, Any]\n    cost_analysis: Dict[str, Any]\n    optimization_opportunities: List[Dict[str, Any]]\n\nclass ProcessPredictionRequest(BaseModel):\n    \"\"\"\n    Request model for process performance prediction\n    \"\"\"\n    historical_data: Dict[str, Any]\n    future_activities: List[Dict[str, Any]]\n    prediction_horizon: int = 30\n\nclass ProcessPredictionResponse(BaseModel):\n    \"\"\"\n    Response model for process performance prediction\n    \"\"\"\n    performance_metrics: Dict[str, Dict[str, float]]\n    resource_requirements: Dict[str, Dict[str, float]]\n    risk_factors: Dict[str, Dict[str, float]]\n    recommendations: List[Dict[str, Any]]\n\nclass ProcessMonitoringRequest(BaseModel):\n    \"\"\"\n    Request model for process monitoring\n    \"\"\"\n    current_state: Dict[str, Any]\n    optimal_config: Dict[str, Any]\n    thresholds: Optional[Dict[str, float]] = None\n\nclass ProcessMonitoringResponse(BaseModel):\n    \"\"\"\n    Response model for process monitoring\n    \"\"\"\n    status: str\n    deviations: Dict[str, Any]\n    adjustments: Dict[str, Any]\n    alerts: List[Dict[str, Any]]\n\nclass SmartQualityCheckRequest(BaseModel):\n    \"\"\"\n    Request model for smart quality check\n    \"\"\"\n    data: Union[Dict[str, Any], List[Dict[str, Any]]]\n    data_type: str = Field(..., description=\"Type of data to check\")\n    analyze_patterns: bool = Field(True, description=\"Whether to analyze quality patterns\")\n\nclass SmartQualityCheckResponse(BaseModel):\n    \"\"\"\n    Response model for smart quality check\n    \"\"\"\n    timestamp: str\n    data_type: str\n    metrics: Dict[str, float]\n    patterns: Optional[List[Dict[str, Any]]] = None\n    issues: List[str]\n    recommendations: List[str]\n\nclass SmartQualityReportRequest(BaseModel):\n    \"\"\"\n    Request model for smart quality report\n    \"\"\"\n    start_time: Optional[datetime] = Field(None, description=\"Start time for report period\")\n    end_time: Optional[datetime] = Field(None, description=\"End time for report period\")\n    include_patterns: bool = Field(True, description=\"Whether to include pattern analysis\")\n    include_impact: bool = Field(True, description=\"Whether to include impact analysis\")\n\nclass SmartQualityReportResponse(BaseModel):\n    \"\"\"\n    Response model for smart quality report\n    \"\"\"\n    generated_at: str\n    period: Dict[str, Optional[str]]\n    summary: Dict[str, Any]\n    trends: Dict[str, Any]\n    patterns: Optional[Dict[str, Any]] = None\n    impact_analysis: Optional[Dict[str, Any]] = None\n    alerts: List[Dict[str, Any]]\n    recommendations: List[str]\n    visualizations: Dict[str, Any]\n\nclass QualityInsightsResponse(BaseModel):\n    \"\"\"\n    Response model for quality insights\n    \"\"\"\n    timestamp: str\n    summary: Dict[str, Any]\n    trend_analysis: Dict[str, Any]\n    pattern_analysis: Dict[str, Any]\n    impact_analysis: Dict[str, Any]\n    recommendations: List[str]\n\nclass SmartProcessOptimizationRequest(BaseModel):\n    \"\"\"\n    Request model for smart process optimization\n    \"\"\"\n    current_state: Dict[str, Any]\n    resources: Dict[str, Any]\n    activities: List[Dict[str, Any]]\n    constraints: Optional[Dict[str, Any]] = None\n    analyze_patterns: bool = Field(True, description=\"Whether to analyze process patterns\")\n\nclass SmartProcessOptimizationResponse(BaseModel):\n    \"\"\"\n    Response model for smart process optimization\n    \"\"\"\n    results: List[Dict[str, Any]]\n    improvements: Dict[str, Dict[str, float]]\n    patterns: Optional[List[Dict[str, Any]]] = None\n    recommendations: List[str]\n    confidence: float\n\nclass ProcessPatternResponse(BaseModel):\n    \"\"\"\n    Response model for process patterns\n    \"\"\"\n    patterns: List[Dict[str, Any]]\n    trend_analysis: Dict[str, Any]\n    impact_analysis: Dict[str, Any]\n    recommendations: List[str]\n\nclass ProcessAnalysisRequest(BaseModel):\n    \"\"\"\n    Request model for process analysis\n    \"\"\"\n    process_id: str\n    process_data: Dict[str, Any]\n    historical_data: Optional[Dict[str, Any]] = None\n\nclass ProcessAnalysisResponse(BaseModel):\n    \"\"\"\n    Response model for process analysis\n    \"\"\"\n    process_id: str\n    timestamp: str\n    metrics: Dict[str, float]\n    optimization_potential: float\n    bottleneck_impact: float\n    pattern_significance: float\n    anomaly_severity: float\n    recommendations: List[str]\n\nclass ProcessMonitoringRequest(BaseModel):\n    \"\"\"\n    Request model for process monitoring\n    \"\"\"\n    process_id: str\n    process_data: Dict[str, Any]\n    monitoring_config: Optional[Dict[str, Any]] = None\n\nclass ProcessMonitoringResponse(BaseModel):\n    \"\"\"\n    Response model for process monitoring\n    \"\"\"\n    process_id: str\n    timestamp: str\n    status: str\n    metrics: Dict[str, float]\n    deviations: Dict[str, float]\n    alerts: List[Dict[str, Any]]\n    optimization_status: str\n    recommendations: List[str]\n\nclass ProcessPredictionRequest(BaseModel):\n    \"\"\"\n    Request model for process prediction\n    \"\"\"\n    process_id: str\n    horizon: int = 10\n\nclass ProcessPredictionResponse(BaseModel):\n    \"\"\"\n    Response model for process prediction\n    \"\"\"\n    process_id: str\n    timestamp: str\n    predictions: List[Dict[str, float]]\n    confidence: float\n\nclass DeepProcessAnalysisRequest(BaseModel):\n    \"\"\"\n    Request model for deep process analysis\n    \"\"\"\n    process_data: Dict[str, Any]\n    historical_data: Optional[List[Dict[str, Any]]] = None\n    analyze_patterns: bool = Field(True, description=\"Whether to analyze patterns\")\n    analyze_bottlenecks: bool = Field(True, description=\"Whether to analyze bottlenecks\")\n    predict_optimization: bool = Field(True, description=\"Whether to predict optimization impact\")\n\nclass DeepProcessAnalysisResponse(BaseModel):\n    \"\"\"\n    Response model for deep process analysis\n    \"\"\"\n    timestamp: str\n    metrics: Dict[str, float]\n    patterns: Optional[List[Dict[str, Any]]] = None\n    bottlenecks: Optional[List[Dict[str, Any]]] = None\n    optimization_predictions: Optional[Dict[str, float]] = None\n    recommendations: List[str]\n\nclass OptimizationImpactRequest(BaseModel):\n    \"\"\"\n    Request model for optimization impact prediction\n    \"\"\"\n    current_state: Dict[str, Any]\n    proposed_changes: Dict[str, Any]\n\nclass OptimizationImpactResponse(BaseModel):\n    \"\"\"\n    Response model for optimization impact prediction\n    \"\"\"\n    improvements: Dict[str, float]\n    confidence: float\n    recommendations: List[str]\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"API root endpoint\"\"\"\n    return {\n        \"status\": \"online\",\n        \"version\": \"0.1.0\",\n        \"docs_url\": \"/docs\"\n    }\n\n@app.post(\"/api/v1/predict\", response_model=PredictionResponse)\nasync def predict_minerals(request: PredictionRequest):\n    \"\"\"\n    Predict mineral deposits at specified location\n    \"\"\"\n    try:\n        # Prepare features\n        features = {\n            \"latitude\": request.latitude,\n            \"longitude\": request.longitude,\n            \"elevation\": request.elevation or 0,\n            \"rock_type\": request.rock_type or \"unknown\",\n            \"geological_age\": request.geological_age or \"unknown\"\n        }\n        \n        # Make prediction\n        probability, confidence = model.predict(features)\n        \n        # Get feature importance\n        importance = model.get_feature_importance()\n        \n        # Generate recommendations based on prediction\n        recommendations = []\n        if probability > 0.7:\n            recommendations.append(f\"High mineral potential ({probability:.1%} probability)\")\n            recommendations.append(\"Recommended for detailed geological survey\")\n        elif probability > 0.4:\n            recommendations.append(f\"Moderate mineral potential ({probability:.1%} probability)\")\n            recommendations.append(\"Consider preliminary survey\")\n        else:\n            recommendations.append(f\"Low mineral potential ({probability:.1%} probability)\")\n            recommendations.append(\"Not recommended for further exploration\")\n            \n        if confidence < 0.5:\n            recommendations.append(\"Low confidence prediction - more data needed\")\n\n        return PredictionResponse(\n            location={\n                \"latitude\": request.latitude,\n                \"longitude\": request.longitude,\n                \"radius_km\": request.radius_km\n            },\n            probability=float(probability),\n            confidence=float(confidence),\n            features_used=list(features.keys()),\n            feature_importance=importance,\n            recommendations=recommendations\n        )\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/deposits\", response_model=TrainingResponse)\nasync def add_deposit(deposit: DepositData):\n    \"\"\"\n    Add a mineral deposit to the dataset\n    \"\"\"\n    try:\n        success = dataset.add_deposit(\n            latitude=deposit.latitude,\n            longitude=deposit.longitude,\n            mineral_type=deposit.mineral_type,\n            is_confirmed=deposit.is_confirmed,\n            properties=deposit.properties\n        )\n        \n        if success:\n            # Save updated data\n            dataset.save_data()\n            return TrainingResponse(\n                success=True,\n                message=\"Deposit added successfully\"\n            )\n        else:\n            raise HTTPException(status_code=500, detail=\"Failed to add deposit\")\n            \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/geological-features\", response_model=TrainingResponse)\nasync def add_geological_feature(feature: GeologicalFeature):\n    \"\"\"\n    Add a geological feature to the dataset\n    \"\"\"\n    try:\n        success = dataset.add_geological_feature(\n            latitude=feature.latitude,\n            longitude=feature.longitude,\n            feature_type=feature.feature_type,\n            properties=feature.properties\n        )\n        \n        if success:\n            # Save updated data\n            dataset.save_data()\n            return TrainingResponse(\n                success=True,\n                message=\"Geological feature added successfully\"\n            )\n        else:\n            raise HTTPException(status_code=500, detail=\"Failed to add geological feature\")\n            \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/train\", response_model=TrainingResponse)\nasync def train_model():\n    \"\"\"\n    Train the model using current dataset\n    \"\"\"\n    try:\n        # Prepare training data\n        X, y = dataset.prepare_training_data()\n        \n        # Train model\n        model.train(X, y)\n        \n        # Get basic metrics\n        importance = model.get_feature_importance()\n        \n        return TrainingResponse(\n            success=True,\n            message=\"Model trained successfully\",\n            metrics={\n                \"training_samples\": len(y),\n                \"positive_samples\": int(sum(y)),\n                \"feature_importance\": importance\n            }\n        )\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/visualize\", response_model=VisualizationResponse)\nasync def create_visualization(request: VisualizationRequest):\n    \"\"\"\n    Create interactive visualization of the area\n    \"\"\"\n    try:\n        # Get nearby data\n        deposits = dataset.get_nearby_deposits(\n            request.latitude,\n            request.longitude,\n            request.radius_km\n        )\n        \n        geological_features = dataset.get_nearby_features(\n            request.latitude,\n            request.longitude,\n            request.radius_km\n        )\n        \n        # Generate predictions if requested\n        predictions = None\n        if request.include_predictions:\n            # Create a grid of points\n            lat_range = np.linspace(\n                request.latitude - 0.1,\n                request.latitude + 0.1,\n                20\n            )\n            lon_range = np.linspace(\n                request.longitude - 0.1,\n                request.longitude + 0.1,\n                20\n            )\n            \n            predictions = []\n            for lat in lat_range:\n                for lon in lon_range:\n                    features = {\n                        \"latitude\": float(lat),\n                        \"longitude\": float(lon),\n                        \"elevation\": 0,\n                        \"rock_type\": \"unknown\",\n                        \"geological_age\": \"unknown\"\n                    }\n                    \n                    probability, confidence = model.predict(features)\n                    \n                    predictions.append({\n                        \"location\": {\n                            \"latitude\": float(lat),\n                            \"longitude\": float(lon)\n                        },\n                        \"probability\": float(probability),\n                        \"confidence\": float(confidence)\n                    })\n        \n        # Create visualization\n        map_file = visualizer.create_exploration_map(\n            center_lat=request.latitude,\n            center_lon=request.longitude,\n            deposits=deposits,\n            geological_features=geological_features,\n            predictions=predictions,\n            radius_km=request.radius_km\n        )\n        \n        # Get relative path for URL\n        map_url = f\"/visualizations/{map_file.split('/')[-1]}\"\n        \n        return VisualizationResponse(\n            map_url=map_url,\n            features_included=[\n                \"deposits\" if not deposits.empty else None,\n                \"geological_features\" if not geological_features.empty else None,\n                \"predictions\" if predictions else None\n            ],\n            center={\n                \"latitude\": request.latitude,\n                \"longitude\": request.longitude,\n                \"radius_km\": request.radius_km\n            },\n            data_points={\n                \"deposits\": len(deposits),\n                \"geological_features\": len(geological_features),\n                \"predictions\": len(predictions) if predictions else 0\n            }\n        )\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/visualizations/{filename}\")\nasync def get_visualization(filename: str):\n    \"\"\"\n    Serve visualization files\n    \"\"\"\n    try:\n        file_path = visualizer.output_dir / filename\n        if not file_path.exists():\n            raise HTTPException(status_code=404, detail=\"Visualization not found\")\n            \n        return FileResponse(str(file_path))\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/analyze\", response_model=AnalysisResponse)\nasync def analyze_features(request: AnalysisRequest):\n    \"\"\"\n    Analyze geological features and their relationships with deposits\n    \"\"\"\n    try:\n        # Get all features and deposits\n        features = dataset.get_all_features()\n        deposits = dataset.get_all_deposits()\n        \n        if features.empty:\n            raise HTTPException(\n                status_code=400,\n                detail=\"No geological features available for analysis\"\n            )\n        \n        # Analyze feature density\n        density_metrics = analyzer.analyze_feature_density(\n            features,\n            feature_type=request.feature_type,\n            radius_km=request.radius_km\n        )\n        \n        # Analyze feature clusters\n        cluster_analysis = analyzer.analyze_feature_clusters(\n            features,\n            min_samples=request.min_samples,\n            eps_km=request.eps_km\n        )\n        \n        # Analyze correlation with deposits\n        correlation_metrics = analyzer.analyze_deposit_correlation(\n            features,\n            deposits,\n            radius_km=request.radius_km\n        )\n        \n        return AnalysisResponse(\n            density_metrics=density_metrics,\n            cluster_analysis=cluster_analysis,\n            correlation_metrics=correlation_metrics\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/assess-risks\", response_model=RiskAssessmentResponse)\nasync def assess_site_risks(request: RiskAssessmentRequest):\n    \"\"\"\n    Assess various risks for a potential mining site\n    \"\"\"\n    try:\n        # Get geological features and deposits\n        features = dataset.get_all_features()\n        deposits = dataset.get_all_deposits()\n        \n        # Calculate risks\n        risks = risk_analyzer.analyze_site_risks(\n            latitude=request.latitude,\n            longitude=request.longitude,\n            geological_features=features,\n            deposits=deposits,\n            properties=request.properties\n        )\n        \n        # Generate recommendations based on risks\n        recommendations = []\n        \n        # Geological recommendations\n        if risks[\"geological_risk\"] > 0.7:\n            recommendations.append(\n                \"High geological risk - Detailed geological survey required\"\n            )\n        elif risks[\"geological_risk\"] > 0.4:\n            recommendations.append(\n                \"Moderate geological risk - Additional geological data recommended\"\n            )\n            \n        # Environmental recommendations\n        if risks[\"environmental_risk\"] > 0.7:\n            recommendations.append(\n                \"High environmental risk - Environmental impact study required\"\n            )\n        elif risks[\"environmental_risk\"] > 0.4:\n            recommendations.append(\n                \"Moderate environmental risk - Environmental assessment recommended\"\n            )\n            \n        # Technical recommendations\n        if risks[\"technical_risk\"] > 0.7:\n            recommendations.append(\n                \"High technical risk - Detailed feasibility study required\"\n            )\n        elif risks[\"technical_risk\"] > 0.4:\n            recommendations.append(\n                \"Moderate technical risk - Technical assessment recommended\"\n            )\n            \n        # Economic recommendations\n        if risks[\"economic_risk\"] > 0.7:\n            recommendations.append(\n                \"High economic risk - Detailed economic analysis required\"\n            )\n        elif risks[\"economic_risk\"] > 0.4:\n            recommendations.append(\n                \"Moderate economic risk - Economic assessment recommended\"\n            )\n            \n        # Overall recommendation\n        if risks[\"overall_risk\"] > 0.7:\n            recommendations.append(\n                \"High overall risk - Comprehensive risk mitigation required\"\n            )\n        elif risks[\"overall_risk\"] > 0.4:\n            recommendations.append(\n                \"Moderate overall risk - Risk assessment recommended\"\n            )\n        else:\n            recommendations.append(\n                \"Low overall risk - Standard monitoring recommended\"\n            )\n        \n        return RiskAssessmentResponse(\n            overall_risk=risks[\"overall_risk\"],\n            geological_risk=risks[\"geological_risk\"],\n            environmental_risk=risks[\"environmental_risk\"],\n            technical_risk=risks[\"technical_risk\"],\n            economic_risk=risks[\"economic_risk\"],\n            recommendations=recommendations\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/analyze-trends\", response_model=TimeSeriesResponse)\nasync def analyze_time_trends(request: TimeSeriesRequest):\n    \"\"\"\n    Analyze temporal trends in exploration data\n    \"\"\"\n    try:\n        # Get all data\n        deposits = dataset.get_all_deposits()\n        features = dataset.get_all_features()\n        \n        # Analyze discovery trends\n        discovery_trends = time_analyzer.analyze_discovery_trends(\n            deposits,\n            window_days=request.window_days\n        )\n        \n        # Analyze feature evolution\n        feature_evolution = time_analyzer.analyze_feature_evolution(\n            features,\n            window_days=request.window_days\n        )\n        \n        # Analyze exploration intensity\n        exploration_intensity = time_analyzer.analyze_exploration_intensity(\n            deposits,\n            features,\n            window_days=request.window_days\n        )\n        \n        # Generate recommendations based on analysis\n        recommendations = []\n        \n        # Discovery trend recommendations\n        if discovery_trends[\"trend_direction\"] == \"increasing\":\n            recommendations.append(\n                \"Discovery rate is increasing - Consider expanding exploration efforts\"\n            )\n        elif discovery_trends[\"trend_direction\"] == \"decreasing\":\n            recommendations.append(\n                \"Discovery rate is decreasing - Review exploration strategies\"\n            )\n            \n        # Seasonal recommendations\n        if discovery_trends[\"seasonal_pattern\"]:\n            peak_month = max(\n                discovery_trends[\"seasonal_pattern\"].items(),\n                key=lambda x: x[1]\n            )[0]\n            recommendations.append(\n                f\"Peak discovery season is month {peak_month} - Plan activities accordingly\"\n            )\n            \n        # Feature mapping recommendations\n        for feature_type, trend in feature_evolution[\"feature_type_trends\"].items():\n            if trend[\"trend_direction\"] == \"increasing\":\n                recommendations.append(\n                    f\"Increasing trend in {feature_type} mapping - Continue current approach\"\n                )\n            elif trend[\"trend_direction\"] == \"decreasing\":\n                recommendations.append(\n                    f\"Decreasing trend in {feature_type} mapping - Consider focused survey\"\n                )\n                \n        # Intensity recommendations\n        if exploration_intensity[\"intensity_trend\"] == \"increasing\":\n            recommendations.append(\n                \"Exploration activity is intensifying - Ensure resource availability\"\n            )\n        elif exploration_intensity[\"intensity_trend\"] == \"decreasing\":\n            recommendations.append(\n                \"Exploration activity is declining - Review resource allocation\"\n            )\n            \n        # Add forecast-based recommendations\n        if discovery_trends[\"forecast\"]:\n            last_forecast = discovery_trends[\"forecast\"][-1]\n            if last_forecast[\"predicted_discoveries\"] > discovery_trends[\"discovery_rate\"]:\n                recommendations.append(\n                    \"Positive growth forecast - Consider preparing for increased activity\"\n                )\n            else:\n                recommendations.append(\n                    \"Slower growth forecast - Focus on optimizing current operations\"\n                )\n        \n        return TimeSeriesResponse(\n            discovery_trends=discovery_trends,\n            feature_evolution=feature_evolution,\n            exploration_intensity=exploration_intensity,\n            recommendations=recommendations\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/generate-report\", response_model=ReportResponse)\nasync def generate_report(request: ReportRequest):\n    \"\"\"\n    Generate comprehensive exploration report\n    \"\"\"\n    try:\n        # Get site data\n        site_info = {\n            \"latitude\": request.latitude,\n            \"longitude\": request.longitude,\n            **(request.site_properties or {})\n        }\n        \n        # Get prediction results\n        features = {\n            \"latitude\": request.latitude,\n            \"longitude\": request.longitude,\n            \"elevation\": site_info.get(\"elevation\", 0),\n            \"rock_type\": site_info.get(\"rock_type\", \"unknown\"),\n            \"geological_age\": site_info.get(\"geological_age\", \"unknown\")\n        }\n        probability, confidence = model.predict(features)\n        \n        prediction_results = {\n            \"probability\": probability,\n            \"confidence\": confidence,\n            \"feature_importance\": model.get_feature_importance()\n        }\n        \n        # Get risk assessment\n        geological_features = dataset.get_all_features()\n        deposits = dataset.get_all_deposits()\n        \n        risks = risk_analyzer.analyze_site_risks(\n            latitude=request.latitude,\n            longitude=request.longitude,\n            geological_features=geological_features,\n            deposits=deposits,\n            properties=request.site_properties\n        )\n        \n        # Get feature analysis\n        feature_analysis = analyzer.analyze_feature_density(\n            geological_features,\n            radius_km=5.0\n        )\n        \n        cluster_analysis = analyzer.analyze_feature_clusters(\n            geological_features,\n            min_samples=3,\n            eps_km=2.0\n        )\n        \n        correlation_analysis = analyzer.analyze_deposit_correlation(\n            geological_features,\n            deposits,\n            radius_km=5.0\n        )\n        \n        feature_results = {\n            \"density_metrics\": feature_analysis,\n            \"cluster_analysis\": cluster_analysis,\n            \"correlation_metrics\": correlation_analysis\n        }\n        \n        # Get time series analysis\n        time_results = time_analyzer.analyze_discovery_trends(\n            deposits,\n            window_days=30\n        )\n        \n        # Generate report\n        report_generator = ReportGenerator()\n        report_path = report_generator.generate_exploration_report(\n            site_info=site_info,\n            prediction_results=prediction_results,\n            risk_assessment=risks,\n            feature_analysis=feature_results,\n            time_analysis=time_results,\n            include_visualizations=request.include_visualizations\n        )\n        \n        # Prepare summary\n        summary = {\n            \"mineral_probability\": float(probability),\n            \"confidence_level\": float(confidence),\n            \"overall_risk\": float(risks[\"overall_risk\"]),\n            \"total_features\": feature_analysis[\"total_features\"],\n            \"feature_clusters\": cluster_analysis[\"n_clusters\"]\n        }\n        \n        return ReportResponse(\n            report_path=report_path,\n            summary=summary\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/reports/{filename}\")\nasync def get_report(filename: str):\n    \"\"\"\n    Serve generated report files\n    \"\"\"\n    try:\n        report_dir = Path(\"reports\")\n        file_path = report_dir / filename\n        \n        if not file_path.exists():\n            raise HTTPException(status_code=404, detail=\"Report not found\")\n            \n        return FileResponse(\n            str(file_path),\n            media_type=\"application/pdf\",\n            filename=filename\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/export/predictions\", response_model=ExportResponse)\nasync def export_predictions(request: ExportRequest):\n    \"\"\"\n    Export prediction results\n    \"\"\"\n    try:\n        # Get all predictions from dataset\n        deposits = dataset.get_all_deposits()\n        predictions = []\n        \n        for _, deposit in deposits.iterrows():\n            features = {\n                \"latitude\": deposit[\"latitude\"],\n                \"longitude\": deposit[\"longitude\"]\n            }\n            probability, confidence = model.predict(features)\n            \n            predictions.append({\n                \"latitude\": deposit[\"latitude\"],\n                \"longitude\": deposit[\"longitude\"],\n                \"mineral_type\": deposit[\"mineral_type\"],\n                \"probability\": float(probability),\n                \"confidence\": float(confidence)\n            })\n        \n        # Export data\n        file_path = exporter.export_prediction_results(\n            predictions,\n            format=request.format,\n            filename=request.filename\n        )\n        \n        # Generate download URL\n        filename = Path(file_path).name\n        download_url = f\"/exports/{filename}\"\n        \n        return ExportResponse(\n            file_path=file_path,\n            format=request.format,\n            download_url=download_url\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/export/risks\", response_model=ExportResponse)\nasync def export_risks(request: ExportRequest):\n    \"\"\"\n    Export risk assessment results\n    \"\"\"\n    try:\n        # Get all deposits for risk analysis\n        deposits = dataset.get_all_deposits()\n        features = dataset.get_all_features()\n        \n        if deposits.empty:\n            raise HTTPException(\n                status_code=400,\n                detail=\"No deposit data available for export\"\n            )\n        \n        # Calculate risks for each deposit\n        risk_data = {\n            \"deposits\": [],\n            \"overall_statistics\": {}\n        }\n        \n        for _, deposit in deposits.iterrows():\n            risks = risk_analyzer.analyze_site_risks(\n                latitude=deposit[\"latitude\"],\n                longitude=deposit[\"longitude\"],\n                geological_features=features,\n                deposits=deposits\n            )\n            \n            risk_data[\"deposits\"].append({\n                \"latitude\": deposit[\"latitude\"],\n                \"longitude\": deposit[\"longitude\"],\n                \"mineral_type\": deposit[\"mineral_type\"],\n                **risks\n            })\n        \n        # Calculate overall statistics\n        risk_data[\"overall_statistics\"] = {\n            \"avg_geological_risk\": np.mean([d[\"geological_risk\"] for d in risk_data[\"deposits\"]]),\n            \"avg_environmental_risk\": np.mean([d[\"environmental_risk\"] for d in risk_data[\"deposits\"]]),\n            \"avg_technical_risk\": np.mean([d[\"technical_risk\"] for d in risk_data[\"deposits\"]]),\n            \"avg_economic_risk\": np.mean([d[\"economic_risk\"] for d in risk_data[\"deposits\"]]),\n            \"avg_overall_risk\": np.mean([d[\"overall_risk\"] for d in risk_data[\"deposits\"]])\n        }\n        \n        # Export data\n        file_path = exporter.export_risk_assessment(\n            risk_data,\n            format=request.format,\n            filename=request.filename\n        )\n        \n        # Generate download URL\n        filename = Path(file_path).name\n        download_url = f\"/exports/{filename}\"\n        \n        return ExportResponse(\n            file_path=file_path,\n            format=request.format,\n            download_url=download_url\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/export/features\", response_model=ExportResponse)\nasync def export_features(request: ExportRequest):\n    \"\"\"\n    Export feature analysis results\n    \"\"\"\n    try:\n        # Get all features\n        features = dataset.get_all_features()\n        deposits = dataset.get_all_deposits()\n        \n        if features.empty:\n            raise HTTPException(\n                status_code=400,\n                detail=\"No feature data available for export\"\n            )\n        \n        # Analyze features\n        density_metrics = analyzer.analyze_feature_density(\n            features,\n            radius_km=5.0\n        )\n        \n        cluster_analysis = analyzer.analyze_feature_clusters(\n            features,\n            min_samples=3,\n            eps_km=2.0\n        )\n        \n        correlation_metrics = analyzer.analyze_deposit_correlation(\n            features,\n            deposits,\n            radius_km=5.0\n        )\n        \n        feature_data = {\n            \"density_metrics\": density_metrics,\n            \"cluster_analysis\": cluster_analysis,\n            \"correlation_metrics\": correlation_metrics\n        }\n        \n        # Export data\n        file_path = exporter.export_feature_analysis(\n            feature_data,\n            format=request.format,\n            filename=request.filename\n        )\n        \n        # Generate download URL\n        filename = Path(file_path).name\n        download_url = f\"/exports/{filename}\"\n        \n        return ExportResponse(\n            file_path=file_path,\n            format=request.format,\n            download_url=download_url\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/export/time-series\", response_model=ExportResponse)\nasync def export_time_series(request: ExportRequest):\n    \"\"\"\n    Export time series analysis results\n    \"\"\"\n    try:\n        # Get all data\n        deposits = dataset.get_all_deposits()\n        features = dataset.get_all_features()\n        \n        if deposits.empty and features.empty:\n            raise HTTPException(\n                status_code=400,\n                detail=\"No data available for time series export\"\n            )\n        \n        # Analyze time series\n        discovery_trends = time_analyzer.analyze_discovery_trends(\n            deposits,\n            window_days=30\n        )\n        \n        feature_evolution = time_analyzer.analyze_feature_evolution(\n            features,\n            window_days=30\n        )\n        \n        exploration_intensity = time_analyzer.analyze_exploration_intensity(\n            deposits,\n            features,\n            window_days=30\n        )\n        \n        time_data = {\n            \"discovery_trends\": discovery_trends,\n            \"feature_evolution\": feature_evolution,\n            \"exploration_intensity\": exploration_intensity\n        }\n        \n        # Export data\n        file_path = exporter.export_time_series(\n            time_data,\n            format=request.format,\n            filename=request.filename\n        )\n        \n        # Generate download URL\n        filename = Path(file_path).name\n        download_url = f\"/exports/{filename}\"\n        \n        return ExportResponse(\n            file_path=file_path,\n            format=request.format,\n            download_url=download_url\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/exports/{filename}\")\nasync def get_export(filename: str):\n    \"\"\"\n    Serve exported files\n    \"\"\"\n    try:\n        export_dir = Path(\"exports\")\n        file_path = export_dir / filename\n        \n        if not file_path.exists():\n            raise HTTPException(status_code=404, detail=\"Export file not found\")\n        \n        # Determine media type based on file extension\n        extension = file_path.suffix.lower()\n        media_type = {\n            \".json\": \"application/json\",\n            \".csv\": \"text/csv\",\n            \".xlsx\": \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n        }.get(extension, \"application/octet-stream\")\n        \n        return FileResponse(\n            str(file_path),\n            media_type=media_type,\n            filename=filename\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/import/csv\", response_model=ImportResponse)\nasync def import_csv_data(\n    file: UploadFile = File(...),\n    data_type: DataType = Query(..., description=\"Type of data being imported\"),\n    mapping: Optional[Dict[str, str]] = None\n):\n    \"\"\"Import data from CSV file\"\"\"\n    try:\n        # Save uploaded file\n        temp_path = f\"temp_{file.filename}\"\n        with open(temp_path, \"wb\") as buffer:\n            content = await file.read()\n            buffer.write(content)\n        \n        # Import data\n        df = data_importer.import_csv_data(temp_path, data_type, mapping)\n        \n        # Clean up temp file\n        Path(temp_path).unlink()\n        \n        return ImportResponse(\n            file_path=str(data_importer.processed_dir / f\"{data_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"),\n            data_type=data_type,\n            row_count=len(df),\n            columns=list(df.columns),\n            preview=df.head().to_dict('records')\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/import/shapefile\", response_model=ImportResponse)\nasync def import_shapefile(\n    file: UploadFile = File(...),\n    data_type: DataType = Query(..., description=\"Type of data being imported\"),\n    mapping: Optional[Dict[str, str]] = None\n):\n    \"\"\"Import data from shapefile\"\"\"\n    try:\n        # Save uploaded file\n        temp_path = f\"temp_{file.filename}\"\n        with open(temp_path, \"wb\") as buffer:\n            content = await file.read()\n            buffer.write(content)\n        \n        # Import data\n        gdf = data_importer.import_shapefile(temp_path, data_type, mapping)\n        \n        # Clean up temp file\n        Path(temp_path).unlink()\n        \n        return ImportResponse(\n            file_path=str(data_importer.processed_dir / f\"{data_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.geojson\"),\n            data_type=data_type,\n            row_count=len(gdf),\n            columns=list(gdf.columns),\n            preview=gdf.head().to_dict('records')\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/import/json\", response_model=ImportResponse)\nasync def import_json_data(\n    file: UploadFile = File(...),\n    data_type: DataType = Query(..., description=\"Type of data being imported\"),\n    mapping: Optional[Dict[str, str]] = None\n):\n    \"\"\"Import data from JSON file\"\"\"\n    try:\n        # Save uploaded file\n        temp_path = f\"temp_{file.filename}\"\n        with open(temp_path, \"wb\") as buffer:\n            content = await file.read()\n            buffer.write(content)\n        \n        # Import data\n        df = data_importer.import_json_data(temp_path, data_type, mapping)\n        \n        # Clean up temp file\n        Path(temp_path).unlink()\n        \n        return ImportResponse(\n            file_path=str(data_importer.processed_dir / f\"{data_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"),\n            data_type=data_type,\n            row_count=len(df),\n            columns=list(df.columns),\n            preview=df.head().to_dict('records')\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/import/kml\", response_model=ImportResponse)\nasync def import_kml_data(\n    file: UploadFile = File(...),\n    data_type: DataType = Query(..., description=\"Type of data being imported\"),\n    mapping: Optional[Dict[str, str]] = None\n):\n    \"\"\"Import data from KML/KMZ file\"\"\"\n    try:\n        # Save uploaded file\n        temp_path = f\"temp_{file.filename}\"\n        with open(temp_path, \"wb\") as buffer:\n            content = await file.read()\n            buffer.write(content)\n        \n        # Import data\n        df = data_importer.import_kml_data(temp_path, data_type, mapping)\n        \n        # Clean up temp file\n        Path(temp_path).unlink()\n        \n        return ImportResponse(\n            file_path=str(data_importer.processed_dir / f\"{data_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"),\n            data_type=data_type,\n            row_count=len(df),\n            columns=list(df.columns),\n            preview=df.head().to_dict('records')\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/import/wms\")\nasync def import_wms_data(\n    url: str = Query(..., description=\"WMS service URL\"),\n    layers: List[str] = Query(..., description=\"Layer names to import\"),\n    bounds: Dict[str, float] = Query(..., description=\"Bounding box coordinates\"),\n    output_format: str = Query(\"geotiff\", description=\"Output format (geotiff, png)\")\n):\n    \"\"\"Import data from WMS service\"\"\"\n    try:\n        # Import data\n        file_path = data_importer.import_wms_data(url, layers, bounds, output_format)\n        \n        return {\n            \"file_path\": file_path,\n            \"format\": output_format,\n            \"layers\": layers,\n            \"bounds\": bounds\n        }\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/import/xyz\", response_model=ImportResponse)\nasync def import_xyz_data(\n    file: UploadFile = File(...),\n    columns: List[str] = Query(..., description=\"Column names\"),\n    delimiter: str = Query(\",\", description=\"Field delimiter\")\n):\n    \"\"\"Import XYZ point cloud data\"\"\"\n    try:\n        # Save uploaded file\n        temp_path = f\"temp_{file.filename}\"\n        with open(temp_path, \"wb\") as buffer:\n            content = await file.read()\n            buffer.write(content)\n        \n        # Import data\n        df = data_importer.import_xyz_data(temp_path, columns, delimiter)\n        \n        # Clean up temp file\n        Path(temp_path).unlink()\n        \n        return ImportResponse(\n            file_path=str(data_importer.processed_dir / f\"xyz_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"),\n            data_type=\"xyz\",\n            row_count=len(df),\n            columns=list(df.columns),\n            preview=df.head().to_dict('records')\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/validate/deposits\", response_model=ValidationResponse)\nasync def validate_deposits(data: Union[DepositData, List[DepositData]]):\n    \"\"\"\n    Validate mineral deposit data\n    \"\"\"\n    try:\n        if isinstance(data, list):\n            data_dict = [d.dict() for d in data]\n        else:\n            data_dict = data.dict()\n            \n        results = data_validator.validate_deposit_data(data_dict)\n        return ValidationResponse(**results)\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/validate/features\", response_model=ValidationResponse)\nasync def validate_features(data: Union[GeologicalFeature, List[GeologicalFeature]]):\n    \"\"\"\n    Validate geological feature data\n    \"\"\"\n    try:\n        if isinstance(data, list):\n            data_dict = [d.dict() for d in data]\n        else:\n            data_dict = data.dict()\n            \n        results = data_validator.validate_geological_feature(data_dict)\n        return ValidationResponse(**results)\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/validate/samples\", response_model=ValidationResponse)\nasync def validate_samples(\n    file: UploadFile = File(...),\n    sample_type: str = Query(..., description=\"Type of sample data\")\n):\n    \"\"\"\n    Validate sample data from file\n    \"\"\"\n    try:\n        # Save uploaded file\n        temp_path = f\"temp_{file.filename}\"\n        with open(temp_path, \"wb\") as buffer:\n            content = await file.read()\n            buffer.write(content)\n            \n        # Read and validate data\n        df = pd.read_csv(temp_path)\n        results = data_validator.validate_sample_data(df)\n        \n        # Clean up temp file\n        Path(temp_path).unlink()\n        \n        return ValidationResponse(**results)\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/validate/dem\", response_model=ValidationResponse)\nasync def validate_dem(\n    file: UploadFile = File(...),\n    metadata: Dict[str, Any] = None\n):\n    \"\"\"\n    Validate DEM data from file\n    \"\"\"\n    try:\n        # Save uploaded file\n        temp_path = f\"temp_{file.filename}\"\n        with open(temp_path, \"wb\") as buffer:\n            content = await file.read()\n            buffer.write(content)\n            \n        # Read and validate data\n        with rasterio.open(temp_path) as src:\n            data = src.read(1)\n            if not metadata:\n                metadata = {\n                    \"resolution\": src.res,\n                    \"crs\": src.crs.to_string(),\n                    \"bounds\": src.bounds._asdict()\n                }\n                \n        results = data_validator.validate_dem_data(data, metadata)\n        \n        # Clean up temp file\n        Path(temp_path).unlink()\n        \n        return ValidationResponse(**results)\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/api/v1/validation-report\", response_model=ValidationReportResponse)\nasync def get_validation_report():\n    \"\"\"\n    Generate and retrieve validation report\n    \"\"\"\n    try:\n        report_path = data_validator.export_validation_report()\n        \n        return ValidationReportResponse(\n            report_path=report_path,\n            summary=data_validator._generate_validation_summary()\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/plan-exploration\", response_model=PlanningResponse)\nasync def plan_exploration(request: PlanningRequest):\n    \"\"\"\n    Generate optimized exploration plan\n    \"\"\"\n    try:\n        # Get predictions for the region\n        predictions = []\n        for lat in np.linspace(request.region[\"min_lat\"], request.region[\"max_lat\"], 10):\n            for lon in np.linspace(request.region[\"min_lon\"], request.region[\"max_lon\"], 10):\n                features = {\n                    \"latitude\": float(lat),\n                    \"longitude\": float(lon),\n                    \"elevation\": 0,\n                    \"rock_type\": \"unknown\",\n                    \"geological_age\": \"unknown\"\n                }\n                probability, confidence = model.predict(features)\n                predictions.append({\n                    \"location\": {\"latitude\": float(lat), \"longitude\": float(lon)},\n                    \"probability\": float(probability),\n                    \"confidence\": float(confidence)\n                })\n        \n        # Get risk assessment for the region\n        risks = risk_analyzer.analyze_site_risks(\n            latitude=(request.region[\"min_lat\"] + request.region[\"max_lat\"]) / 2,\n            longitude=(request.region[\"min_lon\"] + request.region[\"max_lon\"]) / 2,\n            geological_features=dataset.get_all_features(),\n            deposits=dataset.get_all_deposits()\n        )\n        \n        # Generate exploration plan\n        plan = planner.generate_exploration_plan(\n            prediction_results={\"predictions\": predictions},\n            risk_assessment=risks,\n            available_resources=request.available_resources,\n            constraints=request.constraints or {}\n        )\n        \n        return PlanningResponse(**plan)\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/api/v1/resource-templates\")\nasync def get_resource_templates():\n    \"\"\"\n    Get templates for available exploration resources\n    \"\"\"\n    return {\n        \"teams\": {\n            \"survey_team\": {\n                \"cost_per_day\": 1000.0,\n                \"efficiency\": 1.0\n            },\n            \"sampling_team\": {\n                \"cost_per_day\": 800.0,\n                \"efficiency\": 1.0\n            },\n            \"drilling_team\": {\n                \"cost_per_day\": 5000.0,\n                \"efficiency\": 1.0\n            }\n        },\n        \"equipment\": {\n            \"survey_equipment\": {\n                \"cost_per_day\": 500.0,\n                \"efficiency\": 1.0\n            },\n            \"sampling_equipment\": {\n                \"cost_per_day\": 300.0,\n                \"efficiency\": 1.0\n            },\n            \"drilling_equipment\": {\n                \"cost_per_day\": 3000.0,\n                \"efficiency\": 1.0\n            }\n        },\n        \"facilities\": {\n            \"analysis_lab\": {\n                \"cost_per_day\": 2000.0,\n                \"efficiency\": 1.0\n            }\n        }\n    }\n\n@app.post(\"/api/v1/monitor\", response_model=Dict[str, Any])\nasync def monitor_activities(\n    activities: List[Dict[str, Any]],\n    resources: Dict[str, Any],\n    risk_data: Dict[str, Any]\n):\n    \"\"\"\n    Monitor exploration activities and generate alerts\n    \"\"\"\n    try:\n        monitoring_results = monitoring_system.monitor_exploration_activities(\n            activities=activities,\n            resources=resources,\n            risk_data=risk_data\n        )\n        return monitoring_results\n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Error monitoring activities: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/alerts\", response_model=List[Dict[str, Any]])\nasync def get_alerts(\n    level: Optional[str] = Query(None, description=\"Filter by alert level\"),\n    category: Optional[str] = Query(None, description=\"Filter by alert category\"),\n    start_date: Optional[str] = Query(None, description=\"Filter by start date (ISO format)\"),\n    end_date: Optional[str] = Query(None, description=\"Filter by end date (ISO format)\")\n):\n    \"\"\"\n    Get monitoring alerts with optional filters\n    \"\"\"\n    try:\n        alerts = [alert for alert in monitoring_system.alerts]\n        \n        # Apply filters\n        if level:\n            alerts = [\n                alert for alert in alerts\n                if alert.level.value == level.lower()\n            ]\n            \n        if category:\n            alerts = [\n                alert for alert in alerts\n                if alert.category == category.lower()\n            ]\n            \n        if start_date:\n            start_dt = datetime.fromisoformat(start_date)\n            alerts = [\n                alert for alert in alerts\n                if alert.timestamp >= start_dt\n            ]\n            \n        if end_date:\n            end_dt = datetime.fromisoformat(end_date)\n            alerts = [\n                alert for alert in alerts\n                if alert.timestamp <= end_dt\n            ]\n        \n        return [monitoring_system._alert_to_dict(alert) for alert in alerts]\n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Error retrieving alerts: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/metrics\", response_model=Dict[str, Any])\nasync def get_metrics():\n    \"\"\"\n    Get current monitoring metrics\n    \"\"\"\n    try:\n        return monitoring_system.metrics\n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Error retrieving metrics: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/status\", response_model=Dict[str, Any])\nasync def get_status():\n    \"\"\"\n    Get current system status summary\n    \"\"\"\n    try:\n        return monitoring_system._generate_status_summary()\n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Error retrieving status: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/dashboards/exploration\", response_model=Dict[str, str])\nasync def get_exploration_dashboard():\n    \"\"\"\n    Generate comprehensive exploration dashboard\n    \"\"\"\n    try:\n        dashboard = Dashboard()\n        \n        # Get required data\n        deposits = dataset.get_all_deposits()\n        features = dataset.get_all_features()\n        \n        # Get predictions for current region\n        predictions = []\n        for lat in np.arange(-90, 90, 5):\n            for lon in np.arange(-180, 180, 5):\n                pred = model.predict({\n                    \"latitude\": lat,\n                    \"longitude\": lon\n                })\n                predictions.append({\n                    \"location\": {\"latitude\": lat, \"longitude\": lon},\n                    \"probability\": pred[0],\n                    \"confidence\": pred[1]\n                })\n        \n        # Get risk assessment\n        risk_data = risk_analyzer.analyze_site_risks(\n            latitude=0,\n            longitude=0,\n            geological_features=features,\n            deposits=deposits\n        )\n        \n        # Get monitoring data\n        monitoring_data = monitoring_system.monitor_exploration_activities(\n            activities=[],  # Add actual activities\n            resources={},   # Add actual resources\n            risk_data=risk_data\n        )\n        \n        # Generate dashboard\n        dashboard_path = dashboard.create_exploration_dashboard(\n            deposits=deposits,\n            geological_features=features,\n            predictions=predictions,\n            risk_data=risk_data,\n            monitoring_data=monitoring_data\n        )\n        \n        return {\n            \"dashboard_url\": f\"/dashboards/{Path(dashboard_path).name}\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate exploration dashboard: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/dashboards/monitoring\", response_model=Dict[str, str])\nasync def get_monitoring_dashboard(\n    time_range: str = Query(\"24h\", description=\"Time range for metrics (24h, 7d, 30d)\")\n):\n    \"\"\"\n    Generate real-time monitoring dashboard\n    \"\"\"\n    try:\n        dashboard = Dashboard()\n        \n        # Get monitoring data\n        monitoring_data = monitoring_system.monitor_exploration_activities(\n            activities=[],  # Add actual activities\n            resources={},   # Add actual resources\n            risk_data={}    # Add actual risk data\n        )\n        \n        # Generate dashboard\n        dashboard_path = dashboard.create_monitoring_dashboard(\n            monitoring_data=monitoring_data,\n            time_range=time_range\n        )\n        \n        return {\n            \"dashboard_url\": f\"/dashboards/{Path(dashboard_path).name}\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate monitoring dashboard: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/dashboards/analysis\", response_model=Dict[str, str])\nasync def get_analysis_dashboard():\n    \"\"\"\n    Generate analysis dashboard\n    \"\"\"\n    try:\n        dashboard = Dashboard()\n        \n        # Get required data\n        deposits = dataset.get_all_deposits()\n        features = dataset.get_all_features()\n        \n        # Perform feature analysis\n        feature_analyzer = FeatureAnalyzer()\n        feature_analysis = feature_analyzer.analyze_feature_density(features)\n        \n        # Perform time series analysis\n        time_analyzer = TimeSeriesAnalyzer()\n        time_analysis = time_analyzer.analyze_discovery_trends(deposits)\n        \n        # Generate dashboard\n        dashboard_path = dashboard.create_analysis_dashboard(\n            feature_analysis=feature_analysis,\n            time_analysis=time_analysis\n        )\n        \n        return {\n            \"dashboard_url\": f\"/dashboards/{Path(dashboard_path).name}\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate analysis dashboard: {str(e)}\"\n        )\n\n@app.get(\"/dashboards/{filename}\")\nasync def get_dashboard(filename: str):\n    \"\"\"\n    Serve dashboard HTML files\n    \"\"\"\n    dashboard_dir = Path(\"dashboards\")\n    dashboard_path = dashboard_dir / filename\n    \n    if not dashboard_path.exists():\n        raise HTTPException(\n            status_code=404,\n            detail=\"Dashboard not found\"\n        )\n        \n    return FileResponse(str(dashboard_path))\n\n@app.post(\"/api/v1/analyze/deep-learning\", response_model=DeepLearningResponse)\nasync def perform_deep_learning_analysis(request: DeepLearningRequest):\n    \"\"\"\n    Perform advanced deep learning analysis\n    \"\"\"\n    try:\n        # Initialize deep learning analyzer\n        analyzer = DeepLearningAnalyzer()\n        \n        # Get data for analysis\n        deposits = dataset.get_all_deposits()\n        features = dataset.get_all_features()\n        \n        # Apply data filters if provided\n        if request.data_filters:\n            deposits = analyzer.filter_data(deposits, request.data_filters)\n            features = analyzer.filter_data(features, request.data_filters)\n        \n        # Prepare input data\n        input_data = analyzer.prepare_data(\n            deposits=deposits,\n            features=features,\n            region=request.region\n        )\n        \n        # Initialize and configure model\n        model_config = request.model_params or {}\n        model = MineralExplorationModel(\n            input_features=input_data[\"n_features\"],\n            **model_config\n        )\n        \n        # Perform analysis based on type\n        if request.analysis_type == \"deposit_prediction\":\n            results = analyzer.predict_deposits(\n                model=model,\n                input_data=input_data,\n                region=request.region\n            )\n        elif request.analysis_type == \"feature_extraction\":\n            results = analyzer.extract_features(\n                model=model,\n                input_data=input_data\n            )\n        elif request.analysis_type == \"pattern_recognition\":\n            results = analyzer.recognize_patterns(\n                model=model,\n                input_data=input_data\n            )\n        elif request.analysis_type == \"anomaly_detection\":\n            results = analyzer.detect_anomalies(\n                model=model,\n                input_data=input_data\n            )\n        else:\n            raise ValueError(f\"Unsupported analysis type: {request.analysis_type}\")\n        \n        # Generate visualizations\n        visualizations = analyzer.generate_visualizations(\n            results=results,\n            region=request.region\n        )\n        \n        return DeepLearningResponse(\n            analysis_results=results[\"analysis\"],\n            model_metrics=results[\"metrics\"],\n            feature_importance=results[\"importance\"],\n            predictions=results[\"predictions\"],\n            visualizations=visualizations\n        )\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Deep learning analysis failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/visualize/3d\", response_model=Visualization3DResponse)\nasync def create_3d_visualization(request: Visualization3DRequest):\n    \"\"\"\n    Create interactive 3D visualization\n    \"\"\"\n    try:\n        # Get data for visualization\n        deposits = dataset.get_all_deposits()\n        features = dataset.get_all_features()\n        \n        # Apply data filters if provided\n        if request.data_filters:\n            deposits = data_validator.filter_data(deposits, request.data_filters)\n            features = data_validator.filter_data(features, request.data_filters)\n        \n        # Get DEM data if requested\n        dem_data = None\n        if request.include_dem:\n            dem_data = dataset.get_dem_data(request.region)\n        \n        # Create visualization based on type\n        if request.visualization_type == \"exploration\":\n            viz_path = visualizer.create_3d_visualization(\n                deposits=deposits,\n                geological_features=features,\n                dem_data=dem_data,\n                predictions=request.analysis_results.get(\"predictions\") if request.analysis_results else None\n            )\n        elif request.visualization_type == \"analysis\":\n            if not request.analysis_results:\n                raise ValueError(\"Analysis results required for analysis visualization\")\n                \n            viz_path = visualizer.create_3d_analysis(\n                analysis_results=request.analysis_results,\n                dem_data=dem_data\n            )\n        elif request.visualization_type == \"time_series\":\n            if not request.time_data:\n                raise ValueError(\"Time series data required for time series visualization\")\n                \n            viz_path = visualizer.create_3d_time_series(\n                time_data=request.time_data,\n                dem_data=dem_data\n            )\n        else:\n            raise ValueError(f\"Unsupported visualization type: {request.visualization_type}\")\n        \n        # Prepare data summary\n        data_summary = {\n            \"deposits_count\": len(deposits),\n            \"features_count\": len(features),\n            \"region_bounds\": request.region,\n            \"visualization_type\": request.visualization_type\n        }\n        \n        return Visualization3DResponse(\n            visualization_url=f\"/visualizations/{Path(viz_path).name}\",\n            data_summary=data_summary\n        )\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to create 3D visualization: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/streams\", response_model=StreamResponse)\nasync def manage_stream(request: StreamRequest):\n    \"\"\"\n    Manage data streams\n    \"\"\"\n    try:\n        if request.operation == \"create\":\n            # Create new stream processor\n            processor = stream_handler.create_processor(\n                stream_type=request.stream_type,\n                **(request.parameters or {})\n            )\n            \n            # Start processor\n            asyncio.create_task(processor.start())\n            \n            return StreamResponse(\n                success=True,\n                message=f\"Created and started {request.stream_type} stream processor\"\n            )\n            \n        elif request.operation == \"add_data\":\n            # Get processor\n            processor = stream_handler.get_processor(request.stream_type)\n            if not processor:\n                raise ValueError(f\"No processor found for stream type: {request.stream_type}\")\n            \n            # Add data\n            if not request.data:\n                raise ValueError(\"No data provided\")\n                \n            processor.add_data(request.data)\n            \n            return StreamResponse(\n                success=True,\n                message=f\"Added data to {request.stream_type} stream\"\n            )\n            \n        elif request.operation == \"get_results\":\n            # Get processor\n            processor = stream_handler.get_processor(request.stream_type)\n            if not processor:\n                raise ValueError(f\"No processor found for stream type: {request.stream_type}\")\n            \n            # Get results\n            n = request.parameters.get(\"n\", 10) if request.parameters else 10\n            results = processor.get_latest_results(n)\n            \n            return StreamResponse(\n                success=True,\n                message=f\"Retrieved latest results from {request.stream_type} stream\",\n                data={\"results\": results}\n            )\n            \n        elif request.operation == \"get_statistics\":\n            # Get processor\n            processor = stream_handler.get_processor(request.stream_type)\n            if not processor:\n                raise ValueError(f\"No processor found for stream type: {request.stream_type}\")\n            \n            # Get statistics\n            stats = processor.get_statistics()\n            \n            return StreamResponse(\n                success=True,\n                message=f\"Retrieved statistics for {request.stream_type} stream\",\n                data={\"statistics\": stats}\n            )\n            \n        elif request.operation == \"stop\":\n            # Remove processor\n            stream_handler.remove_processor(request.stream_type)\n            \n            return StreamResponse(\n                success=True,\n                message=f\"Stopped and removed {request.stream_type} stream processor\"\n            )\n            \n        else:\n            raise ValueError(f\"Unsupported operation: {request.operation}\")\n            \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Stream operation failed: {str(e)}\"\n        )\n\n@app.websocket(\"/api/v1/streams/{stream_type}/ws\")\nasync def stream_websocket(websocket: WebSocket, stream_type: str):\n    \"\"\"\n    WebSocket endpoint for real-time stream data\n    \"\"\"\n    try:\n        await websocket.accept()\n        \n        # Get or create processor\n        processor = stream_handler.get_processor(stream_type)\n        if not processor:\n            processor = stream_handler.create_processor(stream_type)\n            asyncio.create_task(processor.start())\n        \n        # Subscribe to stream\n        while True:\n            try:\n                # Get latest results\n                results = processor.get_latest_results(1)\n                if results:\n                    await websocket.send_json(results[0])\n                \n                # Wait before next update\n                await asyncio.sleep(1.0)\n                \n            except WebSocketDisconnect:\n                break\n            except Exception as e:\n                await websocket.send_json({\n                    \"error\": f\"Stream error: {str(e)}\"\n                })\n                break\n                \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"WebSocket connection failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/recommend\", response_model=RecommendationResponse)\nasync def get_recommendations(request: RecommendationRequest):\n    \"\"\"\n    Get intelligent recommendations for exploration\n    \"\"\"\n    try:\n        # Get predictions for the region\n        predictions = []\n        for lat in np.linspace(request.region[\"min_lat\"], request.region[\"max_lat\"], 10):\n            for lon in np.linspace(request.region[\"min_lon\"], request.region[\"max_lon\"], 10):\n                features = {\n                    \"latitude\": float(lat),\n                    \"longitude\": float(lon),\n                    \"elevation\": 0,\n                    \"rock_type\": \"unknown\",\n                    \"geological_age\": \"unknown\"\n                }\n                probability, confidence = model.predict(features)\n                predictions.append({\n                    \"location\": {\"latitude\": float(lat), \"longitude\": float(lon)},\n                    \"probability\": float(probability),\n                    \"confidence\": float(confidence)\n                })\n        \n        # Get risk assessment\n        risks = risk_analyzer.analyze_site_risks(\n            latitude=(request.region[\"min_lat\"] + request.region[\"max_lat\"]) / 2,\n            longitude=(request.region[\"min_lon\"] + request.region[\"max_lon\"]) / 2,\n            geological_features=dataset.get_all_features(),\n            deposits=dataset.get_all_deposits()\n        )\n        \n        # Get monitoring data\n        monitoring_data = monitoring_system.monitor_exploration_activities(\n            activities=[],  # Add actual activities\n            resources=request.resource_data,\n            risk_data=risks\n        )\n        \n        # Get historical data if requested\n        historical_data = None\n        if request.include_historical:\n            historical_data = {\n                \"explorations\": dataset.get_historical_explorations(),\n                \"prediction_accuracy\": model.get_historical_accuracy(),\n                \"resource_efficiency\": dataset.get_resource_efficiency()\n            }\n        \n        # Generate recommendations\n        recommendations = recommendation_engine.generate_recommendations(\n            prediction_results={\"predictions\": predictions},\n            risk_assessment=risks,\n            monitoring_data=monitoring_data,\n            resource_data=request.resource_data,\n            historical_data=historical_data\n        )\n        \n        return RecommendationResponse(**recommendations)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate recommendations: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/recommendation-templates\")\nasync def get_recommendation_templates():\n    \"\"\"\n    Get templates for recommendation parameters\n    \"\"\"\n    return {\n        \"region_template\": {\n            \"min_lat\": -90.0,\n            \"max_lat\": 90.0,\n            \"min_lon\": -180.0,\n            \"max_lon\": 180.0\n        },\n        \"resource_template\": {\n            \"survey_team\": {\n                \"utilization\": 0.0,\n                \"efficiency\": 1.0\n            },\n            \"sampling_team\": {\n                \"utilization\": 0.0,\n                \"efficiency\": 1.0\n            },\n            \"drilling_team\": {\n                \"utilization\": 0.0,\n                \"efficiency\": 1.0\n            },\n            \"equipment\": {\n                \"utilization\": 0.0,\n                \"efficiency\": 1.0\n            },\n            \"analysis_lab\": {\n                \"utilization\": 0.0,\n                \"efficiency\": 1.0\n            }\n        }\n    }\n\n@app.get(\"/api/v1/dashboards/recommendations\", response_model=Dict[str, str])\nasync def get_recommendation_dashboard():\n    \"\"\"\n    Generate recommendation dashboard\n    \"\"\"\n    try:\n        dashboard = Dashboard()\n        \n        # Get current recommendations\n        recommendations = recommendation_engine.generate_recommendations(\n            prediction_results={\"predictions\": []},  # Add actual predictions\n            risk_assessment={},  # Add actual risk assessment\n            monitoring_data={},  # Add actual monitoring data\n            resource_data={}     # Add actual resource data\n        )\n        \n        # Generate dashboard\n        dashboard_path = dashboard.create_recommendation_dashboard(\n            recommendations=recommendations\n        )\n        \n        return {\n            \"dashboard_url\": f\"/dashboards/{Path(dashboard_path).name}\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate recommendation dashboard: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/quality/check\", response_model=QualityCheckResponse)\nasync def check_data_quality(request: QualityCheckRequest):\n    \"\"\"\n    Check quality of input data\n    \"\"\"\n    try:\n        results = quality_monitor.check_data_quality(\n            data=request.data,\n            data_type=request.data_type\n        )\n        return QualityCheckResponse(**results)\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/quality/report\", response_model=QualityReportResponse)\nasync def generate_quality_report(request: QualityReportRequest):\n    \"\"\"\n    Generate data quality report\n    \"\"\"\n    try:\n        report = quality_monitor.generate_quality_report(\n            start_time=request.start_time,\n            end_time=request.end_time\n        )\n        return QualityReportResponse(**report)\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/api/v1/quality/dashboard\")\nasync def get_quality_dashboard():\n    \"\"\"\n    Generate and retrieve quality monitoring dashboard\n    \"\"\"\n    try:\n        dashboard_path = quality_monitor.export_quality_dashboard()\n        return FileResponse(dashboard_path)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/quality/monitoring/start\")\nasync def start_quality_monitoring():\n    \"\"\"\n    Start real-time quality monitoring\n    \"\"\"\n    try:\n        await quality_monitor.start_monitoring()\n        return {\"status\": \"success\", \"message\": \"Quality monitoring started\"}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/quality/monitoring/stop\")\nasync def stop_quality_monitoring():\n    \"\"\"\n    Stop quality monitoring\n    \"\"\"\n    try:\n        quality_monitor.stop_monitoring()\n        return {\"status\": \"success\", \"message\": \"Quality monitoring stopped\"}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/detect-anomalies\", response_model=AnomalyDetectionResponse)\nasync def detect_anomalies(request: AnomalyDetectionRequest):\n    \"\"\"\n    Detect anomalies in exploration data\n    \"\"\"\n    try:\n        # Update configuration if provided\n        if request.config:\n            anomaly_detector.config.update(request.config)\n            \n        # Convert data to DataFrame\n        if isinstance(request.data, list):\n            data = pd.DataFrame(request.data)\n        else:\n            data = pd.DataFrame([request.data])\n            \n        # Train detector if needed\n        if len(data) > 10:  # Only train if we have enough data\n            anomaly_detector.train(data)\n            \n        # Detect anomalies\n        anomalies = anomaly_detector.detect_anomalies(data)\n        \n        # Analyze patterns\n        analysis = anomaly_detector.analyze_anomaly_patterns(anomalies)\n        \n        # Generate report\n        report_path = anomaly_detector.generate_anomaly_report(anomalies)\n        report_url = f\"/reports/{Path(report_path).name}\"\n        \n        # Convert anomalies to dict format\n        anomaly_dicts = [\n            {\n                \"score\": a.score,\n                \"confidence\": a.confidence,\n                \"category\": a.category,\n                \"features\": a.features,\n                \"timestamp\": a.timestamp.isoformat(),\n                \"metadata\": a.metadata\n            }\n            for a in anomalies\n        ]\n        \n        return AnomalyDetectionResponse(\n            anomalies=anomaly_dicts,\n            analysis=analysis,\n            report_url=report_url\n        )\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Anomaly detection failed: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/anomaly-templates\")\nasync def get_anomaly_templates():\n    \"\"\"\n    Get templates for anomaly detection configuration\n    \"\"\"\n    return {\n        \"isolation_forest\": {\n            \"contamination\": 0.1,\n            \"n_estimators\": 100,\n            \"random_state\": 42\n        },\n        \"autoencoder\": {\n            \"encoding_dim\": 10,\n            \"learning_rate\": 0.001,\n            \"epochs\": 100,\n            \"batch_size\": 32\n        },\n        \"thresholds\": {\n            \"zscore\": 3.0,\n            \"reconstruction_error\": 0.1,\n            \"isolation_score\": -0.5\n        }\n    }\n\n@app.get(\"/api/v1/dashboards/anomalies\", response_model=Dict[str, str])\nasync def get_anomaly_dashboard():\n    \"\"\"\n    Generate anomaly detection dashboard\n    \"\"\"\n    try:\n        dashboard = Dashboard()\n        \n        # Get recent anomalies\n        recent_anomalies = []  # TODO: Implement anomaly storage and retrieval\n        \n        # Generate dashboard\n        dashboard_path = dashboard.create_anomaly_dashboard(\n            anomalies=recent_anomalies\n        )\n        \n        return {\n            \"dashboard_url\": f\"/dashboards/{Path(dashboard_path).name}\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate anomaly dashboard: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/smart-recommendations\", response_model=SmartRecommendationResponse)\nasync def get_smart_recommendations(request: SmartRecommendationRequest):\n    \"\"\"\n    Get intelligent recommendations for exploration activities\n    \"\"\"\n    try:\n        # Generate recommendations\n        recommendations = smart_recommender.generate_recommendations(\n            exploration_data=request.exploration_data,\n            historical_data=request.historical_data,\n            current_state=request.current_state\n        )\n        \n        # Analyze impact\n        impact_analysis = smart_recommender.analyze_recommendation_impact(\n            recommendations=recommendations,\n            historical_data=request.historical_data\n        )\n        \n        # Calculate confidence metrics\n        confidence_metrics = {\n            \"overall_confidence\": np.mean([r.confidence for r in recommendations]),\n            \"min_confidence\": min(r.confidence for r in recommendations),\n            \"max_confidence\": max(r.confidence for r in recommendations)\n        }\n        \n        # Convert recommendations to dict format\n        recommendation_dicts = [\n            {\n                \"id\": r.recommendation_id,\n                \"category\": r.category,\n                \"priority\": r.priority,\n                \"confidence\": r.confidence,\n                \"description\": r.description,\n                \"actions\": r.actions,\n                \"expected_impact\": r.expected_impact,\n                \"supporting_data\": r.supporting_data,\n                \"timestamp\": r.timestamp.isoformat()\n            }\n            for r in recommendations\n        ]\n        \n        return SmartRecommendationResponse(\n            recommendations=recommendation_dicts,\n            impact_analysis=impact_analysis,\n            confidence_metrics=confidence_metrics\n        )\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate smart recommendations: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/optimize-resources\", response_model=ResourceOptimizationResponse)\nasync def optimize_resources(request: ResourceOptimizationRequest):\n    \"\"\"\n    Optimize resource allocation\n    \"\"\"\n    try:\n        # Get optimization results\n        results = resource_optimizer.optimize_resources(\n            current_resources=request.current_resources,\n            activities=request.activities,\n            constraints=request.constraints\n        )\n        \n        # Convert results to response format\n        response_data = {\n            \"results\": [\n                {\n                    \"resource_id\": r.resource_id,\n                    \"current_metrics\": {\n                        \"utilization\": r.current_metrics.utilization,\n                        \"efficiency\": r.current_metrics.efficiency,\n                        \"cost_effectiveness\": r.current_metrics.cost_effectiveness,\n                        \"availability\": r.current_metrics.availability,\n                        \"performance_score\": r.current_metrics.performance_score\n                    },\n                    \"optimal_allocation\": r.optimal_allocation,\n                    \"expected_improvements\": r.expected_improvements,\n                    \"recommendations\": r.recommendations\n                }\n                for r in results\n            ],\n            \"improvements\": {\n                r.resource_id: r.expected_improvements\n                for r in results\n            },\n            \"recommendations\": [\n                rec\n                for r in results\n                for rec in r.recommendations\n            ],\n            \"confidence\": np.mean([r.confidence for r in results])\n        }\n        \n        return ResourceOptimizationResponse(**response_data)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Resource optimization failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/analyze-efficiency\", response_model=EfficiencyAnalysisResponse)\nasync def analyze_efficiency(request: EfficiencyAnalysisRequest):\n    \"\"\"\n    Analyze resource efficiency\n    \"\"\"\n    try:\n        analysis_results = resource_optimizer.analyze_efficiency(\n            resource_data=request.resource_data,\n            time_period=request.time_period\n        )\n        \n        return EfficiencyAnalysisResponse(**analysis_results)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Efficiency analysis failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/predict-resources\", response_model=ResourcePredictionResponse)\nasync def predict_resources(request: ResourcePredictionRequest):\n    \"\"\"\n    Predict future resource needs\n    \"\"\"\n    try:\n        predictions = resource_optimizer.predict_resource_needs(\n            historical_data=request.historical_data,\n            future_activities=request.future_activities,\n            prediction_horizon=request.prediction_horizon\n        )\n        \n        return ResourcePredictionResponse(**predictions)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Resource prediction failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/monitor-resources\", response_model=ResourceMonitoringResponse)\nasync def monitor_resources(request: ResourceMonitoringRequest):\n    \"\"\"\n    Monitor and adjust resource usage\n    \"\"\"\n    try:\n        monitoring_results = resource_optimizer.monitor_and_adjust(\n            current_state=request.current_state,\n            optimal_allocation=request.optimal_allocation,\n            thresholds=request.thresholds\n        )\n        \n        return ResourceMonitoringResponse(**monitoring_results)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Resource monitoring failed: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/resource-optimization-templates\")\nasync def get_optimization_templates():\n    \"\"\"\n    Get templates for resource optimization\n    \"\"\"\n    return {\n        \"resource_template\": {\n            \"id\": \"resource_1\",\n            \"type\": \"equipment\",\n            \"utilization\": 0.0,\n            \"efficiency\": 1.0,\n            \"cost_effectiveness\": 1.0,\n            \"availability\": 1.0,\n            \"cost_per_day\": 1000.0,\n            \"maintenance_factor\": 1.0\n        },\n        \"activity_template\": {\n            \"id\": \"activity_1\",\n            \"type\": \"exploration\",\n            \"required_resources\": [\"resource_1\"],\n            \"duration_days\": 7,\n            \"priority\": 0.8\n        },\n        \"constraint_template\": {\n            \"max_utilization\": 0.9,\n            \"min_efficiency\": 0.7,\n            \"budget_limit\": 10000.0\n        },\n        \"monitoring_template\": {\n            \"thresholds\": {\n                \"utilization_deviation\": 0.1,\n                \"efficiency_deviation\": 0.1,\n                \"cost_deviation\": 0.2\n            }\n        }\n    }\n\n@app.get(\"/api/v1/dashboards/resource-optimization\", response_model=Dict[str, str])\nasync def get_resource_optimization_dashboard():\n    \"\"\"\n    Generate resource optimization dashboard\n    \"\"\"\n    try:\n        dashboard = Dashboard()\n        \n        # Get current resource states\n        resources = dataset.get_all_resources()\n        \n        # Get optimization results\n        optimization_results = resource_optimizer.optimize_resources(\n            current_resources=resources,\n            activities=[]  # Add actual activities\n        )\n        \n        # Get efficiency analysis\n        efficiency_analysis = resource_optimizer.analyze_efficiency(\n            resource_data=resources\n        )\n        \n        # Get predictions\n        predictions = resource_optimizer.predict_resource_needs(\n            historical_data=resources,\n            future_activities=[]  # Add planned activities\n        )\n        \n        # Generate dashboard\n        dashboard_path = dashboard.create_resource_optimization_dashboard(\n            resources=resources,\n            optimization_results=optimization_results,\n            efficiency_analysis=efficiency_analysis,\n            predictions=predictions\n        )\n        \n        return {\n            \"dashboard_url\": f\"/dashboards/{Path(dashboard_path).name}\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate resource optimization dashboard: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/optimize-process\", response_model=ProcessOptimizationResponse)\nasync def optimize_process(request: ProcessOptimizationRequest):\n    \"\"\"\n    Optimize the entire exploration process\n    \"\"\"\n    try:\n        # Get optimization results\n        results = process_optimizer.optimize_process(\n            current_state=request.current_state,\n            resources=request.resources,\n            activities=request.activities,\n            constraints=request.constraints\n        )\n        \n        # Convert results to response format\n        response_data = {\n            \"results\": [\n                {\n                    \"process_id\": r.process_id,\n                    \"current_metrics\": {\n                        \"efficiency\": r.current_metrics.efficiency,\n                        \"cost_effectiveness\": r.current_metrics.cost_effectiveness,\n                        \"resource_utilization\": r.current_metrics.resource_utilization,\n                        \"exploration_coverage\": r.current_metrics.exploration_coverage,\n                        \"success_rate\": r.current_metrics.success_rate,\n                        \"risk_score\": r.current_metrics.risk_score\n                    },\n                    \"optimal_configuration\": r.optimal_configuration,\n                    \"expected_improvements\": r.expected_improvements,\n                    \"recommendations\": r.recommendations\n                }\n                for r in results\n            ],\n            \"improvements\": {\n                r.process_id: r.expected_improvements\n                for r in results\n            },\n            \"recommendations\": [\n                rec\n                for r in results\n                for rec in r.recommendations\n            ],\n            \"confidence\": np.mean([r.confidence for r in results])\n        }\n        \n        return ProcessOptimizationResponse(**response_data)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Process optimization failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/analyze-process-efficiency\", response_model=ProcessEfficiencyResponse)\nasync def analyze_process_efficiency(request: ProcessEfficiencyRequest):\n    \"\"\"\n    Analyze process efficiency\n    \"\"\"\n    try:\n        analysis_results = process_optimizer.analyze_process_efficiency(\n            process_data=request.process_data,\n            time_period=request.time_period\n        )\n        \n        return ProcessEfficiencyResponse(**analysis_results)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Process efficiency analysis failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/predict-process\", response_model=ProcessPredictionResponse)\nasync def predict_process_performance(request: ProcessPredictionRequest):\n    \"\"\"\n    Predict future process performance\n    \"\"\"\n    try:\n        predictions = process_optimizer.predict_process_performance(\n            historical_data=request.historical_data,\n            future_activities=request.future_activities,\n            prediction_horizon=request.prediction_horizon\n        )\n        \n        return ProcessPredictionResponse(**predictions)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Process prediction failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/monitor-process\", response_model=ProcessMonitoringResponse)\nasync def monitor_process(request: ProcessMonitoringRequest):\n    \"\"\"\n    Monitor and adjust process performance\n    \"\"\"\n    try:\n        monitoring_results = process_optimizer.monitor_and_adjust_process(\n            current_state=request.current_state,\n            optimal_config=request.optimal_config,\n            thresholds=request.thresholds\n        )\n        \n        return ProcessMonitoringResponse(**monitoring_results)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Process monitoring failed: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/process-optimization-templates\")\nasync def get_process_templates():\n    \"\"\"\n    Get templates for process optimization\n    \"\"\"\n    return {\n        \"process_template\": {\n            \"id\": \"process_1\",\n            \"type\": \"exploration\",\n            \"efficiency\": 0.0,\n            \"cost_effectiveness\": 1.0,\n            \"resource_utilization\": 0.0,\n            \"exploration_coverage\": 0.0,\n            \"success_rate\": 0.0,\n            \"risk_score\": 0.0,\n            \"complexity_score\": 0.5\n        },\n        \"resource_template\": {\n            \"id\": \"resource_1\",\n            \"type\": \"equipment\",\n            \"utilization\": 0.0,\n            \"efficiency\": 1.0,\n            \"cost_effectiveness\": 1.0,\n            \"availability\": 1.0\n        },\n        \"activity_template\": {\n            \"id\": \"activity_1\",\n            \"type\": \"survey\",\n            \"required_resources\": [\"resource_1\"],\n            \"duration_days\": 7,\n            \"priority\": 0.8\n        },\n        \"constraint_template\": {\n            \"max_risk_score\": 0.7,\n            \"min_efficiency\": 0.6,\n            \"min_coverage\": 0.5,\n            \"budget_limit\": 100000.0\n        },\n        \"monitoring_template\": {\n            \"thresholds\": {\n                \"efficiency_deviation\": 0.1,\n                \"cost_deviation\": 0.2,\n                \"coverage_deviation\": 0.1,\n                \"risk_deviation\": 0.2\n            }\n        }\n    }\n\n@app.get(\"/api/v1/dashboards/process-optimization\", response_model=Dict[str, str])\nasync def get_process_optimization_dashboard():\n    \"\"\"\n    Generate process optimization dashboard\n    \"\"\"\n    try:\n        dashboard = Dashboard()\n        \n        # Get current process states\n        processes = dataset.get_all_processes()\n        \n        # Get optimization results\n        optimization_results = process_optimizer.optimize_process(\n            current_state=processes,\n            resources=dataset.get_all_resources(),\n            activities=[]  # Add actual activities\n        )\n        \n        # Get efficiency analysis\n        efficiency_analysis = process_optimizer.analyze_process_efficiency(\n            process_data=processes\n        )\n        \n        # Get predictions\n        predictions = process_optimizer.predict_process_performance(\n            historical_data=processes,\n            future_activities=[]  # Add planned activities\n        )\n        \n        # Generate dashboard\n        dashboard_path = dashboard.create_process_optimization_dashboard(\n            processes=processes,\n            optimization_results=optimization_results,\n            efficiency_analysis=efficiency_analysis,\n            predictions=predictions\n        )\n        \n        return {\n            \"dashboard_url\": f\"/dashboards/{Path(dashboard_path).name}\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate process optimization dashboard: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/quality/smart-check\", response_model=SmartQualityCheckResponse)\nasync def check_quality_smart(request: SmartQualityCheckRequest):\n    \"\"\"\n    Perform intelligent quality check on input data\n    \"\"\"\n    try:\n        # Basic quality check\n        results = quality_monitor.check_data_quality(\n            data=request.data,\n            data_type=request.data_type\n        )\n        \n        # Pattern analysis if requested\n        patterns = None\n        if request.analyze_patterns:\n            patterns = quality_monitor.detect_quality_patterns(request.data)\n            patterns = [\n                {\n                    \"pattern_id\": p.pattern_id,\n                    \"pattern_type\": p.pattern_type,\n                    \"confidence\": p.confidence,\n                    \"impact\": p.impact,\n                    \"description\": p.description,\n                    \"affected_metrics\": p.affected_metrics,\n                    \"recommendations\": p.recommendations\n                }\n                for p in patterns\n            ]\n            \n        return SmartQualityCheckResponse(\n            timestamp=results[\"timestamp\"],\n            data_type=results[\"data_type\"],\n            metrics=results[\"metrics\"],\n            patterns=patterns,\n            issues=results[\"issues\"],\n            recommendations=results[\"recommendations\"]\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.post(\"/api/v1/quality/smart-report\", response_model=SmartQualityReportResponse)\nasync def generate_quality_report_smart(request: SmartQualityReportRequest):\n    \"\"\"\n    Generate comprehensive quality report with intelligent analysis\n    \"\"\"\n    try:\n        # Generate basic report\n        report = quality_monitor.generate_quality_report(\n            start_time=request.start_time,\n            end_time=request.end_time\n        )\n        \n        # Add pattern analysis if requested\n        patterns = None\n        if request.include_patterns:\n            patterns = quality_monitor._analyze_pattern_distribution()\n            \n        # Add impact analysis if requested\n        impact_analysis = None\n        if request.include_impact:\n            impact_analysis = quality_monitor._analyze_quality_impact()\n            \n        return SmartQualityReportResponse(\n            generated_at=report[\"generated_at\"],\n            period=report[\"period\"],\n            summary=report[\"summary\"],\n            trends=report[\"trends\"],\n            patterns=patterns,\n            impact_analysis=impact_analysis,\n            alerts=report[\"alerts\"],\n            recommendations=report[\"recommendations\"],\n            visualizations=report[\"visualizations\"]\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/api/v1/quality/insights\", response_model=QualityInsightsResponse)\nasync def get_quality_insights():\n    \"\"\"\n    Get comprehensive quality insights with intelligent analysis\n    \"\"\"\n    try:\n        insights = quality_monitor.generate_quality_insights()\n        \n        return QualityInsightsResponse(\n            timestamp=datetime.now().isoformat(),\n            **insights\n        )\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/quality/train\")\nasync def train_quality_monitor():\n    \"\"\"\n    Train the quality pattern detector\n    \"\"\"\n    try:\n        # Get historical quality data\n        historical_data = quality_monitor.metrics_history\n        \n        if len(historical_data) < 10:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Insufficient historical data for training\"\n            )\n            \n        # Train pattern detector\n        quality_monitor.train_pattern_detector(historical_data)\n        \n        return {\n            \"status\": \"success\",\n            \"message\": \"Quality pattern detector trained successfully\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/optimize-process/smart\", response_model=SmartProcessOptimizationResponse)\nasync def optimize_process_smart(request: SmartProcessOptimizationRequest):\n    \"\"\"\n    Optimize process using intelligent pattern detection\n    \"\"\"\n    try:\n        # Detect patterns if requested\n        patterns = None\n        if request.analyze_patterns:\n            patterns = process_optimizer.detect_process_patterns(request.current_state)\n            patterns = [\n                {\n                    \"pattern_id\": p.pattern_id,\n                    \"pattern_type\": p.pattern_type,\n                    \"confidence\": p.confidence,\n                    \"impact\": p.impact,\n                    \"description\": p.description,\n                    \"affected_metrics\": p.affected_metrics,\n                    \"recommendations\": p.recommendations\n                }\n                for p in patterns\n            ]\n            \n        # Get optimization results\n        results = process_optimizer.optimize_process(\n            current_state=request.current_state,\n            resources=request.resources,\n            activities=request.activities,\n            constraints=request.constraints\n        )\n        \n        # Convert results to response format\n        response_data = {\n            \"results\": [\n                {\n                    \"process_id\": r.process_id,\n                    \"current_metrics\": {\n                        \"efficiency\": r.current_metrics.efficiency,\n                        \"cost_effectiveness\": r.current_metrics.cost_effectiveness,\n                        \"resource_utilization\": r.current_metrics.resource_utilization,\n                        \"exploration_coverage\": r.current_metrics.exploration_coverage,\n                        \"success_rate\": r.current_metrics.success_rate,\n                        \"risk_score\": r.current_metrics.risk_score\n                    },\n                    \"optimal_configuration\": r.optimal_configuration,\n                    \"expected_improvements\": r.expected_improvements,\n                    \"recommendations\": r.recommendations\n                }\n                for r in results\n            ],\n            \"improvements\": {\n                r.process_id: r.expected_improvements\n                for r in results\n            },\n            \"patterns\": patterns,\n            \"recommendations\": [\n                rec\n                for r in results\n                for rec in r.recommendations\n            ],\n            \"confidence\": np.mean([r.confidence for r in results])\n        }\n        \n        return SmartProcessOptimizationResponse(**response_data)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Smart process optimization failed: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/process/patterns\", response_model=ProcessPatternResponse)\nasync def get_process_patterns():\n    \"\"\"\n    Get detected process patterns and analysis\n    \"\"\"\n    try:\n        # Get pattern history\n        patterns = process_optimizer.pattern_history\n        \n        # Convert patterns to dict format\n        pattern_dicts = [\n            {\n                \"pattern_id\": p.pattern_id,\n                \"pattern_type\": p.pattern_type,\n                \"confidence\": p.confidence,\n                \"impact\": p.impact,\n                \"description\": p.description,\n                \"affected_metrics\": p.affected_metrics,\n                \"recommendations\": p.recommendations,\n                \"timestamp\": p.metadata[\"timestamp\"].isoformat()\n            }\n            for p in patterns\n        ]\n        \n        # Analyze trends\n        trend_analysis = {\n            \"pattern_types\": {},\n            \"impact_distribution\": {},\n            \"temporal_distribution\": {},\n            \"metric_impact\": {}\n        }\n        \n        for pattern in patterns:\n            # Pattern type distribution\n            trend_analysis[\"pattern_types\"][pattern.pattern_type] = \\\n                trend_analysis[\"pattern_types\"].get(pattern.pattern_type, 0) + 1\n                \n            # Impact distribution\n            impact_level = \"high\" if pattern.impact > 0.7 else \\\n                         \"medium\" if pattern.impact > 0.4 else \"low\"\n            trend_analysis[\"impact_distribution\"][impact_level] = \\\n                trend_analysis[\"impact_distribution\"].get(impact_level, 0) + 1\n                \n            # Temporal distribution\n            date = pattern.metadata[\"timestamp\"].date()\n            trend_analysis[\"temporal_distribution\"][str(date)] = \\\n                trend_analysis[\"temporal_distribution\"].get(str(date), 0) + 1\n                \n            # Metric impact\n            for metric in pattern.affected_metrics:\n                if metric not in trend_analysis[\"metric_impact\"]:\n                    trend_analysis[\"metric_impact\"][metric] = {\n                        \"total_patterns\": 0,\n                        \"high_impact_patterns\": 0\n                    }\n                trend_analysis[\"metric_impact\"][metric][\"total_patterns\"] += 1\n                if pattern.impact > 0.7:\n                    trend_analysis[\"metric_impact\"][metric][\"high_impact_patterns\"] += 1\n                    \n        # Calculate impact analysis\n        impact_analysis = {\n            \"overall_impact\": np.mean([p.impact for p in patterns]),\n            \"metric_impacts\": {},\n            \"trend_impact\": {}\n        }\n        \n        for metric in [\"efficiency\", \"cost_effectiveness\", \"resource_utilization\",\n                      \"exploration_coverage\", \"success_rate\", \"risk_score\"]:\n            metric_patterns = [\n                p for p in patterns\n                if metric in p.affected_metrics\n            ]\n            if metric_patterns:\n                impact_analysis[\"metric_impacts\"][metric] = np.mean([\n                    p.impact for p in metric_patterns\n                ])\n                \n        # Generate recommendations\n        recommendations = []\n        \n        # Add high-impact recommendations\n        high_impact_patterns = [p for p in patterns if p.impact > 0.7]\n        if high_impact_patterns:\n            recommendations.append(\n                f\"Address {len(high_impact_patterns)} high-impact patterns\"\n            )\n            \n        # Add metric-specific recommendations\n        for metric, impact in impact_analysis[\"metric_impacts\"].items():\n            if impact > 0.7:\n                recommendations.append(\n                    f\"Critical impact on {metric} - Prioritize improvements\"\n                )\n                \n        return ProcessPatternResponse(\n            patterns=pattern_dicts,\n            trend_analysis=trend_analysis,\n            impact_analysis=impact_analysis,\n            recommendations=recommendations\n        )\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to get process patterns: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/process/train\")\nasync def train_process_optimizer():\n    \"\"\"\n    Train the process pattern detector\n    \"\"\"\n    try:\n        # Get historical process data\n        historical_data = process_optimizer.historical_data\n        \n        if len(historical_data) < 10:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Insufficient historical data for training\"\n            )\n            \n        # Train pattern detector\n        process_optimizer.train_pattern_detector(historical_data)\n        \n        return {\n            \"status\": \"success\",\n            \"message\": \"Process pattern detector trained successfully\"\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to train process optimizer: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/analyze-process\", response_model=ProcessAnalysisResponse)\nasync def analyze_process(request: ProcessAnalysisRequest):\n    \"\"\"\n    Analyze process using intelligent analysis\n    \"\"\"\n    try:\n        # Analyze process\n        analysis_result = process_optimizer.process_analyzer.analyze_process(\n            process_data=request.process_data,\n            historical_data=request.historical_data\n        )\n        \n        # Convert result to response format\n        response_data = {\n            \"process_id\": analysis_result.process_id,\n            \"metrics\": analysis_result.metrics.__dict__,\n            \"patterns\": [\n                {\n                    \"pattern_id\": p.pattern_id,\n                    \"pattern_type\": p.pattern_type,\n                    \"confidence\": p.confidence,\n                    \"impact\": p.impact,\n                    \"description\": p.description,\n                    \"affected_metrics\": p.affected_metrics,\n                    \"recommendations\": p.recommendations\n                }\n                for p in analysis_result.patterns\n            ],\n            \"bottlenecks\": analysis_result.bottlenecks,\n            \"anomalies\": analysis_result.anomalies,\n            \"recommendations\": analysis_result.recommendations,\n            \"confidence\": analysis_result.confidence\n        }\n        \n        return ProcessAnalysisResponse(**response_data)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Process analysis failed: {str(e)}\"\n        )\n\nclass ProcessOptimizationPlanRequest(BaseModel):\n    \"\"\"\n    Request model for process optimization plan\n    \"\"\"\n    process_data: Dict[str, Any]\n    resources: Dict[str, Any]\n    activities: List[Dict[str, Any]]\n    constraints: Optional[Dict[str, Any]] = None\n    optimization_goals: Dict[str, float] = Field(\n        ...,\n        description=\"Target values for optimization metrics\"\n    )\n\nclass ProcessOptimizationPlanResponse(BaseModel):\n    \"\"\"\n    Response model for process optimization plan\n    \"\"\"\n    optimization_steps: List[Dict[str, Any]]\n    expected_improvements: Dict[str, float]\n    resource_requirements: Dict[str, Any]\n    timeline: Dict[str, Any]\n    risks: List[Dict[str, Any]]\n    recommendations: List[str]\n\n@app.post(\"/api/v1/optimize-process/plan\", response_model=ProcessOptimizationPlanResponse)\nasync def generate_optimization_plan(request: ProcessOptimizationPlanRequest):\n    \"\"\"\n    Generate optimization plan for process improvement\n    \"\"\"\n    try:\n        # Analyze current process state\n        analysis_result = process_optimizer.process_analyzer.analyze_process(\n            process_data=request.process_data\n        )\n        \n        # Generate optimization plan\n        optimization_plan = process_optimizer.generate_optimization_plan(\n            current_state=request.process_data,\n            analysis_result=analysis_result,\n            resources=request.resources,\n            activities=request.activities,\n            constraints=request.constraints,\n            optimization_goals=request.optimization_goals\n        )\n        \n        return ProcessOptimizationPlanResponse(**optimization_plan)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate optimization plan: {str(e)}\"\n        )\n\nclass ProcessMonitoringRequest(BaseModel):\n    \"\"\"\n    Request model for process monitoring\n    \"\"\"\n    process_data: Dict[str, Any]\n    optimal_config: Dict[str, Any]\n    thresholds: Optional[Dict[str, float]] = None\n    monitoring_interval: int = Field(60, description=\"Monitoring interval in seconds\")\n\nclass ProcessMonitoringResponse(BaseModel):\n    \"\"\"\n    Response model for process monitoring\n    \"\"\"\n    status: str\n    metrics: Dict[str, float]\n    deviations: Dict[str, Any]\n    alerts: List[Dict[str, Any]]\n    recommendations: List[str]\n\n@app.post(\"/api/v1/monitor-process/start\", response_model=ProcessMonitoringResponse)\nasync def start_process_monitoring(request: ProcessMonitoringRequest):\n    \"\"\"\n    Start real-time process monitoring\n    \"\"\"\n    try:\n        # Initialize monitoring\n        monitoring_result = process_optimizer.start_process_monitoring(\n            process_data=request.process_data,\n            optimal_config=request.optimal_config,\n            thresholds=request.thresholds,\n            monitoring_interval=request.monitoring_interval\n        )\n        \n        return ProcessMonitoringResponse(**monitoring_result)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to start process monitoring: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/monitor-process/stop\")\nasync def stop_process_monitoring():\n    \"\"\"\n    Stop process monitoring\n    \"\"\"\n    try:\n        process_optimizer.stop_process_monitoring()\n        return {\"status\": \"success\", \"message\": \"Process monitoring stopped\"}\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to stop process monitoring: {str(e)}\"\n        )\n\n@app.get(\"/api/v1/process/dashboard\", response_model=Dict[str, str])\nasync def get_process_dashboard():\n    \"\"\"\n    Generate process analysis and optimization dashboard\n    \"\"\"\n    try:\n        from minesight.core.dashboard.process_dashboard import ProcessDashboard\n        dashboard = ProcessDashboard()\n        \n        # Get current process state\n        current_state = process_optimizer.get_current_state()\n        \n        # Get analysis results\n        analysis_result = process_optimizer.process_analyzer.analyze_process(\n            process_data=current_state,\n            historical_data=process_optimizer.historical_data[-100:] if process_optimizer.historical_data else None\n        )\n        \n        # Get optimization results\n        optimization_results = process_optimizer.optimize_process(\n            current_state=current_state,\n            resources=dataset.get_all_resources(),\n            activities=dataset.get_active_activities()\n        )\n        \n        # Generate dashboard\n        dashboard_path = dashboard.create_process_dashboard(\n            current_state=current_state,\n            analysis_result=analysis_result.__dict__,\n            optimization_results=[r.__dict__ for r in optimization_results]\n        )\n        \n        return {\n            \"dashboard_url\": f\"/dashboards/{Path(dashboard_path).name}\",\n            \"generated_at\": datetime.now().isoformat(),\n            \"metrics_count\": len(analysis_result.metrics.__dict__),\n            \"patterns_count\": len(analysis_result.patterns),\n            \"bottlenecks_count\": len(analysis_result.bottlenecks),\n            \"alerts_count\": len(analysis_result.alerts)\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate process dashboard: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/process/analyze/deep\", response_model=DeepProcessAnalysisResponse)\nasync def analyze_process_deep(request: DeepProcessAnalysisRequest):\n    \"\"\"\n    Perform deep learning based process analysis\n    \"\"\"\n    try:\n        # Analyze process using deep learning\n        metrics = deep_analyzer.analyze_process(\n            request.process_data,\n            request.historical_data\n        )\n        \n        response = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"metrics\": metrics.__dict__,\n            \"recommendations\": []\n        }\n        \n        # Analyze patterns if requested\n        if request.analyze_patterns:\n            patterns = deep_analyzer.detect_process_patterns(request.process_data)\n            response[\"patterns\"] = patterns\n            response[\"recommendations\"].extend([\n                f\"Leverage pattern {p['pattern_id']} with confidence {p['confidence']:.2f}\"\n                for p in patterns\n            ])\n            \n        # Analyze bottlenecks if requested\n        if request.analyze_bottlenecks:\n            bottlenecks = deep_analyzer.identify_bottlenecks(request.process_data)\n            response[\"bottlenecks\"] = bottlenecks\n            for bottleneck in bottlenecks:\n                response[\"recommendations\"].extend(bottleneck[\"recommendations\"])\n                \n        # Predict optimization impact if requested\n        if request.predict_optimization:\n            optimization = deep_analyzer.predict_optimization_impact(\n                request.process_data,\n                {}  # No changes for baseline prediction\n            )\n            response[\"optimization_predictions\"] = optimization\n            \n            if optimization[\"efficiency_improvement\"] > 0.1:\n                response[\"recommendations\"].append(\n                    f\"Potential efficiency improvement of {optimization['efficiency_improvement']:.2%}\"\n                )\n                \n        return response\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Deep process analysis failed: {str(e)}\"\n        )\n\n@app.post(\"/api/v1/process/optimize/impact\", response_model=OptimizationImpactResponse)\nasync def predict_optimization_impact(request: OptimizationImpactRequest):\n    \"\"\"\n    Predict the impact of proposed process optimizations\n    \"\"\"\n    try:\n        # Predict optimization impact\n        impact = deep_analyzer.predict_optimization_impact(\n            request.current_state,\n            request.proposed_changes\n        )\n        \n        # Generate recommendations based on predictions\n        recommendations = []\n        \n        if impact[\"efficiency_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Expected efficiency improvement: {impact['efficiency_improvement']:.2%}\"\n            )\n            \n        if impact[\"resource_utilization_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Expected resource utilization improvement: {impact['resource_utilization_improvement']:.2%}\"\n            )\n            \n        if impact[\"performance_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Expected performance improvement: {impact['performance_improvement']:.2%}\"\n            )\n            \n        if impact[\"risk_reduction\"] > 0.1:\n            recommendations.append(\n                f\"Expected risk reduction: {impact['risk_reduction']:.2%}\"\n            )\n            \n        return {\n            \"improvements\": {\n                k: v for k, v in impact.items() if k != \"confidence\"\n            },\n            \"confidence\": impact[\"confidence\"],\n            \"recommendations\": recommendations\n        }\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Optimization impact prediction failed: {str(e)}\"\n        )\n\nif __name__ == \"__main__\":\n    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True) "}
{"type": "source_file", "path": "minesight/core/optimization/compression.py", "content": "\"\"\"\nModel compression utilities\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.nn.utils.prune as prune\nfrom typing import Dict, Any, List, Optional, Union, Tuple\nimport numpy as np\n\nclass ModelPruner:\n    \"\"\"Model pruning utility\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 config: Dict[str, Any]):\n        \"\"\"\n        Initialize model pruner\n        \n        Args:\n            model: Model to prune\n            config: Pruning configuration\n        \"\"\"\n        self.model = model\n        self.config = config\n        \n    def _get_parameters_to_prune(self) -> List[Tuple[nn.Module, str]]:\n        \"\"\"Get parameters to prune\"\"\"\n        parameters = []\n        for module in self.model.modules():\n            if isinstance(module, (nn.Linear, nn.Conv2d)):\n                parameters.append((module, 'weight'))\n        return parameters\n        \n    def prune_model(self,\n                    method: str = \"l1_unstructured\",\n                    amount: float = 0.3):\n        \"\"\"\n        Prune model\n        \n        Args:\n            method: Pruning method\n            amount: Amount to prune\n        \"\"\"\n        parameters = self._get_parameters_to_prune()\n        \n        if method == \"l1_unstructured\":\n            prune.global_unstructured(\n                parameters,\n                pruning_method=prune.L1Unstructured,\n                amount=amount\n            )\n        elif method == \"random_unstructured\":\n            prune.global_unstructured(\n                parameters,\n                pruning_method=prune.RandomUnstructured,\n                amount=amount\n            )\n        else:\n            raise ValueError(f\"Unknown pruning method: {method}\")\n            \n    def remove_pruning(self):\n        \"\"\"Remove pruning\"\"\"\n        for module, name in self._get_parameters_to_prune():\n            prune.remove(module, name)\n            \n    def get_sparsity(self) -> float:\n        \"\"\"Get model sparsity\"\"\"\n        total_params = 0\n        zero_params = 0\n        \n        for module, name in self._get_parameters_to_prune():\n            tensor = getattr(module, name)\n            total_params += tensor.nelement()\n            zero_params += (tensor == 0).sum().item()\n            \n        return zero_params / total_params if total_params > 0 else 0\n\nclass ModelQuantizer:\n    \"\"\"Model quantization utility\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 config: Dict[str, Any]):\n        \"\"\"\n        Initialize model quantizer\n        \n        Args:\n            model: Model to quantize\n            config: Quantization configuration\n        \"\"\"\n        self.model = model\n        self.config = config\n        \n    def prepare_for_quantization(self):\n        \"\"\"Prepare model for quantization\"\"\"\n        self.model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n        torch.quantization.prepare(self.model, inplace=True)\n        \n    def quantize_model(self,\n                      calibration_data: Optional[torch.Tensor] = None):\n        \"\"\"\n        Quantize model\n        \n        Args:\n            calibration_data: Data for calibration\n        \"\"\"\n        if calibration_data is not None:\n            with torch.no_grad():\n                self.model(calibration_data)\n                \n        torch.quantization.convert(self.model, inplace=True)\n        \n    def get_model_size(self) -> int:\n        \"\"\"Get model size in bytes\"\"\"\n        size = 0\n        for param in self.model.parameters():\n            size += param.nelement() * param.element_size()\n        return size\n\nclass KnowledgeDistiller:\n    \"\"\"Knowledge distillation utility\"\"\"\n    \n    def __init__(self,\n                 teacher: nn.Module,\n                 student: nn.Module,\n                 config: Dict[str, Any]):\n        \"\"\"\n        Initialize knowledge distiller\n        \n        Args:\n            teacher: Teacher model\n            student: Student model\n            config: Distillation configuration\n        \"\"\"\n        self.teacher = teacher\n        self.student = student\n        self.config = config\n        \n        # Set teacher to eval mode\n        self.teacher.eval()\n        \n    def compute_distillation_loss(self,\n                                student_logits: torch.Tensor,\n                                teacher_logits: torch.Tensor,\n                                labels: torch.Tensor,\n                                temperature: float = 2.0,\n                                alpha: float = 0.5) -> torch.Tensor:\n        \"\"\"\n        Compute distillation loss\n        \n        Args:\n            student_logits: Student model logits\n            teacher_logits: Teacher model logits\n            labels: True labels\n            temperature: Softmax temperature\n            alpha: Weight for distillation loss\n            \n        Returns:\n            Total loss\n        \"\"\"\n        # Compute soft targets\n        soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=1)\n        \n        # Compute losses\n        distillation_loss = nn.KLDivLoss(reduction='batchmean')(\n            nn.functional.log_softmax(student_logits / temperature, dim=1),\n            soft_targets\n        ) * (temperature ** 2)\n        \n        student_loss = nn.CrossEntropyLoss()(student_logits, labels)\n        \n        # Combine losses\n        total_loss = alpha * distillation_loss + (1 - alpha) * student_loss\n        \n        return total_loss\n        \n    def train_step(self,\n                   inputs: torch.Tensor,\n                   labels: torch.Tensor,\n                   optimizer: torch.optim.Optimizer) -> Dict[str, float]:\n        \"\"\"\n        Perform one training step\n        \n        Args:\n            inputs: Input data\n            labels: True labels\n            optimizer: Optimizer\n            \n        Returns:\n            Dictionary with losses\n        \"\"\"\n        # Get teacher predictions\n        with torch.no_grad():\n            teacher_outputs = self.teacher(inputs)\n            \n        # Get student predictions\n        student_outputs = self.student(inputs)\n        \n        # Compute loss\n        loss = self.compute_distillation_loss(\n            student_outputs['logits'],\n            teacher_outputs['logits'],\n            labels,\n            temperature=self.config.get('temperature', 2.0),\n            alpha=self.config.get('alpha', 0.5)\n        )\n        \n        # Update student\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        return {'loss': loss.item()}\n\ndef compress_model(model: nn.Module,\n                  config: Dict[str, Any]) -> nn.Module:\n    \"\"\"\n    Apply model compression techniques\n    \n    Args:\n        model: Model to compress\n        config: Compression configuration\n        \n    Returns:\n        Compressed model\n    \"\"\"\n    # Pruning\n    if config.get('pruning'):\n        pruner = ModelPruner(model, config['pruning'])\n        pruner.prune_model(\n            method=config['pruning'].get('method', 'l1_unstructured'),\n            amount=config['pruning'].get('amount', 0.3)\n        )\n        \n    # Quantization\n    if config.get('quantization'):\n        quantizer = ModelQuantizer(model, config['quantization'])\n        quantizer.prepare_for_quantization()\n        if config['quantization'].get('calibration_data') is not None:\n            quantizer.quantize_model(config['quantization']['calibration_data'])\n        else:\n            quantizer.quantize_model()\n            \n    return model\n\ndef create_compressed_model(teacher_model: nn.Module,\n                          compression_config: Dict[str, Any]) -> nn.Module:\n    \"\"\"\n    Create compressed model using knowledge distillation\n    \n    Args:\n        teacher_model: Teacher model\n        compression_config: Compression configuration\n        \n    Returns:\n        Compressed student model\n    \"\"\"\n    # Create student model\n    student_config = compression_config['student']\n    student_model = student_config['model_class'](**student_config['model_args'])\n    \n    # Apply compression techniques\n    student_model = compress_model(student_model, compression_config)\n    \n    # Setup distillation\n    distiller = KnowledgeDistiller(\n        teacher_model,\n        student_model,\n        compression_config.get('distillation', {})\n    )\n    \n    return student_model, distiller "}
{"type": "source_file", "path": "minesight/core/analysis/feature_analyzer.py", "content": "\"\"\"\nFeature analysis module for geological data\n\"\"\"\nfrom typing import Dict, List, Optional, Tuple\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import pearsonr\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\n\nclass FeatureAnalyzer:\n    \"\"\"Class for analyzing geological features and their relationships with mineral deposits\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer\"\"\"\n        self.scaler = StandardScaler()\n        \n    def analyze_feature_density(self,\n                              features: pd.DataFrame,\n                              feature_type: Optional[str] = None,\n                              radius_km: float = 5.0) -> Dict[str, float]:\n        \"\"\"\n        Analyze the density of geological features in the region\n        \n        Args:\n            features: DataFrame of geological features\n            feature_type: Optional specific feature type to analyze\n            radius_km: Radius for density calculation\n            \n        Returns:\n            Dictionary with density metrics\n        \"\"\"\n        if feature_type:\n            features = features[features['feature_type'] == feature_type]\n            \n        if features.empty:\n            return {\n                \"total_features\": 0,\n                \"avg_density\": 0.0,\n                \"max_density\": 0.0\n            }\n            \n        # Calculate area\n        lat_range = features['latitude'].max() - features['latitude'].min()\n        lon_range = features['longitude'].max() - features['longitude'].min()\n        area_km2 = lat_range * lon_range * 111  # Approximate conversion to km\n        \n        # Calculate densities\n        total = len(features)\n        avg_density = total / area_km2\n        \n        # Find maximum density using a sliding window\n        max_density = 0.0\n        for _, feature in features.iterrows():\n            nearby = self._get_nearby_features(\n                features,\n                feature['latitude'],\n                feature['longitude'],\n                radius_km\n            )\n            density = len(nearby) / (np.pi * radius_km ** 2)\n            max_density = max(max_density, density)\n            \n        return {\n            \"total_features\": total,\n            \"avg_density\": float(avg_density),\n            \"max_density\": float(max_density)\n        }\n    \n    def analyze_feature_clusters(self,\n                               features: pd.DataFrame,\n                               min_samples: int = 3,\n                               eps_km: float = 2.0) -> Dict[str, Any]:\n        \"\"\"\n        Identify clusters of geological features\n        \n        Args:\n            features: DataFrame of geological features\n            min_samples: Minimum samples for a cluster\n            eps_km: Maximum distance between samples in a cluster\n            \n        Returns:\n            Dictionary with cluster analysis results\n        \"\"\"\n        if features.empty:\n            return {\n                \"n_clusters\": 0,\n                \"clusters\": []\n            }\n            \n        # Prepare data for clustering\n        coords = features[['latitude', 'longitude']].values\n        coords_scaled = self.scaler.fit_transform(coords)\n        \n        # Perform clustering\n        clustering = DBSCAN(\n            eps=eps_km/111,  # Convert km to approximate degrees\n            min_samples=min_samples\n        ).fit(coords_scaled)\n        \n        # Analyze clusters\n        labels = clustering.labels_\n        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n        \n        clusters = []\n        for label in range(n_clusters):\n            mask = labels == label\n            cluster_points = coords[mask]\n            \n            cluster_info = {\n                \"center\": {\n                    \"latitude\": float(np.mean(cluster_points[:, 0])),\n                    \"longitude\": float(np.mean(cluster_points[:, 1]))\n                },\n                \"size\": int(np.sum(mask)),\n                \"radius_km\": float(np.max(\n                    self._calculate_distances(\n                        cluster_points[:, 0],\n                        cluster_points[:, 1],\n                        np.mean(cluster_points[:, 0]),\n                        np.mean(cluster_points[:, 1])\n                    )\n                ))\n            }\n            clusters.append(cluster_info)\n            \n        return {\n            \"n_clusters\": n_clusters,\n            \"clusters\": clusters\n        }\n    \n    def analyze_deposit_correlation(self,\n                                  features: pd.DataFrame,\n                                  deposits: pd.DataFrame,\n                                  radius_km: float = 5.0) -> Dict[str, float]:\n        \"\"\"\n        Analyze correlation between geological features and mineral deposits\n        \n        Args:\n            features: DataFrame of geological features\n            deposits: DataFrame of mineral deposits\n            radius_km: Radius for correlation analysis\n            \n        Returns:\n            Dictionary with correlation metrics\n        \"\"\"\n        if features.empty or deposits.empty:\n            return {\n                \"feature_deposit_correlation\": 0.0,\n                \"deposit_density_correlation\": 0.0\n            }\n            \n        # Calculate feature densities around deposits\n        deposit_densities = []\n        random_densities = []\n        \n        for _, deposit in deposits.iterrows():\n            # Count features near deposit\n            nearby_features = self._get_nearby_features(\n                features,\n                deposit['latitude'],\n                deposit['longitude'],\n                radius_km\n            )\n            deposit_densities.append(len(nearby_features))\n            \n            # Count features at random location\n            random_lat = np.random.uniform(\n                features['latitude'].min(),\n                features['latitude'].max()\n            )\n            random_lon = np.random.uniform(\n                features['longitude'].min(),\n                features['longitude'].max()\n            )\n            random_nearby = self._get_nearby_features(\n                features,\n                random_lat,\n                random_lon,\n                radius_km\n            )\n            random_densities.append(len(random_nearby))\n            \n        # Calculate correlations\n        feature_deposit_corr, _ = pearsonr(deposit_densities, random_densities)\n        \n        # Calculate correlation with deposit size/grade if available\n        density_corr = 0.0\n        if 'size' in deposits.columns:\n            density_corr, _ = pearsonr(\n                deposit_densities,\n                deposits['size'].map({'small': 1, 'medium': 2, 'large': 3})\n            )\n            \n        return {\n            \"feature_deposit_correlation\": float(feature_deposit_corr),\n            \"deposit_density_correlation\": float(density_corr)\n        }\n    \n    def _get_nearby_features(self,\n                           features: pd.DataFrame,\n                           latitude: float,\n                           longitude: float,\n                           radius_km: float) -> pd.DataFrame:\n        \"\"\"Get features within specified radius\"\"\"\n        distances = self._calculate_distances(\n            features['latitude'],\n            features['longitude'],\n            latitude,\n            longitude\n        )\n        return features[distances <= radius_km]\n    \n    def _calculate_distances(self,\n                           lat1: np.ndarray,\n                           lon1: np.ndarray,\n                           lat2: float,\n                           lon2: float) -> np.ndarray:\n        \"\"\"Calculate distances using Haversine formula\"\"\"\n        R = 6371  # Earth's radius in kilometers\n        \n        lat1_rad = np.radians(lat1)\n        lon1_rad = np.radians(lon1)\n        lat2_rad = np.radians(lat2)\n        lon2_rad = np.radians(lon2)\n        \n        dlat = lat2_rad - lat1_rad\n        dlon = lon2_rad - lon1_rad\n        \n        a = np.sin(dlat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2)**2\n        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n        \n        return R * c "}
{"type": "source_file", "path": "minesight/core/reporting/report_generator.py", "content": "\"\"\"\nReport generation module for mineral exploration analysis\n\"\"\"\nfrom typing import Dict, Any, Optional, List\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom datetime import datetime\nfrom reportlab.lib import colors\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\nfrom reportlab.lib.units import inch\n\nclass ReportGenerator:\n    \"\"\"Class for generating comprehensive exploration reports\"\"\"\n    \n    def __init__(self, output_dir: str = \"reports\"):\n        \"\"\"\n        Initialize the report generator\n        \n        Args:\n            output_dir: Directory for saving generated reports\n        \"\"\"\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.styles = getSampleStyleSheet()\n        self._setup_custom_styles()\n        \n    def generate_exploration_report(self,\n                                  site_info: Dict[str, Any],\n                                  prediction_results: Dict[str, Any],\n                                  risk_assessment: Dict[str, Any],\n                                  feature_analysis: Dict[str, Any],\n                                  time_analysis: Dict[str, Any],\n                                  include_visualizations: bool = True) -> str:\n        \"\"\"\n        Generate comprehensive exploration report\n        \n        Args:\n            site_info: Site information\n            prediction_results: Prediction analysis results\n            risk_assessment: Risk assessment results\n            feature_analysis: Feature analysis results\n            time_analysis: Time series analysis results\n            include_visualizations: Whether to include visualizations\n            \n        Returns:\n            Path to generated report\n        \"\"\"\n        # Create report filename\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"exploration_report_{timestamp}.pdf\"\n        file_path = self.output_dir / filename\n        \n        # Create document\n        doc = SimpleDocTemplate(\n            str(file_path),\n            pagesize=letter,\n            rightMargin=72,\n            leftMargin=72,\n            topMargin=72,\n            bottomMargin=72\n        )\n        \n        # Build report content\n        story = []\n        \n        # Add title\n        story.extend(self._create_title_section())\n        \n        # Add executive summary\n        story.extend(self._create_executive_summary(\n            prediction_results,\n            risk_assessment\n        ))\n        \n        # Add site information\n        story.extend(self._create_site_information_section(site_info))\n        \n        # Add prediction results\n        story.extend(self._create_prediction_section(prediction_results))\n        \n        # Add risk assessment\n        story.extend(self._create_risk_assessment_section(\n            risk_assessment,\n            include_visualizations\n        ))\n        \n        # Add feature analysis\n        story.extend(self._create_feature_analysis_section(\n            feature_analysis,\n            include_visualizations\n        ))\n        \n        # Add time analysis\n        story.extend(self._create_time_analysis_section(\n            time_analysis,\n            include_visualizations\n        ))\n        \n        # Add recommendations\n        story.extend(self._create_recommendations_section(\n            prediction_results,\n            risk_assessment,\n            time_analysis\n        ))\n        \n        # Build PDF\n        doc.build(story)\n        \n        return str(file_path)\n    \n    def _setup_custom_styles(self):\n        \"\"\"Setup custom paragraph styles\"\"\"\n        self.styles.add(ParagraphStyle(\n            name='CustomTitle',\n            parent=self.styles['Title'],\n            fontSize=24,\n            spaceAfter=30\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='CustomHeading1',\n            parent=self.styles['Heading1'],\n            fontSize=18,\n            spaceAfter=12\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='CustomHeading2',\n            parent=self.styles['Heading2'],\n            fontSize=14,\n            spaceAfter=8\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='CustomBody',\n            parent=self.styles['Normal'],\n            fontSize=11,\n            spaceAfter=8\n        ))\n    \n    def _create_title_section(self) -> List:\n        \"\"\"Create report title section\"\"\"\n        story = []\n        \n        title = Paragraph(\n            \"Mineral Exploration Analysis Report\",\n            self.styles['CustomTitle']\n        )\n        story.append(title)\n        \n        date = Paragraph(\n            f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n            self.styles['CustomBody']\n        )\n        story.append(date)\n        \n        story.append(Spacer(1, 30))\n        return story\n    \n    def _create_executive_summary(self,\n                                prediction_results: Dict[str, Any],\n                                risk_assessment: Dict[str, Any]) -> List:\n        \"\"\"Create executive summary section\"\"\"\n        story = []\n        \n        story.append(Paragraph(\n            \"Executive Summary\",\n            self.styles['CustomHeading1']\n        ))\n        \n        # Summary text\n        summary = [\n            \"This report presents a comprehensive analysis of the exploration site, \",\n            f\"with a mineral deposit probability of {prediction_results['probability']:.1%} \",\n            f\"(confidence: {prediction_results['confidence']:.1%}). \",\n            f\"The overall risk assessment indicates a {risk_assessment['overall_risk']:.1%} risk level.\"\n        ]\n        \n        story.append(Paragraph(\n            \"\".join(summary),\n            self.styles['CustomBody']\n        ))\n        \n        story.append(Spacer(1, 12))\n        return story\n    \n    def _create_site_information_section(self,\n                                       site_info: Dict[str, Any]) -> List:\n        \"\"\"Create site information section\"\"\"\n        story = []\n        \n        story.append(Paragraph(\n            \"Site Information\",\n            self.styles['CustomHeading1']\n        ))\n        \n        # Create site info table\n        data = [\n            [\"Parameter\", \"Value\"],\n            [\"Latitude\", f\"{site_info['latitude']:.6f}\"],\n            [\"Longitude\", f\"{site_info['longitude']:.6f}\"]\n        ]\n        \n        # Add additional site properties\n        for key, value in site_info.items():\n            if key not in ['latitude', 'longitude']:\n                data.append([key.replace('_', ' ').title(), str(value)])\n        \n        table = Table(data, colWidths=[2*inch, 4*inch])\n        table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, 0), 12),\n            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n            ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n            ('FONTSIZE', (0, 1), (-1, -1), 9),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black)\n        ]))\n        \n        story.append(table)\n        story.append(Spacer(1, 12))\n        return story\n    \n    def _create_prediction_section(self,\n                                 prediction_results: Dict[str, Any]) -> List:\n        \"\"\"Create prediction results section\"\"\"\n        story = []\n        \n        story.append(Paragraph(\n            \"Prediction Analysis\",\n            self.styles['CustomHeading1']\n        ))\n        \n        # Prediction results\n        story.append(Paragraph(\n            \"Mineral Deposit Prediction\",\n            self.styles['CustomHeading2']\n        ))\n        \n        results_text = [\n            f\"Probability: {prediction_results['probability']:.1%}\\n\",\n            f\"Confidence: {prediction_results['confidence']:.1%}\\n\\n\",\n            \"Feature Importance:\\n\"\n        ]\n        \n        for feature, importance in prediction_results['feature_importance'].items():\n            results_text.append(f\"- {feature}: {importance:.2%}\\n\")\n        \n        story.append(Paragraph(\n            \"\".join(results_text),\n            self.styles['CustomBody']\n        ))\n        \n        story.append(Spacer(1, 12))\n        return story\n    \n    def _create_risk_assessment_section(self,\n                                      risk_assessment: Dict[str, Any],\n                                      include_visualizations: bool) -> List:\n        \"\"\"Create risk assessment section\"\"\"\n        story = []\n        \n        story.append(Paragraph(\n            \"Risk Assessment\",\n            self.styles['CustomHeading1']\n        ))\n        \n        # Risk scores\n        data = [\n            [\"Risk Category\", \"Score\"],\n            [\"Overall Risk\", f\"{risk_assessment['overall_risk']:.1%}\"],\n            [\"Geological Risk\", f\"{risk_assessment['geological_risk']:.1%}\"],\n            [\"Environmental Risk\", f\"{risk_assessment['environmental_risk']:.1%}\"],\n            [\"Technical Risk\", f\"{risk_assessment['technical_risk']:.1%}\"],\n            [\"Economic Risk\", f\"{risk_assessment['economic_risk']:.1%}\"]\n        ]\n        \n        table = Table(data, colWidths=[3*inch, 3*inch])\n        table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, 0), 12),\n            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n            ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n            ('FONTSIZE', (0, 1), (-1, -1), 9),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black)\n        ]))\n        \n        story.append(table)\n        \n        if include_visualizations:\n            # Create risk radar chart\n            self._create_risk_radar_chart(risk_assessment)\n            story.append(Image(\n                \"temp_risk_radar.png\",\n                width=6*inch,\n                height=4*inch\n            ))\n            Path(\"temp_risk_radar.png\").unlink()\n        \n        story.append(Spacer(1, 12))\n        return story\n    \n    def _create_feature_analysis_section(self,\n                                       feature_analysis: Dict[str, Any],\n                                       include_visualizations: bool) -> List:\n        \"\"\"Create feature analysis section\"\"\"\n        story = []\n        \n        story.append(Paragraph(\n            \"Feature Analysis\",\n            self.styles['CustomHeading1']\n        ))\n        \n        # Density metrics\n        story.append(Paragraph(\n            \"Feature Density\",\n            self.styles['CustomHeading2']\n        ))\n        \n        density_text = []\n        for metric, value in feature_analysis['density_metrics'].items():\n            density_text.append(f\"- {metric}: {value:.2f}\\n\")\n        \n        story.append(Paragraph(\n            \"\".join(density_text),\n            self.styles['CustomBody']\n        ))\n        \n        # Cluster analysis\n        story.append(Paragraph(\n            \"Cluster Analysis\",\n            self.styles['CustomHeading2']\n        ))\n        \n        cluster_text = [\n            f\"Number of clusters: {feature_analysis['cluster_analysis']['n_clusters']}\\n\",\n            f\"Average cluster size: {feature_analysis['cluster_analysis']['avg_cluster_size']:.2f}\\n\"\n        ]\n        \n        story.append(Paragraph(\n            \"\".join(cluster_text),\n            self.styles['CustomBody']\n        ))\n        \n        story.append(Spacer(1, 12))\n        return story\n    \n    def _create_time_analysis_section(self,\n                                    time_analysis: Dict[str, Any],\n                                    include_visualizations: bool) -> List:\n        \"\"\"Create time series analysis section\"\"\"\n        story = []\n        \n        story.append(Paragraph(\n            \"Time Series Analysis\",\n            self.styles['CustomHeading1']\n        ))\n        \n        # Discovery trends\n        story.append(Paragraph(\n            \"Discovery Trends\",\n            self.styles['CustomHeading2']\n        ))\n        \n        trends_text = [\n            f\"Total discoveries: {time_analysis['total_discoveries']}\\n\",\n            f\"Discovery rate: {time_analysis['discovery_rate']:.2f} per day\\n\",\n            f\"Trend direction: {time_analysis['trend_direction']}\\n\"\n        ]\n        \n        story.append(Paragraph(\n            \"\".join(trends_text),\n            self.styles['CustomBody']\n        ))\n        \n        if include_visualizations and time_analysis.get('forecast'):\n            # Create time series plot\n            self._create_time_series_plot(time_analysis)\n            story.append(Image(\n                \"temp_time_series.png\",\n                width=6*inch,\n                height=4*inch\n            ))\n            Path(\"temp_time_series.png\").unlink()\n        \n        story.append(Spacer(1, 12))\n        return story\n    \n    def _create_recommendations_section(self,\n                                      prediction_results: Dict[str, Any],\n                                      risk_assessment: Dict[str, Any],\n                                      time_analysis: Dict[str, Any]) -> List:\n        \"\"\"Create recommendations section\"\"\"\n        story = []\n        \n        story.append(Paragraph(\n            \"Recommendations\",\n            self.styles['CustomHeading1']\n        ))\n        \n        recommendations = []\n        \n        # Prediction-based recommendations\n        if prediction_results['probability'] > 0.7:\n            recommendations.append(\n                \"High mineral potential - Proceed with detailed exploration\"\n            )\n        elif prediction_results['probability'] > 0.4:\n            recommendations.append(\n                \"Moderate potential - Consider preliminary exploration\"\n            )\n        else:\n            recommendations.append(\n                \"Low potential - Review site selection criteria\"\n            )\n        \n        # Risk-based recommendations\n        if risk_assessment['overall_risk'] > 0.7:\n            recommendations.append(\n                \"High risk level - Implement comprehensive risk mitigation\"\n            )\n        elif risk_assessment['overall_risk'] > 0.4:\n            recommendations.append(\n                \"Moderate risk - Develop targeted risk management strategies\"\n            )\n        \n        # Time analysis recommendations\n        if time_analysis['trend_direction'] == \"increasing\":\n            recommendations.append(\n                \"Positive trend - Consider expanding operations\"\n            )\n        elif time_analysis['trend_direction'] == \"decreasing\":\n            recommendations.append(\n                \"Declining trend - Review and optimize strategies\"\n            )\n        \n        # Create bullet points\n        for recommendation in recommendations:\n            story.append(Paragraph(\n                f\" {recommendation}\",\n                self.styles['CustomBody']\n            ))\n        \n        story.append(Spacer(1, 12))\n        return story\n    \n    def _create_risk_radar_chart(self, risk_assessment: Dict[str, Any]):\n        \"\"\"Create radar chart for risk visualization\"\"\"\n        # Prepare data\n        categories = ['Geological', 'Environmental', 'Technical', 'Economic']\n        values = [\n            risk_assessment['geological_risk'],\n            risk_assessment['environmental_risk'],\n            risk_assessment['technical_risk'],\n            risk_assessment['economic_risk']\n        ]\n        \n        # Create radar chart\n        angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False)\n        values = np.concatenate((values, [values[0]]))  # complete the polygon\n        angles = np.concatenate((angles, [angles[0]]))  # complete the polygon\n        \n        fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(projection='polar'))\n        ax.plot(angles, values)\n        ax.fill(angles, values, alpha=0.25)\n        ax.set_xticks(angles[:-1])\n        ax.set_xticklabels(categories)\n        ax.set_title(\"Risk Assessment Radar Chart\")\n        \n        plt.savefig(\"temp_risk_radar.png\")\n        plt.close()\n    \n    def _create_time_series_plot(self, time_analysis: Dict[str, Any]):\n        \"\"\"Create time series plot\"\"\"\n        # Prepare data\n        dates = [pd.to_datetime(d['date']) for d in time_analysis['forecast']]\n        values = [d['predicted_discoveries'] for d in time_analysis['forecast']]\n        lower = [d['lower_bound'] for d in time_analysis['forecast']]\n        upper = [d['upper_bound'] for d in time_analysis['forecast']]\n        \n        # Create plot\n        plt.figure(figsize=(10, 6))\n        plt.plot(dates, values, label='Forecast')\n        plt.fill_between(dates, lower, upper, alpha=0.2, label='95% Confidence Interval')\n        plt.xlabel('Date')\n        plt.ylabel('Predicted Discoveries')\n        plt.title('Discovery Forecast')\n        plt.legend()\n        plt.grid(True)\n        \n        plt.savefig(\"temp_time_series.png\")\n        plt.close() "}
{"type": "source_file", "path": "minesight/core/optimization/process_optimizer.py", "content": "\"\"\"\nIntelligent process optimization system for mineral exploration\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Tuple\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom minesight.core.optimization.resource_optimizer import ResourceOptimizer\nfrom minesight.core.recommendation.smart_recommender import SmartRecommender\nfrom minesight.core.planning.exploration_planner import ExplorationPlanner\n\n@dataclass\nclass ProcessMetrics:\n    \"\"\"Process performance metrics\"\"\"\n    efficiency: float\n    cost_effectiveness: float\n    resource_utilization: float\n    exploration_coverage: float\n    success_rate: float\n    risk_score: float\n\n@dataclass\nclass OptimizationResult:\n    \"\"\"Process optimization result\"\"\"\n    process_id: str\n    current_metrics: ProcessMetrics\n    optimal_configuration: Dict[str, Any]\n    expected_improvements: Dict[str, float]\n    recommendations: List[str]\n    confidence: float\n\nclass ProcessOptimizationModel(nn.Module):\n    \"\"\"Neural network for process optimization\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int = 256):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU()\n        )\n        \n        self.process_head = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 6)  # [efficiency, cost, utilization, coverage, success, risk]\n        )\n        \n        self.impact_head = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 4)  # [performance_impact, cost_impact, time_impact, risk_impact]\n        )\n\nclass ProcessOptimizer:\n    \"\"\"Intelligent process optimization system\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the process optimizer\"\"\"\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model = None\n        self.scaler = StandardScaler()\n        self.importance_model = RandomForestRegressor(n_estimators=100)\n        self.historical_data = []\n        \n        # Initialize sub-components\n        self.resource_optimizer = ResourceOptimizer()\n        self.recommender = SmartRecommender()\n        self.planner = ExplorationPlanner()\n        \n    def optimize_process(self,\n                        current_state: Dict[str, Any],\n                        resources: Dict[str, Any],\n                        activities: List[Dict[str, Any]],\n                        constraints: Optional[Dict[str, Any]] = None) -> List[OptimizationResult]:\n        \"\"\"\n        Optimize the entire exploration process\n        \n        Args:\n            current_state: Current process state\n            resources: Available resources\n            activities: Planned activities\n            constraints: Optional optimization constraints\n            \n        Returns:\n            List of optimization results\n        \"\"\"\n        # Calculate current metrics\n        current_metrics = self._calculate_process_metrics(current_state)\n        \n        # Optimize resources\n        resource_results = self.resource_optimizer.optimize_resources(\n            current_resources=resources,\n            activities=activities,\n            constraints=constraints\n        )\n        \n        # Get smart recommendations\n        recommendations = self.recommender.generate_recommendations(\n            exploration_data=current_state.get(\"exploration_data\", {}),\n            historical_data=current_state.get(\"historical_data\", {}),\n            current_state=current_state\n        )\n        \n        # Generate exploration plan\n        plan = self.planner.generate_exploration_plan(\n            prediction_results=current_state.get(\"predictions\", {}),\n            risk_assessment=current_state.get(\"risks\", {}),\n            available_resources=resources,\n            constraints=constraints or {}\n        )\n        \n        # Prepare optimization features\n        features = self._prepare_optimization_features(\n            current_state,\n            resource_results,\n            recommendations,\n            plan\n        )\n        \n        # Generate optimal process configuration\n        optimal_config = self._generate_optimal_configuration(\n            features,\n            constraints\n        )\n        \n        # Calculate expected improvements\n        improvements = self._calculate_expected_improvements(\n            current_metrics,\n            optimal_config\n        )\n        \n        # Generate process recommendations\n        results = []\n        for process_id, metrics in current_metrics.items():\n            result = OptimizationResult(\n                process_id=process_id,\n                current_metrics=metrics,\n                optimal_configuration=optimal_config[process_id],\n                expected_improvements=improvements[process_id],\n                recommendations=self._generate_recommendations(\n                    process_id,\n                    metrics,\n                    optimal_config[process_id],\n                    improvements[process_id]\n                ),\n                confidence=self._calculate_confidence(\n                    process_id,\n                    metrics,\n                    optimal_config[process_id]\n                )\n            )\n            results.append(result)\n        \n        return results\n    \n    def analyze_process_efficiency(self,\n                                process_data: Dict[str, Any],\n                                time_period: str = \"30d\") -> Dict[str, Any]:\n        \"\"\"\n        Analyze process efficiency\n        \n        Args:\n            process_data: Historical process data\n            time_period: Analysis time period\n            \n        Returns:\n            Process efficiency analysis results\n        \"\"\"\n        analysis_results = {\n            \"efficiency_metrics\": {},\n            \"performance_patterns\": {},\n            \"cost_analysis\": {},\n            \"optimization_opportunities\": []\n        }\n        \n        # Calculate efficiency metrics\n        for process_id, data in process_data.items():\n            metrics = self._analyze_process_efficiency(data, time_period)\n            analysis_results[\"efficiency_metrics\"][process_id] = metrics\n        \n        # Analyze performance patterns\n        analysis_results[\"performance_patterns\"] = self._analyze_performance_patterns(\n            process_data,\n            time_period\n        )\n        \n        # Perform cost analysis\n        analysis_results[\"cost_analysis\"] = self._analyze_process_costs(\n            process_data,\n            time_period\n        )\n        \n        # Identify optimization opportunities\n        analysis_results[\"optimization_opportunities\"] = self._identify_process_opportunities(\n            analysis_results[\"efficiency_metrics\"],\n            analysis_results[\"performance_patterns\"],\n            analysis_results[\"cost_analysis\"]\n        )\n        \n        return analysis_results\n    \n    def predict_process_performance(self,\n                                 historical_data: Dict[str, Any],\n                                 future_activities: List[Dict[str, Any]],\n                                 prediction_horizon: int = 30) -> Dict[str, Any]:\n        \"\"\"\n        Predict future process performance\n        \n        Args:\n            historical_data: Historical process data\n            future_activities: Planned future activities\n            prediction_horizon: Number of days to predict\n            \n        Returns:\n            Process performance predictions\n        \"\"\"\n        predictions = {\n            \"performance_metrics\": {},\n            \"resource_requirements\": {},\n            \"risk_factors\": {},\n            \"recommendations\": []\n        }\n        \n        # Predict performance metrics\n        predictions[\"performance_metrics\"] = self._predict_performance_metrics(\n            historical_data,\n            future_activities,\n            prediction_horizon\n        )\n        \n        # Calculate resource requirements\n        predictions[\"resource_requirements\"] = self._calculate_resource_requirements(\n            predictions[\"performance_metrics\"],\n            future_activities\n        )\n        \n        # Analyze risk factors\n        predictions[\"risk_factors\"] = self._analyze_prediction_risks(\n            predictions[\"performance_metrics\"],\n            historical_data\n        )\n        \n        # Generate recommendations\n        predictions[\"recommendations\"] = self._generate_prediction_recommendations(\n            predictions[\"performance_metrics\"],\n            predictions[\"resource_requirements\"],\n            predictions[\"risk_factors\"]\n        )\n        \n        return predictions\n    \n    def monitor_and_adjust_process(self,\n                                current_state: Dict[str, Any],\n                                optimal_config: Dict[str, Any],\n                                thresholds: Optional[Dict[str, float]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Monitor process performance and make real-time adjustments\n        \n        Args:\n            current_state: Current process state\n            optimal_config: Optimal process configuration\n            thresholds: Adjustment thresholds\n            \n        Returns:\n            Monitoring results and adjustments\n        \"\"\"\n        results = {\n            \"status\": \"nominal\",\n            \"deviations\": {},\n            \"adjustments\": {},\n            \"alerts\": []\n        }\n        \n        # Check for deviations\n        deviations = self._check_process_deviations(\n            current_state,\n            optimal_config,\n            thresholds\n        )\n        \n        if deviations:\n            results[\"status\"] = \"adjustment_needed\"\n            results[\"deviations\"] = deviations\n            \n            # Calculate necessary adjustments\n            results[\"adjustments\"] = self._calculate_process_adjustments(\n                current_state,\n                optimal_config,\n                deviations\n            )\n            \n            # Generate alerts for significant deviations\n            results[\"alerts\"] = self._generate_process_alerts(deviations)\n        \n        return results\n    \n    def _calculate_process_metrics(self,\n                                process_state: Dict[str, Any]) -> Dict[str, ProcessMetrics]:\n        \"\"\"Calculate current process metrics\"\"\"\n        metrics = {}\n        \n        for process_id, data in process_state.items():\n            metrics[process_id] = ProcessMetrics(\n                efficiency=self._calculate_efficiency(data),\n                cost_effectiveness=self._calculate_cost_effectiveness(data),\n                resource_utilization=self._calculate_resource_utilization(data),\n                exploration_coverage=self._calculate_exploration_coverage(data),\n                success_rate=self._calculate_success_rate(data),\n                risk_score=self._calculate_risk_score(data)\n            )\n        \n        return metrics\n    \n    def _prepare_optimization_features(self,\n                                    current_state: Dict[str, Any],\n                                    resource_results: List[Any],\n                                    recommendations: List[Any],\n                                    plan: Dict[str, Any]) -> torch.Tensor:\n        \"\"\"Prepare features for optimization model\"\"\"\n        features = []\n        \n        for process_id, data in current_state.items():\n            process_features = [\n                data.get(\"efficiency\", 0.0),\n                data.get(\"cost_effectiveness\", 0.0),\n                data.get(\"resource_utilization\", 0.0),\n                data.get(\"exploration_coverage\", 0.0),\n                data.get(\"success_rate\", 0.0),\n                data.get(\"risk_score\", 0.0),\n                len(resource_results),\n                len(recommendations),\n                len(plan.get(\"tasks\", [])),\n                data.get(\"complexity_score\", 0.0)\n            ]\n            features.append(process_features)\n        \n        return torch.tensor(features, dtype=torch.float32, device=self.device)\n    \n    def _generate_optimal_configuration(self,\n                                    features: torch.Tensor,\n                                    constraints: Optional[Dict[str, Any]] = None) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Generate optimal process configuration\"\"\"\n        self.model.eval()\n        with torch.no_grad():\n            process_config, impacts = self.model(features)\n        \n        # Convert to dictionary format\n        optimal_config = {}\n        for i, config in enumerate(process_config):\n            optimal_config[f\"process_{i}\"] = {\n                \"efficiency_target\": float(config[0]),\n                \"cost_target\": float(config[1]),\n                \"utilization_target\": float(config[2]),\n                \"coverage_target\": float(config[3]),\n                \"success_target\": float(config[4]),\n                \"risk_target\": float(config[5])\n            }\n        \n        return optimal_config\n    \n    def _calculate_expected_improvements(self,\n                                     current_metrics: Dict[str, ProcessMetrics],\n                                     optimal_config: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, float]]:\n        \"\"\"Calculate expected improvements from optimization\"\"\"\n        improvements = {}\n        \n        for process_id, metrics in current_metrics.items():\n            if process_id in optimal_config:\n                optimal = optimal_config[process_id]\n                improvements[process_id] = {\n                    \"efficiency_improvement\": optimal[\"efficiency_target\"] - metrics.efficiency,\n                    \"cost_improvement\": metrics.cost_effectiveness - optimal[\"cost_target\"],\n                    \"utilization_improvement\": optimal[\"utilization_target\"] - metrics.resource_utilization,\n                    \"coverage_improvement\": optimal[\"coverage_target\"] - metrics.exploration_coverage,\n                    \"success_improvement\": optimal[\"success_target\"] - metrics.success_rate,\n                    \"risk_reduction\": metrics.risk_score - optimal[\"risk_target\"]\n                }\n        \n        return improvements\n    \n    def _generate_recommendations(self,\n                               process_id: str,\n                               current_metrics: ProcessMetrics,\n                               optimal_config: Dict[str, Any],\n                               improvements: Dict[str, float]) -> List[str]:\n        \"\"\"Generate process optimization recommendations\"\"\"\n        recommendations = []\n        \n        # Efficiency recommendations\n        if improvements[\"efficiency_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Improve {process_id} efficiency through process optimization\"\n            )\n        \n        # Cost recommendations\n        if improvements[\"cost_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Implement cost reduction measures for {process_id}\"\n            )\n        \n        # Resource utilization recommendations\n        if improvements[\"utilization_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Optimize resource allocation for {process_id}\"\n            )\n        \n        # Coverage recommendations\n        if improvements[\"coverage_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Expand exploration coverage for {process_id}\"\n            )\n        \n        # Success rate recommendations\n        if improvements[\"success_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Implement measures to improve success rate for {process_id}\"\n            )\n        \n        # Risk recommendations\n        if improvements[\"risk_reduction\"] > 0.1:\n            recommendations.append(\n                f\"Implement risk mitigation measures for {process_id}\"\n            )\n        \n        return recommendations\n    \n    def _calculate_confidence(self,\n                           process_id: str,\n                           current_metrics: ProcessMetrics,\n                           optimal_config: Dict[str, Any]) -> float:\n        \"\"\"Calculate confidence score for optimization results\"\"\"\n        # Calculate based on historical accuracy and data quality\n        historical_accuracy = 0.8  # Placeholder\n        data_quality = self._assess_data_quality(current_metrics)\n        model_confidence = self._calculate_model_confidence(optimal_config)\n        \n        confidence = (historical_accuracy + data_quality + model_confidence) / 3\n        return float(confidence)\n    \n    def _assess_data_quality(self, metrics: ProcessMetrics) -> float:\n        \"\"\"Assess quality of process metrics data\"\"\"\n        # Check for missing or invalid values\n        metric_values = [\n            metrics.efficiency,\n            metrics.cost_effectiveness,\n            metrics.resource_utilization,\n            metrics.exploration_coverage,\n            metrics.success_rate,\n            metrics.risk_score\n        ]\n        \n        valid_values = [v for v in metric_values if 0 <= v <= 1]\n        return len(valid_values) / len(metric_values)\n    \n    def _calculate_model_confidence(self, config: Dict[str, Any]) -> float:\n        \"\"\"Calculate model prediction confidence\"\"\"\n        # Implement confidence calculation based on model uncertainty\n        return 0.8  # Placeholder "}
{"type": "source_file", "path": "minesight/core/quality/data_quality_monitor.py", "content": "\"\"\"\nData quality monitoring system for MineSight\n\"\"\"\nfrom typing import Dict, List, Optional, Union, Any\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom pathlib import Path\nimport json\nimport logging\nfrom dataclasses import dataclass\nfrom collections import deque\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport asyncio\nfrom scipy import stats\n\n@dataclass\nclass QualityMetric:\n    \"\"\"Data class for quality metrics\"\"\"\n    name: str\n    value: float\n    threshold: float\n    status: str\n    timestamp: datetime\n    details: Optional[Dict[str, Any]] = None\n\nclass DataQualityMonitor:\n    \"\"\"Real-time data quality monitoring system\"\"\"\n    \n    def __init__(self, config_path: Optional[str] = None):\n        \"\"\"\n        Initialize the data quality monitor\n        \n        Args:\n            config_path: Optional path to configuration file\n        \"\"\"\n        self.logger = logging.getLogger(__name__)\n        self.config = self._load_config(config_path)\n        self.metrics_history = deque(maxlen=1000)\n        self.alerts = []\n        self.is_monitoring = False\n        \n    async def start_monitoring(self):\n        \"\"\"Start real-time data quality monitoring\"\"\"\n        self.is_monitoring = True\n        while self.is_monitoring:\n            try:\n                # Monitor different data types\n                await self._monitor_stream_data()\n                await self._monitor_batch_data()\n                await self._monitor_system_metrics()\n                \n                # Generate alerts if needed\n                self._check_alerts()\n                \n                # Wait for next monitoring cycle\n                await asyncio.sleep(self.config.get(\"monitoring_interval\", 60))\n                \n            except Exception as e:\n                self.logger.error(f\"Error in monitoring cycle: {str(e)}\")\n                \n    def stop_monitoring(self):\n        \"\"\"Stop real-time monitoring\"\"\"\n        self.is_monitoring = False\n        \n    def check_data_quality(self, data: Union[pd.DataFrame, Dict], data_type: str) -> Dict[str, Any]:\n        \"\"\"\n        Check quality of input data\n        \n        Args:\n            data: Input data to check\n            data_type: Type of data\n            \n        Returns:\n            Quality check results\n        \"\"\"\n        if isinstance(data, dict):\n            data = pd.DataFrame([data])\n            \n        results = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"data_type\": data_type,\n            \"metrics\": {},\n            \"issues\": [],\n            \"recommendations\": []\n        }\n        \n        # Completeness check\n        completeness = self._check_completeness(data)\n        results[\"metrics\"][\"completeness\"] = completeness\n        \n        # Accuracy check\n        accuracy = self._check_accuracy(data)\n        results[\"metrics\"][\"accuracy\"] = accuracy\n        \n        # Consistency check\n        consistency = self._check_consistency(data)\n        results[\"metrics\"][\"consistency\"] = consistency\n        \n        # Timeliness check\n        timeliness = self._check_timeliness(data)\n        results[\"metrics\"][\"timeliness\"] = timeliness\n        \n        # Identify issues and generate recommendations\n        self._analyze_quality_results(results)\n        \n        # Store metrics in history\n        self._store_metrics(results[\"metrics\"])\n        \n        return results\n        \n    def generate_quality_report(self, start_time: Optional[datetime] = None,\n                              end_time: Optional[datetime] = None) -> Dict[str, Any]:\n        \"\"\"\n        Generate data quality report\n        \n        Args:\n            start_time: Optional start time for report period\n            end_time: Optional end time for report period\n            \n        Returns:\n            Quality report\n        \"\"\"\n        # Filter metrics by time range\n        metrics = self._get_metrics_in_range(start_time, end_time)\n        \n        report = {\n            \"generated_at\": datetime.now().isoformat(),\n            \"period\": {\n                \"start\": start_time.isoformat() if start_time else None,\n                \"end\": end_time.isoformat() if end_time else None\n            },\n            \"summary\": self._generate_quality_summary(metrics),\n            \"trends\": self._analyze_quality_trends(metrics),\n            \"alerts\": self._get_alerts_in_range(start_time, end_time),\n            \"recommendations\": self._generate_recommendations(metrics)\n        }\n        \n        # Add visualizations\n        report[\"visualizations\"] = {\n            \"quality_trends\": self._create_quality_trends_plot(metrics),\n            \"issue_distribution\": self._create_issue_distribution_plot(),\n            \"metric_correlations\": self._create_metric_correlations_plot(metrics)\n        }\n        \n        return report\n        \n    def export_quality_dashboard(self, output_path: Optional[str] = None) -> str:\n        \"\"\"\n        Export interactive quality monitoring dashboard\n        \n        Args:\n            output_path: Optional output path for dashboard\n            \n        Returns:\n            Path to generated dashboard\n        \"\"\"\n        if output_path is None:\n            output_path = f\"quality_dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n            \n        # Create dashboard layout\n        fig = make_subplots(\n            rows=3,\n            cols=2,\n            subplot_titles=(\n                \"Quality Metrics Trends\",\n                \"Issue Distribution\",\n                \"Metric Correlations\",\n                \"Alert History\",\n                \"Data Volume\",\n                \"System Health\"\n            )\n        )\n        \n        # Add quality metrics trends\n        metrics = list(self.metrics_history)\n        if metrics:\n            timestamps = [m[\"timestamp\"] for m in metrics]\n            for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n                values = [m[\"metrics\"][metric] for m in metrics]\n                fig.add_trace(\n                    go.Scatter(x=timestamps, y=values, name=metric.title()),\n                    row=1,\n                    col=1\n                )\n                \n        # Add issue distribution\n        issues = self._get_issue_distribution()\n        fig.add_trace(\n            go.Bar(x=list(issues.keys()), y=list(issues.values())),\n            row=1,\n            col=2\n        )\n        \n        # Add metric correlations\n        corr_matrix = self._calculate_metric_correlations()\n        fig.add_trace(\n            go.Heatmap(z=corr_matrix.values, x=corr_matrix.columns, y=corr_matrix.index),\n            row=2,\n            col=1\n        )\n        \n        # Add alert history\n        alert_counts = self._get_alert_history()\n        fig.add_trace(\n            go.Scatter(x=list(alert_counts.keys()), y=list(alert_counts.values())),\n            row=2,\n            col=2\n        )\n        \n        # Add data volume metrics\n        volume_metrics = self._get_data_volume_metrics()\n        fig.add_trace(\n            go.Bar(x=list(volume_metrics.keys()), y=list(volume_metrics.values())),\n            row=3,\n            col=1\n        )\n        \n        # Add system health metrics\n        health_metrics = self._get_system_health_metrics()\n        fig.add_trace(\n            go.Indicator(\n                mode=\"gauge+number\",\n                value=health_metrics[\"overall_health\"],\n                gauge={\"axis\": {\"range\": [0, 100]}},\n                title={\"text\": \"System Health\"}\n            ),\n            row=3,\n            col=2\n        )\n        \n        # Update layout\n        fig.update_layout(\n            height=1200,\n            showlegend=True,\n            title_text=\"Data Quality Monitoring Dashboard\"\n        )\n        \n        # Save dashboard\n        fig.write_html(output_path)\n        \n        return output_path\n        \n    async def _monitor_stream_data(self):\n        \"\"\"Monitor streaming data quality\"\"\"\n        # TODO: Implement stream data monitoring\n        pass\n        \n    async def _monitor_batch_data(self):\n        \"\"\"Monitor batch data quality\"\"\"\n        # TODO: Implement batch data monitoring\n        pass\n        \n    async def _monitor_system_metrics(self):\n        \"\"\"Monitor system health metrics\"\"\"\n        # TODO: Implement system metrics monitoring\n        pass\n        \n    def _check_completeness(self, data: pd.DataFrame) -> float:\n        \"\"\"\n        Check data completeness\n        \n        Args:\n            data: Input DataFrame\n            \n        Returns:\n            Completeness score between 0 and 1\n        \"\"\"\n        if data.empty:\n            return 0.0\n            \n        # Calculate percentage of non-null values\n        total_cells = data.shape[0] * data.shape[1]\n        non_null_cells = data.count().sum()\n        \n        completeness = non_null_cells / total_cells\n        \n        # Apply weights based on column importance\n        if \"column_weights\" in self.config:\n            weighted_completeness = 0.0\n            total_weight = 0.0\n            \n            for column, weight in self.config[\"column_weights\"].items():\n                if column in data.columns:\n                    non_null_ratio = data[column].count() / len(data)\n                    weighted_completeness += non_null_ratio * weight\n                    total_weight += weight\n                    \n            if total_weight > 0:\n                completeness = weighted_completeness / total_weight\n        \n        return float(completeness)\n        \n    def _check_accuracy(self, data: pd.DataFrame) -> float:\n        \"\"\"\n        Check data accuracy\n        \n        Args:\n            data: Input DataFrame\n            \n        Returns:\n            Accuracy score between 0 and 1\n        \"\"\"\n        if data.empty:\n            return 0.0\n            \n        accuracy_scores = []\n        \n        # Check value ranges\n        if \"value_ranges\" in self.config:\n            for column, ranges in self.config[\"value_ranges\"].items():\n                if column in data.columns:\n                    if isinstance(ranges, dict):\n                        min_val = ranges.get(\"min\")\n                        max_val = ranges.get(\"max\")\n                        \n                        if min_val is not None and max_val is not None:\n                            in_range = ((data[column] >= min_val) & \n                                      (data[column] <= max_val)).mean()\n                            accuracy_scores.append(in_range)\n        \n        # Check value patterns\n        if \"value_patterns\" in self.config:\n            for column, pattern in self.config[\"value_patterns\"].items():\n                if column in data.columns:\n                    matches = data[column].astype(str).str.match(pattern).mean()\n                    accuracy_scores.append(matches)\n        \n        # Check statistical outliers\n        numerical_columns = data.select_dtypes(include=[np.number]).columns\n        for column in numerical_columns:\n            z_scores = np.abs(stats.zscore(data[column].dropna()))\n            inliers = (z_scores < 3).mean()  # Using 3 sigma rule\n            accuracy_scores.append(inliers)\n        \n        # Calculate overall accuracy\n        return float(np.mean(accuracy_scores)) if accuracy_scores else 0.0\n        \n    def _check_consistency(self, data: pd.DataFrame) -> float:\n        \"\"\"\n        Check data consistency\n        \n        Args:\n            data: Input DataFrame\n            \n        Returns:\n            Consistency score between 0 and 1\n        \"\"\"\n        if data.empty:\n            return 0.0\n            \n        consistency_scores = []\n        \n        # Check value distributions\n        numerical_columns = data.select_dtypes(include=[np.number]).columns\n        for column in numerical_columns:\n            # Check for sudden changes in distribution\n            if len(self.metrics_history) > 0:\n                historical_data = pd.concat([\n                    pd.DataFrame(m[\"data\"]) for m in self.metrics_history\n                    if \"data\" in m\n                ])\n                \n                if not historical_data.empty and column in historical_data.columns:\n                    # Compare distributions using Kolmogorov-Smirnov test\n                    current_data = data[column].dropna()\n                    historical_data = historical_data[column].dropna()\n                    \n                    if len(current_data) > 0 and len(historical_data) > 0:\n                        _, p_value = stats.ks_2samp(current_data, historical_data)\n                        consistency_scores.append(min(1.0, p_value * 10))\n        \n        # Check categorical value consistency\n        categorical_columns = data.select_dtypes(include=[\"object\", \"category\"]).columns\n        for column in categorical_columns:\n            if len(self.metrics_history) > 0:\n                historical_data = pd.concat([\n                    pd.DataFrame(m[\"data\"]) for m in self.metrics_history\n                    if \"data\" in m\n                ])\n                \n                if not historical_data.empty and column in historical_data.columns:\n                    # Compare value sets\n                    current_values = set(data[column].dropna().unique())\n                    historical_values = set(historical_data[column].dropna().unique())\n                    \n                    if historical_values:\n                        overlap = len(current_values & historical_values)\n                        total = len(current_values | historical_values)\n                        consistency_scores.append(overlap / total)\n        \n        # Check relationship consistency\n        if \"relationships\" in self.config:\n            for relationship in self.config[\"relationships\"]:\n                col1 = relationship[\"column1\"]\n                col2 = relationship[\"column2\"]\n                rel_type = relationship[\"type\"]\n                \n                if col1 in data.columns and col2 in data.columns:\n                    if rel_type == \"correlation\":\n                        corr = data[[col1, col2]].corr().iloc[0, 1]\n                        consistency_scores.append(abs(corr))\n                    elif rel_type == \"ratio\":\n                        target_ratio = relationship.get(\"target\", 1.0)\n                        actual_ratio = (data[col1] / data[col2]).mean()\n                        ratio_diff = abs(1 - (actual_ratio / target_ratio))\n                        consistency_scores.append(max(0, 1 - ratio_diff))\n        \n        return float(np.mean(consistency_scores)) if consistency_scores else 0.0\n        \n    def _check_timeliness(self, data: pd.DataFrame) -> float:\n        \"\"\"\n        Check data timeliness\n        \n        Args:\n            data: Input DataFrame\n            \n        Returns:\n            Timeliness score between 0 and 1\n        \"\"\"\n        if data.empty:\n            return 0.0\n            \n        timeliness_scores = []\n        current_time = datetime.now()\n        \n        # Check timestamp columns\n        if \"timestamp_columns\" in self.config:\n            for column, settings in self.config[\"timestamp_columns\"].items():\n                if column in data.columns:\n                    max_delay = settings.get(\"max_delay\", 3600)  # Default 1 hour\n                    timestamps = pd.to_datetime(data[column])\n                    delays = (current_time - timestamps).total_seconds()\n                    \n                    # Calculate timeliness score based on delay\n                    timeliness = np.mean(np.clip(1 - (delays / max_delay), 0, 1))\n                    timeliness_scores.append(timeliness)\n        \n        # Check data freshness\n        if \"freshness_threshold\" in self.config:\n            threshold = self.config[\"freshness_threshold\"]\n            latest_timestamp = max(data[column].max() for column in data.columns\n                                 if data[column].dtype in [\"datetime64[ns]\", \"datetime64\"])\n            \n            if latest_timestamp:\n                delay = (current_time - latest_timestamp).total_seconds()\n                freshness = max(0, 1 - (delay / threshold))\n                timeliness_scores.append(freshness)\n        \n        # Check update frequency\n        if len(self.metrics_history) > 0:\n            last_update = self.metrics_history[-1][\"timestamp\"]\n            update_delay = (current_time - last_update).total_seconds()\n            \n            if \"update_frequency\" in self.config:\n                expected_frequency = self.config[\"update_frequency\"]\n                frequency_score = max(0, 1 - (update_delay / expected_frequency))\n                timeliness_scores.append(frequency_score)\n        \n        return float(np.mean(timeliness_scores)) if timeliness_scores else 0.0\n        \n    def _analyze_quality_results(self, results: Dict[str, Any]):\n        \"\"\"\n        Analyze quality check results and identify issues\n        \n        Args:\n            results: Quality check results\n        \"\"\"\n        metrics = results[\"metrics\"]\n        thresholds = self.config.get(\"quality_thresholds\", {\n            \"completeness\": 0.95,\n            \"accuracy\": 0.90,\n            \"consistency\": 0.85,\n            \"timeliness\": 0.90\n        })\n        \n        # Check each metric against threshold\n        for metric, value in metrics.items():\n            threshold = thresholds.get(metric, 0.9)\n            if value < threshold:\n                severity = \"high\" if value < threshold * 0.8 else \"medium\"\n                results[\"issues\"].append({\n                    \"metric\": metric,\n                    \"value\": value,\n                    \"threshold\": threshold,\n                    \"severity\": severity,\n                    \"description\": f\"{metric.title()} is below threshold ({value:.2%} < {threshold:.2%})\"\n                })\n                \n                # Generate recommendations\n                recommendation = self._generate_metric_recommendation(\n                    metric,\n                    value,\n                    threshold\n                )\n                if recommendation:\n                    results[\"recommendations\"].append(recommendation)\n        \n        # Check for combined issues\n        if all(metrics[m] < thresholds[m] for m in metrics):\n            results[\"issues\"].append({\n                \"metric\": \"overall\",\n                \"severity\": \"critical\",\n                \"description\": \"All quality metrics are below thresholds\"\n            })\n            results[\"recommendations\"].append({\n                \"priority\": \"high\",\n                \"description\": \"Consider pausing data ingestion and performing full data quality audit\"\n            })\n\n    def _generate_metric_recommendation(self,\n                                     metric: str,\n                                     value: float,\n                                     threshold: float) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Generate recommendation for improving a specific metric\n        \n        Args:\n            metric: Metric name\n            value: Current metric value\n            threshold: Metric threshold\n            \n        Returns:\n            Recommendation dictionary or None\n        \"\"\"\n        gap = threshold - value\n        priority = \"high\" if gap > 0.2 else \"medium\" if gap > 0.1 else \"low\"\n        \n        recommendations = {\n            \"completeness\": {\n                \"high\": \"Implement mandatory field validation and data collection procedures\",\n                \"medium\": \"Review data collection processes for missing values\",\n                \"low\": \"Monitor specific fields with missing values\"\n            },\n            \"accuracy\": {\n                \"high\": \"Review and update data validation rules and constraints\",\n                \"medium\": \"Investigate sources of inaccurate data\",\n                \"low\": \"Enhance data validation checks\"\n            },\n            \"consistency\": {\n                \"high\": \"Standardize data formats and implement strict validation\",\n                \"medium\": \"Review and align data transformation processes\",\n                \"low\": \"Monitor data patterns for potential inconsistencies\"\n            },\n            \"timeliness\": {\n                \"high\": \"Optimize data processing and transmission pipeline\",\n                \"medium\": \"Review and improve data update frequency\",\n                \"low\": \"Monitor data processing delays\"\n            }\n        }\n        \n        if metric in recommendations and priority in recommendations[metric]:\n            return {\n                \"metric\": metric,\n                \"priority\": priority,\n                \"description\": recommendations[metric][priority],\n                \"improvement_target\": f\"Improve {metric} from {value:.2%} to {threshold:.2%}\",\n                \"estimated_effort\": \"high\" if gap > 0.2 else \"medium\" if gap > 0.1 else \"low\"\n            }\n            \n        return None\n        \n    def _store_metrics(self, metrics: Dict[str, float]):\n        \"\"\"Store quality metrics in history\"\"\"\n        self.metrics_history.append({\n            \"timestamp\": datetime.now(),\n            \"metrics\": metrics\n        })\n        \n    def _get_metrics_in_range(self, start_time: Optional[datetime],\n                            end_time: Optional[datetime]) -> List[Dict[str, Any]]:\n        \"\"\"Get metrics within time range\"\"\"\n        metrics = list(self.metrics_history)\n        \n        if start_time:\n            metrics = [m for m in metrics if m[\"timestamp\"] >= start_time]\n        if end_time:\n            metrics = [m for m in metrics if m[\"timestamp\"] <= end_time]\n            \n        return metrics\n        \n    def _generate_quality_summary(self, metrics: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Generate summary of quality metrics\"\"\"\n        if not metrics:\n            return {}\n            \n        summary = {\n            \"total_checks\": len(metrics),\n            \"average_metrics\": {},\n            \"trend_analysis\": {},\n            \"issue_summary\": self._get_issue_distribution()\n        }\n        \n        # Calculate average metrics\n        for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n            values = [m[\"metrics\"][metric] for m in metrics]\n            summary[\"average_metrics\"][metric] = np.mean(values)\n            \n            # Calculate trend\n            if len(values) > 1:\n                trend = np.polyfit(range(len(values)), values, 1)[0]\n                summary[\"trend_analysis\"][metric] = {\n                    \"slope\": trend,\n                    \"direction\": \"improving\" if trend > 0 else \"degrading\"\n                }\n                \n        return summary\n        \n    def _analyze_quality_trends(self, metrics: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Analyze trends in quality metrics\"\"\"\n        if not metrics:\n            return {}\n            \n        trends = {}\n        for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n            values = [m[\"metrics\"][metric] for m in metrics]\n            timestamps = [m[\"timestamp\"] for m in metrics]\n            \n            # Calculate moving average\n            window_size = min(10, len(values))\n            ma = pd.Series(values).rolling(window=window_size).mean()\n            \n            # Calculate trend statistics\n            trends[metric] = {\n                \"current_value\": values[-1],\n                \"moving_average\": float(ma.iloc[-1]),\n                \"min_value\": min(values),\n                \"max_value\": max(values),\n                \"std_dev\": float(np.std(values)),\n                \"trend_direction\": \"improving\" if values[-1] > float(ma.iloc[-1]) else \"degrading\"\n            }\n            \n        return trends\n        \n    def _get_issue_distribution(self) -> Dict[str, int]:\n        \"\"\"Get distribution of quality issues\"\"\"\n        issues = {}\n        for metric in self.metrics_history:\n            for issue in metric.get(\"issues\", []):\n                issues[issue] = issues.get(issue, 0) + 1\n                \n        return dict(sorted(issues.items(), key=lambda x: x[1], reverse=True))\n        \n    def _calculate_metric_correlations(self) -> pd.DataFrame:\n        \"\"\"Calculate correlations between quality metrics\"\"\"\n        if not self.metrics_history:\n            return pd.DataFrame()\n            \n        # Extract metrics into DataFrame\n        metrics_data = []\n        for m in self.metrics_history:\n            metrics_data.append(m[\"metrics\"])\n            \n        df = pd.DataFrame(metrics_data)\n        \n        return df.corr()\n        \n    def _get_alert_history(self) -> Dict[datetime, int]:\n        \"\"\"Get history of quality alerts\"\"\"\n        alert_counts = {}\n        for alert in self.alerts:\n            date = alert[\"timestamp\"].date()\n            alert_counts[date] = alert_counts.get(date, 0) + 1\n            \n        return dict(sorted(alert_counts.items()))\n        \n    def _get_data_volume_metrics(self) -> Dict[str, int]:\n        \"\"\"Get metrics about data volume\"\"\"\n        # TODO: Implement data volume tracking\n        return {\n            \"deposits\": 1000,\n            \"features\": 5000,\n            \"samples\": 10000\n        }\n        \n    def _get_system_health_metrics(self) -> Dict[str, float]:\n        \"\"\"Get system health metrics\"\"\"\n        # TODO: Implement system health monitoring\n        return {\n            \"overall_health\": 95.0,\n            \"cpu_usage\": 45.0,\n            \"memory_usage\": 60.0,\n            \"storage_usage\": 55.0\n        }\n        \n    def _create_quality_trends_plot(self, metrics: List[Dict[str, Any]]) -> Dict:\n        \"\"\"Create quality trends visualization\"\"\"\n        if not metrics:\n            return {}\n            \n        fig = go.Figure()\n        \n        timestamps = [m[\"timestamp\"] for m in metrics]\n        for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n            values = [m[\"metrics\"][metric] for m in metrics]\n            fig.add_trace(\n                go.Scatter(x=timestamps, y=values, name=metric.title())\n            )\n            \n        fig.update_layout(\n            title=\"Quality Metrics Trends\",\n            xaxis_title=\"Time\",\n            yaxis_title=\"Score\",\n            yaxis_range=[0, 1]\n        )\n        \n        return fig.to_dict()\n        \n    def _create_issue_distribution_plot(self) -> Dict:\n        \"\"\"Create issue distribution visualization\"\"\"\n        issues = self._get_issue_distribution()\n        \n        fig = go.Figure(data=[\n            go.Bar(x=list(issues.keys()), y=list(issues.values()))\n        ])\n        \n        fig.update_layout(\n            title=\"Quality Issue Distribution\",\n            xaxis_title=\"Issue Type\",\n            yaxis_title=\"Count\"\n        )\n        \n        return fig.to_dict()\n        \n    def _create_metric_correlations_plot(self, metrics: List[Dict[str, Any]]) -> Dict:\n        \"\"\"Create metric correlations visualization\"\"\"\n        corr_matrix = self._calculate_metric_correlations()\n        \n        fig = go.Figure(data=[\n            go.Heatmap(\n                z=corr_matrix.values,\n                x=corr_matrix.columns,\n                y=corr_matrix.index,\n                colorscale=\"RdBu\"\n            )\n        ])\n        \n        fig.update_layout(\n            title=\"Metric Correlations\",\n            xaxis_title=\"Metric\",\n            yaxis_title=\"Metric\"\n        )\n        \n        return fig.to_dict()\n        \n    def _load_config(self, config_path: Optional[str]) -> Dict:\n        \"\"\"Load configuration from file\"\"\"\n        default_config = {\n            \"monitoring_interval\": 60,  # seconds\n            \"completeness_threshold\": 0.9,\n            \"accuracy_threshold\": 0.9,\n            \"consistency_threshold\": 0.9,\n            \"timeliness_threshold\": 0.9,\n            \"alert_thresholds\": {\n                \"critical\": 0.7,\n                \"warning\": 0.8\n            }\n        }\n        \n        if config_path:\n            try:\n                with open(config_path, 'r') as f:\n                    custom_config = json.load(f)\n                default_config.update(custom_config)\n            except Exception as e:\n                self.logger.warning(f\"Failed to load custom config: {str(e)}\")\n                \n        return default_config\n        \n    def _check_alerts(self):\n        \"\"\"Check for quality alerts\"\"\"\n        if not self.metrics_history:\n            return\n            \n        latest_metrics = self.metrics_history[-1]\n        \n        for metric, value in latest_metrics[\"metrics\"].items():\n            if value < self.config[\"alert_thresholds\"][\"critical\"]:\n                self._add_alert(\"critical\", f\"Critical {metric} issue: {value:.2f}\")\n            elif value < self.config[\"alert_thresholds\"][\"warning\"]:\n                self._add_alert(\"warning\", f\"Warning: {metric} below threshold: {value:.2f}\")\n                \n    def _add_alert(self, level: str, message: str):\n        \"\"\"Add quality alert\"\"\"\n        self.alerts.append({\n            \"timestamp\": datetime.now(),\n            \"level\": level,\n            \"message\": message\n        })\n        \n        # Log alert\n        if level == \"critical\":\n            self.logger.error(message)\n        else:\n            self.logger.warning(message)\n            \n    def _get_alerts_in_range(self, start_time: Optional[datetime],\n                           end_time: Optional[datetime]) -> List[Dict[str, Any]]:\n        \"\"\"Get alerts within time range\"\"\"\n        alerts = self.alerts\n        \n        if start_time:\n            alerts = [a for a in alerts if a[\"timestamp\"] >= start_time]\n        if end_time:\n            alerts = [a for a in alerts if a[\"timestamp\"] <= end_time]\n            \n        return alerts "}
{"type": "source_file", "path": "minesight/core/optimization/smart_process_analyzer.py", "content": "\"\"\"\nIntelligent process analysis and optimization system with deep learning capabilities\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Tuple\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import IsolationForest, RandomForestRegressor\nfrom minesight.core.optimization.process_optimizer import ProcessMetrics, ProcessPattern\n\n@dataclass\nclass ProcessAnalysisMetrics:\n    \"\"\"Enhanced process analysis metrics\"\"\"\n    efficiency: float\n    cost_effectiveness: float\n    resource_utilization: float\n    exploration_coverage: float\n    success_rate: float\n    risk_score: float\n    optimization_potential: float\n    bottleneck_impact: float\n    pattern_significance: float\n    anomaly_severity: float\n\n@dataclass\nclass ProcessOptimizationPlan:\n    \"\"\"Process optimization plan\"\"\"\n    process_id: str\n    current_metrics: ProcessAnalysisMetrics\n    target_metrics: ProcessAnalysisMetrics\n    optimization_steps: List[Dict[str, Any]]\n    resource_requirements: Dict[str, Any]\n    timeline: Dict[str, Any]\n    expected_improvements: Dict[str, float]\n    risk_factors: List[Dict[str, Any]]\n    confidence: float\n\nclass DeepProcessAnalyzer(nn.Module):\n    \"\"\"Deep learning model for process analysis\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int = 128):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU()\n        )\n        self.pattern_detector = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 10)  # 10 pattern types\n        )\n        self.bottleneck_detector = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 5)  # 5 bottleneck types\n        )\n        self.optimization_predictor = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 6)  # 6 optimization metrics\n        )\n        \n    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"Forward pass\"\"\"\n        encoded = self.encoder(x)\n        patterns = torch.sigmoid(self.pattern_detector(encoded))\n        bottlenecks = torch.sigmoid(self.bottleneck_detector(encoded))\n        optimizations = torch.sigmoid(self.optimization_predictor(encoded))\n        return patterns, bottlenecks, optimizations\n\nclass SmartProcessAnalyzer:\n    \"\"\"Intelligent process analyzer with deep learning capabilities\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the smart process analyzer\"\"\"\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.deep_analyzer = DeepProcessAnalyzer(input_size=20).to(self.device)\n        self.scaler = StandardScaler()\n        self.anomaly_detector = IsolationForest(contamination=0.1)\n        self.historical_data = []\n        self.pattern_history = []\n        \n    def analyze_process(self,\n                       process_data: Dict[str, Any],\n                       historical_data: Optional[Dict[str, Any]] = None) -> ProcessAnalysisMetrics:\n        \"\"\"\n        Perform comprehensive process analysis using deep learning\n        \n        Args:\n            process_data: Current process data\n            historical_data: Optional historical data for comparison\n            \n        Returns:\n            Enhanced process analysis metrics\n        \"\"\"\n        # Prepare features\n        features = self._prepare_features(process_data)\n        \n        # Analyze using deep learning model\n        with torch.no_grad():\n            patterns, bottlenecks, optimizations = self.deep_analyzer(features)\n            \n        # Detect anomalies\n        anomalies = self._detect_anomalies(process_data)\n        \n        # Calculate enhanced metrics\n        metrics = ProcessAnalysisMetrics(\n            efficiency=float(optimizations[0]),\n            cost_effectiveness=float(optimizations[1]),\n            resource_utilization=float(optimizations[2]),\n            exploration_coverage=float(optimizations[3]),\n            success_rate=float(optimizations[4]),\n            risk_score=float(optimizations[5]),\n            optimization_potential=self._calculate_optimization_potential(optimizations),\n            bottleneck_impact=self._calculate_bottleneck_impact(bottlenecks),\n            pattern_significance=self._calculate_pattern_significance(patterns),\n            anomaly_severity=self._calculate_anomaly_severity(anomalies)\n        )\n        \n        # Update historical data\n        self._update_historical_data(process_data, metrics)\n        \n        return metrics\n        \n    def generate_optimization_plan(self,\n                                 process_data: Dict[str, Any],\n                                 current_metrics: ProcessAnalysisMetrics,\n                                 optimization_goals: Dict[str, float]) -> ProcessOptimizationPlan:\n        \"\"\"\n        Generate detailed process optimization plan\n        \n        Args:\n            process_data: Current process data\n            current_metrics: Current process metrics\n            optimization_goals: Target values for optimization\n            \n        Returns:\n            Detailed optimization plan\n        \"\"\"\n        # Calculate target metrics\n        target_metrics = self._calculate_target_metrics(current_metrics, optimization_goals)\n        \n        # Generate optimization steps\n        optimization_steps = self._generate_optimization_steps(\n            process_data,\n            current_metrics,\n            target_metrics\n        )\n        \n        # Calculate resource requirements\n        resource_requirements = self._calculate_resource_requirements(\n            optimization_steps\n        )\n        \n        # Generate timeline\n        timeline = self._generate_optimization_timeline(\n            optimization_steps,\n            resource_requirements\n        )\n        \n        # Calculate expected improvements\n        improvements = self._calculate_expected_improvements(\n            current_metrics,\n            target_metrics\n        )\n        \n        # Analyze risks\n        risk_factors = self._analyze_optimization_risks(\n            optimization_steps,\n            improvements\n        )\n        \n        # Calculate confidence\n        confidence = self._calculate_optimization_confidence(\n            current_metrics,\n            target_metrics,\n            risk_factors\n        )\n        \n        return ProcessOptimizationPlan(\n            process_id=process_data[\"process_id\"],\n            current_metrics=current_metrics,\n            target_metrics=target_metrics,\n            optimization_steps=optimization_steps,\n            resource_requirements=resource_requirements,\n            timeline=timeline,\n            expected_improvements=improvements,\n            risk_factors=risk_factors,\n            confidence=confidence\n        )\n        \n    def monitor_process(self,\n                       process_data: Dict[str, Any],\n                       optimal_config: Dict[str, Any],\n                       thresholds: Optional[Dict[str, float]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Monitor process performance in real-time\n        \n        Args:\n            process_data: Current process data\n            optimal_config: Optimal process configuration\n            thresholds: Optional monitoring thresholds\n            \n        Returns:\n            Monitoring results and alerts\n        \"\"\"\n        # Analyze current state\n        current_metrics = self.analyze_process(process_data)\n        \n        # Check for deviations\n        deviations = self._check_process_deviations(\n            current_metrics,\n            optimal_config,\n            thresholds\n        )\n        \n        # Generate alerts\n        alerts = self._generate_process_alerts(deviations)\n        \n        # Calculate adjustments\n        adjustments = self._calculate_process_adjustments(\n            current_metrics,\n            optimal_config,\n            deviations\n        )\n        \n        return {\n            \"status\": \"adjustment_needed\" if deviations else \"nominal\",\n            \"current_metrics\": current_metrics.__dict__,\n            \"deviations\": deviations,\n            \"alerts\": alerts,\n            \"recommended_adjustments\": adjustments\n        }\n        \n    def _prepare_features(self, data: Dict[str, Any]) -> torch.Tensor:\n        \"\"\"Prepare features for deep learning model\"\"\"\n        features = [\n            data.get(\"efficiency\", 0.0),\n            data.get(\"cost_effectiveness\", 0.0),\n            data.get(\"resource_utilization\", 0.0),\n            data.get(\"exploration_coverage\", 0.0),\n            data.get(\"success_rate\", 0.0),\n            data.get(\"risk_score\", 0.0),\n            data.get(\"process_complexity\", 0.0),\n            data.get(\"resource_availability\", 0.0),\n            data.get(\"time_constraints\", 0.0),\n            data.get(\"budget_constraints\", 0.0)\n        ]\n        # Add historical trends\n        if self.historical_data:\n            historical_features = self._calculate_historical_trends()\n            features.extend(historical_features)\n        else:\n            features.extend([0.0] * 10)  # Padding when no history\n            \n        return torch.tensor(features, dtype=torch.float32, device=self.device).unsqueeze(0)\n        \n    def _detect_anomalies(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Detect process anomalies using isolation forest\"\"\"\n        features = self._prepare_anomaly_features(data)\n        scores = self.anomaly_detector.fit_predict(features)\n        anomaly_scores = self.anomaly_detector.score_samples(features)\n        \n        anomalies = []\n        for i, (score, anomaly_score) in enumerate(zip(scores, anomaly_scores)):\n            if score == -1:  # Anomaly detected\n                anomalies.append({\n                    \"metric\": data.get(\"metric_names\", [])[i],\n                    \"score\": float(anomaly_score),\n                    \"severity\": \"high\" if anomaly_score < -0.8 else \"medium\",\n                    \"timestamp\": datetime.now().isoformat()\n                })\n                \n        return anomalies\n        \n    def _calculate_optimization_potential(self, optimizations: torch.Tensor) -> float:\n        \"\"\"Calculate overall optimization potential\"\"\"\n        weights = [0.3, 0.2, 0.15, 0.15, 0.1, 0.1]  # Importance weights\n        return float(torch.sum(optimizations * torch.tensor(weights, device=self.device)))\n        \n    def _calculate_bottleneck_impact(self, bottlenecks: torch.Tensor) -> float:\n        \"\"\"Calculate overall bottleneck impact\"\"\"\n        return float(torch.max(bottlenecks))  # Impact of most severe bottleneck\n        \n    def _calculate_pattern_significance(self, patterns: torch.Tensor) -> float:\n        \"\"\"Calculate overall pattern significance\"\"\"\n        return float(torch.mean(patterns))  # Average pattern significance\n        \n    def _calculate_anomaly_severity(self, anomalies: List[Dict[str, Any]]) -> float:\n        \"\"\"Calculate overall anomaly severity\"\"\"\n        if not anomalies:\n            return 0.0\n        return np.mean([\n            1.0 if a[\"severity\"] == \"high\" else 0.5\n            for a in anomalies\n        ])\n        \n    def _update_historical_data(self,\n                              process_data: Dict[str, Any],\n                              metrics: ProcessAnalysisMetrics):\n        \"\"\"Update historical data with new process data\"\"\"\n        self.historical_data.append({\n            \"timestamp\": datetime.now(),\n            \"process_data\": process_data,\n            \"metrics\": metrics.__dict__\n        })\n        \n        # Keep only last 100 entries\n        if len(self.historical_data) > 100:\n            self.historical_data = self.historical_data[-100:]\n            \n    def _calculate_historical_trends(self) -> List[float]:\n        \"\"\"Calculate historical trends for features\"\"\"\n        if len(self.historical_data) < 2:\n            return [0.0] * 10\n            \n        metrics = [\"efficiency\", \"cost_effectiveness\", \"resource_utilization\",\n                  \"exploration_coverage\", \"success_rate\", \"risk_score\",\n                  \"optimization_potential\", \"bottleneck_impact\",\n                  \"pattern_significance\", \"anomaly_severity\"]\n                  \n        trends = []\n        for metric in metrics:\n            values = [h[\"metrics\"][metric] for h in self.historical_data]\n            trend = np.polyfit(range(len(values)), values, 1)[0]\n            trends.append(float(trend))\n            \n        return trends "}
{"type": "source_file", "path": "minesight/core/validation/validators.py", "content": "\"\"\"\nData validation utilities\n\"\"\"\nfrom typing import Dict, Any, List, Optional\nimport pandas as pd\nimport numpy as np\nfrom pydantic import BaseModel, Field, validator\nfrom pathlib import Path\n\nclass DataValidationError(Exception):\n    \"\"\"Custom exception for data validation errors\"\"\"\n    pass\n\nclass GeologicalData(BaseModel):\n    \"\"\"Validation model for geological data\"\"\"\n    latitude: float = Field(..., ge=-90, le=90)\n    longitude: float = Field(..., ge=-180, le=180)\n    elevation: Optional[float] = Field(None, ge=-500, le=10000)\n    lithology: str\n    structure: Optional[str]\n    alteration: Optional[str]\n    \n    @validator('lithology')\n    def validate_lithology(cls, v):\n        \"\"\"Validate lithology values\"\"\"\n        valid_types = {\n            'granite', 'basalt', 'schist', 'gneiss', 'limestone',\n            'sandstone', 'shale', 'quartzite', 'marble', 'slate'\n        }\n        if v.lower() not in valid_types:\n            raise ValueError(f\"Invalid lithology type: {v}\")\n        return v.lower()\n\nclass GeophysicalData(BaseModel):\n    \"\"\"Validation model for geophysical data\"\"\"\n    magnetic: Optional[float]\n    gravity: Optional[float]\n    electromagnetic: Optional[float]\n    radiometric: Optional[float]\n    \n    @validator('*')\n    def validate_measurements(cls, v):\n        \"\"\"Validate measurement values\"\"\"\n        if v is not None and (v < -1e6 or v > 1e6):\n            raise ValueError(f\"Measurement value out of reasonable range: {v}\")\n        return v\n\ndef validate_deposits_file(file_path: Path) -> List[str]:\n    \"\"\"\n    Validate deposits data file\n    \n    Args:\n        file_path: Path to deposits file\n        \n    Returns:\n        List of validation warnings\n    \"\"\"\n    warnings = []\n    \n    try:\n        # Read file\n        if file_path.suffix == '.csv':\n            data = pd.read_csv(file_path)\n        elif file_path.suffix == '.parquet':\n            data = pd.read_parquet(file_path)\n        else:\n            raise DataValidationError(f\"Unsupported file format: {file_path.suffix}\")\n        \n        # Check required columns\n        required_columns = {'latitude', 'longitude', 'lithology'}\n        missing_columns = required_columns - set(data.columns)\n        if missing_columns:\n            raise DataValidationError(f\"Missing required columns: {missing_columns}\")\n        \n        # Validate each row\n        for idx, row in data.iterrows():\n            try:\n                GeologicalData(**row.to_dict())\n            except Exception as e:\n                warnings.append(f\"Row {idx}: {str(e)}\")\n        \n        # Check for duplicates\n        duplicates = data[data.duplicated(['latitude', 'longitude'])]\n        if not duplicates.empty:\n            warnings.append(f\"Found {len(duplicates)} duplicate locations\")\n        \n        # Check data distribution\n        for col in ['latitude', 'longitude']:\n            values = data[col].values\n            if np.std(values) < 0.0001:\n                warnings.append(f\"Very low variance in {col} values\")\n        \n    except Exception as e:\n        raise DataValidationError(f\"Error validating deposits file: {str(e)}\")\n    \n    return warnings\n\ndef validate_features_file(file_path: Path) -> List[str]:\n    \"\"\"\n    Validate features data file\n    \n    Args:\n        file_path: Path to features file\n        \n    Returns:\n        List of validation warnings\n    \"\"\"\n    warnings = []\n    \n    try:\n        # Read file\n        if file_path.suffix == '.csv':\n            data = pd.read_csv(file_path)\n        elif file_path.suffix == '.parquet':\n            data = pd.read_parquet(file_path)\n        else:\n            raise DataValidationError(f\"Unsupported file format: {file_path.suffix}\")\n        \n        # Check required columns\n        required_columns = {'latitude', 'longitude'}\n        missing_columns = required_columns - set(data.columns)\n        if missing_columns:\n            raise DataValidationError(f\"Missing required columns: {missing_columns}\")\n        \n        # Validate each row\n        for idx, row in data.iterrows():\n            try:\n                GeophysicalData(**row.to_dict())\n            except Exception as e:\n                warnings.append(f\"Row {idx}: {str(e)}\")\n        \n        # Check for missing values\n        missing_counts = data.isnull().sum()\n        if missing_counts.any():\n            warnings.extend([\n                f\"Column {col} has {count} missing values\"\n                for col, count in missing_counts.items()\n                if count > 0\n            ])\n        \n        # Check for outliers\n        numerical_cols = data.select_dtypes(include=[np.number]).columns\n        for col in numerical_cols:\n            values = data[col].values\n            z_scores = np.abs((values - np.mean(values)) / np.std(values))\n            outliers = np.sum(z_scores > 3)\n            if outliers > 0:\n                warnings.append(f\"Found {outliers} outliers in {col}\")\n        \n    except Exception as e:\n        raise DataValidationError(f\"Error validating features file: {str(e)}\")\n    \n    return warnings\n\ndef validate_config(config: Dict[str, Any]) -> List[str]:\n    \"\"\"\n    Validate configuration\n    \n    Args:\n        config: Configuration dictionary\n        \n    Returns:\n        List of validation warnings\n    \"\"\"\n    warnings = []\n    \n    try:\n        # Check model configuration\n        model_config = config.get('model', {})\n        if not model_config.get('hidden_dims'):\n            warnings.append(\"No hidden dimensions specified in model config\")\n        \n        if model_config.get('dropout', 0) > 0.5:\n            warnings.append(\"High dropout rate may impact model performance\")\n        \n        # Check training configuration\n        train_config = config.get('training', {})\n        if train_config.get('batch_size', 32) > 512:\n            warnings.append(\"Large batch size may cause memory issues\")\n        \n        if train_config.get('learning_rate', 0.001) > 0.1:\n            warnings.append(\"Learning rate seems unusually high\")\n        \n        # Check data configuration\n        data_config = config.get('data', {})\n        if not data_config.get('numerical_features'):\n            warnings.append(\"No numerical features specified\")\n        \n        if not data_config.get('categorical_features'):\n            warnings.append(\"No categorical features specified\")\n        \n        test_size = data_config.get('test_size', 0.2)\n        val_size = data_config.get('val_size', 0.2)\n        if test_size + val_size > 0.5:\n            warnings.append(\"Large test and validation sets may leave insufficient training data\")\n        \n    except Exception as e:\n        raise DataValidationError(f\"Error validating configuration: {str(e)}\")\n    \n    return warnings\n\ndef validate_model_inputs(features: torch.Tensor,\n                        config: Dict[str, Any]) -> List[str]:\n    \"\"\"\n    Validate model input data\n    \n    Args:\n        features: Input feature tensor\n        config: Model configuration\n        \n    Returns:\n        List of validation warnings\n    \"\"\"\n    warnings = []\n    \n    try:\n        # Check input dimensions\n        if features.dim() != 2:\n            raise DataValidationError(f\"Expected 2D input tensor, got {features.dim()}D\")\n        \n        if features.shape[1] != config['model']['input_dim']:\n            raise DataValidationError(\n                f\"Input dimension mismatch: got {features.shape[1]}, \"\n                f\"expected {config['model']['input_dim']}\"\n            )\n        \n        # Check for NaN/Inf values\n        if torch.isnan(features).any():\n            warnings.append(\"Input contains NaN values\")\n        \n        if torch.isinf(features).any():\n            warnings.append(\"Input contains infinite values\")\n        \n        # Check value ranges\n        feature_means = features.mean(dim=0)\n        feature_stds = features.std(dim=0)\n        \n        if (feature_stds == 0).any():\n            warnings.append(\"Some features have zero variance\")\n        \n        if (torch.abs(feature_means) > 10).any():\n            warnings.append(\"Some features have unusually large mean values\")\n        \n    except Exception as e:\n        raise DataValidationError(f\"Error validating model inputs: {str(e)}\")\n    \n    return warnings "}
{"type": "source_file", "path": "minesight/core/quality/smart_quality_monitor.py", "content": "\"\"\"\nIntelligent data quality monitoring system for mineral exploration\n\"\"\"\nfrom typing import Dict, List, Optional, Union, Any\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom pathlib import Path\nimport torch\nimport torch.nn as nn\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom dataclasses import dataclass\nimport logging\nfrom minesight.core.quality.data_quality_monitor import DataQualityMonitor, QualityMetric\n\n@dataclass\nclass QualityPattern:\n    \"\"\"Data class for quality patterns\"\"\"\n    pattern_id: str\n    pattern_type: str\n    confidence: float\n    impact: float\n    description: str\n    affected_metrics: List[str]\n    recommendations: List[str]\n    metadata: Optional[Dict[str, Any]] = None\n\nclass QualityPatternDetector(nn.Module):\n    \"\"\"Neural network for detecting quality patterns\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int = 128):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU()\n        )\n        \n        self.pattern_head = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 3)  # [pattern_type, confidence, impact]\n        )\n        \n        self.impact_head = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, len(QualityMetricType))  # Impact on each metric type\n        )\n\nclass SmartQualityMonitor(DataQualityMonitor):\n    \"\"\"Intelligent data quality monitoring system\"\"\"\n    \n    def __init__(self, config_path: Optional[str] = None):\n        \"\"\"Initialize the smart quality monitor\"\"\"\n        super().__init__(config_path)\n        \n        self.pattern_detector = None\n        self.anomaly_detector = IsolationForest(\n            contamination=0.1,\n            random_state=42\n        )\n        self.scaler = StandardScaler()\n        self.pattern_history = []\n        \n    def train_pattern_detector(self, training_data: List[Dict[str, Any]]):\n        \"\"\"\n        Train the pattern detector model\n        \n        Args:\n            training_data: Historical quality data for training\n        \"\"\"\n        if len(training_data) < 10:\n            self.logger.warning(\"Insufficient data for training pattern detector\")\n            return\n            \n        # Prepare training data\n        X = self._prepare_pattern_features(training_data)\n        \n        # Initialize model if needed\n        if self.pattern_detector is None:\n            self.pattern_detector = QualityPatternDetector(\n                input_size=X.shape[1]\n            )\n            \n        # Train model\n        self.pattern_detector.train()\n        optimizer = torch.optim.Adam(self.pattern_detector.parameters())\n        \n        for epoch in range(100):\n            optimizer.zero_grad()\n            \n            # Forward pass\n            patterns, impacts = self.pattern_detector(X)\n            \n            # Calculate loss\n            pattern_loss = self._calculate_pattern_loss(patterns, training_data)\n            impact_loss = self._calculate_impact_loss(impacts, training_data)\n            \n            total_loss = pattern_loss + impact_loss\n            \n            # Backward pass\n            total_loss.backward()\n            optimizer.step()\n            \n        self.pattern_detector.eval()\n        \n    def detect_quality_patterns(self, data: Union[pd.DataFrame, Dict]) -> List[QualityPattern]:\n        \"\"\"\n        Detect quality patterns in data\n        \n        Args:\n            data: Input data to analyze\n            \n        Returns:\n            List of detected quality patterns\n        \"\"\"\n        if isinstance(data, dict):\n            data = pd.DataFrame([data])\n            \n        # Prepare features\n        features = self._prepare_pattern_features([data])\n        \n        # Detect patterns\n        with torch.no_grad():\n            patterns, impacts = self.pattern_detector(features)\n            \n        # Convert to quality patterns\n        detected_patterns = []\n        for i, (pattern, impact) in enumerate(zip(patterns, impacts)):\n            pattern_type = self._get_pattern_type(pattern)\n            confidence = float(torch.sigmoid(pattern[1]))\n            impact_score = float(torch.sigmoid(pattern[2]))\n            \n            affected_metrics = self._get_affected_metrics(impact)\n            \n            pattern_obj = QualityPattern(\n                pattern_id=f\"pattern_{datetime.now().timestamp()}_{i}\",\n                pattern_type=pattern_type,\n                confidence=confidence,\n                impact=impact_score,\n                description=self._generate_pattern_description(pattern_type, affected_metrics),\n                affected_metrics=affected_metrics,\n                recommendations=self._generate_pattern_recommendations(pattern_type, affected_metrics),\n                metadata={\n                    \"raw_pattern\": pattern.tolist(),\n                    \"raw_impact\": impact.tolist()\n                }\n            )\n            \n            detected_patterns.append(pattern_obj)\n            \n        # Store patterns in history\n        self.pattern_history.extend(detected_patterns)\n        \n        return detected_patterns\n        \n    def analyze_quality_trends(self, window_size: int = 10) -> Dict[str, Any]:\n        \"\"\"\n        Analyze quality metric trends\n        \n        Args:\n            window_size: Size of analysis window\n            \n        Returns:\n            Trend analysis results\n        \"\"\"\n        if len(self.metrics_history) < window_size:\n            return {}\n            \n        recent_metrics = list(self.metrics_history)[-window_size:]\n        \n        analysis = {\n            \"trends\": {},\n            \"patterns\": {},\n            \"correlations\": {},\n            \"anomalies\": {},\n            \"recommendations\": []\n        }\n        \n        # Analyze metric trends\n        for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n            values = [m[\"metrics\"][metric] for m in recent_metrics]\n            trend = np.polyfit(range(len(values)), values, 1)[0]\n            \n            analysis[\"trends\"][metric] = {\n                \"direction\": \"improving\" if trend > 0 else \"degrading\",\n                \"slope\": float(trend),\n                \"current_value\": values[-1],\n                \"mean\": float(np.mean(values)),\n                \"std\": float(np.std(values))\n            }\n            \n        # Analyze patterns\n        recent_patterns = [\n            p for p in self.pattern_history\n            if (datetime.now() - p.metadata[\"timestamp\"]).days <= window_size\n        ]\n        \n        pattern_counts = {}\n        for pattern in recent_patterns:\n            pattern_counts[pattern.pattern_type] = pattern_counts.get(pattern.pattern_type, 0) + 1\n            \n        analysis[\"patterns\"] = {\n            \"total_patterns\": len(recent_patterns),\n            \"pattern_distribution\": pattern_counts,\n            \"high_impact_patterns\": [\n                p for p in recent_patterns\n                if p.impact > 0.7\n            ]\n        }\n        \n        # Calculate metric correlations\n        metric_values = {}\n        for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n            metric_values[metric] = [m[\"metrics\"][metric] for m in recent_metrics]\n            \n        corr_matrix = pd.DataFrame(metric_values).corr()\n        analysis[\"correlations\"] = corr_matrix.to_dict()\n        \n        # Detect anomalies\n        metric_matrix = np.array(list(metric_values.values())).T\n        anomaly_scores = self.anomaly_detector.fit_predict(metric_matrix)\n        \n        anomalies = []\n        for i, score in enumerate(anomaly_scores):\n            if score == -1:  # Anomaly detected\n                anomalies.append({\n                    \"timestamp\": recent_metrics[i][\"timestamp\"],\n                    \"metrics\": recent_metrics[i][\"metrics\"],\n                    \"score\": float(self.anomaly_detector.score_samples(metric_matrix[i:i+1])[0])\n                })\n                \n        analysis[\"anomalies\"] = {\n            \"total_anomalies\": len(anomalies),\n            \"anomaly_details\": anomalies\n        }\n        \n        # Generate recommendations\n        analysis[\"recommendations\"] = self._generate_trend_recommendations(analysis)\n        \n        return analysis\n        \n    def generate_quality_insights(self) -> Dict[str, Any]:\n        \"\"\"\n        Generate comprehensive quality insights\n        \n        Returns:\n            Quality insights and recommendations\n        \"\"\"\n        insights = {\n            \"summary\": self._generate_quality_summary(),\n            \"trend_analysis\": self.analyze_quality_trends(),\n            \"pattern_analysis\": self._analyze_pattern_distribution(),\n            \"impact_analysis\": self._analyze_quality_impact(),\n            \"recommendations\": []\n        }\n        \n        # Generate high-level recommendations\n        insights[\"recommendations\"] = self._generate_quality_recommendations(insights)\n        \n        return insights\n        \n    def _prepare_pattern_features(self, data: List[Dict[str, Any]]) -> torch.Tensor:\n        \"\"\"Prepare features for pattern detection\"\"\"\n        features = []\n        \n        for entry in data:\n            metrics = entry[\"metrics\"]\n            feature_vector = [\n                metrics[\"completeness\"],\n                metrics[\"accuracy\"],\n                metrics[\"consistency\"],\n                metrics[\"timeliness\"],\n                len(entry.get(\"issues\", [])),\n                len(entry.get(\"recommendations\", []))\n            ]\n            features.append(feature_vector)\n            \n        X = np.array(features)\n        X_scaled = self.scaler.fit_transform(X)\n        \n        return torch.tensor(X_scaled, dtype=torch.float32)\n        \n    def _get_pattern_type(self, pattern: torch.Tensor) -> str:\n        \"\"\"Get pattern type from model output\"\"\"\n        pattern_types = [\"degradation\", \"improvement\", \"fluctuation\"]\n        pattern_idx = torch.argmax(pattern[0]).item()\n        return pattern_types[pattern_idx]\n        \n    def _get_affected_metrics(self, impact: torch.Tensor) -> List[str]:\n        \"\"\"Get metrics affected by pattern\"\"\"\n        metrics = [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]\n        threshold = 0.5\n        \n        return [\n            metric\n            for i, metric in enumerate(metrics)\n            if torch.sigmoid(impact[i]) > threshold\n        ]\n        \n    def _generate_pattern_description(self, pattern_type: str,\n                                   affected_metrics: List[str]) -> str:\n        \"\"\"Generate human-readable pattern description\"\"\"\n        metric_str = \", \".join(affected_metrics)\n        \n        if pattern_type == \"degradation\":\n            return f\"Detected quality degradation in metrics: {metric_str}\"\n        elif pattern_type == \"improvement\":\n            return f\"Detected quality improvement in metrics: {metric_str}\"\n        else:\n            return f\"Detected quality fluctuations in metrics: {metric_str}\"\n            \n    def _generate_pattern_recommendations(self, pattern_type: str,\n                                       affected_metrics: List[str]) -> List[str]:\n        \"\"\"Generate recommendations based on pattern\"\"\"\n        recommendations = []\n        \n        if pattern_type == \"degradation\":\n            for metric in affected_metrics:\n                recommendations.append(f\"Investigate causes of {metric} degradation\")\n                recommendations.append(f\"Implement quality controls for {metric}\")\n                \n        elif pattern_type == \"improvement\":\n            recommendations.append(\"Document and maintain successful quality practices\")\n            recommendations.append(\"Apply successful patterns to other metrics\")\n            \n        else:\n            recommendations.append(\"Monitor metric stability\")\n            recommendations.append(\"Implement standardization measures\")\n            \n        return recommendations\n        \n    def _generate_trend_recommendations(self, analysis: Dict[str, Any]) -> List[str]:\n        \"\"\"Generate recommendations based on trend analysis\"\"\"\n        recommendations = []\n        \n        # Check metric trends\n        for metric, trend in analysis[\"trends\"].items():\n            if trend[\"direction\"] == \"degrading\":\n                recommendations.append(\n                    f\"Address declining {metric} trend (current: {trend['current_value']:.2f})\"\n                )\n            elif trend[\"std\"] > 0.1:\n                recommendations.append(\n                    f\"Improve {metric} stability (std: {trend['std']:.2f})\"\n                )\n                \n        # Check patterns\n        if analysis[\"patterns\"][\"high_impact_patterns\"]:\n            recommendations.append(\n                f\"Address {len(analysis['patterns']['high_impact_patterns'])} high-impact quality patterns\"\n            )\n            \n        # Check anomalies\n        if analysis[\"anomalies\"][\"total_anomalies\"] > 0:\n            recommendations.append(\n                f\"Investigate {analysis['anomalies']['total_anomalies']} quality anomalies\"\n            )\n            \n        return recommendations\n        \n    def _analyze_pattern_distribution(self) -> Dict[str, Any]:\n        \"\"\"Analyze distribution of quality patterns\"\"\"\n        if not self.pattern_history:\n            return {}\n            \n        analysis = {\n            \"pattern_types\": {},\n            \"impact_distribution\": {},\n            \"temporal_distribution\": {},\n            \"metric_impact\": {}\n        }\n        \n        # Analyze pattern types\n        for pattern in self.pattern_history:\n            # Pattern type distribution\n            analysis[\"pattern_types\"][pattern.pattern_type] = \\\n                analysis[\"pattern_types\"].get(pattern.pattern_type, 0) + 1\n                \n            # Impact distribution\n            impact_level = \"high\" if pattern.impact > 0.7 else \"medium\" if pattern.impact > 0.4 else \"low\"\n            analysis[\"impact_distribution\"][impact_level] = \\\n                analysis[\"impact_distribution\"].get(impact_level, 0) + 1\n                \n            # Temporal distribution\n            date = pattern.metadata[\"timestamp\"].date()\n            analysis[\"temporal_distribution\"][str(date)] = \\\n                analysis[\"temporal_distribution\"].get(str(date), 0) + 1\n                \n            # Metric impact\n            for metric in pattern.affected_metrics:\n                if metric not in analysis[\"metric_impact\"]:\n                    analysis[\"metric_impact\"][metric] = {\n                        \"total_patterns\": 0,\n                        \"high_impact_patterns\": 0\n                    }\n                analysis[\"metric_impact\"][metric][\"total_patterns\"] += 1\n                if pattern.impact > 0.7:\n                    analysis[\"metric_impact\"][metric][\"high_impact_patterns\"] += 1\n                    \n        return analysis\n        \n    def _analyze_quality_impact(self) -> Dict[str, Any]:\n        \"\"\"Analyze impact of quality issues\"\"\"\n        impact_analysis = {\n            \"overall_impact\": self._calculate_overall_impact(),\n            \"metric_impacts\": self._calculate_metric_impacts(),\n            \"trend_impact\": self._calculate_trend_impact(),\n            \"recommendations\": []\n        }\n        \n        # Generate impact-based recommendations\n        if impact_analysis[\"overall_impact\"] > 0.7:\n            impact_analysis[\"recommendations\"].append(\n                \"Critical: Immediate action required to address quality issues\"\n            )\n        elif impact_analysis[\"overall_impact\"] > 0.4:\n            impact_analysis[\"recommendations\"].append(\n                \"Warning: Quality issues require attention\"\n            )\n            \n        # Add metric-specific recommendations\n        for metric, impact in impact_analysis[\"metric_impacts\"].items():\n            if impact > 0.7:\n                impact_analysis[\"recommendations\"].append(\n                    f\"Critical impact on {metric} - Prioritize improvements\"\n                )\n                \n        return impact_analysis\n        \n    def _calculate_overall_impact(self) -> float:\n        \"\"\"Calculate overall quality impact score\"\"\"\n        if not self.metrics_history:\n            return 0.0\n            \n        recent_metrics = list(self.metrics_history)[-10:]\n        impact_scores = []\n        \n        for metrics in recent_metrics:\n            score = 1.0 - np.mean([\n                metrics[\"metrics\"][m]\n                for m in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]\n            ])\n            impact_scores.append(score)\n            \n        return float(np.mean(impact_scores))\n        \n    def _calculate_metric_impacts(self) -> Dict[str, float]:\n        \"\"\"Calculate impact scores for each metric\"\"\"\n        if not self.metrics_history:\n            return {}\n            \n        recent_metrics = list(self.metrics_history)[-10:]\n        impacts = {}\n        \n        for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n            values = [m[\"metrics\"][metric] for m in recent_metrics]\n            impact = 1.0 - np.mean(values)\n            impacts[metric] = float(impact)\n            \n        return impacts\n        \n    def _calculate_trend_impact(self) -> float:\n        \"\"\"Calculate impact of quality trends\"\"\"\n        if not self.metrics_history:\n            return 0.0\n            \n        recent_metrics = list(self.metrics_history)[-10:]\n        trend_impacts = []\n        \n        for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n            values = [m[\"metrics\"][metric] for m in recent_metrics]\n            trend = np.polyfit(range(len(values)), values, 1)[0]\n            \n            # Negative trend indicates higher impact\n            impact = abs(min(trend, 0))\n            trend_impacts.append(impact)\n            \n        return float(np.mean(trend_impacts))\n        \n    def _generate_quality_recommendations(self, insights: Dict[str, Any]) -> List[str]:\n        \"\"\"Generate comprehensive quality recommendations\"\"\"\n        recommendations = []\n        \n        # Add high-priority recommendations\n        if insights[\"summary\"][\"overall_quality\"] < 0.7:\n            recommendations.append(\n                \"Critical: Overall quality requires immediate attention\"\n            )\n            \n        # Add trend-based recommendations\n        for metric, trend in insights[\"trend_analysis\"][\"trends\"].items():\n            if trend[\"direction\"] == \"degrading\":\n                recommendations.append(\n                    f\"Address declining {metric} trend - Current: {trend['current_value']:.2f}\"\n                )\n                \n        # Add pattern-based recommendations\n        pattern_analysis = insights[\"pattern_analysis\"]\n        high_impact_patterns = sum(\n            1 for p in pattern_analysis.get(\"impact_distribution\", {}).values()\n            if p > 0.7\n        )\n        if high_impact_patterns > 0:\n            recommendations.append(\n                f\"Investigate {high_impact_patterns} high-impact quality patterns\"\n            )\n            \n        # Add impact-based recommendations\n        impact_analysis = insights[\"impact_analysis\"]\n        for metric, impact in impact_analysis[\"metric_impacts\"].items():\n            if impact > 0.7:\n                recommendations.append(\n                    f\"Critical: Address high impact on {metric} quality\"\n                )\n                \n        return recommendations "}
{"type": "source_file", "path": "minesight/core/optimization/smart_process_optimizer.py", "content": "\"\"\"\nIntelligent process optimization system with deep learning capabilities\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Tuple\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor, IsolationForest\nfrom minesight.core.optimization.process_optimizer import ProcessOptimizer, ProcessMetrics, OptimizationResult\nfrom minesight.core.streaming.processor import StreamProcessor\nfrom minesight.core.recommendation.smart_recommender import SmartRecommender\nfrom minesight.core.planning.exploration_planner import ExplorationPlanner\n\n@dataclass\nclass ProcessPattern:\n    \"\"\"Data class for process patterns\"\"\"\n    pattern_id: str\n    pattern_type: str\n    confidence: float\n    impact: float\n    description: str\n    affected_metrics: List[str]\n    recommendations: List[str]\n    metadata: Optional[Dict[str, Any]] = None\n\n@dataclass \nclass ProcessAnalysisResult:\n    \"\"\"Data class for process analysis results\"\"\"\n    process_id: str\n    metrics: ProcessMetrics\n    patterns: List[ProcessPattern]\n    bottlenecks: List[Dict[str, Any]]\n    anomalies: List[Dict[str, Any]]\n    recommendations: List[str]\n    confidence: float\n\nclass ProcessAnalyzer:\n    \"\"\"Intelligent process analyzer\"\"\"\n    \n    def __init__(self):\n        self.anomaly_detector = IsolationForest(contamination=0.1)\n        self.pattern_detector = None\n        self.bottleneck_detector = None\n        self.scaler = StandardScaler()\n        \n    def analyze_process(self,\n                       process_data: Dict[str, Any],\n                       historical_data: Optional[Dict[str, Any]] = None) -> ProcessAnalysisResult:\n        \"\"\"\n        Perform comprehensive process analysis\n        \n        Args:\n            process_data: Current process data\n            historical_data: Optional historical data for comparison\n            \n        Returns:\n            Process analysis results\n        \"\"\"\n        # Calculate process metrics\n        metrics = self._calculate_process_metrics(process_data)\n        \n        # Detect patterns\n        patterns = self._detect_patterns(process_data, historical_data)\n        \n        # Detect bottlenecks\n        bottlenecks = self._detect_bottlenecks(process_data)\n        \n        # Detect anomalies\n        anomalies = self._detect_anomalies(process_data)\n        \n        # Generate recommendations\n        recommendations = self._generate_recommendations(\n            metrics,\n            patterns,\n            bottlenecks,\n            anomalies\n        )\n        \n        # Calculate confidence\n        confidence = self._calculate_confidence(\n            metrics,\n            patterns,\n            bottlenecks,\n            anomalies\n        )\n        \n        return ProcessAnalysisResult(\n            process_id=process_data[\"process_id\"],\n            metrics=metrics,\n            patterns=patterns,\n            bottlenecks=bottlenecks,\n            anomalies=anomalies,\n            recommendations=recommendations,\n            confidence=confidence\n        )\n        \n    def _calculate_process_metrics(self, data: Dict[str, Any]) -> ProcessMetrics:\n        \"\"\"Calculate process performance metrics\"\"\"\n        return ProcessMetrics(\n            efficiency=self._calculate_efficiency(data),\n            cost_effectiveness=self._calculate_cost_effectiveness(data),\n            resource_utilization=self._calculate_resource_utilization(data),\n            exploration_coverage=self._calculate_exploration_coverage(data),\n            success_rate=self._calculate_success_rate(data),\n            risk_score=self._calculate_risk_score(data)\n        )\n        \n    def _detect_patterns(self,\n                        current_data: Dict[str, Any],\n                        historical_data: Optional[Dict[str, Any]] = None) -> List[ProcessPattern]:\n        \"\"\"Detect patterns in process data\"\"\"\n        patterns = []\n        \n        # Prepare features\n        features = self._prepare_pattern_features(current_data)\n        \n        # Detect using pattern detector\n        if self.pattern_detector is not None:\n            with torch.no_grad():\n                pattern_outputs = self.pattern_detector(features)\n                patterns.extend(self._convert_pattern_outputs(pattern_outputs))\n                \n        # Compare with historical data if available\n        if historical_data is not None:\n            historical_patterns = self._analyze_historical_patterns(\n                current_data,\n                historical_data\n            )\n            patterns.extend(historical_patterns)\n            \n        return patterns\n        \n    def _detect_bottlenecks(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Detect process bottlenecks\"\"\"\n        bottlenecks = []\n        \n        # Analyze resource utilization\n        resource_bottlenecks = self._analyze_resource_bottlenecks(data)\n        bottlenecks.extend(resource_bottlenecks)\n        \n        # Analyze performance bottlenecks\n        performance_bottlenecks = self._analyze_performance_bottlenecks(data)\n        bottlenecks.extend(performance_bottlenecks)\n        \n        # Analyze cost bottlenecks\n        cost_bottlenecks = self._analyze_cost_bottlenecks(data)\n        bottlenecks.extend(cost_bottlenecks)\n        \n        return bottlenecks\n        \n    def _detect_anomalies(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Detect process anomalies\"\"\"\n        anomalies = []\n        \n        # Prepare features\n        features = self._prepare_anomaly_features(data)\n        \n        # Detect anomalies\n        scores = self.anomaly_detector.fit_predict(features)\n        anomaly_scores = self.anomaly_detector.score_samples(features)\n        \n        for i, (score, anomaly_score) in enumerate(zip(scores, anomaly_scores)):\n            if score == -1:  # Anomaly detected\n                anomalies.append({\n                    \"timestamp\": data.get(\"timestamp\", datetime.now().isoformat()),\n                    \"metric\": data.get(\"metric_names\", [])[i],\n                    \"score\": float(anomaly_score),\n                    \"severity\": \"high\" if anomaly_score < -0.8 else \"medium\"\n                })\n                \n        return anomalies\n        \n    def _generate_recommendations(self,\n                                metrics: ProcessMetrics,\n                                patterns: List[ProcessPattern],\n                                bottlenecks: List[Dict[str, Any]],\n                                anomalies: List[Dict[str, Any]]) -> List[str]:\n        \"\"\"Generate process improvement recommendations\"\"\"\n        recommendations = []\n        \n        # Pattern-based recommendations\n        for pattern in patterns:\n            recommendations.extend(pattern.recommendations)\n            \n        # Bottleneck recommendations\n        for bottleneck in bottlenecks:\n            recommendations.append(\n                f\"Address {bottleneck['type']} bottleneck in {bottleneck['location']}\"\n            )\n            if \"solution\" in bottleneck:\n                recommendations.append(bottleneck[\"solution\"])\n                \n        # Anomaly recommendations\n        for anomaly in anomalies:\n            recommendations.append(\n                f\"Investigate {anomaly['severity']} anomaly in {anomaly['metric']}\"\n            )\n            \n        # Metric-based recommendations\n        if metrics.efficiency < 0.7:\n            recommendations.append(\"Improve process efficiency through optimization\")\n        if metrics.cost_effectiveness < 0.7:\n            recommendations.append(\"Implement cost reduction measures\")\n        if metrics.resource_utilization < 0.7:\n            recommendations.append(\"Optimize resource allocation\")\n        if metrics.exploration_coverage < 0.7:\n            recommendations.append(\"Expand exploration coverage\")\n        if metrics.success_rate < 0.7:\n            recommendations.append(\"Improve process success rate\")\n        if metrics.risk_score > 0.3:\n            recommendations.append(\"Implement risk mitigation measures\")\n            \n        return recommendations\n        \n    def _calculate_confidence(self,\n                            metrics: ProcessMetrics,\n                            patterns: List[ProcessPattern],\n                            bottlenecks: List[Dict[str, Any]],\n                            anomalies: List[Dict[str, Any]]) -> float:\n        \"\"\"Calculate confidence score for analysis results\"\"\"\n        confidence_scores = []\n        \n        # Metric confidence\n        metric_confidence = self._assess_data_quality(metrics)\n        confidence_scores.append(metric_confidence)\n        \n        # Pattern confidence\n        if patterns:\n            pattern_confidence = np.mean([p.confidence for p in patterns])\n            confidence_scores.append(pattern_confidence)\n            \n        # Bottleneck confidence\n        if bottlenecks:\n            bottleneck_confidence = np.mean([\n                b.get(\"confidence\", 0.8) for b in bottlenecks\n            ])\n            confidence_scores.append(bottleneck_confidence)\n            \n        # Anomaly confidence\n        if anomalies:\n            anomaly_confidence = np.mean([\n                1 - abs(a[\"score\"]) for a in anomalies\n            ])\n            confidence_scores.append(anomaly_confidence)\n            \n        return float(np.mean(confidence_scores))\n\nclass SmartProcessOptimizer(ProcessOptimizer):\n    \"\"\"Enhanced intelligent process optimization system\"\"\"\n    \n    def __init__(self):\n        super().__init__()\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        # Initialize optimization models\n        self.resource_optimizer = ResourceOptimizer()\n        self.bottleneck_detector = BottleneckDetector()\n        self.performance_analyzer = PerformanceAnalyzer()\n        self.strategy_generator = OptimizationStrategyGenerator()\n        \n    def optimize_process(self,\n                        current_state: Dict[str, Any],\n                        resources: Dict[str, Any],\n                        activities: List[Dict[str, Any]],\n                        constraints: Optional[Dict[str, Any]] = None) -> List[OptimizationResult]:\n        \"\"\"\n        Optimize process execution with enhanced strategies\n        \n        Args:\n            current_state: Current process state\n            resources: Available resources\n            activities: Process activities\n            constraints: Optional constraints\n            \n        Returns:\n            List of optimization results\n        \"\"\"\n        try:\n            # Analyze current performance\n            performance_metrics = self.performance_analyzer.analyze_performance(\n                current_state,\n                activities\n            )\n            \n            # Detect bottlenecks\n            bottlenecks = self.bottleneck_detector.detect_bottlenecks(\n                current_state,\n                activities,\n                performance_metrics\n            )\n            \n            # Generate optimization strategies\n            strategies = self.strategy_generator.generate_strategies(\n                current_state,\n                bottlenecks,\n                performance_metrics\n            )\n            \n            # Optimize resource allocation\n            optimized_resources = self.resource_optimizer.optimize_allocation(\n                resources,\n                activities,\n                strategies,\n                constraints\n            )\n            \n            # Apply optimization strategies\n            results = []\n            for strategy in strategies:\n                # Validate strategy against constraints\n                if self._validate_strategy(strategy, constraints):\n                    # Calculate resource requirements\n                    required_resources = self._calculate_resource_requirements(\n                        strategy,\n                        current_state,\n                        optimized_resources\n                    )\n                    \n                    # Check resource availability\n                    if self._check_resource_availability(required_resources, optimized_resources):\n                        # Generate optimization steps\n                        steps = self._generate_optimization_steps(\n                            strategy,\n                            required_resources,\n                            current_state\n                        )\n                        \n                        # Calculate expected impact\n                        impact = self._calculate_optimization_impact(\n                            strategy,\n                            performance_metrics\n                        )\n                        \n                        # Calculate confidence score\n                        confidence = self._calculate_optimization_confidence(\n                            strategy,\n                            impact,\n                            performance_metrics\n                        )\n                        \n                        results.append(OptimizationResult(\n                            strategy_id=strategy[\"id\"],\n                            steps=steps,\n                            required_resources=required_resources,\n                            expected_impact=impact,\n                            confidence=confidence,\n                            status=\"ready\"\n                        ))\n            \n            return results\n            \n        except Exception as e:\n            logging.error(f\"Error in process optimization: {str(e)}\")\n            return []\n            \n    def _validate_strategy(self, strategy: Dict[str, Any], constraints: Optional[Dict[str, Any]]) -> bool:\n        \"\"\"Validate optimization strategy against constraints\"\"\"\n        if not constraints:\n            return True\n            \n        # Check resource constraints\n        if \"resource_limits\" in constraints:\n            for resource, limit in constraints[\"resource_limits\"].items():\n                if strategy.get(\"resource_requirements\", {}).get(resource, 0) > limit:\n                    return False\n                    \n        # Check time constraints\n        if \"time_constraints\" in constraints:\n            if strategy.get(\"estimated_duration\", 0) > constraints[\"time_constraints\"].get(\"max_duration\", float(\"inf\")):\n                return False\n                \n        # Check cost constraints\n        if \"cost_constraints\" in constraints:\n            if strategy.get(\"estimated_cost\", 0) > constraints[\"cost_constraints\"].get(\"max_cost\", float(\"inf\")):\n                return False\n                \n        # Check regulatory constraints\n        if \"regulatory_constraints\" in constraints:\n            required_compliance = set(constraints[\"regulatory_constraints\"])\n            strategy_compliance = set(strategy.get(\"compliance_requirements\", []))\n            if not required_compliance.issubset(strategy_compliance):\n                return False\n                \n        return True\n        \n    def _check_resource_availability(self, required: Dict[str, Any], available: Dict[str, Any]) -> bool:\n        \"\"\"Check if required resources are available\"\"\"\n        for resource_type, required_amount in required.items():\n            if resource_type not in available:\n                return False\n            if available[resource_type].get(\"amount\", 0) < required_amount.get(\"amount\", 0):\n                return False\n        return True\n        \n    def _generate_optimization_steps(self,\n                                   strategy: Dict[str, Any],\n                                   required_resources: Dict[str, Any],\n                                   current_state: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate detailed optimization steps\"\"\"\n        steps = []\n        \n        # Initialize optimization context\n        context = {\n            \"current_state\": current_state,\n            \"resources\": required_resources,\n            \"progress\": 0.0\n        }\n        \n        # Generate preparation steps\n        prep_steps = self._generate_preparation_steps(strategy, context)\n        steps.extend(prep_steps)\n        \n        # Generate implementation steps\n        impl_steps = self._generate_implementation_steps(strategy, context)\n        steps.extend(impl_steps)\n        \n        # Generate validation steps\n        validation_steps = self._generate_validation_steps(strategy, context)\n        steps.extend(validation_steps)\n        \n        # Add monitoring and adjustment steps\n        monitoring_steps = self._generate_monitoring_steps(strategy, context)\n        steps.extend(monitoring_steps)\n        \n        return steps\n        \n    def _generate_preparation_steps(self, strategy: Dict[str, Any], context: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate preparation steps for optimization\"\"\"\n        steps = []\n        \n        # Resource allocation step\n        steps.append({\n            \"type\": \"preparation\",\n            \"action\": \"allocate_resources\",\n            \"resources\": context[\"resources\"],\n            \"description\": \"Allocate required resources for optimization\"\n        })\n        \n        # Environment setup step\n        steps.append({\n            \"type\": \"preparation\",\n            \"action\": \"setup_environment\",\n            \"requirements\": strategy.get(\"environment_requirements\", {}),\n            \"description\": \"Set up optimization environment\"\n        })\n        \n        # Validation setup step\n        steps.append({\n            \"type\": \"preparation\",\n            \"action\": \"setup_validation\",\n            \"metrics\": strategy.get(\"validation_metrics\", []),\n            \"description\": \"Set up validation mechanisms\"\n        })\n        \n        return steps\n        \n    def _generate_implementation_steps(self, strategy: Dict[str, Any], context: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate implementation steps for optimization\"\"\"\n        steps = []\n        \n        # Process each optimization action\n        for action in strategy.get(\"actions\", []):\n            step = {\n                \"type\": \"implementation\",\n                \"action\": action[\"type\"],\n                \"parameters\": action.get(\"parameters\", {}),\n                \"description\": action.get(\"description\", \"\"),\n                \"validation\": {\n                    \"metrics\": action.get(\"validation_metrics\", []),\n                    \"thresholds\": action.get(\"validation_thresholds\", {})\n                }\n            }\n            steps.append(step)\n            \n        return steps\n        \n    def _generate_validation_steps(self, strategy: Dict[str, Any], context: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate validation steps for optimization\"\"\"\n        steps = []\n        \n        # Performance validation step\n        steps.append({\n            \"type\": \"validation\",\n            \"action\": \"validate_performance\",\n            \"metrics\": strategy.get(\"performance_metrics\", []),\n            \"thresholds\": strategy.get(\"performance_thresholds\", {}),\n            \"description\": \"Validate optimization performance\"\n        })\n        \n        # Resource utilization validation step\n        steps.append({\n            \"type\": \"validation\",\n            \"action\": \"validate_resources\",\n            \"metrics\": strategy.get(\"resource_metrics\", []),\n            \"thresholds\": strategy.get(\"resource_thresholds\", {}),\n            \"description\": \"Validate resource utilization\"\n        })\n        \n        # Impact validation step\n        steps.append({\n            \"type\": \"validation\",\n            \"action\": \"validate_impact\",\n            \"metrics\": strategy.get(\"impact_metrics\", []),\n            \"thresholds\": strategy.get(\"impact_thresholds\", {}),\n            \"description\": \"Validate optimization impact\"\n        })\n        \n        return steps\n        \n    def _generate_monitoring_steps(self, strategy: Dict[str, Any], context: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate monitoring steps for optimization\"\"\"\n        steps = []\n        \n        # Real-time monitoring step\n        steps.append({\n            \"type\": \"monitoring\",\n            \"action\": \"monitor_performance\",\n            \"metrics\": strategy.get(\"monitoring_metrics\", []),\n            \"interval\": strategy.get(\"monitoring_interval\", 60),\n            \"description\": \"Monitor optimization performance\"\n        })\n        \n        # Adjustment step\n        steps.append({\n            \"type\": \"monitoring\",\n            \"action\": \"adjust_parameters\",\n            \"parameters\": strategy.get(\"adjustable_parameters\", []),\n            \"conditions\": strategy.get(\"adjustment_conditions\", {}),\n            \"description\": \"Adjust optimization parameters\"\n        })\n        \n        return steps\n\nclass BottleneckDetector:\n    \"\"\"Enhanced bottleneck detection system\"\"\"\n    \n    def __init__(self):\n        self.performance_threshold = 0.7\n        self.utilization_threshold = 0.85\n        self.queue_threshold = 5\n        \n    def detect_bottlenecks(self,\n                          current_state: Dict[str, Any],\n                          activities: List[Dict[str, Any]],\n                          performance_metrics: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Detect process bottlenecks with enhanced analysis\"\"\"\n        bottlenecks = []\n        \n        # Detect resource bottlenecks\n        resource_bottlenecks = self._detect_resource_bottlenecks(\n            current_state,\n            activities\n        )\n        bottlenecks.extend(resource_bottlenecks)\n        \n        # Detect performance bottlenecks\n        performance_bottlenecks = self._detect_performance_bottlenecks(\n            activities,\n            performance_metrics\n        )\n        bottlenecks.extend(performance_bottlenecks)\n        \n        # Detect queue bottlenecks\n        queue_bottlenecks = self._detect_queue_bottlenecks(\n            current_state,\n            activities\n        )\n        bottlenecks.extend(queue_bottlenecks)\n        \n        # Calculate bottleneck severity and impact\n        for bottleneck in bottlenecks:\n            bottleneck[\"severity\"] = self._calculate_bottleneck_severity(bottleneck)\n            bottleneck[\"impact\"] = self._calculate_bottleneck_impact(\n                bottleneck,\n                performance_metrics\n            )\n            \n        return sorted(bottlenecks, key=lambda x: x[\"severity\"], reverse=True)\n        \n    def _detect_resource_bottlenecks(self,\n                                   current_state: Dict[str, Any],\n                                   activities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Detect resource-related bottlenecks\"\"\"\n        bottlenecks = []\n        \n        # Check resource utilization\n        for resource, usage in current_state.get(\"resource_usage\", {}).items():\n            if usage > self.utilization_threshold:\n                bottlenecks.append({\n                    \"type\": \"resource\",\n                    \"resource\": resource,\n                    \"utilization\": usage,\n                    \"threshold\": self.utilization_threshold,\n                    \"affected_activities\": self._get_affected_activities(resource, activities)\n                })\n                \n        return bottlenecks\n        \n    def _detect_performance_bottlenecks(self,\n                                      activities: List[Dict[str, Any]],\n                                      performance_metrics: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Detect performance-related bottlenecks\"\"\"\n        bottlenecks = []\n        \n        # Check activity performance\n        for activity in activities:\n            performance = performance_metrics.get(activity[\"id\"], {}).get(\"efficiency\", 1.0)\n            if performance < self.performance_threshold:\n                bottlenecks.append({\n                    \"type\": \"performance\",\n                    \"activity\": activity[\"id\"],\n                    \"performance\": performance,\n                    \"threshold\": self.performance_threshold,\n                    \"factors\": self._analyze_performance_factors(activity, performance_metrics)\n                })\n                \n        return bottlenecks\n        \n    def _detect_queue_bottlenecks(self,\n                                current_state: Dict[str, Any],\n                                activities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Detect queue-related bottlenecks\"\"\"\n        bottlenecks = []\n        \n        # Check queue lengths\n        for activity in activities:\n            queue_length = current_state.get(\"queues\", {}).get(activity[\"id\"], 0)\n            if queue_length > self.queue_threshold:\n                bottlenecks.append({\n                    \"type\": \"queue\",\n                    \"activity\": activity[\"id\"],\n                    \"queue_length\": queue_length,\n                    \"threshold\": self.queue_threshold,\n                    \"impact\": self._calculate_queue_impact(queue_length, activity)\n                })\n                \n        return bottlenecks\n        \n    def _calculate_bottleneck_severity(self, bottleneck: Dict[str, Any]) -> float:\n        \"\"\"Calculate bottleneck severity score\"\"\"\n        if bottleneck[\"type\"] == \"resource\":\n            return (bottleneck[\"utilization\"] - bottleneck[\"threshold\"]) / (1 - bottleneck[\"threshold\"])\n        elif bottleneck[\"type\"] == \"performance\":\n            return (bottleneck[\"threshold\"] - bottleneck[\"performance\"]) / bottleneck[\"threshold\"]\n        elif bottleneck[\"type\"] == \"queue\":\n            return (bottleneck[\"queue_length\"] - bottleneck[\"threshold\"]) / bottleneck[\"threshold\"]\n        return 0.0\n        \n    def _calculate_bottleneck_impact(self,\n                                   bottleneck: Dict[str, Any],\n                                   performance_metrics: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Calculate bottleneck impact on different metrics\"\"\"\n        impact = {\n            \"throughput\": 0.0,\n            \"efficiency\": 0.0,\n            \"cost\": 0.0,\n            \"quality\": 0.0\n        }\n        \n        severity = bottleneck[\"severity\"]\n        \n        if bottleneck[\"type\"] == \"resource\":\n            impact[\"throughput\"] = severity * 0.8\n            impact[\"efficiency\"] = severity * 0.6\n            impact[\"cost\"] = severity * 0.4\n        elif bottleneck[\"type\"] == \"performance\":\n            impact[\"efficiency\"] = severity * 0.9\n            impact[\"quality\"] = severity * 0.7\n            impact[\"cost\"] = severity * 0.5\n        elif bottleneck[\"type\"] == \"queue\":\n            impact[\"throughput\"] = severity * 0.7\n            impact[\"efficiency\"] = severity * 0.5\n            impact[\"cost\"] = severity * 0.3\n            \n        return impact\n        \n    def _get_affected_activities(self,\n                               resource: str,\n                               activities: List[Dict[str, Any]]) -> List[str]:\n        \"\"\"Get activities affected by a resource bottleneck\"\"\"\n        affected = []\n        for activity in activities:\n            if resource in activity.get(\"required_resources\", []):\n                affected.append(activity[\"id\"])\n        return affected\n        \n    def _analyze_performance_factors(self,\n                                   activity: Dict[str, Any],\n                                   performance_metrics: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Analyze factors contributing to performance bottleneck\"\"\"\n        factors = {}\n        \n        metrics = performance_metrics.get(activity[\"id\"], {})\n        \n        # Resource utilization factor\n        if \"resource_utilization\" in metrics:\n            factors[\"resource_utilization\"] = 1 - metrics[\"resource_utilization\"]\n            \n        # Process efficiency factor\n        if \"process_efficiency\" in metrics:\n            factors[\"process_efficiency\"] = 1 - metrics[\"process_efficiency\"]\n            \n        # Quality factor\n        if \"quality_score\" in metrics:\n            factors[\"quality\"] = 1 - metrics[\"quality_score\"]\n            \n        # Time efficiency factor\n        if \"time_efficiency\" in metrics:\n            factors[\"time_efficiency\"] = 1 - metrics[\"time_efficiency\"]\n            \n        return factors\n        \n    def _calculate_queue_impact(self,\n                              queue_length: int,\n                              activity: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Calculate impact of queue bottleneck\"\"\"\n        base_impact = (queue_length - self.queue_threshold) / queue_length\n        \n        return {\n            \"waiting_time\": base_impact * 0.8,\n            \"resource_utilization\": base_impact * 0.6,\n            \"process_efficiency\": base_impact * 0.4\n        }\n\nclass ProcessPatternDetector(nn.Module):\n    \"\"\"Neural network for detecting process patterns\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int = 256):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU()\n        )\n        \n        self.pattern_head = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 3)  # [pattern_type, confidence, impact]\n        )\n        \n        self.impact_head = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 6)  # Impact on each metric type\n        )\n\nclass ProcessStreamProcessor(StreamProcessor):\n    \"\"\"Real-time process data stream processor\"\"\"\n    \n    def __init__(self, batch_size: int = 32, processing_interval: float = 1.0):\n        super().__init__(batch_size, processing_interval)\n        self.anomaly_detector = IsolationForest(contamination=0.1)\n        self.pattern_buffer = []\n        self.alert_thresholds = {\n            \"efficiency\": 0.7,\n            \"cost\": 0.3,\n            \"utilization\": 0.8,\n            \"coverage\": 0.6,\n            \"success\": 0.7,\n            \"risk\": 0.3\n        }\n    \n    async def process_batch(self):\n        \"\"\"Process a batch of process data\"\"\"\n        if not self.data_buffer:\n            return\n            \n        try:\n            # Get batch data\n            batch_data = list(self.data_buffer)\n            self.data_buffer.clear()\n            \n            # Detect anomalies\n            anomalies = self._detect_anomalies(batch_data)\n            \n            # Analyze patterns\n            patterns = self._analyze_patterns(batch_data)\n            \n            # Generate alerts\n            alerts = self._generate_alerts(batch_data, anomalies, patterns)\n            \n            # Save results\n            processed_data = {\n                \"timestamp\": datetime.now().isoformat(),\n                \"metrics\": self._calculate_batch_metrics(batch_data),\n                \"anomalies\": anomalies,\n                \"patterns\": patterns,\n                \"alerts\": alerts\n            }\n            \n            self.processed_data.append(processed_data)\n            self.current_batch_id += 1\n            \n        except Exception as e:\n            self.logger.error(f\"Error processing batch {self.current_batch_id}: {str(e)}\")\n            raise\n            \n    def _detect_anomalies(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Detect anomalies in process data\"\"\"\n        if len(data) < 2:\n            return []\n            \n        try:\n            # Prepare features\n            features = np.array([\n                [\n                    d[\"metrics\"][\"efficiency\"],\n                    d[\"metrics\"][\"cost_effectiveness\"],\n                    d[\"metrics\"][\"resource_utilization\"],\n                    d[\"metrics\"][\"exploration_coverage\"],\n                    d[\"metrics\"][\"success_rate\"],\n                    d[\"metrics\"][\"risk_score\"]\n                ]\n                for d in data\n            ])\n            \n            # Detect anomalies\n            scores = self.anomaly_detector.fit_predict(features)\n            \n            # Return anomalies\n            anomalies = []\n            for i, (score, d) in enumerate(zip(scores, data)):\n                if score == -1:  # Anomaly detected\n                    anomalies.append({\n                        \"timestamp\": d[\"timestamp\"],\n                        \"metrics\": d[\"metrics\"],\n                        \"score\": float(self.anomaly_detector.score_samples(features[i:i+1])[0])\n                    })\n                    \n            return anomalies\n            \n        except Exception as e:\n            self.logger.error(f\"Error detecting anomalies: {str(e)}\")\n            return []\n            \n    def _analyze_patterns(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Analyze patterns in process data\"\"\"\n        if len(data) < 2:\n            return []\n            \n        patterns = []\n        metrics = [\"efficiency\", \"cost_effectiveness\", \"resource_utilization\",\n                  \"exploration_coverage\", \"success_rate\", \"risk_score\"]\n                  \n        for metric in metrics:\n            values = [d[\"metrics\"][metric] for d in data]\n            \n            # Detect trends\n            trend = np.polyfit(range(len(values)), values, 1)[0]\n            \n            if abs(trend) > 0.1:\n                pattern = {\n                    \"type\": \"trend\",\n                    \"metric\": metric,\n                    \"direction\": \"increasing\" if trend > 0 else \"decreasing\",\n                    \"magnitude\": abs(trend),\n                    \"confidence\": self._calculate_pattern_confidence(values)\n                }\n                patterns.append(pattern)\n                \n            # Detect oscillations\n            if len(values) > 3:\n                oscillation = np.std(values) / np.mean(values)\n                if oscillation > 0.2:\n                    pattern = {\n                        \"type\": \"oscillation\",\n                        \"metric\": metric,\n                        \"magnitude\": oscillation,\n                        \"confidence\": self._calculate_pattern_confidence(values)\n                    }\n                    patterns.append(pattern)\n                    \n        return patterns\n        \n    def _generate_alerts(self, data: List[Dict[str, Any]],\n                        anomalies: List[Dict[str, Any]],\n                        patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Generate alerts based on data analysis\"\"\"\n        alerts = []\n        \n        # Anomaly alerts\n        for anomaly in anomalies:\n            alerts.append({\n                \"type\": \"anomaly\",\n                \"severity\": \"high\",\n                \"message\": f\"Detected process anomaly at {anomaly['timestamp']}\",\n                \"details\": anomaly\n            })\n            \n        # Pattern alerts\n        for pattern in patterns:\n            if pattern[\"type\"] == \"trend\" and pattern[\"magnitude\"] > 0.2:\n                alerts.append({\n                    \"type\": \"pattern\",\n                    \"severity\": \"medium\",\n                    \"message\": f\"Significant {pattern['direction']} trend in {pattern['metric']}\",\n                    \"details\": pattern\n                })\n                \n        # Threshold alerts\n        latest_data = data[-1] if data else None\n        if latest_data:\n            metrics = latest_data[\"metrics\"]\n            for metric, threshold in self.alert_thresholds.items():\n                if metric in metrics:\n                    value = metrics[metric]\n                    if (metric in [\"cost\", \"risk\"] and value > threshold) or \\\n                       (metric not in [\"cost\", \"risk\"] and value < threshold):\n                        alerts.append({\n                            \"type\": \"threshold\",\n                            \"severity\": \"medium\",\n                            \"message\": f\"{metric.capitalize()} threshold violated: {value:.2f}\",\n                            \"details\": {\n                                \"metric\": metric,\n                                \"value\": value,\n                                \"threshold\": threshold\n                            }\n                        })\n                        \n        return alerts\n        \n    def _calculate_pattern_confidence(self, values: List[float]) -> float:\n        \"\"\"Calculate confidence score for detected pattern\"\"\"\n        if len(values) < 2:\n            return 0.0\n            \n        # Consider factors like:\n        # - Number of data points\n        # - Variance in the data\n        # - Pattern strength\n        n_points = len(values)\n        variance = np.var(values)\n        mean = np.mean(values)\n        \n        # Calculate confidence score\n        confidence = (\n            0.5 * min(1.0, n_points / 10) +  # More points = higher confidence\n            0.3 * (1 - min(1.0, variance / (mean + 1e-6))) +  # Less variance = higher confidence\n            0.2  # Base confidence\n        )\n        \n        return float(confidence)\n\n    def _prepare_pattern_features(self, data: List[Dict[str, Any]]) -> torch.Tensor:\n        \"\"\"Prepare features for pattern detection\"\"\"\n        features = []\n        \n        for entry in data:\n            metrics = entry.get(\"metrics\", {})\n            feature_vector = [\n                metrics.get(\"efficiency\", 0.0),\n                metrics.get(\"cost_effectiveness\", 0.0),\n                metrics.get(\"resource_utilization\", 0.0),\n                metrics.get(\"exploration_coverage\", 0.0),\n                metrics.get(\"success_rate\", 0.0),\n                metrics.get(\"risk_score\", 0.0),\n                len(entry.get(\"issues\", [])),\n                len(entry.get(\"recommendations\", [])),\n                entry.get(\"complexity_score\", 0.0)\n            ]\n            features.append(feature_vector)\n            \n        X = np.array(features)\n        X_scaled = self.scaler.fit_transform(X)\n        \n        return torch.tensor(X_scaled, dtype=torch.float32)\n        \n    def _get_pattern_type(self, pattern: torch.Tensor) -> str:\n        \"\"\"Get pattern type from model output\"\"\"\n        pattern_types = [\"degradation\", \"improvement\", \"fluctuation\"]\n        pattern_idx = torch.argmax(pattern[0]).item()\n        return pattern_types[pattern_idx]\n        \n    def _get_affected_metrics(self, impact: torch.Tensor) -> List[str]:\n        \"\"\"Get metrics affected by pattern\"\"\"\n        metrics = [\"efficiency\", \"cost_effectiveness\", \"resource_utilization\",\n                  \"exploration_coverage\", \"success_rate\", \"risk_score\"]\n        threshold = 0.5\n        \n        return [\n            metric\n            for i, metric in enumerate(metrics)\n            if torch.sigmoid(impact[i]) > threshold\n        ]\n        \n    def _generate_pattern_description(self, pattern_type: str,\n                                   affected_metrics: List[str]) -> str:\n        \"\"\"Generate human-readable pattern description\"\"\"\n        metric_str = \", \".join(affected_metrics)\n        \n        if pattern_type == \"degradation\":\n            return f\"Detected process degradation affecting {metric_str}\"\n        elif pattern_type == \"improvement\":\n            return f\"Detected process improvement in {metric_str}\"\n        else:\n            return f\"Detected process fluctuations in {metric_str}\"\n            \n    def _generate_pattern_recommendations(self,\n                                       affected_metrics: List[str]) -> List[str]:\n        \"\"\"Generate recommendations based on pattern\"\"\"\n        recommendations = []\n        \n        for metric in affected_metrics:\n            recommendations.append(f\"Investigate causes of {metric} degradation\")\n            recommendations.append(f\"Implement process controls for {metric}\")\n            \n        return recommendations\n        \n    def _calculate_process_metrics(self, data: Dict[str, Any]) -> ProcessMetrics:\n        \"\"\"Calculate process performance metrics\"\"\"\n        return ProcessMetrics(\n            efficiency=self._calculate_efficiency(data),\n            cost_effectiveness=self._calculate_cost_effectiveness(data),\n            resource_utilization=self._calculate_resource_utilization(data),\n            exploration_coverage=self._calculate_exploration_coverage(data),\n            success_rate=self._calculate_success_rate(data),\n            risk_score=self._calculate_risk_score(data)\n        )\n        \n    def _calculate_efficiency(self, data: Dict[str, Any]) -> float:\n        \"\"\"Calculate process efficiency\"\"\"\n        # Implementation of _calculate_efficiency method\n        pass\n        \n    def _calculate_cost_effectiveness(self, data: Dict[str, Any]) -> float:\n        \"\"\"Calculate process cost effectiveness\"\"\"\n        # Implementation of _calculate_cost_effectiveness method\n        pass\n        \n    def _calculate_resource_utilization(self, data: Dict[str, Any]) -> float:\n        \"\"\"Calculate process resource utilization\"\"\"\n        # Implementation of _calculate_resource_utilization method\n        pass\n        \n    def _calculate_exploration_coverage(self, data: Dict[str, Any]) -> float:\n        \"\"\"Calculate process exploration coverage\"\"\"\n        # Implementation of _calculate_exploration_coverage method\n        pass\n        \n    def _calculate_success_rate(self, data: Dict[str, Any]) -> float:\n        \"\"\"Calculate process success rate\"\"\"\n        # Implementation of _calculate_success_rate method\n        pass\n        \n    def _calculate_risk_score(self, data: Dict[str, Any]) -> float:\n        \"\"\"Calculate process risk score\"\"\"\n        # Implementation of _calculate_risk_score method\n        pass\n        \n    def _assess_data_quality(self, metrics: ProcessMetrics) -> float:\n        \"\"\"Assess the quality of process data\"\"\"\n        # Implementation of _assess_data_quality method\n        pass\n        \n    def _detect_bottlenecks(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Detect process bottlenecks\"\"\"\n        # Implementation of _detect_bottlenecks method\n        pass\n        \n    def _analyze_resource_bottlenecks(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Analyze resource bottlenecks\"\"\"\n        # Implementation of _analyze_resource_bottlenecks method\n        pass\n        \n    def _analyze_performance_bottlenecks(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Analyze performance bottlenecks\"\"\"\n        # Implementation of _analyze_performance_bottlenecks method\n        pass\n        \n    def _analyze_cost_bottlenecks(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Analyze cost bottlenecks\"\"\"\n        # Implementation of _analyze_cost_bottlenecks method\n        pass\n        \n    def _prepare_anomaly_features(self, data: Dict[str, Any]) -> np.ndarray:\n        \"\"\"Prepare features for anomaly detection\"\"\"\n        # Implementation of _prepare_anomaly_features method\n        pass\n        \n    def _analyze_historical_patterns(self,\n                                   current_data: Dict[str, Any],\n                                   historical_data: Dict[str, Any]) -> List[ProcessPattern]:\n        \"\"\"Analyze historical patterns in process data\"\"\"\n        # Implementation of _analyze_historical_patterns method\n        pass\n        \n    def _convert_pattern_outputs(self, pattern_outputs: torch.Tensor) -> List[ProcessPattern]:\n        \"\"\"Convert pattern outputs to process patterns\"\"\"\n        # Implementation of _convert_pattern_outputs method\n        pass\n        \n    def _calculate_historical_metrics(self,\n                                   historical_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Calculate average historical metrics\"\"\"\n        # Implementation of _calculate_historical_metrics method\n        pass\n        \n    def _calculate_trend(self, values: List[float]) -> float:\n        \"\"\"Calculate trend in process data\"\"\"\n        # Implementation of _calculate_trend method\n        pass\n        \n    def _identify_optimization_opportunities(self,\n                                         analysis_result: ProcessAnalysisResult) -> List[Dict[str, Any]]:\n        \"\"\"Identify optimization opportunities from analysis\"\"\"\n        # Implementation of _identify_optimization_opportunities method\n        pass "}
{"type": "source_file", "path": "minesight/core/visualization/advanced_visualizer.py", "content": "\"\"\"\nAdvanced visualization utilities\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom typing import Dict, List, Any, Optional, Union\nimport folium\nfrom folium import plugins\nimport torch\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nimport umap\n\nclass AdvancedDataVisualizer:\n    \"\"\"Advanced data visualization utility\"\"\"\n    \n    def __init__(self,\n                 data: Dict[str, pd.DataFrame],\n                 config: Dict[str, Any]):\n        \"\"\"\n        Initialize visualizer\n        \n        Args:\n            data: Dictionary with data frames\n            config: Visualization configuration\n        \"\"\"\n        self.data = data\n        self.config = config\n        \n    def plot_3d_scatter(self,\n                       x: str,\n                       y: str,\n                       z: str,\n                       color: Optional[str] = None,\n                       size: Optional[str] = None,\n                       output_path: Optional[str] = None):\n        \"\"\"\n        Create 3D scatter plot\n        \n        Args:\n            x: X-axis feature\n            y: Y-axis feature\n            z: Z-axis feature\n            color: Color feature\n            size: Size feature\n            output_path: Path to save plot\n        \"\"\"\n        fig = px.scatter_3d(\n            self.data['deposits'],\n            x=x,\n            y=y,\n            z=z,\n            color=color,\n            size=size,\n            title='3D Feature Visualization'\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n            \n    def create_animated_map(self,\n                          time_column: str,\n                          center: List[float],\n                          zoom: int = 8) -> folium.Map:\n        \"\"\"\n        Create animated map\n        \n        Args:\n            time_column: Column for time series\n            center: Map center coordinates [lat, lon]\n            zoom: Initial zoom level\n            \n        Returns:\n            Folium map\n        \"\"\"\n        # Create base map\n        m = folium.Map(\n            location=center,\n            zoom_start=zoom,\n            tiles='OpenStreetMap'\n        )\n        \n        # Create time series data\n        time_data = []\n        \n        for time in sorted(self.data['deposits'][time_column].unique()):\n            time_points = []\n            subset = self.data['deposits'][\n                self.data['deposits'][time_column] == time\n            ]\n            \n            for _, row in subset.iterrows():\n                time_points.append({\n                    'lat': row['latitude'],\n                    'lon': row['longitude'],\n                    'radius': 5,\n                    'color': 'red' if row['deposit'] == 1 else 'blue',\n                    'popup': f\"Time: {time}<br>\"\n                            f\"Deposit: {row['deposit']}\"\n                })\n                \n            time_data.append(time_points)\n            \n        # Add time slider\n        plugins.TimeSliderChoropleth({\n            str(i): {\n                'data': points\n            } for i, points in enumerate(time_data)\n        }).add_to(m)\n        \n        return m\n        \n    def plot_feature_importance_heatmap(self,\n                                      importance_matrix: np.ndarray,\n                                      feature_names: List[str],\n                                      output_path: Optional[str] = None):\n        \"\"\"\n        Plot feature importance heatmap\n        \n        Args:\n            importance_matrix: Feature importance matrix\n            feature_names: Feature names\n            output_path: Path to save plot\n        \"\"\"\n        plt.figure(figsize=(12, 8))\n        sns.heatmap(\n            importance_matrix,\n            xticklabels=feature_names,\n            yticklabels=range(importance_matrix.shape[0]),\n            cmap='YlOrRd',\n            annot=True\n        )\n        plt.title('Feature Importance Across Models')\n        plt.xlabel('Features')\n        plt.ylabel('Models')\n        \n        if output_path:\n            plt.savefig(output_path)\n            plt.close()\n        else:\n            plt.show()\n\nclass AdvancedModelVisualizer:\n    \"\"\"Advanced model visualization utility\"\"\"\n    \n    def __init__(self,\n                 model_outputs: Dict[str, Any],\n                 config: Dict[str, Any]):\n        \"\"\"\n        Initialize visualizer\n        \n        Args:\n            model_outputs: Model output dictionary\n            config: Visualization configuration\n        \"\"\"\n        self.outputs = model_outputs\n        self.config = config\n        \n    def plot_attention_weights(self,\n                             attention_weights: torch.Tensor,\n                             feature_names: List[str],\n                             output_path: Optional[str] = None):\n        \"\"\"\n        Plot attention weights\n        \n        Args:\n            attention_weights: Attention weight matrix\n            feature_names: Feature names\n            output_path: Path to save plot\n        \"\"\"\n        weights = attention_weights.cpu().numpy()\n        \n        fig = px.imshow(\n            weights,\n            labels=dict(\n                x='Key Features',\n                y='Query Features',\n                color='Attention Weight'\n            ),\n            x=feature_names,\n            y=feature_names,\n            title='Attention Weights Visualization'\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n            \n    def plot_latent_space_clustering(self,\n                                   method: str = 'tsne',\n                                   perplexity: int = 30,\n                                   n_neighbors: int = 15,\n                                   min_dist: float = 0.1,\n                                   output_path: Optional[str] = None):\n        \"\"\"\n        Plot latent space with dimensionality reduction\n        \n        Args:\n            method: Dimensionality reduction method ('tsne', 'pca', 'umap')\n            perplexity: t-SNE perplexity\n            n_neighbors: UMAP n_neighbors\n            min_dist: UMAP min_dist\n            output_path: Path to save plot\n        \"\"\"\n        if 'z' not in self.outputs:\n            raise ValueError(\"No latent representations found\")\n            \n        z = self.outputs['z'].cpu().numpy()\n        \n        # Apply dimensionality reduction\n        if method == 'tsne':\n            reducer = TSNE(n_components=2, perplexity=perplexity)\n        elif method == 'pca':\n            reducer = PCA(n_components=2)\n        elif method == 'umap':\n            reducer = umap.UMAP(\n                n_neighbors=n_neighbors,\n                min_dist=min_dist\n            )\n        else:\n            raise ValueError(f\"Unknown method: {method}\")\n            \n        z_2d = reducer.fit_transform(z)\n        \n        # Create plot\n        fig = px.scatter(\n            x=z_2d[:, 0],\n            y=z_2d[:, 1],\n            color=self.outputs.get('labels', None),\n            title=f'Latent Space Clustering ({method.upper()})'\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n            \n    def plot_uncertainty_map(self,\n                           region: Dict[str, float],\n                           resolution: float = 0.01,\n                           output_path: Optional[str] = None):\n        \"\"\"\n        Plot prediction uncertainty map\n        \n        Args:\n            region: Region boundaries\n            resolution: Grid resolution\n            output_path: Path to save plot\n        \"\"\"\n        if 'uncertainty' not in self.outputs:\n            raise ValueError(\"No uncertainty estimates found\")\n            \n        # Create prediction grid\n        lat = np.arange(\n            region['min_lat'],\n            region['max_lat'],\n            resolution\n        )\n        lon = np.arange(\n            region['min_lon'],\n            region['max_lon'],\n            resolution\n        )\n        \n        lat_grid, lon_grid = np.meshgrid(lat, lon)\n        uncertainty = self.outputs['uncertainty'].reshape(\n            len(lon),\n            len(lat)\n        )\n        \n        # Create figure with two subplots\n        fig = make_subplots(\n            rows=1,\n            cols=2,\n            subplot_titles=[\n                'Prediction Probability',\n                'Prediction Uncertainty'\n            ]\n        )\n        \n        # Add probability heatmap\n        fig.add_trace(\n            go.Heatmap(\n                z=self.outputs['probability'].reshape(len(lon), len(lat)),\n                x=lon,\n                y=lat,\n                colorscale='Viridis',\n                colorbar=dict(title='Probability'),\n                showscale=True\n            ),\n            row=1,\n            col=1\n        )\n        \n        # Add uncertainty heatmap\n        fig.add_trace(\n            go.Heatmap(\n                z=uncertainty,\n                x=lon,\n                y=lat,\n                colorscale='Reds',\n                colorbar=dict(title='Uncertainty'),\n                showscale=True\n            ),\n            row=1,\n            col=2\n        )\n        \n        fig.update_layout(\n            title='Prediction and Uncertainty Maps',\n            height=500\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n            \n    def plot_ensemble_predictions(self,\n                                data: Dict[str, torch.Tensor],\n                                output_path: Optional[str] = None):\n        \"\"\"\n        Plot ensemble model predictions\n        \n        Args:\n            data: Input data\n            output_path: Path to save plot\n        \"\"\"\n        if 'ensemble_outputs' not in self.outputs:\n            raise ValueError(\"No ensemble outputs found\")\n            \n        # Get predictions from each model\n        predictions = torch.stack(\n            self.outputs['ensemble_outputs'],\n            dim=0\n        ).cpu().numpy()\n        \n        # Create violin plot\n        fig = go.Figure()\n        \n        for i in range(predictions.shape[1]):\n            fig.add_trace(\n                go.Violin(\n                    y=predictions[:, i],\n                    name=f'Sample {i}',\n                    box_visible=True,\n                    meanline_visible=True\n                )\n            )\n            \n        fig.update_layout(\n            title='Ensemble Predictions Distribution',\n            yaxis_title='Prediction',\n            showlegend=False\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n\nclass InteractiveDashboard:\n    \"\"\"Interactive dashboard with advanced visualizations\"\"\"\n    \n    def __init__(self,\n                 data_visualizer: AdvancedDataVisualizer,\n                 model_visualizer: AdvancedModelVisualizer):\n        \"\"\"\n        Initialize dashboard\n        \n        Args:\n            data_visualizer: Data visualizer instance\n            model_visualizer: Model visualizer instance\n        \"\"\"\n        self.data_viz = data_visualizer\n        self.model_viz = model_visualizer\n        \n    def create_exploration_dashboard(self,\n                                   output_path: str):\n        \"\"\"\n        Create exploration dashboard\n        \n        Args:\n            output_path: Path to save dashboard\n        \"\"\"\n        # Create subplots\n        fig = make_subplots(\n            rows=3,\n            cols=2,\n            subplot_titles=[\n                '3D Feature Space',\n                'Feature Importance',\n                'Correlation Matrix',\n                'Latent Space',\n                'Prediction Map',\n                'Uncertainty Map'\n            ],\n            specs=[\n                [{'type': 'scene'}, {'type': 'heatmap'}],\n                [{'type': 'heatmap'}, {'type': 'scatter'}],\n                [{'type': 'heatmap'}, {'type': 'heatmap'}]\n            ]\n        )\n        \n        # Add plots\n        self.data_viz.plot_3d_scatter(\n            'latitude',\n            'longitude',\n            'elevation',\n            color='deposit',\n            fig=fig,\n            row=1,\n            col=1\n        )\n        \n        self.model_viz.plot_feature_importance_heatmap(\n            self.model_viz.outputs['feature_importance'],\n            self.data_viz.config['feature_names'],\n            fig=fig,\n            row=1,\n            col=2\n        )\n        \n        self.data_viz.plot_correlation_matrix(\n            self.data_viz.config['feature_names'],\n            fig=fig,\n            row=2,\n            col=1\n        )\n        \n        self.model_viz.plot_latent_space_clustering(\n            method='umap',\n            fig=fig,\n            row=2,\n            col=2\n        )\n        \n        self.model_viz.plot_prediction_map(\n            self.model_viz.config['region'],\n            fig=fig,\n            row=3,\n            col=1\n        )\n        \n        self.model_viz.plot_uncertainty_map(\n            self.model_viz.config['region'],\n            fig=fig,\n            row=3,\n            col=2\n        )\n        \n        # Update layout\n        fig.update_layout(\n            height=1200,\n            showlegend=True,\n            title='MineSight Exploration Dashboard'\n        )\n        \n        # Save dashboard\n        fig.write_html(output_path) "}
{"type": "source_file", "path": "minesight/core/optimization/resource_optimizer.py", "content": "\"\"\"\nIntelligent resource optimization system for mineral exploration\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Tuple\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nfrom scipy.optimize import linear_sum_assignment\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\n\n@dataclass\nclass ResourceMetrics:\n    \"\"\"Resource performance metrics\"\"\"\n    utilization: float\n    efficiency: float\n    cost_effectiveness: float\n    availability: float\n    performance_score: float\n\n@dataclass\nclass OptimizationResult:\n    \"\"\"Resource optimization result\"\"\"\n    resource_id: str\n    current_metrics: ResourceMetrics\n    optimal_allocation: Dict[str, float]\n    expected_improvements: Dict[str, float]\n    recommendations: List[str]\n    confidence: float\n\nclass ResourceOptimizationModel(nn.Module):\n    \"\"\"Neural network for resource optimization\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int = 128):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU()\n        )\n        \n        self.allocation_head = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 4)  # [utilization, efficiency, cost, availability]\n        )\n        \n        self.impact_head = nn.Sequential(\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 4, 3)  # [performance_impact, cost_impact, risk_impact]\n        )\n\nclass ResourceOptimizer:\n    \"\"\"Intelligent resource optimization system\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the resource optimizer\"\"\"\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model = None\n        self.scaler = StandardScaler()\n        self.importance_model = RandomForestRegressor(n_estimators=100)\n        self.historical_data = []\n        \n    def optimize_resources(self,\n                         current_resources: Dict[str, Any],\n                         activities: List[Dict[str, Any]],\n                         constraints: Optional[Dict[str, Any]] = None) -> List[OptimizationResult]:\n        \"\"\"\n        Optimize resource allocation\n        \n        Args:\n            current_resources: Current resource states\n            activities: Planned or ongoing activities\n            constraints: Optional optimization constraints\n            \n        Returns:\n            List of optimization results\n        \"\"\"\n        # Calculate current metrics\n        current_metrics = self._calculate_resource_metrics(current_resources)\n        \n        # Prepare optimization features\n        features = self._prepare_optimization_features(\n            current_resources,\n            activities,\n            current_metrics\n        )\n        \n        # Generate optimal allocations\n        optimal_allocations = self._generate_optimal_allocations(\n            features,\n            constraints\n        )\n        \n        # Calculate expected improvements\n        improvements = self._calculate_expected_improvements(\n            current_metrics,\n            optimal_allocations\n        )\n        \n        # Generate recommendations\n        results = []\n        for resource_id, metrics in current_metrics.items():\n            result = OptimizationResult(\n                resource_id=resource_id,\n                current_metrics=metrics,\n                optimal_allocation=optimal_allocations[resource_id],\n                expected_improvements=improvements[resource_id],\n                recommendations=self._generate_recommendations(\n                    resource_id,\n                    metrics,\n                    optimal_allocations[resource_id],\n                    improvements[resource_id]\n                ),\n                confidence=self._calculate_confidence(\n                    resource_id,\n                    metrics,\n                    optimal_allocations[resource_id]\n                )\n            )\n            results.append(result)\n        \n        return results\n    \n    def analyze_efficiency(self,\n                         resource_data: Dict[str, Any],\n                         time_period: str = \"30d\") -> Dict[str, Any]:\n        \"\"\"\n        Analyze resource efficiency\n        \n        Args:\n            resource_data: Historical resource data\n            time_period: Analysis time period\n            \n        Returns:\n            Efficiency analysis results\n        \"\"\"\n        analysis_results = {\n            \"efficiency_metrics\": {},\n            \"utilization_patterns\": {},\n            \"cost_analysis\": {},\n            \"optimization_opportunities\": []\n        }\n        \n        # Calculate efficiency metrics\n        for resource_id, data in resource_data.items():\n            metrics = self._analyze_resource_efficiency(data, time_period)\n            analysis_results[\"efficiency_metrics\"][resource_id] = metrics\n        \n        # Analyze utilization patterns\n        analysis_results[\"utilization_patterns\"] = self._analyze_utilization_patterns(\n            resource_data,\n            time_period\n        )\n        \n        # Perform cost analysis\n        analysis_results[\"cost_analysis\"] = self._analyze_resource_costs(\n            resource_data,\n            time_period\n        )\n        \n        # Identify optimization opportunities\n        analysis_results[\"optimization_opportunities\"] = self._identify_optimization_opportunities(\n            analysis_results[\"efficiency_metrics\"],\n            analysis_results[\"utilization_patterns\"],\n            analysis_results[\"cost_analysis\"]\n        )\n        \n        return analysis_results\n    \n    def predict_resource_needs(self,\n                             historical_data: Dict[str, Any],\n                             future_activities: List[Dict[str, Any]],\n                             prediction_horizon: int = 30) -> Dict[str, Any]:\n        \"\"\"\n        Predict future resource needs\n        \n        Args:\n            historical_data: Historical resource usage data\n            future_activities: Planned future activities\n            prediction_horizon: Number of days to predict\n            \n        Returns:\n            Resource needs predictions\n        \"\"\"\n        predictions = {\n            \"resource_demands\": {},\n            \"capacity_requirements\": {},\n            \"risk_factors\": {},\n            \"recommendations\": []\n        }\n        \n        # Predict resource demands\n        predictions[\"resource_demands\"] = self._predict_resource_demands(\n            historical_data,\n            future_activities,\n            prediction_horizon\n        )\n        \n        # Calculate capacity requirements\n        predictions[\"capacity_requirements\"] = self._calculate_capacity_requirements(\n            predictions[\"resource_demands\"],\n            future_activities\n        )\n        \n        # Analyze risk factors\n        predictions[\"risk_factors\"] = self._analyze_prediction_risks(\n            predictions[\"resource_demands\"],\n            historical_data\n        )\n        \n        # Generate recommendations\n        predictions[\"recommendations\"] = self._generate_prediction_recommendations(\n            predictions[\"resource_demands\"],\n            predictions[\"capacity_requirements\"],\n            predictions[\"risk_factors\"]\n        )\n        \n        return predictions\n    \n    def monitor_and_adjust(self,\n                          current_state: Dict[str, Any],\n                          optimal_allocation: Dict[str, Any],\n                          thresholds: Optional[Dict[str, float]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Monitor resource usage and make real-time adjustments\n        \n        Args:\n            current_state: Current resource state\n            optimal_allocation: Optimal resource allocation\n            thresholds: Adjustment thresholds\n            \n        Returns:\n            Monitoring results and adjustments\n        \"\"\"\n        results = {\n            \"status\": \"nominal\",\n            \"deviations\": {},\n            \"adjustments\": {},\n            \"alerts\": []\n        }\n        \n        # Check for deviations\n        deviations = self._check_allocation_deviations(\n            current_state,\n            optimal_allocation,\n            thresholds\n        )\n        \n        if deviations:\n            results[\"status\"] = \"adjustment_needed\"\n            results[\"deviations\"] = deviations\n            \n            # Calculate necessary adjustments\n            results[\"adjustments\"] = self._calculate_adjustments(\n                current_state,\n                optimal_allocation,\n                deviations\n            )\n            \n            # Generate alerts for significant deviations\n            results[\"alerts\"] = self._generate_deviation_alerts(deviations)\n        \n        return results\n    \n    def _calculate_resource_metrics(self,\n                                 resources: Dict[str, Any]) -> Dict[str, ResourceMetrics]:\n        \"\"\"Calculate current resource metrics\"\"\"\n        metrics = {}\n        \n        for resource_id, data in resources.items():\n            metrics[resource_id] = ResourceMetrics(\n                utilization=data.get(\"utilization\", 0.0),\n                efficiency=data.get(\"efficiency\", 0.0),\n                cost_effectiveness=data.get(\"cost_effectiveness\", 0.0),\n                availability=data.get(\"availability\", 0.0),\n                performance_score=self._calculate_performance_score(data)\n            )\n        \n        return metrics\n    \n    def _prepare_optimization_features(self,\n                                    resources: Dict[str, Any],\n                                    activities: List[Dict[str, Any]],\n                                    metrics: Dict[str, ResourceMetrics]) -> torch.Tensor:\n        \"\"\"Prepare features for optimization model\"\"\"\n        features = []\n        \n        for resource_id, data in resources.items():\n            resource_features = [\n                metrics[resource_id].utilization,\n                metrics[resource_id].efficiency,\n                metrics[resource_id].cost_effectiveness,\n                metrics[resource_id].availability,\n                len([a for a in activities if resource_id in a.get(\"required_resources\", [])]),\n                data.get(\"cost_per_day\", 0.0),\n                data.get(\"maintenance_factor\", 1.0)\n            ]\n            features.append(resource_features)\n        \n        return torch.tensor(features, dtype=torch.float32, device=self.device)\n    \n    def _generate_optimal_allocations(self,\n                                   features: torch.Tensor,\n                                   constraints: Optional[Dict[str, Any]] = None) -> Dict[str, Dict[str, float]]:\n        \"\"\"Generate optimal resource allocations\"\"\"\n        self.model.eval()\n        with torch.no_grad():\n            allocations, impacts = self.model(features)\n        \n        # Convert to dictionary format\n        optimal_allocations = {}\n        for i, allocation in enumerate(allocations):\n            optimal_allocations[f\"resource_{i}\"] = {\n                \"utilization\": float(allocation[0]),\n                \"efficiency\": float(allocation[1]),\n                \"cost\": float(allocation[2]),\n                \"availability\": float(allocation[3])\n            }\n        \n        return optimal_allocations\n    \n    def _calculate_expected_improvements(self,\n                                      current_metrics: Dict[str, ResourceMetrics],\n                                      optimal_allocations: Dict[str, Dict[str, float]]) -> Dict[str, Dict[str, float]]:\n        \"\"\"Calculate expected improvements from optimization\"\"\"\n        improvements = {}\n        \n        for resource_id, metrics in current_metrics.items():\n            if resource_id in optimal_allocations:\n                optimal = optimal_allocations[resource_id]\n                improvements[resource_id] = {\n                    \"utilization_improvement\": optimal[\"utilization\"] - metrics.utilization,\n                    \"efficiency_improvement\": optimal[\"efficiency\"] - metrics.efficiency,\n                    \"cost_reduction\": metrics.cost_effectiveness - optimal[\"cost\"],\n                    \"availability_improvement\": optimal[\"availability\"] - metrics.availability\n                }\n        \n        return improvements\n    \n    def _generate_recommendations(self,\n                               resource_id: str,\n                               current_metrics: ResourceMetrics,\n                               optimal_allocation: Dict[str, float],\n                               improvements: Dict[str, float]) -> List[str]:\n        \"\"\"Generate optimization recommendations\"\"\"\n        recommendations = []\n        \n        # Utilization recommendations\n        if improvements[\"utilization_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Increase {resource_id} utilization by {improvements['utilization_improvement']:.1%}\"\n            )\n        elif improvements[\"utilization_improvement\"] < -0.1:\n            recommendations.append(\n                f\"Decrease {resource_id} utilization by {abs(improvements['utilization_improvement']):.1%}\"\n            )\n        \n        # Efficiency recommendations\n        if improvements[\"efficiency_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Improve {resource_id} efficiency through optimization\"\n            )\n        \n        # Cost recommendations\n        if improvements[\"cost_reduction\"] > 0.1:\n            recommendations.append(\n                f\"Implement cost reduction measures for {resource_id}\"\n            )\n        \n        # Availability recommendations\n        if improvements[\"availability_improvement\"] > 0.1:\n            recommendations.append(\n                f\"Increase {resource_id} availability through better scheduling\"\n            )\n        \n        return recommendations\n    \n    def _calculate_confidence(self,\n                           resource_id: str,\n                           current_metrics: ResourceMetrics,\n                           optimal_allocation: Dict[str, float]) -> float:\n        \"\"\"Calculate confidence score for optimization results\"\"\"\n        # Calculate based on historical accuracy and current data quality\n        historical_accuracy = 0.8  # Placeholder\n        data_quality = self._assess_data_quality(current_metrics)\n        \n        confidence = (historical_accuracy + data_quality) / 2\n        return float(confidence)\n    \n    def _assess_data_quality(self, metrics: ResourceMetrics) -> float:\n        \"\"\"Assess quality of resource metrics data\"\"\"\n        # Check for missing or invalid values\n        metric_values = [\n            metrics.utilization,\n            metrics.efficiency,\n            metrics.cost_effectiveness,\n            metrics.availability\n        ]\n        \n        valid_values = [v for v in metric_values if 0 <= v <= 1]\n        return len(valid_values) / len(metric_values)\n    \n    def _analyze_resource_efficiency(self,\n                                  resource_data: Dict[str, Any],\n                                  time_period: str) -> Dict[str, float]:\n        \"\"\"Analyze resource efficiency metrics\"\"\"\n        return {\n            \"average_utilization\": np.mean(resource_data.get(\"utilization_history\", [])),\n            \"efficiency_trend\": self._calculate_efficiency_trend(resource_data),\n            \"cost_per_unit\": self._calculate_cost_per_unit(resource_data),\n            \"availability_rate\": self._calculate_availability_rate(resource_data)\n        }\n    \n    def _analyze_utilization_patterns(self,\n                                   resource_data: Dict[str, Any],\n                                   time_period: str) -> Dict[str, Any]:\n        \"\"\"Analyze resource utilization patterns\"\"\"\n        patterns = {}\n        for resource_id, data in resource_data.items():\n            patterns[resource_id] = {\n                \"peak_hours\": self._identify_peak_hours(data),\n                \"seasonal_patterns\": self._identify_seasonal_patterns(data),\n                \"utilization_trends\": self._calculate_utilization_trends(data)\n            }\n        return patterns\n    \n    def _analyze_resource_costs(self,\n                             resource_data: Dict[str, Any],\n                             time_period: str) -> Dict[str, Any]:\n        \"\"\"Analyze resource costs\"\"\"\n        return {\n            \"total_costs\": self._calculate_total_costs(resource_data),\n            \"cost_breakdown\": self._generate_cost_breakdown(resource_data),\n            \"cost_trends\": self._analyze_cost_trends(resource_data),\n            \"optimization_potential\": self._estimate_cost_optimization_potential(resource_data)\n        }\n    \n    def _identify_optimization_opportunities(self,\n                                         efficiency_metrics: Dict[str, Dict[str, float]],\n                                         utilization_patterns: Dict[str, Any],\n                                         cost_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Identify resource optimization opportunities\"\"\"\n        opportunities = []\n        \n        for resource_id in efficiency_metrics.keys():\n            if self._has_optimization_potential(\n                efficiency_metrics[resource_id],\n                utilization_patterns[resource_id],\n                cost_analysis\n            ):\n                opportunities.append({\n                    \"resource_id\": resource_id,\n                    \"type\": self._determine_optimization_type(\n                        efficiency_metrics[resource_id],\n                        utilization_patterns[resource_id]\n                    ),\n                    \"potential_impact\": self._estimate_optimization_impact(\n                        efficiency_metrics[resource_id],\n                        cost_analysis\n                    ),\n                    \"implementation_complexity\": self._estimate_implementation_complexity(\n                        resource_id,\n                        efficiency_metrics[resource_id]\n                    )\n                })\n        \n        return opportunities\n    \n    def _predict_resource_demands(self,\n                               historical_data: Dict[str, Any],\n                               future_activities: List[Dict[str, Any]],\n                               prediction_horizon: int) -> Dict[str, List[float]]:\n        \"\"\"Predict future resource demands\"\"\"\n        demands = {}\n        \n        for resource_id in historical_data.keys():\n            demands[resource_id] = self._forecast_resource_demand(\n                historical_data[resource_id],\n                future_activities,\n                prediction_horizon\n            )\n        \n        return demands\n    \n    def _calculate_capacity_requirements(self,\n                                     resource_demands: Dict[str, List[float]],\n                                     future_activities: List[Dict[str, Any]]) -> Dict[str, Dict[str, float]]:\n        \"\"\"Calculate future capacity requirements\"\"\"\n        requirements = {}\n        \n        for resource_id, demands in resource_demands.items():\n            requirements[resource_id] = {\n                \"peak_demand\": max(demands),\n                \"average_demand\": np.mean(demands),\n                \"minimum_capacity\": self._calculate_minimum_capacity(demands),\n                \"recommended_capacity\": self._calculate_recommended_capacity(demands)\n            }\n        \n        return requirements\n    \n    def _analyze_prediction_risks(self,\n                               resource_demands: Dict[str, List[float]],\n                               historical_data: Dict[str, Any]) -> Dict[str, Dict[str, float]]:\n        \"\"\"Analyze risks in resource predictions\"\"\"\n        risks = {}\n        \n        for resource_id, demands in resource_demands.items():\n            risks[resource_id] = {\n                \"demand_volatility\": np.std(demands),\n                \"prediction_uncertainty\": self._calculate_prediction_uncertainty(demands),\n                \"historical_accuracy\": self._calculate_historical_accuracy(\n                    resource_id,\n                    historical_data\n                ),\n                \"risk_score\": self._calculate_prediction_risk_score(\n                    demands,\n                    historical_data.get(resource_id, {})\n                )\n            }\n        \n        return risks\n    \n    def _generate_prediction_recommendations(self,\n                                         demands: Dict[str, List[float]],\n                                         requirements: Dict[str, Dict[str, float]],\n                                         risks: Dict[str, Dict[str, float]]) -> List[Dict[str, Any]]:\n        \"\"\"Generate recommendations based on predictions\"\"\"\n        recommendations = []\n        \n        for resource_id in demands.keys():\n            if risks[resource_id][\"risk_score\"] > 0.7:\n                recommendations.append({\n                    \"resource_id\": resource_id,\n                    \"type\": \"risk_mitigation\",\n                    \"priority\": \"high\",\n                    \"actions\": [\n                        f\"Increase {resource_id} capacity buffer\",\n                        \"Implement contingency plans\",\n                        \"Monitor demand patterns closely\"\n                    ]\n                })\n            \n            if requirements[resource_id][\"peak_demand\"] > requirements[resource_id][\"recommended_capacity\"]:\n                recommendations.append({\n                    \"resource_id\": resource_id,\n                    \"type\": \"capacity_planning\",\n                    \"priority\": \"medium\",\n                    \"actions\": [\n                        f\"Plan for {resource_id} capacity expansion\",\n                        \"Optimize peak demand distribution\",\n                        \"Consider temporary resource augmentation\"\n                    ]\n                })\n        \n        return recommendations "}
{"type": "source_file", "path": "minesight/core/visualization/visualizer.py", "content": "\"\"\"\nVisualization utilities\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nfrom typing import Dict, Any, List, Optional, Union\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nclass DataVisualizer:\n    \"\"\"Data visualization utility\"\"\"\n    \n    def __init__(self,\n                 data: Dict[str, pd.DataFrame],\n                 config: Dict[str, Any]):\n        \"\"\"\n        Initialize visualizer\n        \n        Args:\n            data: Dictionary with data frames\n            config: Visualization configuration\n        \"\"\"\n        self.data = data\n        self.config = config\n        \n    def plot_feature_distributions(self,\n                                 features: List[str],\n                                 output_path: Optional[str] = None):\n        \"\"\"\n        Plot feature distributions\n        \n        Args:\n            features: List of features to plot\n            output_path: Path to save plot\n        \"\"\"\n        n_features = len(features)\n        fig, axes = plt.subplots(\n            n_features,\n            1,\n            figsize=(10, 4 * n_features)\n        )\n        \n        if n_features == 1:\n            axes = [axes]\n        \n        for ax, feature in zip(axes, features):\n            sns.histplot(\n                data=self.data['deposits'],\n                x=feature,\n                hue='deposit',\n                ax=ax\n            )\n            ax.set_title(f'{feature} Distribution')\n            \n        plt.tight_layout()\n        \n        if output_path:\n            plt.savefig(output_path)\n            plt.close()\n        else:\n            plt.show()\n            \n    def plot_correlation_matrix(self,\n                              features: List[str],\n                              output_path: Optional[str] = None):\n        \"\"\"\n        Plot correlation matrix\n        \n        Args:\n            features: List of features to plot\n            output_path: Path to save plot\n        \"\"\"\n        corr = self.data['deposits'][features].corr()\n        \n        plt.figure(figsize=(10, 8))\n        sns.heatmap(\n            corr,\n            annot=True,\n            cmap='coolwarm',\n            center=0\n        )\n        plt.title('Feature Correlation Matrix')\n        \n        if output_path:\n            plt.savefig(output_path)\n            plt.close()\n        else:\n            plt.show()\n            \n    def create_interactive_map(self,\n                             center: List[float],\n                             zoom: int = 8) -> folium.Map:\n        \"\"\"\n        Create interactive map\n        \n        Args:\n            center: Map center coordinates [lat, lon]\n            zoom: Initial zoom level\n            \n        Returns:\n            Folium map\n        \"\"\"\n        # Create base map\n        m = folium.Map(\n            location=center,\n            zoom_start=zoom,\n            tiles='OpenStreetMap'\n        )\n        \n        # Add deposits\n        for _, row in self.data['deposits'].iterrows():\n            color = 'red' if row['deposit'] == 1 else 'blue'\n            folium.CircleMarker(\n                location=[row['latitude'], row['longitude']],\n                radius=5,\n                color=color,\n                fill=True,\n                popup=f\"Deposit: {row['deposit']}<br>\"\n                      f\"Lithology: {row['lithology']}\"\n            ).add_to(m)\n            \n        return m\n\nclass ModelVisualizer:\n    \"\"\"Model visualization utility\"\"\"\n    \n    def __init__(self,\n                 model_outputs: Dict[str, Any],\n                 config: Dict[str, Any]):\n        \"\"\"\n        Initialize visualizer\n        \n        Args:\n            model_outputs: Model output dictionary\n            config: Visualization configuration\n        \"\"\"\n        self.outputs = model_outputs\n        self.config = config\n        \n    def plot_training_history(self,\n                            metrics: List[str],\n                            output_path: Optional[str] = None):\n        \"\"\"\n        Plot training history\n        \n        Args:\n            metrics: List of metrics to plot\n            output_path: Path to save plot\n        \"\"\"\n        n_metrics = len(metrics)\n        fig = make_subplots(rows=n_metrics, cols=1)\n        \n        for i, metric in enumerate(metrics, 1):\n            fig.add_trace(\n                go.Scatter(\n                    y=self.outputs[f'train_{metric}'],\n                    name=f'Train {metric}'\n                ),\n                row=i,\n                col=1\n            )\n            \n            if f'val_{metric}' in self.outputs:\n                fig.add_trace(\n                    go.Scatter(\n                        y=self.outputs[f'val_{metric}'],\n                        name=f'Val {metric}'\n                    ),\n                    row=i,\n                    col=1\n                )\n                \n        fig.update_layout(height=300 * n_metrics)\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n            \n    def plot_prediction_map(self,\n                          region: Dict[str, float],\n                          resolution: float = 0.01,\n                          output_path: Optional[str] = None):\n        \"\"\"\n        Plot prediction map\n        \n        Args:\n            region: Region boundaries\n            resolution: Grid resolution\n            output_path: Path to save plot\n        \"\"\"\n        # Create prediction grid\n        lat = np.arange(\n            region['min_lat'],\n            region['max_lat'],\n            resolution\n        )\n        lon = np.arange(\n            region['min_lon'],\n            region['max_lon'],\n            resolution\n        )\n        \n        lat_grid, lon_grid = np.meshgrid(lat, lon)\n        probabilities = self.outputs['probabilities'].reshape(\n            len(lon),\n            len(lat)\n        )\n        \n        # Create figure\n        fig = go.Figure(data=go.Heatmap(\n            z=probabilities,\n            x=lon,\n            y=lat,\n            colorscale='Viridis',\n            colorbar=dict(title='Probability')\n        ))\n        \n        fig.update_layout(\n            title='Mineral Deposit Probability Map',\n            xaxis_title='Longitude',\n            yaxis_title='Latitude'\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n            \n    def plot_feature_importance(self,\n                              features: List[str],\n                              importance: np.ndarray,\n                              output_path: Optional[str] = None):\n        \"\"\"\n        Plot feature importance\n        \n        Args:\n            features: Feature names\n            importance: Feature importance scores\n            output_path: Path to save plot\n        \"\"\"\n        fig = go.Figure(data=go.Bar(\n            x=features,\n            y=importance,\n            text=np.round(importance, 3),\n            textposition='auto'\n        ))\n        \n        fig.update_layout(\n            title='Feature Importance',\n            xaxis_title='Features',\n            yaxis_title='Importance Score',\n            showlegend=False\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n            \n    def plot_latent_space(self,\n                         labels: Optional[np.ndarray] = None,\n                         output_path: Optional[str] = None):\n        \"\"\"\n        Plot latent space (for VAE)\n        \n        Args:\n            labels: Data labels\n            output_path: Path to save plot\n        \"\"\"\n        if 'z' not in self.outputs:\n            raise ValueError(\"No latent representations found\")\n            \n        z = self.outputs['z']\n        if z.shape[1] > 2:\n            raise ValueError(\"Latent space has more than 2 dimensions\")\n            \n        fig = px.scatter(\n            x=z[:, 0],\n            y=z[:, 1],\n            color=labels if labels is not None else None,\n            title='Latent Space Visualization'\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n            \n    def plot_reconstruction_error_distribution(self,\n                                            output_path: Optional[str] = None):\n        \"\"\"\n        Plot reconstruction error distribution (for autoencoders)\n        \n        Args:\n            output_path: Path to save plot\n        \"\"\"\n        if 'reconstruction_error' not in self.outputs:\n            raise ValueError(\"No reconstruction errors found\")\n            \n        fig = go.Figure(data=go.Histogram(\n            x=self.outputs['reconstruction_error'],\n            nbinsx=50\n        ))\n        \n        fig.update_layout(\n            title='Reconstruction Error Distribution',\n            xaxis_title='Reconstruction Error',\n            yaxis_title='Count'\n        )\n        \n        if output_path:\n            fig.write_html(output_path)\n        else:\n            fig.show()\n\nclass DashboardBuilder:\n    \"\"\"Interactive dashboard builder\"\"\"\n    \n    def __init__(self,\n                 data_visualizer: DataVisualizer,\n                 model_visualizer: ModelVisualizer):\n        \"\"\"\n        Initialize dashboard builder\n        \n        Args:\n            data_visualizer: Data visualizer instance\n            model_visualizer: Model visualizer instance\n        \"\"\"\n        self.data_viz = data_visualizer\n        self.model_viz = model_visualizer\n        \n    def create_training_dashboard(self,\n                                output_path: str):\n        \"\"\"\n        Create training dashboard\n        \n        Args:\n            output_path: Path to save dashboard\n        \"\"\"\n        # Create subplots\n        fig = make_subplots(\n            rows=3,\n            cols=2,\n            subplot_titles=[\n                'Training History',\n                'Feature Distributions',\n                'Correlation Matrix',\n                'Feature Importance',\n                'Prediction Map',\n                'Model Performance'\n            ]\n        )\n        \n        # Add plots\n        self.model_viz.plot_training_history(['loss'], fig.add_subplot(1, 1))\n        self.data_viz.plot_feature_distributions(\n            self.data_viz.config['numerical_features'],\n            fig.add_subplot(1, 2)\n        )\n        self.data_viz.plot_correlation_matrix(\n            self.data_viz.config['numerical_features'],\n            fig.add_subplot(2, 1)\n        )\n        self.model_viz.plot_feature_importance(\n            self.data_viz.config['numerical_features'],\n            self.model_viz.outputs['feature_importance'],\n            fig.add_subplot(2, 2)\n        )\n        self.model_viz.plot_prediction_map(\n            self.model_viz.config['region'],\n            fig.add_subplot(3, 1)\n        )\n        \n        # Save dashboard\n        fig.write_html(output_path)\n        \n    def create_analysis_dashboard(self,\n                                output_path: str):\n        \"\"\"\n        Create analysis dashboard\n        \n        Args:\n            output_path: Path to save dashboard\n        \"\"\"\n        # Create subplots\n        fig = make_subplots(\n            rows=2,\n            cols=2,\n            subplot_titles=[\n                'Latent Space',\n                'Reconstruction Error',\n                'Anomaly Detection',\n                'Pattern Analysis'\n            ]\n        )\n        \n        # Add plots\n        if 'z' in self.model_viz.outputs:\n            self.model_viz.plot_latent_space(\n                self.model_viz.outputs.get('labels'),\n                fig.add_subplot(1, 1)\n            )\n            \n        if 'reconstruction_error' in self.model_viz.outputs:\n            self.model_viz.plot_reconstruction_error_distribution(\n                fig.add_subplot(1, 2)\n            )\n            \n        # Save dashboard\n        fig.write_html(output_path) "}
{"type": "source_file", "path": "minesight/core/optimization/smart_process_monitor.py", "content": "\"\"\"\nReal-time process monitoring and optimization system\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Tuple\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom minesight.core.optimization.smart_process_analyzer import ProcessAnalysisMetrics, SmartProcessAnalyzer\n\n@dataclass\nclass MonitoringConfig:\n    \"\"\"Process monitoring configuration\"\"\"\n    metrics_thresholds: Dict[str, float]\n    alert_thresholds: Dict[str, float]\n    monitoring_interval: int  # seconds\n    optimization_interval: int  # seconds\n    max_deviation_tolerance: float\n    min_confidence_threshold: float\n\n@dataclass\nclass MonitoringAlert:\n    \"\"\"Process monitoring alert\"\"\"\n    alert_id: str\n    timestamp: datetime\n    alert_type: str\n    severity: str\n    metric: str\n    current_value: float\n    threshold_value: float\n    description: str\n    recommendations: List[str]\n\n@dataclass\nclass ProcessState:\n    \"\"\"Current process state\"\"\"\n    process_id: str\n    timestamp: datetime\n    metrics: ProcessAnalysisMetrics\n    status: str\n    deviations: Dict[str, float]\n    alerts: List[MonitoringAlert]\n    optimization_status: str\n    last_optimization: Optional[datetime]\n\nclass DeepStatePredictor(nn.Module):\n    \"\"\"Deep learning model for process state prediction\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int = 128, sequence_length: int = 10):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=2,\n            batch_first=True,\n            dropout=0.2\n        )\n        self.predictor = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_size // 2, input_size)\n        )\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Forward pass\"\"\"\n        lstm_out, _ = self.lstm(x)\n        predictions = self.predictor(lstm_out[:, -1, :])\n        return predictions\n\nclass SmartProcessMonitor:\n    \"\"\"Intelligent process monitoring system\"\"\"\n    \n    def __init__(self, config: MonitoringConfig):\n        \"\"\"Initialize the process monitor\"\"\"\n        self.config = config\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.analyzer = SmartProcessAnalyzer()\n        self.state_predictor = DeepStatePredictor(input_size=20).to(self.device)\n        self.scaler = StandardScaler()\n        self.process_states = {}\n        self.alert_history = []\n        self.optimization_history = []\n        \n    def start_monitoring(self, process_id: str):\n        \"\"\"Start monitoring a process\"\"\"\n        if process_id not in self.process_states:\n            self.process_states[process_id] = ProcessState(\n                process_id=process_id,\n                timestamp=datetime.now(),\n                metrics=None,\n                status=\"initializing\",\n                deviations={},\n                alerts=[],\n                optimization_status=\"pending\",\n                last_optimization=None\n            )\n            \n    def stop_monitoring(self, process_id: str):\n        \"\"\"Stop monitoring a process\"\"\"\n        if process_id in self.process_states:\n            del self.process_states[process_id]\n            \n    def update_process_state(self,\n                           process_id: str,\n                           process_data: Dict[str, Any]) -> ProcessState:\n        \"\"\"\n        Update process state with new data\n        \n        Args:\n            process_id: Process identifier\n            process_data: New process data\n            \n        Returns:\n            Updated process state\n        \"\"\"\n        # Analyze current state\n        current_metrics = self.analyzer.analyze_process(process_data)\n        \n        # Check for deviations\n        deviations = self._check_deviations(current_metrics)\n        \n        # Generate alerts\n        alerts = self._generate_alerts(process_id, current_metrics, deviations)\n        \n        # Update state\n        state = ProcessState(\n            process_id=process_id,\n            timestamp=datetime.now(),\n            metrics=current_metrics,\n            status=\"active\",\n            deviations=deviations,\n            alerts=alerts,\n            optimization_status=self._determine_optimization_status(\n                current_metrics,\n                deviations\n            ),\n            last_optimization=self.process_states[process_id].last_optimization\n            if process_id in self.process_states else None\n        )\n        \n        self.process_states[process_id] = state\n        return state\n        \n    def predict_future_state(self,\n                           process_id: str,\n                           horizon: int = 10) -> List[ProcessAnalysisMetrics]:\n        \"\"\"\n        Predict future process states\n        \n        Args:\n            process_id: Process identifier\n            horizon: Number of future states to predict\n            \n        Returns:\n            List of predicted process metrics\n        \"\"\"\n        if process_id not in self.process_states:\n            raise ValueError(f\"Process {process_id} not being monitored\")\n            \n        # Prepare historical sequence\n        sequence = self._prepare_prediction_sequence(process_id)\n        \n        # Make predictions\n        with torch.no_grad():\n            predictions = []\n            current_sequence = sequence\n            \n            for _ in range(horizon):\n                pred = self.state_predictor(current_sequence)\n                predictions.append(self._convert_prediction_to_metrics(pred))\n                \n                # Update sequence for next prediction\n                current_sequence = torch.cat([\n                    current_sequence[:, 1:, :],\n                    pred.unsqueeze(1)\n                ], dim=1)\n                \n        return predictions\n        \n    def optimize_process(self,\n                        process_id: str,\n                        optimization_goals: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"\n        Optimize process based on current state\n        \n        Args:\n            process_id: Process identifier\n            optimization_goals: Target values for optimization\n            \n        Returns:\n            Optimization results\n        \"\"\"\n        if process_id not in self.process_states:\n            raise ValueError(f\"Process {process_id} not being monitored\")\n            \n        state = self.process_states[process_id]\n        \n        # Generate optimization plan\n        optimization_plan = self.analyzer.generate_optimization_plan(\n            {\"process_id\": process_id},\n            state.metrics,\n            optimization_goals\n        )\n        \n        # Update state\n        state.optimization_status = \"optimizing\"\n        state.last_optimization = datetime.now()\n        \n        # Record optimization\n        self.optimization_history.append({\n            \"timestamp\": datetime.now(),\n            \"process_id\": process_id,\n            \"plan\": optimization_plan,\n            \"current_metrics\": state.metrics.__dict__\n        })\n        \n        return {\n            \"plan\": optimization_plan,\n            \"status\": \"optimization_started\",\n            \"timestamp\": datetime.now().isoformat()\n        }\n        \n    def get_monitoring_dashboard(self, process_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Generate monitoring dashboard data\n        \n        Args:\n            process_id: Process identifier\n            \n        Returns:\n            Dashboard data\n        \"\"\"\n        if process_id not in self.process_states:\n            raise ValueError(f\"Process {process_id} not being monitored\")\n            \n        state = self.process_states[process_id]\n        \n        # Get historical metrics\n        historical_metrics = self._get_historical_metrics(process_id)\n        \n        # Get predictions\n        predictions = self.predict_future_state(process_id)\n        \n        # Get recent alerts\n        recent_alerts = [\n            alert for alert in state.alerts\n            if (datetime.now() - alert.timestamp).total_seconds() < 3600\n        ]\n        \n        # Get optimization history\n        process_optimizations = [\n            opt for opt in self.optimization_history\n            if opt[\"process_id\"] == process_id\n        ]\n        \n        return {\n            \"current_state\": {\n                \"timestamp\": state.timestamp.isoformat(),\n                \"metrics\": state.metrics.__dict__,\n                \"status\": state.status,\n                \"deviations\": state.deviations,\n                \"optimization_status\": state.optimization_status\n            },\n            \"historical_metrics\": historical_metrics,\n            \"predictions\": [pred.__dict__ for pred in predictions],\n            \"alerts\": [alert.__dict__ for alert in recent_alerts],\n            \"optimizations\": process_optimizations\n        }\n        \n    def _check_deviations(self, metrics: ProcessAnalysisMetrics) -> Dict[str, float]:\n        \"\"\"Check for metric deviations from thresholds\"\"\"\n        deviations = {}\n        \n        for metric, threshold in self.config.metrics_thresholds.items():\n            current_value = getattr(metrics, metric)\n            if abs(current_value - threshold) > self.config.max_deviation_tolerance:\n                deviations[metric] = current_value - threshold\n                \n        return deviations\n        \n    def _generate_alerts(self,\n                        process_id: str,\n                        metrics: ProcessAnalysisMetrics,\n                        deviations: Dict[str, float]) -> List[MonitoringAlert]:\n        \"\"\"Generate alerts for significant deviations\"\"\"\n        alerts = []\n        \n        for metric, deviation in deviations.items():\n            if abs(deviation) > self.config.alert_thresholds.get(metric, 0.2):\n                severity = \"high\" if abs(deviation) > 0.5 else \"medium\"\n                \n                alert = MonitoringAlert(\n                    alert_id=f\"alert_{len(self.alert_history)}\",\n                    timestamp=datetime.now(),\n                    alert_type=\"deviation\",\n                    severity=severity,\n                    metric=metric,\n                    current_value=getattr(metrics, metric),\n                    threshold_value=self.config.metrics_thresholds[metric],\n                    description=f\"Significant deviation in {metric}\",\n                    recommendations=self._generate_alert_recommendations(\n                        metric,\n                        deviation\n                    )\n                )\n                \n                alerts.append(alert)\n                self.alert_history.append(alert)\n                \n        return alerts\n        \n    def _determine_optimization_status(self,\n                                    metrics: ProcessAnalysisMetrics,\n                                    deviations: Dict[str, float]) -> str:\n        \"\"\"Determine if optimization is needed\"\"\"\n        if not deviations:\n            return \"optimal\"\n            \n        significant_deviations = sum(\n            1 for d in deviations.values()\n            if abs(d) > self.config.max_deviation_tolerance\n        )\n        \n        if significant_deviations > 2:\n            return \"optimization_needed\"\n        elif significant_deviations > 0:\n            return \"monitoring\"\n        else:\n            return \"stable\"\n            \n    def _prepare_prediction_sequence(self, process_id: str) -> torch.Tensor:\n        \"\"\"Prepare sequence data for prediction\"\"\"\n        # Get historical metrics\n        metrics = self._get_historical_metrics(process_id)\n        \n        # Convert to feature sequence\n        sequence = []\n        for metric_dict in metrics[-10:]:  # Use last 10 states\n            features = [\n                metric_dict[key]\n                for key in [\n                    \"efficiency\", \"cost_effectiveness\", \"resource_utilization\",\n                    \"exploration_coverage\", \"success_rate\", \"risk_score\",\n                    \"optimization_potential\", \"bottleneck_impact\",\n                    \"pattern_significance\", \"anomaly_severity\"\n                ]\n            ]\n            sequence.append(features)\n            \n        # Pad sequence if needed\n        while len(sequence) < 10:\n            sequence.insert(0, [0.0] * 10)\n            \n        return torch.tensor(sequence, dtype=torch.float32, device=self.device).unsqueeze(0)\n        \n    def _convert_prediction_to_metrics(self, prediction: torch.Tensor) -> ProcessAnalysisMetrics:\n        \"\"\"Convert prediction tensor to metrics\"\"\"\n        values = prediction.cpu().numpy()\n        \n        return ProcessAnalysisMetrics(\n            efficiency=float(values[0]),\n            cost_effectiveness=float(values[1]),\n            resource_utilization=float(values[2]),\n            exploration_coverage=float(values[3]),\n            success_rate=float(values[4]),\n            risk_score=float(values[5]),\n            optimization_potential=float(values[6]),\n            bottleneck_impact=float(values[7]),\n            pattern_significance=float(values[8]),\n            anomaly_severity=float(values[9])\n        )\n        \n    def _get_historical_metrics(self, process_id: str) -> List[Dict[str, float]]:\n        \"\"\"Get historical metrics for a process\"\"\"\n        return [\n            opt[\"current_metrics\"]\n            for opt in self.optimization_history\n            if opt[\"process_id\"] == process_id\n        ]\n        \n    def _generate_alert_recommendations(self,\n                                     metric: str,\n                                     deviation: float) -> List[str]:\n        \"\"\"Generate recommendations for alerts\"\"\"\n        recommendations = []\n        \n        if metric == \"efficiency\":\n            if deviation < 0:\n                recommendations.append(\"Review and optimize process workflow\")\n                recommendations.append(\"Check for resource bottlenecks\")\n            else:\n                recommendations.append(\"Monitor for sustainability\")\n                \n        elif metric == \"cost_effectiveness\":\n            if deviation < 0:\n                recommendations.append(\"Analyze cost drivers\")\n                recommendations.append(\"Identify optimization opportunities\")\n            else:\n                recommendations.append(\"Document cost-saving measures\")\n                \n        elif metric == \"resource_utilization\":\n            if deviation < 0:\n                recommendations.append(\"Review resource allocation\")\n                recommendations.append(\"Check for underutilized resources\")\n            else:\n                recommendations.append(\"Monitor for resource strain\")\n                \n        elif metric == \"exploration_coverage\":\n            if deviation < 0:\n                recommendations.append(\"Expand exploration scope\")\n                recommendations.append(\"Review coverage strategy\")\n            else:\n                recommendations.append(\"Optimize exploration density\")\n                \n        elif metric == \"success_rate\":\n            if deviation < 0:\n                recommendations.append(\"Review success criteria\")\n                recommendations.append(\"Analyze failure patterns\")\n            else:\n                recommendations.append(\"Document successful practices\")\n                \n        elif metric == \"risk_score\":\n            if deviation > 0:\n                recommendations.append(\"Implement risk mitigation measures\")\n                recommendations.append(\"Review risk factors\")\n            else:\n                recommendations.append(\"Monitor risk indicators\")\n                \n        return recommendations "}
{"type": "source_file", "path": "minesight/core/validation/data_validator.py", "content": "\"\"\"\nData validation and quality control module for MineSight\n\"\"\"\nfrom typing import Dict, List, Optional, Union, Any\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom pathlib import Path\nimport json\nimport logging\n\nclass DataValidator:\n    \"\"\"Class for validating and ensuring data quality\"\"\"\n    \n    def __init__(self, config_path: Optional[str] = None):\n        \"\"\"\n        Initialize the data validator\n        \n        Args:\n            config_path: Optional path to validation config file\n        \"\"\"\n        self.logger = logging.getLogger(__name__)\n        self.validation_rules = self._load_validation_rules(config_path)\n        self.validation_history = []\n        \n    def validate_deposit_data(self, data: Union[pd.DataFrame, Dict]) -> Dict[str, Any]:\n        \"\"\"\n        Validate mineral deposit data\n        \n        Args:\n            data: Deposit data to validate\n            \n        Returns:\n            Validation results\n        \"\"\"\n        if isinstance(data, dict):\n            data = pd.DataFrame([data])\n            \n        results = {\n            \"is_valid\": True,\n            \"errors\": [],\n            \"warnings\": [],\n            \"stats\": {}\n        }\n        \n        # Required fields check\n        required_fields = [\"latitude\", \"longitude\", \"mineral_type\"]\n        missing_fields = [field for field in required_fields if field not in data.columns]\n        if missing_fields:\n            results[\"is_valid\"] = False\n            results[\"errors\"].append(f\"Missing required fields: {missing_fields}\")\n            \n        # Coordinate validation\n        if \"latitude\" in data.columns:\n            invalid_lat = data[~data[\"latitude\"].between(-90, 90)]\n            if not invalid_lat.empty:\n                results[\"is_valid\"] = False\n                results[\"errors\"].append(\"Invalid latitude values found\")\n                \n        if \"longitude\" in data.columns:\n            invalid_lon = data[~data[\"longitude\"].between(-180, 180)]\n            if not invalid_lon.empty:\n                results[\"is_valid\"] = False\n                results[\"errors\"].append(\"Invalid longitude values found\")\n                \n        # Data type validation\n        if \"mineral_type\" in data.columns:\n            if not data[\"mineral_type\"].dtype == object:\n                results[\"warnings\"].append(\"mineral_type should be string type\")\n                \n        # Duplicate check\n        duplicates = data[data.duplicated(subset=[\"latitude\", \"longitude\"], keep=False)]\n        if not duplicates.empty:\n            results[\"warnings\"].append(f\"Found {len(duplicates)} duplicate coordinates\")\n            \n        # Calculate basic statistics\n        results[\"stats\"] = {\n            \"total_records\": len(data),\n            \"unique_minerals\": len(data[\"mineral_type\"].unique()) if \"mineral_type\" in data.columns else 0,\n            \"confirmed_deposits\": data[\"is_confirmed\"].sum() if \"is_confirmed\" in data.columns else 0\n        }\n        \n        # Log validation results\n        self._log_validation_result(\"deposit_data\", results)\n        \n        return results\n        \n    def validate_geological_feature(self, data: Union[pd.DataFrame, Dict]) -> Dict[str, Any]:\n        \"\"\"\n        Validate geological feature data\n        \n        Args:\n            data: Feature data to validate\n            \n        Returns:\n            Validation results\n        \"\"\"\n        if isinstance(data, dict):\n            data = pd.DataFrame([data])\n            \n        results = {\n            \"is_valid\": True,\n            \"errors\": [],\n            \"warnings\": [],\n            \"stats\": {}\n        }\n        \n        # Required fields check\n        required_fields = [\"latitude\", \"longitude\", \"feature_type\"]\n        missing_fields = [field for field in required_fields if field not in data.columns]\n        if missing_fields:\n            results[\"is_valid\"] = False\n            results[\"errors\"].append(f\"Missing required fields: {missing_fields}\")\n            \n        # Coordinate validation\n        if \"latitude\" in data.columns:\n            invalid_lat = data[~data[\"latitude\"].between(-90, 90)]\n            if not invalid_lat.empty:\n                results[\"is_valid\"] = False\n                results[\"errors\"].append(\"Invalid latitude values found\")\n                \n        if \"longitude\" in data.columns:\n            invalid_lon = data[~data[\"longitude\"].between(-180, 180)]\n            if not invalid_lon.empty:\n                results[\"is_valid\"] = False\n                results[\"errors\"].append(\"Invalid longitude values found\")\n                \n        # Feature type validation\n        if \"feature_type\" in data.columns:\n            valid_types = self.validation_rules.get(\"valid_feature_types\", [])\n            if valid_types:\n                invalid_types = data[~data[\"feature_type\"].isin(valid_types)]\n                if not invalid_types.empty:\n                    results[\"warnings\"].append(f\"Unknown feature types found: {invalid_types['feature_type'].unique()}\")\n                    \n        # Properties validation\n        if \"properties\" in data.columns:\n            invalid_properties = data[data[\"properties\"].apply(lambda x: not isinstance(x, dict))]\n            if not invalid_properties.empty:\n                results[\"warnings\"].append(\"Invalid properties format found\")\n                \n        # Calculate basic statistics\n        results[\"stats\"] = {\n            \"total_records\": len(data),\n            \"unique_features\": len(data[\"feature_type\"].unique()) if \"feature_type\" in data.columns else 0,\n            \"features_with_properties\": data[\"properties\"].notna().sum() if \"properties\" in data.columns else 0\n        }\n        \n        # Log validation results\n        self._log_validation_result(\"geological_feature\", results)\n        \n        return results\n        \n    def validate_sample_data(self, data: Union[pd.DataFrame, Dict]) -> Dict[str, Any]:\n        \"\"\"\n        Validate sample data\n        \n        Args:\n            data: Sample data to validate\n            \n        Returns:\n            Validation results\n        \"\"\"\n        if isinstance(data, dict):\n            data = pd.DataFrame([data])\n            \n        results = {\n            \"is_valid\": True,\n            \"errors\": [],\n            \"warnings\": [],\n            \"stats\": {}\n        }\n        \n        # Required fields check\n        required_fields = [\"latitude\", \"longitude\", \"sample_type\", \"value\"]\n        missing_fields = [field for field in required_fields if field not in data.columns]\n        if missing_fields:\n            results[\"is_valid\"] = False\n            results[\"errors\"].append(f\"Missing required fields: {missing_fields}\")\n            \n        # Coordinate validation\n        if \"latitude\" in data.columns:\n            invalid_lat = data[~data[\"latitude\"].between(-90, 90)]\n            if not invalid_lat.empty:\n                results[\"is_valid\"] = False\n                results[\"errors\"].append(\"Invalid latitude values found\")\n                \n        if \"longitude\" in data.columns:\n            invalid_lon = data[~data[\"longitude\"].between(-180, 180)]\n            if not invalid_lon.empty:\n                results[\"is_valid\"] = False\n                results[\"errors\"].append(\"Invalid longitude values found\")\n                \n        # Value validation\n        if \"value\" in data.columns:\n            if not pd.to_numeric(data[\"value\"], errors=\"coerce\").notna().all():\n                results[\"errors\"].append(\"Invalid numeric values found\")\n                results[\"is_valid\"] = False\n                \n        # Sample type validation\n        if \"sample_type\" in data.columns:\n            valid_types = self.validation_rules.get(\"valid_sample_types\", [])\n            if valid_types:\n                invalid_types = data[~data[\"sample_type\"].isin(valid_types)]\n                if not invalid_types.empty:\n                    results[\"warnings\"].append(f\"Unknown sample types found: {invalid_types['sample_type'].unique()}\")\n                    \n        # Calculate basic statistics\n        results[\"stats\"] = {\n            \"total_records\": len(data),\n            \"unique_sample_types\": len(data[\"sample_type\"].unique()) if \"sample_type\" in data.columns else 0,\n            \"value_stats\": {\n                \"mean\": float(data[\"value\"].mean()) if \"value\" in data.columns else None,\n                \"std\": float(data[\"value\"].std()) if \"value\" in data.columns else None,\n                \"min\": float(data[\"value\"].min()) if \"value\" in data.columns else None,\n                \"max\": float(data[\"value\"].max()) if \"value\" in data.columns else None\n            }\n        }\n        \n        # Log validation results\n        self._log_validation_result(\"sample_data\", results)\n        \n        return results\n        \n    def validate_dem_data(self, data: np.ndarray, metadata: Dict) -> Dict[str, Any]:\n        \"\"\"\n        Validate Digital Elevation Model data\n        \n        Args:\n            data: DEM data array\n            metadata: DEM metadata\n            \n        Returns:\n            Validation results\n        \"\"\"\n        results = {\n            \"is_valid\": True,\n            \"errors\": [],\n            \"warnings\": [],\n            \"stats\": {}\n        }\n        \n        # Check data dimensions\n        if data.ndim != 2:\n            results[\"is_valid\"] = False\n            results[\"errors\"].append(\"DEM data must be 2-dimensional\")\n            \n        # Check for invalid values\n        invalid_mask = ~np.isfinite(data)\n        if np.any(invalid_mask):\n            results[\"warnings\"].append(f\"Found {np.sum(invalid_mask)} invalid/missing values\")\n            \n        # Check metadata\n        required_metadata = [\"resolution\", \"crs\", \"bounds\"]\n        missing_metadata = [field for field in required_metadata if field not in metadata]\n        if missing_metadata:\n            results[\"warnings\"].append(f\"Missing metadata fields: {missing_metadata}\")\n            \n        # Calculate statistics\n        results[\"stats\"] = {\n            \"dimensions\": data.shape,\n            \"resolution\": metadata.get(\"resolution\"),\n            \"value_stats\": {\n                \"mean\": float(np.mean(data[np.isfinite(data)])),\n                \"std\": float(np.std(data[np.isfinite(data)])),\n                \"min\": float(np.min(data[np.isfinite(data)])),\n                \"max\": float(np.max(data[np.isfinite(data)]))\n            }\n        }\n        \n        # Log validation results\n        self._log_validation_result(\"dem_data\", results)\n        \n        return results\n        \n    def get_validation_history(self) -> List[Dict[str, Any]]:\n        \"\"\"Get validation history\"\"\"\n        return self.validation_history\n        \n    def export_validation_report(self, output_path: Optional[str] = None) -> str:\n        \"\"\"\n        Export validation history as a report\n        \n        Args:\n            output_path: Optional output path for report\n            \n        Returns:\n            Path to generated report\n        \"\"\"\n        if output_path is None:\n            output_path = f\"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n            \n        report = {\n            \"generated_at\": datetime.now().isoformat(),\n            \"validation_history\": self.validation_history,\n            \"summary\": self._generate_validation_summary()\n        }\n        \n        with open(output_path, 'w') as f:\n            json.dump(report, f, indent=2)\n            \n        return output_path\n        \n    def _load_validation_rules(self, config_path: Optional[str]) -> Dict:\n        \"\"\"Load validation rules from config file\"\"\"\n        default_rules = {\n            \"valid_feature_types\": [\n                \"fault\",\n                \"fold\",\n                \"intrusion\",\n                \"contact\",\n                \"vein\",\n                \"alteration\"\n            ],\n            \"valid_sample_types\": [\n                \"rock\",\n                \"soil\",\n                \"stream\",\n                \"drill_core\"\n            ],\n            \"coordinate_precision\": 6,\n            \"max_duplicate_distance\": 0.001  # degrees\n        }\n        \n        if config_path:\n            try:\n                with open(config_path, 'r') as f:\n                    custom_rules = json.load(f)\n                default_rules.update(custom_rules)\n            except Exception as e:\n                self.logger.warning(f\"Failed to load custom validation rules: {str(e)}\")\n                \n        return default_rules\n        \n    def _log_validation_result(self, data_type: str, results: Dict[str, Any]):\n        \"\"\"Log validation result to history\"\"\"\n        self.validation_history.append({\n            \"timestamp\": datetime.now().isoformat(),\n            \"data_type\": data_type,\n            \"results\": results\n        })\n        \n    def _generate_validation_summary(self) -> Dict[str, Any]:\n        \"\"\"Generate summary of validation history\"\"\"\n        summary = {\n            \"total_validations\": len(self.validation_history),\n            \"validation_results\": {\n                \"passed\": 0,\n                \"failed\": 0,\n                \"with_warnings\": 0\n            },\n            \"common_errors\": {},\n            \"common_warnings\": {}\n        }\n        \n        for validation in self.validation_history:\n            results = validation[\"results\"]\n            \n            if results[\"is_valid\"]:\n                summary[\"validation_results\"][\"passed\"] += 1\n            else:\n                summary[\"validation_results\"][\"failed\"] += 1\n                \n            if results[\"warnings\"]:\n                summary[\"validation_results\"][\"with_warnings\"] += 1\n                \n            # Count common errors\n            for error in results[\"errors\"]:\n                summary[\"common_errors\"][error] = summary[\"common_errors\"].get(error, 0) + 1\n                \n            # Count common warnings\n            for warning in results[\"warnings\"]:\n                summary[\"common_warnings\"][warning] = summary[\"common_warnings\"].get(warning, 0) + 1\n                \n        return summary "}
{"type": "source_file", "path": "minesight/core/recommendation/smart_recommender.py", "content": "\"\"\"\nSmart recommendation system for mineral exploration\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Tuple\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom dataclasses import dataclass, asdict\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nimport os\nimport time\nimport torch.nn.functional as F\nimport warnings\nimport json\nimport csv\nfrom pathlib import Path\n\n@dataclass\nclass ExplorationRecommendation:\n    \"\"\"Data class for exploration recommendations\"\"\"\n    recommendation_id: str\n    category: str\n    priority: float\n    confidence: float\n    description: str\n    actions: List[str]\n    expected_impact: Dict[str, float]\n    supporting_data: Dict[str, Any]\n    timestamp: datetime\n\nclass RecommendationModel(nn.Module):\n    \"\"\"Enhanced deep learning based recommendation model\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int = 128):\n        super().__init__()\n        \n        # Feature extraction layers\n        self.feature_extractor = nn.Sequential(\n            nn.Linear(input_size, hidden_size * 2),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size * 2, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.2)\n        )\n        \n        # Context understanding layers\n        self.context_encoder = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.Tanh(),\n            nn.Dropout(0.2)\n        )\n        \n        # Recommendation generation layers\n        self.recommendation_head = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_size // 2, hidden_size // 4),\n            nn.ReLU()\n        )\n        \n        # Multi-task outputs\n        self.category_predictor = nn.Linear(hidden_size // 4, 10)  # 10 categories\n        self.impact_predictor = nn.Linear(hidden_size // 4, 5)     # 5 impact metrics\n        self.confidence_predictor = nn.Linear(hidden_size // 4, 1)\n        \n        # Attention mechanism\n        self.attention = nn.MultiheadAttention(hidden_size, num_heads=4)\n        \n        # Feature importance layers\n        self.feature_importance = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, input_size),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n        # Calculate feature importance\n        feature_weights = self.feature_importance(x)\n        weighted_input = x * feature_weights\n        \n        # Extract features\n        features = self.feature_extractor(weighted_input)\n        \n        # Apply self-attention\n        attended_features, _ = self.attention(\n            features.unsqueeze(0),\n            features.unsqueeze(0),\n            features.unsqueeze(0)\n        )\n        attended_features = attended_features.squeeze(0)\n        \n        # Encode context\n        context = self.context_encoder(attended_features)\n        \n        # Generate recommendations\n        shared_features = self.recommendation_head(context)\n        \n        # Multi-task predictions\n        categories = self.category_predictor(shared_features)\n        impact = self.impact_predictor(shared_features)\n        confidence = self.confidence_predictor(shared_features).squeeze(-1)\n        \n        return categories, impact, confidence, feature_weights\n\nclass SmartRecommender:\n    \"\"\"Intelligent recommendation system for exploration activities\"\"\"\n    \n    def __init__(self, model_path: Optional[str] = None):\n        \"\"\"\n        Initialize the smart recommender\n        \n        Args:\n            model_path: Optional path to pre-trained model\n        \"\"\"\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model = None\n        self.scaler = StandardScaler()\n        self.feature_importance_model = RandomForestRegressor(n_estimators=100)\n        \n        if model_path:\n            self.load_model(model_path)\n            \n    def generate_recommendations(self,\n                               exploration_data: Dict[str, Any],\n                               historical_data: Dict[str, Any],\n                               current_state: Dict[str, Any]) -> List[ExplorationRecommendation]:\n        \"\"\"\n        Generate intelligent recommendations\n        \n        Args:\n            exploration_data: Current exploration data\n            historical_data: Historical exploration data\n            current_state: Current system state\n            \n        Returns:\n            List of recommendations\n        \"\"\"\n        # Prepare input data\n        features = self._prepare_features(\n            exploration_data,\n            historical_data,\n            current_state\n        )\n        \n        # Generate recommendations using the model\n        recommendations, impacts, confidences, feature_weights = self._generate_model_recommendations(features)\n        \n        # Analyze patterns in historical data\n        historical_patterns = self._analyze_historical_patterns(historical_data)\n        \n        # Generate context-aware recommendations\n        recommendations = self._generate_context_aware_recommendations(\n            recommendations,\n            impacts,\n            confidences,\n            feature_weights,\n            historical_patterns,\n            current_state\n        )\n        \n        # Sort by priority and confidence\n        recommendations.sort(\n            key=lambda x: (x.priority * x.confidence),\n            reverse=True\n        )\n        \n        return recommendations\n    \n    def train_model(self,\n                   training_data: Dict[str, Any],\n                   validation_data: Dict[str, Any],\n                   epochs: int = 100):\n        \"\"\"\n        Train the recommendation model\n        \n        Args:\n            training_data: Training dataset\n            validation_data: Validation dataset\n            epochs: Number of training epochs\n        \"\"\"\n        # Prepare training data\n        X_train = self._prepare_features(\n            training_data[\"exploration_data\"],\n            training_data[\"historical_data\"],\n            training_data[\"current_state\"]\n        )\n        y_train = self._prepare_labels(training_data)\n        \n        # Prepare validation data\n        X_val = self._prepare_features(\n            validation_data[\"exploration_data\"],\n            validation_data[\"historical_data\"],\n            validation_data[\"current_state\"]\n        )\n        y_val = self._prepare_labels(validation_data)\n        \n        # Initialize model if not exists\n        if self.model is None:\n            self.model = RecommendationModel(\n                input_size=X_train.shape[1]\n            ).to(self.device)\n            \n        # Train model\n        optimizer = torch.optim.Adam(self.model.parameters())\n        criterion = nn.MSELoss()\n        \n        for epoch in range(epochs):\n            self.model.train()\n            optimizer.zero_grad()\n            \n            # Forward pass\n            recommendations, impacts, confidences, feature_weights = self.model(X_train)\n            loss = criterion(recommendations, y_train[\"recommendations\"]) + \\\n                   criterion(impacts, y_train[\"impacts\"]) + \\\n                   criterion(confidences, y_train[\"confidences\"]) + \\\n                   criterion(feature_weights, y_train[\"feature_weights\"])\n            \n            # Backward pass\n            loss.backward()\n            optimizer.step()\n            \n            # Validation\n            if epoch % 10 == 0:\n                self.model.eval()\n                with torch.no_grad():\n                    val_recommendations, val_impacts, val_confidences, val_feature_weights = self.model(X_val)\n                    val_loss = criterion(val_recommendations, y_val[\"recommendations\"]) + \\\n                              criterion(val_impacts, y_val[\"impacts\"]) + \\\n                              criterion(val_confidences, y_val[\"confidences\"]) + \\\n                              criterion(val_feature_weights, y_val[\"feature_weights\"])\n                print(f\"Epoch {epoch}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n    \n    def analyze_recommendation_impact(self,\n                                   recommendations: List[ExplorationRecommendation],\n                                   historical_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze the potential impact of recommendations\n        \n        Args:\n            recommendations: List of generated recommendations\n            historical_data: Historical exploration data\n            \n        Returns:\n            Impact analysis results\n        \"\"\"\n        impact_analysis = {\n            \"overall_impact\": {},\n            \"category_impact\": {},\n            \"risk_analysis\": {},\n            \"cost_benefit_analysis\": {}\n        }\n        \n        # Analyze overall impact\n        impact_analysis[\"overall_impact\"] = self._analyze_overall_impact(\n            recommendations,\n            historical_data\n        )\n        \n        # Analyze impact by category\n        impact_analysis[\"category_impact\"] = self._analyze_category_impact(\n            recommendations,\n            historical_data\n        )\n        \n        # Analyze risks\n        impact_analysis[\"risk_analysis\"] = self._analyze_implementation_risks(\n            recommendations,\n            historical_data\n        )\n        \n        # Cost-benefit analysis\n        impact_analysis[\"cost_benefit_analysis\"] = self._analyze_cost_benefit(\n            recommendations,\n            historical_data\n        )\n        \n        return impact_analysis\n    \n    def _prepare_features(self,\n                         exploration_data: Dict[str, Any],\n                         historical_data: Dict[str, Any],\n                         current_state: Dict[str, Any]) -> torch.Tensor:\n        \"\"\"Enhanced feature preparation with comprehensive feature engineering\"\"\"\n        features = []\n        \n        # Process exploration data\n        if exploration_data:\n            # Geological features\n            geo_features = self._extract_geological_features(exploration_data)\n            features.extend(geo_features)\n            \n            # Temporal features\n            temporal_features = self._extract_temporal_features(exploration_data)\n            features.extend(temporal_features)\n            \n            # Spatial features\n            spatial_features = self._extract_spatial_features(exploration_data)\n            features.extend(spatial_features)\n            \n        # Process historical data\n        if historical_data:\n            # Performance metrics\n            perf_features = self._extract_performance_features(historical_data)\n            features.extend(perf_features)\n            \n            # Success patterns\n            success_features = self._extract_success_patterns(historical_data)\n            features.extend(success_features)\n            \n            # Risk patterns\n            risk_features = self._extract_risk_patterns(historical_data)\n            features.extend(risk_features)\n            \n        # Process current state\n        if current_state:\n            # Resource availability\n            resource_features = self._extract_resource_features(current_state)\n            features.extend(resource_features)\n            \n            # Operational constraints\n            constraint_features = self._extract_constraint_features(current_state)\n            features.extend(constraint_features)\n            \n            # Environmental conditions\n            env_features = self._extract_environmental_features(current_state)\n            features.extend(env_features)\n        \n        # Normalize features\n        features = np.array(features, dtype=np.float32)\n        features = (features - np.mean(features)) / (np.std(features) + 1e-8)\n        \n        return torch.FloatTensor(features)\n\n    def _extract_geological_features(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract geological features from exploration data\"\"\"\n        features = []\n        if \"geology\" in data:\n            geology = data[\"geology\"]\n            features.extend([\n                geology.get(\"mineral_concentration\", 0.0),\n                geology.get(\"depth\", 0.0),\n                geology.get(\"rock_hardness\", 0.0),\n                geology.get(\"formation_type\", 0.0)\n            ])\n        return features\n\n    def _extract_temporal_features(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract temporal features from data\"\"\"\n        features = []\n        if \"timestamps\" in data:\n            timestamps = pd.to_datetime(data[\"timestamps\"])\n            features.extend([\n                timestamps.hour.mean(),\n                timestamps.dayofweek.mean(),\n                timestamps.dayofyear.mean(),\n                timestamps.month.mean()\n            ])\n        return features\n\n    def _extract_spatial_features(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract spatial features from data\"\"\"\n        features = []\n        if \"location\" in data:\n            location = data[\"location\"]\n            features.extend([\n                location.get(\"latitude\", 0.0),\n                location.get(\"longitude\", 0.0),\n                location.get(\"elevation\", 0.0),\n                location.get(\"area\", 0.0)\n            ])\n        return features\n\n    def _extract_performance_features(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract performance features from historical data\"\"\"\n        features = []\n        if \"performance\" in data:\n            perf = data[\"performance\"]\n            features.extend([\n                perf.get(\"efficiency\", 0.0),\n                perf.get(\"success_rate\", 0.0),\n                perf.get(\"cost_effectiveness\", 0.0),\n                perf.get(\"resource_utilization\", 0.0)\n            ])\n        return features\n\n    def _extract_success_patterns(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract success pattern features\"\"\"\n        features = []\n        if \"success_patterns\" in data:\n            patterns = data[\"success_patterns\"]\n            features.extend([\n                patterns.get(\"exploration_success\", 0.0),\n                patterns.get(\"discovery_rate\", 0.0),\n                patterns.get(\"validation_success\", 0.0),\n                patterns.get(\"implementation_success\", 0.0)\n            ])\n        return features\n\n    def _extract_risk_patterns(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract risk pattern features\"\"\"\n        features = []\n        if \"risk_patterns\" in data:\n            risks = data[\"risk_patterns\"]\n            features.extend([\n                risks.get(\"geological_risk\", 0.0),\n                risks.get(\"operational_risk\", 0.0),\n                risks.get(\"environmental_risk\", 0.0),\n                risks.get(\"economic_risk\", 0.0)\n            ])\n        return features\n\n    def _extract_resource_features(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract resource availability features\"\"\"\n        features = []\n        if \"resources\" in data:\n            resources = data[\"resources\"]\n            features.extend([\n                resources.get(\"equipment_availability\", 0.0),\n                resources.get(\"personnel_availability\", 0.0),\n                resources.get(\"budget_availability\", 0.0),\n                resources.get(\"time_availability\", 0.0)\n            ])\n        return features\n\n    def _extract_constraint_features(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract operational constraint features\"\"\"\n        features = []\n        if \"constraints\" in data:\n            constraints = data[\"constraints\"]\n            features.extend([\n                constraints.get(\"regulatory_compliance\", 0.0),\n                constraints.get(\"safety_requirements\", 0.0),\n                constraints.get(\"environmental_limits\", 0.0),\n                constraints.get(\"technical_limitations\", 0.0)\n            ])\n        return features\n\n    def _extract_environmental_features(self, data: Dict[str, Any]) -> List[float]:\n        \"\"\"Extract environmental condition features\"\"\"\n        features = []\n        if \"environment\" in data:\n            env = data[\"environment\"]\n            features.extend([\n                env.get(\"temperature\", 0.0),\n                env.get(\"humidity\", 0.0),\n                env.get(\"precipitation\", 0.0),\n                env.get(\"wind_speed\", 0.0)\n            ])\n        return features\n    \n    def _prepare_labels(self, data: Dict[str, Any]) -> Dict[str, torch.Tensor]:\n        \"\"\"Prepare training labels for the model\"\"\"\n        recommendations = []\n        impacts = []\n        confidences = []\n        feature_weights = []\n        \n        for record in data.get(\"training_records\", []):\n            # Extract recommendation labels\n            recommendations.append([\n                record[\"priority\"],\n                record[\"confidence\"],\n                self._get_category_embedding(record[\"category\"])\n            ])\n            \n            # Extract impact labels\n            impacts.append([\n                record[\"impact\"][\"success_rate\"],\n                record[\"impact\"][\"cost_efficiency\"],\n                record[\"impact\"][\"time_saving\"],\n                record[\"impact\"][\"risk_reduction\"]\n            ])\n            \n            # Extract confidence labels\n            confidences.append([\n                record[\"confidence\"]\n            ])\n            \n            # Extract feature weights\n            feature_weights.append([\n                record[\"feature_weights\"]\n            ])\n        \n        return {\n            \"recommendations\": torch.tensor(recommendations, device=self.device),\n            \"impacts\": torch.tensor(impacts, device=self.device),\n            \"confidences\": torch.tensor(confidences, device=self.device),\n            \"feature_weights\": torch.tensor(feature_weights, device=self.device)\n        }\n    \n    def _generate_model_recommendations(self,\n                                     features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"Generate recommendations using the trained model\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not initialized. Please train or load a model first.\")\n        \n        self.model.eval()\n        with torch.no_grad():\n            recommendations, impacts, confidences, feature_weights = self.model(features.unsqueeze(0))\n        \n        return recommendations.squeeze(0), impacts.squeeze(0), confidences.squeeze(0), feature_weights.squeeze(0)\n    \n    def _analyze_historical_patterns(self,\n                                   historical_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Analyze patterns in historical data\"\"\"\n        patterns = {\n            \"success_patterns\": self._analyze_success_patterns(historical_data),\n            \"failure_patterns\": self._analyze_failure_patterns(historical_data),\n            \"efficiency_patterns\": self._analyze_efficiency_patterns(historical_data)\n        }\n        return patterns\n    \n    def _generate_context_aware_recommendations(self,\n                                             recommendations: torch.Tensor,\n                                             impacts: torch.Tensor,\n                                             confidences: torch.Tensor,\n                                             feature_weights: torch.Tensor,\n                                             historical_patterns: Dict[str, Any],\n                                             current_state: Dict[str, Any]) -> List[ExplorationRecommendation]:\n        \"\"\"Generate context-aware recommendations\"\"\"\n        context_recommendations = []\n        \n        # Extract recommendation components\n        priorities = recommendations[:, 0]\n        category_embeddings = recommendations[:, 1]\n        \n        # Generate recommendations for each prediction\n        for i in range(len(priorities)):\n            # Get category and description\n            category_embedding = category_embeddings[i]\n            description = self._generate_recommendation_description(\n                category_embedding,\n                impacts[i],\n                confidences[i],\n                feature_weights[i],\n                historical_patterns\n            )\n            \n            # Generate recommended actions\n            actions = self._generate_recommended_actions(\n                category_embedding,\n                impacts[i],\n                current_state\n            )\n            \n            # Get supporting data\n            supporting_data = self._get_supporting_data(\n                category_embedding,\n                historical_patterns\n            )\n            \n            # Create recommendation object\n            recommendation = ExplorationRecommendation(\n                recommendation_id=f\"REC_{int(time.time())}_{i}\",\n                category=self._get_category_from_embedding(category_embedding),\n                priority=float(priorities[i]),\n                confidence=float(confidences[i]),\n                description=description,\n                actions=actions,\n                expected_impact={\n                    \"success_rate\": float(impacts[i][0]),\n                    \"cost_efficiency\": float(impacts[i][1]),\n                    \"time_saving\": float(impacts[i][2]),\n                    \"risk_reduction\": float(impacts[i][3])\n                },\n                supporting_data=supporting_data,\n                timestamp=datetime.now()\n            )\n            \n            context_recommendations.append(recommendation)\n        \n        return context_recommendations\n    \n    def _get_category_from_embedding(self, embedding: torch.Tensor) -> str:\n        \"\"\"Convert numerical embedding back to category string\"\"\"\n        category_map = {\n            0.1: \"geological_survey\",\n            0.2: \"geophysical_exploration\",\n            0.3: \"drilling_program\",\n            0.4: \"sample_analysis\",\n            0.5: \"resource_estimation\",\n            0.6: \"environmental_assessment\",\n            0.7: \"infrastructure_planning\",\n            0.8: \"risk_assessment\",\n            0.9: \"economic_evaluation\"\n        }\n        \n        embedding_value = embedding.item()\n        closest_key = min(category_map.keys(), key=lambda x: abs(x - embedding_value))\n        return category_map[closest_key]\n    \n    def _generate_recommendation_description(self,\n                                          category_embedding: torch.Tensor,\n                                          impact: torch.Tensor,\n                                          confidence: torch.Tensor,\n                                          feature_weights: torch.Tensor,\n                                          historical_patterns: Dict[str, Any]) -> str:\n        \"\"\"Generate detailed description for a recommendation\"\"\"\n        category = self._get_category_from_embedding(category_embedding)\n        impact_values = impact.tolist()\n        \n        description_templates = {\n            \"geological_survey\": \"Conduct detailed geological survey with expected success rate of {:.1f}% and cost efficiency of {:.1f}%\",\n            \"geophysical_exploration\": \"Perform geophysical exploration with projected accuracy of {:.1f}% and time saving of {:.1f}%\",\n            \"drilling_program\": \"Implement drilling program with estimated resource potential of {:.1f}% and risk reduction of {:.1f}%\",\n            \"sample_analysis\": \"Conduct comprehensive sample analysis with expected insight gain of {:.1f}% and efficiency improvement of {:.1f}%\",\n            \"resource_estimation\": \"Perform resource estimation with projected accuracy of {:.1f}% and confidence level of {:.1f}%\",\n            \"environmental_assessment\": \"Conduct environmental assessment with compliance rate of {:.1f}% and risk mitigation of {:.1f}%\",\n            \"infrastructure_planning\": \"Develop infrastructure plan with optimization potential of {:.1f}% and cost reduction of {:.1f}%\",\n            \"risk_assessment\": \"Perform risk assessment with coverage of {:.1f}% and mitigation effectiveness of {:.1f}%\",\n            \"economic_evaluation\": \"Conduct economic evaluation with accuracy of {:.1f}% and ROI potential of {:.1f}%\"\n        }\n        \n        template = description_templates.get(category, \"Recommendation with impact potential of {:.1f}% and confidence of {:.1f}%\")\n        description = template.format(impact_values[0] * 100, impact_values[1] * 100)\n        \n        # Add historical context if available\n        if category in historical_patterns.get(\"success_patterns\", {}):\n            success_rate = historical_patterns[\"success_patterns\"][category] * 100\n            description += f\" (Historical success rate: {success_rate:.1f}%)\"\n        \n        return description\n    \n    def _generate_recommended_actions(self,\n                                   category_embedding: torch.Tensor,\n                                   impact: torch.Tensor,\n                                   current_state: Dict[str, Any]) -> List[str]:\n        \"\"\"Generate specific recommended actions based on category and impact\"\"\"\n        category = self._get_category_from_embedding(category_embedding)\n        impact_values = impact.tolist()\n        \n        # Base actions for each category\n        base_actions = {\n            \"geological_survey\": [\n                \"Conduct detailed geological mapping\",\n                \"Perform surface sampling\",\n                \"Analyze structural features\",\n                \"Document lithological variations\"\n            ],\n            \"geophysical_exploration\": [\n                \"Execute magnetic survey\",\n                \"Conduct gravity measurements\",\n                \"Perform seismic analysis\",\n                \"Process geophysical data\"\n            ],\n            \"drilling_program\": [\n                \"Design drill hole locations\",\n                \"Prepare drilling equipment\",\n                \"Collect core samples\",\n                \"Log drilling results\"\n            ],\n            \"sample_analysis\": [\n                \"Prepare sample specimens\",\n                \"Conduct chemical analysis\",\n                \"Perform mineralogical studies\",\n                \"Document analysis results\"\n            ],\n            \"resource_estimation\": [\n                \"Compile geological data\",\n                \"Build 3D resource model\",\n                \"Calculate resource volumes\",\n                \"Validate estimation results\"\n            ],\n            \"environmental_assessment\": [\n                \"Survey environmental conditions\",\n                \"Assess potential impacts\",\n                \"Plan mitigation measures\",\n                \"Prepare compliance documentation\"\n            ],\n            \"infrastructure_planning\": [\n                \"Evaluate site conditions\",\n                \"Design access routes\",\n                \"Plan facility layouts\",\n                \"Assess utility requirements\"\n            ],\n            \"risk_assessment\": [\n                \"Identify potential hazards\",\n                \"Evaluate risk probabilities\",\n                \"Develop mitigation strategies\",\n                \"Create contingency plans\"\n            ],\n            \"economic_evaluation\": [\n                \"Analyze market conditions\",\n                \"Calculate project costs\",\n                \"Estimate potential returns\",\n                \"Assess economic viability\"\n            ]\n        }\n        \n        # Get base actions for the category\n        actions = base_actions.get(category, [])\n        \n        # Add context-specific actions based on current state\n        if current_state:\n            if \"environmental_constraints\" in current_state:\n                actions.append(\"Ensure compliance with environmental regulations\")\n            \n            if \"resource_availability\" in current_state:\n                if current_state[\"resource_availability\"].get(\"equipment\", 0) < 0.5:\n                    actions.append(\"Secure additional equipment resources\")\n                if current_state[\"resource_availability\"].get(\"personnel\", 0) < 0.5:\n                    actions.append(\"Allocate additional personnel\")\n            \n            if \"weather_conditions\" in current_state:\n                if not current_state[\"weather_conditions\"].get(\"favorable\", True):\n                    actions.append(\"Plan for adverse weather conditions\")\n            \n            if \"budget_constraints\" in current_state:\n                if current_state[\"budget_constraints\"].get(\"limited\", False):\n                    actions.append(\"Optimize resource allocation for budget efficiency\")\n        \n        # Prioritize actions based on impact values\n        if impact_values[0] < 0.5:  # Low success rate\n            actions.append(\"Conduct additional preliminary analysis\")\n        if impact_values[1] < 0.5:  # Low cost efficiency\n            actions.append(\"Review and optimize cost structure\")\n        if impact_values[2] < 0.5:  # Low time saving\n            actions.append(\"Streamline operational procedures\")\n        if impact_values[3] < 0.5:  # Low risk reduction\n            actions.append(\"Implement additional safety measures\")\n        \n        return actions\n    \n    def _get_supporting_data(self,\n                           category_embedding: torch.Tensor,\n                           historical_patterns: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Get supporting data for a recommendation\"\"\"\n        category = self._get_category_from_embedding(category_embedding)\n        \n        supporting_data = {\n            \"historical_performance\": {},\n            \"success_factors\": {},\n            \"risk_factors\": {},\n            \"resource_requirements\": {}\n        }\n        \n        # Add historical performance data\n        if \"success_patterns\" in historical_patterns:\n            category_success = historical_patterns[\"success_patterns\"].get(category, {})\n            supporting_data[\"historical_performance\"] = {\n                \"success_rate\": category_success.get(\"success_rate\", 0.0),\n                \"efficiency\": category_success.get(\"efficiency\", 0.0),\n                \"completion_rate\": category_success.get(\"completion_rate\", 0.0)\n            }\n        \n        # Add success factors\n        if \"success_factors\" in historical_patterns:\n            category_factors = historical_patterns[\"success_factors\"].get(category, {})\n            supporting_data[\"success_factors\"] = {\n                k: v for k, v in category_factors.items()\n                if v > 0.3  # Only include significant factors\n            }\n        \n        # Add risk factors\n        if \"risk_factors\" in historical_patterns:\n            category_risks = historical_patterns[\"risk_factors\"].get(category, {})\n            supporting_data[\"risk_factors\"] = {\n                k: v for k, v in category_risks.items()\n                if v > 0.2  # Only include significant risks\n            }\n        \n        # Add resource requirements\n        supporting_data[\"resource_requirements\"] = self._get_resource_requirements(category)\n        \n        return supporting_data\n\n    def _get_resource_requirements(self, category: str) -> Dict[str, Any]:\n        \"\"\"Get typical resource requirements for a category\"\"\"\n        base_requirements = {\n            \"geological_survey\": {\n                \"personnel\": [\"geologist\", \"field_technician\"],\n                \"equipment\": [\"survey_equipment\", \"sampling_tools\"],\n                \"duration\": \"2-4 weeks\",\n                \"expertise_level\": \"high\"\n            },\n            \"geophysical_exploration\": {\n                \"personnel\": [\"geophysicist\", \"field_crew\"],\n                \"equipment\": [\"geophysical_instruments\", \"data_processing_systems\"],\n                \"duration\": \"4-6 weeks\",\n                \"expertise_level\": \"very_high\"\n            },\n            \"drilling_program\": {\n                \"personnel\": [\"drilling_crew\", \"geologist\", \"site_supervisor\"],\n                \"equipment\": [\"drilling_rig\", \"core_storage\", \"sampling_equipment\"],\n                \"duration\": \"8-12 weeks\",\n                \"expertise_level\": \"high\"\n            },\n            \"sample_analysis\": {\n                \"personnel\": [\"laboratory_technician\", \"geologist\"],\n                \"equipment\": [\"laboratory_equipment\", \"analysis_tools\"],\n                \"duration\": \"1-2 weeks\",\n                \"expertise_level\": \"medium\"\n            },\n            \"resource_estimation\": {\n                \"personnel\": [\"resource_geologist\", \"modeler\"],\n                \"equipment\": [\"modeling_software\", \"high_performance_computer\"],\n                \"duration\": \"2-4 weeks\",\n                \"expertise_level\": \"very_high\"\n            },\n            \"environmental_assessment\": {\n                \"personnel\": [\"environmental_scientist\", \"field_technician\"],\n                \"equipment\": [\"monitoring_equipment\", \"sampling_gear\"],\n                \"duration\": \"4-8 weeks\",\n                \"expertise_level\": \"high\"\n            },\n            \"infrastructure_planning\": {\n                \"personnel\": [\"civil_engineer\", \"project_planner\"],\n                \"equipment\": [\"survey_equipment\", \"design_software\"],\n                \"duration\": \"6-10 weeks\",\n                \"expertise_level\": \"high\"\n            },\n            \"risk_assessment\": {\n                \"personnel\": [\"risk_analyst\", \"domain_expert\"],\n                \"equipment\": [\"analysis_software\", \"documentation_tools\"],\n                \"duration\": \"2-3 weeks\",\n                \"expertise_level\": \"high\"\n            },\n            \"economic_evaluation\": {\n                \"personnel\": [\"financial_analyst\", \"economist\"],\n                \"equipment\": [\"financial_software\", \"data_analysis_tools\"],\n                \"duration\": \"2-4 weeks\",\n                \"expertise_level\": \"high\"\n            }\n        }\n        \n        return base_requirements.get(category, {\n            \"personnel\": [\"project_manager\", \"technical_staff\"],\n            \"equipment\": [\"standard_equipment\"],\n            \"duration\": \"2-4 weeks\",\n            \"expertise_level\": \"medium\"\n        })\n    \n    def _analyze_success_patterns(self, historical_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Analyze patterns in successful exploration activities\"\"\"\n        success_patterns = {}\n        \n        if \"exploration_records\" in historical_data:\n            successful_records = [\n                record for record in historical_data[\"exploration_records\"]\n                if record.get(\"success\", False)\n            ]\n            \n            # Analyze geological features\n            if successful_records:\n                geological_features = {}\n                for record in successful_records:\n                    for feature, value in record.get(\"geological_features\", {}).items():\n                        if feature not in geological_features:\n                            geological_features[feature] = []\n                        geological_features[feature].append(value)\n                \n                # Calculate feature importance\n                for feature, values in geological_features.items():\n                    success_patterns[f\"geological_{feature}\"] = np.mean(values)\n            \n            # Analyze exploration methods\n            method_success = {}\n            for record in successful_records:\n                method = record.get(\"exploration_method\")\n                if method:\n                    method_success[method] = method_success.get(method, 0) + 1\n            \n            total_successes = len(successful_records)\n            for method, count in method_success.items():\n                success_patterns[f\"method_{method}\"] = count / total_successes\n        \n        return success_patterns\n    \n    def _analyze_failure_patterns(self, historical_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Analyze patterns in failed exploration activities\"\"\"\n        failure_patterns = {}\n        \n        if \"exploration_records\" in historical_data:\n            failed_records = [\n                record for record in historical_data[\"exploration_records\"]\n                if not record.get(\"success\", True)\n            ]\n            \n            # Analyze common failure factors\n            failure_factors = {}\n            for record in failed_records:\n                for factor in record.get(\"failure_factors\", []):\n                    failure_factors[factor] = failure_factors.get(factor, 0) + 1\n            \n            total_failures = len(failed_records)\n            if total_failures > 0:\n                for factor, count in failure_factors.items():\n                    failure_patterns[f\"factor_{factor}\"] = count / total_failures\n            \n            # Analyze geological conditions in failures\n            geological_conditions = {}\n            for record in failed_records:\n                for condition, value in record.get(\"geological_conditions\", {}).items():\n                    if condition not in geological_conditions:\n                        geological_conditions[condition] = []\n                    geological_conditions[condition].append(value)\n            \n            for condition, values in geological_conditions.items():\n                failure_patterns[f\"condition_{condition}\"] = np.mean(values)\n        \n        return failure_patterns\n    \n    def _analyze_efficiency_patterns(self, historical_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Analyze patterns in exploration efficiency\"\"\"\n        efficiency_patterns = {}\n        \n        if \"exploration_records\" in historical_data:\n            # Calculate time efficiency\n            completion_times = []\n            for record in historical_data[\"exploration_records\"]:\n                if \"start_time\" in record and \"end_time\" in record:\n                    start = datetime.fromisoformat(record[\"start_time\"])\n                    end = datetime.fromisoformat(record[\"end_time\"])\n                    duration = (end - start).total_seconds()\n                    completion_times.append(duration)\n            \n            if completion_times:\n                efficiency_patterns[\"avg_completion_time\"] = np.mean(completion_times)\n                efficiency_patterns[\"std_completion_time\"] = np.std(completion_times)\n            \n            # Analyze resource utilization\n            resource_usage = {}\n            for record in historical_data[\"exploration_records\"]:\n                for resource, amount in record.get(\"resource_usage\", {}).items():\n                    if resource not in resource_usage:\n                        resource_usage[resource] = []\n                    resource_usage[resource].append(amount)\n            \n            for resource, amounts in resource_usage.items():\n                efficiency_patterns[f\"resource_{resource}_avg\"] = np.mean(amounts)\n                efficiency_patterns[f\"resource_{resource}_std\"] = np.std(amounts)\n            \n            # Calculate cost efficiency\n            if \"cost_metrics\" in historical_data:\n                cost_metrics = historical_data[\"cost_metrics\"]\n                total_cost = cost_metrics.get(\"total_cost\", 0)\n                successful_discoveries = sum(1 for r in historical_data[\"exploration_records\"] if r.get(\"success\", False))\n                if successful_discoveries > 0:\n                    efficiency_patterns[\"cost_per_discovery\"] = total_cost / successful_discoveries\n        \n        return efficiency_patterns\n    \n    def _get_category_embedding(self, category: str) -> float:\n        \"\"\"Convert category string to numerical embedding\"\"\"\n        category_map = {\n            \"geological_survey\": 0.1,\n            \"geophysical_exploration\": 0.2,\n            \"drilling_program\": 0.3,\n            \"sample_analysis\": 0.4,\n            \"resource_estimation\": 0.5,\n            \"environmental_assessment\": 0.6,\n            \"infrastructure_planning\": 0.7,\n            \"risk_assessment\": 0.8,\n            \"economic_evaluation\": 0.9\n        }\n        return category_map.get(category, 0.0)\n    \n    def _analyze_overall_impact(self,\n                              recommendations: List[ExplorationRecommendation],\n                              historical_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Analyze the overall potential impact of recommendations\"\"\"\n        impact_metrics = {\n            \"total_success_probability\": 0.0,\n            \"average_cost_efficiency\": 0.0,\n            \"time_optimization\": 0.0,\n            \"risk_reduction\": 0.0,\n            \"resource_optimization\": 0.0,\n            \"discovery_potential\": 0.0\n        }\n        \n        if not recommendations:\n            return impact_metrics\n        \n        # Calculate weighted impact metrics\n        total_weight = sum(rec.priority * rec.confidence for rec in recommendations)\n        \n        if total_weight > 0:\n            for rec in recommendations:\n                weight = (rec.priority * rec.confidence) / total_weight\n                \n                # Aggregate weighted impacts\n                for metric, value in rec.expected_impact.items():\n                    if metric in impact_metrics:\n                        impact_metrics[metric] += value * weight\n        \n        # Adjust based on historical performance\n        if \"exploration_records\" in historical_data:\n            historical_success_rate = self._calculate_historical_success_rate(historical_data)\n            impact_metrics[\"total_success_probability\"] *= (1 + historical_success_rate) / 2\n            \n            historical_efficiency = self._calculate_historical_efficiency(historical_data)\n            impact_metrics[\"average_cost_efficiency\"] *= (1 + historical_efficiency) / 2\n        \n        return impact_metrics\n    \n    def _analyze_category_impact(self,\n                               recommendations: List[ExplorationRecommendation],\n                               historical_data: Dict[str, Any]) -> Dict[str, Dict[str, float]]:\n        \"\"\"Analyze the impact of recommendations by category\"\"\"\n        category_impacts = {}\n        \n        # Group recommendations by category\n        for rec in recommendations:\n            if rec.category not in category_impacts:\n                category_impacts[rec.category] = {\n                    \"success_probability\": 0.0,\n                    \"cost_efficiency\": 0.0,\n                    \"time_saving\": 0.0,\n                    \"risk_reduction\": 0.0,\n                    \"count\": 0,\n                    \"total_priority\": 0.0\n                }\n            \n            # Aggregate impacts\n            impact_dict = category_impacts[rec.category]\n            impact_dict[\"success_probability\"] += rec.expected_impact.get(\"success_rate\", 0.0)\n            impact_dict[\"cost_efficiency\"] += rec.expected_impact.get(\"cost_efficiency\", 0.0)\n            impact_dict[\"time_saving\"] += rec.expected_impact.get(\"time_saving\", 0.0)\n            impact_dict[\"risk_reduction\"] += rec.expected_impact.get(\"risk_reduction\", 0.0)\n            impact_dict[\"count\"] += 1\n            impact_dict[\"total_priority\"] += rec.priority\n        \n        # Calculate averages and adjust with historical data\n        historical_patterns = self._analyze_historical_patterns(historical_data)\n        \n        for category, impact in category_impacts.items():\n            if impact[\"count\"] > 0:\n                # Calculate averages\n                for metric in [\"success_probability\", \"cost_efficiency\", \"time_saving\", \"risk_reduction\"]:\n                    impact[metric] /= impact[\"count\"]\n                \n                # Adjust based on historical performance\n                if category in historical_patterns.get(\"success_patterns\", {}):\n                    historical_rate = historical_patterns[\"success_patterns\"][category]\n                    impact[\"success_probability\"] = (impact[\"success_probability\"] + historical_rate) / 2\n                \n                if category in historical_patterns.get(\"efficiency_patterns\", {}):\n                    historical_efficiency = historical_patterns[\"efficiency_patterns\"][category]\n                    impact[\"cost_efficiency\"] = (impact[\"cost_efficiency\"] + historical_efficiency) / 2\n        \n        return category_impacts\n    \n    def _analyze_implementation_risks(self,\n                                   recommendations: List[ExplorationRecommendation],\n                                   historical_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Analyze potential risks in implementing recommendations\"\"\"\n        risk_analysis = {\n            \"technical_risk\": 0.0,\n            \"operational_risk\": 0.0,\n            \"environmental_risk\": 0.0,\n            \"financial_risk\": 0.0,\n            \"regulatory_risk\": 0.0\n        }\n        \n        # Analyze historical risk patterns\n        historical_risks = self._analyze_historical_risks(historical_data)\n        \n        # Calculate implementation risks\n        for rec in recommendations:\n            # Technical risks\n            risk_analysis[\"technical_risk\"] += (1 - rec.confidence) * rec.priority\n            \n            # Operational risks based on complexity\n            complexity_factor = len(rec.actions) / 10  # Normalize by maximum expected actions\n            risk_analysis[\"operational_risk\"] += complexity_factor * rec.priority\n            \n            # Environmental risks\n            if \"environmental_impact\" in rec.expected_impact:\n                risk_analysis[\"environmental_risk\"] += rec.expected_impact[\"environmental_impact\"]\n            \n            # Financial risks\n            if \"cost_efficiency\" in rec.expected_impact:\n                risk_analysis[\"financial_risk\"] += (1 - rec.expected_impact[\"cost_efficiency\"]) * rec.priority\n            \n            # Regulatory risks\n            if rec.category in [\"environmental_assessment\", \"infrastructure_planning\"]:\n                risk_analysis[\"regulatory_risk\"] += 0.4 * rec.priority\n        \n        # Normalize risks\n        total_recommendations = len(recommendations) if recommendations else 1\n        for risk_type in risk_analysis:\n            risk_analysis[risk_type] = min(1.0, risk_analysis[risk_type] / total_recommendations)\n            \n            # Adjust based on historical patterns\n            if risk_type in historical_risks:\n                risk_analysis[risk_type] = (risk_analysis[risk_type] + historical_risks[risk_type]) / 2\n        \n        return risk_analysis\n    \n    def _analyze_cost_benefit(self,\n                            recommendations: List[ExplorationRecommendation],\n                            historical_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Analyze cost-benefit ratio of recommendations\"\"\"\n        cost_benefit = {\n            \"expected_roi\": 0.0,\n            \"payback_period\": 0.0,\n            \"investment_efficiency\": 0.0,\n            \"resource_efficiency\": 0.0\n        }\n        \n        if not recommendations:\n            return cost_benefit\n        \n        total_cost = 0.0\n        total_benefit = 0.0\n        total_time = 0.0\n        \n        # Calculate costs and benefits\n        for rec in recommendations:\n            # Estimate implementation cost\n            implementation_cost = self._estimate_implementation_cost(rec)\n            total_cost += implementation_cost\n            \n            # Estimate potential benefit\n            success_probability = rec.expected_impact.get(\"success_rate\", 0.0)\n            potential_value = self._estimate_potential_value(rec)\n            expected_benefit = success_probability * potential_value\n            total_benefit += expected_benefit\n            \n            # Estimate implementation time\n            implementation_time = self._estimate_implementation_time(rec)\n            total_time += implementation_time\n        \n        # Calculate ROI and efficiency metrics\n        if total_cost > 0:\n            cost_benefit[\"expected_roi\"] = (total_benefit - total_cost) / total_cost\n            cost_benefit[\"investment_efficiency\"] = total_benefit / total_cost\n        \n        if total_time > 0:\n            cost_benefit[\"payback_period\"] = total_cost / (total_benefit / total_time)\n            cost_benefit[\"resource_efficiency\"] = total_benefit / (total_cost * total_time)\n        \n        # Adjust based on historical performance\n        if \"cost_metrics\" in historical_data:\n            historical_roi = historical_data[\"cost_metrics\"].get(\"average_roi\", 0.0)\n            cost_benefit[\"expected_roi\"] = (cost_benefit[\"expected_roi\"] + historical_roi) / 2\n        \n        return cost_benefit\n\n    def _calculate_historical_success_rate(self, historical_data: Dict[str, Any]) -> float:\n        \"\"\"Calculate historical success rate from exploration records\"\"\"\n        if \"exploration_records\" not in historical_data:\n            return 0.0\n            \n        records = historical_data[\"exploration_records\"]\n        if not records:\n            return 0.0\n            \n        successful = sum(1 for record in records if record.get(\"success\", False))\n        return successful / len(records)\n\n    def _calculate_historical_efficiency(self, historical_data: Dict[str, Any]) -> float:\n        \"\"\"Calculate historical operational efficiency\"\"\"\n        if \"performance_metrics\" not in historical_data:\n            return 0.0\n            \n        metrics = historical_data[\"performance_metrics\"]\n        efficiency_factors = [\n            metrics.get(\"resource_utilization\", 0.0),\n            metrics.get(\"time_efficiency\", 0.0),\n            metrics.get(\"cost_efficiency\", 0.0)\n        ]\n        \n        return sum(efficiency_factors) / len(efficiency_factors) if efficiency_factors else 0.0\n\n    def _analyze_historical_risks(self, historical_data: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"Analyze historical risk patterns\"\"\"\n        risk_patterns = {\n            \"technical_risk\": 0.0,\n            \"operational_risk\": 0.0,\n            \"environmental_risk\": 0.0,\n            \"financial_risk\": 0.0,\n            \"regulatory_risk\": 0.0\n        }\n        \n        if \"risk_records\" in historical_data:\n            risk_records = historical_data[\"risk_records\"]\n            if risk_records:\n                for record in risk_records:\n                    for risk_type, risk_value in record.get(\"risk_levels\", {}).items():\n                        if risk_type in risk_patterns:\n                            risk_patterns[risk_type] = max(risk_patterns[risk_type], risk_value)\n                            \n        return risk_patterns\n\n    def _estimate_implementation_cost(self, recommendation: ExplorationRecommendation) -> float:\n        \"\"\"Estimate the cost of implementing a recommendation\"\"\"\n        base_costs = {\n            \"geological_survey\": 50000.0,\n            \"geophysical_exploration\": 75000.0,\n            \"drilling_program\": 200000.0,\n            \"sample_analysis\": 25000.0,\n            \"resource_estimation\": 40000.0,\n            \"environmental_assessment\": 60000.0,\n            \"infrastructure_planning\": 100000.0,\n            \"risk_assessment\": 30000.0,\n            \"economic_evaluation\": 45000.0\n        }\n        \n        # Get base cost for category\n        base_cost = base_costs.get(recommendation.category, 50000.0)\n        \n        # Adjust based on complexity (number of actions)\n        complexity_factor = len(recommendation.actions) / 5  # Normalize by typical number of actions\n        \n        # Adjust based on priority and confidence\n        priority_factor = 1 + (recommendation.priority - 0.5)  # Higher priority increases cost\n        confidence_factor = 1 + (1 - recommendation.confidence)  # Lower confidence increases cost\n        \n        # Calculate final cost\n        estimated_cost = base_cost * complexity_factor * priority_factor * confidence_factor\n        \n        return estimated_cost\n\n    def _estimate_potential_value(self, recommendation: ExplorationRecommendation) -> float:\n        \"\"\"Estimate the potential value of implementing a recommendation\"\"\"\n        base_values = {\n            \"geological_survey\": 150000.0,\n            \"geophysical_exploration\": 250000.0,\n            \"drilling_program\": 500000.0,\n            \"sample_analysis\": 100000.0,\n            \"resource_estimation\": 200000.0,\n            \"environmental_assessment\": 150000.0,\n            \"infrastructure_planning\": 300000.0,\n            \"risk_assessment\": 120000.0,\n            \"economic_evaluation\": 180000.0\n        }\n        \n        # Get base value for category\n        base_value = base_values.get(recommendation.category, 150000.0)\n        \n        # Adjust based on priority and confidence\n        priority_factor = 1 + recommendation.priority  # Higher priority increases value\n        confidence_factor = 1 + recommendation.confidence  # Higher confidence increases value\n        \n        # Adjust based on expected impacts\n        impact_factor = 1.0\n        if recommendation.expected_impact:\n            impact_values = [\n                recommendation.expected_impact.get(\"success_rate\", 0.0),\n                recommendation.expected_impact.get(\"cost_efficiency\", 0.0),\n                recommendation.expected_impact.get(\"time_saving\", 0.0),\n                recommendation.expected_impact.get(\"risk_reduction\", 0.0)\n            ]\n            impact_factor = 1 + sum(impact_values) / len(impact_values)\n        \n        # Calculate final value\n        estimated_value = base_value * priority_factor * confidence_factor * impact_factor\n        \n        return estimated_value\n\n    def _estimate_implementation_time(self, recommendation: ExplorationRecommendation) -> float:\n        \"\"\"Estimate the time required to implement a recommendation in days\"\"\"\n        base_times = {\n            \"geological_survey\": 30.0,\n            \"geophysical_exploration\": 45.0,\n            \"drilling_program\": 90.0,\n            \"sample_analysis\": 15.0,\n            \"resource_estimation\": 30.0,\n            \"environmental_assessment\": 60.0,\n            \"infrastructure_planning\": 75.0,\n            \"risk_assessment\": 20.0,\n            \"economic_evaluation\": 30.0\n        }\n        \n        # Get base time for category\n        base_time = base_times.get(recommendation.category, 30.0)\n        \n        # Adjust based on complexity (number of actions)\n        complexity_factor = len(recommendation.actions) / 5  # Normalize by typical number of actions\n        \n        # Adjust based on priority\n        priority_factor = 1 - (recommendation.priority * 0.2)  # Higher priority reduces time\n        \n        # Calculate final time estimate\n        estimated_time = base_time * complexity_factor * priority_factor\n        \n        return max(estimated_time, 5.0)  # Minimum 5 days\n\n    def save_model(self, path: str):\n        \"\"\"Save the trained model to disk\"\"\"\n        if self.model is None:\n            raise ValueError(\"No model to save\")\n            \n        # Save model state\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'input_size': self.input_size,\n            'scaler_state': self.scaler.__getstate__() if self.scaler else None\n        }, path)\n\n    def load_model(self, path: str):\n        \"\"\"Load a trained model from disk\"\"\"\n        if not os.path.exists(path):\n            raise FileNotFoundError(f\"Model file not found: {path}\")\n            \n        # Load model state\n        checkpoint = torch.load(path, map_location=self.device)\n        \n        # Initialize model\n        self.input_size = checkpoint['input_size']\n        self.model = RecommendationModel(self.input_size).to(self.device)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        \n        # Load scaler if available\n        if checkpoint.get('scaler_state'):\n            self.scaler = StandardScaler()\n            self.scaler.__setstate__(checkpoint['scaler_state'])\n\n    def evaluate_model(self,\n                      validation_data: Dict[str, Any],\n                      metrics: Optional[List[str]] = None) -> Dict[str, float]:\n        \"\"\"Evaluate model performance on validation data\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not initialized\")\n            \n        if metrics is None:\n            metrics = [\"mse\", \"mae\", \"r2\"]\n            \n        # Prepare validation data\n        X_val = self._prepare_features(\n            validation_data[\"exploration_data\"],\n            validation_data[\"historical_data\"],\n            validation_data[\"current_state\"]\n        )\n        y_val = self._prepare_labels(validation_data)\n        \n        # Generate predictions\n        self.model.eval()\n        with torch.no_grad():\n            recommendations, impacts, confidences, feature_weights = self.model(X_val)\n        \n        # Calculate metrics\n        evaluation_results = {}\n        \n        if \"mse\" in metrics:\n            evaluation_results[\"mse_recommendations\"] = F.mse_loss(\n                recommendations,\n                y_val[\"recommendations\"]\n            ).item()\n            evaluation_results[\"mse_impacts\"] = F.mse_loss(\n                impacts,\n                y_val[\"impacts\"]\n            ).item()\n        \n        if \"mae\" in metrics:\n            evaluation_results[\"mae_recommendations\"] = F.l1_loss(\n                recommendations,\n                y_val[\"recommendations\"]\n            ).item()\n            evaluation_results[\"mae_impacts\"] = F.l1_loss(\n                impacts,\n                y_val[\"impacts\"]\n            ).item()\n        \n        if \"r2\" in metrics:\n            evaluation_results[\"r2_recommendations\"] = self._calculate_r2_score(\n                recommendations,\n                y_val[\"recommendations\"]\n            )\n            evaluation_results[\"r2_impacts\"] = self._calculate_r2_score(\n                impacts,\n                y_val[\"impacts\"]\n            )\n        \n        return evaluation_results\n\n    def _calculate_r2_score(self, predictions: torch.Tensor, targets: torch.Tensor) -> float:\n        \"\"\"Calculate R score between predictions and targets\"\"\"\n        ss_tot = torch.sum((targets - torch.mean(targets, dim=0)) ** 2)\n        ss_res = torch.sum((targets - predictions) ** 2)\n        \n        r2 = 1 - (ss_res / ss_tot)\n        return float(r2.mean().item())\n\n    def validate_data(self,\n                     exploration_data: Dict[str, Any],\n                     historical_data: Dict[str, Any],\n                     current_state: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"\n        Validate input data format and content\n        \n        Returns:\n            Tuple of (is_valid, error_messages)\n        \"\"\"\n        errors = []\n        \n        # Validate exploration data\n        if not exploration_data:\n            errors.append(\"Exploration data is required\")\n        else:\n            # Validate geological data\n            if \"geological_data\" in exploration_data:\n                geo_data = exploration_data[\"geological_data\"]\n                required_geo_fields = [\n                    \"mineralization_grade\",\n                    \"structural_complexity\",\n                    \"deposit_depth\",\n                    \"rock_quality\"\n                ]\n                for field in required_geo_fields:\n                    if field not in geo_data:\n                        errors.append(f\"Missing geological data field: {field}\")\n                    elif not isinstance(geo_data[field], (int, float)):\n                        errors.append(f\"Invalid type for geological data field {field}\")\n            \n            # Validate geophysical data\n            if \"geophysical_data\" in exploration_data:\n                geo_phys = exploration_data[\"geophysical_data\"]\n                required_geophys_fields = [\n                    \"magnetic_intensity\",\n                    \"gravity_anomaly\",\n                    \"resistivity\",\n                    \"seismic_velocity\"\n                ]\n                for field in required_geophys_fields:\n                    if field not in geo_phys:\n                        errors.append(f\"Missing geophysical data field: {field}\")\n                    elif not isinstance(geo_phys[field], (int, float)):\n                        errors.append(f\"Invalid type for geophysical data field {field}\")\n        \n        # Validate historical data\n        if not historical_data:\n            errors.append(\"Historical data is required\")\n        else:\n            # Validate exploration records\n            if \"exploration_records\" in historical_data:\n                records = historical_data[\"exploration_records\"]\n                if not isinstance(records, list):\n                    errors.append(\"Exploration records must be a list\")\n                else:\n                    for i, record in enumerate(records):\n                        if not isinstance(record, dict):\n                            errors.append(f\"Invalid exploration record at index {i}\")\n                        else:\n                            required_record_fields = [\"success\", \"timestamp\"]\n                            for field in required_record_fields:\n                                if field not in record:\n                                    errors.append(f\"Missing field {field} in exploration record at index {i}\")\n            \n            # Validate performance metrics\n            if \"performance_metrics\" in historical_data:\n                metrics = historical_data[\"performance_metrics\"]\n                required_metric_fields = [\n                    \"success_rate\",\n                    \"efficiency\",\n                    \"cost_effectiveness\",\n                    \"time_efficiency\"\n                ]\n                for field in required_metric_fields:\n                    if field not in metrics:\n                        errors.append(f\"Missing performance metric: {field}\")\n                    elif not isinstance(metrics[field], (int, float)):\n                        errors.append(f\"Invalid type for performance metric {field}\")\n        \n        # Validate current state\n        if not current_state:\n            errors.append(\"Current state data is required\")\n        else:\n            required_state_fields = [\n                \"resource_availability\",\n                \"weather_conditions\",\n                \"budget_constraints\"\n            ]\n            for field in required_state_fields:\n                if field not in current_state:\n                    errors.append(f\"Missing current state field: {field}\")\n        \n        return len(errors) == 0, errors\n\n    def preprocess_data(self,\n                       exploration_data: Dict[str, Any],\n                       historical_data: Dict[str, Any],\n                       current_state: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n        \"\"\"\n        Preprocess and normalize input data\n        \n        Returns:\n            Tuple of (processed_exploration_data, processed_historical_data, processed_current_state)\n        \"\"\"\n        # Process exploration data\n        processed_exploration = exploration_data.copy()\n        \n        if \"geological_data\" in processed_exploration:\n            geo_data = processed_exploration[\"geological_data\"]\n            # Normalize geological measurements\n            for field in geo_data:\n                if isinstance(geo_data[field], (int, float)):\n                    geo_data[field] = self._normalize_value(\n                        geo_data[field],\n                        field\n                    )\n        \n        if \"geophysical_data\" in processed_exploration:\n            geo_phys = processed_exploration[\"geophysical_data\"]\n            # Normalize geophysical measurements\n            for field in geo_phys:\n                if isinstance(geo_phys[field], (int, float)):\n                    geo_phys[field] = self._normalize_value(\n                        geo_phys[field],\n                        field\n                    )\n        \n        # Process historical data\n        processed_historical = historical_data.copy()\n        \n        if \"exploration_records\" in processed_historical:\n            # Sort records by timestamp\n            processed_historical[\"exploration_records\"].sort(\n                key=lambda x: x.get(\"timestamp\", \"\")\n            )\n            \n            # Calculate rolling averages\n            window_size = 5\n            for i in range(len(processed_historical[\"exploration_records\"])):\n                window = processed_historical[\"exploration_records\"][max(0, i-window_size+1):i+1]\n                if window:\n                    processed_historical[\"exploration_records\"][i][\"rolling_success_rate\"] = \\\n                        sum(1 for r in window if r.get(\"success\", False)) / len(window)\n        \n        if \"performance_metrics\" in processed_historical:\n            metrics = processed_historical[\"performance_metrics\"]\n            # Normalize performance metrics\n            for field in metrics:\n                if isinstance(metrics[field], (int, float)):\n                    metrics[field] = self._normalize_value(\n                        metrics[field],\n                        field\n                    )\n        \n        # Process current state\n        processed_state = current_state.copy()\n        \n        if \"resource_availability\" in processed_state:\n            resources = processed_state[\"resource_availability\"]\n            # Normalize resource availability\n            for resource in resources:\n                if isinstance(resources[resource], (int, float)):\n                    resources[resource] = self._normalize_value(\n                        resources[resource],\n                        f\"resource_{resource}\"\n                    )\n        \n        return processed_exploration, processed_historical, processed_state\n\n    def _normalize_value(self, value: float, field_name: str) -> float:\n        \"\"\"Normalize a value based on predefined ranges for different fields\"\"\"\n        ranges = {\n            \"mineralization_grade\": (0, 100),\n            \"structural_complexity\": (0, 10),\n            \"deposit_depth\": (0, 1000),\n            \"rock_quality\": (0, 100),\n            \"magnetic_intensity\": (-1000, 1000),\n            \"gravity_anomaly\": (-100, 100),\n            \"resistivity\": (0, 10000),\n            \"seismic_velocity\": (0, 8000),\n            \"success_rate\": (0, 1),\n            \"efficiency\": (0, 1),\n            \"cost_effectiveness\": (0, 1),\n            \"time_efficiency\": (0, 1),\n            \"resource_equipment\": (0, 1),\n            \"resource_personnel\": (0, 1)\n        }\n        \n        if field_name in ranges:\n            min_val, max_val = ranges[field_name]\n            return (value - min_val) / (max_val - min_val)\n        \n        return value\n\n    def _validate_recommendation(self, recommendation: ExplorationRecommendation) -> Tuple[bool, List[str]]:\n        \"\"\"Validate a generated recommendation\"\"\"\n        errors = []\n        \n        # Validate basic fields\n        if not recommendation.recommendation_id:\n            errors.append(\"Missing recommendation ID\")\n        \n        if not recommendation.category:\n            errors.append(\"Missing category\")\n        elif recommendation.category not in [\n            \"geological_survey\",\n            \"geophysical_exploration\",\n            \"drilling_program\",\n            \"sample_analysis\",\n            \"resource_estimation\",\n            \"environmental_assessment\",\n            \"infrastructure_planning\",\n            \"risk_assessment\",\n            \"economic_evaluation\"\n        ]:\n            errors.append(f\"Invalid category: {recommendation.category}\")\n        \n        # Validate numerical fields\n        if not 0 <= recommendation.priority <= 1:\n            errors.append(f\"Invalid priority value: {recommendation.priority}\")\n        \n        if not 0 <= recommendation.confidence <= 1:\n            errors.append(f\"Invalid confidence value: {recommendation.confidence}\")\n        \n        # Validate description\n        if not recommendation.description:\n            errors.append(\"Missing description\")\n        \n        # Validate actions\n        if not recommendation.actions:\n            errors.append(\"No actions specified\")\n        \n        # Validate expected impact\n        required_impact_metrics = [\n            \"success_rate\",\n            \"cost_efficiency\",\n            \"time_saving\",\n            \"risk_reduction\"\n        ]\n        for metric in required_impact_metrics:\n            if metric not in recommendation.expected_impact:\n                errors.append(f\"Missing impact metric: {metric}\")\n            elif not 0 <= recommendation.expected_impact[metric] <= 1:\n                errors.append(f\"Invalid impact value for {metric}\")\n        \n        # Validate supporting data\n        if not recommendation.supporting_data:\n            errors.append(\"Missing supporting data\")\n        \n        # Validate timestamp\n        if not recommendation.timestamp:\n            errors.append(\"Missing timestamp\")\n        \n        return len(errors) == 0, errors\n\n    def generate_recommendation_report(self,\n                                    recommendations: List[ExplorationRecommendation],\n                                    historical_data: Dict[str, Any],\n                                    output_format: str = \"text\") -> str:\n        \"\"\"\n        Generate a detailed report of recommendations\n        \n        Args:\n            recommendations: List of recommendations to report on\n            historical_data: Historical data for context\n            output_format: Report format (\"text\" or \"html\")\n            \n        Returns:\n            Formatted report string\n        \"\"\"\n        if output_format == \"html\":\n            return self._generate_html_report(recommendations, historical_data)\n        else:\n            return self._generate_text_report(recommendations, historical_data)\n\n    def _generate_text_report(self,\n                            recommendations: List[ExplorationRecommendation],\n                            historical_data: Dict[str, Any]) -> str:\n        \"\"\"Generate a text-based recommendation report\"\"\"\n        report = []\n        \n        # Add header\n        report.append(\"=\" * 80)\n        report.append(\"MINESIGHT EXPLORATION RECOMMENDATIONS REPORT\")\n        report.append(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n        report.append(\"=\" * 80)\n        report.append(\"\")\n        \n        # Add summary section\n        report.append(\"EXECUTIVE SUMMARY\")\n        report.append(\"-\" * 50)\n        total_recommendations = len(recommendations)\n        high_priority = sum(1 for r in recommendations if r.priority > 0.7)\n        avg_confidence = sum(r.confidence for r in recommendations) / total_recommendations if recommendations else 0\n        \n        report.append(f\"Total Recommendations: {total_recommendations}\")\n        report.append(f\"High Priority Actions: {high_priority}\")\n        report.append(f\"Average Confidence: {avg_confidence:.2%}\")\n        report.append(\"\")\n        \n        # Add historical context\n        report.append(\"HISTORICAL CONTEXT\")\n        report.append(\"-\" * 50)\n        success_rate = self._calculate_historical_success_rate(historical_data)\n        efficiency = self._calculate_historical_efficiency(historical_data)\n        \n        report.append(f\"Historical Success Rate: {success_rate:.2%}\")\n        report.append(f\"Historical Efficiency: {efficiency:.2%}\")\n        report.append(\"\")\n        \n        # Add detailed recommendations\n        report.append(\"DETAILED RECOMMENDATIONS\")\n        report.append(\"-\" * 50)\n        \n        for i, rec in enumerate(recommendations, 1):\n            report.append(f\"\\n{i}. {rec.category.upper()}\")\n            report.append(f\"   Priority: {rec.priority:.2%}\")\n            report.append(f\"   Confidence: {rec.confidence:.2%}\")\n            report.append(f\"   Description: {rec.description}\")\n            report.append(\"\\n   Recommended Actions:\")\n            for action in rec.actions:\n                report.append(f\"   - {action}\")\n            report.append(\"\\n   Expected Impact:\")\n            for metric, value in rec.expected_impact.items():\n                report.append(f\"   - {metric.replace('_', ' ').title()}: {value:.2%}\")\n            report.append(\"\")\n        \n        # Add risk analysis\n        report.append(\"RISK ANALYSIS\")\n        report.append(\"-\" * 50)\n        risks = self._analyze_implementation_risks(recommendations, historical_data)\n        for risk_type, risk_level in risks.items():\n            report.append(f\"{risk_type.replace('_', ' ').title()}: {risk_level:.2%}\")\n        report.append(\"\")\n        \n        # Add cost-benefit analysis\n        report.append(\"COST-BENEFIT ANALYSIS\")\n        report.append(\"-\" * 50)\n        cost_benefit = self._analyze_cost_benefit(recommendations, historical_data)\n        for metric, value in cost_benefit.items():\n            if metric == \"payback_period\":\n                report.append(f\"{metric.replace('_', ' ').title()}: {value:.1f} months\")\n            else:\n                report.append(f\"{metric.replace('_', ' ').title()}: {value:.2%}\")\n        \n        return \"\\n\".join(report)\n\n    def _generate_html_report(self,\n                            recommendations: List[ExplorationRecommendation],\n                            historical_data: Dict[str, Any]) -> str:\n        \"\"\"Generate an HTML recommendation report\"\"\"\n        html = []\n        \n        # Add header\n        html.append(\"\"\"\n        <html>\n        <head>\n            <style>\n                body { font-family: Arial, sans-serif; margin: 40px; }\n                h1 { color: #2c3e50; }\n                h2 { color: #34495e; margin-top: 30px; }\n                .summary { background: #f8f9fa; padding: 20px; border-radius: 5px; }\n                .recommendation { \n                    border: 1px solid #dee2e6;\n                    padding: 20px;\n                    margin: 20px 0;\n                    border-radius: 5px;\n                }\n                .priority-high { border-left: 5px solid #dc3545; }\n                .priority-medium { border-left: 5px solid #ffc107; }\n                .priority-low { border-left: 5px solid #28a745; }\n                .metric { \n                    display: inline-block;\n                    padding: 5px 10px;\n                    background: #e9ecef;\n                    border-radius: 3px;\n                    margin: 5px;\n                }\n                .actions { margin: 10px 0; }\n                .action-item {\n                    padding: 5px 10px;\n                    margin: 5px 0;\n                    background: #f8f9fa;\n                    border-radius: 3px;\n                }\n            </style>\n        </head>\n        <body>\n        \"\"\")\n        \n        # Add title\n        html.append(f\"\"\"\n        <h1>MineSight Exploration Recommendations Report</h1>\n        <p>Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n        \"\"\")\n        \n        # Add summary section\n        total_recommendations = len(recommendations)\n        high_priority = sum(1 for r in recommendations if r.priority > 0.7)\n        avg_confidence = sum(r.confidence for r in recommendations) / total_recommendations if recommendations else 0\n        \n        html.append(f\"\"\"\n        <div class=\"summary\">\n            <h2>Executive Summary</h2>\n            <p>Total Recommendations: <strong>{total_recommendations}</strong></p>\n            <p>High Priority Actions: <strong>{high_priority}</strong></p>\n            <p>Average Confidence: <strong>{avg_confidence:.2%}</strong></p>\n        </div>\n        \"\"\")\n        \n        # Add historical context\n        success_rate = self._calculate_historical_success_rate(historical_data)\n        efficiency = self._calculate_historical_efficiency(historical_data)\n        \n        html.append(f\"\"\"\n        <h2>Historical Context</h2>\n        <div class=\"metrics\">\n            <span class=\"metric\">Historical Success Rate: {success_rate:.2%}</span>\n            <span class=\"metric\">Historical Efficiency: {efficiency:.2%}</span>\n        </div>\n        \"\"\")\n        \n        # Add detailed recommendations\n        html.append(\"<h2>Detailed Recommendations</h2>\")\n        \n        for rec in recommendations:\n            priority_class = \"high\" if rec.priority > 0.7 else \"medium\" if rec.priority > 0.4 else \"low\"\n            \n            html.append(f\"\"\"\n            <div class=\"recommendation priority-{priority_class}\">\n                <h3>{rec.category.replace('_', ' ').title()}</h3>\n                <div class=\"metrics\">\n                    <span class=\"metric\">Priority: {rec.priority:.2%}</span>\n                    <span class=\"metric\">Confidence: {rec.confidence:.2%}</span>\n                </div>\n                <p><strong>Description:</strong> {rec.description}</p>\n                <div class=\"actions\">\n                    <strong>Recommended Actions:</strong>\n                    <ul>\n            \"\"\")\n            \n            for action in rec.actions:\n                html.append(f'<li class=\"action-item\">{action}</li>')\n            \n            html.append(\"\"\"\n                    </ul>\n                </div>\n                <div class=\"impacts\">\n                    <strong>Expected Impact:</strong>\n                    <div class=\"metrics\">\n            \"\"\")\n            \n            for metric, value in rec.expected_impact.items():\n                html.append(f'<span class=\"metric\">{metric.replace(\"_\", \" \").title()}: {value:.2%}</span>')\n            \n            html.append(\"\"\"\n                    </div>\n                </div>\n            </div>\n            \"\"\")\n        \n        # Add risk analysis\n        risks = self._analyze_implementation_risks(recommendations, historical_data)\n        html.append(\"\"\"\n        <h2>Risk Analysis</h2>\n        <div class=\"metrics\">\n        \"\"\")\n        \n        for risk_type, risk_level in risks.items():\n            html.append(f'<span class=\"metric\">{risk_type.replace(\"_\", \" \").title()}: {risk_level:.2%}</span>')\n        \n        html.append(\"</div>\")\n        \n        # Add cost-benefit analysis\n        cost_benefit = self._analyze_cost_benefit(recommendations, historical_data)\n        html.append(\"\"\"\n        <h2>Cost-Benefit Analysis</h2>\n        <div class=\"metrics\">\n        \"\"\")\n        \n        for metric, value in cost_benefit.items():\n            if metric == \"payback_period\":\n                html.append(f'<span class=\"metric\">{metric.replace(\"_\", \" \").title()}: {value:.1f} months</span>')\n            else:\n                html.append(f'<span class=\"metric\">{metric.replace(\"_\", \" \").title()}: {value:.2%}</span>')\n        \n        html.append(\"</div>\")\n        \n        # Close HTML\n        html.append(\"\"\"\n        </body>\n        </html>\n        \"\"\")\n        \n        return \"\\n\".join(html)\n\n    def visualize_recommendations(self,\n                                recommendations: List[ExplorationRecommendation],\n                                plot_type: str = \"priority_confidence\",\n                                save_path: Optional[str] = None) -> None:\n        \"\"\"\n        Visualize recommendations using various plot types\n        \n        Args:\n            recommendations: List of recommendations to visualize\n            plot_type: Type of visualization (\"priority_confidence\", \"impact_distribution\", \n                      \"category_distribution\", \"risk_analysis\", \"timeline\")\n            save_path: Optional path to save the visualization\n        \"\"\"\n        try:\n            import matplotlib.pyplot as plt\n            import seaborn as sns\n            \n            plt.style.use('seaborn')\n            \n            if plot_type == \"priority_confidence\":\n                self._plot_priority_confidence(recommendations)\n            elif plot_type == \"impact_distribution\":\n                self._plot_impact_distribution(recommendations)\n            elif plot_type == \"category_distribution\":\n                self._plot_category_distribution(recommendations)\n            elif plot_type == \"risk_analysis\":\n                self._plot_risk_analysis(recommendations)\n            elif plot_type == \"timeline\":\n                self._plot_recommendation_timeline(recommendations)\n            else:\n                warnings.warn(f\"Unknown plot type: {plot_type}\")\n                return\n            \n            if save_path:\n                plt.savefig(save_path, bbox_inches='tight', dpi=300)\n            else:\n                plt.show()\n            \n        except ImportError:\n            warnings.warn(\"Visualization requires matplotlib and seaborn packages.\")\n\n    def _plot_priority_confidence(self, recommendations: List[ExplorationRecommendation]) -> None:\n        \"\"\"Plot priority vs confidence scatter plot\"\"\"\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n        \n        # Prepare data\n        priorities = [r.priority for r in recommendations]\n        confidences = [r.confidence for r in recommendations]\n        categories = [r.category for r in recommendations]\n        \n        # Create figure\n        plt.figure(figsize=(12, 8))\n        \n        # Create scatter plot\n        scatter = plt.scatter(priorities, confidences, c=range(len(recommendations)), \n                            cmap='viridis', alpha=0.6, s=150)\n        \n        # Add labels and title\n        plt.xlabel('Priority', fontsize=12)\n        plt.ylabel('Confidence', fontsize=12)\n        plt.title('Recommendation Priority vs Confidence', fontsize=14, pad=20)\n        \n        # Add category labels\n        for i, category in enumerate(categories):\n            plt.annotate(category.replace('_', ' ').title(), \n                        (priorities[i], confidences[i]),\n                        xytext=(5, 5), textcoords='offset points',\n                        fontsize=10)\n        \n        # Add colorbar\n        cbar = plt.colorbar(scatter, label='Recommendation Index')\n        cbar.ax.tick_params(labelsize=10)\n        \n        # Add grid\n        plt.grid(True, alpha=0.3)\n        \n        # Adjust layout\n        plt.tight_layout()\n\n    def _plot_impact_distribution(self, recommendations: List[ExplorationRecommendation]) -> None:\n        \"\"\"Plot impact distribution box plot\"\"\"\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n        \n        # Prepare data\n        impact_data = []\n        labels = []\n        colors = ['#2ecc71', '#3498db', '#e74c3c', '#f1c40f']\n        \n        for metric in [\"success_rate\", \"cost_efficiency\", \"time_saving\", \"risk_reduction\"]:\n            values = [r.expected_impact[metric] for r in recommendations]\n            impact_data.extend(values)\n            labels.extend([metric.replace('_', ' ').title()] * len(values))\n        \n        # Create figure\n        plt.figure(figsize=(12, 6))\n        \n        # Create box plot\n        sns.boxplot(x=labels, y=impact_data, palette=colors)\n        \n        # Customize plot\n        plt.xticks(rotation=45, ha='right')\n        plt.ylabel('Impact Value', fontsize=12)\n        plt.xlabel('')\n        plt.title('Distribution of Expected Impacts', fontsize=14, pad=20)\n        \n        # Add grid\n        plt.grid(True, alpha=0.3)\n        \n        # Adjust layout\n        plt.tight_layout()\n\n    def _plot_category_distribution(self, recommendations: List[ExplorationRecommendation]) -> None:\n        \"\"\"Plot category distribution bar plot\"\"\"\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n        \n        # Prepare data\n        category_counts = {}\n        for rec in recommendations:\n            category_counts[rec.category] = category_counts.get(rec.category, 0) + 1\n        \n        categories = list(category_counts.keys())\n        counts = list(category_counts.values())\n        \n        # Create figure\n        plt.figure(figsize=(14, 6))\n        \n        # Create bar plot\n        colors = sns.color_palette(\"husl\", len(categories))\n        bars = plt.bar(categories, counts, color=colors)\n        \n        # Customize plot\n        plt.xticks(rotation=45, ha='right')\n        plt.ylabel('Number of Recommendations', fontsize=12)\n        plt.title('Distribution of Recommendations by Category', fontsize=14, pad=20)\n        \n        # Add value labels on bars\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height,\n                    f'{int(height)}',\n                    ha='center', va='bottom')\n        \n        # Add grid\n        plt.grid(True, alpha=0.3, axis='y')\n        \n        # Adjust layout\n        plt.tight_layout()\n\n    def _plot_risk_analysis(self, recommendations: List[ExplorationRecommendation]) -> None:\n        \"\"\"Plot risk analysis radar chart\"\"\"\n        import matplotlib.pyplot as plt\n        import numpy as np\n        \n        # Prepare data\n        risks = self._analyze_implementation_risks(recommendations, {})\n        risk_types = list(risks.keys())\n        risk_values = list(risks.values())\n        \n        # Number of variables\n        num_vars = len(risk_types)\n        \n        # Compute angle for each axis\n        angles = [n / float(num_vars) * 2 * np.pi for n in range(num_vars)]\n        angles += angles[:1]\n        \n        # Initialize the spider plot\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n        \n        # Plot data\n        values = risk_values + [risk_values[0]]\n        ax.plot(angles, values, 'o-', linewidth=2, label='Risk Levels')\n        ax.fill(angles, values, alpha=0.25)\n        \n        # Fix axis to go in the right order and start at 12 o'clock\n        ax.set_theta_offset(np.pi / 2)\n        ax.set_theta_direction(-1)\n        \n        # Draw axis lines for each angle and label\n        ax.set_xticks(angles[:-1])\n        ax.set_xticklabels([t.replace('_', ' ').title() for t in risk_types])\n        \n        # Add title\n        plt.title('Risk Analysis Overview', fontsize=14, pad=20)\n        \n        # Add legend\n        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n\n    def _plot_recommendation_timeline(self, recommendations: List[ExplorationRecommendation]) -> None:\n        \"\"\"Plot recommendation timeline\"\"\"\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n        \n        # Prepare data\n        categories = []\n        priorities = []\n        confidences = []\n        timestamps = []\n        \n        for rec in recommendations:\n            categories.append(rec.category)\n            priorities.append(rec.priority)\n            confidences.append(rec.confidence)\n            timestamps.append(rec.timestamp)\n        \n        # Create figure\n        plt.figure(figsize=(15, 6))\n        \n        # Create scatter plot\n        scatter = plt.scatter(timestamps, priorities, c=confidences, \n                            cmap='RdYlGn', s=150, alpha=0.6)\n        \n        # Customize plot\n        plt.xlabel('Time', fontsize=12)\n        plt.ylabel('Priority', fontsize=12)\n        plt.title('Recommendation Timeline', fontsize=14, pad=20)\n        \n        # Add category labels\n        for i, category in enumerate(categories):\n            plt.annotate(category.replace('_', ' ').title(), \n                        (timestamps[i], priorities[i]),\n                        xytext=(5, 5), textcoords='offset points',\n                        fontsize=8)\n        \n        # Add colorbar\n        cbar = plt.colorbar(scatter, label='Confidence')\n        cbar.ax.tick_params(labelsize=10)\n        \n        # Rotate x-axis labels\n        plt.xticks(rotation=45, ha='right')\n        \n        # Add grid\n        plt.grid(True, alpha=0.3)\n        \n        # Adjust layout\n        plt.tight_layout() \n\n    def export_recommendations(self,\n                             recommendations: List[ExplorationRecommendation],\n                             output_path: str,\n                             format: str = \"json\") -> None:\n        \"\"\"\n        Export recommendations to file\n        \n        Args:\n            recommendations: List of recommendations to export\n            output_path: Path to save the exported data\n            format: Export format (\"json\" or \"csv\")\n        \"\"\"\n        if format == \"json\":\n            self._export_to_json(recommendations, output_path)\n        elif format == \"csv\":\n            self._export_to_csv(recommendations, output_path)\n        else:\n            raise ValueError(f\"Unsupported export format: {format}\")\n\n    def _export_to_json(self, recommendations: List[ExplorationRecommendation], output_path: str) -> None:\n        \"\"\"Export recommendations to JSON file\"\"\"\n        # Convert recommendations to dictionary format\n        recommendations_data = []\n        for rec in recommendations:\n            rec_dict = asdict(rec)\n            # Convert datetime to string\n            rec_dict[\"timestamp\"] = rec_dict[\"timestamp\"].isoformat()\n            recommendations_data.append(rec_dict)\n        \n        # Create output directory if it doesn't exist\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        # Write to JSON file\n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(recommendations_data, f, indent=4)\n\n    def _export_to_csv(self, recommendations: List[ExplorationRecommendation], output_path: str) -> None:\n        \"\"\"Export recommendations to CSV file\"\"\"\n        # Convert recommendations to flat dictionary format\n        flat_data = []\n        for rec in recommendations:\n            flat_rec = {\n                \"recommendation_id\": rec.recommendation_id,\n                \"category\": rec.category,\n                \"priority\": rec.priority,\n                \"confidence\": rec.confidence,\n                \"description\": rec.description,\n                \"timestamp\": rec.timestamp.isoformat()\n            }\n            \n            # Add actions as comma-separated string\n            flat_rec[\"actions\"] = \"|\".join(rec.actions)\n            \n            # Add impact metrics\n            for metric, value in rec.expected_impact.items():\n                flat_rec[f\"impact_{metric}\"] = value\n            \n            # Add supporting data\n            for key, value in rec.supporting_data.items():\n                if isinstance(value, (int, float, str)):\n                    flat_rec[f\"supporting_{key}\"] = value\n            \n            flat_data.append(flat_rec)\n        \n        # Create output directory if it doesn't exist\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        # Write to CSV file\n        if flat_data:\n            with open(output_path, 'w', newline='', encoding='utf-8') as f:\n                writer = csv.DictWriter(f, fieldnames=flat_data[0].keys())\n                writer.writeheader()\n                writer.writerows(flat_data)\n\n    def import_recommendations(self, input_path: str, format: str = \"json\") -> List[ExplorationRecommendation]:\n        \"\"\"\n        Import recommendations from file\n        \n        Args:\n            input_path: Path to the file to import\n            format: Import format (\"json\" or \"csv\")\n            \n        Returns:\n            List of imported recommendations\n        \"\"\"\n        if format == \"json\":\n            return self._import_from_json(input_path)\n        elif format == \"csv\":\n            return self._import_from_csv(input_path)\n        else:\n            raise ValueError(f\"Unsupported import format: {format}\")\n\n    def _import_from_json(self, input_path: str) -> List[ExplorationRecommendation]:\n        \"\"\"Import recommendations from JSON file\"\"\"\n        with open(input_path, 'r', encoding='utf-8') as f:\n            recommendations_data = json.load(f)\n        \n        recommendations = []\n        for rec_dict in recommendations_data:\n            # Convert timestamp string back to datetime\n            rec_dict[\"timestamp\"] = datetime.fromisoformat(rec_dict[\"timestamp\"])\n            recommendations.append(ExplorationRecommendation(**rec_dict))\n        \n        return recommendations\n\n    def _import_from_csv(self, input_path: str) -> List[ExplorationRecommendation]:\n        \"\"\"Import recommendations from CSV file\"\"\"\n        recommendations = []\n        \n        with open(input_path, 'r', newline='', encoding='utf-8') as f:\n            reader = csv.DictReader(f)\n            \n            for row in reader:\n                # Convert flat CSV format back to nested structure\n                rec_dict = {\n                    \"recommendation_id\": row[\"recommendation_id\"],\n                    \"category\": row[\"category\"],\n                    \"priority\": float(row[\"priority\"]),\n                    \"confidence\": float(row[\"confidence\"]),\n                    \"description\": row[\"description\"],\n                    \"timestamp\": datetime.fromisoformat(row[\"timestamp\"]),\n                    \"actions\": row[\"actions\"].split(\"|\") if row[\"actions\"] else [],\n                    \"expected_impact\": {},\n                    \"supporting_data\": {}\n                }\n                \n                # Extract impact metrics\n                for key in row:\n                    if key.startswith(\"impact_\"):\n                        metric = key.replace(\"impact_\", \"\")\n                        rec_dict[\"expected_impact\"][metric] = float(row[key])\n                \n                # Extract supporting data\n                for key in row:\n                    if key.startswith(\"supporting_\"):\n                        data_key = key.replace(\"supporting_\", \"\")\n                        value = row[key]\n                        # Try to convert to number if possible\n                        try:\n                            value = float(value)\n                        except ValueError:\n                            pass\n                        rec_dict[\"supporting_data\"][data_key] = value\n                \n                recommendations.append(ExplorationRecommendation(**rec_dict))\n        \n        return recommendations\n\n    def export_model_data(self, output_path: str) -> None:\n        \"\"\"\n        Export model data and parameters\n        \n        Args:\n            output_path: Path to save the model data\n        \"\"\"\n        model_data = {\n            'model_state': self.model.state_dict() if self.model else None,\n            'input_size': self.input_size,\n            'scaler_state': self.scaler.__getstate__() if self.scaler else None,\n            'feature_importance': self.feature_importance_model.__getstate__() if self.feature_importance_model else None\n        }\n        \n        # Create output directory if it doesn't exist\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        # Save model data\n        torch.save(model_data, output_path)\n\n    def import_model_data(self, input_path: str) -> None:\n        \"\"\"\n        Import model data and parameters\n        \n        Args:\n            input_path: Path to the model data file\n        \"\"\"\n        if not os.path.exists(input_path):\n            raise FileNotFoundError(f\"Model data file not found: {input_path}\")\n        \n        # Load model data\n        model_data = torch.load(input_path, map_location=self.device)\n        \n        # Initialize and load model\n        self.input_size = model_data['input_size']\n        self.model = RecommendationModel(self.input_size).to(self.device)\n        if model_data['model_state']:\n            self.model.load_state_dict(model_data['model_state'])\n        \n        # Initialize and load scaler\n        if model_data['scaler_state']:\n            self.scaler = StandardScaler()\n            self.scaler.__setstate__(model_data['scaler_state'])\n        \n        # Initialize and load feature importance model\n        if model_data['feature_importance']:\n            self.feature_importance_model = RandomForestRegressor()\n            self.feature_importance_model.__setstate__(model_data['feature_importance'])\n\n    def get_model_summary(self) -> Dict[str, Any]:\n        \"\"\"\n        Get a summary of the model's architecture and parameters\n        \n        Returns:\n            Dictionary containing model summary information\n        \"\"\"\n        if not self.model:\n            return {\"error\": \"Model not initialized\"}\n        \n        summary = {\n            \"architecture\": {\n                \"input_size\": self.input_size,\n                \"encoder_layers\": [],\n                \"recommendation_head_layers\": [],\n                \"impact_head_layers\": []\n            },\n            \"parameters\": {\n                \"total\": sum(p.numel() for p in self.model.parameters()),\n                \"trainable\": sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n            },\n            \"device\": str(self.device),\n            \"has_scaler\": self.scaler is not None,\n            \"has_feature_importance\": self.feature_importance_model is not None\n        }\n        \n        # Add layer information\n        for name, module in self.model.named_children():\n            if isinstance(module, nn.Sequential):\n                layer_info = []\n                for layer in module:\n                    layer_info.append({\n                        \"type\": layer.__class__.__name__,\n                        \"parameters\": sum(p.numel() for p in layer.parameters())\n                    })\n                summary[\"architecture\"][f\"{name}_layers\"] = layer_info\n        \n        return summary "}
{"type": "source_file", "path": "minesight/core/streaming/processor.py", "content": "\"\"\"\nReal-time data streaming processor module\n\"\"\"\nfrom typing import Dict, List, Any, Optional, Callable\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport asyncio\nfrom collections import deque\nimport json\nfrom pathlib import Path\nimport logging\n\nclass StreamProcessor:\n    \"\"\"Class for processing real-time data streams\"\"\"\n    \n    def __init__(self,\n                 buffer_size: int = 1000,\n                 processing_interval: float = 1.0,\n                 output_dir: str = \"stream_data\"):\n        \"\"\"\n        Initialize the stream processor\n        \n        Args:\n            buffer_size: Maximum number of records to keep in buffer\n            processing_interval: Interval between processing cycles in seconds\n            output_dir: Directory for saving processed data\n        \"\"\"\n        self.buffer_size = buffer_size\n        self.processing_interval = processing_interval\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Initialize buffers\n        self.data_buffer = deque(maxlen=buffer_size)\n        self.processed_data = []\n        \n        # Initialize processors\n        self.preprocessors = []\n        self.processors = []\n        self.postprocessors = []\n        \n        # Initialize state\n        self.is_running = False\n        self.current_batch_id = 0\n        \n        # Set up logging\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.INFO)\n        \n        # Add file handler\n        fh = logging.FileHandler(self.output_dir / \"stream_processor.log\")\n        fh.setLevel(logging.INFO)\n        self.logger.addHandler(fh)\n    \n    def add_preprocessor(self, func: Callable):\n        \"\"\"Add a preprocessing function\"\"\"\n        self.preprocessors.append(func)\n    \n    def add_processor(self, func: Callable):\n        \"\"\"Add a processing function\"\"\"\n        self.processors.append(func)\n    \n    def add_postprocessor(self, func: Callable):\n        \"\"\"Add a postprocessing function\"\"\"\n        self.postprocessors.append(func)\n    \n    async def start(self):\n        \"\"\"Start the stream processor\"\"\"\n        self.is_running = True\n        self.logger.info(\"Stream processor started\")\n        \n        while self.is_running:\n            try:\n                await self.process_batch()\n                await asyncio.sleep(self.processing_interval)\n            except Exception as e:\n                self.logger.error(f\"Error in processing cycle: {str(e)}\")\n    \n    def stop(self):\n        \"\"\"Stop the stream processor\"\"\"\n        self.is_running = False\n        self.logger.info(\"Stream processor stopped\")\n    \n    async def process_batch(self):\n        \"\"\"Process a batch of data\"\"\"\n        if not self.data_buffer:\n            return\n        \n        try:\n            # Get batch data\n            batch_data = list(self.data_buffer)\n            self.data_buffer.clear()\n            \n            # Preprocess data\n            for preprocessor in self.preprocessors:\n                batch_data = preprocessor(batch_data)\n            \n            # Process data\n            processed_data = batch_data\n            for processor in self.processors:\n                processed_data = processor(processed_data)\n            \n            # Postprocess data\n            for postprocessor in self.postprocessors:\n                processed_data = postprocessor(processed_data)\n            \n            # Save results\n            self.save_batch_results(processed_data)\n            \n            # Update state\n            self.processed_data.extend(processed_data)\n            self.current_batch_id += 1\n            \n            self.logger.info(f\"Processed batch {self.current_batch_id}\")\n            \n        except Exception as e:\n            self.logger.error(f\"Error processing batch {self.current_batch_id}: {str(e)}\")\n            raise\n    \n    def add_data(self, data: Dict[str, Any]):\n        \"\"\"\n        Add data to the processing buffer\n        \n        Args:\n            data: Dictionary containing data to process\n        \"\"\"\n        try:\n            # Add timestamp if not present\n            if \"timestamp\" not in data:\n                data[\"timestamp\"] = datetime.now().isoformat()\n            \n            # Add to buffer\n            self.data_buffer.append(data)\n            \n        except Exception as e:\n            self.logger.error(f\"Error adding data: {str(e)}\")\n            raise\n    \n    def get_latest_results(self, n: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the latest processed results\n        \n        Args:\n            n: Number of latest results to return\n            \n        Returns:\n            List of processed results\n        \"\"\"\n        return self.processed_data[-n:]\n    \n    def get_statistics(self) -> Dict[str, Any]:\n        \"\"\"\n        Get processing statistics\n        \n        Returns:\n            Dictionary with statistics\n        \"\"\"\n        return {\n            \"total_processed\": len(self.processed_data),\n            \"buffer_size\": len(self.data_buffer),\n            \"current_batch\": self.current_batch_id,\n            \"is_running\": self.is_running\n        }\n    \n    def save_batch_results(self, results: List[Dict[str, Any]]):\n        \"\"\"\n        Save batch processing results\n        \n        Args:\n            results: List of processed results\n        \"\"\"\n        try:\n            # Create batch directory\n            batch_dir = self.output_dir / f\"batch_{self.current_batch_id}\"\n            batch_dir.mkdir(exist_ok=True)\n            \n            # Save results\n            output_file = batch_dir / \"results.json\"\n            with open(output_file, \"w\") as f:\n                json.dump(results, f, indent=2)\n                \n        except Exception as e:\n            self.logger.error(f\"Error saving batch results: {str(e)}\")\n            raise\n    \n    def clear_old_data(self, max_age_hours: float = 24.0):\n        \"\"\"\n        Clear old processed data\n        \n        Args:\n            max_age_hours: Maximum age of data to keep in hours\n        \"\"\"\n        try:\n            if not self.processed_data:\n                return\n                \n            current_time = datetime.now()\n            self.processed_data = [\n                data for data in self.processed_data\n                if (current_time - datetime.fromisoformat(data[\"timestamp\"])).total_seconds() / 3600 <= max_age_hours\n            ]\n            \n        except Exception as e:\n            self.logger.error(f\"Error clearing old data: {str(e)}\")\n            raise\n\nclass DataStreamHandler:\n    \"\"\"Class for handling different types of data streams\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the stream handler\"\"\"\n        self.processors = {}\n        \n    def create_processor(self,\n                        stream_type: str,\n                        buffer_size: int = 1000,\n                        processing_interval: float = 1.0) -> StreamProcessor:\n        \"\"\"\n        Create a new stream processor\n        \n        Args:\n            stream_type: Type of data stream\n            buffer_size: Buffer size for the processor\n            processing_interval: Processing interval in seconds\n            \n        Returns:\n            New stream processor instance\n        \"\"\"\n        processor = StreamProcessor(\n            buffer_size=buffer_size,\n            processing_interval=processing_interval,\n            output_dir=f\"stream_data/{stream_type}\"\n        )\n        \n        # Add default processors based on stream type\n        self._add_default_processors(processor, stream_type)\n        \n        self.processors[stream_type] = processor\n        return processor\n    \n    def get_processor(self, stream_type: str) -> Optional[StreamProcessor]:\n        \"\"\"\n        Get an existing stream processor\n        \n        Args:\n            stream_type: Type of data stream\n            \n        Returns:\n            Stream processor instance if exists, None otherwise\n        \"\"\"\n        return self.processors.get(stream_type)\n    \n    def remove_processor(self, stream_type: str):\n        \"\"\"\n        Remove a stream processor\n        \n        Args:\n            stream_type: Type of data stream\n        \"\"\"\n        if stream_type in self.processors:\n            self.processors[stream_type].stop()\n            del self.processors[stream_type]\n    \n    def _add_default_processors(self, processor: StreamProcessor, stream_type: str):\n        \"\"\"Add default processors based on stream type\"\"\"\n        if stream_type == \"sensor_data\":\n            processor.add_preprocessor(self._preprocess_sensor_data)\n            processor.add_processor(self._process_sensor_data)\n            processor.add_postprocessor(self._postprocess_sensor_data)\n        elif stream_type == \"geological_data\":\n            processor.add_preprocessor(self._preprocess_geological_data)\n            processor.add_processor(self._process_geological_data)\n            processor.add_postprocessor(self._postprocess_geological_data)\n        elif stream_type == \"monitoring_data\":\n            processor.add_preprocessor(self._preprocess_monitoring_data)\n            processor.add_processor(self._process_monitoring_data)\n            processor.add_postprocessor(self._postprocess_monitoring_data)\n    \n    def _preprocess_sensor_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Preprocess sensor data\"\"\"\n        # TODO: Implement sensor data preprocessing\n        return data\n    \n    def _process_sensor_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Process sensor data\"\"\"\n        # TODO: Implement sensor data processing\n        return data\n    \n    def _postprocess_sensor_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Postprocess sensor data\"\"\"\n        # TODO: Implement sensor data postprocessing\n        return data\n    \n    def _preprocess_geological_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Preprocess geological data\"\"\"\n        # TODO: Implement geological data preprocessing\n        return data\n    \n    def _process_geological_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Process geological data\"\"\"\n        # TODO: Implement geological data processing\n        return data\n    \n    def _postprocess_geological_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Postprocess geological data\"\"\"\n        # TODO: Implement geological data postprocessing\n        return data\n    \n    def _preprocess_monitoring_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Preprocess monitoring data\"\"\"\n        # TODO: Implement monitoring data preprocessing\n        return data\n    \n    def _process_monitoring_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Process monitoring data\"\"\"\n        # TODO: Implement monitoring data processing\n        return data\n    \n    def _postprocess_monitoring_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Postprocess monitoring data\"\"\"\n        # TODO: Implement monitoring data postprocessing\n        return data "}
{"type": "source_file", "path": "minesight/core/planning/exploration_planner.py", "content": "\"\"\"\nExploration planning module for automated task planning and optimization\n\"\"\"\nfrom typing import Dict, List, Optional, Any\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nfrom scipy.optimize import linear_sum_assignment\nimport networkx as nx\n\n@dataclass\nclass ExplorationTask:\n    \"\"\"Exploration task definition\"\"\"\n    task_id: str\n    location: Dict[str, float]\n    task_type: str\n    priority: float\n    estimated_duration: float\n    required_resources: List[str]\n    dependencies: List[str] = None\n    status: str = \"pending\"\n\nclass ExplorationPlanner:\n    \"\"\"Class for planning and optimizing exploration activities\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the exploration planner\"\"\"\n        self.tasks = []\n        self.resources = {}\n        self.schedule = {}\n        \n    def generate_exploration_plan(self,\n                                prediction_results: Dict[str, Any],\n                                risk_assessment: Dict[str, Any],\n                                available_resources: Dict[str, Any],\n                                constraints: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Generate optimized exploration plan\n        \n        Args:\n            prediction_results: Mineral prediction results\n            risk_assessment: Risk assessment results\n            available_resources: Available exploration resources\n            constraints: Planning constraints\n            \n        Returns:\n            Optimized exploration plan\n        \"\"\"\n        # Generate tasks based on predictions and risks\n        self._generate_tasks(prediction_results, risk_assessment)\n        \n        # Allocate resources\n        self._allocate_resources(available_resources)\n        \n        # Create schedule considering dependencies\n        schedule = self._create_schedule(constraints)\n        \n        # Calculate costs and timeline\n        costs = self._calculate_costs()\n        timeline = self._generate_timeline()\n        \n        return {\n            \"tasks\": self.tasks,\n            \"schedule\": schedule,\n            \"resource_allocation\": self.resources,\n            \"costs\": costs,\n            \"timeline\": timeline\n        }\n    \n    def _generate_tasks(self,\n                       prediction_results: Dict[str, Any],\n                       risk_assessment: Dict[str, Any]):\n        \"\"\"Generate exploration tasks based on predictions and risks\"\"\"\n        tasks = []\n        \n        # Generate tasks for high-probability areas\n        for i, pred in enumerate(prediction_results.get(\"predictions\", [])):\n            if pred[\"probability\"] > 0.7:  # High probability threshold\n                task = ExplorationTask(\n                    task_id=f\"survey_{i}\",\n                    location=pred[\"location\"],\n                    task_type=\"detailed_survey\",\n                    priority=pred[\"probability\"] * (1 - risk_assessment.get(\"overall_risk\", 0)),\n                    estimated_duration=5.0,  # days\n                    required_resources=[\"survey_team\", \"equipment\"]\n                )\n                tasks.append(task)\n        \n        # Generate sampling tasks\n        for i, area in enumerate(prediction_results.get(\"high_potential_areas\", [])):\n            task = ExplorationTask(\n                task_id=f\"sampling_{i}\",\n                location=area[\"center\"],\n                task_type=\"sampling\",\n                priority=0.8,\n                estimated_duration=3.0,\n                required_resources=[\"sampling_team\", \"analysis_lab\"]\n            )\n            tasks.append(task)\n        \n        # Add drilling tasks for confirmed areas\n        for i, area in enumerate(prediction_results.get(\"confirmed_areas\", [])):\n            task = ExplorationTask(\n                task_id=f\"drilling_{i}\",\n                location=area[\"center\"],\n                task_type=\"drilling\",\n                priority=0.9,\n                estimated_duration=10.0,\n                required_resources=[\"drilling_team\", \"drilling_equipment\"]\n            )\n            tasks.append(task)\n        \n        self.tasks = sorted(tasks, key=lambda x: x.priority, reverse=True)\n    \n    def _allocate_resources(self, available_resources: Dict[str, Any]):\n        \"\"\"Allocate resources to tasks using Hungarian algorithm\"\"\"\n        # Create cost matrix\n        cost_matrix = np.zeros((len(self.tasks), len(available_resources)))\n        \n        for i, task in enumerate(self.tasks):\n            for j, (resource, details) in enumerate(available_resources.items()):\n                if resource in task.required_resources:\n                    # Lower cost means better allocation\n                    cost_matrix[i, j] = 1 / (task.priority * details.get(\"efficiency\", 1))\n                else:\n                    cost_matrix[i, j] = np.inf\n        \n        # Solve assignment problem\n        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n        \n        # Create resource allocation\n        self.resources = {\n            task.task_id: [\n                list(available_resources.keys())[j]\n                for i, j in zip(row_ind, col_ind)\n                if i == k\n            ]\n            for k, task in enumerate(self.tasks)\n        }\n    \n    def _create_schedule(self, constraints: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create optimized schedule considering dependencies\"\"\"\n        # Create dependency graph\n        G = nx.DiGraph()\n        \n        for task in self.tasks:\n            G.add_node(task.task_id, task=task)\n            if task.dependencies:\n                for dep in task.dependencies:\n                    G.add_edge(dep, task.task_id)\n        \n        # Check for cycles\n        if not nx.is_directed_acyclic_graph(G):\n            raise ValueError(\"Task dependencies contain cycles\")\n        \n        # Get topological sort\n        task_order = list(nx.topological_sort(G))\n        \n        # Create schedule\n        schedule = {}\n        current_date = datetime.now()\n        \n        for task_id in task_order:\n            task = next(t for t in self.tasks if t.task_id == task_id)\n            \n            # Find earliest start date considering dependencies\n            if task.dependencies:\n                dep_end_dates = [\n                    schedule[dep][\"end_date\"]\n                    for dep in task.dependencies\n                ]\n                current_date = max(dep_end_dates)\n            \n            # Add task to schedule\n            schedule[task_id] = {\n                \"start_date\": current_date,\n                \"end_date\": current_date + timedelta(days=task.estimated_duration),\n                \"assigned_resources\": self.resources.get(task_id, [])\n            }\n            \n            current_date += timedelta(days=task.estimated_duration)\n        \n        return schedule\n    \n    def _calculate_costs(self) -> Dict[str, float]:\n        \"\"\"Calculate estimated costs for the exploration plan\"\"\"\n        # Example cost rates\n        cost_rates = {\n            \"survey_team\": 1000.0,  # per day\n            \"sampling_team\": 800.0,\n            \"drilling_team\": 5000.0,\n            \"equipment\": 500.0,\n            \"analysis_lab\": 2000.0,\n            \"drilling_equipment\": 3000.0\n        }\n        \n        costs = {\n            \"labor_cost\": 0.0,\n            \"equipment_cost\": 0.0,\n            \"analysis_cost\": 0.0,\n            \"total_cost\": 0.0\n        }\n        \n        for task in self.tasks:\n            duration = task.estimated_duration\n            for resource in self.resources.get(task.task_id, []):\n                cost = cost_rates.get(resource, 0) * duration\n                \n                if \"team\" in resource:\n                    costs[\"labor_cost\"] += cost\n                elif \"equipment\" in resource:\n                    costs[\"equipment_cost\"] += cost\n                elif \"lab\" in resource:\n                    costs[\"analysis_cost\"] += cost\n                    \n        costs[\"total_cost\"] = sum(cost for cost in costs.values())\n        \n        return costs\n    \n    def _generate_timeline(self) -> List[Dict[str, Any]]:\n        \"\"\"Generate timeline of exploration activities\"\"\"\n        timeline = []\n        \n        for task in self.tasks:\n            schedule_info = self.schedule.get(task.task_id, {})\n            timeline_entry = {\n                \"task_id\": task.task_id,\n                \"task_type\": task.task_type,\n                \"location\": task.location,\n                \"start_date\": schedule_info.get(\"start_date\"),\n                \"end_date\": schedule_info.get(\"end_date\"),\n                \"resources\": schedule_info.get(\"assigned_resources\", []),\n                \"status\": task.status\n            }\n            timeline.append(timeline_entry)\n        \n        return sorted(timeline, key=lambda x: x[\"start_date\"]) "}
{"type": "source_file", "path": "minesight/visualization/map_visualizer.py", "content": "\"\"\"\nMap visualization module for mineral exploration data\n\"\"\"\nimport folium\nfrom folium import plugins\nimport numpy as np\nfrom typing import List, Dict, Optional, Any\nimport pandas as pd\nfrom pathlib import Path\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom datetime import datetime\n\nclass MapVisualizer:\n    \"\"\"Class for creating interactive maps and 3D visualizations\"\"\"\n    \n    def __init__(self, output_dir: str = \"visualizations\"):\n        \"\"\"\n        Initialize visualizer\n        \n        Args:\n            output_dir: Directory for saving visualizations\n        \"\"\"\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n    def create_exploration_map(self,\n                             center_lat: float,\n                             center_lon: float,\n                             deposits: pd.DataFrame,\n                             geological_features: pd.DataFrame,\n                             predictions: Optional[List[Dict]] = None,\n                             radius_km: float = 10.0) -> str:\n        \"\"\"\n        Create interactive map with deposits and features\n        \n        Args:\n            center_lat: Center latitude\n            center_lon: Center longitude\n            deposits: DataFrame of mineral deposits\n            geological_features: DataFrame of geological features\n            predictions: List of prediction results\n            radius_km: Map radius in kilometers\n            \n        Returns:\n            Path to saved HTML file\n        \"\"\"\n        # Create base map\n        m = folium.Map(\n            location=[center_lat, center_lon],\n            zoom_start=12,\n            tiles='cartodbpositron'\n        )\n        \n        # Add deposits\n        if not deposits.empty:\n            deposit_group = folium.FeatureGroup(name=\"Mineral Deposits\")\n            \n            for _, deposit in deposits.iterrows():\n                color = 'green' if deposit['is_confirmed'] else 'orange'\n                \n                popup_html = f\"\"\"\n                    <b>Mineral Deposit</b><br>\n                    Type: {deposit['mineral_type']}<br>\n                    Status: {'Confirmed' if deposit['is_confirmed'] else 'Unconfirmed'}<br>\n                \"\"\"\n                \n                if 'grade' in deposit:\n                    popup_html += f\"Grade: {deposit['grade']}<br>\"\n                if 'size' in deposit:\n                    popup_html += f\"Size: {deposit['size']}<br>\"\n                \n                folium.CircleMarker(\n                    location=[deposit['latitude'], deposit['longitude']],\n                    radius=8,\n                    color=color,\n                    fill=True,\n                    popup=folium.Popup(popup_html, max_width=300)\n                ).add_to(deposit_group)\n            \n            deposit_group.add_to(m)\n        \n        # Add geological features\n        if not geological_features.empty:\n            feature_group = folium.FeatureGroup(name=\"Geological Features\")\n            \n            for _, feature in geological_features.iterrows():\n                color = {\n                    'fault': 'red',\n                    'fold': 'blue',\n                    'intrusion': 'purple'\n                }.get(feature['feature_type'], 'gray')\n                \n                popup_html = f\"\"\"\n                    <b>Geological Feature</b><br>\n                    Type: {feature['feature_type']}<br>\n                \"\"\"\n                \n                if 'age' in feature:\n                    popup_html += f\"Age: {feature['age']}<br>\"\n                if 'rock_type' in feature:\n                    popup_html += f\"Rock Type: {feature['rock_type']}<br>\"\n                \n                folium.CircleMarker(\n                    location=[feature['latitude'], feature['longitude']],\n                    radius=6,\n                    color=color,\n                    fill=True,\n                    popup=folium.Popup(popup_html, max_width=300)\n                ).add_to(feature_group)\n            \n            feature_group.add_to(m)\n        \n        # Add predictions if available\n        if predictions:\n            prediction_group = folium.FeatureGroup(name=\"Predictions\")\n            \n            # Prepare data for heatmap\n            heat_data = []\n            for pred in predictions:\n                loc = pred['location']\n                heat_data.append([\n                    loc['latitude'],\n                    loc['longitude'],\n                    pred['probability']\n                ])\n            \n            # Add heatmap\n            plugins.HeatMap(\n                heat_data,\n                min_opacity=0.3,\n                max_val=1.0,\n                radius=15,\n                blur=10,\n                gradient={\n                    0.4: 'blue',\n                    0.6: 'yellow',\n                    0.8: 'orange',\n                    1.0: 'red'\n                }\n            ).add_to(prediction_group)\n            \n            prediction_group.add_to(m)\n        \n        # Add search radius circle\n        folium.Circle(\n            location=[center_lat, center_lon],\n            radius=radius_km * 1000,  # Convert to meters\n            color='gray',\n            fill=False,\n            dash_array='5, 5'\n        ).add_to(m)\n        \n        # Add layer control\n        folium.LayerControl().add_to(m)\n        \n        # Save map\n        output_file = self.output_dir / f\"exploration_map_{center_lat}_{center_lon}.html\"\n        m.save(str(output_file))\n        \n        return str(output_file)\n    \n    def create_prediction_heatmap(self,\n                                predictions: List[Dict],\n                                center_lat: float,\n                                center_lon: float) -> str:\n        \"\"\"\n        Create heatmap of prediction probabilities\n        \n        Args:\n            predictions: List of prediction results\n            center_lat: Center latitude\n            center_lon: Center longitude\n            \n        Returns:\n            Path to saved HTML file\n        \"\"\"\n        # Create base map\n        m = folium.Map(\n            location=[center_lat, center_lon],\n            zoom_start=12,\n            tiles='cartodbpositron'\n        )\n        \n        # Prepare heatmap data\n        heat_data = []\n        for pred in predictions:\n            loc = pred['location']\n            heat_data.append([\n                loc['latitude'],\n                loc['longitude'],\n                pred['probability']\n            ])\n        \n        # Add heatmap\n        plugins.HeatMap(\n            heat_data,\n            min_opacity=0.3,\n            max_val=1.0,\n            radius=15,\n            blur=10,\n            gradient={\n                0.4: 'blue',\n                0.6: 'yellow',\n                0.8: 'orange',\n                1.0: 'red'\n            }\n        ).add_to(m)\n        \n        # Save map\n        output_file = self.output_dir / f\"prediction_heatmap_{center_lat}_{center_lon}.html\"\n        m.save(str(output_file))\n        \n        return str(output_file)\n    \n    def create_feature_distribution_map(self,\n                                     geological_features: pd.DataFrame,\n                                     feature_type: Optional[str] = None) -> str:\n        \"\"\"\n        Create map showing distribution of geological features\n        \n        Args:\n            geological_features: DataFrame of geological features\n            feature_type: Optional filter for specific feature type\n            \n        Returns:\n            Path to saved HTML file\n        \"\"\"\n        if geological_features.empty:\n            raise ValueError(\"No geological features data provided\")\n            \n        # Filter features if type specified\n        if feature_type:\n            features = geological_features[\n                geological_features['feature_type'] == feature_type\n            ]\n        else:\n            features = geological_features\n        \n        # Calculate center\n        center_lat = features['latitude'].mean()\n        center_lon = features['longitude'].mean()\n        \n        # Create base map\n        m = folium.Map(\n            location=[center_lat, center_lon],\n            zoom_start=12,\n            tiles='cartodbpositron'\n        )\n        \n        # Add features\n        for _, feature in features.iterrows():\n            color = {\n                'fault': 'red',\n                'fold': 'blue',\n                'intrusion': 'purple'\n            }.get(feature['feature_type'], 'gray')\n            \n            popup_html = f\"\"\"\n                <b>Geological Feature</b><br>\n                Type: {feature['feature_type']}<br>\n            \"\"\"\n            \n            if 'age' in feature:\n                popup_html += f\"Age: {feature['age']}<br>\"\n            if 'rock_type' in feature:\n                popup_html += f\"Rock Type: {feature['rock_type']}<br>\"\n            \n            folium.CircleMarker(\n                location=[feature['latitude'], feature['longitude']],\n                radius=6,\n                color=color,\n                fill=True,\n                popup=folium.Popup(popup_html, max_width=300)\n            ).add_to(m)\n        \n        # Save map\n        output_file = self.output_dir / f\"feature_distribution_{feature_type or 'all'}.html\"\n        m.save(str(output_file))\n        \n        return str(output_file)\n    \n    def create_3d_visualization(self,\n                              deposits: pd.DataFrame,\n                              geological_features: pd.DataFrame,\n                              dem_data: Optional[np.ndarray] = None,\n                              predictions: Optional[List[Dict[str, Any]]] = None) -> str:\n        \"\"\"\n        Create interactive 3D visualization\n        \n        Args:\n            deposits: DataFrame of mineral deposits\n            geological_features: DataFrame of geological features\n            dem_data: Optional Digital Elevation Model data\n            predictions: Optional prediction results\n            \n        Returns:\n            Path to generated visualization file\n        \"\"\"\n        # Create figure\n        fig = go.Figure()\n        \n        # Add terrain surface if DEM data is available\n        if dem_data is not None:\n            self._add_terrain_surface(fig, dem_data)\n        \n        # Add deposits\n        if not deposits.empty:\n            self._add_deposits_3d(fig, deposits)\n        \n        # Add geological features\n        if not geological_features.empty:\n            self._add_features_3d(fig, geological_features)\n        \n        # Add predictions if available\n        if predictions:\n            self._add_predictions_3d(fig, predictions)\n        \n        # Update layout\n        fig.update_layout(\n            scene=dict(\n                aspectmode='data',\n                camera=dict(\n                    up=dict(x=0, y=0, z=1),\n                    center=dict(x=0, y=0, z=0),\n                    eye=dict(x=1.5, y=1.5, z=1.5)\n                )\n            ),\n            title=\"3D Mineral Exploration Visualization\",\n            showlegend=True,\n            template=\"plotly_dark\"\n        )\n        \n        # Save visualization\n        output_path = self.output_dir / f\"3d_viz_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n        fig.write_html(str(output_path))\n        \n        return str(output_path)\n    \n    def create_3d_analysis(self,\n                          analysis_results: Dict[str, Any],\n                          dem_data: Optional[np.ndarray] = None) -> str:\n        \"\"\"\n        Create 3D visualization of analysis results\n        \n        Args:\n            analysis_results: Dictionary containing analysis results\n            dem_data: Optional Digital Elevation Model data\n            \n        Returns:\n            Path to generated visualization file\n        \"\"\"\n        # Create figure with subplots\n        fig = make_subplots(\n            rows=2, cols=2,\n            specs=[[{'type': 'scene'}, {'type': 'scene'}],\n                  [{'type': 'scene'}, {'type': 'scene'}]],\n            subplot_titles=(\n                '3D Feature Distribution',\n                'Pattern Analysis',\n                'Anomaly Detection',\n                'Risk Assessment'\n            )\n        )\n        \n        # Add feature distribution\n        if \"features\" in analysis_results:\n            self._add_feature_distribution_3d(\n                fig,\n                analysis_results[\"features\"],\n                row=1, col=1\n            )\n        \n        # Add pattern analysis\n        if \"patterns\" in analysis_results:\n            self._add_pattern_analysis_3d(\n                fig,\n                analysis_results[\"patterns\"],\n                row=1, col=2\n            )\n        \n        # Add anomaly detection\n        if \"anomalies\" in analysis_results:\n            self._add_anomalies_3d(\n                fig,\n                analysis_results[\"anomalies\"],\n                row=2, col=1\n            )\n        \n        # Add risk assessment\n        if \"risks\" in analysis_results:\n            self._add_risk_visualization_3d(\n                fig,\n                analysis_results[\"risks\"],\n                row=2, col=2\n            )\n        \n        # Update layout\n        fig.update_layout(\n            height=1200,\n            width=1600,\n            title_text=\"3D Analysis Visualization\",\n            showlegend=True,\n            template=\"plotly_dark\"\n        )\n        \n        # Save visualization\n        output_path = self.output_dir / f\"3d_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n        fig.write_html(str(output_path))\n        \n        return str(output_path)\n    \n    def create_3d_time_series(self,\n                             time_data: Dict[str, Any],\n                             dem_data: Optional[np.ndarray] = None) -> str:\n        \"\"\"\n        Create 3D visualization of time series data\n        \n        Args:\n            time_data: Dictionary containing time series data\n            dem_data: Optional Digital Elevation Model data\n            \n        Returns:\n            Path to generated visualization file\n        \"\"\"\n        # Create figure\n        fig = go.Figure()\n        \n        # Add terrain surface if DEM data is available\n        if dem_data is not None:\n            self._add_terrain_surface(fig, dem_data)\n        \n        # Add time series data\n        if \"discovery_trends\" in time_data:\n            self._add_discovery_trends_3d(fig, time_data[\"discovery_trends\"])\n        \n        if \"exploration_intensity\" in time_data:\n            self._add_exploration_intensity_3d(\n                fig,\n                time_data[\"exploration_intensity\"]\n            )\n        \n        # Update layout\n        fig.update_layout(\n            scene=dict(\n                aspectmode='data',\n                camera=dict(\n                    up=dict(x=0, y=0, z=1),\n                    center=dict(x=0, y=0, z=0),\n                    eye=dict(x=1.5, y=1.5, z=1.5)\n                )\n            ),\n            title=\"3D Time Series Visualization\",\n            showlegend=True,\n            template=\"plotly_dark\"\n        )\n        \n        # Save visualization\n        output_path = self.output_dir / f\"3d_timeseries_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n        fig.write_html(str(output_path))\n        \n        return str(output_path)\n    \n    def _add_terrain_surface(self, fig: go.Figure, dem_data: np.ndarray):\n        \"\"\"Add terrain surface to 3D visualization\"\"\"\n        # Create meshgrid for surface\n        x = np.linspace(0, dem_data.shape[0]-1, dem_data.shape[0])\n        y = np.linspace(0, dem_data.shape[1]-1, dem_data.shape[1])\n        X, Y = np.meshgrid(x, y)\n        \n        # Add surface\n        fig.add_trace(\n            go.Surface(\n                x=X,\n                y=Y,\n                z=dem_data,\n                colorscale=\"Earth\",\n                opacity=0.8,\n                name=\"Terrain\"\n            )\n        )\n    \n    def _add_deposits_3d(self, fig: go.Figure, deposits: pd.DataFrame):\n        \"\"\"Add deposits to 3D visualization\"\"\"\n        fig.add_trace(\n            go.Scatter3d(\n                x=deposits[\"longitude\"],\n                y=deposits[\"latitude\"],\n                z=deposits.get(\"elevation\", [0] * len(deposits)),\n                mode=\"markers\",\n                marker=dict(\n                    size=8,\n                    color=deposits[\"is_confirmed\"].map({True: \"green\", False: \"yellow\"}),\n                    symbol=\"diamond\"\n                ),\n                text=deposits[\"mineral_type\"],\n                name=\"Mineral Deposits\"\n            )\n        )\n    \n    def _add_features_3d(self, fig: go.Figure, features: pd.DataFrame):\n        \"\"\"Add geological features to 3D visualization\"\"\"\n        for feature_type in features[\"feature_type\"].unique():\n            type_features = features[features[\"feature_type\"] == feature_type]\n            \n            fig.add_trace(\n                go.Scatter3d(\n                    x=type_features[\"longitude\"],\n                    y=type_features[\"latitude\"],\n                    z=type_features.get(\"elevation\", [0] * len(type_features)),\n                    mode=\"markers\",\n                    marker=dict(\n                        size=6,\n                        symbol=\"circle\"\n                    ),\n                    name=f\"Feature: {feature_type}\"\n                )\n            )\n    \n    def _add_predictions_3d(self,\n                           fig: go.Figure,\n                           predictions: List[Dict[str, Any]]):\n        \"\"\"Add predictions to 3D visualization\"\"\"\n        # Extract prediction data\n        lats = [p[\"location\"][\"latitude\"] for p in predictions]\n        lons = [p[\"location\"][\"longitude\"] for p in predictions]\n        probs = [p[\"probability\"] for p in predictions]\n        \n        # Add prediction surface\n        fig.add_trace(\n            go.Scatter3d(\n                x=lons,\n                y=lats,\n                z=[0] * len(predictions),  # Place at ground level\n                mode=\"markers\",\n                marker=dict(\n                    size=6,\n                    color=probs,\n                    colorscale=\"Viridis\",\n                    showscale=True\n                ),\n                name=\"Predictions\"\n            )\n        )\n    \n    def _add_feature_distribution_3d(self,\n                                   fig: go.Figure,\n                                   features: Dict[str, Any],\n                                   row: int,\n                                   col: int):\n        \"\"\"Add 3D feature distribution visualization\"\"\"\n        # TODO: Implement feature distribution visualization\n        pass\n    \n    def _add_pattern_analysis_3d(self,\n                                fig: go.Figure,\n                                patterns: Dict[str, Any],\n                                row: int,\n                                col: int):\n        \"\"\"Add 3D pattern analysis visualization\"\"\"\n        # TODO: Implement pattern analysis visualization\n        pass\n    \n    def _add_anomalies_3d(self,\n                         fig: go.Figure,\n                         anomalies: Dict[str, Any],\n                         row: int,\n                         col: int):\n        \"\"\"Add 3D anomaly visualization\"\"\"\n        # TODO: Implement anomaly visualization\n        pass\n    \n    def _add_risk_visualization_3d(self,\n                                 fig: go.Figure,\n                                 risks: Dict[str, Any],\n                                 row: int,\n                                 col: int):\n        \"\"\"Add 3D risk visualization\"\"\"\n        # TODO: Implement risk visualization\n        pass\n    \n    def _add_discovery_trends_3d(self,\n                                fig: go.Figure,\n                                trends: Dict[str, Any]):\n        \"\"\"Add 3D discovery trends visualization\"\"\"\n        # TODO: Implement discovery trends visualization\n        pass\n    \n    def _add_exploration_intensity_3d(self,\n                                    fig: go.Figure,\n                                    intensity: Dict[str, Any]):\n        \"\"\"Add 3D exploration intensity visualization\"\"\"\n        # TODO: Implement exploration intensity visualization\n        pass "}
{"type": "source_file", "path": "minesight/core/recommendation/recommender.py", "content": "\"\"\"\nIntelligent recommendation system for mineral exploration\n\"\"\"\nfrom typing import Dict, List, Any, Optional\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom dataclasses import dataclass\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\n\n@dataclass\nclass RecommendationScore:\n    \"\"\"Recommendation score definition\"\"\"\n    score: float\n    confidence: float\n    factors: Dict[str, float]\n    supporting_evidence: List[str]\n\nclass RecommendationEngine:\n    \"\"\"Class for generating intelligent recommendations\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the recommendation engine\"\"\"\n        self.scaler = StandardScaler()\n        self.feature_weights = {\n            \"mineral_probability\": 0.3,\n            \"risk_score\": 0.2,\n            \"resource_efficiency\": 0.15,\n            \"cost_effectiveness\": 0.15,\n            \"exploration_potential\": 0.2\n        }\n    \n    def generate_recommendations(self,\n                               prediction_results: Dict[str, Any],\n                               risk_assessment: Dict[str, Any],\n                               monitoring_data: Dict[str, Any],\n                               resource_data: Dict[str, Any],\n                               historical_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Generate comprehensive recommendations\n        \n        Args:\n            prediction_results: Results from mineral prediction\n            risk_assessment: Risk assessment data\n            monitoring_data: Real-time monitoring data\n            resource_data: Available resource data\n            historical_data: Optional historical exploration data\n            \n        Returns:\n            Dictionary containing recommendations\n        \"\"\"\n        # Generate different types of recommendations\n        exploration_recs = self._recommend_exploration_targets(\n            prediction_results,\n            risk_assessment\n        )\n        \n        resource_recs = self._recommend_resource_allocation(\n            resource_data,\n            monitoring_data\n        )\n        \n        strategy_recs = self._recommend_exploration_strategy(\n            prediction_results,\n            risk_assessment,\n            historical_data\n        )\n        \n        timing_recs = self._recommend_optimal_timing(\n            monitoring_data,\n            resource_data\n        )\n        \n        # Combine and prioritize recommendations\n        all_recommendations = {\n            \"exploration_targets\": exploration_recs,\n            \"resource_allocation\": resource_recs,\n            \"exploration_strategy\": strategy_recs,\n            \"optimal_timing\": timing_recs,\n            \"summary\": self._generate_summary(\n                exploration_recs,\n                resource_recs,\n                strategy_recs,\n                timing_recs\n            )\n        }\n        \n        return all_recommendations\n    \n    def _recommend_exploration_targets(self,\n                                    prediction_results: Dict[str, Any],\n                                    risk_assessment: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate recommendations for exploration targets\"\"\"\n        recommendations = []\n        \n        # Analyze predictions\n        for pred in prediction_results.get(\"predictions\", []):\n            location = pred.get(\"location\", {})\n            probability = pred.get(\"probability\", 0)\n            confidence = pred.get(\"confidence\", 0)\n            \n            # Calculate risk score for location\n            risk_score = self._calculate_location_risk(\n                location,\n                risk_assessment\n            )\n            \n            # Calculate overall score\n            score = self._calculate_target_score(\n                probability,\n                confidence,\n                risk_score\n            )\n            \n            if score > 0.7:  # High potential threshold\n                recommendation = {\n                    \"type\": \"exploration_target\",\n                    \"location\": location,\n                    \"score\": RecommendationScore(\n                        score=score,\n                        confidence=confidence,\n                        factors={\n                            \"mineral_probability\": probability,\n                            \"risk_score\": risk_score\n                        },\n                        supporting_evidence=[\n                            f\"High mineral probability: {probability:.2f}\",\n                            f\"Confidence level: {confidence:.2f}\",\n                            f\"Acceptable risk score: {risk_score:.2f}\"\n                        ]\n                    ),\n                    \"priority\": \"high\" if score > 0.8 else \"medium\",\n                    \"suggested_actions\": self._generate_target_actions(\n                        probability,\n                        risk_score\n                    )\n                }\n                recommendations.append(recommendation)\n        \n        return sorted(\n            recommendations,\n            key=lambda x: x[\"score\"].score,\n            reverse=True\n        )\n    \n    def _recommend_resource_allocation(self,\n                                    resource_data: Dict[str, Any],\n                                    monitoring_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate recommendations for resource allocation\"\"\"\n        recommendations = []\n        \n        # Analyze resource utilization\n        for resource_type, details in resource_data.items():\n            utilization = details.get(\"utilization\", 0)\n            efficiency = details.get(\"efficiency\", 0)\n            \n            # Get current activities using this resource\n            current_activities = self._get_resource_activities(\n                resource_type,\n                monitoring_data\n            )\n            \n            # Calculate optimal allocation\n            optimal_allocation = self._calculate_optimal_allocation(\n                utilization,\n                efficiency,\n                current_activities\n            )\n            \n            if optimal_allocation[\"needs_adjustment\"]:\n                recommendation = {\n                    \"type\": \"resource_allocation\",\n                    \"resource_type\": resource_type,\n                    \"score\": RecommendationScore(\n                        score=optimal_allocation[\"priority_score\"],\n                        confidence=optimal_allocation[\"confidence\"],\n                        factors={\n                            \"current_utilization\": utilization,\n                            \"efficiency\": efficiency\n                        },\n                        supporting_evidence=[\n                            f\"Current utilization: {utilization:.2f}\",\n                            f\"Resource efficiency: {efficiency:.2f}\",\n                            optimal_allocation[\"reason\"]\n                        ]\n                    ),\n                    \"suggested_changes\": optimal_allocation[\"suggestions\"],\n                    \"priority\": optimal_allocation[\"priority\"]\n                }\n                recommendations.append(recommendation)\n        \n        return sorted(\n            recommendations,\n            key=lambda x: x[\"score\"].score,\n            reverse=True\n        )\n    \n    def _recommend_exploration_strategy(self,\n                                     prediction_results: Dict[str, Any],\n                                     risk_assessment: Dict[str, Any],\n                                     historical_data: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Generate recommendations for exploration strategy\"\"\"\n        recommendations = []\n        \n        # Analyze current exploration effectiveness\n        effectiveness = self._analyze_exploration_effectiveness(\n            prediction_results,\n            historical_data\n        )\n        \n        # Analyze risk patterns\n        risk_patterns = self._analyze_risk_patterns(risk_assessment)\n        \n        # Generate strategy recommendations\n        strategies = self._generate_strategies(\n            effectiveness,\n            risk_patterns\n        )\n        \n        for strategy in strategies:\n            recommendation = {\n                \"type\": \"exploration_strategy\",\n                \"strategy_name\": strategy[\"name\"],\n                \"score\": RecommendationScore(\n                    score=strategy[\"score\"],\n                    confidence=strategy[\"confidence\"],\n                    factors=strategy[\"factors\"],\n                    supporting_evidence=strategy[\"evidence\"]\n                ),\n                \"description\": strategy[\"description\"],\n                \"implementation_steps\": strategy[\"steps\"],\n                \"priority\": strategy[\"priority\"]\n            }\n            recommendations.append(recommendation)\n        \n        return sorted(\n            recommendations,\n            key=lambda x: x[\"score\"].score,\n            reverse=True\n        )\n    \n    def _recommend_optimal_timing(self,\n                                monitoring_data: Dict[str, Any],\n                                resource_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate recommendations for optimal timing\"\"\"\n        recommendations = []\n        \n        # Analyze current conditions\n        conditions = self._analyze_current_conditions(\n            monitoring_data,\n            resource_data\n        )\n        \n        # Generate timing recommendations\n        for activity_type, timing in conditions[\"optimal_timing\"].items():\n            if timing[\"should_recommend\"]:\n                recommendation = {\n                    \"type\": \"optimal_timing\",\n                    \"activity_type\": activity_type,\n                    \"score\": RecommendationScore(\n                        score=timing[\"score\"],\n                        confidence=timing[\"confidence\"],\n                        factors=timing[\"factors\"],\n                        supporting_evidence=timing[\"evidence\"]\n                    ),\n                    \"suggested_window\": timing[\"window\"],\n                    \"rationale\": timing[\"rationale\"],\n                    \"priority\": timing[\"priority\"]\n                }\n                recommendations.append(recommendation)\n        \n        return sorted(\n            recommendations,\n            key=lambda x: x[\"score\"].score,\n            reverse=True\n        )\n    \n    def _calculate_location_risk(self,\n                               location: Dict[str, float],\n                               risk_assessment: Dict[str, Any]) -> float:\n        \"\"\"Calculate risk score for a location\"\"\"\n        # Extract relevant risk factors\n        geological_risk = risk_assessment.get(\"geological_risk\", 0.5)\n        environmental_risk = risk_assessment.get(\"environmental_risk\", 0.5)\n        technical_risk = risk_assessment.get(\"technical_risk\", 0.5)\n        \n        # Calculate weighted risk score\n        risk_score = (\n            geological_risk * 0.4 +\n            environmental_risk * 0.3 +\n            technical_risk * 0.3\n        )\n        \n        return risk_score\n    \n    def _calculate_target_score(self,\n                              probability: float,\n                              confidence: float,\n                              risk_score: float) -> float:\n        \"\"\"Calculate overall target score\"\"\"\n        # Combine factors with weights\n        score = (\n            probability * self.feature_weights[\"mineral_probability\"] +\n            (1 - risk_score) * self.feature_weights[\"risk_score\"] +\n            confidence * 0.2\n        )\n        \n        return min(max(score, 0), 1)  # Normalize to [0, 1]\n    \n    def _generate_target_actions(self,\n                               probability: float,\n                               risk_score: float) -> List[str]:\n        \"\"\"Generate suggested actions for a target\"\"\"\n        actions = []\n        \n        if probability > 0.8:\n            actions.append(\"Conduct detailed geological survey\")\n            actions.append(\"Plan drilling program\")\n        elif probability > 0.6:\n            actions.append(\"Perform surface sampling\")\n            actions.append(\"Consider geophysical survey\")\n        \n        if risk_score > 0.7:\n            actions.append(\"Conduct detailed risk assessment\")\n            actions.append(\"Develop risk mitigation plan\")\n        \n        return actions\n    \n    def _get_resource_activities(self,\n                               resource_type: str,\n                               monitoring_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Get current activities using a resource\"\"\"\n        activities = []\n        \n        for activity in monitoring_data.get(\"activities\", []):\n            if resource_type in activity.get(\"resources\", []):\n                activities.append(activity)\n        \n        return activities\n    \n    def _calculate_optimal_allocation(self,\n                                   utilization: float,\n                                   efficiency: float,\n                                   current_activities: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Calculate optimal resource allocation\"\"\"\n        result = {\n            \"needs_adjustment\": False,\n            \"priority_score\": 0.0,\n            \"confidence\": 0.0,\n            \"reason\": \"\",\n            \"suggestions\": [],\n            \"priority\": \"low\"\n        }\n        \n        # Check utilization\n        if utilization > 0.9:\n            result.update({\n                \"needs_adjustment\": True,\n                \"priority_score\": 0.9,\n                \"confidence\": 0.8,\n                \"reason\": \"Resource is over-utilized\",\n                \"suggestions\": [\"Reduce resource load\", \"Consider additional resources\"],\n                \"priority\": \"high\"\n            })\n        elif utilization < 0.5:\n            result.update({\n                \"needs_adjustment\": True,\n                \"priority_score\": 0.7,\n                \"confidence\": 0.7,\n                \"reason\": \"Resource is under-utilized\",\n                \"suggestions\": [\"Increase resource allocation\", \"Review resource distribution\"],\n                \"priority\": \"medium\"\n            })\n        \n        return result\n    \n    def _analyze_exploration_effectiveness(self,\n                                        prediction_results: Dict[str, Any],\n                                        historical_data: Optional[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Analyze exploration effectiveness\"\"\"\n        effectiveness = {\n            \"success_rate\": 0.0,\n            \"accuracy\": 0.0,\n            \"efficiency\": 0.0,\n            \"trends\": []\n        }\n        \n        if historical_data:\n            # Calculate success rate\n            total_explorations = len(historical_data.get(\"explorations\", []))\n            successful_explorations = sum(\n                1 for exp in historical_data.get(\"explorations\", [])\n                if exp.get(\"success\", False)\n            )\n            \n            effectiveness[\"success_rate\"] = (\n                successful_explorations / total_explorations\n                if total_explorations > 0 else 0\n            )\n            \n            # Calculate prediction accuracy\n            effectiveness[\"accuracy\"] = historical_data.get(\"prediction_accuracy\", 0.0)\n            \n            # Calculate resource efficiency\n            effectiveness[\"efficiency\"] = historical_data.get(\"resource_efficiency\", 0.0)\n            \n            # Analyze trends\n            effectiveness[\"trends\"] = self._analyze_historical_trends(historical_data)\n        \n        return effectiveness\n    \n    def _analyze_risk_patterns(self,\n                             risk_assessment: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Analyze patterns in risk assessment\"\"\"\n        patterns = {\n            \"high_risk_factors\": [],\n            \"risk_correlations\": {},\n            \"risk_trends\": []\n        }\n        \n        # Identify high risk factors\n        for factor, score in risk_assessment.items():\n            if isinstance(score, (int, float)) and score > 0.7:\n                patterns[\"high_risk_factors\"].append({\n                    \"factor\": factor,\n                    \"score\": score\n                })\n        \n        return patterns\n    \n    def _generate_strategies(self,\n                           effectiveness: Dict[str, Any],\n                           risk_patterns: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Generate exploration strategies\"\"\"\n        strategies = []\n        \n        # Generate strategy based on effectiveness\n        if effectiveness[\"success_rate\"] < 0.5:\n            strategies.append({\n                \"name\": \"Improve Success Rate\",\n                \"score\": 0.8,\n                \"confidence\": 0.7,\n                \"factors\": {\n                    \"current_success_rate\": effectiveness[\"success_rate\"],\n                    \"prediction_accuracy\": effectiveness[\"accuracy\"]\n                },\n                \"evidence\": [\n                    f\"Low success rate: {effectiveness['success_rate']:.2f}\",\n                    f\"Prediction accuracy: {effectiveness['accuracy']:.2f}\"\n                ],\n                \"description\": \"Focus on improving exploration success rate\",\n                \"steps\": [\n                    \"Review unsuccessful explorations\",\n                    \"Enhance prediction models\",\n                    \"Implement stricter selection criteria\"\n                ],\n                \"priority\": \"high\"\n            })\n        \n        # Generate strategy based on risk patterns\n        if risk_patterns[\"high_risk_factors\"]:\n            strategies.append({\n                \"name\": \"Risk Mitigation\",\n                \"score\": 0.75,\n                \"confidence\": 0.8,\n                \"factors\": {\n                    \"high_risk_count\": len(risk_patterns[\"high_risk_factors\"])\n                },\n                \"evidence\": [\n                    f\"Found {len(risk_patterns['high_risk_factors'])} high risk factors\"\n                ],\n                \"description\": \"Develop comprehensive risk mitigation strategy\",\n                \"steps\": [\n                    \"Address identified high risk factors\",\n                    \"Implement risk monitoring\",\n                    \"Develop contingency plans\"\n                ],\n                \"priority\": \"high\"\n            })\n        \n        return strategies\n    \n    def _analyze_current_conditions(self,\n                                  monitoring_data: Dict[str, Any],\n                                  resource_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Analyze current conditions for timing recommendations\"\"\"\n        conditions = {\n            \"optimal_timing\": {}\n        }\n        \n        # Analyze conditions for different activity types\n        activity_types = [\"survey\", \"sampling\", \"drilling\"]\n        \n        for activity_type in activity_types:\n            timing = self._analyze_activity_timing(\n                activity_type,\n                monitoring_data,\n                resource_data\n            )\n            \n            conditions[\"optimal_timing\"][activity_type] = timing\n        \n        return conditions\n    \n    def _analyze_activity_timing(self,\n                               activity_type: str,\n                               monitoring_data: Dict[str, Any],\n                               resource_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Analyze optimal timing for specific activity\"\"\"\n        timing = {\n            \"should_recommend\": False,\n            \"score\": 0.0,\n            \"confidence\": 0.0,\n            \"factors\": {},\n            \"evidence\": [],\n            \"window\": {},\n            \"rationale\": \"\",\n            \"priority\": \"low\"\n        }\n        \n        # Check resource availability\n        resource_availability = self._check_resource_availability(\n            activity_type,\n            resource_data\n        )\n        \n        # Check current activities\n        current_activities = monitoring_data.get(\"activities\", [])\n        activity_count = sum(\n            1 for a in current_activities\n            if a.get(\"type\") == activity_type\n        )\n        \n        # Generate timing recommendation\n        if resource_availability > 0.7 and activity_count < 3:\n            timing.update({\n                \"should_recommend\": True,\n                \"score\": 0.8,\n                \"confidence\": 0.7,\n                \"factors\": {\n                    \"resource_availability\": resource_availability,\n                    \"current_activities\": activity_count\n                },\n                \"evidence\": [\n                    f\"Resource availability: {resource_availability:.2f}\",\n                    f\"Current activities: {activity_count}\"\n                ],\n                \"window\": {\n                    \"start\": \"immediate\",\n                    \"duration_days\": 14\n                },\n                \"rationale\": \"High resource availability and low current activity\",\n                \"priority\": \"high\"\n            })\n        \n        return timing\n    \n    def _check_resource_availability(self,\n                                   activity_type: str,\n                                   resource_data: Dict[str, Any]) -> float:\n        \"\"\"Check resource availability for activity type\"\"\"\n        # Map activity types to required resources\n        required_resources = {\n            \"survey\": [\"survey_team\", \"equipment\"],\n            \"sampling\": [\"sampling_team\", \"analysis_lab\"],\n            \"drilling\": [\"drilling_team\", \"drilling_equipment\"]\n        }\n        \n        if activity_type not in required_resources:\n            return 0.0\n        \n        # Calculate average availability of required resources\n        availabilities = []\n        for resource in required_resources[activity_type]:\n            if resource in resource_data:\n                availability = 1 - resource_data[resource].get(\"utilization\", 0)\n                availabilities.append(availability)\n        \n        return np.mean(availabilities) if availabilities else 0.0\n    \n    def _analyze_historical_trends(self,\n                                 historical_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Analyze trends in historical data\"\"\"\n        trends = []\n        \n        if \"explorations\" in historical_data:\n            explorations = pd.DataFrame(historical_data[\"explorations\"])\n            \n            if not explorations.empty and \"date\" in explorations.columns:\n                # Convert dates\n                explorations[\"date\"] = pd.to_datetime(explorations[\"date\"])\n                \n                # Analyze monthly success rates\n                monthly_success = (\n                    explorations\n                    .set_index(\"date\")\n                    .resample(\"M\")[\"success\"]\n                    .agg([\"count\", \"sum\"])\n                )\n                \n                monthly_success[\"rate\"] = monthly_success[\"sum\"] / monthly_success[\"count\"]\n                \n                # Detect trends\n                rates = monthly_success[\"rate\"].dropna().values\n                if len(rates) > 1:\n                    trend_direction = \"increasing\" if rates[-1] > rates[0] else \"decreasing\"\n                    \n                    trends.append({\n                        \"metric\": \"success_rate\",\n                        \"direction\": trend_direction,\n                        \"magnitude\": abs(rates[-1] - rates[0]),\n                        \"period\": \"monthly\"\n                    })\n        \n        return trends\n    \n    def _generate_summary(self,\n                         exploration_recs: List[Dict[str, Any]],\n                         resource_recs: List[Dict[str, Any]],\n                         strategy_recs: List[Dict[str, Any]],\n                         timing_recs: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Generate summary of all recommendations\"\"\"\n        return {\n            \"total_recommendations\": len(exploration_recs) + len(resource_recs) + len(strategy_recs) + len(timing_recs),\n            \"high_priority_count\": sum(\n                1 for recs in [exploration_recs, resource_recs, strategy_recs, timing_recs]\n                for rec in recs\n                if rec.get(\"priority\") == \"high\"\n            ),\n            \"key_actions\": self._extract_key_actions(\n                exploration_recs,\n                resource_recs,\n                strategy_recs,\n                timing_recs\n            )\n        }\n    \n    def _extract_key_actions(self,\n                           exploration_recs: List[Dict[str, Any]],\n                           resource_recs: List[Dict[str, Any]],\n                           strategy_recs: List[Dict[str, Any]],\n                           timing_recs: List[Dict[str, Any]]) -> List[str]:\n        \"\"\"Extract key actions from recommendations\"\"\"\n        key_actions = []\n        \n        # Add top exploration target\n        if exploration_recs:\n            top_target = exploration_recs[0]\n            key_actions.append(\n                f\"Prioritize exploration at location \"\n                f\"({top_target['location']['latitude']:.4f}, \"\n                f\"{top_target['location']['longitude']:.4f})\"\n            )\n        \n        # Add urgent resource recommendations\n        for rec in resource_recs:\n            if rec[\"priority\"] == \"high\":\n                key_actions.append(\n                    f\"Adjust {rec['resource_type']} allocation: \"\n                    f\"{rec['suggested_changes'][0]}\"\n                )\n        \n        # Add top strategy recommendation\n        if strategy_recs:\n            top_strategy = strategy_recs[0]\n            key_actions.append(\n                f\"Implement {top_strategy['strategy_name']} strategy: \"\n                f\"{top_strategy['implementation_steps'][0]}\"\n            )\n        \n        return key_actions "}
{"type": "source_file", "path": "minesight/predict.py", "content": "\"\"\"\nPrediction script for MineSight\n\"\"\"\nimport argparse\nfrom pathlib import Path\nimport torch\nimport logging\nimport json\nfrom datetime import datetime\nimport pandas as pd\n\nfrom core.config import Config\nfrom core.ai.data import DataProcessor\nfrom core.ai.models import MineralExplorationModel, AutoEncoder, VariationalAutoEncoder\n\ndef setup_logging(output_dir: Path) -> logging.Logger:\n    \"\"\"Setup logging\"\"\"\n    logger = logging.getLogger('MineSight-Predict')\n    logger.setLevel(logging.INFO)\n    \n    # Create handlers\n    console_handler = logging.StreamHandler()\n    file_handler = logging.FileHandler(\n        output_dir / f\"prediction_{datetime.now():%Y%m%d_%H%M%S}.log\"\n    )\n    \n    # Create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    console_handler.setFormatter(formatter)\n    file_handler.setFormatter(formatter)\n    \n    # Add handlers\n    logger.addHandler(console_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\n\ndef load_model(model_path: Path,\n              config: Config,\n              device: torch.device) -> torch.nn.Module:\n    \"\"\"Load trained model\"\"\"\n    # Load checkpoint\n    checkpoint = torch.load(model_path, map_location=device)\n    \n    # Create model\n    if config.model.model_type == 'mineral':\n        model = MineralExplorationModel(\n            input_dim=config.model.input_dim,\n            hidden_dims=config.model.hidden_dims,\n            dropout=config.model.dropout\n        )\n    elif config.model.model_type == 'autoencoder':\n        model = AutoEncoder(\n            input_dim=config.model.input_dim,\n            hidden_dims=config.model.hidden_dims,\n            latent_dim=config.model.hidden_dims[-1]\n        )\n    elif config.model.model_type == 'vae':\n        model = VariationalAutoEncoder(\n            input_dim=config.model.input_dim,\n            hidden_dims=config.model.hidden_dims,\n            latent_dim=config.model.hidden_dims[-1]\n        )\n    else:\n        raise ValueError(f\"Unknown model type: {config.model.model_type}\")\n    \n    # Load state dict\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(device)\n    model.eval()\n    \n    return model\n\ndef predict(model: torch.nn.Module,\n           data: torch.Tensor,\n           device: torch.device) -> dict:\n    \"\"\"Make predictions\"\"\"\n    model.eval()\n    with torch.no_grad():\n        # Move data to device\n        data = data.to(device)\n        \n        # Get predictions\n        outputs = model(data)\n        \n        # Move results to CPU\n        results = {}\n        for key, value in outputs.items():\n            if isinstance(value, torch.Tensor):\n                results[key] = value.cpu()\n            else:\n                results[key] = value\n    \n    return results\n\ndef save_predictions(predictions: dict,\n                    metadata: pd.DataFrame,\n                    output_path: Path):\n    \"\"\"Save predictions to file\"\"\"\n    # Convert predictions to DataFrame\n    results_df = pd.DataFrame()\n    \n    # Add metadata\n    for col in metadata.columns:\n        results_df[col] = metadata[col]\n    \n    # Add predictions\n    if 'probability' in predictions:\n        results_df['probability'] = predictions['probability'].numpy()\n    if 'logits' in predictions:\n        results_df['logits'] = predictions['logits'].numpy()\n    if 'reconstruction_error' in predictions:\n        results_df['reconstruction_error'] = predictions['reconstruction_error'].mean(dim=1).numpy()\n    \n    # Save to CSV\n    results_df.to_csv(output_path, index=False)\n    \n    return results_df\n\ndef main():\n    \"\"\"Main prediction function\"\"\"\n    # Parse arguments\n    parser = argparse.ArgumentParser(description='Run predictions with MineSight model')\n    parser.add_argument('config', type=Path, help='Path to configuration file')\n    parser.add_argument('model', type=Path, help='Path to trained model checkpoint')\n    parser.add_argument('input', type=Path, help='Path to input data file')\n    parser.add_argument('--output-dir', type=Path, default='predictions',\n                      help='Output directory')\n    args = parser.parse_args()\n    \n    # Create output directory\n    output_dir = args.output_dir\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Setup logging\n    logger = setup_logging(output_dir)\n    \n    try:\n        # Load configuration\n        logger.info(f\"Loading configuration from {args.config}\")\n        config = Config.from_file(args.config)\n        \n        # Setup device\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        logger.info(f\"Using device: {device}\")\n        \n        # Initialize data processor\n        logger.info(\"Initializing data processor\")\n        processor = DataProcessor(\n            data_dir=config.data.data_dir,\n            cache_dir=config.data.cache_dir\n        )\n        \n        # Load input data\n        logger.info(f\"Loading input data from {args.input}\")\n        input_data = pd.read_csv(args.input)\n        \n        # Process data\n        logger.info(\"Processing input data\")\n        features = processor._extract_features(\n            input_data,\n            pd.DataFrame(),  # Empty features DataFrame\n            config.data.__dict__\n        )\n        features_tensor = torch.FloatTensor(\n            processor.scalers['feature_scaler'].transform(features)\n        )\n        \n        # Load model\n        logger.info(f\"Loading model from {args.model}\")\n        model = load_model(args.model, config, device)\n        \n        # Make predictions\n        logger.info(\"Making predictions\")\n        predictions = predict(model, features_tensor, device)\n        \n        # Save results\n        output_path = output_dir / f\"predictions_{datetime.now():%Y%m%d_%H%M%S}.csv\"\n        logger.info(f\"Saving predictions to {output_path}\")\n        results_df = save_predictions(predictions, input_data, output_path)\n        \n        # Log summary\n        logger.info(\"\\nPrediction summary:\")\n        if 'probability' in predictions:\n            probs = predictions['probability'].numpy()\n            logger.info(f\"Mean probability: {probs.mean():.4f}\")\n            logger.info(f\"High probability locations (>0.8): {(probs > 0.8).sum()}\")\n        if 'reconstruction_error' in predictions:\n            errors = predictions['reconstruction_error'].mean(dim=1).numpy()\n            logger.info(f\"Mean reconstruction error: {errors.mean():.4f}\")\n            logger.info(f\"Anomalies (error > 2): {(errors > errors.mean() + 2*errors.std()).sum()}\")\n        \n        logger.info(\"Predictions completed successfully\")\n        \n    except Exception as e:\n        logger.error(f\"Error during prediction: {str(e)}\", exc_info=True)\n        raise\n\nif __name__ == '__main__':\n    main() "}
{"type": "source_file", "path": "minesight/train.py", "content": "\"\"\"\nMain training script for MineSight\n\"\"\"\nimport argparse\nfrom pathlib import Path\nimport torch\nimport logging\nfrom datetime import datetime\n\nfrom core.config import Config\nfrom core.ai.data import DataProcessor\nfrom core.ai.models import MineralExplorationModel, AutoEncoder, VariationalAutoEncoder\nfrom core.ai.trainer import ModelTrainer\n\ndef setup_logging(output_dir: Path) -> logging.Logger:\n    \"\"\"Setup logging\"\"\"\n    logger = logging.getLogger('MineSight')\n    logger.setLevel(logging.INFO)\n    \n    # Create handlers\n    console_handler = logging.StreamHandler()\n    file_handler = logging.FileHandler(\n        output_dir / f\"training_{datetime.now():%Y%m%d_%H%M%S}.log\"\n    )\n    \n    # Create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    console_handler.setFormatter(formatter)\n    file_handler.setFormatter(formatter)\n    \n    # Add handlers\n    logger.addHandler(console_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\n\ndef get_model(config: Config, input_dim: int) -> torch.nn.Module:\n    \"\"\"Get model based on configuration\"\"\"\n    if config.model.model_type == 'mineral':\n        return MineralExplorationModel(\n            input_dim=input_dim,\n            hidden_dims=config.model.hidden_dims,\n            dropout=config.model.dropout\n        )\n    elif config.model.model_type == 'autoencoder':\n        return AutoEncoder(\n            input_dim=input_dim,\n            hidden_dims=config.model.hidden_dims,\n            latent_dim=config.model.hidden_dims[-1]\n        )\n    elif config.model.model_type == 'vae':\n        return VariationalAutoEncoder(\n            input_dim=input_dim,\n            hidden_dims=config.model.hidden_dims,\n            latent_dim=config.model.hidden_dims[-1]\n        )\n    else:\n        raise ValueError(f\"Unknown model type: {config.model.model_type}\")\n\ndef main():\n    \"\"\"Main training function\"\"\"\n    # Parse arguments\n    parser = argparse.ArgumentParser(description='Train MineSight model')\n    parser.add_argument('config', type=Path, help='Path to configuration file')\n    parser.add_argument('--output-dir', type=Path, default='outputs',\n                      help='Output directory')\n    args = parser.parse_args()\n    \n    # Create output directory\n    output_dir = args.output_dir\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Setup logging\n    logger = setup_logging(output_dir)\n    \n    try:\n        # Load configuration\n        logger.info(f\"Loading configuration from {args.config}\")\n        config = Config.from_file(args.config)\n        \n        # Setup device\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        logger.info(f\"Using device: {device}\")\n        \n        # Initialize data processor\n        logger.info(\"Initializing data processor\")\n        processor = DataProcessor(\n            data_dir=config.data.data_dir,\n            cache_dir=config.data.cache_dir\n        )\n        \n        # Load and process data\n        logger.info(\"Loading and processing data\")\n        data = processor.load_and_process_data(config.data.__dict__)\n        \n        # Update model input dimension\n        config.model.input_dim = data['train']['features'].shape[1]\n        \n        # Create model\n        logger.info(\"Creating model\")\n        model = get_model(config, config.model.input_dim)\n        model = model.to(device)\n        \n        # Create trainer\n        logger.info(\"Setting up trainer\")\n        trainer = ModelTrainer(\n            model=model,\n            device=device,\n            output_dir=output_dir\n        )\n        \n        # Train model\n        logger.info(\"Starting training\")\n        history = trainer.train(\n            train_data=data['train'],\n            val_data=data['val'],\n            config=config.training.__dict__\n        )\n        \n        # Evaluate model\n        logger.info(\"Evaluating model\")\n        results = trainer.evaluate(data['test'])\n        \n        # Log results\n        logger.info(\"Final test metrics:\")\n        for metric, value in results['metrics'].items():\n            logger.info(f\"{metric}: {value:.4f}\")\n        \n        logger.info(\"Training completed successfully\")\n        \n    except Exception as e:\n        logger.error(f\"Error during training: {str(e)}\", exc_info=True)\n        raise\n\nif __name__ == '__main__':\n    main() "}
{"type": "source_file", "path": "minesight/core/reporting/smart_report.py", "content": "\"\"\"\nIntelligent reporting system for MineSight\n\"\"\"\nfrom typing import Dict, List, Optional, Any, Union, Tuple\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom pathlib import Path\nimport json\nfrom dataclasses import dataclass\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom scipy import stats\nimport logging\nimport jinja2\nimport pdfkit\n\n@dataclass\nclass ReportConfig:\n    \"\"\"Report configuration\"\"\"\n    template: str = \"default\"\n    output_format: str = \"html\"\n    include_visualizations: bool = True\n    max_insights: int = 10\n    confidence_threshold: float = 0.7\n    custom_sections: Optional[List[str]] = None\n    style_config: Optional[Dict[str, Any]] = None\n\n@dataclass\nclass ReportSection:\n    \"\"\"Report section data\"\"\"\n    title: str\n    content: Union[str, Dict[str, Any]]\n    visualizations: Optional[List[Dict[str, Any]] = None\n    metrics: Optional[Dict[str, float]] = None\n    insights: Optional[List[str]] = None\n    recommendations: Optional[List[str]] = None\n    confidence: float = 1.0\n\nclass SmartReport:\n    \"\"\"Intelligent reporting system\"\"\"\n    \n    def __init__(self, config: Optional[ReportConfig] = None):\n        \"\"\"Initialize the reporting system\"\"\"\n        self.config = config or ReportConfig()\n        self.data_sources = {}\n        self.sections = []\n        self.insights = []\n        self.recommendations = []\n        self.logger = logging.getLogger(__name__)\n        \n    def add_data_source(self, name: str, data: Any) -> None:\n        \"\"\"Add a data source for report generation\"\"\"\n        self.data_sources[name] = data\n        \n    def generate_report(self, \n                       title: str,\n                       description: str,\n                       sections: Optional[List[str]] = None) -> str:\n        \"\"\"\n        Generate comprehensive report\n        \n        Args:\n            title: Report title\n            description: Report description\n            sections: Optional list of sections to include\n            \n        Returns:\n            Path to generated report\n        \"\"\"\n        try:\n            # Get sections to include\n            sections_to_include = sections or self._get_default_sections()\n            \n            # Add header section\n            self._add_header_section(title, description)\n            \n            # Process data sources\n            self._process_data_sources()\n            \n            # Generate sections\n            for section in sections_to_include:\n                if section == \"performance\":\n                    self._add_performance_section()\n                elif section == \"optimization\":\n                    self._add_optimization_section()\n                elif section == \"quality\":\n                    self._add_quality_section()\n                elif section == \"anomaly\":\n                    self._add_anomaly_section()\n                elif section == \"resource\":\n                    self._add_resource_section()\n                elif section == \"recommendations\":\n                    self._add_recommendations_section()\n                    \n            # Generate insights\n            self._generate_insights()\n            \n            # Create report output\n            output_path = self._create_report_output(title)\n            \n            self.logger.info(f\"Report generated successfully: {output_path}\")\n            return output_path\n            \n        except Exception as e:\n            self.logger.error(f\"Error generating report: {str(e)}\")\n            raise\n            \n    def _add_header_section(self, title: str, description: str) -> None:\n        \"\"\"Add report header section\"\"\"\n        header = ReportSection(\n            title=\"Report Overview\",\n            content={\n                \"title\": title,\n                \"description\": description,\n                \"generated_at\": datetime.now().isoformat(),\n                \"data_sources\": list(self.data_sources.keys())\n            }\n        )\n        self.sections.append(header)\n        \n    def _process_data_sources(self) -> None:\n        \"\"\"Process and validate data sources\"\"\"\n        if not self.data_sources:\n            raise ValueError(\"No data sources provided for report generation\")\n            \n        # Validate required data sources\n        required_sources = self._get_required_data_sources()\n        missing_sources = [s for s in required_sources if s not in self.data_sources]\n        \n        if missing_sources:\n            raise ValueError(f\"Missing required data sources: {missing_sources}\")\n            \n        # Convert data to appropriate format if needed\n        for name, data in self.data_sources.items():\n            if isinstance(data, dict) and \"data\" in data:\n                self.data_sources[name] = pd.DataFrame(data[\"data\"])\n            elif isinstance(data, list):\n                self.data_sources[name] = pd.DataFrame(data)\n                \n    def _get_required_data_sources(self) -> List[str]:\n        \"\"\"Get list of required data sources based on sections\"\"\"\n        required = set()\n        \n        for section in self.sections:\n            if section.title == \"Performance Analysis\":\n                required.add(\"performance_data\")\n            elif section.title == \"Optimization Results\":\n                required.add(\"optimization_data\")\n            elif section.title == \"Quality Metrics\":\n                required.add(\"quality_data\")\n            elif section.title == \"Anomaly Analysis\":\n                required.add(\"anomaly_data\")\n            elif section.title == \"Resource Utilization\":\n                required.add(\"resource_data\")\n                \n        return list(required)\n        \n    def _create_report_output(self, title: str) -> str:\n        \"\"\"Create report output in specified format\"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        output_dir = Path(\"reports\")\n        output_dir.mkdir(exist_ok=True)\n        \n        if self.config.output_format == \"html\":\n            output_path = output_dir / f\"{title.lower().replace(' ', '_')}_{timestamp}.html\"\n            self._generate_html_report(str(output_path), title)\n            \n        elif self.config.output_format == \"json\":\n            output_path = output_dir / f\"{title.lower().replace(' ', '_')}_{timestamp}.json\"\n            self._generate_json_report(str(output_path))\n            \n        elif self.config.output_format == \"pdf\":\n            output_path = output_dir / f\"{title.lower().replace(' ', '_')}_{timestamp}.pdf\"\n            self._generate_pdf_report(str(output_path), title)\n            \n        else:\n            raise ValueError(f\"Unsupported output format: {self.config.output_format}\")\n            \n        return str(output_path)\n        \n    def _generate_html_report(self, output_path: str, title: str) -> None:\n        \"\"\"Generate HTML report\"\"\"\n        # Load template\n        template_loader = jinja2.FileSystemLoader(searchpath=\"templates\")\n        template_env = jinja2.Environment(loader=template_loader)\n        template = template_env.get_template(f\"{self.config.template}.html\")\n        \n        # Prepare template data\n        template_data = {\n            \"title\": title,\n            \"style\": self._get_report_style(),\n            \"sections\": [self._section_to_html(s) for s in self.sections],\n            \"insights\": self.insights,\n            \"generated_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        }\n        \n        # Render template\n        html_output = template.render(**template_data)\n        \n        # Save report\n        with open(output_path, \"w\") as f:\n            f.write(html_output)\n            \n    def _generate_json_report(self, output_path: str) -> None:\n        \"\"\"Generate JSON report\"\"\"\n        report_data = {\n            \"sections\": [\n                {\n                    \"title\": s.title,\n                    \"content\": s.content,\n                    \"visualizations\": s.visualizations,\n                    \"metrics\": s.metrics,\n                    \"insights\": s.insights,\n                    \"recommendations\": s.recommendations,\n                    \"confidence\": s.confidence\n                }\n                for s in self.sections\n            ],\n            \"insights\": self.insights,\n            \"generated_at\": datetime.now().isoformat()\n        }\n        \n        with open(output_path, \"w\") as f:\n            json.dump(report_data, f, indent=2)\n            \n    def _generate_pdf_report(self, output_path: str, title: str) -> None:\n        \"\"\"Generate PDF report\"\"\"\n        # First generate HTML\n        html_path = output_path.replace(\".pdf\", \".html\")\n        self._generate_html_report(html_path, title)\n        \n        # Convert HTML to PDF\n        pdfkit.from_file(html_path, output_path)\n        \n        # Clean up HTML file\n        Path(html_path).unlink()\n        \n    def _get_report_style(self) -> str:\n        \"\"\"Get report CSS style\"\"\"\n        default_style = \"\"\"\n        body {\n            font-family: Arial, sans-serif;\n            line-height: 1.6;\n            color: #333;\n            max-width: 1200px;\n            margin: 0 auto;\n            padding: 20px;\n        }\n        \n        h1 {\n            color: #2c3e50;\n            border-bottom: 2px solid #3498db;\n            padding-bottom: 10px;\n        }\n        \n        h2 {\n            color: #2980b9;\n            margin-top: 30px;\n        }\n        \n        .section {\n            background: #fff;\n            padding: 20px;\n            margin: 20px 0;\n            border-radius: 5px;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n        }\n        \n        .metrics {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n            gap: 20px;\n            margin: 20px 0;\n        }\n        \n        .metric {\n            background: #f8f9fa;\n            padding: 15px;\n            border-radius: 5px;\n            text-align: center;\n        }\n        \n        .metric-value {\n            font-size: 24px;\n            font-weight: bold;\n            color: #2980b9;\n        }\n        \n        .metric-label {\n            color: #7f8c8d;\n            font-size: 14px;\n        }\n        \n        .insights {\n            background: #f0f7fb;\n            padding: 20px;\n            border-left: 5px solid #3498db;\n            margin: 20px 0;\n        }\n        \n        .recommendations {\n            background: #fff3e0;\n            padding: 20px;\n            border-left: 5px solid #f39c12;\n            margin: 20px 0;\n        }\n        \n        .visualization {\n            margin: 20px 0;\n            padding: 20px;\n            background: #fff;\n            border-radius: 5px;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n        }\n        \n        .confidence {\n            font-size: 14px;\n            color: #7f8c8d;\n            text-align: right;\n            margin-top: 10px;\n        }\n        \"\"\"\n        \n        # Override with custom style if provided\n        if self.config.style_config:\n            custom_style = \"\\n\".join(f\"{k} {{{v}}}\" for k, v in self.config.style_config.items())\n            return custom_style\n            \n        return default_style\n        \n    def _section_to_html(self, section: ReportSection) -> str:\n        \"\"\"Convert section to HTML\"\"\"\n        html = f\"<div class='section'><h2>{section.title}</h2>\"\n        \n        # Add content\n        if isinstance(section.content, str):\n            html += f\"<p>{section.content}</p>\"\n        elif isinstance(section.content, dict):\n            for key, value in section.content.items():\n                html += f\"<div class='content-item'><strong>{key}:</strong> {value}</div>\"\n                \n        # Add metrics\n        if section.metrics:\n            html += \"<div class='metrics'>\"\n            for name, value in section.metrics.items():\n                html += f\"\"\"\n                <div class='metric'>\n                    <div class='metric-value'>{value:.2f}</div>\n                    <div class='metric-label'>{name.replace('_', ' ').title()}</div>\n                </div>\n                \"\"\"\n            html += \"</div>\"\n            \n        # Add insights\n        if section.insights:\n            html += \"<div class='insights'><h3>Key Insights</h3><ul>\"\n            for insight in section.insights:\n                html += f\"<li>{insight}</li>\"\n            html += \"</ul></div>\"\n            \n        # Add recommendations\n        if section.recommendations:\n            html += \"<div class='recommendations'><h3>Recommendations</h3><ul>\"\n            for rec in section.recommendations:\n                html += f\"<li>{rec}</li>\"\n            html += \"</ul></div>\"\n            \n        # Add visualizations\n        if section.visualizations and self.config.include_visualizations:\n            html += \"<div class='visualizations'>\"\n            for viz in section.visualizations:\n                html += f\"<div class='visualization'>{viz}</div>\"\n            html += \"</div>\"\n            \n        # Add confidence score\n        if section.confidence < 1.0:\n            html += f\"<div class='confidence'>Confidence Score: {section.confidence:.2%}</div>\"\n            \n        html += \"</div>\"\n        return html\n        \n    def _get_default_sections(self) -> List[str]:\n        \"\"\"Get default report sections\"\"\"\n        return [\n            \"performance\",\n            \"optimization\",\n            \"quality\",\n            \"anomaly\",\n            \"resource\",\n            \"recommendations\"\n        ]\n\n    def _add_performance_section(self) -> None:\n        \"\"\"Add performance analysis section\"\"\"\n        if \"performance\" not in self.data_sources:\n            self.logger.warning(\"No performance data available for analysis\")\n            return\n            \n        try:\n            data = self.data_sources[\"performance\"]\n            \n            # Calculate performance metrics\n            metrics = self._calculate_performance_metrics(data)\n            \n            # Analyze performance trends\n            trends = self._analyze_performance_trends(data)\n            \n            # Generate insights\n            insights = self._generate_performance_insights(metrics, trends)\n            \n            # Generate recommendations\n            recommendations = self._generate_performance_recommendations(metrics, trends)\n            \n            # Create visualizations\n            visualizations = []\n            if self.config.include_visualizations:\n                visualizations = [\n                    self._create_metrics_timeline(data),\n                    self._create_metrics_correlation(data)\n                ]\n                \n            # Calculate confidence score\n            confidence = self._calculate_metrics_confidence(metrics)\n            \n            # Add section\n            self.sections.append(ReportSection(\n                title=\"Performance Analysis\",\n                content={\n                    \"metrics\": metrics,\n                    \"trends\": trends\n                },\n                visualizations=visualizations,\n                metrics=metrics,\n                insights=insights,\n                recommendations=recommendations,\n                confidence=confidence\n            ))\n            \n        except Exception as e:\n            self.logger.error(f\"Error adding performance section: {str(e)}\")\n            raise\n            \n    def _calculate_performance_metrics(self, data: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"\n        Calculate performance metrics from process data\n        \n        Args:\n            data: Performance data DataFrame\n            \n        Returns:\n            Dictionary of performance metrics\n        \"\"\"\n        metrics = {}\n        \n        try:\n            # Process efficiency\n            if \"efficiency\" in data.columns:\n                metrics[\"process_efficiency\"] = float(data[\"efficiency\"].mean())\n                metrics[\"efficiency_stability\"] = float(1.0 - data[\"efficiency\"].std())\n            \n            # Success rate\n            if all(col in data.columns for col in [\"success_count\", \"total_count\"]):\n                metrics[\"success_rate\"] = float(\n                    data[\"success_count\"].sum() / data[\"total_count\"].sum()\n                )\n            \n            # Cost effectiveness\n            if all(col in data.columns for col in [\"cost\", \"value\"]):\n                metrics[\"cost_effectiveness\"] = float(\n                    data[\"value\"].sum() / data[\"cost\"].sum()\n                )\n            \n            # Resource utilization\n            if all(col in data.columns for col in [\"resource_usage\", \"resource_capacity\"]):\n                metrics[\"resource_utilization\"] = float(\n                    data[\"resource_usage\"].mean() / data[\"resource_capacity\"].mean()\n                )\n            \n            # Error rate\n            if all(col in data.columns for col in [\"error_count\", \"total_count\"]):\n                metrics[\"error_rate\"] = float(\n                    data[\"error_count\"].sum() / data[\"total_count\"].sum()\n                )\n            \n            # Processing time\n            if \"processing_time\" in data.columns:\n                metrics[\"avg_processing_time\"] = float(data[\"processing_time\"].mean())\n                metrics[\"processing_time_stability\"] = float(\n                    1.0 - data[\"processing_time\"].std() / data[\"processing_time\"].mean()\n                )\n            \n            # Throughput\n            if \"throughput\" in data.columns:\n                metrics[\"avg_throughput\"] = float(data[\"throughput\"].mean())\n                metrics[\"throughput_stability\"] = float(\n                    1.0 - data[\"throughput\"].std() / data[\"throughput\"].mean()\n                )\n            \n            # Normalize metrics to 0-1 range\n            for key in metrics:\n                metrics[key] = float(np.clip(metrics[key], 0, 1))\n                \n        except Exception as e:\n            self.logger.error(f\"Error calculating performance metrics: {str(e)}\")\n            \n        return metrics\n        \n    def _analyze_performance_trends(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"\n        Analyze performance trends in time series data\n        \n        Args:\n            data: Performance time series DataFrame\n            \n        Returns:\n            Dictionary of trend analysis results\n        \"\"\"\n        trends = {}\n        \n        try:\n            # Ensure data is sorted by timestamp\n            if \"timestamp\" in data.columns:\n                data = data.sort_values(\"timestamp\")\n                \n            # Calculate trends for key metrics\n            metric_columns = [\n                \"efficiency\", \"success_rate\", \"cost_effectiveness\",\n                \"resource_utilization\", \"error_rate\", \"processing_time\",\n                \"throughput\"\n            ]\n            \n            for metric in metric_columns:\n                if metric in data.columns:\n                    trend = self._calculate_metric_trend(data[metric])\n                    trends[metric] = trend\n            \n            # Detect performance patterns\n            patterns = self._detect_performance_patterns(data)\n            trends[\"patterns\"] = patterns\n            \n            # Analyze seasonality if enough data points\n            if len(data) >= 24:  # At least 24 hours of data\n                seasonality = self._analyze_seasonality(data)\n                trends[\"seasonality\"] = seasonality\n            \n            # Calculate correlations between metrics\n            correlations = self._analyze_metric_correlations(data)\n            trends[\"correlations\"] = correlations\n            \n        except Exception as e:\n            self.logger.error(f\"Error analyzing performance trends: {str(e)}\")\n            \n        return trends\n        \n    def _detect_performance_patterns(self, data: pd.DataFrame) -> List[Dict[str, Any]]:\n        \"\"\"Detect patterns in performance data\"\"\"\n        patterns = []\n        \n        try:\n            # Detect trend patterns\n            for column in data.select_dtypes(include=[np.number]).columns:\n                series = data[column]\n                trend = self._calculate_metric_trend(series)\n                \n                if trend[\"strength\"] > 0.7:  # Strong trend\n                    patterns.append({\n                        \"type\": \"trend\",\n                        \"metric\": column,\n                        \"direction\": trend[\"direction\"],\n                        \"strength\": trend[\"strength\"],\n                        \"description\": (\n                            f\"Strong {trend['direction']} trend detected in {column} \"\n                            f\"(strength: {trend['strength']:.2f})\"\n                        )\n                    })\n                    \n            # Detect outliers\n            for column in data.select_dtypes(include=[np.number]).columns:\n                series = data[column]\n                z_scores = np.abs(stats.zscore(series))\n                outliers = z_scores > 3\n                if any(outliers):\n                    patterns.append({\n                        \"type\": \"outlier\",\n                        \"metric\": column,\n                        \"count\": int(sum(outliers)),\n                        \"indices\": list(np.where(outliers)[0]),\n                        \"description\": (\n                            f\"Found {sum(outliers)} outliers in {column}\"\n                        )\n                    })\n                    \n            # Detect cyclic patterns\n            if \"timestamp\" in data.columns and len(data) >= 24:\n                for column in data.select_dtypes(include=[np.number]).columns:\n                    series = data[column]\n                    # Check hourly patterns\n                    hourly_means = series.groupby(data[\"timestamp\"].dt.hour).mean()\n                    hourly_std = hourly_means.std()\n                    hourly_range = hourly_means.max() - hourly_means.min()\n                    \n                    if hourly_range > 2 * hourly_std:\n                        patterns.append({\n                            \"type\": \"cyclic\",\n                            \"metric\": column,\n                            \"period\": \"hourly\",\n                            \"peak_hour\": int(hourly_means.idxmax()),\n                            \"trough_hour\": int(hourly_means.idxmin()),\n                            \"description\": (\n                                f\"Hourly pattern detected in {column} \"\n                                f\"(peak: {hourly_means.idxmax()}:00, \"\n                                f\"trough: {hourly_means.idxmin()}:00)\"\n                            )\n                        })\n                        \n        except Exception as e:\n            self.logger.error(f\"Error detecting performance patterns: {str(e)}\")\n            \n        return patterns\n        \n    def _generate_performance_insights(self,\n                                    metrics: Dict[str, float],\n                                    trends: Dict[str, Any]) -> List[str]:\n        \"\"\"\n        Generate insights from performance analysis\n        \n        Args:\n            metrics: Performance metrics\n            trends: Trend analysis results\n            \n        Returns:\n            List of performance insights\n        \"\"\"\n        insights = []\n        \n        try:\n            # Metric-based insights\n            if \"process_efficiency\" in metrics:\n                efficiency = metrics[\"process_efficiency\"]\n                if efficiency < 0.6:\n                    insights.append(\n                        f\"Low process efficiency detected: {efficiency:.1%}\"\n                    )\n                elif efficiency > 0.9:\n                    insights.append(\n                        f\"Excellent process efficiency: {efficiency:.1%}\"\n                    )\n                    \n            if \"success_rate\" in metrics:\n                success_rate = metrics[\"success_rate\"]\n                if success_rate < 0.95:\n                    insights.append(\n                        f\"Below target success rate: {success_rate:.1%}\"\n                    )\n                    \n            if \"error_rate\" in metrics:\n                error_rate = metrics[\"error_rate\"]\n                if error_rate > 0.05:\n                    insights.append(\n                        f\"High error rate detected: {error_rate:.1%}\"\n                    )\n                    \n            if \"resource_utilization\" in metrics:\n                utilization = metrics[\"resource_utilization\"]\n                if utilization > 0.9:\n                    insights.append(\n                        f\"High resource utilization: {utilization:.1%}\"\n                    )\n                elif utilization < 0.3:\n                    insights.append(\n                        f\"Low resource utilization: {utilization:.1%}\"\n                    )\n                    \n            # Trend-based insights\n            for metric, trend in trends.items():\n                if isinstance(trend, dict) and \"slope\" in trend:\n                    if abs(trend[\"slope\"]) > 0.01 and trend[\"strength\"] > 0.6:\n                        direction = \"improving\" if trend[\"slope\"] > 0 else \"degrading\"\n                        insights.append(\n                            f\"{metric.replace('_', ' ').title()} is {direction} \"\n                            f\"(confidence: {trend['strength']:.1%})\"\n                        )\n                        \n            # Pattern-based insights\n            for pattern in trends.get(\"patterns\", []):\n                insights.append(pattern[\"description\"])\n                \n            # Correlation insights\n            for corr_name, corr_value in trends.get(\"correlations\", {}).items():\n                if abs(corr_value) > 0.7:\n                    metrics = corr_name.split(\"_vs_\")\n                    direction = \"positive\" if corr_value > 0 else \"negative\"\n                    insights.append(\n                        f\"Strong {direction} correlation between \"\n                        f\"{metrics[0]} and {metrics[1]} ({corr_value:.2f})\"\n                    )\n                    \n        except Exception as e:\n            self.logger.error(f\"Error generating performance insights: {str(e)}\")\n            \n        return insights\n        \n    def _generate_performance_recommendations(self,\n                                          metrics: Dict[str, float],\n                                          trends: Dict[str, Any]) -> List[str]:\n        \"\"\"\n        Generate recommendations based on performance analysis\n        \n        Args:\n            metrics: Performance metrics\n            trends: Trend analysis results\n            \n        Returns:\n            List of recommendations\n        \"\"\"\n        recommendations = []\n        \n        try:\n            # Efficiency recommendations\n            if metrics.get(\"process_efficiency\", 1.0) < 0.7:\n                recommendations.extend([\n                    \"Review and optimize process workflows\",\n                    \"Identify and eliminate bottlenecks\",\n                    \"Consider automation opportunities\"\n                ])\n                \n            # Success rate recommendations\n            if metrics.get(\"success_rate\", 1.0) < 0.95:\n                recommendations.extend([\n                    \"Implement additional validation checks\",\n                    \"Review error handling procedures\",\n                    \"Enhance monitoring and alerting\"\n                ])\n                \n            # Resource utilization recommendations\n            utilization = metrics.get(\"resource_utilization\", 0.0)\n            if utilization > 0.9:\n                recommendations.extend([\n                    \"Scale up resources to handle load\",\n                    \"Implement load balancing\",\n                    \"Review resource allocation strategy\"\n                ])\n            elif utilization < 0.3:\n                recommendations.extend([\n                    \"Optimize resource allocation\",\n                    \"Consider resource consolidation\",\n                    \"Review scaling policies\"\n                ])\n                \n            # Error rate recommendations\n            if metrics.get(\"error_rate\", 0.0) > 0.05:\n                recommendations.extend([\n                    \"Implement error prevention measures\",\n                    \"Enhance error detection capabilities\",\n                    \"Review and update error handling\"\n                ])\n                \n            # Processing time recommendations\n            if metrics.get(\"processing_time_stability\", 1.0) < 0.7:\n                recommendations.extend([\n                    \"Optimize processing algorithms\",\n                    \"Review caching strategy\",\n                    \"Consider parallel processing\"\n                ])\n                \n            # Trend-based recommendations\n            for metric, trend in trends.items():\n                if isinstance(trend, dict):\n                    if trend.get(\"slope\", 0) < -0.01 and trend.get(\"strength\", 0) > 0.6:\n                        recommendations.append(\n                            f\"Investigate and address declining {metric} trend\"\n                        )\n                        \n        except Exception as e:\n            self.logger.error(f\"Error generating performance recommendations: {str(e)}\")\n            \n        return recommendations\n        \n    def _create_metrics_timeline(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create timeline visualization of metrics\"\"\"\n        try:\n            if \"timestamp\" not in data.columns:\n                return {}\n                \n            # Select numeric columns for visualization\n            numeric_cols = data.select_dtypes(include=[np.number]).columns\n            \n            # Create figure\n            fig = go.Figure()\n            \n            # Add traces for each metric\n            for column in numeric_cols:\n                fig.add_trace(\n                    go.Scatter(\n                        x=data[\"timestamp\"],\n                        y=data[column],\n                        name=column.replace(\"_\", \" \").title(),\n                        mode=\"lines+markers\"\n                    )\n                )\n                \n            # Update layout\n            fig.update_layout(\n                title=\"Performance Metrics Timeline\",\n                xaxis_title=\"Time\",\n                yaxis_title=\"Value\",\n                hovermode=\"x unified\",\n                showlegend=True,\n                legend=dict(\n                    yanchor=\"top\",\n                    y=0.99,\n                    xanchor=\"left\",\n                    x=0.01\n                )\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating metrics timeline: {str(e)}\")\n            return {}\n            \n    def _create_metrics_correlation(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create correlation heatmap visualization\"\"\"\n        try:\n            # Select numeric columns\n            numeric_data = data.select_dtypes(include=[np.number])\n            \n            if len(numeric_data.columns) < 2:\n                return {}\n                \n            # Calculate correlation matrix\n            corr_matrix = numeric_data.corr()\n            \n            # Create heatmap\n            fig = go.Figure(data=go.Heatmap(\n                z=corr_matrix.values,\n                x=corr_matrix.columns,\n                y=corr_matrix.columns,\n                colorscale=\"RdBu\",\n                zmin=-1,\n                zmax=1\n            ))\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Metric Correlations\",\n                xaxis_title=\"Metric\",\n                yaxis_title=\"Metric\",\n                width=800,\n                height=800\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating correlation heatmap: {str(e)}\")\n            return {}\n        \n    def _add_optimization_section(self) -> None:\n        \"\"\"Add optimization analysis section\"\"\"\n        if \"optimization\" not in self.data_sources:\n            self.logger.warning(\"No optimization data available for analysis\")\n            return\n            \n        try:\n            data = self.data_sources[\"optimization\"]\n            \n            # Analyze optimization results\n            results = self._analyze_optimization_results(data)\n            \n            # Calculate optimization impact\n            impact = self._calculate_optimization_impact(data)\n            \n            # Generate insights\n            insights = self._generate_optimization_insights(results, impact)\n            \n            # Generate recommendations\n            recommendations = self._generate_optimization_recommendations(results)\n            \n            # Create visualizations\n            visualizations = []\n            if self.config.include_visualizations:\n                visualizations = [\n                    self._create_optimization_impact_plot(impact),\n                    self._create_optimization_timeline(data)\n                ]\n                \n            # Calculate confidence score\n            confidence = self._calculate_optimization_confidence(results)\n            \n            # Add section\n            self.sections.append(ReportSection(\n                title=\"Optimization Analysis\",\n                content={\n                    \"results\": results,\n                    \"impact\": impact\n                },\n                visualizations=visualizations,\n                metrics=impact,\n                insights=insights,\n                recommendations=recommendations,\n                confidence=confidence\n            ))\n            \n        except Exception as e:\n            self.logger.error(f\"Error adding optimization section: {str(e)}\")\n            raise\n            \n    def _analyze_optimization_results(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"\n        Analyze optimization results\n        \n        Args:\n            data: Optimization data DataFrame\n            \n        Returns:\n            Dictionary of optimization analysis results\n        \"\"\"\n        results = {\n            \"metrics\": {},\n            \"improvements\": {},\n            \"comparisons\": {},\n            \"bottlenecks\": []\n        }\n        \n        try:\n            # Calculate optimization metrics\n            if \"objective_value\" in data.columns:\n                results[\"metrics\"][\"objective_improvement\"] = float(\n                    (data[\"objective_value\"].max() - data[\"objective_value\"].min()) /\n                    data[\"objective_value\"].min()\n                )\n                \n            if \"iteration_count\" in data.columns:\n                results[\"metrics\"][\"convergence_rate\"] = float(\n                    1.0 / data[\"iteration_count\"].mean()\n                )\n                \n            if \"execution_time\" in data.columns:\n                results[\"metrics\"][\"avg_execution_time\"] = float(\n                    data[\"execution_time\"].mean()\n                )\n                \n            # Calculate improvements\n            if all(col in data.columns for col in [\"before_value\", \"after_value\"]):\n                improvements = (data[\"after_value\"] - data[\"before_value\"]) / data[\"before_value\"]\n                results[\"improvements\"] = {\n                    \"mean\": float(improvements.mean()),\n                    \"median\": float(improvements.median()),\n                    \"max\": float(improvements.max()),\n                    \"min\": float(improvements.min()),\n                    \"std\": float(improvements.std())\n                }\n                \n            # Compare different optimization strategies\n            if \"strategy\" in data.columns:\n                strategy_results = data.groupby(\"strategy\").agg({\n                    \"objective_value\": [\"mean\", \"std\", \"min\", \"max\"],\n                    \"execution_time\": \"mean\",\n                    \"iteration_count\": \"mean\"\n                }).to_dict()\n                results[\"comparisons\"] = strategy_results\n                \n            # Identify bottlenecks\n            if \"constraint_violation\" in data.columns:\n                violations = data[data[\"constraint_violation\"] > 0]\n                if not violations.empty:\n                    results[\"bottlenecks\"] = [\n                        {\n                            \"constraint\": row[\"constraint_name\"],\n                            \"violation\": float(row[\"constraint_violation\"]),\n                            \"frequency\": float(len(violations) / len(data))\n                        }\n                        for _, row in violations.iterrows()\n                    ]\n                    \n        except Exception as e:\n            self.logger.error(f\"Error analyzing optimization results: {str(e)}\")\n            \n        return results\n        \n    def _calculate_optimization_impact(self, data: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"\n        Calculate optimization impact metrics\n        \n        Args:\n            data: Optimization data DataFrame\n            \n        Returns:\n            Dictionary of impact metrics\n        \"\"\"\n        impact = {}\n        \n        try:\n            # Calculate overall improvement\n            if all(col in data.columns for col in [\"before_value\", \"after_value\"]):\n                impact[\"overall_improvement\"] = float(\n                    (data[\"after_value\"].sum() - data[\"before_value\"].sum()) /\n                    data[\"before_value\"].sum()\n                )\n                \n            # Calculate success rate\n            if \"success\" in data.columns:\n                impact[\"success_rate\"] = float(\n                    data[\"success\"].mean()\n                )\n                \n            # Calculate resource savings\n            if all(col in data.columns for col in [\"before_resources\", \"after_resources\"]):\n                impact[\"resource_savings\"] = float(\n                    (data[\"before_resources\"].sum() - data[\"after_resources\"].sum()) /\n                    data[\"before_resources\"].sum()\n                )\n                \n            # Calculate cost savings\n            if all(col in data.columns for col in [\"before_cost\", \"after_cost\"]):\n                impact[\"cost_savings\"] = float(\n                    (data[\"before_cost\"].sum() - data[\"after_cost\"].sum()) /\n                    data[\"before_cost\"].sum()\n                )\n                \n            # Calculate time savings\n            if all(col in data.columns for col in [\"before_time\", \"after_time\"]):\n                impact[\"time_savings\"] = float(\n                    (data[\"before_time\"].sum() - data[\"after_time\"].sum()) /\n                    data[\"before_time\"].sum()\n                )\n                \n            # Calculate quality improvement\n            if all(col in data.columns for col in [\"before_quality\", \"after_quality\"]):\n                impact[\"quality_improvement\"] = float(\n                    (data[\"after_quality\"].mean() - data[\"before_quality\"].mean()) /\n                    data[\"before_quality\"].mean()\n                )\n                \n            # Normalize impact metrics to 0-1 range\n            for key in impact:\n                impact[key] = float(np.clip(impact[key], 0, 1))\n                \n        except Exception as e:\n            self.logger.error(f\"Error calculating optimization impact: {str(e)}\")\n            \n        return impact\n        \n    def _generate_optimization_insights(self,\n                                     results: Dict[str, Any],\n                                     impact: Dict[str, float]) -> List[str]:\n        \"\"\"\n        Generate insights from optimization analysis\n        \n        Args:\n            results: Optimization analysis results\n            impact: Impact metrics\n            \n        Returns:\n            List of optimization insights\n        \"\"\"\n        insights = []\n        \n        try:\n            # Results-based insights\n            if \"metrics\" in results:\n                metrics = results[\"metrics\"]\n                \n                if \"objective_improvement\" in metrics:\n                    improvement = metrics[\"objective_improvement\"]\n                    if improvement > 0.2:\n                        insights.append(\n                            f\"Significant objective improvement achieved: {improvement:.1%}\"\n                        )\n                        \n                if \"convergence_rate\" in metrics:\n                    conv_rate = metrics[\"convergence_rate\"]\n                    if conv_rate < 0.1:\n                        insights.append(\n                            f\"Slow convergence rate detected: {conv_rate:.3f}\"\n                        )\n                        \n            # Impact-based insights\n            for metric, value in impact.items():\n                if metric == \"overall_improvement\":\n                    if value > 0.2:\n                        insights.append(\n                            f\"Substantial overall improvement: {value:.1%}\"\n                        )\n                    elif value < 0.05:\n                        insights.append(\n                            f\"Limited overall improvement: {value:.1%}\"\n                        )\n                        \n                elif metric == \"resource_savings\":\n                    if value > 0.3:\n                        insights.append(\n                            f\"Significant resource savings achieved: {value:.1%}\"\n                        )\n                        \n                elif metric == \"cost_savings\":\n                    if value > 0.2:\n                        insights.append(\n                            f\"Notable cost savings realized: {value:.1%}\"\n                        )\n                        \n            # Strategy comparison insights\n            if \"comparisons\" in results:\n                comparisons = results[\"comparisons\"]\n                for strategy, stats in comparisons.items():\n                    if isinstance(stats, dict):\n                        mean_value = stats.get((\"objective_value\", \"mean\"))\n                        if mean_value is not None:\n                            insights.append(\n                                f\"Strategy {strategy} achieved mean objective \"\n                                f\"value of {mean_value:.2f}\"\n                            )\n                            \n            # Bottleneck insights\n            if \"bottlenecks\" in results:\n                for bottleneck in results[\"bottlenecks\"]:\n                    if bottleneck[\"frequency\"] > 0.1:\n                        insights.append(\n                            f\"Frequent constraint violation in {bottleneck['constraint']} \"\n                            f\"(frequency: {bottleneck['frequency']:.1%})\"\n                        )\n                        \n        except Exception as e:\n            self.logger.error(f\"Error generating optimization insights: {str(e)}\")\n            \n        return insights\n        \n    def _generate_optimization_recommendations(self,\n                                            results: Dict[str, Any]) -> List[str]:\n        \"\"\"\n        Generate recommendations based on optimization analysis\n        \n        Args:\n            results: Optimization analysis results\n            \n        Returns:\n            List of recommendations\n        \"\"\"\n        recommendations = []\n        \n        try:\n            # Convergence-based recommendations\n            if \"metrics\" in results:\n                metrics = results[\"metrics\"]\n                \n                if metrics.get(\"convergence_rate\", 1.0) < 0.1:\n                    recommendations.extend([\n                        \"Review and adjust optimization parameters\",\n                        \"Consider alternative optimization algorithms\",\n                        \"Implement adaptive parameter tuning\"\n                    ])\n                    \n                if metrics.get(\"objective_improvement\", 1.0) < 0.1:\n                    recommendations.extend([\n                        \"Explore different objective functions\",\n                        \"Review optimization constraints\",\n                        \"Consider multi-objective optimization\"\n                    ])\n                    \n            # Strategy-based recommendations\n            if \"comparisons\" in results:\n                comparisons = results[\"comparisons\"]\n                best_strategy = None\n                best_value = float(\"-inf\")\n                \n                for strategy, stats in comparisons.items():\n                    if isinstance(stats, dict):\n                        mean_value = stats.get((\"objective_value\", \"mean\"))\n                        if mean_value is not None and mean_value > best_value:\n                            best_strategy = strategy\n                            best_value = mean_value\n                            \n                if best_strategy:\n                    recommendations.append(\n                        f\"Consider using {best_strategy} as the primary optimization strategy\"\n                    )\n                    \n            # Bottleneck-based recommendations\n            if \"bottlenecks\" in results:\n                for bottleneck in results[\"bottlenecks\"]:\n                    if bottleneck[\"frequency\"] > 0.1:\n                        recommendations.extend([\n                            f\"Review and adjust {bottleneck['constraint']} constraints\",\n                            \"Implement constraint relaxation techniques\",\n                            \"Consider penalty-based approaches\"\n                        ])\n                        \n            # General recommendations\n            recommendations.extend([\n                \"Regularly monitor and tune optimization parameters\",\n                \"Implement automated parameter optimization\",\n                \"Consider hybrid optimization approaches\"\n            ])\n            \n        except Exception as e:\n            self.logger.error(f\"Error generating optimization recommendations: {str(e)}\")\n            \n        return recommendations\n        \n    def _calculate_optimization_confidence(self,\n                                        results: Dict[str, Any]) -> float:\n        \"\"\"\n        Calculate confidence score for optimization analysis\n        \n        Args:\n            results: Optimization analysis results\n            \n        Returns:\n            Confidence score between 0 and 1\n        \"\"\"\n        try:\n            confidence_scores = []\n            \n            # Check metrics completeness\n            if \"metrics\" in results:\n                expected_metrics = {\n                    \"objective_improvement\",\n                    \"convergence_rate\",\n                    \"avg_execution_time\"\n                }\n                available_metrics = set(results[\"metrics\"].keys())\n                metrics_completeness = len(available_metrics) / len(expected_metrics)\n                confidence_scores.append(metrics_completeness)\n                \n            # Check improvements data\n            if \"improvements\" in results:\n                improvements = results[\"improvements\"]\n                if isinstance(improvements, dict) and len(improvements) >= 4:\n                    confidence_scores.append(1.0)\n                else:\n                    confidence_scores.append(0.5)\n                    \n            # Check strategy comparisons\n            if \"comparisons\" in results:\n                comparisons = results[\"comparisons\"]\n                if comparisons and len(comparisons) >= 2:\n                    confidence_scores.append(1.0)\n                else:\n                    confidence_scores.append(0.5)\n                    \n            # Calculate overall confidence\n            if confidence_scores:\n                return float(np.mean(confidence_scores))\n                \n        except Exception as e:\n            self.logger.error(f\"Error calculating optimization confidence: {str(e)}\")\n            \n        return 0.0\n        \n    def _create_optimization_impact_plot(self,\n                                      impact: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"\n        Create optimization impact visualization\n        \n        Args:\n            impact: Impact metrics dictionary\n            \n        Returns:\n            Plotly figure dictionary\n        \"\"\"\n        try:\n            # Prepare data\n            metrics = list(impact.keys())\n            values = list(impact.values())\n            \n            # Create bar chart\n            fig = go.Figure(data=[\n                go.Bar(\n                    x=metrics,\n                    y=values,\n                    text=[f\"{v:.1%}\" for v in values],\n                    textposition=\"auto\"\n                )\n            ])\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Optimization Impact Analysis\",\n                xaxis_title=\"Metric\",\n                yaxis_title=\"Impact\",\n                yaxis_range=[0, 1],\n                showlegend=False,\n                width=800,\n                height=400\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating optimization impact plot: {str(e)}\")\n            return {}\n            \n    def _create_optimization_timeline(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"\n        Create optimization timeline visualization\n        \n        Args:\n            data: Optimization data DataFrame\n            \n        Returns:\n            Plotly figure dictionary\n        \"\"\"\n        try:\n            if \"timestamp\" not in data.columns:\n                return {}\n                \n            # Create figure with secondary y-axis\n            fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n            \n            # Add objective value trace\n            if \"objective_value\" in data.columns:\n                fig.add_trace(\n                    go.Scatter(\n                        x=data[\"timestamp\"],\n                        y=data[\"objective_value\"],\n                        name=\"Objective Value\",\n                        mode=\"lines+markers\"\n                    ),\n                    secondary_y=False\n                )\n                \n            # Add improvement trace\n            if all(col in data.columns for col in [\"before_value\", \"after_value\"]):\n                improvement = (data[\"after_value\"] - data[\"before_value\"]) / data[\"before_value\"]\n            fig.add_trace(\n                go.Scatter(\n                    x=data[\"timestamp\"],\n                    y=improvement,\n                    name=\"Improvement\",\n                    mode=\"lines+markers\"\n                ),\n                secondary_y=True\n            )\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Optimization Progress Timeline\",\n                xaxis_title=\"Time\",\n                showlegend=True,\n                width=800,\n                height=400\n            )\n            \n            # Update y-axes labels\n            fig.update_yaxes(title_text=\"Objective Value\", secondary_y=False)\n            fig.update_yaxes(title_text=\"Improvement\", secondary_y=True)\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating optimization timeline: {str(e)}\")\n            return {}\n        \n    def _add_quality_section(self) -> None:\n        \"\"\"Add quality analysis section to the report\"\"\"\n        if \"quality_data\" not in self.data_sources:\n            self.logger.warning(\"Quality data source not found, skipping quality section\")\n            return\n\n        try:\n            quality_data = self.data_sources[\"quality_data\"]\n            \n            # Calculate quality metrics\n            metrics = self._calculate_quality_metrics(quality_data)\n            \n            # Analyze quality trends\n            trends = self._analyze_quality_trends(quality_data)\n            \n            # Generate insights and recommendations\n            insights = self._generate_quality_insights(metrics, trends)\n            recommendations = self._generate_quality_recommendations(metrics, trends)\n            \n            # Create visualizations\n            visualizations = [\n                self._create_quality_metrics_plot(quality_data),\n                self._create_quality_trends_plot(quality_data),\n                self._create_quality_correlation_plot(quality_data)\n            ]\n            \n            # Calculate confidence score\n            confidence = self._calculate_quality_confidence(metrics, trends)\n            \n            # Add quality section\n            self.sections.append(ReportSection(\n                title=\"Quality Analysis\",\n                content={\n                    \"summary\": \"Analysis of data quality metrics and trends\",\n                    \"metrics\": metrics,\n                    \"trends\": trends\n                },\n                visualizations=visualizations,\n                insights=insights,\n                recommendations=recommendations,\n                confidence=confidence\n            ))\n            \n        except Exception as e:\n            self.logger.error(f\"Error adding quality section: {str(e)}\")\n            raise\n\n    def _calculate_quality_metrics(self, data: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"Calculate quality metrics from data\"\"\"\n        metrics = {}\n        \n        try:\n            # Calculate completeness\n            metrics[\"completeness\"] = self._calculate_completeness(data)\n            \n            # Calculate accuracy\n            metrics[\"accuracy\"] = self._calculate_accuracy(data)\n            \n            # Calculate consistency\n            metrics[\"consistency\"] = self._calculate_consistency(data)\n            \n            # Calculate timeliness\n            metrics[\"timeliness\"] = self._calculate_timeliness(data)\n            \n            # Calculate overall quality score\n            metrics[\"overall_quality\"] = np.mean([\n                metrics[\"completeness\"],\n                metrics[\"accuracy\"],\n                metrics[\"consistency\"],\n                metrics[\"timeliness\"]\n            ])\n            \n        except Exception as e:\n            self.logger.error(f\"Error calculating quality metrics: {str(e)}\")\n            raise\n            \n        return metrics\n\n    def _calculate_completeness(self, data: pd.DataFrame) -> float:\n        \"\"\"Calculate data completeness score\"\"\"\n        if data.empty:\n            return 0.0\n        \n        # Calculate percentage of non-null values\n        total_cells = data.shape[0] * data.shape[1]\n        non_null_cells = data.count().sum()\n        \n        return float(non_null_cells / total_cells)\n\n    def _calculate_accuracy(self, data: pd.DataFrame) -> float:\n        \"\"\"Calculate data accuracy score\"\"\"\n        if data.empty:\n            return 0.0\n        \n        accuracy_scores = []\n        \n        # Check numerical columns for outliers\n        numerical_columns = data.select_dtypes(include=[np.number]).columns\n        for column in numerical_columns:\n            values = data[column].dropna()\n            if len(values) > 0:\n                # Use z-score to detect outliers\n                z_scores = np.abs(stats.zscore(values))\n                accuracy_scores.append(np.mean(z_scores < 3))  # Consider values within 3 std dev as accurate\n            \n        # Check categorical columns for invalid values\n        categorical_columns = data.select_dtypes(include=[\"object\", \"category\"]).columns\n        for column in categorical_columns:\n            values = data[column].dropna()\n            if len(values) > 0:\n                # Check against expected values if available\n                if hasattr(self, \"expected_values\") and column in self.expected_values:\n                    valid_values = np.isin(values, self.expected_values[column])\n                    accuracy_scores.append(np.mean(valid_values))\n            \n        return float(np.mean(accuracy_scores)) if accuracy_scores else 0.0\n\n    def _calculate_consistency(self, data: pd.DataFrame) -> float:\n        \"\"\"Calculate data consistency score\"\"\"\n        if data.empty:\n            return 0.0\n        \n        consistency_scores = []\n        \n        # Check value distributions\n        numerical_columns = data.select_dtypes(include=[np.number]).columns\n        for column in numerical_columns:\n            values = data[column].dropna()\n            if len(values) > 1:\n                # Check for sudden changes in distribution\n                rolling_mean = values.rolling(window=min(10, len(values))).mean()\n                rolling_std = values.rolling(window=min(10, len(values))).std()\n                consistency = np.mean(np.abs(values - rolling_mean) <= 2 * rolling_std)\n                consistency_scores.append(consistency)\n            \n        # Check categorical value consistency\n        categorical_columns = data.select_dtypes(include=[\"object\", \"category\"]).columns\n        for column in categorical_columns:\n            values = data[column].dropna()\n            if len(values) > 1:\n                # Check value frequency stability\n                value_counts = values.value_counts(normalize=True)\n                consistency = 1 - np.std(value_counts)  # Lower variance = higher consistency\n                consistency_scores.append(consistency)\n            \n        return float(np.mean(consistency_scores)) if consistency_scores else 0.0\n\n    def _calculate_timeliness(self, data: pd.DataFrame) -> float:\n        \"\"\"Calculate data timeliness score\"\"\"\n        if data.empty:\n            return 0.0\n        \n        timeliness_scores = []\n        current_time = pd.Timestamp.now()\n        \n        # Check timestamp columns\n        timestamp_columns = [col for col in data.columns if \"time\" in col.lower() or \"date\" in col.lower()]\n        for column in timestamp_columns:\n            try:\n                timestamps = pd.to_datetime(data[column])\n                delays = (current_time - timestamps).total_seconds()\n                max_delay = np.percentile(delays, 95)  # Use 95th percentile as max delay\n                timeliness = np.mean(np.clip(1 - (delays / max_delay), 0, 1))\n                timeliness_scores.append(timeliness)\n            except:\n                continue\n            \n        return float(np.mean(timeliness_scores)) if timeliness_scores else 0.0\n\n    def _analyze_quality_trends(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Analyze trends in quality metrics\"\"\"\n        trends = {}\n        \n        try:\n            # Calculate metrics over time\n            timestamps = pd.date_range(\n                start=data.index.min(),\n                end=data.index.max(),\n                freq=\"D\"\n            )\n            \n            metric_trends = {\n                \"completeness\": [],\n                \"accuracy\": [],\n                \"consistency\": [],\n                \"timeliness\": []\n            }\n            \n            for timestamp in timestamps:\n                historical_data = data[data.index <= timestamp]\n                if not historical_data.empty:\n                    metrics = self._calculate_quality_metrics(historical_data)\n                    for metric, value in metrics.items():\n                        if metric != \"overall_quality\":\n                            metric_trends[metric].append(value)\n            \n            # Calculate trend statistics\n            for metric, values in metric_trends.items():\n                if len(values) > 1:\n                    trend = np.polyfit(range(len(values)), values, 1)[0]\n                    trends[metric] = {\n                        \"slope\": float(trend),\n                        \"direction\": \"improving\" if trend > 0 else \"degrading\",\n                        \"change_rate\": float(trend / np.mean(values)) if np.mean(values) != 0 else 0,\n                        \"stability\": float(1 - np.std(values))  # Higher stability = lower std dev\n                    }\n            \n        except Exception as e:\n            self.logger.error(f\"Error analyzing quality trends: {str(e)}\")\n            raise\n            \n        return trends\n\n    def _generate_quality_insights(self,\n                                   metrics: Dict[str, float],\n                                   trends: Dict[str, Any]) -> List[str]:\n        \"\"\"Generate insights from quality analysis\"\"\"\n        insights = []\n        \n        try:\n            # Overall quality insights\n            overall_quality = metrics[\"overall_quality\"]\n            if overall_quality >= 0.9:\n                insights.append(\"Data quality is excellent across all metrics\")\n            elif overall_quality >= 0.7:\n                insights.append(\"Data quality is good but has room for improvement\")\n            else:\n                insights.append(\"Data quality needs significant improvement\")\n            \n            # Metric-specific insights\n            for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n                value = metrics[metric]\n                trend = trends.get(metric, {})\n                \n                if value < 0.7:\n                    insights.append(f\"Low {metric} score ({value:.2%}) indicates potential issues\")\n                \n                if trend:\n                    if trend[\"direction\"] == \"improving\":\n                        insights.append(f\"{metric.title()} is showing improvement (rate: {trend['change_rate']:.2%})\")\n                    else:\n                        insights.append(f\"{metric.title()} is degrading (rate: {abs(trend['change_rate']):.2%})\")\n                    \n                    if trend[\"stability\"] < 0.7:\n                        insights.append(f\"{metric.title()} shows high variability\")\n            \n            # Correlation insights\n            correlations = self._generate_metric_correlations(metrics)\n            insights.extend(correlations)\n            \n            # Pattern insights\n            patterns = self._generate_trend_patterns(trends)\n            insights.extend(patterns)\n            \n        except Exception as e:\n            self.logger.error(f\"Error generating quality insights: {str(e)}\")\n            raise\n            \n        return insights\n\n    def _generate_quality_recommendations(self,\n                                      metrics: Dict[str, float],\n                                      trends: Dict[str, Any]) -> List[str]:\n        \"\"\"Generate recommendations for quality improvement\"\"\"\n        recommendations = []\n        \n        try:\n            # Completeness recommendations\n            if metrics[\"completeness\"] < 0.9:\n                recommendations.extend([\n                    \"Implement stricter data validation rules\",\n                    \"Review data collection processes for missing values\",\n                    \"Consider automated data completion techniques\"\n                ])\n            \n            # Accuracy recommendations\n            if metrics[\"accuracy\"] < 0.9:\n                recommendations.extend([\n                    \"Enhance data validation checks\",\n                    \"Implement outlier detection and handling\",\n                    \"Review and update data quality rules\"\n                ])\n            \n            # Consistency recommendations\n            if metrics[\"consistency\"] < 0.9:\n                recommendations.extend([\n                    \"Standardize data formats and validation\",\n                    \"Implement data normalization procedures\",\n                    \"Review data transformation processes\"\n                ])\n            \n            # Timeliness recommendations\n            if metrics[\"timeliness\"] < 0.9:\n                recommendations.extend([\n                    \"Optimize data processing pipeline\",\n                    \"Implement real-time data validation\",\n                    \"Review and improve data update frequency\"\n                ])\n            \n            # Trend-based recommendations\n            for metric, trend in trends.items():\n                if trend[\"direction\"] == \"degrading\":\n                    recommendations.append(\n                        f\"Investigate causes of {metric} degradation (rate: {abs(trend['change_rate']):.2%})\"\n                    )\n                if trend[\"stability\"] < 0.7:\n                    recommendations.append(\n                        f\"Implement stability measures for {metric}\"\n                    )\n            \n        except Exception as e:\n            self.logger.error(f\"Error generating quality recommendations: {str(e)}\")\n            raise\n            \n        return recommendations\n\n    def _create_quality_metrics_plot(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create visualization for quality metrics\"\"\"\n        try:\n            metrics = self._calculate_quality_metrics(data)\n            \n            # Create radar chart\n            fig = go.Figure()\n            \n            # Add metrics trace\n            fig.add_trace(go.Scatterpolar(\n                r=[metrics[m] for m in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]],\n                theta=[\"Completeness\", \"Accuracy\", \"Consistency\", \"Timeliness\"],\n                fill=\"toself\",\n                name=\"Current Metrics\"\n            ))\n            \n            # Update layout\n            fig.update_layout(\n                polar=dict(\n                    radialaxis=dict(\n                        visible=True,\n                        range=[0, 1]\n                    )\n                ),\n                showlegend=True\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating quality metrics plot: {str(e)}\")\n            return {}\n\n    def _create_quality_trends_plot(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create visualization for quality trends\"\"\"\n        try:\n            # Calculate metrics over time\n            timestamps = pd.date_range(\n                start=data.index.min(),\n                end=data.index.max(),\n                freq=\"D\"\n            )\n            \n            metric_values = {\n                \"completeness\": [],\n                \"accuracy\": [],\n                \"consistency\": [],\n                \"timeliness\": []\n            }\n            \n            for timestamp in timestamps:\n                historical_data = data[data.index <= timestamp]\n                if not historical_data.empty:\n                    metrics = self._calculate_quality_metrics(historical_data)\n                    for metric in metric_values.keys():\n                        metric_values[metric].append(metrics[metric])\n            \n            # Create line plot\n            fig = go.Figure()\n            \n            for metric, values in metric_values.items():\n                fig.add_trace(go.Scatter(\n                    x=timestamps,\n                    y=values,\n                    mode=\"lines+markers\",\n                    name=metric.title()\n                ))\n            \n            # Update layout\n            fig.update_layout(\n                xaxis_title=\"Time\",\n                yaxis_title=\"Score\",\n                yaxis_range=[0, 1],\n                showlegend=True\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating quality trends plot: {str(e)}\")\n            return {}\n\n    def _create_quality_correlation_plot(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create visualization for quality metric correlations\"\"\"\n        try:\n            # Calculate metrics over time\n            timestamps = pd.date_range(\n                start=data.index.min(),\n                end=data.index.max(),\n                freq=\"D\"\n            )\n            \n            metrics_df = pd.DataFrame(\n                index=timestamps,\n                columns=[\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]\n            )\n            \n            for timestamp in timestamps:\n                historical_data = data[data.index <= timestamp]\n                if not historical_data.empty:\n                    metrics = self._calculate_quality_metrics(historical_data)\n                    for metric in metrics_df.columns:\n                        metrics_df.loc[timestamp, metric] = metrics[metric]\n            \n            # Calculate correlation matrix\n            corr_matrix = metrics_df.corr()\n            \n            # Create heatmap\n            fig = go.Figure(data=go.Heatmap(\n                z=corr_matrix.values,\n                x=corr_matrix.columns,\n                y=corr_matrix.index,\n                colorscale=\"RdBu\",\n                zmin=-1,\n                zmax=1\n            ))\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Quality Metric Correlations\",\n                xaxis_title=\"Metric\",\n                yaxis_title=\"Metric\"\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating quality correlation plot: {str(e)}\")\n            return {}\n\n    def _calculate_quality_confidence(self,\n                                  metrics: Dict[str, float],\n                                  trends: Dict[str, Any]) -> float:\n        \"\"\"Calculate confidence score for quality analysis\"\"\"\n        try:\n            confidence_scores = []\n            \n            # Metric-based confidence\n            for metric in [\"completeness\", \"accuracy\", \"consistency\", \"timeliness\"]:\n                value = metrics[metric]\n                confidence_scores.append(value)  # Higher metric value = higher confidence\n            \n            # Trend-based confidence\n            for trend in trends.values():\n                stability = trend.get(\"stability\", 0)\n                confidence_scores.append(stability)  # Higher stability = higher confidence\n            \n            # Calculate overall confidence\n            return float(np.mean(confidence_scores))\n            \n        except Exception as e:\n            self.logger.error(f\"Error calculating quality confidence: {str(e)}\")\n            return 0.0\n\n    def _generate_metric_correlations(self,\n                                    metrics: Dict[str, Dict[str, float]]) -> List[str]:\n        \"\"\"\n        Generate insights about metric correlations\n        \n        Args:\n            metrics: Dictionary of metrics by category\n            \n        Returns:\n            List of correlation insights\n        \"\"\"\n        insights = []\n        \n        try:\n            # Convert metrics to DataFrame\n            df = pd.DataFrame()\n            for category, category_metrics in metrics.items():\n                for metric, value in category_metrics.items():\n                    df[f\"{category}_{metric}\"] = [value]\n            \n            # Calculate correlations\n            if len(df.columns) > 1:\n                corr_matrix = df.corr()\n                \n                # Find strong correlations\n                for i in range(len(corr_matrix.columns)):\n                    for j in range(i + 1, len(corr_matrix.columns)):\n                        col1, col2 = corr_matrix.columns[i], corr_matrix.columns[j]\n                        corr = corr_matrix.iloc[i, j]\n                        if abs(corr) > 0.7:\n                            metric1 = corr_matrix.columns[i]\n                            metric2 = corr_matrix.columns[j]\n                            direction = \"positive\" if corr > 0 else \"negative\"\n                            insights.append(\n                                f\"Strong {direction} correlation detected between {metric1} and {metric2}\"\n                            )\n            \n        except Exception as e:\n            self.logger.error(f\"Error generating metric correlations: {str(e)}\")\n            \n        return insights\n\n    def _generate_trend_patterns(self,\n                               trends: Dict[str, Dict[str, Any]]) -> List[str]:\n        \"\"\"\n        Generate insights about trend patterns\n        \n        Args:\n            trends: Dictionary of trend analysis by category\n            \n        Returns:\n            List of trend pattern insights\n        \"\"\"\n        insights = []\n        \n        try:\n            # Analyze trends by category\n            for category, category_trends in trends.items():\n                # Identify consistent trends\n                slopes = [t[\"slope\"] for t in category_trends.values()]\n                if all(s > 0.1 for s in slopes):\n                    insights.append(f\"Consistent improvement detected in {category} metrics\")\n                elif all(s < -0.1 for s in slopes):\n                    insights.append(f\"Consistent degradation detected in {category} metrics\")\n            \n            # Identify volatile metrics\n            for metric, trend in category_trends.items():\n                if trend.get(\"volatility\", 0) > 0.5:\n                    insights.append(f\"High volatility detected in {category} {metric}\")\n            \n            # Identify seasonal patterns\n            for metric, trend in category_trends.items():\n                if trend.get(\"seasonality\", False):\n                    insights.append(f\"Seasonal pattern detected in {category} {metric}\")\n            \n        except Exception as e:\n            self.logger.error(f\"Error generating trend patterns: {str(e)}\")\n            \n        return insights\n\n    def _add_anomaly_section(self) -> None:\n        \"\"\"Add anomaly analysis section to the report\"\"\"\n        if \"anomaly_data\" not in self.data_sources:\n            self.logger.warning(\"Anomaly data source not found, skipping anomaly section\")\n            return\n        \n        try:\n            anomaly_data = self.data_sources[\"anomaly_data\"]\n            \n            # Analyze anomalies\n            anomalies = self._analyze_anomalies(anomaly_data)\n            \n            # Calculate anomaly metrics\n            metrics = self._calculate_anomaly_metrics(anomalies)\n            \n            # Generate insights and recommendations\n            insights = self._generate_anomaly_insights(anomalies, metrics)\n            recommendations = self._generate_anomaly_recommendations(anomalies, metrics)\n            \n            # Create visualizations\n            visualizations = [\n                self._create_anomaly_timeline_plot(anomaly_data),\n                self._create_anomaly_distribution_plot(anomalies),\n                self._create_anomaly_severity_plot(anomalies)\n            ]\n            \n            # Calculate confidence score\n            confidence = self._calculate_anomaly_confidence(anomalies, metrics)\n            \n            # Add anomaly section\n            self.sections.append(ReportSection(\n                title=\"Anomaly Analysis\",\n                content={\n                    \"summary\": \"Analysis of detected anomalies and patterns\",\n                    \"anomalies\": anomalies,\n                    \"metrics\": metrics\n                },\n                visualizations=visualizations,\n                insights=insights,\n                recommendations=recommendations,\n                confidence=confidence\n            ))\n            \n        except Exception as e:\n            self.logger.error(f\"Error adding anomaly section: {str(e)}\")\n            raise\n\n    def _analyze_anomalies(self, data: pd.DataFrame) -> List[Dict[str, Any]]:\n        \"\"\"Analyze anomalies in the data\"\"\"\n        anomalies = []\n        \n        try:\n            # Group anomalies by type\n            if \"type\" in data.columns:\n                for anomaly_type in data[\"type\"].unique():\n                    type_data = data[data[\"type\"] == anomaly_type]\n                    \n                    # Calculate basic statistics\n                    stats = {\n                        \"count\": len(type_data),\n                        \"avg_severity\": float(type_data[\"severity\"].mean()),\n                        \"max_severity\": float(type_data[\"severity\"].max()),\n                        \"min_severity\": float(type_data[\"severity\"].min()),\n                        \"std_severity\": float(type_data[\"severity\"].std())\n                    }\n                    \n                    # Analyze temporal patterns\n                    if \"timestamp\" in type_data.columns:\n                        temporal_patterns = self._analyze_temporal_patterns(type_data)\n                        stats.update(temporal_patterns)\n                    \n                    # Analyze feature importance\n                    if \"features\" in type_data.columns:\n                        feature_importance = self._analyze_feature_importance(type_data)\n                        stats.update({\"feature_importance\": feature_importance})\n                    \n                    anomalies.append({\n                        \"type\": anomaly_type,\n                        \"statistics\": stats,\n                        \"examples\": type_data.head(3).to_dict(\"records\")\n                    })\n                    \n            # Analyze overall patterns\n            overall_patterns = self._analyze_anomaly_patterns(data)\n            if overall_patterns:\n                anomalies.append({\n                    \"type\": \"overall_patterns\",\n                    \"patterns\": overall_patterns\n                })\n                \n        except Exception as e:\n            self.logger.error(f\"Error analyzing anomalies: {str(e)}\")\n            raise\n        \n        return anomalies\n\n    def _calculate_anomaly_metrics(self, anomalies: List[Dict[str, Any]]) -> Dict[str, float]:\n        \"\"\"Calculate anomaly analysis metrics\"\"\"\n        metrics = {}\n        \n        try:\n            # Calculate overall metrics\n            total_anomalies = sum(a[\"statistics\"][\"count\"] for a in anomalies \n                                if \"statistics\" in a)\n            \n            metrics[\"total_anomalies\"] = total_anomalies\n            \n            if total_anomalies > 0:\n                # Calculate severity metrics\n                severity_scores = []\n                for anomaly in anomalies:\n                    if \"statistics\" in anomaly:\n                        severity_scores.extend([\n                            anomaly[\"statistics\"][\"avg_severity\"]\n                        ] * anomaly[\"statistics\"][\"count\"])\n                \n                metrics[\"avg_severity\"] = float(np.mean(severity_scores))\n                metrics[\"max_severity\"] = float(np.max(severity_scores))\n                metrics[\"severity_std\"] = float(np.std(severity_scores))\n                \n                # Calculate type distribution\n                type_counts = {\n                    a[\"type\"]: a[\"statistics\"][\"count\"]\n                    for a in anomalies if \"statistics\" in a\n                }\n                metrics[\"type_diversity\"] = float(\n                    len(type_counts) / total_anomalies\n                )\n                \n                # Calculate temporal metrics\n                temporal_scores = []\n                for anomaly in anomalies:\n                    if \"statistics\" in anomaly and \"temporal_density\" in anomaly[\"statistics\"]:\n                        temporal_scores.append(anomaly[\"statistics\"][\"temporal_density\"])\n                \n                if temporal_scores:\n                    metrics[\"temporal_density\"] = float(np.mean(temporal_scores))\n                \n        except Exception as e:\n            self.logger.error(f\"Error calculating anomaly metrics: {str(e)}\")\n            raise\n        \n        return metrics\n\n    def _analyze_temporal_patterns(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Analyze temporal patterns in anomaly data\"\"\"\n        patterns = {}\n        \n        try:\n            timestamps = pd.to_datetime(data[\"timestamp\"])\n            \n            # Calculate temporal density\n            time_range = (timestamps.max() - timestamps.min()).total_seconds()\n            if time_range > 0:\n                patterns[\"temporal_density\"] = float(len(timestamps) / time_range)\n            \n            # Analyze hourly distribution\n            hourly_counts = timestamps.dt.hour.value_counts(normalize=True)\n            peak_hours = hourly_counts[hourly_counts > hourly_counts.mean() + hourly_counts.std()]\n            \n            if not peak_hours.empty:\n                patterns[\"peak_hours\"] = list(peak_hours.index)\n                patterns[\"peak_hour_probability\"] = float(peak_hours.max())\n            \n            # Analyze daily patterns\n            daily_counts = timestamps.dt.day_name().value_counts(normalize=True)\n            peak_days = daily_counts[daily_counts > daily_counts.mean() + daily_counts.std()]\n            \n            if not peak_days.empty:\n                patterns[\"peak_days\"] = list(peak_days.index)\n                patterns[\"peak_day_probability\"] = float(peak_days.max())\n            \n        except Exception as e:\n            self.logger.error(f\"Error analyzing temporal patterns: {str(e)}\")\n        \n        return patterns\n\n    def _analyze_feature_importance(self, data: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"Analyze feature importance in anomalies\"\"\"\n        importance = {}\n        \n        try:\n            if isinstance(data[\"features\"].iloc[0], list):\n                # Count feature occurrences\n                feature_counts = {}\n                total_anomalies = len(data)\n                \n                for features in data[\"features\"]:\n                    for feature in features:\n                        feature_counts[feature] = feature_counts.get(feature, 0) + 1\n                \n                # Calculate importance scores\n                for feature, count in feature_counts.items():\n                    importance[feature] = float(count / total_anomalies)\n                \n        except Exception as e:\n            self.logger.error(f\"Error analyzing feature importance: {str(e)}\")\n        \n        return importance\n\n    def _analyze_anomaly_patterns(self, data: pd.DataFrame) -> List[Dict[str, Any]]:\n        \"\"\"Analyze overall patterns in anomaly data\"\"\"\n        patterns = []\n        \n        try:\n            # Analyze severity patterns\n            if \"severity\" in data.columns:\n                severity_trend = np.polyfit(range(len(data)), data[\"severity\"], 1)[0]\n                if abs(severity_trend) > 0.1:\n                    patterns.append({\n                        \"type\": \"severity_trend\",\n                        \"direction\": \"increasing\" if severity_trend > 0 else \"decreasing\",\n                        \"magnitude\": float(abs(severity_trend))\n            \n            # Analyze type co-occurrence\n            if \"type\" in data.columns and \"timestamp\" in data.columns:\n                type_pairs = []\n                for type1 in data[\"type\"].unique():\n                    for type2 in data[\"type\"].unique():\n                        if type1 < type2:\n                            cooccurrence = self._calculate_type_cooccurrence(\n                                data, type1, type2\n                            )\n                            if cooccurrence > 0.7:\n                                type_pairs.append({\n                                    \"types\": [type1, type2],\n                                    \"cooccurrence\": float(cooccurrence)\n                                })\n            \n            if type_pairs:\n                patterns.append({\n                    \"type\": \"type_cooccurrence\",\n                    \"pairs\": type_pairs\n                })\n                \n            # Analyze feature correlations\n            if \"features\" in data.columns and \"severity\" in data.columns:\n                feature_correlations = self._analyze_feature_correlations(data)\n                if feature_correlations:\n                    patterns.append({\n                        \"type\": \"feature_correlations\",\n                        \"correlations\": feature_correlations\n                    })\n                \n        except Exception as e:\n            self.logger.error(f\"Error analyzing anomaly patterns: {str(e)}\")\n        \n        return patterns\n\n    def _calculate_type_cooccurrence(self,\n                              data: pd.DataFrame,\n                              type1: str,\n                              type2: str) -> float:\n        \"\"\"Calculate co-occurrence probability of anomaly types\"\"\"\n        try:\n            # Group anomalies by time window (e.g., hour)\n            data[\"hour\"] = pd.to_datetime(data[\"timestamp\"]).dt.floor(\"H\")\n            \n            type1_hours = set(data[data[\"type\"] == type1][\"hour\"])\n            type2_hours = set(data[data[\"type\"] == type2][\"hour\"])\n            \n            if not type1_hours or not type2_hours:\n                return 0.0\n            \n            # Calculate Jaccard similarity\n            intersection = len(type1_hours & type2_hours)\n            union = len(type1_hours | type2_hours)\n            \n            return float(intersection / union) if union > 0 else 0.0\n            \n        except Exception as e:\n            self.logger.error(f\"Error calculating type co-occurrence: {str(e)}\")\n            return 0.0\n\n    def _analyze_feature_correlations(self, data: pd.DataFrame) -> List[Dict[str, Any]]:\n        \"\"\"Analyze correlations between features and severity\"\"\"\n        correlations = []\n        \n        try:\n            # Create feature matrix\n            feature_matrix = pd.DataFrame()\n            all_features = set()\n            \n            # Collect all unique features\n            for features in data[\"features\"]:\n                all_features.update(features)\n            \n            # Create binary feature columns\n            for feature in all_features:\n                feature_matrix[feature] = data[\"features\"].apply(\n                    lambda x: 1 if feature in x else 0\n                )\n            \n            # Calculate correlations with severity\n            for feature in all_features:\n                correlation = np.corrcoef(\n                    feature_matrix[feature],\n                    data[\"severity\"]\n                )[0, 1]\n                \n                if abs(correlation) > 0.3:  # Only include significant correlations\n                    correlations.append({\n                        \"feature\": feature,\n                        \"correlation\": float(correlation)\n                    })\n                \n        except Exception as e:\n            self.logger.error(f\"Error analyzing feature correlations: {str(e)}\")\n        \n        return correlations\n\n    def _generate_anomaly_insights(self,\n                           anomalies: List[Dict[str, Any]],\n                           metrics: Dict[str, float]) -> List[str]:\n        \"\"\"Generate insights from anomaly analysis\"\"\"\n        insights = []\n        \n        try:\n            # Overall insights\n            if metrics[\"total_anomalies\"] > 0:\n                insights.append(\n                    f\"Detected {metrics['total_anomalies']} anomalies with \"\n                    f\"average severity of {metrics['avg_severity']:.2f}\"\n                )\n                \n                if metrics[\"type_diversity\"] < 0.3:\n                    insights.append(\n                        \"Low anomaly type diversity indicates potential systematic issues\"\n                    )\n                \n                if metrics.get(\"temporal_density\", 0) > 0.7:\n                    insights.append(\n                        \"High temporal density of anomalies detected\"\n                    )\n            \n            # Type-specific insights\n            for anomaly in anomalies:\n                if \"statistics\" in anomaly:\n                    stats = anomaly[\"statistics\"]\n                    \n                    if stats[\"avg_severity\"] > 0.8:\n                        insights.append(\n                            f\"High severity {anomaly['type']} anomalies detected \"\n                            f\"(avg: {stats['avg_severity']:.2f})\"\n                        )\n                    \n                    if \"temporal_density\" in stats and stats[\"temporal_density\"] > 0.7:\n                        insights.append(\n                            f\"High frequency of {anomaly['type']} anomalies\"\n                        )\n                    \n                    if \"peak_hours\" in stats:\n                        hours = \", \".join(map(str, stats[\"peak_hours\"]))\n                        insights.append(\n                            f\"{anomaly['type']} anomalies peak during hours: {hours}\"\n                        )\n            \n            # Pattern insights\n            for anomaly in anomalies:\n                if anomaly[\"type\"] == \"overall_patterns\":\n                    for pattern in anomaly[\"patterns\"]:\n                        if pattern[\"type\"] == \"severity_trend\":\n                            insights.append(\n                                f\"Anomaly severity is {pattern['direction']} \"\n                                f\"(magnitude: {pattern['magnitude']:.2f})\"\n                            )\n                        elif pattern[\"type\"] == \"type_cooccurrence\":\n                            for pair in pattern[\"pairs\"]:\n                                types = \" and \".join(pair[\"types\"])\n                                insights.append(\n                                    f\"Strong co-occurrence between {types} \"\n                                    f\"({pair['cooccurrence']:.2f})\"\n                                )\n                                \n        except Exception as e:\n            self.logger.error(f\"Error generating anomaly insights: {str(e)}\")\n        \n        return insights\n\n    def _generate_anomaly_recommendations(self,\n                                  anomalies: List[Dict[str, Any]],\n                                  metrics: Dict[str, float]) -> List[str]:\n        \"\"\"Generate recommendations based on anomaly analysis\"\"\"\n        recommendations = []\n        \n        try:\n            # Overall recommendations\n            if metrics[\"total_anomalies\"] > 0:\n                if metrics[\"avg_severity\"] > 0.7:\n                    recommendations.extend([\n                        \"Implement enhanced anomaly detection mechanisms\",\n                        \"Review and update anomaly thresholds\",\n                        \"Consider automated response procedures\"\n                    ])\n                \n                if metrics[\"type_diversity\"] < 0.3:\n                    recommendations.extend([\n                        \"Investigate root causes of predominant anomaly types\",\n                        \"Review system components related to common anomalies\"\n                    ])\n                \n                if metrics.get(\"temporal_density\", 0) > 0.7:\n                    recommendations.extend([\n                        \"Implement rate limiting mechanisms\",\n                        \"Review system capacity and scaling policies\"\n                    ])\n            \n            # Type-specific recommendations\n            for anomaly in anomalies:\n                if \"statistics\" in anomaly:\n                    stats = anomaly[\"statistics\"]\n                    \n                    if stats[\"avg_severity\"] > 0.8:\n                        recommendations.append(\n                            f\"Prioritize investigation of {anomaly['type']} anomalies\"\n                        )\n                    \n                    if \"feature_importance\" in stats:\n                        features = sorted(\n                            stats[\"feature_importance\"].items(),\n                            key=lambda x: x[1],\n                            reverse=True\n                        )[:3]\n                        \n                        if features:\n                            feature_list = \", \".join(f[0] for f in features)\n                            recommendations.append(\n                                f\"Focus on monitoring {feature_list} for \"\n                                f\"{anomaly['type']} anomalies\"\n                            )\n            \n            # Pattern-based recommendations\n            for anomaly in anomalies:\n                if anomaly[\"type\"] == \"overall_patterns\":\n                    for pattern in anomaly[\"patterns\"]:\n                        if pattern[\"type\"] == \"severity_trend\":\n                            if pattern[\"direction\"] == \"increasing\":\n                                recommendations.extend([\n                                    \"Implement proactive monitoring measures\",\n                                    \"Review and adjust detection sensitivity\"\n                                ])\n                        elif pattern[\"type\"] == \"feature_correlations\":\n                            for corr in pattern[\"correlations\"]:\n                                if abs(corr[\"correlation\"]) > 0.7:\n                                    recommendations.append(\n                                        f\"Monitor {corr['feature']} closely due to \"\n                                        f\"strong correlation with anomaly severity\"\n                                    )\n                                \n        except Exception as e:\n            self.logger.error(f\"Error generating anomaly recommendations: {str(e)}\")\n        \n        return recommendations\n\n    def _create_anomaly_timeline_plot(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create timeline visualization of anomalies\"\"\"\n        try:\n            if \"timestamp\" not in data.columns:\n                return {}\n            \n            # Create figure\n            fig = go.Figure()\n            \n            # Add traces for each anomaly type\n            for anomaly_type in data[\"type\"].unique():\n                type_data = data[data[\"type\"] == anomaly_type]\n                \n                fig.add_trace(go.Scatter(\n                    x=type_data[\"timestamp\"],\n                    y=type_data[\"severity\"],\n                    mode=\"markers\",\n                    name=anomaly_type,\n                    marker=dict(\n                        size=10,\n                        symbol=\"circle\"\n                    )\n                ))\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Anomaly Timeline\",\n                xaxis_title=\"Time\",\n                yaxis_title=\"Severity\",\n                showlegend=True\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating anomaly timeline plot: {str(e)}\")\n            return {}\n\n    def _create_anomaly_distribution_plot(self, anomalies: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Create distribution visualization of anomalies\"\"\"\n        try:\n            # Prepare data\n            types = []\n            counts = []\n            severities = []\n            \n            for anomaly in anomalies:\n                if \"statistics\" in anomaly:\n                    types.append(anomaly[\"type\"])\n                    counts.append(anomaly[\"statistics\"][\"count\"])\n                    severities.append(anomaly[\"statistics\"][\"avg_severity\"])\n            \n            # Create figure\n            fig = go.Figure()\n            \n            # Add bar trace for counts\n            fig.add_trace(go.Bar(\n                x=types,\n                y=counts,\n                name=\"Count\",\n                marker_color=\"blue\"\n            ))\n            \n            # Add line trace for severity\n            fig.add_trace(go.Scatter(\n                x=types,\n                y=severities,\n                name=\"Avg Severity\",\n                yaxis=\"y2\",\n                mode=\"lines+markers\",\n                marker_color=\"red\"\n            ))\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Anomaly Distribution by Type\",\n                xaxis_title=\"Anomaly Type\",\n                yaxis_title=\"Count\",\n                yaxis2=dict(\n                    title=\"Average Severity\",\n                    overlaying=\"y\",\n                    side=\"right\"\n                ),\n                showlegend=True\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating anomaly distribution plot: {str(e)}\")\n            return {}\n\n    def _create_anomaly_severity_plot(self, anomalies: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Create severity analysis visualization\"\"\"\n        try:\n            # Prepare data\n            types = []\n            min_sev = []\n            avg_sev = []\n            max_sev = []\n            \n            for anomaly in anomalies:\n                if \"statistics\" in anomaly:\n                    types.append(anomaly[\"type\"])\n                    min_sev.append(anomaly[\"statistics\"][\"min_severity\"])\n                    avg_sev.append(anomaly[\"statistics\"][\"avg_severity\"])\n                    max_sev.append(anomaly[\"statistics\"][\"max_severity\"])\n            \n            # Create figure\n            fig = go.Figure()\n            \n            # Add box plot\n            for i in range(len(types)):\n                fig.add_trace(go.Box(\n                    name=types[i],\n                    y=[min_sev[i], avg_sev[i], max_sev[i]],\n                    boxpoints=\"all\",\n                    jitter=0.3,\n                    pointpos=-1.8\n                ))\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Anomaly Severity Analysis\",\n                yaxis_title=\"Severity\",\n                showlegend=False\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating anomaly severity plot: {str(e)}\")\n            return {}\n\n    def _calculate_anomaly_confidence(self,\n                              anomalies: List[Dict[str, Any]],\n                              metrics: Dict[str, float]) -> float:\n        \"\"\"Calculate confidence score for anomaly analysis\"\"\"\n        try:\n            confidence_scores = []\n            \n            # Data quality confidence\n            if metrics[\"total_anomalies\"] > 0:\n                confidence_scores.append(1.0)\n            else:\n                confidence_scores.append(0.5)\n            \n            # Severity confidence\n            if \"avg_severity\" in metrics:\n                severity_confidence = 1.0 - metrics[\"severity_std\"]\n                confidence_scores.append(severity_confidence)\n            \n            # Pattern confidence\n            pattern_confidence = 0.0\n            pattern_count = 0\n            \n            for anomaly in anomalies:\n                if anomaly[\"type\"] == \"overall_patterns\":\n                    for pattern in anomaly[\"patterns\"]:\n                        if pattern[\"type\"] == \"severity_trend\":\n                            pattern_confidence += pattern[\"magnitude\"]\n                            pattern_count += 1\n                        elif pattern[\"type\"] == \"type_cooccurrence\":\n                            pattern_confidence += max(\n                                pair[\"cooccurrence\"] for pair in pattern[\"pairs\"]\n                            )\n                            pattern_count += 1\n            \n            if pattern_count > 0:\n                confidence_scores.append(pattern_confidence / pattern_count)\n            \n            # Calculate overall confidence\n            return float(np.mean(confidence_scores)) if confidence_scores else 0.0\n            \n        except Exception as e:\n            self.logger.error(f\"Error calculating anomaly confidence: {str(e)}\")\n            return 0.0 \n\n    def _add_resource_section(self) -> None:\n        \"\"\"Add resource analysis section to the report\"\"\"\n        if \"resource_data\" not in self.data_sources:\n            self.logger.warning(\"Resource data not found in data sources\")\n            return\n\n        try:\n            data = pd.DataFrame(self.data_sources[\"resource_data\"])\n            \n            # Calculate resource metrics\n            metrics = self._calculate_resource_metrics(data)\n            \n            # Analyze resource trends\n            trends = self._analyze_resource_trends(data)\n            \n            # Analyze resource allocation\n            allocation = self._analyze_resource_allocation(data)\n            \n            # Detect resource bottlenecks\n            bottlenecks = self._detect_resource_bottlenecks(data)\n            \n            # Generate insights and recommendations\n            insights = self._generate_resource_insights(metrics, trends, bottlenecks)\n            recommendations = self._generate_resource_recommendations(metrics, trends, bottlenecks)\n            \n            # Create visualizations\n            visualizations = [\n                self._create_resource_usage_plot(data),\n                self._create_resource_trends_plot(data),\n                self._create_resource_allocation_plot(data),\n                self._create_resource_bottleneck_plot(data)\n            ]\n            \n            # Calculate confidence score\n            confidence = self._calculate_resource_confidence(metrics, trends, bottlenecks)\n            \n            # Add section to report\n            self.sections.append(ReportSection(\n                title=\"Resource Analysis\",\n                content={\n                    \"metrics\": metrics,\n                    \"trends\": trends,\n                    \"allocation\": allocation,\n                    \"bottlenecks\": bottlenecks\n                },\n                visualizations=visualizations,\n                insights=insights,\n                recommendations=recommendations,\n                confidence=confidence\n            ))\n            \n        except Exception as e:\n            self.logger.error(f\"Error in resource analysis: {str(e)}\")\n            raise\n\n    def _calculate_resource_metrics(self, data: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"Calculate resource utilization metrics\"\"\"\n        metrics = {}\n        \n        try:\n            # Calculate CPU utilization\n            if \"cpu_usage\" in data.columns:\n                metrics[\"cpu_utilization\"] = float(data[\"cpu_usage\"].mean())\n                metrics[\"cpu_peak\"] = float(data[\"cpu_usage\"].max())\n                metrics[\"cpu_stability\"] = 1.0 - float(data[\"cpu_usage\"].std())\n            \n            # Calculate memory utilization\n            if \"memory_usage\" in data.columns:\n                metrics[\"memory_utilization\"] = float(data[\"memory_usage\"].mean())\n                metrics[\"memory_peak\"] = float(data[\"memory_usage\"].max())\n                metrics[\"memory_stability\"] = 1.0 - float(data[\"memory_usage\"].std())\n            \n            # Calculate storage utilization\n            if \"storage_usage\" in data.columns:\n                metrics[\"storage_utilization\"] = float(data[\"storage_usage\"].mean())\n                metrics[\"storage_growth_rate\"] = float(np.gradient(data[\"storage_usage\"]).mean())\n            \n            # Calculate network utilization\n            if \"network_usage\" in data.columns:\n                metrics[\"network_utilization\"] = float(data[\"network_usage\"].mean())\n                metrics[\"network_peak\"] = float(data[\"network_usage\"].max())\n                metrics[\"network_stability\"] = 1.0 - float(data[\"network_usage\"].std())\n            \n            # Calculate overall resource efficiency\n            utilization_metrics = [v for k, v in metrics.items() if k.endswith(\"_utilization\")]\n            if utilization_metrics:\n                metrics[\"overall_efficiency\"] = float(np.mean(utilization_metrics))\n            \n            # Calculate resource balance\n            if len(utilization_metrics) > 1:\n                metrics[\"resource_balance\"] = 1.0 - float(np.std(utilization_metrics))\n            \n        except Exception as e:\n            self.logger.error(f\"Error calculating resource metrics: {str(e)}\")\n            \n        return metrics\n\n    def _analyze_resource_trends(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Analyze trends in resource utilization\"\"\"\n        trends = {}\n        \n        try:\n            # Analyze trends for each resource type\n            resource_types = [\"cpu_usage\", \"memory_usage\", \"storage_usage\", \"network_usage\"]\n            \n            for resource in resource_types:\n                if resource in data.columns:\n                    values = data[resource].values\n                    timestamps = pd.to_datetime(data[\"timestamp\"]) if \"timestamp\" in data.columns else None\n                    \n                    # Calculate trend using linear regression\n                    x = range(len(values))\n                    z = np.polyfit(x, values, 1)\n                    slope = float(z[0])\n                    \n                    # Calculate seasonality using FFT\n                    if len(values) >= 24:  # At least 24 data points for seasonality\n                        fft = np.fft.fft(values)\n                        frequencies = np.fft.fftfreq(len(values))\n                        magnitudes = np.abs(fft)\n                        peak_frequency_idx = np.argmax(magnitudes[1:]) + 1\n                        seasonality = float(1/frequencies[peak_frequency_idx]) if frequencies[peak_frequency_idx] != 0 else 0\n                    else:\n                        seasonality = 0\n                    \n                    # Calculate volatility\n                    volatility = float(np.std(values))\n                    \n                    trends[resource] = {\n                        \"slope\": slope,\n                        \"direction\": \"increasing\" if slope > 0 else \"decreasing\",\n                        \"seasonality\": seasonality,\n                        \"volatility\": volatility,\n                        \"trend_strength\": abs(slope) / (volatility + 1e-6)\n                    }\n                    \n                    # Add forecast if timestamps are available\n                    if timestamps is not None:\n                        forecast = np.poly1d(z)\n                        future_points = 5  # Forecast next 5 points\n                        future_x = range(len(values), len(values) + future_points)\n                        trends[resource][\"forecast\"] = [float(f) for f in forecast(future_x)]\n                        \n        except Exception as e:\n            self.logger.error(f\"Error analyzing resource trends: {str(e)}\")\n            \n        return trends\n\n    def _analyze_resource_allocation(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Analyze resource allocation patterns\"\"\"\n        allocation = {}\n        \n        try:\n            # Analyze resource distribution\n            resource_types = [\"cpu_usage\", \"memory_usage\", \"storage_usage\", \"network_usage\"]\n            \n            for resource in resource_types:\n                if resource in data.columns:\n                    values = data[resource].values\n                    \n                    allocation[resource] = {\n                        \"mean\": float(np.mean(values)),\n                        \"median\": float(np.median(values)),\n                        \"std\": float(np.std(values)),\n                        \"q25\": float(np.percentile(values, 25)),\n                        \"q75\": float(np.percentile(values, 75)),\n                        \"skewness\": float(stats.skew(values)),\n                        \"kurtosis\": float(stats.kurtosis(values))\n                    }\n                    \n                    # Analyze allocation patterns\n                    allocation[resource][\"patterns\"] = {\n                        \"underutilized\": float(np.mean(values < 0.3)),  # Less than 30% utilization\n                        \"optimal\": float(np.mean((values >= 0.3) & (values <= 0.7))),  # Between 30-70%\n                        \"overutilized\": float(np.mean(values > 0.7))  # More than 70% utilization\n                    }\n                    \n            # Calculate resource correlation matrix\n            if len(resource_types) > 1:\n                correlation_matrix = data[resource_types].corr()\n                allocation[\"correlations\"] = correlation_matrix.to_dict()\n                \n        except Exception as e:\n            self.logger.error(f\"Error analyzing resource allocation: {str(e)}\")\n            \n        return allocation\n\n    def _detect_resource_bottlenecks(self, data: pd.DataFrame) -> List[Dict[str, Any]]:\n        \"\"\"Detect resource bottlenecks and constraints\"\"\"\n        bottlenecks = []\n        \n        try:\n            resource_types = [\"cpu_usage\", \"memory_usage\", \"storage_usage\", \"network_usage\"]\n            \n            for resource in resource_types:\n                if resource in data.columns:\n                    values = data[resource].values\n                    timestamps = pd.to_datetime(data[\"timestamp\"]) if \"timestamp\" in data.columns else None\n                    \n                    # Detect high utilization periods\n                    high_utilization = values > 0.8  # Above 80% utilization\n                    if np.any(high_utilization):\n                        bottleneck = {\n                            \"resource\": resource,\n                            \"type\": \"high_utilization\",\n                            \"severity\": float(np.mean(values[high_utilization])),\n                            \"frequency\": float(np.mean(high_utilization)),\n                            \"duration\": int(np.sum(high_utilization))\n                        }\n                        \n                        if timestamps is not None:\n                            bottleneck[\"periods\"] = [\n                                {\n                                    \"start\": timestamps[i].isoformat(),\n                                    \"end\": timestamps[j].isoformat(),\n                                    \"duration\": j - i\n                                }\n                                for i, j in self._find_contiguous_periods(high_utilization)\n                            ]\n                        \n                        bottlenecks.append(bottleneck)\n                    \n                    # Detect resource exhaustion risks\n                    if np.mean(values) > 0.7 and np.std(values) < 0.1:\n                        bottlenecks.append({\n                            \"resource\": resource,\n                            \"type\": \"exhaustion_risk\",\n                            \"severity\": float(np.mean(values)),\n                            \"trend\": float(np.gradient(values).mean()),\n                            \"estimated_time_to_exhaustion\": self._estimate_time_to_exhaustion(values)\n                        })\n                        \n                    # Detect resource instability\n                    if np.std(values) > 0.2:\n                        bottlenecks.append({\n                            \"resource\": resource,\n                            \"type\": \"instability\",\n                            \"severity\": float(np.std(values)),\n                            \"frequency\": float(len(np.where(np.diff(values) > 0.2)[0])),\n                            \"impact\": float(np.max(values) - np.min(values))\n                        })\n                        \n        except Exception as e:\n            self.logger.error(f\"Error detecting resource bottlenecks: {str(e)}\")\n            \n        return bottlenecks\n\n    def _estimate_time_to_exhaustion(self, values: np.ndarray) -> float:\n        \"\"\"Estimate time to resource exhaustion based on trend and current usage\"\"\"\n        try:\n            # Calculate trend line\n            x = range(len(values))\n            z = np.polyfit(x, values, 1)\n            trend_line = np.poly1d(z)(x)\n            \n            # Calculate current deviation from trend\n            deviation = values[-1] - trend_line[-1]\n            \n            # Calculate time to exhaustion\n            time_to_exhaustion = deviation / np.gradient(trend_line)[-1]\n            \n            return float(time_to_exhaustion)\n            \n        except Exception as e:\n            self.logger.error(f\"Error estimating time to exhaustion: {str(e)}\")\n            return float(\"inf\")\n\n    def _find_contiguous_periods(self, mask: np.ndarray) -> List[Tuple[int, int]]:\n        \"\"\"Find contiguous periods in a boolean mask\"\"\"\n        periods = []\n        start = None\n        \n        for i, value in enumerate(mask):\n            if value and start is None:\n                start = i\n            elif not value and start is not None:\n                periods.append((start, i))\n                start = None\n                \n        if start is not None:\n            periods.append((start, len(mask)))\n            \n        return periods\n\n    def _generate_resource_insights(self,\n                            metrics: Dict[str, float],\n                            trends: Dict[str, Any],\n                            bottlenecks: List[Dict[str, Any]]) -> List[str]:\n        \"\"\"Generate insights from resource analysis\"\"\"\n        insights = []\n        \n        try:\n            # Overall efficiency insights\n            if \"overall_efficiency\" in metrics:\n                efficiency = metrics[\"overall_efficiency\"]\n                if efficiency > 0.8:\n                    insights.append(f\"High overall resource efficiency: {efficiency:.1%}\")\n                elif efficiency < 0.4:\n                    insights.append(f\"Low overall resource efficiency: {efficiency:.1%}\")\n            \n            # Resource balance insights\n            if \"resource_balance\" in metrics:\n                balance = metrics[\"resource_balance\"]\n                if balance < 0.6:\n                    insights.append(\"Significant imbalance detected in resource utilization\")\n            \n            # Resource-specific insights\n            for resource in [\"cpu\", \"memory\", \"storage\", \"network\"]:\n                utilization_key = f\"{resource}_utilization\"\n                peak_key = f\"{resource}_peak\"\n                stability_key = f\"{resource}_stability\"\n                \n                if utilization_key in metrics:\n                    utilization = metrics[utilization_key]\n                    if utilization > 0.8:\n                        insights.append(\n                            f\"High {resource} utilization detected: {utilization:.1%}\"\n                        )\n                    elif utilization < 0.2:\n                        insights.append(\n                            f\"Low {resource} utilization detected: {utilization:.1%}\"\n                        )\n                \n                if peak_key in metrics and stability_key in metrics:\n                    peak = metrics[peak_key]\n                    stability = metrics[stability_key]\n                    if peak > 0.9 and stability < 0.7:\n                        insights.append(\n                            f\"Unstable {resource} usage with high peaks detected\"\n                        )\n            \n            # Trend insights\n            for resource, trend in trends.items():\n                if trend[\"trend_strength\"] > 0.7:\n                    insights.append(\n                        f\"Strong {trend['direction']} trend detected in {resource}\"\n                    )\n                \n                if trend.get(\"seasonality\", 0) > 0:\n                    insights.append(\n                        f\"Seasonal pattern detected in {resource} \"\n                        f\"(period: {trend['seasonality']:.1f} units)\"\n                    )\n                \n                if trend[\"volatility\"] > 0.2:\n                    insights.append(\n                        f\"High volatility detected in {resource} usage\"\n                    )\n            \n            # Bottleneck insights\n            for bottleneck in bottlenecks:\n                if bottleneck[\"type\"] == \"high_utilization\":\n                    insights.append(\n                        f\"Frequent high utilization of {bottleneck['resource']} \"\n                        f\"(frequency: {bottleneck['frequency']:.1%})\"\n                    )\n                elif bottleneck[\"type\"] == \"exhaustion_risk\":\n                    insights.append(\n                        f\"Risk of {bottleneck['resource']} exhaustion detected \"\n                        f\"(severity: {bottleneck['severity']:.1%})\"\n                    )\n                elif bottleneck[\"type\"] == \"instability\":\n                    insights.append(\n                        f\"Unstable {bottleneck['resource']} usage detected \"\n                        f\"(impact: {bottleneck['impact']:.1%})\"\n                    )\n                    \n        except Exception as e:\n            self.logger.error(f\"Error generating resource insights: {str(e)}\")\n            \n        return insights\n\n    def _generate_resource_recommendations(self,\n                                   metrics: Dict[str, float],\n                                   trends: Dict[str, Any],\n                                   bottlenecks: List[Dict[str, Any]]) -> List[str]:\n        \"\"\"Generate recommendations based on resource analysis\"\"\"\n        recommendations = []\n        \n        try:\n            # Efficiency-based recommendations\n            if metrics.get(\"overall_efficiency\", 1.0) < 0.4:\n                recommendations.extend([\n                    \"Review resource allocation strategy\",\n                    \"Consider resource consolidation\",\n                    \"Implement automated scaling policies\"\n                ])\n            \n            # Balance-based recommendations\n            if metrics.get(\"resource_balance\", 1.0) < 0.6:\n                recommendations.extend([\n                    \"Optimize resource distribution\",\n                    \"Review workload placement strategy\",\n                    \"Consider load balancing solutions\"\n                ])\n            \n            # Resource-specific recommendations\n            for resource in [\"cpu\", \"memory\", \"storage\", \"network\"]:\n                utilization_key = f\"{resource}_utilization\"\n                stability_key = f\"{resource}_stability\"\n                \n                if utilization_key in metrics:\n                    utilization = metrics[utilization_key]\n                    if utilization > 0.8:\n                        recommendations.extend([\n                            f\"Scale up {resource} resources\",\n                            f\"Optimize {resource} intensive operations\",\n                            f\"Implement {resource} usage monitoring\"\n                        ])\n                    elif utilization < 0.2:\n                        recommendations.extend([\n                            f\"Consider reducing {resource} allocation\",\n                            f\"Review {resource} sizing strategy\"\n                        ])\n                \n                if stability_key in metrics and metrics[stability_key] < 0.7:\n                    recommendations.extend([\n                        f\"Implement {resource} usage smoothing\",\n                        f\"Review {resource} allocation policies\"\n                    ])\n            \n            # Trend-based recommendations\n            for resource, trend in trends.items():\n                if trend[\"direction\"] == \"increasing\" and trend[\"trend_strength\"] > 0.7:\n                    recommendations.extend([\n                        f\"Plan for {resource} capacity increase\",\n                        f\"Review {resource} growth patterns\",\n                        f\"Implement predictive scaling for {resource}\"\n                    ])\n                \n                if trend[\"volatility\"] > 0.2:\n                    recommendations.extend([\n                        f\"Implement {resource} usage stabilization\",\n                        f\"Review {resource} allocation strategy\"\n                    ])\n            \n            # Bottleneck-based recommendations\n            for bottleneck in bottlenecks:\n                if bottleneck[\"type\"] == \"high_utilization\":\n                    recommendations.extend([\n                        f\"Increase {bottleneck['resource']} capacity\",\n                        f\"Optimize {bottleneck['resource']} usage patterns\",\n                        f\"Implement peak usage handling\"\n                    ])\n                elif bottleneck[\"type\"] == \"exhaustion_risk\":\n                    recommendations.extend([\n                        f\"Plan for {bottleneck['resource']} expansion\",\n                        f\"Implement proactive scaling\",\n                        f\"Review resource forecasting\"\n                    ])\n                elif bottleneck[\"type\"] == \"instability\":\n                    recommendations.extend([\n                        f\"Stabilize {bottleneck['resource']} usage\",\n                        f\"Implement usage smoothing\",\n                        f\"Review workload distribution\"\n                    ])\n                    \n        except Exception as e:\n            self.logger.error(f\"Error generating resource recommendations: {str(e)}\")\n            \n        return recommendations\n\n    def _create_resource_usage_plot(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create resource usage visualization\"\"\"\n        try:\n            # Create figure with secondary y-axis\n            fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n            \n            # Add traces for each resource type\n            resource_types = [\"cpu_usage\", \"memory_usage\", \"storage_usage\", \"network_usage\"]\n            \n            for resource in resource_types:\n                if resource in data.columns:\n                    fig.add_trace(\n                        go.Scatter(\n                            x=data.index if data.index.name == \"timestamp\" else range(len(data)),\n                            y=data[resource],\n                            name=resource.replace(\"_\", \" \").title(),\n                            mode=\"lines\"\n                        ),\n                        secondary_y=False\n                    )\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Resource Usage Over Time\",\n                xaxis_title=\"Time\",\n                yaxis_title=\"Usage (%)\",\n                showlegend=True\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating resource usage plot: {str(e)}\")\n            return {}\n\n    def _create_resource_trends_plot(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create resource trends visualization\"\"\"\n        try:\n            # Create subplots for each resource type\n            resource_types = [\"cpu_usage\", \"memory_usage\", \"storage_usage\", \"network_usage\"]\n            present_resources = [r for r in resource_types if r in data.columns]\n            \n            if not present_resources:\n                return {}\n            \n            fig = make_subplots(\n                rows=len(present_resources),\n                cols=1,\n                subplot_titles=[r.replace(\"_\", \" \").title() for r in present_resources]\n            )\n            \n            for i, resource in enumerate(present_resources, 1):\n                values = data[resource].values\n                x = range(len(values))\n                \n                # Add actual values\n                fig.add_trace(\n                    go.Scatter(\n                        x=x,\n                        y=values,\n                        name=f\"{resource} Actual\",\n                        mode=\"lines\",\n                        line=dict(color=\"blue\")\n                    ),\n                    row=i,\n                    col=1\n                )\n                \n                # Add trend line\n                z = np.polyfit(x, values, 1)\n                trend_line = np.poly1d(z)(x)\n                fig.add_trace(\n                    go.Scatter(\n                        x=x,\n                        y=trend_line,\n                        name=f\"{resource} Trend\",\n                        mode=\"lines\",\n                        line=dict(color=\"red\", dash=\"dash\")\n                    ),\n                    row=i,\n                    col=1\n                )\n            \n            # Update layout\n            fig.update_layout(\n                height=300 * len(present_resources),\n                showlegend=True,\n                title=\"Resource Usage Trends\"\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating resource trends plot: {str(e)}\")\n            return {}\n\n    def _create_resource_allocation_plot(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create resource allocation visualization\"\"\"\n        try:\n            # Create figure\n            fig = go.Figure()\n            \n            # Add box plots for each resource type\n            resource_types = [\"cpu_usage\", \"memory_usage\", \"storage_usage\", \"network_usage\"]\n            \n            for resource in resource_types:\n                if resource in data.columns:\n                    fig.add_trace(go.Box(\n                        y=data[resource],\n                        name=resource.replace(\"_\", \" \").title(),\n                        boxpoints=\"outliers\"\n                    ))\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Resource Allocation Distribution\",\n                yaxis_title=\"Usage (%)\",\n                showlegend=False\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating resource allocation plot: {str(e)}\")\n            return {}\n\n    def _create_resource_bottleneck_plot(self, data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Create resource bottleneck visualization\"\"\"\n        try:\n            # Create figure\n            fig = go.Figure()\n            \n            # Add heatmap for resource bottlenecks\n            resource_types = [\"cpu_usage\", \"memory_usage\", \"storage_usage\", \"network_usage\"]\n            present_resources = [r for r in resource_types if r in data.columns]\n            \n            if not present_resources:\n                return {}\n            \n            # Calculate bottleneck scores\n            bottleneck_scores = np.zeros((len(present_resources), len(data)))\n            \n            for i, resource in enumerate(present_resources):\n                values = data[resource].values\n                # Score based on utilization and stability\n                utilization_score = values\n                stability_score = np.abs(np.gradient(values))\n                bottleneck_scores[i] = utilization_score * (1 + stability_score)\n            \n            # Create heatmap\n            fig.add_trace(go.Heatmap(\n                z=bottleneck_scores,\n                x=range(len(data)),\n                y=[r.replace(\"_\", \" \").title() for r in present_resources],\n                colorscale=\"RdYlBu_r\"\n            ))\n            \n            # Update layout\n            fig.update_layout(\n                title=\"Resource Bottleneck Analysis\",\n                xaxis_title=\"Time\",\n                yaxis_title=\"Resource Type\",\n                height=400\n            )\n            \n            return fig.to_dict()\n            \n        except Exception as e:\n            self.logger.error(f\"Error creating resource bottleneck plot: {str(e)}\")\n            return {}\n\n    def _calculate_resource_confidence(self,\n                               metrics: Dict[str, float],\n                               trends: Dict[str, Any],\n                               bottlenecks: List[Dict[str, Any]]) -> float:\n        \"\"\"Calculate confidence score for resource analysis\"\"\"\n        try:\n            confidence_scores = []\n            \n            # Metrics confidence\n            if metrics:\n                # Check completeness of metrics\n                expected_metrics = {\n                    \"cpu_utilization\", \"memory_utilization\",\n                    \"storage_utilization\", \"network_utilization\"\n                }\n                available_metrics = set(metrics.keys())\n                metrics_completeness = len(available_metrics & expected_metrics) / len(expected_metrics)\n                confidence_scores.append(metrics_completeness)\n                \n                # Check metric stability\n                stability_metrics = [v for k, v in metrics.items() if k.endswith(\"_stability\")]\n                if stability_metrics:\n                    confidence_scores.append(np.mean(stability_metrics))\n            \n            # Trends confidence\n            if trends:\n                for trend in trends.values():\n                    confidence_scores.append(min(1.0, trend[\"trend_strength\"]))\n                    if trend.get(\"seasonality\", 0) > 0:\n                        confidence_scores.append(0.8)  # Bonus for detected seasonality\n            \n            # Bottleneck confidence\n            if bottlenecks:\n                for bottleneck in bottlenecks:\n                    if bottleneck[\"type\"] == \"high_utilization\":\n                        confidence_scores.append(bottleneck[\"frequency\"])\n                    elif bottleneck[\"type\"] == \"exhaustion_risk\":\n                        confidence_scores.append(bottleneck[\"severity\"])\n            \n            # Calculate overall confidence\n            return float(np.mean(confidence_scores)) if confidence_scores else 0.0\n            \n        except Exception as e:\n            self.logger.error(f\"Error calculating resource confidence: {str(e)}\")\n            return 0.0"}
{"type": "source_file", "path": "setup.py", "content": "from setuptools import setup, find_packages\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n    long_description = fh.read()\n\nwith open(\"requirements.txt\", \"r\", encoding=\"utf-8\") as fh:\n    requirements = [line.strip() for line in fh if line.strip() and not line.startswith(\"#\")]\n\nsetup(\n    name=\"minesight\",\n    version=\"0.1.0\",\n    author=\"MineSight Team\",\n    author_email=\"team@minesight.ai\",\n    description=\"AI-Powered Mineral Exploration Platform\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/minesight/minesight\",\n    packages=find_packages(),\n    classifiers=[\n        \"Development Status :: 3 - Alpha\",\n        \"Intended Audience :: Science/Research\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    ],\n    python_requires=\">=3.8\",\n    install_requires=requirements,\n    entry_points={\n        \"console_scripts\": [\n            \"minesight-train=minesight.train:main\",\n            \"minesight-predict=minesight.predict:main\",\n        ],\n    },\n) "}
{"type": "source_file", "path": "minesight/scripts/load_sample_data.py", "content": "\"\"\"\nScript to load sample data for testing\n\"\"\"\nimport sys\nfrom pathlib import Path\nsys.path.append(str(Path(__file__).parent.parent.parent))\n\nfrom minesight.core.data.mineral_data import MineralDataset\n\ndef load_sample_data():\n    \"\"\"Load sample mineral deposits and geological features\"\"\"\n    dataset = MineralDataset()\n    \n    # Sample mineral deposits\n    deposits = [\n        {\n            \"latitude\": 35.6895,\n            \"longitude\": 139.6917,\n            \"mineral_type\": \"gold\",\n            \"is_confirmed\": True,\n            \"properties\": {\n                \"depth\": 500,\n                \"grade\": \"high\",\n                \"size\": \"medium\"\n            }\n        },\n        {\n            \"latitude\": 35.7100,\n            \"longitude\": 139.7100,\n            \"mineral_type\": \"copper\",\n            \"is_confirmed\": True,\n            \"properties\": {\n                \"depth\": 300,\n                \"grade\": \"medium\",\n                \"size\": \"large\"\n            }\n        },\n        {\n            \"latitude\": 35.6700,\n            \"longitude\": 139.6700,\n            \"mineral_type\": \"gold\",\n            \"is_confirmed\": False,\n            \"properties\": {\n                \"depth\": 800,\n                \"grade\": \"unknown\",\n                \"size\": \"unknown\"\n            }\n        }\n    ]\n    \n    # Sample geological features\n    features = [\n        {\n            \"latitude\": 35.6890,\n            \"longitude\": 139.6915,\n            \"feature_type\": \"fault\",\n            \"properties\": {\n                \"orientation\": \"NE-SW\",\n                \"length_km\": 5.2,\n                \"age\": \"mesozoic\"\n            }\n        },\n        {\n            \"latitude\": 35.6900,\n            \"longitude\": 139.6920,\n            \"feature_type\": \"intrusion\",\n            \"properties\": {\n                \"rock_type\": \"granite\",\n                \"age\": \"precambrian\",\n                \"size_km2\": 12.5\n            }\n        },\n        {\n            \"latitude\": 35.7000,\n            \"longitude\": 139.7000,\n            \"feature_type\": \"fold\",\n            \"properties\": {\n                \"type\": \"anticline\",\n                \"age\": \"paleozoic\",\n                \"length_km\": 8.3\n            }\n        }\n    ]\n    \n    # Add deposits\n    print(\"Adding sample deposits...\")\n    for deposit in deposits:\n        success = dataset.add_deposit(\n            latitude=deposit[\"latitude\"],\n            longitude=deposit[\"longitude\"],\n            mineral_type=deposit[\"mineral_type\"],\n            is_confirmed=deposit[\"is_confirmed\"],\n            properties=deposit[\"properties\"]\n        )\n        if success:\n            print(f\"Added {deposit['mineral_type']} deposit at ({deposit['latitude']}, {deposit['longitude']})\")\n    \n    # Add geological features\n    print(\"\\nAdding sample geological features...\")\n    for feature in features:\n        success = dataset.add_geological_feature(\n            latitude=feature[\"latitude\"],\n            longitude=feature[\"longitude\"],\n            feature_type=feature[\"feature_type\"],\n            properties=feature[\"properties\"]\n        )\n        if success:\n            print(f\"Added {feature['feature_type']} at ({feature['latitude']}, {feature['longitude']})\")\n    \n    # Save data\n    print(\"\\nSaving data...\")\n    dataset.save_data()\n    print(\"Sample data loaded successfully!\")\n\nif __name__ == \"__main__\":\n    load_sample_data() "}
{"type": "source_file", "path": "minesight/core/optimization/distributed.py", "content": "\"\"\"\nDistributed training utilities\n\"\"\"\nimport os\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom torch.nn.parallel import DistributedDataParallel\nfrom torch.utils.data.distributed import DistributedSampler\nfrom typing import Dict, Any, Optional, Callable\n\nclass DistributedTrainer:\n    \"\"\"Distributed training manager\"\"\"\n    \n    def __init__(self,\n                 model_fn: Callable,\n                 train_fn: Callable,\n                 world_size: int = None,\n                 backend: str = \"nccl\"):\n        \"\"\"\n        Initialize distributed trainer\n        \n        Args:\n            model_fn: Function to create model instance\n            train_fn: Function to train model\n            world_size: Number of processes (default: number of GPUs)\n            backend: Distributed backend (\"nccl\" or \"gloo\")\n        \"\"\"\n        self.model_fn = model_fn\n        self.train_fn = train_fn\n        self.world_size = world_size or torch.cuda.device_count()\n        self.backend = backend\n        \n    def setup(self, rank: int, world_size: int):\n        \"\"\"\n        Setup distributed training\n        \n        Args:\n            rank: Process rank\n            world_size: Number of processes\n        \"\"\"\n        os.environ['MASTER_ADDR'] = 'localhost'\n        os.environ['MASTER_PORT'] = '12355'\n        \n        # Initialize process group\n        dist.init_process_group(\n            backend=self.backend,\n            init_method='env://',\n            world_size=world_size,\n            rank=rank\n        )\n        \n    def cleanup(self):\n        \"\"\"Clean up distributed training\"\"\"\n        dist.destroy_process_group()\n        \n    def _train_worker(self,\n                     rank: int,\n                     world_size: int,\n                     model_config: Dict[str, Any],\n                     train_config: Dict[str, Any],\n                     data_config: Dict[str, Any]):\n        \"\"\"\n        Worker process for distributed training\n        \n        Args:\n            rank: Process rank\n            world_size: Number of processes\n            model_config: Model configuration\n            train_config: Training configuration\n            data_config: Data configuration\n        \"\"\"\n        # Setup distributed\n        self.setup(rank, world_size)\n        \n        # Create model\n        model = self.model_fn(**model_config)\n        model = model.to(rank)\n        \n        # Wrap model with DDP\n        model = DistributedDataParallel(\n            model,\n            device_ids=[rank],\n            output_device=rank\n        )\n        \n        # Update training config for distributed\n        train_config = train_config.copy()\n        train_config['device'] = rank\n        train_config['distributed'] = True\n        \n        try:\n            # Train model\n            self.train_fn(\n                model=model,\n                train_config=train_config,\n                data_config=data_config\n            )\n        finally:\n            self.cleanup()\n            \n    def train(self,\n              model_config: Dict[str, Any],\n              train_config: Dict[str, Any],\n              data_config: Dict[str, Any]):\n        \"\"\"\n        Start distributed training\n        \n        Args:\n            model_config: Model configuration\n            train_config: Training configuration\n            data_config: Data configuration\n        \"\"\"\n        mp.spawn(\n            self._train_worker,\n            args=(self.world_size, model_config, train_config, data_config),\n            nprocs=self.world_size,\n            join=True\n        )\n\nclass DistributedDataLoader:\n    \"\"\"Distributed data loader\"\"\"\n    \n    def __init__(self,\n                 dataset: torch.utils.data.Dataset,\n                 batch_size: int,\n                 rank: int,\n                 world_size: int,\n                 shuffle: bool = True,\n                 num_workers: int = 4,\n                 pin_memory: bool = True):\n        \"\"\"\n        Initialize distributed data loader\n        \n        Args:\n            dataset: Dataset\n            batch_size: Batch size per GPU\n            rank: Process rank\n            world_size: Number of processes\n            shuffle: Whether to shuffle data\n            num_workers: Number of worker processes\n            pin_memory: Whether to pin memory\n        \"\"\"\n        # Create sampler\n        self.sampler = DistributedSampler(\n            dataset,\n            num_replicas=world_size,\n            rank=rank,\n            shuffle=shuffle\n        )\n        \n        # Create data loader\n        self.loader = torch.utils.data.DataLoader(\n            dataset,\n            batch_size=batch_size,\n            sampler=self.sampler,\n            num_workers=num_workers,\n            pin_memory=pin_memory\n        )\n        \n    def __iter__(self):\n        \"\"\"Return iterator\"\"\"\n        return iter(self.loader)\n        \n    def __len__(self):\n        \"\"\"Return length\"\"\"\n        return len(self.loader)\n        \n    def set_epoch(self, epoch: int):\n        \"\"\"\n        Set epoch number for shuffling\n        \n        Args:\n            epoch: Epoch number\n        \"\"\"\n        self.sampler.set_epoch(epoch)\n\ndef setup_distributed_training(config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Setup configuration for distributed training\n    \n    Args:\n        config: Training configuration\n        \n    Returns:\n        Updated configuration\n    \"\"\"\n    # Get world size\n    world_size = torch.cuda.device_count()\n    if world_size <= 1:\n        return config\n        \n    # Update batch size and learning rate\n    config = config.copy()\n    config['batch_size'] *= world_size\n    config['learning_rate'] *= world_size\n    \n    # Add distributed settings\n    config['distributed'] = {\n        'world_size': world_size,\n        'backend': 'nccl' if torch.cuda.is_available() else 'gloo'\n    }\n    \n    return config\n\ndef is_distributed() -> bool:\n    \"\"\"Check if distributed training is enabled\"\"\"\n    return dist.is_available() and dist.is_initialized()\n\ndef get_rank() -> int:\n    \"\"\"Get process rank\"\"\"\n    return dist.get_rank() if is_distributed() else 0\n\ndef get_world_size() -> int:\n    \"\"\"Get world size\"\"\"\n    return dist.get_world_size() if is_distributed() else 1\n\ndef all_reduce(tensor: torch.Tensor,\n               op: Optional[dist.ReduceOp] = dist.ReduceOp.SUM):\n    \"\"\"\n    All-reduce operation\n    \n    Args:\n        tensor: Input tensor\n        op: Reduction operation\n    \"\"\"\n    if is_distributed():\n        dist.all_reduce(tensor, op=op)\n    return tensor\n\ndef all_gather(tensor: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    All-gather operation\n    \n    Args:\n        tensor: Input tensor\n        \n    Returns:\n        Gathered tensor\n    \"\"\"\n    if not is_distributed():\n        return tensor\n        \n    world_size = get_world_size()\n    tensors = [torch.zeros_like(tensor) for _ in range(world_size)]\n    dist.all_gather(tensors, tensor)\n    return torch.cat(tensors, dim=0)\n\ndef broadcast(tensor: torch.Tensor, src: int = 0):\n    \"\"\"\n    Broadcast operation\n    \n    Args:\n        tensor: Input tensor\n        src: Source rank\n    \"\"\"\n    if is_distributed():\n        dist.broadcast(tensor, src=src)\n    return tensor "}
