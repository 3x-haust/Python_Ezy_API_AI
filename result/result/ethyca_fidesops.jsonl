{"repo_info": {"repo_name": "fidesops", "repo_owner": "ethyca", "repo_url": "https://github.com/ethyca/fidesops"}}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/ops/__init__.py", "content": "\n"}
{"type": "test_file", "path": "tests/ops/api/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/ops/api/test_deps.py", "content": "import pytest\n\nfrom fidesops.ops.api.deps import get_cache, get_db\nfrom fidesops.ops.common_exceptions import FunctionalityNotConfigured\nfrom fidesops.ops.core import config\n\n\n@pytest.fixture\ndef mock_config():\n    db_enabled = config.config.database.enabled\n    redis_enabled = config.config.redis.enabled\n    config.config.database.enabled = False\n    config.config.redis.enabled = False\n    yield\n    config.config.database.enabled = db_enabled\n    config.config.redis.enabled = redis_enabled\n\n\n@pytest.mark.usefixtures(\"mock_config\")\ndef test_get_cache_not_enabled():\n    with pytest.raises(FunctionalityNotConfigured):\n        next(get_cache())\n\n\n@pytest.mark.usefixtures(\"mock_config\")\ndef test_get_db_not_enabled():\n    with pytest.raises(FunctionalityNotConfigured):\n        next(get_db())\n"}
{"type": "test_file", "path": "tests/ops/api/v1/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_config_endpoints.py", "content": "import pytest\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1 import scope_registry as scopes\nfrom fidesops.ops.api.v1 import urn_registry as urls\n\n\nclass TestGetConnections:\n    @pytest.fixture(scope=\"function\")\n    def url(self) -> str:\n        return urls.V1_URL_PREFIX + urls.CONFIG\n\n    def test_get_config(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[scopes.CONFIG_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 200\n\n        config = resp.json()\n        assert \"database\" in config\n        assert \"password\" not in config[\"database\"]\n        assert \"redis\" in config\n        assert \"password\" not in config[\"redis\"]\n        assert \"security\" in config\n        security_keys = set(config[\"security\"].keys())\n        assert (\n            len(\n                security_keys.difference(\n                    set(\n                        [\n                            \"cors_origins\",\n                            \"encoding\",\n                            \"oauth_access_token_expire_minutes\",\n                            \"subject_request_download_link_ttl_seconds\",\n                        ]\n                    )\n                )\n            )\n            == 0\n        )\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_connection_config_endpoints.py", "content": "import json\nfrom datetime import datetime\nfrom typing import Dict, List\nfrom unittest import mock\nfrom unittest.mock import Mock\n\nimport pytest\nfrom fastapi import HTTPException\nfrom fastapi_pagination import Params\nfrom fideslib.models.client import ClientDetail\nfrom sqlalchemy.orm import Session\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    CONNECTION_CREATE_OR_UPDATE,\n    CONNECTION_DELETE,\n    CONNECTION_READ,\n    STORAGE_DELETE,\n)\nfrom fidesops.ops.api.v1.urn_registry import CONNECTIONS, SAAS_CONFIG, V1_URL_PREFIX\nfrom fidesops.ops.graph.config import CollectionAddress\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig, ConnectionType\nfrom fidesops.ops.models.manual_webhook import AccessManualWebhook\nfrom fidesops.ops.models.policy import CurrentStep\nfrom fidesops.ops.models.privacy_request import (\n    CheckpointActionRequired,\n    ManualAction,\n    PrivacyRequestStatus,\n)\nfrom fidesops.ops.schemas.email.email import EmailActionType\nfrom fidesops.ops.tasks import EMAIL_QUEUE_NAME\n\npage_size = Params().size\n\n\nclass TestPatchConnections:\n    @pytest.fixture(scope=\"function\")\n    def url(self) -> str:\n        return V1_URL_PREFIX + CONNECTIONS\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self) -> List[Dict[str, str]]:\n        return [\n            {\n                \"name\": \"My Main Postgres DB\",\n                \"key\": \"postgres_db_1\",\n                \"connection_type\": \"postgres\",\n                \"access\": \"write\",\n            },\n            {\"name\": \"My Mongo DB\", \"connection_type\": \"mongodb\", \"access\": \"read\"},\n        ]\n\n    def test_patch_connections_not_authenticated(\n        self, api_client: TestClient, url, payload\n    ) -> None:\n        response = api_client.patch(url, headers={}, json=payload)\n        assert 401 == response.status_code\n\n    def test_patch_connections_incorrect_scope(\n        self, api_client: TestClient, generate_auth_header, url, payload\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[STORAGE_DELETE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n\n    def test_patch_connections_add_secret_invalid(\n        self, api_client: TestClient, generate_auth_header, url\n    ) -> None:\n        payload_with_secrets = [\n            {\n                \"name\": \"My Main Postgres DB\",\n                \"key\": \"postgres_db_1\",\n                \"connection_type\": \"postgres\",\n                \"access\": \"write\",\n                \"secrets\": {\"host\": \"localhost\"},\n            },\n            {\"name\": \"My Mongo DB\", \"connection_type\": \"mongodb\", \"access\": \"read\"},\n        ]\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload_with_secrets)\n        assert 422 == response.status_code\n        response_body = json.loads(response.text)\n        assert \"extra fields not permitted\" == response_body[\"detail\"][0][\"msg\"]\n\n    def test_patch_http_connection(\n        self, url, api_client, db: Session, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        payload = [\n            {\n                \"name\": \"My Post-Execution Webhook\",\n                \"key\": \"webhook_key\",\n                \"connection_type\": \"https\",\n                \"access\": \"read\",\n            }\n        ]\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n        body = json.loads(response.text)\n        assert body[\"succeeded\"][0][\"connection_type\"] == \"https\"\n        http_config = ConnectionConfig.get_by(db, field=\"key\", value=\"webhook_key\")\n        http_config.delete(db)\n\n    def test_patch_connections_bulk_create(\n        self, api_client: TestClient, db: Session, generate_auth_header, url, payload\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n\n        assert 200 == response.status_code\n        response_body = json.loads(response.text)\n        assert len(response_body) == 2\n        assert len(response_body[\"succeeded\"]) == 2\n\n        postgres_connection = response_body[\"succeeded\"][0]\n        postgres_resource = (\n            db.query(ConnectionConfig).filter_by(key=\"postgres_db_1\").first()\n        )\n        assert postgres_connection[\"name\"] == \"My Main Postgres DB\"\n        assert postgres_connection[\"key\"] == \"postgres_db_1\"\n        assert postgres_connection[\"connection_type\"] == \"postgres\"\n        assert postgres_connection[\"access\"] == \"write\"\n        assert postgres_connection[\"created_at\"] is not None\n        assert postgres_connection[\"updated_at\"] is not None\n        assert postgres_connection[\"last_test_timestamp\"] is None\n        assert postgres_connection[\"disabled\"] is False\n        assert \"secrets\" not in postgres_connection\n\n        mongo_connection = response_body[\"succeeded\"][1]\n        mongo_resource = db.query(ConnectionConfig).filter_by(key=\"my_mongo_db\").first()\n        assert mongo_connection[\"name\"] == \"My Mongo DB\"\n        assert mongo_connection[\"key\"] == \"my_mongo_db\"  # stringified name\n        assert mongo_connection[\"connection_type\"] == \"mongodb\"\n        assert mongo_connection[\"access\"] == \"read\"\n        assert postgres_connection[\"disabled\"] is False\n        assert mongo_connection[\"created_at\"] is not None\n        assert mongo_connection[\"updated_at\"] is not None\n        assert mongo_connection[\"last_test_timestamp\"] is None\n        assert \"secrets\" not in mongo_connection\n\n        assert response_body[\"failed\"] == []  # No failures\n\n        postgres_resource.delete(db)\n        mongo_resource.delete(db)\n\n    def test_patch_connections_bulk_update_key_error(\n        self, url, api_client: TestClient, generate_auth_header, payload\n    ) -> None:\n        # Create resources first\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        api_client.patch(url, headers=auth_header, json=payload)\n\n        # Update resources\n        response = api_client.patch(url, headers=auth_header, json=payload)\n\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 1\n        assert len(response_body[\"failed\"]) == 1\n\n        succeeded = response_body[\"succeeded\"]\n        failed = response_body[\"failed\"]\n\n        # key supplied matches existing key, so the rest of the configs are updated\n        assert succeeded[0][\"key\"] == \"postgres_db_1\"\n\n        # No key was supplied in request body, just a name, and that name turned into a key that exists\n        assert failed[0][\"data\"][\"key\"] is None\n        assert (\n            \"Key my_mongo_db already exists in ConnectionConfig\" in failed[0][\"message\"]\n        )\n\n    def test_patch_connections_bulk_create_limit_exceeded(\n        self, url, api_client: TestClient, db: Session, generate_auth_header\n    ):\n        payload = []\n        for i in range(0, 51):\n            payload.append(\n                {\n                    \"name\": f\"My Main Postgres DB {i}\",\n                    \"key\": f\"postgres_db_{i}\",\n                    \"connection_type\": \"postgres\",\n                    \"access\": \"read\",\n                }\n            )\n\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at most 50 items\"\n        )\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.connection_endpoints.queue_privacy_request\"\n    )\n    def test_disable_manual_webhook(\n        self,\n        mock_queue,\n        db,\n        url,\n        generate_auth_header,\n        api_client,\n        privacy_request_requires_input,\n        integration_manual_webhook_config,\n        access_manual_webhook,\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n\n        # Update resources\n        payload = [\n            {\n                \"name\": integration_manual_webhook_config.name,\n                \"key\": integration_manual_webhook_config.key,\n                \"connection_type\": ConnectionType.manual_webhook.value,\n                \"access\": \"write\",\n                \"disabled\": True,\n            }\n        ]\n\n        response = api_client.patch(\n            V1_URL_PREFIX + CONNECTIONS, headers=auth_header, json=payload\n        )\n\n        assert 200 == response.status_code\n\n        assert (\n            mock_queue.called\n        ), \"Disabling this last webhook caused 'requires_input' privacy requests to be queued\"\n        assert (\n            mock_queue.call_args.kwargs[\"privacy_request_id\"]\n            == privacy_request_requires_input.id\n        )\n        db.refresh(privacy_request_requires_input)\n        assert (\n            privacy_request_requires_input.status == PrivacyRequestStatus.in_processing\n        )\n\n    def test_patch_connections_bulk_update(\n        self, url, api_client: TestClient, db: Session, generate_auth_header, payload\n    ) -> None:\n        # Create resources first\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        api_client.patch(url, headers=auth_header, json=payload)\n\n        # Update resources\n        payload = [\n            {\n                \"name\": \"My Main Postgres DB\",\n                \"key\": \"postgres_db_1\",\n                \"connection_type\": \"postgres\",\n                \"access\": \"read\",\n                \"disabled\": True,\n            },\n            {\n                \"key\": \"my_mongo_db\",\n                \"name\": \"My Mongo DB\",\n                \"connection_type\": \"mongodb\",\n                \"access\": \"write\",\n            },\n            {\n                \"key\": \"my_mysql_db\",\n                \"name\": \"My MySQL DB\",\n                \"connection_type\": \"mysql\",\n                \"access\": \"read\",\n            },\n            {\n                \"key\": \"my_mssql_db\",\n                \"name\": \"My MsSQL DB\",\n                \"connection_type\": \"mssql\",\n                \"access\": \"write\",\n            },\n            {\n                \"key\": \"my_mariadb_db\",\n                \"name\": \"My MariaDB\",\n                \"connection_type\": \"mariadb\",\n                \"access\": \"write\",\n            },\n            {\n                \"key\": \"my_bigquery_db\",\n                \"name\": \"BigQuery Warehouse\",\n                \"connection_type\": \"bigquery\",\n                \"access\": \"write\",\n            },\n            {\n                \"key\": \"my_redshift_cluster\",\n                \"name\": \"My Amazon Redshift\",\n                \"connection_type\": \"redshift\",\n                \"access\": \"read\",\n            },\n            {\n                \"key\": \"my_snowflake\",\n                \"name\": \"Snowflake Warehouse\",\n                \"connection_type\": \"snowflake\",\n                \"access\": \"write\",\n                \"description\": \"Backup snowflake db\",\n            },\n            {\n                \"key\": \"email_connector\",\n                \"name\": \"Third Party Email Connector\",\n                \"connection_type\": \"email\",\n                \"access\": \"write\",\n            },\n            {\n                \"key\": \"manual_webhook_type\",\n                \"name\": \"Third Party Manual Webhook\",\n                \"connection_type\": \"manual_webhook\",\n                \"access\": \"read\",\n            },\n        ]\n\n        response = api_client.patch(\n            V1_URL_PREFIX + CONNECTIONS, headers=auth_header, json=payload\n        )\n\n        assert 200 == response.status_code\n        response_body = json.loads(response.text)\n        assert len(response_body) == 2\n        assert len(response_body[\"succeeded\"]) == 10\n        assert len(response_body[\"failed\"]) == 0\n\n        postgres_connection = response_body[\"succeeded\"][0]\n        assert postgres_connection[\"access\"] == \"read\"\n        assert postgres_connection[\"disabled\"] is True\n        assert \"secrets\" not in postgres_connection\n        assert postgres_connection[\"updated_at\"] is not None\n        postgres_resource = (\n            db.query(ConnectionConfig).filter_by(key=\"postgres_db_1\").first()\n        )\n        assert postgres_resource.access.value == \"read\"\n        assert postgres_resource.disabled\n\n        mongo_connection = response_body[\"succeeded\"][1]\n        assert mongo_connection[\"access\"] == \"write\"\n        assert mongo_connection[\"disabled\"] is False\n        assert mongo_connection[\"updated_at\"] is not None\n        mongo_resource = db.query(ConnectionConfig).filter_by(key=\"my_mongo_db\").first()\n        assert mongo_resource.access.value == \"write\"\n        assert \"secrets\" not in mongo_connection\n        assert not mongo_resource.disabled\n\n        mysql_connection = response_body[\"succeeded\"][2]\n        assert mysql_connection[\"access\"] == \"read\"\n        assert mysql_connection[\"updated_at\"] is not None\n        mysql_resource = db.query(ConnectionConfig).filter_by(key=\"my_mysql_db\").first()\n        assert mysql_resource.access.value == \"read\"\n        assert \"secrets\" not in mysql_connection\n\n        mssql_connection = response_body[\"succeeded\"][3]\n        assert mssql_connection[\"access\"] == \"write\"\n        assert mssql_connection[\"updated_at\"] is not None\n        mssql_resource = db.query(ConnectionConfig).filter_by(key=\"my_mssql_db\").first()\n        assert mssql_resource.access.value == \"write\"\n        assert \"secrets\" not in mssql_connection\n\n        mariadb_connection = response_body[\"succeeded\"][4]\n        assert mariadb_connection[\"access\"] == \"write\"\n        assert mariadb_connection[\"updated_at\"] is not None\n        mariadb_resource = (\n            db.query(ConnectionConfig).filter_by(key=\"my_mariadb_db\").first()\n        )\n        assert mariadb_resource.access.value == \"write\"\n        assert \"secrets\" not in mariadb_connection\n\n        bigquery_connection = response_body[\"succeeded\"][5]\n        assert bigquery_connection[\"access\"] == \"write\"\n        assert bigquery_connection[\"updated_at\"] is not None\n        bigquery_resource = (\n            db.query(ConnectionConfig).filter_by(key=\"my_bigquery_db\").first()\n        )\n        assert bigquery_resource.access.value == \"write\"\n        assert \"secrets\" not in bigquery_connection\n\n        redshift_connection = response_body[\"succeeded\"][6]\n        assert redshift_connection[\"access\"] == \"read\"\n        assert redshift_connection[\"updated_at\"] is not None\n        redshift_resource = (\n            db.query(ConnectionConfig).filter_by(key=\"my_redshift_cluster\").first()\n        )\n        assert redshift_resource.access.value == \"read\"\n        assert \"secrets\" not in redshift_connection\n\n        snowflake_connection = response_body[\"succeeded\"][7]\n        assert snowflake_connection[\"access\"] == \"write\"\n        assert snowflake_connection[\"updated_at\"] is not None\n        assert snowflake_connection[\"description\"] == \"Backup snowflake db\"\n        snowflake_resource = (\n            db.query(ConnectionConfig).filter_by(key=\"my_snowflake\").first()\n        )\n        assert snowflake_resource.access.value == \"write\"\n        assert snowflake_resource.description == \"Backup snowflake db\"\n        assert \"secrets\" not in snowflake_connection\n\n        email_connection = response_body[\"succeeded\"][8]\n        assert email_connection[\"access\"] == \"write\"\n        assert email_connection[\"updated_at\"] is not None\n        email_resource = (\n            db.query(ConnectionConfig).filter_by(key=\"email_connector\").first()\n        )\n        assert email_resource.access.value == \"write\"\n        assert \"secrets\" not in email_connection\n\n        manual_webhook_connection = response_body[\"succeeded\"][9]\n        assert manual_webhook_connection[\"access\"] == \"read\"\n        assert manual_webhook_connection[\"updated_at\"] is not None\n        manual_webhook_resource = (\n            db.query(ConnectionConfig).filter_by(key=\"manual_webhook_type\").first()\n        )\n        assert manual_webhook_resource.access.value == \"read\"\n        assert manual_webhook_resource.connection_type == ConnectionType.manual_webhook\n        assert \"secrets\" not in manual_webhook_connection\n\n        postgres_resource.delete(db)\n        mongo_resource.delete(db)\n        redshift_resource.delete(db)\n        snowflake_resource.delete(db)\n        mariadb_resource.delete(db)\n        mysql_resource.delete(db)\n        mssql_resource.delete(db)\n        bigquery_resource.delete(db)\n        email_resource.delete(db)\n        manual_webhook_resource.delete(db)\n\n    @mock.patch(\"fideslib.db.base_class.OrmWrappedFidesBase.create_or_update\")\n    def test_patch_connections_failed_response(\n        self, mock_create: Mock, api_client: TestClient, generate_auth_header, url\n    ) -> None:\n        mock_create.side_effect = HTTPException(mock.Mock(status=400), \"Test error\")\n\n        payload = [\n            {\n                \"name\": \"My Main Postgres DB\",\n                \"key\": \"postgres_db_1\",\n                \"connection_type\": \"postgres\",\n                \"access\": \"write\",\n            },\n            {\"name\": \"My Mongo DB\", \"connection_type\": \"mongodb\", \"access\": \"read\"},\n        ]\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert response.status_code == 200  # Returns 200 regardless\n        response_body = json.loads(response.text)\n        assert response_body[\"succeeded\"] == []\n        assert len(response_body[\"failed\"]) == 2\n\n        for failed_response in response_body[\"failed\"]:\n            assert (\n                \"This connection configuration could not be added\"\n                in failed_response[\"message\"]\n            )\n            assert set(failed_response.keys()) == {\"message\", \"data\"}\n\n        assert response_body[\"failed\"][0][\"data\"] == {\n            \"name\": \"My Main Postgres DB\",\n            \"key\": \"postgres_db_1\",\n            \"connection_type\": \"postgres\",\n            \"access\": \"write\",\n            \"disabled\": False,\n            \"description\": None,\n        }\n        assert response_body[\"failed\"][1][\"data\"] == {\n            \"name\": \"My Mongo DB\",\n            \"key\": None,\n            \"connection_type\": \"mongodb\",\n            \"access\": \"read\",\n            \"disabled\": False,\n            \"description\": None,\n        }\n\n    @mock.patch(\"fidesops.main.prepare_and_log_request\")\n    def test_patch_connections_incorrect_scope_analytics(\n        self,\n        mocked_prepare_and_log_request,\n        api_client: TestClient,\n        generate_auth_header,\n        payload,\n    ) -> None:\n        url = V1_URL_PREFIX + CONNECTIONS\n        auth_header = generate_auth_header(scopes=[STORAGE_DELETE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n        assert mocked_prepare_and_log_request.called\n        call_args = mocked_prepare_and_log_request._mock_call_args[0]\n\n        assert call_args[0] == \"PATCH: http://testserver/api/v1/connection\"\n        assert call_args[1] == \"testserver\"\n        assert call_args[2] == 403\n        assert isinstance(call_args[3], datetime)\n        assert call_args[4] is None\n        assert call_args[5] == \"HTTPException\"\n\n    @mock.patch(\"fidesops.main.prepare_and_log_request\")\n    def test_patch_http_connection_successful_analytics(\n        self,\n        mocked_prepare_and_log_request,\n        api_client,\n        db: Session,\n        generate_auth_header,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        payload = [\n            {\n                \"name\": \"My Post-Execution Webhook\",\n                \"key\": \"webhook_key\",\n                \"connection_type\": \"https\",\n                \"access\": \"read\",\n            }\n        ]\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n        body = json.loads(response.text)\n        assert body[\"succeeded\"][0][\"connection_type\"] == \"https\"\n        http_config = ConnectionConfig.get_by(db, field=\"key\", value=\"webhook_key\")\n        http_config.delete(db)\n\n        call_args = mocked_prepare_and_log_request._mock_call_args[0]\n\n        assert call_args[0] == \"PATCH: http://testserver/api/v1/connection\"\n        assert call_args[1] == \"testserver\"\n        assert call_args[2] == 200\n        assert isinstance(call_args[3], datetime)\n        assert call_args[4] is None\n        assert call_args[5] is None\n\n\nclass TestGetConnections:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + CONNECTIONS\n\n    def test_get_connections_not_authenticated(\n        self, api_client: TestClient, generate_auth_header, connection_config, url\n    ) -> None:\n        resp = api_client.get(url, headers={})\n        assert resp.status_code == 401\n\n    def test_get_connections_wrong_scope(\n        self, api_client: TestClient, generate_auth_header, connection_config, url\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[STORAGE_DELETE])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 403\n\n    def test_get_connection_configs(\n        self, api_client: TestClient, generate_auth_header, connection_config, url\n    ) -> None:\n        # Test get connection configs happy path\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 200\n\n        response_body = json.loads(resp.text)\n        assert len(response_body[\"items\"]) == 1\n        connection = response_body[\"items\"][0]\n        assert set(connection.keys()) == {\n            \"connection_type\",\n            \"access\",\n            \"updated_at\",\n            \"saas_config\",\n            \"name\",\n            \"last_test_timestamp\",\n            \"last_test_succeeded\",\n            \"key\",\n            \"created_at\",\n            \"disabled\",\n            \"description\",\n        }\n\n        assert connection[\"key\"] == \"my_postgres_db_1\"\n        assert connection[\"connection_type\"] == \"postgres\"\n        assert connection[\"access\"] == \"write\"\n        assert connection[\"updated_at\"] is not None\n        assert connection[\"last_test_timestamp\"] is None\n\n        assert response_body[\"total\"] == 1\n        assert response_body[\"page\"] == 1\n        assert response_body[\"size\"] == page_size\n\n    def test_filter_connections_disabled_and_type(\n        self,\n        db,\n        connection_config,\n        disabled_connection_config,\n        read_connection_config,\n        redshift_connection_config,\n        mongo_connection_config,\n        api_client,\n        generate_auth_header,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n\n        resp = api_client.get(url, headers=auth_header)\n        items = resp.json()[\"items\"]\n        assert len(items) == 5\n\n        resp = api_client.get(url + \"?connection_type=postgres\", headers=auth_header)\n        items = resp.json()[\"items\"]\n        assert len(items) == 3\n        assert all(\n            [con[\"connection_type\"] == \"postgres\" for con in resp.json()[\"items\"]]\n        )\n\n        resp = api_client.get(\n            url + \"?connection_type=postgres&connection_type=redshift\",\n            headers=auth_header,\n        )\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 4\n        assert all(\n            [\n                con[\"connection_type\"] in [\"redshift\", \"postgres\"]\n                for con in resp.json()[\"items\"]\n            ]\n        )\n\n        resp = api_client.get(\n            url + \"?connection_type=postgres&disabled=false\", headers=auth_header\n        )\n        assert resp.status_code == 200\n        items = resp.json()[\"items\"]\n        assert len(items) == 2\n        assert all(\n            [con[\"connection_type\"] in [\"postgres\"] for con in resp.json()[\"items\"]]\n        )\n        assert all([con[\"disabled\"] is False for con in resp.json()[\"items\"]])\n\n        resp = api_client.get(\n            url + \"?connection_type=postgres&disabled=True\", headers=auth_header\n        )\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 1\n        assert all(\n            [con[\"connection_type\"] in [\"postgres\"] for con in resp.json()[\"items\"]]\n        )\n        assert all([con[\"disabled\"] is True for con in resp.json()[\"items\"]])\n\n    def test_filter_test_status(\n        self,\n        db,\n        connection_config,\n        disabled_connection_config,\n        read_connection_config,\n        redshift_connection_config,\n        mongo_connection_config,\n        api_client,\n        generate_auth_header,\n        url,\n    ):\n        mongo_connection_config.last_test_succeeded = True\n        mongo_connection_config.save(db)\n        redshift_connection_config.last_test_succeeded = False\n        redshift_connection_config.save(db)\n\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.get(url + \"?test_status=passed\", headers=auth_header)\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 1\n        assert items[0][\"last_test_succeeded\"] is True\n        assert items[0][\"key\"] == mongo_connection_config.key\n\n        resp = api_client.get(url + \"?test_status=failed\", headers=auth_header)\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 1\n        assert items[0][\"last_test_succeeded\"] is False\n        assert items[0][\"key\"] == redshift_connection_config.key\n\n        resp = api_client.get(url + \"?test_status=untested\", headers=auth_header)\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 3\n        assert [item[\"last_test_succeeded\"] is None for item in items]\n\n    @pytest.mark.integration_saas\n    @pytest.mark.integration_stripe\n    def test_filter_system_type(\n        self,\n        db,\n        connection_config,\n        disabled_connection_config,\n        read_connection_config,\n        redshift_connection_config,\n        mongo_connection_config,\n        api_client,\n        generate_auth_header,\n        stripe_connection_config,\n        integration_manual_config,\n        url,\n    ):\n\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.get(url + \"?system_type=saas\", headers=auth_header)\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 1\n        assert items[0][\"connection_type\"] == \"saas\"\n        assert items[0][\"key\"] == stripe_connection_config.key\n        assert items[0][\"saas_config\"][\"type\"] == \"stripe\"\n\n        resp = api_client.get(url + \"?system_type=database\", headers=auth_header)\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 5\n\n        resp = api_client.get(url + \"?system_type=manual\", headers=auth_header)\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 1\n        assert items[0][\"connection_type\"] == \"manual\"\n        assert items[0][\"key\"] == integration_manual_config.key\n\n        # Conflicting filters\n        resp = api_client.get(\n            url + \"?system_type=saas&connection_type=mongodb\", headers=auth_header\n        )\n        items = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(items) == 0\n\n    def test_search_connections(\n        self,\n        db,\n        connection_config,\n        read_connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n\n        resp = api_client.get(url + \"?search=primary\", headers=auth_header)\n        assert resp.status_code == 200\n        assert len(resp.json()[\"items\"]) == 1\n        assert \"primary\" in resp.json()[\"items\"][0][\"description\"].lower()\n\n        resp = api_client.get(url + \"?search=read\", headers=auth_header)\n        assert resp.status_code == 200\n        assert len(resp.json()[\"items\"]) == 1\n        assert \"read\" in resp.json()[\"items\"][0][\"description\"].lower()\n\n        resp = api_client.get(url + \"?search=nonexistent\", headers=auth_header)\n        assert resp.status_code == 200\n        assert len(resp.json()[\"items\"]) == 0\n\n        resp = api_client.get(url + \"?search=postgres\", headers=auth_header)\n        assert resp.status_code == 200\n        items = resp.json()[\"items\"]\n        assert len(items) == 2\n\n        ordered = (\n            db.query(ConnectionConfig)\n            .filter(\n                ConnectionConfig.key.in_(\n                    [read_connection_config.key, connection_config.key]\n                )\n            )\n            .order_by(ConnectionConfig.name.asc())\n            .all()\n        )\n        assert len(ordered) == 2\n        assert ordered[0].key == items[0][\"key\"]\n        assert ordered[1].key == items[1][\"key\"]\n\n\nclass TestGetConnection:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy, connection_config) -> str:\n        return f\"{V1_URL_PREFIX}{CONNECTIONS}/{connection_config.key}\"\n\n    def test_get_connection_not_authenticated(\n        self, url, api_client: TestClient, connection_config\n    ) -> None:\n        resp = api_client.get(url, headers={})\n        assert resp.status_code == 401\n\n    def test_get_connection_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header, connection_config\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[STORAGE_DELETE])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 403\n\n    def test_get_connection_does_not_exist(\n        self, api_client: TestClient, generate_auth_header, connection_config\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.get(\n            f\"{V1_URL_PREFIX}{CONNECTIONS}/this_is_a_nonexistent_key\",\n            headers=auth_header,\n        )\n        assert resp.status_code == 404\n\n    def test_get_connection_config(\n        self, url, api_client: TestClient, generate_auth_header, connection_config\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 200\n\n        response_body = json.loads(resp.text)\n        assert set(response_body.keys()) == {\n            \"connection_type\",\n            \"access\",\n            \"updated_at\",\n            \"name\",\n            \"last_test_timestamp\",\n            \"last_test_succeeded\",\n            \"key\",\n            \"created_at\",\n            \"disabled\",\n            \"description\",\n            \"saas_config\",\n        }\n\n        assert response_body[\"key\"] == \"my_postgres_db_1\"\n        assert response_body[\"connection_type\"] == \"postgres\"\n        assert response_body[\"access\"] == \"write\"\n        assert response_body[\"updated_at\"] is not None\n        assert response_body[\"last_test_timestamp\"] is None\n\n\nclass TestDeleteConnection:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy, connection_config) -> str:\n        return f\"{V1_URL_PREFIX}{CONNECTIONS}/{connection_config.key}\"\n\n    def test_delete_connection_config_not_authenticated(\n        self, url, api_client: TestClient, generate_auth_header, connection_config\n    ) -> None:\n        # Test not authenticated\n        resp = api_client.delete(url, headers={})\n        assert resp.status_code == 401\n\n    def test_delete_connection_config_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header, connection_config\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.delete(url, headers=auth_header)\n        assert resp.status_code == 403\n\n    def test_delete_connection_config_does_not_exist(\n        self, api_client: TestClient, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_DELETE])\n        resp = api_client.delete(\n            f\"{V1_URL_PREFIX}{CONNECTIONS}/non_existent_config\", headers=auth_header\n        )\n        assert resp.status_code == 404\n\n    def test_delete_connection_config(\n        self,\n        url,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        connection_config,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_DELETE])\n        resp = api_client.delete(url, headers=auth_header)\n        assert resp.status_code == 204\n\n        assert (\n            db.query(ConnectionConfig).filter_by(key=connection_config.key).first()\n            is None\n        )\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.connection_endpoints.queue_privacy_request\"\n    )\n    def test_delete_manual_webhook_connection_config(\n        self,\n        mock_queue,\n        url,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        integration_manual_webhook_config,\n        access_manual_webhook,\n        privacy_request_requires_input,\n    ) -> None:\n        \"\"\"Assert both the connection config and its webhook are deleted\"\"\"\n        assert (\n            db.query(AccessManualWebhook).filter_by(id=access_manual_webhook.id).first()\n            is not None\n        )\n\n        assert (\n            db.query(ConnectionConfig)\n            .filter_by(key=integration_manual_webhook_config.key)\n            .first()\n            is not None\n        )\n\n        url = f\"{V1_URL_PREFIX}{CONNECTIONS}/{integration_manual_webhook_config.key}\"\n        auth_header = generate_auth_header(scopes=[CONNECTION_DELETE])\n        resp = api_client.delete(url, headers=auth_header)\n        assert resp.status_code == 204\n\n        assert (\n            db.query(AccessManualWebhook).filter_by(id=access_manual_webhook.id).first()\n            is None\n        )\n\n        assert (\n            db.query(ConnectionConfig)\n            .filter_by(key=integration_manual_webhook_config.key)\n            .first()\n            is None\n        )\n        assert (\n            mock_queue.called\n        ), \"Deleting this last webhook caused 'requires_input' privacy requests to be queued\"\n        assert (\n            mock_queue.call_args.kwargs[\"privacy_request_id\"]\n            == privacy_request_requires_input.id\n        )\n        db.refresh(privacy_request_requires_input)\n        assert (\n            privacy_request_requires_input.status == PrivacyRequestStatus.in_processing\n        )\n\n\nclass TestPutConnectionConfigSecrets:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy, connection_config) -> str:\n        return f\"{V1_URL_PREFIX}{CONNECTIONS}/{connection_config.key}/secret\"\n\n    def test_put_connection_config_secrets_not_authenticated(\n        self, url, api_client: TestClient, generate_auth_header, connection_config\n    ) -> None:\n        resp = api_client.put(url, headers={})\n        assert resp.status_code == 401\n\n    def test_put_connection_config_secrets_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header, connection_config\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_put_connection_config_secrets_invalid_config(\n        self, api_client: TestClient, generate_auth_header, connection_config\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        resp = api_client.put(\n            f\"{V1_URL_PREFIX}{CONNECTIONS}/this_is_not_a_known_key/secret\",\n            headers=auth_header,\n            json={},\n        )\n        assert resp.status_code == 404\n\n    def test_put_connection_config_secrets_schema_validation(\n        self, url, api_client: TestClient, generate_auth_header, connection_config\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        payload = {\"incorrect_postgres_uri_component\": \"test-1\"}\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 422\n        assert json.loads(resp.text)[\"detail\"][0][\"msg\"] == \"extra fields not permitted\"\n\n        payload = {\"dbname\": \"my_db\"}\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 422\n        assert (\n            json.loads(resp.text)[\"detail\"][0][\"msg\"]\n            == \"PostgreSQLSchema must be supplied a 'url' or all of: ['host'].\"\n        )\n\n        payload = {\"port\": \"cannot be turned into an integer\"}\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 422\n        assert (\n            json.loads(resp.text)[\"detail\"][0][\"msg\"] == \"value is not a valid integer\"\n        )\n\n    def test_put_connection_config_secrets(\n        self,\n        url,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        connection_config,\n    ) -> None:\n        \"\"\"Note: this test does not attempt to actually connect to the db, via use of verify query param.\"\"\"\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        payload = {\"host\": \"localhost\", \"port\": \"1234\", \"dbname\": \"my_test_db\"}\n        resp = api_client.put(\n            url + \"?verify=False\",\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 200\n        assert (\n            json.loads(resp.text)[\"msg\"]\n            == f\"Secrets updated for ConnectionConfig with key: {connection_config.key}.\"\n        )\n        db.refresh(connection_config)\n        assert connection_config.secrets == {\n            \"host\": \"localhost\",\n            \"port\": 1234,\n            \"dbname\": \"my_test_db\",\n            \"username\": None,\n            \"password\": None,\n            \"url\": None,\n            \"db_schema\": None,\n        }\n\n        payload = {\"url\": \"postgresql://test_user:test_pass@localhost:1234/my_test_db\"}\n        resp = api_client.put(\n            url + \"?verify=False\",\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 200\n        assert (\n            json.loads(resp.text)[\"msg\"]\n            == f\"Secrets updated for ConnectionConfig with key: {connection_config.key}.\"\n        )\n        db.refresh(connection_config)\n        assert connection_config.secrets == {\n            \"host\": None,\n            \"port\": None,\n            \"dbname\": None,\n            \"username\": None,\n            \"password\": None,\n            \"url\": payload[\"url\"],\n            \"db_schema\": None,\n        }\n        assert connection_config.last_test_timestamp is None\n        assert connection_config.last_test_succeeded is None\n\n    def test_put_connection_config_redshift_secrets(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        redshift_connection_config,\n    ) -> None:\n        \"\"\"Note: this test does not attempt to actually connect to the db, via use of verify query param.\"\"\"\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        url = f\"{V1_URL_PREFIX}{CONNECTIONS}/{redshift_connection_config.key}/secret\"\n        payload = {\n            \"host\": \"examplecluster.abc123xyz789.us-west-1.redshift.amazonaws.com\",\n            \"port\": 5439,\n            \"database\": \"dev\",\n            \"user\": \"awsuser\",\n            \"password\": \"test_password\",\n            \"db_schema\": \"test\",\n        }\n        resp = api_client.put(\n            url + \"?verify=False\",\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 200\n        assert (\n            json.loads(resp.text)[\"msg\"]\n            == f\"Secrets updated for ConnectionConfig with key: {redshift_connection_config.key}.\"\n        )\n        db.refresh(redshift_connection_config)\n        assert redshift_connection_config.secrets == {\n            \"host\": \"examplecluster.abc123xyz789.us-west-1.redshift.amazonaws.com\",\n            \"port\": 5439,\n            \"database\": \"dev\",\n            \"user\": \"awsuser\",\n            \"password\": \"test_password\",\n            \"db_schema\": \"test\",\n            \"url\": None,\n        }\n        assert redshift_connection_config.last_test_timestamp is None\n        assert redshift_connection_config.last_test_succeeded is None\n\n    def test_put_connection_config_bigquery_secrets(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        bigquery_connection_config_without_secrets,\n    ) -> None:\n        \"\"\"Note: this test does not attempt to actually connect to the db, via use of verify query param.\"\"\"\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        url = f\"{V1_URL_PREFIX}{CONNECTIONS}/{bigquery_connection_config_without_secrets.key}/secret\"\n        payload = {\n            \"dataset\": \"some-dataset\",\n            \"keyfile_creds\": {\n                \"type\": \"service_account\",\n                \"project_id\": \"project-12345\",\n                \"private_key_id\": \"qo28cy4nlwu\",\n                \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nqi2unhflhncflkjas\\nkqiu34c\\n-----END PRIVATE KEY-----\\n\",\n                \"client_email\": \"something@project-12345.iam.gserviceaccount.com\",\n                \"client_id\": \"287345028734538\",\n                \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n                \"token_uri\": \"https://oauth2.googleapis.com/token\",\n                \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n                \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/something%40project-12345.iam.gserviceaccount.com\",\n            },\n        }\n        resp = api_client.put(\n            url + \"?verify=False\",\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 200\n        assert (\n            json.loads(resp.text)[\"msg\"]\n            == f\"Secrets updated for ConnectionConfig with key: {bigquery_connection_config_without_secrets.key}.\"\n        )\n        db.refresh(bigquery_connection_config_without_secrets)\n        assert bigquery_connection_config_without_secrets.secrets == {\n            \"url\": None,\n            \"dataset\": \"some-dataset\",\n            \"keyfile_creds\": {\n                \"type\": \"service_account\",\n                \"project_id\": \"project-12345\",\n                \"private_key_id\": \"qo28cy4nlwu\",\n                \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nqi2unhflhncflkjas\\nkqiu34c\\n-----END PRIVATE KEY-----\\n\",\n                \"client_email\": \"something@project-12345.iam.gserviceaccount.com\",\n                \"client_id\": \"287345028734538\",\n                \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n                \"token_uri\": \"https://oauth2.googleapis.com/token\",\n                \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n                \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/something%40project-12345.iam.gserviceaccount.com\",\n            },\n        }\n        assert bigquery_connection_config_without_secrets.last_test_timestamp is None\n        assert bigquery_connection_config_without_secrets.last_test_succeeded is None\n\n    def test_put_connection_config_snowflake_secrets(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        snowflake_connection_config,\n    ) -> None:\n        \"\"\"Note: this test does not attempt to actually connect to the db, via use of verify query param.\"\"\"\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        url = f\"{V1_URL_PREFIX}{CONNECTIONS}/{snowflake_connection_config.key}/secret\"\n        payload = {\n            \"user_login_name\": \"test_user\",\n            \"password\": \"test_password\",\n            \"account_identifier\": \"flso2222test\",\n            \"database_name\": \"test\",\n        }\n\n        resp = api_client.put(\n            url + \"?verify=False\",\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 200\n        assert (\n            json.loads(resp.text)[\"msg\"]\n            == f\"Secrets updated for ConnectionConfig with key: {snowflake_connection_config.key}.\"\n        )\n        db.refresh(snowflake_connection_config)\n        assert snowflake_connection_config.secrets == {\n            \"user_login_name\": \"test_user\",\n            \"password\": \"test_password\",\n            \"account_identifier\": \"flso2222test\",\n            \"database_name\": \"test\",\n            \"schema_name\": None,\n            \"warehouse_name\": None,\n            \"role_name\": None,\n            \"url\": None,\n        }\n        assert snowflake_connection_config.last_test_timestamp is None\n        assert snowflake_connection_config.last_test_succeeded is None\n\n    def test_put_http_connection_config_secrets(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        https_connection_config,\n    ) -> None:\n        \"\"\"Note: HTTP Connection Configs don't attempt to test secrets\"\"\"\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        url = f\"{V1_URL_PREFIX}{CONNECTIONS}/{https_connection_config.key}/secret\"\n        payload = {\"url\": \"example.com\", \"authorization\": \"test_authorization123\"}\n\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n        assert (\n            body[\"msg\"]\n            == f\"Secrets updated for ConnectionConfig with key: {https_connection_config.key}.\"\n        )\n        assert body[\"test_status\"] == \"skipped\"\n        db.refresh(https_connection_config)\n        assert https_connection_config.secrets == {\n            \"url\": \"example.com\",\n            \"authorization\": \"test_authorization123\",\n        }\n        assert https_connection_config.last_test_timestamp is None\n        assert https_connection_config.last_test_succeeded is None\n\n    @pytest.mark.unit_saas\n    def test_put_saas_example_connection_config_secrets(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        saas_example_connection_config,\n        saas_example_secrets,\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        url = (\n            f\"{V1_URL_PREFIX}{CONNECTIONS}/{saas_example_connection_config.key}/secret\"\n        )\n        payload = saas_example_secrets\n\n        resp = api_client.put(\n            url + \"?verify=False\",\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 200\n\n        body = json.loads(resp.text)\n        assert (\n            body[\"msg\"]\n            == f\"Secrets updated for ConnectionConfig with key: {saas_example_connection_config.key}.\"\n        )\n\n        db.refresh(saas_example_connection_config)\n        assert saas_example_connection_config.secrets == saas_example_secrets\n        assert saas_example_connection_config.last_test_timestamp is None\n        assert saas_example_connection_config.last_test_succeeded is None\n\n    @pytest.mark.unit_saas\n    def test_put_saas_example_connection_config_secrets_missing_saas_config(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        saas_example_connection_config_without_saas_config,\n        saas_example_secrets,\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        url = f\"{V1_URL_PREFIX}{CONNECTIONS}/{saas_example_connection_config_without_saas_config.key}/secret\"\n        payload = saas_example_secrets\n\n        resp = api_client.put(\n            url + \"?verify=False\",\n            headers=auth_header,\n            json=payload,\n        )\n        assert resp.status_code == 422\n\n        body = json.loads(resp.text)\n        assert (\n            body[\"detail\"]\n            == f\"A SaaS config to validate the secrets is unavailable for this connection config, please add one via {SAAS_CONFIG}\"\n        )\n\n    @mock.patch(\"fidesops.ops.service.connectors.email_connector.dispatch_email\")\n    def test_put_email_connection_config_secrets(\n        self,\n        mock_dispatch_email,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        email_connection_config,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_CREATE_OR_UPDATE])\n        payload = {\n            \"url\": None,\n            \"to_email\": \"test1@example.com\",\n            \"test_email\": \"test@example.com\",\n        }\n        url = f\"{V1_URL_PREFIX}{CONNECTIONS}/{email_connection_config.key}/secret\"\n\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=payload,\n        )\n\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n        assert (\n            body[\"msg\"]\n            == f\"Secrets updated for ConnectionConfig with key: {email_connection_config.key}.\"\n        )\n        assert body[\"test_status\"] == \"succeeded\"\n        db.refresh(email_connection_config)\n        assert email_connection_config.secrets == {\n            \"to_email\": \"test1@example.com\",\n            \"url\": None,\n            \"test_email\": \"test@example.com\",\n        }\n        assert email_connection_config.last_test_timestamp is not None\n        assert email_connection_config.last_test_succeeded is not None\n\n        assert mock_dispatch_email.called\n        kwargs = mock_dispatch_email.call_args.kwargs\n        assert (\n            kwargs[\"action_type\"] == EmailActionType.EMAIL_ERASURE_REQUEST_FULFILLMENT\n        )\n        assert kwargs[\"to_email\"] == \"test@example.com\"\n        assert kwargs[\"email_body_params\"] == [\n            CheckpointActionRequired(\n                step=CurrentStep.erasure,\n                collection=CollectionAddress(\"test_dataset\", \"test_collection\"),\n                action_needed=[\n                    ManualAction(\n                        locators={\"id\": [\"example_id\"]},\n                        get=None,\n                        update={\"test_field\": \"null_rewrite\"},\n                    )\n                ],\n            )\n        ]\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_connection_template_endpoints.py", "content": "from unittest import mock\n\nimport pytest\nfrom fideslib.models.client import ClientDetail\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    CONNECTION_READ,\n    CONNECTION_TYPE_READ,\n    SAAS_CONNECTION_INSTANTIATE,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    CONNECTION_TYPE_SECRETS,\n    CONNECTION_TYPES,\n    SAAS_CONNECTOR_FROM_TEMPLATE,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.schemas.connection_configuration.connection_config import SystemType\nfrom fidesops.ops.schemas.saas.saas_config import SaaSType\n\n\nclass TestGetConnections:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + CONNECTION_TYPES\n\n    def test_get_connection_types_not_authenticated(self, api_client, url):\n        resp = api_client.get(url, headers={})\n        assert resp.status_code == 401\n\n    def test_get_connection_types_forbidden(\n        self, api_client, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 403\n\n    def test_get_connection_types(\n        self, api_client: TestClient, generate_auth_header, url\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n        resp = api_client.get(url, headers=auth_header)\n        data = resp.json()[\"items\"]\n        assert resp.status_code == 200\n        assert len(data) == 26\n\n        assert {\n            \"identifier\": ConnectionType.postgres.value,\n            \"type\": SystemType.database.value,\n            \"human_readable\": \"PostgreSQL\",\n        } in data\n        assert {\n            \"identifier\": SaaSType.stripe.value,\n            \"type\": SystemType.saas.value,\n            \"human_readable\": \"Stripe\",\n        } in data\n\n        assert \"saas\" not in [item[\"identifier\"] for item in data]\n        assert \"https\" not in [item[\"identifier\"] for item in data]\n        assert \"custom\" not in [item[\"identifier\"] for item in data]\n        assert \"manual\" not in [item[\"identifier\"] for item in data]\n\n    def test_search_connection_types(self, api_client, generate_auth_header, url):\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n\n        resp = api_client.get(url + \"?search=str\", headers=auth_header)\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 1\n        assert data[0] == {\n            \"identifier\": SaaSType.stripe.value,\n            \"type\": SystemType.saas.value,\n            \"human_readable\": \"Stripe\",\n        }\n\n        resp = api_client.get(url + \"?search=re\", headers=auth_header)\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 4\n        assert data == [\n            {\n                \"identifier\": ConnectionType.postgres.value,\n                \"type\": SystemType.database.value,\n                \"human_readable\": \"PostgreSQL\",\n            },\n            {\n                \"identifier\": ConnectionType.redshift.value,\n                \"type\": SystemType.database.value,\n                \"human_readable\": \"Amazon Redshift\",\n            },\n            {\n                \"identifier\": SaaSType.firebase_auth.value,\n                \"type\": SystemType.saas.value,\n                \"human_readable\": \"Firebase Auth\",\n            },\n            {\n                \"identifier\": SaaSType.outreach.value,\n                \"type\": SystemType.saas.value,\n                \"human_readable\": \"Outreach\",\n            },\n        ]\n\n    def test_search_connection_types_case_insensitive(\n        self, api_client, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n\n        resp = api_client.get(url + \"?search=St\", headers=auth_header)\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 2\n        assert data[0] == {\n            \"identifier\": ConnectionType.postgres.value,\n            \"type\": SystemType.database.value,\n            \"human_readable\": \"PostgreSQL\",\n        }\n        assert data[1] == {\n            \"identifier\": SaaSType.stripe.value,\n            \"type\": SystemType.saas.value,\n            \"human_readable\": \"Stripe\",\n        }\n\n        resp = api_client.get(url + \"?search=Re\", headers=auth_header)\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 4\n        assert data == [\n            {\n                \"identifier\": ConnectionType.postgres.value,\n                \"type\": SystemType.database.value,\n                \"human_readable\": \"PostgreSQL\",\n            },\n            {\n                \"identifier\": ConnectionType.redshift.value,\n                \"type\": SystemType.database.value,\n                \"human_readable\": \"Amazon Redshift\",\n            },\n            {\n                \"identifier\": SaaSType.firebase_auth.value,\n                \"type\": SystemType.saas.value,\n                \"human_readable\": \"Firebase Auth\",\n            },\n            {\n                \"identifier\": SaaSType.outreach.value,\n                \"type\": SystemType.saas.value,\n                \"human_readable\": \"Outreach\",\n            },\n        ]\n\n    def test_search_system_type(self, api_client, generate_auth_header, url):\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n\n        resp = api_client.get(url + \"?system_type=nothing\", headers=auth_header)\n        assert resp.status_code == 422\n\n        resp = api_client.get(url + \"?system_type=saas\", headers=auth_header)\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 16\n\n        resp = api_client.get(url + \"?system_type=database\", headers=auth_header)\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 9\n\n    def test_search_system_type_and_connection_type(\n        self, api_client, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n\n        resp = api_client.get(url + \"?search=str&system_type=saas\", headers=auth_header)\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 1\n\n        resp = api_client.get(\n            url + \"?search=re&system_type=database\", headers=auth_header\n        )\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 2\n\n    def test_search_manual_system_type(self, api_client, generate_auth_header, url):\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n\n        resp = api_client.get(url + \"?system_type=manual\", headers=auth_header)\n        assert resp.status_code == 200\n        data = resp.json()[\"items\"]\n        assert len(data) == 1\n        assert data == [\n            {\n                \"identifier\": \"manual_webhook\",\n                \"type\": \"manual\",\n                \"human_readable\": \"Manual Webhook\",\n            }\n        ]\n\n\nclass TestGetConnectionSecretSchema:\n    @pytest.fixture(scope=\"function\")\n    def base_url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + CONNECTION_TYPE_SECRETS\n\n    def test_get_connection_secret_schema_not_authenticated(self, api_client, base_url):\n        resp = api_client.get(base_url.format(connection_type=\"sentry\"), headers={})\n        assert resp.status_code == 401\n\n    def test_get_connection_secret_schema_forbidden(\n        self, api_client, base_url, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.get(\n            base_url.format(connection_type=\"sentry\"), headers=auth_header\n        )\n        assert resp.status_code == 403\n\n    def test_get_connection_secret_schema_not_found(\n        self, api_client: TestClient, generate_auth_header, base_url\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n        resp = api_client.get(\n            base_url.format(connection_type=\"connection_type_we_do_not_support\"),\n            headers=auth_header,\n        )\n        assert resp.status_code == 404\n        assert (\n            resp.json()[\"detail\"]\n            == \"No connection type found with name 'connection_type_we_do_not_support'.\"\n        )\n\n    def test_get_connection_secret_schema_mongodb(\n        self, api_client: TestClient, generate_auth_header, base_url\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n        resp = api_client.get(\n            base_url.format(connection_type=\"mongodb\"), headers=auth_header\n        )\n        assert resp.json() == {\n            \"title\": \"MongoDBSchema\",\n            \"description\": \"Schema to validate the secrets needed to connect to a MongoDB Database\",\n            \"type\": \"object\",\n            \"properties\": {\n                \"url\": {\"title\": \"Url\", \"type\": \"string\"},\n                \"username\": {\"title\": \"Username\", \"type\": \"string\"},\n                \"password\": {\"title\": \"Password\", \"type\": \"string\"},\n                \"host\": {\"title\": \"Host\", \"type\": \"string\"},\n                \"port\": {\"title\": \"Port\", \"type\": \"integer\"},\n                \"defaultauthdb\": {\"title\": \"Defaultauthdb\", \"type\": \"string\"},\n            },\n            \"additionalProperties\": False,\n        }\n\n    def test_get_connection_secret_schema_hubspot(\n        self, api_client: TestClient, generate_auth_header, base_url\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n        resp = api_client.get(\n            base_url.format(connection_type=\"hubspot\"), headers=auth_header\n        )\n\n        assert resp.json() == {\n            \"title\": \"hubspot_schema\",\n            \"description\": \"Hubspot secrets schema\",\n            \"type\": \"object\",\n            \"properties\": {\n                \"private_app_token\": {\"title\": \"Private App Token\", \"type\": \"string\"},\n                \"domain\": {\n                    \"title\": \"Domain\",\n                    \"default\": \"api.hubapi.com\",\n                    \"type\": \"string\",\n                },\n            },\n            \"required\": [\"private_app_token\"],\n            \"additionalProperties\": False,\n        }\n\n    def test_get_connection_secrets_manual_webhook(\n        self, api_client: TestClient, generate_auth_header, base_url\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_TYPE_READ])\n        resp = api_client.get(\n            base_url.format(connection_type=\"manual_webhook\"), headers=auth_header\n        )\n        assert resp.status_code == 200\n        assert resp.json() == {\n            \"title\": \"ManualWebhookSchema\",\n            \"description\": \"Secrets for manual webhooks. No secrets needed at this time.\",\n            \"type\": \"object\",\n            \"properties\": {},\n        }\n\n\nclass TestInstantiateConnectionFromTemplate:\n    @pytest.fixture(scope=\"function\")\n    def base_url(self) -> str:\n        return V1_URL_PREFIX + SAAS_CONNECTOR_FROM_TEMPLATE\n\n    def test_instantiate_connection_not_authenticated(self, api_client, base_url):\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"), headers={}\n        )\n        assert resp.status_code == 401\n\n    def test_instantiate_connection_wrong_scope(\n        self, generate_auth_header, api_client, base_url\n    ):\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"), headers=auth_header\n        )\n        assert resp.status_code == 403\n\n    def test_instantiate_nonexistent_template(\n        self, generate_auth_header, api_client, base_url\n    ):\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        request_body = {\n            \"instance_key\": \"test_instance_key\",\n            \"secrets\": {},\n            \"name\": \"Unsupported Connector\",\n            \"description\": \"Unsupported connector description\",\n            \"key\": \"unsupported_connector\",\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"does_not_exist\"),\n            headers=auth_header,\n            json=request_body,\n        )\n        assert resp.status_code == 404\n        assert (\n            resp.json()[\"detail\"]\n            == f\"SaaS connector type 'does_not_exist' is not yet available in Fidesops. For a list of available SaaS connectors, refer to /connection_type.\"\n        )\n\n    def test_instance_key_already_exists(\n        self, generate_auth_header, api_client, base_url, dataset_config\n    ):\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        request_body = {\n            \"instance_key\": dataset_config.fides_key,\n            \"secrets\": {\n                \"domain\": \"test_mailchimp_domain\",\n                \"username\": \"test_mailchimp_username\",\n                \"api_key\": \"test_mailchimp_api_key\",\n            },\n            \"name\": \"Mailchimp Connector\",\n            \"description\": \"Mailchimp ConnectionConfig description\",\n            \"key\": \"mailchimp_connection_config\",\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"),\n            headers=auth_header,\n            json=request_body,\n        )\n        assert resp.status_code == 400\n        assert (\n            resp.json()[\"detail\"]\n            == f\"SaaS connector instance key '{dataset_config.fides_key}' already exists.\"\n        )\n\n    def test_template_secrets_validation(\n        self, generate_auth_header, api_client, base_url, db\n    ):\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        # Secrets have one field missing, one field extra\n        request_body = {\n            \"instance_key\": \"secondary_mailchimp_instance\",\n            \"secrets\": {\n                \"bad_mailchimp_secret_key\": \"bad_key\",\n                \"username\": \"test_mailchimp_username\",\n                \"api_key\": \"test_mailchimp_api_key\",\n            },\n            \"name\": \"Mailchimp Connector\",\n            \"description\": \"Mailchimp ConnectionConfig description\",\n            \"key\": \"mailchimp_connection_config\",\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"),\n            headers=auth_header,\n            json=request_body,\n        )\n\n        assert resp.status_code == 422\n        assert resp.json()[\"detail\"][0] == {\n            \"loc\": [\"domain\"],\n            \"msg\": \"field required\",\n            \"type\": \"value_error.missing\",\n        }\n        assert resp.json()[\"detail\"][1] == {\n            \"loc\": [\"bad_mailchimp_secret_key\"],\n            \"msg\": \"extra fields not permitted\",\n            \"type\": \"value_error.extra\",\n        }\n\n        connection_config = ConnectionConfig.filter(\n            db=db, conditions=(ConnectionConfig.key == \"mailchimp_connection_config\")\n        ).first()\n        assert connection_config is None, \"ConnectionConfig not persisted\"\n\n    def test_connection_config_key_already_exists(\n        self, db, generate_auth_header, api_client, base_url, connection_config\n    ):\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        request_body = {\n            \"instance_key\": \"secondary_mailchimp_instance\",\n            \"secrets\": {\n                \"domain\": \"test_mailchimp_domain\",\n                \"username\": \"test_mailchimp_username\",\n                \"api_key\": \"test_mailchimp_api_key\",\n            },\n            \"name\": connection_config.name,\n            \"description\": \"Mailchimp ConnectionConfig description\",\n            \"key\": connection_config.key,\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"),\n            headers=auth_header,\n            json=request_body,\n        )\n        assert resp.status_code == 400\n        assert (\n            f\"Key {connection_config.key} already exists in ConnectionConfig\"\n            in resp.json()[\"detail\"]\n        )\n\n    def test_connection_config_name_already_exists(\n        self, db, generate_auth_header, api_client, base_url, connection_config\n    ):\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        request_body = {\n            \"instance_key\": \"secondary_mailchimp_instance\",\n            \"secrets\": {\n                \"domain\": \"test_mailchimp_domain\",\n                \"username\": \"test_mailchimp_username\",\n                \"api_key\": \"test_mailchimp_api_key\",\n            },\n            \"name\": connection_config.name,\n            \"description\": \"Mailchimp ConnectionConfig description\",\n            \"key\": \"brand_new_key\",\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"),\n            headers=auth_header,\n            json=request_body,\n        )\n        assert resp.status_code == 400\n        assert (\n            f\"Name {connection_config.name} already exists in ConnectionConfig\"\n            in resp.json()[\"detail\"]\n        )\n\n    def test_create_connection_from_template_without_supplying_connection_key(\n        self, db, generate_auth_header, api_client, base_url\n    ):\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        request_body = {\n            \"instance_key\": \"secondary_mailchimp_instance\",\n            \"secrets\": {\n                \"domain\": \"test_mailchimp_domain\",\n                \"username\": \"test_mailchimp_username\",\n                \"api_key\": \"test_mailchimp_api_key\",\n            },\n            \"name\": \"Mailchimp Connector\",\n            \"description\": \"Mailchimp ConnectionConfig description\",\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"),\n            headers=auth_header,\n            json=request_body,\n        )\n        assert resp.status_code == 200\n\n        connection_config = ConnectionConfig.filter(\n            db=db, conditions=(ConnectionConfig.name == \"Mailchimp Connector\")\n        ).first()\n        dataset_config = DatasetConfig.filter(\n            db=db,\n            conditions=(DatasetConfig.fides_key == \"secondary_mailchimp_instance\"),\n        ).first()\n\n        assert connection_config is not None\n        assert dataset_config is not None\n\n        assert connection_config.key == \"mailchimp_connector\"\n        dataset_config.delete(db)\n        connection_config.delete(db)\n\n    def test_invalid_instance_key(self, db, generate_auth_header, api_client, base_url):\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        request_body = {\n            \"instance_key\": \"< this is an invalid key! >\",\n            \"secrets\": {\n                \"domain\": \"test_mailchimp_domain\",\n                \"username\": \"test_mailchimp_username\",\n                \"api_key\": \"test_mailchimp_api_key\",\n            },\n            \"name\": \"Mailchimp Connector\",\n            \"description\": \"Mailchimp ConnectionConfig description\",\n            \"key\": \"mailchimp_connection_config\",\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"),\n            headers=auth_header,\n            json=request_body,\n        )\n        assert resp.json()[\"detail\"][0] == {\n            \"loc\": [\"body\", \"instance_key\"],\n            \"msg\": \"FidesKey must only contain alphanumeric characters, '.', '_' or '-'.\",\n            \"type\": \"value_error\",\n        }\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.saas_config_endpoints.upsert_dataset_config_from_template\"\n    )\n    def test_dataset_config_saving_fails(\n        self, mock_create_dataset, db, generate_auth_header, api_client, base_url\n    ):\n        mock_create_dataset.side_effect = Exception(\"KeyError\")\n\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        request_body = {\n            \"instance_key\": \"secondary_mailchimp_instance\",\n            \"secrets\": {\n                \"domain\": \"test_mailchimp_domain\",\n                \"username\": \"test_mailchimp_username\",\n                \"api_key\": \"test_mailchimp_api_key\",\n            },\n            \"name\": \"Mailchimp Connector\",\n            \"description\": \"Mailchimp ConnectionConfig description\",\n            \"key\": \"mailchimp_connection_config\",\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"),\n            headers=auth_header,\n            json=request_body,\n        )\n        assert resp.status_code == 500\n        assert (\n            resp.json()[\"detail\"]\n            == \"SaaS Connector could not be created from the 'mailchimp' template at this time.\"\n        )\n\n        connection_config = ConnectionConfig.filter(\n            db=db, conditions=(ConnectionConfig.key == \"mailchimp_connection_config\")\n        ).first()\n        assert connection_config is None\n\n        dataset_config = DatasetConfig.filter(\n            db=db,\n            conditions=(DatasetConfig.fides_key == \"secondary_mailchimp_instance\"),\n        ).first()\n        assert dataset_config is None\n\n    def test_instantiate_connection_from_template(\n        self, db, generate_auth_header, api_client, base_url\n    ):\n        connection_config = ConnectionConfig.filter(\n            db=db, conditions=(ConnectionConfig.key == \"mailchimp_connection_config\")\n        ).first()\n        assert connection_config is None\n\n        dataset_config = DatasetConfig.filter(\n            db=db,\n            conditions=(DatasetConfig.fides_key == \"secondary_mailchimp_instance\"),\n        ).first()\n        assert dataset_config is None\n\n        auth_header = generate_auth_header(scopes=[SAAS_CONNECTION_INSTANTIATE])\n        request_body = {\n            \"instance_key\": \"secondary_mailchimp_instance\",\n            \"secrets\": {\n                \"domain\": \"test_mailchimp_domain\",\n                \"username\": \"test_mailchimp_username\",\n                \"api_key\": \"test_mailchimp_api_key\",\n            },\n            \"name\": \"Mailchimp Connector\",\n            \"description\": \"Mailchimp ConnectionConfig description\",\n            \"key\": \"mailchimp_connection_config\",\n        }\n        resp = api_client.post(\n            base_url.format(saas_connector_type=\"mailchimp\"),\n            headers=auth_header,\n            json=request_body,\n        )\n\n        assert resp.status_code == 200\n        assert set(resp.json().keys()) == {\"connection\", \"dataset\"}\n        connection_data = resp.json()[\"connection\"]\n        assert connection_data[\"key\"] == \"mailchimp_connection_config\"\n        assert connection_data[\"name\"] == \"Mailchimp Connector\"\n        assert \"secrets\" not in connection_data\n\n        dataset_data = resp.json()[\"dataset\"]\n        assert dataset_data[\"fides_key\"] == \"secondary_mailchimp_instance\"\n\n        connection_config = ConnectionConfig.filter(\n            db=db, conditions=(ConnectionConfig.key == \"mailchimp_connection_config\")\n        ).first()\n        dataset_config = DatasetConfig.filter(\n            db=db,\n            conditions=(DatasetConfig.fides_key == \"secondary_mailchimp_instance\"),\n        ).first()\n\n        assert connection_config is not None\n        assert dataset_config is not None\n        assert connection_config.name == \"Mailchimp Connector\"\n        assert connection_config.description == \"Mailchimp ConnectionConfig description\"\n\n        assert connection_config.access == AccessLevel.write\n        assert connection_config.connection_type == ConnectionType.saas\n        assert connection_config.saas_config is not None\n        assert connection_config.disabled is False\n        assert connection_config.disabled_at is None\n        assert connection_config.last_test_timestamp is None\n        assert connection_config.last_test_succeeded is None\n\n        assert dataset_config.connection_config_id == connection_config.id\n        assert dataset_config.dataset is not None\n\n        dataset_config.delete(db)\n        connection_config.delete(db)\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_consent_request_endpoints.py", "content": "from __future__ import annotations\n\nfrom copy import deepcopy\nfrom typing import Any\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom fidesops.ops.api.v1.scope_registry import CONNECTION_READ, CONSENT_READ\nfrom fidesops.ops.api.v1.urn_registry import (\n    CONSENT_REQUEST,\n    CONSENT_REQUEST_PREFERENCES,\n    CONSENT_REQUEST_PREFERENCES_WITH_ID,\n    CONSENT_REQUEST_VERIFY,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.privacy_request import (\n    Consent,\n    ConsentRequest,\n    ProvidedIdentity,\n)\n\n\n@pytest.fixture\ndef provided_identity_and_consent_request(db):\n    provided_identity_data = {\n        \"privacy_request_id\": None,\n        \"field_name\": \"email\",\n        \"hashed_value\": ProvidedIdentity.hash_value(\"test@email.com\"),\n        \"encrypted_value\": {\"value\": \"test@email.com\"},\n    }\n    provided_identity = ProvidedIdentity.create(db, data=provided_identity_data)\n\n    consent_request_data = {\n        \"provided_identity_id\": provided_identity.id,\n    }\n    consent_request = ConsentRequest.create(db, data=consent_request_data)\n\n    yield provided_identity, consent_request\n\n\n@pytest.fixture\ndef disable_redis():\n    current = config.redis.enabled\n    config.redis.enabled = False\n    yield\n    config.redis.enabled = current\n\n\nclass TestConsentRequest:\n    @pytest.mark.usefixtures(\n        \"email_config\",\n        \"email_connection_config\",\n        \"email_dataset_config\",\n        \"subject_identity_verification_required\",\n    )\n    @patch(\"fidesops.ops.service._verification.dispatch_email\")\n    def test_consent_request(self, mock_dispatch_email, api_client):\n        data = {\"email\": \"test@example.com\"}\n        response = api_client.post(f\"{V1_URL_PREFIX}{CONSENT_REQUEST}\", json=data)\n        assert response.status_code == 200\n        assert mock_dispatch_email.called\n\n    @pytest.mark.usefixtures(\n        \"email_config\",\n        \"email_connection_config\",\n        \"email_dataset_config\",\n        \"subject_identity_verification_required\",\n    )\n    @patch(\"fidesops.ops.service._verification.dispatch_email\")\n    def test_consent_request_identity_present(\n        self, mock_dispatch_email, provided_identity_and_consent_request, api_client\n    ):\n        provided_identity, _ = provided_identity_and_consent_request\n        data = {\"email\": provided_identity.encrypted_value[\"value\"]}\n        response = api_client.post(f\"{V1_URL_PREFIX}{CONSENT_REQUEST}\", json=data)\n        assert response.status_code == 200\n        assert mock_dispatch_email.called\n\n    @pytest.mark.usefixtures(\n        \"email_config\",\n        \"email_connection_config\",\n        \"email_dataset_config\",\n        \"subject_identity_verification_required\",\n        \"disable_redis\",\n    )\n    def test_consent_request_redis_disabled(self, api_client):\n        data = {\"email\": \"test@example.com\"}\n        response = api_client.post(f\"{V1_URL_PREFIX}{CONSENT_REQUEST}\", json=data)\n        assert response.status_code == 500\n        assert \"redis cache required\" in response.json()[\"message\"]\n\n    @pytest.mark.usefixtures(\n        \"email_config\",\n        \"email_connection_config\",\n        \"email_dataset_config\",\n    )\n    def test_consent_request_subject_verification_disabled(self, api_client):\n        data = {\"email\": \"test@example.com\"}\n        response = api_client.post(f\"{V1_URL_PREFIX}{CONSENT_REQUEST}\", json=data)\n        assert response.status_code == 500\n        assert \"identity verification\" in response.json()[\"message\"]\n\n    @pytest.mark.usefixtures(\n        \"email_config\",\n        \"email_connection_config\",\n        \"email_dataset_config\",\n        \"subject_identity_verification_required\",\n    )\n    def test_consent_request_no_email(self, api_client):\n        data = {\"phone_number\": \"336-867-5309\"}\n        response = api_client.post(f\"{V1_URL_PREFIX}{CONSENT_REQUEST}\", json=data)\n        assert response.status_code == 400\n        assert \"email address is required\" in response.json()[\"detail\"]\n\n\nclass TestConsentVerify:\n    def test_consent_verify_no_consent_request_id(\n        self,\n        api_client,\n    ):\n        data = {\"code\": \"12345\"}\n\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_VERIFY.format(consent_request_id='abcd')}\",\n            json=data,\n        )\n        assert response.status_code == 404\n        assert \"not found\" in response.json()[\"detail\"]\n\n    def test_consent_verify_no_consent_code(\n        self, provided_identity_and_consent_request, api_client\n    ):\n        data = {\"code\": \"12345\"}\n\n        _, consent_request = provided_identity_and_consent_request\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_VERIFY.format(consent_request_id=consent_request.id)}\",\n            json=data,\n        )\n        assert response.status_code == 400\n        assert \"code expired\" in response.json()[\"detail\"]\n\n    def test_consent_verify_invalid_code(\n        self, provided_identity_and_consent_request, api_client\n    ):\n        _, consent_request = provided_identity_and_consent_request\n        consent_request.cache_identity_verification_code(\"abcd\")\n\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_VERIFY.format(consent_request_id=consent_request.id)}\",\n            json={\"code\": \"1234\"},\n        )\n        assert response.status_code == 403\n        assert \"Incorrect identification\" in response.json()[\"detail\"]\n\n    def test_consent_verify_no_email_provided(self, db, api_client):\n        provided_identity_data = {\n            \"privacy_request_id\": None,\n            \"field_name\": \"email\",\n            \"hashed_value\": None,\n            \"encrypted_value\": None,\n        }\n        provided_identity = ProvidedIdentity.create(db, data=provided_identity_data)\n\n        consent_request_data = {\n            \"provided_identity_id\": provided_identity.id,\n        }\n        consent_request = ConsentRequest.create(db, data=consent_request_data)\n        verification_code = \"abcd\"\n        consent_request.cache_identity_verification_code(verification_code)\n\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_VERIFY.format(consent_request_id=consent_request.id)}\",\n            json={\"code\": verification_code},\n        )\n\n        assert response.status_code == 404\n        assert \"missing email\" in response.json()[\"detail\"]\n\n    def test_consent_verify_no_consent_present(\n        self, provided_identity_and_consent_request, api_client\n    ):\n        _, consent_request = provided_identity_and_consent_request\n        verification_code = \"abcd\"\n        consent_request.cache_identity_verification_code(verification_code)\n\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_VERIFY.format(consent_request_id=consent_request.id)}\",\n            json={\"code\": verification_code},\n        )\n        assert response.status_code == 200\n        assert response.json()[\"consent\"] is None\n\n    def test_consent_verify_consent_preferences(\n        self, provided_identity_and_consent_request, db, api_client\n    ):\n        verification_code = \"abcd\"\n        provided_identity, consent_request = provided_identity_and_consent_request\n        consent_request.cache_identity_verification_code(verification_code)\n\n        consent_data: list[dict[str, Any]] = [\n            {\n                \"data_use\": \"email\",\n                \"data_use_description\": None,\n                \"opt_in\": True,\n            },\n            {\n                \"data_use\": \"location\",\n                \"data_use_description\": \"Location data\",\n                \"opt_in\": False,\n            },\n        ]\n\n        for data in deepcopy(consent_data):\n            data[\"provided_identity_id\"] = provided_identity.id\n            Consent.create(db, data=data)\n\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_VERIFY.format(consent_request_id=consent_request.id)}\",\n            json={\"code\": verification_code},\n        )\n        assert response.status_code == 200\n        assert response.json()[\"consent\"] == consent_data\n\n\nclass TestSaveConsent:\n    def test_set_consent_preferences_no_consent_request_id(self, api_client):\n        data = {\n            \"code\": \"12345\",\n            \"identity\": {\"email\": \"test@email.com\"},\n            \"consent\": [{\"data_use\": \"email\", \"opt_in\": True}],\n        }\n\n        response = api_client.patch(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES_WITH_ID.format(consent_request_id='abcd')}\",\n            json=data,\n        )\n        assert response.status_code == 404\n        assert \"not found\" in response.json()[\"detail\"]\n\n    def test_set_consent_preferences_no_consent_code(\n        self, provided_identity_and_consent_request, api_client\n    ):\n        _, consent_request = provided_identity_and_consent_request\n\n        data = {\n            \"code\": \"12345\",\n            \"identity\": {\"email\": \"test@email.com\"},\n            \"consent\": [{\"data_use\": \"email\", \"opt_in\": True}],\n        }\n\n        response = api_client.patch(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES_WITH_ID.format(consent_request_id=consent_request.id)}\",\n            json=data,\n        )\n        assert response.status_code == 400\n        assert \"code expired\" in response.json()[\"detail\"]\n\n    def test_set_consent_preferences_invalid_code(\n        self, provided_identity_and_consent_request, api_client\n    ):\n        _, consent_request = provided_identity_and_consent_request\n        consent_request.cache_identity_verification_code(\"abcd\")\n\n        data = {\n            \"code\": \"12345\",\n            \"identity\": {\"email\": \"test@email.com\"},\n            \"consent\": [{\"data_use\": \"email\", \"opt_in\": True}],\n        }\n        response = api_client.patch(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES_WITH_ID.format(consent_request_id=consent_request.id)}\",\n            json=data,\n        )\n        assert response.status_code == 403\n        assert \"Incorrect identification\" in response.json()[\"detail\"]\n\n    def test_set_consent_preferences_no_email_provided(self, db, api_client):\n        provided_identity_data = {\n            \"privacy_request_id\": None,\n            \"field_name\": \"email\",\n            \"hashed_value\": None,\n            \"encrypted_value\": None,\n        }\n        provided_identity = ProvidedIdentity.create(db, data=provided_identity_data)\n\n        consent_request_data = {\n            \"provided_identity_id\": provided_identity.id,\n        }\n        consent_request = ConsentRequest.create(db, data=consent_request_data)\n        verification_code = \"abcd\"\n        consent_request.cache_identity_verification_code(verification_code)\n\n        data = {\n            \"code\": verification_code,\n            \"identity\": {\"email\": \"test@email.com\"},\n            \"consent\": [{\"data_use\": \"email\", \"opt_in\": True}],\n        }\n        response = api_client.patch(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES_WITH_ID.format(consent_request_id=consent_request.id)}\",\n            json=data,\n        )\n\n        assert response.status_code == 404\n        assert \"missing email\" in response.json()[\"detail\"]\n\n    def test_set_consent_preferences_no_consent_present(\n        self, provided_identity_and_consent_request, api_client\n    ):\n        _, consent_request = provided_identity_and_consent_request\n        verification_code = \"abcd\"\n        consent_request.cache_identity_verification_code(verification_code)\n\n        data = {\n            \"code\": verification_code,\n            \"identity\": {\"email\": \"test@email.com\"},\n            \"consent\": None,\n        }\n        response = api_client.patch(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES_WITH_ID.format(consent_request_id=consent_request.id)}\",\n            json=data,\n        )\n        assert response.status_code == 422\n\n    def test_set_consent_consent_preferences(\n        self, provided_identity_and_consent_request, db, api_client\n    ):\n        provided_identity, consent_request = provided_identity_and_consent_request\n        verification_code = \"abcd\"\n        consent_request.cache_identity_verification_code(verification_code)\n\n        consent_data: list[dict[str, Any]] = [\n            {\n                \"data_use\": \"email\",\n                \"data_use_description\": None,\n                \"opt_in\": True,\n            },\n            {\n                \"data_use\": \"location\",\n                \"data_use_description\": \"Location data\",\n                \"opt_in\": False,\n            },\n        ]\n\n        for data in deepcopy(consent_data):\n            data[\"provided_identity_id\"] = provided_identity.id\n            Consent.create(db, data=data)\n\n        consent_data[1][\"opt_in\"] = False\n\n        data = {\n            \"code\": verification_code,\n            \"identity\": {\"email\": \"test@email.com\"},\n            \"consent\": consent_data,\n        }\n        response = api_client.patch(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES_WITH_ID.format(consent_request_id=consent_request.id)}\",\n            json=data,\n        )\n        assert response.status_code == 200\n        assert response.json()[\"consent\"] == consent_data\n\n\nclass TestGetConsentPreferences:\n    def test_get_consent_peferences_wrong_scope(self, generate_auth_header, api_client):\n        auth_header = generate_auth_header(scopes=[CONNECTION_READ])\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES}\",\n            headers=auth_header,\n            json={\"email\": \"test@user.com\"},\n        )\n\n        assert response.status_code == 403\n\n    def test_get_consent_preferences_no_identity_data(\n        self, generate_auth_header, api_client\n    ):\n        auth_header = generate_auth_header(scopes=[CONSENT_READ])\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES}\",\n            headers=auth_header,\n            json={\"email\": None},\n        )\n\n        assert response.status_code == 400\n        assert \"No identity information\" in response.json()[\"detail\"]\n\n    def test_get_consent_preferences_identity_not_found(\n        self, generate_auth_header, api_client\n    ):\n        auth_header = generate_auth_header(scopes=[CONSENT_READ])\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES}\",\n            headers=auth_header,\n            json={\"email\": \"test@email.com\"},\n        )\n\n        assert response.status_code == 404\n        assert \"Identity not found\" in response.json()[\"detail\"]\n\n    def test_get_consent_preferences(\n        self,\n        provided_identity_and_consent_request,\n        db,\n        generate_auth_header,\n        api_client,\n    ):\n        provided_identity, _ = provided_identity_and_consent_request\n\n        consent_data: list[dict[str, Any]] = [\n            {\n                \"data_use\": \"email\",\n                \"data_use_description\": None,\n                \"opt_in\": True,\n            },\n            {\n                \"data_use\": \"location\",\n                \"data_use_description\": \"Location data\",\n                \"opt_in\": False,\n            },\n        ]\n\n        for data in deepcopy(consent_data):\n            data[\"provided_identity_id\"] = provided_identity.id\n            Consent.create(db, data=data)\n\n        auth_header = generate_auth_header(scopes=[CONSENT_READ])\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}{CONSENT_REQUEST_PREFERENCES}\",\n            headers=auth_header,\n            json={\"email\": provided_identity.encrypted_value[\"value\"]},\n        )\n\n        assert response.status_code == 200\n        assert response.json()[\"consent\"] == consent_data\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_drp_endpoints.py", "content": "from typing import Callable\nfrom unittest import mock\n\nimport jwt\nimport pytest\nfrom sqlalchemy.orm import Session\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    POLICY_READ,\n    PRIVACY_REQUEST_READ,\n    PRIVACY_REQUEST_REVIEW,\n    STORAGE_CREATE_OR_UPDATE,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    DRP_DATA_RIGHTS,\n    DRP_EXERCISE,\n    DRP_REVOKE,\n    DRP_STATUS,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.policy import DrpAction\nfrom fidesops.ops.models.privacy_request import PrivacyRequest, PrivacyRequestStatus\nfrom fidesops.ops.schemas.privacy_request import PrivacyRequestDRPStatus\nfrom fidesops.ops.util.cache import (\n    get_drp_request_body_cache_key,\n    get_identity_cache_key,\n)\n\n\nclass TestCreateDrpPrivacyRequest:\n    @pytest.fixture(scope=\"function\")\n    def url(self) -> str:\n        return V1_URL_PREFIX + DRP_EXERCISE\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_drp_privacy_request(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy_drp_action,\n        cache,\n    ):\n        TEST_EMAIL = \"test@example.com\"\n        TEST_PHONE_NUMBER = \"+1 234 567 8910\"\n        identity = {\n            \"email\": TEST_EMAIL,\n            \"phone_number\": TEST_PHONE_NUMBER,\n        }\n        encoded_identity: str = jwt.encode(\n            identity, config.security.drp_jwt_secret, algorithm=\"HS256\"\n        )\n        data = {\n            \"meta\": {\"version\": \"0.5\"},\n            \"regime\": \"ccpa\",\n            \"exercise\": [DrpAction.access.value],\n            \"identity\": encoded_identity,\n        }\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()\n        assert response_data[\"status\"] == \"open\"\n        assert response_data[\"received_at\"]\n        assert response_data[\"request_id\"]\n        pr = PrivacyRequest.get(db=db, object_id=response_data[\"request_id\"])\n\n        # test appropriate data is cached\n        meta_key = get_drp_request_body_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"meta\",\n        )\n        assert cache.get(meta_key) == \"DrpMeta(version='0.5')\"\n        regime_key = get_drp_request_body_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"regime\",\n        )\n        assert cache.get(regime_key) == \"ccpa\"\n        exercise_key = get_drp_request_body_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"exercise\",\n        )\n        assert cache.get(exercise_key) == \"['access']\"\n        identity_key = get_drp_request_body_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"identity\",\n        )\n        assert cache.get(identity_key) == encoded_identity\n        fidesops_identity_key = get_identity_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"email\",\n        )\n        assert cache.get(fidesops_identity_key) == identity[\"email\"]\n        persisted_identity = pr.get_persisted_identity()\n        assert persisted_identity.email == TEST_EMAIL\n        assert persisted_identity.phone_number == TEST_PHONE_NUMBER\n\n        pr.delete(db=db)\n        assert run_access_request_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_drp_privacy_request_unsupported_identity_props(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy_drp_action,\n        cache,\n    ):\n\n        identity = {\"email\": \"test@example.com\", \"address\": \"something\"}\n        encoded_identity: str = jwt.encode(\n            identity, config.security.drp_jwt_secret, algorithm=\"HS256\"\n        )\n        data = {\n            \"meta\": {\"version\": \"0.5\"},\n            \"regime\": \"ccpa\",\n            \"exercise\": [DrpAction.access.value],\n            \"identity\": encoded_identity,\n        }\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()\n        assert response_data[\"status\"] == \"open\"\n        assert response_data[\"received_at\"]\n        assert response_data[\"request_id\"]\n        pr = PrivacyRequest.get(db=db, object_id=response_data[\"request_id\"])\n\n        # test appropriate data is cached\n        meta_key = get_drp_request_body_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"meta\",\n        )\n        assert cache.get(meta_key) == \"DrpMeta(version='0.5')\"\n        regime_key = get_drp_request_body_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"regime\",\n        )\n        assert cache.get(regime_key) == \"ccpa\"\n        exercise_key = get_drp_request_body_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"exercise\",\n        )\n        assert cache.get(exercise_key) == \"['access']\"\n        identity_key = get_drp_request_body_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"identity\",\n        )\n        assert cache.get(identity_key) == encoded_identity\n        fidesops_identity_key = get_identity_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"email\",\n        )\n        assert cache.get(fidesops_identity_key) == identity[\"email\"]\n        fidesops_identity_key_address = get_identity_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=\"address\",\n        )\n        assert cache.get(fidesops_identity_key_address) is None\n        pr.delete(db=db)\n        assert run_access_request_mock.called\n\n    def test_create_drp_privacy_request_no_jwt(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        policy_drp_action,\n    ):\n\n        original_secret = config.security.drp_jwt_secret\n        config.security.drp_jwt_secret = None\n        identity = {\"email\": \"test@example.com\"}\n        encoded_identity: str = jwt.encode(identity, \"secret\", algorithm=\"HS256\")\n        data = {\n            \"meta\": {\"version\": \"0.5\"},\n            \"regime\": \"ccpa\",\n            \"exercise\": [DrpAction.access.value],\n            \"identity\": encoded_identity,\n        }\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 500\n        config.security.drp_jwt_secret = original_secret\n\n    def test_create_drp_privacy_request_no_exercise(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        policy_drp_action,\n    ):\n\n        identity = {\"email\": \"test@example.com\"}\n        encoded_identity: str = jwt.encode(\n            identity, config.security.drp_jwt_secret, algorithm=\"HS256\"\n        )\n        data = {\n            \"meta\": {\"version\": \"0.5\"},\n            \"regime\": \"ccpa\",\n            \"exercise\": None,\n            \"identity\": encoded_identity,\n        }\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 422\n\n    def test_create_drp_privacy_request_invalid_exercise(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        policy_drp_action,\n    ):\n\n        identity = {\"email\": \"test@example.com\"}\n        encoded_identity: str = jwt.encode(\n            identity, config.security.drp_jwt_secret, algorithm=\"HS256\"\n        )\n        data = {\n            \"meta\": {\"version\": \"0.5\"},\n            \"regime\": \"ccpa\",\n            \"exercise\": [DrpAction.access.value, DrpAction.deletion.value],\n            \"identity\": encoded_identity,\n        }\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 422\n\n    def test_create_drp_privacy_request_no_associated_policy(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n    ):\n\n        identity = {\"email\": \"test@example.com\"}\n        encoded_identity: str = jwt.encode(\n            identity, config.security.drp_jwt_secret, algorithm=\"HS256\"\n        )\n        data = {\n            \"meta\": {\"version\": \"0.5\"},\n            \"regime\": \"ccpa\",\n            \"exercise\": [DrpAction.access.value],\n            \"identity\": encoded_identity,\n        }\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 404\n\n\nclass TestGetPrivacyRequestDRP:\n    \"\"\"\n    Tests for the endpoint retrieving privacy requests specific to the DRP.\n    \"\"\"\n\n    @pytest.fixture(scope=\"function\")\n    def url_for_privacy_request(\n        self,\n        privacy_request: PrivacyRequest,\n    ) -> str:\n        return V1_URL_PREFIX + DRP_STATUS + f\"?request_id={privacy_request.id}\"\n\n    @pytest.fixture(scope=\"function\")\n    def url_for_privacy_request_with_drp_action(\n        self,\n        privacy_request_with_drp_action: PrivacyRequest,\n    ) -> str:\n        return (\n            V1_URL_PREFIX\n            + DRP_STATUS\n            + f\"?request_id={privacy_request_with_drp_action.id}\"\n        )\n\n    def test_get_privacy_requests_unauthenticated(\n        self,\n        api_client: TestClient,\n        url_for_privacy_request: str,\n    ):\n        response = api_client.get(\n            url_for_privacy_request,\n            headers={},\n        )\n        assert 401 == response.status_code\n\n    def test_get_privacy_requests_wrong_scope(\n        self,\n        api_client: TestClient,\n        generate_auth_header: Callable,\n        url_for_privacy_request: str,\n    ):\n        auth_header = generate_auth_header(scopes=[STORAGE_CREATE_OR_UPDATE])\n        response = api_client.get(\n            url_for_privacy_request,\n            headers=auth_header,\n        )\n        assert 403 == response.status_code\n\n    def test_get_non_drp_privacy_request(\n        self,\n        api_client: TestClient,\n        generate_auth_header: Callable,\n        url_for_privacy_request: str,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url_for_privacy_request,\n            headers=auth_header,\n        )\n        assert 404 == response.status_code\n        privacy_request_id = url_for_privacy_request.split(\"=\")[-1]\n        assert (\n            response.json()[\"detail\"]\n            == f\"Privacy request with ID {privacy_request_id} does not exist, or is not associated with a data rights protocol action.\"\n        )\n\n    @pytest.mark.parametrize(\n        \"privacy_request_status,expected_drp_status\",\n        [\n            (PrivacyRequestStatus.pending, PrivacyRequestDRPStatus.open),\n            (PrivacyRequestStatus.approved, PrivacyRequestDRPStatus.in_progress),\n            (PrivacyRequestStatus.denied, PrivacyRequestDRPStatus.denied),\n            (PrivacyRequestStatus.in_processing, PrivacyRequestDRPStatus.in_progress),\n            (PrivacyRequestStatus.complete, PrivacyRequestDRPStatus.fulfilled),\n            (PrivacyRequestStatus.paused, PrivacyRequestDRPStatus.in_progress),\n            (PrivacyRequestStatus.error, PrivacyRequestDRPStatus.expired),\n        ],\n    )\n    def test_get_privacy_request_with_drp_action(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header: Callable,\n        url_for_privacy_request_with_drp_action: str,\n        privacy_request_with_drp_action: PrivacyRequest,\n        privacy_request_status: PrivacyRequestStatus,\n        expected_drp_status: PrivacyRequestDRPStatus,\n    ):\n        privacy_request_with_drp_action.status = privacy_request_status\n        privacy_request_with_drp_action.save(db=db)\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url_for_privacy_request_with_drp_action,\n            headers=auth_header,\n        )\n        assert 200 == response.status_code\n        assert expected_drp_status.value == response.json()[\"status\"]\n        assert privacy_request_with_drp_action.id == response.json()[\"request_id\"]\n        assert (\n            privacy_request_with_drp_action.requested_at.isoformat()\n            == response.json()[\"received_at\"]\n        )\n\n\nclass TestGetDrpDataRights:\n    \"\"\"\n    Tests for the endpoint to retrieve DRP data rights.\n    \"\"\"\n\n    @pytest.fixture(scope=\"function\")\n    def url_for_data_rights(self) -> str:\n        return V1_URL_PREFIX + DRP_DATA_RIGHTS\n\n    def test_get_drp_data_rights_no_drp_policy(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header: Callable,\n        url_for_data_rights: str,\n        policy,\n    ):\n        expected_response = {\n            \"version\": \"0.5\",\n            \"api_base\": None,\n            \"actions\": [],\n            \"user_relationships\": None,\n        }\n        auth_header = generate_auth_header(scopes=[POLICY_READ])\n        response = api_client.get(\n            url_for_data_rights,\n            headers=auth_header,\n        )\n        assert 200 == response.status_code\n        assert response.json() == expected_response\n\n    def test_get_drp_data_rights_one_drp_policy(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header: Callable,\n        url_for_data_rights: str,\n        policy_drp_action,\n    ):\n        expected_response = {\n            \"version\": \"0.5\",\n            \"api_base\": None,\n            \"actions\": [DrpAction.access.value],\n            \"user_relationships\": None,\n        }\n        auth_header = generate_auth_header(scopes=[POLICY_READ])\n        response = api_client.get(\n            url_for_data_rights,\n            headers=auth_header,\n        )\n        assert 200 == response.status_code\n        assert response.json() == expected_response\n\n    def test_get_drp_data_rights_multiple_drp_policies(\n        self,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header: Callable,\n        url_for_data_rights: str,\n        policy_drp_action,\n        policy_drp_action_erasure,\n    ):\n        expected_response = {\n            \"version\": \"0.5\",\n            \"api_base\": None,\n            \"actions\": [DrpAction.access.value, DrpAction.deletion.value],\n            \"user_relationships\": None,\n        }\n        auth_header = generate_auth_header(scopes=[POLICY_READ])\n        response = api_client.get(\n            url_for_data_rights,\n            headers=auth_header,\n        )\n        assert 200 == response.status_code\n        assert response.json() == expected_response\n\n\nclass TestDrpRevoke:\n    @pytest.fixture(scope=\"function\")\n    def url(self) -> str:\n        return V1_URL_PREFIX + DRP_REVOKE\n\n    def test_revoke_not_authenticated(\n        self, api_client: TestClient, privacy_request, url\n    ):\n        response = api_client.post(url, headers={})\n        assert 401 == response.status_code\n\n    def test_revoke_wrong_scope(\n        self, api_client: TestClient, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.post(url, headers=auth_header, json={})\n        assert 403 == response.status_code\n\n    def test_revoke_wrong_status(\n        self, db, api_client: TestClient, generate_auth_header, url, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_REVIEW])\n        response = api_client.post(\n            url, headers=auth_header, json={\"request_id\": privacy_request.id}\n        )\n        assert 400 == response.status_code\n        assert response.json()[\n            \"detail\"\n        ] == \"Invalid revoke request. Can only revoke `pending` requests. Privacy request '{}' status = in_processing.\".format(\n            privacy_request.id\n        )\n        db.refresh(privacy_request)\n        assert privacy_request.status == PrivacyRequestStatus.in_processing\n        assert privacy_request.canceled_at is None\n\n    def test_revoke(\n        self, db, api_client: TestClient, generate_auth_header, url, privacy_request\n    ):\n        privacy_request.status = PrivacyRequestStatus.pending\n        privacy_request.save(db)\n        canceled_reason = \"Accidentally submitted\"\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_REVIEW])\n        response = api_client.post(\n            url,\n            headers=auth_header,\n            json={\"request_id\": privacy_request.id, \"reason\": canceled_reason},\n        )\n        assert 200 == response.status_code\n        db.refresh(privacy_request)\n\n        assert privacy_request.status == PrivacyRequestStatus.canceled\n        assert privacy_request.cancel_reason == canceled_reason\n        assert privacy_request.canceled_at is not None\n\n        data = response.json()\n        assert data[\"request_id\"] == privacy_request.id\n        assert data[\"status\"] == \"revoked\"\n        assert data[\"reason\"] == canceled_reason\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_dataset_endpoints.py", "content": "import json\nfrom typing import Dict, List, Optional\nfrom unittest import mock\nfrom unittest.mock import Mock\n\nimport pydash\nimport pytest\nfrom fastapi import HTTPException\nfrom fastapi_pagination import Params\nfrom pydash import filter_\nfrom sqlalchemy.orm import Session\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    DATASET_CREATE_OR_UPDATE,\n    DATASET_DELETE,\n    DATASET_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    DATASET_BY_KEY,\n    DATASET_VALIDATE,\n    DATASETS,\n    V1_URL_PREFIX,\n    YAML_DATASETS,\n)\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\n\n\ndef _reject_key(dict: Dict, key: str) -> Dict:\n    \"\"\"Return a copy of the given dictionary with the given key removed\"\"\"\n    result = dict.copy()\n    result.pop(key, None)\n    return result\n\n\ndef test_example_datasets(example_datasets):\n    \"\"\"Ensure the test fixture loads the right sample data\"\"\"\n    assert example_datasets\n    assert example_datasets[0][\"fides_key\"] == \"postgres_example_test_dataset\"\n    assert len(example_datasets[0][\"collections\"]) == 11\n    assert example_datasets[1][\"fides_key\"] == \"mongo_test\"\n    assert len(example_datasets[1][\"collections\"]) == 9\n    assert example_datasets[2][\"fides_key\"] == \"snowflake_example_test_dataset\"\n    assert len(example_datasets[2][\"collections\"]) == 11\n    assert example_datasets[3][\"fides_key\"] == \"redshift_example_test_dataset\"\n    assert len(example_datasets[3][\"collections\"]) == 11\n    assert example_datasets[4][\"fides_key\"] == \"mssql_example_test_dataset\"\n    assert len(example_datasets[4][\"collections\"]) == 11\n    assert example_datasets[5][\"fides_key\"] == \"mysql_example_test_dataset\"\n    assert len(example_datasets[5][\"collections\"]) == 11\n    assert example_datasets[6][\"fides_key\"] == \"mariadb_example_test_dataset\"\n    assert len(example_datasets[6][\"collections\"]) == 11\n    assert example_datasets[7][\"fides_key\"] == \"bigquery_example_test_dataset\"\n    assert len(example_datasets[7][\"collections\"]) == 11\n    assert example_datasets[9][\"fides_key\"] == \"email_dataset\"\n    assert len(example_datasets[9][\"collections\"]) == 3\n\n\nclass TestValidateDataset:\n    @pytest.fixture\n    def validate_dataset_url(self, connection_config) -> str:\n        path = V1_URL_PREFIX + DATASET_VALIDATE\n        path_params = {\"connection_key\": connection_config.key}\n        return path.format(**path_params)\n\n    def test_put_validate_dataset_not_authenticated(\n        self, example_datasets: List, validate_dataset_url: str, api_client\n    ) -> None:\n        response = api_client.put(\n            validate_dataset_url, headers={}, json=example_datasets[0]\n        )\n        assert response.status_code == 401\n\n    def test_put_validate_dataset_wrong_scope(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=example_datasets[0]\n        )\n        assert response.status_code == 403\n\n    def test_put_validate_dataset_missing_key(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        invalid_dataset = _reject_key(example_datasets[0], \"fides_key\")\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n        assert response.status_code == 422\n        details = json.loads(response.text)[\"detail\"]\n        assert [\"body\", \"fides_key\"] in [e[\"loc\"] for e in details]\n\n    def test_put_validate_dataset_missing_collections(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        invalid_dataset = _reject_key(example_datasets[0], \"collections\")\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n        assert response.status_code == 422\n        details = json.loads(response.text)[\"detail\"]\n        assert [\"body\", \"collections\"] in [e[\"loc\"] for e in details]\n\n    def test_put_validate_dataset_nested_collections(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        invalid_dataset = example_datasets[0]\n        invalid_dataset[\"collections\"][0][\"fields\"].append(\n            {\n                \"name\": \"details\",\n                \"fields\": [\n                    {\n                        \"name\": \"phone\",\n                        \"data_categories\": [\"user.contact\"],\n                    },\n                    {\"name\": \"count\", \"data_categories\": [\"system.operations\"]},\n                ],\n            }\n        )\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n        json_response = json.loads(response.text)\n        print(json_response)\n\n        # if we extract the details field from the response it will contain\n        # the nested fields \"phone\" and \"count\"\n        details_field = filter_(\n            pydash.get(json_response, \"dataset.collections.0.fields\"),\n            {\"name\": \"details\"},\n        )[0]\n\n        assert set(map(lambda f: f[\"name\"], details_field[\"fields\"])) == {\n            \"phone\",\n            \"count\",\n        }\n\n        assert response.status_code == 200\n\n    def test_put_validate_dataset_invalid_length(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        invalid_dataset = example_datasets[0]\n\n        # string is properly read:\n        invalid_dataset[\"collections\"][0][\"fields\"][0][\"fidesops_meta\"] = {\n            \"length\": 123\n        }\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n        assert response.status_code == 200\n        assert (\n            json.loads(response.text)[\"dataset\"][\"collections\"][0][\"fields\"][0][\n                \"fidesops_meta\"\n            ][\"length\"]\n            == 123\n        )\n\n        # fails with an invalid value\n        invalid_dataset[\"collections\"][0][\"fields\"][0][\"fidesops_meta\"] = {\"length\": -1}\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n\n        assert response.status_code == 422\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"Illegal length (-1). Only positive non-zero values are allowed.\"\n        )\n\n    def test_put_validate_dataset_invalid_data_type(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        invalid_dataset = example_datasets[0]\n\n        # string is properly read:\n        invalid_dataset[\"collections\"][0][\"fields\"][0][\"fidesops_meta\"] = {\n            \"data_type\": \"string\"\n        }\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n        assert response.status_code == 200\n        assert (\n            json.loads(response.text)[\"dataset\"][\"collections\"][0][\"fields\"][0][\n                \"fidesops_meta\"\n            ][\"data_type\"]\n            == \"string\"\n        )\n\n        # fails with an invalid value\n        invalid_dataset[\"collections\"][0][\"fields\"][0][\"fidesops_meta\"] = {\n            \"data_type\": \"stringsssssss\"\n        }\n\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n\n        assert response.status_code == 422\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"The data type stringsssssss is not supported.\"\n        )\n\n    def test_put_validate_dataset_invalid_fidesops_meta(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        invalid_dataset = example_datasets[0]\n        # Add an invalid fidesops_meta annotation to ensure our type-checking is comprehensive\n        invalid_dataset[\"collections\"][0][\"fields\"][0][\"fidesops_meta\"] = {\n            \"references\": [\n                {\n                    \"dataset\": \"postgres_example_test_dataset\",\n                    \"field\": \"another.field\",\n                    \"direction\": \"invalid direction!\",\n                },\n            ]\n        }\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n        assert response.status_code == 422\n        details = json.loads(response.text)[\"detail\"]\n        assert [\n            \"body\",\n            \"collections\",\n            0,\n            \"fields\",\n            0,\n            \"fidesops_meta\",\n            \"references\",\n            0,\n            \"direction\",\n        ] in [e[\"loc\"] for e in details]\n\n    def test_put_validate_dataset_invalid_category(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        invalid_dataset = example_datasets[0].copy()\n        invalid_dataset[\"collections\"][0][\"fields\"][0][\"data_categories\"].append(\n            \"user.invalid.category\"\n        )\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n        assert response.status_code == 422\n        details = json.loads(response.text)[\"detail\"]\n        assert [\"body\", \"collections\", 0, \"fields\", 0, \"data_categories\"] in [\n            e[\"loc\"] for e in details\n        ]\n\n    def test_put_validate_dataset_invalid_connection_key(\n        self, example_datasets: List, api_client: TestClient, generate_auth_header\n    ) -> None:\n        path = V1_URL_PREFIX + DATASET_VALIDATE\n        path_params = {\"connection_key\": \"nonexistent_key\"}\n        validate_dataset_url = path.format(**path_params)\n\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=example_datasets[0]\n        )\n        assert response.status_code == 404\n\n    def test_put_validate_dataset_invalid_traversal(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        invalid_dataset = example_datasets[0].copy()\n\n        # Remove all the \"reference\" annotations; this will make traversal impossible\n        for collection in invalid_dataset[\"collections\"]:\n            for field in collection[\"fields\"]:\n                if field.get(\"fidesops_meta\"):\n                    field[\"fidesops_meta\"][\"references\"] = None\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=invalid_dataset\n        )\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert response_body[\"dataset\"]\n        assert response_body[\"traversal_details\"]\n        assert response_body[\"traversal_details\"][\"is_traversable\"] is False\n        assert (\n            \"Some nodes were not reachable\" in response_body[\"traversal_details\"][\"msg\"]\n        )\n        assert (\n            \"postgres_example_test_dataset:address\"\n            in response_body[\"traversal_details\"][\"msg\"]\n        )\n\n    def test_validate_dataset_that_references_another_dataset(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        dataset = example_datasets[1]\n\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=dataset\n        )\n        print(response.text)\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert response_body[\"dataset\"]\n        assert response_body[\"traversal_details\"]\n        assert response_body[\"traversal_details\"][\"is_traversable\"] is False\n        assert (\n            \"Referred to object postgres_example_test_dataset:customer:id does not exist\"\n            == response_body[\"traversal_details\"][\"msg\"]\n        )\n\n    @pytest.mark.unit_saas\n    def test_validate_saas_dataset_invalid_traversal(\n        self,\n        db,\n        saas_example_connection_config_with_invalid_saas_config,\n        saas_example_dataset,\n        api_client: TestClient,\n        generate_auth_header,\n    ):\n        path = V1_URL_PREFIX + DATASET_VALIDATE\n        path_params = {\n            \"connection_key\": saas_example_connection_config_with_invalid_saas_config.key\n        }\n        validate_dataset_url = path.format(**path_params)\n\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.put(\n            validate_dataset_url,\n            headers=auth_header,\n            json=saas_example_dataset,\n        )\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n        assert response_body[\"dataset\"]\n        assert response_body[\"traversal_details\"]\n        assert response_body[\"traversal_details\"][\"is_traversable\"] is False\n        assert (\n            response_body[\"traversal_details\"][\"msg\"]\n            == \"Some nodes were not reachable: saas_connector_example:messages\"\n        )\n\n    def test_put_validate_dataset(\n        self,\n        example_datasets: List,\n        validate_dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.put(\n            validate_dataset_url, headers=auth_header, json=example_datasets[0]\n        )\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert response_body[\"dataset\"]\n        assert response_body[\"dataset\"][\"fides_key\"] == \"postgres_example_test_dataset\"\n        assert response_body[\"traversal_details\"]\n        assert response_body[\"traversal_details\"][\"is_traversable\"] is True\n        assert response_body[\"traversal_details\"][\"msg\"] is None\n\n\nclass TestPutDatasets:\n    @pytest.fixture\n    def datasets_url(self, connection_config) -> str:\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\"connection_key\": connection_config.key}\n        return path.format(**path_params)\n\n    def test_patch_datasets_not_authenticated(\n        self, example_datasets: List, datasets_url, api_client\n    ) -> None:\n        response = api_client.patch(datasets_url, headers={}, json=example_datasets)\n        assert response.status_code == 401\n\n    def test_patch_datasets_wrong_scope(\n        self,\n        example_datasets: List,\n        datasets_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=example_datasets\n        )\n        assert response.status_code == 403\n\n    def test_patch_datasets_invalid_connection_key(\n        self, example_datasets: List, api_client: TestClient, generate_auth_header\n    ) -> None:\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\"connection_key\": \"nonexistent_key\"}\n        datasets_url = path.format(**path_params)\n\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=example_datasets\n        )\n        assert response.status_code == 404\n\n    def test_patch_datasets_bulk_create_limit_exceeded(\n        self, api_client: TestClient, db: Session, generate_auth_header, datasets_url\n    ):\n        payload = []\n        for i in range(0, 51):\n            payload.append({\"collections\": [{\"fields\": [], \"fides_key\": i}]})\n\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(datasets_url, headers=auth_header, json=payload)\n\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at most 50 items\"\n        )\n\n    def test_patch_datasets_bulk_create(\n        self,\n        example_datasets: List,\n        datasets_url,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n        connection_config,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=example_datasets\n        )\n\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 10\n        assert len(response_body[\"failed\"]) == 0\n\n        # Confirm that postgres dataset matches the values we provided\n        postgres_dataset = response_body[\"succeeded\"][0]\n        postgres_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"postgres_example_test_dataset\"\n        )\n        assert postgres_config is not None\n        assert postgres_dataset[\"fides_key\"] == \"postgres_example_test_dataset\"\n        assert postgres_dataset[\"name\"] == \"Postgres Example Test Dataset\"\n        assert \"Example of a Postgres dataset\" in postgres_dataset[\"description\"]\n        assert len(postgres_dataset[\"collections\"]) == 11\n\n        # Check the mongo dataset was created as well\n        mongo_dataset = response_body[\"succeeded\"][1]\n        mongo_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"mongo_test\"\n        )\n        assert mongo_config is not None\n        assert mongo_dataset[\"fides_key\"] == \"mongo_test\"\n        assert mongo_dataset[\"name\"] == \"Mongo Example Test Dataset\"\n        assert \"Example of a Mongo dataset\" in mongo_dataset[\"description\"]\n        assert len(mongo_dataset[\"collections\"]) == 9\n\n        # Check the mssql dataset\n        mssql_dataset = response_body[\"succeeded\"][4]\n        mssql_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"mssql_example_test_dataset\"\n        )\n        assert mssql_config is not None\n        assert mssql_dataset[\"fides_key\"] == \"mssql_example_test_dataset\"\n        assert mssql_dataset[\"name\"] == \"Microsoft SQLServer Example Test Dataset\"\n        assert (\n            \"Example of a Microsoft SQLServer dataset\" in mssql_dataset[\"description\"]\n        )\n        assert len(mssql_dataset[\"collections\"]) == 11\n\n        # check the mysql dataset\n        mysql_dataset = response_body[\"succeeded\"][5]\n        mysql_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"mysql_example_test_dataset\"\n        )\n        assert mysql_config is not None\n        assert mysql_dataset[\"fides_key\"] == \"mysql_example_test_dataset\"\n        assert mysql_dataset[\"name\"] == \"MySQL Example Test Dataset\"\n        assert \"Example of a MySQL dataset\" in mysql_dataset[\"description\"]\n        assert len(mysql_dataset[\"collections\"]) == 11\n\n        # check the mariadb dataset\n        mariadb_dataset = response_body[\"succeeded\"][6]\n        mariadb_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"mariadb_example_test_dataset\"\n        )\n        assert mariadb_config is not None\n        assert mariadb_dataset[\"fides_key\"] == \"mariadb_example_test_dataset\"\n        assert mariadb_dataset[\"name\"] == \"MariaDB Example Test Dataset\"\n        assert \"Example of a MariaDB dataset\" in mariadb_dataset[\"description\"]\n        assert len(mariadb_dataset[\"collections\"]) == 11\n\n        postgres_config.delete(db)\n        mongo_config.delete(db)\n        mssql_config.delete(db)\n        mysql_config.delete(db)\n        mariadb_config.delete(db)\n\n    def test_patch_datasets_bulk_update(\n        self,\n        example_datasets,\n        datasets_url,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ) -> None:\n        # Create first, then update\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        api_client.patch(datasets_url, headers=auth_header, json=example_datasets)\n\n        updated_datasets = example_datasets.copy()\n        # Remove all collections from the postgres example, except for the customer table.\n        # Note we also need to remove customer.address_id as it references the addresses table\n        updated_datasets[0][\"collections\"] = [\n            c for c in updated_datasets[0][\"collections\"] if c[\"name\"] == \"customer\"\n        ]\n        updated_datasets[0][\"collections\"][0][\"fields\"] = [\n            f\n            for f in updated_datasets[0][\"collections\"][0][\"fields\"]\n            if f[\"name\"] != \"address_id\"\n        ]\n        # Remove the birthday field from the mongo example\n        updated_datasets[1][\"collections\"][0][\"fields\"] = [\n            f\n            for f in updated_datasets[1][\"collections\"][0][\"fields\"]\n            if f[\"name\"] != \"birthday\"\n        ]\n        # Remove city field from snowflake example\n        updated_datasets[2][\"collections\"][0][\"fields\"] = [\n            f\n            for f in updated_datasets[1][\"collections\"][0][\"fields\"]\n            if f[\"name\"] != \"city\"\n        ]\n        # Remove city field from mssql example\n        updated_datasets[4][\"collections\"][0][\"fields\"] = [\n            f\n            for f in updated_datasets[1][\"collections\"][0][\"fields\"]\n            if f[\"name\"] != \"city\"\n        ]\n        # Remove city field from bigquery example\n        updated_datasets[7][\"collections\"][0][\"fields\"] = [\n            f\n            for f in updated_datasets[1][\"collections\"][0][\"fields\"]\n            if f[\"name\"] != \"city\"\n        ]\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=updated_datasets\n        )\n\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 10\n        assert len(response_body[\"failed\"]) == 0\n\n        # test postgres\n        postgres_dataset = response_body[\"succeeded\"][0]\n        assert postgres_dataset[\"fides_key\"] == \"postgres_example_test_dataset\"\n        assert (\n            len(postgres_dataset[\"collections\"]) == 1\n        )  # all non-customer fields should be removed\n        postgres_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"postgres_example_test_dataset\"\n        )\n        assert postgres_config is not None\n        assert postgres_config.updated_at is not None\n\n        # test mongo\n        mongo_dataset = response_body[\"succeeded\"][1]\n        assert mongo_dataset[\"fides_key\"] == \"mongo_test\"\n        assert \"birthday\" not in [\n            f[\"name\"] for f in mongo_dataset[\"collections\"][0][\"fields\"]\n        ]  # \"birthday field should be removed\n        mongo_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"mongo_test\"\n        )\n        assert mongo_config is not None\n        assert mongo_config.updated_at is not None\n\n        # test snowflake\n        snowflake_dataset = response_body[\"succeeded\"][2]\n        assert snowflake_dataset[\"fides_key\"] == \"snowflake_example_test_dataset\"\n        assert \"city\" not in [\n            f[\"name\"] for f in snowflake_dataset[\"collections\"][0][\"fields\"]\n        ]\n        snowflake_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"snowflake_example_test_dataset\"\n        )\n        assert snowflake_config is not None\n        assert snowflake_config.updated_at is not None\n\n        # test mssql\n        mssql_dataset = response_body[\"succeeded\"][4]\n        assert mssql_dataset[\"fides_key\"] == \"mssql_example_test_dataset\"\n        assert \"city\" not in [\n            f[\"name\"] for f in mssql_dataset[\"collections\"][0][\"fields\"]\n        ]\n        mssql_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"mssql_example_test_dataset\"\n        )\n        assert mssql_config is not None\n        assert mssql_config.updated_at is not None\n\n        # test bigquery\n        bigquery_dataset = response_body[\"succeeded\"][7]\n        assert bigquery_dataset[\"fides_key\"] == \"bigquery_example_test_dataset\"\n        assert \"city\" not in [\n            f[\"name\"] for f in bigquery_dataset[\"collections\"][0][\"fields\"]\n        ]\n        bigquery_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"bigquery_example_test_dataset\"\n        )\n        assert bigquery_config is not None\n        assert bigquery_config.updated_at is not None\n\n        postgres_config.delete(db)\n        mongo_config.delete(db)\n        snowflake_config.delete(db)\n        mssql_config.delete(db)\n        bigquery_config.delete(db)\n\n    @pytest.mark.unit_saas\n    def test_patch_datasets_missing_saas_config(\n        self,\n        saas_example_connection_config_without_saas_config,\n        saas_example_dataset,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ):\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\n            \"connection_key\": saas_example_connection_config_without_saas_config.key\n        }\n        datasets_url = path.format(**path_params)\n\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=[saas_example_dataset]\n        )\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 0\n        assert len(response_body[\"failed\"]) == 1\n        assert (\n            response_body[\"failed\"][0][\"message\"]\n            == f\"Connection config '{saas_example_connection_config_without_saas_config.key}' \"\n            \"must have a SaaS config before validating or adding a dataset\"\n        )\n\n    @pytest.mark.unit_saas\n    def test_patch_datasets_extra_reference(\n        self,\n        saas_example_connection_config,\n        saas_example_dataset,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ):\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\"connection_key\": saas_example_connection_config.key}\n        datasets_url = path.format(**path_params)\n\n        invalid_dataset = saas_example_dataset\n        invalid_dataset[\"collections\"][0][\"fields\"][0][\"fidesops_meta\"] = {\n            \"references\": [\n                {\n                    \"dataset\": \"postgres_example_test_dataset\",\n                    \"field\": \"another.field\",\n                    \"direction\": \"from\",\n                },\n            ]\n        }\n\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=[invalid_dataset]\n        )\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 0\n        assert len(response_body[\"failed\"]) == 1\n        assert (\n            response_body[\"failed\"][0][\"message\"]\n            == \"A dataset for a ConnectionConfig type of 'saas' is not allowed to have \"\n            \"references or identities. Please add them to the SaaS config.\"\n        )\n\n    @pytest.mark.unit_saas\n    def test_patch_datasets_extra_identity(\n        self,\n        saas_example_connection_config,\n        saas_example_dataset,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ):\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\"connection_key\": saas_example_connection_config.key}\n        datasets_url = path.format(**path_params)\n\n        invalid_dataset = saas_example_dataset\n        invalid_dataset[\"collections\"][0][\"fields\"][0][\"fidesops_meta\"] = {\n            \"identity\": \"email\"\n        }\n\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=[invalid_dataset]\n        )\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 0\n        assert len(response_body[\"failed\"]) == 1\n        assert (\n            response_body[\"failed\"][0][\"message\"]\n            == \"A dataset for a ConnectionConfig type of 'saas' is not allowed to have \"\n            \"references or identities. Please add them to the SaaS config.\"\n        )\n\n    @pytest.mark.unit_saas\n    def test_patch_datasets_fides_key_mismatch(\n        self,\n        saas_example_connection_config,\n        saas_example_dataset,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ):\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\"connection_key\": saas_example_connection_config.key}\n        datasets_url = path.format(**path_params)\n\n        invalid_dataset = saas_example_dataset\n        invalid_dataset[\"fides_key\"] = \"different_key\"\n\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=[invalid_dataset]\n        )\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 0\n        assert len(response_body[\"failed\"]) == 1\n        assert (\n            response_body[\"failed\"][0][\"message\"]\n            == \"The fides_key 'different_key' of the dataset does not match the fides_key \"\n            \"'saas_connector_example' of the connection config\"\n        )\n\n    @mock.patch(\"fidesops.ops.models.datasetconfig.DatasetConfig.create_or_update\")\n    def test_patch_datasets_failed_response(\n        self,\n        mock_create: Mock,\n        example_datasets: List,\n        datasets_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        mock_create.side_effect = HTTPException(mock.Mock(status=400), \"Test error\")\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            datasets_url, headers=auth_header, json=example_datasets\n        )\n        assert response.status_code == 200  # Returns 200 regardless\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 0\n        assert len(response_body[\"failed\"]) == 10\n\n        for failed_response in response_body[\"failed\"]:\n            assert \"Dataset create/update failed\" in failed_response[\"message\"]\n            assert set(failed_response.keys()) == {\"message\", \"data\"}\n\n        for index, failed in enumerate(response_body[\"failed\"]):\n            assert failed[\"data\"][\"fides_key\"] == example_datasets[index][\"fides_key\"]\n\n\nclass TestPutYamlDatasets:\n    @pytest.fixture\n    def dataset_url(self, connection_config) -> str:\n        path = V1_URL_PREFIX + YAML_DATASETS\n        path_params = {\"connection_key\": connection_config.key}\n        return path.format(**path_params)\n\n    def test_patch_dataset_not_authenticated(\n        self, example_yaml_dataset: str, dataset_url, api_client\n    ) -> None:\n        response = api_client.patch(dataset_url, headers={}, data=example_yaml_dataset)\n        assert response.status_code == 401\n\n    def test_patch_datasets_wrong_scope(\n        self,\n        example_yaml_dataset: str,\n        dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.patch(\n            dataset_url, headers=auth_header, data=example_yaml_dataset\n        )\n        assert response.status_code == 403\n\n    def test_patch_dataset_invalid_connection_key(\n        self, example_yaml_dataset: str, api_client: TestClient, generate_auth_header\n    ) -> None:\n        path = V1_URL_PREFIX + YAML_DATASETS\n        path_params = {\"connection_key\": \"nonexistent_key\"}\n        dataset_url = path.format(**path_params)\n\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            dataset_url, headers=auth_header, data=example_yaml_dataset\n        )\n        assert response.status_code == 404\n\n    def test_patch_dataset_invalid_content_type(\n        self,\n        dataset_url: str,\n        example_datasets: str,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            dataset_url, headers=auth_header, json=example_datasets\n        )\n        assert response.status_code == 415\n\n    def test_patch_dataset_invalid_content(\n        self,\n        dataset_url: str,\n        example_invalid_yaml_dataset: str,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        headers = {\"Content-type\": \"application/x-yaml\"}\n        headers.update(auth_header)\n        response = api_client.patch(\n            dataset_url, headers=headers, data=example_invalid_yaml_dataset\n        )\n        assert response.status_code == 400\n\n    @mock.patch(\"fidesops.ops.models.datasetconfig.DatasetConfig.create_or_update\")\n    def test_patch_datasets_failed_response(\n        self,\n        mock_create: Mock,\n        example_yaml_dataset: str,\n        dataset_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        mock_create.side_effect = HTTPException(mock.Mock(status=400), \"Test error\")\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        headers = {\"Content-type\": \"application/x-yaml\"}\n        headers.update(auth_header)\n        response = api_client.patch(\n            dataset_url, headers=headers, data=example_yaml_dataset\n        )\n        assert response.status_code == 200  # Returns 200 regardless\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 0\n        assert len(response_body[\"failed\"]) == 1\n\n        for failed_response in response_body[\"failed\"]:\n            assert \"Dataset create/update failed\" in failed_response[\"message\"]\n            assert set(failed_response.keys()) == {\"message\", \"data\"}\n\n    def test_patch_dataset_create(\n        self,\n        example_yaml_dataset: List,\n        dataset_url,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        headers = {\"Content-type\": \"application/x-yaml\"}\n        headers.update(auth_header)\n        response = api_client.patch(\n            dataset_url, headers=headers, data=example_yaml_dataset\n        )\n\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 1\n        assert len(response_body[\"failed\"]) == 0\n\n        # Confirm that postgres dataset matches the values we provided\n        postgres_dataset = response_body[\"succeeded\"][0]\n        postgres_config = DatasetConfig.get_by(\n            db=db, field=\"fides_key\", value=\"postgres_example_test_dataset\"\n        )\n        assert postgres_config is not None\n        assert postgres_dataset[\"fides_key\"] == \"postgres_example_test_dataset\"\n        assert postgres_dataset[\"name\"] == \"Postgres Example Test Dataset\"\n        assert \"Example of a Postgres dataset\" in postgres_dataset[\"description\"]\n        assert len(postgres_dataset[\"collections\"]) == 11\n\n        postgres_config.delete(db)\n\n    def test_patch_datasets_create(\n        self,\n        example_yaml_datasets: List,\n        dataset_url,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        headers = {\"Content-type\": \"application/x-yaml\"}\n        headers.update(auth_header)\n        response = api_client.patch(\n            dataset_url, headers=headers, data=example_yaml_datasets\n        )\n\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert len(response_body[\"succeeded\"]) == 2\n        assert len(response_body[\"failed\"]) == 0\n\n\nclass TestGetDatasets:\n    @pytest.fixture\n    def datasets_url(self, connection_config) -> str:\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\"connection_key\": connection_config.key}\n        return path.format(**path_params)\n\n    def test_get_datasets_not_authenticated(\n        self, dataset_config, datasets_url, api_client: TestClient, generate_auth_header\n    ) -> None:\n        response = api_client.get(datasets_url, headers={})\n        assert response.status_code == 401\n\n    def test_get_datasets_invalid_connection_key(\n        self, dataset_config, datasets_url, api_client: TestClient, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\"connection_key\": \"nonexistent_key\"}\n        datasets_url = path.format(**path_params)\n\n        response = api_client.get(datasets_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_get_datasets(\n        self, dataset_config, datasets_url, api_client: TestClient, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.get(datasets_url, headers=auth_header)\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n        assert len(response_body[\"items\"]) == 1\n        dataset_response = response_body[\"items\"][0]\n        assert dataset_response[\"fides_key\"] == \"postgres_example_subscriptions_dataset\"\n        assert len(dataset_response[\"collections\"]) == 1\n\n        assert response_body[\"total\"] == 1\n        assert response_body[\"page\"] == 1\n        assert response_body[\"size\"] == Params().size\n\n\ndef get_dataset_url(\n    connection_config: Optional[ConnectionConfig] = None,\n    dataset_config: Optional[DatasetConfig] = None,\n) -> str:\n    \"\"\"Helper to construct the DATASET_BY_KEY URL, substituting valid/invalid keys in the path\"\"\"\n    path = V1_URL_PREFIX + DATASET_BY_KEY\n    connection_key = \"nonexistent_key\"\n    if connection_config:\n        connection_key = connection_config.key\n    fides_key = \"nonexistent_key\"\n    if dataset_config:\n        fides_key = dataset_config.fides_key\n    path_params = {\"connection_key\": connection_key, \"fides_key\": fides_key}\n    return path.format(**path_params)\n\n\nclass TestGetDataset:\n    def test_get_dataset_not_authenticated(\n        self, dataset_config, connection_config, api_client\n    ) -> None:\n        dataset_url = get_dataset_url(connection_config, dataset_config)\n        response = api_client.get(dataset_url, headers={})\n        assert response.status_code == 401\n\n    def test_get_dataset_wrong_scope(\n        self,\n        dataset_config,\n        connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        dataset_url = get_dataset_url(connection_config, dataset_config)\n        auth_header = generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE])\n        response = api_client.get(dataset_url, headers=auth_header)\n        assert response.status_code == 403\n\n    def test_get_dataset_does_not_exist(\n        self,\n        dataset_config,\n        connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        dataset_url = get_dataset_url(connection_config, None)\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.get(dataset_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_get_dataset_invalid_connection_key(\n        self,\n        dataset_config,\n        connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        dataset_url = get_dataset_url(None, dataset_config)\n        dataset_url.replace(connection_config.key, \"nonexistent_key\")\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.get(dataset_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_get_dataset(\n        self,\n        dataset_config,\n        connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ):\n        dataset_url = get_dataset_url(connection_config, dataset_config)\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.get(dataset_url, headers=auth_header)\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n        assert response_body[\"fides_key\"] == dataset_config.fides_key\n        assert len(response_body[\"collections\"]) == 1\n\n\nclass TestDeleteDataset:\n    def test_delete_dataset_not_authenticated(\n        self, dataset_config, connection_config, api_client\n    ) -> None:\n        dataset_url = get_dataset_url(connection_config, dataset_config)\n        response = api_client.delete(dataset_url, headers={})\n        assert response.status_code == 401\n\n    def test_delete_dataset_wrong_scope(\n        self,\n        dataset_config,\n        connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        dataset_url = get_dataset_url(connection_config, dataset_config)\n        auth_header = generate_auth_header(scopes=[DATASET_READ])\n        response = api_client.delete(dataset_url, headers=auth_header)\n        assert response.status_code == 403\n\n    def test_delete_dataset_does_not_exist(\n        self,\n        dataset_config,\n        connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        dataset_url = get_dataset_url(connection_config, None)\n        auth_header = generate_auth_header(scopes=[DATASET_DELETE])\n        response = api_client.delete(dataset_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_delete_dataset_invalid_connection_key(\n        self,\n        dataset_config,\n        connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        dataset_url = get_dataset_url(None, dataset_config)\n        auth_header = generate_auth_header(scopes=[DATASET_DELETE])\n        response = api_client.delete(dataset_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_delete_dataset(\n        self,\n        db: Session,\n        connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        # Create a new dataset config so we don't run into issues trying to clean up an\n        # already deleted fixture\n        dataset_config = DatasetConfig.create(\n            db=db,\n            data={\n                \"connection_config_id\": connection_config.id,\n                \"fides_key\": \"postgres_example_subscriptions\",\n                \"dataset\": {\n                    \"fides_key\": \"postgres_example_subscriptions\",\n                    \"name\": \"Postgres Example Subscribers Dataset\",\n                    \"description\": \"Example Postgres dataset created in test fixtures\",\n                    \"dataset_type\": \"PostgreSQL\",\n                    \"location\": \"postgres_example.test\",\n                    \"collections\": [\n                        {\n                            \"name\": \"subscriptions\",\n                            \"fields\": [\n                                {\n                                    \"name\": \"id\",\n                                    \"data_categories\": [\"system.operations\"],\n                                },\n                            ],\n                        },\n                    ],\n                },\n            },\n        )\n\n        dataset_url = get_dataset_url(connection_config, dataset_config)\n        auth_header = generate_auth_header(scopes=[DATASET_DELETE])\n        response = api_client.delete(dataset_url, headers=auth_header)\n        assert response.status_code == 204\n\n        assert (\n            DatasetConfig.get_by(\n                db=db, field=\"fides_key\", value=dataset_config.fides_key\n            )\n            is None\n        )\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_email_endpoints.py", "content": "import json\n\nimport pytest\nfrom fastapi_pagination import Params\nfrom sqlalchemy.orm import Session\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    EMAIL_CREATE_OR_UPDATE,\n    EMAIL_DELETE,\n    EMAIL_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    EMAIL_BY_KEY,\n    EMAIL_CONFIG,\n    EMAIL_SECRETS,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.email import EmailConfig\nfrom fidesops.ops.schemas.email.email import (\n    EmailServiceDetails,\n    EmailServiceSecrets,\n    EmailServiceType,\n)\n\nPAGE_SIZE = Params().size\n\n\nclass TestPostEmailConfig:\n    @pytest.fixture(scope=\"function\")\n    def url(self) -> str:\n        return V1_URL_PREFIX + EMAIL_CONFIG\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self):\n        return {\n            \"name\": \"mailgun\",\n            \"service_type\": EmailServiceType.MAILGUN.value,\n            \"details\": {EmailServiceDetails.DOMAIN.value: \"my.mailgun.domain\"},\n        }\n\n    def test_post_email_config_not_authenticated(\n        self, api_client: TestClient, payload, url\n    ):\n        response = api_client.post(url, headers={}, json=payload)\n        assert 401 == response.status_code\n\n    def test_post_email_config_incorrect_scope(\n        self,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([EMAIL_READ])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n\n    def test_post_email_config_with_invalid_mailgun_details(\n        self,\n        db: Session,\n        api_client: TestClient,\n        url,\n        payload,\n        generate_auth_header,\n    ):\n        payload[\"details\"] = {\"invalid\": \"invalid\"}\n\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert 422 == response.status_code\n        assert json.loads(response.text)[\"detail\"][0][\"msg\"] == \"field required\"\n        assert (\n            json.loads(response.text)[\"detail\"][1][\"msg\"]\n            == \"extra fields not permitted\"\n        )\n\n    def test_post_email_config_with_not_supported_service_type(\n        self,\n        db: Session,\n        api_client: TestClient,\n        url,\n        payload,\n        generate_auth_header,\n    ):\n        payload[\"service_type\"] = \"twilio\"\n\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"value is not a valid enumeration member; permitted: 'mailgun'\"\n        )\n\n    def test_post_email_config_with_no_key(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n\n        assert 200 == response.status_code\n        response_body = json.loads(response.text)\n\n        assert response_body[\"key\"] == \"mailgun\"\n        email_config = db.query(EmailConfig).filter_by(key=\"mailgun\")[0]\n        email_config.delete(db)\n\n    def test_post_email_config_with_invalid_key(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        payload[\"key\"] = \"*invalid-key\"\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"FidesKey must only contain alphanumeric characters, '.', '_' or '-'.\"\n        )\n\n    def test_post_email_config_with_key(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        payload[\"key\"] = \"my_email_config\"\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n\n        response_body = json.loads(response.text)\n        email_config = db.query(EmailConfig).filter_by(key=\"my_email_config\")[0]\n\n        expected_response = {\n            \"key\": \"my_email_config\",\n            \"name\": \"mailgun\",\n            \"service_type\": EmailServiceType.MAILGUN.value,\n            \"details\": {\n                EmailServiceDetails.API_VERSION.value: \"v3\",\n                EmailServiceDetails.DOMAIN.value: \"my.mailgun.domain\",\n                EmailServiceDetails.IS_EU_DOMAIN.value: False,\n            },\n        }\n        assert expected_response == response_body\n        email_config.delete(db)\n\n    def test_post_email_config_missing_detail(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        response = api_client.post(\n            url,\n            headers=auth_header,\n            json={\n                \"key\": \"my_email_config\",\n                \"name\": \"mailgun\",\n                \"service_type\": EmailServiceType.MAILGUN.value,\n                \"details\": {\n                    # \"domain\": \"my.mailgun.domain\"\n                },\n            },\n        )\n        assert response.status_code == 422\n        errors = response.json()[\"detail\"]\n        assert \"details\" in errors[0][\"loc\"]\n        assert errors[0][\"msg\"] == \"field required\"\n\n    def test_post_email_config_already_exists(\n        self,\n        api_client: TestClient,\n        url,\n        email_config,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        response = api_client.post(\n            url,\n            headers=auth_header,\n            json={\n                \"key\": \"my_email_config\",\n                \"name\": \"mailgun\",\n                \"service_type\": EmailServiceType.MAILGUN.value,\n                \"details\": {EmailServiceDetails.DOMAIN.value: \"my.mailgun.domain\"},\n            },\n        )\n        assert response.status_code == 400\n        assert response.json() == {\n            \"detail\": \"Only one email config is supported at a time. Config with key my_email_config is already configured.\"\n        }\n\n\nclass TestPatchEmailConfig:\n    @pytest.fixture(scope=\"function\")\n    def url(self, email_config) -> str:\n        return (V1_URL_PREFIX + EMAIL_BY_KEY).format(config_key=email_config.key)\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self):\n        return {\n            \"key\": \"my_email_config\",\n            \"name\": \"mailgun new name\",\n            \"service_type\": EmailServiceType.MAILGUN.value,\n            \"details\": {EmailServiceDetails.DOMAIN.value: \"my.mailgun.domain\"},\n        }\n\n    def test_patch_email_config_not_authenticated(\n        self, api_client: TestClient, payload, url\n    ):\n        response = api_client.patch(url, headers={}, json=payload)\n        assert 401 == response.status_code\n\n    def test_patch_email_config_incorrect_scope(\n        self,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([EMAIL_READ])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n\n    def test_patch_email_config_with_key_not_found(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        email_config,\n        generate_auth_header,\n    ):\n        url = (V1_URL_PREFIX + EMAIL_BY_KEY).format(config_key=\"nonexistent_key\")\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert response.status_code == 404\n        assert response.json() == {\n            \"detail\": \"No email config found with key nonexistent_key\"\n        }\n\n    def test_patch_email_config_with_key(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n\n        response_body = json.loads(response.text)\n        email_config = db.query(EmailConfig).filter_by(key=\"my_email_config\")[0]\n\n        expected_response = {\n            \"key\": \"my_email_config\",\n            \"name\": \"mailgun new name\",\n            \"service_type\": EmailServiceType.MAILGUN.value,\n            \"details\": {\n                EmailServiceDetails.API_VERSION.value: \"v3\",\n                EmailServiceDetails.DOMAIN.value: \"my.mailgun.domain\",\n                EmailServiceDetails.IS_EU_DOMAIN.value: False,\n            },\n        }\n        assert expected_response == response_body\n        email_config.delete(db)\n\n\nclass TestPutEmailConfigSecretsMailgun:\n    @pytest.fixture(scope=\"function\")\n    def url(self, email_config) -> str:\n        return (V1_URL_PREFIX + EMAIL_SECRETS).format(config_key=email_config.key)\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self):\n        return {\n            EmailServiceSecrets.MAILGUN_API_KEY.value: \"1345234524\",\n        }\n\n    def test_put_config_secrets_unauthenticated(\n        self, api_client: TestClient, payload, url\n    ):\n        response = api_client.put(url, headers={}, json=payload)\n        assert 401 == response.status_code\n\n    def test_put_config_secrets_wrong_scope(\n        self, api_client: TestClient, payload, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([EMAIL_READ])\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n\n    def test_put_config_secret_invalid_config(\n        self, api_client: TestClient, payload, generate_auth_header\n    ):\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        url = (V1_URL_PREFIX + EMAIL_SECRETS).format(config_key=\"invalid_key\")\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 404 == response.status_code\n\n    def test_update_with_invalid_secrets_key(\n        self, api_client: TestClient, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        response = api_client.put(url, headers=auth_header, json={\"bad_key\": \"12345\"})\n\n        assert response.status_code == 400\n        assert response.json() == {\n            \"detail\": [\n                \"field required ('mailgun_api_key',)\",\n                \"extra fields not permitted ('bad_key',)\",\n            ]\n        }\n\n    def test_put_config_secrets(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n        email_config,\n    ):\n        auth_header = generate_auth_header([EMAIL_CREATE_OR_UPDATE])\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n\n        db.refresh(email_config)\n\n        assert json.loads(response.text) == {\n            \"msg\": \"Secrets updated for EmailConfig with key: my_email_config.\",\n            \"test_status\": None,\n            \"failure_reason\": None,\n        }\n        assert (\n            email_config.secrets[EmailServiceSecrets.MAILGUN_API_KEY.value]\n            == \"1345234524\"\n        )\n\n\nclass TestGetEmailConfigs:\n    @pytest.fixture(scope=\"function\")\n    def url(self) -> str:\n        return V1_URL_PREFIX + EMAIL_CONFIG\n\n    def test_get_configs_not_authenticated(self, api_client: TestClient, url) -> None:\n        response = api_client.get(url)\n        assert 401 == response.status_code\n\n    def test_get_configs_wrong_scope(\n        self, api_client: TestClient, url, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header([EMAIL_DELETE])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_configs(\n        self, db, api_client: TestClient, url, generate_auth_header, email_config\n    ):\n        auth_header = generate_auth_header([EMAIL_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        expected_response = {\n            \"items\": [\n                {\n                    \"key\": \"my_email_config\",\n                    \"name\": email_config.name,\n                    \"service_type\": EmailServiceType.MAILGUN.value,\n                    \"details\": {\n                        EmailServiceDetails.API_VERSION.value: \"v3\",\n                        EmailServiceDetails.DOMAIN.value: \"some.domain\",\n                        EmailServiceDetails.IS_EU_DOMAIN.value: False,\n                    },\n                }\n            ],\n            \"page\": 1,\n            \"size\": PAGE_SIZE,\n            \"total\": 1,\n        }\n        response_body = json.loads(response.text)\n        assert expected_response == response_body\n\n\nclass TestGetEmailConfig:\n    @pytest.fixture(scope=\"function\")\n    def url(self, email_config) -> str:\n        return (V1_URL_PREFIX + EMAIL_BY_KEY).format(config_key=email_config.key)\n\n    def test_get_config_not_authenticated(self, url, api_client: TestClient):\n        response = api_client.get(url)\n        assert 401 == response.status_code\n\n    def test_get_config_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header([EMAIL_DELETE])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_config_invalid(\n        self, api_client: TestClient, generate_auth_header, email_config\n    ):\n        auth_header = generate_auth_header([EMAIL_READ])\n        response = api_client.get(\n            (V1_URL_PREFIX + EMAIL_BY_KEY).format(config_key=\"invalid\"),\n            headers=auth_header,\n        )\n        assert 404 == response.status_code\n\n    def test_get_config(\n        self, url, api_client: TestClient, generate_auth_header, email_config\n    ):\n        auth_header = generate_auth_header([EMAIL_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n\n        assert response_body == {\n            \"key\": \"my_email_config\",\n            \"name\": email_config.name,\n            \"service_type\": EmailServiceType.MAILGUN.value,\n            \"details\": {\n                EmailServiceDetails.API_VERSION.value: \"v3\",\n                EmailServiceDetails.DOMAIN.value: \"some.domain\",\n                EmailServiceDetails.IS_EU_DOMAIN.value: False,\n            },\n        }\n\n\nclass TestDeleteConfig:\n    @pytest.fixture(scope=\"function\")\n    def url(self, email_config) -> str:\n        return (V1_URL_PREFIX + EMAIL_BY_KEY).format(config_key=email_config.key)\n\n    def test_delete_config_not_authenticated(self, url, api_client: TestClient):\n        response = api_client.delete(url)\n        assert 401 == response.status_code\n\n    def test_delete_config_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header([EMAIL_READ])\n        response = api_client.delete(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_delete_config_invalid(self, api_client: TestClient, generate_auth_header):\n        auth_header = generate_auth_header([EMAIL_DELETE])\n        response = api_client.delete(\n            (V1_URL_PREFIX + EMAIL_BY_KEY).format(config_key=\"invalid\"),\n            headers=auth_header,\n        )\n        assert 404 == response.status_code\n\n    def test_delete_config(\n        self,\n        db: Session,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n    ):\n        # Creating new config, so we don't run into issues trying to clean up a deleted fixture\n        email_config = EmailConfig.create(\n            db=db,\n            data={\n                \"key\": \"my_different_email_config\",\n                \"name\": \"mailgun\",\n                \"service_type\": EmailServiceType.MAILGUN,\n                \"details\": {EmailServiceDetails.DOMAIN.value: \"my.mailgun.domain\"},\n            },\n        )\n        url = (V1_URL_PREFIX + EMAIL_BY_KEY).format(config_key=email_config.key)\n        auth_header = generate_auth_header([EMAIL_DELETE])\n        response = api_client.delete(url, headers=auth_header)\n        assert response.status_code == 204\n\n        db.expunge_all()\n        config = db.query(EmailConfig).filter_by(key=email_config.key).first()\n        assert config is None\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_encryption_endpoints.py", "content": "import json\nfrom unittest import mock\nfrom unittest.mock import Mock\n\nimport pytest\nfrom fideslib.cryptography.cryptographic_util import b64_str_to_bytes, bytes_to_b64_str\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import ENCRYPTION_EXEC, STORAGE_CREATE_OR_UPDATE\nfrom fidesops.ops.api.v1.urn_registry import (\n    DECRYPT_AES,\n    ENCRYPT_AES,\n    ENCRYPTION_KEY,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.util.encryption.aes_gcm_encryption_scheme import (\n    decrypt,\n    encrypt_verify_secret_length,\n)\n\n\nclass TestGetEncryptionKey:\n    @pytest.fixture\n    def url(self) -> str:\n        return V1_URL_PREFIX + ENCRYPTION_KEY\n\n    def test_get_encryption_key_not_authorized(self, api_client: TestClient, url):\n        response = api_client.get(url)\n\n        assert response.status_code == 401\n\n    def test_get_encryption_key_wrong_scope(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        response = api_client.get(\n            url, headers=generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        )\n        assert response.status_code == 403\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.encryption_endpoints.cryptographic_util.generate_secure_random_string\"\n    )\n    def test_get_encryption_key(\n        self,\n        mock_generate_secure_random: Mock,\n        api_client: TestClient,\n        generate_auth_header,\n        url,\n    ):\n        mock_generate_secure_random.return_value = \"a key\"\n\n        response = api_client.get(url, headers=generate_auth_header([ENCRYPTION_EXEC]))\n\n        assert response.status_code == 200\n        assert response.text == '\"' + mock_generate_secure_random.return_value + '\"'\n\n\nclass TestAESEncrypt:\n    @pytest.fixture\n    def url(self) -> str:\n        return V1_URL_PREFIX + ENCRYPT_AES\n\n    def test_aes_encrypt_not_authorized(self, api_client: TestClient, url):\n        request_body = {\"value\": \"plain_val\", \"key\": \"key\"}\n        response = api_client.put(url, json=request_body)\n        assert response.status_code == 401\n\n    def test_aes_encrypt_wrong_scope(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        response = api_client.put(\n            url, headers=generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        )\n        assert response.status_code == 403\n\n    def test_invalid_key(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n    ):\n        plain_val = \"plain value\"\n        key = \"short\"\n        request_body = {\"value\": plain_val, \"key\": key}\n\n        response = api_client.put(\n            url,\n            headers=generate_auth_header([ENCRYPTION_EXEC]),\n            json=request_body,\n        )\n        assert response.status_code == 422\n\n    def test_aes_encrypt(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n    ):\n        plain_val = \"plain value\"\n        key = \"zfkslapqlwodaqld\"\n        request_body = {\"value\": plain_val, \"key\": key}\n\n        response = api_client.put(\n            url,\n            headers=generate_auth_header([ENCRYPTION_EXEC]),\n            json=request_body,\n        )\n        response_body = json.loads(response.text)\n        encrypted_value = response_body[\"encrypted_value\"]\n        nonce = b64_str_to_bytes(response_body[\"nonce\"])\n\n        assert response.status_code == 200\n        decrypted = decrypt(\n            encrypted_value,\n            key.encode(config.security.encoding),\n            nonce,\n        )\n        assert decrypted == plain_val\n\n\nclass TestAESDecrypt:\n    @pytest.fixture\n    def url(self) -> str:\n        return V1_URL_PREFIX + DECRYPT_AES\n\n    def test_aes_decrypt_not_authorized(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        request = {\"value\": \"encrypted_value\", \"key\": \"key\", \"nonce\": \"nonce\"}\n        response = api_client.put(\n            url,\n            headers=generate_auth_header([]),\n            json=request,\n        )\n\n        assert response.status_code == 403\n\n    def test_aes_decrypt_wrong_scope(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        response = api_client.put(\n            url, headers=generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        )\n        assert response.status_code == 403\n\n    def test_aes_decrypt(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n    ):\n        key = \"zfkslapqlwodaqld\"\n        nonce = b'\\x18\\xf5\"+\\xdbj\\xe6O\\xc7|\\x19\\xd2'\n        orig_data = \"test_data\"\n        encrypted_data = encrypt_verify_secret_length(\n            orig_data, key.encode(config.security.encoding), nonce\n        )\n\n        request = {\n            \"value\": encrypted_data,\n            \"key\": key,\n            \"nonce\": bytes_to_b64_str(nonce),\n        }\n\n        response = api_client.put(\n            url,\n            headers=generate_auth_header([ENCRYPTION_EXEC]),\n            json=request,\n        )\n        response_body = json.loads(response.text)\n\n        assert response.status_code == 200\n        assert response_body[\"decrypted_value\"] == orig_data\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_health_endpoints.py", "content": "from starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.urn_registry import HEALTH\n\n\ndef test_health(api_client: TestClient) -> None:\n    response = api_client.get(HEALTH)\n    assert response.json() == {\n        \"webserver\": \"healthy\",\n        \"database\": \"healthy\",\n        \"cache\": \"healthy\",\n    }\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_identity_verification_endpoints.py", "content": "import pytest\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.urn_registry import ID_VERIFICATION_CONFIG, V1_URL_PREFIX\nfrom fidesops.ops.core.config import config\n\n\nclass TestGetIdentityVerificationConfig:\n    @pytest.fixture(scope=\"function\")\n    def url(self) -> str:\n        return V1_URL_PREFIX + ID_VERIFICATION_CONFIG\n\n    @pytest.fixture(scope=\"function\")\n    def subject_identity_verification_required(self):\n        \"\"\"Override autouse fixture to enable identity verification for tests\"\"\"\n        original_value = config.execution.subject_identity_verification_required\n        config.execution.subject_identity_verification_required = True\n        yield\n        config.execution.subject_identity_verification_required = original_value\n\n    def test_get_config_with_verification_required_no_email_config(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        subject_identity_verification_required,\n    ):\n        resp = api_client.get(url)\n        assert resp.status_code == 200\n        response_data = resp.json()\n        assert response_data[\"identity_verification_required\"] is True\n        assert response_data[\"valid_email_config_exists\"] is False\n\n    def test_get_config_with_verification_required_with_email_config(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        email_config,\n        subject_identity_verification_required,\n    ):\n        resp = api_client.get(url)\n        assert resp.status_code == 200\n        response_data = resp.json()\n        assert response_data[\"identity_verification_required\"] is True\n        assert response_data[\"valid_email_config_exists\"] is True\n\n    def test_get_config_with_verification_not_required_with_email_config(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        email_config,\n    ):\n        resp = api_client.get(url)\n        assert resp.status_code == 200\n        response_data = resp.json()\n        assert response_data[\"identity_verification_required\"] is False\n        assert response_data[\"valid_email_config_exists\"] is True\n\n    def test_get_config_with_verification_not_required_with_no_email_config(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n    ):\n        resp = api_client.get(url)\n        assert resp.status_code == 200\n        response_data = resp.json()\n        assert response_data[\"identity_verification_required\"] is False\n        assert response_data[\"valid_email_config_exists\"] is False\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_manual_webhooks.py", "content": "import pytest\nfrom sqlalchemy.orm import Session\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    CONNECTION_READ,\n    STORAGE_READ,\n    WEBHOOK_CREATE_OR_UPDATE,\n    WEBHOOK_DELETE,\n    WEBHOOK_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    ACCESS_MANUAL_WEBHOOK,\n    ACCESS_MANUAL_WEBHOOKS,\n    CONNECTION_TEST,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.manual_webhook import AccessManualWebhook\n\n\nclass TestGetAccessManualWebhook:\n    @pytest.fixture(scope=\"function\")\n    def url(self, integration_manual_webhook_config) -> str:\n        path = V1_URL_PREFIX + ACCESS_MANUAL_WEBHOOK\n        path_params = {\"connection_key\": integration_manual_webhook_config.key}\n        return path.format(**path_params)\n\n    def test_get_manual_webhook_not_authenticated(self, api_client: TestClient, url):\n        response = api_client.get(url, headers={})\n        assert 401 == response.status_code\n\n    def test_get_manual_webhook_wrong_scopes(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_manual_webhook_does_not_exist(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([WEBHOOK_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No access manual webhook exists for connection config with key 'manual_webhook_example'\"\n        )\n\n    def test_try_to_get_manual_webhook_from_postgres_connector(\n        self, api_client: TestClient, generate_auth_header, connection_config\n    ):\n        auth_header = generate_auth_header([WEBHOOK_READ])\n        url = V1_URL_PREFIX + ACCESS_MANUAL_WEBHOOK.format(\n            connection_key=connection_config.key\n        )\n\n        response = api_client.get(url, headers=auth_header)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"Can't access manual webhooks for ConnectionConfigs of type 'postgres'\"\n        )\n\n    def test_get_manual_webhook(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        auth_header = generate_auth_header([WEBHOOK_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        resp = response.json()\n\n        assert resp[\"fields\"] == [\n            {\"pii_field\": \"email\", \"dsr_package_label\": \"email\"},\n            {\"pii_field\": \"Last Name\", \"dsr_package_label\": \"last_name\"},\n        ]\n        connection_config_details = resp[\"connection_config\"]\n        assert connection_config_details[\"key\"] == integration_manual_webhook_config.key\n        assert connection_config_details[\"connection_type\"] == \"manual_webhook\"\n        assert connection_config_details[\"access\"] == \"read\"\n        assert connection_config_details[\"created_at\"] is not None\n        assert connection_config_details[\"updated_at\"] is not None\n        assert \"secrets\" not in connection_config_details\n\n\nclass TestPostAccessManualWebhook:\n    @pytest.fixture(scope=\"function\")\n    def url(self, integration_manual_webhook_config) -> str:\n        path = V1_URL_PREFIX + ACCESS_MANUAL_WEBHOOK\n        path_params = {\"connection_key\": integration_manual_webhook_config.key}\n        return path.format(**path_params)\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self):\n        return {\n            \"fields\": [\n                {\"pii_field\": \"First name\", \"dsr_package_label\": None},\n                {\"pii_field\": \"Last name\", \"dsr_package_label\": \"last_name\"},\n                {\"pii_field\": \"Order number\", \"dsr_package_label\": \"order_number\"},\n            ]\n        }\n\n    def test_post_manual_webhook_not_authenticated(\n        self, api_client: TestClient, payload, url\n    ):\n        response = api_client.post(url, headers={}, json=payload)\n        assert 401 == response.status_code\n\n    def test_post_manual_webhook_incorrect_scope(\n        self,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([WEBHOOK_READ])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n\n    def test_post_access_manual_webhook_already_exists(\n        self, db, api_client, url, payload, generate_auth_header, access_manual_webhook\n    ):\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == \"An Access Manual Webhook already exists for ConnectionConfig 'manual_webhook_example'.\"\n        )\n\n    def test_access_manual_webhook_pii_field_too_long(\n        self, db, api_client, url, generate_auth_header\n    ):\n        payload = {\n            \"fields\": [{\"pii_field\": \"hello\" * 100, \"dsr_package_label\": \"First Name\"}]\n        }\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 422\n        assert (\n            response.json()[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at most 200 characters\"\n        )\n\n    def test_post_manual_webhook_duplicate_fields(\n        self, db, api_client, url, generate_auth_header\n    ):\n        payload = {\n            \"fields\": [\n                {\"pii_field\": \"first_name\", \"dsr_package_label\": \"First Name\"},\n                {\"pii_field\": \"first_name\", \"dsr_package_label\": \"First Name\"},\n            ]\n        }\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 422\n        assert response.json()[\"detail\"][0][\"msg\"] == \"pii_fields must be unique\"\n\n    def test_post_access_manual_webhook_fields_empty_string(\n        self, db, api_client, url, generate_auth_header\n    ):\n        payload = {\n            \"fields\": [\n                {\"pii_field\": \"first_name\", \"dsr_package_label\": \"First Name\"},\n                {\"pii_field\": \"\", \"dsr_package_label\": \"bad_label\"},\n            ]\n        }\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 422\n        assert (\n            response.json()[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at least 1 characters\"\n        )\n\n    def test_post_access_manual_webhook_pii_label_spaces(\n        self, db, api_client, url, generate_auth_header\n    ):\n        payload = {\n            \"fields\": [\n                {\"pii_field\": \"first_name\", \"dsr_package_label\": \"First Name\"},\n                {\"pii_field\": \"   \", \"dsr_package_label\": \"label\"},\n            ]\n        }\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 422\n        assert (\n            response.json()[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at least 1 characters\"\n        )\n\n    def test_post_access_manual_webhook_dsr_package_labels_empty_string(\n        self, db, api_client, url, generate_auth_header\n    ):\n        payload = {\n            \"fields\": [\n                {\"pii_field\": \"first_name\", \"dsr_package_label\": \"First Name\"},\n                {\"pii_field\": \"last_name\", \"dsr_package_label\": \"\"},\n            ]\n        }\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 201\n        assert response.json()[\"fields\"] == [\n            {\"pii_field\": \"first_name\", \"dsr_package_label\": \"First Name\"},\n            {\"pii_field\": \"last_name\", \"dsr_package_label\": \"last_name\"},\n        ]\n\n    def test_post_access_manual_webhook_dsr_package_labels_spaces(\n        self, db, api_client, url, generate_auth_header\n    ):\n        payload = {\n            \"fields\": [\n                {\"pii_field\": \"first_name\", \"dsr_package_label\": \"First Name\"},\n                {\"pii_field\": \"last_name\", \"dsr_package_label\": \"  \"},\n            ]\n        }\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 201\n        assert response.json()[\"fields\"] == [\n            {\"pii_field\": \"first_name\", \"dsr_package_label\": \"First Name\"},\n            {\"pii_field\": \"last_name\", \"dsr_package_label\": \"last_name\"},\n        ]\n\n    def test_post_access_manual_webhook_wrong_connection_config_type(\n        self, connection_config, payload, generate_auth_header, api_client\n    ):\n        url = V1_URL_PREFIX + ACCESS_MANUAL_WEBHOOK.format(\n            connection_key=connection_config.key\n        )\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == \"You can only create manual webhooks for ConnectionConfigs of type 'manual_webhook'.\"\n        )\n\n    def test_post_webhook_no_fields(\n        self, connection_config, payload, generate_auth_header, api_client, url\n    ):\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json={\"fields\": []})\n\n        assert response.status_code == 422\n        assert (\n            response.json()[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at least 1 items\"\n        )\n\n    def test_post_manual_webhook(\n        self,\n        db: Session,\n        api_client: TestClient,\n        url,\n        payload,\n        generate_auth_header,\n        integration_manual_webhook_config,\n    ):\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert response.status_code == 201\n        resp = response.json()\n\n        assert resp[\"fields\"] == [\n            {\"pii_field\": \"First name\", \"dsr_package_label\": \"first_name\"},\n            {\"pii_field\": \"Last name\", \"dsr_package_label\": \"last_name\"},\n            {\"pii_field\": \"Order number\", \"dsr_package_label\": \"order_number\"},\n        ]\n        connection_config_details = resp[\"connection_config\"]\n        assert connection_config_details[\"key\"] == integration_manual_webhook_config.key\n        assert connection_config_details[\"connection_type\"] == \"manual_webhook\"\n        assert connection_config_details[\"access\"] == \"read\"\n        assert connection_config_details[\"created_at\"] is not None\n        assert connection_config_details[\"updated_at\"] is not None\n        assert \"secrets\" not in connection_config_details\n\n        manual_webhook = AccessManualWebhook.get(db=db, object_id=resp[\"id\"])\n        manual_webhook.delete(db)\n\n\nclass TestPatchAccessManualWebhook:\n    @pytest.fixture(scope=\"function\")\n    def url(self, integration_manual_webhook_config) -> str:\n        path = V1_URL_PREFIX + ACCESS_MANUAL_WEBHOOK\n        path_params = {\"connection_key\": integration_manual_webhook_config.key}\n        return path.format(**path_params)\n\n    def test_patch_manual_webhook_not_authenticated(self, api_client: TestClient, url):\n        response = api_client.patch(url, headers={})\n        assert 401 == response.status_code\n\n    def test_patch_manual_webhook_wrong_scopes(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([WEBHOOK_READ])\n\n        response = api_client.patch(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_patch_manual_webhook_does_not_exist(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        payload = {\n            \"fields\": [\n                {\"pii_field\": \"New Field\", \"dsr_package_label\": None},\n            ]\n        }\n\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No access manual webhook exists for connection config with key 'manual_webhook_example'\"\n        )\n\n    def test_patch_manual_webhook(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        auth_header = generate_auth_header([WEBHOOK_CREATE_OR_UPDATE])\n        payload = {\n            \"fields\": [\n                {\"pii_field\": \"New Field\", \"dsr_package_label\": None},\n            ]\n        }\n\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n\n        resp = response.json()\n\n        assert resp[\"fields\"] == [\n            {\"pii_field\": \"New Field\", \"dsr_package_label\": \"new_field\"},\n        ]\n        connection_config_details = resp[\"connection_config\"]\n        assert connection_config_details[\"key\"] == integration_manual_webhook_config.key\n        assert connection_config_details[\"connection_type\"] == \"manual_webhook\"\n        assert connection_config_details[\"access\"] == \"read\"\n        assert connection_config_details[\"created_at\"] is not None\n        assert connection_config_details[\"updated_at\"] is not None\n        assert \"secrets\" not in connection_config_details\n\n\nclass TestDeleteAccessManualWebhook:\n    @pytest.fixture(scope=\"function\")\n    def url(self, integration_manual_webhook_config) -> str:\n        path = V1_URL_PREFIX + ACCESS_MANUAL_WEBHOOK\n        path_params = {\"connection_key\": integration_manual_webhook_config.key}\n        return path.format(**path_params)\n\n    def test_delete_manual_webhook_not_authenticated(self, api_client: TestClient, url):\n        response = api_client.delete(url, headers={})\n        assert 401 == response.status_code\n\n    def test_delete_manual_webhook_wrong_scopes(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([WEBHOOK_READ])\n\n        response = api_client.delete(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_delete_manual_webhook_does_not_exist(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([WEBHOOK_DELETE])\n\n        response = api_client.delete(url, headers=auth_header)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No access manual webhook exists for connection config with key 'manual_webhook_example'\"\n        )\n\n    def test_delete_manual_webhook(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        assert integration_manual_webhook_config.access_manual_webhook is not None\n        auth_header = generate_auth_header([WEBHOOK_DELETE])\n\n        response = api_client.delete(url, headers=auth_header)\n        assert 204 == response.status_code\n        db.refresh(integration_manual_webhook_config)\n        assert integration_manual_webhook_config.access_manual_webhook is None\n\n\nclass TestGetAccessManualWebhooks:\n    @pytest.fixture(scope=\"function\")\n    def url(self, integration_manual_webhook_config) -> str:\n        return V1_URL_PREFIX + ACCESS_MANUAL_WEBHOOKS\n\n    def test_get_manual_webhook_not_authenticated(self, api_client: TestClient, url):\n        response = api_client.get(url, headers={})\n        assert 401 == response.status_code\n\n    def test_get_manual_webhook_wrong_scopes(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_disabled_webhooks(\n        self,\n        db,\n        api_client,\n        url,\n        generate_auth_header,\n        integration_manual_webhook_config,\n        access_manual_webhook,\n    ):\n        integration_manual_webhook_config.disabled = True\n        integration_manual_webhook_config.save(db)\n\n        auth_header = generate_auth_header([WEBHOOK_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        assert len(response.json()) == 0\n\n    def test_get_manual_webhooks(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        auth_header = generate_auth_header([WEBHOOK_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        assert len(response.json()) == 1\n        resp = response.json()[0]\n\n        assert resp[\"fields\"] == [\n            {\"pii_field\": \"email\", \"dsr_package_label\": \"email\"},\n            {\"pii_field\": \"Last Name\", \"dsr_package_label\": \"last_name\"},\n        ]\n        connection_config_details = resp[\"connection_config\"]\n        assert connection_config_details[\"key\"] == integration_manual_webhook_config.key\n        assert connection_config_details[\"connection_type\"] == \"manual_webhook\"\n        assert connection_config_details[\"access\"] == \"read\"\n        assert connection_config_details[\"created_at\"] is not None\n        assert connection_config_details[\"updated_at\"] is not None\n        assert \"secrets\" not in connection_config_details\n\n\nclass TestManualWebhookTest:\n    @pytest.fixture(scope=\"function\")\n    def url(self, integration_manual_webhook_config) -> str:\n        return V1_URL_PREFIX + CONNECTION_TEST.format(\n            connection_key=integration_manual_webhook_config.key\n        )\n\n    def test_connection_test_manual_webhook_not_authenticated(\n        self, api_client: TestClient, url\n    ):\n        response = api_client.get(url, headers={})\n        assert 401 == response.status_code\n\n    def test_connection_test_manual_webhook_wrong_scopes(\n        self, api_client: TestClient, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_connection_test_manual_webhook_no_webhook_resource(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        integration_manual_webhook_config,\n    ):\n        auth_header = generate_auth_header([CONNECTION_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n        assert response.json()[\"test_status\"] == \"failed\"\n\n    def test_connection_test_manual_webhook_no_webhook_fields(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        integration_manual_webhook_config,\n        access_manual_webhook,\n    ):\n        auth_header = generate_auth_header([CONNECTION_READ])\n        access_manual_webhook.fields = None\n        access_manual_webhook.save(db)\n\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n        assert response.json()[\"test_status\"] == \"failed\"\n\n    def test_connection_test_manual_webhook(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        auth_header = generate_auth_header([CONNECTION_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n        assert response.json()[\"test_status\"] == \"succeeded\"\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_masking_endpoints.py", "content": "import json\n\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.urn_registry import MASKING, MASKING_STRATEGY, V1_URL_PREFIX\nfrom fidesops.ops.schemas.masking.masking_api import MaskingAPIResponse\nfrom fidesops.ops.schemas.masking.masking_configuration import (\n    AesEncryptionMaskingConfiguration,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy import MaskingStrategy\nfrom fidesops.ops.service.masking.strategy.masking_strategy_aes_encrypt import (\n    AesEncryptionMaskingStrategy,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy_hash import (\n    HashMaskingStrategy,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy_hmac import (\n    HmacMaskingStrategy,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy_nullify import (\n    NullMaskingStrategy,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy_random_string_rewrite import (\n    RandomStringRewriteMaskingStrategy,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy_string_rewrite import (\n    StringRewriteMaskingStrategy,\n)\n\n\nclass TestGetMaskingStrategies:\n    def test_read_strategies(self, api_client: TestClient):\n        expected_response = []\n        for strategy in MaskingStrategy.get_strategies():\n            expected_response.append(strategy.get_description())\n\n        response = api_client.get(V1_URL_PREFIX + MASKING_STRATEGY)\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert response_body\n        assert expected_response == response_body\n\n\nclass TestMaskValues:\n    def test_no_strategies_specified(self, api_client: TestClient):\n        value = \"my_email\"\n        request = {\n            \"values\": [value],\n        }\n\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 422 == response.status_code\n\n    def test_mask_nothing(self, api_client: TestClient):\n        request = {\n            \"values\": None,\n            \"masking_strategy\": {\n                \"strategy\": StringRewriteMaskingStrategy.name,\n                \"configuration\": {\"rewrite_value\": \"MASKED\"},\n            },\n        }\n\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 422 == response.status_code\n\n    def test_mask_value_string_rewrite(self, api_client: TestClient):\n        value = \"check\"\n        rewrite_val = \"mate\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": StringRewriteMaskingStrategy.name,\n                \"configuration\": {\"rewrite_value\": rewrite_val},\n            },\n        }\n        expected_response = MaskingAPIResponse(\n            plain=[value], masked_values=[rewrite_val]\n        )\n\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n\n        assert 200 == response.status_code\n        assert expected_response == json.loads(response.text)\n\n    def test_mask_value_random_string_rewrite(self, api_client: TestClient):\n        value = \"my email\"\n        length = 20\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": RandomStringRewriteMaskingStrategy.name,\n                \"configuration\": {\"length\": length},\n            },\n        }\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 200 == response.status_code\n        json_response = json.loads(response.text)\n        assert value == json_response[\"plain\"][0]\n        assert length == len(json_response[\"masked_values\"][0])\n\n    def test_mask_value_hmac(self, api_client: TestClient):\n        value = \"867-5309\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": HmacMaskingStrategy.name,\n                \"configuration\": {},\n            },\n        }\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 200 == response.status_code\n        json_response = json.loads(response.text)\n        assert value == json_response[\"plain\"][0]\n        assert json_response[\"masked_values\"][0] != value\n\n    def test_mask_value_hash(self, api_client: TestClient):\n        value = \"867-5309\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": HashMaskingStrategy.name,\n                \"configuration\": {},\n            },\n        }\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 200 == response.status_code\n        json_response = json.loads(response.text)\n        assert value == json_response[\"plain\"][0]\n        assert json_response[\"masked_values\"][0] != value\n\n    def test_mask_value_hash_multi_value(self, api_client: TestClient):\n        value = \"867-5309\"\n        value2 = \"844-5205\"\n        request = {\n            \"values\": [value, value2],\n            \"masking_strategy\": {\n                \"strategy\": HashMaskingStrategy.name,\n                \"configuration\": {},\n            },\n        }\n        response = api_client.put(\n            f\"{V1_URL_PREFIX}{MASKING}\",\n            json=request,\n        )\n        assert 200 == response.status_code\n        json_response = json.loads(response.text)\n        assert value == json_response[\"plain\"][0]\n        assert value2 == json_response[\"plain\"][1]\n        assert json_response[\"masked_values\"][0] != value\n        assert json_response[\"masked_values\"][1] != value2\n\n    def test_mask_value_hash_multi_value_same_value(self, api_client: TestClient):\n        value = \"867-5309\"\n        request = {\n            \"values\": [value, value],\n            \"masking_strategy\": {\n                \"strategy\": HashMaskingStrategy.name,\n                \"configuration\": {},\n            },\n        }\n        response = api_client.put(\n            f\"{V1_URL_PREFIX}{MASKING}\",\n            json=request,\n        )\n        assert 200 == response.status_code\n        json_response = json.loads(response.text)\n        assert value == json_response[\"plain\"][0]\n        assert value == json_response[\"plain\"][1]\n        assert json_response[\"masked_values\"][0] != value\n        assert json_response[\"masked_values\"][1] != value\n\n    def test_mask_value_aes_encrypt(self, api_client: TestClient):\n        value = \"last name\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": AesEncryptionMaskingStrategy.name,\n                \"configuration\": {\n                    \"mode\": AesEncryptionMaskingConfiguration.Mode.GCM.value\n                },\n            },\n        }\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 200 == response.status_code\n        json_response = json.loads(response.text)\n        assert value == json_response[\"plain\"][0]\n        assert json_response[\"masked_values\"][0] != value\n\n    def test_mask_value_no_such_strategy(self, api_client: TestClient):\n        value = \"check\"\n        rewrite_val = \"mate\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": \"No Such Strategy\",\n                \"configuration\": {\"rewrite_value\": rewrite_val},\n            },\n        }\n\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n\n        assert 404 == response.status_code\n\n    def test_mask_value_invalid_config(self, api_client: TestClient):\n        value = \"check\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": StringRewriteMaskingStrategy.name,\n                \"configuration\": {\"wrong\": \"config\"},\n            },\n        }\n\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n\n        assert 400 == response.status_code\n\n    def test_masking_value_null(self, api_client: TestClient):\n        value = \"my_email\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": NullMaskingStrategy.name,\n                \"configuration\": {},\n            },\n        }\n\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 200 == response.status_code\n        json_response = json.loads(response.text)\n        assert value == json_response[\"plain\"][0]\n        assert json_response[\"masked_values\"][0] is None\n\n    def test_masking_values_multiple_strategies(self, api_client: TestClient):\n        value = \"check\"\n        rewrite_val = \"mate\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": [\n                {\n                    \"strategy\": StringRewriteMaskingStrategy.name,\n                    \"configuration\": {\"rewrite_value\": rewrite_val},\n                },\n                {\n                    \"strategy\": HashMaskingStrategy.name,\n                    \"configuration\": {},\n                },\n            ],\n        }\n\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 200 == response.status_code\n        assert response.json()[\"plain\"] == [\"check\"]\n        assert response.json()[\"masked_values\"] != [\n            rewrite_val\n        ], \"Final value is hashed, because that was the last strategy\"\n\n        switch_order = {\n            \"values\": [value],\n            \"masking_strategy\": [\n                {\n                    \"strategy\": HashMaskingStrategy.name,\n                    \"configuration\": {},\n                },\n                {\n                    \"strategy\": StringRewriteMaskingStrategy.name,\n                    \"configuration\": {\"rewrite_value\": rewrite_val},\n                },\n            ],\n        }\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=switch_order)\n        assert 200 == response.status_code\n        assert response.json()[\"plain\"] == [\"check\"]\n        assert response.json()[\"masked_values\"] == [\n            rewrite_val\n        ], \"Final value is rewrite value, because that was the last strategy specified\"\n\n    def test_flexible_config(self, api_client: TestClient):\n        \"\"\"Test that this request is allowed.  Allow the configuration to be\n        very flexible so different configuration requirements by many masking strategies are supported\"\"\"\n        value = \"my_email\"\n        request = {\n            \"values\": [value],\n            \"masking_strategy\": {\n                \"strategy\": NullMaskingStrategy.name,\n                \"configuration\": {\"test_val\": {\"test\": [[\"test\"]]}},\n            },\n        }\n\n        response = api_client.put(f\"{V1_URL_PREFIX}{MASKING}\", json=request)\n        assert 200 == response.status_code\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_oauth_endpoints.py", "content": "import json\nfrom datetime import datetime\nfrom unittest import mock\nfrom unittest.mock import Mock\n\nimport pytest\nfrom fideslib.cryptography.schemas.jwt import (\n    JWE_ISSUED_AT,\n    JWE_PAYLOAD_CLIENT_ID,\n    JWE_PAYLOAD_SCOPES,\n)\nfrom fideslib.models.client import ClientDetail\nfrom fideslib.oauth.jwt import generate_jwe\nfrom fideslib.oauth.oauth_util import extract_payload\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    CLIENT_CREATE,\n    CLIENT_DELETE,\n    CLIENT_READ,\n    CLIENT_UPDATE,\n    SCOPE_READ,\n    SCOPE_REGISTRY,\n    STORAGE_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    CLIENT,\n    CLIENT_BY_ID,\n    CLIENT_SCOPE,\n    OAUTH_CALLBACK,\n    SCOPE,\n    TOKEN,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.common_exceptions import OAuth2TokenException\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.authentication_request import AuthenticationRequest\n\n\nclass TestCreateClient:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client) -> str:\n        return V1_URL_PREFIX + CLIENT\n\n    def test_create_client_not_authenticated(self, api_client: TestClient, url):\n        response = api_client.post(url)\n        assert response.status_code == 401\n\n    def test_create_client_wrong_scope(\n        self, api_client: TestClient, url, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_READ])\n        response = api_client.post(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_create_client_lacks_client(self, api_client: TestClient, url) -> None:\n        payload = {\n            JWE_PAYLOAD_SCOPES: [CLIENT_CREATE],\n        }\n        # Build auth header without client\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n\n        response = api_client.post(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_create_client_with_expired_token(\n        self, api_client: TestClient, url, oauth_client\n    ):\n        payload = {\n            JWE_PAYLOAD_CLIENT_ID: oauth_client.id,\n            JWE_PAYLOAD_SCOPES: oauth_client.scopes,\n            JWE_ISSUED_AT: datetime(1995, 1, 1).isoformat(),\n        }\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n        response = api_client.post(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_create_client(\n        self,\n        db,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_CREATE])\n\n        response = api_client.post(url, headers=auth_header)\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert list(response_body.keys()) == [\"client_id\", \"client_secret\"]\n\n        new_client = ClientDetail.get(\n            db, object_id=response_body[\"client_id\"], config=config\n        )\n        assert new_client.hashed_secret != response_body[\"client_secret\"]\n\n        new_client.delete(db)\n\n    def test_create_client_with_scopes(\n        self,\n        db,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_CREATE])\n\n        scopes = [\n            CLIENT_CREATE,\n            CLIENT_DELETE,\n            CLIENT_READ,\n        ]\n        response = api_client.post(\n            url,\n            headers=auth_header,\n            json=scopes,\n        )\n        response_body = json.loads(response.text)\n        assert 200 == response.status_code\n        assert list(response_body.keys()) == [\"client_id\", \"client_secret\"]\n\n        new_client = ClientDetail.get(\n            db, object_id=response_body[\"client_id\"], config=config\n        )\n        assert new_client.scopes == scopes\n\n        new_client.delete(db)\n\n    def test_create_client_with_invalid_scopes(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_CREATE])\n\n        response = api_client.post(\n            url,\n            headers=auth_header,\n            json=[\"invalid-scope\"],\n        )\n\n        assert 422 == response.status_code\n        assert response.json()[\"detail\"].startswith(\"Invalid Scope.\")\n\n\nclass TestGetClientScopes:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client) -> str:\n        return V1_URL_PREFIX + CLIENT_SCOPE.format(client_id=oauth_client.id)\n\n    def test_get_scopes_not_authenticated(\n        self, api_client: TestClient, oauth_client: ClientDetail, url\n    ):\n        response = api_client.get(url)\n        assert response.status_code == 401\n\n    def test_get_scopes_wrong_scope(\n        self,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_scopes_invalid_client(\n        self, api_client: TestClient, oauth_client: ClientDetail, generate_auth_header\n    ) -> None:\n        url = V1_URL_PREFIX + CLIENT_SCOPE.format(client_id=\"bad_client\")\n\n        auth_header = generate_auth_header([CLIENT_READ])\n        response = api_client.get(url, headers=auth_header)\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert response_body == []\n\n    def test_get_scopes(\n        self,\n        db,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert response_body == SCOPE_REGISTRY\n\n\nclass TestSetClientScopes:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client) -> str:\n        return V1_URL_PREFIX + CLIENT_SCOPE.format(client_id=oauth_client.id)\n\n    def test_set_scopes_not_authenticated(\n        self, api_client: TestClient, oauth_client: ClientDetail, url\n    ):\n        response = api_client.put(url)\n        assert response.status_code == 401\n\n    def test_set_scopes_wrong_scope(\n        self,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_READ])\n        response = api_client.put(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_set_invalid_scope(\n        self,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_UPDATE])\n\n        response = api_client.put(\n            url, headers=auth_header, json=[\"this-is-not-a-valid-scope\"]\n        )\n        assert 422 == response.status_code\n\n    def test_set_scopes_invalid_client(\n        self, api_client: TestClient, oauth_client: ClientDetail, generate_auth_header\n    ) -> None:\n        url = V1_URL_PREFIX + CLIENT_SCOPE.format(client_id=\"bad_client\")\n\n        auth_header = generate_auth_header([CLIENT_UPDATE])\n        response = api_client.put(url, headers=auth_header, json=[\"storage:read\"])\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert response_body is None  # No action was taken\n\n    def test_set_scopes(\n        self,\n        db,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_UPDATE])\n\n        response = api_client.put(url, headers=auth_header, json=[\"storage:read\"])\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert response_body is None\n\n        db.refresh(oauth_client)\n        assert oauth_client.scopes == [\"storage:read\"]\n\n\nclass TestReadScopes:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client) -> str:\n        return V1_URL_PREFIX + SCOPE\n\n    def test_get_scopes_not_authenticated(self, api_client: TestClient, url):\n        response = api_client.get(url)\n        assert response.status_code == 401\n\n    def test_get_scopes_wrong_scope(\n        self,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_scopes(\n        self,\n        db,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([SCOPE_READ])\n\n        response = api_client.get(url, headers=auth_header)\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert response_body == SCOPE_REGISTRY\n\n\nclass TestDeleteClient:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client) -> str:\n        return V1_URL_PREFIX + CLIENT_BY_ID.format(client_id=oauth_client.id)\n\n    def test_delete_client_not_authenticated(\n        self, api_client: TestClient, oauth_client: ClientDetail, url\n    ):\n        response = api_client.delete(url)\n        assert response.status_code == 401\n\n    def test_delete_client_wrong_scope(\n        self,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_READ])\n        response = api_client.delete(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_delete_client_invalid_client(\n        self, api_client: TestClient, oauth_client: ClientDetail, generate_auth_header\n    ) -> None:\n        url = V1_URL_PREFIX + CLIENT_BY_ID.format(client_id=\"bad_client\")\n\n        auth_header = generate_auth_header([CLIENT_DELETE])\n        response = api_client.delete(url, headers=auth_header)\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert response_body is None  # No indicator that client didn't exist\n\n    def test_delete_client(\n        self,\n        db,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_DELETE])\n\n        response = api_client.delete(url, headers=auth_header)\n        response_body = json.loads(response.text)\n\n        assert 200 == response.status_code\n        assert response_body is None\n\n        db.expunge_all()\n        client = ClientDetail.get(db, object_id=oauth_client.id, config=config)\n        assert client is None\n\n\nclass TestAcquireAccessToken:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client) -> str:\n        return V1_URL_PREFIX + TOKEN\n\n    def test_no_form_data(self, db, url, api_client):\n        response = api_client.post(url, data={})\n        assert response.status_code == 401\n\n    def test_invalid_client(self, db, url, api_client):\n        response = api_client.post(\n            url, data={\"client_id\": \"notaclient\", \"secret\": \"badsecret\"}\n        )\n        assert response.status_code == 401\n\n    def test_invalid_client_secret(self, db, url, api_client):\n        new_client, _ = ClientDetail.create_client_and_secret(\n            db,\n            config.security.oauth_client_id_length_bytes,\n            config.security.oauth_client_secret_length_bytes,\n        )\n        response = api_client.post(\n            url, data={\"client_id\": new_client.id, \"secret\": \"badsecret\"}\n        )\n        assert response.status_code == 401\n\n        new_client.delete(db)\n\n    def test_get_access_token_root_client(self, url, api_client):\n        data = {\n            \"client_id\": config.security.oauth_root_client_id,\n            \"client_secret\": config.security.oauth_root_client_secret,\n        }\n\n        response = api_client.post(url, data=data)\n        jwt = json.loads(response.text).get(\"access_token\")\n        assert 200 == response.status_code\n        assert (\n            data[\"client_id\"]\n            == json.loads(extract_payload(jwt, config.security.app_encryption_key))[\n                JWE_PAYLOAD_CLIENT_ID\n            ]\n        )\n        assert (\n            json.loads(extract_payload(jwt, config.security.app_encryption_key))[\n                JWE_PAYLOAD_SCOPES\n            ]\n            == SCOPE_REGISTRY\n        )\n\n    def test_get_access_token(self, db, url, api_client):\n        new_client, secret = ClientDetail.create_client_and_secret(\n            db,\n            config.security.oauth_client_id_length_bytes,\n            config.security.oauth_client_secret_length_bytes,\n        )\n\n        data = {\n            \"client_id\": new_client.id,\n            \"client_secret\": secret,\n        }\n\n        response = api_client.post(url, data=data)\n        jwt = json.loads(response.text).get(\"access_token\")\n        assert 200 == response.status_code\n        assert (\n            data[\"client_id\"]\n            == json.loads(extract_payload(jwt, config.security.app_encryption_key))[\n                JWE_PAYLOAD_CLIENT_ID\n            ]\n        )\n        assert (\n            json.loads(extract_payload(jwt, config.security.app_encryption_key))[\n                JWE_PAYLOAD_SCOPES\n            ]\n            == []\n        )\n\n        new_client.delete(db)\n\n\nclass TestCallback:\n    @pytest.fixture\n    def callback_url(self) -> str:\n        return V1_URL_PREFIX + OAUTH_CALLBACK\n\n    def test_callback_for_missing_state(self, db, api_client: TestClient, callback_url):\n        response = api_client.get(\n            callback_url, params={\"code\": \"abc\", \"state\": \"not_found\"}\n        )\n        assert response.status_code == 404\n        assert response.json() == {\n            \"detail\": \"No authentication request found for the given state.\"\n        }\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.saas_config_endpoints.OAuth2AuthorizationCodeAuthenticationStrategy.get_access_token\"\n    )\n    def test_callback_for_valid_state(\n        self,\n        get_access_token_mock: Mock,\n        db,\n        api_client: TestClient,\n        callback_url,\n        oauth2_authorization_code_connection_config,\n    ):\n        get_access_token_mock.return_value = None\n        authentication_request = AuthenticationRequest.create_or_update(\n            db,\n            data={\n                \"connection_key\": oauth2_authorization_code_connection_config.key,\n                \"state\": \"new_request\",\n            },\n        )\n        response = api_client.get(\n            callback_url, params={\"code\": \"abc\", \"state\": \"new_request\"}\n        )\n        assert response.ok\n        get_access_token_mock.assert_called_once()\n\n        authentication_request.delete(db)\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.saas_config_endpoints.OAuth2AuthorizationCodeAuthenticationStrategy.get_access_token\"\n    )\n    def test_callback_for_valid_state_with_token_error(\n        self,\n        get_access_token_mock: Mock,\n        db,\n        api_client: TestClient,\n        callback_url,\n        oauth2_authorization_code_connection_config,\n    ):\n        get_access_token_mock.side_effect = OAuth2TokenException(\n            \"Unable to retrieve access token.\"\n        )\n        authentication_request = AuthenticationRequest.create_or_update(\n            db,\n            data={\n                \"connection_key\": oauth2_authorization_code_connection_config.key,\n                \"state\": \"new_request\",\n            },\n        )\n        response = api_client.get(\n            callback_url, params={\"code\": \"abc\", \"state\": \"new_request\"}\n        )\n        assert response.status_code == 400\n        assert response.json() == {\"detail\": \"Unable to retrieve access token.\"}\n\n        authentication_request.delete(db)\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_policy_endpoints.py", "content": "import json\nfrom uuid import uuid4\n\nimport pytest\nfrom fideslib.models.client import ClientDetail\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1 import scope_registry as scopes\nfrom fidesops.ops.api.v1.urn_registry import POLICY_DETAIL as POLICY_DETAIL_URI\nfrom fidesops.ops.api.v1.urn_registry import POLICY_LIST as POLICY_CREATE_URI\nfrom fidesops.ops.api.v1.urn_registry import RULE_DETAIL as RULE_DETAIL_URI\nfrom fidesops.ops.api.v1.urn_registry import RULE_LIST as RULE_CREATE_URI\nfrom fidesops.ops.api.v1.urn_registry import (\n    RULE_TARGET_DETAIL,\n    RULE_TARGET_LIST,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.policy import ActionType, DrpAction, Policy, Rule, RuleTarget\nfrom fidesops.ops.service.masking.strategy.masking_strategy_nullify import (\n    NullMaskingStrategy,\n)\nfrom fidesops.ops.util.data_category import DataCategory, generate_fides_data_categories\n\n\nclass TestGetPolicies:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client) -> str:\n        return V1_URL_PREFIX + POLICY_CREATE_URI\n\n    def test_get_policies_unauthenticated(self, url, api_client):\n        resp = api_client.get(url)\n        assert resp.status_code == 401\n\n    def test_get_policies_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.STORAGE_READ])\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_get_policies_with_rules(\n        self, api_client: TestClient, generate_auth_header, policy, url\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 200\n        data = resp.json()\n\n        assert \"items\" in data\n        assert data[\"total\"] == 1\n\n        policy_data = data[\"items\"][0]\n        assert policy_data[\"key\"] == policy.key\n        assert \"rules\" in policy_data\n        assert len(policy_data[\"rules\"]) == 1\n\n        rule = policy_data[\"rules\"][0]\n        assert rule[\"key\"] == \"access_request_rule\"\n        assert rule[\"action_type\"] == \"access\"\n        assert rule[\"storage_destination\"][\"type\"] == \"s3\"\n\n    def test_pagination_ordering(\n        self,\n        db,\n        oauth_client,\n        api_client: TestClient,\n        generate_auth_header,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        policies = []\n        POLICY_COUNT = 50\n        for _ in range(POLICY_COUNT):\n            key = str(uuid4()).replace(\"-\", \"\")\n            policies.append(\n                Policy.create(\n                    db=db,\n                    data={\n                        \"name\": key,\n                        \"key\": key,\n                        \"client_id\": oauth_client.id,\n                    },\n                )\n            )\n\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 200\n        data = resp.json()\n\n        assert \"items\" in data\n        assert data[\"total\"] == POLICY_COUNT\n\n        for policy in data[\"items\"]:\n            # The most recent policy will be that which was last added to `policies`\n            most_recent = policies.pop()\n            assert policy[\"key\"] == most_recent.key\n            # Once we're finished we need to delete the policies, since `oauth_client` will be\n            # subsequently deleted and will cause validation errors\n            most_recent.delete(db=db)\n\n\nclass TestGetPolicyDetail:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + POLICY_DETAIL_URI.format(policy_key=policy.key)\n\n    def test_get_policy_unauthenticated(self, url, api_client):\n        resp = api_client.get(url)\n        assert resp.status_code == 401\n\n    def test_get_policy_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.STORAGE_READ])\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_get_invalid_policy(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        url = V1_URL_PREFIX + POLICY_DETAIL_URI.format(policy_key=\"bad\")\n\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 404\n\n    def test_get_policy_returns_drp_action(\n        self, api_client: TestClient, generate_auth_header, policy_drp_action, url\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        resp = api_client.get(\n            V1_URL_PREFIX + POLICY_DETAIL_URI.format(policy_key=policy_drp_action.key),\n            headers=auth_header,\n        )\n        assert resp.status_code == 200\n        data = resp.json()\n        print(json.dumps(resp.json(), indent=2))\n        assert data[\"key\"] == policy_drp_action.key\n        assert data[\"drp_action\"] == DrpAction.access.value\n        assert \"rules\" in data\n        assert len(data[\"rules\"]) == 1\n\n        rule = data[\"rules\"][0]\n        assert rule[\"key\"] == \"access_request_rule_drp\"\n        assert rule[\"action_type\"] == \"access\"\n        assert rule[\"storage_destination\"][\"type\"] == \"s3\"\n\n    def test_get_policy_returns_rules(\n        self, api_client: TestClient, generate_auth_header, policy, url\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 200\n        data = resp.json()\n        print(json.dumps(resp.json(), indent=2))\n        assert data[\"key\"] == policy.key\n        assert \"rules\" in data\n        assert len(data[\"rules\"]) == 1\n\n        rule = data[\"rules\"][0]\n        assert rule[\"key\"] == \"access_request_rule\"\n        assert rule[\"action_type\"] == \"access\"\n        assert rule[\"storage_destination\"][\"type\"] == \"s3\"\n\n    def test_get_policies_returns_rules(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        policy,\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        resp = api_client.get(\n            V1_URL_PREFIX + POLICY_CREATE_URI,\n            headers=auth_header,\n        )\n        assert resp.status_code == 200\n        print(json.dumps(resp.json(), indent=2))\n        print(f\"POLICY = {policy.__dict__}\")\n        print(f\"RULES = {policy.rules}\")\n        print(f\"RULES = {policy.rules[0]}\")\n        print(f\"RULES = {policy.rules[0].__dict__}\")\n        data = resp.json()\n\n        assert \"items\" in data\n        assert data[\"total\"] == 1\n\n        policy_data = data[\"items\"][0]\n        assert policy_data[\"key\"] == policy.key\n        assert \"rules\" in policy_data\n        assert len(policy_data[\"rules\"]) == 1\n\n        rule = policy_data[\"rules\"][0]\n        assert rule[\"key\"] == \"access_request_rule\"\n        assert rule[\"action_type\"] == \"access\"\n        assert rule[\"storage_destination\"][\"type\"] == \"s3\"\n\n\nclass TestCreatePolicies:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + POLICY_CREATE_URI\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self, storage_config):\n        return [\n            {\n                \"name\": \"policy 1\",\n                \"action_type\": \"erasure\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"storage_destination_key\": storage_config.key,\n            },\n            {\n                \"name\": \"policy 2\",\n                \"action_type\": \"access\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"execution_timeframe\": 5,\n                \"storage_destination_key\": storage_config.key,\n            },\n        ]\n\n    def test_create_policies_unauthenticated(\n        self, url, api_client: TestClient, payload\n    ):\n        resp = api_client.patch(url, json=payload)\n        assert resp.status_code == 401\n\n    def test_create_policies_wrong_scope(\n        self, url, api_client: TestClient, payload, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        resp = api_client.patch(url, headers=auth_header, json=payload)\n        assert resp.status_code == 403\n\n    def test_create_polices_limit_exceeded(\n        self, api_client: TestClient, generate_auth_header, url, storage_config\n    ):\n        payload = []\n        for i in range(0, 51):\n            payload.append(\n                {\n                    \"name\": f\"policy {i}\",\n                    \"action_type\": \"erasure\",\n                    \"data_category\": DataCategory(\"user\").value,\n                    \"storage_destination_key\": storage_config.key,\n                }\n            )\n\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at most 50 items\"\n        )\n\n    def test_create_multiple_policies(\n        self,\n        api_client: TestClient,\n        db,\n        generate_auth_header,\n        storage_config,\n        url,\n        payload,\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=payload, headers=auth_header)\n        assert resp.status_code == 200\n\n        data = resp.json()\n        assert len(data[\"succeeded\"]) == 2\n\n        assert data[\"succeeded\"][0][\"execution_timeframe\"] is None\n        assert data[\"succeeded\"][1][\"execution_timeframe\"] == 5\n\n        elements = data[\"succeeded\"]\n        for el in elements:\n            pol = Policy.filter(db=db, conditions=(Policy.key == el[\"key\"])).first()\n            pol.delete(db=db)\n\n    def test_create_policy_with_duplicate_key(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n        policy,\n        storage_config,\n    ):\n        data = [\n            {\n                \"name\": policy.name,\n                \"action_type\": \"erasure\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"storage_destination_key\": storage_config.key,\n            },\n            {\n                \"name\": policy.name,\n                \"action_type\": \"erasure\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"storage_destination_key\": storage_config.key,\n            },\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=data, headers=auth_header)\n        assert resp.status_code == 200\n\n        data = resp.json()\n        assert len(data[\"failed\"]) == 2\n\n    def test_create_policy_with_duplicate_drp_action(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n        policy_drp_action,\n        storage_config,\n    ):\n        data = [\n            {\n                \"name\": \"policy with pre-existing drp action\",\n                \"action_type\": ActionType.access.value,\n                \"drp_action\": DrpAction.access.value,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=data, headers=auth_header)\n        assert resp.status_code == 200\n\n        data = resp.json()\n        assert len(data[\"failed\"]) == 1\n\n    def test_update_policy_with_duplicate_drp_action(\n        self,\n        db,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n        policy_drp_action,\n        storage_config,\n    ):\n        # creates a new drp policy\n        data = [\n            {\n                \"key\": \"erasure_drp_policy\",\n                \"name\": \"erasure drp policy\",\n                \"action_type\": ActionType.erasure.value,\n                \"drp_action\": DrpAction.deletion.value,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        valid_drp_resp = api_client.patch(url, json=data, headers=auth_header)\n        valid_response_data = valid_drp_resp.json()[\"succeeded\"]\n        assert valid_drp_resp.status_code == 200\n\n        # try to update the above policy with a pre-existing drp action\n        data = [\n            {\n                \"key\": \"erasure_drp_policy\",\n                \"name\": \"policy with pre-existing drp action\",\n                \"action_type\": ActionType.access.value,\n                \"drp_action\": DrpAction.access.value,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=data, headers=auth_header)\n        assert resp.status_code == 200\n\n        data = resp.json()\n        assert len(data[\"failed\"]) == 1\n\n        pol = Policy.filter(\n            db=db, conditions=(Policy.key == valid_response_data[0][\"key\"])\n        ).first()\n        pol.delete(db=db)\n\n    def test_update_policy_with_drp_action(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n        policy,\n        storage_config,\n    ):\n        data = [\n            {\n                \"key\": policy.key,\n                \"name\": \"updated name\",\n                \"action_type\": ActionType.access.value,\n                \"drp_action\": DrpAction.access.value,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=data, headers=auth_header)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n\n    def test_create_policy_invalid_drp_action(\n        self, url, api_client: TestClient, payload, generate_auth_header, storage_config\n    ):\n        payload = [\n            {\n                \"name\": \"policy 1\",\n                \"action_type\": \"erasure\",\n                \"drp_action\": \"invalid\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"storage_destination_key\": storage_config.key,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=payload, headers=auth_header)\n        assert resp.status_code == 422\n\n        response_body = json.loads(resp.text)\n        assert (\n            \"value is not a valid enumeration member; permitted: 'access', 'deletion', 'sale:opt_out', 'sale:opt_in', 'access:categories', 'access:specific'\"\n            == response_body[\"detail\"][0][\"msg\"]\n        )\n\n    def test_create_policy_with_drp_action(\n        self,\n        db,\n        url,\n        api_client: TestClient,\n        payload,\n        generate_auth_header,\n        storage_config,\n    ):\n        payload = [\n            {\n                \"name\": \"policy 1\",\n                \"action_type\": \"erasure\",\n                \"drp_action\": \"deletion\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"storage_destination_key\": storage_config.key,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=payload, headers=auth_header)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n\n        pol = Policy.filter(\n            db=db, conditions=(Policy.key == response_data[0][\"key\"])\n        ).first()\n        pol.delete(db=db)\n\n    def test_create_policy_creates_key(\n        self, db, api_client: TestClient, generate_auth_header, storage_config, url\n    ):\n        data = [\n            {\n                \"name\": \"test create policy api\",\n                \"action_type\": \"erasure\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"storage_destination_key\": storage_config.key,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=data, headers=auth_header)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n\n        pol = Policy.filter(\n            db=db, conditions=(Policy.key == response_data[0][\"key\"])\n        ).first()\n        pol.delete(db=db)\n\n    def test_create_policy_with_key(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        generate_auth_header,\n        storage_config,\n    ):\n        key = \"here_is_a_key\"\n        data = [\n            {\n                \"name\": \"test create policy api\",\n                \"action_type\": \"erasure\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"storage_destination_key\": storage_config.key,\n                \"key\": key,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=data, headers=auth_header)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n\n        policy_data = response_data[0]\n        assert policy_data[\"key\"] == key\n\n        pol = Policy.filter(\n            db=db, conditions=(Policy.key == policy_data[\"key\"])\n        ).first()\n        pol.delete(db=db)\n\n    def test_create_policy_with_invalid_key(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        generate_auth_header,\n        storage_config,\n    ):\n        key = \"here*is*an*invalid*key\"\n        data = [\n            {\n                \"name\": \"test create policy api\",\n                \"action_type\": \"erasure\",\n                \"data_category\": DataCategory(\"user\").value,\n                \"storage_destination_key\": storage_config.key,\n                \"key\": key,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=data, headers=auth_header)\n        assert resp.status_code == 422\n        assert (\n            json.loads(resp.text)[\"detail\"][0][\"msg\"]\n            == \"FidesKey must only contain alphanumeric characters, '.', '_' or '-'.\"\n        )\n\n    def test_create_policy_already_exists(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n        policy,\n    ):\n        data = [\n            {\n                \"name\": \"test create policy api\",\n                \"key\": policy.key,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, json=data, headers=auth_header)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n\n\nclass TestCreateRules:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + RULE_CREATE_URI.format(policy_key=policy.key)\n\n    def test_create_rules_unauthenticated(self, url, api_client):\n        resp = api_client.patch(url, json={})\n        assert resp.status_code == 401\n\n    def test_create_rules_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        resp = api_client.patch(url, headers=auth_header, json={})\n        assert resp.status_code == 403\n\n    def test_create_rules_invalid_policy(\n        self, url, api_client: TestClient, generate_auth_header, policy, storage_config\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        url = V1_URL_PREFIX + RULE_CREATE_URI.format(policy_key=\"bad_key\")\n\n        data = [\n            {\n                \"name\": \"test access rule\",\n                \"action_type\": ActionType.access.value,\n                \"storage_destination_key\": storage_config.key,\n            }\n        ]\n\n        resp = api_client.patch(url, headers=auth_header, json=data)\n        assert resp.status_code == 404\n\n    def test_create_rules_mismatching_drp_policy(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        policy_drp_action,\n        storage_config,\n    ):\n        data = [\n            {\n                \"name\": \"test access rule\",\n                \"action_type\": ActionType.erasure.value,\n                \"storage_destination_key\": storage_config.key,\n            }\n        ]\n        url = V1_URL_PREFIX + RULE_CREATE_URI.format(policy_key=policy_drp_action.key)\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            url,\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        response_data = resp.json()[\"failed\"]\n        assert len(response_data) == 1\n\n    def test_create_rules_limit_exceeded(\n        self, api_client: TestClient, generate_auth_header, url, storage_config\n    ):\n        payload = []\n        for i in range(0, 51):\n            payload.append(\n                {\n                    \"name\": f\"test access rule {i}\",\n                    \"action_type\": ActionType.access.value,\n                    \"storage_destination_key\": storage_config.key,\n                }\n            )\n\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at most 50 items\"\n        )\n\n    def test_create_access_rule_for_policy(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n        policy,\n        storage_config,\n    ):\n        data = [\n            {\n                \"name\": \"test access rule\",\n                \"action_type\": ActionType.access.value,\n                \"storage_destination_key\": storage_config.key,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            url,\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        rule_data = response_data[0]\n        assert \"storage_destination\" in rule_data\n        assert \"key\" in rule_data[\"storage_destination\"]\n        assert \"secrets\" not in rule_data[\"storage_destination\"]\n\n    def test_create_access_rule_for_policy_no_storage_fails(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n        policy,\n    ):\n        data = [\n            {\n                \"name\": \"test access rule\",\n                \"action_type\": ActionType.access.value,\n            }\n        ]\n\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            url,\n            json=data,\n            headers=auth_header,\n        )\n        assert resp.status_code == 200\n        response_data = resp.json()[\"failed\"]\n        assert len(response_data) == 1\n\n    def test_create_erasure_rule_for_policy(\n        self,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n        policy,\n    ):\n\n        data = [\n            {\n                \"name\": \"test erasure rule\",\n                \"action_type\": ActionType.erasure.value,\n                \"masking_strategy\": {\n                    \"strategy\": NullMaskingStrategy.name,\n                    \"configuration\": {},\n                },\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            url,\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        rule_data = response_data[0]\n        assert \"masking_strategy\" in rule_data\n        masking_strategy_data = rule_data[\"masking_strategy\"]\n        assert masking_strategy_data[\"strategy\"] == NullMaskingStrategy.name\n        assert \"configuration\" not in masking_strategy_data\n\n    def test_update_rule_policy_id_fails(\n        self,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        storage_config,\n        db,\n        generate_auth_header,\n        policy,\n    ):\n        rule = policy.rules[0]\n\n        another_policy = Policy.create(\n            db=db,\n            data={\n                \"name\": \"Second Access Request policy\",\n                \"key\": \"second_access_request_policy\",\n                \"client_id\": oauth_client.id,\n            },\n        )\n\n        url = V1_URL_PREFIX + RULE_CREATE_URI.format(policy_key=another_policy.key)\n\n        data = [\n            {\n                \"name\": rule.name,\n                \"key\": rule.key,\n                \"action_type\": ActionType.access.value,\n                \"storage_destination_key\": storage_config.key,\n            }\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            url,\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        response_data = resp.json()[\"failed\"]\n        assert len(response_data) == 1\n        assert (\n            response_data[0][\"message\"]\n            == f\"Rule with identifier {rule.key} belongs to another policy.\"\n        )\n\n        updated_rule = Rule.get(db=db, object_id=rule.id)\n        db.expire(updated_rule)\n        assert updated_rule.policy_id == policy.id\n\n        another_policy.delete(db=db)\n\n\nclass TestDeleteRule:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        rule = policy.rules[0]\n\n        return V1_URL_PREFIX + RULE_DETAIL_URI.format(\n            policy_key=policy.key,\n            rule_key=rule.key,\n        )\n\n    def test_delete_rule_unauthenticated(self, url, api_client):\n        resp = api_client.delete(url)\n        assert resp.status_code == 401\n\n    def test_delete_rule_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.POLICY_READ])\n        resp = api_client.delete(url, headers=auth_header)\n        assert resp.status_code == 403\n\n    def test_delete_rule_invalid_policy(\n        self, api_client: TestClient, generate_auth_header, policy\n    ):\n        rule = policy.rules[0]\n\n        url = V1_URL_PREFIX + RULE_DETAIL_URI.format(\n            policy_key=\"bad_policy\",\n            rule_key=rule.key,\n        )\n\n        auth_header = generate_auth_header(scopes=[scopes.RULE_DELETE])\n        resp = api_client.delete(url, headers=auth_header)\n        assert resp.status_code == 404\n\n    def test_delete_rule_invalid_rule(\n        self, api_client: TestClient, generate_auth_header, policy\n    ):\n        url = V1_URL_PREFIX + RULE_DETAIL_URI.format(\n            policy_key=policy.key,\n            rule_key=\"bad_rule\",\n        )\n\n        auth_header = generate_auth_header(scopes=[scopes.RULE_DELETE])\n        resp = api_client.delete(url, headers=auth_header)\n        assert resp.status_code == 404\n\n    def test_delete_rule_for_policy(\n        self, api_client: TestClient, generate_auth_header, policy, url\n    ):\n        auth_header = generate_auth_header(scopes=[scopes.RULE_DELETE])\n        resp = api_client.delete(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 204\n\n\nclass TestRuleTargets:\n    def get_rule_url(self, policy_key, rule_key):\n        return V1_URL_PREFIX + RULE_TARGET_LIST.format(\n            policy_key=policy_key,\n            rule_key=rule_key,\n        )\n\n    def get_rule_target_url(self, policy_key, rule_key, rule_target_key):\n        return V1_URL_PREFIX + RULE_TARGET_DETAIL.format(\n            policy_key=policy_key,\n            rule_key=rule_key,\n            rule_target_key=rule_target_key,\n        )\n\n    def test_create_rule_targets(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        policy,\n    ):\n        rule = policy.rules[0]\n        data = [\n            {\n                \"data_category\": DataCategory(\"user.name\").value,\n            },\n            {\n                \"data_category\": DataCategory(\"user.contact.email\").value,\n            },\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            self.get_rule_url(policy.key, rule.key),\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 2\n\n    def test_create_duplicate_rule_targets(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        policy,\n    ):\n        rule = policy.rules[0]\n        data_category = DataCategory(\"user.name\").value\n        data = [\n            {\n                \"data_category\": data_category,\n                \"name\": \"this-is-a-test\",\n                \"key\": \"this_is_a_test\",\n            },\n            {\n                \"data_category\": data_category,\n                \"name\": \"this-is-another-test\",\n                \"key\": \"this_is_another_test\",\n            },\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            self.get_rule_url(policy.key, rule.key),\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        assert len(resp.json()[\"succeeded\"]) == 1\n        assert len(resp.json()[\"failed\"]) == 1\n        assert (\n            resp.json()[\"failed\"][0][\"message\"]\n            == f\"DataCategory {data_category} is already specified on Rule with ID {rule.id}\"\n        )\n\n    def test_create_targets_limit_exceeded(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        storage_config,\n        policy,\n    ):\n        categories = [e.value for e in generate_fides_data_categories()]\n\n        rule = policy.rules[0]\n        existing_target = rule.targets[0]\n\n        payload = []\n        for i in range(0, 51):\n            payload.append(\n                {\n                    \"data_category\": categories[i],\n                    \"key\": existing_target.key,\n                },\n            )\n\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            self.get_rule_url(policy.key, rule.key), headers=auth_header, json=payload\n        )\n\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at most 50 items\"\n        )\n\n    def test_update_rule_targets(\n        self,\n        api_client: TestClient,\n        db,\n        generate_auth_header,\n        policy,\n    ):\n        rule = policy.rules[0]\n        existing_target = rule.targets[0]\n        updated_data_category = DataCategory(\"user.name\").value\n        data = [\n            {\n                \"data_category\": updated_data_category,\n                \"key\": existing_target.key,\n            },\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            self.get_rule_url(policy.key, rule.key),\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n\n        updated_target = RuleTarget.get(db=db, object_id=existing_target.id)\n        db.expire(updated_target)\n\n        assert updated_target.data_category == updated_data_category\n        assert updated_target.rule_id == existing_target.rule_id\n        assert updated_target.key == existing_target.key\n        assert updated_target.name == existing_target.name\n\n    def test_update_rule_target_rule_id_fails(\n        self,\n        api_client: TestClient,\n        oauth_client: ClientDetail,\n        storage_config,\n        db,\n        generate_auth_header,\n        policy,\n    ):\n        rule = policy.rules[0]\n        another_rule = Rule.create(\n            db=db,\n            data={\n                \"action_type\": ActionType.access.value,\n                \"client_id\": oauth_client.id,\n                \"name\": \"Example Access Rule\",\n                \"policy_id\": policy.id,\n                \"storage_destination_id\": storage_config.id,\n            },\n        )\n        existing_target = rule.targets[0]\n        updated_data_category = DataCategory(\"user.name\").value\n        data = [\n            {\n                \"data_category\": updated_data_category,\n                \"key\": existing_target.key,\n            },\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            # Here we send the request to the URL corresponding to a different rule entirely\n            self.get_rule_url(policy.key, another_rule.key),\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        response_data = resp.json()[\"failed\"]\n        assert len(response_data) == 1\n        assert (\n            response_data[0][\"message\"]\n            == f\"RuleTarget with identifier {existing_target.key} belongs to another rule.\"\n        )\n\n        updated_target = RuleTarget.get(db=db, object_id=existing_target.id)\n        db.expire(updated_target)\n        assert updated_target.rule_id == existing_target.rule_id\n\n        another_rule.delete(db=db)\n\n    def test_delete_rule_target(\n        self,\n        api_client: TestClient,\n        db,\n        generate_auth_header,\n        policy,\n    ):\n        rule = policy.rules[0]\n        rule_target = rule.targets[0]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_DELETE])\n        url = self.get_rule_target_url(\n            policy_key=policy.key,\n            rule_key=rule.key,\n            rule_target_key=rule_target.key,\n        )\n        resp = api_client.delete(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 204\n\n    def test_create_conflicting_rule_targets(\n        self,\n        api_client: TestClient,\n        db,\n        generate_auth_header,\n        policy,\n    ):\n        erasure_rule = Rule.create(\n            db=db,\n            data={\n                \"action_type\": ActionType.erasure.value,\n                \"client_id\": policy.client.id,\n                \"name\": \"Erasure Rule\",\n                \"policy_id\": policy.id,\n                \"masking_strategy\": {\n                    \"strategy\": NullMaskingStrategy.name,\n                    \"configuration\": {},\n                },\n            },\n        )\n\n        target_1 = \"user.contact.email\"\n        target_2 = \"user.contact\"\n        data = [\n            {\n                \"data_category\": DataCategory(target_1).value,\n            },\n            {\n                \"data_category\": DataCategory(target_2).value,\n            },\n        ]\n        auth_header = generate_auth_header(scopes=[scopes.RULE_CREATE_OR_UPDATE])\n        resp = api_client.patch(\n            self.get_rule_url(policy.key, erasure_rule.key),\n            json=data,\n            headers=auth_header,\n        )\n\n        assert resp.status_code == 200\n        succeeded = resp.json()[\"succeeded\"]\n        assert len(succeeded) == 1\n\n        failed = resp.json()[\"failed\"]\n        assert len(failed) == 1\n        assert (\n            failed[0][\"message\"]\n            == f\"Policy rules are invalid, action conflict in erasure rules detected for categories {target_1} and {target_2}\"\n        )\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_privacy_request_endpoints.py", "content": "import ast\nimport csv\nimport io\nimport json\nfrom datetime import datetime, timedelta\nfrom random import randint\nfrom typing import List\nfrom unittest import mock\n\nimport pytest\nfrom dateutil.parser import parse\nfrom fastapi import HTTPException, status\nfrom fastapi_pagination import Params\nfrom fideslib.cryptography.schemas.jwt import (\n    JWE_ISSUED_AT,\n    JWE_PAYLOAD_CLIENT_ID,\n    JWE_PAYLOAD_SCOPES,\n)\nfrom fideslib.models.audit_log import AuditLog, AuditLogAction\nfrom fideslib.models.client import ClientDetail\nfrom fideslib.oauth.jwt import generate_jwe\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.endpoints.privacy_request_endpoints import (\n    EMBEDDED_EXECUTION_LOG_LIMIT,\n    validate_manual_input,\n)\nfrom fidesops.ops.api.v1.scope_registry import (\n    DATASET_CREATE_OR_UPDATE,\n    PRIVACY_REQUEST_CALLBACK_RESUME,\n    PRIVACY_REQUEST_READ,\n    PRIVACY_REQUEST_REVIEW,\n    PRIVACY_REQUEST_UPLOAD_DATA,\n    PRIVACY_REQUEST_VIEW_DATA,\n    STORAGE_CREATE_OR_UPDATE,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    DATASETS,\n    PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT,\n    PRIVACY_REQUEST_APPROVE,\n    PRIVACY_REQUEST_DENY,\n    PRIVACY_REQUEST_MANUAL_ERASURE,\n    PRIVACY_REQUEST_MANUAL_INPUT,\n    PRIVACY_REQUEST_RESUME,\n    PRIVACY_REQUEST_RESUME_FROM_REQUIRES_INPUT,\n    PRIVACY_REQUEST_RETRY,\n    PRIVACY_REQUEST_VERIFY_IDENTITY,\n    PRIVACY_REQUESTS,\n    REQUEST_PREVIEW,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.graph.config import CollectionAddress\nfrom fidesops.ops.graph.graph import DatasetGraph\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.models.policy import ActionType, CurrentStep, Policy\nfrom fidesops.ops.models.privacy_request import (\n    ExecutionLog,\n    ExecutionLogStatus,\n    ManualAction,\n    PrivacyRequest,\n    PrivacyRequestStatus,\n)\nfrom fidesops.ops.schemas.dataset import DryRunDatasetResponse\nfrom fidesops.ops.schemas.email.email import (\n    EmailActionType,\n    RequestReceiptBodyParams,\n    RequestReviewDenyBodyParams,\n    SubjectIdentityVerificationBodyParams,\n)\nfrom fidesops.ops.schemas.masking.masking_secrets import SecretType\nfrom fidesops.ops.schemas.policy import PolicyResponse\nfrom fidesops.ops.schemas.redis_cache import Identity\nfrom fidesops.ops.tasks import EMAIL_QUEUE_NAME\nfrom fidesops.ops.util.cache import (\n    get_encryption_cache_key,\n    get_identity_cache_key,\n    get_masking_secret_cache_key,\n)\n\npage_size = Params().size\n\n\ndef stringify_date(log_date: datetime) -> str:\n    return log_date.strftime(\"%Y-%m-%dT%H:%M:%S.%f+00:00\")\n\n\nclass TestCreatePrivacyRequest:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + PRIVACY_REQUESTS\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_create_privacy_request(\n        self,\n        mock_dispatch_email,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        pr.delete(db=db)\n        assert run_access_request_mock.called\n        assert not mock_dispatch_email.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_stores_identities(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n    ):\n        TEST_EMAIL = \"test@example.com\"\n        TEST_PHONE_NUMBER = \"+1 234 567 8910\"\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\n                    \"email\": TEST_EMAIL,\n                    \"phone_number\": TEST_PHONE_NUMBER,\n                },\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        persisted_identity = pr.get_persisted_identity()\n        assert persisted_identity.email == TEST_EMAIL\n        assert persisted_identity.phone_number == TEST_PHONE_NUMBER\n        pr.delete(db=db)\n        assert run_access_request_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_require_manual_approval(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n        require_manual_request_approval,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        assert response_data[0][\"status\"] == \"pending\"\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        pr.delete(db=db)\n        assert not run_access_request_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_with_masking_configuration(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        erasure_policy_string_rewrite,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": erasure_policy_string_rewrite.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        pr.delete(db=db)\n        assert run_access_request_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_access_request\"\n    )\n    def test_create_privacy_request_limit_exceeded(\n        self,\n        _,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n    ):\n        payload = []\n        for i in range(0, 51):\n            payload.append(\n                {\n                    \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                    \"policy_key\": policy.key,\n                    \"identity\": {\"email\": \"ftest{i}@example.com\"},\n                },\n            )\n\n        response = api_client.post(url, json=payload)\n\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at most 50 items\"\n        )\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_starts_processing(\n        self,\n        run_privacy_request_mock,\n        url,\n        api_client: TestClient,\n        db,\n        policy,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert run_privacy_request_mock.called\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        pr.delete(db=db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_with_external_id(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n    ):\n        external_id = \"ext_some-uuid-here-1234\"\n        data = [\n            {\n                \"external_id\": external_id,\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        assert response_data[0][\"external_id\"] == external_id\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        assert pr.external_id == external_id\n        pr.delete(db=db)\n        assert run_access_request_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_caches_identity(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n        cache,\n    ):\n        identity = {\"email\": \"test@example.com\"}\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": identity,\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        key = get_identity_cache_key(\n            privacy_request_id=pr.id,\n            identity_attribute=list(identity.keys())[0],\n        )\n        assert cache.get(key) == list(identity.values())[0]\n        pr.delete(db=db)\n        assert run_access_request_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_caches_masking_secrets(\n        self,\n        run_erasure_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        erasure_policy_aes,\n        cache,\n    ):\n        identity = {\"email\": \"test@example.com\"}\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": erasure_policy_aes.key,\n                \"identity\": identity,\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        secret_key = get_masking_secret_cache_key(\n            privacy_request_id=pr.id,\n            masking_strategy=\"aes_encrypt\",\n            secret_type=SecretType.key,\n        )\n        assert cache.get_encoded_by_key(secret_key) is not None\n        pr.delete(db=db)\n        assert run_erasure_request_mock.called\n\n    def test_create_privacy_request_invalid_encryption_values(\n        self, url, db, api_client: TestClient, policy, cache\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n                \"encryption_key\": \"test\",\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 422\n        assert resp.json()[\"detail\"][0][\"msg\"] == \"Encryption key must be 16 bytes long\"\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_caches_encryption_keys(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n        cache,\n    ):\n        identity = {\"email\": \"test@example.com\"}\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": identity,\n                \"encryption_key\": \"test--encryption\",\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        encryption_key = get_encryption_cache_key(\n            privacy_request_id=pr.id,\n            encryption_attr=\"key\",\n        )\n        assert cache.get(encryption_key) == \"test--encryption\"\n\n        pr.delete(db=db)\n        assert run_access_request_mock.called\n\n    def test_create_privacy_request_no_identities(\n        self,\n        url,\n        api_client: TestClient,\n        policy,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 0\n        response_data = resp.json()[\"failed\"]\n        assert len(response_data) == 1\n\n    def test_create_privacy_request_registers_async_task(\n        self,\n        db,\n        url,\n        api_client,\n        policy,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        assert pr.get_cached_task_id() is not None\n        assert pr.get_async_execution_task() is not None\n        pr.delete(db=db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_create_privacy_request_creates_system_audit_log(\n        self,\n        run_access_request_mock,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        response_data = resp.json()[\"succeeded\"][0]\n        approval_audit_log: AuditLog = AuditLog.filter(\n            db=db,\n            conditions=(\n                (AuditLog.privacy_request_id == response_data[\"id\"])\n                & (AuditLog.action == AuditLogAction.approved)\n            ),\n        ).first()\n        assert approval_audit_log is not None\n        assert approval_audit_log.user_id == \"system\"\n\n        approval_audit_log.delete(db=db)\n        pr = PrivacyRequest.get(db=db, object_id=response_data[\"id\"])\n        pr.delete(db=db)\n\n\nclass TestGetPrivacyRequests:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + PRIVACY_REQUESTS\n\n    def test_get_privacy_requests_unauthenticated(self, api_client: TestClient, url):\n        response = api_client.get(url, headers={})\n        assert 401 == response.status_code\n\n    def test_get_privacy_requests_wrong_scope(\n        self, api_client: TestClient, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header(scopes=[STORAGE_CREATE_OR_UPDATE])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_conflicting_query_params(\n        self, api_client: TestClient, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url\n            + f\"?completed_lt=2021-01-01T00:00:00.000Z&errored_gt=2021-01-02T00:00:00.000Z\",\n            headers=auth_header,\n        )\n        assert 400 == response.status_code\n\n    def test_get_privacy_requests_displays_reviewer(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        privacy_request,\n        user,\n        postgres_execution_log,\n        mongo_execution_log,\n    ):\n        privacy_request.reviewer = user\n        privacy_request.save(db=db)\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?request_id={privacy_request.id}\", headers=auth_header\n        )\n        assert 200 == response.status_code\n\n        reviewer = response.json()[\"items\"][0][\"reviewer\"]\n        assert reviewer\n        assert user.id == reviewer[\"id\"]\n        assert user.username == reviewer[\"username\"]\n        privacy_request.delete(db)\n\n    def test_get_privacy_requests_accept_datetime(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        privacy_request,\n        postgres_execution_log,\n        mongo_execution_log,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        for date_format in [\n            \"%Y-%m-%dT00:00:00.000Z\",\n            # \"%Y-%m-%d\",\n        ]:\n            date_input = privacy_request.created_at.strftime(date_format)\n            response = api_client.get(\n                url + f\"?created_gt={date_input}\",\n                headers=auth_header,\n            )\n\n            assert 200 == response.status_code\n\n    def test_get_privacy_requests_by_id(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n        privacy_request,\n        postgres_execution_log,\n        mongo_execution_log,\n        db,\n    ):\n        privacy_request.due_date = None\n        privacy_request.save(db=db)\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?request_id={privacy_request.id}\", headers=auth_header\n        )\n        assert 200 == response.status_code\n\n        expected_resp = {\n            \"items\": [\n                {\n                    \"id\": privacy_request.id,\n                    \"created_at\": stringify_date(privacy_request.created_at),\n                    \"days_left\": None,\n                    \"started_processing_at\": stringify_date(\n                        privacy_request.started_processing_at\n                    ),\n                    \"finished_processing_at\": None,\n                    \"identity_verified_at\": None,\n                    \"status\": privacy_request.status.value,\n                    \"external_id\": privacy_request.external_id,\n                    \"identity\": None,\n                    \"reviewed_at\": None,\n                    \"reviewed_by\": None,\n                    \"paused_at\": None,\n                    \"reviewer\": None,\n                    \"policy\": {\n                        \"drp_action\": None,\n                        \"execution_timeframe\": 7,\n                        \"name\": privacy_request.policy.name,\n                        \"key\": privacy_request.policy.key,\n                        \"rules\": [\n                            rule.dict()\n                            for rule in PolicyResponse.from_orm(\n                                privacy_request.policy\n                            ).rules\n                        ],\n                    },\n                    \"action_required_details\": None,\n                    \"resume_endpoint\": None,\n                }\n            ],\n            \"total\": 1,\n            \"page\": 1,\n            \"size\": page_size,\n        }\n\n        resp = response.json()\n        assert resp == expected_resp\n\n    def test_get_privacy_requests_by_partial_id(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n        privacy_request,\n        postgres_execution_log,\n        mongo_execution_log,\n        db,\n    ):\n        privacy_request.due_date = None\n        privacy_request.save(db=db)\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?request_id={privacy_request.id[:5]}\", headers=auth_header\n        )\n        assert 200 == response.status_code\n\n        expected_resp = {\n            \"items\": [\n                {\n                    \"id\": privacy_request.id,\n                    \"created_at\": stringify_date(privacy_request.created_at),\n                    \"days_left\": None,\n                    \"started_processing_at\": stringify_date(\n                        privacy_request.started_processing_at\n                    ),\n                    \"finished_processing_at\": None,\n                    \"identity_verified_at\": None,\n                    \"status\": privacy_request.status.value,\n                    \"external_id\": privacy_request.external_id,\n                    \"identity\": None,\n                    \"reviewed_at\": None,\n                    \"reviewed_by\": None,\n                    \"paused_at\": None,\n                    \"reviewer\": None,\n                    \"policy\": {\n                        \"execution_timeframe\": 7,\n                        \"drp_action\": None,\n                        \"name\": privacy_request.policy.name,\n                        \"key\": privacy_request.policy.key,\n                        \"rules\": [\n                            rule.dict()\n                            for rule in PolicyResponse.from_orm(\n                                privacy_request.policy\n                            ).rules\n                        ],\n                    },\n                    \"action_required_details\": None,\n                    \"resume_endpoint\": None,\n                }\n            ],\n            \"total\": 1,\n            \"page\": 1,\n            \"size\": page_size,\n        }\n\n        resp = response.json()\n        assert resp == expected_resp\n\n    def test_get_privacy_requests_with_identity(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?status=complete&include_identities=true\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == succeeded_privacy_request.id\n        assert (\n            resp[\"items\"][0][\"identity\"]\n            == succeeded_privacy_request.get_persisted_identity()\n        )\n\n        assert resp[\"items\"][0][\"policy\"][\"key\"] == privacy_request.policy.key\n        assert resp[\"items\"][0][\"policy\"][\"name\"] == privacy_request.policy.name\n\n        # Now test the identities are omitted if not explicitly requested\n        response = api_client.get(url + f\"?status=complete\", headers=auth_header)\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == succeeded_privacy_request.id\n        assert resp[\"items\"][0].get(\"identity\") is None\n\n        response = api_client.get(\n            url + f\"?status=complete&include_identities=false\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == succeeded_privacy_request.id\n        assert resp[\"items\"][0].get(\"identity\") is None\n\n    def test_filter_privacy_requests_by_status(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n        failed_privacy_request,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url + f\"?status=complete\", headers=auth_header)\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == succeeded_privacy_request.id\n\n        response = api_client.get(url + f\"?status=error\", headers=auth_header)\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == failed_privacy_request.id\n\n    def test_filter_privacy_request_by_multiple_statuses(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n        failed_privacy_request,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?status=complete&status=error\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 2\n        assert resp[\"items\"][0][\"id\"] == failed_privacy_request.id\n        assert resp[\"items\"][1][\"id\"] == succeeded_privacy_request.id\n\n    def test_filter_privacy_requests_by_internal_id(\n        self,\n        db,\n        api_client,\n        url,\n        generate_auth_header,\n        policy,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n                \"id\": \"test_internal_id_1\",\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        privacy_request = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?request_id={privacy_request.id}\",\n            headers=auth_header,\n        )\n        assert response.status_code == status.HTTP_200_OK\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == privacy_request.id\n\n    def test_filter_privacy_requests_by_identity_no_request_id(\n        self,\n        db,\n        api_client,\n        url,\n        generate_auth_header,\n        privacy_request,\n    ):\n        TEST_EMAIL = \"test-12345678910@example.com\"\n        privacy_request.persist_identity(\n            db=db,\n            identity=Identity(\n                email=TEST_EMAIL,\n            ),\n        )\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?identity={TEST_EMAIL}\",\n            headers=auth_header,\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == privacy_request.id\n\n    def test_filter_privacy_requests_by_external_id(\n        self,\n        db,\n        api_client,\n        url,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n        failed_privacy_request,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?external_id={succeeded_privacy_request.id}\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 0\n\n        privacy_request.external_id = \"test_external_id_1\"\n        privacy_request.save(db)\n\n        response = api_client.get(\n            url + f\"?external_id=test_external_id_1\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == privacy_request.id\n\n    def test_filter_privacy_requests_by_created(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n        failed_privacy_request,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?created_lt=2019-01-01T00:00:00.000Z\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 0\n\n        response = api_client.get(\n            url + f\"?created_gt=2019-01-01T00:00:00.000Z\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 3\n        assert resp[\"items\"][0][\"id\"] == failed_privacy_request.id\n        assert resp[\"items\"][1][\"id\"] == succeeded_privacy_request.id\n        assert resp[\"items\"][2][\"id\"] == privacy_request.id\n\n    def test_filter_privacy_requests_by_conflicting_date_fields(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n        failed_privacy_request,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        # Search for privacy requests after 2019, but before 2018. This should return an error.\n        start = \"2019-01-01\"\n        end = \"2018-01-01\"\n        response = api_client.get(\n            url + f\"?created_gt={start}T00:00:00.000Z&created_lt={end}T00:00:00.000Z\",\n            headers=auth_header,\n        )\n        assert 400 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == f\"Value specified for created_lt: {end} 00:00:00+00:00 must be after created_gt: {start} 00:00:00+00:00.\"\n        )\n\n    def test_filter_privacy_requests_by_started(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n        failed_privacy_request,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?started_lt=2021-05-01T00:00:00.000Z\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 2\n        assert resp[\"items\"][0][\"id\"] == failed_privacy_request.id\n        assert resp[\"items\"][1][\"id\"] == privacy_request.id\n\n        response = api_client.get(\n            url + f\"?started_gt=2021-05-01T00:00:00.000Z\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == succeeded_privacy_request.id\n\n    def test_filter_privacy_requests_by_completed(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n        failed_privacy_request,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?completed_lt=2021-10-01T00:00:00.000Z\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 0\n\n        response = api_client.get(\n            url + f\"?completed_gt=2021-10-01T00:00:00.000Z\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == succeeded_privacy_request.id\n\n    def test_filter_privacy_requests_by_errored(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request,\n        succeeded_privacy_request,\n        failed_privacy_request,\n        url,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url + f\"?errored_lt=2021-01-01T00:00:00.000Z\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 0\n\n        response = api_client.get(\n            url + f\"?errored_gt=2021-01-01T00:00:00.000Z\", headers=auth_header\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n        assert len(resp[\"items\"]) == 1\n        assert resp[\"items\"][0][\"id\"] == failed_privacy_request.id\n\n    def test_verbose_privacy_requests(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request: PrivacyRequest,\n        audit_log,\n        postgres_execution_log,\n        second_postgres_execution_log,\n        mongo_execution_log,\n        url,\n        db,\n    ):\n        \"\"\"Test privacy requests endpoint with verbose query param to show execution logs\"\"\"\n        privacy_request.due_date = None\n        privacy_request.save(db)\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url + f\"?verbose=True\", headers=auth_header)\n        assert 200 == response.status_code\n\n        resp = response.json()\n        assert (\n            postgres_execution_log.updated_at < second_postgres_execution_log.updated_at\n        )\n        expected_resp = {\n            \"items\": [\n                {\n                    \"id\": privacy_request.id,\n                    \"created_at\": stringify_date(privacy_request.created_at),\n                    \"days_left\": None,\n                    \"started_processing_at\": stringify_date(\n                        privacy_request.started_processing_at\n                    ),\n                    \"finished_processing_at\": None,\n                    \"identity_verified_at\": None,\n                    \"status\": privacy_request.status.value,\n                    \"external_id\": privacy_request.external_id,\n                    \"identity\": None,\n                    \"reviewed_at\": None,\n                    \"reviewed_by\": None,\n                    \"paused_at\": None,\n                    \"reviewer\": None,\n                    \"policy\": {\n                        \"execution_timeframe\": 7,\n                        \"drp_action\": None,\n                        \"name\": privacy_request.policy.name,\n                        \"key\": privacy_request.policy.key,\n                        \"rules\": [\n                            rule.dict()\n                            for rule in PolicyResponse.from_orm(\n                                privacy_request.policy\n                            ).rules\n                        ],\n                    },\n                    \"action_required_details\": None,\n                    \"resume_endpoint\": None,\n                    \"results\": {\n                        \"Request approved\": [\n                            {\n                                \"collection_name\": None,\n                                \"fields_affected\": None,\n                                \"message\": \"\",\n                                \"action_type\": None,\n                                \"status\": \"approved\",\n                                \"updated_at\": stringify_date(audit_log.updated_at),\n                                \"user_id\": \"system\",\n                            }\n                        ],\n                        \"my-mongo-db\": [\n                            {\n                                \"collection_name\": \"orders\",\n                                \"fields_affected\": [\n                                    {\n                                        \"path\": \"my-mongo-db:orders:name\",\n                                        \"field_name\": \"name\",\n                                        \"data_categories\": [\"user.contact.name\"],\n                                    }\n                                ],\n                                \"message\": None,\n                                \"action_type\": \"access\",\n                                \"status\": \"in_processing\",\n                                \"updated_at\": stringify_date(\n                                    mongo_execution_log.updated_at\n                                ),\n                                \"user_id\": None,\n                            }\n                        ],\n                        \"my-postgres-db\": [\n                            {\n                                \"collection_name\": \"user\",\n                                \"fields_affected\": [\n                                    {\n                                        \"path\": \"my-postgres-db:user:email\",\n                                        \"field_name\": \"email\",\n                                        \"data_categories\": [\"user.contact.email\"],\n                                    }\n                                ],\n                                \"message\": None,\n                                \"action_type\": \"access\",\n                                \"status\": \"pending\",\n                                \"updated_at\": stringify_date(\n                                    postgres_execution_log.updated_at\n                                ),\n                                \"user_id\": None,\n                            },\n                            {\n                                \"collection_name\": \"address\",\n                                \"fields_affected\": [\n                                    {\n                                        \"path\": \"my-postgres-db:address:street\",\n                                        \"field_name\": \"street\",\n                                        \"data_categories\": [\n                                            \"user.contact.address.street\"\n                                        ],\n                                    },\n                                    {\n                                        \"path\": \"my-postgres-db:address:city\",\n                                        \"field_name\": \"city\",\n                                        \"data_categories\": [\n                                            \"user.contact.address.city\"\n                                        ],\n                                    },\n                                ],\n                                \"message\": \"Database timed out.\",\n                                \"action_type\": \"access\",\n                                \"status\": \"error\",\n                                \"updated_at\": stringify_date(\n                                    second_postgres_execution_log.updated_at\n                                ),\n                                \"user_id\": None,\n                            },\n                        ],\n                    },\n                },\n            ],\n            \"total\": 1,\n            \"page\": 1,\n            \"size\": page_size,\n        }\n        assert resp == expected_resp\n\n    def test_verbose_privacy_request_embed_limit(\n        self,\n        db,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request: PrivacyRequest,\n        url,\n    ):\n        for i in range(0, EMBEDDED_EXECUTION_LOG_LIMIT + 10):\n            ExecutionLog.create(\n                db=db,\n                data={\n                    \"dataset_name\": \"my-postgres-db\",\n                    \"collection_name\": f\"test_collection_{i}\",\n                    \"fields_affected\": [],\n                    \"action_type\": ActionType.access,\n                    \"status\": ExecutionLogStatus.pending,\n                    \"privacy_request_id\": privacy_request.id,\n                },\n            )\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url + f\"?verbose=True\", headers=auth_header)\n        assert 200 == response.status_code\n        resp = response.json()\n        assert (\n            len(resp[\"items\"][0][\"results\"][\"my-postgres-db\"])\n            == EMBEDDED_EXECUTION_LOG_LIMIT\n        )\n        db.query(ExecutionLog).filter(\n            ExecutionLog.privacy_request_id == privacy_request.id\n        ).delete()\n\n    def test_get_privacy_requests_csv_format(\n        self, db, generate_auth_header, api_client, url, privacy_request, user\n    ):\n        reviewed_at = datetime.now()\n        created_at = datetime.now()\n\n        privacy_request.created_at = created_at\n        privacy_request.status = PrivacyRequestStatus.approved\n        privacy_request.reviewed_by = user.id\n        privacy_request.reviewed_at = reviewed_at\n        TEST_EMAIL = \"test@example.com\"\n        TEST_PHONE = \"+1 234 567 8910\"\n        privacy_request.cache_identity(\n            {\n                \"email\": TEST_EMAIL,\n                \"phone_number\": TEST_PHONE,\n            }\n        )\n        privacy_request.save(db)\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url + f\"?download_csv=True\", headers=auth_header)\n        assert 200 == response.status_code\n\n        assert response.headers[\"content-type\"] == \"text/csv; charset=utf-8\"\n        assert (\n            response.headers[\"content-disposition\"]\n            == f\"attachment; filename=privacy_requests_download_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n        )\n\n        content = response.content.decode()\n        file = io.StringIO(content)\n        csv_file = csv.DictReader(file, delimiter=\",\")\n\n        first_row = next(csv_file)\n        assert parse(first_row[\"Time received\"], ignoretz=True) == created_at\n        assert ast.literal_eval(first_row[\"Subject identity\"]) == {\n            \"email\": TEST_EMAIL,\n            \"phone_number\": TEST_PHONE,\n        }\n        assert first_row[\"Policy key\"] == \"example_access_request_policy\"\n        assert first_row[\"Request status\"] == \"approved\"\n        assert first_row[\"Reviewer\"] == user.id\n        assert parse(first_row[\"Time approved/denied\"], ignoretz=True) == reviewed_at\n        assert first_row[\"Denial reason\"] == \"\"\n\n        privacy_request.delete(db)\n\n    def test_get_paused_access_privacy_request_resume_info(\n        self, db, privacy_request, generate_auth_header, api_client, url\n    ):\n        # Mock the privacy request being in a paused state waiting for manual input to the \"manual_collection\"\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n        paused_step = CurrentStep.access\n        paused_collection = CollectionAddress(\"manual_dataset\", \"manual_collection\")\n        privacy_request.cache_paused_collection_details(\n            step=paused_step,\n            collection=paused_collection,\n            action_needed=[\n                ManualAction(\n                    locators={\"email\": [\"customer-1@example.com\"]},\n                    get=[\"authorized_user\"],\n                    update=None,\n                )\n            ],\n        )\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        data = response.json()[\"items\"][0]\n        assert data[\"status\"] == \"paused\"\n        assert data[\"action_required_details\"] == {\n            \"step\": \"access\",\n            \"collection\": \"manual_dataset:manual_collection\",\n            \"action_needed\": [\n                {\n                    \"locators\": {\"email\": [\"customer-1@example.com\"]},\n                    \"get\": [\"authorized_user\"],\n                    \"update\": None,\n                }\n            ],\n        }\n        assert data[\"resume_endpoint\"] == \"/privacy-request/{}/manual_input\".format(\n            privacy_request.id\n        )\n\n    def test_get_requires_input_privacy_request_resume_info(\n        self, db, privacy_request, generate_auth_header, api_client, url\n    ):\n        # Mock the privacy request being in a requires_input state\n        privacy_request.status = PrivacyRequestStatus.requires_input\n        privacy_request.save(db)\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        data = response.json()[\"items\"][0]\n        assert data[\"status\"] == \"requires_input\"\n        assert data[\"action_required_details\"] is None\n        assert data[\n            \"resume_endpoint\"\n        ] == \"/privacy-request/{}/resume_from_requires_input\".format(privacy_request.id)\n\n    def test_get_paused_erasure_privacy_request_resume_info(\n        self, db, privacy_request, generate_auth_header, api_client, url\n    ):\n        # Mock the privacy request being in a paused state waiting for manual erasure confirmation to the \"another_collection\"\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n        paused_step = CurrentStep.erasure\n        paused_collection = CollectionAddress(\"manual_dataset\", \"another_collection\")\n        privacy_request.cache_paused_collection_details(\n            step=paused_step,\n            collection=paused_collection,\n            action_needed=[\n                ManualAction(\n                    locators={\"id\": [32424]},\n                    get=None,\n                    update={\"authorized_user\": \"abcde_masked_user\"},\n                )\n            ],\n        )\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        data = response.json()[\"items\"][0]\n        assert data[\"status\"] == \"paused\"\n        assert data[\"action_required_details\"] == {\n            \"step\": \"erasure\",\n            \"collection\": \"manual_dataset:another_collection\",\n            \"action_needed\": [\n                {\n                    \"locators\": {\"id\": [32424]},\n                    \"get\": None,\n                    \"update\": {\"authorized_user\": \"abcde_masked_user\"},\n                }\n            ],\n        }\n        assert data[\"resume_endpoint\"] == \"/privacy-request/{}/erasure_confirm\".format(\n            privacy_request.id\n        )\n\n    def test_get_paused_webhook_resume_info(\n        self, db, privacy_request, generate_auth_header, api_client, url\n    ):\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        data = response.json()[\"items\"][0]\n        assert data[\"status\"] == \"paused\"\n        assert data[\"action_required_details\"] is None\n        assert data[\"resume_endpoint\"] == \"/privacy-request/{}/resume\".format(\n            privacy_request.id\n        )\n\n    def test_get_failed_request_resume_info_from_collection(\n        self, db, privacy_request, generate_auth_header, api_client, url\n    ):\n        # Mock the privacy request being in an errored state waiting for retry\n        privacy_request.status = PrivacyRequestStatus.error\n        privacy_request.save(db)\n        privacy_request.cache_failed_checkpoint_details(\n            step=CurrentStep.erasure,\n            collection=CollectionAddress(\"manual_example\", \"another_collection\"),\n        )\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        data = response.json()[\"items\"][0]\n        assert data[\"status\"] == \"error\"\n        assert data[\"action_required_details\"] == {\n            \"step\": \"erasure\",\n            \"collection\": \"manual_example:another_collection\",\n            \"action_needed\": None,\n        }\n        assert data[\"resume_endpoint\"] == f\"/privacy-request/{privacy_request.id}/retry\"\n\n    def test_get_failed_request_resume_info_from_email_send(\n        self, db, privacy_request, generate_auth_header, api_client, url\n    ):\n        # Mock the privacy request being in an errored state waiting for retry\n        privacy_request.status = PrivacyRequestStatus.error\n        privacy_request.save(db)\n        privacy_request.cache_failed_checkpoint_details(\n            step=CurrentStep.erasure_email_post_send,\n            collection=None,\n        )\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n\n        data = response.json()[\"items\"][0]\n        assert data[\"status\"] == \"error\"\n        assert data[\"action_required_details\"] == {\n            \"step\": \"erasure_email_post_send\",\n            \"collection\": None,\n            \"action_needed\": None,\n        }\n        assert data[\"resume_endpoint\"] == f\"/privacy-request/{privacy_request.id}/retry\"\n\n    @pytest.mark.parametrize(\n        \"due_date, days_left\",\n        [\n            (\n                datetime.utcnow() + timedelta(days=7),\n                7,\n            ),\n            (\n                datetime.utcnow(),\n                0,\n            ),\n            (\n                datetime.utcnow() + timedelta(days=-7),\n                -7,\n            ),\n        ],\n    )\n    def test_get_privacy_requests_sets_days_left(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        privacy_request,\n        due_date,\n        days_left,\n    ):\n        privacy_request.due_date = due_date\n        privacy_request.save(db)\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(url, headers=auth_header)\n        data = response.json()[\"items\"][0]\n        assert data[\"days_left\"] == days_left\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_sort_privacy_request_by_due_date(\n        self,\n        run_access_request_mock,\n        generate_auth_header,\n        url,\n        db,\n        api_client: TestClient,\n        policy: Policy,\n    ):\n        days_left_values = []\n        data = []\n        now = datetime.utcnow()\n        for _ in range(0, 10):\n            days = randint(1, 100)\n            requested_at = now + timedelta(days=days)\n            data.append(\n                {\n                    \"requested_at\": str(requested_at),\n                    \"policy_key\": policy.key,\n                    \"identity\": {\"email\": \"test@example.com\"},\n                }\n            )\n            days_left_values.append(days + policy.execution_timeframe)\n\n        api_client.post(url, json=data)\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        resp = api_client.get(\n            f\"{url}?sort_direction=asc&sort_field=due_date\",\n            json=data,\n            headers=auth_header,\n        )\n        asc_response_data = resp.json()[\"items\"]\n        days_left_values.sort()\n        for i, request in enumerate(asc_response_data):\n            assert request[\"days_left\"] == days_left_values[i]\n\n        resp = api_client.get(\n            f\"{url}?sort_direction=desc&sort_field=due_date\",\n            json=data,\n            headers=auth_header,\n        )\n        desc_response_data = resp.json()[\"items\"]\n        days_left_values.reverse()\n        for i, request in enumerate(desc_response_data):\n            assert request[\"days_left\"] == days_left_values[i]\n\n        for request in desc_response_data:\n            pr = PrivacyRequest.get(db=db, object_id=request[\"id\"])\n            pr.delete(db=db)\n\n\nclass TestGetExecutionLogs:\n    @pytest.fixture(scope=\"function\")\n    def url(self, db, privacy_request):\n        return V1_URL_PREFIX + PRIVACY_REQUESTS + f\"/{privacy_request.id}/log\"\n\n    def test_get_execution_logs_unauthenticated(\n        self, api_client: TestClient, privacy_request, url\n    ):\n        response = api_client.get(url, headers={})\n        assert 401 == response.status_code\n\n    def test_get_execution_logs_wrong_scope(\n        self, api_client: TestClient, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header(scopes=[STORAGE_CREATE_OR_UPDATE])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_execution_logs_invalid_privacy_request_id(\n        self, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            V1_URL_PREFIX + PRIVACY_REQUESTS + f\"/invalid_privacy_request_id/log\",\n            headers=auth_header,\n        )\n        assert 404 == response.status_code\n\n    def test_get_execution_logs(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        url,\n        postgres_execution_log,\n        mongo_execution_log,\n        second_postgres_execution_log,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert 200 == response.status_code\n        resp = response.json()\n\n        expected_resp = {\n            \"items\": [\n                {\n                    \"collection_name\": \"user\",\n                    \"fields_affected\": [\n                        {\n                            \"path\": \"my-postgres-db:user:email\",\n                            \"field_name\": \"email\",\n                            \"data_categories\": [\"user.contact.email\"],\n                        }\n                    ],\n                    \"message\": None,\n                    \"action_type\": \"access\",\n                    \"status\": \"pending\",\n                    \"updated_at\": stringify_date(postgres_execution_log.updated_at),\n                    \"dataset_name\": \"my-postgres-db\",\n                },\n                {\n                    \"collection_name\": \"orders\",\n                    \"fields_affected\": [\n                        {\n                            \"path\": \"my-mongo-db:orders:name\",\n                            \"field_name\": \"name\",\n                            \"data_categories\": [\"user.contact.name\"],\n                        }\n                    ],\n                    \"message\": None,\n                    \"action_type\": \"access\",\n                    \"status\": \"in_processing\",\n                    \"updated_at\": stringify_date(mongo_execution_log.updated_at),\n                    \"dataset_name\": \"my-mongo-db\",\n                },\n                {\n                    \"collection_name\": \"address\",\n                    \"fields_affected\": [\n                        {\n                            \"path\": \"my-postgres-db:address:street\",\n                            \"field_name\": \"street\",\n                            \"data_categories\": [\"user.contact.address.street\"],\n                        },\n                        {\n                            \"path\": \"my-postgres-db:address:city\",\n                            \"field_name\": \"city\",\n                            \"data_categories\": [\"user.contact.address.city\"],\n                        },\n                    ],\n                    \"message\": \"Database timed out.\",\n                    \"action_type\": \"access\",\n                    \"status\": \"error\",\n                    \"updated_at\": stringify_date(\n                        second_postgres_execution_log.updated_at\n                    ),\n                    \"dataset_name\": \"my-postgres-db\",\n                },\n            ],\n            \"total\": 3,\n            \"page\": 1,\n            \"size\": page_size,\n        }\n\n        assert resp == expected_resp\n\n\nclass TestRequestPreview:\n    @pytest.fixture(scope=\"function\")\n    def url(self, db, privacy_request):\n        return V1_URL_PREFIX + REQUEST_PREVIEW\n\n    def test_request_preview(\n        self,\n        dataset_config_preview,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        data = [dataset_config_preview.fides_key]\n        response = api_client.put(url, headers=auth_header, json=data)\n        assert response.status_code == 200\n        response_body: List[DryRunDatasetResponse] = json.loads(response.text)\n        assert (\n            next(\n                response[\"query\"]\n                for response in response_body\n                if response[\"collectionAddress\"][\"dataset\"] == \"postgres\"\n                if response[\"collectionAddress\"][\"collection\"] == \"subscriptions\"\n            )\n            == \"SELECT email,id FROM subscriptions WHERE email = ?\"\n        )\n\n    def test_request_preview_incorrect_body(\n        self,\n        dataset_config_preview,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n        example_datasets,\n        mongo_connection_config,\n        connection_config,\n    ) -> None:\n        path = V1_URL_PREFIX + DATASETS\n        path_params = {\"connection_key\": mongo_connection_config.key}\n        datasets_url = path.format(**path_params)\n\n        # Use the dataset endpoint to create the Mongo DatasetConfig\n        api_client.patch(\n            datasets_url,\n            headers=generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE]),\n            json=[example_datasets[1]],\n        )\n\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        data = [\n            example_datasets[1][\"fides_key\"]\n        ]  # Mongo dataset that references a postgres dataset\n        response = api_client.put(url, headers=auth_header, json=data)\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == \"Referred to object postgres_example_test_dataset:customer:id does not \"\n            \"exist. Make sure all referenced datasets are included in the request body.\"\n        )\n\n        # Use the dataset endpoint to create the Postgres DatasetConfig\n        api_client.patch(\n            datasets_url,\n            headers=generate_auth_header(scopes=[DATASET_CREATE_OR_UPDATE]),\n            json=[example_datasets[0]],\n        )\n\n        # Preview still 400's, because both dataset fideskeys aren't included in the response\n        response = api_client.put(url, headers=auth_header, json=data)\n        assert response.status_code == 400\n\n        # Preview returns a 200, because both dataset keys are in the request body\n        response = api_client.put(\n            url,\n            headers=auth_header,\n            json=[example_datasets[0][\"fides_key\"], example_datasets[1][\"fides_key\"]],\n        )\n        assert response.status_code == 200\n\n    def test_request_preview_all(\n        self,\n        dataset_config_preview,\n        manual_dataset_config,\n        integration_manual_config,\n        postgres_example_test_dataset_config,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.put(url, headers=auth_header)\n        assert response.status_code == 200\n        response_body: List[DryRunDatasetResponse] = json.loads(response.text)\n\n        assert (\n            next(\n                response[\"query\"]\n                for response in response_body\n                if response[\"collectionAddress\"][\"dataset\"] == \"postgres\"\n                if response[\"collectionAddress\"][\"collection\"] == \"subscriptions\"\n            )\n            == \"SELECT email,id FROM subscriptions WHERE email = ?\"\n        )\n\n        assert next(\n            response[\"query\"]\n            for response in response_body\n            if response[\"collectionAddress\"][\"dataset\"] == \"manual_input\"\n            if response[\"collectionAddress\"][\"collection\"] == \"filing_cabinet\"\n        ) == {\n            \"locators\": {\"customer_id\": [\"?\", \"?\"]},\n            \"get\": [\"authorized_user\", \"customer_id\", \"id\", \"payment_card_id\"],\n            \"update\": None,\n        }\n\n        assert next(\n            response[\"query\"]\n            for response in response_body\n            if response[\"collectionAddress\"][\"dataset\"] == \"manual_input\"\n            if response[\"collectionAddress\"][\"collection\"] == \"storage_unit\"\n        ) == {\"locators\": {\"email\": [\"?\"]}, \"get\": [\"box_id\", \"email\"], \"update\": None}\n\n\nclass TestApprovePrivacyRequest:\n    @pytest.fixture(scope=\"function\")\n    def url(self, db, privacy_request):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_APPROVE\n\n    @pytest.fixture(scope=\"function\")\n    def privacy_request_review_email_notification_enabled(self):\n        \"\"\"Enable request review email\"\"\"\n        original_value = config.notifications.send_request_review_notification\n        config.notifications.send_request_review_notification = True\n        yield\n        config.notifications.send_request_review_notification = original_value\n\n    def test_approve_privacy_request_not_authenticated(self, url, api_client):\n        response = api_client.patch(url)\n        assert response.status_code == 401\n\n    def test_approve_privacy_request_bad_scopes(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.patch(url, headers=auth_header)\n        assert response.status_code == 403\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_approve_privacy_request_does_not_exist(\n        self, submit_mock, db, url, api_client, generate_auth_header, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_REVIEW])\n\n        body = {\"request_ids\": [\"does_not_exist\"]}\n        response = api_client.patch(url, headers=auth_header, json=body)\n        assert response.status_code == 200\n\n        response_body = response.json()\n        assert response_body[\"succeeded\"] == []\n        assert len(response_body[\"failed\"]) == 1\n        assert (\n            response_body[\"failed\"][0][\"message\"]\n            == \"No privacy request found with id 'does_not_exist'\"\n        )\n        assert not submit_mock.called\n\n    @pytest.mark.parametrize(\n        \"privacy_request_status\",\n        [PrivacyRequestStatus.complete, PrivacyRequestStatus.canceled],\n    )\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_approve_privacy_request_in_non_pending_state(\n        self,\n        submit_mock,\n        db,\n        url,\n        api_client,\n        generate_auth_header,\n        privacy_request,\n        privacy_request_status,\n    ):\n        privacy_request.status = privacy_request_status\n        privacy_request.save(db=db)\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_REVIEW])\n\n        body = {\"request_ids\": [privacy_request.id]}\n        response = api_client.patch(url, headers=auth_header, json=body)\n        assert response.status_code == 200\n\n        response_body = response.json()\n        assert response_body[\"succeeded\"] == []\n        assert len(response_body[\"failed\"]) == 1\n        assert response_body[\"failed\"][0][\"message\"] == \"Cannot transition status\"\n        assert (\n            response_body[\"failed\"][0][\"data\"][\"status\"] == privacy_request_status.value\n        )\n        assert not submit_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_approve_privacy_request_no_user_on_client(\n        self,\n        submit_mock,\n        db,\n        url,\n        api_client,\n        generate_auth_header,\n        privacy_request,\n        user,\n    ):\n        privacy_request.status = PrivacyRequestStatus.pending\n        privacy_request.save(db=db)\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_REVIEW])\n\n        body = {\"request_ids\": [privacy_request.id]}\n        response = api_client.patch(url, headers=auth_header, json=body)\n        assert response.status_code == 200\n\n        response_body = response.json()\n        assert len(response_body[\"succeeded\"]) == 1\n        assert len(response_body[\"failed\"]) == 0\n        assert response_body[\"succeeded\"][0][\"status\"] == \"approved\"\n        assert response_body[\"succeeded\"][0][\"id\"] == privacy_request.id\n        assert response_body[\"succeeded\"][0][\"reviewed_at\"] is not None\n        assert response_body[\"succeeded\"][0][\"reviewed_by\"] is None  # No user on client\n\n        assert submit_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_approve_privacy_request(\n        self,\n        mock_dispatch_email,\n        submit_mock,\n        db,\n        url,\n        api_client,\n        generate_auth_header,\n        user,\n        privacy_request,\n    ):\n        privacy_request.status = PrivacyRequestStatus.pending\n        privacy_request.save(db=db)\n\n        payload = {\n            JWE_PAYLOAD_SCOPES: user.client.scopes,\n            JWE_PAYLOAD_CLIENT_ID: user.client.id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n\n        body = {\"request_ids\": [privacy_request.id]}\n        response = api_client.patch(url, headers=auth_header, json=body)\n\n        assert response.status_code == 200\n\n        response_body = response.json()\n        assert len(response_body[\"succeeded\"]) == 1\n        assert len(response_body[\"failed\"]) == 0\n        assert response_body[\"succeeded\"][0][\"status\"] == \"approved\"\n        assert response_body[\"succeeded\"][0][\"id\"] == privacy_request.id\n        assert response_body[\"succeeded\"][0][\"reviewed_at\"] is not None\n        assert response_body[\"succeeded\"][0][\"reviewed_by\"] == user.id\n\n        assert submit_mock.called\n        assert not mock_dispatch_email.called\n\n        privacy_request.delete(db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_approve_privacy_request_creates_audit_log_and_sends_email(\n        self,\n        mock_dispatch_email,\n        submit_mock,\n        db,\n        url,\n        api_client,\n        generate_auth_header,\n        user,\n        privacy_request_status_pending,\n        privacy_request_review_email_notification_enabled,\n    ):\n        payload = {\n            JWE_PAYLOAD_SCOPES: user.client.scopes,\n            JWE_PAYLOAD_CLIENT_ID: user.client.id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n\n        body = {\"request_ids\": [privacy_request_status_pending.id]}\n        api_client.patch(url, headers=auth_header, json=body)\n        approval_audit_log: AuditLog = AuditLog.filter(\n            db=db,\n            conditions=(\n                (AuditLog.privacy_request_id == privacy_request_status_pending.id)\n                & (AuditLog.user_id == user.id)\n                & (AuditLog.action == AuditLogAction.approved)\n            ),\n        ).first()\n\n        assert approval_audit_log is not None\n        assert approval_audit_log.message == \"\"\n\n        approval_audit_log.delete(db)\n\n        call_args = mock_dispatch_email.call_args[1]\n        task_kwargs = call_args[\"kwargs\"]\n        assert task_kwargs[\"to_email\"] == \"test@example.com\"\n\n        email_meta = task_kwargs[\"email_meta\"]\n        assert (\n            email_meta[\"action_type\"] == EmailActionType.PRIVACY_REQUEST_REVIEW_APPROVE\n        )\n        assert email_meta[\"body_params\"] is None\n        queue = call_args[\"queue\"]\n        assert queue == EMAIL_QUEUE_NAME\n\n\nclass TestDenyPrivacyRequest:\n    @pytest.fixture(scope=\"function\")\n    def url(self, db, privacy_request):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_DENY\n\n    @pytest.fixture(autouse=True, scope=\"function\")\n    def privacy_request_review_email_notification_enabled(self):\n        \"\"\"Enable request review email\"\"\"\n        original_value = config.notifications.send_request_review_notification\n        config.notifications.send_request_review_notification = True\n        yield\n        config.notifications.send_request_review_notification = original_value\n\n    def test_deny_privacy_request_not_authenticated(self, url, api_client):\n        response = api_client.patch(url)\n        assert response.status_code == 401\n\n    def test_deny_privacy_request_bad_scopes(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n        response = api_client.patch(url, headers=auth_header)\n        assert response.status_code == 403\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_deny_privacy_request_does_not_exist(\n        self, submit_mock, db, url, api_client, generate_auth_header, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_REVIEW])\n\n        body = {\"request_ids\": [\"does_not_exist\"]}\n        response = api_client.patch(url, headers=auth_header, json=body)\n        assert response.status_code == 200\n\n        response_body = response.json()\n        assert response_body[\"succeeded\"] == []\n        assert len(response_body[\"failed\"]) == 1\n        assert (\n            response_body[\"failed\"][0][\"message\"]\n            == \"No privacy request found with id 'does_not_exist'\"\n        )\n        assert not submit_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_deny_completed_privacy_request(\n        self, submit_mock, db, url, api_client, generate_auth_header, privacy_request\n    ):\n        privacy_request.status = PrivacyRequestStatus.complete\n        privacy_request.save(db=db)\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_REVIEW])\n\n        body = {\"request_ids\": [privacy_request.id]}\n        response = api_client.patch(url, headers=auth_header, json=body)\n        assert response.status_code == 200\n\n        response_body = response.json()\n        assert response_body[\"succeeded\"] == []\n        assert len(response_body[\"failed\"]) == 1\n        assert response_body[\"failed\"][0][\"message\"] == \"Cannot transition status\"\n        assert response_body[\"failed\"][0][\"data\"][\"status\"] == \"complete\"\n        assert not submit_mock.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_deny_privacy_request_without_denial_reason(\n        self,\n        mock_dispatch_email,\n        submit_mock,\n        db,\n        url,\n        api_client,\n        generate_auth_header,\n        user,\n        privacy_request,\n    ):\n        privacy_request.status = PrivacyRequestStatus.pending\n        privacy_request.save(db=db)\n\n        payload = {\n            JWE_PAYLOAD_SCOPES: user.client.scopes,\n            JWE_PAYLOAD_CLIENT_ID: user.client.id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n\n        body = {\"request_ids\": [privacy_request.id]}\n        response = api_client.patch(url, headers=auth_header, json=body)\n        assert response.status_code == 200\n\n        response_body = response.json()\n        assert len(response_body[\"succeeded\"]) == 1\n        assert len(response_body[\"failed\"]) == 0\n        assert response_body[\"succeeded\"][0][\"status\"] == \"denied\"\n        assert response_body[\"succeeded\"][0][\"id\"] == privacy_request.id\n        assert response_body[\"succeeded\"][0][\"reviewed_at\"] is not None\n        assert response_body[\"succeeded\"][0][\"reviewed_by\"] == user.id\n        denial_audit_log: AuditLog = AuditLog.filter(\n            db=db,\n            conditions=(\n                (AuditLog.privacy_request_id == privacy_request.id)\n                & (AuditLog.user_id == user.id)\n            ),\n        ).first()\n\n        call_args = mock_dispatch_email.call_args[1]\n        task_kwargs = call_args[\"kwargs\"]\n        assert task_kwargs[\"to_email\"] == \"test@example.com\"\n\n        email_meta = task_kwargs[\"email_meta\"]\n        assert email_meta[\"action_type\"] == EmailActionType.PRIVACY_REQUEST_REVIEW_DENY\n        assert email_meta[\"body_params\"] == RequestReviewDenyBodyParams(\n            rejection_reason=None\n        )\n        queue = call_args[\"queue\"]\n        assert queue == EMAIL_QUEUE_NAME\n\n        assert denial_audit_log.message is None\n\n        assert not submit_mock.called  # Shouldn't run! Privacy request was denied\n\n        privacy_request.delete(db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_deny_privacy_request_with_denial_reason(\n        self,\n        mock_dispatch_email,\n        submit_mock,\n        db,\n        url,\n        api_client,\n        generate_auth_header,\n        user,\n        privacy_request,\n    ):\n        privacy_request.status = PrivacyRequestStatus.pending\n        privacy_request.save(db=db)\n\n        payload = {\n            JWE_PAYLOAD_SCOPES: user.client.scopes,\n            JWE_PAYLOAD_CLIENT_ID: user.client.id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n        denial_reason = \"Your request was denied because reasons\"\n        body = {\"request_ids\": [privacy_request.id], \"reason\": denial_reason}\n        response = api_client.patch(url, headers=auth_header, json=body)\n        assert response.status_code == 200\n\n        response_body = response.json()\n        assert len(response_body[\"succeeded\"]) == 1\n        assert len(response_body[\"failed\"]) == 0\n        assert response_body[\"succeeded\"][0][\"status\"] == \"denied\"\n        assert response_body[\"succeeded\"][0][\"id\"] == privacy_request.id\n        assert response_body[\"succeeded\"][0][\"reviewed_at\"] is not None\n        assert response_body[\"succeeded\"][0][\"reviewed_by\"] == user.id\n        denial_audit_log: AuditLog = AuditLog.filter(\n            db=db,\n            conditions=(\n                (AuditLog.privacy_request_id == privacy_request.id)\n                & (AuditLog.user_id == user.id)\n            ),\n        ).first()\n\n        call_args = mock_dispatch_email.call_args[1]\n        task_kwargs = call_args[\"kwargs\"]\n        assert task_kwargs[\"to_email\"] == \"test@example.com\"\n\n        email_meta = task_kwargs[\"email_meta\"]\n        assert email_meta[\"action_type\"] == EmailActionType.PRIVACY_REQUEST_REVIEW_DENY\n        assert email_meta[\"body_params\"] == RequestReviewDenyBodyParams(\n            rejection_reason=denial_reason\n        )\n        queue = call_args[\"queue\"]\n        assert queue == EMAIL_QUEUE_NAME\n\n        assert denial_audit_log.message == denial_reason\n\n        assert not submit_mock.called  # Shouldn't run! Privacy request was denied\n\n        privacy_request.delete(db)\n\n\nclass TestResumePrivacyRequest:\n    @pytest.fixture(scope=\"function\")\n    def url(self, db, privacy_request):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_RESUME.format(\n            privacy_request_id=privacy_request.id\n        )\n\n    def test_resume_privacy_request_not_authenticated(\n        self,\n        url,\n        api_client,\n        generate_webhook_auth_header,\n        policy_pre_execution_webhooks,\n    ):\n        response = api_client.post(url)\n        assert response.status_code == 401\n\n    def test_resume_privacy_request_invalid_jwe_format(\n        self,\n        url,\n        api_client,\n        generate_webhook_auth_header,\n        policy_pre_execution_webhooks,\n    ):\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(\n                json.dumps({\"unexpected\": \"format\"}), config.security.app_encryption_key\n            )\n        }\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == 403\n\n    def test_resume_privacy_request_invalid_scopes(\n        self,\n        url,\n        api_client,\n        generate_webhook_auth_header,\n        policy_pre_execution_webhooks,\n    ):\n        \"\"\"\n        Test scopes are correct, although we just gave a user this token with the\n        correct scopes, the check doesn't mean much\n        \"\"\"\n\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(\n                json.dumps(\n                    {\n                        \"webhook_id\": policy_pre_execution_webhooks[0].id,\n                        \"scopes\": [PRIVACY_REQUEST_READ],\n                        \"iat\": datetime.now().isoformat(),\n                    }\n                ),\n                config.security.app_encryption_key,\n            )\n        }\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == 403\n\n    def test_resume_privacy_request_invalid_webhook(\n        self,\n        url,\n        api_client,\n        generate_webhook_auth_header,\n        policy_post_execution_webhooks,\n    ):\n        \"\"\"Only can resume execution after Pre-Execution webhooks\"\"\"\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(\n                json.dumps(\n                    {\n                        \"webhook_id\": policy_post_execution_webhooks[0].id,\n                        \"scopes\": [PRIVACY_REQUEST_CALLBACK_RESUME],\n                        \"iat\": datetime.now().isoformat(),\n                    }\n                ),\n                config.security.app_encryption_key,\n            )\n        }\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == 404\n\n    def test_resume_privacy_request_not_paused(\n        self,\n        url,\n        api_client,\n        generate_webhook_auth_header,\n        policy_pre_execution_webhooks,\n        privacy_request,\n        db,\n    ):\n        privacy_request.status = PrivacyRequestStatus.complete\n        privacy_request.save(db=db)\n        auth_header = generate_webhook_auth_header(\n            webhook=policy_pre_execution_webhooks[0]\n        )\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == 400\n\n        privacy_request.delete(db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_resume_privacy_request(\n        self,\n        submit_mock,\n        url,\n        api_client,\n        generate_webhook_auth_header,\n        policy_pre_execution_webhooks,\n        privacy_request,\n        db,\n    ):\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.due_date = None\n        privacy_request.save(db=db)\n        auth_header = generate_webhook_auth_header(\n            webhook=policy_pre_execution_webhooks[0]\n        )\n        response = api_client.post(\n            url, headers=auth_header, json={\"derived_identity\": {}}\n        )\n        assert response.status_code == 200\n        response_body = json.loads(response.text)\n        assert submit_mock.called\n        assert response_body == {\n            \"id\": privacy_request.id,\n            \"created_at\": stringify_date(privacy_request.created_at),\n            \"days_left\": None,\n            \"started_processing_at\": stringify_date(\n                privacy_request.started_processing_at\n            ),\n            \"finished_processing_at\": None,\n            \"identity_verified_at\": None,\n            \"status\": \"in_processing\",\n            \"external_id\": privacy_request.external_id,\n            \"identity\": None,\n            \"reviewed_at\": None,\n            \"reviewed_by\": None,\n            \"reviewer\": None,\n            \"paused_at\": None,\n            \"policy\": {\n                \"execution_timeframe\": 7,\n                \"drp_action\": None,\n                \"key\": privacy_request.policy.key,\n                \"name\": privacy_request.policy.name,\n                \"rules\": [\n                    rule.dict()\n                    for rule in PolicyResponse.from_orm(privacy_request.policy).rules\n                ],\n            },\n            \"action_required_details\": None,\n            \"resume_endpoint\": None,\n        }\n\n        privacy_request.delete(db)\n\n\nclass TestResumeAccessRequestWithManualInput:\n    @pytest.fixture(scope=\"function\")\n    def url(self, privacy_request):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_MANUAL_INPUT.format(\n            privacy_request_id=privacy_request.id\n        )\n\n    def test_manual_resume_not_authenticated(self, api_client, url):\n        response = api_client.post(url, headers={}, json={})\n        assert response.status_code == 401\n\n    def test_manual_resume_wrong_scope(self, api_client, url, generate_auth_header):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == 403\n\n    def test_manual_resume_privacy_request_not_paused(\n        self, api_client, url, generate_auth_header, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        response = api_client.post(url, headers=auth_header, json=[{\"mock\": \"row\"}])\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == f\"Invalid resume request: privacy request '{privacy_request.id}' status = in_processing. Privacy request is not paused.\"\n        )\n\n    def test_manual_resume_privacy_request_no_paused_location(\n        self, db, api_client, url, generate_auth_header, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        response = api_client.post(url, headers=auth_header, json=[{\"mock\": \"row\"}])\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == f\"Cannot resume privacy request '{privacy_request.id}'; no paused details.\"\n        )\n\n        privacy_request.delete(db)\n\n    def test_resume_with_manual_input_collection_has_changed(\n        self, db, api_client, url, generate_auth_header, privacy_request\n    ):\n        \"\"\"Fail if user has changed graph so that the paused node doesn't exist\"\"\"\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        privacy_request.cache_paused_collection_details(\n            step=CurrentStep.access,\n            collection=CollectionAddress(\"manual_example\", \"filing_cabinet\"),\n        )\n\n        response = api_client.post(url, headers=auth_header, json=[{\"mock\": \"row\"}])\n        assert response.status_code == 422\n        assert (\n            response.json()[\"detail\"]\n            == \"Cannot save manual data. No collection in graph with name: 'manual_example:filing_cabinet'.\"\n        )\n\n        privacy_request.delete(db)\n\n    @pytest.mark.usefixtures(\n        \"postgres_example_test_dataset_config\", \"manual_dataset_config\"\n    )\n    def test_resume_with_manual_input_invalid_data(\n        self,\n        db,\n        api_client,\n        url,\n        generate_auth_header,\n        privacy_request,\n    ):\n        \"\"\"Fail if the manual data entered does not match fields on the dataset\"\"\"\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        privacy_request.cache_paused_collection_details(\n            step=CurrentStep.access,\n            collection=CollectionAddress(\"manual_input\", \"filing_cabinet\"),\n        )\n\n        response = api_client.post(url, headers=auth_header, json=[{\"mock\": \"row\"}])\n        assert response.status_code == 422\n        assert (\n            response.json()[\"detail\"]\n            == \"Cannot save manual rows. No 'mock' field defined on the 'manual_input:filing_cabinet' collection.\"\n        )\n\n        privacy_request.delete(db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @pytest.mark.usefixtures(\n        \"postgres_example_test_dataset_config\", \"manual_dataset_config\"\n    )\n    def test_resume_with_manual_input(\n        self,\n        _,\n        db,\n        api_client,\n        url,\n        generate_auth_header,\n        privacy_request,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        privacy_request.cache_paused_collection_details(\n            step=CurrentStep.access,\n            collection=CollectionAddress(\"manual_input\", \"filing_cabinet\"),\n        )\n\n        response = api_client.post(\n            url,\n            headers=auth_header,\n            json=[\n                {\n                    \"id\": 1,\n                    \"authorized_user\": \"Jason Doe\",\n                    \"customer_id\": 1,\n                    \"payment_card_id\": \"abcde\",\n                }\n            ],\n        )\n        assert response.status_code == 200\n\n        db.refresh(privacy_request)\n        assert privacy_request.status == PrivacyRequestStatus.in_processing\n\n        privacy_request.delete(db)\n\n\nclass TestValidateManualInput:\n    \"\"\"Verify pytest cell-var-from-loop warning is a false positive\"\"\"\n\n    @pytest.fixture(scope=\"function\")\n    @pytest.mark.usefixtures(\"postgres_example_test_dataset_config\")\n    def dataset_graph(self, db):\n        datasets = DatasetConfig.all(db=db)\n        dataset_graphs = [dataset_config.get_graph() for dataset_config in datasets]\n        dataset_graph = DatasetGraph(*dataset_graphs)\n        return dataset_graph\n\n    @pytest.mark.usefixtures(\"postgres_example_test_dataset_config\")\n    def test_all_fields_match(self, dataset_graph):\n        paused_location = CollectionAddress(\"postgres_example_test_dataset\", \"address\")\n\n        manual_rows = [{\"city\": \"Nashville\", \"state\": \"TN\"}]\n        validate_manual_input(manual_rows, paused_location, dataset_graph)\n\n    @pytest.mark.usefixtures(\"postgres_example_test_dataset_config\")\n    def test_one_field_does_not_match(self, dataset_graph):\n        paused_location = CollectionAddress(\"postgres_example_test_dataset\", \"address\")\n\n        manual_rows = [{\"city\": \"Nashville\", \"state\": \"TN\", \"ccn\": \"aaa-aaa\"}]\n        with pytest.raises(HTTPException) as exc:\n            validate_manual_input(manual_rows, paused_location, dataset_graph)\n        assert (\n            exc.value.detail\n            == \"Cannot save manual rows. No 'ccn' field defined on the 'postgres_example_test_dataset:address' collection.\"\n        )\n\n    @pytest.mark.usefixtures(\"postgres_example_test_dataset_config\")\n    def test_field_on_second_row_does_not_match(self, dataset_graph):\n        paused_location = CollectionAddress(\"postgres_example_test_dataset\", \"address\")\n\n        manual_rows = [\n            {\"city\": \"Nashville\", \"state\": \"TN\"},\n            {\"city\": \"Austin\", \"misspelled_state\": \"TX\"},\n        ]\n        with pytest.raises(HTTPException) as exc:\n            validate_manual_input(manual_rows, paused_location, dataset_graph)\n        assert (\n            exc.value.detail\n            == \"Cannot save manual rows. No 'misspelled_state' field defined on the 'postgres_example_test_dataset:address' collection.\"\n        )\n\n\nclass TestResumeErasureRequestWithManualConfirmation:\n    @pytest.fixture(scope=\"function\")\n    def url(self, privacy_request):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_MANUAL_ERASURE.format(\n            privacy_request_id=privacy_request.id\n        )\n\n    def test_manual_resume_not_authenticated(self, api_client, url):\n        response = api_client.post(url, headers={}, json={})\n        assert response.status_code == 401\n\n    def test_manual_resume_wrong_scope(self, api_client, url, generate_auth_header):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == 403\n\n    def test_manual_resume_privacy_request_not_paused(\n        self, api_client, url, generate_auth_header, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        response = api_client.post(url, headers=auth_header, json={\"row_count\": 0})\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == f\"Invalid resume request: privacy request '{privacy_request.id}' status = in_processing. Privacy request is not paused.\"\n        )\n\n    def test_manual_resume_privacy_request_no_paused_location(\n        self, db, api_client, url, generate_auth_header, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        response = api_client.post(url, headers=auth_header, json={\"row_count\": 0})\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == f\"Cannot resume privacy request '{privacy_request.id}'; no paused details.\"\n        )\n\n        privacy_request.delete(db)\n\n    def test_resume_with_manual_erasure_confirmation_collection_has_changed(\n        self, db, api_client, url, generate_auth_header, privacy_request\n    ):\n        \"\"\"Fail if user has changed graph so that the paused node doesn't exist\"\"\"\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        privacy_request.cache_paused_collection_details(\n            step=CurrentStep.erasure,\n            collection=CollectionAddress(\"manual_example\", \"filing_cabinet\"),\n        )\n\n        response = api_client.post(url, headers=auth_header, json={\"row_count\": 0})\n        assert response.status_code == 422\n        assert (\n            response.json()[\"detail\"]\n            == \"Cannot save manual data. No collection in graph with name: 'manual_example:filing_cabinet'.\"\n        )\n\n        privacy_request.delete(db)\n\n    def test_resume_still_paused_at_access_request(\n        self, db, api_client, url, generate_auth_header, privacy_request\n    ):\n        \"\"\"Fail if user hitting wrong endpoint to resume.\"\"\"\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        privacy_request.cache_paused_collection_details(\n            step=CurrentStep.access,\n            collection=CollectionAddress(\"manual_example\", \"filing_cabinet\"),\n        )\n        response = api_client.post(url, headers=auth_header, json={\"row_count\": 0})\n        assert response.status_code == 400\n\n        assert (\n            response.json()[\"detail\"]\n            == \"Collection 'manual_example:filing_cabinet' is paused at the access step. Pass in manual data instead to '/privacy-request/{privacy_request_id}/manual_input' to resume.\"\n        )\n\n        privacy_request.delete(db)\n\n    @pytest.mark.usefixtures(\n        \"postgres_example_test_dataset_config\", \"manual_dataset_config\"\n    )\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_resume_with_manual_count(\n        self,\n        _,\n        db,\n        api_client,\n        url,\n        generate_auth_header,\n        privacy_request,\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.paused\n        privacy_request.save(db)\n\n        privacy_request.cache_paused_collection_details(\n            step=CurrentStep.erasure,\n            collection=CollectionAddress(\"manual_input\", \"filing_cabinet\"),\n        )\n        response = api_client.post(\n            url,\n            headers=auth_header,\n            json={\"row_count\": 5},\n        )\n        assert response.status_code == 200\n\n        db.refresh(privacy_request)\n        assert privacy_request.status == PrivacyRequestStatus.in_processing\n\n        privacy_request.delete(db)\n\n\nclass TestRestartFromFailure:\n    @pytest.fixture(scope=\"function\")\n    def url(self, db, privacy_request):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_RETRY.format(\n            privacy_request_id=privacy_request.id\n        )\n\n    def test_restart_from_failure_not_authenticated(self, api_client, url):\n        response = api_client.post(url, headers={})\n        assert response.status_code == 401\n\n    def test_restart_from_failure_wrong_scope(\n        self, api_client, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_READ])\n\n        response = api_client.post(url, headers=auth_header)\n        assert response.status_code == 403\n\n    def test_restart_from_failure_not_errored(\n        self, api_client, url, generate_auth_header, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n\n        response = api_client.post(url, headers=auth_header)\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == f\"Cannot restart privacy request from failure: privacy request '{privacy_request.id}' status = in_processing.\"\n        )\n\n    def test_restart_from_failure_no_stopped_step(\n        self, api_client, url, generate_auth_header, db, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.error\n        privacy_request.save(db)\n\n        response = api_client.post(url, headers=auth_header)\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == f\"Cannot restart privacy request from failure '{privacy_request.id}'; no failed step or collection.\"\n        )\n\n        privacy_request.delete(db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_restart_from_failure_from_specific_collection(\n        self, submit_mock, api_client, url, generate_auth_header, db, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.error\n        privacy_request.save(db)\n\n        privacy_request.cache_failed_checkpoint_details(\n            step=CurrentStep.access,\n            collection=CollectionAddress(\"test_dataset\", \"test_collection\"),\n        )\n\n        response = api_client.post(url, headers=auth_header)\n        assert response.status_code == 200\n\n        db.refresh(privacy_request)\n        assert privacy_request.status == PrivacyRequestStatus.in_processing\n\n        submit_mock.assert_called_with(\n            privacy_request_id=privacy_request.id,\n            from_step=CurrentStep.access.value,\n            from_webhook_id=None,\n        )\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_restart_from_failure_outside_graph(\n        self, submit_mock, api_client, url, generate_auth_header, db, privacy_request\n    ):\n        auth_header = generate_auth_header(scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request.status = PrivacyRequestStatus.error\n        privacy_request.save(db)\n\n        privacy_request.cache_failed_checkpoint_details(\n            step=CurrentStep.erasure_email_post_send,\n            collection=None,\n        )\n\n        response = api_client.post(url, headers=auth_header)\n        assert response.status_code == 200\n\n        db.refresh(privacy_request)\n        assert privacy_request.status == PrivacyRequestStatus.in_processing\n\n        submit_mock.assert_called_with(\n            privacy_request_id=privacy_request.id,\n            from_step=CurrentStep.erasure_email_post_send.value,\n            from_webhook_id=None,\n        )\n\n\nclass TestVerifyIdentity:\n    code = \"123456\"\n\n    @pytest.fixture(scope=\"function\")\n    def url(self, db, privacy_request):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_VERIFY_IDENTITY.format(\n            privacy_request_id=privacy_request.id\n        )\n\n    @pytest.fixture(scope=\"function\")\n    def privacy_request_receipt_email_notification_enabled(self):\n        \"\"\"Enable request receipt email\"\"\"\n        original_value = config.notifications.send_request_receipt_notification\n        config.notifications.send_request_receipt_notification = True\n        yield\n        config.notifications.send_request_receipt_notification = original_value\n\n    def test_incorrect_privacy_request_status(self, api_client, url, privacy_request):\n        request_body = {\"code\": self.code}\n        resp = api_client.post(url, headers={}, json=request_body)\n        assert resp.status_code == 400\n        assert (\n            resp.json()[\"detail\"]\n            == f\"Invalid identity verification request. Privacy request '{privacy_request.id}' status = in_processing.\"\n        )\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_verification_code_expired(\n        self,\n        mock_dispatch_email,\n        db,\n        api_client,\n        url,\n        privacy_request,\n        privacy_request_receipt_email_notification_enabled,\n    ):\n        privacy_request.status = PrivacyRequestStatus.identity_unverified\n        privacy_request.save(db)\n\n        request_body = {\"code\": self.code}\n        resp = api_client.post(url, headers={}, json=request_body)\n        assert resp.status_code == 400\n        assert (\n            resp.json()[\"detail\"]\n            == f\"Identification code expired for {privacy_request.id}.\"\n        )\n        assert not mock_dispatch_email.called\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_invalid_code(\n        self,\n        mock_dispatch_email,\n        db,\n        api_client,\n        url,\n        privacy_request,\n        privacy_request_receipt_email_notification_enabled,\n    ):\n        privacy_request.status = PrivacyRequestStatus.identity_unverified\n        privacy_request.save(db)\n        privacy_request.cache_identity_verification_code(\"999999\")\n\n        request_body = {\"code\": self.code}\n        resp = api_client.post(url, headers={}, json=request_body)\n        assert resp.status_code == 403\n        assert (\n            resp.json()[\"detail\"]\n            == f\"Incorrect identification code for '{privacy_request.id}'\"\n        )\n        assert not mock_dispatch_email.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_verify_identity_no_admin_approval_needed(\n        self,\n        mock_dispatch_email,\n        mock_run_privacy_request,\n        db,\n        api_client,\n        url,\n        privacy_request,\n        privacy_request_receipt_email_notification_enabled,\n    ):\n        privacy_request.status = PrivacyRequestStatus.identity_unverified\n        privacy_request.save(db)\n        privacy_request.cache_identity_verification_code(self.code)\n\n        request_body = {\"code\": self.code}\n        resp = api_client.post(url, headers={}, json=request_body)\n        assert resp.status_code == 200\n\n        resp = resp.json()\n        assert resp[\"status\"] == \"pending\"\n        assert resp[\"identity_verified_at\"] is not None\n\n        db.refresh(privacy_request)\n        assert privacy_request.status == PrivacyRequestStatus.pending\n        assert privacy_request.identity_verified_at is not None\n\n        approved_audit_log: AuditLog = AuditLog.filter(\n            db=db,\n            conditions=(\n                (AuditLog.privacy_request_id == privacy_request.id)\n                & (AuditLog.action == AuditLogAction.approved)\n            ),\n        ).first()\n\n        assert approved_audit_log is not None\n\n        assert mock_run_privacy_request.called\n\n        assert mock_dispatch_email.called\n\n        call_args = mock_dispatch_email.call_args[1]\n        task_kwargs = call_args[\"kwargs\"]\n        assert task_kwargs[\"to_email\"] == \"test@example.com\"\n\n        email_meta = task_kwargs[\"email_meta\"]\n        assert email_meta[\"action_type\"] == EmailActionType.PRIVACY_REQUEST_RECEIPT\n        assert email_meta[\"body_params\"] == RequestReceiptBodyParams(\n            request_types={ActionType.access.value}\n        )\n        queue = call_args[\"queue\"]\n        assert queue == EMAIL_QUEUE_NAME\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_verify_identity_no_admin_approval_needed_email_disabled(\n        self,\n        mock_dispatch_email,\n        mock_run_privacy_request,\n        db,\n        api_client,\n        url,\n        privacy_request,\n    ):\n        privacy_request.status = PrivacyRequestStatus.identity_unverified\n        privacy_request.save(db)\n        privacy_request.cache_identity_verification_code(self.code)\n\n        request_body = {\"code\": self.code}\n        resp = api_client.post(url, headers={}, json=request_body)\n        assert resp.status_code == 200\n\n        resp = resp.json()\n        assert resp[\"status\"] == \"pending\"\n        assert resp[\"identity_verified_at\"] is not None\n\n        db.refresh(privacy_request)\n        assert privacy_request.status == PrivacyRequestStatus.pending\n        assert privacy_request.identity_verified_at is not None\n\n        approved_audit_log: AuditLog = AuditLog.filter(\n            db=db,\n            conditions=(\n                (AuditLog.privacy_request_id == privacy_request.id)\n                & (AuditLog.action == AuditLogAction.approved)\n            ),\n        ).first()\n\n        assert approved_audit_log is not None\n\n        assert mock_run_privacy_request.called\n\n        assert not mock_dispatch_email.called\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_verify_identity_admin_approval_needed(\n        self,\n        mock_dispatch_email,\n        mock_run_privacy_request,\n        require_manual_request_approval,\n        db,\n        api_client,\n        url,\n        privacy_request,\n        privacy_request_receipt_email_notification_enabled,\n    ):\n        privacy_request.status = PrivacyRequestStatus.identity_unverified\n        privacy_request.save(db)\n        privacy_request.cache_identity_verification_code(self.code)\n\n        request_body = {\"code\": self.code}\n        resp = api_client.post(url, headers={}, json=request_body)\n        assert resp.status_code == 200\n\n        resp = resp.json()\n        assert resp[\"status\"] == \"pending\"\n        assert resp[\"identity_verified_at\"] is not None\n\n        db.refresh(privacy_request)\n        assert privacy_request.status == PrivacyRequestStatus.pending\n        assert privacy_request.identity_verified_at is not None\n\n        approved_audit_log: AuditLog = AuditLog.filter(\n            db=db,\n            conditions=(\n                (AuditLog.privacy_request_id == privacy_request.id)\n                & (AuditLog.action == AuditLogAction.approved)\n            ),\n        ).first()\n\n        assert approved_audit_log is None\n        assert not mock_run_privacy_request.called\n\n        assert mock_dispatch_email.called\n\n        call_args = mock_dispatch_email.call_args[1]\n        task_kwargs = call_args[\"kwargs\"]\n        assert task_kwargs[\"to_email\"] == \"test@example.com\"\n\n        email_meta = task_kwargs[\"email_meta\"]\n        assert email_meta[\"action_type\"] == EmailActionType.PRIVACY_REQUEST_RECEIPT\n        assert email_meta[\"body_params\"] == RequestReceiptBodyParams(\n            request_types={ActionType.access.value}\n        )\n        queue = call_args[\"queue\"]\n        assert queue == EMAIL_QUEUE_NAME\n\n\nclass TestCreatePrivacyRequestEmailVerificationRequired:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + PRIVACY_REQUESTS\n\n    @pytest.fixture(scope=\"function\")\n    def subject_identity_verification_required(self):\n        \"\"\"Override autouse fixture to enable identity verification for tests\"\"\"\n        original_value = config.execution.subject_identity_verification_required\n        config.execution.subject_identity_verification_required = True\n        yield\n        config.execution.subject_identity_verification_required = original_value\n\n    def test_create_privacy_request_no_email_config(\n        self,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n        subject_identity_verification_required,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"failed\"]\n        assert len(response_data) == 1\n        assert response_data[0][\"message\"] == \"Verification email could not be sent.\"\n        assert (\n            response_data[0][\"data\"][\"status\"]\n            == PrivacyRequestStatus.identity_unverified.value\n        )\n        pr = PrivacyRequest.get(\n            db=db, object_id=response_data[0][\"data\"][\"privacy_request_id\"]\n        )\n        pr.delete(db=db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\"fidesops.ops.service._verification.dispatch_email\")\n    def test_create_privacy_request_with_email_config(\n        self,\n        mock_dispatch_email,\n        mock_execute_request,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n        email_config,\n        subject_identity_verification_required,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        approval_audit_log: AuditLog = AuditLog.filter(\n            db=db,\n            conditions=(\n                (AuditLog.privacy_request_id == pr.id)\n                & (AuditLog.action == AuditLogAction.approved)\n            ),\n        ).first()\n        assert approval_audit_log is None\n        assert not mock_execute_request.called\n\n        assert response_data[0][\"status\"] == PrivacyRequestStatus.identity_unverified\n\n        assert mock_dispatch_email.called\n        kwargs = mock_dispatch_email.call_args.kwargs\n        assert kwargs[\"action_type\"] == EmailActionType.SUBJECT_IDENTITY_VERIFICATION\n        assert kwargs[\"to_email\"] == \"test@example.com\"\n        assert kwargs[\"email_body_params\"] == SubjectIdentityVerificationBodyParams(\n            verification_code=pr.get_cached_verification_code(),\n            verification_code_ttl_seconds=config.redis.identity_verification_code_ttl_seconds,\n        )\n\n        pr.delete(db=db)\n\n\nclass TestUploadManualWebhookInputs:\n    @pytest.fixture(scope=\"function\")\n    def url(\n        self,\n        db,\n        privacy_request_requires_input,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=privacy_request_requires_input.id,\n            connection_key=integration_manual_webhook_config.key,\n        )\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self):\n        return {\"email\": \"customer-1@example.com\", \"last_name\": \"McCustomer\"}\n\n    def test_patch_inputs_not_authenticated(self, api_client: TestClient, url):\n        response = api_client.patch(url, headers={})\n        assert 401 == response.status_code\n\n    def test_patch_inputs_wrong_scopes(\n        self, api_client: TestClient, url, generate_auth_header, payload\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_READ])\n        response = api_client.patch(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_patch_inputs_privacy_request_does_not_exist(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        payload,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=\"bad_privacy_request\",\n            connection_key=integration_manual_webhook_config.key,\n        )\n        auth_header = generate_auth_header([PRIVACY_REQUEST_UPLOAD_DATA])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No privacy request found with id 'bad_privacy_request'.\"\n        )\n\n    def test_patch_inputs_connection_config_does_not_exist(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        payload,\n        privacy_request_requires_input,\n    ):\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=privacy_request_requires_input.id,\n            connection_key=\"bad_connection_key\",\n        )\n        auth_header = generate_auth_header([PRIVACY_REQUEST_UPLOAD_DATA])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No connection config with key 'bad_connection_key'\"\n        )\n\n    def test_patch_inputs_manual_webhook_does_not_exist(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        payload,\n        privacy_request_requires_input,\n        integration_manual_webhook_config,\n    ):\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=privacy_request_requires_input.id,\n            connection_key=integration_manual_webhook_config.key,\n        )\n        auth_header = generate_auth_header([PRIVACY_REQUEST_UPLOAD_DATA])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No access manual webhook exists for connection config with key 'manual_webhook_example'\"\n        )\n\n    def test_supply_invalid_fields(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        payload,\n        privacy_request_requires_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_UPLOAD_DATA])\n        response = api_client.patch(\n            url, headers=auth_header, json={\"bad_field\": \"value\"}\n        )\n        assert 422 == response.status_code\n        assert response.json()[\"detail\"][0][\"msg\"] == \"extra fields not permitted\"\n\n    def test_patch_inputs_bad_privacy_request_status(\n        self,\n        api_client,\n        payload,\n        generate_auth_header,\n        privacy_request,\n        integration_manual_webhook_config,\n        access_manual_webhook,\n    ):\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=privacy_request.id,\n            connection_key=integration_manual_webhook_config.key,\n        )\n        auth_header = generate_auth_header([PRIVACY_REQUEST_UPLOAD_DATA])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert (\n            response.json()[\"detail\"]\n            == f\"Invalid access manual webhook upload request: privacy request '{privacy_request.id}' status = in_processing.\"\n        )\n\n    def test_patch_inputs_for_manual_webhook(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        payload,\n        privacy_request_requires_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_UPLOAD_DATA])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n        assert response.json() is None\n\n        assert (\n            privacy_request_requires_input.get_manual_webhook_input_strict(\n                access_manual_webhook\n            )\n            == payload\n        )\n\n\nclass TestGetManualWebhookInputs:\n    @pytest.fixture(scope=\"function\")\n    def url(\n        self,\n        db,\n        privacy_request_requires_input,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=privacy_request_requires_input.id,\n            connection_key=integration_manual_webhook_config.key,\n        )\n\n    def test_get_inputs_not_authenticated(self, api_client: TestClient, url):\n        response = api_client.get(url, headers={})\n        assert 401 == response.status_code\n\n    def test_get_inputs_wrong_scopes(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_inputs_privacy_request_does_not_exist(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n    ):\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=\"bad_privacy_request\",\n            connection_key=integration_manual_webhook_config.key,\n        )\n        auth_header = generate_auth_header([PRIVACY_REQUEST_VIEW_DATA])\n        response = api_client.get(url, headers=auth_header)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No privacy request found with id 'bad_privacy_request'.\"\n        )\n\n    def test_get_inputs_connection_config_does_not_exist(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request_requires_input,\n    ):\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=privacy_request_requires_input.id,\n            connection_key=\"bad_connection_key\",\n        )\n        auth_header = generate_auth_header([PRIVACY_REQUEST_VIEW_DATA])\n        response = api_client.get(url, headers=auth_header)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No connection config with key 'bad_connection_key'\"\n        )\n\n    def test_get_inputs_manual_webhook_does_not_exist(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        privacy_request_requires_input,\n        integration_manual_webhook_config,\n    ):\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=privacy_request_requires_input.id,\n            connection_key=integration_manual_webhook_config.key,\n        )\n        auth_header = generate_auth_header([PRIVACY_REQUEST_VIEW_DATA])\n        response = api_client.get(url, headers=auth_header)\n        assert 404 == response.status_code\n        assert (\n            response.json()[\"detail\"]\n            == \"No access manual webhook exists for connection config with key 'manual_webhook_example'\"\n        )\n\n    def test_get_inputs_bad_privacy_request_status(\n        self,\n        api_client,\n        generate_auth_header,\n        privacy_request,\n        integration_manual_webhook_config,\n        access_manual_webhook,\n    ):\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT.format(\n            privacy_request_id=privacy_request.id,\n            connection_key=integration_manual_webhook_config.key,\n        )\n        auth_header = generate_auth_header([PRIVACY_REQUEST_VIEW_DATA])\n        response = api_client.get(url, headers=auth_header)\n        assert (\n            response.json()[\"detail\"]\n            == f\"Invalid access manual webhook upload request: privacy request '{privacy_request.id}' status = in_processing.\"\n        )\n\n    def test_no_manual_webhook_data_exists(\n        self,\n        api_client,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        privacy_request_requires_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_VIEW_DATA])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n        assert response.json() == {\n            \"checked\": False,\n            \"fields\": {\"email\": None, \"last_name\": None},\n        }\n\n    def test_cached_data_extra_saved_webhook_field(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        privacy_request_requires_input,\n        cached_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_VIEW_DATA])\n\n        access_manual_webhook.fields = [\n            {\"pii_field\": \"id_no\", \"dsr_package_label\": \"id_number\"}\n        ]\n        access_manual_webhook.save(db)\n        response = api_client.get(url, headers=auth_header)\n        assert response.status_code == 200\n        assert response.json() == {\n            \"checked\": False,\n            \"fields\": {\"id_number\": None},\n        }, \"Response has checked=False, so this data needs to be re-uploaded before we can run the privacy request.\"\n\n    def test_cached_data_missing_saved_webhook_field(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        privacy_request_requires_input,\n        cached_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_VIEW_DATA])\n\n        access_manual_webhook.fields.append(\n            {\"pii_field\": \"id_no\", \"dsr_package_label\": \"id_number\"}\n        )\n        access_manual_webhook.save(db)\n        response = api_client.get(url, headers=auth_header)\n\n        assert response.status_code == 200\n        assert response.json() == {\n            \"checked\": False,\n            \"fields\": {\n                \"id_number\": None,\n                \"email\": \"customer-1@example.com\",\n                \"last_name\": \"McCustomer\",\n            },\n        }, \"Response has checked=False. A new field has been defined on the webhook, so we should re-examine to see if that is more data we need to retrieve.\"\n\n    def test_get_inputs_for_manual_webhook(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        privacy_request_requires_input,\n        cached_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_VIEW_DATA])\n        response = api_client.get(url, headers=auth_header)\n        assert 200 == response.status_code\n        assert response.json() == {\n            \"checked\": True,\n            \"fields\": {\n                \"email\": \"customer-1@example.com\",\n                \"last_name\": \"McCustomer\",\n            },\n        }\n\n\nclass TestResumePrivacyRequestFromRequiresInput:\n    @pytest.fixture(scope=\"function\")\n    def url(\n        self,\n        db,\n        privacy_request_requires_input,\n    ):\n        return V1_URL_PREFIX + PRIVACY_REQUEST_RESUME_FROM_REQUIRES_INPUT.format(\n            privacy_request_id=privacy_request_requires_input.id,\n        )\n\n    def test_resume_from_requires_input_status_not_authenticated(self, url, api_client):\n        response = api_client.post(url, headers={})\n        assert response.status_code == 401\n\n    def test_resume_from_requires_input_status_not_authorized(\n        self, url, privacy_request, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_READ])\n        response = api_client.post(url, headers=auth_header)\n        assert response.status_code == 403\n\n    def test_resume_from_requires_input_status_wrong_status(\n        self, api_client, generate_auth_header, privacy_request\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_CALLBACK_RESUME])\n        url = V1_URL_PREFIX + PRIVACY_REQUEST_RESUME_FROM_REQUIRES_INPUT.format(\n            privacy_request_id=privacy_request.id,\n        )\n        response = api_client.post(url, headers=auth_header)\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == f\"Cannot resume privacy request from 'requires_input': privacy request '{privacy_request.id}' status = {privacy_request.status.value}.\"\n        )\n\n    def test_resume_from_requires_input_status_missing_cached_data(\n        self,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        privacy_request_requires_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_CALLBACK_RESUME])\n\n        response = api_client.post(url, headers=auth_header)\n        assert response.status_code == 400\n        assert (\n            response.json()[\"detail\"]\n            == f\"Cannot resume privacy request. No data cached for privacy_request_id '{privacy_request_requires_input.id}' for connection config '{integration_manual_webhook_config.key}'\"\n        )\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_resume_from_requires_input_status_data_empty_but_confirmed(\n        self,\n        run_privacy_request_mock,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        privacy_request_requires_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_CALLBACK_RESUME])\n        privacy_request_requires_input.cache_manual_webhook_input(\n            access_manual_webhook,\n            {},\n        )\n\n        response = api_client.post(url, headers=auth_header)\n        assert 200 == response.status_code\n        assert response.json()[\"status\"] == PrivacyRequestStatus.in_processing\n        assert run_privacy_request_mock.called\n\n        call_kwargs = run_privacy_request_mock.call_args.kwargs\n        assert call_kwargs[\"privacy_request_id\"] == privacy_request_requires_input.id\n        assert call_kwargs[\"from_webhook_id\"] is None\n        assert call_kwargs[\"from_step\"] is None\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    def test_resume_from_requires_input_status(\n        self,\n        run_privacy_request_mock,\n        api_client: TestClient,\n        db,\n        url,\n        generate_auth_header,\n        access_manual_webhook,\n        integration_manual_webhook_config,\n        privacy_request_requires_input,\n        cached_input,\n    ):\n        auth_header = generate_auth_header([PRIVACY_REQUEST_CALLBACK_RESUME])\n        response = api_client.post(url, headers=auth_header)\n        assert 200 == response.status_code\n        assert response.json()[\"status\"] == PrivacyRequestStatus.in_processing\n        assert run_privacy_request_mock.called\n\n        call_kwargs = run_privacy_request_mock.call_args.kwargs\n        assert call_kwargs[\"privacy_request_id\"] == privacy_request_requires_input.id\n        assert call_kwargs[\"from_webhook_id\"] is None\n        assert call_kwargs[\"from_step\"] is None\n\n\nclass TestCreatePrivacyRequestEmailReceiptNotification:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, policy) -> str:\n        return V1_URL_PREFIX + PRIVACY_REQUESTS\n\n    @pytest.fixture(scope=\"function\")\n    def privacy_request_receipt_email_notification_enabled(self):\n        \"\"\"Enable request receipt email\"\"\"\n        original_value = config.notifications.send_request_receipt_notification\n        config.notifications.send_request_receipt_notification = True\n        yield\n        config.notifications.send_request_receipt_notification = original_value\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_create_privacy_request_no_email_config(\n        self,\n        mock_dispatch_email,\n        mock_execute_request,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n        privacy_request_receipt_email_notification_enabled,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n\n        assert mock_execute_request.called\n        assert response_data[0][\"status\"] == PrivacyRequestStatus.pending\n\n        assert mock_dispatch_email.called\n\n        call_args = mock_dispatch_email.call_args[1]\n        task_kwargs = call_args[\"kwargs\"]\n        assert task_kwargs[\"to_email\"] == \"test@example.com\"\n\n        email_meta = task_kwargs[\"email_meta\"]\n        assert email_meta[\"action_type\"] == EmailActionType.PRIVACY_REQUEST_RECEIPT\n        assert email_meta[\"body_params\"] == RequestReceiptBodyParams(\n            request_types={ActionType.access.value}\n        )\n        queue = call_args[\"queue\"]\n        assert queue == EMAIL_QUEUE_NAME\n\n        pr.delete(db=db)\n\n    @mock.patch(\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request.delay\"\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.privacy_request_endpoints.dispatch_email_task.apply_async\"\n    )\n    def test_create_privacy_request_with_email_config(\n        self,\n        mock_dispatch_email,\n        mock_execute_request,\n        url,\n        db,\n        api_client: TestClient,\n        policy,\n        email_config,\n        privacy_request_receipt_email_notification_enabled,\n    ):\n        data = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"policy_key\": policy.key,\n                \"identity\": {\"email\": \"test@example.com\"},\n            }\n        ]\n        resp = api_client.post(url, json=data)\n        assert resp.status_code == 200\n        response_data = resp.json()[\"succeeded\"]\n        assert len(response_data) == 1\n        pr = PrivacyRequest.get(db=db, object_id=response_data[0][\"id\"])\n        assert mock_execute_request.called\n\n        assert response_data[0][\"status\"] == PrivacyRequestStatus.pending\n        assert mock_dispatch_email.called\n\n        call_args = mock_dispatch_email.call_args[1]\n        task_kwargs = call_args[\"kwargs\"]\n        assert task_kwargs[\"to_email\"] == \"test@example.com\"\n\n        email_meta = task_kwargs[\"email_meta\"]\n        assert email_meta[\"action_type\"] == EmailActionType.PRIVACY_REQUEST_RECEIPT\n        assert email_meta[\"body_params\"] == RequestReceiptBodyParams(\n            request_types={ActionType.access.value}\n        )\n        queue = call_args[\"queue\"]\n        assert queue == EMAIL_QUEUE_NAME\n\n        pr.delete(db=db)\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_saas_config_endpoints.py", "content": "import json\nfrom typing import Optional\nfrom unittest import mock\nfrom unittest.mock import Mock\n\nimport pytest\nfrom sqlalchemy.orm import Session\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    CLIENT_READ,\n    CONNECTION_AUTHORIZE,\n    SAAS_CONFIG_CREATE_OR_UPDATE,\n    SAAS_CONFIG_DELETE,\n    SAAS_CONFIG_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    AUTHORIZE,\n    SAAS_CONFIG,\n    SAAS_CONFIG_VALIDATE,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom tests.ops.api.v1.endpoints.test_dataset_endpoints import _reject_key\n\n\n@pytest.mark.unit_saas\nclass TestValidateSaaSConfig:\n    @pytest.fixture\n    def validate_saas_config_url(self, saas_example_connection_config) -> str:\n        path = V1_URL_PREFIX + SAAS_CONFIG_VALIDATE\n        path_params = {\"connection_key\": saas_example_connection_config.key}\n        return path.format(**path_params)\n\n    def test_put_validate_saas_config_not_authenticated(\n        self, saas_example_config, validate_saas_config_url: str, api_client\n    ) -> None:\n        response = api_client.put(\n            validate_saas_config_url, headers={}, json=saas_example_config\n        )\n        assert response.status_code == 401\n\n    def test_put_validate_dataset_wrong_scope(\n        self,\n        saas_example_config,\n        validate_saas_config_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_CREATE_OR_UPDATE])\n        response = api_client.put(\n            validate_saas_config_url,\n            headers=auth_header,\n            json=saas_example_config,\n        )\n        assert response.status_code == 403\n\n    def test_put_validate_saas_config_missing_key(\n        self,\n        saas_example_config,\n        validate_saas_config_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        invalid_config = _reject_key(saas_example_config, \"fides_key\")\n        response = api_client.put(\n            validate_saas_config_url, headers=auth_header, json=invalid_config\n        )\n        assert response.status_code == 422\n\n        details = json.loads(response.text)[\"detail\"]\n        assert [\"body\", \"fides_key\"] in [e[\"loc\"] for e in details]\n\n    def test_put_validate_saas_config_missing_endpoints(\n        self,\n        saas_example_config,\n        validate_saas_config_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        invalid_config = _reject_key(saas_example_config, \"endpoints\")\n        response = api_client.put(\n            validate_saas_config_url, headers=auth_header, json=invalid_config\n        )\n        assert response.status_code == 422\n\n        details = json.loads(response.text)[\"detail\"]\n        assert [\"body\", \"endpoints\"] in [e[\"loc\"] for e in details]\n\n    def test_put_validate_saas_config_reference_and_identity(\n        self,\n        saas_example_config,\n        validate_saas_config_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        saas_config = saas_example_config\n        param_values = saas_config[\"endpoints\"][0][\"requests\"][\"read\"][\"param_values\"][\n            0\n        ]\n        param_values[\"identity\"] = \"email\"\n        param_values[\"references\"] = [\n            {\n                \"dataset\": \"postgres_example_test_dataset\",\n                \"field\": \"another.field\",\n                \"direction\": \"from\",\n            }\n        ]\n        response = api_client.put(\n            validate_saas_config_url, headers=auth_header, json=saas_config\n        )\n        assert response.status_code == 422\n        details = json.loads(response.text)[\"detail\"]\n        assert (\n            details[0][\"msg\"]\n            == \"Must have exactly one of 'identity', 'references', or 'connector_param'\"\n        )\n\n    def test_put_validate_saas_config_wrong_reference_direction(\n        self,\n        saas_example_config,\n        validate_saas_config_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        saas_config = saas_example_config\n        param_values = saas_config[\"endpoints\"][0][\"requests\"][\"read\"][\"param_values\"][\n            0\n        ]\n        param_values[\"references\"] = [\n            {\n                \"dataset\": \"postgres_example_test_dataset\",\n                \"field\": \"another.field\",\n                \"direction\": \"to\",\n            }\n        ]\n        response = api_client.put(\n            validate_saas_config_url, headers=auth_header, json=saas_config\n        )\n        assert response.status_code == 422\n        details = json.loads(response.text)[\"detail\"]\n        assert (\n            details[0][\"msg\"]\n            == \"References can only have a direction of 'from', found 'to'\"\n        )\n\n\n@pytest.mark.unit_saas\nclass TestPutSaaSConfig:\n    @pytest.fixture\n    def saas_config_url(self, saas_example_connection_config) -> str:\n        path = V1_URL_PREFIX + SAAS_CONFIG\n        path_params = {\"connection_key\": saas_example_connection_config.key}\n        return path.format(**path_params)\n\n    def test_patch_saas_config_not_authenticated(\n        self, saas_example_config, saas_config_url, api_client\n    ) -> None:\n        response = api_client.patch(\n            saas_config_url, headers={}, json=saas_example_config\n        )\n        assert response.status_code == 401\n\n    def test_patch_saas_config_wrong_scope(\n        self,\n        saas_example_config,\n        saas_config_url,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        response = api_client.patch(\n            saas_config_url, headers=auth_header, json=saas_example_config\n        )\n        assert response.status_code == 403\n\n    def test_patch_saas_config_invalid_connection_key(\n        self, saas_example_config, api_client: TestClient, generate_auth_header\n    ) -> None:\n        path = V1_URL_PREFIX + SAAS_CONFIG\n        path_params = {\"connection_key\": \"nonexistent_key\"}\n        saas_config_url = path.format(**path_params)\n\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            saas_config_url, headers=auth_header, json=saas_example_config\n        )\n        assert response.status_code == 404\n\n    def test_patch_saas_config_create(\n        self,\n        saas_example_connection_config_without_saas_config,\n        saas_example_config,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ) -> None:\n        path = V1_URL_PREFIX + SAAS_CONFIG\n        path_params = {\n            \"connection_key\": saas_example_connection_config_without_saas_config.key\n        }\n        saas_config_url = path.format(**path_params)\n\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            saas_config_url, headers=auth_header, json=saas_example_config\n        )\n        assert response.status_code == 200\n\n        updated_config = ConnectionConfig.get_by(\n            db=db,\n            field=\"key\",\n            value=saas_example_connection_config_without_saas_config.key,\n        )\n        db.expire(updated_config)\n        saas_config = updated_config.saas_config\n        assert saas_config is not None\n\n    def test_patch_saas_config_update(\n        self,\n        saas_example_config,\n        saas_config_url,\n        api_client: TestClient,\n        db: Session,\n        generate_auth_header,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_CREATE_OR_UPDATE])\n        saas_example_config[\"endpoints\"].pop()\n        response = api_client.patch(\n            saas_config_url, headers=auth_header, json=saas_example_config\n        )\n        assert response.status_code == 200\n\n        connection_config = ConnectionConfig.get_by(\n            db=db, field=\"key\", value=saas_example_config[\"fides_key\"]\n        )\n        saas_config = connection_config.saas_config\n        assert saas_config is not None\n        assert len(saas_config[\"endpoints\"]) == 9\n\n\ndef get_saas_config_url(connection_config: Optional[ConnectionConfig] = None) -> str:\n    \"\"\"Helper to construct the SAAS_CONFIG URL, substituting valid/invalid keys in the path\"\"\"\n    path = V1_URL_PREFIX + SAAS_CONFIG\n    connection_key = \"nonexistent_key\"\n    if connection_config:\n        connection_key = connection_config.key\n    path_params = {\"connection_key\": connection_key}\n    return path.format(**path_params)\n\n\n@pytest.mark.unit_saas\nclass TestGetSaaSConfig:\n    def test_get_saas_config_not_authenticated(\n        self,\n        saas_example_connection_config,\n        api_client: TestClient,\n    ) -> None:\n        saas_config_url = get_saas_config_url(saas_example_connection_config)\n        response = api_client.get(saas_config_url, headers={})\n        assert response.status_code == 401\n\n    def test_get_saas_config_wrong_scope(\n        self,\n        saas_example_connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        saas_config_url = get_saas_config_url(saas_example_connection_config)\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_CREATE_OR_UPDATE])\n        response = api_client.get(saas_config_url, headers=auth_header)\n        assert response.status_code == 403\n\n    def test_get_saas_config_does_not_exist(\n        self,\n        saas_example_connection_config_without_saas_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        saas_config_url = get_saas_config_url(\n            saas_example_connection_config_without_saas_config\n        )\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        response = api_client.get(saas_config_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_get_saas_config_invalid_connection_key(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        saas_config_url = get_saas_config_url(None)\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        response = api_client.get(saas_config_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_get_saas_config(\n        self,\n        saas_example_connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        saas_config_url = get_saas_config_url(saas_example_connection_config)\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        response = api_client.get(saas_config_url, headers=auth_header)\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n        assert (\n            response_body[\"fides_key\"]\n            == saas_example_connection_config.get_saas_config().fides_key\n        )\n        assert len(response_body[\"endpoints\"]) == 10\n        assert response_body[\"type\"] == \"custom\"\n\n\n@pytest.mark.unit_saas\nclass TestDeleteSaaSConfig:\n    def test_delete_saas_config_not_authenticated(\n        self, saas_example_connection_config, api_client\n    ) -> None:\n        saas_config_url = get_saas_config_url(saas_example_connection_config)\n        response = api_client.delete(saas_config_url, headers={})\n        assert response.status_code == 401\n\n    def test_delete_saas_config_wrong_scope(\n        self,\n        saas_example_connection_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        saas_config_url = get_saas_config_url(saas_example_connection_config)\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_READ])\n        response = api_client.delete(saas_config_url, headers=auth_header)\n        assert response.status_code == 403\n\n    def test_delete_saas_config_does_not_exist(\n        self,\n        saas_example_connection_config_without_saas_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        saas_config_url = get_saas_config_url(\n            saas_example_connection_config_without_saas_config\n        )\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_DELETE])\n        response = api_client.delete(saas_config_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_delete_saas_config_invalid_connection_key(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        saas_config_url = get_saas_config_url(None)\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_DELETE])\n        response = api_client.delete(saas_config_url, headers=auth_header)\n        assert response.status_code == 404\n\n    def test_delete_saas_config(\n        self,\n        db: Session,\n        saas_example_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        # Create a new connection config so we don't run into issues trying to clean up an\n        # already deleted fixture\n        fides_key = \"saas_config_for_deletion_test\"\n        saas_example_config[\"fides_key\"] = fides_key\n        config_to_delete = ConnectionConfig.create(\n            db=db,\n            data={\n                \"key\": fides_key,\n                \"name\": fides_key,\n                \"connection_type\": ConnectionType.saas,\n                \"access\": AccessLevel.read,\n                \"saas_config\": saas_example_config,\n            },\n        )\n        saas_config_url = get_saas_config_url(config_to_delete)\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_DELETE])\n        response = api_client.delete(saas_config_url, headers=auth_header)\n        assert response.status_code == 204\n\n        updated_config = ConnectionConfig.get_by(db=db, field=\"key\", value=fides_key)\n        db.expire(updated_config)\n        assert updated_config.saas_config is None\n\n    def test_delete_saas_config_with_dataset_and_secrets(\n        self,\n        saas_example_connection_config,\n        saas_example_dataset_config,\n        api_client: TestClient,\n        generate_auth_header,\n    ) -> None:\n        saas_config_url = get_saas_config_url(saas_example_connection_config)\n        auth_header = generate_auth_header(scopes=[SAAS_CONFIG_DELETE])\n        response = api_client.delete(saas_config_url, headers=auth_header)\n        assert response.status_code == 400\n\n        response_body = json.loads(response.text)\n        assert (\n            response_body[\"detail\"]\n            == f\"Must delete the dataset with fides_key '{saas_example_dataset_config.fides_key}' \"\n            \"before deleting this SaaS config. Must clear the secrets from this connection \"\n            \"config before deleting the SaaS config.\"\n        )\n\n\nclass TestAuthorizeConnection:\n    @pytest.fixture\n    def authorize_url(self, oauth2_authorization_code_connection_config) -> str:\n        path = V1_URL_PREFIX + AUTHORIZE\n        path_params = {\n            \"connection_key\": oauth2_authorization_code_connection_config.key\n        }\n        return path.format(**path_params)\n\n    def test_client_not_authenticated(self, api_client: TestClient, authorize_url):\n        response = api_client.get(authorize_url)\n        assert response.status_code == 401\n\n    def test_client_wrong_scope(\n        self, api_client: TestClient, authorize_url, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header([CLIENT_READ])\n        response = api_client.get(authorize_url, headers=auth_header)\n        assert 403 == response.status_code\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.saas_config_endpoints.OAuth2AuthorizationCodeAuthenticationStrategy.get_authorization_url\"\n    )\n    def test_get_authorize_url(\n        self,\n        authorization_url_mock: Mock,\n        api_client: TestClient,\n        authorize_url,\n        generate_auth_header,\n    ):\n        authorization_url = \"https://localhost/auth/authorize\"\n        authorization_url_mock.return_value = authorization_url\n        auth_header = generate_auth_header([CONNECTION_AUTHORIZE])\n        response = api_client.get(authorize_url, headers=auth_header)\n        assert response.ok\n        assert response.text == f'\"{authorization_url}\"'\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_storage_endpoints.py", "content": "import json\nfrom typing import Dict\nfrom unittest import mock\nfrom unittest.mock import Mock\n\nimport pytest\nfrom fastapi_pagination import Params\nfrom fideslib.models.client import ClientDetail\nfrom sqlalchemy.orm import Session\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    STORAGE_CREATE_OR_UPDATE,\n    STORAGE_DELETE,\n    STORAGE_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    STORAGE_BY_KEY,\n    STORAGE_CONFIG,\n    STORAGE_SECRETS,\n    STORAGE_UPLOAD,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.storage import StorageConfig\nfrom fidesops.ops.schemas.storage.data_upload_location_response import DataUpload\nfrom fidesops.ops.schemas.storage.storage import (\n    FileNaming,\n    ResponseFormat,\n    S3AuthMethod,\n    StorageDetails,\n    StorageSecrets,\n    StorageSecretsS3,\n    StorageType,\n)\n\nPAGE_SIZE = Params().size\n\n\nclass TestUploadData:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, privacy_request) -> str:\n        return (V1_URL_PREFIX + STORAGE_UPLOAD).format(request_id=privacy_request.id)\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self, oauth_client: ClientDetail, privacy_request) -> Dict:\n        return {\n            \"storage_key\": \"s3_destination_key\",\n            \"data\": {\n                \"email\": \"email@gmail.com\",\n                \"address\": \"123 main ST, Asheville NC\",\n                \"zip codes\": [12345, 54321],\n            },\n        }\n\n    def test_upload_data_not_authenticated(self, url, api_client: TestClient, payload):\n        response = api_client.post(url, headers={}, json=payload)\n        assert 401 == response.status_code\n\n    def test_upload_data_wrong_scope(\n        self, url, api_client: TestClient, payload, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n\n    def test_invalid_privacy_request(\n        self, api_client: TestClient, payload, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        url = (V1_URL_PREFIX + STORAGE_UPLOAD).format(request_id=\"invalid-id\")\n        response = api_client.post(url, headers=auth_header, json=payload)\n        assert 404 == response.status_code\n\n    @mock.patch(\"fidesops.ops.api.v1.endpoints.storage_endpoints.upload\")\n    def test_post_upload_data(\n        self,\n        mock_post_upload_data: Mock,\n        api_client: TestClient,\n        generate_auth_header,\n        url,\n        privacy_request,\n        payload,\n    ) -> None:\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        expected_location = f\"https://bucket.s3.amazonaws.com/{privacy_request.id}.json\"\n        mock_post_upload_data.return_value = expected_location\n\n        response = api_client.post(url, headers=auth_header, json=payload)\n        response_body = json.loads(response.text)\n\n        assert 201 == response.status_code\n        mock_post_upload_data.assert_called_with(\n            mock.ANY,\n            request_id=privacy_request.id,\n            data=payload.get(\"data\"),\n            storage_key=payload.get(\"storage_key\"),\n        )\n        assert response_body == DataUpload(location=expected_location)\n\n\nclass TestPatchStorageConfig:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + STORAGE_CONFIG\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self):\n        return [\n            {\n                \"name\": \"test destination\",\n                \"type\": StorageType.s3.value,\n                \"details\": {\n                    \"auth_method\": S3AuthMethod.SECRET_KEYS.value,\n                    \"bucket\": \"some-bucket\",\n                    \"object_name\": \"requests\",\n                    \"naming\": \"some-filename-convention-enum\",\n                    \"max_retries\": 10,\n                },\n                \"format\": \"csv\",\n            }\n        ]\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.storage_endpoints.initiate_scheduled_request_intake\"\n    )\n    def test_patch_storage_config_not_authenticated(\n        self, mock_scheduled_task, api_client: TestClient, payload, url\n    ):\n        mock_scheduled_task.return_value = None\n        response = api_client.patch(url, headers={}, json=payload)\n        assert 401 == response.status_code\n        mock_scheduled_task.assert_not_called()\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.storage_endpoints.initiate_scheduled_request_intake\"\n    )\n    def test_patch_storage_config_incorrect_scope(\n        self,\n        mock_scheduled_task,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n        mock_scheduled_task.assert_not_called()\n\n    def test_patch_storage_config_with_onetrust_format_conflict(\n        self,\n        db: Session,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ):\n        payload = [\n            {\n                \"name\": \"my test destination\",\n                \"type\": \"onetrust\",\n                \"details\": {\n                    \"service_name\": \"a-service\",\n                    \"onetrust_polling_hr\": 1,\n                    \"onetrust_polling_day_of_week\": 1,\n                },\n                \"format\": \"csv\",\n            }\n        ]\n\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"Only JSON upload format is supported for OneTrust and local storage destinations.\"\n        )\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.storage_endpoints.initiate_scheduled_request_intake\"\n    )\n    def test_patch_storage_config_with_no_key(\n        self,\n        mock_scheduled_task,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n\n        assert 200 == response.status_code\n        mock_scheduled_task.assert_called()\n        response_body = json.loads(response.text)\n\n        assert response_body[\"succeeded\"][0][\"key\"] == \"test_destination\"\n        storage_config = db.query(StorageConfig).filter_by(key=\"test_destination\")[0]\n        storage_config.delete(db)\n\n    def test_put_storage_config_with_invalid_key(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        payload[0][\"key\"] = \"*invalid-key\"\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"FidesKey must only contain alphanumeric characters, '.', '_' or '-'.\"\n        )\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.storage_endpoints.initiate_scheduled_request_intake\"\n    )\n    def test_patch_storage_configs_limits_exceeded(\n        self,\n        _,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n\n        payload = []\n        for i in range(0, 51):\n            payload.append(\n                {\n                    \"name\": f\"my test destination {i}\",\n                    \"type\": \"onetrust\",\n                    \"details\": {\n                        \"bucket\": \"some-bucket\",\n                        \"object_name\": \"requests\",\n                        \"naming\": \"some-filename-convention-enum\",\n                        \"max_retries\": 10,\n                    },\n                    \"format\": \"csv\",\n                }\n            )\n\n        auth_header = generate_auth_header(scopes=[STORAGE_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n\n        assert 422 == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"ensure this value has at most 50 items\"\n        )\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.storage_endpoints.initiate_scheduled_request_intake\"\n    )\n    def test_patch_storage_config_with_key(\n        self,\n        mock_scheduled_task,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        payload[0][\"key\"] = \"my_s3_bucket\"\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n        mock_scheduled_task.assert_called()\n\n        response_body = json.loads(response.text)\n        mock_scheduled_task.assert_called()\n        storage_config = db.query(StorageConfig).filter_by(key=\"my_s3_bucket\")[0]\n\n        expected_response = {\n            \"succeeded\": [\n                {\n                    \"name\": \"test destination\",\n                    \"type\": StorageType.s3.value,\n                    \"details\": {\n                        \"auth_method\": S3AuthMethod.SECRET_KEYS.value,\n                        \"bucket\": \"some-bucket\",\n                        \"naming\": \"some-filename-convention-enum\",\n                        \"max_retries\": 10,\n                        \"object_name\": \"requests\",\n                    },\n                    \"key\": \"my_s3_bucket\",\n                    \"format\": \"csv\",\n                }\n            ],\n            \"failed\": [],\n        }\n        assert expected_response == response_body\n        storage_config.delete(db)\n\n    @pytest.mark.parametrize(\n        \"auth_method\", [S3AuthMethod.SECRET_KEYS.value, S3AuthMethod.AUTOMATIC.value]\n    )\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.storage_endpoints.initiate_scheduled_request_intake\"\n    )\n    def test_patch_storage_config_with_different_auth_methods(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n        auth_method,\n    ):\n        payload[0][\"key\"] = \"my_s3_bucket\"\n        payload[0][\"details\"][\"auth_method\"] = auth_method\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.patch(url, headers=auth_header, json=payload)\n\n        assert 200 == response.status_code\n        response_body = json.loads(response.text)\n        storage_config = db.query(StorageConfig).filter_by(key=\"my_s3_bucket\")[0]\n        assert auth_method == response_body[\"succeeded\"][0][\"details\"][\"auth_method\"]\n        storage_config.delete(db)\n\n    @mock.patch(\n        \"fidesops.ops.api.v1.endpoints.storage_endpoints.initiate_scheduled_request_intake\"\n    )\n    def test_patch_config_response_format_not_specified(\n        self,\n        mock_scheduled_task: Mock,\n        url,\n        db: Session,\n        api_client: TestClient,\n        generate_auth_header,\n    ):\n        key = \"my_s3_upload\"\n        payload = [\n            {\n                \"key\": key,\n                \"name\": \"my-test-dest\",\n                \"type\": StorageType.s3.value,\n                \"details\": {\n                    \"auth_method\": S3AuthMethod.SECRET_KEYS.value,\n                    \"bucket\": \"some-bucket\",\n                    \"object_name\": \"requests\",\n                    \"naming\": \"some-filename-convention-enum\",\n                    \"max_retries\": 10,\n                },\n            }\n        ]\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        mock_scheduled_task.return_value = None\n\n        response = api_client.patch(url, headers=auth_header, json=payload)\n        assert response.status_code == 200\n        assert (\n            json.loads(response.text)[\"succeeded\"][0][\"format\"]\n            == ResponseFormat.json.value\n        )\n\n        # Update storage config\n        response = api_client.patch(\n            V1_URL_PREFIX + STORAGE_CONFIG, headers=auth_header, json=payload\n        )\n        assert response.status_code == 200\n        assert (\n            json.loads(response.text)[\"succeeded\"][0][\"format\"]\n            == ResponseFormat.json.value\n        )\n\n        storage_config = StorageConfig.get_by(db=db, field=\"key\", value=key)\n        storage_config.delete(db)\n\n    def test_patch_storage_config_missing_detail(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.patch(\n            url,\n            headers=auth_header,\n            json=[\n                {\n                    \"key\": \"my_s3_upload\",\n                    \"name\": \"my-test-dest\",\n                    \"type\": StorageType.s3.value,\n                    \"details\": {\n                        # \"bucket\": \"removed-from-payload\",\n                        \"auth_method\": S3AuthMethod.SECRET_KEYS.value,\n                        \"object_name\": \"some-object\",\n                        \"naming\": \"request_id\",\n                        \"max_retries\": 10,\n                    },\n                },\n            ],\n        )\n        assert response.status_code == 422\n        errors = response.json()[\"detail\"]\n        assert \"details\" in errors[0][\"loc\"]\n        assert errors[0][\"msg\"] == \"[\\\"field required ('bucket',)\\\"]\"\n\n\nclass TestPutStorageConfigSecretsS3:\n    @pytest.fixture(scope=\"function\")\n    def url(self, storage_config) -> str:\n        return (V1_URL_PREFIX + STORAGE_SECRETS).format(config_key=storage_config.key)\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self):\n        return {\n            StorageSecrets.AWS_ACCESS_KEY_ID.value: \"1345234524\",\n            StorageSecrets.AWS_SECRET_ACCESS_KEY.value: \"23451345834789\",\n        }\n\n    @pytest.fixture(scope=\"function\")\n    def onetrust_url(self, storage_config_onetrust) -> str:\n        return (V1_URL_PREFIX + STORAGE_SECRETS).format(\n            config_key=storage_config_onetrust.key\n        )\n\n    @pytest.fixture(scope=\"function\")\n    def onetrust_payload(self):\n        return {\n            StorageSecrets.ONETRUST_CLIENT_ID.value: \"1345234524\",\n            StorageSecrets.ONETRUST_CLIENT_SECRET.value: \"23451345834789\",\n            StorageSecrets.ONETRUST_HOSTNAME.value: \"a-hostname\",\n        }\n\n    def test_put_config_secrets_unauthenticated(\n        self, api_client: TestClient, payload, url\n    ):\n        response = api_client.put(url, headers={}, json=payload)\n        assert 401 == response.status_code\n\n    def test_put_config_secrets_wrong_scope(\n        self, api_client: TestClient, payload, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n\n    def test_put_config_secret_invalid_config(\n        self, api_client: TestClient, payload, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        url = (V1_URL_PREFIX + STORAGE_SECRETS).format(config_key=\"invalid_key\")\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 404 == response.status_code\n\n    def test_update_with_invalid_secrets_key(\n        self, api_client: TestClient, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.put(\n            url + \"?verify=False\", headers=auth_header, json={\"bad_key\": \"12345\"}\n        )\n\n        assert response.status_code == 400\n        assert response.json() == {\n            \"detail\": [\n                \"field required ('aws_access_key_id',)\",\n                \"field required ('aws_secret_access_key',)\",\n                \"extra fields not permitted ('bad_key',)\",\n            ]\n        }\n\n    def test_put_config_secrets_without_verifying(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n        storage_config,\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.put(\n            url + \"?verify=False\", headers=auth_header, json=payload\n        )\n        assert 200 == response.status_code\n\n        db.refresh(storage_config)\n\n        assert json.loads(response.text) == {\n            \"msg\": \"Secrets updated for StorageConfig with key: my_test_config.\",\n            \"test_status\": None,\n            \"failure_reason\": None,\n        }\n        assert (\n            storage_config.secrets[StorageSecrets.AWS_ACCESS_KEY_ID.value]\n            == \"1345234524\"\n        )\n        assert (\n            storage_config.secrets[StorageSecrets.AWS_SECRET_ACCESS_KEY.value]\n            == \"23451345834789\"\n        )\n\n    @mock.patch(\"fidesops.ops.api.v1.endpoints.storage_endpoints.secrets_are_valid\")\n    def test_put_config_secrets_and_verify(\n        self,\n        mock_valid: Mock,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n        storage_config,\n    ):\n        mock_valid.return_value = True\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n\n        db.refresh(storage_config)\n\n        assert json.loads(response.text) == {\n            \"msg\": \"Secrets updated for StorageConfig with key: my_test_config.\",\n            \"test_status\": \"succeeded\",\n            \"failure_reason\": None,\n        }\n        assert (\n            storage_config.secrets[StorageSecrets.AWS_ACCESS_KEY_ID.value]\n            == \"1345234524\"\n        )\n        assert (\n            storage_config.secrets[StorageSecrets.AWS_SECRET_ACCESS_KEY.value]\n            == \"23451345834789\"\n        )\n\n        mock_valid.reset_mock()\n        mock_valid.return_value = False\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert json.loads(response.text) == {\n            \"msg\": \"Secrets updated for StorageConfig with key: my_test_config.\",\n            \"test_status\": \"failed\",\n            \"failure_reason\": None,\n        }\n\n    @mock.patch(\n        \"fidesops.ops.service.storage.storage_authenticator_service.get_s3_session\"\n    )\n    def test_put_s3_config_secrets_and_verify(\n        self,\n        get_s3_session_mock: Mock,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n        get_s3_session_mock.assert_called_once_with(\n            S3AuthMethod.SECRET_KEYS.value,\n            {\n                \"aws_access_key_id\": payload[\"aws_access_key_id\"],\n                \"aws_secret_access_key\": payload[\"aws_secret_access_key\"],\n            },\n        )\n\n    @mock.patch(\n        \"fidesops.ops.service.storage.storage_authenticator_service.get_onetrust_access_token\"\n    )\n    def test_put_onetrust_config_secrets_and_verify(\n        self,\n        get_onetrust_access_token_mock: Mock,\n        api_client: TestClient,\n        onetrust_payload,\n        onetrust_url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.put(\n            onetrust_url, headers=auth_header, json=onetrust_payload\n        )\n        assert 200 == response.status_code\n        get_onetrust_access_token_mock.assert_called_once_with(\n            client_id=onetrust_payload[StorageSecrets.ONETRUST_CLIENT_ID.value],\n            client_secret=onetrust_payload[StorageSecrets.ONETRUST_CLIENT_SECRET.value],\n            hostname=onetrust_payload[StorageSecrets.ONETRUST_HOSTNAME.value],\n        )\n\n\nclass TestPutStorageConfigSecretsOneTrust:\n    @pytest.fixture(scope=\"function\")\n    def url(self, storage_config_onetrust) -> str:\n        return (V1_URL_PREFIX + STORAGE_SECRETS).format(\n            config_key=storage_config_onetrust.key\n        )\n\n    @pytest.fixture(scope=\"function\")\n    def payload(self):\n        return {\n            StorageSecrets.ONETRUST_CLIENT_ID.value: \"23iutby1oiur\",\n            StorageSecrets.ONETRUST_CLIENT_SECRET.value: \"23i4bty1i3urhnlw\",\n            StorageSecrets.ONETRUST_HOSTNAME.value: \"peanutbutter.onetrust\",\n        }\n\n    def test_put_config_secrets_unauthenticated(\n        self, api_client: TestClient, payload, url\n    ):\n        response = api_client.put(url, headers={}, json=payload)\n        assert 401 == response.status_code\n\n    def test_put_config_secrets_wrong_scope(\n        self, api_client: TestClient, payload, url, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 403 == response.status_code\n\n    def test_put_config_secret_invalid_config(\n        self, api_client: TestClient, payload, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        url = (V1_URL_PREFIX + STORAGE_SECRETS).format(config_key=\"invalid_key\")\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 404 == response.status_code\n\n    def test_put_config_secrets_without_verifying(\n        self,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n        storage_config_onetrust,\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.put(\n            url + \"?verify=False\", headers=auth_header, json=payload\n        )\n        assert 200 == response.status_code\n\n        db.refresh(storage_config_onetrust)\n\n        assert json.loads(response.text) == {\n            \"msg\": f\"Secrets updated for StorageConfig with key: {storage_config_onetrust.key}.\",\n            \"test_status\": None,\n            \"failure_reason\": None,\n        }\n        assert (\n            storage_config_onetrust.secrets[StorageSecrets.ONETRUST_CLIENT_ID.value]\n            == \"23iutby1oiur\"\n        )\n        assert (\n            storage_config_onetrust.secrets[StorageSecrets.ONETRUST_CLIENT_SECRET.value]\n            == \"23i4bty1i3urhnlw\"\n        )\n        assert (\n            storage_config_onetrust.secrets[StorageSecrets.ONETRUST_HOSTNAME.value]\n            == \"peanutbutter.onetrust\"\n        )\n\n    @mock.patch(\"fidesops.ops.api.v1.endpoints.storage_endpoints.secrets_are_valid\")\n    def test_put_config_secrets_and_verify(\n        self,\n        mock_valid: Mock,\n        db: Session,\n        api_client: TestClient,\n        payload,\n        url,\n        generate_auth_header,\n        storage_config_onetrust,\n    ):\n        mock_valid.return_value = True\n\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert 200 == response.status_code\n\n        db.refresh(storage_config_onetrust)\n\n        assert json.loads(response.text) == {\n            \"msg\": f\"Secrets updated for StorageConfig with key: {storage_config_onetrust.key}.\",\n            \"test_status\": \"succeeded\",\n            \"failure_reason\": None,\n        }\n        assert (\n            storage_config_onetrust.secrets[StorageSecrets.ONETRUST_CLIENT_ID.value]\n            == \"23iutby1oiur\"\n        )\n        assert (\n            storage_config_onetrust.secrets[StorageSecrets.ONETRUST_CLIENT_SECRET.value]\n            == \"23i4bty1i3urhnlw\"\n        )\n        assert (\n            storage_config_onetrust.secrets[StorageSecrets.ONETRUST_HOSTNAME.value]\n            == \"peanutbutter.onetrust\"\n        )\n\n        mock_valid.reset_mock()\n        mock_valid.return_value = False\n        response = api_client.put(url, headers=auth_header, json=payload)\n        assert json.loads(response.text) == {\n            \"msg\": f\"Secrets updated for StorageConfig with key: {storage_config_onetrust.key}.\",\n            \"test_status\": \"failed\",\n            \"failure_reason\": None,\n        }\n\n    def test_put_storage_secrets_invalid_keys(\n        self,\n        api_client: TestClient,\n        url,\n        generate_auth_header,\n    ):\n        auth_header = generate_auth_header([STORAGE_CREATE_OR_UPDATE])\n        response = api_client.put(\n            url,\n            headers=auth_header,\n            json={\n                # StorageSecrets.ONETRUST_CLIENT_ID.value: \"removed-from-payload\",\n                StorageSecrets.ONETRUST_CLIENT_SECRET.value: \"23i4bty1i3urhnlw\",\n                StorageSecrets.ONETRUST_HOSTNAME.value: \"peanutbutter.onetrust\",\n            },\n        )\n\n        assert 400 == response.status_code\n        assert response.json()[\"detail\"] == [\"field required ('onetrust_client_id',)\"]\n\n\nclass TestGetStorageConfigs:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + STORAGE_CONFIG\n\n    def test_get_configs_not_authenticated(self, api_client: TestClient, url) -> None:\n        response = api_client.get(url)\n        assert 401 == response.status_code\n\n    def test_get_configs_wrong_scope(\n        self, api_client: TestClient, url, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header([STORAGE_DELETE])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_configs(\n        self, db, api_client: TestClient, url, generate_auth_header, storage_config\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.get(V1_URL_PREFIX + STORAGE_CONFIG, headers=auth_header)\n        assert 200 == response.status_code\n\n        expected_response = {\n            \"items\": [\n                {\n                    \"key\": \"my_test_config\",\n                    \"name\": storage_config.name,\n                    \"type\": storage_config.type.value,\n                    \"details\": {\n                        \"auth_method\": S3AuthMethod.SECRET_KEYS.value,\n                        \"bucket\": \"test_bucket\",\n                        \"naming\": \"request_id\",\n                    },\n                    \"format\": \"json\",\n                }\n            ],\n            \"page\": 1,\n            \"size\": PAGE_SIZE,\n            \"total\": 1,\n        }\n        response_body = json.loads(response.text)\n        assert expected_response == response_body\n\n\nclass TestGetStorageConfig:\n    @pytest.fixture(scope=\"function\")\n    def url(self, storage_config) -> str:\n        return (V1_URL_PREFIX + STORAGE_BY_KEY).format(config_key=storage_config.key)\n\n    def test_get_config_not_authenticated(self, url, api_client: TestClient):\n        response = api_client.get(url)\n        assert 401 == response.status_code\n\n    def test_get_config_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_DELETE])\n        response = api_client.get(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_get_config_invalid(\n        self, api_client: TestClient, generate_auth_header, storage_config\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.get(\n            (V1_URL_PREFIX + STORAGE_BY_KEY).format(config_key=\"invalid\"),\n            headers=auth_header,\n        )\n        assert 404 == response.status_code\n\n    def test_get_config(\n        self, url, api_client: TestClient, generate_auth_header, storage_config\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.get(url, headers=auth_header)\n        assert response.status_code == 200\n\n        response_body = json.loads(response.text)\n\n        assert response_body == {\n            \"name\": storage_config.name,\n            \"type\": StorageType.s3.value,\n            \"details\": {\n                \"auth_method\": S3AuthMethod.SECRET_KEYS.value,\n                \"bucket\": \"test_bucket\",\n                \"naming\": \"request_id\",\n            },\n            \"key\": \"my_test_config\",\n            \"format\": \"json\",\n        }\n\n\nclass TestDeleteConfig:\n    @pytest.fixture(scope=\"function\")\n    def url(self, storage_config) -> str:\n        return (V1_URL_PREFIX + STORAGE_BY_KEY).format(config_key=storage_config.key)\n\n    def test_delete_config_not_authenticated(self, url, api_client: TestClient):\n        response = api_client.delete(url)\n        assert 401 == response.status_code\n\n    def test_delete_config_wrong_scope(\n        self, url, api_client: TestClient, generate_auth_header\n    ):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.delete(url, headers=auth_header)\n        assert 403 == response.status_code\n\n    def test_delete_config_invalid(\n        self, api_client: TestClient, generate_auth_header, storage_config\n    ):\n        auth_header = generate_auth_header([STORAGE_DELETE])\n        response = api_client.delete(\n            (V1_URL_PREFIX + STORAGE_BY_KEY).format(config_key=\"invalid\"),\n            headers=auth_header,\n        )\n        assert 404 == response.status_code\n\n    def test_delete_config(\n        self,\n        db: Session,\n        url,\n        api_client: TestClient,\n        generate_auth_header,\n    ):\n        # Creating new config, so we don't run into issues trying to clean up a deleted fixture\n        storage_config = StorageConfig.create(\n            db=db,\n            data={\n                \"name\": \"My S3 Storage\",\n                \"type\": StorageType.s3,\n                \"details\": {\n                    StorageDetails.NAMING.value: FileNaming.request_id.value,\n                    StorageDetails.BUCKET.value: \"test_bucket\",\n                },\n                \"key\": \"my_storage_config\",\n                \"format\": ResponseFormat.json,\n            },\n        )\n        url = (V1_URL_PREFIX + STORAGE_BY_KEY).format(config_key=storage_config.key)\n        auth_header = generate_auth_header([STORAGE_DELETE])\n        response = api_client.delete(url, headers=auth_header)\n        assert response.status_code == 204\n\n        db.expunge_all()\n        config = db.query(StorageConfig).filter_by(key=storage_config.key).first()\n        assert config is None\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_user_endpoints.py", "content": "import json\nfrom datetime import datetime, timedelta\nfrom typing import List\n\nimport pytest\nfrom fastapi_pagination import Params\nfrom fideslib.cryptography.cryptographic_util import str_to_b64_str\nfrom fideslib.cryptography.schemas.jwt import (\n    JWE_ISSUED_AT,\n    JWE_PAYLOAD_CLIENT_ID,\n    JWE_PAYLOAD_SCOPES,\n)\nfrom fideslib.models.client import ADMIN_UI_ROOT, ClientDetail\nfrom fideslib.models.fides_user import FidesUser\nfrom fideslib.models.fides_user_permissions import FidesUserPermissions\nfrom fideslib.oauth.jwt import generate_jwe\nfrom fideslib.oauth.oauth_util import extract_payload\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_201_CREATED,\n    HTTP_204_NO_CONTENT,\n    HTTP_400_BAD_REQUEST,\n    HTTP_401_UNAUTHORIZED,\n    HTTP_403_FORBIDDEN,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    PRIVACY_REQUEST_READ,\n    SCOPE_REGISTRY,\n    STORAGE_READ,\n    USER_CREATE,\n    USER_DELETE,\n    USER_PASSWORD_RESET,\n    USER_READ,\n    USER_UPDATE,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    LOGIN,\n    LOGOUT,\n    USER_DETAIL,\n    USERS,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.core.config import config\nfrom tests.ops.conftest import generate_auth_header_for_user\n\npage_size = Params().size\n\n\nclass TestCreateUser:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + USERS\n\n    def test_create_user_not_authenticated(self, url, api_client):\n        response = api_client.post(url, headers={}, json={})\n        assert HTTP_401_UNAUTHORIZED == response.status_code\n\n    def test_create_user_wrong_scope(self, url, api_client, generate_auth_header):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.post(url, headers=auth_header, json={})\n        assert HTTP_403_FORBIDDEN == response.status_code\n\n    def test_create_user_bad_username(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header([USER_CREATE])\n        body = {\n            \"username\": \"spaces in name\",\n            \"password\": str_to_b64_str(\"TestP@ssword9\"),\n        }\n\n        response = api_client.post(url, headers=auth_header, json=body)\n        assert HTTP_422_UNPROCESSABLE_ENTITY == response.status_code\n\n    def test_username_exists(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header([USER_CREATE])\n\n        body = {\"username\": \"test_user\", \"password\": str_to_b64_str(\"TestP@ssword9\")}\n        user = FidesUser.create(db=db, data=body)\n\n        response = api_client.post(url, headers=auth_header, json=body)\n        response_body = json.loads(response.text)\n        assert response_body[\"detail\"] == \"Username already exists.\"\n        assert HTTP_400_BAD_REQUEST == response.status_code\n\n        user.delete(db)\n\n    def test_create_user_bad_password(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header([USER_CREATE])\n\n        body = {\"username\": \"test_user\", \"password\": str_to_b64_str(\"short\")}\n        response = api_client.post(url, headers=auth_header, json=body)\n        assert HTTP_422_UNPROCESSABLE_ENTITY == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"Password must have at least eight characters.\"\n        )\n\n        body = {\"username\": \"test_user\", \"password\": str_to_b64_str(\"longerpassword\")}\n        response = api_client.post(url, headers=auth_header, json=body)\n        assert HTTP_422_UNPROCESSABLE_ENTITY == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"Password must have at least one number.\"\n        )\n\n        body = {\"username\": \"test_user\", \"password\": str_to_b64_str(\"longer55password\")}\n        response = api_client.post(url, headers=auth_header, json=body)\n        assert HTTP_422_UNPROCESSABLE_ENTITY == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"Password must have at least one capital letter.\"\n        )\n\n        body = {\"username\": \"test_user\", \"password\": str_to_b64_str(\"LoNgEr55paSSworD\")}\n        response = api_client.post(url, headers=auth_header, json=body)\n        assert HTTP_422_UNPROCESSABLE_ENTITY == response.status_code\n        assert (\n            json.loads(response.text)[\"detail\"][0][\"msg\"]\n            == \"Password must have at least one symbol.\"\n        )\n\n    def test_create_user(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header([USER_CREATE])\n        body = {\"username\": \"test_user\", \"password\": str_to_b64_str(\"TestP@ssword9\")}\n\n        response = api_client.post(url, headers=auth_header, json=body)\n\n        user = FidesUser.get_by(db, field=\"username\", value=body[\"username\"])\n        response_body = json.loads(response.text)\n        assert HTTP_201_CREATED == response.status_code\n        assert response_body == {\"id\": user.id}\n        assert user.permissions is not None\n        user.delete(db)\n\n    def test_create_user_with_name(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header([USER_CREATE])\n        body = {\n            \"username\": \"test_user\",\n            \"password\": str_to_b64_str(\"TestP@ssword9\"),\n            \"first_name\": \"Test\",\n            \"last_name\": \"User\",\n        }\n\n        response = api_client.post(url, headers=auth_header, json=body)\n\n        user = FidesUser.get_by(db, field=\"username\", value=body[\"username\"])\n        response_body = json.loads(response.text)\n        assert HTTP_201_CREATED == response.status_code\n        assert response_body == {\"id\": user.id}\n        assert user.permissions is not None\n        user.delete(db)\n\n\nclass TestDeleteUser:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail, user) -> str:\n        return f\"{V1_URL_PREFIX}{USERS}/{user.id}\"\n\n    def test_delete_user_not_authenticated(self, url, api_client):\n        response = api_client.delete(url, headers={})\n        assert HTTP_401_UNAUTHORIZED == response.status_code\n\n    def test_create_user_wrong_scope(self, url, api_client, generate_auth_header, db):\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.delete(url, headers=auth_header)\n        assert HTTP_403_FORBIDDEN == response.status_code\n\n    def test_delete_user_not_admin_root_or_self(\n        self, url, api_client, db, generate_auth_header, user\n    ):\n        auth_header = generate_auth_header([USER_DELETE])\n        response = api_client.delete(url, headers=auth_header)\n        assert HTTP_403_FORBIDDEN == response.status_code\n\n    def test_delete_nonexistent_user(self, api_client, db, generate_auth_header, user):\n        auth_header = generate_auth_header([USER_DELETE])\n        url = f\"{V1_URL_PREFIX}{USERS}/nonexistent_user\"\n        response = api_client.delete(url, headers=auth_header)\n        assert HTTP_404_NOT_FOUND == response.status_code\n\n    def test_delete_self(self, api_client, db, generate_auth_header):\n        user = FidesUser.create(\n            db=db,\n            data={\n                \"username\": \"test_delete_user\",\n                \"password\": str_to_b64_str(\"TESTdcnG@wzJeu0&%3Qe2fGo7\"),\n            },\n        )\n        saved_user_id = user.id\n\n        FidesUserPermissions.create(\n            db=db, data={\"user_id\": user.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        )\n\n        assert user.permissions is not None\n        saved_permissions_id = user.permissions.id\n\n        client, _ = ClientDetail.create_client_and_secret(\n            db,\n            config.security.oauth_client_id_length_bytes,\n            config.security.oauth_client_secret_length_bytes,\n            scopes=[USER_DELETE],\n            user_id=user.id,\n        )\n        assert client.user == user\n        saved_client_id = client.id\n\n        payload = {\n            JWE_PAYLOAD_SCOPES: [USER_DELETE],\n            JWE_PAYLOAD_CLIENT_ID: client.id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        jwe = generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        auth_header = {\"Authorization\": \"Bearer \" + jwe}\n\n        response = api_client.delete(\n            f\"{V1_URL_PREFIX}{USERS}/{user.id}\", headers=auth_header\n        )\n        assert HTTP_204_NO_CONTENT == response.status_code\n\n        db.expunge_all()\n\n        user_search = FidesUser.get_by(db, field=\"id\", value=saved_user_id)\n        assert user_search is None\n\n        client_search = ClientDetail.get_by(db, field=\"id\", value=saved_client_id)\n        assert client_search is None\n\n        permissions_search = FidesUserPermissions.get_by(\n            db, field=\"id\", value=saved_permissions_id\n        )\n        assert permissions_search is None\n\n    def test_delete_user_as_root(self, api_client, db, generate_auth_header, user):\n        other_user = FidesUser.create(\n            db=db,\n            data={\n                \"username\": \"test_delete_user\",\n                \"password\": str_to_b64_str(\"TESTdcnG@wzJeu0&%3Qe2fGo7\"),\n            },\n        )\n\n        FidesUserPermissions.create(\n            db=db, data={\"user_id\": other_user.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        )\n\n        user_client, _ = ClientDetail.create_client_and_secret(\n            db,\n            config.security.oauth_client_id_length_bytes,\n            config.security.oauth_client_secret_length_bytes,\n            scopes=[USER_DELETE],\n            user_id=other_user.id,\n        )\n        client_id = user_client.id\n        saved_user_id = other_user.id\n        saved_permission_id = other_user.permissions.id\n\n        # Temporarily set the user's client to be the Admin UI Root client\n        client = user.client\n        client.fides_key = ADMIN_UI_ROOT\n        client.save(db)\n\n        payload = {\n            JWE_PAYLOAD_SCOPES: [USER_DELETE],\n            JWE_PAYLOAD_CLIENT_ID: user.client.id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        jwe = generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        auth_header = {\"Authorization\": \"Bearer \" + jwe}\n\n        response = api_client.delete(\n            f\"{V1_URL_PREFIX}{USERS}/{other_user.id}\", headers=auth_header\n        )\n        assert HTTP_204_NO_CONTENT == response.status_code\n\n        db.expunge_all()\n\n        user_search = FidesUser.get_by(db, field=\"id\", value=saved_user_id)\n        assert user_search is None\n\n        # Deleted user's client is also deleted\n        client_search = ClientDetail.get_by(db, field=\"id\", value=client_id)\n        assert client_search is None\n\n        permissions_search = FidesUserPermissions.get_by(\n            db, field=\"id\", value=saved_permission_id\n        )\n        assert permissions_search is None\n\n        # Deleted user's client is also deleted\n        client_search = ClientDetail.get_by(db, field=\"id\", value=client_id)\n        assert client_search is None\n\n        # Admin client who made the request is not deleted\n        admin_client_search = ClientDetail.get_by(db, field=\"id\", value=user.client.id)\n        assert admin_client_search is not None\n        admin_client_search.delete(db)\n\n\nclass TestGetUsers:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + USERS\n\n    def test_get_users_not_authenticated(\n        self, api_client: TestClient, url: str\n    ) -> None:\n        resp = api_client.get(url, headers={})\n        assert resp.status_code == HTTP_401_UNAUTHORIZED\n\n    def test_get_users_wrong_scope(\n        self, api_client: TestClient, generate_auth_header, url\n    ):\n        auth_header = generate_auth_header(scopes=[USER_DELETE])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == HTTP_403_FORBIDDEN\n\n    def test_get_users_no_users(\n        self, api_client: TestClient, generate_auth_header, url\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[USER_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == HTTP_200_OK\n        response_body = json.loads(resp.text)\n        assert len(response_body[\"items\"]) == 0\n        assert response_body[\"total\"] == 0\n        assert response_body[\"page\"] == 1\n        assert response_body[\"size\"] == page_size\n\n    def test_get_users(self, api_client: TestClient, generate_auth_header, url, db):\n        create_auth_header = generate_auth_header(scopes=[USER_CREATE])\n        saved_users: List[FidesUser] = []\n        total_users = 25\n        for i in range(total_users):\n            body = {\n                \"username\": f\"user{i}@example.com\",\n                \"password\": str_to_b64_str(\"Password123!\"),\n                \"first_name\": \"Test\",\n                \"last_name\": \"User\",\n            }\n            resp = api_client.post(url, headers=create_auth_header, json=body)\n            assert resp.status_code == HTTP_201_CREATED\n            user = FidesUser.get_by(db, field=\"username\", value=body[\"username\"])\n            saved_users.append(user)\n\n        get_auth_header = generate_auth_header(scopes=[USER_READ])\n        resp = api_client.get(url, headers=get_auth_header)\n        assert resp.status_code == HTTP_200_OK\n        response_body = json.loads(resp.text)\n        assert len(response_body[\"items\"]) == total_users\n        assert response_body[\"total\"] == total_users\n        assert response_body[\"page\"] == 1\n        assert response_body[\"size\"] == page_size\n\n        user_data = response_body[\"items\"][0]\n        assert user_data[\"username\"]\n        assert user_data[\"id\"]\n        assert user_data[\"created_at\"]\n        assert user_data[\"first_name\"]\n        assert user_data[\"last_name\"]\n\n        for i in range(total_users):\n            saved_users[i].delete(db)\n\n    def test_get_filtered_users(\n        self, api_client: TestClient, generate_auth_header, url, db\n    ):\n        create_auth_header = generate_auth_header(scopes=[USER_CREATE])\n        saved_users: List[FidesUser] = []\n        total_users = 50\n        for i in range(total_users):\n            body = {\n                \"username\": f\"user{i}@example.com\",\n                \"password\": str_to_b64_str(\"Password123!\"),\n            }\n            resp = api_client.post(url, headers=create_auth_header, json=body)\n            assert resp.status_code == HTTP_201_CREATED\n            user = FidesUser.get_by(db, field=\"username\", value=body[\"username\"])\n            saved_users.append(user)\n\n        get_auth_header = generate_auth_header(scopes=[USER_READ])\n\n        resp = api_client.get(f\"{url}?username={15}\", headers=get_auth_header)\n        assert resp.status_code == HTTP_200_OK\n        response_body = json.loads(resp.text)\n        assert len(response_body[\"items\"]) == 1\n        assert response_body[\"total\"] == 1\n        assert response_body[\"page\"] == 1\n        assert response_body[\"size\"] == page_size\n\n        resp = api_client.get(f\"{url}?username={5}\", headers=get_auth_header)\n        assert resp.status_code == HTTP_200_OK\n        response_body = json.loads(resp.text)\n        assert len(response_body[\"items\"]) == 5\n        assert response_body[\"total\"] == 5\n        assert response_body[\"page\"] == 1\n        assert response_body[\"size\"] == page_size\n\n        resp = api_client.get(f\"{url}?username=not real user\", headers=get_auth_header)\n        assert resp.status_code == HTTP_200_OK\n        response_body = json.loads(resp.text)\n        assert len(response_body[\"items\"]) == 0\n        assert response_body[\"total\"] == 0\n        assert response_body[\"page\"] == 1\n        assert response_body[\"size\"] == page_size\n\n        for i in range(total_users):\n            saved_users[i].delete(db)\n\n\nclass TestGetUser:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + USER_DETAIL\n\n    @pytest.fixture(scope=\"function\")\n    def url_no_id(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + USERS\n\n    def test_get_user_not_authenticated(self, api_client: TestClient, url: str) -> None:\n        resp = api_client.get(url, headers={})\n        assert resp.status_code == HTTP_401_UNAUTHORIZED\n\n    def test_get_user_wrong_scope(\n        self, api_client: TestClient, generate_auth_header, url: str\n    ):\n        auth_header = generate_auth_header(scopes=[USER_DELETE])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == HTTP_403_FORBIDDEN\n\n    def test_get_user_does_not_exist(\n        self, api_client: TestClient, generate_auth_header, url_no_id: str\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[USER_READ])\n        resp = api_client.get(\n            f\"{url_no_id}/this_is_a_nonexistent_key\",\n            headers=auth_header,\n        )\n        assert resp.status_code == HTTP_404_NOT_FOUND\n\n    def test_get_user(\n        self,\n        api_client: TestClient,\n        generate_auth_header,\n        url_no_id: str,\n        application_user,\n    ) -> None:\n        auth_header = generate_auth_header(scopes=[USER_READ])\n        resp = api_client.get(\n            f\"{url_no_id}/{application_user.id}\",\n            headers=auth_header,\n        )\n        assert resp.status_code == HTTP_200_OK\n        user_data = resp.json()\n        assert user_data[\"username\"] == application_user.username\n        assert user_data[\"id\"] == application_user.id\n        assert user_data[\"created_at\"] == application_user.created_at.isoformat()\n        assert user_data[\"first_name\"] == application_user.first_name\n        assert user_data[\"last_name\"] == application_user.last_name\n\n\nclass TestUpdateUser:\n    @pytest.fixture(scope=\"function\")\n    def url_no_id(self) -> str:\n        return V1_URL_PREFIX + USERS\n\n    def test_update_different_users_names(\n        self,\n        api_client,\n        url_no_id,\n        user,\n        application_user,\n    ) -> None:\n        NEW_FIRST_NAME = \"another\"\n        NEW_LAST_NAME = \"name\"\n\n        auth_header = generate_auth_header_for_user(\n            user=application_user,\n            scopes=[USER_UPDATE],\n        )\n        resp = api_client.put(\n            f\"{url_no_id}/{user.id}\",\n            headers=auth_header,\n            json={\n                \"first_name\": NEW_FIRST_NAME,\n                \"last_name\": NEW_LAST_NAME,\n            },\n        )\n        assert resp.status_code == HTTP_200_OK\n        user_data = resp.json()\n        assert user_data[\"username\"] == user.username\n        assert user_data[\"id\"] == user.id\n        assert user_data[\"created_at\"] == user.created_at.isoformat()\n        assert user_data[\"first_name\"] == NEW_FIRST_NAME\n        assert user_data[\"last_name\"] == NEW_LAST_NAME\n\n    def test_update_user_names(\n        self,\n        api_client,\n        url_no_id,\n        application_user,\n    ) -> None:\n        NEW_FIRST_NAME = \"another\"\n        NEW_LAST_NAME = \"name\"\n\n        auth_header = generate_auth_header_for_user(\n            user=application_user,\n            scopes=[USER_UPDATE],\n        )\n        resp = api_client.put(\n            f\"{url_no_id}/{application_user.id}\",\n            headers=auth_header,\n            json={\n                \"first_name\": NEW_FIRST_NAME,\n                \"last_name\": NEW_LAST_NAME,\n            },\n        )\n        assert resp.status_code == HTTP_200_OK\n        user_data = resp.json()\n        assert user_data[\"username\"] == application_user.username\n        assert user_data[\"id\"] == application_user.id\n        assert user_data[\"created_at\"] == application_user.created_at.isoformat()\n        assert user_data[\"first_name\"] == NEW_FIRST_NAME\n        assert user_data[\"last_name\"] == NEW_LAST_NAME\n\n\nclass TestUpdateUserPassword:\n    @pytest.fixture(scope=\"function\")\n    def url_no_id(self) -> str:\n        return V1_URL_PREFIX + USERS\n\n    def test_update_different_user_password(\n        self,\n        api_client,\n        db,\n        url_no_id,\n        user,\n        application_user,\n    ) -> None:\n        OLD_PASSWORD = \"oldpassword\"\n        NEW_PASSWORD = \"newpassword\"\n        application_user.update_password(db=db, new_password=OLD_PASSWORD)\n\n        auth_header = generate_auth_header_for_user(\n            user=application_user,\n            scopes=[USER_PASSWORD_RESET],\n        )\n        resp = api_client.post(\n            f\"{url_no_id}/{user.id}/reset-password\",\n            headers=auth_header,\n            json={\n                \"old_password\": str_to_b64_str(OLD_PASSWORD),\n                \"new_password\": str_to_b64_str(NEW_PASSWORD),\n            },\n        )\n        assert resp.status_code == HTTP_401_UNAUTHORIZED\n        assert (\n            resp.json()[\"detail\"]\n            == \"You are only authorised to update your own user data.\"\n        )\n\n        db.expunge(application_user)\n        application_user = application_user.refresh_from_db(db=db)\n        assert application_user.credentials_valid(password=OLD_PASSWORD)\n\n    def test_update_user_password_invalid(\n        self,\n        api_client,\n        db,\n        url_no_id,\n        application_user,\n    ) -> None:\n        OLD_PASSWORD = \"oldpassword\"\n        NEW_PASSWORD = \"newpassword\"\n        application_user.update_password(db=db, new_password=OLD_PASSWORD)\n\n        auth_header = generate_auth_header_for_user(\n            user=application_user,\n            scopes=[USER_PASSWORD_RESET],\n        )\n        resp = api_client.post(\n            f\"{url_no_id}/{application_user.id}/reset-password\",\n            headers=auth_header,\n            json={\n                \"old_password\": str_to_b64_str(\"mismatching password\"),\n                \"new_password\": str_to_b64_str(NEW_PASSWORD),\n            },\n        )\n        assert resp.status_code == HTTP_401_UNAUTHORIZED\n        assert resp.json()[\"detail\"] == \"Incorrect password.\"\n\n        db.expunge(application_user)\n        application_user = application_user.refresh_from_db(db=db)\n        assert application_user.credentials_valid(password=OLD_PASSWORD)\n\n    def test_update_user_password(\n        self,\n        api_client,\n        db,\n        url_no_id,\n        application_user,\n    ) -> None:\n        OLD_PASSWORD = \"oldpassword\"\n        NEW_PASSWORD = \"newpassword\"\n        application_user.update_password(db=db, new_password=OLD_PASSWORD)\n        auth_header = generate_auth_header_for_user(\n            user=application_user,\n            scopes=[USER_PASSWORD_RESET],\n        )\n        resp = api_client.post(\n            f\"{url_no_id}/{application_user.id}/reset-password\",\n            headers=auth_header,\n            json={\n                \"old_password\": str_to_b64_str(OLD_PASSWORD),\n                \"new_password\": str_to_b64_str(NEW_PASSWORD),\n            },\n        )\n        assert resp.status_code == HTTP_200_OK\n        db.expunge(application_user)\n        application_user = application_user.refresh_from_db(db=db)\n        assert application_user.credentials_valid(password=NEW_PASSWORD)\n\n\nclass TestUserLogin:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + LOGIN\n\n    def test_user_does_not_exist(self, db, url, api_client):\n        body = {\n            \"username\": \"does not exist\",\n            \"password\": str_to_b64_str(\"idonotknowmypassword\"),\n        }\n        response = api_client.post(url, headers={}, json=body)\n        assert response.status_code == HTTP_404_NOT_FOUND\n\n    def test_bad_login(self, db, url, user, api_client):\n        body = {\n            \"username\": user.username,\n            \"password\": str_to_b64_str(\"idonotknowmypassword\"),\n        }\n        response = api_client.post(url, headers={}, json=body)\n        assert response.status_code == HTTP_403_FORBIDDEN\n\n    def test_login_creates_client(self, db, url, user, api_client):\n        # Delete existing client for test purposes\n        user.client.delete(db)\n        body = {\n            \"username\": user.username,\n            \"password\": str_to_b64_str(\"TESTdcnG@wzJeu0&%3Qe2fGo7\"),\n        }\n\n        assert user.client is None  # client does not exist\n        assert user.permissions is not None\n        response = api_client.post(url, headers={}, json=body)\n        assert response.status_code == HTTP_200_OK\n\n        db.refresh(user)\n        assert user.client is not None\n        assert \"token_data\" in list(response.json().keys())\n        token = response.json()[\"token_data\"][\"access_token\"]\n        token_data = json.loads(\n            extract_payload(token, config.security.app_encryption_key)\n        )\n        assert token_data[\"client-id\"] == user.client.id\n        assert token_data[\"scopes\"] == [\n            PRIVACY_REQUEST_READ\n        ]  # Uses scopes on existing client\n\n        assert \"user_data\" in list(response.json().keys())\n        assert response.json()[\"user_data\"][\"id\"] == user.id\n\n        user.client.delete(db)\n\n    def test_login_updates_last_login_date(self, db, url, user, api_client):\n        body = {\n            \"username\": user.username,\n            \"password\": str_to_b64_str(\"TESTdcnG@wzJeu0&%3Qe2fGo7\"),\n        }\n\n        response = api_client.post(url, headers={}, json=body)\n        assert response.status_code == HTTP_200_OK\n\n        db.refresh(user)\n        assert user.last_login_at is not None\n\n    def test_login_uses_existing_client(self, db, url, user, api_client):\n        body = {\n            \"username\": user.username,\n            \"password\": str_to_b64_str(\"TESTdcnG@wzJeu0&%3Qe2fGo7\"),\n        }\n\n        existing_client_id = user.client.id\n        user.client.scopes = [PRIVACY_REQUEST_READ]\n        user.client.save(db)\n        response = api_client.post(url, headers={}, json=body)\n        assert response.status_code == HTTP_200_OK\n\n        db.refresh(user)\n        assert user.client is not None\n        assert \"token_data\" in list(response.json().keys())\n        token = response.json()[\"token_data\"][\"access_token\"]\n        token_data = json.loads(\n            extract_payload(token, config.security.app_encryption_key)\n        )\n        assert token_data[\"client-id\"] == existing_client_id\n        assert token_data[\"scopes\"] == [\n            PRIVACY_REQUEST_READ\n        ]  # Uses scopes on existing client\n\n        assert \"user_data\" in list(response.json().keys())\n        assert response.json()[\"user_data\"][\"id\"] == user.id\n\n\nclass TestUserLogout:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + LOGOUT\n\n    def test_malformed_token_ignored(self, db, url, api_client, user):\n        auth_header = {\"Authorization\": \"Bearer invalid\"}\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == HTTP_204_NO_CONTENT\n\n    def test_user_can_logout_with_expired_token(self, db, url, api_client, user):\n        client_id = user.client.id\n        scopes = user.client.scopes\n\n        payload = {\n            JWE_PAYLOAD_SCOPES: scopes,\n            JWE_PAYLOAD_CLIENT_ID: client_id,\n            JWE_ISSUED_AT: (datetime.now() - timedelta(days=360)).isoformat(),\n        }\n\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == HTTP_204_NO_CONTENT\n\n        # Verify client was deleted\n        client_search = ClientDetail.get_by(db, field=\"id\", value=client_id)\n        assert client_search is None\n\n    def test_root_user_logout(self, db, url, api_client):\n        payload = {\n            JWE_PAYLOAD_SCOPES: SCOPE_REGISTRY,\n            JWE_PAYLOAD_CLIENT_ID: config.security.oauth_root_client_id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == HTTP_204_NO_CONTENT\n\n    def test_user_not_deleted_on_logout(self, db, url, api_client, user):\n        user_id = user.id\n        client_id = user.client.id\n        scopes = user.client.scopes\n\n        payload = {\n            JWE_PAYLOAD_SCOPES: scopes,\n            JWE_PAYLOAD_CLIENT_ID: client_id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == HTTP_204_NO_CONTENT\n\n        # Verify client was deleted\n        client_search = ClientDetail.get_by(db, field=\"id\", value=client_id)\n        assert client_search is None\n\n        # Assert user is not deleted\n        user_search = FidesUser.get_by(db, field=\"id\", value=user_id)\n        db.refresh(user_search)\n        assert user_search is not None\n\n        # Assert user permissions are not deleted\n        permission_search = FidesUserPermissions.get_by(\n            db, field=\"user_id\", value=user_id\n        )\n        assert permission_search is not None\n\n        # Assert user does not still have client reference\n        assert user_search.client is None\n\n        # Outdated client token logout gives a 204\n        payload = {\n            JWE_PAYLOAD_SCOPES: scopes,\n            JWE_PAYLOAD_CLIENT_ID: client_id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        auth_header = {\n            \"Authorization\": \"Bearer \"\n            + generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        }\n        response = api_client.post(url, headers=auth_header, json={})\n        assert HTTP_204_NO_CONTENT == response.status_code\n\n    def test_logout(self, db, url, api_client, generate_auth_header, oauth_client):\n        oauth_client_id = oauth_client.id\n        auth_header = generate_auth_header([STORAGE_READ])\n        response = api_client.post(url, headers=auth_header, json={})\n        assert HTTP_204_NO_CONTENT == response.status_code\n\n        # Verify client was deleted\n        client_search = ClientDetail.get_by(db, field=\"id\", value=oauth_client_id)\n        assert client_search is None\n\n        # Even though client doesn't exist, we still return a 204\n        response = api_client.post(url, headers=auth_header, json={})\n        assert response.status_code == HTTP_204_NO_CONTENT\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_user_permission_endpoints.py", "content": "import json\n\nimport pytest\nfrom fideslib.models.client import ClientDetail\nfrom fideslib.models.fides_user import FidesUser\nfrom fideslib.models.fides_user_permissions import FidesUserPermissions\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_201_CREATED,\n    HTTP_401_UNAUTHORIZED,\n    HTTP_403_FORBIDDEN,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    PRIVACY_REQUEST_READ,\n    SAAS_CONFIG_READ,\n    USER_PERMISSION_CREATE,\n    USER_PERMISSION_READ,\n    USER_PERMISSION_UPDATE,\n)\nfrom fidesops.ops.api.v1.urn_registry import USER_PERMISSIONS, V1_URL_PREFIX\nfrom fidesops.ops.core.config import config\n\n\nclass TestCreateUserPermissions:\n    @pytest.fixture(scope=\"function\")\n    def url(self) -> str:\n        return V1_URL_PREFIX + USER_PERMISSIONS\n\n    def test_create_user_permissions_not_authenticated(self, url, api_client):\n        response = api_client.post(url, headers={}, json={})\n        assert HTTP_401_UNAUTHORIZED == response.status_code\n\n    def test_create_user_permissions_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header([SAAS_CONFIG_READ])\n        response = api_client.post(url, headers=auth_header, json={})\n        assert HTTP_403_FORBIDDEN == response.status_code\n\n    def test_create_user_permissions_invalid_scope(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        user,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header([USER_PERMISSION_CREATE])\n        user = FidesUser.create(\n            db=db,\n            data={\"username\": \"user_1\", \"password\": \"test_password\"},\n        )\n\n        body = {\"user_id\": user.id, \"scopes\": [\"not a real scope\"]}\n\n        response = api_client.post(url, headers=auth_header, json=body)\n        assert HTTP_422_UNPROCESSABLE_ENTITY == response.status_code\n        user.delete(db)\n\n    def test_create_user_permissions_invalid_user_id(\n        self, db, api_client, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header([USER_PERMISSION_CREATE])\n        user_id = \"bogus_user_id\"\n        body = {\"user_id\": user_id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}/user/{user_id}/permission\", headers=auth_header, json=body\n        )\n        permissions = FidesUserPermissions.get_by(db, field=\"user_id\", value=user_id)\n        assert HTTP_404_NOT_FOUND == response.status_code\n        assert permissions is None\n\n    def test_create_user_permissions(\n        self, db, api_client, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header([USER_PERMISSION_CREATE])\n        user = FidesUser.create(\n            db=db,\n            data={\"username\": \"user_1\", \"password\": \"test_password\"},\n        )\n\n        body = {\"user_id\": user.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        response = api_client.post(\n            f\"{V1_URL_PREFIX}/user/{user.id}/permission\", headers=auth_header, json=body\n        )\n        permissions = FidesUserPermissions.get_by(db, field=\"user_id\", value=user.id)\n        response_body = json.loads(response.text)\n        assert HTTP_201_CREATED == response.status_code\n        assert response_body[\"id\"] == permissions.id\n        assert permissions.scopes == [PRIVACY_REQUEST_READ]\n        user.delete(db)\n\n\nclass TestEditUserPermissions:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + USER_PERMISSIONS\n\n    def test_edit_user_permissions_not_authenticated(self, url, api_client):\n        response = api_client.put(url, headers={}, json={})\n        assert HTTP_401_UNAUTHORIZED == response.status_code\n\n    def test_edit_user_permissions_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header([SAAS_CONFIG_READ])\n        response = api_client.put(url, headers=auth_header, json={})\n        assert HTTP_403_FORBIDDEN == response.status_code\n\n    def test_edit_user_permissions_invalid_scope(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        url,\n    ) -> None:\n        auth_header = generate_auth_header([USER_PERMISSION_UPDATE])\n\n        body = {\"user_id\": \"bogus_user_id\", \"scopes\": [\"not a real scope\"]}\n\n        response = api_client.put(url, headers=auth_header, json=body)\n        assert HTTP_422_UNPROCESSABLE_ENTITY == response.status_code\n\n    def test_edit_user_permissions_invalid_user_id(\n        self, db, api_client, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header([USER_PERMISSION_UPDATE])\n        invalid_user_id = \"bogus_user_id\"\n        user = FidesUser.create(\n            db=db,\n            data={\"username\": \"user_1\", \"password\": \"test_password\"},\n        )\n\n        permissions = FidesUserPermissions.create(\n            db=db, data={\"user_id\": user.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        )\n        body = {\"id\": permissions.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        response = api_client.put(\n            f\"{V1_URL_PREFIX}/user/{invalid_user_id}/permission\",\n            headers=auth_header,\n            json=body,\n        )\n        permissions = FidesUserPermissions.get_by(\n            db, field=\"user_id\", value=invalid_user_id\n        )\n        assert HTTP_404_NOT_FOUND == response.status_code\n        assert permissions is None\n        user.delete(db)\n\n    def test_edit_user_permissions(self, db, api_client, generate_auth_header) -> None:\n        auth_header = generate_auth_header([USER_PERMISSION_UPDATE])\n        user = FidesUser.create(\n            db=db,\n            data={\"username\": \"user_1\", \"password\": \"test_password\"},\n        )\n\n        permissions = FidesUserPermissions.create(\n            db=db, data={\"user_id\": user.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        )\n\n        ClientDetail.create_client_and_secret(\n            db,\n            config.security.oauth_client_id_length_bytes,\n            config.security.oauth_client_secret_length_bytes,\n            scopes=[PRIVACY_REQUEST_READ],\n            user_id=user.id,\n        )\n\n        updated_scopes = [PRIVACY_REQUEST_READ, SAAS_CONFIG_READ]\n        body = {\"id\": permissions.id, \"scopes\": updated_scopes}\n        response = api_client.put(\n            f\"{V1_URL_PREFIX}/user/{user.id}/permission\", headers=auth_header, json=body\n        )\n        response_body = json.loads(response.text)\n        client: ClientDetail = ClientDetail.get_by(db, field=\"user_id\", value=user.id)\n        assert HTTP_200_OK == response.status_code\n        assert response_body[\"id\"] == permissions.id\n        assert response_body[\"scopes\"] == updated_scopes\n        assert client.scopes == updated_scopes\n\n        user.delete(db)\n\n\nclass TestGetUserPermissions:\n    @pytest.fixture(scope=\"function\")\n    def url(self, oauth_client: ClientDetail) -> str:\n        return V1_URL_PREFIX + USER_PERMISSIONS\n\n    def test_get_user_permissions_not_authenticated(self, url, api_client):\n        response = api_client.get(url, headers={}, json={})\n        assert HTTP_401_UNAUTHORIZED == response.status_code\n\n    def test_get_user_permissions_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header([SAAS_CONFIG_READ])\n        response = api_client.get(url, headers=auth_header, json={})\n        assert HTTP_403_FORBIDDEN == response.status_code\n\n    def test_get_user_permissions_invalid_user_id(\n        self, db, api_client, generate_auth_header\n    ) -> None:\n        auth_header = generate_auth_header([USER_PERMISSION_READ])\n        invalid_user_id = \"bogus_user_id\"\n        user = FidesUser.create(\n            db=db,\n            data={\"username\": \"user_1\", \"password\": \"test_password\"},\n        )\n\n        permissions = FidesUserPermissions.create(\n            db=db, data={\"user_id\": user.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        )\n        body = {\"id\": permissions.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        response = api_client.get(\n            f\"{V1_URL_PREFIX}/user/{invalid_user_id}/permission\",\n            headers=auth_header,\n            json=body,\n        )\n        permissions = FidesUserPermissions.get_by(\n            db, field=\"user_id\", value=invalid_user_id\n        )\n        assert HTTP_404_NOT_FOUND == response.status_code\n        assert permissions is None\n        user.delete(db)\n\n    def test_get_user_permissions(self, db, api_client, generate_auth_header) -> None:\n        auth_header = generate_auth_header([USER_PERMISSION_READ])\n        user = FidesUser.create(\n            db=db,\n            data={\"username\": \"user_1\", \"password\": \"test_password\"},\n        )\n        permissions = FidesUserPermissions.create(\n            db=db, data={\"user_id\": user.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n        )\n\n        response = api_client.get(\n            f\"{V1_URL_PREFIX}/user/{user.id}/permission\", headers=auth_header\n        )\n        response_body = json.loads(response.text)\n        assert HTTP_200_OK == response.status_code\n        assert response_body[\"id\"] == permissions.id\n        assert response_body[\"user_id\"] == user.id\n        assert response_body[\"scopes\"] == [PRIVACY_REQUEST_READ]\n        user.delete(db)\n"}
{"type": "test_file", "path": "tests/ops/api/v1/test_exception_handlers.py", "content": "import json\n\nimport pytest\nfrom starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.scope_registry import CLIENT_CREATE\nfrom fidesops.ops.api.v1.urn_registry import (\n    CLIENT,\n    HEALTH,\n    PRIVACY_REQUESTS,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.core import config\n\n\n@pytest.fixture\ndef mock_config_db_disabled():\n    db_enabled = config.config.database.enabled\n    config.config.database.enabled = False\n    yield\n    config.config.database.enabled = db_enabled\n\n\n@pytest.fixture\ndef mock_config_redis_disabled():\n    redis_enabled = config.config.redis.enabled\n    config.config.redis.enabled = False\n    yield\n    config.config.redis.enabled = redis_enabled\n\n\nclass TestExceptionHandlers:\n    @pytest.mark.usefixtures(\"mock_config_db_disabled\")\n    def test_db_disabled(self, api_client: TestClient, generate_auth_header):\n        auth_header = generate_auth_header([CLIENT_CREATE])\n        # oauth endpoint should not work\n        expected_response = {\n            \"message\": \"Application database required, but it is currently disabled! Please update your application configuration to enable integration with an application database.\"\n        }\n        response = api_client.post(V1_URL_PREFIX + CLIENT, headers=auth_header)\n        response_body = json.loads(response.text)\n        assert 500 == response.status_code\n        assert expected_response == response_body\n\n        # health endpoint should still work\n        expected_response = {\n            \"webserver\": \"healthy\",\n            \"database\": \"no db configured\",\n            \"cache\": \"healthy\",\n        }\n        response = api_client.get(HEALTH)\n        response_body = json.loads(response.text)\n        assert 200 == response.status_code\n        assert expected_response == response_body\n\n    @pytest.mark.usefixtures(\"mock_config_redis_disabled\")\n    def test_redis_disabled(self, api_client: TestClient, generate_auth_header):\n        auth_header = generate_auth_header([CLIENT_CREATE])\n        # Privacy requests endpoint should not work\n        request_body = [\n            {\n                \"requested_at\": \"2021-08-30T16:09:37.359Z\",\n                \"identity\": {\"email\": \"customer-1@example.com\"},\n                \"policy_key\": \"my_separate_policy\",\n            }\n        ]\n        expected_response = {\n            \"message\": \"Application redis cache required, but it is currently disabled! Please update your application configuration to enable integration with a redis cache.\"\n        }\n        response = api_client.post(\n            V1_URL_PREFIX + PRIVACY_REQUESTS, headers=auth_header, json=request_body\n        )\n        response_body = json.loads(response.text)\n        assert 500 == response.status_code\n        assert expected_response == response_body\n\n        # health endpoint should still work\n        expected_response = {\n            \"webserver\": \"healthy\",\n            \"database\": \"healthy\",\n            \"cache\": \"no cache configured\",\n        }\n        response = api_client.get(HEALTH)\n        response_body = json.loads(response.text)\n        assert 200 == response.status_code\n        assert expected_response == response_body\n"}
{"type": "test_file", "path": "tests/ops/api/v1/test_main.py", "content": "from starlette.testclient import TestClient\n\nfrom fidesops.ops.api.v1.urn_registry import V1_URL_PREFIX\n\n\nclass CustomTestException(BaseException):\n    \"\"\"Mock Non-HTTP Exception\"\"\"\n\n    pass\n\n\ndef test_read_autogenerated_docs(api_client: TestClient):\n    \"\"\"Test to ensure automatically generated docs build properly\"\"\"\n    response = api_client.get(f\"{V1_URL_PREFIX}/openapi.json\")\n    assert response.status_code == 200\n"}
{"type": "test_file", "path": "tests/ops/conftest.py", "content": "# pylint: disable=unused-wildcard-import, wildcard-import\n\nimport asyncio\nimport json\nimport logging\nfrom typing import Any, Callable, Dict, Generator, List\n\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom fideslib.core.config import load_toml\nfrom fideslib.cryptography.schemas.jwt import (\n    JWE_ISSUED_AT,\n    JWE_PAYLOAD_CLIENT_ID,\n    JWE_PAYLOAD_SCOPES,\n)\nfrom fideslib.db.session import Session, get_db_engine, get_db_session\nfrom fideslib.models.client import ClientDetail\nfrom fideslib.oauth.jwt import generate_jwe\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy_utils.functions import create_database, database_exists, drop_database\n\nfrom fidesops.main import app\nfrom fidesops.ops.api.v1.scope_registry import SCOPE_REGISTRY\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.db.base import Base\nfrom fidesops.ops.db.database import init_db\nfrom fidesops.ops.models.privacy_request import generate_request_callback_jwe\nfrom fidesops.ops.tasks.scheduled.scheduler import scheduler\nfrom fidesops.ops.util.cache import get_cache\n\nfrom .fixtures.application_fixtures import *\nfrom .fixtures.bigquery_fixtures import *\nfrom .fixtures.email_fixtures import *\nfrom .fixtures.integration_fixtures import *\nfrom .fixtures.manual_fixtures import *\nfrom .fixtures.manual_webhook_fixtures import *\nfrom .fixtures.mariadb_fixtures import *\nfrom .fixtures.mongodb_fixtures import *\nfrom .fixtures.mssql_fixtures import *\nfrom .fixtures.mysql_fixtures import *\nfrom .fixtures.postgres_fixtures import *\nfrom .fixtures.redshift_fixtures import *\nfrom .fixtures.saas.adobe_campaign_fixtures import *\nfrom .fixtures.saas.auth0_fixtures import *\nfrom .fixtures.saas.braze_fixtures import *\nfrom .fixtures.saas.connection_template_fixtures import *\nfrom .fixtures.saas.datadog_fixtures import *\nfrom .fixtures.saas.hubspot_fixtures import *\nfrom .fixtures.saas.mailchimp_fixtures import *\nfrom .fixtures.saas.outreach_fixtures import *\nfrom .fixtures.saas.request_override.firebase_auth_fixtures import *\nfrom .fixtures.saas.request_override.mailchimp_override_fixtures import *\nfrom .fixtures.saas.rollbar_fixtures import *\nfrom .fixtures.saas.salesforce_fixtures import *\nfrom .fixtures.saas.segment_fixtures import *\nfrom .fixtures.saas.sendgrid_fixtures import *\nfrom .fixtures.saas.sentry_fixtures import *\nfrom .fixtures.saas.shopify_fixtures import *\nfrom .fixtures.saas.stripe_fixtures import *\nfrom .fixtures.saas.zendesk_fixtures import *\nfrom .fixtures.saas_example_fixtures import *\nfrom .fixtures.snowflake_fixtures import *\nfrom .fixtures.timescale_fixtures import *\n\nlogger = logging.getLogger(__name__)\n\n\ndef migrate_test_db() -> None:\n    \"\"\"Apply migrations at beginning and end of testing session\"\"\"\n    logger.debug(\"Applying migrations...\")\n    assert config.is_test_mode\n    if config.database.enabled:\n        init_db(config.database.sqlalchemy_test_database_uri)\n    logger.debug(\"Migrations successfully applied\")\n\n\n@pytest.fixture(scope=\"session\")\ndef db() -> Generator:\n    \"\"\"Return a connection to the test DB\"\"\"\n    # Create the test DB enginge\n    assert config.is_test_mode\n    engine = get_db_engine(\n        database_uri=config.database.sqlalchemy_test_database_uri,\n    )\n\n    logger.debug(\"Configuring database at: %s\", engine.url)\n    if not database_exists(engine.url):\n        logger.debug(\"Creating database at: %s\", engine.url)\n        create_database(engine.url)\n        logger.debug(\"Database at: %s successfully created\", engine.url)\n    else:\n        logger.debug(\"Database at: %s already exists\", engine.url)\n\n    migrate_test_db()\n    scheduler.start()\n    SessionLocal = get_db_session(config, engine=engine)\n    the_session = SessionLocal()\n    # Setup above...\n    yield the_session\n    # Teardown below...\n    the_session.close()\n    engine.dispose()\n    logger.debug(\"Dropping database at: %s\", engine.url)\n    # We don't need to perform any extra checks before dropping the DB\n    # here since we know the engine will always be connected to the test DB\n    drop_database(engine.url)\n    logger.debug(\"Database at: %s successfully dropped\", engine.url)\n\n\n@pytest.fixture(autouse=True)\ndef clear_db_tables(db):\n    \"\"\"Clear data from tables between tests.\n\n    If relationships are not set to cascade on delete they will fail with an\n    IntegrityError if there are relationsips present. This function stores tables\n    that fail with this error then recursively deletes until no more IntegrityErrors\n    are present.\n    \"\"\"\n    yield\n\n    def delete_data(tables):\n        redo = []\n        for table in tables:\n            try:\n                db.execute(table.delete())\n            except IntegrityError:\n                redo.append(table)\n            finally:\n                db.commit()\n\n        if redo:\n            delete_data(redo)\n\n    db.commit()  # make sure all transactions are closed before starting deletes\n    delete_data(Base.metadata.sorted_tables)\n\n\n@pytest.fixture(scope=\"session\")\ndef cache() -> Generator:\n    yield get_cache()\n\n\n@pytest.fixture(scope=\"module\")\ndef api_client() -> Generator:\n    \"\"\"Return a client used to make API requests\"\"\"\n    with TestClient(app) as c:\n        yield c\n\n\n@pytest.fixture(scope=\"function\")\ndef oauth_client(db: Session) -> Generator:\n    \"\"\"Return a client for authentication purposes\"\"\"\n    client = ClientDetail(\n        hashed_secret=\"thisisatest\",\n        salt=\"thisisstillatest\",\n        scopes=SCOPE_REGISTRY,\n    )\n    db.add(client)\n    db.commit()\n    db.refresh(client)\n    yield client\n\n\ndef generate_auth_header_for_user(user, scopes) -> Dict[str, str]:\n    payload = {\n        JWE_PAYLOAD_SCOPES: scopes,\n        JWE_PAYLOAD_CLIENT_ID: user.client.id,\n        JWE_ISSUED_AT: datetime.now().isoformat(),\n    }\n    jwe = generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n    return {\"Authorization\": \"Bearer \" + jwe}\n\n\n@pytest.fixture(scope=\"function\")\ndef generate_auth_header(oauth_client) -> Callable[[Any], Dict[str, str]]:\n    return _generate_auth_header(oauth_client)\n\n\ndef _generate_auth_header(oauth_client) -> Callable[[Any], Dict[str, str]]:\n    client_id = oauth_client.id\n\n    def _build_jwt(scopes: List[str]) -> Dict[str, str]:\n        payload = {\n            JWE_PAYLOAD_SCOPES: scopes,\n            JWE_PAYLOAD_CLIENT_ID: client_id,\n            JWE_ISSUED_AT: datetime.now().isoformat(),\n        }\n        jwe = generate_jwe(json.dumps(payload), config.security.app_encryption_key)\n        return {\"Authorization\": \"Bearer \" + jwe}\n\n    return _build_jwt\n\n\n@pytest.fixture(scope=\"function\")\ndef generate_webhook_auth_header() -> Callable[[Any], Dict[str, str]]:\n    def _build_jwt(webhook: PolicyPreWebhook) -> Dict[str, str]:\n        jwe = generate_request_callback_jwe(webhook)\n        return {\"Authorization\": \"Bearer \" + jwe}\n\n    return _build_jwt\n\n\n@pytest.fixture(scope=\"session\")\ndef integration_config():\n    yield load_toml([\"fidesops-integration.toml\"])\n\n\n@pytest.fixture(autouse=True, scope=\"session\")\ndef celery_enable_logging():\n    \"\"\"Turns on celery output logs.\"\"\"\n    return True\n\n\n@pytest.fixture(autouse=True, scope=\"session\")\ndef celery_use_virtual_worker(celery_session_worker):\n    \"\"\"\n    This is a catch-all fixture that forces all of our\n    tests to use a virtual celery worker if a registered\n    task is executed within the scope of the test.\n    \"\"\"\n    yield celery_session_worker\n\n\n@pytest.fixture(scope=\"session\")\ndef run_privacy_request_task(celery_session_app):\n    \"\"\"\n    This fixture is the version of the run_privacy_request task that is\n    registered to the `celery_app` fixture which uses the virtualised `celery_worker`\n    \"\"\"\n    yield celery_session_app.tasks[\n        \"fidesops.ops.service.privacy_request.request_runner_service.run_privacy_request\"\n    ]\n\n\n@pytest.fixture(autouse=True, scope=\"session\")\ndef analytics_opt_out():\n    \"\"\"Disable sending analytics when running tests.\"\"\"\n    original_value = config.root_user.analytics_opt_out\n    config.root_user.analytics_opt_out = True\n    yield\n    config.root_user.analytics_opt_out = original_value\n\n\n@pytest.fixture(scope=\"function\")\ndef require_manual_request_approval():\n    \"\"\"Require manual request approval\"\"\"\n    original_value = config.execution.require_manual_request_approval\n    config.execution.require_manual_request_approval = True\n    yield\n    config.execution.require_manual_request_approval = original_value\n\n\n@pytest.fixture(scope=\"function\")\ndef subject_identity_verification_required():\n    \"\"\"Enable identity verification.\"\"\"\n    original_value = config.execution.subject_identity_verification_required\n    config.execution.subject_identity_verification_required = True\n    yield\n    config.execution.subject_identity_verification_required = original_value\n\n\n@pytest.fixture(autouse=True, scope=\"function\")\ndef subject_identity_verification_not_required():\n    \"\"\"Disable identity verification for most tests unless overridden\"\"\"\n    original_value = config.execution.subject_identity_verification_required\n    config.execution.subject_identity_verification_required = False\n    yield\n    config.execution.subject_identity_verification_required = original_value\n\n\n@pytest.fixture(autouse=True, scope=\"function\")\ndef privacy_request_complete_email_notification_disabled():\n    \"\"\"Disable request completion email for most tests unless overridden\"\"\"\n    original_value = config.notifications.send_request_completion_notification\n    config.notifications.send_request_completion_notification = False\n    yield\n    config.notifications.send_request_completion_notification = original_value\n\n\n@pytest.fixture(autouse=True, scope=\"function\")\ndef privacy_request_receipt_email_notification_disabled():\n    \"\"\"Disable request receipt email for most tests unless overridden\"\"\"\n    original_value = config.notifications.send_request_receipt_notification\n    config.notifications.send_request_receipt_notification = False\n    yield\n    config.notifications.send_request_receipt_notification = original_value\n\n\n@pytest.fixture(autouse=True, scope=\"function\")\ndef privacy_request_review_email_notification_disabled():\n    \"\"\"Disable request review email for most tests unless overridden\"\"\"\n    original_value = config.notifications.send_request_review_notification\n    config.notifications.send_request_review_notification = False\n    yield\n    config.notifications.send_request_review_notification = original_value\n\n\n@pytest.fixture(scope=\"session\", autouse=True)\ndef event_loop():\n    try:\n        loop = asyncio.get_running_loop()\n    except RuntimeError:\n        loop = asyncio.new_event_loop()\n    yield loop\n    loop.close()\n"}
{"type": "test_file", "path": "tests/ops/core/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/ops/email_templates/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/ops/core/test_config.py", "content": "import logging\nimport os\nfrom unittest.mock import patch\n\nimport pytest\nfrom fideslib.core.config import get_config\nfrom pydantic import ValidationError\n\nfrom fidesops.ops.core.config import FidesopsConfig\n\n\ndef test_config_from_default() -> None:\n    \"Test building a config from default local TOML\"\n    config = get_config(FidesopsConfig)\n\n    assert config.database.server == \"db\"\n    assert config.redis.host == \"redis\"\n    assert config.security.app_encryption_key == \"OLMkv91j8DHiDAULnK5Lxx3kSCov30b3\"\n\n\n@patch.dict(\n    os.environ,\n    {\n        \"FIDES__CONFIG_PATH\": \"data/config/\",\n    },\n    clear=True,\n)\ndef test_config_from_path() -> None:\n    \"\"\"Test reading config using the FIDES__CONFIG_PATH option.\"\"\"\n    config = get_config(FidesopsConfig)\n    assert config.database.server == \"testserver\"\n    assert config.redis.host == \"testredis\"\n    assert config.security.app_encryption_key == \"atestencryptionkeythatisvalidlen\"\n    assert config.admin_ui.enabled == True\n\n\n@patch.dict(\n    os.environ,\n    {\n        \"FIDESOPS__DATABASE__SERVER\": \"envserver\",\n        \"FIDESOPS__REDIS__HOST\": \"envhost\",\n    },\n    clear=True,\n)\ndef test_config_from_env_vars() -> None:\n    \"\"\"Test overriding config using ENV vars.\"\"\"\n    config = get_config(FidesopsConfig)\n    assert config.database.server == \"envserver\"\n    assert config.redis.host == \"envhost\"\n    assert config.security.app_encryption_key == \"OLMkv91j8DHiDAULnK5Lxx3kSCov30b3\"\n\n\ndef test_config_app_encryption_key_validation() -> None:\n    \"\"\"Test APP_ENCRYPTION_KEY is validated to be exactly 32 characters.\"\"\"\n    app_encryption_key = \"atestencryptionkeythatisvalidlen\"\n\n    with patch.dict(\n        os.environ,\n        {\n            \"FIDESOPS__SECURITY__APP_ENCRYPTION_KEY\": app_encryption_key,\n        },\n        clear=True,\n    ):\n        config = get_config(FidesopsConfig)\n        assert config.security.app_encryption_key == app_encryption_key\n\n\n@pytest.mark.parametrize(\n    \"app_encryption_key\",\n    [\"tooshortkey\", \"muchmuchmuchmuchmuchmuchmuchmuchtoolongkey\"],\n)\ndef test_config_app_encryption_key_validation_length_error(app_encryption_key) -> None:\n    \"\"\"Test APP_ENCRYPTION_KEY is validated to be exactly 32 characters.\"\"\"\n    with patch.dict(\n        os.environ,\n        {\n            \"FIDESOPS__SECURITY__APP_ENCRYPTION_KEY\": app_encryption_key,\n        },\n        clear=True,\n    ):\n        with pytest.raises(ValidationError) as err:\n            get_config(FidesopsConfig)\n        assert \"must be exactly 32 characters\" in str(err.value)\n\n\n@pytest.mark.parametrize(\n    \"log_level,expected_log_level\",\n    [\n        (\"DEBUG\", \"DEBUG\"),\n        (\"debug\", \"DEBUG\"),\n        (\"INFO\", \"INFO\"),\n        (\"WARNING\", \"WARNING\"),\n        (\"ERROR\", \"ERROR\"),\n        (\"CRITICAL\", \"CRITICAL\"),\n    ],\n)\ndef test_config_log_level(log_level, expected_log_level):\n    \"\"\"Test overriding the log level using ENV vars.\"\"\"\n    with patch.dict(\n        os.environ,\n        {\n            \"FIDESOPS__SECURITY__LOG_LEVEL\": log_level,\n        },\n        clear=True,\n    ):\n        config = get_config(FidesopsConfig)\n        assert config.security.log_level == expected_log_level\n\n\ndef test_config_log_level_invalid():\n    with patch.dict(\n        os.environ,\n        {\n            \"FIDESOPS__SECURITY__LOG_LEVEL\": \"INVALID\",\n        },\n        clear=True,\n    ):\n        with pytest.raises(ValidationError) as err:\n            get_config(FidesopsConfig)\n        assert \"Invalid LOG_LEVEL\" in str(err.value)\n"}
{"type": "test_file", "path": "tests/ops/email_templates/test_get_email_template.py", "content": "import pytest\nfrom jinja2 import Template\n\nfrom fidesops.ops.common_exceptions import EmailTemplateUnhandledActionType\nfrom fidesops.ops.email_templates import get_email_template\nfrom fidesops.ops.schemas.email.email import EmailActionType\n\n\ndef test_get_email_template_returns_template():\n    result = get_email_template(EmailActionType.SUBJECT_IDENTITY_VERIFICATION)\n    assert type(result) == Template\n\n\ndef test_get_email_template_exception():\n    fake_template = \"templateThatDoesNotExist\"\n    with pytest.raises(EmailTemplateUnhandledActionType) as e:\n        get_email_template(fake_template)\n        assert e.value == f\"No corresponding template linked to the {fake_template}\"\n"}
{"type": "test_file", "path": "tests/ops/fixtures/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/ops/fixtures/bigquery_fixtures.py", "content": "import ast\nimport logging\nimport os\nfrom typing import Dict, Generator, List\nfrom uuid import uuid4\n\nimport pytest\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.schemas.connection_configuration import BigQuerySchema\nfrom fidesops.ops.service.connectors import BigQueryConnector, get_connector\n\nfrom .application_fixtures import integration_config\n\nlogger = logging.getLogger(__name__)\n\n\n@pytest.fixture(scope=\"function\")\ndef bigquery_connection_config_without_secrets(db: Session) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_bigquery_config\",\n            \"connection_type\": ConnectionType.bigquery,\n            \"access\": AccessLevel.write,\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef bigquery_connection_config(db: Session) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_bigquery_config\",\n            \"connection_type\": ConnectionType.bigquery,\n            \"access\": AccessLevel.write,\n        },\n    )\n    # Pulling from integration config file or GitHub secrets\n    keyfile_creds = integration_config.get(\"bigquery\", {}).get(\n        \"keyfile_creds\"\n    ) or ast.literal_eval(os.environ.get(\"BIGQUERY_KEYFILE_CREDS\"))\n    dataset = integration_config.get(\"bigquery\", {}).get(\"dataset\") or os.environ.get(\n        \"BIGQUERY_DATASET\"\n    )\n    if keyfile_creds:\n        schema = BigQuerySchema(keyfile_creds=keyfile_creds, dataset=dataset)\n        connection_config.secrets = schema.dict()\n        connection_config.save(db=db)\n\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture\ndef bigquery_example_test_dataset_config(\n    bigquery_connection_config: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    bigquery_dataset = example_datasets[7]\n    fides_key = bigquery_dataset[\"fides_key\"]\n    bigquery_connection_config.name = fides_key\n    bigquery_connection_config.key = fides_key\n    bigquery_connection_config.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": bigquery_connection_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": bigquery_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef bigquery_resources(\n    bigquery_example_test_dataset_config,\n):\n    bigquery_connection_config = bigquery_example_test_dataset_config.connection_config\n    connector = BigQueryConnector(bigquery_connection_config)\n    bigquery_client = connector.client()\n    with bigquery_client.connect() as connection:\n        uuid = str(uuid4())\n        customer_email = f\"customer-{uuid}@example.com\"\n        customer_name = f\"{uuid}\"\n\n        stmt = \"select max(id) from customer;\"\n        res = connection.execute(stmt)\n        customer_id = res.all()[0][0] + 1\n\n        stmt = \"select max(id) from address;\"\n        res = connection.execute(stmt)\n        address_id = res.all()[0][0] + 1\n\n        city = \"Test City\"\n        state = \"TX\"\n        stmt = f\"\"\"\n        insert into address (id, house, street, city, state, zip)\n        values ({address_id}, '{111}', 'Test Street', '{city}', '{state}', '55555');\n        \"\"\"\n        connection.execute(stmt)\n\n        stmt = f\"\"\"\n            insert into customer (id, email, name, address_id)\n            values ({customer_id}, '{customer_email}', '{customer_name}', {address_id});\n        \"\"\"\n        connection.execute(stmt)\n\n        yield {\n            \"email\": customer_email,\n            \"name\": customer_name,\n            \"id\": customer_id,\n            \"client\": bigquery_client,\n            \"address_id\": address_id,\n            \"city\": city,\n            \"state\": state,\n            \"connector\": connector,\n        }\n        # Remove test data and close BigQuery connection in teardown\n        stmt = f\"delete from customer where email = '{customer_email}';\"\n        connection.execute(stmt)\n\n        stmt = f\"delete from address where id = {address_id};\"\n        connection.execute(stmt)\n\n\n@pytest.fixture(scope=\"session\")\ndef bigquery_test_engine() -> Generator:\n    \"\"\"Return a connection to a Google BigQuery Warehouse\"\"\"\n\n    connection_config = ConnectionConfig(\n        name=\"My BigQuery Config\",\n        key=\"test_bigquery_key\",\n        connection_type=ConnectionType.bigquery,\n    )\n\n    # Pulling from integration config file or GitHub secrets\n    keyfile_creds = integration_config.get(\"bigquery\", {}).get(\n        \"keyfile_creds\"\n    ) or ast.literal_eval(os.environ.get(\"BIGQUERY_KEYFILE_CREDS\"))\n    dataset = integration_config.get(\"bigquery\", {}).get(\"dataset\") or os.environ.get(\n        \"BIGQUERY_DATASET\"\n    )\n    if keyfile_creds:\n        schema = BigQuerySchema(keyfile_creds=keyfile_creds, dataset=dataset)\n        connection_config.secrets = schema.dict()\n\n    connector: BigQueryConnector = get_connector(connection_config)\n    engine = connector.client()\n    yield engine\n    engine.dispose()\n\n\ndef seed_bigquery_integration_db(bigquery_integration_engine) -> None:\n    \"\"\"\n    Currently unused.\n    This helper function has already been run once, and data has been populated in the test BigQuery dataset.\n    We may need this later for integration erasure tests, or in case tables are accidentally removed.\n    \"\"\"\n    logger.info(\"Seeding bigquery db\")\n    statements = [\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.report;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.service_request;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.login;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.visit;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.order_item;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.orders;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.payment_card;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.employee;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.customer;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.address;\n        \"\"\",\n        \"\"\"\n        DROP TABLE IF EXISTS fidesopstest.product;\n\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.product (\n            id INT,\n            name STRING,\n            price DECIMAL(10,2)\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.address (\n            id BIGINT,\n            house STRING,\n            street STRING,\n            city STRING,\n            state STRING,\n            zip STRING\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.customer (\n            id INT,\n            email STRING,\n            name  STRING,\n            created TIMESTAMP,\n            address_id BIGINT\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.employee (\n            id INT,\n            email STRING,\n            name STRING,\n            address_id BIGINT\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.payment_card (\n            id STRING,\n            name STRING,\n            ccn BIGINT,\n            code SMALLINT,\n            preferred BOOLEAN,\n            customer_id INT,\n            billing_address_id BIGINT\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.orders (\n            id STRING,\n            customer_id INT,\n            shipping_address_id BIGINT,\n            payment_card_id STRING\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.order_item (\n            order_id STRING,\n            item_no SMALLINT,\n            product_id INT,\n            quantity SMALLINT\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.visit (\n            email STRING,\n            last_visit TIMESTAMP\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.login (\n            id INT,\n            customer_id INT,\n            time TIMESTAMP\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.service_request (\n            id STRING,\n            email STRING,\n            alt_email STRING,\n            opened DATE,\n            closed DATE,\n            employee_id INT\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE fidesopstest.report (\n            id INT,\n            email STRING,\n            name STRING,\n            year INT,\n            month INT,\n            total_visits INT\n        );\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.product VALUES\n        (1, 'Example Product 1', 10.00),\n        (2, 'Example Product 2', 20.00),\n        (3, 'Example Product 3', 50.00);\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.address VALUES\n        (1, '123', 'Example Street', 'Exampletown', 'NY', '12345'),\n        (2, '4', 'Example Lane', 'Exampletown', 'NY', '12321'),\n        (3, '555', 'Example Ave', 'Example City', 'NY', '12000');\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.customer VALUES\n        (1, 'customer-1@example.com', 'John Customer', '2020-04-01 11:47:42', 1),\n        (2, 'customer-2@example.com', 'Jill Customer', '2020-04-01 11:47:42', 2);\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.employee VALUES\n        (1, 'employee-1@example.com', 'Jack Employee', 3),\n        (2, 'employee-2@example.com', 'Jane Employee', 3);\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.payment_card VALUES\n        ('pay_aaa-aaa', 'Example Card 1', 123456789, 321, true, 1, 1),\n        ('pay_bbb-bbb', 'Example Card 2', 987654321, 123, false, 2, 1);\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.orders VALUES\n        ('ord_aaa-aaa', 1, 2, 'pay_aaa-aaa'),\n        ('ord_bbb-bbb', 2, 1, 'pay_bbb-bbb'),\n        ('ord_ccc-ccc', 1, 1, 'pay_aaa-aaa'),\n        ('ord_ddd-ddd', 1, 1, 'pay_bbb-bbb');\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.order_item VALUES\n        ('ord_aaa-aaa', 1, 1, 1),\n        ('ord_bbb-bbb', 1, 1, 1),\n        ('ord_ccc-ccc', 1, 1, 1),\n        ('ord_ccc-ccc', 2, 2, 1),\n        ('ord_ddd-ddd', 1, 1, 1);\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.visit VALUES\n        ('customer-1@example.com', '2021-01-06 01:00:00'),\n        ('customer-2@example.com', '2021-01-06 01:00:00');\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.login VALUES\n        (1, 1, '2021-01-01 01:00:00'),\n        (2, 1, '2021-01-02 01:00:00'),\n        (5, 1, '2021-01-05 01:00:00'),\n        (6, 1, '2021-01-06 01:00:00'),\n        (7, 2, '2021-01-06 01:00:00');\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.service_request VALUES\n        ('ser_aaa-aaa', 'customer-1@example.com', 'customer-1-alt@example.com', '2021-01-01', '2021-01-03', 1),\n        ('ser_bbb-bbb', 'customer-2@example.com', null, '2021-01-04', null, 1),\n        ('ser_ccc-ccc', 'customer-3@example.com', null, '2021-01-05', '2020-01-07', 1),\n        ('ser_ddd-ddd', 'customer-3@example.com', null, '2021-05-05', '2020-05-08', 2);\n        \"\"\",\n        \"\"\"\n        INSERT INTO fidesopstest.report VALUES\n        (1, 'admin-account@example.com', 'Monthly Report', 2021, 8, 100),\n        (2, 'admin-account@example.com', 'Monthly Report', 2021, 9, 100),\n        (3, 'admin-account@example.com', 'Monthly Report', 2021, 10, 100),\n        (4, 'admin-account@example.com', 'Monthly Report', 2021, 11, 100);\n        \"\"\",\n    ]\n    with bigquery_integration_engine.connect() as connection:\n        [connection.execute(stmt) for stmt in statements]\n    logger.info(\"Finished seeding bigquery db\")\n    return\n"}
{"type": "test_file", "path": "tests/ops/fixtures/email_fixtures.py", "content": "from typing import Dict, Generator, List\nfrom uuid import uuid4\n\nimport pytest\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\n\n\n@pytest.fixture(scope=\"function\")\ndef email_connection_config(db: Session) -> Generator:\n    name = str(uuid4())\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": name,\n            \"key\": \"my_email_connection_config\",\n            \"connection_type\": ConnectionType.email,\n            \"access\": AccessLevel.write,\n            \"secrets\": {\"to_email\": \"test@example.com\"},\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef email_dataset_config(\n    email_connection_config: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    email_dataset = example_datasets[9]\n    fides_key = email_dataset[\"fides_key\"]\n    email_connection_config.name = fides_key\n    email_connection_config.key = fides_key\n    email_connection_config.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": email_connection_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": email_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n"}
{"type": "test_file", "path": "tests/ops/fixtures/integration_fixtures.py", "content": "import logging\nimport random\nfrom datetime import datetime\nfrom typing import Any, Dict, List\nfrom uuid import uuid4\n\nimport pytest\nfrom pymongo import MongoClient\nfrom sqlalchemy import text\nfrom sqlalchemy.engine import Engine\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.service.connectors import MongoDBConnector\n\nfrom .application_fixtures import faker, integration_secrets\n\nlogger = logging.getLogger(__name__)\n\n\ndef generate_integration_records():\n    return {\n        \"customer\": [\n            {\n                \"id\": 10000,\n                \"email\": \"test_one@example.com\",\n                \"name\": faker.name(),\n                \"address_id\": 1000,\n            },\n            {\n                \"id\": 10001,\n                \"email\": \"test_two@example.com\",\n                \"name\": faker.name(),\n                \"address_id\": 1001,\n            },\n            {\n                \"id\": 10002,\n                \"email\": \"test_three@example.com\",\n                \"name\": faker.name(),\n                \"address_id\": 1002,\n            },\n        ],\n        \"orders\": [\n            {\n                \"id\": \"test_order_id_10000\",\n                \"customer_id\": 10000,\n                \"payment_card_id\": \"test_payment_card_1000\",\n                \"shipping_address_id\": 1002,\n            },\n            {\n                \"id\": \"test_order_id_10001\",\n                \"customer_id\": 10001,\n                \"payment_card_id\": uuid4(),\n                \"shipping_address_id\": 1002,\n            },\n            {\n                \"id\": \"test_order_id_10002\",\n                \"customer_id\": 10002,\n                \"payment_card_id\": uuid4(),\n                \"shipping_address_id\": 1002,\n            },\n        ],\n        \"payment_card\": [\n            {\n                \"id\": \"test_payment_card_1001\",\n                \"name\": faker.name(),\n                \"ccn\": random.randint(10000, 1000000000),\n                \"billing_address_id\": 10001,\n            },\n            {\n                \"id\": \"test_payment_card_1002\",\n                \"name\": faker.name(),\n                \"ccn\": random.randint(10000, 1000000000),\n                \"billing_address_id\": 10002,\n            },\n        ],\n        \"address\": [\n            {\n                \"id\": 1000,\n                \"street\": faker.street_address(),\n                \"city\": faker.city(),\n                \"state\": faker.state(),\n                \"zip\": faker.zipcode(),\n            },\n            {\n                \"id\": 1001,\n                \"street\": faker.street_address(),\n                \"city\": faker.city(),\n                \"state\": faker.state(),\n                \"zip\": faker.zipcode(),\n            },\n            {\n                \"id\": 1002,\n                \"street\": faker.street_address(),\n                \"city\": faker.city(),\n                \"state\": faker.state(),\n                \"zip\": faker.zipcode(),\n            },\n        ],\n    }\n\n\n# ======================= postgres ==========================\n\n\n@pytest.fixture(scope=\"function\")\ndef integration_postgres_config(postgres_inserts) -> ConnectionConfig:\n    return ConnectionConfig(\n        name=\"postgres_test\",\n        key=\"postgres_example\",\n        connection_type=ConnectionType.postgres,\n        access=AccessLevel.write,\n        secrets=integration_secrets[\"postgres_example\"],\n    )\n\n\ndef sql_insert(engine: Engine, table_name: str, record: Dict[str, Any]) -> None:\n    fields = record.keys()\n    value_keys = [f\":{k}\" for k in fields]\n    insert_str = f\"INSERT INTO {table_name} ({','.join(fields)}) VALUES ({ ','.join(value_keys)})\"\n    text_clause = text(insert_str)\n    with engine.connect() as connection:\n        connection.execute(text_clause, record)\n\n\ndef sql_delete(engine: Engine, table_name: str, ids: List[Any]) -> None:\n    delete_str = f\"DELETE FROM {table_name} where id in {tuple(ids)}\"\n    with engine.connect() as connection:\n        connection.execute(delete_str)\n\n\n@pytest.fixture(scope=\"function\")\ndef postgres_inserts(postgres_integration_db):\n    integration_postgres_db_engine = postgres_integration_db.bind\n    records = generate_integration_records()\n    for table_name, record_list in records.items():\n        for record in record_list:\n            sql_insert(integration_postgres_db_engine, table_name, record)\n    yield records\n    for table_name, record_list in records.items():\n        sql_delete(\n            integration_postgres_db_engine, table_name, [r[\"id\"] for r in record_list]\n        )\n\n\n# ======================= mongodb  ==========================\n\n\n@pytest.fixture(scope=\"function\")\ndef integration_mongodb_config(db) -> ConnectionConfig:\n    connection_config = ConnectionConfig(\n        key=\"mongo_example\",\n        connection_type=ConnectionType.mongodb,\n        access=AccessLevel.write,\n        secrets=integration_secrets[\"mongo_example\"],\n        name=\"mongo_example\",\n    )\n    connection_config.save(db)\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef integration_mongodb_connector(integration_mongodb_config) -> MongoClient:\n    return MongoDBConnector(integration_mongodb_config).client()\n\n\ndef mongo_insert(\n    client: MongoClient, db_name: str, collection_name: str, record: Dict[str, Any]\n) -> None:\n    db = client[db_name]\n    collection = db[collection_name]\n    return collection.insert_one(record).inserted_id\n\n\ndef mongo_delete(\n    client: MongoClient,\n    db_name: str,\n    collection_name: str,\n    records: List[Dict[str, Any]],\n) -> None:\n    \"\"\"Deletion in the context of this test. This deletion is not using the mongo _id fields,\n    since those are generated at the time of the test.\"\"\"\n\n    db = client[db_name]\n    collection = db[collection_name]\n    return collection.delete_many({\"id\": {\"$in\": [record[\"id\"] for record in records]}})\n\n\ndef generate_mongo_specific_records():\n    \"\"\"These records are generated for mongo erasure tests where we mask some of the data as part of the test\"\"\"\n    return {\n        \"customer_details\": [\n            {\n                \"id\": \"001\",\n                \"customer_id\": 10000,\n                \"gender\": \"male\",\n                \"birthday\": datetime(1988, 1, 10),\n                \"workplace_info\": {\n                    \"employer\": \"Green Tea Company\",\n                    \"position\": \"Head Grower\",\n                    \"direct_reports\": [\"Margo Robbins\"],\n                },\n                \"emergency_contacts\": [\n                    {\n                        \"name\": \"Grace Customer\",\n                        \"relationship\": \"mother\",\n                        \"phone\": \"123-456-7890\",\n                    },\n                    {\n                        \"name\": \"Joseph Customer\",\n                        \"relationship\": \"brother\",\n                        \"phone\": \"000-000-0000\",\n                    },\n                ],\n                \"children\": [\"Kent Customer\", \"Kenny Customer\"],\n                \"travel_identifiers\": [\"D222-22221\", \"Z111-1111\"],\n                \"comments\": [\n                    {\"comment_id\": \"com_0011\"},\n                    {\"comment_id\": \"com_0013\"},\n                    {\"comment_id\": \"com_0015\"},\n                ],\n            },\n            {\n                \"id\": \"002\",\n                \"customer_id\": 10001,\n                \"gender\": \"female\",\n                \"birthday\": datetime(1985, 3, 5),\n                \"workplace_info\": {\n                    \"employer\": \"The Tool Shop\",\n                    \"position\": \"Mechanic 1\",\n                    \"direct_reports\": [\"Langdon Jeanne\", \"Dorothy Faron\"],\n                },\n                \"emergency_contacts\": [\n                    {\n                        \"name\": \"Jenny Customer\",\n                        \"relationship\": \"spouse\",\n                        \"phone\": \"111-000-1111\",\n                    },\n                    {\n                        \"name\": \"Jill Customer\",\n                        \"relationship\": \"sister\",\n                        \"phone\": \"222-222-2222\",\n                    },\n                ],\n                \"children\": [\"Connie Customer\"],\n                \"travel_identifiers\": [\"C222-222222\"],\n            },\n            {\n                \"id\": \"003\",\n                \"customer_id\": 10002,\n                \"gender\": \"female\",\n                \"birthday\": datetime(1990, 2, 28),\n                \"travel_identifiers\": [\"G111-11111\"],\n                \"children\": [\"Erica Example\"],\n                \"comments\": [\n                    {\"comment_id\": \"com_0012\"},\n                    {\"comment_id\": \"com_0014\"},\n                    {\"comment_id\": \"com_0016\"},\n                ],\n            },\n        ],\n        \"customer_feedback\": [\n            {\n                \"id\": \"feed_1\",\n                \"customer_information\": {\n                    \"email\": \"test_one@example.com\",\n                    \"phone\": \"333-000-3333\",\n                    \"internal_customer_id\": \"cust_014\",\n                },\n                \"rating\": 3,\n                \"date\": datetime(2022, 1, 5),\n                \"message\": \"Customer service wait times have increased to over an hour.\",\n            },\n            {\n                \"id\": \"feed_2\",\n                \"customer_information\": {\n                    \"email\": \"test_two@example.com\",\n                    \"phone\": \"111-000-1111\",\n                    \"internal_customer_id\": \"cust_015\",\n                },\n                \"rating\": 5,\n                \"date\": datetime(2022, 1, 10),\n                \"message\": \"Customer service rep was very helpful and answered all my questions.\",\n            },\n        ],\n        \"internal_customer_profile\": [\n            {\n                \"id\": \"prof_1\",\n                \"customer_identifiers\": {\"internal_id\": \"cust_014\"},\n                \"derived_interests\": [\"marketing\", \"food\"],\n            },\n            {\n                \"id\": \"prof_2\",\n                \"customer_identifiers\": {\n                    \"internal_id\": \"cust_015\",\n                    \"derived_phone\": [\"757-499-5508\"],\n                },\n                \"derived_interests\": [\"programming\", \"hiking\", \"skateboarding\"],\n            },\n            {\n                \"id\": \"prof_3\",\n                \"customer_identifiers\": {\n                    \"internal_id\": \"cust_016\",\n                    \"derived_emails\": [\"jenny1@example.com\", \"jenny@example.com\"],\n                    \"derived_phone\": [\"424-216-1577\", \"413-821-6662\"],\n                },\n                \"derived_interests\": [\"interior design\", \"travel\", \"photography\"],\n            },\n        ],\n        \"conversations\": [\n            {\n                \"id\": \"thread_1\",\n                \"thread\": [\n                    {\n                        \"comment\": \"com_0011\",\n                        \"message\": \"hey do you know when we're landing?\",\n                        \"chat_name\": \"John C\",\n                        \"ccn\": \"123456789\",\n                    },\n                    {\n                        \"comment\": \"com_0012\",\n                        \"message\": \"the detour we're taking for the storm we'll probably add an hour\",\n                        \"chat_name\": \"Jenny C\",\n                        \"ccn\": \"987654321\",\n                    },\n                ],\n            },\n            {\n                \"id\": \"thread_2\",\n                \"thread\": [\n                    {\n                        \"comment\": \"com_0013\",\n                        \"message\": \"should we text Grace when we land or should we just surprise her?\",\n                        \"chat_name\": \"John C\",\n                        \"ccn\": \"123456789\",\n                    },\n                    {\n                        \"comment\": \"com_0014\",\n                        \"message\": \"I think we should give her a heads-up\",\n                        \"chat_name\": \"Jenny C\",\n                        \"ccn\": \"987654321\",\n                    },\n                    {\n                        \"comment\": \"com_0015\",\n                        \"message\": \"Aw but she loves surprises.\",\n                        \"chat_name\": \"John C\",\n                        \"ccn\": \"123456789\",\n                    },\n                    {\n                        \"comment\": \"com_0016\",\n                        \"message\": \"I'm pretty sure she needs the peace of mind\",\n                        \"chat_name\": \"Jenny C\",\n                    },\n                ],\n            },\n            {\n                \"id\": \"thread_3\",\n                \"thread\": [\n                    {\n                        \"comment\": \"com_0017\",\n                        \"message\": \"Flight attendants, prepare the cabin take-off please.\",\n                        \"chat_name\": \"Pilot 21\",\n                    },\n                    {\n                        \"comment\": \"com_0018\",\n                        \"message\": \"Airliner B, runway 13 cleared for takeoff\",\n                        \"chat_name\": \"ATC 12\",\n                    },\n                ],\n            },\n        ],\n        \"flights\": [\n            {\n                \"id\": \"cust_flight_1\",\n                \"passenger_information\": {\n                    \"passenger_ids\": [\"old_travel_number\", \"D222-22221\"],\n                    \"full_name\": \"John Customer\",\n                },\n                \"flight_no\": \"AA230\",\n                \"date\": \"2021-01-01\",\n                \"pilots\": [\"3\", \"4\"],\n                \"plane\": 20002,\n            },\n            {\n                \"id\": \"cust_flight_2\",\n                \"passenger_information\": {\n                    \"passenger_ids\": [\"JK111-11111\", \"G111-11111\"],\n                    \"full_name\": \"Jenny Customer\",\n                },\n                \"flight_no\": \"AA240\",\n                \"date\": \"2021-02-01\",\n                \"pilots\": [\"4\"],\n                \"plane\": 40005,\n            },\n        ],\n        \"aircraft\": [\n            {\n                \"id\": \"plane_type_1\",\n                \"model\": \"Airbus A350\",\n                \"planes\": [\"20001\", \"20002\", \"20003\", \"20004\", \"20005\"],\n            },\n            {\n                \"id\": \"plane_type_2\",\n                \"model\": \"Boeing 747-8\",\n                \"planes\": [\"40005\", \"30006\", \"40007\"],\n            },\n        ],\n        \"employee\": [\n            {\n                \"email\": \"employee-3@example.com\",\n                \"name\": \"Jonathan Employee\",\n                \"id\": \"3\",\n                \"address\": {\n                    \"house\": 555,\n                    \"street\": \"Example Ave\",\n                    \"city\": \"Example City\",\n                    \"state\": \"TX\",\n                    \"zip\": \"12000\",\n                },\n                \"foreign_id\": \"000000000000000000000001\",\n            },\n            {\n                \"email\": \"employee-4@example.com\",\n                \"name\": \"Jessica Employee\",\n                \"id\": \"4\",\n                \"address\": {\n                    \"house\": 555,\n                    \"street\": \"Example Ave\",\n                    \"city\": \"Example City\",\n                    \"state\": \"TX\",\n                    \"zip\": \"12000\",\n                },\n                \"foreign_id\": \"000000000000000000000002\",\n            },\n        ],\n        \"rewards\": [\n            {\n                \"id\": \"rew_1\",\n                \"owner\": [\n                    {\"phone\": \"424-216-1577\", \"shopper_name\": \"jenny\"},\n                    {\"phone\": \"217-821-9886\", \"shopper_name\": \"jenny\"},\n                ],\n                \"points\": 100,\n                \"expiration\": datetime(2023, 1, 5),\n            },\n            {\n                \"id\": \"rew_2\",\n                \"owner\": [{\"phone\": \"413-821-6662\", \"shopper_name\": \"jenny\"}],\n                \"points\": 2,\n                \"expiration\": datetime(2023, 2, 5),\n            },\n            {\n                \"id\": \"rew_3\",\n                \"owner\": [{\"phone\": \"805-496-5401\", \"shopper-name\": \"jenny\"}],\n                \"points\": 2,\n                \"expiration\": datetime(2022, 2, 5),\n            },\n        ],\n    }\n\n\n@pytest.fixture(scope=\"function\")\ndef mongo_inserts(integration_mongodb_connector):\n    records = generate_integration_records()\n    records.update(generate_mongo_specific_records())\n    for table_name, record_list in records.items():\n        for record in record_list:\n            mongo_insert(\n                integration_mongodb_connector, \"mongo_test\", table_name, record\n            )\n    yield records\n    for table_name, record_list in records.items():\n        mongo_delete(\n            integration_mongodb_connector, \"mongo_test\", table_name, record_list\n        )\n"}
{"type": "test_file", "path": "tests/ops/fixtures/manual_fixtures.py", "content": "from typing import Dict, Generator, List\nfrom uuid import uuid4\n\nimport pytest\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\n\n\n@pytest.fixture(scope=\"function\")\ndef integration_manual_config(db) -> ConnectionConfig:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"manual_example\",\n            \"connection_type\": ConnectionType.manual,\n            \"access\": AccessLevel.write,\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef manual_dataset_config(\n    integration_manual_config: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    manual_dataset = example_datasets[8]\n    fides_key = manual_dataset[\"fides_key\"]\n    integration_manual_config.name = fides_key\n    integration_manual_config.key = fides_key\n    integration_manual_config.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": integration_manual_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": manual_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n"}
{"type": "test_file", "path": "tests/ops/fixtures/application_fixtures.py", "content": "import logging\nfrom datetime import datetime, timedelta, timezone\nfrom typing import Dict, Generator, List\nfrom unittest import mock\nfrom uuid import uuid4\n\nimport pydash\nimport pytest\nimport yaml\nfrom faker import Faker\nfrom fideslib.core.config import load_file, load_toml\nfrom fideslib.models.audit_log import AuditLog, AuditLogAction\nfrom fideslib.models.client import ClientDetail\nfrom fideslib.models.fides_user import FidesUser\nfrom fideslib.models.fides_user_permissions import FidesUserPermissions\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.orm.exc import ObjectDeletedError\n\nfrom fidesops.ops.api.v1.scope_registry import PRIVACY_REQUEST_READ, SCOPE_REGISTRY\nfrom fidesops.ops.core.config import FidesopsConfig, config\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.models.email import EmailConfig\nfrom fidesops.ops.models.policy import (\n    ActionType,\n    Policy,\n    PolicyPostWebhook,\n    PolicyPreWebhook,\n    Rule,\n    RuleTarget,\n)\nfrom fidesops.ops.models.privacy_request import PrivacyRequest, PrivacyRequestStatus\nfrom fidesops.ops.models.storage import ResponseFormat, StorageConfig\nfrom fidesops.ops.schemas.email.email import (\n    EmailServiceDetails,\n    EmailServiceSecrets,\n    EmailServiceType,\n)\nfrom fidesops.ops.schemas.redis_cache import Identity\nfrom fidesops.ops.schemas.storage.storage import (\n    FileNaming,\n    S3AuthMethod,\n    StorageDetails,\n    StorageSecrets,\n    StorageType,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy_hmac import (\n    HmacMaskingStrategy,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy_nullify import (\n    NullMaskingStrategy,\n)\nfrom fidesops.ops.service.masking.strategy.masking_strategy_string_rewrite import (\n    StringRewriteMaskingStrategy,\n)\nfrom fidesops.ops.util.data_category import DataCategory\n\nlogging.getLogger(\"faker\").setLevel(logging.ERROR)\n# disable verbose faker logging\nfaker = Faker()\nintegration_config = load_toml([\"fidesops-integration.toml\"])\n\nlogger = logging.getLogger(__name__)\n\n\n# Unified list of connections to integration dbs specified from fidesops-integration.toml\n\nintegration_secrets = {\n    \"postgres_example\": {\n        \"host\": pydash.get(integration_config, \"postgres_example.server\"),\n        \"port\": pydash.get(integration_config, \"postgres_example.port\"),\n        \"dbname\": pydash.get(integration_config, \"postgres_example.db\"),\n        \"username\": pydash.get(integration_config, \"postgres_example.user\"),\n        \"password\": pydash.get(integration_config, \"postgres_example.password\"),\n    },\n    \"mongo_example\": {\n        \"host\": pydash.get(integration_config, \"mongodb_example.server\"),\n        \"defaultauthdb\": pydash.get(integration_config, \"mongodb_example.db\"),\n        \"username\": pydash.get(integration_config, \"mongodb_example.user\"),\n        \"password\": pydash.get(integration_config, \"mongodb_example.password\"),\n    },\n    \"mysql_example\": {\n        \"host\": pydash.get(integration_config, \"mysql_example.server\"),\n        \"port\": pydash.get(integration_config, \"mysql_example.port\"),\n        \"dbname\": pydash.get(integration_config, \"mysql_example.db\"),\n        \"username\": pydash.get(integration_config, \"mysql_example.user\"),\n        \"password\": pydash.get(integration_config, \"mysql_example.password\"),\n    },\n    \"mssql_example\": {\n        \"host\": pydash.get(integration_config, \"mssql_example.server\"),\n        \"port\": pydash.get(integration_config, \"mssql_example.port\"),\n        \"dbname\": pydash.get(integration_config, \"mssql_example.db\"),\n        \"username\": pydash.get(integration_config, \"mssql_example.user\"),\n        \"password\": pydash.get(integration_config, \"mssql_example.password\"),\n    },\n    \"mariadb_example\": {\n        \"host\": pydash.get(integration_config, \"mariadb_example.server\"),\n        \"port\": pydash.get(integration_config, \"mariadb_example.port\"),\n        \"dbname\": pydash.get(integration_config, \"mariadb_example.db\"),\n        \"username\": pydash.get(integration_config, \"mariadb_example.user\"),\n        \"password\": pydash.get(integration_config, \"mariadb_example.password\"),\n    },\n    \"timescale_example\": {\n        \"host\": pydash.get(integration_config, \"timescale_example.server\"),\n        \"port\": pydash.get(integration_config, \"timescale_example.port\"),\n        \"dbname\": pydash.get(integration_config, \"timescale_example.db\"),\n        \"username\": pydash.get(integration_config, \"timescale_example.user\"),\n        \"password\": pydash.get(integration_config, \"timescale_example.password\"),\n    },\n}\n\n\n@pytest.fixture(scope=\"session\", autouse=True)\ndef mock_upload_logic() -> Generator:\n    with mock.patch(\n        \"fidesops.ops.service.storage.storage_uploader_service.upload_to_s3\"\n    ) as _fixture:\n        yield _fixture\n\n\n@pytest.fixture(scope=\"function\")\ndef storage_config(db: Session) -> Generator:\n    name = str(uuid4())\n    storage_config = StorageConfig.create(\n        db=db,\n        data={\n            \"name\": name,\n            \"type\": StorageType.s3,\n            \"details\": {\n                StorageDetails.AUTH_METHOD.value: S3AuthMethod.SECRET_KEYS.value,\n                StorageDetails.NAMING.value: FileNaming.request_id.value,\n                StorageDetails.BUCKET.value: \"test_bucket\",\n            },\n            \"key\": \"my_test_config\",\n            \"format\": ResponseFormat.json,\n        },\n    )\n    storage_config.set_secrets(\n        db=db,\n        storage_secrets={\n            StorageSecrets.AWS_ACCESS_KEY_ID.value: \"1234\",\n            StorageSecrets.AWS_SECRET_ACCESS_KEY.value: \"5678\",\n        },\n    )\n    yield storage_config\n    storage_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef storage_config_onetrust(db: Session) -> Generator:\n    \"\"\"\n    This fixture adds onetrust config data to the database.\n    \"\"\"\n    name = \"onetrust config\"\n    storage_config = StorageConfig.create(\n        db=db,\n        data={\n            \"name\": name,\n            \"type\": StorageType.onetrust,\n            \"details\": {\n                StorageDetails.SERVICE_NAME.value: \"Meow Services\",\n                StorageDetails.ONETRUST_POLLING_DAY_OF_WEEK.value: 1,\n                StorageDetails.ONETRUST_POLLING_HR.value: 8,\n            },\n            \"key\": \"my_onetrust_config\",\n        },\n    )\n    storage_config.set_secrets(\n        db=db,\n        storage_secrets={\n            StorageSecrets.ONETRUST_CLIENT_SECRET.value: \"23tcrcrewg\",\n            StorageSecrets.ONETRUST_CLIENT_ID.value: \"9upqn3ufqnff\",\n            StorageSecrets.ONETRUST_HOSTNAME.value: \"meow-services.onetrust\",\n        },\n    )\n    yield storage_config\n    storage_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef email_config(db: Session) -> Generator:\n    name = str(uuid4())\n    email_config = EmailConfig.create(\n        db=db,\n        data={\n            \"name\": name,\n            \"key\": \"my_email_config\",\n            \"service_type\": EmailServiceType.MAILGUN,\n            \"details\": {\n                EmailServiceDetails.API_VERSION.value: \"v3\",\n                EmailServiceDetails.DOMAIN.value: \"some.domain\",\n                EmailServiceDetails.IS_EU_DOMAIN.value: False,\n            },\n        },\n    )\n    email_config.set_secrets(\n        db=db, email_secrets={EmailServiceSecrets.MAILGUN_API_KEY.value: \"12984r70298r\"}\n    )\n    yield email_config\n    email_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef https_connection_config(db: Session) -> Generator:\n    name = str(uuid4())\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": name,\n            \"key\": \"my_webhook_config\",\n            \"connection_type\": ConnectionType.https,\n            \"access\": AccessLevel.read,\n            \"secrets\": {\n                \"url\": \"http://example.com\",\n                \"authorization\": \"test_authorization\",\n            },\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef policy_pre_execution_webhooks(\n    db: Session, https_connection_config, policy\n) -> Generator:\n    pre_webhook = PolicyPreWebhook.create(\n        db=db,\n        data={\n            \"connection_config_id\": https_connection_config.id,\n            \"policy_id\": policy.id,\n            \"direction\": \"one_way\",\n            \"name\": str(uuid4()),\n            \"key\": \"pre_execution_one_way_webhook\",\n            \"order\": 0,\n        },\n    )\n    pre_webhook_two = PolicyPreWebhook.create(\n        db=db,\n        data={\n            \"connection_config_id\": https_connection_config.id,\n            \"policy_id\": policy.id,\n            \"direction\": \"two_way\",\n            \"name\": str(uuid4()),\n            \"key\": \"pre_execution_two_way_webhook\",\n            \"order\": 1,\n        },\n    )\n    db.commit()\n    yield [pre_webhook, pre_webhook_two]\n    try:\n        pre_webhook.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        pre_webhook_two.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef policy_post_execution_webhooks(\n    db: Session, https_connection_config, policy\n) -> Generator:\n    post_webhook = PolicyPostWebhook.create(\n        db=db,\n        data={\n            \"connection_config_id\": https_connection_config.id,\n            \"policy_id\": policy.id,\n            \"direction\": \"one_way\",\n            \"name\": str(uuid4()),\n            \"key\": \"cache_busting_webhook\",\n            \"order\": 0,\n        },\n    )\n    post_webhook_two = PolicyPostWebhook.create(\n        db=db,\n        data={\n            \"connection_config_id\": https_connection_config.id,\n            \"policy_id\": policy.id,\n            \"direction\": \"one_way\",\n            \"name\": str(uuid4()),\n            \"key\": \"cleanup_webhook\",\n            \"order\": 1,\n        },\n    )\n    db.commit()\n    yield [post_webhook, post_webhook_two]\n    try:\n        post_webhook.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        post_webhook_two.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef access_and_erasure_policy(\n    db: Session,\n    oauth_client: ClientDetail,\n    storage_config: StorageConfig,\n) -> Generator:\n    access_and_erasure_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"example access and erasure policy\",\n            \"key\": \"example_access_erasure_policy\",\n            \"client_id\": oauth_client.id,\n        },\n    )\n    access_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.access.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Access Request Rule\",\n            \"policy_id\": access_and_erasure_policy.id,\n            \"storage_destination_id\": storage_config.id,\n        },\n    )\n    access_rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user\").value,\n            \"rule_id\": access_rule.id,\n        },\n    )\n    erasure_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.erasure.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Erasure Rule\",\n            \"policy_id\": access_and_erasure_policy.id,\n            \"masking_strategy\": {\n                \"strategy\": \"null_rewrite\",\n                \"configuration\": {},\n            },\n        },\n    )\n\n    erasure_rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user.name\").value,\n            \"rule_id\": erasure_rule.id,\n        },\n    )\n    yield access_and_erasure_policy\n    try:\n        access_rule_target.delete(db)\n        erasure_rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        access_rule.delete(db)\n        erasure_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        access_and_erasure_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef erasure_policy(\n    db: Session,\n    oauth_client: ClientDetail,\n) -> Generator:\n    erasure_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"example erasure policy\",\n            \"key\": \"example_erasure_policy\",\n            \"client_id\": oauth_client.id,\n        },\n    )\n\n    erasure_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.erasure.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Erasure Rule\",\n            \"policy_id\": erasure_policy.id,\n            \"masking_strategy\": {\n                \"strategy\": \"null_rewrite\",\n                \"configuration\": {},\n            },\n        },\n    )\n\n    rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user.name\").value,\n            \"rule_id\": erasure_rule.id,\n        },\n    )\n    yield erasure_policy\n    try:\n        rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef erasure_policy_aes(\n    db: Session,\n    oauth_client: ClientDetail,\n) -> Generator:\n    erasure_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"example erasure policy aes\",\n            \"key\": \"example_erasure_policy_aes\",\n            \"client_id\": oauth_client.id,\n        },\n    )\n\n    erasure_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.erasure.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Erasure Rule\",\n            \"policy_id\": erasure_policy.id,\n            \"masking_strategy\": {\n                \"strategy\": \"aes_encrypt\",\n                \"configuration\": {},\n            },\n        },\n    )\n\n    rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user.name\").value,\n            \"rule_id\": erasure_rule.id,\n        },\n    )\n    yield erasure_policy\n    try:\n        rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef erasure_policy_string_rewrite_long(\n    db: Session,\n    oauth_client: ClientDetail,\n) -> Generator:\n    erasure_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"example erasure policy string rewrite\",\n            \"key\": \"example_erasure_policy_string_rewrite\",\n            \"client_id\": oauth_client.id,\n        },\n    )\n\n    erasure_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.erasure.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Erasure Rule\",\n            \"policy_id\": erasure_policy.id,\n            \"masking_strategy\": {\n                \"strategy\": StringRewriteMaskingStrategy.name,\n                \"configuration\": {\n                    \"rewrite_value\": \"some rewrite value that is very long and goes on and on\"\n                },\n            },\n        },\n    )\n\n    rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user.name\").value,\n            \"rule_id\": erasure_rule.id,\n        },\n    )\n    yield erasure_policy\n    try:\n        rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef erasure_policy_two_rules(\n    db: Session, oauth_client: ClientDetail, erasure_policy: Policy\n) -> Generator:\n\n    second_erasure_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.erasure.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Second Erasure Rule\",\n            \"policy_id\": erasure_policy.id,\n            \"masking_strategy\": {\n                \"strategy\": NullMaskingStrategy.name,\n                \"configuration\": {},\n            },\n        },\n    )\n\n    # TODO set masking strategy in Rule.create() call above, once more masking strategies beyond NULL_REWRITE are supported.\n    second_erasure_rule.masking_strategy = {\n        \"strategy\": StringRewriteMaskingStrategy.name,\n        \"configuration\": {\"rewrite_value\": \"*****\"},\n    }\n\n    second_rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user.contact.email\").value,\n            \"rule_id\": second_erasure_rule.id,\n        },\n    )\n    yield erasure_policy\n    try:\n        second_rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        second_erasure_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef policy(\n    db: Session,\n    oauth_client: ClientDetail,\n    storage_config: StorageConfig,\n) -> Generator:\n    access_request_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"example access request policy\",\n            \"key\": \"example_access_request_policy\",\n            \"client_id\": oauth_client.id,\n            \"execution_timeframe\": 7,\n        },\n    )\n\n    access_request_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.access.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Access Request Rule\",\n            \"policy_id\": access_request_policy.id,\n            \"storage_destination_id\": storage_config.id,\n        },\n    )\n\n    rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user\").value,\n            \"rule_id\": access_request_rule.id,\n        },\n    )\n    yield access_request_policy\n    try:\n        rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        access_request_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        access_request_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef policy_drp_action(\n    db: Session,\n    oauth_client: ClientDetail,\n    storage_config: StorageConfig,\n) -> Generator:\n    access_request_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"example access request policy drp\",\n            \"key\": \"example_access_request_policy_drp\",\n            \"drp_action\": \"access\",\n            \"client_id\": oauth_client.id,\n        },\n    )\n\n    access_request_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.access.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Access Request Rule DRP\",\n            \"policy_id\": access_request_policy.id,\n            \"storage_destination_id\": storage_config.id,\n        },\n    )\n\n    rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user\").value,\n            \"rule_id\": access_request_rule.id,\n        },\n    )\n    yield access_request_policy\n    try:\n        rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        access_request_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        access_request_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef policy_drp_action_erasure(db: Session, oauth_client: ClientDetail) -> Generator:\n    erasure_request_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"example erasure request policy drp\",\n            \"key\": \"example_erasure_request_policy_drp\",\n            \"drp_action\": \"deletion\",\n            \"client_id\": oauth_client.id,\n        },\n    )\n\n    erasure_request_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.erasure.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"Erasure Request Rule DRP\",\n            \"policy_id\": erasure_request_policy.id,\n            \"masking_strategy\": {\n                \"strategy\": StringRewriteMaskingStrategy.name,\n                \"configuration\": {\"rewrite_value\": \"MASKED\"},\n            },\n        },\n    )\n\n    rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user\").value,\n            \"rule_id\": erasure_request_rule.id,\n        },\n    )\n    yield erasure_request_policy\n    try:\n        rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_request_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_request_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef erasure_policy_string_rewrite(\n    db: Session,\n    oauth_client: ClientDetail,\n    storage_config: StorageConfig,\n) -> Generator:\n    erasure_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"string rewrite policy\",\n            \"key\": \"string_rewrite_policy\",\n            \"client_id\": oauth_client.id,\n        },\n    )\n\n    erasure_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.erasure.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"string rewrite erasure rule\",\n            \"policy_id\": erasure_policy.id,\n            \"masking_strategy\": {\n                \"strategy\": StringRewriteMaskingStrategy.name,\n                \"configuration\": {\"rewrite_value\": \"MASKED\"},\n            },\n        },\n    )\n\n    erasure_rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user.name\").value,\n            \"rule_id\": erasure_rule.id,\n        },\n    )\n\n    yield erasure_policy\n    try:\n        erasure_rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef erasure_policy_hmac(\n    db: Session,\n    oauth_client: ClientDetail,\n    storage_config: StorageConfig,\n) -> Generator:\n    erasure_policy = Policy.create(\n        db=db,\n        data={\n            \"name\": \"hmac policy\",\n            \"key\": \"hmac_policy\",\n            \"client_id\": oauth_client.id,\n        },\n    )\n\n    erasure_rule = Rule.create(\n        db=db,\n        data={\n            \"action_type\": ActionType.erasure.value,\n            \"client_id\": oauth_client.id,\n            \"name\": \"hmac erasure rule\",\n            \"policy_id\": erasure_policy.id,\n            \"masking_strategy\": {\n                \"strategy\": HmacMaskingStrategy.name,\n                \"configuration\": {},\n            },\n        },\n    )\n\n    erasure_rule_target = RuleTarget.create(\n        db=db,\n        data={\n            \"client_id\": oauth_client.id,\n            \"data_category\": DataCategory(\"user.name\").value,\n            \"rule_id\": erasure_rule.id,\n        },\n    )\n\n    yield erasure_policy\n    try:\n        erasure_rule_target.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_rule.delete(db)\n    except ObjectDeletedError:\n        pass\n    try:\n        erasure_policy.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef privacy_requests(db: Session, policy: Policy) -> Generator:\n    privacy_requests = []\n    for count in range(3):\n        privacy_requests.append(\n            PrivacyRequest.create(\n                db=db,\n                data={\n                    \"external_id\": f\"ext-{str(uuid4())}\",\n                    \"started_processing_at\": datetime.utcnow(),\n                    \"requested_at\": datetime.utcnow() - timedelta(days=1),\n                    \"status\": PrivacyRequestStatus.in_processing,\n                    \"origin\": f\"https://example.com/{count}/\",\n                    \"policy_id\": policy.id,\n                    \"client_id\": policy.client_id,\n                },\n            )\n        )\n    yield privacy_requests\n    for pr in privacy_requests:\n        pr.delete(db)\n\n\ndef _create_privacy_request_for_policy(\n    db: Session,\n    policy: Policy,\n    status: PrivacyRequestStatus = PrivacyRequestStatus.in_processing,\n) -> PrivacyRequest:\n    data = {\n        \"external_id\": f\"ext-{str(uuid4())}\",\n        \"requested_at\": datetime(\n            2018,\n            12,\n            31,\n            hour=2,\n            minute=30,\n            second=23,\n            microsecond=916482,\n            tzinfo=timezone.utc,\n        ),\n        \"status\": status,\n        \"origin\": f\"https://example.com/\",\n        \"policy_id\": policy.id,\n        \"client_id\": policy.client_id,\n    }\n    if status != PrivacyRequestStatus.pending:\n        data[\"started_processing_at\"] = datetime(\n            2019,\n            1,\n            1,\n            hour=1,\n            minute=45,\n            second=55,\n            microsecond=393185,\n            tzinfo=timezone.utc,\n        )\n    pr = PrivacyRequest.create(\n        db=db,\n        data=data,\n    )\n    email_identity = \"test@example.com\"\n    identity_kwargs = {\"email\": email_identity}\n    pr.cache_identity(identity_kwargs)\n    pr.persist_identity(\n        db=db,\n        identity=Identity(\n            email=email_identity,\n            phone_number=\"+1 234 567 8910\",\n        ),\n    )\n    return pr\n\n\n@pytest.fixture(scope=\"function\")\ndef privacy_request(db: Session, policy: Policy) -> PrivacyRequest:\n    privacy_request = _create_privacy_request_for_policy(\n        db,\n        policy,\n    )\n    yield privacy_request\n    privacy_request.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef privacy_request_requires_input(db: Session, policy: Policy) -> PrivacyRequest:\n    privacy_request = _create_privacy_request_for_policy(\n        db,\n        policy,\n    )\n    privacy_request.status = PrivacyRequestStatus.requires_input\n    privacy_request.save(db)\n    yield privacy_request\n    privacy_request.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef audit_log(db: Session, privacy_request) -> PrivacyRequest:\n    audit_log = AuditLog.create(\n        db=db,\n        data={\n            \"user_id\": \"system\",\n            \"privacy_request_id\": privacy_request.id,\n            \"action\": AuditLogAction.approved,\n            \"message\": \"\",\n        },\n    )\n    yield audit_log\n    audit_log.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef privacy_request_status_pending(db: Session, policy: Policy) -> PrivacyRequest:\n    privacy_request = _create_privacy_request_for_policy(\n        db,\n        policy,\n        PrivacyRequestStatus.pending,\n    )\n    yield privacy_request\n    privacy_request.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef privacy_request_status_canceled(db: Session, policy: Policy) -> PrivacyRequest:\n    privacy_request = _create_privacy_request_for_policy(\n        db,\n        policy,\n        PrivacyRequestStatus.canceled,\n    )\n    privacy_request.started_processing_at = None\n    privacy_request.save(db)\n    yield privacy_request\n    privacy_request.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef privacy_request_with_drp_action(\n    db: Session, policy_drp_action: Policy\n) -> PrivacyRequest:\n    privacy_request = _create_privacy_request_for_policy(\n        db,\n        policy_drp_action,\n    )\n    yield privacy_request\n    privacy_request.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef succeeded_privacy_request(cache, db: Session, policy: Policy) -> PrivacyRequest:\n    pr = PrivacyRequest.create(\n        db=db,\n        data={\n            \"external_id\": f\"ext-{str(uuid4())}\",\n            \"started_processing_at\": datetime(2021, 10, 1),\n            \"finished_processing_at\": datetime(2021, 10, 3),\n            \"requested_at\": datetime(2021, 10, 1),\n            \"status\": PrivacyRequestStatus.complete,\n            \"origin\": f\"https://example.com/\",\n            \"policy_id\": policy.id,\n            \"client_id\": policy.client_id,\n        },\n    )\n    identity_kwargs = {\"email\": \"email@example.com\"}\n    pr.cache_identity(identity_kwargs)\n    pr.persist_identity(\n        db=db,\n        identity=Identity(**identity_kwargs),\n    )\n    yield pr\n    pr.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef user(db: Session):\n    user = FidesUser.create(\n        db=db,\n        data={\n            \"username\": \"test_fidesops_user\",\n            \"password\": \"TESTdcnG@wzJeu0&%3Qe2fGo7\",\n        },\n    )\n    client = ClientDetail(\n        hashed_secret=\"thisisatest\",\n        salt=\"thisisstillatest\",\n        scopes=SCOPE_REGISTRY,\n        user_id=user.id,\n    )\n\n    FidesUserPermissions.create(\n        db=db, data={\"user_id\": user.id, \"scopes\": [PRIVACY_REQUEST_READ]}\n    )\n\n    db.add(client)\n    db.commit()\n    db.refresh(client)\n    yield user\n    try:\n        client.delete(db)\n    except ObjectDeletedError:\n        pass\n    user.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef failed_privacy_request(db: Session, policy: Policy) -> PrivacyRequest:\n    pr = PrivacyRequest.create(\n        db=db,\n        data={\n            \"external_id\": f\"ext-{str(uuid4())}\",\n            \"started_processing_at\": datetime(2021, 1, 1),\n            \"finished_processing_at\": datetime(2021, 1, 2),\n            \"requested_at\": datetime(2020, 12, 31),\n            \"status\": PrivacyRequestStatus.error,\n            \"origin\": f\"https://example.com/\",\n            \"policy_id\": policy.id,\n            \"client_id\": policy.client_id,\n        },\n    )\n    yield pr\n    pr.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef dataset_config(\n    connection_config: ConnectionConfig,\n    db: Session,\n) -> Generator:\n    dataset_config = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": connection_config.id,\n            \"fides_key\": \"postgres_example_subscriptions_dataset\",\n            \"dataset\": {\n                \"fides_key\": \"postgres_example_subscriptions_dataset\",\n                \"name\": \"Postgres Example Subscribers Dataset\",\n                \"description\": \"Example Postgres dataset created in test fixtures\",\n                \"dataset_type\": \"PostgreSQL\",\n                \"location\": \"postgres_example.test\",\n                \"collections\": [\n                    {\n                        \"name\": \"subscriptions\",\n                        \"fields\": [\n                            {\n                                \"name\": \"id\",\n                                \"data_categories\": [\"system.operations\"],\n                            },\n                            {\n                                \"name\": \"email\",\n                                \"data_categories\": [\"user.contact.email\"],\n                                \"fidesops_meta\": {\n                                    \"identity\": \"email\",\n                                },\n                            },\n                        ],\n                    },\n                ],\n            },\n        },\n    )\n    yield dataset_config\n    dataset_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef dataset_config_preview(\n    connection_config: ConnectionConfig, db: Session\n) -> Generator:\n    dataset_config = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": connection_config.id,\n            \"fides_key\": \"postgres\",\n            \"dataset\": {\n                \"fides_key\": \"postgres\",\n                \"name\": \"Postgres Example Subscribers Dataset\",\n                \"description\": \"Example Postgres dataset created in test fixtures\",\n                \"dataset_type\": \"PostgreSQL\",\n                \"location\": \"postgres_example.test\",\n                \"collections\": [\n                    {\n                        \"name\": \"subscriptions\",\n                        \"fields\": [\n                            {\n                                \"name\": \"id\",\n                                \"data_categories\": [\"system.operations\"],\n                            },\n                            {\n                                \"name\": \"email\",\n                                \"data_categories\": [\"user.contact.email\"],\n                                \"fidesops_meta\": {\n                                    \"identity\": \"email\",\n                                },\n                            },\n                        ],\n                    },\n                ],\n            },\n        },\n    )\n    yield dataset_config\n    dataset_config.delete(db)\n\n\ndef load_dataset(filename: str) -> Dict:\n    yaml_file = load_file([filename])\n    with open(yaml_file, \"r\") as file:\n        return yaml.safe_load(file).get(\"dataset\", [])\n\n\ndef load_dataset_as_string(filename: str) -> str:\n    yaml_file = load_file([filename])\n    with open(yaml_file, \"r\") as file:\n        return file.read()\n\n\n@pytest.fixture\ndef example_datasets() -> List[Dict]:\n    example_datasets = []\n    example_filenames = [\n        \"data/dataset/postgres_example_test_dataset.yml\",\n        \"data/dataset/mongo_example_test_dataset.yml\",\n        \"data/dataset/snowflake_example_test_dataset.yml\",\n        \"data/dataset/redshift_example_test_dataset.yml\",\n        \"data/dataset/mssql_example_test_dataset.yml\",\n        \"data/dataset/mysql_example_test_dataset.yml\",\n        \"data/dataset/mariadb_example_test_dataset.yml\",\n        \"data/dataset/bigquery_example_test_dataset.yml\",\n        \"data/dataset/manual_dataset.yml\",\n        \"data/dataset/email_dataset.yml\",\n    ]\n    for filename in example_filenames:\n        example_datasets += load_dataset(filename)\n    return example_datasets\n\n\n@pytest.fixture\ndef example_yaml_datasets() -> str:\n    example_filename = \"data/dataset/example_test_datasets.yml\"\n    return load_dataset_as_string(example_filename)\n\n\n@pytest.fixture\ndef example_yaml_dataset() -> str:\n    example_filename = \"data/dataset/postgres_example_test_dataset.yml\"\n    return load_dataset_as_string(example_filename)\n\n\n@pytest.fixture\ndef example_invalid_yaml_dataset() -> str:\n    example_filename = \"data/dataset/example_test_dataset.invalid\"\n    return load_dataset_as_string(example_filename)\n\n\n@pytest.fixture(scope=\"function\")\ndef sample_data():\n    return {\n        \"_id\": 12345,\n        \"thread\": [\n            {\n                \"comment\": \"com_0001\",\n                \"message\": \"hello, testing in-flight chat feature\",\n                \"chat_name\": \"John\",\n                \"messages\": {},\n            },\n            {\n                \"comment\": \"com_0002\",\n                \"message\": \"yep, got your message, looks like it works\",\n                \"chat_name\": \"Jane\",\n            },\n            {\"comment\": \"com_0002\", \"message\": \"hello!\", \"chat_name\": \"Jeanne\"},\n        ],\n        \"snacks\": [\"pizza\", \"chips\"],\n        \"seats\": {\"first_choice\": \"A2\", \"second_choice\": \"B3\"},\n        \"upgrades\": {\n            \"magazines\": [\"Time\", \"People\"],\n            \"books\": [\"Once upon a Time\", \"SICP\"],\n            \"earplugs\": True,\n        },\n        \"other_flights\": [\n            {\"DFW\": [\"11 AM\", \"12 PM\"], \"CHO\": [\"12 PM\", \"1 PM\"]},\n            {\"DFW\": [\"2 AM\", \"12 PM\"], \"CHO\": [\"2 PM\", \"1 PM\"]},\n            {\"DFW\": [\"3 AM\", \"2 AM\"], \"CHO\": [\"2 PM\", \"1:30 PM\"]},\n        ],\n        \"months\": {\n            \"july\": [\n                {\n                    \"activities\": [\"swimming\", \"hiking\"],\n                    \"crops\": [\"watermelon\", \"cheese\", \"grapes\"],\n                },\n                {\"activities\": [\"tubing\"], \"crops\": [\"corn\"]},\n            ],\n            \"march\": [\n                {\n                    \"activities\": [\"skiing\", \"bobsledding\"],\n                    \"crops\": [\"swiss chard\", \"swiss chard\"],\n                },\n                {\"activities\": [\"hiking\"], \"crops\": [\"spinach\"]},\n            ],\n        },\n        \"hello\": [1, 2, 3, 4, 2],\n        \"weights\": [[1, 2], [3, 4]],\n        \"toppings\": [[[\"pepperoni\", \"salami\"], [\"pepperoni\", \"cheese\", \"cheese\"]]],\n        \"A\": {\"C\": [{\"M\": [\"p\", \"n\", \"n\"]}]},\n        \"C\": [[\"A\", \"B\", \"C\", \"B\"], [\"G\", \"H\", \"B\", \"B\"]],  # Double lists\n        \"D\": [\n            [[\"A\", \"B\", \"C\", \"B\"], [\"G\", \"H\", \"B\", \"B\"]],\n            [[\"A\", \"B\", \"C\", \"B\"], [\"G\", \"H\", \"B\", \"B\"]],\n        ],  # Triple lists\n        \"E\": [[[\"B\"], [[\"A\", \"B\", \"C\", \"B\"], [\"G\", \"H\", \"B\", \"B\"]]]],  # Irregular lists\n        \"F\": [\n            \"a\",\n            [\"1\", \"a\", [[\"z\", \"a\", \"a\"]]],\n        ],  # Lists elems are different types, not officially supported\n    }\n\n\n@pytest.fixture(scope=\"function\")\ndef application_user(\n    db,\n    oauth_client,\n) -> FidesUser:\n    unique_username = f\"user-{uuid4()}\"\n    user = FidesUser.create(\n        db=db,\n        data={\n            \"username\": unique_username,\n            \"password\": \"test_password\",\n            \"first_name\": \"Test\",\n            \"last_name\": \"User\",\n        },\n    )\n    oauth_client.user_id = user.id\n    oauth_client.save(db=db)\n    yield user\n    user.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef short_redis_cache_expiration() -> FidesopsConfig:\n    original_value: int = config.redis.default_ttl_seconds\n    config.redis.default_ttl_seconds = (\n        1  # Set redis cache to expire very quickly for testing purposes\n    )\n    yield config\n    config.redis.default_ttl_seconds = original_value\n"}
{"type": "test_file", "path": "tests/ops/fixtures/manual_webhook_fixtures.py", "content": "from uuid import uuid4\n\nimport pytest\nfrom sqlalchemy.orm.exc import ObjectDeletedError\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.manual_webhook import AccessManualWebhook\n\n\n@pytest.fixture(scope=\"function\")\ndef integration_manual_webhook_config(db) -> ConnectionConfig:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"manual_webhook_example\",\n            \"connection_type\": ConnectionType.manual_webhook,\n            \"access\": AccessLevel.read,\n        },\n    )\n    yield connection_config\n    try:\n        connection_config.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef access_manual_webhook(db, integration_manual_webhook_config) -> ConnectionConfig:\n    manual_webhook = AccessManualWebhook.create(\n        db=db,\n        data={\n            \"connection_config_id\": integration_manual_webhook_config.id,\n            \"fields\": [\n                {\"pii_field\": \"email\", \"dsr_package_label\": \"email\"},\n                {\"pii_field\": \"Last Name\", \"dsr_package_label\": \"last_name\"},\n            ],\n        },\n    )\n    yield manual_webhook\n    try:\n        manual_webhook.delete(db)\n    except ObjectDeletedError:\n        pass\n\n\n@pytest.fixture(scope=\"function\")\ndef cached_input(privacy_request_requires_input, access_manual_webhook):\n    privacy_request_requires_input.cache_manual_webhook_input(\n        access_manual_webhook,\n        {\"email\": \"customer-1@example.com\", \"last_name\": \"McCustomer\"},\n    )\n"}
{"type": "test_file", "path": "tests/ops/fixtures/mariadb_fixtures.py", "content": "import logging\nfrom typing import Dict, Generator, List\nfrom uuid import uuid4\n\nimport pytest\nimport sqlalchemy\nfrom fideslib.db.session import get_db_engine, get_db_session\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.service.connectors import MariaDBConnector\n\nfrom .application_fixtures import integration_secrets\n\nlogger = logging.getLogger(__name__)\n\n\n@pytest.fixture(scope=\"function\")\ndef connection_config_mariadb(db: Session) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_maria_db_1\",\n            \"connection_type\": ConnectionType.mariadb,\n            \"access\": AccessLevel.write,\n            \"secrets\": integration_secrets[\"mariadb_example\"],\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"session\")\ndef mariadb_example_db() -> Generator:\n    \"\"\"Return a connection to the MariaDB example DB\"\"\"\n    example_mariadb_uri = (\n        \"mariadb+pymysql://mariadb_user:mariadb_pw@mariadb_example/mariadb_example\"\n    )\n    engine = get_db_engine(database_uri=example_mariadb_uri)\n    logger.debug(f\"Connecting to MariaDB example database at: {engine.url}\")\n    SessionLocal = get_db_session(\n        config=config,\n        engine=engine,\n        autocommit=True,\n        autoflush=True,\n    )\n    the_session = SessionLocal()\n    # Setup above...\n    yield the_session\n    # Teardown below...\n    the_session.close()\n    engine.dispose()\n\n\n@pytest.fixture\ndef mariadb_example_test_dataset_config(\n    connection_config_mariadb: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    mariadb_dataset = example_datasets[6]\n    fides_key = mariadb_dataset[\"fides_key\"]\n    connection_config_mariadb.name = fides_key\n    connection_config_mariadb.key = fides_key\n    connection_config_mariadb.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": connection_config_mariadb.id,\n            \"fides_key\": fides_key,\n            \"dataset\": mariadb_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef mariadb_integration_session(connection_config_mariadb):\n    example_mariadb_uri = MariaDBConnector(connection_config_mariadb).build_uri()\n    engine = get_db_engine(database_uri=example_mariadb_uri)\n    SessionLocal = get_db_session(\n        config=config,\n        engine=engine,\n        autocommit=True,\n        autoflush=True,\n    )\n    yield SessionLocal()\n\n\ndef truncate_all_tables(db_session):\n    tables = [\n        \"report\",\n        \"service_request\",\n        \"login\",\n        \"visit\",\n        \"order_item\",\n        \"orders\",\n        \"payment_card\",\n        \"employee\",\n        \"customer\",\n        \"address\",\n        \"product\",\n    ]\n    [db_session.execute(f\"TRUNCATE TABLE {table};\") for table in tables]\n\n\n@pytest.fixture(scope=\"function\")\ndef mariadb_integration_db(mariadb_integration_session):\n    truncate_all_tables(mariadb_integration_session)\n    with open(\"./docker/sample_data/mariadb_example_data.sql\", \"r\") as query_file:\n        lines = query_file.read().splitlines()\n        filtered = [line for line in lines if not line.startswith(\"--\")]\n        queries = \" \".join(filtered).split(\";\")\n        [\n            mariadb_integration_session.execute(f\"{sqlalchemy.text(query.strip())};\")\n            for query in queries\n            if query\n        ]\n    yield mariadb_integration_session\n    truncate_all_tables(mariadb_integration_session)\n"}
{"type": "test_file", "path": "tests/ops/fixtures/mongodb_fixtures.py", "content": "from typing import Generator\nfrom uuid import uuid4\n\nimport pytest\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.policy import ActionType\nfrom fidesops.ops.models.privacy_request import (\n    ExecutionLog,\n    ExecutionLogStatus,\n    PrivacyRequest,\n)\n\nfrom .application_fixtures import integration_secrets\n\n\n@pytest.fixture(scope=\"function\")\ndef mongo_connection_config(db: Session) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_mongo_db_1\",\n            \"connection_type\": ConnectionType.mongodb,\n            \"access\": AccessLevel.write,\n            \"secrets\": integration_secrets[\"mongo_example\"],\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef mongo_execution_log(\n    db: Session,\n    privacy_request: PrivacyRequest,\n) -> ExecutionLog:\n    el = ExecutionLog.create(\n        db=db,\n        data={\n            \"dataset_name\": \"my-mongo-db\",\n            \"collection_name\": \"orders\",\n            \"fields_affected\": [\n                {\n                    \"path\": \"my-mongo-db:orders:name\",\n                    \"field_name\": \"name\",\n                    \"data_categories\": [\"user.contact.name\"],\n                }\n            ],\n            \"action_type\": ActionType.access,\n            \"status\": ExecutionLogStatus.in_processing,\n            \"privacy_request_id\": privacy_request.id,\n        },\n    )\n    yield el\n    el.delete(db)\n"}
{"type": "test_file", "path": "tests/ops/fixtures/mssql_fixtures.py", "content": "import logging\nfrom typing import Dict, Generator, List\nfrom uuid import uuid4\n\nimport pytest\nfrom fideslib.db.session import get_db_engine, get_db_session\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.service.connectors import MicrosoftSQLServerConnector\n\nfrom .application_fixtures import integration_secrets\n\nlogger = logging.getLogger(__name__)\n\n\n@pytest.fixture\ndef mssql_example_test_dataset_config(\n    connection_config_mssql: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    mssql_dataset = example_datasets[4]\n    fides_key = mssql_dataset[\"fides_key\"]\n    connection_config_mssql.name = fides_key\n    connection_config_mssql.key = fides_key\n    connection_config_mssql.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": connection_config_mssql.id,\n            \"fides_key\": fides_key,\n            \"dataset\": mssql_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef connection_config_mssql(db: Session) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_mssql_db_1\",\n            \"connection_type\": ConnectionType.mssql,\n            \"access\": AccessLevel.write,\n            \"secrets\": integration_secrets[\"mssql_example\"],\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef mssql_integration_session_cls(connection_config_mssql):\n    uri = MicrosoftSQLServerConnector(connection_config_mssql).build_uri()\n    engine = get_db_engine(database_uri=uri)\n    SessionLocal = get_db_session(\n        config=config,\n        engine=engine,\n        autocommit=True,\n        autoflush=True,\n    )\n    yield SessionLocal\n\n\n@pytest.fixture(scope=\"function\")\ndef mssql_integration_session(mssql_integration_session_cls):\n    yield mssql_integration_session_cls()\n\n\ndef truncate_all_tables(mssql_integration_session):\n    tables = [\n        \"dbo.product\",\n        \"dbo.customer\",\n        \"dbo.employee\",\n        \"dbo.address\",\n        \"dbo.customer\",\n        \"dbo.employee\",\n        \"dbo.payment_card\",\n        \"dbo.orders\",\n        \"dbo.order_item\",\n        \"dbo.visit\",\n        \"dbo.login\",\n        \"dbo.service_request\",\n        \"dbo.report\",\n        \"dbo.type_link_test\",\n        \"dbo.composite_pk_test\",\n    ]\n    [mssql_integration_session.execute(f\"DELETE FROM {table};\") for table in tables]\n\n\n@pytest.fixture(scope=\"function\")\ndef mssql_integration_db(mssql_integration_session):\n    truncate_all_tables(mssql_integration_session)\n    statements = [\n        \"INSERT INTO dbo.product VALUES (1, 'Example Product 1', '$10.00'), (2, 'Example Product 2', '$20.00'), (3, 'Example Product 3', '$50.00');\",\n        \"INSERT INTO dbo.address VALUES (1, '123', 'Example Street', 'Exampletown', 'NY', '12345'), (2, '4', 'Example Lane', 'Exampletown', 'NY', '12321'), (3, '555', 'Example Ave', 'Example City', 'NY', '12000'), (4, '1111', 'Example Place', 'Example Mountain', 'TX', '54321');\",\n        \"INSERT INTO dbo.customer VALUES (1, 'customer-1@example.com', 'John Customer', '2020-04-01 11:47:42', 1), (2, 'customer-2@example.com', 'Jill Customer', '2020-04-01 11:47:42', 2), (3, 'jane@example.com', 'Jane Customer', '2020-04-01 11:47:42', 4);\",\n        \"INSERT INTO dbo.employee VALUES (1, 'employee-1@example.com', 'Jack Employee', 3), (2, 'employee-2@example.com', 'Jane Employee', 3);\",\n        \"INSERT INTO dbo.payment_card VALUES ('pay_aaa-aaa', 'Example Card 1', 123456789, 321, 1, 1, 1), ('pay_bbb-bbb', 'Example Card 2', 987654321, 123, 0, 2, 1), ('pay_ccc-ccc', 'Example Card 3', 373719391, 222, 0, 3, 4);\",\n        \"INSERT INTO dbo.orders VALUES ('ord_aaa-aaa', 1, 2, 'pay_aaa-aaa'), ('ord_bbb-bbb', 2, 1, 'pay_bbb-bbb'), ('ord_ccc-ccc', 1, 1, 'pay_aaa-aaa'), ('ord_ddd-ddd', 1, 1, 'pay_bbb-bbb'), ('ord_ddd-eee', 3, 4, 'pay-ccc-ccc');\",\n        \"INSERT INTO dbo.order_item VALUES ('ord_aaa-aaa', 1, 1, 1), ('ord_bbb-bbb', 1, 1, 1), ('ord_ccc-ccc', 1, 1, 1), ('ord_ccc-ccc', 2, 2, 1), ('ord_ddd-ddd', 1, 1, 1), ('ord_eee-eee', 3, 4, 3);\",\n        \"INSERT INTO dbo.visit VALUES ('customer-1@example.com', '2021-01-06 01:00:00'), ('customer-2@example.com', '2021-01-06 01:00:00');\",\n        \"INSERT INTO dbo.login VALUES (1, 1, '2021-01-01 01:00:00'), (2, 1, '2021-01-02 01:00:00'), (3, 1, '2021-01-03 01:00:00'), (4, 1, '2021-01-04 01:00:00'), (5, 1, '2021-01-05 01:00:00'), (6, 1, '2021-01-06 01:00:00'), (7, 2, '2021-01-06 01:00:00'), (8, 3, '2021-01-06 01:00:00');\",\n        \"INSERT INTO dbo.service_request VALUES ('ser_aaa-aaa', 'customer-1@example.com', 'customer-1-alt@example.com', '2021-01-01', '2021-01-03', 1), ('ser_bbb-bbb', 'customer-2@example.com', null, '2021-01-04', null, 1), ('ser_ccc-ccc', 'customer-3@example.com', null, '2021-01-05', '2020-01-07', 1), ('ser_ddd-ddd', 'customer-3@example.com', null, '2021-05-05', '2020-05-08', 2);\",\n        \"INSERT INTO dbo.report VALUES (1, 'admin-account@example.com', 'Monthly Report', 2021, 8, 100), (2, 'admin-account@example.com', 'Monthly Report', 2021, 9, 100), (3, 'admin-account@example.com', 'Monthly Report', 2021, 10, 100), (4, 'admin-account@example.com', 'Monthly Report', 2021, 11, 100);\",\n        \"INSERT INTO dbo.type_link_test VALUES ('1', 'name1'), ('2', 'name2');\",\n        \"INSERT INTO dbo.composite_pk_test VALUES (1,10,'linked to customer 1',1), (1,11,'linked to customer 2',2), (2,10,'linked to customer 3',3);\",\n    ]\n    [mssql_integration_session.execute(stmt) for stmt in statements]\n    yield mssql_integration_session\n    truncate_all_tables(mssql_integration_session)\n"}
{"type": "test_file", "path": "tests/ops/fixtures/postgres_fixtures.py", "content": "import logging\nfrom typing import Dict, Generator, List\nfrom uuid import uuid4\n\nimport pytest\nfrom fideslib.db.session import get_db_engine, get_db_session\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.sql import text\nfrom sqlalchemy_utils.functions import create_database, database_exists, drop_database\n\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.models.policy import ActionType\nfrom fidesops.ops.models.privacy_request import (\n    ExecutionLog,\n    ExecutionLogStatus,\n    PrivacyRequest,\n)\nfrom fidesops.ops.service.connectors import PostgreSQLConnector\n\nfrom .application_fixtures import integration_secrets\n\nlogger = logging.getLogger(__name__)\n\n\n@pytest.fixture\ndef postgres_example_test_dataset_config(\n    connection_config: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    postgres_dataset = example_datasets[0]\n    fides_key = postgres_dataset[\"fides_key\"]\n    connection_config.name = fides_key\n    connection_config.key = fides_key\n    connection_config.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": connection_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": postgres_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture\ndef postgres_example_test_dataset_config_read_access(\n    read_connection_config: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    postgres_dataset = example_datasets[0]\n    fides_key = postgres_dataset[\"fides_key\"]\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": read_connection_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": postgres_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef postgres_execution_log(\n    db: Session,\n    privacy_request: PrivacyRequest,\n) -> ExecutionLog:\n    el = ExecutionLog.create(\n        db=db,\n        data={\n            \"dataset_name\": \"my-postgres-db\",\n            \"collection_name\": \"user\",\n            \"fields_affected\": [\n                {\n                    \"path\": \"my-postgres-db:user:email\",\n                    \"field_name\": \"email\",\n                    \"data_categories\": [\"user.contact.email\"],\n                }\n            ],\n            \"action_type\": ActionType.access,\n            \"status\": ExecutionLogStatus.pending,\n            \"privacy_request_id\": privacy_request.id,\n        },\n    )\n    yield el\n    el.delete(db)\n\n\n# TODO: Consolidate these\n@pytest.fixture(scope=\"function\")\ndef second_postgres_execution_log(\n    db: Session, privacy_request: PrivacyRequest\n) -> ExecutionLog:\n    el = ExecutionLog.create(\n        db=db,\n        data={\n            \"dataset_name\": \"my-postgres-db\",\n            \"collection_name\": \"address\",\n            \"fields_affected\": [\n                {\n                    \"path\": \"my-postgres-db:address:street\",\n                    \"field_name\": \"street\",\n                    \"data_categories\": [\"user.contact.address.street\"],\n                },\n                {\n                    \"path\": \"my-postgres-db:address:city\",\n                    \"field_name\": \"city\",\n                    \"data_categories\": [\"user.contact.address.city\"],\n                },\n            ],\n            \"action_type\": ActionType.access,\n            \"status\": ExecutionLogStatus.error,\n            \"privacy_request_id\": privacy_request.id,\n            \"message\": \"Database timed out.\",\n        },\n    )\n    yield el\n    el.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef connection_config(\n    db: Session,\n) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_postgres_db_1\",\n            \"connection_type\": ConnectionType.postgres,\n            \"access\": AccessLevel.write,\n            \"secrets\": integration_secrets[\"postgres_example\"],\n            \"disabled\": False,\n            \"description\": \"Primary postgres connection\",\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef disabled_connection_config(\n    db: Session,\n) -> Generator:\n    disabled_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"disabled_postgres_connection\",\n            \"connection_type\": ConnectionType.postgres,\n            \"access\": AccessLevel.read,\n            \"secrets\": integration_secrets[\"postgres_example\"],\n            \"disabled\": True,\n            \"description\": \"Old postgres connection\",\n        },\n    )\n    yield connection_config\n    disabled_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef read_connection_config(\n    db: Session,\n) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_postgres_db_1_read_config\",\n            \"connection_type\": ConnectionType.postgres,\n            \"access\": AccessLevel.read,\n            \"secrets\": integration_secrets[\"postgres_example\"],\n            \"description\": \"Read-only connection config\",\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef postgres_connection_config_with_schema(\n    db: Session,\n) -> Generator:\n    \"\"\"Create a connection config with a db_schema set which allows the PostgresConnector to connect\n    to a non-default schema\"\"\"\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_postgres_db_backup_schema\",\n            \"connection_type\": ConnectionType.postgres,\n            \"access\": AccessLevel.write,\n            \"secrets\": integration_secrets[\"postgres_example\"],\n            \"disabled\": False,\n            \"description\": \"Backup postgres data\",\n        },\n    )\n    connection_config.secrets[\n        \"db_schema\"\n    ] = \"backup_schema\"  # Matches the second schema created in postgres_example.schema\n    connection_config.save(db)\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef postgres_integration_session_cls(connection_config):\n    example_postgres_uri = PostgreSQLConnector(connection_config).build_uri()\n    engine = get_db_engine(database_uri=example_postgres_uri)\n    SessionLocal = get_db_session(\n        config=config,\n        engine=engine,\n        autocommit=True,\n        autoflush=True,\n    )\n    yield SessionLocal\n\n\n@pytest.fixture(scope=\"function\")\ndef postgres_integration_session(postgres_integration_session_cls):\n    yield postgres_integration_session_cls()\n\n\n@pytest.fixture(scope=\"function\")\ndef postgres_integration_db(postgres_integration_session):\n    if database_exists(postgres_integration_session.bind.url):\n        # Postgres cannot drop databases from within a transaction block, so\n        # we should drop the DB this way instead\n        drop_database(postgres_integration_session.bind.url)\n    create_database(postgres_integration_session.bind.url)\n    with open(\"./docker/sample_data/postgres_example.sql\", \"r\") as query_file:\n        lines = query_file.read().splitlines()\n        filtered = [line for line in lines if not line.startswith(\"--\")]\n        queries = \" \".join(filtered).split(\";\")\n        [\n            postgres_integration_session.execute(f\"{text(query.strip())};\")\n            for query in queries\n            if query\n        ]\n    yield postgres_integration_session\n    drop_database(postgres_integration_session.bind.url)\n"}
{"type": "test_file", "path": "tests/ops/fixtures/redshift_fixtures.py", "content": "import os\nfrom typing import Dict, Generator, List\nfrom uuid import uuid4\n\nimport pytest\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.schemas.connection_configuration.connection_secrets_redshift import (\n    RedshiftSchema,\n)\n\nfrom .application_fixtures import integration_config\n\n\n@pytest.fixture(scope=\"function\")\ndef redshift_connection_config(db: Session) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_redshift_config\",\n            \"connection_type\": ConnectionType.redshift,\n            \"access\": AccessLevel.write,\n        },\n    )\n    uri = integration_config.get(\"redshift\", {}).get(\"external_uri\") or os.environ.get(\n        \"REDSHIFT_TEST_URI\"\n    )\n    db_schema = integration_config.get(\"redshift\", {}).get(\n        \"db_schema\"\n    ) or os.environ.get(\"REDSHIFT_TEST_DB_SCHEMA\")\n    if uri and db_schema:\n        schema = RedshiftSchema(url=uri, db_schema=db_schema)\n        connection_config.secrets = schema.dict()\n        connection_config.save(db=db)\n\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture\ndef redshift_example_test_dataset_config(\n    redshift_connection_config: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    dataset = example_datasets[3]\n    fides_key = dataset[\"fides_key\"]\n    dataset_config = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": redshift_connection_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": dataset,\n        },\n    )\n    yield dataset_config\n    dataset_config.delete(db=db)\n"}
{"type": "test_file", "path": "tests/ops/fixtures/saas/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/ops/fixtures/mysql_fixtures.py", "content": "import logging\nfrom typing import Dict, Generator, List\nfrom uuid import uuid4\n\nimport pytest\nfrom fideslib.db.session import get_db_engine, get_db_session\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.service.connectors import MySQLConnector\n\nfrom .application_fixtures import integration_secrets\n\nlogger = logging.getLogger(__name__)\n\n\n@pytest.fixture(scope=\"function\")\ndef dataset_config_mysql(\n    connection_config: ConnectionConfig,\n    db: Session,\n) -> Generator:\n    dataset_config = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": connection_config.id,\n            \"fides_key\": \"mysql_example_subscriptions_dataset\",\n            \"dataset\": {\n                \"fides_key\": \"mysql_example_subscriptions_dataset\",\n                \"name\": \"Mysql Example Subscribers Dataset\",\n                \"description\": \"Example Mysql dataset created in test fixtures\",\n                \"dataset_type\": \"MySQL\",\n                \"location\": \"mysql_example.test\",\n                \"collections\": [\n                    {\n                        \"name\": \"subscriptions\",\n                        \"fields\": [\n                            {\n                                \"name\": \"id\",\n                                \"data_categories\": [\"system.operations\"],\n                            },\n                            {\n                                \"name\": \"email\",\n                                \"data_categories\": [\"user.contact.email\"],\n                                \"fidesops_meta\": {\n                                    \"identity\": \"email\",\n                                },\n                            },\n                        ],\n                    },\n                ],\n            },\n        },\n    )\n    yield dataset_config\n    dataset_config.delete(db)\n\n\n# TODO: Consolidate these\n@pytest.fixture\ndef mysql_example_test_dataset_config(\n    connection_config_mysql: ConnectionConfig,\n    db: Session,\n    example_datasets: List[Dict],\n) -> Generator:\n    mysql_dataset = example_datasets[5]\n    fides_key = mysql_dataset[\"fides_key\"]\n    connection_config_mysql.name = fides_key\n    connection_config_mysql.key = fides_key\n    connection_config_mysql.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": connection_config_mysql.id,\n            \"fides_key\": fides_key,\n            \"dataset\": mysql_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef connection_config_mysql(db: Session) -> Generator:\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"name\": str(uuid4()),\n            \"key\": \"my_mysql_db_1\",\n            \"connection_type\": ConnectionType.mysql,\n            \"access\": AccessLevel.write,\n            \"secrets\": integration_secrets[\"mysql_example\"],\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture(scope=\"function\")\ndef mysql_integration_session_cls(connection_config_mysql):\n    example_postgres_uri = MySQLConnector(connection_config_mysql).build_uri()\n    engine = get_db_engine(database_uri=example_postgres_uri)\n    SessionLocal = get_db_session(\n        config=config,\n        engine=engine,\n        autocommit=True,\n        autoflush=True,\n    )\n    yield SessionLocal\n\n\n@pytest.fixture(scope=\"function\")\ndef mysql_integration_session(mysql_integration_session_cls):\n    yield mysql_integration_session_cls()\n\n\ndef truncate_all_tables(mysql_integration_session):\n    tables = [\n        \"product\",\n        \"customer\",\n        \"employee\",\n        \"address\",\n        \"customer\",\n        \"employee\",\n        \"payment_card\",\n        \"orders\",\n        \"order_item\",\n        \"visit\",\n        \"login\",\n        \"service_request\",\n        \"report\",\n    ]\n    [mysql_integration_session.execute(f\"TRUNCATE TABLE {table};\") for table in tables]\n\n\n@pytest.fixture(scope=\"function\")\ndef mysql_integration_db(mysql_integration_session):\n    truncate_all_tables(mysql_integration_session)\n    statements = [\n        \"\"\"\n        INSERT INTO product VALUES\n        (1, 'Example Product 1', 10.00),\n        (2, 'Example Product 2', 20.00),\n        (3, 'Example Product 3', 50.00);\n        \"\"\",\n        \"\"\"\n        INSERT INTO address VALUES\n        (1, '123', 'Example Street', 'Exampletown', 'NY', '12345'),\n        (2, '4', 'Example Lane', 'Exampletown', 'NY', '12321'),\n        (3, '555', 'Example Ave', 'Example City', 'NY', '12000');\n        \"\"\",\n        \"\"\"\n        INSERT INTO customer VALUES\n        (1, 'customer-1@example.com', 'John Customer', '2020-04-01 11:47:42', 1),\n        (2, 'customer-2@example.com', 'Jill Customer', '2020-04-01 11:47:42', 2);\n        \"\"\",\n        \"\"\"\n        INSERT INTO employee VALUES\n        (1, 'employee-1@example.com', 'Jack Employee', 3),\n        (2, 'employee-2@example.com', 'Jane Employee', 3);\n        \"\"\",\n        \"\"\"\n        INSERT INTO payment_card VALUES\n        ('pay_aaa-aaa', 'Example Card 1', 123456789, 321, true, 1, 1),\n        ('pay_bbb-bbb', 'Example Card 2', 987654321, 123, false, 2, 1);\n        \"\"\",\n        \"\"\"\n        INSERT INTO orders VALUES\n        ('ord_aaa-aaa', 1, 2, 'pay_aaa-aaa'),\n        ('ord_bbb-bbb', 2, 1, 'pay_bbb-bbb'),\n        ('ord_ccc-ccc', 1, 1, 'pay_aaa-aaa'),\n        ('ord_ddd-ddd', 1, 1, 'pay_bbb-bbb');\n        \"\"\",\n        \"\"\"\n        INSERT INTO order_item VALUES\n        ('ord_aaa-aaa', 1, 1, 1),\n        ('ord_bbb-bbb', 1, 1, 1),\n        ('ord_ccc-ccc', 1, 1, 1),\n        ('ord_ccc-ccc', 2, 2, 1),\n        ('ord_ddd-ddd', 1, 1, 1);\n        \"\"\",\n        \"\"\"\n        INSERT INTO visit VALUES\n        ('customer-1@example.com', '2021-01-06 01:00:00'),\n        ('customer-2@example.com', '2021-01-06 01:00:00');\n        \"\"\",\n        \"\"\"\n        INSERT INTO login VALUES\n        (1, 1, '2021-01-01 01:00:00'),\n        (2, 1, '2021-01-02 01:00:00'),\n        (3, 1, '2021-01-03 01:00:00'),\n        (4, 1, '2021-01-04 01:00:00'),\n        (5, 1, '2021-01-05 01:00:00'),\n        (6, 1, '2021-01-06 01:00:00'),\n        (7, 2, '2021-01-06 01:00:00');\n        \"\"\",\n        \"\"\"\n        INSERT INTO service_request VALUES\n        ('ser_aaa-aaa', 'customer-1@example.com', 'customer-1-alt@example.com', '2021-01-01', '2021-01-03', 1),\n        ('ser_bbb-bbb', 'customer-2@example.com', null, '2021-01-04', null, 1),\n        ('ser_ccc-ccc', 'customer-3@example.com', null, '2021-01-05', '2020-01-07', 1),\n        ('ser_ddd-ddd', 'customer-3@example.com', null, '2021-05-05', '2020-05-08', 2);\n        \"\"\",\n        \"\"\"\n        INSERT INTO report VALUES\n        (1, 'admin-account@example.com', 'Monthly Report', 2021, 8, 100),\n        (2, 'admin-account@example.com', 'Monthly Report', 2021, 9, 100),\n        (3, 'admin-account@example.com', 'Monthly Report', 2021, 10, 100),\n        (4, 'admin-account@example.com', 'Monthly Report', 2021, 11, 100);\n        \"\"\",\n    ]\n    [mysql_integration_session.execute(stmt) for stmt in statements]\n    yield mysql_integration_session\n    truncate_all_tables(mysql_integration_session)\n"}
{"type": "test_file", "path": "tests/ops/fixtures/saas/adobe_campaign_fixtures.py", "content": "from typing import Any, Dict, Generator\n\nimport pydash\nimport pytest\nimport requests\nfrom fideslib.cryptography import cryptographic_util\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.util.saas_util import (\n    load_config_with_replacement,\n    load_dataset_with_replacement,\n)\nfrom tests.ops.test_helpers.vault_client import get_secrets\n\nsecrets = get_secrets(\"adobe_campaign\")\n\n\n@pytest.fixture(scope=\"function\")\ndef adobe_campaign_secrets(saas_config):\n    return {\n        \"domain\": pydash.get(saas_config, \"adobe_campaign.domain\") or secrets[\"domain\"],\n        \"organization_id\": pydash.get(saas_config, \"adobe_campaign.organization_id\")\n        or secrets[\"organization_id\"],\n        \"namespace\": pydash.get(saas_config, \"adobe_campaign.namespace\")\n        or secrets[\"namespace\"],\n        \"regulation\": pydash.get(saas_config, \"adobe_campaign.regulation\")\n        or secrets[\"regulation\"],\n        \"client_id\": pydash.get(saas_config, \"adobe_campaign.client_id\")\n        or secrets[\"client_id\"],\n        \"access_token\": pydash.get(saas_config, \"adobe_campaign.access_token\")\n        or secrets[\"access_token\"],\n    }\n\n\n@pytest.fixture(scope=\"function\")\ndef adobe_campaign_identity_email(saas_config):\n    return (\n        pydash.get(saas_config, \"adobe_campaign.identity_email\")\n        or secrets[\"identity_email\"]\n    )\n\n\n@pytest.fixture(scope=\"function\")\ndef adobe_campaign_erasure_identity_email() -> str:\n    return f\"{cryptographic_util.generate_secure_random_string(13)}@email.com\"\n\n\n@pytest.fixture\ndef adobe_campaign_config() -> Dict[str, Any]:\n    return load_config_with_replacement(\n        \"data/saas/config/adobe_campaign_config.yml\",\n        \"<instance_fides_key>\",\n        \"adobe_campaign_instance\",\n    )\n\n\n@pytest.fixture\ndef adobe_campaign_dataset() -> Dict[str, Any]:\n    return load_dataset_with_replacement(\n        \"data/saas/dataset/adobe_campaign_dataset.yml\" \"<instance_fides_key>\",\n        \"adobe_campaign_instance\",\n    )[0]\n\n\n@pytest.fixture(scope=\"function\")\ndef adobe_campaign_connection_config(\n    db: Session, adobe_campaign_config, adobe_campaign_secrets\n) -> Generator:\n    fides_key = adobe_campaign_config[\"fides_key\"]\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"key\": fides_key,\n            \"name\": fides_key,\n            \"connection_type\": ConnectionType.saas,\n            \"access\": AccessLevel.write,\n            \"secrets\": adobe_campaign_secrets,\n            \"saas_config\": adobe_campaign_config,\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture\ndef adobe_campaign_dataset_config(\n    db: Session,\n    adobe_campaign_connection_config: ConnectionConfig,\n    adobe_campaign_dataset: Dict[str, Any],\n) -> Generator:\n    fides_key = adobe_campaign_dataset[\"fides_key\"]\n    adobe_campaign_connection_config.name = fides_key\n    adobe_campaign_connection_config.key = fides_key\n    adobe_campaign_connection_config.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": adobe_campaign_connection_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": adobe_campaign_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef adobe_campaign_erasure_data(\n    adobe_campaign_connection_config: ConnectionConfig,\n    adobe_campaign_erasure_identity_email: str,\n) -> None:\n\n    secrets = adobe_campaign_connection_config.secrets\n    base_url = f\"https://{secrets['domain']}/{secrets['organization_id']}\"\n    headers = {\n        \"Authorization\": f\"Bearer {secrets['access_token']}\",\n        \"X-Api-Key\": secrets[\"client_id\"],\n    }\n\n    # Create profile\n    profile_data = {\"email\": adobe_campaign_erasure_identity_email}\n    profile_response = requests.post(\n        url=f\"{base_url}/campaign/profileAndServices/profile\",\n        headers=headers,\n        json=profile_data,\n    )\n    assert profile_response.ok\n"}
{"type": "test_file", "path": "tests/ops/fixtures/saas/auth0_fixtures.py", "content": "from typing import Any, Dict, Generator\n\nimport pydash\nimport pytest\nimport requests\nfrom fideslib.cryptography import cryptographic_util\nfrom fideslib.db import session\nfrom sqlalchemy.orm import Session\nfrom starlette.status import HTTP_204_NO_CONTENT\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.util.saas_util import (\n    load_config_with_replacement,\n    load_dataset_with_replacement,\n)\nfrom tests.ops.test_helpers.saas_test_utils import poll_for_existence\nfrom tests.ops.test_helpers.vault_client import get_secrets\n\nsecrets = get_secrets(\"auth0\")\n\n\n@pytest.fixture(scope=\"function\")\ndef auth0_secrets(saas_config):\n    return {\n        \"domain\": pydash.get(saas_config, \"auth0.domain\") or secrets[\"domain\"],\n        \"access_token\": pydash.get(saas_config, \"auth0.access_token\")\n        or secrets[\"access_token\"],\n    }\n\n\n@pytest.fixture(scope=\"function\")\ndef auth0_identity_email(saas_config):\n    return pydash.get(saas_config, \"auth0.identity_email\") or secrets[\"identity_email\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef auth0_erasure_identity_email():\n    return f\"{cryptographic_util.generate_secure_random_string(13)}@email.com\"\n\n\n@pytest.fixture\ndef auth0_config() -> Dict[str, Any]:\n    return load_config_with_replacement(\n        \"data/saas/config/auth0_config.yml\", \"<instance_fides_key>\", \"auth_0_instance\"\n    )\n\n\n@pytest.fixture\ndef auth0_dataset() -> Dict[str, Any]:\n    return load_dataset_with_replacement(\n        \"data/saas/dataset/auth0_dataset.yml\", \"<instance_fides_key>\", \"auth_0_instance\"\n    )[0]\n\n\n@pytest.fixture(scope=\"function\")\ndef auth0_connection_config(db: session, auth0_config, auth0_secrets) -> Generator:\n    fides_key = auth0_config[\"fides_key\"]\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"key\": fides_key,\n            \"name\": fides_key,\n            \"connection_type\": ConnectionType.saas,\n            \"access\": AccessLevel.write,\n            \"secrets\": auth0_secrets,\n            \"saas_config\": auth0_config,\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture\ndef auth0_dataset_config(\n    db: Session,\n    auth0_connection_config: ConnectionConfig,\n    auth0_dataset: Dict[str, Any],\n) -> Generator:\n    fides_key = auth0_dataset[\"fides_key\"]\n    auth0_connection_config.name = fides_key\n    auth0_connection_config.key = fides_key\n    auth0_connection_config.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": auth0_connection_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": auth0_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef auth0_access_data(\n    auth0_connection_config, auth0_identity_email, auth0_secrets\n) -> Generator:\n    \"\"\"\n    Updates user password to have some data in user_logs\n    \"\"\"\n\n    base_url = f\"https://{auth0_secrets['domain']}\"\n\n    headers = {\"Authorization\": f\"Bearer {auth0_secrets['access_token']}\"}\n    user_response = requests.get(\n        url=f\"{base_url}/api/v2/users-by-email?email={auth0_identity_email}\",\n        headers=headers,\n    )\n    assert user_response.ok\n    user = user_response.json()\n    user_id = user[0][\"user_id\"]\n\n    body = {\n        \"connection\": \"Username-Password-Authentication\",\n        \"password\": f\"pass+{cryptographic_util.generate_secure_random_string(8)}+test\",\n    }\n    users_response = requests.patch(\n        url=f\"{base_url}/api/v2/users/{user_id}\", json=body, headers=headers\n    )\n    assert users_response.ok\n\n    yield user\n\n\n@pytest.fixture(scope=\"function\")\ndef auth0_erasure_data(\n    auth0_connection_config, auth0_erasure_identity_email, auth0_secrets\n) -> Generator:\n    \"\"\"\n    Creates a dynamic test data record for erasure tests.\n    Yields user ID as this may be useful to have in test scenarios\n    \"\"\"\n\n    base_url = f\"https://{auth0_secrets['domain']}\"\n    # Create user\n    body = {\n        \"email\": auth0_erasure_identity_email,\n        \"blocked\": False,\n        \"email_verified\": False,\n        \"app_metadata\": {},\n        \"given_name\": \"John\",\n        \"family_name\": \"Doe\",\n        \"name\": \"John Doe\",\n        \"nickname\": \"Johnny\",\n        \"picture\": \"https://secure.gravatar.com/avatar/15626c5e0c749cb912f9d1ad48dba440?s=480&r=pg&d=https%3A%2F%2Fssl.gstatic.com%2Fs2%2Fprofiles%2Fimages%2Fsilhouette80.png\",\n        \"connection\": \"Username-Password-Authentication\",\n        \"password\": \"P@ssword123\",\n        \"verify_email\": False,\n    }\n    headers = {\"Authorization\": f\"Bearer {auth0_secrets['access_token']}\"}\n    users_response = requests.post(\n        url=f\"{base_url}/api/v2/users\", json=body, headers=headers\n    )\n    user = users_response.json()\n    assert users_response.ok\n    error_message = (\n        f\"User with email {auth0_erasure_identity_email} could not be added to auth0\"\n    )\n    poll_for_existence(\n        _user_exists,\n        (auth0_erasure_identity_email, auth0_secrets),\n        error_message=error_message,\n    )\n    yield user\n\n    user_id = user[\"user_id\"]\n    # Deleting user after verifying update request\n    user_delete_response = requests.delete(\n        url=f\"{base_url}/api/v2/users/{user_id}\",\n        headers=headers,\n    )\n    # we expect 204 if user doesn't exist\n    assert user_delete_response.status_code == HTTP_204_NO_CONTENT\n\n\ndef _user_exists(auth0_erasure_identity_email: str, auth0_secrets):\n    \"\"\"\n    Confirm whether user exists by calling user search by email api and comparing resulting firstname str.\n    Returns user ID if it exists, returns None if it does not.\n    \"\"\"\n    base_url = f\"https://{auth0_secrets['domain']}\"\n    headers = {\n        \"Authorization\": f\"Bearer {auth0_secrets['access_token']}\",\n    }\n\n    user_response = requests.get(\n        url=f\"{base_url}/api/v2/users-by-email?email={auth0_erasure_identity_email}\",\n        headers=headers,\n    )\n\n    # we expect 404 if user doesn't exist\n    if 404 == user_response.status_code:\n        return None\n\n    return user_response.json()\n"}
{"type": "test_file", "path": "tests/ops/fixtures/saas/braze_fixtures.py", "content": "import uuid\nfrom typing import Any, Dict, Generator\n\nimport pydash\nimport pytest\nimport requests\nfrom fideslib.cryptography import cryptographic_util\nfrom fideslib.db import session\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.models.connectionconfig import (\n    AccessLevel,\n    ConnectionConfig,\n    ConnectionType,\n)\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.util.saas_util import (\n    load_config_with_replacement,\n    load_dataset_with_replacement,\n)\nfrom tests.ops.test_helpers.saas_test_utils import poll_for_existence\nfrom tests.ops.test_helpers.vault_client import get_secrets\n\nsecrets = get_secrets(\"braze\")\n\n\n@pytest.fixture(scope=\"session\")\ndef braze_secrets(saas_config):\n    return {\n        \"domain\": pydash.get(saas_config, \"braze.domain\") or secrets[\"domain\"],\n        \"api_key\": pydash.get(saas_config, \"braze.api_key\") or secrets[\"api_key\"],\n    }\n\n\n@pytest.fixture(scope=\"session\")\ndef braze_identity_email(saas_config):\n    return pydash.get(saas_config, \"braze.identity_email\") or secrets[\"identity_email\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef braze_erasure_identity_email():\n    return f\"{cryptographic_util.generate_secure_random_string(13)}@email.com\"\n\n\n@pytest.fixture\ndef braze_config() -> Dict[str, Any]:\n    return load_config_with_replacement(\n        \"data/saas/config/braze_config.yml\",\n        \"<instance_fides_key>\",\n        \"braze_instance\",\n    )\n\n\n@pytest.fixture\ndef braze_dataset() -> Dict[str, Any]:\n    return load_dataset_with_replacement(\n        \"data/saas/dataset/braze_dataset.yml\",\n        \"<instance_fides_key>\",\n        \"braze_instance\",\n    )[0]\n\n\n@pytest.fixture(scope=\"function\")\ndef braze_connection_config(db: session, braze_config, braze_secrets) -> Generator:\n    fides_key = braze_config[\"fides_key\"]\n    connection_config = ConnectionConfig.create(\n        db=db,\n        data={\n            \"key\": fides_key,\n            \"name\": fides_key,\n            \"connection_type\": ConnectionType.saas,\n            \"access\": AccessLevel.write,\n            \"secrets\": braze_secrets,\n            \"saas_config\": braze_config,\n        },\n    )\n    yield connection_config\n    connection_config.delete(db)\n\n\n@pytest.fixture\ndef braze_dataset_config(\n    db: Session,\n    braze_connection_config: ConnectionConfig,\n    braze_dataset,\n    braze_config,\n) -> Generator:\n    fides_key = braze_config[\"fides_key\"]\n    braze_connection_config.name = fides_key\n    braze_connection_config.key = fides_key\n    braze_connection_config.save(db=db)\n    dataset = DatasetConfig.create(\n        db=db,\n        data={\n            \"connection_config_id\": braze_connection_config.id,\n            \"fides_key\": fides_key,\n            \"dataset\": braze_dataset,\n        },\n    )\n    yield dataset\n    dataset.delete(db=db)\n\n\n@pytest.fixture(scope=\"function\")\ndef braze_erasure_data(\n    braze_connection_config, braze_erasure_identity_email, braze_secrets\n) -> Generator:\n    base_url = f\"https://{braze_secrets['domain']}\"\n    external_id = uuid.uuid4().hex\n    body = {\n        \"attributes\": [\n            {\n                \"external_id\": external_id,\n                \"first_name\": \"Walter\",\n                \"last_name\": \"White\",\n                \"email\": braze_erasure_identity_email,\n                \"phone\": \"+16175551212\",\n                \"country\": \"US\",\n                \"date_of_first_session\": \"2022-09-14T16:14:56+00:00\",\n                \"dob\": \"1980-12-21\",\n                \"email_subscribe\": \"opted_in\",\n                \"gender\": \"M\",\n                \"home_city\": \"New York\",\n                \"language\": \"en\",\n                \"time_zone\": \"US/Eastern\",\n                \"user_aliases\": [\n                    {\n                        \"external_id\": external_id,\n                        \"alias_name\": \"Breaking\",\n                        \"alias_label\": \"Bad\",\n                    }\n                ],\n                \"app_id\": f\"app_identifier.{external_id}\",\n            }\n        ],\n        \"events\": [\n            {\n                \"external_id\": external_id,\n                \"app_id\": f\"app_identifier.{external_id}\",\n                \"name\": \"watched_trailer\",\n                \"time\": \"2013-07-16T19:20:30+1:00\",\n            },\n            {\n                \"external_id\": external_id,\n                \"app_id\": \"app_identifier.{{external_id}}\",\n                \"name\": \"this is test event to create\",\n                \"time\": \"2022-07-16T19:20:30+1:00\",\n            },\n        ],\n        \"purchases\": [\n            {\n                \"external_id\": external_id,\n                \"product_id\": \"Car\",\n                \"currency\": \"USD\",\n                \"price\": 12.12,\n                \"quantity\": 6,\n                \"time\": \"2017-05-12T18:47:12Z\",\n                \"properties\": {\n                    \"integer_property\": 3,\n                    \"string_property\": \"Some Property\",\n                    \"date_property\": \"2014-02-02T00:00:00Z\",\n                },\n            }\n        ],\n    }\n\n    headers = {\"Authorization\": f\"Bearer {braze_secrets['api_key']}\"}\n\n    response = requests.post(url=f\"{base_url}/users/track\", json=body, headers=headers)\n    response_data = response.json()\n\n    assert response.ok\n\n    error_message = (\n        f\"User with email {braze_erasure_identity_email} could not be added to Braze\"\n    )\n    poll_for_existence(\n        _user_exists,\n        (braze_erasure_identity_email, braze_secrets),\n        error_message=error_message,\n    )\n\n    yield response_data\n\n    # Remove Data\n\n    export_data = requests.post(\n        url=f\"{base_url}/users/export/ids\",\n        json={\n            \"external_ids\": [\n                external_id,\n            ],\n            \"fields_to_export\": [\n                \"braze_id\",\n            ],\n        },\n        headers=headers,\n    )\n    assert export_data.ok\n\n    braze_ids = [i[\"braze_id\"] for i in export_data.json().get(\"users\")]\n    delete_user = requests.post(\n        url=f\"{base_url}/users/delete\", json={\"braze_ids\": braze_ids}, headers=headers\n    )\n    assert delete_user.status_code == 201\n\n\ndef _user_exists(braze_erasure_identity_email: str, braze_secrets):\n    \"\"\"\n    Confirm whether user exists by calling user search by email api and comparing resulting firstname str.\n    Returns user ID if it exists, returns None if it does not.\n    \"\"\"\n    base_url = f\"https://{braze_secrets['domain']}\"\n    headers = {\n        \"Authorization\": f\"Bearer {braze_secrets['api_key']}\",\n    }\n    body = {\n        \"email_address\": braze_erasure_identity_email,\n        \"fields_to_export\": [\"email\"],\n    }\n\n    user_response = requests.post(\n        url=f\"{base_url}/users/export/ids\",\n        json=body,\n        headers=headers,\n    )\n\n    # we expect 404 if user doesn't exist\n    if 404 == user_response.status_code:\n        return None\n\n    return user_response.json()\n"}
{"type": "test_file", "path": "tests/ops/api/v1/endpoints/test_policy_webhook_endpoints.py", "content": "import json\nfrom typing import Dict\n\nimport pytest\n\nfrom fidesops.ops.api.v1.scope_registry import (\n    POLICY_READ,\n    WEBHOOK_CREATE_OR_UPDATE,\n    WEBHOOK_DELETE,\n    WEBHOOK_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    POLICY_POST_WEBHOOK_DETAIL,\n    POLICY_PRE_WEBHOOK_DETAIL,\n    POLICY_WEBHOOKS_POST,\n    POLICY_WEBHOOKS_PRE,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig\nfrom fidesops.ops.models.policy import PolicyPostWebhook, PolicyPreWebhook\nfrom tests.ops.api.v1.endpoints.test_privacy_request_endpoints import stringify_date\n\n\ndef embedded_http_connection_config(connection_config: ConnectionConfig) -> Dict:\n    \"\"\"Helper to reduce clutter - a lot of the tests below assert the entire response body, which includes the\n    https connection config\"\"\"\n    return {\n        \"name\": connection_config.name,\n        \"key\": connection_config.key,\n        \"connection_type\": \"https\",\n        \"access\": connection_config.access.value,\n        \"created_at\": stringify_date(connection_config.created_at),\n        \"updated_at\": stringify_date(connection_config.updated_at),\n        \"last_test_timestamp\": None,\n        \"last_test_succeeded\": None,\n        \"disabled\": False,\n        \"description\": None,\n        \"saas_config\": None,\n    }\n\n\nclass TestGetPolicyPreExecutionWebhooks:\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy) -> str:\n        return V1_URL_PREFIX + POLICY_WEBHOOKS_PRE.format(policy_key=policy.key)\n\n    def test_get_pre_execution_webhooks_unauthenticated(self, url, api_client):\n        resp = api_client.get(url)\n        assert resp.status_code == 401\n\n    def test_get_pre_execution_webhooks_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[POLICY_READ])\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_invalid_policy(self, db, api_client, generate_auth_header):\n        url = V1_URL_PREFIX + POLICY_WEBHOOKS_PRE.format(policy_key=\"my_fake_policy\")\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n\n        assert resp.status_code == 404\n        body = json.loads(resp.text)\n        assert body[\"detail\"] == \"No Policy found for key my_fake_policy.\"\n\n    def test_get_pre_execution_policy_webhooks(\n        self,\n        url,\n        db,\n        api_client,\n        generate_auth_header,\n        policy_pre_execution_webhooks,\n        https_connection_config,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n\n        assert body == {\n            \"items\": [\n                {\n                    \"direction\": \"one_way\",\n                    \"key\": \"pre_execution_one_way_webhook\",\n                    \"name\": policy_pre_execution_webhooks[0].name,\n                    \"connection_config\": embedded_http_connection_config(\n                        https_connection_config\n                    ),\n                    \"order\": 0,\n                },\n                {\n                    \"direction\": \"two_way\",\n                    \"key\": \"pre_execution_two_way_webhook\",\n                    \"name\": policy_pre_execution_webhooks[1].name,\n                    \"connection_config\": embedded_http_connection_config(\n                        https_connection_config\n                    ),\n                    \"order\": 1,\n                },\n            ],\n            \"total\": 2,\n            \"page\": 1,\n            \"size\": 50,\n        }\n\n\nclass TestGetPolicyPostExecutionWebhooks:\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy) -> str:\n        return V1_URL_PREFIX + POLICY_WEBHOOKS_POST.format(policy_key=policy.key)\n\n    def test_get_post_execution_webhooks_unauthenticated(self, url, api_client):\n        resp = api_client.get(url)\n        assert resp.status_code == 401\n\n    def test_get_post_execution_webhooks_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[POLICY_READ])\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_invalid_policy(self, db, api_client, generate_auth_header):\n        url = V1_URL_PREFIX + POLICY_WEBHOOKS_PRE.format(policy_key=\"my_fake_policy\")\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n\n        assert resp.status_code == 404\n        body = json.loads(resp.text)\n        assert body[\"detail\"] == \"No Policy found for key my_fake_policy.\"\n\n    def test_get_post_execution_policy_webhooks(\n        self,\n        url,\n        db,\n        api_client,\n        generate_auth_header,\n        policy_post_execution_webhooks,\n        https_connection_config,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n        assert body == {\n            \"items\": [\n                {\n                    \"direction\": \"one_way\",\n                    \"key\": \"cache_busting_webhook\",\n                    \"name\": policy_post_execution_webhooks[0].name,\n                    \"connection_config\": embedded_http_connection_config(\n                        https_connection_config\n                    ),\n                    \"order\": 0,\n                },\n                {\n                    \"direction\": \"one_way\",\n                    \"key\": \"cleanup_webhook\",\n                    \"name\": policy_post_execution_webhooks[1].name,\n                    \"connection_config\": embedded_http_connection_config(\n                        https_connection_config\n                    ),\n                    \"order\": 1,\n                },\n            ],\n            \"total\": 2,\n            \"page\": 1,\n            \"size\": 50,\n        }\n\n\nclass TestGetPolicyPreExecutionWebhookDetail:\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy, policy_pre_execution_webhooks) -> str:\n        return V1_URL_PREFIX + POLICY_PRE_WEBHOOK_DETAIL.format(\n            policy_key=policy.key, pre_webhook_key=policy_pre_execution_webhooks[0].key\n        )\n\n    def test_get_pre_execution_webhook_detail_unauthenticated(self, url, api_client):\n        resp = api_client.get(url)\n        assert resp.status_code == 401\n\n    def test_get_pre_execution_webhook_detail_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[POLICY_READ])\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_invalid_policy(\n        self, db, api_client, generate_auth_header, policy_pre_execution_webhooks\n    ):\n        url = V1_URL_PREFIX + POLICY_PRE_WEBHOOK_DETAIL.format(\n            policy_key=\"my_fake_policy\",\n            pre_webhook_key=policy_pre_execution_webhooks[0].key,\n        )\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n\n        assert resp.status_code == 404\n        body = json.loads(resp.text)\n        assert body[\"detail\"] == \"No Policy found for key my_fake_policy.\"\n\n    def test_webhook_not_on_policy(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        erasure_policy,\n        policy_pre_execution_webhooks,\n    ):\n        url = V1_URL_PREFIX + POLICY_PRE_WEBHOOK_DETAIL.format(\n            policy_key=erasure_policy.key,\n            pre_webhook_key=policy_pre_execution_webhooks[0].key,\n        )\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n\n        assert resp.status_code == 404\n        body = json.loads(resp.text)\n        assert (\n            body[\"detail\"]\n            == \"No Pre-Execution Webhook found for key 'pre_execution_one_way_webhook' on Policy 'example_erasure_policy'.\"\n        )\n\n    def test_get_pre_execution_policy_webhook_detail(\n        self,\n        url,\n        db,\n        api_client,\n        generate_auth_header,\n        policy_pre_execution_webhooks,\n        https_connection_config,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n\n        assert body == {\n            \"direction\": \"one_way\",\n            \"key\": \"pre_execution_one_way_webhook\",\n            \"name\": policy_pre_execution_webhooks[0].name,\n            \"connection_config\": embedded_http_connection_config(\n                https_connection_config\n            ),\n            \"order\": 0,\n        }\n\n\nclass TestGetPolicyPostExecutionWebhookDetail:\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy, policy_post_execution_webhooks) -> str:\n        return V1_URL_PREFIX + POLICY_POST_WEBHOOK_DETAIL.format(\n            policy_key=policy.key,\n            post_webhook_key=policy_post_execution_webhooks[0].key,\n        )\n\n    def test_get_post_execution_webhook_detail_unauthenticated(self, url, api_client):\n        resp = api_client.get(url)\n        assert resp.status_code == 401\n\n    def test_get_post_execution_webhook_detail_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[POLICY_READ])\n        resp = api_client.get(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_invalid_policy(\n        self, db, api_client, generate_auth_header, policy_post_execution_webhooks\n    ):\n        url = V1_URL_PREFIX + POLICY_POST_WEBHOOK_DETAIL.format(\n            policy_key=\"my_fake_policy\",\n            post_webhook_key=policy_post_execution_webhooks[0].key,\n        )\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n\n        assert resp.status_code == 404\n        body = json.loads(resp.text)\n        assert body[\"detail\"] == \"No Policy found for key my_fake_policy.\"\n\n    def test_webhook_not_on_policy(\n        self,\n        db,\n        api_client,\n        generate_auth_header,\n        erasure_policy,\n        policy_post_execution_webhooks,\n    ):\n        url = V1_URL_PREFIX + POLICY_POST_WEBHOOK_DETAIL.format(\n            policy_key=erasure_policy.key,\n            post_webhook_key=policy_post_execution_webhooks[0].key,\n        )\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n\n        assert resp.status_code == 404\n        body = json.loads(resp.text)\n        assert (\n            body[\"detail\"]\n            == \"No Post-Execution Webhook found for key 'cache_busting_webhook' on Policy 'example_erasure_policy'.\"\n        )\n\n    def test_get_pre_execution_policy_webhook_detail(\n        self,\n        url,\n        db,\n        api_client,\n        generate_auth_header,\n        policy_post_execution_webhooks,\n        https_connection_config,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.get(url, headers=auth_header)\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n\n        assert body == {\n            \"direction\": \"one_way\",\n            \"key\": \"cache_busting_webhook\",\n            \"name\": policy_post_execution_webhooks[0].name,\n            \"connection_config\": embedded_http_connection_config(\n                https_connection_config\n            ),\n            \"order\": 0,\n        }\n\n\nclass TestPutPolicyPreExecutionWebhooks:\n    @pytest.fixture(scope=\"function\")\n    def valid_webhook_request(self, https_connection_config) -> Dict:\n        return {\n            \"connection_config_key\": https_connection_config.key,\n            \"direction\": \"one_way\",\n            \"name\": \"Poke Snowflake Webhook\",\n            \"key\": \"poke_snowflake_webhook\",\n        }\n\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy) -> str:\n        return V1_URL_PREFIX + POLICY_WEBHOOKS_PRE.format(policy_key=policy.key)\n\n    def test_put_pre_execution_webhooks_unauthenticated(self, url, api_client):\n        resp = api_client.put(url)\n        assert resp.status_code == 401\n\n    def test_put_pre_execution_webhooks_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_invalid_policy(\n        self, db, api_client, generate_auth_header, valid_webhook_request\n    ):\n        url = V1_URL_PREFIX + POLICY_WEBHOOKS_PRE.format(policy_key=\"my_fake_policy\")\n\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.put(url, headers=auth_header, json=[valid_webhook_request])\n\n        assert resp.status_code == 404\n        body = json.loads(resp.text)\n        assert body[\"detail\"] == \"No Policy found for key my_fake_policy.\"\n        assert db.query(PolicyPreWebhook).count() == 0  # All must succeed or fail\n\n    def test_invalid_connection_config(\n        self, db, url, api_client, generate_auth_header, valid_webhook_request\n    ):\n        invalid_connection_config_body = {\n            \"connection_config_key\": \"unknown_connection_key\",\n            \"direction\": \"one_way\",\n            \"name\": \"my_pre_execution_webhook\",\n        }\n\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=[valid_webhook_request, invalid_connection_config_body],\n        )\n\n        assert resp.status_code == 404\n        body = json.loads(resp.text)\n        assert (\n            body[\"detail\"]\n            == \"No connection configuration found with key 'unknown_connection_key'.\"\n        )\n        assert db.query(PolicyPreWebhook).count() == 0  # All must succeed or fail\n\n    def test_direction_error_fails_all(\n        self,\n        db,\n        https_connection_config,\n        generate_auth_header,\n        api_client,\n        url,\n        valid_webhook_request,\n    ):\n        invalid_connection_config_body = {\n            \"connection_config_key\": https_connection_config.key,\n            \"direction\": \"invalid_direction\",\n            \"name\": \"my_pre_execution_webhook\",\n        }\n\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=[valid_webhook_request, invalid_connection_config_body],\n        )\n        assert resp.status_code == 422\n        body = json.loads(resp.text)\n        assert (\n            body[\"detail\"][0][\"msg\"]\n            == \"value is not a valid enumeration member; permitted: 'one_way', 'two_way'\"\n        )\n        assert db.query(PolicyPreWebhook).count() == 0  # All must succeed or fail\n\n    def test_put_pre_execution_webhooks_duplicate_keys(\n        self,\n        db,\n        url,\n        api_client,\n        generate_auth_header,\n        valid_webhook_request,\n        https_connection_config,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=[valid_webhook_request, valid_webhook_request],\n        )\n        assert resp.status_code == 400\n        body = json.loads(resp.text)\n        assert (\n            body[\"detail\"]\n            == \"Check request body: there are multiple webhooks whose keys or names resolve to the same value.\"\n        )\n\n        name_only = {\n            \"connection_config_key\": https_connection_config.key,\n            \"direction\": \"one_way\",\n            \"name\": \"Poke Snowflake Webhook\",\n        }\n\n        resp = api_client.put(\n            url, headers=auth_header, json=[valid_webhook_request, name_only]\n        )\n        assert resp.status_code == 400\n        body = json.loads(resp.text)\n        assert (\n            body[\"detail\"]\n            == \"Check request body: there are multiple webhooks whose keys or names resolve to the same value.\"\n        )\n        assert db.query(PolicyPreWebhook).count() == 0  # All must succeed or fail\n\n    def test_put_pre_execution_webhooks_duplicate_names(\n        self,\n        db,\n        url,\n        api_client,\n        generate_auth_header,\n        valid_webhook_request,\n        https_connection_config,\n    ):\n        second_payload = valid_webhook_request.copy()\n        second_payload[\"key\"] = \"new_key\"\n\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=[valid_webhook_request, valid_webhook_request],\n        )\n        assert resp.status_code == 400\n        body = json.loads(resp.text)\n        assert (\n            body[\"detail\"]\n            == \"Check request body: there are multiple webhooks whose keys or names resolve to the same value.\"\n        )\n\n    def test_create_multiple_pre_execution_webhooks(\n        self,\n        db,\n        generate_auth_header,\n        api_client,\n        url,\n        valid_webhook_request,\n        https_connection_config,\n    ):\n        second_webhook_body = {\n            \"connection_config_key\": https_connection_config.key,\n            \"direction\": \"two_way\",\n            \"name\": \"My Pre Execution Webhook\",\n        }\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=[valid_webhook_request, second_webhook_body],\n        )\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n        assert len(body) == 2\n        assert body == [\n            {\n                \"direction\": \"one_way\",\n                \"key\": \"poke_snowflake_webhook\",\n                \"name\": \"Poke Snowflake Webhook\",\n                \"connection_config\": embedded_http_connection_config(\n                    https_connection_config\n                ),\n                \"order\": 0,\n            },\n            {\n                \"direction\": \"two_way\",\n                \"key\": \"my_pre_execution_webhook\",\n                \"name\": \"My Pre Execution Webhook\",\n                \"connection_config\": embedded_http_connection_config(\n                    https_connection_config\n                ),\n                \"order\": 1,\n            },\n        ]\n\n        pre_webhooks = PolicyPreWebhook.filter(\n            db=db,\n            conditions=(\n                PolicyPreWebhook.key.in_(\n                    [\"my_pre_execution_webhook\", \"poke_snowflake_webhook\"]\n                )\n            ),\n        )\n\n        assert pre_webhooks.count() == 2\n        for webhook in pre_webhooks:\n            webhook.delete(db=db)\n\n    def test_update_webhooks_reorder(\n        self,\n        db,\n        generate_auth_header,\n        api_client,\n        url,\n        policy_pre_execution_webhooks,\n        https_connection_config,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        assert policy_pre_execution_webhooks[0].key == \"pre_execution_one_way_webhook\"\n        assert policy_pre_execution_webhooks[0].order == 0\n        assert policy_pre_execution_webhooks[1].key == \"pre_execution_two_way_webhook\"\n        assert policy_pre_execution_webhooks[1].order == 1\n\n        # Flip the order in the request\n        request_body = [\n            {\n                \"connection_config_key\": https_connection_config.key,\n                \"direction\": policy_pre_execution_webhooks[1].direction.value,\n                \"name\": policy_pre_execution_webhooks[1].name,\n                \"key\": policy_pre_execution_webhooks[1].key,\n            },\n            {\n                \"connection_config_key\": https_connection_config.key,\n                \"direction\": policy_pre_execution_webhooks[0].direction.value,\n                \"name\": policy_pre_execution_webhooks[0].name,\n                \"key\": policy_pre_execution_webhooks[0].key,\n            },\n        ]\n\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=request_body,\n        )\n        body = json.loads(resp.text)\n        assert body[0][\"key\"] == \"pre_execution_two_way_webhook\"\n        assert body[0][\"order\"] == 0\n        assert body[1][\"key\"] == \"pre_execution_one_way_webhook\"\n        assert body[1][\"order\"] == 1\n\n    def test_update_hooks_remove_hook_from_request(\n        self,\n        db,\n        generate_auth_header,\n        api_client,\n        url,\n        policy_pre_execution_webhooks,\n        https_connection_config,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n\n        # Only include one hook\n        request_body = [\n            {\n                \"connection_config_key\": https_connection_config.key,\n                \"direction\": policy_pre_execution_webhooks[0].direction.value,\n                \"name\": policy_pre_execution_webhooks[0].name,\n                \"key\": policy_pre_execution_webhooks[0].key,\n            },\n        ]\n\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=request_body,\n        )\n        body = json.loads(resp.text)\n        assert len(body) == 1  # Other webhook was removed\n        assert body[0][\"key\"] == \"pre_execution_one_way_webhook\"\n        assert body[0][\"order\"] == 0\n\n\nclass TestPutPolicyPostExecutionWebhooks:\n    \"\"\"Shares a lot of logic with Pre Execution Webhooks - see TestPutPolicyPreExecutionWebhooks tests\"\"\"\n\n    @pytest.fixture(scope=\"function\")\n    def valid_webhook_request(self, https_connection_config) -> Dict:\n        return {\n            \"connection_config_key\": https_connection_config.key,\n            \"direction\": \"one_way\",\n            \"name\": \"Clear App Cache\",\n            \"key\": \"clear_app_cache\",\n        }\n\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy) -> str:\n        return V1_URL_PREFIX + POLICY_WEBHOOKS_POST.format(policy_key=policy.key)\n\n    def test_put_post_execution_webhooks_unauthenticated(self, url, api_client):\n        resp = api_client.put(url)\n        assert resp.status_code == 401\n\n    def test_put_post_execution_webhooks_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_create_multiple_post_execution_webhooks(\n        self,\n        db,\n        generate_auth_header,\n        api_client,\n        url,\n        valid_webhook_request,\n        https_connection_config,\n    ):\n        second_webhook_body = {\n            \"connection_config_key\": https_connection_config.key,\n            \"direction\": \"two_way\",\n            \"name\": \"My Post Execution Webhook\",\n        }\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.put(\n            url,\n            headers=auth_header,\n            json=[valid_webhook_request, second_webhook_body],\n        )\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n        assert len(body) == 2\n        assert body == [\n            {\n                \"direction\": \"one_way\",\n                \"key\": \"clear_app_cache\",\n                \"name\": \"Clear App Cache\",\n                \"connection_config\": embedded_http_connection_config(\n                    https_connection_config\n                ),\n                \"order\": 0,\n            },\n            {\n                \"direction\": \"two_way\",\n                \"key\": \"my_post_execution_webhook\",\n                \"name\": \"My Post Execution Webhook\",\n                \"connection_config\": embedded_http_connection_config(\n                    https_connection_config\n                ),\n                \"order\": 1,\n            },\n        ]\n\n        post_webhooks = PolicyPostWebhook.filter(\n            db=db,\n            conditions=(\n                PolicyPostWebhook.key.in_(\n                    [\"my_post_execution_webhook\", \"clear_app_cache\"]\n                )\n            ),\n        )\n\n        assert post_webhooks.count() == 2\n        for webhook in post_webhooks:\n            webhook.delete(db=db)\n\n\nclass TestPatchPreExecutionPolicyWebhook:\n    \"\"\"Test updating a single PolicyPreWebhook - however, updates to \"order\" can affect the orders of other webhooks\"\"\"\n\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy, policy_pre_execution_webhooks) -> str:\n        return V1_URL_PREFIX + POLICY_PRE_WEBHOOK_DETAIL.format(\n            policy_key=policy.key, pre_webhook_key=policy_pre_execution_webhooks[0].key\n        )\n\n    def test_patch_pre_execution_webhook_unauthenticated(self, url, api_client):\n        resp = api_client.patch(url)\n        assert resp.status_code == 401\n\n    def test_patch_pre_execution_webhook_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.patch(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_patch_pre_execution_webhook_invalid_webhook_key(\n        self, api_client, generate_auth_header, policy\n    ):\n        return V1_URL_PREFIX + POLICY_PRE_WEBHOOK_DETAIL.format(\n            policy_key=policy.key, pre_webhook_key=\"invalid_webhook_key\"\n        )\n\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.patch(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 404\n\n    def test_path_pre_execution_webhook_invalid_order(\n        self, generate_auth_header, api_client, url, policy_pre_execution_webhooks\n    ):\n        request_body = {\"order\": 5}\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, headers=auth_header, json=request_body)\n\n        assert resp.status_code == 400\n        response_body = json.loads(resp.text)\n        assert (\n            response_body[\"detail\"]\n            == \"Cannot set order to 5: there are only 2 PolicyPreWebhook(s) defined on this Policy.\"\n        )\n\n    def test_update_name_only(\n        self,\n        db,\n        generate_auth_header,\n        api_client,\n        url,\n        policy_pre_execution_webhooks,\n        https_connection_config,\n    ):\n        request_body = {\"name\": \"Renaming this webhook\"}\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, headers=auth_header, json=request_body)\n        assert resp.status_code == 200\n        response_body = json.loads(resp.text)\n        assert response_body == {\n            \"resource\": {\n                \"direction\": \"one_way\",\n                \"key\": \"pre_execution_one_way_webhook\",\n                \"name\": \"Renaming this webhook\",\n                \"connection_config\": embedded_http_connection_config(\n                    https_connection_config\n                ),\n                \"order\": 0,\n            },\n            \"new_order\": [],\n        }\n        webhook = PolicyPreWebhook.filter(\n            db=db, conditions=(PolicyPreWebhook.key == \"pre_execution_one_way_webhook\")\n        ).first()\n        assert webhook.order == 0\n\n    def test_update_name_and_order(\n        self,\n        db,\n        generate_auth_header,\n        api_client,\n        url,\n        policy_pre_execution_webhooks,\n        https_connection_config,\n    ):\n        request_body = {\"name\": \"Renaming this webhook\", \"order\": 1}\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, headers=auth_header, json=request_body)\n        assert resp.status_code == 200\n        response_body = json.loads(resp.text)\n        assert response_body == {\n            \"resource\": {\n                \"direction\": \"one_way\",\n                \"key\": \"pre_execution_one_way_webhook\",\n                \"name\": \"Renaming this webhook\",\n                \"connection_config\": embedded_http_connection_config(\n                    https_connection_config\n                ),\n                \"order\": 1,\n            },\n            \"new_order\": [\n                {\"key\": \"pre_execution_two_way_webhook\", \"order\": 0},\n                {\"key\": \"pre_execution_one_way_webhook\", \"order\": 1},\n            ],\n        }\n        webhook = PolicyPreWebhook.filter(\n            db=db, conditions=(PolicyPreWebhook.key == \"pre_execution_one_way_webhook\")\n        ).first()\n        db.refresh(webhook)\n        assert webhook.order == 1\n\n\nclass TestPatchPostExecutionPolicyWebhook:\n    \"\"\"Test updating a single PolicyPostWebhook - however, updates to \"order\" can affect the orders of other webhooks\n\n    This endpoint shares code with the pre-execution PATCH - see TestPatchPreExecutionPolicyWebhook\n    \"\"\"\n\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy, policy_post_execution_webhooks) -> str:\n        return V1_URL_PREFIX + POLICY_POST_WEBHOOK_DETAIL.format(\n            policy_key=policy.key,\n            post_webhook_key=policy_post_execution_webhooks[0].key,\n        )\n\n    def test_patch_post_execution_webhook_unauthenticated(self, url, api_client):\n        resp = api_client.patch(url)\n        assert resp.status_code == 401\n\n    def test_patch_post_execution_webhook_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.patch(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_update_name_and_order_and_direction(\n        self,\n        db,\n        generate_auth_header,\n        api_client,\n        url,\n        policy_pre_execution_webhooks,\n        https_connection_config,\n    ):\n        webhook = PolicyPostWebhook.filter(\n            db=db, conditions=(PolicyPostWebhook.key == \"cache_busting_webhook\")\n        ).first()\n        db.refresh(webhook)\n        assert webhook.order == 0\n        request_body = {\n            \"name\": \"Better Webhook Name\",\n            \"order\": 1,\n            \"direction\": \"two_way\",\n        }\n        auth_header = generate_auth_header(scopes=[WEBHOOK_CREATE_OR_UPDATE])\n        resp = api_client.patch(url, headers=auth_header, json=request_body)\n        assert resp.status_code == 200\n        response_body = json.loads(resp.text)\n        assert response_body == {\n            \"resource\": {\n                \"direction\": \"two_way\",\n                \"key\": \"cache_busting_webhook\",\n                \"name\": \"Better Webhook Name\",\n                \"connection_config\": embedded_http_connection_config(\n                    https_connection_config\n                ),\n                \"order\": 1,\n            },\n            \"new_order\": [\n                {\"key\": \"cleanup_webhook\", \"order\": 0},\n                {\"key\": \"cache_busting_webhook\", \"order\": 1},\n            ],\n        }\n\n        db.refresh(webhook)\n        assert webhook.order == 1\n\n\nclass TestDeletePolicyPreWebhook:\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy, policy_pre_execution_webhooks) -> str:\n        return V1_URL_PREFIX + POLICY_PRE_WEBHOOK_DETAIL.format(\n            policy_key=policy.key, pre_webhook_key=policy_pre_execution_webhooks[0].key\n        )\n\n    def test_delete_pre_execution_webhook(self, url, api_client):\n        resp = api_client.delete(url)\n        assert resp.status_code == 401\n\n    def test_delete_pre_execution_webhook_detail_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.delete(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_delete_pre_execution_webhook_detail_and_reorder(\n        self,\n        url,\n        api_client,\n        generate_auth_header,\n        policy,\n        policy_pre_execution_webhooks,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_DELETE])\n        resp = api_client.delete(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n        assert body == {\n            \"new_order\": [{\"key\": policy_pre_execution_webhooks[1].key, \"order\": 0}]\n        }\n\n        assert policy.pre_execution_webhooks.count() == 1\n\n\nclass TestDeletePolicyPostWebhook:\n    @pytest.fixture(scope=\"function\")\n    def url(self, policy, policy_post_execution_webhooks) -> str:\n        return V1_URL_PREFIX + POLICY_POST_WEBHOOK_DETAIL.format(\n            policy_key=policy.key,\n            post_webhook_key=policy_post_execution_webhooks[0].key,\n        )\n\n    def test_delete_pre_execution_webhook(self, url, api_client):\n        resp = api_client.delete(url)\n        assert resp.status_code == 401\n\n    def test_delete_post_execution_webhook_detail_wrong_scope(\n        self, url, api_client, generate_auth_header\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_READ])\n        resp = api_client.delete(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 403\n\n    def test_delete_post_execution_webhook_detail_and_reorder(\n        self,\n        url,\n        api_client,\n        generate_auth_header,\n        policy,\n        policy_post_execution_webhooks,\n    ):\n        auth_header = generate_auth_header(scopes=[WEBHOOK_DELETE])\n        resp = api_client.delete(\n            url,\n            headers=auth_header,\n        )\n        assert resp.status_code == 200\n        body = json.loads(resp.text)\n        assert body == {\n            \"new_order\": [{\"key\": policy_post_execution_webhooks[1].key, \"order\": 0}]\n        }\n\n        assert policy.post_execution_webhooks.count() == 1\n\n        url = V1_URL_PREFIX + POLICY_POST_WEBHOOK_DETAIL.format(\n            policy_key=policy.key,\n            post_webhook_key=policy_post_execution_webhooks[1].key,\n        )\n        resp = api_client.delete(\n            url,\n            headers=auth_header,\n        )\n        body = json.loads(resp.text)\n        assert body == {\"new_order\": []}\n\n        assert policy.post_execution_webhooks.count() == 0\n"}
{"type": "source_file", "path": "noxfile.py", "content": "\"\"\"\nDevelopment & Build tasks for Fidesops.\n\"\"\"\nimport sys\n\nimport nox\n\nsys.path.append(\"noxfiles\")\nfrom ci_nox import *\nfrom dev_nox import *\nfrom docker_nox import *\nfrom docs_nox import *\nfrom utils_nox import *\n\n# Sets the default session to `--list`\nnox.options.sessions = []\nnox.options.reuse_existing_virtualenvs = True\n"}
{"type": "source_file", "path": "noxfiles/ci_nox.py", "content": "\"\"\"Contains the nox sessions used during CI checks.\"\"\"\n\nfrom pathlib import Path\n\nimport nox\nfrom constants_nox import (\n    CI_ARGS,\n    COMPOSE_SERVICE_NAME,\n    IMAGE_LOCAL,\n    RUN,\n    RUN_NO_DEPS,\n    START_APP,\n)\nfrom run_infrastructure import OPS_TEST_DIR, run_infrastructure\nfrom utils_nox import db, install_requirements\n\n\n@nox.session()\ndef ci_suite(session: nox.Session) -> None:\n    \"\"\"\n    Runs the CI check suite.\n\n    Excludes external tests so that no additional secrets/tooling are required.\n    \"\"\"\n    # Use \"notify\" instead of direct calls here to provide better user feedback\n    session.notify(\"teardown\")\n    session.notify(\"build\", [\"test\"])\n    session.notify(\"black\")\n    session.notify(\"isort\")\n    session.notify(\"xenon\")\n    session.notify(\"mypy\")\n    session.notify(\"pylint\")\n    session.notify(\"check_install\")\n    session.notify(\"check_migrations\")\n    session.notify(\"pytest_unit\")\n    session.notify(\"pytest_integration\")\n    session.notify(\"teardown\")\n\n\n# Static Checks\n@nox.session()\ndef static_checks(session: nox.Session) -> None:\n    \"\"\"Run the static checks only.\"\"\"\n    session.notify(\"black\")\n    session.notify(\"isort\")\n    session.notify(\"xenon\")\n    session.notify(\"mypy\")\n    session.notify(\"pylint\")\n\n\n@nox.session()\ndef black(session: nox.Session) -> None:\n    \"\"\"Run the 'black' style linter.\"\"\"\n    install_requirements(session)\n    command = (\n        \"black\",\n        \"--check\",\n        \"src\",\n        \"tests\",\n        \"noxfiles\",\n    )\n    session.run(*command)\n\n\n@nox.session()\ndef isort(session: nox.Session) -> None:\n    \"\"\"Run the 'isort' import linter.\"\"\"\n    install_requirements(session)\n    command = (\"isort\", \"src\", \"tests\", \"noxfiles\", \"--check\")\n    session.run(*command)\n\n\n@nox.session()\ndef mypy(session: nox.Session) -> None:\n    \"\"\"Run the 'mypy' static type checker.\"\"\"\n    install_requirements(session)\n    command = \"mypy\"\n    session.run(command)\n\n\n@nox.session()\ndef pylint(session: nox.Session) -> None:\n    \"\"\"Run the 'pylint' code linter.\"\"\"\n    install_requirements(session)\n    command = (\"pylint\", \"src\", \"noxfiles\")\n    session.run(*command)\n\n\n@nox.session()\ndef xenon(session: nox.Session) -> None:\n    \"\"\"Run 'xenon' code complexity monitoring.\"\"\"\n    install_requirements(session)\n    command = (\n        \"xenon\",\n        \"noxfiles\",\n        \"src\",\n        \"tests\",\n        \"--max-absolute B\",\n        \"--max-modules B\",\n        \"--max-average A\",\n        \"--ignore 'data, docs'\",\n        \"--exclude src/fidesops/_version.py\",\n    )\n    session.run(*command)\n\n\n@nox.session()\ndef check_install(session: nox.Session) -> None:\n    \"\"\"Check that fidesops is installed in the container.\"\"\"\n    session.run(\n        \"docker\",\n        \"run\",\n        \"-v\",\n        f\"{Path().absolute()}:/fidesops\",\n        IMAGE_LOCAL,\n        \"fidesops\",\n        external=True,\n    )\n\n\n@nox.session()\ndef check_migrations(session: nox.Session) -> None:\n    \"\"\"Check for missing migrations.\"\"\"\n    db(session, \"init\")\n    check_migration_command = (\n        \"python\",\n        \"-c\",\n        \"from fidesops.ops.db.database import check_missing_migrations; from fidesops.ops.core.config import config; check_missing_migrations(config.database.sqlalchemy_database_uri);\",\n    )\n    session.run(*RUN, *check_migration_command, external=True)\n\n\n# Pytest\n@nox.session()\ndef pytest_unit(session: nox.Session) -> None:\n    \"\"\"Runs tests.\"\"\"\n    session.notify(\"teardown\")\n    session.run(*START_APP, external=True)\n    run_command = (\n        *RUN_NO_DEPS,\n        \"pytest\",\n        OPS_TEST_DIR,\n        \"-m\",\n        \"not integration and not integration_external and not integration_saas\",\n    )\n    session.run(*run_command, external=True)\n\n\n@nox.session()\ndef pytest_integration(session: nox.Session) -> None:\n    \"\"\"Runs tests.\"\"\"\n    session.notify(\"teardown\")\n    run_infrastructure(\n        run_tests=True,\n        analytics_opt_out=True,\n        datastores=[],\n        pytest_path=OPS_TEST_DIR,\n    )\n\n\n@nox.session()\ndef pytest_integration_external(session: nox.Session) -> None:\n    \"\"\"Run all tests that rely on the third-party databases and services.\"\"\"\n    session.notify(\"teardown\")\n    run_command = (\n        \"docker-compose\",\n        \"run\",\n        \"-e\",\n        \"ANALYTICS_OPT_OUT\",\n        \"-e\",\n        \"REDSHIFT_TEST_URI\",\n        \"-e\",\n        \"SNOWFLAKE_TEST_URI\",\n        \"-e\",\n        \"REDSHIFT_TEST_DB_SCHEMA\",\n        \"-e\",\n        \"BIGQUERY_KEYFILE_CREDS\",\n        \"-e\",\n        \"BIGQUERY_DATASET\",\n        \"--rm\",\n        CI_ARGS,\n        COMPOSE_SERVICE_NAME,\n        \"pytest\",\n        OPS_TEST_DIR,\n        \"-m\",\n        \"integration_external\",\n    )\n    session.run(*run_command, external=True)\n\n\n@nox.session()\ndef pytest_saas(session: nox.Session) -> None:\n    \"\"\"Run all saas tests that rely on the third-party databases and services.\"\"\"\n    session.notify(\"teardown\")\n    run_command = (\n        \"docker-compose\",\n        \"run\",\n        \"-e\",\n        \"ANALYTICS_OPT_OUT\",\n        \"-e\",\n        \"VAULT_ADDR\",\n        \"-e\",\n        \"VAULT_NAMESPACE\",\n        \"-e\",\n        \"VAULT_TOKEN\",\n        \"--rm\",\n        CI_ARGS,\n        COMPOSE_SERVICE_NAME,\n        \"pytest\",\n        OPS_TEST_DIR,\n        \"-m\",\n        \"integration_saas\",\n    )\n    session.run(*run_command, external=True)\n"}
{"type": "source_file", "path": "noxfiles/constants_nox.py", "content": "\"\"\"Define constants to be used across the noxfiles.\"\"\"\nfrom os import getenv\n\n\ndef get_current_tag() -> str:\n    \"\"\"Get the current git tag.\"\"\"\n    from git.repo import Repo\n\n    repo = Repo()\n    git_session = repo.git()\n    git_session.fetch(\"--force\", \"--tags\")\n    current_tag = git_session.describe(\"--tags\", \"--dirty\", \"--always\")\n    return current_tag\n\n\nCOMPOSE_SERVICE_NAME = \"webserver\"\n\n# Files\nCOMPOSE_FILE = \"docker-compose.yml\"\nINTEGRATION_COMPOSE_FILE = \"docker-compose.integration-tests.yml\"\nWITH_TEST_CONFIG = (\"-f\", \"tests/test_config.toml\")\n\n# Image Names & Tags\nREGISTRY = \"ethyca\"\nIMAGE_NAME = \"fidesops\"\nIMAGE = f\"{REGISTRY}/{IMAGE_NAME}\"\nIMAGE_LOCAL = f\"{IMAGE}:local\"\nIMAGE_LOCAL_UI = f\"{IMAGE}:local-ui\"\nIMAGE_DEV = f\"{IMAGE}:dev\"\nIMAGE_LATEST = f\"{IMAGE}:latest\"\n\n# Disable TTY to perserve output within Github Actions logs\n# CI env variable is always set to true in Github Actions\n# The else statement is required due to the way commmands are structured and is arbitrary.\nCI_ARGS = \"-T\" if getenv(\"CI\") else \"--user=root\"\n\nANALYTICS_OPT_OUT = (\"-e\", \"ANALYTICS_OPT_OUT\")\n\n# Reusable Commands\nRUN = (\n    \"docker-compose\",\n    \"run\",\n    \"--rm\",\n    *ANALYTICS_OPT_OUT,\n    CI_ARGS,\n    COMPOSE_SERVICE_NAME,\n)\nRUN_NO_DEPS = (\n    \"docker-compose\",\n    \"run\",\n    \"--no-deps\",\n    \"--rm\",\n    *ANALYTICS_OPT_OUT,\n    CI_ARGS,\n    COMPOSE_SERVICE_NAME,\n)\nSTART_APP = (\"docker-compose\", \"up\", \"-d\", COMPOSE_SERVICE_NAME)\nSTART_APP_EXTERNAL = (\n    \"docker-compose\",\n    \"-f\",\n    COMPOSE_FILE,\n    \"-f\",\n    INTEGRATION_COMPOSE_FILE,\n    \"up\",\n    \"-d\",\n    COMPOSE_SERVICE_NAME,\n)\n"}
{"type": "source_file", "path": "noxfiles/run_infrastructure.py", "content": "\"\"\"\nThis file invokes a command used to setup infrastructure for use in testing Fidesops\nand related workflows.\n\"\"\"\n# pylint: disable=inconsistent-return-statements\nimport argparse\nimport subprocess\nimport sys\nfrom time import sleep\nfrom typing import List\n\nfrom constants_nox import COMPOSE_SERVICE_NAME\n\nDOCKER_WAIT = 5\nDOCKERFILE_DATASTORES = [\n    \"mssql\",\n    \"postgres\",\n    \"mysql\",\n    \"mongodb\",\n    \"mariadb\",\n    \"timescale\",\n]\nEXTERNAL_DATASTORE_CONFIG = {\n    \"snowflake\": [\"SNOWFLAKE_TEST_URI\"],\n    \"redshift\": [\"REDSHIFT_TEST_URI\", \"REDSHIFT_TEST_DB_SCHEMA\"],\n    \"bigquery\": [\"BIGQUERY_KEYFILE_CREDS\", \"BIGQUERY_DATASET\"],\n}\nEXTERNAL_DATASTORES = list(EXTERNAL_DATASTORE_CONFIG.keys())\nALL_DATASTORES = DOCKERFILE_DATASTORES + EXTERNAL_DATASTORES\nOPS_TEST_DIR = \"tests/ops/\"\n\n\ndef run_infrastructure(\n    datastores: List[str] = [],  # Which infra should we create? If empty, we create all\n    open_shell: bool = False,  # Should we open a bash shell?\n    pytest_path: str = \"\",  # Which subset of tests should we run?\n    run_application: bool = False,  # Should we run the Fidesops webserver?\n    run_quickstart: bool = False,  # Should we run the quickstart command?\n    run_tests: bool = False,  # Should we run the tests after creating the infra?\n    run_create_test_data: bool = False,  # Should we run the create_test_data command?\n    analytics_opt_out: bool = False,  # Should we opt out of analytics?\n) -> None:\n    \"\"\"\n    - Create a Docker Compose file path for all datastores specified in `datastores`.\n    - Defaults to creating infrastructure for all datastores in `DOCKERFILE_DATASTORES` if none\n    are provided.\n    - Optionally runs integration tests against those datastores from the container identified\n    with `COMPOSE_SERVICE_NAME`.\n    \"\"\"\n\n    if len(datastores) == 0:\n        _run_cmd_or_err(\n            'echo \"no datastores specified, configuring infrastructure for all datastores\"'\n        )\n        datastores = DOCKERFILE_DATASTORES + EXTERNAL_DATASTORES\n    else:\n        _run_cmd_or_err(f'echo \"datastores specified: {\", \".join(datastores)}\"')\n\n    # De-duplicate datastores\n    datastores = list(set(datastores))\n\n    # Configure docker-compose path\n    path: str = get_path_for_datastores(datastores)\n\n    _run_cmd_or_err(f'echo \"infrastructure path: {path}\"')\n    if \"mssql\" not in datastores:\n        _run_cmd_or_err(\n            f'docker-compose {path} build --build-arg SKIP_MSSQL_INSTALLATION=\"true\"'\n        )\n    else:\n        _run_cmd_or_err(f\"docker-compose {path} build\")\n\n    _run_cmd_or_err(f\"docker-compose {path} up -d\")\n\n    wait = min(DOCKER_WAIT * len(datastores), 15)\n    print(f\"Sleeping for: {wait} while infrastructure loads...\")\n    sleep(wait)\n\n    seed_initial_data(\n        datastores,\n        path,\n        service_name=COMPOSE_SERVICE_NAME,\n    )\n\n    if open_shell:\n        return _open_shell(path, COMPOSE_SERVICE_NAME)\n\n    if run_application:\n        return _run_application(path)\n\n    if run_quickstart:\n        return _run_quickstart(path, COMPOSE_SERVICE_NAME)\n\n    if run_tests:\n        # Now run the tests\n        return _run_tests(\n            datastores,\n            docker_compose_path=path,\n            pytest_path=pytest_path,\n            analytics_opt_out=analytics_opt_out,\n        )\n\n    if run_create_test_data:\n        return _run_create_test_data(path, COMPOSE_SERVICE_NAME)\n\n\ndef seed_initial_data(\n    datastores: List[str],\n    path: str,\n    service_name: str,\n) -> None:\n    \"\"\"\n    Seed the datastores with initial data as defined in the file at `setup_path`\n    \"\"\"\n    _run_cmd_or_err('echo \"Seeding initial data for all datastores...\"')\n    for datastore in datastores:\n        if datastore in DOCKERFILE_DATASTORES:\n            setup_path = (\n                f\"{OPS_TEST_DIR}integration_tests/setup_scripts/{datastore}_setup.py\"\n            )\n            _run_cmd_or_err(\n                f'echo \"Attempting to create schema and seed initial data for {datastore} from {setup_path}...\"'\n            )\n            _run_cmd_or_err(\n                f'docker-compose {path} run {service_name} python {setup_path} || echo \"no custom setup logic found for {datastore}, skipping\"'\n            )\n\n\ndef get_path_for_datastores(datastores: List[str]) -> str:\n    \"\"\"\n    Returns the docker-compose file paths for the specified datastores\n    \"\"\"\n    path: str = \"-f docker-compose.yml\"\n    for datastore in datastores:\n        _run_cmd_or_err(f'echo \"configuring infrastructure for {datastore}\"')\n        if datastore in DOCKERFILE_DATASTORES:\n            # We only need to locate the docker-compose file if the datastore runs in Docker\n            path += f\" -f docker/docker-compose.integration-{datastore}.yml\"\n        elif datastore not in EXTERNAL_DATASTORES:\n            # If the specified datastore is not known to us\n            _run_cmd_or_err(f'echo \"Datastore {datastore} is currently not supported\"')\n\n    return path\n\n\ndef _run_cmd_or_err(cmd: str) -> None:\n    \"\"\"\n    Runs a command in the bash prompt and throws an error if the command was not successful\n    \"\"\"\n    with subprocess.Popen(cmd, shell=True) as result:\n        if result.wait() > 0:\n            raise Exception(f\"Error executing command: {cmd}\")\n\n\ndef _run_quickstart(\n    path: str,\n    service_name: str,\n) -> None:\n    \"\"\"\n    Invokes the Fidesops command line quickstart\n    \"\"\"\n    _run_cmd_or_err('echo \"Running the quickstart...\"')\n    _run_cmd_or_err(f\"docker-compose {path} up -d\")\n    _run_cmd_or_err(f\"docker-compose run {service_name} python scripts/quickstart.py\")\n\n\ndef _run_create_test_data(\n    path: str,\n    service_name: str,\n) -> None:\n    \"\"\"\n    Invokes the Fidesops create_user_and_client command\n    \"\"\"\n    _run_cmd_or_err('echo \"Running create test data...\"')\n    _run_cmd_or_err(f\"docker-compose {path} up -d\")\n    _run_cmd_or_err(\n        f\"docker-compose run {service_name} python scripts/create_test_data.py\"\n    )\n\n\ndef _open_shell(\n    path: str,\n    service_name: str,\n) -> None:\n    \"\"\"\n    Opens a bash shell on the container at `service_name`\n    \"\"\"\n    _run_cmd_or_err(f'echo \"Opening bash shell on {service_name}\"')\n    _run_cmd_or_err(f\"docker-compose {path} run {service_name} /bin/bash\")\n\n\ndef _run_application(docker_compose_path: str) -> None:\n    \"\"\"\n    Runs the application at `docker_compose_path` without detaching it from the shell\n    \"\"\"\n    _run_cmd_or_err('echo \"Running application\"')\n    _run_cmd_or_err(f\"docker-compose {docker_compose_path} up\")\n\n\ndef _run_tests(\n    datastores: List[str],\n    docker_compose_path: str,\n    pytest_path: str = \"\",\n    analytics_opt_out: bool = False,\n) -> None:\n    \"\"\"\n    Runs unit tests against the specified datastores\n    \"\"\"\n    if pytest_path is None:\n        pytest_path = \"\"\n\n    path_includes_markers = \"-m\" in pytest_path\n    pytest_markers: str = \"\"\n    if not path_includes_markers:\n        # If the path manually specified already uses markers, don't add more here\n        if set(datastores) == set(DOCKERFILE_DATASTORES + EXTERNAL_DATASTORES):\n            # If all datastores have been specified use the generic `integration` flag\n            pytest_markers += \"integration\"\n        else:\n            # Otherwise only include the datastores provided\n            for datastore in datastores:\n                if len(pytest_markers) == 0:\n                    pytest_markers += f\"integration_{datastore}\"\n                else:\n                    pytest_markers += f\" or integration_{datastore}\"\n\n    environment_variables = \"\"\n    for datastore in EXTERNAL_DATASTORES:\n        if datastore in datastores:\n            for env_var in EXTERNAL_DATASTORE_CONFIG[datastore]:\n                environment_variables += f\"-e {env_var} \"\n\n    if analytics_opt_out:\n        environment_variables += \"-e ANALYTICS_OPT_OUT\"\n\n    pytest_path += f' -m \"{pytest_markers}\"'\n\n    _run_cmd_or_err(\n        f'echo \"running pytest for conditions: {pytest_path} with environment variables: {environment_variables}\"'\n    )\n    _run_cmd_or_err(\n        f\"docker-compose {docker_compose_path} run {environment_variables} {COMPOSE_SERVICE_NAME} pytest {pytest_path}\"\n    )\n\n    # Now tear down the infrastructure\n    _run_cmd_or_err(f\"docker-compose {docker_compose_path} down --remove-orphans\")\n    _run_cmd_or_err('echo \"fin.\"')\n\n\nif __name__ == \"__main__\":\n    if sys.version_info.major < 3:\n        raise Exception(\"Python3 is required to configure Fidesops.\")\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"-d\",\n        \"--datastores\",\n        action=\"extend\",\n        nargs=\"*\",\n        type=str,\n    )\n    parser.add_argument(\n        \"-t\",\n        \"--run_tests\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-p\",\n        \"--pytest_path\",\n    )\n    parser.add_argument(\n        \"-s\",\n        \"--open_shell\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-r\",\n        \"--run_application\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-q\",\n        \"--run_quickstart\",\n        action=\"store_true\",\n    )\n\n    parser.add_argument(\n        \"-a\",\n        \"--analytics_opt_out\",\n        action=\"store_true\",\n    )\n\n    config_args = parser.parse_args()\n\n    run_infrastructure(\n        datastores=config_args.datastores,\n        open_shell=config_args.open_shell,\n        pytest_path=config_args.pytest_path,\n        run_application=config_args.run_application,\n        run_quickstart=config_args.run_quickstart,\n        run_tests=config_args.run_tests,\n        analytics_opt_out=config_args.analytics_opt_out,\n    )\n"}
{"type": "source_file", "path": "noxfiles/dev_nox.py", "content": "\"\"\"Contains the nox sessions for running development environments.\"\"\"\nimport nox\nfrom constants_nox import ANALYTICS_OPT_OUT, COMPOSE_SERVICE_NAME, RUN, START_APP\nfrom docker_nox import build\nfrom run_infrastructure import ALL_DATASTORES, run_infrastructure\n\n\n@nox.session()\ndef dev(session: nox.Session) -> None:\n    \"\"\"Spin up the application. Uses positional arguments for additional features.\"\"\"\n    build(session, \"dev\")\n    session.notify(\"teardown\")\n    datastores = [\n        datastore for datastore in session.posargs if datastore in ALL_DATASTORES\n    ] or None\n    open_shell = \"shell\" in session.posargs\n    if not datastores:\n        if open_shell:\n            session.run(*START_APP, external=True)\n            session.run(*RUN, \"/bin/bash\", external=True)\n        else:\n            session.run(\"docker-compose\", \"up\", COMPOSE_SERVICE_NAME, external=True)\n    else:\n        # Run the webserver with additional datastores\n        run_infrastructure(\n            open_shell=open_shell, run_application=True, datastores=datastores\n        )\n\n\n@nox.session()\ndef dev_with_worker(session: nox.Session) -> None:\n    \"\"\"Spin up the entire application with the celery worker in a separate container.\"\"\"\n    build(session, \"dev\")\n    session.notify(\"teardown\")\n    session.run(\"docker-compose\", \"up\", \"--detach\", \"worker\", external=True)\n    session.run(\n        \"docker-compose\",\n        \"run\",\n        *ANALYTICS_OPT_OUT,\n        \"-e\",\n        \"FIDESOPS__EXECUTION__WORKER_ENABLED=True\",\n        COMPOSE_SERVICE_NAME,\n        external=True,\n    )\n\n\n@nox.session()\ndef quickstart(session: nox.Session) -> None:\n    \"\"\"Run the quickstart tutorial.\"\"\"\n    build(session, \"dev\")\n    session.notify(\"teardown\")\n    run_infrastructure(datastores=[\"mongodb\", \"postgres\"], run_quickstart=True)\n"}
{"type": "source_file", "path": "noxfiles/docker_nox.py", "content": "\"\"\"Contains the nox sessions for docker-related tasks.\"\"\"\nimport nox\nfrom constants_nox import (\n    IMAGE,\n    IMAGE_DEV,\n    IMAGE_LATEST,\n    IMAGE_LOCAL,\n    IMAGE_LOCAL_UI,\n    get_current_tag,\n)\n\n\ndef get_current_image() -> str:\n    \"\"\"Returns the current image tag\"\"\"\n    return f\"{IMAGE}:{get_current_tag()}\"\n\n\n@nox.session()\n@nox.parametrize(\n    \"image\",\n    [\n        nox.param(\"prod\", id=\"prod\"),\n        nox.param(\"dev\", id=\"dev\"),\n        nox.param(\"test\", id=\"test\"),\n        nox.param(\"ui\", id=\"ui\"),\n    ],\n)\ndef build(session: nox.Session, image: str) -> None:\n    \"\"\"Build the Docker containers.\"\"\"\n\n    # The lambdas are a workaround to lazily evaluate get_current_image\n    # This allows the dev deployment to run without needing other dev requirements\n    build_matrix = {\n        \"prod\": {\"tag\": get_current_image, \"target\": \"prod\"},\n        \"dev\": {\"tag\": lambda: IMAGE_LOCAL, \"target\": \"dev\"},\n        \"test\": {\"tag\": lambda: IMAGE_LOCAL, \"target\": \"prod\"},\n        \"ui\": {\"tag\": lambda: IMAGE_LOCAL_UI, \"target\": \"frontend\"},\n    }\n    target = build_matrix[image][\"target\"]\n    tag = build_matrix[image][\"tag\"]\n    session.run(\n        \"docker\",\n        \"build\",\n        f\"--target={target}\",\n        \"--tag\",\n        tag(),\n        \".\",\n        external=True,\n    )\n\n\n@nox.session()\n@nox.parametrize(\n    \"tag\",\n    [\n        nox.param(\"prod\", id=\"prod\"),\n        nox.param(\"dev\", id=\"dev\"),\n    ],\n)\ndef push(session: nox.Session, tag: str) -> None:\n    \"\"\"Push the Docker image to Dockerhub.\"\"\"\n\n    tag_matrix = {\"prod\": IMAGE_LATEST, \"dev\": IMAGE_DEV}\n\n    # Push either \"ethyca/fidesops:dev\" or \"ethyca/fidesops:latest\"\n    session.run(\"docker\", \"tag\", get_current_image(), tag_matrix[tag], external=True)\n    session.run(\"docker\", \"push\", tag_matrix[tag], external=True)\n\n    # Only push the tagged version if its for prod\n    # Example: \"ethyca/fidesops:1.7.0\"\n    if tag == \"prod\":\n        session.run(\"docker\", \"push\", f\"{IMAGE}:{get_current_tag()}\", external=True)\n"}
{"type": "source_file", "path": "noxfiles/docs_nox.py", "content": "\"\"\"Contains the nox sessions for developing docs.\"\"\"\nimport nox\nfrom constants_nox import CI_ARGS, RUN\nfrom docker_nox import build\n\n\n@nox.session()\n@nox.parametrize(\n    \"build_type\", [nox.param(\"local\", id=\"local\"), nox.param(\"ci\", id=\"ci\")]\n)\ndef docs_build(session: nox.Session, build_type: str) -> None:\n    \"\"\"Build docs from the source code.\"\"\"\n    session.notify(\"teardown\")\n    if build_type == \"local\":\n        build(session, \"dev\")\n    run_shell = (\n        *RUN,\n        \"python\",\n        \"scripts/generate_openapi.py\",\n        \"docs/fidesops/docs/api/openapi.json\",\n    )\n    session.run(*run_shell, external=True)\n\n\n@nox.session()\ndef docs_serve(session: nox.Session) -> None:\n    \"\"\"Serve the docs.\"\"\"\n    docs_build(session, \"local\")\n    session.notify(\"teardown\")\n    session.run(\"docker-compose\", \"build\", \"docs\", external=True)\n    run_shell = (\n        \"docker-compose\",\n        \"run\",\n        \"--rm\",\n        \"--service-ports\",\n        CI_ARGS,\n        \"docs\",\n        \"/bin/bash\",\n        \"-c\",\n        \"mkdocs serve --dev-addr=0.0.0.0:8000\",\n    )\n    session.run(*run_shell, external=True)\n\n\n@nox.session()\ndef docs_check(session: nox.Session) -> None:\n    \"\"\"Check that the docs can build.\"\"\"\n    docs_build(session, \"ci\")\n    session.notify(\"teardown\")\n    session.run(\"docker-compose\", \"build\", \"docs\", external=True)\n    run_shell = (\n        \"docker-compose\",\n        \"run\",\n        \"--rm\",\n        \"--service-ports\",\n        CI_ARGS,\n        \"docs\",\n        \"/bin/bash\",\n        \"-c\",\n        \"mkdocs build\",\n    )\n    session.run(*run_shell, external=True)\n"}
{"type": "source_file", "path": "noxfiles/utils_nox.py", "content": "\"\"\"Contains various utility-related nox sessions.\"\"\"\nimport nox\nfrom constants_nox import COMPOSE_FILE, RUN\nfrom run_infrastructure import run_infrastructure\n\nCOMPOSE_DOWN = (\n    \"docker-compose\",\n    \"-f\",\n    COMPOSE_FILE,\n    \"-f\",\n    \"docker/docker-compose.integration-mariadb.yml\",\n    \"-f\",\n    \"docker/docker-compose.integration-mongodb.yml\",\n    \"-f\",\n    \"docker/docker-compose.integration-mysql.yml\",\n    \"-f\",\n    \"docker/docker-compose.integration-timescale.yml\",\n    \"-f\",\n    \"docker/docker-compose.integration-postgres.yml\",\n    \"-f\",\n    \"docker/docker-compose.integration-mssql.yml\",\n    \"down\",\n    \"--remove-orphans\",\n)\n\n\n@nox.session()\ndef seed_test_data(session: nox.Session) -> None:\n    \"\"\"Seed test data in the Postgres application database.\"\"\"\n    run_infrastructure(datastores=[\"postgres\"], run_create_test_data=True)\n\n\n@nox.session()\n@nox.parametrize(\n    \"db_command\",\n    [\n        nox.param(\"init\", id=\"init\"),\n        nox.param(\"reset\", id=\"reset\"),\n    ],\n)\ndef db(session: nox.Session, db_command: str) -> None:\n    \"\"\"Run commands against the database.\"\"\"\n    teardown(session)\n    if db_command == \"reset\":\n        reset_command = (\"docker\", \"volume\", \"rm\", \"-f\", \"fidesops_app-db-data\")\n        session.run(*reset_command, external=True)\n    init_command = (\n        \"python\",\n        \"-c\",\n        \"from fidesops.ops.db.database import init_db; from fidesops.ops.core.config import config; init_db(config.database.sqlalchemy_database_uri)\",\n    )\n    session.run(*RUN, *init_command, external=True)\n\n\n@nox.session()\ndef clean(session: nox.Session) -> None:\n    \"\"\"\n    Clean up docker containers, remove orphans, remove volumes\n    and prune images related to this project.\n    \"\"\"\n    clean_command = (*COMPOSE_DOWN, \"--volumes\", \"--rmi\", \"all\")\n    session.run(*clean_command, external=True)\n    session.run(\"docker\", \"system\", \"prune\", \"--force\", external=True)\n    print(\"Clean Complete!\")\n\n\n@nox.session()\ndef teardown(session: nox.Session) -> None:\n    \"\"\"Tear down the docker dev environment.\"\"\"\n    session.run(*COMPOSE_DOWN, external=True)\n    print(\"Teardown complete\")\n\n\ndef install_requirements(session: nox.Session) -> None:\n    session.install(\"-r\", \"requirements.txt\")\n    session.install(\"-r\", \"dev-requirements.txt\")\n"}
{"type": "source_file", "path": "scripts/generate_openapi.py", "content": "\"\"\"\nExports the OpenAPI JSON to a file, which can then be imported into the mkdocs site.\n\nUsage:\n  python generate_openapi.py [outfile_path]\n\n  outfile_path: file path to write the output file to (defaults to \"openapi.json\")\n\"\"\"\nimport json\nimport sys\n\nfrom fidesops.main import app\n\nif __name__ == \"__main__\":\n    outfile_path = \"openapi.json\"\n\n    if len(sys.argv) > 1:\n        outfile_path = sys.argv[1]\n    print(f\"Generating OpenAPI JSON from fidesops and writing to '{outfile_path}'...\")\n    with open(outfile_path, \"w\") as outfile:\n        json.dump(app.openapi(), outfile, indent=2)\n        print(f\"Exported OpenAPI JSON from fidesops to '{outfile_path}'\")\n"}
{"type": "source_file", "path": "scripts/mssql_discover.py", "content": "# This file is not committed to the repo, please create secrets.py with the required\n# variables in the same dir as this file before running this script\nfrom secrets import DB, IP, PASS, PORT, USER\n\nimport sqlalchemy\n\nMASTER_MSSQL_URL = f\"mssql+pyodbc://{USER}:{PASS}@{IP}:{PORT}/{DB}?driver=ODBC+Driver+17+for+SQL+Server\"\n\n\nSUPPORTED_DATA_TYPES = set(\n    [\n        # char types\n        \"varchar\",\n        \"nvarchar\",\n        \"char\",\n        \"nchar\",\n        \"ntext\",\n        \"text\",\n        # numeric types\n        \"int\",\n        \"bigint\",\n        \"smallint\",\n        \"tinyint\",\n        \"money\",\n        \"float\",\n        \"decimal\",\n        # date types\n        \"date\",\n        \"datetime\",\n        \"datetime2\",\n        \"smalldatetime\",\n        # other types\n        \"bit\",\n    ]\n)\n\n\ndef mssql_discover():\n    \"\"\"\n    Select all databases from the instance\n    Select the schema data for each data base\n    Check if there are any fields in the schema that Fidesops does not yet support\n    \"\"\"\n    engine = sqlalchemy.create_engine(MASTER_MSSQL_URL)\n    all_dbs = engine.execute(\"SELECT name FROM sys.databases;\").all()\n    all_columns = []\n    flagged_columns = []\n    flagged_datatypes = set()\n    for db_name in all_dbs:\n        db_name = db_name[0]\n        try:\n            columns = engine.execute(\n                f\"SELECT TABLE_NAME, COLUMN_NAME, DATA_TYPE FROM {db_name}.INFORMATION_SCHEMA.COLUMNS;\"\n            ).all()\n        except Exception:\n            continue\n\n        all_columns.extend(columns)\n        for table, column, data_type in columns:\n            if data_type not in SUPPORTED_DATA_TYPES:\n                flagged_datatypes.add(data_type)\n                flagged_columns.append(f\"{db_name}.{table}.{column}: {data_type}\")\n\n    print(f\"{len(all_columns)} columns found\")\n    print(f\"{len(flagged_columns)} columns flagged\")\n    print(f\"Flagged datatypes:\")\n    print(\",\\n\".join(flagged_datatypes))\n    print(f\"Flagged columns:\")\n    print(\",\\n\".join(flagged_columns))\n\n\nif __name__ == \"__main__\":\n    mssql_discover()\n"}
{"type": "source_file", "path": "scripts/quickstart.py", "content": "\"\"\"\nA five-step fidesops quickstart\n\"\"\"\nimport json\nimport logging\nimport os\nimport time\nfrom datetime import datetime\nfrom os.path import exists\nfrom time import sleep\nfrom typing import Optional\n\nimport requests\nimport yaml\n\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.connectionconfig import ConnectionType\nfrom fidesops.ops.models.policy import ActionType\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\n\n\ndef get_access_token(client_id: str, client_secret: str) -> str:\n    \"\"\"\n    Authorize with fidesops via OAuth.\n    Returns a valid access token if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-OAuth-acquire_access_token_api_v1_oauth_token_post\n    \"\"\"\n    data = {\n        \"grant_type\": \"client_credentials\",\n        \"client_id\": client_id,\n        \"client_secret\": client_secret,\n    }\n    response = requests.post(f\"{FIDESOPS_URL}/api/v1/oauth/token\", data=data)\n\n    if response.ok:\n        token = (response.json())[\"access_token\"]\n        if token:\n            logger.info(\"Completed fidesops oauth login via /api/v1/oauth/token\")\n            return token\n\n    raise RuntimeError(\n        f\"fidesops oauth login failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef create_oauth_client():\n    \"\"\"\n    Create a new OAuth client in fidesops.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-OAuth-acquire_access_token_api_v1_oauth_token_post\n    See http://localhost:8000/api#operations-OAuth-acquire_access_token_api_v1_oauth_token_post\n    \"\"\"\n    scopes_data = [\n        \"client:create\",\n        \"client:update\",\n        \"client:read\",\n        \"client:delete\",\n        \"policy:create_or_update\",\n        \"policy:read\",\n        \"policy:delete\",\n        \"connection:create_or_update\",\n        \"connection:read\",\n        \"connection:delete\",\n        \"privacy-request:read\",\n        \"privacy-request:delete\",\n        \"rule:create_or_update\",\n        \"rule:read\",\n        \"rule:delete\",\n        \"storage:create_or_update\",\n        \"storage:read\",\n        \"storage:delete\",\n        \"dataset:create_or_update\",\n        \"dataset:read\",\n        \"dataset:delete\",\n    ]\n    response = requests.post(\n        f\"{FIDESOPS_URL}/api/v1/oauth/client\",\n        headers=root_oauth_header,\n        json=scopes_data,\n    )\n\n    if response.ok:\n        created_client = response.json()\n        if created_client[\"client_id\"] and created_client[\"client_secret\"]:\n            logger.info(\"Created fidesops oauth client via /api/v1/oauth/client\")\n            return created_client\n\n    raise RuntimeError(\n        f\"fidesops oauth client creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef create_connection(key: str, connection_type: ConnectionType):\n    \"\"\"\n    Create a connection in fidesops for your PostgreSQL database\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Connections-put_connections_api_v1_connection_put\n    \"\"\"\n    connection_create_data = [\n        {\n            \"name\": key,\n            \"key\": key,\n            \"connection_type\": connection_type.value,\n            \"access\": \"write\",\n        },\n    ]\n    response = requests.patch(\n        f\"{FIDESOPS_URL}/api/v1/connection\",\n        headers=oauth_header,\n        json=connection_create_data,\n    )\n\n    if response.ok:\n        connections = (response.json())[\"succeeded\"]\n        if len(connections) > 0:\n            logger.info(\n                f\"Created fidesops {connection_type.value} connection with key={key} via /api/v1/connection\"\n            )\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops connection creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef configure_postgres_connection(\n    key: str, host: str, port: int, dbname: str, username: str, password: str\n):\n    \"\"\"\n    Configure the connection with the given `key` in fidesops with your PostgreSQL database credentials.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Connections-put_connection_config_secrets_api_v1_connection__connection_key__secret_put\n    \"\"\"\n    connection_secrets_data = {\n        \"host\": host,\n        \"port\": port,\n        \"dbname\": dbname,\n        \"username\": username,\n        \"password\": password,\n    }\n    response = requests.put(\n        f\"{FIDESOPS_URL}/api/v1/connection/{key}/secret\",\n        headers=oauth_header,\n        json=connection_secrets_data,\n    )\n\n    if response.ok:\n        if (response.json())[\"test_status\"] != \"failed\":\n            logger.info(\n                f\"Configured fidesops postgres connection secrets for via /api/v1/connection/{key}/secret\"\n            )\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops connection configuration failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef configure_mongo_connection(\n    key: str, host: str, port: int, dbname: str, username: str, password: str\n):\n    \"\"\"\n    Configure the connection with the given `key` in fidesops with your PostgreSQL database credentials.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Connections-put_connection_config_secrets_api_v1_connection__connection_key__secret_put\n    \"\"\"\n    connection_secrets_data = {\n        \"host\": host,\n        \"port\": port,\n        \"defaultauthdb\": dbname,\n        \"username\": username,\n        \"password\": password,\n    }\n    response = requests.put(\n        f\"{FIDESOPS_URL}/api/v1/connection/{key}/secret\",\n        headers=oauth_header,\n        json=connection_secrets_data,\n    )\n\n    if response.ok:\n        if (response.json())[\"test_status\"] != \"failed\":\n            logger.info(\n                f\"Configured fidesops mongo connection secrets via /api/v1/connection/{key}/secret\"\n            )\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops connection configuration failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef validate_dataset(connection_key: str, yaml_path: str):\n    \"\"\"\n    Validate a dataset in fidesops given a YAML manifest file.\n    Requires the `connection_key` for the connection, and `yaml_path`\n    that is a local filepath to a .yml dataset Fides manifest file.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Datasets-validate_dataset_api_v1_connection__connection_key__validate_dataset_put\n    \"\"\"\n\n    with open(yaml_path, \"r\") as file:\n        dataset = yaml.safe_load(file).get(\"dataset\", [])[0]\n\n    validate_dataset_data = dataset\n    response = requests.put(\n        f\"{FIDESOPS_URL}/api/v1/connection/{connection_key}/validate_dataset\",\n        headers=oauth_header,\n        json=validate_dataset_data,\n    )\n\n    if response.ok:\n        traversal_details = (response.json())[\"traversal_details\"]\n        if traversal_details[\"is_traversable\"]:\n            logger.info(\n                f\"Validated fidesops dataset via /api/v1/connection/{connection_key}/dataset\"\n            )\n            return response.json()\n        else:\n            raise RuntimeError(\n                f\"fidesops dataset is not traversable! traversal_details={traversal_details}\"\n            )\n    print(vars(response))\n    raise RuntimeError(\n        f\"fidesops dataset creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef create_dataset(connection_key: str, yaml_path: str):\n    \"\"\"\n    Create a dataset in fidesops given a YAML manifest file.\n    Requires the `connection_key` for the PostgreSQL connection, and `yaml_path`\n    that is a local filepath to a .yml dataset Fides manifest file.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Datasets-put_datasets_api_v1_connection__connection_key__dataset_put\n    \"\"\"\n\n    with open(yaml_path, \"r\") as file:\n        dataset = yaml.safe_load(file).get(\"dataset\", [])[0]\n\n    dataset_create_data = [dataset]\n    response = requests.patch(\n        f\"{FIDESOPS_URL}/api/v1/connection/{connection_key}/dataset\",\n        headers=oauth_header,\n        json=dataset_create_data,\n    )\n\n    if response.ok:\n        datasets = (response.json())[\"succeeded\"]\n        if len(datasets) > 0:\n            logger.info(\n                f\"Created fidesops dataset via /api/v1/connection/{connection_key}/dataset\"\n            )\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops dataset creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef create_local_storage(key: str, file_format: str):\n    \"\"\"\n    Create a storage config in fidesops to write to a local file.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Storage-put_config_api_v1_storage_config_put\n    \"\"\"\n    storage_create_data = [\n        {\n            \"name\": key,\n            \"key\": key,\n            \"type\": \"local\",\n            \"format\": file_format,\n            \"details\": {\n                \"naming\": \"request_id\",\n            },\n        },\n    ]\n    response = requests.patch(\n        f\"{FIDESOPS_URL}/api/v1/storage/config\",\n        headers=oauth_header,\n        json=storage_create_data,\n    )\n\n    if response.ok:\n        storage = (response.json())[\"succeeded\"]\n        if len(storage) > 0:\n            logger.info(\n                f\"Created fidesops storage with key={key} via /api/v1/storage/config\"\n            )\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops storage creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef create_policy(key: str):\n    \"\"\"\n    Create a request policy in fidesops with the given key.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Policy-create_or_update_policies_api_v1_policy_put\n    \"\"\"\n\n    policy_create_data = [\n        {\n            \"name\": key,\n            \"key\": key,\n            \"execution_timeframe\": 45,\n        },\n    ]\n    response = requests.patch(\n        f\"{FIDESOPS_URL}/api/v1/policy\",\n        headers=oauth_header,\n        json=policy_create_data,\n    )\n\n    if response.ok:\n        policies = (response.json())[\"succeeded\"]\n        if len(policies) > 0:\n            logger.info(\"Created fidesops policy with key=%s via /api/v1/policy\", key)\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops policy creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef delete_policy_rule(policy_key: str, key: str):\n    \"\"\"\n    Deletes a policy rule with the given key.\n    Returns the response JSON.\n    See http://localhost:8000/api#operations-Policy-delete_rule_api_v1_policy__policy_key__rule__rule_key__delete\n    \"\"\"\n    return requests.delete(\n        f\"{FIDESOPS_URL}/api/v1/policy/{policy_key}/rule/{key}\", headers=oauth_header\n    )\n\n\ndef create_policy_rule(\n    policy_key: str,\n    key: str,\n    action_type: ActionType,\n    storage_destination_key: Optional[str] = None,\n):\n    \"\"\"\n    Create a policy rule to return matched data in an access request to the given storage destination.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Policy-create_or_update_rules_api_v1_policy__policy_key__rule_put\n    \"\"\"\n\n    rule_create_data = {\n        \"name\": key,\n        \"key\": key,\n        \"action_type\": action_type.value,\n    }\n\n    if action_type == ActionType.access:\n        rule_create_data[\"storage_destination_key\"] = storage_destination_key\n    elif action_type == ActionType.erasure:\n        # Only null masking supported currently\n        rule_create_data[\"masking_strategy\"] = {\n            \"strategy\": \"null_rewrite\",\n            \"configuration\": {},\n        }\n\n    response = requests.patch(\n        f\"{FIDESOPS_URL}/api/v1/policy/{policy_key}/rule\",\n        headers=oauth_header,\n        json=[rule_create_data],\n    )\n\n    if response.ok:\n        rules = (response.json())[\"succeeded\"]\n        if len(rules) > 0:\n            logger.info(\n                f\"Created fidesops policy rule via /api/v1/policy/{policy_key}/rule\"\n            )\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops policy rule creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef create_policy_rule_target(policy_key: str, rule_key: str, data_cat: str):\n    \"\"\"\n    Create a policy rule target that matches the given data_category.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Policy-create_or_update_rule_targets_api_v1_policy__policy_key__rule__rule_key__target_put\n    \"\"\"\n\n    target_create_data = [\n        {\n            \"data_category\": data_cat,\n        },\n    ]\n    response = requests.patch(\n        f\"{FIDESOPS_URL}/api/v1/policy/{policy_key}/rule/{rule_key}/target\",\n        headers=oauth_header,\n        json=target_create_data,\n    )\n\n    if response.ok:\n        targets = (response.json())[\"succeeded\"]\n        if len(targets) > 0:\n            logger.info(\n                f\"Created fidesops policy rule target for '{data_cat}' via /api/v1/policy/{policy_key}/rule/{rule_key}/target\"\n            )\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops policy rule target creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef create_privacy_request(user_email: str, policy_key: str):\n    \"\"\"\n    Create a privacy request that is executed against the given request policy.\n    Returns the response JSON if successful, or throws an error otherwise.\n    See http://localhost:8000/api#operations-Privacy_Requests-create_privacy_request_api_v1_privacy_request_post\n    \"\"\"\n\n    privacy_request_data = [\n        {\n            \"requested_at\": str(datetime.utcnow()),\n            \"policy_key\": policy_key,\n            \"identity\": {\"email\": user_email},\n        },\n    ]\n    response = requests.post(\n        f\"{FIDESOPS_URL}/api/v1/privacy-request\",\n        json=privacy_request_data,\n    )\n\n    if response.ok:\n        created_privacy_requests = (response.json())[\"succeeded\"]\n        if len(created_privacy_requests) > 0:\n            logger.info(\n                f\"Created fidesops privacy request for email={email} via /api/v1/privacy-request\"\n            )\n            return response.json()\n\n    raise RuntimeError(\n        f\"fidesops privacy request creation failed! response.status_code={response.status_code}, response.json()={response.json()}\"\n    )\n\n\ndef print_results(request_id: str) -> None:\n    \"\"\"\n    Check to see if a result JSON for the given privacy request exists, and\n    print it to the console if so.\n    \"\"\"\n    results_path = f\"fides_uploads/{request_id}.json\"\n\n    count = 0\n    max_allowed_waiting = 10\n    while not os.path.exists(results_path) and count < max_allowed_waiting:\n        logger.info(\"Waiting for privacy request results...\")\n        time.sleep(5)\n        count += 1  # Only loop through a reasonable number of times\n\n    if exists(results_path):\n        logger.info(\n            f\"Successfully read fidesops privacy request results from {results_path}:\"\n        )\n        with open(results_path, \"r\") as file:\n            results_json = json.loads(file.read())\n            print(json.dumps(results_json, indent=4))\n    else:\n        raise RuntimeError(\n            f\"fidesops privacy request results not found at results_path={results_path}\"\n        )\n\n\nif __name__ == \"__main__\":\n    sleep(10)\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"\"\"\n    ┌┬┐┬ ┬┌─┐  ┌─┐┬┌┬┐┌─┐┌─┐┌─┐┌─┐┌─┐  ┌─┐ ┬ ┬┬┌─┐┬┌─┌─┐┌┬┐┌─┐┬─┐┌┬┐\n     │ ├─┤├┤   ├┤ │ ││├┤ └─┐│ │├─┘└─┐  │─┼┐│ │││  ├┴┐└─┐ │ ├─┤├┬┘ │ \n     ┴ ┴ ┴└─┘  └  ┴ ┴┘└─┘└─┘└─┘┴  └─┘  └─┘└└─┘┴└─┘┴ ┴└─┘ ┴ ┴ ┴┴└─ ┴ \n    \"\"\"\n    )\n\n    # NOTE: In a real application, these secrets and config values would be provided\n    # via ENV vars or similar, but we've inlined everything here for simplicity\n    FIDESOPS_URL = \"http://webserver:8080\"\n    ROOT_CLIENT_ID = \"fidesopsadmin\"\n    ROOT_CLIENT_SECRET = \"fidesopsadminsecret\"\n\n    POSTGRES_SERVER = \"host.docker.internal\"\n    POSTGRES_USER = \"postgres\"\n    POSTGRES_PASSWORD = \"postgres\"\n    POSTGRES_PORT = 6432\n    POSTGRES_DB_NAME = \"postgres_example\"\n\n    MONGO_SERVER = \"mongodb_example\"\n    MONGO_USER = \"mongo_user\"\n    MONGO_PASSWORD = \"mongo_pass\"\n    MONGO_PORT = 27017\n    MONGO_DB = \"mongo_test\"\n\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\"Setting up the fidesops environment with the following test configuration:\")\n    print(f\"  FIDESOPS_URL = {FIDESOPS_URL}\")\n    print(f\"  ROOT_CLIENT_ID = {ROOT_CLIENT_ID}\")\n    print(f\"  ROOT_CLIENT_SECRET = {ROOT_CLIENT_SECRET}\")\n    print(f\"  POSTGRES_SERVER = {POSTGRES_SERVER}\")\n    print(f\"  POSTGRES_USER = {POSTGRES_USER}\")\n    print(f\"  POSTGRES_PASSWORD = {POSTGRES_PASSWORD}\")\n    print(f\"  POSTGRES_PORT = {POSTGRES_PORT}\")\n    print(f\"  POSTGRES_DB_NAME = {POSTGRES_DB_NAME}\")\n    print(f\"  MONGO_SERVER = {MONGO_SERVER}\")\n    print(f\"  MONGO_USER = {MONGO_USER}\")\n    print(f\"  MONGO_PASSWORD = {MONGO_PASSWORD}\")\n    print(f\"  MONGO_PORT = {MONGO_PORT}\")\n    print(f\"  MONGO_DB = {MONGO_DB}\")\n\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"\"\"\n    ┌─┐┌┬┐┌─┐┌─┐  ┌─┐┌┐┌┌─┐\n    └─┐ │ ├┤ ├─┘  │ ││││├┤     ...  Set up basic configuration\n    └─┘ ┴ └─┘┴    └─┘┘└┘└─┘  \n    \"\"\"\n    )\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n\n    # Create a new OAuth client to use for your app\n    print(\"Press [enter] to create an Oauth Token...\")\n    input()\n\n    root_token = get_access_token(\n        client_id=config.security.oauth_root_client_id,\n        client_secret=config.security.oauth_root_client_secret,\n    )\n    root_oauth_header = {\"Authorization\": f\"Bearer {root_token}\"}\n    client = create_oauth_client()\n    access_token = get_access_token(\n        client_id=client[\"client_id\"], client_secret=client[\"client_secret\"]\n    )\n    # In scope for all the methods below to use\n    oauth_header = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    # Connect to your PostgreSQL database\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\"Press [enter] to connect fidesops to your test PostgreSQL database...\")\n    input()\n\n    create_connection(\n        key=\"test_application_postgres_db\", connection_type=ConnectionType.postgres\n    )\n    configure_postgres_connection(\n        key=\"test_application_postgres_db\",\n        host=POSTGRES_SERVER,\n        port=POSTGRES_PORT,\n        dbname=POSTGRES_DB_NAME,\n        username=POSTGRES_USER,\n        password=POSTGRES_PASSWORD,\n    )\n\n    # Connect to your Mongo database\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\"Press [enter] to connect fidesops to your test Mongo database...\")\n    input()\n\n    create_connection(\n        key=\"test_application_mongo_db\", connection_type=ConnectionType.mongodb\n    )\n    sleep(5)\n    configure_mongo_connection(\n        key=\"test_application_mongo_db\",\n        host=MONGO_SERVER,\n        port=MONGO_PORT,\n        dbname=MONGO_DB,\n        username=MONGO_USER,\n        password=MONGO_PASSWORD,\n    )\n\n    # Upload the dataset YAML for your PostgreSQL schema\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"Press [enter] to define the data categories and relationships in your Postgres tables...\"\n    )\n    input()\n\n    validate_dataset(\n        connection_key=\"test_application_postgres_db\",\n        yaml_path=\"data/dataset/postgres_example_test_dataset.yml\",\n    )\n    postgres_dataset = create_dataset(\n        connection_key=\"test_application_postgres_db\",\n        yaml_path=\"data/dataset/postgres_example_test_dataset.yml\",\n    )\n\n    # Upload the dataset YAML for your MongoDB schema\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"Press [enter] to define the data categories and relationships in your Mongo collections...\"\n    )\n    input()\n\n    mongo_dataset = create_dataset(\n        connection_key=\"test_application_mongo_db\",\n        yaml_path=\"data/dataset/mongo_example_test_dataset.yml\",\n    )\n\n    # Configure a storage config to upload the results\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"Press [enter] to configure a storage destination to upload your final results (just local for now)...\"\n    )\n    input()\n\n    create_local_storage(\n        key=\"example_storage\",\n        file_format=\"json\",\n    )\n\n    # Create a policy that returns all user identifiable contact data\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"\"\"\n    ┌─┐┌┬┐┌─┐┌─┐  ┌┬┐┬ ┬┌─┐\n    └─┐ │ ├┤ ├─┘   │ ││││ │  ...  Create an access policy rule\n    └─┘ ┴ └─┘┴     ┴ └┴┘└─┘\n    \"\"\"\n    )\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    data_category = \"user\"\n    print(\n        f\"Press [enter] to create a Policy Rule that accesses information with the data category '{data_category}':\"\n    )\n    input()\n\n    create_policy(\n        key=\"example_request_policy\",\n    )\n    # Delete any existing policy rule so we can reconfigure it based on input\n    delete_policy_rule(\n        policy_key=\"example_request_policy\",\n        key=\"access_user_data\",\n    )\n    create_policy_rule(\n        policy_key=\"example_request_policy\",\n        key=\"access_user_data\",\n        action_type=ActionType.access,\n        storage_destination_key=\"example_storage\",\n    )\n    create_policy_rule_target(\n        policy_key=\"example_request_policy\",\n        rule_key=\"access_user_data\",\n        data_cat=data_category,\n    )\n\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"\"\"\n    ┌─┐┌┬┐┌─┐┌─┐  ┌┬┐┬ ┬┬─┐┌─┐┌─┐\n    └─┐ │ ├┤ ├─┘   │ ├─┤├┬┘├┤ ├┤    ...  Run an access privacy request\n    └─┘ ┴ └─┘┴     ┴ ┴ ┴┴└─└─┘└─┘\n    \"\"\"\n    )\n\n    # Execute a privacy request\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    email = \"jane@example.com\"\n    print(\n        f\"Press [enter] to run an access request for {email} with Policy `example_request_policy`:\"\n    )\n    input()\n    print(\"Please wait...\")\n    privacy_requests = create_privacy_request(\n        user_email=email,\n        policy_key=\"example_request_policy\",\n    )\n    privacy_request_id = privacy_requests[\"succeeded\"][0][\"id\"]\n    print_results(request_id=privacy_request_id)\n\n    sleep(2)\n\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"\"\"\n    ┌─┐┌┬┐┌─┐┌─┐  ┌─┐┌─┐┬ ┬┬─┐\n    └─┐ │ ├┤ ├─┘  ├┤ │ ││ │├┬┘   ...  Create an erasure policy rule\n    └─┘ ┴ └─┘┴    └  └─┘└─┘┴└─    \n    \"\"\"\n    )\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n\n    # Create a policy that erases all user data\n    print(\n        f\"Press [enter] to create a Policy Rule describing how to erase information with the data category `{data_category}`:\"\n    )\n    input()\n\n    create_policy(\n        key=\"example_erasure_policy\",\n    )\n    # Delete any existing policy rule so we can reconfigure it based on input\n    delete_policy_rule(\n        policy_key=\"example_erasure_policy\",\n        key=\"erase_user_data\",\n    )\n    create_policy_rule(\n        policy_key=\"example_erasure_policy\",\n        key=\"erase_user_data\",\n        action_type=ActionType.erasure,\n    )\n    create_policy_rule_target(\n        policy_key=\"example_erasure_policy\",\n        rule_key=\"erase_user_data\",\n        data_cat=data_category,\n    )\n\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    print(\n        \"\"\"\n    ┌─┐┌┬┐┌─┐┌─┐  ┌─┐┬┬  ┬┌─┐\n    └─┐ │ ├┤ ├─┘  ├┤ │└┐┌┘├┤     ...  Issue an erasure privacy request and verify\n    └─┘ ┴ └─┘┴    └  ┴ └┘ └─┘   \n    \"\"\"\n    )\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n\n    # Execute a privacy request for jane@example.com\n    email = \"jane@example.com\"\n    print(\n        f\"Press [enter] to issue an erasure request for email {email}: with policy `example_erasure_policy`\"\n    )\n    input()\n    print(\"Please wait...\")\n    privacy_requests = create_privacy_request(\n        user_email=email,\n        policy_key=\"example_erasure_policy\",\n    )\n    erasure_privacy_request_id = privacy_requests[\"succeeded\"][0][\"id\"]\n\n    print(\n        f\"Press [enter] to issue a follow-up access request to confirm removal of user data for {email}:\"\n    )\n    input()\n    print(\"Please wait...\")\n    privacy_requests = create_privacy_request(\n        user_email=email,\n        policy_key=\"example_request_policy\",\n    )\n    print(\n        \"-------------------------------------------------------------------------------------\"\n    )\n    access_result_id = privacy_requests[\"succeeded\"][0][\"id\"]\n    print_results(request_id=access_result_id)\n    print(f\"Jane's data has been removed for data category `{data_category}`.\")\n    exit(0)\n"}
{"type": "source_file", "path": "setup.py", "content": "import pathlib\n\nfrom setuptools import find_packages, setup\n\nimport versioneer\n\nhere = pathlib.Path(__file__).parent.resolve()\nlong_description = open(\"README.md\").read()\n\n# Requirements\ninstall_requires = open(\"requirements.txt\").read().strip().split(\"\\n\")\ndev_requires = open(\"dev-requirements.txt\").read().strip().split(\"\\n\")\n\nsetup(\n    name=\"fidesops\",\n    version=versioneer.get_version(),\n    cmdclass=versioneer.get_cmdclass(),\n    description=\"Automation engine for privacy requests\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/ethyca/fidesops\",\n    entry_points={\"console_scripts\": [\"fidesops=fidesops.ops.cli:cli\"]},\n    python_requires=\">=3.7, <4\",\n    package_dir={\"\": \"src\"},\n    packages=find_packages(where=\"src\"),\n    package_data={\"fidesops\": [\"alembic.ini\"]},\n    include_package_data=True,\n    author=\"Ethyca, Inc.\",\n    author_email=\"fidesteam@ethyca.com\",\n    license=\"Apache License 2.0\",\n    install_requires=install_requires,\n    dev_requires=dev_requires,\n    classifiers=[\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python :: 3 :: Only\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Topic :: Software Development :: Libraries\",\n    ],\n)\n"}
{"type": "source_file", "path": "src/fidesops/_version.py", "content": "# pylint: skip-file\n# type: ignore\n\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.19 (https://github.com/python-versioneer/python-versioneer)\n\n\"\"\"Git implementation of _version.py.\"\"\"\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    \"\"\"Get the keywords needed to look up the version information.\"\"\"\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \"$Format:%d$\"\n    git_full = \"$Format:%H$\"\n    git_date = \"$Format:%ci$\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\n\n\ndef get_config():\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"\"\n    cfg.versionfile_source = \"src/fidesops/_version.py\"\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen(\n                [c] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None),\n            )\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(\n                \"unable to find command, tried %s\" % (commands),\n            )\n        return None, None\n    stdout = p.communicate()[0].strip().decode()\n    if p.returncode != 0:\n        if verbose:\n            print(\"unable to run %s (error)\" % dispcmd)\n            print(\"stdout was %s\" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                \"version\": dirname[len(parentdir_prefix) :],\n                \"full-revisionid\": None,\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": None,\n            }\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\n            \"Tried directories %s but none started with prefix %s\"\n            % (str(rootdirs), parentdir_prefix)\n        )\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")\n\n\n@register_vcs_handler(\"git\", \"get_keywords\")\ndef git_get_keywords(versionfile_abs):\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, \"r\")\n        for line in f.readlines():\n            if line.strip().startswith(\"git_refnames =\"):\n                mo = re.search(r'=\\s*\"(.*)\"', line)\n                if mo:\n                    keywords[\"refnames\"] = mo.group(1)\n            if line.strip().startswith(\"git_full =\"):\n                mo = re.search(r'=\\s*\"(.*)\"', line)\n                if mo:\n                    keywords[\"full\"] = mo.group(1)\n            if line.strip().startswith(\"git_date =\"):\n                mo = re.search(r'=\\s*\"(.*)\"', line)\n                if mo:\n                    keywords[\"date\"] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(\"git\", \"keywords\")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    \"\"\"Get version information from git keywords.\"\"\"\n    if not keywords:\n        raise NotThisMethod(\"no keywords at all, weird\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # Use only the last line.  Previous lines may contain GPG signature\n        # information.\n        date = date.splitlines()[-1]\n\n        # git-2.2.0 added \"%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = set([r.strip() for r in refnames.strip(\"()\").split(\",\")])\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = set([r[len(TAG) :] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = set([r for r in refs if re.search(r\"\\d\", r)])\n        if verbose:\n            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix) :]\n            if verbose:\n                print(\"picking %s\" % r)\n            return {\n                \"version\": r,\n                \"full-revisionid\": keywords[\"full\"].strip(),\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": date,\n            }\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": keywords[\"full\"].strip(),\n        \"dirty\": False,\n        \"error\": \"no suitable tags\",\n        \"date\": None,\n    }\n\n\n@register_vcs_handler(\"git\", \"pieces_from_vcs\")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n\n    out, rc = run_command(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root, hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(\"Directory %s not under git control\" % root)\n        raise NotThisMethod(\"'git rev-parse --git-dir' returned error\")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn't one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(\n        GITS,\n        [\n            \"describe\",\n            \"--tags\",\n            \"--dirty\",\n            \"--always\",\n            \"--long\",\n            \"--match\",\n            \"%s*\" % tag_prefix,\n        ],\n        cwd=root,\n    )\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[: git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\"^(.+)-(\\d+)-g([0-9a-f]+)$\", git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = \"unable to parse git-describe output: '%s'\" % describe_out\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n                print(fmt % (full_tag, tag_prefix))\n            pieces[\"error\"] = \"tag '%s' doesn't start with prefix '%s'\" % (\n                full_tag,\n                tag_prefix,\n            )\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix) :]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        count_out, rc = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"], cwd=root)\n        pieces[\"distance\"] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"], cwd=root)[\n        0\n    ].strip()\n    # Use only the last line.  Previous lines may contain GPG signature\n    # information.\n    date = date.splitlines()[-1]\n    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n\n\ndef render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    \"\"\"TAG[.post0.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post0.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \".post0.dev%d\" % pieces[\"distance\"]\n    else:\n        # exception #1\n        rendered = \"0.post0.dev%d\" % pieces[\"distance\"]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n\n    The \".dev0\" means dirty.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered\n\n\ndef render_git_describe(pieces):\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n\n    Like 'git describe --tags --dirty --always'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render(pieces, style):\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\n            \"version\": \"unknown\",\n            \"full-revisionid\": pieces.get(\"long\"),\n            \"dirty\": None,\n            \"error\": pieces[\"error\"],\n            \"date\": None,\n        }\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\n        \"version\": rendered,\n        \"full-revisionid\": pieces[\"long\"],\n        \"dirty\": pieces[\"dirty\"],\n        \"error\": None,\n        \"date\": pieces.get(\"date\"),\n    }\n\n\ndef get_versions():\n    \"\"\"Get version information or return default if unable to do so.\"\"\"\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\"/\"):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\n            \"version\": \"0+unknown\",\n            \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": \"unable to find root of source tree\",\n            \"date\": None,\n        }\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": None,\n        \"dirty\": None,\n        \"error\": \"unable to compute version\",\n        \"date\": None,\n    }\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/config_endpoints.py", "content": "import logging\nfrom typing import Any, Dict\n\nfrom fastapi.params import Security\n\nfrom fidesops.ops.api.v1 import scope_registry as scopes\nfrom fidesops.ops.api.v1 import urn_registry as urls\nfrom fidesops.ops.core.config import censored_config\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"Config\"], prefix=urls.V1_URL_PREFIX)\n\nlogger = logging.getLogger(__name__)\n\n\n@router.get(\n    urls.CONFIG,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.CONFIG_READ])],\n    response_model=Dict[str, Any],\n)\ndef get_config() -> Dict[str, Any]:\n    \"\"\"Returns the current API exposable Fidesops configuration.\"\"\"\n    logger.info(\"Getting the exposable Fidesops configuration\")\n    return censored_config\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/connection_endpoints.py", "content": "from __future__ import annotations\n\nimport logging\nfrom typing import List, Optional\n\nfrom fastapi import Depends, HTTPException\nfrom fastapi.params import Query, Security\nfrom fastapi_pagination import Page, Params\nfrom fastapi_pagination.bases import AbstractPage\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom fideslib.exceptions import KeyOrNameAlreadyExists\nfrom pydantic import ValidationError, conlist\nfrom sqlalchemy import or_\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy_utils import escape_like\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_204_NO_CONTENT,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1.scope_registry import (\n    CONNECTION_CREATE_OR_UPDATE,\n    CONNECTION_DELETE,\n    CONNECTION_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    CONNECTION_BY_KEY,\n    CONNECTION_SECRETS,\n    CONNECTION_TEST,\n    CONNECTIONS,\n    SAAS_CONFIG,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.common_exceptions import (\n    ClientUnsuccessfulException,\n    ConnectionException,\n)\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig, ConnectionType\nfrom fidesops.ops.models.manual_webhook import AccessManualWebhook\nfrom fidesops.ops.models.privacy_request import PrivacyRequest, PrivacyRequestStatus\nfrom fidesops.ops.schemas.api import BulkUpdateFailed\nfrom fidesops.ops.schemas.connection_configuration import (\n    connection_secrets_schemas,\n    get_connection_secrets_validator,\n)\nfrom fidesops.ops.schemas.connection_configuration.connection_config import (\n    BulkPutConnectionConfiguration,\n    ConnectionConfigurationResponse,\n    CreateConnectionConfiguration,\n    SystemType,\n    TestStatus,\n)\nfrom fidesops.ops.schemas.connection_configuration.connection_secrets import (\n    ConnectionConfigSecretsSchema,\n    ConnectionTestStatus,\n    TestStatusMessage,\n)\nfrom fidesops.ops.schemas.shared_schemas import FidesOpsKey\nfrom fidesops.ops.service.connectors import get_connector\nfrom fidesops.ops.service.privacy_request.request_runner_service import (\n    queue_privacy_request,\n)\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.logger import Pii\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"Connections\"], prefix=V1_URL_PREFIX)\n\nlogger = logging.getLogger(__name__)\n\n\ndef get_connection_config_or_error(\n    db: Session, connection_key: FidesOpsKey\n) -> ConnectionConfig:\n    \"\"\"Helper to load the ConnectionConfig object or throw a 404\"\"\"\n    connection_config = ConnectionConfig.get_by(db, field=\"key\", value=connection_key)\n    logger.info(\"Finding connection configuration with key '%s'\", connection_key)\n    if not connection_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No connection configuration found with key '{connection_key}'.\",\n        )\n    return connection_config\n\n\n@router.get(\n    CONNECTIONS,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_READ])],\n    response_model=Page[ConnectionConfigurationResponse],\n)\ndef get_connections(\n    *,\n    db: Session = Depends(deps.get_db),\n    params: Params = Depends(),\n    search: Optional[str] = None,\n    disabled: Optional[bool] = None,\n    test_status: Optional[TestStatus] = None,\n    system_type: Optional[SystemType] = None,\n    connection_type: Optional[List[ConnectionType]] = Query(\n        default=None\n    ),  # type:ignore\n) -> AbstractPage[ConnectionConfig]:\n    \"\"\"Returns all connection configurations in the database.\n    Optionally filter the key, name, and description with a search query param.\n\n    Can also filter on disabled, connection_type, test_status, and system_type.\n\n    Connection_type supports \"or\" filtering:\n    ?connection_type=postgres&connection_type=mongo will be translated\n    into an \"or\" query.\n    \"\"\"\n    logger.info(\n        \"Finding connection configurations with pagination params %s and search query: '%s'.\",\n        params,\n        search if search else \"\",\n    )\n    query = ConnectionConfig.query(db)\n\n    if search:\n        query = query.filter(\n            or_(\n                ConnectionConfig.key.ilike(f\"%{escape_like(search)}%\"),\n                ConnectionConfig.name.ilike(f\"%{escape_like(search)}%\"),\n                ConnectionConfig.description.ilike(f\"%{escape_like(search)}%\"),\n            )\n        )\n\n    if connection_type:\n        query = query.filter(ConnectionConfig.connection_type.in_(connection_type))\n\n    if disabled is not None:\n        query = query.filter(ConnectionConfig.disabled == disabled)\n\n    if test_status:\n        query = query.filter(\n            ConnectionConfig.last_test_succeeded.is_(test_status.str_to_bool())\n        )\n\n    if system_type:\n        if system_type == SystemType.saas:\n            query = query.filter(\n                ConnectionConfig.connection_type == ConnectionType.saas\n            )\n        elif system_type == SystemType.manual:\n            query = query.filter(\n                ConnectionConfig.connection_type == ConnectionType.manual\n            )\n        elif system_type == SystemType.database:\n            query = query.filter(\n                ConnectionConfig.connection_type.notin_(\n                    [ConnectionType.saas, ConnectionType.manual]\n                )\n            )\n\n    return paginate(\n        query.order_by(ConnectionConfig.name.asc()),\n        params=params,\n    )\n\n\n@router.get(\n    CONNECTION_BY_KEY,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_READ])],\n    response_model=ConnectionConfigurationResponse,\n)\ndef get_connection_detail(\n    connection_key: FidesOpsKey, db: Session = Depends(deps.get_db)\n) -> ConnectionConfig:\n    \"\"\"Returns connection configuration with matching key.\"\"\"\n    return get_connection_config_or_error(db, connection_key)\n\n\n@router.patch(\n    CONNECTIONS,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_CREATE_OR_UPDATE])],\n    status_code=HTTP_200_OK,\n    response_model=BulkPutConnectionConfiguration,\n)\ndef patch_connections(\n    *,\n    db: Session = Depends(deps.get_db),\n    configs: conlist(CreateConnectionConfiguration, max_items=50),  # type: ignore\n) -> BulkPutConnectionConfiguration:\n    \"\"\"\n    Given a list of connection config data elements, create or update corresponding ConnectionConfig objects\n    or report failure\n\n    If the key in the payload exists, it will be used to update an existing ConnectionConfiguration.\n    Otherwise, a new ConnectionConfiguration will be created for you.\n\n    Note that ConnectionConfiguration.secrets are not updated through this endpoint.\n    \"\"\"\n    created_or_updated: List[ConnectionConfig] = []\n    failed: List[BulkUpdateFailed] = []\n    logger.info(\"Starting bulk upsert for %s connection configuration(s)\", len(configs))\n\n    for config in configs:\n        orig_data = config.dict().copy()\n        try:\n            connection_config = ConnectionConfig.create_or_update(\n                db, data=config.dict()\n            )\n            created_or_updated.append(connection_config)\n        except KeyOrNameAlreadyExists as exc:\n            logger.warning(\n                \"Create/update failed for connection config with key '%s': %s\",\n                config.key,\n                exc,\n            )\n            failed.append(\n                BulkUpdateFailed(\n                    message=exc.args[0],\n                    data=orig_data,\n                )\n            )\n        except Exception:\n            logger.warning(\n                \"Create/update failed for connection config with key '%s'.\", config.key\n            )\n            failed.append(\n                BulkUpdateFailed(\n                    message=\"This connection configuration could not be added.\",\n                    data=orig_data,\n                )\n            )\n\n    # Check if possibly disabling a manual webhook here causes us to need to queue affected privacy requests\n    requeue_requires_input_requests(db)\n\n    return BulkPutConnectionConfiguration(\n        succeeded=created_or_updated,\n        failed=failed,\n    )\n\n\n@router.delete(\n    CONNECTION_BY_KEY,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_DELETE])],\n    status_code=HTTP_204_NO_CONTENT,\n)\ndef delete_connection(\n    connection_key: FidesOpsKey, *, db: Session = Depends(deps.get_db)\n) -> None:\n    \"\"\"Removes the connection configuration with matching key.\"\"\"\n    connection_config = get_connection_config_or_error(db, connection_key)\n    connection_type = connection_config.connection_type\n    logger.info(\"Deleting connection config with key '%s'.\", connection_key)\n    connection_config.delete(db)\n\n    # Access Manual Webhooks are cascade deleted if their ConnectionConfig is deleted,\n    # so we queue any privacy requests that are no longer blocked by webhooks\n    if connection_type == ConnectionType.manual_webhook:\n        requeue_requires_input_requests(db)\n\n\ndef validate_secrets(\n    request_body: connection_secrets_schemas, connection_config: ConnectionConfig\n) -> ConnectionConfigSecretsSchema:\n    \"\"\"Validate incoming connection configuration secrets.\"\"\"\n\n    connection_type = connection_config.connection_type\n    saas_config = connection_config.get_saas_config()\n    if connection_type == ConnectionType.saas and saas_config is None:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=\"A SaaS config to validate the secrets is unavailable for this \"\n            f\"connection config, please add one via {SAAS_CONFIG}\",\n        )\n\n    try:\n        schema = get_connection_secrets_validator(connection_type.value, saas_config)  # type: ignore\n        logger.info(\n            \"Validating secrets on connection config with key '%s'\",\n            connection_config.key,\n        )\n        connection_secrets = schema.parse_obj(request_body)\n    except ValidationError as e:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=e.errors()\n        )\n\n    return connection_secrets\n\n\ndef connection_status(\n    connection_config: ConnectionConfig, msg: str, db: Session = Depends(deps.get_db)\n) -> TestStatusMessage:\n    \"\"\"Connect, verify with a trivial query or API request, and report the status.\"\"\"\n\n    connector = get_connector(connection_config)\n    try:\n        status: ConnectionTestStatus | None = connector.test_connection()\n\n    except (ConnectionException, ClientUnsuccessfulException) as exc:\n        logger.warning(\n            \"Connection test failed on %s: %s\",\n            connection_config.key,\n            Pii(str(exc)),\n        )\n        connection_config.update_test_status(\n            test_status=ConnectionTestStatus.failed, db=db\n        )\n        return TestStatusMessage(\n            msg=msg,\n            test_status=ConnectionTestStatus.failed,\n            failure_reason=str(exc),\n        )\n\n    logger.info(\"Connection test %s on %s\", status.value, connection_config.key)  # type: ignore\n    connection_config.update_test_status(test_status=status, db=db)  # type: ignore\n\n    return TestStatusMessage(\n        msg=msg,\n        test_status=status,\n    )\n\n\n@router.put(\n    CONNECTION_SECRETS,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_CREATE_OR_UPDATE])],\n    response_model=TestStatusMessage,\n)\nasync def put_connection_config_secrets(\n    connection_key: FidesOpsKey,\n    *,\n    db: Session = Depends(deps.get_db),\n    unvalidated_secrets: connection_secrets_schemas,\n    verify: Optional[bool] = True,\n) -> TestStatusMessage:\n    \"\"\"\n    Update secrets that will be used to connect to a specified connection_type.\n\n    The specific secrets will be connection-dependent. For example, the components needed to connect to a Postgres DB\n    will differ from Dynamo DB.\n    \"\"\"\n    connection_config = get_connection_config_or_error(db, connection_key)\n\n    connection_config.secrets = validate_secrets(\n        unvalidated_secrets, connection_config\n    ).dict()\n    # Save validated secrets, regardless of whether they've been verified.\n    logger.info(\"Updating connection config secrets for '%s'\", connection_key)\n    connection_config.save(db=db)\n\n    msg = f\"Secrets updated for ConnectionConfig with key: {connection_key}.\"\n    if verify:\n        return connection_status(connection_config, msg, db)\n\n    return TestStatusMessage(msg=msg, test_status=None)\n\n\n@router.get(\n    CONNECTION_TEST,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_READ])],\n    response_model=TestStatusMessage,\n)\nasync def test_connection_config_secrets(\n    connection_key: FidesOpsKey,\n    *,\n    db: Session = Depends(deps.get_db),\n) -> TestStatusMessage:\n    \"\"\"\n    Endpoint to test a connection at any time using the saved configuration secrets.\n    \"\"\"\n    connection_config = get_connection_config_or_error(db, connection_key)\n    msg = f\"Test completed for ConnectionConfig with key: {connection_key}.\"\n    return connection_status(connection_config, msg, db)\n\n\ndef requeue_requires_input_requests(db: Session) -> None:\n    \"\"\"\n    Queue privacy requests with request status \"requires_input\" if they are no longer blocked by\n    access manual webhooks.\n\n    For use when all access manual webhooks have been either disabled or deleted, leaving privacy requests\n    lingering in a \"requires_input\" state.\n    \"\"\"\n    if not AccessManualWebhook.get_enabled(db):\n        for pr in PrivacyRequest.filter(\n            db=db,\n            conditions=(PrivacyRequest.status == PrivacyRequestStatus.requires_input),\n        ):\n            logger.info(\n                \"Queuing privacy request '%s with '%s' status now that manual inputs are no longer required.\",\n                pr.id,\n                pr.status.value,\n            )\n            pr.status = PrivacyRequestStatus.in_processing\n            pr.save(db=db)\n            queue_privacy_request(\n                privacy_request_id=pr.id,\n            )\n"}
{"type": "source_file", "path": "src/fidesops/__init__.py", "content": "from ._version import get_versions  # type: ignore\n\n__version__ = get_versions()[\"version\"]\ndel get_versions\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/dataset_endpoints.py", "content": "import logging\nfrom typing import List\n\nimport yaml\nfrom fastapi import Depends, HTTPException, Request\nfrom fastapi.params import Security\nfrom fastapi_pagination import Page, Params\nfrom fastapi_pagination.bases import AbstractPage\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom pydantic import conlist\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.orm import Session\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_204_NO_CONTENT,\n    HTTP_400_BAD_REQUEST,\n    HTTP_404_NOT_FOUND,\n    HTTP_415_UNSUPPORTED_MEDIA_TYPE,\n)\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1.scope_registry import (\n    DATASET_CREATE_OR_UPDATE,\n    DATASET_DELETE,\n    DATASET_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    DATASET_BY_KEY,\n    DATASET_VALIDATE,\n    DATASETS,\n    V1_URL_PREFIX,\n    YAML_DATASETS,\n)\nfrom fidesops.ops.common_exceptions import (\n    SaaSConfigNotFoundException,\n    TraversalError,\n    ValidationError,\n)\nfrom fidesops.ops.graph.traversal import DatasetGraph, Traversal\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig, ConnectionType\nfrom fidesops.ops.models.datasetconfig import (\n    DatasetConfig,\n    convert_dataset_to_graph,\n    to_graph_field,\n)\nfrom fidesops.ops.schemas.api import BulkUpdateFailed\nfrom fidesops.ops.schemas.dataset import (\n    BulkPutDataset,\n    DatasetTraversalDetails,\n    FidesopsDataset,\n    ValidateDatasetResponse,\n)\nfrom fidesops.ops.schemas.shared_schemas import FidesOpsKey\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\nfrom fidesops.ops.util.saas_util import merge_datasets\n\nX_YAML = \"application/x-yaml\"\n\nlogger = logging.getLogger(__name__)\nrouter = APIRouter(tags=[\"Datasets\"], prefix=V1_URL_PREFIX)\n\n\n# Helper method to inject the parent ConnectionConfig into these child routes\ndef _get_connection_config(\n    connection_key: FidesOpsKey, db: Session = Depends(deps.get_db)\n) -> ConnectionConfig:\n    logger.info(\"Finding connection config with key '%s'\", connection_key)\n    connection_config = ConnectionConfig.get_by(db, field=\"key\", value=connection_key)\n    if not connection_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No connection config with key '{connection_key}'\",\n        )\n    return connection_config\n\n\n@router.put(\n    DATASET_VALIDATE,\n    dependencies=[Security(verify_oauth_client, scopes=[DATASET_READ])],\n    status_code=HTTP_200_OK,\n    response_model=ValidateDatasetResponse,\n)\ndef validate_dataset(\n    dataset: FidesopsDataset,\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n) -> ValidateDatasetResponse:\n    \"\"\"\n    Run validations against a dataset without attempting to save it to the database.\n\n    Checks that:\n    - all required fields are present, all field values are valid types\n    - all DataCategory values reference known keys\n    - etc.\n\n    After validating, also tests to see if the dataset is traversable. Note that\n    it's possible for a dataset to be valid but not traversable; this happens\n    when a dataset is dependent on references to other datasets.\n\n    Returns a 200 OK for all valid datasets, and a traversal_details object with\n    information about the traversal (or traversal errors).\n    \"\"\"\n\n    try:\n        # Attempt to generate a traversal for this dataset by providing an empty\n        # dictionary of all unique identity keys\n        graph = convert_dataset_to_graph(dataset, connection_config.key)  # type: ignore\n\n        # Datasets for SaaS connections need to be merged with a SaaS config to\n        # be able to generate a valid traversal\n        if connection_config.connection_type == ConnectionType.saas:\n            _validate_saas_dataset(connection_config, dataset)\n            graph = merge_datasets(\n                graph, connection_config.get_saas_config().get_graph()  # type: ignore\n            )\n        complete_graph = DatasetGraph(graph)\n        unique_identities = set(complete_graph.identity_keys.values())\n        Traversal(complete_graph, {k: None for k in unique_identities})\n    except (TraversalError, ValidationError) as err:\n        logger.warning(\n            \"Traversal validation failed for dataset '%s': %s\", dataset.fides_key, err\n        )\n        return ValidateDatasetResponse(\n            dataset=dataset,\n            traversal_details=DatasetTraversalDetails(\n                is_traversable=False,\n                msg=str(err),\n            ),\n        )\n\n    logger.info(\"Validation successful for dataset '%s'!\", dataset.fides_key)\n    return ValidateDatasetResponse(\n        dataset=dataset,\n        traversal_details=DatasetTraversalDetails(\n            is_traversable=True,\n            msg=None,\n        ),\n    )\n\n\n@router.patch(\n    DATASETS,\n    dependencies=[Security(verify_oauth_client, scopes=[DATASET_CREATE_OR_UPDATE])],\n    status_code=HTTP_200_OK,\n    response_model=BulkPutDataset,\n)\ndef patch_datasets(\n    datasets: conlist(FidesopsDataset, max_items=50),  # type: ignore\n    db: Session = Depends(deps.get_db),\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n) -> BulkPutDataset:\n    \"\"\"\n    Given a list of dataset elements, create or update corresponding Dataset objects\n    or report failure\n\n    Use for bulk creating and/or updating datasets.\n\n    If the fides_key for a given dataset exists, it will be treated as an update.\n    Otherwise, a new dataset will be created.\n    \"\"\"\n\n    created_or_updated: List[FidesopsDataset] = []\n    failed: List[BulkUpdateFailed] = []\n    logger.info(\"Starting bulk upsert for %s datasets\", len(datasets))\n\n    # warn if there are duplicate fides_keys within the datasets\n    # valid datasets with the same fides_key will override each other\n    key_list = [dataset.fides_key for dataset in datasets]\n    if len(key_list) != len(set(key_list)):\n        logger.warning(\n            \"Datasets with duplicate fides_keys detected, may result in unintended behavior.\"\n        )\n\n    for dataset in datasets:\n        data = {\n            \"connection_config_id\": connection_config.id,\n            \"fides_key\": dataset.fides_key,\n            \"dataset\": dataset.dict(),\n        }\n        create_or_update_dataset(\n            connection_config, created_or_updated, data, dataset, db, failed\n        )\n    return BulkPutDataset(\n        succeeded=created_or_updated,\n        failed=failed,\n    )\n\n\n@router.patch(\n    YAML_DATASETS,\n    dependencies=[Security(verify_oauth_client, scopes=[DATASET_CREATE_OR_UPDATE])],\n    status_code=200,\n    response_model=BulkPutDataset,\n    include_in_schema=False  # Not including this path in the schema.\n    # Since this yaml function needs to access the request, the open api spec will not be generated correctly.\n    # To include this path, extend open api: https://fastapi.tiangolo.com/advanced/extending-openapi/\n)\nasync def patch_yaml_datasets(\n    request: Request,\n    db: Session = Depends(deps.get_db),\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n) -> BulkPutDataset:\n    if request.headers.get(\"content-type\") != X_YAML:\n        raise HTTPException(\n            status_code=HTTP_415_UNSUPPORTED_MEDIA_TYPE,\n            detail=\"Supported type: \" + X_YAML,\n        )\n    body = await request.body()\n    try:\n        yaml_request_body: dict = yaml.safe_load(body)\n    except yaml.MarkedYAMLError as e:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST, detail=\"Error in YAML: \" + str(e)\n        )\n    datasets = (\n        yaml_request_body.get(\"dataset\") if isinstance(yaml_request_body, dict) else []\n    )\n    created_or_updated: List[FidesopsDataset] = []\n    failed: List[BulkUpdateFailed] = []\n    if isinstance(datasets, list):\n        for dataset in datasets:  # type: ignore\n            data: dict = {\n                \"connection_config_id\": connection_config.id,\n                \"fides_key\": dataset[\"fides_key\"],\n                \"dataset\": dataset,\n            }\n            create_or_update_dataset(\n                connection_config,\n                created_or_updated,\n                data,\n                yaml_request_body,\n                db,\n                failed,\n            )\n    return BulkPutDataset(\n        succeeded=created_or_updated,\n        failed=failed,\n    )\n\n\ndef create_or_update_dataset(\n    connection_config: ConnectionConfig,\n    created_or_updated: List[FidesopsDataset],\n    data: dict,\n    dataset: dict,\n    db: Session,\n    failed: List[BulkUpdateFailed],\n) -> None:\n    try:\n        if connection_config.connection_type == ConnectionType.saas:\n            _validate_saas_dataset(connection_config, dataset)  # type: ignore\n        # Try to find an existing DatasetConfig matching the given connection & key\n        dataset_config = DatasetConfig.create_or_update(db, data=data)\n        created_or_updated.append(dataset_config.dataset)\n    except (\n        SaaSConfigNotFoundException,\n        ValidationError,\n    ) as exception:\n        logger.warning(exception.message)\n        failed.append(\n            BulkUpdateFailed(\n                message=exception.message,\n                data=data,\n            )\n        )\n    except IntegrityError:\n        message = \"Dataset with key '%s' already exists.\" % data[\"fides_key\"]\n        logger.warning(message)\n        failed.append(\n            BulkUpdateFailed(\n                message=message,\n                data=data,\n            )\n        )\n    except Exception:\n        logger.warning(\"Create/update failed for dataset '%s'.\", data[\"fides_key\"])\n        failed.append(\n            BulkUpdateFailed(\n                message=\"Dataset create/update failed.\",\n                data=data,\n            )\n        )\n\n\ndef _validate_saas_dataset(\n    connection_config: ConnectionConfig, dataset: FidesopsDataset\n) -> None:\n    if connection_config.saas_config is None:\n        raise SaaSConfigNotFoundException(\n            f\"Connection config '{connection_config.key}' must have a \"\n            \"SaaS config before validating or adding a dataset\"\n        )\n\n    fides_key = connection_config.saas_config[\"fides_key\"]\n    if fides_key != dataset.fides_key:\n        raise ValidationError(\n            f\"The fides_key '{dataset.fides_key}' of the dataset \"\n            f\"does not match the fides_key '{fides_key}' \"\n            \"of the connection config\"\n        )\n    for collection in dataset.collections:\n        for field in collection.fields:\n            graph_field = to_graph_field(field)\n            if graph_field.references or graph_field.identity:\n                raise ValidationError(\n                    \"A dataset for a ConnectionConfig type of 'saas' is not \"\n                    \"allowed to have references or identities. Please add \"\n                    \"them to the SaaS config.\"\n                )\n\n\n@router.get(\n    DATASETS,\n    dependencies=[Security(verify_oauth_client, scopes=[DATASET_READ])],\n    response_model=Page[FidesopsDataset],\n)\ndef get_datasets(\n    db: Session = Depends(deps.get_db),\n    params: Params = Depends(),\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n) -> AbstractPage[FidesopsDataset]:\n    \"\"\"Returns all datasets in the database.\"\"\"\n\n    logger.info(\n        \"Finding all datasets for connection '%s' with pagination params %s\",\n        connection_config.key,\n        params,\n    )\n    dataset_configs = DatasetConfig.filter(\n        db=db, conditions=(DatasetConfig.connection_config_id == connection_config.id)\n    ).order_by(DatasetConfig.created_at.desc())\n\n    # Generate the paginated results, but don't return them as-is. Instead,\n    # modify the items array to be just the FidesopsDataset instead of the full\n    # DatasetConfig. This has to be done *afterwards* to ensure that the\n    # paginated query is handled by paginate()\n    paginated_results = paginate(dataset_configs, params=params)\n    paginated_results.items = [  # type: ignore\n        dataset_config.dataset for dataset_config in paginated_results.items  # type: ignore\n    ]\n    return paginated_results\n\n\n@router.get(\n    DATASET_BY_KEY,\n    dependencies=[Security(verify_oauth_client, scopes=[DATASET_READ])],\n    response_model=FidesopsDataset,\n)\ndef get_dataset(\n    fides_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n) -> FidesopsDataset:\n    \"\"\"Returns a single dataset based on the given key.\"\"\"\n\n    logger.info(\n        \"Finding dataset '%s' for connection '%s'\", fides_key, connection_config.key\n    )\n    dataset_config = DatasetConfig.filter(\n        db=db,\n        conditions=(\n            (DatasetConfig.connection_config_id == connection_config.id)\n            & (DatasetConfig.fides_key == fides_key)\n        ),\n    ).first()\n    if not dataset_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No dataset with fides_key '{fides_key}' and connection key {connection_config.key}'\",\n        )\n    return dataset_config.dataset\n\n\n@router.delete(\n    DATASET_BY_KEY,\n    dependencies=[Security(verify_oauth_client, scopes=[DATASET_DELETE])],\n    status_code=HTTP_204_NO_CONTENT,\n)\ndef delete_dataset(\n    fides_key: FidesOpsKey,\n    *,\n    db: Session = Depends(deps.get_db),\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n) -> None:\n    \"\"\"Removes the dataset based on the given key.\"\"\"\n\n    logger.info(\n        \"Finding dataset '%s' for connection '%s'\", fides_key, connection_config.key\n    )\n    dataset_config = DatasetConfig.filter(\n        db=db,\n        conditions=(\n            (DatasetConfig.connection_config_id == connection_config.id)\n            & (DatasetConfig.fides_key == fides_key)\n        ),\n    ).first()\n    if not dataset_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No dataset with fides_key '{fides_key}' and connection_key '{connection_config.key}'\",\n        )\n\n    logger.info(\n        \"Deleting dataset '%s' for connection '%s'\", fides_key, connection_config.key\n    )\n    dataset_config.delete(db)\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/email_endpoints.py", "content": "import logging\nfrom typing import Optional\n\nfrom fastapi import Depends, Security\nfrom fastapi_pagination import Page, Params\nfrom fastapi_pagination.bases import AbstractPage\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom sqlalchemy.orm import Session\nfrom starlette.exceptions import HTTPException\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_204_NO_CONTENT,\n    HTTP_400_BAD_REQUEST,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n    HTTP_500_INTERNAL_SERVER_ERROR,\n)\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1.scope_registry import (\n    EMAIL_CREATE_OR_UPDATE,\n    EMAIL_DELETE,\n    EMAIL_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    EMAIL_BY_KEY,\n    EMAIL_CONFIG,\n    EMAIL_SECRETS,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.common_exceptions import (\n    EmailConfigAlreadyExistsException,\n    EmailConfigNotFoundException,\n)\nfrom fidesops.ops.models.email import EmailConfig, get_schema_for_secrets\nfrom fidesops.ops.schemas.email.email import (\n    EmailConfigRequest,\n    EmailConfigResponse,\n    TestEmailStatusMessage,\n)\nfrom fidesops.ops.schemas.email.email_secrets_docs_only import possible_email_secrets\nfrom fidesops.ops.schemas.shared_schemas import FidesOpsKey\nfrom fidesops.ops.service.email.email_crud_service import (\n    create_email_config,\n    delete_email_config,\n    get_email_config_by_key,\n    update_email_config,\n)\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.logger import Pii\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"email\"], prefix=V1_URL_PREFIX)\nlogger = logging.getLogger(__name__)\n\n\n@router.post(\n    EMAIL_CONFIG,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[EMAIL_CREATE_OR_UPDATE])],\n    response_model=EmailConfigResponse,\n)\ndef post_config(\n    *,\n    db: Session = Depends(deps.get_db),\n    email_config: EmailConfigRequest,\n) -> EmailConfigResponse:\n    \"\"\"\n    Given an email config, create corresponding EmailConfig object, provided no config already exists\n    \"\"\"\n\n    try:\n        return create_email_config(db=db, config=email_config)\n    except EmailConfigAlreadyExistsException as e:\n        logger.warning(e.message)\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=e.message)\n\n    except Exception as exc:\n        logger.warning(\n            \"Create failed for email config %s: %s\", email_config.key, Pii(str(exc))\n        )\n        raise HTTPException(\n            status_code=HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Config with key {email_config.key} failed to be added\",\n        )\n\n\n@router.patch(\n    EMAIL_BY_KEY,\n    dependencies=[Security(verify_oauth_client, scopes=[EMAIL_CREATE_OR_UPDATE])],\n    response_model=EmailConfigResponse,\n)\ndef patch_config_by_key(\n    config_key: FidesOpsKey,\n    *,\n    db: Session = Depends(deps.get_db),\n    email_config: EmailConfigRequest,\n) -> Optional[EmailConfigResponse]:\n    \"\"\"\n    Updates config for email by key, provided config with key can be found.\n    \"\"\"\n    try:\n        return update_email_config(db=db, key=config_key, config=email_config)\n    except EmailConfigNotFoundException:\n        logger.warning(\"No email config found with key %s\", config_key)\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No email config found with key {config_key}\",\n        )\n\n    except Exception as exc:\n        logger.warning(\n            \"Patch failed for email config %s: %s\", email_config.key, Pii(str(exc))\n        )\n        raise HTTPException(\n            status_code=HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Config with key {email_config.key} failed to be added\",\n        )\n\n\n@router.put(\n    EMAIL_SECRETS,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[EMAIL_CREATE_OR_UPDATE])],\n    response_model=TestEmailStatusMessage,\n)\ndef put_config_secrets(\n    config_key: FidesOpsKey,\n    *,\n    db: Session = Depends(deps.get_db),\n    unvalidated_email_secrets: possible_email_secrets,\n) -> TestEmailStatusMessage:\n    \"\"\"\n    Add or update secrets for email config.\n    \"\"\"\n    logger.info(\"Finding email config with key '%s'\", config_key)\n    email_config = EmailConfig.get_by(db=db, field=\"key\", value=config_key)\n    if not email_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No email configuration with key {config_key}.\",\n        )\n\n    try:\n        secrets_schema = get_schema_for_secrets(\n            service_type=email_config.service_type,\n            secrets=unvalidated_email_secrets,\n        )\n    except KeyError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=exc.args[0],\n        )\n    except ValueError as exc:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=exc.args[0],\n        )\n\n    logger.info(\"Updating email config secrets for config with key '%s'\", config_key)\n    try:\n        email_config.set_secrets(db=db, email_secrets=secrets_schema.dict())\n    except ValueError as exc:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=exc.args[0],\n        )\n\n    msg = f\"Secrets updated for EmailConfig with key: {config_key}.\"\n    # todo- implement test status for email service\n    return TestEmailStatusMessage(msg=msg, test_status=None)\n\n\n@router.get(\n    EMAIL_CONFIG,\n    dependencies=[Security(verify_oauth_client, scopes=[EMAIL_READ])],\n    response_model=Page[EmailConfigResponse],\n)\ndef get_configs(\n    *, db: Session = Depends(deps.get_db), params: Params = Depends()\n) -> AbstractPage[EmailConfig]:\n    \"\"\"\n    Retrieves configs for email.\n    \"\"\"\n    logger.info(\"Finding all email configurations with pagination params %s\", params)\n    return paginate(\n        EmailConfig.query(db=db).order_by(EmailConfig.created_at.desc()), params=params\n    )\n\n\n@router.get(\n    EMAIL_BY_KEY,\n    dependencies=[Security(verify_oauth_client, scopes=[EMAIL_READ])],\n    response_model=EmailConfigResponse,\n)\ndef get_config_by_key(\n    config_key: FidesOpsKey, *, db: Session = Depends(deps.get_db)\n) -> EmailConfigResponse:\n    \"\"\"\n    Retrieves configs for email by key.\n    \"\"\"\n    logger.info(\"Finding email config with key '%s'\", config_key)\n\n    try:\n        return get_email_config_by_key(db=db, key=config_key)\n    except EmailConfigNotFoundException as e:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=e.message,\n        )\n\n\n@router.delete(\n    EMAIL_BY_KEY,\n    status_code=HTTP_204_NO_CONTENT,\n    dependencies=[Security(verify_oauth_client, scopes=[EMAIL_DELETE])],\n)\ndef delete_config_by_key(\n    config_key: FidesOpsKey, *, db: Session = Depends(deps.get_db)\n) -> None:\n    \"\"\"\n    Deletes email configs by key.\n    \"\"\"\n    try:\n        delete_email_config(db=db, key=config_key)\n    except EmailConfigNotFoundException as e:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=e.message,\n        )\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/privacy_request_endpoints.py", "content": "# pylint: disable=too-many-branches,too-many-locals,too-many-lines, too-many-statements\n\nimport csv\nimport io\nimport logging\nfrom collections import defaultdict\nfrom datetime import datetime\nfrom typing import Any, Callable, DefaultDict, Dict, List, Optional, Set, Union\n\nimport sqlalchemy\nfrom fastapi import Body, Depends, HTTPException, Security\nfrom fastapi.params import Query as FastAPIQuery\nfrom fastapi_pagination import Page, Params\nfrom fastapi_pagination.bases import AbstractPage\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom fideslib.models.audit_log import AuditLog, AuditLogAction\nfrom fideslib.models.client import ClientDetail\nfrom pydantic import ValidationError as PydanticValidationError\nfrom pydantic import conlist\nfrom sqlalchemy import cast, column, null\nfrom sqlalchemy.orm import Query, Session\nfrom sqlalchemy.sql.expression import nullslast\nfrom starlette.responses import StreamingResponse\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_400_BAD_REQUEST,\n    HTTP_403_FORBIDDEN,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n    HTTP_424_FAILED_DEPENDENCY,\n)\n\nfrom fidesops.ops import common_exceptions\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1 import scope_registry as scopes\nfrom fidesops.ops.api.v1 import urn_registry as urls\nfrom fidesops.ops.api.v1.endpoints.dataset_endpoints import _get_connection_config\nfrom fidesops.ops.api.v1.endpoints.manual_webhook_endpoints import (\n    get_access_manual_webhook_or_404,\n)\nfrom fidesops.ops.api.v1.scope_registry import (\n    PRIVACY_REQUEST_CALLBACK_RESUME,\n    PRIVACY_REQUEST_READ,\n    PRIVACY_REQUEST_REVIEW,\n    PRIVACY_REQUEST_UPLOAD_DATA,\n    PRIVACY_REQUEST_VIEW_DATA,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT,\n    PRIVACY_REQUEST_APPROVE,\n    PRIVACY_REQUEST_DENY,\n    PRIVACY_REQUEST_MANUAL_ERASURE,\n    PRIVACY_REQUEST_MANUAL_INPUT,\n    PRIVACY_REQUEST_RESUME,\n    PRIVACY_REQUEST_RESUME_FROM_REQUIRES_INPUT,\n    PRIVACY_REQUEST_RETRY,\n    PRIVACY_REQUEST_VERIFY_IDENTITY,\n    REQUEST_PREVIEW,\n)\nfrom fidesops.ops.common_exceptions import (\n    EmailDispatchException,\n    FunctionalityNotConfigured,\n    IdentityNotFoundException,\n    IdentityVerificationException,\n    ManualWebhookFieldsUnset,\n    NoCachedManualWebhookEntry,\n    PolicyNotFoundException,\n    TraversalError,\n    ValidationError,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.graph.config import CollectionAddress\nfrom fidesops.ops.graph.graph import DatasetGraph, Node\nfrom fidesops.ops.graph.traversal import Traversal\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.models.manual_webhook import AccessManualWebhook\nfrom fidesops.ops.models.policy import ActionType, CurrentStep, Policy, PolicyPreWebhook\nfrom fidesops.ops.models.privacy_request import (\n    ExecutionLog,\n    PrivacyRequest,\n    PrivacyRequestStatus,\n    ProvidedIdentity,\n    ProvidedIdentityType,\n)\nfrom fidesops.ops.schemas.dataset import (\n    CollectionAddressResponse,\n    DryRunDatasetResponse,\n)\nfrom fidesops.ops.schemas.email.email import (\n    EmailActionType,\n    FidesopsEmail,\n    RequestReceiptBodyParams,\n    RequestReviewDenyBodyParams,\n)\nfrom fidesops.ops.schemas.external_https import PrivacyRequestResumeFormat\nfrom fidesops.ops.schemas.privacy_request import (\n    BulkPostPrivacyRequests,\n    BulkReviewResponse,\n    CheckpointActionRequired,\n    DenyPrivacyRequests,\n    ExecutionLogDetailResponse,\n    ManualWebhookData,\n    PrivacyRequestCreate,\n    PrivacyRequestResponse,\n    PrivacyRequestVerboseResponse,\n    ReviewPrivacyRequestIds,\n    RowCountRequest,\n    VerificationCode,\n)\nfrom fidesops.ops.service._verification import send_verification_code_to_user\nfrom fidesops.ops.service.email.email_dispatch_service import dispatch_email_task\nfrom fidesops.ops.service.privacy_request.request_runner_service import (\n    queue_privacy_request,\n)\nfrom fidesops.ops.service.privacy_request.request_service import (\n    build_required_privacy_request_kwargs,\n    cache_data,\n)\nfrom fidesops.ops.task.graph_task import EMPTY_REQUEST, collect_queries\nfrom fidesops.ops.task.task_resources import TaskResources\nfrom fidesops.ops.tasks import EMAIL_QUEUE_NAME\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.cache import FidesopsRedis\nfrom fidesops.ops.util.collection_util import Row\nfrom fidesops.ops.util.enums import ColumnSort\nfrom fidesops.ops.util.logger import Pii\nfrom fidesops.ops.util.oauth_util import verify_callback_oauth, verify_oauth_client\n\nlogger = logging.getLogger(__name__)\nrouter = APIRouter(tags=[\"Privacy Requests\"], prefix=urls.V1_URL_PREFIX)\nEMBEDDED_EXECUTION_LOG_LIMIT = 50\n\n\ndef get_privacy_request_or_error(\n    db: Session, privacy_request_id: str\n) -> PrivacyRequest:\n    \"\"\"Load the privacy request or throw a 404\"\"\"\n    logger.info(\"Finding privacy request with id '%s'\", privacy_request_id)\n\n    privacy_request = PrivacyRequest.get(db, object_id=privacy_request_id)\n\n    if not privacy_request:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No privacy request found with id '{privacy_request_id}'.\",\n        )\n\n    return privacy_request\n\n\n@router.post(\n    urls.PRIVACY_REQUESTS,\n    status_code=HTTP_200_OK,\n    response_model=BulkPostPrivacyRequests,\n)\nasync def create_privacy_request(\n    *,\n    db: Session = Depends(deps.get_db),\n    data: conlist(PrivacyRequestCreate, max_items=50) = Body(...),  # type: ignore\n) -> BulkPostPrivacyRequests:\n    \"\"\"\n    Given a list of privacy request data elements, create corresponding PrivacyRequest objects\n    or report failure and execute them within the Fidesops system.\n\n    You cannot update privacy requests after they've been created.\n    \"\"\"\n    if not config.redis.enabled:\n        raise FunctionalityNotConfigured(\n            \"Application redis cache required, but it is currently disabled! Please update your application configuration to enable integration with a redis cache.\"\n        )\n\n    created = []\n    failed = []\n    # Optional fields to validate here are those that are both nullable in the DB, and exist\n    # on the Pydantic schema\n\n    logger.info(\"Starting creation for %s privacy requests\", len(data))\n\n    optional_fields = [\"external_id\", \"started_processing_at\", \"finished_processing_at\"]\n    for privacy_request_data in data:\n        if not any(privacy_request_data.identity.dict().values()):\n            logger.warning(\n                \"Create failed for privacy request with no identity provided\"\n            )\n            failure = {\n                \"message\": \"You must provide at least one identity to process\",\n                \"data\": privacy_request_data,\n            }\n            failed.append(failure)\n            continue\n\n        logger.info(\"Finding policy with key '%s'\", privacy_request_data.policy_key)\n        policy: Optional[Policy] = Policy.get_by(\n            db=db,\n            field=\"key\",\n            value=privacy_request_data.policy_key,\n        )\n        if policy is None:\n            logger.warning(\n                \"Create failed for privacy request with invalid policy key %s'\",\n                privacy_request_data.policy_key,\n            )\n\n            failure = {\n                \"message\": f\"Policy with key {privacy_request_data.policy_key} does not exist\",\n                \"data\": privacy_request_data,\n            }\n            failed.append(failure)\n            continue\n\n        kwargs = build_required_privacy_request_kwargs(\n            privacy_request_data.requested_at, policy.id\n        )\n        for field in optional_fields:\n            attr = getattr(privacy_request_data, field)\n            if attr is not None:\n                kwargs[field] = attr\n\n        try:\n            privacy_request: PrivacyRequest = PrivacyRequest.create(db=db, data=kwargs)\n            privacy_request.persist_identity(\n                db=db, identity=privacy_request_data.identity\n            )\n\n            cache_data(\n                privacy_request,\n                policy,\n                privacy_request_data.identity,\n                privacy_request_data.encryption_key,\n                None,\n            )\n\n            if config.execution.subject_identity_verification_required:\n                send_verification_code_to_user(\n                    db, privacy_request, privacy_request_data.identity.email\n                )\n                created.append(privacy_request)\n                continue  # Skip further processing for this privacy request\n            if config.notifications.send_request_receipt_notification:\n                _send_privacy_request_receipt_email_to_user(\n                    policy, privacy_request_data.identity.email\n                )\n            if not config.execution.require_manual_request_approval:\n                AuditLog.create(\n                    db=db,\n                    data={\n                        \"user_id\": \"system\",\n                        \"privacy_request_id\": privacy_request.id,\n                        \"action\": AuditLogAction.approved,\n                        \"message\": \"\",\n                    },\n                )\n                queue_privacy_request(privacy_request.id)\n        except EmailDispatchException as exc:\n            kwargs[\"privacy_request_id\"] = privacy_request.id\n            logger.error(\"EmailDispatchException: %s\", exc)\n            failure = {\n                \"message\": \"Verification email could not be sent.\",\n                \"data\": kwargs,\n            }\n            failed.append(failure)\n        except common_exceptions.RedisConnectionError as exc:\n            logger.error(\"RedisConnectionError: %s\", Pii(str(exc)))\n            # Thrown when cache.ping() fails on cache connection retrieval\n            raise HTTPException(\n                status_code=HTTP_424_FAILED_DEPENDENCY,\n                detail=exc.args[0],\n            )\n        except Exception as exc:\n            logger.error(\"Exception: %s\", Pii(str(exc)))\n            failure = {\n                \"message\": \"This record could not be added\",\n                \"data\": kwargs,\n            }\n            failed.append(failure)\n        else:\n            created.append(privacy_request)\n\n    return BulkPostPrivacyRequests(\n        succeeded=created,\n        failed=failed,\n    )\n\n\ndef _send_privacy_request_receipt_email_to_user(\n    policy: Optional[Policy], email: Optional[str]\n) -> None:\n    \"\"\"Helper function to send request receipt email to the user\"\"\"\n    if not email:\n        logger.error(\n            IdentityNotFoundException(\n                \"Identity email was not found, so request receipt email could not be sent.\"\n            )\n        )\n        return\n    if not policy:\n        logger.error(\n            PolicyNotFoundException(\n                \"Policy was not found, so request receipt email could not be sent.\"\n            )\n        )\n        return\n    request_types: Set[str] = set()\n    for action_type in ActionType:\n        if policy.get_rules_for_action(action_type=ActionType(action_type)):\n            request_types.add(action_type)\n    dispatch_email_task.apply_async(\n        queue=EMAIL_QUEUE_NAME,\n        kwargs={\n            \"email_meta\": FidesopsEmail(\n                action_type=EmailActionType.PRIVACY_REQUEST_RECEIPT,\n                body_params=RequestReceiptBodyParams(request_types=request_types),\n            ).dict(),\n            \"to_email\": email,\n        },\n    )\n\n\ndef privacy_request_csv_download(\n    db: Session, privacy_request_query: Query\n) -> StreamingResponse:\n    \"\"\"Download privacy requests as CSV for Admin UI\"\"\"\n    f = io.StringIO()\n    csv_file = csv.writer(f)\n\n    csv_file.writerow(\n        [\n            \"Time received\",\n            \"Subject identity\",\n            \"Policy key\",\n            \"Request status\",\n            \"Reviewer\",\n            \"Time approved/denied\",\n            \"Denial reason\",\n        ]\n    )\n    privacy_request_ids: List[str] = [r.id for r in privacy_request_query]\n    denial_audit_log_query: Query = db.query(AuditLog).filter(\n        AuditLog.action == AuditLogAction.denied,\n        AuditLog.privacy_request_id.in_(privacy_request_ids),\n    )\n    denial_audit_logs: Dict[str, str] = {\n        r.privacy_request_id: r.message for r in denial_audit_log_query\n    }\n\n    for pr in privacy_request_query:\n        denial_reason = (\n            denial_audit_logs[pr.id]\n            if pr.status == PrivacyRequestStatus.denied and pr.id in denial_audit_logs\n            else None\n        )\n        csv_file.writerow(\n            [\n                pr.created_at,\n                pr.get_persisted_identity().dict(),\n                pr.policy.key if pr.policy else None,\n                pr.status.value if pr.status else None,\n                pr.reviewed_by,\n                pr.reviewed_at,\n                denial_reason,\n            ]\n        )\n    f.seek(0)\n    response = StreamingResponse(f, media_type=\"text/csv\")\n    response.headers[\n        \"Content-Disposition\"\n    ] = f\"attachment; filename=privacy_requests_download_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n    return response\n\n\ndef execution_and_audit_logs_by_dataset_name(\n    self: PrivacyRequest,\n) -> DefaultDict[str, List[\"ExecutionLog\"]]:\n    \"\"\"\n    Returns a combined mapping of execution and audit logs for the given privacy request.\n\n    Audit Logs are for the entire privacy request as a whole, while execution logs are created for specific collections.\n    Logs here are grouped by dataset, but if it is an audit log, it is just given a fake dataset name, here \"Request + status\"\n    ExecutionLogs for each dataset are truncated.\n\n    Added as a conditional property to the PrivacyRequest class at runtime to\n    show optionally embedded execution and audit logs.\n\n    An example response might include your execution logs from your mongo db in one group, and execution logs from\n    your postgres db in a different group, plus audit logs for when the request was approved and denied.\n    \"\"\"\n    db: Session = Session.object_session(self)\n    all_logs: DefaultDict[str, List[Union[\"AuditLog\", \"ExecutionLog\"]]] = defaultdict(\n        list\n    )\n\n    execution_log_query: Query = db.query(\n        ExecutionLog.id,\n        ExecutionLog.created_at,\n        ExecutionLog.updated_at,\n        ExecutionLog.message,\n        cast(ExecutionLog.status, sqlalchemy.String).label(\"status\"),\n        ExecutionLog.privacy_request_id,\n        ExecutionLog.dataset_name,\n        ExecutionLog.collection_name,\n        ExecutionLog.fields_affected,\n        ExecutionLog.action_type,\n        null().label(\"user_id\"),\n    ).filter(ExecutionLog.privacy_request_id == self.id)\n\n    audit_log_query: Query = db.query(\n        AuditLog.id,\n        AuditLog.created_at,\n        AuditLog.updated_at,\n        AuditLog.message,\n        cast(AuditLog.action.label(\"status\"), sqlalchemy.String).label(\"status\"),\n        AuditLog.privacy_request_id,\n        null().label(\"dataset_name\"),\n        null().label(\"collection_name\"),\n        null().label(\"fields_affected\"),\n        null().label(\"action_type\"),\n        AuditLog.user_id,\n    ).filter(AuditLog.privacy_request_id == self.id)\n\n    combined: Query = execution_log_query.union_all(audit_log_query)\n\n    for log in combined.order_by(ExecutionLog.updated_at.asc()):\n        dataset_name: str = log.dataset_name or f\"Request {log.status}\"\n\n        if len(all_logs[dataset_name]) > EMBEDDED_EXECUTION_LOG_LIMIT - 1:\n            continue\n        all_logs[dataset_name].append(log)\n    return all_logs\n\n\ndef _filter_privacy_request_queryset(\n    db: Session,\n    query: Query,\n    request_id: Optional[str] = None,\n    identity: Optional[str] = None,\n    status: Optional[List[PrivacyRequestStatus]] = None,\n    created_lt: Optional[datetime] = None,\n    created_gt: Optional[datetime] = None,\n    started_lt: Optional[datetime] = None,\n    started_gt: Optional[datetime] = None,\n    completed_lt: Optional[datetime] = None,\n    completed_gt: Optional[datetime] = None,\n    errored_lt: Optional[datetime] = None,\n    errored_gt: Optional[datetime] = None,\n    external_id: Optional[str] = None,\n) -> Query:\n    \"\"\"\n    Utility method to apply filters to our privacy request query.\n\n    Status supports \"or\" filtering:\n    ?status=approved&status=pending will be translated into an \"or\" query.\n    \"\"\"\n    if any([completed_lt, completed_gt]) and any([errored_lt, errored_gt]):\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=\"Cannot specify both succeeded and failed query params.\",\n        )\n\n    for end, start, field_name in [\n        [created_lt, created_gt, \"created\"],\n        [completed_lt, completed_gt, \"completed\"],\n        [errored_lt, errored_gt, \"errored\"],\n        [started_lt, started_gt, \"started\"],\n    ]:\n        if end is None or start is None:\n            continue\n\n        if not (isinstance(end, datetime) and isinstance(start, datetime)):\n            continue\n\n        if end < start:\n            # With date fields, if the start date is after the end date, return a 400\n            # because no records will lie within this range.\n            raise HTTPException(\n                status_code=HTTP_400_BAD_REQUEST,\n                detail=f\"Value specified for {field_name}_lt: {end} must be after {field_name}_gt: {start}.\",\n            )\n\n    if identity:\n        hashed_identity = ProvidedIdentity.hash_value(value=identity)\n        identities: Set[str] = {\n            identity[0]\n            for identity in ProvidedIdentity.filter(\n                db=db,\n                conditions=(\n                    (ProvidedIdentity.hashed_value == hashed_identity)\n                    & (ProvidedIdentity.privacy_request_id.isnot(None))\n                ),\n            ).values(column(\"privacy_request_id\"))\n        }\n        query = query.filter(PrivacyRequest.id.in_(identities))\n    # Further restrict all PrivacyRequests by query params\n    if request_id:\n        query = query.filter(PrivacyRequest.id.ilike(f\"{request_id}%\"))\n    if external_id:\n        query = query.filter(PrivacyRequest.external_id.ilike(f\"{external_id}%\"))\n    if status:\n        query = query.filter(PrivacyRequest.status.in_(status))\n    if created_lt:\n        query = query.filter(PrivacyRequest.created_at < created_lt)\n    if created_gt:\n        query = query.filter(PrivacyRequest.created_at > created_gt)\n    if started_lt:\n        query = query.filter(PrivacyRequest.started_processing_at < started_lt)\n    if started_gt:\n        query = query.filter(PrivacyRequest.started_processing_at > started_gt)\n    if completed_lt:\n        query = query.filter(\n            PrivacyRequest.status == PrivacyRequestStatus.complete,\n            PrivacyRequest.finished_processing_at < completed_lt,\n        )\n    if completed_gt:\n        query = query.filter(\n            PrivacyRequest.status == PrivacyRequestStatus.complete,\n            PrivacyRequest.finished_processing_at > completed_gt,\n        )\n    if errored_lt:\n        query = query.filter(\n            PrivacyRequest.status == PrivacyRequestStatus.error,\n            PrivacyRequest.finished_processing_at < errored_lt,\n        )\n    if errored_gt:\n        query = query.filter(\n            PrivacyRequest.status == PrivacyRequestStatus.error,\n            PrivacyRequest.finished_processing_at > errored_gt,\n        )\n\n    return query\n\n\ndef _sort_privacy_request_queryset(\n    query: Query, sort_field: str, sort_direction: ColumnSort\n) -> Query:\n    if hasattr(PrivacyRequest, sort_field) is False:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=f\"{sort_field} is not on PrivacyRequest\",\n        )\n\n    sort_object_attribute = getattr(PrivacyRequest, sort_field)\n    sort_func = getattr(sort_object_attribute, sort_direction)\n    return query.order_by(nullslast(sort_func()))\n\n\ndef attach_resume_instructions(privacy_request: PrivacyRequest) -> None:\n    \"\"\"\n    Temporarily update a paused/errored/requires_input privacy request object with instructions from the Redis cache\n    about how to resume manually if applicable.\n    \"\"\"\n    resume_endpoint: Optional[str] = None\n    action_required_details: Optional[CheckpointActionRequired] = None\n\n    if privacy_request.status == PrivacyRequestStatus.paused:\n        action_required_details = privacy_request.get_paused_collection_details()\n\n        if action_required_details:\n            # Graph is paused on a specific collection\n            resume_endpoint = (\n                PRIVACY_REQUEST_MANUAL_ERASURE\n                if action_required_details.step == CurrentStep.erasure\n                else PRIVACY_REQUEST_MANUAL_INPUT\n            )\n        else:\n            # Graph is paused on a pre-processing webhook\n            resume_endpoint = PRIVACY_REQUEST_RESUME\n\n    elif privacy_request.status == PrivacyRequestStatus.error:\n        action_required_details = privacy_request.get_failed_checkpoint_details()\n        resume_endpoint = PRIVACY_REQUEST_RETRY\n\n    elif privacy_request.status == PrivacyRequestStatus.requires_input:\n        # No action required details because this doesn't need to resume from a\n        # specific step or collection\n        resume_endpoint = PRIVACY_REQUEST_RESUME_FROM_REQUIRES_INPUT\n\n    if action_required_details:\n        action_required_details.step = action_required_details.step.value  # type: ignore\n        action_required_details.collection = (\n            action_required_details.collection.value if action_required_details.collection else None  # type: ignore\n        )\n\n    privacy_request.action_required_details = action_required_details\n    # replaces the placeholder in the url with the privacy request id\n    privacy_request.resume_endpoint = (\n        resume_endpoint.format(privacy_request_id=privacy_request.id)\n        if resume_endpoint\n        else None\n    )\n\n\n@router.get(\n    urls.PRIVACY_REQUESTS,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.PRIVACY_REQUEST_READ])],\n    response_model=Page[\n        Union[\n            PrivacyRequestVerboseResponse,\n            PrivacyRequestResponse,\n        ]\n    ],\n)\ndef get_request_status(\n    *,\n    db: Session = Depends(deps.get_db),\n    params: Params = Depends(),\n    request_id: Optional[str] = None,\n    identity: Optional[str] = None,\n    status: Optional[List[PrivacyRequestStatus]] = FastAPIQuery(\n        default=None\n    ),  # type:ignore\n    created_lt: Optional[datetime] = None,\n    created_gt: Optional[datetime] = None,\n    started_lt: Optional[datetime] = None,\n    started_gt: Optional[datetime] = None,\n    completed_lt: Optional[datetime] = None,\n    completed_gt: Optional[datetime] = None,\n    errored_lt: Optional[datetime] = None,\n    errored_gt: Optional[datetime] = None,\n    external_id: Optional[str] = None,\n    verbose: Optional[bool] = False,\n    include_identities: Optional[bool] = False,\n    download_csv: Optional[bool] = False,\n    sort_field: str = \"created_at\",\n    sort_direction: ColumnSort = ColumnSort.DESC,\n) -> Union[StreamingResponse, AbstractPage[PrivacyRequest]]:\n    \"\"\"Returns PrivacyRequest information. Supports a variety of optional query params.\n\n    To fetch a single privacy request, use the request_id query param `?request_id=`.\n    To see individual execution logs, use the verbose query param `?verbose=True`.\n    \"\"\"\n    logger.info(\"Finding all request statuses with pagination params %s\", params)\n\n    query = db.query(PrivacyRequest)\n    query = _filter_privacy_request_queryset(\n        db,\n        query,\n        request_id,\n        identity,\n        status,\n        created_lt,\n        created_gt,\n        started_lt,\n        started_gt,\n        completed_lt,\n        completed_gt,\n        errored_lt,\n        errored_gt,\n        external_id,\n    )\n\n    logger.info(\n        \"Sorting requests by field: %s and direction: %s\", sort_field, sort_direction\n    )\n    query = _sort_privacy_request_queryset(query, sort_field, sort_direction)\n\n    if download_csv:\n        # Returning here if download_csv param was specified\n        logger.info(\"Downloading privacy requests as csv\")\n        return privacy_request_csv_download(db, query)\n\n    # Conditionally embed execution log details in the response.\n    if verbose:\n        logger.info(\"Finding execution and audit log details\")\n        PrivacyRequest.execution_and_audit_logs_by_dataset = property(\n            execution_and_audit_logs_by_dataset_name\n        )\n    else:\n        PrivacyRequest.execution_and_audit_logs_by_dataset = property(lambda self: None)\n\n    paginated = paginate(query, params)\n    if include_identities:\n        # Conditionally include the cached identity data in the response if\n        # it is explicitly requested\n        for item in paginated.items:  # type: ignore\n            item.identity = item.get_persisted_identity().dict()\n            attach_resume_instructions(item)\n    else:\n        for item in paginated.items:  # type: ignore\n            attach_resume_instructions(item)\n\n    return paginated\n\n\n@router.get(\n    urls.REQUEST_STATUS_LOGS,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.PRIVACY_REQUEST_READ])],\n    response_model=Page[ExecutionLogDetailResponse],\n)\ndef get_request_status_logs(\n    privacy_request_id: str,\n    *,\n    db: Session = Depends(deps.get_db),\n    params: Params = Depends(),\n) -> AbstractPage[ExecutionLog]:\n    \"\"\"Returns all the execution logs associated with a given privacy request ordered by updated asc.\"\"\"\n\n    get_privacy_request_or_error(db, privacy_request_id)\n\n    logger.info(\n        \"Finding all execution logs for privacy request %s with params '%s'\",\n        privacy_request_id,\n        params,\n    )\n\n    return paginate(\n        ExecutionLog.query(db=db)\n        .filter(ExecutionLog.privacy_request_id == privacy_request_id)\n        .order_by(ExecutionLog.updated_at.asc()),\n        params,\n    )\n\n\n@router.put(\n    REQUEST_PREVIEW,\n    status_code=HTTP_200_OK,\n    response_model=List[DryRunDatasetResponse],\n    dependencies=[Security(verify_oauth_client, scopes=[PRIVACY_REQUEST_READ])],\n)\ndef get_request_preview_queries(\n    *,\n    db: Session = Depends(deps.get_db),\n    dataset_keys: Optional[List[str]] = Body(None),\n) -> List[DryRunDatasetResponse]:\n    \"\"\"Returns dry run queries given a list of dataset ids.  If a dataset references another dataset, both dataset\n    keys must be in the request body.\"\"\"\n    dataset_configs: List[DatasetConfig] = []\n    if not dataset_keys:\n        dataset_configs = DatasetConfig.all(db=db)\n        if not dataset_configs:\n            raise HTTPException(\n                status_code=HTTP_404_NOT_FOUND,\n                detail=\"No datasets could be found\",\n            )\n    else:\n        for dataset_key in dataset_keys:\n            dataset_config = DatasetConfig.get_by(\n                db=db, field=\"fides_key\", value=dataset_key\n            )\n            if not dataset_config:\n                raise HTTPException(\n                    status_code=HTTP_404_NOT_FOUND,\n                    detail=f\"No dataset with id '{dataset_key}'\",\n                )\n            dataset_configs.append(dataset_config)\n    try:\n        connection_configs: List[ConnectionConfig] = [\n            ConnectionConfig.get(db=db, object_id=dataset.connection_config_id)\n            for dataset in dataset_configs\n        ]\n\n        try:\n            dataset_graph: DatasetGraph = DatasetGraph(\n                *[dataset.get_graph() for dataset in dataset_configs]\n            )\n        except ValidationError as exc:\n            raise HTTPException(\n                status_code=HTTP_400_BAD_REQUEST,\n                detail=f\"{exc}. Make sure all referenced datasets are included in the request body.\",\n            )\n\n        identity_seed: Dict[str, str] = {\n            k: \"something\" for k in dataset_graph.identity_keys.values()\n        }\n        traversal: Traversal = Traversal(dataset_graph, identity_seed)\n        queries: Dict[CollectionAddress, str] = collect_queries(\n            traversal,\n            TaskResources(EMPTY_REQUEST, Policy(), connection_configs, db),\n        )\n        return [\n            DryRunDatasetResponse(\n                collectionAddress=CollectionAddressResponse(\n                    dataset=key.dataset, collection=key.collection\n                ),\n                query=value,\n            )\n            for key, value in queries.items()\n        ]\n    except TraversalError as err:\n        logger.info(\"Dry run failed: %s\", err)\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=\"Dry run failed\",\n        )\n\n\n@router.post(\n    PRIVACY_REQUEST_RESUME,\n    status_code=HTTP_200_OK,\n    response_model=PrivacyRequestResponse,\n)\nasync def resume_privacy_request(\n    privacy_request_id: str,\n    *,\n    db: Session = Depends(deps.get_db),\n    webhook: PolicyPreWebhook = Security(\n        verify_callback_oauth, scopes=[scopes.PRIVACY_REQUEST_CALLBACK_RESUME]\n    ),\n    webhook_callback: PrivacyRequestResumeFormat,\n) -> PrivacyRequestResponse:\n    \"\"\"Resume running a privacy request after it was paused by a Pre-Execution webhook\"\"\"\n    privacy_request = get_privacy_request_or_error(db, privacy_request_id)\n    # We don't want to persist derived identities because they have not been provided\n    # by the end user\n    privacy_request.cache_identity(webhook_callback.derived_identity)  # type: ignore\n\n    if privacy_request.status != PrivacyRequestStatus.paused:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Invalid resume request: privacy request '{privacy_request.id}' status = {privacy_request.status.value}.\",  # type: ignore\n        )\n\n    logger.info(\n        \"Resuming privacy request '%s' from webhook '%s'\",\n        privacy_request_id,\n        webhook.key,\n    )\n\n    privacy_request.status = PrivacyRequestStatus.in_processing\n    privacy_request.save(db=db)\n\n    queue_privacy_request(\n        privacy_request_id=privacy_request.id,\n        from_webhook_id=webhook.id,\n    )\n    return privacy_request\n\n\ndef validate_manual_input(\n    manual_rows: List[Row],\n    collection: CollectionAddress,\n    dataset_graph: DatasetGraph,\n) -> None:\n    \"\"\"Validate manually-added data for a collection.\n\n    The specified collection must exist and all fields must be previously defined.\n    \"\"\"\n    for row in manual_rows:\n        for field_name in row:\n            if not dataset_graph.nodes[collection].contains_field(\n                lambda f: f.name == field_name  # pylint: disable=W0640\n            ):\n                raise HTTPException(\n                    status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n                    detail=f\"Cannot save manual rows. No '{field_name}' field defined on the '{collection.value}' collection.\",\n                )\n\n\nasync def resume_privacy_request_with_manual_input(\n    privacy_request_id: str,\n    db: Session,\n    expected_paused_step: CurrentStep,\n    manual_rows: List[Row] = [],\n    manual_count: Optional[int] = None,\n) -> PrivacyRequest:\n    \"\"\"Resume privacy request after validating and caching manual data for an access or an erasure request.\n\n    This assumes the privacy request is being resumed from a specific collection in the graph.\n    \"\"\"\n    privacy_request: PrivacyRequest = get_privacy_request_or_error(\n        db, privacy_request_id\n    )\n    if privacy_request.status != PrivacyRequestStatus.paused:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Invalid resume request: privacy request '{privacy_request.id}' \"  # type: ignore\n            f\"status = {privacy_request.status.value}. Privacy request is not paused.\",\n        )\n\n    paused_details: Optional[\n        CheckpointActionRequired\n    ] = privacy_request.get_paused_collection_details()\n    if not paused_details:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Cannot resume privacy request '{privacy_request.id}'; no paused details.\",\n        )\n\n    paused_step: CurrentStep = paused_details.step\n    paused_collection: Optional[CollectionAddress] = paused_details.collection\n\n    if paused_step != expected_paused_step:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Collection '{paused_collection}' is paused at the {paused_step.value} step. Pass in manual data instead to \"\n            f\"'{PRIVACY_REQUEST_MANUAL_ERASURE if paused_step == CurrentStep.erasure else PRIVACY_REQUEST_MANUAL_INPUT}' to resume.\",\n        )\n\n    datasets = DatasetConfig.all(db=db)\n    dataset_graphs = [dataset_config.get_graph() for dataset_config in datasets]\n    dataset_graph = DatasetGraph(*dataset_graphs)\n\n    if not paused_collection:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=\"Cannot save manual data on paused collection. No paused collection saved'.\",\n        )\n\n    node: Optional[Node] = dataset_graph.nodes.get(paused_collection)\n    if not node:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=f\"Cannot save manual data. No collection in graph with name: '{paused_collection.value}'.\",\n        )\n\n    if paused_step == CurrentStep.access:\n        validate_manual_input(manual_rows, paused_collection, dataset_graph)\n        logger.info(\n            \"Caching manual input for privacy request '%s', collection: '%s'\",\n            privacy_request_id,\n            paused_collection,\n        )\n        privacy_request.cache_manual_input(paused_collection, manual_rows)\n\n    elif paused_step == CurrentStep.erasure:\n        logger.info(\n            \"Caching manually erased row count for privacy request '%s', collection: '%s'\",\n            privacy_request_id,\n            paused_collection,\n        )\n        privacy_request.cache_manual_erasure_count(paused_collection, manual_count)  # type: ignore\n\n    logger.info(\n        \"Resuming privacy request '%s', %s step, from collection '%s'\",\n        privacy_request_id,\n        paused_step.value,\n        paused_collection.value,\n    )\n\n    privacy_request.status = PrivacyRequestStatus.in_processing\n    privacy_request.save(db=db)\n\n    queue_privacy_request(\n        privacy_request_id=privacy_request.id,\n        from_step=paused_step.value,\n    )\n\n    return privacy_request\n\n\n@router.post(\n    PRIVACY_REQUEST_MANUAL_INPUT,\n    status_code=HTTP_200_OK,\n    response_model=PrivacyRequestResponse,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n    ],\n)\nasync def resume_with_manual_input(\n    privacy_request_id: str,\n    *,\n    db: Session = Depends(deps.get_db),\n    manual_rows: List[Row],\n) -> PrivacyRequestResponse:\n    \"\"\"Resume a privacy request by passing in manual input for the paused collection.\n\n    If there's no manual data to submit, pass in an empty list to resume the privacy request.\n    \"\"\"\n    return await resume_privacy_request_with_manual_input(\n        privacy_request_id=privacy_request_id,\n        db=db,\n        expected_paused_step=CurrentStep.access,\n        manual_rows=manual_rows,\n    )\n\n\n@router.post(\n    PRIVACY_REQUEST_MANUAL_ERASURE,\n    status_code=HTTP_200_OK,\n    response_model=PrivacyRequestResponse,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n    ],\n)\nasync def resume_with_erasure_confirmation(\n    privacy_request_id: str,\n    *,\n    db: Session = Depends(deps.get_db),\n    cache: FidesopsRedis = Depends(deps.get_cache),\n    manual_count: RowCountRequest,\n) -> PrivacyRequestResponse:\n    \"\"\"Resume the erasure portion of privacy request by passing in the number of rows that were manually masked.\n\n    If no rows were masked, pass in a 0 to resume the privacy request.\n    \"\"\"\n    return await resume_privacy_request_with_manual_input(\n        privacy_request_id=privacy_request_id,\n        db=db,\n        expected_paused_step=CurrentStep.erasure,\n        manual_count=manual_count.row_count,\n    )\n\n\n@router.post(\n    PRIVACY_REQUEST_RETRY,\n    status_code=HTTP_200_OK,\n    response_model=PrivacyRequestResponse,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n    ],\n)\nasync def restart_privacy_request_from_failure(\n    privacy_request_id: str,\n    *,\n    db: Session = Depends(deps.get_db),\n) -> PrivacyRequestResponse:\n    \"\"\"Restart a privacy request from failure\"\"\"\n    privacy_request: PrivacyRequest = get_privacy_request_or_error(\n        db, privacy_request_id\n    )\n\n    if privacy_request.status != PrivacyRequestStatus.error:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Cannot restart privacy request from failure: privacy request '{privacy_request.id}' status = {privacy_request.status.value}.\",  # type: ignore\n        )\n\n    failed_details: Optional[\n        CheckpointActionRequired\n    ] = privacy_request.get_failed_checkpoint_details()\n    if not failed_details:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Cannot restart privacy request from failure '{privacy_request.id}'; no failed step or collection.\",\n        )\n\n    failed_step: CurrentStep = failed_details.step\n    failed_collection: Optional[CollectionAddress] = failed_details.collection\n\n    logger.info(\n        \"Restarting failed privacy request '%s' from '%s step, 'collection '%s'\",\n        privacy_request_id,\n        failed_step,\n        failed_collection,\n    )\n\n    privacy_request.status = PrivacyRequestStatus.in_processing\n    privacy_request.save(db=db)\n    queue_privacy_request(\n        privacy_request_id=privacy_request.id,\n        from_step=failed_step.value,\n    )\n\n    privacy_request.cache_failed_checkpoint_details()  # Reset failed step and collection to None\n\n    return privacy_request\n\n\ndef review_privacy_request(\n    db: Session,\n    request_ids: List[str],\n    process_request_function: Callable,\n) -> BulkReviewResponse:\n    \"\"\"Helper method shared between the approve and deny privacy request endpoints\"\"\"\n    succeeded: List[PrivacyRequest] = []\n    failed: List[Dict[str, Any]] = []\n\n    for request_id in request_ids:\n        privacy_request = PrivacyRequest.get(db, object_id=request_id)\n        if not privacy_request:\n            failed.append(\n                {\n                    \"message\": f\"No privacy request found with id '{request_id}'\",\n                    \"data\": {\"privacy_request_id\": request_id},\n                }\n            )\n            continue\n\n        if privacy_request.status != PrivacyRequestStatus.pending:\n            failed.append(\n                {\n                    \"message\": \"Cannot transition status\",\n                    \"data\": PrivacyRequestResponse.from_orm(privacy_request),\n                }\n            )\n            continue\n\n        try:\n            process_request_function(privacy_request)\n        except Exception:\n            failure = {\n                \"message\": \"Privacy request could not be updated\",\n                \"data\": PrivacyRequestResponse.from_orm(privacy_request),\n            }\n            failed.append(failure)\n        else:\n            succeeded.append(privacy_request)\n\n    return BulkReviewResponse(\n        succeeded=succeeded,\n        failed=failed,\n    )\n\n\ndef _send_privacy_request_review_email_to_user(\n    action_type: EmailActionType,\n    email: Optional[str],\n    rejection_reason: Optional[str],\n) -> None:\n    \"\"\"Helper method to send review notification email to user, shared between approve and deny\"\"\"\n    if not email:\n        logger.error(\n            IdentityNotFoundException(\n                \"Identity email was not found, so request review email could not be sent.\"\n            )\n        )\n    dispatch_email_task.apply_async(\n        queue=EMAIL_QUEUE_NAME,\n        kwargs={\n            \"email_meta\": FidesopsEmail(\n                action_type=action_type,\n                body_params=RequestReviewDenyBodyParams(\n                    rejection_reason=rejection_reason\n                )\n                if action_type is EmailActionType.PRIVACY_REQUEST_REVIEW_DENY\n                else None,\n            ).dict(),\n            \"to_email\": email,\n        },\n    )\n\n\n@router.post(\n    PRIVACY_REQUEST_VERIFY_IDENTITY,\n    status_code=HTTP_200_OK,\n    response_model=PrivacyRequestResponse,\n)\nasync def verify_identification_code(\n    privacy_request_id: str,\n    *,\n    db: Session = Depends(deps.get_db),\n    provided_code: VerificationCode,\n) -> PrivacyRequestResponse:\n    \"\"\"Verify the supplied identity verification code.\n\n    If successful, and we don't need separate manual request approval, queue the privacy request\n    for execution.\n    \"\"\"\n\n    privacy_request: PrivacyRequest = get_privacy_request_or_error(\n        db, privacy_request_id\n    )\n    try:\n        privacy_request.verify_identity(db, provided_code.code)\n        policy: Optional[Policy] = Policy.get(\n            db=db, object_id=privacy_request.policy_id\n        )\n        if config.notifications.send_request_receipt_notification:\n            _send_privacy_request_receipt_email_to_user(\n                policy, privacy_request.get_persisted_identity().email\n            )\n    except IdentityVerificationException as exc:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=exc.message)\n    except PermissionError as exc:\n        logger.info(\"Invalid verification code provided for %s.\", privacy_request.id)\n        raise HTTPException(status_code=HTTP_403_FORBIDDEN, detail=exc.args[0])\n\n    logger.info(\"Identity verified for %s.\", privacy_request.id)\n\n    if not config.execution.require_manual_request_approval:\n        AuditLog.create(\n            db=db,\n            data={\n                \"user_id\": \"system\",\n                \"privacy_request_id\": privacy_request.id,\n                \"action\": AuditLogAction.approved,\n                \"message\": \"\",\n            },\n        )\n        queue_privacy_request(privacy_request.id)\n\n    return privacy_request\n\n\n@router.patch(\n    PRIVACY_REQUEST_APPROVE,\n    status_code=HTTP_200_OK,\n    response_model=BulkReviewResponse,\n)\ndef approve_privacy_request(\n    *,\n    db: Session = Depends(deps.get_db),\n    client: ClientDetail = Security(\n        verify_oauth_client,\n        scopes=[PRIVACY_REQUEST_REVIEW],\n    ),\n    privacy_requests: ReviewPrivacyRequestIds,\n) -> BulkReviewResponse:\n    \"\"\"Approve and dispatch a list of privacy requests and/or report failure\"\"\"\n    user_id = client.user_id\n\n    def _approve_request(privacy_request: PrivacyRequest) -> None:\n        \"\"\"Method for how to process requests - approved\"\"\"\n        privacy_request.status = PrivacyRequestStatus.approved\n        privacy_request.reviewed_at = datetime.utcnow()\n        privacy_request.reviewed_by = user_id\n        privacy_request.save(db=db)\n        AuditLog.create(\n            db=db,\n            data={\n                \"user_id\": user_id,\n                \"privacy_request_id\": privacy_request.id,\n                \"action\": AuditLogAction.approved,\n                \"message\": \"\",\n            },\n        )\n        if config.notifications.send_request_review_notification:\n            _send_privacy_request_review_email_to_user(\n                action_type=EmailActionType.PRIVACY_REQUEST_REVIEW_APPROVE,\n                email=privacy_request.get_cached_identity_data().get(\n                    ProvidedIdentityType.email.value\n                ),\n                rejection_reason=None,\n            )\n\n        queue_privacy_request(privacy_request_id=privacy_request.id)\n\n    return review_privacy_request(\n        db=db,\n        request_ids=privacy_requests.request_ids,\n        process_request_function=_approve_request,\n    )\n\n\n@router.patch(\n    PRIVACY_REQUEST_DENY,\n    status_code=HTTP_200_OK,\n    response_model=BulkReviewResponse,\n)\ndef deny_privacy_request(\n    *,\n    db: Session = Depends(deps.get_db),\n    client: ClientDetail = Security(\n        verify_oauth_client,\n        scopes=[PRIVACY_REQUEST_REVIEW],\n    ),\n    privacy_requests: DenyPrivacyRequests,\n) -> BulkReviewResponse:\n    \"\"\"Deny a list of privacy requests and/or report failure\"\"\"\n    user_id = client.user_id\n\n    def _deny_request(\n        privacy_request: PrivacyRequest,\n    ) -> None:\n        \"\"\"Method for how to process requests - denied\"\"\"\n        privacy_request.status = PrivacyRequestStatus.denied\n        privacy_request.reviewed_at = datetime.utcnow()\n        privacy_request.reviewed_by = user_id\n        privacy_request.save(db=db)\n        AuditLog.create(\n            db=db,\n            data={\n                \"user_id\": user_id,\n                \"privacy_request_id\": privacy_request.id,\n                \"action\": AuditLogAction.denied,\n                \"message\": privacy_requests.reason,\n            },\n        )\n        if config.notifications.send_request_review_notification:\n            _send_privacy_request_review_email_to_user(\n                action_type=EmailActionType.PRIVACY_REQUEST_REVIEW_DENY,\n                email=privacy_request.get_cached_identity_data().get(\n                    ProvidedIdentityType.email.value\n                ),\n                rejection_reason=privacy_requests.reason,\n            )\n\n    return review_privacy_request(\n        db=db,\n        request_ids=privacy_requests.request_ids,\n        process_request_function=_deny_request,\n    )\n\n\n@router.patch(\n    PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[PRIVACY_REQUEST_UPLOAD_DATA])],\n    response_model=None,\n)\ndef upload_manual_webhook_data(\n    *,\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n    privacy_request_id: str,\n    db: Session = Depends(deps.get_db),\n    input_data: Dict[str, Any],\n) -> None:\n    \"\"\"Upload manual input for the privacy request for the fields defined on the access manual webhook.\n    The data collected here is not included in the graph but uploaded directly to the user at the end\n    of privacy request execution.\n\n    Because a 'manual_webhook' ConnectionConfig has one AccessManualWebhook associated with it,\n    we are using the ConnectionConfig key as the AccessManualWebhook identifier here.\n    \"\"\"\n    privacy_request: PrivacyRequest = get_privacy_request_or_error(\n        db, privacy_request_id\n    )\n    access_manual_webhook: AccessManualWebhook = get_access_manual_webhook_or_404(\n        connection_config\n    )\n\n    if not privacy_request.status == PrivacyRequestStatus.requires_input:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Invalid access manual webhook upload request: privacy request '{privacy_request.id}' status = {privacy_request.status.value}.\",  # type: ignore\n        )\n\n    try:\n        privacy_request.cache_manual_webhook_input(access_manual_webhook, input_data)\n    except PydanticValidationError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=exc.errors()\n        )\n\n    logger.info(\n        \"Input saved for access manual webhook '%s' for privacy_request '%s'.\",\n        access_manual_webhook,\n        privacy_request,\n    )\n\n\n@router.get(\n    PRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[PRIVACY_REQUEST_VIEW_DATA])],\n    response_model=Optional[ManualWebhookData],\n)\ndef view_uploaded_manual_webhook_data(\n    *,\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n    privacy_request_id: str,\n    db: Session = Depends(deps.get_db),\n) -> Optional[ManualWebhookData]:\n    \"\"\"\n    View uploaded data for this privacy request for the given access manual webhook\n\n    If no data exists for this webhook, we just return all fields as None.\n    If we have missing or extra fields saved, we'll just return the overlap between what is saved and what is defined on the webhook.\n\n    If checked=False, data must be reviewed before submission. The privacy request should not be submitted as-is.\n    \"\"\"\n    privacy_request: PrivacyRequest = get_privacy_request_or_error(\n        db, privacy_request_id\n    )\n    access_manual_webhook: AccessManualWebhook = get_access_manual_webhook_or_404(\n        connection_config\n    )\n\n    if not privacy_request.status == PrivacyRequestStatus.requires_input:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Invalid access manual webhook upload request: privacy request \"\n            f\"'{privacy_request.id}' status = {privacy_request.status.value}.\",  # type: ignore\n        )\n\n    try:\n        logger.info(\n            \"Retrieving input data for access manual webhook '%s' for privacy request '%s'.\",\n            connection_config.key,\n            privacy_request.id,\n        )\n        data: Dict[str, Any] = privacy_request.get_manual_webhook_input_strict(\n            access_manual_webhook\n        )\n        checked = True\n    except (\n        PydanticValidationError,\n        ManualWebhookFieldsUnset,\n        NoCachedManualWebhookEntry,\n    ) as exc:\n        logger.info(exc)\n        data = privacy_request.get_manual_webhook_input_non_strict(\n            manual_webhook=access_manual_webhook\n        )\n        checked = False\n\n    return ManualWebhookData(checked=checked, fields=data)\n\n\n@router.post(\n    PRIVACY_REQUEST_RESUME_FROM_REQUIRES_INPUT,\n    status_code=HTTP_200_OK,\n    response_model=PrivacyRequestResponse,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[PRIVACY_REQUEST_CALLBACK_RESUME])\n    ],\n)\nasync def resume_privacy_request_from_requires_input(\n    privacy_request_id: str,\n    *,\n    db: Session = Depends(deps.get_db),\n) -> PrivacyRequestResponse:\n    \"\"\"Resume a privacy request from 'requires_input' status.\"\"\"\n    privacy_request: PrivacyRequest = get_privacy_request_or_error(\n        db, privacy_request_id\n    )\n\n    if privacy_request.status != PrivacyRequestStatus.requires_input:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Cannot resume privacy request from 'requires_input': privacy request '{privacy_request.id}' status = {privacy_request.status.value}.\",  # type: ignore\n        )\n\n    access_manual_webhooks: List[AccessManualWebhook] = AccessManualWebhook.get_enabled(\n        db\n    )\n    try:\n        for manual_webhook in access_manual_webhooks:\n            privacy_request.get_manual_webhook_input_strict(manual_webhook)\n    except (\n        NoCachedManualWebhookEntry,\n        PydanticValidationError,\n        ManualWebhookFieldsUnset,\n    ) as exc:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Cannot resume privacy request. {exc}\",\n        )\n\n    logger.info(\n        \"Resuming privacy request '%s' after manual inputs verified\",\n        privacy_request_id,\n    )\n\n    privacy_request.status = PrivacyRequestStatus.in_processing\n    privacy_request.save(db=db)\n    queue_privacy_request(\n        privacy_request_id=privacy_request.id,\n    )\n\n    return privacy_request\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/urn_registry.py", "content": "# Prefixes\nV1_URL_PREFIX = \"/api/v1\"\nYAML = \"/yml\"\n\n# Config URLs\nCONFIG = \"/config\"\n\n# Consent request URLs\nCONSENT_REQUEST = \"/consent-request\"\nCONSENT_REQUEST_PREFERENCES = \"/consent-request/preferences\"\nCONSENT_REQUEST_PREFERENCES_WITH_ID = (\n    \"/consent-request/{consent_request_id}/preferences\"\n)\nCONSENT_REQUEST_VERIFY = \"/consent-request/{consent_request_id}/verify\"\n\n\n# Oauth Client URLs\nTOKEN = \"/oauth/token\"\nCLIENT = \"/oauth/client\"\nSCOPE = \"/oauth/scope\"\nCLIENT_BY_ID = \"/oauth/client/{client_id}\"\nCLIENT_SCOPE = \"/oauth/client/{client_id}/scope\"\nOAUTH_CALLBACK = \"/oauth/callback\"\n\n# Encryption URLs\nENCRYPT_AES = \"/cryptography/encryption/aes/encrypt\"\nDECRYPT_AES = \"/cryptography/encryption/aes/decrypt\"\nENCRYPTION_KEY = \"/cryptography/encryption/key\"\n\n# Masking URLs\nMASKING = \"/masking/mask\"\nMASKING_STRATEGY = \"/masking/strategy\"\n\n# Storage URLs\nSTORAGE_CONFIG = \"/storage/config\"\nSTORAGE_SECRETS = \"/storage/config/{config_key}/secret\"\nSTORAGE_BY_KEY = \"/storage/config/{config_key}\"\nSTORAGE_UPLOAD = \"/storage/{request_id}\"\n\n# Email URLs\nEMAIL_CONFIG = \"/email/config\"\nEMAIL_SECRETS = \"/email/config/{config_key}/secret\"\nEMAIL_BY_KEY = \"/email/config/{config_key}\"\n\n# Policy URLs\nPOLICY_LIST = \"/policy\"\nPOLICY_DETAIL = \"/policy/{policy_key}\"\n\n# Privacy request URLs\nPRIVACY_REQUESTS = \"/privacy-request\"\nPRIVACY_REQUEST_APPROVE = \"/privacy-request/administrate/approve\"\nPRIVACY_REQUEST_DENY = \"/privacy-request/administrate/deny\"\nREQUEST_STATUS_LOGS = \"/privacy-request/{privacy_request_id}/log\"\nPRIVACY_REQUEST_VERIFY_IDENTITY = \"/privacy-request/{privacy_request_id}/verify\"\nPRIVACY_REQUEST_RESUME = \"/privacy-request/{privacy_request_id}/resume\"\nPRIVACY_REQUEST_MANUAL_INPUT = \"/privacy-request/{privacy_request_id}/manual_input\"\nPRIVACY_REQUEST_MANUAL_ERASURE = \"/privacy-request/{privacy_request_id}/erasure_confirm\"\nPRIVACY_REQUEST_RETRY = \"/privacy-request/{privacy_request_id}/retry\"\nREQUEST_PREVIEW = \"/privacy-request/preview\"\nPRIVACY_REQUEST_ACCESS_MANUAL_WEBHOOK_INPUT = (\n    \"/privacy-request/{privacy_request_id}/access_manual_webhook/{connection_key}\"\n)\nPRIVACY_REQUEST_RESUME_FROM_REQUIRES_INPUT = (\n    \"/privacy-request/{privacy_request_id}/resume_from_requires_input\"\n)\n\n\n# Identity Verification URLs\nID_VERIFICATION_CONFIG = \"/id-verification/config\"\n\n# Rule URLs\nRULE_LIST = \"/policy/{policy_key}/rule\"\nRULE_DETAIL = \"/policy/{policy_key}/rule/{rule_key}\"\n\n# Rule URLs\nRULE_TARGET_LIST = \"/policy/{policy_key}/rule/{rule_key}/target\"\nRULE_TARGET_DETAIL = \"/policy/{policy_key}/rule/{rule_key}/target/{rule_target_key}\"\n\n# Policy Webhook URL's\nPOLICY_WEBHOOKS_PRE = \"/policy/{policy_key}/webhook/pre_execution\"\nPOLICY_WEBHOOKS_POST = \"/policy/{policy_key}/webhook/post_execution\"\nPOLICY_PRE_WEBHOOK_DETAIL = (\n    \"/policy/{policy_key}/webhook/pre_execution/{pre_webhook_key}\"\n)\nPOLICY_POST_WEBHOOK_DETAIL = (\n    \"/policy/{policy_key}/webhook/post_execution/{post_webhook_key}\"\n)\n\n# Connection Type URLs\nCONNECTION_TYPES = \"/connection_type\"\nCONNECTION_TYPE_SECRETS = \"/connection_type/{connection_type}/secret\"\n\n# Connection Configurations URLs\nCONNECTIONS = \"/connection\"\nCONNECTION_BY_KEY = \"/connection/{connection_key}\"\nCONNECTION_SECRETS = \"/connection/{connection_key}/secret\"\nCONNECTION_TEST = \"/connection/{connection_key}/test\"\nAUTHORIZE = \"/connection/{connection_key}/authorize\"\n\n# Manual Webhooks\nACCESS_MANUAL_WEBHOOKS = \"/access_manual_webhook\"\nACCESS_MANUAL_WEBHOOK = CONNECTION_BY_KEY + \"/access_manual_webhook\"\n\n# Collection URLs\nDATASET_VALIDATE = CONNECTION_BY_KEY + \"/validate_dataset\"\nDATASETS = CONNECTION_BY_KEY + \"/dataset\"\nDATASET_BY_KEY = CONNECTION_BY_KEY + \"/dataset/{fides_key}\"\n\n# YAML Collection URLs\nYAML_DATASETS = YAML + DATASETS\n\n# SaaS Config URLs\nSAAS_CONFIG_VALIDATE = CONNECTION_BY_KEY + \"/validate_saas_config\"\nSAAS_CONFIG = CONNECTION_BY_KEY + \"/saas_config\"\nSAAS_CONNECTOR_FROM_TEMPLATE = \"/connection/instantiate/{saas_connector_type}\"\n\n\n# User URLs\nUSERS = \"/user\"\nUSER_DETAIL = \"/user/{user_id}\"\nUSER_PASSWORD_RESET = \"/user/{user_id}/reset-password\"\n\n# User Permission URLs\nUSER_PERMISSIONS = \"/user/{user_id}/permission\"\n\n# Login URLs\nLOGIN = \"/login\"\nLOGOUT = \"/logout\"\n\n# Health URL\nHEALTH = \"/health\"\n\n# DRP\nDRP_EXERCISE = \"/drp/exercise\"\nDRP_STATUS = \"/drp/status\"\nDRP_DATA_RIGHTS = \"/drp/data-rights\"\nDRP_REVOKE = \"/drp/revoke\"\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/identity_verification_endpoints.py", "content": "import logging\nfrom typing import Optional\n\nfrom fastapi import Depends\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1 import urn_registry as urls\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.email import EmailConfig\nfrom fidesops.ops.schemas.identity_verification import (\n    IdentityVerificationConfigResponse,\n)\nfrom fidesops.ops.util.api_router import APIRouter\n\nlogger = logging.getLogger(__name__)\nrouter = APIRouter(tags=[\"Identity Verification\"], prefix=urls.V1_URL_PREFIX)\n\n\n@router.get(\n    urls.ID_VERIFICATION_CONFIG,\n    response_model=IdentityVerificationConfigResponse,\n)\ndef get_id_verification_config(\n    *,\n    db: Session = Depends(deps.get_db),\n) -> IdentityVerificationConfigResponse:\n    \"\"\"Returns id verification config.\"\"\"\n    email_config: Optional[EmailConfig] = db.query(EmailConfig).first()\n    return IdentityVerificationConfigResponse(\n        identity_verification_required=config.execution.subject_identity_verification_required,\n        valid_email_config_exists=bool(email_config and email_config.secrets),\n    )\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/api.py", "content": "from fidesops.ops.api.v1.endpoints import (\n    config_endpoints,\n    connection_endpoints,\n    connection_type_endpoints,\n    consent_request_endpoints,\n    dataset_endpoints,\n    drp_endpoints,\n    email_endpoints,\n    encryption_endpoints,\n    health_endpoints,\n    identity_verification_endpoints,\n    manual_webhook_endpoints,\n    masking_endpoints,\n    oauth_endpoints,\n    policy_endpoints,\n    policy_webhook_endpoints,\n    privacy_request_endpoints,\n    saas_config_endpoints,\n    storage_endpoints,\n    user_endpoints,\n    user_permission_endpoints,\n)\nfrom fidesops.ops.util.api_router import APIRouter\n\napi_router = APIRouter()\napi_router.include_router(config_endpoints.router)\napi_router.include_router(connection_type_endpoints.router)\napi_router.include_router(connection_endpoints.router)\napi_router.include_router(consent_request_endpoints.router)\napi_router.include_router(dataset_endpoints.router)\napi_router.include_router(drp_endpoints.router)\napi_router.include_router(encryption_endpoints.router)\napi_router.include_router(health_endpoints.router)\napi_router.include_router(masking_endpoints.router)\napi_router.include_router(oauth_endpoints.router)\napi_router.include_router(policy_endpoints.router)\napi_router.include_router(policy_webhook_endpoints.router)\napi_router.include_router(privacy_request_endpoints.router)\napi_router.include_router(identity_verification_endpoints.router)\napi_router.include_router(storage_endpoints.router)\napi_router.include_router(email_endpoints.router)\napi_router.include_router(saas_config_endpoints.router)\napi_router.include_router(user_endpoints.router)\napi_router.include_router(user_permission_endpoints.router)\napi_router.include_router(manual_webhook_endpoints.router)\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/manual_webhook_endpoints.py", "content": "import logging\nfrom typing import Optional, Sequence\n\nfrom fastapi import Depends, Security\nfrom fastapi.encoders import jsonable_encoder\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.orm import Session\nfrom starlette.exceptions import HTTPException\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_201_CREATED,\n    HTTP_204_NO_CONTENT,\n    HTTP_400_BAD_REQUEST,\n    HTTP_404_NOT_FOUND,\n)\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1.endpoints.dataset_endpoints import _get_connection_config\nfrom fidesops.ops.api.v1.scope_registry import (\n    WEBHOOK_CREATE_OR_UPDATE,\n    WEBHOOK_DELETE,\n    WEBHOOK_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    ACCESS_MANUAL_WEBHOOK,\n    ACCESS_MANUAL_WEBHOOKS,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig, ConnectionType\nfrom fidesops.ops.models.manual_webhook import AccessManualWebhook\nfrom fidesops.ops.schemas.manual_webhook_schemas import (\n    AccessManualWebhookResponse,\n    AccessManualWebhooks,\n)\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.logger import Pii\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nlogger = logging.getLogger(__name__)\nrouter = APIRouter(tags=[\"Manual Webhooks\"], prefix=V1_URL_PREFIX)\n\n\ndef get_access_manual_webhook_or_404(\n    connection_config: ConnectionConfig,\n) -> AccessManualWebhook:\n    \"\"\"Loads the single AccessManualWebhook associated with the \"manual_webhook\" ConnectionConfig if it exists.\"\"\"\n    if (\n        connection_config.connection_type != ConnectionType.manual_webhook\n    ):  # Sanity check\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"Can't access manual webhooks for ConnectionConfigs of type '{connection_config.connection_type.value}'\",  # type: ignore\n        )\n\n    if not connection_config.access_manual_webhook:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No access manual webhook exists for connection config with key '{connection_config.key}'\",\n        )\n    return connection_config.access_manual_webhook\n\n\n@router.post(\n    ACCESS_MANUAL_WEBHOOK,\n    status_code=HTTP_201_CREATED,\n    dependencies=[Security(verify_oauth_client, scopes=[WEBHOOK_CREATE_OR_UPDATE])],\n    response_model=AccessManualWebhookResponse,\n)\ndef create_access_manual_webhook(\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n    *,\n    db: Session = Depends(deps.get_db),\n    request_body: AccessManualWebhooks,\n) -> AccessManualWebhookResponse:\n    \"\"\"\n    Create an Access Manual Webhook to describe the fields that should be manually uploaded and passed directly to the user\n    \"\"\"\n    if connection_config.connection_type != ConnectionType.manual_webhook:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"You can only create manual webhooks for ConnectionConfigs of type '{ConnectionType.manual_webhook.value}'.\",\n        )\n\n    if connection_config.access_manual_webhook:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"An Access Manual Webhook already exists for ConnectionConfig '{connection_config.key}'.\",\n        )\n\n    logger.info(\n        \"Creating access manual webhook for connection config '%s'\",\n        connection_config.key,\n    )\n\n    try:\n        webhook = AccessManualWebhook.create(\n            db=db,\n            data={\n                \"connection_config_id\": connection_config.id,\n                \"fields\": jsonable_encoder(request_body.fields),\n            },\n        )\n    except IntegrityError as exc:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=Pii(str(exc)))\n\n    return webhook\n\n\n@router.patch(\n    ACCESS_MANUAL_WEBHOOK,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[WEBHOOK_CREATE_OR_UPDATE])],\n    response_model=AccessManualWebhookResponse,\n)\ndef patch_access_manual_webhook(\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n    *,\n    db: Session = Depends(deps.get_db),\n    request_body: AccessManualWebhooks,\n) -> Optional[AccessManualWebhookResponse]:\n    \"\"\"\n    Updates the AccessManualWebhook associated with this ConnectionConfig\n    \"\"\"\n    access_manual_webhook: AccessManualWebhook = get_access_manual_webhook_or_404(\n        connection_config\n    )\n    access_manual_webhook.fields = jsonable_encoder(request_body.fields)\n\n    try:\n        access_manual_webhook.save(db=db)\n    except IntegrityError as exc:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=Pii(str(exc)))\n\n    logger.info(\n        \"Updated access manual webhook for connection config '%s'\",\n        connection_config.key,\n    )\n    return access_manual_webhook\n\n\n@router.get(\n    ACCESS_MANUAL_WEBHOOK,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[WEBHOOK_READ])],\n    response_model=AccessManualWebhookResponse,\n)\ndef get_access_manual_webhook(\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n) -> AccessManualWebhookResponse:\n    \"\"\"\n    Gets the Access Manual Webhook associated with this ConnectionConfig.\n    \"\"\"\n    access_manual_webhook: AccessManualWebhook = get_access_manual_webhook_or_404(\n        connection_config\n    )\n    logger.info(\n        \"Retrieved access manual webhook for connection config '%s'\",\n        connection_config.key,\n    )\n    return access_manual_webhook\n\n\n@router.delete(\n    ACCESS_MANUAL_WEBHOOK,\n    status_code=HTTP_204_NO_CONTENT,\n    dependencies=[Security(verify_oauth_client, scopes=[WEBHOOK_DELETE])],\n)\ndef delete_access_manual_webhook(\n    connection_config: ConnectionConfig = Depends(_get_connection_config),\n    *,\n    db: Session = Depends(deps.get_db),\n) -> None:\n    \"\"\"\n    Deletes the AccessManualWebhook associated with this ConnectionConfig if it exists.\n    \"\"\"\n    access_manual_webhook: AccessManualWebhook = get_access_manual_webhook_or_404(\n        connection_config\n    )\n\n    access_manual_webhook.delete(db)\n    logger.info(\n        \"Deleted access manual webhook for connection config '%s'\",\n        connection_config.key,\n    )\n\n\n@router.get(\n    ACCESS_MANUAL_WEBHOOKS,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[WEBHOOK_READ])],\n    response_model=Sequence[AccessManualWebhookResponse],\n)\ndef get_access_manual_webhooks(\n    db: Session = Depends(deps.get_db),\n) -> Sequence[AccessManualWebhookResponse]:\n    \"\"\"\n    Get all enabled Access Manual Webhooks\n    \"\"\"\n    logger.info(\n        \"Retrieving all enabled access manual webhooks\",\n    )\n    return AccessManualWebhook.get_enabled(db)\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/drp_endpoints.py", "content": "import logging\nfrom typing import Any, Dict, List, Optional\n\nimport jwt\nfrom fastapi import Depends, HTTPException, Security\nfrom sqlalchemy.orm import Session\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_400_BAD_REQUEST,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n    HTTP_424_FAILED_DEPENDENCY,\n    HTTP_500_INTERNAL_SERVER_ERROR,\n)\n\nfrom fidesops.ops import common_exceptions\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1 import scope_registry as scopes\nfrom fidesops.ops.api.v1 import urn_registry as urls\nfrom fidesops.ops.api.v1.endpoints.privacy_request_endpoints import (\n    get_privacy_request_or_error,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.policy import DrpAction, Policy\nfrom fidesops.ops.models.privacy_request import PrivacyRequest, PrivacyRequestStatus\nfrom fidesops.ops.schemas.drp_privacy_request import (\n    DRP_VERSION,\n    DrpDataRightsResponse,\n    DrpIdentity,\n    DrpPrivacyRequestCreate,\n    DrpRevokeRequest,\n)\nfrom fidesops.ops.schemas.privacy_request import PrivacyRequestDRPStatusResponse\nfrom fidesops.ops.schemas.redis_cache import Identity\nfrom fidesops.ops.service.drp.drp_fidesops_mapper import DrpFidesopsMapper\nfrom fidesops.ops.service.privacy_request.request_runner_service import (\n    queue_privacy_request,\n)\nfrom fidesops.ops.service.privacy_request.request_service import (\n    build_required_privacy_request_kwargs,\n    cache_data,\n)\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.cache import FidesopsRedis\nfrom fidesops.ops.util.logger import Pii\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nlogger = logging.getLogger(__name__)\nrouter = APIRouter(tags=[\"DRP\"], prefix=urls.V1_URL_PREFIX)\nEMBEDDED_EXECUTION_LOG_LIMIT = 50\n\n\n@router.post(\n    urls.DRP_EXERCISE,\n    status_code=HTTP_200_OK,\n    response_model=PrivacyRequestDRPStatusResponse,\n)\nasync def create_drp_privacy_request(\n    *,\n    cache: FidesopsRedis = Depends(deps.get_cache),\n    db: Session = Depends(deps.get_db),\n    data: DrpPrivacyRequestCreate,\n) -> PrivacyRequestDRPStatusResponse:\n    \"\"\"\n    Given a drp privacy request body, create and execute\n    a corresponding Fidesops PrivacyRequest\n    \"\"\"\n\n    jwt_key: Optional[str] = config.security.drp_jwt_secret\n    if jwt_key is None:\n        raise HTTPException(\n            status_code=HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"JWT key must be provided\",\n        )\n\n    logger.info(\"Finding policy with drp action '%s'\", data.exercise[0])\n    policy: Optional[Policy] = Policy.get_by(\n        db=db,\n        field=\"drp_action\",\n        value=data.exercise[0],\n    )\n\n    if not policy:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No policy found with drp action '{data.exercise}'.\",\n        )\n\n    privacy_request_kwargs: Dict[str, Any] = build_required_privacy_request_kwargs(\n        None, policy.id\n    )\n\n    try:\n        decrypted_identity: DrpIdentity = DrpIdentity(\n            **jwt.decode(data.identity, jwt_key, algorithms=[\"HS256\"])\n        )\n\n        mapped_identity: Identity = DrpFidesopsMapper.map_identity(\n            drp_identity=decrypted_identity\n        )\n\n        privacy_request: PrivacyRequest = PrivacyRequest.create(\n            db=db,\n            data=privacy_request_kwargs,\n        )\n        privacy_request.persist_identity(\n            db=db,\n            identity=mapped_identity,\n        )\n\n        logger.info(\n            \"Decrypting identity for DRP privacy request %s\", privacy_request.id\n        )\n\n        cache_data(privacy_request, policy, mapped_identity, None, data)\n\n        queue_privacy_request(privacy_request.id)\n\n        return PrivacyRequestDRPStatusResponse(\n            request_id=privacy_request.id,\n            received_at=privacy_request.requested_at,\n            status=DrpFidesopsMapper.map_status(privacy_request.status),  # type: ignore\n        )\n\n    except common_exceptions.RedisConnectionError as exc:\n        logger.error(\"RedisConnectionError: %s\", Pii(str(exc)))\n        # Thrown when cache.ping() fails on cache connection retrieval\n        raise HTTPException(\n            status_code=HTTP_424_FAILED_DEPENDENCY,\n            detail=exc.args[0],\n        )\n    except Exception as exc:\n        logger.error(\"Exception: %s\", Pii(str(exc)))\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=\"DRP privacy request could not be exercised\",\n        )\n\n\n@router.get(\n    urls.DRP_STATUS,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.PRIVACY_REQUEST_READ])],\n    response_model=PrivacyRequestDRPStatusResponse,\n)\ndef get_request_status_drp(\n    *, db: Session = Depends(deps.get_db), request_id: str\n) -> PrivacyRequestDRPStatusResponse:\n    \"\"\"\n    Returns PrivacyRequest information where the respective privacy request is associated with\n    a policy that implements a Data Rights Protocol action.\n    \"\"\"\n\n    logger.info(\"Finding request for DRP with ID: %s\", request_id)\n    request = PrivacyRequest.get(\n        db=db,\n        object_id=request_id,\n    )\n    if not request or not request.policy or not request.policy.drp_action:\n        # If no request is found with this ID, or that request has no policy,\n        # or that request's policy has no associated drp_action.\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"Privacy request with ID {request_id} does not exist, or is not associated with a data rights protocol action.\",\n        )\n\n    logger.info(\"Privacy request with ID: %s found for DRP status.\", request_id)\n    return PrivacyRequestDRPStatusResponse(\n        request_id=request.id,\n        received_at=request.requested_at,\n        status=DrpFidesopsMapper.map_status(request.status),\n    )\n\n\n@router.get(\n    urls.DRP_DATA_RIGHTS,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.POLICY_READ])],\n    response_model=DrpDataRightsResponse,\n)\ndef get_drp_data_rights(*, db: Session = Depends(deps.get_db)) -> DrpDataRightsResponse:\n    \"\"\"\n    Query all policies and determine the list of DRP actions that are attached to existing policies.\n    \"\"\"\n\n    logger.info(\"Fetching available DRP data rights\")\n    actions: List[DrpAction] = [\n        item.drp_action  # type: ignore\n        for item in db.query(Policy.drp_action).filter(Policy.drp_action.isnot(None))\n    ]\n\n    return DrpDataRightsResponse(\n        version=DRP_VERSION, api_base=None, actions=actions, user_relationships=None\n    )\n\n\n@router.post(\n    urls.DRP_REVOKE,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[scopes.PRIVACY_REQUEST_REVIEW])\n    ],\n    response_model=PrivacyRequestDRPStatusResponse,\n)\ndef revoke_request(\n    *, db: Session = Depends(deps.get_db), data: DrpRevokeRequest\n) -> PrivacyRequestDRPStatusResponse:\n    \"\"\"\n    Revoke a pending privacy request.\n    \"\"\"\n    privacy_request: PrivacyRequest = get_privacy_request_or_error(db, data.request_id)\n\n    if privacy_request.status != PrivacyRequestStatus.pending:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"Invalid revoke request. Can only revoke `pending` requests. Privacy request '{privacy_request.id}' status = {privacy_request.status.value}.\",  # type: ignore\n        )\n\n    logger.info(\"Canceling privacy request '%s'\", privacy_request.id)\n    privacy_request.cancel_processing(db, cancel_reason=data.reason)\n\n    return PrivacyRequestDRPStatusResponse(\n        request_id=privacy_request.id,\n        received_at=privacy_request.requested_at,\n        status=DrpFidesopsMapper.map_status(privacy_request.status),  # type: ignore\n        reason=data.reason,\n    )\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/health_endpoints.py", "content": "import logging\nfrom typing import Dict, Optional, Union\n\nfrom alembic import migration, script\nfrom fastapi import Depends\nfrom redis.exceptions import ResponseError\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1.urn_registry import HEALTH\nfrom fidesops.ops.common_exceptions import RedisConnectionError\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.db.database import get_alembic_config\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.cache import get_cache\nfrom fidesops.ops.util.logger import Pii\n\nrouter = APIRouter(tags=[\"Public\"])\n\nlogger = logging.getLogger(__name__)\n# stops polluting logs with sqlalchemy / alembic info-level logs\nlogging.getLogger(\"sqlalchemy.engine\").setLevel(logging.ERROR)\nlogging.getLogger(\"alembic\").setLevel(logging.WARNING)\n\n\n@router.get(HEALTH, response_model=Dict[str, Union[bool, str]])\ndef health_check(\n    db: Session = Depends(deps.get_db_for_health_check),\n) -> Dict[str, Union[bool, str]]:\n    return {\n        \"webserver\": \"healthy\",\n        \"database\": get_db_health(config.database.sqlalchemy_database_uri, db),\n        \"cache\": get_cache_health(),\n    }\n\n\ndef get_db_health(database_url: Optional[str], db: Session) -> str:\n    \"\"\"Checks if the db is reachable and up to date in alembic migrations\"\"\"\n    if not database_url or not config.database.enabled:\n        return \"no db configured\"\n    try:\n        alembic_config = get_alembic_config(database_url)\n        alembic_script_directory = script.ScriptDirectory.from_config(alembic_config)\n        context = migration.MigrationContext.configure(db.connection())\n        if (\n            context.get_current_revision()\n            != alembic_script_directory.get_current_head()\n        ):\n            return \"needs migration\"\n        return \"healthy\"\n    except Exception as error:  # pylint: disable=broad-except\n        logger.error(\"Unable to reach the database: %s\", Pii(str(error)))\n        return \"unhealthy\"\n\n\ndef get_cache_health() -> str:\n    \"\"\"Checks if the cache is reachable\"\"\"\n    if not config.redis.enabled:\n        return \"no cache configured\"\n    try:\n        get_cache()\n        return \"healthy\"\n    except (RedisConnectionError, ResponseError) as e:\n        logger.error(\"Unable to reach cache: %s\", Pii(str(e)))\n        return \"unhealthy\"\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/user_endpoints.py", "content": "import json\nimport logging\nfrom typing import Optional\n\nimport jose.exceptions\nfrom fastapi import Depends, HTTPException, Security\nfrom fideslib.cryptography.cryptographic_util import b64_str_to_str\nfrom fideslib.cryptography.schemas.jwt import JWE_PAYLOAD_CLIENT_ID\nfrom fideslib.exceptions import AuthenticationError\nfrom fideslib.models.client import ClientDetail\nfrom fideslib.models.fides_user import FidesUser\nfrom fideslib.oauth.oauth_util import extract_payload\nfrom fideslib.oauth.schemas.user import UserPasswordReset, UserResponse, UserUpdate\nfrom sqlalchemy.orm import Session\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_204_NO_CONTENT,\n    HTTP_401_UNAUTHORIZED,\n    HTTP_404_NOT_FOUND,\n)\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.deps import get_db\nfrom fidesops.ops.api.v1 import urn_registry as urls\nfrom fidesops.ops.api.v1.scope_registry import (\n    SCOPE_REGISTRY,\n    USER_PASSWORD_RESET,\n    USER_UPDATE,\n)\nfrom fidesops.ops.api.v1.urn_registry import V1_URL_PREFIX\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.oauth_util import (\n    get_current_user,\n    oauth2_scheme,\n    verify_oauth_client,\n)\n\nlogger = logging.getLogger(__name__)\nrouter = APIRouter(tags=[\"Users\"], prefix=V1_URL_PREFIX)\n\n\ndef _validate_current_user(user_id: str, user_from_token: FidesUser) -> None:\n    if not user_from_token:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"User with ID {user_id} does not exist.\",\n        )\n\n    if user_id != user_from_token.id:\n        raise HTTPException(\n            status_code=HTTP_401_UNAUTHORIZED,\n            detail=\"You are only authorised to update your own user data.\",\n        )\n\n\n@router.put(\n    urls.USER_DETAIL,\n    dependencies=[Security(verify_oauth_client, scopes=[USER_UPDATE])],\n    status_code=HTTP_200_OK,\n    response_model=UserResponse,\n)\ndef update_user(\n    *,\n    db: Session = Depends(deps.get_db),\n    user_id: str,\n    data: UserUpdate,\n) -> FidesUser:\n    \"\"\"\n    Update a user given a `user_id`. By default this is limited to users\n    updating their own data.\n    \"\"\"\n    user = FidesUser.get(db=db, object_id=user_id)\n    if not user:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=f\"User with id {user_id} not found.\"\n        )\n\n    user.update(db=db, data=data.dict())\n    logger.info(\"Updated user with id: '%s'.\", user.id)\n    return user\n\n\n@router.post(\n    urls.USER_PASSWORD_RESET,\n    dependencies=[Security(verify_oauth_client, scopes=[USER_PASSWORD_RESET])],\n    status_code=HTTP_200_OK,\n    response_model=UserResponse,\n)\ndef update_user_password(\n    *,\n    db: Session = Depends(deps.get_db),\n    current_user: FidesUser = Depends(get_current_user),\n    user_id: str,\n    data: UserPasswordReset,\n) -> FidesUser:\n    \"\"\"\n    Update a user's password given a `user_id`. By default this is limited to users\n    updating their own data.\n    \"\"\"\n    _validate_current_user(user_id, current_user)\n\n    if not current_user.credentials_valid(\n        b64_str_to_str(data.old_password), config.security.encoding\n    ):\n        raise HTTPException(\n            status_code=HTTP_401_UNAUTHORIZED, detail=\"Incorrect password.\"\n        )\n\n    current_user.update_password(db=db, new_password=b64_str_to_str(data.new_password))\n\n    logger.info(\"Updated user with id: '%s'.\", current_user.id)\n    return current_user\n\n\ndef logout_oauth_client(\n    authorization: str = Security(oauth2_scheme), db: Session = Depends(get_db)\n) -> Optional[ClientDetail]:\n    \"\"\"\n    Streamlined oauth checks for logout.  Only raises an error if no authorization is supplied.\n    Otherwise, regardless if the token is malformed or expired, still return a 204.\n    Returns a client if we can extract one from the token.\n    \"\"\"\n    if authorization is None:\n        raise AuthenticationError(detail=\"Authentication Failure\")\n\n    try:\n        token_data = json.loads(\n            extract_payload(authorization, config.security.app_encryption_key)\n        )\n    except jose.exceptions.JWEParseError:\n        return None\n\n    client_id = token_data.get(JWE_PAYLOAD_CLIENT_ID)\n    if (\n        not client_id or client_id == config.security.oauth_root_client_id\n    ):  # The root client is not a persisted object\n        return None\n\n    client = ClientDetail.get(\n        db, object_id=client_id, config=config, scopes=SCOPE_REGISTRY\n    )\n\n    return client\n\n\n@router.post(\n    urls.LOGOUT,\n    status_code=HTTP_204_NO_CONTENT,\n)\ndef user_logout(\n    *,\n    client: Optional[ClientDetail] = Security(\n        logout_oauth_client,\n    ),\n    db: Session = Depends(deps.get_db),\n) -> None:\n    \"\"\"Logout the user by deleting its client where applicable\"\"\"\n\n    logger.info(\"Logging out user.\")\n    if client:\n        client.delete(db)\n"}
{"type": "source_file", "path": "src/fidesops/main.py", "content": "import asyncio\nimport logging\nimport os\nimport re\nimport subprocess\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Callable, Optional, Union\n\nimport uvicorn\nfrom fastapi import FastAPI, Request, Response\nfrom fastapi.exceptions import HTTPException\nfrom fastapi.responses import FileResponse\nfrom fideslib.oauth.api.deps import get_config as lib_get_config\nfrom fideslib.oauth.api.deps import get_db as lib_get_db\nfrom fideslib.oauth.api.deps import verify_oauth_client as lib_verify_oauth_client\nfrom fideslib.oauth.api.routes.user_endpoints import router as user_router\nfrom fideslog.sdk.python.event import AnalyticsEvent\nfrom redis.exceptions import ResponseError\nfrom starlette.background import BackgroundTask\nfrom starlette.middleware.cors import CORSMiddleware\nfrom starlette.status import HTTP_404_NOT_FOUND\n\nfrom fidesops.ops.analytics import (\n    accessed_through_local_host,\n    in_docker_container,\n    send_analytics_event,\n)\nfrom fidesops.ops.api.deps import get_api_session, get_config, get_db\nfrom fidesops.ops.api.v1.api import api_router\nfrom fidesops.ops.api.v1.exception_handlers import ExceptionHandlers\nfrom fidesops.ops.api.v1.urn_registry import V1_URL_PREFIX\nfrom fidesops.ops.common_exceptions import (\n    FunctionalityNotConfigured,\n    RedisConnectionError,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.db.database import init_db\nfrom fidesops.ops.schemas.analytics import Event, ExtraData\nfrom fidesops.ops.service.connectors.saas.connector_registry_service import (\n    load_registry,\n    registry_file,\n    update_saas_configs,\n)\nfrom fidesops.ops.tasks.scheduled.scheduler import scheduler\nfrom fidesops.ops.tasks.scheduled.tasks import initiate_scheduled_request_intake\nfrom fidesops.ops.util.cache import get_cache\nfrom fidesops.ops.util.logger import Pii, get_fides_log_record_factory\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nlogging.basicConfig(level=config.security.log_level)\nlogging.setLogRecordFactory(get_fides_log_record_factory())\nlogger = logging.getLogger(__name__)\n\napp = FastAPI(title=\"fidesops\", openapi_url=f\"{V1_URL_PREFIX}/openapi.json\")\n\n# Set all CORS enabled origins\nif config.security.cors_origins:\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[str(origin) for origin in config.security.cors_origins],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n\nif not config.root_user.analytics_opt_out:\n\n    @app.middleware(\"http\")\n    async def dispatch_log_request(request: Request, call_next: Callable) -> Response:\n        \"\"\"\n        HTTP Middleware that logs analytics events for each call to Fidesops endpoints.\n        :param request: Request to fidesops api\n        :param call_next: Callable api endpoint\n        :return: Response\n        \"\"\"\n        fides_source: Optional[str] = request.headers.get(\"X-Fides-Source\")\n        now: datetime = datetime.now(tz=timezone.utc)\n        endpoint = f\"{request.method}: {request.url}\"\n\n        try:\n            response = await call_next(request)\n            # HTTPExceptions are considered a handled err by default so are not thrown here.\n            # Accepted workaround is to inspect status code of response.\n            # More context- https://github.com/tiangolo/fastapi/issues/1840\n            response.background = BackgroundTask(\n                prepare_and_log_request,\n                endpoint,\n                request.url.hostname,\n                response.status_code,\n                now,\n                fides_source,\n                \"HTTPException\" if response.status_code >= 400 else None,\n            )\n            return response\n\n        except Exception as e:\n            await prepare_and_log_request(\n                endpoint,\n                request.url.hostname,\n                500,\n                now,\n                fides_source,\n                e.__class__.__name__,\n            )\n            raise\n\n\nasync def prepare_and_log_request(\n    endpoint: str,\n    hostname: Optional[str],\n    status_code: int,\n    event_created_at: datetime,\n    fides_source: Optional[str],\n    error_class: Optional[str],\n) -> None:\n    \"\"\"\n    Prepares and sends analytics event provided the user is not opted out of analytics.\n    \"\"\"\n\n    # this check prevents AnalyticsEvent from being called with invalid endpoint during unit tests\n    if config.root_user.analytics_opt_out:\n        return\n    await send_analytics_event(\n        AnalyticsEvent(\n            docker=in_docker_container(),\n            event=Event.endpoint_call.value,\n            event_created_at=event_created_at,\n            local_host=accessed_through_local_host(hostname),\n            endpoint=endpoint,\n            status_code=status_code,\n            error=error_class or None,\n            extra_data={ExtraData.fides_source.value: fides_source}\n            if fides_source\n            else None,\n        )\n    )\n\n\napp.include_router(api_router)\napp.include_router(user_router, tags=[\"Users\"], prefix=f\"{V1_URL_PREFIX}\")\napp.dependency_overrides[lib_get_config] = get_config\napp.dependency_overrides[lib_get_db] = get_db\napp.dependency_overrides[lib_verify_oauth_client] = verify_oauth_client\n\nfor handler in ExceptionHandlers.get_handlers():\n    app.add_exception_handler(FunctionalityNotConfigured, handler)\n\nWEBAPP_DIRECTORY = Path(\"/admin_ui\")\nWEBAPP_INDEX = WEBAPP_DIRECTORY / \"index.html\"\n\nif config.admin_ui.enabled:\n    route_file_map = {}\n\n    def generate_route_file_map() -> None:\n        \"\"\"Generates a map of frontend routes and the corresponding files to serve for each route.\n        Each route is based frontend build directories and files.\"\"\"\n        exact_pattern = r\"\\[[a-zA-Z]+\\]\"\n        nested_pattern = r\"\\[...[a-zA-Z]+\\]\"\n\n        exact_pattern_replacement = \"[a-zA-Z10-9-_]+/?$\"\n        nested_pattern_replacement = \"[a-zA-Z10-9-_/]+\"\n\n        for filepath in WEBAPP_DIRECTORY.glob(\"**/*.html\"):\n            # Strip off the file extenstion and convert to a string\n            relative_web_dir_path = str(\n                filepath.relative_to(WEBAPP_DIRECTORY).with_suffix(\"\")\n            )\n            if filepath != WEBAPP_INDEX:\n                path = None\n                if re.search(exact_pattern, str(filepath)):\n                    path = re.sub(\n                        exact_pattern, exact_pattern_replacement, relative_web_dir_path\n                    )\n                if re.search(nested_pattern, str(filepath)):\n                    path = re.sub(\n                        nested_pattern,\n                        nested_pattern_replacement,\n                        relative_web_dir_path,\n                    )\n                if path is None:\n                    path = relative_web_dir_path\n\n                rule = re.compile(r\"^\" + path)\n\n                route_file_map[rule] = FileResponse(\n                    f\"{WEBAPP_DIRECTORY}/{str(filepath.relative_to(WEBAPP_DIRECTORY))}\"\n                )\n\n    @app.on_event(\"startup\")\n    def check_if_admin_ui_index_exists() -> None:\n        if not WEBAPP_INDEX.is_file():\n            WEBAPP_DIRECTORY.mkdir(parents=True, exist_ok=True)\n            with open(\n                WEBAPP_DIRECTORY / \"index.html\", \"w\", encoding=\"utf-8\"\n            ) as index_file:\n                heading = \"<h1>No src/fidesops/ops/build/static/index.html found</h1>\"\n                help_message = \"<h2>A docker-compose.yml volume may be overwriting the built in Admin UI files</h2>\"\n                index_file.write(f\"{heading}{help_message}\")\n                logger.info(\n                    \"No Admin UI files are bundled in the docker image. Creating diagnostic help index.html\"\n                )\n\n        generate_route_file_map()\n\n    @app.get(\"/\", response_class=FileResponse)\n    def read_index() -> FileResponse:\n        \"\"\"Returns index.html file\"\"\"\n        return FileResponse(WEBAPP_INDEX)\n\n    def match_route(path: str) -> Union[FileResponse, None]:\n        for key, value in route_file_map.items():\n            if re.fullmatch(key, path):\n                return value\n        return None\n\n    @app.get(\"/{catchall:path}\", response_class=FileResponse)\n    def read_ui_files(request: Request) -> FileResponse:\n        \"\"\"Return requested UI  file or return index.html file if requested file doesn't exist\"\"\"\n        path: str = request.path_params[\"catchall\"]\n        if V1_URL_PREFIX in \"/\" + path:\n            raise HTTPException(status_code=HTTP_404_NOT_FOUND)\n\n        entry_point_html_file = match_route(path)\n        if entry_point_html_file:\n            return entry_point_html_file\n\n        file = WEBAPP_DIRECTORY / path\n        if os.path.exists(file):\n            return FileResponse(file)\n\n        return FileResponse(WEBAPP_DIRECTORY / \"404.html\")\n\n\ndef start_webserver() -> None:\n    \"\"\"Run any pending DB migrations and start the webserver.\"\"\"\n    logger.warning(\n        \"Fidesops has been deprecated. The codebase has merged into the Fides repo. Fides is located at \"\n        \"https://github.com/ethyca/fides. The documentation is located at https://ethyca.github.io/fides.\"\n    )\n    logger.info(\"****************fidesops****************\")\n\n    if logger.getEffectiveLevel() == logging.DEBUG:\n        logger.warning(\n            \"WARNING: log level is DEBUG, so sensitive or personal data may be logged. \"\n            \"Set FIDESOPS__SECURITY__LOG_LEVEL to INFO or higher in production.\"\n        )\n        config.log_all_config_values()\n\n    logger.info(\"Validating SaaS connector templates...\")\n    registry = load_registry(registry_file)\n\n    if config.database.enabled:\n        logger.info(\"Running any pending DB migrations...\")\n        try:\n            init_db(config.database.sqlalchemy_database_uri)\n            db = get_api_session()\n            update_saas_configs(registry, db)\n            db.close()\n        except Exception as error:  # pylint: disable=broad-except\n            logger.error(\"Connection to database failed: %s\", Pii(str(error)))\n            return\n\n    if config.redis.enabled:\n        logger.info(\"Running Redis connection test...\")\n        try:\n            get_cache()\n        except (RedisConnectionError, ResponseError) as e:\n            logger.error(\"Connection to cache failed: %s\", e)\n            return\n\n    scheduler.start()\n\n    if config.database.enabled:\n        logger.info(\"Starting scheduled request intake...\")\n        initiate_scheduled_request_intake()\n\n    asyncio.run(\n        send_analytics_event(\n            AnalyticsEvent(\n                docker=in_docker_container(),\n                event=Event.server_start.value,\n                event_created_at=datetime.now(tz=timezone.utc),\n            )\n        )\n    )\n\n    if not config.execution.worker_enabled:\n        logger.info(\"Starting worker...\")\n        subprocess.Popen([\"fidesops\", \"worker\"])  # pylint: disable=consider-using-with\n\n    logger.info(\"Starting web server...\")\n    uvicorn.run(\n        \"fidesops.main:app\",\n        host=\"0.0.0.0\",\n        port=config.port,\n        log_config=None,\n        reload=config.hot_reloading,\n    )\n\n\nif __name__ == \"__main__\":\n    start_webserver()\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/user_permission_endpoints.py", "content": "import logging\n\nfrom fastapi import Depends, HTTPException, Security\nfrom fideslib.models.fides_user import FidesUser\nfrom fideslib.models.fides_user_permissions import FidesUserPermissions\nfrom sqlalchemy.orm import Session\nfrom starlette.status import HTTP_201_CREATED, HTTP_400_BAD_REQUEST, HTTP_404_NOT_FOUND\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1 import urn_registry as urls\nfrom fidesops.ops.api.v1.scope_registry import (\n    USER_PERMISSION_CREATE,\n    USER_PERMISSION_READ,\n    USER_PERMISSION_UPDATE,\n)\nfrom fidesops.ops.api.v1.urn_registry import V1_URL_PREFIX\nfrom fidesops.ops.schemas.user_permission import (\n    UserPermissionsCreate,\n    UserPermissionsEdit,\n    UserPermissionsResponse,\n)\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nlogger = logging.getLogger(__name__)\nrouter = APIRouter(tags=[\"User Permissions\"], prefix=V1_URL_PREFIX)\n\n\ndef validate_user_id(db: Session, user_id: str) -> FidesUser:\n    user = FidesUser.get_by(db, field=\"id\", value=user_id)\n\n    if not user:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=f\"No user found with id {user_id}.\"\n        )\n    return user\n\n\n@router.post(\n    urls.USER_PERMISSIONS,\n    dependencies=[Security(verify_oauth_client, scopes=[USER_PERMISSION_CREATE])],\n    status_code=HTTP_201_CREATED,\n    response_model=UserPermissionsResponse,\n)\ndef create_user_permissions(\n    *,\n    db: Session = Depends(deps.get_db),\n    user_id: str,\n    permissions: UserPermissionsCreate,\n) -> FidesUserPermissions:\n    user = validate_user_id(db, user_id)\n    if user.permissions is not None:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=\"This user already has permissions set.\",\n        )\n    logger.info(\"Created FidesUserPermission record\")\n    return FidesUserPermissions.create(\n        db=db, data={\"user_id\": user_id, **permissions.dict()}\n    )\n\n\n@router.put(\n    urls.USER_PERMISSIONS,\n    dependencies=[Security(verify_oauth_client, scopes=[USER_PERMISSION_UPDATE])],\n    response_model=UserPermissionsResponse,\n)\ndef update_user_permissions(\n    *,\n    db: Session = Depends(deps.get_db),\n    user_id: str,\n    permissions: UserPermissionsEdit,\n) -> FidesUserPermissions:\n    user = validate_user_id(db, user_id)\n    logger.info(\"Updated FidesUserPermission record\")\n    if user.client:\n        user.client.update(db=db, data={\"scopes\": permissions.scopes})\n    return user.permissions.update(\n        db=db,\n        data={\"id\": user.permissions.id, \"user_id\": user_id, **permissions.dict()},\n    )\n\n\n@router.get(\n    urls.USER_PERMISSIONS,\n    dependencies=[Security(verify_oauth_client, scopes=[USER_PERMISSION_READ])],\n    response_model=UserPermissionsResponse,\n)\ndef get_user_permissions(\n    *, db: Session = Depends(deps.get_db), user_id: str\n) -> FidesUserPermissions:\n    validate_user_id(db, user_id)\n    logger.info(\"Retrieved FidesUserPermission record\")\n    return FidesUserPermissions.get_by(db, field=\"user_id\", value=user_id)\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/scope_registry.py", "content": "CLIENT_CREATE = \"client:create\"\nCLIENT_UPDATE = \"client:update\"\nCLIENT_READ = \"client:read\"\nCLIENT_DELETE = \"client:delete\"\n\nCONFIG_READ = \"config:read\"\n\nPOLICY_CREATE_OR_UPDATE = \"policy:create_or_update\"\nPOLICY_READ = \"policy:read\"\nPOLICY_DELETE = \"policy:delete\"\n\nCONNECTION_TYPE_READ = \"connection_type:read\"\n\nCONNECTION_CREATE_OR_UPDATE = \"connection:create_or_update\"\nCONNECTION_READ = \"connection:read\"\nCONNECTION_DELETE = \"connection:delete\"\nCONNECTION_AUTHORIZE = \"connection:authorize\"\nSAAS_CONNECTION_INSTANTIATE = \"connection:instantiate\"\n\nCONSENT_READ = \"consent:read\"\n\nPRIVACY_REQUEST_READ = \"privacy-request:read\"\nPRIVACY_REQUEST_DELETE = \"privacy-request:delete\"\nPRIVACY_REQUEST_CALLBACK_RESUME = (\n    \"privacy-request:resume\"  # User has permission to resume a privacy request\n)\nPRIVACY_REQUEST_REVIEW = \"privacy-request:review\"\nPRIVACY_REQUEST_UPLOAD_DATA = \"privacy-request:upload_data\"\nPRIVACY_REQUEST_VIEW_DATA = \"privacy-request:view_data\"\n\nWEBHOOK_CREATE_OR_UPDATE = \"webhook:create_or_update\"\nWEBHOOK_READ = \"webhook:read\"\nWEBHOOK_DELETE = \"webhook:delete\"\n\nRULE_CREATE_OR_UPDATE = \"rule:create_or_update\"\nRULE_READ = \"rule:read\"\nRULE_DELETE = \"rule:delete\"\n\nSTORAGE_CREATE_OR_UPDATE = \"storage:create_or_update\"\nSTORAGE_READ = \"storage:read\"\nSTORAGE_DELETE = \"storage:delete\"\n\nEMAIL_CREATE_OR_UPDATE = \"email:create_or_update\"\nEMAIL_READ = \"email:read\"\nEMAIL_DELETE = \"email:delete\"\n\nSCOPE_READ = \"scope:read\"\n\nENCRYPTION_EXEC = \"encryption:exec\"\n\nDATASET_CREATE_OR_UPDATE = \"dataset:create_or_update\"\nDATASET_READ = \"dataset:read\"\nDATASET_DELETE = \"dataset:delete\"\n\nSAAS_CONFIG_CREATE_OR_UPDATE = \"saas_config:create_or_update\"\nSAAS_CONFIG_READ = \"saas_config:read\"\nSAAS_CONFIG_DELETE = \"saas_config:delete\"\n\nUSER_CREATE = \"user:create\"\nUSER_UPDATE = \"user:update\"\nUSER_READ = \"user:read\"\nUSER_DELETE = \"user:delete\"\nUSER_PASSWORD_RESET = \"user:reset-password\"\n\nUSER_PERMISSION_CREATE = \"user-permission:create\"\nUSER_PERMISSION_UPDATE = \"user-permission:update\"\nUSER_PERMISSION_READ = \"user-permission:read\"\n\nSCOPE_REGISTRY = [\n    CLIENT_CREATE,\n    CLIENT_UPDATE,\n    CLIENT_READ,\n    CLIENT_DELETE,\n    CONFIG_READ,\n    CONNECTION_READ,\n    CONNECTION_CREATE_OR_UPDATE,\n    CONNECTION_DELETE,\n    CONNECTION_AUTHORIZE,\n    SAAS_CONNECTION_INSTANTIATE,\n    CONSENT_READ,\n    CONNECTION_TYPE_READ,\n    DATASET_CREATE_OR_UPDATE,\n    DATASET_DELETE,\n    DATASET_READ,\n    ENCRYPTION_EXEC,\n    POLICY_CREATE_OR_UPDATE,\n    POLICY_READ,\n    POLICY_DELETE,\n    PRIVACY_REQUEST_REVIEW,\n    PRIVACY_REQUEST_READ,\n    PRIVACY_REQUEST_DELETE,\n    PRIVACY_REQUEST_CALLBACK_RESUME,\n    PRIVACY_REQUEST_UPLOAD_DATA,\n    PRIVACY_REQUEST_VIEW_DATA,\n    RULE_CREATE_OR_UPDATE,\n    RULE_READ,\n    RULE_DELETE,\n    SCOPE_READ,\n    STORAGE_CREATE_OR_UPDATE,\n    STORAGE_DELETE,\n    STORAGE_READ,\n    EMAIL_CREATE_OR_UPDATE,\n    EMAIL_DELETE,\n    EMAIL_READ,\n    WEBHOOK_CREATE_OR_UPDATE,\n    WEBHOOK_READ,\n    WEBHOOK_DELETE,\n    SAAS_CONFIG_CREATE_OR_UPDATE,\n    SAAS_CONFIG_READ,\n    SAAS_CONFIG_DELETE,\n    USER_CREATE,\n    USER_UPDATE,\n    USER_READ,\n    USER_PASSWORD_RESET,\n    USER_DELETE,\n    USER_PERMISSION_CREATE,\n    USER_PERMISSION_UPDATE,\n    USER_PERMISSION_READ,\n]\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/saas_config_endpoints.py", "content": "import logging\nfrom typing import Optional\n\nfrom fastapi import Depends, HTTPException\nfrom fastapi.params import Security\nfrom fideslib.exceptions import KeyOrNameAlreadyExists\nfrom sqlalchemy.orm import Session\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_204_NO_CONTENT,\n    HTTP_400_BAD_REQUEST,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n    HTTP_500_INTERNAL_SERVER_ERROR,\n)\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1.endpoints.connection_endpoints import validate_secrets\nfrom fidesops.ops.api.v1.scope_registry import (\n    CONNECTION_AUTHORIZE,\n    SAAS_CONFIG_CREATE_OR_UPDATE,\n    SAAS_CONFIG_DELETE,\n    SAAS_CONFIG_READ,\n    SAAS_CONNECTION_INSTANTIATE,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    AUTHORIZE,\n    CONNECTION_TYPES,\n    SAAS_CONFIG,\n    SAAS_CONFIG_VALIDATE,\n    SAAS_CONNECTOR_FROM_TEMPLATE,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.common_exceptions import FidesopsException\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig, ConnectionType\nfrom fidesops.ops.models.datasetconfig import DatasetConfig\nfrom fidesops.ops.schemas.connection_configuration.connection_config import (\n    SaasConnectionTemplateResponse,\n    SaasConnectionTemplateValues,\n)\nfrom fidesops.ops.schemas.saas.saas_config import (\n    SaaSConfig,\n    SaaSConfigValidationDetails,\n    ValidateSaaSConfigResponse,\n)\nfrom fidesops.ops.schemas.shared_schemas import FidesOpsKey\nfrom fidesops.ops.service.authentication.authentication_strategy import (\n    AuthenticationStrategy,\n)\nfrom fidesops.ops.service.authentication.authentication_strategy_oauth2_authorization_code import (\n    OAuth2AuthorizationCodeAuthenticationStrategy,\n)\nfrom fidesops.ops.service.connectors.saas.connector_registry_service import (\n    ConnectorRegistry,\n    ConnectorTemplate,\n    create_connection_config_from_template_no_save,\n    load_registry,\n    registry_file,\n    upsert_dataset_config_from_template,\n)\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"SaaS Configs\"], prefix=V1_URL_PREFIX)\nlogger = logging.getLogger(__name__)\n\n# Helper method to inject the parent ConnectionConfig into these child routes\ndef _get_saas_connection_config(\n    connection_key: FidesOpsKey, db: Session = Depends(deps.get_db)\n) -> ConnectionConfig:\n    logger.info(\"Finding connection config with key '%s'\", connection_key)\n    connection_config = ConnectionConfig.get_by(db, field=\"key\", value=connection_key)\n    if not connection_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No connection config with key '{connection_key}'\",\n        )\n    if connection_config.connection_type != ConnectionType.saas:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=\"This action is only applicable to connection configs of connection type 'saas'\",\n        )\n    return connection_config\n\n\ndef verify_oauth_connection_config(\n    connection_config: Optional[ConnectionConfig],\n) -> None:\n    \"\"\"\n    Verifies that the connection config is present and contains\n    the necessary configurations for OAuth2 Authorization Code authentication.\n    Returns an HTTPException with the appropriate error message indicating\n    which configurations are missing or incorrect.\n    \"\"\"\n\n    if not connection_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=\"The connection config cannot be found.\",\n        )\n\n    saas_config = connection_config.get_saas_config()\n    if not saas_config:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=\"The connection config does not contain a SaaS config.\",\n        )\n\n    authentication = saas_config.client_config.authentication\n    if not authentication:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=\"The connection config does not contain an authentication configuration.\",\n        )\n\n    if authentication.strategy != OAuth2AuthorizationCodeAuthenticationStrategy.name:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=\"The connection config does not use OAuth2 Authorization Code authentication.\",\n        )\n\n\n@router.put(\n    SAAS_CONFIG_VALIDATE,\n    dependencies=[Security(verify_oauth_client, scopes=[SAAS_CONFIG_READ])],\n    status_code=HTTP_200_OK,\n    response_model=ValidateSaaSConfigResponse,\n)\ndef validate_saas_config(\n    saas_config: SaaSConfig,\n) -> ValidateSaaSConfigResponse:\n    \"\"\"\n    Uses the SaaSConfig Pydantic model to validate the SaaS config\n    without attempting to save it to the database.\n\n    Checks that:\n    - all required fields are present, all field values are valid types\n    - each connector_param only has one of references or identity, not both\n    \"\"\"\n\n    logger.info(\"Validation successful for SaaS config '%s'\", saas_config.fides_key)\n    return ValidateSaaSConfigResponse(\n        saas_config=saas_config,\n        validation_details=SaaSConfigValidationDetails(\n            msg=\"Validation successful\",\n        ),\n    )\n\n\n@router.patch(\n    SAAS_CONFIG,\n    dependencies=[Security(verify_oauth_client, scopes=[SAAS_CONFIG_CREATE_OR_UPDATE])],\n    status_code=HTTP_200_OK,\n    response_model=SaaSConfig,\n)\ndef patch_saas_config(\n    saas_config: SaaSConfig,\n    db: Session = Depends(deps.get_db),\n    connection_config: ConnectionConfig = Depends(_get_saas_connection_config),\n) -> SaaSConfig:\n    \"\"\"\n    Given a SaaS config element, update the corresponding ConnectionConfig object\n    or report failure\n    \"\"\"\n    logger.info(\n        \"Updating SaaS config '%s' on connection config '%s'\",\n        saas_config.fides_key,\n        connection_config.key,\n    )\n    connection_config.update_saas_config(db, saas_config=saas_config)\n    return connection_config.saas_config  # type: ignore\n\n\n@router.get(\n    SAAS_CONFIG,\n    dependencies=[Security(verify_oauth_client, scopes=[SAAS_CONFIG_READ])],\n    response_model=SaaSConfig,\n)\ndef get_saas_config(\n    connection_config: ConnectionConfig = Depends(_get_saas_connection_config),\n) -> SaaSConfig:\n    \"\"\"Returns the SaaS config for the given connection config.\"\"\"\n\n    logger.info(\"Finding SaaS config for connection '%s'\", connection_config.key)\n    saas_config = connection_config.saas_config\n    if not saas_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No SaaS config found for connection '{connection_config.key}'\",\n        )\n    return saas_config\n\n\n@router.delete(\n    SAAS_CONFIG,\n    dependencies=[Security(verify_oauth_client, scopes=[SAAS_CONFIG_DELETE])],\n    status_code=HTTP_204_NO_CONTENT,\n)\ndef delete_saas_config(\n    db: Session = Depends(deps.get_db),\n    connection_config: ConnectionConfig = Depends(_get_saas_connection_config),\n) -> None:\n    \"\"\"Removes the SaaS config for the given connection config.\n    The corresponding dataset and secrets must be deleted before deleting the SaaS config\"\"\"\n\n    logger.info(\"Finding SaaS config for connection '%s'\", connection_config.key)\n    saas_config = connection_config.saas_config\n    if not saas_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No SaaS config found for connection '{connection_config.key}'\",\n        )\n\n    fides_key = saas_config.get(\"fides_key\")\n    dataset = DatasetConfig.filter(\n        db=db,\n        conditions=(\n            (DatasetConfig.connection_config_id == connection_config.id)\n            & (DatasetConfig.fides_key == fides_key)\n        ),\n    ).first()\n\n    warnings = []\n\n    if not fides_key:\n        warnings.append(\"A fides_key was not found for this SaaS config.\")\n\n    if dataset:\n        warnings.append(\n            f\"Must delete the dataset with fides_key '{fides_key}' before deleting this SaaS config.\"\n        )\n\n    # The secrets must be cleared since the SaaS config is used for validation and the secrets\n    # might not pass validation once a new SaaS config is added.\n    if connection_config.secrets:\n        warnings.append(\n            \"Must clear the secrets from this connection config before deleting the SaaS config.\"\n        )\n\n    if warnings:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=\" \".join(warnings))\n\n    logger.info(\"Deleting SaaS config for connection '%s'\", connection_config.key)\n    connection_config.update(db, data={\"saas_config\": None})\n\n\n@router.get(\n    AUTHORIZE,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_AUTHORIZE])],\n    response_model=str,\n)\ndef authorize_connection(\n    db: Session = Depends(deps.get_db),\n    connection_config: ConnectionConfig = Depends(_get_saas_connection_config),\n) -> Optional[str]:\n    \"\"\"Returns the authorization URL for the SaaS Connector (if available)\"\"\"\n\n    verify_oauth_connection_config(connection_config)\n    authentication = connection_config.get_saas_config().client_config.authentication  # type: ignore\n\n    try:\n        auth_strategy: OAuth2AuthorizationCodeAuthenticationStrategy = AuthenticationStrategy.get_strategy(\n            authentication.strategy, authentication.configuration  # type: ignore\n        )\n        return auth_strategy.get_authorization_url(db, connection_config)\n    except FidesopsException as exc:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=str(exc))\n\n\n@router.post(\n    SAAS_CONNECTOR_FROM_TEMPLATE,\n    dependencies=[Security(verify_oauth_client, scopes=[SAAS_CONNECTION_INSTANTIATE])],\n    response_model=SaasConnectionTemplateResponse,\n)\ndef instantiate_connection_from_template(\n    saas_connector_type: str,\n    template_values: SaasConnectionTemplateValues,\n    db: Session = Depends(deps.get_db),\n) -> SaasConnectionTemplateResponse:\n    \"\"\"\n    Creates a SaaS Connector and a SaaS Dataset from a template.\n\n    Looks up the connector type in the SaaS connector registry and, if all required\n    fields are provided, persists the associated connection config and dataset to the database.\n    \"\"\"\n\n    registry: ConnectorRegistry = load_registry(registry_file)\n    connector_template: Optional[ConnectorTemplate] = registry.get_connector_template(\n        saas_connector_type\n    )\n    if not connector_template:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"SaaS connector type '{saas_connector_type}' is not yet available in Fidesops. For a list of available SaaS connectors, refer to {CONNECTION_TYPES}.\",\n        )\n\n    if DatasetConfig.filter(\n        db=db,\n        conditions=(DatasetConfig.fides_key == template_values.instance_key),\n    ).count():\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=f\"SaaS connector instance key '{template_values.instance_key}' already exists.\",\n        )\n\n    try:\n        connection_config: ConnectionConfig = (\n            create_connection_config_from_template_no_save(\n                db, connector_template, template_values\n            )\n        )\n    except KeyOrNameAlreadyExists as exc:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=exc.args[0],\n        )\n\n    connection_config.secrets = validate_secrets(\n        template_values.secrets, connection_config\n    ).dict()\n    connection_config.save(db=db)  # Not persisted to db until secrets are validated\n\n    try:\n        dataset_config: DatasetConfig = upsert_dataset_config_from_template(\n            db, connection_config, connector_template, template_values\n        )\n    except Exception:\n        connection_config.delete(db)\n        raise HTTPException(\n            status_code=HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"SaaS Connector could not be created from the '{saas_connector_type}' template at this time.\",\n        )\n    logger.info(\n        \"SaaS Connector and Dataset %s successfully created from '%s' template.\",\n        template_values.instance_key,\n        saas_connector_type,\n    )\n    return SaasConnectionTemplateResponse(\n        connection=connection_config, dataset=dataset_config.dataset\n    )\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/storage_endpoints.py", "content": "import logging\nfrom typing import Dict, List, Optional\n\nfrom fastapi import Body, Depends, Security\nfrom fastapi_pagination import Page, Params\nfrom fastapi_pagination.bases import AbstractPage\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom fideslib.exceptions import KeyOrNameAlreadyExists\nfrom pydantic import conlist\nfrom requests import RequestException\nfrom sqlalchemy.orm import Session\nfrom starlette.exceptions import HTTPException\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_201_CREATED,\n    HTTP_204_NO_CONTENT,\n    HTTP_400_BAD_REQUEST,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1.scope_registry import (\n    STORAGE_CREATE_OR_UPDATE,\n    STORAGE_DELETE,\n    STORAGE_READ,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    STORAGE_BY_KEY,\n    STORAGE_CONFIG,\n    STORAGE_SECRETS,\n    STORAGE_UPLOAD,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.common_exceptions import StorageUploadError\nfrom fidesops.ops.models.connectionconfig import ConnectionTestStatus\nfrom fidesops.ops.models.privacy_request import PrivacyRequest\nfrom fidesops.ops.models.storage import StorageConfig, get_schema_for_secrets\nfrom fidesops.ops.schemas.api import BulkUpdateFailed\nfrom fidesops.ops.schemas.connection_configuration.connection_secrets import (\n    TestStatusMessage,\n)\nfrom fidesops.ops.schemas.shared_schemas import FidesOpsKey\nfrom fidesops.ops.schemas.storage.data_upload_location_response import DataUpload\nfrom fidesops.ops.schemas.storage.storage import (\n    BulkPutStorageConfigResponse,\n    StorageDestination,\n    StorageDestinationResponse,\n)\nfrom fidesops.ops.schemas.storage.storage_secrets_docs_only import (\n    possible_storage_secrets,\n)\nfrom fidesops.ops.service.storage.storage_authenticator_service import secrets_are_valid\nfrom fidesops.ops.service.storage.storage_uploader_service import upload\nfrom fidesops.ops.tasks.scheduled.tasks import initiate_scheduled_request_intake\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.logger import Pii\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"Storage\"], prefix=V1_URL_PREFIX)\nlogger = logging.getLogger(__name__)\n\n\n@router.post(\n    STORAGE_UPLOAD,\n    status_code=HTTP_201_CREATED,\n    dependencies=[Security(verify_oauth_client, scopes=[STORAGE_CREATE_OR_UPDATE])],\n    response_model=DataUpload,\n)\ndef upload_data(\n    request_id: str,\n    *,\n    db: Session = Depends(deps.get_db),\n    data: Dict = Body(...),\n    storage_key: FidesOpsKey = Body(...),\n) -> DataUpload:\n    \"\"\"\n    Uploads data from an access request to specified storage destination.\n    Returns location of data.\n    \"\"\"\n    logger.info(\"Finding privacy request with id '%s'\", request_id)\n\n    privacy_request = PrivacyRequest.get(db, object_id=request_id)\n    if not privacy_request:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No privacy with id {request_id}.\",\n        )\n\n    logger.info(\"Starting storage upload for request id: %s\", request_id)\n    try:\n        data_location: str = upload(\n            db, request_id=request_id, data=data, storage_key=storage_key\n        )\n    except StorageUploadError as e:\n        raise HTTPException(status_code=HTTP_404_NOT_FOUND, detail=str(e))\n    except RequestException as e:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=str(e))\n    return DataUpload(location=data_location)\n\n\n@router.patch(\n    STORAGE_CONFIG,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[STORAGE_CREATE_OR_UPDATE])],\n    response_model=BulkPutStorageConfigResponse,\n)\ndef patch_config(\n    *,\n    db: Session = Depends(deps.get_db),\n    storage_configs: conlist(StorageDestination, max_items=50),  # type: ignore\n) -> BulkPutStorageConfigResponse:\n    \"\"\"\n    Given a list of storage destination elements, create or update corresponding StorageConfig objects\n    or report failure.\n    \"\"\"\n    created_or_updated: List[StorageConfig] = []\n    failed: List[BulkUpdateFailed] = []\n\n    logger.info(\"Starting bulk upsert for %s storage configs\", len(storage_configs))\n    for destination in storage_configs:\n        try:\n            storage_config = StorageConfig.create_or_update(\n                db=db, data=destination.dict()\n            )\n        except KeyOrNameAlreadyExists as exc:\n            logger.warning(\n                \"Create/update failed for storage config %s: %s\",\n                destination.key,\n                exc,\n            )\n            failure = {\n                \"message\": exc.args[0],\n                \"data\": destination.dict(),\n            }\n            failed.append(BulkUpdateFailed(**failure))\n            continue\n        except Exception as exc:\n            logger.warning(\n                \"Create/update failed for storage config %s: %s\",\n                destination.key,\n                Pii(str(exc)),\n            )\n            failed.append(\n                BulkUpdateFailed(\n                    **{\n                        \"message\": \"Error creating or updating storage config.\",\n                        \"data\": destination.dict(),\n                    }\n                )\n            )\n        else:\n            created_or_updated.append(storage_config)\n\n    if created_or_updated:\n        initiate_scheduled_request_intake()\n\n    return BulkPutStorageConfigResponse(succeeded=created_or_updated, failed=failed)\n\n\n@router.put(\n    STORAGE_SECRETS,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[STORAGE_CREATE_OR_UPDATE])],\n    response_model=TestStatusMessage,\n)\ndef put_config_secrets(\n    config_key: FidesOpsKey,\n    *,\n    db: Session = Depends(deps.get_db),\n    unvalidated_storage_secrets: possible_storage_secrets,\n    verify: Optional[bool] = True,\n) -> TestStatusMessage:\n    \"\"\"\n    Add or update secrets for storage config.\n    \"\"\"\n    logger.info(\"Finding storage config with key '%s'\", config_key)\n    storage_config = StorageConfig.get_by(db=db, field=\"key\", value=config_key)\n    if not storage_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No storage configuration with key {config_key}.\",\n        )\n\n    try:\n        secrets_schema = get_schema_for_secrets(\n            storage_type=storage_config.type,\n            secrets=unvalidated_storage_secrets,\n        )\n    except KeyError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=exc.args[0],\n        )\n    except ValueError as exc:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=exc.args[0],\n        )\n\n    logger.info(\"Updating storage config secrets for config with key '%s'\", config_key)\n    try:\n        storage_config.set_secrets(db=db, storage_secrets=secrets_schema.dict())\n    except ValueError as exc:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=exc.args[0],\n        )\n\n    msg = f\"Secrets updated for StorageConfig with key: {config_key}.\"\n    if verify:\n        status = secrets_are_valid(secrets_schema, storage_config.type)\n        if status:\n            logger.info(\n                \"Storage secrets are valid for config with key '%s'\", config_key\n            )\n        else:\n            logger.warning(\n                \"Storage secrets are invalid for config with key '%s'\", config_key\n            )\n\n        return TestStatusMessage(\n            msg=msg,\n            test_status=ConnectionTestStatus.succeeded\n            if status\n            else ConnectionTestStatus.failed,\n        )\n\n    return TestStatusMessage(msg=msg, test_status=None)\n\n\n@router.get(\n    STORAGE_CONFIG,\n    dependencies=[Security(verify_oauth_client, scopes=[STORAGE_READ])],\n    response_model=Page[StorageDestinationResponse],\n)\ndef get_configs(\n    *, db: Session = Depends(deps.get_db), params: Params = Depends()\n) -> AbstractPage[StorageConfig]:\n    \"\"\"\n    Retrieves configs for storage.\n    \"\"\"\n    logger.info(\"Finding all storage configurations with pagination params %s\", params)\n    return paginate(\n        StorageConfig.query(db).order_by(StorageConfig.created_at.desc()), params=params\n    )\n\n\n@router.get(\n    STORAGE_BY_KEY,\n    dependencies=[Security(verify_oauth_client, scopes=[STORAGE_READ])],\n    response_model=StorageDestinationResponse,\n)\ndef get_config_by_key(\n    config_key: FidesOpsKey, *, db: Session = Depends(deps.get_db)\n) -> Optional[StorageConfig]:\n    \"\"\"\n    Retrieves configs for storage by key.\n    \"\"\"\n    logger.info(\"Finding storage config with key '%s'\", config_key)\n\n    storage_config = StorageConfig.get_by(db, field=\"key\", value=config_key)\n    if not storage_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No configuration with key {config_key}.\",\n        )\n    return storage_config\n\n\n@router.delete(\n    STORAGE_BY_KEY,\n    status_code=HTTP_204_NO_CONTENT,\n    dependencies=[Security(verify_oauth_client, scopes=[STORAGE_DELETE])],\n)\ndef delete_config_by_key(\n    config_key: FidesOpsKey, *, db: Session = Depends(deps.get_db)\n) -> None:\n    \"\"\"\n    Deletes configs by key.\n    \"\"\"\n    logger.info(\"Finding storage config with key '%s'\", config_key)\n\n    storage_config = StorageConfig.get_by(db, field=\"key\", value=config_key)\n    if not storage_config:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No configuration with key {config_key}.\",\n        )\n\n    logger.info(\"Deleting storage config with key '%s'\", config_key)\n    storage_config.delete(db)\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/__init__.py", "content": ""}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/masking_endpoints.py", "content": "import logging\nfrom typing import Any, List\n\nfrom fastapi import HTTPException\nfrom starlette.status import HTTP_400_BAD_REQUEST, HTTP_404_NOT_FOUND\n\nfrom fidesops.ops.api.v1.urn_registry import MASKING, MASKING_STRATEGY, V1_URL_PREFIX\nfrom fidesops.ops.common_exceptions import NoSuchStrategyException, ValidationError\nfrom fidesops.ops.schemas.masking.masking_api import (\n    MaskingAPIRequest,\n    MaskingAPIResponse,\n)\nfrom fidesops.ops.schemas.masking.masking_strategy_description import (\n    MaskingStrategyDescription,\n)\nfrom fidesops.ops.schemas.policy import PolicyMaskingSpec\nfrom fidesops.ops.service.masking.strategy.masking_strategy import MaskingStrategy\nfrom fidesops.ops.util.api_router import APIRouter\n\nrouter = APIRouter(tags=[\"Masking\"], prefix=V1_URL_PREFIX)\n\nlogger = logging.getLogger(__name__)\n\n\n@router.put(MASKING, response_model=MaskingAPIResponse)\ndef mask_value(request: MaskingAPIRequest) -> MaskingAPIResponse:\n    \"\"\"Masks the value(s) provided using the provided masking strategies\n\n    Each masking strategy supplied will be run on all the values in sequence.  The masked values\n    from one masking strategy will be passed into the next masking strategy.\n\n    \"\"\"\n    try:\n        values: List[Any] = request.values\n        masked_values: List[Any] = request.values.copy()\n        masking_strategies: List[PolicyMaskingSpec] = request.masking_strategies\n\n        num_strat: int = len(masking_strategies)\n\n        if num_strat > 1:\n            logger.info(\n                \"%s masking strategies requested; running in order.\",\n                num_strat,\n            )\n\n        for strategy in masking_strategies:\n            masking_strategy = MaskingStrategy.get_strategy(\n                strategy.strategy, strategy.configuration\n            )\n            logger.info(\n                \"Starting masking of %s value(s) with strategy %s\",\n                len(values),\n                strategy.strategy,\n            )\n            masked_values = masking_strategy.mask(  # type: ignore\n                masked_values, None\n            )  # passing in masked values from previous strategy\n\n        return MaskingAPIResponse(plain=values, masked_values=masked_values)\n    except NoSuchStrategyException as e:\n        raise HTTPException(status_code=HTTP_404_NOT_FOUND, detail=str(e))\n    except ValidationError as e:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=str(e))\n    except ValueError as e:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=str(e))\n\n\n@router.get(MASKING_STRATEGY, response_model=List[MaskingStrategyDescription])\ndef list_masking_strategies() -> List[MaskingStrategyDescription]:\n    \"\"\"Lists available masking strategies with instructions on how to use them\"\"\"\n    logger.info(\"Getting available masking strategies\")\n    return [strategy.get_description() for strategy in MaskingStrategy.get_strategies()]\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/connection_type_endpoints.py", "content": "import logging\nfrom typing import Any, Dict, List, Optional\n\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom fastapi.params import Security\nfrom fastapi_pagination import Page, Params, paginate\nfrom fastapi_pagination.bases import AbstractPage\nfrom starlette.status import HTTP_404_NOT_FOUND\n\nfrom fidesops.ops.api.v1.scope_registry import CONNECTION_TYPE_READ\nfrom fidesops.ops.api.v1.urn_registry import (\n    CONNECTION_TYPE_SECRETS,\n    CONNECTION_TYPES,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.models.connectionconfig import ConnectionType\nfrom fidesops.ops.schemas.connection_configuration import (\n    SaaSSchemaFactory,\n    secrets_validators,\n)\nfrom fidesops.ops.schemas.connection_configuration.connection_config import (\n    ConnectionSystemTypeMap,\n    SystemType,\n)\nfrom fidesops.ops.schemas.saas.saas_config import SaaSConfig, SaaSType\nfrom fidesops.ops.service.connectors.saas.connector_registry_service import (\n    ConnectorRegistry,\n    load_registry,\n    registry_file,\n)\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\nfrom fidesops.ops.util.saas_util import load_config\n\nrouter = APIRouter(tags=[\"Connection Types\"], prefix=V1_URL_PREFIX)\n\nlogger = logging.getLogger(__name__)\n\n\ndef get_connection_types(\n    search: Optional[str] = None, system_type: Optional[SystemType] = None\n) -> List[ConnectionSystemTypeMap]:\n    def is_match(elem: str) -> bool:\n        \"\"\"If a search query param was included, is it a substring of an available connector type?\"\"\"\n        return search.lower() in elem.lower() if search else True\n\n    connection_system_types: List[ConnectionSystemTypeMap] = []\n    if system_type == SystemType.database or system_type is None:\n        database_types: List[str] = sorted(\n            [\n                conn_type.value\n                for conn_type in ConnectionType\n                if conn_type\n                not in [\n                    ConnectionType.saas,\n                    ConnectionType.https,\n                    ConnectionType.manual,\n                    ConnectionType.email,\n                    ConnectionType.manual_webhook,\n                ]\n                and is_match(conn_type.value)\n            ]\n        )\n        connection_system_types.extend(\n            [\n                ConnectionSystemTypeMap(\n                    identifier=item,\n                    type=SystemType.database,\n                    human_readable=ConnectionType(item).human_readable,\n                )\n                for item in database_types\n            ]\n        )\n    if system_type == SystemType.saas or system_type is None:\n        saas_types: List[str] = sorted(\n            [\n                saas_type.value\n                for saas_type in SaaSType\n                if saas_type != SaaSType.custom and is_match(saas_type.value)\n            ]\n        )\n        registry: ConnectorRegistry = load_registry(registry_file)\n\n        for item in saas_types:\n            human_readable_name: str = item\n            if registry.get_connector_template(item) is not None:\n                human_readable_name = registry.get_connector_template(  # type: ignore[union-attr]\n                    item\n                ).human_readable\n\n            connection_system_types.append(\n                ConnectionSystemTypeMap(\n                    identifier=item,\n                    type=SystemType.saas,\n                    human_readable=human_readable_name,\n                )\n            )\n\n    if system_type == SystemType.manual or system_type is None:\n        manual_types: List[str] = sorted(\n            [\n                manual_type.value\n                for manual_type in ConnectionType\n                if manual_type == ConnectionType.manual_webhook\n                and is_match(manual_type.value)\n            ]\n        )\n        connection_system_types.extend(\n            [\n                ConnectionSystemTypeMap(\n                    identifier=item,\n                    type=SystemType.manual,\n                    human_readable=ConnectionType(item).human_readable,\n                )\n                for item in manual_types\n            ]\n        )\n\n    return connection_system_types\n\n\n@router.get(\n    CONNECTION_TYPES,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_TYPE_READ])],\n    response_model=Page[ConnectionSystemTypeMap],\n)\ndef get_all_connection_types(\n    *,\n    params: Params = Depends(),\n    search: Optional[str] = None,\n    system_type: Optional[SystemType] = None,\n) -> AbstractPage[ConnectionSystemTypeMap]:\n    \"\"\"Returns a list of connection options in Fidesops - includes only database and saas options here.\"\"\"\n\n    return paginate(\n        get_connection_types(search, system_type),\n        params,\n    )\n\n\n@router.get(\n    CONNECTION_TYPE_SECRETS,\n    dependencies=[Security(verify_oauth_client, scopes=[CONNECTION_TYPE_READ])],\n)\ndef get_connection_type_secret_schema(\n    *, connection_type: str\n) -> Optional[Dict[str, Any]]:\n    \"\"\"Returns the secret fields that should be supplied to authenticate with a particular connection type\n\n    Note that this endpoint should never return actual secrets, we return the *types* of secret fields needed\n    to authenticate.\n    \"\"\"\n    connection_system_types: List[ConnectionSystemTypeMap] = get_connection_types()\n    if not any(item.identifier == connection_type for item in connection_system_types):\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No connection type found with name '{connection_type}'.\",\n        )\n\n    if connection_type in [db_type.value for db_type in ConnectionType]:\n        return secrets_validators[connection_type].schema()\n\n    config: SaaSConfig = SaaSConfig(\n        **load_config(f\"data/saas/config/{connection_type}_config.yml\")\n    )\n    return SaaSSchemaFactory(config).get_saas_schema().schema()\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/oauth_endpoints.py", "content": "import logging\nfrom typing import List\n\nfrom fastapi import Body, Depends, HTTPException, Request, Security\nfrom fastapi.security import HTTPBasic\nfrom fideslib.models.client import ClientDetail\nfrom fideslib.oauth.schemas.oauth import AccessToken, OAuth2ClientCredentialsRequestForm\nfrom sqlalchemy.orm import Session\nfrom starlette.status import (\n    HTTP_400_BAD_REQUEST,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\nfrom fidesops.ops.api.deps import get_db\nfrom fidesops.ops.api.v1.endpoints.saas_config_endpoints import (\n    verify_oauth_connection_config,\n)\nfrom fidesops.ops.api.v1.scope_registry import (\n    CLIENT_CREATE,\n    CLIENT_DELETE,\n    CLIENT_READ,\n    CLIENT_UPDATE,\n    SCOPE_READ,\n    SCOPE_REGISTRY,\n)\nfrom fidesops.ops.api.v1.urn_registry import (\n    CLIENT,\n    CLIENT_BY_ID,\n    CLIENT_SCOPE,\n    OAUTH_CALLBACK,\n    SCOPE,\n    TOKEN,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.common_exceptions import (\n    AuthenticationFailure,\n    FidesopsException,\n    OAuth2TokenException,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.authentication_request import AuthenticationRequest\nfrom fidesops.ops.models.connectionconfig import ConnectionConfig\nfrom fidesops.ops.schemas.client import ClientCreatedResponse\nfrom fidesops.ops.service.authentication.authentication_strategy import (\n    AuthenticationStrategy,\n)\nfrom fidesops.ops.service.authentication.authentication_strategy_oauth2_authorization_code import (\n    OAuth2AuthorizationCodeAuthenticationStrategy,\n)\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"OAuth\"], prefix=V1_URL_PREFIX)\n\nlogger = logging.getLogger(__name__)\n\n\n@router.post(\n    TOKEN,\n    response_model=AccessToken,\n)\nasync def acquire_access_token(\n    request: Request,\n    form_data: OAuth2ClientCredentialsRequestForm = Depends(),\n    db: Session = Depends(get_db),\n) -> AccessToken:\n    \"\"\"Returns an access token if given credentials are correct, raises 401\n    exception if not\"\"\"\n\n    basic_credentials = await HTTPBasic(auto_error=False)(request)\n\n    if form_data.client_id and form_data.client_secret:\n        client_id = form_data.client_id\n        client_secret = form_data.client_secret\n    elif basic_credentials:\n        client_id = basic_credentials.username\n        client_secret = basic_credentials.password\n    else:\n        raise AuthenticationFailure(detail=\"Authentication Failure\")\n\n    # scopes param is only used if client is root client, otherwise we use the client's associated scopes\n    client_detail = ClientDetail.get(\n        db, object_id=client_id, config=config, scopes=SCOPE_REGISTRY\n    )\n\n    if client_detail is None:\n        raise AuthenticationFailure(detail=\"Authentication Failure\")\n\n    if not client_detail.credentials_valid(client_secret):\n        raise AuthenticationFailure(detail=\"Authentication Failure\")\n\n    logger.info(\"Creating access token\")\n    access_code = client_detail.create_access_code_jwe(\n        config.security.app_encryption_key\n    )\n    return AccessToken(access_token=access_code)\n\n\n@router.post(\n    CLIENT,\n    dependencies=[Security(verify_oauth_client, scopes=[CLIENT_CREATE])],\n    response_model=ClientCreatedResponse,\n)\ndef create_client(\n    *,\n    db: Session = Depends(get_db),\n    scopes: List[str] = Body([]),\n) -> ClientCreatedResponse:\n    \"\"\"Creates a new client and returns the credentials\"\"\"\n    logging.info(\"Creating new client\")\n    if not all(scope in SCOPE_REGISTRY for scope in scopes):\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=f\"Invalid Scope. Scopes must be one of {SCOPE_REGISTRY}.\",\n        )\n\n    client, secret = ClientDetail.create_client_and_secret(\n        db,\n        config.security.oauth_client_id_length_bytes,\n        config.security.oauth_client_secret_length_bytes,\n        scopes=scopes,\n    )\n    return ClientCreatedResponse(client_id=client.id, client_secret=secret)\n\n\n@router.delete(\n    CLIENT_BY_ID, dependencies=[Security(verify_oauth_client, scopes=[CLIENT_DELETE])]\n)\ndef delete_client(client_id: str, db: Session = Depends(get_db)) -> None:\n    \"\"\"Deletes the client associated with the client_id. Does nothing if the client does\n    not exist\"\"\"\n    client = ClientDetail.get(db, object_id=client_id, config=config)\n    if not client:\n        return\n    logging.info(\"Deleting client\")\n    client.delete(db)\n\n\n@router.get(\n    CLIENT_SCOPE,\n    dependencies=[Security(verify_oauth_client, scopes=[CLIENT_READ])],\n    response_model=List[str],\n)\ndef get_client_scopes(client_id: str, db: Session = Depends(get_db)) -> List[str]:\n    \"\"\"Returns a list of the scopes associated with the client. Returns an empty list if client does not exist.\"\"\"\n    client = ClientDetail.get(db, object_id=client_id, config=config)\n    if not client:\n        return []\n\n    logging.info(\"Getting client scopes\")\n    return client.scopes\n\n\n@router.put(\n    CLIENT_SCOPE,\n    dependencies=[Security(verify_oauth_client, scopes=[CLIENT_UPDATE])],\n    response_model=None,\n)\ndef set_client_scopes(\n    client_id: str,\n    scopes: List[str],\n    db: Session = Depends(get_db),\n) -> None:\n    \"\"\"Overwrites the client's scopes with those provided. Does nothing if the client doesn't exist\"\"\"\n    client = ClientDetail.get(db, object_id=client_id, config=config)\n    if not client:\n        return\n\n    if not all(elem in SCOPE_REGISTRY for elem in scopes):\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=f\"Invalid Scope. Scopes must be one of {SCOPE_REGISTRY}.\",\n        )\n\n    logging.info(\"Updating client scopes\")\n    client.update(db, data={\"scopes\": scopes})\n\n\n@router.get(\n    SCOPE,\n    dependencies=[Security(verify_oauth_client, scopes=[SCOPE_READ])],\n    response_model=List[str],\n)\ndef read_scopes() -> List[str]:\n    \"\"\"Returns a list of all scopes available for assignment in the system\"\"\"\n    logging.info(\"Getting all available scopes\")\n    return SCOPE_REGISTRY\n\n\n@router.get(OAUTH_CALLBACK, response_model=None)\ndef oauth_callback(code: str, state: str, db: Session = Depends(get_db)) -> None:\n    \"\"\"\n    Uses the passed in code to generate the token access request\n    for the connection associated with the given state.\n    \"\"\"\n\n    # find authentication request by state\n    authentication_request: AuthenticationRequest = AuthenticationRequest.get_by(\n        db, field=\"state\", value=state\n    )\n    if not authentication_request:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=\"No authentication request found for the given state.\",\n        )\n\n    connection_config: ConnectionConfig = ConnectionConfig.get_by(\n        db, field=\"key\", value=authentication_request.connection_key\n    )\n    verify_oauth_connection_config(connection_config)\n\n    try:\n        authentication = (\n            connection_config.get_saas_config().client_config.authentication  # type: ignore\n        )\n        auth_strategy: OAuth2AuthorizationCodeAuthenticationStrategy = AuthenticationStrategy.get_strategy(  # type: ignore\n            authentication.strategy, authentication.configuration  # type: ignore\n        )\n        connection_config.secrets = {**connection_config.secrets, \"code\": code}  # type: ignore\n        auth_strategy.get_access_token(connection_config, db)\n    except (OAuth2TokenException, FidesopsException) as exc:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=str(exc))\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/policy_endpoints.py", "content": "import logging\nfrom typing import Any, Dict, List\n\nfrom fastapi import Body, Depends, Security\nfrom fastapi_pagination import Page, Params\nfrom fastapi_pagination.bases import AbstractPage\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom fideslib.exceptions import KeyOrNameAlreadyExists\nfrom fideslib.models.client import ClientDetail\nfrom pydantic import conlist\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.orm import Session\nfrom starlette.exceptions import HTTPException\nfrom starlette.status import HTTP_200_OK, HTTP_204_NO_CONTENT, HTTP_404_NOT_FOUND\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1 import scope_registry\nfrom fidesops.ops.api.v1 import urn_registry as urls\nfrom fidesops.ops.common_exceptions import (\n    DataCategoryNotSupported,\n    DrpActionValidationError,\n    PolicyValidationError,\n    RuleTargetValidationError,\n    RuleValidationError,\n)\nfrom fidesops.ops.models.policy import ActionType, Policy, Rule, RuleTarget\nfrom fidesops.ops.models.storage import StorageConfig\nfrom fidesops.ops.schemas import policy as schemas\nfrom fidesops.ops.schemas.api import BulkUpdateFailed\nfrom fidesops.ops.schemas.shared_schemas import FidesOpsKey\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.logger import Pii\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"Policy\"], prefix=urls.V1_URL_PREFIX)\n\nlogger = logging.getLogger(__name__)\n\n\n@router.get(\n    urls.POLICY_LIST,\n    status_code=HTTP_200_OK,\n    response_model=Page[schemas.PolicyResponse],\n    dependencies=[Security(verify_oauth_client, scopes=[scope_registry.POLICY_READ])],\n)\ndef get_policy_list(\n    *,\n    db: Session = Depends(deps.get_db),\n    params: Params = Depends(),\n) -> AbstractPage[Policy]:\n    \"\"\"\n    Return a paginated list of all Policy records in this system\n    \"\"\"\n    logger.info(\"Finding all policies with pagination params '%s'\", params)\n    policies = Policy.query(db=db).order_by(Policy.created_at.desc())\n    return paginate(policies, params=params)\n\n\ndef get_policy_or_error(db: Session, policy_key: FidesOpsKey) -> Policy:\n    \"\"\"Helper method to load Policy or throw a 404\"\"\"\n    logger.info(\"Finding policy with key '%s'\", policy_key)\n    policy = Policy.get_by(db=db, field=\"key\", value=policy_key)\n    if not policy:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No Policy found for key {policy_key}.\",\n        )\n\n    return policy\n\n\n@router.get(\n    urls.POLICY_DETAIL,\n    status_code=HTTP_200_OK,\n    response_model=schemas.PolicyResponse,\n    dependencies=[Security(verify_oauth_client, scopes=[scope_registry.POLICY_READ])],\n)\ndef get_policy(\n    *,\n    policy_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n) -> schemas.PolicyResponse:\n    \"\"\"\n    Return a single Policy\n    \"\"\"\n    return get_policy_or_error(db, policy_key)\n\n\n@router.patch(\n    urls.POLICY_LIST,\n    status_code=HTTP_200_OK,\n    response_model=schemas.BulkPutPolicyResponse,\n)\ndef create_or_update_policies(\n    *,\n    client: ClientDetail = Security(\n        verify_oauth_client,\n        scopes=[scope_registry.POLICY_CREATE_OR_UPDATE],\n    ),\n    db: Session = Depends(deps.get_db),\n    data: conlist(schemas.Policy, max_items=50) = Body(...),  # type: ignore\n) -> schemas.BulkPutPolicyResponse:\n    \"\"\"\n    Given a list of policy data elements, create or update corresponding Policy objects\n    or report failure\n    \"\"\"\n    created_or_updated: List[Policy] = []\n    failed: List[BulkUpdateFailed] = []\n    logger.info(\"Starting bulk upsert for %s policies\", len(data))\n\n    for policy_schema in data:\n        policy_data: Dict[str, Any] = dict(policy_schema)\n        try:\n            policy = Policy.create_or_update(\n                db=db,\n                data={\n                    \"name\": policy_data[\"name\"],\n                    \"key\": policy_data.get(\"key\"),\n                    \"client_id\": client.id,\n                    \"drp_action\": policy_data.get(\"drp_action\"),\n                    \"execution_timeframe\": policy_data.get(\"execution_timeframe\"),\n                },\n            )\n        except (\n            KeyOrNameAlreadyExists,\n            DrpActionValidationError,\n            IntegrityError,\n        ) as exc:\n            logger.warning(\"Create/update failed for policy: %s\", Pii(str(exc)))\n            failure = {\n                \"message\": exc.args[0],\n                \"data\": policy_data,\n            }\n            failed.append(BulkUpdateFailed(**failure))\n            continue\n        except PolicyValidationError as exc:\n            logger.warning(\"Create/update failed for policy: %s\", Pii(str(exc)))\n            failure = {\n                \"message\": \"This record could not be added because the data provided was invalid.\",\n                \"data\": policy_data,\n            }\n            failed.append(BulkUpdateFailed(**failure))\n            continue\n        else:\n            created_or_updated.append(policy)\n\n    return schemas.BulkPutPolicyResponse(\n        succeeded=created_or_updated,\n        failed=failed,\n    )\n\n\n@router.patch(\n    urls.RULE_LIST,\n    status_code=HTTP_200_OK,\n    response_model=schemas.BulkPutRuleResponse,\n)\ndef create_or_update_rules(\n    *,\n    client: ClientDetail = Security(\n        verify_oauth_client,\n        scopes=[scope_registry.RULE_CREATE_OR_UPDATE],\n    ),\n    policy_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n    input_data: conlist(schemas.RuleCreate, max_items=50) = Body(...),  # type: ignore\n) -> schemas.BulkPutRuleResponse:\n    \"\"\"\n    Given a list of Rule data elements, create or update corresponding Rule objects\n    or report failure\n    \"\"\"\n    logger.info(\"Finding policy with key '%s'\", policy_key)\n\n    policy = get_policy_or_error(db, policy_key)\n\n    created_or_updated: List[Rule] = []\n    failed: List[BulkUpdateFailed] = []\n\n    logger.info(\n        \"Starting bulk upsert for %s rules on policy %s\", len(input_data), policy_key\n    )\n\n    for schema in input_data:\n        # Validate all FKs in the input data exist\n        associated_storage_config_id = None\n        if schema.action_type == ActionType.access:\n            # Only validate the associated StorageConfig on access rules\n            storage_destination_key = schema.storage_destination_key\n            associated_storage_config: StorageConfig = StorageConfig.get_by(\n                db=db,\n                field=\"key\",\n                value=storage_destination_key,\n            )\n            if not associated_storage_config:\n                logger.warning(\n                    \"No storage config found with key %s\", storage_destination_key\n                )\n                failure = {\n                    \"message\": f\"A StorageConfig with key {storage_destination_key} does not exist\",\n                    \"data\": dict(\n                        schema\n                    ),  # Be sure to pass the schema out the same way it came in\n                }\n                failed.append(BulkUpdateFailed(**failure))\n                continue\n\n            associated_storage_config_id = associated_storage_config.id\n\n        masking_strategy_data = None\n        if schema.masking_strategy:\n            masking_strategy_data = schema.masking_strategy.dict()\n\n        try:\n            rule = Rule.create_or_update(\n                db=db,\n                data={\n                    \"action_type\": schema.action_type,\n                    \"client_id\": client.id,\n                    \"key\": schema.key,\n                    \"name\": schema.name,\n                    \"policy_id\": policy.id,\n                    \"storage_destination_id\": associated_storage_config_id,\n                    \"masking_strategy\": masking_strategy_data,\n                },\n            )\n        except KeyOrNameAlreadyExists as exc:\n            logger.warning(\n                \"Create/update failed for rule '%s' on policy %s: %s\",\n                schema.key,\n                policy_key,\n                exc,\n            )\n            failure = {\n                \"message\": exc.args[0],\n                \"data\": dict(schema),\n            }\n            failed.append(BulkUpdateFailed(**failure))\n            continue\n        except RuleValidationError as exc:\n            logger.warning(\n                \"Create/update failed for rule '%s' on policy %s: %s\",\n                schema.key,\n                policy_key,\n                Pii(str(exc)),\n            )\n            failure = {\n                \"message\": exc.args[0],\n                \"data\": dict(schema),\n            }\n            failed.append(BulkUpdateFailed(**failure))\n            continue\n        except ValueError as exc:\n            logger.warning(\n                \"Create/update failed for rule '%s' on policy %s: %s\",\n                schema.key,\n                policy_key,\n                Pii(str(exc)),\n            )\n            failure = {\n                \"message\": exc.args[0],\n                \"data\": dict(schema),\n            }\n            failed.append(BulkUpdateFailed(**failure))\n            continue\n        else:\n            created_or_updated.append(rule)\n\n    return schemas.BulkPutRuleResponse(succeeded=created_or_updated, failed=failed)\n\n\n@router.delete(\n    urls.RULE_DETAIL,\n    status_code=HTTP_204_NO_CONTENT,\n    dependencies=[Security(verify_oauth_client, scopes=[scope_registry.RULE_DELETE])],\n)\ndef delete_rule(\n    *,\n    policy_key: FidesOpsKey,\n    rule_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n) -> None:\n    \"\"\"\n    Delete a policy rule.\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n\n    logger.info(\"Finding rule with key '%s'\", rule_key)\n\n    rule = Rule.filter(\n        db=db, conditions=(Rule.key == rule_key and Rule.policy_id == policy.id)\n    ).first()\n    if not rule:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No Rule found for key {rule_key} on Policy {policy_key}.\",\n        )\n\n    logger.info(\"Deleting rule with key '%s'\", rule_key)\n    rule.delete(db=db)\n\n\n@router.patch(\n    urls.RULE_TARGET_LIST,\n    status_code=HTTP_200_OK,\n    response_model=schemas.BulkPutRuleTargetResponse,\n)\ndef create_or_update_rule_targets(\n    *,\n    client: ClientDetail = Security(\n        verify_oauth_client, scopes=[scope_registry.RULE_CREATE_OR_UPDATE]\n    ),\n    policy_key: FidesOpsKey,\n    rule_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n    input_data: conlist(schemas.RuleTarget, max_items=50) = Body(...),  # type: ignore\n) -> schemas.BulkPutRuleTargetResponse:\n    \"\"\"\n    Given a list of Rule data elements, create corresponding Rule objects\n    or report failure\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n\n    logger.info(\"Finding rule with key '%s'\", rule_key)\n    rule = Rule.filter(\n        db=db, conditions=(Rule.key == rule_key and Rule.policy_id == policy.id)\n    ).first()\n    if not rule:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No Rule found for key {rule_key} on Policy {policy_key}.\",\n        )\n\n    created_or_updated = []\n    failed = []\n    logger.info(\n        \"Starting bulk upsert for %s rule targets on rule %s\", len(input_data), rule_key\n    )\n    for schema in input_data:\n        try:\n            target = RuleTarget.create_or_update(\n                db=db,\n                data={\n                    \"name\": schema.name,\n                    \"key\": schema.key,\n                    \"data_category\": schema.data_category,\n                    \"rule_id\": rule.id,\n                    \"client_id\": client.id,\n                },\n            )\n        except KeyOrNameAlreadyExists as exc:\n            logger.warning(\n                \"Create/update failed for rule target %s on rule %s: %s\",\n                schema.key,\n                rule_key,\n                exc,\n            )\n            failure = {\n                \"message\": exc.args[0],\n                \"data\": dict(schema),\n            }\n            failed.append(BulkUpdateFailed(**failure))\n            continue\n        except (\n            DataCategoryNotSupported,\n            PolicyValidationError,\n            RuleTargetValidationError,\n        ) as exc:\n            logger.warning(\n                \"Create/update failed for rule target %s on rule %s: %s\",\n                schema.key,\n                rule_key,\n                Pii(str(exc)),\n            )\n            failure = {\n                \"message\": exc.args[0],\n                \"data\": dict(schema),\n            }\n            failed.append(BulkUpdateFailed(**failure))\n            continue\n        except IntegrityError as exc:\n            logger.warning(\n                \"Create/update failed for rule target %s on rule %s: %s\",\n                schema.key,\n                rule_key,\n                Pii(str(exc)),\n            )\n            failure = {\n                \"message\": f\"DataCategory {schema.data_category} is already specified on Rule with ID {rule.id}\",\n                \"data\": dict(schema),\n            }\n            failed.append(BulkUpdateFailed(**failure))\n        else:\n            created_or_updated.append(target)\n\n    return schemas.BulkPutRuleTargetResponse(\n        succeeded=created_or_updated,\n        failed=failed,\n    )\n\n\n@router.delete(\n    urls.RULE_TARGET_DETAIL,\n    status_code=HTTP_204_NO_CONTENT,\n    dependencies=[Security(verify_oauth_client, scopes=[scope_registry.RULE_DELETE])],\n)\ndef delete_rule_target(\n    *,\n    policy_key: FidesOpsKey,\n    rule_key: FidesOpsKey,\n    rule_target_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n) -> None:\n    \"\"\"\n    Delete the rule target.\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n\n    logger.info(\"Finding rule with key '%s'\", rule_key)\n    rule = Rule.filter(\n        db=db, conditions=(Rule.key == rule_key and Rule.policy_id == policy.id)\n    ).first()\n    if not rule:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No Rule found for key {rule_key} on Policy {policy_key}.\",\n        )\n\n    logger.info(\"Finding rule target with key '%s'\", rule_target_key)\n    target = RuleTarget.filter(\n        db=db,\n        conditions=(\n            RuleTarget.key == rule_target_key and RuleTarget.rule_id == rule.id\n        ),\n    ).first()\n    if not target:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No RuleTarget found for key {rule_target_key} at Rule {rule_key} on Policy {policy_key}.\",\n        )\n\n    logger.info(\"Deleting rule target with key '%s'\", rule_target_key)\n\n    target.delete(db=db)\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/consent_request_endpoints.py", "content": "from __future__ import annotations\n\nimport logging\n\nfrom fastapi import Depends, HTTPException, Security\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.orm import Session\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_400_BAD_REQUEST,\n    HTTP_403_FORBIDDEN,\n    HTTP_404_NOT_FOUND,\n    HTTP_500_INTERNAL_SERVER_ERROR,\n)\n\nfrom fidesops.ops.api.deps import get_db\nfrom fidesops.ops.api.v1.scope_registry import CONSENT_READ\nfrom fidesops.ops.api.v1.urn_registry import (\n    CONSENT_REQUEST,\n    CONSENT_REQUEST_PREFERENCES,\n    CONSENT_REQUEST_PREFERENCES_WITH_ID,\n    CONSENT_REQUEST_VERIFY,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.common_exceptions import (\n    EmailDispatchException,\n    FunctionalityNotConfigured,\n    IdentityVerificationException,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.models.privacy_request import (\n    Consent,\n    ConsentRequest,\n    ProvidedIdentity,\n    ProvidedIdentityType,\n)\nfrom fidesops.ops.schemas.privacy_request import Consent as ConsentSchema\nfrom fidesops.ops.schemas.privacy_request import (\n    ConsentPreferences,\n    ConsentPreferencesWithVerificationCode,\n    ConsentRequestResponse,\n    VerificationCode,\n)\nfrom fidesops.ops.schemas.redis_cache import Identity\nfrom fidesops.ops.service._verification import send_verification_code_to_user\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.logger import Pii\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"Consent\"], prefix=V1_URL_PREFIX)\n\nlogger = logging.getLogger(__name__)\n\n\n@router.post(\n    CONSENT_REQUEST,\n    status_code=HTTP_200_OK,\n    response_model=ConsentRequestResponse,\n)\ndef create_consent_request(\n    *,\n    db: Session = Depends(get_db),\n    data: Identity,\n) -> ConsentRequestResponse:\n    \"\"\"Creates a verification code for the user to verify access to manage consent preferences.\"\"\"\n    if not config.redis.enabled:\n        raise FunctionalityNotConfigured(\n            \"Application redis cache required, but it is currently disabled! Please update your application configuration to enable integration with a redis cache.\"\n        )\n\n    if not config.execution.subject_identity_verification_required:\n        raise FunctionalityNotConfigured(\n            \"Subject identity verification is required, but it is currently disabled! Please update your application configuration to enable subject identity verification.\"\n        )\n\n    if not data.email:\n        raise HTTPException(HTTP_400_BAD_REQUEST, detail=\"An email address is required\")\n\n    identity = ProvidedIdentity.filter(\n        db=db,\n        conditions=(\n            (ProvidedIdentity.field_name == ProvidedIdentityType.email)\n            & (ProvidedIdentity.hashed_value == ProvidedIdentity.hash_value(data.email))\n            & (ProvidedIdentity.privacy_request_id.is_(None))\n        ),\n    ).first()\n\n    if not identity:\n        provided_identity_data = {\n            \"privacy_request_id\": None,\n            \"field_name\": \"email\",\n            \"hashed_value\": ProvidedIdentity.hash_value(data.email),\n            \"encrypted_value\": {\"value\": data.email},\n        }\n        identity = ProvidedIdentity.create(db, data=provided_identity_data)\n\n    consent_request_data = {\n        \"provided_identity_id\": identity.id,\n    }\n    consent_request = ConsentRequest.create(db, data=consent_request_data)\n    try:\n        send_verification_code_to_user(db, consent_request, data.email)\n    except EmailDispatchException as exc:\n        logger.error(\"Error sending the verification code email: %s\", str(exc))\n        raise HTTPException(\n            status_code=HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error sending the verification code email: {str(exc)}\",\n        )\n    return ConsentRequestResponse(\n        identity=data,\n        consent_request_id=consent_request.id,\n    )\n\n\n@router.post(\n    CONSENT_REQUEST_VERIFY,\n    status_code=HTTP_200_OK,\n    response_model=ConsentPreferences,\n)\ndef consent_request_verify(\n    *,\n    consent_request_id: str,\n    db: Session = Depends(get_db),\n    data: VerificationCode,\n) -> ConsentPreferences:\n    \"\"\"Verifies the verification code and returns the current consent preferences if successful.\"\"\"\n    provided_identity = _get_consent_request_and_provided_identity(\n        db=db, consent_request_id=consent_request_id, verification_code=data.code\n    )\n\n    if not provided_identity.hashed_value:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"Provided identity missing email\"\n        )\n\n    return _prepare_consent_preferences(db, provided_identity)\n\n\n@router.post(\n    CONSENT_REQUEST_PREFERENCES,\n    dependencies=[Security(verify_oauth_client, scopes=[CONSENT_READ])],\n    status_code=HTTP_200_OK,\n    response_model=ConsentPreferences,\n)\ndef get_consent_preferences(\n    *, db: Session = Depends(get_db), data: Identity\n) -> ConsentPreferences:\n    \"\"\"Gets the consent preferences for the specified user.\"\"\"\n    if data.email:\n        lookup = data.email\n    elif data.phone_number:\n        lookup = data.phone_number\n    else:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST, detail=\"No identity information provided\"\n        )\n\n    identity = ProvidedIdentity.filter(\n        db,\n        conditions=(\n            (ProvidedIdentity.hashed_value == ProvidedIdentity.hash_value(lookup))\n            & (ProvidedIdentity.privacy_request_id.is_(None))\n        ),\n    ).first()\n\n    if not identity:\n        raise HTTPException(status_code=HTTP_404_NOT_FOUND, detail=\"Identity not found\")\n\n    return _prepare_consent_preferences(db, identity)\n\n\n@router.patch(\n    CONSENT_REQUEST_PREFERENCES_WITH_ID,\n    status_code=HTTP_200_OK,\n    response_model=ConsentPreferences,\n)\ndef set_consent_preferences(\n    *,\n    consent_request_id: str,\n    db: Session = Depends(get_db),\n    data: ConsentPreferencesWithVerificationCode,\n) -> ConsentPreferences:\n    \"\"\"Verifies the verification code and saves the user's consent preferences if successful.\"\"\"\n    provided_identity = _get_consent_request_and_provided_identity(\n        db=db,\n        consent_request_id=consent_request_id,\n        verification_code=data.code,\n    )\n\n    if not provided_identity.hashed_value:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"Provided identity missing email\"\n        )\n\n    for preference in data.consent:\n        current_preference = Consent.filter(\n            db=db,\n            conditions=(Consent.provided_identity_id == provided_identity.id)\n            & (Consent.data_use == preference.data_use),\n        ).first()\n\n        if current_preference:\n            current_preference.update(db, data=dict(preference))\n        else:\n            preference_dict = dict(preference)\n            preference_dict[\"provided_identity_id\"] = provided_identity.id\n            try:\n                Consent.create(db, data=preference_dict)\n            except IntegrityError as exc:\n                raise HTTPException(\n                    status_code=HTTP_400_BAD_REQUEST, detail=Pii(str(exc))\n                )\n\n    return _prepare_consent_preferences(db, provided_identity)\n\n\ndef _get_consent_request_and_provided_identity(\n    db: Session,\n    consent_request_id: str,\n    verification_code: str,\n) -> ProvidedIdentity:\n    \"\"\"Verifies the consent request and verification code, then return the ProvidedIdentity if successful.\"\"\"\n    consent_request = ConsentRequest.get_by_key_or_id(\n        db=db, data={\"id\": consent_request_id}\n    )\n\n    if not consent_request:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"Consent request not found\"\n        )\n\n    try:\n        consent_request.verify_identity(verification_code)\n    except IdentityVerificationException as exc:\n        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=exc.message)\n    except PermissionError as exc:\n        logger.info(\"Invalid verification code provided for %s.\", consent_request.id)\n        raise HTTPException(status_code=HTTP_403_FORBIDDEN, detail=exc.args[0])\n\n    provided_identity: ProvidedIdentity | None = ProvidedIdentity.get_by_key_or_id(\n        db, data={\"id\": consent_request.provided_identity_id}\n    )\n\n    # It shouldn't be possible to hit this because the cascade delete of the identity\n    # data would also delete the consent_request, but including this as a safety net.\n    if not provided_identity:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=\"No identity found for consent request id\",\n        )\n\n    return provided_identity\n\n\ndef _prepare_consent_preferences(\n    db: Session, provided_identity: ProvidedIdentity\n) -> ConsentPreferences:\n    consent = Consent.filter(\n        db=db, conditions=Consent.provided_identity_id == provided_identity.id\n    ).all()\n\n    if not consent:\n        return ConsentPreferences(consent=None)\n\n    return ConsentPreferences(\n        consent=[\n            ConsentSchema(\n                data_use=x.data_use,\n                data_use_description=x.data_use_description,\n                opt_in=x.opt_in,\n            )\n            for x in consent\n        ],\n    )\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/exception_handlers.py", "content": "from typing import Callable, List\n\nfrom fastapi import Request\nfrom fastapi.responses import JSONResponse\nfrom starlette.status import HTTP_500_INTERNAL_SERVER_ERROR\n\nfrom fidesops.ops.common_exceptions import FunctionalityNotConfigured\n\n\nclass ExceptionHandlers:\n    @staticmethod\n    def functionality_not_configured_handler(\n        request: Request, exc: FunctionalityNotConfigured\n    ) -> JSONResponse:\n        return JSONResponse(\n            status_code=HTTP_500_INTERNAL_SERVER_ERROR, content={\"message\": str(exc)}\n        )\n\n    @classmethod\n    def get_handlers(\n        cls,\n    ) -> List[Callable[[Request, FunctionalityNotConfigured], JSONResponse]]:\n        return [ExceptionHandlers.functionality_not_configured_handler]\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/encryption_endpoints.py", "content": "import logging\nimport secrets\n\nfrom fastapi import Security\nfrom fideslib.cryptography import cryptographic_util\nfrom fideslib.cryptography.cryptographic_util import b64_str_to_bytes, bytes_to_b64_str\n\nfrom fidesops.ops.api.v1.scope_registry import ENCRYPTION_EXEC\nfrom fidesops.ops.api.v1.urn_registry import (\n    DECRYPT_AES,\n    ENCRYPT_AES,\n    ENCRYPTION_KEY,\n    V1_URL_PREFIX,\n)\nfrom fidesops.ops.core.config import config\nfrom fidesops.ops.schemas.encryption_request import (\n    AesDecryptionRequest,\n    AesDecryptionResponse,\n    AesEncryptionRequest,\n    AesEncryptionResponse,\n)\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.encryption.aes_gcm_encryption_scheme import (\n    decrypt as aes_gcm_decrypt,\n)\nfrom fidesops.ops.util.encryption.aes_gcm_encryption_scheme import (\n    encrypt_verify_secret_length as aes_gcm_encrypt,\n)\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"Encryption\"], prefix=V1_URL_PREFIX)\n\n\nlogger = logging.getLogger(__name__)\n\n\n@router.get(\n    ENCRYPTION_KEY,\n    dependencies=[Security(verify_oauth_client, scopes=[ENCRYPTION_EXEC])],\n    response_model=str,\n)\ndef get_encryption_key() -> str:\n    logger.info(\"Generating encryption key\")\n    return cryptographic_util.generate_secure_random_string(\n        config.security.aes_encryption_key_length\n    )\n\n\n@router.put(\n    ENCRYPT_AES,\n    dependencies=[Security(verify_oauth_client, scopes=[ENCRYPTION_EXEC])],\n    response_model=AesEncryptionResponse,\n)\ndef aes_encrypt(encryption_request: AesEncryptionRequest) -> AesEncryptionResponse:\n    logger.info(\"Starting AES Encryption\")\n    nonce: bytes = secrets.token_bytes(config.security.aes_gcm_nonce_length)\n\n    encrypted_value: str = aes_gcm_encrypt(\n        encryption_request.value,\n        encryption_request.key,  # type: ignore\n        nonce,\n    )\n    return AesEncryptionResponse(\n        encrypted_value=encrypted_value, nonce=bytes_to_b64_str(nonce)\n    )\n\n\n@router.put(\n    DECRYPT_AES,\n    dependencies=[Security(verify_oauth_client, scopes=[ENCRYPTION_EXEC])],\n    response_model=AesDecryptionResponse,\n)\ndef aes_decrypt(decryption_request: AesDecryptionRequest) -> AesDecryptionResponse:\n    logger.info(\"Starting AES Decryption\")\n    nonce: bytes = b64_str_to_bytes(decryption_request.nonce)\n\n    decrypted_value: str = aes_gcm_decrypt(\n        decryption_request.value,\n        decryption_request.key.encode(config.security.encoding),\n        nonce,\n    )\n    return AesDecryptionResponse(decrypted_value=decrypted_value)\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/endpoints/policy_webhook_endpoints.py", "content": "import logging\nfrom typing import List\n\nfrom fastapi import Body, Depends, Security\nfrom fastapi_pagination import Page, Params\nfrom fastapi_pagination.bases import AbstractPage\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom fideslib.db.base_class import get_key_from_data\nfrom fideslib.exceptions import KeyOrNameAlreadyExists\nfrom pydantic import conlist\nfrom sqlalchemy.orm import Session\nfrom starlette.exceptions import HTTPException\nfrom starlette.status import HTTP_200_OK, HTTP_400_BAD_REQUEST, HTTP_404_NOT_FOUND\n\nfrom fidesops.ops.api import deps\nfrom fidesops.ops.api.v1 import scope_registry as scopes\nfrom fidesops.ops.api.v1 import urn_registry as urls\nfrom fidesops.ops.api.v1.endpoints.connection_endpoints import (\n    get_connection_config_or_error,\n)\nfrom fidesops.ops.api.v1.endpoints.policy_endpoints import get_policy_or_error\nfrom fidesops.ops.common_exceptions import WebhookOrderException\nfrom fidesops.ops.models.policy import (\n    Policy,\n    PolicyPostWebhook,\n    PolicyPreWebhook,\n    WebhookTypes,\n)\nfrom fidesops.ops.schemas import policy_webhooks as schemas\nfrom fidesops.ops.schemas.policy_webhooks import PolicyWebhookDeleteResponse\nfrom fidesops.ops.schemas.shared_schemas import FidesOpsKey\nfrom fidesops.ops.util.api_router import APIRouter\nfrom fidesops.ops.util.oauth_util import verify_oauth_client\n\nrouter = APIRouter(tags=[\"Policy Webhooks\"], prefix=urls.V1_URL_PREFIX)\n\nlogger = logging.getLogger(__name__)\n\n\n@router.get(\n    urls.POLICY_WEBHOOKS_PRE,\n    status_code=HTTP_200_OK,\n    response_model=Page[schemas.PolicyWebhookResponse],\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.WEBHOOK_READ])],\n)\ndef get_policy_pre_execution_webhooks(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    params: Params = Depends(),\n) -> AbstractPage[PolicyPreWebhook]:\n    \"\"\"\n    Return a paginated list of all Pre-Execution Webhooks that will run in order for the Policy **before** a\n    Privacy Request is executed.\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n\n    logger.info(\n        \"Finding all Pre-Execution Webhooks for Policy '%s' with pagination params '%s'\",\n        policy.key,\n        params,\n    )\n    return paginate(policy.pre_execution_webhooks.order_by(\"order\"), params=params)\n\n\n@router.get(\n    urls.POLICY_WEBHOOKS_POST,\n    status_code=HTTP_200_OK,\n    response_model=Page[schemas.PolicyWebhookResponse],\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.WEBHOOK_READ])],\n)\ndef get_policy_post_execution_webhooks(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    params: Params = Depends(),\n) -> AbstractPage[PolicyPostWebhook]:\n    \"\"\"\n    Return a paginated list of all Post-Execution Webhooks that will run in order for the Policy **after** a\n    Privacy Request is executed.\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n\n    logger.info(\n        \"Finding all Post-Execution Webhooks for Policy '%s' with pagination params '%s'\",\n        policy.key,\n        params,\n    )\n    return paginate(policy.post_execution_webhooks.order_by(\"order\"), params=params)\n\n\ndef put_webhooks(\n    webhook_cls: WebhookTypes,\n    policy_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n    webhooks: List[schemas.PolicyWebhookCreate] = Body(...),\n) -> List[WebhookTypes]:\n    \"\"\"\n    Helper method to PUT pre-execution or post-execution policy webhooks.\n\n    Creates/updates webhooks with the same \"order\" in which they arrived. This endpoint is all-or-nothing.\n    Either all webhooks should be created/updated or none should be updated. Deletes any webhooks not present\n    in the request body.\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n\n    keys = [\n        get_key_from_data(webhook.dict(), webhook_cls.__name__) for webhook in webhooks\n    ]\n    names = [webhook.name for webhook in webhooks]\n    # Because resources are dependent on each other for order, we want to make sure that we don't have multiple\n    # resources in the request that actually point to the same object.\n    if len(keys) != len(set(keys)) or len(names) != len(set(names)):\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=\"Check request body: there are multiple webhooks whose keys or names resolve to the same value.\",\n        )\n\n    staged_webhooks = []  # Webhooks will be committed at the end\n    for webhook_index, schema in enumerate(webhooks):\n        connection_config = get_connection_config_or_error(\n            db, schema.connection_config_key\n        )\n\n        try:\n            webhook = webhook_cls.create_or_update(\n                db=db,\n                data={\n                    \"key\": schema.key,\n                    \"name\": schema.name,\n                    \"policy_id\": policy.id,\n                    \"connection_config_id\": connection_config.id,\n                    \"direction\": schema.direction,\n                    \"order\": webhook_index,  # Add in the order they arrived in the request\n                },\n            )\n            staged_webhooks.append(webhook)\n        except KeyOrNameAlreadyExists as exc:\n            raise HTTPException(\n                status_code=HTTP_400_BAD_REQUEST,\n                detail=exc.args[0],\n            )\n\n    staged_webhook_keys = [webhook.key for webhook in staged_webhooks]\n    webhooks_to_remove = getattr(\n        policy, f\"{webhook_cls.prefix}_execution_webhooks\"\n    ).filter(\n        webhook_cls.key.not_in(staged_webhook_keys)  # type: ignore\n    )\n\n    if webhooks_to_remove.count():\n        logger.info(\n            \"Removing %s-Execution Webhooks from Policy '%s' that were not included in request: %s\",\n            webhook_cls.prefix.capitalize(),\n            policy.key,\n            [webhook.key for webhook in webhooks_to_remove],\n        )\n        webhooks_to_remove.delete()\n\n    logger.info(\n        \"Creating/updating Policy Pre-Execution Webhooks: %s\", staged_webhook_keys\n    )\n    # Committing to database now, as a last step, once we've verified that all the webhooks\n    # in the request are free of issues.\n    db.commit()\n    return staged_webhooks\n\n\n@router.put(\n    urls.POLICY_WEBHOOKS_PRE,\n    status_code=HTTP_200_OK,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[scopes.WEBHOOK_CREATE_OR_UPDATE])\n    ],\n    response_model=List[schemas.PolicyWebhookResponse],\n)\ndef create_or_update_pre_execution_webhooks(\n    *,\n    policy_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n    webhooks: conlist(schemas.PolicyWebhookCreate, max_items=50) = Body(...),  # type: ignore\n) -> List[PolicyPreWebhook]:\n    \"\"\"\n    Create or update the list of Policy Pre-Execution Webhooks that run **before** query execution.\n\n    All webhooks must be included in the request in the desired order. Any missing webhooks\n    from the request body will be removed.\n    \"\"\"\n    return put_webhooks(PolicyPreWebhook, policy_key, db, webhooks)  # type: ignore\n\n\n@router.put(\n    urls.POLICY_WEBHOOKS_POST,\n    status_code=HTTP_200_OK,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[scopes.WEBHOOK_CREATE_OR_UPDATE])\n    ],\n    response_model=List[schemas.PolicyWebhookResponse],\n)\ndef create_or_update_post_execution_webhooks(\n    *,\n    policy_key: FidesOpsKey,\n    db: Session = Depends(deps.get_db),\n    webhooks: conlist(schemas.PolicyWebhookCreate, max_items=50) = Body(...),  # type: ignore\n) -> List[PolicyPostWebhook]:\n    \"\"\"\n    Create or update the list of Policy Post-Execution Webhooks that run **after** query execution.\n\n    All webhooks must be included in the request in the desired order. Any missing webhooks\n    from the request body will be removed.\n    \"\"\"\n    return put_webhooks(PolicyPostWebhook, policy_key, db, webhooks)  # type: ignore\n\n\ndef get_policy_webhook_or_error(\n    db: Session,\n    policy: Policy,\n    webhook_key: FidesOpsKey,\n    webhook_cls: WebhookTypes,\n) -> WebhookTypes:\n    \"\"\"Helper method to load a Pre-Execution or Post-Execution Policy Webhook or 404\n\n    Also verifies that the webhook belongs to the given Policy.\n    \"\"\"\n    logger.info(\n        \"Finding %s-Execution Webhook with key '%s' for Policy '%s'\",\n        webhook_cls.prefix.capitalize(),\n        webhook_key,\n        policy.key,\n    )\n    loaded_webhook = webhook_cls.filter(\n        db=db,\n        conditions=(\n            (webhook_cls.policy_id == policy.id) & (webhook_cls.key == webhook_key)\n        ),\n    ).first()\n    if not loaded_webhook:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND,\n            detail=f\"No {webhook_cls.prefix.capitalize()}-Execution Webhook found for key '{webhook_key}' on Policy '{policy.key}'.\",\n        )\n    return loaded_webhook\n\n\n@router.get(\n    urls.POLICY_PRE_WEBHOOK_DETAIL,\n    status_code=HTTP_200_OK,\n    response_model=schemas.PolicyWebhookResponse,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.WEBHOOK_READ])],\n)\ndef get_policy_pre_execution_webhook(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    pre_webhook_key: FidesOpsKey,\n) -> PolicyPreWebhook:\n    \"\"\"\n    Loads the given Pre-Execution Webhook on the Policy\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n    return get_policy_webhook_or_error(db, policy, pre_webhook_key, PolicyPreWebhook)  # type: ignore\n\n\n@router.get(\n    urls.POLICY_POST_WEBHOOK_DETAIL,\n    status_code=HTTP_200_OK,\n    response_model=schemas.PolicyWebhookResponse,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.WEBHOOK_READ])],\n)\ndef get_policy_post_execution_webhook(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    post_webhook_key: FidesOpsKey,\n) -> PolicyPostWebhook:\n    \"\"\"\n    Loads the given Post-Execution Webhook on the Policy\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n    return get_policy_webhook_or_error(db, policy, post_webhook_key, PolicyPostWebhook)  # type: ignore\n\n\ndef _patch_webhook(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    webhook_key: FidesOpsKey,\n    webhook_body: schemas.PolicyWebhookUpdate = Body(...),\n    webhook_cls: WebhookTypes,\n) -> schemas.PolicyWebhookUpdateResponse:\n    \"\"\"Helper method for PATCHing a single webhook, either Pre-Execution or Post-Execution\n\n    If the order is updated, this will affect the order of other webhooks.\n    \"\"\"\n    policy = get_policy_or_error(db, policy_key)\n    loaded_webhook = get_policy_webhook_or_error(db, policy, webhook_key, webhook_cls)\n    data = webhook_body.dict(exclude_none=True)\n\n    if data.get(\"connection_config_key\"):\n        connection_config = get_connection_config_or_error(\n            db, data.get(\"connection_config_key\")  # type: ignore\n        )\n        data[\"connection_config_id\"] = connection_config.id\n\n    # Removing index from incoming data - we'll set this at the end.\n    index = data.pop(\"order\", None)\n\n    try:\n        logger.info(\n            \"Updating %s-Execution Webhook with key '%s' on Policy '%s' \",\n            webhook_cls.prefix.capitalize(),\n            webhook_key,\n            policy_key,\n        )\n        loaded_webhook.update(db, data=data)\n    except KeyOrNameAlreadyExists as exc:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=exc.args[0],\n        )\n\n    if index is not None and index != loaded_webhook.order:\n        logger.info(\n            \"Reordering %s-Execution Webhooks for Policy '%s'\",\n            webhook_cls.prefix.capitalize(),\n            policy_key,\n        )\n        try:\n            loaded_webhook.reorder_related_webhooks(db=db, new_index=index)\n        except WebhookOrderException as exc:\n            raise HTTPException(\n                status_code=HTTP_400_BAD_REQUEST,\n                detail=exc.args[0],\n            )\n\n        return schemas.PolicyWebhookUpdateResponse(\n            resource=loaded_webhook,\n            new_order=[\n                webhook\n                for webhook in getattr(\n                    policy, f\"{webhook_cls.prefix}_execution_webhooks\"\n                ).order_by(webhook_cls.order)\n            ],\n        )\n\n    # Policy Webhooks are not committed by default, so we commit at the end.\n    db.commit()\n    return schemas.PolicyWebhookUpdateResponse(resource=loaded_webhook, new_order=[])\n\n\n@router.patch(\n    urls.POLICY_PRE_WEBHOOK_DETAIL,\n    status_code=HTTP_200_OK,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[scopes.WEBHOOK_CREATE_OR_UPDATE])\n    ],\n    response_model=schemas.PolicyWebhookUpdateResponse,\n)\ndef update_pre_execution_webhook(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    pre_webhook_key: FidesOpsKey,\n    webhook_body: schemas.PolicyWebhookUpdate = Body(...),\n) -> schemas.PolicyWebhookUpdateResponse:\n    \"\"\"PATCH a single Policy Pre-Execution Webhook that runs **prior** to executing the Privacy Request.\n\n    Note that updates to the webhook's \"order\" can affect the order of the other pre-execution webhooks.\n    \"\"\"\n    return _patch_webhook(\n        db=db,\n        policy_key=policy_key,\n        webhook_key=pre_webhook_key,\n        webhook_body=webhook_body,\n        webhook_cls=PolicyPreWebhook,  # type: ignore\n    )\n\n\n@router.patch(\n    urls.POLICY_POST_WEBHOOK_DETAIL,\n    status_code=HTTP_200_OK,\n    dependencies=[\n        Security(verify_oauth_client, scopes=[scopes.WEBHOOK_CREATE_OR_UPDATE])\n    ],\n    response_model=schemas.PolicyWebhookUpdateResponse,\n)\ndef update_post_execution_webhook(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    post_webhook_key: FidesOpsKey,\n    webhook_body: schemas.PolicyWebhookUpdate = Body(...),\n) -> schemas.PolicyWebhookUpdateResponse:\n    \"\"\"PATCH a single Policy Post-Execution Webhook that runs **after** executing the Privacy Request.\n\n    Note that updates to the webhook's \"order\" can affect the order of the other post-execution webhooks.\n    \"\"\"\n    return _patch_webhook(\n        db=db,\n        policy_key=policy_key,\n        webhook_key=post_webhook_key,\n        webhook_body=webhook_body,\n        webhook_cls=PolicyPostWebhook,  # type: ignore\n    )\n\n\ndef delete_webhook(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    webhook_key: FidesOpsKey,\n    webhook_cls: WebhookTypes,\n) -> PolicyWebhookDeleteResponse:\n    \"\"\"Handles deleting Pre- or Post-Execution Policy Webhooks. Related webhooks are reordered as necessary\"\"\"\n    policy = get_policy_or_error(db, policy_key)\n    loaded_webhook = get_policy_webhook_or_error(db, policy, webhook_key, webhook_cls)\n    total_webhook_count = (\n        getattr(policy, f\"{webhook_cls.prefix}_execution_webhooks\").count() - 1\n    )\n    reordering = total_webhook_count != loaded_webhook.order\n\n    if reordering:\n        # Move the webhook to the end and shuffle other webhooks\n        logger.info(\n            \"Reordering %s-Execution Webhooks for Policy '%s'\",\n            webhook_cls.prefix.capitalize(),\n            policy_key,\n        )\n        loaded_webhook.reorder_related_webhooks(db=db, new_index=total_webhook_count)\n\n    logger.info(\n        \"Deleting %s-Execution Webhook with key '%s' off of Policy '%s'\",\n        webhook_cls.prefix.capitalize(),\n        webhook_key,\n        policy_key,\n    )\n    loaded_webhook.delete(db=db)\n    return PolicyWebhookDeleteResponse(\n        new_order=[\n            webhook\n            for webhook in getattr(\n                policy, f\"{webhook_cls.prefix}_execution_webhooks\"\n            ).order_by(webhook_cls.order)\n        ]\n        if reordering\n        else []\n    )\n\n\n@router.delete(\n    urls.POLICY_PRE_WEBHOOK_DETAIL,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.WEBHOOK_DELETE])],\n    response_model=schemas.PolicyWebhookDeleteResponse,\n)\ndef delete_pre_execution_webhook(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    pre_webhook_key: FidesOpsKey,\n) -> schemas.PolicyWebhookDeleteResponse:\n    \"\"\"Delete the Pre-Execution Webhook from the Policy and reorder remaining webhooks as necessary.\"\"\"\n    return delete_webhook(\n        db=db,\n        policy_key=policy_key,\n        webhook_key=pre_webhook_key,\n        webhook_cls=PolicyPreWebhook,  # type: ignore\n    )\n\n\n@router.delete(\n    urls.POLICY_POST_WEBHOOK_DETAIL,\n    status_code=HTTP_200_OK,\n    dependencies=[Security(verify_oauth_client, scopes=[scopes.WEBHOOK_DELETE])],\n    response_model=schemas.PolicyWebhookDeleteResponse,\n)\ndef delete_post_execution_webhook(\n    *,\n    db: Session = Depends(deps.get_db),\n    policy_key: FidesOpsKey,\n    post_webhook_key: FidesOpsKey,\n) -> schemas.PolicyWebhookDeleteResponse:\n    \"\"\"Delete the Post-Execution Webhook from the Policy and reorder remaining webhooks as necessary.\"\"\"\n    return delete_webhook(\n        db=db,\n        policy_key=policy_key,\n        webhook_key=post_webhook_key,\n        webhook_cls=PolicyPostWebhook,  # type: ignore\n    )\n"}
{"type": "source_file", "path": "src/fidesops/ops/common_exceptions.py", "content": "from typing import List\n\nfrom fastapi import HTTPException\nfrom starlette.status import (\n    HTTP_400_BAD_REQUEST,\n    HTTP_401_UNAUTHORIZED,\n    HTTP_404_NOT_FOUND,\n)\n\n\nclass FidesopsException(Exception):\n    \"\"\"Base class for fidesops exceptions\"\"\"\n\n    def __init__(self, message: str, errors: List[str] = []):\n        super().__init__(message)\n        self.message = message\n        self.errors = errors\n\n\nclass TraversalError(FidesopsException):\n    \"\"\"Fidesops error with the names of all nodes that could not be reached.\"\"\"\n\n\nclass ValidationError(FidesopsException):\n    \"\"\"Data does not pass validation.\"\"\"\n\n\nclass StorageUploadError(FidesopsException):\n    \"\"\"Data cannot be uploaded to storage destination\"\"\"\n\n\nclass ConnectionException(FidesopsException):\n    \"\"\"Exception class when there are errors making a connection\"\"\"\n\n\nclass InsufficientDataException(FidesopsException):\n    \"\"\"Exception class when there is not sufficient data to proceed\"\"\"\n\n\nclass RedisConnectionError(Exception):\n    \"\"\"The Configured Redis instance is uncontactable.\"\"\"\n\n\nclass MisconfiguredPolicyException(Exception):\n    \"\"\"Thrown when a Privacy Request cannot be processed due to a misconfigured Policy.\"\"\"\n\n\nclass PolicyValidationError(ValueError):\n    \"\"\"The policy you are trying to create has invalid data\"\"\"\n\n\nclass InvalidDataLengthValidationError(ValueError):\n    \"\"\"The length provided is invalid\"\"\"\n\n\nclass RuleValidationError(ValueError):\n    \"\"\"The Rule you are trying to create has invalid data\"\"\"\n\n\nclass InvalidDataTypeValidationError(ValueError):\n    \"\"\"The specified data type is invalid.\"\"\"\n\n\nclass RuleTargetValidationError(ValueError):\n    \"\"\"The Rule you are trying to create has invalid data\"\"\"\n\n\nclass DataCategoryNotSupported(ValueError):\n    \"\"\"The data category you have supplied is not supported.\"\"\"\n\n\nclass PolicyNotFoundException(Exception):\n    \"\"\"Policy could not be found\"\"\"\n\n\nclass ConnectorNotFoundException(Exception):\n    \"\"\"Connector could not be found\"\"\"\n\n\nclass DrpActionValidationError(Exception):\n    \"\"\"A resource already exists with this DRP Action.\"\"\"\n\n\nclass StorageConfigNotFoundException(BaseException):\n    \"\"\"Custom Exception - StorageConfig Not Found\"\"\"\n\n\nclass IdentityNotFoundException(BaseException):\n    \"\"\"Identity Not Found\"\"\"\n\n\nclass WebhookOrderException(BaseException):\n    \"\"\"Custom Exception - Issue with webhooks order\"\"\"\n\n\nclass PostProcessingException(BaseException):\n    \"\"\"Custom Exception - Issue with post processing\"\"\"\n\n\nclass CollectionDisabled(BaseException):\n    \"\"\"Collection is attached to disabled ConnectionConfig\"\"\"\n\n\nclass PrivacyRequestPaused(BaseException):\n    \"\"\"Halt Instruction Received on Privacy Request\"\"\"\n\n\nclass NoCachedManualWebhookEntry(BaseException):\n    \"\"\"No manual data exists for this webhook on the given privacy request.\"\"\"\n\n\nclass ManualWebhookFieldsUnset(BaseException):\n    \"\"\"Manual webhook has fields that are not explicitly set: Likely new field has been added\"\"\"\n\n\nclass PrivacyRequestErasureEmailSendRequired(BaseException):\n    \"\"\"Erasure requests will need to be fulfilled by email send.  Exception is raised to change ExecutionLog details\"\"\"\n\n\nclass SaaSConfigNotFoundException(FidesopsException):\n    \"\"\"Custom Exception - SaaS Config Not Found\"\"\"\n\n\nclass EmailConfigAlreadyExistsException(FidesopsException):\n    \"\"\"Custom Exception - Email Config already exists\"\"\"\n\n\nclass EmailConfigNotFoundException(FidesopsException):\n    \"\"\"Custom Exception - Email Config Not Found\"\"\"\n\n\nclass EmailDispatchException(FidesopsException):\n    \"\"\"Custom Exception - Email Dispatch Error\"\"\"\n\n\nclass EmailTemplateUnhandledActionType(FidesopsException):\n    \"\"\"Custom Exception - Email Template Unhandled ActionType Error\"\"\"\n\n\nclass OAuth2TokenException(FidesopsException):\n    \"\"\"Custom Exception - Unable to access or refresh OAuth2 tokens for SaaS connector\"\"\"\n\n\nclass AuthenticationFailure(HTTPException):\n    \"\"\"Wrapper for authentication failure exception\"\"\"\n\n    def __init__(self, detail: str) -> None:\n        super().__init__(status_code=HTTP_401_UNAUTHORIZED, detail=detail)\n\n\nclass BadRequest(HTTPException):\n    \"\"\"Wrapper for bad request exception\"\"\"\n\n    def __init__(self, detail: str) -> None:\n        super().__init__(status_code=HTTP_400_BAD_REQUEST, detail=detail)\n\n\nclass NotFoundException(HTTPException):\n    \"\"\"Wrapper for not found exception\"\"\"\n\n    def __init__(self, detail: str) -> None:\n        super().__init__(status_code=HTTP_404_NOT_FOUND, detail=detail)\n\n\nclass ClientUnsuccessfulException(FidesopsException):\n    \"\"\"Exception for when client call fails\"\"\"\n\n    def __init__(self, status_code: int):\n        super().__init__(message=f\"Client call failed with status code '{status_code}'\")\n\n\nclass NoSuchStrategyException(ValueError):\n    \"\"\"Exception for when a masking strategy does not exist\"\"\"\n\n\nclass FunctionalityNotConfigured(Exception):\n    \"\"\"Custom exception for when invoked functionality is unavailable due to configuration.\"\"\"\n\n\nclass InvalidSaaSRequestOverrideException(ValueError):\n    \"\"\"Exception for when a provied SaaS request override function is invalid\"\"\"\n\n\nclass NoSuchSaaSRequestOverrideException(ValueError):\n    \"\"\"Exception for when a requested SaaS request override function does not exist\"\"\"\n\n\nclass IdentityVerificationException(FidesopsException):\n    \"\"\"Custom exceptions for when we cannot verify the identity of a subjct\"\"\"\n"}
{"type": "source_file", "path": "src/fidesops/ops/core/config.py", "content": "# pylint: disable=C0115,C0116, E0213\n\nimport logging\nimport os\nfrom typing import Any, Dict, List, MutableMapping, Optional\nfrom urllib.parse import quote_plus\n\nfrom fideslib.core.config import (\n    DatabaseSettings,\n    FidesSettings,\n    SecuritySettings,\n    get_config,\n    load_file,\n    load_toml,\n)\nfrom fideslog.sdk.python.utils import FIDESOPS, generate_client_id\nfrom pydantic import validator\nfrom toml import dump\n\nfrom fidesops.ops.api.v1.scope_registry import SCOPE_REGISTRY\n\nlogger = logging.getLogger(__name__)\n\n\nclass FidesopsDatabaseSettings(DatabaseSettings):\n    \"\"\"Configuration settings for Postgres.\"\"\"\n\n    enabled: bool = True\n\n    class Config:\n        env_prefix = \"FIDESOPS__DATABASE__\"\n\n\nclass ExecutionSettings(FidesSettings):\n    \"\"\"Configuration settings for execution.\"\"\"\n\n    privacy_request_delay_timeout: int = 3600\n    # By default Fidesops will not retry graph nodes\n    task_retry_count: int = 0\n    task_retry_delay: int = 0  # In seconds\n    task_retry_backoff: int = 0\n    subject_identity_verification_required: bool = False\n    require_manual_request_approval: bool = False\n    masking_strict: bool = True\n    worker_enabled: bool = True\n    celery_config_path: Optional[str] = \"celery.toml\"\n\n    class Config:\n        env_prefix = \"FIDESOPS__EXECUTION__\"\n\n\nclass RedisSettings(FidesSettings):\n    \"\"\"Configuration settings for Redis.\"\"\"\n\n    host: str\n    port: int = 6379\n    user: Optional[str] = \"\"\n    password: str\n    charset: str = \"utf8\"\n    decode_responses: bool = True\n    default_ttl_seconds: int = 604800\n    identity_verification_code_ttl_seconds: int = 600\n    db_index: Optional[int]\n    enabled: bool = True\n    ssl: bool = False\n    ssl_cert_reqs: Optional[str] = \"required\"\n    connection_url: Optional[str] = None\n\n    @validator(\"connection_url\", pre=True)\n    @classmethod\n    def assemble_connection_url(\n        cls,\n        v: Optional[str],\n        values: Dict[str, str],\n    ) -> str:\n        \"\"\"Join Redis connection credentials into a connection string\"\"\"\n        if isinstance(v, str):\n            # If the whole URL is provided via the config, preference that\n            return v\n\n        db_index = values.get(\"db_index\") if values.get(\"db_index\") is not None else \"\"\n        return f\"redis://{quote_plus(values.get('user', ''))}:{quote_plus(values.get('password', ''))}@{values.get('host', '')}:{values.get('port', '')}/{db_index}\"\n\n    class Config:\n        env_prefix = \"FIDESOPS__REDIS__\"\n\n\nclass FidesopsSecuritySettings(SecuritySettings):\n    \"\"\"Configuration settings for Security variables.\"\"\"\n\n    log_level: str = \"INFO\"\n    root_user_scopes: Optional[List[str]] = SCOPE_REGISTRY\n    subject_request_download_link_ttl_seconds: Optional[int] = 86400\n\n    @validator(\"log_level\", pre=True)\n    def validate_log_level(cls, value: str) -> str:\n        \"\"\"Ensure the provided LOG_LEVEL is a valid value.\"\"\"\n        valid_values = [\n            logging.DEBUG,\n            logging.INFO,\n            logging.WARNING,\n            logging.ERROR,\n            logging.CRITICAL,\n        ]\n        value = value.upper()  # force uppercase, for safety\n\n        # Attempt to convert the string value (e.g. 'debug') to a numeric level, e.g. 10 (logging.DEBUG)\n        # NOTE: If the string doesn't match a valid level, this will return a string like 'Level {value}'\n        if logging.getLevelName(value) not in valid_values:\n            raise ValueError(\n                f\"Invalid LOG_LEVEL provided '{value}', must be one of: DEBUG, INFO, WARNING, ERROR, CRITICAL\"\n            )\n\n        return value\n\n    class Config:\n        env_prefix = \"FIDESOPS__SECURITY__\"\n\n\nclass RootUserSettings(FidesSettings):\n    \"\"\"Configuration settings for Analytics variables.\"\"\"\n\n    analytics_opt_out: Optional[bool] = True\n    analytics_id: Optional[str] = None\n\n    @validator(\"analytics_id\", pre=True)\n    def populate_analytics_id(\n        cls,\n        v: Optional[str],\n        values: Dict[str, str],\n    ) -> Optional[str]:\n        \"\"\"\n        Populates the appropriate value for analytics id based on config\n        \"\"\"\n        if not v and not values.get(\"analytics_opt_out\"):\n            v = cls.generate_and_store_client_id()\n        return v\n\n    @staticmethod\n    def generate_and_store_client_id() -> str:\n        update_obj: Dict[str, Dict] = {}\n        client_id: str = generate_client_id(FIDESOPS)\n        logger.debug(\"analytics client id generated\")\n        update_obj.update(root_user={\"analytics_id\": client_id})\n        update_config_file(update_obj)\n        return client_id\n\n    class Config:\n        env_prefix = \"FIDESOPS__ROOT_USER__\"\n\n\nclass AdminUiSettings(FidesSettings):\n    \"\"\"Configuration settings for Analytics variables.\"\"\"\n\n    enabled: bool = True\n\n    class Config:\n        env_prefix = \"FIDESOPS__ADMIN_UI__\"\n\n\nclass FidesopsNotificationSettings(FidesSettings):\n    \"\"\"Configuration settings for data subject and/or data processor notifications\"\"\"\n\n    send_request_completion_notification: Optional[bool] = True\n    send_request_receipt_notification: Optional[bool] = True\n    send_request_review_notification: Optional[bool] = True\n\n    class Config:\n        env_prefix = \"FIDESOPS__NOTIFICATIONS__\"\n\n\nclass FidesopsConfig(FidesSettings):\n    \"\"\"Configuration variables for the FastAPI project\"\"\"\n\n    # Pydantic doesn't initialise subsections automatically if\n    # only environment variables are provided at runtime. If the\n    # config subclass is instantiated with no args, Pydantic runs\n    # validation before loading in environment variables, which\n    # always fails if any config vars in the subsection are non-optional.\n    # Using the empty dict allows Python to load in the environment\n    # variables _before_ validating them against the Pydantic schema.\n    database: FidesopsDatabaseSettings = {}  # type: ignore\n    redis: RedisSettings = {}  # type: ignore\n    security: FidesopsSecuritySettings = {}  # type: ignore\n    execution: Optional[ExecutionSettings] = ExecutionSettings()\n    root_user: Optional[RootUserSettings] = RootUserSettings()\n    admin_ui: Optional[AdminUiSettings] = AdminUiSettings()\n    notifications: Optional[\n        FidesopsNotificationSettings\n    ] = FidesopsNotificationSettings()\n\n    port: int = int(\n        os.getenv(\n            \"FIDESOPS__PORT\",\n            \"8080\",  # Run the webserver on port 8080 by default\n        )\n    )\n    is_test_mode: bool = os.getenv(\"TESTING\", \"\").lower() == \"true\"\n    hot_reloading: bool = os.getenv(\"FIDESOPS__HOT_RELOAD\", \"\").lower() == \"true\"\n    dev_mode: bool = os.getenv(\"FIDESOPS__DEV_MODE\", \"\").lower() == \"true\"\n    oauth_instance: Optional[str] = os.getenv(\"FIDESOPS__OAUTH_INSTANCE\")\n\n    class Config:  # pylint: disable=C0115\n        case_sensitive = True\n\n    logger.warning(\n        \"Startup configuration: reloading = %s, dev_mode = %s\", hot_reloading, dev_mode\n    )\n    logger.warning(\n        \"Startup configuration: pii logging = %s\",\n        os.getenv(\"FIDESOPS__LOG_PII\", \"\").lower() == \"true\",\n    )\n\n    def log_all_config_values(self) -> None:\n        \"\"\"Output DEBUG logs of all the config values.\"\"\"\n        for settings in [\n            self.database,\n            self.redis,\n            self.security,\n            self.execution,\n            self.admin_ui,\n        ]:\n            for key, value in settings.dict().items():  # type: ignore\n                logger.debug(\n                    \"Using config: %s%s = %s\",\n                    settings.Config.env_prefix,  # type: ignore\n                    key,\n                    value,\n                )\n\n\nCONFIG_KEY_ALLOWLIST = {\n    \"database\": [\n        \"server\",\n        \"user\",\n        \"port\",\n        \"db\",\n        \"test_db\",\n    ],\n    \"redis\": [\n        \"host\",\n        \"port\",\n        \"charset\",\n        \"decode_responses\",\n        \"default_ttl_seconds\",\n        \"db_index\",\n    ],\n    \"security\": [\n        \"cors_origins\",\n        \"encoding\",\n        \"oauth_access_token_expire_minutes\",\n        \"subject_request_download_link_ttl_seconds\",\n    ],\n    \"execution\": [\n        \"task_retry_count\",\n        \"task_retry_delay\",\n        \"task_retry_backoff\",\n        \"require_manual_request_approval\",\n        \"subject_identity_verification_required\",\n    ],\n    \"notifications\": [\"send_request_completion_notification\"],\n}\n\n\ndef get_censored_config(the_config: FidesopsConfig) -> Dict[str, Any]:\n    \"\"\"\n    Returns a config that is safe to expose over the API. This function will\n    strip out any keys not specified in the `CONFIG_KEY_ALLOWLIST` above.\n    \"\"\"\n    as_dict = the_config.dict()\n    filtered: Dict[str, Any] = {}\n    for key, value in CONFIG_KEY_ALLOWLIST.items():\n        data = as_dict[key]\n        filtered[key] = {}\n        for field in value:\n            filtered[key][field] = data[field]\n\n    return filtered\n\n\ndef update_config_file(updates: Dict[str, Dict[str, Any]]) -> None:\n    \"\"\"\n    Overwrite the existing config file with a new version that includes the desired `updates`.\n    :param updates: A nested `dict`, where top-level keys correspond to configuration sections and top-level values contain `dict`s whose key/value pairs correspond to the desired option/value updates.\n    \"\"\"\n    try:\n        config_path: str = load_file([\"fidesops.toml\"])\n        current_config: MutableMapping[str, Any] = load_toml([\"fidesops.toml\"])\n    except FileNotFoundError as e:\n        logger.warning(\"fidesops.toml could not be loaded: %s\", e)\n\n    for key, value in updates.items():\n        if key in current_config:\n            current_config[key].update(value)\n        else:\n            current_config.update({key: value})\n\n    with open(config_path, \"w\") as config_file:  # pylint: disable=W1514\n        dump(current_config, config_file)\n\n    logger.info(\"Updated %s:\", config_path)\n\n    for key, value in updates.items():\n        for subkey, val in value.items():\n            logger.info(\"\\tSet %s.%s = %s\", key, subkey, val)\n\n\nconfig = get_config(FidesopsConfig)\n# `censored_config` is included below because it's important we keep the censored\n# config at parity with `config`. This means if we change the path at which fidesops\n# loads `config`, we should also change `censored_config`.\ncensored_config = get_censored_config(config)\n"}
{"type": "source_file", "path": "src/fidesops/ops/__init__.py", "content": ""}
{"type": "source_file", "path": "src/fidesops/ops/db/__init__.py", "content": ""}
{"type": "source_file", "path": "src/fidesops/ops/cli.py", "content": "\"\"\"Sets up a simple fidesops CLI\"\"\"\nimport logging\n\nimport click\n\nfrom fidesops.main import start_webserver\nfrom fidesops.ops.tasks import start_worker\n\nlogger = logging.getLogger(__name__)\n\n\n@click.group()\n@click.pass_context\ndef cli(ctx: click.Context) -> None:\n    \"\"\"fidesops CLI\"\"\"\n    ctx.ensure_object(dict)\n\n\n@cli.command()\n@click.pass_context\ndef webserver(ctx: click.Context) -> None:\n    \"\"\"\n    Runs any pending DB migrations and starts the webserver.\n    \"\"\"\n    start_webserver()\n\n\n@cli.command()\n@click.pass_context\ndef worker(ctx: click.Context) -> None:\n    \"\"\"\n    Starts a Celery worker\n    \"\"\"\n    logger.info(\"Running Celery worker from CLI...\")\n    start_worker()\n"}
{"type": "source_file", "path": "src/fidesops/ops/core/__init__.py", "content": ""}
{"type": "source_file", "path": "src/fidesops/ops/api/__init__.py", "content": ""}
{"type": "source_file", "path": "src/fidesops/ops/api/deps.py", "content": "from typing import Generator\n\nfrom fideslib.db.session import get_db_engine, get_db_session\nfrom sqlalchemy.orm import Session\n\nfrom fidesops.ops.common_exceptions import FunctionalityNotConfigured\nfrom fidesops.ops.core.config import FidesopsConfig, config\nfrom fidesops.ops.util.cache import get_cache as get_redis_connection\n\n_engine = None\n\n\ndef get_config() -> FidesopsConfig:\n    \"\"\"Returns the config for use in dependency injection.\"\"\"\n    return config\n\n\ndef get_db() -> Generator:\n    \"\"\"Return our database session\"\"\"\n    if not config.database.enabled:\n        raise FunctionalityNotConfigured(\n            \"Application database required, but it is currently disabled! Please update your application configuration to enable integration with an application database.\"\n        )\n\n    try:\n        db = get_api_session()\n        yield db\n    finally:\n        db.close()\n\n\ndef get_db_for_health_check() -> Generator:\n    \"\"\"Gets a database session regardless of whether the application db is disabled, for a health check.\"\"\"\n    try:\n        db = get_api_session()\n        yield db\n    finally:\n        db.close()\n\n\ndef get_api_session() -> Session:\n    \"\"\"Gets the shared database session to use for API functionality\"\"\"\n    global _engine  # pylint: disable=W0603\n    if not _engine:\n        _engine = get_db_engine(config=config)\n    SessionLocal = get_db_session(config, engine=_engine)\n    db = SessionLocal()\n    return db\n\n\ndef get_cache() -> Generator:\n    \"\"\"Return a connection to our redis cache\"\"\"\n    if not config.redis.enabled:\n        raise FunctionalityNotConfigured(\n            \"Application redis cache required, but it is currently disabled! Please update your application configuration to enable integration with a redis cache.\"\n        )\n    yield get_redis_connection()\n"}
{"type": "source_file", "path": "src/fidesops/ops/api/v1/__init__.py", "content": ""}
{"type": "source_file", "path": "src/fidesops/ops/analytics.py", "content": "import logging\nimport os\nfrom platform import system\nfrom typing import Optional\n\nfrom fideslog.sdk.python.client import AnalyticsClient\nfrom fideslog.sdk.python.event import AnalyticsEvent\nfrom fideslog.sdk.python.exceptions import AnalyticsError\n\nfrom fidesops import __version__ as fidesops_version\nfrom fidesops.ops.core.config import config\n\nlogger = logging.getLogger(__name__)\n\n\ndef in_docker_container() -> bool:\n    \"\"\"`True` if the command was submitted within a Docker container. Default: `False`.\"\"\"\n    return bool(os.getenv(\"RUNNING_IN_DOCKER\") == \"true\")\n\n\ndef accessed_through_local_host(hostname: Optional[str]) -> bool:\n    \"\"\"`True`if the event was submitted through a local host, e,g, 127.0.0.1.\"\"\"\n    # testserver is hostname in unit tests\n    LOCAL_HOSTS = [\"localhost\", \"0.0.0.0\", \"127.0.0.1\", \"testserver\"]\n    return hostname in LOCAL_HOSTS\n\n\nanalytics_client = AnalyticsClient(\n    client_id=config.root_user.analytics_id,\n    developer_mode=config.dev_mode,\n    extra_data=None,\n    os=system(),\n    product_name=\"fidesops\",\n    production_version=fidesops_version,\n)\n\n\nasync def send_analytics_event(event: AnalyticsEvent) -> None:\n    if config.root_user.analytics_opt_out:\n        return\n    try:\n        await analytics_client._AnalyticsClient__send(  # pylint: disable=protected-access\n            event\n        )\n    except AnalyticsError as err:\n        logger.warning(\"Error sending analytics event: %s\", err)\n    else:\n        logger.info(\n            \"Analytics event sent: %s with client id: %s\",\n            event.event,\n            analytics_client.client_id,\n        )\n"}
