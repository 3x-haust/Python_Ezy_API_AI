{"repo_info": {"repo_name": "gulp", "repo_owner": "mentat-is", "repo_url": "https://github.com/mentat-is/gulp"}}
{"type": "test_file", "path": "src/gulp/api/rest/test_values.py", "content": "# test values for the API\n\nTEST_OPERATION_ID = \"test_operation\"\nTEST_CONTEXT_NAME = \"test_context\"\nTEST_CONTEXT_ID = \"66d98ed55d92b6b7382ffc77df70eda37a6efaa1\"  # test_context\nTEST_SOURCE_NAME = \"test_source\"\nTEST_SOURCE_ID_2 = \"fa144510fd16cf5ffbaeec79d68b593f3ba7e7e0\"  # name=test_source\nTEST_SOURCE_ID = (\n    \"fabae8858452af6c2acde7f90786b3de3a928289\"  # name=security_big_sample.evtx\n)\nTEST_INDEX = TEST_OPERATION_ID\nTEST_REQ_ID = \"test_req\"\nTEST_WS_ID = \"test_ws\"\nTEST_HOST = \"http://localhost:8080\"\nTEST_HOST_HTTPS = \"https://localhost:8080\"\n"}
{"type": "test_file", "path": "test_scripts/count_data_chunk.py", "content": "#!/usr/bin/env python3\nimport json\nimport sys\n\n# get args (min 1)\nif len(sys.argv) < 2:\n    print(\"Usage: count_data_chunk.py <path_to_json>\")\n    sys.exit(1)\n\njson_path = sys.argv[1]\nwith open(json_path) as f:\n    data = f.read()\n    js = json.loads(data)\n    print(\"number of docs in chunk: %d\" % len(js[\"data\"][\"docs\"]))\n"}
{"type": "test_file", "path": "test_scripts/count_json.py", "content": "#!/usr/bin/env python3\nimport json\nimport os\n\npwd = os.path.dirname(__file__)\npath = muty.file.safe_path_join(pwd, \"./test.json\")\nwith open(path, \"r\") as file:\n    data = json.load(file)\n\nnum_elements = len(data[\"data\"][\"category\"][\"buckets\"][0][\"histograms\"][\"buckets\"])\nprint(num_elements)\n"}
{"type": "test_file", "path": "test_scripts/count_lines.py", "content": "#!/usr/bin/env python3\n\nimport sys\nfrom pathlib import Path\n\n\ndef count_lines(file_path):\n    \"\"\"\n    Count the number of lines in a text file.\n\n    Args:\n        file_path (str): Path to the text file\n\n    Returns:\n        int: Number of lines in the file\n\n    Raises:\n        FileNotFoundError: If the file doesn't exist\n        IOError: If there's an error reading the file\n    \"\"\"\n    try:\n        # Convert string path to Path object\n        path = Path(file_path)\n\n        # Check if file exists\n        if not path.is_file():\n            raise FileNotFoundError(f\"File not found: {file_path}\")\n\n        # Open and count lines\n        with open(path, 'r', encoding='utf-8') as file:\n            line_count = sum(1 for line in file)\n\n        return line_count\n\n    except FileNotFoundError as e:\n        print(f\"Error: {e}\")\n        return None\n    except IOError as e:\n        print(f\"Error reading file: {e}\")\n        return None\n\n\ndef main():\n    # Check if filename was provided as command line argument\n    if len(sys.argv) != 2:\n        print(\"Usage: %s <filename>\" % (sys.argv[0]))\n        return\n\n    file_path = sys.argv[1]\n    result = count_lines(file_path)\n\n    if result is not None:\n        print(f\"Number of lines in {file_path}: {result}\")\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "test_file", "path": "test_scripts/create_mutated_raw.py", "content": "#!/usr/bin/env python3\n# filepath: json_anomaly_generator.py\n\nimport argparse\nimport copy\nimport datetime\nimport json\nimport random\nimport string\nimport sys\nimport uuid\nfrom typing import Any, Dict, List, Optional, Tuple, Union\n\nimport muty.string\n\n\ndef parse_arguments() -> argparse.Namespace:\n    \"\"\"\n    parse command line arguments for the anomaly generator\n\n    Args:\n        None\n\n    Returns:\n        argparse.Namespace: parsed command line arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"generate json elements with mutations\")\n    parser.add_argument(\"--elements\", type=int, default=2000,\n                        help=\"number of elements to generate (default: 2000)\")\n    parser.add_argument(\"--output\", type=str, default=\"./test_anomalies.json\",\n                        help=\"output file path (default: ./test_anomalies.json)\")\n    parser.add_argument(\"--field\", type=str, default=\"destination.port\",\n                        help=\"field to mutate (default: destination.port)\")\n    parser.add_argument(\"--num_mutations\", type=int, default=3,\n                        help=\"number of elements to mutate (default: 3)\")\n    parser.add_argument(\"--start_timestamp\", type=str,\n                        default=\"2022-06-07T15:30:20+00:00\",\n                        help=\"starting timestamp in ISO-8601 format (default: 2022-06-07T15:30:20+00:00)\")\n\n    return parser.parse_args()\n\n\ndef generate_random_id(length: int = 24) -> str:\n    \"\"\"\n    generate a random hexadecimal id\n\n    Args:\n        length: length of the id to generate\n\n    Returns:\n        str: random hexadecimal id\n    \"\"\"\n    return ''.join(random.choice('0123456789abcdef') for _ in range(length))\n\n\ndef get_nested_field(data: Dict[str, Any], field_path: str) -> Tuple[Any, bool]:\n    \"\"\"\n    get the value of a nested field in a dictionary using dot notation\n\n    Args:\n        data: dictionary to search in\n        field_path: path to the field using dot notation\n\n    Returns:\n        Tuple[Any, bool]: the value of the field and a boolean indicating if field exists\n    \"\"\"\n    # handle non-nested fields directly\n    if field_path in data:\n        return data[field_path], True\n\n    # handle nested fields with dot notation\n    keys = field_path.split('.')\n    current = data\n\n    for key in keys:\n        if not isinstance(current, dict) or key not in current:\n            return None, False\n        current = current[key]\n\n    return current, True\n\n\ndef set_nested_field(data: Dict[str, Any], field_path: str, value: Any) -> None:\n    \"\"\"\n    set the value of a nested field in a dictionary using dot notation\n\n    Args:\n        data: dictionary to modify\n        field_path: path to the field using dot notation\n        value: new value to set\n    \"\"\"\n    # handle non-nested fields directly\n    if field_path in data:\n        data[field_path] = value\n        return\n\n    # handle nested fields with dot notation\n    keys = field_path.split('.')\n    current = data\n\n    # navigate to the last parent\n    for key in keys[:-1]:\n        if key not in current:\n            current[key] = {}\n        current = current[key]\n\n    # set the value\n    current[keys[-1]] = value\n\n\ndef generate_mutation(original_value: Any) -> Any:\n    \"\"\"\n    generate a mutation based on the type of the original value\n\n    Args:\n        original_value: value to mutate\n\n    Returns:\n        Any: mutated value of the same type as the original\n    \"\"\"\n    # determine the type and generate an appropriate mutation\n    if isinstance(original_value, int):\n        # for integers, generate a different random integer\n        # avoid the original value\n        new_value = original_value\n        while new_value == original_value:\n            # common port range for network ports\n            new_value = random.randint(1, 65535)\n        return new_value\n\n    elif isinstance(original_value, float):\n        # for floats, generate a different random float\n        return original_value * random.uniform(0.5, 1.5)\n\n    elif isinstance(original_value, str):\n        # for strings, modify by adding some random characters\n        random_suffix = ''.join(random.choice(\n            string.ascii_letters) for _ in range(5))\n        return f\"{original_value}_{random_suffix}\"\n\n    elif isinstance(original_value, bool):\n        # for booleans, flip the value\n        return not original_value\n\n    else:\n        # for other types, return the original value\n        return original_value\n\n\ndef iso_to_nanoseconds(iso_timestamp: str) -> int:\n    \"\"\"\n    convert iso-8601 timestamp to nanoseconds from unix epoch\n\n    Args:\n        iso_timestamp: timestamp in iso-8601 format\n\n    Returns:\n        int: timestamp in nanoseconds\n    \"\"\"\n    # parse the iso timestamp\n    dt = datetime.datetime.fromisoformat(iso_timestamp.replace('Z', '+00:00'))\n\n    # convert to nanoseconds (seconds * 10^9)\n    return int(dt.timestamp() * 1_000_000_000)\n\n\ndef generate_timestamps(start_timestamp: str, interval_seconds: int,\n                        index: int) -> Tuple[str, int]:\n    \"\"\"\n    generate consecutive timestamps spaced by an interval\n\n    Args:\n        start_timestamp: starting timestamp in iso-8601 format\n        interval_seconds: seconds between consecutive timestamps\n        index: index of the current element\n\n    Returns:\n        Tuple[str, int]: tuple containing the iso timestamp and nanosecond timestamp\n    \"\"\"\n    # parse the starting timestamp\n    dt = datetime.datetime.fromisoformat(\n        start_timestamp.replace('Z', '+00:00'))\n\n    # add the appropriate interval based on index\n    new_dt = dt + datetime.timedelta(seconds=interval_seconds * index)\n\n    # format as iso-8601\n    iso_timestamp = new_dt.isoformat()\n\n    # convert to nanoseconds\n    nano_timestamp = iso_to_nanoseconds(iso_timestamp)\n\n    return iso_timestamp, nano_timestamp\n\n\ndef main() -> None:\n    \"\"\"\n    main function to generate json elements with targeted mutations\n\n    Args:\n        None\n\n    Returns:\n        None\n    \"\"\"\n    # parse command line arguments\n    args = parse_arguments()\n\n    # base json template\n    base_template = {\n        \"_id\": \"60e7b1b4b3f1b1b1b1b1b1b1\",\n        \"@timestamp\": \"2022-06-07T15:30:20+00:00\",\n        \"gulp.timestamp\": 1654615820000000000,\n        \"gulp.operation_id\": \"test_operation\",\n        \"gulp.context_id\": \"aa12e662778fe5cdad22371f9cd8d2a55484c513\",\n        \"gulp.source_id\": \"949e4f4e0463d5b51ec9dac32b9aea806400e809\",\n        \"log.file.path\": \"C:\\\\Users\\\\co29617\\\\Desktop\\\\Incidente 183651\\\\T4VDI1001R-017 winevt\\\\Security.evtx\",\n        \"agent.type\": \"query_splunk\",\n        \"event.original\": \"06/07/2022 05:30:20 PM\\nLogName=Security\\nEventCode=5156\\nEventType=0\\nComputerName=T4VDI1001R-017.ad04.eni.intranet\\nSourceName=Microsoft Windows security auditing.\\nType=Informazioni\\nRecordNumber=1224403878\\nKeywords=Controllo riuscito\\nTaskCategory=Filtering Platform Connection\\nOpCode=Informazioni\\nMessage=Connessione consentita da Piattaforma filtro Windows.\\r\\n\\r\\nInformazioni sull'applicazione:\\r\\n\\tID processo:\\t\\t18268\\r\\n\\tNome applicazione:\\t\\\\device\\\\harddiskvolume2\\\\program files\\\\intergraph smart licensing\\\\client\\\\islclient.exe\\r\\n\\r\\nInformazioni di rete:\\r\\n\\tDirezione:\\t\\tIn uscita\\r\\n\\tIndirizzo di origine:\\t\\t::1\\r\\n\\tPorta di origine:\\t\\t61904\\r\\n\\tIndirizzo di destinazione:\\t::1\\r\\n\\tPorta di destinazione:\\t\\t8088\\r\\n\\tProtocollo:\\t\\t6\\r\\n\\r\\nInformazioni sul filtro:\\r\\n\\tID run-time filtro:\\t65692\\r\\n\\tNome livello:\\t\\tConnetti\\r\\n\\tID run-time livello:\\t50\\n\",\n        \"event.sequence\": 56403,\n        \"event.code\": \"WinEventLog:Security\",\n        \"gulp.event_code\": 6560703015527673681,\n        \"event.duration\": 1,\n        \"winlog.computer_name\": \"T4VDI1001R-017.ad04.eni.intranet\",\n        \"destination.port\": 8088,\n        \"source.port\": 61904,\n        \"gulp.unmapped.Protocollo\": \"6\",\n        \"gulp.unmapped.RecordNumber\": \"1224403878\",\n        \"gulp.unmapped.SourceName\": \"Microsoft Windows security auditing.\",\n        \"gulp.unmapped.TaskCategory\": \"Filtering Platform Connection\",\n        \"gulp.unmapped.Type\": \"Informazioni\",\n        \"host.name\": \"test_host\",\n        \"gulp.unmapped.index\": \"incidente_183651\"\n    }\n\n    # check if the field exists in the template\n    original_value, field_exists = get_nested_field(base_template, args.field)\n    if not field_exists:\n        print(f\"error: field '{args.field}' not found in the template\")\n        sys.exit(1)\n\n    # validate number of mutations\n    if args.num_mutations > args.elements:\n        print(\n            f\"error: number of mutations ({args.num_mutations}) cannot be greater than total elements ({args.elements})\")\n        sys.exit(1)\n\n    # generate elements\n    elements = []\n    mutation_indices = random.sample(range(args.elements), args.num_mutations)\n    mutated_elements = []\n\n    for i in range(args.elements):\n        # create a deep copy of the template\n        element = copy.deepcopy(base_template)\n\n        # set a random _id for each element\n        element[\"_id\"] = generate_random_id()\n\n        # set consecutive timestamps, time interval is a random between 1 and 10 seconds\n        time_interval = random.randint(1, 10)\n        iso_timestamp, nano_timestamp = generate_timestamps(\n            args.start_timestamp,\n            time_interval,\n            i\n        )\n        element[\"@timestamp\"] = iso_timestamp\n        element[\"gulp.timestamp\"] = nano_timestamp\n\n        # generate random event.original and update associated fields\n        event_original = muty.string.generate_unique()\n        element[\"event.original\"] = event_original\n        element[\"event.sequence\"] = i\n\n        # apply mutation if this element is selected for mutation\n        if i in mutation_indices:\n            # get the original value\n            original_value, _ = get_nested_field(element, args.field)\n\n            # generate a mutated value\n            mutated_value = generate_mutation(original_value)\n\n            # set the mutated value\n            set_nested_field(element, args.field, mutated_value)\n\n            # save the mutated element for later output\n            mutated_element_info = {\n                \"index\": i,\n                \"id\": element[\"_id\"],\n                \"timestamp\": element[\"@timestamp\"],\n                \"original_value\": original_value,\n                \"mutated_value\": mutated_value\n            }\n            mutated_elements.append(mutated_element_info)\n\n        elements.append(element)\n\n    # write to output file\n    try:\n        with open(args.output, 'w') as f:\n            json.dump(elements, f, indent=2)\n        print(f\"successfully wrote {args.elements} elements to {args.output}\")\n    except Exception as e:\n        print(f\"error writing to file: {e}\")\n        sys.exit(1)\n\n    # output summary information\n    print(f\"total elements: {args.elements}\")\n    print(f\"mutated elements: {args.num_mutations}\")\n    print(f\"start timestamp: {args.start_timestamp}\")\n    print(f\"end timestamp: {elements[-1]['@timestamp']}\")\n    print(\"mutated elements details:\")\n    for elem in mutated_elements:\n        print(\n            f\"  index: {elem['index']}, id: {elem['id']}, timestamp: {elem['timestamp']}, field: {args.field}, original: {elem['original_value']}, mutated: {elem['mutated_value']}\")\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "test_file", "path": "test_scripts/restart_gulp.py", "content": "#!/usr/bin/env python3\n\"\"\"\nscript to restart gulp by calling /restart_server endpoint with an admin token\n\"\"\"\nimport argparse\nimport asyncio\nimport logging\nimport os\nimport sys\n\n# add the project root directory to Python path\nfrom gulp.api.rest.test_values import TEST_HOST, TEST_REQ_ID, TEST_WS_ID\n\n\ndef _parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Restart gulp by calling /restart_server.\"\n    )\n    parser.add_argument(\"--host\", default=\"http://localhost:8080\", help=\"Gulp host\")\n    return parser.parse_args()\n\n\nasync def main():\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    project_root = os.path.dirname(script_dir)  # Go up one level to /gulp\n    sys.path.append(project_root)\n\n    from muty.log import MutyLogger\n\n    from gulp.api.rest.client.common import GulpAPICommon\n    from gulp.api.rest.client.user import GulpAPIUser\n    from gulp.api.rest.client.utility import GulpAPIUtility\n\n    MutyLogger.get_instance(\"restart_gulp\", level=logging.DEBUG)\n    args = _parse_args()\n    GulpAPICommon.get_instance().init(\n        host=args.host,\n        ws_id=TEST_WS_ID,\n        req_id=TEST_REQ_ID,\n    )\n    token = await GulpAPIUser.login_admin()\n    await GulpAPIUtility.restart_server(token)\n\n    # done\n    MutyLogger.get_instance().info(\"DONE!\")\n\n\nif __name__ == \"__main__\":\n    sys.exit(asyncio.run(main()))\n"}
{"type": "test_file", "path": "tests/ingest/__init__.py", "content": ""}
{"type": "test_file", "path": "test_scripts/query_external.py", "content": "#!/usr/bin/env python3\nimport argparse\nimport asyncio\nimport json\nimport sys\n\nimport pytest\nimport pytest_asyncio\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.opensearch.query import GulpQueryParameters\nfrom gulp.api.rest.client.common import GulpAPICommon, _test_init\nfrom gulp.api.rest.client.db import GulpAPIDb\nfrom gulp.api.rest.client.query import GulpAPIQuery\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import (\n    TEST_HOST,\n    TEST_OPERATION_ID,\n    TEST_REQ_ID,\n    TEST_WS_ID,\n)\nfrom gulp.api.ws_api import GulpQueryDonePacket, GulpWsAuthPacket\nfrom gulp.structs import GulpPluginParameters\n\n\"\"\"\nexample usage:\n\n./test_scripts/query_external.py \\\n    --q 'sourcetype=\"WinEventLog:Security\" Nome_applicazione=\"\\\\\\\\device\\\\\\\\harddiskvolume2\\\\\\\\program files\\\\\\\\intergraph smart licensing\\\\\\\\client\\\\\\\\islclient.exe\"' \\\n    --plugin splunk --operation_id test_operation --reset --ingest \\\n    --plugin_params '{\n        \"custom_parameters\":  {\n            \"uri\": \"http://localhost:8089\",\n            \"username\": \"admin\",\n            \"password\": \"Valerino74!\",\n            \"index\": \"incidente_183651\"\n        },\n        \"override_chunk_size\": 200,\n        \"additional_mapping_files\": [[ \"windows.json\", \"windows\" ]]\n}'\n\"\"\"\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init()\n\n\nSPLUNK_RAW_Q = \"EventCode=5156\"  # all\nSPLUNK_PLUGIN = \"splunk\"\n\n\ndef _parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"tests gulp 'query_external' endpoint.\"\n    )\n    parser.add_argument(\n        \"--username\",\n        help=\"Gulp user name\",\n        default=\"ingest\",\n    )\n    parser.add_argument(\n        \"--password\",\n        help=\"Gulp user password\",\n        default=\"ingest\",\n    )\n    parser.add_argument(\"--host\", default=TEST_HOST, help=\"Gulp host\")\n    parser.add_argument(\n        \"--operation_id\",\n        default=TEST_OPERATION_ID,\n        help=\"Gulp operation_id\",\n    )\n    parser.add_argument(\n        \"--plugin\",\n        default=SPLUNK_PLUGIN,\n        help=\"Plugin to be used\",\n    )\n    parser.add_argument(\"--ws_id\", default=TEST_WS_ID, help=\"Websocket id\")\n    parser.add_argument(\"--req_id\", default=TEST_REQ_ID, help=\"Request id\")\n    parser.add_argument(\n        \"--ingest\", action=\"store_true\", help=\"Ingest data\", default=False\n    )\n    parser.add_argument(\n        \"--preview-mode\",\n        action=\"store_true\",\n        help=\"Preview mode (ignores --ingest)\",\n        default=False,\n    )\n    parser.add_argument(\"--q\", default=SPLUNK_RAW_Q, help=\"Query to be used\")\n    parser.add_argument(\"--q_options\", default=None, help=\"GulpQueryParameters as JSON\")\n    parser.add_argument(\n        \"--plugin_params\",\n        default=None,\n        help=\"GulpPluginParameters as JSON\",\n        required=True,\n    )\n    parser.add_argument(\n        \"--reset\",\n        action=\"store_true\",\n        help=\"reset gulp first\",\n        default=False,\n    )\n    return parser.parse_args()\n\n\nasync def query_external(args):\n\n    MutyLogger.get_instance(name=\"query_external_test\").debug(\"args=%s\", args)\n\n    GulpAPICommon.get_instance().init(\n        host=args.host, ws_id=args.ws_id, req_id=args.req_id\n    )\n    if args.reset:\n        # reset first\n        MutyLogger.get_instance().info(\"resetting gulp !\")\n        token = await GulpAPIUser.login(\"admin\", \"admin\")\n        await GulpAPIDb.gulp_reset(token)\n\n    # login\n    token = await GulpAPIUser.login(args.username, args.password)\n    _, ws_host = args.host.split(\"://\")\n    ws_url = f\"ws://{ws_host}/ws\"\n\n    async with websockets.connect(ws_url) as ws:\n        # connect websocket\n        p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=TEST_WS_ID)\n        await ws.send(p.model_dump_json(exclude_none=True))\n\n        # receive responses\n        try:\n            while True:\n                response = await ws.recv()\n                data = json.loads(response)\n                if data[\"type\"] == \"ws_connected\":\n                    # perform query\n                    q_options = args.q_options or \"{}\"\n                    # query\n                    q_options: GulpQueryParameters = (\n                        GulpQueryParameters.model_validate_json(args.q_options)\n                        if args.q_options\n                        else GulpQueryParameters()\n                    )\n                    MutyLogger.get_instance().debug(\n                        \"plugin_params=%s\", json.loads(args.plugin_params)\n                    )\n                    plugin_params: GulpPluginParameters = (\n                        GulpPluginParameters.model_validate_json(args.plugin_params)\n                    )\n                    q_options.name = \"test_raw_query_splunk\"\n                    if not plugin_params.override_chunk_size:\n                        plugin_params.override_chunk_size = 1000  # force if not set\n\n                    if args.preview_mode:\n                        args.ingest = False\n                        q_options.preview_mode = True\n\n                    # dump structs before running the query\n                    MutyLogger.get_instance().debug(\"q_options=%s\", q_options)\n\n                    await GulpAPIQuery.query_external(\n                        token,\n                        args.operation_id,\n                        q=[args.q],\n                        plugin=args.plugin,\n                        plugin_params=plugin_params,\n                        q_options=q_options,\n                        ingest=args.ingest,\n                    )\n                elif data[\"type\"] == \"query_done\":\n                    q_done_packet: GulpQueryDonePacket = (\n                        GulpQueryDonePacket.model_validate(data[\"data\"])\n                    )\n                    MutyLogger.get_instance().debug(\n                        \"query done, packet=%s\", q_done_packet\n                    )\n                    if q_done_packet.name == q_options.name:\n                        if q_done_packet.status != \"done\":\n                            MutyLogger.get_instance().error(\n                                f\"query failed: {q_done_packet}\"\n                            )\n                            break\n                        MutyLogger.get_instance().info(\"DONE: %s\" % (q_done_packet))\n                    break\n\n        except websockets.exceptions.ConnectionClosed as ex:\n            MutyLogger.get_instance().exception(ex)\n\n\ndef main():\n    args = _parse_args()\n    return asyncio.run(query_external(args))\n\n\n# add a main\nif __name__ == \"__main__\":\n    sys.exit(main())\n"}
{"type": "test_file", "path": "tests/ingest/test_ingest.py", "content": "import asyncio\nimport json\nimport os\nimport platform\nimport random\nimport shutil\nimport string\nimport tempfile\nfrom datetime import datetime, timedelta\n\nimport muty.crypto\nimport muty.file\nimport muty.string\nimport pytest\nimport pytest_asyncio\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.mapping.models import GulpMapping, GulpMappingField\nfrom gulp.api.opensearch.filters import GulpIngestionFilter\nfrom gulp.api.rest.client.common import (\n    GulpAPICommon,\n    _test_ingest_generic,\n    _test_ingest_ws_loop,\n    _test_init,\n)\nfrom gulp.api.rest.client.db import GulpAPIDb\nfrom gulp.api.rest.client.ingest import GulpAPIIngest\nfrom gulp.api.rest.client.operation import GulpAPIOperation\nfrom gulp.api.rest.client.query import GulpAPIQuery\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import (\n    TEST_CONTEXT_NAME,\n    TEST_HOST,\n    TEST_INDEX,\n    TEST_OPERATION_ID,\n    TEST_REQ_ID,\n    TEST_WS_ID,\n)\nfrom gulp.api.ws_api import GulpWsAuthPacket, GulpWsIngestPacket\nfrom gulp.structs import GulpPluginParameters\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\n@pytest.mark.run(order=1)\nasync def test_ingest_account():\n    \"\"\"\n    test guest account cannot ingest\n    \"\"\"\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    samples_dir = os.path.join(current_dir, \"../../samples/win_evtx\")\n    file_path = os.path.join(samples_dir, \"Security_short_selected.evtx\")\n\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n\n    # ingest the file (guest cannot)\n    await GulpAPIIngest.ingest_file(\n        token=guest_token,\n        file_path=file_path,\n        operation_id=TEST_OPERATION_ID,\n        context_name=TEST_CONTEXT_NAME,\n        plugin=\"win_evtx\",\n        expected_status=401,\n    )\n    MutyLogger.get_instance().info(test_ingest_account.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\n@pytest.mark.run(order=2)\nasync def test_failed_upload():\n    \"\"\"\n    simulate a failed upload and reupload with resume after\n    \"\"\"\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    samples_dir = os.path.join(current_dir, \"../../samples/win_evtx\")\n    file_path = os.path.join(samples_dir, \"Security_short_selected.evtx\")\n\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    # get full file size\n    file_size = os.path.getsize(file_path)\n    file_sha1 = await muty.crypto.hash_sha1_file(file_path)\n\n    # copy to a temporary file, using a smaller size\n    tmp_dir = os.path.join(tempfile.gettempdir(), \"gulp\")\n    os.makedirs(tmp_dir, exist_ok=True)\n    temp_file_path = os.path.join(tmp_dir, os.path.basename(file_path))\n    with open(file_path, \"rb\") as f:\n        with open(temp_file_path, \"wb\") as f2:\n            f2.write(f.read(file_size - 100))\n    try:\n        # ingest the partial file, it will fail\n        await GulpAPIIngest.ingest_file(\n            token=ingest_token,\n            file_path=temp_file_path,\n            operation_id=TEST_OPERATION_ID,\n            context_name=TEST_CONTEXT_NAME,\n            plugin=\"win_evtx\",\n            file_sha1=file_sha1,\n            total_file_size=file_size,\n            expected_status=206,\n        )\n\n        # ingest the real file, starting from file_size - 100\n        await GulpAPIIngest.ingest_file(\n            token=ingest_token,\n            file_path=file_path,\n            operation_id=TEST_OPERATION_ID,\n            context_name=TEST_CONTEXT_NAME,\n            plugin=\"win_evtx\",\n            file_sha1=file_sha1,\n            total_file_size=file_size,\n            restart_from=file_size - 100,\n        )\n\n        await _test_ingest_ws_loop(check_ingested=7, check_processed=7)\n    finally:\n        shutil.rmtree(tmp_dir)\n    MutyLogger.get_instance().info(test_failed_upload.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\n@pytest.mark.run(order=3)\nasync def test_skipped_records():\n    \"\"\"\n    simulate skipped records due to duplicate ingestion\n    \"\"\"\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    samples_dir = os.path.join(current_dir, \"../../samples/win_evtx\")\n    file_path = os.path.join(samples_dir, \"Security_short_selected.evtx\")\n\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    # ingest first\n    await GulpAPIIngest.ingest_file(\n        token=ingest_token,\n        file_path=file_path,\n        operation_id=TEST_OPERATION_ID,\n        context_name=TEST_CONTEXT_NAME,\n        plugin=\"win_evtx\",\n    )\n    await _test_ingest_ws_loop(check_ingested=7, check_processed=7)\n\n    # ingest same file again, use another req_id\n    await GulpAPIIngest.ingest_file(\n        token=ingest_token,\n        file_path=file_path,\n        operation_id=TEST_OPERATION_ID,\n        context_name=TEST_CONTEXT_NAME,\n        plugin=\"win_evtx\",\n        req_id=\"req_id_2\",\n    )\n    await _test_ingest_ws_loop(check_ingested=0, check_processed=7, check_skipped=7)\n    MutyLogger.get_instance().info(test_skipped_records.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\n@pytest.mark.run(order=4)\nasync def test_ingest_filter():\n    \"\"\"\n    test ingestion filter\n    \"\"\"\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    samples_dir = os.path.join(current_dir, \"../../samples/win_evtx\")\n    file_path = os.path.join(samples_dir, \"Security_short_selected.evtx\")\n\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    # ingest the file\n    flt = GulpIngestionFilter(time_range=[0, 1467213874345999999])\n    await GulpAPIIngest.ingest_file(\n        token=ingest_token,\n        file_path=file_path,\n        operation_id=TEST_OPERATION_ID,\n        context_name=TEST_CONTEXT_NAME,\n        plugin=\"win_evtx\",\n        flt=flt,\n    )\n\n    await _test_ingest_ws_loop(check_ingested=1, check_processed=7)\n\n    await GulpAPIUser.login_admin_and_reset_operation(TEST_OPERATION_ID)\n\n    # ingest another part\n    flt = GulpIngestionFilter(time_range=[1467213874345999999, 0])\n    await GulpAPIIngest.ingest_file(\n        token=ingest_token,\n        file_path=file_path,\n        operation_id=TEST_OPERATION_ID,\n        context_name=TEST_CONTEXT_NAME,\n        plugin=\"win_evtx\",\n        flt=flt,\n    )\n\n    await _test_ingest_ws_loop(check_ingested=6, check_processed=7)\n    MutyLogger.get_instance().info(test_ingest_filter.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\n@pytest.mark.run(order=5)\nasync def test_raw():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    raw_chunk_path = os.path.join(current_dir, \"raw_chunk.json\")\n    buf = await muty.file.read_file_async(raw_chunk_path)\n    raw_chunk = json.loads(buf)\n\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    # ingest raw chunk with \"raw\" plugin\n    await GulpAPIIngest.ingest_raw(\n        token=ingest_token,\n        raw_data=raw_chunk,\n        operation_id=TEST_OPERATION_ID,\n    )\n    # wait ws\n    await _test_ingest_ws_loop(check_ingested=3)  # , check_on_source_done=True)\n\n    # ingest another\n    MutyLogger.get_instance().debug(\"ingesting another chunk ...\")\n    for r in raw_chunk:\n        # randomize event original\n        r[\"event.original\"] = muty.string.generate_unique()\n    await GulpAPIIngest.ingest_raw(\n        token=ingest_token,\n        raw_data=raw_chunk,\n        operation_id=TEST_OPERATION_ID,\n    )\n    await _test_ingest_ws_loop(check_ingested=6) # plus the 3 above, we're using the same req_id\n\n    MutyLogger.get_instance().info(test_raw.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\n@pytest.mark.run(order=6)\nasync def test_ingest_ws_raw():\n    \"\"\"\n    tests websocket ingestion of raw data\n    \"\"\"\n\n    def _generate_random_chunk(template_chunk: dict, size=1000):\n        \"\"\"\n        randomize the given template chunk\n        \"\"\"\n        base_timestamp = datetime(2019, 7, 1)\n        result = []\n        contexts = [\"context1\", \"context2\", \"context3\"]\n        sources = [\"source1\", \"source2\", \"source3\"]\n\n        for i in range(size):\n            new_docs = []\n            for doc in template_chunk:\n                new_doc = {}\n                for key, value in doc.items():\n                    if key == \"@timestamp\":\n                        # sequential timestamps\n                        new_doc[key] = (\n                            base_timestamp + timedelta(minutes=i)\n                        ).isoformat() + \".000Z\"\n                    elif isinstance(value, str):\n                        if key == \"event.code\":\n                            new_doc[key] = f\"event_code_{random.randint(1, 1000)}\"\n                        else:\n                            # leave gulp.operation_id as is\n                            if key == \"gulp.operation_id\":\n                                new_doc[key] = value\n                            elif key == \"gulp.context_id\":\n                                # use one of the contexts\n                                new_doc[key] = contexts[random.randint(0, 2)]\n                            elif key == \"gulp.source_id\":\n                                # use one of the sources\n                                new_doc[key] = sources[random.randint(0, 2)]\n                            else:\n                                # random string of similar length\n                                new_doc[key] = \"\".join(\n                                    random.choices(\n                                        string.ascii_letters + string.digits,\n                                        k=len(value),\n                                    )\n                                )\n                    elif isinstance(value, int):\n                        # Random integer between 0 and 1000\n                        new_doc[key] = random.randint(0, 1000)\n                new_docs.append(new_doc)\n            result.extend(new_docs)\n        return result\n\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    raw_chunk_path = os.path.join(current_dir, \"raw_chunk.json\")\n    buf = await muty.file.read_file_async(raw_chunk_path)\n    raw_chunk = json.loads(buf)\n\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    _, host = TEST_HOST.split(\"://\")\n    ws_url = f\"ws://{host}/ws_ingest_raw\"\n    test_completed = False\n\n    async with websockets.connect(ws_url) as ws:\n        # connect websocket\n        p: GulpWsAuthPacket = GulpWsAuthPacket(\n            token=ingest_token, ws_id=TEST_WS_ID\n        )\n        await ws.send(p.model_dump_json(exclude_none=True))\n\n        # receive responses\n        try:\n            while True:\n                response = await ws.recv()\n                data = json.loads(response)\n                if data[\"type\"] == \"ws_connected\":\n                    for i in range(2):\n                        # send chunk\n                        p: GulpWsIngestPacket = GulpWsIngestPacket(\n                            docs=_generate_random_chunk(raw_chunk, size=1000),\n                            index=TEST_INDEX,\n                            operation_id=TEST_OPERATION_ID,\n                            context_name=TEST_CONTEXT_NAME,\n                            source=\"test_source\",\n                            req_id=TEST_REQ_ID,\n                            ws_id=TEST_WS_ID,\n                        )\n                        await ws.send(p.model_dump_json(exclude_none=True))\n                        await asyncio.sleep(0.1)\n\n                    # TODO: check data, but should be ok ....\n                    test_completed = True\n                    break\n\n                # ws delay\n                await asyncio.sleep(0.1)\n\n        except websockets.exceptions.ConnectionClosed as ex:\n            MutyLogger.get_instance().exception(ex)\n\n    assert test_completed\n    await asyncio.sleep(10)\n    op = await GulpAPIOperation.operation_get_by_id(\n        token=ingest_token, operation_id=TEST_OPERATION_ID\n    )\n    assert op[\"doc_count\"] == 6000\n    MutyLogger.get_instance().info(test_ingest_ws_raw.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_win_evtx():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    samples_dir = os.path.join(current_dir, \"../../samples/win_evtx\")\n    file_path = os.path.join(samples_dir, \"Security_short_selected.evtx\")\n\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    # ingest the file\n    await GulpAPIIngest.ingest_file(\n        token=ingest_token,\n        file_path=file_path,\n        operation_id=TEST_OPERATION_ID,\n        context_name=TEST_CONTEXT_NAME,\n        plugin=\"win_evtx\",\n    )\n\n    await _test_ingest_ws_loop(check_ingested=7, check_processed=7)\n    MutyLogger.get_instance().info(test_win_evtx.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_win_evtx_multiple():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    samples_dir = os.path.join(current_dir, \"../../samples/win_evtx\")\n    files = muty.file.list_directory(samples_dir, recursive=True, files_only=True)\n    await _test_ingest_generic(files, plugin=\"win_evtx\", check_ingested=98633)\n    MutyLogger.get_instance().info(test_win_evtx_multiple.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_csv_standalone():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/mftecmd/sample_record.csv\")]\n    plugin_params = GulpPluginParameters(\n        mappings={\n            \"test_mapping\": GulpMapping(\n                fields={\"Created0x10\": GulpMappingField(ecs=\"@timestamp\")}\n            )\n        }\n    )\n    await _test_ingest_generic(\n        files, \"csv\", check_ingested=10, plugin_params=plugin_params\n    )\n    MutyLogger.get_instance().info(test_csv_standalone.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_csv_file_mapping():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/mftecmd/sample_record.csv\")]\n    plugin_params = GulpPluginParameters(\n        mapping_file=\"mftecmd_csv.json\", mapping_id=\"record\"\n    )\n    await _test_ingest_generic(\n        files, \"csv\", check_ingested=44, check_processed=10, plugin_params=plugin_params\n    )\n    MutyLogger.get_instance().info(test_csv_file_mapping.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_csv_stacked():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/mftecmd/sample_record.csv\")]\n    plugin_params = GulpPluginParameters(\n        mappings={\n            \"test_mapping\": GulpMapping(\n                fields={\"Created0x10\": GulpMappingField(ecs=\"@timestamp\")}\n            )\n        }\n    )\n    await _test_ingest_generic(\n        files, \"stacked_example\", check_ingested=10, plugin_params=plugin_params\n    )\n\n    # check at least one document ...\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    doc = await GulpAPIQuery.query_single_id(\n        guest_token, TEST_OPERATION_ID, \"d3bd618f59c8b001d77c6c8edc729b0a\"\n    )\n    assert doc[\"event.duration\"] == 9999\n    assert doc[\"enriched\"]\n    MutyLogger.get_instance().info(test_csv_stacked.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_ingest_zip():\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    test_zip = os.path.join(current_dir, \"test_ingest_zip.zip\")\n\n    # ingest raw chunk\n    await GulpAPIIngest.ingest_zip(\n        token=ingest_token,\n        file_path=test_zip,\n        operation_id=TEST_OPERATION_ID,\n        context_name=TEST_CONTEXT_NAME,\n    )\n\n    # wait ws\n    await _test_ingest_ws_loop(check_ingested=13779, check_processed=13745)\n    MutyLogger.get_instance().info(test_ingest_zip.__name__ + \" succeeded!\")\n\n\n@pytest.mark.skipif(\n    platform.system() == \"Darwin\", reason=\"systemd journal tests not supported on macOS\"\n)\n@pytest.mark.asyncio\nasync def test_systemd_journal():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/systemd_journal/system.journal\")]\n    await _test_ingest_generic(files, \"systemd_journal\", 9243)\n    MutyLogger.get_instance().info(test_systemd_journal.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_win_reg():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/win_reg/NTUSER.DAT\")]\n    await _test_ingest_generic(files, \"win_reg\", 1206)\n    MutyLogger.get_instance().info(test_win_reg.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_eml():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/eml/sample.eml\")]\n    await _test_ingest_generic(files, \"eml\", 1)\n    MutyLogger.get_instance().info(test_eml.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_mbox():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/mbox/sample.mbox\")]\n    await _test_ingest_generic(files, \"mbox\", 16)\n    MutyLogger.get_instance().info(test_mbox.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_chrome_history():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/sqlite/chrome_history\")]\n    await _test_ingest_generic(files, \"chrome_history_sqlite_stacked\", 19)\n    MutyLogger.get_instance().info(test_chrome_history.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_chrome_webdata():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/sqlite/chrome_webdata\")]\n    await _test_ingest_generic(\n        files, \"chrome_webdata_sqlite_stacked\", 2, check_processed=1\n    )\n    MutyLogger.get_instance().info(test_chrome_webdata.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_pfsense():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/pfsense/filter.log\")]\n    await _test_ingest_generic(files, \"pfsense\", 61)\n    MutyLogger.get_instance().info(test_pfsense.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_pcap():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [\n        os.path.join(current_dir, \"../../samples/pcap/220614_ip_flags_google.pcapng\")\n    ]\n    await _test_ingest_generic(files, \"pcap\", 58)\n    MutyLogger.get_instance().info(test_pcap.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_teamviewer_regex_stacked():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [\n        os.path.join(current_dir, \"../../samples/teamviewer/connections_incoming.txt\")\n    ]\n    await _test_ingest_generic(files, \"teamviewer_regex_stacked\", 2)\n    MutyLogger.get_instance().info(\n        test_teamviewer_regex_stacked.__name__ + \" succeeded!\"\n    )\n\n\n@pytest.mark.asyncio\nasync def test_apache_access_clf():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/apache_clf/access.log\")]\n    await _test_ingest_generic(files, \"apache_access_clf\", 1311)\n    MutyLogger.get_instance().info(test_apache_access_clf.__name__ + \" succeeded!\")\n\n\n@pytest.mark.asyncio\nasync def test_apache_error_clf():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    files = [os.path.join(current_dir, \"../../samples/apache_clf/error.log\")]\n    await _test_ingest_generic(files, \"apache_error_clf\", 1178)\n    MutyLogger.get_instance().info(test_apache_error_clf.__name__ + \" succeeded!\")\n"}
{"type": "test_file", "path": "tests/query/test_query_external.py", "content": "#!/usr/bin/env python3\nimport asyncio\nimport json\n\nimport pytest\nimport pytest_asyncio\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.opensearch.query import GulpQueryParameters\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.query import GulpAPIQuery\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import TEST_HOST, TEST_INDEX, TEST_OPERATION_ID, TEST_WS_ID\nfrom gulp.api.ws_api import GulpQueryDonePacket, GulpWsAuthPacket\nfrom gulp.structs import GulpPluginParameters\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init()\n\n\n@pytest.mark.asyncio\nasync def test_elasticsearch():\n    async def _test_raw_external(token: str, ingest: bool = False):\n        _, host = TEST_HOST.split(\"://\")\n        ws_url = f\"ws://{host}/ws\"\n        test_completed = False\n\n        async with websockets.connect(ws_url) as ws:\n            # connect websocket\n            p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=TEST_WS_ID)\n            await ws.send(p.model_dump_json(exclude_none=True))\n\n            # receive responses\n            try:\n                while True:\n                    response = await ws.recv()\n                    data = json.loads(response)\n\n                    if data[\"type\"] == \"ws_connected\":\n                        # run test\n                        q_options = GulpQueryParameters()\n                        plugin_params: GulpPluginParameters = GulpPluginParameters()\n                        q_options.name = \"test_external_elasticsearch\"\n                        q_options.group = \"test group\"\n                        plugin_params.additional_mapping_files = [\n                            (\"windows.json\", \"windows\")\n                        ]\n                        plugin_params.custom_parameters[\"uri\"] = \"http://localhost:9200\"\n                        plugin_params.custom_parameters[\"username\"] = \"admin\"\n                        plugin_params.custom_parameters[\"password\"] = \"Gulp1234!\"\n                        plugin_params.custom_parameters[\"index\"] = TEST_INDEX\n                        plugin_params.custom_parameters[\"is_elasticsearch\"] = (\n                            False  # we are querying gulp's opensearch\n                        )\n\n                        # 1 hits\n                        from tests.query.test_query_api import TEST_QUERY_RAW\n\n                        await GulpAPIQuery.query_external(\n                            token,\n                            TEST_OPERATION_ID,\n                            q=[TEST_QUERY_RAW],\n                            plugin=\"query_elasticsearch\",\n                            plugin_params=plugin_params,\n                            q_options=q_options,\n                            ingest=ingest,\n                        )\n                    elif data[\"type\"] == \"query_done\":\n                        # query done\n                        q_done_packet: GulpQueryDonePacket = (\n                            GulpQueryDonePacket.model_validate(data[\"data\"])\n                        )\n                        MutyLogger.get_instance().debug(\n                            \"query done, packet=%s\", q_done_packet\n                        )\n                        if q_done_packet.name == \"test_external_elasticsearch\":\n                            assert q_done_packet.total_hits == 1\n                            test_completed = True\n                        else:\n                            raise ValueError(\n                                f\"unexpected query name: {q_done_packet.name}\"\n                            )\n                        break\n\n                    # ws delay\n                    await asyncio.sleep(0.1)\n\n            except websockets.exceptions.ConnectionClosed as ex:\n                MutyLogger.get_instance().exception(ex)\n\n        assert test_completed\n        MutyLogger.get_instance().info(_test_raw_external.__name__ + \" succeeded!\")\n\n    # ingest some data\n    from tests.ingest.test_ingest import test_win_evtx\n\n    await test_win_evtx()\n\n    # TODO: better test, this uses gulp's opensearch .... should work, but better to be sure\n    # login\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n    await _test_raw_external(token=guest_token) \n"}
{"type": "test_file", "path": "tests/test_glyph.py", "content": "import os\nimport pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpCollabType\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.glyph import GulpAPIGlyph\nfrom gulp.api.rest.client.object_acl import GulpAPIObjectACL\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import TEST_CONTEXT_ID, TEST_OPERATION_ID\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_glyph():\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    edit_token = await GulpAPIUser.login(\"editor\", \"editor\")\n    assert edit_token\n    # power user can delete glyphs, editor not\n    power_token = await GulpAPIUser.login(\"power\", \"power\")\n    assert power_token\n\n    # delete all exysting glyph first\n    l = await GulpAPIGlyph.glyph_list(edit_token)\n    for glyph in l:\n        try:\n            await GulpAPIGlyph.glyph_delete(edit_token, glyph[\"id\"], expected_status=401)\n            await GulpAPIGlyph.glyph_delete(power_token, glyph[\"id\"])\n        except:\n            pass\n    l = await GulpAPIGlyph.glyph_list(edit_token)\n    assert not l\n    pwd = os.path.dirname(os.path.abspath(__file__))\n    \n    # guest cannot create\n    st = await GulpAPIGlyph.glyph_create(\n        guest_token,\n        img_path=os.path.join(pwd, \"./user.png\"),\n        name=\"user_test_glyph\",\n        expected_status=401,\n    )\n\n    st = await GulpAPIGlyph.glyph_create(\n        edit_token,\n        img_path=os.path.join(pwd, \"./user.png\"),\n        name=\"user_test_glyph\",\n    )\n    assert st\n    assert st[\"name\"] == \"user_test_glyph\"\n\n    # name filter\n    l = await GulpAPIGlyph.glyph_list(\n        guest_token,\n        GulpCollabFilter(\n            names=[\"*ser_test_gly*\"],\n        ),\n    )\n    assert len(l) == 1\n    assert l[0][\"id\"] == st[\"id\"]\n\n    l = await GulpAPIGlyph.glyph_list(\n        guest_token,\n        GulpCollabFilter(names=[\"aaaaa*\"]),\n    )\n    assert not l  # 0 len\n\n    # update\n    await GulpAPIGlyph.glyph_update(\n        edit_token, st[\"id\"], img_path=os.path.join(pwd, \"./user.png\"), name=\"glyph\"\n    )\n    st = await GulpAPIGlyph.glyph_get_by_id(guest_token, st[\"id\"])\n    assert st[\"name\"] == \"glyph\"\n\n    # make glyph private\n    st_id = st[\"id\"]\n    await GulpAPIObjectACL.object_make_private(\n        edit_token, st[\"id\"], GulpCollabType.GLYPH\n    )\n    st = await GulpAPIGlyph.glyph_get_by_id(guest_token, st[\"id\"], expected_status=401)\n    l = await GulpAPIGlyph.glyph_list(\n        guest_token,\n        GulpCollabFilter(\n            names=[\"glyph\"],\n        ),\n    )\n    assert not l\n\n    await GulpAPIObjectACL.object_make_public(edit_token, st_id, GulpCollabType.GLYPH)\n    st = await GulpAPIGlyph.glyph_get_by_id(guest_token, st_id)\n    assert st\n    l = await GulpAPIGlyph.glyph_list(\n        guest_token,\n        GulpCollabFilter(\n            names=[\"glyph\"],\n        ),\n    )\n    assert len(l) == 1\n\n    # delete\n    await GulpAPIGlyph.glyph_delete(power_token, st[\"id\"])\n    l = await GulpAPIGlyph.glyph_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert not l\n\n    MutyLogger.get_instance().info(test_glyph.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "tests/test_highlight.py", "content": "import pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpCollabType\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.highlight import GulpAPIHighlight\nfrom gulp.api.rest.client.link import GulpAPILink\nfrom gulp.api.rest.client.object_acl import GulpAPIObjectACL\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import TEST_CONTEXT_ID, TEST_OPERATION_ID\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_highlight():\n    # ingest some data\n    from tests.ingest.test_ingest import test_win_evtx\n\n    await test_win_evtx()\n    source_id = \"64e7c3a4013ae243aa13151b5449aac884e36081\"\n    doc_id = \"c8869c95f8e92be5e86d6b1f03a50252\"\n\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    edit_token = await GulpAPIUser.login(\"editor\", \"editor\")\n    assert edit_token\n\n    h = await GulpAPIHighlight.highlight_create(\n        guest_token,\n        operation_id=TEST_OPERATION_ID,\n        source_id=source_id,\n        time_range=[1000000, 2000000],\n        expected_status=401,\n    )\n\n    h = await GulpAPIHighlight.highlight_create(\n        edit_token,\n        operation_id=TEST_OPERATION_ID,\n        source_id=source_id,\n        time_range=[1000000, 2000000],\n    )\n    assert h\n    assert h[\"source_id\"] == source_id\n\n    # doc filter\n    l = await GulpAPIHighlight.highlight_list(\n        guest_token,\n        GulpCollabFilter(source_ids=[source_id], operation_ids=[TEST_OPERATION_ID]),\n    )\n    assert len(l) == 1\n    assert l[0][\"id\"] == h[\"id\"]\n\n    l = await GulpAPIHighlight.highlight_list(\n        guest_token,\n        GulpCollabFilter(operation_ids=[TEST_OPERATION_ID], source_ids=[\"aaaa\"]),\n    )\n    assert not l  # 0 len\n\n    # update\n    await GulpAPIHighlight.highlight_update(\n        edit_token, h[\"id\"], color=\"black\", time_range=[2000000, 3000000]\n    )\n    h = await GulpAPIHighlight.highlight_get_by_id(guest_token, h[\"id\"])\n    assert h[\"color\"] == \"black\"\n    assert h[\"time_range\"] == [2000000, 3000000]\n\n    # make private\n    h_id = h[\"id\"]\n    await GulpAPIObjectACL.object_make_private(\n        edit_token, h[\"id\"], GulpCollabType.HIGHLIGHT\n    )\n    h = await GulpAPIHighlight.highlight_get_by_id(\n        guest_token, h_id, expected_status=401\n    )\n    l = await GulpAPIHighlight.highlight_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert not l\n\n    await GulpAPIObjectACL.object_make_public(\n        edit_token, h_id, GulpCollabType.HIGHLIGHT\n    )\n    h = await GulpAPIHighlight.highlight_get_by_id(guest_token, h_id)\n    assert h\n\n    # delete\n    await GulpAPIHighlight.highlight_delete(edit_token, h_id)\n    l = await GulpAPIHighlight.highlight_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert not l\n\n    MutyLogger.get_instance().info(test_highlight.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "tests/test_link.py", "content": "import pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpCollabType\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.link import GulpAPILink\nfrom gulp.api.rest.client.object_acl import GulpAPIObjectACL\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import TEST_CONTEXT_ID, TEST_OPERATION_ID\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_link():\n    doc_id = \"c8869c95f8e92be5e86d6b1f03a50252\"\n    target_doc_ids = [\n        \"9d6f4d014b7dd9f5f65ce43f3c142749\",\n        \"7090d29202d7cd8b57c30fa14202ac37\",\n    ]\n\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    edit_token = await GulpAPIUser.login(\"editor\", \"editor\")\n    assert edit_token\n\n    lnk = await GulpAPILink.link_create(\n        guest_token,\n        operation_id=TEST_OPERATION_ID,\n        doc_id_from=doc_id,\n        doc_ids=target_doc_ids,\n        expected_status=401,\n    )\n\n    lnk = await GulpAPILink.link_create(\n        edit_token,\n        operation_id=TEST_OPERATION_ID,\n        doc_id_from=doc_id,\n        doc_ids=target_doc_ids,\n    )\n    assert lnk\n    assert lnk[\"doc_id_from\"] == doc_id\n\n    # doc filter\n    l = await GulpAPILink.link_list(\n        guest_token,\n        GulpCollabFilter(\n            doc_ids=[target_doc_ids[0]],\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert len(l) == 1\n    assert l[0][\"id\"] == lnk[\"id\"]\n\n    l = await GulpAPILink.link_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID], doc_ids=[\"aaaaa\"]\n        ),\n    )\n    assert not l  # 0 len\n\n    # update\n    await GulpAPILink.link_update(\n        edit_token, lnk[\"id\"], doc_ids=[\"aaaaa\"], color=\"black\"\n    )\n    lnk = await GulpAPILink.link_get_by_id(guest_token, lnk[\"id\"])\n    assert lnk[\"color\"] == \"black\"\n    assert lnk[\"doc_ids\"] == [\"aaaaa\"]\n\n    # make link private\n    lnk_id=lnk[\"id\"]\n    await GulpAPIObjectACL.object_make_private(\n        edit_token, lnk[\"id\"], GulpCollabType.LINK\n    )\n    lnk = await GulpAPILink.link_get_by_id(guest_token, lnk[\"id\"], expected_status=401)\n    l = await GulpAPILink.link_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert not l\n\n    await GulpAPIObjectACL.object_make_public(\n        edit_token, lnk_id, GulpCollabType.LINK\n    )\n    lnk = await GulpAPILink.link_get_by_id(guest_token, lnk_id)\n    assert lnk\n\n    # delete\n    await GulpAPILink.link_delete(edit_token, lnk[\"id\"])\n    l = await GulpAPILink.link_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert not l\n\n    MutyLogger.get_instance().info(test_link.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "tests/test_note.py", "content": "\nimport pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpCollabType\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.note import GulpAPINote\nfrom gulp.api.rest.client.object_acl import GulpAPIObjectACL\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import (\n    TEST_CONTEXT_ID,\n    TEST_OPERATION_ID,\n)\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_note():\n    \"\"\"\n    test notes and ACL\n    \"\"\"\n\n    # ingest some data\n    from tests.ingest.test_ingest import test_win_evtx\n\n    await test_win_evtx()\n    source_id = \"64e7c3a4013ae243aa13151b5449aac884e36081\"\n    doc_id = \"c8869c95f8e92be5e86d6b1f03a50252\"\n\n    # create note\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    edit_token = await GulpAPIUser.login(\"editor\", \"editor\")\n    assert edit_token\n\n    note1 = await GulpAPINote.note_create(\n        guest_token,\n        operation_id=TEST_OPERATION_ID,\n        context_id=TEST_CONTEXT_ID,\n        source_id=source_id,\n        text=\"pinned note 1\",\n        time_pin=1000000,\n        name=\"test_pinned_note\",\n        tags=[\"test\"],\n        color=\"blue\",\n        expected_status=401,\n    )\n\n    note1 = await GulpAPINote.note_create(\n        edit_token,\n        operation_id=TEST_OPERATION_ID,\n        context_id=TEST_CONTEXT_ID,\n        source_id=source_id,\n        text=\"pinned note 1\",\n        time_pin=1000000,\n        name=\"test_pinned_note\",\n        tags=[\"test\"],\n        color=\"blue\",\n    )\n\n    note2 = await GulpAPINote.note_create(\n        edit_token,\n        operation_id=TEST_OPERATION_ID,\n        context_id=TEST_CONTEXT_ID,\n        source_id=source_id,\n        text=\"pinned note 2\",\n        time_pin=1100000,\n        name=\"test_pinned_note_2\",\n        tags=[\"test\"],\n        color=\"blue\",\n    )\n\n    note3 = await GulpAPINote.note_create(\n        edit_token,\n        operation_id=TEST_OPERATION_ID,\n        context_id=TEST_CONTEXT_ID,\n        source_id=source_id,\n        text=\"pinned note 3\",\n        docs=[\n            {\n                \"_id\": doc_id,\n                \"@timestamp\": \"2021-01-01T00:00:00Z\",\n                \"gulp.timestamp\": 1609459200000000000,\n                \"gulp.operation_id\": TEST_OPERATION_ID,\n                \"gulp.context_id\": TEST_CONTEXT_ID,\n                \"gulp.source_id\": source_id,\n            }\n        ],\n        name=\"test_pinned_note_3\",\n        tags=[\"test\"],\n        color=\"blue\",\n    )\n\n    # doc filter\n    l = await GulpAPINote.note_list(\n        guest_token,\n        GulpCollabFilter(\n            doc_ids=[doc_id],\n            operation_ids=[TEST_OPERATION_ID],\n            context_ids=[TEST_CONTEXT_ID],\n            source_ids=[source_id],\n        ),\n    )\n    assert len(l) == 1\n    assert l[0][\"id\"] == note3[\"id\"]\n\n    # doc time range filter\n    l = await GulpAPINote.note_list(\n        guest_token,\n        GulpCollabFilter(\n            doc_time_range=(1609459100000000000, 1609459300000000000),\n            operation_ids=[TEST_OPERATION_ID],\n            context_ids=[TEST_CONTEXT_ID],\n            source_ids=[source_id],\n        ),\n    )\n    assert len(l) == 1\n    assert l[0][\"id\"] == note3[\"id\"]\n\n    # time pin filter\n    l = await GulpAPINote.note_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n            context_ids=[TEST_CONTEXT_ID],\n            source_ids=[source_id],\n            time_pin_range=(1000000, 1100000),\n        ),\n    )\n    assert len(l) == 2\n\n    # update\n    await GulpAPINote.note_update(edit_token, note1[\"id\"], text=\"modified\")\n    note1 = await GulpAPINote.note_get_by_id(guest_token, note1[\"id\"])\n    assert note1[\"text\"] == \"modified\"\n    assert note1[\"edits\"]\n\n    # delete\n    await GulpAPINote.note_delete(edit_token, note1[\"id\"])\n\n    # list without filter, 2 notes (was 3, 1 deleted)\n    l = await GulpAPINote.note_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n            context_ids=[TEST_CONTEXT_ID],\n            source_ids=[source_id],\n        ),\n    )\n    assert len(l) == 2\n\n    # make note2 private\n    await GulpAPIObjectACL.object_make_private(\n        guest_token, note2[\"id\"], GulpCollabType.NOTE, expected_status=401\n    )\n    await GulpAPIObjectACL.object_make_private(\n        edit_token,\n        note2[\"id\"],\n        GulpCollabType.NOTE,\n    )\n    l = await GulpAPINote.note_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n            context_ids=[TEST_CONTEXT_ID],\n            source_ids=[source_id],\n        ),\n    )\n\n    # only note 3 is visible to guest\n    assert len(l) == 1\n    assert l[0][\"id\"] == note3[\"id\"]\n\n    # make public again\n    await GulpAPIObjectACL.object_make_public(\n        edit_token,\n        note2[\"id\"],\n        GulpCollabType.NOTE,\n    )\n    l = await GulpAPINote.note_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n            context_ids=[TEST_CONTEXT_ID],\n            source_ids=[source_id],\n        ),\n    )\n    assert len(l) == 2\n    MutyLogger.get_instance().info(test_note.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "test_scripts/__init__.py", "content": ""}
{"type": "test_file", "path": "test_scripts/count_strings.py", "content": "#!/usr/bin/env python3\nimport sys\n\n\ndef count_string_in_file(search_string, filename):\n    total_occurrences = 0\n    line_count = 0\n\n    try:\n        with open(filename, \"r\") as file:\n            for line in file:\n                line_count += 1\n                total_occurrences += line.count(search_string)\n\n        print(f\"Found {total_occurrences} occurrences of '{search_string}'\")\n        print(f\"Total lines processed: {line_count}\")\n\n    except FileNotFoundError:\n        print(f\"Error: File '{filename}' not found\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Error: {str(e)}\")\n        sys.exit(1)\n\n\ndef main():\n    if len(sys.argv) != 3:\n        print(\"Usage: python string_counter.py <search_string> <filename>\")\n        sys.exit(1)\n\n    search_string = sys.argv[1]\n    filename = sys.argv[2]\n    count_string_in_file(search_string, filename)\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "test_file", "path": "test_scripts/ingest.py", "content": "#!/usr/bin/env python3\n\"\"\"\nscript to test gulp ingestion api, simulates multiple client processes ingesting files in parallel\n\ncurl is used to send the files to the gulp ingestion api, to be as much close as possible to a real client.\n\"\"\"\n\nimport argparse\nimport asyncio\nimport json\nimport logging\nimport os\nimport subprocess\nimport sys\nfrom multiprocessing import Pool\n\nimport muty.crypto\nimport muty.file\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.rest.test_values import (\n    TEST_CONTEXT_NAME,\n    TEST_OPERATION_ID,\n    TEST_REQ_ID,\n    TEST_WS_ID,\n)\nfrom gulp.api.ws_api import GulpWsAuthPacket\n\n\ndef _parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Spawn n curl processes in parallel for file ingestion.\"\n    )\n    parser.add_argument(\n        \"--username\",\n        help=\"user name\",\n        default=\"ingest\",\n    )\n    parser.add_argument(\n        \"--password\",\n        help=\"user password\",\n        default=\"ingest\",\n    )\n    parser.add_argument(\"--path\", help=\"File or directory path.\", metavar=\"FILEPATH\")\n    parser.add_argument(\n        \"--raw\",\n        help='a JSON file with raw data for the \"raw\" plugin, --path is ignored if this is set',\n    )\n    parser.add_argument(\"--host\", default=\"http://localhost:8080\", help=\"Gulp host\")\n    parser.add_argument(\n        \"--operation_id\",\n        default=TEST_OPERATION_ID,\n        help=\"Gulp operation_id\",\n    )\n    parser.add_argument(\n        \"--context_name\",\n        default=TEST_CONTEXT_NAME,\n        help=\"Gulp context_name\",\n    )\n    parser.add_argument(\n        \"--plugin\",\n        default=\"win_evtx\",\n        help=\"Plugin to be used, ignored if --raw is set or file is a zip\",\n    )\n    parser.add_argument(\"--ws_id\", default=TEST_WS_ID, help=\"Websocket id\")\n    parser.add_argument(\"--req_id\", default=TEST_REQ_ID, help=\"Request id\")\n    parser.add_argument(\n        \"--flt\",\n        default=None,\n        help=\"GulpIngestionFilter as JSON\",\n    )\n    parser.add_argument(\n        \"--plugin_params\",\n        default=None,\n        help=\"GulpPluginParameters as JSON, ignored if ingesting a zip file (use metadata.json)\",\n    )\n    parser.add_argument(\n        \"--continue_offset\",\n        type=int,\n        default=0,\n        help=\"Offset to continue upload from\",\n    )\n    parser.add_argument(\n        \"--reset\",\n        action=\"store_true\",\n        help=\"reset gulp first\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--preview-mode\",\n        action=\"store_true\",\n        help=\"preview mode: no ingestion, no stats, no ws, ignored with --raw\",\n        default=False,\n    )\n    return parser.parse_args()\n\n\ndef _create_ingest_curl_command(file_path: str, file_total: int, raw_chunk: dict, args):\n    def _create_payload(file_path, raw_chunk, args, is_zip=False):\n        payload = {\"flt\": json.loads(args.flt) if args.flt else {}}\n\n        if not is_zip:\n            payload[\"plugin_params\"] = (\n                json.loads(args.plugin_params) if args.plugin_params else {}\n            )\n            payload[\"original_file_path\"] = file_path\n        if raw_chunk:\n            payload[\"chunk\"] = raw_chunk\n        else:\n            # add file sha1\n            sha1_hash = asyncio.run(muty.crypto.hash_sha1_file(file_path))\n            payload[\"file_sha1\"] = sha1_hash\n\n        return json.dumps(payload)\n\n    def _get_common_headers(args, file_size=None):\n        # create headers array with token, size, continue_offset\n        headers = [\n            (\"-H\", \"content-type: multipart/form-data\"),\n            (\"-H\", f\"token: {args.token or 'null'}\"),\n        ]\n        if file_size:\n            headers.extend(\n                [\n                    (\"-H\", f\"size: {file_size}\"),\n                    (\"-H\", f\"continue_offset: {args.continue_offset}\"),\n                ]\n            )\n        return headers\n\n    is_zip = file_path and file_path.lower().endswith(\".zip\")\n    preview_mode = args.preview_mode\n    base_url = f\"{args.host}\"\n    command = [\"curl\", \"-v\", \"-X\", \"POST\"]\n    payload = _create_payload(file_path, raw_chunk, args, is_zip)\n    temp_file_path = None\n\n    if raw_chunk:\n        # raw request\n        url = f\"{base_url}/ingest_raw\"\n        params = f\"plugin=raw&operation_id={args.operation_id}&context_name={args.context_name}&source=raw_source&ws_id={args.ws_id}&req_id={args.req_id}\"\n        command.extend(\n            [\n                \"-H\",\n                f\"token: {args.token or 'null'}\",\n                f\"{url}?{params}\",\n                \"-H\",\n                \"content-type: application/json\",\n                \"-d\",\n                payload,\n            ]\n        )\n    else:\n        # file upload request\n        full_file_size = os.path.getsize(file_path)\n        continue_offset = int(args.continue_offset)\n        if args.continue_offset > 0:\n            # handling restart using a truncated temp file\n            MutyLogger.get_instance().info(\n                \"restarting %s from %d\" % (file_path, continue_offset)\n            )\n            temp_file_path = \"/tmp/%s\" % (os.path.basename(file_path))\n            with open(file_path, \"rb\") as f:\n                f.seek(continue_offset)\n                with open(temp_file_path, \"wb\") as tf:\n                    tf.write(f.read())\n            file_path = temp_file_path\n\n        upload_file_size = os.path.getsize(file_path)\n        MutyLogger.get_instance().info(f\"uploading size: {upload_file_size}\")\n\n        if is_zip:\n            url = f\"{base_url}/ingest_zip\"\n            params = f\"operation_id={args.operation_id}&context_name={args.context_name}&ws_id={args.ws_id}&req_id={args.req_id}\"\n            file_type = \"application/zip\"\n        else:\n            url = f\"{base_url}/ingest_file\"\n            params = f\"operation_id={args.operation_id}&context_name={args.context_name}&plugin={\n                args.plugin}&ws_id={args.ws_id}&req_id={args.req_id}&file_total={file_total}&preview_mode={preview_mode}\"\n\n            file_type = \"application/octet-stream\"\n\n        command.extend(\n            [\n                f\"{url}?{params}\",\n                *[\n                    item\n                    for pair in _get_common_headers(args, full_file_size)\n                    for item in pair\n                ],\n                \"-F\",\n                f\"payload={payload}; type=application/json\",\n                \"-F\",\n                f\"f=@{file_path};type={file_type}\",\n            ]\n        )\n\n    return command, temp_file_path\n\n\ndef _run_curl(file_path: str, file_total: int, raw: dict, args):\n    MutyLogger.get_instance(\"test_ingest_worker-%d\" % (os.getpid())).debug(\"_run_curl\")\n\n    command, tmp_file_path = _create_ingest_curl_command(\n        file_path, file_total, raw, args\n    )\n\n    # copy file to a temporary location and truncate to args.continue_offset\n    # print curl command line\n    cmdline = \" \".join(command)\n    MutyLogger.get_instance().debug(f\"CURL:\\n{cmdline}\")\n    subprocess.run(command)\n\n    if tmp_file_path:\n        # remove temp file\n        muty.file.delete_file_or_dir(tmp_file_path)\n\n\ndef _login(host, username, password, req_id, ws_id) -> str:\n    MutyLogger.get_instance().info(\"logging in %s\" % (username))\n    login_command = [\n        \"curl\",\n        \"-v\",\n        \"-X\",\n        \"POST\",\n        \"-H\",\n        \"Content-Type: application/json\",\n        \"--data\",\n        json.dumps({\"user_id\": username, \"password\": password}),\n        f\"{host}/login?req_id={req_id}&ws_id={ws_id}\",\n    ]\n    MutyLogger.get_instance().info(f\"login command: {login_command}\")\n    login_response = subprocess.run(login_command, capture_output=True)\n    if login_response.returncode != 0:\n        MutyLogger.get_instance().error(\"login failed\")\n        sys.exit(1)\n    MutyLogger.get_instance().debug(login_response.stdout)\n    token = json.loads(login_response.stdout)[\"data\"][\"token\"]\n    return token\n\n\ndef _reset(host, req_id, ws_id):\n    MutyLogger.get_instance().info(\"resetting gulp\")\n    admin_token = _login(host, \"admin\", \"admin\", req_id, ws_id)\n    reset_command = [\n        \"curl\",\n        \"-v\",\n        \"-H\",\n        f\"token: {admin_token}\",\n        \"-X\",\n        \"POST\",\n        f\"{host}/gulp_reset?req_id={req_id}\",\n    ]\n    MutyLogger.get_instance().info(f\"reset command: {reset_command}\")\n    reset_response = subprocess.run(reset_command, capture_output=True)\n    if reset_response.returncode != 0:\n        MutyLogger.get_instance().error(\"reset failed\")\n        sys.exit(1)\n    MutyLogger.get_instance().debug(reset_response.stdout)\n\n\ndef _ws_loop(host: str, token: str, ws_id: str):\n    \"\"\"\n    consumes websocket data until ingestion is finished\n    \"\"\"\n\n    async def _ws_loop_internal(host: str, token: str, ws_id: str):\n\n        # connect to websocket\n        MutyLogger.get_instance(\"ws_loop\").info(\"ws loop running!\")\n\n        _, host = host.split(\"://\")\n        ws_url = f\"ws://{host}/ws\"\n        async with websockets.connect(ws_url) as ws:\n            # connect websocket\n            p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=ws_id)\n            await ws.send(p.model_dump_json(exclude_none=True))\n\n            # receive responses\n            try:\n                while True:\n                    response = await ws.recv()\n                    data = json.loads(response)\n                    if data[\"type\"] == \"stats_update\":\n                        # MutyLogger.get_instance().error(f\"data: {data}\")\n                        d = data[\"data\"][\"data\"]\n                        if d[\"status\"] != \"ongoing\":\n                            MutyLogger.get_instance().info(f\"stats: {d}\")\n                            break\n\n                    # ws delay\n                    await asyncio.sleep(0.1)\n\n            except websockets.exceptions.ConnectionClosed as ex:\n                MutyLogger.get_instance().exception(ex)\n\n        MutyLogger.get_instance().info(\"ingestion finished!\")\n\n    try:\n        asyncio.run(_ws_loop_internal(host, token, ws_id))\n    except Exception as ex:\n        MutyLogger.get_instance().exception(ex)\n        raise\n\n\ndef main():\n    MutyLogger.get_instance(\"test_ingest\", level=logging.DEBUG)\n    args = _parse_args()\n\n    if args.path and args.raw:\n        MutyLogger.get_instance().error(\"only one of --path or --raw can be set\")\n        sys.exit(1)\n    if not args.path and not args.raw:\n        MutyLogger.get_instance().error(\"either --path or --raw must be set\")\n        sys.exit(1)\n\n    if args.reset:\n        # reset first\n        _reset(args.host, args.req_id, args.ws_id)\n\n    # get an ingest token\n    args.token = _login(\n        args.host, args.username, args.password, args.req_id, args.ws_id\n    )\n\n    if args.path:\n        path = os.path.abspath(os.path.expanduser(args.path))\n        if os.path.isdir(path):\n            files = muty.file.list_directory(path, recursive=True, files_only=True)\n        else:\n            files = [path]\n        raw = None\n        MutyLogger.get_instance().info(f\"files to ingest: {files}\")\n    else:\n        # raw data is set, ignore path\n        with open(args.raw) as f:\n            raw = json.loads(f.read())\n        files = None\n        MutyLogger.get_instance().info(\"raw data loaded.\")\n\n    # spawn curl processes\n    with Pool() as pool:\n        # run the loop\n        pool.apply_async(\n            _ws_loop, kwds={\"host\": args.host, \"token\": args.token, \"ws_id\": args.ws_id}\n        )\n\n        # run requests\n        if raw:\n            l = pool.starmap(_run_curl, [(None, 1, raw, args)])\n        else:\n            l = pool.starmap(\n                _run_curl, [(file, len(files), None, args) for file in files]\n            )\n\n        # wait for all processes to finish\n        pool.close()\n        pool.join()\n\n    # done\n    MutyLogger.get_instance().info(\"DONE!\")\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "test_file", "path": "tests/query/test_query_api.py", "content": "#!/usr/bin/env python3\nimport asyncio\nimport json\nimport os\nimport time\n\nimport muty.file\nimport pytest\nimport pytest_asyncio\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpCollabType\nfrom gulp.api.opensearch.filters import GulpQueryFilter\nfrom gulp.api.opensearch.query import GulpQueryParameters\nfrom gulp.api.rest.client.common import GulpAPICommon, _test_ingest_ws_loop, _test_init\nfrom gulp.api.rest.client.db import GulpAPIDb\nfrom gulp.api.rest.client.ingest import GulpAPIIngest\nfrom gulp.api.rest.client.note import GulpAPINote\nfrom gulp.api.rest.client.object_acl import GulpAPIObjectACL\nfrom gulp.api.rest.client.operation import GulpAPIOperation\nfrom gulp.api.rest.client.query import GulpAPIQuery\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import (\n    TEST_CONTEXT_ID,\n    TEST_HOST,\n    TEST_INDEX,\n    TEST_OPERATION_ID,\n    TEST_REQ_ID,\n    TEST_WS_ID,\n)\nfrom gulp.api.ws_api import (\n    GulpQueryDonePacket,\n    GulpQueryGroupMatchPacket,\n    GulpWsAuthPacket,\n)\n\nTEST_QUERY_RAW = {\n    \"query\": {\n        \"query_string\": {\n            \"query\": \"event.code: 4625 AND (gulp.operation_id: %s)\"\n            % (TEST_OPERATION_ID),\n        }\n    }\n}\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init()\n    # GulpAPICommon.get_instance().init(\n    #     host=TEST_HOST, ws_id=TEST_WS_ID, req_id=TEST_REQ_ID, index=TEST_INDEX\n    # )\n    # admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    # assert admin_token\n    # await GulpAPIDb.postgres_reset_collab(admin_token, full_reset=False)\n\n\n@pytest.mark.asyncio\nasync def test_queries():\n    \"\"\"\n    NOTE: assumes the test windows samples in ./samples/win_evtx are ingested\n\n    and the gulp server running on http://localhost:8080\n    \"\"\"\n\n    async def _test_sigma_zip(token: str):\n        # read sigmas\n        current_dir = os.path.dirname(os.path.realpath(__file__))\n        sigma_zip_path = os.path.join(current_dir, \"sigma/windows.zip\")\n\n        _, host = TEST_HOST.split(\"://\")\n        ws_url = f\"ws://{host}/ws\"\n        test_completed = False\n\n        async with websockets.connect(\n            ws_url,\n            ping_interval=30,  # less frequent pings (default is 20)\n            ping_timeout=30,  # longer timeout (default is 10)\n            close_timeout=15,  # give more time for close frame\n        ) as ws:\n            # connect websocket\n            p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=TEST_WS_ID)\n            await ws.send(p.model_dump_json(exclude_none=True))\n            num_done: int = 0\n\n            # receive responses\n            try:\n                while True:\n                    response = await ws.recv()\n                    data = json.loads(response)\n\n                    if data[\"type\"] == \"ws_connected\":\n                        # run test\n                        q_options = GulpQueryParameters()\n                        q_options.group = \"test group\"\n                        q_options.note_parameters.create_notes = False\n                        await GulpAPIQuery.query_sigma_zip(\n                            token,\n                            sigma_zip_path,\n                            TEST_OPERATION_ID,\n                            \"win_evtx\",\n                            q_options,\n                        )\n                    elif data[\"type\"] == \"query_done\":\n                        # query done\n                        num_done += 1\n                        q_done_packet: GulpQueryDonePacket = (\n                            GulpQueryDonePacket.model_validate(data[\"data\"])\n                        )\n                        MutyLogger.get_instance().debug(\n                            \"query done, name=%s, matches=%d, num_done=%d\"\n                            % (q_done_packet.name, q_done_packet.total_hits, num_done)\n                        )\n                        if num_done == 1209:\n                            test_completed = True\n                            break\n\n                    # ping the server\n                    if num_done % 100 == 0:\n                        await ws.ping()\n\n                    # ws delay\n                    await asyncio.sleep(0.1)\n\n            except websockets.exceptions.ConnectionClosed as ex:\n                MutyLogger.get_instance().exception(ex)\n            except Exception as ex:\n                MutyLogger.get_instance().exception(ex)\n\n        assert test_completed\n        MutyLogger.get_instance().info(_test_sigma_zip.__name__ + \" succeeded!\")\n\n    async def _test_sigma_group(token: str):\n        # read sigmas\n        current_dir = os.path.dirname(os.path.realpath(__file__))\n\n        sigma_match_some = await muty.file.read_file_async(\n            os.path.join(current_dir, \"sigma/match_some.yaml\")\n        )\n\n        sigma_match_some_more = await muty.file.read_file_async(\n            os.path.join(current_dir, \"sigma/match_some_more.yaml\")\n        )\n\n        _, host = TEST_HOST.split(\"://\")\n        ws_url = f\"ws://{host}/ws\"\n        test_completed = False\n\n        async with websockets.connect(ws_url) as ws:\n            # connect websocket\n            p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=TEST_WS_ID)\n            await ws.send(p.model_dump_json(exclude_none=True))\n\n            # receive responses\n            try:\n                while True:\n                    response = await ws.recv()\n                    data = json.loads(response)\n\n                    if data[\"type\"] == \"ws_connected\":\n                        # run test\n                        q_options = GulpQueryParameters()\n                        q_options.group = \"test group\"\n                        await GulpAPIQuery.query_sigma(\n                            token,\n                            TEST_OPERATION_ID,\n                            \"win_evtx\",\n                            [\n                                sigma_match_some.decode(),\n                                sigma_match_some_more.decode(),\n                            ],\n                            q_options,\n                        )\n                    elif data[\"type\"] == \"query_done\":\n                        # query done\n                        q_done_packet: GulpQueryDonePacket = (\n                            GulpQueryDonePacket.model_validate(data[\"data\"])\n                        )\n                        MutyLogger.get_instance().debug(\n                            \"query done, name=%s\", q_done_packet.name\n                        )\n                        if q_done_packet.name == \"match_some_event_sequence_numbers\":\n                            assert q_done_packet.total_hits == 3\n                        elif (\n                            q_done_packet.name\n                            == \"match_some_more_event_sequence_numbers\"\n                        ):\n                            assert q_done_packet.total_hits == 2\n                        else:\n                            raise ValueError(\n                                f\"unexpected query name: {q_done_packet.name}\"\n                            )\n                    elif data[\"type\"] == \"query_group_match\":\n                        # query done\n                        q_group_match_packet: GulpQueryGroupMatchPacket = (\n                            GulpQueryGroupMatchPacket.model_validate(data[\"data\"])\n                        )\n                        MutyLogger.get_instance().debug(\n                            \"query group match, name=%s\", q_group_match_packet.name\n                        )\n                        if q_group_match_packet.name == \"test group\":\n                            assert q_group_match_packet.total_hits == 5\n\n                            # check notes creation on postgres, there should be 5 nots with \"test_group\" in the tags\n                            flt = GulpCollabFilter(tags=[\"test group\"])\n                            notes = await GulpAPINote.note_list(token, flt)\n                            MutyLogger.get_instance().debug(\n                                \"notes: %s\", json.dumps(notes, indent=2)\n                            )\n                            assert len(notes) == 5\n                            test_completed = True\n                        else:\n                            raise ValueError(\n                                f\"unexpected query group name: {\n                                    q_done_packet.name}\"\n                            )\n                        break\n\n                    # ws delay\n                    await asyncio.sleep(0.1)\n\n            except websockets.exceptions.ConnectionClosed as ex:\n                MutyLogger.get_instance().exception(ex)\n\n        assert test_completed\n        MutyLogger.get_instance().info(_test_sigma_group.__name__ + \" succeeded!\")\n\n    async def _test_sigma_single(token: str):\n        # read sigma\n        current_dir = os.path.dirname(os.path.realpath(__file__))\n        sigma_match_some = await muty.file.read_file_async(\n            os.path.join(current_dir, \"sigma/match_some.yaml\")\n        )\n\n        _, host = TEST_HOST.split(\"://\")\n        ws_url = f\"ws://{host}/ws\"\n        test_completed = False\n\n        async with websockets.connect(ws_url) as ws:\n            # connect websocket\n            p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=TEST_WS_ID)\n            await ws.send(p.model_dump_json(exclude_none=True))\n\n            # receive responses\n            try:\n                while True:\n                    response = await ws.recv()\n                    data = json.loads(response)\n\n                    if data[\"type\"] == \"ws_connected\":\n                        # run test\n                        await GulpAPIQuery.query_sigma(\n                            token,\n                            TEST_OPERATION_ID,\n                            plugin=\"win_evtx\",\n                            sigmas=[\n                                sigma_match_some.decode(),\n                            ],\n                        )\n                    elif data[\"type\"] == \"query_done\":\n                        # query done\n                        q_done_packet: GulpQueryDonePacket = (\n                            GulpQueryDonePacket.model_validate(data[\"data\"])\n                        )\n                        MutyLogger.get_instance().debug(\n                            \"query done, name=%s\", q_done_packet.name\n                        )\n                        if q_done_packet.name == \"match_some_event_sequence_numbers\":\n                            assert q_done_packet.total_hits == 3\n                            test_completed = True\n                        else:\n                            raise ValueError(\n                                f\"unexpected query name: {q_done_packet.name}\"\n                            )\n                        break\n\n                    # ws delay\n                    await asyncio.sleep(0.1)\n\n            except websockets.exceptions.ConnectionClosed as ex:\n                MutyLogger.get_instance().exception(ex)\n\n        assert test_completed\n        MutyLogger.get_instance().info(_test_sigma_single.__name__ + \" succeeded!\")\n\n    async def _test_query_raw(token: str):\n        _, host = TEST_HOST.split(\"://\")\n        ws_url = f\"ws://{host}/ws\"\n        test_completed = False\n\n        async with websockets.connect(ws_url) as ws:\n            # connect websocket\n            p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=TEST_WS_ID)\n            await ws.send(p.model_dump_json(exclude_none=True))\n\n            # receive responses\n            try:\n                while True:\n                    response = await ws.recv()\n                    data = json.loads(response)\n\n                    if data[\"type\"] == \"ws_connected\":\n                        # run test\n                        q_options = GulpQueryParameters()\n                        q_options.name = \"test_raw_query\"\n                        await GulpAPIQuery.query_raw(\n                            token,\n                            TEST_OPERATION_ID,\n                            [TEST_QUERY_RAW],\n                            q_options=q_options,\n                        )\n                    elif data[\"type\"] == \"query_done\":\n                        # query done\n                        q_done_packet: GulpQueryDonePacket = (\n                            GulpQueryDonePacket.model_validate(data[\"data\"])\n                        )\n                        MutyLogger.get_instance().debug(\n                            \"query done, name=%s\", q_done_packet.name\n                        )\n                        if q_done_packet.name == \"test_raw_query\":\n                            assert q_done_packet.total_hits == 1\n                            test_completed = True\n                        else:\n                            raise ValueError(\n                                f\"unexpected query name: {q_done_packet.name}\"\n                            )\n                        break\n\n                    # ws delay\n                    await asyncio.sleep(0.1)\n\n            except websockets.exceptions.ConnectionClosed as ex:\n                MutyLogger.get_instance().exception(ex)\n\n        assert test_completed\n        MutyLogger.get_instance().info(_test_query_raw.__name__ + \" succeeded!\")\n\n    async def _test_query_gulp(token: str):\n        _, host = TEST_HOST.split(\"://\")\n        ws_url = f\"ws://{host}/ws\"\n        test_completed = False\n\n        async with websockets.connect(ws_url) as ws:\n            # connect websocket\n            p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=TEST_WS_ID)\n            await ws.send(p.model_dump_json(exclude_none=True))\n\n            # receive responses\n            try:\n                while True:\n                    response = await ws.recv()\n                    data = json.loads(response)\n\n                    if data[\"type\"] == \"ws_connected\":\n                        # run test\n                        q_options = GulpQueryParameters()\n                        q_options.name = \"test_gulp_query\"\n                        await GulpAPIQuery.query_gulp(\n                            token,\n                            TEST_OPERATION_ID,\n                            flt=GulpQueryFilter(\n                                operation_ids=[TEST_OPERATION_ID],\n                                context_ids=[TEST_CONTEXT_ID],\n                            ),\n                            q_options=q_options,\n                        )\n                    elif data[\"type\"] == \"query_done\":\n                        # query done\n                        q_done_packet: GulpQueryDonePacket = (\n                            GulpQueryDonePacket.model_validate(data[\"data\"])\n                        )\n                        MutyLogger.get_instance().debug(\n                            \"query done, name=%s\", q_done_packet.name\n                        )\n                        if q_done_packet.name == \"test_gulp_query\":\n                            assert q_done_packet.total_hits == 7\n                            test_completed = True\n                        else:\n                            raise ValueError(\n                                f\"unexpected query name: {q_done_packet.name}\"\n                            )\n                        break\n\n                    # ws delay\n                    await asyncio.sleep(0.1)\n\n            except websockets.exceptions.ConnectionClosed as ex:\n                MutyLogger.get_instance().exception(ex)\n\n        assert test_completed\n        MutyLogger.get_instance().info(_test_query_gulp.__name__ + \" succeeded!\")\n\n    async def _test_query_single_id(token: str):\n        \"\"\"\n        {\n            \"@timestamp\": \"2016-06-29T15:24:36.686000+00:00\",\n            \"gulp.timestamp\": 1467213876686000128,\n            \"gulp.operation_id\": \"test_operation\",\n            \"gulp.context_id\": \"66d98ed55d92b6b7382ffc77df70eda37a6efaa1\",\n            \"gulp.source_id\": \"64e7c3a4013ae243aa13151b5449aac884e36081\",\n            \"log.file.path\": \"/Users/valerino/repos/gulp/tests/ingest/../../samples/win_evtx/Security_short_selected.evtx\",\n            \"agent.type\": \"win_evtx\",\n            \"event.original\": \"{\\n  \\\"Event\\\": {\\n    \\\"#attributes\\\": {\\n      \\\"xmlns\\\": \\\"http://schemas.microsoft.com/win/2004/08/events/event\\\"\\n    },\\n    \\\"System\\\": {\\n      \\\"Provider\\\": {\\n        \\\"#attributes\\\": {\\n          \\\"Name\\\": \\\"Microsoft-Windows-Security-Auditing\\\",\\n          \\\"Guid\\\": \\\"54849625-5478-4994-A5BA-3E3B0328C30D\\\"\\n        }\\n      },\\n      \\\"EventID\\\": 4611,\\n      \\\"Version\\\": 0,\\n      \\\"Level\\\": 0,\\n      \\\"Task\\\": 12289,\\n      \\\"Opcode\\\": 0,\\n      \\\"Keywords\\\": \\\"0x8020000000000000\\\",\\n      \\\"TimeCreated\\\": {\\n        \\\"#attributes\\\": {\\n          \\\"SystemTime\\\": \\\"2016-06-29T15:24:36.686000Z\\\"\\n        }\\n      },\\n      \\\"EventRecordID\\\": 319457830,\\n      \\\"Correlation\\\": null,\\n      \\\"Execution\\\": {\\n        \\\"#attributes\\\": {\\n          \\\"ProcessID\\\": 768,\\n          \\\"ThreadID\\\": 2764\\n        }\\n      },\\n      \\\"Channel\\\": \\\"Security\\\",\\n      \\\"Computer\\\": \\\"temporal\\\",\\n      \\\"Security\\\": null\\n    },\\n    \\\"EventData\\\": {\\n      \\\"SubjectUserSid\\\": \\\"S-1-5-18\\\",\\n      \\\"SubjectUserName\\\": \\\"TEMPORAL$\\\",\\n      \\\"SubjectDomainName\\\": \\\"WORKGROUP\\\",\\n      \\\"SubjectLogonId\\\": \\\"0x3e7\\\",\\n      \\\"LogonProcessName\\\": \\\"Winlogon\\\"\\n    }\\n  }\\n}\",\n            \"event.sequence\": 1,\n            \"event.code\": \"4611\",\n            \"gulp.event_code\": 4611,\n            \"event.duration\": 1,\n            \"gulp.unmapped.Guid\": \"54849625-5478-4994-A5BA-3E3B0328C30D\",\n            \"gulp.unmapped.Task\": 12289,\n            \"gulp.unmapped.Keywords\": \"0x8020000000000000\",\n            \"gulp.unmapped.SystemTime\": \"2016-06-29T15:24:36.686000Z\",\n            \"winlog.record_id\": \"319457830\",\n            \"process.pid\": 768,\n            \"process.thread.id\": 2764,\n            \"winlog.channel\": \"Security\",\n            \"winlog.computer_name\": \"temporal\",\n            \"user.id\": \"S-1-5-18\",\n            \"user.name\": \"TEMPORAL$\",\n            \"user.domain\": \"WORKGROUP\",\n            \"winlog.logon.id\": \"0x3e7\",\n            \"gulp.unmapped.LogonProcessName\": \"Winlogon\"\n        }\n        \"\"\"\n        target_id = \"172511ceb3c6c0ef9f6cbf1a10fcffc3\"\n        d = await GulpAPIQuery.query_single_id(token, TEST_OPERATION_ID, target_id)\n        assert d[\"_id\"] == target_id\n        MutyLogger.get_instance().info(_test_query_single_id.__name__ + \" succeeded!\")\n\n    async def _test_query_operations():\n        guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n        assert guest_token\n        operations = await GulpAPIQuery.query_operations(guest_token)\n        assert operations and len(operations) == 1\n\n        # create another operation (with no guest grants), with the guest user cannot see it\n        admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n        assert admin_token\n        try:\n            await GulpAPIOperation.operation_delete(admin_token, \"new_operation\")\n        except:\n            pass\n        op = await GulpAPIOperation.operation_create(admin_token, \"new_operation\")\n        assert op and op[\"id\"] == \"new_operation\"\n\n        # ingest some data in this operation\n        current_dir = os.path.dirname(os.path.realpath(__file__))\n        samples_dir = os.path.join(current_dir, \"../../samples/win_evtx\")\n        file_path = os.path.join(samples_dir, \"Security_short_selected.evtx\")\n        await GulpAPIIngest.ingest_file(\n            token=admin_token,\n            file_path=file_path,\n            operation_id=\"new_operation\",\n            context_name=\"new_context\",\n            plugin=\"win_evtx\",\n            req_id=\"new_req_id\",\n        )\n        await _test_ingest_ws_loop(check_ingested=7, check_processed=7)\n\n        # check that the guest user cannot see the new operation\n        operations = await GulpAPIQuery.query_operations(guest_token)\n        assert operations and len(operations) == 1\n\n        # grant guest user\n        await GulpAPIObjectACL.object_add_granted_user(\n            token=admin_token,\n            object_id=\"new_operation\",\n            object_type=GulpCollabType.OPERATION,\n            user_id=\"guest\",\n        )\n\n        # guest token can now see the operation\n        operations = await GulpAPIQuery.query_operations(guest_token)\n        assert operations and len(operations) == 2\n\n        # delete the new operation\n        await GulpAPIOperation.operation_delete(admin_token, \"new_operation\")\n\n    # login\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    # ingest some data\n    from tests.ingest.test_ingest import test_win_evtx, test_win_evtx_multiple\n\n    await test_win_evtx()\n\n    # test different queries\n    await _test_sigma_group(guest_token)\n    await _test_sigma_single(guest_token)\n    await _test_query_gulp(guest_token)\n    await _test_query_raw(guest_token)\n    await _test_query_single_id(guest_token)\n    await _test_query_operations()\n\n\n@pytest.mark.asyncio\nasync def test_sigma_zip():\n\n    async def _test_sigma_zip(token: str):\n        current_dir = os.path.dirname(os.path.realpath(__file__))\n        sigma_zip_path = os.path.join(current_dir, \"sigma/windows.zip\")\n\n        _, host = TEST_HOST.split(\"://\")\n        ws_url = f\"ws://{host}/ws\"\n        test_completed = False\n\n        # create a ping task to ensure regular pings regardless of message processing\n        async def _ping_loop(websocket):\n            try:\n                while True:\n                    await asyncio.sleep(10)  # Ping every 10 seconds consistently\n                    try:\n                        await websocket.ping()\n                    except Exception as e:\n                        MutyLogger.get_instance().error(f\"Ping error: {e}\")\n                        break\n            except asyncio.CancelledError:\n                pass\n\n        try:\n            async with websockets.connect(\n                ws_url,\n                ping_interval=30,\n                ping_timeout=30,\n                close_timeout=15,\n                max_size=10_000_000,  # Allow larger messages\n            ) as ws:\n                # Start a dedicated ping task\n                ping_task = asyncio.create_task(_ping_loop(ws))\n\n                # Connect websocket\n                p: GulpWsAuthPacket = GulpWsAuthPacket(token=token, ws_id=TEST_WS_ID)\n                await ws.send(p.model_dump_json(exclude_none=True))\n                num_done: int = 0\n                last_progress_time = time.time()\n\n                try:\n                    # Use separate task to run the query to not block message processing\n                    query_task = asyncio.create_task(\n                        GulpAPIQuery.query_sigma_zip(\n                            token,\n                            sigma_zip_path,\n                            TEST_OPERATION_ID,\n                            \"win_evtx\",\n                            GulpQueryParameters(\n                                group=\"test group\",\n                                note_parameters={\"create_notes\": False},\n                            ),\n                        )\n                    )\n\n                    # Message processing loop\n                    while True:\n                        try:\n                            # Use a timeout to avoid blocking indefinitely\n                            response = await asyncio.wait_for(ws.recv(), timeout=5.0)\n                            data = json.loads(response)\n\n                            # Process different message types\n                            if data[\"type\"] == \"query_done\":\n                                num_done += 1\n                                q_done_packet = GulpQueryDonePacket.model_validate(\n                                    data[\"data\"]\n                                )\n                                MutyLogger.get_instance().debug(\n                                    f\"Query done: {q_done_packet.name}, matches: {q_done_packet.total_hits}, num_done: {num_done}\"\n                                )\n\n                                if num_done == 1209:\n                                    test_completed = True\n                                    break\n\n                            # add dynamic backpressure - slow down if processing lots of messages\n                            if num_done % 20 == 0:\n                                await asyncio.sleep(0.01)\n\n                        except asyncio.TimeoutError:\n                            # Check if query task failed\n                            if query_task.done() and not test_completed:\n                                if query_task.exception():\n                                    raise query_task.exception()\n                                MutyLogger.get_instance().warning(\n                                    \"No messages received for 5 seconds\"\n                                )\n                            continue\n\n                finally:\n                    # Clean up the ping task\n                    ping_task.cancel()\n                    await asyncio.gather(ping_task, return_exceptions=True)\n\n                    # Check query task status\n                    if not query_task.done():\n                        query_task.cancel()\n\n        except websockets.exceptions.ConnectionClosed as ex:\n            MutyLogger.get_instance().error(f\"WebSocket closed: {ex}\")\n        except Exception as ex:\n            MutyLogger.get_instance().error(f\"Exception: {ex}\")\n\n        assert test_completed, \"Test did not complete successfully\"\n        MutyLogger.get_instance().info(_test_sigma_zip.__name__ + \" succeeded!\")\n\n    # login\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    # ingest some data\n    from tests.ingest.test_ingest import test_win_evtx_multiple\n\n    # sigma zip test\n    await test_win_evtx_multiple()\n    await _test_sigma_zip(guest_token)\n"}
{"type": "test_file", "path": "test_scripts/ingest_raw.py", "content": "#!/usr/bin/env python3\nimport argparse\nimport asyncio\nimport json\n\nimport muty.file\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.rest.client.common import GulpAPICommon\nfrom gulp.api.rest.client.db import GulpAPIDb\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import (\n    TEST_HOST,\n    TEST_INDEX,\n    TEST_OPERATION_ID,\n    TEST_REQ_ID,\n    TEST_WS_ID,\n)\nfrom gulp.api.ws_api import GulpWsAuthPacket, GulpWsIngestPacket\n\n\ndef _chunk_array(arr: list, chunk_size: int) -> list:\n    \"\"\"\n    split an array into chunks of specified size\n\n    Args:\n        arr: the array to split\n        chunk_size: the size of each chunk\n\n    Returns:\n        list: a list of chunks (lists)\n    \"\"\"\n    return [arr[i:i + chunk_size] for i in range(0, len(arr), chunk_size)]\n\n\nasync def _ingest_ws_raw(args) -> None:\n    MutyLogger.get_instance(\"ingest_raw\").info(\n        \"ingesting raw, args=%s ...\" % (args))\n\n    path = args.path\n    reset = args.reset\n    ws_id = args.ws_id\n    req_id = args.req_id\n    operation_id = args.operation_id\n    host = args.host\n\n    GulpAPICommon.get_instance().init(\n        host=host, ws_id=ws_id, req_id=req_id\n    )\n\n    buf = await muty.file.read_file_async(path)\n    raw_data = json.loads(buf)\n    chunk_size = 200\n\n    if reset:\n        # reset first\n        MutyLogger.get_instance().info(\"resetting gulp !\")\n        token = await GulpAPIUser.login(\"admin\", \"admin\")\n        await GulpAPIDb.gulp_reset(token)\n\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n\n    _, host = host.split(\"://\")\n    ws_url = f\"ws://{host}/ws_ingest_raw\"\n\n    async with websockets.connect(ws_url) as ws:\n        # connect websocket\n        p: GulpWsAuthPacket = GulpWsAuthPacket(\n            token=ingest_token, ws_id=ws_id\n        )\n        await ws.send(p.model_dump_json(exclude_none=True))\n\n        # receive responses\n        while True:\n            response = await ws.recv()\n            data = json.loads(response)\n            if data[\"type\"] == \"ws_connected\":\n\n                chunks = _chunk_array(raw_data, chunk_size)\n                c = 0\n                for chunk in chunks:\n                    # send chunk\n                    p: GulpWsIngestPacket = GulpWsIngestPacket(\n                        docs=chunk,\n                        index=operation_id,\n                        operation_id=operation_id,\n                        req_id=req_id,\n                        ws_id=ws_id,\n                    )\n                    await ws.send(p.model_dump_json(exclude_none=True))\n                    await asyncio.sleep(0.1)\n                    c += 1\n                    MutyLogger.get_instance().info(\"sent chunk %d of %d documents ...\" % (c, len(chunk)))\n                break\n\n            # ws delay\n            await asyncio.sleep(0.1)\n\n        MutyLogger.get_instance().info(\"DONE!\")\n\n\ndef parse_arguments() -> argparse.Namespace:\n    \"\"\"\n    parse command line arguments for the anomaly generator\n\n    Returns:\n        argparse.Namespace: parsed command line arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"ingest raw data with the raw plugin using the /ingest_ws/raw api\")\n    parser.add_argument(\"--path\", required=True,\n                        help=\"path to the raw file with gulp json documents to be ingested\")\n    parser.add_argument(\"--host\", default=TEST_HOST, help=\"Gulp host\")\n    parser.add_argument(\n        \"--operation_id\",\n        default=TEST_OPERATION_ID,\n        help=\"Gulp operation_id\",\n    )\n    parser.add_argument(\n        \"--req_id\",\n        default=TEST_REQ_ID,\n        help=\"Gulp req_id\",\n    )\n    parser.add_argument(\n        \"--ws_id\",\n        default=TEST_WS_ID,\n        help=\"Gulp ws_id\",\n    )\n    parser.add_argument(\"--reset\", action=\"store_true\",\n                        help=\"reset gulp before ingesting\", default=False)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_arguments()\n    try:\n        asyncio.run(_ingest_ws_raw(args))\n        return 0\n    except Exception as ex:\n        MutyLogger.get_instance().exception(ex)\n        return 1\n\n\nif __name__ == \"__main__\":\n    exit(main())\n"}
{"type": "test_file", "path": "test_scripts/evtx_count.py", "content": "#!/usr/bin/env python3\n\"\"\"\ncount the number of events in one or more evtx files\n\"\"\"\nimport json\nimport os\nimport sys\n\nimport muty.file\nfrom evtx import PyEvtxParser\n\ncount = 0\nfailed = 0\n\n\ndef process_file(file):\n    global count, failed\n    print(\"parsing %s ...\" % (file))\n\n    parser = PyEvtxParser(file, number_of_threads=8)\n    try:\n        it = parser.records()\n        for r in it:\n            count += 1\n    except:\n        failed += 1\n\n\ndef process_files(files):\n    for f in files:\n        process_file(f)\n\n\ndef main():\n    # first parameter is the path to the evtx file\n    if len(sys.argv) < 2:\n        print(\"count the number of events in one or more evtx files\")\n        print(\"Usage: evtx_count.py <evtx_file|directory>\")\n        return\n\n    filepath = sys.argv[1]\n    if os.path.isfile(filepath):\n        process_file(filepath)\n    else:\n        files = muty.file.list_directory(os.path.abspath(filepath))\n        process_files(files)\n    print(\"total events count: processed=%d, failed=%d\" % (count, failed))\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/test_db.py", "content": "import asyncio\nimport json\n\nimport pytest\nimport pytest_asyncio\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.opensearch.filters import GulpQueryFilter\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.db import GulpAPIDb\nfrom gulp.api.rest.client.operation import GulpAPIOperation\nfrom gulp.api.rest.client.query import GulpAPIQuery\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import (\n    TEST_HOST,\n    TEST_INDEX,\n    TEST_OPERATION_ID,\n    TEST_WS_ID,\n)\nfrom gulp.api.ws_api import GulpQueryDonePacket, GulpWsAuthPacket\n\n\nasync def _ws_loop(total: int = None):\n    _, host = TEST_HOST.split(\"://\")\n    ws_url = f\"ws://{host}/ws\"\n    test_completed = False\n    async with websockets.connect(ws_url) as ws:\n        # connect websocket\n        p: GulpWsAuthPacket = GulpWsAuthPacket(token=\"monitor\", ws_id=TEST_WS_ID)\n        await ws.send(p.model_dump_json(exclude_none=True))\n\n        # receive responses\n        try:\n            while True:\n                response = await ws.recv()\n                data = json.loads(response)\n                if data[\"type\"] == \"rebase_done\":\n                    # stats update\n                    MutyLogger.get_instance().debug(f\"rebase done received: {data}\")\n                    rebase_packet = data[\"data\"]\n                    if rebase_packet[\"status\"] == \"done\":\n                        test_completed = True\n                    else:\n                        raise ValueError(f\"unexpected rebase status: {rebase_packet}\")\n                    break\n                elif data[\"type\"] == \"ws_connected\":\n                    # ws connected\n                    MutyLogger.get_instance().debug(\"ws connected: %s\", data)\n\n                elif data[\"type\"] == \"query_done\":\n                    # query done\n                    q_done_packet: GulpQueryDonePacket = (\n                        GulpQueryDonePacket.model_validate(data[\"data\"])\n                    )\n                    if q_done_packet.total_hits == total:\n                        test_completed = True\n                    else:\n                        raise ValueError(\n                            f\"unexpected total hits: {q_done_packet.total_hits}\"\n                        )\n                    break\n                # ws delay\n                await asyncio.sleep(0.1)\n\n        except websockets.exceptions.ConnectionClosed:\n            MutyLogger.get_instance().warning(\"WebSocket connection closed\")\n\n    assert test_completed\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_db_api():\n    # ingest some data\n    from tests.ingest.test_ingest import test_win_evtx\n\n    # login users\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n\n    admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert admin_token\n\n    ingest_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert ingest_token\n\n    # clear indexes to start clean\n    indexes = await GulpAPIDb.opensearch_list_index(admin_token)\n    for l in indexes:\n        await GulpAPIDb.opensearch_delete_index(admin_token, l[\"name\"], delete_operation=False)\n\n    # recreate operation\n    await GulpAPIOperation.operation_delete(admin_token, TEST_OPERATION_ID)\n    await GulpAPIOperation.operation_create(admin_token, TEST_OPERATION_ID, set_default_grants=True)\n\n    # ingest some data\n    await test_win_evtx()\n\n    # get doc by id\n    target_id = \"50edff98db7773ef04378ec20a47f622\"\n    d = await GulpAPIQuery.query_single_id(guest_token, TEST_OPERATION_ID, target_id)\n    assert d[\"_id\"] == target_id\n    assert d[\"@timestamp\"] == \"2016-06-29T15:24:34.346000+00:00\"\n    assert d[\"gulp.timestamp\"] == 1467213874345999872\n\n    # rebase on another index (guest cannot rebase)\n    one_day_msec = 1000 * 60 * 60 * 24\n    new_index = \"new_idx\"\n    # onoy 1 document should be rebased\n    flt: GulpQueryFilter = GulpQueryFilter(\n        time_range=[1467213874345999870, 1467213874345999875]\n    )\n    await GulpAPIDb.opensearch_rebase_index(\n        token=guest_token,\n        operation_id=TEST_OPERATION_ID,\n        dest_index=new_index,\n        offset_msec=one_day_msec,\n        flt=flt,\n        expected_status=401,\n    )\n\n    # ingest can do it\n    await GulpAPIDb.opensearch_rebase_index(\n        token=ingest_token,\n        operation_id=TEST_OPERATION_ID,\n        dest_index=new_index,\n        offset_msec=one_day_msec,\n        flt=flt,\n    )\n\n    # wait rebase done\n    await _ws_loop()\n\n    # check rebase\n    await GulpAPIQuery.query_gulp(guest_token, operation_id=TEST_OPERATION_ID)\n    await _ws_loop(total=1)\n\n    # check same document on new idx (should be 1 day ahead)\n    doc = await GulpAPIQuery.query_single_id(guest_token, TEST_OPERATION_ID, target_id)\n    assert doc[\"_id\"] == target_id\n    assert doc[\"@timestamp\"] == \"2016-06-30T15:24:34.346000000Z\"\n    assert doc[\"gulp.timestamp\"] == 1467300274345999872  # 1467213874345999872 + 1 day\n\n    # list indexes (should be 2)\n    indexes = await GulpAPIDb.opensearch_list_index(admin_token)\n    assert len(indexes) == 2\n    for i in indexes:\n        # there should be an indexes with doc_count=1 (the new index)\n        assert i[\"name\"] in [TEST_OPERATION_ID, new_index]\n        if i[\"name\"] == new_index:\n            assert i[\"doc_count\"] == 1\n\n    # delete the new index (this will also delete the operation test_operation)\n    await GulpAPIDb.opensearch_delete_index(ingest_token, new_index)\n\n    # only the original stale index should be left\n    indexes = await GulpAPIDb.opensearch_list_index(admin_token)\n    assert len(indexes) == 1\n    assert indexes[0][\"name\"] == TEST_OPERATION_ID\n    assert indexes[0][\"doc_count\"] == 7\n\n    # delete the old stale index (test_operation)\n    await GulpAPIDb.opensearch_delete_index(admin_token, TEST_OPERATION_ID)\n\n    MutyLogger.get_instance().info(test_db_api.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "tests/test_story.py", "content": "import pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpCollabType\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.object_acl import GulpAPIObjectACL\nfrom gulp.api.rest.client.story import GulpAPIStory\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import TEST_CONTEXT_ID, TEST_OPERATION_ID\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_story():\n    target_doc_ids = [\n        \"9d6f4d014b7dd9f5f65ce43f3c142749\",\n        \"7090d29202d7cd8b57c30fa14202ac37\",\n    ]\n\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    edit_token = await GulpAPIUser.login(\"editor\", \"editor\")\n    assert edit_token\n\n    st = await GulpAPIStory.story_create(\n        guest_token,\n        operation_id=TEST_OPERATION_ID,\n        doc_ids=target_doc_ids,\n        name=\"story\",\n        expected_status=401,\n    )\n\n    st = await GulpAPIStory.story_create(\n        edit_token,\n        operation_id=TEST_OPERATION_ID,\n        name=\"story\",\n        doc_ids=target_doc_ids,\n    )\n    assert st\n    assert st[\"doc_ids\"][0] == target_doc_ids[0]\n    assert st[\"doc_ids\"][1] == target_doc_ids[1]\n    assert st[\"name\"] == \"story\"\n\n    # doc filter\n    l = await GulpAPIStory.story_list(\n        guest_token,\n        GulpCollabFilter(\n            doc_ids=[target_doc_ids[0]],\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert len(l) == 1\n    assert l[0][\"id\"] == st[\"id\"]\n\n    l = await GulpAPIStory.story_list(\n        guest_token,\n        GulpCollabFilter(operation_ids=[TEST_OPERATION_ID], doc_ids=[\"aaaaa\"]),\n    )\n    assert not l  # 0 len\n\n    # update\n    await GulpAPIStory.story_update(\n        edit_token, st[\"id\"], doc_ids=[\"aaaaa\"], color=\"black\"\n    )\n    st = await GulpAPIStory.story_get_by_id(guest_token, st[\"id\"])\n    assert st[\"color\"] == \"black\"\n    assert st[\"doc_ids\"] == [\"aaaaa\"]\n    assert st[\"name\"] == \"story\"\n\n    # make story private\n    st_id = st[\"id\"]\n    await GulpAPIObjectACL.object_make_private(\n        edit_token, st[\"id\"], GulpCollabType.STORY\n    )\n    st = await GulpAPIStory.story_get_by_id(guest_token, st[\"id\"], expected_status=401)\n    l = await GulpAPIStory.story_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert not l\n\n    await GulpAPIObjectACL.object_make_public(edit_token, st_id, GulpCollabType.STORY)\n    st = await GulpAPIStory.story_get_by_id(guest_token, st_id)\n    assert st\n\n    # delete\n    await GulpAPIStory.story_delete(edit_token, st[\"id\"])\n    l = await GulpAPIStory.story_list(\n        guest_token,\n        GulpCollabFilter(\n            operation_ids=[TEST_OPERATION_ID],\n        ),\n    )\n    assert not l\n\n    MutyLogger.get_instance().info(test_story.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "tests/test_stored_query.py", "content": "import json\nimport os\n\nimport muty.file\nimport pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.stored_query import GulpAPIStoredQuery\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.structs import GulpPluginParameters\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_stored_query():\n    # login users\n    admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert admin_token\n    editor_token = await GulpAPIUser.login(\"editor\", \"editor\")\n    assert editor_token\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n\n    # delete any existing stored queries\n    queries = await GulpAPIStoredQuery.stored_query_list(admin_token)\n    for q in queries:\n        await GulpAPIStoredQuery.stored_query_delete(admin_token, q[\"id\"])\n\n    # read sigma\n    pwd = os.path.dirname(os.path.abspath(__file__))\n    sigma_q = muty.file.read_file(os.path.join(pwd, \"./query/sigma/match_all.yaml\"))\n\n    sigma_q: str = sigma_q.decode(\"utf-8\")\n    raw_q: str = json.dumps({\"query\": {\"match_all\": {}}})\n\n    # guest cannot create stored query\n    await GulpAPIStoredQuery.stored_query_create(\n        guest_token,\n        name=\"test_query_sigma\",\n        q=sigma_q,\n        tags=[\"test\"],\n        description=\"Test stored sigma query\",\n        plugin=\"win_evtx\",\n        plugin_params=GulpPluginParameters(\n            custom_parameters={\"test\": \"test\"}\n        ).model_dump(),\n        expected_status=401,\n    )\n\n    query_sigma = await GulpAPIStoredQuery.stored_query_create(\n        editor_token,\n        name=\"test_query_sigma\",\n        q=sigma_q,\n        tags=[\"test\", \"sigma\"],\n        plugin=\"win_evtx\",\n        plugin_params=GulpPluginParameters(\n            custom_parameters={\"test\": \"test\"}\n        ).model_dump(),\n        description=\"Test stored sigma query\",\n    )\n    MutyLogger.get_instance().debug(query_sigma)\n    assert query_sigma[\"name\"] == \"test_query_sigma\"\n    assert query_sigma[\"q\"] == sigma_q\n\n    query_raw = await GulpAPIStoredQuery.stored_query_create(\n        editor_token,\n        name=\"test_query_raw\",\n        q=raw_q,\n        tags=[\"test\", \"raw\"],\n        q_groups=[\"query_group_1\"],\n        description=\"Test stored query\",\n    )\n    assert query_raw[\"name\"] == \"test_query_raw\"\n    assert query_raw[\"q\"] == raw_q\n\n    # filter by tags\n    queries = await GulpAPIStoredQuery.stored_query_list(\n        guest_token, GulpCollabFilter(tags=[\"test\"])\n    )\n    assert len(queries) == 2\n    queries = await GulpAPIStoredQuery.stored_query_list(\n        guest_token, GulpCollabFilter(tags=[\"sigma\"])\n    )\n    assert len(queries) == 1\n\n    # filter by q_groups\n    queries = await GulpAPIStoredQuery.stored_query_list(\n        guest_token, GulpCollabFilter(q_groups=[\"query_group_1\"])\n    )\n    assert len(queries) == 1\n    assert queries[0][\"id\"] == query_raw[\"id\"]\n\n    # guest cannot edit the query\n    _ = await GulpAPIStoredQuery.stored_query_update(\n        guest_token,\n        query_sigma[\"id\"],\n        q=\"updated query\",\n        tags=[\"test\", \"updated\"],\n        expected_status=401,\n    )\n\n    # editor can edit the query\n    updated = await GulpAPIStoredQuery.stored_query_update(\n        editor_token,\n        query_sigma[\"id\"],\n        q=\"updated query\",\n        tags=[\"test\", \"updated\"],\n    )\n    assert \"updated query\" in updated[\"q\"]\n    assert \"updated\" in updated[\"tags\"]\n\n    # editor can delete query\n    d = await GulpAPIStoredQuery.stored_query_delete(editor_token, query_sigma[\"id\"])\n    assert d[\"id\"] == query_sigma[\"id\"]\n    d = await GulpAPIStoredQuery.stored_query_delete(editor_token, query_raw[\"id\"])\n    assert d[\"id\"] == query_raw[\"id\"]\n\n    # verify deleted\n    queries = await GulpAPIStoredQuery.stored_query_list(guest_token)\n    assert len(queries) == 0\n    MutyLogger.get_instance().info(test_stored_query.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "tests/test_operation.py", "content": "import asyncio\nimport json\n\nimport pytest\nimport pytest_asyncio\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpCollabType\nfrom gulp.api.opensearch.filters import GulpQueryFilter\nfrom gulp.api.rest.client.common import GulpAPICommon, _test_init\nfrom gulp.api.rest.client.db import GulpAPIDb\nfrom gulp.api.rest.client.object_acl import GulpAPIObjectACL\nfrom gulp.api.rest.client.operation import GulpAPIOperation\nfrom gulp.api.rest.client.query import GulpAPIQuery\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.client.user_group import GulpAPIUserGroup\nfrom gulp.api.rest.test_values import (\n    TEST_HOST,\n    TEST_INDEX,\n    TEST_OPERATION_ID,\n    TEST_REQ_ID,\n    TEST_WS_ID,\n)\nfrom gulp.api.ws_api import GulpQueryDonePacket, GulpWsAuthPacket\nfrom gulp.api.collab.user_group import ADMINISTRATORS_GROUP_ID\n\n\nasync def _ws_loop():\n    _, host = TEST_HOST.split(\"://\")\n    ws_url = f\"ws://{host}/ws\"\n    test_completed = False\n\n    async with websockets.connect(ws_url) as ws:\n        # connect websocket\n        p: GulpWsAuthPacket = GulpWsAuthPacket(token=\"monitor\", ws_id=TEST_WS_ID)\n        await ws.send(p.model_dump_json(exclude_none=True))\n\n        # receive responses\n        try:\n            while True:\n                response = await ws.recv()\n                data = json.loads(response)\n                if data[\"type\"] == \"ws_connected\":\n                    # ws connected\n                    MutyLogger.get_instance().debug(\"ws connected: %s\", data)\n\n                elif data[\"type\"] == \"query_done\":\n                    # query done\n                    q_done_packet: GulpQueryDonePacket = (\n                        GulpQueryDonePacket.model_validate(data[\"data\"])\n                    )\n                    if q_done_packet.total_hits == 0:\n                        test_completed = True\n                    else:\n                        raise ValueError(\n                            f\"unexpected total hits: {\n                                q_done_packet.total_hits}\"\n                        )\n                    break\n                # ws delay\n                await asyncio.sleep(0.1)\n\n        except websockets.exceptions.ConnectionClosed:\n            MutyLogger.get_instance().warning(\"WebSocket connection closed\")\n\n    assert test_completed\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    GulpAPICommon.get_instance().init(\n        host=TEST_HOST, ws_id=TEST_WS_ID, req_id=TEST_REQ_ID, index=TEST_INDEX\n    )\n\n\n@pytest.mark.asyncio\nasync def test_operation_api():\n    \"\"\"\n    this tests operation, acl, user groups\n    \"\"\"\n    admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert admin_token\n\n    # clear indexes\n    indexes = await GulpAPIDb.opensearch_list_index(admin_token)\n    for l in indexes:\n        await GulpAPIDb.opensearch_delete_index(\n            admin_token, l[\"name\"], delete_operation=False\n        )\n    indexes = await GulpAPIDb.opensearch_list_index(admin_token)\n    assert not indexes\n\n    # reset whole admin and collab\n    await GulpAPIDb.reset_all_as_admin()\n\n    # login users\n    editor_token = await GulpAPIUser.login(\"editor\", \"editor\")\n    assert editor_token\n\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n\n    admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert admin_token\n\n    ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n    assert ingest_token\n\n    # recreate test operation\n    await GulpAPIOperation.operation_delete(admin_token, TEST_OPERATION_ID)\n    await GulpAPIOperation.operation_create(admin_token, TEST_OPERATION_ID, set_default_grants=True)\n\n    # ingest some data\n    from tests.ingest.test_ingest import test_csv_file_mapping\n\n    await test_csv_file_mapping()\n\n    # guest user cannot create operation\n    await GulpAPIOperation.operation_create(\n        guest_token, TEST_OPERATION_ID, set_default_grants=True, expected_status=401\n    )\n\n    # editor cannot update operation\n    await GulpAPIOperation.operation_update(\n        editor_token,\n        TEST_OPERATION_ID,\n        description=\"Updated description\",\n        expected_status=401,\n    )\n\n    # ingest can update operation\n    updated = await GulpAPIOperation.operation_update(\n        ingest_token,\n        TEST_OPERATION_ID,\n        description=\"Updated description\",\n        operation_data={\"hello\": \"world\"},\n    )\n    assert updated.get(\"description\") == \"Updated description\"\n    assert updated.get(\"operation_data\")[\"hello\"] == \"world\"\n\n    updated = await GulpAPIOperation.operation_update(\n        ingest_token, TEST_OPERATION_ID, operation_data={\"hello\": \"1234\", \"abc\": \"def\"}\n    )\n    assert updated.get(\"description\") == \"Updated description\"\n    assert updated.get(\"operation_data\")[\"hello\"] == \"1234\"\n    assert updated.get(\"operation_data\")[\"abc\"] == \"def\"\n\n    # guest cannot delete operation\n    await GulpAPIOperation.operation_delete(\n        guest_token, updated[\"id\"], expected_status=401\n    )\n\n    # create new operation with just owner's grants\n    new_operation_id = \"new_operation\"\n    new_operation = await GulpAPIOperation.operation_create(\n        admin_token, \"new_operation\"\n    )\n    assert new_operation.get(\"name\") == new_operation_id\n    assert new_operation.get(\"index\") == new_operation_id\n    assert new_operation.get(\"id\") == new_operation_id\n\n    # list operations (ingest can see only one operation)\n    operations = await GulpAPIOperation.operation_list(ingest_token)\n    assert operations and len(operations) == 1\n    assert operations[0][\"id\"] == TEST_OPERATION_ID\n\n    # admin can also see the new operation\n    operations = await GulpAPIOperation.operation_list(admin_token)\n    for o in operations:\n        assert o[\"id\"] in [TEST_OPERATION_ID, new_operation_id]\n    assert operations and len(operations) == 2\n\n    # allow ingest to see the new operation (ingest cannot do it)\n    await GulpAPIObjectACL.object_add_granted_user(\n        token=ingest_token,\n        object_id=new_operation_id,\n        object_type=GulpCollabType.OPERATION,\n        user_id=\"ingest\",\n        expected_status=401,\n    )\n\n    # allow ingest to see the new operation (admin can)\n    await GulpAPIObjectACL.object_add_granted_user(\n        token=admin_token,\n        object_id=new_operation_id,\n        object_type=GulpCollabType.OPERATION,\n        user_id=\"ingest\",\n    )\n\n    # guest can still see the test operation\n    operations = await GulpAPIOperation.operation_list(\n        guest_token, GulpCollabFilter(names=[TEST_OPERATION_ID])\n    )\n    assert operations and len(operations) == 1 and operations[0][\"id\"] == updated[\"id\"]\n\n    # ingest can also see the new operation\n    operations = await GulpAPIOperation.operation_list(ingest_token)\n    for o in operations:\n        assert o[\"id\"] in [TEST_OPERATION_ID, new_operation_id]\n    assert operations and len(operations) == 2\n\n    # now no more\n    await GulpAPIObjectACL.object_remove_granted_user(\n        token=ingest_token,\n        object_id=new_operation_id,\n        object_type=GulpCollabType.OPERATION,\n        user_id=\"ingest\",\n        expected_status=401,\n    )\n    await GulpAPIObjectACL.object_remove_granted_user(\n        token=admin_token,\n        object_id=new_operation_id,\n        object_type=GulpCollabType.OPERATION,\n        user_id=\"ingest\",\n    )\n    operations = await GulpAPIOperation.operation_list(ingest_token)\n    assert operations and len(operations) == 1\n\n    # add ingest to administrators group\n    await GulpAPIUserGroup.usergroup_add_user(admin_token, \"ingest\", ADMINISTRATORS_GROUP_ID)\n\n    # now ingest can see the new operation again\n\n    operations = await GulpAPIOperation.operation_list(ingest_token)\n    assert operations and len(operations) == 2\n\n    # list contexts\n    contexts = await GulpAPIOperation.context_list(guest_token, TEST_OPERATION_ID)\n    assert contexts and len(contexts) == 1\n    context_id = contexts[0][\"id\"]\n\n    # list sources\n    sources = await GulpAPIOperation.source_list(\n        guest_token, TEST_OPERATION_ID, context_id=context_id\n    )\n    assert sources and len(sources) == 1\n\n    for s in sources:\n        n: str = s[\"name\"]\n        if n.endswith(\".csv\"):\n            source_id = s[\"id\"]\n            break\n\n    # delete source with data\n    d = await GulpAPIOperation.source_delete(\n        ingest_token,\n        TEST_OPERATION_ID,\n        context_id,\n        source_id,\n    )\n    # check data on opensearch (should be empty)\n    res = await GulpAPIQuery.query_gulp(guest_token, TEST_OPERATION_ID)\n    assert not res\n    await _ws_loop()\n\n    # verify that the source is deleted\n    sources = await GulpAPIOperation.source_list(\n        guest_token, TEST_OPERATION_ID, context_id=context_id\n    )\n    assert len(sources) == 0\n\n    # also delete operation (should delete the context)\n    await GulpAPIOperation.operation_delete(ingest_token, TEST_OPERATION_ID)\n\n    # verify that the operation is deleted\n    operations = await GulpAPIOperation.operation_list(guest_token)\n    assert len(operations) == 0\n\n    operations = await GulpAPIOperation.operation_list(ingest_token)\n    # ingest can still see new operation\n    assert len(operations) == 1\n\n    # also delete the new operation\n    await GulpAPIOperation.operation_delete(ingest_token, new_operation_id)\n    operations = await GulpAPIOperation.operation_list(ingest_token)\n    assert len(operations) == 0\n\n    contexts = await GulpAPIOperation.context_list(ingest_token, TEST_OPERATION_ID)\n    assert len(contexts) == 0\n\n    sources = await GulpAPIOperation.source_list(\n        ingest_token, TEST_OPERATION_ID, context_id=context_id\n    )\n    assert len(sources) == 0\n    MutyLogger.get_instance().info(\"all OPERATION tests succeeded!\")\n"}
{"type": "test_file", "path": "tests/test_utility.py", "content": "import os\n\nimport muty.file\nimport pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.rest.client.common import GulpAPICommon, _test_init\nfrom gulp.api.rest.client.db import GulpAPIDb\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.client.utility import GulpAPIUtility\nfrom gulp.api.rest.test_values import TEST_HOST, TEST_INDEX, TEST_REQ_ID, TEST_WS_ID\nfrom gulp.config import GulpConfig\nfrom gulp.plugin import GulpPluginBase\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init()\n\n\n@pytest.mark.asyncio\nasync def test_utility():\n    async def _test_plugins():\n        # reset first\n        await GulpAPIDb.reset_collab_as_admin()\n        if not os.environ.get(\"PATH_PLUGINS_EXTRA\"):\n            raise ValueError(\"PATH_PLUGINS_EXTRA not set\")\n        MutyLogger.get_instance().info(\n            \"PATH_PLUGINS_EXTRA: \" + os.environ.get(\"PATH_PLUGINS_EXTRA\")\n        )\n\n        # ensure clean\n        test_plugin = \"csv.py\"\n        test_plugin_path = os.path.join(\n            GulpConfig.get_instance().path_plugins_extra(), test_plugin\n        )\n        await muty.file.delete_file_or_dir_async(test_plugin_path)\n\n        # login admin, guest\n        admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n        assert admin_token\n\n        guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n        assert guest_token\n\n        # guest can list plugins\n        l = await GulpAPIUtility.plugin_list(admin_token)\n        assert l\n\n        # path should be the default path\n        found = False\n        for plugin in l:\n            if plugin[\"filename\"] == test_plugin:\n                assert plugin[\"path\"] == os.path.join(\n                    GulpConfig.get_instance().path_plugins_default(), test_plugin\n                )\n                found = True\n        assert found\n\n        # get and upload plugin to extra path\n        # (guest cannot upload a plugin)\n        await GulpAPIUtility.plugin_get(guest_token, test_plugin, expected_status=401)\n        p = await GulpAPIUtility.plugin_get(admin_token, test_plugin)\n        assert p[\"path\"] == os.path.join(\n            GulpConfig.get_instance().path_plugins_default(), test_plugin\n        )\n        to_be_uploaded = GulpPluginBase.path_from_plugin(test_plugin)\n\n        await GulpAPIUtility.plugin_upload(\n            guest_token, to_be_uploaded, expected_status=401\n        )\n        p = await GulpAPIUtility.plugin_upload(admin_token, to_be_uploaded)\n        assert os.path.realpath(p[\"path\"]) == os.path.realpath(\n            os.path.join(GulpConfig.get_instance(\n            ).path_plugins_extra(), test_plugin)\n        )\n\n        # list plugin again\n        # csv plugin should be in the list, but its path should be the extra path now (precedence)\n        l = await GulpAPIUtility.plugin_list(guest_token)\n        p = await GulpAPIUtility.plugin_get(admin_token, test_plugin)\n        assert os.path.realpath(p[\"path\"]) == os.path.realpath(\n            os.path.join(GulpConfig.get_instance(\n            ).path_plugins_extra(), test_plugin)\n        )\n        found = False\n        for plugin in l:\n            if plugin[\"filename\"] == test_plugin:\n                assert os.path.realpath(plugin[\"path\"]) == os.path.realpath(\n                    os.path.join(\n                        GulpConfig.get_instance().path_plugins_extra(), test_plugin\n                    )\n                )\n                found = True\n        assert found\n\n        # when deleting a plugin, it should be removed from the extra path but not from the main path\n        # (guest cannot delete plugins)\n        await GulpAPIUtility.plugin_delete(\n            guest_token, plugin=test_plugin, expected_status=401\n        )\n        d = await GulpAPIUtility.plugin_delete(admin_token, plugin=test_plugin)\n        assert os.path.realpath(d[\"path\"]) == os.path.realpath(\n            os.path.join(GulpConfig.get_instance(\n            ).path_plugins_extra(), test_plugin)\n        )\n        l = await GulpAPIUtility.plugin_list(guest_token)\n        found = False\n        for plugin in l:\n            if plugin[\"filename\"] == test_plugin:\n                assert os.path.realpath(plugin[\"path\"]) == os.path.realpath(\n                    os.path.join(\n                        GulpConfig.get_instance().path_plugins_default(), test_plugin\n                    )\n                )\n                found = True\n        assert found\n\n    async def _test_mapping_files():\n        if not os.environ.get(\"PATH_MAPPING_FILES_EXTRA\"):\n            raise ValueError(\"PATH_MAPPING_FILES_EXTRA not set\")\n        MutyLogger.get_instance().info(\n            \"PATH_MAPPING_FILES_EXTRA: \" +\n            os.environ.get(\"PATH_MAPPING_FILES_EXTRA\")\n        )\n\n        # ensure clean\n        test_mapping_file = \"chrome_history.json\"\n        test_mapping_file_path = os.path.join(\n            GulpConfig.get_instance().path_mapping_files_extra(), test_mapping_file\n        )\n        await muty.file.delete_file_or_dir_async(test_mapping_file_path)\n\n        # login admin, guest\n        admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n        assert admin_token\n\n        guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n        assert guest_token\n\n        # guest can list and get mapping file\n        l = await GulpAPIUtility.mapping_file_list(guest_token)\n        assert l\n\n        # path should be the default path\n        found = False\n        for mf in l:\n            if mf[\"filename\"] == test_mapping_file:\n                assert mf[\"path\"] == os.path.join(\n                    GulpConfig.get_instance().path_mapping_files_default(),\n                    test_mapping_file,\n                )\n                found = True\n        assert found\n\n        # get and upload mapping file to extra path\n        # (guest cannot download a mapping file)\n        await GulpAPIUtility.mapping_file_get(\n            guest_token, test_mapping_file, expected_status=401\n        )\n        p = await GulpAPIUtility.mapping_file_get(admin_token, test_mapping_file)\n        assert p[\"path\"] == os.path.join(\n            GulpConfig.get_instance().path_mapping_files_default(), test_mapping_file\n        )\n        to_be_uploaded = GulpConfig.get_instance().build_mapping_file_path(\n            test_mapping_file\n        )\n        await GulpAPIUtility.mapping_file_upload(\n            guest_token, to_be_uploaded, expected_status=401\n        )\n        p = await GulpAPIUtility.mapping_file_upload(admin_token, to_be_uploaded)\n        assert os.path.realpath(p[\"path\"]) == os.path.realpath(\n            os.path.join(\n                GulpConfig.get_instance().path_mapping_files_extra(), test_mapping_file\n            )\n        )\n\n        # list mapping files again\n        # mapping file should be in the list, but its path should be the extra path now (precedence)\n        l = await GulpAPIUtility.mapping_file_list(guest_token)\n        p = await GulpAPIUtility.mapping_file_get(admin_token, test_mapping_file)\n        assert os.path.realpath(p[\"path\"]) == os.path.realpath(\n            os.path.join(\n                GulpConfig.get_instance().path_mapping_files_extra(), test_mapping_file\n            )\n        )\n        found = False\n        for mf in l:\n            if mf[\"filename\"] == test_mapping_file:\n                assert os.path.realpath(mf[\"path\"]) == os.path.realpath(\n                    os.path.join(\n                        GulpConfig.get_instance().path_mapping_files_extra(),\n                        test_mapping_file,\n                    )\n                )\n                found = True\n        assert found\n\n        # when deleting a mapping file, it should be removed from the extra path but not from the main path\n        # (guest cannot delete mapping files)\n        await GulpAPIUtility.mapping_file_delete(\n            guest_token, mapping_file=test_mapping_file, expected_status=401\n        )\n        d = await GulpAPIUtility.mapping_file_delete(\n            admin_token, mapping_file=test_mapping_file\n        )\n        assert os.path.realpath(d[\"path\"]) == os.path.realpath(\n            os.path.join(\n                GulpConfig.get_instance().path_mapping_files_extra(), test_mapping_file\n            )\n        )\n        l = await GulpAPIUtility.mapping_file_list(guest_token)\n        found = False\n        for mf in l:\n            if mf[\"filename\"] == test_mapping_file:\n                assert os.path.realpath(mf[\"path\"]) == os.path.realpath(\n                    os.path.join(\n                        GulpConfig.get_instance().path_mapping_files_default(),\n                        test_mapping_file,\n                    )\n                )\n                found = True\n        assert found\n\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n\n    # test version\n    v = await GulpAPIUtility.version(guest_token)\n    assert v\n\n    # check env\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    if not os.environ.get(\"PATH_MAPPING_FILES_EXTRA\"):\n        # probably not in the dev container, gulp-paid-plugins must be at the same level of gulp directory\n        os.environ[\"PATH_MAPPING_FILES_EXTRA\"] = os.path.join(\n            current_dir, \"../../gulp-paid-plugins/src/gulp-paid-plugins/mapping_files\"\n        )\n        os.environ[\"PATH_PLUGINS_EXTRA\"] = os.path.join(\n            current_dir, \"../../gulp-paid-plugins/src/gulp-paid-plugins/plugins\"\n        )\n    MutyLogger.get_instance().info(\n        \"PATH_MAPPING_FILES_EXTRA: \" + os.environ[\"PATH_MAPPING_FILES_EXTRA\"]\n    )\n    MutyLogger.get_instance().info(\"PATH_PLUGINS_EXTRA: \" +\n                                   os.environ[\"PATH_PLUGINS_EXTRA\"])\n    # assert os.path.exists(os.environ[\"PATH_MAPPING_FILES_EXTRA\"])\n    # assert os.path.exists(os.environ[\"PATH_PLUGINS_EXTRA\"])\n\n    # test mapping files api\n    await _test_mapping_files()\n\n    # test plugin api\n    await _test_plugins()\n\n    MutyLogger.get_instance().info(test_utility.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "tests/test_user_group.py", "content": "import pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.client.user_group import GulpAPIUserGroup\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(reset_collab=True, recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_user_group():\n    \"\"\"\n    test user groups\n    \"\"\"\n    # get tokens\n    admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert admin_token\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n\n    # create test group\n    test_group = await GulpAPIUserGroup.usergroup_create(\n        admin_token,\n        name=\"test_group\",\n        permission=[\"read\", \"edit\"],\n        description=\"Test group\",\n        expected_status=200,\n    )\n    assert test_group[\"name\"] == \"test_group\"\n    assert \"read\" in test_group[\"permission\"]\n    assert \"edit\" in test_group[\"permission\"]\n\n    # guest cannot create group\n    _ = await GulpAPIUserGroup.usergroup_create(\n        guest_token, name=\"guest_group\", permission=[\"read\"], expected_status=401\n    )\n\n    # update group\n    updated_group = await GulpAPIUserGroup.usergroup_update(\n        admin_token,\n        group_id=test_group[\"id\"],\n        permission=[\"read\"],\n        description=\"Updated test group\",\n        expected_status=200,\n    )\n    assert updated_group[\"description\"] == \"Updated test group\"\n    assert updated_group[\"permission\"] == [\"read\"]\n\n    # guest cannot update group\n    _ = await GulpAPIUserGroup.usergroup_update(\n        guest_token, group_id=test_group[\"id\"], permission=[\"read\"], expected_status=401\n    )\n\n    # create test user\n    test_user = await GulpAPIUser.user_create(\n        admin_token, \"test_user\", \"TestPass123!\", [\"read\"], email=\"test@localhost.com\"\n    )\n    assert test_user[\"id\"] == \"test_user\"\n\n    # add user to group\n    group_with_user = await GulpAPIUserGroup.usergroup_add_user(\n        admin_token,\n        user_id=test_user[\"id\"],\n        group_id=test_group[\"id\"],\n        expected_status=200,\n    )\n    assert test_user[\"id\"] in [u[\"id\"] for u in group_with_user[\"users\"]]\n\n    # guest cannot add user to group\n    _ = await GulpAPIUserGroup.usergroup_add_user(\n        guest_token,\n        user_id=test_user[\"id\"],\n        group_id=test_group[\"id\"],\n        expected_status=401,\n    )\n\n    # get group by id\n    group = await GulpAPIUserGroup.usergroup_get_by_id(\n        admin_token, group_id=test_group[\"id\"], expected_status=200\n    )\n    assert group[\"id\"] == test_group[\"id\"]\n\n    # guest cannot get group\n    _ = await GulpAPIUserGroup.usergroup_get_by_id(\n        guest_token, group_id=test_group[\"id\"], expected_status=401\n    )\n\n    # list groups\n    groups = await GulpAPIUserGroup.usergroup_list(admin_token, expected_status=200)\n    assert len(groups) > 0\n    assert any(g[\"id\"] == test_group[\"id\"] for g in groups)\n\n    # guest cannot list groups\n    _ = await GulpAPIUserGroup.usergroup_list(guest_token, expected_status=401)\n\n    # remove user from group\n    group_without_user = await GulpAPIUserGroup.usergroup_remove_user(\n        admin_token,\n        user_id=test_user[\"id\"],\n        group_id=test_group[\"id\"],\n        expected_status=200,\n    )\n    assert test_user[\"id\"] not in [u[\"id\"] for u in group_without_user[\"users\"]]\n\n    # guest cannot remove user from group\n    _ = await GulpAPIUserGroup.usergroup_remove_user(\n        guest_token,\n        user_id=test_user[\"id\"],\n        group_id=test_group[\"id\"],\n        expected_status=401,\n    )\n\n    # guest cannot delete group\n    _ = await GulpAPIUserGroup.usergroup_delete(\n        guest_token, group_id=test_group[\"id\"], expected_status=401\n    )\n\n    # delete group\n    _ = await GulpAPIUserGroup.usergroup_delete(\n        admin_token, group_id=test_group[\"id\"], expected_status=200\n    )\n\n    # verify group is deleted\n    _ = await GulpAPIUserGroup.usergroup_get_by_id(\n        admin_token, group_id=test_group[\"id\"], expected_status=404\n    )\n\n    # cleanup test user\n    await GulpAPIUser.user_delete(admin_token, test_user[\"id\"])\n    _ = await GulpAPIUser.user_get_by_id(\n        admin_token, test_user[\"id\"], expected_status=404\n    )\n\n    MutyLogger.get_instance().debug(test_user_group.__name__ + \" passed\")\n"}
{"type": "test_file", "path": "tests/query/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/test_user.py", "content": "import pytest\nimport pytest_asyncio\nfrom muty.log import MutyLogger\n\nfrom gulp.api.rest.client.common import _test_init\nfrom gulp.api.rest.client.db import GulpAPIDb\nfrom gulp.api.rest.client.operation import GulpAPIOperation\nfrom gulp.api.rest.client.query import GulpAPIQuery\nfrom gulp.api.rest.client.user import GulpAPIUser\nfrom gulp.api.rest.test_values import TEST_OPERATION_ID\n\n\n@pytest_asyncio.fixture(scope=\"function\", autouse=True)\nasync def _setup():\n    \"\"\"\n    this is called before any test, to initialize the environment\n    \"\"\"\n    await _test_init(recreate=True)\n\n\n@pytest.mark.asyncio\nasync def test_user():\n    # login admin, guest\n    admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert admin_token\n\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n\n    # test user creation\n    test_user_id = \"test_user\"\n    test_user_password = \"Test123!\"\n    user = await GulpAPIUser.user_create(\n        admin_token, test_user_id, test_user_password, [\"read\"], \"test@example.com\"\n    )\n    assert user.get(\"email\") == \"test@example.com\"\n    assert user.get(\"permission\") == [\"read\"]\n\n    # test user listing\n    users = await GulpAPIUser.user_list(admin_token)\n    assert users and len(users) >= 1\n\n    # test user update\n    updated = await GulpAPIUser.user_update(\n        admin_token,\n        test_user_id,\n        permission=[\"read\", \"edit\"],\n        email=\"updated@example.com\",\n        user_data={\n            \"hello\": \"world\",\n        },\n    )\n    assert updated.get(\"email\") == \"updated@example.com\"\n    assert updated.get(\"permission\") == [\"read\", \"edit\"]\n    assert updated.get(\"user_data\") == {\"hello\": \"world\"}\n\n    # test user deletion\n    res = await GulpAPIUser.user_delete(admin_token, test_user_id)\n    assert res[\"id\"] == test_user_id\n\n    # verify deletion\n    _ = await GulpAPIUser.user_get_by_id(admin_token, test_user_id, expected_status=404)\n\n    # logout admin\n    t = await GulpAPIUser.logout(admin_token)\n    assert t == admin_token\n\n    # admin should be logget out, calling any api should return 401\n    await GulpAPIUser.user_list(admin_token, expected_status=401)\n\n    # guest tests now!\n\n    # guest cannot create, list, delete users\n    await GulpAPIUser.user_create(\n        guest_token, \"new_user\", \"Password#1234!\", [\"read\"], expected_status=401\n    )\n    await GulpAPIUser.user_list(guest_token, expected_status=401)\n    await GulpAPIUser.user_delete(guest_token, \"editor\", expected_status=401)\n\n    # guest should not be able to update its own permission\n    await GulpAPIUser.user_update(\n        guest_token, \"guest\", permission=[\"read\", \"edit\"], expected_status=401\n    )\n\n    # guest should not be able to update other users\n    await GulpAPIUser.user_update(\n        guest_token, \"editor\", password=\"Hacked#1234!\", expected_status=401\n    )\n\n    # guest should be able to get their own details\n    guest_data = await GulpAPIUser.user_get_by_id(guest_token, \"guest\")\n    assert guest_data[\"id\"] == \"guest\"\n\n    # guest should be able to update their own password or email\n    updated = await GulpAPIUser.user_update(\n        guest_token,\n        \"guest\",\n        password=\"Password#1234!\",\n        email=\"mynewemail@email.com\",\n    )\n    assert updated[\"email\"] == \"mynewemail@email.com\"\n\n    MutyLogger.get_instance().info(test_user.__name__ + \" passed\")\n\n\n@pytest.mark.asyncio\nasync def test_user_vs_operations():\n    # login admin, guest\n    admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert admin_token\n\n    # reset collab full\n    await GulpAPIDb.postgres_reset_collab(admin_token, full_reset=True)\n    admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n    assert admin_token\n    guest_token = await GulpAPIUser.login(\"guest\", \"guest\")\n    assert guest_token\n    res = await GulpAPIOperation.operation_reset(admin_token, TEST_OPERATION_ID)\n    assert res[\"id\"] == TEST_OPERATION_ID\n\n    # ingest some data\n    from tests.ingest.test_ingest import test_win_evtx\n\n    await test_win_evtx()\n\n    # test admin user creation\n    test_user_id = \"test_admin\"\n    test_user_password = \"Test123!\"\n    test_admin = await GulpAPIUser.user_create(\n        admin_token,\n        test_user_id,\n        test_user_password,\n        [\"admin\"],\n        \"testadmin@example.com\",\n    )\n    assert test_admin.get(\"email\") == \"testadmin@example.com\"\n    assert test_admin.get(\"permission\") == [\"admin\", \"read\"]\n\n    # test guest user creation\n    test_user_id = \"test_user\"\n    test_user_password = \"Test123!\"\n    test_user = await GulpAPIUser.user_create(\n        admin_token, test_user_id, test_user_password, [\"read\"], \"testuser@example.com\"\n    )\n    assert test_user.get(\"email\") == \"testuser@example.com\"\n    assert test_user.get(\"permission\") == [\"read\"]\n\n    # login test users\n    test_admin_token = await GulpAPIUser.login(\"test_admin\", \"Test123!\")\n    assert test_admin_token\n    test_user_token = await GulpAPIUser.login(\"test_user\", \"Test123!\")\n    assert test_user_token\n\n    # query operations\n    operations = await GulpAPIQuery.query_operations(admin_token)\n    assert operations and len(operations) == 1\n\n    operations = await GulpAPIQuery.query_operations(test_admin_token)\n    assert operations and len(operations) == 1\n\n    operations = await GulpAPIQuery.query_operations(test_user_token)\n    assert not operations\n\n    # delete test users\n    res = await GulpAPIUser.user_delete(admin_token, test_user[\"id\"])\n    assert res[\"id\"] == test_user[\"id\"]\n    res = await GulpAPIUser.user_delete(admin_token, test_admin[\"id\"])\n    assert res[\"id\"] == test_admin[\"id\"]\n    MutyLogger.get_instance().info(test_user_vs_operations.__name__ + \" passed\")\n"}
{"type": "source_file", "path": "src/gulp/api/opensearch/structs.py", "content": "import json\nfrom typing import Optional, TypeVar, Union, override\n\nimport muty.crypto\nimport muty.dict\nimport muty.string\nimport muty.time\nfrom muty.log import MutyLogger\nfrom muty.pydantic import autogenerate_model_example_by_class\nfrom pydantic import BaseModel, ConfigDict, Field, model_validator\n\nfrom gulp.api.mapping.models import GulpMapping\nfrom gulp.api.opensearch.filters import QUERY_DEFAULT_FIELDS, GulpBaseDocumentFilter\nfrom gulp.api.rest.test_values import TEST_CONTEXT_ID, TEST_OPERATION_ID, TEST_SOURCE_ID\n\nT = TypeVar(\"T\", bound=\"GulpBaseDocumentFilter\")\n\n\nclass GulpBasicDocument(BaseModel):\n    model_config = ConfigDict(\n        extra=\"allow\",\n        # solves the issue of not being able to populate fields using field name instead of alias\n        populate_by_name=True,\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"_id\": \"1234567890abcdef1234567890abcdef\",\n                    \"@timestamp\": \"2021-01-01T00:00:00Z\",\n                    \"gulp.timestamp\": 1609459200000000000,\n                    \"gulp.timestamp_invalid\": False,\n                    \"gulp.operation_id\": TEST_OPERATION_ID,\n                    \"gulp.context_id\": TEST_CONTEXT_ID,\n                    \"gulp.source_id\": TEST_SOURCE_ID,\n                }\n            ]\n        },\n    )\n\n    id: str = Field(\n        description='\"_id\": the unique identifier of the document.',\n        alias=\"_id\",\n    )\n    timestamp: str = Field(\n        description='\"@timestamp\": document timestamp, in iso8601 format.',\n        alias=\"@timestamp\",\n    )\n    gulp_timestamp: int = Field(\n        description='\"@timestamp\": document timestamp in nanoseconds from unix epoch',\n        alias=\"gulp.timestamp\",\n    )\n    invalid_timestamp: bool = Field(\n        False,\n        description='True if \"@timestamp\" is invalid and set to 1/1/1970 (the document should be checked, probably ...).',\n        alias=\"gulp.timestamp_invalid\",\n    )\n    operation_id: str = Field(\n        description='\"gulp.operation_id\": the operation ID the document is associated with.',\n        alias=\"gulp.operation_id\",\n    )\n    context_id: str = Field(\n        description='\"gulp.context_id\": the context (i.e. an host name) the document is associated with.',\n        alias=\"gulp.context_id\",\n    )\n    source_id: str = Field(\n        description='\"gulp.source_id\": the source the document is associated with.',\n        alias=\"gulp.source_id\",\n    )\n\n\nclass GulpDocument(GulpBasicDocument):\n    \"\"\"\n    represents a Gulp document.\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        # solves the issue of not being able to populate fields using field name instead of alias\n        populate_by_name=True,\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"_id\": \"1234567890abcdef1234567890abcdef\",\n                    \"@timestamp\": \"2021-01-01T00:00:00Z\",\n                    \"gulp.timestamp\": 1609459200000000000,\n                    \"gulp.timestamp_invalid\": False,\n                    \"gulp.operation_id\": TEST_OPERATION_ID,\n                    \"gulp.context_id\": TEST_CONTEXT_ID,\n                    \"gulp.source_id\": TEST_SOURCE_ID,\n                    \"agent.type\": \"win_evtx\",\n                    \"event.original\": \"raw event content\",\n                    \"event.sequence\": 1,\n                    \"event.code\": \"1234\",\n                    \"gulp.event_code\": 1234,\n                    \"event.duration\": 1,\n                    \"log.file.path\": \"C:\\\\Windows\\\\System32\\\\winevt\\\\Logs\\\\Security.evtx\",\n                }\n            ]\n        },\n    )\n\n    log_file_path: Optional[str] = Field(\n        None,\n        description='\"log.file.path\": the original log file name or path.',\n        alias=\"log.file.path\",\n    )\n    agent_type: str = Field(\n        None,\n        description='\"agent.type\": the ingestion source, i.e. gulp plugin.name().',\n        alias=\"agent.type\",\n    )\n    event_original: Optional[str] = Field(\n        None,\n        description='\"event.original\": the original event as text.',\n        alias=\"event.original\",\n    )\n    event_sequence: int = Field(\n        0,\n        description='\"event.sequence\": the sequence number of the document in the source.',\n        alias=\"event.sequence\",\n    )\n    event_code: Optional[str] = Field(\n        \"0\",\n        description='\"event.code\": the event code, \"0\" if missing.',\n        alias=\"event.code\",\n    )\n    gulp_event_code: Optional[int] = Field(\n        0,\n        description='\"gulp.event_code\": \"event.code\" as integer.',\n        alias=\"gulp.event_code\",\n    )\n    event_duration: Optional[int] = Field(\n        1,\n        description='\"event.duration\": the duration of the event in nanoseconds, defaults to 1.',\n        alias=\"event.duration\",\n    )\n\n    @staticmethod\n    def ensure_timestamp(\n        timestamp: str\n    ) -> tuple[str, int, bool]:\n        \"\"\"\n        returns a string guaranteed to be in iso8601 time format\n\n        Args:\n            timestamp (str): The time string to parse (in iso8601 format or a string in a format supported by muty.time.ensure_iso8601).\n        Returns:\n            tuple[str, int, bool]: The timestamp in iso8601 format, the timestamp in nanoseconds from unix epoch, and a boolean indicating if the timestamp is invalid.\n        \"\"\"\n        epoch_start: str = \"1970-01-01T00:00:00Z\"\n        # MutyLogger.get_instance().debug(f\"ensure_timestamp: {timestamp}\")\n        if not timestamp:\n            # invalid timestamp\n            return epoch_start, 0, True\n\n        try:\n            # get iso8601 timestamp\n            ts = muty.time.ensure_iso8601(timestamp)\n            # we also need nanoseconds from the unix epoch\n            if timestamp.isdigit():\n                # timestamp is in seconds/milliseconds/nanoseconds from unix epoch\n                ns = muty.time.number_to_nanos_from_unix_epoch(timestamp)\n            else:\n                ns = muty.time.string_to_nanos_from_unix_epoch(ts)\n\n            return ts, ns, False\n        except Exception as e:\n            # invalid timestamp\n            # MutyLogger.get_instance().error(f\"invalid timestamp: {timestamp}, {e}\")\n            return epoch_start, 0, True\n\n    @override\n    def __init__(\n        self,\n        plugin_instance,\n        operation_id: str | int,\n        context_id: str,\n        source_id: str,\n        event_original: str,\n        event_sequence: int,\n        timestamp: str = None,\n        event_code: str = \"0\",\n        event_duration: int = 1,\n        log_file_path: str = None,\n        **kwargs,\n    ) -> None:\n        \"\"\"\n        initializea a GulpDocument instance.\n\n        Args:\n            plugin_instance: The calling PluginBase\n            operation_id (str): The operation id on gulp collab database.\n            context_id (str): The context id on gulp collab database.\n            source_id (str): The source id on gulp collab database.\n            event_original (str): The original event data.\n            event_sequence (int): The sequence number of the event.\n            timestamp (str, optional): the time string, will be converted to iso8601 time string (ignored if \"timestamp\" is in kwargs). Defaults to None.\n            event_code (str, optional): The event code. Defaults to \"0\".\n            event_duration (int, optional): The duration of the event. Defaults to 1.\n            log_file_path (str, optional): The source log file path. Defaults to None.\n\n            **kwargs: Additional keyword arguments to be added as attributes.\n                - ignore_default_event_code (bool, optional): If True, do not use the default event code from the mapping. Defaults to False.\n\n            Returns:\n            None\n        \"\"\"\n        # turn any document already in gulp ecs format back to GulpDocument\n        # (i.e. turn \"@timestamp\" back to \"timestamp\")\n        kwargs = GulpDocumentFieldAliasHelper.set_kwargs_and_fix_aliases(\n            kwargs)\n\n        # this is internal, set by _finalize_process_record() in the mapping engine\n        ignore_default_event_code = kwargs.pop(\n            \"__ignore_default_event_code__\", False)\n\n        # build initial data dict\n        mapping: GulpMapping = plugin_instance.selected_mapping()\n        data = {\n            \"operation_id\": operation_id,\n            \"context_id\": context_id,\n            # force agent type from mapping or default to plugin name\n            \"agent_type\": (\n                mapping.agent_type\n                if mapping and mapping.agent_type\n                else plugin_instance.bare_filename\n            ),\n            \"event_original\": event_original,\n            \"event_sequence\": event_sequence,\n            # force event code from mapping or default to event_code\n            \"event_code\": (\n                mapping.event_code\n                if mapping and mapping.event_code and not ignore_default_event_code\n                else event_code\n            ),\n            \"event_duration\": event_duration,\n            \"source_id\": source_id,\n            \"log_file_path\": log_file_path,\n            # add each kwargs as an attribute as-is (may contain event.code, @timestamp, and other fields previously set above, they will be overwritten)\n            # @timestamp may have been mapped and already checked for validity in plugin._process_key()\n            # if so, we will find it here...\n        }\n        data.update(kwargs)\n\n        if \"timestamp\" not in data:\n            # use timestamp from argument, if not among the kwargs\n            data[\"timestamp\"] = timestamp\n\n        # ensure timestamp is valid\n        ts, ts_nanos, invalid = GulpDocument.ensure_timestamp(\n            str(data[\"timestamp\"])\n        )\n        data[\"timestamp\"] = ts\n        data[\"gulp_timestamp\"] = ts_nanos\n        if invalid or ts_nanos == 0:\n            data[\"invalid_timestamp\"] = invalid\n\n        # add gulp_event_code (event code as a number)\n        data[\"gulp_event_code\"] = (\n            int(data[\"event_code\"])\n            if data[\"event_code\"].isnumeric()\n            else muty.crypto.hash_xxh64_int(data[\"event_code\"])\n        )\n\n        # id is a hash of the document\n        data[\"id\"] = muty.crypto.hash_xxh128(\n            f\"{data['event_original']}{data['event_code']}{data['operation_id']}{data['context_id']}{data['source_id']}{data['event_sequence']}\"\n        )\n\n        # initialize with complete data (and validate)\n        super().__init__(**data)\n\n    def __repr__(self) -> str:\n        return f\"GulpDocument(timestamp={self.timestamp}, gulp_timestamp={self.gulp_timestamp}, operation_id={self.operation_id}, context_id={self.context_id}, agent_type={self.agent_type}, event_sequence={self.event_sequence}, event_code={self.event_code}, event_duration={self.event_duration}, source_id={self.source_id}\"\n\n    @override\n    def model_dump(\n        self,\n        lite: bool = False,\n        exclude_none: bool = True,\n        exclude_unset: bool = True,\n        **kwargs,\n    ) -> dict:\n        \"\"\"\n        Convert the model instance to a dictionary.\n        Args:\n            lite (bool): If True, return a subset of the dictionary with \"_id\", \"@timestamp\",\n                  \"gulp.context_id\", \"gulp.operation_id\", and \"gulp.source_id\" keys.\n                         Defaults to False.\n            **kwargs: Additional keyword arguments to pass to the parent class model_dump method.\n        Returns:\n            dict: A dictionary representation of the model instance\n        \"\"\"\n        d = super().model_dump(\n            exclude_none=exclude_none, exclude_unset=exclude_unset, **kwargs\n        )\n        if lite:\n            # return just a minimal subset\n            for k in list(d.keys()):\n                if k not in QUERY_DEFAULT_FIELDS:\n                    d.pop(k, None)\n        return d\n\n\nclass GulpDocumentFieldAliasHelper:\n    \"\"\"\n    internal helper class to fix alias keys in kwargs with their corresponding field names.\n    \"\"\"\n\n    _alias_to_field_cache: dict[str, str] = {}\n\n    @staticmethod\n    def set_kwargs_and_fix_aliases(kwargs: dict) -> dict:\n        \"\"\"\n        Replace alias keys in kwargs with their corresponding field names.\n\n        i.e. \"event.code\" -> \"event_code\n\n        - if key is an alias, replace it with the corresponding field name,\n        - if key is not an alias, keep it as is.\n\n        NOTE: this is needed to i.e. ingest raw documents already in gulp ecs format.\n\n        Args:\n            kwargs (dict): The keyword arguments to fix.\n        Returns:\n            dict: The fixed keyword arguments.\n        \"\"\"\n        if not GulpDocumentFieldAliasHelper._alias_to_field_cache:\n            # initialize on first call\n            GulpDocumentFieldAliasHelper._alias_to_field_cache = {\n                field.alias: name\n                for name, field in GulpDocument.model_fields.items()\n                if field.alias\n            }\n        return {\n            GulpDocumentFieldAliasHelper._alias_to_field_cache.get(k, k): v\n            for k, v in kwargs.items()\n        }\n\n\nclass GulpRawDocumentBaseFields(BaseModel):\n    \"\"\"\n    the base(=mandatory) fields in a raw GulpDocument record\n    \"\"\"\n\n    model_config = ConfigDict(\n        # solves the issue of not being able to populate fields using field name instead of alias\n        populate_by_name=True,\n        extra=\"allow\",\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"@timestamp\": \"2021-01-01T00:00:00Z\",\n                    \"event.original\": \"raw event content\",\n                    \"event.code\": \"1234\",\n                }\n            ]\n        },\n    )\n    timestamp: str = Field(\n        ...,\n        description=\"the document timestamp, in iso8601 format.\",\n        alias=\"@timestamp\",\n    )\n    event_original: str = Field(\n        ...,\n        description=\"the original event as text.\",\n        alias=\"event.original\",\n    )\n\n\nclass GulpRawDocument(BaseModel):\n    \"\"\"\n    represents a raw GulpDocument record, consisting of:\n\n    - base_fields: these are the mandatory fields (timestamp, event code, original raw event).\n    - doc: the rest of the document as key/value pairs, to generate the `GulpDocument` with.\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        # solves the issue of not being able to populate fields using field name instead of alias\n        populate_by_name=True,\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"base_fields\": autogenerate_model_example_by_class(\n                        GulpRawDocumentBaseFields\n                    ),\n                    \"doc\": {\n                        \"agent.type\": \"win_evtx\",\n                        \"event.original\": \"raw event content\",\n                        \"event.sequence\": 1,\n                        \"event.code\": \"1234\",\n                        \"gulp.event_code\": 1234,\n                        \"event.duration\": 1,\n                        \"log.file.path\": \"C:\\\\Windows\\\\System32\\\\winevt\\\\Logs\\\\Security.evtx\",\n                    },\n                }\n            ]\n        },\n    )\n\n    base_fields: GulpRawDocumentBaseFields = Field(\n        ...,\n        description=\"the basic fields.\",\n    )\n    doc: dict = Field(\n        ...,\n        description=\"the document as key/value pairs, to generate the `GulpDocument` with.\",\n    )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/opensearch_api.py", "content": "import asyncio\nimport json\nimport os\nfrom typing import TYPE_CHECKING\nfrom urllib.parse import urlparse\n\nimport muty.crypto\nimport muty.dict\nimport muty.file\nimport muty.log\nimport muty.string\nimport muty.time\nfrom elasticsearch import AsyncElasticsearch\nfrom muty.log import MutyLogger\nfrom opensearchpy import AsyncOpenSearch, NotFoundError\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom gulp.api.collab.fields import GulpSourceFields\nfrom gulp.api.collab.note import GulpNote\nfrom gulp.api.collab.operation import GulpOperation\nfrom gulp.api.collab.stats import GulpRequestStats\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpRequestStatus\nfrom gulp.api.collab.user import GulpUser\nfrom gulp.api.collab_api import GulpCollab\nfrom gulp.api.opensearch.filters import (\n    GulpDocumentFilterResult,\n    GulpIngestionFilter,\n    GulpQueryFilter,\n)\nfrom gulp.api.ws_api import (\n    GulpDocumentsChunkPacket,\n    GulpQueryDonePacket,\n    GulpSourceFieldsChunkPacket,\n    GulpWsQueueDataType,\n    GulpWsSharedQueue,\n)\nfrom gulp.config import GulpConfig\nfrom gulp.structs import ObjectNotFound\n\nif TYPE_CHECKING:\n    from gulp.api.opensearch.query import GulpQueryParameters\n    from gulp.plugin import GulpPluginBase\n\n\nclass GulpOpenSearch:\n    \"\"\"\n    singleton class to handle OpenSearch client connection.\n\n    for ssl, it will use the CA certificate and client certificate/key if they exist in the certs directory (see config.path_certs()).\n\n    they should be named os-ca.pem, os.pem, os.key.\n    \"\"\"\n    _instance: \"GulpOpenSearch\" = None\n\n    # to be used in dynamic templates\n    UNMAPPED_PREFIX: str = \"gulp.unmapped\"\n\n    def __init__(self):\n        pass\n\n    def __new__(cls):\n        \"\"\"\n        Create a new instance of the class.\n        \"\"\"\n        if not cls._instance:\n            cls._instance=super().__new__(cls)\n            cls._instance._initialize()\n        return cls._instance\n\n    def _initialize(self):\n        \"\"\"\n        Initialize the OpenSearch client singleton.\n        \"\"\"\n        self._initialized: bool = True\n        self._opensearch: AsyncOpenSearch = self._get_client()\n\n    @classmethod\n    def get_instance(cls) -> \"GulpOpenSearch\":\n        \"\"\"\n        returns the singleton instance of the OpenSearch client.\n\n        Returns:\n            GulpOpenSearch: The singleton instance of the OpenSearch client.\n        \"\"\"\n        if not cls._instance:\n            cls._instance=cls()\n        return cls._instance\n\n    async def reinit(self):\n        \"\"\"\n        reinitializes the OpenSearch client in the singleton instance.\n        \"\"\"\n        if self._opensearch is not None:\n            await self._opensearch.close()\n\n        self._opensearch = self._get_client()\n\n    def _get_client(self) -> AsyncOpenSearch:\n        \"\"\"\n        creates an OpenSearch client instance.\n\n        Returns:\n            AsyncOpenSearch: An instance of the OpenSearch client.\n\n        \"\"\"\n        url = GulpConfig.get_instance().opensearch_url()\n        verify_certs = GulpConfig.get_instance().opensearch_verify_certs()\n\n        # split into user:pwd@host:port\n        parsed = urlparse(url)\n\n        # url = \"%s://%s:***********@%s:%s\" % (parsed.scheme, parsed.username, parsed.hostname, parsed.port)\n        # MutyLogger.get_instance().debug('%s, opensearch hostname=%s, port=%d, user_id=%s, password=***********' % (url, parsed.hostname, parsed.port, parsed.username))\n\n        host = parsed.scheme + \"://\" + parsed.hostname + \":\" + str(parsed.port)\n        ca = None\n        certs_dir = GulpConfig.get_instance().path_certs()\n        if certs_dir and parsed.scheme.lower() == \"https\":\n            # https and certs_dir is set\n            ca: str = muty.file.abspath(\n                muty.file.safe_path_join(certs_dir, \"os-ca.pem\")\n            )\n\n            # check if client certificate exists. if so, it will be used\n            client_cert = muty.file.safe_path_join(certs_dir, \"os.pem\")\n            client_key = muty.file.safe_path_join(certs_dir, \"os.key\")\n            if os.path.exists(client_cert) and os.path.exists(client_key):\n                MutyLogger.get_instance().debug(\n                    \"using client certificate: %s, key=%s, ca=%s\"\n                    % (client_cert, client_key, ca)\n                )\n                return AsyncOpenSearch(\n                    host,\n                    use_ssl=True,\n                    http_auth=(parsed.username, parsed.password),\n                    ca_certs=ca,\n                    client_cert=client_cert,\n                    client_key=client_key,\n                    verify_certs=verify_certs,\n                )\n            else:\n                MutyLogger.get_instance().debug(\n                    \"no client certificate found, using CA certificate only: %s\" % (ca)\n                )\n                return AsyncOpenSearch(\n                    host,\n                    use_ssl=True,\n                    http_auth=(parsed.username, parsed.password),\n                    ca_certs=ca,\n                    verify_certs=verify_certs,\n                )\n\n        # no https\n        el = AsyncOpenSearch(host, http_auth=(parsed.username, parsed.password))\n        MutyLogger.get_instance().debug(\"created opensearch client: %s\" % (el))\n        return el\n\n    async def shutdown(self) -> None:\n        \"\"\"\n        Shutdown the OpenSearch client.\n\n        Returns:\n            None\n        \"\"\"\n        MutyLogger.get_instance().debug(\n            \"shutting down opensearch client: %s\" % (self._opensearch)\n        )\n        await self._opensearch.close()\n        MutyLogger.get_instance().debug(\"opensearch client shutdown\")\n        self._opensearch = None\n\n    async def check_alive(self) -> None:\n        \"\"\"\n        Check if the OpenSearch client is alive.\n\n        Raises:\n            Exception: If the client is not reachable\n\n        \"\"\"\n        res = await self._opensearch.info()\n        MutyLogger.get_instance().debug(\"opensearch info: %s\" % (res))\n\n    async def datastream_get_key_value_mapping(\n        self, index: str, return_raw_result: bool = False\n    ) -> dict:\n        \"\"\"\n        Get and parse mappings for the given datastream or index: it will result in a dict (if return_raw_result is not set) like:\n        {\n            \"field1\": \"type\",\n            \"field2\": \"type\",\n            ...\n        }\n\n        Args:\n            index (str): an index/datastream to query\n            return_raw_result (bool, optional): Whether to return the raw result (mapping + settings). Defaults to False.\n        Returns:\n            dict: The mapping dict.\n        \"\"\"\n\n        def _parse_mappings_internal(d: dict, parent_key=\"\", result=None) -> dict:\n            if result is None:\n                result = {}\n            for k, v in d.items():\n                new_key = \"%s.%s\" % (parent_key, k) if parent_key else k\n                if isinstance(v, dict):\n                    if \"properties\" in v:\n                        _parse_mappings_internal(v[\"properties\"], new_key, result)\n                    elif \"type\" in v:\n                        result[new_key] = v[\"type\"]\n                else:\n                    result[new_key] = v\n            return result\n\n        try:\n            res = await self._opensearch.indices.get_mapping(index=index)\n        except Exception as e:\n            MutyLogger.get_instance().warning(\n                'no mapping for index \"%s\" found: %s' % (index, e)\n            )\n            return {}\n\n        # MutyLogger.get_instance().debug(\"index_get_mapping: %s\" % (json.dumps(res, indent=2)))\n        if return_raw_result:\n            return res\n\n        idx = list(res.keys())[0]\n        properties = res[idx][\"mappings\"][\"properties\"]\n        return _parse_mappings_internal(properties)\n\n    async def datastream_get_mapping_by_src(\n        self,\n        sess: AsyncSession,\n        operation_id: str,\n        context_id: str,\n        source_id: str,\n        user_id: str,\n        user_id_is_admin: bool = False,\n        user_group_ids: list[str] = None,\n    ) -> dict:\n        \"\"\"\n        get source->fields mappings from the collab database\n\n        Args:\n            sess (AsyncSession): The database session.\n            operation_id (str): The operation ID.\n            context_id (str): The context ID.\n            source_id (str): The source ID.\n            user_id (str): The user ID.\n            user_id_is_admin (bool, optional): Whether the user is an admin. Defaults to False.\n            user_group_ids (list[str], optional): The user group IDs. Defaults to None.\n        Returns:\n            dict: The mapping dict (same as index_get_mapping with return_raw_result=False), or None if the mapping does not exist\n\n        \"\"\"\n        # check if if a mapping already exists on the database\n        flt = GulpCollabFilter(\n            operation_ids=[operation_id],\n            context_ids=[context_id],\n            source_ids=[source_id],\n        )\n        fields: list[GulpSourceFields] = await GulpSourceFields.get_by_filter(\n            sess, flt, throw_if_not_found=False, user_id=user_id, user_id_is_admin=user_id_is_admin, user_group_ids=user_group_ids\n        )\n        if fields:\n            # cache hit!\n            return fields[0].fields\n\n        return None\n\n    def _extract_ids_from_query_operations_result(\n        self, operations: list[dict]\n    ) -> list[tuple[str, str, str]]:\n        \"\"\"\n        Extracts operation_id, context_id and source_id from the query_operations result\n\n        Args:\n            operations (list): List of operation dictionaries\n\n        Returns:\n            list[tuple]: List of tuples containing (operation_id, context_id, source_id)\n\n        Example:\n            [\n                (\"test_operation\", \"66d98ed55d92b6b7382ffc77df70eda37a6efaa1\",\n                 \"fabae8858452af6c2acde7f90786b3de3a928289\"),\n                (\"test_operation\", \"66d98ed55d92b6b7382ffc77df70eda37a6efaa1\",\n                 \"60213bb57e849a624b7989c448b7baec75043a1b\"),\n                ...\n            ]\n        \"\"\"\n        result = []\n        for operation in operations:\n            operation_id = operation.get(\"id\")\n            for context in operation.get(\"contexts\", []):\n                context_id = context.get(\"id\")\n                for plugin in context.get(\"plugins\", []):\n                    for source in plugin.get(\"sources\", []):\n                        source_id = source.get(\"id\")\n                        result.append((operation_id, context_id, source_id))\n\n        return result\n\n    async def datastream_update_mapping_by_operation(\n        self,\n        index: str,\n        user_id: str,\n        operation_ids: list[str],\n        context_ids: list[str] = None,\n        source_ids: list[str] = None,\n    ) -> None:\n        \"\"\"\n        Updates the mappings for the given operation/context/source IDs on the given index/datastream.\n\n        Args:\n            index (str): The index/datastream name.\n            user_id (str): The user ID.\n            operation_ids (list[str]): The operation IDs to update mappings for.\n            context_ids (list[str], optional): The context IDs to update mappings for. Defaults to None.\n            source_ids (list[str], optional): The source IDs to update mappings for. Defaults to None.\n\n        \"\"\"\n        MutyLogger.get_instance().debug(\n            \"updating mappings for index=%s, operation_ids=%s\" % (index, operation_ids)\n        )\n\n        l = await self.query_operations(index, user_id)\n        ids = self._extract_ids_from_query_operations_result(l)\n        for op, ctx, src in ids:\n            if (\n                (not operation_ids or (operation_ids and op in operation_ids))\n                and (not context_ids or (context_ids and ctx in context_ids))\n                and (not source_ids or (source_ids and src in source_ids))\n            ):\n                await self.datastream_update_mapping_by_src(\n                    index=index, operation_id=op, context_id=ctx, source_id=src\n                )\n\n                MutyLogger.get_instance().info(\n                    \"mappings created/updated for index=%s, operation_id=%s, context_id=%s, source_id=%s\"\n                    % (index, op, ctx, src)\n                )\n\n    async def datastream_update_mapping_by_src(\n        self,\n        index: str,\n        operation_id: str = None,\n        context_id: str = None,\n        source_id: str = None,\n        doc_ids: list[str] = None,\n        user_id: str = None,\n        ws_id: str = None,\n        req_id: str = None,\n        el: AsyncElasticsearch = None,\n    ) -> tuple[dict, bool]:\n        \"\"\"\n        create/update source->fields mappings for the given operation/context/source on the collab database\n\n        - SOURCE_FIELDS_CHUNK are streamed to the websocket ws_id if it is not None.\n\n        WARNING: this call may take long time, so it is better to offload it to a worker coroutine.\n\n        Args:\n            index (str): The index/datastream name.\n            operation_id (str): The operation ID, may be None to indicate all operations.\n            context_id (str, optional): The context ID, may be None to indicate all contexts.\n            source_id (str, optional): The source ID, may be None to indicate all sources.\n            doc_ids (list[str], optional): limit to these document IDs. Defaults to None.\n            user_id (str, optional): The user ID. Defaults to None.\n            ws_id (str, optional): The websocket ID to stream SOURCE_FIELDS_CHUNK during the loop. Defaults to None.\n            req_id (str, optional): The request ID. Defaults to None.\n            el: AsyncElasticsearch, optional): The Elasticsearch client. Defaults to None (use the default OpenSearch client).\n        Returns:\n            dict: The mapping dict (same as index_get_mapping with return_raw_result=False), may be empty if no documents are found\n\n        \"\"\"\n\n        MutyLogger.get_instance().debug(\n            \"creating/updating source->fields mapping for source_id=%s, context_id=%s, operation_id=%s, doc_ids=%s ...\"\n            % (source_id, context_id, operation_id, doc_ids)\n        )\n\n        from gulp.api.opensearch.query import GulpQueryParameters\n\n        options = GulpQueryParameters()\n        options.limit = 1000\n        options.fields = [\"*\"]\n        if not operation_id:\n            # all\n            q = {\"query\": {\"match_all\": {}}}\n        else:\n            q = {\n                \"query\": {\n                    \"query_string\": {\"query\": \"gulp.operation_id: %s\" % (operation_id)}\n                }\n            }\n            if context_id:\n                q[\"query\"][\"query_string\"][\"query\"] += \" AND gulp.context_id: %s\" % (\n                    context_id\n                )\n            if source_id:\n                q[\"query\"][\"query_string\"][\"query\"] += \" AND gulp.source_id: %s\" % (\n                    source_id\n                )\n            if doc_ids:\n                # limit to these document IDs\n                q[\"query\"][\"query_string\"][\"query\"] += \" AND _id: (%s)\" % (\n                    \" OR \".join(doc_ids)\n                )\n\n        # get mapping\n        mapping = await self.datastream_get_key_value_mapping(index)\n        filtered_mapping = {}\n\n        # loop with query_raw until there's data and update filtered_mapping\n        processed: int = 0\n        total_hits: int = 0\n        while True:\n            last: bool = False\n            parsed_options = options.parse()\n            total_hits, docs, search_after = await self._search_dsl_internal(\n                index, parsed_options, q, el=el, raise_on_error=False\n            )\n\n            options.search_after = search_after\n            processed += len(docs)\n            # MutyLogger.get_instance().debug(\"processed=%d, total=%d\" % (processed, total_hits))\n            if processed >= total_hits:\n                # last chunk\n                last = True\n\n            # update filtered_mapping with the current batch of documents\n            chunk: dict = {}\n            for doc in docs:\n                for k in mapping.keys():\n                    if k in doc:\n                        if k not in filtered_mapping:\n                            filtered_mapping[k] = mapping[k]\n                            if k not in chunk:\n                                chunk[k] = mapping[k]\n\n            send: bool = True\n            if ws_id:\n                if not last:\n                    # avoid sending empty chunks except last\n                    if not chunk:\n                        send = False\n\n                if send:\n                    # send this chunk over the ws\n                    p = GulpSourceFieldsChunkPacket(\n                        operation_id=operation_id,\n                        source_id=source_id,\n                        context_id=context_id,\n                        fields=chunk,\n                        last=last,\n                    )\n                    GulpWsSharedQueue.get_instance().put(\n                        type=GulpWsQueueDataType.SOURCE_FIELDS_CHUNK,\n                        ws_id=ws_id,\n                        user_id=user_id,\n                        req_id=req_id,\n                        data=p.model_dump(exclude_none=True),\n                    )\n\n            if last:\n                # no more results\n                break\n\n        if not filtered_mapping:\n            MutyLogger.get_instance().warning\n            \"no documents found for source_id=%s, context_id=%s, operation_id=%s\" % (\n                source_id,\n                context_id,\n                operation_id,\n            )\n            return {}\n\n        # sort the keys\n        # filtered_mapping = dict(sorted(filtered_mapping.items()))\n\n        # store on database\n        MutyLogger.get_instance().debug(\n            \"found %d mappings, storing on db ...\" % (len(filtered_mapping))\n        )\n        async with GulpCollab.get_instance().session() as sess:\n            await GulpSourceFields.create(\n                sess, user_id, operation_id, context_id, source_id, filtered_mapping\n            )\n\n        return filtered_mapping\n\n    async def index_template_delete(self, index: str) -> None:\n        \"\"\"\n        Delete the index template for the given index/datastream.\n\n        Args:\n            index (str): The index/datastream name.\n        \"\"\"\n        try:\n            template_name = \"%s-template\" % (index)\n            MutyLogger.get_instance().debug(\n                \"deleting index template: %s ...\" % (template_name)\n            )\n            res = await self._opensearch.indices.delete_index_template(\n                name=template_name\n            )\n            MutyLogger.get_instance().debug(\n                \"index template deleted: %s, res=%s\" % (template_name, res)\n            )\n        except Exception as e:\n            MutyLogger.get_instance().warning(\"index template does not exist: %s\" % (e))\n\n    async def index_template_get(self, index: str) -> dict:\n        \"\"\"\n        Get the index template for the given index/datastream.\n\n        Args:\n            index (str): The index/datastream name.\n\n        Returns:\n            dict: The index template, like:\n\n            {\n                \"index_patterns\": [\n                    \"test_operation\"\n                ],\n                \"template\": {\n                    \"settings\": {\n                    \"index\": {\n                        \"number_of_replicas\": \"0\",\n                        \"mapping\": {\n                        \"total_fields\": {\n                            \"limit\": \"10000\"\n                        }\n                        },\n                        \"refresh_interval\": \"5s\"\n                    }\n                    },\n                    \"mappings\": {\n                        \"numeric_detection\": false,\n                        \"_meta\": {\n                            \"version\": \"8.8.0-dev\"\n                        },\n                        \"dynamic_templates: [ ... ],\n                        ...\n                    }\n                },\n                ...\n            }\n        \"\"\"\n        template_name = \"%s-template\" % (index)\n        MutyLogger.get_instance().debug(\n            \"getting index template: %s ...\" % (template_name)\n        )\n\n        try:\n            res = await self._opensearch.indices.get_index_template(name=template_name)\n        except Exception as e:\n            raise ObjectNotFound(\"no template found for datastream/index %s\" % (index))\n\n        return res[\"index_templates\"][0][\"index_template\"]\n\n    async def index_template_put(self, index: str, d: dict) -> dict:\n        \"\"\"\n        Put the index template for the given index/datastream.\n\n        Args:\n            index (str): The index/datastream name.\n            d (dict): The index template.\n\n        Returns:\n            dict: The response from the OpenSearch client.\n        \"\"\"\n        template_name = \"%s-template\" % (index)\n        MutyLogger.get_instance().debug(\n            \"putting index template: %s ...\" % (template_name)\n        )\n        headers = {\"accept\": \"application/json\", \"content-type\": \"application/json\"}\n        res = await self._opensearch.indices.put_index_template(\n            name=template_name, body=d, headers=headers\n        )\n        MutyLogger.get_instance().debug(\n            \"index template set for index: %s, res=%s\" % (index, res)\n        )\n        return res\n\n    async def index_template_set_from_file(\n        self, index: str, path: str, apply_patches: bool = True\n    ) -> dict:\n        \"\"\"\n        Asynchronously sets an index template in OpenSearch from a JSON file.\n\n        Args:\n            index (str): The name of the index/datastream to set the template for.\n            path (str): The file path to the JSON file containing the index template.\n            apply_patches (bool, optional): Whether to apply specific patches to the mappings and settings before setting the index template. Defaults to True.\n        Returns:\n            dict: The response from OpenSearch after setting the index template.\n        \"\"\"\n\n        MutyLogger.get_instance().debug(\n            'loading index template from file \"%s\" ...' % (path)\n        )\n        d = muty.dict.from_json_file(path)\n        return await self.build_and_set_index_template(index, d, apply_patches)\n\n    async def build_and_set_index_template(\n        self, index: str, d: dict, apply_patches: bool = True\n    ) -> dict:\n        \"\"\"\n        Sets an index template in OpenSearch, applying the needed patches to the mappings and settings.\n\n        Args:\n            index (str): The name of the index for which the template is being set.\n            d (dict): The dictionary containing the template, mappings, and settings for the index.\n            apply_patches (bool, optional): Whether to apply specific patches to the mappings and settings before setting the index template. Defaults to True.\n        Returns:\n            dict: The response from the OpenSearch client after setting the index template.\n        Raises:\n            ValueError: If the 'template' or 'mappings' key is not found in the provided dictionary.\n        Notes:\n            - The function modifies the provided dictionary to include default settings and mappings if they are not present.\n            - It applies specific patches to the mappings and settings before setting the index template.\n            - If the OpenSearch cluster is configured for a single node, the number of replicas is set to 0 to optimize performance.\n        \"\"\"\n        MutyLogger.get_instance().debug('setting index template for \"%s\" ...' % (index))\n        template = d.get(\"template\", None)\n        if template is None:\n            raise ValueError('no \"template\" key found in the index template')\n        mappings = template.get(\"mappings\", None)\n        if mappings is None:\n            raise ValueError('no \"mappings\" key found in the index template')\n        settings = template.get(\"settings\", None)\n        if settings is None:\n            template[\"settings\"] = {}\n            settings = template[\"settings\"]\n        if settings.get(\"index\", None) is None:\n            settings[\"index\"] = {}\n        if settings[\"index\"].get(\"mapping\", None) is None:\n            settings[\"index\"][\"mapping\"] = {}\n        dt = mappings.get(\"dynamic_templates\", None)\n        if dt is None:\n            dt = []\n            mappings[\"dynamic_templates\"] = dt\n\n        # apply our patches\n        d[\"index_patterns\"] = [index]\n        d[\"data_stream\"] = {}\n        d[\"priority\"] = 100\n\n        # always set gulp specific mappings\n        mappings[\"properties\"][\"gulp\"] = {\n            \"properties\": {\n                \"event_code\": {\"type\": \"long\"},\n                \"context_id\": {\"type\": \"keyword\"},\n                \"operation_id\": {\"type\": \"keyword\"},\n                \"source_id\": {\"type\": \"keyword\"},\n                \"timestamp\": {\"type\": \"long\"},\n                \"timestamp_invalid\": {\"type\": \"boolean\"},\n            }\n        }\n\n        # add dynamic templates for unmapped fields\n        dtt = []\n\n        # handle object fields\n        dtt.append(\n            {\n                \"objects\": {\n                    \"path_match\": \"%s.*\" % (self.UNMAPPED_PREFIX),\n                    \"match_mapping_type\": \"object\",\n                    \"mapping\": {\"type\": \"object\", \"dynamic\": True},\n                }\n            }\n        )\n\n        # handle string fields (all unmapped to keyword)\n        dtt.append(\n            {\n                \"hex_values\": {\n                    \"path_match\": \"%s.*\" % (self.UNMAPPED_PREFIX),\n                    \"match_pattern\": \"regex\",\n                    \"match\": \"^0[xX][0-9a-fA-F]+$\",\n                    \"mapping\": {\"type\": \"keyword\", \"ignore_above\": 1024},\n                }\n            }\n        )\n        dtt.append(\n            {\n                \"unmapped_fields\": {\n                    \"path_match\": \"%s.*\" % (self.UNMAPPED_PREFIX),\n                    \"match_mapping_type\": \"*\",\n                    \"mapping\": {\"type\": \"keyword\", \"ignore_above\": 1024},\n                }\n            }\n        )\n        dtt.extend(dt)\n        mappings[\"dynamic_templates\"] = dtt\n\n        if apply_patches:\n            # only set these if we do not want to use the template as is\n            # mappings['date_detection'] = True\n            # mappings['numeric_detection'] = True\n            # mappings['dynamic'] = False\n\n            mappings[\"numeric_detection\"] = False\n            mappings[\"date_detection\"] = False\n            mappings[\"properties\"][\"@timestamp\"] = {\n                \"type\": \"date_nanos\",\n                \"format\": \"strict_date_optional_time_nanos\",\n            }\n\n            # support for original event both as keyword and text\n            # keyword is case sensitive, text is not\n            mappings[\"properties\"][\"event\"][\"properties\"][\"original\"] = {\n                \"type\": \"text\",\n                \"analyzer\": \"standard\",\n                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 1024}},\n            }\n\n            settings[\"index\"][\"mapping\"][\"total_fields\"] = {\n                \"limit\": GulpConfig.get_instance().index_template_default_total_fields_limit()\n            }\n            settings[\"index\"][\n                \"refresh_interval\"\n            ] = GulpConfig.get_instance().index_template_default_refresh_interval()\n            if not GulpConfig.get_instance().opensearch_multiple_nodes():\n                # optimize for single node\n                # this also removes \"yellow\" node in single node mode\n                # this also removes \"yellow\" node in single node mode\n                MutyLogger.get_instance().warning(\"setting number_of_replicas to 0\")\n                settings[\"index\"][\"number_of_replicas\"] = 0\n\n        # write template\n        await self.index_template_put(index, d)\n        return d\n\n    async def datastream_list(self) -> list[dict]:\n        \"\"\"\n        Retrieves a list of datastream names (with associated indices) from OpenSearch.\n\n        Returns:\n            list[dict]: The list of datastreams with their backing index as\n            {\n                \"name\": \"datastream_name\",\n                \"indexes\": [\"index1\", \"index2\", ...], <== this is always a list of one element for gulp datastreams\n                \"template\": \"template_name\"\n            }\n        \"\"\"\n        headers = {\"accept\": \"text/plain,application/json\"}\n        l = await self._opensearch.indices.get_data_stream(headers=headers)\n        # MutyLogger.get_instance().debug(json.dumps(l, indent=2))\n        ll = []\n        ds = l.get(\"data_streams\", [])\n        for c in ds:\n            # get count\n            count = await self.datastream_get_count(c[\"name\"])\n            cc = {\n                \"name\": c[\"name\"],\n                \"doc_count\": count,\n                \"indexes\": c[\"indices\"],\n                \"template\": c.get(\"template\", None),\n            }\n            ll.append(cc)\n\n        return ll\n\n    async def datastream_delete(self, ds: str, throw_on_error: bool = False) -> None:\n        \"\"\"\n        Delete the datastream and associated index and template from OpenSearch.\n\n        Args:\n            ds (str): The name of the datastream to delete.\n\n        Returns:\n            None\n        \"\"\"\n        # params = {\"ignore_unavailable\": \"true\"}\n        headers = {\"accept\": \"application/json\"}\n        exists = await self.datastream_exists(ds)\n        try:\n            if not exists and throw_on_error:\n                raise ObjectNotFound(\"datastream %s does not exist\" % (ds))\n\n            res = await self._opensearch.indices.delete_data_stream(ds, headers=headers)\n            MutyLogger.get_instance().debug(\n                'deleted datastream \"%s\", res=%s' % (ds, res)\n            )\n            try:\n                # delete index too\n                res = await self._opensearch.indices.delete(ds)\n                MutyLogger.get_instance().debug(\n                    'deleted index \"%s\", res=%s' % (ds, res)\n                )\n            except:\n                pass\n        finally:\n            # also (try to) delete the corresponding template\n            try:\n                await self.index_template_delete(ds)\n            except Exception as e:\n                MutyLogger.get_instance().error(\n                    \"cannot delete template for index/datastream: %s (%s)\" % (ds, e)\n                )\n\n    async def datastream_exists(self, ds: str) -> bool:\n        \"\"\"\n        Check if a datastream exists in OpenSearch.\n\n        Args:\n            ds (str): The name of the datastream to check.\n\n        Returns:\n            bool: True if the datastream exists, False otherwise.\n        \"\"\"\n        try:\n            await self._opensearch.indices.get_data_stream(name=ds)\n            return True\n        except NotFoundError:\n            return False\n\n    async def datastream_get_count(self, ds: str) -> bool:\n        \"\"\"\n        Get the count of documents in the datastream.\n\n        Args:\n            ds (str): The name of the datastream to check.\n\n        Raises:\n            NotFoundError: If the datastream does not exist.\n        Returns:\n            int: The count of documents in the datastream.\n        \"\"\"\n        res = await self._opensearch.count(index=ds)\n        return res[\"count\"]\n\n    async def datastream_create(\n        self, ds: str, index_template: str = None, delete_first: bool = True\n    ) -> dict:\n        \"\"\"\n        (re)creates the OpenSearch datastream (with backing index) and associates the index template from configuration (or uses the default).\n\n        Args:\n            ds(str): The name of the datastream to be created, the index template will be re/created as \"<index_name>-template\".\n                if it already exists, it will be deleted first.\n            index_template (str, optional): path to the index template to use. Defaults to None (use the default index template).\n            delete_first (bool, optional): Whether to delete the datastream first if it exists. Defaults to True.\n\n        Returns:\n            dict: The response from the OpenSearch client after creating the datastream.\n        \"\"\"\n        if delete_first:\n            # attempt to delete the datastream first, if it exists\n            MutyLogger.get_instance().debug(\n                \"datastream_create, deleting datastream before creation: %s ...\" % (ds)\n            )\n            await self.datastream_delete(ds)\n\n        # create index template, check if we are overriding the default index template.\n        # if so, we only apply gulp-related patching and leaving everything else as is\n        apply_patches = True\n        if index_template is None:\n            template_path = GulpConfig.get_instance().path_index_template()\n        else:\n            template_path = index_template\n            MutyLogger.get_instance().debug(\n                \"datastream_create, using custom index template: %s ...\"\n                % (template_path)\n            )\n            apply_patches = False\n        await self.index_template_set_from_file(\n            ds, template_path, apply_patches=apply_patches\n        )\n\n        try:\n            # create datastream\n            headers = {\"accept\": \"application/json\", \"content-type\": \"application/json\"}\n            r = await self._opensearch.indices.create_data_stream(ds, headers=headers)\n            MutyLogger.get_instance().debug(\n                \"datastream_create, datastream created: %s\" % (r)\n            )\n            return r\n        except Exception as e:\n            # also delete the index template\n            MutyLogger.get_instance().error(\n                \"error creating datastream %s, deleting template\" % (ds)\n            )\n            await self.index_template_delete(ds)\n            raise e\n\n    async def datastream_create_from_raw_dict(\n        self, ds: str, index_template: dict = None, delete_first: bool = True\n    ) -> dict:\n        \"\"\"\n        (re)creates the OpenSearch datastream (with backing index) and associates the index template from a dictionary (or uses the default).\n\n        Args:\n            ds(str): The name of the datastream to be created, the index template will be re/created as \"<index_name>-template\".\n                if it already exists, it will be deleted first.\n            index_template (dict, optional): The index template to use (same format as the output of index_template_get). Defaults to None (use the default index template).\n            delete_first (bool, optional): Whether to delete the datastream first if it exists. Defaults to True.\n\n        Returns:\n            dict: The response from the OpenSearch client after creating the datastream.\n        \"\"\"\n        if delete_first:\n            # attempt to delete the datastream first, if it exists\n            MutyLogger.get_instance().debug(\n                \"datastream_create_from_raw_dict, re/creating datastream: %s ...\" % (ds)\n            )\n            await self.datastream_delete(ds)\n\n        # ensure the index template is set\n        try:\n            if not index_template:\n                # use default\n                template_path = GulpConfig.get_instance().path_index_template()\n                await self.index_template_set_from_file(ds, template_path)\n            else:\n                # use provided as-is, just ensure the index is set\n                index_template[\"index_patterns\"] = [ds]\n                await self.index_template_put(ds, index_template)\n\n            # create datastream\n            headers = {\"accept\": \"application/json\", \"content-type\": \"application/json\"}\n            r = await self._opensearch.indices.create_data_stream(ds, headers=headers)\n            MutyLogger.get_instance().debug(\n                \"datastream_create_from_raw_dict, datastream created: %s\" % (r)\n            )\n            return r\n        except Exception as e:\n            # delete the index template\n            await self.index_template_delete(ds)\n            raise e\n\n    def _bulk_docs_result_to_ingest_chunk(\n        self, bulk_docs: list[tuple[dict, dict]], errors: list[dict] = None\n    ) -> list[dict]:\n        \"\"\"\n        Extracts the ingested documents from a bulk ingestion result, excluding the ones that failed.\n\n        Args:\n            bulk_docs (list[tuple[dict, dict]]): The bulk ingestion documents.\n            errors (list[dict], optional): The errors from the bulk ingestion. Defaults to None.\n\n        Returns:\n            list[dict]: The ingested documents.\n        \"\"\"\n        if not errors:\n            return [\n                {**doc, \"_id\": create_doc[\"create\"][\"_id\"]}\n                for create_doc, doc in zip(bulk_docs[::2], bulk_docs[1::2])\n            ]\n\n        error_ids = {error[\"create\"][\"_id\"] for error in errors}\n        result = [\n            {**doc, \"_id\": create_doc[\"create\"][\"_id\"]}\n            for create_doc, doc in zip(bulk_docs[::2], bulk_docs[1::2])\n            if create_doc[\"create\"][\"_id\"] not in error_ids\n        ]\n\n        return result\n\n    async def update_documents(\n        self,\n        index: str,\n        docs: list[dict],\n        wait_for_refresh: bool = False,\n        replace: bool = False,\n    ) -> tuple[int, list[dict]]:\n        \"\"\"\n        updates documents in an OpenSearch datastream using update_by_query.\n\n        NOTE: this method is not recommended for large updates as it can be slow and resource intensive, but it is ok to use for small updates.\n\n        Args:\n            index (str): Name of the datastream/index to update documents in\n            docs (list[dict]): List of documents to update. Each doc must have _id field\n            wait_for_refresh (bool): Whether to wait for index refresh. Defaults to False\n            replace (bool): Whether to completely replace documents keeping only _id. Defaults to False\n\n        Returns:\n            tuple:\n            - number of successfully updated documents\n            - list of errors if any occurred\n\n        Raises:\n            ValueError: If doc is missing _id field\n        \"\"\"\n        if not docs:\n            return 0, []\n\n        # Build document updates\n        update_operations = []\n        for doc in docs:\n            if \"_id\" not in doc:\n                raise ValueError(\"Document missing _id field\")\n\n            doc_id = doc[\"_id\"]\n            update_fields = {k: v for k, v in doc.items() if k != \"_id\"}\n\n            if replace:\n                # replace entire document except _id\n                operation = {\n                    \"script\": {\n                        \"source\": \"ctx._source.clear(); for (entry in params.updates.entrySet()) { ctx._source[entry.getKey()] = entry.getValue(); }\",\n                        \"lang\": \"painless\",\n                        \"params\": {\"updates\": update_fields},\n                    },\n                    \"query\": {\"term\": {\"_id\": doc_id}},\n                }\n            else:\n                # update only specified fields\n                operation = {\n                    \"script\": {\n                        \"source\": \"\"\"\n                            for (entry in params.updates.entrySet()) {\n                                ctx._source[entry.getKey()] = entry.getValue();\n                            }\n                        \"\"\",\n                        \"lang\": \"painless\",\n                        \"params\": {\"updates\": update_fields},\n                    },\n                    \"query\": {\"term\": {\"_id\": doc_id}},\n                }\n\n            update_operations.append(operation)\n\n        # set parameters\n        params = {\"conflicts\": \"abort\", \"wait_for_completion\": \"true\"}\n        if wait_for_refresh:\n            params[\"refresh\"] = \"true\"\n\n        # Execute updates\n        headers = {\"accept\": \"application/json\", \"content-type\": \"application/json\"}\n\n        success_count = 0\n        errors = []\n\n        try:\n            for operation in update_operations:\n                try:\n                    res = await self._opensearch.update_by_query(\n                        index=index, body=operation, params=params, headers=headers\n                    )\n                    success_count += res.get(\"updated\", 0)\n                except Exception as e:\n                    errors.append({\"query\": operation[\"query\"], \"error\": str(e)})\n\n        except Exception as e:\n            MutyLogger.get_instance().error(f\"error updating documents: {str(e)}\")\n            return 0, [{\"error\": str(e)}]\n\n        return success_count, errors\n\n    async def bulk_ingest(\n        self,\n        index: str,\n        docs: list[dict],\n        flt: GulpIngestionFilter = None,\n        wait_for_refresh: bool = False,\n    ) -> tuple[int, int, list[dict], bool]:\n        \"\"\"\n        ingests a list of GulpDocument into OpenSearch.\n\n        Args:\n            index (str): Name of the index (or datastream) to ingest documents to.\n            docs (list[dict]): The documents to be ingested\n            flt (GulpIngestionFilter, optional): The filter parameters. Defaults to None.\n            wait_for_refresh (bool, optional): Whether to wait for the refresh(=refreshed index is available for searching) to complete. Defaults to False.\n\n        Returns:\n            tuple:\n            - number of skipped (because already existing=duplicated) events\n            - number of failed events\n            - list of ingested documents\n            - whether the ingestion was successful after retrying\n        \"\"\"\n\n        # Filter documents if needed\n        filtered_docs = docs\n        if flt:\n            filtered_docs = [\n                doc\n                for doc in docs\n                if GulpIngestionFilter.filter_doc_for_ingestion(doc, flt)\n                != GulpDocumentFilterResult.SKIP\n            ]\n\n        if not filtered_docs:\n            MutyLogger.get_instance().warning(f\"No document to ingest (flt={flt})\")\n            return 0, 0, [], False\n\n        # Prepare bulk operation format\n        bulk_docs = []\n        for doc in filtered_docs:\n            bulk_docs.append({\"create\": {\"_id\": doc[\"_id\"]}})\n            bulk_docs.append({k: v for k, v in doc.items() if k != \"_id\"})\n\n        # Set request parameters\n        timeout = GulpConfig.get_instance().ingestion_request_timeout()\n        params = {\"timeout\": timeout}\n        if wait_for_refresh:\n            params[\"refresh\"] = \"wait_for\"\n\n        headers = {\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/x-ndjson\",\n        }\n\n        # Execute bulk operation with retries\n        max_retries = GulpConfig.get_instance().ingestion_retry_max()\n        attempt = 0\n        success_after_retry = False\n        res = None\n\n        while attempt < max_retries:\n            try:\n                res = await self._opensearch.bulk(\n                    body=bulk_docs, index=index, params=params, headers=headers\n                )\n\n                # Check for server errors that would require retry\n                if res[\"errors\"]:\n                    for item in res[\"items\"]:\n                        if item[\"create\"][\"status\"] >= 500:\n                            raise Exception(\n                                f\"bulk ingestion failed with status {item['create']['status']}: {item['create']['error']}\"\n                            )\n\n                if attempt > 0:\n                    # mark success after retry if applicable\n                    # (success is intended the bulk operation did not raised an exception, including error items with status 500)\n                    success_after_retry = True\n\n                break  # Success, exit retry loop\n\n            except Exception as ex:\n                attempt += 1\n                if attempt < max_retries:\n                    MutyLogger.get_instance().exception(ex)\n                    retry_delay = GulpConfig.get_instance().ingestion_retry_delay()\n                    MutyLogger.get_instance().warning(\n                        f\"bulk ingestion failed, retrying in {retry_delay}s (attempt {attempt}/{max_retries})\"\n                    )\n                    await asyncio.sleep(retry_delay)\n                else:\n                    raise ex  # All retries failed\n\n        # Process results\n        skipped = failed = 0\n        ingested = []\n\n        if res[\"errors\"]:\n            # Count skipped (already exists) and failed documents\n            skipped = sum(1 for item in res[\"items\"] if item[\"create\"][\"status\"] == 409)\n            failed = sum(\n                1\n                for item in res[\"items\"]\n                if item[\"create\"][\"status\"] not in [200, 201, 409]\n            )\n\n            if failed > 0:\n                failed_items = [\n                    item\n                    for item in res[\"items\"]\n                    if item[\"create\"][\"status\"] not in [200, 201]\n                ]\n                s = json.dumps(failed_items, indent=2)\n                MutyLogger.get_instance().error(\n                    f\"{failed} failed ingestion, {skipped} skipped: {muty.string.make_shorter(s, max_len=10000)}\"\n                )\n\n            # Extract successfully ingested documents\n            error_ids = {\n                item[\"create\"][\"_id\"]\n                for item in res[\"items\"]\n                if item[\"create\"][\"status\"] not in [200, 201]\n            }\n            ingested = [\n                {**doc, \"_id\": action[\"create\"][\"_id\"]}\n                for action, doc in zip(bulk_docs[::2], bulk_docs[1::2])\n                if action[\"create\"][\"_id\"] not in error_ids\n            ]\n        else:\n            # All documents were successfully ingested\n            ingested = [\n                {**doc, \"_id\": action[\"create\"][\"_id\"]}\n                for action, doc in zip(bulk_docs[::2], bulk_docs[1::2])\n            ]\n\n        if skipped > 0:\n            MutyLogger.get_instance().debug(\n                f\"{skipped} skipped, {failed} failed in this bulk ingestion of {len(filtered_docs)} documents!\"\n            )\n\n        if failed > 0:\n            MutyLogger.get_instance().critical(\n                \"Failed is set, ingestion format needs to be fixed!\"\n            )\n\n        return skipped, failed, ingested, success_after_retry\n\n    async def rebase(\n        self,\n        index: str,\n        dest_index: str,\n        offset_msec: int,\n        flt: GulpQueryFilter = None,\n        rebase_script: str = None,\n    ) -> dict:\n        \"\"\"\n        Rebase documents from one OpenSearch index to another with a timestamp offset.\n        Args:\n            index (str): The source index name.\n            dest_index (str): The destination index name.\n            offset_msec (int): The offset in milliseconds from unix epoch to adjust the '@timestamp' field.\n            flt (GulpQueryFilter, optional): if set, it will be used to rebase only a subset of the documents. Defaults to None.\n            rebase_script (str, optional): a [painless script](https://www.elastic.co/guide/en/elasticsearch/painless/current/painless-guide.html) to customize rebasing. Defaults to None (use the default script).\n                the rebase script takes a single parameter `nsec_offset` which is the offset in nanoseconds to apply to the '@timestamp' field.\n        Returns:\n            dict: The response from the OpenSearch reindex operation.\n\n        \"\"\"\n        MutyLogger.get_instance().debug(\n            \"rebase index %s to %s with offset=%d, flt=%s ...\"\n            % (index, dest_index, offset_msec, flt)\n        )\n        if not flt:\n            flt = GulpQueryFilter()\n\n        q = flt.to_opensearch_dsl()\n\n        if rebase_script:\n            convert_script = rebase_script\n        else:\n            convert_script = \"\"\"\n                if (ctx._source['@timestamp'] != null && ctx._source['@timestamp'] != '0') {\n                    ZonedDateTime ts = ZonedDateTime.parse(ctx._source['@timestamp']);\n                    DateTimeFormatter fmt = DateTimeFormatter.ofPattern('yyyy-MM-dd\\\\'T\\\\'HH:mm:ss.nnnnnnnnnX');\n                    ZonedDateTime new_ts = ts.plusNanos(params.offset_nsec);\n                    ctx._source['@timestamp'] = new_ts.format(fmt);\n                    ctx._source['gulp.timestamp'] += params.offset_nsec;\n                }\n            \"\"\"\n        body: dict = {\n            \"source\": {\"index\": index, \"query\": q[\"query\"]},\n            \"dest\": {\"index\": dest_index, \"op_type\": \"create\"},\n            \"script\": {\n                \"lang\": \"painless\",\n                \"source\": convert_script,\n                \"params\": {\n                    \"offset_nsec\": offset_msec * muty.time.MILLISECONDS_TO_NANOSECONDS,\n                },\n            },\n        }\n        params: dict = {\"refresh\": \"true\", \"wait_for_completion\": \"true\", \"timeout\": 0}\n        headers = {\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/x-ndjson\",\n        }\n\n        MutyLogger.get_instance().debug(\"rebase body=%s\" % (body))\n        res = await self._opensearch.reindex(body=body, params=params, headers=headers)\n        MutyLogger.get_instance().debug(\"rebase result=%s\" % (res))\n        return res\n\n    async def index_refresh(self, index: str) -> None:\n        \"\"\"\n        Refresh an index(=make changes available to search) in OpenSearch.\n\n        Args:\n            index (str): Name of the index (or datastream) to refresh.\n\n        Returns:\n            None\n        \"\"\"\n        MutyLogger.get_instance().debug(\"refreshing index: %s\" % (index))\n        res = await self._opensearch.indices.refresh(index=index)\n        MutyLogger.get_instance().debug(\"refreshed index: %s\" % (res))\n\n    async def delete_data_by_operation(\n        self, index: str, operation_id: str, refresh: bool = True\n    ) -> dict:\n        \"\"\"\n        Deletes all data from an index that matches the given operation.\n\n        Args:\n            index (str): Name of the index (or datastream) to delete data from.\n            operation_id (str): The ID of the operation.\n            refresh (bool, optional): Whether to refresh the index after deletion. Defaults to True.\n\n        Returns:\n            None\n        \"\"\"\n        return await self._delete_data_by_operation_source_context(\n            index=index, operation_id=operation_id, refresh=refresh\n        )\n\n    async def delete_data_by_context(\n        self, index: str, operation_id: str, context_id: str, refresh: bool = True\n    ) -> dict:\n        \"\"\"\n        Deletes all data from an index that matches the given operation and context.\n\n        Args:\n            index (str): Name of the index (or datastream) to delete data from.\n            operation_id (str): The ID of the operation.\n            context_id (str): The ID of the context.\n            refresh (bool, optional): Whether to refresh the index after deletion. Defaults to True.\n\n        Returns:\n            None\n        \"\"\"\n        return await self._delete_data_by_operation_source_context(\n            index=index,\n            operation_id=operation_id,\n            context_id=context_id,\n            refresh=refresh,\n        )\n\n    async def delete_data_by_source(\n        self,\n        index: str,\n        operation_id: str,\n        context_id: str,\n        source_id: str,\n        refresh: bool = True,\n    ) -> dict:\n        \"\"\"\n        Deletes all data from an index that matches the given operation, context and source\n\n        Args:\n            index (str): Name of the index (or datastream) to delete data from.\n            operation_id (str): The ID of the operation.\n            context_id (str): The ID of the context.\n            source_id (str): The ID of the source\n            refresh (bool, optional): Whether to refresh the index after deletion. Defaults to True.\n\n        Returns:\n            None\n        \"\"\"\n        return await self._delete_data_by_operation_source_context(\n            index=index,\n            operation_id=operation_id,\n            context_id=context_id,\n            source_id=source_id,\n            refresh=refresh,\n        )\n\n    async def _delete_data_by_operation_source_context(\n        self,\n        index: str,\n        operation_id: str,\n        context_id: str = None,\n        source_id: str = None,\n        refresh: bool = True,\n    ) -> dict:\n\n        # build bool query with must clauses\n        must_clauses = [{\"term\": {\"gulp.operation_id\": operation_id}}]\n\n        if context_id:\n            must_clauses.append({\"term\": {\"gulp.context_id\": context_id}})\n\n        if source_id:\n            must_clauses.append({\"term\": {\"gulp.source_id\": source_id}})\n\n        q = {\"query\": {\"bool\": {\"must\": must_clauses}}}\n\n        params = None\n        if refresh:\n            params = {\"refresh\": \"true\"}\n        headers = {\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/x-ndjson\",\n        }\n\n        res = await self._opensearch.delete_by_query(\n            index=index, body=q, params=params, headers=headers\n        )\n        MutyLogger.get_instance().debug(\"delete_by_query result=%s\" % (res))\n        return res\n\n    def _parse_query_max_min(self, d: dict) -> dict:\n        \"\"\"\n        Parse the query result of query_max_min_per_field.\n\n        Args:\n            d (dict): The query result.\n\n        Returns:\n            dict: The parsed result as\n            {\n                'buckets': list[dict], # the matched events\n                'total': int, # total matches\n            }\n        \"\"\"\n        buckets = d[\"by_type\"][\"buckets\"]\n        dd = {\n            \"buckets\": [\n                {\n                    bucket[\"key\"]: {\n                        \"doc_count\": bucket[\"doc_count\"],\n                        \"max_event.code\": int(bucket[\"max_event.code\"][\"value\"]),\n                        \"min_gulp.timestamp\": int(\n                            bucket[\"min_gulp.timestamp\"][\"value\"]\n                        ),\n                        \"max_gulp.timestamp\": int(\n                            bucket[\"max_gulp.timestamp\"][\"value\"]\n                        ),\n                        \"min_event.code\": int(bucket[\"min_event.code\"][\"value\"]),\n                    }\n                }\n                for bucket in buckets\n            ],\n            \"total\": sum(bucket[\"doc_count\"] for bucket in buckets),\n        }\n        return dd\n\n    async def query_max_min_per_field(\n        self,\n        index: str,\n        group_by: str = None,\n        flt: GulpQueryFilter = None,\n    ):\n        \"\"\"\n        Queries the maximum and minimum @gulp.timestamp and event.code in an index, grouping per type if specified.\n\n        Args:\n            el (AsyncOpenSearch): The OpenSearch client.\n            index (str): Name of the index (or datastream) to query.\n            group_by (str): The field to group by (None to consider all fields).\n            flt (GulpQueryFilter): The query filter.\n\n        Returns: a dict like\n            {\n                'buckets': [\n                    {\n                        'type1': {\n                            'doc_count': 123,\n                            'max_event.code': 123,\n                            'min_gulp.timestamp': 123,\n                            'max_gulp.timestamp': 123,\n                            'min_event.code': 123\n                        }\n                    },\n                    ...\n                ],\n                total: 123\n        \"\"\"\n        if not flt:\n            flt = GulpQueryFilter()\n\n        aggregations = {\n            \"count\": {\"value_count\": {\"field\": \"gulp.timestamp\"}},\n            \"max_gulp.timestamp\": {\"max\": {\"field\": \"gulp.timestamp\"}},\n            \"min_gulp.timestamp\": {\"min\": {\"field\": \"gulp.timestamp\"}},\n            \"max_event.code\": {\"max\": {\"field\": \"gulp.event_code\"}},\n            \"min_event.code\": {\"min\": {\"field\": \"gulp.event_code\"}},\n        }\n        if group_by is not None:\n            aggregations = {\n                \"by_type\": {\n                    \"terms\": {\"field\": group_by},\n                    \"aggs\": aggregations,\n                }\n            }\n            MutyLogger.get_instance().debug(\n                f\"aggregations with group_by={group_by}: {\n                    json.dumps(aggregations, indent=2)}\"\n            )\n\n        q = flt.to_opensearch_dsl()\n        MutyLogger.get_instance().debug(\n            f\"query_max_min_per_field: q={json.dumps(q, indent=2)}\"\n        )\n        body = {\n            \"track_total_hits\": True,\n            \"query\": q[\"query\"],\n            \"aggregations\": aggregations,\n        }\n        headers = {\n            \"content-type\": \"application/json\",\n        }\n\n        res = await self._opensearch.search(body=body, index=index, headers=headers)\n        hits = res[\"hits\"][\"total\"][\"value\"]\n        if not hits:\n            raise ObjectNotFound()\n\n        if group_by:\n            MutyLogger.get_instance().debug(\n                f\"group_by={group_by}, res['aggregations']={\n                    json.dumps(res['aggregations'], indent=2)}\"\n            )\n            return self._parse_query_max_min(res[\"aggregations\"])\n\n        # no group by, standardize the result\n        d = {\n            \"by_type\": {\n                \"buckets\": [\n                    {\n                        \"key\": \"*\",\n                        \"doc_count\": res[\"aggregations\"][\"count\"][\"value\"],\n                        \"max_event.code\": res[\"aggregations\"][\"max_event.code\"],\n                        \"min_event.code\": res[\"aggregations\"][\"min_event.code\"],\n                        \"min_gulp.timestamp\": res[\"aggregations\"][\"min_gulp.timestamp\"],\n                        \"max_gulp.timestamp\": res[\"aggregations\"][\"max_gulp.timestamp\"],\n                    }\n                ]\n            }\n        }\n        return self._parse_query_max_min(d)\n\n    async def _parse_operation_aggregation(\n        self, aggregations: dict, user_id: str\n    ) -> list[dict]:\n        \"\"\"\n        parse OpenSearch operations aggregations and match with collab database operations.\n\n        Args:\n            aggregations (dict): Raw OpenSearch aggregations results\n            user_id (str): The user ID to filter operations\n        Returns:\n            list[dict]: Parsed operations with context and source details\n        \"\"\"\n        # get all operations from collab db\n        # MutyLogger.get_instance().debug(f\"parsing operations aggregations: {json.dumps(aggregations, indent=2)}\")\n        async with GulpCollab.get_instance().session() as sess:\n            u: GulpUser = await GulpUser.get_by_id(sess, user_id)\n            user_group_ids: list[str] = [g.id for g in u.groups] if u.groups else []\n            all_operations = await GulpOperation.get_by_filter(\n                sess, user_id=user_id, user_id_is_admin=u.is_admin(), user_group_ids=user_group_ids\n            )\n\n        # create operation lookup map\n        operation_map = {op.id: op for op in all_operations}\n\n        result = []\n\n        # process each operation bucket\n        for op_bucket in aggregations[\"operations\"][\"buckets\"]:\n            operation_id = op_bucket[\"key\"]\n\n            # look up matching operation\n            if operation_id not in operation_map:\n                continue\n\n            operation: GulpOperation = operation_map[operation_id]\n\n            # build operation entry\n            operation_entry = {\n                \"name\": operation.name,\n                \"index\": operation.index,\n                \"id\": operation.id,\n                \"contexts\": [],\n            }\n\n            # process contexts\n            for ctx_bucket in op_bucket[\"context_id\"][\"buckets\"]:\n                context_id = ctx_bucket[\"key\"]\n\n                # Find matching context in operation\n                matching_context = next(\n                    (ctx for ctx in operation.contexts if ctx.id == context_id), None\n                )\n                if not matching_context:\n                    continue\n\n                context_entry = {\n                    \"name\": matching_context.name,\n                    \"id\": matching_context.id,\n                    \"doc_count\": ctx_bucket[\"doc_count\"],\n                    \"plugins\": [],\n                }\n\n                # Process plugins\n                for plugin_bucket in ctx_bucket[\"plugin\"][\"buckets\"]:\n                    plugin_entry = {\"name\": plugin_bucket[\"key\"], \"sources\": []}\n\n                    # Process sources\n                    for src_bucket in plugin_bucket[\"source_id\"][\"buckets\"]:\n                        source_id = src_bucket[\"key\"]\n\n                        # Find matching source in context\n                        matching_source = next(\n                            (\n                                src\n                                for src in matching_context.sources\n                                if src.id == source_id\n                            ),\n                            None,\n                        )\n                        if not matching_source:\n                            continue\n\n                        source_entry = {\n                            \"name\": matching_source.name,\n                            \"id\": matching_source.id,\n                            \"doc_count\": src_bucket[\"doc_count\"],\n                            \"max_event.code\": int(\n                                src_bucket[\"max_event.code\"][\"value\"]\n                            ),\n                            \"min_event.code\": int(\n                                src_bucket[\"min_event.code\"][\"value\"]\n                            ),\n                            \"min_gulp.timestamp\": int(\n                                src_bucket[\"min_gulp.timestamp\"][\"value\"]\n                            ),\n                            \"max_gulp.timestamp\": int(\n                                src_bucket[\"max_gulp.timestamp\"][\"value\"]\n                            ),\n                        }\n                        plugin_entry[\"sources\"].append(source_entry)\n\n                    if plugin_entry[\"sources\"]:\n                        context_entry[\"plugins\"].append(plugin_entry)\n\n                if context_entry[\"plugins\"]:\n                    operation_entry[\"contexts\"].append(context_entry)\n\n            if operation_entry[\"contexts\"]:\n                result.append(operation_entry)\n\n        return result\n\n    async def query_operations(self, index: str, user_id: str) -> list[dict]:\n        \"\"\"\n        queries the OpenSearch index for each \"operation_id\" value found and returns the aggregations.\n\n        Args:\n            index (str): Name of the index (or datastream) to query\n            user_id (str): The user ID to filter operations\n\n        Returns:\n            liist[dict]: The aggregations result (WARNING: will return at most \"aggregation_max_buckets\" hits, which should cover 99,99% of the usage ....).\n        \"\"\"\n\n        def _create_terms_aggregation(field):\n            return {\"terms\": {\"field\": field, \"size\": max_buckets}}\n\n        max_buckets = GulpConfig.get_instance().aggregation_max_buckets()\n\n        aggs = {\"operations\": _create_terms_aggregation(\"gulp.operation_id\")}\n        aggs[\"operations\"][\"aggs\"] = {\n            \"context_id\": _create_terms_aggregation(\"gulp.context_id\"),\n        }\n        aggs[\"operations\"][\"aggs\"][\"context_id\"][\"aggs\"] = {\n            \"plugin\": _create_terms_aggregation(\"agent.type\")\n        }\n        aggs[\"operations\"][\"aggs\"][\"context_id\"][\"aggs\"][\"plugin\"][\"aggs\"] = {\n            \"source_id\": _create_terms_aggregation(\"gulp.source_id\")\n        }\n        aggs[\"operations\"][\"aggs\"][\"context_id\"][\"aggs\"][\"plugin\"][\"aggs\"][\"source_id\"][\n            \"aggs\"\n        ] = {\n            \"max_gulp.timestamp\": {\"max\": {\"field\": \"gulp.timestamp\"}},\n            \"min_gulp.timestamp\": {\"min\": {\"field\": \"gulp.timestamp\"}},\n            \"max_event.code\": {\"max\": {\"field\": \"gulp.event_code\"}},\n            \"min_event.code\": {\"min\": {\"field\": \"gulp.event_code\"}},\n        }\n        body = {\n            \"track_total_hits\": True,\n            \"aggregations\": aggs,\n            \"size\": 0,\n        }\n        headers = {\n            \"content-type\": \"application/json\",\n        }\n\n        res = await self._opensearch.search(body=body, index=index, headers=headers)\n        hits = res[\"hits\"][\"total\"][\"value\"]\n        if not hits:\n            MutyLogger.get_instance().warning(\n                \"no results found, returning empty aggregations (possibly no data on opensearch)!\"\n            )\n            # raise ObjectNotFound()\n            return []\n        MutyLogger.get_instance().debug(json.dumps(res, indent=2))\n\n        d = {\"total\": hits, \"aggregations\": res[\"aggregations\"]}\n        # MutyLogger.get_instance().debug(json.dumps(d, indent=2))\n        return await self._parse_operation_aggregation(d[\"aggregations\"], user_id)\n\n    async def query_single_document(\n        self,\n        datastream: str,\n        id: str,\n        el: AsyncElasticsearch | AsyncOpenSearch = None,\n    ) -> dict:\n        \"\"\"\n        Get a single event from OpenSearch.\n\n        Args:\n            datastream (str): The name of the datastream or index to query\n            id (str): The ID of the document to retrieve\n            el (AsyncElasticSearch|AsyncOpenSearch, optional): the ElasticSearch/OpenSearch client to use instead of the default OpenSearch. Defaults to None.\n        Returns:\n            dict: The query result.\n\n        Raises:\n            ObjectNotFound: If no results are found.\n        \"\"\"\n        try:\n            # check if datastream is an index\n            if el:\n                res = await el.indices.get_data_stream(name=datastream)\n            else:\n                res = await self._opensearch.indices.get_data_stream(name=datastream)\n\n            # resolve to index\n            index = res[\"data_streams\"][0][\"indices\"][0][\"index_name\"]\n        except Exception:\n            # datastream is actually an index\n            index = datastream\n\n        try:\n            if el:\n                res = await el.get(index=index, id=id)\n            else:\n                res = await self._opensearch.get(index=index, id=id)\n            js = res[\"_source\"]\n            js[\"_id\"] = res[\"_id\"]\n            return js\n        except KeyError:\n            raise ObjectNotFound(\n                f'document with ID \"{id}\" not found in datastream={\n                    datastream} index={index}'\n            )\n\n    async def _search_dsl_internal(\n        self,\n        index: str,\n        parsed_options: dict,\n        q: dict,\n        el: AsyncElasticsearch | AsyncOpenSearch = None,\n        raise_on_error: bool = True,\n    ) -> tuple[int, list[dict], list[dict]]:\n        \"\"\"\n        Executes a raw DSL query on OpenSearch and returns the results.\n\n        Args:\n            index (str): Name of the index (or datastream) to query.\n            parsed_options (dict): The parsed query options.\n            q (dict): The DSL query to execute.\n            el (AsyncElasticSearch|AsyncOpenSearch, optional): an EXTERNAL ElasticSearch/OpenSearch client to use instead of the default internal gulp's OpenSearch. Defaults to None.\n            raise_on_error (bool, optional): Whether to raise an exception if no more hits are found. Defaults to True.\n\n        Returns:\n            tuple:\n            - total_hits (int): The total number of hits found.\n            - docs (list[dict]): The documents found.\n            - search_after (list[dict]): to be passed via `q_options.search_after` in the next iteration.\n\n        Raises:\n            ObjectNotFound: If no more hits are found.\n        \"\"\"\n        body = q\n        body[\"track_total_hits\"] = True\n        for k, v in parsed_options.items():\n            if v:\n                body[k] = v\n        # MutyLogger.get_instance().debug(\"index=%s, query_raw body=%s, parsed_options=%s\" % (index, json.dumps(body, indent=2), json.dumps(parsed_options, indent=2)))\n\n        headers = {\n            \"content-type\": \"application/json\",\n        }\n\n        if el:\n            if isinstance(el, AsyncElasticsearch):\n                # use the ElasticSearch client provided\n                res = await el.search(\n                    index=index,\n                    track_total_hits=True,\n                    query=q[\"query\"],\n                    sort=parsed_options[\"sort\"],\n                    size=parsed_options[\"size\"],\n                    search_after=parsed_options[\"search_after\"],\n                    source=parsed_options[\"_source\"],\n                    highlight=q.get(\"highlight\", None),\n                )\n            else:\n                # external opensearch\n                res = await el.search(body=body, index=index, headers=headers)\n        else:\n            # use the OpenSearch client (default)\n            res = await self._opensearch.search(body=body, index=index, headers=headers)\n\n        # MutyLogger.get_instance().debug(\"_search_dsl_internal: res=%s\" % (json.dumps(res, indent=2)))\n        hits = res[\"hits\"][\"hits\"]\n        if not hits:\n            if raise_on_error:\n                raise ObjectNotFound(\"no more hits\")\n            else:\n                return 0, [], []\n\n        # get data\n        total_hits = res[\"hits\"][\"total\"][\"value\"]\n        # docs = [{**hit[\"_source\"], \"_id\": hit[\"_id\"]} for hit in hits]\n        docs = [\n            {\n                **hit[\"_source\"],\n                \"_id\": hit[\"_id\"],\n                **({\"highlight\": hit[\"highlight\"]} if \"highlight\" in hit else {}),\n            }\n            for hit in hits\n        ]\n\n        search_after = hits[-1][\"sort\"]\n        return total_hits, docs, search_after\n\n    async def search_dsl_sync(\n        self,\n        index: str,\n        q: dict,\n        q_options: \"GulpQueryParameters\" = None,\n        el: AsyncElasticsearch | AsyncOpenSearch = None,\n        raise_on_error: bool = True,\n    ) -> tuple[int, list[dict], list[dict]]:\n        \"\"\"\n        Executes a raw DSL query on OpenSearch/Elasticsearch and returns the results.\n\n        Args:\n            index (str): Name of the index (or datastream) to query.\n            q (dict): The DSL query to execute.\n            el (AsyncElasticSearch|AsyncOpenSearch, optional): an EXTERNAL ElasticSearch/OpenSearch client to use instead of the default internal gulp's OpenSearch. Defaults to None.\n            raise_on_error (bool, optional): Whether to raise an exception if no more hits are found. Defaults to True.\n\n        Returns:\n            tuple:\n            - total_hits (int): The total number of hits found.\n            - docs (list[dict]): The documents found.\n            - search_after (list[dict]): to be passed via `q_options.search_after` in the next iteration.\n\n        Raises:\n            ObjectNotFound: If no more hits are found.\n        \"\"\"\n        from gulp.api.opensearch.query import GulpQueryParameters\n\n        if not q_options:\n            q_options = GulpQueryParameters()\n\n        parsed_options: dict = q_options.parse()\n        total_hits, docs, search_after = await self._search_dsl_internal(\n            index, parsed_options, q, el, raise_on_error=raise_on_error\n        )\n        return total_hits, docs, search_after\n\n    async def search_dsl(\n        self,\n        sess: AsyncSession,\n        index: str,\n        q: dict,\n        req_id: str = None,\n        ws_id: str = None,\n        user_id: str = None,\n        q_options: \"GulpQueryParameters\" = None,\n        el: AsyncElasticsearch | AsyncOpenSearch = None,\n        callback: callable = None,\n        callback_args: dict = None,\n        callback_chunk: callable = None,\n        callback_chunk_args: dict = None,\n    ) -> tuple[int, int]:\n        \"\"\"\n        Executes a raw DSL query on OpenSearch and optionally streams the results on the websocket.\n\n        NOTE: in the end, all gulp **local** queries and all **elasticsearch/opensearch** based queries for external plugins will be done through this function.\n\n        Args:\n            sess (AsyncSession): SQLAlchemy session (to check if request has been canceled and/or create notes on match)\n            index (str): Name of the index (or datastream) to query. may also be a comma-separated list of indices/datastreams, or \"*\" to query all.\n            q (dict): The DSL query to execute (will be run as \"query\": q }, so be sure it is stripped of the root \"query\" key)\n            req_id (str), optional: The request ID for the query\n            ws_id (str, optional): The websocket ID to send the results to, pass None to disable sending on the websocket.\n            user_id (str, optional): The user ID performing the query\n            q_options (GulpQueryOptions, optional): Additional query options. Defaults to None (use defaults).\n            el (AsyncElasticSearch|AsyncOpenSearch, optional): an EXTERNAL ElasticSearch/OpenSearch client to use instead of the default internal gulp's OpenSearch. Defaults to None.\n            callback (callable, optional): the callback to call for each document found. Defaults to None.\n                the callback must be defined as:\n                async def callback(doc: dict, idx: int, **kwargs) -> None\n\n                NOTE: if callback is set, all postprocessing on the document is disabled (including sending on the websockets and note creations) and must be done by the callback if needed.\n            callback_args (dict, optional): further arguments to pass to the callback. Defaults to None.\n            callback_chunk (callable, optional): the callback to call for each chunk of documents found. Defaults to None.\n                the callback must be defined as:\n                async def callback_chunk(docs: list[dict], **kwargs) -> None\n\n                NOTE: if callback is set, all postprocessing on the document is disabled (including sending on the websockets and note creations) and must done by the callback if needed.\n            callback_chunk_args (dict, optional): further arguments to pass to the callback_chunk. Defaults to None.\n        Return:\n            tuple:\n            - processed (int): The number of documents processed (on a clean exit, this will be equal to total_hits).\n            - total_hits (int): The total number of hits found.\n\n        Raises:\n            ValueError: argument error\n            Exception: If an error occurs during the query.\n        \"\"\"\n        from gulp.api.opensearch.query import GulpQueryParameters\n\n        if not q_options:\n            # use defaults\n            q_options = GulpQueryParameters()\n\n        if q_options.note_parameters.create_notes and not sess:\n            raise ValueError(\"sess is required if create_notes is set!\")\n\n        if el:\n            # force use_elasticsearch_api if el is provided\n            MutyLogger.get_instance().debug(\n                \"search_dsl: using provided ElasticSearch/OpenSearch client %s, class=%s\"\n                % (el, el.__class__)\n            )\n\n        parsed_options: dict = q_options.parse()\n        processed: int = 0\n        chunk_num: int = 0\n        check_canceled_count: int = 0\n\n        while True:\n            last: bool = False\n            docs: list[dict] = []\n            try:\n                total_hits, docs, search_after = await self._search_dsl_internal(\n                    index, parsed_options, q, el\n                )\n                if q_options.loop:\n                    # auto setup for next iteration\n                    parsed_options[\"search_after\"] = search_after\n\n                processed += len(docs)\n                if processed >= total_hits or not q_options.loop:\n                    # this is the last chunk\n                    last = True\n\n                # MutyLogger.get_instance().debug(\"retrieved chunk of %d documents, total=%d\" % (len(docs), total_hits))\n\n                check_canceled_count += 1\n                if check_canceled_count >= 10:\n                    # every 10 chunk, check for request cancelation\n                    check_canceled_count = 0\n                    stats: GulpRequestStats = await GulpRequestStats.get_by_id(\n                        sess, req_id, throw_if_not_found=False\n                    )\n                    # MutyLogger.get_instance().debug(\"search_dsl: request %s stats=%s\" % (req_id, stats))\n                    if stats and stats.status == GulpRequestStatus.CANCELED:\n                        last = True\n                        MutyLogger.get_instance().warning(\n                            \"search_dsl: request %s cancelled!\" % (req_id)\n                        )\n\n                if callback:\n                    # call the callback for each document\n                    for idx, doc in enumerate(docs):\n                        await callback(\n                            doc,\n                            processed + idx,\n                            **callback_args if callback_args else {},\n                        )\n\n                if callback_chunk:\n                    # call the callback for each chunk of documents\n                    await callback_chunk(\n                        docs,\n                        total_hits=total_hits,\n                        last=last,\n                        chunk_num=chunk_num,\n                        **callback_chunk_args if callback_chunk_args else {},\n                    )\n\n            except ObjectNotFound as ex:\n                if processed == 0 and ws_id:\n                    # no results\n                    return 0, 0\n                else:\n                    # indicates the last result\n                    last = True\n            except Exception as ex:\n                # something went wrong\n                MutyLogger.get_instance().exception(ex)\n                raise ex\n\n            if ws_id and not callback and not callback_chunk:\n                # build a GulpDocumentsChunk and send to websocket\n                chunk = GulpDocumentsChunkPacket(\n                    docs=docs,\n                    num_docs=len(docs),\n                    chunk_number=chunk_num,\n                    total_hits=total_hits,\n                    last=last,\n                    search_after=search_after,\n                    name=q_options.name,\n                )\n                GulpWsSharedQueue.get_instance().put(\n                    type=GulpWsQueueDataType.DOCUMENTS_CHUNK,\n                    ws_id=ws_id,\n                    user_id=user_id,\n                    req_id=req_id,\n                    data=chunk.model_dump(exclude_none=True),\n                )\n\n            if (\n                q_options.note_parameters.create_notes\n                and not callback\n                and not callback_chunk\n            ):\n                # automatically generate notes\n                await GulpNote.bulk_create_from_documents(\n                    sess,\n                    user_id,\n                    ws_id=ws_id,\n                    req_id=req_id,\n                    docs=docs,\n                    name=q_options.note_parameters.note_name,\n                    tags=q_options.note_parameters.note_tags,\n                    color=q_options.note_parameters.note_color,\n                    glyph_id=q_options.note_parameters.note_glyph_id,\n                )\n\n            # next chunk\n            chunk_num += 1\n            if last or not q_options.loop:\n                break\n\n        MutyLogger.get_instance().info(\n            \"search_dsl: processed %d documents, total=%d, chunks=%d\"\n            % (processed, total_hits, chunk_num)\n        )\n        return processed, total_hits\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/common.py", "content": "import asyncio\nimport json\nimport multiprocessing\nimport os\nfrom typing import Any\n\nimport requests\nimport websockets\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.opensearch.filters import GulpIngestionFilter\nfrom gulp.api.rest.test_values import (\n    TEST_CONTEXT_NAME,\n    TEST_HOST,\n    TEST_INDEX,\n    TEST_OPERATION_ID,\n    TEST_REQ_ID,\n    TEST_WS_ID,\n)\nfrom gulp.api.ws_api import GulpWsAuthPacket\nfrom gulp.structs import GulpPluginParameters\n\n\nasync def _test_init(\n    login_admin_and_reset_operation: bool = True,\n    recreate: bool = False,\n    reset_collab: bool = False,\n) -> None:\n    \"\"\"\n    initialize the environment, automatically called before each test by the _setup() fixture\n\n    :param login_admin_and_reset_operation: if True, login as admin and reset the operation\n    :param recreate: if True, recreate the operation\n    :param reset_collab: if True, reset the collab db\n    \"\"\"\n    GulpAPICommon.get_instance().init(\n        host=TEST_HOST, ws_id=TEST_WS_ID, req_id=TEST_REQ_ID, index=TEST_INDEX\n    )\n    from gulp.api.rest.client.db import GulpAPIDb\n    from gulp.api.rest.client.user import GulpAPIUser\n\n    if reset_collab:\n        # reset the collab\n        admin_token = await GulpAPIUser.login(\"admin\", \"admin\")\n        assert admin_token\n        await GulpAPIDb.postgres_reset_collab(admin_token, full_reset=True)\n\n    if login_admin_and_reset_operation:\n        await GulpAPIUser.login_admin_and_reset_operation(\n            TEST_OPERATION_ID, recreate=recreate\n        )\n\n\ndef _process_file_in_worker_process(\n    host: str,\n    ws_id: str,\n    req_id: str,\n    index: str,\n    plugin: str,\n    plugin_params: GulpPluginParameters,\n    flt: GulpIngestionFilter,\n    file_path: str,\n    file_total: int,\n):\n    \"\"\"\n    process a file\n    \"\"\"\n\n    async def _process_file_async():\n        GulpAPICommon.get_instance().init(\n            host=host, ws_id=ws_id, req_id=req_id, index=index\n        )\n        MutyLogger.get_instance().info(f\"processing file: {file_path}\")\n        from gulp.api.rest.client.user import GulpAPIUser\n\n        ingest_token = await GulpAPIUser.login(\"ingest\", \"ingest\")\n        assert ingest_token\n\n        # ingest the file\n        from gulp.api.rest.client.ingest import GulpAPIIngest\n\n        await GulpAPIIngest.ingest_file(\n            ingest_token,\n            file_path=file_path,\n            operation_id=TEST_OPERATION_ID,\n            context_name=TEST_CONTEXT_NAME,\n            plugin=plugin,\n            flt=flt,\n            plugin_params=plugin_params,\n            file_total=file_total,\n        )\n\n    asyncio.run(_process_file_async())\n\n\nasync def _test_ingest_generic(\n    files: list[str],\n    plugin: str,\n    check_ingested: int,\n    check_processed: int = None,\n    plugin_params: GulpPluginParameters = None,\n    flt: GulpIngestionFilter = None,\n) -> str:\n    \"\"\"\n    for each file, spawn a process using multiprocessing and perform ingestion with the selected plugin\n\n    :param files: list of files to ingest\n    :param plugin: plugin to use\n    :param check_ingested: number of ingested records to check\n    :param check_processed: number of processed records to check\n    :param plugin_params: plugin parameters\n    :param flt: ingestion filter\n    \"\"\"\n    # this must be called manually since we're in a worker process and the _setup() fixture has not been called there...\n    await _test_init(False)\n\n    # for each file, spawn a process using multiprocessing\n    for file in files:\n        p = multiprocessing.Process(\n            target=_process_file_in_worker_process,\n            args=(\n                TEST_HOST,\n                TEST_WS_ID,\n                TEST_REQ_ID,\n                TEST_INDEX,\n                plugin,\n                plugin_params,\n                flt,\n                file,\n                len(files),\n            ),\n        )\n        p.start()\n\n    # wait for all processes to finish\n    await _test_ingest_ws_loop(\n        check_ingested=check_ingested, check_processed=check_processed\n    )\n\n\nasync def _test_ingest_ws_loop(\n    check_ingested: int = None,\n    check_processed: int = None,\n    check_skipped: int = None,\n    success: bool = None,\n):\n    \"\"\"\n    open a websocket and wait for the ingestion to complete, optionally enforcing check of the number of ingested/processed records\n\n    :param check_ingested: if not None, check the number of ingested records\n    :param check_processed: if not None, check the number of processed records\n    :param check_skipped: if not None, check the number of skipped records\n    :param success: if not None, check if the ingestion was successful\n    \"\"\"\n    _, host = TEST_HOST.split(\"://\")\n    ws_url = f\"ws://{host}/ws\"\n    test_completed = False\n    records_ingested = 0\n    records_processed = 0\n    records_skipped = 0\n\n    async with websockets.connect(ws_url) as ws:\n        # connect websocket\n        p: GulpWsAuthPacket = GulpWsAuthPacket(token=\"monitor\", ws_id=TEST_WS_ID)\n        await ws.send(p.model_dump_json(exclude_none=True))\n\n        # receive responses\n        try:\n            while True:\n                response = await ws.recv()\n                data = json.loads(response)\n\n                # wait for the stats update\n                if data[\"type\"] == \"stats_update\":\n                    # stats update\n                    stats_packet = data[\"data\"][\"data\"]\n                    MutyLogger.get_instance().info(f\"ingestion stats: {stats_packet}\")\n                    records_ingested = stats_packet.get(\"records_ingested\", 0)\n                    records_processed = stats_packet.get(\"records_processed\", 0)\n                    records_skipped = stats_packet.get(\"records_skipped\", 0)\n\n                    # perform checks\n                    skipped_test_succeeded = True\n                    processed_test_succeeded = True\n                    ingested_test_succeeded = True\n                    success_test_succeeded = True\n                    if check_ingested is not None:\n                        if records_ingested == check_ingested:\n                            MutyLogger.get_instance().info(\n                                \"all %d records ingested!\" % (check_ingested)\n                            )\n                            ingested_test_succeeded = True\n                        else:\n                            ingested_test_succeeded = False\n\n                    if check_processed is not None:\n                        if records_processed == check_processed:\n                            MutyLogger.get_instance().info(\n                                \"all %d records processed!\" % (check_processed)\n                            )\n                            processed_test_succeeded = True\n                        else:\n                            processed_test_succeeded = False\n\n                    if check_skipped is not None:\n\n                        if records_skipped == check_skipped:\n                            MutyLogger.get_instance().info(\n                                \"all %d records skipped!\" % (check_skipped)\n                            )\n                            skipped_test_succeeded = True\n                        else:\n                            skipped_test_succeeded = False\n\n                    if success is not None:\n                        if stats_packet[\"status\"] == \"done\":\n                            MutyLogger.get_instance().info(\"success!\")\n                            success_test_succeeded = True\n                        else:\n                            success_test_succeeded = False\n\n                    if (\n                        ingested_test_succeeded\n                        and processed_test_succeeded\n                        and skipped_test_succeeded\n                        and success_test_succeeded\n                    ):\n                        MutyLogger.get_instance().info(\n                            \"all tests succeeded, breaking the loop!\"\n                        )\n                        test_completed = True\n                        break\n\n                    # check for failed/canceled\n                    if (\n                        stats_packet[\"status\"] == \"failed\"\n                        or stats_packet[\"status\"] == \"canceled\"\n                    ):\n                        break\n\n                # ws delay\n                await asyncio.sleep(0.1)\n\n        except websockets.exceptions.ConnectionClosed as ex:\n            MutyLogger.get_instance().exception(ex)\n\n    MutyLogger.get_instance().info(\n        f\"found_ingested={records_ingested} (requested={check_ingested}), found_processed={\n            records_processed} (requested={check_processed}), found_skipped={records_skipped} (requested={check_skipped})\"\n    )\n    assert test_completed\n    MutyLogger.get_instance().info(\"_test_ingest_ws_loop succeeded!\")\n\n\nclass GulpAPICommon:\n    _instance: \"GulpAPICommon\" = None\n\n    def __init__(self):\n        pass\n\n    def __new__(cls):\n        \"\"\"\n        Create a new instance of the class.\n        \"\"\"\n        if not cls._instance:\n            cls._instance = super().__new__(cls)\n            cls._instance._initialize()\n        return cls._instance\n\n    @classmethod\n    def get_instance(cls):\n        if not cls._instance:\n            cls._instance = cls()\n        return cls._instance\n\n    def _initialize(self):\n        MutyLogger.get_instance(\"gulp_test\")\n\n    def init(\n        self,\n        host: str,\n        ws_id: str = None,\n        req_id: str = None,\n        index: str = None,\n        log_request: bool = False,\n        log_response: bool = False,\n    ):\n        \"\"\"\n        must be called before any other method\n        \"\"\"\n        self.index = index\n        self.ws_id = ws_id\n        self.req_id = req_id\n        self.host = host\n        self._log_res = log_request\n        self._log_req = log_response\n\n    def _make_url(self, endpoint: str) -> str:\n        return f\"{self.host}/{endpoint}\"\n\n    def _log_request(self, method: str, url: str, params: dict):\n        if not self._log_req:\n            return\n        MutyLogger.get_instance().debug(f\"REQUEST {method} {url}\")\n        MutyLogger.get_instance().debug(\n            f\"REQUEST PARAMS: {json.dumps(params, indent=2)}\"\n        )\n\n    def _log_response(self, r: requests.Response):\n        if not self._log_res:\n            return\n        MutyLogger.get_instance().debug(f\"RESPONSE Status: {r.status_code}\")\n        MutyLogger.get_instance().debug(\n            f\"RESPONSE Body: {json.dumps(r.json(), indent=2)}\"\n        )\n\n    async def make_request(\n        self,\n        method: str,\n        endpoint: str,\n        params: dict,\n        token: str = None,\n        body: Any = None,\n        files: dict = None,\n        headers: dict = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"\n        make request, verify status, return \"data\" member or {}\n        params:\n            files: dict of file objects, e.g. {'file': ('filename.txt', open('file.txt', 'rb'))}\n        \"\"\"\n        url = self._make_url(endpoint)\n        if headers:\n            headers.update({\"token\": token})\n        else:\n            headers = {\"token\": token} if token else {}\n\n        self._log_request(\n            method,\n            url,\n            {\"params\": params, \"body\": body, \"headers\": headers, \"files\": files},\n        )\n\n        # handle file uploads and regular requests\n        if files:\n            # for file uploads, body data needs to be part of form-data\n            data = body if body else None\n            r = requests.request(\n                method, url, headers=headers, params=params, files=files, data=data\n            )\n        elif method in [\"POST\", \"PATCH\", \"PUT\"] and body:\n            r = requests.request(method, url, headers=headers, params=params, json=body)\n        else:\n            r = requests.request(method, url, headers=headers, params=params)\n\n        self._log_response(r)\n        assert r.status_code == expected_status\n\n        return r.json().get(\"data\") if r.status_code == 200 else {}\n\n    async def object_delete(\n        self,\n        token: str,\n        object_id: str,\n        api: str,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"\n        common object deletion\n        \"\"\"\n        MutyLogger.get_instance().info(f\"Deleting object {object_id}, api={api}...\")\n        params = {\n            \"object_id\": object_id,\n            \"ws_id\": req_id or self.ws_id,\n            \"req_id\": req_id or self.req_id,\n        }\n        res = await self.make_request(\n            \"DELETE\", api, params=params, token=token, expected_status=expected_status\n        )\n        return res\n\n    async def object_get_by_id(\n        self,\n        token: str,\n        object_id: str,\n        api: str,\n        req_id: str = None,\n        expected_status: int = 200,\n        **kwargs,\n    ) -> dict:\n        \"\"\"\n        common object get\n        \"\"\"\n        MutyLogger.get_instance().info(f\"Getting object {object_id}, api={api}...\")\n        params = {\"object_id\": object_id, \"req_id\": req_id or self.req_id, **kwargs}\n        res = await self.make_request(\n            \"GET\",\n            api,\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    async def object_list(\n        self,\n        token: str,\n        api: str,\n        flt: GulpCollabFilter = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        \"\"\"\n        common object list\n        \"\"\"\n        MutyLogger.get_instance().info(\"Listing objects: api=%s ...\" % (api))\n        res = await self.make_request(\n            \"POST\",\n            api,\n            params={\"req_id\": req_id or self.req_id},\n            body=(\n                flt.model_dump(by_alias=True, exclude_none=True, exclude_defaults=True)\n                if flt\n                else None\n            ),\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/db.py", "content": "import os\n\nfrom muty.log import MutyLogger\n\nfrom gulp.api.opensearch.filters import GulpQueryFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\nfrom gulp.api.rest.client.user import GulpAPIUser\n\n\nclass GulpAPIDb:\n    \"\"\"\n    bindings to call gulp's db related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def opensearch_list_index(\n        token: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        res = await api_common.make_request(\n            \"GET\",\n            \"opensearch_list_index\",\n            params={\n                \"req_id\": req_id or api_common.req_id,\n            },\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def opensearch_delete_index(\n        token: str,\n        index: str,\n        delete_operation: bool = True,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"index\": index,\n            \"delete_operation\": delete_operation,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        res = await api_common.make_request(\n            \"DELETE\",\n            \"opensearch_delete_index\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def opensearch_rebase_index(\n        token: str,\n        operation_id: str,\n        dest_index: str,\n        offset_msec: int,\n        flt: GulpQueryFilter = None,\n        rebase_script: str = None,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"dest_index\": dest_index,\n            \"offset_msec\": offset_msec,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {}\n        if flt:\n            body[\"flt\"] = flt.model_dump(exclude_none=True)\n        if rebase_script:\n            body[\"rebase_script\"] = rebase_script\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"opensearch_rebase_index\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def gulp_reset(token: str, req_id: str = None) -> None:\n        api_common = GulpAPICommon.get_instance()\n        await api_common.make_request(\n            \"POST\",\n            \"gulp_reset\",\n            params={\"req_id\": req_id or api_common.req_id},\n            token=token,\n        )\n\n    @staticmethod\n    async def postgres_reset_collab(\n        token: str,\n        full_reset: bool = False,\n        restart_process: bool = False,\n        req_id: str = None,\n    ) -> None:\n        api_common = GulpAPICommon.get_instance()\n        await api_common.make_request(\n            \"POST\",\n            \"postgres_reset_collab\",\n            params={\n                \"restart_processes\": restart_process,\n                \"full_reset\": full_reset,\n                \"req_id\": req_id or api_common.req_id,\n            },\n            token=token,\n        )\n\n    @staticmethod\n    async def reset_all_as_admin(req_id: str = None) -> None:\n        no_reset = os.getenv(\"GULP_NO_RESET\", None)\n        if no_reset:\n            MutyLogger.get_instance().info(\n                \"GULP_NO_RESET is set, skipping reset_all_as_admin.\"\n            )\n            return\n        MutyLogger.get_instance().info(\n            \"Resetting gULP (both collab and opensearch, creating default data) ...\"\n        )\n        token = await GulpAPIUser.login_admin()\n        await GulpAPIDb.gulp_reset(token, req_id=req_id)\n\n    @staticmethod\n    async def reset_collab_as_admin(\n        full_reset: bool = False, req_id: str = None\n    ) -> None:\n        \"\"\"\n        NOTE: using full_reset=True means also the test operation must be recreated\n        \"\"\"\n        no_reset = os.getenv(\"GULP_NO_RESET_COLLAB\", None)\n        if no_reset:\n            MutyLogger.get_instance().info(\n                \"GULP_NO_RESET_COLLAB is set, skipping reset_collab_as_admin.\"\n            )\n            return\n        MutyLogger.get_instance().info(\n            \"Resetting gULP collab database, full_reset=%r ...\" % (full_reset)\n        )\n        token = await GulpAPIUser.login_admin(req_id=req_id)\n        await GulpAPIDb.postgres_reset_collab(\n            token, full_reset=full_reset, restart_process=False, req_id=req_id\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/rest/client/glyph.py", "content": "import os\nfrom io import BytesIO\n\nimport muty.file\n\nfrom gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPIGlyph:\n    \"\"\"\n    bindings to call gulp's glyph related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def glyph_create(\n        token: str,\n        img_path: str,\n        name: str = None,\n        private: bool = False,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        buffer = await muty.file.read_file_async(img_path)\n        files = {\"img\": (os.path.basename(img_path), BytesIO(buffer))}\n        params = {\n            \"name\": name,\n            \"private\": private,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"glyph_create\",\n            params=params,\n            files=files,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def glyph_update(\n        token: str,\n        object_id: str,\n        img_path: str = None,\n        name: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        if img_path:\n            buffer = await muty.file.read_file_async(img_path)\n            files = {\"img\": (os.path.basename(img_path), BytesIO(buffer))}\n        else:\n            files = None\n\n        params = {\n            \"name\": name,\n            \"object_id\": object_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"glyph_update\",\n            params=params,\n            files=files,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def glyph_delete(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_delete(\n            token=token,\n            object_id=object_id,\n            api=\"glyph_delete\",\n            req_id=req_id,\n            ws_id=ws_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def glyph_get_by_id(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_get_by_id(\n            token=token,\n            object_id=object_id,\n            api=\"glyph_get_by_id\",\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def glyph_list(\n        token: str,\n        flt: GulpCollabFilter = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_list(\n            token=token,\n            api=\"glyph_list\",\n            flt=flt,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/highlight.py", "content": "from gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPIHighlight:\n    \"\"\"\n    bindings to call gulp's highlight related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def highlight_create(\n        token: str,\n        operation_id: str,\n        source_id: str,\n        time_range: tuple[int, int],\n        name: str = None,\n        tags: list[str] = None,\n        glyph_id: str = None,\n        color: str = None,\n        ws_id: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"operation_id\": operation_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"source_id\": source_id,\n            \"name\": name,\n            \"glyph_id\": glyph_id,\n            \"color\": color,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"time_range\": time_range,\n            \"tags\": tags,\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"highlight_create\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def highlight_update(\n        token: str,\n        object_id: str,\n        time_range: tuple[int, int] = None,\n        name: str = None,\n        tags: list[str] = None,\n        glyph_id: str = None,\n        color: str = None,\n        private: bool = False,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"object_id\": object_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"name\": name,\n            \"private\": private,\n            \"glyph_id\": glyph_id,\n            \"color\": color,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"time_range\": time_range,\n            \"tags\": tags,\n        }\n\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"highlight_update\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def highlight_delete(\n        token: str,\n        object_id: str,\n        ws_id: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"object_id\": object_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        return await api_common.make_request(\n            \"DELETE\",\n            \"highlight_delete\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def highlight_get_by_id(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_get_by_id(\n            token=token,\n            object_id=object_id,\n            req_id=req_id,\n            api=\"highlight_get_by_id\",\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def highlight_list(\n        token: str,\n        flt: GulpCollabFilter = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_list(\n            token=token,\n            api=\"highlight_list\",\n            flt=flt,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/ingest.py", "content": "import json\nimport os\nfrom typing import Dict, Optional\n\nimport muty.crypto\nfrom muty.log import MutyLogger\n\nfrom gulp.api.opensearch.filters import GulpIngestionFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\nfrom gulp.structs import GulpPluginParameters\n\n\nclass GulpAPIIngest:\n    \"\"\"Bindings to call gulp's ingest related API endpoints\"\"\"\n\n    @staticmethod\n    async def ingest_file(\n        token: str,\n        file_path: str,\n        operation_id: str,\n        context_name: str,\n        plugin: str,\n        file_total: int = 1,\n        flt: Optional[GulpIngestionFilter] = None,\n        plugin_params: Optional[GulpPluginParameters] = None,\n        ws_id: str = None,\n        req_id: str = None,\n        restart_from: int = 0,\n        file_sha1: str = None,\n        total_file_size: int = 0,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        if not total_file_size:\n            total_file_size = os.path.getsize(file_path)\n\n        if not file_sha1:\n            file_sha1 = await muty.crypto.hash_sha1_file(file_path)\n\n        params = {\n            \"operation_id\": operation_id,\n            \"context_name\": context_name,\n            \"plugin\": plugin,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n            \"file_total\": file_total,\n        }\n\n        payload = {\n            \"flt\": flt.model_dump(exclude_none=True) if flt else {},\n            \"file_sha1\": file_sha1,\n            \"plugin_params\": (\n                plugin_params.model_dump(exclude_none=True) if plugin_params else {}\n            ),\n            \"original_file_path\": file_path,\n        }\n\n        f = open(file_path, \"rb\")\n        if restart_from > 0:\n            # advance to the restart offset\n            f.seek(restart_from)\n\n        files = {\n            \"payload\": (\"payload.json\", json.dumps(payload), \"application/json\"),\n            \"f\": (\n                os.path.basename(file_path),\n                f,\n                \"application/octet-stream\",\n            ),\n        }\n\n        headers = {\"size\": str(total_file_size), \"continue_offset\": str(restart_from)}\n\n        return await api_common.make_request(\n            \"POST\",\n            \"ingest_file\",\n            params=params,\n            token=token,\n            files=files,\n            headers=headers,\n            expected_status=expected_status,\n        )\n\n\n    @staticmethod\n    async def ingest_zip(\n        token: str,\n        file_path: str,\n        operation_id: str,\n        context_name: str,\n        flt: GulpIngestionFilter = None,\n        ws_id: str = None,\n        req_id: str = None,\n        restart_from: int = 0,\n        file_sha1: str = None,\n        total_file_size: int = 0,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"Ingest a ZIP archive containing files to process\"\"\"\n        api_common = GulpAPICommon.get_instance()\n        if not total_file_size:\n            total_file_size = os.path.getsize(file_path)\n\n        if not file_sha1:\n            file_sha1 = await muty.crypto.hash_sha1_file(file_path)\n\n        params = {\n            \"operation_id\": operation_id,\n            \"context_name\": context_name,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        payload = {\n            \"flt\": flt.model_dump(exclude_none=True) if flt else {},\n            \"file_sha1\": file_sha1,\n            \"original_file_path\": file_path,\n        }\n\n        f = open(file_path, \"rb\")\n        if restart_from > 0:\n            # advance to the restart offset\n            f.seek(restart_from)\n\n        files = {\n            \"payload\": (\"payload.json\", json.dumps(payload), \"application/json\"),\n            \"f\": (\n                os.path.basename(file_path),\n                f,\n                \"application/zip\",\n            ),\n        }\n\n        headers = {\"size\": str(total_file_size), \"continue_offset\": str(restart_from)}\n\n        return await api_common.make_request(\n            \"POST\",\n            \"ingest_zip\",\n            params=params,\n            token=token,\n            files=files,\n            headers=headers,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def ingest_raw(\n        token: str,\n        raw_data: Dict,\n        operation_id: str,\n        plugin: str = None,\n        plugin_params: Optional[GulpPluginParameters] = None,\n        flt: Optional[GulpIngestionFilter] = None,\n        ws_id: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"Ingest raw data using the raw plugin\"\"\"\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"operation_id\": operation_id,\n            \"plugin\": plugin or \"raw\",\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"flt\": flt.model_dump(exclude_none=True) if flt else {},\n            \"chunk\": raw_data,\n            \"plugin_params\": (\n                plugin_params.model_dump(exclude_none=True) if plugin_params else {}\n            ),\n        }\n\n        return await api_common.make_request(\n            \"POST\",\n            \"ingest_raw\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/link.py", "content": "from gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPILink:\n    \"\"\"\n    bindings to call gulp's link related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def link_create(\n        token: str,\n        operation_id: str,\n        doc_id_from: str,\n        doc_ids: list[str],\n        name: str = None,\n        tags: list[str] = None,\n        glyph_id: str = None,\n        color: str = None,\n        private: bool = False,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"operation_id\": operation_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"doc_id_from\": doc_id_from,\n            \"name\": name,\n            \"private\": private,\n            \"color\": color,\n            \"glyph_id\": glyph_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"doc_ids\": doc_ids,\n            \"tags\": tags,\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"link_create\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def link_update(\n        token: str,\n        object_id: str,\n        doc_ids: list = None,\n        name: str = None,\n        tags: list[str] = None,\n        glyph_id: str = None,\n        color: str = None,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"object_id\": object_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"name\": name,\n            \"color\": color,\n            \"glyph_id\": glyph_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"doc_ids\": doc_ids,\n            \"tags\": tags,\n        }\n\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"link_update\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def link_delete(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_delete(\n            token=token,\n            object_id=object_id,\n            api=\"link_delete\",\n            req_id=req_id,\n            ws_id=ws_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def link_get_by_id(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_get_by_id(\n            token=token,\n            object_id=object_id,\n            api=\"link_get_by_id\",\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def link_list(\n        token: str,\n        flt: GulpCollabFilter = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_list(\n            token=token,\n            api=\"link_list\",\n            flt=flt,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/note.py", "content": "from gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPINote:\n    \"\"\"\n    bindings to call gulp's note related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def note_create(\n        token: str,\n        operation_id: str,\n        context_id: str,\n        source_id: str,\n        text: str,\n        time_pin: int = None,\n        docs: list[dict] = None,\n        name: str = None,\n        tags: list[str] = None,\n        color: str = None,\n        private: bool = False,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"\n        creates a note.\n\n        - `docs` is a list of GulpBasicDocuments dictionaries\n\n        \"\"\"\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"operation_id\": operation_id,\n            \"context_id\": context_id,\n            \"source_id\": source_id,\n            \"time_pin\": time_pin,\n            \"name\": name,\n            \"color\": color,\n            \"private\": private,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"docs\": docs,\n            \"text\": text,\n            \"tags\": tags,\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"note_create\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def note_update(\n        token: str,\n        object_id: str,\n        text: str = None,\n        time_pin: int = None,\n        docs: list = None,\n        name: str = None,\n        tags: list[str] = None,\n        color: str = None,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"object_id\": object_id,\n            \"time_pin\": time_pin,\n            \"color\": color,\n            \"name\": name,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"docs\": docs,\n            \"tags\": tags,\n            \"text\": text,\n        }\n\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"note_update\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def note_delete(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_delete(\n            token=token,\n            object_id=object_id,\n            req_id=req_id,\n            ws_id=ws_id,\n            api=\"note_delete\",\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def note_get_by_id(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_get_by_id(\n            token=token,\n            object_id=object_id,\n            req_id=req_id,\n            api=\"note_get_by_id\",\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def note_list(\n        token: str,\n        flt: GulpCollabFilter = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_list(\n            token=token,\n            api=\"note_list\",\n            flt=flt,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/object_acl.py", "content": "from muty.log import MutyLogger\n\nfrom gulp.api.collab.structs import GulpCollabType\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPIObjectACL:\n    \"\"\"\n    bindings to call gulp's object acl related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def _object_make_public_or_private(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        private: bool,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        MutyLogger.get_instance().info(\n            \"Making object %s public/private, private=%r\" % (object_id, private)\n        )\n        if private:\n            api = \"object_make_private\"\n        else:\n            api = \"object_make_public\"\n        params = {\n            \"object_id\": object_id,\n            \"type\": object_type.value,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        res = await api_common.make_request(\n            \"PATCH\",\n            api,\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def object_make_public(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        return await GulpAPIObjectACL._object_make_public_or_private(\n            token,\n            object_id=object_id,\n            object_type=object_type,\n            private=False,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def object_make_private(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        return await GulpAPIObjectACL._object_make_public_or_private(\n            token,\n            object_id=object_id,\n            object_type=object_type,\n            private=True,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def _object_add_remove_granted_user(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        user_id: str,\n        remove: bool,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        MutyLogger.get_instance().info(\n            \"Adding/removing user grant on object %s, user %s, remove=%r\"\n            % (object_id, user_id, remove)\n        )\n        if remove:\n            api = \"object_remove_granted_user\"\n        else:\n            api = \"object_add_granted_user\"\n        params = {\n            \"object_id\": object_id,\n            \"type\": object_type.value,\n            \"user_id\": user_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        res = await api_common.make_request(\n            \"PATCH\",\n            api,\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def object_add_granted_user(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        user_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        return await GulpAPIObjectACL._object_add_remove_granted_user(\n            token,\n            object_id=object_id,\n            object_type=object_type,\n            user_id=user_id,\n            req_id=req_id,\n            remove=False,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def object_remove_granted_user(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        user_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        return await GulpAPIObjectACL._object_add_remove_granted_user(\n            token,\n            object_id=object_id,\n            object_type=object_type,\n            user_id=user_id,\n            req_id=req_id,\n            remove=True,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def _object_add_remove_granted_group(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        group_id: str,\n        remove: bool,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        MutyLogger.get_instance().info(\n            \"Adding group grant, object %s, group %s, remove=%r\"\n            % (object_id, group_id, remove)\n        )\n        if remove:\n            api = \"object_remove_granted_group\"\n        else:\n            api = \"object_add_granted_group\"\n        params = {\n            \"object_id\": object_id,\n            \"type\": object_type.value,\n            \"group_id\": group_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        res = await api_common.make_request(\n            \"PATCH\",\n            api,\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def object_add_granted_group(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        group_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        return await GulpAPIObjectACL._object_add_remove_granted_group(\n            token,\n            object_id=object_id,\n            object_type=object_type,\n            group_id=group_id,\n            remove=False,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def object_remove_granted_group(\n        token: str,\n        object_id: str,\n        object_type: GulpCollabType,\n        group_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        return await GulpAPIObjectACL._object_add_remove_granted_group(\n            token,\n            object_id=object_id,\n            object_type=object_type,\n            group_id=group_id,\n            remove=True,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/operation.py", "content": "from gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPIOperation:\n    \"\"\"\n    bindings to call gulp's operation related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def operation_create(\n        token: str,\n        name: str,\n        index: str = None,\n        description: str = None,\n        glyph_id: str = None,\n        set_default_grants: bool = False,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"name\": name,\n            \"index\": index,\n            \"glyph_id\": glyph_id,\n            \"set_default_grants\": set_default_grants,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        body = description\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"operation_create\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def operation_update(\n        token: str,\n        operation_id: str,\n        index: str = None,\n        description: str = None,\n        operation_data: dict = None,\n        merge_operation_data: bool = True,\n        glyph_id: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"operation_id\": operation_id,\n            \"index\": index,\n            \"glyph_id\": glyph_id,\n            \"req_id\": req_id or api_common.req_id,\n            \"merge_operation_data\": merge_operation_data,\n        }\n        body = {\n            \"description\": description,\n            \"operation_data\": operation_data,\n        }\n\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"operation_update\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def operation_delete(\n        token: str,\n        operation_id: str,\n        delete_data: bool = True,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"operation_id\": operation_id,\n            \"delete_data\": delete_data,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        return await api_common.make_request(\n            \"DELETE\",\n            \"operation_delete\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def operation_get_by_id(\n        token: str,\n        operation_id: str,\n        get_count: bool = True,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_get_by_id(\n            token=token,\n            object_id=operation_id,\n            api=\"operation_get_by_id\",\n            req_id=req_id,\n            expected_status=expected_status,\n            operation_id=operation_id,\n            get_count=get_count,\n        )\n\n    @staticmethod\n    async def operation_list(\n        token: str,\n        flt: GulpCollabFilter = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_list(\n            token=token,\n            api=\"operation_list\",\n            req_id=req_id,\n            flt=flt,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def context_list(\n        token: str,\n        operation_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        res = await api_common.make_request(\n            \"GET\",\n            \"context_list\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def context_delete(\n        token: str,\n        operation_id: str,\n        context_id: str,\n        delete_data: bool = True,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"context_id\": context_id,\n            \"delete_data\": delete_data,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        return await api_common.make_request(\n            \"DELETE\",\n            \"context_delete\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def source_list(\n        token: str,\n        operation_id: str,\n        context_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"context_id\": context_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        return await api_common.make_request(\n            \"GET\",\n            \"source_list\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def source_delete(\n        token: str,\n        operation_id: str,\n        context_id: str,\n        source_id: str,\n        delete_data: bool = True,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"context_id\": context_id,\n            \"source_id\": source_id,\n            \"delete_data\": delete_data,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        return await api_common.make_request(\n            \"DELETE\",\n            \"source_delete\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def operation_reset(\n        token: str,\n        operation_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        return await api_common.make_request(\n            \"POST\",\n            \"operation_reset\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/story.py", "content": "from gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPIStory:\n    \"\"\"\n    bindings to call gulp's story related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def story_create(\n        token: str,\n        operation_id: str,\n        doc_ids: list[str],\n        name: str = None,\n        tags: list[str] = None,\n        glyph_id: str = None,\n        color: str = None,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"operation_id\": operation_id,\n            \"name\": name,\n            \"color\": color,\n            \"glyph_id\": glyph_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"doc_ids\": doc_ids,\n            \"tags\": tags,\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"story_create\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def story_update(\n        token: str,\n        object_id: str,\n        doc_ids: list[str] = None,\n        name: str = None,\n        tags: list[str] = None,\n        glyph_id: str = None,\n        color: str = None,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"object_id\": object_id,\n            \"color\": color,\n            \"name\": name,\n            \"glyph_id\": glyph_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"doc_ids\": doc_ids,\n            \"tags\": tags,\n        }\n\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"story_update\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def story_delete(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_delete(\n            token=token,\n            object_id=object_id,\n            api=\"story_delete\",\n            req_id=req_id,\n            ws_id=ws_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def story_get_by_id(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_get_by_id(\n            token=token,\n            object_id=object_id,\n            req_id=req_id,\n            api=\"story_get_by_id\",\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def story_list(\n        token: str,\n        flt: GulpCollabFilter = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_list(\n            token=token,\n            api=\"story_list\",\n            flt=flt,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/opensearch/sigma.py", "content": "\"\"\"\nsigma rules tools\n\"\"\"\n\nfrom typing import TYPE_CHECKING\n\nimport muty.string\nfrom muty.log import MutyLogger\nfrom sigma.collection import SigmaCollection\nfrom sigma.conversion.base import Backend\nfrom sigma.rule import SigmaRule\n\nfrom gulp.plugin import GulpPluginBase\nfrom gulp.structs import GulpPluginParameters\n\nif TYPE_CHECKING:\n    from gulp.api.opensearch.query import GulpQuery\n\n\nasync def sigma_to_tags(\n    plugin: str, sigma: str, plugin_params: GulpPluginParameters = None\n) -> list[str]:\n    \"\"\"\n    get tags from a sigma rule.\n\n    Args:\n        plugin (str): the plugin to use\n        sigma (str): the sigma rule YAML\n        plugin_params (GulpPluginParameters, optional): the plugin parameters. Defaults to None.\n\n    Returns:\n        list[str]: the tags extracted from the sigma rule\n    \"\"\"\n    mod: GulpPluginBase = None\n    tags: list[str] = []\n    try:\n        mod = await GulpPluginBase.load(plugin)\n        q: list[GulpQuery] = mod.sigma_convert(sigma, plugin_params)\n        for qq in q:\n            if qq.tags:\n                tags.extend(qq.tags)\n    finally:\n        if mod:\n            mod.unload()\n    MutyLogger.get_instance().debug(\"extracted tags from sigma rule:\\n%s\", tags)\n    return tags\n\n\ndef to_gulp_query_struct(\n    sigma: str, backend: Backend, output_format: str = None, tags: list[str] = None\n) -> list[\"GulpQuery\"]:\n    \"\"\"\n    convert a Sigma rule to a GulpQuery object.\n\n    Args:\n        sigma (str): the sigma rule YAML\n        backend (Backend): the backend to use\n        output_format (str, optional): the output format to use. Defaults to None (use backend's default)\n        tags (list[str], optional): the (additional) tags to set on the query\n\n    Returns:\n        list[GulpConvertedSigma]: one or more queries in the format specified by backend/pipeline/output_format.\n    \"\"\"\n    from gulp.api.opensearch.query import GulpQuery\n\n    converted_sigmas: list[GulpQuery] = []\n    sc: list[SigmaRule] = SigmaCollection.from_yaml(sigma)\n    for r in sc:\n        # a single sigma may originate multiple queries\n        q = backend.convert_rule(r, output_format=output_format)\n        for qq in q:\n            # generate a GulpQuery for each\n            rule_id = str(r.id) or muty.string.generate_unique()\n            rule_name = r.name or r.title or \"sigma_%s\" % (rule_id)\n            rule_tags: list[str] = [t.name for t in r.tags if t]\n            if r.level:\n                # add severity tag\n                rule_tags.append(f\"severity-{r.level.name.lower()}\")\n            if tags:\n                # additional tags\n                [rule_tags.append(t) for t in tags if t not in rule_tags]\n\n            converted = GulpQuery(\n                name=rule_name,\n                sigma_id=rule_id,\n                tags=rule_tags,\n                q=qq,\n            )\n            converted_sigmas.append(converted)\n    MutyLogger.get_instance().debug(\n        \"converted %d sigma rules to GulpQuery:\\n%s\",\n        len(converted_sigmas),\n        converted_sigmas,\n    )\n    return converted_sigmas\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/query.py", "content": "import json\nimport os\nfrom typing import Any, Optional\n\nfrom muty.log import MutyLogger\nimport muty.file\nimport muty.crypto\nfrom gulp.api.opensearch.filters import GulpQueryFilter\nfrom gulp.api.opensearch.query import GulpQueryParameters\nfrom gulp.api.rest.client.common import GulpAPICommon\nfrom gulp.structs import GulpPluginParameters\n\n\nclass GulpAPIQuery:\n    \"\"\"\n    bindings to call gulp's query related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def query_fields_by_source(\n        token: str,\n        operation_id: str,\n        context_id: str,\n        source_id: str,\n        req_id: str = None,\n        ws_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"context_id\": context_id,\n            \"source_id\": source_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        res = await api_common.make_request(\n            \"GET\",\n            \"query_fields_by_source\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def query_gulp(\n        token: str,\n        operation_id: str,\n        flt: GulpQueryFilter = None,\n        q_options: GulpQueryParameters = None,\n        expected_status: int = 200,\n        req_id: str = None,\n        ws_id: str = None,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"req_id\": req_id or api_common.req_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n        }\n        body = {\n            \"flt\": (\n                flt.model_dump(by_alias=True, exclude_none=True, exclude_defaults=True)\n                if flt\n                else None\n            ),\n            \"q_options\": (\n                q_options.model_dump(\n                    by_alias=True, exclude_none=True, exclude_defaults=True\n                )\n                if q_options\n                else None\n            ),\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"query_gulp\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def query_sigma_zip(\n        token: str,\n        zip_file_path: str,\n        operation_id: str,\n        plugin: str,\n        q_options: Optional[GulpQueryParameters] = None,\n        plugin_params: Optional[GulpPluginParameters] = None,\n        flt: Optional[GulpQueryFilter] = None,\n        ws_id: str = None,\n        req_id: str = None,\n        restart_from: int = 0,\n        file_sha1: str = None,\n        total_file_size: int = 0,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        if not total_file_size:\n            total_file_size = os.path.getsize(zip_file_path)\n\n        if not file_sha1:\n            file_sha1 = await muty.crypto.hash_sha1_file(zip_file_path)\n\n        params = {\n            \"operation_id\": operation_id,\n            \"plugin\": plugin,\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        payload = {\n            \"flt\": flt.model_dump(exclude_none=True) if flt else {},\n            \"q_options\": (\n                q_options.model_dump(exclude_none=True) if q_options else {}\n            ),\n            \"file_sha1\": file_sha1,\n            \"plugin_params\": (\n                plugin_params.model_dump(exclude_none=True) if plugin_params else {}\n            ),\n            \"original_file_path\": zip_file_path,\n        }\n\n        f = open(zip_file_path, \"rb\")\n        if restart_from > 0:\n            # advance to the restart offset\n            f.seek(restart_from)\n\n        files = {\n            \"payload\": (\"payload.json\", json.dumps(payload), \"application/json\"),\n            \"f\": (\n                os.path.basename(zip_file_path),\n                f,\n                \"application/octet-stream\",\n            ),\n        }\n\n        headers = {\"size\": str(total_file_size), \"continue_offset\": str(restart_from)}\n\n        return await api_common.make_request(\n            \"POST\",\n            \"query_sigma_zip\",\n            params=params,\n            token=token,\n            files=files,\n            headers=headers,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def query_sigma(\n        token: str,\n        operation_id: str,\n        plugin: str,\n        sigmas: list[str],\n        q_options: GulpQueryParameters = None,\n        plugin_params: GulpPluginParameters = None,\n        flt: GulpQueryFilter = None,\n        expected_status: int = 200,\n        req_id: str = None,\n        ws_id: str = None,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"plugin\": plugin,\n            \"req_id\": req_id or api_common.req_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n        }\n        body = {\n            \"sigmas\": sigmas,\n            \"flt\": (\n                flt.model_dump(by_alias=True, exclude_none=True, exclude_defaults=True)\n                if flt\n                else None\n            ),\n            \"plugin_params\": (\n                plugin_params.model_dump(\n                    by_alias=True, exclude_none=True, exclude_defaults=True\n                )\n                if plugin_params\n                else None\n            ),\n            \"q_options\": (\n                q_options.model_dump(\n                    by_alias=True, exclude_none=True, exclude_defaults=True\n                )\n                if q_options\n                else None\n            ),\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"query_sigma\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def sigma_convert(\n        token: str,\n        sigma: str,\n        plugin: str,\n        plugin_params: GulpPluginParameters = None,\n        expected_status: int = 200,\n        req_id: str = None,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"plugin\": plugin,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        body = {\n            \"sigma\": sigma,\n            \"plugin_params\": (\n                plugin_params.model_dump(\n                    by_alias=True, exclude_none=True, exclude_defaults=True\n                )\n                if plugin_params\n                else None\n            ),\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"sigma_convert\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def query_single_id(\n        token: str,\n        operation_id: str,\n        doc_id: str,\n        expected_status: int = 200,\n        req_id: str = None,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"req_id\": req_id or api_common.req_id,\n            \"doc_id\": doc_id,\n            \"operation_id\": operation_id,\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"query_single_id\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def query_raw(\n        token: str,\n        operation_id: str,\n        q: list[dict],\n        q_options: GulpQueryParameters = None,\n        expected_status: int = 200,\n        req_id: str = None,\n        ws_id: str = None,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"req_id\": req_id or api_common.req_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n        }\n        body = {\n            \"q\": q,\n            \"q_options\": (\n                q_options.model_dump(\n                    by_alias=True, exclude_none=True, exclude_defaults=True\n                )\n                if q_options\n                else None\n            ),\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"query_raw\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def query_external(\n        token: str,\n        operation_id: str,\n        q: Any,\n        plugin: str,\n        q_options: GulpQueryParameters,\n        plugin_params: GulpPluginParameters = None,\n        ingest: bool = False,\n        ws_id: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"ingest\": ingest,\n            \"plugin\": plugin,\n            \"req_id\": req_id or api_common.req_id,\n            \"ws_id\": ws_id or api_common.ws_id,\n        }\n        body = {\n            \"q\": q,\n            \"q_options\": (\n                q_options.model_dump(\n                    by_alias=True, exclude_none=True, exclude_defaults=True\n                )\n                if q_options\n                else None\n            ),\n            \"plugin_params\": (\n                plugin_params.model_dump(\n                    by_alias=True, exclude_none=True, exclude_defaults=True\n                )\n                if plugin_params\n                else None\n            ),\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"query_external\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def query_operations(\n        token: str,\n        expected_status: int = 200,\n        req_id: str = None,\n    ) -> list[dict]:\n        \"\"\"\n        Get operations with aggregations\n        \"\"\"\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        res = await api_common.make_request(\n            \"GET\",\n            \"query_operations\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def query_max_min_per_field(\n        token: str,\n        operation_id: str,\n        group_by: str = None,\n        flt: GulpQueryFilter = None,\n        expected_status: int = 200,\n        req_id: str = None,\n    ) -> dict:\n        \"\"\"\n        Get max/min values per field with optional grouping\n        \"\"\"\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"operation_id\": operation_id,\n            \"group_by\": group_by,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        body = {\n            \"flt\": (\n                flt.model_dump(by_alias=True, exclude_none=True, exclude_defaults=True)\n                if flt\n                else None\n            ),\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"query_max_min_per_field\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n"}
{"type": "source_file", "path": "src/gulp/api/collab/stored_query.py", "content": "from typing import Optional, override\n\nfrom sqlalchemy import ARRAY, String\nfrom sqlalchemy.ext.mutable import MutableList, MutableDict\nfrom sqlalchemy.dialects.postgresql import JSONB\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom gulp.api.collab.structs import GulpCollabBase, GulpCollabType\n\n\nclass GulpStoredQuery(GulpCollabBase, type=GulpCollabType.STORED_QUERY):\n    \"\"\"\n    a stored query in the gulp collaboration system\n    \"\"\"\n\n    q: Mapped[str] = mapped_column(\n        String,\n        doc=\"a query as string, i.e. YAML (i.e. sigma), JSON string, ...\",\n    )\n    tags: Mapped[Optional[list[str]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(String)),\n        default_factory=list,\n        doc=\"The tags associated with the query.\",\n    )\n    q_groups: Mapped[Optional[list[str]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(String)),\n        default_factory=list,\n        doc=\"Groups associated with the query.\",\n    )\n    plugin: Mapped[Optional[str]] = mapped_column(\n        String,\n        default=None,\n        doc=\"If q is a sigma YAML, this is the plugin implementing `sigma_convert` to be used for conversion.\",\n    )\n    plugin_params: Mapped[Optional[dict]] = mapped_column(\n        MutableDict.as_mutable(JSONB),\n        default_factory=dict,\n        doc=\"Parameters to be passed to the plugin.\",)\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d[\"q\"] = [\"example query\"]\n        \n        d[\"plugin\"] = \"win_evtx\"\n        d[\"tags\"] = [\"example\", \"tag\"]\n        d[\"q_groups\"] = [\"group1\", \"group2\"]\n        return d\n"}
{"type": "source_file", "path": "src/gulp/api/collab/highlight.py", "content": "from typing import Optional\n\nfrom sqlalchemy import ARRAY, ForeignKey, Integer\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.ext.mutable import MutableList\nfrom gulp.api.collab.structs import GulpCollabObject, GulpCollabType\n\n\nclass GulpHighlight(GulpCollabObject, type=GulpCollabType.HIGHLIGHT):\n    \"\"\"\n    an highlight in the gulp collaboration system\n    \"\"\"\n\n    time_range: Mapped[tuple[int, int]] = mapped_column(\n        MutableList.as_mutable(ARRAY(Integer)),\n        doc=\"The time range of the highlight, in nanoseconds from unix epoch.\",\n    )\n    source_id: Mapped[Optional[str]] = mapped_column(\n        ForeignKey(\"source.id\", ondelete=\"CASCADE\"), doc=\"The associated GulpSource id.\"\n    )\n\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d[\"time_range\"] = [0, 1000000]\n        d[\"source_id\"] = \"source_id\"\n        return d\n"}
{"type": "source_file", "path": "src/gulp/api/collab/note.py", "content": "from typing import Optional, override\n\nfrom muty.log import MutyLogger\nfrom muty.pydantic import autogenerate_model_example_by_class\nfrom opensearchpy import Field\nfrom pydantic import BaseModel, ConfigDict\nfrom sqlalchemy import ARRAY, BIGINT, ForeignKey, Index, String, insert\nfrom sqlalchemy.dialects.postgresql import JSONB\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.ext.mutable import MutableList\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom gulp.api.collab.structs import GulpCollabFilter, GulpCollabObject, GulpCollabType\nfrom gulp.api.opensearch.structs import GulpBasicDocument\nfrom gulp.api.ws_api import (\n    GulpCollabCreateUpdatePacket,\n    GulpWsQueueDataType,\n    GulpWsSharedQueue,\n)\n\n\nclass GulpNoteEdit(BaseModel):\n    \"\"\"\n    a note edit\n    \"\"\"\n\n    model_config = ConfigDict(\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"editor_id\": \"editor_id\",\n                    \"timestamp\": 1234567890,\n                    \"text\": \"previous note text\",\n                }\n            ]\n        }\n    )\n\n    user_id: str = Field(..., description=\"The user ID of the editor.\")\n    timestamp: int = Field(\n        ..., description=\"The timestamp of the edit, in milliseconds from unix epoch.\"\n    )\n    text: str = Field(..., description=\"The note text.\")\n\n\nclass GulpNote(GulpCollabObject, type=GulpCollabType.NOTE):\n    \"\"\"\n    a note in the gulp collaboration system\n    \"\"\"\n\n    context_id: Mapped[str] = mapped_column(\n        ForeignKey(\"context.id\", ondelete=\"CASCADE\"),\n        doc=\"The context associated with the note.\",\n    )\n    source_id: Mapped[Optional[str]] = mapped_column(\n        ForeignKey(\"source.id\", ondelete=\"CASCADE\"),\n        doc=\"The log file path (source) associated with the note.\",\n    )\n    docs: Mapped[Optional[list[GulpBasicDocument]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(JSONB)),\n        doc=\"One or more GulpBasicDocument associated with the note.\",\n    )\n    time_pin: Mapped[Optional[int]] = mapped_column(\n        BIGINT,\n        doc=\"To pin the note to a specific time, in nanoseconds from the unix epoch.\",\n    )\n    last_editor_id: Mapped[Optional[str]] = mapped_column(\n        ForeignKey(\"user.id\", ondelete=\"SET NULL\"),\n        doc=\"The ID of the last user who edited the note.\",\n    )\n    text: Mapped[Optional[str]] = mapped_column(String, doc=\"The text of the note.\")\n\n    edits: Mapped[Optional[list[GulpNoteEdit]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(JSONB)),\n        doc=\"The edits made to the note.\",\n        default_factory=list,\n    )\n\n    # add an index on the operation_id for faster queries\n    __table_args__ = (Index(\"idx_note_operation\", \"operation_id\"),)\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d.update(\n            {\n                \"context_id\": \"context_id\",\n                \"source_id\": \"source_id\",\n                \"docs\": [[autogenerate_model_example_by_class(GulpBasicDocument)]],\n                \"time_pin\": 1234567890,\n                \"last_editor_id\": \"last_editor_id\",\n                \"text\": \"note text\",\n                \"edits\": [\n                    autogenerate_model_example_by_class(GulpNoteEdit),\n                ],\n            }\n        )\n        return d\n\n    @override\n    @classmethod\n    def build_dict(\n        cls,\n        operation_id: str,\n        context_id: str,\n        source_id: str,\n        glyph_id: str = None,\n        tags: list[str] = None,\n        color: str = None,\n        name: str = None,\n        description: str = None,\n        docs: list[GulpBasicDocument] = None,\n        time_pin: int = None,\n        text: str = None,\n    ) -> dict:\n        \"\"\"\n        builds a note dictionary, taking care of converting the documents to dictionaries\n\n        Args:\n            operation_id (str): the operation id\n            context_id (str): the context id\n            source_id (str): the source id\n            glyph_id (str, optional): the glyph id. Defaults to None.\n            tags (list[str], optional): the tags. Defaults to None.\n            color (str, optional): the color. Defaults to None.\n            name (str, optional): the name. Defaults to None.\n            description (str, optional): the description. Defaults to None.\n            docs (list[GulpBasicDocument], optional): the documents. Defaults to None.\n            time_pin (int, optional): the time pin. Defaults to None.\n            text (str, optional): the text. Defaults to None.\n\n        Returns:\n            the note dictionary\n        \"\"\"\n        if docs:\n            # convert the documents to dictionaries\n            docs = [\n                doc.model_dump(by_alias=True, exclude_none=True, exclude_defaults=True)\n                for doc in docs\n            ]\n        return super().build_dict(\n            operation_id=operation_id,\n            context_id=context_id,\n            source_id=source_id,\n            glyph_id=glyph_id,\n            tags=tags,\n            color=color,\n            name=name,\n            description=description,\n            docs=docs,\n            time_pin=time_pin,\n            text=text,\n            edits=[],\n        )\n\n    @staticmethod\n    async def bulk_create_from_documents(\n        sess: AsyncSession,\n        user_id: str,\n        ws_id: str,\n        req_id: str,\n        docs: list[dict],\n        name: str,\n        tags: list[str] = None,\n        color: str = None,\n        glyph_id: str = None,\n    ) -> int:\n        \"\"\"\n        creates a note for each document in the list, using bulk insert\n\n        Args:\n            sess (AsyncSession): the database session\n            user_id (str): the user id creating the notes\n            ws_id (str): the websocket id\n            req_id (str): the request id\n            docs (list[dict]): the list of documents to create notes for\n            name (str): the name of the notes\n            tags (list[str], optional): the tags to add to the notes. Defaults to None (set to [\"auto\"]).\n            color (str, optional): the color of the notes. Defaults to None (use default).\n            glyph_id (str, optional): the glyph id of the notes. Defaults to None (use default).\n\n        Returns:\n            the number of notes created\n        \"\"\"\n        tt: list[str] = tags\n        if not tt:\n            tt = []\n\n        if \"auto\" not in tt:\n            tt.append(\"auto\")\n\n        # creates a list of notes, one for each document\n        notes = []\n        MutyLogger.get_instance().info(\"creating a bulk of %d notes...\" % len(docs))\n        for doc in docs:\n            # associate the document with the note by creating a GulpBasicDocument object\n            associated_doc = GulpBasicDocument(\n                id=doc.get(\"_id\"),\n                timestamp=doc.get(\"@timestamp\"),\n                gulp_timestamp=doc.get(\"gulp.timestamp\"),\n                invalid_timestamp=doc.get(\"gulp.timestamp_invalid\", False),\n                operation_id=doc.get(\"gulp.operation_id\"),\n                context_id=doc.get(\"gulp.context_id\"),\n                source_id=doc.get(\"gulp.source_id\"),\n            )\n\n            # add the note object dictionary\n            object_data = GulpNote.build_dict(\n                operation_id=associated_doc.operation_id,\n                context_id=associated_doc.context_id,\n                source_id=associated_doc.source_id,\n                glyph_id=glyph_id,\n                tags=tt,\n                color=color,\n                name=name,\n                docs=[associated_doc],\n            )\n\n            note_dict = GulpNote.build_base_object_dict(\n                object_data=object_data, owner_id=user_id, private=False\n            )\n            notes.append(note_dict)\n\n        # bulk insert\n        await sess.execute(insert(GulpNote).values(notes))\n        await sess.commit()\n        MutyLogger.get_instance().info(\"written %d notes on collab db\" % len(notes))\n\n        # send over the websocket\n        MutyLogger.get_instance().debug(\n            \"sending %d notes on the websocket %s \" % (len(notes), ws_id)\n        )\n\n        # operation is always the same\n        operation_id = notes[0].get(\"operation_id\")\n        data: GulpCollabCreateUpdatePacket = GulpCollabCreateUpdatePacket(\n            data=notes,\n            bulk=True,\n            type=GulpCollabType.NOTE,\n            created=True,\n            bulk_size=len(notes),\n        )\n        GulpWsSharedQueue.get_instance().put(\n            GulpWsQueueDataType.COLLAB_UPDATE,\n            ws_id=ws_id,\n            user_id=user_id,\n            operation_id=operation_id,\n            req_id=req_id,\n            data=data,\n        )\n        MutyLogger.get_instance().debug(\n            \"sent %d notes on the websocket %s \" % (len(notes), ws_id)\n        )\n\n        return len(notes)\n\n    @staticmethod\n    async def bulk_update_tags(\n        sess: AsyncSession,\n        tags: list[str],\n        new_tags: list[str],\n        operation_id: str,\n        user_id: str,\n        user_id_is_admin: bool = False,\n        user_group_ids: list[str] = None,\n    ) -> None:\n        \"\"\"\n        get tags from notes and update them with new tags\n\n        Args:\n            sess (AsyncSession): the database session\n            tags (list[str]): the tags to match\n            new_tags (list[str]): the new tags to add\n            operation_id (str): the operation id\n            user_id (str): the user id making the request\n            user_id_is_admin (bool): whether the user is an admin\n            user_group_ids (list[str], optional): the user groups ids. Defaults to None.\n        \"\"\"\n        MutyLogger.get_instance().debug(\n            f\"updating notes tags from {tags} to {new_tags}, user_id_is_admin={user_id_is_admin} ...\"\n        )\n        offset = 0\n        chunk_size = 1000\n\n        # build filter\n        flt = GulpCollabFilter(\n            tags=tags,\n            limit=chunk_size,\n            offset=offset,\n        )\n\n        # restrict to operation_id and user_id\n        if operation_id:\n            flt.operation_ids = [operation_id]\n        # if user_id:\n        #   flt.owner_user_ids = [user_id]\n\n        updated = 0\n\n        while True:\n            # get all notes matching \"tags\"\n            notes: list[GulpNote] = await GulpNote.get_by_filter(\n                sess,\n                flt,\n                user_id=user_id,\n                user_id_is_admin=user_id_is_admin,\n                user_group_ids=user_group_ids,\n                throw_if_not_found=False,\n                with_for_update=True,\n            )\n            if not notes:\n                break\n\n            # for each note, update tags\n            for n in notes:\n                for t in new_tags:\n                    if t not in n.tags:\n                        n.tags.append(t)\n\n            await sess.commit()\n            rows_updated = len(notes)\n            MutyLogger.get_instance().debug(f\"updated {rows_updated} notes\")\n\n            # next chunk\n            offset += rows_updated\n            flt.offset = offset\n            updated += rows_updated\n\n        MutyLogger.get_instance().info(\"updated %d notes tags\" % (updated))\n"}
{"type": "source_file", "path": "src/gulp/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/collab/assets/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/collab/user_session.py", "content": "from typing import TYPE_CHECKING, Optional, override\n\nimport muty.time\nfrom muty.log import MutyLogger\nfrom sqlalchemy import BIGINT, ForeignKey\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom gulp.api.collab.structs import (\n    GulpCollabBase,\n    GulpCollabType,\n    GulpUserPermission,\n    MissingPermission,\n    T,\n)\nfrom gulp.config import GulpConfig\nfrom gulp.structs import ObjectNotFound\n\nif TYPE_CHECKING:\n    from gulp.api.collab.user import GulpUser\n\n\nclass GulpUserSession(GulpCollabBase, type=GulpCollabType.USER_SESSION):\n    \"\"\"\n    Represents a user session (logged user).\n    \"\"\"\n\n    user_id: Mapped[str] = mapped_column(\n        ForeignKey(\"user.id\", ondelete=\"CASCADE\"),\n        doc=\"The user ID associated with the session.\",\n        unique=True,\n    )\n\n    user: Mapped[\"GulpUser\"] = relationship(\n        \"GulpUser\",\n        foreign_keys=[user_id],\n        uselist=False,\n        lazy=\"joined\",\n    )\n    time_expire: Mapped[Optional[int]] = mapped_column(\n        BIGINT,\n        default=0,\n        doc=\"The time when the session expires, in milliseconds from unix epoch.\",\n    )\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d[\"user_id\"] = \"user_id\"\n        d[\"time_expire\"] = 0\n        return d\n\n    @classmethod\n    async def create(\n        cls,\n        *args,\n        **kwargs,\n    ) -> T:\n        \"\"\"\n        uninmplemented, use GulpUser.login() to create a session.\n        \"\"\"\n        raise NotImplementedError(\"use GulpUser.login() to create a session.\")\n\n    @staticmethod\n    async def _get_admin_session(sess: AsyncSession) -> \"GulpUserSession\":\n        \"\"\"\n        Get an admin session, for debugging purposes only\n\n        Args:\n            sess (AsyncSession): The database session to use.\n\n        Returns:\n            GulpUserSession: The admin session object.\n        \"\"\"\n        from gulp.api.collab.user import GulpUser\n\n        # first acquire an advisory lock for admin session creation\n        # use a consistent lock ID for admin session management\n        ADMIN_SESSION_LOCK_ID = 1\n        await GulpCollabBase.acquire_advisory_lock(sess, ADMIN_SESSION_LOCK_ID)\n\n        # the \"admin\" user always exists\n        admin_user: GulpUser = await GulpUser.get_by_id(sess, id=\"admin\")\n        if admin_user.session:\n            # already exists\n            return admin_user.session\n\n        # create a new permanent admin session\n        object_data = {\"user_id\": admin_user.id, \"time_expire\": 0}\n        admin_session: GulpUserSession = await GulpUserSession._create(\n            sess,\n            object_data=object_data,\n            owner_id=admin_user.id,\n        )\n        # MutyLogger.get_instance().debug(\"created new admin session: %s\" % (admin_session.to_dict()))\n        return admin_session\n\n    @staticmethod\n    async def check_token(\n        sess: AsyncSession,\n        token: str,\n        permission: list[GulpUserPermission] | GulpUserPermission = None,\n        obj: Optional[GulpCollabBase] = None,\n        throw_on_no_permission: bool = True,\n        enforce_owner: bool = False,\n    ) -> \"GulpUserSession\":\n        \"\"\"\n        Check if the user represented by token is logged in and has the required permissions.\n\n        - if both permission and obj are None, the function will return the user session without checking permissions.\n        - if user is an admin, the function will always grant access.\n        - first, if permission is provided, the function will check if the user has the required permission/s.\n        - then, if obj is provided, the function will check the user permissions against the object to access it.\n            - check GulpUser.check_object_access() for details.\n\n        Args:\n            sess (AsyncSession, optional): The database session to use. Defaults to None.\n            token (str): The token representing the user's session.\n            permission (list[GulpUserPermission]|GulpUserPermission, optional): The permission(s) required to access the object. Defaults to None.\n            obj (Optional[GulpCollabBase], optional): The object to check the permissions against, for access. Defaults to None.\n            throw_on_no_permission (bool, optional): If True, raises an exception if the user does not have the required permissions. Defaults to True.\n            enforce_owner (bool, optional): If True, the user must be the owner of the object to access it (or administrator). Defaults to False.\n\n        Returns:\n            GulpUserSession: The user session object (includes GulpUser object).\n\n        Raises:\n            MissingPermission: If the user does not have the required permissions.\n        \"\"\"\n        MutyLogger.get_instance().debug(\n            \"---> check_token_permission: token=%s, permission=%s, sess=%s ...\"\n            % (token, permission, sess)\n        )\n        if not permission:\n            # assume read permission if not provided\n            permission = [GulpUserPermission.READ]\n\n        if isinstance(permission, GulpUserPermission):\n            # allow single permission as string\n            permission = [permission]\n\n        if GulpConfig.get_instance().debug_allow_any_token_as_admin():\n            return await GulpUserSession._get_admin_session(sess)\n\n        try:\n            user_session: GulpUserSession = await GulpUserSession.get_by_id(\n                sess, id=token, throw_if_not_found=throw_on_no_permission\n            )\n            # MutyLogger.get_instance().debug(\"got user session for token %s: %s\" % (token, user_session.to_dict()))\n        except ObjectNotFound:\n            raise MissingPermission('token \"%s\" not logged in' % (token))\n\n        if user_session.user.is_admin():\n            # admin user can access any object and always have permission\n            return user_session\n\n        if not obj:\n            # check if the user have the required permission (owner always have permission)\n            if user_session.user.has_permission(permission):\n                # access granted\n                return user_session\n\n            if throw_on_no_permission:\n                raise MissingPermission(\n                    f\"User {user_session.user_id} does not have the required permissions {permission} to perform this operation.\"\n                )\n            return None\n\n        # check if the user has access\n        if user_session.user.check_object_access(\n            obj,\n            throw_on_no_permission=throw_on_no_permission,\n            enforce_owner=enforce_owner,\n        ):\n            # check if the user have the required permission (owner always have permission)\n            if user_session.user.has_permission(permission) or obj.is_owner(\n                user_session.user.id\n            ):\n                # access granted\n                return user_session\n\n        if throw_on_no_permission:\n            raise MissingPermission(\n                f\"User {user_session.user_id} does not have the required permissions {permission} to perform this operation, obj={obj.id if obj else None}, obj_owner={obj.owner_user_id if obj else None}.\"\n            )\n        return None\n"}
{"type": "source_file", "path": "src/gulp/api/collab/context.py", "content": "from typing import Optional, override\n\nimport muty.crypto\nimport muty.string\nfrom muty.log import MutyLogger\nfrom sqlalchemy import ForeignKey, PrimaryKeyConstraint, String, text\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom gulp.api.collab.source import GulpSource\nfrom gulp.api.collab.structs import GulpCollabBase, GulpCollabFilter, GulpCollabType, T\nfrom gulp.api.ws_api import GulpWsQueueDataType\n\n\nclass GulpContext(GulpCollabBase, type=GulpCollabType.CONTEXT):\n    \"\"\"\n    Represents a context object\n\n    in gulp terms, a context is used to group a set of data coming from the same host.\n\n    it has always associated an operation, and the tuple composed by the two is unique.\n    \"\"\"\n\n    operation_id: Mapped[str] = mapped_column(\n        ForeignKey(\"operation.id\", ondelete=\"CASCADE\"),\n        doc=\"The ID of the operation associated with the context.\",\n        primary_key=True,\n    )\n    # multiple sources can be associated with a context\n    sources: Mapped[Optional[list[GulpSource]]] = relationship(\n        \"GulpSource\",\n        cascade=\"all, delete-orphan\",\n        uselist=True,\n        lazy=\"selectin\",\n        foreign_keys=[GulpSource.context_id],\n        doc=\"The source/s associated with the context.\",\n    )\n\n    color: Mapped[Optional[str]] = mapped_column(\n        String, default=\"white\", doc=\"The color of the context.\"\n    )\n\n    @staticmethod\n    def make_context_id_key(operation_id: str, context_name: str) -> str:\n        \"\"\"\n        Make a key for the context_id.\n\n        Args:\n            operation_id (str): The operation id.\n            context_id (str): The context name.\n\n        Returns:\n            str: The key.\n        \"\"\"\n        return muty.crypto.hash_sha1(\"%s%s\" % (operation_id, context_name.lower()))\n\n    @staticmethod\n    def make_source_id_key(operation_id: str, context_id: str, source_name: str) -> str:\n        \"\"\"\n        Make a key for the source_id.\n\n        Args:\n            operation_id (str): The operation id.\n            context_id (str): The context id.\n            source_name (str): The source name.\n\n        Returns:\n            str: The key.\n        \"\"\"\n        return muty.crypto.hash_sha1(\n            \"%s%s%s\" % (operation_id, context_id, source_name.lower())\n        )\n\n    async def add_source(\n        self,\n        sess: AsyncSession,\n        user_id: str,\n        name: str,\n        ws_id: str = None,\n        req_id: str = None,\n    ) -> tuple[GulpSource, bool]:\n        \"\"\"\n        Add a source to the context.\n\n        Args:\n            sess (AsyncSession): The session to use.\n            user_id (str): The id of the user adding the source.\n            name (str): The name of the source (may be file name, path, etc...)\n            ws_id (str, optional): The websocket id to stream NEW_SOURCE to. Defaults to None.\n            req_id (str, optional): The request id. Defaults to None.\n        Returns:\n            tuple(GulpSource, bool): The source added (or already existing) and a flag indicating if the source was added\n        \"\"\"\n        # consider just the last part of the name if it's a path\n        bare_name = name.split(\"/\")[-1]\n        src_id = GulpContext.make_source_id_key(self.operation_id, self.id, bare_name)\n\n        # acquire lock first\n        lock_id = muty.crypto.hash_xxh64_int(src_id)\n        await GulpCollabBase.acquire_advisory_lock(sess, lock_id)\n        sess.add(self)\n\n        # check if source exists\n        flt = GulpCollabFilter(\n            names=[name],\n            operation_ids=[self.operation_id],\n            context_ids=[self.id],\n        )\n        src: GulpSource = await GulpSource.get_first_by_filter(\n            sess,\n            flt=flt,\n            user_id=user_id,\n            user_id_is_admin=True, # we want to check if the source exists, not if the user has access to it\n            throw_if_not_found=False,\n        )\n        # MutyLogger.get_instance().debug(\"flt=%s, res=%s\" % (flt, src))\n        if src:\n            MutyLogger.get_instance().debug(\n                f\"source {src.id}, name={name} already exists in context {self.id}.\"\n            )\n            return src, False\n\n        # create new source and link it to context\n        object_data = {\n            \"operation_id\": self.operation_id,\n            \"context_id\": self.id,\n            \"name\": name,\n            \"color\": \"purple\",\n        }\n        src = await GulpSource._create(\n            sess,\n            object_data,\n            id=src_id,\n            owner_id=user_id,\n            ws_queue_datatype=GulpWsQueueDataType.NEW_SOURCE if ws_id else None,\n            ws_id=ws_id,\n            req_id=req_id,\n        )\n\n        # add same grants to the source as the context\n        for u in self.granted_user_ids:\n            await src.add_user_grant(sess, u)\n        for g in self.granted_user_group_ids:\n            await src.add_group_grant(sess, g)\n\n        await sess.refresh(self)\n\n        MutyLogger.get_instance().info(\n            f\"source {src.id}, name={name} added to context {self.id}.\"\n        )\n        return src, True\n"}
{"type": "source_file", "path": "src/gulp/api/collab/story.py", "content": "from typing import override\nfrom sqlalchemy import ARRAY, String\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.ext.mutable import MutableList\nfrom gulp.api.collab.structs import GulpCollabObject, GulpCollabType\n\n\nclass GulpStory(GulpCollabObject, type=GulpCollabType.STORY):\n    \"\"\"\n    a story in the gulp collaboration system\n    \"\"\"\n\n    doc_ids: Mapped[list[str]] = mapped_column(\n        MutableList.as_mutable(ARRAY(String)),\n        default_factory=list,\n        doc=\"one or more document IDs associated with the story.\",\n    )\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d[\"doc_ids\"] = [\"doc_id1\", \"doc_id2\"]\n        return d\n"}
{"type": "source_file", "path": "src/gulp/api/mapping/models.py", "content": "from typing import Literal, Optional, override\n\nfrom muty.pydantic import autogenerate_model_example_by_class\nfrom pydantic import BaseModel, ConfigDict, Field\n\n\nclass GulpMappingField(BaseModel):\n    \"\"\"\n    defines how to map a single field, including field-specific options.\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"ecs\": [\"test.mapped\"],\n                    \"extra_doc_with_event_code\": \"1234\",\n                    \"is_timestamp_chrome\": False,\n                }\n            ]\n        },\n    )\n\n    ecs: Optional[list[str] | str] = Field(\n        None,\n        description=\"one or more ECS field names to map the source field to in the resulting document.\",\n        min_length=1,\n    )\n    extra_doc_with_event_code: Optional[str] = Field(\n        None,\n        description=\"\"\"\nif this is set, the creation of an extra document is triggered with the given `event.code` and `@timestamp` set to this field value.\n\nin this setting, the mapping file should:\n\n- map a **single** field directly as `@timestamp` (to indicate the *main* document)\n- set `mapping.event_code` to the *main* event code\n- add additional `extra_doc_with_event_code` fields to create further documents with their own event code.\n\ncheck `mftecmd_csv.json` for an example of this setting.\n\"\"\",\n    )\n    is_timestamp_chrome: Optional[bool] = Field(\n        False,\n        description=\"if set, the corresponding value is a `webkit timestamp` (from 1601) and will be converted to nanoseconds from the unix epoch.\",\n    )\n    multiplier: Optional[float] = Field(\n        None,\n        description=\"if set and > 1, the corresponding value is multiplied by this value.\",\n    )\n    force_type: Optional[Literal[\"str\", \"int\", \"float\"]] = Field(\n        None, description=\"if set, the corresponding value is forced to this type before ingestion.\")\n\n\nclass GulpMapping(BaseModel):\n    \"\"\"\n    defines a logsource -> gulp document mapping\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"fields\": {\"field1\": {\"ecs\": [\"test.mapped\"]}},\n                    \"description\": \"test description.\",\n                    \"agent_type\": \"win_evtx\",\n                    \"event_code\": \"1234\",\n                    \"allow_prefixed\": False\n                }\n            ]\n        },\n    )\n\n    fields: Optional[dict[str, GulpMappingField]] = Field(\n        {},\n        description=\"field mappings { raw_field: { GulpMappingField } } to translate a logsource to gulp document.\",\n    )\n    description: Optional[str] = Field(\n        None,\n        description=\"if set, mapping's description.\",\n    )\n    agent_type: Optional[str] = Field(\n        None,\n        description='if set, all documents generated by this mapping have \"agent.type\" set to this value. either, the plugin is responsible for setting this.',\n    )\n\n    event_code: Optional[str] = Field(\n        None,\n        description='if set, all documents generated by this mapping have \"event.code\" set to this value (and \"gulp.event_code\" to the corresponding numeric value). either, the plugin is responsible for setting this.',\n    )\n    exclude: Optional[list[str]] = Field(\n        None,\n        description=\"if set, these fields are ignored and not included in the generated document/s.\",\n    )\n    include: Optional[list[str]] = Field(\n        None,\n        description=\"if set, only these fields are processed and included in the generated document/s.\",\n    )\n    # TODO: consider if this is needed or we can just deprecate/remove this.... it is used only by the win_evtx plugin and probably it is not needed even there.\n    allow_prefixed: Optional[bool] = Field(\n        False,\n        description=\"\"\"\nif set, the source field can be prefixed and only last part after \"_\" is used to match the `ecs` mapping.\ni.e. if the source field is \"this_is_a_sourcekey\", only \"sourcekey\" is considered.\n\n\"\"\",\n    )\n\n\nclass GulpMappingFileMetadata(BaseModel):\n    \"\"\"\n    metadata for a mapping file.\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"allow\", json_schema_extra={\"examples\": [{\"plugin\": [\"win_evtx\", \"csv\"]}]}\n    )\n\n    plugin: list[str] = Field(\n        ...,\n        description=\"one or more plugin names that this mapping file is associated with.\",\n    )\n\n\nclass GulpMappingFile(BaseModel):\n    \"\"\"\n    a mapping file, containing one or more GulpMapping objects.\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"mappings\": autogenerate_model_example_by_class(GulpMapping),\n                    \"metadata\": autogenerate_model_example_by_class(\n                        GulpMappingFileMetadata\n                    ),\n                }\n            ]\n        },\n    )\n\n    mappings: dict[str, GulpMapping] = Field(\n        ...,\n        description=\"defined mappings for this mapping file, key is the `mapping_id`\",\n        min_length=1,\n    )\n    metadata: Optional[GulpMappingFileMetadata] = Field(\n        ...,\n        description=\"metadata for the mapping file.\",\n    )\n"}
{"type": "source_file", "path": "src/gulp/__main__.py", "content": "import argparse\nimport asyncio\nimport logging\nimport os\nimport sys\nfrom multiprocessing import freeze_support\n\nimport art\nfrom muty.log import MutyLogger\n\nfrom gulp.api.rest_api import GulpRestServer\n\n# just for quick testing from the command line\n__RUN_TESTS__ = os.getenv(\"INTERNAL_TEST\", False)\nif not __debug__:\n    __RUN_TESTS__ = False\n\n\nasync def async_test():\n    if not __debug__:\n        return\n    l = 10\n    batch_size = 3\n    count = 0\n    for i in range(0, l, batch_size):\n        is_last = False\n        if i + batch_size > l:\n            batch_size = l - i\n            is_last = True\n\n        count += 1\n        print(\n            \"running batch %d of %d tasks, total=%d, last=%r ...\"\n            % (count, batch_size, l, is_last)\n        )\n\n\ndef main():\n    \"\"\"\n    :return:\n    \"\"\"\n    ver = GulpRestServer.get_instance().version_string()\n    installation_dir = os.path.dirname(os.path.realpath(__file__))\n    banner = art.text2art(\"(g)ULP\", font=\"random\")\n\n    # parse args\n    parser = argparse.ArgumentParser(\n        description=banner,\n        epilog=\"(generic) unified log parser\\nversion: %s\\ninstallation path: %s\"\n        % (ver, installation_dir),\n        formatter_class=argparse.RawTextHelpFormatter,\n    )\n    parser.add_argument(\n        \"--log-to-file\",\n        nargs=1,\n        metavar=(\"file path\"),\n        help=\"also outputs log to this (rotating) file, default=stdout only.\",\n    )\n    parser.add_argument(\n        \"--log-level\",\n        nargs=1,\n        metavar=(\"level\"),\n        help='select log level, default=\"debug\".',\n        choices=[\"critical\", \"error\", \"warning\", \"info\", \"debug\"],\n        default=[\"debug\"],\n    )\n    parser.add_argument(\n        \"--reset-collab\",\n        help=\"reset collaboration database on start (do not delete 'operation', 'users' and related tables to maintain existing owners and associations).\",\n        action=\"store_const\",\n        const=True,\n        default=False,\n    )\n    parser.add_argument(\n        \"--reset-collab-full\",\n        help=\"same as --reset-collab, but perform a full collaboration database reset also deleting data on OpenSearch for the operations found in the 'operations' table.\",\n        action=\"store_const\",\n        const=True,\n        default=False,\n    )\n    parser.add_argument(\n        \"--reset-operation\",\n        help=\"deletes operation data both on OpenSearch and on the collaboration database.\",\n        nargs=1,\n        metavar=(\"operation_id\"),\n    )\n    parser.add_argument(\n        \"--version\",\n        help=\"print version string and exits.\",\n        action=\"store_const\",\n        const=True,\n        default=False,\n    )\n    args = parser.parse_args()\n\n    # reconfigure logger\n    lv = logging.getLevelNamesMapping()[args.log_level[0].upper()]\n    logger_file_path = args.log_to_file[0] if args.log_to_file else None\n    MutyLogger.get_instance(\n        \"gulp\", logger_file_path=logger_file_path, level=lv)\n\n    if __RUN_TESTS__:\n        # test stuff\n        asyncio.run(async_test())\n        return 0\n\n    # get params\n    try:\n        if args.version:\n            # print version string and exit\n            print(ver)\n        else:\n            reset_collab = 0\n            if args.reset_collab:\n                reset_collab = 1\n            if args.reset_collab_full:\n                reset_collab = 2\n            # default\n            print(\"%s\\n%s\" % (banner, ver))\n            reset_operation = args.reset_operation[0] if args.reset_operation is not None else None\n            GulpRestServer.get_instance().start(\n                logger_file_path=logger_file_path,\n                level=lv,\n                reset_collab=reset_collab,\n                reset_operation=reset_operation,\n            )\n    except Exception as ex:\n        # print exception and exit\n        MutyLogger.get_instance().exception(ex)\n        return 1\n\n    # done\n    return 0\n\n\nif __name__ == \"__main__\":\n    freeze_support()  # this is needed for macos\n    sys.exit(main())\n"}
{"type": "source_file", "path": "src/gulp/api/collab/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/collab/stats.py", "content": "from typing import Optional, Union, override\n\nimport muty.crypto\nimport muty.log\nimport muty.time\nfrom muty.log import MutyLogger\nfrom sqlalchemy import ARRAY, BIGINT, ForeignKey, Index, Integer, String\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.ext.mutable import MutableList\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.types import Enum as SQLEnum\n\nfrom gulp.api.collab.structs import GulpCollabBase, GulpCollabType, GulpRequestStatus, T\nfrom gulp.api.ws_api import GulpQueryDonePacket, GulpWsQueueDataType, GulpWsSharedQueue\nfrom gulp.config import GulpConfig\n\n\nclass RequestCanceledError(Exception):\n    \"\"\"\n    Raised when a request is aborted (by API or in case of too many failures).\n    \"\"\"\n\n    pass\n\n\nclass SourceCanceledError(Exception):\n    \"\"\"\n    Raised when a source is aborted (by API or in case of too many failures).\n    \"\"\"\n\n    pass\n\n\nclass PreviewDone(Exception):\n    \"\"\"\n    Raised when a preview is done on ingestion\n    \"\"\"\n\n\nclass GulpRequestStats(GulpCollabBase, type=GulpCollabType.REQUEST_STATS):\n    \"\"\"\n    Represents the statistics for an ingestion operation.\n    \"\"\"\n\n    operation_id: Mapped[str] = mapped_column(\n        ForeignKey(\"operation.id\", ondelete=\"CASCADE\"),\n        nullable=True,\n        doc=\"The operation associated with the stats.\",\n    )\n    context_id: Mapped[Optional[str]] = mapped_column(\n        ForeignKey(\"context.id\", ondelete=\"CASCADE\"),\n        doc=\"The context associated with the stats.\",\n        nullable=True,\n    )\n    source_id: Mapped[Optional[str]] = mapped_column(\n        ForeignKey(\"source.id\", ondelete=\"CASCADE\"),\n        doc=\"The source associated with the stats.\",\n        nullable=True,\n    )\n    status: Mapped[GulpRequestStatus] = mapped_column(\n        SQLEnum(GulpRequestStatus),\n        default=GulpRequestStatus.ONGOING,\n        doc=\"The status of the stats (done, ongoing, ...).\",\n    )\n    time_expire: Mapped[Optional[int]] = mapped_column(\n        BIGINT,\n        default=0,\n        doc=\"The timestamp when the stats will expire, in milliseconds from the unix epoch.\",\n    )\n    time_finished: Mapped[Optional[int]] = mapped_column(\n        BIGINT,\n        default=0,\n        doc=\"The timestamp when the stats were completed, in milliseconds from the unix epoch.\",\n    )\n    errors: Mapped[Optional[list[str]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(String)),\n        default_factory=list,\n        doc=\"The errors that occurred during processing.\",\n    )\n    # TODO: consider to remove this column and convert \"status\" to a String column instead, to ease comparison\n    completed: Mapped[Optional[str]] = mapped_column(\n        String,\n        default=\"0\",\n        doc=\"to easily filter against completion: '0' indicates requests still running, '1' indicates completed (done, canceled or failed)\",\n    )\n    source_processed: Mapped[Optional[int]] = mapped_column(\n        Integer, default=0, doc=\"The number of sources processed.\"\n    )\n    source_total: Mapped[Optional[int]] = mapped_column(\n        Integer, default=0, doc=\"The total number of sources to be processed.\"\n    )\n    source_failed: Mapped[Optional[int]] = mapped_column(\n        Integer, default=0, doc=\"The number of sources that failed.\"\n    )\n    records_failed: Mapped[Optional[int]] = mapped_column(\n        Integer, default=0, doc=\"The number of records that failed.\"\n    )\n    records_skipped: Mapped[Optional[int]] = mapped_column(\n        Integer, default=0, doc=\"The number of records that were skipped.\"\n    )\n    records_processed: Mapped[Optional[int]] = mapped_column(\n        Integer, default=0, doc=\"The number of records that were processed.\"\n    )\n    records_ingested: Mapped[Optional[int]] = mapped_column(\n        Integer,\n        default=0,\n        doc=\"The number of records that were ingested (may be more than records_processed: a single record may originate more than one record to be ingested).\",\n    )\n    total_hits: Mapped[Optional[int]] = mapped_column(\n        Integer,\n        default=0,\n        doc=\"The total number of hits for the query (used for search requests).\",\n    )\n    __table_args__ = (Index(\"idx_stats_operation\", \"operation_id\"),)\n\n    @override\n    def to_dict(\n        self, nested=False, hybrid_attributes=False, exclude=None, exclude_none=False\n    ):\n        \"\"\"\n        convert object to dictionary with 'gulpesque' keys.\n\n        Args:\n            nested (bool): whether to include nested objects. Defaults to False.\n            hybrid_attributes (bool): whether to include hybrid attributes. Defaults to False.\n            exclude (list, optional): list of attributes to exclude. Defaults to None.\n            exclude_none (bool): whether to exclude None values. Defaults to False.\n\n        Returns:\n            dict: dictionary representation of the object\n        \"\"\"\n        # override to have 'gulpesque' keys\n        d = super().to_dict(nested, hybrid_attributes, exclude, exclude_none)\n\n        # convert keys to gulp namespaced format\n        for key in [\"operation_id\", \"context_id\", \"source_id\"]:\n            if key in d:\n                d[f\"gulp.{key}\"] = d.pop(key)\n\n        return d\n\n    @classmethod\n    async def _update_existing_stats(\n        cls,\n        sess: AsyncSession,\n        stats: \"GulpRequestStats\",\n        time_updated: int,\n        time_expire: int,\n    ) -> \"GulpRequestStats\":\n        \"\"\"\n        update existing stats object.\n\n        Args:\n            sess (AsyncSession): database session\n            stats (GulpRequestStats): existing stats object\n            time_updated (int): current timestamp\n            time_expire (int): expiration timestamp\n\n        Returns:\n            GulpRequestStats: updated stats object\n        \"\"\"\n        # update existing stats\n        stats.status = GulpRequestStatus.ONGOING\n        stats.time_updated = time_updated\n        stats.time_finished = 0\n\n        if time_expire > 0:\n            stats.time_expire = time_expire\n\n        await sess.commit()\n        return stats\n\n    @staticmethod\n    def _calculate_expiration_time(never_expire: bool) -> int:\n        \"\"\"\n        calculate the expiration time for stats.\n\n        Args:\n            never_expire (bool): whether the stats should never expire\n\n        Returns:\n            int: expiration time in milliseconds since epoch\n        \"\"\"\n        if never_expire:\n            return 0\n\n        time_updated = muty.time.now_msec()\n        msecs_to_expiration = GulpConfig.get_instance().stats_ttl() * 1000\n\n        if msecs_to_expiration > 0:\n            # MutyLogger.get_instance().debug(\"now=%s, setting stats %s time_expire to %s\", time_updated, req_id, time_updated + time_expire)\n            return time_updated + msecs_to_expiration\n\n        return 0\n\n    @classmethod\n    async def create(\n        cls,\n        sess: AsyncSession,\n        user_id: str,\n        req_id: str,\n        ws_id: str,\n        operation_id: str,\n        context_id: str,\n        source_id: str = None,\n        source_total: int = 1,\n        never_expire: bool = False,\n    ) -> T:\n        \"\"\"\n        Create new (or get an existing) GulpRequestStats object on the collab database.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            user_id (str): The user ID creating the stats.\n            req_id (str): The request ID (= the id of the stats)\n            ws_id (str): The websocket ID.\n            operation_id (str): The operation associated with the stats\n            source_id (str, optional): The source associated with the stats. Defaults to None.\n            context_id (str): The context associated with the stats\n            source_total (int, optional): The total number of sources to be processed by the request to which this stats belong. Defaults to 1.\n            never_expire (bool, optional): Whether the stats should never expire, ignoring the configuration. Defaults to False.\n        Returns:\n            T: The created stats.\n        \"\"\"\n        MutyLogger.get_instance().debug(\n            \"---> create: id=%s, operation_id=%s, context_id=%s, source_id=%s, source_total=%d\",\n            req_id,\n            operation_id,\n            context_id,\n            source_id,\n            source_total,\n        )\n\n        # acquire an advisory lock\n        lock_id = muty.crypto.hash_xxh64_int(req_id)\n        await GulpCollabBase.acquire_advisory_lock(sess, lock_id)\n\n        # determine expiration time\n        time_expire = cls._calculate_expiration_time(never_expire)\n        time_updated = muty.time.now_msec()\n\n        # check if the stats already exist\n        s: GulpRequestStats = await cls.get_by_id(\n            sess, id=req_id, throw_if_not_found=False\n        )\n        if s:\n            # update existing stats\n            return await cls._update_existing_stats(sess, s, time_updated, time_expire)\n\n        object_data = {\n            \"time_expire\": time_expire,\n            \"operation_id\": operation_id,\n            \"context_id\": context_id,\n            \"source_id\": source_id,\n            \"source_total\": source_total,\n        }\n        return await super()._create(\n            sess,\n            object_data=object_data,\n            id=req_id,\n            ws_id=ws_id,\n            owner_id=user_id,\n            ws_queue_datatype=GulpWsQueueDataType.STATS_UPDATE,\n            req_id=req_id,\n        )\n\n    async def cancel(\n        self,\n        sess: AsyncSession,\n        user_id: str,\n    ):\n        \"\"\"\n        Cancel the stats.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            user_id (str): The user ID who cancels the stats.\n        \"\"\"\n        # expires in 5 minutes, allow any loop to finish\n        time_expire = muty.time.now_msec() + 60 * 1000 * 5\n        return await super().update(\n            sess,\n            {\n                \"status\": GulpRequestStatus.CANCELED,\n                \"time_expire\": time_expire,\n                \"completed\": \"1\",\n                \"time_finished\": muty.time.now_msec(),\n            },\n            ws_id=None,\n            user_id=user_id,\n            req_id=self.id,\n            ws_queue_datatype=GulpWsQueueDataType.STATS_UPDATE,\n        )\n\n    @override\n    async def delete(\n        self,\n        sess,\n        ws_id=None,\n        user_id=None,\n        ws_queue_datatype=GulpWsQueueDataType.COLLAB_DELETE,\n        ws_data=None,\n        req_id=None,\n    ):\n        raise NotImplementedError(\"Stats will be deleted by the system automatically.\")\n\n    @classmethod\n    async def update_by_id(\n        cls,\n        sess: AsyncSession,\n        id: str,\n        user_id: str,\n        ws_id: str,\n        req_id: str,\n        d: dict = None,\n        updated_instance: T = None,\n    ) -> dict:\n        \"\"\"\n        same as base class update_by_id, but without checking token\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            id (str): The ID of the object to update.\n            user_id (str): The user ID updating the object.\n            ws_id (str): The websocket ID.\n            req_id (str): The request ID.\n            d (dict, optional): The data to update the object with. Defaults to None.\n            updated_instance (T, optional): An already updated instance of the object. Defaults to None.\n\n        Returns:\n            dict: The updated object as a dictionary.\n\n        Raises:\n            ValueError: If both d and updated_instance are provided.\n            MissingPermissionError: If the user does not have permission to update the object.\n        \"\"\"\n        if d and updated_instance:\n            raise ValueError(\"only one of d or updated_instance should be provided\")\n\n        n: GulpCollabBase = await cls.get_by_id(sess, id, with_for_update=True)\n        try:\n            await n.update(\n                sess,\n                d=d,\n                ws_id=ws_id,\n                user_id=user_id,\n            )\n        except:\n            pass\n        return n.to_dict(exclude_none=True)\n\n    async def _refresh_and_lock(self, sess: AsyncSession) -> None:\n        \"\"\"\n        refresh stats from db and acquire advisory lock.\n\n        Args:\n            sess (AsyncSession): database session\n        \"\"\"\n        lock_id = muty.crypto.hash_xxh64_int(self.id)\n        await GulpCollabBase.acquire_advisory_lock(sess, lock_id)\n        await sess.refresh(self)\n\n    def _update_counters(self, d: dict) -> None:\n        \"\"\"\n        update counter fields from input dictionary.\n\n        Args:\n            d (dict): input data with counter updates\n        \"\"\"\n        self.source_processed += d.get(\"source_processed\", 0)\n        self.source_failed += d.get(\"source_failed\", 0)\n        self.records_failed += d.get(\"records_failed\", 0)\n        self.records_skipped += d.get(\"records_skipped\", 0)\n        self.records_processed += d.get(\"records_processed\", 0)\n        self.records_ingested += d.get(\"records_ingested\", 0)\n        self.source_id = d.get(\"source_id\", self.source_id)\n\n    def _process_errors(\n        self, error: Optional[Union[Exception, str, list[str]]]\n    ) -> None:\n        \"\"\"\n        process and store errors.\n\n        Args:\n            error (Exception|str|list[str], optional): error information to process\n        \"\"\"\n        if not error:\n            return\n\n        if not self.errors:\n            self.errors = []\n\n        # handle different error types\n        if isinstance(error, Exception):\n            MutyLogger.get_instance().exception(error)\n            error_str = str(error)\n            if error_str not in self.errors:\n                self.errors.append(error_str)\n        elif isinstance(error, str):\n            if error not in self.errors:\n                self.errors.append(error)\n        elif isinstance(error, list):\n            for e in error:\n                if e not in self.errors:\n                    self.errors.append(e)\n\n    def _handle_status_updates(self, d: dict) -> Optional[GulpRequestStatus]:\n        \"\"\"\n        handle explicit status updates from input data.\n\n        Args:\n            d (dict): input data with possible status update\n\n        Returns:\n            GulpRequestStatus: forced status if provided in update\n        \"\"\"\n        status: GulpRequestStatus = d.get(\"status\", None)\n        if status:\n            self.status = status\n        return status\n\n    def _determine_status_based_on_state(self) -> None:\n        \"\"\"\n        determine the status based on processing state and counts.\n        \"\"\"\n        # check if all sources processed\n        if self.source_processed == self.source_total:\n            MutyLogger.get_instance().debug(\n                'source_processed: %d == source_total: %d, setting request \"%s\" to DONE'\n                % (self.source_processed, self.source_total, self.id)\n            )\n            if self.records_processed > 0 and self.records_ingested == 0:\n                self.status = GulpRequestStatus.FAILED\n            else:\n                self.status = GulpRequestStatus.DONE\n\n        # check if all sources failed\n        if self.source_failed == self.source_total:\n            MutyLogger.get_instance().error(\n                'source_failed: %d == source_total: %d, setting request \"%s\" to FAILED'\n                % (self.source_failed, self.source_total, self.id)\n            )\n            self.status = GulpRequestStatus.FAILED\n\n        # edge case for DONE but records processing failed\n        if self.status == GulpRequestStatus.DONE:\n            if self.records_processed == 0 and self.records_failed > 0:\n                self.status = GulpRequestStatus.FAILED\n\n    def _handle_completed_status(self) -> None:\n        \"\"\"\n        handle finalization of the request when status indicates completion.\n        \"\"\"\n        if self.status not in [\n            GulpRequestStatus.CANCELED,\n            GulpRequestStatus.FAILED,\n            GulpRequestStatus.DONE,\n        ]:\n            return\n\n        # mark as complete and record finishing time\n        self.time_finished = muty.time.now_msec()\n        self.completed = \"1\"\n\n        # log completion information\n        MutyLogger.get_instance().info(\n            'REQUEST TIME INFO: request \"%s\" COMPLETED with status=%s, TOTAL TIME: %d seconds'\n            % (\n                self.id,\n                self.status,\n                (self.time_finished - self.time_created) / 1000,\n            )\n        )\n\n    @override\n    async def update(\n        self,\n        sess: AsyncSession,\n        d: dict,\n        ws_id: str,\n        user_id: str,\n    ) -> None:\n        \"\"\"\n        Update the stats.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            d (dict): The dictionary of values to update:\n                source_processed (int): The number of sources processed.\n                source_failed (int): The number of sources that failed.\n                records_failed (int): The number of records that failed.\n                records_skipped (int): The number of records that were skipped.\n                records_processed (int): The number of records that were processed.\n                records_ingested (int): The number of records that were ingested.\n                error (str|Exception|list[str]): The error message or exception that occurred.\n                status (GulpRequestStatus): The status of the stats.\n\n            ws_id (str): The websocket ID.\n            user_id (str): The user ID updating the stats.\n\n        \"\"\"\n        # refresh stats and acquire lock\n        await self._refresh_and_lock(sess)\n\n        # update counters\n        self._update_counters(d)\n\n        # process errors if any\n        self._process_errors(d.get(\"error\", None))\n\n        # handle status updates\n        forced_status = self._handle_status_updates(d)\n\n        # log update details\n        msg = f\"---> update: ws_id={ws_id}, d={d}\"\n        if \"error\" in d and d[\"error\"]:\n            MutyLogger.get_instance().error(msg)\n        else:\n            MutyLogger.get_instance().debug(msg)\n\n        # determine status based on processing state\n        self._determine_status_based_on_state()\n\n        # handle completed status and update completion metrics\n        self._handle_completed_status()\n\n        # update the instance (will update websocket too)\n        if forced_status:\n            self.status = forced_status\n\n        await super().update(\n            sess,\n            d=None,\n            ws_id=ws_id,\n            user_id=user_id,\n            ws_queue_datatype=GulpWsQueueDataType.STATS_UPDATE,\n            req_id=self.id,\n            updated_instance=self,\n        )\n\n    @staticmethod\n    async def _update_stats_for_query_completion(\n        stats: \"GulpRequestStats\", hits: int, errors: Optional[list[str]]\n    ) -> None:\n        \"\"\"\n        update stats object for query completion.\n\n        Args:\n            stats (GulpRequestStats): stats object to update\n            hits (int): number of hits\n            errors (list[str], optional): list of errors\n        \"\"\"\n        # mark as completed\n        stats.completed = \"1\"\n        stats.time_finished = muty.time.now_msec()\n\n        # determine status based on hits\n        if hits >= 1:\n            stats.status = GulpRequestStatus.DONE\n        else:\n            stats.status = GulpRequestStatus.FAILED\n\n        # add any errors\n        if errors:\n            if not stats.errors:\n                stats.errors = errors\n            else:\n                stats.errors.extend(errors)\n\n        stats.total_hits = hits\n        MutyLogger.get_instance().debug(f\"update_query_stats: {stats}\")\n\n    @staticmethod\n    def _send_query_done_notification(\n        ws_id: str,\n        user_id: str,\n        req_id: str,\n        status: GulpRequestStatus,\n        errors: Optional[list[str]],\n        hits: int,\n        q_name: Optional[str],\n        ws_queue_datatype: GulpWsQueueDataType,\n    ) -> None:\n        \"\"\"\n        send query done notification through websocket.\n\n        Args:\n            ws_id (str): websocket id\n            user_id (str): user id\n            req_id (str): request id\n            status (GulpRequestStatus): final status\n            errors (list[str], optional): list of errors\n            hits (int): number of hits\n            q_name (str, optional): query name\n            ws_queue_datatype (GulpWsQueueDataType): websocket queue data type\n        \"\"\"\n        MutyLogger.get_instance().debug(f\"sending query done packet, errors={errors}\")\n\n        p = GulpQueryDonePacket(\n            status=status,\n            errors=errors or [],\n            total_hits=hits,\n            name=q_name,\n        )\n\n        GulpWsSharedQueue.get_instance().put(\n            type=ws_queue_datatype,\n            ws_id=ws_id,\n            user_id=user_id,\n            req_id=req_id,\n            data=p.model_dump(exclude_none=True),\n        )\n\n    @staticmethod\n    async def finalize_query_stats(\n        sess: AsyncSession,\n        req_id: str,\n        ws_id: str,\n        user_id: str,\n        q_name: str = None,\n        hits: int = 0,\n        ws_queue_datatype: GulpWsQueueDataType = GulpWsQueueDataType.QUERY_DONE,\n        errors: list[str] = None,\n        send_query_done: bool = True,\n    ) -> None:\n        \"\"\"\n        sets the final status of a query stats\n\n        Args:\n            sess(AsyncSession): collab database session\n            req_id(str): the request id\n            ws_id(str): the websocket id\n            user_id(str): the user id\n            q_name(str, optional): the query name (default: None)\n            hits(int, optiona): the number of hits (default: 0)\n            ws_queue_datatype(GulpWsQueueDataType, optional): the websocket queue data type (default: GulpWsQueueDataType.QUERY_DONE)\n            errors(list[str], optional): the list of errors (default: None)\n            send_query_done(bool, optional): whether to send the query done packet to the websocket (default: True)\n        \"\"\"\n        stats: GulpRequestStats = await GulpRequestStats.get_by_id(\n            sess, req_id, throw_if_not_found=False\n        )\n        status: GulpRequestStatus = GulpRequestStatus.DONE\n\n        if stats and stats.status != GulpRequestStatus.CANCELED:\n            await GulpRequestStats._update_stats_for_query_completion(\n                stats, hits, errors\n            )\n            status = stats.status\n            await sess.commit()\n\n        if send_query_done:\n            # inform the websocket\n            GulpRequestStats._send_query_done_notification(\n                ws_id, user_id, req_id, status, errors, hits, q_name, ws_queue_datatype\n            )\n"}
{"type": "source_file", "path": "src/gulp/api/collab_api.py", "content": "import asyncio\nimport json\nimport os\nimport pkgutil\nfrom importlib import import_module, resources\n\nimport muty.file\nimport muty.time\nfrom muty.log import MutyLogger\nfrom sqlalchemy import text\nfrom sqlalchemy.ext.asyncio import (\n    AsyncEngine,\n    AsyncSession,\n    async_sessionmaker,\n    create_async_engine,\n)\nfrom sqlalchemy_utils import create_database, database_exists, drop_database\n\nfrom gulp.api.collab.structs import GulpCollabBase\nfrom gulp.api.rest.test_values import (\n    TEST_CONTEXT_NAME,\n    TEST_INDEX,\n    TEST_OPERATION_ID,\n    TEST_SOURCE_NAME,\n)\nfrom gulp.config import GulpConfig\nfrom gulp.structs import ObjectNotFound\n\n\nclass GulpCollab:\n    \"\"\"\n    singleton class, represents the collab database connection.\n\n    init() must be called first to initialize the connection.\n\n    for ssl connection, it will use the certificates in the GulpConfig.get_instance().path_certs() directory if they exist.\n\n    they should be named \"postgres-ca.pem\", \"postgres.pem\", \"postgres.key\" for the CA, client certificate, and client key respectively.\n\n    \"\"\"\n\n    _instance: \"GulpCollab\" = None\n\n    def __init__(self):\n        pass\n\n    def __new__(cls):\n        \"\"\"\n        Create a new instance of the class.\n        \"\"\"\n        if not cls._instance:\n            cls._instance = super().__new__(cls)\n            cls._instance._initialize()\n        return cls._instance\n\n    @classmethod\n    def get_instance(cls) -> \"GulpCollab\":\n        \"\"\"\n        returns the singleton instance of the collab database connection.\n\n        Returns:\n            GulpCollab: The singleton instance of the collab database connection\n        \"\"\"\n        if not cls._instance:\n            cls._instance = cls()\n        return cls._instance\n\n    def _initialize(self):\n        \"\"\"\n        initializes the collab database connection (create the engine and configure it) in the singleton instance.\n        \"\"\"\n        self._initialized: bool = True\n        self._setup_done: bool = False\n        self._engine: AsyncEngine = None\n        self._collab_sessionmaker: async_sessionmaker = None\n\n    async def init(\n        self,\n        force_recreate: bool = False,\n        expire_on_commit: bool = False,\n        main_process: bool = False,\n    ) -> None:\n        \"\"\"\n        initializes the collab database connection (create the engine and configure it) in the singleton instance.\n\n        if called on an already initialized instance, the existing engine is disposed and a new one is created.\n\n        Args:\n            force_recreate (bool, optional): whether to drop and recreate the database tables. Defaults to False.\n            expire_on_commit (bool, optional): whether to expire sessions returned by session() on commit. Defaults to False.\n            main_process (bool, optional): whether this is the main process. Defaults to False.\n        \"\"\"\n        url = GulpConfig.get_instance().postgres_url()\n\n        # NOTE: i am not quite sure why this is needed, seems like sqlalchemy needs all the classes to be loaded before accessing the tables.\n        package_name = \"gulp.api.collab\"\n        package = import_module(package_name)\n        for _, module_name, _ in pkgutil.iter_modules(package.__path__):\n            import_module(f\"{package_name}.{module_name}\")\n\n        if main_process:\n            MutyLogger.get_instance().debug(\"init in MAIN process ...\")\n            if force_recreate:\n                # drop and recreate the database\n                await GulpCollab.db_drop(url)\n                await GulpCollab.db_create(url)\n\n            await self.shutdown()\n            self._engine = await self._create_engine()\n            self._collab_sessionmaker = async_sessionmaker(\n                bind=self._engine, expire_on_commit=expire_on_commit\n            )\n            if force_recreate:\n                await self.create_tables()\n\n            # check tables exists\n            async with self._collab_sessionmaker() as sess:\n                if not await self._check_all_tables_exist(sess):\n                    raise Exception(\n                        \"collab database exists but (some) tables are missing.\"\n                    )\n        else:\n            MutyLogger.get_instance().debug(\"init in worker process ...\")\n            self._engine = await self._create_engine()\n            self._collab_sessionmaker = async_sessionmaker(\n                bind=self._engine, expire_on_commit=expire_on_commit\n            )\n\n        self._setup_done = True\n\n    async def _create_engine(self) -> AsyncEngine:\n        \"\"\"\n        creates the collab database engine\n\n        Returns:\n            AsyncEngine: The collab database engine.\n        \"\"\"\n        url = GulpConfig.get_instance().postgres_url()\n\n        # check for ssl connection preferences\n        # https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-PARAMKEYWORDS\n        certs_dir = GulpConfig.get_instance().path_certs()\n        postgres_ssl = GulpConfig.get_instance().postgres_ssl()\n        verify_certs = GulpConfig.get_instance().postgres_verify_certs()\n        if verify_certs:\n            sslmode = \"verify-full\"\n        else:\n            sslmode = \"prefer\"\n        # MutyLogger.get_instance().debug(\"---> collab: creating AsyncEngine connection, sslmode=%s...\" % (sslmode))\n\n        if certs_dir is not None and postgres_ssl:\n            # https and certs_dir is set\n            ca: str = muty.file.abspath(\n                muty.file.safe_path_join(certs_dir, \"postgres-ca.pem\")\n            )\n\n            # check if client certificate exists. if so, it will be used\n            client_cert = muty.file.safe_path_join(certs_dir, \"postgres.pem\")\n            client_key = muty.file.safe_path_join(certs_dir, \"postgres.key\")\n            client_key_password = (\n                GulpConfig.get_instance().postgres_client_cert_password()\n            )\n            if os.path.exists(client_cert) and os.path.exists(client_key):\n                MutyLogger.get_instance().debug(\n                    \"using client certificate: %s, key=%s, ca=%s\"\n                    % (client_cert, client_key, ca)\n                )\n                connect_args = {\n                    \"sslrootcert\": ca,\n                    \"sslcert\": client_cert,\n                    \"sslkey\": client_key,\n                    \"sslmode\": sslmode,\n                    \"sslpassword\": client_key_password,\n                }\n            else:\n                # no client certificate\n                MutyLogger.get_instance().debug(\n                    \"using server CA certificate only: %s\" % (ca)\n                )\n                connect_args = {\"sslrootcert\": ca, \"sslmode\": sslmode}\n        else:\n            # no SSL\n            connect_args = {}\n\n        # create engine\n        _engine = create_async_engine(\n            url,\n            echo=GulpConfig.get_instance().debug_collab(),\n            connect_args=connect_args,\n            pool_pre_ping=True,  # Enables connection health checks\n            pool_recycle=3600,  # Recycle connections after 1 hour\n            max_overflow=10,  # Allow up to 10 additional connections\n            pool_timeout=30,  # Wait up to 30 seconds for available connection\n        )\n\n        MutyLogger.get_instance().info(\n            \"engine %s created/initialized, url=%s ...\" % (_engine, url)\n        )\n        return _engine\n\n    def session(self) -> AsyncSession:\n        \"\"\"\n        Returns a session (preconfigured with expire_on_commit=False) to the collab database, per-process engine is created if needed.\n\n        WARNING: to call this, an event loop must be running.\n\n        Returns:\n            AsyncSession: The session to the collab database\n        \"\"\"\n        if not self._setup_done:\n            raise Exception(\"collab not initialized, call GulpCollab().init() first!\")\n\n        return self._collab_sessionmaker()\n\n    async def shutdown(self) -> None:\n        \"\"\"\n        Shuts down the per-process collab database engine.\n\n        after calling this, the engine is invalidated and all existing connections are disposed and GulpCollab().init() must be called again to reinitialize the engine in the same process.\n\n        Returns:\n            None\n        \"\"\"\n        if self._engine:\n            MutyLogger.get_instance().debug(\n                \"shutting down collab database engine and invalidate existing connections ...\"\n            )\n            await self._engine.dispose()\n\n        self._setup_done = False\n        self._engine = None\n        self._collab_sessionmaker = None\n\n    @staticmethod\n    async def db_exists(url: str) -> bool:\n        \"\"\"\n        Check if a database exists at the given URL.\n\n        Args:\n            url (str): The URL of the database.\n\n        Returns:\n            bool: True if the database exists, False otherwise.\n        \"\"\"\n        b = await asyncio.to_thread(database_exists, url=url)\n        MutyLogger.get_instance().debug(\"---> exists: url=%s, result=%r\" % (url, b))\n        return b\n\n    @staticmethod\n    async def db_drop(url: str, raise_if_not_exists: bool = False) -> None:\n        \"\"\"\n        Drops a database specified by the given URL.\n\n        Args:\n            url (str): The URL of the database to drop.\n            raise_if_not_exists (bool, optional): Whether to raise an exception if the database does not exist. Defaults to False.\n            recreate (bool, optional): Whether to recreate the database (including the default data) after dropping it. Defaults to True.\n        Note:\n            if recreate is specified, only the database is created. to create tables and the default data, use engine_get then.\n        \"\"\"\n\n        def _blocking_drop(url: str, raise_if_not_exists: bool = False):\n            \"\"\"\n            internal function to drop, and possibly recreate, the database: this is blocking, so this is wrapped in a thread.\n            \"\"\"\n            if database_exists(url):\n                MutyLogger.get_instance().info(\n                    \"--> drop: dropping database %s ...\" % (url)\n                )\n                drop_database(url)\n                MutyLogger.get_instance().info(\n                    \"--> drop: database %s dropped ...\" % (url)\n                )\n            else:\n                MutyLogger.get_instance().warning(\n                    \"--> drop: database %s does not exist!\" % (url)\n                )\n                if raise_if_not_exists:\n                    raise ObjectNotFound(\"database %s does not exist!\" % (url))\n\n        MutyLogger.get_instance().debug(\n            \"---> drop: url=%s, raise_if_not_exists=%r\" % (url, raise_if_not_exists)\n        )\n        await asyncio.to_thread(_blocking_drop, url, raise_if_not_exists)\n\n    @staticmethod\n    async def db_create(url: str) -> None:\n        \"\"\"\n        Create a database at the given URL.\n\n        Args:\n            url (str): The URL of the database to create.\n        \"\"\"\n        MutyLogger.get_instance().debug(\"---> create: url=%s\" % (url))\n        await asyncio.to_thread(create_database, url=url)\n\n    async def _setup_collab_expirations(self) -> None:\n        # TODO: check issues with pg-cron process dying\n        MutyLogger.get_instance().debug(\n            \"setting up stats and tokens expiration with pg_cron ...\"\n        )\n        async with self._collab_sessionmaker() as sess:\n            # create pg_cron extension\n            await sess.execute(text(\"CREATE EXTENSION IF NOT EXISTS pg_cron;\"))\n\n            await sess.execute(\n                text(\n                    \"\"\"\n                CREATE OR REPLACE FUNCTION delete_expired_stats_rows() RETURNS void AS $$\n                BEGIN\n                    DELETE FROM request_stats WHERE (EXTRACT(EPOCH FROM NOW()) * 1000) > time_expire AND time_expire > 0;\n                END;\n                $$ LANGUAGE plpgsql;\n            \"\"\"\n                )\n            )\n\n            await sess.execute(\n                text(\n                    \"\"\"\n                CREATE OR REPLACE FUNCTION delete_expired_tokens_rows() RETURNS void AS $$\n                BEGIN\n                    DELETE FROM user_session WHERE (EXTRACT(EPOCH FROM NOW()) * 1000) > time_expire AND time_expire > 0;\n                END;\n                $$ LANGUAGE plpgsql;\n            \"\"\"\n                )\n            )\n\n            # purge stats and tokens every 1 minutes\n            await sess.execute(\n                text(\n                    \"\"\"\n                    SELECT cron.schedule('* * * * *', 'SELECT delete_expired_stats_rows();');\n                    \"\"\"\n                )\n            )\n            await sess.execute(\n                text(\n                    \"\"\"\n                    SELECT cron.schedule('* * * * *', 'SELECT delete_expired_tokens_rows();');\n                    \"\"\"\n                )\n            )\n            await sess.commit()\n\n    async def create_tables(self) -> None:\n        \"\"\"\n        creates the database tables and functions.\n        \"\"\"\n        # create database tables and functions\n        async with self._engine.begin() as conn:\n            await conn.run_sync(GulpCollabBase.metadata.create_all)\n        await self._setup_collab_expirations()\n\n    async def clear_tables(self, exclude: list[str] = None) -> None:\n        \"\"\"\n        clears the database tables, excluding the ones in the exclude list.\n\n        Args:\n            exclude (list[str], optional): The list of tables to exclude. Defaults to None.\n        \"\"\"\n        if not exclude:\n            # clear all tables\n            exclude = []\n\n        async with self._engine.begin() as conn:\n            for table_name, table in GulpCollabBase.metadata.tables.items():\n                # MutyLogger.get_instance().debug(\"---> clear: table=%s\" % (table_name))\n                if table_name not in exclude:\n                    await conn.execute(table.delete())\n\n    async def create_default_operation(\n        self, operation_id: str = TEST_OPERATION_ID, index: str = TEST_INDEX\n    ) -> None:\n        \"\"\"\n        create the default operation with a context and a source.\n\n        Args:\n            operation_id (str, optional): The operation ID to use. Defaults to TEST_OPERATION_ID.\n            index (str, optional): The index name to use. Defaults to TEST_INDEX.\n        \"\"\"\n        from gulp.api.collab.context import GulpContext\n        from gulp.api.collab.glyph import GulpGlyph\n        from gulp.api.collab.operation import GulpOperation\n        from gulp.api.collab.structs import GulpCollabFilter\n        from gulp.api.collab.user import GulpUser\n\n        async with self._collab_sessionmaker() as sess:\n            admin_user: GulpUser = await GulpUser.get_by_id(sess, \"admin\")\n            operation_glyph: GulpGlyph = await GulpGlyph.get_first_by_filter(\n                sess,\n                GulpCollabFilter(names=[\"test_operation_icon\"]),\n                user_id=\"admin\",\n                user_id_is_admin=True,\n                throw_if_not_found=False,\n            )\n\n            # create default operation\n            operation: GulpOperation = await GulpOperation._create(\n                sess,\n                object_data={\n                    \"name\": operation_id,\n                    \"index\": index,\n                    \"glyph_id\": operation_glyph.id if operation_glyph else None,\n                },\n                id=operation_id,\n                owner_id=admin_user.id,\n            )\n\n            # add sources to context and context to operation\n            ctx: GulpContext\n            ctx, _ = await operation.add_context(\n                sess,\n                user_id=admin_user.id,\n                name=TEST_CONTEXT_NAME,\n            )\n            await ctx.add_source(sess, admin_user.id, TEST_SOURCE_NAME)\n\n            # add default grants (groups and users)\n            await operation.add_default_grants(sess)\n\n            operations: list[GulpOperation] = await GulpOperation.get_by_filter(\n                sess, user_id=\"admin\", user_id_is_admin=True\n            )\n            for op in operations:\n                MutyLogger.get_instance().debug(\n                    json.dumps(op.to_dict(nested=True), indent=4)\n                )\n\n    async def create_default_users(self) -> None:\n        \"\"\"\n        create default users and user groups\n\n        Args:\n            user_id (str): The (admin) user ID to use (will be set as the owner of the created objects).\n        \"\"\"\n        from gulp.api.collab.structs import (\n            PERMISSION_MASK_DELETE,\n            PERMISSION_MASK_EDIT,\n            PERMISSION_MASK_INGEST,\n            GulpUserPermission,\n        )\n        from gulp.api.collab.user import GulpUser\n        from gulp.api.collab.user_group import GulpUserGroup\n\n        async with self._collab_sessionmaker() as sess:\n            # create admin user, which is the root of everything else\n            admin_user: GulpUser = await GulpUser.create(\n                sess,\n                \"admin\",\n                \"admin\",\n                permission=[GulpUserPermission.ADMIN],\n            )\n\n            # login admin user\n            # admin_session = await GulpUser.login(sess, \"admin\", \"admin\", None, None)\n\n            # create other users\n            guest_user = await GulpUser.create(\n                sess,\n                user_id=\"guest\",\n                password=\"guest\",\n            )\n            editor_user = await GulpUser.create(\n                sess,\n                user_id=\"editor\",\n                password=\"editor\",\n                permission=PERMISSION_MASK_EDIT,\n            )\n            ingest_user = await GulpUser.create(\n                sess,\n                user_id=\"ingest\",\n                password=\"ingest\",\n                permission=PERMISSION_MASK_INGEST,\n            )\n            power_user = await GulpUser.create(\n                sess,\n                user_id=\"power\",\n                password=\"power\",\n                permission=PERMISSION_MASK_DELETE,\n            )\n\n            # create user groups\n            from gulp.api.collab.user_group import ADMINISTRATORS_GROUP_ID\n\n            group: GulpUserGroup = await GulpUserGroup._create(\n                sess,\n                id=ADMINISTRATORS_GROUP_ID,\n                object_data={\n                    \"name\": \"example group\",\n                    \"permission\": [GulpUserPermission.ADMIN],\n                },\n                owner_id=admin_user.id,\n                private=False,\n            )\n\n            # add admin to administrators group\n            await group.add_user(sess, admin_user.id)\n\n            # dump groups\n            groups: list[GulpUserGroup] = await GulpUserGroup.get_by_filter(\n                sess, user_id=\"admin\", user_id_is_admin=True\n            )\n            for group in groups:\n                MutyLogger.get_instance().debug(\n                    json.dumps(group.to_dict(nested=True), indent=4)\n                )\n\n            # dump admin user\n            MutyLogger.get_instance().debug(\n                json.dumps(admin_user.to_dict(nested=True), indent=4)\n            )\n\n    async def create_default_data(self) -> None:\n        \"\"\"\n        create the default data: glyphs, stored queries\n        \"\"\"\n        from gulp.api.collab.glyph import GulpGlyph\n        from gulp.api.collab.stored_query import GulpStoredQuery\n        from gulp.api.collab.user import GulpUser\n\n        async with self._collab_sessionmaker() as sess:\n            # get users\n            admin_user: GulpUser = await GulpUser.get_by_id(sess, \"admin\")\n            guest_user: GulpUser = await GulpUser.get_by_id(\n                sess, \"guest\", throw_if_not_found=False\n            )\n            editor_user: GulpUser = await GulpUser.get_by_id(\n                sess, \"editor\", throw_if_not_found=False\n            )\n            ingest_user: GulpUser = await GulpUser.get_by_id(\n                sess, \"ingest\", throw_if_not_found=False\n            )\n            power_user: GulpUser = await GulpUser.get_by_id(\n                sess, \"power\", throw_if_not_found=False\n            )\n\n            # read glyphs\n            assets_path = resources.files(\"gulp.api.collab.assets\")\n            user_b = await muty.file.read_file_async(\n                muty.file.safe_path_join(assets_path, \"user.png\")\n            )\n            operation_b = await muty.file.read_file_async(\n                muty.file.safe_path_join(assets_path, \"operation.png\")\n            )\n\n            # create glyphs\n            user_glyph = await GulpGlyph._create(\n                sess,\n                object_data={\n                    \"name\": \"test_user_icon\",\n                    \"img\": user_b,\n                },\n                owner_id=admin_user.id,\n                private=False,\n                id=\"test_user_icon\",\n            )\n\n            _ = await GulpGlyph._create(\n                sess,\n                object_data={\n                    \"name\": \"test_operation_icon\",\n                    \"img\": operation_b,\n                },\n                owner_id=admin_user.id,\n                private=False,\n                id=\"test_operation_icon\",\n            )\n\n            # assign glyphs\n            admin_user.glyph_id = user_glyph.id\n            if guest_user:\n                guest_user.glyph_id = user_glyph.id\n            if editor_user:\n                editor_user.glyph_id = user_glyph.id\n            if ingest_user:\n                ingest_user.glyph_id = user_glyph.id\n            if power_user:\n                power_user.glyph_id = user_glyph.id\n            await sess.commit()\n\n            # stored query: windows sigma 1\n            sigma_match_some = await muty.file.read_file_async(\n                muty.file.safe_path_join(assets_path, \"sigma_match_some.yaml\")\n            )\n            sigma_match_some_more = await muty.file.read_file_async(\n                muty.file.safe_path_join(assets_path, \"sigma_match_some_more.yaml\")\n            )\n            GulpStoredQuery = await GulpStoredQuery._create(\n                sess,\n                object_data={\n                    \"name\": \"win_evtx_sigma_1\",\n                    \"tags\": [\"stored\", \"sigma\"],\n                    \"q_groups\": [\"group1\"],\n                    \"q\": sigma_match_some.decode(\"utf-8\"),\n                    \"plugin\": \"win_evtx\",\n                },\n                id=\"test_stored_sigma_1\",\n                owner_id=admin_user.id,\n                private=False,\n            )\n\n            # stored query: windows sigma 2\n            GulpStoredQuery = await GulpStoredQuery._create(\n                sess,\n                object_data={\n                    \"name\": \"win_evtx_sigma_2\",\n                    \"tags\": [\"stored\", \"sigma\"],\n                    \"q_groups\": [\"group1\"],\n                    \"q\": sigma_match_some_more.decode(\"utf-8\"),\n                    \"plugin\": \"win_evtx\",\n                },\n                id=\"test_stored_sigma_2\",\n                owner_id=admin_user.id,\n                private=False,\n            )\n\n            # stored query: raw query\n            GulpStoredQuery = await GulpStoredQuery._create(\n                sess,\n                object_data={\n                    \"name\": \"raw_query\",\n                    \"tags\": [\"stored\", \"raw\"],\n                    \"q_groups\": [\"group2\"],\n                    \"q\": json.dumps(\n                        {\n                            \"query\": {\n                                \"bool\": {\n                                    \"must\": [\n                                        {\n                                            \"query_string\": {\n                                                \"query\": \"event.sequence:(352 OR 353 OR 354 OR 355)\",\n                                                \"analyze_wildcard\": True,\n                                            }\n                                        }\n                                    ]\n                                }\n                            }\n                        }\n                    ),\n                },\n                id=\"test_stored_raw\",\n                owner_id=admin_user.id,\n                private=False,\n            )\n\n            # stored query: splunk query\n            GulpStoredQuery = await GulpStoredQuery._create(\n                sess,\n                object_data={\n                    \"name\": \"splunk_raw_query\",\n                    \"tags\": [\"stored\", \"raw\", \"splunk\"],\n                    \"q\": 'EventCode=5156 Nome_applicazione=\"\\\\\\\\device\\\\\\\\harddiskvolume2\\\\\\\\program files\\\\\\\\intergraph smart licensing\\\\\\\\client\\\\\\\\islclient.exe\" RecordNumber=1224403979',\n                },\n                id=\"test_stored_raw_splunk\",\n                owner_id=admin_user.id,\n                private=False,\n            )\n\n    async def _check_all_tables_exist(self, sess: AsyncSession) -> bool:\n        \"\"\"\n        check if all tables exist in the database.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n        Returns:\n            bool: True if all tables exist, False otherwise.\n        \"\"\"\n\n        # get all table names from metadata\n        table_names = GulpCollabBase.metadata.tables.keys()\n\n        # build query to check all tables\n        tables_check = []\n        for table in table_names:\n            tables_check.append(f\"to_regclass('public.{table}') AS {table}\")\n\n        query = text(f\"SELECT {', '.join(tables_check)}\")\n\n        # execute query\n        result = await sess.execute(query)\n        row = result.one()\n\n        # check if any table is missing\n        return all(row)\n"}
{"type": "source_file", "path": "src/gulp/api/mapping/index_template/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/opensearch/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/collab/user_group.py", "content": "from typing import Optional, override\n\nfrom muty.log import MutyLogger\nfrom sqlalchemy import ARRAY, Column, ForeignKey, Table\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.ext.mutable import MutableList\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\nfrom sqlalchemy.types import Enum as SQLEnum\n\nfrom gulp.api.collab.structs import (\n    GulpCollabBase,\n    GulpCollabType,\n    GulpUserPermission,\n)\nfrom gulp.structs import ObjectAlreadyExists, ObjectNotFound\n\nADMINISTRATORS_GROUP_ID = \"administrators\"\n\nclass GulpUserAssociations:\n    # multiple users can be associated with a group\n    table = Table(\n        \"user_associations\",\n        GulpCollabBase.metadata,\n        Column(\"user_id\", ForeignKey(\"user.id\", ondelete=\"CASCADE\"), primary_key=True),\n        Column(\n            \"group_id\",\n            ForeignKey(\"user_group.id\", ondelete=\"CASCADE\"),\n            primary_key=True,\n        ),\n    )\n\n\nclass GulpUserGroup(GulpCollabBase, type=GulpCollabType.USER_GROUP):\n    \"\"\"\n    Represents an user group in the gulp system.\n    \"\"\"\n\n    users: Mapped[list[\"GulpUser\"]] = relationship(\n        \"GulpUser\",\n        secondary=GulpUserAssociations.table,\n        lazy=\"selectin\",\n    )\n    permission: Mapped[Optional[list[GulpUserPermission]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(SQLEnum(GulpUserPermission))),\n        default_factory=lambda: [GulpUserPermission.READ],\n        doc=\"One or more permissions of the user.\",\n    )\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d[\"permission\"] = [GulpUserPermission.READ]\n        return d\n\n    @classmethod\n    def example_nested(cls) -> dict:\n        from gulp.api.collab.user import GulpUser\n\n        d = cls.example()\n        d[\"users\"] = [GulpUser.example()]\n        return d\n\n    async def add_user(\n        self, sess: AsyncSession, user_id: str, raise_if_already_exists: bool = True\n    ) -> None:\n        \"\"\"\n        Adds a user to the group.\n\n        Args:\n            sess (AsyncSession): The session to use.\n            user_id (str): The user id to add to the group.\n            raise_if_already_exists (bool): If True, raises an error if the user is already in the group.\n        \"\"\"\n        from gulp.api.collab.user import GulpUser\n\n        user = await GulpUser.get_by_id(sess, id=user_id)\n        existing_users = [u.id for u in self.users]\n        if user_id not in existing_users:\n            self.users.append(user)\n            await sess.commit()\n            await sess.refresh(user)\n            MutyLogger.get_instance().info(\n                \"Adding user %s to group %s\" % (user_id, self.id)\n            )\n        else:\n            MutyLogger.get_instance().info(\n                \"User %s already in group %s\" % (user_id, self.id)\n            )\n            if raise_if_already_exists:\n                raise ObjectAlreadyExists(\n                    \"User %s already in group %s\" % (user_id, self.id)\n                )\n\n    async def remove_user(\n        self, sess: AsyncSession, user_id: str, raise_if_not_found: bool = True\n    ) -> None:\n        \"\"\"\n        Removes a user from the group.\n\n        Args:\n            sess (AsyncSession): The session to use.\n            user_id (str): The user id to remove from the group.\n            raise_if_not_found (bool): If True, raises an error if the user is not in the group.\n        \"\"\"\n        from gulp.api.collab.user import GulpUser\n\n        user = await GulpUser.get_by_id(sess, id=user_id)\n        existing_users = [u.id for u in self.users]\n        if user_id in existing_users:\n            self.users.remove(user)\n            await sess.commit()\n            await sess.refresh(self)\n            MutyLogger.get_instance().info(\n                \"Removing user %s from group %s\" % (user_id, self.id)\n            )\n        else:\n            MutyLogger.get_instance().info(\n                \"User %s not in group %s\" % (user_id, self.id)\n            )\n            if raise_if_not_found:\n                raise ObjectNotFound(\"User %s not in group %s\" % (user_id, self.id))\n\n    def is_admin(self) -> bool:\n        \"\"\"\n        Checks if the group is an admin group.\n\n        Returns:\n            bool: True if the group is an admin group, False otherwise.\n        \"\"\"\n        return GulpUserPermission.ADMIN in self.permission\n\n    def has_user(self, user_id: str) -> bool:\n        \"\"\"\n        Checks if the group has a user.\n\n        Args:\n            sess (AsyncSession): The session to use.\n            user_id (str): The user id to check.\n\n        Returns:\n            bool: True if the group has the user, False otherwise.\n        \"\"\"\n        return any([u.id == user_id for u in self.users])\n\n    def has_permission(self, permission: list[GulpUserPermission]) -> bool:\n        \"\"\"\n        Checks if the group has a permission.\n\n        Args:\n            permission (list[GulpUserPermission]): The permission/s to check\n\n        Returns:\n            bool: True if the group has the permission/s, False otherwise.\n        \"\"\"\n        if GulpUserPermission.ADMIN in self.permission:\n            return True\n\n        granted = all([p in self.permission for p in permission])\n        return granted\n"}
{"type": "source_file", "path": "src/gulp/api/collab/structs.py", "content": "import json\nimport re\nfrom enum import StrEnum\nfrom typing import TYPE_CHECKING, Any, List, Optional, TypeVar, override\n\nimport muty.string\nimport muty.time\nfrom muty.log import MutyLogger\nfrom psycopg import OperationalError\nfrom pydantic import BaseModel, ConfigDict, Field\nfrom sqlalchemy import (\n    ARRAY,\n    BIGINT,\n    VARCHAR,\n    Boolean,\n    ColumnElement,\n    ForeignKey,\n    Select,\n    String,\n    Tuple,\n    and_,\n    column,\n    exists,\n    func,\n    insert,\n    inspect,\n    literal,\n    or_,\n    select,\n    text,\n)\nfrom sqlalchemy.ext.asyncio import AsyncAttrs, AsyncSession\nfrom sqlalchemy.ext.mutable import MutableList\nfrom sqlalchemy.orm import (\n    DeclarativeBase,\n    Mapped,\n    MappedAsDataclass,\n    mapped_column,\n    selectinload,\n)\nfrom sqlalchemy.types import Enum as SqlEnum\nfrom sqlalchemy_mixins.serialize import SerializeMixin\nfrom tenacity import (\n    retry,\n    retry_if_exception_type,\n    stop_after_attempt,\n    wait_exponential,\n)\n\nif TYPE_CHECKING:\n    from gulp.api.ws_api import GulpWsQueueDataType\n\nfrom gulp.structs import GulpSortOrder, ObjectAlreadyExists, ObjectNotFound\n\n\nclass SessionExpired(Exception):\n    \"\"\"if the user session has expired\"\"\"\n\n\nclass WrongUsernameOrPassword(Exception):\n    \"\"\"if the user provides wrong username or password\"\"\"\n\n\nclass MissingPermission(Exception):\n    \"\"\"if the user does not have the required permission\"\"\"\n\n\nclass GulpRequestStatus(StrEnum):\n    \"\"\"Gulp request status codes.\"\"\"\n\n    ONGOING = \"ongoing\"\n    DONE = \"done\"\n    FAILED = \"failed\"\n    CANCELED = \"canceled\"\n    PENDING = \"pending\"\n\n\nclass GulpUserPermission(StrEnum):\n    \"\"\"represent the permission of a user in the Gulp platform.\n\n    a user can always read/edit/delete their own objects, but can only read other users' objects unless EDIT or DELETE permission is granted.\n    \"\"\"\n\n    # can read only\n    READ = \"read\"\n    # can edit highlights, notes, stories, links\n    EDIT = \"edit\"\n    # can delete highlights, notes, stories, links\n    DELETE = \"delete\"\n    # can ingest data\n    INGEST = \"ingest\"\n    # can do anything, including creating new users and change permissions\n    ADMIN = \"admin\"\n\n\nPERMISSION_MASK_EDIT = [GulpUserPermission.READ, GulpUserPermission.EDIT]\nPERMISSION_MASK_DELETE = [\n    GulpUserPermission.READ,\n    GulpUserPermission.EDIT,\n    GulpUserPermission.DELETE,\n]\nPERMISSION_MASK_INGEST = [\n    GulpUserPermission.READ,\n    GulpUserPermission.INGEST,\n    GulpUserPermission.EDIT,\n]\n\n\nclass GulpCollabType(StrEnum):\n    \"\"\"\n    defines the types in the collab database\n    \"\"\"\n\n    GENERIC_OBJECT = \"collab_obj\"\n    NOTE = \"note\"\n    HIGHLIGHT = \"highlight\"\n    STORY = \"story\"\n    LINK = \"link\"\n    STORED_QUERY = \"stored_query\"\n    REQUEST_STATS = \"request_stats\"\n    USER_DATA = \"user_data\"\n    USER_SESSION = \"user_session\"\n    CONTEXT = \"context\"\n    USER = \"user\"\n    GLYPH = \"glyph\"\n    OPERATION = \"operation\"\n    SOURCE = \"source\"\n    USER_GROUP = \"user_group\"\n    SOURCE_FIELDS = \"source_fields\"\n\n    def __str__(self) -> str:\n        return self.value\n\n    def __repr__(self) -> str:\n        return f\"'{str(self)}'\"\n\n    def __json__(self) -> str:\n        return str(self)\n\n\nT = TypeVar(\"T\", bound=\"GulpCollabBase\")\n\n\nclass GulpCollabFilter(BaseModel):\n    \"\"\"\n    defines filter to be applied to all objects in the collaboration system.\n\n    - filtering by basic types in `GulpCollabBase` and `GulpCollabObject` (for collab objects) is always supported.\n    - use % for wildcard instead of * (SQL LIKE operator).\n    - custom fields are supported via `model_extra` as k: [v,v,v,...] pairs where v are strings to match against the column (case insensitive/OR match).\n        i.e. `{\"custom_field\": [\"val1\", \"val2\"]}` will match all objects where `custom_field` is either \"val1\" or \"val2\".\n        if \"grant_user_ids\" and/or \"grant_user_group_ids\" are provided, only objects with the defined (or empty, public) grants will be returned.\n    \"\"\"\n\n    # allow extra fields to be interpreted as additional filters on the object columns as simple key-value pairs\n    model_config = ConfigDict(\n        extra=\"allow\",\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"ids\": [\"id1\", \"id2\"],\n                    \"types\": [\"note\", \"highlight\"],\n                    \"operation_ids\": [\"op1\", \"op2\"],\n                    \"context_ids\": [\"ctx1\", \"ctx2\"],\n                    \"source_ids\": [\"src1\", \"src2\"],\n                    \"owner_user_ids\": [\"admin\"],\n                    \"tags\": [\"tag1\", \"tag2\"],\n                    \"names\": [\"name1\", \"name2\"],\n                    \"texts\": [\"text1\", \"text2\"],\n                    \"time_pin_range\": (1620000000000000000, 1620000000000000001),\n                    \"doc_ids\": [\"18b6332595d82048e31963e6960031a1\"],\n                    \"doc_time_range\": (1620000000000000000, 1620000000000000001),\n                    \"limit\": 10,\n                    \"offset\": 100,\n                    \"tags_and\": False,\n                    \"sort\": [(\"time_created\", \"ASC\"), (\"id\", \"ASC\")],\n                },\n            ]\n        },\n    )\n\n    ids: Optional[list[str]] = Field(None, description=\"filter by the given id/s.\")\n    types: Optional[list[GulpCollabType]] = Field(\n        None,\n        description=\"filter by the given type/s.\",\n    )\n    operation_ids: Optional[list[str]] = Field(\n        None, description=\"filter by the given operation/s.\"\n    )\n    context_ids: Optional[list[str]] = Field(\n        None, description=\"filter by the given context/s.\"\n    )\n    source_ids: Optional[list[str]] = Field(\n        None,\n        description=\"filter by the given source path/s or name/s.\",\n    )\n    owner_user_ids: Optional[list[str]] = Field(\n        None, description=\"filter by the given owner user id/s.\"\n    )\n    tags: Optional[list[str]] = Field(None, description=\"filter by the given tag/s.\")\n    names: Optional[list[str]] = Field(None, description=\"filter by the given name/s.\")\n    texts: Optional[list[str]] = Field(\n        None,\n        description=\"filter by the given object text (wildcard accepted).\",\n    )\n    time_pin_range: Optional[tuple[int, int]] = Field(\n        None,\n        description=\"\"\"\nif set, matches objects in a `CollabObject.time_pin` range [start, end], inclusive, in nanoseconds from unix epoch.\n\n- cannot be used with `doc_ids` or `doc_time_range`.\n\"\"\",\n    )\n    doc_ids: Optional[list[str]] = Field(\n        None,\n        description=\"\"\"\nfilter by the given document ID/s in a `CollabObject.docs` list of `GulpBasicDocument` or in a `CollabObject.doc_ids` list of document IDs.\n\n- cannot be used with `time_pin_range` or `doc_time_range`.\n\"\"\",\n    )\n    doc_time_range: Optional[tuple[int, int]] = Field(\n        None,\n        description=\"\"\"\nif set, a `gulp.timestamp` range [start, end] to match documents in a `CollabObject.docs`, inclusive, in nanoseconds from unix epoch.\n\n- cannot be used with `time_pin_range` or `doc_ids`.\n- works with Notes, does not work with Links\n\"\"\",\n    )\n    limit: Optional[int] = Field(\n        None,\n        description='to be used together with \"offset\", maximum number of results to return. default=return all.',\n    )\n    offset: Optional[int] = Field(\n        None,\n        description='to be used together with \"limit\", number of results to skip from the beginning. default=0 (from start).',\n    )\n    tags_and: Optional[bool] = Field(\n        False,\n        description=\"if True, all tags must match. Default=False (at least one tag must match).\",\n    )\n    sort: Optional[list[tuple[str, GulpSortOrder]]] = Field(\n        None,\n        description=\"sort fields and order. Default=sort by `time_created` ASC, `id` ASC.\",\n    )\n\n    @override\n    def __str__(self) -> str:\n        return self.model_dump_json(exclude_none=True)\n\n    def _case_insensitive_or_ilike(self, column, values: list) -> ColumnElement[bool]:\n        \"\"\"\n        Create a case-insensitive OR query for the given column and values.\n\n        Args:\n            column: The column to apply the ilike condition.\n            values: The list of values to match against the column.\n\n        Returns:\n            ColumnElement[bool]: The OR query.\n        \"\"\"\n        # print(\"column=%s, values=%s\" % (column, values))\n        # check if values in values contains wildcards as *, if so, replace with % for SQL LIKE operator\n        values = [val.replace(\"*\", \"%\") for val in values]\n        conditions = [column.ilike(value) for value in values]\n        return or_(*conditions)\n\n    def _array_contains_all(self, array_field, values):\n        \"\"\"\n        array containment check (ALL must match)\n        \"\"\"\n        lowered_values = [val.lower() for val in values]\n        conditions = []\n        for val in lowered_values:\n            subq = (\n                select(literal(1))\n                .select_from(func.unnest(array_field).alias(\"elem\"))\n                .where(func.lower(column(\"elem\")) == val)\n            )\n            conditions.append(exists(subq))\n        return and_(*conditions)\n\n    def _array_contains_any(self, array_field, values):\n        \"\"\"\n        array overlap check (ANY must match)\n        \"\"\"\n        lowered_values = [val.lower() for val in values]\n\n        # Unnest the array, compare each element in a simple WHERE condition\n        subq = (\n            select(literal(1))\n            .select_from(func.unnest(array_field).alias(\"elem\"))\n            .where(func.lower(column(\"elem\")).in_(lowered_values))\n        )\n        return exists(subq)\n\n    def to_select_query(self, type: T, with_for_update: bool = False) -> Select[Tuple]:\n        \"\"\"\n        convert the filter to a select query\n\n        Args:\n            type (T): the type of the object (one derived from GulpCollabBase)\n\n        Returns:\n            Select[Tuple]: the select query\n        \"\"\"\n        q: Select = select(type)\n        if self.ids:\n            q = q.filter(self._case_insensitive_or_ilike(type.id, self.ids))\n        if self.types:\n            # match if equal to any in the list\n            q = q.filter(type.type.in_(self.types))\n        if self.operation_ids and \"operation_id\" in type.columns:\n            q = q.filter(\n                self._case_insensitive_or_ilike(type.operation_id, self.operation_ids)\n            )\n        if self.context_ids and \"context_id\" in type.columns:\n            q = q.filter(\n                self._case_insensitive_or_ilike(type.context_id, self.context_ids)\n            )\n        if self.source_ids and \"source_id\" in type.columns:\n            q = q.filter(\n                self._case_insensitive_or_ilike(type.source_id, self.source_ids)\n            )\n        if self.owner_user_ids and \"owner_user_id\" in type.columns:\n            q = q = q.filter(\n                self._case_insensitive_or_ilike(type.owner_user_id, self.owner_user_ids)\n            )\n\n        if self.tags and \"tags\" in type.columns:\n            lower_tags = [tag.lower() for tag in self.tags]\n            if self.tags_and:\n                # all tags must match (CONTAINS operator)\n                q = q.filter(self._array_contains_all(type.tags, lower_tags))\n            else:\n                # at least one tag must match (OVERLAP operator)\n                q = q.filter(self._array_contains_any(type.tags, lower_tags))\n\n        if self.names and \"name\" in type.columns:\n            q = q.filter(self._case_insensitive_or_ilike(type.name, self.names))\n        if self.texts and \"text\" in type.columns:\n            q = q.filter(self._case_insensitive_or_ilike(type.text, self.texts))\n\n        if self.model_extra:\n            # Handle granted_user_ids and granted_group_ids as special case first\n            granted_user_ids = self.model_extra.pop(\"granted_user_ids\", None)\n            granted_group_ids = self.model_extra.pop(\"granted_user_group_ids\", None)\n\n            if granted_user_ids or granted_group_ids:\n                # match only objects with the defined granted_user_ids or granted_group_ids\n                conditions = []\n                if granted_user_ids:\n                    conditions.append(type.granted_user_ids.op(\"&&\")(granted_user_ids))\n\n                    # append condition that the column is empty or an empty array, as OR\n                    conditions.append(type.granted_user_ids is None)\n                    conditions.append(type.granted_user_ids == [])\n                if granted_group_ids:\n                    conditions.append(\n                        type.granted_user_group_ids.op(\"&&\")(granted_group_ids)\n                    )\n\n                    # append condition that the column is empty or an empty array, as OR\n                    conditions.append(type.granted_user_group_ids is None)\n                    conditions.append(type.granted_user_group_ids == [])\n\n                # Combine with OR\n                if conditions:\n                    q = q.filter(or_(*conditions))\n\n            # Process remaining model_extra fields\n            for k, v in self.model_extra.items():\n                if hasattr(type, k):\n                    column = getattr(type, k)\n                    # check if column type is ARRAY using SQLAlchemy's inspection\n                    is_array = isinstance(getattr(column, \"type\", None), ARRAY)\n                    if is_array:\n                        q = q.filter(self._array_contains_any(column, v))\n                    else:\n                        q = q.filter(self._case_insensitive_or_ilike(column, v))\n\n        if self.doc_ids and \"doc_ids\" in type.columns:\n            # return all collab objects that have at least one document with _id in doc_ids\n            q = q.filter(type.doc_ids.op(\"&&\")(self.doc_ids))\n\n        if self.time_pin_range and \"time_pin\" in type.columns:\n            # returns all collab objects that have time_pin in time_pin_range\n            if self.time_pin_range[0]:\n                q = q.where(type.time_pin >= self.time_pin_range[0])\n            if self.time_pin_range[1]:\n                q = q.where(type.time_pin <= self.time_pin_range[1])\n\n        if self.doc_ids and \"docs\" in type.columns:\n            # returns all collab objects that have at least one document with _id in doc_ids\n            conditions = []\n            for doc_id in self.doc_ids:\n                # check if any document in the array has _id matching doc_id\n                # using -> to navigate JSONB array and ->> to extract text\n                conditions.append(\n                    text(\n                        \"\"\"EXISTS (\n                        SELECT 1 FROM unnest(docs) AS doc\n                        WHERE doc->>'_id'::text = :doc_id\n                    )\"\"\"\n                    ).bindparams(doc_id=doc_id.lower())\n                )\n            q = q.filter(or_(*conditions))\n        if self.doc_time_range and \"docs\" in type.columns:\n            # returns all collab objects that have at least one document with gulp.timestamp in doc_time_range\n            conditions = []\n            if self.doc_time_range[0]:\n                conditions.append(\n                    text(\n                        \"\"\"EXISTS (\n                        SELECT 1 FROM unnest(docs) AS doc\n                        WHERE CAST(doc->>'gulp.timestamp' AS BIGINT) >= :start_time\n                    )\"\"\"\n                    ).bindparams(start_time=self.doc_time_range[0])\n                )\n            if self.doc_time_range[1]:\n                conditions.append(\n                    text(\n                        \"\"\"EXISTS (\n                        SELECT 1 FROM unnest(docs) AS doc\n                        WHERE CAST(doc->>'gulp.timestamp' AS BIGINT) <= :end_time\n                    )\"\"\"\n                    ).bindparams(end_time=self.doc_time_range[1])\n                )\n            q = q.filter(and_(*conditions))\n\n        # add sort\n        if not self.sort:\n            # default, time_created ASC, id ASC\n            order_clauses = [\n                type.time_created.asc(),\n                type.id.asc(),\n            ]\n        else:\n            order_clauses = []\n            for field, direction in self.sort:\n                if direction == GulpSortOrder.ASC:\n                    order_clauses.append(getattr(type, field).asc())\n                else:\n                    order_clauses.append(getattr(type, field).desc())\n        q = q.order_by(*order_clauses)\n\n        if self.limit:\n            q = q.limit(self.limit)\n        if self.offset:\n            q = q.offset(self.offset)\n\n        if with_for_update:\n            q = q.with_for_update()\n        # MutyLogger.get_instance().debug(f\"to_select_query: {q}\")\n        return q\n\n\nclass GulpCollabBase(DeclarativeBase, MappedAsDataclass, AsyncAttrs, SerializeMixin):\n    \"\"\"\n    base for everything on the collab database\n    \"\"\"\n\n    __abstract__ = True\n\n    id: Mapped[str] = mapped_column(\n        String,\n        primary_key=True,\n        unique=True,\n        doc=\"The unque id/name of the object.\",\n    )\n    type: Mapped[GulpCollabType] = mapped_column(\n        SqlEnum(GulpCollabType), doc=\"The type of the object.\"\n    )\n    owner_user_id: Mapped[str] = mapped_column(\n        ForeignKey(\"user.id\", ondelete=\"CASCADE\"),\n        doc=\"The id of the user who created the object.\",\n    )\n    granted_user_ids: Mapped[Optional[list[str]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(String)),\n        doc=\"The ids of the users who have been granted access to the object. if not set(default), all objects have access.\",\n    )\n    granted_user_group_ids: Mapped[Optional[list[str]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(String)),\n        doc=\"The ids of the user groups who have been granted access to the object. if not set(default), all groups have access.\",\n    )\n    time_created: Mapped[Optional[int]] = mapped_column(\n        BIGINT,\n        doc=\"The time the object was created, in milliseconds from unix epoch.\",\n    )\n    time_updated: Mapped[Optional[int]] = mapped_column(\n        BIGINT,\n        doc=\"The time the object was last updated, in milliseconds from unix epoch.\",\n    )\n    glyph_id: Mapped[Optional[str]] = mapped_column(\n        ForeignKey(\"glyph.id\", ondelete=\"SET NULL\"), doc=\"The glyph ID.\"\n    )\n    name: Mapped[Optional[str]] = mapped_column(\n        String, doc=\"The display name of the object.\"\n    )\n    description: Mapped[Optional[str]] = mapped_column(\n        String, doc=\"The description of the object.\"\n    )\n\n    __mapper_args__ = {\n        \"polymorphic_identity\": \"collab_base\",\n        \"polymorphic_on\": type,\n    }\n\n    @classmethod\n    def example(cls) -> dict:\n        \"\"\"\n        builds example of the model\n\n        Returns:\n            dict: the model example\n        \"\"\"\n        return {\n            \"id\": \"id1\",\n            \"type\": cls.__tablename__,\n            \"owner_user_id\": \"admin\",\n            \"granted_user_ids\": [\"user1\"],\n            \"granted_user_group_ids\": [\"group1\"],\n            \"time_created\": 1620000000000000000,\n            \"time_updated\": 1620000000000000001,\n            \"glyph_id\": \"glyph_id\",\n            \"name\": \"the object display name\",\n            \"description\": \"object description\",\n        }\n\n    def __init_subclass__(\n        cls, type: GulpCollabType | str, abstract: bool = False, **kwargs\n    ) -> None:\n        \"\"\"\n        this is called automatically when a subclass is created, before __init__ on the instance is called\n\n        Args:\n            type (GulpCollabType|str): The type of the object.\n            abstract (bool): If True, the class is abstract\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        # print(f\"__init_subclass__: cls={cls}, type={type}, abstract={abstract}, kwargs={kwargs}\")\n\n        cls.__gulp_collab_type__ = type\n\n        if abstract:\n            # this is an abstract class\n            cls.__abstract__ = True\n        else:\n            # set table name based on type\n            cls.__tablename__ = str(type)\n\n        cls.__mapper_args__ = {\n            \"polymorphic_identity\": str(type),\n        }\n\n        # print(\"type=%s, cls.__name__=%s, abstract=%r, cls.__abstract__=%r, cls.__mapper_args__=%s\" % (cls.__gulp_collab_type__, cls.__name__, abstract, cls.__abstract__, cls.__mapper_args__))\n        super().__init_subclass__(**kwargs)\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Initialize the object with the specified attributes.\n        \"\"\"\n        # MutyLogger.get_instance().debug(\"**** GulpCollabBase __init__\")\n        if self.__class__ == GulpCollabBase:\n            # cannot instantiate this class directly\n            raise Exception(\n                \"GulpCollabBase is an abstract class and cannot be instantiated directly.\"\n            )\n\n        # call the base class constructor\n        # MutyLogger.get_instance().debug(\"---> GulpCollabBase self in __init__=%s\" % self)\n        super().__init__()\n\n    @override\n    def to_dict(\n        self,\n        nested: bool = False,\n        hybrid_attributes: bool = False,\n        exclude: List[str] | None = None,\n        exclude_none: bool = False,\n    ) -> dict:\n        # same as super.to_dict() but with exclude_none parameter\n        d = super().to_dict(nested, hybrid_attributes, exclude)\n        if not exclude_none:\n            return d\n\n        return {k: v for k, v in d.items() if v is not None}\n\n    @staticmethod\n    def _create_retry_decorator():\n        # retry logic for database operations\n        return retry(\n            retry=retry_if_exception_type(OperationalError),\n            stop=stop_after_attempt(3),\n            wait=wait_exponential(multiplier=1, min=4, max=10),\n            reraise=True,\n        )\n\n    @classmethod\n    async def release_advisory_lock(cls, sess: AsyncSession, lock_id: int) -> None:\n        \"\"\"\n        release an advisory lock\n\n        Args:\n            session (AsyncSession): The database session to use.\n            lock_id (int): The lock ID to release.\n        \"\"\"\n        await sess.execute(\n            text(\"SELECT pg_advisory_unlock(:lock_id)\"), {\"lock_id\": lock_id}\n        )\n\n    @staticmethod\n    @_create_retry_decorator()\n    async def acquire_advisory_lock(sess: AsyncSession, lock_id: int) -> None:\n        \"\"\"\n        Acquire an advisory lock, with retry logic.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            lock_id (int): The lock ID to acquire.\n        \"\"\"\n        try:\n            await sess.execute(\n                text(\"SELECT pg_advisory_xact_lock(:lock_id)\"), {\"lock_id\": lock_id}\n            )\n        except OperationalError as e:\n            # Log the error\n            MutyLogger.get_instance().error(f\"Failed to acquire advisory lock: {e}\")\n            raise\n\n    @classmethod\n    def _build_relationship_loading_options(\n        cls, recursive: bool = False, seen: set = None\n    ) -> list:\n        \"\"\"\n        build query options for eager loading relationships.\n\n        Args:\n            recursive (bool): whether to load nested relationships recursively\n            seen (set): set of classes already seen to prevent circular dependencies\n\n        Returns:\n            list: the list of loading options\n        \"\"\"\n        from sqlalchemy.orm import selectinload\n\n        if seen is None:\n            seen = set()\n\n        if cls in seen:\n            # prevent circular dependencies\n            return []\n\n        seen.add(cls)\n\n        if recursive:\n            options = []\n            for rel in inspect(cls).relationships:\n                # add direct relationship\n                load_opt = selectinload(getattr(cls, rel.key))\n                options.append(load_opt)\n\n                # add nested relationships\n                target_class = rel.mapper.class_\n                nested_opts = target_class._build_relationship_loading_options(\n                    recursive=True, seen=seen\n                )\n                for nested_opt in nested_opts:\n                    options.append(load_opt.selectinload(nested_opt))\n            return options\n        else:\n            # direct relationships only\n            return [\n                selectinload(getattr(cls, rel.key))\n                for rel in inspect(cls).relationships\n            ]\n\n    @classmethod\n    def _process_grants(\n        cls, object_data: dict, owner_id: str, private: bool\n    ) -> tuple[list[str], list[str]]:\n        \"\"\"\n        process user and group grants from object data.\n        \n        Args:\n            object_data (dict): the object data containing grants.\n            owner_id (str): the owner user ID.\n            private (bool): whether the object is private.\n            \n        Returns:\n            tuple[list[str], list[str]]: tuple of (user_grants, group_grants)\n        \"\"\"\n        # extract grants from object data\n        granted_user_ids = object_data.get(\"granted_user_ids\", [])\n        granted_user_group_ids = object_data.get(\"granted_user_group_ids\", [])\n        \n        # determine final user grants\n        if granted_user_ids:\n            user_grants = granted_user_ids\n        elif private:\n            user_grants = [owner_id]  # private object, owner only\n        else:\n            user_grants = []  # public object\n        \n        # determine final group grants\n        if granted_user_group_ids:\n            group_grants = granted_user_group_ids\n        else:\n            group_grants = []\n        \n        return user_grants, group_grants\n\n    @classmethod\n    def build_base_object_dict(\n        cls, object_data: dict, owner_id: str, id: str = None, private: bool = True\n    ) -> dict:\n        \"\"\"\n        build a dictionary to create a new base object\n\n        Args:\n            object_data (dict): The data to create the object with.\n            owner_id (str): The ID of the user creating the object\n            id (str, optional): The ID of the object to create. Defaults to None (generate a unique ID).\n            private (bool, optional): If True, the object is private (streamed only to ws_id websocket). Defaults to False.\n\n        Returns:\n            dict: The dictionary to create the object with\n        \"\"\"\n        if not id:\n            # generate a unique ID if not provided or None\n            id = muty.string.generate_unique()\n        else:\n            # check id is a valid string for a primary key (not having spaces, ...)\n            if \" \" in id or not re.match(r\"^[a-zA-Z0-9_\\-@\\.]+$\", id):\n                raise ValueError(f\"invalid id: {id}\")\n\n        # set the time created\n        time_created = muty.time.now_msec()\n\n        # remove None values\n        obj: dict = {k: v for k, v in object_data.items() if v is not None}\n\n        obj[\"type\"] = cls.__gulp_collab_type__\n        obj[\"id\"] = id\n        obj[\"time_created\"] = time_created\n        obj[\"time_updated\"] = time_created\n        obj[\"owner_user_id\"] = owner_id\n\n        # set user and group grants\n        user_grants, group_grants = cls._process_grants(object_data, owner_id, private)\n        obj[\"granted_user_ids\"] = user_grants\n        obj[\"granted_user_group_ids\"] = group_grants\n\n        if not obj.get(\"name\", None):\n            # set the name to the id if not provided\n            obj[\"name\"] = id\n        return obj\n\n    @classmethod\n    async def _create_instance(cls, sess: AsyncSession, object_dict: dict) -> T:\n        \"\"\"\n        creates an instance in the database from a prepared dictionary.\n\n        Args:\n            sess (AsyncSession): the database session to use.\n            object_dict (dict): the prepared dictionary with all required fields.\n\n        Returns:\n            T: the created instance.\n        \"\"\"\n        # create select statement with eager loading\n        # MutyLogger.get_instance().debug(f\"creating instance of {cls.__name__}, base object dict: {object_dict}\")\n        stmt = (\n            select(cls)\n            .options(*cls._build_relationship_loading_options())\n            .from_statement(insert(cls).values(**object_dict).returning(cls))\n        )\n\n        result = await sess.execute(stmt)\n        instance: GulpCollabBase = result.scalar_one()\n        await sess.commit()\n        return instance\n\n    @classmethod\n    async def _send_ws_notification(\n        cls,\n        instance: T,\n        ws_id: str,\n        user_id: str,\n        ws_queue_datatype: \"GulpWsQueueDataType\" = None,\n        ws_data: dict = None,\n        object_data: dict = None,\n        req_id: str = None,\n        private: bool = True,\n    ) -> None:\n        \"\"\"\n        sends websocket notification about an object creation or update.\n\n        Args:\n            instance (T): the instance that was created or updated.\n            ws_id (str): the websocket ID.\n            user_id (str): the user ID.\n            ws_queue_datatype (GulpWsQueueDataType, optional): the type of websocket data. defaults to COLLAB_UPDATE.\n            ws_data (dict, optional): custom data to send. defaults to None.\n            object_data (dict, optional): original object data. defaults to None.\n            req_id (str, optional): request ID. defaults to None.\n            private (bool, optional): if True, the notification is private. defaults to True.\n        \"\"\"\n        from gulp.api.ws_api import (\n            GulpCollabCreateUpdatePacket,\n            GulpWsQueueDataType,\n            GulpWsSharedQueue,\n        )\n\n        if not ws_queue_datatype:\n            ws_queue_datatype = GulpWsQueueDataType.COLLAB_UPDATE\n\n        # use provided data or serialize the instance\n        if ws_data:\n            data = ws_data\n        else:\n            data = instance.to_dict(nested=True, exclude_none=True)\n\n        p = GulpCollabCreateUpdatePacket(data=data, created=True)\n        GulpWsSharedQueue.get_instance().put(\n            ws_queue_datatype,\n            ws_id=ws_id,\n            user_id=user_id,\n            operation_id=object_data.get(\"operation_id\", None) if object_data else None,\n            req_id=req_id,\n            data=p.model_dump(exclude_none=True, exclude_defaults=True),\n            private=private,\n        )\n\n    @classmethod\n    async def _create(\n        cls,\n        sess: AsyncSession,\n        object_data: dict,\n        id: str = None,\n        ws_id: str = None,\n        owner_id: str = None,\n        ws_queue_datatype: \"GulpWsQueueDataType\" = None,\n        ws_data: dict = None,\n        req_id: str = None,\n        private: bool = True,\n    ) -> T:\n        \"\"\"\n        Asynchronously creates and stores an instance of the class, also updating the websocket if required.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            object_data (dict): The data to create the object with.\n            id (str, optional): The ID of the object to create. Defaults to None (generate a unique ID).\n            operation_id (str, optional): The ID of the operation associated with the instance. Defaults to None.\n            ws_id (str, optional): WebSocket ID associated with the instance. Defaults to None.\n            owner_id (str, optional): The user to be set as the owner of the object. Defaults to None(\"admin\" user will be set).\n            ws_queue_datatype (GulpWsQueueDataType, optional): The type of the websocket queue data. Defaults to GulpWsQueueDataType.COLLAB_UPDATE.\n            ws_data (dict, optional): data to send to the websocket. Defaults to the created object.\n            req_id (str, optional): Request ID associated with the instance. Defaults to None.\n            private (bool, optional): If True, the object is private (streamed only to ws_id websocket). Defaults to True.\n        Returns:\n            T: The created instance of the class.\n        Raises:\n            Exception: If there is an error during the creation or storage process.\n        \"\"\"\n        object_data = object_data or {}\n        owner_id = owner_id or \"admin\"\n\n        # build object dictionary with necessary attributes\n        d = cls.build_base_object_dict(\n            object_data, owner_id=owner_id, id=id, private=private\n        )\n\n        # create object with eager loading\n        instance: GulpCollabBase = await cls._create_instance(sess, d)\n        if ws_id:\n            await cls._send_ws_notification(\n                instance,\n                ws_id,\n                owner_id,\n                ws_queue_datatype,\n                ws_data,\n                object_data,\n                req_id,\n                private,\n            )\n\n        # MutyLogger.get_instance().debug(f\"created instance: {instance.to_dict(nested=True, exclude_none=True)}\")\n        return instance\n\n    async def add_default_grants(self, sess: AsyncSession):\n        \"\"\"\n        shortcut to add default user and groups grants to the object\n\n        NOTE: should be used only when resetting the database.\n\n        Args:\n            sess (AsyncSession): The session to use.\n        \"\"\"\n        # add user grants\n        await self.add_user_grant(sess, \"ingest\")\n        await self.add_user_grant(sess, \"admin\")\n        await self.add_user_grant(sess, \"editor\")\n        await self.add_user_grant(sess, \"power\")\n        await self.add_user_grant(sess, \"guest\")\n\n        # add group grants\n        from gulp.api.collab.user_group import ADMINISTRATORS_GROUP_ID\n\n        await self.add_group_grant(sess, ADMINISTRATORS_GROUP_ID)\n\n    async def add_group_grant(self, sess: AsyncSession, group_id: str) -> None:\n        \"\"\"\n        grant a user group access to the object\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            group_id (str): The ID of the user group to add.\n        Returns:\n            None\n        \"\"\"\n        if group_id not in self.granted_user_group_ids:\n            MutyLogger.get_instance().info(\n                \"Adding granted user group %s to object %s\" % (group_id, self.id)\n            )\n            self.granted_user_group_ids.append(group_id)\n            await sess.commit()\n            await sess.refresh(self)\n        else:\n            MutyLogger.get_instance().warning(\n                \"User group %s already granted on object %s\" % (group_id, self.id)\n            )\n\n    async def remove_group_grant(self, sess: AsyncSession, group_id: str) -> None:\n        \"\"\"\n        remove a user group access to the object\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            group_id (str): The ID of the user group to remove.\n        Returns:\n            None\n        \"\"\"\n        if group_id in self.granted_user_group_ids:\n            self.granted_user_group_ids.remove(group_id)\n            await sess.commit()\n            await sess.refresh(self)\n            MutyLogger.get_instance().info(\n                \"Removed granted user group %s from object %s\" % (group_id, self.id)\n            )\n        else:\n            MutyLogger.get_instance().warning(\n                \"User group %s not in granted list on object %s\" % (group_id, self.id)\n            )\n\n    async def add_user_grant(self, sess: AsyncSession, user_id: str) -> None:\n        \"\"\"\n        grant a user access to the object\n\n        Args:\n            sess (AsyncSession): The session to use for the query.\n            user_id (str): The ID of the user to add.\n        Returns:\n            None\n        \"\"\"\n        if user_id not in self.granted_user_ids:\n            MutyLogger.get_instance().info(\n                \"Adding granted user %s to object %s\" % (user_id, self.id)\n            )\n            self.granted_user_ids.append(user_id)\n            await sess.commit()\n            await sess.refresh(self)\n        else:\n            MutyLogger.get_instance().warning(\n                \"User %s already granted on object %s\" % (user_id, self.id)\n            )\n\n    async def remove_user_grant(self, sess: AsyncSession, user_id: str) -> None:\n        \"\"\"\n        remove a user access to the object\n\n        Args:\n            sess (AsyncSession): The session to use for the query.\n            user_id (str): The ID of the user to remove.\n        Returns:\n            None\n        \"\"\"\n        if user_id in self.granted_user_ids:\n            self.granted_user_ids.remove(user_id)\n            await sess.commit()\n            await sess.refresh(self)\n            MutyLogger.get_instance().info(\n                \"Removed granted user %s from object %s\" % (user_id, self.id)\n            )\n        else:\n            MutyLogger.get_instance().warning(\n                \"User %s not in granted list on object %s\" % (user_id, self.id)\n            )\n\n    async def delete(\n        self,\n        sess: AsyncSession,\n        ws_id: str = None,\n        user_id: str = None,\n        ws_queue_datatype: \"GulpWsQueueDataType\" = None,\n        ws_data: dict = None,\n        req_id: str = None,\n    ) -> None:\n        \"\"\"\n        deletes the object, also updating the websocket if required.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            ws_id (str, optional): The ID of the websocket connection. Defaults to None.\n            user_id (str, optional): The ID of the user making the request. Defaults to None.\n            ws_queue_datatype (GulpWsQueueDataType, optional): The type of the websocket queue data. Defaults to GulpWsQueueDataType.COLLAB_DELETE.\n            ws_data (dict, optional): data to send to the websocket. Defaults to GulpDeleteCollabPacket.\n            req_id (str, optional): The ID of the request. Defaults to None.\n        Raises:\n            ObjectNotFoundError: If throw_if_not_found is True and the object does not exist.\n        Returns:\n            None\n        \"\"\"\n        # query to get the instance\n        stmt = select(self.__class__).filter(self.__class__.id == self.id)\n        result = await sess.execute(stmt)\n        instance = result.scalar_one()\n        await sess.delete(instance)\n        await sess.commit()\n\n        if ws_id:\n            from gulp.api.ws_api import (\n                GulpCollabDeletePacket,\n                GulpWsQueueDataType,\n                GulpWsSharedQueue,\n            )\n\n            if not ws_queue_datatype:\n                ws_queue_datatype = GulpWsQueueDataType.COLLAB_DELETE\n\n            # notify the websocket of the deletion\n            if ws_data:\n                data = ws_data\n            else:\n                p: GulpCollabDeletePacket = GulpCollabDeletePacket(id=self.id)\n                data = p.model_dump()\n            GulpWsSharedQueue.get_instance().put(\n                type=ws_queue_datatype,\n                ws_id=ws_id,\n                user_id=user_id,\n                operation_id=getattr(self, \"operation_id\", None),\n                req_id=req_id,\n                data=data,\n            )\n\n    def is_owner(self, user_id: str) -> bool:\n        \"\"\"\n        check if the user is the owner of the object\n\n        Args:\n            user_id (str): The ID of the user to check.\n        Returns:\n            bool: True if the user is the owner, False otherwise.\n        \"\"\"\n        return self.owner_user_id == user_id\n\n    def is_granted_user(self, user_id: str) -> bool:\n        \"\"\"\n        check if the user is granted access to the object\n\n        Args:\n            user_id (str): The ID of the user to check.\n        Returns:\n            bool: True if the user is granted access, False otherwise.\n        \"\"\"\n        return user_id in self.granted_user_ids\n\n    def is_granted_group(self, group_id: str) -> bool:\n        \"\"\"\n        check if the user group is granted access to the object\n\n        Args:\n            group_id (str): The ID of the user group to check.\n        Returns:\n            bool: True if the user group is granted access, False otherwise.\n        \"\"\"\n        return group_id in self.granted_user_group_ids\n\n    def is_private(self) -> bool:\n        \"\"\"\n        check if the object is private (only the owner or admin can see it)\n\n        Returns:\n            bool: True if the object is private, False otherwise.\n        \"\"\"\n        # private object = only owner or admin can see it\n        if (\n            self.granted_user_ids\n            and len(self.granted_user_ids) == 1\n            and self.granted_user_ids[0] == self.owner_user_id\n            and not self.granted_user_group_ids\n        ):\n            return True\n        return False\n\n    async def make_private(self, sess: AsyncSession) -> None:\n        \"\"\"\n        make the object private (only the owner or admin can see it)\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            user_id (str): The ID of the user making the request.\n        Returns:\n            None\n        \"\"\"\n\n        # private object = only owner or admin can see it\n        self.granted_user_ids = [self.owner_user_id]\n        self.granted_user_group_ids = []\n        await sess.commit()\n        await sess.refresh(self)\n        MutyLogger.get_instance().info(\n            \"object %s is now PRIVATE to user %s\" % (self.id, self.owner_user_id)\n        )\n\n    async def make_public(self, sess: AsyncSession) -> None:\n        \"\"\"\n        make the object public\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            user_id (str): The ID of the user making the request.\n        Returns:\n            None\n        \"\"\"\n        # clear all granted users and groups\n        self.granted_user_group_ids = []\n        self.granted_user_ids = []\n        await sess.commit()\n        await sess.refresh(self)\n        MutyLogger.get_instance().info(\"Object %s is now PUBLIC\" % (self.id))\n\n    @staticmethod\n    def object_type_to_class(collab_type: GulpCollabType) -> T:\n        \"\"\"\n        get the class of the given type\n\n        Args:\n            collab_type (GulpCollabType): The type of the object.\n        Returns:\n            Type: The class of the object.\n\n        Raises:\n            ValueError: If the class is not found.\n        \"\"\"\n        subclasses = GulpCollabBase.__subclasses__()\n        subclasses.extend(GulpCollabObject.__subclasses__())\n        for cls in subclasses:\n            if cls.__gulp_collab_type__ == collab_type:\n                return cls\n        raise ValueError(f\"no class found for type {collab_type}\")\n\n    async def update(\n        self,\n        sess: AsyncSession,\n        d: dict,\n        ws_id: str = None,\n        user_id: str = None,\n        ws_queue_datatype: \"GulpWsQueueDataType\" = None,\n        ws_data: dict = None,\n        req_id: str = None,\n        updated_instance: T = None,\n    ) -> None:\n        \"\"\"\n        updates the object, also updating the websocket if required.\n\n        Args:\n            sess (AsyncSession): The database session to use: the session will be committed and refreshed after the update.\n            d (dict): A dictionary containing the fields to update and their new values, must be None and is ignored if updated_instance is provided.\n            ws_id (str, optional): The ID of the websocket connection. Defaults to None.\n            user_id (str, optional): The ID of the user making the request. Defaults to None.\n            ws_queue_datatype (GulpWsQueueDataType, optional): The type of the websocket queue data. Defaults to GulpWsQueueDataType.COLLAB_UPDATE.\n            ws_data (dict, optional): data to send to the websocket. Defaults to the updated object.\n            req_id (str, optional): The ID of the request. Defaults to None.\n            updated_instance (T, optional): An already updated instance of the object, if set d is ignored. Defaults to None.\n        \"\"\"\n        if updated_instance:\n            # use updated_instance if provided\n            instance = updated_instance\n        else:\n            # use dict, query our instance with lock\n            stmt = (\n                select(self.__class__)\n                .filter(self.__class__.id == self.id)\n                .options(selectinload(\"*\"))\n                .with_for_update()\n            )\n            result = await sess.execute(stmt)\n            instance: GulpCollabBase = result.scalar_one()\n\n            # update instance from d, ensure d has no 'id' (the id cannot be updated)\n            d.pop(\"id\", None)\n            for k, v in d.items():\n                # only update if the value is not None and different from the current value\n                if v is not None and getattr(instance, k, None) != v:\n                    # MutyLogger.get_instance().debug(f\"setattr: {k}={v}\")\n                    setattr(instance, k, v)\n\n        # update time\n        instance.time_updated = muty.time.now_msec()\n        updated_dict = instance.to_dict(nested=True, exclude_none=True)\n        private = instance.is_private()\n\n        # commit\n        await sess.commit()\n\n        MutyLogger.get_instance().debug(\"---> updated: %s\" % (updated_dict))\n\n        if ws_id:\n            from gulp.api.ws_api import (\n                GulpCollabCreateUpdatePacket,\n                GulpWsQueueDataType,\n                GulpWsSharedQueue,\n            )\n\n            if not ws_queue_datatype:\n                ws_queue_datatype = GulpWsQueueDataType.COLLAB_UPDATE\n\n            # notify the websocket of the collab object update\n            if ws_data:\n                data = ws_data\n            else:\n                data = updated_dict\n                p = GulpCollabCreateUpdatePacket(data=data)\n            GulpWsSharedQueue.get_instance().put(\n                type=ws_queue_datatype,\n                ws_id=ws_id,\n                user_id=user_id,\n                operation_id=data.get(\"operation_id\", None),\n                req_id=req_id,\n                data=p.model_dump(exclude_none=True, exclude_defaults=True),\n                private=private,\n            )\n\n    @classmethod\n    async def get_by_id(\n        cls,\n        sess: AsyncSession,\n        id: str,\n        throw_if_not_found: bool = True,\n        with_for_update: bool = False,\n        recursive: bool = False,\n    ) -> T:\n        \"\"\"\n        Asynchronously retrieves an object of the class type with the specified ID.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            id (str): The ID of the object to retrieve.\n            throw_if_not_found (bool, optional): If True, raises an exception if the object is not found. Defaults to True.\n            with_for_update (bool, optional): If True, the query will be executed with the FOR UPDATE clause (lock). Defaults to False.\n            recursive (bool, optional): If True, loads nested relationships recursively. Defaults to False.\n        Returns:\n            T: The object with the specified ID or None if not found.\n        Raises:\n            ObjectNotFound: If the object with the specified ID is not found.\n        \"\"\"\n        loading_options = cls._build_relationship_loading_options(recursive=recursive)\n\n        stmt = select(cls).options(*loading_options).filter(cls.id == id)\n        if with_for_update:\n            stmt = stmt.with_for_update()\n        res = await sess.execute(stmt)\n        c = res.scalar_one_or_none()\n        if not c and throw_if_not_found:\n            raise ObjectNotFound(f'{cls.__name__} with id \"{id}\" not found')\n\n        return c\n\n    @classmethod\n    async def get_by_filter(\n        cls,\n        sess: AsyncSession,\n        flt: GulpCollabFilter = None,\n        throw_if_not_found: bool = True,\n        with_for_update: bool = False,\n        user_id: str = None,\n        user_id_is_admin: bool = False,\n        user_group_ids: list[str] = None,\n        recursive: bool = False,\n    ) -> list[T]:\n        \"\"\"\n        Asynchronously retrieves a list of objects based on the provided filter.\n        Args:\n            sess (AsyncSession): The database session to use.\n            flt (GulpCollabFilter, optional): The filter to apply to the query. Defaults to None (all objects).\n            throw_if_not_found (bool, optional): If True, raises an exception if no objects are found. Defaults to True.\n            with_for_update (bool, optional): If True, the query will be executed with the FOR UPDATE clause (lock). Defaults to False.\n            user_id (str, optional): if set, only return objects that the user has access to.\n            user_id_is_admin (bool, optional): If True, the user is an admin (has access to all objects). Defaults to False.\n            user_group_ids (list[str], optional): The IDs of the groups the user belongs to. Defaults to None.\n            recursive (bool, optional): If True, loads nested relationships recursively. Defaults to False.\n        Returns:\n            list[T]: A list of objects that match the filter criteria.\n        Raises:\n            Exception: If there is an error during the query execution or result processing.\n        \"\"\"\n\n        # filter or empty filter\n        flt = flt or GulpCollabFilter()\n\n        # build and run query (ensure eager loading)\n        if user_id_is_admin:\n            # admin must see all\n            flt.granted_user_ids = None\n            flt.granted_user_group_ids = None\n            flt.owner_user_ids = None\n        else:\n            # user can see only objects he has access to\n            flt.granted_user_ids = [user_id]\n            flt.granted_user_group_ids = user_group_ids or []\n\n        q = flt.to_select_query(cls, with_for_update=with_for_update)\n        q = q.options(*cls._build_relationship_loading_options(recursive=recursive))\n        MutyLogger.get_instance().debug(\n            \"get_by_filter, flt=%s, user_id=%s, query:\\n%s\" % (flt, user_id, q)\n        )\n        res = await sess.execute(q)\n        objects = res.scalars().all()\n        if not objects:\n            if throw_if_not_found:\n                raise ObjectNotFound(\n                    f\"No {cls.__name__} found with filter {flt}\", cls.__name__, str(flt)\n                )\n            else:\n                return []\n\n        # MutyLogger.get_instance().debug(\"user_id=%s, POST-filtered objects: %s\" % (user_id, objects))\n        return objects\n\n    @classmethod\n    async def get_first_by_filter(\n        cls,\n        sess: AsyncSession,\n        flt: GulpCollabFilter = None,\n        throw_if_not_found: bool = True,\n        with_for_update: bool = False,\n        user_id: str = None,\n        user_id_is_admin: bool = False,\n        user_group_ids: list[str] = None,\n        recursive: bool = False,\n    ) -> T:\n        \"\"\"\n        Asynchronously retrieves the first object based on the provided filter.\n\n        Args:\n            sess (AsyncSession): The database session to use.\n            flt (GulpCollabFilter, optional): The filter to apply to the query. Defaults to None (all objects).\n            throw_if_not_found (bool, optional): If True, raises an exception if no objects are found. Defaults to True.\n            with_for_update (bool, optional): If True, the query will be executed\n            user_id (str, optional): if set, only return objects that the user has access to.\n            user_id_is_admin (bool, optional): If True, the user is an admin (has access to all objects). Defaults to False.\n            user_group_ids (list[str], optional): The IDs of the groups the user belongs to. Defaults to None.\n            recursive (bool, optional): If True, loads nested relationships recursively. Defaults to False.\n\n        Returns:\n            T: The first object that matches the filter criteria or None if not found.\n        \"\"\"\n        obj = await cls.get_by_filter(\n            sess,\n            flt=flt,\n            throw_if_not_found=throw_if_not_found,\n            with_for_update=with_for_update,\n            user_id=user_id,\n            user_id_is_admin=user_id_is_admin,\n            user_group_ids=user_group_ids,\n            recursive=recursive,\n        )\n\n        if obj:\n            return obj[0]\n        return None\n\n    @classmethod\n    async def get_by_id_wrapper(\n        cls,\n        token: str,\n        id: str,\n        with_for_update: bool = False,\n        permission: list[GulpUserPermission] = [GulpUserPermission.READ],\n        nested: bool = False,\n        enforce_owner: bool = False,\n    ) -> dict:\n        \"\"\"\n        helper to get an object by ID, handling session and ACL check\n\n        Args:\n            token (str): The user token.\n            id (str): The ID of the object to get.\n            with_for_update (bool, optional): If True, the query will be executed with the FOR UPDATE clause (lock). Defaults to False.\n            permission (list[GulpUserPermission], optional): The permission required to read the object. Defaults to GulpUserPermission.READ.\n            nested (bool, optional): If True, nested relationships will be loaded. Defaults to False.\n            enforce_owner (bool, optional): If True, the user must be the owner of the object (or admin). Defaults to False.\n\n        Returns:\n            dict: The object as a dictionary\n\n        Raises:\n            MissingPermissionError: If the user does not have permission to read the object.\n            ObjectNotFound: If the object is not found.\n        \"\"\"\n        from gulp.api.collab.user_session import GulpUserSession\n        from gulp.api.collab_api import GulpCollab\n\n        async with GulpCollab.get_instance().session() as sess:\n            n: GulpCollabBase = await cls.get_by_id(\n                sess, id, with_for_update=with_for_update\n            )\n\n            # token needs at least read permission (or be the owner)\n            await GulpUserSession.check_token(\n                sess, token, permission=permission, obj=n, enforce_owner=enforce_owner\n            )\n            return n.to_dict(exclude_none=True, nested=nested)\n\n    @classmethod\n    async def get_by_filter_wrapper(\n        cls,\n        token: str,\n        flt: GulpCollabFilter,\n        permission: list[GulpUserPermission] = [GulpUserPermission.READ],\n        throw_if_not_found: bool = False,\n        nested: bool = False,\n    ) -> list[dict]:\n        \"\"\"\n        helper to get objects by filter, handling session and ACL check for each returned object (based on token permission)\n\n        Args:\n            token (str): The user token.\n            flt (GulpCollabFilter): The filter to apply to the query.\n            permission (list[GulpUserPermission], optional): The permission required to read the object. Defaults to GulpUserPermission.READ.\n            throw_if_not_found (bool, optional): If True, raises an exception if no objects are found. Defaults to False (return empty list).\n            nested (bool, optional): If True, nested relationships will be loaded. Defaults to False.\n        Returns:\n            list[dict]: The list of object dictionaries that match the filter criteria.\n        \"\"\"\n        from gulp.api.collab.user_session import GulpUserSession\n        from gulp.api.collab_api import GulpCollab\n\n        async with GulpCollab.get_instance().session() as sess:\n            # token needs at least read permission\n            s = await GulpUserSession.check_token(sess, token, permission=permission)\n            user_id = s.user_id\n            user_group_ids = [] if not s.user.groups else [g.id for g in s.user.groups]\n            is_admin = s.user.is_admin()\n            MutyLogger.get_instance().debug(\n                \"get_by_filter, user_id=%s, group_ids for the user=%s, is_admin=%r\"\n                % (s.user_id if s else None, user_group_ids, is_admin)\n            )\n\n            objs = await cls.get_by_filter(\n                sess,\n                flt,\n                throw_if_not_found=throw_if_not_found,\n                user_id=user_id,\n                user_id_is_admin=is_admin,\n                user_group_ids=user_group_ids,\n            )\n            if not objs:\n                return []\n\n            data = []\n            for o in objs:\n                data.append(o.to_dict(exclude_none=True, nested=nested))\n\n            MutyLogger.get_instance().debug(\n                \"User %s get_by_filter_result: %s\"\n                % (\n                    s.user.id,\n                    json.dumps(data, indent=2),\n                )\n            )\n\n            return data\n\n    @classmethod\n    async def delete_by_id(\n        cls,\n        token: str,\n        id: str,\n        ws_id: str,\n        req_id: str,\n        permission: list[GulpUserPermission] = [GulpUserPermission.DELETE],\n    ) -> None:\n        \"\"\"\n        helper to delete an object by ID, handling session and ACL check\n\n        Args:\n            token (str): The user token, pass None to skip token check.\n            id (str): The ID of the object to delete.\n            ws_id (str): The websocket ID, ignored if token is None\n            req_id (str): The request ID.\n            permission (list[GulpUserPermission], optional): The permission required to delete the object. Defaults to GulpUserPermission.DELETE.\n\n        Raises:\n            MissingPermissionError: If the user does not have permission to delete the object.\n            ObjectNotFoundError: If the object is not found.\n        \"\"\"\n        from gulp.api.collab.user_session import GulpUserSession\n        from gulp.api.collab_api import GulpCollab\n\n        async with GulpCollab.get_instance().session() as sess:\n            n: GulpCollabBase = await cls.get_by_id(sess, id, with_for_update=True)\n\n            if token:\n                # token needs at least delete permission (or be the owner)\n                s = await GulpUserSession.check_token(\n                    sess, token, permission=permission, obj=n\n                )\n                user_id = s.user_id\n            else:\n                user_id = None\n                ws_id = None\n\n            # delete\n            await n.delete(sess, ws_id=ws_id, user_id=user_id, req_id=req_id)\n\n    @classmethod\n    async def update_by_id(\n        cls,\n        token: str,\n        id: str,\n        ws_id: str,\n        req_id: str,\n        d: dict = None,\n        updated_instance: T = None,\n        permission: list[GulpUserPermission] = [GulpUserPermission.EDIT],\n    ) -> dict:\n        \"\"\"\n        helper to update an object by ID, handling session\n\n        Args:\n            token (str): The user token.\n            id (str): The ID of the object to update.\n            ws_id (str): The websocket ID.\n            req_id (str): The request ID.\n            d (dict, optional): The data to update the object with. Defaults to None.\n            updated_instance (T, optional): An already updated instance of the object. Defaults to None.\n            permission (list[GulpUserPermission], optional): The permission required to update the object. Defaults to GulpUserPermission.EDIT.\n\n        Returns:\n            dict: The updated object as a dictionary.\n\n        Raises:\n            ValueError: If both d and updated_instance are provided.\n            MissingPermissionError: If the user does not have permission to update the object.\n        \"\"\"\n        from gulp.api.collab.user_session import GulpUserSession\n        from gulp.api.collab_api import GulpCollab\n\n        async with GulpCollab.get_instance().session() as sess:\n            if d and updated_instance:\n                raise ValueError(\"only one of d or updated_instance should be provided\")\n\n            n: GulpCollabBase = await cls.get_by_id(sess, id, with_for_update=True)\n\n            # token needs at least edit permission (or be the owner)\n            s = await GulpUserSession.check_token(\n                sess, token, permission=permission, obj=n\n            )\n            await n.update(\n                sess,\n                d=d,\n                ws_id=ws_id,\n                user_id=s.user_id,\n                req_id=req_id,\n                updated_instance=updated_instance,\n            )\n            return n.to_dict(exclude_none=True)\n\n    @classmethod\n    async def create(\n        cls,\n        token: str,\n        ws_id: str,\n        req_id: str,\n        object_data: dict,\n        permission: list[GulpUserPermission] = [GulpUserPermission.EDIT],\n        id: str = None,\n        private: bool = True,\n        operation_id: str = None,\n    ) -> dict:\n        \"\"\"\n        helper to create a new object, handling session\n\n        Args:\n            token (str): The user token.\n            ws_id (str): The websocket ID: pass None to not notify the websocket.\n            req_id (str): The request ID.\n            object_data (dict): The data to create the object with.\n            permission (list[GulpUserPermission], optional): The permission required to create the object. Defaults to GulpUserPermission.EDIT.\n            id (str, optional): The ID of the object to create. Defaults to None (generate a unique ID).\n            private (bool, optional): If True, the object will be private. Defaults to False.\n            operation_id (str, optional): The ID of the operation associated with the object to be created: if set, it will be checked for permission. Defaults to None.\n        Returns:\n            dict: The created object as a dictionary.\n\n        Raises:\n            MissingPermissionError: If the user does not have permission to create the object.\n        \"\"\"\n        from gulp.api.collab.user_session import GulpUserSession\n        from gulp.api.collab_api import GulpCollab\n\n        async with GulpCollab.get_instance().session() as sess:\n            # check permission for creation\n            if operation_id:\n                # check permission on the operation\n                from gulp.api.collab.operation import GulpOperation\n\n                op: GulpOperation = await GulpOperation.get_by_id(sess, operation_id)\n                s = await GulpUserSession.check_token(\n                    sess, token, permission=permission, obj=op\n                )\n            else:\n                # just check token permission\n                s = await GulpUserSession.check_token(\n                    sess, token, permission=permission\n                )\n\n            n: GulpCollabBase = await cls._create(\n                sess,\n                object_data,\n                id=id,\n                owner_id=s.user_id,\n                ws_id=ws_id,\n                req_id=req_id,\n                private=private,\n            )\n            return n.to_dict(exclude_none=True)\n\n\nclass GulpCollabObject(\n    GulpCollabBase, type=GulpCollabType.GENERIC_OBJECT, abstract=True\n):\n    \"\"\"\n    base for all collaboration objects (notes, links, stories, highlights) related to an operation.\n\n    those objects are meant to be shared among users.\n    \"\"\"\n\n    operation_id: Mapped[str] = mapped_column(\n        ForeignKey(\n            \"operation.id\",\n            ondelete=\"CASCADE\",\n        ),\n        doc=\"The id of the operation associated with the object.\",\n    )\n    tags: Mapped[list[str]] = mapped_column(\n        MutableList.as_mutable(ARRAY(String)),\n        doc=\"The tags associated with the object.\",\n    )\n    color: Mapped[Optional[str]] = mapped_column(\n        String, doc=\"The color associated with the object.\"\n    )\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d.update(\n            {\n                \"operation_id\": \"op1\",\n                \"tags\": [\"tag1\", \"tag2\"],\n                \"color\": \"#FF0000\",\n            }\n        )\n        return d\n\n    @staticmethod\n    def build_dict(\n        operation_id: str,\n        tags: list[str] = None,\n        color: str = None,\n        **kwargs,\n    ) -> dict:\n        \"\"\"\n        build a dictionary to create a new collaboration object\n\n        Args:\n            operation_id (str): The ID of the operation associated with the object.\n            tags (list[str], optional): The tags associated with the object. Defaults to None.\n            color (str, optional): The color associated with the object. Defaults to None.\n            **kwargs: Any other additional keyword arguments to set as attributes on the instance, if any\n        Returns:\n            dict: The dictionary to create the object with.\n        \"\"\"\n        d = {\n            \"operation_id\": operation_id,\n            \"tags\": tags,\n            \"color\": color,\n        }\n        d.update(kwargs)\n        return d\n\n    @override\n    def __init__(self, *args, **kwargs):\n        if self.type == GulpCollabObject:\n            raise NotImplementedError(\n                \"GulpCollabObject is an abstract class and cannot be instantiated directly.\"\n            )\n        super().__init__(*args, **kwargs)\n        MutyLogger.get_instance().debug(\"---> GulpCollabObject: \" % (*args, kwargs))\n"}
{"type": "source_file", "path": "src/gulp/api/mapping/templates/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/mapping/__init__.py", "content": ""}
{"type": "source_file", "path": "src/gulp/api/opensearch/filters.py", "content": "from enum import IntEnum\nfrom typing import Optional, override\n\nfrom pydantic import BaseModel, ConfigDict, Field\n\nfrom gulp.api.rest.test_values import TEST_CONTEXT_ID, TEST_OPERATION_ID, TEST_SOURCE_ID\n\n# mandatory fields to be included in the result for queries\nQUERY_DEFAULT_FIELDS = [\n    \"_id\",\n    \"@timestamp\",\n    \"event.duration\",\n    \"event.code\",\n    \"gulp.timestamp\",\n    \"gulp.timestamp_invalid\",\n    \"gulp.operation_id\",\n    \"gulp.context_id\",\n    \"gulp.source_id\",\n    \"gulp.event_code\",\n]\n\n\nclass GulpBaseDocumentFilter(BaseModel):\n    \"\"\"\n    base class for Gulp filters acting on documents.\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"time_range\": [\n                        1551385571023173120,\n                        1551446406878338048,\n                    ],\n                    \"query_string_parameters\": {\n                        \"analyze_wildcard\": True,\n                        \"default_field\": \"_id\",\n                    },\n                }\n            ]\n        },\n    )\n\n    time_range: Optional[tuple[int, int]] = Field(\n        default=None,\n        description=\"\"\"\na tuple representing a `gulp.timestamp` range `[ start, end ]`.\n\n- `start` and `end` are nanoseconds from the unix epoch.\n\"\"\",\n    )\n\n    query_string_parameters: Optional[dict] = Field(\n        default=None,\n        description=\"\"\"\nadditional parameters to be applied to the resulting `query_string` query, according to [opensearch documentation](https://opensearch.org/docs/latest/query-dsl/full-text/query-string)\n\n\"\"\",\n    )\n\n    @override\n    def __str__(self) -> str:\n        return self.model_dump_json(exclude_none=True)\n\n\nclass GulpDocumentFilterResult(IntEnum):\n    \"\"\"wether if the event should be accepted or skipped during ingestion.\"\"\"\n\n    ACCEPT = 0\n    SKIP = 1\n\n\nclass GulpIngestionFilter(GulpBaseDocumentFilter):\n    \"\"\"\n    a GulpIngestionFilter defines a filter for the ingestion API.<br><br>\n\n    each field is optional, if no filter is specified all events are ingested.\n    \"\"\"\n\n    model_config = ConfigDict(\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"time_range\": [\n                        1551385571023173120,\n                        1551446406878338048,\n                    ],\n                    \"storage_ignore_filter\": False,\n                }\n            ]\n        }\n    )\n    storage_ignore_filter: Optional[bool] = Field(\n        False,\n        description=\"\"\"\nif set, websocket receives filtered results while OpenSearch stores unfiltered (=all) documents.\ndefault is False (both OpenSearch and websocket receives the filtered results).\n\"\"\",\n    )\n\n    @override\n    def __str__(self) -> str:\n        return super().__str__()\n\n    @staticmethod\n    def filter_doc_for_ingestion(\n        doc: dict, flt: \"GulpIngestionFilter\" = None\n    ) -> GulpDocumentFilterResult:\n        \"\"\"\n        Check if a document is eligible for ingestion based on a time-range filter.\n\n        Args:\n            doc (dict): The GulpDocument dictionary to check.\n            flt (GulpIngestionFilter): The filter parameters, if any.\n\n        Returns:\n            GulpEventFilterResult: The result of the filter check.\n        \"\"\"\n        # MutyLogger.get_instance().error(flt)\n        if not flt or flt.storage_ignore_filter:\n            # empty filter or ignore\n            return GulpDocumentFilterResult.ACCEPT\n        if not flt.time_range:\n            # no time range, accept all\n            return GulpDocumentFilterResult.ACCEPT\n\n        # filter based on time range\n        # check if ts is within the range. either start or end can be None\n        # if both are None, the filter is empty and all events are accepted\n        ts = doc[\"gulp.timestamp\"]\n        if flt.time_range[0] and flt.time_range[1]:\n            if ts >= flt.time_range[0] and ts <= flt.time_range[1]:\n                return GulpDocumentFilterResult.ACCEPT\n        if flt.time_range[0]:\n            if ts >= flt.time_range[0]:\n                return GulpDocumentFilterResult.ACCEPT\n        if flt.time_range[1]:\n            if ts <= flt.time_range[1]:\n                return GulpDocumentFilterResult.ACCEPT\n\n        return GulpDocumentFilterResult.SKIP\n\n\nclass GulpQueryFilter(GulpBaseDocumentFilter):\n    \"\"\"\n    a GulpQueryFilter defines a filter for the query API.\n\n    - query is built using [query_string](https://opensearch.org/docs/latest/query-dsl/full-text/query-string/) query.\n    - further extra key=value pairs are allowed and are intended as k: [v1, v2, ...] filters: they match any of the values as OR, i.e.: `{\"key\": [\"v1\", \"v2\"]}` matches `key: v1 OR key: v2`.\n    \"\"\"\n\n    model_config = ConfigDict(\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"agent_types\": [\"win_evtx\"],\n                    \"operation_ids\": [TEST_OPERATION_ID],\n                    \"context_ids\": [TEST_CONTEXT_ID],\n                    \"source_ids\": [TEST_SOURCE_ID],\n                    \"doc_ids\": [\"d0739e61e3566845838fd78012b8201d\"],\n                    \"event_codes\": [\"5152\"],\n                    \"time_range\": [\n                        1551385571023173120,\n                        1551446406878338048,\n                    ],\n                    \"storage_ignore_filter\": False,\n                }\n            ]\n        }\n    )\n    agent_types: Optional[list[str]] = Field(\n        None,\n        description=\"include documents matching the given `agent.type`/s.\",\n    )\n    doc_ids: Optional[list[str]] = Field(\n        None,\n        description=\"include documents matching the given `_id`/s.\",\n    )\n    operation_ids: Optional[list[str]] = Field(\n        None,\n        description=\"include documents  matching the given `gulp.operation_id`/s\",\n    )\n    context_ids: Optional[list[str]] = Field(\n        None,\n        description=\"\"\"\ninclude documents matching the given `gulp.context_id`/s.\n\n- this must be set to the *real context_id* as on the collab database, calculated as *SHA1(operation_id+context_id)*.\n\"\"\",\n    )\n    source_ids: Optional[list[str]] = Field(\n        None,\n        description=\"\"\"\ninclude documents matching the given `gulp.source_id`/s.\n- this must be set to the *real source_id* as on the collab database, calculated as *SHA1(operation_id+context_id+source_id)*.\n\"\"\",\n    )\n    event_codes: Optional[list[str]] = Field(\n        None,\n        description=\"include documents matching the given `event.code`/s.\",\n    )\n\n    @override\n    def __str__(self) -> str:\n        return super().__str__()\n\n    def _query_string_build_or_clauses(self, field: str, values: list) -> str:\n        if not values:\n            return \"\"\n\n        qs = \"(\"\n        for v in values:\n            \"\"\"\n            if isinstance(v, str):\n                # only enclose if there is a space in the value\n                vv = muty.string.enclose(v) if \" \" in v else v\n            else:\n                vv = v\n            \"\"\"\n            qs += f\"{field}: {v} OR \"\n\n        qs = qs[:-4]  # remove last \" OR \"\n        qs += \")\"\n        return qs\n\n    def _query_string_build_eq_clause(self, field: str, v: int | str) -> str:\n        qs = f\"{field}: {v}\"\n        return qs\n\n    def _query_string_build_gte_clause(self, field: str, v: int) -> str:\n        qs = f\"{field}: >={v}\"\n        return qs\n\n    def _query_string_build_lte_clause(self, field: str, v: int) -> str:\n        qs = f\"{field}: <={v}\"\n        return qs\n\n    def _query_string_build_exists_clause(self, field: str, exist: bool) -> str:\n        if exist:\n            qs = f\"_exists_: {field}\"\n        else:\n            qs = f\"NOT _exists_: {field}\"\n        return qs\n\n    def to_opensearch_dsl(self, flt: \"GulpQueryFilter\" = None) -> dict:\n        \"\"\"\n        convert to a query in OpenSearch DSL format using [query_string](https://opensearch.org/docs/latest/query-dsl/full-text/query-string/) query\n\n        Args:\n            flt (GulpQueryFilter, optional): used to pre-filter the query, default=None\n        Returns:\n            dict: a ready to be used query object for the search API, like:\n            ```json\n            {\n                \"query\": {\n                    \"query_string\": {\n                        \"query\": \"agent.type: \\\"winlogbeat\\\" AND gulp.operation_id: \\\"test\\\" AND gulp.context_id: \\\"testcontext\\\" AND gulp.source_id: \\\"test.log\\\" AND _id: \\\"testid\\\" AND event.original: \\\"test event\\\" AND event.code: \\\"5152\\\" AND @timestamp: >=1609459200000 AND @timestamp: <=1609545600000\",\n                        \"analyze_wildcard\": true,\n                        \"default_field\": \"_id\"\n                    }\n                }\n            }\n            ```\n        \"\"\"\n\n        def _build_clauses():\n            clauses: list[str] = []\n\n            if self.agent_types:\n                clauses.append(\n                    self._query_string_build_or_clauses(\"agent.type\", self.agent_types)\n                )\n            if self.operation_ids:\n                clauses.append(\n                    self._query_string_build_or_clauses(\n                        \"gulp.operation_id\", self.operation_ids\n                    )\n                )\n            if self.context_ids:\n                clauses.append(\n                    self._query_string_build_or_clauses(\n                        \"gulp.context_id\", self.context_ids\n                    )\n                )\n            if self.source_ids:\n                clauses.append(\n                    self._query_string_build_or_clauses(\n                        \"gulp.source_id\", self.source_ids\n                    )\n                )\n            if self.doc_ids:\n                clauses.append(self._query_string_build_or_clauses(\"_id\", self.doc_ids))\n\n            if self.event_codes:\n                clauses.append(\n                    self._query_string_build_or_clauses(\"event.code\", self.event_codes)\n                )\n            if self.time_range:\n                # simple >=, <= clauses\n                field = \"gulp.timestamp\"\n                if self.time_range[0]:\n                    clauses.append(\n                        self._query_string_build_gte_clause(field, self.time_range[0])\n                    )\n                if self.time_range[1]:\n                    clauses.append(\n                        self._query_string_build_lte_clause(field, self.time_range[1])\n                    )\n            if self.model_extra:\n                # extra fields\n                for k, v in self.model_extra.items():\n                    clauses.append(self._query_string_build_or_clauses(k, v))\n\n            # only return non-empty clauses\n            clauses = [c for c in clauses if c and c.strip()]\n            # print(clauses)\n            return clauses\n\n        # build the query struct\n        #\n        # NOTE: default_field: _id below is an attempt to fix \"field expansion matches too many fields\"\n        # https://discuss.elastic.co/t/no-detection-of-fields-in-query-string-query-strings-results-in-field-expansion-matches-too-many-fields/216137/2\n        # (caused by \"default_field\" which by default is \"*\" and the query string is incorrectly parsed when parenthesis are used as we do, maybe this could be fixed in a later opensearch version as it is in elasticsearch)\n        query_dict = {\n            \"query\": {\n                \"bool\": {\n                    \"must\": [\n                        {\n                            \"query_string\": {\n                                # all clauses are ANDed, if none return all\n                                \"query\": \" AND \".join(filter(None, _build_clauses()))\n                                or \"*\",\n                                \"analyze_wildcard\": True,\n                                \"default_field\": \"_id\",\n                            }\n                        }\n                    ]\n                }\n            }\n        }\n        bool_dict = query_dict[\"query\"][\"bool\"]\n        q_string = query_dict[\"query\"][\"bool\"][\"must\"][0][\"query_string\"]\n        if self.query_string_parameters:\n            q_string.update(self.query_string_parameters)\n\n        if flt:\n            # merge with the provided filter using a bool query\n            bool_dict[\"filter\"] = [flt.to_opensearch_dsl()[\"query\"]]\n\n        # MutyLogger.get_instance().debug('flt=%s, resulting query=%s' % (flt, json.dumps(query_dict, indent=2)))\n        return query_dict\n\n    def merge_to_opensearch_dsl(self, dsl: dict) -> dict:\n        \"\"\"\n        merge the filter with an existing OpenSearch DSL query.\n\n        Args:\n            dsl (dict): the existing OpenSearch DSL query.\n        Returns:\n            dict: the merged query.\n        \"\"\"\n        return {\n            \"query\": {\n                \"bool\": {\n                    \"filter\": [\n                        self.to_opensearch_dsl()[\"query\"],\n                        dsl[\"query\"],\n                    ]\n                }\n            }\n        }\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Check if the filter is empty.\n\n        Returns:\n            bool: True if the filter is empty, False otherwise.\n        \"\"\"\n        return not any(\n            [\n                self.time_range,\n                self.agent_types,\n                self.operation_ids,\n                self.context_ids,\n                self.source_ids,\n                self.event_codes,\n                self.doc_ids,\n            ]\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/collab/user.py", "content": "from typing import TYPE_CHECKING, Optional, override\n\nimport muty.crypto\nimport muty.string\nimport muty.time\nfrom muty.log import MutyLogger\nfrom sqlalchemy import ARRAY, BIGINT, String\nfrom sqlalchemy.dialects.postgresql import JSONB\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.ext.mutable import MutableDict, MutableList\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\nfrom sqlalchemy.types import Enum as SQLEnum\n\nfrom gulp.api.collab.structs import (\n    GulpCollabBase,\n    GulpCollabType,\n    GulpUserPermission,\n    MissingPermission,\n    T,\n    WrongUsernameOrPassword,\n)\nfrom gulp.api.collab.user_group import GulpUserAssociations\nfrom gulp.api.ws_api import GulpUserLoginLogoutPacket, GulpWsQueueDataType\nfrom gulp.config import GulpConfig\n\nif TYPE_CHECKING:\n    from gulp.api.collab.user_group import GulpUserGroup\n    from gulp.api.collab.user_session import GulpUserSession\n\n\nclass GulpUser(GulpCollabBase, type=GulpCollabType.USER):\n    \"\"\"\n    Represents a user in the system.\n    \"\"\"\n\n    pwd_hash: Mapped[str] = mapped_column(\n        String, doc=\"The hashed password of the user.\"\n    )\n    groups: Mapped[list[\"GulpUserGroup\"]] = relationship(\n        \"GulpUserGroup\",\n        secondary=GulpUserAssociations.table,\n        back_populates=\"users\",\n        lazy=\"selectin\",\n    )\n    permission: Mapped[Optional[list[GulpUserPermission]]] = mapped_column(\n        MutableList.as_mutable(ARRAY(SQLEnum(GulpUserPermission))),\n        default_factory=lambda: [GulpUserPermission.READ],\n        doc=\"One or more permissions of the user.\",\n    )\n    email: Mapped[Optional[str]] = mapped_column(\n        String, default=None, doc=\"The email of the user.\", unique=True\n    )\n    time_last_login: Mapped[Optional[int]] = mapped_column(\n        BIGINT,\n        default=0,\n        doc=\"The time of the last login, in milliseconds from the unix epoch.\",\n    )\n    session: Mapped[Optional[\"GulpUserSession\"]] = relationship(\n        \"GulpUserSession\",\n        back_populates=\"user\",\n        cascade=\"all,delete-orphan\",\n        default=None,\n        foreign_keys=\"[GulpUserSession.user_id]\",\n    )\n\n    user_data: Mapped[Optional[dict]] = mapped_column(\n        MutableDict.as_mutable(JSONB), default_factory=dict, doc=\"Arbitrary user data.\"\n    )\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        from gulp.api.collab.user_group import GulpUserGroup\n        from gulp.api.collab.user_session import GulpUserSession\n\n        d = super().example()\n        d.update(\n            {\n                \"pwd_hash\": \"hashed_password\",\n                \"groups\": [GulpUserGroup.example()],\n                \"permission\": [\"READ\"],\n                \"email\": \"user@mail.com\",\n                \"time_last_login\": 1234567890,\n                \"session\": GulpUserSession.example(),\n                \"user_data\": {\"key\": \"value\", \"key2\": 1234},\n            }\n        )\n        return d\n\n    async def add_to_default_administrators_group(self, sess: AsyncSession) -> bool:\n        \"\"\"\n        if the default administrators group exists, and the user is administrator, add\n        the user to the default administrators group\n\n        Args:\n            sess (AsyncSession): The database session.\n\n        Returns:\n            bool: True if the user was added to the administrators group, False otherwise\n        \"\"\"\n        from gulp.api.collab.user_group import ADMINISTRATORS_GROUP_ID, GulpUserGroup\n\n        g: GulpUserGroup = await GulpUserGroup.get_by_id(\n            sess, ADMINISTRATORS_GROUP_ID, throw_if_not_found=False\n        )\n        if g:\n            MutyLogger.get_instance().debug(\n                \"adding newly created user %s to the administrators default group\"\n                % (self.id)\n            )\n            try:\n                await g.add_user(sess, self.id)\n                return True\n            except Exception as e:\n                MutyLogger.get_instance().error(\n                    \"error adding user %s to administrators group: %s\" % (self.id, e)\n                )\n        return False\n\n    @classmethod\n    async def create(\n        cls,\n        sess: AsyncSession,\n        user_id: str,\n        password: str,\n        permission: list[GulpUserPermission] = [GulpUserPermission.READ],\n        email: str = None,\n        glyph_id: str = None,\n    ) -> T:\n        \"\"\"\n        Create a new user object on the collab database (can only be called by an admin).\n\n        Args:\n            sess (AsyncSession): The database session.\n            user_id (str): The ID of the user to create.\n            password (str): The password of the user to create.\n            permission (list[GulpUserPermission], optional): The permission of the user to create. Defaults to [GulpUserPermission.READ].\n            email (str, optional): The email of the user to create. Defaults to None.\n            glyph_id (str, optional): The glyph ID of the user to create. Defaults to None.\n\n        Returns:\n            The created user object.\n        \"\"\"\n        if GulpUserPermission.READ not in permission:\n            # ensure that all users have read permission\n            permission.append(GulpUserPermission.READ)\n\n        object_data = {\n            \"pwd_hash\": muty.crypto.hash_sha256(password) if password else \"-\",\n            \"permission\": permission,\n            \"email\": email,\n            \"glyph_id\": glyph_id,\n            \"user_data\": {},\n        }\n\n        # set user_id to username (user owns itself)\n        u: GulpUser = await super()._create(\n            sess, id=user_id, object_data=object_data, owner_id=user_id\n        )\n\n        # if the default administrators group exists, and the user is administrator, add\n        # the user to the default administrators group\n        if u.is_admin():\n            await u.add_to_default_administrators_group(sess)\n        return u\n\n    @override\n    async def update(\n        self,\n        sess: AsyncSession,\n        d: dict,\n        user_session: \"GulpUserSession\",\n    ) -> None:\n        \"\"\"\n        updates the user object with the specified data, checking for permission and password changes.\n\n        Args:\n            sess (AsyncSession): The database session.\n            d (dict): The data to update.\n            user_session (GulpUserSession): The user session object (will be invalidated).\n\n        Raises:\n            MissingPermission: If the user does not have the required permission.\n        \"\"\"\n\n        # special checks for permission and password\n        #\n        # - only admin can change permission\n        # - only admin can change password to other users\n        # - changing password will invalidate the session\n        if \"permission\" in d:\n            if not user_session.user.is_admin():\n                # only admin can change permission\n                raise MissingPermission(\n                    \"only admin can change permission, session_user_id=%s\"\n                    % (user_session.user_id)\n                )\n\n        if \"password\" in d:\n            if not user_session.user.is_admin() and user_session.user.id != self.id:\n                # only admin can change password to other users\n                raise MissingPermission(\n                    \"only admin can change password to other users, user_id=%s, session_user_id=%s\"\n                    % (self.id, user_session.user_id)\n                )\n\n        # checks ok, update user\n        if \"password\" in d:\n            d[\"pwd_hash\"] = muty.crypto.hash_sha256(d[\"password\"])\n            del d[\"password\"]\n        if \"permission\" in d:\n            # ensure that all users have read permission\n            if GulpUserPermission.READ not in d[\"permission\"]:\n                d[\"permission\"].append(GulpUserPermission.READ)\n\n        # update\n        await super().update(sess, d)\n\n        # if the default administrators group exists, and the user is administrator, add\n        # the user to the default administrators group\n        if self.is_admin():\n            self.add_to_default_administrators_group(sess)\n\n        if user_session:\n            # invalidate session for the user\n            MutyLogger.get_instance().warning(\n                \"updated user, invalidating session for user_id=%s\" % (self.id)\n            )\n\n            await sess.delete(user_session)\n        await sess.flush()\n\n    def is_admin(self) -> bool:\n        \"\"\"\n        Check if the user has admin permission (or is in an admin group).\n\n        Returns:\n            bool: True if the user has admin permission, False otherwise.\n        \"\"\"\n        admin = GulpUserPermission.ADMIN in self.permission\n        if admin:\n            return admin\n\n        if self.groups:\n            # also check if the user is in an admin group\n            for group in self.groups:\n                if group.is_admin():\n                    return True\n\n        return False\n\n    def logged_in(self) -> bool:\n        \"\"\"\n        check if the user is logged in\n\n        Returns:\n            bool: True if the user has an active session (logged in)\n        \"\"\"\n        return self.session is not None\n\n    @staticmethod\n    async def login(\n        sess: AsyncSession,\n        user_id: str,\n        password: str,\n        ws_id: str,\n        req_id: str,\n        skip_password_check: bool = False,\n    ) -> \"GulpUserSession\":\n        \"\"\"\n        Asynchronously logs in a user and creates a session (=obtain token).\n        Args:\n            user (str): The username of the user to log in.\n            password (str): The password of the user to log in.\n            ws_id (str): The websocket ID.\n            req_id (str): The request ID.\n            skip_password_check (bool, optional): Whether to skip the password check, internal usage only. Defaults to False.\n\n        Returns:\n            GulpUserSession: The created session object.\n        \"\"\"\n        from gulp.api.collab.user_session import GulpUserSession\n\n        # ensure atomicity of login\n        await GulpCollabBase.acquire_advisory_lock(\n            sess, muty.crypto.hash_xxh64_int(user_id)\n        )\n        u: GulpUser = await GulpUser.get_by_id(sess, user_id)\n        if u.session:\n            # check if user has a session already, if so invalidate\n            MutyLogger.get_instance().warning(\n                \"user %s was already logged in, resetting...\" % (user_id)\n            )\n            await sess.delete(u.session)\n            await sess.flush()\n            await sess.refresh(u)\n\n        if not skip_password_check:\n            # check password\n            if u.pwd_hash != muty.crypto.hash_sha256(password):\n                raise WrongUsernameOrPassword(\n                    \"wrong password for user_id=%s\" % (user_id)\n                )\n\n        # get expiration time\n        if GulpConfig.get_instance().debug_no_token_expiration():\n            time_expire = None\n        else:\n            # setup session expiration\n            if u.is_admin():\n                time_expire = (\n                    muty.time.now_msec()\n                    + GulpConfig.get_instance().token_admin_ttl() * 1000\n                )\n            else:\n                time_expire = (\n                    muty.time.now_msec() + GulpConfig.get_instance().token_ttl() * 1000\n                )\n\n        # create new session\n        p = GulpUserLoginLogoutPacket(user_id=u.id, login=True)\n        object_data = {\n            \"user_id\": u.id,\n            \"time_expire\": time_expire,\n        }\n        if GulpConfig.get_instance().is_integration_test():\n            # for integration tests, this api will return a fixed token based on the user_id\n            # (the user must anyway log in first)\n            token_id = \"token_\" + user_id\n            MutyLogger.get_instance().warning(\n                \"using fixed token %s for integration test\" % (token_id)\n            )\n        else:\n            # autogenerated\n            token_id = None\n\n        new_session: GulpUserSession = await GulpUserSession._create(\n            sess,\n            object_data,\n            id=token_id,\n            ws_id=ws_id,\n            owner_id=u.id,\n            ws_queue_datatype=GulpWsQueueDataType.USER_LOGIN,\n            ws_data=p.model_dump(),\n            req_id=req_id,\n        )\n\n        # update user with new session and write the new session object itself\n        u.session = new_session\n        u.time_last_login = muty.time.now_msec()\n        MutyLogger.get_instance().info(\n            \"user %s logged in, token=%s, expire=%d, admin=%r\"\n            % (u.id, new_session.id, new_session.time_expire, u.is_admin())\n        )\n        sess.add(u)\n        await sess.commit()\n        await sess.refresh(new_session)\n        return new_session\n\n    @staticmethod\n    async def logout(\n        sess: AsyncSession, s: \"GulpUserSession\", ws_id: str, req_id: str\n    ) -> None:\n        \"\"\"\n        Logs out the specified user by deleting the session.\n\n        Args:\n            sess (AsyncSession): The session to use.\n            s: the GulpUserSession to log out\n            ws_id (str): The websocket ID.\n            req_id (str): The request ID.\n        Returns:\n            None\n        \"\"\"\n        async with sess:\n            MutyLogger.get_instance().info(\n                \"logging out token=%s, user=%s\" % (s.id, s.user_id)\n            )\n            p = GulpUserLoginLogoutPacket(user_id=s.user_id, login=False)\n            await s.delete(\n                sess=sess,\n                user_id=s.user_id,\n                ws_id=ws_id,\n                req_id=req_id,\n                ws_queue_datatype=GulpWsQueueDataType.USER_LOGOUT,\n                ws_data=p.model_dump(),\n            )\n\n    def has_permission(self, permission: list[GulpUserPermission]) -> bool:\n        \"\"\"\n        Check if the user has the specified permission\n\n        Args:\n            permission (list[GulpUserPermission]): The permission(s) to check.\n\n        Returns:\n            bool: True if the user has the specified permissions, False otherwise.\n        \"\"\"\n        if self.is_admin():\n            return True\n\n        has_permission = all([p in self.permission for p in permission])\n        if has_permission:\n            return True\n        if self.groups:\n            for group in self.groups:\n                if group.has_permission(permission):\n                    return True\n        return False\n\n    def check_object_access(\n        self,\n        obj: GulpCollabBase,\n        enforce_owner: bool = False,\n        throw_on_no_permission: bool = False,\n    ) -> bool:\n        \"\"\"\n        Check if the user has READ permission to access the specified object.\n\n        the user has permission to access the object if:\n\n        - no granted users or groups are set (everyone has access)\n        - the user is an admin\n        - the user is the owner of the object\n        - the user is in the granted groups of the object\n        - the user is in the granted users of the object\n\n        Args:\n            obj (GulpCollabBase): The object to check against.\n            enforce_owner (bool, optional): Whether to enforce that the user is the owner of the object (or administrator). Defaults to False.\n            throw_on_no_permission (bool, optional): Whether to throw an exception if the user does not have permission. Defaults to False.\n        Returns:\n            bool: True if the user has permission to access the object, False otherwise.\n        \"\"\"\n        if self.is_admin():\n            # admin is always granted\n            # MutyLogger.get_instance().debug(\"allowing access to admin\")\n            return True\n\n        # check if the user is the owner of the object\n        if obj.is_owner(self.id):\n            # MutyLogger.get_instance().debug(\"allowing access to object owner\")\n            return True\n\n        if enforce_owner:\n            if throw_on_no_permission:\n                raise MissingPermission(\n                    f\"User {self.id} is not the owner of the object {obj.id}.\"\n                )\n            return False\n\n        if not obj.granted_user_group_ids and not obj.granted_user_ids:\n            # public object (both granted_user_group_ids and granted_user_ids are empty)\n            MutyLogger.get_instance().debug(\n                \"allowing access to object without granted users or groups, user=%s\"\n                % (self.id)\n            )\n            return True\n\n        # check if the user is in the granted groups\n        if obj.granted_user_group_ids:\n            for group in self.groups:\n                if group.id in obj.granted_user_group_ids:\n                    MutyLogger.get_instance().debug(\n                        \"allowing access to granted group %s\" % (group.id)\n                    )\n                    return True\n\n        # check if the user is in the granted users\n        if obj.granted_user_ids and self.id in obj.granted_user_ids:\n            MutyLogger.get_instance().debug(\n                \"allowing access to granted user %s\" % (self.id)\n            )\n            return True\n\n        if throw_on_no_permission:\n            raise MissingPermission(\n                f\"User {self.id} does not have the required permissions to access the object {obj.id}.\"\n            )\n        MutyLogger.get_instance().debug(\n            f\"User {self.id} does not have the required permissions to access the object {obj.id}, granted_user_ids={obj.granted_user_ids}, granted_group_ids={obj.granted_user_group_ids}, requestor_user_id={self.id}\"\n        )\n        return False\n"}
{"type": "source_file", "path": "src/gulp/api/collab/operation.py", "content": "from typing import Optional, override\n\nimport muty.crypto\nimport muty.string\nfrom muty.log import MutyLogger\nfrom sqlalchemy import String\nfrom sqlalchemy.dialects.postgresql import JSONB\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.ext.mutable import MutableDict\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom gulp.api.collab.context import GulpContext\nfrom gulp.api.collab.structs import GulpCollabBase, GulpCollabType\nfrom gulp.api.ws_api import GulpWsQueueDataType\n\nclass GulpOperation(GulpCollabBase, type=GulpCollabType.OPERATION):\n    \"\"\"\n    Represents an operation in the gulp system.\n    \"\"\"\n\n    index: Mapped[str] = mapped_column(\n        String,\n        doc=\"The gulp opensearch index to associate the operation with.\",\n    )\n    # multiple contexts can be associated with an operation\n    contexts: Mapped[Optional[list[GulpContext]]] = relationship(\n        \"GulpContext\",\n        cascade=\"all, delete-orphan\",\n        lazy=\"selectin\",\n        uselist=True,\n        doc=\"The context/s associated with the operation.\",\n    )\n    operation_data: Mapped[Optional[dict]] = mapped_column(\n        MutableDict.as_mutable(JSONB), default_factory=dict, doc=\"Arbitrary operation data.\"\n    )\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d[\"index\"] = \"operation_index\"\n        d[\"operation_data\"] = {\"key\": \"value\"}\n        return d\n\n    @override\n    def to_dict(self, nested=False, **kwargs) -> dict:\n        d = super().to_dict(nested=nested, **kwargs)\n        if nested:\n            # add nested contexts\n            d[\"contexts\"] = (\n                [ctx.to_dict(nested=True) for ctx in self.contexts]\n                if self.contexts\n                else []\n            )\n        return d\n\n    async def add_context(\n        self, sess: AsyncSession, user_id: str, name: str, ws_id: str = None, req_id: str = None\n\n    ) -> tuple[GulpContext, bool]:\n        \"\"\"\n        Add a context to the operation, or return the context if already added.\n\n        Args:\n            sess (AsyncSession): The session to use.\n            user_id (str): The id of the user adding the context.\n            name (str): The name of the context.\n            ws_id (str, optional): The websocket id to stream NEW_CONTEXT to. Defaults to None.\n            req_id (str, optional): The request id. Defaults to None.\n\n        Returns:\n            tuple(GulpContext, bool): The context added (or already existing) and a flag indicating if the context was added\n        \"\"\"\n        id = GulpContext.make_context_id_key(self.id, name)\n\n        # acquire lock first\n        lock_id = muty.crypto.hash_xxh64_int(id)\n        await GulpCollabBase.acquire_advisory_lock(sess, lock_id)\n\n        # check if context exists\n        ctx: GulpContext = await GulpContext.get_by_id(\n            sess, id=id, throw_if_not_found=False\n        )\n        if ctx:\n            MutyLogger.get_instance().debug(\n                f\"context {name} already added to operation {self.id}.\"\n            )\n            return ctx, False\n\n        # create new context and link it to operation\n        object_data = {\n            \"operation_id\": self.id,\n            \"name\": name,\n            \"color\": \"white\",\n        }\n        ctx = await GulpContext._create(\n            sess,\n            object_data,\n            id=id,\n            owner_id=user_id,\n            ws_queue_datatype=GulpWsQueueDataType.NEW_CONTEXT if ws_id else None,\n            ws_id=ws_id,\n            req_id=req_id,\n        )\n\n        # add same grants to the context as the operation\n        for u in self.granted_user_ids:\n            await ctx.add_user_grant(sess, u)\n        for g in self.granted_user_group_ids:\n            await ctx.add_group_grant(sess, g)\n\n        await sess.refresh(self)\n\n        MutyLogger.get_instance().info(\n            f\"context {name} added to operation {self.id}.\")\n        return ctx, True\n\n    @override\n    async def add_user_grant(self, sess: AsyncSession, user_id: str) -> None:\n        # add grant to the operation\n        await super().add_user_grant(sess, user_id)\n        if not self.contexts:\n            return\n\n        # add grant to all contexts and sources\n        for ctx in self.contexts:\n            await ctx.add_user_grant(sess, user_id)\n            if ctx.sources:\n                for src in ctx.sources:\n                    await src.add_user_grant(sess, user_id)\n        # await sess.refresh(self)\n\n    @override\n    async def remove_user_grant(self, sess: AsyncSession, user_id: str) -> None:\n        # remove grant from the operation\n        await super().remove_user_grant(sess, user_id)\n        if not self.contexts:\n            return\n\n        # remove grant from all contexts and sources\n        for ctx in self.contexts:\n            await ctx.remove_user_grant(sess, user_id)\n            if ctx.sources:\n                for src in ctx.sources:\n                    await src.remove_user_grant(sess, user_id)\n\n    @override\n    async def add_group_grant(self, sess: AsyncSession, group_id: str):\n        # add grant to the operation\n        await super().add_group_grant(sess, group_id)\n        if not self.contexts:\n            return\n\n        # add grant to all contexts and sources\n        for ctx in self.contexts:\n            await ctx.add_group_grant(sess, group_id)\n            if ctx.sources:\n                for src in ctx.sources:\n                    await src.add_group_grant(sess, group_id)\n\n    @override\n    async def remove_group_grant(self, sess: AsyncSession, group_id: str):\n        # remove grant from the operation\n        await super().remove_group_grant(sess, group_id)\n        if not self.contexts:\n            return\n\n        # remove grant from all contexts and sources\n        for ctx in self.contexts:\n            await ctx.remove_group_grant(sess, group_id)\n            if ctx.sources:\n                for src in ctx.sources:\n                    await src.remove_group_grant(sess, group_id)\n"}
{"type": "source_file", "path": "src/gulp/api/collab/link.py", "content": "from typing import override\nfrom sqlalchemy import ARRAY, String\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.ext.mutable import MutableList\nfrom gulp.api.collab.structs import GulpCollabObject, GulpCollabType\n\n\nclass GulpLink(GulpCollabObject, type=GulpCollabType.LINK):\n    \"\"\"\n    a link in the gulp collaboration system\n    \"\"\"\n\n    # the source document\n    doc_id_from: Mapped[str] = mapped_column(String, doc=\"The source document ID.\")\n    # target documents\n    doc_ids: Mapped[list[str]] = mapped_column(\n        MutableList.as_mutable(ARRAY(String)),\n        default_factory=list,\n        doc=\"One or more target document IDs.\",\n    )\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d[\"doc_id_from\"] = \"source_doc_id\"\n        d[\"doc_ids\"] = [\"target_doc_id\"]\n        return d\n"}
{"type": "source_file", "path": "src/gulp/api/collab/fields.py", "content": "from typing import override\n\nimport muty.crypto\nimport muty.log\nimport muty.time\nfrom muty.log import MutyLogger\nfrom sqlalchemy import ForeignKey\nfrom sqlalchemy.dialects.postgresql import JSONB\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.ext.mutable import MutableDict\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom gulp.api.collab.structs import GulpCollabBase, GulpCollabType, T\n\n\nclass GulpSourceFields(GulpCollabBase, type=GulpCollabType.SOURCE_FIELDS):\n    \"\"\"\n    represents the fields mapping for a source, as returned by GulpOpenSearch.datastream_get_mapping_by_src\n    \"\"\"\n\n    operation_id: Mapped[str] = mapped_column(\n        ForeignKey(\"operation.id\", ondelete=\"CASCADE\"),\n        doc=\"The associable operation.\",\n    )\n    context_id: Mapped[str] = mapped_column(\n        ForeignKey(\"context.id\", ondelete=\"CASCADE\"),\n        doc=\"The associated context.\",\n    )\n    source_id: Mapped[str] = mapped_column(\n        ForeignKey(\"source.id\", ondelete=\"CASCADE\"),\n        doc=\"The associated source.\",\n    )\n    fields: Mapped[dict] = mapped_column(\n        MutableDict.as_mutable(JSONB),\n        default_factory=dict,\n        doc=\"The fields mapping.\",\n    )\n\n    @override\n    def to_dict(\n        self, nested=False, hybrid_attributes=False, exclude=None, exclude_none=False\n    ):\n        # override to have 'gulpesque' keys\n        d = super().to_dict(nested, hybrid_attributes, exclude, exclude_none)\n        if \"operation_id\" in d:\n            d[\"gulp.operation_id\"] = d.pop(\"operation_id\")\n        if \"context_id\" in d:\n            d[\"gulp.context_id\"] = d.pop(\"context_id\")\n        if \"source_id\" in d:\n            d[\"gulp.source_id\"] = d.pop(\"source_id\")\n        return d\n\n    @classmethod\n    async def create(\n        cls,\n        sess: AsyncSession,\n        user_id: str,\n        operation_id: str,\n        context_id: str,\n        source_id: str,\n        fields: dict = None,\n    ) -> T:\n        \"\"\"\n        \"\"\"\n        obj_id = muty.crypto.hash_xxh128(\n            f\"{operation_id}{context_id}{source_id}\"\n        )\n\n        MutyLogger.get_instance().debug(\n            \"---> create: id=%s, operation_id=%s, context_id=%s, source_id=%s, # of fields=%d\",\n            obj_id,\n            operation_id,\n            context_id,\n            source_id,\n            len(fields),\n        )\n\n        # acquire an advisory lock\n        lock_id = muty.crypto.hash_xxh64_int(obj_id)\n        await GulpCollabBase.acquire_advisory_lock(sess, lock_id)\n\n        # check if the stats already exist\n        s: GulpSourceFields = await cls.get_by_id(\n            sess, id=obj_id, throw_if_not_found=False\n        )\n        if s:\n            # update existing\n            MutyLogger.get_instance().debug(\n                \"---> update: id=%s, operation_id=%s, context_id=%s, source_id=%s, # of fields=%d\",\n                obj_id,\n                operation_id,\n                context_id,\n                source_id,\n                len(fields),\n            )\n            s.fields = fields\n            await sess.commit()\n            return s\n\n        object_data = {\n            \"operation_id\": operation_id,\n            \"context_id\": context_id,\n            \"source_id\": source_id,\n            \"fields\": fields,\n        }\n        return await super()._create(\n            sess,\n            object_data=object_data,\n            id=obj_id,\n            owner_id=user_id,\n            private=False\n        )\n"}
{"type": "source_file", "path": "setup.py", "content": "\"\"\"\nreads requirements from requirements.txt, then uses pyproject.toml to setup\n\"\"\"\n\nfrom setuptools import setup\nimport os\n\ndef get_requirements():\n    with open(\"requirements.txt\") as f:\n        return [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n\n\nsetup(\n    name=\"gulp\",\n    install_requires=get_requirements(),\n)\n"}
{"type": "source_file", "path": "src/gulp/api/collab/glyph.py", "content": "import base64\nfrom typing import override\n\nimport muty.file\nfrom sqlalchemy import LargeBinary, String\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom gulp.api.collab.structs import (\n    GulpCollabBase,\n    GulpCollabType,\n    T,\n)\n\n\nclass GulpGlyph(GulpCollabBase, type=GulpCollabType.GLYPH):\n    \"\"\"\n    Represents a glyph object.\n    \"\"\"\n\n    img: Mapped[bytes] = mapped_column(\n        LargeBinary, doc=\"The image data of the glyph as binary blob.\"\n    )\n\n    @override\n    @classmethod\n    def example(cls) -> dict:\n        d = super().example()\n        d[\"img\"] = \"base64_image_data\"\n        return d\n\n    @override\n    def __repr__(self) -> str:\n        return super().__repr__() + f\" img={self.img[:10]}[...]\"\n\n    @override\n    def to_dict(self, **kwargs) -> dict:\n        \"\"\"\n        Convert the object to a dictionary representation.\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        Returns:\n            dict: A dictionary representation of the object, including base64 encoded \"img\".\n        \"\"\"\n        d = super().to_dict(**kwargs)\n        d[\"img\"] = base64.b64encode(self.img).decode()\n        return d\n"}
{"type": "source_file", "path": "src/gulp/api/opensearch/query.py", "content": "from typing import Any, Optional\n\nimport muty.log\nimport muty.string\nfrom elasticsearch import AsyncElasticsearch\nfrom muty.log import MutyLogger\nfrom muty.pydantic import autogenerate_model_example_by_class\nfrom opensearchpy import AsyncOpenSearch\nfrom pydantic import BaseModel, ConfigDict, Field\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom gulp.api.opensearch.filters import QUERY_DEFAULT_FIELDS, GulpQueryFilter\nfrom gulp.structs import GulpSortOrder\n\n\nclass GulpQuery(BaseModel):\n    \"\"\"\n    A query\n    \"\"\"\n\n    def __init__(\n        self,\n        q: Any,\n        name: str = None,\n        sigma_id: str = None,\n        tags: list[str] = None,\n    ):\n        if name is None:\n            # autogenerate name\n            name = \"query_%s\" % (muty.string.generate_unique())\n        if tags is None:\n            tags = []\n\n        super().__init__(\n            name=name,\n            q=q,\n            sigma_id=sigma_id,\n            tags=tags,\n        )\n\n    model_config = ConfigDict(\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"name\": \"test\",\n                    \"id\": \"test\",\n                    \"q\": {\"query\": {\"match_all\": {}}},\n                    \"tags\": [\"test\"],\n                }\n            ]\n        }\n    )\n    q: Any = Field(..., description=\"the query in the target DSL format.\")\n    name: Optional[str] = Field(\n        None,\n        description=\"the name/title of the query, autogenerated if not set.\",\n    )\n    sigma_id: Optional[str] = Field(\n        None, description=\"the id of the sigma rule, if this is a sigma query.\"\n    )\n    tags: Optional[list[str]] = Field([], description=\"query tags.\")\n\n\nclass GulpQueryNoteParameters(BaseModel):\n    \"\"\"\n    to automatically create notes on query matches\n    \"\"\"\n\n    model_config = ConfigDict(\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"create_notes\": True,\n                    \"note_name\": \"test\",\n                    \"note_tags\": [\"test\"],\n                    \"note_color\": None,\n                    \"note_glyph_id\": None,\n                    \"note_private\": False,\n                }\n            ]\n        }\n    )\n    create_notes: bool = Field(\n        None,\n        description=\"if True, creates a note for every match (default for sigma queries and during external query ingestion, unless explicitly set to False)\",\n    )\n    note_name: str = Field(\n        None,\n        description=\"the display name of the notes to create on match, defaults None (uses query name)\",\n    )\n    note_tags: list[str] = Field(\n        [],\n        description='the tags of the notes to create on match, defaults to [] ([\"auto\", sigma rule tags (for sigma queries))',\n    )\n    note_color: str = Field(\n        None,\n        description=\"the color of the notes to create on match, defaults to None (use notes default color)\",\n    )\n    note_glyph_id: str = Field(\n        None,\n        description=\"id of the glyph of the notes to create on match, defaults to None (query group glyph if set, otherwise use notes default).\",\n    )\n\n\nclass GulpQueryParameters(BaseModel):\n    \"\"\"\n    additional options for a query.\n\n    when using with external queries, not all options are guaranteed to be implemented (it is the plugin responsibility to handle them)\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        json_schema_extra={\n            \"examples\": [\n                {\n                    \"sort\": {\n                        \"@timestamp\": GulpSortOrder.ASC,\n                        \"_doc\": GulpSortOrder.ASC,\n                        \"event.sequence\": GulpSortOrder.ASC,\n                    },\n                    \"fields\": [\"@timestamp\", \"event.id\"],\n                    \"limit\": 1000,\n                    \"group\": \"test\",\n                    \"name\": \"test\",\n                    \"preview_mode\": False,\n                    \"search_after\": None,\n                    \"loop\": True,\n                    \"note_parameters\": autogenerate_model_example_by_class(\n                        GulpQueryNoteParameters\n                    ),\n                }\n            ]\n        },\n    )\n    name: Optional[str] = Field(\n        None,\n        description=\"the name of the query: for sigma queries, this is automatically set to the sigma rule name/title.\",\n    )\n    group: Optional[str] = Field(\n        None,\n        description=\"the query group, if any: if set, `QUERY_GROUP_MATCH` is sent on the websocket when there is at least a match for each query belonging to the same group.\",\n    )\n    sort: Optional[dict[str, GulpSortOrder]] = Field(\n        default=None,\n        description=\"\"\"\nhow to sort results, default=sort by ascending `@timestamp`.\n\n- for `external` queries, its the plugin responsibility to handle this.\"\"\",\n    )\n    fields: Optional[list[str] | str] = Field(\n        default=None,\n        description=\"\"\"\nthe set of fields to include in the returned documents.\n\n- for `external` queries, the plugin should ignore this and always return all fields\n- default=`%s`, use `*` to return all fields.\n\"\"\"\n        % (QUERY_DEFAULT_FIELDS),\n    )\n    ensure_default_fields: Optional[bool] = Field(\n        True,\n        description=\"\"\"\nif set and `fields` is set, ensure the default fields (%s) are included in the returned documents (default=True).\n\n- for `external` queries, its the plugin responsibility to handle this.\"\"\"\n        % (QUERY_DEFAULT_FIELDS),\n    )\n    limit: Optional[int] = Field(\n        1000,\n        ge=1,\n        le=10000,\n        description=\"\"\"\nfor pagination, the maximum number of documents to return **per chunk**, default=1000 (None=return up to 10000 documents per chunk).\n\n- for `external` queries, its the plugin responsibility to handle this.\"\"\",\n    )\n    search_after: Optional[list[dict]] = Field(\n        None,\n        description=\"\"\"\nfor pagination, this should be set to the `search_after` returned by the previous call.\n\n- check [OpenSearch documentation](https://opensearch.org/docs/latest/search-plugins/searching-data/paginate/#the-search_after-parameter).\n- ignored if `loop` is set.\n- for `external` queries, its the plugin responsibility to handle this.\n\"\"\",\n    )\n    loop: Optional[bool] = Field(\n        True,\n        description=\"\"\"\nif set, keep querying until all documents are returned (default=True, ignores `search_after`).\n\n- for `external` queries, its the plugin responsibility to handle this.\n\"\"\",\n    )\n    note_parameters: Optional[GulpQueryNoteParameters] = Field(\n        GulpQueryNoteParameters(),\n        description=\"controls how notes are created during queries.\",\n    )\n    preview_mode: Optional[bool] = Field(\n        False,\n        description=\"\"\"\nif set, the query is **synchronous** and returns the preview chunk of documents, without streaming data on the websocket nor counting data in the stats.\n\"\"\",\n    )\n\n    def parse(self) -> dict:\n        \"\"\"\n        Parse the additional options to a dictionary for the OpenSearch/Elasticsearch search api.\n\n        Returns:\n            dict: The parsed dictionary.\n        \"\"\"\n        n = {}\n\n        # sorting\n        n[\"sort\"] = []\n        if not self.sort:\n            # default sort\n            sort = {\n                \"@timestamp\": GulpSortOrder.ASC,\n                # read the NOTE below...\n                \"_doc\": GulpSortOrder.ASC,\n                \"event.sequence\": GulpSortOrder.ASC,\n            }\n\n        else:\n            # use provided\n            sort = self.sort\n\n        for k, v in sort.items():\n            n[\"sort\"].append({k: {\"order\": v}})\n            # NOTE: test with VERY VERY large datasets (5M+), and consider to remove \"_doc\" here this since it may not be needed after all.... event.sequence should be enough.\n            if \"_doc\" not in sort:\n                # make sure document order is always sorted, use _doc instead of _id for less overhead (CircuitBreakingException error from opensearch)\n                n[\"sort\"].append({\"_doc\": {\"order\": v}})\n            if \"event.sequence\" not in sort:\n                # make sure event.sequence is always sorted\n                n[\"sort\"].append({\"event.sequence\": {\"order\": v}})\n\n        # fields to be returned\n        if not self.fields:\n            # default, if not set\n            fields = QUERY_DEFAULT_FIELDS\n        else:\n            # use the given set\n            fields = self.fields\n\n        n[\"_source\"] = None\n        if fields != \"*\":\n            # if \"*\", return all (so we do not set \"_source\"). either, only return these fields\n            if self.ensure_default_fields:\n                # ensure default fields are included\n                for f in QUERY_DEFAULT_FIELDS:\n                    if f not in fields:\n                        fields.append(f)\n            n[\"_source\"] = fields\n\n        # pagination: doc limit\n        n[\"size\"] = None\n        if self.limit is not None:\n            # use provided\n            n[\"size\"] = self.limit\n\n        # pagination: start from\n        if self.search_after:\n            # next chunk from this point\n            n[\"search_after\"] = self.search_after\n        else:\n            n[\"search_after\"] = None\n\n        # MutyLogger.get_instance().debug(\"query options: %s\" % (json.dumps(n, indent=2)))\n        return n\n\n\nclass GulpQueryHelpers:\n    \"\"\"\n    helpers to perform queries\n    \"\"\"\n\n    @staticmethod\n    def merge_queries(q1: dict, q2: dict) -> dict:\n        \"\"\"\n        merge two queries into one.\n\n        Args:\n            q1 (dict): the first query\n            q2 (dict): the second query\n\n        Returns:\n            dict: the merged query\n        \"\"\"\n        # handle empty queries\n        if not q1:\n            return q2\n        if not q2:\n            return q1\n\n        return {\n            \"query\": {\"bool\": {\"filter\": [q1.get(\"query\", q1), q2.get(\"query\", q2)]}}\n        }\n\n    @staticmethod\n    async def query_raw(\n        sess: AsyncSession,\n        user_id: str,\n        req_id: str,\n        ws_id: str,\n        q: dict,\n        index: str,\n        flt: GulpQueryFilter = None,\n        q_options: GulpQueryParameters = None,\n        el: AsyncElasticsearch | AsyncOpenSearch = None,\n        callback: callable = None,\n        callback_args: dict = None,\n        callback_chunk: callable = None,\n        callback_chunk_args: dict = None,\n    ) -> tuple[int, int, str]:\n        \"\"\"\n        Perform a raw opensearch/elasticsearch DSL query using \"search\" API, streaming GulpDocumentChunk results to the websocket.\n\n        Args:\n            sess(AsyncSession): collab database session\n            user_id(str): the user id of the requestor\n            req_id(str): the request id\n            ws_id(str): the websocket id\n            q(dict): the dsl query to be used in OpenSearch/Elasticsearch DSL language, must have \"query\" set.\n            index(str): the opensearch/elasticsearch index/datastream to target\n            flt(GulpQueryFilter, optional): if set, the filter to merge with the query (to restrict the search)\n            q_options(GulpQueryParameters, optional): additional options to use\n            el (AsyncElasticSearch|AsyncOpenSearch, optional): an EXTERNAL ElasticSearch/OpenSearch client to use instead of the default internal gulp's OpenSearch. Defaults to None.\n            callback (callable, optional): the callback to call for each document found. Defaults to None.\n                the callback must be defined as:\n                async def callback(doc: dict, idx: int, **kwargs) -> None\n            callback_args (dict, optional): further arguments to pass to the callback. Defaults to None.\n            callback_chunk (callable, optional): the callback to call for each chunk of documents found. Defaults to None.\n                the callback must be defined as:\n                async def callback_chunk(docs: list[dict], **kwargs) -> None\n            callback_chunk_args (dict, optional): further arguments to pass to the callback_chunk. Defaults to None.\n        Returns:\n            tuple[int, int, str]: the number of documents processed, the total number of hits (they should be the same if all documents are processed), the query name.\n        Raises:\n            Exception: if an error occurs during the query\n        \"\"\"\n        MutyLogger.get_instance().debug(\n            \"GulpQueryHelpers.query_raw: q=%s, index=%s, flt=%s, q_options=%s\"\n            % (q, index, flt, q_options)\n        )\n        if not q_options:\n            q_options = GulpQueryParameters()\n\n        if \"query\" not in q.keys():\n            raise ValueError(\"q must have 'query' set\")\n\n        if flt and not flt.is_empty():\n            # merge with filter\n            q = flt.merge_to_opensearch_dsl(q)\n\n        from gulp.api.opensearch_api import GulpOpenSearch\n\n        processed, total = await GulpOpenSearch.get_instance().search_dsl(\n            sess=sess,\n            index=index,\n            q=q,\n            req_id=req_id,\n            ws_id=ws_id,\n            user_id=user_id,\n            q_options=q_options,\n            el=el,\n            callback=callback,\n            callback_args=callback_args or {},\n            callback_chunk=callback_chunk,\n            callback_chunk_args=callback_chunk_args or {},\n        )\n        return processed, total, q_options.name\n\n    @staticmethod\n    async def query_single(\n        index: str,\n        doc_id: str,\n        el: AsyncElasticsearch | AsyncOpenSearch = None,\n    ) -> dict:\n        \"\"\"\n        Perform a single document query using the given document id on gulp's opensearch/elasticsearch, and return the document as a GulpDocument dictionary.\n\n        Args:\n            req_id (str): the request id\n            index (str): the opensearch/elasticsearch index/datastream to target\n            doc_id (str): the document id to query\n            el (AsyncElasticSearch|AsyncOpenSearch, optional): an EXTERNAL ElasticSearch/OpenSearch client to use instead of the default internal gulp's OpenSearch. Defaults to None.\n\n        Returns:\n            dict: the document as a GulpDocument dictionary\n\n        Raises:\n            ObjectNotFound: if the document is not found.\n        \"\"\"\n        from gulp.api.opensearch_api import GulpOpenSearch\n\n        return await GulpOpenSearch.get_instance().query_single_document(\n            index, doc_id, el=el\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/collab/source.py", "content": "from typing import Optional\n\nfrom sqlalchemy import ForeignKey, PrimaryKeyConstraint, String\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom gulp.api.collab.structs import (\n    GulpCollabBase,\n    GulpCollabType,\n    T,\n)\n\n\nclass GulpSource(GulpCollabBase, type=GulpCollabType.SOURCE):\n    \"\"\"\n    Represents a source of data being processed by the gulp system.\n\n    it has always associated a context and an operation, and the tuple composed by the three is unique.\n    \"\"\"\n\n    operation_id: Mapped[str] = mapped_column(\n        ForeignKey(\"operation.id\", ondelete=\"CASCADE\"),\n        doc=\"The ID of the operation associated with the context.\",\n        primary_key=True,\n    )\n    context_id: Mapped[str] = mapped_column(\n        ForeignKey(\"context.id\", ondelete=\"CASCADE\"),\n        doc=\"The ID of the context associated with this source.\",\n        primary_key=True,\n    )\n    color: Mapped[Optional[str]] = mapped_column(\n        String, default=\"purple\", doc=\"The color of the context.\"\n    )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/user_group.py", "content": "from muty.log import MutyLogger\n\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPIUserGroup:\n    \"\"\"\n    bindings to call gulp's user group related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def usergroup_create(\n        token: str,\n        name: str,\n        permission: list,\n        description: str = None,\n        glyph_id: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"name\": name,\n            \"glyph_id\": glyph_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        body = {\n            \"description\": description,\n            \"permission\": permission,\n        }\n        res = await api_common.make_request(\n            \"POST\",\n            \"user_group_create\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def usergroup_update(\n        token: str,\n        group_id: str,\n        permission: list = None,\n        description: str = None,\n        glyph_id: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"group_id\": group_id,\n            \"glyph_id\": glyph_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        body = {\n            \"description\": description,\n            \"permission\": permission,\n        }\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"user_group_update\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def usergroup_delete(\n        token: str,\n        group_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"group_id\": group_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        res = await api_common.make_request(\n            \"DELETE\",\n            \"user_group_delete\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def usergroup_get_by_id(\n        token: str,\n        group_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"group_id\": group_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        res = await api_common.make_request(\n            \"GET\",\n            \"user_group_get_by_id\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def usergroup_list(\n        token: str,\n        flt: dict = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"req_id\": req_id or api_common.req_id,\n        }\n        body = {\n            \"flt\": flt,\n        }\n        res = await api_common.make_request(\n            \"POST\",\n            \"user_group_list\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def _usergroup_add_remove_user(\n        token: str,\n        user_id: str,\n        group_id: str,\n        remove: bool,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        MutyLogger.get_instance().info(\n            \"Adding user %s to group %s\" % (user_id, group_id)\n            if not remove\n            else \"Removing user %s from group %s\" % (user_id, group_id)\n        )\n        api_common = GulpAPICommon.get_instance()\n        if remove:\n            api = \"user_group_remove_user\"\n        else:\n            api = \"user_group_add_user\"\n        params = {\n            \"group_id\": group_id,\n            \"user_id\": user_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        res = await api_common.make_request(\n            \"PATCH\",\n            api,\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def usergroup_add_user(\n        token: str,\n        user_id: str,\n        group_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        return await GulpAPIUserGroup._usergroup_add_remove_user(\n            token,\n            user_id,\n            group_id,\n            remove=False,\n            expected_status=expected_status,\n            req_id=req_id,\n        )\n\n    @staticmethod\n    async def usergroup_remove_user(\n        token: str,\n        user_id: str,\n        group_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        return await GulpAPIUserGroup._usergroup_add_remove_user(\n            token,\n            user_id,\n            group_id,\n            remove=True,\n            expected_status=expected_status,\n            req_id=req_id,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/user.py", "content": "from typing import Optional\n\nfrom muty.log import MutyLogger\n\nfrom gulp.api.rest.client.common import GulpAPICommon\nfrom gulp.api.rest.client.operation import GulpAPIOperation\nfrom gulp.api.rest.test_values import TEST_OPERATION_ID\n\n\nclass GulpAPIUser:\n    \"\"\"\n    bindings to call gulp's user related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def login_admin_and_reset_operation(\n        req_id: str, ws_id: str = None, operation_id: str = None, recreate: bool = False\n    ) -> str:\n        admin_token = await GulpAPIUser.login_admin(req_id=req_id, ws_id=ws_id)\n        assert admin_token\n        op = operation_id or TEST_OPERATION_ID\n        if recreate:\n            # delete first\n            try:\n                await GulpAPIOperation.operation_delete(admin_token, op, req_id=req_id)\n            except Exception as e:\n                MutyLogger.get_instance().warning(\n                    f\"failed to delete operation {op}: {e}\"\n                )\n\n        res = await GulpAPIOperation.operation_reset(admin_token, op, req_id=req_id)\n        assert res[\"id\"] == op\n        return admin_token\n\n    @staticmethod\n    async def login_admin(req_id: str = None, ws_id: str = None) -> str:\n        MutyLogger.get_instance().info(\"Logging in as admin...\")\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        body = {\n            \"user_id\": \"admin\",\n            \"password\": \"admin\",\n        }\n        res = await api_common.make_request(\"POST\", \"login\", params=params, body=body)\n        token = res.get(\"token\")\n        assert token\n        return token\n\n    @staticmethod\n    async def logout(token: str, req_id: str = None, ws_id: str = None) -> str:\n        \"\"\"\n        Returns:\n\n        the logged out token\n        \"\"\"\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        res = await api_common.make_request(\n            \"POST\", \"logout\", params=params, token=token\n        )\n        t = res.get(\"token\")\n        assert t\n        return t\n\n    @staticmethod\n    async def get_available_login_api_handler() -> dict:\n        api_common = GulpAPICommon.get_instance()\n        res = await api_common.make_request(\"GET\", \"get_available_login_api\", params={})\n        assert res\n        return res\n\n    @staticmethod\n    async def login(\n        user_id: str, password: str, req_id: str = None, ws_id: str = None\n    ) -> str:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"ws_id\": ws_id or api_common.ws_id,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        body = {\n            \"password\": password,\n            \"user_id\": user_id,\n        }\n        res = await api_common.make_request(\"POST\", \"login\", params=params, body=body)\n        token = res.get(\"token\")\n        assert token\n        return token\n\n    @staticmethod\n    async def user_get_by_id(\n        token: str, user_id: str, req_id: str = None, expected_status: int = 200\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\"user_id\": user_id, \"req_id\": req_id or api_common.req_id}\n        res = await api_common.make_request(\n            \"GET\",\n            \"user_get_by_id\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def user_delete(\n        token: str, user_id: str, req_id: str = None, expected_status: int = 200\n    ) -> str:\n        api_common = GulpAPICommon.get_instance()\n        params = {\"user_id\": user_id, \"req_id\": req_id or api_common.req_id}\n        res = await api_common.make_request(\n            \"DELETE\",\n            \"user_delete\",\n            params=params,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def user_update(\n        token: str,\n        username: str,\n        password: Optional[str] = None,\n        permission: Optional[list[str]] = None,\n        email: Optional[str] = None,\n        user_data: Optional[dict] = None,\n        merge_user_data: bool = False,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        body = {}\n        params = {\n            \"user_id\": username,\n            \"merge_user_data\": merge_user_data,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        if password:\n            params[\"password\"] = password\n        if permission:\n            body[\"permission\"] = permission\n        if email:\n            params[\"email\"] = email\n        if user_data:\n            body[\"user_data\"] = user_data\n\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"user_update\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def user_list(\n        token: str, req_id: str = None, expected_status: int = 200\n    ) -> list[dict]:\n        api_common = GulpAPICommon.get_instance()\n        res = await api_common.make_request(\n            \"GET\",\n            \"user_list\",\n            params={\"req_id\": req_id or api_common.req_id},\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def user_create(\n        token: str,\n        user_id: str,\n        password: str,\n        permission: list[str],\n        email: Optional[str] = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"user_id\": user_id,\n            \"password\": password,\n            \"req_id\": req_id or api_common.req_id,\n        }\n        body = permission\n        if email:\n            params[\"email\"] = email\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"user_create\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n"}
{"type": "source_file", "path": "src/gulp/api/rest/enrich.py", "content": "from typing import Annotated\n\nimport muty.log\nfrom fastapi import APIRouter, Body, Depends, Query\nfrom fastapi.responses import JSONResponse\nfrom muty.jsend import JSendException, JSendResponse\nfrom muty.log import MutyLogger\nfrom muty.pydantic import autogenerate_model_example_by_class\n\nfrom gulp.api.collab.operation import GulpOperation\nfrom gulp.api.collab.stats import GulpRequestStats\nfrom gulp.api.collab.structs import GulpRequestStatus, GulpUserPermission\nfrom gulp.api.collab.user_session import GulpUserSession\nfrom gulp.api.collab_api import GulpCollab\nfrom gulp.api.opensearch.filters import GulpQueryFilter\nfrom gulp.api.opensearch.query import GulpQueryHelpers, GulpQueryParameters\nfrom gulp.api.opensearch.structs import GulpDocument\nfrom gulp.api.opensearch_api import GulpOpenSearch\nfrom gulp.api.rest.server_utils import ServerUtils\nfrom gulp.api.rest.structs import APIDependencies\nfrom gulp.api.rest_api import GulpRestServer\nfrom gulp.api.ws_api import GulpQueryDonePacket, GulpWsQueueDataType, GulpWsSharedQueue\nfrom gulp.plugin import GulpPluginBase\nfrom gulp.process import GulpProcess\nfrom gulp.structs import GulpPluginParameters\n\nrouter: APIRouter = APIRouter()\n\n\nasync def _tag_documents_internal(\n    user_id: str,\n    req_id: str,\n    ws_id: str,\n    index: str,\n    flt: GulpQueryFilter,\n    tags: list[str],\n) -> None:\n    \"\"\"\n    runs in a worker to tag the given documents\n    \"\"\"\n\n    async def _tag_documents_chunk_wrapper(self, docs: list[dict], **kwargs):\n        \"\"\"\n        tags a chunk of documents, called by GulpOpenSearch.search_dsl during loop over chunks\n\n        :param docs: the documents to tag\n        :param kwargs: the keyword arguments\n        \"\"\"\n\n        # build documents list\n        tags = kwargs[\"tags\"]\n        last = kwargs.get(\"last\", False)\n        flt = kwargs[\"flt\"]\n\n        MutyLogger.get_instance().debug(\n            \"---> _tagging chunk of %d documents with tags=%s, kwargs=%s ...\"\n            % (len(docs), tags, kwargs)\n        )\n\n        # add tags to documents\n        [d.update({\"gulp.tags\": tags}) for d in docs]\n\n        # update the documents\n        last = kwargs.get(\"last\", False)\n        await GulpOpenSearch.get_instance().update_documents(\n            self._enrich_index, docs, wait_for_refresh=last\n        )\n\n        if last:\n            # also send a GulpQueryDonePacket\n            p = GulpQueryDonePacket(\n                status=GulpRequestStatus.DONE,\n                total_hits=kwargs.get(\"total_hits\", 0),\n            )\n            GulpWsSharedQueue.get_instance().put(\n                type=GulpWsQueueDataType.ENRICH_DONE,\n                ws_id=self._ws_id,\n                user_id=self._user_id,\n                req_id=self._req_id,\n                data=p.model_dump(exclude_none=True),\n            )\n\n            if last:\n                # update source -> fields mappings on the collab db\n                await GulpOpenSearch.get_instance().datastream_update_mapping_by_operation(\n                    index,\n                    user_id,\n                    operation_ids=flt.operation_ids,\n                    context_ids=flt.context_ids,\n                    source_ids=flt.source_ids,\n                )\n\n    MutyLogger.get_instance().debug(\"---> _tag_documents_internal\")\n\n    # build query\n    if not flt:\n        # match all query\n        q = {\"query\": {\"match_all\": {}}}\n    else:\n        # use the given filter\n        q = flt.to_opensearch_dsl()\n\n    # we need id only\n    q_options = GulpQueryParameters(fields=[\"_id\"])\n\n    # call query_raw, which in turn calls _tag_documents_chunk_wrapper\n    errors: list[str] = []\n    total = 0\n    async with GulpCollab.get_instance().session() as sess:\n        try:\n            _, total, _ = await GulpQueryHelpers.query_raw(\n                sess=sess,\n                user_id=user_id,\n                req_id=req_id,\n                ws_id=ws_id,\n                q=q,\n                index=index,\n                q_options=q_options,\n                callback_chunk=_tag_documents_chunk_wrapper,\n                callback_chunk_args={\n                    \"tags\": tags,\n                    \"flt\": flt,\n                },\n            )\n        except Exception as ex:\n            # record error\n            errors = [muty.log.exception_to_string(ex, with_full_traceback=True)]\n            MutyLogger.get_instance().exception(ex)\n        finally:\n            # also update stats\n            await GulpRequestStats.finalize_query_stats(\n                sess,\n                req_id=req_id,\n                ws_id=ws_id,\n                user_id=user_id,\n                hits=total,\n                ws_queue_datatype=GulpWsQueueDataType.TAG_DONE,\n                errors=errors,\n            )\n\n\nasync def _enrich_documents_internal(\n    user_id: str,\n    req_id: str,\n    ws_id: str,\n    flt: GulpQueryFilter,\n    operation_id: str,\n    index: str,\n    plugin: str,\n    plugin_params: GulpPluginParameters,\n) -> None:\n    \"\"\"\n    runs in a worker process to enrich documents\n    \"\"\"\n    # MutyLogger.get_instance().debug(\"---> _enrich_documents_internal\")\n    mod: GulpPluginBase = None\n    failed = False\n    error: str = None\n    total: int = 0\n    async with GulpCollab.get_instance().session() as sess:\n        try:\n            # load plugin\n            mod = await GulpPluginBase.load(plugin)\n\n            # enrich\n            total = await mod.enrich_documents(\n                sess=sess,\n                user_id=user_id,\n                req_id=req_id,\n                ws_id=ws_id,\n                operation_id=operation_id,\n                index=index,\n                flt=flt,\n                plugin_params=plugin_params,\n            )\n        except Exception as ex:\n            failed = True\n            error = muty.log.exception_to_string(ex, with_full_traceback=True)\n        finally:\n            # also update stats\n            await GulpRequestStats.finalize_query_stats(\n                sess,\n                req_id=req_id,\n                ws_id=ws_id,\n                user_id=user_id,\n                hits=total,\n                ws_queue_datatype=GulpWsQueueDataType.ENRICH_DONE,\n                errors=[error] if error else [],\n            )\n\n            # done\n            if mod:\n                await mod.unload()\n\n            if not failed:\n                # update source -> fields mappings on the collab db\n                await GulpOpenSearch.get_instance().datastream_update_mapping_by_operation(\n                    index,\n                    user_id,\n                    operation_ids=flt.operation_ids,\n                    context_ids=flt.context_ids,\n                    source_ids=flt.source_ids,\n                )\n\n\n@router.post(\n    \"/enrich_documents\",\n    response_model=JSendResponse,\n    tags=[\"enrich\"],\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"pending\",\n                        \"timestamp_msec\": 1704380570434,\n                        \"req_id\": \"c4f7ae9b-1e39-416e-a78a-85264099abfb\",\n                    }\n                }\n            }\n        }\n    },\n    summary=\"Enrich documents.\",\n    description=\"\"\"\nuses an `enrichment` plugin to augment data in multiple documents.\n\n- token must have the `edit` permission.\n- `flt.operation_ids` is ignored and set to `[operation_id]`\n- the enriched documents are updated in the Gulp `operation_id.index` and  streamed on the websocket `ws_id` as `GulpDocumentsChunkPacket`.\n- `flt` is provided as a `GulpQueryFilter` to select the documents to enrich.\n\"\"\",\n)\nasync def enrich_documents_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    operation_id: Annotated[str, Depends(APIDependencies.param_operation_id)],\n    plugin: Annotated[str, Depends(APIDependencies.param_plugin)],\n    ws_id: Annotated[str, Depends(APIDependencies.param_ws_id)],\n    flt: Annotated[GulpQueryFilter, Depends(APIDependencies.param_query_flt_optional)],\n    plugin_params: Annotated[\n        GulpPluginParameters,\n        Depends(APIDependencies.param_plugin_params_optional),\n    ] = None,\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSONResponse:\n    params = locals()\n    params[\"flt\"] = flt.model_dump(exclude_none=True)\n    params[\"plugin_params\"] = (\n        plugin_params.model_dump(exclude_none=True) if plugin_params else None\n    )\n    ServerUtils.dump_params(params)\n\n    try:\n        # enforce operation_id\n        flt.operation_ids = [operation_id]\n\n        async with GulpCollab.get_instance().session() as sess:\n            # get operation and check acl\n            op: GulpOperation = await GulpOperation.get_by_id(sess, operation_id)\n            s = await GulpUserSession.check_token(\n                sess, token, obj=op, permission=GulpUserPermission.EDIT\n            )\n            user_id = s.user_id\n            index = op.index\n\n            # create a stats, just to allow request canceling\n            await GulpRequestStats.create(\n                sess,\n                user_id=user_id,\n                req_id=req_id,\n                ws_id=ws_id,\n                operation_id=operation_id,\n                context_id=None,\n            )\n\n        # spawn a task which runs the enrichment in a worker process\n        # run ingestion in a coroutine in one of the workers\n        MutyLogger.get_instance().debug(\"spawning enrichment task ...\")\n        kwds = dict(\n            user_id=user_id,\n            req_id=req_id,\n            ws_id=ws_id,\n            flt=flt,\n            operation_id=operation_id,\n            index=index,\n            plugin=plugin,\n            plugin_params=plugin_params,\n        )\n\n        # print(json.dumps(kwds, indent=2))\n        async def worker_coro(kwds: dict):\n            await GulpProcess.get_instance().process_pool.apply(\n                _enrich_documents_internal, kwds=kwds\n            )\n\n        await GulpRestServer.get_instance().spawn_bg_task(worker_coro(kwds))\n\n        # and return pending\n        return JSONResponse(JSendResponse.pending(req_id=req_id))\n    except Exception as ex:\n        raise JSendException(ex=ex, req_id=req_id)\n\n\n@router.post(\n    \"/enrich_single_id\",\n    response_model=JSendResponse,\n    tags=[\"enrich\"],\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"success\",\n                        \"timestamp_msec\": 1704380570434,\n                        \"req_id\": \"c4f7ae9b-1e39-416e-a78a-85264099abfb\",\n                        \"data\": autogenerate_model_example_by_class(GulpDocument),\n                    }\n                }\n            }\n        }\n    },\n    summary=\"Enrich a single document.\",\n    description=\"\"\"\nuses an `enrichment` plugin to augment data in a single document and returns it directly.\n\n- token must have the `edit` permission.\n- the enriched document is updated in the Gulp `index`.\n\"\"\",\n)\nasync def enrich_single_id_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    operation_id: Annotated[str, Depends(APIDependencies.param_operation_id)],\n    doc_id: Annotated[\n        str,\n        Query(description=\"the `_id` of the document to enrich.\"),\n    ],\n    plugin: Annotated[str, Depends(APIDependencies.param_plugin)],\n    plugin_params: Annotated[\n        GulpPluginParameters,\n        Depends(APIDependencies.param_plugin_params_optional),\n    ] = None,\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSONResponse:\n    params = locals()\n    params[\"plugin_params\"] = (\n        plugin_params.model_dump(exclude_none=True) if plugin_params else None\n    )\n    ServerUtils.dump_params(params)\n\n    mod = None\n    try:\n        async with GulpCollab.get_instance().session() as sess:\n            # get operation and check acl\n            op: GulpOperation = await GulpOperation.get_by_id(sess, operation_id)\n            await GulpUserSession.check_token(\n                sess, token, obj=op, permission=GulpUserPermission.EDIT\n            )\n            index = op.index\n\n            # load plugin\n            mod = await GulpPluginBase.load(plugin)\n\n            # query document\n            doc = await mod.enrich_single_document(\n                sess, doc_id, operation_id, index, plugin_params\n            )\n\n            # rebuild mapping\n            await GulpOpenSearch.get_instance().datastream_update_mapping_by_src(\n                index=index,\n                operation_id=doc[\"gulp.operation_id\"],\n                context_id=doc[\"gulp.context_id\"],\n                source_id=doc[\"gulp.source_id\"],\n                doc_ids=[doc_id],\n            )\n\n        return JSONResponse(JSendResponse.success(req_id, data=doc))\n\n    except Exception as ex:\n        raise JSendException(ex=ex, req_id=req_id)\n    finally:\n        if mod:\n            await mod.unload()\n\n\n@router.post(\n    \"/tag_documents\",\n    response_model=JSendResponse,\n    tags=[\"enrich\"],\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"pending\",\n                        \"timestamp_msec\": 1704380570434,\n                        \"req_id\": \"c4f7ae9b-1e39-416e-a78a-85264099abfb\",\n                    }\n                }\n            }\n        }\n    },\n    summary=\"Add tags to document/s.\",\n    description=\"\"\"\nTag important documents, so they can be queried back via `gulp.tags` provided via `GulpQueryFilter` as custom key.\n\n- token must have the `edit` permission.\n- `flt.operation_ids` is ignored and set to `[operation_id]`\n- the enriched documents are updated in the Gulp `index`.\n\"\"\",\n)\nasync def tag_documents_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    operation_id: Annotated[str, Depends(APIDependencies.param_operation_id)],\n    flt: Annotated[GulpQueryFilter, Depends(APIDependencies.param_query_flt_optional)],\n    tags: Annotated[list[str], Body(description=\"The tags to add.\")],\n    ws_id: Annotated[str, Depends(APIDependencies.param_ws_id)],\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSONResponse:\n    params = locals()\n    ServerUtils.dump_params(params)\n\n    try:\n        async with GulpCollab.get_instance().session() as sess:\n            # enforce operation_id\n            flt.operation_ids = [operation_id]\n\n            # get operation and check acl\n            op: GulpOperation = await GulpOperation.get_by_id(sess, operation_id)\n            s = await GulpUserSession.check_token(\n                sess, token, obj=op, permission=GulpUserPermission.EDIT\n            )\n            user_id = s.user_id\n            index = op.index\n\n            # create a stats, just to allow request canceling\n            await GulpRequestStats.create(\n                sess,\n                user_id=user_id,\n                req_id=req_id,\n                ws_id=ws_id,\n                operation_id=operation_id,\n            )\n\n        # spawn a task which runs the enrichment in a worker process\n        # run ingestion in a coroutine in one of the workers\n        MutyLogger.get_instance().debug(\"spawning tagging task ...\")\n        kwds = dict(\n            user_id=user_id,\n            req_id=req_id,\n            ws_id=ws_id,\n            index=index,\n            flt=flt,\n            tags=tags,\n        )\n\n        # print(json.dumps(kwds, indent=2))\n        async def worker_coro(kwds: dict):\n            await GulpProcess.get_instance().process_pool.apply(\n                _tag_documents_internal, kwds=kwds\n            )\n\n        await GulpRestServer.get_instance().spawn_bg_task(worker_coro(kwds))\n\n        # and return pending\n        return JSONResponse(JSendResponse.pending(req_id=req_id))\n    except Exception as ex:\n        raise JSendException(ex=ex, req_id=req_id)\n"}
{"type": "source_file", "path": "src/gulp/api/rest/db.py", "content": "import json\nfrom typing import Annotated, Optional, Union\n\nimport muty.file\nimport muty.log\nimport muty.uploadfile\nfrom fastapi import APIRouter, Body, Depends, File, Query, UploadFile\nfrom fastapi.responses import JSONResponse\nfrom muty.jsend import JSendException, JSendResponse\nfrom muty.log import MutyLogger\n\nfrom gulp.api.collab.operation import GulpOperation\nfrom gulp.api.collab.structs import (\n    GulpCollabFilter,\n    GulpRequestStatus,\n    GulpUserPermission,\n)\nfrom gulp.api.collab.user_session import GulpUserSession\nfrom gulp.api.collab_api import GulpCollab\nfrom gulp.api.opensearch.filters import GulpQueryFilter\nfrom gulp.api.opensearch_api import GulpOpenSearch\nfrom gulp.api.rest.server_utils import ServerUtils\nfrom gulp.api.rest.structs import APIDependencies\nfrom gulp.api.rest.test_values import TEST_INDEX\nfrom gulp.api.rest_api import GulpRestServer\nfrom gulp.api.ws_api import GulpRebaseDonePacket, GulpWsQueueDataType, GulpWsSharedQueue\nfrom gulp.process import GulpProcess\nfrom gulp.structs import ObjectAlreadyExists, ObjectNotFound\n\nrouter: APIRouter = APIRouter()\n\n\n@router.delete(\n    \"/opensearch_delete_index\",\n    tags=[\"db\"],\n    response_model=JSendResponse,\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"success\",\n                        \"timestamp_msec\": 1701266243057,\n                        \"req_id\": \"fb2759b8-b0a0-40cc-bc5b-b988f72255a8\",\n                        \"data\": {\n                            \"index\": \"test_operation\",\n                            \"operation_id\": \"test_operation\",\n                        },\n                    }\n                }\n            }\n        }\n    },\n    summary=\"deletes an opensearch datastream.\",\n    description=\"\"\"\ndeletes the datastream `index`, including the backing index/es and the index template.\n\n- **WARNING**: all data in the `index` will be deleted!\n- if `delete_operation` is set, the corresponding operation on the collab database is deleted if it exists..\n- `token` needs `admin` permission.\n\"\"\",\n)\nasync def opensearch_delete_index_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    index: Annotated[str, Depends(APIDependencies.param_index)],\n    delete_operation: Annotated[\n        bool,\n        Query(\n            description=\"if set, the corresponding operation (if any) on the collab database is deleted as well (default: true).\"\n        ),\n    ] = True,\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSONResponse:\n    params = locals()\n    ServerUtils.dump_params(params)\n    try:\n        async with GulpCollab.get_instance().session() as sess:\n            # we must be admin\n            s: GulpUserSession = await GulpUserSession.check_token(\n                sess, token, permission=GulpUserPermission.ADMIN\n            )\n            user_id: str = s.user_id\n            op: GulpOperation = None\n            if delete_operation:\n                # get operation\n                op = await GulpOperation.get_first_by_filter(\n                    sess, GulpCollabFilter(index=[index]), throw_if_not_found=False, user_id=user_id, user_id_is_admin=True\n                )\n                if op:\n                    # delete the operation on collab\n                    await op.delete(sess, ws_id=None, user_id=s.user_id, req_id=req_id)\n                else:\n                    MutyLogger.get_instance().warning(\n                        f\"operation with index={index} not found, skipping deletion...\"\n                    )\n\n            # delete the datastream (deletes the corresponding index and template)\n            await GulpOpenSearch.get_instance().datastream_delete(\n                ds=index, throw_on_error=True\n            )\n            return JSONResponse(\n                JSendResponse.success(\n                    req_id=req_id,\n                    data={\"index\": index, \"operation_id\": op.id if op else None},\n                )\n            )\n    except Exception as ex:\n        raise JSendException(req_id=req_id, ex=ex) from ex\n\n\n@router.get(\n    \"/opensearch_list_index\",\n    tags=[\"db\"],\n    response_model=JSendResponse,\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"success\",\n                        \"timestamp_msec\": 1734619572441,\n                        \"req_id\": \"test_req\",\n                        \"data\": [\n                            {\n                                \"name\": \"new_index\",\n                                \"count\": 7,\n                                \"indexes\": [\n                                    {\n                                        \"index_name\": \".ds-new_index-000001\",\n                                        \"index_uuid\": \"qwrMdTrgRI6fdU_SsIxbzw\",\n                                    }\n                                ],\n                                \"template\": \"new_index-template\",\n                            },\n                            {\n                                \"name\": \"test_operation\",\n                                \"count\": 7,\n                                \"indexes\": [\n                                    {\n                                        \"index_name\": \".ds-test_operation-000001\",\n                                        \"index_uuid\": \"ZUuTB5KrSw6V-JVt9jtbcw\",\n                                    }\n                                ],\n                                \"template\": \"test_operation-template\",\n                            },\n                        ],\n                    }\n                }\n            }\n        }\n    },\n    summary=\"lists available datastreams.\",\n    description=\"\"\"\nlists all the available datastreams and their backing indexes\n\n- `token` needs `admin` permission.\n\"\"\",\n)\nasync def opensearch_list_index_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSONResponse:\n    params = locals()\n    ServerUtils.dump_params(params)\n    try:\n        async with GulpCollab.get_instance().session() as sess:\n            await GulpUserSession.check_token(\n                sess, token, permission=GulpUserPermission.ADMIN\n            )\n\n        l = await GulpOpenSearch.get_instance().datastream_list()\n        return JSONResponse(JSendResponse.success(req_id=req_id, data=l))\n    except Exception as ex:\n        raise JSendException(req_id=req_id, ex=ex) from ex\n\n\nasync def _recreate_index_internal(\n    index: str, restart_processes: bool, index_template: str = None\n) -> None:\n    # reset data\n    await GulpOpenSearch.get_instance().reinit()\n    await GulpOpenSearch.get_instance().datastream_create(\n        index, index_template=index_template\n    )\n\n    if restart_processes:\n        # restart the process pool\n        await GulpProcess.get_instance().init_gulp_process()\n\n\n@router.post(\n    \"/opensearch_create_index\",\n    tags=[\"db\"],\n    response_model=JSendResponse,\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"success\",\n                        \"timestamp_msec\": 1701266243057,\n                        \"req_id\": \"fb2759b8-b0a0-40cc-bc5b-b988f72255a8\",\n                        \"data\": {\"index\": \"testidx\"},\n                    }\n                }\n            }\n        }\n    },\n    summary=\"creates or recreates the opensearch datastream `index`, including its backing index.\",\n    description=\"\"\"\n> **WARNING: ANY EXISTING DOCUMENT WILL BE ERASED !**\n\n- `token` needs `admin` permission.\n- if `index` exists, it is **deleted** and recreated unless `fail_if_exists` is set.\n- if `index_template` is provided, it is used to create the index, otherwise the default template is used.\n\"\"\",\n)\nasync def opensearch_create_index_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    index: Annotated[str, Depends(APIDependencies.param_index)],\n    index_template: Annotated[\n        Union[UploadFile, str],\n        File(\n            description=\"optional custom index template, for advanced usage only: see [here](https://opensearch.org/docs/latest/im-plugin/index-templates/)\",\n        ),\n    ] = None,\n    fail_if_exists: Annotated[\n        bool,\n        Query(\n            description=\"if set, the API fails if the index already exists (default: false).\",\n        ),\n    ] = False,\n    restart_processes: Annotated[\n        bool,\n        Query(\n            description=\"if set, the process pool is restarted as well (default: false).\",\n        ),\n    ] = False,\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSONResponse:\n    params = locals()\n    params.pop(\"index_template\", None)\n    ServerUtils.dump_params(params)\n    f: str = None\n    try:\n        async with GulpCollab.get_instance().session() as sess:\n            # op: GulpOperation = await GulpOperation.get_by_id(sess, operation_id)\n            await GulpUserSession.check_token(\n                sess, token, permission=GulpUserPermission.ADMIN\n            )\n            if fail_if_exists:\n                # check if index exists\n                if await GulpOpenSearch.get_instance().datastream_exists(index):\n                    raise ObjectAlreadyExists(f\"index {index} already exists\")\n\n            if index_template and isinstance(index_template, UploadFile):\n                # get index template from file\n                f = await muty.uploadfile.to_path(index_template)\n\n            await _recreate_index_internal(index, restart_processes, index_template=f)\n            return JSONResponse(\n                JSendResponse.success(req_id=req_id, data={\"index\": index})\n            )\n    except Exception as ex:\n        raise JSendException(req_id=req_id, ex=ex) from ex\n    finally:\n        if f is not None:\n            await muty.file.delete_file_or_dir_async(f)\n\n\nasync def postgres_reset_collab_internal(reinit: bool = False) -> None:\n    \"\"\"\n    resets the collab database.\n\n    Args:\n        reinit: if true, the whole collab database is dropped and recreated and initialized with default data (users, groups, etc. BUT not operation).\n                either, just collab objects and stats are reset.\n\n    \"\"\"\n    MutyLogger.get_instance().warning(\"resetting collab!\")\n    if reinit:\n        MutyLogger.get_instance().warning(\"drop and recreate whole collab database...\")\n        # reinit whole collab\n        collab = GulpCollab.get_instance()\n        await collab.init(main_process=True, force_recreate=True)\n        await collab.create_default_users()\n        await collab.create_default_data()\n    else:\n        MutyLogger.get_instance().warning(\"collab: leaving operation table untouched!\")\n        collab = GulpCollab.get_instance()\n        await collab.init(main_process=True)\n\n        # do not touch these tables\n        await collab.clear_tables(\n            exclude=[\n                \"operation\",\n                \"user\",\n                \"user_associations\",\n                \"user_group\",\n                \"source\",\n                \"source_fields\",\n                \"context\",\n            ]\n        )\n        await collab.create_default_data()\n\n\n@router.post(\n    \"/postgres_reset_collab\",\n    tags=[\"db\"],\n    response_model=JSendResponse,\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"success\",\n                        \"timestamp_msec\": 1701266243057,\n                        \"req_id\": \"fb2759b8-b0a0-40cc-bc5b-b988f72255a8\",\n                    }\n                }\n            }\n        }\n    },\n    summary=\"(re)creates gulp collab database.\",\n    description=\"\"\"\n> **WARNING: ALL COLLABORATION AND INDEXED DATA WILL BE ERASED IF `full_reset` IS SET**\n\n- `token` needs to have `admin` permission.\n- if `full_reset` is set, default `users` and `user groups` are recreated, a new operation must be created then using the `operation_create` API.\n- if `full_reset` is not set, the following tables are left untouched: 'operation', 'user', 'user_groups', 'user_associations', 'context', 'source', 'source_fields'.\n\"\"\",\n)\nasync def postgres_reset_collab_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    full_reset: Annotated[\n        bool,\n        Query(\n            description=\"if set, the whole collab database is cleared and also operation data on gulp's OpenSearch is DELETED as well.\",\n        ),\n    ] = False,\n    restart_processes: Annotated[\n        bool,\n        Query(\n            description=\"if true, the process pool is restarted as well.\",\n        ),\n    ] = True,\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSONResponse:\n    ServerUtils.dump_params(locals())\n    try:\n        async with GulpCollab.get_instance().session() as sess:\n            s: GulpUserSession = await GulpUserSession.check_token(\n                sess, token, permission=GulpUserPermission.ADMIN\n            )\n            user_id = s.user_id\n            if full_reset:\n                # check if we have operations\n                ops = await GulpOperation.get_by_filter(\n                    sess,\n                    throw_if_not_found=False,\n                    user_id=user_id,\n                    user_id_is_admin=True,  # user can't be other than admin here\n                )\n                if ops:\n                    # delete all indexes\n                    for op in ops:\n                        # delete index data\n                        MutyLogger.get_instance().debug(\n                            \"operation=%s, deleting index=%s ...\" % (op.id, op.index)\n                        )\n                        await GulpOpenSearch.get_instance().datastream_delete(\n                            ds=op.index, throw_on_error=False\n                        )\n\n        if full_reset:\n            # reinit whole collab\n            await postgres_reset_collab_internal(reinit=True)\n        else:\n            # do not delete operations\n            await postgres_reset_collab_internal(reinit=False)\n\n        if restart_processes:\n            # restart the process pool\n            await GulpProcess.get_instance().init_gulp_process()\n\n        return JSONResponse(JSendResponse.success(req_id=req_id))\n    except Exception as ex:\n        raise JSendException(req_id=req_id, ex=ex) from ex\n\n\n@router.post(\n    \"/gulp_reset\",\n    tags=[\"db\"],\n    response_model=JSendResponse,\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"success\",\n                        \"timestamp_msec\": 1701266243057,\n                        \"req_id\": \"fb2759b8-b0a0-40cc-bc5b-b988f72255a8\",\n                    }\n                }\n            }\n        }\n    },\n    summary=\"reset whole gulp's OpenSearch and PostgreSQL storages.\",\n    description=\"\"\"\n> **WARNING: ALL COLLABORATION AND INDEXED DATA WILL BE ERASED AND DEFAULT USERS/DATA RECREATED ON THE COLLAB DATABASE**\n\n- `token` needs to have `admin` permission.\n\"\"\",\n)\nasync def gulp_reset_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSONResponse:\n    ServerUtils.dump_params(locals())\n\n    try:\n        # reset collab\n        await postgres_reset_collab_handler(\n            token, full_reset=True, restart_processes=False, req_id=req_id\n        )\n\n        # create default index and operation\n        collab = GulpCollab.get_instance()\n\n        # recreate gulp test index\n        await _recreate_index_internal(TEST_INDEX, restart_processes=True)\n\n        # recreate default operation\n        await collab.create_default_operation()\n        return JSONResponse(JSendResponse.success(req_id=req_id))\n    except Exception as ex:\n        raise JSendException(req_id=req_id, ex=ex) from ex\n\n\nasync def _rebase_internal(\n    user_id: str,\n    req_id: str,\n    ws_id: str,\n    operation_id: str,\n    index: str,\n    dest_index: str,\n    offset_msec: int,\n    flt: GulpQueryFilter,\n    rebase_script: str,\n):\n    \"\"\"\n    runs in a worker process to rebase the index.\n    \"\"\"\n    try:\n        # get existing index datastream\n        template = await GulpOpenSearch.get_instance().index_template_get(index)\n\n        # create the destination datastream, applying the same template\n        await GulpOpenSearch.get_instance().datastream_create_from_raw_dict(\n            dest_index, template\n        )\n\n        # rebase\n        res = await GulpOpenSearch.get_instance().rebase(\n            index,\n            dest_index=dest_index,\n            offset_msec=offset_msec,\n            flt=flt,\n            rebase_script=rebase_script,\n        )\n\n        # the operation object must now point to the new index\n        async with GulpCollab.get_instance().session() as sess:\n            op: GulpOperation = await GulpOperation.get_by_id(\n                sess, operation_id, with_for_update=True\n            )\n            d = {\n                \"index\": dest_index,\n            }\n        await op.update(\n            sess,\n            d,\n            ws_id=None,  # do not propagate on the websocket\n            req_id=req_id,\n            user_id=user_id,\n        )\n\n    except Exception as ex:\n        # signal failure on the websocket\n        MutyLogger.get_instance().exception(ex)\n        GulpWsSharedQueue.get_instance().put(\n            type=GulpWsQueueDataType.REBASE_DONE,\n            ws_id=ws_id,\n            user_id=user_id,\n            operation_id=operation_id,\n            req_id=req_id,\n            data=GulpRebaseDonePacket(\n                operation_id=operation_id,\n                src_index=index,\n                dest_index=dest_index,\n                status=GulpRequestStatus.FAILED,\n                result=muty.log.exception_to_string(ex),\n            ),\n        )\n        return\n\n    # done\n    MutyLogger.get_instance().debug(\n        \"rebase done, result=%s\" % (json.dumps(res, indent=2))\n    )\n    # signal the websocket\n    GulpWsSharedQueue.get_instance().put(\n        type=GulpWsQueueDataType.REBASE_DONE,\n        ws_id=ws_id,\n        user_id=user_id,\n        req_id=req_id,\n        operation_id=operation_id,\n        data=GulpRebaseDonePacket(\n            operation_id=operation_id,\n            src_index=index,\n            dest_index=dest_index,\n            status=GulpRequestStatus.DONE,\n            result=res,\n        ),\n    )\n\n\n@router.post(\n    \"/opensearch_rebase_index\",\n    response_model=JSendResponse,\n    tags=[\"db\"],\n    response_model_exclude_none=True,\n    responses={\n        200: {\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"status\": \"pending\",\n                        \"timestamp_msec\": 1704380570434,\n                        \"req_id\": \"c4f7ae9b-1e39-416e-a78a-85264099abfb\",\n                    }\n                }\n            }\n        }\n    },\n    summary=\"rebases operation's index to a different time.\",\n    description=\"\"\"\nrebases `operation_id.index` and creates a new `dest_index` with rebased `@timestamp` + `offset`, then set the operation's index to `dest_index` on success.\n\n- `token` needs `ingest` permission.\n- `flt` may be used to filter the documents to rebase.\n- rebase happens in the background: when it is done, a `GulpWsQueueDataType.REBASE_DONE` event is sent to the `ws_id` websocket.\n\"\"\",\n)\nasync def opensearch_rebase_index_handler(\n    token: Annotated[str, Depends(APIDependencies.param_token)],\n    operation_id: Annotated[str, Depends(APIDependencies.param_operation_id)],\n    dest_index: Annotated[\n        str,\n        Query(\n            description=\"name of the destination index, will be reset or created if not exists.\",\n            example=\"new_index\",\n        ),\n    ],\n    offset_msec: Annotated[\n        int,\n        Query(\n            example=3600000,\n            description=\"\"\"offset in milliseconds to add to document `@timestamp` and `gulp.timestamp`.\n\n- to subtract, use a negative offset.\n\"\"\",\n        ),\n    ],\n    ws_id: Annotated[str, Depends(APIDependencies.param_ws_id)],\n    flt: Annotated[str, Depends(APIDependencies.param_query_flt_optional)] = None,\n    rebase_script: Annotated[\n        str,\n        Body(\n            description=\"\"\"\noptional custom rebase script to run on the documents.\n\n- must be a [painless script](https://www.elastic.co/guide/en/elasticsearch/painless/current/painless-guide.html).\n- the script receives as input a single parameter `offset_nsec`, the offset in `nanoseconds from the unix epoch` to be applied to the fields during the rebase operation.\n- the example script is the one applied by default (rebases `@timestamp` and `gulp.timestamp`).\n\"\"\",\n            examples=[\n                \"\"\"if (ctx._source['@timestamp'] != 0) {\n    def ts = ZonedDateTime.parse(ctx._source['@timestamp']);\n    def new_ts = ts.plusNanos(params.offset_nsec);\n    ctx._source['@timestamp'] = new_ts.toString();\n    ctx._source[\"gulp.timestamp\"] += params.offset_nsec;\n}\"\"\"\n            ],\n        ),\n    ] = None,\n    req_id: Annotated[str, Depends(APIDependencies.ensure_req_id)] = None,\n) -> JSendResponse:\n    params = locals()\n    params[\"flt\"] = flt.model_dump(exclude_none=True, exclude_defaults=True)\n    ServerUtils.dump_params(params)\n\n    try:\n        async with GulpCollab.get_instance().session() as sess:\n            # check permission and get user id and index\n            op: GulpOperation = await GulpOperation.get_by_id(sess, operation_id)\n            s = await GulpUserSession.check_token(\n                sess, token, obj=op, permission=GulpUserPermission.INGEST\n            )\n            user_id = s.user_id\n            index = op.index\n\n        if index == dest_index:\n            raise JSendException(\n                req_id=req_id,\n                ex=Exception(\n                    \"index and dest_index must be different! (index=%s, dest_index=%s)\"\n                    % (index, dest_index)\n                ),\n            )\n\n        # spawn a task which runs the rebase in a worker process\n        kwds = dict(\n            user_id=user_id,\n            req_id=req_id,\n            ws_id=ws_id,\n            operation_id=operation_id,\n            index=index,\n            dest_index=dest_index,\n            offset_msec=offset_msec,\n            flt=flt,\n            rebase_script=rebase_script,\n        )\n\n        async def worker_coro(kwds: dict):\n            await GulpProcess.get_instance().process_pool.apply(\n                _rebase_internal, kwds=kwds\n            )\n\n        await GulpRestServer.get_instance().spawn_bg_task(worker_coro(kwds))\n\n        # and return pending\n        return JSONResponse(JSendResponse.pending(req_id=req_id))\n    except Exception as ex:\n        raise JSendException(ex=ex, req_id=req_id)\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/stored_query.py", "content": "from gulp.api.collab.structs import GulpCollabFilter\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPIStoredQuery:\n    \"\"\"\n    Bindings to call gulp's stored query related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def stored_query_create(\n        token: str,\n        name: str,\n        q: str,\n        q_groups: list[str] = None,\n        plugin: str = None,\n        plugin_params: dict = None,\n        tags: list[str] = None,\n        description: str = None,\n        glyph_id: str = None,\n        private: bool = False,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"Create a new stored query\"\"\"\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"name\": name,\n            \"req_id\": req_id or api_common.req_id,\n            \"plugin\": plugin,\n            \"glyph_id\": glyph_id,\n            \"private\": private,\n        }\n\n        body = {\n            \"q\": q,\n            \"q_groups\": q_groups,\n            \"tags\": tags,\n            \"description\": description,\n            \"plugin_params\": plugin_params,\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"stored_query_create\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def stored_query_update(\n        token: str,\n        object_id: str,\n        name: str = None,\n        q: str = None,\n        q_groups: list[str] = None,\n        plugin: str = None,\n        plugin_params: dict = None,\n        tags: list[str] = None,\n        description: str = None,\n        glyph_id: str = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"Update an existing stored query\"\"\"\n        api_common = GulpAPICommon.get_instance()\n        params = {\n            \"object_id\": object_id,\n            \"name\": name,\n            \"plugin\": plugin,\n            \"req_id\": req_id or api_common.req_id,\n            \"glyph_id\": glyph_id,\n        }\n\n        body = {\n            \"q\": q,\n            \"q_groups\": q_groups,\n            \"tags\": tags,\n            \"plugin_params\": plugin_params,\n            \"description\": description,\n        }\n\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"stored_query_update\",\n            params=params,\n            body=body,\n            token=token,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def stored_query_delete(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"Delete a stored query\"\"\"\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_delete(\n            token=token,\n            object_id=object_id,\n            api=\"stored_query_delete\",\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def stored_query_get_by_id(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"Get stored query by ID\"\"\"\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_get_by_id(\n            token=token,\n            object_id=object_id,\n            req_id=req_id,\n            api=\"stored_query_get_by_id\",\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def stored_query_list(\n        token: str,\n        flt: GulpCollabFilter = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> list[dict]:\n        \"\"\"List stored queries\"\"\"\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_list(\n            token=token,\n            api=\"stored_query_list\",\n            flt=flt,\n            req_id=req_id,\n            expected_status=expected_status,\n        )\n"}
{"type": "source_file", "path": "src/gulp/api/rest/client/utility.py", "content": "import io\nimport os\n\nfrom gulp.api.rest.client.common import GulpAPICommon\n\n\nclass GulpAPIUtility:\n    \"\"\"\n    bindings to call gulp's utility related API endpoints\n    \"\"\"\n\n    @staticmethod\n    async def server_restart(\n        token: str, req_id: str = None, expected_status: int = 200\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"server_restart\",\n            params={\"req_id\": req_id or api_common.req_id},\n            token=token,\n            body=None,\n            expected_status=expected_status,\n        )\n\n        return res\n\n    @staticmethod\n    async def trigger_gc(\n        token: str,\n        gulp_only: bool = True,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"server_status\",\n            params={\"gulp_only\": gulp_only, \"req_id\": req_id or api_common.req_id},\n            token=token,\n            expected_status=expected_status,\n        )\n\n        return res\n\n    @staticmethod\n    async def server_status(\n        token: str,\n        gulp_only: bool = True,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        res = await api_common.make_request(\n            \"GET\",\n            \"server_status\",\n            params={\"gulp_only\": gulp_only, \"req_id\": req_id or api_common.req_id},\n            token=token,\n            expected_status=expected_status,\n        )\n\n        return res\n\n    @staticmethod\n    async def request_get_by_id(\n        token: str,\n        object_id: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        \"\"\"Get stored query by ID\"\"\"\n        api_common = GulpAPICommon.get_instance()\n        return await api_common.object_get_by_id(\n            token=token,\n            object_id=object_id,\n            req_id=req_id,\n            api=\"request_get_by_id\",\n            expected_status=expected_status,\n        )\n\n    @staticmethod\n    async def request_cancel(\n        token: str,\n        req_id_to_cancel: str,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        res = await api_common.make_request(\n            \"PATCH\",\n            \"plugin_list\",\n            {\n                \"req_id_to_cancel\": req_id_to_cancel,\n                \"req_id\": req_id or api_common.req_id,\n            },\n            token=token,\n            body=None,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def request_list(\n        token: str,\n        operation_id: str = None,\n        running_only: bool = None,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        res = await api_common.make_request(\n            \"GET\",\n            \"request_list\",\n            {\n                \"operation_id\": operation_id,\n                \"running_only\": running_only,\n                \"req_id\": req_id or api_common.req_id,\n            },\n            token=token,\n            body=None,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def plugin_list(\n        token: str, req_id: str = None, expected_status: int = 200\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n        res = await api_common.make_request(\n            \"GET\",\n            \"plugin_list\",\n            {\"req_id\": req_id or api_common.req_id},\n            token=token,\n            body=None,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def plugin_get(\n        token: str,\n        plugin: str,\n        is_extension: bool = False,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"plugin\": plugin,\n            \"is_extension\": is_extension,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        res = await api_common.make_request(\n            \"GET\",\n            \"plugin_get\",\n            params=params,\n            token=token,\n            body=None,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def plugin_delete(\n        token: str,\n        plugin: str,\n        is_extension: bool = False,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"plugin\": plugin,\n            \"is_extension\": is_extension,\n            \"req_id\": req_id or api_common.req_id,\n        }\n\n        \"\"\"Delete plugin\"\"\"\n        res = await api_common.make_request(\n            \"DELETE\",\n            \"plugin_delete\",\n            params=params,\n            token=token,\n            body=None,\n            expected_status=expected_status,\n        )\n        return res\n\n    @staticmethod\n    async def plugin_upload(\n        token: str,\n        plugin_path: str,\n        allow_overwrite: bool = False,\n        is_extension: bool = False,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        filename = os.path.basename(plugin_path)\n        params = {\n            \"filename\": filename,\n            \"is_extension\": is_extension,\n            \"req_id\": req_id or api_common.req_id,\n            \"allow_overwrite\": allow_overwrite,\n        }\n\n        files = {\n            \"plugin\": (\n                filename,\n                open(plugin_path, \"rb\"),\n                \"application/octet-stream\",\n            ),\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"plugin_upload\",\n            params=params,\n            token=token,\n            files=files,\n            expected_status=expected_status,\n        )\n\n        return res\n\n    @staticmethod\n    async def version(\n        token: str, req_id: str = None, expected_status: int = 200\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        \"\"\"Get gulp version\"\"\"\n        res = await api_common.make_request(\n            \"GET\",\n            \"version\",\n            params={\"req_id\": req_id or api_common.req_id},\n            token=token,\n            body=None,\n            expected_status=expected_status,\n        )\n\n        return res\n\n    @staticmethod\n    async def mapping_file_list(\n        token: str, req_id: str = None, expected_status: int = 200\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        res = await api_common.make_request(\n            \"GET\",\n            \"mapping_file_list\",\n            params={\"req_id\": req_id or api_common.req_id},\n            token=token,\n            body=None,\n            expected_status=expected_status,\n        )\n\n        return res\n\n    @staticmethod\n    async def mapping_file_get(\n        token: str, mapping_file: str, req_id: str = None, expected_status: int = 200\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\"mapping_file\": mapping_file, \"req_id\": req_id or api_common.req_id}\n\n        res = await api_common.make_request(\n            \"GET\",\n            \"mapping_file_get\",\n            token=token,\n            params=params,\n            body=None,\n            expected_status=expected_status,\n        )\n\n        return res\n\n    @staticmethod\n    async def mapping_file_delete(\n        token: str, mapping_file: str, req_id: str = None, expected_status: int = 200\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\"mapping_file\": mapping_file, \"req_id\": req_id or api_common.req_id}\n        res = await api_common.make_request(\n            \"DELETE\",\n            \"mapping_file_delete\",\n            token=token,\n            params=params,\n            body=None,\n            expected_status=expected_status,\n        )\n\n        return res\n\n    @staticmethod\n    async def mapping_file_upload(\n        token: str,\n        mapping_file_path: str,\n        allow_overwrite: bool = False,\n        req_id: str = None,\n        expected_status: int = 200,\n    ) -> dict:\n        api_common = GulpAPICommon.get_instance()\n\n        params = {\n            \"allow_overwrite\": allow_overwrite,\n            req_id: req_id or api_common.req_id,\n        }\n\n        filename = os.path.basename(mapping_file_path)\n\n        files = {\n            \"mapping_file\": (\n                filename,\n                open(mapping_file_path, \"rb\"),\n                \"application/octet-stream\",\n            ),\n        }\n\n        res = await api_common.make_request(\n            \"POST\",\n            \"mapping_file_upload\",\n            token=token,\n            params=params,\n            files=files,\n            body=None,\n            expected_status=expected_status,\n        )\n\n        return res\n"}
