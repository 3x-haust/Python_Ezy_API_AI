{"repo_info": {"repo_name": "raggenie", "repo_owner": "sirocco-ventures", "repo_url": "https://github.com/sirocco-ventures/raggenie"}}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/functional/test_llmchat.py", "content": "import pytest\nfrom unittest.mock import patch\nfrom fastapi.testclient import TestClient\n\n@pytest.mark.usefixtures(\"client\")\nclass TestLLMChat:\n\n    # Fixture to provide a sample chat payload for tests\n    @pytest.fixture\n    def chat_payload(self):\n        return {\n            \"chat_context_id\": \"context_1\",\n            \"chat_query\": \"What is AI?\",\n            \"chat_answer\": {\"response\": \"Artificial Intelligence\"},\n            \"chat_summary\": \"Summary\",\n            \"user_id\": 123,\n            \"primary_chat\": True\n        }\n\n    # Fixture to provide a sample feedback payload for tests\n    @pytest.fixture\n    def feedback_payload(self):\n        return {\n            \"chat_context_id\": \"context_1\",\n            \"chat_id\": 1,\n            \"feedback_status\": 1,\n            \"feedback_json\": {\"feedback\": \"Good\"}\n        }\n\n    # Test case for creating a chat\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            ({\"chat_id\": 1}, None, {\n                \"status\": True,\n                \"status_code\": 201,\n                \"message\": \"Chat created successfully\",\n                \"data\": {\"chat\": {\"chat_id\": 1}},\n                \"error\": None\n            }, 200),\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB Error\",\n                \"data\": {\"chat\": {}},\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.llmchat.create_chat')  # Mock the create_chat function\n    def test_create_chat(self, mock_create_chat, client: TestClient, chat_payload, mock_return_value, error, expected_response, expected_status_code):\n        mock_create_chat.return_value = (mock_return_value, error)  # Set mock return values\n\n        response = client.post(\"/api/v1/chat/create\", json=chat_payload)  # Make POST request\n\n        # Assertions to verify the response status code and body\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Test case for creating feedback\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            ({\"chat_id\": 1}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Feedback updated successfully\",\n                \"data\": {\"chat\": {\"chat_id\": 1}},\n                \"error\": None\n            }, 200),\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB Error\",\n                \"data\": {\"chat\": {}},\n                \"error\": \"DB Error\"\n            }, 200),\n            (None, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Chat Not Found\",\n                \"data\": {\"chat\": {}},\n                \"error\": \"Not Found\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.llmchat.create_feedback')  # Mock the create_feedback function\n    def test_create_feedback(self, mock_create_feedback, client: TestClient, feedback_payload, mock_return_value, error, expected_response, expected_status_code):\n        mock_create_feedback.return_value = (mock_return_value, error)  # Set mock return values\n\n        response = client.post(\"/api/v1/chat/feedback/create\", json=feedback_payload)  # Make POST request\n\n        # Assertions to verify the response status code and body\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Test case for listing chats by context\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            ([{\"key\": \"value\"}], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Primary chats found\",\n                \"data\": {\"chats\": [{\"key\": \"value\"}]},\n                \"error\": None\n            }, 200),\n            ([], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Context Not found\",\n                \"data\": {\"chats\": []},\n                \"error\": \"Not Found\"\n            }, 200),\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB Error\",\n                \"data\": {\"chats\": []},\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.llmchat.list_chats_by_context')  # Mock the list_chats_by_context function\n    def test_list_chats_by_context(self, mock_list_chats_by_context, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        mock_list_chats_by_context.return_value = (mock_return_value, error)  # Set mock return values\n\n        response = client.get(\"/api/v1/chat/list/context/all\")  # Make GET request\n\n        # Assertions to verify the response status code and body\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Test case for getting chat by context ID\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            ([{\"key\": \"value\"}], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Chat found\",\n                \"data\": {\"chats\": [{\"key\": \"value\"}]},\n                \"error\": None\n            }, 200),\n            ([], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Chat not found\",\n                \"data\": {\"chats\": []},\n                \"error\": \"Not Found\"\n            }, 200),\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB Error\",\n                \"data\": {\"chats\": []},\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.llmchat.list_all_chats_by_context_id')  # Mock the list_all_chats_by_context_id function\n    def test_get_chat_by_context(self, mock_list_all_chats_by_context_id, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        mock_list_all_chats_by_context_id.return_value = (mock_return_value, error)  # Set mock return values\n\n        response = client.get(\"/api/v1/chat/get/context_1\")  # Make GET request\n\n        # Assertions to verify the response status code and body\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n"}
{"type": "test_file", "path": "tests/functional/test_connectors.py", "content": "import pytest\nfrom unittest.mock import patch\nfrom fastapi.testclient import TestClient\n\n# Use the pytest fixture for the FastAPI test client\n@pytest.mark.usefixtures(\"client\")\nclass TestConnectorAPI:\n\n    # Parameterized test for listing connectors\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: valid connector data returned\n            ([{\"id\": 1, \"name\": \"Connector A\"}], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"connectors\": [{\"id\": 1, \"name\": \"Connector A\"}]},\n                \"message\": \"Connectors Found\",\n                \"error\": None\n            }, 200),\n            # Empty connector case: no connectors found\n            ([], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"connectors\": []},\n                \"message\": \"Connector Not Found\",\n                \"error\": \"Not Found\"\n            }, 200),\n            # Database error case: simulate a database error\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"data\": {\"connectors\": []},\n                \"message\": \"DB Error\",\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.list_connectors')\n    def test_list_connectors(self, mock_list_connectors, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the list_connectors service to return the specified value and error\n        mock_list_connectors.return_value = (mock_return_value, error)\n\n        # Make a GET request to the list connectors endpoint\n        response = client.get(\"/api/v1/connector/list\")\n\n        # Assert the response status code and content\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Parameterized test for getting a specific connector\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: valid connector data returned\n            ({\"id\": 1, \"name\": \"Connector A\"}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"connector\": {\"id\": 1, \"name\": \"Connector A\"}},\n                \"message\": \"Connector Found\",\n                \"error\": None\n            }, 200),\n            # Connector not found case: empty response\n            ({}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"connector\": {}},\n                \"message\": \"Connector Not Found\",\n                \"error\": \"Not Found\"\n            }, 200),\n            # Database error case: simulate a database error\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"data\": {\"connector\": {}},\n                \"message\": \"DB Error\",\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.get_connector')\n    def test_get_connector(self, mock_get_connector, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the get_connector service to return the specified value and error\n        mock_get_connector.return_value = (mock_return_value, error)\n\n        # Make a GET request to the get connector endpoint\n        response = client.get(\"/api/v1/connector/get/1\")\n\n        # Assert the response status code and content\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Parameterized test for creating a new connector\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: valid connector creation\n            ({\"id\": 1, \"name\": \"Connector A\", \"type\": 1, \"config\": {\"type\": \"Config A\"}}, None, {\n                \"status\": True,\n                \"status_code\": 201,\n                \"data\": {\"connector\": {\"id\": 1, \"name\": \"Connector A\", \"type\": 1, \"config\": {\"type\": \"Config A\"}}},\n                \"message\": \"Connector Created\",\n                \"error\": None\n            }, 200),\n            # Database error case: simulate a database error\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"data\": {\"connector\": {}},\n                \"message\": \"Connector Not Created\",\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.create_connector')\n    def test_create_connector(self, mock_create_connector, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the create_connector service to return the specified value and error\n        mock_create_connector.return_value = (mock_return_value, error)\n\n        # Make a POST request to the create connector endpoint with the connector data\n        response = client.post(\"/api/v1/connector/create\", json={\n            \"name\": \"Connector A\",\n            \"connector_type\": 1,\n            \"connector_name\": \"Connector A\",\n            \"connector_config\": {\"type\": \"Config A\"}\n        })\n\n        # Assert the response status code and content\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Parameterized test for updating an existing connector\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: valid connector updated\n            ({\"id\": 1, \"name\": \"Connector A\"}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"connector\": {\"id\": 1, \"name\": \"Connector A\"}},\n                \"message\": \"Connector Updated\",\n                \"error\": None\n            }, 200),\n            # Connector not found case: no connector returned\n            (None, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"connector\": {}},\n                \"message\": \"Connector Not Found\",\n                \"error\": \"Not Found\"\n            }, 200),\n            # Database error case: simulate a database error\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"data\": {\"connector\": {}},\n                \"message\": \"DB Error\",\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.update_connector')\n    def test_update_connector(self, mock_update_connector, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the update_connector service to return the specified value and error\n        mock_update_connector.return_value = (mock_return_value, error)\n\n        # Make a POST request to the update connector endpoint with the updated data\n        response = client.post(\"/api/v1/connector/update/1\", json={\"name\": \"Connector A\"})\n\n        # Assert the response status code and content\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Parameterized test for deleting a connector\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: valid connector deleted\n            ({\"id\": 1, \"name\": \"Connector A\"}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"connector\": {\"id\": 1, \"name\": \"Connector A\"}},\n                \"message\": \"Connector Deleted\",\n                \"error\": None\n            }, 200),\n            # Connector not found case: no connector returned\n            (None, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"connector\": {}},\n                \"message\": \"Connector Not Found\",\n                \"error\": \"Not Found\"\n            }, 200),\n            # Database error case: simulate a database error\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"data\": {\"connector\": {}},\n                \"message\": \"DB Error\",\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.delete_connector')\n    def test_delete_connector(self, mock_delete_connector, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the delete_connector service to return the specified value and error\n        mock_delete_connector.return_value = (mock_return_value, error)\n\n        # Make a DELETE request to the delete connector endpoint\n        response = client.delete(\"/api/v1/connector/delete/1\")\n\n        # Assert the response status code and content\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Parameterized test for the update_schemas function\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case\n            ({\"id\": 1, \"schema_config\": [{\"key\": \"value\"}]}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"schemas\": {\"id\": 1, \"schema_config\": [{\"key\": \"value\"}]}},\n                \"message\": \"Schema Updated\",\n                \"error\": None\n            }, 200),\n            # Connector not found case\n            (None, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"schemas\": {}},\n                \"message\": \"Connector Not Found\",\n                \"error\": \"Not Found\"\n            }, 200),\n            # Database error case\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"data\": {\"schemas\": {}},\n                \"message\": \"DB Error\",\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.updateschemas')  # Mock the updateschemas function\n    def test_update_schemas(self, mock_updateschemas, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        mock_updateschemas.return_value = (mock_return_value, error)  # Set mock return value\n\n        # Make a POST request to update schemas\n        response = client.post(\"/api/v1/connector/schema/update/1\", json={\n            \"schema_config\": [{\"key\": \"value\"}]\n        })\n\n        # Assert the status code and response JSON\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Parameterized test for the list_configurations function\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case\n            ([{\"id\": 1, \"name\": \"Config A\"}], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Configurations retrieved successfully\",\n                \"error\": None,\n                \"data\": {\"configurations\": [{\"id\": 1, \"name\": \"Config A\"}]}\n            }, 200),\n            # No configurations found case\n            ([], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Configurations Not Found\",\n                \"error\": \"Not Found\",\n                \"data\": {\"configurations\": []}\n            }, 200),\n            # Database error case\n            (\"DB error\", \"DB error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB error\",\n                \"error\": \"DB error\",\n                \"data\": {\"configurations\": []}\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.list_configurations')  # Mock the list_configurations function\n    def test_list_configurations(self, mock_list_configurations, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        mock_list_configurations.return_value = (mock_return_value, error)  # Set mock return value\n\n        # Make a GET request to list configurations\n        response = client.get(\"/api/v1/connector/configuration/list\")\n\n        # Assert the status code and response JSON\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Parameterized test for the create_configuration function\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case\n            ({\"id\": 1, \"name\": \"Config A\"}, None, {\n                \"status\": True,\n                \"status_code\": 201,\n                \"message\": \"Configuration created successfully\",\n                \"error\": None,\n                \"data\": {\"configuration\": {\"id\": 1, \"name\": \"Config A\"}}\n            }, 200),\n            # Database error case\n            (\"DB error\", \"DB error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB error\",\n                \"error\": \"DB error\",\n                \"data\": {\"configuration\": []}\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.create_configuration')  # Mock the create_configuration function\n    def test_create_configuration(self, mock_create_configuration, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        mock_create_configuration.return_value = (mock_return_value, error)  # Set mock return value\n\n        # Make a POST request to create a new configuration\n        response = client.post(\"/api/v1/connector/configuration/create\", json={\n            \"name\": \"Config A\",\n            \"short_description\": \"Short description\",\n            \"long_description\": \"Long description\",\n            \"status\": 1,\n            \"capabilities\": [1, 2]\n        })\n\n        # Assert the status code and response JSON\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    # Parameterized test for the update_configuration function\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case\n            ({\"id\": 1, \"name\": \"Config A\"}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Configuration updated successfully\",\n                \"error\": None,\n                \"data\": {\"configuration\": {\"id\": 1, \"name\": \"Config A\"}}\n            }, 200),\n            # Database error case\n            (\"DB error\", \"DB error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB error\",\n                \"error\": \"DB error\",\n                \"data\": {\"configuration\": []}\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.update_configuration')  # Mock the update_configuration function\n    def test_update_configuration(self, mock_update_configuration, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        mock_update_configuration.return_value = (mock_return_value, error)  # Set mock return value\n\n        # Make a POST request to update a configuration\n        response = client.post(\"/api/v1/connector/configuration/update/1\", json={\n            \"name\": \"Config A Updated\",\n            \"short_description\": \"Updated short description\",\n            \"long_description\": \"Updated long description\",\n            \"status\": 1\n        })\n\n        # Assert the status code and response JSON\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: A capability is created successfully\n            ({\"id\": 1, \"name\": \"Capability A\"}, None, {\n                \"status\": True,\n                \"status_code\": 201,\n                \"message\": \"Capabilities created successfully\",\n                \"error\": None,\n                \"data\": {\"capability\": {\"id\": 1, \"name\": \"Capability A\"}}\n            }, 200),\n            # Database error case: Simulating a database error during capability creation\n            (\"DB error\", \"DB error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB error\",\n                \"error\": \"DB error\",\n                \"data\": {\"capability\": {}}\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.create_capabilities')\n    def test_create_capability(self, mock_create_capabilities, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the create_capabilities function to return the specified mock_return_value and error\n        mock_create_capabilities.return_value = (mock_return_value, error)\n\n        # Send a POST request to create a new capability\n        response = client.post(\"/api/v1/capability/create\", json={\n            \"name\": \"Capability A\",\n            \"description\": \"Description for Capability A\",\n            \"requirements\": [{\"key\": \"value\"}]\n        })\n\n        # Assert that the response status code and JSON match the expected values\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: List of capabilities is retrieved successfully\n            ([{\"id\": 1, \"name\": \"Capability A\"}], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Capabilities retrieved successfully\",\n                \"error\": None,\n                \"data\": {\"capabilities\": [{\"id\": 1, \"name\": \"Capability A\"}]}\n            }, 200),\n            # Database error case: Simulating a database error while retrieving capabilities\n            (\"DB error\", \"DB error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB error\",\n                \"error\": \"DB error\",\n                \"data\": {\"capabilities\": []}\n            }, 200),\n            # Not found case: No capabilities are found\n            ([], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Capabilities Not Found\",\n                \"error\": \"Not Found\",\n                \"data\": {\"capabilities\": []}\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.get_all_capabilities')\n    def test_list_capabilities(self, mock_get_all_capabilities, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the get_all_capabilities function to return the specified mock_return_value and error\n        mock_get_all_capabilities.return_value = (mock_return_value, error)\n\n        # Send a GET request to retrieve all capabilities\n        response = client.get(\"/api/v1/capability/all\")\n\n        # Assert that the response status code and JSON match the expected values\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: A capability is updated successfully\n            ({\"id\": 1, \"name\": \"Capability A Updated\"}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Capability updated successfully\",\n                \"error\": None,\n                \"data\": {\"capability\": {\"id\": 1, \"name\": \"Capability A Updated\"}}\n            }, 200),\n            # Database error case: Simulating a database error during capability update\n            (\"DB error\", \"DB error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB error\",\n                \"error\": \"DB error\",\n                \"data\": {\"capability\": {}}\n            }, 200),\n            # Not found case: Capability not found during update\n            (None, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Capability Not Found\",\n                \"error\": \"Not Found\",\n                \"data\": {\"capability\": {}}\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.update_capability')\n    def test_update_capability(self, mock_update_capability, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the update_capability function to return the specified mock_return_value and error\n        mock_update_capability.return_value = (mock_return_value, error)\n\n        # Send a POST request to update a capability\n        response = client.post(\"/api/v1/capability/update/1\", json={\n            \"name\": \"Capability A Updated\",\n            \"description\": \"Updated description\",\n            \"requirements\": [{\"key\": \"new_value\"}]\n        })\n\n        # Assert that the response status code and JSON match the expected values\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: A capability is deleted successfully\n            ({\"id\": 1, \"name\": \"Capability\"}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Capability deleted successfully\",\n                \"error\": None,\n                \"data\": {\"capability\": {}}\n            }, 200),\n            # Database error case: Simulating a database error during capability deletion\n            (\"DB error\", \"DB error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"DB error\",\n                \"error\": \"DB error\",\n                \"data\": {\"capability\": {}}\n            }, 200),\n            # Not found case: Capability not found during deletion\n            (None, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Capability Not Found\",\n                \"error\": \"Not Found\",\n                \"data\": {\"capability\": {}}\n            }, 200)\n        ]\n    )\n    @patch('app.services.connector.delete_capability')\n    def test_delete_capability(self, mock_delete_capability, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Mock the delete_capability function to return the specified mock_return_value and error\n        mock_delete_capability.return_value = (mock_return_value, error)\n\n        # Send a DELETE request to delete a capability\n        response = client.delete(\"/api/v1/capability/delete/1\")\n\n        # Assert that the response status code and JSON match the expected values\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n"}
{"type": "test_file", "path": "tests/functional/test_provider.py", "content": "import pytest\nfrom unittest.mock import patch\nfrom fastapi.testclient import TestClient\nfrom app.schemas.provider import CredentialsHelper\n\n# Use fixtures for client management in tests\n@pytest.mark.usefixtures(\"client\")\nclass TestProviderAPI:\n\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: provider found\n            ([{\"id\": 1, \"name\": \"Provider A\"}], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"providers\": [{\"id\": 1, \"name\": \"Provider A\"}]},\n                \"message\": \"Providers Found\",\n                \"error\": None\n            }, 200),\n            # Empty provider case: no providers found\n            ([], None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"providers\": []},\n                \"message\": \"Providers Not Found\",\n                \"error\": \"Not Found\"\n            }, 200),\n            # Database error case: simulates a database error\n            (\"SQL Error\", \"DB error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"data\": {\"providers\": []},\n                \"message\": \"DB error\",\n                \"error\": \"SQL Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.provider.list_providers')  # Mock the list_providers function\n    def test_list_providers(self, mock_list_providers, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Set the mock return value for list_providers\n        mock_list_providers.return_value = (mock_return_value, error)\n\n        # Send a GET request to the endpoint\n        response = client.get(\"/api/v1/provider/list\")\n\n        # Assert the status code and response data match expected values\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: specific provider found\n            ({\"id\": 1, \"name\": \"Provider A\"}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"provider\": {\"id\": 1, \"name\": \"Provider A\"}},\n                \"message\": \"Provider Found\",\n                \"error\": None\n            }, 200),\n            # Provider not found case: no provider data returned\n            ({}, None, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"data\": {\"provider\": {}},\n                \"message\": \"Providers Not Found\",\n                \"error\": \"Not Found\"\n            }, 200),\n            # Database error case: simulates a database error\n            (\"DB Error\", \"DB Error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"data\": {\"provider\": {}},\n                \"message\": \"DB error\",\n                \"error\": \"DB Error\"\n            }, 200)\n        ]\n    )\n    @patch('app.services.provider.get_provider')  # Mock the get_provider function\n    def test_get_provider(self, mock_get_provider, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Set the mock return value for get_provider\n        mock_get_provider.return_value = (mock_return_value, error)\n\n        # Send a GET request to the endpoint for a specific provider\n        response = client.get(\"/api/v1/provider/get/1\")\n\n        # Assert the status code and response data match expected values\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    @pytest.mark.parametrize(\n        \"mock_return_value, error, expected_response, expected_status_code\",\n        [\n            # Success case: credentials test passes\n            (True, \"Test Credentials successfully completed\", {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"Test Credentials successfully completed\",\n                \"error\": None,\n                \"data\": None,\n            }, 200),\n            # Provider not found case: simulates provider not found\n            (None, \"Provider Not Found\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"Provider Not Found\",\n                \"error\": \"Provider Not Found\",\n                \"data\": None,\n            }, 200),\n            # Failed to get provider configurations case\n            (None, \"Failed to get provider configurations\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"Failed to get provider configurations\",\n                \"error\": \"Failed to get provider configurations\",\n                \"data\": None,\n            }, 200),\n            # Unsupported provider case: tests for unsupported provider response\n            (None, \"Unsupported Provider\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"Unsupported Provider\",\n                \"error\": \"Unsupported Provider\",\n                \"data\": None,\n            }, 200),\n            # Missing required key case: checks for missing config key\n            (None, \"Missing required config key: key\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"Missing required config key: key\",\n                \"error\": \"Missing required config key: key\",\n                \"data\": None,\n            }, 200),\n            # Failed to connect case: simulates a connection error during credentials testing\n            (None, \"Test Credentials Failed: Connection error\", {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"Test Credentials Failed: Connection error\",\n                \"error\": \"Test Credentials Failed: Connection error\",\n                \"data\": None,\n            }, 200),\n        ]\n    )\n    @patch('app.services.provider.test_credentials')  # Mock the test_credentials function\n    def test_test_connections(self, mock_test_credentials, client: TestClient, mock_return_value, error, expected_response, expected_status_code):\n        # Set the mock return value for test_credentials\n        mock_test_credentials.return_value = (mock_return_value, error)\n\n        # Create credentials data using the CredentialsHelper\n        credentials = CredentialsHelper(provider_config={\"key\": \"value\"})\n        # Send a POST request to test credentials\n        response = client.post(\"/api/v1/provider/1/test-credentials\", json=credentials.model_dump())\n\n        # Assert the status code and response data match expected values\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n\n    @pytest.mark.parametrize(\n        \"mock_return_value, is_error, expected_response, expected_status_code\",\n        [\n            # Success case: LLM providers found\n            ({\"llm_providers\": [\"Provider A\"]}, False, {\n                \"status\": True,\n                \"status_code\": 200,\n                \"message\": \"LLM providers found\",\n                \"data\": {\"llm_providers\": [\"Provider A\"]},\n                \"error\": None\n            }, 200),\n            # Not found case: no LLM providers returned\n            (None, True, {\n                \"status\": False,\n                \"status_code\": 422,\n                \"message\": \"LLM providers not found\",\n                \"data\": None,\n                \"error\": None\n            }, 200),\n        ]\n    )\n    @patch('app.services.provider.getllmproviders')  # Mock the getllmproviders function\n    def test_getllmproviders(self, mock_getllmproviders, client: TestClient, mock_return_value, is_error, expected_response, expected_status_code):\n        # Set the mock return value for getllmproviders\n        mock_getllmproviders.return_value = (mock_return_value, is_error)\n\n        # Send a GET request to fetch LLM providers\n        response = client.get(\"/api/v1/provider/llmproviders\")\n\n        # Assert the status code and response data match expected values\n        assert response.status_code == expected_status_code\n        assert response.json() == expected_response\n"}
{"type": "test_file", "path": "tests/integration/test_integration_connector.py", "content": "import pytest\nfrom fastapi.testclient import TestClient\nfrom sqlalchemy.orm import Session\nfrom app.models.connector import Connector\nfrom app.models.provider import Provider, ProviderConfig\nfrom unittest.mock import patch\n\n# Use pytest fixtures for client and database session management\n@pytest.mark.usefixtures(\"client\", \"db_session\")\nclass TestConnectorAPI:\n\n    # Integration testing for creating a PDF-based connector\n    @patch('app.repository.provider.get_config_types')  # Mock the get_config_types function to return predefined values\n    def test_create_connector_type_2(self, mock_get_config_types, client: TestClient, db_session: Session, provider_fixture: Provider):\n\n        # Mocking the return value of get_config_types to simulate a response from the provider config\n        mock_get_config_types.return_value = (\n            [\n                ProviderConfig(slug=\"website_url\", field=\"website_url\"),\n            ],\n            False\n        )\n\n        # Prepare the connector data for the POST request\n        connector_data = {\n            \"connector_type\": provider_fixture.id,  # Use the provider ID from the fixture\n            \"connector_name\": \"Test Website Connector\",  # Name of the connector\n            \"connector_description\": \"Connector for Website database\",  # Description of the connector\n            \"connector_config\": {\n                \"website_url\":\"https://www.siroccoventures.com/\"\n            }\n        }\n\n        # Perform the POST request to create the connector\n        response = client.post(\"/api/v1/connector/create\", json=connector_data)\n\n        # Check the response from the API\n        response_data = response.json()  # Get the JSON response data\n\n        # Assert that the response status code is 200 (OK)\n        assert response.status_code == 200\n        # Assert that the status in the response data is True\n        assert response_data[\"status\"] is True\n        # Assert that the message indicates the connector was created\n        assert response_data[\"message\"] == \"Connector Created\"\n        # Assert that the returned connector name matches the input data\n        assert response_data[\"data\"][\"connector\"][\"connector_name\"] == connector_data[\"connector_name\"]\n        # Assert that the returned connector type matches the provider ID\n        assert response_data[\"data\"][\"connector\"][\"connector_type\"] == provider_fixture.id\n\n        # Verify that the connector has been created in the database\n        created_connector = db_session.query(Connector).filter(Connector.connector_name == connector_data[\"connector_name\"]).first()\n        # Assert that the created connector is not None (it should exist in the database)\n        assert created_connector is not None\n"}
{"type": "test_file", "path": "tests/functional/test_commons.py", "content": ""}
{"type": "test_file", "path": "tests/conftest.py", "content": "from typing import Generator, Any\nimport pytest\nfrom fastapi import FastAPI\nfrom fastapi.testclient import TestClient\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy.orm import Session\nfrom app.models.provider import Provider\nfrom app.utils.database import Base\nfrom app.utils.database import get_db\nfrom app.api.v1.provider import router\nfrom app.api.v1.llmchat import chat_router\nfrom app.api.v1.connector import router as ConnectorRouter\nfrom app.api.v1.connector import cap_router as capabilityrouter\nfrom app.api.v1.connector import inference_router as inference_router\nfrom app.api.v1.connector import actions as actions\nfrom app.api.v1.main_router import MainRouter\nfrom app.api.v1.provider import sample as sample_sql\n\n# Function to initialize the FastAPI application with all necessary routers\ndef start_application() -> FastAPI:\n    app = FastAPI()\n    app.include_router(MainRouter, prefix=\"/api/v1/query\")\n    app.include_router(router, prefix=\"/api/v1/provider\")\n    app.include_router(chat_router, prefix=\"/api/v1/chat\")\n    app.include_router(capabilityrouter, prefix=\"/api/v1/capability\")\n    app.include_router(inference_router, prefix=\"/api/v1/inference\")\n    app.include_router(ConnectorRouter, prefix=\"/api/v1/connector\")\n    app.include_router(actions, prefix=\"/api/v1/actions\")\n    app.include_router(sample_sql, prefix=\"/api/v1/sql\")\n\n    return app\n\n# Database URL for testing with SQLite\nSQLALCHEMY_DATABASE_URL = \"sqlite:///./test_db.db\"\n# Create a SQLAlchemy engine for testing\nengine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False})\nSessionTesting = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n# Fixture to create a fresh database for each test case\n@pytest.fixture(scope=\"function\")\ndef app() -> Generator[FastAPI, None, None]:\n    \"\"\"\n    Create a fresh database on each test case.\n    \"\"\"\n    Base.metadata.create_all(engine)  # Create the database tables\n    _app = start_application()  # Initialize the FastAPI application\n    yield _app  # Yield the application instance for use in tests\n    Base.metadata.drop_all(engine)  # Drop the database tables after tests\n\n# Fixture to manage database sessions for tests\n@pytest.fixture(scope=\"function\")\ndef db_session(app: FastAPI) -> Generator[Session, None, None]:\n    # Connect to the database and begin a transaction for testing\n    connection = engine.connect()\n    transaction = connection.begin()\n    session = SessionTesting(bind=connection)  # Create a new session\n    yield session  # Yield the session for use in tests\n    session.close()  # Close the session after tests\n    transaction.rollback()  # Roll back the transaction to maintain isolation\n    connection.close()  # Close the database connection\n\n# Fixture to create a FastAPI TestClient for sending requests in tests\n@pytest.fixture(scope=\"function\")\ndef client(app: FastAPI, db_session: Session) -> Generator[TestClient, None, None]:\n    \"\"\"\n    Create a new FastAPI TestClient that uses the `db_session` fixture to override\n    the `get_db` dependency that is injected into routes.\n    \"\"\"\n\n    # Override the get_db dependency to use the test database session\n    def _get_test_db():\n        try:\n            yield db_session  # Yield the test database session\n        finally:\n            pass\n\n    app.dependency_overrides[get_db] = _get_test_db  # Apply the dependency override\n    with TestClient(app) as client:\n        yield client  # Yield the TestClient for use in tests\n\n# Fixture to create a sample Provider for testing\n@pytest.fixture\ndef provider_fixture(db_session: Session) -> Provider:\n    # Sample provider data for creating a Provider instance\n    provider_data = {\n        \"name\": \"website provider\",\n        \"description\": \"Provider for website connectors\",\n        \"enable\": True,\n        \"icon\": \"website.png\",\n        \"category_id\": 1,\n        \"key\": \"website\",\n    }\n    new_provider = Provider(**provider_data)  # Create a new Provider instance\n    db_session.add(new_provider)  # Add the provider to the session\n    db_session.commit()  # Commit the session to save the provider\n    db_session.refresh(new_provider)  # Refresh the provider instance to get updated data\n    return new_provider  # Return the created Provider instance\n"}
{"type": "test_file", "path": "tests/unittest/test_svc/test_svc_provider.py", "content": "from fastapi.testclient import TestClient\nfrom sqlalchemy.orm import Session\nfrom app.models.provider import Provider\nfrom app.api.v1.provider import router\nfrom app.services import provider as svc\nfrom app.schemas.provider import ProviderResp\nfrom unittest.mock import patch\nimport pytest\n\n# Use the pytest fixture for client management\n@pytest.mark.usefixtures(\"client\")\nclass TestProviderAPI:\n\n    # Test case for successfully retrieving a provider by ID\n    @patch('app.services.provider.repo')  # Mock the repository layer for the test\n    def test_get_provider_success(self, mock_repo, db_session: Session):\n        # Create a mock provider instance to simulate a successful database return\n        provider = Provider(\n            id=1,\n            name=\"Test Provider\",\n            description=\"A test provider\",\n            enable=True,\n            icon=\"icon.png\",\n            category_id=1,\n            key=\"test_provider\"\n        )\n        provider.providerconfig = []  # Initialize an empty list for provider config\n\n        # Set the mock return value for the repo method\n        mock_repo.get_provider_by_id.return_value = (provider, False)\n\n        # Call the service method to get the provider\n        result, error = svc.get_provider(1, db_session)\n\n        # Assertions to verify the correct behavior\n        assert error is None  # No error should occur\n        assert isinstance(result, ProviderResp)  # Result should be an instance of ProviderResp\n        assert result.id == 1  # ID should match the mock provider's ID\n        assert result.name == \"Test Provider\"  # Name should match the mock provider's name\n\n    # Test case for handling a database error when retrieving a provider\n    @patch('app.services.provider.repo')  # Mock the repository layer for the test\n    def test_get_provider_db_error(self, mock_repo, db_session: Session):\n        # Simulate a database error by returning None and an error message\n        mock_repo.get_provider_by_id.return_value = (None, \"DB Error\")\n\n        # Call the service method to get the provider\n        result, error = svc.get_provider(1, db_session)\n\n        # Assertions to verify the correct error handling\n        assert error == \"DB Error\"  # Error should match the simulated database error\n        assert result is None  # Result should be None due to the error\n\n    # Test case for handling a case where a provider is not found\n    @patch('app.services.provider.repo')  # Mock the repository layer for the test\n    def test_get_provider_not_found(self, mock_repo, db_session: Session):\n        # Simulate a case where no provider is found by returning an empty dict and no error\n        mock_repo.get_provider_by_id.return_value = ({}, None)\n\n        # Call the service method to get the provider\n        result, error = svc.get_provider(1, db_session)\n\n        # Assertions to verify the correct handling of a not found case\n        assert error is None  # No error should occur\n        assert result == {}  # Result should be an empty dict\n"}
{"type": "source_file", "path": "app/base/base_llm.py", "content": "# SPDX-FileCopyrightText: Copyright (c) 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import List, Optional, Any\nimport requests\nimport json\n\nfrom langchain.callbacks.manager import (\n    AsyncCallbackManagerForLLMRun,\n    CallbackManagerForLLMRun,\n)\nfrom langchain.llms.base import LLM\nfrom loguru import logger\n\n\nclass BaseLLM(LLM):\n\n    temperature: Optional[float] = 0.5\n    url: Any = \"\"\n    headers : Optional[Any]  = {}\n    body : Optional[Any]  = {}\n\n\n    def _call(\n        self,\n        prompt: Optional[str]=\"\",\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[CallbackManagerForLLMRun] = None,\n    ) -> str:\n\n        if prompt != \"\":\n            self.body[\"prompt\"] = prompt\n        try:\n            r = requests.post(self.url,  json=self.body,headers=self.headers)\n            model_out = json.loads(r.content)\n        except Exception as e:\n            logger.error(e)\n            model_out = {}\n\n        return model_out\n\n\n\n    async def _acall(\n        self,\n        prompt: str,\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n        **kwargs: Any,\n    ) -> str:\n\n        return \"hi\"\n\n    @property\n    def _llm_type(self) -> str:\n        return \"rest llm\"\n\n    @property\n    def _identifying_params(self) -> dict:\n        return {\n            \"url\": self.url,\n        }\n\n"}
{"type": "source_file", "path": "app/api/v1/provider.py", "content": "from fastapi import APIRouter, Depends\nfrom sqlalchemy.orm import Session\nimport app.schemas.common as resp_schemas\nimport app.schemas.provider as schemas\nfrom app.utils.database import get_db\nimport app.services.provider as svc\nimport app.api.v1.commons as commons\nimport app.schemas.connector as conn_schemas\nfrom fastapi import Request\nfrom app.providers.middleware import verify_token\n\n\nrouter = APIRouter()\nsample = APIRouter()\nvectordb = APIRouter()\n\n\n@router.get(\"/list\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef list_providers(db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves a list of providers (plugins) from the database.\n\n    Args:\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing either the list of providers or an error message.\n    \"\"\"\n\n    result, error = svc.list_providers(db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"providers\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Providers Not Found\", {\"providers\": []})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"providers\": result},\n        message=\"Providers Found\",\n        error=None\n    )\n\n@router.get(\"/get/{provider_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_provider(provider_id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves a specific provider (plugin) by its ID.\n\n    Args:\n        provider_id (int): The ID of the provider to retrieve.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing either the provider details or an error message.\n    \"\"\"\n\n    result, error=svc.get_provider(provider_id, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"provider\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Providers Not Found\", {\"provider\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"provider\": result},\n        message=\"Provider Found\",\n        error=None\n    )\n\n@router.post(\"/{provider_id}/test-credentials\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef test_connections(provider_id: int, config: schemas.TestCredentials, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Tests the credentials for a specific provider (plugin) by its ID.\n\n    Args:\n        provider_id (int): The ID of the provider for which to test credentials.\n        config (TestCredentials): The credentials to test.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the credential test.\n    \"\"\"\n\n    success, message = svc.test_credentials(provider_id, config, db)\n\n    if not success:\n        return resp_schemas.CommonResponse(\n            status=False,\n            status_code=422,\n            message=message,\n            error=message,\n        )\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=message,\n        error=None,\n    )\n\n@vectordb.post(\"/test_credentials\", response_model=resp_schemas.CommonResponse)\ndef test_vectordb_credentials(config: schemas.TestVectorDBCredentials, db: Session = Depends(get_db)):\n    \"\"\"\n    Tests the credentials for a VectorDB provider.\n\n    Args:\n        config (TestVectorDBCredentials): The credentials to test.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the credential test.\n    \"\"\"\n    message, is_error = svc.test_vectordb_credentials(config, db)\n\n    if is_error:\n        return resp_schemas.CommonResponse(\n            status=False,\n            status_code=422,\n            message=\"Test credentials Failed\",\n            error=message,\n        )\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=message,\n        error=None,\n    )\n\n\n@vectordb.get(\"/list/all\",response_model= resp_schemas.CommonResponse)\ndef getvectordbs(db: Session = Depends(get_db)):\n    \"\"\"\n    Retrieves a list of available VectorDB providers.\n\n    Args:\n        request (Request): The HTTP request object.\n\n    Returns:\n        CommonResponse: A response containing either the list of VectorDB providers or an error message.\n    \"\"\"\n\n    result, is_error = svc.getvectordbs(db)\n\n\n    if is_error:\n        return commons.is_error_response(\"DB error\", result, {\"vectordbs\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Sample SQL Not Found\", {\"vectordbs\": []})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"VectorDB providers found\",\n        data={\"vectordbs\":result},\n        error=None,\n    )\n\n@router.get(\"/llmproviders\", response_model=resp_schemas.CommonResponse)\ndef getllmproviders(request: Request):\n\n    \"\"\"\n    Retrieves a list of available LLM (Large Language Model) providers.\n\n    Args:\n        request (Request): The HTTP request object.\n\n    Returns:\n        CommonResponse: A response containing either the list of LLM providers or an error message.\n    \"\"\"\n\n    result, is_error = svc.getllmproviders(request)\n\n    if is_error:\n        return resp_schemas.CommonResponse(\n            status=False,\n            status_code=422,\n            message=\"LLM providers not found\",\n            error=None,\n        )\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"LLM providers found\",\n        data=result,\n        error=None,\n    )\n\n@router.post(\"/test-inference-credentials\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef test_inference_connections(inference: conn_schemas.InferenceBase):\n    \"\"\"\n    Tests the inference connections by validating the credentials for a specific LLM provider.\n\n    Args:\n        inference (conn_schemas.InferenceBase):\n            Configuration object containing the provider details, including model name, API key, and endpoint, for testing the connections.\n\n    Returns:\n        resp_schemas.CommonResponse:\n            - Response object containing:\n                - status (bool): Indicates whether the credentials validation was successful.\n                - status_code (int): HTTP status code (200 for success, 422 for failure).\n                - message (str): A message providing the outcome of the credentials test.\n                - error (Optional[str]): Error message if the credentials test failed, otherwise None.\n    \"\"\"\n\n    success, message = svc.test_inference_credentials(inference)\n    if not success:\n        return resp_schemas.CommonResponse(\n            status=False,\n            status_code=422,\n            message=\"Test Credentials Failed\",\n            error=message,\n        )\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=message,\n        error=None,\n    )\n\n@sample.get(\"/list\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef list_sql(db: Session = Depends(get_db), user_data: dict = Depends(verify_token)):\n\n    \"\"\"\n    Retrieves a list of sample SQL records from the database.\n\n    Args:\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing either the list of sample SQL records or an error message.\n    \"\"\"\n    \n    user_id = user_data[\"user_id\"]\n    result, error = svc.listsql(db, user_id)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"sql\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Sample SQL Not Found\", {\"sql\": []})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"sql\": result},\n        message=\"Sample SQL Found\",\n        error=None\n    )\n\n@sample.get(\"/{id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_sql(id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves a specific sample SQL record by its ID.\n\n    Args:\n        id (int): The ID of the sample SQL record to retrieve.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing either the SQL record or an error message.\n    \"\"\"\n\n    result, error = svc.getsql(id, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"sql\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Sample SQL Not Found\", {\"sql\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"sql\": result},\n        message=\"Sample SQL Found\",\n        error=None\n    )\n\n\n\n@sample.post(\"/create\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef create_sql(request:Request,sql: schemas.SampleSQLBase, db: Session = Depends(get_db), user_data: dict = Depends(verify_token)):\n\n    \"\"\"\n    Creates a new sample SQL record in the database.\n\n    Args:\n        request (Request): The HTTP request object.\n        sql (SampleSQLBase): The data for the new SQL record.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the SQL creation process.\n    \"\"\"\n    user_id = user_data[\"user_id\"]\n\n    result, error = svc.create_sql(request, sql, db, user_id)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"sql\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        message=\"Sample SQL Created Successfully\",\n        error=None,\n        data={\"SQL\": result}\n    )\n\n@sample.post(\"/update/{id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef update_sql(id: int, request: Request, sql: schemas.SampleSQLUpdate, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Updates an existing sample SQL record by its ID.\n\n    Args:\n        id (int): The ID of the SQL record to update.\n        request (Request): The HTTP request object.\n        sql (SampleSQLUpdate): The updated SQL data.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the SQL update process.\n    \"\"\"\n\n    result, error = svc.update_sql(request, id, sql, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"sql\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Sample SQL Not Found\", {\"sql\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Sample SQL Updated Successfully\",\n        error=None,\n        data={\"sql\": result}\n    )\n\n@sample.post(\"delete/{id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef delete_sql(id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Deletes a sample SQL record by its ID.\n\n    Args:\n        id (int): The ID of the SQL record to delete.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the SQL deletion process.\n    \"\"\"\n\n    result, error = svc.delete_sql(id, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"sql\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Sample SQL Deleted Successfully\",\n        error=None,\n    )\n\n\n@vectordb.post(\"/create\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef create_vectordb_instance(vectordb: schemas.VectorDBBase, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Creates a new VectorDB instance in the database.\n\n    Args:\n        request (Request): The HTTP request object.\n        sql (VectorDBBase): The data for the new VectorDB instance.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the VectorDB instance creation process.\n    \"\"\"\n\n    result, error = svc.create_vectordb_and_embedding(\"create\",0,vectordb, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"vectordb\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        message=\"VectorDB Instance Created Successfully\",\n        error=None,\n        data={\"VectorDB\": result}\n    )\n\n@vectordb.post(\"/update/{id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef update_vectordb_instance(id:int,vectordb: schemas.VectorDBUpdateBase, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Updates VectorDB instance in the database.\n\n    Args:\n        request (Request): The HTTP request object.\n        sql (VectorDBBase): The data for the new VectorDB instance.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the VectorDB instance creation process.\n    \"\"\"\n\n    result, error = svc.create_vectordb_and_embedding(key=\"update\",id=id,vectordb=vectordb, db=db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"vectordb\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        message=\"VectorDB Instance Updated Successfully\",\n        error=None,\n        data={\"VectorDB\": result}\n    )\n\n@vectordb.get(\"/get/{config_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_vectordb_instance(id: int, db: Session = Depends(get_db)):\n    \"\"\"\n    Retrieves a VectorDB instance by its ID.\n\n    Args:\n        id (int): The ID of the VectorDB instance.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing the VectorDB instance or an error message.\n    \"\"\"\n\n    result, error = svc.get_vectordb_instance(id, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"vectordb\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"VectorDB Instance Retrieved Successfully\",\n        error=None,\n        data={\"VectorDB\": result}\n    )\n\n@vectordb.delete(\"/delete/{id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef delete_vectordb_instance(id: int, db: Session = Depends(get_db)):\n    \"\"\"\n    Deletes a VectorDB instance by its ID, along with its associated config mapping.\n\n    Args:\n        id (int): The ID of the VectorDB instance to delete.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the deletion process.\n    \"\"\"\n\n    result, error = svc.delete_vectordb_instance(id, db)\n\n    if error:\n        return commons.is_error_response(\"DB error or VectorDB not found\", result, {\"vectordb\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"VectorDB Instance Deleted Successfully\",\n        error=None,\n        data={\"VectorDB\": result}\n    )\n\n@vectordb.get(\"/embedding/all\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_all_embeddings():\n\n    \"\"\"\n    Retrieves all embeddings from module.\n\n    Returns:\n        CommonResponse: A response containing the embeddings or an error message.\n    \"\"\"\n\n    result, error = svc.get_all_embeddings()\n\n    if error:\n        return commons.is_error_response(\"Fetching Error\", result, {\"embeddings\": []})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Embeddings Retrieved Successfully\",\n        error=None,\n        data={\"embeddings\": result}\n    )\n"}
{"type": "source_file", "path": "app/base/base_formatter.py", "content": "from abc import ABC, abstractmethod\n\n\nclass BaseFormatter(ABC):\n\n    @abstractmethod\n    def format(self)-> (dict):\n        \"\"\"\n        Abstract method to format data.\n\n        This method should be implemented by subclasses to define\n        specific formatting logic.\n\n        Returns:\n            dict: A dictionary containing the formatted data.\n        \"\"\"\n        pass"}
{"type": "source_file", "path": "app/api/v1/commons.py", "content": "import app.schemas.common as resp_schemas\n\ndef is_error_response(message:str, err:str, data:dict):\n    return resp_schemas.CommonResponse(\n            status= False,\n            status_code=422,\n            message=message,\n            data=data,\n            error=err\n        )\n\ndef is_none_reponse(message:str, data:dict):\n    return resp_schemas.CommonResponse(\n            status= True,\n            status_code=200,\n            message=message,\n            data=data,\n            error=\"Not Found\"\n        )"}
{"type": "source_file", "path": "app/api/v1/main_router.py", "content": "from app.providers.cache_manager import cache_manager\nfrom fastapi import APIRouter, Depends, status, Query\nfrom fastapi.encoders import jsonable_encoder\nfrom app.models.request import Chat, FeedbackCorrectionRequest\nfrom starlette.requests import Request\nfrom loguru import logger\nfrom app.schemas import llmchat as schemas\nfrom app.api.v1 import llmchat\nfrom app.api.v1 import connector\nfrom sqlalchemy.orm import Session\nfrom app.utils.database import get_db\n\n\nMainRouter = APIRouter()\n\n\n@MainRouter.post(\"/query\", status_code=status.HTTP_201_CREATED)\n\nasync def qna(\n    query: Chat,\n    request: Request,\n    context_id: str = Query(..., alias=\"contextId\"),\n    config_id: str = Query(..., alias=\"configId\"),\n    env_id: str = Query(..., alias=\"envId\"),\n    db: Session = Depends(get_db)\n):\n\n    \"\"\"\n    Handles user queries and invokes the chain to get an answer from the LLM.\n\n    Args:\n        query (Chat): User query as a Chat model.\n        request (Request): FastAPI request object containing context and app-level dependencies.\n        background_tasks (BackgroundTasks): Background task for asynchronous logging.\n        db (Session): Database session dependency.\n\n    Returns:\n        dict: Response containing the answer to the user's query and the original query text.\n    \"\"\"\n    \n    logger.info(f\"{context_id} - {config_id} - query: {query.content}\")\n    cached_data = cache_manager.get(int(config_id))\n    if not cached_data:\n        logger.info(\"configuration was not found in the cache\")\n        response = connector.create_yaml(request, int(config_id), db)\n        if response['success'] == True:\n            cached_data = cache_manager.get(int(config_id))\n        else:\n            return\n        \n    chain = cached_data[\"chain\"]\n    vector_store = cached_data['vector_store']\n    request.app.chain = chain\n    request.app.vector_store = vector_store\n    \n    out = await chain.invoke({\n        \"question\": query.content,\n        \"context_id\": context_id,\n    })\n\n    resp = llmchat.create_chat(\n        schemas.ChatHistoryCreate(\n            chat_context_id=context_id,\n            chat_query=query.content,\n            chat_answer= jsonable_encoder(out),\n            chat_summary=out.get(\"summary\", query.content),\n            configuration_id=config_id,\n            environment_id=env_id\n        ),\n        db\n    )\n\n    if resp.status:\n        out[\"chat_id\"] = resp.data[\"chat\"].chat_id\n\n\n    return {\n        \"response\": out,\n        \"query\": query.content,\n    }\n\n\n#! This api is not in use right now, instead we are using a scheduler for the feedback_correction job\n@MainRouter.post(\"/feedback_correction\", status_code=status.HTTP_201_CREATED)\ndef feedback_correction(request: Request, body: FeedbackCorrectionRequest):\n\n    \"\"\"\n    Processes feedback from LLM responses and updates the vector store accordingly.\n\n    Args:\n        request (Request): FastAPI request object containing the app's vector store.\n        body (FeedbackCorrectionRequest): Request body containing user feedback to be processed.\n\n    Returns:\n        str: Success message indicating the feedback processing outcome.\n\n    \"\"\"\n\n    store = request.app.vector_store\n\n    if body.responses:\n        for response in body.responses:\n            similar_sample = store.find_similar_samples(response.description)\n            if len(similar_sample) > 0 and similar_sample[0]['distances'] < 0.3:\n                store.update_store(similar_sample[0]['id'],response.metadata,response.description)\n            else:\n                store.update_store(metadatas = response.metadata,documents = response.description)\n        return \"Success: Feedback received and processed.\"\n\n    else:\n        return \"Success: No Feedback received and processed.\"\n\n\n"}
{"type": "source_file", "path": "app/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/v1/auth.py", "content": "import json\nimport requests\nfrom app.schemas.common import LoginData\nimport os\nfrom fastapi import APIRouter, Depends, Response, Request, HTTPException, status\nfrom fastapi.responses import RedirectResponse, JSONResponse\nfrom app.providers.config import configs\nfrom app.providers.zitadel import Zitadel\nfrom app.utils.jwt import JWTUtils\nfrom app.schemas.common import CommonResponse\nfrom app.providers.middleware import verify_token\nfrom typing import Optional\nfrom app.providers.config import configs\nimport app.services.user as svc\nimport app.schemas.user as schemas\nfrom app.utils.database import get_db\nfrom sqlalchemy.orm import Session\nimport app.api.v1.commons as commons\n\nlogin = APIRouter()\nzitadel = Zitadel()\n\n\n# will redirect to idp when called with ipdId\n# need to set successurl and failureUrl dynamically *****\n@login.get(\"/login/idp/{idp_id}\")\ndef idp_login(response: Response, idp_id : int):\n    return zitadel.redirect_to_idp(idp_id)\n\n# if idp login is success then is redirected to this endpoint with which we get the user\n# details from the idp (currently only tested with google)\n@login.get(\"/idp/success\")\ndef idp_success(request: Request,db: Session = Depends(get_db)):\n    query_params = request.query_params\n    idp_intent_id = query_params.get(\"id\")\n    idp_token = query_params.get(\"token\")\n    if not idp_intent_id or not idp_token:\n        return commons.is_error_response(\"Missing required parameters\", {}, {\"user\": {}})\n    user_id = query_params.get(\"user\")\n    try:\n        response = zitadel.get_idp_intent_data(idp_intent_id, idp_token)\n        user_data = response.json()\n        username = user_data.get(\"idpInformation\", {}).get(\"rawInformation\", {}).get(\"User\", {}).get(\"name\", \"\")\n        if(user_id):\n            user, error = svc.get_or_create_user(schemas.UserCreate(id=int(user_id), username=username), db)\n            session_response = zitadel.create_user_session(user_id, idp_intent_id, idp_token)\n        else:\n            session_response = zitadel.create_user(user_data, idp_intent_id, idp_token)\n            if session_response.status_code != 201:\n                return commons.is_error_response(\"Failed to create Zitadel user\", session_response.body.decode(\"utf-8\"), {\"user\": {}})\n            response_data = json.loads(session_response.body.decode(\"utf-8\"))\n            zitadel_user_id = response_data.get(\"user_id\")\n            new_user = schemas.UserCreate(\n                                    id=int(zitadel_user_id),\n                                    username=username,\n                                )\n            result, error = svc.get_or_create_user(new_user, db)\n            if error:\n                return commons.is_error_response(\"DB Error\", error, {\"user\": {}})\n\n            if not result:\n                return commons.is_none_reponse(\"User Not Created\", {\"user\": {}})\n\n        if session_response.status_code == 201:\n            redirect_response = RedirectResponse(url=\"/ui\", status_code=303)\n\n            # Copy cookies from session_response to redirect_response\n            for cookie in session_response.headers.getlist(\"set-cookie\"):\n                redirect_response.headers.append(\"set-cookie\", cookie)\n\n            return redirect_response\n\n        return session_response\n    except (requests.exceptions.RequestException, json.JSONDecodeError, AttributeError) as e:\n        return {\"error\": \"Failed to create session\", \"details\": str(e)}, 500\n\n\n\n# endpoint to retreive all the available idp providers that is setup in Zitadel\n@login.get(\"/idp/list\")\ndef list_idp(response: Response):\n    return zitadel.list_idp_providers()\n\n\n@login.get(\"/user_info\", dependencies=[Depends(verify_token)])\ndef get_user_info(request: Request, db: Session = Depends(get_db), user_data: dict = Depends(verify_token)):\n    if user_data == 'Admin':\n        return CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"User info retrieved successfully\",\n        data={ \"username\": user_data, \"auth_enabled\": configs.auth_enabled, \"env_id\": 0 },\n        error=None\n    )\n         \n    session_id = user_data[\"session_id\"]\n    user_info = zitadel.get_user_info(session_id)\n    username = user_info.get(\"session\").get(\"factors\").get(\"user\").get(\"displayName\")\n    user_id = user_info.get(\"session\").get(\"factors\").get(\"user\").get(\"id\")\n    env_id, error = svc.get_users_active_env(user_id, db)\n    if error:\n        return commons.is_error_response(\"DB Error\", error, {\"env\": {}})\n    return CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"User info retrieved successfully\",\n        data={ \"username\": username, \"auth_enabled\": configs.auth_enabled, \"env_id\": env_id },\n        error=None\n    )\n\n\n# change to get user info from raggenie.db\n@login.post(\"/logout\",dependencies=[Depends(verify_token)])\ndef logout_user(response: Response, user_data: dict = Depends(verify_token)):\n    session_id = user_data[\"session_id\"]\n    res = zitadel.logout_user(session_id)\n    if res.status_code == 200:\n        response.delete_cookie(\"session_data\")\n    return res\n\n"}
{"type": "source_file", "path": "app/base/abstract_handlers.py", "content": "from __future__ import annotations\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Optional\n\n\nclass Handler(ABC):\n    \"\"\"\n    The Handler interface declares a method for building the chain of handlers.\n    It also declares a method for executing a request.\n    \"\"\"\n\n    @abstractmethod\n    def set_next(self, handler: Handler) -> Handler:\n        pass\n\n    @abstractmethod\n    async def handle(self, request) -> Optional[str]:\n        pass\n\nclass AbstractHandler(Handler):\n    \"\"\"\n    The default chaining behavior can be implemented inside a base handler\n    class.\n    \"\"\"\n\n    _next_handler: Handler = None\n\n    def set_next(self, handler: Handler) -> Handler:\n        self._next_handler = handler\n        # Returning a handler from here will let us link handlers in a\n        # convenient way like this:\n        # monkey.set_next(squirrel).set_next(dog)\n        return handler\n\n    @abstractmethod\n    async def handle(self, request: Any) -> str:\n        if self._next_handler:\n            return await self._next_handler.handle(request)\n\n        return None"}
{"type": "source_file", "path": "app/api/v1/llmchat.py", "content": "# src/endpoints/chat.py\n\nfrom fastapi import APIRouter, Depends\nfrom sqlalchemy.orm import Session\nimport app.schemas.common as resp_schemas\nfrom app.schemas import llmchat as schemas\nfrom app.utils.database import get_db\nfrom app.services import llmchat as svc\nimport app.api.v1.commons as commons\n\nchat_router = APIRouter()\n\n# Create a new chat\n@chat_router.post(\"/create\", response_model=resp_schemas.CommonResponse)\ndef create_chat(chat: schemas.ChatHistoryCreate, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Creates a new chat record in the database.\n\n    Args:\n        chat (ChatHistoryCreate): The data for the new chat entry.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating success or failure of the chat creation process.\n    \"\"\"\n\n    result, error = svc.create_chat(chat, db)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", result, {\"chat\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        data={\"chat\": result},\n        message=\"Chat created successfully\",\n        error=None\n    )\n\n# Create feedback for a chat\n@chat_router.post(\"/feedback/create\", response_model=resp_schemas.CommonResponse)\ndef create_feedback(feedback: schemas.FeedbackCreate, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Creates feedback for an existing chat record.\n\n    Args:\n        feedback (FeedbackCreate): The feedback data to be added to the chat.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating success or failure of the feedback creation process.\n    \"\"\"\n\n    result, error = svc.create_feedback(feedback, db)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", result, {\"chat\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Chat Not Found\", {\"chat\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"chat\": result},\n        message=\"Feedback updated successfully\",\n        error=None\n    )\n\n# List the primary chat based on context\n@chat_router.get(\"/list/context/all/{env_id}\", response_model=resp_schemas.CommonResponse)\ndef list_chat_by_context(env_id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves all the primary chats based on context from the database.\n\n    Args:\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing either the list of primary chats or an error message.\n    \"\"\"\n\n    result, error = svc.list_chats_by_context(env_id, db)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", error, {\"chats\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Context Not found\", {\"chats\": []})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"chats\": result},\n        message=\"Primary chats found\",\n        error=None\n    )\n\n# Get a specific chat by context ID\n@chat_router.get(\"/get/{context_id}\", response_model=resp_schemas.CommonResponse)\ndef get_chat_by_context(context_id: str, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves a specific chat by context ID from the database.\n\n    Args:\n        context_id (str): The ID of the context to retrieve the chat for.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing either the chat data or an error message.\n    \"\"\"\n\n    result, error = svc.list_all_chats_by_context_id(context_id, db)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", error, {\"chats\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Chat not found\", {\"chats\": []})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"chats\": result},\n        message=\"Chat found\",\n        error=None\n    )\n"}
{"type": "source_file", "path": "app/api/v1/connector.py", "content": "from typing import List, Optional\nfrom app.providers.cache_manager import cache_manager\nfrom fastapi import APIRouter, Depends\nfrom sqlalchemy.orm import Session\nimport app.schemas.connector as schemas\nimport app.schemas.common as resp_schemas\nfrom app.utils.database import get_db\nimport app.services.connector as svc\nimport app.services.provider as provider_svc\nfrom starlette.requests import Request\nfrom fastapi import APIRouter, UploadFile, File\n\nfrom app.chain.chains.capability_chain import CapabilityChain\nfrom app.chain.chains.metadata_chain import MetadataChain\nfrom app.chain.chains.query_chain import QueryChain\nfrom app.chain.chains.intent_chain import IntentChain\nfrom app.chain.chains.general_chain import GeneralChain\n\nimport app.api.v1.commons as commons\nfrom loguru import logger\nfrom app.providers.config import configs\nfrom app.providers.middleware import verify_token\n\n\nrouter = APIRouter()\ncap_router = APIRouter()\ninference_router = APIRouter()\nactions = APIRouter()\n\n@router.get(\"/list\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef list_connectors(db: Session = Depends(get_db), provider_category_ids:  Optional[List[int]] = None, user_data: dict = Depends(verify_token)):\n\n    \"\"\"\n    Retrieves a list of all connectors from the database. If a provider category ID is provided, only connectors from that category are returned.\n\n    Args:\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing either the list of connectors or an error message.\n    \"\"\"\n    user_id = user_data[\"user_id\"]\n    if provider_category_ids:\n        result, error = svc.list_connectors_by_provider_category(provider_category_ids, db, user_id)\n    else:\n        result, error = svc.list_connectors(db, user_id)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", result, {\"connectors\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Connector Not Found\", {\"connectors\": []})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"connectors\": result},\n        message=\"Connectors Found\",\n        error=None\n    )\n\n@router.get(\"/get/{connector_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_connector(connector_id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves a specific connector by its ID from the database.\n\n    Args:\n        connector_id (int): The ID of the connector.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing either the connector details or an error message.\n    \"\"\"\n\n    result, error = svc.get_connector(connector_id, db)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", result, {\"connector\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Connector Not Found\", {\"connector\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"connector\": result},\n        message=\"Connector Found\",\n        error=None\n    )\n\n@router.post(\"/upload/datasource\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\nasync def upload_document_datsource(\n    file: UploadFile = File(...)\n):\n\n    \"\"\"\n    Uploads an document data source file to the server.\n\n    Args:\n        file (UploadFile): The uploaded document file. Accepted formats are .pdf, .txt, .yaml, and .docx.\n\n    Returns:\n        CommonResponse: A response containing the file upload status, file details, or an error message.\n    \"\"\"\n\n    error, size = await svc.fileValidation(file)\n\n    if error:\n        return commons.is_error_response(\"Invalid File\", error, {\"file_path\": None})\n\n    result, error = await svc.upload_pdf(file)\n\n    if error:\n        return commons.is_error_response(\"document not uploaded\", error, {\"file_path\": None})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        data={\"file\": {\"file_path\": result[\"file_path\"],\"file_name\": file.filename, \"file_size\":f\"{round(size / (1024 * 1024), 2)}MB\", \"file_id\": result[\"file_id\"]}},\n        message=\"File Uploaded Success\",\n        error=None\n    )\n\n@router.post(\"/create\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef create_connector(connector: schemas.ConnectorBase, db: Session = Depends(get_db), user_data: dict = Depends(verify_token)):\n\n    \"\"\"\n    Creates a new connector in the database.\n\n    Args:\n        connector (ConnectorBase): The data for the new connector.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating success or failure of the connector creation process.\n    \"\"\"\n    user_id = user_data[\"user_id\"]\n    result, error = svc.create_connector(connector, db, user_id)\n    if error:\n        return commons.is_error_response(\"Connector Not Created\", error, {\"connector\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        data={\"connector\": result},\n        message=\"Connector Created\",\n        error=None\n    )\n\n@router.post(\"/update/{connector_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef update_connector(connector_id: int, connector: schemas.ConnectorUpdate, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Updates an existing connector based on its ID.\n\n    Args:\n        connector_id (int): The ID of the connector to update.\n        connector (ConnectorUpdate): The updated data for the connector.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating success or failure of the update process.\n    \"\"\"\n\n    result, error = svc.update_connector(connector_id, connector, db)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", result, {\"connector\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Connector Not Found\", {\"connector\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"connector\": result},\n        message=\"Connector Updated\",\n        error=None\n    )\n\n@router.post(\"/delete/{connector_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef delete_connector(connector_id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Deletes a connector from the database based on its ID.\n\n    Args:\n        connector_id (int): The ID of the connector to delete.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating success or failure of the deletion process.\n    \"\"\"\n\n    result, error = svc.delete_connector(connector_id, db)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", result, {\"connector\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Connector Not Found\", {\"connector\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"connector\": result},\n        message=\"Connector Deleted\",\n        error=None\n    )\n\n@router.post(\"/schema/update/{connector_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef updateschemas(connector_id: int, connector: schemas.SchemaUpdate, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Updates the schema details of a connector based on its ID.\n\n    Args:\n        connector_id (int): The ID of the connector whose schema is being updated.\n        connector (SchemaUpdate): The schema update data for the connector.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating success or failure of the schema update.\n    \"\"\"\n\n    result, error = svc.updateschemas(connector_id, connector, db)\n\n    if error:\n        return commons.is_error_response(\"DB Error\", result, {\"schemas\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Connector Not Found\", {\"schemas\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"schemas\": result},\n        message=\"Schema Updated\",\n        error=None\n    )\n\n\n\n@router.get(\"/configuration/list\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef list_configurations(db: Session = Depends(get_db), user_data: dict = Depends(verify_token)):\n\n    \"\"\"\n    Lists all available configurations from the database.\n\n    Args:\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing the list of configurations or an error message.\n    \"\"\"\n    user_id = user_data[\"user_id\"]\n    result, error = svc.list_configurations(db, user_id)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"configurations\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Configurations Not Found\", {\"configurations\": []})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Configurations retrieved successfully\",\n        error=None,\n        data={\"configurations\": result}\n    )\n    \n@router.get(\"/configuration/{config_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_configuration(config_id: int, db: Session = Depends(get_db)):\n    \"\"\"\n    Retrieves a configuration by its ID.\n\n    Args:\n        config_id (int): ID of the configuration to retrieve.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing the configuration or an error message.\n    \"\"\"\n    result, error = svc.get_configuration(db, config_id)\n\n    if error == \"DB Error\":\n        return commons.is_error_response(\"DB error\", result, {\"configuration\": None})\n\n    if error == \"Configuration not found\":\n        return commons.is_none_reponse(\"Configuration Not Found\", {\"configuration\": None})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Configuration retrieved successfully\",\n        error=None,\n        data={\"configuration\": result}\n    )\n    \n@router.delete(\"/configuration/{config_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_configuration(config_id: int, db: Session = Depends(get_db)):\n    \"\"\"\n    Retrieves a configuration by its ID.\n\n    Args:\n        config_id (int): ID of the configuration to retrieve.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing the configuration or an error message.\n    \"\"\"\n    result, error = svc.delete_configuration(db, config_id)\n\n    if error == \"DB Error\":\n        return commons.is_error_response(\"DB error\", result, {\"configuration\": None})\n\n    if error == \"Configuration not found\":\n        return commons.is_none_reponse(\"Configuration Not Found\", {\"configuration\": None})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Configuration deleted successfully\",\n        error=None,\n        data={\"configuration\": result}\n    )\n\n\n@router.post(\"/configuration/create\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef create_configuration(configuration: schemas.ConfigurationCreation, db: Session = Depends(get_db), user_data: dict = Depends(verify_token)):\n\n    \"\"\"\n    Creates a new configuration and stores it in the database.\n\n    Args:\n        configuration (ConfigurationCreation): The new configuration details.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the configuration creation.\n    \"\"\"\n    user_id = user_data[\"user_id\"]\n    result, error = svc.create_configuration(configuration, db, user_id)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"configuration\": []})\n\n\n    if not result:\n        return commons.is_none_reponse(\"Configuration Not Found\", {\"configuration\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        message=\"Configuration created successfully\",\n        error=None,\n        data={\"configuration\": result}\n    )\n\n@router.post(\"/configuration/update/{config_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef update_configuration(config_id: int, configuration: schemas.ConfigurationUpdate, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Updates an existing configuration in the database.\n\n    Args:\n        config_id (int): The ID of the configuration to update.\n        configuration (ConfigurationUpdate): The updated configuration details.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the configuration update.\n    \"\"\"\n\n    result, error = svc.update_configuration(config_id, configuration, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"configuration\": []})\n\n\n    if not result:\n        return commons.is_none_reponse(\"Configuration Not Found\", {\"configuration\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Configuration updated successfully\",\n        error=None,\n        data={\"configuration\": result}\n    )\n\n\n\n\n@cap_router.post(\"/create\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef create_capability(capability: schemas.CapabilitiesBase, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Creates a new capability in the database.\n\n    Args:\n        capability (CapabilitiesBase): The new capability details.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the capability creation.\n    \"\"\"\n\n    result, error = svc.create_capabilities(capability, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"capability\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        message=\"Capabilities created successfully\",\n        error=None,\n        data={\"capability\": result}\n    )\n\n@cap_router.get(\"/all\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_all_capabilities(db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves all capabilities from the database.\n\n    Args:\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing the list of capabilities or an error message.\n    \"\"\"\n\n    result, error = svc.get_all_capabilities(db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"capabilities\": []})\n\n\n    if not result:\n        return commons.is_none_reponse(\"Capabilities Not Found\", {\"capabilities\": []})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Capabilities retrieved successfully\",\n        error=None,\n        data={\"capabilities\": result}\n    )\n\n\n@cap_router.post(\"/update/{cap_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef update_capability(cap_id: int, capability: schemas.CapabilitiesUpdateBase, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Updates an existing capability in the database.\n\n    Args:\n        cap_id (int): The ID of the capability to update.\n        capability (CapabilitiesUpdateBase): The updated capability details.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the capability update.\n    \"\"\"\n\n    result, error = svc.update_capability(cap_id, capability, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"capability\": {}})\n\n\n    if not result:\n        return commons.is_none_reponse(\"Capability Not Found\", {\"capability\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Capability updated successfully\",\n        error=None,\n        data={\"capability\": result}\n    )\n\n@cap_router.delete(\"/delete/{cap_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef delete_capability(cap_id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Deletes an existing capability from the database.\n\n    Args:\n        cap_id (int): The ID of the capability to delete.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the capability deletion.\n    \"\"\"\n\n    result, error = svc.delete_capability(cap_id, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"capability\": {}})\n\n\n    if not result:\n        return commons.is_none_reponse(\"Capability Not Found\", {\"capability\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Capability deleted successfully\",\n        error=None,\n        data={\"capability\": {}}\n    )\n\n\n\n@router.post(\"/createyaml/{config_id}\", dependencies=[Depends(verify_token)])\ndef create_yaml(request: Request, config_id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Creates a YAML configuration file and initializes processing chains for the specified configuration.\n\n    Args:\n        request (Request): The request object containing the data for YAML creation.\n        config_id (int): The ID of the configuration to use.\n        db (Session): The database session dependency.\n\n    Returns:\n        dict: A dictionary with success status and error message, if any.\n    \"\"\"\n\n    documentations, use_case, is_error = svc.create_yaml_file(request,config_id, db)\n\n    if is_error:\n        return {\n            \"success\":False,\n            \"error\":is_error\n        }\n\n    inference_config, is_error = svc.create_inference_yaml(config_id,db)\n\n    if is_error and not inference_config:\n        return {\n            \"success\":False,\n            \"error\":is_error\n        }\n\n\n    combined_yaml_content = {\n        'datasources': documentations if documentations != None else [],\n        'use_case': use_case\n    }\n\n    configs.inference_llm_model=inference_config[0][\"unique_name\"]\n\n    config = request.app.config\n    vector_store, is_error = provider_svc.create_vectorstore_instance(db, config_id)\n    if vector_store:\n        vector_store.connect()\n        vector_store.clear_collection(config_id)\n    context_storage = request.app.context_storage\n\n    data_sources = combined_yaml_content[\"datasources\"]\n    use_case = combined_yaml_content[\"use_case\"]\n\n    config[\"use_case\"] = use_case\n    config[\"datasources\"] = data_sources\n    config[\"models\"] = inference_config\n\n    confyaml = svc.get_inference_and_plugin_configurations(db, config_id)\n    request.app.container.config.from_dict(confyaml)\n    datasources = request.app.container.datasources()\n\n    mappings = confyaml.get(\"mappings\",{})\n    datasources, err = svc.update_datasource_documentations(db, vector_store, datasources, mappings, config_id)\n    if err:\n        logger.error(\"Error updating\")\n\n    query_chain = QueryChain(config, vector_store, datasources, context_storage)\n    general_chain = GeneralChain(config, vector_store, datasources, context_storage)\n    capability_chain = CapabilityChain(config, context_storage, query_chain)\n    metedata_chain = MetadataChain(config, vector_store, datasources, context_storage)\n\n    chain = IntentChain(config, vector_store, datasources, context_storage, query_chain, general_chain, capability_chain, metedata_chain)\n\n    cache_manager.set(config_id, {\n        \"chain\": chain,\n        \"config\": config,\n        \"vector_store\": vector_store,\n        \"datasources\": datasources,\n        \"context_storage\": context_storage\n    })\n    \n    \n\n    return {\n        \"success\": True,\n        \"error\":None\n    }\n\n@inference_router.post(\"/get/models\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_llm_provider_models(llm_provider: schemas.LLMProviderBase):\n    \"\"\"\n    Retrieves the models associated with the specified LLM provider.\n    Args:\n        llm_provider (schemas.LLMProviderBase): The details of the LLM provider.\n        db (Session): The database session dependency.\n    Returns:\n        CommonResponse: A response containing the list of LLM provider models or an error message.\n    \"\"\"\n    data, is_error = svc.get_llm_provider_models(llm_provider)\n    if is_error:\n        return commons.is_error_response(\"LLM Provider Models Not Found\", data, {\"provider_models\": []})\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"LLM Provider Models Found\",\n        error=None,\n        data={\"provider_models\": [data]}\n    )\n\n@inference_router.get(\"/get/{inference_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_inference(inference_id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves an inference record from the database using the given inference ID.\n\n    Args:\n        inference_id (int): The ID of the inference record to retrieve.\n        db (Session): The database session dependency.\n\n    Returns:\n        dict: A dictionary with the inference details or error message, if any.\n    \"\"\"\n\n    result, error = svc.get_inference(inference_id, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"inference\": {}})\n\n\n    if not result:\n        return commons.is_none_reponse(\"Inference Not Found\", {\"inference\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Inference Found\",\n        error=None,\n        data={\"inference\": result}\n    )\n\n@inference_router.post(\"/create\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef create_inference(inference: schemas.InferenceBase, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Creates a new inference record in the database.\n\n    Args:\n        inference (schemas.InferenceBase): The details of the inference to be created.\n        db (Session): The database session dependency.\n\n    Returns:\n        dict: A dictionary indicating the success of the operation and the created inference details or error message.\n    \"\"\"\n    success, message = provider_svc.test_inference_credentials(inference)\n    if not success:\n        return commons.is_error_response(\"Test Credentials Failed\", message, {\"inference\": {}})\n\n    result, error = svc.create_inference(inference, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"inference\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        message=\"Inference Created Successfully\",\n        error=None,\n        data={\"inference\": result}\n    )\n\n@inference_router.post(\"/update/{inference_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef update_inference(inference_id: int, inference: schemas.InferenceBaseUpdate, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Updates an existing inference record in the database.\n\n    Args:\n        inference_id (int): The ID of the inference record to update.\n        inference (schemas.InferenceBaseUpdate): The updated details of the inference.\n        db (Session): The database session dependency.\n\n    Returns:\n        dict: A dictionary with the status of the update operation and the updated inference details or error message, if any.\n    \"\"\"\n    success, message = provider_svc.test_inference_credentials(inference)\n    if not success:\n        return commons.is_error_response(\"Test Credentials Failed\", message, {\"inference\": {}})\n\n    result, error = svc.update_inference(inference_id, inference, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"inference\": {}})\n\n\n    if not result:\n        return commons.is_none_reponse(\"Inference Not Found\", {\"inference\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        message=\"Inference Updated Successfully\",\n        error=None,\n        data={\"inference\": result}\n    )\n\n\n\n@actions.get(\"/list\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef list_actions(db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves all actions from the database.\n\n    Args:\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing the list of actions or an error message.\n    \"\"\"\n\n    result, error = svc.list_actions(db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"actions\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Actions Not Found\", {\"actions\": []})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"actions\": result},\n        message=\"Actions Found\",\n        error=None\n    )\n\n@actions.get(\"/get/{action_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_action(action_id:int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves a specific action by its ID.\n\n    Args:\n        action_id (int): The unique identifier of the action to retrieve.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing the action details or an error message.\n    \"\"\"\n\n    result, error = svc.get_actions(action_id,db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"action\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Action Not Found\", {\"action\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"action\": result},\n        message=\"Action Found\",\n        error=None\n    )\n\n@actions.get(\"/{connector_id}/list\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef get_actions_by_connector(connector_id:int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Retrieves all actions related to a specific connector by its ID.\n\n    Args:\n        connector_id (int): The unique identifier of the connector.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response containing the list of actions or an error message.\n    \"\"\"\n\n    result, error = svc.get_actions_by_connector(connector_id,db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"actions\": []})\n\n    if not result:\n        return commons.is_none_reponse(\"Actions Not Found\", {\"actions\": []})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"actions\": result},\n        message=\"Action Found\",\n        error=None\n    )\n\n@actions.post(\"/create\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef create_action(action: schemas.Actions, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Creates a new action in the database.\n\n    Args:\n        action (Actions): The schema containing action details to create.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the action creation.\n    \"\"\"\n\n    result, error = svc.create_action(action, db)\n\n    if error:\n        return commons.is_error_response(\"Action Not Created\", result, {\"action\": {}})\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=201,\n        data={\"action\": result},\n        message=\"Action Created\",\n        error=None\n    )\n\n@actions.post(\"/update/{action_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef update_action(action_id: int, action: schemas.ActionsUpdate, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Updates an existing action in the database by its ID.\n\n    Args:\n        action_id (int): The unique identifier of the action to update.\n        action (ActionsUpdate): The schema containing updated action details.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the action update.\n    \"\"\"\n\n    result, error = svc.update_action(action_id, action, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"action\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Action Not Found\", {\"action\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"action\": result},\n        message=\"Action Updated\",\n        error=None\n    )\n\n@actions.post(\"/{action_id}\", response_model=resp_schemas.CommonResponse, dependencies=[Depends(verify_token)])\ndef delete_action(action_id: int, db: Session = Depends(get_db)):\n\n    \"\"\"\n    Deletes an action by its ID from the database.\n\n    Args:\n        action_id (int): The unique identifier of the action to delete.\n        db (Session): Database session dependency.\n\n    Returns:\n        CommonResponse: A response indicating the success or failure of the action deletion.\n    \"\"\"\n\n    result, error = svc.delete_action(action_id, db)\n\n    if error:\n        return commons.is_error_response(\"DB error\", result, {\"action\": {}})\n\n    if not result:\n        return commons.is_none_reponse(\"Action Not Found\", {\"action\": {}})\n\n\n    return resp_schemas.CommonResponse(\n        status=True,\n        status_code=200,\n        data={\"action\": result},\n        message=\"Action Deleted\",\n        error=None\n    )\n"}
{"type": "source_file", "path": "app/chain/modules/context_storage.py", "content": "from typing import Any\nfrom loguru import logger\nfrom app.base.abstract_handlers import AbstractHandler\nfrom app.models.db import Chat\nimport datetime\n\nclass ContextStorage(AbstractHandler):\n    \"\"\"\n    A handler class for storing chat interactions in the context.\n\n    This class extends AbstractHandler and provides functionality to store\n    chat interactions, including questions, answers, and summaries, in the context store.\n    \"\"\"\n\n    def __init__(self,common_context, context_store) -> None:\n        \"\"\"\n        Initialize the ContextStorage.\n\n        Args:\n            common_context (Any): The common context shared across handlers.\n            context_store (Any): The storage mechanism for context data.\n        \"\"\"\n        self.context_store = context_store\n        self.common_context = context_store\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Handle the incoming request by storing the interaction in the context.\n\n        Args:\n            request (Dict[str, Any]): The incoming request to be processed.\n\n        Returns:\n            str: The response after processing the request.\n        \"\"\"\n\n        logger.info(\"Storing interaction into context\")\n        response = request\n\n        summary = ''\n        if \"summary\" in request:\n            summary = request['summary']\n        if \"context_id\" in request:\n            self.context_store.insert_data(Chat(context_id = request[\"context_id\"], question = request[\"question\"], created_at = datetime.datetime.now(), answer = request[\"content\"], summary = summary))\n\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/base/base_vectordb.py", "content": "from app.embeddings.loader import EmLoader\n\nclass BaseVectorDB():\n\n    def load_embeddings_function(self):\n        return EmLoader(self.embeddings).load_embclass().load_emb()"}
{"type": "source_file", "path": "app/chain/formatter/general_response.py", "content": "class Formatter:\n\n    def format(data: any, error: any) -> (dict):\n        response = {}\n\n        response[\"main_entity\"] = \"none\"\n        response[\"main_format\"] = \"general_chat\"\n        response[\"role\"] = \"assistant\"\n        response[\"content\"] = data\n        response[\"summary\"] = data\n        response[\"error\"] = error\n\n        return response"}
{"type": "source_file", "path": "app/chain/chains/intent_chain.py", "content": "from app.chain.modules.document_retriever import DocumentRetriever\nfrom app.chain.modules.input_formatter import InputFormatter\n\nfrom app.chain.modules.intent_extracter import IntentExtracter\nfrom app.chain.modules.router import Router\nfrom app.chain.modules.post_processor import PostProcessor\nfrom app.chain.formatter.general_response import Formatter\nfrom app.chain.modules.context_retreiver import ContextRetreiver\n\n\nfrom loguru import logger\n\nclass IntentChain:\n    \"\"\"\n    IntentChain class represents the main processing chain for handling user intents.\n\n    This class orchestrates various modules to process user input, extract intents,\n    route requests, and manage context across interactions.\n\n    Attributes:\n        vector_store: A storage system for vector embeddings.\n        data_source: A data source to be used in processing.\n        context_store: A storage system for maintaining context across interactions.\n        common_context (dict): A shared context dictionary used across modules.\n        configs (dict): Configuration settings for the models.\n        input_formatter (InputFormatter): Module for formatting user input.\n        context_retriver (ContextRetreiver): Module for retrieving context.\n        intent_extractor (IntentExtracter): Module for extracting intents from user input.\n        post_processor (PostProcessor): Module for post-processing responses.\n        router (Router): Module for routing requests to appropriate chains.\n        handler: The first module in the processing chain.\n\n    The IntentChain class follows a modular design, where each module is responsible\n    for a specific part of the processing pipeline. This allows for flexibility\n    and easy extension of functionality.\n    \"\"\"\n    def __init__(self, model_configs, store, datasource, context_store, intent_chain, general_chain, capability_chain, metadata_chain):\n        logger.info(\"loading modules into chain\")\n\n        self.vector_store = store\n        self.context_store = context_store\n        self.data_sources = datasource if datasource is not None else {}\n\n        self.common_context = {\n            \"chain_retries\" : 0,\n        }\n\n        self.configs = model_configs\n        self.input_formatter = InputFormatter()\n        self.context_retriver = ContextRetreiver(self.common_context, context_store)\n        self.intent_extractor = IntentExtracter(self.common_context, model_configs, self.data_sources)\n        self.document_retriever = DocumentRetriever(self.vector_store, self.data_sources)\n        self.post_processor = PostProcessor()\n        self.router = Router(self.common_context, self.post_processor, intent_chain, general_chain, capability_chain, metadata_chain)\n\n        self.input_formatter.set_next(self.context_retriver).set_next(self.document_retriever).set_next(self.intent_extractor).set_next(self.router).set_next(self.post_processor)\n\n        self.handler =  self.input_formatter\n\n\n    def invoke(self, user_request):\n        try:\n            self.common_context[\"chain_retries\"] = 0\n            self.common_context[\"context_id\"] = user_request[\"context_id\"]\n            return self.handler.handle(user_request)\n        except Exception as error:\n            logger.error(f\"An error occurred: {error}\")\n            return Formatter.format(\"Oops! Something went wrong. Try Again!\",error)\n"}
{"type": "source_file", "path": "app/chain/chains/metadata_chain.py", "content": "from app.chain.modules.input_formatter import InputFormatter\nfrom app.chain.modules.post_processor import PostProcessor\nfrom app.chain.modules.metadata_generator import MetadataGenerator\nfrom app.chain.modules.context_retreiver import ContextRetreiver\nfrom app.chain.modules.ouput_formatter import OutputFormatter\nfrom app.chain.modules.metadata_ragfilter import MetadataRagFilter\nfrom app.chain.modules.document_retriever import DocumentRetriever\n\nfrom loguru import logger\n\nclass MetadataChain:\n    \"\"\"\n    MetadataChain class represents the processing chain for handling metadata-related requests.\n\n    This class orchestrates various modules to process user input, retrieve context,\n    generate metadata, and format output for metadata-related operations.\n\n    Attributes:\n        vector_store: A storage system for vector embeddings.\n        data_sources: A list of data sources to be used in processing.\n        context_store: A storage system for maintaining context across interactions.\n        common_context (dict): A shared context dictionary used across modules.\n        input_formatter (InputFormatter): Module for formatting user input.\n        context_retriver (ContextRetreiver): Module for retrieving context.\n        document_retriever (DocumentRetriever): Module for retrieving relevant documents.\n        metadata_generator (MetadataGenerator): Module for generating metadata.\n        post_processor (PostProcessor): Module for post-processing responses.\n        metadata_ragfilter (MetadataRagFilter): Module for filtering metadata using RAG.\n        output_formatter (OutputFormatter): Module for formatting output.\n        handler: The first module in the processing chain.\n\n    The MetadataChain class follows a modular design, where each module is responsible\n    for a specific part of the processing pipeline. This allows for flexibility\n    and easy extension of functionality in metadata processing and generation.\n    \"\"\"\n    def __init__(self, model_configs, store, datasource, context_store):\n        logger.info(\"loading modules into metadata chain\")\n        self.vector_store = store\n        self.data_sources = datasource if datasource is not None else []\n        self.context_store = context_store\n\n        self.common_context = {\n            \"chain_retries\" : 0,\n        }\n\n        self.input_formatter = InputFormatter()\n        self.context_retriver = ContextRetreiver(self.common_context, context_store)\n        self.document_retriever = DocumentRetriever(self.vector_store, self.data_sources)\n\n        self.metadata_generator = MetadataGenerator(self.common_context, model_configs, self.data_sources)\n        self.post_processor = PostProcessor()\n        self.metadata_ragfilter = MetadataRagFilter()\n        self.output_formatter = OutputFormatter(self.common_context,self.data_sources)\n\n        self.input_formatter.set_next(self.context_retriver).set_next(self.metadata_ragfilter).set_next(self.document_retriever).set_next(self.metadata_generator).set_next(self.output_formatter).set_next(self.post_processor)\n        self.handler =  self.input_formatter\n\n\n    def invoke(self, user_request):\n\n        self.common_context[\"chain_retries\"] = 0\n        return self.handler.handle(user_request)\n"}
{"type": "source_file", "path": "app/chain/modules/executer.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\nfrom app.providers.config import configs\n\n\nclass Executer(AbstractHandler):\n    \"\"\"\n    A handler class for executing queries based on the inference.\n\n    This class extends AbstractHandler and provides functionality to execute\n    queries using the appropriate datasource and handle any errors that occur.\n    \"\"\"\n\n    def __init__(self, common_context, datasource, fallback_handler) -> None:\n        \"\"\"\n        Initialize the Executer.\n\n        Args:\n            common_context (Dict[str, Any]): The common context shared across handlers.\n            datasource (Dict[str, Any]): A dictionary of datasources keyed by intent.\n            fallback_handler (AbstractHandler): The handler to call in case of errors.\n        \"\"\"\n\n        self.fall_back_handler = fallback_handler\n        self.common_context = common_context\n        self.datasource = datasource\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Handle the incoming request by executing the query.\n\n        Args:\n            request (Dict[str, Any]): The incoming request to be processed.\n\n        Returns:\n            str: The response after processing the request.\n        \"\"\"\n        logger.info(\"passing through => executor\")\n\n        inference = request.get(\"inference\", {})\n        formated_sql = inference.get(\"query\", \"\")\n        logger.debug(f\"executing query:{formated_sql}\")\n\n        out, err = self.datasource[self.common_context[\"intent\"]].fetch_data(formated_sql)\n\n\n        if err is not None:\n            logger.error(f\"error in executing query:{err}\")\n            if self.common_context[\"chain_retries\"] < configs.retry_limit :\n                logger.info(\"going back for resolving error\")\n                self.common_context[\"chain_retries\"] =self.common_context[\"chain_retries\"] + 1\n                self.common_context[\"execution_logs\"].append({\"query\": formated_sql, \"error\": str(err)})\n                return self.fall_back_handler.handle(request)\n\n        response = {**dict(request), **{\n            \"query_response\": out,\n            \"query_error\": err,\n        }}\n\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/chain/chains/general_chain.py", "content": "from app.chain.modules.input_formatter import InputFormatter\n# from app.chain.modules.guard_rail import GuardRail\nfrom app.chain.modules.prompt_generator import PromptGenerator\nfrom app.chain.modules.general_answer_generator import GeneralAnswerGenerator\nfrom app.chain.modules.ouput_formatter import OutputFormatter\nfrom app.chain.modules.post_processor import PostProcessor\n\nfrom app.chain.modules.context_retreiver import ContextRetreiver\n\n\n\n\nfrom loguru import logger\n\nclass GeneralChain:\n    \"\"\"\n    Chain class represents the main processing chain for handling user requests.\n\n    This class orchestrates various modules to process user input, retrieve context,\n    generate prompts, execute actions, and format output.\n\n    Attributes:\n        vector_store: A storage system for vector embeddings.\n        data_sources: A list of data sources to be used in processing.\n        context_store: A storage system for maintaining context across interactions.\n        common_context (dict): A shared context dictionary used across modules.\n        configs (dict): Configuration settings for the models.\n        input_formatter (InputFormatter): Module for formatting user input.\n        rag_module (RagModule): Module for Retrieval-Augmented Generation.\n        prompt_generator (PromptGenerator): Module for generating prompts.\n        generator (Generator): Module for generating responses.\n        validator (Validator): Module for validating responses.\n        context_retriver (ContextRetreiver): Module for retrieving context.\n        context_storage (ContextStorage): Module for storing context.\n        executer (Executer): Module for executing actions.\n        cache_checker (Cachechecker): Module for checking and managing cache.\n        output_formatter (OutputFormatter): Module for formatting output.\n\n    The Chain class follows a modular design, where each module is responsible\n    for a specific part of the processing pipeline. This allows for flexibility\n    and easy extension of functionality.\n    \"\"\"\n    def __init__(self, model_configs, store, datasource, context_store):\n\n        logger.info(\"loading modules into chain\")\n\n\n        self.vector_store = store\n        self.data_sources = datasource if datasource is not None else []\n        self.context_store = context_store\n\n        self.common_context = {\n            \"chain_retries\" : 0,\n            \"rag\": {\n                \"context\": [],\n                \"schema\" : [],\n            },\n        }\n\n        self.configs = model_configs\n        self.input_formatter = InputFormatter()\n        self.prompt_generator = PromptGenerator(self.common_context, model_configs, self.data_sources)\n        self.generator = GeneralAnswerGenerator(self.common_context, model_configs)\n        self.context_retriver = ContextRetreiver(self.common_context, context_store)\n        self.output_formatter = OutputFormatter(self.common_context,self.data_sources)\n\n        self.post_processor = PostProcessor()\n\n        logger.info(\"initializing chain\")\n\n        self.input_formatter.set_next(self.context_retriver) \\\n        .set_next(self.prompt_generator).set_next(self.generator).set_next(self.output_formatter).set_next(self.post_processor)\n\n        self.handler =  self.input_formatter\n\n\n    def invoke(self, user_request):\n        self.common_context[\"chain_retries\"] = 0\n        self.common_context[\"intent\"] = user_request[\"intent_extractor\"][\"intent\"]\n        self.common_context[\"context_id\"] = user_request[\"context_id\"]\n        self.common_context[\"rag\"].update({\n            \"context\": [],\n            \"schema\" : [],\n        })\n        return self.handler.handle(user_request)\n"}
{"type": "source_file", "path": "app/base/remote_data_plugin.py", "content": "from abc import ABC, abstractmethod\nfrom typing import Dict, Any, Optional\n\nclass RemoteDataPlugin(ABC):\n\n    @abstractmethod\n    def fetch_data(self, params: Optional[Dict[str, Any]] = None) -> list:\n        \"\"\"\n        Fetches data based on the provided parameters.\n\n        :param params: Optional query parameters.\n        :return: a list of strings\n        \"\"\"\n        pass\n"}
{"type": "source_file", "path": "app/chain/modules/generator.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom app.providers.config import configs\nfrom app.loaders.base_loader import BaseLoader\nfrom app.utils.parser import parse_llm_response\nfrom app.chain.formatter.general_response import Formatter\nfrom loguru import logger\n\nclass Generator(AbstractHandler):\n        \"\"\"\n        A handler class for generating inferences based on prompts and contexts.\n\n        This class extends AbstractHandler and provides functionality to generate\n        inferences using a specified language model based on given prompts and contexts.\n        \"\"\"\n\n        def __init__(self, common_context, model_configs) -> None:\n                \"\"\"\n                Initialize the Generator.\n\n                Args:\n                common_context (Dict[str, Any]): The common context shared across handlers.\n                model_configs (Dict[str, Any]): Configuration for the models used in processing.\n                \"\"\"\n                self.model_configs = model_configs\n                self.common_context = common_context\n\n        async def handle(self, request: dict) -> str:\n                \"\"\"\n                Handle the incoming request by generating an inference based on the prompt and context.\n\n                This method extracts the prompt and context from the request, uses an inference model\n                to generate a response, and adds the parsed inference to the response.\n\n                Args:\n                request (Dict[str, Any]): The incoming request to be processed.\n\n                Returns:\n                str: The response after processing the request, including the generated inference.\n                \"\"\"\n                logger.info(\"passing through => generator\")\n\n                response = request\n                prompt = response[\"prompt\"]\n\n                contexts = request.get(\"context\",[])\n                contexts = contexts[-5:] if len(contexts) >= 5 else contexts\n\n                loader = BaseLoader(model_configs=self.model_configs[\"models\"])\n                infernce_model = loader.load_model(configs.inference_llm_model)\n\n                output, response_metadata = infernce_model.do_inference(\n                        prompt, contexts\n                )\n                if output[\"error\"] is not None:\n                        return Formatter.format(\"Oops! Something went wrong. Try Again!\",output['error'])\n\n                response[\"inference\"] = parse_llm_response(output['content'])\n                if not response[\"inference\"]:\n                        return Formatter.format(\"Oops! Something went wrong. Try Again!\",\"\")\n\n                return await super().handle(response)\n"}
{"type": "source_file", "path": "app/base/base_plugin.py", "content": "from abc import ABC, abstractmethod\n\nclass BasePlugin(ABC):\n\n    @abstractmethod\n    def connect(self):\n        pass\n\n    @abstractmethod\n    def healthcheck(self):\n        pass"}
{"type": "source_file", "path": "app/base/document_data_plugin.py", "content": "from abc import ABC, abstractmethod\nfrom typing import Dict, Any, Optional\n\nclass DocumentDataPlugin(ABC):\n\n    @abstractmethod\n    def fetch_data(self, params: Optional[Dict[str, Any]] = None) -> list:\n        \"\"\"\n        Fetches data based on the provided parameters.\n\n        :param params: Optional query parameters.\n        :return: a list of strings\n        \"\"\"\n        pass\n"}
{"type": "source_file", "path": "app/base/query_plugin.py", "content": "from abc import ABC, abstractmethod\nfrom typing import Dict, Any, Optional, Tuple\n\nclass QueryPlugin(ABC):\n\n    @abstractmethod\n    def fetch_data(self, query: str, params: Optional[Dict[str, Any]] = None) -> Tuple[Any, Optional[str]]:\n        \"\"\"\n        Fetches data based on the provided query.\n\n        :param query: The query.\n        :param params: Optional query parameters.\n        :return: A tuple containing the fetched data and an optional error message.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def fetch_schema_details(self) -> Tuple[list, list]:\n        \"\"\"\n        Fetches schema details from Airtable.\n\n        :return: A tuple containing schema DDL as a list of strings and table metadata.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def create_ddl_from_metadata(self, table_metadata: list) -> list:\n        \"\"\"\n        Creates DDL from table metadata.\n\n        :param table_metadata: List of table metadata dictionaries.\n        :return: List of schema DDL strings.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate(self, formatted_sql: str) -> None:\n        \"\"\"\n        Validates the provided SQL.\n\n        :param formatted_sql: SQL string to validate.\n        \"\"\"\n        pass"}
{"type": "source_file", "path": "app/base/messaging_plugin.py", "content": "from abc import ABC, abstractmethod\n\nclass MessagePlugin(ABC):\n\n    @abstractmethod\n    def send(self):\n        pass\n"}
{"type": "source_file", "path": "app/chain/modules/context_retreiver.py", "content": "from typing import Any\nfrom loguru import logger\nfrom app.base.abstract_handlers import AbstractHandler\nfrom app.models.llmchat import ChatHistory\n\nclass ContextRetreiver(AbstractHandler):\n    \"\"\"\n    A handler class for retrieving context information for a chat.\n\n    This class extends AbstractHandler and provides functionality to fetch\n    relevant context based on the context_id provided in the request.\n    \"\"\"\n\n    def __init__(self,common_context, context_store) -> None:\n        \"\"\"\n        Initialize the ContextRetriever.\n\n        Args:\n            common_context (Any): The common context shared across handlers.\n            context_store (Any): The storage mechanism for context data.\n        \"\"\"\n        self.context_store = context_store\n        self.common_context = context_store\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Handle the incoming request by retrieving relevant context.\n\n        Args:\n            request (Dict[str, Any]): The incoming request to be processed.\n\n        Returns:\n            str: The response after processing the request.\n        \"\"\"\n\n        logger.info(\"retrieving context into chain\")\n        response = request\n\n        context = []\n\n        if \"context_id\" in request:\n            records = self.context_store.query_data(model = ChatHistory, filters= {\"chat_context_id\": request[\"context_id\"]})\n            context.extend(records)\n\n        response[\"context\"] = context\n\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/chain/chains/query_chain.py", "content": "from app.chain.modules.document_retriever import DocumentRetriever\nfrom app.chain.modules.input_formatter import InputFormatter\n# from app.chain.modules.guard_rail import GuardRail\nfrom app.chain.modules.prompt_generator import PromptGenerator\nfrom app.chain.modules.generator import Generator\nfrom app.chain.modules.schema_retriever import SchemaRetriever\nfrom app.chain.modules.validator import Validator\nfrom app.chain.modules.executer import Executer\nfrom app.chain.modules.ouput_formatter import OutputFormatter\nfrom app.chain.modules.post_processor import PostProcessor\nfrom app.chain.formatter.general_response import Formatter\nfrom app.chain.modules.cache_checker import Cachechecker\n\nfrom app.chain.modules.context_retreiver import ContextRetreiver\nfrom app.chain.modules.context_storage import ContextStorage\n\n\n\n\nfrom loguru import logger\n\nclass QueryChain:\n    \"\"\"\n    Chain class represents the main processing chain for handling user requests.\n\n    This class orchestrates various modules to process user input, retrieve context,\n    generate prompts, execute actions, and format output.\n\n    Attributes:\n        vector_store: A storage system for vector embeddings.\n        data_sources: A list of data sources to be used in processing.\n        context_store: A storage system for maintaining context across interactions.\n        common_context (dict): A shared context dictionary used across modules.\n        configs (dict): Configuration settings for the models.\n        input_formatter (InputFormatter): Module for formatting user input.\n        rag_module (RagModule): Module for Retrieval-Augmented Generation.\n        prompt_generator (PromptGenerator): Module for generating prompts.\n        generator (Generator): Module for generating responses.\n        validator (Validator): Module for validating responses.\n        context_retriver (ContextRetreiver): Module for retrieving context.\n        context_storage (ContextStorage): Module for storing context.\n        executer (Executer): Module for executing actions.\n        cache_checker (Cachechecker): Module for checking and managing cache.\n        output_formatter (OutputFormatter): Module for formatting output.\n\n    The Chain class follows a modular design, where each module is responsible\n    for a specific part of the processing pipeline. This allows for flexibility\n    and easy extension of functionality.\n    \"\"\"\n    def __init__(self, model_configs, store, datasource, context_store):\n\n        logger.info(\"loading modules into chain\")\n\n\n        self.vector_store = store\n        self.data_sources = datasource if datasource is not None else []\n        self.context_store = context_store\n\n        self.common_context = {\n            \"chain_retries\" : 0,\n            \"llm\": {\n                \"input_tokens\" : 0,\n                \"output_tokens\": 0,\n                \"total_cost\": 0,\n                \"latency\": 0,\n                \"response\": {\n                    \"input_tokens\" : 0,\n                    \"output_tokens\": 0,\n                    \"total_cost\": 0,\n                    \"latency\": 0,\n                    \"logprob_percentage\": 0,\n                    \"name\": \"default\"\n                    },\n            },\n            \"execution_logs\": [],\n            \"general_response\": Formatter,\n            \"prompt_mode\" : \"manual\",\n            \"inference_raw\" : \"\",\n            \"prompt\": \"\",\n            \"rag\": {\n                \"context\": [],\n                \"schema\" : [],\n            },\n        }\n\n        self.configs = model_configs\n        self.input_formatter = InputFormatter()\n\n        self.prompt_generator = PromptGenerator(self.common_context, model_configs, self.data_sources)\n        self.generator = Generator(self.common_context, model_configs)\n        self.validator = Validator(self.common_context,self.data_sources)\n        self.context_retriver = ContextRetreiver(self.common_context, context_store)\n        self.context_storage = ContextStorage(self.common_context, context_store)\n        self.schema_retriever = SchemaRetriever(self.vector_store, self.data_sources)\n        self.executer = Executer(self.common_context,self.data_sources, self.prompt_generator)\n        self.cache_checker = Cachechecker(self.common_context, self.vector_store,self.executer)\n        self.output_formatter = OutputFormatter(self.common_context,self.data_sources)\n        self.post_processor = PostProcessor()\n\n        logger.info(\"initializing chain\")\n\n        self.input_formatter.set_next(self.cache_checker) \\\n        .set_next(self.context_retriver) \\\n        .set_next(self.prompt_generator).set_next(self.generator).set_next(self.validator).set_next(self.executer) \\\n        .set_next(self.output_formatter).set_next(self.post_processor)\n\n        self.handler =  self.input_formatter\n\n\n    def invoke(self, user_request):\n        self.common_context[\"chain_retries\"] = 0\n        self.common_context[\"intent\"] = user_request[\"intent_extractor\"][\"intent\"]\n        self.common_context[\"context_id\"] = user_request[\"context_id\"]\n        self.common_context[\"llm\"].update({\n            \"input_tokens\" : 0,\n            \"output_tokens\": 0,\n            \"total_cost\": 0,\n            \"latency\": 0,\n            \"response\": {\n                \"input_tokens\" : 0,\n                \"output_tokens\": 0,\n                \"total_cost\": 0,\n                \"latency\": 0,\n                \"logprob_percentage\": 0,\n                \"name\": \"default\"\n                },\n        })\n        self.common_context[\"prompt_mode\"] = \"manual\"\n        self.common_context[\"rag\"].update({\n            \"context\": [],\n            \"schema\" : [],\n        })\n        return self.handler.handle(user_request)\n"}
{"type": "source_file", "path": "app/base/plugin_metadata_mixin.py", "content": "import importlib\nfrom loguru import logger\n\nclass PluginMetadataMixin:\n\n    # plugin default variables\n    __version__ = \"\"\n    __plugin_name__ = \"\"\n    __description__ = \"\"\n    __icon__ = \"\"\n    __connection_args__= \"\"\n    __category__ = \"\"\n    __prompt__ = \"\"\n\n\n\n    def __init__(self, name):\n        logger.info(\"Initializing mixin class\")\n        self._load_metadata(name.removesuffix('.handler'))\n\n\n    @classmethod\n    def _load_metadata(self, class_path):\n        module = importlib.import_module(class_path)\n\n        try:\n            self.__version__ = getattr(module, '__version__')\n            self.__plugin_name__ = getattr(module, '__plugin_name__')\n            self.__description__ = getattr(module, '__description__')\n            self.__icon__ = getattr(module, '__icon__')\n            self.__connection_args__ = getattr(module, '__connection_args__')\n            self.__category__ = getattr(module, '__category__')\n            self.__prompt__ = getattr(module, '__prompt__')\n        except Exception as e:\n            raise Exception(e)"}
{"type": "source_file", "path": "app/chain/modules/input_formatter.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\n\n\nclass InputFormatter(AbstractHandler):\n\n    async def handle(self, request: Any) -> str:\n        logger.info(\"passing through => input_formatter\")\n\n        response = request\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/base/model_loader.py", "content": "class ModelLoader:\n\n\n    def __init__(self, model_config):\n        self.model_config = model_config\n\n    def load_model(self):\n        raise NotImplementedError(\"load_model method must be implemented in subclass\")\n\n    def get_response(self) -> dict:\n        raise NotImplementedError(\"load_model method must be implemented in subclass\")\n\n    def get_usage(self, prompt, response, out) -> dict:\n        raise NotImplementedError(\"load_model method must be implemented in subclass\")\n\n    def get_models(self):\n        raise NotImplementedError(\"load_model method must be implemented in subclass\")"}
{"type": "source_file", "path": "app/chain/modules/cache_updater.py", "content": "from typing import Any\nfrom loguru import logger\nfrom app.base.abstract_handlers import AbstractHandler\n\nclass Cacheupdater(AbstractHandler):\n    \"\"\"\n    A handler class for updating the cache with new query responses.\n\n    This class extends AbstractHandler and provides functionality to update\n    the cache with new question-inference pairs when appropriate.\n    \"\"\"\n\n    def __init__(self,cachestore) -> None:\n        \"\"\"\n        Initialize the Cacheupdater.\n\n        Args:\n            Cachestore (Any): The cache storage mechanism.\n        \"\"\"\n        self.cache = cachestore\n\n    async def handle(self, response: Any) -> str:\n        \"\"\"\n        Handle the incoming response by updating the cache if necessary.\n\n        Args:\n            response (Dict[str, Any]): The response to be processed.\n\n        Returns:\n            str: The response after processing.\n        \"\"\"\n        logger.info(\"passing through => cache_updater\")\n        data = response[\"query_response\"]\n\n        # question would not be in response if retrieved from cache\n        if (\"question\" in response) and not(data is None or len(data) == 0):\n            logger.info(\"cache updated\")\n            inference = response[\"inference\"]\n            question = response[\"question\"]\n            self.cache.update_cache(\n                document = question,\n                metadata = inference,\n            )\n        return await super().handle(response)"}
{"type": "source_file", "path": "app/chain/modules/document_retriever.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom loguru import logger\nfrom typing import Any\nfrom app.providers.container import Container\nimport asyncio\n\n\n\nclass DocumentRetriever(AbstractHandler):\n    \"\"\"\n    A handler class for retrieving relevant documents based on the input question.\n\n    This class extends AbstractHandler and provides functionality to find and\n    process similar documents from a vector store based on the input question.\n    \"\"\"\n\n    def __init__(self,store, datasources):\n        \"\"\"\n        Initialize the DocumentRetriever.\n\n        Args:\n            store (Any): The vector store for document retrieval.\n        \"\"\"\n\n        self.store =store\n        self.context_relevance_threshold = 4\n        self.datasources = datasources\n\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Handle the incoming request by retrieving relevant documents.\n\n        Args:\n            request (Dict[str, Any]): The incoming request to be processed.\n\n        Returns:\n            str: The response after processing the request.\n        \"\"\"\n\n        logger.info(\"passing through => document_retriever\")\n        response = request\n        tasks = [\n                self.store.find_similar_documentation(datasource, request['question'], 10)\n                for datasource in self.datasources\n            ]\n        results = await asyncio.gather(*tasks)\n\n\n        logger.info(\"sorting retrieved documents\")\n        for index, out in enumerate(results):\n            opt_doc = []\n            if out and len(out) > 0 and out[0]['distances'] < self.context_relevance_threshold:\n                distances = [doc['distances'] for doc in out]\n                if len(out) > 5:\n                    clusters = Container.clustering().kmeans(distances, 2)\n                    shortest_cluster = clusters[0]\n                    for doc in out:\n                        if doc['distances'] in shortest_cluster:\n                            opt_doc.append(doc)\n                else:\n                    opt_doc = out\n\n            if \"rag\" not in response:\n                response[\"rag\"]= {\"context\" : {}}\n            response[\"rag\"][\"context\"][list(self.datasources.keys())[index]] = opt_doc\n\n        return await super().handle(response)\n\n\n\n\n\n"}
{"type": "source_file", "path": "app/base/loader_metadata_mixin.py", "content": "import importlib\nfrom loguru import logger\n\nclass LoaderMetadataMixin:\n\n    # plugin default variables\n    __unique_name__ = \"\"\n    __display_name__ = \"\"\n    __icon__ = \"\"\n\n\n    def __init__(self, name):\n        logger.info(\"Initializing mixin class\")\n        self._load_metadata(name.removesuffix('.loader'))\n\n\n    @classmethod\n    def _load_metadata(self, class_path):\n        module = importlib.import_module(class_path)\n\n        try:\n            self.__unique_name__ = getattr(module, '__unique_name__')\n            self.__display_name__ = getattr(module, '__display_name__')\n            self.__icon__ = getattr(module, '__icon__')\n        except Exception as e:\n            raise Exception(e)"}
{"type": "source_file", "path": "app/chain/modules/cache_checker.py", "content": "from typing import Any\nfrom loguru import logger\nfrom app.base.abstract_handlers import AbstractHandler\n\n\nclass Cachechecker(AbstractHandler):\n    \"\"\"\n    A handler class for checking and managing cache operations.\n\n    This class extends AbstractHandler and provides functionality to check\n    if a query exists in the cache and handle the response accordingly.\n    \"\"\"\n\n    def __init__(self,common_context, cachestore, forward_handler, forward: bool = True) -> None:\n        \"\"\"\n        Initialize the Cachechecker.\n\n        Args:\n            common_context: The common context shared across handlers.\n            Cachestore: The cache storage mechanism.\n            forward_handler: The next handler in the chain.\n            forward (bool): Whether to forward the request to the next handler.\n        \"\"\"\n        self.cache = cachestore\n        self.forward_handler = forward_handler\n        self.forward = forward\n        self.common_context = common_context\n\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Handle the incoming request by checking the cache\n\n        Args:\n            request (Any): The incoming request to be processed.\n\n        Returns:\n            str: The response after processing the request.\n        \"\"\"\n        logger.info(\"passing through => cache_checker\")\n\n        response = request\n        question = request.get(\"question\", \"\")\n        rag_filters = response[\"rag_filters\"][\"datasources\"]\n        output = self.cache.find_similar_cache(rag_filters, question)\n        if \"rag\" not in response:\n            response[\"rag\"] = {\n                \"suggestions\": output\n            }\n        else:\n            response[\"rag\"][\"suggestions\"] = output\n\n\n\n        if self.forward and len(output) > 0:\n            if output[0][\"distances\"] < -10:\n                result = output[0][\"metadatas\"]\n                logger.info(\"query retrieved from cache\")\n                return await self.forward_handler.handle({\"inference\":result})\n\n        logger.info(\"query not retrieved from cache\")\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/chain/modules/follow_up_handler.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\nfrom app.providers.config import configs\nfrom app.loaders.base_loader import BaseLoader\nfrom string import Template\nfrom app.utils.parser import parse_llm_response\nfrom app.chain.formatter.general_response import Formatter\n\nclass FollowupHandler(AbstractHandler):\n    \"\"\"\n    A handler class for processing follow-up queries and extracting required parameters.\n\n    This class extends AbstractHandler and provides functionality to process\n    follow-up queries, extract intent-specific parameters, and generate appropriate responses.\n    \"\"\"\n\n    def __init__(self, common_context , model_configs) -> None:\n        \"\"\"\n        Initialize the FollowupHandler.\n\n        Args:\n            common_context (Dict[str, Any]): The common context shared across handlers.\n            model_configs (Dict[str, Any]): Configuration for the models used in processing.\n        \"\"\"\n\n        self.model_configs = model_configs\n        self.common_context = common_context\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Handle the incoming request by processing follow-up queries and extracting parameters.\n\n        Args:\n            request (Dict[str, Any]): The incoming request to be processed.\n\n        Returns:\n            str: The response after processing the request.\n        \"\"\"\n        response = request\n        logger.info(\"passing through => Intent extractor\")\n\n        use_case = self.model_configs.get(\"use_case\", {})\n        capabilities = use_case.get(\"capabilities\", [])\n\n        intent_extracted = request.get(\"intent_extractor\")\n        intent = intent_extracted.get(\"intent\", \"\")\n\n        filtered_capabilities = [capability for capability in capabilities if capability[\"name\"]== intent]\n        capability = filtered_capabilities[0]\n\n\n        long_description = use_case[\"long_description\"]\n        capability_description = capability[\"description\"]\n        parameter_description = \"\"\n\n        parameters = capability[\"requirements\"]\n        for parameter in parameters:\n            parameter_description= parameter_description + parameter[\"parameter_name\"]+ \" : \"+ parameter[\"parameter_description\"]+\"\\n\"\n\n        prompt = \"\"\"\n                You are part of a Form automations system where your duty is to: $capability_description\n                You will be given inputs that need to be captured. Your task is to ask and capture this information from the user and get it confirmed.\n\n                -- Form system context ---\n                $long_description\n                -- Form system context ---\n\n                Required parameters\n                -- Parameter section ---\n                $parameter_description\n                --- Parameter section ---\n\n                Instructions:\n                Carefully review all previous messages to establish context.\n                Only extract values that are explicitly provided in previous messages.\n                Do not assume or fill in any values that are not present in previous messages.\n                Do not hallucinate or claim that required values are present when they are not.\n\n                Generate a JSON response in the following format for the query '$question':\n                {\n                  \"explanation\": \"Describe which required values were found in previous messages and how they were extracted. If no values were found, state this clearly.\",\n                  \"params\": {},dont extract values for the params which is not mentioned in previous messages\n                  \"completed\": \"true|false, if all the required values are captured\",\n                  \"message\": \"Ask for specific required parameters that have not been provided yet. If all parameters are captured, provide a success message for the booking.\",\n                  \"summary\" : \"summarise question and answer in one sentence\"\n                }\n          \"\"\"\n\n        contexts = request.get(\"context\", [])\n        contexts = contexts[-5:] if len(contexts) >= 5 else contexts\n\n        prompt = Template(prompt).safe_substitute(\n            question = request[\"question\"],\n            long_description= long_description,\n            capability_description= capability_description,\n            parameter_description=parameter_description\n        )\n\n\n        loader = BaseLoader(model_configs=self.model_configs[\"models\"])\n        infernce_model = loader.load_model(configs.inference_llm_model)\n\n        output, response_metadata = infernce_model.do_inference(\n                            prompt, contexts\n                    )\n        \n        if output[\"error\"] is not None:\n            return await Formatter.format(\"Oops! Something went wrong. Try Again!\",output['error'])\n\n        response[\"inference\"] = parse_llm_response(output['content'])\n        response[\"capability\"] = capability\n        return await super().handle(response)\n\n\n"}
{"type": "source_file", "path": "app/chain/modules/followup_interpreter.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\nfrom app.chain.formatter.general_response import Formatter\n\nclass FollowupInterpreter(AbstractHandler):\n    \"\"\"\n    A handler class for interpreting follow-up responses and formatting them.\n\n    This class extends AbstractHandler and provides functionality to interpret\n    the inference results from follow-up queries and format the response accordingly.\n    \"\"\"\n\n\n    def __init__(self, common_context, general_chain) -> None:\n        \"\"\"\n        Initialize the FollowupInterpreter.\n\n        Args:\n            common_context (Dict[str, Any]): The common context shared across handlers.\n            general_chain (Any): The general processing chain for fallback scenarios.\n        \"\"\"\n\n        self.common_context = common_context\n        self.general_chain = general_chain\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Handle the incoming request by interpreting the inference results and formatting the response.\n        Args:\n            request (Dict[str, Any]): The incoming request to be processed.\n\n        Returns:\n            str: The formatted response after processing the request.\n        \"\"\"\n\n        logger.info(\"passing through => interpreter\")\n        response = request\n\n        if \"inference\" in request:\n            inference = request[\"inference\"]\n            if inference[\"completed\"] == True or inference[\"completed\"] == \"true\":\n                logger.info(\"Intent completed, trigger the action\")\n\n            response = Formatter.format(inference[\"message\"],\"\")\n            response[\"summary\"] = request[\"inference\"][\"summary\"]\n            response[\"question\"] = request[\"question\"]\n            response[\"context_id\"] = request[\"context_id\"]\n        else:\n            logger.info(\"No intents detected\")\n            response = Formatter.format(\"Sorry, I didn't get that\",\"\")\n\n        return await super().handle(response)\n\n"}
{"type": "source_file", "path": "app/chain/modules/general_answer_generator.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom app.providers.config import configs\nfrom app.loaders.base_loader import BaseLoader\nfrom app.utils.parser import markdown_parse_llm_response\nfrom app.chain.formatter.general_response import Formatter\nfrom loguru import logger\n\nclass GeneralAnswerGenerator(AbstractHandler):\n        \"\"\"\n        A handler class for generating inferences based on prompts and contexts.\n\n        This class extends AbstractHandler and provides functionality to generate\n        inferences using a specified language model based on given prompts and contexts.\n        \"\"\"\n\n        def __init__(self, common_context, model_configs) -> None:\n                \"\"\"\n                Initialize the Generator.\n\n                Args:\n                common_context (Dict[str, Any]): The common context shared across handlers.\n                model_configs (Dict[str, Any]): Configuration for the models used in processing.\n                \"\"\"\n                self.model_configs = model_configs\n                self.common_context = common_context\n\n        async def handle(self, request: dict) -> str:\n                \"\"\"\n                Handle the incoming request by generating an inference based on the prompt and context.\n\n                This method extracts the prompt and context from the request, uses an inference model\n                to generate a response, and adds the parsed inference to the response.\n\n                Args:\n                request (Dict[str, Any]): The incoming request to be processed.\n\n                Returns:\n                str: The response after processing the request, including the generated inference.\n                \"\"\"\n                logger.info(\"passing through => generator\")\n\n                response = request\n                prompt = response[\"prompt\"]\n\n                contexts = request.get(\"context\",[])\n                contexts = contexts[-5:] if len(contexts) >= 5 else contexts\n\n                loader = BaseLoader(model_configs=self.model_configs[\"models\"])\n                infernce_model = loader.load_model(configs.inference_llm_model)\n\n                output, response_metadata = infernce_model.do_inference(\n                        prompt, contexts\n                )\n                if output[\"error\"] is not None:\n                        return await Formatter.format(\"Oops! Something went wrong. Try Again!\",output['error'])\n\n                response[\"inference\"] = markdown_parse_llm_response(output['content'])\n                if not response[\"inference\"]:\n                        return await Formatter.format(\"Oops! Something went wrong. Try Again!\",\"\")\n\n                return await super().handle(response)\n"}
{"type": "source_file", "path": "app/chain/chains/capability_chain.py", "content": "from app.chain.modules.input_formatter import InputFormatter\nfrom app.chain.modules.post_processor import PostProcessor\nfrom app.chain.modules.follow_up_handler import FollowupHandler\nfrom app.chain.modules.context_retreiver import ContextRetreiver\nfrom app.chain.modules.followup_interpreter import FollowupInterpreter\n\n\nfrom loguru import logger\n\nclass CapabilityChain:\n    \"\"\"\n    CapabilityChain class represents the processing chain for handling capability-related requests.\n\n    This class orchestrates various modules to process user input, handle follow-ups,\n    interpret follow-up requests, and manage context across interactions.\n\n    Attributes:\n        common_context (dict): A shared context dictionary used across modules.\n        input_formatter (InputFormatter): Module for formatting user input.\n        context_retriver (ContextRetreiver): Module for retrieving context.\n        followup_handler (FollowupHandler): Module for handling follow-up requests.\n        followup_interpreter (FollowupInterpreter): Module for interpreting follow-up requests.\n        post_processor (PostProcessor): Module for post-processing responses.\n        handler: The first module in the processing chain.\n\n    The CapabilityChain class follows a modular design, where each module is responsible\n    for a specific part of the processing pipeline. This allows for flexibility\n    and easy extension of functionality.\n    \"\"\"\n    def __init__(self, model_configs, context_storage, general_chain):\n\n        logger.info(\"loading modules into capability chain\")\n\n\n        self.common_context = {}\n\n        self.input_formatter = InputFormatter()\n        self.context_retriver = ContextRetreiver(self.common_context, context_storage)\n        self.followup_handler = FollowupHandler(self.common_context, model_configs)\n        self.followup_interpreter = FollowupInterpreter(self.common_context, general_chain)\n        self.post_processor = PostProcessor()\n\n\n\n        logger.info(\"initializing chain\")\n        self.input_formatter.set_next(self.context_retriver).set_next(self.followup_handler).set_next(self.followup_interpreter).set_next(self.post_processor)\n        self.handler =  self.input_formatter\n\n\n    def invoke(self, user_request):\n        logger.info(\"Processing user request\")\n        return self.handler.handle(user_request)\n"}
{"type": "source_file", "path": "app/chain/modules/metadata_ragfilter.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\n\n\nclass MetadataRagFilter(AbstractHandler):\n    \"\"\"\n    A handler for applying RAG (retrieval-augmented generation) filters based on metadata.\n\n    This class modifies the request's response to include RAG filters, setting the number of documents and schemas\n    to be considered in retrieval operations. It also includes tracing for monitoring and debugging purposes.\n\n    Inherits from:\n        AbstractHandler: A base class for handling requests in the application.\n\n    Methods:\n        handle(request: Any) -> str:\n            Processes the request to apply RAG filters and forwards it to the next handler.\n    \"\"\"\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Applies RAG filters to the request's response and forwards it to the next handler.\n\n        Args:\n            request (Any): The incoming request containing the necessary information for filtering.\n\n        Returns:\n            str: The result of the superclass's handle method with updated response information.\n        \"\"\"\n        logger.info(\"passing through => metadata_ragfilter\")\n        response = request\n        response[\"rag_filters\"] = {\n                \"datasources\": response.get(\"available_datasources\", []),\n                \"document_count\": 10,\n                \"schema_count\": 10\n        }\n\n\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/chain/modules/schema_retriever.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom loguru import logger\nfrom typing import Any\nfrom app.providers.container import Container\n\n\n\nclass SchemaRetriever(AbstractHandler):\n    \"\"\"\n    A handler for retrieving similar schemas based on a given question and context.\n\n    This class queries the store for schemas similar to the input question and context. It processes the\n    retrieved schemas to potentially cluster them and select the most relevant schemas based on certain criteria.\n\n    Attributes:\n        store (object): The data store used to find similar schemas.\n    \"\"\"\n\n    def __init__(self,store,datasources):\n        \"\"\"\n        Initializes the SchemaRetriever with the provided store.\n\n        Args:\n            store (object): The data store used for schema retrieval.\n        \"\"\"\n        self.store = store\n        self.datasources = datasources\n\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Retrieves similar schemas from the store and updates the response with the results.\n\n        Args:\n            request (Any): The incoming request containing the question, context, and filtering criteria.\n\n        Returns:\n            Dict[str, Any]: The updated response dictionary with retrieved schemas.\n        \"\"\"\n\n        logger.info(\"passing through => schema_retriever\")\n\n        response = request\n\n        schema_count = request.get('rag_filters', {}).get(\"schema_count\", 0)\n\n        auto_context = \"\\n\\n\".join(cont.get(\"document\", \"\") for cont in request.get(\"rag\", {}).get(\"context\", []))\n        intent = request.get(\"intent_extracter\",{}).get(\"intent\",\"\")\n\n        datasource = self.datasources[intent]\n        out = await self.store.find_similar_schema(datasource, request[\"question\"] + \"\\n\" + auto_context, schema_count)\n\n        if out and len(out) > 0:\n            distances = [doc['distances'] for doc in out]\n            if len(out) > 2:\n                clusters = Container.clustering().kmeans(distances, 2)\n                shortest_cluster = clusters[0]\n                opt_doc = [doc for doc in out if doc.get('distances') in shortest_cluster]\n            else:\n                opt_doc = out\n\n            response[\"rag\"].update({\n                 \"schema\":    opt_doc,\n            })\n        else:\n            response[\"rag\"].update({\n                \"schema\": [],\n            })\n\n        return await super().handle(response)\n\n\n\n\n\n"}
{"type": "source_file", "path": "app/chain/modules/post_processor.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\n\nclass PostProcessor(AbstractHandler):\n\n    async def handle(self, request: Any) -> str:\n        logger.info(\"passing through => post_processor\")\n        response = request\n        return response\n"}
{"type": "source_file", "path": "app/chain/modules/prompt_generator.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\nfrom string import Template\n\nclass PromptGenerator(AbstractHandler):\n    \"\"\"\n    A handler for generating prompts based on the provided context, model configurations, and data sources.\n\n    This class creates a formatted prompt for the model by combining various elements such as system prompts,\n    user prompts, and context information. It supports both manual and automatic prompt injection modes.\n\n    Attributes:\n        common_context (dict): Shared context information used across handlers.\n        model_configs (dict): Configuration settings for the model, including prompt injection settings.\n        datasources (dict): Data sources for generating prompt contexts based on intent.\n    \"\"\"\n\n\n    def __init__(self, common_context , model_configs, datasources) -> None:\n        \"\"\"\n        Initializes the PromptGenerator with common context, model configurations, and data sources.\n\n        Args:\n            common_context (dict): Shared context information used across handlers.\n            model_configs (dict): Configuration settings for the model.\n            datasources (dict): Data sources for generating prompt contexts based on intent.\n        \"\"\"\n\n        self.model_configs = model_configs\n        self.common_context = common_context\n        self.datasources = datasources\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Generates a prompt based on the incoming request and provided configurations.\n        Args:\n            request (Any): The incoming request containing data for prompt generation.\n\n        Returns:\n            str: The result of the superclass's handle method with the generated prompt included in the response.\n        \"\"\"\n\n        logger.info(\"passing through => prompt_generator\")\n        response = request\n        intent = response[\"intent_extractor\"]['intent']\n\n        # Few shot prompting\n        samples_retrieved = \"\"\n\n        recal_history = \"\"\n        rag = request.get(\"rag\", {})\n        suggestions = rag.get(\"suggestions\", [])\n        for doc in suggestions:\n            samples_retrieved += f\"question: {doc.get('document', '')}\\n\"\n            samples_retrieved += f\"query: {doc.get('metadatas', {}).get('query', '')}\\n\\n\"\n\n\n        prompt_injection = self.model_configs.get(\"prompt_injection\", {\"mode\": \"auto\"})\n        data_source = self.datasources.get(self.common_context.get(\"intent\", \"default\"))\n\n        context = data_source.__prompt__\n        prompt = context.base_prompt\n\n\n        system_prompt = \"\"\n\n        if prompt_injection[\"mode\"] == \"manual\" :\n            system_prompt_context = context.system_prompt\n            system_prompt = system_prompt_context.template.format(\n                **{**system_prompt_context[\"prompt_variables\"]}\n            )\n        else:\n            auto_context = \"\\n\\n\".join(cont[\"document\"] for cont in rag.get(\"context\", {}).get(intent,[]))\n            auto_schema = \"\\n\\n\".join(schema[\"document\"] for schema in rag.get(\"schema\", []))\n            system_prompt_context = context.system_prompt\n            system_prompt = system_prompt_context.template.format(\n                schema=auto_schema,\n                context=auto_context,\n                question=request.get(\"question\", \"\"),\n                suggestions=\"\",\n                recall=recal_history\n            )\n\n\n        user_prompt = \"\"\n\n        if self.common_context[\"chain_retries\"] == 0:\n            user_prompt = context.user_prompt.template\n        else:\n            logger.info(\"regenerating prompt using available context\")\n            regeneration_promt_context = context.regeneration_prompt\n\n            user_prompt = Template(regeneration_promt_context.template).safe_substitute(\n                exception_log =self.common_context[\"execution_logs\"][0][\"error\"] if len(self.common_context[\"execution_logs\"])>0 else \"\",\n                query_generated =self.common_context[\"execution_logs\"][0][\"query\"] if len(self.common_context[\"execution_logs\"])>0 else \"\"\n            )\n\n        final_prompt = prompt.format(user_prompt=user_prompt, system_prompt=system_prompt)\n        final_prompt = Template(final_prompt).safe_substitute(\n            question=request.get(\"question\", \"\"),\n            suggestions=samples_retrieved,\n            **self.model_configs.get(\"use_case\", {})\n        )\n\n        response[\"prompt\"] = final_prompt\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/chain/modules/intent_extracter.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\nfrom app.providers.config import configs\nfrom app.loaders.base_loader import BaseLoader\nfrom string import Template\nfrom app.chain.formatter.general_response import Formatter\nfrom app.utils.parser import parse_llm_response\n\n\nclass IntentExtracter(AbstractHandler):\n    \"\"\"\n    A handler for extracting user intents from chat queries based on a provided use case configuration.\n\n    This class processes chat requests to determine the intent behind user queries using a language model.\n    It generates a prompt with the chat context, available intents, and instructions to guide the model in\n    intent extraction.\n\n    Attributes:\n        common_context (Any): Shared context information used across handlers.\n        model_configs (dict): Configuration settings for the model, including use case details and model paths.\n    \"\"\"\n\n    def __init__(self, common_context , model_configs, datasources) -> None:\n        \"\"\"\n        Initializes the IntentExtractor with common context and model configurations.\n\n        Args:\n            common_context (Any): Shared context information used across handlers.\n            model_configs (dict): Configuration settings for the model.\n        \"\"\"\n        self.model_configs = model_configs\n        self.common_context = common_context\n        self.datasources = datasources\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Processes the request to extract the intent from the user's query.\n\n        Args:\n            request (Any): The incoming request containing the user query and context.\n\n        Returns:\n            str: The result of the superclass's handle method with updated response information.\n        \"\"\"\n\n        response = request\n        logger.info(\"passing through => Intent extractor\")\n\n        use_case = self.model_configs.get(\"use_case\", {})\n        long_description = use_case.get(\"long_description\", \"\")\n        short_description = use_case.get(\"short_description\", \"\")\n        capabilities = use_case.get(\"capabilities\", [])\n        rag = request.get(\"rag\", {})\n        context = rag.get(\"context\", {})\n\n        capability_description = \"\"\n        capability_names = [\"out_of_context\"]\n\n        for capability in capabilities:\n            name = capability[\"name\"]\n            description = capability[\"description\"]\n            capability_names.append(name)\n            capability_description += f\"{name} : {description}\\n\"\n\n\n        datasources = self.model_configs.get(\"datasources\", [])\n        datasource_names = []\n        for datasource in datasources:\n            if datasource[\"name\"] in self.datasources:\n                if self.datasources[datasource[\"name\"]].__category__ in [2,5] and \"metadata_inquiry\" not in capability_names:\n                    capability_names.append(\"metadata_inquiry\")\n                name = datasource[\"name\"]\n                description = datasource[\"description\"]\n\n                capability_names.append(name)\n                datasource_names.append(name)\n                capability_description += f\"\\n{name} : {description}\\n\"\n                datasource_context = context[name]\n                for index,cont in enumerate(datasource_context[:2]):\n                    if index == 0:\n                        capability_description += f\"{cont.get(\"document\",\"\")}\\n\"\n                    else:\n                        capability_description += f\"{cont.get(\"document\",\"\")}\\n\"\n\n                \n        response[\"available_datasources\"] = datasource_names\n\n        if \"metadata_inquiry\" in capability_names:\n            capability_description += \"\\n\\nmetadata_inquiry : queries about overview of available data, the structure of a database (including tables and columns), the meaning behind specific columns, and the purpose within a database context, eg: what kind of data you have? or list questions which can be asked?\\n\"\n\n        chat_contexts = request.get(\"context\", [])\n        previous_intent = chat_contexts[-1].chat_answer[\"intent\"] if len(chat_contexts) > 0 else \"None\"\n\n        prompt = \"\"\"\n        You are part of a chatbot system where you have to extract intent from users chats and match it with given intents.\n\n        -- chatbot context ---\n        $long_description\n        Also provide data structure information and overview of available data.\n        -- chatbot context ---\n\n        Available intents are:\n        -- Intent section ---\n        $capabilities\n        out_of_context: If chat is irrelevant to chatbot context and its capabilities\n        --- Intent section ---\n\n        Previous last message Intent : $previous_intent\n\n        Instructions:\n        1.Only one intent must be identified.Multiple intents are prohibited.\n        2.Pay special attention to whether the previous intent has been completed.\n        3.Strictly only if the current user query doesn't clearly match an intent, consider the previous messages to identify the most appropriate intent.\n        3.If user seeks data structure info or data overview, label intent as metadata_inquiry.\n        4.When asked to list possible questions, provide general examples without mentioning \"specific\" word\n\n        Generate a response for the user query '$question' in the following JSON format:\n\n        {\n            \"explanation\": \"Explain how you finalized the intent based on user context and instructions. Include your reasoning for determining whether the previous intent was completed or if the current query relates to a new intent.\",\n            \"intent\": \"Detected intent, strictly one from the $capability_list\"\n        }\n        \"\"\"\n\n\n\n        capability_list = \"|\".join(capability_names)\n\n        prompt = Template(prompt).safe_substitute(\n            question = request[\"question\"],\n            long_description = long_description,\n            short_description =short_description,\n            capability_list = capability_list,\n            capabilities= capability_description,\n            previous_intent = previous_intent\n        )\n        logger.debug(f\"intent prompt:{prompt}\")\n\n        loader = BaseLoader(model_configs=self.model_configs[\"models\"])\n        infernce_model = loader.load_model(configs.inference_llm_model)\n\n        output, response_metadata = infernce_model.do_inference(\n                            prompt, chat_contexts\n                    )\n        if output[\"error\"] is not None:\n            return Formatter.format(\"Oops! Something went wrong. Try Again!\",output['error'])\n\n        response[\"intent_extractor\"] = parse_llm_response(output['content'])\n\n        response[\"available_intents\"] = capability_names\n        response[\"rag_filters\"] = {\n             \"datasources\" : [response[\"intent_extractor\"]['intent']] if 'intent_extractor' in response else [],\n             \"document_count\" : 5,\n             \"schema_count\" : 5\n        }\n        return await super().handle(response)\n\n\n"}
{"type": "source_file", "path": "app/embeddings/cohere/__init__.py", "content": "from collections import OrderedDict\nfrom app.models.request import ConnectionArgument\n\n\n__provider_name__ = \"cohere\"\n__vectordb_name__ = [\"chroma\"]\n__icon__ = '/assets/embeddings/logos/cohere.svg'\n__connection_args__ = [\n    {\n        \"config\": [\"api_key\"],\n        \"models\": [\n                \"large\"\n        ]\n    }\n]\n\n\n\n\n\n__all__ = [\n    __vectordb_name__, __connection_args__, __provider_name__, __icon__\n]"}
{"type": "source_file", "path": "app/embeddings/cohere/handler.py", "content": "\nimport chromadb.utils.embedding_functions as embedding_functions\nfrom loguru import logger\n\n\nclass CohereEm:\n    def __init__(self,model_name:str = \"\",api_key:str = \"\"):\n        logger.info(\"Initialising embedding providers\")\n        self.ef = embedding_functions.CohereEmbeddingFunction(api_key=api_key,  model_name= model_name)\n\n    def load_emb(self):\n        return self.ef\n\n    def health_check(self) -> None:\n        pass\n\n\n\n\n"}
{"type": "source_file", "path": "app/chain/modules/validator.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\nfrom app.chain.formatter.general_response import Formatter\n\nclass Validator(AbstractHandler):\n    \"\"\"\n    A handler for validating queries generated by the system.\n\n    This class validates the generated SQL queries against the data source and returns an appropriate response\n    if there are validation issues.\n\n    Attributes:\n        common_context (dict): Shared context information used for formatting responses and accessing intent-specific data.\n        datasource (dict): Data source used to validate the generated SQL queries.\n    \"\"\"\n\n    def __init__(self,common_context,datasource) -> None:\n        \"\"\"\n        Initializes the Validator with the provided context and datasource.\n\n        Args:\n            common_context (dict): Shared context information used for validation and response formatting.\n            datasource (dict): Data source used for query validation.\n        \"\"\"\n\n        super().__init__()\n        self.common_context = common_context\n        self.datasource = datasource\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Validates the generated SQL query and updates the response if there are validation issues.\n\n        Args:\n            request (Any): The incoming request containing the generated query and other relevant information.\n\n        Returns:\n            str: The result of the handled request or an error message if validation fails.\n        \"\"\"\n        logger.info(\"passing through => query_validator\")\n        response = request\n\n        inference = request.get(\"inference\", {})\n        formated_sql = inference.get(\"query\", \"\")\n\n        if formated_sql:\n            intent = self.common_context.get(\"intent\", \"\")\n            validator = self.datasource.get(intent, None)\n\n            if validator:\n                result = validator.validate(formated_sql)\n                if result:\n                    logger.critical(f\"Generated Query Validation Issue: {result}\")\n                    return await Formatter.format(result,\"\")\n\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/chain/modules/ouput_formatter.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\n\n\nclass OutputFormatter(AbstractHandler):\n    \"\"\"\n    A handler for formatting the output based on the provided inference and query responses.\n\n    This class processes the response from a query, formats it based on the available data and inference results,\n    and prepares it for further handling. It manages content, context, and additional metadata.\n\n    Attributes:\n        common_context (dict): Shared context information used across handlers.\n        datasource (dict): A dictionary for data formatting based on the intent.\n    \"\"\"\n\n    def __init__(self,common_context, datasource):\n        \"\"\"\n        Initializes the OutputFormatter with common context and datasource.\n\n        Args:\n            common_context (dict): Shared context information used across handlers.\n            datasource (dict): A dictionary for data formatting based on the intent.\n        \"\"\"\n        self.datasource = datasource\n        self.common_context = common_context\n\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Formats the response based on the inference and query response.\n\n        Args:\n            request (Any): The incoming request containing inference results and query response.\n\n        Returns:\n            str: The result of the superclass's handle method with updated response information.\n        \"\"\"\n\n        logger.info(\"passing through => output_formatter\")\n\n        input_data = request.get(\"inference\", {})\n        response = {}\n\n        if \"main_entity\" in input_data and \"operation_kind\" in input_data :\n            intent_key = self.common_context.get(\"intent\")\n            if intent_key in self.datasource:\n                response = self.datasource[intent_key].format(request.get(\"query_response\"), input_data)\n        elif \"general_message\" in input_data:\n            response[\"content\"] = str(input_data.get('general_message'))\n\n\n        if \"data\" in response and isinstance(response[\"data\"], list) and len(response[\"data\"]) == 0:\n            if  \"empty_message\" in input_data:\n                response[\"content\"] = input_data[\"empty_message\"]\n            else:\n                response[\"content\"] = \"I didn't find any data matching the query\"\n            response[\"main_format\"] = \"general_chat\"\n        elif \"kind\" in response and response[\"kind\"] == \"none\":\n            response[\"content\"] = input_data.get(\"empty_message\", \"I didn't find any relevant data regarding this, please reframe your query\")\n            response[\"main_format\"] = \"general_chat\"\n\n\n        response[\"next_questions\"] = input_data.get(\"next_questions\", [])\n\n        if \"context_id\" in request:\n            response[\"context_id\"] = request[\"context_id\"]\n            response[\"question\"] = request[\"question\"]\n\n        response[\"query\"] = input_data.get(\"query\", '')\n        response[\"intent\"] = request.get(\"intent_extractor\", {}).get(\"intent\",\"\")\n        response[\"summary\"] = request.get(\"summary\", '')\n\n\n        return await super().handle(response)\n"}
{"type": "source_file", "path": "app/chain/modules/metadata_generator.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\nfrom app.providers.config import configs\nfrom app.loaders.base_loader import BaseLoader\nfrom string import Template\nfrom app.utils.parser import markdown_parse_llm_response\nfrom app.chain.formatter.general_response import Formatter\n\n\n\nclass MetadataGenerator(AbstractHandler):\n\n    def __init__(self, common_context , model_configs, datasources) -> None:\n        self.model_configs = model_configs\n        self.common_context = common_context\n        self.datasources = datasources\n\n    async def handle(self, request: Any) -> str:\n        response = request\n        logger.info(\"passing through => Metadata description generator\")\n        rag = request[\"rag\"]\n        contexts = \"\"\n        for datasource_name, handler in self.datasources.items():\n            if handler.__category__ in [2,5]:\n                rag_contexts = rag.get(\"context\", {}).get(datasource_name,\"\")\n                for index,cont in enumerate(rag_contexts):\n                    if index==0:\n                        contexts += \"\\n\\n\" + \"Plugin/Database Name: \"+ datasource_name + \"\\n\" + cont[\"document\"] \n                    else:\n                        contexts +=  \"\\n\" + cont[\"document\"]\n                    \n\n        prompt = \"\"\"\n            You are part of a chatbot system where you need to answer user questions based on the given database schema and context.\n            Please review the following information carefully:\n\n            A brief description about the schema is given below:\n            -- start db schema context section--\n            $context\n            -- end db schema context section--\n\n            Make sure to follow these:\n            1. Use the provided schema and context to inform your answer.\n            2. while listing tables and its columns strictly mention under which plugin name it is.\n            3. Provide accurate information based on the available data.\n            4. Keep the answer concise and with minimal explanation\n            5. If the question cannot be fully answered with the given information, explain what can be answered and what additional information might be needed.\n            6. Present the answer in a human-readable Markdown format\n            7. Give only what user wants, don't hallucinate to give long answers\n\n            Your task is to go through the chat history carefully to understand the user's context and instructions. Then, generate a response to the user query '$question' using the provided schema and metadata information. Format your response in the following JSON structure:\n            {\n            \"general_message\": \"Provide a concise human-readable answer in Markdown format to the user's question using the available information\",\n            }\n        \"\"\"\n\n        prompt = Template(prompt).safe_substitute(question = request[\"question\"], context =contexts)\n        response[\"prompt\"] = prompt\n        logger.info(f\"prompt:{prompt}\")\n        chat_history = []\n        if \"context\" in request and len(request[\"context\"]) > 0:\n            chat_history = request[\"context\"]\n            chat_history = chat_history[-7:] if len(chat_history) >= 7 else chat_history\n\n        loader = BaseLoader(model_configs=self.model_configs[\"models\"])\n        infernce_model = loader.load_model(configs.inference_llm_model)\n\n        output, response_metadata = infernce_model.do_inference(\n                            prompt, chat_history\n                    )\n        if output[\"error\"] is not None:\n            return await Formatter.format(\"Oops! Something went wrong. Try Again!\",output['error'])\n\n        response[\"inference\"] = markdown_parse_llm_response(output['content'])\n\n        response[\"summary\"] = \"\"\n        return await super().handle(response)"}
{"type": "source_file", "path": "app/embeddings/default/default.py", "content": "from .onnx import DefaultEmbeddingModel\nfrom .chroma_default import ChromaDefaultEmbedding\n\nfrom loguru import logger\nclass DefaultEmbedding:\n    def __init__(self, vectordb_key: str = \"chroma\"):\n        logger.info(\"Initializing embedding providers\")\n        self.vectordb = vectordb_key\n\n    def load_emb(self):\n        match self.vectordb:\n            case \"chroma\":\n                return ChromaDefaultEmbedding().load_emb()\n            case \"mongodb\":\n                return DefaultEmbeddingModel()\n            case _:\n                logger.error(f\"Unsupported vectordb_key: {self.key}\")\n                return None\n\n    def health_check(self) -> None:\n        pass\n"}
{"type": "source_file", "path": "app/chain/modules/router.py", "content": "from app.base.abstract_handlers import AbstractHandler\nfrom typing import Any\nfrom loguru import logger\nfrom app.chain.formatter.general_response import Formatter\n\n\nclass Router(AbstractHandler):\n    \"\"\"\n    A handler that routes requests to appropriate handlers based on the detected intent.\n\n    The Router class determines the correct handler to process the request based on the intent extracted\n    from the request. It forwards the request to the appropriate handler or returns a fallback response\n    if no suitable handler is found.\n\n    Attributes:\n        fallback_handler (AbstractHandler): Handler to process requests that do not match any specific intent.\n        general_handler (AbstractHandler): Handler for general intent processing.\n        capability_handler (AbstractHandler): Handler for capability-related intents.\n        metadata_handler (AbstractHandler): Handler for metadata-related intents.\n    \"\"\"\n\n\n    def __init__(self, common_context, fallback_handler, intent_handler, general_handler, capability_handler, metadata_handler) -> None:\n        \"\"\"\n        Initializes the Router with the provided handlers.\n\n        Args:\n            common_context (dict): Shared context information used across handlers.\n            fallback_handler (AbstractHandler): Handler for fallback responses.\n            general_handler (AbstractHandler): Handler for general intent processing.\n            capability_handler (AbstractHandler): Handler for capability-related intents.\n            metadata_handler (AbstractHandler): Handler for metadata-related intents.\n        \"\"\"\n\n        self.fallback_handler = fallback_handler\n        self.forwared_handler = intent_handler\n        self.general_handler = general_handler\n        self.capability_handler = capability_handler\n        self.metadata_handler = metadata_handler\n\n\n    async def handle(self, request: Any) -> str:\n        \"\"\"\n        Routes the request to the appropriate handler based on the detected intent.\n\n\n        Args:\n            request (Any): The incoming request containing intent information.\n\n        Returns:\n            str: The result of the handled request.\n        \"\"\"\n\n        logger.info(\"passing through => Router\")\n        response = request\n\n        intent_extractor = request.get(\"intent_extractor\", {})\n        intent = intent_extractor.get(\"intent\", \"\")\n\n        if intent:\n            if intent in  self.forwared_handler.data_sources:\n                datasource = self.forwared_handler.data_sources[intent]\n\n                if datasource.__category__ == 2 or datasource.__category__ == 5:\n                    logger.info(\"entered database workflow\")\n                    return await self.forwared_handler.invoke(request)\n                else:\n                    logger.info(\"entered default workflow\")\n                    return await self.general_handler.invoke(request)\n\n            elif intent == \"metadata_inquiry\":\n                return await self.metadata_handler.invoke(request)\n            elif intent in request.get(\"available_intents\", []) and intent != \"out_of_context\":\n                return await self.capability_handler.invoke(request)\n            else:\n                response = Formatter.format(\"Sorry, I can't help you with that. Is there anything i can help you with ?\",\"\")\n                return await self.fallback_handler.handle(response)\n\n        else:\n            logger.info(\"No intents detected\")\n            response = Formatter.format(\"Sorry, I can't help you with that. Is there anything i can help you with ?\",\"\")\n            return await self.fallback_handler.handle(response)\n\n"}
{"type": "source_file", "path": "app/embeddings/default/chroma_default.py", "content": "import chromadb.utils.embedding_functions as embedding_functions\n\nfrom loguru import logger\n\nclass ChromaDefaultEmbedding:\n    def __init__(self):\n        logger.info(\"Initialising embedding providers\")\n        self.ef = embedding_functions.DefaultEmbeddingFunction()\n\n    def load_emb(self):\n        return self.ef\n    \n\n"}
{"type": "source_file", "path": "app/embeddings/default/onnx.py", "content": "import os\nimport requests\nimport numpy as np\nfrom tokenizers import Tokenizer\nimport onnxruntime as ort\nfrom typing import List\nfrom loguru import logger\n\nMODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\nTOKENIZER_URL = \"https://raw.githubusercontent.com/chroma-core/onnx-embedding/main/onnx/tokenizer.json\"\nMODEL_URL = \"https://github.com/chroma-core/onnx-embedding/raw/main/onnx/model.onnx?download=\"\n\n# Function to download files from a URL and save them locally\ndef download_file(url: str, local_path: str):\n    response = requests.get(url)\n    response.raise_for_status()  # Check if the download is successful\n    with open(local_path, 'wb') as f:\n        f.write(response.content)\n\n# Ensure that the directory exists\ndef ensure_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n# Use PyTorch's default epsilon for division by zero\ndef normalize(v):\n    norm = np.linalg.norm(v, axis=1)\n    norm[norm == 0] = 1e-12\n    return v / norm[:, np.newaxis]\n\n# Sample implementation of the default sentence-transformers model using ONNX\nclass DefaultEmbeddingModel():\n\n    def __init__(self):\n        # Define paths to save the tokenizer and model\n        embedding_dir = os.path.join(os.getcwd(), \"embeddings\", \"onnx\")\n        ensure_dir(embedding_dir)\n\n        tokenizer_path = os.path.join(embedding_dir, \"tokenizer.json\")\n        model_path = os.path.join(embedding_dir, \"model.onnx\")\n\n        # Download the tokenizer and model from GitHub if they don't exist locally\n        if not os.path.isfile(tokenizer_path):\n            logger.info(\"Downloading tokenizer...\")\n            download_file(TOKENIZER_URL, tokenizer_path)\n\n        if not os.path.isfile(model_path):\n            logger.info(\"Downloading ONNX model...\")\n            download_file(MODEL_URL, model_path)\n\n        # Load the tokenizer\n        self.tokenizer = Tokenizer.from_file(tokenizer_path)\n        self.tokenizer.enable_truncation(max_length=256)\n        self.tokenizer.enable_padding(pad_id=0, pad_token=\"[PAD]\", length=256)\n\n        # Load the ONNX model\n        self.model = ort.InferenceSession(model_path)\n\n    def __call__(self, documents: List[str], batch_size: int = 32):\n        all_embeddings = []\n        for i in range(0, len(documents), batch_size):\n            batch = documents[i:i + batch_size]\n            encoded = [self.tokenizer.encode(d) for d in batch]\n            input_ids = np.array([e.ids for e in encoded])\n            attention_mask = np.array([e.attention_mask for e in encoded])\n            onnx_input = {\n                \"input_ids\": np.array(input_ids, dtype=np.int64),\n                \"attention_mask\": np.array(attention_mask, dtype=np.int64),\n                \"token_type_ids\": np.array([np.zeros(len(e), dtype=np.int64) for e in input_ids], dtype=np.int64),\n            }\n            model_output = self.model.run(None, onnx_input)\n            last_hidden_state = model_output[0]\n            # Perform mean pooling with attention weighting\n            input_mask_expanded = np.broadcast_to(np.expand_dims(attention_mask, -1), last_hidden_state.shape)\n            embeddings = np.sum(last_hidden_state * input_mask_expanded, 1) / np.clip(input_mask_expanded.sum(1), a_min=1e-9, a_max=None)\n            embeddings = normalize(embeddings).astype(np.float32)\n            all_embeddings.append(embeddings)\n        return np.concatenate(all_embeddings)\n\n\n"}
