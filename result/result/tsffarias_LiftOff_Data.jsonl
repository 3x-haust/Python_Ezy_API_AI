{"repo_info": {"repo_name": "LiftOff_Data", "repo_owner": "tsffarias", "repo_url": "https://github.com/tsffarias/LiftOff_Data"}}
{"type": "test_file", "path": "tests/test_db_schema.py", "content": "import pandas as pd\nimport os\nfrom dotenv import load_dotenv\nfrom sqlalchemy import create_engine\nimport psycopg2\n\nload_dotenv(\".env\")\n\n# Lê as variáveis de ambiente\nPOSTGRES_USER = os.getenv('DB_USER_PROD')\nPOSTGRES_PASSWORD = os.getenv('DB_PASS_PROD')\nPOSTGRES_HOST = os.getenv('DB_HOST_PROD')\nPOSTGRES_PORT = os.getenv('DB_PORT_PROD')\nPOSTGRES_DB = os.getenv('DB_NAME_PROD')\n\nconn = psycopg2.connect(database=POSTGRES_DB, user=POSTGRES_USER, password=POSTGRES_PASSWORD)\n\ndef test_read_data_and_check_schema_sales():\n    df = pd.read_sql('SELECT * FROM sales', con=conn)\n\n    # Verificar se o DataFrame não está vazio\n    assert not df.empty, \"O DataFrame está vazio.\"\n\n    # Schema esperado\n    expected_dtype = {\n        'id': 'int64',\n        'email_employee': 'object',\n        'email_customer': 'object',\n        'first_name': 'object',\n        'last_name': 'object',\n        'phone_number': 'object',\n        'price': 'float64',\n        'quantity': 'int64',\n        'name_product': 'object',\n        'date': 'datetime64[ns, UTC]',\n        'created_at': 'datetime64[ns, UTC]'\n    }\n\n    # Verificar o schema\n    print(\"Schema do DataFrame:\", df.dtypes.to_dict())\n    assert df.dtypes.to_dict() == expected_dtype, \"O schema do DataFrame não corresponde ao esperado.\"\n\ndef test_read_data_and_check_schema_employees():\n    df = pd.read_sql('SELECT * FROM employees', con=conn)\n\n    date_cols = ['hire_date', 'birth_date', 'start_date', 'termination_date', 'created_at']\n    for col in date_cols:\n        df[col] = pd.to_datetime(df[col], errors='coerce', utc=True)\n\n    # Verificar se o DataFrame não está vazio\n    assert not df.empty, \"O DataFrame está vazio.\"\n\n    expected_dtype = {\n        'employee_id': 'int64',\n        'manager_id': 'float64',   \n        'first_name': 'object',\n        'last_name': 'object',\n        'email': 'object',\n        'phone_number': 'object',\n        'hire_date': 'datetime64[ns, UTC]',\n        'department_id': 'int64',\n        'job_title': 'object',\n        'location': 'object',\n        'birth_date': 'datetime64[ns, UTC]',\n        'gender': 'object',\n        'nationality': 'object',\n        'start_date': 'datetime64[ns, UTC]',\n        'salary': 'float64',\n        'termination_date': 'datetime64[ns, UTC]',\n        'created_at': 'datetime64[ns, UTC]'\n    }\n\n    # Verificar o schema\n    print(\"Schema do DataFrame:\", df.dtypes.to_dict())\n    assert df.dtypes.to_dict() == expected_dtype, \"O schema do DataFrame não corresponde ao esperado.\"\n\ndef test_read_data_and_check_schema_products():\n    # Lê os dados da tabela products\n    df = pd.read_sql('SELECT * FROM products', con=conn)\n\n    # Converter a coluna de data/datetime manualmente, caso esteja como string\n    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce', utc=True)\n\n    # Verifica se o DataFrame não está vazio\n    assert not df.empty, \"O DataFrame está vazio.\"\n\n    # Define o schema esperado\n    expected_dtype = {\n        'id': 'int64',\n        'name': 'object',\n        'description': 'object',\n        'price': 'float64',\n        'categoria': 'object',\n        'email_fornecedor': 'object',\n        'created_at': 'datetime64[ns, UTC]'\n    }\n\n    print(\"Schema do DataFrame:\", df.dtypes.to_dict())\n\n    # Converte o dtypes atual e esperado em strings para comparação\n    actual_schema = {col: str(dtype) for col, dtype in df.dtypes.to_dict().items()}\n    expected_schema_str = {col: str(dtype) for col, dtype in expected_dtype.items()}\n\n    assert actual_schema == expected_schema_str, f\"O schema do DataFrame não corresponde ao esperado.\\nEsperado: {expected_schema_str}\\nObtido: {actual_schema}\"\n\ndef test_read_data_and_check_schema_suppliers():\n    # Lê os dados da tabela suppliers\n    df = pd.read_sql('SELECT * FROM suppliers', con=conn)\n\n    # Converter a coluna de data/datetime caso esteja como string\n    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce', utc=True)\n\n    # Verifica se o DataFrame não está vazio\n    assert not df.empty, \"O DataFrame está vazio.\"\n\n    # Define o schema esperado\n    expected_dtype = {\n        'supplier_id': 'int64',\n        'company_name': 'object',\n        'contact_name': 'object',\n        'email': 'object',\n        'phone_number': 'object',\n        'website': 'object',\n        'address': 'object',\n        'product_categories': 'object',\n        'primary_product': 'object',\n        'created_at': 'datetime64[ns, UTC]'\n    }\n\n    print(\"Schema do DataFrame:\", df.dtypes.to_dict())\n\n    # Converter o dtypes atual e esperado em strings para comparação\n    actual_schema = {col: str(dtype) for col, dtype in df.dtypes.to_dict().items()}\n    expected_schema_str = {col: str(dtype) for col, dtype in expected_dtype.items()}\n\n    assert actual_schema == expected_schema_str, f\"O schema do DataFrame não corresponde ao esperado.\\nEsperado: {expected_schema_str}\\nObtido: {actual_schema}\""}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/test_models.py", "content": "import pytest\nfrom datetime import date\nfrom pydantic import ValidationError\nfrom app.backend.models.product.product_schema import ProductCreate\nfrom app.backend.models.employee.employee_schema import EmployeeCreate\nfrom app.backend.models.supplier.supplier_schema import SupplierCreate\n\ndef test_product_com_dados_validos():\n    dados_validos = {\n        \"name\": \"Notebook\",\n        \"description\": \"Notebook ultrafino\",\n        \"price\": 2999.99,\n        \"categoria\": \"Eletrônico\",\n        \"email_fornecedor\": \"fornecedor@example.com\"\n    }\n\n    produto = ProductCreate(**dados_validos)\n\n    assert produto.name == dados_validos[\"name\"]\n    assert produto.description == dados_validos[\"description\"]\n    assert produto.price == dados_validos[\"price\"]\n    assert produto.categoria == dados_validos[\"categoria\"]\n    assert produto.email_fornecedor == dados_validos[\"email_fornecedor\"]\n\n\ndef test_product_com_dados_invalidos():\n    dados_invalidos = {\n        \"name\": \"Notebook\",\n        \"description\": \"Notebook ultrafino\",\n        \"price\": -100,  # Valor negativo inválido\n        \"categoria\": \"Inexistente\",  # Categoria inválida\n        \"email_fornecedor\": \"fornecedor\"  # Email inválido\n    }\n\n    with pytest.raises(ValidationError):\n        ProductCreate(**dados_invalidos)\n\n\ndef test_employee_com_dados_validos():\n    dados_validos = {\n        \"first_name\": \"Maria\",\n        \"last_name\": \"Souza\",\n        \"email\": \"maria.souza@example.com\",\n        \"phone_number\": \"11999999999\",\n        \"hire_date\": date.today(),\n        \"department_id\": 10,\n        \"manager_id\": 2,\n        \"job_title\": \"Analista de Dados\",\n        \"location\": \"São Paulo, Brasil\",\n        \"birth_date\": date(1990, 5, 20),\n        \"gender\": \"Masculino\",  # Campo string conforme schema\n        \"nationality\": \"Brasileira\",\n        \"start_date\": date.today(),\n        \"salary\": 5000.0,\n        \"termination_date\": None\n    }\n\n    funcionario = EmployeeCreate(**dados_validos)\n\n    assert funcionario.first_name == dados_validos[\"first_name\"]\n    assert funcionario.last_name == dados_validos[\"last_name\"]\n    assert funcionario.email == dados_validos[\"email\"]\n    assert funcionario.phone_number == dados_validos[\"phone_number\"]\n    assert funcionario.hire_date == dados_validos[\"hire_date\"]\n    assert funcionario.department_id == dados_validos[\"department_id\"]\n    assert funcionario.manager_id == dados_validos[\"manager_id\"]\n    assert funcionario.job_title == dados_validos[\"job_title\"]\n    assert funcionario.location == dados_validos[\"location\"]\n    assert funcionario.birth_date == dados_validos[\"birth_date\"]\n    assert funcionario.gender == dados_validos[\"gender\"]\n    assert funcionario.nationality == dados_validos[\"nationality\"]\n    assert funcionario.start_date == dados_validos[\"start_date\"]\n    assert funcionario.salary == dados_validos[\"salary\"]\n    assert funcionario.termination_date == dados_validos[\"termination_date\"]\n\n\ndef test_employee_com_dados_invalidos():\n    dados_invalidos = {\n        \"first_name\": \"Maria\",\n        \"last_name\": \"Souza\",\n        \"email\": \"maria.souza\",  # Email inválido\n        \"phone_number\": \"11999999999\",\n        \"hire_date\": \"não é uma data\",\n        \"department_id\": 10,\n        \"manager_id\": 2,\n        \"job_title\": \"Analista de Dados\",\n        \"location\": \"São Paulo, Brasil\",\n        \"birth_date\": \"não é uma data\",\n        \"gender\": \"Inexistente\", # Não há validação direta, mas poderia ter\n        \"nationality\": \"Brasileira\",\n        \"start_date\": \"não é uma data\",\n        \"salary\": -1000.0, # Valor negativo\n        \"termination_date\": \"não é uma data\"\n    }\n\n    with pytest.raises(ValidationError):\n        EmployeeCreate(**dados_invalidos)\n\n\ndef test_supplier_com_dados_validos():\n    dados_validos = {\n        \"company_name\": \"Fornecedor LTDA\",\n        \"contact_name\": \"Carlos\",\n        \"email\": \"contato@fornecedor.com\",\n        \"phone_number\": \"11988888888\",\n        \"website\": \"https://fornecedor.com\",\n        \"address\": \"Rua A, 123\",\n        \"product_categories\": \"Categoria 1\",\n        \"primary_product\": \"Peças de Computador\"\n    }\n\n    fornecedor = SupplierCreate(**dados_validos)\n\n    assert fornecedor.company_name == dados_validos[\"company_name\"]\n    assert fornecedor.contact_name == dados_validos[\"contact_name\"]\n    assert fornecedor.email == dados_validos[\"email\"]\n    assert fornecedor.phone_number == dados_validos[\"phone_number\"]\n    assert fornecedor.website == dados_validos[\"website\"]\n    assert fornecedor.address == dados_validos[\"address\"]\n    assert fornecedor.product_categories == dados_validos[\"product_categories\"]\n    assert fornecedor.primary_product == dados_validos[\"primary_product\"]\n\n\ndef test_supplier_com_dados_invalidos():\n    dados_invalidos = {\n        \"company_name\": \"Fornecedor LTDA\",\n        \"contact_name\": \"Carlos\",\n        \"email\": \"contato\",  # Email inválido\n        \"phone_number\": \"11988888888\",\n        \"website\": \"https://fornecedor.com\",\n        \"address\": \"Rua A, 123\",\n        \"product_categories\": \"Categoria Inexistente\", # Categoria inválida\n        \"primary_product\": \"Peças de Computador\"\n    }\n\n    with pytest.raises(ValidationError):\n        SupplierCreate(**dados_invalidos)\n"}
{"type": "test_file", "path": "app/frontend/AI/test_groq_simples.py", "content": "import os\nimport pandas as pd\nimport streamlit as st\nfrom groq import Groq\nfrom datetime import datetime\n\nclient = Groq(\n    api_key=os.environ.get(\"GROQ_API_KEY\"),\n)\n\n# Função para ler o CSV\ndef load_data():\n    return pd.read_csv('gold_sales_7_days.csv')\n\ndef send_question(pergunta, dados, agente_tipo):\n    data_atual = datetime.now().strftime('%d/%m/%Y')\n    \n    # Definindo o contexto de acordo com o tipo de agente selecionado\n    if agente_tipo == \"Robo Comercial para Dados\":\n        contexto = (\n            f\"Hoje é {data_atual}. Você é um robô comercial especializado em análise de dados de vendas. \"\n            f\"Os dados de vendas dos últimos 7 dias são: {dados.to_string(index=False)}. \"\n            f\"Sua função é responder perguntas sobre esses dados de forma direta e objetiva, sem especulações. \"\n            f\"Nunca responda algo que não esteja nos dados ou fora do contexto fornecido.\"\n        )\n        imagem = \"agente_comercial.png\"\n    elif agente_tipo == \"Análise Comercial Avançada\":\n        contexto = (\n            f\"Hoje é {data_atual}. Você é um analista comercial avançado especializado em estratégias de vendas. \"\n            f\"Os dados de vendas dos últimos 7 dias são: {dados.to_string(index=False)}. \"\n            f\"Sua função é sugerir estratégias de vendas baseadas nos dados, respondendo perguntas e oferecendo insights. \"\n            f\"Nunca responda algo que não tenha nos dados ou seja fora do contexto fornecido.\"\n        )\n        imagem = \"laennder.png\"\n    \n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"{contexto}\\n\\nPergunta: {pergunta}\",\n            }\n        ],\n        model=\"llama3-8b-8192\",\n    )\n    return chat_completion.choices[0].message.content.strip(), imagem\n\n# Interface do Streamlit\nst.title(\"Agente de Atendimento - Escolha seu Analista\")\n\n# Escolha do tipo de agente\nagent_type = st.selectbox(\n    \"Escolha o tipo de agente para suas análises:\",\n    [\"Robo Comercial para Dados\", \"Análise Comercial Avançada\"]\n)\n\n# Carregar e exibir dados\ndata = load_data()\n\n# Caixa de entrada para perguntas\nquestion = st.text_input(\"Digite sua pergunta ou peça uma estratégia:\")\n\n# Quando uma pergunta é feita\nif question:\n    response, imagem = send_question(question, data, agent_type)\n    # Ajusta o tamanho da imagem com o parâmetro width\n    st.image(imagem, caption=f\"Agente Selecionado: {agent_type}\", width=300)\n    st.write(f\"Resposta do {agent_type}: {response}\")"}
{"type": "test_file", "path": "tests/test_frontend.py", "content": "from selenium import webdriver\nfrom time import sleep\nimport pytest\nimport subprocess\nfrom selenium.webdriver.firefox.options import Options\nfrom selenium.webdriver.common.by import By\n\n@pytest.fixture\ndef driver():\n    # Iniciar o Streamlit em background\n    process = subprocess.Popen([\"streamlit\", \"run\", \"app/frontend/app.py\", \"--server.headless\", \"true\"])\n    options = Options()\n    options.headless = True  # Executar em modo headless\n    driver = webdriver.Firefox(options=options)\n    # Iniciar o WebDriver usando GeckoDriver\n    driver.set_page_load_timeout(10)\n    yield driver\n\n    # Fechar o WebDriver e o Streamlit após o teste\n    driver.quit()\n    process.kill()\n\ndef test_app_opens(driver):\n    # Verificar se a página abre\n    driver.get(\"http://localhost:8501\")\n    sleep(10)"}
{"type": "source_file", "path": "app/backend/crud/sales/crud.py", "content": "from sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.future import select\nfrom models.sales.sales_schema import SalesUpdate, SalesCreate\nfrom models.sales.sales import SalesModel\n\n\nasync def get_sales_by_id(db: AsyncSession, sales_id: int):\n    \"\"\"\n    Funcao que recebe um id e retorna somente ele\n    \"\"\"\n    result = await db.execute(select(SalesModel).filter(SalesModel.id == sales_id))\n    return result.scalars().first()\n\nasync def get_sales(db: AsyncSession):\n    \"\"\"\n    Funcao que retorna todos os elementos\n    \"\"\"\n    result = await db.execute(select(SalesModel))\n    return result.scalars().all()\n\nasync def create_sales(db: AsyncSession, sales: SalesCreate):\n    \"\"\"\n    Cria uma nova venda.\n    \"\"\"\n    db_sales = SalesModel(**sales.model_dump())\n    db.add(db_sales)\n    await db.commit()\n    await db.refresh(db_sales)\n    return db_sales\n\nasync def delete_sales(db: AsyncSession, sales_id: int):\n    \"\"\"\n    Deleta uma venda específica.\n    \"\"\"\n    db_sales = await get_sales_by_id(db, sales_id)\n    if db_sales:\n        await db.delete(db_sales)\n        await db.commit()\n    return db_sales\n\nasync def update_sales(db: AsyncSession, sales_id: int, sales: SalesUpdate):\n    \"\"\"\n    Atualiza apenas os campos modificados de uma venda existente.\n    \"\"\"\n    db_sales = await get_sales_by_id(db, sales_id)\n    if db_sales is None:\n        return None\n\n    # Obtém apenas os campos que foram alterados\n    update_data = sales.model_dump(exclude_unset=True)\n\n    # Atualiza somente os campos que realmente foram modificados\n    for key, value in update_data.items():\n        current_value = getattr(db_sales, key, None)\n        if current_value != value:  # Atualiza somente se o valor for diferente\n            setattr(db_sales, key, value)\n\n    if update_data:  # Realiza commit apenas se houver alterações\n        await db.commit()\n        await db.refresh(db_sales)\n\n    return db_sales\n"}
{"type": "source_file", "path": "app/backend/crud/supplier/crud.py", "content": "from sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.future import select\nfrom models.supplier.supplier_schema import SupplierUpdate, SupplierCreate\nfrom models.supplier.supplier import SupplierModel\n\n\nasync def get_supplier(db: AsyncSession, supplier_id: int):\n    \"\"\"\n    Função que recebe um id e retorna somente o fornecedor correspondente\n    \"\"\"\n    result = await db.execute(select(SupplierModel).filter(SupplierModel.supplier_id == supplier_id))\n    return result.scalars().first()\n\n\nasync def get_suppliers(db: AsyncSession):\n    \"\"\"\n    Função que retorna todos os fornecedores\n    \"\"\"\n    result = await db.execute(select(SupplierModel))\n    return result.scalars().all()\n\nasync def create_supplier(db: AsyncSession, supplier: SupplierCreate):\n    \"\"\"\n    Cria um novo fornecedor.\n    \"\"\"\n    db_supplier = SupplierModel(**supplier.model_dump())\n    db.add(db_supplier)\n    await db.commit()\n    await db.refresh(db_supplier)\n    return db_supplier\n\nasync def delete_supplier(db: AsyncSession, supplier_id: int):\n    \"\"\"\n    Deleta um fornecedor específico.\n    \"\"\"\n    db_supplier = await get_supplier(db, supplier_id)\n    if db_supplier:\n        await db.delete(db_supplier)\n        await db.commit()\n    return db_supplier\n\nasync def update_supplier(db: AsyncSession, supplier_id: int, supplier: SupplierUpdate):\n    \"\"\"\n    Atualiza apenas os campos modificados de um fornecedor existente.\n    \"\"\"\n    db_supplier = await get_supplier(db, supplier_id)\n    if db_supplier is None:\n        return None\n\n    # Obtém apenas os campos que foram alterados\n    update_data = supplier.model_dump(exclude_unset=True)\n\n    # Atualiza somente os campos que realmente foram modificados\n    for key, value in update_data.items():\n        current_value = getattr(db_supplier, key, None)\n        if current_value != value:  # Atualiza somente se o valor for diferente\n            setattr(db_supplier, key, value)\n\n    if update_data:  # Realiza commit apenas se houver alterações\n        await db.commit()\n        await db.refresh(db_supplier)\n\n    return db_supplier\n\n\n"}
{"type": "source_file", "path": "app/backend/crud/product/crud.py", "content": "from sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.future import select\nfrom models.product.product_schema import ProductUpdate, ProductCreate\nfrom models.product.product import ProductModel\n\n\nasync def get_product(db: AsyncSession, product_id: int):\n    \"\"\"\n    Funcao que recebe um id e retorna somente ele\n    \"\"\"\n    result = await db.execute(select(ProductModel).filter(ProductModel.id == product_id))\n    return result.scalars().first()\n\nasync def get_products(db: AsyncSession):\n    \"\"\"\n    Funcao que retorna todos os elementos\n    \"\"\"\n    result = await db.execute(select(ProductModel))\n    return result.scalars().all()\n\nasync def create_product(db: AsyncSession, product: ProductCreate):\n    \"\"\"\n    Cria um novo produto.\n    \"\"\"\n    db_product = ProductModel(**product.model_dump())\n    db.add(db_product)\n    await db.commit()\n    await db.refresh(db_product)\n    return db_product\n\nasync def delete_product(db: AsyncSession, product_id: int):\n    \"\"\"\n    Deleta um produto específico.\n    \"\"\"\n    db_product = await get_product(db, product_id)\n    if db_product:\n        await db.delete(db_product)\n        await db.commit()\n    return db_product\n\nasync def update_product(db: AsyncSession, product_id: int, product: ProductUpdate):\n    \"\"\"\n    Atualiza apenas os campos modificados de um produto.\n    \"\"\"\n    db_product = await get_product(db, product_id)\n    if db_product is None:\n        return None\n\n    # Obtém apenas os campos que foram alterados\n    update_data = product.model_dump(exclude_unset=True)\n\n    # Atualiza apenas os campos que realmente foram modificados\n    for key, value in update_data.items():\n        current_value = getattr(db_product, key, None)\n        if current_value != value:  # Atualiza somente se o valor for diferente\n            setattr(db_product, key, value)\n\n    if update_data:  # Apenas realiza commit se houver alterações\n        await db.commit()\n        await db.refresh(db_product)\n\n    return db_product\n"}
{"type": "source_file", "path": "app/backend/database/database.py", "content": "from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\n# Obter as variáveis do arquivo .env\nDB_PORT = os.getenv('DB_PORT_PROD')\nDB_NAME = os.getenv('DB_NAME_PROD')\nDB_USER = os.getenv('DB_USER_PROD')\nDB_PASS = os.getenv('DB_PASS_PROD')\n\n# Criar a URL de conexão do banco de dados assíncrono\nSQLALCHEMY_DATABASE_URL = f\"postgresql+asyncpg://{DB_USER}:{DB_PASS}@postgres:{DB_PORT}/{DB_NAME}\"\n\n# Criar o motor assíncrono\nasync_engine = create_async_engine(SQLALCHEMY_DATABASE_URL, echo=False)\n\n# Sessão assíncrona\nasync_session = sessionmaker(\n    bind=async_engine,\n    class_=AsyncSession,\n    expire_on_commit=False\n)\n\n# Base para os modelos declarativos\nBase = declarative_base()\n\n\n# Dependência para injeção de sessão no FastAPI\nasync def get_db():\n    async with async_session() as session:\n        try:\n            yield session\n        finally:\n            await session.close()\n\n\n# Inicializar o banco de dados\nasync def init_db():\n    async with async_engine.begin() as conn:\n        # Criar as tabelas (migrations podem substituir isso no futuro)\n        await conn.run_sync(Base.metadata.create_all)\n"}
{"type": "source_file", "path": "app/backend/generate_dataset/generate_raw.py", "content": "import pandas as pd\nfrom faker import Faker\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nfrom datetime import datetime, timedelta\nfrom enum import Enum\nimport uuid\nimport random\nimport time\nimport os\n\n# Inicializando o Faker para dados em português\nfake = Faker('pt_BR')\nclass CategoriaBase(Enum):\n    \"\"\"\n    Enum representando as categorias de produtos.\n    \"\"\"\n    categoria1 = \"Eletrônico\"\n    categoria2 = \"Eletrodoméstico\"\n    categoria3 = \"Móveis\"\n    categoria4 = \"Roupas\"\n    categoria5 = \"Calçados\"\n\nclass ProductCategoriesEnum(str, Enum):\n    categoria1 = \"Categoria 1\"\n    categoria2 = \"Categoria 2\"\n    categoria3 = \"Categoria 3\"\n\nclass ProdutoEnum(str, Enum):\n    produto1 = \"ZapFlow com Gemini\"\n    produto2 = \"ZapFlow com chatGPT\"\n    produto3 = \"ZapFlow com Llama3.0\"\n\n# Função para gerar dados de funcionários (employees)\ndef gerar_dados_employee(n_linhas=5000):\n    data = []\n    ids_gerados = set()  # Conjunto para rastrear os IDs gerados\n    emails_gerados = set()  # Conjunto para rastrear os emails gerados\n    \n    for _ in range(n_linhas):\n        employee_id = len(ids_gerados) + 1  # Garante que o ID seja único e sequencial\n        ids_gerados.add(employee_id)  # Adiciona o ID ao conjunto\n        \n        email = fake.email()\n        while email in emails_gerados:  # Gera um novo email se já existir\n            email = fake.email()\n        emails_gerados.add(email)  # Adiciona o email ao conjunto\n        \n        data.append({\n            'employee_id': employee_id,\n            'manager_id': random.choice([None, random.randint(1, 100000)]),\n            'first_name': fake.first_name(),\n            'last_name': fake.last_name(),\n            'email': email,\n            'phone_number': fake.phone_number(),\n            'hire_date': fake.date_between(start_date='-10y', end_date='today'),\n            'department_id': random.randint(1, 20),\n            'job_title': fake.job(),\n            'location': f\"{fake.city()}, {fake.state()}, Brasil\",\n            'birth_date': fake.date_of_birth(minimum_age=18, maximum_age=70),\n            'gender': random.choice(['Masculino', 'Feminino', 'Prefiro não dizer']),\n            'nationality': 'Brasileiro(a)',\n            'start_date': fake.date_between(start_date='-5y', end_date='today'),\n            'salary': round(random.uniform(2000, 15000), 2),\n            'termination_date': fake.date_between(start_date='-2y', end_date='today') if random.random() < 0.1 else None,\n            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        })\n    \n    return pd.DataFrame(data)\n\n# Função para gerar dados de produtos (products)\ndef gerar_dados_product(n_linhas=5000):\n    data = []\n    ids_gerados = set()  # Conjunto para rastrear os IDs gerados\n    emails_gerados = set()  # Conjunto para rastrear os emails gerados\n\n    while len(data) < n_linhas:\n        product_id = random.randint(1, 100000)\n        while product_id in ids_gerados:  # Gera um novo ID se já existir\n            product_id = random.randint(1, 100000)\n        ids_gerados.add(product_id)  # Adiciona o ID ao conjunto\n\n        email_fornecedor = fake.email()\n        while email_fornecedor in emails_gerados:  # Gera um novo email se já existir\n            email_fornecedor = fake.email()\n        emails_gerados.add(email_fornecedor)  # Adiciona o email ao conjunto\n\n        data.append({\n            'id': product_id,\n            'name': fake.word(),\n            'description': fake.text(max_nb_chars=100),\n            'price': round(random.uniform(10, 5000), 2),\n            'categoria': random.choice(list(CategoriaBase)).value,\n            'email_fornecedor': email_fornecedor,\n            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        })\n    \n    return pd.DataFrame(data)\n\n# Função para gerar dados de vendas (sales)\ndef gerar_dados_sales(n_linhas=5000):\n    data = []\n    \n    for sale_id in range(1, n_linhas + 1): \n        data.append({\n            'id': sale_id,\n            'email_employee': fake.email(),\n            'email_customer': fake.email(),\n            'first_name': fake.first_name(),\n            'last_name': fake.last_name(),\n            'phone_number': fake.phone_number(),\n            'price': round(random.uniform(50, 2000), 2),\n            'quantity': random.randint(1, 10),\n            'name_product':  random.choice(list(ProdutoEnum)).value,\n            'date': fake.date_time_between(start_date='-2y', end_date='now'),\n            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        })  \n    \n    return pd.DataFrame(data)\n# Função para gerar dados de fornecedores (suppliers)\ndef gerar_dados_supplier(n_linhas=5000):\n    data = []\n    ids_gerados = set()  # Conjunto para rastrear os IDs gerados\n    emails_gerados = set()  # Conjunto para rastrear os emails gerados\n\n    while len(data) < n_linhas:\n        supplier_id = random.randint(1, 100000)\n        while supplier_id in ids_gerados:  # Gera um novo ID se já existir\n            supplier_id = random.randint(1, 100000)\n        ids_gerados.add(supplier_id)  # Adiciona o ID ao conjunto\n\n        email = fake.email()\n        while email in emails_gerados:  # Gera um novo email se já existir\n            email = fake.email()\n        emails_gerados.add(email)  # Adiciona o email ao conjunto\n\n        data.append({\n            'supplier_id': supplier_id,\n            'company_name': fake.company(),\n            'contact_name': fake.name(),\n            'email': email,\n            'phone_number': fake.phone_number(),\n            'website': fake.url(),\n            'address': f\"{fake.street_name()}, {fake.building_number()}, {fake.neighborhood()}, {fake.city()}\",\n            'product_categories': random.choice(list(ProductCategoriesEnum)).value,\n            'primary_product': fake.word(),\n            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        })\n    \n    return pd.DataFrame(data)\n\n\n# Definindo caminhos para salvar os dados\ncaminho_raw_employee = './app/backend/datasets/raw_data/employee/'\ncaminho_raw_product = './app/backend/datasets/raw_data/product/'\ncaminho_raw_sales = './app/backend/datasets/raw_data/sales/'\ncaminho_raw_supplier = './app/backend/datasets/raw_data/supplier/'\n\n# Gerando e salvando os arquivos em Parquet para cada tabela\nfor func, caminho, nome_tabela in [\n        (gerar_dados_employee, caminho_raw_employee, 'employees'),\n        (gerar_dados_product, caminho_raw_product, 'products'),\n        (gerar_dados_sales, caminho_raw_sales, 'sales'),\n        (gerar_dados_supplier, caminho_raw_supplier, 'suppliers')]:\n\n    # Ensure the directory exists\n    os.makedirs(caminho, exist_ok=True)\n\n    df = func()  # Gerando os dados\n    table = pa.Table.from_pandas(df)  # Convertendo para tabela Parquet\n    data_referencia = datetime.today().strftime('%Y-%m-%d')  # Data de referência para nome do arquivo\n    arquivo_saida = f'{caminho}{nome_tabela}_{data_referencia}.parquet'\n    \n    print(f'Escrevendo arquivo em: {arquivo_saida}')  # Adicione esta linha para depuração\n    pq.write_table(table, arquivo_saida)\n    print(f'Arquivo {nome_tabela} para {data_referencia} gerado com sucesso.')\n"}
{"type": "source_file", "path": "app/backend/generate_dataset/generate_raw_minio.py", "content": "import pandas as pd\nfrom faker import Faker\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nfrom datetime import datetime\nfrom enum import Enum\nimport random\nimport os\nimport boto3\nfrom botocore.client import Config\n\n# Configuração de conexão com o MinIO\nMINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"minio:9000\") \nMINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\", \"minioadmin\")\nMINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\", \"minioadmin\")\nMINIO_BUCKET_EMPLOYEE = os.getenv(\"MINIO_BUCKET_EMPLOYEE\", \"employee\")\nMINIO_BUCKET_PRODUCT = os.getenv(\"MINIO_BUCKET_PRODUCT\", \"product\")\nMINIO_BUCKET_SALES = os.getenv(\"MINIO_BUCKET_SALES\", \"sales\")\nMINIO_BUCKET_SUPPLIER = os.getenv(\"MINIO_BUCKET_SUPPLIER\", \"supplier\")\n\n# Inicializando o cliente do MinIO\ns3_client = boto3.client(\n    's3',\n    endpoint_url=f\"http://{MINIO_ENDPOINT}\",\n    aws_access_key_id=MINIO_ACCESS_KEY,\n    aws_secret_access_key=MINIO_SECRET_KEY,\n    config=Config(signature_version='s3v4')\n)\n\ndef upload_to_minio(file_path, bucket_name, object_name=None):\n    \"\"\"Função para enviar um arquivo para um bucket MinIO\"\"\"\n    if object_name is None:\n        object_name = os.path.basename(file_path)\n    try:\n        s3_client.upload_file(file_path, bucket_name, object_name)\n        print(f\"Arquivo {object_name} enviado para o bucket {bucket_name} com sucesso.\")\n    except Exception as e:\n        print(f\"Erro ao enviar arquivo para o MinIO: {e}\")\n\n# Inicializando o Faker para dados em português\nfake = Faker('pt_BR')\n\nclass CategoriaBase(Enum):\n    categoria1 = \"Eletrônico\"\n    categoria2 = \"Eletrodoméstico\"\n    categoria3 = \"Móveis\"\n    categoria4 = \"Roupas\"\n    categoria5 = \"Calçados\"\n\nclass ProductCategoriesEnum(str, Enum):\n    categoria1 = \"Categoria 1\"\n    categoria2 = \"Categoria 2\"\n    categoria3 = \"Categoria 3\"\n\nclass ProdutoEnum(str, Enum):\n    produto1 = \"ZapFlow com Gemini\"\n    produto2 = \"ZapFlow com chatGPT\"\n    produto3 = \"ZapFlow com Llama3.0\"\n\ndef gerar_dados_employee(n_linhas=5000):\n    data = []\n    ids_gerados = set()\n    emails_gerados = set()\n    \n    for _ in range(n_linhas):\n        employee_id = len(ids_gerados) + 1\n        ids_gerados.add(employee_id)\n        \n        email = fake.email()\n        while email in emails_gerados:\n            email = fake.email()\n        emails_gerados.add(email)\n        \n        data.append({\n            'employee_id': employee_id,\n            'manager_id': random.choice([None, random.randint(1, 100000)]),\n            'first_name': fake.first_name(),\n            'last_name': fake.last_name(),\n            'email': email,\n            'phone_number': fake.phone_number(),\n            'hire_date': fake.date_between(start_date='-10y', end_date='today'),\n            'department_id': random.randint(1, 20),\n            'job_title': fake.job(),\n            'location': f\"{fake.city()}, {fake.state()}, Brasil\",\n            'birth_date': fake.date_of_birth(minimum_age=18, maximum_age=70),\n            'gender': random.choice(['Masculino', 'Feminino', 'Prefiro não dizer']),\n            'nationality': 'Brasileiro(a)',\n            'start_date': fake.date_between(start_date='-5y', end_date='today'),\n            'salary': round(random.uniform(2000, 15000), 2),\n            'termination_date': fake.date_between(start_date='-2y', end_date='today') if random.random() < 0.1 else None,\n            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        })\n    \n    return pd.DataFrame(data)\n\ndef gerar_dados_product(n_linhas=5000):\n    data = []\n    ids_gerados = set()\n    emails_gerados = set()\n\n    while len(data) < n_linhas:\n        product_id = random.randint(1, 100000)\n        while product_id in ids_gerados:\n            product_id = random.randint(1, 100000)\n        ids_gerados.add(product_id)\n\n        email_fornecedor = fake.email()\n        while email_fornecedor in emails_gerados:\n            email_fornecedor = fake.email()\n        emails_gerados.add(email_fornecedor)\n\n        data.append({\n            'id': product_id,\n            'name': fake.word(),\n            'description': fake.text(max_nb_chars=100),\n            'price': round(random.uniform(10, 5000), 2),\n            'categoria': random.choice(list(CategoriaBase)).value,\n            'email_fornecedor': email_fornecedor,\n            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        })\n    \n    return pd.DataFrame(data)\n\ndef gerar_dados_sales(n_linhas=5000):\n    data = []\n    \n    for sale_id in range(1, n_linhas + 1): \n        data.append({\n            'id': sale_id,\n            'email': fake.email(),\n            'valor': round(random.uniform(50, 2000), 2),\n            'quantidade': random.randint(1, 10),\n            'produto':  random.choice(list(ProdutoEnum)).value,\n            'data': fake.date_time_between(start_date='-2y', end_date='now'),\n            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        })\n    \n    return pd.DataFrame(data)\n\ndef gerar_dados_supplier(n_linhas=5000):\n    data = []\n    ids_gerados = set()\n    emails_gerados = set()\n\n    while len(data) < n_linhas:\n        supplier_id = random.randint(1, 100000)\n        while supplier_id in ids_gerados:\n            supplier_id = random.randint(1, 100000)\n        ids_gerados.add(supplier_id)\n\n        email = fake.email()\n        while email in emails_gerados:\n            email = fake.email()\n        emails_gerados.add(email)\n\n        data.append({\n            'supplier_id': supplier_id,\n            'company_name': fake.company(),\n            'contact_name': fake.name(),\n            'email': email,\n            'phone_number': fake.phone_number(),\n            'website': fake.url(),\n            'address': f\"{fake.street_name()}, {fake.building_number()}, {fake.neighborhood()}, {fake.city()}\",\n            'product_categories': random.choice(list(ProductCategoriesEnum)).value,\n            'primary_product': fake.word(),\n            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        })\n    \n    return pd.DataFrame(data)\n\n# Definindo caminhos para salvar os dados\ncaminho_raw_employee = './app/backend/datasets/raw_data/employee/'\ncaminho_raw_product = './app/backend/datasets/raw_data/product/'\ncaminho_raw_sales = './app/backend/datasets/raw_data/sales/'\ncaminho_raw_supplier = './app/backend/datasets/raw_data/supplier/'\n\n# Gerando e salvando os arquivos em Parquet para cada tabela\nfor func, caminho, nome_tabela, bucket in [\n        (gerar_dados_employee, caminho_raw_employee, 'employees', MINIO_BUCKET_EMPLOYEE),\n        (gerar_dados_product, caminho_raw_product, 'products', MINIO_BUCKET_PRODUCT),\n        (gerar_dados_sales, caminho_raw_sales, 'sales', MINIO_BUCKET_SALES),\n        (gerar_dados_supplier, caminho_raw_supplier, 'suppliers', MINIO_BUCKET_SUPPLIER)]:\n\n    os.makedirs(caminho, exist_ok=True)\n\n    df = func()\n    table = pa.Table.from_pandas(df)\n    data_referencia = datetime.today().strftime('%Y-%m-%d')\n    arquivo_saida = f'{caminho}{nome_tabela}_{data_referencia}.parquet'\n    \n    pq.write_table(table, arquivo_saida)\n    print(f'Arquivo {nome_tabela} para {data_referencia} gerado com sucesso.')\n\n    upload_to_minio(arquivo_saida, bucket)\n"}
{"type": "source_file", "path": "app/backend/generate_dataset/load_raw_to_postgres.py", "content": "import duckdb\nimport os\nfrom dotenv import load_dotenv\nfrom tqdm import tqdm\nimport glob\nimport time\nfrom sqlalchemy import create_engine, text\n\nstart_time = time.time()\n\n# Carregar as variáveis de ambiente do arquivo .env\nload_dotenv()\n\n# Obter as variáveis do arquivo .env\nDB_HOST = os.getenv('DB_HOST_PROD')\nDB_PORT = os.getenv('DB_PORT_PROD')\nDB_NAME = os.getenv('DB_NAME_PROD')\nDB_USER = os.getenv('DB_USER_PROD')\nDB_PASS = os.getenv('DB_PASS_PROD')\n\n# Criar a URL de conexão do banco de dados\npostgres_conn = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n\n# Conexão com o DuckDB e o PostgreSQL\ncon = duckdb.connect()\n\n# Instalar e carregar o scanner PostgreSQL no DuckDB\ncon.execute(\"\"\"\n    INSTALL postgres_scanner;\n    LOAD postgres_scanner;\n\"\"\")\n\n# Conectar ao PostgreSQL usando o comando ATTACH\ncon.execute(f\"\"\"\n    ATTACH 'dbname={DB_NAME} user={DB_USER} password={DB_PASS} host={DB_HOST} port={DB_PORT}' AS postgres_db (TYPE POSTGRES, SCHEMA 'public');\n\"\"\")\n\n# Função para ajustar a sequência automaticamente\ndef ajustar_sequencia(postgres_table, sequence_name, id_column):\n    engine = create_engine(postgres_conn)\n    with engine.connect() as connection:\n        # Ajustar sequência sem cross-database reference\n        max_id = connection.execute(text(f\"SELECT MAX({id_column}) FROM {postgres_table}\")).scalar()\n        if max_id is not None:\n            connection.execute(text(f\"SELECT setval('{sequence_name}', :new_val)\"), {\"new_val\": max_id + 1})\n    engine.dispose()\n\n# Função para criar a tabela se ela não existir\ndef create_table_if_not_exists(postgres_table, schema):\n    con.execute(f\"\"\"\n        CREATE TABLE IF NOT EXISTS postgres_db.public.{postgres_table} AS \n        SELECT * FROM {schema} LIMIT 0;\n    \"\"\")\n\n# Função para carregar arquivos Parquet e transferir para PostgreSQL\ndef load_parquet_to_postgres(parquet_dir, postgres_table, sequence_name, id_column):\n    # Listar todos os arquivos Parquet\n    parquet_files = glob.glob(os.path.join(parquet_dir, '*.parquet'))\n    \n    # Mensagem de debug\n    print(f\"Arquivos Parquet encontrados em {parquet_dir}: {parquet_files}\")\n\n    if not parquet_files:\n        print(f\"Nenhum arquivo Parquet encontrado em {parquet_dir}.\")\n        return  # Saia se não houver arquivos\n    \n    # Mostrar a barra de progresso\n    for parquet_file in tqdm(parquet_files, desc=f\"Carregando {postgres_table}\", unit=\"arquivo\"):\n        # Carregar os arquivos Parquet no DuckDB\n        query = f\"CREATE OR REPLACE TEMPORARY VIEW temp_view AS SELECT * FROM read_parquet('{parquet_file}');\"\n        con.execute(query)\n        \n        # Criar a tabela no PostgreSQL, se não existir\n        create_table_if_not_exists(postgres_table, 'temp_view')\n        \n        # Inserir os dados diretamente no PostgreSQL\n        con.execute(f\"\"\"\n            INSERT INTO postgres_db.public.{postgres_table}\n            SELECT * FROM temp_view;\n        \"\"\")\n    \n    print(f\"Dados de {parquet_dir} carregados na tabela {postgres_table} no PostgreSQL\")\n    \n    # Ajustar a sequência automaticamente após inserir dados\n    ajustar_sequencia(postgres_table, sequence_name, id_column)\n\n# Caminhos para as pastas de arquivos Parquet e configurações de sequência\nparquet_config = [\n    {\"dir\": './app/backend/datasets/raw_data/employee/', \"table\": \"employees\", \"sequence\": \"employees_employee_id_seq\", \"id_column\": \"employee_id\"},\n    {\"dir\": './app/backend/datasets/raw_data/product/', \"table\": \"products\", \"sequence\": \"products_id_seq\", \"id_column\": \"id\"},\n    {\"dir\": './app/backend/datasets/raw_data/sales/', \"table\": \"sales\", \"sequence\": \"sales_id_seq\", \"id_column\": \"id\"},\n    {\"dir\": './app/backend/datasets/raw_data/supplier/', \"table\": \"suppliers\", \"sequence\": \"suppliers_supplier_id_seq\", \"id_column\": \"supplier_id\"},\n]\n\n# Carregar os arquivos Parquet para PostgreSQL de acordo com os modelos de dados\nfor config in parquet_config:\n    load_parquet_to_postgres(config[\"dir\"], config[\"table\"], config[\"sequence\"], config[\"id_column\"])\n\n# Fechar a conexão\ncon.close()\n\nelapsed_time = time.time() - start_time\nprint(f\"Tempo decorrido: {elapsed_time:.2f} segundos\")\n"}
{"type": "source_file", "path": "app/backend/generate_dataset/local_to_s3_boto3.py", "content": "import duckdb\nimport os\nfrom dotenv import load_dotenv\nfrom tqdm import tqdm\nimport glob\nimport time\nimport boto3\n\nstart_time = time.time()\n\n# Remover variáveis previamente carregadas (se houver)\nos.environ.pop('AWS_ACCESS_KEY_ID', None)\nos.environ.pop('AWS_SECRET_ACCESS_KEY', None)\nos.environ.pop('AWS_BUCKET_NAME', None)\nos.environ.pop('AWS_REGION', None)\n\n# Carregar as variáveis de ambiente do arquivo .env\nload_dotenv(override=True)\n\n# Obter as variáveis de ambiente para o S3\nAWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\nAWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\nAWS_BUCKET_NAME = os.getenv('AWS_BUCKET_NAME')\nAWS_REGION = os.getenv('AWS_REGION')\n\n# Conexão com o S3 usando boto3\ns3_client = boto3.client('s3', \n                         aws_access_key_id=AWS_ACCESS_KEY_ID, \n                         aws_secret_access_key=AWS_SECRET_ACCESS_KEY, \n                         region_name=AWS_REGION)\n\n# Função para fazer upload dos arquivos Parquet para o S3\ndef upload_parquet_to_s3(file_path, bucket_name, s3_key):\n    try:\n        # Upload do arquivo\n        s3_client.upload_file(file_path, bucket_name, s3_key)\n        print(f\"Arquivo {file_path} carregado para {bucket_name}/{s3_key}\")\n    except Exception as e:\n        print(f\"Erro ao carregar o arquivo {file_path}: {e}\")\n\n# Função para carregar arquivos Parquet e transferir para o S3\ndef load_parquet_to_s3(parquet_dir, s3_prefix):\n    # Listar todos os arquivos Parquet\n    parquet_files = glob.glob(os.path.join(parquet_dir, '*.parquet'))\n    \n    # Mostrar a barra de progresso\n    for parquet_file in tqdm(parquet_files, desc=f\"Carregando {s3_prefix}\", unit=\"arquivo\"):\n        # Carregar o arquivo Parquet no DuckDB (opcional, caso queira realizar alguma operação)\n        con = duckdb.connect()\n        query = f\"CREATE OR REPLACE TEMPORARY VIEW temp_view AS SELECT * FROM read_parquet('{parquet_file}');\"\n        con.execute(query)\n        \n        # Opcional: se quiser manipular os dados, pode fazer aqui\n        \n        # Definir o caminho (key) no S3 onde o arquivo será salvo\n        s3_key = f\"{s3_prefix}/{os.path.basename(parquet_file)}\"\n        \n        # Fazer upload do arquivo Parquet para o S3\n        upload_parquet_to_s3(parquet_file, AWS_BUCKET_NAME, s3_key)\n        \n        con.close()\n    \n    print(f\"Dados de {parquet_dir} carregados no S3 com prefixo {s3_prefix}\")\n\n# Caminho para as pastas de arquivos Parquet\nparquet_dir_cadastros = './datasets/raw_data/cadastros/'\nparquet_dir_pedidos = './datasets/raw_data/pedidos/'\n\n# Carregar os arquivos de cadastros e pedidos para o S3\nload_parquet_to_s3(parquet_dir_cadastros, 'datasets/bronze/cadastros')\nload_parquet_to_s3(parquet_dir_pedidos, 'datasets/bronze/pedidos')\n\nelapsed_time = time.time() - start_time\nprint(f\"Tempo decorrido: {elapsed_time:.2f} segundos\")"}
{"type": "source_file", "path": "app/backend/integration/google_analytics.py", "content": "import os\nimport pandas as pd\nfrom sqlalchemy import create_engine\nfrom google.analytics.data_v1beta import BetaAnalyticsDataClient\nfrom google.analytics.data_v1beta.types import (\n    DateRange,\n    Dimension,\n    Metric,\n    RunReportRequest,\n)\nfrom dotenv import load_dotenv\n\n# Carrega as variáveis de ambiente do arquivo .env\nload_dotenv()\n\ndef baixar_dados_analytics():\n    \"\"\"Baixa dados do Google Analytics 4 e salva em um banco de dados SQL.\"\"\"\n    client = BetaAnalyticsDataClient()\n\n    property_id = os.getenv(\"GA_PROPERTY_ID\")\n    start_date = os.getenv(\"GA_START_DATE\")\n\n    request = RunReportRequest(\n        property=f\"properties/{property_id}\",\n        dimensions=[\n            Dimension(name=\"date\"),\n            Dimension(name=\"city\"),\n            Dimension(name=\"country\"),\n            Dimension(name=\"deviceCategory\"),\n            Dimension(name=\"sessionSource\"),\n            Dimension(name=\"sessionMedium\"),\n        ],\n        metrics=[\n            Metric(name=\"totalUsers\"),\n            Metric(name=\"newUsers\"),\n            Metric(name=\"activeUsers\"),\n            Metric(name=\"sessions\"),\n            Metric(name=\"engagedSessions\"),\n            Metric(name=\"averageSessionDuration\"),\n            Metric(name=\"screenPageViews\"),\n            Metric(name=\"conversions\"),\n            Metric(name=\"totalRevenue\"),\n        ],\n        date_ranges=[DateRange(start_date=start_date, end_date=\"today\")],\n    )\n    response = client.run_report(request)\n\n    # Criar listas para armazenar os dados\n    data = []\n    header = [dim.name for dim in request.dimensions] + [metric.name for metric in request.metrics]\n\n    # Preencher a lista de dados\n    for row in response.rows:\n        row_data = [dim_value.value for dim_value in row.dimension_values] + [metric_value.value for metric_value in row.metric_values]\n        data.append(row_data)\n\n    # Criar um DataFrame com os dados\n    df = pd.DataFrame(data, columns=header)\n\n    # Configuração da conexão com o banco de dados PostgreSQL\n    # Obter as variáveis do arquivo .env\n    DB_PORT = os.getenv('DB_PORT_PROD')\n    DB_NAME = os.getenv('DB_NAME_PROD')\n    DB_USER = os.getenv('DB_USER_PROD')\n    DB_PASS = os.getenv('DB_PASS_PROD')\n\n    # Criar a URL de conexão do banco de dados\n    SQLALCHEMY_DATABASE_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@postgres:{DB_PORT}/{DB_NAME}\"\n    engine = create_engine(SQLALCHEMY_DATABASE_URL)\n\n    # Salvar o DataFrame na tabela 'google_analytics_data' do banco de dados\n    df.to_sql(name='google_analytics_data', con=engine, if_exists='replace', index=False)\n\n    print(\"Dados do Google Analytics salvos no banco de dados PostgreSQL.\")\n\nif __name__ == \"__main__\":\n    baixar_dados_analytics()"}
{"type": "source_file", "path": "app/backend/generate_dataset/local_to_s3_duckdb.py", "content": "import duckdb\nimport os\nfrom dotenv import load_dotenv\nfrom tqdm import tqdm\nimport glob\nimport time\n\nstart_time = time.time()\n\n# Remover variáveis previamente carregadas (se houver)\nos.environ.pop('AWS_ACCESS_KEY_ID', None)\nos.environ.pop('AWS_SECRET_ACCESS_KEY', None)\nos.environ.pop('AWS_BUCKET_NAME', None)\nos.environ.pop('AWS_REGION', None)\n\n# Carregar as variáveis de ambiente do arquivo .env\nload_dotenv(override=True)\n\n# Obter as variáveis de ambiente para o S3\nAWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\nAWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\nAWS_BUCKET_NAME = os.getenv('AWS_BUCKET_NAME')\nAWS_REGION = os.getenv('AWS_REGION')\n\n# Conectar ao DuckDB (em memória ou em arquivo se necessário)\ncon = duckdb.connect()\n\n# Instalar e carregar a extensão httpfs para acesso ao S3\ncon.execute(\"INSTALL httpfs;\")\ncon.execute(\"LOAD httpfs;\")\n\n# Configurar as credenciais do S3 no DuckDB\ncon.execute(f\"\"\"\n    SET s3_region='{AWS_REGION}';\n    SET s3_access_key_id='{AWS_ACCESS_KEY_ID}';\n    SET s3_secret_access_key='{AWS_SECRET_ACCESS_KEY}';\n\"\"\")\n\n# Função para carregar arquivos Parquet e transferir para o S3 via DuckDB\ndef load_parquet_to_s3(parquet_dir, s3_prefix):\n    # Listar todos os arquivos Parquet\n    parquet_files = glob.glob(os.path.join(parquet_dir, '*.parquet'))\n    \n    # Mostrar a barra de progresso\n    for parquet_file in tqdm(parquet_files, desc=f\"Carregando {s3_prefix}\", unit=\"arquivo\"):\n        # Definir o caminho (key) no S3 onde o arquivo será salvo\n        s3_path = f\"s3://{AWS_BUCKET_NAME}/{s3_prefix}/{os.path.basename(parquet_file)}\"\n        \n        # Carregar o arquivo Parquet no DuckDB e enviar diretamente para o S3\n        con.execute(f\"\"\"\n            COPY (SELECT * FROM read_parquet('{parquet_file}')) \n            TO '{s3_path}' \n            (FORMAT PARQUET);\n        \"\"\")\n        \n        print(f\"Arquivo {parquet_file} carregado para {s3_path}\")\n    \n    print(f\"Dados de {parquet_dir} carregados no S3 com prefixo {s3_prefix}\")\n\n# Caminho para as pastas de arquivos Parquet\nparquet_dir_cadastros = './datasets/raw_data/cadastros/'\nparquet_dir_pedidos = './datasets/raw_data/pedidos/'\n\n# Carregar os arquivos de cadastros e pedidos para o S3\nload_parquet_to_s3(parquet_dir_cadastros, 'datasets_duckdb/bronze/cadastros')\nload_parquet_to_s3(parquet_dir_pedidos, 'datasets_duckdb/bronze/pedidos')\n\n# Fechar a conexão com o DuckDB\ncon.close()\n\nelapsed_time = time.time() - start_time\nprint(f\"Tempo decorrido: {elapsed_time:.2f} segundos\")"}
{"type": "source_file", "path": "app/backend/integration/typeform_to_csv.py", "content": "import os\nfrom dotenv import load_dotenv\nimport requests\nimport pandas as pd\n\ndef load_environment_variables():\n    \"\"\"Carrega as variáveis de ambiente do arquivo .env\"\"\"\n    load_dotenv()\n    api_token = os.getenv('TYPEFORM_API_TOKEN')\n    form_id = os.getenv('TYPEFORM_FORM_ID')\n    return api_token, form_id\n\ndef fetch_typeform_responses(api_token, form_id):\n    \"\"\"Faz a requisição à API do Typeform e retorna as respostas\"\"\"\n    url = f'https://api.typeform.com/forms/{form_id}/responses'\n    headers = {'Authorization': f'Bearer {api_token}'}\n    params = {'page_size': 100}\n    \n    try:\n        response = requests.get(url, headers=headers, params=params)\n        response.raise_for_status()\n        return response.json()['items']\n    except requests.exceptions.RequestException as e:\n        print(f\"Erro ao obter as respostas: {e}\")\n        return None\n\ndef format_responses(responses):\n    \"\"\"Formata as respostas obtidas da API\"\"\"\n    formatted_responses = []\n    for resp in responses:\n        formatted_resp = {\n            'submitted_at': resp['submitted_at'],\n            'response_id': resp['response_id']\n        }\n        \n        for answer in resp['answers']:\n            question_id = answer['field']['id']\n            question_type = answer['type']\n            \n            if question_type in ['text', 'number', 'date']:\n                formatted_resp[question_id] = answer[question_type]\n            elif question_type == 'choice':\n                formatted_resp[question_id] = answer['choice']['label']\n            elif question_type == 'choices':\n                formatted_resp[question_id] = ', '.join(answer['choices']['labels'])\n        \n        formatted_responses.append(formatted_resp)\n    return formatted_responses\n\ndef save_responses_to_csv(formatted_responses, filename='typeform_responses.csv'):\n    \"\"\"Salva as respostas formatadas em um arquivo CSV\"\"\"\n    df = pd.DataFrame(formatted_responses)\n    df.to_csv(filename, index=False)\n    print(f\"As respostas foram salvas em '{filename}'\")\n\ndef main():\n    api_token, form_id = load_environment_variables()\n    responses = fetch_typeform_responses(api_token, form_id)\n    if responses:\n        formatted_responses = format_responses(responses)\n        save_responses_to_csv(formatted_responses)\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "app/backend/integration/typeform_to_postgresql.py", "content": "import os\nimport logging\nfrom dotenv import load_dotenv\nimport requests\nimport pandas as pd\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.exc import SQLAlchemyError\n\n# Configura o logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\ndef load_env_variables():\n    load_dotenv()\n    api_token = os.getenv('TYPEFORM_API_TOKEN')\n    form_id = os.getenv('TYPEFORM_FORM_ID')\n    db_url = os.getenv('SQLALCHEMY_DATABASE_URL')\n    \n    if not all([api_token, form_id, db_url]):\n        raise EnvironmentError(\"Variáveis de ambiente necessárias não estão definidas.\")\n    \n    return api_token, form_id, db_url\n\ndef fetch_typeform_responses(api_token, form_id):\n    url = f'https://api.typeform.com/forms/{form_id}/responses'\n    headers = {'Authorization': f'Bearer {api_token}'}\n    params = {'page_size': 100}\n    \n    try:\n        response = requests.get(url, headers=headers, params=params)\n        response.raise_for_status()\n        return response.json()['items']\n    except requests.exceptions.RequestException as e:\n        logging.error(f\"Erro ao obter as respostas: {e}\")\n        return []\n\ndef format_responses(responses):\n    formatted_responses = []\n    for resp in responses:\n        formatted_resp = {\n            'submitted_at': resp['submitted_at'],\n            'response_id': resp['response_id']\n        }\n        for answer in resp['answers']:\n            question_id = answer['field']['id']\n            question_type = answer['type']\n            if question_type in ['text', 'number', 'date']:\n                formatted_resp[question_id] = answer[question_type]\n            elif question_type == 'choice':\n                formatted_resp[question_id] = answer['choice']['label']\n            elif question_type == 'choices':\n                formatted_resp[question_id] = ', '.join([choice['label'] for choice in answer['choices']['labels']])\n        formatted_responses.append(formatted_resp)\n    return formatted_responses\n\ndef save_to_csv(df, filename='typeform_responses.csv'):\n    df.to_csv(filename, index=False)\n    logging.info(f\"As respostas foram salvas em '{filename}'\")\n\ndef save_to_database(df, db_url):\n    try:\n        engine = create_engine(db_url)\n        df.to_sql('typeform_responses', con=engine, if_exists='replace', index=False)\n        logging.info(\"As respostas foram inseridas no banco de dados PostgreSQL.\")\n    except SQLAlchemyError as e:\n        logging.error(f\"Erro ao inserir no banco de dados: {e}\")\n\ndef main():\n    try:\n        api_token, form_id, db_url = load_env_variables()\n        responses = fetch_typeform_responses(api_token, form_id)\n        if responses:\n            formatted_responses = format_responses(responses)\n            df = pd.DataFrame(formatted_responses)\n            save_to_csv(df)\n            save_to_database(df, db_url)\n    except EnvironmentError as e:\n        logging.error(e)\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "app/backend/main.py", "content": "from fastapi import FastAPI\nimport socket\nfrom database.database import async_engine, init_db\n\nfrom routes.product.routes_product import router as product_router\nfrom routes.sales.routes_sales import router as sales_router\nfrom routes.employee.routes_employee import router as employee_router\nfrom routes.supplier.routes_supplier import router as supplier_router\n\n# Inicializa as tabelas de forma assíncrona\nasync def on_startup():\n    await init_db()\n\napp = FastAPI(docs_url=\"/docs\", openapi_url=\"/openapi.json\", on_startup=[on_startup])\n\n@app.get(\"/whoami\")\nasync def whoami():\n    return {\"hostname\": socket.gethostname()}\n\napp.include_router(product_router)\napp.include_router(sales_router)\napp.include_router(employee_router)\napp.include_router(supplier_router)\n"}
{"type": "source_file", "path": "app/backend/models/employee/employee.py", "content": "from sqlalchemy import Column, Integer, String, Float, Date, Enum as SQLAlchemyEnum, DateTime\nfrom sqlalchemy.sql import func\nfrom database.database import Base\nfrom .employee_schema import GenderEnum\n\n\nclass EmployeeModel(Base):\n    \"\"\"\n    Modelo de dados para representar um funcionário no banco de dados.\n\n    Atributos:\n        employee_id (Integer): Identificador único do funcionário, chave primária.\n        first_name (String): Nome do funcionário.\n        last_name (String): Sobrenome do funcionário.\n        email (String): Endereço de email do funcionário.\n        phone_number (String): Número de telefone do funcionário.\n        hire_date (Date): Data de contratação do funcionário.\n        department_id (Integer): Identificador do departamento.\n        job_title (String): Cargo do funcionário.\n        location (String): Localização do funcionário (cidade, estado, país).\n        birth_date (Date): Data de nascimento do funcionário.\n        gender (Enum): Gênero do funcionário.\n        nationality (String): Nacionalidade do funcionário.\n        start_date (Date): Data de início no cargo atual.\n        salary (Float): Salário do funcionário.\n        termination_date (Date): Data de término do contrato do funcionário, se aplicável.\n        manager_id (Integer): Identificador do gerente, se aplicável.\n    \"\"\"\n\n    __tablename__ = \"employees\"\n\n    employee_id = Column(Integer, primary_key=True, autoincrement=True, index=True)\n    manager_id = Column(Integer, index=True)\n    first_name = Column(String, index=True)\n    last_name = Column(String, index=True)\n    email = Column(String, unique=True, index=True)\n    phone_number = Column(String)\n    hire_date = Column(Date, index=True)\n    department_id = Column(Integer, index=True)\n    job_title = Column(String)\n    location = Column(String)\n    birth_date = Column(Date)\n    gender = Column(String)\n    nationality = Column(String)\n    start_date = Column(Date)\n    salary = Column(Float)\n    termination_date = Column(Date, nullable=True)\n    created_at = Column(DateTime(timezone=True), default=func.now(), index=True)"}
{"type": "source_file", "path": "app/backend/models/product/product.py", "content": "from sqlalchemy import Column, Integer, String, Float, DateTime\nfrom sqlalchemy.sql import func\nfrom database.database import Base\n\n\nclass ProductModel(Base):\n    \"\"\"\n    Modelo de dados para representar um produto no banco de dados.\n\n    Atributos:\n        id (Integer): Identificador único do produto, chave primária.\n        name (String): Nome do produto.\n        description (String): Descrição do produto.\n        price (Float): Preço do produto.\n        categoria (String): Categoria do produto.\n        email_fornecedor (String): Email do fornecedor do produto.\n        created_at (DateTime): Data e hora de criação do registro do produto.\n    \"\"\"\n\n    __tablename__ = \"products\"\n\n    id = Column(Integer, primary_key=True, autoincrement=True, index=True)\n    name = Column(String, index=True)\n    description = Column(String, index=True)\n    price = Column(Float, index=True)\n    categoria = Column(String, index=True)\n    email_fornecedor = Column(String, index=True)\n    created_at = Column(DateTime(timezone=True), default=func.now(), index=True)"}
{"type": "source_file", "path": "app/frontend/sales/__init__.py", "content": "from .create import create\nfrom .delete import delete\nfrom .read_all import read_all\nfrom .read_sale import read_sale\nfrom .update import update"}
{"type": "source_file", "path": "app/frontend/sales/delete.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\nfrom utils import show_response_message\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\n\ndef delete():\n    delete_id = st.number_input(\"ID da Venda para Deletar\", min_value=1, format=\"%d\")\n    \n    # Botão para consultar Venda\n    if st.button(\"Buscar Venda\"):\n        response = requests.get(f\"{os.getenv('BACKEND_URL')}/sales/{delete_id}\")\n        if response.status_code == 200:\n            sales = response.json()\n            # Verifica se o JSON está vazio\n            if not sales:\n                st.warning(\"⚠️ Nenhuma Venda encontrada!\")\n                return\n            \n            df = pd.DataFrame([sales])\n\n            # Seleciona as colunas desejadas\n            df = df[\n                [\n                    \"id\",\n                    \"email_employee\",\n                    \"email_customer\",\n                    \"first_name\",\n                    \"last_name\",\n                    \"phone_number\",\n                    \"name_product\",\n                    \"price\",\n                    \"quantity\",\n                    \"date\"\n                ]\n            ]\n\n            # Salvando a venda encontrada no estado da sessão\n            st.session_state['df_sales_del'] = df\n            st.session_state['id_sales_del'] = delete_id\n        else:\n            st.warning(\"Venda não encontrada!\")\n            st.session_state.pop('df_sales_del', None)\n\n    # Exibe as informações do Produto, se encontrado\n    if 'df_sales_del' in st.session_state:    \n        st.text_input(\"Email Funcionario:\", value=st.session_state[\"df_sales_del\"].at[0, \"email_employee\"], disabled=True, key=\"del_input_email_employee\")\n        st.text_input(\"Email Cliente:\", value=st.session_state[\"df_sales_del\"].at[0, \"email_customer\"], disabled=True, key=\"del_input_email_customer\")\n        st.text_input(\"Primeiro Nome:\", value=st.session_state[\"df_sales_del\"].at[0, \"first_name\"], disabled=True, key=\"del_input_first_name\")\n        st.text_input(\"Ultimo Nome:\", value=st.session_state[\"df_sales_del\"].at[0, \"last_name\"], disabled=True, key=\"del_input_last_name\")\n        st.text_input(\"Número Telefone:\", value=st.session_state[\"df_sales_del\"].at[0, \"phone_number\"], disabled=True, key=\"del_input_phone_number\")\n        st.text_input(\"Produto:\", value=st.session_state[\"df_sales_del\"].at[0, \"name_product\"], disabled=True, key=\"del_input_name_product\")\n        st.text_input(\"Valor (R$):\", value=st.session_state[\"df_sales_del\"].at[0, \"price\"], disabled=True, key=\"del_input_price\")\n        st.text_input(\"Quantidade:\", value=st.session_state[\"df_sales_del\"].at[0, \"quantity\"], disabled=True, key=\"del_input_quantity\")     \n        st.text_input(\"Data Venda:\", value=st.session_state[\"df_sales_del\"].at[0, \"date\"], disabled=True, key=\"del_input_date\")\n        \n\n        # Botão para deletar Venda\n        if st.button(\"Deletar Venda\"):\n            response = requests.delete(f\"{os.getenv('BACKEND_URL')}/sales/{st.session_state['id_sales_del']}\")\n            if response.status_code == 200:\n                st.success(\"Venda deletada com sucesso!\")\n                st.session_state.pop('df_sales_del')\n                st.session_state.pop('id_sales_del')\n            else:\n                st.error(\"Erro ao deletar a Venda!\")"}
{"type": "source_file", "path": "app/frontend/sales/create.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\n\nfrom utils import show_response_message\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef create():\n    # Buscar a lista de funcionários\n    response_employees = requests.get(f\"{os.getenv('BACKEND_URL')}/employees/\")\n    if response_employees.status_code == 200:\n        employees = response_employees.json()\n        # Extrair os emails dos funcionários\n        emails = [employee['email'] for employee in employees]\n        # Inserir \"Selecione o Email\" no início da lista\n        emails.insert(0, \"Selecione o Email\")\n    else:\n        show_response_message(response_employees)\n        emails = [\"Selecione o Email\"]\n\n    # Buscar a lista de produtos\n    response_products = requests.get(f\"{os.getenv('BACKEND_URL')}/products/\")\n    if response_products.status_code == 200:\n        products = response_products.json()\n        # Extrair os nomes dos produtos\n        product_names = [product['name'] for product in products]\n        # Inserir \"Selecione o Produto\" no início da lista\n        product_names.insert(0, \"Selecione o Produto\")\n    else:\n        show_response_message(response_products)\n        product_names = [\"Selecione o Produto\"]\n\n    with st.form(\"new_sale\"):\n        email = st.selectbox(\"Email do Vendedor\", options=emails)\n        email_customer = st.text_input(\"Email do Cliente\")\n        first_name = st.text_input(\"Primeiro nome do Cliente\")\n        last_name = st.text_input(\"Ultimo nome do Cliente\")\n        phone_number = st.text_input(\"Número de telefone do Cliente\")\n        data = st.date_input(\"Data da compra\", datetime.now())\n        hora = st.time_input(\"Hora da compra\", value=time(9, 0))\n        valor = st.number_input(\"Valor da venda\", min_value=0.0, format=\"%.2f\")\n        quantidade = st.number_input(\"Quantidade de produtos\", min_value=1, step=1)\n        produto = st.selectbox(\"Produto\", options=product_names)\n        \n        submit_button = st.form_submit_button(\"Adicionar Venda\")\n\n        if submit_button:\n            # Verificações antes de enviar o formulário\n            if email == \"Selecione o Email\":\n                st.warning(\"Por favor, selecione um email válido do vendedor.\")\n            elif produto == \"Selecione o Produto\":\n                st.warning(\"Por favor, selecione um produto válido.\")\n            else:\n                data_hora = datetime.combine(data, hora)\n                response = requests.post(\n                    f\"{os.getenv('BACKEND_URL')}/sales/\",\n                    json={\n                        \"email_employee\": email,\n                        \"email_customer\": email_customer,\n                        \"first_name\": first_name,\n                        \"last_name\": last_name,\n                        \"phone_number\": phone_number,\n                        \"date\": data_hora.isoformat(),\n                        \"price\": valor,\n                        \"quantity\": quantidade,\n                        \"name_product\": produto,\n                    },\n                )\n                show_response_message(response)"}
{"type": "source_file", "path": "app/backend/crud/employee/crud.py", "content": "from sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.future import select\nfrom models.employee.employee_schema import EmployeeUpdate, EmployeeCreate\nfrom models.employee.employee import EmployeeModel\n\nasync def get_employee(db: AsyncSession, employee_id: int):\n    \"\"\"\n    Função que recebe um id e retorna somente o funcionário correspondente\n    \"\"\"\n    result = await db.execute(select(EmployeeModel).where(EmployeeModel.employee_id == employee_id))\n    return result.scalars().first()\n\nasync def get_employees(db: AsyncSession):\n    \"\"\"\n    Função que retorna todos os funcionários\n    \"\"\"\n    result = await db.execute(select(EmployeeModel))\n    return result.scalars().all()\n\nasync def create_employee(db: AsyncSession, employee: EmployeeCreate):\n    \"\"\"\n    Função que cria um novo funcionário\n    \"\"\"\n    db_employee = EmployeeModel(**employee.model_dump())\n    db.add(db_employee)\n    await db.commit()\n    await db.refresh(db_employee)\n    return db_employee\n\nasync def delete_employee(db: AsyncSession, employee_id: int):\n    \"\"\"\n    Função que deleta um funcionário\n    \"\"\"\n    db_employee = await get_employee(db, employee_id=employee_id)\n    if db_employee:\n        await db.delete(db_employee)\n        await db.commit()\n    return db_employee\n\nasync def update_employee(db: AsyncSession, employee_id: int, employee: EmployeeUpdate):\n    \"\"\"\n    Atualiza apenas os campos modificados de um funcionário.\n    \"\"\"\n    db_employee = await get_employee(db, employee_id=employee_id)\n    if db_employee is None:\n        return None\n\n    # Obtém apenas os campos que foram alterados\n    update_data = employee.model_dump(exclude_unset=True)\n    \n    # Atualiza apenas os campos modificados\n    for key, value in update_data.items():\n        current_value = getattr(db_employee, key, None)\n        if current_value != value:  # Atualiza somente se o valor for diferente\n            setattr(db_employee, key, value)\n\n    if update_data:  # Apenas realiza commit se houver alterações\n        await db.commit()\n        await db.refresh(db_employee)\n        \n    return db_employee\n"}
{"type": "source_file", "path": "app/backend/models/employee/employee_schema.py", "content": "from pydantic import BaseModel, EmailStr, PositiveFloat, field_validator, computed_field, validator, ConfigDict\nfrom enum import Enum\nfrom datetime import date, datetime, timedelta\nfrom typing import Optional\n\n\nclass GenderEnum(Enum):\n    \"\"\"\n    Enum representando os gêneros dos funcionários.\n    \"\"\"\n    male = \"Masculino\"\n    female = \"Feminino\"\n    prefer_not_to_say = \"Prefiro não dizer\"\n\n\nclass EmployeeBase(BaseModel):\n    \"\"\"\n    Modelo base para informações do funcionário.\n\n    Atributos:\n        first_name (str): Nome do funcionário.\n        last_name (str): Sobrenome do funcionário.\n        email (EmailStr): Endereço de email do funcionário.\n        phone_number (str): Número de telefone do funcionário.\n        hire_date (date): Data de contratação do funcionário.\n        department_id (int): Identificador do departamento.\n        job_title (str): Cargo do funcionário.\n        location (str): Localização do funcionário (cidade, estado, país).\n        birth_date (date): Data de nascimento do funcionário.\n        gender (GenderEnum): Gênero do funcionário.\n        nationality (str): Nacionalidade do funcionário.\n        start_date (date): Data de início no cargo atual.\n        salary (PositiveFloat): Salário do funcionário.\n        termination_date (Optional[date]): Data de término do contrato do funcionário, se aplicável.\n    \"\"\"\n    first_name: str\n    last_name: str\n    email: EmailStr\n    phone_number: str\n    hire_date: date\n    department_id: int\n    manager_id: int\n    job_title: str\n    location: str\n    birth_date: date\n    gender: str\n    nationality: str\n    start_date: date\n    salary: PositiveFloat\n    termination_date: Optional[date] = None\n\n\nclass EmployeeCreate(EmployeeBase):\n    \"\"\"\n    Modelo para criar um novo funcionário. Herda todos os campos de EmployeeBase.\n    \"\"\"\n    pass\n\n\nclass EmployeeResponse(EmployeeBase):\n    \"\"\"\n    Modelo para resposta de funcionário, incluindo campos adicionais.\n\n    Atributos:\n        employee_id (int): O identificador único do funcionário.\n        manager_id (Optional[int]): Identificador do gerente, se aplicável.\n        service_duration (str): Duração do serviço do funcionário na empresa.\n    \"\"\"\n    employee_id: int\n    manager_id: Optional[int] = None\n\n    @computed_field\n    def service_duration(self) -> str:\n        \"\"\"\n        Calcula a duração do serviço do funcionário até a data atual ou até a data de término.\n        \"\"\"\n        end_date = self.termination_date or datetime.now().date()\n        duration = end_date - self.hire_date\n        years = duration.days // 365\n        months = (duration.days % 365) // 30\n        days = (duration.days % 365) % 30\n        \n        if years > 0:\n            return f\"{years} anos, {months} meses e {days} dias\"\n        elif months > 0:\n            return f\"{months} meses e {days} dias\"\n        else:\n            return f\"{days} dias\"\n\n    model_config = ConfigDict(from_attributes=True)\n\n\nclass EmployeeUpdate(BaseModel):\n    \"\"\"\n    Modelo para atualizar um funcionário existente.\n\n    Todos os campos são opcionais para permitir atualizações parciais.\n    \"\"\"\n    first_name: Optional[str] = None\n    last_name: Optional[str] = None\n    email: Optional[EmailStr] = None\n    phone_number: Optional[str] = None\n    department_id: Optional[int] = None\n    job_title: Optional[str] = None\n    manager_id: Optional[int] = None\n    location: Optional[str] = None\n    gender: Optional[str] = None\n    nationality: Optional[str] = None\n    start_date: Optional[date] = None\n    hire_date: Optional[date] = None\n    salary: Optional[PositiveFloat] = None\n    termination_date: Optional[date] = None\n    birth_date: Optional[date] = None\n"}
{"type": "source_file", "path": "app/frontend/AI/exemplo_chatgpt.py", "content": "import openai\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Set your API key\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n# Function to send a question to GPT-4\ndef pergunte_ao_chatgpt(pergunta: str):\n    response = openai.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"user\", \"content\": \"\"}\n        ]\n    )\n    # Extracting the actual content message from the response\n    return response.choices[0].message.content\n\n# Asking the question\nquestion = \"Quanto eu vendi ontem?\"\nanswer = pergunte_ao_chatgpt(question)\n\n# Print the response\nprint(f\"Resposta do ChatGPT: {answer}\")"}
{"type": "source_file", "path": "app/backend/models/product/product_schema.py", "content": "from pydantic import BaseModel, PositiveFloat, EmailStr, field_validator, Field, ConfigDict\nfrom enum import Enum\nfrom datetime import datetime\nfrom typing import Optional\n\n\nclass CategoriaBase(Enum):\n    \"\"\"\n    Enum representando as categorias de produtos.\n    \"\"\"\n    categoria1 = \"Eletrônico\"\n    categoria2 = \"Eletrodoméstico\"\n    categoria3 = \"Móveis\"\n    categoria4 = \"Roupas\"\n    categoria5 = \"Calçados\"\n\n\nclass ProductBase(BaseModel):\n    \"\"\"\n    Modelo base para informações do produto.\n\n    Atributos:\n        name (str): O nome do produto.\n        description (Optional[str]): Uma descrição opcional do produto.\n        price (PositiveFloat): O preço do produto.\n        categoria (str): A categoria do produto.\n        email_fornecedor (EmailStr): O email do fornecedor do produto.\n    \"\"\"\n    name: str\n    description: Optional[str] = None\n    price: PositiveFloat\n    categoria: str\n    email_fornecedor: EmailStr\n\n    @field_validator(\"categoria\")\n    @classmethod\n    def check_categoria(cls, v):\n        \"\"\"\n        Valida a categoria do produto.\n\n        Args:\n            v (str): O valor da categoria a ser validado.\n\n        Returns:\n            str: O valor da categoria validado.\n\n        Raises:\n            ValueError: Se a categoria for inválida.\n        \"\"\"\n        if v in [item.value for item in CategoriaBase]:\n            return v\n        raise ValueError(\"Categoria inválida\")\n\n\nclass ProductCreate(ProductBase):\n    \"\"\"\n    Modelo para criar um novo produto. Herda todos os campos de ProductBase.\n    \"\"\"\n    pass\n\n\nclass ProductResponse(ProductBase):\n    \"\"\"\n    Modelo para resposta de produto, incluindo campos adicionais.\n\n    Atributos:\n        id (int): O identificador único do produto.\n        created_at (datetime): O timestamp de quando o produto foi criado.\n    \"\"\"\n    id: int\n    created_at: datetime\n\n    model_config = ConfigDict(from_attributes=True)\n\n\nclass ProductUpdate(BaseModel):\n    \"\"\"\n    Modelo para atualizar um produto existente.\n\n    Atributos:\n        name (Optional[str]): O nome atualizado do produto.\n        description (Optional[str]): A descrição atualizada do produto.\n        price (Optional[PositiveFloat]): O preço atualizado do produto.\n        categoria (Optional[str]): A categoria atualizada do produto.\n        email_fornecedor (Optional[EmailStr]): O email atualizado do fornecedor do produto.\n    \"\"\"\n    name: Optional[str] = None\n    description: Optional[str] = None\n    price: Optional[PositiveFloat] = None\n    categoria: Optional[str] = None\n    email_fornecedor: Optional[EmailStr] = None\n\n    @field_validator(\"categoria\", mode='before')\n    def check_categoria(cls, v):\n        \"\"\"\n        Valida a categoria do produto durante a atualização.\n\n        Args:\n            v (Optional[str]): O valor da categoria a ser validado.\n\n        Returns:\n            Optional[str]: O valor da categoria validado ou None.\n\n        Raises:\n            ValueError: Se a categoria for inválida.\n        \"\"\"\n        if v is None:\n            return v\n        if v in [item.value for item in CategoriaBase]:\n            return v\n        raise ValueError(\"Categoria inválida\")"}
{"type": "source_file", "path": "app/backend/models/sales/sales.py", "content": "from sqlalchemy import Column, Integer, String, Float, DateTime\nfrom sqlalchemy.sql import func\nfrom database.database import Base\n\n\nclass SalesModel(Base):\n    \"\"\"\n    Modelo de dados para representar uma venda no banco de dados.\n\n    Atributos:\n        id (Integer): Identificador único da venda, chave primária.\n        email_employee (EmailStr): email do funcionario\n        email_customer (EmailStr): email do comprador\n        first_name (str): Primeiro nome do comprador\n        last_name (str): Ultimo nome do comprador   \n        phone_number (str): Número de telefone do comprador\n        price (Float): Valor total da venda.\n        quantity (Integer): Quantidade de itens vendidos.\n        name_product (String): Nome ou identificador do produto vendido.\n        date (datetime): Data e hora da venda.\n        created_at (DateTime): Data e hora de criação do registro da venda.\n    \"\"\"\n\n    __tablename__ = \"sales\"\n\n    id = Column(Integer, primary_key=True, autoincrement=True, index=True)\n    email_employee = Column(String, index=True)\n    email_customer = Column(String, index=True)\n    first_name = Column(String, index=True)\n    last_name = Column(String, index=True)\n    phone_number = Column(String, index=True)\n    price = Column(Float, index=True)\n    quantity = Column(Integer, index=True)\n    name_product = Column(String, index=True)\n    date = Column(DateTime(timezone=True), index=True)\n    created_at = Column(DateTime(timezone=True), default=func.now(), index=True)    "}
{"type": "source_file", "path": "app/backend/routes/sales/routes_sales.py", "content": "from fastapi import APIRouter, Depends, HTTPException\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom database.database import get_db\nfrom models.sales.sales_schema import SalesResponse, SalesUpdate, SalesCreate\nfrom typing import List\nfrom crud.sales.crud import (\n    create_sales,\n    get_sales,\n    get_sales_by_id,\n    delete_sales,\n    update_sales,\n)\n\nrouter = APIRouter()\n\n@router.post(\"/sales/\", response_model=SalesResponse)\nasync def create_sales_route(sales: SalesCreate, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Cria uma nova venda.\n\n    Parâmetros:\n    - sales (SalesCreate): Dados da venda a ser criada.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - ProductResponse: Dados do produto criado.\n    \"\"\"\n    return await create_sales(db=db, sales=sales)\n\n@router.get(\"/sales/\", response_model=List[SalesResponse])\nasync def read_all_sales_route(db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Retorna todas as vendas.\n\n    Parâmetros:\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - List[ProductResponse]: Lista de todos os produtos.\n    \"\"\"\n    sales = await get_sales(db)\n    return sales\n\n@router.get(\"/sales/{sales_id}\", response_model=SalesResponse)\nasync def read_sales_route(sales_id: int, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Retorna uma venda específica.\n\n    Parâmetros:\n    - sales_id (int): ID da venda a ser retornada.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - SalesResponse: Dados da venda solicitada.\n\n    Lança:\n    - HTTPException: Se a venda não for encontrada.\n    \"\"\"\n    db_sales = await get_sales_by_id(db, sales_id=sales_id)\n    if db_sales is None:\n        raise HTTPException(status_code=404, detail=\"Venda não encontrada\")\n    return db_sales\n\n@router.delete(\"/sales/{sales_id}\", response_model=SalesResponse)\nasync def delete_sales_route(sales_id: int, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Deleta uma venda específica.\n\n    Parâmetros:\n    - sales_id (int): ID da venda a ser deletada.\n    - db (Session): Sessão do banco de dados.\n\n    Retorna:\n    - SalesResponse: Dados da venda deletada.\n\n    Lança:\n    - HTTPException: Se a venda não for encontrada.\n    \"\"\"\n    db_sales = await delete_sales(db, sales_id=sales_id)\n    if db_sales is None:\n        raise HTTPException(status_code=404, detail=\"Venda não encontrada\")\n    return db_sales\n\n@router.put(\"/sales/{sales_id}\", response_model=SalesResponse)\nasync def update_sales_route(sales_id: int, sales: SalesUpdate, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Atualiza uma venda específica.\n\n    Parâmetros:\n    - sales_id (int): ID da venda a ser atualizada.\n    - sales (SalesUpdate): Dados atualizados da venda.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - SalesResponse: Dados da venda atualizada.\n\n    Lança:\n    - HTTPException: Se a venda não for encontrada.\n    \"\"\"\n    db_sales = await update_sales(db, sales_id=sales_id, sales=sales)\n    if db_sales is None:\n        raise HTTPException(status_code=404, detail=\"Venda não encontrada\")\n    return db_sales"}
{"type": "source_file", "path": "app/frontend/app.py", "content": "import streamlit as st\nst.set_page_config(\n            page_title=\"LiftOff\",\n            layout=\"wide\",\n            initial_sidebar_state=\"expanded\"\n)\n\nfrom streamlit_option_menu import option_menu\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nfrom utils import show_response_message\n\nfrom employee import create as create_employee, delete as delete_employee, read_all as read_all_employee, read_employee, update as update_employee\nfrom product import create as create_product, delete as delete_product, read_all as read_all_product, read_product, update as update_product\nfrom sales import create as create_sale, delete as delete_sale, read_all as read_all_sales, read_sale, update as update_sale\nfrom supplier import create as create_supplier, delete as delete_supplier, read_all as read_all_supplier, read_supplier, update as update_supplier\nfrom dashboard import dashboard\n\n\n\nclass Dashboard:\n    def __init__(self):\n        self.layout()\n\n    def layout(self):\n        st.markdown(\"\"\"\n        <style>\n        .big-font {\n            font-size:80px !important;\n        }\n        </style>\n        \"\"\", unsafe_allow_html=True)\n\n        #Options Menu\n        with st.sidebar:\n            selected = option_menu('LiftOff', [\"Home\", 'Funcionário', 'Fornecedor', 'Produto', 'Vendas', 'Dashboard', 'Sobre'], \n                icons=['house', 'person-badge', 'truck', 'box', 'graph-up', 'bar-chart', 'info-circle'], menu_icon='intersect', default_index=0,\n                styles={\n                        \"container\": {\"background-color\": \"#fafafa\"},\n                        \"nav-link\": {\"--hover-color\": \"#eee\"},\n                        \"nav-link-selected\": {\"background-color\": \"#0068C9\"},\n                    }\n                )\n            \n        # Menu Lateral\n        if selected==\"Home\":\n            self.home()\n        elif selected==\"Funcionário\":\n            self.employee() \n        elif selected==\"Fornecedor\":\n            self.supplier()     \n        elif selected==\"Produto\":\n            self.product()\n        elif selected==\"Vendas\":\n            self.sales()\n        elif selected=='Dashboard':\n            self.dashboard()\n        else:\n            self.about() \n\n    def home(self):\n        st.title('📊 LiftOff Data')\n        st.subheader('Arquitetura de Pipeline de Dados Inovadora para Startups 🚀')\n\n        st.divider()\n\n        col1, col2 = st.columns([3, 2])\n        with col1:\n            st.header('Bem-vindo ao LiftOff Data')\n            st.markdown(\n                \"\"\"\n                Transforme sua startup com nossa solução de pipeline de dados de última geração!\n\n                ### Nossa Missão\n                Capacitar startups com uma arquitetura de dados robusta, escalável e econômica, \n                permitindo que você se concentre no crescimento do seu negócio.\n\n                ### Principais Benefícios\n                - **Economia**: Solução de baixo custo ideal para startups\n                - **Eficiência**: Processamento e análise rápida de dados de vendas\n                - **Escalabilidade**: Cresce com seu negócio\n                - **Integração**: Conecta-se facilmente com APIs e CRMs existentes\n                - **Colaboração**: Facilita o trabalho entre engenheiros e analistas de dados\n\n                ### Nossa Tecnologia\n                - Pipeline em camadas: Bronze, Silver e Gold\n                - Airbyte para ingestão de dados flexível\n                - Airflow para orquestração poderosa\n                - DBT para transformações de dados confiáveis\n                - Plataforma 'Briefer' para análise colaborativa\n                \"\"\"\n            )\n        with col2:\n            st.image(\"https://www.scrapehero.com/wp/wp-content/uploads/2019/05/price-monitoring.gif\", use_container_width=True)\n            st.markdown(\"### 📈 Visualize seu Sucesso\")\n            st.metric(label=\"Aumento na Eficiência de Dados\", value=\"300%\", delta=\"50%\")\n            st.metric(label=\"Redução de Custos Operacionais\", value=\"40%\", delta=\"-15%\")\n            st.metric(label=\"Tempo de Insights\", value=\"5 min\", delta=\"-55 min\")\n\n        st.divider()\n        st.subheader(\"Pronto para decolar? 🚀\")\n        if st.button(\"Agende uma Demo\"):\n            st.success(\"Obrigado pelo seu interesse! Nossa equipe entrará em contato em breve.\")\n    \n    def product(self):\n        st.title(\"Gerenciamento de Produtos\")\n        \n        # Adicionar Produto\n        with st.expander(\"Adicionar um Novo Produto\"):\n            create_product()\n        # Visualizar Produtos\n        with st.expander(\"Visualizar Produtos\"):\n            read_all_product()\n\n        # Obter Detalhes de um Produto\n        with st.expander(\"Obter Detalhes de um Produto\"):\n            read_product()\n            \n        # Deletar Produto\n        with st.expander(\"Deletar Produto\"):\n            delete_product()\n\n        # Atualizar Produto\n        with st.expander(\"Atualizar Produto\"):\n            update_product()\n\n    def employee(self): \n        st.title(\"Gerenciamento de Funcionários\")\n        \n        # Criar funcionário\n        with st.expander(\"Adicionar Novo Funcionário\"):\n            create_employee()\n\n        # Visualizar Funcionários\n        with st.expander(\"Visualizar Funcionários\"):\n            read_all_employee()\n\n        # Obter Detalhes de um Funcionário\n        with st.expander(\"Obter Detalhes de um Funcionário\"):\n            read_employee()\n\n        # Deletar Funcionário\n        with st.expander(\"Deletar Funcionário\"):\n            delete_employee()\n        \n        # Atualizar Funcionário\n        with st.expander(\"Atualizar Funcionário\"):\n            update_employee()\n\n    def supplier(self):\n        st.title(\"Gerenciamento de Fornecedores\")\n\n        # Adicionar Fornecedor\n        with st.expander(\"Adicionar um Novo Fornecedor\"):\n            create_supplier()\n\n        # Visualizar Fornecedores\n        with st.expander(\"Visualizar Fornecedores\"):\n            read_all_supplier()\n\n        # Obter Detalhes de um Fornecedor\n        with st.expander(\"Obter Detalhes de um Fornecedor\"):\n            read_supplier()\n\n        # Deletar Fornecedor\n        with st.expander(\"Deletar Fornecedor\"):\n            delete_supplier()\n\n\n        # Atualizar Fornecedor\n        with st.expander(\"Atualizar Fornecedor\"):\n            update_supplier()\n\n    def dashboard(self):\n        dashboard()\n    \n    def sales(self):\n        st.title(\"Gerenciamento de Vendas\")\n        \n        # Adicionar Venda\n        with st.expander(\"Adicionar uma Nova Venda\"):\n            create_sale()\n\n        # Visualizar Vendas\n        with st.expander(\"Visualizar Vendas\"):\n            read_all_sales()\n\n        # Obter Detalhes de uma Venda\n        with st.expander(\"Obter Detalhes de uma Venda\"):\n            read_sale()\n\n        # Deletar Venda\n        with st.expander(\"Deletar Venda\"):\n            delete_sale()\n\n        # Atualizar Venda\n        with st.expander(\"Atualizar Venda\"):\n            update_sale()\n    \n    def about(self):\n        st.title('Sobre o Projeto LiftOff Data')\n        \n        st.header('Arquitetura do Projeto')\n        st.markdown(\"\"\"\n        Este projeto apresenta uma arquitetura de pipeline de dados inovadora e de baixo custo, projetada especificamente para startups. Nosso foco é na integração eficiente de dados de vendas provenientes de diversas fontes, como APIs e CRMs.\n\n        ### Principais Características:\n        - **Escalabilidade:** Solução adaptável ao crescimento da sua startup\n        - **Eficiência:** Otimizada para ingestão, transformação e visualização de dados\n        - **Colaboração:** Facilita o trabalho conjunto entre engenheiros e analistas de dados\n\n        ### Componentes Chave:\n        1. Pipeline em camadas: Bronze, Silver e Gold\n        2. Integração com APIs\n        3. Airbyte para ingestão de dados\n        4. Airflow para orquestração de tarefas\n        5. DBT para transformação de dados\n        6. Plataforma 'Briefer' para acesso e utilização dos dados transformados\n        \"\"\")\n\n        st.image(\"https://raw.githubusercontent.com/tsffarias/LiftOff_Data/refs/heads/main/img/arquitetura_1.6.png\", use_container_width=True, caption=\"Arquitetura do Pipeline de Dados\")\n\n        st.divider()\n\n        st.header('Sobre o Criador')\n        col1, col2 = st.columns([2, 1])\n        with col1:\n            st.markdown(\"\"\"\n            ### Thiago Silva Farias\n            - 🎓 **Formação:** Sistemas de Informação - UFMS\n            - 💼 **Experiência:** Engenheiro de Dados\n            - 🔗 **LinkedIn:** [Perfil Profissional](https://www.linkedin.com/in/thiagosilvafarias/)\n            - 📁 **GitHub:** [Repositório do Projeto](https://github.com/tsffarias/LiftOff_Data/tree/main)\n\n            Obrigado por visitar o projeto LiftOff Data! Estou sempre aberto para discussões sobre engenharia de dados, arquiteturas de pipeline e tecnologias inovadoras. Não hesite em entrar em contato para trocar ideias ou colaborar em projetos futuros.\n            \"\"\")\n\n        with col2:\n            st.image(\"https://www.scrapehero.com/wp/wp-content/uploads/2019/05/api-gif.gif\", use_container_width=True, caption=\"Integração de Dados em Ação\")\n\nif __name__ == \"__main__\":\n    Dashboard()"}
{"type": "source_file", "path": "app/backend/models/supplier/supplier.py", "content": "\nfrom sqlalchemy import Column, Integer, String, DateTime, ARRAY\nfrom sqlalchemy.sql import func\nfrom database.database import Base\n\nclass SupplierModel(Base):\n    \"\"\"\n    Modelo de dados para representar um fornecedor no banco de dados.\n\n    Atributos:\n        supplier_id (Integer): Identificador único do fornecedor, chave primária.\n        company_name (String): Nome da empresa fornecedora.\n        contact_name (String): Nome do contato principal.\n        email (String): Endereço de email.\n        phone_number (String): Número de telefone.\n        website (String): Website da empresa.\n        address (String): Endereço completo.\n        product_categories (String): Lista de categorias de produtos ou serviços fornecidos.\n        primary_product (String): Produto ou serviço principal.\n        created_at (DateTime): Data e hora de criação do registro do fornecedor.\n    \"\"\"\n\n    __tablename__ = \"suppliers\"\n\n    supplier_id = Column(Integer, primary_key=True, autoincrement=True, index=True)\n    company_name = Column(String, index=True, nullable=False)\n    contact_name = Column(String, nullable=False)\n    email = Column(String, index=True, nullable=False)\n    phone_number = Column(String, nullable=False)\n    website = Column(String)\n    address = Column(String)\n    product_categories = Column(String, index=True)    \n    primary_product = Column(String, nullable=False)\n    created_at = Column(DateTime(timezone=True), default=func.now(), index=True)\n"}
{"type": "source_file", "path": "app/backend/routes/product/routes_product.py", "content": "from fastapi import APIRouter, Depends, HTTPException\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom database.database import get_db\nfrom models.product.product_schema import ProductResponse, ProductUpdate, ProductCreate\nfrom typing import List\nfrom crud.product.crud import (\n    create_product,\n    get_products,\n    get_product,\n    delete_product,\n    update_product,\n)\n\nrouter = APIRouter()\n\n@router.post(\"/products/\", response_model=ProductResponse)\nasync def create_product_route(product: ProductCreate, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Cria um novo produto.\n\n    Parâmetros:\n    - product (ProductCreate): Dados do produto a ser criado.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - ProductResponse: Dados do produto criado.\n    \"\"\"\n    return await create_product(db=db, product=product)\n\n@router.get(\"/products/\", response_model=List[ProductResponse])\nasync def read_all_products_route(db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Retorna todos os produtos.\n\n    Parâmetros:\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - List[ProductResponse]: Lista de todos os produtos.\n    \"\"\"\n    products = await get_products(db)\n    return products\n\n@router.get(\"/products/{product_id}\", response_model=ProductResponse)\nasync def read_product_route(product_id: int, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Retorna um produto específico.\n\n    Parâmetros:\n    - product_id (int): ID do produto a ser retornado.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - ProductResponse: Dados do produto solicitado.\n\n    Lança:\n    - HTTPException: Se o produto não for encontrado.\n    \"\"\"\n    db_product = await get_product(db, product_id=product_id)\n    if db_product is None:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return db_product\n\n@router.delete(\"/products/{product_id}\", response_model=ProductResponse)\nasync def delete_product_route(product_id: int, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Deleta um produto específico.\n\n    Parâmetros:\n    - product_id (int): ID do produto a ser deletado.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - ProductResponse: Dados do produto deletado.\n\n    Lança:\n    - HTTPException: Se o produto não for encontrado.\n    \"\"\"\n    db_product = await delete_product(db, product_id=product_id)\n    if db_product is None:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return db_product\n\n\n@router.put(\"/products/{product_id}\", response_model=ProductResponse)\nasync def update_product_route(product_id: int, product: ProductUpdate, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Atualiza um produto específico.\n\n    Parâmetros:\n    - product_id (int): ID do produto a ser atualizado.\n    - product (ProductUpdate): Dados atualizados do produto.\n    - db (Session): Sessão do banco de dados.\n\n    Retorna:\n    - ProductResponse: Dados do produto atualizado.\n\n    Lança:\n    - HTTPException: Se o produto não for encontrado.\n    \"\"\"\n    db_product = await update_product(db, product_id=product_id, product=product)\n    if db_product is None:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return db_product"}
{"type": "source_file", "path": "app/frontend/AI/extract_data_json.py", "content": "import os\nimport json\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy import text\nfrom dotenv import load_dotenv\nfrom datetime import datetime, date\nfrom decimal import Decimal\n\n# Load environment variables\nload_dotenv()\n\n# Obter as variáveis do arquivo .env\nDB_PORT = os.getenv('DB_PORT_PROD') or '5432'\nDB_NAME = os.getenv('DB_NAME_PROD')\nDB_USER = os.getenv('DB_USER_PROD')\nDB_PASS = os.getenv('DB_PASS_PROD')\nDB_HOST = os.getenv('DB_HOST_PROD')\n\n# Criar a URL de conexão do banco de dados\nSQLALCHEMY_DATABASE_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@postgres:{DB_PORT}/{DB_NAME}\"\n\n# Cria o motor do banco de dados e a sessão\nengine = create_engine(SQLALCHEMY_DATABASE_URL)\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n# Custom serializer for non-serializable types\ndef custom_serializer(obj):\n    if isinstance(obj, (datetime, date)):\n        return obj.isoformat()\n    elif isinstance(obj, Decimal):\n        return float(obj)\n    raise TypeError(f\"Tipo {type(obj)} não é serializável\")\n\n# Function to load data from a table and return as a dictionary list\ndef carregar_dados(tabela):\n    session = SessionLocal()\n    try:\n        query = text(f\"SELECT * FROM {tabela};\")\n        result = session.execute(query)\n        colunas = result.keys()\n        dados = [dict(zip(colunas, row)) for row in result.fetchall()]\n    finally:\n        session.close()\n    return dados\n\n# Function to save data into a JSON file\ndef salvar_em_json(dados, file_path):\n    with open(file_path, 'w') as file:\n        json.dump(dados, file, indent=4, default=custom_serializer)\n\n# Main execution: read data and save into JSON files\nif __name__ == \"__main__\":\n    dados_vendas_por_vendedor = carregar_dados(\"gold_sales_by_seller\")\n    salvar_em_json(dados_vendas_por_vendedor, \"gold_sales_by_seller.json\")\n    \n    dados_gold_vendas_por_produto = carregar_dados(\"gold_sales_7_days\")\n    salvar_em_json(dados_gold_vendas_por_produto, \"gold_sales_7_days.json\")\n    \n    print(\"Dados salvos em 'gold_sales_by_seller.json' e 'gold_sales_7_days.json'.\")\n"}
{"type": "source_file", "path": "app/backend/routes/supplier/routes_supplier.py", "content": "from fastapi import APIRouter, Depends, HTTPException\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom database.database import get_db\nfrom models.supplier.supplier_schema import SupplierResponse, SupplierUpdate, SupplierCreate\nfrom typing import List\nfrom crud.supplier.crud import (\n    create_supplier,\n    get_suppliers,\n    get_supplier,\n    delete_supplier,\n    update_supplier,\n)\n\nrouter = APIRouter()\n\n@router.post(\"/suppliers/\", response_model=SupplierResponse)\nasync def create_supplier_route(supplier: SupplierCreate, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Cria um novo fornecedor.\n\n    Parâmetros:\n    - supplier (SupplierCreate): Dados do fornecedor a ser criado.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - SupplierResponse: Dados do fornecedor criado.\n    \"\"\"\n    return await create_supplier(db=db, supplier=supplier)\n\n@router.get(\"/suppliers/\", response_model=List[SupplierResponse])\nasync def read_all_suppliers_route(db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Retorna todos os fornecedores.\n\n    Parâmetros:\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - List[SupplierResponse]: Lista de todos os fornecedores.\n    \"\"\"\n    suppliers = await get_suppliers(db)\n    return suppliers\n\n@router.get(\"/suppliers/{supplier_id}\", response_model=SupplierResponse)\nasync def read_supplier_route(supplier_id: int, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Retorna um fornecedor específico.\n\n    Parâmetros:\n    - supplier_id (int): ID do fornecedor a ser retornado.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - SupplierResponse: Dados do fornecedor solicitado.\n\n    Lança:\n    - HTTPException: Se o fornecedor não for encontrado.\n    \"\"\"\n    db_supplier = await get_supplier(db, supplier_id=supplier_id)\n    if db_supplier is None:\n        raise HTTPException(status_code=404, detail=\"Supplier not found\")\n    return db_supplier\n\n@router.delete(\"/suppliers/{supplier_id}\", response_model=SupplierResponse)\nasync def delete_supplier_route(supplier_id: int, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Deleta um fornecedor específico.\n\n    Parâmetros:\n    - supplier_id (int): ID do fornecedor a ser deletado.\n    - db (Session): Sessão do banco de dados.\n\n    Retorna:\n    - SupplierResponse: Dados do fornecedor deletado.\n\n    Lança:\n    - HTTPException: Se o fornecedor não for encontrado.\n    \"\"\"\n    db_supplier = await delete_supplier(db, supplier_id=supplier_id)\n    if db_supplier is None:\n        raise HTTPException(status_code=404, detail=\"Supplier not found\")\n    return db_supplier\n\n@router.put(\"/suppliers/{supplier_id}\", response_model=SupplierResponse)\nasync def update_supplier_route(supplier_id: int, supplier: SupplierUpdate, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Atualiza um fornecedor específico.\n\n    Parâmetros:\n    - supplier_id (int): ID do fornecedor a ser atualizado.\n    - supplier (SupplierUpdate): Dados atualizados do fornecedor.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - SupplierResponse: Dados do fornecedor atualizado.\n\n    Lança:\n    - HTTPException: Se o fornecedor não for encontrado.\n    \"\"\"\n    db_supplier = await update_supplier(db, supplier_id=supplier_id, supplier=supplier)\n    if db_supplier is None:\n        raise HTTPException(status_code=404, detail=\"Supplier not found\")\n    return db_supplier\n\n\n"}
{"type": "source_file", "path": "app/backend/routes/employee/routes_employee.py", "content": "from fastapi import APIRouter, Depends, HTTPException\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom database.database import get_db\nfrom models.employee.employee_schema import EmployeeResponse, EmployeeUpdate, EmployeeCreate\nfrom typing import List\nfrom crud.employee.crud import (\n    create_employee,\n    get_employees,\n    get_employee,\n    delete_employee,\n    update_employee,\n)\n\nrouter = APIRouter()\n\n@router.post(\"/employees/\", response_model=EmployeeResponse)\nasync def create_employee_route(employee: EmployeeCreate, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Cria um novo funcionário.\n\n    Parâmetros:\n    - employee (EmployeeCreate): Dados do funcionário a ser criado.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - EmployeeResponse: Dados do funcionário criado.\n\n    Lança:\n    - HTTPException: Se houver um problema ao criar o funcionário.\n    \"\"\"\n    try:\n        return await create_employee(db=db, employee=employee)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Erro ao criar funcionário: {str(e)}\")\n\n\n@router.get(\"/employees/\", response_model=List[EmployeeResponse])\nasync def read_all_employees_route(db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Retorna todos os funcionários.\n\n    Parâmetros:\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - List[EmployeeResponse]: Lista de todos os funcionários.\n\n    Lança:\n    - HTTPException: Se não houver funcionários no banco de dados.\n    \"\"\"\n    employees = await get_employees(db)\n    if not employees:\n        raise HTTPException(status_code=404, detail=\"Não há dados no banco de dados\")\n    return employees\n\n@router.get(\"/employees/{employee_id}\", response_model=EmployeeResponse)\nasync def read_employee_route(employee_id: int, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Retorna um funcionário específico.\n\n    Parâmetros:\n    - employee_id (int): ID do funcionário a ser retornado.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - EmployeeResponse: Dados do funcionário solicitado.\n\n    Lança:\n    - HTTPException: Se o funcionário não for encontrado.\n    \"\"\"\n    db_employee = await get_employee(db, employee_id=employee_id)\n    if db_employee is None:\n        raise HTTPException(status_code=404, detail=\"Funcionário não encontrado\")\n    return db_employee\n\n@router.delete(\"/employees/{employee_id}\", response_model=EmployeeResponse)\nasync def delete_employee_route(employee_id: int, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Deleta um funcionário específico.\n\n    Parâmetros:\n    - employee_id (int): ID do funcionário a ser deletado.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - EmployeeResponse: Dados do funcionário deletado.\n\n    Lança:\n    - HTTPException: Se o funcionário não for encontrado.\n    \"\"\"\n    db_employee = await delete_employee(db, employee_id=employee_id)\n    if db_employee is None:\n        raise HTTPException(status_code=404, detail=\"Funcionário não encontrado\")\n    return db_employee\n\n@router.put(\"/employees/{employee_id}\", response_model=EmployeeResponse)\nasync def update_employee_route(\n    employee_id: int, employee: EmployeeUpdate, db: AsyncSession = Depends(get_db)):\n    \"\"\"\n    Atualiza um funcionário específico.\n\n    Parâmetros:\n    - employee_id (int): ID do funcionário a ser atualizado.\n    - employee (EmployeeUpdate): Dados atualizados do funcionário.\n    - db (AsyncSession): Sessão do banco de dados.\n\n    Retorna:\n    - EmployeeResponse: Dados do funcionário atualizado.\n\n    Lança:\n    - HTTPException: Se o funcionário não for encontrado.\n    \"\"\"\n    db_employee = await update_employee(db, employee_id=employee_id, employee=employee)\n    if db_employee is None:\n        raise HTTPException(status_code=404, detail=\"Funcionário não encontrado\")\n    return db_employee\n"}
{"type": "source_file", "path": "app/frontend/dashboard/__init__.py", "content": "from .dashboard import dashboard"}
{"type": "source_file", "path": "app/frontend/product/create.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\n\nfrom utils import show_response_message\n\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef create():\n    # Buscar a lista de fornecedores\n    response_suppliers = requests.get(f\"{os.getenv('BACKEND_URL')}/suppliers/\")\n    if response_suppliers.status_code == 200:\n        suppliers = response_suppliers.json()\n        # Extrair os emails dos fornecedores\n        supplier_emails = [supplier['email'] for supplier in suppliers]\n        # Inserir \"Selecione o Email do Fornecedor\" no início da lista\n        supplier_emails.insert(0, \"Selecione o Email do Fornecedor\")\n    else:\n        show_response_message(response_suppliers)\n        supplier_emails = [\"Selecione o Email do Fornecedor\"]\n\n    with st.form(\"new_product\"):\n        name = st.text_input(\"Nome do Produto\")\n        description = st.text_area(\"Descrição do Produto\")\n        price = st.number_input(\"Preço\", min_value=0.01, format=\"%f\")\n        categoria = st.selectbox(\n            \"Categoria\",\n            [\"Eletrônico\", \"Eletrodoméstico\", \"Móveis\", \"Roupas\", \"Calçados\"],\n        )\n        email_fornecedor = st.selectbox(\"Email do Fornecedor\", options=supplier_emails)\n        submit_button = st.form_submit_button(\"Adicionar Produto\")\n\n        if submit_button:\n            # Verificação antes de enviar o formulário\n            if email_fornecedor == \"Selecione o Email do Fornecedor\":\n                st.warning(\"Por favor, selecione um email válido do fornecedor.\")\n            else:\n                response = requests.post(\n                    f\"{os.getenv('BACKEND_URL')}/products/\",\n                    json={\n                        \"name\": name,\n                        \"description\": description,\n                        \"price\": price,\n                        \"categoria\": categoria,\n                        \"email_fornecedor\": email_fornecedor,\n                    },\n                )\n                show_response_message(response)"}
{"type": "source_file", "path": "app/frontend/AI/create_assistent_exemplo.py", "content": "import openai\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\nimport os\n\n# Carrega as variáveis de ambiente\nload_dotenv()\n\n# Configuração da API\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# Função para criar o assistente com File Search habilitado\ndef create_assistant_with_file_search():\n    assistant = client.beta.assistants.create(\n        name=\"Assistente Especializado em Vendas\",\n        instructions=\"Você é um especialista em análise e insights para equipes de vendas, com foco em maximizar o desempenho de vendas, otimizar estoques e melhorar o relacionamento com fornecedores. Sua expertise abrange a análise de dados de produtos, desempenho de vendedores, produtividade dos funcionários, e gestão de fornecedores. Sempre que receber uma solicitação, responda com um resumo conciso, seguido de insights detalhados e recomendações práticas. Sua linguagem deve ser profissional, direta, e prática. Use gráficos e visualizações sempre que possível para simplificar a compreensão dos dados.\",\n        model=\"gpt-4o\",\n        tools=[{\"type\": \"file_search\"}],  # Habilitando o file_search\n    )\n    print(f\"Assistente criado com ID: {assistant}\")\n    return assistant\n\n# Criar um Vector Store para armazenar arquivos\ndef create_vector_store():\n    vector_store = client.beta.vector_stores.create(name=\"Vendas Data Store\")\n    print(f\"Vector Store criado com ID: {vector_store.id}\")\n    return vector_store\n\n# Carregar os arquivos JSON no Vector Store e aguardar o processamento\ndef upload_files_to_vector_store(vector_store, file_paths):\n    file_streams = []\n    for file_path in file_paths:\n        try:\n            with open(file_path, \"rb\") as file:\n                file_streams.append(file)\n            print(f\"Arquivo {file_path} preparado para upload.\")\n        except FileNotFoundError:\n            print(f\"Arquivo {file_path} não encontrado.\")\n\n    if file_streams:\n        file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n            vector_store_id=vector_store.id, files=file_streams\n        )\n        print(f\"Status do upload: {file_batch.status}\")\n        print(f\"Contagem de arquivos: {file_batch.file_counts}\")\n    else:\n        print(\"Nenhum arquivo foi preparado para upload.\")\n\n# Atualizar o assistente para usar o Vector Store\ndef update_assistant_with_vector_store(assistant, vector_store):\n    client.beta.assistants.update(\n        assistant_id=assistant.id,\n        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n    )\n    print(\"Assistente atualizado para usar o Vector Store.\")\n\n# Criar o assistente com file_search habilitado\nassistant = create_assistant_with_file_search()\n\n# Criar um Vector Store e fazer o upload dos arquivos JSON\nvector_store = create_vector_store()\nupload_files_to_vector_store(vector_store, [\"gold_sales_7_days.json\", \"gold_sales_by_seller.json\"])\n\n# Atualizar o assistente com o Vector Store criado\nupdate_assistant_with_vector_store(assistant, vector_store)\n"}
{"type": "source_file", "path": "app/frontend/product/__init__.py", "content": "from .create import create\nfrom .delete import delete\nfrom .read_all import read_all\nfrom .read_product import read_product\nfrom .update import update"}
{"type": "source_file", "path": "app/frontend/dashboard/dashboard.py", "content": "import streamlit as st\nimport requests\nimport duckdb\nimport os\nimport pandas as pd\nfrom dotenv import load_dotenv\nfrom concurrent.futures import ThreadPoolExecutor\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom datetime import datetime\n\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\n# Função para exibir uma mensagem em caso de erro\ndef show_response_message(response):\n    st.error(f\"Erro {response.status_code}: {response.json().get('detail', 'Erro desconhecido')}\")\n\n# Função para fazer requisições assíncronas e retornar dados JSON\ndef fetch_data(api_url):\n    response = requests.get(api_url)\n    if response.status_code == 200:\n        return response.json()\n    else:\n        show_response_message(response)\n        return None\n\n# Função para registrar e exibir dados JSON diretamente no DuckDB\ndef show_table_from_data(data, table_name):\n    if data:\n        df_data = pd.DataFrame(data)\n        if not df_data.empty:\n            conn.register(table_name, df_data)\n            result = conn.execute(f\"SELECT * FROM {table_name}\").fetchdf()\n            st.dataframe(result, hide_index=True)\n        else:\n            st.warning(f\"A tabela '{table_name}' está vazia.\")\n    else:\n        st.warning(f\"Sem dados disponíveis para '{table_name}'.\")\n\n# Função para exibir métricas\ndef display_metrics(sales_df, employee_df):\n    # Verifica se a coluna 'produto' está presente\n    if 'name_product' in sales_df.columns:\n        num_produtos = sales_df['name_product'].nunique()\n    else:\n        num_produtos = 0\n        st.warning(\"⚠️ Coluna 'name_product' ausente no DataFrame de vendas.\")\n\n    # Verifica se a coluna 'valor' está presente\n    if 'price' in sales_df.columns:\n        receita_total = sales_df['price'].sum()\n    else:\n        receita_total = 0.0\n        st.warning(\"⚠️ Coluna 'price' ausente no DataFrame de vendas.\")\n\n    # Verifica se a coluna 'id' está presente\n    if 'id' in sales_df.columns:\n        num_vendas = sales_df['id'].nunique()\n    else:\n        num_vendas = 0\n        st.warning(\"⚠️ Coluna 'id' ausente no DataFrame de vendas.\")\n\n    # Verifica se a coluna 'quantidade' está presente\n    if 'quantity' in sales_df.columns:\n        total_itens = sales_df['quantity'].sum()\n    else:\n        total_itens = 0\n        st.warning(\"⚠️ Coluna 'quantidade' ausente no DataFrame de vendas.\")\n\n    # Verifica se a coluna 'employee_id' está presente no employee_df\n    if 'employee_id' in employee_df.columns:\n        num_funcionarios = employee_df['employee_id'].nunique()\n    else:\n        num_funcionarios = 0\n        st.warning(\"⚠️ Coluna 'employee_id' ausente no DataFrame de funcionários.\")\n\n    # CSS para criar estilo de \"card\"\n    st.markdown(\"\"\"\n        <style>\n        .metric-container {\n            border: 1px solid #ddd;\n            padding: 20px;\n            border-radius: 10px;\n            background-color: #f9f9f9;\n            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\n            text-align: center;\n            margin-bottom: 20px;\n        }\n        .metric-container h4 {\n            margin-bottom: 5px;\n            font-weight: bold;\n        }\n        .metric-value {\n            font-size: 1.5em;\n            font-weight: bold;\n        }\n        </style>\n    \"\"\", unsafe_allow_html=True)\n\n    # Dividindo os KPIs em colunas\n    col1, col2, col3, col4, col5 = st.columns(5)\n    \n    with col1:\n        with st.container():\n            st.markdown(\"<div class='metric-container'><h4>📦 Produtos</h4><div class='metric-value'>{}</div></div>\".format(num_produtos), unsafe_allow_html=True)\n\n    with col2:\n        with st.container():\n            st.markdown(\"<div class='metric-container'><h4>💰 Receita</h4><div class='metric-value'>R$ {:,.2f}</div></div>\".format(receita_total), unsafe_allow_html=True)\n\n    with col3:\n        with st.container():\n            st.markdown(\"<div class='metric-container'><h4>📈 Vendas</h4><div class='metric-value'>{}</div></div>\".format(num_vendas), unsafe_allow_html=True)\n\n    with col4:\n        with st.container():\n            st.markdown(\"<div class='metric-container'><h4>📊 Itens Vendidos</h4><div class='metric-value'>{}</div></div>\".format(total_itens), unsafe_allow_html=True)\n\n    with col5:\n        with st.container():\n            st.markdown(\"<div class='metric-container'><h4>👥 Funcionários</h4><div class='metric-value'>{}</div></div>\".format(num_funcionarios), unsafe_allow_html=True)\n\n\n# Função para gerar e exibir gráficos\ndef display_charts(sales_df, employee_df):\n    if 'birth_date' in employee_df.columns:\n        employee_df['birth_date'] = pd.to_datetime(employee_df['birth_date'], errors='coerce')\n\n    if 'hire_date' in employee_df.columns:\n        # Garantir que 'hire_date' esteja no formato datetime\n        employee_df['hire_date'] = pd.to_datetime(employee_df['hire_date'], errors='coerce')\n        # Remover fuso horário se existir\n        employee_df['hire_date'] = employee_df['hire_date'].dt.tz_localize(None)\n\n    # Gráfico de Vendas por Data\n    if 'date' in sales_df.columns:\n        sales_by_date = sales_df.groupby(sales_df['date'].dt.date)['price'].sum().reset_index()\n        # Transformar em gráfico de área\n        fig_sales_date = px.area(sales_by_date, x='date', y='price')\n        # Calcular a média\n        media_vendas = sales_by_date['price'].mean()\n        # Adicionar linha de média vermelha\n        fig_sales_date.add_hline(y=media_vendas, line_dash=\"dash\", line_color=\"red\",\n                                 annotation_text=f\"Média: R$ {media_vendas:,.2f}\", \n                                 annotation_position=\"top left\")\n        st.subheader(\"Vendas ao Longo do Tempo\")\n        st.write(\"Este gráfico mostra a evolução das vendas ao longo do tempo, permitindo identificar tendências e sazonalidades.\")\n        st.plotly_chart(fig_sales_date)\n    else:\n        st.warning(\"A coluna 'date' não está presente nos dados de vendas.\")\n\n    # Gráfico de Vendas por Produto\n    sales_by_product = sales_df.groupby('name_product')['price'].sum().reset_index()\n    fig_sales_product = px.bar(sales_by_product, x='name_product', y='price')\n    st.subheader(\"Vendas por Produto\")\n    st.write(\"Este gráfico apresenta o total de vendas por produto, destacando quais produtos geraram mais receita.\")\n    st.plotly_chart(fig_sales_product)\n\n    # Top 10 Melhores Vendedores\n    top_vendedores = sales_df.groupby('email_employee')['price'].sum().nlargest(10).reset_index()\n    fig_top_vendedores = px.bar(top_vendedores, x='email_employee', y='price')\n    st.subheader(\"Top 10 Melhores Vendedores\")\n    st.write(\"Este gráfico mostra os 10 vendedores com maior volume de vendas, reconhecendo a performance individual.\")\n    st.plotly_chart(fig_top_vendedores)\n\n    # Card divisório para separar as seções\n    st.markdown(\"\"\"\n        <div style=\"\n            border: 1px solid #ddd;\n            padding: 20px;\n            margin-top: 40px;\n            margin-bottom: 20px;\n            border-radius: 10px;\n            background-color: #f1f3f4;\n            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);\n            text-align: center;\n        \">\n            <h2 style=\"margin: 0; font-size: 1.5em;\">👥 Seção de Funcionários</h2>\n            <p style=\"margin: 10px 0 0; color: #555;\">Análise dos dados de funcionários</p>\n        </div>\n    \"\"\", unsafe_allow_html=True)\n\n    # Conversão de colunas de data para datetime no employee_df\n    if 'hire_date' in employee_df.columns:\n        employee_df['hire_date'] = pd.to_datetime(employee_df['hire_date'], errors='coerce')\n        # Remover fuso horário se existir\n        employee_df['hire_date'] = employee_df['hire_date'].dt.tz_localize(None)\n\n        min_date_hire = employee_df['hire_date'].min().to_pydatetime()\n        max_date_hire = employee_df['hire_date'].max().to_pydatetime()\n\n        # Seletor de intervalo de datas para funcionários usando slider\n        st.header(\"Filtro de Data para Funcionários\")\n        date_range_hire = st.slider(\n            \"Selecione o intervalo de datas para funcionários (data de contratação):\",\n            min_value=min_date_hire,\n            max_value=max_date_hire,\n            value=(min_date_hire, max_date_hire),\n            format=\"DD/MM/YYYY\",\n            key='hire_date_range'\n        )\n\n        # Filtrar o DataFrame de funcionários com base no intervalo selecionado\n        if date_range_hire:\n            start_datetime_hire, end_datetime_hire = date_range_hire\n            employee_df = employee_df[(employee_df['hire_date'] >= start_datetime_hire) & (employee_df['hire_date'] <= end_datetime_hire)]\n    else:\n        st.warning(\"A coluna 'hire_date' não está presente nos dados de funcionários.\")\n    \n    # Gráfico de Folha Salarial Mensal\n    if 'hire_date' in employee_df.columns:\n        # Cálculo da folha salarial mensal considerando todos os funcionários\n        employee_df['hire_date'] = pd.to_datetime(employee_df['hire_date'], errors='coerce')\n        employee_df['termination_date'] = pd.to_datetime(employee_df['termination_date'], errors='coerce')\n        # Remover fuso horário se existir\n        employee_df['hire_date'] = employee_df['hire_date'].dt.tz_localize(None)\n        employee_df['termination_date'] = employee_df['termination_date'].dt.tz_localize(None)\n        \n        # Remover registros com 'hire_date' nulo\n        employee_df = employee_df[employee_df['hire_date'].notnull()]\n        \n        # Remover duplicatas\n        employee_df = employee_df.drop_duplicates(subset='employee_id')\n        \n        # Converter 'salary' para numérico\n        employee_df['salary'] = pd.to_numeric(employee_df['salary'], errors='coerce')\n        \n        # Remover registros com 'salary' nulo ou negativo\n        employee_df = employee_df[employee_df['salary'] > 0]\n        \n        # Criar DataFrame auxiliar para armazenar os resultados\n        folha_mensal_df = pd.DataFrame()\n        \n        # Gerar o intervalo de meses desde a primeira contratação até o mês atual\n        start_month = employee_df['hire_date'].min().to_period('M')\n        end_month = pd.Timestamp.today().to_period('M')\n        \n        # Gerar todos os meses no intervalo\n        all_months = pd.period_range(start=start_month, end=end_month, freq='M')\n        \n        # Lista para armazenar os resultados\n        folha_mensal = []\n        \n        for month in all_months:\n            # Definir o início e fim do mês\n            start_of_month = month.to_timestamp()\n            end_of_month = month.to_timestamp(how='end')\n            \n            # Filtrar funcionários ativos no mês\n            active_employees = employee_df[\n                (employee_df['hire_date'] <= end_of_month) &\n                ((employee_df['termination_date'].isna()) | (employee_df['termination_date'] >= start_of_month))\n            ]\n            \n            # Somar os salários mensais dos funcionários ativos\n            total_salary = active_employees['salary'].sum()\n            folha_mensal.append({'mes': str(month), 'salary': total_salary})\n        \n        folha_mensal_df = pd.DataFrame(folha_mensal)\n        \n        # Converter 'mes' para datetime para ordenar corretamente\n        folha_mensal_df['mes'] = pd.to_datetime(folha_mensal_df['mes'])\n        \n        # Ordenar por mês\n        folha_mensal_df = folha_mensal_df.sort_values('mes')\n        \n        # Criar o gráfico\n        fig_folha_mensal = px.bar(folha_mensal_df, x='mes', y='salary')\n        # Calcular a média\n        media_folha = folha_mensal_df['salary'].mean()\n        # Adicionar linha de média vermelha\n        fig_folha_mensal.add_hline(y=media_folha, line_dash=\"dash\", line_color=\"red\",\n                                   annotation_text=f\"Média: R$ {media_folha:,.2f}\",\n                                   annotation_position=\"top left\")\n        st.subheader(\"Folha Salarial Mensal\")\n        st.write(\"Este gráfico apresenta o total mensal da folha salarial, indicando os custos com pessoal ao longo do tempo.\")\n        st.plotly_chart(fig_folha_mensal)\n    else:\n        st.warning(\"A coluna 'hire_date' não está presente nos dados de funcionários.\")\n\n    # Gráfico de Percentual de Funcionários por Gênero\n    genero_percent = employee_df['gender'].value_counts(normalize=True) * 100\n    fig_genero = px.pie(values=genero_percent, names=genero_percent.index)\n    st.subheader(\"Percentual de Funcionários por Gênero\")\n    st.write(\"Este gráfico ilustra a distribuição percentual de funcionários por gênero na empresa.\")\n    st.plotly_chart(fig_genero)\n\n    # Média Salarial por Cargo\n    salario_por_cargo = employee_df.groupby('job_title')['salary'].mean().reset_index()\n    fig_salario_cargo = px.bar(salario_por_cargo, x='job_title', y='salary')\n    st.subheader(\"Média Salarial por Cargo\")\n    st.write(\"Este gráfico mostra a média salarial para cada cargo, permitindo comparar remunerações entre posições.\")\n    st.plotly_chart(fig_salario_cargo)\n\n    # Gráfico de Contratações por Mês\n    if 'hire_date' in employee_df.columns:\n        employee_df['hire_mes'] = employee_df['hire_date'].dt.to_period('M').astype(str)\n        contratacoes_mes = employee_df.groupby('hire_mes')['employee_id'].count().reset_index()\n\n        # Converter 'hire_mes' para datetime para ordenar corretamente\n        contratacoes_mes['hire_mes'] = pd.to_datetime(contratacoes_mes['hire_mes'])\n\n        # Transformar em gráfico de área\n        fig_contratacoes = px.area(contratacoes_mes, x='hire_mes', y='employee_id')\n        # Calcular a média\n        media_contratacoes = contratacoes_mes['employee_id'].mean()\n        # Adicionar linha de média vermelha\n        fig_contratacoes.add_hline(y=media_contratacoes, line_dash=\"dash\", line_color=\"red\",\n                                   annotation_text=f\"Média: {media_contratacoes:.2f}\",\n                                   annotation_position=\"top left\")\n        st.subheader(\"Contratações por Mês\")\n        st.write(\"Este gráfico mostra o número de funcionários contratados a cada mês, indicando o ritmo de crescimento da equipe.\")\n        st.plotly_chart(fig_contratacoes)\n    else:\n        st.warning(\"A coluna 'hire_date' não está presente nos dados de funcionários\")\n\n    # Tabela com aniversariantes do mês atual\n    if 'birth_date' in employee_df.columns:\n        current_month = pd.to_datetime(\"today\").month\n        aniversariantes = employee_df[employee_df['birth_date'].dt.month == current_month]\n        st.header(\"Aniversariantes do Mês\")\n        st.write(\"Esta tabela lista os funcionários que fazem aniversário no mês atual.\")\n        st.dataframe(aniversariantes[['first_name', 'last_name', 'email', 'birth_date']], use_container_width=True)\n    else:\n        st.warning(\"A coluna 'birth_date' não está presente nos dados de funcionários.\")\n\n\n# Função principal do dashboard\ndef dashboard():\n    st.title(\"Dashboard LiftOff\")\n\n    # Configuração inicial da conexão DuckDB\n    global conn\n    conn = duckdb.connect(database=\":memory:\")\n\n    # URLs das APIs\n    api_urls = {\n        \"sales\": f\"{os.getenv('BACKEND_URL')}/sales/\",\n        \"employees\": f\"{os.getenv('BACKEND_URL')}/employees/\"\n    }\n\n    # Requisições em paralelo para obter dados\n    with ThreadPoolExecutor() as executor:\n        results = executor.map(fetch_data, api_urls.values())\n\n    # Transformar dados em DataFrames\n    sales_data = next(results)\n    employee_data = next(results)\n    sales_df = pd.DataFrame(sales_data)\n    employee_df = pd.DataFrame(employee_data)\n\n    # Conversão de colunas de data para datetime\n    if 'date' in sales_df.columns:\n        sales_df['date'] = pd.to_datetime(sales_df['date'], errors='coerce')\n        # Remover fuso horário das datas\n        sales_df['date'] = sales_df['date'].dt.tz_localize(None)\n\n        min_date_sales = sales_df['date'].min().to_pydatetime()\n        max_date_sales = sales_df['date'].max().to_pydatetime()\n\n        # Seletor de intervalo de datas para vendas usando slider\n        st.header(\"Filtro de Data para Vendas\")\n        date_range_sales = st.slider(\n            \"Selecione o intervalo de datas para vendas:\",\n            min_value=min_date_sales,\n            max_value=max_date_sales,\n            value=(min_date_sales, max_date_sales),\n            format=\"DD/MM/YYYY\"\n        )\n\n        # Filtrar o DataFrame de vendas com base no intervalo selecionado\n        if date_range_sales:\n            start_datetime_sales, end_datetime_sales = date_range_sales\n            sales_df = sales_df[(sales_df['date'] >= start_datetime_sales) & (sales_df['date'] <= end_datetime_sales)]\n    else:\n        st.warning(\"A coluna 'date' não está presente nos dados de vendas.\")\n\n    # Exibir métricas e gráficos\n    display_metrics(sales_df, employee_df)\n    display_charts(sales_df, employee_df)\n\n    # Fechar a conexão DuckDB\n    conn.close()\n\n# Executa o dashboard\nif __name__ == \"__main__\":\n    dashboard()\n"}
{"type": "source_file", "path": "app/frontend/employee/read_all.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\n\nfrom utils import show_response_message\n\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef read_all():\n    if st.button(\"Exibir Todos os Funcionários\"):\n        response = requests.get(f\"{os.getenv('BACKEND_URL')}/employees/\")\n        if response.status_code == 200:\n            employees = response.json()\n            # Verifica se o JSON está vazio\n            if not employees:\n                st.warning(\"⚠️ Nenhum Funcionário encontrado!\")\n                return\n            \n            df = pd.DataFrame(employees)\n            st.dataframe(df, hide_index=True, use_container_width=True)\n        else:\n            show_response_message(response)"}
{"type": "source_file", "path": "app/backend/models/supplier/supplier_schema.py", "content": "from datetime import datetime\nfrom typing import List, Optional\nfrom pydantic import BaseModel, EmailStr, Field, field_validator, ConfigDict\nfrom enum import Enum\n\nclass ProductCategoriesEnum(str, Enum):\n    categoria1 = \"Categoria 1\"\n    categoria2 = \"Categoria 2\"\n    categoria3 = \"Categoria 3\"\n\nclass SupplierBase(BaseModel):\n    \"\"\"\n    Modelo de dados para fornecedores.\n\n    Args:\n        company_name (str): Nome da empresa fornecedora\n        contact_name (str): Nome do contato principal\n        email (EmailStr): Endereço de email\n        phone_number (str): Número de telefone\n        website (str): Website da empresa\n        address (str): Endereço completo\n        product_categories (List[ProductCategoriesEnum]): Categorias dos produtos ou serviços fornecidos\n        primary_product (str): Produto ou serviço principal\n    \"\"\"\n    \n    company_name: str\n    contact_name: str\n    email: EmailStr\n    phone_number: str\n    website: str\n    address: str\n    product_categories: ProductCategoriesEnum\n    primary_product: str\n\n    @field_validator(\"product_categories\", mode=\"before\")\n    @classmethod\n    def check_categoria(cls, v):\n        if v in [item.value for item in ProductCategoriesEnum]:\n            return v\n        raise ValueError(\"Categoria inválida\")\n\nclass SupplierCreate(SupplierBase):\n    pass\n\nclass SupplierResponse(SupplierBase):\n    supplier_id: int\n    created_at: datetime\n\n    model_config = ConfigDict(from_attributes=True)\n\nclass SupplierUpdate(BaseModel):\n    company_name: Optional[str] = None\n    contact_name: Optional[str] = None\n    email: Optional[EmailStr] = None\n    phone_number: Optional[str] = None\n    website: Optional[str] = None\n    address: Optional[str] = None\n    product_categories: Optional[str] = None\n    primary_product: Optional[str] = None\n\n    @field_validator(\"product_categories\", mode='before')\n    def check_categoria(cls, v):\n        if v is None:\n            return v\n        if v in [item.value for item in ProductCategoriesEnum]: \n            return v\n        raise ValueError(\"Categoria inválida\")"}
{"type": "source_file", "path": "app/frontend/employee/delete.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\n\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef delete():\n    delete_id = st.number_input(\"Pesquisar funcionário por ID:\", min_value=1, format=\"%d\")\n\n    # Botão para consultar funcionário\n    if st.button(\"Buscar Funcionário\", key=\"search_employee_delete_button\"):\n        response = requests.get(f\"{os.getenv('BACKEND_URL')}/employees/{delete_id}\")\n        if response.status_code == 200:\n            employee = response.json()\n            # Verifica se o JSON está vazio\n            if not employee:\n                st.warning(\"⚠️ Nenhum Funcionário encontrado!\")\n                return\n            \n            df = pd.DataFrame([employee])\n\n            # Seleciona as colunas desejadas\n            df = df[\n                [\n                    \"employee_id\",\n                    \"first_name\",\n                    \"last_name\",\n                    \"email\",\n                    \"phone_number\"\n                ]\n            ]\n\n            # Concatenando Nome e Sobrenome\n            df[\"full_name\"] = df[\"first_name\"] + \" \" + df[\"last_name\"]\n\n            # Salvando o funcionário encontrado no estado da sessão\n            st.session_state['df_employee_del'] = df\n            st.session_state['id_employee_del'] = delete_id\n        else:\n            st.warning(\"Funcionário não encontrado!\")\n            st.session_state.pop('df_employee_del', None)\n\n    # Exibe as informações do funcionário, se encontrado\n    if 'df_employee_del' in st.session_state:    \n        st.text_input(\"Nome:\", value=st.session_state[\"df_employee_del\"].at[0, \"full_name\"], disabled=True, key=\"input_full_name\")\n        st.text_input(\"E-mail:\", value=st.session_state[\"df_employee_del\"].at[0, \"email\"], disabled=True, key=\"input_email\")\n        st.text_input(\"Telefone:\", value=st.session_state[\"df_employee_del\"].at[0, \"phone_number\"], disabled=True, key=\"input_phone\")     \n\n        # Botão para deletar funcionário\n        if st.button(\"Deletar Funcionário\"):\n            response = requests.delete(f\"{os.getenv('BACKEND_URL')}/employees/{st.session_state['id_employee_del']}\")\n            if response.status_code == 200:\n                st.success(\"Funcionário deletado com sucesso!\")\n                st.session_state.pop('df_employee_del')\n                st.session_state.pop('id_employee_del')\n            else:\n                st.error(\"Erro ao deletar o funcionário!\")\n\n"}
{"type": "source_file", "path": "app/frontend/AI/main.py", "content": "import streamlit as st\nimport time\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\nfrom datetime import datetime\n\n# Carregar variáveis de ambiente\nload_dotenv()\n\n# Configuração da API e do ID do Assistente\nASSISTANT_ID = \"asst_aEIuoXZHAuFDJctbvBaEc3u0\"\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# Função para enviar a pergunta ao assistente e obter a resposta\ndef responder_pergunta(pergunta):\n    thread = client.beta.threads.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"hoje é dia {datetime.now()} {pergunta}\",\n            }\n        ]\n    )\n    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=ASSISTANT_ID)\n    \n    # Verifica o status da execução até sua conclusão\n    while run.status != \"completed\":\n        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n        time.sleep(1)\n\n    # Obtém a resposta mais recente do thread\n    message_response = client.beta.threads.messages.list(thread_id=thread.id)\n    messages = message_response.data\n    latest_message = messages[0]\n    return latest_message.content[0].text.value.strip()\n\n# Função para mostrar a resposta de forma \"streaming\"\ndef mostrar_resposta_streaming(resposta):\n    with st.chat_message(\"assistant\"):\n        # Placeholder para atualizar o texto progressivamente\n        resposta_display = st.empty()\n        \n        # Remove o \"pensando...\" e começa a mostrar a resposta gradual\n        resposta_temporaria = \"\"\n        for char in resposta:\n            resposta_temporaria += char  # Adiciona o próximo caractere\n            resposta_display.markdown(resposta_temporaria)  # Atualiza o texto exibido\n            time.sleep(0.01)  # Intervalo entre caracteres\n\n# Configurações e título estilizado\nst.set_page_config(page_title=\"Assistente Virtual 🤖💬\", page_icon=\"🤖\")\nst.title(\"Assistente Virtual 🤖💬\")\n\n# Botão para reiniciar a conversa\nif st.button(\"🔄 Reiniciar Conversa\"):\n    st.session_state.messages = []\n\n# Inicializar o histórico de mensagens na sessão\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\n# Exibir o histórico de mensagens\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n\n# Caixa de entrada de texto para novas perguntas\npergunta = st.chat_input(\"Digite sua pergunta:\")\n\nif pergunta:\n    # Armazenar pergunta do usuário no histórico\n    st.session_state.messages.append({\"role\": \"user\", \"content\": pergunta})\n    with st.chat_message(\"user\"):\n        st.markdown(pergunta)\n\n    # Exibir a mensagem \"pensando...\" antes de chamar a API\n    pensando_display = st.empty()  # Placeholder para \"pensando...\"\n    pensando_display.markdown(\"Pensando... 🤔\")  # Exibe \"pensando...\"\n\n    # Enviar pergunta para o assistente e obter a resposta\n    resposta = responder_pergunta(pergunta)\n    \n    # Remove o \"pensando...\" e mostra a resposta em modo \"streaming\"\n    pensando_display.empty()  # Remove \"pensando...\" antes de mostrar a resposta\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": resposta})\n    mostrar_resposta_streaming(resposta)\n\n\n# Prompt \"Assistente Especializado em Vendas\"\n#Você é um especialista em análise e insights para equipes de vendas, com foco em maximizar o desempenho de vendas, otimizar estoques e melhorar o relacionamento com fornecedores. Sua expertise abrange a análise de dados de produtos, desempenho de vendedores, produtividade dos funcionários, e gestão de fornecedores. \n#Sempre que receber uma solicitação, responda com um resumo conciso, seguido de insights detalhados e recomendações práticas. \n#Sua linguagem deve ser profissional, direta, e prática. \n#Use gráficos e visualizações sempre que possível para simplificar a compreensão dos dados.\n\n# Perguntas de teste:\n# Qual é o valor do ticket médio dos produtos?\n# Qual é o Top 3 vendedores?\n# Qual a média de vendas mensais dos produtos?\n# Quantos produtos gemini foram vendidos ontem?"}
{"type": "source_file", "path": "app/frontend/employee/create.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\n\nfrom utils import show_response_message\n\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef create():\n    # Adicionar Funcionário\n    with st.form(\"new_employee\"):\n        first_name = st.text_input(\"Nome\")\n        last_name = st.text_input(\"Sobrenome\")\n        email = st.text_input(\"Email\")\n        phone_number = st.text_input(\"Número de Telefone\")\n        hire_date = st.date_input(\"Data de Contratação\")\n        department_id = st.number_input(\"ID do Departamento\", min_value=1, step=1)\n        manager_id = st.number_input(\"ID do Gerente\", min_value=1, step=1)\n        job_title = st.text_input(\"Cargo\")\n        location = st.text_input(\"Localização\")\n        birth_date = st.date_input(\"Data de Nascimento\")\n        gender = st.selectbox(\"Gênero\", [\"Masculino\", \"Feminino\", \"Prefiro não dizer\"])\n        nationality = st.text_input(\"Nacionalidade\")\n        start_date = st.date_input(\"Data de Início\")\n        salary = st.number_input(\"Salário\", min_value=0.01, format=\"%.2f\")\n        \n        submit_button = st.form_submit_button(\"Adicionar Funcionário\")\n\n        if submit_button:\n            response = requests.post(f\"{os.getenv('BACKEND_URL')}/employees/\", json={\n                                    \"first_name\": first_name,\n                                    \"last_name\": last_name,\n                                    \"email\": email,\n                                    \"phone_number\": phone_number,\n                                    \"hire_date\": hire_date.isoformat(),\n                                    \"department_id\": department_id,\n                                    \"manager_id\": manager_id,\n                                    \"job_title\": job_title,\n                                    \"location\": location,\n                                    \"birth_date\": birth_date.isoformat(),\n                                    \"gender\": gender,\n                                    \"nationality\": nationality,\n                                    \"start_date\": start_date.isoformat(),\n                                    \"salary\": salary\n                                }\n                            )\n            show_response_message(response)"}
{"type": "source_file", "path": "app/frontend/AI/exemplo_groq_read_csv.py", "content": "import os\nimport pandas as pd\nfrom groq import Groq\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Configure sua chave de API como uma variável de ambiente\nclient = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n\n# Função para ler o arquivo CSV usando pandas\ndef read_sales_data(file_path):\n    try:\n        # Lê o arquivo vendas.csv\n        sales_data = pd.read_csv(file_path)\n        print(\"Dados de vendas carregados com sucesso:\")\n        print(sales_data.head())  # Exibe as primeiras linhas dos dados\n        return sales_data\n    except FileNotFoundError:\n        print(\"Arquivo não encontrado. Verifique o caminho do arquivo.\")\n        return None\n\n# Função para enviar uma pergunta ao Groq com os dados em JSON\ndef ask_groq(question, data_json):\n    # Cria o conteúdo da mensagem com a pergunta e os dados em JSON\n    content = {\n        \"question\": question,\n        \"sales_data\": data_json\n    }\n    # Envia a pergunta e os dados ao Groq\n    chat_completion = client.chat.completions.create(\n        messages=[{\"role\": \"user\", \"content\": str(content)}],\n        model=\"llama3-8b-8192\"  # Certifique-se de escolher o modelo correto\n    )\n    # Extraindo o conteúdo da resposta\n    return chat_completion.choices[0].message.content\n\n# Caminho para o arquivo vendas.csv\nfile_path = 'vendas.csv'\n\n# Ler os dados do CSV\nsales_data = read_sales_data(file_path)\n\n# Verificar se os dados foram carregados com sucesso\nif sales_data is not None:\n    # Converter o DataFrame para JSON\n    sales_data_json = sales_data.to_json(orient='records')\n    \n    # Fazendo a pergunta ao Groq com os dados em JSON\n    question = \"Quanto vendemos no dia 2 de setembro?\"\n    answer = ask_groq(question, sales_data_json)\n    \n    # Imprimir a resposta\n    print(f\"Resposta do Groq: {answer}\")\nelse:\n    print(\"Não foi possível enviar a pergunta ao Groq devido a erro na leitura dos dados.\")"}
{"type": "source_file", "path": "app/frontend/employee/update.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\n\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef update():\n    update_id = str(st.number_input(\"Digite o id do Funcionário:\", min_value=1, format=\"%d\"))\n\n    # Botão para consultar cliente\n    search_update_employee_bt = st.button(\"Buscar Funcionário\", key=\"search_employee_update_button\")\n\n    if search_update_employee_bt:\n        df = pd.DataFrame()\n        response = requests.get(f\"{os.getenv('BACKEND_URL')}/employees/{update_id}\")\n        if response.status_code == 200:\n            employee = response.json()\n            # Verifica se o JSON está vazio\n            if not employee:\n                st.warning(\"⚠️ Nenhum Funcionário encontrado!\")\n                return\n            \n            df = pd.DataFrame([employee])\n\n            df = df[\n                [\n                    \"employee_id\",\n                    \"first_name\",\n                    \"last_name\",\n                    \"email\",\n                    \"phone_number\",\n                    \"department_id\",\n                    \"manager_id\",\n                    \"job_title\",\n                    \"location\",\n                    \"gender\",\n                    \"birth_date\",\n                    \"nationality\",\n                    \"start_date\",\n                    \"salary\",\n                    \"termination_date\",\n                    \"hire_date\",\n                    \"service_duration\"\n                ]\n            ]\n\n            df['hire_date'] = pd.to_datetime(df['hire_date']).dt.date\n            df['birth_date'] = pd.to_datetime(df['birth_date']).dt.date\n            df['termination_date'] = pd.to_datetime(df['termination_date']).dt.date\n            df['start_date'] = pd.to_datetime(df['start_date']).dt.date\n\n        else:\n            st.warning(\"Funcionário não encontrado!\")\n\n        if not df.empty:\n            st.session_state['df_employee_upd'] = df\n            st.session_state['id_employee_upd'] = update_id\n\n    # Verifica se o cliente foi encontrado e exibe as informações\n    if 'df_employee_upd' in st.session_state:\n        with st.form(\"update_employee\"):\n            col1, col2 = st.columns([2, 3])\n\n            gender_options = [\"Masculino\", \"Feminino\", \"Prefiro não dizer\"]\n            current_gender = st.session_state[\"df_employee_upd\"].at[0, \"gender\"]\n            gender_index = gender_options.index(current_gender) if current_gender in gender_options else 0\n\n            termination_date = st.session_state[\"df_employee_upd\"].at[0, \"termination_date\"]\n            if pd.isna(termination_date):  # Check if the date is NaT\n                termination_date = None\n\n            with col1:\n                new_first_name = st.text_input(\"Novo Nome\", value=st.session_state[\"df_employee_upd\"].at[0, \"first_name\"], disabled=False, key=\"input_first_name\")\n                new_email = st.text_input(\"Novo Email\", value=st.session_state[\"df_employee_upd\"].at[0, \"email\"], disabled=False, key=\"input_email_employee\")\n                new_hire_date = st.date_input(\"Nova Data de Contratação\", value=st.session_state[\"df_employee_upd\"].at[0, \"hire_date\"], disabled=False, key=\"input_hire_date\")\n                new_birth_date = st.date_input(\"Nova Data de Nascimento\", value=st.session_state[\"df_employee_upd\"].at[0, \"birth_date\"], disabled=False, key=\"input_birth_date\")\n                new_department_id = st.number_input(\"Novo ID do Departamento\", min_value=1, step=1, value=st.session_state[\"df_employee_upd\"].at[0, \"department_id\"], disabled=False, key=\"input_department_id\")\n                new_job_title = st.text_input(\"Novo Cargo\", value=st.session_state[\"df_employee_upd\"].at[0, \"job_title\"], disabled=False, key=\"input_job_title\")\n                new_gender = st.selectbox(\"Novo Gênero\", gender_options, index=gender_index, disabled=False, key=\"input_gender\")\n                new_nationality = st.text_input(\"Nova Nacionalidade\", value=st.session_state[\"df_employee_upd\"].at[0, \"nationality\"], disabled=False, key=\"input_nationality\")\n            with col2:\n                new_last_name = st.text_input(\"Novo Sobrenome\", value=st.session_state[\"df_employee_upd\"].at[0, \"last_name\"], disabled=False, key=\"input_last_name\")\n                new_phone_number = st.text_input(\"Novo Número de Telefone\", value=st.session_state[\"df_employee_upd\"].at[0, \"phone_number\"], disabled=False, key=\"input_phone_number\")\n                new_termination_date = st.date_input(\"Nova Data de Terminação\", value=termination_date, disabled=False, key=\"input_termination_date\")\n                new_start_date = st.date_input(\"Nova Data de Início\", value=st.session_state[\"df_employee_upd\"].at[0, \"start_date\"], disabled=False, key=\"input_start_date\")\n                new_manager_id = st.number_input(\"Novo ID do Gerente\", min_value=1, step=1, value=st.session_state[\"df_employee_upd\"].at[0, \"manager_id\"], disabled=False, key=\"input_manager_id\")\n                new_salary = st.number_input(\"Novo Salário\", min_value=0.01, format=\"%.2f\", value=st.session_state[\"df_employee_upd\"].at[0, \"salary\"], disabled=False, key=\"input_salary\")\n                new_location = st.text_input(\"Nova Localização\", value=st.session_state[\"df_employee_upd\"].at[0, \"location\"], disabled=False, key=\"input_location\")\n\n            update_employee_bt = st.form_submit_button(\"Atualizar Funcionário\")\n\n            if update_employee_bt:\n                employee_updated = {}\n                employee_updated[\"first_name\"] = new_first_name\n                employee_updated[\"last_name\"] = new_last_name\n                employee_updated[\"email\"] = new_email\n                employee_updated[\"phone_number\"] = new_phone_number\n                employee_updated[\"department_id\"] = new_department_id\n                employee_updated[\"job_title\"] = new_job_title\n                employee_updated[\"gender\"] = new_gender\n                employee_updated[\"nationality\"] = new_nationality\n                employee_updated[\"manager_id\"] = new_manager_id\n                employee_updated[\"salary\"] = new_salary\n                employee_updated[\"location\"] = new_location\n\n                if new_termination_date is not None:\n                    employee_updated[\"termination_date\"] = new_termination_date.strftime(\"%Y-%m-%d\")  # Convert to string\n                else:\n                    employee_updated[\"termination_date\"] = None\n\n                if new_hire_date is not None:\n                    employee_updated[\"hire_date\"] = new_hire_date.strftime(\"%Y-%m-%d\")\n                else:\n                    employee_updated[\"hire_date\"] = None\n\n                if new_birth_date is not None:\n                    employee_updated[\"birth_date\"] = new_birth_date.strftime(\"%Y-%m-%d\")\n                else:\n                    employee_updated[\"birth_date\"] = None\n\n                if new_start_date is not None:\n                    employee_updated[\"start_date\"] = new_start_date.strftime(\"%Y-%m-%d\")\n                else:\n                    employee_updated[\"start_date\"] = None\n\n                if employee_updated:\n                    response = requests.put(\n                            f\"{os.getenv('BACKEND_URL')}/employees/{st.session_state['id_employee_upd']}\", json=employee_updated\n                        )\n                    \n                    if response.status_code == 200:\n                        st.success(\"Funcionário atualizado com sucesso!\")\n                        del st.session_state['df_employee_upd']\n                        del st.session_state['id_employee_upd']\n                    else:\n                        st.error(\"Erro ao atualizar Funcionário.\")"}
{"type": "source_file", "path": "app/frontend/employee/__init__.py", "content": "from .create import create\nfrom .delete import delete\nfrom .read_all import read_all\nfrom .read_employee import read_employee\nfrom .update import update"}
{"type": "source_file", "path": "app/frontend/AI/exemplo_bancovetorial.py", "content": "import chromadb\nchroma_client = chromadb.Client()\n\ncollection = chroma_client.get_or_create_collection(name=\"expansao_liftoff\")\n\ncollection.upsert(\n    documents=[\n        \"A LiftOff vai abrir escritório no Brasil.\",\n        \"A LiftOff vai abrir escritório na França.\",\n        \"A LiftOff vai abrir escritório no Japão.\",\n        \"A LiftOff vai abrir escritório na Alemanha.\",\n        \"A LiftOff vai abrir escritório no Canadá.\",\n        \"A LiftOff vai abrir escritório na Austrália.\",\n        \"A LiftOff vai abrir escritório na Itália.\",\n        \"A LiftOff vai abrir escritório na Argentina.\",\n        \"A LiftOff vai abrir escritório na Espanha.\",\n        \"A LiftOff vai abrir escritório na Rússia.\"\n    ],\n    ids=[\"pais1\", \"pais2\", \"pais3\", \"pais4\", \"pais5\", \"pais6\", \"pais7\", \"pais8\", \"pais9\", \"pais10\"]\n)\n\nresultado = collection.query(\n    query_texts=[\"O LiftOff terá um escritório no Rio de Janeiro?\"],\n    n_results=3\n)\n\nprint(resultado)"}
{"type": "source_file", "path": "app/backend/models/sales/sales_schema.py", "content": "from datetime import datetime\nfrom typing import Tuple\nfrom pydantic import BaseModel, EmailStr, PositiveFloat, PositiveInt, field_validator, ConfigDict\nfrom enum import Enum\nfrom typing import Optional\n\nclass ProdutoEnum(str, Enum):\n    produto1 = \"ZapFlow com Gemini\"\n    produto2 = \"ZapFlow com chatGPT\"\n    produto3 = \"ZapFlow com Llama3.0\"\n\nclass SalesBase(BaseModel):\n    \"\"\"\n    Modelo de dados para as vendas.\n\n    Args:\n        email_employee (EmailStr): email do funcionario\n        email_customer (EmailStr): email do comprador\n        date (datetime): data da compra\n        first_name (str): Primeiro nome do comprador\n        last_name (str): Ultimo nome do comprador   \n        phone_number (str): Número de telefone do comprador\n        price (PositiveFloat): valor da compra\n        name_product (PositiveInt): nome do produto\n        quantity (PositiveInt): quantidade de produtos\n        produto_category (ProdutoEnum): categoria do produto\n    \"\"\"\n\n    email_employee: EmailStr\n    email_customer: EmailStr\n    first_name: str\n    last_name: str    \n    phone_number: str\n    date: datetime\n    price: PositiveFloat\n    quantity: PositiveInt\n    name_product: str\n\n    '''\n    @field_validator(\"produto_category\", mode=\"before\")\n    @classmethod\n    def check_categoria(cls, v):\n        if v in [item.value for item in ProdutoEnum]:\n            return v\n        raise ValueError(\"Produto inválido\")\n    '''\n    \nclass SalesCreate(SalesBase):\n    pass\n\nclass SalesResponse(SalesBase):\n    id: int\n    created_at: datetime\n\n    model_config = ConfigDict(from_attributes=True)\n\nclass SalesUpdate(BaseModel):\n    email_employee: Optional[EmailStr] = None\n    email_customer: Optional[EmailStr] = None\n    first_name: Optional[str] = None\n    last_name: Optional[str] = None    \n    phone_number: Optional[str] = None\n    date: Optional[datetime] = None \n    price: Optional[PositiveFloat] = None\n    quantity: Optional[PositiveInt] = None\n    name_product: Optional[str] = None\n\n    '''\n    @field_validator(\"name_product\", mode='before')\n    def check_categoria(cls, v):\n        if v is None:\n            return v\n        if v in [item.value for item in ProdutoEnum]:\n            return v\n        raise ValueError(\"Produto inválido\")\n   '''"}
{"type": "source_file", "path": "app/frontend/employee/read_employee.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\n\nfrom utils import show_response_message\n\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef read_employee():\n    options = [\"Selecione uma opção:\", \"ID\", \"Nome\", \"Sobrenome\", \"Email\", \"Telefone\"]\n    select_search = st.selectbox(\"Buscar por:\", options=options)\n\n    # Determina o estado do campo de entrada de texto\n    input_disabled = select_search == \"Selecione uma opção:\"\n\n    # Determina a mensagem do text_input\n    if input_disabled:\n        mensagem = \"Selecione uma opção de pesquisa\"\n    else:\n        mensagem = f\"Pesquisar funcionário por {select_search}:\"\n\n    # Entrada de texto para pesquisa\n    search_field = st.text_input(mensagem, disabled=input_disabled)\n\n    search_employee_bt = st.button(\"Buscar funcionário\", disabled=input_disabled, key=\"search_employee_button\")\n\n    if search_employee_bt:\n        # Filtrando o DataFrame com base na entrada do usuário\n        if search_field.strip() == \"\":\n            st.warning(\"Digite uma valor para ser pesquisado!\")\n        else:\n            if not input_disabled and search_field:\n                response = requests.get(f\"{os.getenv('BACKEND_URL')}/employees/\")\n\n                if response.status_code == 200:\n                    employee = response.json()\n                    # Verifica se o JSON está vazio\n                    if not employee:\n                        st.warning(\"⚠️ Nenhum Funcionário encontrado!\")\n                        return\n            \n                    df = pd.DataFrame(employee)\n                    \n                    if select_search == \"Nome\":\n                        df_employee = df[df['first_name'].str.contains(search_field, case=False, na=False)]\n                    elif select_search == \"Sobrenome\":\n                        df_employee = df[df['last_name'].str.contains(search_field, case=False, na=False)]\n                    elif select_search == \"Email\":\n                        df_employee = df[df['email'].str.contains(search_field, case=False, na=False)]\n                    elif select_search == \"Telefone\":\n                        df_employee = df[df['phone_number'].str.contains(search_field, case=False, na=False)]\n                    else:  # Assuming 'ID'\n                        df_employee = df[df['employee_id'].astype(str).str.contains(search_field, case=False, na=False)]\n                                                    \n                    if not df_employee.empty:\n                        st.dataframe(df_employee, hide_index=True, use_container_width=True)\n                    else:\n                        st.warning(\"Nenhum Funcionário encontrado!\")\n                else:\n                    show_response_message(response)"}
{"type": "source_file", "path": "app/frontend/product/read_all.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\nfrom utils import show_response_message\n\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef read_all():\n    if st.button(\"Exibir Todos os Produtos\"):\n        response = requests.get(f\"{os.getenv('BACKEND_URL')}/products/\")\n        if response.status_code == 200:\n            product = response.json()\n\n            # Verifica se o JSON está vazio\n            if not product:\n                st.warning(\"⚠️ Nenhum produto encontrado!\")\n                return\n            \n            df = pd.DataFrame(product)\n\n            df = df[list([\n                \"id\",\n                \"name\",\n                \"description\",\n                \"price\",\n                \"categoria\",\n                \"email_fornecedor\",\n                \"created_at\",\n            ])]\n\n            # Exibe o DataFrame sem o índice\n            st.dataframe(df, hide_index=True, use_container_width=True)\n        else:\n            show_response_message(response)"}
{"type": "source_file", "path": "app/frontend/product/update.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\nfrom utils import show_response_message\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef update():\n\n    update_id = str(st.number_input(\"Digite o id do Produto:\", min_value=1, format=\"%d\"))\n\n    # Botão para consultar produto\n    search_update_product_bt = st.button(\"Buscar Produto\", key=\"search_product_update_button\")\n\n    if search_update_product_bt:\n        df = pd.DataFrame()\n        response = requests.get(f\"{os.getenv('BACKEND_URL')}/products/{update_id}\")\n        if response.status_code == 200:\n            product = response.json()\n            # Verifica se o JSON está vazio\n            if not product:\n                st.warning(\"⚠️ Nenhum produto encontrado!\")\n                return\n            \n            df = pd.DataFrame([product])\n\n            df = df[\n                [\n                    \"id\",\n                    \"name\",\n                    \"description\",\n                    \"price\",\n                    \"categoria\",\n                    \"email_fornecedor\"\n                ]\n            ]\n\n        else:\n            st.warning(\"Produto não encontrado!\")\n\n        if not df.empty:\n            st.session_state['df_product_upd'] = df\n            st.session_state['id_product_upd'] = update_id\n\n    # Verifica se o cliente foi encontrado e exibe as informações\n    if 'df_product_upd' in st.session_state:\n        with st.form(\"update_product\"):\n            col1, col2 = st.columns([2, 3])\n\n            options = [\"Eletrônico\", \"Eletrodoméstico\", \"Móveis\", \"Roupas\", \"Calçados\"]\n            current_option = st.session_state[\"df_product_upd\"].at[0, \"categoria\"]\n            category_index = options.index(current_option) if current_option in options else 0\n\n            with col1:\n                new_name = st.text_input(\"Novo Nome do Produto\", value=st.session_state[\"df_product_upd\"].at[0, \"name\"], disabled=False, key=\"input_name_product\")\n                new_price = st.number_input(\"Novo Preço\", min_value=0.01, format=\"%.2f\", value=st.session_state[\"df_product_upd\"].at[0, \"price\"], disabled=False, key=\"input_price_product\")\n                new_email = st.text_input(\"Novo Email do Fornecedor\", value=st.session_state[\"df_product_upd\"].at[0, \"email_fornecedor\"], disabled=False, key=\"input_email_product_supplier\")\n\n            with col2:\n                new_description = st.text_area(\"Nova Descrição do Produto\", value=st.session_state[\"df_product_upd\"].at[0, \"description\"], disabled=False, key=\"input_description_product\")\n                new_categoria = st.selectbox(\"Nova Categoria de produtos\", options=options, index=category_index, disabled=False, key=\"input_category_product_form\")         \n            \n            update_product_bt = st.form_submit_button(\"Atualizar Produto\")\n\n            if update_product_bt:\n                product_updated = {}\n                product_updated[\"name\"] = new_name\n                product_updated[\"price\"] = new_price\n                product_updated[\"email_fornecedor\"] = new_email\n                product_updated[\"description\"] = new_description\n                product_updated[\"categoria\"] = new_categoria\n\n                if product_updated:\n                    response = requests.put(\n                            f\"{os.getenv('BACKEND_URL')}/products/{st.session_state['id_product_upd']}\", json=product_updated\n                        )\n                    \n                    if response.status_code == 200:\n                        st.success(\"Produto atualizado com sucesso!\")\n                        del st.session_state['df_product_upd']\n                        del st.session_state['id_product_upd']\n                    else:\n                        st.error(\"Erro ao atualizar Produto.\")"}
{"type": "source_file", "path": "app/frontend/product/delete.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\n\nfrom utils import show_response_message\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef delete():\n    delete_id = st.number_input(\"ID do Produto para Deletar\", min_value=1, format=\"%d\")\n    \n    # Botão para consultar Produto\n    if st.button(\"Buscar Produto\"):\n        response = requests.get(f\"{os.getenv('BACKEND_URL')}/products/{delete_id}\")\n        if response.status_code == 200:\n            product = response.json()\n            # Verifica se o JSON está vazio\n            if not product:\n                st.warning(\"⚠️ Nenhum produto encontrado!\")\n                return\n            \n            df = pd.DataFrame([product])\n\n            # Seleciona as colunas desejadas\n            df = df[\n                [\n                    \"id\",\n                    \"name\",\n                    \"description\",\n                    \"categoria\",\n                    \"email_fornecedor\",\n                    \"price\"\n                ]\n            ]\n\n            # Salvando o funcionário encontrado no estado da sessão\n            st.session_state['df_product_del'] = df\n            st.session_state['id_product_del'] = delete_id\n        else:\n            st.warning(\"Produto não encontrado!\")\n            st.session_state.pop('df_product_del', None)\n        \n    # Exibe as informações do Produto, se encontrado\n    if 'df_product_del' in st.session_state:    \n        st.text_input(\"Nome:\", value=st.session_state[\"df_product_del\"].at[0, \"name\"], disabled=True, key=\"input_name\")\n        st.text_input(\"Descrição:\", value=st.session_state[\"df_product_del\"].at[0, \"description\"], disabled=True, key=\"input_description\")\n        st.text_input(\"Categoria:\", value=st.session_state[\"df_product_del\"].at[0, \"categoria\"], disabled=True, key=\"input_categoria\")\n        st.text_input(\"Preço:\", value=st.session_state[\"df_product_del\"].at[0, \"price\"], disabled=True, key=\"input_price\")     \n        st.text_input(\"E-mail Fornecedor:\", value=st.session_state[\"df_product_del\"].at[0, \"email_fornecedor\"], disabled=True, key=\"input_email_fornecedor\")\n        \n\n        # Botão para deletar Produto\n        if st.button(\"Deletar Produto\"):\n            response = requests.delete(f\"{os.getenv('BACKEND_URL')}/products/{st.session_state['id_product_del']}\")\n            if response.status_code == 200:\n                st.success(\"Produto deletado com sucesso!\")\n                st.session_state.pop('df_product_del')\n                st.session_state.pop('id_product_del')\n            else:\n                st.error(\"Erro ao deletar o Produto!\")"}
{"type": "source_file", "path": "app/frontend/product/read_product.py", "content": "import streamlit as st\nimport pandas as pd\nimport requests\nfrom datetime import datetime, time, date\nimport os\nfrom dotenv import load_dotenv\nfrom utils import show_response_message\n# Carrega o arquivo .env usando um caminho relativo\nload_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))\n\ndef read_product():\n    options = [\"Selecione uma opção:\", \"ID\", \"Nome\", \"Descrição\", \"Email Fornecedor\"]\n    select_search = st.selectbox(\"Buscar por:\", options=options)\n\n    # Determina o estado do campo de entrada de texto\n    input_disabled = select_search == \"Selecione uma opção:\"\n\n    # Determina a mensagem do text_input\n    if input_disabled:\n        mensagem = \"Selecione uma opção de pesquisa\"\n    else:\n        mensagem = f\"Pesquisar Produto por {select_search}:\"\n\n    # Entrada de texto para pesquisa\n    search_field = st.text_input(mensagem, disabled=input_disabled)\n\n    search_supplier_bt = st.button(\"Buscar produto\", disabled=input_disabled)\n\n    if search_supplier_bt:\n        # Filtrando o DataFrame com base na entrada do usuário\n        if search_field.strip() == \"\":\n            st.warning(\"Digite uma valor para ser pesquisado!\")\n        else:\n            if not input_disabled and search_field:\n                response = requests.get(f\"{os.getenv('BACKEND_URL')}/products/\")\n\n                if response.status_code == 200:\n                    product = response.json()\n                    # Verifica se o JSON está vazio\n                    if not product:\n                        st.warning(\"⚠️ Nenhum produto encontrado!\")\n                        return\n            \n                    df = pd.DataFrame(product)\n                    \n                    if select_search == \"Nome\":\n                        df_product = df[df['name'].str.contains(search_field, case=False, na=False)]\n                    elif select_search == \"Descrição\":\n                        df_product = df[df['description'].str.contains(search_field, case=False, na=False)]\n                    elif select_search == \"Email Fornecedor\":\n                        df_product = df[df['email_fornecedor'].str.contains(search_field, case=False, na=False)]\n                    else:  # Assuming 'ID'\n                        df_product = df[df['id'].astype(str).str.contains(search_field, case=False, na=False)]\n                                                        \n                    if not df_product.empty:\n                        st.dataframe(df_product, hide_index=True, use_container_width=True)\n                    else:\n                        st.warning(\"Nenhum Produto encontrado!\")\n                else:\n                    show_response_message(response)"}
