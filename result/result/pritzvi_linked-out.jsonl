{"repo_info": {"repo_name": "linked-out", "repo_owner": "pritzvi", "repo_url": "https://github.com/pritzvi/linked-out"}}
{"type": "test_file", "path": "browser-use/browser_use/browser/tests/screenshot_test.py", "content": "import base64\n\nimport pytest\n\nfrom browser_use.browser.browser import Browser, BrowserConfig\n\n\n@pytest.fixture\nasync def browser():\n\tbrowser_service = Browser(config=BrowserConfig(headless=True))\n\tyield browser_service\n\n\tawait browser_service.close()\n\n\n# @pytest.mark.skip(reason='takes too long')\ndef test_take_full_page_screenshot(browser):\n\t# Go to a test page\n\tbrowser.go_to_url('https://example.com')\n\n\t# Take full page screenshot\n\tscreenshot_b64 = browser.take_screenshot(full_page=True)\n\n\t# Verify screenshot is not empty and is valid base64\n\tassert screenshot_b64 is not None\n\tassert isinstance(screenshot_b64, str)\n\tassert len(screenshot_b64) > 0\n\n\t# Test we can decode the base64 string\n\ttry:\n\t\tbase64.b64decode(screenshot_b64)\n\texcept Exception as e:\n\t\tpytest.fail(f'Failed to decode base64 screenshot: {str(e)}')\n\n\nif __name__ == '__main__':\n\ttest_take_full_page_screenshot(Browser(config=BrowserConfig(headless=False)))\n"}
{"type": "test_file", "path": "browser-use/tests/test_stress.py", "content": "import asyncio\nimport os\nimport random\nimport string\nimport time\n\nimport pytest\nfrom langchain_openai import AzureChatOpenAI\nfrom pydantic import SecretStr\n\nfrom browser_use.agent.service import Agent\nfrom browser_use.browser.browser import Browser, BrowserConfig\nfrom browser_use.controller.service import Controller\n\n\n@pytest.fixture(scope='session')\ndef event_loop():\n\tloop = asyncio.get_event_loop_policy().new_event_loop()\n\tyield loop\n\tloop.close()\n\n\n@pytest.fixture(scope='session')\nasync def browser(event_loop):\n\tbrowser_instance = Browser(\n\t\tconfig=BrowserConfig(\n\t\t\theadless=True,\n\t\t)\n\t)\n\tyield browser_instance\n\tawait browser_instance.close()\n\n\n@pytest.fixture\nasync def context(browser):\n\tasync with await browser.new_context() as context:\n\t\tyield context\n\n\n@pytest.fixture\ndef llm():\n\t\"\"\"Initialize the language model\"\"\"\n\tmodel = AzureChatOpenAI(\n\t\tapi_version='2024-10-21',\n\t\tmodel='gpt-4o',\n\t\tazure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),\n\t\tapi_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),\n\t)\n\treturn model\n\n\ndef generate_random_text(length: int) -> str:\n\t\"\"\"Generate random text of specified length\"\"\"\n\treturn ''.join(random.choices(string.ascii_letters + string.digits + ' ', k=length))\n\n\n@pytest.fixture\nasync def controller():\n\t\"\"\"Initialize the controller\"\"\"\n\tcontroller = Controller()\n\tlarge_text = generate_random_text(10000)\n\n\t@controller.action('call this magical function to get very special text')\n\tdef get_very_special_text():\n\t\treturn large_text\n\n\tyield controller\n\n\n@pytest.mark.asyncio\nasync def test_token_limit_with_multiple_extractions(llm, controller, context):\n\t\"\"\"Test handling of multiple smaller extractions accumulating tokens\"\"\"\n\tagent = Agent(\n\t\ttask='Call the magical function to get very special text 5 times',\n\t\tllm=llm,\n\t\tcontroller=controller,\n\t\tbrowser_context=context,\n\t\tmax_input_tokens=2000,\n\t\tsave_conversation_path='tmp/stress_test/test_token_limit_with_multiple_extractions.json',\n\t)\n\n\thistory = await agent.run(max_steps=5)\n\n\t# check if 5 times called get_special_text\n\tcalls = [a for a in history.action_names() if a == 'get_very_special_text']\n\tassert len(calls) == 5\n\t# check the message history should be max 3 messages\n\tassert len(agent.message_manager.history.messages) > 3\n\n\n@pytest.mark.slow\n@pytest.mark.parametrize('max_tokens', [4000])  # 8000 20000\n@pytest.mark.asyncio\nasync def test_open_3_tabs_and_extract_content(llm, controller, context, max_tokens):\n\t\"\"\"Stress test: Open 3 tabs with urls and extract content\"\"\"\n\tagent = Agent(\n\t\ttask='Open 3 tabs with https://en.wikipedia.org/wiki/Internet and extract the content from each.',\n\t\tllm=llm,\n\t\tcontroller=controller,\n\t\tbrowser_context=context,\n\t\tmax_input_tokens=max_tokens,\n\t\tsave_conversation_path='tmp/stress_test/test_open_3_tabs_and_extract_content.json',\n\t)\n\tstart_time = time.time()\n\thistory = await agent.run(max_steps=7)\n\tend_time = time.time()\n\n\ttotal_time = end_time - start_time\n\n\tprint(f'Total time: {total_time:.2f} seconds')\n\t# Check for errors\n\terrors = history.errors()\n\tassert len(errors) == 0, 'Errors occurred during the test'\n\t# check if 3 tabs were opened\n\tassert len(context.current_state.tabs) >= 3, '3 tabs were not opened'\n"}
{"type": "test_file", "path": "browser-use/tests/test_qwen.py", "content": "import asyncio\n\nimport pytest\nfrom langchain_ollama import ChatOllama\n\nfrom browser_use.agent.service import Agent\nfrom browser_use.agent.views import AgentHistoryList\nfrom browser_use.browser.browser import Browser, BrowserConfig\n\n\n@pytest.fixture\ndef llm():\n\t\"\"\"Initialize language model for testing\"\"\"\n\n\t# return ChatAnthropic(model_name='claude-3-5-sonnet-20240620', timeout=25, stop=None)\n\t# NOTE: Make sure to run ollama server with `ollama start'\n\treturn ChatOllama(\n\t\tmodel='qwen2.5:latest',\n\t\tnum_ctx=128000,\n\t)\n\n\n@pytest.fixture(scope='session')\ndef event_loop():\n\t\"\"\"Create an instance of the default event loop for each test case.\"\"\"\n\tloop = asyncio.get_event_loop_policy().new_event_loop()\n\tyield loop\n\tloop.close()\n\n\n@pytest.fixture(scope='session')\nasync def browser(event_loop):\n\tbrowser_instance = Browser(\n\t\tconfig=BrowserConfig(\n\t\t\theadless=True,\n\t\t)\n\t)\n\tyield browser_instance\n\tawait browser_instance.close()\n\n\n@pytest.fixture\nasync def context(browser):\n\tasync with await browser.new_context() as context:\n\t\tyield context\n\n\n# pytest tests/test_qwen.py -v -k \"test_qwen_url\" --capture=no\n# @pytest.mark.asyncio\nasync def test_qwen_url(llm, context):\n\t\"\"\"Test complex ecommerce interaction sequence\"\"\"\n\tagent = Agent(\n\t\ttask='go_to_url amazon.com',\n\t\tllm=llm,\n\t\ttool_call_in_content=False,\n\t)\n\n\thistory: AgentHistoryList = await agent.run(max_steps=3)\n\n\t# Verify sequence of actions\n\taction_sequence = []\n\tfor action in history.model_actions():\n\t\taction_name = list(action.keys())[0]\n\t\tif action_name in ['go_to_url', 'open_tab']:\n\t\t\taction_sequence.append('navigate')\n\n\tassert 'navigate' in action_sequence  # Navigated to Amazon\n"}
{"type": "test_file", "path": "browser-use/browser_use/dom/tests/process_dom_test.py", "content": "import json\nimport os\nimport time\n\nfrom browser_use.browser.browser import Browser, BrowserConfig\n\n\nasync def test_process_dom():\n\tbrowser = Browser(config=BrowserConfig(headless=False))\n\n\tasync with await browser.new_context() as context:\n\t\tpage = await context.get_current_page()\n\t\tawait page.goto('https://kayak.com/flights')\n\t\t# await page.goto('https://google.com/flights')\n\t\t# await page.goto('https://immobilienscout24.de')\n\t\t# await page.goto('https://seleniumbase.io/w3schools/iframes')\n\n\t\ttime.sleep(3)\n\n\t\twith open('browser_use/dom/process_dom.js', 'r') as f:\n\t\t\tjs_code = f.read()\n\n\t\tstart = time.time()\n\t\tdom_tree = await page.evaluate(js_code)\n\t\tend = time.time()\n\n\t\t# print(dom_tree)\n\t\tprint(f'Time: {end - start:.2f}s')\n\n\t\tos.makedirs('./tmp', exist_ok=True)\n\t\twith open('./tmp/dom.json', 'w') as f:\n\t\t\tjson.dump(dom_tree, f, indent=1)\n\n\t\t# both of these work for immobilienscout24.de\n\t\t# await page.click('.sc-dcJsrY.ezjNCe')\n\t\t# await page.click(\n\t\t# \t'div > div:nth-of-type(2) > div > div:nth-of-type(2) > div > div:nth-of-type(2) > div > div > div > button:nth-of-type(2)'\n\t\t# )\n\n\t\tinput('Press Enter to continue...')\n"}
{"type": "test_file", "path": "browser-use/tests/test_agent_actions.py", "content": "import asyncio\nimport os\n\nimport pytest\nfrom langchain_openai import AzureChatOpenAI\nfrom pydantic import BaseModel, SecretStr\n\nfrom browser_use.agent.service import Agent\nfrom browser_use.agent.views import AgentHistoryList\nfrom browser_use.browser.browser import Browser, BrowserConfig\nfrom browser_use.browser.views import BrowserState\n\n\n@pytest.fixture\ndef llm():\n\t\"\"\"Initialize language model for testing\"\"\"\n\n\t# return ChatAnthropic(model_name='claude-3-5-sonnet-20240620', timeout=25, stop=None)\n\treturn AzureChatOpenAI(\n\t\tmodel='gpt-4o',\n\t\tapi_version='2024-10-21',\n\t\tazure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),\n\t\tapi_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),\n\t)\n\t# return ChatOpenAI(model='gpt-4o-mini')\n\n\n@pytest.fixture(scope='session')\ndef event_loop():\n\t\"\"\"Create an instance of the default event loop for each test case.\"\"\"\n\tloop = asyncio.get_event_loop_policy().new_event_loop()\n\tyield loop\n\tloop.close()\n\n\n@pytest.fixture(scope='session')\nasync def browser(event_loop):\n\tbrowser_instance = Browser(\n\t\tconfig=BrowserConfig(\n\t\t\theadless=True,\n\t\t)\n\t)\n\tyield browser_instance\n\tawait browser_instance.close()\n\n\n@pytest.fixture\nasync def context(browser):\n\tasync with await browser.new_context() as context:\n\t\tyield context\n\t\t# Clean up automatically happens with __aexit__\n\n\n# pytest tests/test_agent_actions.py -v -k \"test_ecommerce_interaction\" --capture=no\n# @pytest.mark.asyncio\n@pytest.mark.skip(reason='Kinda expensive to run')\nasync def test_ecommerce_interaction(llm, context):\n\t\"\"\"Test complex ecommerce interaction sequence\"\"\"\n\tagent = Agent(\n\t\ttask=\"Go to amazon.com, search for 'laptop', filter by 4+ stars, and find the price of the first result\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t\tsave_conversation_path='tmp/test_ecommerce_interaction/conversation',\n\t)\n\n\thistory: AgentHistoryList = await agent.run(max_steps=20)\n\n\t# Verify sequence of actions\n\taction_sequence = []\n\tfor action in history.model_actions():\n\t\taction_name = list(action.keys())[0]\n\t\tif action_name in ['go_to_url', 'open_tab']:\n\t\t\taction_sequence.append('navigate')\n\t\telif action_name == 'input_text':\n\t\t\taction_sequence.append('input')\n\t\t\t# Check that the input is 'laptop'\n\t\t\tinp = action['input_text']['text'].lower()  # type: ignore\n\t\t\tif inp == 'laptop':\n\t\t\t\taction_sequence.append('input_exact_correct')\n\t\t\telif 'laptop' in inp:\n\t\t\t\taction_sequence.append('correct_in_input')\n\t\t\telse:\n\t\t\t\taction_sequence.append('incorrect_input')\n\t\telif action_name == 'click_element':\n\t\t\taction_sequence.append('click')\n\n\t# Verify essential steps were performed\n\tassert 'navigate' in action_sequence  # Navigated to Amazon\n\tassert 'input' in action_sequence  # Entered search term\n\tassert 'click' in action_sequence  # Clicked search/filter\n\tassert 'input_exact_correct' in action_sequence or 'correct_in_input' in action_sequence\n\n\n# @pytest.mark.asyncio\nasync def test_error_recovery(llm, context):\n\t\"\"\"Test agent's ability to recover from errors\"\"\"\n\tagent = Agent(\n\t\ttask='Navigate to nonexistent-site.com and then recover by going to google.com ',\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\n\thistory: AgentHistoryList = await agent.run(max_steps=10)\n\n\tactions_names = history.action_names()\n\tactions = history.model_actions()\n\tassert (\n\t\t'go_to_url' in actions_names or 'open_tab' in actions_names\n\t), f'{actions_names} does not contain go_to_url or open_tab'\n\tfor action in actions:\n\t\tif 'go_to_url' in action:\n\t\t\tassert 'url' in action['go_to_url'], 'url is not in go_to_url'\n\t\t\tassert action['go_to_url']['url'].endswith(\n\t\t\t\t'google.com'\n\t\t\t), 'url does not end with google.com'\n\t\t\tbreak\n\n\n# @pytest.mark.asyncio\nasync def test_find_contact_email(llm, context):\n\t\"\"\"Test agent's ability to find contact email on a website\"\"\"\n\tagent = Agent(\n\t\ttask='Go to https://browser-use.com/ and find out the contact email',\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\n\thistory: AgentHistoryList = await agent.run(max_steps=10)\n\n\t# Verify the agent found the contact email\n\textracted_content = history.extracted_content()\n\temail = 'info@browser-use.com'\n\tfor content in extracted_content:\n\t\tif email in content:\n\t\t\tbreak\n\telse:\n\t\tpytest.fail(f'{extracted_content} does not contain {email}')\n\n\n# @pytest.mark.asyncio\nasync def test_agent_finds_installation_command(llm, context):\n\t\"\"\"Test agent's ability to find the pip installation command for browser-use on the web\"\"\"\n\tagent = Agent(\n\t\ttask='Find the pip installation command for the browser-use repo',\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\n\thistory: AgentHistoryList = await agent.run(max_steps=10)\n\n\t# Verify the agent found the correct installation command\n\textracted_content = history.extracted_content()\n\tinstall_command = 'pip install browser-use'\n\tfor content in extracted_content:\n\t\tif install_command in content:\n\t\t\tbreak\n\telse:\n\t\tpytest.fail(f'{extracted_content} does not contain {install_command}')\n\n\nclass CaptchaTest(BaseModel):\n\tname: str\n\turl: str\n\tsuccess_text: str\n\tadditional_text: str | None = None\n\n\n# run 3 test: python -m pytest tests/test_agent_actions.py -v -k \"test_captcha_solver\" --capture=no --log-cli-level=INFO\n# pytest tests/test_agent_actions.py -v -k \"test_captcha_solver\" --capture=no --log-cli-level=INFO\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\n\t'captcha',\n\t[\n\t\tCaptchaTest(\n\t\t\tname='Text Captcha',\n\t\t\turl='https://2captcha.com/demo/text',\n\t\t\tsuccess_text='Captcha is passed successfully!',\n\t\t),\n\t\tCaptchaTest(\n\t\t\tname='Basic Captcha',\n\t\t\turl='https://captcha.com/demos/features/captcha-demo.aspx',\n\t\t\tsuccess_text='Correct!',\n\t\t),\n\t\tCaptchaTest(\n\t\t\tname='Rotate Captcha',\n\t\t\turl='https://2captcha.com/demo/rotatecaptcha',\n\t\t\tsuccess_text='Captcha is passed successfully',\n\t\t\tadditional_text='Use multiple clicks at once. click done when image is exact correct position.',\n\t\t),\n\t\tCaptchaTest(\n\t\t\tname='MT Captcha',\n\t\t\turl='https://2captcha.com/demo/mtcaptcha',\n\t\t\tsuccess_text='Verified Successfully',\n\t\t\tadditional_text='Stop when you solved it successfully.',\n\t\t),\n\t],\n)\nasync def test_captcha_solver(llm, context, captcha: CaptchaTest):\n\t\"\"\"Test agent's ability to solve different types of captchas\"\"\"\n\tagent = Agent(\n\t\ttask=f'Go to {captcha.url} and solve the captcha. {captcha.additional_text}',\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\tfrom browser_use.agent.views import AgentHistoryList\n\n\thistory: AgentHistoryList = await agent.run(max_steps=7)\n\n\tstate: BrowserState = await context.get_state()\n\n\tall_text = state.element_tree.get_all_text_till_next_clickable_element()\n\n\tif not all_text:\n\t\tall_text = ''\n\n\tif not isinstance(all_text, str):\n\t\tall_text = str(all_text)\n\n\tsolved = captcha.success_text in all_text\n\tassert solved, f'Failed to solve {captcha.name}'\n\n\t# python -m pytest tests/test_agent_actions.py -v --capture=no\n\n\t# pytest tests/test_agent_actions.py -v -k \"test_captcha_solver\" --capture=no --log-cli-level=INFO\n"}
{"type": "test_file", "path": "browser-use/tests/test_attach_chrome.py", "content": "import asyncio\n\nfrom playwright.async_api import async_playwright\n\n\nasync def test_full_screen(start_fullscreen: bool, maximize: bool):\n\tasync with async_playwright() as p:\n\t\ttry:\n\t\t\tprint('Attempting to connect to Chrome...')\n\t\t\t# run in terminal: /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222 --no-first-run\n\t\t\tbrowser = await p.chromium.connect_over_cdp(\n\t\t\t\t'http://localhost:9222',\n\t\t\t\ttimeout=20000,  # 20 second timeout for connection\n\t\t\t)\n\t\t\tprint('Connected to Chrome successfully')\n\n\t\t\t# Get the first context and page, or create new ones if needed\n\t\t\tif len(browser.contexts) == 0:\n\t\t\t\tcontext = await browser.new_context(ignore_https_errors=True)\n\t\t\telse:\n\t\t\t\tcontext = browser.contexts[0]\n\n\t\t\tif len(context.pages) == 0:\n\t\t\t\tpage = await context.new_page()\n\t\t\telse:\n\t\t\t\tpage = context.pages[0]\n\n\t\t\tprint('Attempting to navigate to Gmail...')\n\t\t\ttry:\n\t\t\t\t# First try with a shorter timeout\n\t\t\t\tawait page.goto(\n\t\t\t\t\t'https://mail.google.com',\n\t\t\t\t\twait_until='load',  # Changed from domcontentloaded\n\t\t\t\t\ttimeout=10000,\n\t\t\t\t)\n\t\t\texcept Exception as e:\n\t\t\t\tprint(f'First navigation attempt failed: {e}')\n\t\t\t\tprint('Trying again with different settings...')\n\t\t\t\t# If that fails, try again with different settings\n\t\t\t\tawait page.goto(\n\t\t\t\t\t'https://mail.google.com',\n\t\t\t\t\twait_until='commit',  # Less strict wait condition\n\t\t\t\t\ttimeout=30000,\n\t\t\t\t)\n\n\t\t\t# Wait for the page to stabilize\n\t\t\tawait asyncio.sleep(2)\n\n\t\t\tprint(f'Current page title: {await page.title()}')\n\n\t\t\t# Optional: wait for specific Gmail elements\n\t\t\ttry:\n\t\t\t\tawait page.wait_for_selector('div[role=\"main\"]', timeout=5000)\n\t\t\t\tprint('Gmail interface detected')\n\t\t\texcept Exception as e:\n\t\t\t\tprint(f'Note: Gmail interface not detected: {e}')\n\n\t\t\tawait asyncio.sleep(30)\n\t\texcept Exception as e:\n\t\t\tprint(f'An error occurred: {e}')\n\t\t\timport traceback\n\n\t\t\ttraceback.print_exc()\n\t\tfinally:\n\t\t\tawait browser.close()\n\n\nif __name__ == '__main__':\n\tasyncio.run(test_full_screen(False, False))\n"}
{"type": "test_file", "path": "browser-use/tests/test_self_registered_actions.py", "content": "import asyncio\nimport os\n\nimport pytest\nfrom langchain_openai import AzureChatOpenAI\nfrom pydantic import BaseModel, SecretStr\n\nfrom browser_use.agent.service import Agent\nfrom browser_use.agent.views import AgentHistoryList\nfrom browser_use.browser.browser import Browser, BrowserConfig\nfrom browser_use.controller.service import Controller\n\n\n@pytest.fixture(scope='session')\ndef event_loop():\n\tloop = asyncio.get_event_loop_policy().new_event_loop()\n\tyield loop\n\tloop.close()\n\n\n@pytest.fixture(scope='session')\nasync def browser(event_loop):\n\tbrowser_instance = Browser(\n\t\tconfig=BrowserConfig(\n\t\t\theadless=True,\n\t\t)\n\t)\n\tyield browser_instance\n\tawait browser_instance.close()\n\n\n@pytest.fixture\nasync def context(browser):\n\tasync with await browser.new_context() as context:\n\t\tyield context\n\n\n@pytest.fixture\nasync def controller():\n\t\"\"\"Initialize the controller with self-registered actions\"\"\"\n\tcontroller = Controller()\n\n\t# Define custom actions without Pydantic models\n\t@controller.action('Print a message')\n\tdef print_message(message: str):\n\t\tprint(f'Message: {message}')\n\t\treturn f'Printed message: {message}'\n\n\t@controller.action('Add two numbers')\n\tdef add_numbers(a: int, b: int):\n\t\tresult = a + b\n\t\treturn f'The sum is {result}'\n\n\t@controller.action('Concatenate strings')\n\tdef concatenate_strings(str1: str, str2: str):\n\t\tresult = str1 + str2\n\t\treturn f'Concatenated string: {result}'\n\n\t# Define Pydantic models\n\tclass SimpleModel(BaseModel):\n\t\tname: str\n\t\tage: int\n\n\tclass Address(BaseModel):\n\t\tstreet: str\n\t\tcity: str\n\n\tclass NestedModel(BaseModel):\n\t\tuser: SimpleModel\n\t\taddress: Address\n\n\t# Add actions with Pydantic model arguments\n\t@controller.action('Process simple model', param_model=SimpleModel)\n\tdef process_simple_model(model: SimpleModel):\n\t\treturn f'Processed {model.name}, age {model.age}'\n\n\t@controller.action('Process nested model', param_model=NestedModel)\n\tdef process_nested_model(model: NestedModel):\n\t\tuser_info = f'{model.user.name}, age {model.user.age}'\n\t\taddress_info = f'{model.address.street}, {model.address.city}'\n\t\treturn f'Processed user {user_info} at address {address_info}'\n\n\t@controller.action('Process multiple models')\n\tdef process_multiple_models(model1: SimpleModel, model2: Address):\n\t\treturn f'Processed {model1.name} living at {model2.street}, {model2.city}'\n\n\tyield controller\n\n\n@pytest.fixture\ndef llm():\n\t\"\"\"Initialize language model for testing\"\"\"\n\n\t# return ChatAnthropic(model_name='claude-3-5-sonnet-20240620', timeout=25, stop=None)\n\treturn AzureChatOpenAI(\n\t\tmodel='gpt-4o',\n\t\tapi_version='2024-10-21',\n\t\tazure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),\n\t\tapi_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),\n\t)\n\n\n# @pytest.mark.skip(reason=\"Skipping test for now\")\n@pytest.mark.asyncio\nasync def test_self_registered_actions_no_pydantic(llm, controller):\n\t\"\"\"Test self-registered actions with individual arguments\"\"\"\n\tagent = Agent(\n\t\ttask=\"First, print the message 'Hello, World!'. Then, add 10 and 20. Next, concatenate 'foo' and 'bar'.\",\n\t\tllm=llm,\n\t\tcontroller=controller,\n\t)\n\thistory: AgentHistoryList = await agent.run(max_steps=10)\n\t# Check that custom actions were executed\n\taction_names = history.action_names()\n\n\tassert 'print_message' in action_names\n\tassert 'add_numbers' in action_names\n\tassert 'concatenate_strings' in action_names\n\n\n# @pytest.mark.skip(reason=\"Skipping test for now\")\n@pytest.mark.asyncio\nasync def test_mixed_arguments_actions(llm, controller):\n\t\"\"\"Test actions with mixed argument types\"\"\"\n\n\t# Define another action during the test\n\t# Test for async actions\n\t@controller.action('Calculate the area of a rectangle')\n\tasync def calculate_area(length: float, width: float):\n\t\tarea = length * width\n\t\treturn f'The area is {area}'\n\n\tagent = Agent(\n\t\ttask='Calculate the area of a rectangle with length 5.5 and width 3.2.',\n\t\tllm=llm,\n\t\tcontroller=controller,\n\t)\n\thistory = await agent.run(max_steps=5)\n\n\t# Check that the action was executed\n\taction_names = history.action_names()\n\n\tassert 'calculate_area' in action_names\n\t# check result\n\tcorrect = 'The area is 17.6'\n\tfor content in history.extracted_content():\n\t\tif correct in content:\n\t\t\tbreak\n\telse:\n\t\tpytest.fail(f'{correct} not found in extracted content')\n\n\n@pytest.mark.asyncio\nasync def test_pydantic_simple_model(llm, controller):\n\t\"\"\"Test action with a simple Pydantic model argument\"\"\"\n\tagent = Agent(\n\t\ttask=\"Process a simple model with name 'Alice' and age 30.\",\n\t\tllm=llm,\n\t\tcontroller=controller,\n\t)\n\thistory = await agent.run(max_steps=5)\n\n\t# Check that the action was executed\n\taction_names = history.action_names()\n\n\tassert 'process_simple_model' in action_names\n\tcorrect = 'Processed Alice, age 30'\n\tfor content in history.extracted_content():\n\t\tif correct in content:\n\t\t\tbreak\n\telse:\n\t\tpytest.fail(f'{correct} not found in extracted content')\n\n\n@pytest.mark.asyncio\nasync def test_pydantic_nested_model(llm, controller):\n\t\"\"\"Test action with a nested Pydantic model argument\"\"\"\n\tagent = Agent(\n\t\ttask=\"Process a nested model with user name 'Bob', age 25, living at '123 Maple St', 'Springfield'.\",\n\t\tllm=llm,\n\t\tcontroller=controller,\n\t)\n\thistory = await agent.run(max_steps=5)\n\n\t# Check that the action was executed\n\taction_names = history.action_names()\n\n\tassert 'process_nested_model' in action_names\n\tcorrect = 'Processed user Bob, age 25 at address 123 Maple St, Springfield'\n\tfor content in history.extracted_content():\n\t\tif correct in content:\n\t\t\tbreak\n\telse:\n\t\tpytest.fail(f'{correct} not found in extracted content')\n\n\n# run this file with:\n# pytest tests/test_self_registered_actions.py --capture=no\n"}
{"type": "test_file", "path": "browser-use/tests/test_full_screen.py", "content": "import asyncio\n\nfrom playwright.async_api import async_playwright\n\n\nasync def test_full_screen(start_fullscreen: bool, maximize: bool):\n\tasync with async_playwright() as p:\n\t\tbrowser = await p.chromium.launch(\n\t\t\theadless=False,\n\t\t\targs=['--start-maximized'],\n\t\t)\n\t\tcontext = await browser.new_context(no_viewport=True, viewport=None)\n\t\tpage = await context.new_page()\n\t\tawait page.goto('https://google.com')\n\n\t\tawait asyncio.sleep(10)\n\t\tawait browser.close()\n\n\nif __name__ == '__main__':\n\tasyncio.run(test_full_screen(False, False))\n"}
{"type": "test_file", "path": "browser-use/tests/test_mind2web.py", "content": "\"\"\"\nTest browser automation using Mind2Web dataset tasks with pytest framework.\n\"\"\"\n\nimport asyncio\nimport json\nimport os\nfrom typing import Any, Dict, List\n\nimport pytest\nfrom langchain_openai import AzureChatOpenAI\nfrom pydantic import SecretStr\n\nfrom browser_use.agent.service import Agent\nfrom browser_use.browser.browser import Browser, BrowserConfig\nfrom browser_use.utils import logger\n\n# Constants\nMAX_STEPS = 50\nTEST_SUBSET_SIZE = 10\n\n\n@pytest.fixture(scope='session')\ndef event_loop():\n\tloop = asyncio.get_event_loop_policy().new_event_loop()\n\tyield loop\n\tloop.close()\n\n\n@pytest.fixture(scope='session')\nasync def browser(event_loop):\n\tbrowser_instance = Browser(\n\t\tconfig=BrowserConfig(\n\t\t\theadless=True,\n\t\t)\n\t)\n\tyield browser_instance\n\tawait browser_instance.close()\n\n\n@pytest.fixture\nasync def context(browser):\n\tasync with await browser.new_context() as new_context:\n\t\tyield new_context\n\n\n@pytest.fixture(scope='session')\ndef test_cases() -> List[Dict[str, Any]]:\n\t\"\"\"Load test cases from Mind2Web dataset\"\"\"\n\tfile_path = os.path.join(os.path.dirname(__file__), 'mind2web_data/processed.json')\n\tlogger.info(f'Loading test cases from {file_path}')\n\n\twith open(file_path, 'r') as f:\n\t\tdata = json.load(f)\n\n\tsubset = data[:TEST_SUBSET_SIZE]\n\tlogger.info(f'Loaded {len(subset)}/{len(data)} test cases')\n\treturn subset\n\n\n@pytest.fixture\ndef llm():\n\t\"\"\"Initialize language model for testing\"\"\"\n\n\t# return ChatAnthropic(model_name='claude-3-5-sonnet-20240620', timeout=25, stop=None)\n\treturn AzureChatOpenAI(\n\t\tmodel='gpt-4o',\n\t\tapi_version='2024-10-21',\n\t\tazure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),\n\t\tapi_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),\n\t)\n\n\n# run with: pytest -s -v tests/test_mind2web.py:test_random_samples\n@pytest.mark.asyncio\nasync def test_random_samples(test_cases: List[Dict[str, Any]], llm, context, validator):\n\t\"\"\"Test a random sampling of tasks across different websites\"\"\"\n\timport random\n\n\tlogger.info('=== Testing Random Samples ===')\n\n\t# Take random samples\n\tsamples = random.sample(test_cases, 1)\n\n\tfor i, case in enumerate(samples, 1):\n\t\ttask = f\"Go to {case['website']}.com and {case['confirmed_task']}\"\n\t\tlogger.info(f'--- Random Sample {i}/{len(samples)} ---')\n\t\tlogger.info(f'Task: {task}\\n')\n\n\t\tagent = Agent(task, llm, browser_context=context)\n\n\t\tawait agent.run()\n\n\t\tlogger.info('Validating random sample task...')\n\n\t\t# TODO: Validate the task\n\n\ndef test_dataset_integrity(test_cases):\n\t\"\"\"Test the integrity of the test dataset\"\"\"\n\tlogger.info('\\n=== Testing Dataset Integrity ===')\n\n\trequired_fields = ['website', 'confirmed_task', 'action_reprs']\n\tmissing_fields = []\n\n\tlogger.info(f'Checking {len(test_cases)} test cases for required fields')\n\n\tfor i, case in enumerate(test_cases, 1):\n\t\tlogger.debug(f'Checking case {i}/{len(test_cases)}')\n\n\t\tfor field in required_fields:\n\t\t\tif field not in case:\n\t\t\t\tmissing_fields.append(f'Case {i}: {field}')\n\t\t\t\tlogger.warning(f\"Missing field '{field}' in case {i}\")\n\n\t\t# Type checks\n\t\tif not isinstance(case.get('confirmed_task'), str):\n\t\t\tlogger.error(f\"Case {i}: 'confirmed_task' must be string\")\n\t\t\tassert False, 'Task must be string'\n\n\t\tif not isinstance(case.get('action_reprs'), list):\n\t\t\tlogger.error(f\"Case {i}: 'action_reprs' must be list\")\n\t\t\tassert False, 'Actions must be list'\n\n\t\tif len(case.get('action_reprs', [])) == 0:\n\t\t\tlogger.error(f\"Case {i}: 'action_reprs' must not be empty\")\n\t\t\tassert False, 'Must have at least one action'\n\n\tif missing_fields:\n\t\tlogger.error('Dataset integrity check failed')\n\t\tassert False, f'Missing fields: {missing_fields}'\n\telse:\n\t\tlogger.info('✅ Dataset integrity check passed')\n\n\nif __name__ == '__main__':\n\tpytest.main([__file__, '-v'])\n"}
{"type": "test_file", "path": "browser-use/browser_use/dom/tests/extraction_test.py", "content": "import time\n\nfrom tokencost import count_string_tokens\n\nfrom browser_use.browser.browser import Browser, BrowserConfig\n\n# from browser_use.browser.service import Browser\nfrom browser_use.dom.service import DomService\nfrom browser_use.utils import time_execution_sync\n\n\n# @pytest.mark.skip(\"slow af\")\nasync def test_process_html_file():\n\tbrowser = Browser(config=BrowserConfig(headless=False))\n\n\tasync with await browser.new_context() as context:\n\t\tpage = await context.get_current_page()\n\n\t\tdom_service = DomService(page)\n\n\t\t# await page.goto('https://kayak.com/flights')\n\t\t# browser.go_to_url('https://google.com/flights')\n\t\tawait page.goto('https://immobilienscout24.de')\n\n\t\ttime.sleep(3)\n\t\t# browser._click_element_by_xpath(\n\t\t# \t'/html/body/div[5]/div/div[2]/div/div/div[3]/div/div[1]/button[1]'\n\t\t# )\n\t\t# browser._click_element_by_xpath(\"//button[div/div[text()='Alle akzeptieren']]\")\n\n\t\tdom_state = await time_execution_sync('get_clickable_elements')(\n\t\t\tdom_service.get_clickable_elements\n\t\t)()\n\t\telements = dom_state.element_tree\n\t\tselector_map = dom_state.selector_map\n\n\t\tprint(elements.clickable_elements_to_string())\n\t\tprint(\n\t\t\t'Tokens:', count_string_tokens(elements.clickable_elements_to_string(), model='gpt-4o')\n\t\t)\n\t\tprint(len(selector_map.keys()), 'elements highlighted')\n\n\t\tinput('Press Enter to continue...')\n"}
{"type": "test_file", "path": "browser-use/tests/test_dropdown.py", "content": "\"\"\"\nSimple try of the agent.\n\n@dev You need to add OPENAI_API_KEY to your environment variables.\n\"\"\"\n\nimport os\nimport sys\n\nfrom browser_use.browser.browser import Browser, BrowserConfig\nfrom browser_use.browser.context import BrowserContext\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom langchain_openai import ChatOpenAI\n\nfrom browser_use import Agent, AgentHistoryList\n\nllm = ChatOpenAI(model='gpt-4o')\n# browser = Browser(config=BrowserConfig(headless=False))\n\nagent = Agent(\n\ttask=(\n\t\t'go to https://codepen.io/geheimschriftstift/pen/mPLvQz and first get all options for the dropdown and then select the 5th option'\n\t),\n\tllm=llm,\n\tbrowser_context=BrowserContext(\n\t\tbrowser=Browser(config=BrowserConfig(headless=False, disable_security=True)),\n\t),\n)\n\n\nasync def test_dropdown():\n\thistory: AgentHistoryList = await agent.run(20)\n\t# await controller.browser.close(force=True)\n\n\tresult = history.final_result()\n\tassert result is not None\n\tassert 'Duck' in result\n\t# await browser.close()\n"}
{"type": "test_file", "path": "browser-use/tests/test_dropdown_complex.py", "content": "\"\"\"\nSimple try of the agent.\n\n@dev You need to add OPENAI_API_KEY to your environment variables.\n\"\"\"\n\nimport os\nimport sys\n\nfrom browser_use.browser.browser import Browser, BrowserConfig\nfrom browser_use.browser.context import BrowserContext\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom langchain_openai import ChatOpenAI\n\nfrom browser_use import Agent, AgentHistoryList\n\nllm = ChatOpenAI(model='gpt-4o')\n# browser = Browser(config=BrowserConfig(headless=False))\n\nagent = Agent(\n\ttask=(\n\t\t'go to https://codepen.io/shyam-king/pen/pvzpByJ and first get all options for the dropdown and then select the json option'\n\t),\n\tllm=llm,\n\tbrowser_context=BrowserContext(\n\t\tbrowser=Browser(config=BrowserConfig(headless=False, disable_security=True)),\n\t),\n)\n\n\nasync def test_dropdown():\n\thistory: AgentHistoryList = await agent.run(20)\n\t# await controller.browser.close(force=True)\n\n\tresult = history.final_result()\n\tassert result is not None\n\t# await browser.close()\n"}
{"type": "test_file", "path": "browser-use/tests/test_core_functionality.py", "content": "import asyncio\nimport os\n\nimport pytest\nfrom langchain_openai import AzureChatOpenAI\nfrom pydantic import SecretStr\n\nfrom browser_use.agent.service import Agent\nfrom browser_use.agent.views import AgentHistoryList\nfrom browser_use.browser.browser import Browser, BrowserConfig\n\n\n@pytest.fixture(scope='function')\ndef event_loop():\n\t\"\"\"Create an instance of the default event loop for each test case.\"\"\"\n\tloop = asyncio.get_event_loop_policy().new_event_loop()\n\tyield loop\n\tloop.close()\n\n\n@pytest.fixture(scope='function')\nasync def browser(event_loop):\n\tbrowser_instance = Browser(\n\t\tconfig=BrowserConfig(\n\t\t\theadless=True,\n\t\t)\n\t)\n\tyield browser_instance\n\tawait browser_instance.close()\n\n\n@pytest.fixture\nasync def context(browser):\n\tasync with await browser.new_context() as context:\n\t\tyield context\n\n\n@pytest.fixture\ndef llm():\n\t\"\"\"Initialize language model for testing\"\"\"\n\treturn AzureChatOpenAI(\n\t\tmodel='gpt-4o',\n\t\tapi_version='2024-10-21',\n\t\tazure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),\n\t\tapi_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),\n\t)\n\n\n# pytest -s -k test_search_google\n@pytest.mark.asyncio\nasync def test_search_google(llm, context):\n\t\"\"\"Test 'Search Google' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Search Google for 'OpenAI'.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\thistory: AgentHistoryList = await agent.run(max_steps=2)\n\taction_names = history.action_names()\n\tassert 'search_google' in action_names\n\n\n@pytest.mark.asyncio\nasync def test_go_to_url(llm, context):\n\t\"\"\"Test 'Navigate to URL' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Navigate to 'https://www.python.org'.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\thistory = await agent.run(max_steps=2)\n\taction_names = history.action_names()\n\tassert 'go_to_url' in action_names\n\n\n@pytest.mark.asyncio\nasync def test_go_back(llm, context):\n\t\"\"\"Test 'Go back' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Go to 'https://www.example.com', then go back.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\thistory = await agent.run(max_steps=3)\n\taction_names = history.action_names()\n\tassert 'go_to_url' in action_names\n\tassert 'go_back' in action_names\n\n\n@pytest.mark.asyncio\nasync def test_click_element(llm, context):\n\t\"\"\"Test 'Click element' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Go to 'https://www.python.org' and click on the first link.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\thistory = await agent.run(max_steps=4)\n\taction_names = history.action_names()\n\tassert 'go_to_url' in action_names or 'open_tab' in action_names\n\tassert 'click_element' in action_names\n\n\n@pytest.mark.asyncio\nasync def test_input_text(llm, context):\n\t\"\"\"Test 'Input text' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Go to 'https://www.google.com' and input 'OpenAI' into the search box.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\thistory = await agent.run(max_steps=4)\n\taction_names = history.action_names()\n\tassert 'go_to_url' in action_names\n\tassert 'input_text' in action_names\n\n\n@pytest.mark.asyncio\nasync def test_switch_tab(llm, context):\n\t\"\"\"Test 'Switch tab' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Open new tabs with 'https://www.google.com' and 'https://www.wikipedia.org', then switch to the first tab.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\thistory = await agent.run(max_steps=6)\n\taction_names = history.action_names()\n\topen_tab_count = action_names.count('open_tab')\n\tassert open_tab_count >= 2\n\tassert 'switch_tab' in action_names\n\n\n@pytest.mark.asyncio\nasync def test_open_new_tab(llm, context):\n\t\"\"\"Test 'Open new tab' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Open a new tab and go to 'https://www.example.com'.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\thistory = await agent.run(max_steps=3)\n\taction_names = history.action_names()\n\tassert 'open_tab' in action_names\n\n\n@pytest.mark.asyncio\nasync def test_extract_page_content(llm, context):\n\t\"\"\"Test 'Extract page content' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Go to 'https://www.example.com' and extract the page content.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\thistory = await agent.run(max_steps=3)\n\taction_names = history.action_names()\n\tassert 'go_to_url' in action_names\n\tassert 'extract_content' in action_names\n\n\n# pytest -k test_done_action\n@pytest.mark.asyncio\nasync def test_done_action(llm, context):\n\t\"\"\"Test 'Complete task' action\"\"\"\n\tagent = Agent(\n\t\ttask=\"Navigate to 'https://www.example.com' and signal that the task is done.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\n\thistory = await agent.run(max_steps=3)\n\taction_names = history.action_names()\n\tassert 'go_to_url' in action_names\n\tassert 'done' in action_names\n\n\n# run with: pytest -k test_scroll_down\n@pytest.mark.asyncio\nasync def test_scroll_down(llm, context):\n\t\"\"\"Test 'Scroll down' action and validate that the page actually scrolled\"\"\"\n\tagent = Agent(\n\t\ttask=\"Go to 'https://en.wikipedia.org/wiki/Internet' and scroll down the page.\",\n\t\tllm=llm,\n\t\tbrowser_context=context,\n\t)\n\t# Get the browser instance\n\tpage = await context.get_current_page()\n\n\t# Navigate to the page and get initial scroll position\n\tawait agent.run(max_steps=1)\n\tinitial_scroll_position = await page.evaluate('window.scrollY;')\n\n\t# Perform the scroll down action\n\tawait agent.run(max_steps=2)\n\tfinal_scroll_position = await page.evaluate('window.scrollY;')\n\n\t# Validate that the scroll position has changed\n\tassert final_scroll_position > initial_scroll_position, 'Page did not scroll down'\n\n\t# Validate that the 'scroll_down' action was executed\n\thistory = agent.history\n\taction_names = history.action_names()\n\tassert 'scroll_down' in action_names\n"}
{"type": "test_file", "path": "browser-use/browser_use/browser/tests/test_clicks.py", "content": "import asyncio\nimport json\n\nimport pytest\n\nfrom browser_use.browser.browser import Browser, BrowserConfig\nfrom browser_use.dom.views import ElementTreeSerializer\nfrom browser_use.utils import time_execution_sync\n\n\n# run with: pytest browser_use/browser/tests/test_clicks.py\n@pytest.mark.asyncio\nasync def test_highlight_elements():\n\tbrowser = Browser(config=BrowserConfig(headless=False, disable_security=True))\n\n\tasync with await browser.new_context() as context:\n\t\tpage = await context.get_current_page()\n\t\t# await page.goto('https://immobilienscout24.de')\n\t\t# await page.goto('https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/service-plans')\n\t\t# await page.goto('https://google.com/search?q=elon+musk')\n\t\t# await page.goto('https://kayak.com')\n\t\t# await page.goto('https://www.w3schools.com/tags/tryit.asp?filename=tryhtml_iframe')\n\t\t# await page.goto('https://dictionary.cambridge.org')\n\t\t# await page.goto('https://github.com')\n\t\tawait page.goto('https://huggingface.co/')\n\n\t\tawait asyncio.sleep(1)\n\n\t\twhile True:\n\t\t\ttry:\n\t\t\t\t# await asyncio.sleep(10)\n\t\t\t\tstate = await context.get_state()\n\n\t\t\t\twith open('./tmp/page.json', 'w') as f:\n\t\t\t\t\tjson.dump(\n\t\t\t\t\t\tElementTreeSerializer.dom_element_node_to_json(state.element_tree),\n\t\t\t\t\t\tf,\n\t\t\t\t\t\tindent=1,\n\t\t\t\t\t)\n\n\t\t\t\t# await time_execution_sync('highlight_selector_map_elements')(\n\t\t\t\t# \tbrowser.highlight_selector_map_elements\n\t\t\t\t# )(state.selector_map)\n\n\t\t\t\t# Find and print duplicate XPaths\n\t\t\t\txpath_counts = {}\n\t\t\t\tif not state.selector_map:\n\t\t\t\t\tcontinue\n\t\t\t\tfor selector in state.selector_map.values():\n\t\t\t\t\txpath = selector.xpath\n\t\t\t\t\tif xpath in xpath_counts:\n\t\t\t\t\t\txpath_counts[xpath] += 1\n\t\t\t\t\telse:\n\t\t\t\t\t\txpath_counts[xpath] = 1\n\n\t\t\t\tprint('\\nDuplicate XPaths found:')\n\t\t\t\tfor xpath, count in xpath_counts.items():\n\t\t\t\t\tif count > 1:\n\t\t\t\t\t\tprint(f'XPath: {xpath}')\n\t\t\t\t\t\tprint(f'Count: {count}\\n')\n\n\t\t\t\tprint(list(state.selector_map.keys()), 'Selector map keys')\n\t\t\t\tprint(state.element_tree.clickable_elements_to_string())\n\t\t\t\taction = input('Select next action: ')\n\n\t\t\t\tawait time_execution_sync('remove_highlight_elements')(context.remove_highlights)()\n\n\t\t\t\tnode_element = state.selector_map[int(action)]\n\n\t\t\t\t# check if index of selector map are the same as index of items in dom_items\n\n\t\t\t\tawait context._click_element_node(node_element)\n\n\t\t\texcept Exception as e:\n\t\t\t\tprint(e)\n"}
{"type": "test_file", "path": "browser-use/tests/test_vision.py", "content": "\"\"\"\nSimple try of the agent.\n\n@dev You need to add OPENAI_API_KEY to your environment variables.\n\"\"\"\n\nimport os\nimport sys\nfrom pprint import pprint\n\nimport pytest\n\nfrom browser_use.browser.browser import Browser, BrowserConfig\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom langchain_openai import ChatOpenAI\n\nfrom browser_use import Agent, AgentHistoryList, Controller\n\nllm = ChatOpenAI(model='gpt-4o')\ncontroller = Controller()\n\n# use this test to ask the model questions about the page like\n# which color do you see for bbox labels, list all with their label\n# whats the smallest bboxes with labels and\n\n\n@controller.registry.action(description='explain what you see on the screen and ask user for input')\nasync def explain_screen(text: str) -> str:\n\tpprint(text)\n\tanswer = input('\\nuser input next question: \\n')\n\treturn answer\n\n\n@controller.registry.action(description='done')\nasync def done(text: str) -> str:\n\t# pprint(text)\n\treturn 'call explain_screen'\n\n\nagent = Agent(\n\ttask='call explain_screen all the time the user asks you questions e.g. about the page like bbox which you see are labels  - your task is to expalin it and get the next question',\n\tllm=llm,\n\tcontroller=controller,\n\tbrowser=Browser(config=BrowserConfig(disable_security=True, headless=False)),\n)\n\n\n@pytest.mark.skip(reason='this is for local testing only')\nasync def test_vision():\n\thistory: AgentHistoryList = await agent.run(20)\n"}
{"type": "test_file", "path": "tests/test_mimicflow.py", "content": "from mimicflow import example_function\n\n\ndef test_example_function():\n    assert example_function() == 2\n"}
{"type": "source_file", "path": "browser-use/browser_use/dom/views.py", "content": "from dataclasses import dataclass\nfrom functools import cached_property\nfrom typing import TYPE_CHECKING, Dict, List, Optional\n\nfrom browser_use.dom.history_tree_processor.view import HashedDomElement\n\n# Avoid circular import issues\nif TYPE_CHECKING:\n\tfrom .views import DOMElementNode\n\n\n@dataclass(frozen=False)\nclass DOMBaseNode:\n\tis_visible: bool\n\t# Use None as default and set parent later to avoid circular reference issues\n\tparent: Optional['DOMElementNode']\n\n\n@dataclass(frozen=False)\nclass DOMTextNode(DOMBaseNode):\n\ttext: str\n\ttype: str = 'TEXT_NODE'\n\n\tdef has_parent_with_highlight_index(self) -> bool:\n\t\tcurrent = self.parent\n\t\twhile current is not None:\n\t\t\tif current.highlight_index is not None:\n\t\t\t\treturn True\n\t\t\tcurrent = current.parent\n\t\treturn False\n\n\n@dataclass(frozen=False)\nclass DOMElementNode(DOMBaseNode):\n\t\"\"\"\n\txpath: the xpath of the element from the last root node (shadow root or iframe OR document if no shadow root or iframe).\n\tTo properly reference the element we need to recursively switch the root node until we find the element (work you way up the tree with `.parent`)\n\t\"\"\"\n\n\ttag_name: str\n\txpath: str\n\tattributes: Dict[str, str]\n\tchildren: List[DOMBaseNode]\n\tis_interactive: bool = False\n\tis_top_element: bool = False\n\tshadow_root: bool = False\n\thighlight_index: Optional[int] = None\n\n\tdef __repr__(self) -> str:\n\t\ttag_str = f'<{self.tag_name}'\n\n\t\t# Add attributes\n\t\tfor key, value in self.attributes.items():\n\t\t\ttag_str += f' {key}=\"{value}\"'\n\t\ttag_str += '>'\n\n\t\t# Add extra info\n\t\textras = []\n\t\tif self.is_interactive:\n\t\t\textras.append('interactive')\n\t\tif self.is_top_element:\n\t\t\textras.append('top')\n\t\tif self.shadow_root:\n\t\t\textras.append('shadow-root')\n\t\tif self.highlight_index is not None:\n\t\t\textras.append(f'highlight:{self.highlight_index}')\n\n\t\tif extras:\n\t\t\ttag_str += f' [{\", \".join(extras)}]'\n\n\t\treturn tag_str\n\n\t@cached_property\n\tdef hash(self) -> HashedDomElement:\n\t\tfrom browser_use.dom.history_tree_processor.service import (\n\t\t\tHistoryTreeProcessor,\n\t\t)\n\n\t\treturn HistoryTreeProcessor._hash_dom_element(self)\n\n\tdef get_all_text_till_next_clickable_element(self, max_depth: int = -1) -> str:\n\t\ttext_parts = []\n\n\t\tdef collect_text(node: DOMBaseNode, current_depth: int) -> None:\n\t\t\tif max_depth != -1 and current_depth > max_depth:\n\t\t\t\treturn\n\n\t\t\t# Skip this branch if we hit a highlighted element (except for the current node)\n\t\t\tif (\n\t\t\t\tisinstance(node, DOMElementNode)\n\t\t\t\tand node != self\n\t\t\t\tand node.highlight_index is not None\n\t\t\t):\n\t\t\t\treturn\n\n\t\t\tif isinstance(node, DOMTextNode):\n\t\t\t\ttext_parts.append(node.text)\n\t\t\telif isinstance(node, DOMElementNode):\n\t\t\t\tfor child in node.children:\n\t\t\t\t\tcollect_text(child, current_depth + 1)\n\n\t\tcollect_text(self, 0)\n\t\treturn '\\n'.join(text_parts).strip()\n\n\tdef clickable_elements_to_string(self, include_attributes: list[str] = []) -> str:\n\t\t\"\"\"Convert the processed DOM content to HTML.\"\"\"\n\t\tformatted_text = []\n\n\t\tdef process_node(node: DOMBaseNode, depth: int) -> None:\n\t\t\tif isinstance(node, DOMElementNode):\n\t\t\t\t# Add element with highlight_index\n\t\t\t\tif node.highlight_index is not None:\n\t\t\t\t\tattributes_str = ''\n\t\t\t\t\tif include_attributes:\n\t\t\t\t\t\tattributes_str = ' ' + ' '.join(\n\t\t\t\t\t\t\tf'{key}=\"{value}\"'\n\t\t\t\t\t\t\tfor key, value in node.attributes.items()\n\t\t\t\t\t\t\tif key in include_attributes\n\t\t\t\t\t\t)\n\t\t\t\t\tformatted_text.append(\n\t\t\t\t\t\tf'{node.highlight_index}[:]<{node.tag_name}{attributes_str}>{node.get_all_text_till_next_clickable_element()}</{node.tag_name}>'\n\t\t\t\t\t)\n\n\t\t\t\t# Process children regardless\n\t\t\t\tfor child in node.children:\n\t\t\t\t\tprocess_node(child, depth + 1)\n\n\t\t\telif isinstance(node, DOMTextNode):\n\t\t\t\t# Add text only if it doesn't have a highlighted parent\n\t\t\t\tif not node.has_parent_with_highlight_index():\n\t\t\t\t\tformatted_text.append(f'_[:]{node.text}')\n\n\t\tprocess_node(self, 0)\n\t\treturn '\\n'.join(formatted_text)\n\n\tdef get_file_upload_element(self, check_siblings: bool = True) -> Optional['DOMElementNode']:\n\t\t# Check if current element is a file input\n\t\tif self.tag_name == 'input' and self.attributes.get('type') == 'file':\n\t\t\treturn self\n\n\t\t# Check children\n\t\tfor child in self.children:\n\t\t\tif isinstance(child, DOMElementNode):\n\t\t\t\tresult = child.get_file_upload_element(check_siblings=False)\n\t\t\t\tif result:\n\t\t\t\t\treturn result\n\n\t\t# Check siblings only for the initial call\n\t\tif check_siblings and self.parent:\n\t\t\tfor sibling in self.parent.children:\n\t\t\t\tif sibling is not self and isinstance(sibling, DOMElementNode):\n\t\t\t\t\tresult = sibling.get_file_upload_element(check_siblings=False)\n\t\t\t\t\tif result:\n\t\t\t\t\t\treturn result\n\n\t\treturn None\n\n\nclass ElementTreeSerializer:\n\t@staticmethod\n\tdef serialize_clickable_elements(element_tree: DOMElementNode) -> str:\n\t\treturn element_tree.clickable_elements_to_string()\n\n\t@staticmethod\n\tdef dom_element_node_to_json(element_tree: DOMElementNode) -> dict:\n\t\tdef node_to_dict(node: DOMBaseNode) -> dict:\n\t\t\tif isinstance(node, DOMTextNode):\n\t\t\t\treturn {'type': 'text', 'text': node.text}\n\t\t\telif isinstance(node, DOMElementNode):\n\t\t\t\treturn {\n\t\t\t\t\t'type': 'element',\n\t\t\t\t\t'tag_name': node.tag_name,\n\t\t\t\t\t'attributes': node.attributes,\n\t\t\t\t\t'highlight_index': node.highlight_index,\n\t\t\t\t\t'children': [node_to_dict(child) for child in node.children],\n\t\t\t\t}\n\t\t\treturn {}\n\n\t\treturn node_to_dict(element_tree)\n\n\nSelectorMap = dict[int, DOMElementNode]\n\n\n@dataclass\nclass DOMState:\n\telement_tree: DOMElementNode\n\tselector_map: SelectorMap\n"}
{"type": "source_file", "path": "browser-use/browser_use/__init__.py", "content": "from browser_use.logging_config import setup_logging\n\nsetup_logging()\n\nfrom browser_use.agent.prompts import SystemPrompt as SystemPrompt\nfrom browser_use.agent.service import Agent as Agent\nfrom browser_use.agent.views import ActionModel as ActionModel\nfrom browser_use.agent.views import ActionResult as ActionResult\nfrom browser_use.agent.views import AgentHistoryList as AgentHistoryList\nfrom browser_use.browser.browser import Browser as Browser\nfrom browser_use.browser.browser import BrowserConfig as BrowserConfig\nfrom browser_use.controller.service import Controller as Controller\nfrom browser_use.dom.service import DomService as DomService\n\n__all__ = [\n\t'Agent',\n\t'Browser',\n\t'BrowserConfig',\n\t'Controller',\n\t'DomService',\n\t'SystemPrompt',\n\t'ActionResult',\n\t'ActionModel',\n\t'AgentHistoryList',\n]\n"}
{"type": "source_file", "path": "browser-use/browser_use/agent/service.py", "content": "from __future__ import annotations\n\nimport asyncio\nimport base64\nimport io\nimport json\nimport logging\nimport os\nimport platform\nimport textwrap\nimport time\nimport uuid\nfrom io import BytesIO\nfrom pathlib import Path\nfrom typing import Any, Optional, Type, TypeVar, List\n\nfrom dotenv import load_dotenv\nfrom langchain_core.language_models.chat_models import BaseChatModel\nfrom langchain_core.messages import (\n\tBaseMessage,\n\tSystemMessage,\n)\nfrom openai import RateLimitError\nfrom PIL import Image, ImageDraw, ImageFont\nfrom pydantic import BaseModel, ValidationError\n\nfrom browser_use.agent.message_manager.service import MessageManager\nfrom browser_use.agent.prompts import AgentMessagePrompt, SystemPrompt\nfrom browser_use.agent.views import (\n\tActionResult,\n\tAgentError,\n\tAgentHistory,\n\tAgentHistoryList,\n\tAgentOutput,\n\tAgentStepInfo,\n)\nfrom browser_use.browser.browser import Browser\nfrom browser_use.browser.context import BrowserContext\nfrom browser_use.browser.views import BrowserState, BrowserStateHistory\nfrom browser_use.controller.registry.views import ActionModel\nfrom browser_use.controller.service import Controller\nfrom browser_use.dom.history_tree_processor.service import (\n\tDOMHistoryElement,\n\tHistoryTreeProcessor,\n)\nfrom browser_use.telemetry.service import ProductTelemetry\nfrom browser_use.telemetry.views import (\n\tAgentEndTelemetryEvent,\n\tAgentRunTelemetryEvent,\n\tAgentStepTelemetryEvent,\n)\nfrom browser_use.utils import time_execution_async\n\nload_dotenv()\nlogger = logging.getLogger(__name__)\n\nT = TypeVar('T', bound=BaseModel)\n\n\nclass Agent:\n\tdef __init__(\n\t\tself,\n\t\ttask: str,\n\t\tllm: BaseChatModel,\n\t\tbrowser: Browser | None = None,\n\t\tbrowser_context: BrowserContext | None = None,\n\t\tcontroller: Controller = Controller(),\n\t\tuse_vision: bool = True,\n\t\tsave_conversation_path: Optional[str] = None,\n\t\tsave_conversation_path_encoding: Optional[str] = 'utf-8',\n\t\tmax_failures: int = 3,\n\t\tretry_delay: int = 10,\n\t\tsystem_prompt_class: Type[SystemPrompt] = SystemPrompt,\n\t\tmax_input_tokens: int = 128000,\n\t\tvalidate_output: bool = False,\n\t\tgenerate_gif: bool = True,\n\t\tinclude_attributes: list[str] = [\n\t\t\t'title',\n\t\t\t'type',\n\t\t\t'name',\n\t\t\t'role',\n\t\t\t'tabindex',\n\t\t\t'aria-label',\n\t\t\t'placeholder',\n\t\t\t'value',\n\t\t\t'alt',\n\t\t\t'aria-expanded',\n\t\t],\n\t\tmax_error_length: int = 400,\n\t\tmax_actions_per_step: int = 10,\n\t\ttool_call_in_content: bool = True,\n\t):\n\t\tself.agent_id = str(uuid.uuid4())  # unique identifier for the agent\n\n\t\tself.task = task\n\t\tself.use_vision = use_vision\n\t\tself.llm = llm\n\t\tself.save_conversation_path = save_conversation_path\n\t\tself.save_conversation_path_encoding = save_conversation_path_encoding\n\t\tself._last_result = None\n\t\tself.include_attributes = include_attributes\n\t\tself.max_error_length = max_error_length\n\t\tself.generate_gif = generate_gif\n\t\t# Controller setup\n\t\tself.controller = controller\n\t\tself.max_actions_per_step = max_actions_per_step\n\n\t\tself.current_states: List[AgentMessagePrompt] = []\n\n\t\t# Browser setup\n\t\tself.injected_browser = browser is not None\n\t\tself.injected_browser_context = browser_context is not None\n\n\t\t# Initialize browser first if needed\n\t\tself.browser = browser if browser is not None else (None if browser_context else Browser())\n\n\t\t# Initialize browser context\n\t\tif browser_context:\n\t\t\tself.browser_context = browser_context\n\t\telif self.browser:\n\t\t\tself.browser_context = BrowserContext(\n\t\t\t\tbrowser=self.browser, config=self.browser.config.new_context_config\n\t\t\t)\n\t\telse:\n\t\t\t# If neither is provided, create both new\n\t\t\tself.browser = Browser()\n\t\t\tself.browser_context = BrowserContext(browser=self.browser)\n\n\t\tself.system_prompt_class = system_prompt_class\n\n\t\t# Telemetry setup\n\t\tself.telemetry = ProductTelemetry()\n\n\t\t# Action and output models setup\n\t\tself._setup_action_models()\n\n\t\tself.max_input_tokens = max_input_tokens\n\t\tself.tool_call_in_content = tool_call_in_content\n\n\t\tself.message_manager = MessageManager(\n\t\t\tllm=self.llm,\n\t\t\ttask=self.task,\n\t\t\taction_descriptions=self.controller.registry.get_prompt_description(),\n\t\t\tsystem_prompt_class=self.system_prompt_class,\n\t\t\tmax_input_tokens=self.max_input_tokens,\n\t\t\tinclude_attributes=self.include_attributes,\n\t\t\tmax_error_length=self.max_error_length,\n\t\t\tmax_actions_per_step=self.max_actions_per_step,\n\t\t\ttool_call_in_content=tool_call_in_content,\n\t\t)\n\n\t\t# Tracking variables\n\t\tself.history: AgentHistoryList = AgentHistoryList(history=[])\n\t\tself.n_steps = 1\n\t\tself.consecutive_failures = 0\n\t\tself.max_failures = max_failures\n\t\tself.retry_delay = retry_delay\n\t\tself.validate_output = validate_output\n\n\t\tif save_conversation_path:\n\t\t\tlogger.info(f'Saving conversation to {save_conversation_path}')\n\n\tdef _setup_action_models(self) -> None:\n\t\t\"\"\"Setup dynamic action models from controller's registry\"\"\"\n\t\t# Get the dynamic action model from controller's registry\n\t\tself.ActionModel = self.controller.registry.create_action_model()\n\t\t# Create output model with the dynamic actions\n\t\tself.AgentOutput = AgentOutput.type_with_custom_actions(self.ActionModel)\n\n\t@time_execution_async('--step')\n\tasync def step(self, step_info: Optional[AgentStepInfo] = None) -> None:\n\t\t\"\"\"Execute one step of the task\"\"\"\n\t\tlogger.info(f'\\n📍 Step {self.n_steps}')\n\t\tstate = None\n\t\tmodel_output = None\n\t\tresult: list[ActionResult] = []\n\n\t\ttry:\n\t\t\tstate = await self.browser_context.get_state(use_vision=self.use_vision)\n\t\t\tagent_current_prompt = self.message_manager.add_state_message(\n\t\t\t\tstate, self._last_result, step_info\n\t\t\t).content\n\n\t\t\tself.current_states.append(agent_current_prompt)\n\t\t\tinput_messages = self.message_manager.get_messages()\n\t\t\ttry:\n\t\t\t\tmodel_output = await self.get_next_action(input_messages)\n\t\t\t\tself._save_conversation(input_messages, model_output)\n\t\t\t\tself.message_manager._remove_last_state_message()  # we dont want the whole state in the chat history\n\t\t\t\tself.message_manager.add_model_output(model_output)\n\t\t\texcept Exception as e:\n\t\t\t\t# model call failed, remove last state message from history\n\t\t\t\tself.message_manager._remove_last_state_message()\n\t\t\t\traise e\n\n\t\t\tresult: list[ActionResult] = await self.controller.multi_act(\n\t\t\t\tmodel_output.action, self.browser_context\n\t\t\t)\n\n\t\t\tself._last_result = result\n\n\t\t\tif len(result) > 0 and result[-1].is_done:\n\t\t\t\tlogger.info(f'📄 Result: {result[-1].extracted_content}')\n\n\t\t\tself.consecutive_failures = 0\n\n\t\texcept Exception as e:\n\t\t\tresult = self._handle_step_error(e)\n\t\t\tself._last_result = result\n\n\t\tfinally:\n\t\t\tactions = (\n\t\t\t\t[a.model_dump(exclude_unset=True) for a in model_output.action]\n\t\t\t\tif model_output\n\t\t\t\telse []\n\t\t\t)\n\t\t\tself.telemetry.capture(\n\t\t\t\tAgentStepTelemetryEvent(\n\t\t\t\t\tagent_id=self.agent_id,\n\t\t\t\t\tstep=self.n_steps,\n\t\t\t\t\tactions=actions,\n\t\t\t\t\tconsecutive_failures=self.consecutive_failures,\n\t\t\t\t\tstep_error=[r.error for r in result if r.error] if result else ['No result'],\n\t\t\t\t)\n\t\t\t)\n\t\t\tif not result:\n\t\t\t\treturn\n\n\t\t\tif state:\n\t\t\t\tself._make_history_item(model_output, state, result)\n\n\tdef _handle_step_error(self, error: Exception) -> list[ActionResult]:\n\t\t\"\"\"Handle all types of errors that can occur during a step\"\"\"\n\t\tinclude_trace = logger.isEnabledFor(logging.DEBUG)\n\t\terror_msg = AgentError.format_error(error, include_trace=include_trace)\n\t\tprefix = f'❌ Result failed {self.consecutive_failures + 1}/{self.max_failures} times:\\n '\n\n\t\tif isinstance(error, (ValidationError, ValueError)):\n\t\t\tlogger.error(f'{prefix}{error_msg}')\n\t\t\tif 'Max token limit reached' in error_msg:\n\t\t\t\t# cut tokens from history\n\t\t\t\tself.message_manager.max_input_tokens = self.max_input_tokens - 500\n\t\t\t\tlogger.info(\n\t\t\t\t\tf'Cutting tokens from history - new max input tokens: {self.message_manager.max_input_tokens}'\n\t\t\t\t)\n\t\t\t\tself.message_manager.cut_messages()\n\t\t\telif 'Could not parse response' in error_msg:\n\t\t\t\t# give model a hint how output should look like\n\t\t\t\terror_msg += '\\n\\nReturn a valid JSON object with the required fields.'\n\n\t\t\tself.consecutive_failures += 1\n\t\telif isinstance(error, RateLimitError):\n\t\t\tlogger.warning(f'{prefix}{error_msg}')\n\t\t\ttime.sleep(self.retry_delay)\n\t\t\tself.consecutive_failures += 1\n\t\telse:\n\t\t\tlogger.error(f'{prefix}{error_msg}')\n\t\t\tself.consecutive_failures += 1\n\n\t\treturn [ActionResult(error=error_msg, include_in_memory=True)]\n\n\tdef _make_history_item(\n\t\tself,\n\t\tmodel_output: AgentOutput | None,\n\t\tstate: BrowserState,\n\t\tresult: list[ActionResult],\n\t) -> None:\n\t\t\"\"\"Create and store history item\"\"\"\n\t\tinteracted_element = None\n\t\tlen_result = len(result)\n\n\t\tif model_output:\n\t\t\tinteracted_elements = AgentHistory.get_interacted_element(\n\t\t\t\tmodel_output, state.selector_map\n\t\t\t)\n\t\telse:\n\t\t\tinteracted_elements = [None]\n\n\t\tstate_history = BrowserStateHistory(\n\t\t\turl=state.url,\n\t\t\ttitle=state.title,\n\t\t\ttabs=state.tabs,\n\t\t\tinteracted_element=interacted_elements,\n\t\t\tscreenshot=state.screenshot,\n\t\t\tprompt=self.current_states[-1],\n\t\t)\n\n\t\thistory_item = AgentHistory(model_output=model_output, result=result, state=state_history)\n\n\t\tself.history.history.append(history_item)\n\n\t@time_execution_async('--get_next_action')\n\tasync def get_next_action(self, input_messages: list[BaseMessage]) -> AgentOutput:\n\t\t\"\"\"Get next action from LLM based on current state\"\"\"\n\n\t\tstructured_llm = self.llm.with_structured_output(self.AgentOutput, include_raw=True)\n\t\tresponse: dict[str, Any] = await structured_llm.ainvoke(input_messages)  # type: ignore\n\n\t\tparsed: AgentOutput = response['parsed']\n\t\tif parsed is None:\n\t\t\traise ValueError('Could not parse response.')\n\n\t\t# cut the number of actions to max_actions_per_step\n\t\tparsed.action = parsed.action[: self.max_actions_per_step]\n\t\tself._log_response(parsed)\n\t\tself.n_steps += 1\n\n\t\treturn parsed\n\n\tdef _log_response(self, response: AgentOutput) -> None:\n\t\t\"\"\"Log the model's response\"\"\"\n\t\tif 'Success' in response.current_state.evaluation_previous_goal:\n\t\t\temoji = '👍'\n\t\telif 'Failed' in response.current_state.evaluation_previous_goal:\n\t\t\temoji = '⚠'\n\t\telse:\n\t\t\temoji = '🤷'\n\n\t\tlogger.info(f'{emoji} Eval: {response.current_state.evaluation_previous_goal}')\n\t\tlogger.info(f'🧠 Memory: {response.current_state.memory}')\n\t\tlogger.info(f'🎯 Next goal: {response.current_state.next_goal}')\n\t\tfor i, action in enumerate(response.action):\n\t\t\tlogger.info(\n\t\t\t\tf'🛠️  Action {i + 1}/{len(response.action)}: {action.model_dump_json(exclude_unset=True)}'\n\t\t\t)\n\n\tdef _save_conversation(self, input_messages: list[BaseMessage], response: Any) -> None:\n\t\t\"\"\"Save conversation history to file if path is specified\"\"\"\n\t\tif not self.save_conversation_path:\n\t\t\treturn\n\n\t\t# create folders if not exists\n\t\tos.makedirs(os.path.dirname(self.save_conversation_path), exist_ok=True)\n\n\t\twith open(\n\t\t\tself.save_conversation_path + f'_{self.n_steps}.txt',\n\t\t\t'w',\n\t\t\tencoding=self.save_conversation_path_encoding,\n\t\t) as f:\n\t\t\tself._write_messages_to_file(f, input_messages)\n\t\t\tself._write_response_to_file(f, response)\n\n\tdef _write_messages_to_file(self, f: Any, messages: list[BaseMessage]) -> None:\n\t\t\"\"\"Write messages to conversation file\"\"\"\n\t\tfor message in messages:\n\t\t\tf.write(f' {message.__class__.__name__} \\n')\n\n\t\t\tif isinstance(message.content, list):\n\t\t\t\tfor item in message.content:\n\t\t\t\t\tif isinstance(item, dict) and item.get('type') == 'text':\n\t\t\t\t\t\tf.write(item['text'].strip() + '\\n')\n\t\t\telif isinstance(message.content, str):\n\t\t\t\ttry:\n\t\t\t\t\tcontent = json.loads(message.content)\n\t\t\t\t\tf.write(json.dumps(content, indent=2) + '\\n')\n\t\t\t\texcept json.JSONDecodeError:\n\t\t\t\t\tf.write(message.content.strip() + '\\n')\n\n\t\t\tf.write('\\n')\n\n\tdef _write_response_to_file(self, f: Any, response: Any) -> None:\n\t\t\"\"\"Write model response to conversation file\"\"\"\n\t\tf.write(' RESPONSE\\n')\n\t\tf.write(json.dumps(json.loads(response.model_dump_json(exclude_unset=True)), indent=2))\n\n\tdef _log_agent_run(self) -> None:\n\t\t\"\"\"Log the agent run\"\"\"\n\t\tlogger.info(f'🚀 Starting task: {self.task}')\n\t\t# model_name is eiter model or model_name\n\t\tif hasattr(self.llm, 'model_name'):\n\t\t\tmodel_name = self.llm.model_name  # type: ignore\n\t\telif hasattr(self.llm, 'model'):\n\t\t\tmodel_name = self.llm.model  # type: ignore\n\t\telse:\n\t\t\tmodel_name = 'Unknown'\n\n\t\ttry:\n\t\t\timport pkg_resources\n\n\t\t\tversion = pkg_resources.get_distribution('browser-use').version\n\t\t\tsource = 'pip'\n\t\texcept Exception:\n\t\t\ttry:\n\t\t\t\timport subprocess\n\n\t\t\t\tversion = (\n\t\t\t\t\tsubprocess.check_output(['git', 'describe', '--tags']).decode('utf-8').strip()\n\t\t\t\t)\n\t\t\t\tsource = 'git'\n\t\t\texcept Exception:\n\t\t\t\tversion = 'unknown'\n\t\t\t\tsource = 'unknown'\n\t\tlogger.debug(f'Version: {version}, Source: {source}')\n\t\tself.telemetry.capture(\n\t\t\tAgentRunTelemetryEvent(\n\t\t\t\tagent_id=self.agent_id,\n\t\t\t\tuse_vision=self.use_vision,\n\t\t\t\ttool_call_in_content=self.tool_call_in_content,\n\t\t\t\ttask=self.task,\n\t\t\t\tmodel_name=model_name,\n\t\t\t\tchat_model_library=self.llm.__class__.__name__,\n\t\t\t\tversion=version,\n\t\t\t\tsource=source,\n\t\t\t)\n\t\t)\n\n\tasync def run(self, max_steps: int = 100) -> AgentHistoryList:\n\t\t\"\"\"Execute the task with maximum number of steps\"\"\"\n\t\ttry:\n\t\t\tself._log_agent_run()\n\n\t\t\tfor step in range(max_steps):\n\t\t\t\tif self._too_many_failures():\n\t\t\t\t\tbreak\n\n\t\t\t\tawait self.step()\n\n\t\t\t\tif self.history.is_done():\n\t\t\t\t\tif (\n\t\t\t\t\t\tself.validate_output and step < max_steps - 1\n\t\t\t\t\t):  # if last step, we dont need to validate\n\t\t\t\t\t\tif not await self._validate_output():\n\t\t\t\t\t\t\tcontinue\n\n\t\t\t\t\tlogger.info('✅ Task completed successfully')\n\t\t\t\t\tbreak\n\t\t\telse:\n\t\t\t\tlogger.info('❌ Failed to complete task in maximum steps')\n\n\t\t\treturn self.history\n\n\t\tfinally:\n\t\t\tself.telemetry.capture(\n\t\t\t\tAgentEndTelemetryEvent(\n\t\t\t\t\tagent_id=self.agent_id,\n\t\t\t\t\tsuccess=self.history.is_done(),\n\t\t\t\t\tsteps=self.n_steps,\n\t\t\t\t\tmax_steps_reached=self.n_steps >= max_steps,\n\t\t\t\t\terrors=self.history.errors(),\n\t\t\t\t)\n\t\t\t)\n\t\t\tif not self.injected_browser_context:\n\t\t\t\tawait self.browser_context.close()\n\n\t\t\tif not self.injected_browser and self.browser:\n\t\t\t\tawait self.browser.close()\n\n\t\t\tif self.generate_gif:\n\t\t\t\tself.create_history_gif()\n\n\tdef _too_many_failures(self) -> bool:\n\t\t\"\"\"Check if we should stop due to too many failures\"\"\"\n\t\tif self.consecutive_failures >= self.max_failures:\n\t\t\tlogger.error(f'❌ Stopping due to {self.max_failures} consecutive failures')\n\t\t\treturn True\n\t\treturn False\n\n\tasync def _validate_output(self) -> bool:\n\t\t\"\"\"Validate the output of the last action is what the user wanted\"\"\"\n\t\tsystem_msg = (\n\t\t\tf'You are a validator of an agent who interacts with a browser. '\n\t\t\tf'Validate if the output of last action is what the user wanted and if the task is completed. '\n\t\t\tf'If the task is unclear defined, you can let it pass. But if something is missing or the image does not show what was requested dont let it pass. '\n\t\t\tf'Try to understand the page and help the model with suggestions like scroll, do x, ... to get the solution right. '\n\t\t\tf'Task to validate: {self.task}. Return a JSON object with 2 keys: is_valid and reason. '\n\t\t\tf'is_valid is a boolean that indicates if the output is correct. '\n\t\t\tf'reason is a string that explains why it is valid or not.'\n\t\t\tf' example: {{\"is_valid\": false, \"reason\": \"The user wanted to search for \"cat photos\", but the agent searched for \"dog photos\" instead.\"}}'\n\t\t)\n\n\t\tif self.browser_context.session:\n\t\t\tstate = await self.browser_context.get_state(use_vision=self.use_vision)\n\t\t\tcontent = AgentMessagePrompt(\n\t\t\t\tstate=state,\n\t\t\t\tresult=self._last_result,\n\t\t\t\tinclude_attributes=self.include_attributes,\n\t\t\t\tmax_error_length=self.max_error_length,\n\t\t\t)\n\t\t\tmsg = [SystemMessage(content=system_msg), content.get_user_message()]\n\t\telse:\n\t\t\t# if no browser session, we can't validate the output\n\t\t\treturn True\n\n\t\tclass ValidationResult(BaseModel):\n\t\t\tis_valid: bool\n\t\t\treason: str\n\n\t\tvalidator = self.llm.with_structured_output(ValidationResult, include_raw=True)\n\t\tresponse: dict[str, Any] = await validator.ainvoke(msg)  # type: ignore\n\t\tparsed: ValidationResult = response['parsed']\n\t\tis_valid = parsed.is_valid\n\t\tif not is_valid:\n\t\t\tlogger.info(f'❌ Validator decision: {parsed.reason}')\n\t\t\tmsg = f'The output is not yet correct. {parsed.reason}.'\n\t\t\tself._last_result = [ActionResult(extracted_content=msg, include_in_memory=True)]\n\t\telse:\n\t\t\tlogger.info(f'✅ Validator decision: {parsed.reason}')\n\t\treturn is_valid\n\n\tasync def rerun_history(\n\t\tself,\n\t\thistory: AgentHistoryList,\n\t\tmax_retries: int = 3,\n\t\tskip_failures: bool = True,\n\t\tdelay_between_actions: float = 2.0,\n\t) -> list[ActionResult]:\n\t\t\"\"\"\n\t\tRerun a saved history of actions with error handling and retry logic.\n\n\t\tArgs:\n\t\t        history: The history to replay\n\t\t        max_retries: Maximum number of retries per action\n\t\t        skip_failures: Whether to skip failed actions or stop execution\n\t\t        delay_between_actions: Delay between actions in seconds\n\n\t\tReturns:\n\t\t        List of action results\n\t\t\"\"\"\n\t\tresults = []\n\n\t\tfor i, history_item in enumerate(history.history):\n\t\t\tgoal = (\n\t\t\t\thistory_item.model_output.current_state.next_goal\n\t\t\t\tif history_item.model_output\n\t\t\t\telse ''\n\t\t\t)\n\t\t\tlogger.info(f'Replaying step {i + 1}/{len(history.history)}: goal: {goal}')\n\n\t\t\tif (\n\t\t\t\tnot history_item.model_output\n\t\t\t\tor not history_item.model_output.action\n\t\t\t\tor history_item.model_output.action == [None]\n\t\t\t):\n\t\t\t\tlogger.warning(f'Step {i + 1}: No action to replay, skipping')\n\t\t\t\tresults.append(ActionResult(error='No action to replay'))\n\t\t\t\tcontinue\n\n\t\t\tretry_count = 0\n\t\t\twhile retry_count < max_retries:\n\t\t\t\ttry:\n\t\t\t\t\tresult = await self._execute_history_step(history_item, delay_between_actions)\n\t\t\t\t\tresults.extend(result)\n\t\t\t\t\tbreak\n\n\t\t\t\texcept Exception as e:\n\t\t\t\t\tretry_count += 1\n\t\t\t\t\tif retry_count == max_retries:\n\t\t\t\t\t\terror_msg = f'Step {i + 1} failed after {max_retries} attempts: {str(e)}'\n\t\t\t\t\t\tlogger.error(error_msg)\n\t\t\t\t\t\tif not skip_failures:\n\t\t\t\t\t\t\tresults.append(ActionResult(error=error_msg))\n\t\t\t\t\t\t\traise RuntimeError(error_msg)\n\t\t\t\t\telse:\n\t\t\t\t\t\tlogger.warning(\n\t\t\t\t\t\t\tf'Step {i + 1} failed (attempt {retry_count}/{max_retries}), retrying...'\n\t\t\t\t\t\t)\n\t\t\t\t\t\tawait asyncio.sleep(delay_between_actions)\n\n\t\treturn results\n\n\tasync def _execute_history_step(\n\t\tself, history_item: AgentHistory, delay: float\n\t) -> list[ActionResult]:\n\t\t\"\"\"Execute a single step from history with element validation\"\"\"\n\n\t\tstate = await self.browser_context.get_state()\n\t\tif not state or not history_item.model_output:\n\t\t\traise ValueError('Invalid state or model output')\n\t\tupdated_actions = []\n\t\tfor i, action in enumerate(history_item.model_output.action):\n\t\t\tupdated_action = await self._update_action_indices(\n\t\t\t\thistory_item.state.interacted_element[i],\n\t\t\t\taction,\n\t\t\t\tstate,\n\t\t\t)\n\t\t\tupdated_actions.append(updated_action)\n\n\t\t\tif updated_action is None:\n\t\t\t\traise ValueError(f'Could not find matching element {i} in current page')\n\n\t\tresult = await self.controller.multi_act(updated_actions, self.browser_context)\n\n\t\tawait asyncio.sleep(delay)\n\t\treturn result\n\n\tasync def _update_action_indices(\n\t\tself,\n\t\thistorical_element: Optional[DOMHistoryElement],\n\t\taction: ActionModel,  # Type this properly based on your action model\n\t\tcurrent_state: BrowserState,\n\t) -> Optional[ActionModel]:\n\t\t\"\"\"\n\t\tUpdate action indices based on current page state.\n\t\tReturns updated action or None if element cannot be found.\n\t\t\"\"\"\n\t\tif not historical_element or not current_state.element_tree:\n\t\t\treturn action\n\n\t\tcurrent_element = HistoryTreeProcessor.find_history_element_in_tree(\n\t\t\thistorical_element, current_state.element_tree\n\t\t)\n\n\t\tif not current_element or current_element.highlight_index is None:\n\t\t\treturn None\n\n\t\told_index = action.get_index()\n\t\tif old_index != current_element.highlight_index:\n\t\t\taction.set_index(current_element.highlight_index)\n\t\t\tlogger.info(\n\t\t\t\tf'Element moved in DOM, updated index from {old_index} to {current_element.highlight_index}'\n\t\t\t)\n\n\t\treturn action\n\n\tasync def load_and_rerun(\n\t\tself, history_file: Optional[str | Path] = None, **kwargs\n\t) -> list[ActionResult]:\n\t\t\"\"\"\n\t\tLoad history from file and rerun it.\n\n\t\tArgs:\n\t\t        history_file: Path to the history file\n\t\t        **kwargs: Additional arguments passed to rerun_history\n\t\t\"\"\"\n\t\tif not history_file:\n\t\t\thistory_file = 'AgentHistory.json'\n\t\thistory = AgentHistoryList.load_from_file(history_file, self.AgentOutput)\n\t\treturn await self.rerun_history(history, **kwargs)\n\n\tdef save_history(self, file_path: Optional[str | Path] = None) -> None:\n\t\t\"\"\"Save the history to a file\"\"\"\n\t\tif not file_path:\n\t\t\tfile_path = 'AgentHistory.json'\n\t\tself.history.save_to_file(file_path)\n\n\tdef create_history_gif(\n\t\tself,\n\t\toutput_path: str = 'agent_history.gif',\n\t\tduration: int = 3000,\n\t\tshow_goals: bool = True,\n\t\tshow_task: bool = True,\n\t\tshow_logo: bool = False,\n\t\tfont_size: int = 40,\n\t\ttitle_font_size: int = 56,\n\t\tgoal_font_size: int = 44,\n\t\tmargin: int = 40,\n\t\tline_spacing: float = 1.5,\n\t) -> None:\n\t\t\"\"\"Create a GIF from the agent's history with overlaid task and goal text.\"\"\"\n\t\tif not self.history.history:\n\t\t\tlogger.warning('No history to create GIF from')\n\t\t\treturn\n\n\t\timages = []\n\t\t# if history is empty or first screenshot is None, we can't create a gif\n\t\tif not self.history.history or not self.history.history[0].state.screenshot:\n\t\t\tlogger.warning('No history or first screenshot to create GIF from')\n\t\t\treturn\n\n\t\t# Try to load nicer fonts\n\t\ttry:\n\t\t\t# Try different font options in order of preference\n\t\t\tfont_options = ['Helvetica', 'Arial', 'DejaVuSans', 'Verdana']\n\t\t\tfont_loaded = False\n\n\t\t\tfor font_name in font_options:\n\t\t\t\ttry:\n\t\t\t\t\tif platform.system() == 'Windows':\n\t\t\t\t\t\t# Need to specify the abs font path on Windows\n\t\t\t\t\t\tfont_name = os.path.join(\n\t\t\t\t\t\t\tos.getenv('WIN_FONT_DIR', 'C:\\\\Windows\\\\Fonts'), font_name + '.ttf'\n\t\t\t\t\t\t)\n\t\t\t\t\tregular_font = ImageFont.truetype(font_name, font_size)\n\t\t\t\t\ttitle_font = ImageFont.truetype(font_name, title_font_size)\n\t\t\t\t\tgoal_font = ImageFont.truetype(font_name, goal_font_size)\n\t\t\t\t\tfont_loaded = True\n\t\t\t\t\tbreak\n\t\t\t\texcept OSError:\n\t\t\t\t\tcontinue\n\n\t\t\tif not font_loaded:\n\t\t\t\traise OSError('No preferred fonts found')\n\n\t\texcept OSError:\n\t\t\tregular_font = ImageFont.load_default()\n\t\t\ttitle_font = ImageFont.load_default()\n\n\t\t\tgoal_font = regular_font\n\n\t\t# Load logo if requested\n\t\tlogo = None\n\t\tif show_logo:\n\t\t\ttry:\n\t\t\t\tlogo = Image.open('./static/browser-use.png')\n\t\t\t\t# Resize logo to be small (e.g., 40px height)\n\t\t\t\tlogo_height = 150\n\t\t\t\taspect_ratio = logo.width / logo.height\n\t\t\t\tlogo_width = int(logo_height * aspect_ratio)\n\t\t\t\tlogo = logo.resize((logo_width, logo_height), Image.Resampling.LANCZOS)\n\t\t\texcept Exception as e:\n\t\t\t\tlogger.warning(f'Could not load logo: {e}')\n\n\t\t# Create task frame if requested\n\t\tif show_task and self.task:\n\t\t\ttask_frame = self._create_task_frame(\n\t\t\t\tself.task,\n\t\t\t\tself.history.history[0].state.screenshot,\n\t\t\t\ttitle_font,\n\t\t\t\tregular_font,\n\t\t\t\tlogo,\n\t\t\t\tline_spacing,\n\t\t\t)\n\t\t\timages.append(task_frame)\n\n\t\t# Process each history item\n\t\tfor i, item in enumerate(self.history.history, 1):\n\t\t\tif not item.state.screenshot:\n\t\t\t\tcontinue\n\n\t\t\t# Convert base64 screenshot to PIL Image\n\t\t\timg_data = base64.b64decode(item.state.screenshot)\n\t\t\timage = Image.open(io.BytesIO(img_data))\n\n\t\t\tif show_goals and item.model_output:\n\t\t\t\timage = self._add_overlay_to_image(\n\t\t\t\t\timage=image,\n\t\t\t\t\tstep_number=i,\n\t\t\t\t\tgoal_text=item.model_output.current_state.next_goal,\n\t\t\t\t\tregular_font=regular_font,\n\t\t\t\t\ttitle_font=title_font,\n\t\t\t\t\tmargin=margin,\n\t\t\t\t\tlogo=logo,\n\t\t\t\t)\n\n\t\t\timages.append(image)\n\n\t\tif images:\n\t\t\t# Save the GIF\n\t\t\timages[0].save(\n\t\t\t\toutput_path,\n\t\t\t\tsave_all=True,\n\t\t\t\tappend_images=images[1:],\n\t\t\t\tduration=duration,\n\t\t\t\tloop=0,\n\t\t\t\toptimize=False,\n\t\t\t)\n\t\t\tlogger.info(f'Created GIF at {output_path}')\n\t\telse:\n\t\t\tlogger.warning('No images found in history to create GIF')\n\n\tdef _create_task_frame(\n\t\tself,\n\t\ttask: str,\n\t\tfirst_screenshot: str,\n\t\ttitle_font: ImageFont.FreeTypeFont,\n\t\tregular_font: ImageFont.FreeTypeFont,\n\t\tlogo: Optional[Image.Image] = None,\n\t\tline_spacing: float = 1.5,\n\t) -> Image.Image:\n\t\t\"\"\"Create initial frame showing the task.\"\"\"\n\t\timg_data = base64.b64decode(first_screenshot)\n\t\ttemplate = Image.open(io.BytesIO(img_data))\n\t\timage = Image.new('RGB', template.size, (0, 0, 0))\n\t\tdraw = ImageDraw.Draw(image)\n\n\t\t# Calculate vertical center of image\n\t\tcenter_y = image.height // 2\n\n\t\t# Draw task text with increased font size\n\t\tmargin = 140  # Increased margin\n\t\tmax_width = image.width - (2 * margin)\n\t\tlarger_font = ImageFont.truetype(\n\t\t\tregular_font.path, regular_font.size + 16\n\t\t)  # Increase font size more\n\t\twrapped_text = self._wrap_text(task, larger_font, max_width)\n\n\t\t# Calculate line height with spacing\n\t\tline_height = larger_font.size * line_spacing\n\n\t\t# Split text into lines and draw with custom spacing\n\t\tlines = wrapped_text.split('\\n')\n\t\ttotal_height = line_height * len(lines)\n\n\t\t# Start position for first line\n\t\ttext_y = center_y - (total_height / 2) + 50  # Shifted down slightly\n\n\t\tfor line in lines:\n\t\t\t# Get line width for centering\n\t\t\tline_bbox = draw.textbbox((0, 0), line, font=larger_font)\n\t\t\ttext_x = (image.width - (line_bbox[2] - line_bbox[0])) // 2\n\n\t\t\tdraw.text(\n\t\t\t\t(text_x, text_y),\n\t\t\t\tline,\n\t\t\t\tfont=larger_font,\n\t\t\t\tfill=(255, 255, 255),\n\t\t\t)\n\t\t\ttext_y += line_height\n\n\t\t# Add logo if provided (top right corner)\n\t\tif logo:\n\t\t\tlogo_margin = 20\n\t\t\tlogo_x = image.width - logo.width - logo_margin\n\t\t\timage.paste(logo, (logo_x, logo_margin), logo if logo.mode == 'RGBA' else None)\n\n\t\treturn image\n\n\tdef _add_overlay_to_image(\n\t\tself,\n\t\timage: Image.Image,\n\t\tstep_number: int,\n\t\tgoal_text: str,\n\t\tregular_font: ImageFont.FreeTypeFont,\n\t\ttitle_font: ImageFont.FreeTypeFont,\n\t\tmargin: int,\n\t\tlogo: Optional[Image.Image] = None,\n\t) -> Image.Image:\n\t\t\"\"\"Add step number and goal overlay to an image.\"\"\"\n\t\timage = image.convert('RGBA')\n\t\ttxt_layer = Image.new('RGBA', image.size, (0, 0, 0, 0))\n\t\tdraw = ImageDraw.Draw(txt_layer)\n\n\t\t# Add step number (bottom left)\n\t\tstep_text = str(step_number)\n\t\tstep_bbox = draw.textbbox((0, 0), step_text, font=title_font)\n\t\tstep_width = step_bbox[2] - step_bbox[0]\n\t\tstep_height = step_bbox[3] - step_bbox[1]\n\n\t\t# Position step number in bottom left\n\t\tx_step = margin + 10  # Slight additional offset from edge\n\t\ty_step = image.height - margin - step_height - 10  # Slight offset from bottom\n\n\t\t# Draw rounded rectangle background for step number\n\t\tpadding = 20  # Increased padding\n\t\tstep_bg_bbox = (\n\t\t\tx_step - padding,\n\t\t\ty_step - padding,\n\t\t\tx_step + step_width + padding,\n\t\t\ty_step + step_height + padding,\n\t\t)\n\t\tdraw.rounded_rectangle(\n\t\t\tstep_bg_bbox,\n\t\t\tradius=15,  # Add rounded corners\n\t\t\tfill=(0, 0, 0, 255),\n\t\t)\n\n\t\t# Draw step number\n\t\tdraw.text(\n\t\t\t(x_step, y_step),\n\t\t\tstep_text,\n\t\t\tfont=title_font,\n\t\t\tfill=(255, 255, 255, 255),\n\t\t)\n\n\t\t# Draw goal text (centered, bottom)\n\t\tmax_width = image.width - (4 * margin)\n\t\twrapped_goal = self._wrap_text(goal_text, title_font, max_width)\n\t\tgoal_bbox = draw.multiline_textbbox((0, 0), wrapped_goal, font=title_font)\n\t\tgoal_width = goal_bbox[2] - goal_bbox[0]\n\t\tgoal_height = goal_bbox[3] - goal_bbox[1]\n\n\t\t# Center goal text horizontally, place above step number\n\t\tx_goal = (image.width - goal_width) // 2\n\t\ty_goal = y_step - goal_height - padding * 4  # More space between step and goal\n\n\t\t# Draw rounded rectangle background for goal\n\t\tpadding_goal = 25  # Increased padding for goal\n\t\tgoal_bg_bbox = (\n\t\t\tx_goal - padding_goal,  # Remove extra space for logo\n\t\t\ty_goal - padding_goal,\n\t\t\tx_goal + goal_width + padding_goal,\n\t\t\ty_goal + goal_height + padding_goal,\n\t\t)\n\t\tdraw.rounded_rectangle(\n\t\t\tgoal_bg_bbox,\n\t\t\tradius=15,  # Add rounded corners\n\t\t\tfill=(0, 0, 0, 255),\n\t\t)\n\n\t\t# Draw goal text\n\t\tdraw.multiline_text(\n\t\t\t(x_goal, y_goal),\n\t\t\twrapped_goal,\n\t\t\tfont=title_font,\n\t\t\tfill=(255, 255, 255, 255),\n\t\t\talign='center',\n\t\t)\n\n\t\t# Add logo if provided (top right corner)\n\t\tif logo:\n\t\t\tlogo_layer = Image.new('RGBA', image.size, (0, 0, 0, 0))\n\t\t\tlogo_margin = 20\n\t\t\tlogo_x = image.width - logo.width - logo_margin\n\t\t\tlogo_layer.paste(logo, (logo_x, logo_margin), logo if logo.mode == 'RGBA' else None)\n\t\t\ttxt_layer = Image.alpha_composite(logo_layer, txt_layer)\n\n\t\t# Composite and convert\n\t\tresult = Image.alpha_composite(image, txt_layer)\n\t\treturn result.convert('RGB')\n\n\tdef _wrap_text(self, text: str, font: ImageFont.FreeTypeFont, max_width: int) -> str:\n\t\t\"\"\"\n\t\tWrap text to fit within a given width.\n\n\t\tArgs:\n\t\t\ttext: Text to wrap\n\t\t\tfont: Font to use for text\n\t\t\tmax_width: Maximum width in pixels\n\n\t\tReturns:\n\t\t\tWrapped text with newlines\n\t\t\"\"\"\n\t\twords = text.split()\n\t\tlines = []\n\t\tcurrent_line = []\n\n\t\tfor word in words:\n\t\t\tcurrent_line.append(word)\n\t\t\tline = ' '.join(current_line)\n\t\t\tbbox = font.getbbox(line)\n\t\t\tif bbox[2] > max_width:\n\t\t\t\tif len(current_line) == 1:\n\t\t\t\t\tlines.append(current_line.pop())\n\t\t\t\telse:\n\t\t\t\t\tcurrent_line.pop()\n\t\t\t\t\tlines.append(' '.join(current_line))\n\t\t\t\t\tcurrent_line = [word]\n\n\t\tif current_line:\n\t\t\tlines.append(' '.join(current_line))\n\n\t\treturn '\\n'.join(lines)\n\n\tdef _create_frame(\n\t\tself, screenshot: str, text: str, step_number: int, width: int = 1200, height: int = 800\n\t) -> Image.Image:\n\t\t\"\"\"Create a frame for the GIF with improved styling\"\"\"\n\n\t\t# Create base image\n\t\tframe = Image.new('RGB', (width, height), 'white')\n\n\t\t# Load and resize screenshot\n\t\tscreenshot_img = Image.open(BytesIO(base64.b64decode(screenshot)))\n\t\tscreenshot_img.thumbnail((width - 40, height - 160))  # Leave space for text\n\n\t\t# Calculate positions\n\t\tscreenshot_x = (width - screenshot_img.width) // 2\n\t\tscreenshot_y = 120  # Leave space for header\n\n\t\t# Draw screenshot\n\t\tframe.paste(screenshot_img, (screenshot_x, screenshot_y))\n\n\t\t# Load browser-use logo\n\t\tlogo_size = 100  # Increased size for browser-use logo\n\t\tlogo_path = os.path.join(os.path.dirname(__file__), 'assets/browser-use-logo.png')\n\t\tif os.path.exists(logo_path):\n\t\t\tlogo = Image.open(logo_path)\n\t\t\tlogo.thumbnail((logo_size, logo_size))\n\t\t\tframe.paste(\n\t\t\t\tlogo, (width - logo_size - 20, 20), logo if 'A' in logo.getbands() else None\n\t\t\t)\n\n\t\t# Create drawing context\n\t\tdraw = ImageDraw.Draw(frame)\n\n\t\t# Load fonts\n\t\ttry:\n\t\t\ttitle_font = ImageFont.truetype('Arial.ttf', 36)  # Increased font size\n\t\t\ttext_font = ImageFont.truetype('Arial.ttf', 24)  # Increased font size\n\t\t\tnumber_font = ImageFont.truetype('Arial.ttf', 48)  # Increased font size for step number\n\t\texcept:\n\t\t\ttitle_font = ImageFont.load_default()\n\t\t\ttext_font = ImageFont.load_default()\n\t\t\tnumber_font = ImageFont.load_default()\n\n\t\t# Draw task text with increased spacing\n\t\tmargin = 80  # Increased margin\n\t\tmax_text_width = width - (2 * margin)\n\n\t\t# Create rounded rectangle for goal text\n\t\ttext_padding = 20\n\t\ttext_lines = textwrap.wrap(text, width=60)\n\t\ttext_height = sum(draw.textsize(line, font=text_font)[1] for line in text_lines)\n\t\ttext_box_height = text_height + (2 * text_padding)\n\n\t\t# Draw rounded rectangle background for goal\n\t\tgoal_bg_coords = [\n\t\t\tmargin - text_padding,\n\t\t\t40,  # Top position\n\t\t\twidth - margin + text_padding,\n\t\t\t40 + text_box_height,\n\t\t]\n\t\tdraw.rounded_rectangle(\n\t\t\tgoal_bg_coords,\n\t\t\tradius=15,  # Increased radius for more rounded corners\n\t\t\tfill='#f0f0f0',\n\t\t)\n\n\t\t# Draw browser-use small logo in top left of goal box\n\t\tsmall_logo_size = 30\n\t\tif os.path.exists(logo_path):\n\t\t\tsmall_logo = Image.open(logo_path)\n\t\t\tsmall_logo.thumbnail((small_logo_size, small_logo_size))\n\t\t\tframe.paste(\n\t\t\t\tsmall_logo,\n\t\t\t\t(margin - text_padding + 10, 45),  # Positioned inside goal box\n\t\t\t\tsmall_logo if 'A' in small_logo.getbands() else None,\n\t\t\t)\n\n\t\t# Draw text with proper wrapping\n\t\ty = 50  # Starting y position for text\n\t\tfor line in text_lines:\n\t\t\tdraw.text((margin + small_logo_size + 20, y), line, font=text_font, fill='black')\n\t\t\ty += draw.textsize(line, font=text_font)[1] + 5\n\n\t\t# Draw step number with rounded background\n\t\tnumber_text = str(step_number)\n\t\tnumber_size = draw.textsize(number_text, font=number_font)\n\t\tnumber_padding = 20\n\t\tnumber_box_width = number_size[0] + (2 * number_padding)\n\t\tnumber_box_height = number_size[1] + (2 * number_padding)\n\n\t\t# Draw rounded rectangle for step number\n\t\tnumber_bg_coords = [\n\t\t\t20,  # Left position\n\t\t\theight - number_box_height - 20,  # Bottom position\n\t\t\t20 + number_box_width,\n\t\t\theight - 20,\n\t\t]\n\t\tdraw.rounded_rectangle(\n\t\t\tnumber_bg_coords,\n\t\t\tradius=15,\n\t\t\tfill='#007AFF',  # Blue background\n\t\t)\n\n\t\t# Center number in its background\n\t\tnumber_x = number_bg_coords[0] + ((number_box_width - number_size[0]) // 2)\n\t\tnumber_y = number_bg_coords[1] + ((number_box_height - number_size[1]) // 2)\n\t\tdraw.text((number_x, number_y), number_text, font=number_font, fill='white')\n\n\t\treturn frame\n"}
{"type": "source_file", "path": "browser-use/browser_use/agent/prompts.py", "content": "from datetime import datetime\nfrom typing import List, Optional\n\nfrom langchain_core.messages import HumanMessage, SystemMessage\n\nfrom browser_use.agent.views import ActionResult, AgentStepInfo\nfrom browser_use.browser.views import BrowserState\n\n\nclass SystemPrompt:\n\tdef __init__(\n\t\tself, action_description: str, current_date: datetime, max_actions_per_step: int = 10\n\t):\n\t\tself.default_action_description = action_description\n\t\tself.current_date = current_date\n\t\tself.max_actions_per_step = max_actions_per_step\n\n\tdef important_rules(self) -> str:\n\t\t\"\"\"\n\t\tReturns the important rules for the agent.\n\t\t\"\"\"\n\t\ttext = \"\"\"\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n   {\n     \"current_state\": {\n       \"evaluation_previous_goal\": \"Success|Failed|Unknown - Analyze the current elements and the image to check if the previous goals/actions are succesful like intended by the task. Ignore the action result. The website is the ground truth. Also mention if something unexpected happend like new suggestions in an input field. Shortly state why/why not. Most importantly, all your actions may not be succesfully executed by the user, so despite the memory and input prompt, you need to re-evaluate the situation and decide whether you need to continue with the same actions or change them. Make sure to re-evaluate the situation and provide a reason for failure/unknown, for example: 'Problem:My search query is too complex due to the use of multiple logical operators and no results were found.' Then come up with a new solution to your problem, example: 'Solution: Try a simpler search query without quotation marks and logical operators to find more results and then filter the results.'\",\n       \"memory\": \"Description of what has been done and what you need to remember until the end of the task\",\n       \"next_goal\": \"What needs to be done with the next actions. First, reason about the current state and what element you would need to click and interact with using which action. Then, come up with the next goal. Then, think about how to achieve the next goal using actions.\"\n     },\n     \"action\": [\n       {\n         \"one_action_name\": {\n           // action-specific parameter\n         }\n       },\n       // ... more actions in sequence\n     ]\n   }\n\n2. ACTIONS: You can specify multiple actions in the list to be executed in sequence. But always specify only one action name per item. \n\n   Common action sequences:\n   - Form filling: [\n       {\"input_text\": {\"index\": 1, \"text\": \"username\"}},\n       {\"input_text\": {\"index\": 2, \"text\": \"password\"}},\n       {\"click_element\": {\"index\": 3}}\n     ]\n   - Navigation and extraction: [\n       {\"open_new_tab\": {}},\n       {\"go_to_url\": {\"url\": \"https://example.com\"}},\n       {\"extract_page_content\": {}}\n     ]\n\n\n3. ELEMENT INTERACTION:\n   - Only use indexes that exist in the provided element list\n   - Each element has a unique index number (e.g., \"33[:]<button>\")\n   - Elements marked with \"_[:]\" are non-interactive (for context only)\n\n4. NAVIGATION & ERROR HANDLING:\n   - If no suitable elements exist, use other functions to complete the task\n   - If stuck, try alternative approaches\n   - Handle popups/cookies by accepting or closing them\n   - Use scroll to find elements you are looking for\n\n5. TASK COMPLETION:\n   - Use the done action as the last action as soon as the task is complete\n   - Don't hallucinate actions\n   - If the task requires specific information - make sure to include everything in the done function. This is what the user will see.\n   - If you are running out of steps (current step), think about speeding it up, and ALWAYS use the done action as the last action.\n\n6. VISUAL CONTEXT:\n   - When an image is provided, use it to understand the page layout\n   - Bounding boxes with labels correspond to element indexes\n   - Each bounding box and its label have the same color\n   - Most often the label is inside the bounding box, on the top right\n   - Visual context helps verify element locations and relationships\n   - sometimes labels overlap, so use the context to verify the correct element\n\n7. Form filling:\n   - If you fill an input field and your action sequence is interrupted, most often a list with suggestions poped up under the field and you need to first select the right element from the suggestion list.\n\n8. Searching via input box:\n\t- If you fill out an input field for the purpose of searching, then you need to use send_keys with enter key to submit the search. Try using send_keys and only if that fails, use click_element to submit the search.\n\n9. ACTION SEQUENCING:\n   - Actions are executed in the order they appear in the list \n   - Each action should logically follow from the previous one\n   - If the page changes after an action, the sequence is interrupted and you get the new state. This mean your previous actions may not be succesfully executed by the user. You must re-evaluate the situation and decide whether you need to continue with the same actions or change them.\n   - If content only disappears the sequence continues.\n   - Only provide the action sequence until you think the page will change. For example, if you type something in an input field, suggestions pop up and the page changes. You need to provide the action sequence until you think the page will change.\n   - Try to be efficient, e.g. fill forms at once, or chain actions where nothing changes on the page like saving, extracting, checkboxes...\n   - only use multiple actions if it makes sense. \n\n10. Troubleshooting: If you are stuck and an action fails, try to find the reason for the failure and try out a different approach. If you come up with a sequence of actions, and if your sequence is interrupted because of the page changing or something new appearing on the page, then propose an action sequence with only one single action.\n\"\"\"\n\t\ttext += f'   - use maximum {self.max_actions_per_step} actions per sequence'\n\t\treturn text\n\n\tdef input_format(self) -> str:\n\t\treturn \"\"\"\nINPUT STRUCTURE:\n1. Current URL: The webpage you're currently on\n2. Available Tabs: List of open browser tabs\n3. Interactive Elements: List in the format:\n   index[:]<element_type>element_text</element_type>\n   - index: Numeric identifier for interaction\n   - element_type: HTML element type (button, input, etc.)\n   - element_text: Visible text or element description\n\nExample:\n33[:]<button>Submit Form</button>\n_[:] Non-interactive text\n\n\nNotes:\n- Only elements with numeric indexes are interactive\n- _[:] elements provide context but cannot be interacted with\n\"\"\"\n\n\tdef get_system_message(self) -> SystemMessage:\n\t\t\"\"\"\n\t\tGet the system prompt for the agent.\n\n\t\tReturns:\n\t\t    str: Formatted system prompt\n\t\t\"\"\"\n\t\ttime_str = self.current_date.strftime('%Y-%m-%d %H:%M')\n\n\t\tAGENT_PROMPT = f\"\"\"You are a precise browser automation agent that interacts with websites through structured commands. Your role is to:\n1. Analyze the provided webpage elements and structure\n2. Plan a sequence of actions to accomplish the given task\n3. Respond with valid JSON containing your action sequence and state assessment\n\nCurrent date and time: {time_str}\n\n{self.input_format()}\n\n{self.important_rules()}\n\nFunctions:\n{self.default_action_description}\n\nRemember: Your responses must be valid JSON matching the specified format. Each action in the sequence must be valid.\"\"\"\n\t\treturn SystemMessage(content=AGENT_PROMPT)\n\n\n# Example:\n# {self.example_response()}\n# Your AVAILABLE ACTIONS:\n# {self.default_action_description}\n\n\nclass AgentMessagePrompt:\n\tdef __init__(\n\t\tself,\n\t\tstate: BrowserState,\n\t\tresult: Optional[List[ActionResult]] = None,\n\t\tinclude_attributes: list[str] = [],\n\t\tmax_error_length: int = 400,\n\t\tstep_info: Optional[AgentStepInfo] = None,\n\t):\n\t\tself.state = state\n\t\tself.result = result\n\t\tself.max_error_length = max_error_length\n\t\tself.include_attributes = include_attributes\n\t\tself.step_info = step_info\n\n\tdef get_user_message(self) -> HumanMessage:\n\t\tif self.step_info:\n\t\t\tstep_info_description = (\n\t\t\t\tf'Current step: {self.step_info.step_number + 1}/{self.step_info.max_steps}'\n\t\t\t)\n\t\telse:\n\t\t\tstep_info_description = ''\n\n\t\telements_text = self.state.element_tree.clickable_elements_to_string(\n\t\t\tinclude_attributes=self.include_attributes\n\t\t)\n\t\tif elements_text != '':\n\t\t\textra = '... Cut off - use extract content or scroll to get more ...'\n\t\t\telements_text = f'{extra}\\n{elements_text}\\n{extra}'\n\t\telse:\n\t\t\telements_text = 'empty page'\n\n\t\tstate_description = f\"\"\"\n{step_info_description}\nCurrent url: {self.state.url}\nAvailable tabs:\n{self.state.tabs}\nInteractive elements from current page view:\n{elements_text}\n\"\"\"\n\n\t\tif self.result:\n\t\t\tfor i, result in enumerate(self.result):\n\t\t\t\tif result.extracted_content:\n\t\t\t\t\tstate_description += (\n\t\t\t\t\t\tf'\\nAction result {i + 1}/{len(self.result)}: {result.extracted_content}'\n\t\t\t\t\t)\n\t\t\t\tif result.error:\n\t\t\t\t\t# only use last 300 characters of error\n\t\t\t\t\terror = result.error[-self.max_error_length :]\n\t\t\t\t\tstate_description += f'\\nAction error {i + 1}/{len(self.result)}: ...{error}'\n\n\t\tif self.state.screenshot:\n\t\t\t# Format message for vision model\n\t\t\treturn HumanMessage(\n\t\t\t\tcontent=[\n\t\t\t\t\t{'type': 'text', 'text': state_description},\n\t\t\t\t\t{\n\t\t\t\t\t\t'type': 'image_url',\n\t\t\t\t\t\t'image_url': {'url': f'data:image/png;base64,{self.state.screenshot}'},\n\t\t\t\t\t},\n\t\t\t\t]\n\t\t\t)\n\n\t\treturn HumanMessage(content=state_description)\n"}
{"type": "source_file", "path": "browser-use/browser_use/controller/registry/views.py", "content": "from typing import Callable, Dict, Type\n\nfrom pydantic import BaseModel, ConfigDict\n\n\nclass RegisteredAction(BaseModel):\n\t\"\"\"Model for a registered action\"\"\"\n\n\tname: str\n\tdescription: str\n\tfunction: Callable\n\tparam_model: Type[BaseModel]\n\trequires_browser: bool = False\n\n\tmodel_config = ConfigDict(arbitrary_types_allowed=True)\n\n\tdef prompt_description(self) -> str:\n\t\t\"\"\"Get a description of the action for the prompt\"\"\"\n\t\tskip_keys = ['title']\n\t\ts = f'{self.description}: \\n'\n\t\ts += '{' + str(self.name) + ': '\n\t\ts += str(\n\t\t\t{\n\t\t\t\tk: {sub_k: sub_v for sub_k, sub_v in v.items() if sub_k not in skip_keys}\n\t\t\t\tfor k, v in self.param_model.schema()['properties'].items()\n\t\t\t}\n\t\t)\n\t\ts += '}'\n\t\treturn s\n\n\nclass ActionModel(BaseModel):\n\t\"\"\"Base model for dynamically created action models\"\"\"\n\n\t# this will have all the registered actions, e.g.\n\t# click_element = param_model = ClickElementParams\n\t# done = param_model = None\n\t#\n\tmodel_config = ConfigDict(arbitrary_types_allowed=True)\n\n\tdef get_index(self) -> int | None:\n\t\t\"\"\"Get the index of the action\"\"\"\n\t\t# {'clicked_element': {'index':5}}\n\t\tparams = self.model_dump(exclude_unset=True).values()\n\t\tif not params:\n\t\t\treturn None\n\t\tfor param in params:\n\t\t\tif param is not None and 'index' in param:\n\t\t\t\treturn param['index']\n\t\treturn None\n\n\tdef set_index(self, index: int):\n\t\t\"\"\"Overwrite the index of the action\"\"\"\n\t\t# Get the action name and params\n\t\taction_data = self.model_dump(exclude_unset=True)\n\t\taction_name = next(iter(action_data.keys()))\n\t\taction_params = getattr(self, action_name)\n\n\t\t# Update the index directly on the model\n\t\tif hasattr(action_params, 'index'):\n\t\t\taction_params.index = index\n\n\nclass ActionRegistry(BaseModel):\n\t\"\"\"Model representing the action registry\"\"\"\n\n\tactions: Dict[str, RegisteredAction] = {}\n\n\tdef get_prompt_description(self) -> str:\n\t\t\"\"\"Get a description of all actions for the prompt\"\"\"\n\t\treturn '\\n'.join([action.prompt_description() for action in self.actions.values()])\n"}
{"type": "source_file", "path": "browser-use/browser_use/agent/views.py", "content": "from __future__ import annotations\n\nimport json\nimport traceback\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Type\n\nfrom openai import RateLimitError\nfrom pydantic import BaseModel, ConfigDict, Field, ValidationError, create_model\n\nfrom browser_use.browser.views import BrowserStateHistory\nfrom browser_use.controller.registry.views import ActionModel\nfrom browser_use.dom.history_tree_processor.service import (\n\tDOMElementNode,\n\tDOMHistoryElement,\n\tHistoryTreeProcessor,\n)\nfrom browser_use.dom.views import SelectorMap\n\n\n@dataclass\nclass AgentStepInfo:\n\tstep_number: int\n\tmax_steps: int\n\n\nclass ActionResult(BaseModel):\n\t\"\"\"Result of executing an action\"\"\"\n\n\tis_done: Optional[bool] = False\n\textracted_content: Optional[str] = None\n\terror: Optional[str] = None\n\tinclude_in_memory: bool = False  # whether to include in past messages as context or not\n\n\nclass AgentBrain(BaseModel):\n\t\"\"\"Current state of the agent\"\"\"\n\n\tevaluation_previous_goal: str\n\tmemory: str\n\tnext_goal: str\n\n\nclass AgentOutput(BaseModel):\n\t\"\"\"Output model for agent\n\n\t@dev note: this model is extended with custom actions in AgentService. You can also use some fields that are not in this model as provided by the linter, as long as they are registered in the DynamicActions model.\n\t\"\"\"\n\n\tmodel_config = ConfigDict(arbitrary_types_allowed=True)\n\n\tcurrent_state: AgentBrain\n\taction: list[ActionModel]\n\n\t@staticmethod\n\tdef type_with_custom_actions(custom_actions: Type[ActionModel]) -> Type['AgentOutput']:\n\t\t\"\"\"Extend actions with custom actions\"\"\"\n\t\treturn create_model(\n\t\t\t'AgentOutput',\n\t\t\t__base__=AgentOutput,\n\t\t\taction=(list[custom_actions], Field(...)),  # Properly annotated field with no default\n\t\t\t__module__=AgentOutput.__module__,\n\t\t)\n\n\nclass AgentHistory(BaseModel):\n\t\"\"\"History item for agent actions\"\"\"\n\n\tmodel_output: AgentOutput | None\n\tresult: list[ActionResult]\n\tstate: BrowserStateHistory\n\n\tmodel_config = ConfigDict(arbitrary_types_allowed=True, protected_namespaces=())\n\n\t@staticmethod\n\tdef get_interacted_element(\n\t\tmodel_output: AgentOutput, selector_map: SelectorMap\n\t) -> list[DOMHistoryElement | None]:\n\t\telements = []\n\t\tfor action in model_output.action:\n\t\t\tindex = action.get_index()\n\t\t\tif index and index in selector_map:\n\t\t\t\tel: DOMElementNode = selector_map[index]\n\t\t\t\telements.append(HistoryTreeProcessor.convert_dom_element_to_history_element(el))\n\t\t\telse:\n\t\t\t\telements.append(None)\n\t\treturn elements\n\n\tdef model_dump(self, **kwargs) -> Dict[str, Any]:\n\t\t\"\"\"Custom serialization handling circular references\"\"\"\n\n\t\t# Handle action serialization\n\t\tmodel_output_dump = None\n\t\tif self.model_output:\n\t\t\taction_dump = [\n\t\t\t\taction.model_dump(exclude_none=True) for action in self.model_output.action\n\t\t\t]\n\t\t\tmodel_output_dump = {\n\t\t\t\t'current_state': self.model_output.current_state.model_dump(),\n\t\t\t\t'action': action_dump,  # This preserves the actual action data\n\t\t\t}\n\n\t\treturn {\n\t\t\t'model_output': model_output_dump,\n\t\t\t'result': [r.model_dump(exclude_none=True) for r in self.result],\n\t\t\t'state': self.state.to_dict(),\n\t\t}\n\n\nclass AgentHistoryList(BaseModel):\n\t\"\"\"List of agent history items\"\"\"\n\n\thistory: list[AgentHistory]\n\n\tdef __str__(self) -> str:\n\t\t\"\"\"Representation of the AgentHistoryList object\"\"\"\n\t\treturn f'AgentHistoryList(all_results={self.action_results()}, all_model_outputs={self.model_actions()})'\n\n\tdef __repr__(self) -> str:\n\t\t\"\"\"Representation of the AgentHistoryList object\"\"\"\n\t\treturn self.__str__()\n\n\tdef save_to_file(self, filepath: str | Path) -> None:\n\t\t\"\"\"Save history to JSON file with proper serialization\"\"\"\n\t\ttry:\n\t\t\tPath(filepath).parent.mkdir(parents=True, exist_ok=True)\n\t\t\tdata = self.model_dump()\n\t\t\twith open(filepath, 'w', encoding='utf-8') as f:\n\t\t\t\tjson.dump(data, f, indent=2)\n\t\texcept Exception as e:\n\t\t\traise e\n\n\tdef model_dump(self, **kwargs) -> Dict[str, Any]:\n\t\t\"\"\"Custom serialization that properly uses AgentHistory's model_dump\"\"\"\n\t\treturn {\n\t\t\t'history': [h.model_dump(**kwargs) for h in self.history],\n\t\t}\n\n\t@classmethod\n\tdef load_from_file(\n\t\tcls, filepath: str | Path, output_model: Type[AgentOutput]\n\t) -> 'AgentHistoryList':\n\t\t\"\"\"Load history from JSON file\"\"\"\n\t\twith open(filepath, 'r', encoding='utf-8') as f:\n\t\t\tdata = json.load(f)\n\t\t# loop through history and validate output_model actions to enrich with custom actions\n\t\tfor h in data['history']:\n\t\t\tif h['model_output']:\n\t\t\t\tif isinstance(h['model_output'], dict):\n\t\t\t\t\th['model_output'] = output_model.model_validate(h['model_output'])\n\t\t\t\telse:\n\t\t\t\t\th['model_output'] = None\n\t\t\tif 'interacted_element' not in h['state']:\n\t\t\t\th['state']['interacted_element'] = None\n\t\thistory = cls.model_validate(data)\n\t\treturn history\n\n\tdef last_action(self) -> None | dict:\n\t\t\"\"\"Last action in history\"\"\"\n\t\tif self.history and self.history[-1].model_output:\n\t\t\treturn self.history[-1].model_output.action[-1].model_dump(exclude_none=True)\n\t\treturn None\n\n\tdef errors(self) -> list[str]:\n\t\t\"\"\"Get all errors from history\"\"\"\n\t\terrors = []\n\t\tfor h in self.history:\n\t\t\terrors.extend([r.error for r in h.result if r.error])\n\t\treturn errors\n\n\tdef final_result(self) -> None | str:\n\t\t\"\"\"Final result from history\"\"\"\n\t\tif self.history and self.history[-1].result[-1].extracted_content:\n\t\t\treturn self.history[-1].result[-1].extracted_content\n\t\treturn None\n\n\tdef is_done(self) -> bool:\n\t\t\"\"\"Check if the agent is done\"\"\"\n\t\tif (\n\t\t\tself.history\n\t\t\tand len(self.history[-1].result) > 0\n\t\t\tand self.history[-1].result[-1].is_done\n\t\t):\n\t\t\treturn self.history[-1].result[-1].is_done\n\t\treturn False\n\n\tdef has_errors(self) -> bool:\n\t\t\"\"\"Check if the agent has any errors\"\"\"\n\t\treturn len(self.errors()) > 0\n\n\tdef urls(self) -> list[str]:\n\t\t\"\"\"Get all unique URLs from history\"\"\"\n\t\treturn [h.state.url for h in self.history if h.state.url]\n\n\tdef screenshots(self) -> list[str]:\n\t\t\"\"\"Get all screenshots from history\"\"\"\n\t\treturn [h.state.screenshot for h in self.history if h.state.screenshot]\n\n\tdef action_names(self) -> list[str]:\n\t\t\"\"\"Get all action names from history\"\"\"\n\t\treturn [list(action.keys())[0] for action in self.model_actions()]\n\n\tdef model_thoughts(self) -> list[AgentBrain]:\n\t\t\"\"\"Get all thoughts from history\"\"\"\n\t\treturn [h.model_output.current_state for h in self.history if h.model_output]\n\n\tdef model_outputs(self) -> list[AgentOutput]:\n\t\t\"\"\"Get all model outputs from history\"\"\"\n\t\treturn [h.model_output for h in self.history if h.model_output]\n\n\t# get all actions with params\n\tdef model_actions(self) -> list[dict]:\n\t\t\"\"\"Get all actions from history\"\"\"\n\t\toutputs = []\n\n\t\tfor h in self.history:\n\t\t\tif h.model_output:\n\t\t\t\tfor action in h.model_output.action:\n\t\t\t\t\toutput = action.model_dump(exclude_none=True)\n\t\t\t\t\toutputs.append(output)\n\t\treturn outputs\n\n\tdef action_results(self) -> list[ActionResult]:\n\t\t\"\"\"Get all results from history\"\"\"\n\t\tresults = []\n\t\tfor h in self.history:\n\t\t\tresults.extend([r for r in h.result if r])\n\t\treturn results\n\n\tdef extracted_content(self) -> list[str]:\n\t\t\"\"\"Get all extracted content from history\"\"\"\n\t\tcontent = []\n\t\tfor h in self.history:\n\t\t\tcontent.extend([r.extracted_content for r in h.result if r.extracted_content])\n\t\treturn content\n\n\tdef model_actions_filtered(self, include: list[str] = []) -> list[dict]:\n\t\t\"\"\"Get all model actions from history as JSON\"\"\"\n\t\toutputs = self.model_actions()\n\t\tresult = []\n\t\tfor o in outputs:\n\t\t\tfor i in include:\n\t\t\t\tif i == list(o.keys())[0]:\n\t\t\t\t\tresult.append(o)\n\t\treturn result\n\n\nclass AgentError:\n\t\"\"\"Container for agent error handling\"\"\"\n\n\tVALIDATION_ERROR = 'Invalid model output format. Please follow the correct schema.'\n\tRATE_LIMIT_ERROR = 'Rate limit reached. Waiting before retry.'\n\tNO_VALID_ACTION = 'No valid action found'\n\n\t@staticmethod\n\tdef format_error(error: Exception, include_trace: bool = False) -> str:\n\t\t\"\"\"Format error message based on error type and optionally include trace\"\"\"\n\t\tmessage = ''\n\t\tif isinstance(error, ValidationError):\n\t\t\treturn f'{AgentError.VALIDATION_ERROR}\\nDetails: {str(error)}'\n\t\tif isinstance(error, RateLimitError):\n\t\t\treturn AgentError.RATE_LIMIT_ERROR\n\t\tif include_trace:\n\t\t\treturn f'{str(error)}\\nStacktrace:\\n{traceback.format_exc()}'\n\t\treturn f'{str(error)}'\n"}
{"type": "source_file", "path": "browser-use/browser_use/dom/history_tree_processor/view.py", "content": "from dataclasses import dataclass\nfrom typing import Optional\n\n\n@dataclass\nclass HashedDomElement:\n\t\"\"\"\n\tHash of the dom element to be used as a unique identifier\n\t\"\"\"\n\n\tbranch_path_hash: str\n\tattributes_hash: str\n\t# text_hash: str\n\n\n@dataclass\nclass DOMHistoryElement:\n\ttag_name: str\n\txpath: str\n\thighlight_index: Optional[int]\n\tentire_parent_branch_path: list[str]\n\tattributes: dict[str, str]\n\tshadow_root: bool = False\n\n\tdef to_dict(self) -> dict:\n\t\treturn {\n\t\t\t'tag_name': self.tag_name,\n\t\t\t'xpath': self.xpath,\n\t\t\t'highlight_index': self.highlight_index,\n\t\t\t'entire_parent_branch_path': self.entire_parent_branch_path,\n\t\t\t'attributes': self.attributes,\n\t\t\t'shadow_root': self.shadow_root,\n\t\t}\n"}
{"type": "source_file", "path": "browser-use/browser_use/browser/browser.py", "content": "\"\"\"\nPlaywright browser on steroids.\n\"\"\"\n\nimport asyncio\nimport logging\nfrom dataclasses import dataclass, field\n\nfrom playwright._impl._api_structures import ProxySettings\nfrom playwright.async_api import Browser as PlaywrightBrowser\nfrom playwright.async_api import (\n\tPlaywright,\n\tasync_playwright,\n)\n\nfrom browser_use.browser.context import BrowserContext, BrowserContextConfig\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass BrowserConfig:\n\t\"\"\"\n\tConfiguration for the Browser.\n\n\tDefault values:\n\t\theadless: True\n\t\t\tWhether to run browser in headless mode\n\n\t\tdisable_security: False\n\t\t\tDisable browser security features\n\n\t\textra_chromium_args: []\n\t\t\tExtra arguments to pass to the browser\n\n\t\twss_url: None\n\t\t\tConnect to a browser instance via WebSocket\n\n\t\tcdp_url: None\n\t\t\tConnect to a browser instance via CDP\n\n\t\tchrome_instance_path: None\n\t\t\tPath to a Chrome instance to use to connect to your normal browser\n\t\t\te.g. '/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome'\n\t\"\"\"\n\n\theadless: bool = False\n\tdisable_security: bool = True\n\textra_chromium_args: list[str] = field(default_factory=list)\n\tchrome_instance_path: str | None = None\n\twss_url: str | None = None\n\tcdp_url: str | None = None\n\n\tproxy: ProxySettings | None = field(default=None)\n\tnew_context_config: BrowserContextConfig = field(default_factory=BrowserContextConfig)\n\n\n# @singleton: TODO - think about id singleton makes sense here\n# @dev By default this is a singleton, but you can create multiple instances if you need to.\nclass Browser:\n\t\"\"\"\n\tPlaywright browser on steroids.\n\n\tThis is persistant browser factory that can spawn multiple browser contexts.\n\tIt is recommended to use only one instance of Browser per your application (RAM usage will grow otherwise).\n\t\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\tconfig: BrowserConfig = BrowserConfig(),\n\t):\n\t\tlogger.debug('Initializing new browser')\n\t\tself.config = config\n\t\tself.playwright: Playwright | None = None\n\t\tself.playwright_browser: PlaywrightBrowser | None = None\n\n\tasync def new_context(\n\t\tself, config: BrowserContextConfig = BrowserContextConfig()\n\t) -> BrowserContext:\n\t\t\"\"\"Create a browser context\"\"\"\n\t\treturn BrowserContext(config=config, browser=self)\n\n\tasync def get_playwright_browser(self) -> PlaywrightBrowser:\n\t\t\"\"\"Get a browser context\"\"\"\n\t\tif self.playwright_browser is None:\n\t\t\treturn await self._init()\n\n\t\treturn self.playwright_browser\n\n\tasync def _init(self):\n\t\t\"\"\"Initialize the browser session\"\"\"\n\t\tplaywright = await async_playwright().start()\n\t\tbrowser = await self._setup_browser(playwright)\n\n\t\tself.playwright = playwright\n\t\tself.playwright_browser = browser\n\n\t\treturn self.playwright_browser\n\n\tasync def _setup_browser(self, playwright: Playwright) -> PlaywrightBrowser:\n\t\t\"\"\"Sets up and returns a Playwright Browser instance with anti-detection measures.\"\"\"\n\t\tif self.config.cdp_url:\n\t\t\t# Loggin : Connecting to remote browser via CDP\n\t\t\tlogger.info(f'Connecting to remote browser via CDP {self.config.cdp_url}')\n\t\t\tbrowser = await playwright.chromium.connect_over_cdp(self.config.cdp_url)\n\t\t\treturn browser\n\t\tif self.config.wss_url:\n\t\t\tbrowser = await playwright.chromium.connect(self.config.wss_url)\n\t\t\treturn browser\n\t\telif self.config.chrome_instance_path:\n\t\t\timport subprocess\n\n\t\t\timport requests\n\n\t\t\ttry:\n\t\t\t\t# Check if browser is already running\n\t\t\t\tresponse = requests.get('http://localhost:9222/json/version', timeout=2)\n\t\t\t\tif response.status_code == 200:\n\t\t\t\t\tlogger.info('Reusing existing Chrome instance')\n\t\t\t\t\tbrowser = await playwright.chromium.connect_over_cdp(\n\t\t\t\t\t\tendpoint_url='http://localhost:9222',\n\t\t\t\t\t\ttimeout=20000,  # 20 second timeout for connection\n\t\t\t\t\t)\n\t\t\t\t\treturn browser\n\t\t\texcept requests.ConnectionError:\n\t\t\t\tlogger.debug('No existing Chrome instance found, starting a new one')\n\n\t\t\t# Start a new Chrome instance\n\t\t\tsubprocess.Popen(\n\t\t\t\t[\n\t\t\t\t\tself.config.chrome_instance_path,\n\t\t\t\t\t'--remote-debugging-port=9222',\n\t\t\t\t],\n\t\t\t\tstdout=subprocess.DEVNULL,\n\t\t\t\tstderr=subprocess.DEVNULL,\n\t\t\t)\n\n\t\t\t# Attempt to connect again after starting a new instance\n\t\t\ttry:\n\t\t\t\tbrowser = await playwright.chromium.connect_over_cdp(\n\t\t\t\t\tendpoint_url='http://localhost:9222',\n\t\t\t\t\ttimeout=20000,  # 20 second timeout for connection\n\t\t\t\t)\n\t\t\t\treturn browser\n\t\t\texcept Exception as e:\n\t\t\t\tlogger.error(f'Failed to start a new Chrome instance.: {str(e)}')\n\t\t\t\traise RuntimeError(\n\t\t\t\t\t' To start chrome in Debug mode, you need to close all existing Chrome instances and try again otherwise we can not connect to the instance.'\n\t\t\t\t)\n\n\t\telse:\n\t\t\ttry:\n\t\t\t\tdisable_security_args = []\n\t\t\t\tif self.config.disable_security:\n\t\t\t\t\tdisable_security_args = [\n\t\t\t\t\t\t'--disable-web-security',\n\t\t\t\t\t\t'--disable-site-isolation-trials',\n\t\t\t\t\t\t'--disable-features=IsolateOrigins,site-per-process',\n\t\t\t\t\t]\n\n\t\t\t\tbrowser = await playwright.chromium.launch(\n\t\t\t\t\theadless=self.config.headless,\n\t\t\t\t\targs=[\n\t\t\t\t\t\t'--no-sandbox',\n\t\t\t\t\t\t'--disable-blink-features=AutomationControlled',\n\t\t\t\t\t\t'--disable-infobars',\n\t\t\t\t\t\t'--disable-background-timer-throttling',\n\t\t\t\t\t\t'--disable-popup-blocking',\n\t\t\t\t\t\t'--disable-backgrounding-occluded-windows',\n\t\t\t\t\t\t'--disable-renderer-backgrounding',\n\t\t\t\t\t\t'--disable-window-activation',\n\t\t\t\t\t\t'--disable-focus-on-load',\n\t\t\t\t\t\t'--no-first-run',\n\t\t\t\t\t\t'--no-default-browser-check',\n\t\t\t\t\t\t'--no-startup-window',\n\t\t\t\t\t\t'--window-position=0,0',\n\t\t\t\t\t\t# '--window-size=1280,1000',\n\t\t\t\t\t]\n\t\t\t\t\t+ disable_security_args\n\t\t\t\t\t+ self.config.extra_chromium_args,\n\t\t\t\t\tproxy=self.config.proxy,\n\t\t\t\t)\n\n\t\t\t\treturn browser\n\t\t\texcept Exception as e:\n\t\t\t\tlogger.error(f'Failed to initialize Playwright browser: {str(e)}')\n\t\t\t\traise\n\n\tasync def close(self):\n\t\t\"\"\"Close the browser instance\"\"\"\n\t\ttry:\n\t\t\tif self.playwright_browser:\n\t\t\t\tawait self.playwright_browser.close()\n\t\t\tif self.playwright:\n\t\t\t\tawait self.playwright.stop()\n\t\texcept Exception as e:\n\t\t\tlogger.debug(f'Failed to close browser properly: {e}')\n\t\tfinally:\n\t\t\tself.playwright_browser = None\n\t\t\tself.playwright = None\n\n\tdef __del__(self):\n\t\t\"\"\"Async cleanup when object is destroyed\"\"\"\n\t\ttry:\n\t\t\tif self.playwright_browser or self.playwright:\n\t\t\t\tloop = asyncio.get_running_loop()\n\t\t\t\tif loop.is_running():\n\t\t\t\t\tloop.create_task(self.close())\n\t\t\t\telse:\n\t\t\t\t\tasyncio.run(self.close())\n\t\texcept Exception as e:\n\t\t\tlogger.debug(f'Failed to cleanup browser in destructor: {e}')\n"}
{"type": "source_file", "path": "browser-use/browser_use/browser/context.py", "content": "\"\"\"\nPlaywright browser on steroids.\n\"\"\"\n\nimport asyncio\nimport base64\nimport json\nimport logging\nimport os\nimport re\nimport time\nimport uuid\nfrom dataclasses import dataclass, field\nfrom typing import TYPE_CHECKING, Optional, TypedDict\n\nfrom playwright.async_api import Browser as PlaywrightBrowser\nfrom playwright.async_api import (\n\tBrowserContext as PlaywrightBrowserContext,\n)\nfrom playwright.async_api import (\n\tElementHandle,\n\tFrameLocator,\n\tPage,\n)\n\nfrom browser_use.browser.views import BrowserError, BrowserState, TabInfo\nfrom browser_use.dom.service import DomService\nfrom browser_use.dom.views import DOMElementNode, SelectorMap\nfrom browser_use.utils import time_execution_sync\n\nif TYPE_CHECKING:\n\tfrom browser_use.browser.browser import Browser\n\nlogger = logging.getLogger(__name__)\n\n\nclass BrowserContextWindowSize(TypedDict):\n\twidth: int\n\theight: int\n\n\n@dataclass\nclass BrowserContextConfig:\n\t\"\"\"\n\tConfiguration for the BrowserContext.\n\n\tDefault values:\n\t\tcookies_file: None\n\t\t\tPath to cookies file for persistence\n\n\t        disable_security: False\n\t                Disable browser security features\n\n\t\tminimum_wait_page_load_time: 0.5\n\t\t\tMinimum time to wait before getting page state for LLM input\n\n\t        wait_for_network_idle_page_load_time: 1.0\n\t                Time to wait for network requests to finish before getting page state.\n\t                Lower values may result in incomplete page loads.\n\n\t\tmaximum_wait_page_load_time: 5.0\n\t\t\tMaximum time to wait for page load before proceeding anyway\n\n\t\twait_between_actions: 1.0\n\t\t\tTime to wait between multiple per step actions\n\n\t\tbrowser_window_size: {\n\t\t\t\t'width': 1280,\n\t\t\t\t'height': 1100,\n\t\t\t}\n\t\t\tDefault browser window size\n\n\t\tno_viewport: False\n\t\t\tDisable viewport\n\t\tsave_recording_path: None\n\t\t\tPath to save video recordings\n\n\t\ttrace_path: None\n\t\t\tPath to save trace files. It will auto name the file with the TRACE_PATH/{context_id}.zip\n\n\t        locale: None\n\t                Specify user locale, for example en-GB, de-DE, etc. Locale will affect navigator.language value, Accept-Language request header value as well as number and date formatting rules. If not provided, defaults to the system default locale.\n\t\"\"\"\n\n\tcookies_file: str | None = None\n\tminimum_wait_page_load_time: float = 1\n\twait_for_network_idle_page_load_time: float = 1\n\tmaximum_wait_page_load_time: float = 5\n\twait_between_actions: float = 1.5\n\n\tdisable_security: bool = False\n\n\tbrowser_window_size: BrowserContextWindowSize = field(\n\t\tdefault_factory=lambda: {'width': 1280, 'height': 1100}\n\t)\n\tno_viewport: Optional[bool] = None\n\n\tsave_recording_path: str | None = None\n\ttrace_path: str | None = None\n\tlocale: str | None = None\n\n\n@dataclass\nclass BrowserSession:\n\tcontext: PlaywrightBrowserContext\n\tcurrent_page: Page\n\tcached_state: BrowserState\n\n\nclass BrowserContext:\n\tdef __init__(\n\t\tself,\n\t\tbrowser: 'Browser',\n\t\tconfig: BrowserContextConfig = BrowserContextConfig(),\n\t):\n\t\tself.context_id = str(uuid.uuid4())\n\t\tlogger.debug(f'Initializing new browser context with id: {self.context_id}')\n\n\t\tself.config = config\n\t\tself.browser = browser\n\n\t\t# Initialize these as None - they'll be set up when needed\n\t\tself.session: BrowserSession | None = None\n\n\tasync def __aenter__(self):\n\t\t\"\"\"Async context manager entry\"\"\"\n\t\tawait self._initialize_session()\n\t\treturn self\n\n\tasync def __aexit__(self, exc_type, exc_val, exc_tb):\n\t\t\"\"\"Async context manager exit\"\"\"\n\t\tawait self.close()\n\n\tasync def close(self):\n\t\t\"\"\"Close the browser instance\"\"\"\n\t\tlogger.debug('Closing browser context')\n\n\t\ttry:\n\t\t\t# check if already closed\n\t\t\tif self.session is None:\n\t\t\t\treturn\n\n\t\t\tawait self.save_cookies()\n\n\t\t\tif self.config.trace_path:\n\t\t\t\ttry:\n\t\t\t\t\tawait self.session.context.tracing.stop(\n\t\t\t\t\t\tpath=os.path.join(self.config.trace_path, f'{self.context_id}.zip')\n\t\t\t\t\t)\n\t\t\t\texcept Exception as e:\n\t\t\t\t\tlogger.debug(f'Failed to stop tracing: {e}')\n\n\t\t\ttry:\n\t\t\t\tawait self.session.context.close()\n\t\t\texcept Exception as e:\n\t\t\t\tlogger.debug(f'Failed to close context: {e}')\n\t\tfinally:\n\t\t\tself.session = None\n\n\tdef __del__(self):\n\t\t\"\"\"Cleanup when object is destroyed\"\"\"\n\t\tif self.session is not None:\n\t\t\tlogger.debug('BrowserContext was not properly closed before destruction')\n\t\t\ttry:\n\t\t\t\t# Use sync Playwright method for force cleanup\n\t\t\t\tif hasattr(self.session.context, '_impl_obj'):\n\t\t\t\t\tasyncio.run(self.session.context._impl_obj.close())\n\t\t\t\tself.session = None\n\t\t\texcept Exception as e:\n\t\t\t\tlogger.warning(f'Failed to force close browser context: {e}')\n\n\tasync def _initialize_session(self):\n\t\t\"\"\"Initialize the browser session\"\"\"\n\t\tlogger.debug('Initializing browser context')\n\n\t\tplaywright_browser = await self.browser.get_playwright_browser()\n\n\t\tcontext = await self._create_context(playwright_browser)\n\t\tself._add_new_page_listener(context)\n\t\tpage = await context.new_page()\n\n\t\t# Instead of calling _update_state(), create an empty initial state\n\t\tinitial_state = BrowserState(\n\t\t\telement_tree=DOMElementNode(\n\t\t\t\ttag_name='root',\n\t\t\t\tis_visible=True,\n\t\t\t\tparent=None,\n\t\t\t\txpath='',\n\t\t\t\tattributes={},\n\t\t\t\tchildren=[],\n\t\t\t),\n\t\t\tselector_map={},\n\t\t\turl=page.url,\n\t\t\ttitle=await page.title(),\n\t\t\tscreenshot=None,\n\t\t\ttabs=[],\n\t\t)\n\n\t\tself.session = BrowserSession(\n\t\t\tcontext=context,\n\t\t\tcurrent_page=page,\n\t\t\tcached_state=initial_state,\n\t\t)\n\t\treturn self.session\n\n\tdef _add_new_page_listener(self, context: PlaywrightBrowserContext):\n\t\tasync def on_page(page: Page):\n\t\t\tawait page.wait_for_load_state()\n\t\t\tlogger.debug(f'New page opened: {page.url}')\n\t\t\tif self.session is not None:\n\t\t\t\tself.session.current_page = page\n\n\t\tcontext.on('page', on_page)\n\n\tasync def get_session(self) -> BrowserSession:\n\t\t\"\"\"Lazy initialization of the browser and related components\"\"\"\n\t\tif self.session is None:\n\t\t\treturn await self._initialize_session()\n\t\treturn self.session\n\n\tasync def get_current_page(self) -> Page:\n\t\t\"\"\"Get the current page\"\"\"\n\t\tsession = await self.get_session()\n\t\treturn session.current_page\n\n\tasync def _create_context(self, browser: PlaywrightBrowser):\n\t\t\"\"\"Creates a new browser context with anti-detection measures and loads cookies if available.\"\"\"\n\t\tif self.browser.config.chrome_instance_path and len(browser.contexts) > 0:\n\t\t\t# Connect to existing Chrome instance instead of creating new one\n\t\t\tcontext = browser.contexts[0]\n\t\telse:\n\t\t\t# Original code for creating new context\n\t\t\tcontext = await browser.new_context(\n\t\t\t\tviewport=self.config.browser_window_size,\n\t\t\t\tno_viewport=False,\n\t\t\t\tuser_agent=(\n\t\t\t\t\t'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n\t\t\t\t\t'(KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'\n\t\t\t\t),\n\t\t\t\tjava_script_enabled=True,\n\t\t\t\tbypass_csp=self.config.disable_security,\n\t\t\t\tignore_https_errors=self.config.disable_security,\n\t\t\t\trecord_video_dir=self.config.save_recording_path,\n\t\t\t\tlocale=self.config.locale,\n\t\t\t)\n\n\t\tif self.config.trace_path:\n\t\t\tawait context.tracing.start(screenshots=True, snapshots=True, sources=True)\n\n\t\t# Load cookies if they exist\n\t\tif self.config.cookies_file and os.path.exists(self.config.cookies_file):\n\t\t\twith open(self.config.cookies_file, 'r') as f:\n\t\t\t\tcookies = json.load(f)\n\t\t\t\tlogger.info(f'Loaded {len(cookies)} cookies from {self.config.cookies_file}')\n\t\t\t\tawait context.add_cookies(cookies)\n\n\t\t# Expose anti-detection scripts\n\t\tawait context.add_init_script(\n\t\t\t\"\"\"\n\t\t\t// Webdriver property\n\t\t\tObject.defineProperty(navigator, 'webdriver', {\n\t\t\t\tget: () => undefined\n\t\t\t});\n\n\t\t\t// Languages\n\t\t\tObject.defineProperty(navigator, 'languages', {\n\t\t\t\tget: () => ['en-US', 'en']\n\t\t\t});\n\n\t\t\t// Plugins\n\t\t\tObject.defineProperty(navigator, 'plugins', {\n\t\t\t\tget: () => [1, 2, 3, 4, 5]\n\t\t\t});\n\n\t\t\t// Chrome runtime\n\t\t\twindow.chrome = { runtime: {} };\n\n\t\t\t// Permissions\n\t\t\tconst originalQuery = window.navigator.permissions.query;\n\t\t\twindow.navigator.permissions.query = (parameters) => (\n\t\t\t\tparameters.name === 'notifications' ?\n\t\t\t\t\tPromise.resolve({ state: Notification.permission }) :\n\t\t\t\t\toriginalQuery(parameters)\n\t\t\t);\n\t\t\t\"\"\"\n\t\t)\n\n\t\treturn context\n\n\tasync def _wait_for_stable_network(self):\n\t\tpage = await self.get_current_page()\n\n\t\tpending_requests = set()\n\t\tlast_activity = asyncio.get_event_loop().time()\n\n\t\t# Define relevant resource types and content types\n\t\tRELEVANT_RESOURCE_TYPES = {\n\t\t\t'document',\n\t\t\t'stylesheet',\n\t\t\t'image',\n\t\t\t'font',\n\t\t\t'script',\n\t\t\t'iframe',\n\t\t}\n\n\t\tRELEVANT_CONTENT_TYPES = {\n\t\t\t'text/html',\n\t\t\t'text/css',\n\t\t\t'application/javascript',\n\t\t\t'image/',\n\t\t\t'font/',\n\t\t\t'application/json',\n\t\t}\n\n\t\t# Additional patterns to filter out\n\t\tIGNORED_URL_PATTERNS = {\n\t\t\t# Analytics and tracking\n\t\t\t'analytics',\n\t\t\t'tracking',\n\t\t\t'telemetry',\n\t\t\t'beacon',\n\t\t\t'metrics',\n\t\t\t# Ad-related\n\t\t\t'doubleclick',\n\t\t\t'adsystem',\n\t\t\t'adserver',\n\t\t\t'advertising',\n\t\t\t# Social media widgets\n\t\t\t'facebook.com/plugins',\n\t\t\t'platform.twitter',\n\t\t\t'linkedin.com/embed',\n\t\t\t# Live chat and support\n\t\t\t'livechat',\n\t\t\t'zendesk',\n\t\t\t'intercom',\n\t\t\t'crisp.chat',\n\t\t\t'hotjar',\n\t\t\t# Push notifications\n\t\t\t'push-notifications',\n\t\t\t'onesignal',\n\t\t\t'pushwoosh',\n\t\t\t# Background sync/heartbeat\n\t\t\t'heartbeat',\n\t\t\t'ping',\n\t\t\t'alive',\n\t\t\t# WebRTC and streaming\n\t\t\t'webrtc',\n\t\t\t'rtmp://',\n\t\t\t'wss://',\n\t\t\t# Common CDNs for dynamic content\n\t\t\t'cloudfront.net',\n\t\t\t'fastly.net',\n\t\t}\n\n\t\tasync def on_request(request):\n\t\t\t# Filter by resource type\n\t\t\tif request.resource_type not in RELEVANT_RESOURCE_TYPES:\n\t\t\t\treturn\n\n\t\t\t# Filter out streaming, websocket, and other real-time requests\n\t\t\tif request.resource_type in {\n\t\t\t\t'websocket',\n\t\t\t\t'media',\n\t\t\t\t'eventsource',\n\t\t\t\t'manifest',\n\t\t\t\t'other',\n\t\t\t}:\n\t\t\t\treturn\n\n\t\t\t# Filter out by URL patterns\n\t\t\turl = request.url.lower()\n\t\t\tif any(pattern in url for pattern in IGNORED_URL_PATTERNS):\n\t\t\t\treturn\n\n\t\t\t# Filter out data URLs and blob URLs\n\t\t\tif url.startswith(('data:', 'blob:')):\n\t\t\t\treturn\n\n\t\t\t# Filter out requests with certain headers\n\t\t\theaders = request.headers\n\t\t\tif headers.get('purpose') == 'prefetch' or headers.get('sec-fetch-dest') in [\n\t\t\t\t'video',\n\t\t\t\t'audio',\n\t\t\t]:\n\t\t\t\treturn\n\n\t\t\tnonlocal last_activity\n\t\t\tpending_requests.add(request)\n\t\t\tlast_activity = asyncio.get_event_loop().time()\n\t\t\t# logger.debug(f'Request started: {request.url} ({request.resource_type})')\n\n\t\tasync def on_response(response):\n\t\t\trequest = response.request\n\t\t\tif request not in pending_requests:\n\t\t\t\treturn\n\n\t\t\t# Filter by content type if available\n\t\t\tcontent_type = response.headers.get('content-type', '').lower()\n\n\t\t\t# Skip if content type indicates streaming or real-time data\n\t\t\tif any(\n\t\t\t\tt in content_type\n\t\t\t\tfor t in [\n\t\t\t\t\t'streaming',\n\t\t\t\t\t'video',\n\t\t\t\t\t'audio',\n\t\t\t\t\t'webm',\n\t\t\t\t\t'mp4',\n\t\t\t\t\t'event-stream',\n\t\t\t\t\t'websocket',\n\t\t\t\t\t'protobuf',\n\t\t\t\t]\n\t\t\t):\n\t\t\t\tpending_requests.remove(request)\n\t\t\t\treturn\n\n\t\t\t# Only process relevant content types\n\t\t\tif not any(ct in content_type for ct in RELEVANT_CONTENT_TYPES):\n\t\t\t\tpending_requests.remove(request)\n\t\t\t\treturn\n\n\t\t\t# Skip if response is too large (likely not essential for page load)\n\t\t\tcontent_length = response.headers.get('content-length')\n\t\t\tif content_length and int(content_length) > 5 * 1024 * 1024:  # 5MB\n\t\t\t\tpending_requests.remove(request)\n\t\t\t\treturn\n\n\t\t\tnonlocal last_activity\n\t\t\tpending_requests.remove(request)\n\t\t\tlast_activity = asyncio.get_event_loop().time()\n\t\t\t# logger.debug(f'Request resolved: {request.url} ({content_type})')\n\n\t\t# Attach event listeners\n\t\tpage.on('request', on_request)\n\t\tpage.on('response', on_response)\n\n\t\ttry:\n\t\t\t# Wait for idle time\n\t\t\tstart_time = asyncio.get_event_loop().time()\n\t\t\twhile True:\n\t\t\t\tawait asyncio.sleep(0.1)\n\t\t\t\tnow = asyncio.get_event_loop().time()\n\t\t\t\tif (\n\t\t\t\t\tlen(pending_requests) == 0\n\t\t\t\t\tand (now - last_activity) >= self.config.wait_for_network_idle_page_load_time\n\t\t\t\t):\n\t\t\t\t\tbreak\n\t\t\t\tif now - start_time > self.config.maximum_wait_page_load_time:\n\t\t\t\t\tlogger.debug(\n\t\t\t\t\t\tf'Network timeout after {self.config.maximum_wait_page_load_time}s with {len(pending_requests)} '\n\t\t\t\t\t\tf'pending requests: {[r.url for r in pending_requests]}'\n\t\t\t\t\t)\n\t\t\t\t\tbreak\n\n\t\tfinally:\n\t\t\t# Clean up event listeners\n\t\t\tpage.remove_listener('request', on_request)\n\t\t\tpage.remove_listener('response', on_response)\n\n\t\tlogger.debug(\n\t\t\tf'Network stabilized for {self.config.wait_for_network_idle_page_load_time} seconds'\n\t\t)\n\n\tasync def _wait_for_page_and_frames_load(self, timeout_overwrite: float | None = None):\n\t\t\"\"\"\n\t\tEnsures page is fully loaded before continuing.\n\t\tWaits for either network to be idle or minimum WAIT_TIME, whichever is longer.\n\t\t\"\"\"\n\t\t# Start timing\n\t\tstart_time = time.time()\n\n\t\t# await asyncio.sleep(self.minimum_wait_page_load_time)\n\n\t\t# Wait for page load\n\t\ttry:\n\t\t\tawait self._wait_for_stable_network()\n\t\texcept Exception:\n\t\t\tlogger.warning('Page load failed, continuing...')\n\t\t\tpass\n\n\t\t# Calculate remaining time to meet minimum WAIT_TIME\n\t\telapsed = time.time() - start_time\n\t\tremaining = max((timeout_overwrite or self.config.minimum_wait_page_load_time) - elapsed, 0)\n\n\t\tlogger.debug(\n\t\t\tf'--Page loaded in {elapsed:.2f} seconds, waiting for additional {remaining:.2f} seconds'\n\t\t)\n\n\t\t# Sleep remaining time if needed\n\t\tif remaining > 0:\n\t\t\tawait asyncio.sleep(remaining)\n\n\tasync def navigate_to(self, url: str):\n\t\t\"\"\"Navigate to a URL\"\"\"\n\t\tpage = await self.get_current_page()\n\t\tawait page.goto(url)\n\t\tawait page.wait_for_load_state()\n\n\tasync def refresh_page(self):\n\t\t\"\"\"Refresh the current page\"\"\"\n\t\tpage = await self.get_current_page()\n\t\tawait page.reload()\n\t\tawait page.wait_for_load_state()\n\n\tasync def go_back(self):\n\t\t\"\"\"Navigate back in history\"\"\"\n\t\tpage = await self.get_current_page()\n\t\tawait page.go_back()\n\t\tawait page.wait_for_load_state()\n\n\tasync def go_forward(self):\n\t\t\"\"\"Navigate forward in history\"\"\"\n\t\tpage = await self.get_current_page()\n\t\tawait page.go_forward()\n\t\tawait page.wait_for_load_state()\n\n\tasync def close_current_tab(self):\n\t\t\"\"\"Close the current tab\"\"\"\n\t\tsession = await self.get_session()\n\t\tpage = session.current_page\n\t\tawait page.close()\n\n\t\t# Switch to the first available tab if any exist\n\t\tif session.context.pages:\n\t\t\tawait self.switch_to_tab(0)\n\n\t\t# otherwise the browser will be closed\n\n\tasync def get_page_html(self) -> str:\n\t\t\"\"\"Get the current page HTML content\"\"\"\n\t\tpage = await self.get_current_page()\n\t\treturn await page.content()\n\n\tasync def execute_javascript(self, script: str):\n\t\t\"\"\"Execute JavaScript code on the page\"\"\"\n\t\tpage = await self.get_current_page()\n\t\treturn await page.evaluate(script)\n\n\t@time_execution_sync('--get_state')  # This decorator might need to be updated to handle async\n\tasync def get_state(self, use_vision: bool = False) -> BrowserState:\n\t\t\"\"\"Get the current state of the browser\"\"\"\n\t\tawait self._wait_for_page_and_frames_load()\n\t\tsession = await self.get_session()\n\t\tsession.cached_state = await self._update_state(use_vision=use_vision)\n\n\t\t# Save cookies if a file is specified\n\t\tif self.config.cookies_file:\n\t\t\tasyncio.create_task(self.save_cookies())\n\n\t\treturn session.cached_state\n\n\tasync def _update_state(self, use_vision: bool = False) -> BrowserState:\n\t\t\"\"\"Update and return state.\"\"\"\n\t\tsession = await self.get_session()\n\n\t\t# Check if current page is still valid, if not switch to another available page\n\t\ttry:\n\t\t\tpage = await self.get_current_page()\n\t\t\t# Test if page is still accessible\n\t\t\tawait page.evaluate('1')\n\t\texcept Exception as e:\n\t\t\tlogger.debug(f'Current page is no longer accessible: {str(e)}')\n\t\t\t# Get all available pages\n\t\t\tpages = session.context.pages\n\t\t\tif pages:\n\t\t\t\tsession.current_page = pages[-1]\n\t\t\t\tpage = session.current_page\n\t\t\t\tlogger.debug(f'Switched to page: {await page.title()}')\n\t\t\telse:\n\t\t\t\traise BrowserError('Browser closed: no valid pages available')\n\n\t\ttry:\n\t\t\tawait self.remove_highlights()\n\t\t\tdom_service = DomService(page)\n\t\t\tcontent = await dom_service.get_clickable_elements()\n\n\t\t\tscreenshot_b64 = None\n\t\t\tif use_vision:\n\t\t\t\tscreenshot_b64 = await self.take_screenshot()\n\n\t\t\tself.current_state = BrowserState(\n\t\t\t\telement_tree=content.element_tree,\n\t\t\t\tselector_map=content.selector_map,\n\t\t\t\turl=page.url,\n\t\t\t\ttitle=await page.title(),\n\t\t\t\ttabs=await self.get_tabs_info(),\n\t\t\t\tscreenshot=screenshot_b64,\n\t\t\t)\n\n\t\t\treturn self.current_state\n\t\texcept Exception as e:\n\t\t\tlogger.error(f'Failed to update state: {str(e)}')\n\t\t\t# Return last known good state if available\n\t\t\tif hasattr(self, 'current_state'):\n\t\t\t\treturn self.current_state\n\t\t\traise\n\n\t# region - Browser Actions\n\n\tasync def take_screenshot(self, full_page: bool = False) -> str:\n\t\t\"\"\"\n\t\tReturns a base64 encoded screenshot of the current page.\n\t\t\"\"\"\n\t\tpage = await self.get_current_page()\n\n\t\tscreenshot = await page.screenshot(\n\t\t\tfull_page=full_page,\n\t\t\tanimations='disabled',\n\t\t)\n\n\t\tscreenshot_b64 = base64.b64encode(screenshot).decode('utf-8')\n\n\t\t# await self.remove_highlights()\n\n\t\treturn screenshot_b64\n\n\tasync def remove_highlights(self):\n\t\t\"\"\"\n\t\tRemoves all highlight overlays and labels created by the highlightElement function.\n\t\tHandles cases where the page might be closed or inaccessible.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tpage = await self.get_current_page()\n\t\t\tawait page.evaluate(\n\t\t\t\t\"\"\"\n                try {\n                    // Remove the highlight container and all its contents\n                    const container = document.getElementById('playwright-highlight-container');\n                    if (container) {\n                        container.remove();\n                    }\n\n                    // Remove highlight attributes from elements\n                    const highlightedElements = document.querySelectorAll('[browser-user-highlight-id^=\"playwright-highlight-\"]');\n                    highlightedElements.forEach(el => {\n                        el.removeAttribute('browser-user-highlight-id');\n                    });\n                } catch (e) {\n                    console.error('Failed to remove highlights:', e);\n                }\n                \"\"\"\n\t\t\t)\n\t\texcept Exception as e:\n\t\t\tlogger.debug(f'Failed to remove highlights (this is usually ok): {str(e)}')\n\t\t\t# Don't raise the error since this is not critical functionality\n\t\t\tpass\n\n\t# endregion\n\n\t# region - User Actions\n\tdef _convert_simple_xpath_to_css_selector(self, xpath: str) -> str:\n\t\t\"\"\"Converts simple XPath expressions to CSS selectors.\"\"\"\n\t\tif not xpath:\n\t\t\treturn ''\n\n\t\t# Remove leading slash if present\n\t\txpath = xpath.lstrip('/')\n\n\t\t# Split into parts\n\t\tparts = xpath.split('/')\n\t\tcss_parts = []\n\n\t\tfor part in parts:\n\t\t\tif not part:\n\t\t\t\tcontinue\n\n\t\t\t# Handle index notation [n]\n\t\t\tif '[' in part:\n\t\t\t\tbase_part = part[: part.find('[')]\n\t\t\t\tindex_part = part[part.find('[') :]\n\n\t\t\t\t# Handle multiple indices\n\t\t\t\tindices = [i.strip('[]') for i in index_part.split(']')[:-1]]\n\n\t\t\t\tfor idx in indices:\n\t\t\t\t\ttry:\n\t\t\t\t\t\t# Handle numeric indices\n\t\t\t\t\t\tif idx.isdigit():\n\t\t\t\t\t\t\tindex = int(idx) - 1\n\t\t\t\t\t\t\tbase_part += f':nth-of-type({index+1})'\n\t\t\t\t\t\t# Handle last() function\n\t\t\t\t\t\telif idx == 'last()':\n\t\t\t\t\t\t\tbase_part += ':last-of-type'\n\t\t\t\t\t\t# Handle position() functions\n\t\t\t\t\t\telif 'position()' in idx:\n\t\t\t\t\t\t\tif '>1' in idx:\n\t\t\t\t\t\t\t\tbase_part += ':nth-of-type(n+2)'\n\t\t\t\t\texcept ValueError:\n\t\t\t\t\t\tcontinue\n\n\t\t\t\tcss_parts.append(base_part)\n\t\t\telse:\n\t\t\t\tcss_parts.append(part)\n\n\t\tbase_selector = ' > '.join(css_parts)\n\t\treturn base_selector\n\n\tdef _enhanced_css_selector_for_element(self, element: DOMElementNode) -> str:\n\t\t\"\"\"\n\t\tCreates a CSS selector for a DOM element, handling various edge cases and special characters.\n\n\t\tArgs:\n\t\t        element: The DOM element to create a selector for\n\n\t\tReturns:\n\t\t        A valid CSS selector string\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# Get base selector from XPath\n\t\t\tcss_selector = self._convert_simple_xpath_to_css_selector(element.xpath)\n\n\t\t\t# Handle class attributes\n\t\t\tif 'class' in element.attributes and element.attributes['class']:\n\t\t\t\t# Define a regex pattern for valid class names in CSS\n\t\t\t\tvalid_class_name_pattern = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_-]*$')\n\n\t\t\t\t# Iterate through the class attribute values\n\t\t\t\tclasses = element.attributes['class'].split()\n\t\t\t\tfor class_name in classes:\n\t\t\t\t\t# Skip empty class names\n\t\t\t\t\tif not class_name.strip():\n\t\t\t\t\t\tcontinue\n\n\t\t\t\t\t# Check if the class name is valid\n\t\t\t\t\tif valid_class_name_pattern.match(class_name):\n\t\t\t\t\t\t# Append the valid class name to the CSS selector\n\t\t\t\t\t\tcss_selector += f'.{class_name}'\n\t\t\t\t\telse:\n\t\t\t\t\t\t# Skip invalid class names\n\t\t\t\t\t\tcontinue\n\n\t\t\t# Expanded set of safe attributes that are stable and useful for selection\n\t\t\tSAFE_ATTRIBUTES = {\n\t\t\t\t# Standard HTML attributes\n\t\t\t\t'id',\n\t\t\t\t'name',\n\t\t\t\t'type',\n\t\t\t\t'value',\n\t\t\t\t'placeholder',\n\t\t\t\t# Accessibility attributes\n\t\t\t\t'aria-label',\n\t\t\t\t'aria-labelledby',\n\t\t\t\t'aria-describedby',\n\t\t\t\t'role',\n\t\t\t\t# Common form attributes\n\t\t\t\t'for',\n\t\t\t\t'autocomplete',\n\t\t\t\t'required',\n\t\t\t\t'readonly',\n\t\t\t\t# Media attributes\n\t\t\t\t'alt',\n\t\t\t\t'title',\n\t\t\t\t'src',\n\t\t\t\t# Data attributes (if they're stable in your application)\n\t\t\t\t'data-testid',\n\t\t\t\t'data-id',\n\t\t\t\t'data-qa',\n\t\t\t\t'data-cy',\n\t\t\t\t# Custom stable attributes (add any application-specific ones)\n\t\t\t\t'href',\n\t\t\t\t'target',\n\t\t\t}\n\n\t\t\t# Handle other attributes\n\t\t\tfor attribute, value in element.attributes.items():\n\t\t\t\tif attribute == 'class':\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Skip invalid attribute names\n\t\t\t\tif not attribute.strip():\n\t\t\t\t\tcontinue\n\n\t\t\t\tif attribute not in SAFE_ATTRIBUTES:\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Escape special characters in attribute names\n\t\t\t\tsafe_attribute = attribute.replace(':', r'\\:')\n\n\t\t\t\t# Handle different value cases\n\t\t\t\tif value == '':\n\t\t\t\t\tcss_selector += f'[{safe_attribute}]'\n\t\t\t\telif any(char in value for char in '\"\\'<>`'):\n\t\t\t\t\t# Use contains for values with special characters\n\t\t\t\t\tsafe_value = value.replace('\"', '\\\\\"')\n\t\t\t\t\tcss_selector += f'[{safe_attribute}*=\"{safe_value}\"]'\n\t\t\t\telse:\n\t\t\t\t\tcss_selector += f'[{safe_attribute}=\"{value}\"]'\n\n\t\t\treturn css_selector\n\n\t\texcept Exception:\n\t\t\t# Fallback to a more basic selector if something goes wrong\n\t\t\ttag_name = element.tag_name or '*'\n\t\t\treturn f\"{tag_name}[highlight_index='{element.highlight_index}']\"\n\n\tasync def get_locate_element(self, element: DOMElementNode) -> ElementHandle | None:\n\t\tcurrent_frame = await self.get_current_page()\n\n\t\t# Start with the target element and collect all parents\n\t\tparents: list[DOMElementNode] = []\n\t\tcurrent = element\n\t\twhile current.parent is not None:\n\t\t\tparent = current.parent\n\t\t\tparents.append(parent)\n\t\t\tcurrent = parent\n\t\t\tif parent.tag_name == 'iframe':\n\t\t\t\tbreak\n\n\t\t# There can be only one iframe parent (by design of the loop above)\n\t\tiframe_parent = [item for item in parents if item.tag_name == 'iframe']\n\t\tif iframe_parent:\n\t\t\tparent = iframe_parent[0]\n\t\t\tcss_selector = self._enhanced_css_selector_for_element(parent)\n\t\t\tcurrent_frame = current_frame.frame_locator(css_selector)\n\n\t\tcss_selector = self._enhanced_css_selector_for_element(element)\n\n\t\ttry:\n\t\t\tif isinstance(current_frame, FrameLocator):\n\t\t\t\treturn await current_frame.locator(css_selector).element_handle()\n\t\t\telse:\n\t\t\t\t# Try to scroll into view if hidden\n\t\t\t\telement_handle = await current_frame.query_selector(css_selector)\n\t\t\t\tif element_handle:\n\t\t\t\t\tawait element_handle.scroll_into_view_if_needed()\n\t\t\t\t\treturn element_handle\n\t\texcept Exception as e:\n\t\t\tlogger.error(f'Failed to locate element: {str(e)}')\n\t\t\treturn None\n\n\tasync def _input_text_element_node(self, element_node: DOMElementNode, text: str):\n\t\ttry:\n\t\t\tpage = await self.get_current_page()\n\t\t\telement = await self.get_locate_element(element_node)\n\n\t\t\tif element is None:\n\t\t\t\traise Exception(f'Element: {repr(element_node)} not found')\n\n\t\t\tawait element.scroll_into_view_if_needed(timeout=2500)\n\t\t\tawait element.fill('')\n\t\t\tawait element.type(text)\n\t\t\tawait page.wait_for_load_state()\n\n\t\texcept Exception as e:\n\t\t\traise Exception(\n\t\t\t\tf'Failed to input text into element: {repr(element_node)}. Error: {str(e)}'\n\t\t\t)\n\n\tasync def _click_element_node(self, element_node: DOMElementNode):\n\t\t\"\"\"\n\t\tOptimized method to click an element using xpath.\n\t\t\"\"\"\n\t\tpage = await self.get_current_page()\n\n\t\ttry:\n\t\t\telement = await self.get_locate_element(element_node)\n\n\t\t\tif element is None:\n\t\t\t\traise Exception(f'Element: {repr(element_node)} not found')\n\n\t\t\t# await element.scroll_into_view_if_needed()\n\n\t\t\ttry:\n\t\t\t\tawait element.click(timeout=1500)\n\t\t\t\tawait page.wait_for_load_state()\n\t\t\texcept Exception:\n\t\t\t\ttry:\n\t\t\t\t\tawait page.evaluate('(el) => el.click()', element)\n\t\t\t\t\tawait page.wait_for_load_state()\n\t\t\t\texcept Exception as e:\n\t\t\t\t\traise Exception(f'Failed to click element: {str(e)}')\n\n\t\texcept Exception as e:\n\t\t\traise Exception(f'Failed to click element: {repr(element_node)}. Error: {str(e)}')\n\n\tasync def get_tabs_info(self) -> list[TabInfo]:\n\t\t\"\"\"Get information about all tabs\"\"\"\n\t\tsession = await self.get_session()\n\n\t\ttabs_info = []\n\t\tfor page_id, page in enumerate(session.context.pages):\n\t\t\ttab_info = TabInfo(page_id=page_id, url=page.url, title=await page.title())\n\t\t\ttabs_info.append(tab_info)\n\n\t\treturn tabs_info\n\n\tasync def switch_to_tab(self, page_id: int) -> None:\n\t\t\"\"\"Switch to a specific tab by its page_id\n\n\t\t@You can also use negative indices to switch to tabs from the end (Pure pythonic way)\n\t\t\"\"\"\n\t\tsession = await self.get_session()\n\t\tpages = session.context.pages\n\n\t\tif page_id >= len(pages):\n\t\t\traise BrowserError(f'No tab found with page_id: {page_id}')\n\n\t\tpage = pages[page_id]\n\t\tsession.current_page = page\n\n\t\tawait page.bring_to_front()\n\t\tawait page.wait_for_load_state()\n\n\tasync def create_new_tab(self, url: str | None = None) -> None:\n\t\t\"\"\"Create a new tab and optionally navigate to a URL\"\"\"\n\t\tsession = await self.get_session()\n\t\tnew_page = await session.context.new_page()\n\t\tsession.current_page = new_page\n\n\t\tawait new_page.wait_for_load_state()\n\n\t\tpage = await self.get_current_page()\n\n\t\tif url:\n\t\t\tawait page.goto(url)\n\t\t\tawait self._wait_for_page_and_frames_load(timeout_overwrite=1)\n\n\t# endregion\n\n\t# region - Helper methods for easier access to the DOM\n\tasync def get_selector_map(self) -> SelectorMap:\n\t\tsession = await self.get_session()\n\t\treturn session.cached_state.selector_map\n\n\tasync def get_element_by_index(self, index: int) -> ElementHandle | None:\n\t\tselector_map = await self.get_selector_map()\n\t\treturn await self.get_locate_element(selector_map[index])\n\n\tasync def get_dom_element_by_index(self, index: int) -> DOMElementNode | None:\n\t\tselector_map = await self.get_selector_map()\n\t\treturn selector_map[index]\n\n\tasync def save_cookies(self):\n\t\t\"\"\"Save current cookies to file\"\"\"\n\t\tif self.session and self.session.context and self.config.cookies_file:\n\t\t\ttry:\n\t\t\t\tcookies = await self.session.context.cookies()\n\t\t\t\tlogger.info(f'Saving {len(cookies)} cookies to {self.config.cookies_file}')\n\n\t\t\t\t# Check if the path is a directory and create it if necessary\n\t\t\t\tdirname = os.path.dirname(self.config.cookies_file)\n\t\t\t\tif dirname:\n\t\t\t\t\tos.makedirs(dirname, exist_ok=True)\n\n\t\t\t\twith open(self.config.cookies_file, 'w') as f:\n\t\t\t\t\tjson.dump(cookies, f)\n\t\t\texcept Exception as e:\n\t\t\t\tlogger.warning(f'Failed to save cookies: {str(e)}')\n\n\tasync def is_file_uploader(\n\t\tself, element_node: DOMElementNode, max_depth: int = 3, current_depth: int = 0\n\t) -> bool:\n\t\t\"\"\"Check if element or its children are file uploaders\"\"\"\n\t\tif current_depth > max_depth:\n\t\t\treturn False\n\n\t\t# Check current element\n\t\tis_uploader = False\n\n\t\tif not isinstance(element_node, DOMElementNode):\n\t\t\treturn False\n\n\t\t# Check for file input attributes\n\t\tif element_node.tag_name == 'input':\n\t\t\tis_uploader = (\n\t\t\t\telement_node.attributes.get('type') == 'file'\n\t\t\t\tor element_node.attributes.get('accept') is not None\n\t\t\t)\n\n\t\tif is_uploader:\n\t\t\treturn True\n\n\t\t# Recursively check children\n\t\tif element_node.children and current_depth < max_depth:\n\t\t\tfor child in element_node.children:\n\t\t\t\tif isinstance(child, DOMElementNode):\n\t\t\t\t\tif await self.is_file_uploader(child, max_depth, current_depth + 1):\n\t\t\t\t\t\treturn True\n\n\t\treturn False\n"}
{"type": "source_file", "path": "browser-use/browser_use/dom/service.py", "content": "import logging\nfrom importlib import resources\nfrom typing import Optional\n\nfrom playwright.async_api import Page\n\nfrom browser_use.dom.views import (\n\tDOMBaseNode,\n\tDOMElementNode,\n\tDOMState,\n\tDOMTextNode,\n\tSelectorMap,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nclass DomService:\n\tdef __init__(self, page: Page):\n\t\tself.page = page\n\t\tself.xpath_cache = {}\n\n\t# region - Clickable elements\n\tasync def get_clickable_elements(self, highlight_elements: bool = True) -> DOMState:\n\t\telement_tree = await self._build_dom_tree(highlight_elements)\n\t\tselector_map = self._create_selector_map(element_tree)\n\n\t\treturn DOMState(element_tree=element_tree, selector_map=selector_map)\n\n\tasync def _build_dom_tree(self, highlight_elements: bool) -> DOMElementNode:\n\t\tjs_code = resources.read_text('browser_use.dom', 'buildDomTree.js')\n\n\t\teval_page = await self.page.evaluate(\n\t\t\tjs_code, (highlight_elements)\n\t\t)  # This is quite big, so be careful\n\t\thtml_to_dict = self._parse_node(eval_page)\n\n\t\tif html_to_dict is None or not isinstance(html_to_dict, DOMElementNode):\n\t\t\traise ValueError('Failed to parse HTML to dictionary')\n\n\t\treturn html_to_dict\n\n\tdef _create_selector_map(self, element_tree: DOMElementNode) -> SelectorMap:\n\t\tselector_map = {}\n\n\t\tdef process_node(node: DOMBaseNode):\n\t\t\tif isinstance(node, DOMElementNode):\n\t\t\t\tif node.highlight_index is not None:\n\t\t\t\t\tselector_map[node.highlight_index] = node\n\n\t\t\t\tfor child in node.children:\n\t\t\t\t\tprocess_node(child)\n\n\t\tprocess_node(element_tree)\n\t\treturn selector_map\n\n\tdef _parse_node(\n\t\tself,\n\t\tnode_data: dict,\n\t\tparent: Optional[DOMElementNode] = None,\n\t) -> Optional[DOMBaseNode]:\n\t\tif not node_data:\n\t\t\treturn None\n\n\t\tif node_data.get('type') == 'TEXT_NODE':\n\t\t\ttext_node = DOMTextNode(\n\t\t\t\ttext=node_data['text'],\n\t\t\t\tis_visible=node_data['isVisible'],\n\t\t\t\tparent=parent,\n\t\t\t)\n\n\t\t\treturn text_node\n\n\t\ttag_name = node_data['tagName']\n\n\t\telement_node = DOMElementNode(\n\t\t\ttag_name=tag_name,\n\t\t\txpath=node_data['xpath'],\n\t\t\tattributes=node_data.get('attributes', {}),\n\t\t\tchildren=[],  # Initialize empty, will fill later\n\t\t\tis_visible=node_data.get('isVisible', False),\n\t\t\tis_interactive=node_data.get('isInteractive', False),\n\t\t\tis_top_element=node_data.get('isTopElement', False),\n\t\t\thighlight_index=node_data.get('highlightIndex'),\n\t\t\tshadow_root=node_data.get('shadowRoot', False),\n\t\t\tparent=parent,\n\t\t)\n\n\t\tchildren: list[DOMBaseNode] = []\n\t\tfor child in node_data.get('children', []):\n\t\t\tif child is not None:\n\t\t\t\tchild_node = self._parse_node(child, parent=element_node)\n\t\t\t\tif child_node is not None:\n\t\t\t\t\tchildren.append(child_node)\n\n\t\telement_node.children = children\n\n\t\treturn element_node\n\n\t# endregion\n"}
{"type": "source_file", "path": "browser-use/browser_use/controller/service.py", "content": "import asyncio\nimport logging\nimport json\n\nfrom main_content_extractor import MainContentExtractor\n\nfrom browser_use.agent.views import ActionModel, ActionResult\nfrom browser_use.browser.context import BrowserContext\nfrom browser_use.controller.registry.service import Registry\nfrom browser_use.controller.views import (\n\tClickElementAction,\n\tDoneAction,\n\tExtractPageContentAction,\n\tGoToUrlAction,\n\tInputTextAction,\n\tOpenTabAction,\n\tScrollAction,\n\tSearchGoogleAction,\n\tSendKeysAction,\n\tSwitchTabAction,\n)\nfrom browser_use.utils import time_execution_async, time_execution_sync\n\nlogger = logging.getLogger(__name__)\n\n\nclass Controller:\n\tdef __init__(\n\t\tself,\n\t):\n\t\tself.registry = Registry()\n\t\tself._register_default_actions()\n\n\tdef _register_default_actions(self):\n\t\t\"\"\"Register all default browser actions\"\"\"\n\n\t\t# Basic Navigation Actions\n\t\t@self.registry.action(\n\t\t\t'Search Google in the current tab',\n\t\t\tparam_model=SearchGoogleAction,\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def search_google(params: SearchGoogleAction, browser: BrowserContext):\n\t\t\tpage = await browser.get_current_page()\n\t\t\tawait page.goto(f'https://www.google.com/search?q={params.query}&udm=14')\n\t\t\tawait page.wait_for_load_state()\n\t\t\tmsg = f'🔍  Searched for \"{params.query}\" in Google'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t@self.registry.action(\n\t\t\t'Navigate to URL in the current tab', param_model=GoToUrlAction, requires_browser=True\n\t\t)\n\t\tasync def go_to_url(params: GoToUrlAction, browser: BrowserContext):\n\t\t\tpage = await browser.get_current_page()\n\t\t\tawait page.goto(params.url)\n\t\t\tawait page.wait_for_load_state()\n\t\t\tmsg = f'🔗  Navigated to {params.url}'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t@self.registry.action('Go back', requires_browser=True)\n\t\tasync def go_back(browser: BrowserContext):\n\t\t\tpage = await browser.get_current_page()\n\t\t\tawait page.go_back()\n\t\t\tawait page.wait_for_load_state()\n\t\t\tmsg = '🔙  Navigated back'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t# Element Interaction Actions\n\t\t@self.registry.action(\n\t\t\t'Click element', param_model=ClickElementAction, requires_browser=True\n\t\t)\n\t\tasync def click_element(params: ClickElementAction, browser: BrowserContext):\n\t\t\tsession = await browser.get_session()\n\t\t\tstate = session.cached_state\n\n\t\t\tif params.index not in state.selector_map:\n\t\t\t\traise Exception(\n\t\t\t\t\tf'Element with index {params.index} does not exist - retry or use alternative actions'\n\t\t\t\t)\n\n\t\t\telement_node = state.selector_map[params.index]\n\t\t\tinitial_pages = len(session.context.pages)\n\n\t\t\t# if element has file uploader then dont click\n\t\t\tif await browser.is_file_uploader(element_node):\n\t\t\t\tmsg = f'Index {params.index} - has an element which opens file upload dialog. To upload files please use a specific function to upload files '\n\t\t\t\tlogger.info(msg)\n\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t\tmsg = None\n\n\t\t\ttry:\n\t\t\t\tawait browser._click_element_node(element_node)\n\t\t\t\tmsg = f'🖱️  Clicked button with index {params.index}: {element_node.get_all_text_till_next_clickable_element(max_depth=2)}'\n\n\t\t\t\tlogger.info(msg)\n\t\t\t\tlogger.debug(f'Element xpath: {element_node.xpath}')\n\t\t\t\tif len(session.context.pages) > initial_pages:\n\t\t\t\t\tnew_tab_msg = 'New tab opened - switching to it'\n\t\t\t\t\tmsg += f' - {new_tab_msg}'\n\t\t\t\t\tlogger.info(new_tab_msg)\n\t\t\t\t\tawait browser.switch_to_tab(-1)\n\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\t\t\texcept Exception as e:\n\t\t\t\tlogger.warning(\n\t\t\t\t\tf'Element no longer available with index {params.index} - most likely the page changed'\n\t\t\t\t)\n\t\t\t\treturn ActionResult(error=str(e))\n\n\t\t@self.registry.action(\n\t\t\t'Input text into a input interactive element',\n\t\t\tparam_model=InputTextAction,\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def input_text(params: InputTextAction, browser: BrowserContext):\n\t\t\tsession = await browser.get_session()\n\t\t\tstate = session.cached_state\n\n\t\t\tif params.index not in state.selector_map:\n\t\t\t\traise Exception(\n\t\t\t\t\tf'Element index {params.index} does not exist - retry or use alternative actions'\n\t\t\t\t)\n\n\t\t\telement_node = state.selector_map[params.index]\n\t\t\tawait browser._input_text_element_node(element_node, params.text)\n\t\t\tmsg = f'⌨️  Input \"{params.text}\" into index {params.index}'\n\t\t\tlogger.info(msg)\n\t\t\tlogger.debug(f'Element xpath: {element_node.xpath}')\n\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t# Tab Management Actions\n\t\t@self.registry.action('Switch tab', param_model=SwitchTabAction, requires_browser=True)\n\t\tasync def switch_tab(params: SwitchTabAction, browser: BrowserContext):\n\t\t\tawait browser.switch_to_tab(params.page_id)\n\t\t\t# Wait for tab to be ready\n\t\t\tpage = await browser.get_current_page()\n\t\t\tawait page.wait_for_load_state()\n\t\t\tmsg = f'🔄  Switched to tab {params.page_id}'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t@self.registry.action(\n\t\t\t'Open url in new tab', param_model=OpenTabAction, requires_browser=True\n\t\t)\n\t\tasync def open_tab(params: OpenTabAction, browser: BrowserContext):\n\t\t\tawait browser.create_new_tab(params.url)\n\t\t\tmsg = f'🔗  Opened new tab with {params.url}'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t# Content Actions\n\t\t@self.registry.action(\n\t\t\t'Extract page content to get the pure text or markdown with links if include_links is set to true',\n\t\t\tparam_model=ExtractPageContentAction,\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def extract_content(params: ExtractPageContentAction, browser: BrowserContext):\n\t\t\tpage = await browser.get_current_page()\n\t\t\toutput_format = 'markdown' if params.include_links else 'text'\n\t\t\tcontent = MainContentExtractor.extract(  # type: ignore\n\t\t\t\thtml=await page.content(),\n\t\t\t\toutput_format=output_format,\n\t\t\t)\n\t\t\tmsg = f'📄  Extracted page as {output_format}\\n: {content}\\n'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(extracted_content=msg)\n\n\t\t@self.registry.action('Complete task', param_model=DoneAction)\n\t\tasync def done(params: DoneAction):\n\t\t\treturn ActionResult(is_done=True, extracted_content=params.text)\n\n\t\t@self.registry.action(\n\t\t\t'Scroll down the page by pixel amount - if no amount is specified, scroll down one page',\n\t\t\tparam_model=ScrollAction,\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def scroll_down(params: ScrollAction, browser: BrowserContext):\n\t\t\tpage = await browser.get_current_page()\n\t\t\tif params.amount is not None:\n\t\t\t\tawait page.evaluate(f'window.scrollBy(0, {params.amount});')\n\t\t\telse:\n\t\t\t\tawait page.keyboard.press('PageDown')\n\n\t\t\tamount = f'{params.amount} pixels' if params.amount is not None else 'one page'\n\t\t\tmsg = f'🔍  Scrolled down the page by {amount}'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(\n\t\t\t\textracted_content=msg,\n\t\t\t\tinclude_in_memory=True,\n\t\t\t)\n\n\t\t# scroll up\n\t\t@self.registry.action(\n\t\t\t'Scroll up the page by pixel amount - if no amount is specified, scroll up one page',\n\t\t\tparam_model=ScrollAction,\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def scroll_up(params: ScrollAction, browser: BrowserContext):\n\t\t\tpage = await browser.get_current_page()\n\t\t\tif params.amount is not None:\n\t\t\t\tawait page.evaluate(f'window.scrollBy(0, -{params.amount});')\n\t\t\telse:\n\t\t\t\tawait page.keyboard.press('PageUp')\n\n\t\t\tamount = f'{params.amount} pixels' if params.amount is not None else 'one page'\n\t\t\tmsg = f'🔍  Scrolled up the page by {amount}'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(\n\t\t\t\textracted_content=msg,\n\t\t\t\tinclude_in_memory=True,\n\t\t\t)\n\n\t\t# send keys\n\t\t@self.registry.action(\n\t\t\t'Send strings of special keys like Backspace, Insert, PageDown, Delete, Enter, Shortcuts such as `Control+o`, `Control+Shift+T` are supported as well. This gets used in keyboard.press. Be aware of different operating systems and their shortcuts',\n\t\t\tparam_model=SendKeysAction,\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def send_keys(params: SendKeysAction, browser: BrowserContext):\n\t\t\tpage = await browser.get_current_page()\n\n\t\t\tawait page.keyboard.press(params.keys)\n\t\t\tmsg = f'⌨️  Sent keys: {params.keys}'\n\t\t\tlogger.info(msg)\n\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t@self.registry.action(\n\t\t\tdescription='If you dont find something which you want to interact with, scroll to it',\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def scroll_to_text(text: str, browser: BrowserContext):  # type: ignore\n\t\t\tpage = await browser.get_current_page()\n\t\t\ttry:\n\t\t\t\t# Try different locator strategies\n\t\t\t\tlocators = [\n\t\t\t\t\tpage.get_by_text(text, exact=False),\n\t\t\t\t\tpage.locator(f'text={text}'),\n\t\t\t\t\tpage.locator(f\"//*[contains(text(), '{text}')]\"),\n\t\t\t\t]\n\n\t\t\t\tfor locator in locators:\n\t\t\t\t\ttry:\n\t\t\t\t\t\t# First check if element exists and is visible\n\t\t\t\t\t\tif await locator.count() > 0 and await locator.first.is_visible():\n\t\t\t\t\t\t\tawait locator.first.scroll_into_view_if_needed()\n\t\t\t\t\t\t\tawait asyncio.sleep(0.5)  # Wait for scroll to complete\n\t\t\t\t\t\t\tmsg = f'🔍  Scrolled to text: {text}'\n\t\t\t\t\t\t\tlogger.info(msg)\n\t\t\t\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\tlogger.debug(f'Locator attempt failed: {str(e)}')\n\t\t\t\t\t\tcontinue\n\n\t\t\t\tmsg = f\"Text '{text}' not found or not visible on page\"\n\t\t\t\tlogger.info(msg)\n\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t\texcept Exception as e:\n\t\t\t\tmsg = f\"Failed to scroll to text '{text}': {str(e)}\"\n\t\t\t\tlogger.error(msg)\n\t\t\t\treturn ActionResult(error=msg, include_in_memory=True)\n\n\t\t@self.registry.action(\n\t\t\tdescription='Get all options from a native dropdown',\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def get_dropdown_options(index: int, browser: BrowserContext) -> ActionResult:\n\t\t\t\"\"\"Get all options from a native dropdown\"\"\"\n\t\t\tpage = await browser.get_current_page()\n\t\t\tselector_map = await browser.get_selector_map()\n\t\t\tdom_element = selector_map[index]\n\n\t\t\ttry:\n\t\t\t\t# Frame-aware approach since we know it works\n\t\t\t\tall_options = []\n\t\t\t\tframe_index = 0\n\n\t\t\t\tfor frame in page.frames:\n\t\t\t\t\ttry:\n\t\t\t\t\t\toptions = await frame.evaluate(\n\t\t\t\t\t\t\t\"\"\"\n\t\t\t\t\t\t\t(xpath) => {\n\t\t\t\t\t\t\t\tconst select = document.evaluate(xpath, document, null,\n\t\t\t\t\t\t\t\t\tXPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n\t\t\t\t\t\t\t\tif (!select) return null;\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\toptions: Array.from(select.options).map(opt => ({\n\t\t\t\t\t\t\t\t\t\ttext: opt.text, //do not trim, because we are doing exact match in select_dropdown_option\n\t\t\t\t\t\t\t\t\t\tvalue: opt.value,\n\t\t\t\t\t\t\t\t\t\tindex: opt.index\n\t\t\t\t\t\t\t\t\t})),\n\t\t\t\t\t\t\t\t\tid: select.id,\n\t\t\t\t\t\t\t\t\tname: select.name\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\"\"\",\n\t\t\t\t\t\t\tdom_element.xpath,\n\t\t\t\t\t\t)\n\n\t\t\t\t\t\tif options:\n\t\t\t\t\t\t\tlogger.debug(f'Found dropdown in frame {frame_index}')\n\t\t\t\t\t\t\tlogger.debug(f'Dropdown ID: {options[\"id\"]}, Name: {options[\"name\"]}')\n\n\t\t\t\t\t\t\tformatted_options = []\n\t\t\t\t\t\t\tfor opt in options['options']:\n\t\t\t\t\t\t\t\t# encoding ensures AI uses the exact string in select_dropdown_option\n\t\t\t\t\t\t\t\tencoded_text = json.dumps(opt['text'])\n\t\t\t\t\t\t\t\tformatted_options.append(f\"{opt['index']}: text={encoded_text}\")\n\n\t\t\t\t\t\t\tall_options.extend(formatted_options)\n\n\t\t\t\t\texcept Exception as frame_e:\n\t\t\t\t\t\tlogger.debug(f'Frame {frame_index} evaluation failed: {str(frame_e)}')\n\n\t\t\t\t\tframe_index += 1\n\n\t\t\t\tif all_options:\n\t\t\t\t\tmsg = '\\n'.join(all_options)\n\t\t\t\t\tmsg += '\\nUse the exact text string in select_dropdown_option'\n\t\t\t\t\tlogger.info(msg)\n\t\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\t\t\t\telse:\n\t\t\t\t\tmsg = 'No options found in any frame for dropdown'\n\t\t\t\t\tlogger.info(msg)\n\t\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t\texcept Exception as e:\n\t\t\t\tlogger.error(f'Failed to get dropdown options: {str(e)}')\n\t\t\t\tmsg = f'Error getting options: {str(e)}'\n\t\t\t\tlogger.info(msg)\n\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t@self.registry.action(\n\t\t\tdescription='Select dropdown option for interactive element index by the text of the option you want to select',\n\t\t\trequires_browser=True,\n\t\t)\n\t\tasync def select_dropdown_option(\n\t\t\tindex: int,\n\t\t\ttext: str,\n\t\t\tbrowser: BrowserContext,\n\t\t) -> ActionResult:\n\t\t\t\"\"\"Select dropdown option by the text of the option you want to select\"\"\"\n\t\t\tpage = await browser.get_current_page()\n\t\t\tselector_map = await browser.get_selector_map()\n\t\t\tdom_element = selector_map[index]\n\n\t\t\t# Validate that we're working with a select element\n\t\t\tif dom_element.tag_name != 'select':\n\t\t\t\tlogger.error(\n\t\t\t\t\tf'Element is not a select! Tag: {dom_element.tag_name}, Attributes: {dom_element.attributes}'\n\t\t\t\t)\n\t\t\t\tmsg = f'Cannot select option: Element with index {index} is a {dom_element.tag_name}, not a select'\n\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t\tlogger.debug(f\"Attempting to select '{text}' using xpath: {dom_element.xpath}\")\n\t\t\tlogger.debug(f'Element attributes: {dom_element.attributes}')\n\t\t\tlogger.debug(f'Element tag: {dom_element.tag_name}')\n\n\t\t\ttry:\n\t\t\t\tframe_index = 0\n\t\t\t\tfor frame in page.frames:\n\t\t\t\t\ttry:\n\t\t\t\t\t\tlogger.debug(f'Trying frame {frame_index} URL: {frame.url}')\n\n\t\t\t\t\t\t# First verify we can find the dropdown in this frame\n\t\t\t\t\t\tfind_dropdown_js = \"\"\"\n\t\t\t\t\t\t\t(xpath) => {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tconst select = document.evaluate(xpath, document, null,\n\t\t\t\t\t\t\t\t\t\tXPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n\t\t\t\t\t\t\t\t\tif (!select) return null;\n\t\t\t\t\t\t\t\t\tif (select.tagName.toLowerCase() !== 'select') {\n\t\t\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\t\t\terror: `Found element but it's a ${select.tagName}, not a SELECT`,\n\t\t\t\t\t\t\t\t\t\t\tfound: false\n\t\t\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\t\tid: select.id,\n\t\t\t\t\t\t\t\t\t\tname: select.name,\n\t\t\t\t\t\t\t\t\t\tfound: true,\n\t\t\t\t\t\t\t\t\t\ttagName: select.tagName,\n\t\t\t\t\t\t\t\t\t\toptionCount: select.options.length,\n\t\t\t\t\t\t\t\t\t\tcurrentValue: select.value,\n\t\t\t\t\t\t\t\t\t\tavailableOptions: Array.from(select.options).map(o => o.text.trim())\n\t\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\t\t\t\treturn {error: e.toString(), found: false};\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\"\"\"\n\n\t\t\t\t\t\tdropdown_info = await frame.evaluate(find_dropdown_js, dom_element.xpath)\n\n\t\t\t\t\t\tif dropdown_info:\n\t\t\t\t\t\t\tif not dropdown_info.get('found'):\n\t\t\t\t\t\t\t\tlogger.error(\n\t\t\t\t\t\t\t\t\tf'Frame {frame_index} error: {dropdown_info.get(\"error\")}'\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\tcontinue\n\n\t\t\t\t\t\t\tlogger.debug(f'Found dropdown in frame {frame_index}: {dropdown_info}')\n\n\t\t\t\t\t\t\t# Rest of the selection code remains the same...\n\t\t\t\t\t\t\tselect_option_js = \"\"\"\n\t\t\t\t\t\t\t\t(params) => {\n\t\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\t\tconst select = document.evaluate(params.xpath, document, null,\n\t\t\t\t\t\t\t\t\t\t\tXPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n\t\t\t\t\t\t\t\t\t\tif (!select || select.tagName.toLowerCase() !== 'select') {\n\t\t\t\t\t\t\t\t\t\t\treturn {success: false, error: 'Select not found or invalid element type'};\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tconst option = Array.from(select.options)\n\t\t\t\t\t\t\t\t\t\t\t.find(opt => opt.text === params.text);\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tif (!option) {\n\t\t\t\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\t\t\t\tsuccess: false, \n\t\t\t\t\t\t\t\t\t\t\t\terror: 'Option not found',\n\t\t\t\t\t\t\t\t\t\t\t\tavailableOptions: Array.from(select.options).map(o => o.text)\n\t\t\t\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tselect.value = option.value;\n\t\t\t\t\t\t\t\t\t\tselect.dispatchEvent(new Event('change'));\n\t\t\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\t\t\tsuccess: true, \n\t\t\t\t\t\t\t\t\t\t\tselectedValue: option.value,\n\t\t\t\t\t\t\t\t\t\t\tselectedText: option.text\n\t\t\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\t\t\t\t\treturn {success: false, error: e.toString()};\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\"\"\"\n\n\t\t\t\t\t\t\tparams = {'xpath': dom_element.xpath, 'text': text}\n\n\t\t\t\t\t\t\tresult = await frame.evaluate(select_option_js, params)\n\t\t\t\t\t\t\tlogger.debug(f'Selection result: {result}')\n\n\t\t\t\t\t\t\tif result.get('success'):\n\t\t\t\t\t\t\t\tmsg = f\"Selected option {json.dumps(text)} (value={result.get('selectedValue')}\"\n\t\t\t\t\t\t\t\tlogger.info(msg + f' in frame {frame_index}')\n\t\t\t\t\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tlogger.error(f'Selection failed: {result.get(\"error\")}')\n\t\t\t\t\t\t\t\tif 'availableOptions' in result:\n\t\t\t\t\t\t\t\t\tlogger.error(f'Available options: {result[\"availableOptions\"]}')\n\n\t\t\t\t\texcept Exception as frame_e:\n\t\t\t\t\t\tlogger.error(f'Frame {frame_index} attempt failed: {str(frame_e)}')\n\t\t\t\t\t\tlogger.error(f'Frame type: {type(frame)}')\n\t\t\t\t\t\tlogger.error(f'Frame URL: {frame.url}')\n\n\t\t\t\t\tframe_index += 1\n\n\t\t\t\tmsg = f\"Could not select option '{text}' in any frame\"\n\t\t\t\tlogger.info(msg)\n\t\t\t\treturn ActionResult(extracted_content=msg, include_in_memory=True)\n\n\t\t\texcept Exception as e:\n\t\t\t\tmsg = f'Selection failed: {str(e)}'\n\t\t\t\tlogger.error(msg)\n\t\t\t\treturn ActionResult(error=msg, include_in_memory=True)\n\n\tdef action(self, description: str, **kwargs):\n\t\t\"\"\"Decorator for registering custom actions\n\n\t\t@param description: Describe the LLM what the function does (better description == better function calling)\n\t\t\"\"\"\n\t\treturn self.registry.action(description, **kwargs)\n\n\t@time_execution_async('--multi-act')\n\tasync def multi_act(\n\t\tself, actions: list[ActionModel], browser_context: BrowserContext\n\t) -> list[ActionResult]:\n\t\t\"\"\"Execute multiple actions\"\"\"\n\t\tresults = []\n\n\t\tsession = await browser_context.get_session()\n\t\tcached_selector_map = session.cached_state.selector_map\n\t\tcached_path_hashes = set(e.hash.branch_path_hash for e in cached_selector_map.values())\n\t\tawait browser_context.remove_highlights()\n\n\t\tfor i, action in enumerate(actions):\n\t\t\tif action.get_index() is not None and i != 0:\n\t\t\t\tnew_state = await browser_context.get_state()\n\t\t\t\tnew_path_hashes = set(\n\t\t\t\t\te.hash.branch_path_hash for e in new_state.selector_map.values()\n\t\t\t\t)\n\t\t\t\tif not new_path_hashes.issubset(cached_path_hashes):\n\t\t\t\t\t# next action requires index but there are new elements on the page\n\t\t\t\t\tlogger.info(f'Something new appeared after action {i } / {len(actions)}')\n\t\t\t\t\tresults.append(\n\t\t\t\t\t\tActionResult(\n\t\t\t\t\t\t\textracted_content=f'Action {i}: {action.model_dump_json(exclude_unset=True)} failed because there are new elements on the page. Need to evaluate the page again and retry the action that failed.',\n\t\t\t\t\t\t\tinclude_in_memory=True,\n\t\t\t\t\t\t)\n\t\t\t\t\t)\n\t\t\t\t\tbreak\n\n\t\t\tresults.append(await self.act(action, browser_context))\n\n\t\t\tlogger.debug(f'Executed action {i + 1} / {len(actions)}')\n\t\t\tif results[-1].is_done or results[-1].error or i == len(actions) - 1:\n\t\t\t\tbreak\n\n\t\t\tawait asyncio.sleep(browser_context.config.wait_between_actions)\n\t\t\t# hash all elements. if it is a subset of cached_state its fine - else break (new elements on page)\n\n\t\treturn results\n\n\t@time_execution_sync('--act')\n\tasync def act(self, action: ActionModel, browser_context: BrowserContext) -> ActionResult:\n\t\t\"\"\"Execute an action\"\"\"\n\t\ttry:\n\t\t\tfor action_name, params in action.model_dump(exclude_unset=True).items():\n\t\t\t\tif params is not None:\n\t\t\t\t\t# remove highlights\n\t\t\t\t\tresult = await self.registry.execute_action(\n\t\t\t\t\t\taction_name, params, browser=browser_context\n\t\t\t\t\t)\n\t\t\t\t\tif isinstance(result, str):\n\t\t\t\t\t\treturn ActionResult(extracted_content=result)\n\t\t\t\t\telif isinstance(result, ActionResult):\n\t\t\t\t\t\treturn result\n\t\t\t\t\telif result is None:\n\t\t\t\t\t\treturn ActionResult()\n\t\t\t\t\telse:\n\t\t\t\t\t\traise ValueError(f'Invalid action result type: {type(result)} of {result}')\n\t\t\treturn ActionResult()\n\t\texcept Exception as e:\n\t\t\traise e\n"}
{"type": "source_file", "path": "browser-use/browser_use/agent/message_manager/views.py", "content": "from __future__ import annotations\n\nfrom typing import List\n\nfrom langchain_core.messages import BaseMessage\nfrom pydantic import BaseModel, Field\n\n\nclass MessageMetadata(BaseModel):\n\t\"\"\"Metadata for a message including token counts\"\"\"\n\n\tinput_tokens: int = 0\n\n\nclass ManagedMessage(BaseModel):\n\t\"\"\"A message with its metadata\"\"\"\n\n\tmessage: BaseMessage\n\tmetadata: MessageMetadata = Field(default_factory=MessageMetadata)\n\n\nclass MessageHistory(BaseModel):\n\t\"\"\"Container for message history with metadata\"\"\"\n\n\tmessages: List[ManagedMessage] = Field(default_factory=list)\n\ttotal_tokens: int = 0\n\n\tdef add_message(self, message: BaseMessage, metadata: MessageMetadata) -> None:\n\t\t\"\"\"Add a message with metadata\"\"\"\n\t\tself.messages.append(ManagedMessage(message=message, metadata=metadata))\n\t\tself.total_tokens += metadata.input_tokens\n\n\tdef remove_message(self, index: int = -1) -> None:\n\t\t\"\"\"Remove last message from history\"\"\"\n\t\tif self.messages:\n\t\t\tmsg = self.messages.pop(index)\n\t\t\tself.total_tokens -= msg.metadata.input_tokens\n"}
{"type": "source_file", "path": "browser-use/browser_use/dom/history_tree_processor/service.py", "content": "import hashlib\nfrom typing import Optional\n\nfrom browser_use.dom.history_tree_processor.view import DOMHistoryElement, HashedDomElement\nfrom browser_use.dom.views import DOMElementNode\n\n\nclass HistoryTreeProcessor:\n\t\"\"\" \"\n\tOperations on the DOM elements\n\n\t@dev be careful - text nodes can change even if elements stay the same\n\t\"\"\"\n\n\t@staticmethod\n\tdef convert_dom_element_to_history_element(dom_element: DOMElementNode) -> DOMHistoryElement:\n\t\tparent_branch_path = HistoryTreeProcessor._get_parent_branch_path(dom_element)\n\t\treturn DOMHistoryElement(\n\t\t\tdom_element.tag_name,\n\t\t\tdom_element.xpath,\n\t\t\tdom_element.highlight_index,\n\t\t\tparent_branch_path,\n\t\t\tdom_element.attributes,\n\t\t\tdom_element.shadow_root,\n\t\t)\n\n\t@staticmethod\n\tdef find_history_element_in_tree(\n\t\tdom_history_element: DOMHistoryElement, tree: DOMElementNode\n\t) -> Optional[DOMElementNode]:\n\t\thashed_dom_history_element = HistoryTreeProcessor._hash_dom_history_element(\n\t\t\tdom_history_element\n\t\t)\n\n\t\tdef process_node(node: DOMElementNode):\n\t\t\tif node.highlight_index is not None:\n\t\t\t\thashed_node = HistoryTreeProcessor._hash_dom_element(node)\n\t\t\t\tif hashed_node == hashed_dom_history_element:\n\t\t\t\t\treturn node\n\t\t\tfor child in node.children:\n\t\t\t\tif isinstance(child, DOMElementNode):\n\t\t\t\t\tresult = process_node(child)\n\t\t\t\t\tif result is not None:\n\t\t\t\t\t\treturn result\n\t\t\treturn None\n\n\t\treturn process_node(tree)\n\n\t@staticmethod\n\tdef compare_history_element_and_dom_element(\n\t\tdom_history_element: DOMHistoryElement, dom_element: DOMElementNode\n\t) -> bool:\n\t\thashed_dom_history_element = HistoryTreeProcessor._hash_dom_history_element(\n\t\t\tdom_history_element\n\t\t)\n\t\thashed_dom_element = HistoryTreeProcessor._hash_dom_element(dom_element)\n\n\t\treturn hashed_dom_history_element == hashed_dom_element\n\n\t@staticmethod\n\tdef _hash_dom_history_element(dom_history_element: DOMHistoryElement) -> HashedDomElement:\n\t\tbranch_path_hash = HistoryTreeProcessor._parent_branch_path_hash(\n\t\t\tdom_history_element.entire_parent_branch_path\n\t\t)\n\t\tattributes_hash = HistoryTreeProcessor._attributes_hash(dom_history_element.attributes)\n\n\t\treturn HashedDomElement(branch_path_hash, attributes_hash)\n\n\t@staticmethod\n\tdef _hash_dom_element(dom_element: DOMElementNode) -> HashedDomElement:\n\t\tparent_branch_path = HistoryTreeProcessor._get_parent_branch_path(dom_element)\n\t\tbranch_path_hash = HistoryTreeProcessor._parent_branch_path_hash(parent_branch_path)\n\t\tattributes_hash = HistoryTreeProcessor._attributes_hash(dom_element.attributes)\n\t\t# text_hash = DomTreeProcessor._text_hash(dom_element)\n\n\t\treturn HashedDomElement(branch_path_hash, attributes_hash)\n\n\t@staticmethod\n\tdef _get_parent_branch_path(dom_element: DOMElementNode) -> list[str]:\n\t\tparents: list[DOMElementNode] = []\n\t\tcurrent_element: DOMElementNode = dom_element\n\t\twhile current_element.parent is not None:\n\t\t\tparents.append(current_element)\n\t\t\tcurrent_element = current_element.parent\n\n\t\tparents.reverse()\n\n\t\treturn [parent.tag_name for parent in parents]\n\n\t@staticmethod\n\tdef _parent_branch_path_hash(parent_branch_path: list[str]) -> str:\n\t\tparent_branch_path_string = '/'.join(parent_branch_path)\n\t\treturn hashlib.sha256(parent_branch_path_string.encode()).hexdigest()\n\n\t@staticmethod\n\tdef _attributes_hash(attributes: dict[str, str]) -> str:\n\t\tattributes_string = ''.join(f'{key}={value}' for key, value in attributes.items())\n\t\treturn hashlib.sha256(attributes_string.encode()).hexdigest()\n\n\t@staticmethod\n\tdef _text_hash(dom_element: DOMElementNode) -> str:\n\t\t\"\"\" \"\"\"\n\t\ttext_string = dom_element.get_all_text_till_next_clickable_element()\n\t\treturn hashlib.sha256(text_string.encode()).hexdigest()\n"}
{"type": "source_file", "path": "browser-use/browser_use/agent/message_manager/service.py", "content": "from __future__ import annotations\n\nimport logging\nfrom datetime import datetime\nfrom typing import List, Optional, Type\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_core.language_models import BaseChatModel\nfrom langchain_core.messages import (\n\tAIMessage,\n\tBaseMessage,\n\tHumanMessage,\n)\nfrom langchain_openai import ChatOpenAI\n\nfrom browser_use.agent.message_manager.views import MessageHistory, MessageMetadata\nfrom browser_use.agent.prompts import AgentMessagePrompt, SystemPrompt\nfrom browser_use.agent.views import ActionResult, AgentOutput, AgentStepInfo\nfrom browser_use.browser.views import BrowserState\n\nlogger = logging.getLogger(__name__)\n\n\nclass MessageManager:\n\tdef __init__(\n\t\tself,\n\t\tllm: BaseChatModel,\n\t\ttask: str,\n\t\taction_descriptions: str,\n\t\tsystem_prompt_class: Type[SystemPrompt],\n\t\tmax_input_tokens: int = 128000,\n\t\testimated_tokens_per_character: int = 3,\n\t\timage_tokens: int = 800,\n\t\tinclude_attributes: list[str] = [],\n\t\tmax_error_length: int = 400,\n\t\tmax_actions_per_step: int = 10,\n\t\ttool_call_in_content: bool = True,\n\t):\n\t\tself.llm = llm\n\t\tself.system_prompt_class = system_prompt_class\n\t\tself.max_input_tokens = max_input_tokens\n\t\tself.history = MessageHistory()\n\t\tself.task = task\n\t\tself.action_descriptions = action_descriptions\n\t\tself.ESTIMATED_TOKENS_PER_CHARACTER = estimated_tokens_per_character\n\t\tself.IMG_TOKENS = image_tokens\n\t\tself.include_attributes = include_attributes\n\t\tself.max_error_length = max_error_length\n\n\t\tsystem_message = self.system_prompt_class(\n\t\t\tself.action_descriptions,\n\t\t\tcurrent_date=datetime.now(),\n\t\t\tmax_actions_per_step=max_actions_per_step,\n\t\t).get_system_message()\n\n\t\tself._add_message_with_tokens(system_message)\n\t\tself.system_prompt = system_message\n\t\tself.tool_call_in_content = tool_call_in_content\n\t\ttool_calls = [\n\t\t\t{\n\t\t\t\t'name': 'AgentOutput',\n\t\t\t\t'args': {\n\t\t\t\t\t'current_state': {\n\t\t\t\t\t\t'evaluation_previous_goal': 'Unknown - No previous actions to evaluate.',\n\t\t\t\t\t\t'memory': '',\n\t\t\t\t\t\t'next_goal': 'Obtain task from user',\n\t\t\t\t\t},\n\t\t\t\t\t'action': [],\n\t\t\t\t},\n\t\t\t\t'id': '',\n\t\t\t\t'type': 'tool_call',\n\t\t\t}\n\t\t]\n\t\tif self.tool_call_in_content:\n\t\t\t# openai throws error if tool_calls are not responded -> move to content\n\t\t\texample_tool_call = AIMessage(\n\t\t\t\tcontent=f'{tool_calls}',\n\t\t\t\ttool_calls=[],\n\t\t\t)\n\t\telse:\n\t\t\texample_tool_call = AIMessage(\n\t\t\t\tcontent='',\n\t\t\t\ttool_calls=tool_calls,\n\t\t\t)\n\n\t\tself._add_message_with_tokens(example_tool_call)\n\n\t\ttask_message = self.task_instructions(task)\n\t\tself._add_message_with_tokens(task_message)\n\n\t@staticmethod\n\tdef task_instructions(task: str) -> HumanMessage:\n\t\tcontent = f'Your ultimate task is: {task}. If you achieved your ultimate task, stop everything and use the done action in the next step to complete the task. If not, continue as usual.'\n\t\treturn HumanMessage(content=content)\n\n\tdef add_state_message(\n\t\tself,\n\t\tstate: BrowserState,\n\t\tresult: Optional[List[ActionResult]] = None,\n\t\tstep_info: Optional[AgentStepInfo] = None,\n\t) -> AgentMessagePrompt:\n\t\t\"\"\"Add browser state as human message\"\"\"\n\n\t\t# if keep in memory, add to directly to history and add state without result\n\t\tif result:\n\t\t\tfor r in result:\n\t\t\t\tif r.include_in_memory:\n\t\t\t\t\tif r.extracted_content:\n\t\t\t\t\t\tmsg = HumanMessage(content='Action result: ' + str(r.extracted_content))\n\t\t\t\t\t\tself._add_message_with_tokens(msg)\n\t\t\t\t\tif r.error:\n\t\t\t\t\t\tmsg = HumanMessage(\n\t\t\t\t\t\t\tcontent='Action error: ' + str(r.error)[-self.max_error_length :]\n\t\t\t\t\t\t)\n\t\t\t\t\t\tself._add_message_with_tokens(msg)\n\t\t\t\t\tresult = None  # if result in history, we dont want to add it again\n\n\t\t# otherwise add state message and result to next message (which will not stay in memory)\n\t\tstate_message = AgentMessagePrompt(\n\t\t\tstate,\n\t\t\tresult,\n\t\t\tinclude_attributes=self.include_attributes,\n\t\t\tmax_error_length=self.max_error_length,\n\t\t\tstep_info=step_info,\n\t\t).get_user_message()\n\t\tself._add_message_with_tokens(state_message)\n\n\t\treturn state_message\n\n\tdef _remove_last_state_message(self) -> None:\n\t\t\"\"\"Remove last state message from history\"\"\"\n\t\tif len(self.history.messages) > 2 and isinstance(\n\t\t\tself.history.messages[-1].message, HumanMessage\n\t\t):\n\t\t\tself.history.remove_message()\n\n\tdef add_model_output(self, model_output: AgentOutput) -> None:\n\t\t\"\"\"Add model output as AI message\"\"\"\n\t\ttool_calls = [\n\t\t\t{\n\t\t\t\t'name': 'AgentOutput',\n\t\t\t\t'args': model_output.model_dump(mode='json', exclude_unset=True),\n\t\t\t\t'id': '',\n\t\t\t\t'type': 'tool_call',\n\t\t\t}\n\t\t]\n\t\tif self.tool_call_in_content:\n\t\t\tmsg = AIMessage(\n\t\t\t\tcontent=f'{tool_calls}',\n\t\t\t\ttool_calls=[],\n\t\t\t)\n\t\telse:\n\t\t\tmsg = AIMessage(\n\t\t\t\tcontent='',\n\t\t\t\ttool_calls=tool_calls,\n\t\t\t)\n\n\t\tself._add_message_with_tokens(msg)\n\n\tdef get_messages(self) -> List[BaseMessage]:\n\t\t\"\"\"Get current message list, potentially trimmed to max tokens\"\"\"\n\t\tself.cut_messages()\n\t\treturn [m.message for m in self.history.messages]\n\n\tdef cut_messages(self):\n\t\t\"\"\"Get current message list, potentially trimmed to max tokens\"\"\"\n\t\tdiff = self.history.total_tokens - self.max_input_tokens\n\t\tif diff <= 0:\n\t\t\treturn None\n\n\t\tmsg = self.history.messages[-1]\n\n\t\t# if list with image remove image\n\t\tif isinstance(msg.message.content, list):\n\t\t\ttext = ''\n\t\t\tfor item in msg.message.content:\n\t\t\t\tif 'image_url' in item:\n\t\t\t\t\tmsg.message.content.remove(item)\n\t\t\t\t\tdiff -= self.IMG_TOKENS\n\t\t\t\t\tmsg.metadata.input_tokens -= self.IMG_TOKENS\n\t\t\t\t\tself.history.total_tokens -= self.IMG_TOKENS\n\t\t\t\t\tlogger.debug(\n\t\t\t\t\t\tf'Removed image with {self.IMG_TOKENS} tokens - total tokens now: {self.history.total_tokens}/{self.max_input_tokens}'\n\t\t\t\t\t)\n\t\t\t\telif 'text' in item and isinstance(item, dict):\n\t\t\t\t\ttext += item['text']\n\t\t\tmsg.message.content = text\n\t\t\tself.history.messages[-1] = msg\n\n\t\tif diff <= 0:\n\t\t\treturn None\n\n\t\t# if still over, remove text from state message proportionally to the number of tokens needed with buffer\n\t\t# Calculate the proportion of content to remove\n\t\tproportion_to_remove = diff / msg.metadata.input_tokens\n\t\tif proportion_to_remove > 0.99:\n\t\t\traise ValueError(\n\t\t\t\tf'Max token limit reached - history is too long - reduce the system prompt or task less tasks or remove old messages. '\n\t\t\t\tf'proportion_to_remove: {proportion_to_remove}'\n\t\t\t)\n\t\tlogger.debug(\n\t\t\tf'Removing {proportion_to_remove * 100:.2f}% of the last message  {proportion_to_remove * msg.metadata.input_tokens:.2f} / {msg.metadata.input_tokens:.2f} tokens)'\n\t\t)\n\n\t\tcontent = msg.message.content\n\t\tcharacters_to_remove = int(len(content) * proportion_to_remove)\n\t\tcontent = content[:-characters_to_remove]\n\n\t\t# remove tokens and old long message\n\t\tself.history.remove_message(index=-1)\n\n\t\t# new message with updated content\n\t\tmsg = HumanMessage(content=content)\n\t\tself._add_message_with_tokens(msg)\n\n\t\tlast_msg = self.history.messages[-1]\n\n\t\tlogger.debug(\n\t\t\tf'Added message with {last_msg.metadata.input_tokens} tokens - total tokens now: {self.history.total_tokens}/{self.max_input_tokens} - total messages: {len(self.history.messages)}'\n\t\t)\n\n\tdef _add_message_with_tokens(self, message: BaseMessage) -> None:\n\t\t\"\"\"Add message with token count metadata\"\"\"\n\t\ttoken_count = self._count_tokens(message)\n\t\tmetadata = MessageMetadata(input_tokens=token_count)\n\t\tself.history.add_message(message, metadata)\n\n\tdef _count_tokens(self, message: BaseMessage) -> int:\n\t\t\"\"\"Count tokens in a message using the model's tokenizer\"\"\"\n\t\ttokens = 0\n\t\tif isinstance(message.content, list):\n\t\t\tfor item in message.content:\n\t\t\t\tif 'image_url' in item:\n\t\t\t\t\ttokens += self.IMG_TOKENS\n\t\t\t\telif isinstance(item, dict) and 'text' in item:\n\t\t\t\t\ttokens += self._count_text_tokens(item['text'])\n\t\telse:\n\t\t\ttokens += self._count_text_tokens(message.content)\n\t\treturn tokens\n\n\tdef _count_text_tokens(self, text: str) -> int:\n\t\t\"\"\"Count tokens in a text string\"\"\"\n\t\tif isinstance(self.llm, (ChatOpenAI, ChatAnthropic)):\n\t\t\ttry:\n\t\t\t\ttokens = self.llm.get_num_tokens(text)\n\t\t\texcept Exception:\n\t\t\t\ttokens = (\n\t\t\t\t\tlen(text) // self.ESTIMATED_TOKENS_PER_CHARACTER\n\t\t\t\t)  # Rough estimate if no tokenizer available\n\t\telse:\n\t\t\ttokens = (\n\t\t\t\tlen(text) // self.ESTIMATED_TOKENS_PER_CHARACTER\n\t\t\t)  # Rough estimate if no tokenizer available\n\t\treturn tokens\n\n\n# Gemini: client.models.count_tokens(text)\n"}
{"type": "source_file", "path": "browser-use/browser_use/controller/views.py", "content": "from typing import Optional\n\nfrom pydantic import BaseModel\n\n\n# Action Input Models\nclass SearchGoogleAction(BaseModel):\n\tquery: str\n\n\nclass GoToUrlAction(BaseModel):\n\turl: str\n\n\nclass ClickElementAction(BaseModel):\n\tindex: int\n\txpath: Optional[str] = None\n\n\nclass InputTextAction(BaseModel):\n\tindex: int\n\ttext: str\n\txpath: Optional[str] = None\n\n\nclass DoneAction(BaseModel):\n\ttext: str\n\n\nclass SwitchTabAction(BaseModel):\n\tpage_id: int\n\n\nclass OpenTabAction(BaseModel):\n\turl: str\n\n\nclass ExtractPageContentAction(BaseModel):\n\tinclude_links: bool\n\n\nclass ScrollAction(BaseModel):\n\tamount: Optional[int] = None  # The number of pixels to scroll. If None, scroll down/up one page\n\n\nclass SendKeysAction(BaseModel):\n\tkeys: str\n"}
{"type": "source_file", "path": "browser-use/browser_use/dom/__init__.py", "content": ""}
{"type": "source_file", "path": "browser-use/browser_use/controller/registry/service.py", "content": "import asyncio\nfrom inspect import iscoroutinefunction, signature\nfrom typing import Any, Callable, Optional, Type\n\nfrom pydantic import BaseModel, create_model\n\nfrom browser_use.browser.context import BrowserContext\nfrom browser_use.controller.registry.views import (\n\tActionModel,\n\tActionRegistry,\n\tRegisteredAction,\n)\nfrom browser_use.telemetry.service import ProductTelemetry\nfrom browser_use.telemetry.views import (\n\tControllerRegisteredFunctionsTelemetryEvent,\n\tRegisteredFunction,\n)\n\n\nclass Registry:\n\t\"\"\"Service for registering and managing actions\"\"\"\n\n\tdef __init__(self):\n\t\tself.registry = ActionRegistry()\n\t\tself.telemetry = ProductTelemetry()\n\n\tdef _create_param_model(self, function: Callable) -> Type[BaseModel]:\n\t\t\"\"\"Creates a Pydantic model from function signature\"\"\"\n\t\tsig = signature(function)\n\t\tparams = {\n\t\t\tname: (param.annotation, ... if param.default == param.empty else param.default)\n\t\t\tfor name, param in sig.parameters.items()\n\t\t\tif name != 'browser'\n\t\t}\n\t\t# TODO: make the types here work\n\t\treturn create_model(\n\t\t\tf'{function.__name__}Params',\n\t\t\t__base__=ActionModel,\n\t\t\t**params,  # type: ignore\n\t\t)\n\n\tdef action(\n\t\tself,\n\t\tdescription: str,\n\t\tparam_model: Optional[Type[BaseModel]] = None,\n\t\trequires_browser: bool = False,\n\t):\n\t\t\"\"\"Decorator for registering actions\"\"\"\n\n\t\tdef decorator(func: Callable):\n\t\t\t# Create param model from function if not provided\n\t\t\tactual_param_model = param_model or self._create_param_model(func)\n\n\t\t\t# Wrap sync functions to make them async\n\t\t\tif not iscoroutinefunction(func):\n\n\t\t\t\tasync def async_wrapper(*args, **kwargs):\n\t\t\t\t\treturn await asyncio.to_thread(func, *args, **kwargs)\n\n\t\t\t\t# Copy the signature and other metadata from the original function\n\t\t\t\tasync_wrapper.__signature__ = signature(func)\n\t\t\t\tasync_wrapper.__name__ = func.__name__\n\t\t\t\tasync_wrapper.__annotations__ = func.__annotations__\n\t\t\t\twrapped_func = async_wrapper\n\t\t\telse:\n\t\t\t\twrapped_func = func\n\n\t\t\taction = RegisteredAction(\n\t\t\t\tname=func.__name__,\n\t\t\t\tdescription=description,\n\t\t\t\tfunction=wrapped_func,\n\t\t\t\tparam_model=actual_param_model,\n\t\t\t\trequires_browser=requires_browser,\n\t\t\t)\n\t\t\tself.registry.actions[func.__name__] = action\n\t\t\treturn func\n\n\t\treturn decorator\n\n\tasync def execute_action(\n\t\tself, action_name: str, params: dict, browser: Optional[BrowserContext] = None\n\t) -> Any:\n\t\t\"\"\"Execute a registered action\"\"\"\n\t\tif action_name not in self.registry.actions:\n\t\t\traise ValueError(f'Action {action_name} not found')\n\n\t\taction = self.registry.actions[action_name]\n\t\ttry:\n\t\t\t# Create the validated Pydantic model\n\t\t\tvalidated_params = action.param_model(**params)\n\n\t\t\t# Check if the first parameter is a Pydantic model\n\t\t\tsig = signature(action.function)\n\t\t\tparameters = list(sig.parameters.values())\n\t\t\tis_pydantic = parameters and issubclass(parameters[0].annotation, BaseModel)\n\n\t\t\t# Prepare arguments based on parameter type\n\t\t\tif action.requires_browser:\n\t\t\t\tif not browser:\n\t\t\t\t\traise ValueError(\n\t\t\t\t\t\tf'Action {action_name} requires browser but none provided. This has to be used in combination of `requires_browser=True` when registering the action.'\n\t\t\t\t\t)\n\t\t\t\tif is_pydantic:\n\t\t\t\t\treturn await action.function(validated_params, browser=browser)\n\t\t\t\treturn await action.function(**validated_params.model_dump(), browser=browser)\n\n\t\t\tif is_pydantic:\n\t\t\t\treturn await action.function(validated_params)\n\t\t\treturn await action.function(**validated_params.model_dump())\n\n\t\texcept Exception as e:\n\t\t\traise RuntimeError(f'Error executing action {action_name}: {str(e)}') from e\n\n\tdef create_action_model(self) -> Type[ActionModel]:\n\t\t\"\"\"Creates a Pydantic model from registered actions\"\"\"\n\t\tfields = {\n\t\t\tname: (Optional[action.param_model], None)\n\t\t\tfor name, action in self.registry.actions.items()\n\t\t}\n\n\t\tself.telemetry.capture(\n\t\t\tControllerRegisteredFunctionsTelemetryEvent(\n\t\t\t\tregistered_functions=[\n\t\t\t\t\tRegisteredFunction(name=name, params=action.param_model.model_json_schema())\n\t\t\t\t\tfor name, action in self.registry.actions.items()\n\t\t\t\t]\n\t\t\t)\n\t\t)\n\n\t\treturn create_model('ActionModel', __base__=ActionModel, **fields)  # type:ignore\n\n\tdef get_prompt_description(self) -> str:\n\t\t\"\"\"Get a description of all actions for the prompt\"\"\"\n\t\treturn self.registry.get_prompt_description()\n"}
{"type": "source_file", "path": "browser-use/browser_use/browser/views.py", "content": "from dataclasses import dataclass\nfrom typing import Any, Optional\n\nfrom pydantic import BaseModel\n\nfrom browser_use.dom.history_tree_processor.service import DOMHistoryElement\nfrom browser_use.dom.views import DOMState\n# from browser_use.agent.prompts import AgentMessagePrompt\n\n\n# Pydantic\nclass TabInfo(BaseModel):\n\t\"\"\"Represents information about a browser tab\"\"\"\n\n\tpage_id: int\n\turl: str\n\ttitle: str\n\n\n@dataclass\nclass BrowserState(DOMState):\n\turl: str\n\ttitle: str\n\ttabs: list[TabInfo]\n\tscreenshot: Optional[str] = None\n\n\n@dataclass\nclass BrowserStateHistory:\n\turl: str\n\ttitle: str\n\ttabs: list[TabInfo]\n\tinteracted_element: list[DOMHistoryElement | None] | list[None]\n\tscreenshot: Optional[str] = None\n\tprompt: Optional[Any] = None\n\n\tdef to_dict(self) -> dict[str, Any]:\n\t\tdata = {}\n\t\tdata['tabs'] = [tab.model_dump() for tab in self.tabs]\n\t\tdata['screenshot'] = self.screenshot\n\t\tdata['interacted_element'] = [\n\t\t\tel.to_dict() if el else None for el in self.interacted_element\n\t\t]\n\t\tdata['url'] = self.url\n\t\tdata['title'] = self.title\n\t\tdata['prompt'] = self.prompt\n\t\treturn data\n\n\nclass BrowserError(Exception):\n\t\"\"\"Base class for all browser errors\"\"\"\n"}
{"type": "source_file", "path": "browser-use/browser_use/telemetry/views.py", "content": "from abc import ABC, abstractmethod\nfrom dataclasses import asdict, dataclass\nfrom typing import Any, Dict\n\n\n@dataclass\nclass BaseTelemetryEvent(ABC):\n\t@property\n\t@abstractmethod\n\tdef name(self) -> str:\n\t\tpass\n\n\t@property\n\tdef properties(self) -> Dict[str, Any]:\n\t\treturn {k: v for k, v in asdict(self).items() if k != 'name'}\n\n\n@dataclass\nclass RegisteredFunction:\n\tname: str\n\tparams: dict[str, Any]\n\n\n@dataclass\nclass ControllerRegisteredFunctionsTelemetryEvent(BaseTelemetryEvent):\n\tregistered_functions: list[RegisteredFunction]\n\tname: str = 'controller_registered_functions'\n\n\n@dataclass\nclass AgentStepTelemetryEvent(BaseTelemetryEvent):\n\tagent_id: str\n\tstep: int\n\tstep_error: list[str]\n\tconsecutive_failures: int\n\tactions: list[dict]\n\tname: str = 'agent_step'\n\n\n@dataclass\nclass AgentRunTelemetryEvent(BaseTelemetryEvent):\n\tagent_id: str\n\tuse_vision: bool\n\ttool_call_in_content: bool\n\ttask: str\n\tmodel_name: str\n\tchat_model_library: str\n\tversion: str\n\tsource: str\n\tname: str = 'agent_run'\n\n\n@dataclass\nclass AgentEndTelemetryEvent(BaseTelemetryEvent):\n\tagent_id: str\n\tsteps: int\n\tmax_steps_reached: bool\n\tsuccess: bool\n\terrors: list[str]\n\tname: str = 'agent_end'\n"}
{"type": "source_file", "path": "mimicflow/agents/linkedin/linkedin_agent.py", "content": "import os\nimport json\nimport asyncio\nimport pandas as pd\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\nfrom datetime import datetime\nfrom pydantic import BaseModel, Field, model_validator\nfrom dotenv import load_dotenv\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_openai import ChatOpenAI\nfrom browser_use.browser.browser import Browser, BrowserConfig, BrowserContext\nfrom browser_use import ActionResult, Agent, Controller\nfrom mimicflow.app.progress_manager import ProgressManager\n\n\nclass ExtractAndSaveContent(BaseModel):\n    page_number: int = Field(..., description=\"Current page number\")\n    include_links: bool = Field(\n        ..., description=\"Whether to include links in the extracted content\"\n    )\n\n    class Config:\n        json_schema_extra = {\"example\": {\"page_number\": 1, \"include_links\": True}}\n\n\nclass LinkedInProfileResult(BaseModel):\n    Full_Name: str = Field(...)\n    Current_Title: str = Field(...)\n    Company: str = Field(...)\n    Location: str = Field(...)\n    Education: List[str]\n    Companies_Worked_At: List[str]\n    Common_Interests: List[str]\n    Custom_Message: str = Field(...)\n    Profile_URL: str = Field(...)\n\n    class Config:\n        extra = \"forbid\"\n\n\nclass LinkedInFilter(BaseModel):\n    \"\"\"Structured filter for LinkedIn search\"\"\"\n\n    # New URL field for direct search\n    linkedin_url: Optional[str] = Field(None, description=\"LinkedIn search URL\")\n\n    # Optional fields for form-based search\n    companies: Optional[List[str]] = None\n    universities: Optional[List[str]] = None\n    titles: Optional[List[str]] = None\n    profiles_needed: int = Field(..., description=\"Number of profiles to collect\", gt=0)\n    additional_filters: Optional[List[str]] = Field(default=[])\n\n    @model_validator(mode=\"after\")\n    def check_if_url_or_form(self) -> \"LinkedInFilter\":\n        \"\"\"Validate that either URL is provided or all form fields\"\"\"\n        if not self.linkedin_url and not all(\n            [self.companies, self.universities, self.titles]\n        ):\n            if self.linkedin_url is None:\n                raise ValueError(\n                    \"Must provide either linkedin_url or all form fields (companies, universities, titles)\"\n                )\n        return self\n\n    def to_prompt_string(self) -> str:\n        \"\"\"Convert filter to formatted string for prompt\"\"\"\n        if self.linkedin_url:\n            return f\"LinkedIn Search URL: {self.linkedin_url}\"\n\n        # These should never be None due to the validator\n        return f\"\"\"Companies: {', '.join(self.companies or [])}\nUniversities: {', '.join(self.universities or [])}\nTitles: {', '.join(self.titles or [])}\nAdditional Filters: {', '.join(self.additional_filters) if self.additional_filters else 'None'}\"\"\"\n\n\nclass LinkedInSearchAgent:\n    def __init__(\n        self,\n        filter_config: LinkedInFilter,\n        base_output_dir: str = \"linkedin_searches\",\n        llm: str = \"gemini-2.0-flash-exp\",\n        progress_manager: ProgressManager = None,\n        send_connection_request: bool = True,\n        include_note: bool = True,\n        template_mode: str = \"examples\",\n        custom_template: str = None,\n    ):\n        self.filter = filter_config\n        self.send_connection_request = send_connection_request\n        self.include_note = include_note\n        # Assuming 10 profiles per page\n        self.pages_needed = (\n            filter_config.profiles_needed + 9\n        ) // 10  # Ceiling division\n        self.profiles_needed = filter_config.profiles_needed\n        self.progress_manager = progress_manager\n        self.base_dir, self.csv_file_path = self._setup_directories(base_output_dir)\n        self.controller = Controller()\n        self.llm = self._setup_llm(llm)\n        self.browser = Browser(\n            config=BrowserConfig(\n                headless=False,\n                chrome_instance_path=\"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\",\n            )\n        )\n\n        # Register the extract and save content action\n        self._register_actions()\n        self.total_profiles_collected = 0\n        self.search_agent_history = None\n        self.profile_agent_histories = {}  # Store histories for each profile agent\n        self.template_mode = template_mode\n        self.custom_template = custom_template\n\n    def _setup_directories(self, base_dir: str) -> Path:\n        \"\"\"Setup directory structure for this search\"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n        # Use URL or first company/title for directory name\n        if self.filter.linkedin_url:\n            # Create a safe filename from the URL\n            url_part = self.filter.linkedin_url.split(\"?\")[0].split(\"/\")[\n                -1\n            ]  # Get last part of URL\n            search_id = f\"url_search_{url_part}_{timestamp}\"\n        else:\n            # Form-based search - use first company and title\n            first_company = (\n                self.filter.companies[0] if self.filter.companies else \"no_company\"\n            )\n            first_title = self.filter.titles[0] if self.filter.titles else \"no_title\"\n            search_id = f\"{first_company}_{first_title}_{timestamp}\"\n\n        # Create safe filename by removing special characters\n        search_id = \"\".join(\n            c for c in search_id if c.isalnum() or c in (\"_\", \"-\")\n        ).strip()\n\n        # Create and return the directory path\n        search_path = Path(base_dir) / search_id\n        search_path.mkdir(parents=True, exist_ok=True)\n\n        # Create subdirectories\n        (search_path / \"histories\").mkdir(exist_ok=True)\n        (search_path / \"histories\" / \"profiles\").mkdir(exist_ok=True)\n        (search_path / \"conversations\").mkdir(exist_ok=True)\n        (search_path / \"conversations\" / \"profiles\").mkdir(exist_ok=True)\n\n        csv_file_path = search_path / \"detailed_profiles.csv\"\n\n        return search_path, csv_file_path\n\n    def _register_profile_result(self):\n        @self.controller.registry.action(\n            \"Done with task\", param_model=LinkedInProfileResult\n        )\n        async def done(params: LinkedInProfileResult):\n            return ActionResult(\n                is_done=True, extracted_content=params.model_dump_json()\n            )\n\n    def _setup_llm(self, llm: str):\n        \"\"\"Initialize the specified LLM\"\"\"\n        load_dotenv()\n        if \"gemini\" in llm:\n            api_key = os.getenv(\"GEMINI_API_KEY\")\n            if not api_key:\n                raise ValueError(\"GEMINI_API_KEY not set\")\n            return ChatGoogleGenerativeAI(\n                model=\"gemini-2.0-flash-exp\",\n                api_key=api_key,\n                temperature=0.0,\n            )\n        elif \"gpt\" in llm or \"o1\" in llm:\n            return (\n                ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n                if \"gpt\" in llm\n                else ChatOpenAI(model=\"gpt-4o\")\n            )\n        else:\n            raise ValueError(f\"Unsupported LLM type: {llm}\")\n\n    def _register_actions(self):\n        \"\"\"Register custom actions with the controller\"\"\"\n\n        @self.controller.registry.action(\n            \"Extract and save page content to a file\",\n            param_model=ExtractAndSaveContent,\n            requires_browser=True,\n        )\n        async def extract_and_save_content(\n            params: ExtractAndSaveContent, browser: BrowserContext\n        ):\n            # First use the extract_content action directly from registry\n            extract_result = await self.controller.registry.execute_action(\n                \"extract_content\",\n                {\"include_links\": params.include_links},\n                browser=browser,\n            )\n\n            # Extract the content from the result\n            raw_content = extract_result.extracted_content\n\n            # Try OpenAI first, fallback to Gemini\n            openai_key = os.getenv('OPENAI_API_KEY')\n            if openai_key:\n                try:\n                    dom_analysis_llm = ChatOpenAI(\n                        model=\"gpt-4\",\n                        temperature=0.0,\n                        api_key=openai_key\n                    )\n                except Exception as e:\n                    print(f\"Failed to initialize OpenAI: {e}\")\n                    dom_analysis_llm = None\n            else:\n                dom_analysis_llm = None\n\n            # Fallback to Gemini if OpenAI fails or isn't configured\n            if dom_analysis_llm is None:\n                try:\n                    dom_analysis_llm = ChatGoogleGenerativeAI(\n                        model=\"gemini-2.0-flash-exp\",\n                        temperature=0.0,\n                        api_key=os.getenv('GEMINI_API_KEY')\n                    )\n                except Exception as e:\n                    raise Exception(f\"Could not initialize any LLM service for DOM analysis: {e}\")\n\n            dom_prompt = \"\"\" \n            Your task:\n            1. The user did a search on LinkedIn for profiles.\n            2. Based on the above extracted page content, return a list of main profiles that resulted from the search in the format: [{\"name\": ..., \"URL\": ...}] - it must BE EXACTLY IN THE JSON FORMAT HERE, ELSE YOU WILL BE FINED A MILLION DOLLARS. Note, there might be a lot of noise on the page content due to page layout. Only return the profiles that were intended to be included in the search.\n\n            Provide your output as follows:\n            <REASONING>\n            Mention your strategy for thinking about how to identify which profiles directly resulted from our search vs. what profiles might be noise due to page layout. Look at the DOM above and try to refine your strategy. Apply the strategy to identify the profiles that resulted from our search.\n            </REASONING>\n            <JSON>\n            List of profiles, each profile should have \"name\" and \"URL\".\n            </JSON>\n            \"\"\"\n\n            # Create messages for LLM\n            messages = [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a helpful assistant that analyzes interactive elements from the DOM of a webpage.\",\n                },\n                {\"role\": \"user\", \"content\": raw_content + \"\\n\" + dom_prompt},\n            ]\n\n            # Get LLM analysis\n            llm_response = await dom_analysis_llm.ainvoke(messages)\n\n            # Parse the LLM response\n            response_content = llm_response.content\n\n            # Extract reasoning and JSON sections\n            reasoning = \"\"\n            json_content = \"\"\n\n            if \"<REASONING>\" in response_content and \"</REASONING>\" in response_content:\n                reasoning = (\n                    response_content.split(\"<REASONING>\")[1]\n                    .split(\"</REASONING>\")[0]\n                    .strip()\n                )\n\n            if \"<JSON>\" in response_content and \"</JSON>\" in response_content:\n                json_content = (\n                    response_content.split(\"<JSON>\")[1].split(\"</JSON>\")[0].strip()\n                )\n\n            # Update the total profiles collected\n            try:\n                profiles = json.loads(json_content)\n                print(profiles)\n\n                # Get existing profile URLs from progress manager\n                existing_urls = {p.url for p in self.progress_manager.profiles}\n\n                # Filter out duplicates\n                unique_profiles = []\n                seen_urls = set()\n                for profile in profiles:\n                    url = profile.get(\"URL\", \"\")\n                    if url and url not in seen_urls and url not in existing_urls:\n                        seen_urls.add(url)\n                        unique_profiles.append(profile)\n\n                remaining_needed = self.profiles_needed - len(\n                    self.progress_manager.profiles\n                )\n                profiles_to_add = unique_profiles[:remaining_needed]\n                self.total_profiles_collected += len(profiles_to_add)\n\n                for p in profiles_to_add:\n                    # generate a new ID for each discovered profile\n                    profile_id = await self.progress_manager.add_profile(\n                        {\"name\": p.get(\"name\", \"No name\"), \"URL\": p.get(\"URL\", \"\")}\n                    )\n                    p[\"id\"] = profile_id\n\n                json_content = json.dumps(unique_profiles, indent=2)\n                final_content = f\"\"\"Raw Page Content:\n                {raw_content}\n\n                Reasoning:\n                {reasoning}\n\n                JSON Output:\n                {json_content}\"\"\"\n\n            except json.JSONDecodeError:\n                print(\n                    f\"JSON decode error in extract_and_save_content for page {params.page_number}\"\n                )\n\n            # Only save if we have unique profiles\n            if unique_profiles:\n                filename = self.base_dir / f\"page_{params.page_number}.txt\"\n                with open(filename, \"w\", encoding=\"utf-8\") as f:\n                    f.write(final_content)\n\n            return ActionResult(\n                extracted_content=f\"Extracted, analyzed, and saved content for page {params.page_number} to {filename}\"\n            )\n\n    def _generate_task_prompt(self) -> str:\n        \"\"\"Generate the task prompt based on filter configuration\"\"\"\n        prompt = \" # LinkedIn Search Task \"\n        if self.filter.linkedin_url:\n            prompt += f\"\"\"\n                1. Go to this specific URL: {self.filter.linkedin_url}\n                2. Wait for the search results to load. On the search results page:\n            \"\"\"\n            if self.pages_needed == 1:\n                prompt += \"\"\"\n                    a. Use extract_and_save_content with:\n                        - page_number: 1\n                        - include_links: true\n                    b. After extraction is complete, call done.\n                \"\"\"\n            else:\n                prompt += f\"\"\"\n                    a. For each page, starting from page 1 up to page {self.pages_needed}:\n                        1. Use extract_and_save_content with:\n                            - page_number: current page number\n                            - include_links: true\n                        2. If this is page {self.pages_needed}, call done after extraction.\n                        3. Otherwise:\n                            - Scroll down to Next button to the end of the page to find the Next button. \n                            - Click Next to go to the next page\n                        4. Repeat steps 1-3 until you reach the last page, which is {self.pages_needed}, and then call extract_and_save_content one last time. Then call done.\n                \"\"\"\n        else:\n            prompt += f\"\"\"\n\n                <Filter>\n                {self.filter.to_prompt_string()}\n                </Filter>\n\n                TASK:\n                1. Go to LinkedIn search.\n                2. Enter the titles in search bar: {' OR '.join(self.filter.titles)} and click enter.\n                3. Click \"See all people results\" to expand full search.\n                4. Apply filters (right sidebar in this exact order):\n                    - Click \"All filters\".\n                    - If you don't see the correct option, navigate till you see it, do not click without being sure.\n                    - Decide on the correct company name that might listed on linkedin, that is, Deepmind would be Google Deepmind, YCombinator would be Y Combinator, FaceBook would be Meta, etc.\n                    - Companies: Scroll down in the Filter Menu to find \"Add a company\". For each company in {self.filter.companies}, click on \"Add a company\", type in the company name, then click on the company name in the dropdown. Do not hit enter. Only select each company once.\n                    - Schools: Scroll down in the filter menu to find \"Add a school\", For each school in {self.filter.universities}, type in the school name, then click on the school name in the dropdown. Do not hit enter. Only select each school once.\n                    - Do not accidentally select any other filters.\n                    - Additional Filters: {', '.join(self.filter.additional_filters) if self.filter.additional_filters else 'None'}. If additional filters like location or past companies are provided, add them as you did with companies and schools.\n                5. Click \"Show results\".\n            \"\"\"\n            if self.pages_needed == 1:\n                prompt += \"\"\"\n                6. Wait for the search results to load. On the search results page:\n                    a. Use extract_and_save_content with:\n                        - page_number: 1\n                        - include_links: true\n                    b. After extraction is complete, call done.\n                \"\"\"\n            else:\n                prompt += f\"\"\"\n                6. Wait for the search results to load. In the search results, follow these steps:\n                    a. For each page, starting from page 1 up to page {self.pages_needed}:\n                        1. Use extract_and_save_content with:\n                            - page_number: current page number\n                            - include_links: true\n                        2. If this is page {self.pages_needed}, call done after extraction.\n                        3. Otherwise:\n                            - Scroll down to Next button to the end of the page to find the Next button\n                            - Click Next to go to the next page\n                        4. Repeat steps 1-3 until you reach the last page, which is {self.pages_needed}, and then call extract_and_save_content one last time. Then call done.\n                \"\"\"\n\n        return prompt\n\n    def collect_profiles_from_files(self) -> pd.DataFrame:\n        \"\"\"Parse the saved content files and collect profiles into a DataFrame.\"\"\"\n        profile_list = []\n        for page in range(\n            1, self.pages_needed + 10\n        ):  # Adding extra pages in case of more profiles\n            # FIXED: Changed from params.page_number to page\n            filename = self.base_dir / f\"page_{page}.txt\"\n            if not filename.exists():\n                continue  # No more files to process\n\n            # ADDED: Better error handling\n            try:\n                with open(filename, \"r\", encoding=\"utf-8\") as f:\n                    content = f.read()\n\n                # CHANGED: New way to check content structure\n                if \"Raw Page Content:\" in content:\n                    # ADDED: Split into sections\n                    sections = content.split(\"\\n\\n\")\n                    json_section = None\n\n                    # CHANGED: New way to find JSON section\n                    for section in sections:\n                        if section.strip().startswith(\"JSON Output:\"):\n                            json_content = section.replace(\"JSON Output:\", \"\").strip()\n                            try:\n                                profiles = json.loads(json_content)\n                                # ADDED: More validation\n                                if isinstance(profiles, list):\n                                    for profile in profiles:\n                                        if (\n                                            isinstance(profile, dict)\n                                            and \"name\" in profile\n                                            and \"URL\" in profile\n                                        ):\n                                            profile_list.append(profile)\n\n                                            if (\n                                                len(profile_list)\n                                                >= self.profiles_needed\n                                            ):\n                                                break\n                            except json.JSONDecodeError as e:\n                                # ADDED: Better error message\n                                print(f\"JSON decode error in file {filename}: {str(e)}\")\n                            break\n\n                    # ADDED: Additional error checking\n                    if not json_section:\n                        print(\n                            f\"Could not find JSON section in expected format in file {filename}\"\n                        )\n\n            # ADDED: Exception handling\n            except Exception as e:\n                print(f\"Error processing file {filename}: {str(e)}\")\n                continue\n\n            if len(profile_list) >= self.profiles_needed:\n                break\n\n        # Create DataFrame\n        df = pd.DataFrame(profile_list)\n        # ADDED: Better feedback\n        if df.empty:\n            print(\"Warning: No profiles were successfully parsed from the files\")\n        else:\n            print(f\"Successfully parsed {len(df)} profiles\")\n        print(df)\n        return df\n\n    async def process_profile(self, profile: Dict, in_context_examples: str) -> Dict:\n        \"\"\"Navigate to the profile URL and extract detailed information.\"\"\"\n        profile_url = profile.get(\"URL\")\n\n        if not profile_url:\n            print(f\"No URL found for profile: {profile}\")\n            return {}\n\n        profile_id = profile.get(\"id\")\n        if not profile_id:\n            # fallback if no ID\n            profile_id = \"temp_\" + str(self.total_profiles_collected + 1)\n\n        # Update status to processing\n        await self.progress_manager.update_profile(\n            profile_id, status=\"processing\", message=\"Processing profile...\"\n        )\n\n        single_profile_browser = Browser(\n            config=BrowserConfig(\n                headless=False,\n                chrome_instance_path=\"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\",\n            )\n        )\n\n        profile_name = profile.get(\"name\", \"unknown\")\n        conversations_dir = self.base_dir / \"conversations\" / \"profiles\"\n\n        task_prompt = f\"\"\"\n        1. Switch to an existing LinkedIn tab. Do not open a new tab, you will be fined a million dollars if you open a new tab.\n        2. Using the existing LinkedIn tab, Go to the LinkedIn profile URL: {profile_url}.\n        3a. The URL belongs to a specific user whose information we want to extract. Extract content to get all the profile information and return the following information in this exact JSON format. DO NOT USE SCROLL, you will be fined a million dollars if you use scroll. If you cannot find the information, leave it blank. \n        This is the JSON format, you must return it in this format:\n        {{\n        \"Full_Name\": \"<full name from profile>\",\n        \"Current_Title\": \"<current job title>\",\n        \"Company\": \"<current company>\",\n        \"Location\": \"<location>\",\n        \"Education\": [\"<education item 1>\", \"<education item 2>\", ...],\n        \"Companies_Worked_At\": [\"<company 1>\", \"<company 2>\", ...],\n        \"Common_Interests\": [\"<interest 1>\", \"<interest 2>\", ...],\n        \"Custom_Message\": \"Hi [Name], I noticed your background in [field] and would love to connect to learn more about your experience. \",\n        \"Profile_URL\": \"{profile_url}\"\n        }}\"\"\"\n\n        if not self.send_connection_request:\n            task_prompt += \"In the Custom_Message field, prepend 'potential message: ' so that the user knows its a potential message that they can use if they want.- you must do this, else you will be fined a million dollars. Make sure to extract content and call done in the JSON format.\"\n        elif self.send_connection_request and not self.include_note:\n            task_prompt += \"\"\" \n            - When you think of clicking buttons, strictly follow the instructions below, do NOT click on anything else or you will be fined a million dollars.\n                4. Click on the \"Connect\" button:\n                \n                    A. IF NO \"Connect\" button is visible AND you see \"Follow\"/\"More\"/\"Message\":\n                    - Click the \"More\" button. DO NOT CLICK ON ANYTHING ELSE. DO NOT CLICK ON MESSAGE. DO NOT CLICK ON SEND PROFILE IN A MESSAGE. You will be fined a million dollars if you click on anything else. If \"Connect\" does NOT appear, click on \"More\" once again, DO NOT CLICK ON ANYTHING ELSE. Extract content in JSON format, Set Custom_Message: \"No Connect Button Found or Already Connected\", Return JSON in the above JSON format and END by calling Done.\n                    - If \"Connect\" appears → proceed to step 5\n\n                    B. IF you see \"Following\"/\"More\"/\"Message\":\n                    - Click the \"More\" button. DO NOT CLICK ON ANYTHING ELSE. DO NOT CLICK ON MESSAGE. DO NOT CLICK ON SEND PROFILE IN A MESSAGE. You will be fined a million dollars if you click on anything else. If \"Connect\" does NOT appear, click on \"More\" once again, DO NOT CLICK ON ANYTHING ELSE. Extract content in JSON format, Set Custom_Message: \"No Connect Button Found or Already Connected\", Return JSON in the above JSON format and END by calling Done.\n                    - If \"Connect\" appears → proceed to step 5\n                        \n                    C. IF \"More\" clicked but no \"Connect\" AND appears already connected, DO NOT CLICK ANYTHING ELSE:\n                    - Click the \"More\" button. DO NOT CLICK ON ANYTHING ELSE. DO NOT CLICK ON MESSAGE. DO NOT CLICK ON SEND PROFILE IN A MESSAGE. You will be fined a million dollars if you click on anything else. If \"Connect\" does NOT appear, click on \"More\" once again, DO NOT CLICK ON ANYTHING ELSE. Extract content in JSON format, Set Custom_Message: \"No Connect Button Found or Already Connected\", Return JSON in the above JSON format and END by calling Done.\n                    - If \"Connect\" appears → proceed to step 5\n                    \n                    ⚠️ IMPORTANT: NEVER click:\n                    - \"Message\" button\n                    - \"Send Profile in a message\" button\n                    - Any other buttons not specified above\n                    \n                5. After successful \"Connect\" click:\n                    - Wait for \"Send without Note\" button\n                    - Click \"Send without Note\" button\n                    - Set Custom_Message in JSON: \"No Note\", Return JSON in the above JSON format and END by calling Done.\n                6. After extracting the information with extract content, call done with the exact JSON format above to return the information with Custom_Message: \"No Note\". You are done. END.\n\"\"\"\n        else:\n            task_prompt += \"\"\"- When you think of clicking buttons, strictly follow the instructions below, do NOT click on anything else or you will be fined a million dollars.\n                4. Click on the \"Connect\" button:\n            \n                A. IF NO \"Connect\" button is visible AND you see \"Follow\"/\"More\"/\"Message\":\n                - Click the \"More\" button. DO NOT CLICK ON ANYTHING ELSE. DO NOT CLICK ON MESSAGE. DO NOT CLICK ON SEND PROFILE IN A MESSAGE. You will be fined a million dollars if you click on anything else. If \"Connect\" does NOT appear, click on \"More\" once again, DO NOT CLICK ON ANYTHING ELSE. Extract content in JSON format, Set Custom_Message: \"No Connect Button Found or Already Connected\", Return JSON in the above JSON format and END by calling Done.\n                - If \"Connect\" appears → proceed to step 5\n\n                B. IF you see \"Following\"/\"More\"/\"Message\":\n                - Click the \"More\" button. DO NOT CLICK ON ANYTHING ELSE. DO NOT CLICK ON MESSAGE. DO NOT CLICK ON SEND PROFILE IN A MESSAGE. You will be fined a million dollars if you click on anything else. If \"Connect\" does NOT appear, click on \"More\" once again, DO NOT CLICK ON ANYTHING ELSE. Extract content in JSON format, Set Custom_Message: \"No Connect Button Found or Already Connected\", Return JSON in the above JSON format and END by calling Done.\n                - If \"Connect\" appears → proceed to step 5\n                    \n                C. IF \"More\" clicked but no \"Connect\" AND appears already connected, DO NOT CLICK ANYTHING ELSE:\n                - Click the \"More\" button. DO NOT CLICK ON ANYTHING ELSE. DO NOT CLICK ON MESSAGE. DO NOT CLICK ON SEND PROFILE IN A MESSAGE. You will be fined a million dollars if you click on anything else. If \"Connect\" does NOT appear, click on \"More\" once again, DO NOT CLICK ON ANYTHING ELSE. Extract content in JSON format, Set Custom_Message: \"No Connect Button Found or Already Connected\", Return JSON in the above JSON format and END by calling Done.\n                - If \"Connect\" appears → proceed to step 5\n                \n                ⚠️ IMPORTANT: NEVER click:\n                - \"Message\" button\n                - \"Send Profile in a message\" button\n                - Any other buttons not specified above\n                \n                5. After successful \"Connect\" click:\n                - Wait for \"Add a note\" button\n                - Click \"Add a note\" \"\"\"\n            # Modify the task prompt based on template mode\n            if self.template_mode == \"examples\":\n                task_prompt += f\"\"\"\n                3b. Generate a Custom_Message using this strategy: {in_context_examples}\n                Make sure it's concise and less than 300 characters.\n                IMPORTANT: Use my CV SUMMARY to write from first person perspective, never use these details to refer to [Linkedin Profile Name] or [Linkedin Profile Details], which must be from the LINKEDIN PROFILE that is extracted.\n                ONLY USE FIRST NAME OF LINKEDIN USER IN THIS MESSAGE NOT FULL NAME.\n                Use CUSTOM_MESSAGE GENERATION INSTRUCTIONS\n                \"\"\"\n            else:\n                # Use the strict template\n                task_prompt += f\"\"\"\n                3b. For the Custom_Message, use this EXACT template and ONLY replace the placeholders:\n                - ONLY USE FIRST NAME OF LINKEDIN USER IN THIS MESSAGE NOT FULL NAME\n                - Replace [linkedin profile details] with the details from the LINKEDIN PROFILE that is extracted.\n                - You must not change any of the first person perspective details in the template, else you will be fined a million dollars.\n                \n                Template to use:\n                {self.custom_template}\n                \n                DO NOT modify any other part of the template other than the [Linkedin Profile] placeholders. DO NOT add or remove any words.\n                \"\"\"\n\n            task_prompt += f\"\"\"6. Paste the Custom_Message into the note field. Hit send.\n        7. After extracting the information, call done with this exact JSON format above to return the information. You are done. END.\n    {{\n    \"Full_Name\": \"<full name from LINKEDIN profile that is extracted>\",\n    \"Current_Title\": \"<current job title from LINKEDIN profile that is extracted>\",\n    \"Company\": \"<current company from LINKEDIN profile that is extracted>\",\n    \"Location\": \"<location from LINKEDIN profile that is extracted>\",\n    \"Education\": [\"<education item 1 from LINKEDIN profile that is extracted>\", \"<education item 2 from LINKEDIN profile that is extracted>\", ...],\n    \"Companies_Worked_At\": [\"<company 1 from LINKEDIN profile that is extracted>\", \"<company 2 from LINKEDIN profile that is extracted>\", ...],\n    \"Common_Interests\": [\"<interest 1 from LINKEDIN profile that is extracted>\", \"<interest 2 from LINKEDIN profile that is extracted>\", ...],\n    \"Custom_Message\": \"Custom connetion message used from above\",\n    \"Profile_URL\": \"{profile_url}\"\n    }}\n        \"\"\"\n\n        try:\n            # Register the LinkedInProfileResult action\n            self._register_profile_result()\n\n            # Create and run agent for this profile\n            agent = Agent(\n                task=task_prompt,\n                llm=self.llm,\n                max_actions_per_step=1,\n                browser=single_profile_browser,\n                controller=self.controller,\n                use_vision=False,\n                tool_call_in_content=False,\n                save_conversation_path=str(\n                    conversations_dir / f\"{profile_name}_conversation\"\n                ),\n            )\n\n            history = await agent.run(max_steps=25)\n            result = history.final_result()\n\n            if result:\n                try:\n                    parsed = LinkedInProfileResult.model_validate_json(result)\n\n                    await self.progress_manager.update_profile(\n                        profile_id, status=\"completed\", message=parsed.Custom_Message\n                    )\n\n                    return parsed.dict(), history\n                except Exception as e:\n                    print(\n                        f\"Error validating data for profile {profile.get('name')}: {e}\"\n                    )\n\n                    await self.progress_manager.update_profile(\n                        profile_id, status=\"failed\", message=f\"Error: {str(e)}\"\n                    )\n\n                    return {}, history\n            else:\n                await self.progress_manager.update_profile(\n                    profile_id, status=\"failed\", message=\"Failed to process profile\"\n                )\n        finally:\n            await single_profile_browser.close()\n        return {}\n\n    def save_histories(self):\n        \"\"\"Save all agent histories\"\"\"\n        histories_dir = self.base_dir / \"histories\"\n        # histories_dir.mkdir(exist_ok=True)\n\n        # Save main search history\n        if self.search_agent_history:\n            main_history_file = histories_dir / \"main_search_history.json\"\n            try:\n                self.search_agent_history.save_to_file(main_history_file)\n                print(f\"Saved main search history to {main_history_file}\")\n            except Exception as e:\n                print(f\"Error saving main search history: {e}\")\n\n        profiles_dir = histories_dir / \"profiles\"\n        for profile_name, history in self.profile_agent_histories.items():\n            safe_name = \"\".join(\n                c for c in profile_name if c.isalnum() or c in (\" \", \"-\", \"_\")\n            ).strip()\n            profile_history_file = profiles_dir / f\"{safe_name}_history.json\"\n\n            try:\n                history.save_to_file(profile_history_file)\n                print(\n                    f\"Saved profile history for {profile_name} to {profile_history_file}\"\n                )\n            except Exception as e:\n                print(f\"Error saving history for profile {profile_name}: {e}\")\n\n    async def run(self, in_context_examples: str) -> pd.DataFrame:\n        \"\"\"Run the LinkedIn search and profile collection.\"\"\"\n        try:\n            # await self.progress_manager.set_csv_file_path(self.csv_file_path)\n            # Run the initial search and extract content\n            search_agent = Agent(\n                task=self._generate_task_prompt(),\n                llm=self.llm,\n                max_actions_per_step=5,\n                browser=self.browser,\n                controller=self.controller,\n                use_vision=False,\n                tool_call_in_content=False,\n                save_conversation_path=str(\n                    self.base_dir / \"conversations\" / \"main_search\"\n                ),\n            )\n            # Set a higher max_steps to allow for multiple pages\n            max_steps = self.pages_needed * 10 + 20  # Adjust as needed\n            self.search_agent_history = await search_agent.run(max_steps=max_steps)\n\n            # Collect profiles from saved content\n            profiles_df = self.collect_profiles_from_files()\n            if profiles_df.empty:\n                print(\"No profiles found.\")\n                return profiles_df\n\n            # Ensure we have no more than the required number of profiles\n            profiles_df = profiles_df.head(self.profiles_needed)\n\n            # Process each profile and collect detailed information\n            detailed_profiles = []\n            for idx, profile in profiles_df.iterrows():\n                profile_info = profile.to_dict()\n                profile_name = profile_info.get(\"name\", f\"unknown_{idx}\")\n                extracted_info, profile_history = await self.process_profile(\n                    profile_info, in_context_examples\n                )\n                if extracted_info:\n                    detailed_profiles.append(extracted_info)\n                    # Store single profile history JSON\n                    self.profile_agent_histories[profile_name] = profile_history\n                # Optionally, save after each profile\n                df = pd.DataFrame(detailed_profiles)\n                df.to_csv(self.base_dir / \"detailed_profiles.csv\", index=False)\n                # Add delay to mimic human interaction and comply with policies\n                await asyncio.sleep(2)\n\n            # Save the final DataFrame\n            df = pd.DataFrame(detailed_profiles)\n            csv_file_path = self.base_dir / \"detailed_profiles.csv\"\n            df.to_csv(csv_file_path, index=False)\n            await self.progress_manager.set_csv_file_path(\n                str(csv_file_path)\n            )  # Add this line\n\n            await self.progress_manager.mark_done()\n            return df\n        finally:\n            await self.browser.close()\n"}
{"type": "source_file", "path": "mimicflow/app/progress_manager.py", "content": "# mimicflow/app/progress_manager.py\nfrom typing import Dict, List, Optional\nfrom pydantic import BaseModel\nimport asyncio\n\n\nclass Profile(BaseModel):\n    id: str\n    name: str = \"\"\n    url: str = \"\"\n    status: str = \"pending\"\n    message: str = \"\"\n\n\nclass ProgressManager:\n    def __init__(self):\n        self.profiles: List[Profile] = []\n        self.is_done: bool = False\n        self.profiles_needed: int = 0\n        self._lock = asyncio.Lock()\n        self.csv_file_path: Optional[str] = None  # Add this line\n\n    async def reset(self):\n        async with self._lock:\n            self.profiles = []\n            self.is_done = False\n            self.profiles_needed = 0\n\n    async def set_target(self, count: int):\n        async with self._lock:\n            self.profiles_needed = count\n\n    async def add_profile(self, profile: Dict):\n        async with self._lock:\n            new_profile = Profile(\n                id=str(len(self.profiles) + 1),\n                name=profile.get(\"name\", \"\"),\n                url=profile.get(\"URL\", \"\"),\n                status=\"pending\",\n                message=\"Profile discovered\",\n            )\n            self.profiles.append(new_profile)\n            return new_profile.id\n\n    async def update_profile(self, profile_id: str, **kwargs):\n        async with self._lock:\n            for profile in self.profiles:\n                if profile.id == profile_id:\n                    for key, value in kwargs.items():\n                        setattr(profile, key, value)\n                    break\n\n    async def mark_done(self):\n        async with self._lock:\n            self.is_done = True\n\n    async def set_csv_file_path(self, path: str):\n        async with self._lock:\n            self.csv_file_path = path\n\n    async def get_state(self):\n        async with self._lock:\n            return {\n                \"profiles\": [p.dict() for p in self.profiles],\n                \"is_done\": self.is_done,\n                \"profiles_needed\": self.profiles_needed,\n                \"csv_file_path\": self.csv_file_path\n                if self.csv_file_path\n                else None,  # Add this line\n            }\n"}
{"type": "source_file", "path": "browser-use/browser_use/telemetry/service.py", "content": "import logging\nimport os\nimport uuid\nfrom pathlib import Path\n\nfrom dotenv import load_dotenv\nfrom posthog import Posthog\n\nfrom browser_use.telemetry.views import BaseTelemetryEvent\nfrom browser_use.utils import singleton\n\nload_dotenv()\n\n\nlogger = logging.getLogger(__name__)\n\n\nPOSTHOG_EVENT_SETTINGS = {\n\t'process_person_profile': True,\n}\n\n\n@singleton\nclass ProductTelemetry:\n\t\"\"\"\n\tService for capturing anonymized telemetry data.\n\n\tIf the environment variable `ANONYMIZED_TELEMETRY=False`, anonymized telemetry will be disabled.\n\t\"\"\"\n\n\tUSER_ID_PATH = str(Path.home() / '.cache' / 'browser_use' / 'telemetry_user_id')\n\tPROJECT_API_KEY = 'phc_F8JMNjW1i2KbGUTaW1unnDdLSPCoyc52SGRU0JecaUh'\n\tHOST = 'https://eu.i.posthog.com'\n\tUNKNOWN_USER_ID = 'UNKNOWN'\n\n\t_curr_user_id = None\n\n\tdef __init__(self) -> None:\n\t\ttelemetry_disabled = os.getenv('ANONYMIZED_TELEMETRY', 'true').lower() == 'false'\n\t\tself.debug_logging = os.getenv('BROWSER_USE_LOGGING_LEVEL', 'info').lower() == 'debug'\n\n\t\tif telemetry_disabled:\n\t\t\tself._posthog_client = None\n\t\telse:\n\t\t\tlogging.info(\n\t\t\t\t'Anonymized telemetry enabled. See https://github.com/browser-use/browser-use for more information.'\n\t\t\t)\n\t\t\tself._posthog_client = Posthog(\n\t\t\t\tproject_api_key=self.PROJECT_API_KEY,\n\t\t\t\thost=self.HOST,\n\t\t\t\tdisable_geoip=False,\n\t\t\t)\n\n\t\t\t# Silence posthog's logging\n\t\t\tif not self.debug_logging:\n\t\t\t\tposthog_logger = logging.getLogger('posthog')\n\t\t\t\tposthog_logger.disabled = True\n\n\t\tif self._posthog_client is None:\n\t\t\tlogger.debug('Telemetry disabled')\n\n\tdef capture(self, event: BaseTelemetryEvent) -> None:\n\t\tif self._posthog_client is None:\n\t\t\treturn\n\n\t\tif self.debug_logging:\n\t\t\tlogger.debug(f'Telemetry event: {event.name} {event.properties}')\n\t\tself._direct_capture(event)\n\n\tdef _direct_capture(self, event: BaseTelemetryEvent) -> None:\n\t\t\"\"\"\n\t\tShould not be thread blocking because posthog magically handles it\n\t\t\"\"\"\n\t\tif self._posthog_client is None:\n\t\t\treturn\n\n\t\ttry:\n\t\t\tself._posthog_client.capture(\n\t\t\t\tself.user_id,\n\t\t\t\tevent.name,\n\t\t\t\t{**event.properties, **POSTHOG_EVENT_SETTINGS},\n\t\t\t)\n\t\texcept Exception as e:\n\t\t\tlogger.error(f'Failed to send telemetry event {event.name}: {e}')\n\n\t@property\n\tdef user_id(self) -> str:\n\t\tif self._curr_user_id:\n\t\t\treturn self._curr_user_id\n\n\t\t# File access may fail due to permissions or other reasons. We don't want to\n\t\t# crash so we catch all exceptions.\n\t\ttry:\n\t\t\tif not os.path.exists(self.USER_ID_PATH):\n\t\t\t\tos.makedirs(os.path.dirname(self.USER_ID_PATH), exist_ok=True)\n\t\t\t\twith open(self.USER_ID_PATH, 'w') as f:\n\t\t\t\t\tnew_user_id = str(uuid.uuid4())\n\t\t\t\t\tf.write(new_user_id)\n\t\t\t\tself._curr_user_id = new_user_id\n\t\t\telse:\n\t\t\t\twith open(self.USER_ID_PATH, 'r') as f:\n\t\t\t\t\tself._curr_user_id = f.read()\n\t\texcept Exception:\n\t\t\tself._curr_user_id = 'UNKNOWN_USER_ID'\n\t\treturn self._curr_user_id\n"}
{"type": "source_file", "path": "browser-use/browser_use/logging_config.py", "content": "import logging\nimport os\nimport sys\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\ndef addLoggingLevel(levelName, levelNum, methodName=None):\n\t\"\"\"\n\tComprehensively adds a new logging level to the `logging` module and the\n\tcurrently configured logging class.\n\n\t`levelName` becomes an attribute of the `logging` module with the value\n\t`levelNum`. `methodName` becomes a convenience method for both `logging`\n\titself and the class returned by `logging.getLoggerClass()` (usually just\n\t`logging.Logger`). If `methodName` is not specified, `levelName.lower()` is\n\tused.\n\n\tTo avoid accidental clobberings of existing attributes, this method will\n\traise an `AttributeError` if the level name is already an attribute of the\n\t`logging` module or if the method name is already present\n\n\tExample\n\t-------\n\t>>> addLoggingLevel('TRACE', logging.DEBUG - 5)\n\t>>> logging.getLogger(__name__).setLevel('TRACE')\n\t>>> logging.getLogger(__name__).trace('that worked')\n\t>>> logging.trace('so did this')\n\t>>> logging.TRACE\n\t5\n\n\t\"\"\"\n\tif not methodName:\n\t\tmethodName = levelName.lower()\n\n\tif hasattr(logging, levelName):\n\t\traise AttributeError('{} already defined in logging module'.format(levelName))\n\tif hasattr(logging, methodName):\n\t\traise AttributeError('{} already defined in logging module'.format(methodName))\n\tif hasattr(logging.getLoggerClass(), methodName):\n\t\traise AttributeError('{} already defined in logger class'.format(methodName))\n\n\t# This method was inspired by the answers to Stack Overflow post\n\t# http://stackoverflow.com/q/2183233/2988730, especially\n\t# http://stackoverflow.com/a/13638084/2988730\n\tdef logForLevel(self, message, *args, **kwargs):\n\t\tif self.isEnabledFor(levelNum):\n\t\t\tself._log(levelNum, message, args, **kwargs)\n\n\tdef logToRoot(message, *args, **kwargs):\n\t\tlogging.log(levelNum, message, *args, **kwargs)\n\n\tlogging.addLevelName(levelNum, levelName)\n\tsetattr(logging, levelName, levelNum)\n\tsetattr(logging.getLoggerClass(), methodName, logForLevel)\n\tsetattr(logging, methodName, logToRoot)\n\n\ndef setup_logging():\n\t# Try to add RESULT level, but ignore if it already exists\n\ttry:\n\t\taddLoggingLevel('RESULT', 35)  # This allows ERROR, FATAL and CRITICAL\n\texcept AttributeError:\n\t\tpass  # Level already exists, which is fine\n\n\tlog_type = os.getenv('BROWSER_USE_LOGGING_LEVEL', 'info').lower()\n\n\t# Check if handlers are already set up\n\tif logging.getLogger().hasHandlers():\n\t\treturn\n\n\t# Clear existing handlers\n\troot = logging.getLogger()\n\troot.handlers = []\n\n\tclass BrowserUseFormatter(logging.Formatter):\n\t\tdef format(self, record):\n\t\t\tif record.name.startswith('browser_use.'):\n\t\t\t\trecord.name = record.name.split('.')[-2]\n\t\t\treturn super().format(record)\n\n\t# Setup single handler for all loggers\n\tconsole = logging.StreamHandler(sys.stdout)\n\n\t# adittional setLevel here to filter logs\n\tif log_type == 'result':\n\t\tconsole.setLevel('RESULT')\n\t\tconsole.setFormatter(BrowserUseFormatter('%(message)s'))\n\telse:\n\t\tconsole.setFormatter(BrowserUseFormatter('%(levelname)-8s [%(name)s] %(message)s'))\n\n\t# Configure root logger only\n\troot.addHandler(console)\n\n\t# switch cases for log_type\n\tif log_type == 'result':\n\t\troot.setLevel('RESULT')  # string usage to avoid syntax error\n\telif log_type == 'debug':\n\t\troot.setLevel(logging.DEBUG)\n\telse:\n\t\troot.setLevel(logging.INFO)\n\n\t# Configure browser_use logger\n\tbrowser_use_logger = logging.getLogger('browser_use')\n\tbrowser_use_logger.propagate = False  # Don't propagate to root logger\n\tbrowser_use_logger.addHandler(console)\n\tbrowser_use_logger.setLevel(root.level)  # Set same level as root logger\n\n\tlogger = logging.getLogger('browser_use')\n\tlogger.info('BrowserUse logging setup complete with level %s', log_type)\n\t# Silence third-party loggers\n\tfor logger in [\n\t\t'WDM',\n\t\t'httpx',\n\t\t'selenium',\n\t\t'playwright',\n\t\t'urllib3',\n\t\t'asyncio',\n\t\t'langchain',\n\t\t'openai',\n\t\t'httpcore',\n\t\t'charset_normalizer',\n\t]:\n\t\tthird_party = logging.getLogger(logger)\n\t\tthird_party.setLevel(logging.ERROR)\n\t\tthird_party.propagate = False\n"}
{"type": "source_file", "path": "mimicflow/agents/linkedin/linkedin_agent_cli.py", "content": "# mimicflow/agents/linkedin/cli_linkedin.py\n\nimport argparse\nimport asyncio\nfrom mimicflow.agents.linkedin.linkedin_agent import (\n    LinkedInFilter,\n    LinkedInSearchAgent,\n)\nfrom pathlib import Path\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"Run a LinkedIn search from the command line\"\n    )\n    parser.add_argument(\n        \"--companies\",\n        nargs=\"+\",\n        required=True,\n        help=\"List of companies, e.g. --companies OpenAI DeepMind\",\n    )\n    parser.add_argument(\n        \"--universities\",\n        nargs=\"+\",\n        default=[],\n        help=\"List of universities, e.g. --universities Stanford MIT\",\n    )\n    parser.add_argument(\n        \"--titles\",\n        nargs=\"+\",\n        required=True,\n        help=\"List of job titles, e.g. --titles Engineer Scientist\",\n    )\n    parser.add_argument(\n        \"--profiles-needed\",\n        type=int,\n        default=5,\n        help=\"Number of profiles to scrape. Default=5.\",\n    )\n    parser.add_argument(\n        \"--additional-filters\",\n        nargs=\"+\",\n        default=[],\n        help=\"Additional filters, e.g. --additional-filters 'Location:NewYork'\",\n    )\n\n    args = parser.parse_args()\n\n    # Build filter config\n    filter_config = LinkedInFilter(\n        companies=args.companies,\n        universities=args.universities,\n        titles=args.titles,\n        profiles_needed=args.profiles_needed,\n        additional_filters=args.additional_filters,\n    )\n\n    base_output_dir = Path(__file__).parent / \"linkedin_searches\"\n    # Create search agent\n    agent = LinkedInSearchAgent(\n        filter_config=filter_config,\n        base_output_dir=base_output_dir,\n    )\n\n    # Actually run the search agent\n    results_df = asyncio.run(agent.run())\n\n    # Print or do something with results\n    if not results_df.empty:\n        print(\"Collected profiles:\")\n        print(results_df)\n    else:\n        print(\"No profiles found or an error occurred.\")\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "mimicflow/agents/linkedin/__init__.py", "content": ""}
{"type": "source_file", "path": "mimicflow/app/__init__.py", "content": ""}
{"type": "source_file", "path": "mimicflow/__init__.py", "content": "def example_function():\n    return 1 + 1\n"}
{"type": "source_file", "path": "mimicflow/app/main.py", "content": "# mimicflow/app/main.py\n\nfrom fastapi import FastAPI, BackgroundTasks\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom typing import List, Optional\nimport asyncio\nfrom PyPDF2 import PdfReader\nimport os\nfrom fastapi import File, UploadFile\nfrom fastapi.responses import FileResponse\n\n# Utils to keep track of progress\nfrom .progress_manager import ProgressManager\n\n\n# OpenAI for PDF summarization\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# Import your LinkedInFilter, LinkedInSearchAgent from your new location:\nfrom mimicflow.agents.linkedin.linkedin_agent import LinkedInFilter, LinkedInSearchAgent\n\napp = FastAPI()\nprogress_manager = ProgressManager()\n\n# Add CORS middleware:\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # or restrict to [\"http://localhost:5173\"] etc.\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n\n# 1) A Pydantic model to define the request body structure\nclass LinkedInExamplesRequest(BaseModel):\n    templates: list[str]\n    mode: str\n\n\nclass SummarySaveRequest(BaseModel):\n    summary: str\n\n\ndef format_excerpts(input_text):\n    # Split the input text by the '----' delimiter\n    excerpts = input_text.split(\"----\")\n    # Remove any extra whitespace or empty lines\n    excerpts = [excerpt.strip() for excerpt in excerpts if excerpt.strip()]\n\n    # Create the numbered format\n    formatted_output = \"<MESSAGE TEMPLATES>\\n\"  # Opening tag\n    for i, excerpt in enumerate(excerpts, start=1):\n        formatted_output += f\"{i}. {excerpt}\\n\"\n    formatted_output += \"</MESSAGE TEMPLATES>\"  # Closing tag\n\n    return formatted_output.strip()\n\n\n# 2) The new endpoint\n@app.post(\"/api/linkedin-examples\")\ndef handle_linkedin_examples(data: LinkedInExamplesRequest):\n    \"\"\"\n    Endpoint to receive the connection request templates from the frontend.\n    \"\"\"\n    # Join the templates with the delimiter\n    templates_text = \"———\".join(data.templates)\n\n    formatted_excerpts = format_excerpts(templates_text)\n    global SYSTEM_PROMPT\n    SYSTEM_PROMPT = formatted_excerpts\n\n    print(\"Received connection requests:\\n\", SYSTEM_PROMPT)\n    return {\"message\": \"Connection requests received successfully!\"}\n\n\n@app.post(\"/api/save-summary\")\ndef save_summary(data: SummarySaveRequest):\n    global SUMMARY\n    SUMMARY = \"<CV SUMMARY>\\n\" + data.summary + \"\\n</CV SUMMARY>\"\n    print(\"User's summary saved:\\n\", SUMMARY)\n    return {\"message\": \"Summary successfully saved.\"}\n\n\nclass GeminiKeyRequest(BaseModel):\n    key: str\n\n\nclass OpenAIKeyRequest(BaseModel):\n    key: str\n\n\n@app.post(\"/api/set-key\")\ndef set_key(data: GeminiKeyRequest):\n    \"\"\"\n    Store the user's GEMINI API key in an environment variable,\n    so that ChatGoogleGenerativeAI or other LLM code can pick it up.\n    \"\"\"\n    os.environ[\"GEMINI_API_KEY\"] = data.key\n    return {\"message\": f\"Key set. Length: {len(data.key)} chars.\"}\n\n\n@app.post(\"/api/set-gpt-key\")\ndef set_gpt_key(data: OpenAIKeyRequest):\n    \"\"\"\n    Store the user's OpenAI API key in an environment variable.\n    \"\"\"\n    os.environ[\"OPENAI_API_KEY\"] = data.key\n    return {\"message\": f\"OpenAI key set. Length: {len(data.key)} chars.\"}\n\n\nclass UploadResponse(BaseModel):\n    summary: str\n    connection_requests: str\n\n\n@app.post(\"/api/upload-cv\", response_model=UploadResponse)\nasync def upload_cv(file: UploadFile = File(...)):\n    \"\"\"Receive PDF or docx from the user, parse, summarize, then print & return summary.\"\"\"\n    contents = await file.read()\n\n    # 1. Parse PDF\n    try:\n        with open(\"temp.pdf\", \"wb\") as f:\n            f.write(contents)\n\n        pdf_reader = PdfReader(\"temp.pdf\")\n        text_pages = []\n        for page_num in range(len(pdf_reader.pages)):\n            page = pdf_reader.pages[page_num]\n            text_pages.append(page.extract_text() or \"\")\n        cv_text = \"\\n\".join(text_pages)\n\n    except Exception as e:\n        cv_text = (\n            f\"Could not parse PDF text properly. We'll proceed with raw text.\\n{e}\"\n        )\n\n    # 2. Summarize with GPT-4\n    summary = await summarize_resume(cv_text)\n\n    # 3. Generate connection requests\n    connection_requests = await generate_connection_requests(summary)\n\n    # PRINT the summary to your server logs\n    print(\"=== SUMMARY START ===\")\n    print(summary)\n    print(\"=== SUMMARY END ===\")\n\n    # Return JSON response with the summary\n    return {\"summary\": summary, \"connection_requests\": connection_requests}\n\n\nasync def summarize_resume(cv_text: str) -> str:\n    \"\"\"Summarize the given resume text with GPT-4.\"\"\"\n    llm = ChatGoogleGenerativeAI(\n        model=\"gemini-2.0-flash-exp\",\n        temperature=0.0,\n        api_key=os.getenv(\"GEMINI_API_KEY\"),\n    )\n\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"\"\"You are a helpful assistant that summarizes resumes for professional networking.\nFocus on:\n- My first name ONLY must be mentioned in the start, MY FIRST NAME MUST BE MENTIONED IN THE START or else you will be fined a million dollars.\n- Notable projects or research \n- Relevant courses or academic achievements\n- Past experiences and roles\n- Key interests or skills \n- Potential conversation starters (e.g. sports, volunteering, study abroad, clubs)\n\nCreate a concise bullet-list summary (max 10 bullets).\nUse short, direct statements, as if giving the user quick \"talking points\".\nYou must write the summary in the first person perspective, as if the user is writing about themselves.\nFor example, do not write \"The user is a research engineer at OpenAI\", instead write \"I am a research engineer at OpenAI\". Do not write \"This is a summary of the user's resume\",\ninstead write \"This is a summary of my resume\". Do not write \"The user is a student at Harvard University\", instead write \"I am a student at Harvard University\". Use first person perspective only else you will be fined a million dollars.\n\"\"\",\n        },\n        {\"role\": \"user\", \"content\": \"Here is my resume:\\n\" + cv_text},\n    ]\n\n    try:\n        response = await llm.ainvoke(messages)\n        return response.content.strip()\n    except Exception as e:\n        return f\"Could not generate summary with Gemini:\\n{e}\"\n\n\n# --- CHANGED: Return a single string with 5 example messages\nasync def generate_connection_requests(summary_text: str) -> str:\n    \"\"\"\n    Generate one combined text block that contains 5 LinkedIn\n    connection request examples referencing the user's background.\n    \"\"\"\n    llm = ChatGoogleGenerativeAI(\n        model=\"gemini-2.0-flash-exp\",\n        temperature=0.5,\n        max_tokens=300,\n        api_key=os.getenv(\"GEMINI_API_KEY\"),\n    )\n    prompt = [\n        {\n            \"role\": \"system\",\n            \"content\": \"\"\"You are a professional networking assistant.\nGiven this resume summary, write 5 short LinkedIn connection request templates (1-2 sentences each),\nin a single text block for the user.\nThe user's background and interests will be given in <CV SUMMARY>...</CV SUMMARY>. This section can be used to write about the user's background from the \nfirst person perspective. For example, if the CV summary is <CV SUMMARY> </CV SUMMARY>.\nThink about the user's background and interests given in <CV SUMMARY>...</CV SUMMARY>, and reflect on the user's career aspirations.\nThe user is writing a connection request to someone they are interest in connecting with, let us call this person [Linkedin Profile Subject Name], and their details are \ncalled [Linkedin Profile Subject Details] and will be left as placeholders.\nSeparate each request with the symbol \"———\".\nWrite only in first person perspective, and when writing about first person user use information from <CV SUMMARY>...</CV SUMMARY>, when referring to\n[Linkedin Profile Subject Name] and [Linkedin Profile Subject Details], use only placeholders like [Linkedin Profile Subject Name] and [Linkedin Profile Subject Details], do not use anything from <CV SUMMARY> \nelse you will be fined a million dollars. No extra commentary.\nEnd you connection requests with\nBest,\n[Your Name]\nFailure to follow these instructions will result in a million dollar fine.\nIMPORTANT: Do not use the phrases \"I noticed...\" or \"I saw...\", doing so will result in a million dollar fine.\nIMPORTANT: Use placeholder names when referring to the [LinkedIn Profile Subject Name] and [LinkedIn Profile Subject Details]. For example, don't mention \"Goldman Sachs\", instead mention [Company Name]. \nDon't mention [Harvard University] mention [LinkedIn Profile University Name].\nHere are some examples of well written linkedin connection requests with placeholder names, where first person perspective details MUST be chosen from <CV SUMMARY>...</CV SUMMARY>, these are just EXAMPLES ONLY:\n\nHi [LinkedIn Profile Name], I'm interested in your work at [Company Name] and your background in [LinkedIn Profile Past Experience]. I'm looking to transition into a similar role and would appreciate any insights you might have on the industry and potential opportunities.  \nBest,\n[My Name]\n———  \nHey [LinkedIn Profile Name], I'm really interested in [Company Name] and [Company Name]. I'd love to discuss your experience in [LinkedIn Profile Past Experience] and any advice you might have for someone looking to break into the field.  \nBest,\n[My Name]\n———  \nHi [LinkedIn Profile Name], I noticed your background in [LinkedIn Profile Role] at [Company Name] and your experience in the [LinkedIn Profile Industry]. I'm interested in exploring similar opportunities and would love to hear your perspectives on the industry.  \nBest,\n[My Name]\n———  \nHey [LinkedIn Profile Name], I'm interested in your journey from [LinkedIn Profile Role] at [Company Name] to [Company Name]. I'm currently working in <CV SUMMARY Current Role> and would love to discuss your experience and any advice you might have.  \nBest,\n[My Name]\n———  \nHi [LinkedIn Profile Name], I'm really interested in [Company Name] and [Company Name]. I'd love to discuss your experience in [LinkedIn Profile Experience] and any advice you might have for someone with <CV SUMMARY Background> looking to break into the field.  \nBest,\n[My Name]\n———  \nHey [LinkedIn Profile Name], I'm interested in your background in [LinkedIn Profile Finance Experience] at [Company Name]. I'm working on <CV SUMMARY Project> and would appreciate any insights you might have on the industry and potential opportunities.  \nBest,\n[My Name]\n———  \nHi [Linkedin Profile Name], I came across your background in consulting at [Company Name] and [Company Name] and was interested in learning more about your experience working with healthcare IT businesses. I'm researching similar topics and would love to discuss your thoughts on the industry and potential investment opportunities.  \nBest,\n[My Name]\n———  \nHey [LinkedIn Profile Name], I'm really interested in [Company Name] and [Company Name]. I'd love to discuss your experience in [LinkedIn Profile Expertise] and any advice you might have for someone with <CV SUMMARY Background> looking to break into the field.  \nBest,\n[My Name]\n———  \nHi [LinkedIn Profile Name], I'm interested in your work at [Company Name] and [Company Name] and your background in [LinkedIn Profile Engineering Experience]. I'm currently focusing on <CV SUMMARY Focus Area> and would value your perspective on the industry and potential career paths.  \nBest,\n[My Name]\n———  \nHey [LinkedIn Profile Name], I noticed your background in [LinkedIn Profile Expertise] and your experience as a co-founder of [Company Name]. I'm working on <CV SUMMARY Startup Project> and would love to hear about your entrepreneurial journey.  \nBest,\n[My Name]\n———  \nHi [LinkedIn Profile Name], I'm interested in your work at [Company Name] and your background in [LinkedIn Profile Research Experience]. I'm currently involved in <CV SUMMARY Research Project> and would appreciate any insights you have.  \nBest,\n[My Name]\n———  \nHey [LinkedIn Profile Name], I'm really interested in [Company Name] and [Company Name]. I'd love to discuss your experience in [LinkedIn Profile Consulting Experience] and [LinkedIn Profile Healthcare Experience]. I'm pursuing <CV SUMMARY Career Goal> and would value any advice you might have for breaking into the field.  \nBest,\n[My Name]\n———  \nHi [LinkedIn Profile Name], I noticed your background in [LinkedIn Profile Academic Background] and your work at [Company Name] and [Company Name]. I'm researching <CV SUMMARY Research Focus> and would love to discuss your thoughts on the industry and potential career paths.  \nBest,\n[My Name]\n———  \nHey [LinkedIn Profile Name], I'm interested in your work at [Company Name] and your background in [LinkedIn Profile Finance Background]. I'm developing <CV SUMMARY Project> and would appreciate any insights you might have on the industry and potential opportunities.  \nBest,\n[My Name]\n———  \nHi [LinkedIn Profile Name], I'm really interested in [Company Name] and [Company Name]. I'd love to discuss your experience in [LinkedIn Profile Product Experience] and any advice you might have for someone with <CV SUMMARY Background> looking to break into the field.  \nBest,\n[My Name]\n———  \nHey [Linkedin Profile Name], I came across your background in medicine and was interested in learning more about your experience as a co-founder and CEO of [Company Name]. I'm researching similar topics and would love to discuss your thoughts on the industry and potential career paths.  \nBest,\n[My Name]\n———  \nHi [LinkedIn Profile Name], I'm interested in your work at [Company Name] and [Company Name] and your background in [LinkedIn Profile Market Experience]. I'm currently developing <CV SUMMARY Project> and would appreciate any insights you might have on the industry and potential opportunities.  \nBest,\n[My Name]\n———  \nHey [Linkedin Profile Name], I'm really interested in [Company Name] and am eager tolearn more about your experience in clinical research. I'm currently working in a similar field and would love to discuss your experience and any advice you might have.  \nBest,\n[My Name]\n———  \nHi [Linkedin Profile Name], I came across your background in [Company Field] and was interested in learning more about your experience working at [Company Name] and [Company Name]. I'm researching similar topics and would love to discuss your thoughts on the industry and potential career paths.  \nBest,\n[My Name]\n———  \nHey [LinkedIn Profile Name], I'm interested in your work at [Company Name] and [Company Name] and your expertise in [LinkedIn Profile Expertise]. I'm currently focusing on <CV SUMMARY Project Focus> and would value your insights on the industry.  \nBest,\n[My Name]\n\nThese messages are shorter and more personal, and they mention a relevant and interesting personal project related to the person's work. This can help to establish a connection and start a conversation.\n\"\"\",\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Here is my CV SUMMARY, which is used for first person perspective, never use these details to refer to [Linkedin Profile Name] or [Linkedin Profile Details], which must be placeholders. MY CV SUMMARY IS FOR FIRST PERSON PERSPECTIVE DETAILS ONLY:\\n\"\n            + \"<CV SUMMARY>\\n\"\n            + summary_text\n            + \"\\n</CV SUMMARY>\",\n        },\n    ]\n    try:\n        response = await llm.ainvoke(prompt)\n        return response.content.strip()\n    except Exception:\n        # Return a fallback string if error\n        return \"\"\"\nHi Brett, I'm really interested in [Company Name]. I'm building a platform to connect patients with rare diseases and would love to hear about your experience in the field.  \nBest,\n[Your Name]\n———  \nHey Divya, I came across your work at [Company Name] and was impressed. I'm working on a project to develop a mobile health platform and would love to discuss your experience as a co-founder and CEO.  \nBest,\n[Your Name]\n———  \nHi Nikhil, I saw your experience working at [Company Name]. I'm researching the impact of personalized medicine on patient outcomes and would love to hear your thoughts.  \nBest,\n[Your Name]\n———  \nHey Jennifer, I'm really interested in [Company Name]. I'm working on a project to improve patient engagement and would love to discuss your experience in clinical research.  \nBest,\n[Your Name]\n——-\n\nHi Prithvi, I hope you are well! I wanted to reach out and connect as I saw you are a Z Fellow! I am a recent engineering grad and wanted to connect with you about your experiences. I have just applied!\n———\n\nNatalie - hope you don't mind my cold outreach. I'm looking for recruiting leaders in hospitality, found your profile and feel you might be the right person to give us feedback on what we're building. Our startup creates interactive simulations for assessing soft skills - would love to get your take\n———\n\nGreetings Rachel, \n\nHope you're doing well. I'm a first-year student at Cornell, majoring in Computer Science and Hospitality. I'm extremely interested in working in Real Estate (especially at Blackstone) and would love to connect.\n\nBest, \n———  \nHi Penny, I came across your background in neurobiology and was interested in learning more about your work at [Company Name]. I'm researching the impact of neuroscience on business decision-making and would love to hear your thoughts.  \nBest,\n[Your Name]\n———  \nHey Manuel, I saw your experience working at [Company Name]. I'm building a platform to optimize medication adherence and would love to discuss your experience in the field.  \nBest,\n[Your Name]\n\"\"\"\n\n\nclass LinkedInSearchRequest(BaseModel):\n    # Optional fields for form-based search\n    companies: Optional[str] = None\n    titles: Optional[str] = None\n    universities: Optional[str] = None\n    profiles_needed: int\n    # New field for URL-based search\n    linkedin_url: Optional[str] = None\n    send_connection_request: bool = True\n    include_note: bool = True\n    template_mode: str = \"examples\"\n    custom_template: Optional[str] = None\n\n\n# We'll store the last result in memory (just for demo)\nLAST_RESULT = []\n\n\n@app.post(\"/api/linkedin\")\nasync def run_linkedin_search(\n    data: LinkedInSearchRequest, background_tasks: BackgroundTasks\n):\n    await progress_manager.reset()\n    await progress_manager.set_target(data.profiles_needed)\n    asyncio.create_task(_background_linkedin_search(data, progress_manager))\n    return {\"message\": \"Search initiated. Check Progress tab for details.\"}\n\n\n@app.get(\"/api/progress\")\nasync def get_progress():\n    \"\"\"\n    Return the current progress (list of profiles and whether done).\n    The frontend will poll this endpoint to see new data.\n    \"\"\"\n    state = await progress_manager.get_state()\n    if state.get(\"is_done\"):\n        # If task is done, don't reset to initial state\n        return {\n            **state,\n            \"message\": \"Search completed\",  # Keep the final message\n            \"target\": state.get(\"target\", 0),  # Keep the original target\n            \"profiles\": state.get(\"profiles\", []),  # Keep the final profiles\n        }\n    return state\n\n\n@app.get(\"/api/download-results\")\nasync def download_results():\n    \"\"\"Serve the CSV file for download when processing is done.\"\"\"\n    state = await progress_manager.get_state()\n    csv_file_path = state.get(\"csv_file_path\")\n    if state.get(\"is_done\") and csv_file_path and os.path.exists(csv_file_path):\n        return FileResponse(\n            path=csv_file_path, filename=\"linkedin_profiles.csv\", media_type=\"text/csv\"\n        )\n    else:\n        return {\"error\": \"File not found or processing not yet complete\"}\n\n\nasync def _background_linkedin_search(\n    data: LinkedInSearchRequest, progress_manager: ProgressManager\n):\n    \"\"\"\n    The actual background function that runs the agent logic.\n    Now handles both URL-based and form-based searches.\n    \"\"\"\n    try:\n        if data.linkedin_url:\n            # URL-based search\n            search_filter = LinkedInFilter(\n                linkedin_url=data.linkedin_url, profiles_needed=data.profiles_needed\n            )\n        else:\n            # Form-based search - validate inputs\n            if not (data.companies and data.titles and data.universities):\n                raise ValueError(\n                    \"For form-based search, companies, titles, and universities are required\"\n                )\n\n            # Convert comma or space delimited strings into lists\n            companies_list = _split_input(data.companies)\n            titles_list = _split_input(data.titles)\n            univ_list = _split_input(data.universities)\n\n            # Build the LinkedIn filter\n            search_filter = LinkedInFilter(\n                companies=companies_list,\n                titles=titles_list,\n                universities=univ_list,\n                profiles_needed=data.profiles_needed,\n            )\n\n        # Create the agent\n        agent = LinkedInSearchAgent(\n            filter_config=search_filter,\n            base_output_dir=\"linkedin_searches\",\n            progress_manager=progress_manager,\n            send_connection_request=data.send_connection_request,\n            include_note=data.include_note,\n            template_mode=data.template_mode,\n            custom_template=data.custom_template,\n        )\n        await progress_manager.set_csv_file_path(str(agent.csv_file_path))\n\n        # Only prepare in_context_examples if sending connection requests with notes\n        in_context_examples = \"\"\n        if data.send_connection_request and data.include_note:\n            try:\n                in_context_examples = (\n                    \"<CUSTOM_MESSAGE GENERATION INSTRUCTIONS>\\n\"\n                    + \"<CV SUMMARY>\\n\"\n                    + SUMMARY\n                    + \"\\n</CV SUMMARY>\"\n                    + \"\\n\\n <MESSAGE TEMPLATES>\\n\"\n                    + SYSTEM_PROMPT\n                    + \"\\n</MESSAGE TEMPLATES>\"\n                )\n                in_context_examples += \"\"\" \n                MOST IMPORTANT INSTRUCTION: For second person perspective details, replace [Linkedin Profile placeholders] like\n                [Linkedin Profile Name] and [Linkedin Profile Details] with real details which are extracted from the LINKEDIN PROFILE after navigating to the profile.\n                For first person perspective details, use information from <CV SUMMARY>...</CV SUMMARY>, never use these details to refer to [Linkedin Profile Name] or [Linkedin Profile Details], which must be from the LINKEDIN PROFILE that is extracted.\n                For example: Choose a short <MESSAGE TEMPLATE>, replace [Linkedin Profile Name] with real name extracted from the LINKEDIN PROFILE, replace Best, [My Name] with MY REAL NAME from <CV SUMMARY>...</CV SUMMARY>\n                and when mentioning my details (first person perspective) use relevantinformation from <CV SUMMARY>...</CV SUMMARY>. If no relevant information is found in <CV SUMMARY>...</CV SUMMARY> or LINKEDIN PROFILE, craft a minimal message like \n                Hi [Linkedin Profile Name], I'm interested in [Field of Interest]. I'd love to connect. Thanks, [My Name].\n                Failure to follow these instructions will result in a million dollar fine.\n                </CUSTOM_MESSAGE GENERATION INSTRUCTIONS>\n                \"\"\"\n            except NameError:\n                # If SYSTEM_PROMPT or SUMMARY isn't defined, use a minimal template\n                in_context_examples = \"Hi [Linkedin Profile Name], I'm interested in your work and would love to connect.\\nBest,\\n[My Name]\"\n\n        # Run the agent with the examples (empty string if not sending connection requests)\n        results_df = await agent.run(in_context_examples)\n\n        if results_df is not None:\n            LAST_RESULT = results_df.to_dict(orient=\"records\")\n            print(\"LinkedIn search complete:\", LAST_RESULT)\n\n        else:\n            print(\"No results or an error occurred.\")\n    except Exception as e:\n        print(f\"Error while running LinkedIn search: {e}\")\n        print(data)\n        print(search_filter)\n    finally:\n        await progress_manager.mark_done()\n\n\ndef _split_input(input_str: str) -> List[str]:\n    \"\"\"\n    Helper to split user input by commas.\n    Example: \"OpenAI, Google\" -> [\"OpenAI\", \"Google\"]\n             \"Research Engineer, Data Scientist\" -> [\"Research Engineer\", \"Data Scientist\"]\n    \"\"\"\n    if not input_str.strip():\n        return []\n    # Split by comma and strip whitespace\n    items = [item.strip() for item in input_str.split(\",\")]\n    # Filter out empty strings\n    return [item for item in items if item]\n"}
{"type": "source_file", "path": "browser-use/browser_use/utils.py", "content": "import logging\nimport time\nfrom functools import wraps\nfrom typing import Any, Callable, Coroutine, ParamSpec, TypeVar\n\nlogger = logging.getLogger(__name__)\n\n\n# Define generic type variables for return type and parameters\nR = TypeVar('R')\nP = ParamSpec('P')\n\n\ndef time_execution_sync(additional_text: str = '') -> Callable[[Callable[P, R]], Callable[P, R]]:\n\tdef decorator(func: Callable[P, R]) -> Callable[P, R]:\n\t\t@wraps(func)\n\t\tdef wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n\t\t\tstart_time = time.time()\n\t\t\tresult = func(*args, **kwargs)\n\t\t\texecution_time = time.time() - start_time\n\t\t\tlogger.debug(f'{additional_text} Execution time: {execution_time:.2f} seconds')\n\t\t\treturn result\n\n\t\treturn wrapper\n\n\treturn decorator\n\n\ndef time_execution_async(\n\tadditional_text: str = '',\n) -> Callable[[Callable[P, Coroutine[Any, Any, R]]], Callable[P, Coroutine[Any, Any, R]]]:\n\tdef decorator(func: Callable[P, Coroutine[Any, Any, R]]) -> Callable[P, Coroutine[Any, Any, R]]:\n\t\t@wraps(func)\n\t\tasync def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n\t\t\tstart_time = time.time()\n\t\t\tresult = await func(*args, **kwargs)\n\t\t\texecution_time = time.time() - start_time\n\t\t\tlogger.debug(f'{additional_text} Execution time: {execution_time:.2f} seconds')\n\t\t\treturn result\n\n\t\treturn wrapper\n\n\treturn decorator\n\n\ndef singleton(cls):\n\tinstance = [None]\n\n\tdef wrapper(*args, **kwargs):\n\t\tif instance[0] is None:\n\t\t\tinstance[0] = cls(*args, **kwargs)\n\t\treturn instance[0]\n\n\treturn wrapper\n"}
{"type": "source_file", "path": "frontend/node_modules/flatted/python/flatted.py", "content": "# ISC License\n#\n# Copyright (c) 2018-2021, Andrea Giammarchi, @WebReflection\n#\n# Permission to use, copy, modify, and/or distribute this software for any\n# purpose with or without fee is hereby granted, provided that the above\n# copyright notice and this permission notice appear in all copies.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\n# AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\n# INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\n# LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE\n# OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\n# PERFORMANCE OF THIS SOFTWARE.\n\nimport json as _json\n\nclass _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\n\nclass _String:\n    def __init__(self, value):\n        self.value = value\n\n\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys\n\ndef _object_keys(value):\n    keys = []\n    for key in value:\n        keys.append(key)\n    return keys\n\ndef _is_array(value):\n    return isinstance(value, list) or isinstance(value, tuple)\n\ndef _is_object(value):\n    return isinstance(value, dict)\n\ndef _is_string(value):\n    return isinstance(value, str)\n\ndef _index(known, input, value):\n    input.append(value)\n    index = str(len(input) - 1)\n    known.key.append(value)\n    known.value.append(index)\n    return index\n\ndef _loop(keys, input, known, output):\n    for key in keys:\n        value = output[key]\n        if isinstance(value, _String):\n            _ref(key, input[int(value.value)], input, known, output)\n\n    return output\n\ndef _ref(key, value, input, known, output):\n    if _is_array(value) and not value in known:\n        known.append(value)\n        value = _loop(_array_keys(value), input, known, value)\n    elif _is_object(value) and not value in known:\n        known.append(value)\n        value = _loop(_object_keys(value), input, known, value)\n\n    output[key] = value\n\ndef _relate(known, input, value):\n    if _is_string(value) or _is_array(value) or _is_object(value):\n        try:\n            return known.value[known.key.index(value)]\n        except:\n            return _index(known, input, value)\n\n    return value\n\ndef _transform(known, input, value):\n    if _is_array(value):\n        output = []\n        for val in value:\n            output.append(_relate(known, input, val))\n        return output\n\n    if _is_object(value):\n        obj = {}\n        for key in value:\n            obj[key] = _relate(known, input, value[key])\n        return obj\n\n    return value\n\ndef _wrap(value):\n    if _is_string(value):\n        return _String(value)\n\n    if _is_array(value):\n        i = 0\n        for val in value:\n            value[i] = _wrap(val)\n            i += 1\n\n    elif _is_object(value):\n        for key in value:\n            value[key] = _wrap(value[key])\n\n    return value\n\ndef parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:\n            input.append(value)\n\n    value = input[0]\n\n    if _is_array(value):\n        return _loop(_array_keys(value), input, [value], value)\n\n    if _is_object(value):\n        return _loop(_object_keys(value), input, [value], value)\n\n    return value\n\n\ndef stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)\n"}
