{"repo_info": {"repo_name": "lps", "repo_owner": "jw9730", "repo_url": "https://github.com/jw9730/lps"}}
{"type": "source_file", "path": "src/data/__init__.py", "content": "from .data import DatasetBuilder, setup_symmetry\n"}
{"type": "source_file", "path": "src/data/compute_frames.py", "content": "from tqdm import tqdm\nimport numpy as np\nimport torch\nimport torch_geometric\n\n\ndef load_graphs(filepath): \n    data_obj, dict_slice = torch.load(filepath)\n\n    if 'pos' in dict_slice:\n        slice_node = dict_slice['pos']\n    else:\n        slice_node = dict_slice['x']\n    slice_edge_index = dict_slice['edge_index']\n    num_node = (slice_node[1:] - slice_node[:-1]).tolist()\n    num_edge_index = (slice_edge_index[1:] - slice_edge_index[:-1]).tolist()\n\n    assert sum(num_edge_index) == data_obj.edge_index.shape[1]\n\n    list_edge_index = torch.split(data_obj.edge_index, num_edge_index, dim=1)\n    assert len(num_node) == len(list_edge_index)\n\n    dict_graphs = {\"Ns\": num_node, \"edge_indexs\": list_edge_index, \"slice_node\": slice_node}\n    return dict_graphs\n\n\ndef sort_fn_laplacian(N, edge_index):\n    # N: number of nodes\n    # construct laplacian\n    L_e, L_w = torch_geometric.utils.get_laplacian(edge_index)\n    L = np.zeros((N,N),dtype=np.float32)\n    L[L_e[0],L_e[1]]=L_w\n\n    # compute eigen decomposition of Laplacian, evals are returned in ascending order\n    evals, evecs = np.linalg.eigh(L)\n\n    # ----- create sorting criterion -----\n    unique_vals, evals_idx, evals_mult = np.unique(evals, return_counts=True, return_index=True) # get eigenvals multiplicity\n\n    chosen_evecs = []\n    len_evals_idx = len(evals_idx)\n    for ii in range(len_evals_idx):\n        if evals_mult[ii] == 1:\n            chosen_evecs.append(np.abs(evecs[:,evals_idx[ii]]))\n        else:\n            eigen_space_start_idx = evals_idx[ii]\n            eigen_space_size = evals_mult[ii]\n            eig_space_basis = evecs[:, eigen_space_start_idx:(eigen_space_start_idx+eigen_space_size)] # (52, 2)\n            chosen_evecs.append(np.sqrt((eig_space_basis ** 2).sum(1))) # (52,)\n    chosen_evecs = np.stack(chosen_evecs, axis=1).round(decimals=2)  # (52, 37), it's the matrix S(X) in section 3.2\n    sort_idx = np.lexsort([col for col in chosen_evecs.transpose()[::-1]]) # consider regular sort, there are 37 elements in this list\n    return sort_idx, chosen_evecs\n\ndef compute_frame(N, edge_index):\n    \"\"\"\n    N: number of nodes\n    edge_index: [2, 4884]\n    edge_index = tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, ...],\n                         [ 6,  9, 11, 12, 13, 16, 27, 35, 37, 43, ...]])\"\"\"\n    e = edge_index.shape[1]\n    sort_idx, to_sort = sort_fn_laplacian(N, edge_index) # to_sort is S(X) in section 3.2 \n    # sort_idx = [ 96  40  65  55   2 ... 73   0  11]\n    sorted_x = to_sort[sort_idx,:]\n    unique_rows, dup_rows_idx, dup_rows_mult = np.unique(sorted_x, axis=0, return_index=True, return_counts=True) # return unique elements in sorted order\n    # dup_rows_idx =  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 22 23 25 27 28 34 46]\n    # dup_rows_mult =  [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  1  2  1  2  2  1 6 12  6]\n    \n    perm_idx = torch.repeat_interleave(torch.tensor(dup_rows_idx), torch.tensor(dup_rows_mult)) \n    # perm_idx =  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 16, 18, 19, 20, 20, 22, 23, 23, 25, 25, 27, 28, 28, 28, 28, 28, 28, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 46, 46, 46, 46, 46, 46])\n    # create binary mask perm \n    mask_perm = dup_rows_mult != 1 \n    mask_perm = torch.from_numpy(mask_perm)\n    mask_perm = torch.repeat_interleave(mask_perm, torch.tensor(dup_rows_mult))\n    sort_idx = torch.tensor(sort_idx)\n    \n    return sort_idx, perm_idx, mask_perm\n\n\ndef compute_all_frames(data_filepath):\n    dict_graphs = load_graphs(data_filepath)\n    num_graphs = len(dict_graphs[\"Ns\"])\n    list_sort_idx = []\n    list_perm_idx = []\n    list_mask_perm = []\n    for i in tqdm(range(num_graphs)): \n        N = dict_graphs[\"Ns\"][i]\n        edge_index = dict_graphs[\"edge_indexs\"][i]\n        sort_idx, perm_idx, mask_perm = compute_frame(N, edge_index)\n        list_sort_idx.append(sort_idx)\n        list_perm_idx.append(perm_idx)\n        list_mask_perm.append(mask_perm)\n\n    sort_idxs = torch.cat(list_sort_idx, dim=0)\n    perm_idxs = torch.cat(list_perm_idx, dim=0)\n    mask_perms = torch.cat(list_mask_perm, dim=0)\n\n    slice_sort_idxs = dict_graphs[\"slice_node\"].clone()\n    slice_perm_idxs = dict_graphs[\"slice_node\"].clone()\n    slice_mask_perms = dict_graphs[\"slice_node\"].clone()\n\n    frame_data = {\n        \"sort_idxs\": sort_idxs,\n        \"perm_idxs\": perm_idxs,\n        \"mask_perms\": mask_perms,\n        \"slice\": {\n            \"sort_idxs\": slice_sort_idxs,\n            \"perm_idxs\": slice_perm_idxs,\n            \"mask_perms\": slice_mask_perms\n        }\n    }\n    return frame_data\n"}
{"type": "source_file", "path": "src/data/graph_classification_peptides_func.py", "content": "# pylint: disable=protected-access,too-many-locals,unused-argument,line-too-long,too-many-instance-attributes,too-many-arguments,not-callable\nfrom typing import Tuple, Dict\nfrom functools import partial\nimport warnings\nimport torch\nfrom torch import nn\nfrom torch.nn.functional import one_hot\nfrom torch_geometric.data import Data\nfrom torchmetrics.functional.classification import multilabel_average_precision, binary_average_precision\n\nfrom src.symmetry import Symmetry\nfrom src.symmetry.groups.S import samples_from_haar_distribution\nfrom src.symmetry.frame.S import samples_from_frame\nfrom src.symmetry.prob.S import EquivariantInterface\n\n\nT = torch.Tensor\n\nNODE_NUM_CLASSES = [17, 3, 7, 7, 5, 1, 6, 2, 2]\nEDGE_NUM_CLASSES = [4, 1, 2]\n\n\nclass GraphClassificationPeptidesfunc(Symmetry):\n    def __init__(self, config):\n        super().__init__()\n        self.group_name = 'S'\n        self.rep_dim = 444\n        self.rep_in = {1: sum(NODE_NUM_CLASSES), 2: 1 + sum(EDGE_NUM_CLASSES)}\n        self.rep_out = {0: 10}\n        self.metric_name = 'average-precision'\n        if config.interface == 'prob':\n            self.entropy_loss_scale = config.entropy_loss_scale\n            self.interface = partial(\n                EquivariantInterface,\n                noise_scale=config.noise_scale,\n                tau=config.tau,\n                hard=config.hard,\n                rep_dim=self.rep_dim,\n                node_rep_channels=self.rep_in[1],\n                interface_num_layers=config.interface_num_layers,\n                interface_hidden_dim=config.interface_hidden_dim,\n                interface_dropout=config.interface_dropout\n            )\n\n    def process_input(self, batch: Data) -> Tuple[T, T]:\n        device = batch.x.device\n        batch_size = batch.num_graphs\n        node_ptr = batch._slice_dict['x'].to(device)\n        edge_ptr = batch._slice_dict['edge_index'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        num_edges = edge_ptr[1:] - edge_ptr[:-1]\n        n = self.rep_dim\n        # convert node and edge classes to one-hot vectors\n        node_attr_one_hot = torch.cat([one_hot(x, num_classes=NODE_NUM_CLASSES[idx]) for idx, x in enumerate(batch.x.unbind(-1))], dim=-1).float()\n        edge_attr_one_hot = torch.cat([one_hot(x, num_classes=EDGE_NUM_CLASSES[idx]) for idx, x in enumerate(batch.edge_attr.unbind(-1))], dim=-1).float()\n        # parse node features (B, N, C)\n        tri = torch.tril(torch.ones(n, n, device=device, dtype=torch.bool))\n        node_mask = tri[num_nodes - 1]\n        node_features = torch.zeros(batch_size, n, self.rep_in[1], device=device, dtype=torch.float)\n        node_features[node_mask] = node_attr_one_hot\n        # parse edge features (B, N, N, C)\n        edge_features = torch.zeros(batch_size, n, n, self.rep_in[2], device=device, dtype=torch.float)\n        edge_batch_index = torch.arange(batch_size, device=device).repeat_interleave(num_edges)\n        edge_index_offset = node_ptr[:-1].repeat_interleave(num_edges)\n        edge_index = batch.edge_index - edge_index_offset[None, :]\n        edge_features[edge_batch_index, edge_index[0], edge_index[1], 0] = 1.\n        edge_features[edge_batch_index, edge_index[0], edge_index[1], 1:] = edge_attr_one_hot\n        # return features\n        xs = (node_features, edge_features)\n        return xs\n\n    def process_output(self, xs: Tuple[T], batch: Data) -> torch.Tensor:\n        graph_output = xs[0]\n        return graph_output\n\n    def samples_from_haar_distribution(self, xs: Tuple[T, T], batch: Data) -> torch.Tensor:\n        n, bsize, device, dtype = self.rep_dim, xs[0].size(0), xs[0].device, xs[0].dtype\n        node_ptr = batch._slice_dict['x'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        return samples_from_haar_distribution(num_nodes, n, bsize, device, dtype)\n\n    def samples_from_frame(self, xs: Tuple[T, T], batch: Data, n_samples: int) -> torch.Tensor:\n        n = self.rep_dim\n        gs = samples_from_frame(n, xs, batch, n_samples)\n        return gs\n\n    def samples_from_prob(self, prob_interface_net: nn.Module, xs: Tuple[T, T], batch: Data, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        gs, entropy_loss = prob_interface_net(xs, batch, n_samples)\n        loss_dict['entropy'] = {'weight': self.entropy_loss_scale, 'value': entropy_loss}\n        return gs, loss_dict\n\n    def transform_input(self, xs: Tuple[T, T], gs: torch.Tensor) -> Tuple[T, T]:\n        node_features, edge_features = xs\n        # leverage orthogonality of permutation matrices\n        # gs_inv = torch.linalg.inv(gs)\n        gs_inv = gs.transpose(1, 2)\n        node_features = gs_inv @ node_features\n        edge_features = torch.einsum('bij,bjkd,blk->bild', gs_inv, edge_features, gs_inv)\n        xs = (node_features, edge_features)\n        return xs\n\n    def transform_output(self, xs: Tuple[T], gs: torch.Tensor) -> Tuple[T]:\n        graph_output = xs[0]\n        xs = (graph_output,)\n        return xs\n\n    def criterion(self, y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n        \"\"\"Implementation from LRGB:\n        https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/loss/multilabel_classification_loss.py\n        \"\"\"\n        is_labeled = torch.eq(y, y)\n        return torch.nn.functional.binary_cross_entropy_with_logits(y_hat[is_labeled], y[is_labeled].to(y_hat.dtype))\n\n    def evaluator(self, y_hat: list, y: list) -> dict:\n        \"\"\"Implementation from LRGB:\n        https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/metric_wrapper.py\n        https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/logger.py\n        https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/metrics_ogb.py\n        \"\"\"\n        preds, target = torch.cat(y_hat, dim=0), torch.cat(y, dim=0)\n        # torchmetrics expects probability preds and long targets\n        preds = torch.sigmoid(preds)\n        target = target.long()\n        # compute metrics\n        determinism = torch.are_deterministic_algorithms_enabled()\n        torch.use_deterministic_algorithms(False)\n        if torch.isnan(target).any():\n            warnings.warn(\"NaNs in targets, falling back to slow evaluation.\")\n            # Compute the metric for each column, and output nan if there's an error on a given column\n            target_nans = torch.isnan(target)\n            target_list = [target[..., ii][~target_nans[..., ii]] for ii in range(target.shape[-1])]\n            preds_list = [preds[..., ii][~target_nans[..., ii]] for ii in range(preds.shape[-1])]\n            target = target_list\n            preds = preds_list\n            metric_val = []\n            for p, t in zip(preds, target):\n                # below is tested to be equivalent with OGB metric\n                # https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/metrics_ogb.py\n                res = binary_average_precision(p, t)\n                metric_val.append(res)\n            # Average the metric\n            # PyTorch 1.10\n            metric_val = torch.nanmean(torch.stack(metric_val))\n            # PyTorch <= 1.9\n            # x = torch.stack(metric_val)\n            # metric_val = torch.div(torch.nansum(x), (~torch.isnan(x)).count_nonzero())\n        else:\n            # below is tested to be equivalent with OGB metric\n            # https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/metrics_ogb.py\n            metric_val = multilabel_average_precision(preds, target, num_labels=self.rep_out[0])\n        torch.use_deterministic_algorithms(determinism)\n        return {\n            'metric_sum': metric_val,\n            'metric_count': 1,\n        }\n"}
{"type": "source_file", "path": "src/data/data.py", "content": "# pylint: disable=too-many-return-statements,too-many-branches,line-too-long\nfrom functools import partial\nfrom pathlib import Path\nimport pickle\nfrom torch.utils.data import Dataset\nimport torch_geometric.datasets\n\nfrom .node_classification_pattern import NodeClassificationPATTERN\nfrom .graph_classification_peptides_func import GraphClassificationPeptidesfunc\nfrom .graph_regression_peptides_struct import GraphRegressionPeptidesstruct\nfrom .link_prediction_pcqm_contact import LinkPredictionPCQMContact\n\nfrom .compute_frames import compute_all_frames\n\n\ndef setup_symmetry(dataset: str, config):\n    if dataset == \"gnn_benchmark/pattern\":\n        return NodeClassificationPATTERN(config)\n    if dataset == \"lrgb/pcqm_contact\":\n        return LinkPredictionPCQMContact(config)\n    if dataset == \"lrgb/peptides_func\":\n        return GraphClassificationPeptidesfunc(config)\n    if dataset == \"lrgb/peptides_struct\":\n        return GraphRegressionPeptidesstruct(config)\n    raise NotImplementedError(f\"Dataset ({dataset}) not supported!\")\n\n\nclass DatasetBuilder():\n    \"\"\"Dataset configuration class\"\"\"\n    def __init__(\n            self,\n            dataset: str,\n            root_dir: str,\n            compute_frames: bool\n        ):\n        self.root_dir = root_dir\n        self.compute_frames = compute_frames\n        # pyg datasets\n        self.is_pyg_dataset = True\n        if dataset == \"gnn_benchmark/pattern\":\n            self.ds_builder = partial(torch_geometric.datasets.GNNBenchmarkDataset, name=\"PATTERN\")\n        elif dataset == \"lrgb/pcqm_contact\":\n            self.ds_builder = partial(torch_geometric.datasets.LRGBDataset, name=\"PCQM-Contact\")\n        elif dataset == \"lrgb/peptides_func\":\n            self.ds_builder = partial(torch_geometric.datasets.LRGBDataset, name=\"Peptides-func\")\n        elif dataset == \"lrgb/peptides_struct\":\n            self.ds_builder = partial(torch_geometric.datasets.LRGBDataset, name=\"Peptides-struct\")\n        else:\n            # non-pyg datasets\n            self.is_pyg_dataset = False\n            raise NotImplementedError(f\"Dataset ({dataset}) not supported!\")\n\n    def setup_frames(self, data_name, split):\n        assert split in ['train', 'val', 'test']\n        frame_filepath = Path(self.root_dir) / data_name / f\"processed/{split}_frame.pickle\"\n        if not frame_filepath.exists():\n            print(f\"Computing frames for the {split} dataset at {frame_filepath}...\")\n            data_filepath = Path(self.root_dir) / data_name / f\"processed/{split}_data.pt\"\n            if not data_filepath.exists():\n                data_filepath = Path(self.root_dir) / data_name / f\"processed/{split}.pt\"\n            assert data_filepath.exists()\n            frame_data = compute_all_frames(data_filepath)\n            with open(frame_filepath, \"wb\") as f:\n                pickle.dump(frame_data, f)\n\n    def prepare_data(self):\n        if self.is_pyg_dataset:\n            ds_builder = self.ds_builder(self.root_dir)\n            if self.compute_frames:\n                data_name = getattr(ds_builder, 'name')\n                self.setup_frames(data_name, 'train')\n                self.setup_frames(data_name, 'val')\n                self.setup_frames(data_name, 'test')\n                print(\"Done!\")\n        else:\n            raise NotImplementedError\n\n    def load_frames(self, ds_builder, data_name, split):\n        frame_filepath = Path(self.root_dir) / data_name / f\"processed/{split}_frame.pickle\"\n        with open(frame_filepath, \"rb\") as f:\n            frame_dict = pickle.load(f)\n        sort_idxs = frame_dict[\"sort_idxs\"]\n        perm_idxs = frame_dict[\"perm_idxs\"]\n        mask_perms = frame_dict[\"mask_perms\"]\n        slice_sort_idxs = frame_dict[\"slice\"][\"sort_idxs\"]\n        slice_perm_idxs = frame_dict[\"slice\"][\"perm_idxs\"]\n        slice_mask_perms = frame_dict[\"slice\"][\"mask_perms\"]\n        _data = getattr(ds_builder, \"_data\")\n        slices = getattr(ds_builder, \"slices\")\n        _data.sort_idx = sort_idxs\n        _data.perm_idx = perm_idxs\n        _data.mask_perm = mask_perms\n        slices[\"sort_idx\"] = slice_sort_idxs\n        slices[\"perm_idx\"] = slice_perm_idxs\n        slices[\"mask_perm\"] = slice_mask_perms\n        return ds_builder\n\n    def train_dataset(self) -> Dataset:\n        if self.is_pyg_dataset:\n            ds_builder = self.ds_builder(self.root_dir, split='train')\n            data_name = getattr(ds_builder, \"name\")\n            if self.compute_frames:\n                ds_builder = self.load_frames(ds_builder, data_name, 'train')\n            return ds_builder\n        raise NotImplementedError\n\n    def val_dataset(self) -> Dataset:\n        if self.is_pyg_dataset:\n            ds_builder = self.ds_builder(self.root_dir, split='val')\n            data_name = getattr(ds_builder, \"name\")\n            if self.compute_frames:\n                ds_builder = self.load_frames(ds_builder, data_name, 'val')\n            return ds_builder\n        raise NotImplementedError\n\n    def test_dataset(self)  -> Dataset:\n        if self.is_pyg_dataset:\n            ds_builder = self.ds_builder(self.root_dir, split='test')\n            data_name = getattr(ds_builder, \"name\")\n            if self.compute_frames:\n                ds_builder = self.load_frames(ds_builder, data_name, 'test')\n            return ds_builder\n        raise NotImplementedError\n\n    def predict_dataset(self) -> Dataset:\n        if self.is_pyg_dataset:\n            return NotImplemented\n        raise NotImplementedError\n"}
{"type": "source_file", "path": "src/data/link_prediction_pcqm_contact.py", "content": "# pylint: disable=protected-access,too-many-locals,unused-argument,line-too-long,too-many-instance-attributes,too-many-arguments,not-callable\nfrom typing import Tuple, Dict\nfrom functools import partial\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn.functional import one_hot\nfrom torch_geometric.data import Data\n\nfrom src.symmetry import Symmetry\nfrom src.symmetry.groups.S import samples_from_haar_distribution\nfrom src.symmetry.frame.S import samples_from_frame\nfrom src.symmetry.prob.S import EquivariantInterface\n\n\nT = torch.Tensor\n\nNODE_NUM_CLASSES = [35,  3,  7,  7,  2,  4,  6,  2,  2]\nEDGE_NUM_CLASSES = [4, 1, 1]\n\n\nclass LinkPredictionPCQMContact(Symmetry):\n    def __init__(self, config):\n        super().__init__()\n        self.group_name = 'S'\n        self.rep_dim = 53\n        self.rep_in = {1: sum(NODE_NUM_CLASSES), 2: 1 + sum(EDGE_NUM_CLASSES)}\n        self.rep_out = {2: 1}\n        self.metric_name = ['hits@1', 'hits@3', 'hits@10', 'mrr', 'mrr_filtered', 'mrr_filtered_noself']\n        if config.interface == 'prob':\n            self.entropy_loss_scale = config.entropy_loss_scale\n            self.interface = partial(\n                EquivariantInterface,\n                noise_scale=config.noise_scale,\n                tau=config.tau,\n                hard=config.hard,\n                rep_dim=self.rep_dim,\n                node_rep_channels=self.rep_in[1],\n                interface_num_layers=config.interface_num_layers,\n                interface_hidden_dim=config.interface_hidden_dim,\n                interface_dropout=config.interface_dropout\n            )\n\n    def process_input(self, batch: Data) -> Tuple[T, T]:\n        device = batch.x.device\n        batch_size = batch.num_graphs\n        node_ptr = batch._slice_dict['x'].to(device)\n        edge_ptr = batch._slice_dict['edge_index'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        num_edges = edge_ptr[1:] - edge_ptr[:-1]\n        n = self.rep_dim\n        # convert node and edge classes to one-hot vectors\n        node_attr_one_hot = torch.cat([one_hot(x, num_classes=NODE_NUM_CLASSES[idx]) for idx, x in enumerate(batch.x.unbind(-1))], dim=-1).float()\n        edge_attr_one_hot = torch.cat([one_hot(x, num_classes=EDGE_NUM_CLASSES[idx]) for idx, x in enumerate(batch.edge_attr.unbind(-1))], dim=-1).float()\n        # parse node features (B, N, C)\n        tri = torch.tril(torch.ones(n, n, device=device, dtype=torch.bool))\n        node_mask = tri[num_nodes - 1]\n        node_features = torch.zeros(batch_size, n, self.rep_in[1], device=device, dtype=torch.float)\n        node_features[node_mask] = node_attr_one_hot\n        # parse edge features (B, N, N, C)\n        edge_features = torch.zeros(batch_size, n, n, self.rep_in[2], device=device, dtype=torch.float)\n        edge_batch_index = torch.arange(batch_size, device=device).repeat_interleave(num_edges)\n        edge_index_offset = node_ptr[:-1].repeat_interleave(num_edges)\n        edge_index = batch.edge_index - edge_index_offset[None, :]\n        edge_features[edge_batch_index, edge_index[0], edge_index[1], 0] = 1.\n        edge_features[edge_batch_index, edge_index[0], edge_index[1], 1:] = edge_attr_one_hot\n        # return features\n        xs = (node_features, edge_features)\n        return xs\n\n    def process_output(self, xs: Tuple[T], batch: Data) -> torch.Tensor:\n        edge_output = xs[0]\n        # (B, N, N, 1) -> (B, N, N)\n        return edge_output[..., 0]\n\n    def samples_from_haar_distribution(self, xs: Tuple[T, T], batch: Data) -> torch.Tensor:\n        n, bsize, device, dtype = self.rep_dim, xs[0].size(0), xs[0].device, xs[0].dtype\n        node_ptr = batch._slice_dict['x'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        return samples_from_haar_distribution(num_nodes, n, bsize, device, dtype)\n\n    def samples_from_frame(self, xs: Tuple[T, T], batch: Data, n_samples: int) -> torch.Tensor:\n        n = self.rep_dim\n        gs = samples_from_frame(n, xs, batch, n_samples)\n        return gs\n\n    def samples_from_prob(self, prob_interface_net: nn.Module, xs: Tuple[T, T], batch: Data, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        gs, entropy_loss = prob_interface_net(xs, batch, n_samples)\n        loss_dict['entropy'] = {'weight': self.entropy_loss_scale, 'value': entropy_loss}\n        return gs, loss_dict\n\n    def transform_input(self, xs: Tuple[T, T], gs: torch.Tensor) -> Tuple[T, T]:\n        node_features, edge_features = xs\n        # leverage orthogonality of permutation matrices\n        # gs_inv = torch.linalg.inv(gs)\n        gs_inv = gs.transpose(1, 2)\n        node_features = gs_inv @ node_features\n        edge_features = torch.einsum('bij,bjkd,blk->bild', gs_inv, edge_features, gs_inv)\n        xs = (node_features, edge_features)\n        return xs\n\n    def transform_output(self, xs: Tuple[T], gs: torch.Tensor) -> Tuple[T]:\n        edge_output = xs[0]\n        edge_output = torch.einsum('bij,bjkd,blk->bild', gs, edge_output, gs)\n        xs = (edge_output,)\n        return xs\n\n    def criterion(self, y_hat: torch.Tensor, y: Data) -> torch.Tensor:\n        # parse inputs\n        batch = y\n        y = batch.edge_label.float()\n        device = batch.x.device\n        batch_size = batch.num_graphs\n        node_ptr = batch._slice_dict['x'].to(device)\n        edge_ptr = batch._slice_dict['edge_label_index'].to(device)\n        num_edges = edge_ptr[1:] - edge_ptr[:-1]\n        # (B, N, N) -> (sum(Ei),)\n        edge_batch_index = torch.arange(batch_size, device=device).repeat_interleave(num_edges)\n        edge_index_offset = node_ptr[:-1].repeat_interleave(num_edges)\n        edge_index = batch.edge_label_index - edge_index_offset[None, :]\n        y_hat = y_hat[edge_batch_index, edge_index[0], edge_index[1]]\n        return nn.BCEWithLogitsLoss()(y_hat, y)\n\n    @torch.no_grad()\n    def _eval_mrr(self, y_pred_pos, y_pred_neg, suffix='') -> dict:\n        \"\"\" Compute Hits@k and Mean Reciprocal Rank (MRR).\n        Implementation from OGB:\n        https://github.com/snap-stanford/ogb/blob/master/ogb/linkproppred/evaluate.py\n        Args:\n            y_pred_neg: array with shape (batch size, num_entities_neg).\n            y_pred_pos: array with shape (batch size, )\n        \"\"\"\n        assert y_pred_pos.ndim == 1 and y_pred_neg.ndim == 2\n        assert y_pred_pos.shape[0] == y_pred_neg.shape[0]\n        y_pred = torch.cat([y_pred_pos.view(-1, 1), y_pred_neg], dim=1)\n        argsort = torch.argsort(y_pred, dim=1, descending=True)\n        ranking_list = torch.nonzero(argsort == 0, as_tuple=False)\n        ranking_list = ranking_list[:, 1] + 1\n        hits1_list = (ranking_list <= 1).to(torch.float)\n        hits3_list = (ranking_list <= 3).to(torch.float)\n        hits10_list = (ranking_list <= 10).to(torch.float)\n        mrr_list = 1. / ranking_list.to(torch.float)\n        return {\n            f'hits@1{suffix}': hits1_list,\n            f'hits@3{suffix}': hits3_list,\n            f'hits@10{suffix}': hits10_list,\n            f'mrr{suffix}': mrr_list\n        }\n\n    @torch.no_grad()\n    def _eval(self, pred, data) -> dict:\n        pred = pred[:data.num_nodes, :data.num_nodes]\n        pos_edge_index = data.edge_label_index[:, data.edge_label == 1]\n        num_pos_edges = pos_edge_index.shape[1]\n        pred_pos = pred[pos_edge_index[0], pos_edge_index[1]]\n        if num_pos_edges > 0:\n            # raw MRR\n            neg_mask = torch.ones([num_pos_edges, data.num_nodes], dtype=torch.bool)\n            neg_mask[torch.arange(num_pos_edges), pos_edge_index[1]] = False\n            pred_neg = pred[pos_edge_index[0]][neg_mask].view(num_pos_edges, -1)\n            mrr_list = self._eval_mrr(pred_pos, pred_neg, suffix='')\n\n            # filtered MRR\n            pred_masked = pred.clone()\n            pred_masked[pos_edge_index[0], pos_edge_index[1]] -= float(\"inf\")\n            pred_neg = pred_masked[pos_edge_index[0]]\n            mrr_list.update(self._eval_mrr(pred_pos, pred_neg, suffix='_filtered'))\n\n            # extended filter without self-loops\n            pred_masked.fill_diagonal_(-float(\"inf\"))\n            pred_neg = pred_masked[pos_edge_index[0]]\n            mrr_list.update(self._eval_mrr(pred_pos, pred_neg, suffix='_filtered_noself'))\n        else:\n            mrr_list = self._eval_mrr(pred_pos, pred_pos)\n        return mrr_list\n\n    @torch.no_grad()\n    def evaluator(self, y_hat: list, y: list) -> dict:\n        \"\"\" Compute Hits@k and Mean Reciprocal Rank (MRR).\n        Implementation from LRGB:\n        https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/head/inductive_edge.py\n        \"\"\"\n        y_hat = torch.cat(y_hat, dim=0)\n        data_list = []\n        for batch in y:\n            data_list.extend(batch.to_data_list())\n\n        stats = {}\n        for pred, data in zip(y_hat, data_list):\n            mrr_list = self._eval(pred, data)\n            for key, val in mrr_list.items():\n                val = float(val.mean().item())\n                if np.isnan(val):\n                    val = 0.\n                if key not in stats:\n                    stats[key] = [val]\n                else:\n                    stats[key].append(val)\n\n        batch_stats = {}\n        for key, val in stats.items():\n            batch_stats[key] = {\n                'metric_sum': sum(val),\n                'metric_count': len(val)\n            }\n        return batch_stats\n"}
{"type": "source_file", "path": "src/data/graph_regression_peptides_struct.py", "content": "# pylint: disable=protected-access,too-many-locals,unused-argument,line-too-long,too-many-instance-attributes,too-many-arguments,not-callable\nfrom typing import Tuple, Dict\nfrom functools import partial\nimport torch\nfrom torch import nn\nfrom torch.nn.functional import one_hot\nfrom torch_geometric.data import Data\nfrom torchmetrics.functional import mean_absolute_error\nfrom sklearn.metrics import r2_score\n\nfrom src.symmetry import Symmetry\nfrom src.symmetry.groups.S import samples_from_haar_distribution\nfrom src.symmetry.frame.S import samples_from_frame\nfrom src.symmetry.prob.S import EquivariantInterface\n\n\nT = torch.Tensor\n\nNODE_NUM_CLASSES = [17, 3, 7, 7, 5, 1, 6, 2, 2]\nEDGE_NUM_CLASSES = [4, 1, 2]\n\n\nclass GraphRegressionPeptidesstruct(Symmetry):\n    def __init__(self, config):\n        super().__init__()\n        self.group_name = 'S'\n        self.rep_dim = 444\n        self.rep_in = {1: sum(NODE_NUM_CLASSES), 2: 1 + sum(EDGE_NUM_CLASSES)}\n        self.rep_out = {0: 11}\n        self.metric_name = ['mae', 'r2']\n        if config.interface == 'prob':\n            self.entropy_loss_scale = config.entropy_loss_scale\n            self.interface = partial(\n                EquivariantInterface,\n                noise_scale=config.noise_scale,\n                tau=config.tau,\n                hard=config.hard,\n                rep_dim=self.rep_dim,\n                node_rep_channels=self.rep_in[1],\n                interface_num_layers=config.interface_num_layers,\n                interface_hidden_dim=config.interface_hidden_dim,\n                interface_dropout=config.interface_dropout\n            )\n\n    def process_input(self, batch: Data) -> Tuple[T, T]:\n        device = batch.x.device\n        batch_size = batch.num_graphs\n        node_ptr = batch._slice_dict['x'].to(device)\n        edge_ptr = batch._slice_dict['edge_index'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        num_edges = edge_ptr[1:] - edge_ptr[:-1]\n        n = self.rep_dim\n        # convert node and edge classes to one-hot vectors\n        node_attr_one_hot = torch.cat([one_hot(x, num_classes=NODE_NUM_CLASSES[idx]) for idx, x in enumerate(batch.x.unbind(-1))], dim=-1).float()\n        edge_attr_one_hot = torch.cat([one_hot(x, num_classes=EDGE_NUM_CLASSES[idx]) for idx, x in enumerate(batch.edge_attr.unbind(-1))], dim=-1).float()\n        # parse node features (B, N, C)\n        tri = torch.tril(torch.ones(n, n, device=device, dtype=torch.bool))\n        node_mask = tri[num_nodes - 1]\n        node_features = torch.zeros(batch_size, n, self.rep_in[1], device=device, dtype=torch.float)\n        node_features[node_mask] = node_attr_one_hot\n        # parse edge features (B, N, N, C)\n        edge_features = torch.zeros(batch_size, n, n, self.rep_in[2], device=device, dtype=torch.float)\n        edge_batch_index = torch.arange(batch_size, device=device).repeat_interleave(num_edges)\n        edge_index_offset = node_ptr[:-1].repeat_interleave(num_edges)\n        edge_index = batch.edge_index - edge_index_offset[None, :]\n        edge_features[edge_batch_index, edge_index[0], edge_index[1], 0] = 1.\n        edge_features[edge_batch_index, edge_index[0], edge_index[1], 1:] = edge_attr_one_hot\n        # return features\n        xs = (node_features, edge_features)\n        return xs\n\n    def process_output(self, xs: Tuple[T], batch: Data) -> torch.Tensor:\n        graph_output = xs[0]\n        return graph_output\n\n    def samples_from_haar_distribution(self, xs: Tuple[T, T], batch: Data) -> torch.Tensor:\n        n, bsize, device, dtype = self.rep_dim, xs[0].size(0), xs[0].device, xs[0].dtype\n        node_ptr = batch._slice_dict['x'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        return samples_from_haar_distribution(num_nodes, n, bsize, device, dtype)\n\n    def samples_from_frame(self, xs: Tuple[T, T], batch: Data, n_samples: int) -> torch.Tensor:\n        n = self.rep_dim\n        gs = samples_from_frame(n, xs, batch, n_samples)\n        return gs\n\n    def samples_from_prob(self, prob_interface_net: nn.Module, xs: Tuple[T, T], batch: Data, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        gs, entropy_loss = prob_interface_net(xs, batch, n_samples)\n        loss_dict['entropy'] = {'weight': self.entropy_loss_scale, 'value': entropy_loss}\n        return gs, loss_dict\n\n    def calculate_entropy_prob(self, prob_entropy_net: nn.Module, prob_interface_net: nn.Module, xs: Tuple[T, T], batch):\n        entropy_loss = prob_entropy_net(prob_interface_net, xs, batch)\n        return entropy_loss\n\n    def transform_input(self, xs: Tuple[T, T], gs: torch.Tensor) -> Tuple[T, T]:\n        node_features, edge_features = xs\n        # leverage orthogonality of permutation matrices\n        # gs_inv = torch.linalg.inv(gs)\n        gs_inv = gs.transpose(1, 2)\n        node_features = gs_inv @ node_features\n        edge_features = torch.einsum('bij,bjkd,blk->bild', gs_inv, edge_features, gs_inv)\n        xs = (node_features, edge_features)\n        return xs\n\n    def transform_output(self, xs: Tuple[T], gs: torch.Tensor) -> Tuple[T]:\n        graph_output = xs[0]\n        xs = (graph_output,)\n        return xs\n\n    def criterion(self, y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n        \"\"\"Implementation from LRGB:\n        https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/loss/l1.py\n        \"\"\"\n        return nn.L1Loss()(y_hat, y)\n\n    def evaluator(self, y_hat: list, y: list) -> dict:\n        \"\"\"Implementation from LRGB:\n        https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/logger.py\n        \"\"\"\n        y_hat, y = torch.cat(y_hat, dim=0), torch.cat(y, dim=0)\n        batch_size = y.size(0)\n        mae_val = mean_absolute_error(y, y_hat)\n        # caution: torchmetric and sklearn r2_score give different values\n        # official LRGB implementation uses sklearn\n        r2_score_val = r2_score(y.cpu().detach().numpy(), y_hat.cpu().detach().numpy(), multioutput='uniform_average')\n        return {\n            'mae': {\n                'metric_sum': mae_val * batch_size,\n                'metric_count': batch_size\n            },\n            'r2': {\n                'metric_sum': r2_score_val * batch_size,\n                'metric_count': batch_size\n            }\n        }\n"}
{"type": "source_file", "path": "src/data/node_classification_pattern.py", "content": "# pylint: disable=protected-access,too-many-locals,unused-argument,line-too-long,too-many-instance-attributes,too-many-arguments\nfrom typing import Tuple, Dict\nfrom functools import partial\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport torch\nfrom torch import nn\nfrom torch_geometric.data import Data\n\nfrom src.symmetry import Symmetry\nfrom src.symmetry.groups.S import samples_from_haar_distribution\nfrom src.symmetry.frame.S import samples_from_frame\nfrom src.symmetry.prob.S import EquivariantInterface\n\n\nT = torch.Tensor\n\nNODE_NUM_FEAT = 3\n\n\nclass NodeClassificationPATTERN(Symmetry):\n    def __init__(self, config):\n        super().__init__()\n        self.group_name = 'S'\n        self.rep_dim = 188\n        self.rep_in = {1: NODE_NUM_FEAT, 2: 1 + NODE_NUM_FEAT}\n        self.rep_out = {2: 2}\n        self.metric_name = 'accuracy'\n        if config.interface == 'prob':\n            self.entropy_loss_scale = config.entropy_loss_scale\n            self.interface = partial(\n                EquivariantInterface,\n                noise_scale=config.noise_scale,\n                tau=config.tau,\n                hard=config.hard,\n                rep_dim=self.rep_dim,\n                node_rep_channels=self.rep_in[1],\n                interface_num_layers=config.interface_num_layers,\n                interface_hidden_dim=config.interface_hidden_dim,\n                interface_dropout=config.interface_dropout\n            )\n\n    def process_input(self, batch: Data) -> Tuple[T, T]:\n        device, dtype = batch.x.device, batch.x.dtype\n        batch_size = batch.num_graphs\n        node_ptr = batch._slice_dict['x'].to(device)\n        edge_ptr = batch._slice_dict['edge_index'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        num_edges = edge_ptr[1:] - edge_ptr[:-1]\n        n = self.rep_dim\n        # parse node features (B, N, C)\n        tri = torch.tril(torch.ones(n, n, device=device, dtype=torch.bool))\n        node_mask = tri[num_nodes - 1]\n        node_features = torch.zeros(batch_size, n, self.rep_in[1], device=device, dtype=dtype)\n        node_features[node_mask] = batch.x\n        # parse edge features (B, N, N, C)\n        edge_features = torch.zeros(batch_size, n, n, self.rep_in[2], device=device, dtype=dtype)\n        edge_batch_index = torch.arange(batch_size, device=device).repeat_interleave(num_edges)\n        edge_index_offset = node_ptr[:-1].repeat_interleave(num_edges)\n        edge_index = batch.edge_index - edge_index_offset[None, :]\n        edge_features[edge_batch_index, edge_index[0], edge_index[1], 0] = 1.\n        # place node features on the diagonals of the edge features\n        node_indices = torch.arange(n, device=device)\n        edge_features[:, node_indices, node_indices, -NODE_NUM_FEAT:] = node_features\n        # return features\n        # only edge features are used in the backbone\n        # node features are only used for the interface\n        xs = (node_features, edge_features)\n        return xs\n\n    def process_output(self, xs: Tuple[T], batch: Data) -> torch.Tensor:\n        edge_output = xs[0]\n        # (B, N, N, C) -> (B, N, C) -> (sum(Ni), C)\n        device = batch.x.device\n        node_ptr = batch._slice_dict['x'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        n = self.rep_dim\n        tri = torch.tril(torch.ones(n, n, device=device, dtype=torch.bool))\n        node_mask = tri[num_nodes - 1]\n        node_output = edge_output.diagonal(dim1=1, dim2=2).transpose(1, 2)\n        node_output = node_output[node_mask]\n        return node_output\n\n    def samples_from_haar_distribution(self, xs: Tuple[T, T], batch: Data) -> torch.Tensor:\n        n, bsize, device, dtype = self.rep_dim, xs[0].size(0), xs[0].device, xs[0].dtype\n        node_ptr = batch._slice_dict['x'].to(device)\n        num_nodes = node_ptr[1:] - node_ptr[:-1]\n        return samples_from_haar_distribution(num_nodes, n, bsize, device, dtype)\n\n    def samples_from_frame(self, xs: Tuple[T, T], batch: Data, n_samples: int):\n        n = self.rep_dim\n        gs = samples_from_frame(n, xs, batch, n_samples)\n        return gs\n\n    def samples_from_prob(self, prob_interface_net: nn.Module, xs: Tuple[T, T], batch: Data, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        gs, entropy_loss = prob_interface_net(xs, batch, n_samples)\n        loss_dict['entropy'] = {'weight': self.entropy_loss_scale, 'value': entropy_loss}\n        return gs, loss_dict\n\n    def transform_input(self, xs: Tuple[T, T], gs: torch.Tensor) -> Tuple[T, T]:\n        node_features, edge_features = xs\n        # leverage orthogonality of permutation matrices\n        # gs_inv = torch.linalg.inv(gs)\n        gs_inv = gs.transpose(1, 2)\n        node_features = gs_inv @ node_features\n        edge_features = torch.einsum('bij,bjkd,blk->bild', gs_inv, edge_features, gs_inv)\n        # remove node features as they are already encoded in the edge features\n        node_features = node_features.fill_(0)\n        xs = (node_features, edge_features)\n        return xs\n\n    def transform_output(self, xs: Tuple[T], gs: torch.Tensor) -> Tuple[T]:\n        edge_output = xs[0]\n        edge_output = torch.einsum('bij,bjkd,blk->bild', gs, edge_output, gs)\n        xs = (edge_output,)\n        return xs\n\n    def criterion(self, y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n        \"\"\"Multiclass weighted cross-entropy for imbalanced classification.\n        Implementation from LRGB:\n        https://github.com/vijaydwivedi75/lrgb/blob/main/graphgps/loss/weighted_cross_entropy.py\n        \"\"\"\n        y = y.long()\n        # calculating label weights for weighted loss computation\n        V = y.size(0)\n        n_classes = y_hat.size(-1)\n        torch.use_deterministic_algorithms(False)\n        label_count = torch.bincount(y)\n        torch.use_deterministic_algorithms(True)\n        label_count = label_count[label_count.nonzero(as_tuple=True)].squeeze()\n        cluster_sizes = torch.zeros(n_classes, device=y_hat.device, dtype=torch.long)\n        cluster_sizes[torch.unique(y)] = label_count\n        weight = (V - cluster_sizes).float() / max(V, 1e-5)\n        weight *= (cluster_sizes > 0).float()\n        # weighted cross-entropy\n        return nn.CrossEntropyLoss(weight=weight)(y_hat, y)\n\n    def _eval(self, scores: torch.Tensor, targets: torch.Tensor) -> float:\n        \"\"\" Implementation from Benchmarking GNNs:\n        https://github.com/graphdeeplearning/benchmarking-gnns/blob/master/train/metrics.py\"\"\"\n        S = targets.cpu().numpy()\n        C = np.argmax(torch.nn.Softmax(dim=1)(scores.float()).cpu().detach().numpy(), axis=1)\n        CM = confusion_matrix(S, C).astype(np.float32)\n        nb_classes = CM.shape[0]\n        targets = targets.cpu().detach().numpy()\n        nb_non_empty_classes = 0\n        pr_classes = np.zeros(nb_classes)\n        for r in range(nb_classes):\n            cluster = np.where(targets==r)[0]\n            if cluster.shape[0] != 0:\n                pr_classes[r] = CM[r,r] / float(cluster.shape[0])\n                if CM[r,r] > 0:\n                    nb_non_empty_classes += 1\n            else:\n                pr_classes[r] = 0.0\n        acc = 100. * np.sum(pr_classes) / float(nb_classes)\n        return acc\n\n    def evaluator(self, y_hat: list, y: list) -> dict:\n        \"\"\" Implementation from Benchmarking GNNs:\n        https://github.com/graphdeeplearning/benchmarking-gnns/blob/master/train/train_SBMs_node_classification.py\n        Caution: at test time, device-level batch size must be 128 for the evaluation to be consistent with GIN in benchmark:\n        https://github.com/graphdeeplearning/benchmarking-gnns/blob/master/configs/SBMs_node_clustering_GIN_PATTERN_500k.json\n        This can be specified by --test_batch_size 128 in the command line arguments\n        \"\"\"\n        acc = 0\n        for scores, targets in zip(y_hat, y):\n            acc += self._eval(scores, targets)\n        return {\n            'metric_sum': acc,\n            'metric_count': len(y_hat),\n        }\n"}
{"type": "source_file", "path": "src/model/__init__.py", "content": "from .backbone import Backbone\nfrom .interface import InterfacedModel\n"}
{"type": "source_file", "path": "main.py", "content": "# pylint: disable=line-too-long,no-member,protected-access,used-before-assignment\nimport os\nimport sys\nimport logging\nimport argparse\nimport yaml\nfrom easydict import EasyDict as edict\nimport torch\nimport torch._dynamo.config\nimport pytorch_lightning as pl\n\nfrom src.train import configure_data, configure_model, configure_experiment\n\ntorch._dynamo.config.log_level = logging.ERROR\n\n\ndef str2bool(v):\n    if v in ('True', 'true'):\n        return True\n    if v in ('False', 'false'):\n        return False\n    raise argparse.ArgumentTypeError('Boolean value expected.')\n\n\ndef add_args(parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n    # necessary arguments\n    parser.add_argument('--config', '-cfg', type=str, default=None)\n    parser.add_argument('--debug_mode', '-debug', default=False, action='store_true')\n    parser.add_argument('--resume_mode', '-resume', default=False, action='store_true')\n    parser.add_argument('--test_mode', '-test', default=False, action='store_true')\n    parser.add_argument('--skip_mode', '-skip', default=False, action='store_true')\n    parser.add_argument('--reset_mode', '-reset', default=False, action='store_true')\n    parser.add_argument('--no_eval', '-ne', default=False, action='store_true')\n    parser.add_argument('--no_save', '-ns', default=False, action='store_true')\n    parser.add_argument('--test_ckpt_path', '-ckpt', type=str, default=None)\n\n    # experiment arguments\n    parser.add_argument('--seed', type=int, default=None)\n    parser.add_argument('--test_seed', type=int, default=None)\n    parser.add_argument('--exp_name', type=str, default='')\n    parser.add_argument('--name_postfix', '-pf', type=str, default=None)\n    parser.add_argument('--exp_subname', type=str, default='')\n\n    # data arguments\n    parser.add_argument('--dataset', '-ds', type=str, default=None)\n    parser.add_argument('--strategy', '-str', type=str, default=None)\n    parser.add_argument('--accelerator', '-acc', type=str, default=None)\n    parser.add_argument('--num_workers', '-nw', type=int, default=None)\n    parser.add_argument('--global_batch_size', '-gbs', type=int, default=None)\n    parser.add_argument('--accumulate_grad_batches', '-agb', type=int, default=None)\n    parser.add_argument('--test_batch_size', '-tbs', type=int, default=None)\n\n    # model arguments\n    parser.add_argument('--backbone', '-bb', type=str, default=None)\n    parser.add_argument('--pretrained', '-pre', type=str2bool, default=None)\n    parser.add_argument('--centering', '-cen', type=str2bool, default=None)\n\n    # symmetry arguments\n    parser.add_argument('--interface', '-io', type=str, default=None, choices=['unif', 'frame', 'prob'])\n    parser.add_argument('--sample_size', '-sz', type=int, default=None)\n    parser.add_argument('--eval_sample_size', '-esz', type=int, default=None)\n    parser.add_argument('--test_sample_size', '-tsz', type=int, default=None)\n\n    # probabilistic symmetrization arguments\n    parser.add_argument('--hard', '-hrd', type=str2bool, default=None)\n\n    # training arguments\n    parser.add_argument('--n_steps', '-nst', type=int, default=None)\n    parser.add_argument('--optimizer', '-opt', type=str, default=None, choices=['sgd', 'adam', 'adamw'])\n    parser.add_argument('--gradient_clip_val', '-clip', type=float, default=None)\n    parser.add_argument('--lr', type=float, default=None)\n    parser.add_argument('--lr_pretrained', '-lrp', type=float, default=None)\n    parser.add_argument('--lr_schedule', '-lrs', type=str, default=None, choices=['const', 'sqrt', 'cos', 'poly'])\n    parser.add_argument('--early_stopping_monitor', '-esm', type=str, default=None)\n    parser.add_argument('--early_stopping_mode', '-esd', type=str, default=None, choices=['min', 'max'])\n    parser.add_argument('--early_stopping_patience', '-esp', type=int, default=None)\n\n    # logging arguments\n    parser.add_argument('--root_dir', type=str, default=None)\n    parser.add_argument('--data_dir', type=str, default=None)\n    parser.add_argument('--log_dir', type=str, default=None)\n    parser.add_argument('--save_dir', type=str, default=None)\n    parser.add_argument('--load_dir', type=str, default=None)\n    parser.add_argument('--val_iter', '-viter', type=int, default=None)\n    parser.add_argument('--save_iter', '-siter', type=int, default=None)\n\n    return parser\n\n\ndef get_config() -> edict:\n    # parse arguments\n    parser = argparse.ArgumentParser(description='Probabilistic Symmetrization')\n    parser = add_args(parser)\n    args = parser.parse_args()\n\n    # load config\n    with open(args.config, 'r', encoding='utf-8') as f:\n        config = yaml.safe_load(f)\n        config = edict(config)\n\n    # update config with parsed arguments\n    for k, v in vars(args).items():\n        if v is not None:\n            setattr(config, k, v)\n\n    # create experiment name\n    if config.exp_name == '':\n        postfix = config.name_postfix if hasattr(config, 'name_postfix') else ''\n        config.exp_name = f\"pt_{config.pretrained},\" \\\n            + f\"k_{config.sample_size},\" \\\n            + (f\"eval_k_{config.eval_sample_size},\" if config.sample_size != config.eval_sample_size else '') \\\n            + (f\"cen_{config.centering},\" if (hasattr(config, 'centering') and config.centering) else '') \\\n            + (f\"pad_{config.pad_mode},\" if hasattr(config, 'pad_mode') else '') \\\n            + (f\"patch_drop_{config.patch_dropout},\" if hasattr(config, 'patch_dropout') else '') \\\n            + (f\"patch_drop<{config.max_patch_dropout},\" if hasattr(config, 'max_patch_dropout') else '')\n        if config.interface == 'unif':\n            config.exp_name += 'ga,'\n        elif config.interface == 'frame':\n            config.exp_name += 'fa,'\n        elif config.interface == 'prob':\n            config.exp_name += f\"z_{config.noise_scale},\" \\\n                + f\"tau_{config.tau},\" \\\n                + ('hard,' if config.hard else '') \\\n                + (f\"l_{config.interface_num_layers},\" if hasattr(config, 'interface_num_layers') else '') \\\n                + (f\"d_{config.interface_hidden_dim},\" if hasattr(config, 'interface_hidden_dim') else '') \\\n                + (f\"drop_{config.interface_dropout},\" if hasattr(config, 'interface_dropout') else '')\n        else:\n            raise NotImplementedError\n        config.exp_name += f\"b_{config.global_batch_size}{(f'x{config.accumulate_grad_batches}' if hasattr(config, 'accumulate_grad_batches') else '')},\" \\\n            + f\"es_{config.early_stopping_monitor.replace('/', '_')}_{config.early_stopping_mode}_{config.early_stopping_patience},\" \\\n            + f\"lr_{config.lr}_{config.lr_pretrained},\" \\\n            + f\"steps_{config.n_steps},\" \\\n            + f\"wu_{config.lr_warmup},\" \\\n            + f\"wd_{config.weight_decay},\" \\\n            + (f\"clip_{config.gradient_clip_val},\" if hasattr(config, 'gradient_clip_val') else '') \\\n            + f\"seed_{config.seed},\"\n        config.exp_name += postfix\n\n    # create seed for testing\n    if not hasattr(config, 'test_seed'):\n        config.test_seed = config.seed\n\n    # create checkpoint for testing\n    if not hasattr(config, 'test_ckpt_path'):\n        config.test_ckpt_path = None\n\n    # create team name for wandb logging\n    config.team_name = 'lps'\n\n    # # this is a hack for debugging with visual studio code\n    # config.debug_mode = True\n\n    # setup debugging\n    if config.debug_mode:\n        config.accelerator = 'cpu'\n        config.num_workers = 0\n        config.global_batch_size = 2\n        config.n_samples = 2\n        config.n_samples_eval = 2\n        config.n_steps = 10\n        config.log_iter = 1\n        config.val_iter = 5\n        config.save_iter = 5\n        config.log_dir += '_debug'\n        config.save_dir += '_debug'\n        config.load_dir += '_debug'\n\n    return config\n\n\ndef main(config):\n    # reproducibility (this and deterministic=True in trainer)\n    pl.seed_everything(config.seed, workers=True)\n\n    # utilize Tensor Cores (RTX 3090)\n    torch.set_float32_matmul_precision('medium')\n\n    # configure data and task\n    datamodule, symmetry = configure_data(config, verbose=IS_RANK_ZERO)\n\n    # configure model\n    model, ckpt_path = configure_model(config, symmetry, verbose=IS_RANK_ZERO)\n\n    # configure experiment\n    logger, log_dir, callbacks, precision, strategy, plugins = configure_experiment(config, model)\n\n    # compile the model and *step (training/validation/test/prediction)\n    # note: can lead to nondeterministic behavior\n    # note: temporarily disabled due to an issue with python 3.8\n    # model = torch.compile(model)\n\n    if config.test_mode:\n        # test routine reproducibility (this and deterministic=True in trainer)\n        pl.seed_everything(config.test_seed, workers=True)\n\n        # setup trainer\n        # during evaluation, it is recommended to use `Trainer(devices=1, num_nodes=1)`\n        # to ensure each sample/batch gets evaluated exactly once. Otherwise,\n        # multi-device settings use `DistributedSampler` that replicates some\n        # samples to make sure all devices have same batch size in case of uneven inputs.\n        # https://github.com/Lightning-AI/lightning/issues/12862\n        trainer = pl.Trainer(\n            logger=logger,\n            default_root_dir=log_dir,\n            accelerator=config.accelerator,\n            num_sanity_val_steps=0,\n            callbacks=callbacks,\n            deterministic=True,\n            devices=1,\n            num_nodes=1,\n            strategy=strategy,\n            precision=precision,\n            plugins=plugins,\n            sync_batchnorm=True\n        )\n\n        # start evaluation\n        trainer.test(model, datamodule=datamodule, verbose=IS_RANK_ZERO)\n\n        # terminate\n        sys.exit()\n\n    # setup trainer\n    trainer = pl.Trainer(\n        logger=logger,\n        default_root_dir=log_dir,\n        accelerator=config.accelerator,\n        max_steps=config.n_steps,\n        log_every_n_steps=-1,\n        num_sanity_val_steps=0,\n        callbacks=callbacks,\n        deterministic=not (hasattr(config, 'pad_mode') and (config.pad_mode != 'reflect')),\n        devices=torch.cuda.device_count() if config.accelerator == 'gpu' else 1,\n        strategy=strategy,\n        precision=precision,\n        plugins=plugins,\n        sync_batchnorm=True,\n        gradient_clip_val=0.0 if not hasattr(config, 'gradient_clip_val') else config.gradient_clip_val,\n        accumulate_grad_batches=1 if not hasattr(config, 'accumulate_grad_batches') else config.accumulate_grad_batches\n    )\n\n    if not config.resume_mode:\n        # validation at start\n        trainer.validate(model, datamodule=datamodule, verbose=IS_RANK_ZERO)\n\n    # start training\n    trainer.fit(model, datamodule=datamodule, ckpt_path=ckpt_path)\n\n    # start evaluation\n    # this uses the last checkpoint for testing, and replicates some test samples.\n    # for exact evaluation using the best checkpoint, it is recommended to run a\n    # separate process with command `python3 main,py ... --test_mode` after training.\n    trainer.test(model, datamodule=datamodule, verbose=IS_RANK_ZERO)\n\n    # terminate\n    sys.exit()\n\n\nif __name__ == '__main__':\n    IS_RANK_ZERO = int(os.environ.get('LOCAL_RANK', 0)) == 0\n    config_ = get_config()\n    main(config_)\n"}
{"type": "source_file", "path": "src/symmetry/frame/__init__.py", "content": "from . import S\n"}
{"type": "source_file", "path": "src/model/checkpoints.py", "content": "# huggingface checkpoints\nHF_CHECKPOINTS = [\n    # text transformers\n    'bert-base-uncased',\n    'bert-large-uncased',\n    'bert-base-cased',\n    'bert-large-cased',\n    'roberta-base',\n    'roberta-large',\n    'albert-base-v2',\n    'albert-large-v2',\n    'albert-xlarge-v2',\n    'albert-xxlarge-v2',\n    'google/electra-small-discriminator',\n    'google/electra-base-discriminator',\n    'google/electra-large-discriminator',\n    'xlm-roberta-base',\n    'xlm-roberta-large',\n    # MAE pretrained\n    'facebook/vit-mae-base',\n    'facebook/vit-mae-large',\n    'facebook/vit-mae-huge',\n    # CoCa (does not work)\n    # 'laion/mscoco_finetuned_CoCa-ViT-B-32-laion2B-s13B-b90k',\n    # 'laion/mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k',\n    # 'laion/CoCa-ViT-B-32-laion2B-s13B-b90k',\n    # 'laion/CoCa-ViT-L-14-laion2B-s13B-b90k',\n    # Perceiver and Perceiver IO\n    'deepmind/language-perceiver',\n    'deepmind/multimodal-perceiver',\n    'deepmind/optical-flow-perceiver',\n    'deepmind/vision-perceiver-learned',\n    'deepmind/vision-perceiver-fourier',\n    'deepmind/vision-perceiver-conv',\n    # Graphormer\n    'clefourrier/graphormer-base-pcqm4mv2'\n]\n\n# timm checkpoints\nTIMM_CHECKPOINTS = [\n    'timm/beit_base_patch16_224.in22k_ft_in22k',  # TODO: temporary\n    # re-finetuned augreg 21k FT on in1k weights\n    'hf_hub:timm/vit_base_patch16_224.augreg2_in21k_ft_in1k',\n    'hf_hub:timm/vit_base_patch16_384.augreg2_in21k_ft_in1k',\n    'hf_hub:timm/vit_base_patch8_224.augreg2_in21k_ft_in1k',\n    # How to train your ViT (augreg) weights, pretrained on 21k FT on in1k\n    'hf_hub:timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_tiny_patch16_384.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_small_patch32_224.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_small_patch32_384.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_small_patch16_224.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_small_patch16_384.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_base_patch32_224.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_base_patch32_384.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_base_patch16_224.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_base_patch16_384.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_base_patch8_224.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_large_patch16_224.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_large_patch16_224.augreg_in21k_ft_in1k',\n    'hf_hub:timm/vit_large_patch16_384.augreg_in21k_ft_in1k',\n    # patch models (weights from official Google JAX impl) pretrained on in21k FT on in1k\n    'hf_hub:timm/vit_base_patch16_224.orig_in21k_ft_in1k',\n    'hf_hub:timm/vit_base_patch16_384.orig_in21k_ft_in1k',\n    'hf_hub:timm/vit_large_patch32_384.orig_in21k_ft_in1k',\n    # How to train your ViT (augreg) weights trained on in1k only\n    'hf_hub:timm/vit_small_patch16_224.augreg_in1k',\n    'hf_hub:timm/vit_small_patch16_384.augreg_in1k',\n    'hf_hub:timm/vit_base_patch32_224.augreg_in1k',\n    'hf_hub:timm/vit_base_patch32_384.augreg_in1k',\n    'hf_hub:timm/vit_base_patch16_224.augreg_in1k',\n    'hf_hub:timm/vit_base_patch16_384.augreg_in1k',\n    # patch models, imagenet21k (weights from official Google JAX impl)\n    'hf_hub:timm/vit_large_patch32_224.orig_in21k',\n    'hf_hub:timm/vit_huge_patch14_224.orig_in21k',\n    # How to train your ViT (augreg) weights, pretrained on in21k\n    'hf_hub:timm/vit_tiny_patch16_224.augreg_in21k',\n    'hf_hub:timm/vit_small_patch32_224.augreg_in21k',\n    'hf_hub:timm/vit_small_patch16_224.augreg_in21k',\n    'hf_hub:timm/vit_base_patch32_224.augreg_in21k',\n    'hf_hub:timm/vit_base_patch16_224.augreg_in21k',\n    'hf_hub:timm/vit_base_patch8_224.augreg_in21k',\n    'hf_hub:timm/vit_large_patch16_224.augreg_in21k',\n    # SAM trained models (https://arxiv.org/abs/2106.01548)\n    'hf_hub:timm/vit_base_patch32_224.sam',\n    'hf_hub:timm/vit_base_patch16_224.sam',\n    # DINO pretrained - https://arxiv.org/abs/2104.14294 (no classifier head, for fine-tune only)\n    'hf_hub:timm/vit_small_patch16_224.dino',\n    'hf_hub:timm/vit_small_patch8_224.dino',\n    'hf_hub:timm/vit_base_patch16_224.dino',\n    'hf_hub:timm/vit_base_patch8_224.dino',\n    # ViT ImageNet-21K-P pretraining by MILL\n    'hf_hub:timm/vit_base_patch16_224_miil.in21k',\n    'hf_hub:timm/vit_base_patch16_224_miil.in21k_ft_in1k',\n    # BEiT fine-tuned weights from MAE style MIM - BEiT target pretrain\n    'hf_hub:timm/beit_base_patch16_224.in22k_ft_in22k',\n    'hf_hub:timm/beit_base_patch16_224.in22k_ft_in22k_in1k',\n    'hf_hub:timm/beit_base_patch16_384.in22k_ft_in22k_in1k',\n    'hf_hub:timm/beit_large_patch16_224.in22k_ft_in22k',\n    'hf_hub:timm/beit_large_patch16_224.in22k_ft_in22k_in1k',\n    'hf_hub:timm/beit_large_patch16_384.in22k_ft_in22k_in1k',\n    'hf_hub:timm/beit_large_patch16_512.in22k_ft_in22k_in1k',\n    'hf_hub:timm/beitv2_base_patch16_224.in1k_ft_in22k',\n    'hf_hub:timm/beitv2_base_patch16_224.in1k_ft_in22k_in1k',\n    'hf_hub:timm/beitv2_large_patch16_224.in1k_ft_in22k',\n    'hf_hub:timm/beitv2_large_patch16_224.in1k_ft_in22k_in1k',\n    # DeiT models (FB weights)\n    'hf_hub:timm/deit_tiny_patch16_224.fb_in1k',\n    'hf_hub:timm/deit_small_patch16_224.fb_in1k',\n    'hf_hub:timm/deit_base_patch16_224.fb_in1k',\n    'hf_hub:timm/deit_base_patch16_384.fb_in1k',\n    'hf_hub:timm/deit_tiny_distilled_patch16_224.fb_in1k',\n    'hf_hub:timm/deit_small_distilled_patch16_224.fb_in1k',\n    'hf_hub:timm/deit_base_distilled_patch16_224.fb_in1k',\n    'hf_hub:timm/deit_base_distilled_patch16_384.fb_in1k',\n    'hf_hub:timm/deit3_small_patch16_224.fb_in1k',\n    'hf_hub:timm/deit3_small_patch16_384.fb_in1k',\n    'hf_hub:timm/deit3_medium_patch16_224.fb_in1k',\n    'hf_hub:timm/deit3_base_patch16_224.fb_in1k',\n    'hf_hub:timm/deit3_base_patch16_384.fb_in1k',\n    'hf_hub:timm/deit3_large_patch16_224.fb_in1k',\n    'hf_hub:timm/deit3_large_patch16_384.fb_in1k',\n    'hf_hub:timm/deit3_huge_patch14_224.fb_in1k',\n    'hf_hub:timm/deit3_small_patch16_224.fb_in22k_ft_in1k',\n    'hf_hub:timm/deit3_small_patch16_384.fb_in22k_ft_in1k',\n    'hf_hub:timm/deit3_medium_patch16_224.fb_in22k_ft_in1k',\n    'hf_hub:timm/deit3_base_patch16_224.fb_in22k_ft_in1k',\n    'hf_hub:timm/deit3_base_patch16_384.fb_in22k_ft_in1k',\n    'hf_hub:timm/deit3_large_patch16_224.fb_in22k_ft_in1k',\n    'hf_hub:timm/deit3_large_patch16_384.fb_in22k_ft_in1k',\n    'hf_hub:timm/deit3_huge_patch14_224.fb_in22k_ft_in1k',\n    # FlexiViT models\n    'hf_hub:timm/flexivit_small.1200ep_in1k',\n    'hf_hub:timm/flexivit_small.600ep_in1k',\n    'hf_hub:timm/flexivit_small.300ep_in1k',\n    'hf_hub:timm/flexivit_base.1200ep_in1k',\n    'hf_hub:timm/flexivit_base.600ep_in1k',\n    'hf_hub:timm/flexivit_base.300ep_in1k',\n    'hf_hub:timm/flexivit_base.1000ep_in21k',\n    'hf_hub:timm/flexivit_base.300ep_in21k',\n    'hf_hub:timm/flexivit_large.1200ep_in1k',\n    'hf_hub:timm/flexivit_large.600ep_in1k',\n    'hf_hub:timm/flexivit_large.300ep_in1k',\n    'hf_hub:timm/flexivit_base.patch16_in21k',\n    'hf_hub:timm/flexivit_base.patch30_in21k',\n    # CLIP pretrained image tower and related fine-tuned weights\n    'hf_hub:timm/vit_base_patch32_clip_224.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch32_clip_384.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch32_clip_448.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch16_clip_224.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_large_patch14_clip_224.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_large_patch14_clip_336.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch32_clip_224.openai_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch32_clip_384.openai_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch32_clip_448.openai_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch16_clip_224.openai_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch16_clip_384.openai_ft_in12k_in1k',\n    'hf_hub:timm/vit_large_patch14_clip_224.openai_ft_in12k_in1k',\n    'hf_hub:timm/vit_large_patch14_clip_336.openai_ft_in12k_in1k',\n    'hf_hub:timm/vit_base_patch32_clip_224.laion2b_ft_in1k',\n    'hf_hub:timm/vit_base_patch16_clip_224.laion2b_ft_in1k',\n    'hf_hub:timm/vit_base_patch16_clip_384.laion2b_ft_in1k',\n    'hf_hub:timm/vit_large_patch14_clip_224.laion2b_ft_in1k',\n    'hf_hub:timm/vit_large_patch14_clip_336.laion2b_ft_in1k',\n    'hf_hub:timm/vit_huge_patch14_clip_224.laion2b_ft_in1k',\n    'hf_hub:timm/vit_huge_patch14_clip_336.laion2b_ft_in1k',\n    'hf_hub:timm/vit_base_patch32_clip_224.openai_ft_in1k',\n    'hf_hub:timm/vit_base_patch16_clip_224.openai_ft_in1k',\n    'hf_hub:timm/vit_base_patch16_clip_384.openai_ft_in1k',\n    'hf_hub:timm/vit_large_patch14_clip_224.openai_ft_in1k',\n    'hf_hub:timm/vit_base_patch32_clip_224.laion2b_ft_in12k',\n    'hf_hub:timm/vit_base_patch16_clip_224.laion2b_ft_in12k',\n    'hf_hub:timm/vit_large_patch14_clip_224.laion2b_ft_in12k',\n    'hf_hub:timm/vit_huge_patch14_clip_224.openai_ft_in12k',\n    'hf_hub:timm/vit_base_patch32_clip_224.openai_ft_in12k',\n    'hf_hub:timm/vit_base_patch16_clip_224.openai_ft_in12k',\n    'hf_hub:timm/vit_large_patch14_clip_224.openai_ft_in12k',\n    'hf_hub:timm/vit_base_patch32_clip_224.laion2b',\n    'hf_hub:timm/vit_base_patch16_clip_224.laion2b',\n    'hf_hub:timm/vit_large_patch14_clip_224.laion2b',\n    'hf_hub:timm/vit_huge_patch14_clip_224.laion2b',\n    'hf_hub:timm/vit_giant_patch14_clip_224.laion2b',\n    'hf_hub:timm/vit_gigantic_patch14_clip_224.laion2b',\n    'hf_hub:timm/vit_base_patch32_clip_224.openai',\n    'hf_hub:timm/vit_base_patch16_clip_224.openai',\n    'hf_hub:timm/vit_large_patch14_clip_224.openai',\n    'hf_hub:timm/vit_large_patch14_clip_336.openai',\n    # EVA fine-tuned weights from MAE style MIM - EVA-CLIP target pretrain\n    'hf_hub:timm/eva_large_patch14_196.in22k_ft_in22k_in1k',\n    'hf_hub:timm/eva_large_patch14_336.in22k_ft_in22k_in1k',\n    'hf_hub:timm/eva_large_patch14_196.in22k_ft_in1k',\n    'hf_hub:timm/eva_large_patch14_336.in22k_ft_in1k',\n]\n"}
{"type": "source_file", "path": "src/symmetry/groups/__init__.py", "content": "from . import O, S, SO, U\n"}
{"type": "source_file", "path": "src/symmetry/frame/S.py", "content": "# pylint:disable=unused-variable,line-too-long\nimport torch\n\n\ndef compute_node_mask(num_nodes, n, device):\n    tri = torch.tril(torch.ones(n, n, device=device, dtype=torch.bool))\n    node_mask = tri[num_nodes - 1]\n    b, n = node_mask.shape\n    arr0 = node_mask.unsqueeze(1).expand(b, n, n)\n    arr1 = node_mask.unsqueeze(2).expand(b, n, n)\n    node_mask2d = torch.logical_and(arr0, arr1)\n    return node_mask, node_mask2d\n\n\ndef perm1d_to_2d(perm1d, device):\n    b, n = perm1d.shape\n    perm2d = torch.eye(n, device=device)[None, :, :].expand(b, n, n)\n    perm2d = perm2d.gather(1, perm1d[:, :, None].expand(b, n, n))\n    return perm2d\n\n\ndef sample_perm(perm_idx_pad, mask_perm_pad, sort_idx_pad, n_samples):\n    device = perm_idx_pad.device\n    b, n = perm_idx_pad.shape\n    assert mask_perm_pad.shape == sort_idx_pad.shape == (b, n)\n\n    sort_idx_perm = perm1d_to_2d(sort_idx_pad, device)\n    sort_idx_perm = sort_idx_perm[:, None, :, :].expand(b, n_samples, n, n)\n    perm_idx_pad = perm_idx_pad[:, None, :].expand(b, n_samples, n)\n    mask_perm_pad = mask_perm_pad[:, None, :].expand(b, n_samples, n)\n\n    sort_idx_perm = sort_idx_perm.reshape(b * n_samples, n, n)\n    perm_idx_pad = perm_idx_pad.reshape(b * n_samples, n)\n    mask_perm_pad = mask_perm_pad.reshape(b * n_samples, n)\n\n    z = torch.zeros(b * n_samples, n, device=device).uniform_(0.1, 0.5)\n    perm_idx_pad = perm_idx_pad.to(z.dtype)\n    perm_idx_pad[mask_perm_pad] += z[mask_perm_pad]\n    perms = perm_idx_pad.argsort(dim=-1)\n    assert perms.shape == (b * n_samples, n)\n\n    gs = perm1d_to_2d(perms, device)\n    assert gs.shape == (b * n_samples, n, n)\n\n    gs = torch.matmul(gs, sort_idx_perm)  # gs[0, -1, -1] = 1, not 0\n    return gs\n\n\n@torch.no_grad()\ndef samples_from_frame(n, xs, batch, n_samples):\n    b, n, _ = xs[0].shape\n    assert b == batch.num_graphs\n    device = xs[0].device\n\n    n_nodes = batch.ptr[1:] - batch.ptr[:-1]\n    node_mask, _ = compute_node_mask(n_nodes, n, device)\n\n    perm_idx_pad = torch.arange(n, device=device)[None, :].expand(b, n).clone()\n    mask_perm_pad = torch.ones(b, n, device=device) == 0\n    sort_idx_pad = torch.arange(n, device=device)[None, :].expand(b, n).clone()\n\n    perm_idx_pad[node_mask] = batch.perm_idx.to(device)\n    mask_perm_pad[node_mask] = batch.mask_perm.to(device)\n    sort_idx_pad[node_mask] = batch.sort_idx.to(device)\n\n    gs = sample_perm(perm_idx_pad, mask_perm_pad, sort_idx_pad, n_samples)\n    gs = gs.transpose(1,2)\n    return gs\n"}
{"type": "source_file", "path": "src/train/pl_datamodule.py", "content": "# pylint: disable=too-many-instance-attributes,disable=too-many-arguments,unused-argument\nfrom torch.utils.data import DataLoader\nimport pytorch_lightning as pl\nimport torch_geometric.data.lightning\n\nfrom src.data import DatasetBuilder\n\n\nclass LitDataModule(pl.LightningDataModule):\n    def __init__(\n            self,\n            ds_builder: DatasetBuilder,\n            global_batch_size: int,\n            devices: int,\n            num_workers: int,\n            verbose: bool=True\n        ):\n        super().__init__()\n        self.train_dataset = None\n        self.val_dataset = None\n        self.test_dataset = None\n        self.predict_dataset = None\n\n        self.ds_builder = ds_builder\n        self.batch_size = global_batch_size // devices\n        self.num_workers = num_workers\n\n        self.verbose = verbose\n\n    def prepare_data(self):\n        \"\"\"Download data, split, etc. Only called on 1 GPU/TPU in distributed.\"\"\"\n        self.ds_builder.prepare_data()\n\n    def setup(self, stage: str):\n        \"\"\"Make assignments here (val/train/test split). Called on every GPU/TPU in DDP.\"\"\"\n\n        # assign train/val split(s) for use in Dataloaders\n        if stage in ('fit', 'validate'):\n            self.train_dataset = self.ds_builder.train_dataset()\n            self.val_dataset = self.ds_builder.val_dataset()\n\n        # assign test split(s) for use in Dataloaders\n        if stage == 'test':\n            self.test_dataset = self.ds_builder.test_dataset()\n\n        # assign predict split(s) for use in Dataloaders\n        if stage == 'predict':\n            self.predict_dataset = self.ds_builder.predict_dataset()\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            pin_memory=True,\n            drop_last=True,\n            num_workers=self.num_workers\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.val_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            pin_memory=True,\n            drop_last=False,\n            num_workers=1\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            pin_memory=True,\n            drop_last=False,\n            num_workers=1\n        )\n\n    def predict_dataloader(self):\n        return DataLoader(\n            self.predict_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            pin_memory=True,\n            drop_last=False,\n            num_workers=1\n        )\n\n\n@pl.utilities.rank_zero_only\ndef prepare_pyg_data(ds_builder: DatasetBuilder):\n    \"\"\"Prepare PyTorch Geometric data\"\"\"\n    ds_builder.prepare_data()\n\n\ndef setup_pyg_datamodule(\n        ds_builder: DatasetBuilder,\n        global_batch_size: int,\n        devices: int,\n        num_workers: int,\n        verbose: bool=True\n    ):\n    \"\"\"Setup PyTorch Geometric datamodule\"\"\"\n    prepare_pyg_data(ds_builder=ds_builder)\n    train_dataset = ds_builder.train_dataset()\n    val_dataset = ds_builder.val_dataset()\n    test_dataset = ds_builder.test_dataset()\n    pred_dataset = ds_builder.predict_dataset()\n    batch_size = global_batch_size // devices\n    datamodule = torch_geometric.data.lightning.LightningDataset(\n        train_dataset=train_dataset,\n        val_dataset=val_dataset,\n        test_dataset=test_dataset,\n        pred_dataset=pred_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers\n    )\n    return datamodule\n"}
{"type": "source_file", "path": "src/model/backbone.py", "content": "# pylint: disable=protected-access,too-many-arguments\nimport torch\nfrom torch import nn\nfrom torch.utils.checkpoint import checkpoint\nfrom transformers import AutoConfig, AutoModel\nfrom transformers import BertModel, RobertaModel, AlbertModel, ElectraModel, XLMRobertaModel\nfrom transformers import ViTMAEModel, PerceiverModel, GraphormerModel\nimport timm\nfrom timm.models import VisionTransformer, Beit, checkpoint_seq\nfrom timm.layers import PatchDropout\n\nfrom .checkpoints import HF_CHECKPOINTS, TIMM_CHECKPOINTS\n\nTextTransformer = (BertModel, RobertaModel, AlbertModel, ElectraModel, XLMRobertaModel)\nTODO = (ViTMAEModel, PerceiverModel, GraphormerModel)\n\n\ndef setup_backbone(backbone, pretrained=True):\n    \"\"\"Initialize backbone architecture and load pretrained weights\"\"\"\n    if backbone in HF_CHECKPOINTS:\n        if pretrained:\n            return AutoModel.from_pretrained(backbone)\n        return AutoModel.from_config(AutoConfig.from_pretrained(backbone))\n    if backbone in TIMM_CHECKPOINTS:\n        return timm.create_model(backbone, pretrained=pretrained)\n    raise NotImplementedError(f\"Backbone ({backbone}) not supported!\")\n\n\nclass Backbone(nn.Module):\n    \"\"\"Backbone transformer architecture (optionally pre-trained)\"\"\"\n    def __init__(self, backbone, pretrained, patch_dropout, max_patch_dropout):\n        super().__init__()\n        assert (patch_dropout is None) or (max_patch_dropout is None)\n        self.patch_drop_rate = patch_dropout\n        self.max_patch_drop_rate = max_patch_dropout\n        self.patch_drop = nn.Identity()\n        self.backbone = setup_backbone(backbone, pretrained)\n        if isinstance(self.backbone, TextTransformer):\n            self.num_tokens = self.backbone.config.max_position_embeddings\n            self.hidden_size = self.backbone.config.hidden_size\n            self._forward = self._forward_text\n            if patch_dropout or max_patch_dropout:\n                raise NotImplementedError(\"PatchDropout not supported for TextTransformer!\")\n        elif isinstance(self.backbone, VisionTransformer):\n            self.num_tokens = self.backbone.patch_embed.num_patches\n            self.hidden_size = self.backbone.num_features\n            self._forward = self._forward_vision\n        elif isinstance(self.backbone, Beit):\n            self.num_tokens = self.backbone.patch_embed.num_patches\n            self.hidden_size = self.backbone.num_features\n            self._forward = self._forward_beit\n            if patch_dropout or max_patch_dropout:\n                raise NotImplementedError(\"PatchDropout not supported for Beit!\")\n        elif isinstance(self.backbone, TODO):\n            raise NotImplementedError(f\"Backbone ({self.backbone}) not implemented (TODO)!\")\n        else:\n            raise NotImplementedError(f\"Backbone ({self.backbone}) not supported!\")\n\n    def _forward_text(self, x: torch.Tensor):\n        output = self.backbone(inputs_embeds=x)\n        unpooled_output = output.last_hidden_state\n        pooled_output = output.pooler_output\n        return unpooled_output, pooled_output\n\n    def _forward_vision(self, x: torch.Tensor):\n        # x = backbone.patch_embed(x)\n        x = self.backbone._pos_embed(x)\n        if self.patch_drop_rate:\n            self.patch_drop = PatchDropout(\n                prob=self.patch_drop_rate,\n                num_prefix_tokens=self.backbone.num_prefix_tokens)\n        elif self.max_patch_drop_rate:\n            self.patch_drop = PatchDropout(\n                prob=torch.rand(1).item() * self.max_patch_drop_rate,\n                num_prefix_tokens=self.backbone.num_prefix_tokens)\n        else:\n            assert self.patch_drop_rate is None and self.max_patch_drop_rate is None\n            self.patch_drop = nn.Identity()\n        x = self.patch_drop(x)\n        x = self.backbone.norm_pre(x)\n        if self.backbone.grad_checkpointing and not torch.jit.is_scripting():\n            x = checkpoint_seq(self.backbone.blocks, x)\n        else:\n            x = self.backbone.blocks(x)\n        x = self.backbone.norm(x)\n        unpooled_output = x[:, self.backbone.num_prefix_tokens:]\n        pooled_output = self.backbone.forward_head(x, pre_logits=True)\n        return unpooled_output, pooled_output\n\n    def _forward_beit(self, x: torch.Tensor):\n        # x = self.backbone.patch_embed(x)\n        b = x.size(0)\n        x = torch.cat((self.backbone.cls_token.expand(b, -1, -1), x), dim=1)\n        if self.backbone.pos_embed is not None:\n            x = x + self.backbone.pos_embed\n        x = self.backbone.pos_drop(x)\n        rel_pos_bias = self.backbone.rel_pos_bias() if \\\n            self.backbone.rel_pos_bias is not None else None\n        for blk in self.backbone.blocks:\n            if self.backbone.grad_checkpointing and not torch.jit.is_scripting():\n                x = checkpoint(blk, x, shared_rel_pos_bias=rel_pos_bias)\n            else:\n                x = blk(x, shared_rel_pos_bias=rel_pos_bias)\n        x = self.backbone.norm(x)\n        unpooled_output = x[:, self.backbone.num_prefix_tokens:]\n        pooled_output = self.backbone.forward_head(x, pre_logits=True)\n        return unpooled_output, pooled_output\n\n    def forward(self, x: torch.Tensor):\n        \"\"\"forward pass for the backbone using features as input and output.\n        bypass tokenizer and input embeddings, do not bypass positional embeddings.\n        bypass global pooling and head classifier.\n        :param x: input tensor of size (N, L, C)\n        :return: output tensor of size (N, L, D) and pooled output of size (N, D)\n        \"\"\"\n        assert x.dim() == 3, f\"input tensor of size ({x.size()}) must be 3D (NLC)!\"\n        return self._forward(x)\n"}
{"type": "source_file", "path": "src/model/interface.py", "content": "# pylint: disable=too-many-arguments,too-many-instance-attributes\nfrom typing import Tuple, Any, Dict\nfrom torch import nn\n\nfrom src.symmetry import Symmetry\nfrom src.symmetry.interface import Uniform, Frame, Probabilistic\nfrom src.symmetry.projections_conv import ConvInputProj, ConvOutputProj\nfrom .backbone import Backbone\n\nDIST = {'unif': Uniform, 'frame': Frame, 'prob': Probabilistic}\n\n\nclass InterfacedModel(nn.Module):\n    def __init__(self, backbone: Backbone, symmetry: Symmetry, interface: str, centering: bool, pad_mode: str):\n        super().__init__()\n        # setup backbone\n        self.backbone = backbone\n        # setup group and reps\n        self.symmetry = symmetry\n        self.criterion = self.symmetry.criterion\n        self.evaluator = self.symmetry.evaluator\n        self.metric_name = self.symmetry.metric_name\n        # setup equivariant distribution p(g|x)\n        self.distribution = DIST[interface](self.symmetry)\n        # setup input and output projections\n        assert pad_mode in ['zero', 'reflect', 'replicate', 'circular']\n        num_tokens = self.backbone.num_tokens\n        hidden_size = self.backbone.hidden_size\n        self.input_proj = ConvInputProj(symmetry, num_tokens, hidden_size, centering, pad_mode)\n        self.output_proj = ConvOutputProj(symmetry, num_tokens, hidden_size, centering, pad_mode)\n\n    def pretrained_parameters(self):\n        return self.backbone.parameters()\n\n    def scratch_parameters(self):\n        for module in [self.input_proj, self.output_proj, self.distribution]:\n            yield from module.parameters()\n\n    def _forward(self, xs: tuple) -> tuple:\n        x = self.input_proj(xs)\n        x_unpooled, x_pooled = self.backbone(x)\n        xs = self.output_proj(x_unpooled, x_pooled)\n        return xs\n\n    def forward(self, batch, n_samples: int=1, transform: bool=True) -> Tuple[Any, Dict]:\n        \"\"\"Forward pass with monte carlo sampling for symmetrization\"\"\"\n        loss_dict = {}\n        if not transform:\n            xs = self.symmetry.process_input(batch)\n            xs = self._forward(xs)\n            x = self.symmetry.process_output(xs, batch)\n            return x, loss_dict\n        xs = self.symmetry.process_input(batch)\n        gs, loss_dict = self.distribution(xs, batch, n_samples, loss_dict)\n        xs, batch_size = self.symmetry.broadcast(xs, n_samples)\n        xs = self.symmetry.transform_input(xs, gs)\n        xs = self._forward(xs)\n        xs = self.symmetry.transform_output(xs, gs)\n        xs = self.symmetry.reduce(xs, batch_size, n_samples)\n        x = self.symmetry.process_output(xs, batch)\n        return x, loss_dict\n"}
{"type": "source_file", "path": "src/symmetry/__init__.py", "content": "from .symmetry import Symmetry\nfrom . import interface, projections, projections_conv\nfrom . import groups, frame, prob\n"}
{"type": "source_file", "path": "src/symmetry/groups/O.py", "content": "import torch\n\n\ndef samples_from_haar_distribution(d, bsize, device, dtype) -> torch.Tensor:\n    \"\"\"Random orthogonal matrices drawn from O(d) Haar distribution\n    Adopted from scipy.stats.ortho_group, which implements the algorithm described in\n    Mezzadri, How to generate random matrices from the classical compact groups (2006)\n    \"\"\"\n    z = torch.randn(bsize, d, d, device=device, dtype=dtype)\n    q, r = torch.linalg.qr(z)\n    # The last two dimensions are the rows and columns of R matrices.\n    # Extract the diagonals. Note that this eliminates a dimension.\n    d = r.diagonal(offset=0, dim1=-2, dim2=-1)\n    # Add back a dimension for proper broadcasting: we're dividing\n    # each row of each R matrix by the diagonal of the R matrix.\n    q *= (d/abs(d))[..., None, :]  # to broadcast properly\n    return q\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/analysis/__init__.py", "content": "from .interface import analyze_interface\nfrom .forward import analyze_forward\nfrom .backward import analyze_backward\n"}
{"type": "source_file", "path": "src/train/pl_module.py", "content": "# pylint: disable=arguments-differ,unused-argument,too-many-instance-attributes,too-many-arguments,line-too-long,comparison-with-itself\nimport warnings\nimport torch\nimport torch_geometric.data\nimport pytorch_lightning as pl\n\nfrom src.model import InterfacedModel\nfrom src.optim import OptimizerConfig, LRSchedulerConfig\n\n\nclass LitModule(pl.LightningModule):\n    def __init__(\n            self,\n            model: InterfacedModel,\n            sample_size: int,\n            eval_sample_size: int,\n            optimizer_config: OptimizerConfig,\n            lr_scheduler_config: LRSchedulerConfig,\n            verbose: bool=True\n        ):\n        super().__init__()\n        self.model = model\n        self.sample_size = sample_size\n        self.eval_sample_size = eval_sample_size\n        self.optimizer_config = optimizer_config\n        self.lr_scheduler_config = lr_scheduler_config\n        self.lr_scheduler = None\n        self.verbose = verbose\n\n        self.criterion = model.criterion\n        self.evaluator = model.evaluator\n        self.metric_name = model.metric_name\n\n        self.training_step_outputs = []\n        self.validation_step_outputs = []\n        self.test_step_outputs = []\n        self.predict_step_outputs = []\n\n        self.save_hyperparameters(ignore=['model'])\n\n    def configure_optimizers(self):\n        optimizer = self.optimizer_config.setup(self.model)\n        self.lr_scheduler = self.lr_scheduler_config.setup(optimizer)\n        return optimizer\n\n    def forward(self, x, n_samples=1):\n        return self.model(x, n_samples)\n\n    def parse_batch(self, batch):\n        if isinstance(batch, torch_geometric.data.Data):\n            if hasattr(batch, 'edge_label'):\n                assert batch.y is None, 'Cannot have both y and edge_label'\n                return batch, batch\n            return batch, batch.y\n        if isinstance(batch, (list, tuple)):\n            return batch\n        raise ValueError(f'Unknown batch type: {type(batch)}')\n\n    def training_step(self, batch, batch_idx):\n        assert self.model.training\n        x, y = self.parse_batch(batch)\n        y_hat, loss_dict = self(x, n_samples=self.sample_size)\n        loss_total = 0\n\n        loss_main = self.criterion(y_hat, y)\n        loss_total = loss_total + (loss_main if torch.isfinite(loss_main) else 0)\n\n        for loss_name in loss_dict.keys():\n            loss_value = loss_dict[loss_name]['value']\n            loss_total = loss_total + loss_dict[loss_name]['weight'] * loss_value\n            self.log(f'training/loss_{loss_name}', loss_value, on_step=True, logger=True, sync_dist=True)\n\n        self.lr_scheduler.step(self.global_step)\n        self.log('training/loss_main', loss_main, on_step=True, logger=True, sync_dist=True)\n        self.log('training/lr', self.lr_scheduler.lr, on_step=True, logger=True, sync_dist=True)\n        self.log('step', float(self.global_step), on_step=True, logger=True, sync_dist=True)\n        self.training_step_outputs.append((loss_main.detach(), loss_dict))\n        return loss_total\n\n    def on_train_epoch_end(self):\n        if len(self.training_step_outputs) == 0:\n            if self.verbose:\n                warnings.warn(\"training_step_outputs is empty. This can happen when training is resumed from a checkpoint.\")\n            return\n\n        losses_main, loss_dicts = zip(*self.training_step_outputs)\n\n        epoch_loss_main = torch.stack([l for l in losses_main if l == l]).mean()\n        self.log('training/loss_main_epoch', epoch_loss_main, on_epoch=True, logger=True, sync_dist=True)\n\n        for loss_name in loss_dicts[0].keys():\n            loss_epoch_mean = torch.stack([loss_dict[loss_name]['value'] for loss_dict in loss_dicts]).mean()\n            self.log(f'training/loss_{loss_name}_epoch', loss_epoch_mean, on_epoch=True, logger=True, sync_dist=True)\n\n        self.training_step_outputs.clear()\n\n    @torch.autocast(device_type='cuda', dtype=torch.float32)\n    def inference(self, x, n_samples=1):\n        assert not self.model.training\n        return self(x, n_samples)\n\n    def validation_step(self, batch, batch_idx):\n        x, y = self.parse_batch(batch)\n        y_hat, loss_dict = self.inference(x, n_samples=self.eval_sample_size)\n\n        val_output = (y_hat, y)\n\n        val_loss_total = 0\n        val_loss_main = self.criterion(y_hat, y)\n        val_loss_total = val_loss_total + (val_loss_main if torch.isfinite(val_loss_main) else 0)\n\n        for loss_name in loss_dict.keys():\n            val_loss_total = val_loss_total + loss_dict[loss_name]['weight'] * loss_dict[loss_name]['value']\n\n        self.validation_step_outputs.append((val_loss_main.detach(), val_output, loss_dict))\n        return val_loss_total\n\n    def on_validation_epoch_end(self):\n        losses_main, outputs, loss_dicts = zip(*self.validation_step_outputs)\n\n        epoch_loss_main = torch.stack([l for l in losses_main if l == l]).mean()\n        self.log('validation/loss_main_epoch', epoch_loss_main, on_epoch=True, logger=True, sync_dist=True)\n\n        perfs = self.evaluator(*zip(*outputs))\n\n        if isinstance(self.metric_name, str):\n            epoch_perf = perfs['metric_sum'] / perfs['metric_count']\n            self.log(f'validation/{self.metric_name}_epoch', epoch_perf, on_epoch=True, logger=True, sync_dist=True)\n        else:\n            assert isinstance(self.metric_name, list)\n            for metric_name in self.metric_name:\n                epoch_perf = perfs[metric_name]['metric_sum'] / perfs[metric_name]['metric_count']\n                self.log(f'validation/{metric_name}_epoch', epoch_perf, on_epoch=True, logger=True, sync_dist=True)\n\n        for loss_name in loss_dicts[0].keys():\n            losses = [loss_dict[loss_name]['value'] for loss_dict in loss_dicts]\n            loss_epoch_mean = torch.stack(losses).mean()\n            self.log(f'validation/loss_{loss_name}_epoch', loss_epoch_mean, on_epoch=True, logger=True, sync_dist=True)\n\n        self.validation_step_outputs.clear()\n\n    def test_step(self, batch, batch_idx):\n        x, y = self.parse_batch(batch)\n        y_hat, loss_dict = self.inference(x, n_samples=self.eval_sample_size)\n\n        test_output = (y_hat, y)\n\n        test_loss_total = 0\n        test_loss_main = self.criterion(y_hat, y)\n        test_loss_total = test_loss_total + (test_loss_main if torch.isfinite(test_loss_main) else 0)\n\n        for loss_name in loss_dict.keys():\n            test_loss_total = test_loss_total + loss_dict[loss_name]['weight'] * loss_dict[loss_name]['value']\n\n        self.test_step_outputs.append((test_loss_main.detach(), test_output, loss_dict))\n        return test_loss_total\n\n    def on_test_epoch_end(self):\n        losses_main, outputs, loss_dicts = zip(*self.test_step_outputs)\n\n        epoch_loss_main = torch.stack([l for l in losses_main if l == l]).mean()\n        self.log('test/loss_main_epoch', epoch_loss_main, on_epoch=True, logger=True, sync_dist=True)\n\n        perfs = self.evaluator(*zip(*outputs))\n\n        if isinstance(self.metric_name, str):\n            epoch_perf = perfs['metric_sum'] / perfs['metric_count']\n            self.log(f'test/{self.metric_name}_epoch', epoch_perf, on_epoch=True, logger=True, sync_dist=True)\n        else:\n            assert isinstance(self.metric_name, list)\n            for metric_name in self.metric_name:\n                epoch_perf = perfs[metric_name]['metric_sum'] / perfs[metric_name]['metric_count']\n                self.log(f'test/{metric_name}_epoch', epoch_perf, on_epoch=True, logger=True, sync_dist=True)\n\n        for loss_name in loss_dicts[0].keys():\n            loss_epoch_mean = torch.stack([loss_dict[loss_name]['value'] for loss_dict in loss_dicts]).mean()\n            self.log(f'test/loss_{loss_name}_epoch', loss_epoch_mean, on_epoch=True, logger=True, sync_dist=True)\n\n        self.test_step_outputs.clear()\n"}
{"type": "source_file", "path": "src/symmetry/groups/SO.py", "content": "import torch\n\n\ndef samples_from_haar_distribution(d, bsize, device, dtype) -> torch.Tensor:\n    \"\"\"Random orthogonal matrices with determinant 1 drawn from SO(d) Haar distribution\n    Adopted from scipy.stats.special_ortho_group, which implements the algorithm described in\n    Mezzadri, How to generate random matrices from the classical compact groups (2006)\n    \"\"\"\n    # H represents a (dim, dim) matrix, while D represents the diagonal of\n    # a (dim, dim) diagonal matrix. The algorithm that follows is\n    # broadcasted on the leading shape in `size` to vectorize along\n    # samples.\n    H = torch.empty(bsize, d, d, device=device, dtype=dtype)\n    H[..., :, :] = torch.eye(d, device=device, dtype=dtype)\n    D = torch.empty(bsize, d, device=device, dtype=dtype).fill_(float('inf'))\n    for n in range(d-1):\n        # x is a vector with length dim-n, xrow and xcol are views of it as\n        # a row vector and column vector respectively. It's important they\n        # are views and not copies because we are going to modify x\n        # in-place.\n        x = torch.randn(bsize, d-n, device=device, dtype=dtype)\n        xrow = x[..., None, :]\n        xcol = x[..., :, None]\n\n        # This is the squared norm of x, without vectorization it would be\n        # dot(x, x), to have proper broadcasting we use matmul and squeeze\n        # out (convert to scalar) the resulting 1x1 matrix\n        norm2 = torch.matmul(xrow, xcol).squeeze((-2, -1))\n\n        x0 = x[..., 0].clone()\n        D[..., n] = torch.where(x0 != 0, torch.sign(x0), 1)\n        x[..., 0] += D[..., n] * torch.sqrt(norm2)\n\n        # In renormalizing x we have to append an additional axis with\n        # [..., None] to broadcast the scalar against the vector x\n        x /= torch.sqrt((norm2 - x0**2 + x[..., 0]**2) / 2.)[..., None]\n\n        # Householder transformation, without vectorization the RHS can be\n        # written as outer(H @ x, x) (apart from the slicing)\n        H[..., :, n:] -= torch.matmul(H[..., :, n:], xcol) * xrow\n\n    D[..., -1] = (-1)**(d-1) * D[..., :-1].prod(dim=-1)\n\n    # Without vectorization this could be written as H = diag(D) @ H,\n    # left-multiplication by a diagonal matrix amounts to multiplying each\n    # row of H by an element of the diagonal, so we add a dummy axis for\n    # the column index\n    H *= D[..., :, None]\n    return H\n"}
{"type": "source_file", "path": "src/train/__init__.py", "content": "from .configure_data import configure_data\nfrom .configure_model import configure_model\nfrom .configure_experiment import configure_experiment\n"}
{"type": "source_file", "path": "src/optim/__init__.py", "content": "from .optim import OptimizerConfig\nfrom .lr_scheduler import LRSchedulerConfig\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/dataset/__init__.py", "content": "from .dataset import PlanarSATPairsDataset, GRAPH8cDataset\n"}
{"type": "source_file", "path": "src/symmetry/groups/U.py", "content": "import math\nimport torch\n\n\ndef samples_from_haar_distribution(d, bsize, device, dtype) -> torch.Tensor:\n    \"\"\"Random unitary matrices drawn from U(d) Haar distribution\n    Adopted from scipy.stats.unitary_group, which implements the algorithm described in\n    Mezzadri, How to generate random matrices from the classical compact groups (2006)\n    \"\"\"\n    z = 1 / math.sqrt(2) * (\n        torch.randn(bsize, d, d, device=device, dtype=dtype) +\n        1j * torch.randn(bsize, d, d, device=device, dtype=dtype)\n    )\n    q, r = torch.linalg.qr(z)\n    # The last two dimensions are the rows and columns of R matrices.\n    # Extract the diagonals. Note that this eliminates a dimension.\n    d = r.diagonal(offset=0, dim1=-2, dim2=-1)\n    # Add back a dimension for proper broadcasting: we're dividing\n    # each row of each R matrix by the diagonal of the R matrix.\n    q *= (d/abs(d))[..., None, :]  # to broadcast properly\n    return q\n"}
{"type": "source_file", "path": "src/symmetry/groups/S.py", "content": "# pylint: disable=line-too-long\nimport torch\n\n\ndef samples_from_haar_distribution_constant_n(n, bsize, device, dtype) -> torch.Tensor:\n    \"\"\"Random permutations within given numbers of nodes\"\"\"\n    # sample permutations\n    scores = torch.rand(bsize, n, device=device, dtype=dtype)\n    perms = scores.argsort(dim=-1)\n    gs = torch.eye(n, device=device, dtype=dtype)[None].expand(bsize, -1, -1)\n    gs = gs.gather(1, perms[..., None].expand(-1, -1, n))\n    return gs\n\n\ndef samples_from_haar_distribution(num_nodes: torch.Tensor, n, bsize, device, dtype) -> torch.Tensor:\n    \"\"\"Random permutations within given numbers of nodes\"\"\"\n    # handle broadcasted case (n_samples > 1)\n    n_samples = bsize // num_nodes.size(0)\n    if n_samples > 1:\n        num_nodes = num_nodes[None, ...].expand(n_samples, *num_nodes.shape).reshape(-1, *num_nodes.shape[1:])\n    # get padding mask\n    tri = torch.triu(torch.ones(n, n, device=device, dtype=torch.bool), diagonal=1)\n    padding_mask = tri[num_nodes - 1]\n    # sample permutations\n    scores = torch.rand(bsize, n, device=device, dtype=dtype)\n    padding_scores = (torch.arange(n, device=device, dtype=dtype) + 10)[None, :].expand(bsize, -1)\n    scores[padding_mask] = padding_scores[padding_mask]\n    perms = scores.argsort(dim=-1)\n    gs = torch.eye(n, device=device, dtype=dtype)[None].expand(bsize, -1, -1)\n    gs = gs.gather(1, perms[..., None].expand(-1, -1, n))\n    return gs\n"}
{"type": "source_file", "path": "src/symmetry/prob/__init__.py", "content": "from . import S\n"}
{"type": "source_file", "path": "src/symmetry/projections.py", "content": "from typing import Tuple, List\nimport torch\nfrom torch import nn\n\nfrom .symmetry import Symmetry, is_order_zero_rep\n\n\ndef _sum(k):\n    return k if isinstance(k, int) else sum(k)\n\nclass InputProj(nn.Module):\n    proj: nn.ModuleList\n    proj_keys: List\n\n    def __init__(self, symmetry: Symmetry):\n        super().__init__()\n        self.symmetry = symmetry\n\n    def forward(self, xs: Tuple) -> torch.Tensor:\n        \"\"\"Projection from input representations to (N, L, D) tensor\"\"\"\n        assert [_sum(k) for k in self.proj_keys] == [x.ndim - 2 for x in xs]\n        return torch.stack([proj(x) for proj, x in zip(self.proj, xs)]).sum(0)\n\n\nclass OutputProj(nn.Module):\n    proj: nn.ModuleList\n    proj_keys: List\n\n    def __init__(self, symmetry: Symmetry):\n        super().__init__()\n        self.symmetry = symmetry\n\n    def forward(self, x_unpooled: torch.Tensor, x_pooled: torch.Tensor) -> Tuple:\n        \"\"\"Projection from (N, L, D) tensor to output representations\"\"\"\n        return tuple(proj(x_pooled if is_order_zero_rep(k) else x_unpooled) for proj, k in\n                     zip(self.proj, self.proj_keys))\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/exp_iso.py", "content": "# pylint: disable=not-callable,line-too-long\n# https://github.com/omri1348/Frame-Averaging/blob/master/graph_separation/exp_iso.py\nimport random\nimport numpy as np\nimport torch\nfrom torch_geometric.loader import DataLoader\n\nfrom args import get_args\nfrom dataset import PlanarSATPairsDataset\nfrom preprocess import PrecomputeSpectral, PrecomputeSortFrame, PrecomputePad\nfrom interface import InterfacedModel\n\n\ndef main(args):\n    # configure device\n    device = torch.device(f'cuda:{args.device_id}' if torch.cuda.is_available() else 'cpu')\n\n    # configure data\n    pre_transform = PrecomputeSpectral(nmax=64, recfield=1, dv=2, nfreq=5, adddegree=True)\n    pre_transform = PrecomputeSortFrame(pre_transform, device)\n    transform = PrecomputePad(nmax=64)\n    dataset = PlanarSATPairsDataset(root='dataset/EXP/', transform=transform, pre_transform=pre_transform)\n    train_loader = DataLoader(dataset, args.batch_size, shuffle=False)\n\n    # main loop\n    M = 0\n    for seed in range(100):\n        random.seed(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\n        # configure model\n        model = InterfacedModel(\n            n=64,\n            d=2,\n            interface=args.interface,\n            num_interface_layers=args.num_interface_layers,\n            backbone=args.backbone,\n            noise_scale=args.noise_scale,\n            tau=args.tau,\n            hard=args.hard,\n            task='EXPiso'\n        ).to(device)\n\n        # run test\n        embeddings = []\n        model.eval()\n        for data in train_loader:\n            data = data.to(device)\n            emb, _ = model(data, n_samples=args.eval_sample_size)\n            embeddings.append(emb)\n\n        E = torch.cat(embeddings).cpu().detach().numpy()\n        M = M+1*(np.abs(E[0::2]-E[1::2]).sum(1) > 0.001)\n        sm = (M == 0).sum()\n        print('similar:', sm)\n\n\nif __name__ == '__main__':\n    args_ = get_args()\n    main(args_)\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/exp_classify_analysis.py", "content": "# pylint: disable=not-callable,line-too-long\nimport os\nimport sys\nimport argparse\nfrom pathlib import Path\nimport json\nimport random\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport torch\nfrom torch_geometric.loader import DataLoader\n\nfrom args import add_args\nfrom exp_classify import configure_device, configure_experiment_name\nfrom dataset import PlanarSATPairsDataset\nfrom preprocess import PrecomputeSpectral, PrecomputeSortFrame, PrecomputePad\nfrom interface import InterfacedModel\nfrom analysis import analyze_interface, analyze_forward, analyze_backward\n\n\ndef get_args() -> argparse.Namespace:\n    # parse arguments\n    parser = argparse.ArgumentParser('Probabilistic Symmetrization')\n    # experiment arguments\n    parser = add_args(parser)\n    # analysis arguments\n    parser.add_argument('--all_epochs', action='store_true')\n    parser.add_argument('--compile_results', action='store_true')\n    args = parser.parse_args()\n    return args\n\n\ndef configure_data(args):\n    device = configure_device(args)\n    # setup dataset\n    pre_transform = PrecomputeSpectral(nmax=64, recfield=1, dv=2, nfreq=5, adddegree=True)\n    pre_transform = PrecomputeSortFrame(pre_transform, device)\n    transform = PrecomputePad(nmax=64)\n    dataset = PlanarSATPairsDataset(root='dataset/EXP/', transform=transform, pre_transform=pre_transform)\n    # setup loaders\n    val_loader = DataLoader(dataset[0:200], args.batch_size, shuffle=False, pin_memory=True, num_workers=0)\n    test_loader = DataLoader(dataset[200:400], args.batch_size, shuffle=False, pin_memory=True, num_workers=0)\n    train_loader = DataLoader(dataset[400:1200], args.batch_size, shuffle=False, pin_memory=True, num_workers=0)\n    return train_loader, val_loader, test_loader\n\n\ndef configure_model(args):\n    # setup save directory\n    exp_name = configure_experiment_name(args)\n    ckpt_dir = Path(args.save_dir) / exp_name\n    assert ckpt_dir.exists(), f'checkpoint directory {ckpt_dir} does not exist'\n    # setup model\n    device = configure_device(args)\n    model = InterfacedModel(\n        n=64,\n        d=2,\n        interface=args.interface,\n        num_interface_layers=args.num_interface_layers,\n        backbone=args.backbone,\n        fixed_noise=args.fixed_noise,\n        noise_scale=args.noise_scale,\n        tau=args.tau,\n        hard=args.hard,\n        task='EXPclassify',\n        backbone_seed=args.backbone_seed,\n        interface_seed=args.interface_seed\n    ).to(device)\n    return model, ckpt_dir.as_posix()\n\n\ndef configure_experiment(args):\n    # setup log directory\n    exp_name = configure_experiment_name(args)\n    log_dir = Path(args.log_dir) / exp_name\n    assert log_dir.exists(), f'log directory {log_dir} does not exist'\n    return log_dir.as_posix()\n\n\ndef analyze(model, log_dir, epoch, train_loader, val_loader, device, args):\n    # analyze\n    val_entropy_list = analyze_interface(model, log_dir, epoch, val_loader, device, args)\n    val_pred_std_dict, val_loss_mean_dict, val_loss_std_dict = analyze_forward(model, val_loader, device)\n    backbone_grad_norm_list, backbone_grad_direction_norm = analyze_backward(model, train_loader, device, args)\n    # organize\n    val_entropy = np.mean(val_entropy_list)\n    backbone_grad_norm = np.mean(backbone_grad_norm_list)\n    # save results as json\n    results_dict = {\n        'val_entropy': val_entropy,\n        'backbone_grad_norm': backbone_grad_norm,\n        'backbone_grad_direction_norm': backbone_grad_direction_norm,\n        'val_pred_std_dict': val_pred_std_dict,\n        'val_loss_mean_dict': val_loss_mean_dict,\n        'val_loss_std_dict': val_loss_std_dict\n    }\n    results_path = Path(log_dir) / f'epoch_{epoch}.json'\n    with open(results_path.as_posix(), 'w', encoding='utf-8') as f:\n        json.dump(results_dict, f)\n    # return\n    results = (\n        val_entropy,\n        backbone_grad_norm,\n        backbone_grad_direction_norm,\n        val_pred_std_dict,\n        val_loss_mean_dict,\n        val_loss_std_dict\n    )\n    return results\n\n\ndef save_results(results_list, epochs_list, log_dir, args):\n    # extract\n    (\n        val_entropy_list,\n        backbone_grad_norm_list,\n        backbone_grad_direction_norm_list,\n        val_pred_std_dict_list,\n        val_loss_mean_dict_list,\n        val_loss_std_dict_list,\n    ) = zip(*results_list)\n    eval_sample_size_list = list(val_pred_std_dict_list[0].keys())\n    colors = plt.colormaps.get_cmap('viridis').resampled(len(eval_sample_size_list)).colors\n    # plot val entropy\n    plt.figure()\n    plt.plot(epochs_list, val_entropy_list)\n    plt.xlabel('epoch')\n    plt.ylabel('entropy')\n    plt.savefig(Path(log_dir) / 'entropy_val.pdf')\n    plt.close()\n    # plot grad norm\n    plt.figure()\n    plt.plot(epochs_list, backbone_grad_norm_list)\n    plt.xlabel('epoch')\n    plt.ylabel('grad norm')\n    plt.savefig(Path(log_dir) / 'grad_norm.pdf')\n    # plot grad direction norm\n    plt.figure()\n    plt.plot(epochs_list, backbone_grad_direction_norm_list)\n    plt.xlabel('epoch')\n    plt.ylabel('grad direction norm')\n    plt.savefig(Path(log_dir) / 'grad_direction_norm.pdf')\n    plt.close()\n    # plot output (logit) std\n    plt.figure()\n    for eval_sample_size, color in zip(eval_sample_size_list, colors):\n        val_pred_std_list = [val_pred_std_dict[eval_sample_size] for val_pred_std_dict in val_pred_std_dict_list]\n        plt.plot(epochs_list, val_pred_std_list, label=f'{eval_sample_size} samples', color=color)\n    plt.xlabel('epoch')\n    plt.ylabel('output std')\n    plt.legend()\n    plt.savefig(Path(log_dir) / 'output_std.pdf')\n    plt.close()\n    # plot loss mean\n    plt.figure()\n    for eval_sample_size, color in zip(eval_sample_size_list, colors):\n        val_loss_mean_list = [val_loss_mean_dict[eval_sample_size] for val_loss_mean_dict in val_loss_mean_dict_list]\n        plt.plot(epochs_list, val_loss_mean_list, label=f'{eval_sample_size} samples', color=color)\n    plt.xlabel('epoch')\n    plt.ylabel('loss mean')\n    plt.legend()\n    plt.savefig(Path(log_dir) / 'loss_mean.pdf')\n    plt.close()\n    # plot loss std\n    plt.figure()\n    for eval_sample_size, color in zip(eval_sample_size_list, colors):\n        val_loss_std_list = [val_loss_std_dict[eval_sample_size] for val_loss_std_dict in val_loss_std_dict_list]\n        plt.plot(epochs_list, val_loss_std_list, label=f'{eval_sample_size} samples', color=color)\n    plt.xlabel('epoch')\n    plt.ylabel('loss std')\n    plt.legend()\n    plt.savefig(Path(log_dir) / 'loss_std.pdf')\n    plt.close()\n    if args.all_epochs:\n        # plot output (logit) std at initialization\n        plt.figure()\n        plt.plot(*zip(*sorted(val_pred_std_dict_list[0].items())))\n        plt.xlabel('sample size')\n        plt.ylabel('output std')\n        plt.savefig(Path(log_dir) / 'output_std_init.pdf')\n        plt.close()\n        # plot loss mean at initialization\n        plt.figure()\n        plt.plot(*zip(*sorted(val_loss_mean_dict_list[0].items())))\n        plt.xlabel('sample size')\n        plt.ylabel('loss mean')\n        plt.savefig(Path(log_dir) / 'loss_mean_init.pdf')\n        plt.close()\n        # plot loss std at initialization\n        plt.figure()\n        plt.plot(*zip(*sorted(val_loss_std_dict_list[0].items())))\n        plt.xlabel('sample size')\n        plt.ylabel('loss std')\n        plt.savefig(Path(log_dir) / 'loss_std_init.pdf')\n        plt.close()\n\n\ndef read_results(log_dir, epoch):\n    # read log_dir / epoch_{epoch}.json\n    results_path = Path(log_dir) / f'epoch_{epoch}.json'\n    with open(results_path.as_posix(), 'r', encoding='utf-8') as f:\n        results_dict = json.load(f)\n    return results_dict\n\n\ndef compile_results(args):\n    # configure experiments\n    args.hard = True\n    args.interface = 'unif'\n    log_dir_ga = configure_experiment(args)\n    args.interface = 'prob'\n    args.sample_size = 1\n    log_dir_ps_1 = configure_experiment(args)\n    args.sample_size = 2\n    log_dir_ps_2 = configure_experiment(args)\n    args.sample_size = 5\n    log_dir_ps_5 = configure_experiment(args)\n    args.sample_size = 10\n    log_dir_ps = configure_experiment(args)\n    log_dir_ps_10 = configure_experiment(args)\n    args.sample_size = 20\n    log_dir_ps_20 = configure_experiment(args)\n    args.sample_size = 50\n    log_dir_ps_50 = configure_experiment(args)\n    # analyze ps in comparison to ga\n    epochs_list = [100, 500, 1000, 1500, 2000]\n    entropy_ga = [read_results(log_dir_ga, epoch)['val_entropy'] for epoch in epochs_list]\n    entropy_ps = [read_results(log_dir_ps, epoch)['val_entropy'] for epoch in epochs_list]\n    grad_norm_ga = [read_results(log_dir_ga, epoch)['backbone_grad_direction_norm'] for epoch in epochs_list]\n    grad_norm_ps = [read_results(log_dir_ps, epoch)['backbone_grad_direction_norm'] for epoch in epochs_list]\n    pred_std_ga = read_results(log_dir_ga, '_init')['val_pred_std_dict']\n    pred_std_ps = read_results(log_dir_ps, '_init')['val_pred_std_dict']\n    loss_std_ga = read_results(log_dir_ga, '_init')['val_loss_std_dict']\n    loss_std_ps = read_results(log_dir_ps, '_init')['val_loss_std_dict']\n    pred_var_ga = {int(k): v ** 2 for k, v in pred_std_ga.items()}\n    pred_var_ps = {int(k): v ** 2 for k, v in pred_std_ps.items()}\n    loss_var_ga = {int(k): v ** 2 for k, v in loss_std_ga.items()}\n    loss_var_ps = {int(k): v ** 2 for k, v in loss_std_ps.items()}\n    print('entropy of permutation matrices averaged over validation samples')\n    print('ga: epoch, entropy')\n    print('\\n'.join([f'{k}, {v}' for k, v in zip(epochs_list, entropy_ga)]))\n    print('ps: epoch, entropy')\n    print('\\n'.join([f'{k}, {v}' for k, v in zip(epochs_list, entropy_ps)]))\n    print('\\ngradient norm of backbone averaged over training samples')\n    print('ga: epoch, grad norm')\n    print('\\n'.join([f'{k}, {v}' for k, v in zip(epochs_list, grad_norm_ga)]))\n    print('ps: epoch, grad norm')\n    print('\\n'.join([f'{k}, {v}' for k, v in zip(epochs_list, grad_norm_ps)]))\n    print('\\nvariance of estimated output')\n    print('ga: inference sample size, output variance')\n    print('\\n'.join([f'{k}, {v}' for k, v in sorted(pred_var_ga.items())]))\n    print('ps: inference sample size, output variance')\n    print('\\n'.join([f'{k}, {v}' for k, v in sorted(pred_var_ps.items())]))\n    print('\\nvariance of estimated loss')\n    print('ga: inference sample size, loss variance')\n    print('\\n'.join([f'{k}, {v}' for k, v in sorted(loss_var_ga.items())]))\n    print('ps: inference sample size, loss variance')\n    print('\\n'.join([f'{k}, {v}' for k, v in sorted(loss_var_ps.items())]))\n    # analyze ps on the effect of training sample size\n    entropy_ps = {\n        1: read_results(log_dir_ps_1, 'best')['val_entropy'],\n        2: read_results(log_dir_ps_2, 'best')['val_entropy'],\n        5: read_results(log_dir_ps_5, 'best')['val_entropy'],\n        10: read_results(log_dir_ps_10, 'best')['val_entropy'],\n        20: read_results(log_dir_ps_20, 'best')['val_entropy'],\n        50: read_results(log_dir_ps_50, 'best')['val_entropy']\n    }\n    pred_std_ps = {\n        1: read_results(log_dir_ps_1, 'best')['val_pred_std_dict'],\n        2: read_results(log_dir_ps_2, 'best')['val_pred_std_dict'],\n        5: read_results(log_dir_ps_5, 'best')['val_pred_std_dict'],\n        10: read_results(log_dir_ps_10, 'best')['val_pred_std_dict'],\n        20: read_results(log_dir_ps_20, 'best')['val_pred_std_dict'],\n        50: read_results(log_dir_ps_50, 'best')['val_pred_std_dict']\n    }\n    loss_std_ps = {\n        1: read_results(log_dir_ps_1, 'best')['val_loss_std_dict'],\n        2: read_results(log_dir_ps_2, 'best')['val_loss_std_dict'],\n        5: read_results(log_dir_ps_5, 'best')['val_loss_std_dict'],\n        10: read_results(log_dir_ps_10, 'best')['val_loss_std_dict'],\n        20: read_results(log_dir_ps_20, 'best')['val_loss_std_dict'],\n        50: read_results(log_dir_ps_50, 'best')['val_loss_std_dict']\n    }\n    loss_mean_ps = {\n        1: read_results(log_dir_ps_1, 'best')['val_loss_mean_dict'],\n        2: read_results(log_dir_ps_2, 'best')['val_loss_mean_dict'],\n        5: read_results(log_dir_ps_5, 'best')['val_loss_mean_dict'],\n        10: read_results(log_dir_ps_10, 'best')['val_loss_mean_dict'],\n        20: read_results(log_dir_ps_20, 'best')['val_loss_mean_dict'],\n        50: read_results(log_dir_ps_50, 'best')['val_loss_mean_dict']\n    }\n    pred_var_ps = {k: {int(kk): vv ** 2 for kk, vv in v.items()} for k, v in pred_std_ps.items()}\n    loss_var_ps = {k: {int(kk): vv ** 2 for kk, vv in v.items()} for k, v in loss_std_ps.items()}\n    loss_mean_ps = {k: {int(kk): vv for kk, vv in v.items()} for k, v in loss_mean_ps.items()}\n    print('\\nentropy of permutation matrices averaged over validation samples')\n    print('ps: train sample size, entropy')\n    print('\\n'.join([f'{k}, {v}' for k, v in entropy_ps.items()]))\n    print('\\nvariance of estimated output')\n    print('ps: train sample size, output variance for each inference sample size')\n    print('\\n'.join([f'{k}, {v}' for k, v in pred_var_ps.items()]))\n    print('\\nvariance of estimated loss')\n    print('ps: train sample size, loss variance for each inference sample size')\n    print('\\n'.join([f'{k}, {v}' for k, v in loss_var_ps.items()]))\n    print('\\nmean of estimated loss')\n    print('ps: train sample size, loss mean for each inference sample size')\n    print('\\n'.join([f'{k}, {v}' for k, v in loss_mean_ps.items()]))\n    print('done')\n\n\ndef main(args):\n    # reproducibility\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    torch.cuda.manual_seed_all(args.seed)\n    torch.use_deterministic_algorithms(True)\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n\n    # compile results if specified\n    if args.compile_results:\n        compile_results(args)\n        sys.exit()\n\n    # configure device\n    device = configure_device(args)\n\n    # configure data\n    train_loader, val_loader, _ = configure_data(args)\n\n    # configure model\n    model, ckpt_dir = configure_model(args)\n\n    # configure experiment\n    log_dir = configure_experiment(args)\n\n    # analyze\n    print(f'checkpoint directory found at src_synthetic/graph_separation/{ckpt_dir}')\n    epochs_list = []\n    results_list = []\n    if args.all_epochs:\n        # initialization\n        # setup\n        epoch = '_init'\n        # analyze\n        print('analyzing initialized model')\n        results = analyze(model, log_dir, epoch, train_loader, val_loader, device, args)\n        # record\n        epochs_list.append(-100)\n        results_list.append(results)\n        # main loop\n        for epoch in range(args.num_epochs + 1):\n            # setup\n            ckpt_path = Path(ckpt_dir) / f'epoch_{epoch}.ckpt'\n            if not ckpt_path.exists():\n                continue\n            # load\n            model.load_state_dict(torch.load(ckpt_path.as_posix(), map_location=device))\n            # analyze\n            print(f'analyzing epoch_{epoch}.ckpt')\n            results = analyze(model, log_dir, epoch, train_loader, val_loader, device, args)\n            # record\n            epochs_list.append(epoch)\n            results_list.append(results)\n    # best checkpoint\n    # setup\n    epoch = 'best'\n    ckpt_path = Path(ckpt_dir) / 'best.ckpt'\n    # load\n    model.load_state_dict(torch.load(ckpt_path.as_posix(), map_location=device))\n    # analyze\n    print('analyzing best.ckpt')\n    results = analyze(model, log_dir, epoch, train_loader, val_loader, device, args)\n    # record\n    epochs_list.append(args.num_epochs + 100)\n    results_list.append(results)\n    # save\n    save_results(results_list, epochs_list, log_dir, args)\n    # close\n    print(f'done, results saved to src_synthetic/graph_separation/{log_dir}')\n\n\nif __name__ == '__main__':\n    args_ = get_args()\n    main(args_)\n"}
{"type": "source_file", "path": "src/symmetry/prob/S.py", "content": "# pylint:disable=line-too-long,too-many-instance-attributes,too-many-arguments,too-many-locals,redefined-outer-name,unused-argument,unused-variable,protected-access\nimport numpy as np\nimport torch\nfrom torch import nn, Tensor as T\nfrom torch.nn import functional as F\nimport torch_sparse\n\n\nclass MLP(nn.Module):\n    def __init__(self, num_layers, input_dim, hidden_dim, output_dim, dropout):\n        super().__init__()\n        assert num_layers > 1, \"number of layers must be greater than 1\"\n        self.num_layers = num_layers\n        self.linear_layers = nn.ModuleList()\n        self.norms = nn.ModuleList()\n        self.dropout = nn.Dropout(dropout)\n        self.linear_layers.append(nn.Linear(input_dim, hidden_dim))\n        for _ in range(num_layers - 2):\n            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n        self.linear_layers.append(nn.Linear(hidden_dim, output_dim))\n        for _ in range(num_layers - 1):\n            self.norms.append(nn.BatchNorm1d(hidden_dim))\n        # initialize batchnorm statistics and bias\n        for m in self.modules():\n            if isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        for i in range(self.num_layers - 1):\n            x = self.linear_layers[i](x)\n            x = self.norms[i](x)\n            x = F.relu(x)\n            x = self.dropout(x)\n        return self.linear_layers[self.num_layers - 1](x)\n\n\nclass GIN(nn.Module):\n    def __init__(\n        self,\n        num_layers,\n        num_mlp_layers,\n        input_dim,\n        hidden_dim,\n        output_dim,\n        dropout,\n        learn_eps,\n        initial_eps\n    ):\n        \"\"\"\n        num_layers: including input layer, excluding output layer\n        num_mlp_layers: number of nn.Linear layers in each MLP block \n        \"\"\"\n        super().__init__()\n        self.num_layers = num_layers\n        if initial_eps is None:\n            eps = torch.tensor([np.random.uniform() for _ in range(num_layers)])\n        else:\n            eps = torch.tensor(initial_eps).float().repeat(num_layers)\n        if learn_eps:\n            self.eps = nn.Parameter(eps)\n        else:\n            self.register_buffer('eps', eps)\n        self.mlps = nn.ModuleList()\n        self.mlps.append(MLP(num_mlp_layers, input_dim, hidden_dim, hidden_dim, dropout))\n        for _ in range(num_layers - 1):\n            self.mlps.append(MLP(num_mlp_layers, hidden_dim, hidden_dim, hidden_dim, dropout))\n        self.norms = nn.ModuleList()\n        for _ in range(num_layers):\n            self.norms.append(nn.BatchNorm1d(hidden_dim))\n        self.head = nn.Linear(hidden_dim, output_dim)\n        # initialize batchnorm statistics and bias\n        for m in self.modules():\n            if isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def layer_forward(self, x, sparse_adj, layer_idx):\n        x_pool = torch_sparse.matmul(sparse_adj.t().float(), x.float()).to(x.dtype)\n        x = x_pool + (1 + self.eps[layer_idx]) * x\n        x = self.mlps[layer_idx](x)\n        x = self.norms[layer_idx](x)\n        x = F.relu(x)\n        return x\n\n    def forward(self, x: torch.tensor, edge_index: torch.tensor):\n        # x: [sum(n), input_dim]\n        # edge_index: [2, sum(e)]\n        assert x.ndim == edge_index.ndim == 2\n        n, _ = x.shape\n        # create sparse adj\n        row, col = edge_index\n        sparse_adj = torch_sparse.SparseTensor(row=row, col=col, sparse_sizes=(n, n))\n        # forward\n        for i in range(self.num_layers):\n            x = self.layer_forward(x, sparse_adj, i)\n        x = self.head(x)\n        # x: [sum(n), output_dim]\n        return x\n\n\n@torch.no_grad()\ndef compute_edge_mask(n_edges: T, n: int):\n    b = n_edges.shape[0]\n    idxs = torch.arange(0, n*n, device=n_edges.device)[None, :].expand(b, n*n)\n    edge_mask = idxs < n_edges[:, None]\n    return edge_mask\n\n\n@torch.no_grad()\ndef increment_edge_idx(edge_idx: T, mask: T, h: int):\n    b, l = mask.shape\n    device = edge_idx.device\n    increment = torch.arange(start=0, end=h*(b-1)+1, step=h, device=device)\n    increment = increment[:, None, None].expand(b, 2, l)\n    new_edge_idx = edge_idx + increment\n    mask = mask.unsqueeze(1).expand(b, 2, l)\n    new_edge_idx[~mask] = -1\n    return new_edge_idx\n\n\n@torch.no_grad()\ndef compute_k_edge_idx(edge_idx: T, mask: T, h: int, k: int):\n    b, _, l = edge_idx.shape\n    k_edge_idx = edge_idx.unsqueeze(1).expand(b, k, 2, l)\n    k_edge_idx = k_edge_idx.reshape(b*k, 2, l)\n    k_mask = mask.unsqueeze(1).expand(b, k, l)\n    k_mask = k_mask.reshape(b*k, l)\n    k_edge_idx = increment_edge_idx(k_edge_idx, k_mask, h=h)\n    return k_edge_idx, k_mask\n\n\ndef flatten_edge_idx(edge_idx: T, mask: T):\n    device = edge_idx.device\n    result = torch.zeros(2, mask.sum(), dtype=edge_idx.dtype, device=device)\n    result[0] = edge_idx[:, 0, :][mask]\n    result[1] = edge_idx[:, 1, :][mask]\n    return result\n\n\n@torch.no_grad()\ndef compute_node_mask(n_nodes: T, n: int):\n    b = n_nodes.shape[0]\n    idxs = torch.arange(0, n, device=n_nodes.device)[None, :].expand(b, n)\n    node_mask = idxs < n_nodes[:, None]\n    return node_mask\n\n\n@torch.no_grad()\ndef compute_node_pair_mask(node_mask: T):\n    b, n = node_mask.shape\n    mask1 = node_mask[:, None, :].expand(b, n, n)\n    mask2 = node_mask[:, :, None].expand(b, n, n)\n    node_pair_mask = torch.logical_and(mask1, mask2)\n    return node_pair_mask\n\n\nclass PermutaionMatrixPenalty(nn.Module):\n    def __init__(self, n):\n        super().__init__()\n        self.n = n\n\n    @staticmethod\n    def _normalize(scores, axis, eps=1e-12):\n        normalizer = torch.sum(scores, axis).clamp(min=eps)\n        normalizer = normalizer.unsqueeze(axis)\n        prob = torch.div(scores, normalizer)\n        return prob\n\n    @staticmethod\n    def _entropy(prob, axis):\n        return -torch.sum(prob * prob.log().clamp(min=-100), axis)\n\n    def entropy(self, scores, node_mask, eps=1e-12):\n        b, k, n, _ = scores.shape\n        # clamp min to avoid zero logarithm\n        scores = scores.clone()\n        node_pair_mask = compute_node_pair_mask(node_mask)\n        node_pair_mask = node_pair_mask[:, None, :, :].expand(b, k, n, n)\n        scores[node_pair_mask] = scores[node_pair_mask].clamp(min=eps)\n        # compute columnwise entropy\n        col_prob = self._normalize(scores, axis=2)\n        col_prob = torch.where(node_pair_mask, col_prob, torch.ones_like(scores))\n        entropy_col = self._entropy(col_prob, axis=2)\n        # compute rowwise entropy\n        row_prob = self._normalize(scores, axis=3)\n        row_prob = torch.where(node_pair_mask, row_prob, torch.ones_like(scores))\n        entropy_row = self._entropy(row_prob, axis=3)\n        # return entropy\n        assert entropy_col.shape == entropy_row.shape == (b, k, n)\n        return entropy_col, entropy_row\n\n    def forward(self, perm_soft: T, n_nodes: T):\n        b, k, n, _ = perm_soft.shape\n        assert n == self.n\n        assert perm_soft.shape == (b, k, n, n)\n        # compute node mask\n        node_mask = compute_node_mask(n_nodes, n)\n        # compute entropy\n        entropy_col, entropy_row = self.entropy(perm_soft, node_mask)\n        # compute mean over samples\n        loss = entropy_col.mean(1) + entropy_row.mean(1)\n        # compute mean over nodes\n        loss[~node_mask] = 0\n        loss = loss.sum(1) / n_nodes\n        # compute mean over batch\n        loss = loss.mean()\n        return loss\n\n\nclass EquivariantInterface(nn.Module):\n    def __init__(\n            self,\n            noise_scale,\n            tau,\n            hard,\n            rep_dim,\n            node_rep_channels,\n            interface_num_layers,\n            interface_hidden_dim,\n            interface_dropout\n        ):\n        super().__init__()\n        self.noise_scale = noise_scale\n        self.tau = tau\n        self.hard = hard\n        self.n = rep_dim\n        self.d = node_rep_channels\n        self.use_virtual_node = True\n        # build graph isomorphism network\n        self.gin_interface = GIN(\n            num_layers=interface_num_layers,\n            num_mlp_layers=2,\n            input_dim=self.d,\n            hidden_dim=interface_hidden_dim,\n            output_dim=1,\n            dropout=interface_dropout,\n            learn_eps=True,\n            initial_eps=None\n        )\n        self.virtual_node = nn.Parameter(torch.randn(self.d))\n        # entropy loss for soft permutation matrix\n        self.compute_entropy_loss = PermutaionMatrixPenalty(self.n)\n\n    def compute_pad_edge_idx(self, batch):\n        b = batch.num_graphs\n        node_ptr = batch.ptr\n        edge_ptr = batch._slice_dict['edge_index'].to(node_ptr.device)\n        num_edges = edge_ptr[1:] - edge_ptr[:-1]\n        edge_index_offset = node_ptr[:-1].repeat_interleave(num_edges)\n        edge_index = batch.edge_index - edge_index_offset[None, :]\n        edge_mask = compute_edge_mask(num_edges, self.n)\n        pad_edge_idx = torch.zeros(b, 2, self.n*self.n,\n                                   dtype=edge_index.dtype,\n                                   device=edge_index.device).fill_(-1)\n        pad_edge_idx[:, 0, :][edge_mask] = edge_index[0]\n        pad_edge_idx[:, 1, :][edge_mask] = edge_index[1]\n        return pad_edge_idx\n\n    def _add_vnode_x(self, x: T):\n        b, n, d = x.shape\n        new_x = torch.zeros(b, 1+n, d, dtype=x.dtype, device=x.device)\n        new_x[:, 1:, :] = x\n        new_x[:, 0, :] = self.virtual_node[None, :].expand(b, d)\n        return new_x\n\n    @torch.no_grad()\n    def _add_vnode_node_mask(self, n_nodes: T):\n        b, n = n_nodes.shape[0], self.n\n        new_n_nodes = 1 + n_nodes\n        idx = torch.arange(0, 1+n, device=n_nodes.device)\n        idx = idx[None, :].expand(b, 1+n)\n        new_node_mask = idx < new_n_nodes[:, None]\n        return new_node_mask\n\n    @torch.no_grad()\n    def _add_vnode_edge_idx(self, edge_idx: T, n_nodes: T, n_edges: T):\n        b, n = n_nodes.shape[0], self.n\n        device, dtype = edge_idx.device, edge_idx.dtype\n        # initialize edge_idx with virtual node\n        new_pad_edge_idx = torch.zeros(b, 2, (1+n)*(1+n), device=device, dtype=dtype)\n        # setup intermediate tensors\n        edge_mask = compute_edge_mask(n_edges, n)\n        new_idx = torch.arange(0, (1+n)*(1+n), device=device, dtype=dtype)\n        new_idx = new_idx[None, None, :].expand(b, 2, (1+n)*(1+n))\n        # first entry is self-loop on virtual node\n        # from second entry are edges connecting virtual node and original nodes\n        ve = torch.zeros(b, 2, n, device=device, dtype=dtype)\n        ve[:, 1, :] = torch.arange(n, device=device, dtype=dtype) + 1\n        # ev = ve[:, [1, 0], :]\n        idx = torch.arange(0, n, device=device, dtype=dtype)\n        idx = idx[None, :].expand(b, n)\n        idx_mask = idx < n_nodes[:, None]\n        idx_mask = idx_mask[:, None, :].expand(b, 2, n)\n        n_nodes = n_nodes[:, None, None].expand(b, 2, (1+n)*(1+n))\n        new_idx_mask = (new_idx >= 1) & (new_idx < 1 + n_nodes)\n        new_pad_edge_idx[new_idx_mask] = ve[idx_mask]\n        new_idx_mask = (new_idx >= 1 + n_nodes) & (new_idx < 1 + 2 * n_nodes)\n        new_pad_edge_idx[new_idx_mask] = ve[:, [1, 0], :][idx_mask]\n        # the remaining are edges connecting original nodes\n        # ee = pad_edge_idx + 1\n        idx_mask = edge_mask[:, None, :].expand(b, 2, n*n)\n        n_edges = n_edges[:, None, None].expand(b, 2, (1+n)*(1+n))\n        new_idx_mask = (new_idx >= 1 + 2 * n_nodes) & (new_idx < 1 + 2 * n_nodes + n_edges)\n        new_pad_edge_idx[new_idx_mask] = (edge_idx + 1)[idx_mask]\n        return new_pad_edge_idx\n\n    @torch.no_grad()\n    def _add_vnode_edge_mask(self, n_nodes: T, n_edges: T, dtype):\n        b, n = n_nodes.shape[0], self.n\n        n_total = (1 + 2 * n_nodes + n_edges)[:, None]\n        idx = torch.arange(0, (1+n)*(1+n), device=n_nodes.device, dtype=dtype)\n        idx = idx[None, :].expand(b, (1+n)*(1+n))\n        new_edge_mask = idx < n_total\n        return new_edge_mask\n\n    def add_vnode(self, x, edge_idx, n_nodes, n_edges):\n        b, n, _ = x.shape\n        assert n == self.n\n        assert edge_idx.shape == (b, 2, n*n)\n        assert n_nodes.shape == n_edges.shape == (b,)\n        new_x = self._add_vnode_x(x)\n        new_node_mask = self._add_vnode_node_mask(n_nodes)\n        new_pad_edge_idx = self._add_vnode_edge_idx(edge_idx, n_nodes, n_edges)\n        new_edge_mask = self._add_vnode_edge_mask(n_nodes, n_edges, edge_idx.dtype)\n        return new_x, new_pad_edge_idx, new_node_mask, new_edge_mask\n\n    def repeat(self, x: T, edge_idx: T, node_mask: T, edge_mask: T, k: int):\n        b, n, d = x.shape\n        _, _, l = edge_idx.shape\n        assert edge_idx.shape == (b, 2, l)\n        assert node_mask.shape == (b, n)\n        assert edge_mask.shape == (b, l)\n        x = x[:, None, :, :].expand(b, k, n, d).reshape(b * k, n, d)\n        node_mask = node_mask[:, None, :].expand(b, k, n).reshape(b * k, n)\n        edge_idx = edge_idx[:, None, :, :].expand(b, k, 2, l).reshape(b * k, 2, l)\n        edge_mask = edge_mask[:, None, :].expand(b, k, l).reshape(b * k, l)\n        return x, edge_idx, node_mask, edge_mask\n\n    @torch.no_grad()\n    def _incr_edge_idx(self, edge_idx: T, edge_mask: T, step: int):\n        # batch increment edge_idx by step\n        b, _, l = edge_idx.shape\n        assert edge_idx.shape == (b, 2, l)\n        assert edge_mask.shape == (b, l)\n        edge_mask = edge_mask[:, None, :].expand(b, 2, l)\n        incr = torch.arange(0, step*(b-1)+1, step, device=edge_idx.device)\n        assert incr.shape == (b,)\n        inc_edge_idx = edge_idx + incr[:, None, None]\n        inc_edge_idx[~edge_mask] = -1\n        assert inc_edge_idx.shape == (b, 2, l)\n        return inc_edge_idx\n\n    def pyg_format(self, x: T, edge_idx: T, node_mask: T, edge_mask: T):\n        b, n, d = x.shape\n        _, _, l = edge_idx.shape\n        assert edge_idx.shape == (b, 2, l)\n        assert node_mask.shape == (b, n)\n        assert edge_mask.shape == (b, l)\n        pyg_x = x.view(b*n, d)\n        n_total_edges = int(edge_mask.sum())\n        incr_edge_idx = self._incr_edge_idx(edge_idx, edge_mask, n)\n        pyg_edge_idx = torch.zeros(2, n_total_edges,\n                                   dtype=edge_idx.dtype,\n                                   device=edge_idx.device)\n        pyg_edge_idx[0] = incr_edge_idx[:, 0, :][edge_mask]\n        pyg_edge_idx[1] = incr_edge_idx[:, 1, :][edge_mask]\n        return pyg_x, pyg_edge_idx\n\n    def normalize_scores(self, scores: T, n_nodes: T, eps=1e-6):\n        # normalize scores considering masked nodes\n        # this does not affect hard permutation, but affects\n        # straight-through gradient from soft permutation matrix\n        b, k, n = scores.shape\n        assert n == self.n, f'{n} != {self.n}'\n        assert n_nodes.shape == (b,)\n        # compute node mask\n        node_mask = compute_node_mask(n_nodes, n)\n        node_mask = node_mask[:, None, :].expand(b, k, n)\n        n_nodes = n_nodes[:, None, None].expand(b, k, n)\n        # normalize\n        scores[~node_mask] = 0.\n        l2_norm = scores.pow(2).sum(2, keepdim=True).sqrt()\n        normalized_scores = scores / l2_norm.clamp(min=eps)\n        # mask\n        normalized_scores[~node_mask] = -float('inf')\n        return normalized_scores\n\n    def argsort(self, scores: T, n_nodes: T, sinkhorn_iter=20):\n        b, k, n = scores.shape\n        assert n == self.n\n        assert n_nodes.shape == (b,)\n        assert sinkhorn_iter >= 0\n        # compute node pair mask\n        node_mask = compute_node_mask(n_nodes, n)\n        node_pair_mask = compute_node_pair_mask(node_mask)\n        node_pair_mask = node_pair_mask[:, None, :, :].expand(b, k, n, n)\n        # sort scores, result is unique up to permutations of tied scores\n        scores = scores[:, :, :, None]\n        scores_sorted, indices = scores.sort(descending=True, dim=2)\n        scores = scores.expand(b, k, n, n)\n        scores_sorted = scores_sorted.transpose(2, 3).expand(b, k, n, n)\n        # softsort + log sinkhorn operator for computing soft permutation matrix\n        log_perm_soft = (scores - scores_sorted).abs().neg() / self.tau\n        log_zero = torch.zeros_like(log_perm_soft).fill_(-float('inf'))\n        for _ in range(sinkhorn_iter):\n            log_perm_soft = torch.where(node_pair_mask, log_perm_soft, log_zero)\n            log_perm_soft = log_perm_soft - torch.logsumexp(log_perm_soft, dim=-1, keepdim=True)\n            log_perm_soft[~torch.isfinite(log_perm_soft)] = -float('inf')\n            log_perm_soft = torch.where(node_pair_mask, log_perm_soft, log_zero)\n            log_perm_soft = log_perm_soft - torch.logsumexp(log_perm_soft, dim=-2, keepdim=True)\n            log_perm_soft[~torch.isfinite(log_perm_soft)] = -float('inf')\n        perm_soft = log_perm_soft.exp()\n        if self.hard:\n            # argsort for hard permutation matrix\n            with torch.no_grad():\n                perm_hard = torch.zeros_like(perm_soft).scatter(dim=-1, index=indices, value=1)\n                perm_hard = perm_hard.transpose(2, 3)\n                perm_hard[~node_pair_mask] = 0\n                # (optional) test if perm_hard is a permutation matrix\n                assert torch.allclose(perm_hard.sum(-1).mean(1), node_mask.to(perm_hard))\n                assert torch.allclose(perm_hard.sum(-2).mean(1), node_mask.to(perm_hard))\n            # differentiability with straight-through gradient\n            # the estimated gradient is accurate if perm_soft is close to perm_hard\n            # for this, entropy regularization is necessary\n            perm_hard = (perm_hard - perm_soft).detach() + perm_soft\n            return perm_hard, perm_soft\n        return perm_soft, perm_soft\n\n    def sample_invariant_noise(self, x):\n        z = torch.zeros_like(x).uniform_(0, self.noise_scale)\n        if self.use_virtual_node:\n            z[:, 0, :] = 0\n        return z\n\n    def forward(self, xs, batch, k):\n        # k is the number of interface samples\n        x, _ = xs\n        edge_idx = self.compute_pad_edge_idx(batch)\n        b, n, d = x.shape\n        assert n == self.n and d == self.d\n        assert edge_idx.shape == (b, 2, n*n)\n        # compute batch info\n        node_ptr = batch.ptr\n        edge_ptr = batch._slice_dict['edge_index'].to(node_ptr.device)\n        n_nodes = node_ptr[1:] - node_ptr[:-1]\n        n_edges = edge_ptr[1:] - edge_ptr[:-1]\n        # add virtual node and compute masks\n        if self.use_virtual_node:\n            x, edge_idx, node_mask, edge_mask = self.add_vnode(x, edge_idx, n_nodes, n_edges)\n            n = n + 1\n        else:\n            node_mask = compute_node_mask(n_nodes, n)\n            edge_mask = compute_edge_mask(n_edges, n)\n        # replicate input k times\n        x, edge_idx, node_mask, edge_mask = self.repeat(x, edge_idx, node_mask, edge_mask, k)\n        # add noise\n        x = x + self.sample_invariant_noise(x)\n        # remove masked nodes\n        x[~node_mask] = 0\n        # compute scores\n        scores = self.gin_interface(*self.pyg_format(x, edge_idx, node_mask, edge_mask))\n        assert scores.shape == (b*k*n, 1) and node_mask.shape == (b*k, n)\n        scores = scores.view(b, k, n)\n        node_mask = node_mask.view(b, k, n)\n        # add small noise to break ties\n        # without this, models can exploit the ordering of tied scores\n        scores = scores + torch.zeros_like(scores).uniform_(0, 1e-6)\n        # mask invalid nodes\n        scores[~node_mask] = -float('inf')\n        # remove virtual node from scores\n        if self.use_virtual_node:\n            scores = scores[:, :, 1:]\n            n = n - 1\n        # normalize\n        # this is optional, for improving training stability\n        scores = self.normalize_scores(scores, n_nodes)\n        # compute argsort and permutation without virtual node\n        perm, perm_soft = self.argsort(scores, n_nodes)\n        # compute entropy loss\n        entropy_loss = self.compute_entropy_loss(perm_soft, n_nodes)\n        # reshape permutation\n        perm = perm.view(b*k, n, n)\n        return perm, entropy_loss\n"}
{"type": "source_file", "path": "src/symmetry/projections_conv.py", "content": "# pylint: disable=too-many-arguments,unused-variable,too-many-instance-attributes,line-too-long,unused-argument,not-callable\nfrom typing import Optional, Callable, Tuple\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nfrom .symmetry import Symmetry\nfrom .projections import InputProj, OutputProj\n\n\nclass ConvInputProj(InputProj):\n    def __init__(self, symmetry: Symmetry, num_tokens: int, embed_dim: int, centering: bool, pad_mode: str, bias: bool=True):\n        super().__init__(symmetry)\n        proj_keys = []\n        proj = []\n        if 0 in symmetry.rep_in and 0 not in symmetry.ignore_rep_in:\n            proj_keys.append(0)\n            proj.append(Order0ConvInputProj(in_chans=symmetry.rep_in[0], num_tokens=num_tokens, embed_dim=embed_dim,\n                                            centering=centering, pad_mode=pad_mode, bias=bias))\n        if 1 in symmetry.rep_in and 1 not in symmetry.ignore_rep_in:\n            proj_keys.append(1)\n            proj.append(Order1ConvInputProj(seq_size=symmetry.rep_dim, in_chans=symmetry.rep_in[1], num_tokens=num_tokens, embed_dim=embed_dim,\n                                            centering=centering, pad_mode=pad_mode, bias=bias))\n        if 2 in symmetry.rep_in and 2 not in symmetry.ignore_rep_in:\n            proj_keys.append(2)\n            proj.append(Order2ConvInputProj(img_size=symmetry.rep_dim, in_chans=symmetry.rep_in[2], num_tokens=num_tokens, embed_dim=embed_dim,\n                                            centering=centering, pad_mode=pad_mode, bias=bias))\n        if (0, 0) in symmetry.rep_in and (0, 0) not in symmetry.ignore_rep_in:\n            proj_keys.append((0, 0))\n            proj.append(Order0ConvInputProj(in_chans=symmetry.rep_in[(0, 0)], num_tokens=num_tokens, embed_dim=embed_dim,\n                                            centering=centering, pad_mode=pad_mode, bias=bias))\n        if (1, 1) in symmetry.rep_in and (1, 1) not in symmetry.ignore_rep_in:\n            proj_keys.append((1, 1))\n            if symmetry.rep_dim[1] == 3:\n                print(f\"Point cloud inputs detected, using Order1ConvInputProj({symmetry.rep_dim[0]},) instead of Order1x1ConvInputProj({symmetry.rep_dim})\")\n                proj.append(Order1ConvInputProj(seq_size=symmetry.rep_dim[0], in_chans=symmetry.rep_dim[1] * symmetry.rep_in[(1, 1)], num_tokens=num_tokens, embed_dim=embed_dim,\n                                                centering=centering, pad_mode=pad_mode, bias=bias))\n            else:\n                proj.append(Order1x1ConvInputProj(img_size=symmetry.rep_dim, in_chans=symmetry.rep_in[(1, 1)], num_tokens=num_tokens, embed_dim=embed_dim,\n                                                  centering=centering, pad_mode=pad_mode, bias=bias))\n        for k in symmetry.rep_in:\n            assert k in proj_keys and k not in symmetry.ignore_rep_in, f\"Missing projection for {k}-order representation\"\n        self.proj_keys = proj_keys\n        self.proj = nn.ModuleList(proj)\n\n\nclass ConvOutputProj(OutputProj):\n    def __init__(self, symmetry: Symmetry, num_tokens: int, embed_dim: int, centering: bool, pad_mode: str, bias: bool=True):\n        super().__init__(symmetry)\n        proj_keys = []\n        proj = []\n        if 0 in symmetry.rep_out and 0 not in symmetry.ignore_rep_out:\n            proj_keys.append(0)\n            proj.append(nn.Linear(embed_dim, symmetry.rep_out[0], bias=bias))\n        if 1 in symmetry.rep_out and 1 not in symmetry.ignore_rep_out:\n            proj_keys.append(1)\n            proj.append(Order1ConvOutputProj(seq_size=symmetry.rep_dim, out_chans=symmetry.rep_out[1], num_tokens=num_tokens, embed_dim=embed_dim,\n                                             centering=centering, pad_mode=pad_mode, bias=bias))\n        if 2 in symmetry.rep_out and 2 not in symmetry.ignore_rep_out:\n            proj_keys.append(2)\n            proj.append(Order2ConvOutputProj(img_size=symmetry.rep_dim, out_chans=symmetry.rep_out[2], num_tokens=num_tokens, embed_dim=embed_dim,\n                                             centering=centering, pad_mode=pad_mode, bias=bias))\n        if (0, 0) in symmetry.rep_out and (0, 0) not in symmetry.ignore_rep_out:\n            proj_keys.append((0, 0))\n            proj.append(nn.Linear(embed_dim, symmetry.rep_out[(0, 0)], bias=bias))\n        if (1, 0) in symmetry.rep_out and (1, 0) not in symmetry.ignore_rep_out:\n            proj_keys.append((1, 0))\n            proj.append(Order1ConvOutputProj(seq_size=symmetry.rep_dim[0], out_chans=symmetry.rep_out[(1, 0)], num_tokens=num_tokens, embed_dim=embed_dim,\n                                             centering=centering, pad_mode=pad_mode, bias=bias))\n        for k in symmetry.rep_out:\n            assert k in proj_keys and k not in symmetry.ignore_rep_out, f\"Missing projection for {k}-order representation\"\n        self.proj_keys = proj_keys\n        self.proj = nn.ModuleList(proj)\n\n\ndef setup_1d(seq_size: int, num_tokens: int):\n    if num_tokens <= seq_size:\n        patch_size = (seq_size - 1) // num_tokens + 1\n        pad_size = (patch_size * num_tokens) - seq_size\n    else:\n        patch_size = 1\n        pad_size = num_tokens - seq_size\n    return patch_size, pad_size\n\n\nclass Order0ConvInputProj(nn.Module):\n    \"\"\"0D to Tokens\"\"\"\n    def __init__(self, in_chans: int, num_tokens: int, embed_dim: int, centering: bool, pad_mode: str, norm_layer: Optional[Callable]=None, bias: bool=True):\n        super().__init__()\n        self.num_tokens = num_tokens\n        self.proj = nn.Linear(in_chans, embed_dim, bias=bias)\n        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        assert x.ndim == 2\n        x = self.proj(x)\n        x = x.unsqueeze(1).repeat(1, self.num_tokens, 1)\n        x = self.norm(x)\n        return x\n\n\nclass Order1ConvInputProj(nn.Module):\n    \"\"\"1D to Tokens\"\"\"\n    def __init__(self, seq_size: int, in_chans: int, num_tokens: int, embed_dim: int, centering: bool, pad_mode: str, norm_layer: Optional[Callable]=None, bias: bool=True):\n        super().__init__()\n        patch_size, pad_size = setup_1d(seq_size, num_tokens)\n        self.seq_size = seq_size\n        self.pad_size = pad_size\n        self.centering = centering\n        self.pad_mode = pad_mode\n        self.proj = nn.Conv1d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, bias=bias)\n        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if x.ndim == 4:\n            # point cloud inputs, x is (B, N, 3, C)\n            assert x.size(1) == self.seq_size\n            x = x.flatten(2, 3)\n        B, L, C = x.shape\n        assert L == self.seq_size, f\"Input sequence length ({L}) doesn't match model ({self.seq_size}).\"\n        x = x.transpose(1, 2)\n\n        if not self.centering:\n            if self.pad_mode == 'zero':\n                x = F.pad(x, (0, self.pad_size))\n            elif self.pad_mode in ('replicate', 'circular'):\n                x = F.pad(x, (0, self.pad_size), mode=self.pad_mode)\n            elif self.pad_mode == 'reflect':\n                determinism = torch.are_deterministic_algorithms_enabled()\n                torch.use_deterministic_algorithms(False)\n                x = F.pad(x, (0, self.pad_size), mode='reflect')\n                torch.use_deterministic_algorithms(determinism)\n            else:\n                raise ValueError(f\"Invalid padding mode: {self.pad_mode}\")\n        else:\n            if self.pad_mode == 'zero':\n                x = F.pad(x, (self.pad_size // 2, self.pad_size - (self.pad_size // 2)))\n            elif self.pad_mode in ('replicate', 'circular'):\n                x = F.pad(x, (self.pad_size // 2, self.pad_size - (self.pad_size // 2)), mode=self.pad_mode)\n            elif self.pad_mode == 'reflect':\n                determinism = torch.are_deterministic_algorithms_enabled()\n                torch.use_deterministic_algorithms(False)\n                x = F.pad(x, (self.pad_size // 2, self.pad_size - (self.pad_size // 2)), mode='reflect')\n                torch.use_deterministic_algorithms(determinism)\n            else:\n                raise ValueError(f\"Invalid padding mode: {self.pad_mode}\")\n\n        x = self.proj(x)\n        x = x.transpose(1, 2)\n        x = self.norm(x)\n        return x\n\n\nclass Order1ConvOutputProj(nn.Module):\n    \"\"\"Tokens to 1D\"\"\"\n    def __init__(self, seq_size: int, out_chans: int, num_tokens: int, embed_dim: int, centering: bool, pad_mode: str, norm_layer: Optional[Callable]=None, bias: bool=True):\n        super().__init__()\n        patch_size, pad_size = setup_1d(seq_size, num_tokens)\n        self.num_tokens = num_tokens\n        self.pad_size = pad_size\n        if centering:\n            raise NotImplementedError(\"Centering not supported for 1D output projections\")\n        self.proj = nn.ConvTranspose1d(embed_dim, out_chans, kernel_size=patch_size, stride=patch_size, bias=bias)\n        self.norm = norm_layer(out_chans) if norm_layer else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        B, L, C = x.shape\n        assert L == self.num_tokens, f\"Input sequence length ({L}) doesn't match model ({self.num_tokens}).\"\n        x = x.transpose(1, 2)\n        x = self.proj(x)\n        x = x[:, :, :-self.pad_size]\n        x = x.transpose(1, 2)\n        x = self.norm(x)\n        return x\n\n\ndef setup_2d(img_size: int, num_tokens: int):\n    assert int(num_tokens ** 0.5) ** 2 == num_tokens, \"num_patches must be a perfect square\"\n    img_size = (img_size, img_size)\n    grid_size = (\n        int(num_tokens ** 0.5),\n        int(num_tokens ** 0.5)\n    )\n    if grid_size[0] <= img_size[0]:\n        assert grid_size[1] <= img_size[1]\n        patch_size = (\n            (img_size[0] - 1) // grid_size[0] + 1,\n            (img_size[1] - 1) // grid_size[1] + 1\n        )\n        pad_size = (\n            (patch_size[0] * grid_size[0]) - img_size[0],\n            (patch_size[1] * grid_size[1]) - img_size[1]\n        )\n    else:\n        patch_size = (1, 1)\n        pad_size = (\n            grid_size[0] - img_size[0],\n            grid_size[1] - img_size[1]\n        )\n    return img_size, grid_size, patch_size, pad_size\n\n\nclass Order2ConvInputProj(nn.Module):\n    \"\"\"2D to Tokens\"\"\"\n    def __init__(self, img_size: int, in_chans: int, num_tokens: int, embed_dim: int, centering: bool, pad_mode: str, norm_layer: Optional[Callable]=None, bias: bool=True):\n        super().__init__()\n        img_size, _, patch_size, pad_size = setup_2d(img_size, num_tokens)\n        self.img_size = img_size\n        self.pad_size = pad_size\n        self.centering = centering\n        self.pad_mode = pad_mode\n        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, bias=bias)\n        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        B, H, W, C = x.shape\n        assert H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\"\n        assert W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\"\n        x = x.permute(0, 3, 1, 2)\n\n        if not self.centering:\n            if self.pad_mode == 'zero':\n                x = F.pad(x, (0, self.pad_size[1], 0, self.pad_size[0]))\n            elif self.pad_mode in ('replicate', 'circular'):\n                x = F.pad(x, (0, self.pad_size[1], 0, self.pad_size[0]), mode=self.pad_mode)\n            elif self.pad_mode == 'reflect':\n                determinism = torch.are_deterministic_algorithms_enabled()\n                torch.use_deterministic_algorithms(False)\n                x = F.pad(x, (0, self.pad_size[1], 0, self.pad_size[0]), mode='reflect')\n                torch.use_deterministic_algorithms(determinism)\n            else:\n                raise ValueError(f\"Invalid padding mode: {self.pad_mode}\")\n        else:\n            if self.pad_mode == 'zero':\n                x = F.pad(x, (\n                    self.pad_size[1] // 2, self.pad_size[1] - (self.pad_size[1] // 2),\n                    self.pad_size[0] // 2, self.pad_size[0] - (self.pad_size[0] // 2)\n                ))\n            elif self.pad_mode in ('replicate', 'circular'):\n                x = F.pad(x, (\n                    self.pad_size[1] // 2, self.pad_size[1] - (self.pad_size[1] // 2),\n                    self.pad_size[0] // 2, self.pad_size[0] - (self.pad_size[0] // 2)\n                ), mode=self.pad_mode)\n            elif self.pad_mode == 'reflect':\n                determinism = torch.are_deterministic_algorithms_enabled()\n                torch.use_deterministic_algorithms(False)\n                x = F.pad(x, (\n                    self.pad_size[1] // 2, self.pad_size[1] - (self.pad_size[1] // 2),\n                    self.pad_size[0] // 2, self.pad_size[0] - (self.pad_size[0] // 2)\n                ), mode='reflect')\n                torch.use_deterministic_algorithms(determinism)\n            else:\n                raise ValueError(f\"Invalid padding mode: {self.pad_mode}\")\n\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)  # NCHW -> NLC\n        x = self.norm(x)\n        return x\n\n\nclass Order2ConvOutputProj(nn.Module):\n    \"\"\"Tokens to 2D\"\"\"\n    def __init__(self, img_size: int, out_chans: int, num_tokens: int, embed_dim: int, centering: bool, pad_mode: str, norm_layer: Optional[Callable]=None, bias: bool=True):\n        super().__init__()\n        _, grid_size, patch_size, pad_size = setup_2d(img_size, num_tokens)\n        self.grid_size = grid_size\n        self.num_tokens = num_tokens\n        self.pad_size = pad_size\n        if centering:\n            raise NotImplementedError(\"Centering not supported for 2D output projections\")\n        self.proj = nn.ConvTranspose2d(embed_dim, out_chans, kernel_size=patch_size, stride=patch_size, bias=bias)\n        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        B, L, C = x.shape\n        assert L == self.num_tokens, f\"Input sequence length ({L}) doesn't match model ({self.num_tokens}).\"\n        x = x.transpose(1, 2)\n        x = x.reshape(B, C, self.grid_size[0], self.grid_size[1])\n        x = self.proj(x)\n        x = x[:, :, :-self.pad_size[0], :-self.pad_size[1]]\n        x = x.permute(0, 2, 3, 1)  # NCHW -> NHWC\n        x = self.norm(x)\n        return x\n\n\ndef setup_1x1d(img_size: Tuple[int, int], num_tokens: int):\n    assert int(num_tokens ** 0.5) ** 2 == num_tokens, \"num_patches must be a perfect square\"\n    grid_size = (\n        int(num_tokens ** 0.5),\n        int(num_tokens ** 0.5)\n    )\n    patch_size = [None, None]\n    pad_size = [None, None]\n    if grid_size[0] <= img_size[0]:\n        patch_size[0] = (img_size[0] - 1) // grid_size[0] + 1\n        pad_size[0] = (patch_size[0] * grid_size[0]) - img_size[0]\n    else:\n        patch_size[0] = 1\n        pad_size[0] = grid_size[0] - img_size[0]\n    if grid_size[1] <= img_size[1]:\n        patch_size[1] = (img_size[1] - 1) // grid_size[1] + 1\n        pad_size[1] = (patch_size[1] * grid_size[1]) - img_size[1]\n    else:\n        patch_size[1] = 1\n        pad_size[1] = grid_size[1] - img_size[1]\n    patch_size = tuple(patch_size)\n    pad_size = tuple(pad_size)\n    return img_size, grid_size, patch_size, pad_size\n\n\nclass Order1x1ConvInputProj(nn.Module):\n    \"\"\"2D (1Dx1D) to Tokens\"\"\"\n    def __init__(self, img_size: Tuple[int, int], in_chans: int, num_tokens: int, embed_dim: int, centering: bool, pad_mode: str, norm_layer: Optional[Callable]=None, bias: bool=True):\n        super().__init__()\n        img_size, _, patch_size, pad_size = setup_1x1d(img_size, num_tokens)\n        self.img_size = img_size\n        self.pad_size = pad_size\n        if centering:\n            raise NotImplementedError(\"Centering not supported for 1x1D input projections\")\n        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, bias=bias)\n        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        B, H, W, C = x.shape\n        assert H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\"\n        assert W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\"\n        x = x.permute(0, 3, 1, 2)\n        x = F.pad(x, (0, self.pad_size[1], 0, self.pad_size[0]))\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)  # NCHW -> NLC\n        x = self.norm(x)\n        return x\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/analysis/interface.py", "content": "# pylint: disable=too-many-arguments,line-too-long\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt\nimport torch\n\n\ndef visualize(perm, name, log_dir):\n    perm = perm.cpu().numpy()\n    plt.figure(figsize=(5, 5))\n    img = plt.imshow(perm, norm=plt.Normalize(0, 0.25), interpolation='nearest')\n    plt.axis('off')\n    img.axes.get_xaxis().set_visible(False)\n    img.axes.get_yaxis().set_visible(False)\n    plt.savefig(Path(log_dir) / f'{name}.pdf', bbox_inches='tight', pad_inches=0)\n    plt.close()\n\n\nclass EntropyMetric():\n    def __init__(self, n):\n        super().__init__()\n        self.n = n\n\n    @torch.no_grad()\n    def compute_node_mask(self, n_nodes: torch.Tensor):\n        b = n_nodes.shape[0]\n        idxs = torch.arange(0, self.n, device=n_nodes.device)[None, :].expand(b, self.n)\n        node_mask = idxs < n_nodes[:, None]\n        return node_mask\n\n    @torch.no_grad()\n    def compute_node_pair_mask(self, node_mask: torch.Tensor):\n        b = node_mask.shape[0]\n        mask1 = node_mask[:, None, :].expand(b, self.n, self.n)\n        mask2 = node_mask[:, :, None].expand(b, self.n, self.n)\n        node_pair_mask = torch.logical_and(mask1, mask2)\n        return node_pair_mask\n\n    @staticmethod\n    def _normalize(scores, axis, eps=1e-12):\n        normalizer = torch.sum(scores, axis).clamp(min=eps)\n        normalizer = normalizer.unsqueeze(axis)\n        prob = torch.div(scores, normalizer)\n        return prob\n\n    @staticmethod\n    def _entropy(prob, axis):\n        return -torch.sum(prob * prob.log().clamp(min=-100), axis)\n\n    def entropy(self, scores, node_mask, eps=1e-12):\n        b, n, _ = scores.shape\n        # clamp min to avoid zero logarithm\n        scores = scores.clone()\n        node_pair_mask = self.compute_node_pair_mask(node_mask)\n        scores[node_pair_mask] = scores[node_pair_mask].clamp(min=eps)\n        scores[~node_pair_mask] = 0\n        # compute columnwise entropy\n        col_prob = self._normalize(scores, axis=1)\n        col_prob = torch.where(node_pair_mask, col_prob, torch.ones_like(scores))\n        entropy_col = self._entropy(col_prob, axis=1)\n        # compute rowwise entropy\n        row_prob = self._normalize(scores, axis=2)\n        row_prob = torch.where(node_pair_mask, row_prob, torch.ones_like(scores))\n        entropy_row = self._entropy(row_prob, axis=2)\n        # return entropy\n        assert entropy_col.shape == entropy_row.shape == (b, n)\n        return entropy_col, entropy_row\n\n    def get_entropy(self, perm: torch.Tensor, n_nodes: torch.Tensor):\n        b, n, _ = perm.shape\n        assert n == self.n\n        assert perm.shape == (b, n, n)\n        # compute node mask\n        node_mask = self.compute_node_mask(n_nodes)\n        # compute entropy\n        entropy_col, entropy_row = self.entropy(perm, node_mask)\n        entropy = entropy_col + entropy_row\n        # compute mean over nodes\n        entropy[~node_mask] = 0\n        entropy = entropy.sum(1) / n_nodes\n        # unbind to list\n        return entropy.tolist()\n\n\n@torch.no_grad()\ndef analyze_interface(model, log_dir, epoch, val_loader, device, args):\n    # analyze trained distribution p(g|x)\n    entropy_metric = EntropyMetric(64)\n    num_visualize = 1\n    eval_sample_size = 100\n    # val data\n    model.eval()\n    entropy_list = []\n    for batch_idx, data in enumerate(val_loader):\n        data = data.to(device)\n        # entropy of averaged permutation samples\n        _, _, perm = model(data, n_samples=eval_sample_size, return_perm=True)\n        average_perm = perm.mean(1)\n        entropy_list += entropy_metric.get_entropy(average_perm, data.n)\n        # visualization of averaged permutation samples\n        if batch_idx == 0:\n            for data_idx, (p, n) in enumerate(zip(average_perm, data.n)):\n                if data_idx < num_visualize:\n                    visualize(p[:n, :n], f'perm_val_data_{data_idx}_epoch_{epoch}_k_{eval_sample_size}', log_dir)\n    # return results\n    return entropy_list\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/analysis/forward.py", "content": "# pylint: disable=line-too-long\nimport numpy as np\nimport torch\nfrom torch.nn import functional as F\n\n\n@torch.no_grad()\ndef analyze_forward(model, val_loader, device):\n    # analyze trained backbone gf(g-1x)\n    # variance of prediction and loss of gf(g-1x) over sample sizes\n    eval_sample_size_list = [1, 2, 5, 10, 20, 50, 100, 200]\n    n_trials = 100\n    # val data\n    model.eval()\n    pred_mean_dict = {eval_sample_size: [] for eval_sample_size in eval_sample_size_list}\n    pred_std_dict = {eval_sample_size: [] for eval_sample_size in eval_sample_size_list}\n    loss_mean_dict = {eval_sample_size: [] for eval_sample_size in eval_sample_size_list}\n    loss_std_dict = {eval_sample_size: [] for eval_sample_size in eval_sample_size_list}\n    for data in val_loader:\n        data = data.to(device)\n        for eval_sample_size in eval_sample_size_list:\n            pred_list = []\n            loss_list = []\n            for _ in range(n_trials):\n                # pred, loss: [b, 1]\n                # gf(g-1x)\n                pred, _ = model(data, n_samples=eval_sample_size)\n                loss = F.binary_cross_entropy_with_logits(pred, data.y[:, None].float(), reduction='none')\n                pred_list.append(F.sigmoid(pred))\n                loss_list.append(loss)\n            # pred, loss: [b, n_trials]\n            pred_std, pred_mean = torch.std_mean(torch.cat(pred_list, dim=1), dim=1)\n            loss_std, loss_mean = torch.std_mean(torch.cat(loss_list, dim=1), dim=1)\n            pred_mean_dict[eval_sample_size] += pred_mean.tolist()\n            pred_std_dict[eval_sample_size] += pred_std.tolist()\n            loss_mean_dict[eval_sample_size] += loss_mean.tolist()\n            loss_std_dict[eval_sample_size] += loss_std.tolist()\n    # average over val data\n    pred_mean_dict = {eval_sample_size: np.mean(pred_mean_dict[eval_sample_size]) for eval_sample_size in eval_sample_size_list}\n    pred_std_dict = {eval_sample_size: np.mean(pred_std_dict[eval_sample_size]) for eval_sample_size in eval_sample_size_list}\n    loss_mean_dict = {eval_sample_size: np.mean(loss_mean_dict[eval_sample_size]) for eval_sample_size in eval_sample_size_list}\n    loss_std_dict = {eval_sample_size: np.mean(loss_std_dict[eval_sample_size]) for eval_sample_size in eval_sample_size_list}\n    # return results\n    return pred_std_dict, loss_mean_dict, loss_std_dict\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/exp_classify_analysis_draw_plots.py", "content": "# pylint: disable=line-too-long\nimport sys\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt, colors as mcolors, cm\nimport numpy as np\n\n\ndef main():\n    result_dir = Path('experiments/exp_classify_analysis_results')\n    result_dir.mkdir(exist_ok=True, parents=True)\n\n    inference_sample_size_list = [1, 2, 5, 10, 20, 50, 100, 200]\n    output_variance_ga = [\n        3.0706462169081845e-07,\n        1.5521085427016174e-07,\n        6.171463413547161e-08,\n        3.017349290337683e-08,\n        1.5502213285103925e-08,\n        6.172048835150004e-09,\n        3.0883258973997898e-09,\n        1.5264307195648647e-09\n    ]\n    output_variance_ps = [\n        1.6541861126420024e-07,\n        8.08703081663165e-08,\n        3.34797365137036e-08,\n        1.626220088479192e-08,\n        8.201903479779489e-09,\n        3.3071799775451203e-09,\n        1.6516958891311414e-09,\n        8.255185086715526e-10\n    ]\n    loss_variance_ga = [\n        1.2749933750875217e-06,\n        6.416980301819289e-07,\n        2.5513579288871584e-07,\n        1.2498019269397055e-07,\n        6.41882245852448e-08,\n        2.5605660191740127e-08,\n        1.2772980042971844e-08,\n        6.332357995155924e-09\n    ]\n    loss_variance_ps = [\n        6.86501097257535e-07,\n        3.348565073013885e-07,\n        1.3830502426699794e-07,\n        6.736574970622854e-08,\n        3.401901327210593e-08,\n        1.366817101688436e-08,\n        6.829182854227606e-09,\n        3.416330793589359e-09\n    ]\n    fig, axes = plt.subplots(1, 2, figsize=(7, 3))\n    (ax1, ax2) = axes\n    # output variance\n    ax1.plot(inference_sample_size_list, output_variance_ga, label='GA', color='C0')\n    ax1.plot(inference_sample_size_list, output_variance_ps, label='PS (Ours)', color='C1')\n    ax1.legend()\n    ax1.set_xscale('log')\n    ax1.set_yscale('log')\n    ax1.set_xlim(1, 200)\n    ax1.set_xticks([1, 10, 100, 200], [1, 10, 100, 200])\n    ax1.set_xlabel('Inference sample size')\n    ax1.set_title('Output variance', fontsize='medium')\n    # loss variance\n    ax2.plot(inference_sample_size_list, loss_variance_ga, label='GA', color='C0')\n    ax2.plot(inference_sample_size_list, loss_variance_ps, label='PS (Ours)', color='C1')\n    ax2.legend()\n    ax2.set_xscale('log')\n    ax2.set_yscale('log')\n    ax2.set_xlim(1, 200)\n    ax2.set_xticks([1, 10, 100, 200], [1, 10, 100, 200])\n    ax2.set_xlabel('Inference sample size')\n    ax2.set_title('Loss variance', fontsize='medium')\n    plt.savefig(result_dir / 'ps_ga_variance.pdf', bbox_inches='tight')\n\n    train_epoch_list = [100, 500, 1000, 1500, 2000]\n    grad_direction_norm_ga = [\n        0.014915736392140388,\n        4.267692565917969e-05,\n        0.00017434358596801758,\n        0.000244140625,\n        0.0001653432846069336,\n    ]\n    grad_direction_norm_ps = [\n        1.0259549617767334,\n        0.2769050896167755,\n        0.7440996766090393,\n        9.538859367370605,\n        5.858701229095459,\n    ]\n    # gradient direction norm\n    fig, ax = plt.subplots(figsize=(3, 3))\n    plt.plot(train_epoch_list, grad_direction_norm_ga, label='GA', color='C0')\n    plt.plot(train_epoch_list, grad_direction_norm_ps, label='PS (Ours)', color='C1')\n    plt.legend()\n    plt.yscale('log')\n    plt.xlim(100, 2000)\n    plt.xlabel('Train epoch')\n    ax.set_xticks([100, 1000, 2000], [100, 1000, 2000])\n    plt.title('Gradient direction norm', fontsize='medium')\n    plt.savefig(result_dir / 'ps_ga_grad_norm.pdf', bbox_inches='tight')\n\n    train_sample_size_list = [1, 2, 5, 10, 20, 50]\n    inference_sample_size_list = [1, 2, 5, 10, 20, 50, 100, 200]\n    test_accuracy = [97.5, 99.5, 100, 100, 99, 94]\n    aggregated_permutation_entropy = [\n        4.974285411834717,\n        5.299808316230774,\n        5.358375126123429,\n        5.742276425361633,\n        5.747604515552521,\n        5.30451651096344\n    ]\n    output_variance = [\n        {1: 0.05728540128145767, 2: 0.032672350350251754, 5: 0.012965064540418481, 10: 0.006170224073062822, 20: 0.002819192289717801, 50: 0.0010073832749461717, 100: 0.0004884824521033333, 200: 0.00024102387989053761},\n        {1: 0.04755314971920915, 2: 0.016754518029810678, 5: 0.001946336805543455, 10: 0.0002948745111992412, 20: 4.783197569895825e-05, 50: 6.661319064728145e-06, 100: 1.78873204204653e-06, 200: 6.23118489596231e-07},\n        {1: 0.09002647590863345, 2: 0.03659204683170373, 5: 0.0036435529535214055, 10: 0.00023107155553143865, 20: 1.0280959465683454e-05, 50: 1.0580583547434355e-06, 100: 5.617410243095228e-08, 200: 4.527922321175236e-08},\n        {1: 0.14569390694058423, 2: 0.08929549883315309, 5: 0.02144938430969646, 10: 0.002310744434182581, 20: 5.360684752834944e-05, 50: 5.807636329062895e-06, 100: 5.091100683234808e-06, 200: 4.461098718287459e-06},\n        {1: 0.1241547902609871, 2: 0.09962326593091256, 5: 0.04785178475418612, 10: 0.014283032962366656, 20: 0.0020969656284951866, 50: 3.715859175285424e-05, 100: 4.112851225488069e-06, 200: 1.6563160001433478e-06},\n        {1: 0.08050555874827163, 2: 0.09401509907651842, 5: 0.08431665470390054, 10: 0.04340998786275198, 20: 0.013189855166497915, 50: 0.00038904690386628346, 100: 2.4882944106092414e-05, 200: 4.056367785957766e-06}\n    ]\n    loss_variance = [\n        {1: 0.4000418267228548, 2: 0.13337507248833302, 5: 0.03486299537701681, 10: 0.013175297208119142, 20: 0.005040805204194193, 50: 0.0016127704062788007, 100: 0.000744324748079055, 200: 0.00036107173560480995},\n        {1: 0.7236731346015357, 2: 0.1295406887971354, 5: 0.0065013059269430976, 10: 0.0006241246756301404, 20: 0.00010132196784034605, 50: 1.2004449122738783e-05, 100: 1.93354597911522e-06, 200: 6.446190115315819e-07},\n        {1: 7.132708199979103, 2: 1.216346814788016, 5: 0.04653701569269349, 10: 0.005274886205105127, 20: 0.0014057028670501702, 50: 0.0004878179465428622, 100: 0.0002880938077497577, 200: 0.00016064789667179618},\n        {1: 52.28317690177816, 2: 13.798393484290461, 5: 1.1953691224350025, 10: 0.09047484326610364, 20: 0.008144452601046978, 50: 0.0017325448479229546, 100: 0.0004526347949273957, 200: 0.0004094342561653763},\n        {1: 41.50281031121177, 2: 15.521975466521464, 5: 2.9619437042459076, 10: 0.5271301576410243, 20: 0.047739374706024365, 50: 0.004049775145598979, 100: 0.002103717963976271, 200: 0.0010971306150064344},\n        {1: 160.86562676302051, 2: 75.47981941667413, 5: 21.206526386592667, 10: 5.923607240395657, 20: 1.0606971534114171, 50: 0.048946166348650025, 100: 0.013917550760540381, 200: 0.008890745940731463}\n    ]\n    loss_mean = [\n        {1: 0.435622586235404, 2: 0.29533577896188945, 5: 0.19525568856319298, 10: 0.16018273997702637, 20: 0.14125716980728611, 50: 0.12965848148473924, 100: 0.12588263908468433, 200: 0.12427737602708021},\n        {1: 0.3065085884765449, 2: 0.11678855236912, 5: 0.02751179982636671, 10: 0.01074560106758589, 20: 0.0058102655517033594, 50: 0.003877121023839556, 100: 0.0032957341034962197, 200: 0.0030892978498623237},\n        {1: 0.8668395363446325, 2: 0.3046738412324518, 5: 0.08010372936664639, 10: 0.05043500425110715, 20: 0.04305245564993055, 50: 0.03773379633310266, 100: 0.04095681383465477, 200: 0.03911080474429121},\n        {1: 2.897936876192689, 2: 1.26465321514057, 5: 0.2714503089405946, 10: 0.09756674202105552, 20: 0.05137166503250737, 50: 0.02990997344752923, 100: 0.016784781603436136, 200: 0.01457264707265697},\n        {1: 3.0712811067467554, 2: 1.7953001398764536, 5: 0.6234068413883885, 10: 0.23779508759592047, 20: 0.09143870905411093, 50: 0.05856174626692872, 100: 0.059284366246608246, 200: 0.05450170620723685},\n        {1: 4.786832296289504, 2: 3.640420485427603, 5: 1.9148857730797317, 10: 0.900712268892459, 20: 0.3894244514891711, 50: 0.19439654105668588, 100: 0.1990255922348682, 200: 0.19358754464953973},\n    ]\n    # test accuracy\n    fig, ax = plt.subplots(figsize=(3, 3))\n    plt.axhline(y=100, color='k', linestyle='--', linewidth=0.5)\n    plt.plot(train_sample_size_list, test_accuracy, '-o', label='Test accuracy', color='C1')\n    plt.xscale('log')\n    plt.xlabel('Train sample size')\n    plt.title('Test accuracy (%)', fontsize='medium')\n    ax.set_yticks([90, 95, 100], [90, 95, 100])\n    ax.set_xticks([1, 10, 50], [1, 10, 50])\n    plt.ylim(89, 101)\n    plt.xlim(1, 50)\n    plt.savefig(result_dir / 'train_sample_size_accuracy.pdf', bbox_inches='tight')\n    # aggregated permutation entropy\n    fig, ax = plt.subplots(figsize=(3, 3))\n    # dashed horizontal line at random entropy\n    plt.axhline(y=7.035248444080353, linestyle='--', color='C0', label='Random')\n    plt.plot(train_sample_size_list, aggregated_permutation_entropy, '-o', color='C1')\n    plt.xscale('log')\n    plt.xlabel('Train sample size')\n    plt.title('Entropy of sampled permutation', fontsize='medium')\n    ax.set_xticks([1, 10, 50], [1, 10, 50])\n    plt.xlim(1, 50)\n    plt.savefig(result_dir / 'train_sample_size_entropy.pdf', bbox_inches='tight')\n    # output variance, loss variance, loss mean\n    normalize = mcolors.Normalize(vmin=np.log10(1), vmax=np.log10(200))\n    colormap = cm.viridis\n    scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n    scalarmappaple.set_array([np.log10(i) for i in inference_sample_size_list])\n    fig, axes = plt.subplots(1, 3, figsize=(13, 3))\n    (ax1, ax2, ax3) = axes\n    # output variance\n    ax1.plot(train_sample_size_list, [e[1] for e in output_variance], '-o', label='1', color=colormap(normalize(np.log10(1))), linewidth=0.8, markersize=4)\n    ax1.plot(train_sample_size_list, [e[2] for e in output_variance], '-o', label='2', color=colormap(normalize(np.log10(2))), linewidth=0.8, markersize=4)\n    ax1.plot(train_sample_size_list, [e[5] for e in output_variance], '-o', label='5', color=colormap(normalize(np.log10(5))), linewidth=0.8, markersize=4)\n    ax1.plot(train_sample_size_list, [e[10] for e in output_variance], '-o', label='10', color=colormap(normalize(np.log10(10))), linewidth=0.8, markersize=4)\n    ax1.plot(train_sample_size_list, [e[20] for e in output_variance], '-o', label='20', color=colormap(normalize(np.log10(20))), linewidth=0.8, markersize=4)\n    ax1.plot(train_sample_size_list, [e[50] for e in output_variance], '-o', label='50', color=colormap(normalize(np.log10(50))), linewidth=0.8, markersize=4)\n    ax1.plot(train_sample_size_list, [e[100] for e in output_variance], '-o', label='100', color=colormap(normalize(np.log10(100))), linewidth=0.8, markersize=4)\n    ax1.plot(train_sample_size_list, [e[200] for e in output_variance], '-o', label='200', color=colormap(normalize(np.log10(200))), linewidth=0.8, markersize=4)\n    ax1.set_xscale('log')\n    ax1.set_yscale('log')\n    ax1.set_xlabel('Train sample size')\n    ax1.set_title('Output variance', fontsize='medium')\n    ax1.set_xticks([1, 10, 50], [1, 10, 50])\n    # loss variance\n    ax2.plot(train_sample_size_list, [e[1] for e in loss_variance], '-o', label='1', color=colormap(normalize(np.log10(1))), linewidth=0.8, markersize=4)\n    ax2.plot(train_sample_size_list, [e[2] for e in loss_variance], '-o', label='2', color=colormap(normalize(np.log10(2))), linewidth=0.8, markersize=4)\n    ax2.plot(train_sample_size_list, [e[5] for e in loss_variance], '-o', label='5', color=colormap(normalize(np.log10(5))), linewidth=0.8, markersize=4)\n    ax2.plot(train_sample_size_list, [e[10] for e in loss_variance], '-o', label='10', color=colormap(normalize(np.log10(10))), linewidth=0.8, markersize=4)\n    ax2.plot(train_sample_size_list, [e[20] for e in loss_variance], '-o', label='20', color=colormap(normalize(np.log10(20))), linewidth=0.8, markersize=4)\n    ax2.plot(train_sample_size_list, [e[50] for e in loss_variance], '-o', label='50', color=colormap(normalize(np.log10(50))), linewidth=0.8, markersize=4)\n    ax2.plot(train_sample_size_list, [e[100] for e in loss_variance], '-o', label='100', color=colormap(normalize(np.log10(100))), linewidth=0.8, markersize=4)\n    ax2.plot(train_sample_size_list, [e[200] for e in loss_variance], '-o', label='200', color=colormap(normalize(np.log10(200))), linewidth=0.8, markersize=4)\n    ax2.set_xscale('log')\n    ax2.set_yscale('log')\n    ax2.set_xlabel('Train sample size')\n    ax2.set_title('Loss variance', fontsize='medium')\n    ax2.set_xticks([1, 10, 50], [1, 10, 50])\n    # loss mean\n    ax3.plot(train_sample_size_list, [e[1] for e in loss_mean], '-o', label='1', color=colormap(normalize(np.log10(1))), linewidth=0.8, markersize=4)\n    ax3.plot(train_sample_size_list, [e[2] for e in loss_mean], '-o', label='2', color=colormap(normalize(np.log10(2))), linewidth=0.8, markersize=4)\n    ax3.plot(train_sample_size_list, [e[5] for e in loss_mean], '-o', label='5', color=colormap(normalize(np.log10(5))), linewidth=0.8, markersize=4)\n    ax3.plot(train_sample_size_list, [e[10] for e in loss_mean], '-o', label='10', color=colormap(normalize(np.log10(10))), linewidth=0.8, markersize=4)\n    ax3.plot(train_sample_size_list, [e[20] for e in loss_mean], '-o', label='20', color=colormap(normalize(np.log10(20))), linewidth=0.8, markersize=4)\n    ax3.plot(train_sample_size_list, [e[50] for e in loss_mean], '-o', label='50', color=colormap(normalize(np.log10(50))), linewidth=0.8, markersize=4)\n    ax3.plot(train_sample_size_list, [e[100] for e in loss_mean], '-o', label='100', color=colormap(normalize(np.log10(100))), linewidth=0.8, markersize=4)\n    ax3.plot(train_sample_size_list, [e[200] for e in loss_mean], '-o', label='200', color=colormap(normalize(np.log10(200))), linewidth=0.8, markersize=4)\n    ax3.set_xscale('log')\n    ax3.set_yscale('log')\n    ax3.set_xlabel('Train sample size')\n    ax3.set_title('Loss mean', fontsize='medium')\n    ax3.set_xticks([1, 10, 50], [1, 10, 50])\n    # global colorbar\n    cbar = fig.colorbar(scalarmappaple, ax=axes.ravel().tolist(), label='Inference sample size')\n    cbar.set_ticks([np.log10(i) for i in [1, 10, 50, 200]])\n    cbar.set_ticklabels([1, 10, 50, 200])\n    plt.savefig(result_dir / 'train_sample_size_variance.pdf', bbox_inches='tight')\n\n    # done\n    sys.exit()\n\n\nif __name__ == '__main__':\n    main()\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/args.py", "content": "import argparse\n\n\ndef add_args(parser: argparse.ArgumentParser) -> argparse.ArgumentParser:\n    # experiment arguments\n    parser.add_argument('--seed', type=int, default=1)\n    parser.add_argument('--backbone_seed', type=int, default=None)\n    parser.add_argument('--interface_seed', type=int, default=None)\n    parser.add_argument('--device_id', type=int, default=0)\n    parser.add_argument('--postfix', type=str, default='')\n    parser.add_argument('--skip_if_run_exists', action='store_true')\n\n    # data arguments\n    parser.add_argument('--batch_size', type=int, default=100)\n\n    # model arguments\n    parser.add_argument('--backbone', type=str, default='mlp', choices=['mlp', 'gin'])\n\n    # probabilistic symmetrization arguments\n    parser.add_argument('--interface', type=str, default='prob', choices=['prob', 'unif'])\n    parser.add_argument('--sample_size', type=int, default=10)\n    parser.add_argument('--eval_sample_size', type=int, default=10)\n    parser.add_argument('--hard', action='store_true')\n    parser.add_argument('--noise_scale', type=float, default=1)\n    parser.add_argument('--fixed_noise', action='store_true')\n    parser.add_argument('--tau', type=float, default=0.01)\n    parser.add_argument('--entropy_loss_scale', type=float, default=0.1)\n    parser.add_argument('--num_interface_layers', type=int, default=3)\n\n    # training arguments\n    parser.add_argument('--num_epochs', type=int, default=2000)\n    parser.add_argument('--lr', type=float, default=1e-3)\n    parser.add_argument('--gradient_clip', type=float, default=0.1)\n    parser.add_argument('--lr_warmup_epochs', type=int, default=200)\n    parser.add_argument('--lr_decay_after_warmup', action='store_true')\n\n    # logging arguments\n    parser.add_argument('--log_dir', type=str, default='experiments/logs')\n    parser.add_argument('--save_dir', type=str, default='experiments/checkpoints')\n    parser.add_argument('--save_interval', type=int, default=100)\n\n    return parser\n\n\ndef get_args() -> argparse.Namespace:\n    # parse arguments\n    parser = argparse.ArgumentParser('Probabilistic Symmetrization')\n    parser = add_args(parser)\n    args = parser.parse_args()\n    return args\n"}
{"type": "source_file", "path": "src/train/configure_model.py", "content": "# pylint:disable=too-many-arguments,line-too-long\nfrom pathlib import Path\nimport torch\n\nfrom src.model import Backbone, InterfacedModel\nfrom src.optim import OptimizerConfig, LRSchedulerConfig\nfrom .pl_module import LitModule\n\n\ndef configure_model(config, symmetry, verbose=True):\n    # setup model\n    backbone = Backbone(\n        backbone=config.backbone,\n        pretrained=getattr(config, 'pretrained', True),\n        patch_dropout=getattr(config, 'patch_dropout', None),\n        max_patch_dropout=getattr(config, 'max_patch_dropout', None),\n    )\n    model = InterfacedModel(\n        backbone=backbone,\n        symmetry=symmetry,\n        interface=config.interface,\n        centering=getattr(config, 'centering', False),\n        pad_mode=getattr(config, 'pad_mode', 'zero'),\n    )\n    # setup optimizer and lr scheduler\n    optimizer_config = OptimizerConfig(\n        optimizer=config.optimizer,\n        weight_decay=config.weight_decay,\n        lr_pretrained=config.lr_pretrained,\n        lr=config.lr\n    )\n    lr_scheduler_config = LRSchedulerConfig(\n        lr_schedule=config.lr_schedule,\n        n_steps=config.n_steps,\n        lr_pretrained=config.lr_pretrained,\n        lr=config.lr,\n        lr_warmup=config.lr_warmup,\n        lr_warmup_scale=config.lr_warmup_scale,\n        lr_decay_degree=config.lr_decay_degree\n    )\n    # setup lightning model\n    model = LitModule(\n        model=model,\n        sample_size=config.sample_size,\n        eval_sample_size=config.eval_sample_size if not config.test_mode else config.test_sample_size,\n        optimizer_config=optimizer_config,\n        lr_scheduler_config=lr_scheduler_config,\n        verbose=verbose\n    )\n    if verbose:\n        print(model)\n    # setup and load trained ckeckpoint\n    ckpt_path = setup_ckpt_path(\n        load_dir=config.load_dir,\n        dataset=config.dataset,\n        exp_name=config.exp_name,\n        resume_mode=config.resume_mode,\n        test_mode=config.test_mode,\n        test_ckpt_path=config.test_ckpt_path\n    )\n    model = load_ckpt(\n        model=model,\n        ckpt_path=ckpt_path,\n        resume_mode=config.resume_mode,\n        test_mode=config.test_mode\n    )\n    if verbose:\n        print(f'trained checkpoint loaded from {ckpt_path}' if ckpt_path is not None \\\n              else 'no trained checkpoint loaded')\n    return model, ckpt_path\n\n\ndef setup_ckpt_path(load_dir, dataset, exp_name, resume_mode=False, test_mode=False, test_ckpt_path=None):\n    dataset = dataset.replace('/', '_')\n    if resume_mode or test_mode:\n        if resume_mode:\n            assert test_ckpt_path is None, \"test_ckpt_path must be None if resume_mode is True!\"\n            ckpt_name = 'last.ckpt'\n        else:\n            assert test_mode, \"test_mode must be True if resume_mode is False!\"\n            if test_ckpt_path is not None:\n                return test_ckpt_path\n            # check the directory Path('experiments') / load_dir / exp_name\n            # the best checkpoints have format 'best.ckpt', 'bestv1.ckpt', ...\n            # select the latest one\n            ckpt_dir = Path('experiments') / load_dir / dataset / exp_name\n            ckpt_names = [ckpt.name for ckpt in ckpt_dir.iterdir() if ckpt.name.startswith('best')]\n            if len(ckpt_names) > 1:\n                ckpt_names.sort()\n                version_postfix = ckpt_names[-1].split('best')[-1].split('.')[0]\n            else:\n                version_postfix = ''\n            ckpt_name = f'best{version_postfix}.ckpt'\n        ckpt_path = Path('experiments') / load_dir / dataset / exp_name / ckpt_name\n        if not ckpt_path.exists():\n            raise FileNotFoundError(f\"checkpoint ({ckpt_path}) does not exist!\")\n        return ckpt_path.as_posix()\n    return None\n\n\ndef load_ckpt(model, ckpt_path, resume_mode, test_mode):\n    if resume_mode or test_mode:\n        checkpoint = torch.load(ckpt_path)\n        model.load_state_dict(checkpoint['state_dict'])\n    return model\n"}
{"type": "source_file", "path": "src/train/configure_data.py", "content": "# pylint:disable=line-too-long\nfrom pathlib import Path\nimport torch\n\nfrom src.data import DatasetBuilder, setup_symmetry\nfrom .pl_datamodule import LitDataModule, setup_pyg_datamodule\n\n\ndef configure_data(config, verbose=True):\n    # setup data directory\n    data_dir = setup_data_directory(\n        root_dir=config.root_dir,\n        data_dir=config.data_dir\n    )\n    # setup dataset\n    compute_frames = config.interface == 'frame'\n    ds_builder = DatasetBuilder(\n        root_dir=data_dir,\n        dataset=config.dataset,\n        compute_frames=compute_frames\n    )\n    # setup lightning datamodule\n    global_batch_size = config.global_batch_size\n    devices = torch.cuda.device_count() if config.accelerator == 'gpu' else 1\n    if config.test_mode:\n        global_batch_size = getattr(config, 'test_batch_size', config.global_batch_size // devices)\n        devices = 1\n    datamodule = setup_datamodule(\n        ds_builder=ds_builder,\n        global_batch_size=global_batch_size,\n        devices=devices,\n        num_workers=config.num_workers,\n        verbose=verbose\n    )\n    # setup data symmetry\n    symmetry = setup_symmetry(\n        dataset=config.dataset,\n        config=config,\n    )\n    if verbose:\n        print(symmetry)\n    return datamodule, symmetry\n\n\ndef setup_data_directory(root_dir='experiments', data_dir='data'):\n    data_dir = Path(root_dir) / data_dir\n    data_dir.mkdir(parents=True, exist_ok=True)\n    return data_dir.as_posix()\n\n\ndef setup_datamodule(ds_builder: DatasetBuilder, global_batch_size, devices, num_workers, verbose=True):\n    dm_builder = setup_pyg_datamodule if ds_builder.is_pyg_dataset else LitDataModule\n    datamodule = dm_builder(\n        ds_builder=ds_builder,\n        global_batch_size=global_batch_size,\n        devices=devices,\n        num_workers=num_workers,\n        verbose=verbose\n    )\n    return datamodule\n"}
{"type": "source_file", "path": "src/optim/lr_scheduler.py", "content": "# pylint: disable=too-many-arguments,too-few-public-methods,too-many-instance-attributes,line-too-long\nimport math\nimport torch\n\n\nclass LRSchedulerConfig():\n    def __init__(\n            self,\n            lr_schedule: str,\n            n_steps: int,\n            lr_pretrained: float,\n            lr: float,\n            lr_warmup: int,\n            lr_warmup_scale: float,\n            lr_decay_degree: float\n    ):\n        self.lr_schedule = lr_schedule\n        self.n_steps = n_steps\n        self.lr_pretrained = lr_pretrained\n        self.lr = lr\n        if lr_warmup >= 0:\n            self.lr_warmup = lr_warmup\n        else:\n            assert 0. <= lr_warmup_scale <= 1.\n            self.lr_warmup = int(lr_warmup_scale * self.n_steps)\n        self.lr_warmup_scale = lr_warmup_scale\n        self.lr_decay_degree = lr_decay_degree\n\n    def setup(self, optimizer: torch.optim.Optimizer):\n        return CustomLRScheduler(\n            optimizer=optimizer,\n            mode=self.lr_schedule,\n            base_lr=self.lr,\n            num_iters=self.n_steps,\n            warmup_iters=self.lr_warmup,\n            decay_degree=self.lr_decay_degree\n        )\n\n\nclass CustomLRScheduler():\n    \"\"\"\n    Custom learning rate scheduler for pytorch optimizer.\n    Assumes 1 <= self.iter <= 1 + num_iters.\n    \"\"\"\n    def __init__(\n            self,\n            optimizer: torch.optim.Optimizer,\n            mode: str,\n            base_lr: float,\n            num_iters: int,\n            warmup_iters: int=1000,\n            from_iter: int=0,\n            decay_degree: float=0.9,\n            decay_steps: int=5000\n        ):\n        self.optimizer = optimizer\n        self.mode = mode\n        self.base_lr = base_lr\n        self.lr = base_lr\n        self.iter = from_iter\n        self.N = num_iters + 1\n        self.warmup_iters = warmup_iters\n        self.decay_degree = decay_degree\n        self.decay_steps = decay_steps\n\n        self.lr_coefs = []\n        for param_group in optimizer.param_groups:\n            self.lr_coefs.append(param_group['lr'] / base_lr)\n\n        if mode == 'cos':\n            self._lr_schedule = self._lr_schedule_cos\n        elif mode == 'linear':\n            self._lr_schedule = self._lr_schedule_linear\n        elif mode == 'poly':\n            self._lr_schedule = self._lr_schedule_poly\n        elif mode == 'step':\n            self._lr_schedule = self._lr_schedule_step\n        elif mode == 'constant':\n            self._lr_schedule = self._lr_schedule_constant\n        elif mode == 'sqroot':\n            self._lr_schedule = self._lr_schedule_sqroot\n        else:\n            raise ValueError(f'Unknown mode {mode}!')\n\n    def _lr_schedule_cos(self):\n        if self.warmup_iters < self.iter < self.N:\n            self.lr = 0.5 * self.base_lr * (1 + math.cos(1.0 * (self.iter - self.warmup_iters) / (self.N - self.warmup_iters) * math.pi))\n\n    def _lr_schedule_linear(self):\n        if self.warmup_iters < self.iter < self.N:\n            self.lr = self.base_lr * (1 - 1.0 * (self.iter - self.warmup_iters) / (self.N - self.warmup_iters))\n\n    def _lr_schedule_poly(self):\n        if self.warmup_iters < self.iter < self.N:\n            self.lr = self.base_lr * pow((1 - 1.0 * (self.iter - self.warmup_iters) / (self.N - self.warmup_iters)), self.decay_degree)\n\n    def _lr_schedule_step(self):\n        if self.warmup_iters < self.iter:\n            self.lr = self.base_lr * (0.1 ** (self.decay_steps // (self.iter - self.warmup_iters)))\n\n    def _lr_schedule_constant(self):\n        self.lr = self.base_lr\n\n    def _lr_schedule_sqroot(self):\n        self.lr = self.base_lr * self.warmup_iters**0.5 * min(self.iter * self.warmup_iters**-1.5, self.iter**-0.5)\n\n    def _lr_warmup(self):\n        if self.warmup_iters > 0 and self.iter < self.warmup_iters and self.mode != 'sqroot':\n            self.lr = self.base_lr * 1.0 * self.iter / self.warmup_iters\n\n    def _adjust_learning_rate(self, optimizer, lr):\n        assert lr >= 0\n        for i, _ in enumerate(optimizer.param_groups):\n            optimizer.param_groups[i]['lr'] = lr * self.lr_coefs[i]\n\n    def step(self, step=-1):\n        \"\"\"Update current step\"\"\"\n        self.iter = step if step >= 0 else self.iter + 1\n        self._lr_schedule()\n        self._lr_warmup()\n        self._adjust_learning_rate(self.optimizer, self.lr)\n\n    def reset(self):\n        self.lr = self.base_lr\n        self.iter = 0\n        self._adjust_learning_rate(self.optimizer, self.lr)\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/backbone.py", "content": "import numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GINConv\n\n\nclass MLPNetGraph8C(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Linear(64, 128)\n        self.conv2 = nn.Linear(128, 64)\n        self.fc1 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        assert x.ndim == 3  # [b, k, d]\n        x = torch.tanh(self.conv1(x))\n        x = torch.tanh(self.conv2(x))\n        x = torch.tanh(self.fc1(x))\n        # mean over samples\n        x = x.mean(1)\n        return x\n\n\nclass MLPNetEXPiso(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Linear(4224, 2048)\n        self.conv2 = nn.Linear(2048, 4096)\n        self.conv3 = nn.Linear(4096, 2048)\n        self.fc1 = nn.Linear(2048, 10)\n\n    def forward(self, x):\n        assert x.ndim == 3  # [b, k, d]\n        x = torch.tanh(self.conv1(x))\n        x = torch.tanh(self.conv2(x))\n        x = torch.tanh(self.conv3(x))\n        x = torch.tanh(self.fc1(x))\n        # mean over samples\n        x = x.mean(1)\n        return x\n\n\nclass MLPNetEXPclassify(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Linear(4224, 2048)\n        self.conv2 = nn.Linear(2048, 4096)\n        self.conv3 = nn.Linear(4096, 2048)\n        self.fc1 = nn.Linear(2048, 10)\n        self.fc2 = nn.Linear(10, 1)\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        assert x.ndim == 3  # [b, k, d]\n        x = self.activation(self.conv1(x))\n        x = self.activation(self.conv2(x))\n        x = self.activation(self.conv3(x))\n        x = self.activation(self.fc1(x))\n        x = self.fc2(x)\n        # mean over samples\n        x = x.mean(1)\n        return x\n\n\nclass MLPNetAutomorphism(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Linear(25*25, 2048)\n        self.conv2 = nn.Linear(2048, 4096)\n        self.conv3 = nn.Linear(4096, 2048)\n        self.fc1 = nn.Linear(2048, 25)\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        assert x.ndim == 3  # [b, k, d]\n        x = self.activation(self.conv1(x))\n        x = self.activation(self.conv2(x))\n        x = self.activation(self.conv3(x))\n        x = self.fc1(x)\n        return x\n\n\nclass GINNetGRAPH8C(nn.Module):\n    def __init__(self, n, d):\n        super().__init__()\n        self.n = n\n        self.d = d\n        neuron = 64\n        r1 = np.random.uniform()\n        r2 = np.random.uniform()\n        r3 = np.random.uniform()\n        nn1 = nn.Sequential(nn.Linear(self.n + self.d, neuron))\n        nn2 = nn.Sequential(nn.Linear(neuron, neuron))\n        nn3 = nn.Sequential(nn.Linear(neuron, neuron))\n        self.conv1 = GINConv(nn1, eps=r1, train_eps=True)\n        self.conv2 = GINConv(nn2, eps=r2, train_eps=True)\n        self.conv3 = GINConv(nn3, eps=r3, train_eps=True)\n        self.fc1 = nn.Linear(neuron, 10)\n\n    def forward(self, x, edge_index, node_mask, k):\n        x = torch.tanh(self.conv1(x, edge_index))\n        x = torch.tanh(self.conv2(x, edge_index))\n        x = torch.tanh(self.conv3(x, edge_index))\n        # sum pooling\n        b, n = node_mask.shape\n        _, d = x.shape\n        assert n == self.n\n        assert x.shape == (b * k * n, d)\n        x = x.reshape(b, k, n, d)\n        node_mask = node_mask[:, None, :, None].expand(b, k, n, d)\n        x[~node_mask] = 0\n        # sum over nodes\n        x = x.sum(2)\n        # fc\n        x = torch.tanh(self.fc1(x))\n        # mean over samples\n        x = x.mean(1)\n        return x\n\n\nclass GINNetEXPiso(nn.Module):\n    def __init__(self, n, d):\n        super().__init__()\n        self.n = n\n        self.d = d\n        neuron = 64\n        r1 = np.random.uniform()\n        r2 = np.random.uniform()\n        r3 = np.random.uniform()\n        nn1 = nn.Sequential(nn.Linear(self.n + self.d, neuron))\n        nn2 = nn.Sequential(nn.Linear(neuron, neuron))\n        nn3 = nn.Sequential(nn.Linear(neuron, neuron))\n        self.conv1 = GINConv(nn1, eps=r1, train_eps=True)\n        self.conv2 = GINConv(nn2, eps=r2, train_eps=True)\n        self.conv3 = GINConv(nn3, eps=r3, train_eps=True)\n        self.fc1 = nn.Linear(neuron, 10)\n\n    def forward(self, x, edge_index, node_mask, k):\n        x = torch.tanh(self.conv1(x, edge_index))\n        x = torch.tanh(self.conv2(x, edge_index))\n        x = torch.tanh(self.conv3(x, edge_index))\n        # sum pooling\n        b, n = node_mask.shape\n        _, d = x.shape\n        assert n == self.n\n        assert x.shape == (b * k * n, d)\n        x = x.reshape(b, k, n, d)\n        node_mask = node_mask[:, None, :, None].expand(b, k, n, d)\n        x[~node_mask] = 0\n        # sum over nodes\n        x = x.sum(2)\n        # fc\n        x = torch.tanh(self.fc1(x))\n        # mean over samples\n        x = x.mean(1)\n        return x\n\n\nclass GINNetEXPclassify(nn.Module):\n    def __init__(self, n, d):\n        super().__init__()\n        self.n = n\n        self.d = d\n        neuron = 64\n        r1 = np.random.uniform()\n        r2 = np.random.uniform()\n        r3 = np.random.uniform()\n        nn1 = nn.Sequential(nn.Linear(self.n + self.d, neuron))\n        nn2 = nn.Sequential(nn.Linear(neuron, neuron))\n        nn3 = nn.Sequential(nn.Linear(neuron, neuron))\n        self.conv1 = GINConv(nn1, eps=r1, train_eps=True)\n        self.conv2 = GINConv(nn2, eps=r2, train_eps=True)\n        self.conv3 = GINConv(nn3, eps=r3, train_eps=True)\n        self.fc1 = nn.Linear(neuron, 10)\n        self.fc2 = nn.Linear(10, 1)\n\n    def forward(self, x, edge_index, node_mask, k):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = F.relu(self.conv3(x, edge_index)) # [6400, 64]\n        # sum pooling\n        b, n = node_mask.shape\n        _, d = x.shape\n        assert n == self.n\n        assert x.shape == (b * k * n, d)\n        x = x.reshape(b, k, n, d)\n        node_mask = node_mask[:, None, :, None].expand(b, k, n, d) \n        x = torch.where(node_mask, x, torch.zeros_like(x)) # [b, k, n, d]\n\n        # sum over nodes\n        x = x.sum(2) # [b, k, d]\n        # fc\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        # mean over samples\n        x = x.mean(1)\n        return x\n\n\ndef setup_backbone(backbone_type, task, n, d, backbone_seed=None):\n    assert backbone_type in ('mlp', 'gin')\n    if backbone_seed:\n        print(f'initializing backbone with random seed {backbone_seed}')\n        # get current random states\n        torch_state = torch.get_rng_state()\n        np_state = np.random.get_state()\n        # seed random states\n        torch.manual_seed(backbone_seed)\n        np.random.seed(backbone_seed)\n    if backbone_type == 'mlp':\n        backbone = {\n            'GRAPH8c': MLPNetGraph8C,\n            'EXPiso': MLPNetEXPiso,\n            'EXPclassify': MLPNetEXPclassify,\n            'automorphism': MLPNetAutomorphism,\n        }[task]()\n    else:\n        backbone = {\n            'GRAPH8c': GINNetGRAPH8C,\n            'EXPiso': GINNetEXPiso,\n            'EXPclassify': GINNetEXPclassify\n        }[task](n=n, d=d)\n    if backbone_seed:\n        # restore random states\n        torch.set_rng_state(torch_state)\n        np.random.set_state(np_state)\n    return backbone\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/gin.py", "content": "# pylint: disable=not-callable\nimport numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch_sparse\n\n\nclass MLP(nn.Module):\n    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        assert num_layers > 1, \"number of layers must be greater than 1\"\n        self.num_layers = num_layers\n        self.linear_layers = nn.ModuleList()\n        self.norms = nn.ModuleList()\n        self.linear_layers.append(nn.Linear(input_dim, hidden_dim))\n        for _ in range(num_layers - 2):\n            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n        self.linear_layers.append(nn.Linear(hidden_dim, output_dim))\n        for _ in range(num_layers - 1):\n            self.norms.append(nn.BatchNorm1d((hidden_dim)))\n        # initialize batchnorm statistics and bias\n        for m in self.modules():\n            if isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        for i in range(self.num_layers - 1):\n            x = self.linear_layers[i](x)\n            x = self.norms[i](x)\n            x = F.relu(x)\n        x = self.linear_layers[self.num_layers - 1](x)\n        return x\n\n\nclass GIN(nn.Module):\n    def __init__(\n        self,\n        num_layers,\n        num_mlp_layers,\n        input_dim,\n        hidden_dim,\n        output_dim,\n        learn_eps,\n        initial_eps\n    ):\n        \"\"\"\n        num_layers: including input layer, excluding output layer\n        num_mlp_layers: number of nn.Linear layers in each MLP block\n        \"\"\"\n        super().__init__()\n        self.num_layers = num_layers\n        if initial_eps is None:\n            eps = torch.tensor([np.random.uniform() for _ in range(num_layers)])\n        else:\n            eps = torch.tensor(initial_eps).float().repeat(num_layers)\n        if learn_eps:\n            self.eps = nn.Parameter(eps)\n        else:\n            self.register_buffer(\"eps\", eps)\n        self.input = nn.Linear(input_dim, hidden_dim)\n        self.mlps = nn.ModuleList()\n        self.mlps.append(MLP(num_mlp_layers, input_dim, hidden_dim, hidden_dim))\n        for _ in range(self.num_layers - 1):\n            self.mlps.append(MLP(num_mlp_layers, hidden_dim, hidden_dim, hidden_dim))\n        self.norms = nn.ModuleList()\n        for _ in range(num_layers):\n            self.norms.append(nn.BatchNorm1d((hidden_dim)))\n        self.head = nn.Linear(hidden_dim, output_dim)\n        # initialize batchnorm statistics and bias\n        for m in self.modules():\n            if isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def layer_forward(self, x, sparse_adj, layer_idx):\n        x = torch_sparse.matmul(sparse_adj.t(), x) + (1 + self.eps[layer_idx]) * x\n        x = self.mlps[layer_idx](x)\n        x = self.norms[layer_idx](x)\n        x = F.relu(x)\n        return x\n\n    def forward(self, x, edge_index):\n        # x: [sum(n), input_dim]\n        # edge_index: [2, sum(e)]\n        assert x.ndim == edge_index.ndim == 2\n        n, _ = x.shape\n        # create sparse adj\n        row, col = edge_index\n        sparse_adj = torch_sparse.SparseTensor(row=row, col=col, sparse_sizes=(n, n))\n        # forward\n        for i in range(self.num_layers):\n            x = self.layer_forward(x, sparse_adj, i)\n        x = self.head(x)\n        # x: [sum(n), output_dim]\n        return x\n"}
{"type": "source_file", "path": "src/optim/optim.py", "content": "# pylint: disable=too-few-public-methods\nimport torch\nfrom torch import nn\n\nfrom src.model import InterfacedModel\n\n\nOPTIMIZERS = {'sgd': torch.optim.SGD, 'adam': torch.optim.Adam, 'adamw': torch.optim.AdamW}\n\n\nclass OptimizerConfig():\n    def __init__(\n            self,\n            optimizer: str,\n            weight_decay: float,\n            lr_pretrained: float,\n            lr: float\n        ):\n        self.optimizer = optimizer\n        self.weight_decay = weight_decay\n        self.lr_pretrained = lr_pretrained\n        self.lr = lr\n\n    def setup(self, model: InterfacedModel):\n        learnable_params = []\n        learnable_params.append({'params': model.pretrained_parameters(),'lr': self.lr_pretrained})\n        learnable_params.append({'params': model.scratch_parameters(), 'lr': self.lr})\n\n        if self.optimizer == 'sgd':\n            return torch.optim.SGD(learnable_params, weight_decay=self.weight_decay, momentum=0.9)\n        if self.optimizer == 'adam':\n            return torch.optim.Adam(learnable_params, weight_decay=self.weight_decay)\n        if self.optimizer == 'adamw':\n            return torch.optim.AdamW(learnable_params, weight_decay=self.weight_decay)\n\n        raise ValueError(f'Optimizer {self.optimizer} not supported!')\n"}
{"type": "source_file", "path": "src/symmetry/interface.py", "content": "# pylint: disable=line-too-long\nfrom typing import Tuple, Any, Dict\nimport torch\nfrom torch import nn\n\nfrom .symmetry import Symmetry\n\n\nclass EquivariantCondDist(nn.Module):\n    \"\"\"Conditional equivariant distribution g ~ p(g|x)\"\"\"\n    def __init__(self, symmetry: Symmetry):\n        super().__init__()\n        self.symmetry = symmetry\n\n    def forward(self, xs: Tuple, batch: Any, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        \"\"\"Sample group elements g ~ p(g|x)\"\"\"\n        raise NotImplementedError\n\n\nclass Uniform(EquivariantCondDist):\n    \"\"\"g ~ Unif(G)\"\"\"\n\n    def forward(self, xs: Tuple, batch: Any, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        xs, _ = self.symmetry.broadcast(xs, n_samples)\n        gs = self.symmetry.samples_from_haar_distribution(xs, batch)\n        return gs, loss_dict\n\n\nclass Frame(EquivariantCondDist):\n    \"\"\"g ~ Unif(F(x)) for predefined set-valued equivariant frame F\"\"\"\n\n    def forward(self, xs: Tuple, batch: Any, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        gs = self.symmetry.samples_from_frame(xs, batch, n_samples)\n        return gs, loss_dict\n\n\nclass Probabilistic(EquivariantCondDist):\n    \"\"\"g ~ p(g|x) with trainable equivariant distribution p(g|x)\"\"\"\n    def __init__(self, symmetry: Symmetry):\n        super().__init__(symmetry)\n        self.prob_interface_net = self.symmetry.interface()\n\n    def forward(self, xs: Tuple, batch: Any, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        gs, loss_dict = self.symmetry.samples_from_prob(self.prob_interface_net, xs, batch, n_samples, loss_dict)\n        return gs, loss_dict\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/automorphism.py", "content": "# pylint: disable=not-callable,line-too-long,no-value-for-parameter\nimport os\nfrom pathlib import Path\nimport random\nimport numpy as np\nfrom matplotlib import pyplot as plt, colors, cm\nimport networkx as nx\nimport torch\nfrom torch_geometric.data import Data, Batch\nfrom torch_geometric.utils import to_undirected\n\nfrom args import get_args\nfrom preprocess import PrecomputePad\nfrom interface import InterfacedModel\n\n\nMAX_NODES = 25\n\n\ndef to_edge_index(edge_list):\n    return to_undirected(torch.tensor(edge_list, dtype=torch.long).t())\n\n\ndef data_trivial():\n    edge_index = to_edge_index([[0, 1], [1, 2], [2, 0], [2, 3], [1, 4], [4, 5], [2, 5], [5, 6]])\n    node_labels = torch.tensor([0, 1, 2, 3, 4, 5, 6])[:, None]\n    return Data(idx=0, x=torch.zeros(7, 1), edge_index=edge_index, y=node_labels)\n\n\ndef data_s6():\n    edge_index = to_edge_index([[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6]])\n    node_labels = torch.tensor([0, 1, 1, 1, 1, 1, 1])[:, None]\n    return Data(idx=1, x=torch.zeros(7, 1), edge_index=edge_index, y=node_labels)\n\n\ndef data_s3xs2():\n    edge_index = to_edge_index([[0, 1], [0, 2], [0, 3], [4, 5], [4, 6], [0, 4]])\n    node_labels = torch.tensor([0, 1, 1, 1, 2, 3, 3])[:, None]\n    return Data(idx=2, x=torch.zeros(7, 1), edge_index=edge_index, y=node_labels)\n\n\ndef data_d7():\n    edge_index = to_edge_index([[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 0]])\n    node_labels = torch.tensor([0, 0, 0, 0, 0, 0, 0])[:, None]\n    return Data(idx=3, x=torch.zeros(7, 1), edge_index=edge_index, y=node_labels)\n\n\ndef data_d4():\n    G = nx.grid_2d_graph(5, 5)\n    nodes = list(G.nodes())\n    edges = list(G.edges())\n    edge_index = to_edge_index([[nodes.index(u), nodes.index(v)] for u, v in edges])\n    pos = torch.tensor(nodes)\n    node_labels = (pos - 2).pow(2).sum(-1, keepdim=True)\n    return Data(idx=4, x=torch.zeros(25, 1), edge_index=edge_index, y=node_labels)\n\n\ndef draw_graph(data, fname, label, vmin, vmax):\n    result_dir = Path('experiments/automorphism_results')\n    result_dir.mkdir(exist_ok=True, parents=True)\n    G = nx.Graph()\n    G.add_nodes_from(list(range(data.num_nodes)))\n    G.add_edges_from(data.edge_index.t().tolist())\n    norm = colors.Normalize(vmin=vmin, vmax=vmax)\n    mapper = cm.ScalarMappable(norm=norm, cmap='rainbow')\n    node_color = [mapper.to_rgba(val) for val in label]\n    pos = nx.kamada_kawai_layout(G)\n    plt.figure(figsize=(4, 4))\n    node_size = 1000 if data.num_nodes <= 10 else 500\n    nx.draw(G, pos, with_labels=True, node_size=node_size, node_color=node_color, edgecolors='black')\n    plt.colorbar(mapper, ax=plt.gca(), shrink=0.5)\n    plt.axis('off')\n    plt.savefig(result_dir / f'{fname}.pdf', bbox_inches='tight')\n    plt.close()\n\n\ndef main(args):\n    # reproducibility\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    torch.cuda.manual_seed_all(args.seed)\n    torch.use_deterministic_algorithms(True)\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n\n    # configure device\n    device = torch.device(f'cuda:{args.device_id}' if torch.cuda.is_available() else 'cpu')\n\n    # configure data\n    transform = PrecomputePad(nmax=MAX_NODES)\n    data_list = [data_trivial(), data_s6(), data_s3xs2(), data_d7(), data_d4()]\n    labels_list = [data.y[:, 0].tolist() for data in data_list]\n    for data, label in zip(data_list, labels_list):\n        vmin, vmax = min(label), max(label)\n        draw_graph(data, f'data_{data.idx}_label', label, vmin, vmax)\n    batched_data = Batch.from_data_list([transform(data) for data in data_list]).to(device)\n\n    # configure model\n    model = InterfacedModel(\n        n=MAX_NODES,\n        d=1,\n        num_interface_layers=args.num_interface_layers,\n        backbone=args.backbone,\n        noise_scale=args.noise_scale,\n        tau=args.tau,\n        hard=args.hard,\n        task='automorphism'\n    ).to(device)\n    model.eval()\n\n    # run test\n    emb_1, _ = model(batched_data, n_samples=args.eval_sample_size)\n    labels_list_1 = emb_1[:, :, 0].cpu().tolist()\n    model.interface.noise_scale = 0\n    emb_2, _ = model(batched_data, n_samples=1)\n    labels_list_2 = emb_2[:, :, 0].cpu().tolist()\n    for data, label_1, label_2 in zip(data_list, labels_list_1, labels_list_2):\n        label_1 = label_1[:data.num_nodes]\n        label_2 = label_2[:data.num_nodes]\n        vmin, vmax = min(label_1), max(label_1)\n        draw_graph(data, f'data_{data.idx}_embed_ps', label_1, vmin, vmax)\n        vmin, vmax = min(label_2), max(label_2)\n        draw_graph(data, f'data_{data.idx}_embed_canonical', label_2, vmin, vmax)\n    print(\"Done, saved results to automorphism_results/\")\n\n\nif __name__ == '__main__':\n    args_ = get_args()\n    main(args_)\n"}
{"type": "source_file", "path": "src/symmetry/symmetry.py", "content": "# pylint: disable=line-too-long,too-many-arguments\nfrom typing import Any, Tuple, Dict, Union, Callable, List\nimport torch\nfrom torch import nn\n\n\ndef is_order_zero_rep(k):\n    if isinstance(k, tuple):\n        return all(is_order_zero_rep(k_) for k_ in k)\n    return k == 0\n\n\nclass Symmetry():\n    \"\"\"Base class for symmetry operations.\"\"\"\n    group_name: Union[str, Tuple] = NotImplemented\n    rep_dim: Union[int, Tuple] = NotImplemented\n    rep_in: Union[Dict[int, int], Dict[Tuple, int]] = NotImplemented\n    rep_out: Union[Dict[int, int], Dict[Tuple, int]] = NotImplemented\n    metric_name: Union[str, List[str]] = NotImplemented\n    interface: Callable = NotImplemented\n    ignore_rep_in: List = []\n    ignore_rep_out: List = []\n\n    def __repr__(self):\n        if isinstance(self.group_name, str):\n            name = f\"Group: {self.group_name}({self.rep_dim}), \" \\\n                   f\"Rep: {rep2str(self.rep_in)} -> {rep2str(self.rep_out)}\"\n        else:\n            name = f\"Group: {'*'.join([f'{g}({d})' for g, d in zip(self.group_name, self.rep_dim)])}, \" \\\n                   f\"Rep: {rep2str_prod(self.rep_in)} -> {rep2str_prod(self.rep_out)}\"\n        return name\n\n    def __init__(self):\n        pass\n\n    def process_input(self, batch) -> Tuple:\n        \"\"\"Proprocess input batch to representation (tuple of (B, N ... N, C) tensors)\"\"\"\n        raise NotImplementedError\n\n    def process_output(self, xs: Tuple, batch) -> Any:\n        \"\"\"Postprocess output representation to target format\"\"\"\n        raise NotImplementedError\n\n    def samples_from_haar_distribution(self, xs: Tuple, batch) -> torch.Tensor:\n        \"\"\"Sample from Haar measure on the group\"\"\"\n        raise NotImplementedError\n\n    def samples_from_frame(self, xs: Tuple, batch, n_samples: int) -> torch.Tensor:\n        \"\"\"Sample from frame\"\"\"\n        raise NotImplementedError\n\n    def samples_from_prob(self, prob_interface_net: nn.Module, xs: Tuple, batch, n_samples: int, loss_dict: Dict) -> Tuple[torch.Tensor, Dict]:\n        \"\"\"Sample from equivariant distribution\"\"\"\n        raise NotImplementedError\n\n    def transform_input(self, xs: Tuple, gs: torch.Tensor) -> torch.Tensor:\n        \"\"\"Transform using base group representations gs\"\"\"\n        raise NotImplementedError\n\n    def transform_output(self, xs: Tuple, gs: torch.Tensor) -> torch.Tensor:\n        \"\"\"Transform using (inverse of) base group representations gs\"\"\"\n        raise NotImplementedError\n\n    def broadcast(self, xs: Tuple, n_samples: int) -> Tuple[Tuple, int]:\n        \"\"\"Broadcast to n_samples copies\"\"\"\n        batch_size = xs[0].size(0)\n        if n_samples == 1:\n            return xs, batch_size\n        xs = tuple(self._broadcast(x, n_samples) for x in xs)\n        return xs, batch_size\n\n    def reduce(self, xs: Tuple, batch_size: int, n_samples: int) -> Tuple:\n        \"\"\"Reduce from n_samples copies\"\"\"\n        if n_samples == 1:\n            return xs\n        xs = tuple(self._reduce(x, batch_size, n_samples) for x in xs)\n        return xs\n\n    @staticmethod\n    def _broadcast(x: torch.Tensor, n_samples: int) -> torch.Tensor:\n        \"\"\"Broadcast x to n_samples copies\"\"\"\n        return x.repeat_interleave(n_samples, dim=0)\n\n    @staticmethod\n    def _reduce(x: torch.Tensor, batch_size: int, n_samples: int) -> torch.Tensor:\n        \"\"\"Reduce x from n_samples copies\"\"\"\n        return x.reshape(batch_size, n_samples, *x.shape[1:]).mean(1)\n\n    def criterion(self, y_hat: Any, y: Any) -> torch.Tensor:\n        \"\"\"Compute loss between prediction y_hat and target y\"\"\"\n        raise NotImplementedError\n\n    def evaluator(self, y_hat: Any, y: Any) -> torch.Tensor:\n        \"\"\"Compute metric between prediction y_hat and target y\"\"\"\n        # caution: the metric should be higher the better\n        # due to mode='max' in earlystopping and checkpoint callbacks\n        raise NotImplementedError\n\n\ndef rep2str(rep: dict):\n    def fn(p, c):\n        if p == 0:\n            return f\"{c}\"\n        if p == 1:\n            return f\"{c}V\"\n        if p == 2:\n            return f\"{c}(V*V)\"\n        return f\"{c}(V**{p})\"\n    return f'{\"+\".join([fn(k, v) for k, v in rep.items()])}'\n\n\ndef rep2str_prod(rep: dict):\n    def fn(p, s):\n        if p == 0:\n            return \"\"\n        if p == 1:\n            return f\"{s}\"\n        if p == 2:\n            return f\"({s}*{s})\"\n        return f\"({s}**{p})\"\n    def fn_(p_tup, c):\n        r = \"*\".join([fn(p_, f\"V{i+1}\") for i, p_ in enumerate(p_tup)]).strip(\"*\")\n        return f'{c}({r})' if len(r) > 0 else f'{c}'\n    return f'{\"+\".join([fn_(k, v) for k, v in rep.items()])}'\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/dataset/dataset.py", "content": "import pickle\nfrom pathlib import Path\nimport networkx as nx\nimport torch\nimport torch_geometric.data\nfrom torch_geometric.data import InMemoryDataset\nfrom torch_geometric.data.data import Data\nfrom torch_geometric.utils import to_undirected\n\n\ndef get_n_params(model):\n    pp = 0\n    for p in list(model.parameters()):\n        nn = 1\n        for s in list(p.size()):\n            nn = nn * s\n        pp += nn\n    return pp\n\n\nclass PlanarSATPairsDataset(InMemoryDataset):\n    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n        super().__init__(root, transform, pre_transform, pre_filter)\n        self.data, self.slices = torch.load(self.processed_paths[0])\n\n    @property\n    def raw_file_names(self):\n        return ['GRAPHSAT.pkl']\n\n    @property\n    def processed_file_names(self):\n        return 'data.pt'\n\n    def download(self):\n        pass\n\n    @staticmethod\n    def parse_old_version_data(data):\n        return torch_geometric.data.Data(\n            x=data.__dict__['x'],\n            edge_index=data.__dict__['edge_index'],\n            y=data.__dict__['y'],\n        )\n\n    def process(self):\n        # Read data into huge `Data` list.\n        with open(Path(self.root) / 'raw/GRAPHSAT.pkl', 'rb') as f:\n            data_list = pickle.load(f)\n\n        # Parse old PyG version data\n        keys = data_list[0].__dict__.keys()\n        for k in keys:\n            if k not in ('x', 'edge_index', 'y'):\n                assert all(d.__dict__[k] is None for d in data_list)\n        data_list = [self.parse_old_version_data(data) for data in data_list]\n\n        if self.pre_filter is not None:\n            data_list = [data for data in data_list if self.pre_filter(data)]\n\n        if self.pre_transform is not None:\n            data_list = [self.pre_transform(data) for data in data_list]\n\n        # add idx for fixing noise\n        for idx, data in enumerate(data_list):\n            data.idx = idx\n\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])\n\n\nclass GRAPH8cDataset(InMemoryDataset):\n    def __init__(self, root, transform=None, pre_transform=None):\n        super().__init__(root, transform, pre_transform)\n        self.data, self.slices = torch.load(self.processed_paths[0])\n\n    @property\n    def raw_file_names(self):\n        return ['graph8c.g6']\n\n    @property\n    def processed_file_names(self):\n        return 'data.pt'\n\n    def download(self):\n        # Download to `self.raw_dir`.\n        pass\n\n    def process(self):\n        # Read data into huge `Data` list.\n        dataset = nx.read_graph6(self.raw_paths[0])\n        data_list = []\n        for datum in dataset:\n            x = torch.ones(datum.number_of_nodes(), 1)\n            edge_index = to_undirected(torch.tensor(list(datum.edges())).transpose(1, 0))\n            data_list.append(Data(edge_index=edge_index, x=x, y=0))\n\n        if self.pre_filter is not None:\n            data_list = [data for data in data_list if self.pre_filter(data)]\n\n        if self.pre_transform is not None:\n            data_list = [self.pre_transform(data) for data in data_list]\n\n        # add idx for fixing noise\n        for idx, data in enumerate(data_list):\n            data.idx = idx\n\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/analysis/backward.py", "content": "# pylint: disable=line-too-long\nimport torch\nfrom torch.nn import functional as F\n\n\ndef get_backbone_grad(model, data, args):\n    model.zero_grad()\n    pred, _ = model(data, n_samples=args.sample_size)\n    # pred: [b, 1]\n    loss = F.binary_cross_entropy_with_logits(pred, data.y[:, None].float())\n    # only task loss affects gradient of backbone, entropy loss does not\n    backbone_grad = torch.autograd.grad(loss, model.backbone.parameters())\n    backbone_grad = torch.cat([g.view(-1) for g in backbone_grad])\n    backbone_grad_norm = torch.norm(backbone_grad, p=2)\n    return backbone_grad.detach(), backbone_grad_norm.item()\n\n\ndef analyze_backward(model, train_loader, device, args):\n    # analyze trained backbone gf(g-1x)\n    # gradient norm and direction of gf(g-1x)\n    model.train()\n    grad_direction = 0\n    grad_norm_list = []\n    for data in train_loader:\n        data = data.to(device)\n        for i in range(args.batch_size):\n            data_instance = data[i]\n            # gradient of gf(g-1x)\n            grad, grad_norm = get_backbone_grad(model, data_instance, args)\n            grad_direction += grad\n            grad_norm_list.append(grad_norm)\n    # gradient direction of gf(g-1x)\n    count = len(grad_norm_list)\n    grad_direction_norm = torch.norm(grad_direction / count, p=2).item()\n    # return results\n    return grad_norm_list, grad_direction_norm\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/exp_classify.py", "content": "# pylint: disable=not-callable,line-too-long\n# https://github.com/omri1348/Frame-Averaging/blob/master/graph_separation/exp_classify.py\nimport os\nimport sys\nfrom pathlib import Path\nimport random\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.tensorboard.writer import SummaryWriter\nfrom torch_geometric.loader import DataLoader\n\nfrom args import get_args\nfrom dataset import PlanarSATPairsDataset\nfrom preprocess import PrecomputeSpectral, PrecomputeSortFrame, PrecomputePad\nfrom interface import InterfacedModel\n\n\ndef configure_device(args):\n    return torch.device(f'cuda:{args.device_id}' if torch.cuda.is_available() else 'cpu')\n\n\ndef configure_data(args):\n    device = configure_device(args)\n    # setup dataset\n    pre_transform = PrecomputeSpectral(nmax=64, recfield=1, dv=2, nfreq=5, adddegree=True)\n    pre_transform = PrecomputeSortFrame(pre_transform, device)\n    transform = PrecomputePad(nmax=64)\n    dataset = PlanarSATPairsDataset(root='dataset/EXP/', transform=transform, pre_transform=pre_transform)\n    # setup loaders\n    val_loader = DataLoader(dataset[0:200], args.batch_size, shuffle=False, pin_memory=True, num_workers=0)\n    test_loader = DataLoader(dataset[200:400], args.batch_size, shuffle=False, pin_memory=True, num_workers=0)\n    train_loader = DataLoader(dataset[400:1200], args.batch_size, shuffle=True, pin_memory=True, num_workers=0)\n    return train_loader, val_loader, test_loader\n\n\ndef configure_experiment_name(args):\n    exp_name = f'seed_{args.seed},' \\\n        + (f'backbone_seed_{args.backbone_seed},' if args.backbone_seed else '') \\\n        + (f'interface_seed_{args.interface_seed},' if args.interface_seed else '') \\\n        + f'backbone_{args.backbone},'\n    if args.interface == 'unif':\n        exp_name += 'ga,hard,'\n    elif args.interface == 'prob':\n        exp_name += f'z_scale_{args.noise_scale},' \\\n            + f'tau_{args.tau},' \\\n            + ('hard,' if args.hard else '') \\\n            + ('fix,' if args.fixed_noise else '')\n    else:\n        raise NotImplementedError\n    exp_name += f'epo_{args.num_epochs},' \\\n        + f'b_{args.batch_size},' \\\n        + f'lr_{args.lr},' \\\n        + f'k_{args.sample_size},' \\\n        + (f'eval_k_{args.eval_sample_size},' if args.sample_size != args.eval_sample_size else '') \\\n        + (f'clip_{args.gradient_clip},' if args.gradient_clip else '') \\\n        + (f'wu_{args.lr_warmup_epochs},' if args.lr_warmup_epochs > 0 else '')\n    if args.interface == 'prob':\n        exp_name += (f'entropy_{args.entropy_loss_scale},' if args.entropy_loss_scale > 0.0 else '')\n    exp_name += args.postfix\n    return exp_name\n\n\ndef configure_model(args, step_per_epoch):\n    # setup save directory\n    exp_name = configure_experiment_name(args)\n    ckpt_dir = Path(args.save_dir) / exp_name\n    if ckpt_dir.exists():\n        if args.skip_if_run_exists:\n            print(f'ckpt_dir {ckpt_dir} already exists. terminating.')\n            sys.exit()\n        while True:\n            print(f'ckpt_dir {ckpt_dir} already exists. overwrite? [y/n]')\n            inp = input()\n            if inp == 'y':\n                break\n            if inp == 'n':\n                sys.exit()\n            print('invalid input')\n    ckpt_dir.mkdir(parents=True, exist_ok=True)\n    # setup model\n    device = configure_device(args)\n    model = InterfacedModel(\n        n=64,\n        d=2,\n        interface=args.interface,\n        num_interface_layers=args.num_interface_layers,\n        backbone=args.backbone,\n        fixed_noise=args.fixed_noise,\n        noise_scale=args.noise_scale,\n        tau=args.tau,\n        hard=args.hard,\n        task='EXPclassify',\n        backbone_seed=args.backbone_seed,\n        interface_seed=args.interface_seed\n    ).to(device)\n    # setup optimizer and lr scheduler\n    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n    total_steps = step_per_epoch * args.num_epochs\n    warmup_steps = int(args.lr_warmup_epochs / args.num_epochs * total_steps)\n    def lr_lambda(step):\n        if step < warmup_steps:\n            return float(step) / float(max(1, warmup_steps))\n        if args.lr_decay_after_warmup:\n            return max(0.0, float(total_steps - step) / float(max(1, total_steps - warmup_steps)))\n        return 1.0\n    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n    return model, optimizer, lr_scheduler, ckpt_dir.as_posix()\n\n\ndef configure_experiment(args):\n    # setup log directory\n    exp_name = configure_experiment_name(args)\n    log_dir = Path(args.log_dir) / exp_name\n    if log_dir.exists():\n        if args.skip_if_run_exists:\n            print(f'log_dir {log_dir} already exists. terminating.')\n            sys.exit()\n        while True:\n            print(f'log_dir {log_dir} already exists. overwrite? [y/n]')\n            inp = input()\n            if inp == 'y':\n                break\n            if inp == 'n':\n                sys.exit()\n            print('invalid input')\n    log_dir.mkdir(parents=True, exist_ok=True)\n    # setup logger\n    logger =  SummaryWriter(log_dir)\n    return logger\n\n\ndef train_epoch(model, optimizer, lr_scheduler, train_loader, device, args):\n    model.train()\n    epoch_loss_sum = 0\n    epoch_entropy_loss_sum = 0\n    total = 0\n    for data in train_loader:\n        data = data.to(device)\n        optimizer.zero_grad()\n        pred, entropy_loss = model(data, n_samples=args.sample_size)\n        # pred: [b, 1]\n        loss = F.binary_cross_entropy_with_logits(pred, data.y[:, None].float())\n        total_loss = loss\n        if args.entropy_loss_scale > 0.0:\n            total_loss = loss + args.entropy_loss_scale * entropy_loss\n        total_loss.backward()\n        if args.gradient_clip:\n            torch.nn.utils.clip_grad.clip_grad_norm_(model.parameters(), args.gradient_clip)\n        optimizer.step()\n        lr_scheduler.step()\n        epoch_loss_sum += loss.item() * len(data.y)\n        epoch_entropy_loss_sum += entropy_loss.item() * len(data.y)\n        total += len(data.y)\n    epoch_loss_mean = epoch_loss_sum / total\n    epoch_entropy_loss_mean = epoch_entropy_loss_sum / total\n    return epoch_loss_mean, epoch_entropy_loss_mean\n\n\n@torch.no_grad()\ndef eval_epoch(model, loader, device, args):\n    model.eval()\n    epoch_loss_sum = 0\n    epoch_entropy_loss_sum = 0\n    correct = 0\n    total = 0\n    for data in loader:\n        data = data.to(device)\n        pred, entropy_loss = model(data, n_samples=args.eval_sample_size)\n        correct += torch.round(F.sigmoid(pred)).eq(data.y[:, None].float()).sum().item()\n        loss = F.binary_cross_entropy_with_logits(pred, data.y[:, None].float())\n        epoch_loss_sum += loss.item() * len(data.y)\n        epoch_entropy_loss_sum += entropy_loss.item() * len(data.y)\n        total += len(data.y)\n    epoch_acc = correct / total\n    epoch_loss_mean = epoch_loss_sum / total\n    epoch_entropy_loss_mean = epoch_entropy_loss_sum / total\n    return epoch_acc, epoch_loss_mean, epoch_entropy_loss_mean\n\n\ndef main(args):\n    # reproducibility\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    torch.cuda.manual_seed_all(args.seed)\n    torch.use_deterministic_algorithms(True)\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n\n    # configure device\n    device = configure_device(args)\n\n    # configure data\n    train_loader, val_loader, test_loader = configure_data(args)\n\n    # configure model\n    model, optimizer, lr_scheduler, ckpt_dir = configure_model(args, len(train_loader))\n\n    # configure experiment\n    logger = configure_experiment(args)\n\n    # main loop\n    best_val_loss = float('inf')\n    best_val_acc = 0\n    best_test_acc = 0\n    torch.save(model.state_dict(), Path(ckpt_dir) / 'epoch_init.ckpt')\n    for epoch in range(args.num_epochs + 1):\n        # train\n        train_loss, train_entropy_loss = train_epoch(model, optimizer, lr_scheduler, train_loader, device, args)\n        # eval\n        val_acc, val_loss, val_entropy_loss = eval_epoch(model, val_loader, device, args)\n        test_acc, _, _ = eval_epoch(model, test_loader, device, args)\n        # save\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_val_acc = val_acc\n            best_test_acc = test_acc\n            torch.save(model.state_dict(), Path(ckpt_dir) / 'best.ckpt')\n        if epoch % args.save_interval == 0:\n            torch.save(model.state_dict(), Path(ckpt_dir) / f'epoch_{epoch}.ckpt')\n        # log\n        logger.add_scalar('train/loss', train_loss, epoch)\n        logger.add_scalar('train/entropy loss', train_entropy_loss, epoch)\n        logger.add_scalar('val/acc', val_acc, epoch)\n        logger.add_scalar('val/loss', val_loss, epoch)\n        logger.add_scalar('val/entropy loss', val_entropy_loss, epoch)\n        logger.add_scalar('test/acc', test_acc, epoch)\n        logger.add_scalar('val/best acc', best_val_acc, epoch)\n        logger.add_scalar('val/best loss', best_val_loss, epoch)\n        logger.add_scalar('test/best acc', best_test_acc, epoch)\n        print(f'epoch {epoch:04d} | ' \\\n              f'loss {train_loss:.4f} | ' \\\n              f'val loss {val_loss:.4f} | ' \\\n              f'best val loss {best_val_loss:.4f} | ' \\\n              f'best test acc {best_test_acc * 100:.1f}%')\n    # close\n    logger.flush()\n    logger.close()\n\n\nif __name__ == '__main__':\n    args_ = get_args()\n    main(args_)\n"}
{"type": "source_file", "path": "src/train/configure_experiment.py", "content": "# pylint: disable=too-many-arguments,unused-argument,no-member\nimport os\nimport sys\nimport shutil\nfrom pathlib import Path\nimport tqdm\nimport pytorch_lightning as pl\nfrom pytorch_lightning.strategies import DDPStrategy\nfrom pytorch_lightning.loggers.wandb import WandbLogger\nfrom pytorch_lightning.callbacks.progress.tqdm_progress import TQDMProgressBar\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n\ndef configure_experiment(config, model):\n    # setup log and save directories\n    log_dir = setup_log_directory(\n        root_dir=config.root_dir,\n        log_dir=config.log_dir,\n        dataset=config.dataset,\n        exp_name=config.exp_name,\n        exp_subname=config.exp_subname,\n        debug_mode=config.debug_mode,\n        resume_mode=config.resume_mode,\n        test_mode=config.test_mode,\n        reset_mode=config.reset_mode\n    )\n    save_dir = setup_save_directory(\n        root_dir=config.root_dir,\n        save_dir=config.save_dir,\n        dataset=config.dataset,\n        exp_name=config.exp_name,\n        exp_subname=config.exp_subname,\n        debug_mode=config.debug_mode,\n        resume_mode=config.resume_mode,\n        test_mode=config.test_mode,\n        skip_mode=config.skip_mode,\n        reset_mode=config.reset_mode\n    )\n    # setup lightning callbacks, logger, precision, strategy, and plugins\n    callbacks = setup_callbacks(\n        no_eval=config.no_eval,\n        no_save=config.no_save,\n        save_dir=save_dir,\n        early_stopping_monitor=config.early_stopping_monitor,\n        early_stopping_mode=config.early_stopping_mode,\n        early_stopping_patience=config.early_stopping_patience\n    )\n    logger = setup_logger(\n        log_dir=log_dir,\n        team_name=config.team_name,\n        dataset_name=config.dataset,\n        exp_name=config.exp_name\n    )\n    precision = setup_precision(precision=config.precision)\n    strategy = setup_strategy(strategy=config.strategy)\n    plugins = setup_plugins(model=model)\n    return logger, log_dir, callbacks, precision, strategy, plugins\n\n\ndef setup_log_directory(root_dir='experiments', log_dir='logs',\n                        dataset='', exp_name='', dir_postfix='', exp_subname='',\n                        debug_mode=False, resume_mode=False,\n                        test_mode=False, reset_mode=False):\n    dataset = dataset.replace('/', '_')\n    log_dir = Path(root_dir) / log_dir / dataset / (exp_name + dir_postfix) / exp_subname\n    IS_RANK_ZERO = int(os.environ.get('LOCAL_RANK', 0)) == 0\n    if log_dir.exists() and IS_RANK_ZERO:\n        if debug_mode or reset_mode:\n            print(f'remove existing logs ({exp_name})')\n            shutil.rmtree(log_dir)\n        elif resume_mode or test_mode:\n            pass\n        else:\n            while True:\n                print(f'redundant log directory! ({log_dir}) remove existing logs? (y/n)')\n                inp = input()\n                if inp == 'y':\n                    shutil.rmtree(log_dir)\n                    break\n                if inp == 'n':\n                    print('quit')\n                    sys.exit()\n                print('invalid input')\n    log_dir.mkdir(parents=True, exist_ok=True)\n    return log_dir.as_posix()\n\n\ndef setup_save_directory(root_dir='experiments', save_dir='checkpoints',\n                         dataset='', exp_name='', dir_postfix='', exp_subname='',\n                         debug_mode=False, resume_mode=False, test_mode=False,\n                         skip_mode=False, reset_mode=False):\n    # create save directory if checkpoint doesn't exist or in skipping mode,\n    # otherwise ask user to reset it\n    dataset = dataset.replace('/', '_')\n    save_dir = Path(root_dir) / save_dir / dataset / (exp_name + dir_postfix) / exp_subname\n    IS_RANK_ZERO = int(os.environ.get('LOCAL_RANK', 0)) == 0\n    if save_dir.exists() and IS_RANK_ZERO:\n        if resume_mode:\n            print(f'resume from checkpoint ({exp_name})')\n        elif test_mode:\n            print(f'test existing checkpoint ({exp_name})')\n        elif skip_mode:\n            print(f'skip the existing checkpoint ({exp_name})')\n            sys.exit()\n        elif debug_mode or reset_mode:\n            print(f'remove existing checkpoint ({exp_name})')\n            shutil.rmtree(save_dir)\n        else:\n            while True:\n                print(f'redundant experiment name! ({exp_name}) remove existing checkpoints? (y/n)')\n                inp = input()\n                if inp == 'y':\n                    shutil.rmtree(save_dir)\n                    break\n                if inp == 'n':\n                    print('quit')\n                    sys.exit()\n                print('invalid input')\n    save_dir.mkdir(parents=True, exist_ok=True)\n    return save_dir.as_posix()\n\n\nclass CustomEarlyStopping(EarlyStopping):\n    def __init__(\n            self,\n            monitor,\n            patience,\n            verbose,\n            mode,\n            check_on_train_epoch_end\n        ):\n        super().__init__(\n            monitor=monitor,\n            patience=patience,\n            verbose=verbose,\n            mode=mode,\n            check_on_train_epoch_end=check_on_train_epoch_end\n        )\n        self.patience_for_overriding = patience\n\n    def on_validation_end(self, trainer, pl_module):\n        if self.patience_for_overriding != self.patience:\n            if self.verbose:\n                print(\"Overriding early stopping patience loaded from checkpoint: \"\n                      f\"{self.patience} -> {self.patience_for_overriding}\")\n            self.patience = self.patience_for_overriding\n        self._run_early_stopping_check(trainer)\n\n\ndef setup_callbacks(no_eval, no_save, save_dir, early_stopping_monitor, early_stopping_mode, early_stopping_patience):\n    callbacks = [\n        CustomProgressBar(),\n    ]\n    IS_RANK_ZERO = int(os.environ.get('LOCAL_RANK', 0)) == 0\n    if not no_eval and early_stopping_monitor is not None and early_stopping_patience > 0:\n        callbacks.append(\n            CustomEarlyStopping(\n                monitor=early_stopping_monitor,\n                patience=early_stopping_patience,\n                verbose=IS_RANK_ZERO,\n                mode=early_stopping_mode,\n                check_on_train_epoch_end=False\n            )\n        )\n    if not no_save and save_dir is not None:\n        # last checkpointing\n        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n            dirpath=save_dir,\n            filename='last',\n            monitor='epoch',\n            verbose=False,\n            save_last=False,\n            save_top_k=1,\n            mode='max',\n            auto_insert_metric_name=False,\n            every_n_epochs=1\n        )\n        checkpoint_callback.CHECKPOINT_JOIN_CHAR = \"_\"\n        callbacks.append(checkpoint_callback)\n        # best checkpointing\n        if not (no_eval or early_stopping_monitor is None):\n            checkpoint_callback = pl.callbacks.ModelCheckpoint(\n                dirpath=save_dir,\n                filename='best',\n                monitor=early_stopping_monitor,\n                verbose=IS_RANK_ZERO,\n                save_last=False,\n                save_top_k=1,\n                mode=early_stopping_mode,\n                auto_insert_metric_name=False,\n                every_n_epochs=1\n            )\n            checkpoint_callback.CHECKPOINT_JOIN_CHAR = \"_\"\n            callbacks.append(checkpoint_callback)\n    return callbacks\n\n\ndef setup_logger(log_dir, team_name, dataset_name, exp_name):\n    logger = WandbLogger(\n        name=exp_name,\n        save_dir=log_dir,\n        project=dataset_name.replace('/', '_'),\n        entity=team_name,\n        log_model=True\n    )\n    return logger\n\n\ndef setup_plugins(model):\n    plugins = []\n    return plugins\n\n\ndef setup_precision(precision):\n    return int(precision.strip('fp')) if precision in ['fp16', 'fp32'] else precision\n\n\ndef setup_strategy(strategy):\n    if strategy == 'ddp':\n        strategy = DDPStrategy(find_unused_parameters=True)\n    else:\n        strategy = None\n    return strategy\n\n\nclass CustomProgressBar(TQDMProgressBar):\n    def __init__(self, rescale_validation_batches=1):\n        super().__init__()\n        self.rescale_validation_batches = rescale_validation_batches\n\n    def init_train_tqdm(self):\n        \"\"\"Override this to customize the tqdm bar for training.\"\"\"\n        pbar = tqdm.tqdm(\n            desc=\"Training\",\n            bar_format=\"{desc:<5}{percentage:3.0f}%|{bar:10}{r_bar}\",\n            position=(2 * self.process_position),\n            disable=self.is_disabled,\n            leave=True,\n            dynamic_ncols=True,\n            file=sys.stdout,\n            smoothing=0,\n        )\n        return pbar\n\n    def init_validation_tqdm(self):\n        \"\"\"Override this to customize the tqdm bar for validation.\"\"\"\n        # The main progress bar doesn't exist in `trainer.validate()`\n        has_main_bar = self.trainer.state.fn != \"validate\"\n        pbar = tqdm.tqdm(\n            desc=\"Validation\",\n            bar_format=\"{desc:<5}{percentage:3.0f}%|{bar:10}{r_bar}\",\n            position=(2 * self.process_position + has_main_bar),\n            disable=self.is_disabled,\n            leave=not has_main_bar,\n            dynamic_ncols=True,\n            file=sys.stdout,\n        )\n        return pbar\n\n    def init_test_tqdm(self):\n        \"\"\"Override this to customize the tqdm bar for testing.\"\"\"\n        pbar = tqdm.tqdm(\n            desc=\"Testing\",\n            bar_format=\"{desc:<5}{percentage:3.0f}%|{bar:10}{r_bar}\",\n            position=(2 * self.process_position),\n            disable=self.is_disabled,\n            leave=True,\n            dynamic_ncols=True,\n            file=sys.stdout,\n        )\n        return pbar\n"}
{"type": "source_file", "path": "src_synthetic/graph_separation/graph8c.py", "content": "# pylint: disable=not-callable,line-too-long\n# https://github.com/omri1348/Frame-Averaging/blob/master/graph_separation/graph8c.py\nimport random\nimport numpy as np\nimport torch\nfrom torch_geometric.loader import DataLoader\n\nfrom args import get_args\nfrom dataset import GRAPH8cDataset\nfrom preprocess import PrecomputeSpectral, PrecomputeSortFrame, PrecomputePad\nfrom interface import InterfacedModel\n\n\ndef main(args):\n    # configure device\n    device = torch.device(f'cuda:{args.device_id}' if torch.cuda.is_available() else 'cpu')\n\n    # configure data\n    pre_transform = PrecomputeSpectral(nmax=8, recfield=1, dv=2, nfreq=5, adddegree=True)\n    pre_transform = PrecomputeSortFrame(pre_transform, device)\n    transform = PrecomputePad(nmax=8)\n    dataset = GRAPH8cDataset(root='dataset/graph8c/', transform=transform, pre_transform=pre_transform)\n    train_loader = DataLoader(dataset, args.batch_size, shuffle=False)\n\n    # main loop\n    M = 0\n    for seed in range(100):\n        random.seed(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\n        # configure model\n        model = InterfacedModel(\n            n=8,\n            d=2,\n            interface=args.interface,\n            num_interface_layers=args.num_interface_layers,\n            backbone=args.backbone,\n            noise_scale=args.noise_scale,\n            tau=args.tau,\n            hard=args.hard,\n            task='GRAPH8c'\n        ).to(device)\n\n        # run test\n        embeddings = []\n        model.eval()\n        for data in train_loader:\n            data = data.to(device)\n            emb, _ = model(data, n_samples=args.eval_sample_size)\n            embeddings.append(emb)\n\n        E = torch.cat(embeddings).cpu().detach().numpy()\n        M = M+1*((np.abs(np.expand_dims(E, 1)-np.expand_dims(E, 0))).sum(2) > 0.001)\n        sm = ((M == 0).sum()-M.shape[0])/2\n        print('similar:', sm)\n\n\nif __name__ == '__main__':\n    args_ = get_args()\n    main(args_)\n"}
