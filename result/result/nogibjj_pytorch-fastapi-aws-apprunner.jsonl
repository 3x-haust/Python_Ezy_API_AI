{"repo_info": {"repo_name": "pytorch-fastapi-aws-apprunner", "repo_owner": "nogibjj", "repo_url": "https://github.com/nogibjj/pytorch-fastapi-aws-apprunner"}}
{"type": "test_file", "path": "test_main.py", "content": "\"\"\"\nTest goes here\n\n\"\"\"\n\nfrom mylib.calculator import add\n\n\ndef test_add():\n    assert add(1, 2) == 3\n"}
{"type": "source_file", "path": "main.py", "content": "\"\"\"\nMain cli or app entry point\n\"\"\"\n\nfrom mylib.calculator import add\nimport click\n\n\n@click.command(\"add\")\n@click.argument(\"a\", type=int)\n@click.argument(\"b\", type=int)\ndef add_cli(a, b):\n    click.echo(add(a, b))\n\n\nif __name__ == \"__main__\":\n    # pylint: disable=no-value-for-parameter\n    add_cli()\n"}
{"type": "source_file", "path": "app.py", "content": "\"\"\"\nBuild a PyTorch model that can be used for prediction served out via FastAPI\n\"\"\"\n\nimport io\nimport json\n\nfrom torchvision import models\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport fastapi\nfrom fastapi import File, UploadFile\nimport uvicorn\n\napp = fastapi.FastAPI()\n\nmodel = models.densenet121(weights=\"DenseNet121_Weights.IMAGENET1K_V1\")\nmodel.eval()\nimagenet_class_index = json.load(open(\"imagenet_class_index.json\", encoding=\"utf-8\"))\n\n\ndef transform_image(image_bytes):\n    my_transforms = transforms.Compose(\n        [\n            transforms.Resize(255),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]\n    )\n    image = Image.open(io.BytesIO(image_bytes))\n    return my_transforms(image).unsqueeze(0)\n\n\ndef get_prediction(image_bytes):\n    tensor = transform_image(image_bytes=image_bytes)\n    outputs = model.forward(tensor)\n    _, y_hat = outputs.max(1)\n    predicted_idx = str(y_hat.item())\n    return imagenet_class_index[predicted_idx]\n\n\n@app.get(\"/\")\ndef index():\n    return {\"message\": \"Hello World\"}\n\n\n@app.post(\"/files/\")\nasync def create_file(file: bytes = File()):\n    return {\"file_size\": len(file)}\n\n\n@app.post(\"/uploadfile/\")\nasync def create_upload_file(file: UploadFile):\n    return {\"filename\": file.filename}\n\n\n@app.post(\"/predict\")\nasync def predict(file: UploadFile = File(...)):\n    image_bytes = await file.read()\n    print(len(image_bytes))\n    class_id, class_name = get_prediction(image_bytes=image_bytes)\n    return {\"class_id\": class_id, \"class_name\": class_name}\n\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8080)\n"}
{"type": "source_file", "path": "mylib/__init__.py", "content": ""}
{"type": "source_file", "path": "utils/quickstart_tf2.py", "content": "#!/usr/bin/env python\n\nimport tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10)\n])\npredictions = model(x_train[:1]).numpy()\npredictions\ntf.nn.softmax(predictions).numpy()\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nloss_fn(y_train[:1], predictions).numpy()\nmodel.compile(optimizer='adam',\n              loss=loss_fn,\n              metrics=['accuracy'])\nmodel.fit(x_train, y_train, epochs=5)\nmodel.evaluate(x_test,  y_test, verbose=2)\nprobability_model = tf.keras.Sequential([\n  model,\n  tf.keras.layers.Softmax()\n])\nprobability_model(x_test[:5])"}
{"type": "source_file", "path": "mylib/calculator.py", "content": "\"\"\"\nCalculations library\n\"\"\"\n\n\ndef add(a, b):\n    return a + b\n\n\ndef subtract(a, b):\n    return a - b\n\n\ndef multiply(a, b):\n    return a * b\n\n\ndef divide(a, b):\n    return a / b"}
{"type": "source_file", "path": "utils/verify_pytorch.py", "content": "import torch\n\nif torch.cuda.is_available():\n    print(\"CUDA is available\")\n    print(\"CUDA version: {}\".format(torch.version.cuda))\n    print(\"PyTorch version: {}\".format(torch.__version__))\n    print(\"cuDNN version: {}\".format(torch.backends.cudnn.version()))\n    print(\"Number of CUDA devices: {}\".format(torch.cuda.device_count()))\n    print(\"Current CUDA device: {}\".format(torch.cuda.current_device()))\n    print(\"Device name: {}\".format(torch.cuda.get_device_name(torch.cuda.current_device())))\nelse:\n    print(\"CUDA is not available\")"}
{"type": "source_file", "path": "utils/verify_tf.py", "content": "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"}
{"type": "source_file", "path": "utils/quickstart_pytorch.py", "content": "\"\"\"\n`Learn the Basics <intro.html>`_ ||\n**Quickstart** ||\n`Tensors <tensorqs_tutorial.html>`_ ||\n`Datasets & DataLoaders <data_tutorial.html>`_ ||\n`Transforms <transforms_tutorial.html>`_ ||\n`Build Model <buildmodel_tutorial.html>`_ ||\n`Autograd <autogradqs_tutorial.html>`_ ||\n`Optimization <optimization_tutorial.html>`_ ||\n`Save & Load Model <saveloadrun_tutorial.html>`_\n\nQuickstart\n===================\nThis section runs through the API for common tasks in machine learning. Refer to the links in each section to dive deeper.\n\nWorking with data\n-----------------\nPyTorch has two `primitives to work with data <https://pytorch.org/docs/stable/data.html>`_:\n``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``.\n``Dataset`` stores the samples and their corresponding labels, and ``DataLoader`` wraps an iterable around\nthe ``Dataset``.\n\n\"\"\"\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\n######################################################################\n# PyTorch offers domain-specific libraries such as `TorchText <https://pytorch.org/text/stable/index.html>`_,\n# `TorchVision <https://pytorch.org/vision/stable/index.html>`_, and `TorchAudio <https://pytorch.org/audio/stable/index.html>`_,\n# all of which include datasets. For this tutorial, we  will be using a TorchVision dataset.\n#\n# The ``torchvision.datasets`` module contains ``Dataset`` objects for many real-world vision data like\n# CIFAR, COCO (`full list here <https://pytorch.org/vision/stable/datasets.html>`_). In this tutorial, we\n# use the FashionMNIST dataset. Every TorchVision ``Dataset`` includes two arguments: ``transform`` and\n# ``target_transform`` to modify the samples and labels respectively.\n\n# Download training data from open datasets.\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\n# Download test data from open datasets.\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)\n\n######################################################################\n# We pass the ``Dataset`` as an argument to ``DataLoader``. This wraps an iterable over our dataset, and supports\n# automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element\n# in the dataloader iterable will return a batch of 64 features and labels.\n\nbatch_size = 64\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break\n\n######################################################################\n# Read more about `loading data in PyTorch <data_tutorial.html>`_.\n#\n\n######################################################################\n# --------------\n#\n\n################################\n# Creating Models\n# ------------------\n# To define a neural network in PyTorch, we create a class that inherits\n# from `nn.Module <https://pytorch.org/docs/stable/generated/torch.nn.Module.html>`_. We define the layers of the network\n# in the ``__init__`` function and specify how data will pass through the network in the ``forward`` function. To accelerate\n# operations in the neural network, we move it to the GPU if available.\n\n# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\nprint(model)\n\n######################################################################\n# Read more about `building neural networks in PyTorch <buildmodel_tutorial.html>`_.\n#\n\n\n######################################################################\n# --------------\n#\n\n\n#####################################################################\n# Optimizing the Model Parameters\n# ----------------------------------------\n# To train a model, we need a `loss function <https://pytorch.org/docs/stable/nn.html#loss-functions>`_\n# and an `optimizer <https://pytorch.org/docs/stable/optim.html>`_.\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\n\n#######################################################################\n# In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and\n# backpropagates the prediction error to adjust the model's parameters.\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n##############################################################################\n# We also check the model's performance against the test dataset to ensure it is learning.\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n\n##############################################################################\n# The training process is conducted over several iterations (*epochs*). During each epoch, the model learns\n# parameters to make better predictions. We print the model's accuracy and loss at each epoch; we'd like to see the\n# accuracy increase and the loss decrease with every epoch.\n\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")\n\n######################################################################\n# Read more about `Training your model <optimization_tutorial.html>`_.\n#\n\n######################################################################\n# --------------\n#\n\n######################################################################\n# Saving Models\n# -------------\n# A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n\ntorch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch Model State to model.pth\")\n\n\n\n######################################################################\n# Loading Models\n# ----------------------------\n#\n# The process for loading a model includes re-creating the model structure and loading\n# the state dictionary into it.\n\nmodel = NeuralNetwork()\nmodel.load_state_dict(torch.load(\"model.pth\"))\n\n#############################################################\n# This model can now be used to make predictions.\n\nclasses = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\",\n]\n\nmodel.eval()\nx, y = test_data[0][0], test_data[0][1]\nwith torch.no_grad():\n    pred = model(x)\n    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n\n\n######################################################################\n# Read more about `Saving & Loading your model <saveloadrun_tutorial.html>`_.\n#"}
