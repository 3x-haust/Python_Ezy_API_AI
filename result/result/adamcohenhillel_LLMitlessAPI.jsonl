{"repo_info": {"repo_name": "LLMitlessAPI", "repo_owner": "adamcohenhillel", "repo_url": "https://github.com/adamcohenhillel/LLMitlessAPI"}}
{"type": "source_file", "path": "app/__init__.py", "content": ""}
{"type": "source_file", "path": "run.py", "content": "\"\"\"LLMitlessAPI\n\"\"\"\nimport uvicorn\n\nfrom app.api import app\n\nif __name__ == '__main__':\n    print('\\33[36mAPI Running.\\33[0m')\n    uvicorn.run(app, host='0.0.0.0', port=8000, log_level=\"critical\")\n"}
{"type": "source_file", "path": "app/api.py", "content": "\"\"\"LLMitlessAPI\n\"\"\"\nfrom uuid import uuid4\nfrom typing import Dict\n\nfrom fastapi import FastAPI, BackgroundTasks\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\n\nfrom app.agent import agent_loop\n\n\napp = FastAPI()\n\norigins = [\"*\"]\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\nclass RequestBody(BaseModel):\n    \"\"\"\n    \"\"\"\n    service: str\n    data: str\n\n\ntasks_status: Dict[str, str] = {}\n\n\n@app.post('/')\nasync def trigger_new_task(\n    body: RequestBody,\n    background_tasks: BackgroundTasks\n) -> Dict[str, str]:\n    new_task_id = str(uuid4())\n    background_tasks.add_task(\n        agent_loop,\n        task_id=new_task_id,\n        tasks_status=tasks_status,\n        service=body.service,\n        data=body.data\n    )\n    tasks_status[new_task_id] = \"running\"\n    return {\"task_id\": new_task_id}\n\n\n@app.get(\"/{task_id}\")\nasync def check_task(task_id: str) -> Dict[str, str]:\n    if task_id in tasks_status:\n        status = tasks_status[task_id]\n    else:\n        status = \"not found\"\n    return {\"result\": status}"}
{"type": "source_file", "path": "app/agent.py", "content": "import os\nimport json\nfrom typing import Dict\n\nimport openai\nfrom openai.embeddings_utils import distances_from_embeddings\nimport pandas as pd\nimport tiktoken\n\n\nopenai.api_key = os.environ.get('OPENAI_APIKEY')\nmemory = pd.DataFrame([], columns = ['text', 'embeddings', 'n_tokens', 'distances'])\n\nACTIONS: dict = {\n    \"SAVE\": \"Save information to database, so you can retrieve it later\",\n    \"FETCH\": \"Fetch information from database\",\n    \"EVAL\": \"Execute a python expression that is present inside a string\",\n    \"FINISHED\": \"Finish serving the request\",\n}\n\n\ndef fetch(memory: pd.DataFrame, to_retrieve: str, depth: int = 50) -> str:\n    \"\"\"Trying to retrieve information from memory\n\n    :param memory: A dataframe of the texts and their embeddings\n    :param retrieve: The information to retrieve from memory\n    :param depth: How many results to return\n\n    :return: The information retrieved from memory\n    \"\"\"\n    to_retrieve = str(to_retrieve).replace(\"{\", \" \").replace(\"}\", \" \")\n    info_embedded = openai.Embedding.create(\n        input=to_retrieve,\n        engine='text-embedding-ada-002'\n    )['data'][0]['embedding']\n\n    # Get the distances from the embeddings\n    memory['distances'] = distances_from_embeddings(\n        info_embedded,\n        memory['embeddings'].values,\n        distance_metric='cosine'\n    )\n\n    relevant_memories = []\n    for _, row in memory.sort_values('distances', ascending=True).head(depth).iterrows():\n        relevant_memories.append(row[\"text\"])\n\n    return \"\\n###\\n\".join(relevant_memories)\n\n\ndef save(memory: pd.DataFrame, information: str) -> pd.DataFrame:\n    \"\"\"Saving information to memory (embeddings)\n\n    :param memory: A dataframe of the texts and their embeddings\n    :param information: The information to save to memory\n\n    :return: Updated dataframe of the memory with the new information\n    \"\"\"\n    information = str(information).replace(\"{\", \" \").replace(\"}\", \" \")\n    tokenizer: tiktoken.Encoding = tiktoken.get_encoding(\"cl100k_base\")\n    n_tokens = len(tokenizer.encode(information))\n    embeddings = openai.Embedding.create(\n        input=str(information),\n        engine='text-embedding-ada-002'\n    )['data'][0]['embedding']\n    new_memory = pd.concat([\n        memory,\n        pd.DataFrame([{'text': information, 'n_tokens': n_tokens, 'embeddings': embeddings}])\n    ], ignore_index=True)\n    return new_memory\n\n\ndef thought_process(conversation_context: list, service: str, data: dict):\n    \"\"\"Uses to decide what to do next, based on the previous actions and the constraints of the agent's world.\n    \"\"\"\n\n    meta_prompt = '''You are autonomus agent called \"assistant\" which act as an API service. You are given a service to act as, and a body data to act on.\nTo serve the request, you must choose one of following actions, one at a time, until you finish serving the request.\nActions:\n<actions>\n\nRules:\n1. As \"assistant\", you MUST response only with the following JSON format:\\n{\"action\": \"<ACTION>\", \"info\": \"<INFO_FOR_THE_ACTION>\"}\n2. Action must be one of the provided actions above.\n3. The responses from \"user\" are the results of the action you performed. Use them to choose your next action.\n4. When finished serving a request, include the end response to the user with the FINISHED action.\n'''\n\n    meta_prompt = meta_prompt.replace(\"<actions>\", \"\\n\".join([f\"{i+1}. {k} - {v}\" for i, (k, v) in enumerate(ACTIONS.items())]))\n\n    conversation_context = [\n        {\"role\": \"system\", \"content\": meta_prompt},\n        {\"role\": \"user\", \"content\": f\"Service: {service}\\nBody Data: {data}\"},\n        *conversation_context\n    ]\n    \n    try:\n        response = openai.ChatCompletion.create(\n            model=\"gpt-4\",\n            messages=conversation_context,\n        )\n        message = response[\"choices\"][0][\"message\"]\n        return message\n    except Exception as e:\n        print(e)\n        return \"\"\n\n\ndef agent_loop(task_id: str, tasks_status: Dict, service: str, data: str):\n    \"\"\"The main loop of the agent\n\n    \"\"\"\n    global memory\n    print(f'\\33[36m\\nBooting agent for task: {task_id}...\\33[0m')\n\n    conversation_context = []\n    running = True\n\n    while running:\n\n        # Choose the next action:\n        action = thought_process(\n            conversation_context,\n            service,\n            data\n        )\n        conversation_context.append(action)\n\n        try:\n            action_content = json.loads(action[\"content\"])\n\n            # Execute the action:\n            if action_content['action'] == 'SAVE':\n                print(f\"\\33[0;37m\\nSAVE: {action_content['info']}\\33[0m\")\n                memory = save(memory, action_content['info'])\n                conversation_context.append({\"role\": \"user\", \"content\": \"SAVED.\"})\n\n            elif action_content['action'] == 'FETCH':\n                print(f\"\\33[0;37m\\nFetch query: {action_content['info']}\\33[0m\")\n                remembered = fetch(memory, action_content['info']) or \"Nothing found.\"\n                print(f\"\\nFecthed: {remembered}\")\n                conversation_context.append({\"role\": \"user\", \"content\": f\"Remembered: {remembered}\"})\n\n            elif action_content['action'] == 'EXECUTE':\n                print(f\"\\33[0;37m\\nExecute: {action_content['info']}\\33[0m\")\n                try:\n                    result = eval(action_content['info'])\n                    print(f\"\\nCode Result: {result}\")\n                    conversation_context.append({\"role\": \"user\", \"content\": result})\n                except Exception as e:\n                    print(e)\n\n            elif action_content['action'] == 'FINISHED':\n                tasks_status[task_id] = str(action_content['info'])\n                print(f\"\\33[32m\\nFinished: {action_content['info']}\\33[0m\")\n                running = False\n                break\n            print('\\n-----------------------------------')\n\n        except Exception as e:\n            tasks_status[task_id] = \"ERRORED\"\n            print(f\"\\33[31m\\nError: {e}\\33[0m\")\n            raise e\n\n\nif __name__ == \"__main__\":\n    ## only for testing\n    agent_loop(\n        service = \"Get all Adam's messages\",\n        data = \"\",\n        task_id=\"1\",\n        tasks_status={}\n    )\n"}
