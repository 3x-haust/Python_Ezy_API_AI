{"repo_info": {"repo_name": "XAgent", "repo_owner": "OpenBMB", "repo_url": "https://github.com/OpenBMB/XAgent"}}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/test_run.py", "content": "import pytest\nfrom run import parse_args, execute_command_line_process, start_command_line\nfrom unittest.mock import patch\nimport sys\n\n@pytest.fixture\ndef mock_argv(monkeypatch):\n    \"\"\"\n    A pytest fixture to mock the command line arguments.\n    It sets the sys.argv to mimic command line input for testing.\n    \"\"\"\n    test_args = [\"--task\", \"example_task\", \"--upload-files\", \"file1\", \"file2\", \"--model\", \"model1\"]\n    monkeypatch.setattr(sys, 'argv', ['test_script.py'] + test_args)\n\ndef test_parse_args(mock_argv):\n    \"\"\"\n    Test to ensure that the parse_args function correctly parses command line arguments.\n    \"\"\"\n    args = parse_args()\n    assert args.task == \"example_task\", \"Task argument did not match.\"\n    assert args.upload_files == [\"file1\", \"file2\"], \"Upload files argument did not match.\"\n    assert args.model == \"model1\", \"Model argument did not match.\"\n\n@patch('run.start_command_line')\ndef test_execute_command_line_process_quiet_mode(mock_start_command_line, mock_argv):\n    \"\"\"\n    Test to verify if the execute_command_line_process function correctly handles the 'quiet_mode' argument.\n    \"\"\"\n    args = parse_args()\n    execute_command_line_process(args, quiet_mode=True)\n    mock_start_command_line.assert_called_once()\n    print(\"execute_command_line_process called start_command_line in quiet mode.\")\n\n@patch('run.start_command_line')\ndef test_execute_command_line_process_normal_mode(mock_start_command_line, mock_argv):\n    \"\"\"\n    Test to verify if the execute_command_line_process function behaves correctly without the 'quiet_mode' argument.\n    \"\"\"\n    args = parse_args()\n    execute_command_line_process(args, quiet_mode=False)\n    mock_start_command_line.assert_called_once()\n    print(\"execute_command_line_process called start_command_line in normal mode.\")\n\n@patch('run.CommandLine')\ndef test_start_command_line(mock_command_line, mock_argv):\n    \"\"\"\n    Test to ensure the start_command_line function correctly initializes the CommandLine class\n    with the expected CommandLineParam instance based on the parsed arguments.\n    \"\"\"\n    args = parse_args()\n    start_command_line(vars(args))\n\n    called_args, _ = mock_command_line.call_args\n    called_param = called_args[0]\n    assert called_param.task == args.task, \"CommandLineParam task attribute did not match.\"\n    assert called_param.upload_files == args.upload_files, \"CommandLineParam upload_files attribute did not match.\"\n    assert called_param.mode == args.mode, \"CommandLineParam mode attribute did not match.\"\n    print(\"start_command_line function called with correct CommandLineParam.\")\n"}
{"type": "test_file", "path": "tests/test_1106_model_openai.py", "content": "from unittest import mock\nfrom XAgent.ai_functions.request.openai import chatcompletion_request\nimport importlib.metadata as metadata\n\nopenai_version = metadata.version(\"openai\")\n\n\ndef test_1106_model_openai():\n    if openai_version >= \"1.0.0\":\n        # Mock the OpenAI client and response\n        with mock.patch(\"openai.OpenAI\") as mock_openai:\n            mock_client = mock_openai.return_value\n            mock_response = mock_client.chat.completions.create.return_value\n\n            # Mock the model_dump() method\n            mock_model_dump = mock_response.model_dump\n            mock_model_dump.return_value = {\n                \"choices\": [\n                    {\n                        \"finish_reason\": \"stop\",\n                        \"index\": 0,\n                        \"message\": {\"content\": \"Hello, World!\"},\n                    }\n                ]\n            }\n\n            # Call the function\n            response = chatcompletion_request(\n                model=\"gpt-4-1106-preview\", prompt=\"Hello, world\"\n            )\n\n            # Assert that the response is as expected\n            assert response[\"choices\"][0][\"finish_reason\"] == \"stop\"\n            assert response[\"choices\"][0][\"index\"] == 0\n            assert response[\"choices\"][0][\"message\"][\"content\"] == \"Hello, World!\"\n\n    else:\n        with mock.patch(\"openai.ChatCompletion\") as mock_create:\n            mock_response_data = \"\"\"{\"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"message\": {\"content\": \"Hello, World!\"}}]}\"\"\"\n\n            mock_create.create.return_value = mock_response_data\n\n            response = chatcompletion_request(\n                model=\"gpt-4-1106-preview\", prompt=\"Hello, world\"\n            )\n            assert response[\"choices\"][0][\"message\"][\"content\"] == \"Hello, World!\"\n\n    print(f\"Your OpenAI version is {openai_version}, Successful test\")\n\n\n# Run the test\nif __name__ == \"__main__\":\n    test_1106_model_openai()"}
{"type": "test_file", "path": "tests/test_model_alias.py", "content": "from unittest import mock\nfrom XAgent.ai_functions.request.openai import chatcompletion_request\nimport importlib.metadata as metadata\n\nopenai_version = metadata.version(\"openai\")\n\n\ndef test_model_alias():\n    if openai_version >= \"1.0.0\":\n        # Mock the OpenAI client and response\n        with mock.patch(\"openai.OpenAI\") as mock_openai:\n            mock_client = mock_openai.return_value\n            mock_response = mock_client.chat.completions.create.return_value\n\n            # Mock the model_dump() method\n            mock_model_dump = mock_response.model_dump\n            mock_model_dump.return_value = {\n                \"choices\": [\n                    {\n                        \"finish_reason\": \"stop\",\n                        \"index\": 0,\n                        \"message\": {\"content\": \"Hello, World!\"},\n                    }\n                ]\n            }\n\n            # Call the function\n            response = chatcompletion_request(\n                model=\"gpt-4-turbo\", prompt=\"Hello, world\"\n            )\n\n            # Assert that the response is as expected\n            assert response[\"choices\"][0][\"finish_reason\"] == \"stop\"\n            assert response[\"choices\"][0][\"index\"] == 0\n            assert response[\"choices\"][0][\"message\"][\"content\"] == \"Hello, World!\"\n\n    else:\n        with mock.patch(\"openai.ChatCompletion\") as mock_create:\n            mock_response_data = \"\"\"{\"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"message\": {\"content\": \"Hello, World!\"}}]}\"\"\"\n\n            mock_create.create.return_value = mock_response_data\n\n            response = chatcompletion_request(\n                model=\"gpt-4-turbo\", prompt=\"Hello, world\"\n            )\n            assert response[\"choices\"][0][\"message\"][\"content\"] == \"Hello, World!\"\n\n    print(f\"Your OpenAI version is {openai_version}, Successful test\")\n\n\n# Run the test\nif __name__ == \"__main__\":\n    test_model_alias()"}
{"type": "source_file", "path": "ToolServer/ToolServerManager/connections.py", "content": "import os\nimport docker\nimport sqlite3\n\nfrom typing import List, Dict, Optional, Union\n\nfrom motor.motor_asyncio import AsyncIOMotorClient\nfrom motor.core import AgnosticDatabase\nfrom config import CONFIG, logger\n\n\n# Database connection object\n# It may be of two types, either a SQLite Connection (sqlite3.Connection) or \n# an AsyncIO MongoDB Client (AgnosticDatabase), depending on the environment variables set.\n\nDB_TYPE = 'mongodb'\ndb_url = f\"mongodb://{os.getenv('DB_USERNAME', '')}:{os.getenv('DB_PASSWORD', '')}@{os.getenv('DB_HOST', 'localhost')}:{os.getenv('DB_PORT', '27017')}/\"\n\n# Create an instance of AsyncIOMotorClient for asynchronous MongoDB operations.\n# It will be used to connect to the MongoDB database.\nmongo_client = AsyncIOMotorClient(db_url)\n\ndb: AgnosticDatabase = mongo_client[os.getenv('DB_COLLECTION', 'TSM')]\n\n# Log confirmation message\nlogger.info(\"Database connected\")\n\n# Define a Docker client object\n# It will be used for controlling Docker using python.\n# by default it reads the environmental variables DOCKER_HOST, DOCKER_TLS_HOSTNAME, \n# DOCKER_API_VERSION, DOCKER_CERT_PATH, DOCKER_SSL_VERSION, DOCKER_TLS, DOCKER_TLS_VERIFY and DOCKER_TIMEOUT.\ndocker_client = docker.from_env()\n\n# Log confirmation message\nlogger.info(\"Docker client connected\")"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/extensions/__init__.py", "content": ""}
{"type": "source_file", "path": "ToolServer/ToolServerNode/extensions/tools/__init__.py", "content": ""}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/envs/pycoding.py", "content": "import os\nimport re\nimport asyncio\nimport nbformat\n\nfrom typing import Dict,Any\nfrom nbclient import NotebookClient\nfrom nbclient.exceptions import CellExecutionError,DeadKernelError\nfrom nbclient.client import ensure_async\n\nfrom core.register import toolwrapper\nfrom core.base import BaseEnv\nfrom core.exceptions import ToolExecutionError\n\n@toolwrapper()\nclass PythonNotebook(BaseEnv):\n    \"\"\"Python Notebook Environment. Provide a notebook interface to run python code.\"\"\"\n    def __init__(self, config: Dict[str, Any] = None):\n        super().__init__(config)\n        filesystem_config = self.config['filesystem']\n        \n        self.work_directory = filesystem_config[\"work_directory\"]\n        \n        self.nb_cfg = self.config['notebook']\n        \n        if not os.path.exists(self.work_directory):\n            os.mkdir(self.work_directory,mode=0o777)\n\n        # make a new notebook\n        self.nb = nbformat.v4.new_notebook(\n            metadata = {'kernelspec': {'name': 'python', 'language': 'python', 'display_name': 'python'}})\n        self.nbc = NotebookClient(self.nb,timeout=self.nb_cfg['timeout'])\n    \n    async def _running(self):\n        if self.nbc.kc is not None:\n            return await ensure_async(self.nbc.kc.is_alive())\n        return False\n    \n    async def _reset(self):\n        if await self._running():\n            await self.nbc._async_cleanup_kernel()\n        self.nbc.create_kernel_manager()\n        await self.nbc.async_start_new_kernel(cwd=self.work_directory)\n        await self.nbc.async_start_new_kernel_client()\n\n    @staticmethod\n    def _fix_escape(problematic_code: str) -> str:\n        for str_sign in ['\"', \"'\", '\"\"\"', \"'''\"]:\n\n            pattern = rf'{str_sign}(.*?){str_sign}'\n            in_line_strs = re.findall(pattern, problematic_code, re.DOTALL)\n            replaced_in_line_strs = []\n            for in_line_str in in_line_strs:\n                replaced_in_line_strs.append(in_line_str.replace('\\n', '\\\\n').replace('\\r', '\\\\r').replace('\\t', '\\\\t'))\n            for original_str, modified_str in zip(in_line_strs, replaced_in_line_strs):\n                fixed_code = problematic_code.replace(f'{str_sign}' + original_str + f'{str_sign}',\n                                                            f'{str_sign}' + modified_str + f'{str_sign}')\n\n        return fixed_code\n\n        \n    async def execute_cell(self,code:str,cell_index:int=None,reset:bool=False) -> str:\n        \"\"\"Create or replace a notebook cell and execute it, return the output.\n        Use this tool to test your idea quickly. Carefully examine the output to make sure it is what you want.\n        \n        Example:\n        ```\n        In[0]: code='print(\"hello world\")' # This will create a new cell and execute it.\n        Out[0]: ['cell_index: 0', 'hello world']\n        In[1]: code='print(\"hello world\")',cell_index=0 # This will overwrite the first cell and execute it.\n        In[2]: code='print(\"hello world\")',cell_index=-1 # This will overwrite the last cell and execute it.\n        ```\n        \n        :param string code: python code to be executed, make sure it is valid python code with right format. don't provide shell command that started with '!' here.\n        :param integer? cell_index: the index of the cell to be insert and overwrite `code`, default to `None`, which means append new cell.\n        :param boolean? reset: whether to reset the kernel before executing the code. Default to `False`.\n        :return string: execution result.\n        \"\"\"\n        # code = self._fix_escape(code)\n        if reset or not await self._running():\n            await self._reset()\n        if cell_index is None or cell_index == len(self.nb.cells) or len(self.nb.cells) == 0:\n            self.nb.cells.append(nbformat.v4.new_code_cell(code))\n            cell_index = len(self.nb.cells)-1\n        else:\n            self.nb.cells[cell_index] = nbformat.v4.new_code_cell(code)\n        \n        try:\n            await self.nbc.async_execute_cell(self.nb.cells[-1],len(self.nb.cells)-1)\n        except CellExecutionError as e:\n            pass\n        except DeadKernelError as e:\n            await self._reset()\n            \n        nbformat.write(self.nb,os.path.join(self.work_directory,self.nb_cfg['save_name']))\n        \n        return self._format_outputs(self.nb.cells[cell_index].outputs,cell_index,reraise=True,return_binary=True)\n        \n    def print_notebook(self)->str:\n        \"\"\"print all notebook cells' content and output.\n        \n        :return string: all notebook cells description.\n        \"\"\"\n        ret = ''\n        for i,cell in enumerate(self.nb.cells):\n            ret += f'= Cell {i} =\\n'\n            if cell['cell_type'] == 'code':\n                ret += f'{cell[\"source\"]}\\n'\n                if len(cell['outputs']) != 0:\n                    ret += f'= Output {i} =\\n'\n                    ret += f'{self._format_outputs(cell[\"outputs\"])}\\n'\n        return ret\n    def _format_outputs(self,outputs,cell_index=None,reraise=False,return_binary=False):\n        ret = None\n        if len(outputs) == 0:\n            ret = '' if cell_index is None else f'cell_index: {cell_index}'\n        elif len(outputs) == 1:\n            if cell_index is not None:\n                ret = {\n                    'type':'composite',\n                    'data':[\n                        f'cell_index: {cell_index}',\n                        self._format_output(outputs[0],cell_index,reraise,return_binary)\n                    ]\n                }\n            else:\n                ret = self._format_output(outputs[0],cell_index,reraise,return_binary)\n        else:\n            ret = {\n                'type':'composite',\n                'data':[\n                    self._format_output(output,cell_index,reraise,return_binary) for output in outputs\n                ]\n            }\n            if cell_index is not None:\n                ret['data'].insert(0,f'cell_index: {cell_index}')\n        return ret\n        \n    def _format_output(self,output,cell_index=None,reraise=False,return_binary=False):\n        def format_single_data(data,data_type:str):\n            if data_type.startswith('image/'):\n                return {\n                    'type': 'binary',\n                    'media_type':data_type,\n                    'data': data if return_binary else '`Wrapped`'\n                }\n            elif data_type.startswith('text/'):\n                return ''.join(data)\n            elif data_type.startswith('application/'):\n                return data\n            return data\n            \n        ret = None\n        match output['output_type']:\n            case 'execute_result' | 'display_data':\n                keys = list(output['data'].keys())\n                if 'text/html' in keys and 'text/plain' in keys:\n                    keys.remove('text/html') # remove html\n                if len(keys) == 1:\n                    ret = format_single_data(output['data'][keys[0]],keys[0])\n                elif len(keys) > 1:\n                    ret = {\n                        'type': 'composite',\n                        'data':[]\n                    }\n                    for k in keys:\n                        ret['data'].append(format_single_data(output['data'][k],k))\n                    \n            case 'error':\n                if reraise:\n                    raise ToolExecutionError(f'cell_index: {cell_index}\\n'+'\\n'.join(output['traceback']))\n                else:\n                    return '\\n'.join(output['traceback'])\n            case 'stream':\n                ret = output['text']\n            case _:\n                ret = output\n        return ret\n\n    \n"}
{"type": "source_file", "path": "ToolServer/ToolServerManager/main.py", "content": "import os\nimport psutil\nimport uvicorn\nimport httpx\nimport asyncio\nimport traceback\nimport datetime\nimport docker.types\n\nfrom fastapi import FastAPI, Cookie,Request,HTTPException,Response\nfrom fastapi.responses import JSONResponse,RedirectResponse\nfrom config import CONFIG,logger,MANAGER_ID\nfrom connections import db,docker_client\nfrom models import ToolServerNode, NodeChecker\n\napp = FastAPI()\n\n@app.on_event(\"startup\")\nasync def startup():\n    \"\"\"\n    Event handler triggered on startup of the app. Sets up necessary configurations \n    like checking and creating table nodes if not exists in databse, creating subprocess \n    to update node status, and registering path to node. \n    \"\"\"\n    \n    from beanie import init_beanie\n    await init_beanie(database=db,\n                      document_models=[ToolServerNode,NodeChecker],)\n    \n    # create subprocess to update node status\n    if CONFIG['builtin_monitor']:\n        from node_checker import check_nodes_status_loop\n        \n        async for checker in NodeChecker.find_all():\n            if not psutil.pid_exists(checker.pid):\n                checker.delete()\n\n        checker = NodeChecker(\n            manager_id=MANAGER_ID,\n            interval=float(CONFIG['node'].get('health_check_interval',1)),\n            pid=os.getpid()\n            )\n        await checker.save()\n\n        asyncio.create_task(check_nodes_status_loop())\n            \n\n    # register path to node\n    for path in CONFIG['redirect_to_node_path']['post']:\n        app.add_api_route(path, route_to_node, methods=[\"POST\"])\n        \n    for path in CONFIG['redirect_to_node_path']['get']:\n        app.add_api_route(path, route_to_node, methods=[\"GET\"])\n\n@app.on_event(\"shutdown\")\nasync def shutdown():\n    \"\"\"\n    Event handler on shutdown of the app. Specifically closes the database cursor if \n    the database type os sqlite3.\n    \"\"\"\n    async for checker in NodeChecker.find(NodeChecker.manager_id == MANAGER_ID):\n        await checker.delete()\n    db.client.close()\n        \n@app.get('/alive')\nasync def alive():\n    \"\"\"\n    Endpoint to check if the service is running.\n\n    Returns:\n        str: \"alive\"\n    \"\"\"\n    return \"alive\"\n\nasync def wait_for_node_startup(node_id:str):\n    \"\"\"\n    Wait for the startup of node with id node_id. It probes the node status every seconds until \n    creation_wait_seconds reached.\n    \n    Args:\n        node_id (str): The unique identifier of the node whose startup is to be waited for.\n\n    Returns:\n        bool: True if node has started successfully, False if time out occured before node startup.\n    \n    Raises:\n        HTTPException: If node is not found in the databse.\n    \"\"\"\n    MAX_PROBE_TIMES = CONFIG['node']['creation_wait_seconds']\n    probe_times = 0\n    while probe_times < MAX_PROBE_TIMES:\n        node = await ToolServerNode.find_one(ToolServerNode.id == node_id)\n            \n        if node is None:\n            raise HTTPException(status_code=503, detail=\"Failed to detect node status! Node not found in db!\")\n        \n        if CONFIG['node']['health_check']:\n            if node.health == 'healthy':\n                return True\n        else:\n            if node.status == \"running\":\n                return True\n            \n        probe_times += 1\n        await asyncio.sleep(1)\n    return False\n\n@app.post(\"/get_cookie\")\nasync def read_cookie_info():\n    \"\"\"\n    Fetch server version and node info, create docker container and set the response cookies \n    with the key \"node_id\" and value as the id of the created container. Also, adds the created \n    node's details to the databse and waits for the node to startup.\n\n    Returns:\n        JSONResponse: A response object with status, headers and cookies set accordingly.\n\n    Raises:\n        HTTPException: If node creation timeout occurs.\n    \"\"\"\n    # append server version info\n    content = {\"message\": \"add cookie\",\"version\":CONFIG['version']}\n    response = JSONResponse(content=content)\n    response.headers[\"Server\"] = \"ToolServerManager/\" + CONFIG['version']\n    \n    # create a docker container\n    container = docker_client.containers.run(\n        device_requests=[docker.types.DeviceRequest(**req) for req in CONFIG['node']['device_requests']] if CONFIG['node']['device_requests'] else None,\n        **(CONFIG['node']['creation_kwargs']),)\n    logger.info(\"Node created: \" + container.id)\n    response.set_cookie(key=\"node_id\", value=container.id)\n    container.reload()\n    \n    node = ToolServerNode(\n        id=container.id,\n        short_id=container.short_id,\n        status=container.attrs[\"State\"][\"Status\"],\n        ip=container.attrs[\"NetworkSettings\"][\"Networks\"][CONFIG['node']['creation_kwargs']['network']][\"IPAddress\"],\n        port=CONFIG['node'].get('port',31942),\n        last_req_time=datetime.datetime.utcnow(),\n        health=container.attrs['State']['Health']['Status'] if CONFIG['node']['health_check'] else None\n    )\n    await node.insert()\n\n    # probe node status every seconds until creation_wait_seconds reached\n    if await wait_for_node_startup(container.id):\n        return response\n    else:\n        logger.warning(\"Node status detection timeout: \" + container.id)\n        raise HTTPException(status_code=503, detail=\"Node creation timeout!\")\n\n@app.post(\"/reconnect_session\")\nasync def reconnect_session(node_id:str = Cookie(None)):\n    \"\"\"\n    Reconnect session of a node. Fetches node info and restarts the node if it exists.\n\n    Args:\n        node_id (str, optional): The unique identifier of the node. Defaults to Cookie(None).\n\n    Returns:\n        str: Success message if node restarts successfully.\n    \n    Raises:\n        HTTPException: If node restart timeout occurs.\n    \"\"\"\n    node = await ToolServerNode.find_one(ToolServerNode.id == node_id)\n    if node is None:\n        return \"invalid node_id: \" + str(node_id)\n    # restart node\n    container = docker_client.containers.get(node_id)\n    if container is not None:\n        container.restart()\n        logger.info(\"Node restarted: \" + node_id)\n    \n    if await wait_for_node_startup(node_id):\n        return \"Reconnect session: \" + str(node_id)\n    else:\n        logger.warning(\"Node restart timeout: \" + node_id)\n        raise HTTPException(status_code=503, detail=\"Node restart timeout!\")\n\n@app.post(\"/close_session\")\nasync def close_session(node_id:str = Cookie(None)):\n    \"\"\"\n    Close session of a node. Fetches node info and stops the node if it exists and is not already exited.\n\n    Args:\n        node_id (str, optional): The unique identifier of the node. Defaults to Cookie(None).\n\n    Returns:\n        str: Success message if node stops successfully.\n    \"\"\"\n    node = await ToolServerNode.find_one(ToolServerNode.id == node_id)\n    if node is None:\n        return \"invalid node_id: \" + str(node_id)\n    # stop node\n    container = docker_client.containers.get(node_id)\n    if container is not None and container.attrs[\"State\"][\"Status\"] != \"exit\":\n        container.stop()\n        logger.info(\"Node stopped: \" + node_id)\n    return \"Close session: \" + str(node_id)\n\n@app.post(\"/release_session\")\nasync def release_session(node_id:str = Cookie(None)):\n    \"\"\"\n    Release session of a node. Fetches node info and kills the node if it exists and is not already exited. \n    Also, removes the node.\n\n    Args:\n        node_id (str, optional): The unique identifier of the node. Defaults to Cookie(None).\n\n    Returns:\n        str: Success message if node is successfully killed and removed.\n    \"\"\"\n    node = await ToolServerNode.find_one(ToolServerNode.id == node_id)\n    if node is None:\n        return \"invalid node_id: \" + str(node_id)\n    \n    # delete node in docker\n    container = docker_client.containers.get(node_id)\n    if container is not None:\n        if container.attrs[\"State\"][\"Status\"] != \"exited\":\n            container.kill()\n            logger.info(\"Node killed: \" + node_id)\n        container.remove()\n        logger.info(\"Node deleted: \" + node_id)\n    return \"Release session: \" + str(node_id)\n\nasync def route_to_node(requset:Request,*,node_id:str = Cookie(None)):\n    \"\"\"\n    Routes a request to a specific node. Fetches the node info, checks if it is valid and running. Updates latest \n    request time in the database and then sends a post request to the node.\n    \n    Args:\n        request (Request): The request object containing all request information.\n\n    Returns:\n        Response: The response object containing all response information received from the node.\n\n    Raises:\n        HTTPException: If node_id is not valid or if the node is not running or not responding.\n    \"\"\"\n    # logger.info(\"accept node_id:\",node_id)\n    node = await ToolServerNode.find_one(ToolServerNode.id == node_id)\n    if node is None:\n        raise HTTPException(status_code=403,detail=\"invalid node_id: \" + str(node_id)) \n    \n    if node.status != \"running\":\n        raise HTTPException(status_code=503,detail=\"node is not running: \" + str(node_id)) \n\n    # update latest_req_time in db\n    node.last_req_time = datetime.datetime.utcnow()\n    await node.replace()\n        \n    #post request to node\n    method = requset.method\n    headers = dict(requset.headers)\n    body = await requset.body()\n    url = \"http://\" + node.ip +\":\"+str(node.port) + requset.url.path\n    logger.info(\"Request to node: \" + url)\n    \n    async with httpx.AsyncClient(timeout=None) as client:\n        try:\n            response = await client.request(method,url,headers=headers,data=body)\n        except httpx.RequestError:\n            traceback.print_exc()\n            raise HTTPException(status_code=503, detail=\"node is not responding\")\n    logger.info('Response from node: ' + str(response.status_code))\n    res = Response(content=response.content, status_code=response.status_code, headers=response.headers)\n    return res\n\nif __name__==\"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8080)"}
{"type": "source_file", "path": "ToolServer/ToolServerManager/models.py", "content": "from beanie import Document\nfrom datetime import datetime\n\n\nclass ToolServerNode(Document):\n    \"\"\"\n    A class that represents a node in the database. \n    \"\"\"\n    id: str\n    short_id: str\n    status: str\n    health: str\n    last_req_time: datetime\n    ip: str\n    port: int\n\nclass NodeChecker(Document):\n    manager_id: str\n    interval: float\n    pid: int"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/envs/filesystem.py", "content": "import os\nimport fnmatch\nfrom typing import Any, Dict\nfrom collections import defaultdict\n\nfrom core.register import toolwrapper\nfrom core.base import BaseEnv\n\n@toolwrapper()\nclass FileSystemEnv(BaseEnv):\n    \"\"\"Provide a file system operation environment for Agent.\n    \"\"\"\n    def __init__(self, config: Dict[str, Any] = None):\n        super().__init__(config)\n        filesystem_config = self.config['filesystem']\n        \n        self.ignored_list = filesystem_config[\"ignored_list\"]\n        self.work_directory = filesystem_config[\"work_directory\"]\n        self.max_entry_nums_for_level = filesystem_config[\"max_entry_nums_for_level\"]\n        if not os.path.exists(self.work_directory):\n            os.mkdir(self.work_directory,mode=0o777)\n        \n    def _check_ignorement(self,path:str)->bool:\n        for pattern in self.ignored_list:\n            if fnmatch.fnmatch(path,pattern):\n                return True\n        return False\n    \n    def _is_path_within_workspace(self,path:str)->bool:\n        common_prefix = os.path.commonprefix([os.path.realpath(path),\n                                            os.path.realpath(self.work_directory)])\n        return common_prefix == os.path.realpath(self.work_directory)\n    \n    def _is_path_exist(self,path:str)->bool:\n        \"\"\"Check if the path exists in the workspace.\n        \n        :param string path: The path to be checked.\n        :return bool: `True` if the path exists, else `False`.\n        \"\"\"\n\n        full_path = os.path.join(self.work_directory, path)\n        if not self._is_path_within_workspace(full_path):\n            raise ValueError(f\"Path {path} is not within workspace.\")\n        return os.path.exists(full_path)\n\n    def print_filesys_struture(self,return_root=False)->str:\n        \"\"\"Return a tree-like structure for all files and folders in the workspace. Use this tool if you are not sure what files are in the workspace.\n\n        This function recursively walks through all the directories in the workspace\n        and return them in a tree-like structure, \n        displaying all the files under each directory.\n        \n        Example:\n        ```\n        - root/\n            - sub_directory1/\n                - file1.txt\n                - file2.txt\n            - sub_directory2/\n                - file3.txt\n        ```\n\n        :return string: The tree-like structure of the workspace.\n        \"\"\"\n        full_repr = ''\n        if return_root:\n            full_repr += f'Global Root Work Directory: {self.work_directory}\\n'\n\n        folder_counts =  defaultdict(lambda: 0)\n        for root, dirs, files in os.walk(self.work_directory):\n            if self._check_ignorement(root):\n                continue\n            level = root.replace(self.work_directory, '').count(os.sep)\n            indent = ' ' * 4 * (level)\n            \n            folder_counts[root] += 1\n            if folder_counts[root] > self.max_entry_nums_for_level:\n                full_repr += f'{indent}`wrapped`\\n'\n            \n            full_repr += f'{indent}- {os.path.basename(root)}/\\n'\n            \n            idx = 0\n            subindent = ' ' * 4 * (level + 1) + '- '\n            for f in files:\n                if self._check_ignorement(f):\n                    continue\n                \n                idx += 1\n                if idx > self.max_entry_nums_for_level:\n                    full_repr += f'{subindent}`wrapped`\\n'\n                    break\n                full_repr += f'{subindent}{f}\\n'\n\n\n        return full_repr\n    \n    def read_from_file(self,filepath:str,line_number:int = 1)->str:\n        \"\"\"Open and read the textual file content in the workspace, you will see the content of the target file.\n        Don't use this if the give `filepath` is writen or modified before, the content in `filepath` should be already returned.\n        \n        :param string filepath: The path to the file to be opened, always use relative path to the workspace root.\n        :param integer? line_number: The starting line number of the content to be opened. Defaults to 1.\n        :return string: The content of the file.\n        \"\"\"\n        if not filepath.startswith(self.work_directory):\n            filepath = filepath.strip('/')\n            full_path = os.path.join(self.work_directory, filepath)        \n        else:\n            full_path = filepath\n                \n        if self._check_ignorement(full_path) or not os.path.isfile(full_path):\n            raise FileNotFoundError(f\"File {filepath} not found in workspace.\")\n        if not self._is_path_within_workspace(full_path):\n            raise ValueError(f\"File {filepath} is not within workspace.\")\n        if not os.path.exists(full_path):\n            raise FileNotFoundError(f\"File {filepath} not found in workspace.\")\n\n        content = ''\n        with open(full_path, 'r') as f:\n            lines = f.readlines(int(1e5))\n            \n        read_count = 0\n        if not (abs(line_number) - 1 < len(lines)):\n            raise ValueError(f\"Line number {line_number} is out of range.\")\n        index = line_number if line_number >= 0 else len(lines) + line_number\n        if index == 0:\n            index = 1\n            \n        if line_number == 0:\n            indexed_lines = lines\n        elif line_number > 0:\n            indexed_lines = lines[line_number-1:]\n        else:\n            indexed_lines = lines[line_number:]\n            \n        for line in indexed_lines:\n            content += f'{index}'.rjust(5) + ': '\n            content += line\n            read_count += len(line)\n            index += 1\n        return content\n\n    def write_to_file(self, filepath:str,content:str,truncating:bool = False,line_number:int = None, overwrite:bool = False)->str:\n        \"\"\"Write or modify the textual file lines based on `content` provided. \n        Return updated content of the file after modification so no further need to call `read_from_file` for this file. Create file if not exists.\n        \n        Example:\n        ```\n        In[0]: write_to_file('test.txt', 'Hello World!\\\\nA new line!')\n        Out[0]: '1: Hello World!\\\\n2: A new line!'\n        In[1]: write_to_file('test.txt', 'Hello World 1!', 2)\n        Out[1]: '1: Hello World!\\\\n2: Hello World 1!\\\\n3: A new line!'\n        In[2]: write_to_file('test.txt', 'Hello World 2!', 2, overwrite=True)\n        Out[2]: '1: Hello World!\\\\n2: Hello World 2!\\\\n3: A new line!'\n        ```\n        \n        :param string filepath: The path to the file to be modified, always use relative path to the workspace root.\n        :param boolean? truncating: If `True`, the file will be truncated before writing, else will read current content before writing. Defaults to `False`.\n        :param integer? line_number: The start line to modified file. Defaults to `None`, which means insert the new content at the end of the file. So do not provide this if you want to append the new content to the file.\n        :param boolean? overwrite: If `True`, the new content will overwrite content started from `line_number` line. Defaults to `False`, which insert the new content at the `line_number` line.\n        :param string content: The new content to be replaced with the old content.\n        \"\"\"\n        if not filepath.startswith(self.work_directory):\n            filepath = filepath.strip('/')\n            full_path = os.path.join(self.work_directory, filepath)\n        else:\n            full_path = filepath\n        if not self._is_path_within_workspace(full_path) or  self._check_ignorement(full_path):\n            raise ValueError(f\"File {filepath} is not within workspace.\")\n        \n        if not os.path.exists(full_path):\n            if line_number is None or line_number==0 or line_number == 1:\n                os.makedirs(os.path.split(full_path)[0],exist_ok=True)\n                open(full_path, 'w+').close()\n            else:\n                raise FileNotFoundError(f\"File {filepath} not found in workspace.\")\n        elif not os.path.isfile(full_path):\n            raise ValueError(f\"File {filepath} is not a file.\")\n            \n        # protential overflow\n        if truncating:\n            lines = []\n        else:\n            with open(full_path, 'r') as f:\n                lines = f.readlines()\n        \n        \n        new_lines = content.splitlines(keepends=True)\n        if line_number is None:\n            lines.extend(new_lines)\n        else:\n            if line_number >= 1:\n                line_number -= 1\n            if overwrite:\n                lines[line_number: line_number+len(new_lines)] = new_lines\n            else:\n                lines[line_number: line_number] = new_lines \n\n        for idx, _ in enumerate(lines):\n            if not lines[idx].endswith('\\n'):\n                lines[idx] += '\\n'\n                \n        with open(full_path, 'w+') as f:\n            f.writelines(lines)\n            \n        return self.read_from_file(filepath)\n        \n\n"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/extensions/tools/calculator.py", "content": "import requests\nimport xmltodict\n\nfrom config import CONFIG\nfrom core.register import toolwrapper\n        \n\n# @toolwrapper()\ndef calculator(expression:str)->str:\n    \"\"\"It is a simple calculator, which can execute Python expressions: e.g., \"(123 + 234) / 23 * 1.5 - 8\".\n        \n    :param string expression: The python expression you requested.\n    :return string: The execution results of the expression.\n    \"\"\"\n    globals={}\n    locals={}\n    try:\n        # Wrap the code in an eval() call to return the result\n        wrapped_code = f\"__result__ = eval({repr(expression)}, globals(), locals())\"\n        exec(wrapped_code, globals, locals)\n        return locals.get('__result__', None)\n    except Exception as e:\n        try:\n        # If eval fails, attempt to exec the code without returning a result\n            exec(expression, globals, locals)\n            return \"Code executed successfully.\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n\n#wolfram_cfg = CONFIG['wolfram']  \n# @toolwrapper()\n# def query_wolfram(query:str) -> list[dict]:\n#     \"\"\"Query WolframAlpha using natural language and return parsed results.\n\n#     Query by access computation, math, curated knowledge & real-time data through Wolfram|Alpha and Wolfram Language. Note this tool is only used for high-level mathematically related queries, NOT the simple computations.\n\n#     :param string query: The query you requested.\n#     :return array[Object]: The results of the query.\n#     \"\"\"\n#     response = requests.get(wolfram_cfg['endpoint'], params={'appid': wolfram_cfg['appid'], \"input\": query})\n    \n#     json_data = xmltodict.parse(response.text)\n#     if 'pod' not in json_data[\"queryresult\"]:\n#         return \"WolframAlpha API cannot parse the input query.\"\n#     rets = json_data[\"queryresult\"]['pod']\n\n#     cleaned_rets = []\n#     blacklist = [\"@scanner\", \"@id\", \"@position\", \"@error\", \"@numsubpods\", \"@width\", \"@height\", \"@type\", \"@themes\",\n#                  \"@colorinvertable\", \"expressiontypes\"]\n\n#     def filter_dict(d, blacklist):\n#         if isinstance(d, dict):\n#             return {k: filter_dict(v, blacklist) for k, v in d.items() if k not in blacklist}\n#         elif isinstance(d, list):\n#             return [filter_dict(i, blacklist) for i in d]\n#         else:\n#             return d\n\n#     for ret in rets:\n#         ret = filter_dict(ret, blacklist=blacklist)\n#         # Do further cleaning to retain only the input and result pods\n#         if \"@title\" in ret:\n#             if ret[\"@title\"] == \"Input\" or ret[\"@title\"] == \"Result\":\n#                 cleaned_rets.append(ret)\n\n#     return cleaned_rets\n"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/extensions/envs/shell.py", "content": "import subprocess\nimport sys\nimport select\nimport os\nimport io\n\nfrom typing import Union,Dict,Any\nfrom core.base import BaseEnv\nfrom core.register import toolwrapper,get_func_name\nfrom core.exceptions import OutputNotReady\n\ndef read_pipe(pipe:Union[io.StringIO,io.BytesIO],text=True)->Union[str,bytes]:\n    \"\"\"Reading the `subprocess.PIPE` when readable.\n    If `text` is `True`, return str, else return bytes.\n    \"\"\"\n    output = '' if text else b''\n    while True:\n        ready_fds,_,_ = select.select( [pipe.fileno()],[],[],0.01)\n        if len(ready_fds) == 0:\n            break\n        output += os.read(ready_fds[0],16384).decode() if text else os.read(ready_fds[0],16384)\n\n    return output\n\n# @toolwrapper()\nclass ShellEnv(BaseEnv):\n    \"\"\"Provide and maintain an interactive shell environment.\n    \"\"\"\n    def __init__(self,\n                 config:Dict[str,Any]):\n        super().__init__(config)\n        \n        if sys.platform.startswith(\"linux\"):\n            self.shell_program = \"bash\"\n        elif sys.platform.startswith(\"darwin\"):\n            self.shell_program = \"zsh\"\n        else:\n            self.shell_program = \"powershell\"\n        self.work_directory = self.config['filesystem']['work_directory']\n        self._restart()\n\n    @property\n    def running(self)->bool:\n        \"\"\"`True` if shell is running, else `False`\n        \"\"\"\n        if hasattr(self,'running_proc') and isinstance(self.running_proc,subprocess.Popen):\n            if self.running_proc.poll() is None:\n                return True\n        return False\n    \n    def _restart(self,program:str=None,shell:bool=True):\n        f\"\"\"Restart the shell.\n        \n        :param string? program: The program to be executed in shell, the default is `{self.shell_program}`.\n        \"\"\"\n        self._kill()\n        if program is None:\n            program = self.shell_program\n        self.running_proc = subprocess.Popen(\n            program, # adding more shells support\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            cwd=self.work_directory,\n            shell=shell,\n            text=True\n        )\n        self.output_fileno = [self.running_proc.stdout.fileno(),self.running_proc.stderr.fileno()]\n    \n    def _terminate(self):\n        \"\"\"Terminate the shell.\n        \"\"\"\n        if self.running:\n            self.running_proc.terminate()\n\n    def _kill(self):\n        \"\"\"Kill the shell.\n        \"\"\"\n        if self.running:\n            self.running_proc.kill()\n\n    def read_stdout(self, probe: bool = False) -> str:\n        \"\"\"Read the stdout stream of the shell. If stderr is not empty, it will be returned instead.\n        \n        Empty string will be returned if both stdout and stderr are empty.\n        You can use this function to check if the shell has new content to be read for a running process takes a while.\n        \n        :param boolean? probe: If `True`, the function will return immediately if no output is ready, else it will raise `OutputNotReady` exception and request to call functions in `next_calling` to get result.\n        \"\"\"\n        if not self.running:\n            raise RuntimeError('Shell is not running!')\n        \n        ready_fds,_,_ = select.select(self.output_fileno,[],[],0.01)\n        if probe and len(ready_fds) == 0 :\n            raise OutputNotReady('Output is not ready!',next_calling=get_func_name(self.read_stdout,self),arguments={'probe':True})\n        \n        error = read_pipe(self.running_proc.stderr)\n        if error:\n            return error\n\n        return read_pipe(self.running_proc.stdout)\n    \n    \n    def write_stdin(self, content:str) -> str:\n        \"\"\"Write the stdin stream of the shell and get instant feedback from stderr or stdout.\n        \n        Example:\n        ```\n        write_stdin('echo \"hello world\"')\n        ```\n        This will execute the command `echo \"hello world\"` in shell and return the output `hello world`.\n        \n        :param string content: The content to be written.\n        \"\"\"\n\n        # removed temporarily, maybe put back later?\n        # You may need to call `read_stdout` to get further feedback for running process takes a while.\n        if not self.running:\n            raise RuntimeError('Shell is not running!')\n        if not content.endswith(\"\\n\"):\n            content += \"\\n\"\n        self.running_proc.stdin.write(content)\n        self.running_proc.stdin.flush()\n        \n        ready_fds,_,_ = select.select(self.output_fileno,[],[],0.01)\n        if len(ready_fds) == 0:\n            raise OutputNotReady('Output is not ready!',next_calling=get_func_name(self.read_stdout,self),arguments={'probe':True})\n        \n        return 'Instant shell output: ' + self.read_stdout()\n    \n"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/config.py", "content": "import os\nimport yaml\nimport logging\nfrom typing import Dict, Any, Union\n\nclass NodeConfig:\n    \"\"\"\n    A class used to load and manage the configurations defined in a specified configuration file and the environment variables.\n\n    Methods\n    -------\n    __getitem__(self, key):\n        Fetches a configuration value for a given key.\n    dict():\n        Returns the entire configuration dictionary.\n    update(new_config: Dict):\n        Updates the configuration dictionary with new configurations.\n    \"\"\"\n    def __init__(self,\n                 config_file_path=\"./assets/config/node.yml\",):\n        \"\"\"\n        The constructor for NodeConfig class that loads the configuration details.\n\n        Args:\n          config_file_path (str, optional): The path to the configuration file. Defaults to \"assets/config.yml\".\n\n        Raises:\n          FileNotFoundError: If specified configuration file path could not be located.\n          yaml.YAMLError: If there are syntax errors in the provided yaml configuration file.\n        \"\"\"\n        self.cfg:Dict = yaml.load(open(config_file_path, \"r\", encoding=\"utf-8\").read(), Loader=yaml.FullLoader)\n        \n        for k in os.environ.keys():\n            if k in self.cfg:\n                self.cfg[k] = os.environ[k] # overwrite the config with environment variables\n\n    def __getitem__(self, key):\n        \"\"\"\n        Fetches a configuration value for a given key.\n\n        Args:\n          key (str): The configuration key to fetch value for.\n        \n        Returns:\n          Any: The value of the requested configuration key.\n        \n        Raises:\n          KeyError: If the given key is not found in the configuration.\n        \"\"\"\n        return self.cfg[key]\n    \n    def dict(self)-> Dict[str, Any]:\n        \"\"\"\n        Returns the entire configuration dictionary.\n        \n        Returns:\n          Dict[str, Any]: The entire configuration dictionary.\n        \"\"\"\n        return self.cfg\n\n    def update(self, new_config: Dict)-> None:\n        \"\"\"\n        Updates the configuration dictionary with new configurations.\n\n        Args:\n          new_config (Dict): The new configurations dictionary to update the existing configurations.\n\n        Returns:\n          None\n        \"\"\"\n        self.cfg.update(new_config)\n        \nCONFIG = NodeConfig()\nlogger = logging.getLogger(CONFIG['logger'])\nlogger.setLevel(CONFIG['logger_level'])"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/extensions/envs/rapidapi.py", "content": "import os\nimport json\nimport httpx\n\nfrom typing import Type\nfrom copy import deepcopy\nfrom config import CONFIG\nfrom core.base import BaseEnv\nfrom core.register import toolwrapper\nfrom utils.retriever import standardizing\n\nAPI_INFOS = {}\n\ndef generate_arg_doc(arg_name,arg_type,arg_desc,arg_default=None,arg_optional=None):\n    match arg_type:\n        case 'NUMBER':\n            arg_type = 'integer'\n        case 'STRING':\n            arg_type = 'string'\n        case 'BOOLEAN':\n            arg_type = 'boolean'\n        case 'ARRAY':\n            arg_type = 'array'\n        case 'OBJECT':\n            arg_type = 'object'\n\n    if arg_optional:\n        arg_type += '?'\n    if arg_default:\n        return f':param {arg_type} {arg_name}: {arg_desc} defaults to {arg_default}'\n    else:\n        return f':param {arg_type} {arg_name}: {arg_desc}'\n\ndef convert_rapidapi_desc_to_code(rapidapi_desc:dict)->list[dict]:\n    tool_desc = {\n        'category':rapidapi_desc['category'],\n        'tool_name':standardizing(rapidapi_desc['tool_name']),\n    }\n    api_infos = {}\n    for api_desc in rapidapi_desc['api_list']:\n        api_name = standardizing(api_desc['name'])\n        if api_name in ['from','class','return','false','true','id','and']:\n            api_name = 'is_'+ api_name\n        api_info = {'api_name':api_name}\n        api_info.update(tool_desc)\n        \n        api_uri = '_'.join(['rapi',tool_desc['tool_name'],api_name])\n        \n        \n        args_doc = []\n        \n        for param in api_desc['required_parameters']:\n            args_doc.append(generate_arg_doc(\n                param['name'],\n                param['type'],\n                param['description'],\n                param['default'] if 'default' in param else None,\n                ))\n        \n        for param in api_desc['optional_parameters']:\n            args_doc.append(generate_arg_doc(\n                param['name'],\n                param['type'],\n                param['description'],\n                param['default'] if 'default' in param else None,\n                True))\n        \n        args_doc = '\\n    '.join(args_doc)\n        code = f\"\"\"async def {api_uri}(self,*args,**kwargs):\n    '''{rapidapi_desc['tool_description']}\n    {api_info['description'] if 'description' in api_info else ''}\n    \n\n    {args_doc}\n    '''\n    return await self._request_rapid_api('{api_uri}',kwargs)\n        \"\"\"\n        api_info['code'] = code\n        \n        api_infos[api_uri] = api_info\n    return api_infos\n\ndef rapid_api_mapper(cls:Type):\n    \"\"\"Dynamic adding api functions to RapidAPIENnv.\"\"\"\n    #reading api list\n    if not os.path.exists(CONFIG['rapidapi']['api_infos_json']):\n        try:\n            api_list = json.load(open(CONFIG['rapidapi']['api_raw_json']))\n        except:\n            raise FileNotFoundError(f'Both api_infos_json and api_raw_json are not found! Failed to setup RapidAPIEnv!')\n        \n        for rapidapi_desc in api_list:\n            API_INFOS.update(convert_rapidapi_desc_to_code(rapidapi_desc))\n        \n        json.dump(API_INFOS,open(CONFIG['rapidapi']['api_infos_json'],'w'),indent=4)\n    else:\n        API_INFOS.update(json.load(open(CONFIG['rapidapi']['api_infos_json'])))\n    \n    for api_uri,api_info in API_INFOS.items():\n        exec(api_info['code'])\n        setattr(cls,api_uri,eval(api_uri))\n    \n    return cls\n\n\n@toolwrapper(visible=False)\n@rapid_api_mapper\nclass RapidAPIEnv(BaseEnv):\n    \"\"\"RapidAPI Env delivers rapid api for tool server.\"\"\"\n    \n    def __init__(self,config:dict={}):\n        super().__init__(config=config)\n        \n        self.rapidapi_cfg = self.config['rapidapi']\n        self.api_key = self.rapidapi_cfg['api_key']\n        self.endpoint = self.rapidapi_cfg['endpoint']\n        \n        self.api_infos = deepcopy(API_INFOS)\n        \n    async def _request_rapid_api(self,api_uri:str,arguments:dict={}):\n        api_info = self.api_infos[api_uri]\n        payload = {\n            'category':api_info['category'],\n            'tool_name':api_info['tool_name'],\n            'api_name':api_info['api_name'],\n            'tool_input':arguments,\n            'strip':'truncate',\n            'toolbench_key':self.api_key\n        }\n        async with httpx.AsyncClient() as client:\n            response = await client.post(self.endpoint,json=payload,headers={'toolbench_key':self.api_key})\n        \n        response.raise_for_status()\n        \n        return response.json()\n    \n    "}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/labels.py", "content": "from typing import Optional,Callable,Any,Type,Union\nfrom config import CONFIG\n\n\nclass ToolLabels:\n    \"\"\"A class representing a tool.\n\n    When invoked, this object runs the associated method using parameters defined in the signature.\n\n    Attributes:\n        name (str): The name of the tool.\n        description (str): Description of the tool.\n        method (Callable): The function/method that the tool executes.\n        signature (dict): Argument keys and values needed by the method to execute.\n        required (list): List of required arguments for the method.\n        enabled (bool): Flag indicating whether the tool is enabled or not.\n        disabled_reason (str): Reason for disabling the tool, if applicable.\n        func_type (str): Type of function for the tool, defaults to 'function'.\n        visible (bool): Flag indicating whether the tool is visible or not.\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        description: str,\n        method: Callable[..., Any],\n        signature: dict = {},\n        required: list = [],\n        enabled: bool = True,\n        disabled_reason: Optional[str] = None,\n        func_type: str = 'function',\n        visible: bool = True,\n    ):\n        self.name = name\n        self.description = description\n        self.method = method\n        self.signature = signature\n        self.required = required\n        self.enabled = enabled\n        self.disabled_reason = disabled_reason\n        self.func_type = func_type\n        self.visible = visible\n\n    def dict(self, name_overwrite: str = '') -> dict:\n        \"\"\"Returns the tool information as a dictionary.\n\n        Args:\n            name_overwrite (str): Replacement string for tool name, defaults to empty string.\n\n        Returns:\n            dict: Dictionary of tool attributes.\n        \"\"\"\n        \n        return {\n            \"name\": self.name if name_overwrite == '' else name_overwrite,\n            \"description\": self.description[:1024],\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": self.signature,\n                \"required\": self.required\n            }\n        }\n\n    def __str__(self) -> str:\n        \"\"\"Returns the tool information in a formatted string.\n\n        Returns:\n            str: Formatted string containing tool attributes.\n        \"\"\"\n        return f\"{self.name}: {self.description}, args: {self.signature}\"\n\n\nclass EnvLabels:\n    \"\"\"A class representing an environment.\n\n    Each environment has a set of subtools associated with it. This object manages the collection of tools.\n\n    Attributes:\n        name (str): Name of the environment.\n        description (str): Description of the environment.\n        subtools_labels (dict): Collection of tools associated to the environment.\n        defined_tools (list): List of tool names defined in the environment.\n        cls (Type): Class that the environment pertains to.\n        enabled (bool): Flag indicating whether the environment is enabled or not.\n        disabled_reason (str): Reason for disabling the environment, if applicable.\n        visible (bool): Flag indicating whether the environment is visible or not.\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        description: str,\n        subtools_labels: dict[ToolLabels] = {},\n        defined_tools:list[str] = [],\n        cls: Type = None,\n        enabled: bool = True,\n        disabled_reason: Optional[str] = None,\n        visible: bool = True,\n    ):\n        self.name = name\n        self.description = description\n        self.subtools_labels = subtools_labels\n        self.defined_tools = defined_tools\n        self.cls = cls\n        self.enabled = enabled\n        self.disabled_reason = disabled_reason\n        self.visible = visible\n\n    def dict(self,\n             include_invisible=False,\n             max_show_tools: int = CONFIG['toolregister']['env_max_tools_display']) -> dict:\n        \"\"\"\n        Returns the environment's tools as a dictionary.\n\n        Args:\n            include_invisible (bool): If true, includes tools even if they're set as invisible.\n            max_show_tools (int): Maximum number of tools to display in the output.\n\n        Returns:\n            dict: Dictionary of environment attributes and associated tools.\n        \"\"\"\n        \n        if include_invisible:\n            tools_name = list(self.subtools_labels.keys())\n        else:\n            if CONFIG['toolregister']['parent_tools_visible']:\n                tools_name = [tool_name for tool_name in self.subtools_labels.keys() if self.subtools_labels[tool_name].visible]\n            else:\n                tools_name = self.defined_tools\n\n        if max_show_tools != -1 and len(tools_name) > max_show_tools:\n            # only show first max_show_tools tools\n            tools_name = tools_name[:max_show_tools]\n            tools_name.append('...')\n\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"total_tools\": len(self.subtools_labels),\n            \"tools\": tools_name,\n        }\n\n    def __str__(self) -> str:\n        \"\"\"Returns the environment information as a formatted string.\n\n        Returns:\n            str: Formatted string containing environment attributes.\n        \"\"\"\n        return f\"{self.name}: {self.description}\""}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/register/__init__.py", "content": "from .register import ToolRegister,get_func_name\nfrom .wrapper import toolwrapper"}
{"type": "source_file", "path": "ToolServer/ToolServerManager/config.py", "content": "import os\nimport shutil\nimport yaml\nimport logging\nfrom typing import Dict, Any, Union\nimport uuid\n\nclass ManagerConfig:\n    \"\"\"\n    This class manages configuration settings for the application.\n    Configuration settings are initially loaded from a yaml file. \n    However, if an environment variable exists with the same name as a configuration setting, \n    the value from the environment variable will be used instead.\n\n    Attributes:\n        cfg: A dictionary containing all configuration settings.\n    \"\"\"\n\n    def __init__(self, config_file_path=\"./assets/config/manager.yml\"):\n        \"\"\"\n        Initializes a new instance of the ManagerConfig class.\n\n        Args:\n            config_file_path (str, optional): The path to a yaml file containing configuration settings. \n            Defaults to \"./assets/config.yml\".\n        \"\"\"\n        self.cfg:Dict = yaml.load(open(config_file_path,\"r\",encoding=\"utf-8\").read(), Loader=yaml.FullLoader)\n        for k in os.environ.keys():\n            if k in self.cfg:\n                self.cfg[k] = os.environ[k]  # overwrite the config with environment variables\n\n    def __getitem__(self, key):\n        \"\"\"\n        Returns the value of a configuration setting.\n\n        Args:\n            key (str): The name of the configuration setting.\n\n        Returns:\n            The value of the configuration setting. \n        \"\"\"\n        return self.cfg[key]\n\n    def dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Returns all configuration settings.\n\n        Returns:\n            A dictionary containing all configuration settings.\n        \"\"\"\n        return self.cfg\n\n    def update(self, new_config: Dict) -> None:\n        \"\"\"\n        Updates configuration settings with the values from another dictionary.\n\n        Args:\n            new_config (Dict): A dictionary containing the configuration settings to be updated.\n\n        Returns:\n            None\n        \"\"\"\n        self.cfg.update(new_config)\n\nCONFIG = ManagerConfig()\nlogger = logging.getLogger(CONFIG['logger'])\nlogger.setLevel(CONFIG['logger_level'])\nMANAGER_ID = uuid.uuid4().hex"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/extensions/tools/code_interpreter.py", "content": "import asyncio\n\nfrom config import CONFIG\n\nfrom core.register import toolwrapper\nfrom core.envs.filesystem import FileSystemEnv\n\nCODE_FS = FileSystemEnv()\n\n@toolwrapper()\nasync def run_interpreter(code:str=None,command:str=None,filename:str='code.py'):\n    \"\"\"The code interpreter tool that runs code and return the output.\n\n    The `code` will be written to file `filename` and the `command` will be executed in a shell.\n    Example:\n    ```\n    run_interpreter(code='print(\"hello world\")',command='python code.py')\n    ```\n\n    :param string? code: The code to be written, default to `None`, which means no code will be written to file.\n    :param string? command: The shell command to be executed should avoid requiring additional user input, default to `python {filename}`.\n    :param string? filename: The filename to be written in mode `w`, default to `code.py`.\n\n    \"\"\"\n    if code is not None and code != \"\" and filename != \"\":\n        CODE_FS.write_to_file(filename,code)\n\n    if command is None:\n        command = f'python {filename}'\n    exec_proc = await asyncio.create_subprocess_shell(\n        'bash',\n        stderr=asyncio.subprocess.PIPE,\n        stdout=asyncio.subprocess.PIPE,\n        stdin=asyncio.subprocess.PIPE,\n        cwd=CODE_FS.work_directory)\n    \n    ret = await asyncio.wait_for(exec_proc.communicate(command.encode()),timeout=CONFIG['shell']['timeout'])\n    \n    result = {\n        'ReturnCode':exec_proc.returncode,\n    }\n    if ret[1]!=b'':\n        result['Error'] = ret[1].decode()\n    if ret[0]!=b'':\n        result['Output'] = ret[0].decode()\n\n    return result\n"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/envs/web.py", "content": "import httpx\n\nfrom typing import Callable,Any,Coroutine,List\nfrom bs4 import BeautifulSoup\nfrom duckduckgo_search import DDGS\n\nfrom config import logger\nfrom core.base import BaseEnv\nfrom core.register import toolwrapper\n\n@toolwrapper()\nclass WebEnv(BaseEnv):\n    \"\"\"Web Environment providing web interface and browsering.\n    \"\"\"\n    def __init__(self,config:dict = {}):\n        super().__init__(config=config)\n        self.bing_cfg = self.config['bing']\n        if self.bing_cfg['api_key'] is None:\n            logger.warning(\"Bing API key is not provided, rollback to duckduckgo.\")\n        \n        self.web_cfg = self.config['web']\n        self.headers = {\n            \"User-Agent\":self.web_cfg['user_agent']\n        }\n        self.client = httpx.AsyncClient(headers=self.headers,verify=False,timeout=30.0,http2=True)\n\n    def _check_url_valid(self,url:str):\n        local_prefixes = [\n            \"file:///\",\n            \"file://127.0.0.1\",\n            \"file://localhost\",\n            \"http://localhost\",\n            \"https://localhost\",\n            \"http://2130706433\",\n            \"https://2130706433\",\n            \"http://127.0.0.1\",\n            \"https://127.0.0.1\",\n            \"https://0.0.0.0\",\n            \"http://0.0.0.0\",\n            \"http://0000\",\n            \"https://0000\",\n        ]\n        if any(url.startswith(prefix) for prefix in local_prefixes):\n            raise ValueError(f\"URL {url} is a local url, blocked!\")\n        if not (url.startswith(\"http\") or url.startswith(\"file\")):\n            raise ValueError(f\"URL {url} is not a http or https url, please give a valid url!\")\n        \n    async def search_and_browse(self, search_query:str,goals_to_browse:str,region:str=None,num_results = 3) -> List[str]:\n        \"\"\"Search with search tools and browse the website returned by search. Note some websites may not be accessable due to network error.\n    \n        :param string search_query: The search query.\n        :param string goals_to_browse: What's you want to find on the website returned by search. If you need more details, request it in here. Examples: 'What is latest news about deepmind?', 'What is the main idea of this article?'\n        :param string? region: The region code of the search, default to `en-US`. Available regions: `en-US`, `zh-CN`, `ja-JP`, `de-DE`, `fr-FR`, `en-GB`.\n        :return string: The results of the search.\n        \"\"\"\n        \n        api_key = self.bing_cfg[\"api_key\"]\n        endpoint = self.bing_cfg[\"endpoint\"]\n        if region is None:\n            region = 'en-US'\n        if api_key is None:\n            pages = [{\n                'name':ret['title'],\n                'snippet':ret['body'],\n                'url':ret['href']\n            } for ret in DDGS().text(search_query, region='wt-wt')]\n            \n        else:\n            result = await self.client.get(endpoint,\n                        headers={'Ocp-Apim-Subscription-Key': api_key},\n                        params={'q': search_query, 'mkt': region },\n                        timeout=10)\n            result.raise_for_status()\n            result = result.json()\n            pages = result[\"webPages\"][\"value\"]\n            \n        search_results = []\n\n        for idx in range(min(len(pages),num_results)):\n            try:\n                page = await self.browse_website(pages[idx]['url'],goals_to_browse)\n            except httpx.HTTPStatusError as e:\n                page = e.response.text\n            except Exception as e:\n                page = str(e)\n                \n            message = {\n                'name':pages[idx]['name'],\n                'snippet':pages[idx]['snippet'],\n                'page':page\n            }\n            search_results.append(message)\n\n        return search_results\n    \n    async def browse_website(self,url:str,goals_to_browse:str)->str:\n        \"\"\"Give a http or https url to browse a website and return the summarize text. Note some websites may not be accessable due to network error. This tool only return the content of give url and cannot provide any information need interaction with the website.\n        \n        :param string url: The realworld Uniform Resource Locator (web address) to scrape text from. Never provide something like \"<URL of the second news article>\", give real url!!! Example: 'https://www.deepmind.com/'\n        :param string goals_to_browse: The goals for browse the given `url` (e.g. what you want to find on webpage.). If you need more details, request it in here.\n        :return string: The content of the website, with formatted text.\n        \"\"\"\n        # self._check_url_valid(url)\n        res = await self.client.get(url)\n        if res.status_code in [301,302,307,308]:\n            res = await self.client.get(res.headers['location'])\n        else:\n            res.raise_for_status()\n        \n        soup = BeautifulSoup(res.text,\"html.parser\")\n        text = soup.get_text()\n        lines = (line.strip() for line in text.splitlines())\n        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n        text = \"\\n\".join(chunk for chunk in chunks if chunk)\n        \n        links = soup.find_all('a')\n        if len(links) > 0:\n            text += '\\n\\nLinks:\\n'\n            for link in links:\n                if link.string != None and link.get('href')!= None:\n                    # print(''.join(link.string.split()),link.get('href'))\n                    striped_link_string = link.string.strip()\n                    if striped_link_string != '' and  link.get('href').startswith('http'):\n                        text += f\"{striped_link_string} ({link.get('href')})\\n\"\n        \n        return text"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/extensions/envs/__init__.py", "content": ""}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/tools/__init__.py", "content": "\"\"\"\nThis module provides a utility function to import all modules \nin a specified folder.\n\nThe \"__all__\" variable is a list that defines the public interface of a module.\nHere it is utilized to dynamically import all modules in the current directory.\n\"\"\"\n\nfrom utils import import_all_modules_in_folder\n\n# dynamically import all modules in the current directory \n__all__ = import_all_modules_in_folder(__file__,__name__)"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/envs/__init__.py", "content": "from utils import import_all_modules_in_folder\n\n__all__ = import_all_modules_in_folder(__file__,__name__)\n\n\"\"\"\nThis script is for importing all the modules in a specified folder. The '__all__' variable is a list of public \nobjects of that module, as interpreted by 'import *'. The import statement uses the following convention: if a \npackage's __init__.py code defines a list named '__all__', it is taken to be the list of module names that \nshould be imported when 'from package import *' is encountered. It imports everything until it encounters an \nimport error.\n\nThe import_all_modules_in_folder function takes the current filename and module name as arguments and returns \na list of all module names under the current folder.\n\"\"\""}
{"type": "source_file", "path": "ToolServer/ToolServerNode/extensions/tools/search.py", "content": "import requests\n\nfrom config import CONFIG\nfrom core.register import toolwrapper\n\n\nbing_cfg = CONFIG['bing']\n\n@toolwrapper()\ndef bing_search(query:str,region:str = None)->str|list[str]:\n    \"\"\"Return 3 most relevant results of a Bing search using the official Bing API. This tool does not provide website details, use other tools to browse website if you need.\n    \n    :param string query: The search query.\n    :param string? region: The region code of the search, default to `en-US`. Available regions: `en-US`, `zh-CN`, `ja-JP`, `en-AU`, `en-CA`, `en-GB`, `de-DE`, `en-IN`, `en-ID`, `es-ES`, `fr-FR`, `it-IT`, `en-MY`, `nl-NL`, `en-NZ`, `en-PH`, `en-SG`, `en-ZA`, `sv-SE`, `tr-TR`.\n    :return string: The results of the search.\n    \"\"\"\n    #     :param int num_results: The number of results to return.\n    \n    num_results = 3\n    endpoint = bing_cfg[\"endpoint\"]\n    api_key = bing_cfg[\"api_key\"]\n    if region is None:\n        region = 'en-US'\n    result = requests.get(endpoint, headers={'Ocp-Apim-Subscription-Key': api_key}, params={'q': query, 'mkt': region }, timeout=10)\n    result.raise_for_status()\n    result = result.json()\n\n    pages = result[\"webPages\"][\"value\"]\n    search_results = []\n\n    for idx in range(min(len(pages),num_results)):\n        message = {\n            'url':pages[idx]['url'],\n            'name':pages[idx]['name'],\n            'snippet':pages[idx]['snippet']\n        }\n        search_results.append(message)\n\n    # Return the list of search result\n    return search_results"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/__init__.py", "content": ""}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/register/wrapper.py", "content": "import logging\nimport inspect\nimport docstring_parser\n\nfrom typing import Optional,Callable,Any,Type,Union\n\nfrom core.base import BaseEnv\nfrom core.labels import ToolLabels,EnvLabels\n\nfrom config import CONFIG\n\nlogger = logging.getLogger(CONFIG['logger'])\n\ndef generate_tool_labels(\n    name: str = None,\n    enabled: bool = True,\n    disabled_reason: Optional[str] = None,\n    func: Callable[..., Any] = None,\n    visible:bool = True,\n)->Union[ToolLabels,None]:\n    \"\"\"\n    Generate and return tool labels for the provided function. If the tool is not enabled,\n    then a debug log message is printed and None is returned.\n\n    Args:\n        name (str, optional): The name of the tool. If it's not specified, the function's name is used.\n        enabled (bool, optional): Determines if the tool is enabled or not. Defaults to True.\n        disabled_reason (Optional[str], optional): The reason why the tool is disabled. Defaults to None.\n        func (Callable[..., Any], optional): The function for which the tool labels are generated. Defaults to None.\n        visible(bool, optional): The visibility status of the tool. Defaults to True.\n\n    Returns:\n        Union[ToolLabels,None]: A ToolLabels object containing tool information or None if tool is not enabled. \n    \"\"\"\n\n    if not enabled:\n        if disabled_reason is not None:\n            logger.debug(f\"tool '{func.__name__}' is disabled: {disabled_reason}\")\n        return None\n\n    # check if the method have full annotations\n    auto_signature = {}\n    func_desc =  docstring_parser.parse(func.__doc__)\n    required = []\n    for arg in func_desc.params:\n        auto_signature[arg.arg_name] = {\n            'type':arg.type_name,           # TODO support self defined type\n            'description':arg.description,\n        }\n        if arg.default is not None:\n            auto_signature[arg.arg_name]['default'] = arg.default\n        if not arg.is_optional:\n            required.append(arg.arg_name)\n\n    # for arg in inspect.getargs(func.__code__).args:\n    #     if arg in auto_signature:\n    #         continue\n    #     if arg in ['self','cls','config','return']:\n    #         continue\n    #     # if arg not in func.__annotations__:\n    #     #     raise SyntaxError(f'Signature is None and the annotation of varable {arg} in func {func.__name__} is not found!')\n    #     auto_signature[arg] = {\n    #         'type':'string',\n    #         'description':''                # TODO try to generate description\n    #     }\n\n    tool_name = func.__name__ if name is None else name\n    description = ''\n    if func_desc.short_description is not None:\n        description = func_desc.short_description\n    if func_desc.long_description is not None:\n        description += '\\n' + func_desc.long_description\n\n    return ToolLabels(\n        name=tool_name,\n        description=description,\n        method=func,\n        signature=auto_signature,\n        required=required,\n        enabled=enabled,\n        disabled_reason=disabled_reason,\n        visible=visible,\n    )\n\ndef toolwrapper(\n    name: str = None,\n    enabled: bool = True,\n    disabled_reason: Optional[str] = None,\n    parent_tools_visible: bool = CONFIG['toolregister']['parent_tools_visible'],\n    visible:bool = True,\n)->Union[Type,Callable[..., Any]]:\n    \"\"\"The tool decorator for class, used to create tool objects from ordinary class.\"\"\"\n\n    def decorator(obj:object)->Union[Type,Callable[..., Any]]:\n        if inspect.isclass(obj):\n            cls = obj\n            cls_name = name if name is not None else cls.__name__\n            if not issubclass(cls,BaseEnv):\n                raise Exception(f'The class {cls} is not a subclass of BaseEnv!')\n            \n            description = cls.__doc__ if cls.__doc__ is not None else ''\n            if not visible:\n                description = 'Note: All tools of this env are invisible during all tools display, please check this env\\'s defination to show all tools.\\n' + description\n            \n            \n            subtools_labels = {}\n            if BaseEnv not in cls.__bases__:\n                direct_parents = [parent.__name__ for parent in cls.__bases__]\n                if not parent_tools_visible:\n                    description = f'Note: This env is subclass of {direct_parents}, and all tools of parent envs are inherited and not visible. You can try call parent tools or check this env\\'s defination to show them.\\n' + description\n                else:\n                    description = f'Note: This env is subclass of {direct_parents}, and all tools of parent envs are inherited.\\n' + description\n                for parent in cls.__bases__:\n                    if hasattr(parent,'env_labels') and isinstance(parent.env_labels,EnvLabels):\n                        subtools_labels.update(parent.env_labels.subtools_labels)\n            \n            cls_func_names = cls.__get_defined_func_name__()            \n            for func_name in cls_func_names:\n                origin_func = getattr(cls,func_name)\n                tool_labels = generate_tool_labels(\n                    name=func_name,\n                    enabled=enabled,\n                    disabled_reason=disabled_reason,\n                    func=origin_func,\n                    visible=visible)\n                if tool_labels is None:\n                    continue\n                \n                # label classmethod, staticmethod and instance method\n                #check if the function is a classmethod\n                if inspect.ismethod(origin_func) and not inspect.isfunction(origin_func):\n                    tool_labels.func_type = 'classmethod'\n                # check if the function is a staticmethod\n                if 'self' in inspect.getargs(origin_func.__code__).args:\n                    tool_labels.func_type = 'instancemethod'\n                else:   \n                    tool_labels.func_type = 'staticmethod'\n                \n                # tool_labels.dependent_cls = cls\n                origin_func.tool_labels = tool_labels\n                subtools_labels[tool_labels.name] = tool_labels\n            \n\n            cls.env_labels = EnvLabels(\n                name=cls_name,\n                description=description,\n                subtools_labels=subtools_labels,\n                defined_tools=cls_func_names,\n                cls=cls,\n                enabled=enabled,\n                disabled_reason=disabled_reason,\n                visible=visible\n            )\n            return cls\n        elif inspect.isfunction(obj):\n            func = obj\n            tool_labels = generate_tool_labels(\n                name=name,\n                enabled=enabled, \n                disabled_reason=disabled_reason,\n                func=func,\n                visible=visible)\n            func.tool_labels = tool_labels\n            return func\n        else:\n            raise NotImplementedError(f'Object with type {type(obj)} not recognized!')\n    return decorator\n"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/exceptions.py", "content": "import re\nfrom fastapi import HTTPException\n\nclass OutputNotReady(Exception):\n    \"\"\"The output is not ready.\n        \"\"\"\n    def __init__(self, *args: object,type:str='retry',next_calling:str=None,arguments:dict={}) -> None:\n        super().__init__(*args)\n        self.type = type\n        self.next_calling = next_calling\n        self.arguments = arguments\n        \n    def next_try(self):\n        \"\"\"Prepare the next try by returning a dictionary\n           containing type, next calling event and arguments.\"\"\"\n        return {\n            \"type\":self.type,\n            \"next_calling\":self.next_calling,\n            \"arguments\":self.arguments\n        }\n    \nclass ToolNotFound(Exception):\n    \"\"\"Custom exception class that is raised when the tool is not found.\n    \n    Args:\n        *args (object): Variable length argument list.\n        tool_name (str): The name of the tool.\n\n    Attributes:\n        tool_name (str): The name of the tool.\n    \"\"\"\n    def __init__(self, *args: object,tool_name:str=None) -> None:\n        super().__init__(*args)\n        self.tool_name = tool_name\n        \n    def __str__(self) -> str:\n        \"\"\"Returns the formatted exception error message with the name of the tool\"\"\"\n        s = super().__str__()\n        if s != '':\n            s += f'\\nThe tool {self.tool_name} is not found!'\n        else:\n            s = f'The tool {self.tool_name} is not found!'\n        return s \n\n    \nclass EnvNotFound(Exception):\n    \"\"\"Custom exception class that is raised when the environment variable is not found.\n    \n    Args:\n        *args (object): Variable length argument list.\n        env_name (str): The name of the environment variable.\n\n    Attributes:\n        addition_info (tuple): Additional information.\n        env_name (str): The name of the environment variable.\n    \"\"\"\n    def __init__(self, *args: object,env_name:str=None) -> None:\n        super().__init__(*args)\n        self.addition_info = args\n        self.env_name =  env_name\n        \n    def __str__(self)->str:\n        \"\"\"Returns the formatted exception error message with the name of the environment variable\"\"\"\n        s = super().__str__()\n        if s != '':\n            s += f'\\nThe env {self.env_name} is not found!'\n        else:\n            s = f'The tool {self.env_name} is not found!'\n        return s \n    \nclass ToolRegisterError(Exception):\n    \"\"\"Custom exception class that is raised when registering a tool encounters an error.\n    \n    Args:\n        *args (object): Variable length argument list.\n        tool_name (str): The name of the tool.\n\n    Attributes:\n        addition_info (tuple): Additional information.\n        tool_name (str): The name of the tool.\n    \"\"\"\n    def __init__(self, *args: object,tool_name:str=None) -> None:\n        super().__init__(*args)\n        self.addition_info = args\n        self.tool_name = tool_name\n        \n    def __str__(self)->str:\n        \"\"\"Returns the formatted exception error message with the name of the tool\"\"\"\n        s = super().__str__()\n        if s != '':\n            s += f'\\nError happens when registering tool {self.tool_name}!'\n        else:\n            s = f'Error happens when registering tool {self.tool_name}!'\n        return s \n\nansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\ndef remove_color(text):\n    \"\"\"Removes ANSI escape sequences i.e. colors, from the text.\n\n    Args:\n        text (str): The text from which color needs to be removed.\n\n    Returns:\n        str: The filtered text with no color.\n    \"\"\"\n\n    return ansi_escape.sub('', text)\n\nclass ToolExecutionError(HTTPException):\n    \"\"\"Custom exception class that is raised when the tool execution encounters an error.\n\n    Args:\n        error_msg (str): The error message during tool execution.\n    \"\"\"\n    def __init__(self,error_msg:str):\n        if isinstance(error_msg,str):\n            error_msg = remove_color(error_msg)\n        super().__init__(500,error_msg)"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/register/register.py", "content": "import logging\nimport importlib\nimport traceback\n\nfrom copy import deepcopy\nfrom typing import Optional,Callable,Any,Type,Union\n\nfrom core.base import BaseEnv\nfrom core.labels import ToolLabels,EnvLabels\nfrom core.exceptions import ToolNotFound,EnvNotFound,ToolRegisterError\n\nfrom config import CONFIG\n\nlogger = logging.getLogger(CONFIG['logger'])\n\ndef get_func_name(func:Callable,env:BaseEnv=None)->str:\n    if env is None or not hasattr(env,'env_labels'):\n        if hasattr(func,'tool_labels'):\n            return func.tool_labels.name\n        else:\n            return func.__name__\n    else:\n        if hasattr(func,'tool_labels'):\n            return env.env_labels.name + '_' + func.tool_labels.name\n        else:\n            return env.env_labels.name + '_' + func.__name__\n\n\nclass ToolRegister:\n    def __init__(self,\n                 config:dict = {},\n                 ):\n        self.config = deepcopy(CONFIG)\n        for k in config:\n            self.config[k] = config[k]\n        self.toolregister_cfg = self.config['toolregister']\n        self.tool_creation_doc = open(self.toolregister_cfg['tool_creation_doc']).read()\n        self.tool_creation_context = {}\n        self.tool_creation_context_load_code = []\n        for k in self.toolregister_cfg['tool_creation_context']:\n            # load\n            load_code = f\"from {self.toolregister_cfg['tool_creation_context'][k]} import {k}\"\n            exec(load_code)\n            self.tool_creation_context[k] = eval(k)\n            self.tool_creation_context_load_code.append(load_code)\n        # load modules\n        self.tools = {}\n        self.envs = {}\n        for module_name in ['core.envs','core.tools']:            \n            sub_modules = importlib.import_module(module_name).__all__\n            for module in sub_modules:\n                for attr_name in dir(module):\n                    attr = getattr(module,attr_name)\n                    self.check_and_register(attr)\n            \n        # load extensions\n        if 'enabled_extensions' in self.config.cfg and isinstance(self.config['enabled_extensions'],list):\n            for extension in self.config['enabled_extensions']:\n                self.dynamic_extension_load(extension)\n        \n        logger.info(f'Loaded {len(self.tools)} tools and {len(self.envs)} envs!')\n        # print(self.tools)\n    def check_and_register(self,attr:Any):\n        if hasattr(attr,'tool_labels') and isinstance(attr.tool_labels,ToolLabels):\n            tool_name = get_func_name(attr)\n            if tool_name in self.tools:\n                logger.warning(f'Tool {tool_name} is replicated! The new one will be replaced!')\n                return None\n            \n            self.tools[tool_name] = attr\n            logger.info(f'Register tool {tool_name}!')\n            return attr\n            \n        if hasattr(attr,'env_labels') and isinstance(attr.env_labels,EnvLabels):\n            # attr is a cls, need get instance\n            if attr.env_labels.name in self.envs:\n                return\n            if not issubclass(attr,BaseEnv):\n                raise Exception(f'The env {attr.env_labels.name} is not a subclass of BaseEnv!')\n            env = attr(config=self.config.dict())\n            env_tools = {}\n            \n            if self.toolregister_cfg['parent_tools_visible']:\n                func_names = env.__get_all_func_name__()\n            else:\n                func_names = env.__get_defined_func_name__()\n            \n            for func_name in func_names:\n                func = getattr(env,func_name)\n                if hasattr(func,'tool_labels'):\n                    env_tools[get_func_name(func,env)] = func\n            \n            env_keys = set(env_tools.keys())\n            tools_keys = set(self.tools.keys())\n            if env_keys & tools_keys:\n                logger.warning(f'Env {env.env_labels.name} has tools with same name as other tools! The new one will be ignored!')\n                for tool_name in env_keys & tools_keys:\n                    env_tools.pop(tool_name)\n\n            self.tools.update(env_tools)\n            \n            self.envs[attr.env_labels.name] = env\n            logger.info(f'Register env {env.env_labels.name} with {len(env_tools)} tools!')\n            \n            return env\n            \n        return None\n\n    def register_tool(self,tool_name:str,code:str)->str:\n        try:\n            exec(code,self.tool_creation_context)\n        except Exception as e:\n            error_report =  traceback.format_exc()\n            logger.error(error_report)\n            raise ToolRegisterError(f'Failed to execute new tool code: {e}\\n\\n' + error_report,tool_name=tool_name)\n        \n        try:\n            tool_func = eval(tool_name,self.tool_creation_context)\n        except:\n            raise ToolRegisterError(f'Failed to find tool, please verify the tool_name!',tool_name=tool_name)\n        \n        tool_func = self.check_and_register(tool_func)\n        if tool_func is None:\n            raise ToolRegisterError(f'Tool: {tool_name} has no labels or replicated! Ensuring wrap the tool with `@toolwrapper()`.',tool_name=tool_name)\n        \n        # write the tool into file under extensions/tools\n        code = '\\n'.join(self.tool_creation_context_load_code) +'\\n# Tool Creation Context Load Ended.\\n'+ code\n        tool_file = f'extensions/tools/{tool_name}.py'\n        with open(tool_file,'w') as f:\n            f.write(code)\n        \n        return self.get_tool_dict(tool_name)\n    \n    def dynamic_extension_load(self,extension:str)->bool:\n        '''Load extension dynamically.\n        \n        :param string extension: The load path of the extension.\n        :return boolean: True if success, False if failed.\n        '''\n        try:\n            module = importlib.import_module(extension)\n            for attr_name in dir(module):\n                attr = getattr(module,attr_name)\n                self.check_and_register(attr)\n        except Exception as e:\n            logger.error(f'Failed to load extension {extension}! Exception: {e}')\n            # logger.error(traceback.format_exc())\n            return False\n        \n        return True\n        \n    def get_tool_dict(self,tool_name:str)->dict:\n        return self[tool_name].tool_labels.dict(name_overwrite=tool_name)\n    \n    def get_env_dict(self,env_name:str)->dict:\n        if env_name not in self.envs:\n            raise EnvNotFound(env_name=env_name)\n        return self.envs[env_name].env_labels.dict(include_invisible=True,max_show_tools = -1)\n    \n    def get_all_envs(self)->list[dict]:\n        return [self.envs[env_name].env_labels.dict()  for env_name in self.envs]\n    \n    def get_all_tools(self,include_invisible=False)->list[str]:\n        if include_invisible:\n            return [tool_name  for tool_name in self.tools]\n        else:\n            return [tool_name  for tool_name in self.tools if self.tools[tool_name].tool_labels.visible]\n    \n    def get_all_tools_dict(self,include_invisible=False)->list[dict]:\n        return [self.tools[tool_name].tool_labels.dict(name_overwrite=tool_name)  for tool_name in self.get_all_tools(include_invisible)]\n    \n    def __getitem__(self, key)->Callable[..., Any]:\n        # two stage index, first find env, then find tool\n        if isinstance(key,str):\n            if key not in self.tools:\n                # check if the tool is a env subtool which not visible\n                try:\n                    tool_name = key.split('_')\n                    env_name = tool_name[0]\n                    tool_name = '_'.join(tool_name[1:])\n                    return self[env_name,tool_name]\n                except:\n                    if self.dynamic_extension_load(f'extensions.tools.{key}') and key in self.tools:\n                        # try to find tool in unloaded extensions\n                        return self.tools[key]\n                    else:\n                        raise ToolNotFound(tool_name=key)\n            return self.tools[key]\n        elif isinstance(key,tuple):\n            if len(key) != 2:\n                raise NotImplementedError(f'Key {key} is not valid!')\n            env_name,tool_name = key\n            if env_name not in self.envs:\n                # try to find env in unloaded extensions\n                if self.dynamic_extension_load(f'extensions.envs.{env_name}') and env_name in self.envs:\n                    env = self.envs[env_name]\n                raise EnvNotFound(env_name=env_name)\n            env = self.envs[env_name]\n            if tool_name not in env.env_labels.subtools_labels:\n                raise ToolNotFound(tool_name=env_name+'_'+tool_name)\n            else:\n                func = getattr(env,env.env_labels.subtools_labels[tool_name].method.__name__)\n                return func\n        raise NotImplementedError(f'Key {key} is not valid!')"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/base.py", "content": "from typing import Callable, Dict, Any\nfrom copy import deepcopy\nfrom config import CONFIG\n\nclass BaseEnv:\n    \"\"\"\n    BaseEnv class. It helps to handle functions and function names of the classes and subclasses.\n    This class provides methods to get all functions, defined functions and their names.\n    It also ensures the configuration updates if necessary.\n\n    Attributes:\n        config(Dict[str, Any], optional): A dictionary containing the configuration. Defaults to an empty dictionary.\n    \"\"\"\n    def __init__(self, config: Dict[str, Any] = {}):\n        \"\"\"Initialize BaseEnv class with specified or default configuration.\n\n        Args:\n            config (Dict[str, Any], optional): A dictionary containing the configuration. Defaults to an empty dictionary.\n\n        Notes:\n            The configuration is deep copied to avoid modifications to the original object.\n        \"\"\"\n        self.config = deepcopy(CONFIG)\n        if isinstance(config, dict):\n            self.config.update(config)\n        \n    @classmethod\n    def __get_all_func_name__(cls) -> list[str]:\n        \"\"\"Get all the function names of the class, excluding methods starting with '_' character.\n\n        Returns:\n            list[str]: A list that contains function names.\n        \"\"\"\n        return [name for name in dir(cls) \n        if not str(name).startswith('_') and callable(getattr(cls, name))]\n\n\n    @classmethod\n    def __get_all_func__(cls) -> list[Callable]:\n        \"\"\"Get all functions of the class, excluding methods starting with '__' characters.\n\n        Returns:\n            list[Callable]: A list that contains functions.\n        \"\"\"\n        func_names = cls.__get_all_func_name__()\n        return list(map(getattr, [cls]*len(func_names), func_names))\n\n    @classmethod\n    def __get_defined_func__(cls) -> list[Callable]:\n        \"\"\"Get all the functions of the subclass, excluding methods starting with '_' character.\n\n        Returns:\n            list[Callable]: A list that contains defined functions of the subclass.\n\n        Notes:\n            This method removes the parent class's methods from the functions list to \n            provide only the functions that are newly defined in the subclass.\n        \"\"\"\n        functions = cls.__get_all_func__()\n        for parent_cls in cls.__bases__:\n            if not issubclass(parent_cls, BaseEnv):\n                continue\n            parent_functions = parent_cls.__get_all_func__()\n            functions = list(filter(lambda x: x not in parent_functions, functions))\n    \n        return functions\n\n    @classmethod\n    def __get_defined_func_name__(cls) -> list[str]:\n        \"\"\"Get all the function names of the subclass, excluding methods starting with '_' character.\n\n        Returns:\n            list[str]: A list that contains function names of the subclass.\n        \"\"\"\n        functions = cls.__get_defined_func__()\n        return list(map(lambda x: x.__name__, functions))"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/core/tools/shell.py", "content": "import asyncio\nfrom config import CONFIG\n\nfrom core.register import toolwrapper\nfrom core.exceptions import ToolExecutionError\n\nALL_SHELLS: dict[int, asyncio.subprocess.Process] = {}\n\n\nasync def async_read_pipe(pipe: asyncio.StreamReader):\n    ret = b''\n    while True:\n        try:\n            ret += await asyncio.wait_for(pipe.readline(), timeout=0.01)\n        except asyncio.TimeoutError:\n            return ret\nasync def read_exec_proc_display(exec_proc: asyncio.subprocess.Process):\n    display = \"\"\n    for pipe, name in zip([exec_proc.stderr,exec_proc.stdout], ['stderr','stdout']):\n        ret = await async_read_pipe(pipe)\n        if ret != b'':\n            display += f'\\n{name}:\\n'+ ret.decode()\n    return display\n\n@toolwrapper()\nasync def shell_command_executor(command: str = '', run_async: bool = False, shell_id: int = None, kill:bool = False):\n    \"\"\"The shell tool that execute shell command in root privilege, return the output and error. \n    You can use this tool to install packages, download files, run programs, etc.\n    Set run_async=True to run the command in a new thread and return instantly if your command is time costly like install packages, host services. \n    Example:\n    ```\n    In: shell_command_executor(command='echo \"hello world\"')\n    Out: \"hello world\"\n    In: shell_command_executor(command='sleep 10', run_async=True)\n    Out: {'shell_id': 0} # You can use this id to read the output and error later.\n    In: shell_command_executor(shell_id=0, kill=True)\n    Out: \"\" # The shell 0 will be killed.\n    ```\n\n    :param string? command: The shell command to be executed, must avoid command requiring additional user input. Default is empty string.\n    :param boolean? run_async: Whether to run the command asynchronously, default is False. If True, call this tool again with shell_id to get the final output and error. \n    :param integer? shell_id: The id of shell to execute command, default is None, which means running in a new shell. Change this to execute command in the same shell.\n    :param boolean? kill: If True, kill the shell which runs the command after execution. Default is False. Don't use any other kill command!\n    \"\"\"\n    if shell_id is not None:\n        exec_proc = ALL_SHELLS.get(shell_id, None)\n        if exec_proc is None:\n            raise ToolExecutionError(\n                {'Error': 'Shell not found or has been closed.'})\n        if exec_proc.returncode is not None:\n            print(exec_proc.returncode)\n            ALL_SHELLS.pop(shell_id)\n            raise ToolExecutionError({'Error': 'Shell has been closed.'})\n\n    else:\n        exec_proc = await asyncio.create_subprocess_shell(\n            'bash',\n            stderr=asyncio.subprocess.PIPE,\n            stdout=asyncio.subprocess.PIPE,\n            stdin=asyncio.subprocess.PIPE,\n            cwd=CONFIG['filesystem']['work_directory'])\n        shell_id = max(ALL_SHELLS.keys(), default=-1) + 1\n        ALL_SHELLS[shell_id] = exec_proc\n\n    if not run_async:\n        try:\n            ret = await asyncio.wait_for(exec_proc.communicate(command.encode()), timeout=CONFIG['shell']['timeout'])\n        except asyncio.TimeoutError:\n            des = \"Timeout while executing command.\"\n            if kill:\n                des += \" Shell has been killed.\"\n                exec_proc.kill()\n            display = await read_exec_proc_display(exec_proc)\n            if display != \"\":\n                des += \" But get some response:\" + display\n                \n            raise ToolExecutionError(des)\n            \n        ALL_SHELLS.pop(shell_id)\n\n        result = {\n            'ReturnCode': exec_proc.returncode,\n            'display': ''\n        }\n        if ret[1] != b'':\n            result['display'] += f'\\nstderr:\\n'+ret[1].decode()\n        if ret[0] != b'':\n            result['display'] = f'\\nstdout:\\n'+ret[0].decode()\n            \n        if result['ReturnCode'] != 0 and not kill:\n            raise ToolExecutionError(result)\n        return result\n    else:\n        if command[-1] != '\\n':\n            command += '\\n'\n        exec_proc.stdin.write(command.encode())\n        await exec_proc.stdin.drain()\n        await asyncio.sleep(5)\n        result = {'shell_id': shell_id , 'display':await read_exec_proc_display(exec_proc)}\n        if result['display'] == \"\":\n            await asyncio.sleep(30)\n            result['display'] = await read_exec_proc_display(exec_proc)\n        if kill:\n            exec_proc.kill()\n            ALL_SHELLS.pop(shell_id)\n            result['status'] = 'shell thread has been killed'\n        else:\n            result['status'] = 'shell still running, no return code'\n        return result\n"}
{"type": "source_file", "path": "ToolServer/ToolServerManager/node_checker.py", "content": "\nimport asyncio\nimport docker.errors\nimport datetime\n\nfrom config import CONFIG, logger\nfrom connections import docker_client\nfrom models import ToolServerNode\n\n\nasync def check_nodes_status():\n    \"\"\"\n    Check the status of all existing nodes from the selected database 'sqlite3' or 'mongodb'.\n    If a node doesn't exist in Docker, it will be deleted from the database. \n\n    Raises:\n        docker.errors.NotFound: Raised when a Node is not found in Docker\n        docker.errors.APIError: Raised when it fails to get Node info from Docker\n    \"\"\"\n    # Check if each node exists in Docker\n    async for node in ToolServerNode.find_all():\n        container = None\n        try:\n            container = docker_client.containers.get(node.id)\n        except docker.errors.NotFound:\n            # Delete from db if not found in Docker\n            await node.delete()\n            logger.info(\"Node deleted from db: \" + node.id + '(not in docker)')\n            continue\n        except docker.errors.APIError:\n            logger.warning(\"Failed to get node info from docker: \" + node['node_id'])\n            continue\n\n        if container is not None:\n            # Update the node state in db\n            node_status = container.attrs[\"State\"][\"Status\"]\n \n            if node_status != node.status:\n                logger.info(f\"Node {node.short_id} status updated: \" + node.status + \" -> \" + node_status)\n            node.status = node_status\n                \n            if CONFIG['node']['health_check']:\n                health = container.attrs['State']['Health']['Status']\n                if health != node.health:\n                    logger.info(f\"Node {node.short_id} health updated: \" + node.health + \" -> \" + health)\n                node.health = health\n                \n            await node.replace()\n\n            # Check if node is running\n            if node_status == \"running\":\n                if datetime.datetime.utcnow() - node.last_req_time >= datetime.timedelta(minutes=CONFIG['node']['idling_close_minutes']):\n                    container.stop()\n                    logger.info(\"Stopping node: \" + node.id + \" due to idling time used up\")\n\n\nasync def check_nodes_status_loop():\n    \"\"\"\n    An infinite loop that checks the status of the nodes and waits 1 second before each iteration.\n    \"\"\"\n    logger.info(\"Nodes status checker started.\")\n    while True:\n        try:\n            await check_nodes_status()\n        except:\n            import traceback\n            traceback.print_exc()\n        await asyncio.sleep(CONFIG['node'].get('health_check_interval',1))\n\n\nif __name__ == '__main__':\n    asyncio.run(check_nodes_status_loop())\n"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/main.py", "content": "import os\nimport sys\nimport zipfile\nimport traceback\n\nfrom typing import Coroutine,List\n\nfrom fastapi import FastAPI,Body,UploadFile\nfrom fastapi.requests import Request\nfrom fastapi.exceptions import HTTPException\nfrom starlette.responses import FileResponse\n\nfrom config import CONFIG,logger\nfrom core.register import ToolRegister\nfrom core.exceptions import ToolNotFound,OutputNotReady\n\nfrom utils.retriever import ada_retriever,build_tool_embeddings\nfrom utils.response import wrap_tool_response\n\napp = FastAPI()\n\n@app.on_event(\"startup\")\ndef startup():\n    \"\"\"\n    Startup function to initialize the required services and variables for the application.\n    \"\"\"\n    try:\n        # start docker service\n        os.system('service docker start')\n    except:\n        pass\n    app.tool_register = ToolRegister()\n    app.doc_embeddings, app.id2tool = build_tool_embeddings(app.tool_register.get_all_tools_dict(include_invisible=True))\n\n@app.post(\"/\")\n@app.get(\"/\")\nasync def root():\n    \"\"\"\n    Root function that returns a message Hello World.\n    \n    Returns:\n        dict: A dictionary containing a welcoming message.\n    \"\"\"\n    return {\"message\": \"Hello World\"}\n\n@app.post('/upload_file')\nasync def upload_file(file:UploadFile):\n    \"\"\"\n    This function allows the user to upload a file to the work directory defined in configuration file.\n\n    Args:\n        file (fastapi.UploadFile): The file to be uploaded.\n    \n    Returns:\n        dict: A message denoting successful upload of the file.\n    \"\"\"\n    upload_file =  file.file.read()\n    file_name = file.filename\n    work_directory = CONFIG['filesystem']['work_directory']\n    with open(os.path.join(work_directory,file_name),'wb') as f:\n        f.write(upload_file)\n    return {\"message\": \"Upload Success!\"}\n\n@app.post('/download_file')\nasync def download_file(file_path:str=Body(...),file_type:str=Body(default='text/plain')):\n    \"\"\"\n    This function downloads a file from the work directory.\n\n    Args:\n        file_path (str): The path of the file to be downloaded.\n        file_type (str, optional): Type of the file. Defaults to 'text/plain'.\n    \n    Returns:\n        starlette.responses.FileResponse: File response containing the requested file for user to download.\n    \"\"\"\n    work_directory = CONFIG['filesystem']['work_directory']\n    if file_path.startswith(os.path.basename(work_directory)):\n        file_path = file_path[len(os.path.basename(work_directory))+1:]\n    response = FileResponse(\n        path=os.path.join(work_directory,file_path),\n        filename=os.path.basename(file_path),\n        )\n    return response\n\n@app.post('/download_workspace')\nasync def download_workspace():\n    \"\"\"\n    This function downloads the workspace which is a directory consisting of all the uploaded files. \n    \n    Returns:\n        starlette.responses.FileResponse: File response containing the workspace for the user to download. \n    \"\"\"\n    work_directory = CONFIG['filesystem']['work_directory']\n    zip = zipfile.ZipFile('/tmp/workspace.zip','w',zipfile.ZIP_DEFLATED)\n    for path,dirs,files in os.walk(work_directory):\n        fpath= path.replace(work_directory,'')\n        for file in files:\n            zip.write(os.path.join(path,file),os.path.join(fpath,file))\n    \n    zip.close()\n    response = FileResponse(\n        path=os.path.join(work_directory,'/tmp/workspace.zip'),\n        filename='workspace.zip',\n        )\n    return response\n\n\n@app.post('/get_workspace_structure')\nasync def get_workspace_structure():\n    \"\"\"\n    This function generates the structure of the workspace directory.\n    \n    Returns:\n        dict: A dictionary depicting the structure of the workspace directory.\n    \"\"\"\n    work_directory = CONFIG['filesystem']['work_directory']\n    def generate_directory_structure(path):\n        result = {'name':os.path.basename(path)}\n        if os.path.isdir(path):\n            result['type'] = 'directory'\n            result['children'] = [generate_directory_structure(os.path.join(path,child)) for child in os.listdir(path)]\n        else:\n            result['type'] = 'file'\n        return result\n    return generate_directory_structure(work_directory)\n\n@app.post('/get_available_tools')\nasync def get_available_tools():\n    \"\"\"\n    This function returns the available tools and environments registered in the ToolRegister.\n    \n    Returns:\n        dict: A dictionary of available tools, environments and the JSON representation of the tools.\n    \"\"\"\n    tool_register:ToolRegister = app.tool_register\n    return {\n        \"available_envs\": tool_register.get_all_envs(),\n        \"available_tools\": tool_register.get_all_tools(),\n        \"tools_json\": tool_register.get_all_tools_dict(),\n    }\n\n@app.post('/retrieving_tools')\nasync def retrieving_tools(question:str=Body(...), top_k:int=Body(default=5)):\n    \"\"\"\n    This function retrieves the tool names based on a query question using the ADA retriever.\n\n    Args:\n        question (str): The query question for which tools are to be retrieved.\n        top_k (int, optional): The number of top similar tools to be retrieved. Defaults to 5.\n\n    Returns:\n        dict: A dictionary with the list of retrieved tools and JSON representations of the tools.\n\n    Raises:\n        HTTPException: If an error occurs during retrieving the tools.\n    \"\"\"\n    try:\n        retrieved_tools = ada_retriever(app.doc_embeddings, app.id2tool, question, top_k)\n    except Exception as e:\n        error_report =  traceback.format_exc()\n        logger.error(error_report)\n        raise HTTPException(status_code=500, detail=f\"Errorhappens when retrieving tools:\\n{e}\\n\\n\" + error_report)\n    \n    tool_register:ToolRegister = app.tool_register\n    tools_json = []\n    for tool_name in retrieved_tools:\n        if tool_name in tool_register.tools:\n            tools_json.append(tool_register.get_tool_dict(tool_name))\n    \n    return {\n        \"retrieved_tools\":retrieved_tools,\n        \"tools_json\":tools_json,\n    }\n    \n\n@app.post('/get_json_schema_for_tools')\nasync def get_json_schema_for_tool(tool_names:List[str]=Body(...)):\n    \"\"\"\n    This function returns the JSON schema for the given list of tools.\n\n    Args:\n        tool_names (List[str]): List of tool names for which JSON schema is required.\n\n    Returns:\n        dict: JSON schema dictionary for all the available tools and list of error names for missing tools. \n    \"\"\"\n    tool_register:ToolRegister = app.tool_register\n    \n    error_names = []\n    tools_json = []\n    for tool_name in tool_names:\n        if tool_name not in tool_register.tools:\n            error_names.append(tool_name)\n        else:\n            tools_json.append(tool_register.get_tool_dict(tool_name))\n    return {\n        \"tools_json\": tools_json,\n        \"missing_tools\": error_names,\n    }\n\n@app.post('/get_json_schema_for_envs')\nasync def get_json_schema_for_env(env_names:List[str]=Body(...)):\n    \"\"\"\n    This function returns the JSON schema for the given list of tool environments.\n\n    Args:\n        env_names (List[str]): List of environment names for which JSON schema is required.\n\n    Returns:\n        dict: JSON schema dictionary for all the available environments and list of error names for missing environments. \n    \"\"\"\n    tool_register:ToolRegister = app.tool_register\n    \n    error_names = []\n    envs_json = []\n    for env_name in env_names:\n        if env_name not in tool_register.envs:\n            error_names.append(env_name)\n        else:\n            envs_json.append(tool_register.get_env_dict(env_name))\n    return {\n        \"envs_json\": envs_json,\n        \"missing_envs\": error_names,\n    }\n    \n@app.post('/register_new_tool')\nasync def register_new_tool(tool_name:str=Body(...), code:str=Body(...)):\n    \"\"\"\n    This function allows the user to register a new tool by providing the tool name and code.\n\n    Args:\n        tool_name (str): The name of the new tool.\n        code (str): The code for the new tool.\n\n    Returns:\n        dict: A dictionary representing the registered tool.\n\n    Raises:\n        HTTPException: If an error occurs during registering the new tool.\n    \"\"\"\n    tool_register:ToolRegister = app.tool_register\n    try:\n        tool_dict = tool_register.register_tool(tool_name,code)\n    except Exception as e:\n        error_report =  traceback.format_exc()\n        logger.error(error_report)\n        raise HTTPException(status_code=406, detail=f\"Error happens when registering new tool:\\n{e}\\n\\n\" + error_report)\n    \n    return tool_dict\n\n@app.post('/execute_tool')\nasync def execute_tool(tool_name:str=Body(...), arguments:dict=Body(...), env_name:str=Body(default=None)):\n    \"\"\"\n    This function executes a tool with the provided arguments and environment.\n\n    Args:\n        tool_name (str): The name of the tool to be executed.\n        arguments (dict): The arguments for executing the tool.\n        env_name (str, optional): The name of the tool environment in which tool is to be executed. Defaults to None.\n\n    Returns:\n        dict: The result of executing the tool is wrapped in a dictionary.\n\n    Raises:\n        HTTPException: If an error occurs during tool execution.\n    \"\"\"\n    tool_register:ToolRegister = app.tool_register\n    \n    try:\n        if env_name is not None:\n            tool = tool_register[env_name,tool_name]\n        else:\n            tool = tool_register[tool_name]\n        result = tool(**arguments)\n        if isinstance(result,Coroutine):\n            result = await result\n        result = wrap_tool_response(result)\n    except ToolNotFound as e:\n        raise HTTPException(status_code=404, detail=str(e))\n    except OutputNotReady as e:\n        raise HTTPException(status_code=450, detail=e.next_try())\n    except HTTPException as e:\n        raise e\n    except Exception as e:\n        trace_info = traceback.format_exc()\n        logger.error(f'Error happens when executing tool {tool_name}! Exception: {e}\\n{trace_info}')\n        raise HTTPException(status_code=500, detail=trace_info)\n    \n    return result\n\nif __name__=='__main__':\n    import uvicorn\n    uvicorn.run(app, port=12345)"}
{"type": "source_file", "path": "XAgent/agent/dispatcher_agent/prompt.py", "content": "# SYSTEM_PROMPT = \"\"\"Your task is to devise an appropriate role-based name (_GPT) and a clear prompt for an autonomous agent to successfully complete the assigned task.\n\n# The user will provide the task, you will provide only the output in the exact format specified below with no explanation or conversation. Your response should include \"Name\", \"System Prompt\" and \"User Prompt\". The generated prompt should contain all the placeholders that will be filled by the user, including {{system_prompt_placeholders}} in system prompt, and {{user_prompt_placeholders}} in user prompt. These placeholders should be wrapped with {{ and }} in the prompt. Also, you need to keep the important information the same as those specified in the example, such as rules and response format.\n\n# Example input:\n# {{example_input}}\n\n# Example output:\n# Name: PlannerGPT\n# System Prompt: {{example_system_prompt}}\n# User Prompt: {{example_user_prompt}}\"\"\"\n\n# SYSTEM_PROMPT = \"\"\"Your task is to refine a prompt for an autonomous agent to successfully complete the assigned task. The user will provide the task, you will provide only the output in the exact format specified below with no explanation or conversation. \n\n# Below is the current version of prompt:\n# SYSTEM PROMPT:\n# {{example_system_prompt}}\n# USER PROMPT:\n# {{example_user_prompt}}\n\n# Now, please generate additional content that the agent should pay attention to when dealing with the incoming task. Note your generated content will help the agent to avoid some mistakes and more effectively solve the target task. You should only generate the additional content and avoid those unnecessary words.\n\n# Here are some prompts (resources) that maybe helpful for the given task, you could consider them. But they are irrelevant to the upcoming task, please just ignore it:\n# {{retrieved_procedure}}\n\n# Note, you should only generate the ADDITIONAL system prompts, not those existing ones. Make them concise and useful. Do not copy anything that already exist in the given system prompt. Generate new prompts!\n# \"\"\"\n\nSYSTEM_PROMPT = \"\"\"You are a prompt generator, who is capable of generating prompts for autonomous agents. Now, an agent is assigned the following task:\n{{task}}\n\nBelow is the draft prompt that will be given to the agent:\nSYSTEM PROMPT:\n```\n{{example_system_prompt}}\n```\n\nUSER PROMPT:\n```\n{{example_user_prompt}}\n```\n\nNow, please generate additional content that the agent should pay attention to when dealing with the incoming task. Your generated content should help the agent to avoid some mistakes and more effectively solve the target task. \n\nYou should only generate the ADDITIONAL user prompts, do not include the existing content. Make your additional prompt concise and informative. When responding, you should follow the following response format:\nADDITIONAL USER PROMPT:\n```\nWrite your additional user prompt here. If there is nothing to add, just set it to a special token \"[NONE]\".\n```\"\"\"\n# Here are some resources that may be helpful for the given task, you could consider them when responding. If they are irrelevant to the upcoming task, please just ignore it:\n# ```\n# {{retrieved_procedure}}\n# ```"}
{"type": "source_file", "path": "XAgent/agent/base_agent.py", "content": "import abc\nimport json5\nfrom typing import List\nfrom colorama import Fore\nfrom copy import deepcopy\n\nfrom XAgent.config import CONFIG\nfrom XAgent.utils import LLMStatusCode, RequiredAbilities\nfrom XAgent.message_history import Message\nfrom XAgent.logs import logger\nfrom XAgent.ai_functions import objgenerator\n\n\nclass BaseAgent(metaclass=abc.ABCMeta):\n    \"\"\"\n    The BaseAgent class abstracts the essential attributes and methods for classes,\n    which inherit it. It is a metaclass of the Abstract Base Class (abc module).\n\n    Attributes:\n        abilities (set): A set of RequiredAbilities, which are necessary skills for BaseAgent.\n    \"\"\"\n\n    abilities = set([\n        RequiredAbilities.plan_generation,\n        RequiredAbilities.plan_refinement,\n        RequiredAbilities.task_evaluator,\n        RequiredAbilities.tool_tree_search,\n        RequiredAbilities.reflection,\n        RequiredAbilities.summarization,\n    ])\n\n    def __init__(self, config, prompt_messages: List[Message] = None):\n        \"\"\"\n        Constructs an agent object with set abilities, configuration settings,\n        and initial set of prompt messages.\n\n        Args:\n            config (obj): Configuration settings for agent.\n            prompt_messages (List): Initial set of messages user gives to interact with the agent.\n        \"\"\"\n        logger.typewriter_log(\n            f\"Constructing an Agent:\",\n            Fore.YELLOW,\n            self.__class__.__name__,\n        )\n        self.config = config\n        self.prompt_messages = prompt_messages\n        self.usage = { }\n\n    @abc.abstractmethod\n    def parse(self,**args) -> (LLMStatusCode, Message, dict):\n        \"\"\"\n        Abstract method that needs to be implemented by the subclasses.\n        Required for parsing the given arguments.\n        \"\"\"\n        pass    \n\n    def fill_in_placeholders(self, placeholders: dict):\n        \"\"\"\n        Fills in placeholders defined in the input with the corresponding values.\n        \n        Args:\n            placeholders (dict): A dictionary containing keys as placeholders and values as their replacements.\n\n        Returns:\n            filled_messages: A copy of the initial prompt_messages with placeholders replaced with their corresponding values.\n        \"\"\"\n        filled_messages = deepcopy(self.prompt_messages)\n        for message in filled_messages:\n            role = message.role\n            if role in placeholders:\n                for key, value in placeholders[role].items():\n                    message.content = message.content.replace(\"{{\" + str(key) + \"}}\", str(value))\n        return filled_messages\n\n    def generate(self,\n                 messages:list[dict]|list[Message],\n                 arguments:dict=None,\n                 functions:list[dict]=None,\n                 function_call:dict=None,\n                 stop:dict=None,\n                 *args,**kwargs):\n        \"\"\"\n        Generates a response from the AI model, using the given messages, arguments, functions,\n        and a function call.\n\n        Args:\n            messages (list[dict]|list[Message]): A list of messages with which to interact with the AI model.\n            arguments (dict, optional): A dictionary containing arguments to use for AI model responses.\n            functions (list[dict], optional): A list of dictionaries representing functions to use for AI model responses.\n            function_call (dict, optional): A dictionary representing a function call to use for AI model responses.\n            stop (dict, optional): A dictionary that signifies when to stop the conversation with the AI model.\n            *args: Variable list of arguments. \n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            message (dict): A message generated by the AI model.\n            tokens (int): Number of tokens used in generating the AI model's response.\n        \"\"\"\n        if isinstance(messages[0],Message):\n            messages = [message.raw() for message in messages]\n        if functions is not None and len(functions) == 1 and function_call is None:\n            function_call = {'name':functions[0]['name']} # must call at least one function\n        match CONFIG.default_request_type:\n            case 'openai':\n                if arguments is not None:\n                    if functions is None or len(functions) == 0:\n                        functions = [{\n                            'name':'reasoning',\n                            'parameters':arguments\n                        }]\n                        function_call = {'name':'reasoning'}\n                    elif len(functions) == 1:\n                        for k,v in arguments['properties'].items():\n                            functions[0]['parameters']['properties'][k] = v\n                            if k in arguments['required']:\n                                functions[0]['parameters']['required'].append(k)\n                    else:\n                        raise NotImplementedError(\"Not implemented for multiple functions with arguments\")\n                    \n                response = objgenerator.chatcompletion(\n                    messages=messages,\n                    functions=functions,\n                    function_call=function_call,\n                    stop=stop,\n                    *args,**kwargs)\n                \n                message = {}\n                function_call_args:dict = json5.loads(response[\"choices\"][0][\"message\"][\"function_call\"]['arguments'])\n                \n                if arguments is not None:\n                    message['arguments'] = {\n                        k: function_call_args.pop(k)\n                        for k in arguments['properties'].keys() if k in function_call_args\n                    }\n                if len(function_call_args) > 0:\n                    message['function_call'] = {\n                        'name': response['choices'][0]['message']['function_call']['name'],\n                        'arguments': function_call_args\n                    }\n\n            case 'xagent':\n                response = objgenerator.chatcompletion(\n                    messages=messages,\n                    arguments=arguments,\n                    functions=functions,\n                    function_call=function_call,\n                    stop=stop,\n                    *args,**kwargs)\n                message = json5.loads(response[\"choices\"][0][\"message\"]['content'])\n            case _:\n                raise NotImplementedError(f\"Request type {CONFIG.default_request_type} not implemented\")\n            \n        tokens = response[\"usage\"]\n        return message, tokens\n"}
{"type": "source_file", "path": "XAgent/agent/dispatcher_agent/agent.py", "content": "import re\nimport copy\nimport json5\nfrom typing import List\n\nfrom .prompt import SYSTEM_PROMPT\n\nfrom XAgent.logs import logger\nfrom XAgent.message_history import Message\nfrom XAgent.agent.base_agent import BaseAgent\n\nclass DispatcherAgent(BaseAgent):\n    \"\"\"\n    A subclass of BaseAgent whose primary function is to help dispatch tasks to \n    different agent handlers based on the task requirements.\n\n    Attributes:\n    ------------\n    config : object\n        The configuration settings for the agent.\n    prompt_messages : List[Message]\n        The list of prompt messages for the agent to dispatch.\n    \"\"\"\n    def __init__(self, config, prompt_messages: List[Message] = None):\n        \"\"\"\n        Initialize a DispatcherAgent instance.\n\n        Args:\n        -------\n        config : object\n            The configuration settings for the agent.\n        prompt_messages : list, optional\n            The list of prompt messages for the agent to dispatch, defaults to None.\n            If not provided, default_prompt_messages is used instead.\n        \"\"\"\n        self.config = config\n        self.prompt_messages = (\n            self.default_prompt_messages if prompt_messages is None else prompt_messages\n        )\n\n    @property\n    def default_prompt_messages(self):\n        \"\"\"\n        Returns the default system prompt messages in the form of a list of Message objects.\n\n        Returns:\n        -----------\n        list[Message] : \n            A list containing the default prompt message.\n        \"\"\"\n        return [Message(role=\"system\", content=SYSTEM_PROMPT)]\n\n    def find_all_placeholders(self, prompt):\n        \"\"\"\n        Finds all placeholders within a prompt.\n\n        Args:\n        --------\n        prompt : str\n            The string within which placeholders are to be found.\n\n        Returns:\n        --------\n        list[str] : \n            A list of all placeholders found within the prompt.\n        \"\"\"\n        return re.findall(r\"{{(.*?)}}\", prompt)\n\n    def construct_input_messages(\n        self,\n        task: str,\n        example_input: str,\n        example_system_prompt: str,\n        example_user_prompt: str,\n        retrieved_procedure: str,\n    ):\n        \"\"\"\n        Constructs input messages by replacing placeholders in the prompt_messages \n        with provided data.\n\n        Args:\n        ---------\n        task : str\n            The task to be completed.\n        example_input : str\n            An example input for the task.\n        example_system_prompt : str\n            The example system prompt for the task.\n        example_user_prompt : str\n            The example user prompt for the task.\n        retrieved_procedure : str\n            The retrieved process for the task.\n\n        Returns:\n        ---------\n        list[Message] :\n            A list containing the constructed input messages with placeholders replaced with provided data.\n        \"\"\"\n        prompt_messages = copy.deepcopy(self.prompt_messages)\n        # TODO: Make it more robust. Here we assume only the first message is system prompt\n        #       and we only update the placeholders in the first message.\n        prompt_messages[0].content = (\n            prompt_messages[0]\n            .content.replace(\"{{example_system_prompt}}\", example_system_prompt)\n            .replace(\"{{example_user_prompt}}\", example_user_prompt)\n            .replace(\"{{retrieved_procedure}}\", retrieved_procedure)\n            .replace(\"{{task}}\", task)\n        )\n        return prompt_messages  # + [Message(role=\"user\", content=task)] \n\n    def extract_prompts_from_response(self, message):\n        \"\"\"\n        Extracts additional prompts from the dispatcher's response message.\n\n        Args:\n        --------\n        message : str \n           The response message from the dispatcher.\n\n        Returns:\n        ---------\n        str : \n            The additional prompt extracted from the message; if not found, \"\" is returned.\n\n        \"\"\"\n        try:\n            additional_prompt = re.findall(r\"ADDITIONAL USER PROMPT:?\\n```(.*)```\", message['content'], re.DOTALL)[0].strip()\n        except IndexError as e:\n            logger.error(\n                f\"Failed to extract prompts from the dispatcher's response:\\n{message['content']}\"\n            )\n            logger.error(\"Fallback to use the default prompts.\")\n            additional_prompt = \"\"\n        return additional_prompt\n\n    def retrieved_procedure(self, query: str) -> str:\n        # TODO: this function should be implemented thru tool server\n\n        \"\"\"\n        Retrieves a procedure relevant to the given query from an external site.\n\n        Args:\n        --------\n        query : str\n            The query to retrieve the relevant procedure.\n\n        Returns:\n        ---------\n        str : \n            The relevant procedure retrieved; if retrieval fails, the string 'None' is returned.\n        \"\"\"\n        \n        url = \"https://open-procedures.replit.app/search/\"\n        try:\n            import requests\n            import json\n\n            relevant_procedures = requests.get(url, params={'query': query}).json()[\n                \"procedures\"\n            ][0]\n        except:\n            # For someone, this failed for a super secure SSL reason.\n            # Since it's not strictly necessary, let's worry about that another day. Should probably log this somehow though.\n            relevant_procedures = \"None\"\n\n        return relevant_procedures\n\n    def parse(\n        self,\n        task: str,\n        example_input: str,\n        example_system_prompt: str,\n        example_user_prompt: str,\n        stop=None,\n        **args,\n    ) -> List[Message]:\n        # TODO: should we consider additional messages when generating prompt?\n        # currently the plan generation and refine agent are the same since we\n        # don't consider the additional messages when generating prompt.\n\n        \"\"\"\n        Parse the task and related data to generate prompt messages.\n\n        Args:\n        ---------\n        task : str\n            The task to be processed.\n        example_input : str\n            An example input related to the task.\n        example_system_prompt : str\n            An example system prompt related to the task.\n        example_user_prompt : str\n            An example user prompt related to the task.\n        stop : str, optional\n            The stopping criterion for message generation, defaults to None.\n\n        Returns:\n        ---------\n        Tuple[List[Message], List[str]] : \n            A tuple containing a list of prompt messages and tokens.\n        \"\"\"\n        message,tokens = self.generate(\n            messages=self.construct_input_messages(\n                task,\n                example_input,\n                example_system_prompt,\n                example_user_prompt,\n                \"\"  \n            ),\n            stop=stop,\n            **args,\n        )\n\n        additional_prompt = message['arguments']['additional_prompt']\n\n        prompt_messages = []\n        if additional_prompt != \"\":\n            example_user_prompt += \"\\n\\nADDITIONAL NOTES\\n\" + additional_prompt\n        prompt_messages.append(Message(role=\"system\", content=example_system_prompt))\n        prompt_messages.append(Message(role=\"user\", content=example_user_prompt))\n\n        return prompt_messages, tokens"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/utils/retriever.py", "content": "import os\nimport re\nimport json\nimport tqdm\nimport requests\nimport numpy as np\nimport logging\n\nfrom concurrent.futures import ThreadPoolExecutor\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom config import CONFIG\n\nlogger = logging.getLogger(CONFIG['logger'])\nSTANDARDIZING_PATTERN = re.compile(\"[^\\\\u4e00-\\\\u9fa5^a-z^A-Z^0-9^_]\")\n\ndef standardizing(string: str) -> str:\n    \"\"\"\n    Return a standardized string by replacing non-alphanumeric characters with underscores,\n    reducing multiple underscores to one, and converting all characters to lowercase.\n\n    Args:\n        string: The input string to be standardized.\n\n    Returns: \n        A standardized version of the input string.\n    \"\"\"\n    string = STANDARDIZING_PATTERN.sub(\"_\", string)\n    string = re.sub(r\"(_)\\1+\",\"_\", string)\n    string = string.strip(\"_\").lower()\n    return string\n\ndef ada_retriever(doc_embeddings: list, id2tool:dict, question: str, top_k: int=5) -> list:\n    \"\"\"\n    Retrieve tools related to the provided question.\n\n    Args:\n        doc_embeddings: The list of document embeddings.\n        id2tool: A dictionary mapping tool id to tool name.\n        question: The question for the ADA retriever.\n        top_k: The number of top tools to return (default is 5).\n\n    Returns:\n        A list of retrieved tools.\n    \"\"\"\n    cfg = CONFIG['retriver']\n    url = cfg['endpoint']\n    headers = cfg['headers']\n    payload = {'input':question}\n    payload.update(cfg['payload'])\n    \n    response = requests.post(url, json=payload, headers=headers)\n    query_embedding = np.array(response.json()['data'][0]['embedding'])\n\n    similarities = cosine_similarity([query_embedding], doc_embeddings)\n\n    sorted_doc_indices = sorted(range(len(similarities[0])), key=lambda i: similarities[0][i], reverse=True)\n    retrieved_tools = list(map(lambda doc_id: id2tool[str(doc_id)],sorted_doc_indices[:top_k]))\n    \n    return retrieved_tools\n\ndef build_tool_embeddings(tools_json: list[dict]) -> tuple:\n    \"\"\"\n    Build tool embeddings.\n\n    Args:\n        tools_json: The list of dictionaries containing tool data.\n\n    Returns:\n        A tuple containing a list of document embeddings and a dictionary\n        mapping tool id to tool name.\n    \"\"\"\n    cfg = CONFIG['retriver']\n    if os.path.exists(cfg['id2tool_file']) and os.path.exists(cfg['embedding_file']):\n        id2tool = json.load(open(cfg['id2tool_file'], \"r\"))\n        doc_embedings = np.load(cfg['embedding_file'])\n        if len(id2tool) != len(doc_embedings):\n            logger.error('Embedding file and id2tool file do not match! Rebuild embeddings!')\n            id2tool = {}\n            doc_embedings = []\n    else:\n        id2tool = {}\n        doc_embedings = []\n\n    # check embedding file whether need to be updated\n    # get all current tool names\n    # tool_names = set(map(lambda tool_json: tool_json['name'], tools_json))\n    # cached_tool_names = set(id2tool.values())\n    # if tool_names == cached_tool_names:\n    #     logger.info('No tools change, use cached embeddings!')\n    #     return doc_embedings, id2tool\n    return doc_embedings, id2tool\n    \n    # update embeddings\n    logger.info('Tools change detected, updating embeddings...')\n    url = cfg['endpoint']\n    headers = cfg['headers']\n    \n    new_id2tool = { str(i):tool_json['name'] for i,tool_json in enumerate(tools_json) }\n    json.dump(new_id2tool, open(cfg['id2tool_file'], \"w\"), indent=4)\n\n    def get_embedding(tool_json:dict) -> list:\n        \"\"\"\n        Get embedding for a certain tool.\n\n        Args:\n            tool_json: The dictionary containing tool data.\n\n        Returns:\n            A list of tool embeddings.\n        \"\"\"\n        payload = {'input':json.dumps(tool_json)}\n        payload.update(cfg['payload'])\n        try:\n            response = requests.post(url, json=payload, headers=headers)\n            response.raise_for_status()\n        except Exception as e:\n            logger.error(f'Failed to get embedding for tool {tool_json[\"name\"]}! Error: {e}')\n            return [-1.000001] * cfg['embedding_dim']\n        return response.json()['data'][0]['embedding']\n    \n    uncached_tools = list(filter(lambda tool_json: tool_json['name'] not in cached_tool_names, tools_json))\n    uncached_tools_name = list(map(lambda tool_json: tool_json['name'],uncached_tools))\n    uncached_doc_embedings = []\n    with ThreadPoolExecutor(16) as pool:\n        futures = [pool.submit(get_embedding, tool_json) for tool_json in uncached_tools]\n        \n        for future in tqdm.tqdm(futures,ncols=100):\n            uncached_doc_embedings.append(future.result())\n    \n    new_doc_embedings = []\n    for tool_json in tools_json:\n        if tool_json['name'] not in cached_tool_names:\n            new_doc_embedings.append(\n                uncached_doc_embedings[\n                    uncached_tools_name.index(tool_json['name'])\n                    ])\n        else:\n            for doc_id in id2tool.keys():\n                if id2tool[doc_id] == tool_json['name']:\n                    new_doc_embedings.append(doc_embedings[int(doc_id)])\n                    break\n\n    new_doc_embedings = np.array(new_doc_embedings)\n    np.save(cfg['embedding_file'], new_doc_embedings)\n\n    logger.info('Embeddings updated! New embeddings saved!')\n    return doc_embedings, new_id2tool"}
{"type": "source_file", "path": "XAgent/agent/plan_refine_agent/__init__.py", "content": "from .agent import PlanRefineAgent\nfrom .prompt import get_examples_for_dispatcher"}
{"type": "source_file", "path": "XAgent/agent/plan_refine_agent/agent.py", "content": "from typing import List\nfrom XAgent.agent.plan_generate_agent import PlanGenerateAgent\nfrom XAgent.utils import RequiredAbilities\nfrom XAgent.message_history import Message\n\nclass PlanRefineAgent(PlanGenerateAgent):\n    \"\"\"PlanRefineAgent is a subclass of PlanGenerateAgent and is involved in refining the plan.\n\n    This class utilizes the required ability of plan refinement to parse information \n    and generate a refined plan. It includes placeholders as the desired expressions.\n\n    Attributes:\n        abilities: A set of required abilities for the Agent. For PlanRefineAgent, it includes plan refinement.\n    \"\"\"\n    abilities = set([RequiredAbilities.plan_refinement])\n\n    def parse(\n        self,\n        placeholders: dict = {},\n        arguments:dict = None,\n        functions=None,\n        function_call=None,\n        stop=None,\n        additional_messages: List[Message] = [],\n        additional_insert_index: int = -1,\n        *args,\n        **kwargs\n    ):\n        \"\"\" Parses information in order to refine the existing plan.\n\n        This method fills in placeholders with corresponding expressions, then prompts and \n        additional messages are processed and converged into final messages. Finally, the \n        'generate' method of PlanGenerateAgent class is then invoked on the final messages.\n\n        Args:\n            placeholders (dict, optional): Desired expressions to fill in partially completed text snippets.\n            arguments (dict, optional): Arguments to the function.\n            functions (optional): Functions to be carried out.\n            function_call (optional): Functional request from the user.\n            stop (optional): Stop parsing at some particular point.\n            additional_messages (List[Message], optional): Additional messages to be included in final message.\n            additional_insert_index (int, optional): Index in prompt messages where additional messages should be inserted.\n            *args: Variable length argument list.\n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            object: A refined plan generated from provided placeholders, arguments, functions, and messages.\n        \"\"\"\n        \n        prompt_messages = self.fill_in_placeholders(placeholders)\n        messages =prompt_messages[:additional_insert_index] + additional_messages + prompt_messages[additional_insert_index:]\n        \n        return self.generate(\n            messages=messages,\n            arguments=arguments,\n            functions=functions,\n            function_call=function_call,\n            stop=stop,\n            *args,**kwargs\n        )"}
{"type": "source_file", "path": "XAgent/agent/dispatcher_agent/__init__.py", "content": "from .agent import DispatcherAgent\n"}
{"type": "source_file", "path": "XAgent/agent/plan_generate_agent/agent.py", "content": "from typing import List\nfrom XAgent.agent.base_agent import BaseAgent\nfrom XAgent.utils import RequiredAbilities\nfrom XAgent.ai_functions import function_manager, objgenerator\nfrom XAgent.message_history import Message\n\n\nclass PlanGenerateAgent(BaseAgent):\n    \"\"\"\n    This class is responsible for plan generation. It is a subclass of BaseAgent.\n\n    Attributes:\n        abilities: A set indicating the abilities required by this agent.\n    \"\"\"\n    abilities = set([RequiredAbilities.plan_generation])\n\n    def parse(\n        self,\n        placeholders: dict = {},\n        arguments: dict = None,\n        functions=None,\n        function_call=None,\n        stop=None,\n        additional_messages: List[Message] = [],\n        *args,\n        **kwargs\n    ):\n        \"\"\"\n        This method is used to parse placeholders, arguments, function calls, and additional messages \n        to generate a plan.\n\n        Args:\n            placeholders (dict, optional): A dictionary containing placeholders to fill in the messages.\n            arguments (dict, optional): A dictionary containing arguments to be used in the functions.\n            functions: The functions to be used during plan generation.\n            function_call: The object representing a function call.\n            stop: The condition to stop the plan generation process if specified.\n            additional_messages (List[Message], optional): A list of additional messages to be added to \n            the initial prompt messages.\n            *args: Variable length argument list.\n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            This method returns the result of the plan generated by the \"generate\" method.\n        \"\"\"\n        prompt_messages = self.fill_in_placeholders(placeholders)\n        messages = prompt_messages + additional_messages\n\n        return self.generate(\n            messages=messages,\n            arguments=arguments,\n            functions=functions,\n            function_call=function_call,\n            stop=stop,\n            *args, **kwargs\n        )"}
{"type": "source_file", "path": "XAgent/agent/dispatcher.py", "content": "import abc\nfrom typing import List\nfrom colorama import Fore, Style\nfrom XAgent.config import CONFIG\n\nfrom XAgent.agent.base_agent import BaseAgent\nfrom XAgent.utils import RequiredAbilities, TaskSaveItem, AgentRole\nfrom XAgent.agent.dispatcher_agent import DispatcherAgent\nfrom XAgent.message_history import Message\n\n\nclass AgentDispatcher(metaclass=abc.ABCMeta):\n    \"\"\"\n    Base abstract class for Agent Dispatcher.\n    \"\"\"\n    def __init__(self, logger=None):\n        \"\"\"\n        Initialize AgentDispatcher. Assign agent markets for each requirement in RequiredAbilities.\n        Agent markets are initially empty.\n        \"\"\"\n        self.agent_markets = {}\n        self.logger = logger\n        for requirement in RequiredAbilities:\n            self.agent_markets[requirement] = []\n        self.logger.typewriter_log(\n            f\"Constructing an AgentDispatcher:\",\n            Fore.YELLOW,\n            self.__class__.__name__,\n        )\n\n    @abc.abstractmethod\n    def dispatch(self, ability_type: RequiredAbilities, target_task) -> BaseAgent:\n        \"\"\"\n        Abstract dispatch method to be implemented by subclasses. Dispatches tasks based\n        on ability type.\n\n        Args:\n            ability_type (RequiredAbilities): The ability type required for the task.\n            target_task: The task which needs to be dispatched.\n\n        Returns:\n            BaseAgent: Base agent responsible for the task.\n        \"\"\"\n        pass\n\n    def dispatch_role(self, target_task: TaskSaveItem) -> AgentRole:\n        \"\"\"\n        Dispatch a role for the target task.\n\n        Args:\n            target_task (TaskSaveItem): The task for which a role needs to be dispatched.\n\n        Returns:\n            AgentRole: Returns a default AgentRole.\n        \"\"\"\n        return AgentRole()\n\n    def regist_agent(self, agent: BaseAgent):\n        \"\"\"\n        Register agent to the respective agent markets based on abilities.\n\n        Args:\n            agent (BaseAgent): The agent that needs to be registered.\n        \"\"\"\n        for requirement in RequiredAbilities:\n            if requirement in agent.abilities:\n                self.agent_markets[requirement].append(agent)\n\n\nclass AutomaticAgentDispatcher(AgentDispatcher):\n    \"\"\"\n    AgentDispatcher that automatically dispatches tasks to agents.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize AutomaticAgentDispatcher.\n        \"\"\"\n        super().__init__()\n\n    def dispatch(self, ability_type: RequiredAbilities, target_task) -> BaseAgent:\n        \"\"\"\n        Dispatch task to the agent in the market corresponding to the task ability type.\n\n        Args:\n            ability_type (RequiredAbilities): The ability type required for the task.\n            target_task: The task which needs to be dispatched.\n\n        Returns:\n            BaseAgent: Base agent responsible for the task.\n        \"\"\"\n        return self.agent_markets[ability_type][0]()\n\n\nclass XAgentDispatcher(AgentDispatcher):\n    \"\"\"Generate the prompt and the agent for the given task.\"\"\"\n\n    def __init__(self, config, enable=True, logger=None):\n        \"\"\"\n        Initialize XAgentDispatcher.\n\n        Args:\n            config: Dispatcher configuration.\n            enable (bool, optional): Whether the dispatcher is active. Defaults to True.\n        \"\"\"\n        self.logger = logger\n        super().__init__(logger)\n        self.config = config\n        self.dispatcher = DispatcherAgent(config)\n        self.enable = enable\n\n    def get_examples(self, ability_type: RequiredAbilities):\n        \"\"\"\n        Get examples based on the ability type.\n\n        Args:\n            ability_type (RequiredAbilities): The ability type for which examples are needed.\n\n        Returns:\n            Returns examples for the dispatcher.\n        \"\"\"\n        if ability_type == RequiredAbilities.plan_generation:\n            from .plan_generate_agent import get_examples_for_dispatcher\n        elif ability_type == RequiredAbilities.plan_refinement:\n            from .plan_refine_agent import get_examples_for_dispatcher\n        elif ability_type == RequiredAbilities.tool_tree_search:\n            from .tool_agent import get_examples_for_dispatcher\n        elif ability_type == RequiredAbilities.reflection:\n            from .reflect_agent import get_examples_for_dispatcher\n        return get_examples_for_dispatcher()\n\n    def build_agent(\n        self,\n        ability_type: RequiredAbilities,\n        config,\n        prompt_messages: List[Message],\n        *args,\n        **kwargs,\n    ) -> BaseAgent:\n        \"\"\"\n        Build agent based on the ability type. If failed, fallback to use default agent.\n\n        Args:\n            ability_type (RequiredAbilities): Type of ability required by the agent.\n            config: Configuration for the agent.\n            prompt_messages (List[Message]): List of prompt messages for the agent.\n\n        Returns:\n            BaseAgent: The built agent.\n        \"\"\"\n        try:\n            agent = self.agent_markets[ability_type][0](\n                config, prompt_messages, *args, **kwargs\n            )\n        except:\n            # TODO: remove when all the agents can be created with dispatcher.\n            self.logger.info(\"build agent error, use default agent\")\n            agent = self.agent_markets[ability_type][0](config, *args, **kwargs)\n        return agent\n\n    def dispatch(\n        self,\n        ability_type: RequiredAbilities,\n        target_task: TaskSaveItem,\n        *args,\n        **kwargs,\n    ) -> BaseAgent:\n        \"\"\"\n        Dispatch task to the agent in the market corresponding to the task ability type.\n        Additionally refines the prompt for the task and builds the agent.\n\n        Args:\n            ability_type (RequiredAbilities): The ability type required for the task.\n            target_task (TaskSaveItem): The task which needs to be dispatched.\n\n        Returns:\n            BaseAgent: Base agent responsible for the task.\n        \"\"\"\n        example_input, example_system_prompt, example_user_prompt = self.get_examples(\n            ability_type\n        )\n        if self.enable:\n            self.logger.typewriter_log(self.__class__.__name__, Fore.GREEN, f\"Refine the prompt of a specific agent for {Fore.GREEN}RequiredAbilities.{ability_type.name}{Style.RESET_ALL}\")\n            _, prompt_messages, tokens = self.dispatcher.parse(\n                target_task, example_input, example_system_prompt, example_user_prompt\n            )\n            print(prompt_messages)\n            if prompt_messages[0].content == \"\" and prompt_messages[1].content == \"\":\n                self.logger.info(\"Dispatcher fail to follow the output format, we fallback to use the default prompt.\")\n                prompt_messages = [\n                    Message(role=\"system\", content=example_system_prompt),\n                    Message(role=\"user\", content=example_user_prompt),\n                ]\n            else:\n                self.logger.typewriter_log(self.__class__.__name__, Fore.GREEN, f\"The prompt has been refined!\")\n        else:\n            prompt_messages = [\n                Message(role=\"system\", content=example_system_prompt),\n                Message(role=\"user\", content=example_user_prompt),\n            ]\n        agent = self.build_agent(ability_type, self.config, prompt_messages, *args, **kwargs)\n        return agent\n\n\n# agent_dispatcher = XAgentDispatcher(CONFIG, enable=False)"}
{"type": "source_file", "path": "XAgent/agent/reflect_agent/__init__.py", "content": "from .agent import ReflectAgent\nfrom .prompt import get_examples_for_dispatcher"}
{"type": "source_file", "path": "XAgent/agent/plan_generate_agent/__init__.py", "content": "from .agent import PlanGenerateAgent\nfrom .prompt import get_examples_for_dispatcher"}
{"type": "source_file", "path": "XAgent/agent/__init__.py", "content": "from .plan_generate_agent import PlanGenerateAgent\nfrom .plan_refine_agent import PlanRefineAgent\nfrom .tool_agent import ToolAgent\nfrom .reflect_agent import ReflectAgent"}
{"type": "source_file", "path": "XAgent/agent/plan_refine_agent/prompt.py", "content": "SYSTEM_PROMPT = '''You are plan-rectify agent, your task is to iteratively rectify a plan of a query.\n--- Background Information ---\nPLAN AND SUBTASK:\nA plan has a tree manner of subtasks: task 1 contains subtasks task 1.1, task 1.2, task 1.3, and task 1.2 contains subtasks 1.2.1, 1.2.2...\nPlease remember:\n1.The plan tree has a max width of {{max_plan_tree_width}}, meaning the max subtask count of a task. If max_width=4, the task like 1.4 is valid, but task 1.5 is not valid.\n2.The plan tree has a max depth of {{max_plan_tree_depth}}. If max_depth=3, the task like 1.3.2 is valid, but task 1.4.4.5 is not valid.\n\nA subtask-structure has the following json component:\n{\n\"subtask name\": string\n\"goal.goal\": string, the main purpose of the sub-task should handle, and what will you do to reach this goal?\n\"goal.criticism\": string, What problems may the current subtask and goal have?\n\"milestones\": list[string]. How to automatically check the sub-task is done?\n}\n\nSUBTASK HANDLE:\nA task-handling agent will handle all the subtasks as the inorder-traversal. For example:\n1. it will handle subtask 1 first.\n2. if solved, handle subtask 2. If failed, split subtask 1 as subtask 1.1 1.2 1.3... Then handle subtask 1.1.\n3. Handle subtasks recursively, until all subtasks are solved.\n4. It is powered by a state-of-the-art LLM, so it can handle many subtasks without using external tools or execute codes.\n\nRESOURCES:\n1. Internet access for searches and information gathering, search engine and web browsing.\n2. A FileSystemEnv to read and write files (txt, code, markdown, latex...)\n3. A python interpretor to execute python files together with a pdb debugger to test and refine the code.\n4. A ShellEnv to execute bash or zsh command to further achieve complex goals. \n\n--- Task Description ---\nYour task is iteratively rectify a given plan and based on the goals, suggestions and now handling postions. \n\nPLAN_REFINE_MODE: At this mode, you will use the given operations to rectify the plan. At each time, use one operation.\nSUBTASK OPERATION:\n - split: Split a already handled but failed subtask into subtasks because it is still so hard. The `target_subtask_id` for this operation must be a leaf task node that have no children subtasks, and should provide new splitted `subtasks` of length 2-4. You must ensure the `target_subtask_id` exist, and the depth of new splitted subtasks < {{max_plan_tree_depth}}.\n    - split 1.2 with 2 subtasks will result in create new 1.2.1, 1.2.2 subtasks.\n - add: Add new subtasks as brother nodes of the `target_subtask_id`. This operation will expand the width of the plan tree. The `target_subtask_id` should point to a now handling subtask or future subtask.\n    - add 1.1 with 2 subtasks will result in create new 1.2, 1.3 subtasks.\n    - add 1.2.1 with 3 subtasks wil result in create new 1.2.2, 1.2.3, 1.2.4 subtasks.\n - delete: Delete a subtask. The `target_subtask_id` should point to a future/TODO subtask. Don't delete the now handling or done subtask.\n    - delete 1.2.1 will result in delete 1.2.1 subtask.\n - exit: Exit PLAN_REFINE_MODE and let task-handle agent to perform subtasks.\n\n--- Note ---\nThe user is busy, so make efficient plans that can lead to successful task solving.\nDo not waste time on making irrelevant or unnecessary plans.\nDon't use search engine if you have the knowledge for planning.\nDon't divide trivial task into multiple steps. \nIf task is un-solvable, give up and submit the task.\n\n*** Important Notice ***\n- Never change the subtasks before the handling positions, you can compare them in lexicographical order.\n- Never create (with add or split action) new subtasks that similar or same as the existing subtasks.\n- For subtasks with similar goals, try to do them together in one subtask with a list of subgoals, rather than split them into multiple subtasks.\n- Every time you use a operation, make sure the hierarchy structure of the subtasks remians, e.g. if a subtask 1.2 is to \"find A,B,C\" , then newly added plan directly related to this plan (like \"find A\", \"find B\", \"find C\") should always be added as 1.2.1, 1.2.2, 1.2.3...\n- You are restricted to give operations in at most 4 times, so the plan refine is not so much.\n- The task handler is powered by sota LLM, which can directly answer many questions. So make sure your plan can fully utilize its ability and reduce the complexity of the subtasks tree.\n'''\n\nUSER_PROMPT = '''Your task is to choose one of the operators of SUBTASK OPERATION, note that\n1.You can only modify the subtask with subtask_id>{{subtask_id}}(not included). \n2.If you think the existing plan is good enough, use REFINE_SUBMIT.\n3.You can at most perform {{max_step}} operations before REFINE_SUBMIT operation, you have already made {{modify_steps}} steps, watch out the budget. \n4.All the plan has a max depth of {{max_plan_tree_depth}}. Be carefull when using SUBTASK_SPLIT.\n5. Please use function call to respond to me (remember this!!!).\n\n--- Status ---\nFile System Structure: {{workspace_files}}\nRefine Node Message: {{refine_node_message}}\n'''\n\ndef get_examples_for_dispatcher():\n    \"\"\"The example that will be given to the dispatcher to generate the prompt\n\n    Returns:\n        example_input: the user query or the task\n        example_system_prompt: the system prompt\n        example_user_prompt: the user prompt\n    \"\"\"\n    example_input = \"Refine a plan for writing a Python-based calculator.\"\n    example_system_prompt = SYSTEM_PROMPT\n    example_user_prompt = USER_PROMPT\n    return example_input, example_system_prompt, example_user_prompt"}
{"type": "source_file", "path": "XAgent/agent/plan_generate_agent/prompt.py", "content": "SYSTEM_PROMPT = '''You are an efficient plan-generation agent, your task is to decompose a query into several subtasks that describe must achieved goals for the query.\n--- Background Information ---\nPLAN AND SUBTASK:\nA plan has a tree manner of subtasks: task 1 contatins subtasks task 1.1, task 1.2, task 1.3, ... and task 1.2 contains subtasks 1.2.1, 1.2.2, ...\n\nA subtask-structure has the following json component:\n{\n\"subtask name\": string, name of the subtask\n\"goal.goal\": string, the main purpose of the subtask, and what will you do to reach this goal?\n\"goal.criticism\": string, what potential problems may the current subtask and goal have?\n\"milestones\": list[string]. what milestones should be achieved to ensure the subtask is done? Make it detailed and specific.\n}\nSUBTASK HANDLE:\nA task-handling agent will handle all the subtasks as the inorder-traversal. For example:\n1. it will handle subtask 1 first.\n2. if solved, handle subtask 2. If failed, split subtask 1 as subtask 1.1 1.2 1.3... Then handle subtask 1.1 1.2 1.3...\n3. Handle subtasks recurrsively, until all subtasks are soloved. Do not make the task queue too complex, make it efficiently solve the original task.\n4. It is powered by a state-of-the-art LLM, so it can handle many subtasks without using external tools or execute codes.\n\nRESOURCES:\n1. Internet access for searches and information gathering, search engine and web browsing.\n2. A FileSystemEnv to read and write files (txt, code, markdown, latex...)\n3. A python notebook to execute python code. Always follow python coding rules.\n4. A ShellEnv to execute bash or zsh command to further achieve complex goals. \n--- Task Description ---\nGenerate the plan for query with operation SUBTASK_SPLIT, make sure all must reach goals are included in the plan.\n\n*** Important Notice ***\n- Always make feasible and efficient plans that can lead to successful task solving. Never create new subtasks that similar or same as the existing subtasks.\n- For subtasks with similar goals, try to do them together in one subtask with a list of subgoals, rather than split them into multiple subtasks.\n- Do not waste time on making irrelevant or unnecessary plans.\n- The task handler is powered by sota LLM, which can directly answer many questions. So make sure your plan can fully utilize its ability and reduce the complexity of the subtasks tree.\n- You can plan multiple subtasks if you want.\n- Minimize the number of subtasks, but make sure all must reach goals are included in the plan.\n'''\n\nUSER_PROMPT = '''This is not the first time you are handling the task, so you should give a initial plan. Here is the query:\n\"\"\"\n{{query}}\n\"\"\"\nYou will use operation SUBTASK_SPLIT to split the query into 2-4 subtasks and then commit.'''\n\n\ndef get_examples_for_dispatcher():\n    \"\"\"The example that will be given to the dispatcher to generate the prompt\n\n    Returns:\n        example_input: the user query or the task\n        example_system_prompt: the system prompt\n        example_user_prompt: the user prompt\n    \"\"\"\n    example_input = \"Generate a plan for writing a Python-based calculator.\"\n    example_system_prompt = SYSTEM_PROMPT\n    example_user_prompt = USER_PROMPT\n    return example_input, example_system_prompt, example_user_prompt"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/utils/__init__.py", "content": "from .import_helper import import_all_modules_in_folder"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/utils/response.py", "content": "import base64\nfrom typing import Callable,Dict,Any\n\nfrom config import logger\n\ndef is_base64(s:str) -> bool:\n    \"\"\"\n    Check if the given string is a base64 sting or not.\n\n    Args:\n        s (str): the string to be checked.\n\n    Returns:\n        bool: Returns True if the given string is a base64 string, False otherwise.\n    \"\"\"\n    try:\n        base64.b64decode(s)\n        return True\n    except:\n        return False\n\ndef is_wrapped_response(obj:dict) -> bool:\n    \"\"\"\n    Check if the dictionary object is a wrapped response.\n    A dictionary is considered as wrapped response if it has 'type' and 'data' keys,\n    and value of 'type' key is one of ['simple','composite','binary'].\n\n    Args:\n        obj (dict): the dictionary object to be checked.\n\n    Returns:\n        bool: Returns True if the dictionary is a wrapped response, False otherwise.\n    \"\"\"\n    if 'type' in obj and obj['type'] in ['simple','composite','binary'] and 'data' in obj:\n        return True\n    return False\n\ndef wrap_tool_response(obj:Any) -> dict|list|str|int|float|bool:\n    \"\"\"\n    Wrap the tool response in a standardized object structure (depending on its type) to allow decoding.\n    \n    Format\n    ======\n    ```\n    {\n        'type': 'simple',       # for single return value like python basic types\n        'data': obj\n    },\n    {\n        'type': 'binary',       # for single return value like python basic types\n        'media_type':'image/png',   # or other media types\n        'name': 'xxx',             # file name of the binary data\n        'data': obj             # base64 encoded binary data\n    },\n    str,int,float,bool,list is directly returned\n    or\n    {\n        'type': 'composite',    # for multiple return values\n        'data': [\n            {\n                'type': 'simple',\n                'data': obj1\n            },\n            {\n                'type': 'simple',\n                'data': obj2\n            }\n        ]\n    }\n    ```\n    Standardized Structures:\n    - For simple data types (str, int, float, bool), the object is directly returned.\n    - For composite types (tuples), data is wrapped in an object with a composite type.\n    - For binary data, data is base64 encoded and wrapped in an object with a binary type.\n     \n\n    Args:\n        obj (Any): any Python object that needs to be wrapped.\n\n    Returns:\n        Union[dict, list, str, int, float, bool]: the wrapped response.\n        \n    Raises:\n        logger.warning: raises warning if the type of 'obj' is unknown.\n    \"\"\"\n    if isinstance(obj,tuple):\n        if len(obj) == 0:\n            ret = {\n                'type': 'simple',\n                'data': None\n            }\n        elif len(obj) == 1:\n            ret = {\n                'type': 'simple',\n                'data': obj[0]\n            }\n        else:\n            ret = {\n                'type': 'composite',\n                'data': []\n            }\n            for o in obj:\n                ret['data'].append(wrap_tool_response(o))\n    elif isinstance(obj,bytes):\n        ret = {\n            'type': 'binary',\n            'media_type': 'bytes',\n            'name': None,\n            'data': base64.b64encode(obj).decode()\n        }\n    elif isinstance(obj,(str,int,float,bool,list)) or obj is None:\n        ret = obj\n    elif isinstance(obj,dict):\n        # check if already wrapped\n        if is_wrapped_response(obj):\n            ret = obj\n        else:\n            ret = {\n                'type': 'simple',\n                'data': obj\n            }\n    else:\n        logger.warning(f'Unknown type {type(obj)} in wrap_tool_response')\n        ret = {\n            'type': 'simple',\n            'data': obj\n        }\n    return ret"}
{"type": "source_file", "path": "XAgent/agent/reflect_agent/prompt.py", "content": "SYSTEM_PROMPT = '''You are a posterior_knowledge_obtainer. You have performed some subtask together with:\n1.Some intermediate thoughts, this is the reasoning path.\n2.Some tool calls, which can interact with physical world, and provide in-time and accurate data.\n3.A workspace, a minimal file system and code executer.\n\nYou plan of the task is as follows:\n--- Plan ---\n{{all_plan}}\n\nYou have handled the following subtask:\n--- Handled Subtask ---\n{{terminal_plan}}\n\nthe available tools are as follows: \n--- Tools ---\n{{tool_functions_description_list}}\n\nThe following steps have been performed:\n--- Actions ---\n{{action_process}}\n\nNow, you have to learn some posterior knowledge from this process, doing the following things:\n1.Summary: Summarize the tool calls and thoughts of the existing process. You will carry these data to do next subtasks(Because the full process is too long to bring to next subtasks), So it must contain enough information of this subtask handling process. Especially, If you modified some files, Tell the file_name and what you done.\n\n2.Reflection of SUBTASK_PLAN: After performing the subtask, you get some knowledge of generating plan for the next time. This will be carried to the next time when you generate plan for a task.\n\n3.Reflection of tool calling: What knowledge of tool calling do you learn after the process? (Like \"tool xxx is not available now\", or \"I need to provide a field yyy in tool aaa\") This knowledge will be showed before handling the task next time.'''\n\nUSER_PROMPT = \"\"\n\n\ndef get_examples_for_dispatcher():\n    \"\"\"The example that will be given to the dispatcher to generate the prompt\n\n    Returns:\n        example_input: the user query or the task\n        example_system_prompt: the system prompt\n        example_user_prompt: the user prompt\n    \"\"\"\n    example_input = \"Reflect on the previous actions and give the posterior knowledge\"\n    example_system_prompt = SYSTEM_PROMPT\n    example_user_prompt = USER_PROMPT\n    return example_input, example_system_prompt, example_user_prompt"}
{"type": "source_file", "path": "XAgent/__init__.py", "content": ""}
{"type": "source_file", "path": "XAgent/agent/summarize.py", "content": "from colorama import Fore\nfrom XAgent.utils import ToolCallStatusCode,get_token_nums,clip_text\nfrom XAgent.ai_functions import function_manager\nfrom XAgent.config import CONFIG\nfrom XAgent.logs import logger\n\nSINGLE_ACTION_MAX_LENGTH = CONFIG.summary['single_action_max_length']\nMAX_RETURN_LENGTH = CONFIG.summary['max_return_length']\nMAX_PLAN_LENGTH = CONFIG.max_plan_length\n\ndef summarize_action(action_process:list[dict], task:str,)->(list[str],str):\n    \"\"\"\n    Generate a summarized series of actions.\n\n    Args:\n        action_process (list[dict]): The list of actions to process.\n        task (str): The task name.\n\n    Returns:\n        str: The string contains a summary of the actions.\n    \"\"\"\n    if len(action_process) < 1:\n        return \"No steps found\"\n    \n    def generate_func_args(args:dict,black_list=[])->str:\n        \"\"\"\n        Generate function arguments in the form of strings.\n\n        Args:\n            args (dict): A dictionary of arguments.\n            black_list (list): A list of forbidden or restricted words or keys in the args dictionary.\n\n        Returns:\n            str: A string that summarizes the function arguments.\n        \"\"\"\n        ret = ''\n        args_len = 0\n        for k,v in args.items():\n            if k in black_list:\n                v = '`wrapped`'\n            v_str,v_len = clip_text(str(v),SINGLE_ACTION_MAX_LENGTH-args_len,clip_end=True)\n            if v_len < SINGLE_ACTION_MAX_LENGTH-args_len:\n                ret += f'{k}=\"{v_str}\",' if isinstance(v,str) else f'{k}={v_str},'\n                args_len += v_len\n            else:\n                ret += f'{k}=\"{v_str}...\",' if isinstance(v,str) else f'{k}={v_str}...,'\n                args_len += SINGLE_ACTION_MAX_LENGTH-args_len\n                \n        return ret[:-1] # remove last comma\n    \n    # wrap old content\n    raw_actions = {}\n    accessed_files = []\n    last_successful_action_index = None\n    last_failed_action_index = None\n    for index,action in zip(range(len(action_process)-1,-1,-1),action_process[::-1]):\n        if last_successful_action_index is None and action['tool_status_code'] == ToolCallStatusCode.TOOL_CALL_SUCCESS:\n            last_successful_action_index = index\n        if last_failed_action_index is None and action['tool_status_code'] == ToolCallStatusCode.TOOL_CALL_FAILED:\n            last_failed_action_index = index\n        \n        command = action[\"command\"][\"properties\"]\n        if command['name'] == '' or not isinstance(command['args'],dict):\n            continue\n        \n        raw_action = ['`placeholder`','`placeholder`']\n        \n        if \"FileSystem\" in command[\"name\"] and \"filepath\" in command[\"args\"] and action[\"tool_status_code\"] == ToolCallStatusCode.TOOL_CALL_SUCCESS:\n            raw_action[0] = command['name']+f\"({generate_func_args(command['args'],black_list=['content','new_content'])})\"\n            if command['args']['filepath'] in accessed_files:\n                raw_action[1] = \"`Old Content has been wrapped, check latest filesystem calling`\"\n            else:\n                raw_action[1] = str(action['tool_output'])\n                accessed_files.append(command[\"args\"][\"filepath\"])\n        else:\n            raw_action[0] = command['name']+f\"({generate_func_args(command['args'])})\"\n            raw_action[1] = str(action['tool_output'])\n            \n        raw_actions[index] = raw_action\n    valid_index = list(raw_actions.keys())\n    valid_index.sort()\n    \n    ret = {}\n    for index in valid_index:\n        action = action_process[index]\n        if 'summary' not in action:\n            raw_actions_des = '\\n'.join([\n                f'[{k}] {v}' for k,v in action['thoughts']['properties'].items()\n            ] + [\n                f\"[tool_status_code] {action['tool_status_code']}\",\n                f\"[tool calling] {raw_actions[index][0]}\",\n                f\"[return] \"\n            ])\n            raw_actions_des += clip_text(raw_actions[index][1],MAX_RETURN_LENGTH-get_token_nums(raw_actions_des))[0]\n            \n            summary,tokens = function_manager('summarize_action',\n                                              action=raw_actions_des,current_task=task,\n                                              return_generation_usage=True,)\n            action['summary'] = summary\n            logger.typewriter_log(f\"Action summarized in {tokens['completion_tokens']} tokens\",Fore.YELLOW)\n        else:\n            summary = action['summary']\n        \n        act_str = '\\n'.join([\n            f'[{index}] {raw_actions[index][0]}',\n            f\"[{index}][summary] {summary['summary']}\",\n            f\"[{index}][description] {summary['description']}\",\n            f\"[{index}][status code] {action['tool_status_code']}\"\n        ])\n        if 'failed_reason_and_reflection' in summary and summary['failed_reason_and_reflection'] != '':\n            act_str += f'\\n[{index}][failed reason] {summary[\"failed_reason_and_reflection\"]}'\n        \n        # directly adding short returns\n        if len(raw_actions[index][1]) < 1000 and get_token_nums(raw_actions[index][1]) < 150:\n            act_str += f'\\n[{index}][return] {raw_actions[index][1]}'\n            \n        ret[index] = act_str\n    \n    reflection = function_manager('actions_reflection',\n                                  actions=clip_text('\\n'.join([ret[i] for i in valid_index]),MAX_RETURN_LENGTH)[0],\n                                  current_task=task)\n    \n    ret_lenght = {k:get_token_nums(v) for k,v in ret.items()}\n    total_length = sum(ret_lenght.values())\n    \n    # adding more return to last successful action\n    for i in [last_successful_action_index,last_failed_action_index]:\n        if i is not None and '[return]' not in ret[i]:\n            s = f'\\n[{i}][return] {clip_text(raw_actions[i][1],(MAX_RETURN_LENGTH-total_length)//2)[0]}'\n            return_length = get_token_nums(s)\n            ret_lenght[i] += return_length\n            total_length += return_length\n            ret[i] += s\n\n    key_actions:list = reflection['key_actions']\n    key_actions.sort(reverse=True)\n    for i in key_actions:\n        if total_length >= MAX_RETURN_LENGTH:\n            break\n        if i in ret and action_process[i][\"tool_status_code\"] == ToolCallStatusCode.TOOL_CALL_SUCCESS and '[return]' not in ret[i]:\n            s = f'\\n[{i}][return] {clip_text(raw_actions[i][1],SINGLE_ACTION_MAX_LENGTH-ret_lenght[i])[0]}'\n            if (tokens := get_token_nums(s))> MAX_RETURN_LENGTH-total_length:\n                continue\n            total_length += tokens\n            ret[i] += s\n    \n    while len(valid_index) > 0:\n        i = valid_index.pop()\n        if total_length >= MAX_RETURN_LENGTH:\n            break\n        if action_process[i][\"tool_status_code\"] == ToolCallStatusCode.TOOL_CALL_SUCCESS and '[return]' not in ret[i]:\n            s = f'\\n[{i}][return] {clip_text(raw_actions[i][1],SINGLE_ACTION_MAX_LENGTH-ret_lenght[i])[0]}'\n            if (tokens := get_token_nums(s))> MAX_RETURN_LENGTH-total_length:\n                continue\n            total_length += tokens\n            ret[i] += s\n\n\n    valid_index = list(ret.keys())\n    valid_index.sort()\n    ordered_rets = [ret[i] for i in valid_index] + [f'[suggestion] {sugg}'for sugg in reflection[\"suggestions\"]]\n    \n    return '\\n'.join(ordered_rets)\n\ndef summarize_plan(plans:dict)->str:\n    \"\"\"\n    Generate a summarized plan based on provided plans.\n\n    Args:\n        plans (dict): The plans to provide.\n\n    Returns:\n        str: The string contains a summary of the plan.\n    \"\"\"\n    summary:list[list] = []\n    task_ids = []\n    detailed_info:dict[str,list] = {}\n    current_task_id = None\n    def recursive_summary(plan:dict,):\n        \"\"\"\n        Generate a summarized plan in a recursive process.\n\n        Args:\n            plan (dict): A dictionary of plans.\n\n        Returns:\n            None\n        \"\"\"\n        nonlocal summary\n        nonlocal current_task_id\n        plan_des = [\n            f'[Task ID] {plan[\"task_id\"]}',\n            f'[Name] {plan[\"name\"]}',\n            f'[Goal] {plan[\"goal\"]}',\n            f'[Status] {plan[\"exceute_status\"]}',\n        ]\n        if current_task_id is None and plan['exceute_status'] == 'DOING':\n            current_task_id = plan['task_id']\n            \n        if 'milestones' in plan and len(plan['milestones']) > 0:\n            plan_des.extend(['[Milestones]']+['- '+milestone for milestone in plan[\"milestones\"]])\n\n        \n        if 'action_list_summary' not in plan and 'prior_plan_criticism' in plan:\n            plan_des.append(f'[Prior Plan Criticism] {plan[\"prior_plan_criticism\"]}')\n        \n        if 'submit_result' in plan and 'args' in plan['submit_result']:\n            submission = plan['submit_result']['args']\n            plan_des.append(f'[Action Status] {\"Success\" if submission[\"result\"][\"success\"] else \"Fail\"}')\n            \n            # possible too long part\n            action_des = [\n                '[Action Info]',\n                f\"- [Conclusion] {submission['result']['conclusion']}\"\n            ]\n            if 'action_list_summary' in plan:\n                action_des.append(f'- [Summary] {plan[\"action_list_summary\"]}')  \n            if submission['suggestions_for_latter_subtasks_plan']['need_for_plan_refine']:\n                if submission['suggestions_for_latter_subtasks_plan']['reason'] != '':\n                    action_des.append(f\"- [Proposal] {submission['suggestions_for_latter_subtasks_plan']['reason']}\")\n            detailed_info[plan['task_id']] = action_des\n        \n        task_ids.append(plan['task_id'])\n        summary.append(plan_des)\n        if \"subtask\" in plan:\n            for subtask in plan[\"subtask\"]:\n                recursive_summary(subtask)\n    recursive_summary(plans)\n    total_tokens = sum([get_token_nums('\\n'.join(plan)) for plan in summary])\n    if current_task_id is None:\n        current_task_id = task_ids[-1]\n    for task_id,plan in zip(task_ids[::-1],summary[::-1]):\n        if task_id <= current_task_id and task_id in detailed_info:\n            if (tokens:=get_token_nums('\\n'.join(detailed_info[task_id]))) > MAX_PLAN_LENGTH-total_tokens:\n                continue\n            else:\n                total_tokens += tokens\n                plan.extend(detailed_info[task_id])\n    # logger.typewriter_log(f'Plan summarized {total_tokens}',Fore.YELLOW)\n    ret = []\n    for plan in summary:\n        ret.append('\\n'.join(plan))\n    return '\\n'.join(ret)"}
{"type": "source_file", "path": "XAgent/agent/reflect_agent/agent.py", "content": "from typing import List\nfrom XAgent.agent.base_agent import BaseAgent\nfrom XAgent.utils import RequiredAbilities\nfrom XAgent.message_history import Message\n\nclass ReflectAgent(BaseAgent):\n    \"\"\"This ReflectAgent class extends the BaseAgent class. It primarily has the ability of reflection \n    which means it can reflect upon the chat or dialogue and generate responses based on the messages\n    received.\n\n    Attributes:\n        abilities (set): Required abilities for the agent, namely reflection in this case. \n    \"\"\"\n\n    abilities = set([RequiredAbilities.reflection])\n\n    def parse(\n        self,\n        placeholders: dict = {},\n        arguments:dict = None,\n        functions=None,\n        function_call=None,\n        stop=None,\n        additional_messages: List[Message] = [],\n        *args,\n        **kwargs\n    ):\n        \"\"\"\n        The function is used to parse various arguments and call the generate function with these parsed arguments.\n\n        Args:\n            placeholders (dict, optional): Placeholders for the agent's responses. \n            arguments(dict, optional): Argument to influence the response of the agent.\n            functions (functions, optional): Functions to guide the agent's response.\n            function_call (FunctionType, optional): Function called to generate agent's response. \n            stop (bool, optional): Flag to stop the induction of the response. \n            additional_messages (list, optional): Additional messages to be included in the response. \n\n        Returns:\n            object: Response generated by the agent. \n\n        \"\"\"\n        prompt_messages = self.fill_in_placeholders(placeholders)\n        messages = prompt_messages + additional_messages\n\n        return self.generate(\n            messages=messages,\n            arguments=arguments,\n            functions=functions,\n            function_call=function_call,\n            stop=stop,\n            *args,**kwargs\n        )"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/utils/import_helper.py", "content": "import os\nimport importlib\ndef import_all_modules_in_folder(file,name):\n    current_dir = os.path.dirname(file)\n    all_modules = []\n    for item in os.listdir(current_dir):\n        item_path = os.path.join(current_dir, item)\n        if os.path.isfile(item_path) and item != '__init__.py' and item.endswith('.py'):\n            module_name = item[:-3]\n        elif os.path.isdir(item_path) and item != '__pycache__' and os.path.exists(os.path.join(item_path, '__init__.py')) and os.path.isfile(os.path.join(item_path, '__init__.py')):\n            module_name = item\n        else:\n            continue\n\n        full_module_path = f\"{name}.{module_name}\"\n        # print(module_name,full_module_path)\n        imported_module = importlib.import_module(full_module_path)\n        globals()[module_name] = imported_module\n        all_modules.append(imported_module)\n    return all_modules"}
{"type": "source_file", "path": "ToolServer/ToolServerNode/utils/openai.py", "content": "import os\nimport json\nimport openai\nimport random\nimport logging\n\nfrom copy import deepcopy\nfrom config import CONFIG\nfrom typing import List,Dict,Any\nfrom tenacity import wait_random_exponential,stop_after_attempt,retry\n\nlogger = logging.getLogger(CONFIG['logger'])\n\nclass OpenaiPoolRequest:\n    \"\"\"\n    Handles all OpenAI requests by dispatching them to the API endpoints.\n\n    Attributes:\n        openai_cfg: Configuration dictionary containing OpenAI parameters.\n        pool: list of dictionaries, where each dictionary has all the required details of an endpoint.\n    \"\"\"\n    def __init__(self,):\n        \"\"\"\n        Initializes the OpenaiPoolRequest class by setting the configuration and loading the pool.\n        \"\"\"\n        self.openai_cfg = deepcopy(CONFIG['openai'])\n        \n        self.pool:List[Dict] = []\n        \n        __pool_file = self.openai_cfg['key_pool_json']\n        if os.environ.get('API_POOL_FILE',None) is not None:\n            __pool_file = os.environ.get('API_POOL_FILE')\n        \n        if os.path.exists(__pool_file):\n            self.pool = json.load(open(__pool_file))\n        \n        if os.environ.get('OPENAI_KEY',None) is not None:\n            self.pool.append({\n                'api_key':os.environ.get('OPENAI_KEY'),\n                'organization':os.environ.get('OPENAI_ORG',None),\n                'api_type':os.environ.get('OPENAI_TYPE',None),\n                'api_version':os.environ.get('OPENAI_VER',None)\n            })\n        if len(self.pool) == 0:\n            logger.warning('No openai api key found! Some functions will be disable!')\n\n    @retry(wait=wait_random_exponential(multiplier=1, max=10), stop=stop_after_attempt(5),reraise=True)\n    async def request(self,messages,**kwargs) -> Dict[str, Any]:\n        \"\"\"\n        Sends a request to the OpenAI and gets a response.\n\n        Args:\n            messages: Payload to be sent to OpenAI.\n            kwargs: Optional arguments that the function takes.\n\n        Returns:\n            A dictionary containing the response from the OpenAI.\n\n        Raises:\n            Exception: If the attempt to reach the endpoint exceed limit.\n        \"\"\"\n        \n        chat_args:dict = deepcopy(self.openai_cfg['chat_args'])\n        chat_args.update(kwargs)\n\n        item = random.choice(self.pool)\n        chat_args['api_key'] = item['api_key']\n        if 'organization' in item:\n            chat_args['organization'] = item['organization']\n        if 'api_type' in item:\n            chat_args['api_type'] = item['api_type']\n        if 'api_version' in item:\n            chat_args['api_version'] = item['api_version']\n\n        return await openai.ChatCompletion.acreate(messages=messages,**chat_args)\n    \n    async def __call__(self,messages,**kwargs) -> Dict[str, Any]:\n        \"\"\"\n        Makes a request to the OpenAI by calling the instance of the class.\n\n        Args:\n            messages: Payload to be sent to OpenAI.\n            kwargs: Optional arguments that the function takes.\n\n        Returns:\n            A dictionary containing the response from the OpenAI.\n\n        Raises:\n            Exception: If there are no API keys available in the pool.\n        \"\"\"\n        if len(self.pool)==0:\n            raise Exception('No openai api key found! OPENAI_PR Disabled!')\n        return await self.request(messages,**kwargs)\n    \nOPENAI_PR = OpenaiPoolRequest()\n\n"}
