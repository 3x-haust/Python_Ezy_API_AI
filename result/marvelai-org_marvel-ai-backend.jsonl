{"repo_info": {"repo_name": "marvel-ai-backend", "repo_owner": "marvelai-org", "repo_url": "https://github.com/marvelai-org/marvel-ai-backend"}}
{"type": "test_file", "path": "app/assistants/classroom_support/co_teacher/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/assistants/classroom_support/co_teacher/tests/test_core.py", "content": "import pytest\n\nfrom app.assistants.classroom_support.co_teacher.core import executor\nfrom app.services.assistant_registry import Message, MessagePayload, MessageType, Role, UserInfo\n\nbase_attributes = {\n    \"user_info\": UserInfo(\n        user_name=\"Aaron\",\n        user_age=30,\n        user_preference=\"Senior AI Engineer\"\n    )\n}\n\ndef test_executor_translate_valid():\n    result = executor(\n        **base_attributes,\n        messages = [\n            Message(\n                role=Role.human,\n                type=MessageType.text,\n                timestamp=\"string\",\n                payload=MessagePayload(\n                    text=\"Give me insights for personalized teaching\"\n                )\n            ),\n            Message(\n                role=Role.ai,\n                type=MessageType.text,\n                timestamp=None,\n                payload=MessagePayload(\n                    text=(\n                        \"Okay, Aaron, as a Senior AI Engineer, you're likely someone who values data-driven strategies and innovative \"\n                        \"solutions. Let's tailor some insights for personalized teaching with that in mind. Here's how you can approach \"\n                        \"this, leveraging your analytical and problem-solving skills:\\n\\n\"\n                        \"**1. Data-Driven Student Understanding:**\\n\\n\"\n                        \"*   **Analytics Approach:** Just like in AI projects, you can analyze student performance data to identify patterns \"\n                        \"and tailor your teaching methods. Look at areas where students excel and where they struggle. Use this data to \"\n                        \"understand the varying needs of your students.\\n\"\n                        \"*   **Actionable Steps:**\\n\"\n                        \"    *   Use formative assessments (quizzes, exit tickets, in-class activities) to collect data.\\n\"\n                        \"    *   Create a spreadsheet or use a digital tool to track student performance across different topics or skills.\\n\"\n                        \"    *   Identify individual student strengths, areas of improvement, and preferred learning styles.\\n\\n\"\n                        \"**2. Adaptive Content and Delivery:**\\n\\n\"\n                        \"*   **Modular Content Creation:** Think of your teaching material like modular code, where you can easily modify \"\n                        \"and adapt it. Develop a core set of learning materials and then adapt to student needs by offering multiple versions \"\n                        \"(different problem sets, examples, or explanations).\\n\"\n                        \"*   **Actionable Steps:**\\n\"\n                        \"    *   Develop a resource repository of varying complexity levels for each topic.\\n\"\n                        \"    *   Experiment with different media formats (videos, interactive simulations, audio explanations) to cater to diverse \"\n                        \"learning preferences.\\n\"\n                        \"    *   Offer a range of choices in how students approach their learning - which project they want to work on, which \"\n                        \"practice questions they attempt, etc.\\n\\n\"\n                        \"**3. Algorithm-Based Feedback:**\\n\\n\"\n                        \"*   **Timely and Specific Feedback:** Aim to provide feedback that is not only timely but also very specific. Think \"\n                        \"of it as debugging a code – the feedback needs to pinpoint the problem precisely.\\n\"\n                        \"*   **Actionable Steps:**\\n\"\n                        \"    *   Use rubrics for grading that clearly outline expectations.\\n\"\n                        \"    *   Provide feedback that is focused on the concepts, not just the final answer.\\n\"\n                        \"    *   Use automated tools, where possible, to offer initial feedback, allowing you to focus on more complex issues.\\n\\n\"\n                        \"**4. Collaborative Problem-Solving:**\\n\\n\"\n                        \"*   **Agile Team Teaching:** Approach your classroom as an agile team working on a project. Encourage collaboration \"\n                        \"and peer-to-peer learning.\\n\"\n                        \"*   **Actionable Steps:**\\n\"\n                        \"    *   Implement group activities with defined roles, as you might in a project team.\\n\"\n                        \"    *   Have students teach each other concepts, thereby reinforcing their own understanding.\\n\"\n                        \"    *   Use pair programming or group programming tasks to foster learning from each other.\\n\\n\"\n                        \"**5. Iterative Teaching Process:**\\n\\n\"\n                        \"*   **Continuous Improvement:** Just like in software development, use a continuous improvement approach to your teaching. \"\n                        \"Regularly evaluate your teaching practices and make adjustments based on results.\\n\"\n                        \"*   **Actionable Steps:**\\n\"\n                        \"    *   Solicit student feedback on your teaching methods and the content.\\n\"\n                        \"    *   Periodically reflect on what works and what doesn't.\\n\"\n                        \"    *   Don't be afraid to experiment with new approaches based on feedback and data.\\n\\n\"\n                        \"Aaron, your experience with AI and data analysis can be a powerful asset in personalizing your teaching approach. By treating \"\n                        \"your classroom as a dynamic system with evolving needs, you can create a learning environment that is truly tailored to each \"\n                        \"of your students. You have an analytical mindset and the tools to make data-driven decisions in the classroom. By embracing \"\n                        \"these strategies, you'll be able to provide a more engaging and effective learning experience for your students! Let me know \"\n                        \"if you want to explore any of these strategies further.\"\n                    )\n                )\n            ),\n            Message(\n                role=Role.human,\n                type=MessageType.text,\n                timestamp=\"string\",\n                payload=MessagePayload(\n                    text=\"Please, summarize what you said and translate that to Spanish\"\n                )\n            )\n        ]\n    )\n    assert isinstance(result, str)\n\ndef test_executor_translate_invalid():\n    with pytest.raises(TypeError) as exc_info:\n        executor(\n            messages=[\n                {\n                    \"role\":\"human\",\n                    \"type\":\"text\",\n                    \"timestamp\":\"string\",\n                    \"payload\":{\n                    \"text\":\"Give me insights for personalized teaching\"\n                    }\n                },\n                {\n                    \"role\":\"ai\",\n                    \"type\":\"text\",\n                    \"timestamp\":None,\n                    \"payload\":{\n                    \"text\":\"Okay, Aaron, as a Senior AI Engineer, you're likely someone who values data-driven strategies and innovative solutions. Let's tailor some insights for personalized teaching with that in mind. Here's how you can approach this, leveraging your analytical and problem-solving skills:\\n\\n**1. Data-Driven Student Understanding:**\\n\\n*   **Analytics Approach:** Just like in AI projects, you can analyze student performance data to identify patterns and tailor your teaching methods. Look at areas where students excel and where they struggle. Use this data to understand the varying needs of your students.\\n*   **Actionable Steps:**\\n    *   Use formative assessments (quizzes, exit tickets, in-class activities) to collect data.\\n    *   Create a spreadsheet or use a digital tool to track student performance across different topics or skills.\\n    *   Identify individual student strengths, areas of improvement, and preferred learning styles.\\n\\n**2. Adaptive Content and Delivery:**\\n\\n*   **Modular Content Creation:** Think of your teaching material like modular code, where you can easily modify and adapt it. Develop a core set of learning materials and then adapt to student needs by offering multiple versions (different problem sets, examples, or explanations).\\n*   **Actionable Steps:**\\n    *   Develop a resource repository of varying complexity levels for each topic.\\n    *   Experiment with different media formats (videos, interactive simulations, audio explanations) to cater to diverse learning preferences.\\n    *   Offer a range of choices in how students approach their learning - which project they want to work on, which practice questions they attempt, etc.\\n\\n**3. Algorithm-Based Feedback:**\\n\\n*   **Timely and Specific Feedback:** Aim to provide feedback that is not only timely but also very specific. Think of it as debugging a code – the feedback needs to pinpoint the problem precisely.\\n*   **Actionable Steps:**\\n    *   Use rubrics for grading that clearly outline expectations.\\n    *   Provide feedback that is focused on the concepts, not just the final answer.\\n    *   Use automated tools, where possible, to offer initial feedback, allowing you to focus on more complex issues.\\n\\n**4. Collaborative Problem-Solving:**\\n\\n*   **Agile Team Teaching:** Approach your classroom as an agile team working on a project. Encourage collaboration and peer-to-peer learning.\\n*   **Actionable Steps:**\\n    *   Implement group activities with defined roles, as you might in a project team.\\n    *   Have students teach each other concepts, thereby reinforcing their own understanding.\\n    *   Use pair programming or group programming tasks to foster learning from each other.\\n\\n**5. Iterative Teaching Process:**\\n\\n*   **Continuous Improvement:** Just like in software development, use a continuous improvement approach to your teaching. Regularly evaluate your teaching practices and make adjustments based on results.\\n*   **Actionable Steps:**\\n    *   Solicit student feedback on your teaching methods and the content.\\n    *   Periodically reflect on what works and what doesn't.\\n    *   Don't be afraid to experiment with new approaches based on feedback and data.\\n\\nAaron, your experience with AI and data analysis can be a powerful asset in personalizing your teaching approach. By treating your classroom as a dynamic system with evolving needs, you can create a learning environment that is truly tailored to each of your students. You have an analytical mindset and the tools to make data driven decisions in the classroom. By embracing these strategies, you'll be able to provide a more engaging and effective learning experience for your students! Let me know if you want to explore any of these strategies further.\\n\"\n                    }\n                },\n                {\n                    \"role\":\"human\",\n                    \"type\":\"text\",\n                    \"timestamp\":\"string\",\n                    \"payload\":{\n                    \"text\":\"Please, summarize what you said and translate that to spanish\"\n                    }\n                }\n            ]\n        )\n    assert isinstance(exc_info.value, TypeError)"}
{"type": "test_file", "path": "app/tools/ai_resistant_assignment_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/flashcards_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/lesson_plan_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/multiple_choice_quiz_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/multiple_choice_quiz_generator/tests/test_tools.py", "content": "import pytest\nfrom unittest.mock import patch, MagicMock, Mock\nimport os\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_chroma import Chroma\nfrom app.tools.multiple_choice_quiz_generator.tools import (\n    transform_json_dict, read_text_file, QuizBuilderConfig, QuizBuilder, RetrieverFactory, Document\n)\n\nclass QuizBuilderFactory:\n    \"\"\"\n    Factory class to create QuizBuilder instances with default or custom configurations.\n    \"\"\"\n    @staticmethod\n    def create_quiz_builder(topic = \"Science\",\n                            n_questions = 5,\n                            lang = \"en\",\n                            grade_level = \"High School\",\n                            quiz_description = \"Sample quiz\",\n                            config = QuizBuilderConfig()):\n        \n        user_input = {\n                        \"topic\": topic,\n                        \"n_questions\": n_questions,\n                        \"grade_level\": grade_level,\n                        \"quiz_description\": quiz_description,\n                        \"lang\": lang,\n                        \"config\": config\n        }\n        return QuizBuilder(**user_input)\n\n@pytest.fixture\ndef config():\n    return QuizBuilderConfig()\n\n@pytest.fixture\ndef quiz_builder(config):\n    return QuizBuilderFactory.create_quiz_builder(config=config)\n\n@pytest.fixture\ndef factory(config):\n    return RetrieverFactory(config)\n\ndef test_transform_json_dict():\n    input_data = {\n        \"questions_list\": [\n            {\n                \"question\": \"What is the capital of France?\",\n                \"choices\": [\n                    {\"key\": \"A\", \"value\": \"Berlin\"},\n                    {\"key\": \"B\", \"value\": \"Madrid\"},\n                    {\"key\": \"C\", \"value\": \"Paris\"},\n                    {\"key\": \"D\", \"value\": \"Rome\"},\n                ],\n                \"answer\": \"C\",\n                \"explanation\": \"Paris is the capital of France.\"\n            }\n        ]\n    }\n    expected_output = [\n        {\n            \"question\": \"What is the capital of France?\",\n            \"choices\": {\"A\": \"Berlin\", \"B\": \"Madrid\", \"C\": \"Paris\", \"D\": \"Rome\"},\n            \"answer\": \"C\",\n            \"explanation\": \"Paris is the capital of France.\"\n        }\n    ]\n    assert transform_json_dict(input_data) == expected_output\n\ndef test_read_text_file():\n    with patch(\"builtins.open\", new_callable=MagicMock) as mock_open:\n        mock_open.return_value.__enter__.return_value.read.return_value = \"sample text\"\n        \n        # Adjust the expected path to match the absolute path construction in read_text_file\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        expected_path = os.path.join(script_dir, \"dummy_path.txt\")\n        \n        result = read_text_file(expected_path)\n        assert result == \"sample text\"\n        mock_open.assert_called_once_with(expected_path, 'r')\n\ndef test_quiz_builder_config_initialization(config):\n    assert config.max_questions == 10\n    assert config.min_questions == 1\n    assert config.max_attempts == 2\n    assert config.prompt_template_path == \"prompt/multiple_choice_quiz_generator_prompt.txt\"\n    assert config.multi_query_prompt_path == \"prompt/multi_query_prompt.txt\"\n    assert config.verbose == False\n    assert config.score_threshold == 0.4\n\ndef test_quiz_builder_initialization(config, quiz_builder):\n    assert quiz_builder.topic == \"Science\"\n    assert quiz_builder.lang == 'en'\n    assert quiz_builder.grade_level == \"High School\"\n    assert quiz_builder.n_questions == 5\n    assert quiz_builder.quiz_description == \"Sample quiz\"\n    assert quiz_builder.config == config\n    assert quiz_builder.verbose == False\n\ndef test_quiz_builder_custom_initialization(config):\n    user_input = {\n        \"topic\": \"Chemistry\",\n        \"n_questions\": 10,\n        \"grade_level\": \"High School\",\n        \"quiz_description\": \"Create a quiz on Chemistry\",\n        \"lang\": \"pt\",\n        \"config\": config\n    }\n    quiz_builder = QuizBuilder(**user_input)\n    for key, value in user_input.items():\n        assert getattr(quiz_builder, key) == value, \\\n        f\"Expected {key} to be {value}, but got {getattr(quiz_builder, key)}\"\n\ndef test_compile(quiz_builder):\n    documents = [Document(page_content=\"Sample content\")]\n    chain = quiz_builder.compile(documents)\n    assert chain is not None\n\ndef test_create_questions(quiz_builder):\n    documents = [Document(page_content=\"Sample content\")]\n    with patch.object(quiz_builder, 'compile', return_value=MagicMock()) as mock_compile:\n        with patch.object(quiz_builder, 'run_chain', return_value=[{\"question\": \"Sample question\", \"choices\": {\"A\": \"Option A\", \"B\": \"Option B\", \"C\": \"Option C\", \"D\": \"Option D\"}, \"answer\": \"A\", \"explanation\": \"Sample explanation\"}]):\n            questions = quiz_builder.create_questions(documents)\n            assert len(questions) == 1\n            assert questions[0][\"question\"] == \"Sample question\"\n\ndef test_validate_response(quiz_builder):\n    valid_response = {\n        \"question\": \"Sample question\",\n        \"choices\": {\"A\": \"Option A\", \"B\": \"Option B\", \"C\": \"Option C\", \"D\": \"Option D\"},\n        \"answer\": \"A\",\n        \"explanation\": \"Sample explanation\"\n    }\n    assert quiz_builder.validate_response(valid_response) == True\n\n    invalid_response = {\n        \"question\": \"Sample question\",\n        \"choices\": {\"A\": \"Option A\", \"B\": \"Option B\", \"C\": \"Option C\"},\n        \"answer\": \"A\",\n        \"explanation\": \"Sample explanation\"\n    }\n    assert quiz_builder.validate_response(invalid_response) == False\n\ndef test_format_choices(quiz_builder):\n    choices = {\"A\": \"Option A\", \"B\": \"Option B\", \"C\": \"Option C\", \"D\": \"Option D\"}\n    formatted_choices = quiz_builder.format_choices(choices)\n    assert formatted_choices == choices\n\ndef test_cleanup(quiz_builder):\n    with patch.object(quiz_builder.vectorstore_manager, 'cleanup') as mock_cleanup:\n        with patch.object(quiz_builder.retriever_factory, 'cleanup') as mock_retriever_cleanup:\n            quiz_builder.cleanup()\n            mock_cleanup.assert_called_once()\n            mock_retriever_cleanup.assert_called_once()\n            \ndef test_run_chain_max_attempts():\n    config = QuizBuilderConfig(max_attempts=3)\n    quiz_builder = QuizBuilderFactory.create_quiz_builder(config=config)\n    chain_mock = MagicMock()\n  \n    with patch.object(chain_mock, 'invoke', side_effect=Exception(\"Test Exception\")):\n        with pytest.raises(Exception, match=\"Test Exception\"):\n            quiz_builder.run_chain(chain_mock, {} )\n        assert chain_mock.invoke.call_count == config.max_attempts\n\ndef test_quiz_builder_config_default_initialization(config):\n    assert isinstance(config.model, GoogleGenerativeAI)\n    assert isinstance(config.embedding_model, GoogleGenerativeAIEmbeddings)\n    assert config.vectorstore_class == Chroma\n    assert config.max_questions == 10\n    assert config.min_questions == 1\n    assert config.max_attempts == 2\n    assert config.prompt_template_path == \"prompt/multiple_choice_quiz_generator_prompt.txt\"\n    assert config.multi_query_prompt_path == \"prompt/multi_query_prompt.txt\"\n    assert config.verbose == False\n    assert config.score_threshold == 0.4\n    assert config.prompt_template is not None\n    assert config.multi_query_prompt_template is not None\n    assert isinstance(config.parser, JsonOutputParser)\n\ndef test_quiz_builder_config_custom_initialization():\n    custom_model = MagicMock()\n    custom_embedding_model = MagicMock()\n    custom_vectorstore_class = MagicMock()\n    custom_parser = MagicMock()\n\n    config = QuizBuilderConfig(\n        model=custom_model,\n        embedding_model=custom_embedding_model,\n        vectorstore_class=custom_vectorstore_class,\n        max_questions=20,\n        min_questions=5,\n        max_attempts=3,\n        parser=custom_parser,\n        verbose=True,\n        score_threshold=0.5\n    )\n\n    assert config.model == custom_model\n    assert config.embedding_model == custom_embedding_model\n    assert config.vectorstore_class == custom_vectorstore_class\n    assert config.max_questions == 20\n    assert config.min_questions == 5\n    assert config.max_attempts == 3\n    assert config.verbose == True\n    assert config.score_threshold == 0.5\n    assert config.prompt_template is not None\n    assert config.multi_query_prompt_template is not None\n    assert config.parser == custom_parser\n\ndef test_create_multiquery_prompt(factory):\n    # Test prompt creation\n    prompt = factory.create_multiquery_prompt(num_questions=5)\n    assert isinstance(prompt, PromptTemplate)\n    assert \"num_questions\" in prompt.partial_variables\n\ndef test_create_base_retriever(factory):\n    # Mock vectorstore\n    mock_vectorstore = Mock()\n    mock_vectorstore.as_retriever.return_value = Mock()\n    \n    retriever = factory.create_base_retriever(\n        vectorstore=mock_vectorstore,\n        retriever_k=3,\n        score_threshold=0.5\n    )\n    \n    # Verify the retriever was created with correct params\n    mock_vectorstore.as_retriever.assert_called_once_with(\n        search_type=\"similarity_score_threshold\",\n        search_kwargs={\"k\": 3, \"score_threshold\": 0.5}\n    )\n\ndef test_get_optional_instructions(quiz_builder):\n\n    # Test cases\n    test_cases = [\n        {\n            \"input_name\": \"quiz_description\",\n            \"input_value\": \"This is a test quiz\",\n            \"expected\": \"- Assessment Description: This is a test quiz\"\n        },\n        {\n            \"input_name\": \"non_existent\",\n            \"input_value\": \"Some value\",\n            \"expected\": \"\"\n        },\n        {\n            \"input_name\": \"quiz_description\",\n            \"input_value\": \"description\",\n            \"expected\": \"- Assessment Description: description\"\n        }\n    ]\n    \n    # Act & Assert\n    for case in test_cases:\n        result = quiz_builder.get_optional_instructions(\n            case[\"input_name\"],\n            case[\"input_value\"]\n        )\n        assert result == case[\"expected\"], \\\n            f\"Failed for input_name={case['input_name']}, input_value={case['input_value']}\""}
{"type": "test_file", "path": "app/tools/presentation_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.presentation_generator.core import executor\n\n# Base attributes reused across all tests\nbase_attributes = {\n    \"grade_level\": \"5th grade\",\n    \"n_slides\": 10,\n    \"topic\": \"Mathematics\",\n    \"objectives\": \"\",\n    \"additional_comments\": \"\",\n    \"additional_comments_file_url\": \"https://docs.google.com/document/d/1IsTPJSgWMdD20tXMm1sXJSCc0xz9Kxmn/edit?usp=sharing&ouid=107052763106493355624&rtpof=true&sd=true\",\n    \"additional_comments_file_type\": \"gdoc\",\n    \"lang\": \"en\"\n}\n\n# PDF Tests\ndef test_executor_pdf_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        objectives_file_type=\"pdf\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_pdf_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# CSV Tests\ndef test_executor_csv_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        objectives_file_type=\"csv\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_csv_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# TXT Tests\ndef test_executor_txt_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        objectives_file_type=\"txt\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_txt_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MD Tests\ndef test_executor_md_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        objectives_file_type=\"md\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_md_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# PPTX Tests\ndef test_executor_pptx_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        objectives_file_type=\"pptx\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_pptx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# DOCX Tests\ndef test_executor_docx_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        objectives_file_type=\"docx\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_docx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLS Tests\ndef test_executor_xls_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        objectives_file_type=\"xls\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_xls_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLSX Tests\ndef test_executor_xlsx_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        objectives_file_type=\"xlsx\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_xlsx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GPDF Tests\ndef test_executor_gpdf_objectives_url_valid():\n    presentation = executor(\n        **base_attributes,\n        objectives_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        objectives_file_type=\"gpdf\"\n    )\n    assert isinstance(presentation, dict)\n\ndef test_executor_gpdf_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MP3 Tests\ndef test_executor_mp3_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)"}
{"type": "test_file", "path": "app/tools/presentation_generator_updated/outline_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/presentation_generator_updated/outline_generator/tests/test_core.py", "content": "import pytest\nfrom unittest.mock import MagicMock, patch\nfrom app.tools.presentation_generator_updated.outline_generator.core import executor\nfrom app.tools.presentation_generator_updated.outline_generator.tools import OutlineGenerator, Outlines\nfrom app.services.schemas import OutlineGeneratorInput\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\nfrom langchain_core.documents import Document\nfrom unittest.mock import Mock\n# Base test attributes\nbase_attributes = {\n    \"n_slides\": 2,\n    \"topic\": \"Introduction to Python Programming\",\n    \"instructional_level\": \"beginner\",\n    \"file_url\": \"\",\n    \"file_type\": \"\",\n    \"lang\": \"en\"\n}\n\n# Mock OutlineGeneratorInput\nmock_args = OutlineGeneratorInput(\n    n_slides=base_attributes[\"n_slides\"],\n    topic=base_attributes[\"topic\"],\n    instructional_level=base_attributes[\"instructional_level\"],\n    file_url=base_attributes[\"file_url\"],\n    file_type=base_attributes[\"file_type\"],\n    lang=base_attributes[\"lang\"]\n)\n@pytest.fixture\ndef mock_outline_data():\n    return {\n        \"outlines\": [\n            \"Introduction to Python Programming\",\n            \"Basic Syntax\"\n        ]\n    }\n@pytest.fixture\ndef mock_outline_generator():\n    with patch(\"app.tools.presentation_generator.slide_generator.tools.GoogleGenerativeAI\", autospec=True) as mock_model, \\\n         patch(\"app.tools.presentation_generator.slide_generator.tools.GoogleGenerativeAIEmbeddings\", autospec=True) as mock_embeddings, \\\n         patch(\"app.tools.presentation_generator.slide_generator.tools.JsonOutputParser\", autospec=True) as mock_parser, \\\n         patch(\"app.tools.presentation_generator.slide_generator.tools.Chroma\", autospec=True) as mock_chroma:\n        # Create mock objects for the dependencies\n        mock_model_instance = mock_model.return_value\n        mock_embeddings_instance = mock_embeddings.return_value\n        mock_parser_instance = mock_parser.return_value\n        mock_chroma_instance = mock_chroma.return_value\n\n        # Create a mock SlideGenerator instance\n        outline_generator = OutlineGenerator()\n\n        # Override attributes with mocks\n        outline_generator.model = mock_model_instance\n        outline_generator.embedding_model = mock_embeddings_instance\n        outline_generator.parser = mock_parser_instance\n        outline_generator.vectorstore_class = mock_chroma_instance\n        yield outline_generator\n\n# Test OutlineGenerator class initialization\ndef test_outline_generator_init():\n    \"\"\"Test initialization of OutlineGenerator.\"\"\"\n    generator = OutlineGenerator(args=mock_args, verbose=False)\n    assert generator.args is not None\n    assert generator.verbose is False\n    assert generator.vectorstore is None\n    assert generator.retriever is None\n    assert generator.runner is None\n\n# Test the executor function (integration test)\ndef test_executor_normal_operation(mock_outline_data):\n    \"\"\"Test the executor function with valid inputs.\"\"\"\n\n    # Set up mock returns\n    mock_outline_generator = MagicMock()\n    mock_outline_generator.generate_outline.return_value = mock_outline_data\n    # Patch OutlineGenerator to return the mock instance\n    with patch(\"app.tools.presentation_generator.outline_generator.core.OutlineGenerator\", return_value=mock_outline_generator):\n        result = executor(\n            n_slides=base_attributes[\"n_slides\"],\n            topic=base_attributes[\"topic\"],\n            instructional_level=base_attributes[\"instructional_level\"],\n            file_url=base_attributes[\"file_url\"],\n            file_type=base_attributes[\"file_type\"],\n            lang=base_attributes[\"lang\"],\n            verbose=False\n        )\n  \n    # Check if the result is a dictionary instead of an Outlines instance\n    assert result == mock_outline_data\n    # Ensure the function was called once\n    mock_outline_generator.generate_outline.assert_called_once()\n\n    # Validate the structure of the dictionary\n    assert \"outlines\" in result, \"Key 'outlines' not found in response\"\n    assert isinstance(result[\"outlines\"], list), \"Expected 'outlines' to be a list\"\n    \n\ndef test_executor_missing_required_inputs():\n    \"\"\"Test the executor function with missing required inputs.\"\"\"\n    with pytest.raises(ValueError):\n        result =  executor(\n                n_slides=None,\n                topic=None,\n                instructional_level=base_attributes[\"instructional_level\"],\n                file_url=base_attributes[\"file_url\"],\n                file_type=base_attributes[\"file_type\"],\n                lang=base_attributes[\"lang\"],\n                verbose=False\n            )\n# Test OutlineGenerator with invalid arguments\ndef test_outline_generator_init_missing_params():\n    \"\"\"Test initialization of OutlineGenerator with missing parameters.\"\"\"\n\n    with pytest.raises(ValueError, match=\"Topic must be provided\"):\n        OutlineGenerator(args=Mock(topic=None, lang=\"en\"))\n    \n    with pytest.raises(ValueError, match=\"Language must be provided\"):\n        OutlineGenerator(args=Mock(topic=\"Test\", lang=None))\n\n\ndef test_outline_generator_compile_without_context(mock_outline_generator):\n    \"\"\"Test compilation of pipeline without context.\"\"\"\n    args = OutlineGeneratorInput(\n        n_slides=3,\n        topic=\"Machine Learning\",\n        instructional_level=\"Advanced\",\n        file_url=\"\",\n        file_type=\"\",\n        lang=\"en\"\n    )\n    \n    generator = OutlineGenerator(args=args)\n    chain = generator.compile_without_context()\n    \n    assert chain is not None\n\ndef test_outlines_model():\n    \"\"\"Test the Outlines Pydantic model.\"\"\"\n    outlines = Outlines(\n        outlines=[\n            \"Introduction to Cybersecurity\",\n            \"Types of Cyber Threats\",\n            \"Basic Security Practices\"\n        ]\n    )    \n    assert len(outlines.outlines) == 3\n    assert all(isinstance(outline, str) for outline in outlines.outlines)"}
{"type": "test_file", "path": "app/tools/rubric_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/writing_feedback_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.writing_feedback_generator.core import executor\nfrom app.tools.writing_feedback_generator.tools import WritingFeedback\n\n# Base attributes reused across all tests\nbase_attributes = {\n    \"grade_level\": \"university\",\n    \"assignment_description\": \"Review and provide feedback on the assigned text.\",\n    \"criteria\": \"\",\n    \"writing_to_review\": \"\",\n    \"criteria_file_url\": \"https://docs.google.com/document/d/1IsTPJSgWMdD20tXMm1sXJSCc0xz9Kxmn/edit?usp=sharing&ouid=107052763106493355624&rtpof=true&sd=true\",\n    \"criteria_file_type\": \"gdoc\",\n    \"lang\": \"en\"\n}\n\n# PDF Tests\ndef test_executor_pdf_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        writing_to_review_file_type=\"pdf\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_pdf_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# CSV Tests\ndef test_executor_csv_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        writing_to_review_file_type=\"csv\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_csv_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# TXT Tests\ndef test_executor_txt_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        writing_to_review_file_type=\"txt\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_txt_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MD Tests\ndef test_executor_md_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        writing_to_review_file_type=\"md\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_md_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# PPTX Tests\ndef test_executor_pptx_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        writing_to_review_file_type=\"pptx\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_pptx_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# DOCX Tests\ndef test_executor_docx_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        writing_to_review_file_type=\"docx\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_docx_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLS Tests\ndef test_executor_xls_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        writing_to_review_file_type=\"xls\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_xls_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLSX Tests\ndef test_executor_xlsx_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        writing_to_review_file_type=\"xlsx\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_xlsx_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GPDF Tests\ndef test_executor_gpdf_wtr_url_valid():\n    writing_feedback = executor(\n        **base_attributes,\n        writing_to_review_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        writing_to_review_file_type=\"gpdf\"\n    )\n    assert isinstance(writing_feedback, WritingFeedback)\n\ndef test_executor_gpdf_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MP3 Tests\ndef test_executor_mp3_wtr_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            writing_to_review_file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            writing_to_review_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n"}
{"type": "test_file", "path": "app/tools/syllabus_generator/tests/test_core.py", "content": "import pytest\nfrom app.api.error_utilities import SyllabusGeneratorError\nfrom app.tools.syllabus_generator.core import executor\n\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv())\n\n# Base attributes reused across all tests\nbase_attributes = {\n    \"grade_level\": \"5th grade\",\n    \"subject\": \"Math\",\n    \"course_description\": \"This course covers basic arithmetic operations.\",\n    \"objectives\": \"Understand addition, subtraction, multiplication, and division.\",\n    \"required_materials\": \"Notebook, pencils, calculator.\",\n    \"grading_policy\": \"Homework 40%, Exams 60%.\",\n    \"policies_expectations\": \"Complete assignments on time, participate in class.\",\n    \"course_outline\": \"Week 1: Addition; Week 2: Subtraction; Week 3: Multiplication.\",\n    \"additional_notes\": \"Bring a calculator every day.\",\n    \"lang\": \"en\"\n}\n\n# PDF Tests\ndef test_executor_pdf_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        file_type=\"pdf\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_pdf_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# CSV Tests\ndef test_executor_csv_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        file_type=\"csv\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_csv_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# TXT Tests\ndef test_executor_txt_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        file_type=\"txt\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_txt_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# MD Tests\ndef test_executor_md_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        file_type=\"md\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_md_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# PPTX Tests\ndef test_executor_pptx_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        file_type=\"pptx\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_pptx_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# DOCX Tests\ndef test_executor_docx_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        file_type=\"docx\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_docx_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# XLS Tests\ndef test_executor_xls_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        file_type=\"xls\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_xls_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# XLSX Tests\ndef test_executor_xlsx_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        file_type=\"xlsx\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_xlsx_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# XML Tests\ndef test_executor_xml_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesampleshub.com/download/code/xml/dummy.xml\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# GDocs Tests\ndef test_executor_gdocs_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1Ct/edit\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# GSheets Tests\ndef test_executor_gsheets_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# GSlides Tests\ndef test_executor_gslides_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# GPDFs Tests\ndef test_executor_gpdfs_url_valid():\n    syllabus = executor(\n        **base_attributes,\n        file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        file_type=\"gpdf\"\n    )\n    assert isinstance(syllabus, dict)\n\ndef test_executor_gpdfs_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)\n\n# MP3 Tests\ndef test_executor_mp3_url_invalid():\n    with pytest.raises(SyllabusGeneratorError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, SyllabusGeneratorError)"}
{"type": "test_file", "path": "app/tools/rubric_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.rubric_generator.core import executor\n\n# Base attributes reused across all tests\nbase_attributes = {\n    \"grade_level\": \"university\",\n    \"point_scale\": 4,\n    \"objectives\": \"\",\n    \"assignment_description\": \"\",\n    \"assignment_description_file_url\": \"https://docs.google.com/document/d/1IsTPJSgWMdD20tXMm1sXJSCc0xz9Kxmn/edit?usp=sharing&ouid=107052763106493355624&rtpof=true&sd=true\",\n    \"assignment_description_file_type\": \"gdoc\",\n    \"lang\": \"en\"\n}\n\n# PDF Tests\ndef test_executor_pdf_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        objectives_file_type=\"pdf\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_pdf_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# CSV Tests\ndef test_executor_csv_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        objectives_file_type=\"csv\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_csv_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# TXT Tests\ndef test_executor_txt_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        objectives_file_type=\"txt\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_txt_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MD Tests\ndef test_executor_md_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        objectives_file_type=\"md\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_md_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# PPTX Tests\ndef test_executor_pptx_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        objectives_file_type=\"pptx\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_pptx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# DOCX Tests\ndef test_executor_docx_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        objectives_file_type=\"docx\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_docx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLS Tests\ndef test_executor_xls_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        objectives_file_type=\"xls\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_xls_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLSX Tests\ndef test_executor_xlsx_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        objectives_file_type=\"xlsx\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_xlsx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GPDF Tests\ndef test_executor_gpdf_objectives_url_valid():\n    rubric = executor(\n        **base_attributes,\n        objectives_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        objectives_file_type=\"gpdf\"\n    )\n    assert isinstance(rubric, dict)\n\ndef test_executor_gpdf_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MP3 Tests\ndef test_executor_mp3_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)"}
{"type": "test_file", "path": "app/utils/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/ai_resistant_assignment_generator/tests/test_core.py", "content": "import pytest\n\nfrom app.tools.ai_resistant_assignment_generator.core import executor\n\n# Base attributes reused across all tests\nbase_attributes = {\n    \"assignment\": \"Math Homework\",\n    \"grade_level\": \"university\",\n    \"lang\": \"en\"\n}\n\n# PDF Tests\ndef test_executor_pdf_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        file_type=\"pdf\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_pdf_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# CSV Tests\ndef test_executor_csv_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        file_type=\"csv\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_csv_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# TXT Tests\ndef test_executor_txt_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        file_type=\"txt\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_txt_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MD Tests\ndef test_executor_md_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        file_type=\"md\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_md_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# PPTX Tests\ndef test_executor_pptx_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        file_type=\"pptx\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_pptx_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# DOCX Tests\ndef test_executor_docx_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        file_type=\"docx\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_docx_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLS Tests\ndef test_executor_xls_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        file_type=\"xls\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_xls_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLSX Tests\ndef test_executor_xlsx_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        file_type=\"xlsx\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_xlsx_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XML Tests\ndef test_executor_xml_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://filesampleshub.com/download/code/xml/dummy.xml\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GDocs Tests\ndef test_executor_gdocs_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1Ct/edit\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GSheets Tests\ndef test_executor_gsheets_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GSlides Tests\ndef test_executor_gslides_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GPDFs Tests\ndef test_executor_gpdfs_url_valid():\n    ai_resistant_assignment = executor(\n        **base_attributes,\n        file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        file_type=\"gpdf\"\n    )\n    assert isinstance(ai_resistant_assignment, dict)\n\ndef test_executor_gpdfs_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MP3 Tests\ndef test_executor_mp3_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n"}
{"type": "test_file", "path": "app/tools/presentation_generator_updated/slide_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.presentation_generator_updated.slide_generator.core import executor,SlideGeneratorInput\nfrom unittest.mock import patch, MagicMock, Mock\nfrom app.tools.presentation_generator_updated.slide_generator.tools import SlideGenerator, Slide,SlidePresentation\n\n@pytest.fixture\ndef mock_slide_data():\n    return {\n        \"slides\": [\n            {\n                \"title\": \"Introduction to Python\",\n                \"template\": \"titleAndBullets\",\n                \"content\": [\"Python is a programming language\"]\n            },\n            {\n                \"title\": \"Basic Syntax\",\n                \"template\": \"titleBody\",\n                \"content\": \"Python syntax is simple\"\n            }\n        ]\n    }\n@pytest.fixture\ndef mock_args():\n    return SlideGeneratorInput(\n        slides_titles=[\"Intro\", \"Details\"],\n        topic=\"Data Science\",\n        instructional_level=\"Intermediate\",\n        lang=\"en\"\n    )\n\n\n@pytest.fixture\ndef mock_slide_generator():\n    \"\"\"Mock SlideGenerator instead of instantiating it.\"\"\"\n    with patch(\"app.tools.presentation_generator.slide_generator.tools.GoogleGenerativeAI\"), \\\n         patch(\"app.tools.presentation_generator.slide_generator.tools.GoogleGenerativeAIEmbeddings\"), \\\n         patch(\"app.tools.presentation_generator.slide_generator.tools.Chroma\"):\n            slide_generator = SlideGenerator()\n            slide_generator.validate_slides_content = MagicMock()\n            slide_generator.generate_slides = MagicMock()\n            return slide_generator\n#Test the executor function, we mock the generate_slides method.\ndef test_executor(mock_slide_data,mock_slide_generator):\n    slides_titles = [\"Introduction to Python\", \"Basic Syntax\"]\n    topic = \"Python Programming\"\n    instructional_level = \"Beginner\"\n    lang = \"en\"\n    verbose = False\n    # Create a mock instance of SlideGenerator\n    mock_slide_generator.generate_slides.return_value = mock_slide_data\n\n    # Patch SlideGenerator to return the mock instance\n    with patch(\"app.tools.presentation_generator.slide_generator.core.SlideGenerator\", return_value=mock_slide_generator):\n        result = executor(slides_titles, topic, instructional_level, lang, verbose)\n    # Assertions\n    assert result == mock_slide_data\n    mock_slide_generator.generate_slides.assert_called_once() \n   # Ensure the function was called once\n\n#Test the executor function with missing required inputs.\ndef test_executor_missing_inputs():\n    \"\"\"Test the executor function with missing required inputs.\"\"\"\n    with pytest.raises(ValueError, match=\"Missing required inputs\"):\n        executor(\n            slides_titles=[],\n            topic=\"\",\n            instructional_level=\"\",\n            lang=\"en\"\n        )\n\n#Test the executor function with a LoaderError.\n@patch(\"app.tools.presentation_generator.slide_generator.tools.SlideGenerator.generate_slides\")\n@patch(\"google.auth.default\")\ndef test_executor_loader_error(mock_auth,mock_generate_slides):\n    mock_auth.return_value=(MagicMock(),\"fake-project-id\")\n    from app.api.error_utilities import LoaderError\n    mock_generate_slides.side_effect = LoaderError(\"Error in Slide Generator Pipeline\")\n    with pytest.raises(Exception) as exc_info:\n        executor(slides_titles=[\"Intro\"], topic=\"AI\", instructional_level=\"Intermediate\", lang=\"en\")\n    assert \"Error in Slide Generator Pipeline\" in str(exc_info.value)\n\n#Test the executor function with an unexpected error.\n@patch(\"app.tools.presentation_generator.slide_generator.tools.SlideGenerator.generate_slides\")\n@patch(\"google.auth.default\")\ndef test_executor_unexpected_error(mock_auth,mock_generate_slides):\n    mock_auth.return_value=(MagicMock(),\"fake-project-id\")\n    mock_generate_slides.side_effect = Exception(\"Unexpected error occurred\")\n    with pytest.raises(ValueError, match=\"Error in executor: Unexpected error occurred\"):\n        executor(slides_titles=[\"Intro\"], topic=\"AI\", instructional_level=\"Intermediate\", lang=\"en\")\n\n#Test the validate_slides_content function.\ndef test_validate_slides_content(mock_slide_generator):\n    # Define fake return value\n    mock_slide_generator.validate_slides_content.return_value = {\n        \"topic_coverage\": 80,\n        \"template_requirements_met\": True,\n        \"garbage_coverage_percentage\": 0,\n        \"valid\": True\n    }\n    topic = \"AI in Education\"\n    response = {\"slides\": [{\"template\": \"twoColumn\", \"content\": [\"AI and learning\"]}]}\n    result = mock_slide_generator.validate_slides_content(response, topic)\n\n    assert result[\"valid\"] == True\n    assert result[\"topic_coverage\"] == 80\n    \n    \n\n#Test the validate_slides_content function with garbage content.\ndef test_validate_slides_content_with_garbage(mock_slide_generator):\n    topic = \"Introduction\"\n    response = {\n        \"slides\": [\n            {\n                \"title\": \"Introduction\",\n                \"template\": \"sectionHeader\",  # Not \"twoColumn\"\n                \"content\": [\"Unrelated content\", \"* This should not be here\"]\n            }\n        ]\n    }\n    # Mock the return value for an invalid response\n    mock_slide_generator.validate_slides_content.return_value = {\n        \"topic_coverage\": 20,\n        \"template_requirements_met\": False,\n        \"garbage_coverage_percentage\": 50,\n        \"valid\": False\n    }\n    result = mock_slide_generator.validate_slides_content(response, topic)\n\n    assert result[\"valid\"] == False\n    assert result[\"topic_coverage\"] == 20\n    assert result[\"template_requirements_met\"] == False\n    assert result[\"garbage_coverage_percentage\"] == 50\n\n\n#Test the validate_slides_content function with empty slides.\ndef test_validate_slides_content_empty_slides(mock_slide_generator):\n    topic = \"Introduction\"\n    response = {\"slides\": []}  # No slides\n\n    # Mock the method to raise ValueError when slides are empty\n    mock_slide_generator.validate_slides_content.side_effect = ValueError(\"No slides found in the response\")\n\n    with pytest.raises(ValueError, match=\"No slides found in the response\"):\n        mock_slide_generator.validate_slides_content(response, topic)\n\n#Test the compile_with_context function.\ndef test_slide_generator_compile_context(mock_args,mock_slide_generator):\n    \"\"\"Test compilation of pipeline.\"\"\"\n    args = mock_args\n    test_instance = mock_slide_generator\n    test_instance.args = args    \n    chain = test_instance.compile_context()    \n    assert chain is not None\n\n\n#Test the Slide Pydantic model.\ndef test_slide_model():\n    \"\"\"Test the Slide Pydantic model.\"\"\"\n    slide = Slide(\n        title=\"Introduction\",\n        template=\"titleAndBullets\",\n        content=[\"Key Point 1\", \"Key Point 2\"]\n    )\n    \n    assert slide.title == \"Introduction\"\n    assert slide.template == \"titleAndBullets\"\n    assert slide.content == [\"Key Point 1\", \"Key Point 2\"]\n    \n#Test the SlidePresentation Pydantic model.\ndef test_slide_presentation_model():\n    \"\"\"Test the SlidePresentation Pydantic model.\"\"\"\n    slides = [\n        Slide(title=\"Intro\", template=\"titleAndBody\", content=\"Overview\"),\n        Slide(title=\"Details\", template=\"twoColumn\", content={\"left\": \"Content1\", \"right\": \"Content2\"})\n    ]\n    \n    presentation = SlidePresentation(slides=slides)\n    \n    assert len(presentation.slides) == 2\n    assert all(isinstance(slide, Slide) for slide in presentation.slides)\n"}
{"type": "test_file", "path": "app/utils/tests/test_loaders.py", "content": "import pytest\nimport requests\nfrom app.api.error_utilities import FileHandlerError\nfrom unittest.mock import patch\nfrom app.utils.document_loaders import *\n\ndef simulate_http_error(status_code):\n    mock_response = requests.Response()\n    mock_response.status_code = status_code\n    return mock_response\n\ndef test_load_pdf_documents_valid():\n    pdf_url = \"https://filesamples.com/samples/document/pdf/sample1.pdf\"\n    full_content = load_pdf_documents(pdf_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_pdf_documents_invalid():\n    dummy_pdf_url = \"https://filesamples.com/samples/document/pdf/dummy.pdf\"\n    with patch(\"requests.get\") as mock_get:\n        mock_get.return_value = simulate_http_error(404)\n\n        with pytest.raises(FileHandlerError) as exc_info:\n            load_pdf_documents(dummy_pdf_url)\n\n        assert \"Failed to download file from URL\" in str(exc_info.value)\n\ndef test_load_pdf_documents_invalid_file_type():\n    not_pdf_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_pdf_documents(not_pdf_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_csv_documents_valid():\n    csv_url = \"https://filesamples.com/samples/document/csv/sample1.csv\"\n    full_content = load_csv_documents(csv_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_csv_documents_invalid():\n    dummy_csv_url = \"https://filesamples.com/samples/document/csv/dummy.csv\"\n    with patch(\"requests.get\") as mock_get:\n        mock_get.return_value = simulate_http_error(404)\n\n        with pytest.raises(FileHandlerError) as exc_info:\n            load_csv_documents(dummy_csv_url)\n\n        assert \"Failed to download file from URL\" in str(exc_info.value)\n\ndef test_load_csv_documents_invalid_file_type():\n    not_csv_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_csv_documents(not_csv_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_txt_documents_valid():\n    txt_url = \"https://filesamples.com/samples/document/txt/sample1.txt\"\n    full_content = load_txt_documents(txt_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_txt_documents_invalid():\n    dummy_txt_url = \"https://filesamples.com/samples/document/txt/dummy.txt\"\n    with patch(\"requests.get\") as mock_get:\n        mock_get.return_value = simulate_http_error(404)\n\n        with pytest.raises(FileHandlerError) as exc_info:\n            load_txt_documents(dummy_txt_url)\n\n        assert \"Failed to download file from URL\" in str(exc_info.value)\n\ndef test_load_txt_documents_invalid_file_type():\n    not_txt_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_txt_documents(not_txt_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_md_documents_valid():\n    md_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\"\n    full_content = load_md_documents(md_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_md_documents_invalid():\n    dummy_md_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/dummy.md\"\n    with patch(\"requests.get\") as mock_get:\n        mock_get.return_value = simulate_http_error(404)\n\n        with pytest.raises(FileHandlerError) as exc_info:\n            load_md_documents(dummy_md_url)\n\n        assert \"Failed to download file from URL\" in str(exc_info.value)\n\ndef test_load_md_documents_invalid_file_type():\n    not_md_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_md_documents(not_md_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_url_documents_valid():\n    valid_url = \"https://en.wikipedia.org/wiki/Gemini_(language_model)\"\n    full_content = load_url_documents(valid_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_pptx_documents_valid():\n    pptx_url = \"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\"\n    full_content = load_pptx_documents(pptx_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_pptx_documents_invalid():\n    dummy_pptx_url = \"https://scholar.harvard.edu/files/torman_personal/files/dummy.pptx\"\n    with patch(\"requests.get\") as mock_get:\n        mock_get.return_value = simulate_http_error(404)\n\n        with pytest.raises(FileHandlerError) as exc_info:\n            load_pptx_documents(dummy_pptx_url)\n\n        assert \"Failed to download file from URL\" in str(exc_info.value)\n\ndef test_load_pptx_documents_invalid_file_type():\n    not_pptx_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_md_documents(not_pptx_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_docx_documents_valid():\n    docx_url = \"https://filesamples.com/samples/document/docx/sample1.docx\"\n    full_content = load_docx_documents(docx_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_docx_documents_invalid():\n    dummy_docx_url = \"https://filesamples.com/samples/document/docx/dummy.docx\"\n    with patch(\"requests.get\") as mock_get:\n        mock_get.return_value = simulate_http_error(404)\n\n        with pytest.raises(FileHandlerError) as exc_info:\n            load_docx_documents(dummy_docx_url)\n\n        assert \"Failed to download file from URL\" in str(exc_info.value)\n\ndef test_load_docx_documents_invalid_file_type():\n    not_docx_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_docx_documents(not_docx_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_xls_documents_valid():\n    xls_url = \"https://filesamples.com/samples/document/xls/sample1.xls\"\n    full_content = load_xls_documents(xls_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_xls_documents_invalid():\n    dummy_xls_url = \"https://filesamples.com/samples/document/xls/dummy.xls\"\n    with patch(\"requests.get\") as mock_get:\n        mock_get.return_value = simulate_http_error(404)\n\n        with pytest.raises(FileHandlerError) as exc_info:\n            load_xls_documents(dummy_xls_url)\n\n        assert \"Failed to download file from URL\" in str(exc_info.value)\n\ndef test_load_xls_documents_invalid_file_type():\n    not_xls_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_xls_documents(not_xls_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_xlsx_documents_valid():\n    xlsx_url = \"https://filesamples.com/samples/document/xlsx/sample1.xlsx\"\n    full_content = load_xlsx_documents(xlsx_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_xlsx_documents_invalid():\n    dummy_xlsx_url = \"https://filesamples.com/samples/document/xlsx/dummy.xlsx\"\n    with patch(\"requests.get\") as mock_get:\n        mock_get.return_value = simulate_http_error(404)\n\n        with pytest.raises(FileHandlerError) as exc_info:\n            load_xlsx_documents(dummy_xlsx_url)\n\n        assert \"Failed to download file from URL\" in str(exc_info.value)\n\ndef test_load_xlsx_documents_invalid_file_type():\n    not_xlsx_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_xlsx_documents(not_xlsx_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_xml_documents_valid():\n    xml_url = \"https://raw.githubusercontent.com/AaronSosaRamos/mission-flights/main/files-for-test/sample.xml\"\n    full_content = load_xml_documents(xml_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_xml_documents_invalid_file_type():\n    not_xml_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_xml_documents(not_xml_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gdocs_documents_valid():\n    gdocs_url = \"https://docs.google.com/document/d/1DkOTKlHnZC6Us2N-ZHgECsQezYoB49af/edit?usp=drive_link&ouid=107052763106493355624&rtpof=true&sd=true\"\n    full_content = load_gdocs_documents(gdocs_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_gdocs_documents_invalid_permission():\n    private_gdocs_url = \"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1CCJBhJgkYLXM5IY/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gdocs_documents(private_gdocs_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gdocs_documents_invalid_url():\n    dummy_gdocs_url = \"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1Ct/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gdocs_documents(dummy_gdocs_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gdocs_documents_invalid_file_type():\n    not_gdocs_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gdocs_documents(not_gdocs_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gsheets_documents_valid():\n    gsheets_url = \"https://docs.google.com/spreadsheets/d/15Wvok1cjrTJGQQyokVKPsJ2jW2mbiuAJ/edit?usp=drive_link&ouid=107052763106493355624&rtpof=true&sd=true\"\n    full_content = load_gsheets_documents(gsheets_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_gsheets_documents_invalid_permission():\n    private_gsheets_url = \"https://docs.google.com/spreadsheets/d/16OPtLLSfUptnCNpXBXqPP7GpbNTlHTBRO_bWgmH_RvU/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gsheets_documents(private_gsheets_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gsheets_documents_invalid_url():\n    dummy_gsheets_url = \"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gsheets_documents(dummy_gsheets_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gsheets_documents_invalid_file_type():\n    not_gsheets_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gsheets_documents(not_gsheets_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gslides_documents_valid():\n    gslides_url = \"https://docs.google.com/presentation/d/1m99qIFwnGXIoxCJNCmIbecIvnoP3ecbT/edit?usp=drive_link&ouid=107052763106493355624&rtpof=true&sd=true\"\n    full_content = load_gslides_documents(gslides_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_gslides_documents_invalid_permission():\n    private_gslides_url = \"https://docs.google.com/presentation/d/1GeIRGJF63vyPMCeyqonluj4-8ZF0NF683LEn4J3UnhI/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gslides_documents(private_gslides_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gslides_documents_invalid_url():\n    dummy_gslides_url = \"https://docs.google.com/presentation/d/1GeIRGJF63v683LEn4J3UnhI/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gslides_documents(dummy_gslides_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gslides_documents_invalid_file_type():\n    not_gslides_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gslides_documents(not_gslides_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gpdf_documents_valid():\n    gpdf_url = \"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\"\n    full_content = load_gpdf_documents(gpdf_url)\n    assert isinstance(full_content, list)\n    assert len(full_content) > 0\n\ndef test_load_gpdf_documents_invalid_permission():\n    private_gpdf_url = \"https://drive.google.com/file/d/1gBeAzJKTaZFwEbub8wkXr1MM-TXtw5F3/view\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gpdf_documents(private_gpdf_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gpdf_documents_invalid_url():\n    dummy_gpdf_url = \"https://drive.google.com/file/d/1gBeAzJKTaZFwEbub8wkXrF3/view?usp=sharing\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gpdf_documents(dummy_gpdf_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gpdf_documents_invalid_file_type():\n    not_gpdf_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gpdf_documents(not_gpdf_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)"}
{"type": "test_file", "path": "app/tools/connect_with_them/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/connect_with_them/tests/test_core.py", "content": "import pytest\nfrom app.tools.connect_with_them.core import executor\n\n# Base attributes reused across all tests\nbase_attributes = {\n    \"grade_level\": \"5th grade\",\n    \"task_description\": \"\",\n    \"students_description\": \"\",\n    \"student_description_file_url\": \"https://docs.google.com/document/d/1IsTPJSgWMdD20tXMm1sXJSCc0xz9Kxmn/edit?usp=sharing&ouid=107052763106493355624&rtpof=true&sd=true\",\n    \"student_description_file_type\": \"gdoc\",\n    \"lang\": \"en\"\n}\n\n# PDF Tests\ndef test_executor_pdf_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        task_description_file_type=\"pdf\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_pdf_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# CSV Tests\ndef test_executor_csv_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        task_description_file_type=\"csv\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_csv_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# TXT Tests\ndef test_executor_txt_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        task_description_file_type=\"txt\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_txt_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MD Tests\ndef test_executor_md_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        task_description_file_type=\"md\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_md_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# PPTX Tests\ndef test_executor_pptx_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        task_description_file_type=\"pptx\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_pptx_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# DOCX Tests\ndef test_executor_docx_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        task_description_file_type=\"docx\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_docx_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLS Tests\ndef test_executor_xls_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        task_description_file_type=\"xls\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_xls_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLSX Tests\ndef test_executor_xlsx_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        task_description_file_type=\"xlsx\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_xlsx_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GPDF Tests\ndef test_executor_gpdf_td_url_valid():\n    connect_with_them = executor(\n        **base_attributes,\n        task_description_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        task_description_file_type=\"gpdf\"\n    )\n    assert isinstance(connect_with_them, dict)\n\ndef test_executor_gpdf_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MP3 Tests\ndef test_executor_mp3_td_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            task_description_file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            task_description_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n"}
{"type": "test_file", "path": "app/tools/lesson_plan_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.lesson_plan_generator.core import executor\nfrom app.tools.lesson_plan_generator.tools import LessonPlan\n\n# Base attributes reused across all tests\nbase_attributes = {\n    \"grade_level\": \"university\",\n    \"topic\": \"Linear Algebra\",\n    \"objectives\": \"\",\n    \"additional_customization\": \"\",\n    \"additional_customization_file_url\": \"https://docs.google.com/document/d/1IsTPJSgWMdD20tXMm1sXJSCc0xz9Kxmn/edit?usp=sharing&ouid=107052763106493355624&rtpof=true&sd=true\",\n    \"additional_customization_file_type\": \"gdoc\",\n    \"lang\": \"en\"\n}\n\n# PDF Tests\ndef test_executor_pdf_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        objectives_file_type=\"pdf\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_pdf_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n    \n# CSV Tests\ndef test_executor_csv_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        objectives_file_type=\"csv\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_csv_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# TXT Tests\ndef test_executor_txt_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        objectives_file_type=\"txt\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_txt_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MD Tests\ndef test_executor_md_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        objectives_file_type=\"md\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_md_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# PPTX Tests\ndef test_executor_pptx_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        objectives_file_type=\"pptx\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_pptx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# DOCX Tests\ndef test_executor_docx_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        objectives_file_type=\"docx\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_docx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLS Tests\ndef test_executor_xls_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        objectives_file_type=\"xls\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_xls_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLSX Tests\ndef test_executor_xlsx_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        objectives_file_type=\"xlsx\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_xlsx_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# GPDF Tests\ndef test_executor_gpdf_objectives_url_valid():\n    lesson_plan = executor(\n        **base_attributes,\n        objectives_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        objectives_file_type=\"gpdf\"\n    )\n    assert isinstance(lesson_plan, dict)\n\ndef test_executor_gpdf_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MP3 Tests\ndef test_executor_mp3_objectives_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            **base_attributes,\n            objectives_file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            objectives_file_type=1\n        )\n    assert isinstance(exc_info.value, ValueError)\n"}
{"type": "test_file", "path": "app/tools/notes_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.notes_generator.core import executor\nfrom app.tools.notes_generator.tools import GenerateNotesOutput\nfrom app.tools.notes_generator.tools import NoteGeneratorPipeline\nfrom app.tools.notes_generator.tools import Document\nfrom app.tools.notes_generator.core import NoteGeneratorArgs\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom app.tools.notes_generator.tools import BulletPoints\n\n \nbase_attributes = {\n    \"focus\": \"Summarize the key steps of photosynthesis.\",\n    \"page_layout\": \"bullet points\",\n    \"text_input\": \"Photosynthesis is a process used by plants to convert sunlight into energy.\",\n    \"file_type\": \"pdf\",\n    \"file_url\": \"https://firebasestorage.googleapis.com/v0/b/kai-ai-f63c8.appspot.com/o/uploads%2F510f946e-823f-42d7-b95d-d16925293946-Linear%20Regression%20Stat%20Yale.pdf?alt=media&token=caea86aa-c06b-4cde-9fd0-42962eb72ddd\",\n    \"lang\": \"en\"\n    \n}\nmock_args = NoteGeneratorArgs(\n        focus = base_attributes[\"focus\"],\n        page_layout = base_attributes[\"page_layout\"],\n        text_input = base_attributes[\"text_input\"],\n        file_type = base_attributes[\"file_type\"],\n        file_url = base_attributes[\"file_url\"],\n        lang = base_attributes[\"lang\"]\n    )\nmock_parser = JsonOutputParser(pydantic_object=BulletPoints)\n\n\n#Test the executor function (Integration test)\ndef test_executor_normal_operation():\n    \"\"\"Test the executor function with valid inputs.\"\"\"\n    result = executor(\n        focus=base_attributes[\"focus\"],\n        page_layout=base_attributes[\"page_layout\"],\n        text_input=base_attributes[\"text_input\"],\n        file_type=base_attributes[\"file_type\"],\n        file_url=base_attributes[\"file_url\"],\n        lang=base_attributes[\"lang\"],\n        verbose=False        \n    )\n    \n    assert isinstance(result, BulletPoints)\n    assert hasattr(result, \"title\")\n    assert hasattr(result, \"notes\")\n\n\n \n# def test_executor_no_page_layout():\n#     \"\"\"Test the executor function with no page layout provided.\"\"\"\n#     with pytest.raises(ValueError, match=\"No page layout provided for note generation.\"):\n#         executor(\n#             focus=base_attributes[\"focus\"],\n#             page_layout=\"\",\n#             text_input=base_attributes[\"text_input\"],\n#             file_type=base_attributes[\"file_type\"],\n#             file_url=base_attributes[\"file_url\"],\n#             lang=base_attributes[\"lang\"],\n#             verbose=False            \n#         )\n\ndef test_executor_no_input():\n    \"\"\"Test the executor function with no input provided.\"\"\"\n    with pytest.raises(ValueError, match=\"No input provided for note generation.\"):\n        executor(\n            focus=\"\",\n            page_layout=base_attributes[\"page_layout\"],\n            text_input=\"\",\n            file_type=\"\",\n            file_url=\"\",\n            lang=base_attributes[\"lang\"],\n            verbose=False\n        )\ndef test_executor_no_filetype__error():\n    \"\"\"Test the executor function without a file type.\"\"\"\n\n    with pytest.raises(ValueError, match=\"Error in executor: No file type provided for document loading.\"):\n        executor(\n            focus=base_attributes[\"focus\"],\n            page_layout=base_attributes[\"page_layout\"],\n            text_input=\"\",\n            file_type=\"\",\n            file_url=base_attributes[\"file_url\"],\n            lang=base_attributes[\"lang\"],\n            verbose=False\n        )\n    \ndef test_executor_loader_error():\n    \"\"\"Test the executor function without an invalid filetype and fileurl.\"\"\"\n\n    with pytest.raises(ValueError, match=\"Error in executor: Document loading failed\"):\n        executor(\n            focus=base_attributes[\"focus\"],\n            page_layout=base_attributes[\"page_layout\"],\n            text_input=\"\",\n            file_type=\"Invalid\",\n            file_url=\"Invalid_url\",\n            lang=base_attributes[\"lang\"],\n            verbose=False\n        )\n#Test for NoteGeneratorPipeline\ndef test_note_generator_pipeline_init():\n    \"\"\"Test initialization of NoteGeneratorPipeline.\"\"\"\n    pipeline = NoteGeneratorPipeline(args=None, verbose=False)\n    assert pipeline.args is None\n    assert pipeline.verbose is False\n\ndef test_note_generator_pipeline_compile_vectorstore():\n    \"\"\"Test the compile_vectorstore method.\"\"\"\n    pipeline = NoteGeneratorPipeline(args=None, verbose=False)\n    documents = [Document(page_content=\"Sample document content\")]\n    pipeline.compile_vectorstore(documents)\n    assert pipeline.vectorstore is not None\n    assert pipeline.retriever is not None\n\n# def test_note_generator_pipeline_generate_context():\n#     \"\"\"Test the generate_context method.\"\"\"\n#     pipeline = NoteGeneratorPipeline(args=None, verbose=False)\n#     documents = [Document(page_content=\"Photosynthesis is a process used by plants to convert sunlight into energy.\")]\n#     pipeline.compile_vectorstore(documents)\n#     context = pipeline.generate_context(\"Provide general context for the topic to create notes.\")\n#     assert isinstance(context, list)\n\n# def test_note_generator_pipeline_compile_pipeline():\n    # \"\"\"Test the compile_pipeline method.\"\"\"   \n    # pipeline = NoteGeneratorPipeline(args=None, verbose=False)\n    # pipeline.args = mock_args\n    # pipeline.parsers = JsonOutputParser(pydantic_object=BulletPoints)\n    # compiled_pipeline = pipeline.compile_pipeline()\n    # assert compiled_pipeline is not None\n\n# def test_note_generator_pipeline_generate_notes():\n#     \"\"\"Test the generate_notes method.\"\"\"\n#     pipeline = NoteGeneratorPipeline(args=None, verbose=False)\n#     pipeline.args = mock_args\n#     pipeline.parsers = mock_parser\n#     documents = [Document(page_content=base_attributes[\"text_input\"])]\n#     result = pipeline.generate_notes(documents)\n#     assert isinstance(result, GenerateNotesOutput)\n#     assert result.title == \"Generated Notes in bullet points format\"\n#     assert isinstance(result.notes, str)\n\ndef test_note_generator_pipeline_invalid_page_layout():\n    \"\"\"Test the generate_notes method with an invalid page layout.\"\"\"\n    pipeline = NoteGeneratorPipeline(args=None, verbose=False)\n    pipeline.args=mock_args\n    pipeline.args.page_layout = \"invalid\"\n    pipeline.parsers = mock_parser\n    with pytest.raises(ValueError) as exc_info:\n        pipeline.generate_notes([])\n        assert isinstance(exc_info.value, ValueError)\n\n# def test_generate_notes_output_model():\n#     \"\"\"Test the GenerateNotesOutput model.\"\"\"\n#     output = GenerateNotesOutput(title=\"Test Title\", notes=\"Test Notes\")\n#     assert output.title == \"Test Title\"\n#     assert output.notes == \"Test Notes\"\n\n\n\n\n    "}
{"type": "test_file", "path": "app/tools/presentation_generator_updated/slide_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/worksheet_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/multiple_choice_quiz_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.multiple_choice_quiz_generator.core import executor\n\ndef test_executor_pdf_url_valid():\n\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"college\",\n        n_questions = n_questions,\n        file_url = \"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        file_type = \"pdf\",\n        lang = \"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_pdf_url_invalid():\n    \n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            file_type = \"pdf\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_csv_url_valid():\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"college\",\n        n_questions = n_questions,\n        file_url = \"https://filesamples.com/samples/document/csv/sample1.csv\",\n        file_type = \"csv\",\n        lang = \"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_csv_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://filesamples.com/samples/document/csv/dummy.csv\",\n            file_type = \"csv\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_txt_url_valid():\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"college\",\n        n_questions = n_questions,\n        file_url = \"https://filesamples.com/samples/document/txt/sample1.txt\",\n        file_type = \"txt\",\n        lang = \"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_txt_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://filesamples.com/samples/document/txt/dummy.txt\",\n            file_type = \"txt\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_md_url_valid():\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"college\",\n        n_questions = n_questions,\n        file_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        file_type = \"md\",\n        lang = \"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_md_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/dummy.md\",\n            file_type = \"md\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_pptx_url_valid():\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"college\",\n        n_questions = 1,\n        file_url = \"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        file_type = \"pptx\",\n        lang = \"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_pptx_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://filesamples.com/samples/document/samplepptx.pptx\",\n            file_type = \"pptx\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_docx_url_valid():\n\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"college\",\n        n_questions = n_questions,\n        file_url = \"https://filesamples.com/samples/document/docx/sample1.docx\",\n        file_type = \"docx\",\n        lang = \"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_docx_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://filesamples.com/samples/document/docx/dummy.docx\",\n            file_type = \"docx\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_xls_url_valid():\n\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"college\",\n        n_questions = n_questions,\n        file_url = \"https://filesamples.com/samples/document/xls/sample1.xls\",\n        file_type = \"xls\",\n        lang = \"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_xls_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://filesamples.com/samples/document/xls/dummy.xls\",\n            file_type = \"xls\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_xlsx_url_valid():\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"college\",\n        n_questions = n_questions,\n        file_url = \"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        file_type = \"xlsx\",\n        lang = \"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_xlsx_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://filesamples.com/samples/document/xlsx/dummy.xlsx\",\n            file_type = \"xlsx\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_xml_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://filesampleshub.com/download/code/xml/dummy.xml\",\n            file_type = \"xml\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_gdocs_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1Ct/edit\",\n            file_type = \"gdoc\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_gsheets_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type = \"gsheet\",\n            lang = \"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_gslides_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type = \"gslide\",\n            lang=\"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_gpdfs_url_valid():\n    n_questions = 1\n\n    quiz = executor(\n        topic = \"doc\",\n        n_questions = n_questions,\n        file_url = \"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        file_type = \"gpdf\",\n        lang=\"en\",\n        grade_level= \"college\",\n        quiz_description= \"Test quiz\"\n    )\n\n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n\ndef test_executor_gpdfs_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://drive.google.com/file/d/1gBeAzJKTaZFwEbub8wkXrF3/view?usp=sharing\",\n            file_type = \"gpdf\",\n            lang=\"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_mp3_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = \"a\",\n            file_url = \"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            file_type = \"mp3\",\n            lang=\"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\n\ndef test_executor_gmp3_url_invalid():\n\n    with pytest.raises(ValueError) as exc_info:\n        quiz = executor(\n            topic = \"college\",\n            n_questions = 1,\n            file_url = \"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            file_type = \"gmp3\",\n            lang=\"en\",\n            grade_level= \"college\",\n            quiz_description= \"Test quiz\"\n        )\n\n    assert isinstance(exc_info.value, ValueError)\ndef test_quiz_voting():\n    n_questions = 1\n    quiz = executor(\n        topic=\"test topic\",\n        n_questions=n_questions,\n        file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        file_type=\"pdf\",\n        lang=\"en\"\n    )\n    \n    assert isinstance(quiz[0].get('thumbs_up', 0), int)\n    assert isinstance(quiz[0].get('thumbs_down', 0), int)\ndef test_vocabulary_quiz():\n    n_questions = 10\n    quiz = executor(\n        topic=\"Science Terms Vocabulary\",\n        n_questions=n_questions,\n        file_url=\"attached_assets/Science_Glossary.pdf\",\n        file_type=\"pdf\",\n        lang=\"en\"\n    )\n    \n    assert isinstance(quiz, list)\n    assert len(quiz) == n_questions\n    # Check if questions contain vocabulary-related content\n    for question in quiz:\n        assert 'question' in question\n        assert 'choices' in question\n        assert 'answer' in question\n        assert 'explanation' in question\n        assert isinstance(question.get('thumbs_up', 0), int)\n        assert isinstance(question.get('thumbs_down', 0), int)\n"}
{"type": "test_file", "path": "app/utils/tests/test_loaders_summarization.py", "content": "import pytest\nimport requests\nfrom app.api.error_utilities import FileHandlerError\nfrom app.utils.document_loaders_summarization import *\n\ndef test_load_pdf_documents_valid():\n    pdf_url = \"https://filesamples.com/samples/document/pdf/sample1.pdf\"\n    full_content = load_pdf_documents(pdf_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_pdf_documents_invalid():\n    dummy_pdf_url = \"https://filesamples.com/samples/document/pdf/dummy.pdf\"\n\n    with pytest.raises(requests.exceptions.HTTPError) as exc_info:\n        full_content = load_pdf_documents(dummy_pdf_url)\n\n    assert isinstance(exc_info.value, requests.exceptions.HTTPError)\n    assert exc_info.value.response.status_code == 404\n\ndef test_load_pdf_documents_invalid_file_type():\n    not_pdf_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_pdf_documents(not_pdf_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_csv_documents_valid():\n    csv_url = \"https://filesamples.com/samples/document/csv/sample1.csv\"\n    full_content = load_csv_documents(csv_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_csv_documents_invalid():\n    dummy_csv_url = \"https://filesamples.com/samples/document/csv/dummy.csv\"\n\n    with pytest.raises(requests.exceptions.HTTPError) as exc_info:\n        full_content = load_csv_documents(dummy_csv_url)\n\n    assert isinstance(exc_info.value, requests.exceptions.HTTPError)\n    assert exc_info.value.response.status_code == 404 \n\ndef test_load_csv_documents_invalid_file_type():\n    not_csv_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_csv_documents(not_csv_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_txt_documents_valid():\n    txt_url = \"https://filesamples.com/samples/document/txt/sample1.txt\"\n    full_content = load_txt_documents(txt_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_txt_documents_invalid():\n    dummy_txt_url = \"https://filesamples.com/samples/document/txt/dummy.txt\"\n\n    with pytest.raises(requests.exceptions.HTTPError) as exc_info:\n        full_content = load_txt_documents(dummy_txt_url)\n\n    assert isinstance(exc_info.value, requests.exceptions.HTTPError)\n    assert exc_info.value.response.status_code == 404\n\ndef test_load_txt_documents_invalid_file_type():\n    not_txt_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_txt_documents(not_txt_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_md_documents_valid():\n    md_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\"\n    full_content = load_md_documents(md_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_md_documents_invalid():\n    dummy_md_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/dummy.md\"\n\n    with pytest.raises(requests.exceptions.HTTPError) as exc_info:\n        full_content = load_md_documents(dummy_md_url)\n\n    assert isinstance(exc_info.value, requests.exceptions.HTTPError)\n    assert exc_info.value.response.status_code == 404\n\ndef test_load_md_documents_invalid_file_type():\n    not_md_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_md_documents(not_md_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_url_documents_valid():\n    valid_url = \"https://en.wikipedia.org/wiki/Gemini_(language_model)\"\n    full_content = load_url_documents(valid_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_pptx_documents_valid():\n    pptx_url = \"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\"\n    full_content = load_pptx_documents(pptx_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_pptx_documents_invalid():\n    dummy_pptx_url = \"https://scholar.harvard.edu/files/torman_personal/files/dummy.pptx\"\n\n    with pytest.raises(requests.exceptions.HTTPError) as exc_info:\n        full_content = load_pptx_documents(dummy_pptx_url)\n\n    assert isinstance(exc_info.value, requests.exceptions.HTTPError)\n    assert exc_info.value.response.status_code == 404\n\ndef test_load_pptx_documents_invalid_file_type():\n    not_pptx_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_md_documents(not_pptx_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_docx_documents_valid():\n    docx_url = \"https://filesamples.com/samples/document/docx/sample1.docx\"\n    full_content = load_docx_documents(docx_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_docx_documents_invalid():\n    dummy_docx_url = \"https://filesamples.com/samples/document/docx/dummy.docx\"\n\n    with pytest.raises(requests.exceptions.HTTPError) as exc_info:\n        full_content = load_docx_documents(dummy_docx_url)\n\n    assert isinstance(exc_info.value, requests.exceptions.HTTPError)\n    assert exc_info.value.response.status_code == 404\n\ndef test_load_docx_documents_invalid_file_type():\n    not_docx_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_docx_documents(not_docx_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_xls_documents_valid():\n    xls_url = \"https://filesamples.com/samples/document/xls/sample1.xls\"\n    full_content = load_xls_documents(xls_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_xls_documents_invalid():\n    dummy_xls_url = \"https://filesamples.com/samples/document/xls/dummy.xls\"\n\n    with pytest.raises(requests.exceptions.HTTPError) as exc_info:\n        full_content = load_xls_documents(dummy_xls_url)\n\n    assert isinstance(exc_info.value, requests.exceptions.HTTPError)\n    assert exc_info.value.response.status_code == 404\n\ndef test_load_xls_documents_invalid_file_type():\n    not_xls_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_xls_documents(not_xls_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_xlsx_documents_valid():\n    xlsx_url = \"https://filesamples.com/samples/document/xlsx/sample1.xlsx\"\n    full_content = load_xlsx_documents(xlsx_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_xlsx_documents_invalid():\n    dummy_xlsx_url = \"https://filesamples.com/samples/document/xlsx/dummy.xlsx\"\n\n    with pytest.raises(requests.exceptions.HTTPError) as exc_info:\n        full_content = load_xlsx_documents(dummy_xlsx_url)\n\n    assert isinstance(exc_info.value, requests.exceptions.HTTPError)\n    assert exc_info.value.response.status_code == 404\n\ndef test_load_xlsx_documents_invalid_file_type():\n    not_xlsx_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_xlsx_documents(not_xlsx_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_xml_documents_valid():\n    xml_url = \"https://raw.githubusercontent.com/AaronSosaRamos/mission-flights/main/files-for-test/sample.xml\"\n    full_content = load_xml_documents(xml_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_xml_documents_invalid_file_type():\n    not_xml_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_xml_documents(not_xml_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gdocs_documents_valid():\n    gdocs_url = \"https://docs.google.com/document/d/1DkOTKlHnZC6Us2N-ZHgECsQezYoB49af/edit?usp=drive_link&ouid=107052763106493355624&rtpof=true&sd=true\"\n    full_content = load_gdocs_documents(gdocs_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_gdocs_documents_invalid_permission():\n    private_gdocs_url = \"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1CCJBhJgkYLXM5IY/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gdocs_documents(private_gdocs_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gdocs_documents_invalid_url():\n    dummy_gdocs_url = \"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1Ct/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gdocs_documents(dummy_gdocs_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gdocs_documents_invalid_file_type():\n    not_gdocs_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gdocs_documents(not_gdocs_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gsheets_documents_valid():\n    gsheets_url = \"https://docs.google.com/spreadsheets/d/15Wvok1cjrTJGQQyokVKPsJ2jW2mbiuAJ/edit?usp=drive_link&ouid=107052763106493355624&rtpof=true&sd=true\"\n    full_content = load_gsheets_documents(gsheets_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_gsheets_documents_invalid_permission():\n    private_gsheets_url = \"https://docs.google.com/spreadsheets/d/16OPtLLSfUptnCNpXBXqPP7GpbNTlHTBRO_bWgmH_RvU/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gsheets_documents(private_gsheets_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gsheets_documents_invalid_url():\n    dummy_gsheets_url = \"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gsheets_documents(dummy_gsheets_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gsheets_documents_invalid_file_type():\n    not_gsheets_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gsheets_documents(not_gsheets_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gslides_documents_valid():\n    gslides_url = \"https://docs.google.com/presentation/d/1m99qIFwnGXIoxCJNCmIbecIvnoP3ecbT/edit?usp=drive_link&ouid=107052763106493355624&rtpof=true&sd=true\"\n    full_content = load_gslides_documents(gslides_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_gslides_documents_invalid_permission():\n    private_gslides_url = \"https://docs.google.com/presentation/d/1GeIRGJF63vyPMCeyqonluj4-8ZF0NF683LEn4J3UnhI/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gslides_documents(private_gslides_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gslides_documents_invalid_url():\n    dummy_gslides_url = \"https://docs.google.com/presentation/d/1GeIRGJF63v683LEn4J3UnhI/edit\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gslides_documents(dummy_gslides_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gslides_documents_invalid_file_type():\n    not_gslides_url = \"https://gbihr.org/images/docs/test.pdf\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gslides_documents(not_gslides_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gpdf_documents_valid():\n    gpdf_url = \"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\"\n    full_content = load_gpdf_documents(gpdf_url)\n    assert isinstance(full_content, str)\n    assert len(full_content) > 0\n\ndef test_load_gpdf_documents_invalid_permission():\n    private_gpdf_url = \"https://drive.google.com/file/d/1gBeAzJKTaZFwEbub8wkXr1MM-TXtw5F3/view\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gpdf_documents(private_gpdf_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gpdf_documents_invalid_url():\n    dummy_gpdf_url = \"https://drive.google.com/file/d/1gBeAzJKTaZFwEbub8wkXrF3/view?usp=sharing\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gpdf_documents(dummy_gpdf_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)\n\ndef test_load_gpdf_documents_invalid_file_type():\n    not_gpdf_url = \"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\"\n\n    with pytest.raises(FileHandlerError) as exc_info:\n        full_content = load_gpdf_documents(not_gpdf_url)\n\n    assert isinstance(exc_info.value, FileHandlerError)"}
{"type": "test_file", "path": "app/tools/flashcards_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.flashcards_generator.core import executor\n\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv())\n\n# PDF Tests\ndef test_executor_pdf_url_valid():\n    flashcards = executor(\n        file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        file_type=\"pdf\",\n        lang=\"en\"\n    )\n    assert isinstance(flashcards, list)\n\ndef test_executor_pdf_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# CSV Tests\ndef test_executor_csv_url_valid():\n    quiz = executor(\n        file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        file_type=\"csv\",\n        lang=\"en\"\n    )\n    assert isinstance(quiz, list)\n\ndef test_executor_csv_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# TXT Tests\ndef test_executor_txt_url_valid():\n    quiz = executor(\n        file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        file_type=\"txt\",\n        lang=\"en\"\n    )\n    assert isinstance(quiz, list)\n\ndef test_executor_txt_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MD Tests\ndef test_executor_md_url_valid():\n    quiz = executor(\n        file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        file_type=\"md\",\n        lang=\"en\"\n    )\n    assert isinstance(quiz, list)\n\ndef test_executor_md_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# PPTX Tests\ndef test_executor_pptx_url_valid():\n    quiz = executor(\n        file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        file_type=\"pptx\",\n        lang=\"en\"\n    )\n    assert isinstance(quiz, list)\n\ndef test_executor_pptx_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# DOCX Tests\ndef test_executor_docx_url_valid():\n    quiz = executor(\n        file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        file_type=\"docx\",\n        lang=\"en\"\n    )\n    assert isinstance(quiz, list)\n\ndef test_executor_docx_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLS Tests\ndef test_executor_xls_url_valid():\n    quiz = executor(\n        file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        file_type=\"xls\",\n        lang=\"en\"\n    )\n    assert isinstance(quiz, list)\n\ndef test_executor_xls_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XLSX Tests\ndef test_executor_xlsx_url_valid():\n    quiz = executor(\n        file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        file_type=\"xlsx\",\n        lang=\"en\"\n    )\n    assert isinstance(quiz, list)\n\ndef test_executor_xlsx_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# XML Tests\ndef test_executor_xml_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://filesampleshub.com/download/code/xml/dummy.xml\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# Google Docs Tests\ndef test_executor_gdocs_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1Ct/edit\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# Google Sheets Tests\ndef test_executor_gsheets_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# Google Slides Tests\ndef test_executor_gslides_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# Google PDFs Tests\ndef test_executor_gpdfs_url_valid():\n    quiz = executor(\n        file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        file_type=\"gpdf\",\n        lang=\"en\"\n    )\n    assert isinstance(quiz, list)\n\ndef test_executor_gpdfs_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)\n\n# MP3 Tests\ndef test_executor_mp3_url_invalid():\n    with pytest.raises(ValueError) as exc_info:\n        executor(\n            file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, ValueError)"}
{"type": "test_file", "path": "app/tools/worksheet_generator/tests/test_core.py", "content": "import pytest\nfrom app.tools.worksheet_generator.core import executor\n\n# PDF Tests\ndef test_executor_pdf_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n        file_type=\"pdf\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_pdf_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://filesamples.com/samples/document/pdf/sample1.pdf\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# CSV Tests\ndef test_executor_csv_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n        file_type=\"csv\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_csv_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://filesamples.com/samples/document/csv/sample1.csv\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# TXT Tests\ndef test_executor_txt_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n        file_type=\"txt\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_txt_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://filesamples.com/samples/document/txt/sample1.txt\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# MD Tests\ndef test_executor_md_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n        file_type=\"md\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_md_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://github.com/radicalxdev/kai-ai-backend/blob/main/README.md\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# PPTX Tests\ndef test_executor_pptx_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n        file_type=\"pptx\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_pptx_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://scholar.harvard.edu/files/torman_personal/files/samplepptx.pptx\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# DOCX Tests\ndef test_executor_docx_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n        file_type=\"docx\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_docx_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://filesamples.com/samples/document/docx/sample1.docx\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# XLS Tests\ndef test_executor_xls_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n        file_type=\"xls\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_xls_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://filesamples.com/samples/document/xls/sample1.xls\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# XLSX Tests\ndef test_executor_xlsx_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n        file_type=\"xlsx\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_xlsx_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://filesamples.com/samples/document/xlsx/sample1.xlsx\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# XML Tests\ndef test_executor_xml_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://filesampleshub.com/download/code/xml/dummy.xml\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# Google Docs Tests\ndef test_executor_gdocs_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://docs.google.com/document/d/1OWQfO9LX6psGipJu9LabzNE22us1Ct/edit\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# Google Sheets Tests\ndef test_executor_gsheets_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# Google Slides Tests\ndef test_executor_gslides_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://docs.google.com/spreadsheets/d/16OPtLLSfU/edit\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# Google PDFs Tests\ndef test_executor_gpdfs_url_valid():\n    worksheet = executor(\n        grade_level=\"5th grade\",\n        topic=\"Math\",\n        file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n        file_type=\"gpdf\",\n        lang=\"en\"\n    )\n    assert isinstance(worksheet, dict)\n\ndef test_executor_gpdfs_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://drive.google.com/file/d/1fUj1uWIMh6QZsPkt0Vs7mEd2VEqz3O8l/view\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n\n# MP3 Tests\ndef test_executor_mp3_url_invalid():\n    with pytest.raises(AttributeError) as exc_info:\n        executor(\n            grade_level=\"5th grade\",\n            topic=123,\n            file_url=\"https://raw.githubusercontent.com/asleem/uploaded_files/main/dummy.mp3\",\n            file_type=1,\n            lang=\"en\"\n        )\n    assert isinstance(exc_info.value, AttributeError)\n"}
{"type": "test_file", "path": "app/tools/notes_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/writing_feedback_generator/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "app/tools/presentation_generator/tests/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/error_utilities.py", "content": "from pydantic import BaseModel\nfrom typing import Any\n\nclass VideoTranscriptError(Exception):\n    \"\"\"Raised when a video transcript cannot be loaded. Used for tools which require video transcripts.\"\"\"\n    def __init__(self, message, url):\n        self.message = message\n        self.url = url\n        super().__init__(self.message)\n\n    def __str__(self):\n        return f\"{self.message}\"\n\nclass InputValidationError(Exception):\n    \"\"\"Raised when an input validation error occurs.\"\"\"\n    def __init__(self, message: str):\n        self.message = message\n        super().__init__(self.message)\n\nclass LoaderError(Exception):\n    \"\"\"Raised when a tool module's loader function encounters an error.\"\"\"\n    def __init__(self, message: str):\n        self.message = message\n        super().__init__(self.message)\n\nclass ToolExecutorError(Exception):\n    \"\"\"Raised when a tool executor encounters an error.\"\"\"\n    def __init__(self, message: str):\n        self.message = message\n        super().__init__(self.message)\n\nclass ErrorResponse(BaseModel):\n    \"\"\"Base model for error responses.\"\"\"\n    status: int\n    message: Any\n    \n    model_config = {\n        \"arbitrary_types_allowed\": True\n    }\n\nclass FileHandlerError(Exception):\n    \"\"\"Raised when a file content cannot be loaded. Used for tools which require file handling.\"\"\"\n    def __init__(self, message, url=None):\n        self.message = message\n        self.url = url\n        super().__init__(self.message)\n\n    def __str__(self):\n        return f\"{self.message}\"\n\nclass ImageHandlerError(Exception):\n    \"\"\"Raised when an image cannot be loaded. Used for tools which require image handling.\"\"\"\n    def __init__(self, message, url):\n        self.message = message\n        self.url = url\n        super().__init__(self.message)\n\n    def __str__(self):\n        return f\"{self.message}\"\n    \nclass WorksheetGeneratorError(Exception):\n    \"\"\"Base class for errors related to the worksheet generator.\"\"\"\n    def __init__(self, message: str):\n        self.message = message\n        super().__init__(self.message)\n    \nclass SyllabusGeneratorError(Exception):\n    \"\"\"Base class for errors related to the syllabus generator.\"\"\"\n    def __init__(self, message: str):\n        self.message = message\n        super().__init__(self.message)"}
{"type": "source_file", "path": "app/assistants/classroom_support/__init__.py", "content": ""}
{"type": "source_file", "path": "app/assistants/utils/assistants_utilities.py", "content": "import json\nimport os\nfrom typing import Any, Dict, List\n\nfrom fastapi import HTTPException\nfrom app.api.error_utilities import InputValidationError\nfrom app.services.logger import setup_logger\n\nlogger = setup_logger(__name__)\n\ndef load_config():\n    config_path = os.path.join(os.path.dirname(__file__), \"assistants_config.json\")\n    with open(config_path, 'r') as f:\n        return json.load(f)\n\nassistants_config = load_config()\n\ndef get_executor_by_name(module_path):\n    try:\n        module = __import__('app.'+module_path, fromlist=['executor'])\n        return getattr(module, 'executor')\n    except Exception as e:\n        logger.error(f\"Failed to import executor from {module_path}: {str(e)}\")\n        raise ImportError(f\"Failed to import module from {module_path}: {str(e)}\")\n    \n\ndef execute_assistant(assistant_group, assistant_name, user_info, messages):\n    try:\n        assistant_group = assistants_config.get(str(assistant_group))\n        assistant_config = assistant_group.get(str(assistant_name))     \n\n        if not assistant_config:\n            raise HTTPException(status_code=404, detail=\"Assistant executable not found\")\n        \n        execute_function = get_executor_by_name(assistant_config['path'])\n        \n        return execute_function(user_info, messages)\n    \n    except ImportError as e:\n        logger.error(f\"Failed to execute assistant due to import error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=str(e))\n    \n    except Exception as e:\n        logger.error(f\"Encountered error in executing assistant: {str(e)}\")\n        raise HTTPException(status_code=500, detail=str(e))"}
{"type": "source_file", "path": "app/services/logger.py", "content": "import logging\nimport os\n\n# Global variable to track logger configuration state\nlogger_configured = False\n\ndef setup_logger(name=__name__):\n    \"\"\"\n    Sets up a logger based on the environment.\n\n    If the environment variable ENV_TYPE is set to 'sandbox' or 'production', it configures\n    Google Cloud Logging. Otherwise, it uses the standard logging.\n\n    Parameters:\n    name (str): The name of the logger.\n\n    Returns:\n    logging.Logger: Configured logger.\n    \"\"\"\n    global logger_configured\n    env_type = os.environ.get('ENV_TYPE', 'undefined')\n    project = os.environ.get('PROJECT_ID', 'undefined')\n\n    # Obtain a reference to the logger\n    logger = logging.getLogger(name)\n    \n    # Check if the logger is already configured\n    if not logger.handlers:\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        handler.setFormatter(formatter)\n        logger.addHandler(handler)\n        logger.setLevel(logging.DEBUG)\n        logger.propagate = True\n\n    return logger\n"}
{"type": "source_file", "path": "app/assistants/classroom_support/co_teacher/__init__.py", "content": ""}
{"type": "source_file", "path": "app/main.py", "content": "from fastapi import FastAPI, Request, Depends\nfrom fastapi.responses import JSONResponse\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom contextlib import asynccontextmanager\nfrom app.api.router import router\nfrom app.services.logger import setup_logger\nfrom app.api.error_utilities import ErrorResponse\n\nimport os\nfrom dotenv import load_dotenv, find_dotenv\n\nload_dotenv(find_dotenv())\n\nlogger = setup_logger(__name__)\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    logger.info(f\"Initializing Application Startup\")\n    logger.info(f\"Successfully Completed Application Startup\")\n    \n    yield\n    logger.info(\"Application shutdown\")\n\napp = FastAPI(lifespan = lifespan)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n@app.exception_handler(RequestValidationError)\nasync def validation_exception_handler(request: Request, exc: RequestValidationError):\n    errors = []\n    for error in exc.errors():\n        field = \" -> \".join(str(loc) for loc in error['loc'])\n        message = error['msg']\n        error_detail = f\"Error in field '{field}': {message}\"\n        errors.append(error_detail)\n        logger.error(error_detail)  # Log the error details\n\n    error_response = ErrorResponse(status=422, message=errors)\n    return JSONResponse(\n        status_code=422,\n        content=error_response.dict()\n    )\n\napp.include_router(router)"}
{"type": "source_file", "path": "app/assistants/utils/__init__.py", "content": ""}
{"type": "source_file", "path": "app/services/schemas.py", "content": "from pydantic import BaseModel, Field\nfrom typing import Optional, List, Any, Literal, Union\nfrom enum import Enum\nfrom app.services.assistant_registry import AssistantInputs\nfrom app.services.tool_registry import BaseTool\n\nclass User(BaseModel):\n    id: str\n    fullName: str\n    email: str\n    \nclass Role(str, Enum):\n    human = \"human\"\n    ai = \"ai\"\n    system = \"system\"\n\nclass MessageType(str, Enum):\n    text = \"text\"\n    image = \"image\"\n    video = \"video\"\n    file = \"file\"\n\nclass MessagePayload(BaseModel):\n    text: Union[str, dict]\n\nclass Message(BaseModel):\n    role: Role\n    type: MessageType\n    timestamp: Optional[Any] = None\n    payload: MessagePayload\n    \nclass RequestType(str, Enum):\n    chat = \"chat\"\n    tool = \"tool\"\n\nclass GenericRequest(BaseModel):\n    user: User\n    type: RequestType\n    \nclass ChatRequest(GenericRequest):\n    messages: List[Message]\n\nclass GenericAssistantRequest(BaseModel):\n    assistant_inputs: AssistantInputs\n    \nclass ToolRequest(GenericRequest):\n    tool_data: BaseTool\n    \nclass ChatResponse(BaseModel):\n    data: List[Message]\n\nclass ToolResponse(BaseModel):\n    data: Any\n    \nclass ChatMessage(BaseModel):\n    role: str\n    type: str\n    text: str\n\nclass QuizzifyArgs(BaseModel):\n    topic: str\n    n_questions: int\n    file_url: str\n    file_type: str\n    lang: Optional[str] = \"en\"\n\nclass WorksheetQuestion(BaseModel):\n    question_type: str\n    number: int\n    \nclass WorksheetQuestionModel(BaseModel):\n    worksheet_question_list: List[WorksheetQuestion]\n\nclass WorksheetGeneratorArgs(BaseModel):\n    grade_level: str\n    topic: str\n    worksheet_list: WorksheetQuestionModel\n    file_url: str\n    file_type: str\n    lang: Optional[str] = \"en\"\n    \nclass SyllabusGeneratorArgsModel(BaseModel):\n    grade_level: str\n    subject: str\n    course_description: str\n    objectives: str\n    required_materials: str\n    grading_policy: str\n    policies_expectations: str\n    course_outline: str\n    additional_notes: str\n    file_url: str\n    file_type: str\n    lang: Optional[str] = \"en\"\n    \nclass AIResistantArgs(BaseModel):\n    assignment: str = Field(..., max_length=255, description=\"The given assignment\")\n    grade_level: Literal[\"pre-k\", \"kindergarten\", \"elementary\", \"middle\", \"high\", \"university\", \"professional\"] = Field(..., description=\"Educational level to which the content is directed\")\n    file_type: str = Field(..., description=\"Type of file being handled, according to the defined enumeration\")\n    file_url: str = Field(..., description=\"URL or path of the file to be processed\")\n    lang: str = Field(..., description=\"Language in which the file or content is written\")\n    \nclass ConnectWithThemArgs(BaseModel):\n    grade_level: str = Field(..., description=\"The grade level the teacher is instructing.\")\n    task_description: str = Field(..., description=\"A brief description of the subject or topic the teacher is instructing.\")\n    students_description: str = Field(..., description=\"A description of the students including age group, interests, location, and any relevant cultural or social factors.\")\n    task_description_file_url: str \n    task_description_file_type: str \n    student_description_file_url: str\n    student_description_file_type: str\n    lang: str = Field(..., description=\"The language in which the subject is being taught.\")\n\nclass PresentationGeneratorInput(BaseModel):\n    grade_level: str\n    n_slides: int\n    topic: str\n    objectives: str\n    additional_comments: str\n    objectives_file_url: str\n    objectives_file_type: str\n    additional_comments_file_url: str\n    additional_comments_file_type: str\n    lang: Optional[str] = \"en\"\n\nclass RubricGeneratorArgs(BaseModel):\n    grade_level: Literal[\"pre-k\", \"kindergarten\", \"elementary\", \"middle\", \"high\", \"university\", \"professional\"]\n    point_scale: int\n    objectives: str\n    assignment_description: str\n    objectives_file_url: str\n    objectives_file_type: str\n    assignment_description_file_url: str\n    assignment_description_file_type: str\n    lang: Optional[str]\n\nclass LessonPlanGeneratorArgs(BaseModel):\n    grade_level: str\n    topic: str\n    objectives: str\n    additional_customization: str\n    objectives_file_url: str\n    objectives_file_type: str\n    additional_customization_file_url: str\n    additional_customization_file_type: str\n    lang: Optional[str] = \"en\"\n\nclass WritingFeedbackGeneratorArgs(BaseModel):\n    grade_level: str\n    assignment_description: str\n    criteria: str\n    writing_to_review: str\n    criteria_file_url: str\n    criteria_file_type: str\n    writing_to_review_file_url: str\n    writing_to_review_file_type: str\n    lang: Optional[str] = \"en\"\n\nclass NoteGeneratorArgs(BaseModel):\n    focus: str\n    page_layout: str\n    text_input: str\n    file_type: str\n    file_url: str\n    lang: Optional[str] = \"en\"\n\nclass OutlineGeneratorInput(BaseModel):\n    n_slides: int\n    topic: str\n    instructional_level: str\n    file_url: str\n    file_type: str\n    lang: Optional[str] = \"en\"\n\nclass SlideGeneratorInput(BaseModel):\n    slides_titles: List[str]\n    instructional_level: str\n    topic: str\n    lang: Optional[str] = \"en\""}
{"type": "source_file", "path": "app/services/assistant_registry.py", "content": "from enum import Enum\nfrom typing import Any, List, Optional, Union\nfrom pydantic import BaseModel\n\nclass Role(str, Enum):\n    human = \"human\"\n    ai = \"ai\"\n    system = \"system\"\n\nclass MessageType(str, Enum):\n    text = \"text\"\n    image = \"image\"\n    video = \"video\"\n    file = \"file\"\n\nclass MessagePayload(BaseModel):\n    text: Union[str, dict]\n\nclass Message(BaseModel):\n    role: Role\n    type: MessageType\n    timestamp: Optional[Any] = None\n    payload: MessagePayload\n    \nclass UserInfo(BaseModel):\n    user_name: str\n    user_age: int\n    user_preference: str\n\nclass AssistantInputs(BaseModel):\n    assistant_group: str\n    assistant_name: str\n    user_info: UserInfo\n    messages: List[Message]"}
{"type": "source_file", "path": "app/assistants/classroom_support/co_teacher/core.py", "content": "from app.assistants.classroom_support.co_teacher.assistant import run_co_teacher_assistant\nfrom app.services.assistant_registry import Message, UserInfo\nfrom app.services.logger import setup_logger\nfrom app.services.schemas import (\n    ChatMessage\n)\n\nlogger = setup_logger()\n\ndef executor(\n        user_info: UserInfo,\n        messages: list[Message]=None, \n        k=3\n    ):\n    \n    logger.info(f\"Generating response from CoTeacher\")\n\n    chat_context_list = [\n        ChatMessage(\n            role=message.role, \n            type=message.type, \n            text=message.payload.text\n        ) for message in messages[-k:]\n    ]\n\n    chat_context_string = \"\\n\\n\".join(\n        map(\n            lambda message: (\n                f\"Role: {message.role}\\n\"\n                f\"Type: {message.type}\\n\"\n                f\"Text: {message.text}\"\n            ),\n            chat_context_list        \n        )\n    )\n    \n    response = run_co_teacher_assistant(\n        user_query=chat_context_list[-1].text,\n        chat_context=chat_context_string,\n        user_info=user_info\n    )\n\n    logger.info(f\"Response generated successfully for CoTeacher: {response}\")\n\n    return response"}
{"type": "source_file", "path": "app/services/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/router.py", "content": "import os\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom fastapi.encoders import jsonable_encoder\nfrom fastapi.responses import JSONResponse\nfrom typing import Union\nfrom app.assistants.utils.assistants_utilities import execute_assistant\nfrom app.services.schemas import GenericAssistantRequest, ToolRequest, ChatRequest, Message, ChatResponse, ToolResponse\nfrom app.utils.auth import key_check\nfrom app.services.logger import setup_logger\nfrom app.api.error_utilities import InputValidationError, ErrorResponse\nfrom app.tools.utils.tool_utilities import load_tool_metadata, execute_tool, finalize_inputs\nfrom fastapi.responses import FileResponse\nfrom starlette.background import BackgroundTask\n\nlogger = setup_logger(__name__)\nrouter = APIRouter()\n\n@router.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n\n@router.post(\"/submit-tool\", response_model=Union[ToolResponse, ErrorResponse])\nasync def submit_tool( data: ToolRequest, _ = Depends(key_check)):     \n    try: \n        # Unpack GenericRequest for tool data\n        request_data = data.tool_data\n        \n        requested_tool = load_tool_metadata(request_data.tool_id)\n        \n        request_inputs_dict = finalize_inputs(request_data.inputs, requested_tool['inputs'])\n\n        result = execute_tool(request_data.tool_id, request_inputs_dict)\n        \n        return ToolResponse(data=result)\n    \n    except InputValidationError as e:\n        logger.error(f\"InputValidationError: {e}\")\n\n        return JSONResponse(\n            status_code=400,\n            content=jsonable_encoder(ErrorResponse(status=400, message=e.message))\n        )\n    \n    except HTTPException as e:\n        logger.error(f\"HTTPException: {e}\")\n        return JSONResponse(\n            status_code=e.status_code,\n            content=jsonable_encoder(ErrorResponse(status=e.status_code, message=e.detail))\n        )\n\n@router.post(\"/assistant-chat\", response_model=ChatResponse)\nasync def assistants( request: GenericAssistantRequest, _ = Depends(key_check) ):\n    \n    assistant_group = request.assistant_inputs.assistant_group\n    assistant_name = request.assistant_inputs.assistant_name\n    user_info = request.assistant_inputs.user_info\n    messages = request.assistant_inputs.messages\n\n    result = execute_assistant(assistant_group, assistant_name, user_info, messages)\n\n    formatted_response = Message(\n        role=\"ai\",\n        type=\"text\",\n        payload={\"text\": result}\n    )\n    \n    return ChatResponse(data=[formatted_response])\n"}
{"type": "source_file", "path": "app/api/__init__.py", "content": ""}
{"type": "source_file", "path": "app/assistants/__init__.py", "content": ""}
{"type": "source_file", "path": "app/__init__.py", "content": ""}
{"type": "source_file", "path": "app/services/tool_registry.py", "content": "from pydantic import BaseModel\nfrom app.services.logger import setup_logger\nfrom typing import List, Any, Optional, Dict\nfrom app.api.error_utilities import InputValidationError\n\nlogger = setup_logger(__name__)\n\nclass ToolInput(BaseModel):\n    # Input from incoming request typically represent HTML Form elements\n    name: str\n    value: Any\n    # When passing \"files\", the value field is an object with file details as properties\n    \n# Base model for all tools\nclass BaseTool(BaseModel):\n    tool_id: str  # Unique identifier for each tool,\n    inputs: List[ToolInput]\n\nclass ToolFile(BaseModel):\n    filePath: Optional[str] = None\n    url: str\n    filename: Optional[str] = None"}
{"type": "source_file", "path": "app/assistants/classroom_support/co_teacher/assistant.py", "content": "import os\nfrom dotenv import load_dotenv, find_dotenv\nimport google.generativeai as genai\nfrom app.services.assistant_registry import UserInfo\nfrom app.services.logger import setup_logger\n\nload_dotenv(find_dotenv())\n\ngenai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n\nlogger = setup_logger()\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n    \n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n\nmodel = genai.GenerativeModel(model_name='gemini-2.0-flash-exp',\n                              system_instruction=read_text_file('prompt/co_teacher_context.txt'),\n                              )\n\ndef run_co_teacher_assistant(user_query: str, chat_context: str, user_info: UserInfo):\n  chat = model.start_chat()\n\n  user_name = user_info.user_name\n  user_age = user_info.user_age\n  user_preference = user_info.user_preference\n\n  response = chat.send_message(f\"\"\"\n                               User query: {user_query}\\n\n                               Personalize the response for {user_name} (Age: {user_age}) with preference: {user_preference}.\\n\n                               You can use the chat context if further information is needed: {chat_context}\\n\n                               \"\"\")\n\n  return response.text"}
{"type": "source_file", "path": "app/tools/connect_with_them/core.py", "content": "from app.utils.document_loaders import get_docs\nfrom app.tools.connect_with_them.tools import AIConnectWithThemGenerator\nfrom app.services.schemas import ConnectWithThemArgs\nfrom app.services.logger import setup_logger\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\n\nlogger = setup_logger()\n\ndef executor(grade_level: str,\n             task_description: str,\n             students_description: str,\n             task_description_file_url: str,\n             task_description_file_type: str,\n             student_description_file_url: str,\n             student_description_file_type: str,\n             lang: str,\n             verbose=False):\n    \n    try:\n        if(task_description_file_type):\n            logger.info(f\"Generating docs. from {task_description_file_type}\")\n        if(student_description_file_type):\n            logger.info(f\"Generating docs. from {student_description_file_type}\")\n\n        docs = None\n\n        def fetch_docs(file_url, file_type):\n            return get_docs(file_url, file_type, True) if file_url and file_type else None\n\n        task_description_docs = fetch_docs(task_description_file_url, task_description_file_type)\n        student_description_docs = fetch_docs(student_description_file_url, student_description_file_type)\n\n        docs = (\n            task_description_docs + student_description_docs\n            if task_description_docs and student_description_docs\n            else task_description_docs or student_description_docs\n        )\n\n        connect_with_them_args = ConnectWithThemArgs(\n            grade_level=grade_level,\n            task_description=task_description,\n            students_description=students_description,\n            task_description_file_url=task_description_file_url,\n            task_description_file_type=task_description_file_type,\n            student_description_file_url=student_description_file_url,\n            student_description_file_type=student_description_file_type,\n            lang=lang\n        )\n\n        output = AIConnectWithThemGenerator(args=connect_with_them_args, verbose=verbose).generate_suggestion(docs)\n\n        logger.info(f\"Connect with Them assignments generated successfully\")\n\n    except LoaderError as e:\n        error_message = e\n        logger.error(f\"Error in the Connect with Them Assignment Generator Pipeline -> {error_message}\")\n        raise ToolExecutorError(error_message)\n    \n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)\n    \n    return output\n"}
{"type": "source_file", "path": "app/tools/lesson_plan_generator/tools.py", "content": "from pydantic import BaseModel\nfrom typing import List, Optional\nfrom langchain_core.documents import Document\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnableParallel\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom app.services.logger import setup_logger\n\nlogger = setup_logger(__name__)\n\nclass LessonPlanGeneratorPipeline:\n    def __init__(self, args=None, verbose=False):\n        self.verbose = verbose\n        self.args = args\n        self.model = GoogleGenerativeAI(model=\"gemini-1.5-pro\")\n        self.embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n        self.vectorstore_class = Chroma\n        self.parsers = {\n            \"title\": JsonOutputParser(pydantic_object=Title),\n            \"objective\": JsonOutputParser(pydantic_object=Objective),\n            \"assessment\": JsonOutputParser(pydantic_object=Assessment),\n            \"key_points\": JsonOutputParser(pydantic_object=KeyPoints),\n            \"opening\": JsonOutputParser(pydantic_object=Section),\n            \"introduction_to_new_material\": JsonOutputParser(pydantic_object=Section),\n            \"guided_practice\": JsonOutputParser(pydantic_object=Section),\n            \"independent_practice\": JsonOutputParser(pydantic_object=IndependentPractice),\n            \"closing\": JsonOutputParser(pydantic_object=Section),\n            \"extension_activity\": JsonOutputParser(pydantic_object=ExtensionActivity),\n            \"homework\": JsonOutputParser(pydantic_object=Homework),\n            \"standards_addressed\": JsonOutputParser(pydantic_object=StandardsAddressed),\n        }\n        self.vectorstore = None\n        self.retriever = None\n\n    def compile_vectorstore(self, documents: List[Document]):\n        if self.verbose:\n            logger.info(\"Creating vectorstore from documents...\")\n        self.vectorstore = self.vectorstore_class.from_documents(documents, self.embedding_model)\n        self.retriever = self.vectorstore.as_retriever()\n        if self.verbose:\n            logger.info(\"Vectorstore and retriever created successfully.\")\n\n    def compile_pipeline(self):\n        prompts = {\n            \"title\": PromptTemplate(\n                template=\"Generate a detailed title for {topic} (Grade Level: {grade_level}). You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\", \"grade_level\"],\n                partial_variables={\"format_instructions\": self.parsers[\"title\"].get_format_instructions()},\n            ),\n            \"objective\": PromptTemplate(\n                template=\"Provide an objective for {topic} (Grade Level: {grade_level}). You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\", \"grade_level\"],\n                partial_variables={\"format_instructions\": self.parsers[\"objective\"].get_format_instructions()},\n            ),\n            \"assessment\": PromptTemplate(\n                template=\"Suggest an assessment for {topic}. Context: {context}, Objectives: {objectives}, Customization: {additional_customization}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\", \"context\", \"objectives\", \"additional_customization\"],\n                partial_variables={\"format_instructions\": self.parsers[\"assessment\"].get_format_instructions()},\n            ),\n            \"key_points\": PromptTemplate(\n                template=\"List key points for {topic}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\"],\n                partial_variables={\"format_instructions\": self.parsers[\"key_points\"].get_format_instructions()},\n            ),\n            \"opening\": PromptTemplate(\n                template=\"Describe an opening activity for {topic}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\"],\n                partial_variables={\"format_instructions\": self.parsers[\"opening\"].get_format_instructions()},\n            ),\n            \"introduction_to_new_material\": PromptTemplate(\n                template=\"Outline the introduction to new material for {topic}. Context: {context}, Objectives: {objectives}, Comments: {additional_customization}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\", \"context\", \"objectives\", \"additional_customization\"],\n                partial_variables={\"format_instructions\": self.parsers[\"introduction_to_new_material\"].get_format_instructions()},\n            ),\n            \"guided_practice\": PromptTemplate(\n                template=\"Describe guided practice for {topic}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\"],\n                partial_variables={\"format_instructions\": self.parsers[\"guided_practice\"].get_format_instructions()},\n            ),\n            \"independent_practice\": PromptTemplate(\n                template=\"Provide an independent practice task for {topic}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\"],\n                partial_variables={\"format_instructions\": self.parsers[\"independent_practice\"].get_format_instructions()},\n            ),\n            \"closing\": PromptTemplate(\n                template=\"Describe a conclusion for {topic}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\"],\n                partial_variables={\"format_instructions\": self.parsers[\"closing\"].get_format_instructions()},\n            ),\n            \"extension_activity\": PromptTemplate(\n                template=\"Suggest an extension activity for {topic}. Context: {context}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\", \"context\"],\n                partial_variables={\"format_instructions\": self.parsers[\"extension_activity\"].get_format_instructions()},\n            ),\n            \"homework\": PromptTemplate(\n                template=\"Provide homework for {topic}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\"],\n                partial_variables={\"format_instructions\": self.parsers[\"homework\"].get_format_instructions()},\n            ),\n            \"standards_addressed\": PromptTemplate(\n                template=\"List standards addressed by teaching {topic}. You must respond as a JSON in this format: \\n{format_instructions}\",\n                input_variables=[\"topic\"],\n                partial_variables={\"format_instructions\": self.parsers[\"standards_addressed\"].get_format_instructions()},\n            ),\n        }\n        chains = {key: prompt | self.model | self.parsers[key] for key, prompt in prompts.items()}\n        return RunnableParallel(branches=chains)\n\n    def generate_context(self, query: str) -> str:\n        return self.retriever.invoke(query)\n\n    def generate_lesson_plan(self, documents: Optional[List[Document]]):\n\n        if documents: \n            self.compile_vectorstore(documents)\n\n        pipeline = self.compile_pipeline()\n\n        if documents:\n            context_queries = {\n                \"general\": \"Provide general context for the topic.\",\n                \"specific\": \"Provide specific details for creating an educational lesson plan.\",\n            }\n            context = {\n                query_name: self.generate_context(query)\n                for query_name, query in context_queries.items()\n            }\n\n        inputs = {\n            \"topic\": self.args.topic,\n            \"grade_level\": self.args.grade_level,\n            \"context\": context[\"general\"] if documents else '',\n            \"objectives\": self.args.objectives,\n            \"additional_customization\": self.args.additional_customization,\n        }\n        results = pipeline.invoke(inputs)\n        lesson_plan = {\n            \"title\": results[\"branches\"][\"title\"][\"title\"],\n            \"objective\": results[\"branches\"][\"objective\"][\"objective\"],\n            \"assessment\": results[\"branches\"][\"assessment\"][\"assessment\"],\n            \"key_points\": results[\"branches\"][\"key_points\"][\"key_points\"],\n            \"opening\": results[\"branches\"][\"opening\"],\n            \"introduction_to_new_material\": results[\"branches\"][\"introduction_to_new_material\"],\n            \"guided_practice\": results[\"branches\"][\"guided_practice\"],\n            \"independent_practice\": results[\"branches\"][\"independent_practice\"],\n            \"closing\": results[\"branches\"][\"closing\"],\n            \"extension_activity\": results[\"branches\"][\"extension_activity\"],\n            \"homework\": results[\"branches\"][\"homework\"],\n            \"standards_addressed\": results[\"branches\"][\"standards_addressed\"][\"standards_addressed\"],\n        }\n        if self.verbose:\n            logger.info(\"Lesson Plan successfully generated.\")\n        return lesson_plan\n\nclass Title(BaseModel):\n    title: str\n\nclass Objective(BaseModel):\n    objective: str\n\nclass Assessment(BaseModel):\n    assessment: str\n\nclass KeyPoint(BaseModel):\n    title: str\n    description: str\n\nclass Section(BaseModel):\n    title: str\n    content: List[str]\n\nclass IndependentPractice(BaseModel):\n    description: str\n    tasks: List[str]\n\nclass ExtensionActivity(BaseModel):\n    description: str\n    additional_instructions: Optional[str]\n\nclass Homework(BaseModel):\n    description: str\n    submission_instructions: Optional[str]\n\nclass Standard(BaseModel):\n    name: str\n    description: str\n\nclass KeyPoints(BaseModel):\n    key_points: List[KeyPoint]\n\nclass StandardsAddressed(BaseModel):\n    standards_addressed: List[Standard]\n\nclass LessonPlan(BaseModel):\n    title: Title\n    objective: Objective\n    assessment: Assessment\n    key_points: KeyPoints\n    opening: Section\n    introduction_to_new_material: Section\n    guided_practice: Section\n    independent_practice: IndependentPractice\n    closing: Section\n    extension_activity: ExtensionActivity\n    homework: Homework\n    standards_addressed: StandardsAddressed"}
{"type": "source_file", "path": "app/tools/lesson_plan_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/flashcards_generator/core.py", "content": "from app.services.logger import setup_logger\nfrom app.tools.flashcards_generator.tools import (\n    get_summary, \n    summarize_transcript_youtube_url, \n    generate_flashcards, \n    generate_concepts_from_img\n)\nfrom app.api.error_utilities import ToolExecutorError, VideoTranscriptError\n\nlogger = setup_logger(__name__)\n\nSUPPORTED_FILE_TYPES = [\n    'pdf', 'csv', 'txt', 'md', 'url', 'pptx', 'docx', 'xls', 'xlsx', 'xml',\n    'gdoc', 'gsheet', 'gslide', 'gpdf'\n]\n\ndef executor(file_url: str, file_type: str, lang: str = \"en\", verbose=False):\n    try:\n        if verbose:\n            print(f\"File URL loaded: {file_url}\")\n        \n        flashcards = []\n\n        if file_type == \"img\":\n            flashcards = generate_concepts_from_img(file_url, lang)\n        elif file_type == 'youtube_url':\n            summary = summarize_transcript_youtube_url(file_url, verbose=verbose)\n            flashcards = generate_flashcards(summary, lang, verbose)\n        elif file_type in SUPPORTED_FILE_TYPES:\n            summary = get_summary(file_url, file_type, verbose=verbose)\n            flashcards = generate_flashcards(summary, lang, verbose)\n        else:\n            logger.error(f\"Unsupported file type: {file_type}\")\n            raise ValueError(f\"Unsupported file type: {file_type}\")\n        \n        sanitized_flashcards = []\n        for flashcard in flashcards:\n            if 'concept' in flashcard and 'definition' in flashcard:\n                sanitized_flashcards.append({\n                    \"concept\": flashcard['concept'],\n                    \"definition\": flashcard['definition']\n                })\n            else:\n                logger.warning(f\"Malformed flashcard skipped: {flashcard}\")\n\n        return sanitized_flashcards\n\n    except VideoTranscriptError as e:\n        error_message = e\n        logger.error(f\"Error processing video transcript: {e}\")\n        raise ToolExecutorError(error_message)\n\n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(f\"An error occurred while processing the file: {e}\")\n        raise ValueError(error_message)"}
{"type": "source_file", "path": "app/tools/multiple_choice_quiz_generator/core.py", "content": "import os\nfrom app.utils.document_loaders import get_docs\nfrom app.services.logger import setup_logger\nfrom app.tools.multiple_choice_quiz_generator.tools import QuizBuilder\nfrom langsmith import Client\n\nclient = Client()\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\n\nlogger = setup_logger()\n\ndef executor(topic: str,\n             n_questions: int,\n             file_url: str,\n             file_type: str,\n             lang: str,\n             grade_level: str,\n             quiz_description: str,\n             verbose=True):\n    \n    try:\n        if verbose:\n            logger.info(f\"File URL loaded: {file_url}\")\n        \n        # Handle local file paths\n        if not file_url.startswith(('http://', 'https://')):\n            file_url = os.path.join(os.getcwd(), file_url)\n            if not os.path.exists(file_url):\n                raise ValueError(f\"File not found at path: {file_url}\")\n            \n        docs = get_docs(file_url, file_type, lang, verbose=True)\n        if not docs:\n            raise ValueError(\"Error: Could not load document content from the provided URL\")\n    \n        output = QuizBuilder(topic, n_questions, grade_level, quiz_description, lang, verbose=verbose) \\\n                .create_questions(docs)\n    \n    except LoaderError as e:\n        error_message = e\n        logger.error(f\"Error in RAGPipeline -> {error_message}\")\n        raise ToolExecutorError(error_message)\n    \n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)\n    \n    return output\n\n"}
{"type": "source_file", "path": "app/tools/flashcards_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/multiple_choice_quiz_generator/tools.py", "content": "from typing import List, Dict\nimport os\nfrom operator import itemgetter\nfrom pydantic import BaseModel, Field\nfrom langchain_core.documents import Document\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnableParallel, RunnableLambda\nfrom langchain_core.output_parsers import JsonOutputParser, BaseOutputParser\nfrom langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\nfrom langchain.retrievers.multi_query import MultiQueryRetriever\nfrom langsmith import traceable\n\nfrom app.services.logger import setup_logger\n\nrelative_path = \"tools/multiple_choice_quiz_generator\"\n\nlogger = setup_logger(__name__)\n\ndef transform_json_dict(input_data: dict) -> dict:\n    generated_questions = []\n\n    # Validate and parse the input data to ensure it matches the QuizQuestion schema\n    quiz_questions_list = QuizQuestionsList(**input_data)\n    \n    for question in quiz_questions_list.questions_list:\n        transformed_question = {\n                \"question\": question.question,\n                \"choices\": {choice.key: choice.value for choice in question.choices},\n                \"answer\": question.answer,\n                \"explanation\": question.explanation\n            }\n        generated_questions.append(transformed_question)\n\n    return generated_questions\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n    \n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n\nclass QuizBuilderConfig:\n    \n    def __init__(\n        self,\n        model = None,\n        embedding_model = None,\n        vectorstore_class = None,\n        max_questions: int = 10,\n        min_questions: int = 1,\n        max_attempts: int = 2,\n        prompt_template_path: str = \"prompt/multiple_choice_quiz_generator_prompt.txt\",\n        multi_query_prompt_path: str = \"prompt/multi_query_prompt.txt\",\n        parser: JsonOutputParser = None,\n        verbose: bool = False,\n        score_threshold: float = 0.4\n    ):\n        self.model = model or GoogleGenerativeAI(model=\"gemini-1.5-pro\", max_output_tokens=None ) \n        self.embedding_model = embedding_model or GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n        self.vectorstore_class = vectorstore_class or Chroma\n        self.max_questions = max_questions\n        self.min_questions = min_questions\n        self.max_attempts = max_attempts\n        self.prompt_template_path = prompt_template_path\n        self.multi_query_prompt_path = multi_query_prompt_path\n        self.verbose = verbose\n        self.score_threshold = score_threshold\n\n        # load the prompt template\n        self.prompt_template = read_text_file(self.prompt_template_path)\n        self.multi_query_prompt_template = read_text_file(self.multi_query_prompt_path)\n\n        self.parser = parser or JsonOutputParser(pydantic_object=QuizQuestionsList)\n\nclass QuizBuilder:\n            \n    def __init__(\n        self, \n        topic: str, \n        n_questions: int, \n        grade_level: str, \n        quiz_description: str = \"\", \n        lang: str ='en', \n        config: QuizBuilderConfig = None, \n        verbose: bool = False\n    ):\n        \"\"\"\n            Initialize the QuizBuilder with configuration and models.\n            \n            Args:\n                topic (str): The main topic for quiz questions\n                n_questions (int): The number of questions to generate\n                grade_level (str): The grade level for the quiz\n                quiz_description (str): Description of the quiz (default: \"\")\n                lang (str): Language code for question generation (default: 'en')\n                config (QuizBuilderConfig): Configuration object for the quiz builder (default: None)   \n                verbose (bool): Enable detailed logging (default: False)\n        \"\"\"\n        self.topic = topic\n        self.lang = lang\n        self.n_questions = n_questions\n        self.grade_level = grade_level\n        self.quiz_description = quiz_description\n\n        self.config = config or QuizBuilderConfig(verbose=verbose)\n        self.verbose = verbose\n        self.runner = None\n        self._model = self.config.model\n        self._prompt_template = self.config.prompt_template\n        self._parser = self.config.parser\n\n        # Initialize components\n        self.vectorstore_manager = VectorStoreManager(self.config)\n        self.retriever_factory = RetrieverFactory(self.config)\n\n        if topic is None: raise ValueError(\"Topic must be provided\")\n\n    def get_optional_instructions(self, input_name: str, input_value: str) -> str:\n        \"\"\"\n        Get the optional instructions for a given input variable.\n        \n        Args:\n            input_name (str): The name of the input variable\n            input_value (str): The value of the input variable\n        \n        Returns:\n            str: The optional instructions for the input variable\n        \"\"\"\n        OPT_INSTRUCTIONS_TEMPLATE = {\n            \"quiz_description\": \"- Assessment Description: %s\"\n        }\n        if input_name in OPT_INSTRUCTIONS_TEMPLATE:\n            return OPT_INSTRUCTIONS_TEMPLATE[input_name] % input_value\n        else:\n            return \"\"\n    \n    def compile(self, documents: List[Document]) -> RunnableParallel:\n        \"\"\"\n        Compile the question generation chain using the provided documents.\n        \n        Args:\n            documents (List[Document]): List of documents to use as context\n            \n        Returns:\n            Chain: A compiled LangChain chain for question generation\n        \"\"\"\n        # Initialize prompt template with all required variables\n        prompt = PromptTemplate(\n            template=self._prompt_template,\n            input_variables=[\"topic\", \"lan\", \"context\", \"num_questions\", \"grade_level\", \"quiz_description\"],\n            partial_variables={\"format_instructions\": self._parser.get_format_instructions()})\n\n        number_documents = len(documents)\n\n        # Create vector store and retriever if not already initialized\n        if self.runner is None:\n            vectorstore = self.vectorstore_manager.create_vectorstore(documents)\n            retriever_k = number_documents # Set the retriever k value to the number of documents\n            retriever = self.retriever_factory.create_multiquery_retriever(\n                vectorstore, \n                self.n_questions, \n                retriever_k\n            )\n\n            # Set up parallel running to pass all required variables for prompt\n            self.runner = RunnableParallel(\n                {\n                    \"context\": itemgetter(\"topic\") |  retriever, # Retrieves relevant context from documents\n                    \"topic\": itemgetter(\"topic\"),  # Passes through the topic\n                    \"lang\": itemgetter(\"lang\"),  # Passes through the language\n                    \"num_questions\": itemgetter(\"n_questions\"),  # Passes through the number of questions\n                    \"grade_level\": itemgetter(\"grade_level\"),  # Passes through the grade level\n                    \"quiz_description\": \n                        lambda input : self.get_optional_instructions(\n                            \"quiz_description\", \n                            input[\"quiz_description\"])  # Passes through the quiz description\n                }\n            )\n        logger.info(f\"Runner initialized\") if self.verbose else None\n\n        # Compile the full chain: runner -> prompt -> model -> parser\n        chain = (self.runner | prompt | self._model | self._parser)\n        \n        logger.info(f\"Chain compilation complete\") if self.verbose else None\n        \n        return chain\n\n    def create_questions(self, documents: List[Document]) -> List[Dict]:\n        \"\"\"\n        Generate multiple-choice quiz questions based on the provided documents.\n        \n        Args:\n            documents (List[Document]): List of documents to use as context\n            \n        Returns:\n            List[Dict]: List of generated quiz questions with choices and answers\n        \"\"\"\n        logger.info(f\"Creating {self.n_questions} questions\") if self.verbose else None\n     \n        if self.n_questions > self.config.max_questions:\n            return {\"message\": \"error\", \"data\": f\"Number of questions cannot exceed {self.config.max_questions}\"}\n        \n        try:\n            chain = self.compile(documents)\n\n            user_input = {\n                \"n_questions\": self.n_questions,\n                \"topic\": self.topic,\n                \"lang\": self.lang,\n                \"grade_level\": self.grade_level,\n                \"quiz_description\": self.quiz_description\n            }\n            generated_questions = self.run_chain(chain, user_input)\n\n            number_gen_questions = len(generated_questions)\n            logger.info(f\"Total generated questions: {number_gen_questions}\") if self.verbose else None\n            \n            # Log if fewer questions are generated\n            if number_gen_questions < self.n_questions:\n                if self.verbose: \n                    logger.warning(f\"Only generated {number_gen_questions} out of \"\n                                   \"{self.n_questions} requested questions\")\n            \n            # Return requested number of questions (or fewer if not enough were generated)\n            return generated_questions[:self.n_questions]\n        except Exception as e:\n            if self.verbose:\n                logger.error(f\"Error generating questions: {e}\")\n            raise e\n        finally:\n            self.cleanup()\n\n    \n    def run_chain(self, chain: RunnableParallel, user_input: dict) -> List[Dict]:\n        \"\"\"\n        Run the LangChain pipeline to generate quiz questions.\n\n        Args:\n            chain (RunnableParallel): The compiled LangChain pipeline\n            user_input (dict): The input data for the pipeline\n        \"\"\"\n        generated_questions = []\n        attempts = 0\n        max_attempts = self.config.max_attempts  # Allow for more attempts to generate questions\n\n        while not generated_questions and attempts < max_attempts:\n            error = None\n            if self.verbose:\n                logger.info(f\"Running pipeline. Attempt {attempts + 1} of {max_attempts}\")\n\n            try:\n                # Run the pipeline with the provided input data\n                response = chain.invoke(user_input)\n        \n                logger.info(f\"Generated response: {response}\") if self.verbose else None\n\n                questions_list = transform_json_dict(response)\n                for question in questions_list:\n                    # Directly check if the response format is valid\n                    if self.validate_response(question):\n                        question[\"choices\"] = self.format_choices(question[\"choices\"])\n                        generated_questions.append(question)\n                        if self.verbose:\n                            logger.info(f\"Valid question added: {question}\")\n                    else:\n                        if self.verbose:\n                            logger.warning(f\"Invalid response format. Attempt {attempts + 1} of {max_attempts}\")\n            except TypeError as e:\n                error = f\"TypeError generating questions: {e}\"\n                if self.verbose:\n                    logger.error(error)\n            except Exception as e:\n                error = f\"Error generating questions: {e}\"\n                if self.verbose:\n                    logger.error(error)\n            finally:\n                if error:\n                    generated_questions = []\n                attempts += 1\n\n        if error: \n            raise Exception(error)\n            \n        return generated_questions\n\n    \n    #new function to validate the response\n    def validate_response(self, response: dict) -> bool:\n        \"\"\"\n        Validates the structure and content of a quiz question response.\n        \n        Args:\n            response (dict): The quiz question response to validate\n            \n        Returns:\n            bool: True if valid, False otherwise\n        \"\"\"\n        try:\n            # Check if all required fields are present\n            required_fields = ['question', 'choices', 'answer', 'explanation']\n            if not all(field in response for field in required_fields):\n                logger.warning(\"Missing required fields\") if self.verbose else None\n                return False\n            \n            # Validate choices\n            if not isinstance(response['choices'], dict):\n                logger.warning(\"Choices must be a dictionary\") if self.verbose else None\n                return False\n            \n            # Validate that there are exactly 4 choices\n            if len(response['choices']) != 4:\n                logger.warning(\"Must have exactly 4 choices\") if self.verbose else None\n                return False\n            \n            # Validate choice keys are A, B, C, D\n            valid_keys = set(['A', 'B', 'C', 'D'])\n            if set(response['choices'].keys()) != valid_keys:\n                logger.warning(\"Choice keys must be A, B, C, D\") if self.verbose else None\n                return False\n            \n            # Validate answer is one of the valid keys\n            if response['answer'] not in valid_keys:\n                logger.warning(\"Answer must be one of: A, B, C, D\") if self.verbose else None\n                return False\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Validation error: {str(e)}\") if self.verbose else None\n            return False\n\n    def format_choices(self, choices: dict) -> dict:\n        \"\"\"\n        Formats the choices to ensure they are in the correct order and structure.\n        \n        Args:\n            choices (dict): Dictionary of choices with keys A, B, C, D\n            \n        Returns:\n            dict: Formatted choices in correct order\n        \"\"\"\n        ordered_keys = ['A', 'B', 'C', 'D']\n        return {key: choices[key] for key in ordered_keys if key in choices}\n    \n    def vote_question(self, question_index: int, vote_type: str) -> bool:\n        \"\"\"\n        Add a vote to a specific question\n        \n        Args:\n            question_index (int): Index of the question\n            vote_type (str): Either 'up' or 'down'\n            \n        Returns:\n            bool: True if vote was successful\n        \"\"\"\n        try:\n            if vote_type == 'up':\n                self.questions[question_index].thumbs_up += 1\n            elif vote_type == 'down':\n                self.questions[question_index].thumbs_down += 1\n            return True\n        except (IndexError, AttributeError):\n            return False\n\n    def cleanup(self):\n        \"\"\"\n        Cleanup resources used by the QuizBuilder.\n        \"\"\"\n        if self.verbose:\n            logger.info(\"Cleaning up resources\")\n\n        self.vectorstore_manager.cleanup()\n        self.vectorstore_manager = None\n        self.retriever_factory.cleanup()\n        self.retriever_factory = None\n\nclass RetrieverFactory:\n    \n    def __init__(self, config: QuizBuilderConfig):\n        self.verbose = config.verbose\n\n        self._model = config.model\n        self._prompt_template = config.multi_query_prompt_template\n        self._score_threshold = config.score_threshold\n    \n    def create_multiquery_prompt(self, num_questions: int) -> PromptTemplate:\n        try:\n            return PromptTemplate(\n                input_variables=[\"question\"],\n                partial_variables={\n                    \"num_questions\": num_questions,\n                },\n                template=self._prompt_template\n            )\n        except Exception as e:\n            logger.error(f\"Failed to create multiquery prompt: {e}\") if self.verbose else None\n            raise Exception(f\"Prompt creation failed: {str(e)}\")\n\n    def create_base_retriever(self, vectorstore, retriever_k: int, score_threshold: float):\n        try:\n            return vectorstore.as_retriever(\n                search_type=\"similarity_score_threshold\",\n                search_kwargs={\n                    \"k\": retriever_k,\n                    \"score_threshold\": score_threshold\n                }\n            )\n        except Exception as e:\n            logger.error(f\"Failed to create base retriever: {e}\")\n            raise Exception(f\"Base retriever creation failed: {str(e)}\")\n\n    def create_multiquery_chain(self, prompt: PromptTemplate):\n        # Create the multiquery chain\n        try:\n            output_parser = QueryListOutputParser()\n            return prompt | self._model | output_parser\n        except Exception as e:\n            logger.error(f\"Failed to create multiquery chain: {e}\")\n            raise Exception(f\"Chain creation failed: {str(e)}\")\n\n    def create_multiquery_retriever(\n        self, \n        vectorstore,\n        num_questions: int,\n        retriever_k: int,\n        score_threshold: float = None,\n        only_page_content: bool = True\n    ) -> MultiQueryRetriever:\n        if self.verbose:\n            logger.info(\"Setting up MultiQueryRetriever\")\n            \n        try:\n            search_score_threshold = score_threshold or self._score_threshold\n            base_retriever = self.create_base_retriever(vectorstore, retriever_k, search_score_threshold)\n            prompt = self.create_multiquery_prompt(num_questions)\n            chain = self.create_multiquery_chain(prompt)\n            \n            retriever = MultiQueryRetriever(\n                retriever=base_retriever,\n                llm_chain=chain,\n                parser_key=\"lines\",\n                verbose=self.verbose\n            )\n            \n            if self.verbose:\n                logger.info(\"MultiQueryRetriever created successfully\")\n            \n            factory = self\n            def wrapper_retriever(inputs):\n                if self.verbose:\n                    logger.info(f\"Invoking enhanced retriever with inputs: {inputs}\")\n\n                retrieved_docs = retriever.invoke(inputs)\n                factory.number_retrieved_docs = len(retrieved_docs)\n\n                if self.verbose:\n                    logger.info(f\"Retrieved {factory.number_retrieved_docs} documents\")\n\n                if only_page_content:\n                    if self.verbose:\n                        logger.info(\"Returning only page content\")\n                    return [doc.page_content for doc in retrieved_docs]\n                \n                return retrieved_docs\n\n            return RunnableLambda(wrapper_retriever)\n            \n        except Exception as e:\n            logger.error(f\"Failed to create enhanced retriever: {e}\")\n            raise Exception(f\"Multiquery retriever creation failed: {str(e)}\")\n        \n    def cleanup(self):\n        \"\"\"\n        Cleanup resources used by the RetrieverFactory.\n        \"\"\"\n        if self.verbose:\n            logger.info(\"Cleaning up RetrieverFactory resources\")\n        self._model = None\n        \nclass VectorStoreManager:\n    \n    def __init__(self, config: QuizBuilderConfig):\n        self.config = config\n        self.verbose = config.verbose\n        self._vectorstore_class = self.config.vectorstore_class\n        self._embedding_model = self.config.embedding_model \n        \n        self._vectorstore = None\n    \n    @property\n    def vectorstore(self):\n        if self._vectorstore is None:\n            self._vectorstore = self.create_vectorstore()\n        return self._vectorstore\n    \n    @traceable(run_type=\"embedding\")\n    def create_vectorstore(self, documents: List[Document]):\n\n        logger.info(f\"Creating vectorstore from {len(documents)} documents\") if self.verbose else None\n        self._vectorstore = self._vectorstore_class.from_documents(\n            documents, \n            self._embedding_model\n        )\n        logger.info(f\"Vectorstore created\") if self.verbose else None\n        return self._vectorstore\n    \n    def cleanup(self):\n        if self.verbose: logger.info(f\"Deleting vectorstore\")\n        if self._vectorstore:\n            self._vectorstore.delete_collection()\n            self._vectorstore = None\n            self._vectorstore_class = None\n\nclass QueryListOutputParser(BaseOutputParser[List[str]]):\n    # Output parser for a list of lines.\n    def parse(self, text: str) -> List[str]:\n        lines = text.strip().split(\"\\n\")\n        return list(filter(None, lines)) \n    \nclass QuestionChoice(BaseModel):\n    key: str = Field(description=\"A unique identifier for the choice using letters A, B, C, or D.\")\n    value: str = Field(description=\"The text content of the choice\")\n\nclass QuizQuestion(BaseModel):\n    question: str = Field(description=\"The question text\")\n    choices: List[QuestionChoice] = Field(description=\"A list of choices for the question, each with a key and a value\")\n    answer: str = Field(description=\"The key of the correct answer from the choices list\")\n    explanation: str = Field(description=\"An explanation of why the answer is correct\")\n    thumbs_up: int = Field(default=0, description=\"Number of thumbs up votes\")\n    thumbs_down: int = Field(default=0, description=\"Number of thumbs down votes\")\n\nclass QuizQuestionsList(BaseModel):\n    questions_list: List[QuizQuestion] = Field(description=\"A list of questions for the quiz\")\n\n    model_config = {\n        \"json_schema_extra\": {\n            \"examples\": \"\"\" \n                \"questions_list\": [\n                    {\n                        \"question\": \"What is the capital of France?\",\n                        \"choices\": [\n                            {\"key\": \"A\", \"value\": \"Berlin\"},\n                            {\"key\": \"B\", \"value\": \"Madrid\"},\n                            {\"key\": \"C\", \"value\": \"Paris\"},\n                            {\"key\": \"D\", \"value\": \"Rome\"},\n                        ],\n                        \"answer\": \"C\",\n                        \"explanation\": \"Paris is the capital of France.\"\n                    },\n                    {\n                        \"question\": \"What is the official language of France?\",\n                        \"choices\": [\n                            {\"key\": \"A\", \"value\": \"French\"},\n                            {\"key\": \"B\", \"value\": \"English\"},\n                            {\"key\": \"C\", \"value\": \"German\"},\n                            {\"key\": \"D\", \"value\": \"Spanish\"}\n                        ],\n                        \"answer\": \"A\",\n                        \"explanation\": \"The official language of France is French.\"\n                    },\n                ]\n\n          \"\"\"\n        }\n\n      }\n    \n\n"}
{"type": "source_file", "path": "app/tools/presentation_generator/tools.py", "content": "from pydantic import BaseModel, Field\nfrom typing import List, Optional\nimport os\nfrom app.services.logger import setup_logger\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough, RunnableParallel\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_core.documents import Document\n\nlogger = setup_logger(__name__)\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n\n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n    \nclass PresentationGenerator:\n    def __init__(self, args=None, vectorstore_class=Chroma, prompt=None, embedding_model=None, model=None, parser=None, verbose=False):\n        default_config = {\n            \"model\": GoogleGenerativeAI(model=\"gemini-1.5-flash\"),\n            \"embedding_model\": GoogleGenerativeAIEmbeddings(model='models/embedding-001'),\n            \"parser\": JsonOutputParser(pydantic_object=FullPresentation),\n            \"prompt\": read_text_file(\"prompt/presentation-generator-prompt.txt\"),\n            \"prompt_without_context\": read_text_file(\"prompt/presentation-generator-without-context-prompt.txt\"),\n            \"vectorstore_class\": Chroma\n        }\n\n        self.prompt = prompt or default_config[\"prompt\"]\n        self.prompt_without_context = default_config[\"prompt_without_context\"]\n        self.model = model or default_config[\"model\"]\n        self.parser = parser or default_config[\"parser\"]\n        self.embedding_model = embedding_model or default_config[\"embedding_model\"]\n\n        self.vectorstore_class = vectorstore_class or default_config[\"vectorstore_class\"]\n        self.vectorstore, self.retriever, self.runner = None, None, None\n        self.args = args\n        self.verbose = verbose\n\n        if vectorstore_class is None: raise ValueError(\"Vectorstore must be provided\")\n        if args.grade_level is None: raise ValueError(\"Grade Level must be provided\")\n        if args.n_slides is None: raise ValueError(\"Number of Slides must be provided\")\n        if int(args.n_slides) < 1 or int(args.n_slides) > 10:\n            raise ValueError(\"Number must be between 1 and 10.\")\n        if args.topic is None: raise ValueError(\"Topic must be provided\")\n        if args.objectives is None: raise ValueError(\"Objectives must be provided\")\n        if args.lang is None: raise ValueError(\"Language must be provided\")\n\n    def compile_with_context(self, documents: List[Document]):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt,\n            input_variables=[\"attribute_collection\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        if self.runner is None:\n            logger.info(f\"Creating vectorstore from {len(documents)} documents\") if self.verbose else None\n            self.vectorstore = self.vectorstore_class.from_documents(documents, self.embedding_model)\n            logger.info(f\"Vectorstore created\") if self.verbose else None\n\n            self.retriever = self.vectorstore.as_retriever()\n            logger.info(f\"Retriever created successfully\") if self.verbose else None\n\n            self.runner = RunnableParallel(\n                {\"context\": self.retriever,\n                \"attribute_collection\": RunnablePassthrough()\n                }\n            )\n\n        chain = self.runner | prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n    \n    def compile_without_context(self):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt_without_context,\n            input_variables=[\"attribute_collection\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        chain = prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n\n    def generate_presentation(self, documents: Optional[List[Document]]):\n        logger.info(f\"Creating the Presentation\")\n\n        if(documents):\n            chain = self.compile_with_context(documents)\n        else:\n            chain = self.compile_without_context()\n\n        input_parameters = (\n            f\"Grade Level: {self.args.grade_level}, \"\n            f\"Number of Slides: {self.args.n_slides+1 if self.args.n_slides>9 else self.args.n_slides}, \"\n            f\"Topic: {self.args.topic}, \"\n            f\"Standard/Objectives: {self.args.objectives}, \"\n            f\"Additional Comments: {self.args.additional_comments}, \"\n            f\"Language (YOU MUST RESPOND IN THIS LANGUAGE): {self.args.lang}\"\n        )\n        logger.info(f\"Input parameters: {input_parameters}\")\n\n        response = chain.invoke(input_parameters)\n\n        logger.info(f\"Generated response: {response}\")\n\n        if(documents):\n            if self.verbose: print(f\"Deleting vectorstore\")\n            self.vectorstore.delete_collection()\n\n        return response\n\nclass Slide(BaseModel):\n    title: str = Field(..., description=\"The title of the Slide\")\n    content: str = Field(..., description=\"The content of the Slide. It must be the actual context, not simple indications\")\n    suggestions: str = Field(..., description=\"\"\"Suggestions for visual elements (e.g., charts, images, layouts) \n                             that enhance understanding and engagement (ONLY IF NEEDED).\"\"\")\n\nclass FullPresentation(BaseModel):\n    main_title: str = Field(..., description=\"The main title of the Presentation\")\n    list_slides: List[Slide] = Field(..., description=\"The full collection of slides about the Presentation\")"}
{"type": "source_file", "path": "app/tools/presentation_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/connect_with_them/tools.py", "content": "from pydantic import BaseModel, Field\nfrom typing import List, Dict, Optional\nimport os\nfrom langchain_core.documents import Document\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough, RunnableParallel\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\nfrom app.services.logger import setup_logger\n\nlogger = setup_logger(__name__)\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n    \n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n\nclass AIConnectWithThemGenerator:\n    def __init__(self, args=None, vectorstore_class=Chroma, prompt=None, embedding_model=None, model=None, parser=None, verbose=False):\n        default_config = {\n            \"model\": GoogleGenerativeAI(model=\"gemini-1.5-flash\"),\n            \"embedding_model\": GoogleGenerativeAIEmbeddings(model='models/embedding-001'),\n            \"parser\": JsonOutputParser(pydantic_object=RecommendationsOutput),\n            \"prompt\": read_text_file(\"prompt/connect-with-them-prompt.txt\"),\n            \"prompt_without_context\": read_text_file(\"prompt/connect-with-them-without-context-prompt.txt\"),\n            \"vectorstore_class\": Chroma\n        }\n\n        self.prompt = prompt or default_config[\"prompt\"]\n        self.prompt_without_context = default_config[\"prompt_without_context\"]\n        self.model = model or default_config[\"model\"]\n        self.parser = parser or default_config[\"parser\"]\n        self.embedding_model = embedding_model or default_config[\"embedding_model\"]\n\n        self.vectorstore_class = vectorstore_class or default_config[\"vectorstore_class\"]\n        self.vectorstore, self.retriever, self.runner = None, None, None\n        self.args = args\n        self.verbose = verbose\n\n        if vectorstore_class is None: raise ValueError(\"Vectorstore must be provided\")\n        if args.grade_level is None: raise ValueError(\"Grade Level must be provided\")\n        if args.task_description is None: raise ValueError(\"Task Description must be provided\")\n        if args.students_description is None: raise ValueError(\"Student Description Level must be provided\")\n        if args.lang is None: raise ValueError(\"Language must be provided\")\n\n\n    def compile_with_context(self, documents: List[Document]):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt,\n            input_variables=[\"attribute_collection\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        if self.runner is None:\n            logger.info(f\"Creating vectorstore from {len(documents)} documents\") if self.verbose else None\n            self.vectorstore = self.vectorstore_class.from_documents(documents, self.embedding_model)\n            logger.info(f\"Vectorstore created\") if self.verbose else None\n\n            self.retriever = self.vectorstore.as_retriever()\n            logger.info(f\"Retriever created successfully\") if self.verbose else None\n\n            self.runner = RunnableParallel(\n                {\"context\": self.retriever,\n                \"attribute_collection\": RunnablePassthrough()\n                }\n            )\n\n        chain = self.runner | prompt | self.model | self.parser\n\n        if self.verbose: logger.info(f\"Chain compilation complete\")\n\n        return chain\n    \n    def compile_without_context(self):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt_without_context,\n            input_variables=[\"attribute_collection\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        chain = prompt | self.model | self.parser\n\n        if self.verbose: logger.info(f\"Chain compilation complete\")\n\n        return chain\n\n    def generate_suggestion(self, documents: Optional[List[Document]]):\n        if self.verbose: logger.info(f\"Creating the AI Connect with Them suggestions\")\n\n        if(documents):\n            chain = self.compile_with_context(documents)\n        else:\n            chain = self.compile_without_context()\n\n        response = chain.invoke(f\"\"\"Grade Level: {self.args.grade_level},\n          Task Description: {self.args.task_description},\n          Student's Description: {self.args.students_description},\n          Language (YOU MUST RESPOND IN THIS LANGUAGE): {self.args.lang}\"\"\")\n\n        if(documents):\n            if self.verbose: logger.info(f\"Deleting vectorstore\")\n            self.vectorstore.delete_collection()\n    \n        return response\n\nclass Recommendation(BaseModel):\n    title: str = Field(..., description=\"The title of the recommendation\")\n    project_overview: str = Field(..., description=\"A detailed description of the project or activity recommendation. It must be a large paragraph.\")\n    rationale: str = Field(..., description=\"An explanation of why this recommendation is relevant to the students' interests or background.\")\n    difficulty_level: str = Field(..., description=\"The difficulty level of the project (e.g., easy, moderate, challenging).\")\n    required_tools: List[str] = Field(..., description=\"A list of tools, software, or resources required to complete the project.\")\n    estimated_time: str = Field(..., description=\"The estimated time to complete the project or activity.\")\n\nclass RecommendationsOutput(BaseModel):\n    recommendations: List[Recommendation] = Field(..., description=\"A list of personalized recommendations based on the input.\")"}
{"type": "source_file", "path": "app/tools/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/multiple_choice_quiz_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/ai_resistant_assignment_generator/core.py", "content": "from app.utils.document_loaders import get_docs\nfrom app.tools.ai_resistant_assignment_generator.tools import AIResistantAssignmentGenerator\nfrom app.services.schemas import AIResistantArgs\nfrom app.services.logger import setup_logger\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\n\nlogger = setup_logger()\n\ndef executor(grade_level: str,\n             assignment_description: str,\n             file_url: str,\n             file_type: str,\n             lang: str, \n             verbose=False):\n    \n    try:\n        logger.info(f\"Generating docs. from {file_type}\")\n\n        if (file_url and file_type):\n            logger.info(f\"Generating docs. from {file_type}\")\n            docs = get_docs(file_url, file_type, True)\n        else:\n            docs = None\n            \n        ai_resistant_args = AIResistantArgs(\n            assignment=assignment_description,\n            grade_level=grade_level,\n            file_type=file_type,\n            file_url=file_url,\n            lang=lang\n        )\n\n        output = AIResistantAssignmentGenerator(args=ai_resistant_args, verbose=verbose).create_assignments(docs)\n\n        logger.info(f\"AI-Resistant Assignments generated successfully\")\n\n    except LoaderError as e:\n        error_message = e\n        logger.error(f\"Error in AI Resistant Assignment Generator Pipeline -> {error_message}\")\n        raise ToolExecutorError(error_message)\n    \n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)\n    \n    return output\n\n"}
{"type": "source_file", "path": "app/tools/notes_generator/core.py", "content": "from app.tools.notes_generator.tools import NoteGeneratorPipeline\nfrom app.services.schemas import NoteGeneratorArgs\nfrom app.utils.document_loaders import get_docs\nfrom app.services.logger import setup_logger\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\nfrom langchain_core.documents import Document\nlogger = setup_logger()\n\ndef executor(\n    focus: str,\n    page_layout: str,\n    text_input: str,\n    file_type: str,\n    file_url: str,\n    lang: str,\n    verbose=True\n):\n    \"\"\"\n    Executor function for the Notes Generator tool.\n    \n    Args:\n        focus (str): The focus or topic of the notes.\n        page_layout (str): The structure or template for the notes (e.g., bullet points, paragraphs, tables).\n        text_input (str): Direct text input for note generation.\n        file_type (str): Type of the uploaded file (e.g., CSV, PDF, DOCX, PPT, Plain Text).\n        file_url (str): URL of the uploaded file.\n        lang (str): Language of the input.\n        verbose (bool): Flag for verbose logging.\n    \n    Returns:\n        dict: Generated notes in the specified format.\n    \n    Raises:\n        ToolExecutorError: If there is an error during execution.\n        ValueError: If an unexpected error occurs.\n    \"\"\"\n    try:\n        # Check if page layout is provided\n        if not page_layout:\n            raise ValueError(\"No page layout provided for note generation.\")\n        \n        # Check if any input is provided for note generation\n        if not any([text_input, file_url,focus,file_type]):\n            raise ValueError(\"No input provided for note generation.\")        \n            \n        # Check if url is provided without file type\n        if file_url and not file_type: \n            raise ValueError(\"No file type provided for document loading.\") \n        \n         # Log file type if provided\n        if file_type:\n            logger.info(f\"Generating docs from {file_type} file.\")\n\n        # Load documents if a file URL is provided\n        docs = None\n        \n           \n        if file_url and file_type:\n            logger.info(f\"Loading documents from {file_url}.\")\n            docs = get_docs(file_url, file_type, True)\n        \n\n        # If user provides text, add it as a Document\n        if text_input:\n            logger.info(\"Using provided text input for note generation.\")\n            text_doc = Document(page_content=text_input)\n            if docs:  \n                docs.append(text_doc)  # Append to existing list\n            else:\n                docs = [text_doc]  # Create a new list with the text\n            \n            print(\"length of docs;\",len(docs))\n\n        # Initialize the NoteGeneratorArgs schema\n        note_generator_args = NoteGeneratorArgs(\n            focus=focus,\n            page_layout=page_layout,\n            text_input=text_input,\n            file_type=file_type,\n            file_url=file_url,\n            lang=lang\n        )\n    \n        # Initialize the NoteGeneratorPipeline\n        note_generator = NoteGeneratorPipeline(args=note_generator_args, verbose=verbose)\n\n        # Generate notes\n        output = note_generator.generate_notes(docs)\n\n        logger.info(\"Notes generated successfully.\")\n        return output\n\n    except LoaderError as e:\n        error_message = f\"Error loading documents: {e}\"\n        logger.error(error_message)\n        raise ToolExecutorError(error_message)\n\n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)"}
{"type": "source_file", "path": "app/tools/presentation_generator/core.py", "content": "from app.utils.document_loaders import get_docs\nfrom app.tools.presentation_generator.tools import PresentationGenerator\nfrom app.services.schemas import PresentationGeneratorInput\nfrom app.services.logger import setup_logger\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\n\nlogger = setup_logger()\n\ndef executor(grade_level: str,\n             n_slides: int,\n             topic: str,\n             objectives: str,\n             additional_comments: str,\n             objectives_file_url: str,\n             objectives_file_type: str,\n             additional_comments_file_url: str,\n             additional_comments_file_type: str,\n             lang: str, \n             verbose=False):\n\n    try:\n        if(objectives_file_type):\n            logger.info(f\"Generating docs. from {objectives_file_type}\")\n        if(additional_comments_file_type):\n            logger.info(f\"Generating docs. from {additional_comments_file_type}\")\n\n        docs = None\n\n        def fetch_docs(file_url, file_type):\n            return get_docs(file_url, file_type, True) if file_url and file_type else None\n\n        objectives_docs = fetch_docs(objectives_file_url, objectives_file_type)\n        additional_comments_docs = fetch_docs(additional_comments_file_url, additional_comments_file_type)\n\n        docs = (\n            objectives_docs + additional_comments_docs\n            if objectives_docs and additional_comments_docs\n            else objectives_docs or additional_comments_docs\n        )\n\n        presentation_generator_args = PresentationGeneratorInput(\n            grade_level=grade_level,\n            n_slides=n_slides,\n            topic=topic,\n            objectives=objectives,\n            additional_comments=additional_comments,\n            objectives_file_url=objectives_file_url,\n            objectives_file_type=objectives_file_type,\n            additional_comments_file_url=additional_comments_file_url,\n            additional_comments_file_type=additional_comments_file_type,\n            lang=lang\n        )\n\n        output = PresentationGenerator(args=presentation_generator_args, verbose=verbose).generate_presentation(docs)\n\n        logger.info(f\"Presentation generated successfully\")\n\n    except LoaderError as e:\n        error_message = e\n        logger.error(f\"Error in Presentation Generator Pipeline -> {error_message}\")\n        raise ToolExecutorError(error_message)\n\n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)\n\n    return output"}
{"type": "source_file", "path": "app/tools/lesson_plan_generator/core.py", "content": "from app.tools.lesson_plan_generator.tools import LessonPlanGeneratorPipeline\nfrom app.services.schemas import LessonPlanGeneratorArgs\nfrom app.utils.document_loaders import get_docs\nfrom app.services.logger import setup_logger\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\n\nlogger = setup_logger()\n\ndef executor(grade_level: str,\n             topic: str,\n             objectives: str,\n             additional_customization: str,\n             objectives_file_url: str,\n             objectives_file_type: str,\n             additional_customization_file_url: str,\n             additional_customization_file_type: str,\n             lang: str, \n             verbose=False):\n    \n    try:\n        if objectives_file_type:\n            logger.info(f\"Generating docs. from {objectives_file_type}\")\n        if additional_customization_file_type:\n            logger.info(f\"Generating docs. from {additional_customization_file_type}\")\n\n        docs = None\n\n        def fetch_docs(file_url, file_type):\n            return get_docs(file_url, file_type, True) if file_url and file_type else None\n\n        objectives_docs = fetch_docs(objectives_file_url, objectives_file_type)\n        additional_customization_docs = fetch_docs(additional_customization_file_url, additional_customization_file_type)\n\n        docs = (\n            objectives_docs + additional_customization_docs\n            if objectives_docs and additional_customization_docs\n            else objectives_docs or additional_customization_docs\n        )\n\n        lesson_plan_generator_args = LessonPlanGeneratorArgs(\n            grade_level=grade_level,\n            topic=topic,\n            objectives=objectives,\n            additional_customization=additional_customization,\n            objectives_file_url=objectives_file_url,\n            objectives_file_type=objectives_file_type,\n            additional_customization_file_url=additional_customization_file_url,\n            additional_customization_file_type=additional_customization_file_type,\n            lang=lang\n        )\n\n        output = LessonPlanGeneratorPipeline(args=lesson_plan_generator_args, verbose=verbose).generate_lesson_plan(docs)\n\n        logger.info(f\"Lesson Plan generated successfully\")\n\n    except LoaderError as e:\n        error_message = e\n        logger.error(f\"Error in Lesson Plan Generator Pipeline -> {error_message}\")\n        raise ToolExecutorError(error_message)\n    \n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)\n    \n    return output\n"}
{"type": "source_file", "path": "app/tools/flashcards_generator/tools.py", "content": "from langchain_core.documents import Document\nfrom langchain_community.document_loaders.csv_loader import CSVLoader\nfrom langchain_community.document_loaders import (\n    YoutubeLoader,\n    PyPDFLoader,\n    TextLoader,\n    UnstructuredURLLoader,\n    UnstructuredPowerPointLoader,\n    Docx2txtLoader,\n    UnstructuredExcelLoader,\n    UnstructuredXMLLoader\n)\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom app.utils.allowed_file_extensions import FileType\nfrom app.api.error_utilities import FileHandlerError, ImageHandlerError\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain.prompts import PromptTemplate\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain.chains.summarize import load_summarize_chain\nfrom pydantic import BaseModel, Field\nfrom app.api.error_utilities import VideoTranscriptError\nfrom langchain_core.messages import HumanMessage\nfrom fastapi import HTTPException\nfrom app.services.logger import setup_logger\nimport os\nimport tempfile\nimport uuid\nimport requests\nimport gdown\n\nSTRUCTURED_TABULAR_FILE_EXTENSIONS = {\"csv\", \"xls\", \"xlsx\", \"gsheet\", \"xml\"}\n\nlogger = setup_logger(__name__)\n\n# AI Model\nmodel = GoogleGenerativeAI(model=\"gemini-1.0-pro\")\n\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size = 1000,\n    chunk_overlap = 0\n)\n\ndef build_chain(prompt: str):\n    prompt_template = read_text_file(prompt)\n    summarize_prompt = PromptTemplate.from_template(prompt_template)\n\n    summarize_model = GoogleGenerativeAI(model=\"gemini-1.5-flash\")\n        \n    chain = summarize_prompt | summarize_model \n    return chain\n\ndef get_summary(file_url: str, file_type: str, verbose=False):\n    file_type = file_type.lower()\n    try:\n        file_loader = file_loader_map[FileType(file_type)]\n        full_content = file_loader(file_url, verbose)\n        if file_type in STRUCTURED_TABULAR_FILE_EXTENSIONS:\n            prompt = r\"prompt/summarize-structured-tabular-data-prompt.txt\"\n        else:\n            prompt = r\"prompt/summarize-text-prompt.txt\"\n            \n        chain = build_chain(prompt)\n        return chain.invoke(full_content)\n        \n    except Exception as e:\n        logger.error(e)\n        logger.error(f\"Unsupported file type: {file_type}\")\n        raise FileHandlerError(f\"Unsupported file type\", file_url) from e\n\ndef generate_flashcards(summary: str, lang:str, verbose=False) -> list:\n    # Receive the summary from the map reduce chain and generate flashcards\n    parser = JsonOutputParser(pydantic_object=Flashcard)\n    \n    if verbose: logger.info(f\"Beginning to process flashcards from summary\")\n    \n    template = read_text_file(r\"prompt/flashcards-generator-prompt.txt\")\n    examples = read_text_file(r\"prompt/examples.txt\")\n    \n    cards_prompt = PromptTemplate(\n        template=template,\n        input_variables=[\"summary\", \"examples\", \"lang\"],\n        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n    )\n    \n    cards_chain = cards_prompt | model | parser\n    \n    try:\n        response = cards_chain.invoke({\"summary\": summary, \"examples\": examples, \"lang\": lang})\n    except Exception as e:\n        logger.error(f\"Failed to generate flashcards: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Failed to generate flashcards from LLM\")\n    \n    return response\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n    \n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n    \nclass FileHandler:\n    def __init__(self, file_loader, file_extension):\n        self.file_loader = file_loader\n        self.file_extension = file_extension\n\n    def load(self, url):\n        # Generate a unique filename with a UUID prefix\n        unique_filename = f\"{uuid.uuid4()}.{self.file_extension}\"\n\n        # Download the file from the URL and save it to a temporary file\n        response = requests.get(url)\n        response.raise_for_status()  # Ensure the request was successful\n\n        with tempfile.NamedTemporaryFile(delete=False, prefix=unique_filename) as temp_file:\n            temp_file.write(response.content)\n            temp_file_path = temp_file.name\n\n        # Use the file_loader to load the documents\n        try:\n            loader = self.file_loader(file_path=temp_file_path)\n        except Exception as e:\n            logger.error(f\"No such file found at {temp_file_path}\")\n            raise FileHandlerError(f\"No file found\", temp_file_path) from e\n        \n        try:\n            documents = loader.load()\n        except Exception as e:\n            logger.error(f\"File content might be private or unavailable or the URL is incorrect.\")\n            raise FileHandlerError(f\"No file content available\", temp_file_path) from e\n\n        # Remove the temporary file\n        os.remove(temp_file_path)\n\n        return documents\n\ndef load_pdf_documents(pdf_url: str, verbose=False):\n    pdf_loader = FileHandler(PyPDFLoader, \"pdf\")\n    docs = pdf_loader.load(pdf_url)\n\n    if docs:\n        split_docs = splitter.split_documents(docs)\n\n        if verbose:\n            logger.info(f\"Found PDF file\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n\n        return full_content\n        \n\ndef load_csv_documents(csv_url: str, verbose=False):\n    csv_loader = FileHandler(CSVLoader, \"csv\")\n    docs = csv_loader.load(csv_url)\n\n    if docs:\n        if verbose:\n            logger.info(f\"Found CSV file\")\n            logger.info(f\"Splitting documents into {len(docs)} chunks\")\n\n        full_content = [doc.page_content for doc in docs]\n        full_content = \" \".join(full_content)\n\n        return full_content\n\ndef load_txt_documents(notes_url: str, verbose=False):\n    notes_loader = FileHandler(TextLoader, \"txt\")\n    docs = notes_loader.load(notes_url)\n\n    if docs: \n        \n        split_docs = splitter.split_documents(docs)\n        \n        if verbose:\n            logger.info(f\"Found TXT file\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\ndef load_md_documents(notes_url: str, verbose=False):\n    notes_loader = FileHandler(TextLoader, \"md\")\n    docs = notes_loader.load(notes_url)\n    \n    if docs:\n        \n        split_docs = splitter.split_documents(docs)\n\n        if verbose:\n            logger.info(f\"Found MD file\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\ndef load_url_documents(url: str, verbose=False):\n    url_loader = UnstructuredURLLoader(urls=[url])\n    docs = url_loader.load()\n\n    if docs:\n        split_docs = splitter.split_documents(docs)\n\n        if verbose:\n            logger.info(f\"Found URL\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\ndef load_pptx_documents(pptx_url: str, verbose=False):\n    pptx_handler = FileHandler(UnstructuredPowerPointLoader, 'pptx')\n\n    docs = pptx_handler.load(pptx_url)\n    if docs: \n\n        split_docs = splitter.split_documents(docs)\n\n        if verbose:\n            logger.info(f\"Found PPTX file\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n        \n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n\n        return full_content\n        \ndef load_docx_documents(docx_url: str, verbose=False):\n    docx_handler = FileHandler(Docx2txtLoader, 'docx')\n    docs = docx_handler.load(docx_url)\n    if docs: \n\n        split_docs = splitter.split_documents(docs)\n        \n        if verbose:\n            logger.info(f\"Found DOCX file\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\ndef load_xls_documents(xls_url: str, verbose=False):\n    xls_handler = FileHandler(UnstructuredExcelLoader, 'xls')\n    docs = xls_handler.load(xls_url)\n    if docs: \n\n        split_docs = splitter.split_documents(docs)\n        \n        if verbose:\n            logger.info(f\"Found XLS file\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\ndef load_xlsx_documents(xlsx_url: str, verbose=False):\n    xlsx_handler = FileHandler(UnstructuredExcelLoader, 'xlsx')\n    docs = xlsx_handler.load(xlsx_url)\n    if docs: \n\n        split_docs = splitter.split_documents(docs)\n        \n        if verbose:\n            logger.info(f\"Found XLSX file\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\ndef load_xml_documents(xml_url: str, verbose=False):\n    xml_handler = FileHandler(UnstructuredXMLLoader, 'xml')\n    docs = xml_handler.load(xml_url)\n    if docs: \n\n        split_docs = splitter.split_documents(docs)\n        \n        if verbose:\n            logger.info(f\"Found XML file\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\n\nclass FileHandlerForGoogleDrive:\n    def __init__(self, file_loader, file_extension='docx'):\n        self.file_loader = file_loader\n        self.file_extension = file_extension\n\n    def load(self, url):\n        try:\n            with tempfile.TemporaryDirectory() as temp_dir:\n                unique_filename = os.path.join(temp_dir, f\"{uuid.uuid4()}.{self.file_extension}\")\n                \n                logger.info(f\"Downloading file from URL: {url}\")\n                \n                try:\n                    gdown.download(url=url, output=unique_filename, fuzzy=True)\n                    logger.info(f\"File downloaded successfully to {unique_filename}\")\n                except Exception as e:\n                    logger.error(e)\n                    logger.error(\"File content might be private or unavailable, or the URL is incorrect.\")\n                    raise FileHandlerError(\"No file content available\") from e\n\n                try:\n                    loader = self.file_loader(file_path=unique_filename)\n                except Exception as e:\n                    logger.error(f\"No such file found at {unique_filename}\")\n                    raise FileHandlerError(\"No file found\", unique_filename) from e\n\n                try:\n                    documents = loader.load()\n                    logger.info(\"File loaded successfully.\")\n                except Exception as e:\n                    logger.error(e)\n                    logger.error(\"Error loading file content.\")\n                    raise FileHandlerError(\"No file content available\") from e\n\n                return documents\n        except Exception as e:\n            logger.error(\"An unexpected error occurred during the file handling process.\")\n            raise e\n    \ndef load_gdocs_documents(drive_folder_url: str, verbose=False):\n\n    gdocs_loader = FileHandlerForGoogleDrive(Docx2txtLoader)\n\n    docs = gdocs_loader.load(drive_folder_url)\n    \n    if docs: \n\n        split_docs = splitter.split_documents(docs)\n        \n        if verbose:\n            logger.info(f\"Found Google Docs files\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        return full_content\n    \ndef load_gsheets_documents(drive_folder_url: str, verbose=False):\n    gsheets_loader = FileHandlerForGoogleDrive(UnstructuredExcelLoader, 'xlsx')\n    docs = gsheets_loader.load(drive_folder_url)\n    if docs: \n\n        split_docs = splitter.split_documents(docs)\n\n        if verbose:\n            logger.info(f\"Found Google Sheets files\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\ndef load_gslides_documents(drive_folder_url: str, verbose=False):\n    gslides_loader = FileHandlerForGoogleDrive(UnstructuredPowerPointLoader, 'pptx')\n    docs = gslides_loader.load(drive_folder_url)\n    if docs: \n\n        split_docs = splitter.split_documents(docs)\n\n        if verbose:\n            logger.info(f\"Found Google Slides files\")\n            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n\n        full_content = [doc.page_content for doc in split_docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n    \ndef load_gpdf_documents(drive_folder_url: str, verbose=False):\n\n    gpdf_loader = FileHandlerForGoogleDrive(PyPDFLoader,'pdf')\n\n    docs = gpdf_loader.load(drive_folder_url)\n    if docs: \n\n        if verbose:\n            logger.info(f\"Found Google PDF files\")\n            logger.info(f\"Splitting documents into {len(docs)} chunks\")\n\n        full_content = [doc.page_content for doc in docs]\n        full_content = \" \".join(full_content)\n        \n        return full_content\n\n\ndef summarize_transcript_youtube_url(youtube_url: str, max_video_length=600, verbose=False) -> str:\n    try:\n        loader = YoutubeLoader.from_youtube_url(youtube_url, add_video_info=False)\n    except Exception as e:\n        logger.error(f\"No such video found at {youtube_url}\")\n        raise VideoTranscriptError(f\"No video found\", youtube_url) from e\n    \n    try:\n        docs = loader.load()\n    except Exception as e:\n        logger.error(f\"Video transcript might be private or unavailable in 'en' or the URL is incorrect.\")\n        raise VideoTranscriptError(f\"No video transcripts available\", youtube_url) from e\n    \n    split_docs = splitter.split_documents(docs)\n    \n    full_transcript = [doc.page_content for doc in split_docs]\n    full_transcript = \" \".join(full_transcript)\n\n\n    if verbose:\n        logger.info(f\"Found video\")\n        logger.info(f\"Combined documents into a single string.\")\n        logger.info(f\"Beginning to process transcript...\")\n    \n    prompt_template = read_text_file(r\"prompt/summarize-youtube-video-prompt.txt\")\n    summarize_prompt = PromptTemplate.from_template(prompt_template)\n\n    summarize_model = GoogleGenerativeAI(model=\"gemini-1.5-flash\")\n    \n    chain = summarize_prompt | summarize_model \n    \n    return chain.invoke(full_transcript)\n\nfile_loader_map = {\n    FileType.PDF: load_pdf_documents,\n    FileType.CSV: load_csv_documents,\n    FileType.TXT: load_txt_documents,\n    FileType.MD: load_md_documents,\n    FileType.URL: load_url_documents,\n    FileType.PPTX: load_pptx_documents,\n    FileType.DOCX: load_docx_documents,\n    FileType.XLS: load_xls_documents,\n    FileType.XLSX: load_xlsx_documents,\n    FileType.XML: load_xml_documents,\n    FileType.GDOC: load_gdocs_documents,\n    FileType.GSHEET: load_gsheets_documents,\n    FileType.GSLIDE: load_gslides_documents,\n    FileType.GPDF: load_gpdf_documents\n}\n\nllm_for_img = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n\ndef generate_concepts_from_img(img_url, lang):\n    parser = JsonOutputParser(pydantic_object=Flashcard)\n    message = HumanMessage(\n    content=[\n            {\n                \"type\": \"text\",\n                \"text\": \"Give me more than 5 key concepts of what you see in the image\",\n            },  # You can optionally provide text parts\n            {\"type\": \"image_url\", \"image_url\": img_url},\n            {\"type\": \"text\", \"text\": f\"In this format: {parser.get_format_instructions()}\"},\n            {\"type:\": \"text\", \"text\": f\"You must provide the concept, definition in {lang} language\"}\n        ]\n    )\n\n    try:\n        response = llm_for_img.invoke([message]).content\n        logger.info(f\"Generated concepts: {response}\")\n    except Exception as e:\n        logger.error(f\"Error processing the request due to Invalid Content or Invalid Image URL\")\n        raise ImageHandlerError(f\"Error processing the request\", img_url) from e\n    \n    try:\n        response = parser.parse(response)\n    except Exception as e:\n        response = []\n        \n    return response\n\nclass Flashcard(BaseModel):\n    concept: str = Field(description=\"The concept of the flashcard\")\n    definition: str = Field(description=\"The definition of the flashcard\")"}
{"type": "source_file", "path": "app/tools/notes_generator/tools.py", "content": "from langchain_chroma import Chroma\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_core.documents import Document\nfrom typing import Optional, List, Union\nfrom app.services.logger import setup_logger\nfrom pydantic import BaseModel, Field\n\nlogger = setup_logger(__name__)\n\n# Define Models to Match the Presentation Tool\nclass BulletPoints(BaseModel):\n    title: str = Field(..., description=\"The title of the notes section\")\n    points: List[str] = Field(..., description=\"Key bullet points extracted from the content\")\n\nclass Paragraph(BaseModel):\n    title: str = Field(..., description=\"The title of the notes section\")\n    content: str = Field(..., description=\"A well-structured paragraph summarizing the content\")\n\nclass Table(BaseModel):\n    title: str = Field(..., description=\"The title of the table section\")\n    headers: List[str] = Field(..., description=\"Column headers for the table\")\n    rows: List[List[str]] = Field(..., description=\"Table rows containing structured data\")\nclass GenerateNotesOutput(BaseModel):\n    title: str = Field(..., description=\"Title of the generated notes\")\n    notes: BulletPoints | Paragraph | Table = Field(..., description=\"Structured notes generated based on the content\")\n\nclass NoteGeneratorPipeline:\n    def __init__(self, args=None , verbose=False):       \n        self.args = args\n        self.verbose = verbose\n        \"\"\"Dynamically selects the correct output schema based on page_layout.\"\"\"\n        layout_map = {\n            \"bullet_points\": BulletPoints,\n            \"paragraph\": Paragraph,\n            \"table\": Table\n        }\n\n        selected_format = layout_map.get(self.args.page_layout)\n        self.parser = JsonOutputParser(pydantic_object=selected_format)   \n        \n        self.model = GoogleGenerativeAI(model=\"gemini-1.5-pro\")\n        self.vectorstore_class = Chroma\n        self.vectorstore = None\n        self.retriever = None\n\n    def compile_vectorstore(self, documents: List[Document]):\n        \"\"\"Creates a vector store for document retrieval.\"\"\"\n        if self.verbose:\n            logger.info(\"Creating vectorstore from documents...\")\n            \n        self.vectorstore = self.vectorstore_class.from_documents(\n            documents, \n            GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n        )\n        self.retriever = self.vectorstore.as_retriever()\n        \n        if self.verbose:\n            logger.info(\"Vectorstore and retriever created successfully.\")\n\n    def generate_context(self, query):\n        \"\"\"Retrieves relevant context from the vector database.\"\"\"\n        return self.retriever.invoke(query)\n\n    def compile_pipeline(self):\n        \"\"\"Creates prompt templates for different layouts.\"\"\"\n        \"\"\"Creates prompt templates for structured note generation.\"\"\"\n        prompt_template = PromptTemplate(\n            template=(\n                \"Generate structured notes in {layout} format focusing on: {focus}. \"\n                \"Use the following text: {context}. \"\n                \"Ensure clarity, coherence, and well-structured content. \"\n                \"Respond in the {lang} language. \"\n                \"Your response must follow this JSON format: {format_instructions}\"\n             ),\n            input_variables=[\"layout\", \"focus\", \"context\", \"lang\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()},\n        )\n        return prompt_template | self.model | self.parser\n\n    def generate_notes(self, documents: Optional[List[Document]]):\n        \"\"\"Generates notes based on the selected layout.\"\"\"\n        if documents:\n            self.compile_vectorstore(documents)\n            query = \"Provide general context for the topic to create notes.\"\n            context = self.generate_context(query)\n        else:\n            context = \"\"\n\n        # Compile the processing pipeline\n        pipeline = self.compile_pipeline()\n\n        # Prepare inputs for the AI model\n        inputs = {\n            \"layout\": self.args.page_layout,\n            \"focus\": self.args.focus,\n            \"context\": context,\n            \"lang\": self.args.lang,\n        }\n\n        try:\n            result = pipeline.invoke(inputs)\n            \n            if self.verbose:\n                logger.info(\"Notes successfully generated.\")\n            return result\n        except Exception as e:\n            logger.error(f\"Error generating notes: {e}\")\n            raise ValueError(\"Failed to generate notes.\")\n"}
{"type": "source_file", "path": "app/tools/connect_with_them/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/ai_resistant_assignment_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/notes_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/rubric_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/presentation_generator_updated/outline_generator/core.py", "content": "from app.utils.document_loaders import get_docs\nfrom app.services.schemas import OutlineGeneratorInput\nfrom app.services.logger import setup_logger\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\nfrom app.tools.presentation_generator_updated.outline_generator.tools import OutlineGenerator\nlogger = setup_logger()\n\ndef executor(\n             n_slides: int,\n             topic: str,\n             instructional_level: str,\n             file_url: str,\n             file_type: str,\n             lang: str, \n             verbose=False):\n\n    try:\n        if (not (n_slides and topic and instructional_level)):\n            logger.info(f\"Missing required inputs.\")\n            raise ValueError(\"Missing required inputs\")\n         \n        if(n_slides and topic and instructional_level):\n            logger.info(f\"Generating slide outlines. from {topic} for {instructional_level} level\")\n            #CHECKING IF BOTH FILE UPLOAD URL AND FILE UPLOAD TYPE ARE PROVIDED\n        if bool(file_url) != bool(file_type):\n            missing = \"file_type\" if file_url else \"file_url\"\n            provided = \"file_url\" if file_url else \"file_type\"\n            message = f\"{provided} provided but {missing} is missing\"\n            logger.info(message)\n            raise ValueError(message)\n        if(file_url and file_type):\n            logger.info(f\"Fetching documents from {file_url} of type {file_type}\")\n\n        docs = None\n        \n\n        def fetch_docs(file_url, file_type):\n            return get_docs(file_url, file_type, True) if file_url and file_type else None\n\n        docs = fetch_docs(file_type=file_type, file_url=file_url)        \n\n\n        presentation_generator_args = OutlineGeneratorInput(\n            instructional_level=instructional_level,\n            n_slides=n_slides,\n            topic=topic,\n            file_url=file_url,\n            file_type=file_type,\n            lang=lang\n        )\n     \n        output = OutlineGenerator(args=presentation_generator_args, verbose=verbose).generate_outline(docs)\n\n        logger.info(f\"Presentation generated successfully\")\n\n    except LoaderError as e:\n        error_message = e\n        logger.error(f\"Error in Presentation Generator Pipeline -> {error_message}\")\n        raise ToolExecutorError(error_message)\n\n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)\n\n    return output"}
{"type": "source_file", "path": "app/tools/presentation_generator_updated/slide_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/presentation_generator_updated/outline_generator/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/rubric_generator/core.py", "content": "from app.services.logger import setup_logger\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\nfrom app.services.schemas import RubricGeneratorArgs\nfrom app.utils.document_loaders import get_docs\nfrom app.tools.rubric_generator.tools import RubricGenerator\n\nlogger = setup_logger()\n\ndef executor(grade_level: str,\n             point_scale: int,\n             objectives: str,\n             assignment_description: str,\n             objectives_file_url: str,\n             objectives_file_type: str,\n             assignment_description_file_url: str,\n             assignment_description_file_type: str,\n             lang: str,\n             verbose=False):\n    try:\n        if objectives_file_type: \n            logger.info(f\"Generating docs from {objectives_file_type}\")\n        if assignment_description_file_type: \n            logger.info(f\"Generating docs from {assignment_description_file_type}\")\n\n        docs = None\n\n        def fetch_docs(file_url, file_type):\n            return get_docs(file_url, file_type, True) if file_url and file_type else None\n\n        objectives_docs = fetch_docs(objectives_file_url, objectives_file_type)\n        assignment_desc_comments_docs = fetch_docs(assignment_description_file_url, assignment_description_file_type)\n\n        docs = (\n            objectives_docs + assignment_desc_comments_docs\n            if objectives_docs and assignment_desc_comments_docs\n            else objectives_docs or assignment_desc_comments_docs\n        )\n        \n        # Create and return the Rubric\n        rubric_generator_args = RubricGeneratorArgs(\n            grade_level=grade_level,\n            point_scale=point_scale,\n            objectives=objectives,\n            assignment_description=assignment_description,\n            objectives_file_url=objectives_file_url,\n            objectives_file_type=objectives_file_type,\n            assignment_description_file_url=assignment_description_file_url,\n            assignment_description_file_type=assignment_description_file_type,\n            lang=lang\n        )\n        \n        output = RubricGenerator(args=rubric_generator_args, verbose=verbose).create_rubric(docs)\n\n        logger.info(f\"Rubric generated successfully\")\n    \n    except LoaderError as e:\n        error_message = e\n        logger.error(f\"Error in Rubric Genarator Pipeline -> {error_message}\")\n        raise ToolExecutorError(error_message)\n    \n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)\n    \n    return output"}
{"type": "source_file", "path": "app/tools/presentation_generator_updated/slide_generator/core.py", "content": "\nfrom app.api.error_utilities import LoaderError, ToolExecutorError\nfrom typing import List\nfrom app.services.schemas import SlideGeneratorInput\nfrom app.tools.presentation_generator_updated.slide_generator.tools import SlideGenerator\nfrom app.services.logger import setup_logger\nlogger = setup_logger()\n\n\ndef executor(\n             slides_titles: List[str],\n             topic: str,\n             instructional_level: str,\n             lang: str, \n             verbose=False):\n    try: \n        if (not (slides_titles and topic and instructional_level)):\n            logger.info(f\"Missing required inputs.\")\n            raise ValueError(\"Missing required inputs\")\n         \n        if(slides_titles and topic and instructional_level):\n            logger.info(f\"Generating slide outlines. from {topic} for {instructional_level} level\")\n        \n       \n        slide_generator_args = SlideGeneratorInput(\n            slides_titles=slides_titles,\n            instructional_level=instructional_level, \n            topic=topic,\n            lang=lang\n        )\n        output = SlideGenerator(args=slide_generator_args, verbose=verbose).generate_slides()\n        logger.info(f\"Slides generated successfully\")\n    except LoaderError as e:\n        error_message = e\n        logger.error(f\"Error in Slide Generator Pipeline -> {error_message}\")\n        raise ToolExecutorError(error_message)\n    except Exception as e:\n        error_message = f\"Error in executor: {e}\"\n        logger.error(error_message)\n        raise ValueError(error_message)\n    return output"}
{"type": "source_file", "path": "app/tools/ai_resistant_assignment_generator/tools.py", "content": "from pydantic import BaseModel, Field\nfrom typing import List, Dict, Optional\nimport os\nfrom langchain_core.documents import Document\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough, RunnableParallel\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\nfrom app.services.logger import setup_logger\n\nlogger = setup_logger(__name__)\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n    \n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n    \nclass AIResistantAssignmentGenerator:\n    def __init__(self, args=None, vectorstore_class=Chroma, prompt=None, embedding_model=None, model=None, parser=None, verbose=False):\n        default_config = {\n            \"model\": GoogleGenerativeAI(model=\"gemini-1.5-flash\"),\n            \"embedding_model\": GoogleGenerativeAIEmbeddings(model='models/embedding-001'),\n            \"parser\": JsonOutputParser(pydantic_object=AIResistantOutput),\n            \"prompt\": read_text_file(\"prompt/ai-resistant-prompt.txt\"),\n            \"prompt_without_context\": read_text_file(\"prompt/ai-resistant-without-context-prompt.txt\"),\n            \"vectorstore_class\": Chroma\n        }\n\n        self.prompt = prompt or default_config[\"prompt\"]\n        self.prompt_without_context = default_config[\"prompt_without_context\"]\n        self.model = model or default_config[\"model\"]\n        self.parser = parser or default_config[\"parser\"]\n        self.embedding_model = embedding_model or default_config[\"embedding_model\"]\n\n        self.vectorstore_class = vectorstore_class or default_config[\"vectorstore_class\"]\n        self.vectorstore, self.retriever, self.runner = None, None, None\n        self.args = args\n        self.verbose = verbose\n\n        if vectorstore_class is None: raise ValueError(\"Vectorstore must be provided\")\n        if args.assignment is None: raise ValueError(\"Assignment must be provided\")\n        if args.grade_level is None: raise ValueError(\"Grade Level must be provided\")\n        if args.lang is None: raise ValueError(\"Language must be provided\")\n\n\n    def compile_with_docs(self, documents: List[Document]):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt,\n            input_variables=[\"attribute_collection\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        if self.runner is None:\n            logger.info(f\"Creating vectorstore from {len(documents)} documents\") if self.verbose else None\n            self.vectorstore = self.vectorstore_class.from_documents(documents, self.embedding_model)\n            logger.info(f\"Vectorstore created\") if self.verbose else None\n\n            self.retriever = self.vectorstore.as_retriever()\n            logger.info(f\"Retriever created successfully\") if self.verbose else None\n\n            self.runner = RunnableParallel(\n                {\"context\": self.retriever,\n                \"attribute_collection\": RunnablePassthrough()\n                }\n            )\n\n        chain = self.runner | prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n    \n    def compile_without_docs(self):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt_without_context,\n            input_variables=[\"attribute_collection\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        chain = prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n\n    def create_assignments(self, documents: Optional[List[Document]]):\n        logger.info(f\"Creating the AI-Resistant assignments\")\n\n        if(documents):\n            chain = self.compile_with_docs(documents)\n        else:\n            chain = self.compile_without_docs()\n\n        response = chain.invoke(f\"\"\"Assignment Description: {self.args.assignment}, \n                                Grade Level: {self.args.grade_level}, \n                                Language (YOU MUST RESPOND IN THIS LANGUAGE): {self.args.lang}\"\"\")\n\n        if(documents):\n            if self.verbose: print(f\"Deleting vectorstore\")\n            self.vectorstore.delete_collection()\n\n        return response\n\nclass AIResistanceIdea(BaseModel):\n    title: str = Field(..., description=\"The main title of the idea\")\n    assignment_description: str = Field(..., description=\"Detailed description of the modified assignment\")\n    explanation: str = Field(..., description=\"Explanation of how this modification makes the assignment AI-resistant\")\n\nclass AIResistantOutput(BaseModel):\n    topic: str = Field(..., description=\"Topic or subject related to the assignment\")\n    grade_level: str = Field(..., description=\"Educational level to which the assignment is directed\")\n    ideas: List[AIResistanceIdea] = Field(..., description=\"List of 3 ideas to make the assignment AI-resistant, including explanation\")"}
{"type": "source_file", "path": "app/tools/presentation_generator_updated/outline_generator/tools.py", "content": "from pydantic import BaseModel, Field\nfrom typing import List, Optional\nimport os\nfrom app.services.logger import setup_logger\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough, RunnableParallel\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_core.documents import Document\n\nlogger = setup_logger(__name__)\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n\n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n    \nclass OutlineGenerator:\n    def __init__(self, args=None, vectorstore_class=Chroma, embedding_model=None, model=None, parser=None, verbose=False):\n        default_config = {\n            \"model\": GoogleGenerativeAI(model=\"gemini-1.5-flash\"),\n            \"embedding_model\": GoogleGenerativeAIEmbeddings(model='models/embedding-001'),\n            \"parser\": JsonOutputParser(pydantic_object=Outlines),\n            \"prompt_with_context\": read_text_file(\"prompt/outline_prompt_with_context.txt\"),\n            \"prompt_without_context\": read_text_file(\"prompt/outline_prompt.txt\"),\n            \"vectorstore_class\": Chroma\n        }\n\n        self.prompt_with_context =  default_config[\"prompt_with_context\"]\n        self.prompt_without_context = default_config[\"prompt_without_context\"]\n        self.model = model or default_config[\"model\"]\n        self.parser = parser or default_config[\"parser\"]\n        self.embedding_model = embedding_model or default_config[\"embedding_model\"]\n\n        self.vectorstore_class = vectorstore_class or default_config[\"vectorstore_class\"]\n        self.vectorstore, self.retriever, self.runner = None, None, None\n        self.args = args\n        self.verbose = verbose\n        self.context = None\n        \n        if vectorstore_class is None: raise ValueError(\"Vectorstore must be provided\")\n        if args.topic is None: raise ValueError(\"Topic must be provided\")\n        if args.lang is None: raise ValueError(\"Language must be provided\")\n\n    def compile_with_context(self, documents: List[Document]):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt_with_context,\n            input_variables=[\"instructional_level\", \"n_slides\", \"topic\",\"context\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        if self.runner is None:\n            logger.info(f\"Creating vectorstore from {len(documents)} documents\") if self.verbose else None\n            self.vectorstore = self.vectorstore_class.from_documents(documents, self.embedding_model)\n            logger.info(f\"Vectorstore created\") if self.verbose else None\n\n            retriever = self.vectorstore.as_retriever()\n            logger.info(f\"Retriever created successfully\") if self.verbose else None\n            query = \"Provide general context for the topic to create notes.\"\n            self.context = retriever.invoke(query)\n            \n        chain = prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n\n    \n    def compile_without_context(self):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt_without_context,\n            input_variables=[\"instructional_level\", \"n_slides\", \"topic\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        chain = prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n\n    def generate_outline(self, documents: Optional[List[Document]]):\n        logger.info(f\"Creating the Outlines for the Presentation\") \n\n        if(documents):\n            chain = self.compile_with_context(documents)\n        else:\n            chain = self.compile_without_context()\n\n\n        input_parameters = {\n            \"instructional_level\": self.args.instructional_level,\n            \"n_slides\": self.args.n_slides,\n            \"topic\": self.args.topic,\n            \"lang\": self.args.lang,\n            \"context\":self.context\n        }\n        logger.info(f\"Input parameters: {input_parameters}\")\n\n        response = chain.invoke(input_parameters)\n\n        logger.info(f\"Generated response: {response}\")\n\n        if(documents):\n            if self.verbose: print(f\"Deleting vectorstore\")\n            self.vectorstore.delete_collection()\n        return response\n\n\n\nclass Outlines(BaseModel):\n    outlines: List[str] = Field(..., description=\"The full collection of slide outlines about the Presentation\")"}
{"type": "source_file", "path": "app/tools/presentation_generator_updated/slide_generator/tools.py", "content": "from pydantic import BaseModel, Field\nfrom typing import List, Optional,Union, Any\nimport os\nfrom app.services.logger import setup_logger\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough, RunnableParallel\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_core.documents import Document\nimport re\nlogger = setup_logger(__name__)\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n\n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n    \nclass SlideGenerator:\n    def __init__(self, args=None, vectorstore_class=Chroma, prompt=None, embedding_model=None, model=None, parser=None, verbose=False):\n        default_config = {\n            \"model\": GoogleGenerativeAI(model=\"gemini-1.5-flash\"),\n            \"embedding_model\": GoogleGenerativeAIEmbeddings(model='models/embedding-001'),\n            \"parser\": JsonOutputParser(pydantic_object=SlidePresentation),\n            \"prompt\": read_text_file(\"prompt/slide_generator_prompt.txt\"),\n            \"vectorstore_class\": Chroma\n        }\n\n        self.prompt = prompt or default_config[\"prompt\"]\n        self.model = model or default_config[\"model\"]\n        self.parser = parser or default_config[\"parser\"]\n        self.embedding_model = embedding_model or default_config[\"embedding_model\"]\n\n        self.vectorstore_class = vectorstore_class or default_config[\"vectorstore_class\"]\n        self.vectorstore, self.retriever, self.runner = None, None, None\n        self.args = args\n        self.verbose = verbose\n\n        if vectorstore_class is None: raise ValueError(\"Vectorstore must be provided\")\n       \n\n      \n\n    def validate_slides_content(self, response, topic):\n        \"\"\"Validates that slide content matches the requested topic and level.\"\"\"\n        topic_keywords = set(topic.lower().split())\n        topic_coverage = 0\n        garbage_coverage = 0\n        template_requirements_met = False\n        slides = response[\"slides\"]\n        try:\n            if  len(slides) == 0:\n                raise ValueError(\"No slides found in the response\")\n            for slide in slides:\n                slide_text = \"\"\n                if slide[\"template\"] == \"twoColumn\":\n                    template_requirements_met = True\n                    \n                if isinstance(slide[\"content\"], list):\n                    slide_text = ' '.join(slide[\"content\"])\n                elif isinstance(slide[\"content\"], dict):\n                    slide_text = ' '.join(slide[\"content\"].values())\n                else:\n                    slide_text = slide[\"content\"]\n                # Check for topic keywords in the slide text\n                if any(keyword in slide_text.lower() for keyword in topic_keywords):\n                    topic_coverage += 1\n            \n            # Check for Markdown remnants or excessive newlines\n                if any(char in slide_text for char in ['*', '\\n', '`', '_']):\n                    garbage_coverage += 1\n        \n            coverage_percentage = (topic_coverage / len(slides)) * 100\n            garbage_coverage_percentage = (garbage_coverage / len(slides)) * 100\n        \n            return {\n            \n                \"topic_coverage\": coverage_percentage,\n                \"template_requirements_met\": template_requirements_met,\n                \"garbage_coverage_percentage\": garbage_coverage_percentage,\n                \"valid\": coverage_percentage > 70 and template_requirements_met and garbage_coverage_percentage == 0\n            }\n            \n        except ValueError as e:\n            raise ValueError(e)\n\n        \n        \n\n    def compile_context(self):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt,\n            input_variables=[\"instructional_level\", \"topic\", \"slides_titles\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n        chain = prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n\n    def generate_slides(self):\n        logger.info(f\"Creating the Outlines for the Presentation\") \n        chain = self.compile_context() \n\n        input_parameters = {\n            \"instructional_level\": self.args.instructional_level,\n            \"topic\": self.args.topic,\n            \"slides_titles\": self.args.slides_titles,\n            \"lang\": self.args.lang\n        }\n        logger.info(f\"Input parameters: {input_parameters}\")\n\n        response = chain.invoke(input_parameters)\n\n        logger.info(f\"Generated response: {response}\")\n         # Add validation metrics\n        validation_results = self.validate_slides_content(response=response, topic=self.args.topic)\n        logger.info(f\"Response validation: {validation_results}\")\n        \n        if not validation_results[\"valid\"]:\n            logger.warning(f\"Generated content may not fully match the requested topic\")\n        return response\n\nclass Slide(BaseModel):\n    title: str = Field(..., description=\"The title of the slide\")\n    template: str = Field(..., description=\"The slide template type: sectionHeader, titleAndBody, titleAndBullets, twoColumn\")\n    #content: Optional[Union[str, list, dict, Any]] = Field(None, description=\"Content of the slide, can be string, list, dict, or any type\")\n    content: str | list | dict | Any = Field(None, description=\"Content of the slide, can be string, list, dict, or any type\")\n\nclass SlidePresentation(BaseModel):\n    slides: List[Slide] = Field(..., description=\"The complete set of slides in the presentation\")"}
{"type": "source_file", "path": "app/tools/presentation_generator_updated/__init__.py", "content": ""}
{"type": "source_file", "path": "app/tools/syllabus_generator/core.py", "content": "from app.services.logger import setup_logger\nfrom app.tools.syllabus_generator.tools import SyllabusRequestArgs\nfrom app.tools.syllabus_generator.tools import generate_syllabus\nfrom app.utils.document_loaders_summarization import (\n    generate_summary_from_img, \n    summarize_transcript_youtube_url, \n    get_summary\n)\nfrom app.api.error_utilities import SyllabusGeneratorError\nfrom app.services.schemas import SyllabusGeneratorArgsModel\n\nlogger = setup_logger()\n\ndef executor(grade_level: str,\n             subject: str,\n             course_description: str,\n             objectives: str,\n             required_materials: str,\n             grading_policy: str,\n             policies_expectations: str,\n             course_outline: str,\n             additional_notes: str,\n             file_url: str,\n             file_type: str,\n             lang: str,\n             verbose: bool = True):\n\n    if verbose:\n        logger.info(f\"File URL loaded: {file_url}\")\n\n    try:\n\n        if file_type == 'img':\n            summary = generate_summary_from_img(file_url)\n        elif file_type == 'youtube_url':\n            summary = summarize_transcript_youtube_url(file_url, verbose=verbose)\n        else:\n            summary = get_summary(file_url, file_type, verbose=verbose)\n\n        syllabus_args_model = SyllabusGeneratorArgsModel(\n            grade_level = grade_level,\n            subject = subject,\n            course_description = course_description,\n            objectives = objectives,\n            required_materials = required_materials,\n            grading_policy = grading_policy,\n            policies_expectations = policies_expectations,\n            course_outline = course_outline,\n            additional_notes = additional_notes,\n            file_url = file_url,\n            file_type = file_type,\n            lang = lang\n        )\n\n        request_args = SyllabusRequestArgs(\n                                syllabus_args_model,\n                                summary)\n\n        syllabus = generate_syllabus(request_args, verbose=verbose)\n\n    except Exception as e:\n        logger.error(f\"Failed to generate syllabus: {str(e)}\")\n        raise SyllabusGeneratorError(f\"Failed to generate syllabus: {str(e)}\") from e\n\n    return syllabus"}
{"type": "source_file", "path": "app/tools/rubric_generator/tools.py", "content": "from pydantic import BaseModel, Field\nfrom typing import List, Dict\nimport os\nfrom langchain_core.documents import Document\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough, RunnableParallel\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom app.services.logger import setup_logger\n\nlogger = setup_logger(__name__)\n\ndef read_text_file(file_path):\n    # Get the directory containing the script file\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Combine the script directory with the relative file path\n    absolute_file_path = os.path.join(script_dir, file_path)\n    \n    with open(absolute_file_path, 'r') as file:\n        return file.read()\n    \nclass RubricGenerator:\n    def __init__(self, args=None, vectorstore_class=Chroma, prompt=None, embedding_model=None, model=None, parser=None, verbose=False):\n        default_config = {\n            \"model\": GoogleGenerativeAI(model=\"gemini-1.5-flash\"),\n            \"embedding_model\": GoogleGenerativeAIEmbeddings(model='models/embedding-001'),\n            \"parser\": JsonOutputParser(pydantic_object=RubricOutput),\n            \"prompt\": read_text_file(\"prompt/rubric-generator-prompt.txt\"),\n            \"prompt_without_context\": read_text_file(\"prompt/rubric-generator-without-context-prompt.txt\"),\n            \"vectorstore_class\": Chroma\n        }\n\n        self.prompt = prompt or default_config[\"prompt\"]\n        self.prompt_without_context = default_config[\"prompt_without_context\"]\n        self.model = model or default_config[\"model\"]\n        self.parser = parser or default_config[\"parser\"]\n        self.embedding_model = embedding_model or default_config[\"embedding_model\"]\n\n        self.vectorstore_class = vectorstore_class or default_config[\"vectorstore_class\"]\n        self.vectorstore, self.retriever, self.runner = None, None, None\n        self.args = args\n        self.verbose = verbose\n\n        if vectorstore_class is None: raise ValueError(\"Vectorstore must be provided\")\n        if args.grade_level is None: raise ValueError(\"Grade Level must be provided\")\n        if args.point_scale is None: raise ValueError(\"Point Scale must be provided\")\n        if int(args.point_scale) < 2 or int(args.point_scale) > 8:\n            raise ValueError(\"Point Scale must be between 2 and 8. Suggested value is 4 for optimal granularity in grading.\")\n        if args.objectives is None: raise ValueError(\"Objectives description must be provided\")\n        if args.assignment_description is None: raise ValueError(\"Assignment description must be provided\")\n        if args.lang is None: raise ValueError(\"Language must be provided\")\n\n    def compile_with_context(self, documents: List[Document]):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt,\n            input_variables=[\"attribute_collection\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        if self.runner is None:\n            logger.info(f\"Creating vectorstore from {len(documents)} documents\") if self.verbose else None\n            self.vectorstore = self.vectorstore_class.from_documents(documents, self.embedding_model)\n            logger.info(f\"Vectorstore created\") if self.verbose else None\n\n            self.retriever = self.vectorstore.as_retriever()\n            logger.info(f\"Retriever created successfully\") if self.verbose else None\n\n            self.runner = RunnableParallel(\n                {\"context\": self.retriever,\n                \"attribute_collection\": RunnablePassthrough()\n                }\n            )\n\n        chain = self.runner | prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n    \n    def compile_without_context(self):\n        # Return the chain\n        prompt = PromptTemplate(\n            template=self.prompt_without_context,\n            input_variables=[\"attribute_collection\"],\n            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n        )\n\n        chain = prompt | self.model | self.parser\n\n        logger.info(f\"Chain compilation complete\")\n\n        return chain\n\n    def create_rubric(self, documents: List[Document]):\n        logger.info(f\"Creating the Rubric\")\n\n        if documents:\n            chain = self.compile_with_context(documents)\n        else:\n            chain = self.compile_without_context()\n\n         # Log the input parameters\n        input_parameters = (\n            f\"Grade Level: {self.args.grade_level}, \"\n            f\"Point Scale: {self.args.point_scale}, \"\n            f\"Objectives: {self.args.objectives}, \"\n            f\"Assignment Description: {self.args.assignment_description}, \"\n            f\"Language (YOU MUST RESPOND IN THIS LANGUAGE): {self.args.lang}\"\n        )\n        logger.info(f\"Input parameters: {input_parameters}\")\n\n        attempt = 1\n        max_attempt = 6\n\n        while attempt < max_attempt:\n            try:\n                response = chain.invoke(input_parameters)\n                logger.info(f\"Rubric generated during attempt nb: {attempt}\")\n            except Exception as e:\n                logger.error(f\"Error during rubric generation: {str(e)}\")\n                attempt += 1\n                continue\n            if response == None:\n                logger.error(f\"could not generate Rubric, trying again\")\n                attempt += 1\n                continue\n\n            if self.validate_rubric(response) == False:\n                attempt += 1\n                continue\n\n            # If everything is valid, break the outer loop\n            break\n\n        if attempt >= max_attempt:\n            raise ValueError(\"Error: Unable to generate the Rubric after 5 attempts.\")\n        else:\n            logger.info(f\"Rubric successfully generated after {attempt} attempt(s).\")\n\n        if documents:\n            if self.verbose: print(f\"Deleting vectorstore\")\n            self.vectorstore.delete_collection()\n\n        return response \n    \n    def validate_rubric(self, response: Dict) -> bool:\n         # Check if \"criterias\" exist and are valid\n        if \"criterias\" not in response or len(response[\"criterias\"]) == 0:\n            logger.error(\"Rubric generation failed, criterias not created successfully, trying agian.\")\n            return False\n\n        if \"feedback\" not in response:\n            logger.error(\"Rubric generation failed, feedback not created successfully, trying again.\")\n            return False\n\n        # Validate each criterion\n        criteria_valid = True\n        for criterion in response[\"criterias\"]:\n            if \"criteria_description\" not in criterion or len(criterion[\"criteria_description\"]) != int(self.args.point_scale):\n                logger.error(\"Mismatch between point scale nb and a criteria description. Trying again.\")\n                criteria_valid = False\n                break  # Exit the for loop if a criterion is invalid\n\n        if not criteria_valid:\n            return False\n        \n        return True\n    \nclass CriteriaDescription(BaseModel):\n    points: str = Field(..., description=\"The total points gained by the student according to the point_scale an the level name\")\n    description: List[str] = Field(..., description=\"Description for the specific point on the scale\")\n\nclass RubricCriteria(BaseModel):\n    criteria: str = Field(..., description=\"name of the criteria in the rubric\")\n    criteria_description: List[CriteriaDescription] = Field(..., description=\"Descriptions for each point on the scale\")\n    \nclass RubricOutput(BaseModel):\n    title: str = Field(..., description=\"the rubric title of the assignment based on the standard input parameter\")\n    grade_level: str = Field(..., description=\"The grade level for which the rubric is created\")\n    criterias: List[RubricCriteria] = Field(..., description=\"The grading criteria for the rubric\")\n    feedback: str = Field(..., description=\"the feedback provided by the AI model on the generated rubric\")\n    \n"}
