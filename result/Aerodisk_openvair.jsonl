{"repo_info": {"repo_name": "openvair", "repo_owner": "Aerodisk", "repo_url": "https://github.com/Aerodisk/openvair"}}
{"type": "test_file", "path": "openvair/libs/cli/test_executor.py", "content": "\"\"\"Unit tests for the `execute` function in the `openvair.libs.cli.executor`.\n\nThis test suite verifies the behavior of the `execute` function under various\nconditions, including successful execution, errors, timeouts, and invalid\ncommands. Mocking is used to isolate the function from actual subprocess calls,\nensuring that tests are deterministic and safe.\n\nUsage:\nRun the tests using pytest:\n    pytest openvair/libs/cli/test_executor.py\n\"\"\"\n\nfrom typing import TYPE_CHECKING\nfrom subprocess import TimeoutExpired\nfrom unittest.mock import MagicMock, patch\n\nimport pytest\n\nfrom openvair.libs.cli.models import ExecuteParams\nfrom openvair.libs.cli.executor import execute\nfrom openvair.libs.cli.exceptions import (\n    ExecuteError,\n    ExecuteTimeoutExpiredError,\n)\n\nif TYPE_CHECKING:\n    from openvair.libs.cli.models import ExecutionResult\n\n\ndef test_execute_success() -> None:\n    \"\"\"Test the successful execution of a command.\n\n    Simulates a command execution using `subprocess.Popen` and verifies that:\n        - The command returns the correct `stdout`.\n        - The `returncode` is 0, indicating successful execution.\n        - The `stderr` is empty.\n    \"\"\"\n    with patch('subprocess.Popen') as mock_popen:\n        process_mock: MagicMock = MagicMock()\n        process_mock.communicate.return_value = ('output', '')\n        process_mock.returncode = 0\n        mock_popen.return_value = process_mock\n\n        result: ExecutionResult = execute('echo', 'hello')\n\n        assert result.returncode == 0\n        assert result.stdout == 'hello'\n        assert result.stderr == ''\n\n\ndef test_execute_with_error() -> None:\n    \"\"\"Test execution of a command that returns an error.\n\n    Simulates a command execution where the return code is non-zero and verifies\n        that:\n        - The `ExecuteError` exception is raised when `raise_on_error=True`.\n        - The error details are logged correctly.\n    \"\"\"\n    with patch('subprocess.Popen') as mock_popen:\n        process_mock: MagicMock = MagicMock()\n        process_mock.communicate.return_value = ('', 'error')\n        process_mock.returncode = 1\n        mock_popen.return_value = process_mock\n\n        with pytest.raises(ExecuteError):\n            execute('false', params=ExecuteParams(raise_on_error=True))\n\n\ndef test_execute_timeout() -> None:\n    \"\"\"Test execution of a command that exceeds the timeout.\n\n    Simulates a command execution where the process exceeds the specified\n        timeout and verifies that:\n        - The `ExecuteTimeoutExpiredError` exception is raised.\n        - The timeout behavior is logged and handled correctly.\n    \"\"\"\n    with patch('subprocess.Popen') as mock_popen:\n        process_mock: MagicMock = MagicMock()\n        mock_popen.return_value = process_mock\n        process_mock.communicate.side_effect = TimeoutExpired(\n            cmd='sleep 1', timeout=1\n        )\n\n        with pytest.raises(ExecuteTimeoutExpiredError):\n            execute('sleep', '5', params=ExecuteParams(timeout=1))\n\n\ndef test_execute_invalid_command() -> None:\n    \"\"\"Test execution of an invalid command.\n\n    Simulates a scenario where the command to be executed does not exist and\n        verifies that:\n        - An `OSError` exception is raised.\n        - The error details are captured and logged correctly.\n    \"\"\"\n    with patch('subprocess.Popen', side_effect=OSError()), pytest.raises(\n        OSError\n    ):\n        execute('invalid_command')\n"}
{"type": "test_file", "path": "openvair/modules/network/tests/domain/__init__.py", "content": ""}
{"type": "test_file", "path": "openvair/modules/network/tests/domain/bridges/utils/__init__.py", "content": ""}
{"type": "test_file", "path": "openvair/modules/network/tests/domain/bridges/__init__.py", "content": ""}
{"type": "test_file", "path": "openvair/modules/network/tests/domain/bridges/utils/test_ovs_lib.py", "content": "import pytest\nimport time\nimport random\n\nfrom openvair.modules.network.domain.utils.exceptions import (\n    OVSManagerException,\n    InterfaceNotFoundException,\n    BridgeNotFoundException,\n)\nfrom openvair.modules.network.domain.utils.ovs_manager import OVSManager\n\nTEST_INTERFACE_PREFIX = 'tst_br'\n\n\ndef generate_unique_id():\n    \"\"\"\n    Generate a unique identifier for testing purposes.\n\n    Returns:\n        str: A unique identifier.\n    \"\"\"\n    timestamp = int(time.time() * 1000)\n    random_part = random.randint(1, 1000)\n    short_timestamp = str(timestamp)[-3:]  # Используем последние 5 символов\n    return f'{short_timestamp}_{random_part}'\n\n\n@pytest.fixture\ndef ovs_manager():\n    \"\"\"\n    Fixture to create an instance of OVSManager for testing.\n    \"\"\"\n    return OVSManager()\n\n\n@pytest.fixture\ndef tmp_bridge(ovs_manager):\n    \"\"\"\n    Fixture to create a test bridge for testing.\n    \"\"\"\n    bridge_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.create_bridge(bridge_name)\n    yield bridge_name\n    try:\n        ovs_manager.delete_bridge(bridge_name)\n    except BridgeNotFoundException:\n        pass\n\n\ndef test_create_bridge(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for creating an OVS bridge.\n    \"\"\"\n    assert ovs_manager.check_bridge_existence(tmp_bridge)\n\n\ndef test_delete_bridge(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for deleting an OVS bridge.\n    \"\"\"\n    assert ovs_manager.check_bridge_existence(tmp_bridge)\n    ovs_manager.delete_bridge(tmp_bridge)\n    assert not ovs_manager.check_bridge_existence(tmp_bridge)\n\n\ndef test_add_interface(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for adding an interface to an OVS bridge.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n    assert ovs_manager.check_interface_existence(tmp_bridge, interface_name)\n\n\ndef test_remove_interface(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for removing an interface from an OVS bridge.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n    assert ovs_manager.check_interface_existence(tmp_bridge, interface_name)\n    ovs_manager.remove_interface(tmp_bridge, interface_name)\n    assert not ovs_manager.check_interface_existence(tmp_bridge, interface_name)\n\n\ndef test_set_interface_address(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for setting the IP address for an OVS interface.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n    ip_address = '192.168.1.1/24'\n    ip_address2 = '192.168.1.2/24'\n    ovs_manager.set_interface_address(interface_name, ip_address)\n    ovs_manager.set_interface_address(interface_name, ip_address2)\n    if ovs_manager.check_interface_existence(tmp_bridge, interface_name):\n        addresses = ovs_manager.get_interface_addresses(interface_name)\n        assert ip_address in addresses\n\n\ndef test_edit_interface_address(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for editing the IP address for an OVS interface.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n    initial_ip_address = '192.168.1.1/24'\n    ovs_manager.set_interface_address(interface_name, initial_ip_address)\n    new_ip_address = '192.168.1.2/24'\n    ovs_manager.turn_on_interface(interface_name)\n    ovs_manager.edit_interface_address(\n        interface_name, initial_ip_address, new_ip_address\n    )\n\n    # Check that the new IP address is set\n    if ovs_manager.check_interface_existence(tmp_bridge, interface_name):\n        addresses = ovs_manager.get_interface_addresses(interface_name)\n        assert new_ip_address in addresses\n\n        # Check that the old IP address no longer exists\n        assert initial_ip_address not in addresses\n    else:\n        # The interface doesn't exist, which could happen if deletion failed\n        # Add the appropriate code to handle this situation\n        pass\n\n\ndef test_create_bridge_failure(ovs_manager):\n    \"\"\"\n    Test for failure case when creating an OVS bridge with an invalid name.\n    \"\"\"\n    with pytest.raises(OVSManagerException):\n        ovs_manager.create_bridge('invalid name')\n\n\ndef test_remove_interface_failure(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for failure case when removing a non-existing interface.\n    \"\"\"\n    with pytest.raises(InterfaceNotFoundException):\n        ovs_manager.remove_interface(tmp_bridge, 'nonexistent_interface')\n\n\ndef test_edit_interface(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for editing the configuration of an OVS interface.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n    options = 'type=internal'\n    ovs_manager.edit_interface(interface_name, options)\n    output = ovs_manager._execute_command(\n        f'sudo ovs-vsctl get Interface {interface_name} type'\n    )\n    assert output.stdout.strip() == 'internal'\n\n\ndef test_turn_off_interface(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for turning off an OVS interface.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n\n    # Check that the interface is initially on or in an unknown state\n    assert ovs_manager.check_interface_state(\n        interface_name, {'DOWN', 'UNKNOWN'}\n    )\n\n    ovs_manager.turn_off_interface(interface_name)\n\n    # Check that the interface is now off\n    assert ovs_manager.check_interface_state(interface_name)\n\n\ndef test_turn_on_interface(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for turning on an OVS interface.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n\n    # Check that the interface is initially off or in an unknown state\n    assert ovs_manager.check_interface_state(interface_name)\n\n    ovs_manager.turn_on_interface(interface_name)\n\n    # Check that the interface is now on\n    assert ovs_manager.check_interface_state(interface_name, {'UP', 'UNKNOWN'})\n\n\ndef test_check_interface_state(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for checking the state of an OVS interface.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n\n    # Check that the initial state is either up or in an unknown state\n    assert ovs_manager.check_interface_state(interface_name)\n\n    # Turn off the interface\n    ovs_manager.turn_off_interface(interface_name)\n\n    # Check that the state is now down\n    assert ovs_manager.check_interface_state(interface_name, {'DOWN'})\n\n\ndef test_check_interface_existence(ovs_manager, tmp_bridge):\n    \"\"\"\n    Test for checking the existence of an interface in an OVS bridge.\n    \"\"\"\n    interface_name = f'{TEST_INTERFACE_PREFIX}{generate_unique_id()}'\n    assert not ovs_manager.check_interface_existence(tmp_bridge, interface_name)\n\n    # Add the interface to the bridge\n    ovs_manager.add_interface(tmp_bridge, interface_name)\n\n    # Check if the interface exists in the bridge\n    assert ovs_manager.check_interface_existence(tmp_bridge, interface_name)\n"}
{"type": "test_file", "path": "openvair/modules/network/tests/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/abstracts/base_exception.py", "content": "\"\"\"Custom base exception class.\n\nThis module defines a base class for custom exceptions, providing a framework\nfor creating exceptions with detailed error messages.\n\nClasses:\n    BaseCustomException: A base class for custom exceptions that includes\n        message handling and string representation.\n\"\"\"\n\nfrom typing import Any\n\n\nclass BaseCustomException(Exception):  # noqa: N818 need complex rename if change this class\n    \"\"\"A base class for custom exceptions.\n\n    This class extends the standard Python Exception class and adds support\n    for detailed error messages, which can be either a string or a tuple.\n\n    Attributes:\n        message (str): The error message associated with the exception.\n    \"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the BaseCustomException.\n\n        Args:\n            message (str): The error message to associate with this exception.\n            *args: Additional arguments to pass to the base Exception class.\n        \"\"\"\n        self.message = message\n        super().__init__(message, *args)\n\n    def __str__(self) -> str:\n        \"\"\"Return the string representation of the exception.\n\n        If the message is a tuple, only the first element is returned in the\n        string representation. Otherwise, the full message is returned.\n\n        Returns:\n            str: The string representation of the exception, including its\n            class name and message.\n        \"\"\"\n        if self.message:\n            if isinstance(self.message, tuple):\n                return f'{self.__class__.__name__}: {self.message[0]}'\n            return f'{self.__class__.__name__}: {self.message}'\n        return f'{self.__class__.__name__}: raised.'\n"}
{"type": "source_file", "path": "openvair/abstracts/serializer.py", "content": "\"\"\"_summary_\"\"\"\n\nimport abc\nfrom typing import Dict, Type, Generic, TypeVar\n\nT = TypeVar('T')\n\n\nclass AbstractDataSerializer(Generic[T], metaclass=abc.ABCMeta):\n    \"\"\"Abstract class for data serialization.\"\"\"\n\n    @classmethod\n    @abc.abstractmethod\n    def to_domain(\n        cls,\n        orm_object: T,\n    ) -> Dict:\n        \"\"\"Convert an ORM object to a domain dictionary.\"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    @abc.abstractmethod\n    def to_db(\n        cls,\n        data: Dict,\n        orm_class: Type[T],\n    ) -> T:\n        \"\"\"Convert a dictionary to an ORM object.\"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    @abc.abstractmethod\n    def to_web(\n        cls,\n        orm_object: T,\n    ) -> Dict:\n        \"\"\"Convert an ORM object to a web dictionary.\"\"\"\n        raise NotImplementedError\n"}
{"type": "source_file", "path": "openvair/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/alembic/versions/1_initial_revisions.py", "content": "\"\"\"initial_revisions\n\nRevision ID: 1\nRevises:\nCreate Date: 2024-11-01 11:48:02.482067\n\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql\n\n# revision identifiers, used by Alembic.\nrevision = '1'\ndown_revision = None\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        'interfaces',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('name', sa.String(length=30), nullable=True),\n        sa.Column('mac', sa.String(length=20), nullable=True),\n        sa.Column('ip', sa.String(length=40), nullable=True),\n        sa.Column('netmask', sa.Integer(), nullable=True),\n        sa.Column('gateway', sa.String(length=40), nullable=True),\n        sa.Column('inf_type', sa.String(length=20), nullable=True),\n        sa.Column('mtu', sa.Integer(), nullable=True),\n        sa.Column('speed', sa.Integer(), nullable=True),\n        sa.Column('power_state', sa.String(length=20), nullable=False),\n        sa.Column('status', sa.String(length=20), nullable=False),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'interface_extra_specs',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('key', sa.String(length=60), nullable=True),\n        sa.Column('value', sa.String(length=155), nullable=True),\n        sa.Column('interface_id', sa.UUID(), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['interface_id'],\n            ['interfaces.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'storages',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('name', sa.String(length=60), nullable=True),\n        sa.Column('description', sa.String(length=255), nullable=True),\n        sa.Column('storage_type', sa.String(length=30), nullable=False),\n        sa.Column('initialized', sa.Boolean(), nullable=True),\n        sa.Column('status', sa.String(length=30), nullable=False),\n        sa.Column('information', sa.Text(), nullable=True),\n        sa.Column('size', sa.BigInteger(), nullable=True),\n        sa.Column('available', sa.BigInteger(), nullable=True),\n        sa.Column('user_id', sa.UUID(), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'storage_extra_specs',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('key', sa.String(length=60), nullable=True),\n        sa.Column('value', sa.String(length=155), nullable=True),\n        sa.Column('storage_id', sa.UUID(), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['storage_id'],\n            ['storages.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'users',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('username', sa.String(length=30), nullable=True),\n        sa.Column('email', sa.String(length=255), nullable=True),\n        sa.Column('is_superuser', sa.Boolean(), nullable=True),\n        sa.Column('hashed_password', sa.String(length=255), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n        sa.UniqueConstraint('email'),\n        sa.UniqueConstraint('username'),\n    )\n    op.create_table(\n        'volumes',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('name', sa.String(length=40), nullable=True),\n        sa.Column('user_id', sa.UUID(), nullable=True),\n        sa.Column('format', sa.String(length=10), nullable=True),\n        sa.Column('size', sa.BigInteger(), nullable=True),\n        sa.Column('used', sa.BigInteger(), nullable=True),\n        sa.Column('status', sa.String(length=20), nullable=True),\n        sa.Column('information', sa.Text(), nullable=True),\n        sa.Column('path', sa.String(length=255), nullable=True),\n        sa.Column('description', sa.String(length=255), nullable=True),\n        sa.Column('storage_id', sa.UUID(), nullable=True),\n        sa.Column('storage_type', sa.String(length=30), nullable=True),\n        sa.Column('read_only', sa.Boolean(), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'volume_attach_vm',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('volume_id', sa.UUID(), nullable=True),\n        sa.Column('vm_id', sa.UUID(), nullable=True),\n        sa.Column('user_id', sa.UUID(), nullable=True),\n        sa.Column('target', sa.String(length=50), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['volume_id'],\n            ['volumes.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'virtual_machines',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('power_state', sa.String(length=30), nullable=True),\n        sa.Column('status', sa.String(length=30), nullable=True),\n        sa.Column('name', sa.String(length=60), nullable=True),\n        sa.Column('description', sa.String(length=255), nullable=True),\n        sa.Column('information', sa.Text(), nullable=True),\n        sa.Column('user_id', sa.UUID(), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'cpu_info',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('cores', sa.Integer(), nullable=True),\n        sa.Column('threads', sa.Integer(), nullable=True),\n        sa.Column('sockets', sa.Integer(), nullable=True),\n        sa.Column('type', sa.String(length=30), nullable=True),\n        sa.Column('model', sa.String(length=30), nullable=True),\n        sa.Column('vm_id', sa.UUID(), nullable=True),\n        sa.Column('vcpu', sa.Integer(), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['vm_id'],\n            ['virtual_machines.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'disk',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('name', sa.String(length=255), nullable=True),\n        sa.Column('emulation', sa.String(length=30), nullable=True),\n        sa.Column('format', sa.String(length=20), nullable=True),\n        sa.Column('qos', postgresql.JSON(astext_type=sa.Text()), nullable=True),\n        sa.Column('boot_order', sa.Integer(), nullable=True),\n        sa.Column('path', sa.String(length=255), nullable=True),\n        sa.Column('size', sa.BigInteger(), nullable=True),\n        sa.Column('provisioning', sa.String(length=30), nullable=True),\n        sa.Column('type', sa.Integer(), nullable=True),\n        sa.Column('order', sa.Integer(), nullable=True),\n        sa.Column('vm_id', sa.UUID(), nullable=True),\n        sa.Column('disk_id', sa.UUID(), nullable=True),\n        sa.Column('read_only', sa.Boolean(), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['vm_id'],\n            ['virtual_machines.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'os',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('os_type', sa.String(length=80), nullable=True),\n        sa.Column('os_variant', sa.String(length=255), nullable=True),\n        sa.Column('boot_device', sa.String(length=10), nullable=True),\n        sa.Column('graphic_driver', sa.String(length=30), nullable=True),\n        sa.Column('bios', sa.String(length=30), nullable=True),\n        sa.Column('vm_id', sa.UUID(), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['vm_id'],\n            ['virtual_machines.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'protocol_graphic_interface',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('login', sa.String(length=90), nullable=True),\n        sa.Column('password', sa.String(length=255), nullable=True),\n        sa.Column('connect_type', sa.String(length=30), nullable=True),\n        sa.Column('url', sa.String(length=255), nullable=True),\n        sa.Column('vm_id', sa.UUID(), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['vm_id'],\n            ['virtual_machines.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'ram',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('size', sa.BigInteger(), nullable=True),\n        sa.Column('vm_id', sa.UUID(), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['vm_id'],\n            ['virtual_machines.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'virtual_interface',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('interface', sa.String(length=60), nullable=True),\n        sa.Column('mac', sa.String(length=20), nullable=True),\n        sa.Column('mode', sa.String(length=30), nullable=True),\n        sa.Column('portgroup', sa.String(length=30), nullable=True),\n        sa.Column('model', sa.String(length=30), nullable=True),\n        sa.Column('order', sa.Integer(), nullable=True),\n        sa.Column('vm_id', sa.UUID(), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['vm_id'],\n            ['virtual_machines.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'images',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('name', sa.String(length=40), nullable=True),\n        sa.Column('user_id', sa.UUID(), nullable=True),\n        sa.Column('size', sa.BigInteger(), nullable=True),\n        sa.Column('path', sa.String(length=255), nullable=True),\n        sa.Column('status', sa.String(length=20), nullable=True),\n        sa.Column('information', sa.Text(), nullable=True),\n        sa.Column('description', sa.String(length=255), nullable=True),\n        sa.Column('storage_id', sa.UUID(), nullable=True),\n        sa.Column('storage_type', sa.String(length=30), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'image_attach_vm',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('image_id', sa.UUID(), nullable=True),\n        sa.Column('vm_id', sa.UUID(), nullable=True),\n        sa.Column('user_id', sa.UUID(), nullable=True),\n        sa.Column('target', sa.String(length=50), nullable=True),\n        sa.ForeignKeyConstraint(\n            ['image_id'],\n            ['images.id'],\n        ),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'events',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('module', sa.String(length=40), nullable=True),\n        sa.Column('object_id', sa.UUID(), nullable=True),\n        sa.Column('user_id', sa.UUID(), nullable=True),\n        sa.Column('event', sa.String(length=50), nullable=True),\n        sa.Column('timestamp', sa.DateTime(), nullable=True),\n        sa.Column('information', sa.Text(), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'notifications',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('create_datetime', sa.TIMESTAMP(), nullable=True),\n        sa.Column('msg_type', sa.String(length=30), nullable=True),\n        sa.Column('subject', sa.String(length=30), nullable=True),\n        sa.Column('recipients', sa.ARRAY(sa.String()), nullable=True),\n        sa.Column('message', sa.String(length=255), nullable=True),\n        sa.Column('status', sa.String(length=255), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'virtual_networks',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('network_name', sa.String(), nullable=True),\n        sa.Column('forward_mode', sa.String(), nullable=True),\n        sa.Column('bridge', sa.String(), nullable=True),\n        sa.Column('virtual_port_type', sa.String(), nullable=True),\n        sa.Column('state', sa.String(), nullable=True),\n        sa.Column('autostart', sa.String(), nullable=True),\n        sa.Column('persistent', sa.String(), nullable=True),\n        sa.Column('virsh_xml', sa.Text(), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table(\n        'virtual_network_port_groups',\n        sa.Column('port_group_name', sa.String(), nullable=False),\n        sa.Column('is_trunk', sa.String(), nullable=True),\n        sa.Column('tags', sa.ARRAY(sa.Integer()), nullable=True),\n        sa.Column('virtual_network_id', sa.UUID(), nullable=False),\n        sa.ForeignKeyConstraint(\n            ['virtual_network_id'],\n            ['virtual_networks.id'],\n        ),\n        sa.PrimaryKeyConstraint('port_group_name', 'virtual_network_id'),\n    )\n    op.create_table(\n        'iscsi_interfaces',\n        sa.Column('id', sa.UUID(), nullable=False),\n        sa.Column('inf_type', sa.String(length=20), nullable=True),\n        sa.Column('ip', sa.String(length=40), nullable=True),\n        sa.Column('port', sa.String(length=20), nullable=True),\n        sa.Column('status', sa.String(length=20), nullable=True),\n        sa.PrimaryKeyConstraint('id'),\n        sa.UniqueConstraint('ip'),\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table('iscsi_interfaces')\n    op.drop_table('virtual_network_port_groups')\n    op.drop_table('virtual_networks')\n    op.drop_table('notifications')\n    op.drop_table('events')\n    op.drop_table('image_attach_vm')\n    op.drop_table('images')\n    op.drop_table('virtual_interface')\n    op.drop_table('ram')\n    op.drop_table('protocol_graphic_interface')\n    op.drop_table('os')\n    op.drop_table('disk')\n    op.drop_table('cpu_info')\n    op.drop_table('virtual_machines')\n    op.drop_table('volume_attach_vm')\n    op.drop_table('volumes')\n    op.drop_table('users')\n    op.drop_table('storage_extra_specs')\n    op.drop_table('storages')\n    op.drop_table('interface_extra_specs')\n    op.drop_table('interfaces')\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "openvair/alembic/env.py", "content": "from logging.config import fileConfig\n\nfrom sqlalchemy import engine_from_config, pool\n\nfrom openvair.modules.event_store.adapters.orm import Base as EventBase\nfrom openvair.modules.image.adapters.orm import Base as ImageBase\nfrom openvair.modules.network.adapters.orm import Base as NetworkBase\nfrom openvair.modules.storage.adapters.orm import Base as StorageBase\nfrom openvair.modules.user.adapters.orm import Base as UserBase\nfrom openvair.modules.virtual_machines.adapters.orm import Base as VMBase\nfrom openvair.modules.volume.adapters.orm import Base as VolumeBase\nfrom openvair.modules.notification.adapters.orm import Base as NotificationBase\nfrom openvair.modules.virtual_network.adapters.orm import (\n    Base as VirtualNetworkBase,\n)\nfrom openvair.modules.block_device.adapters.orm import Base as BlockDeviceBase\nfrom alembic import context\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n# config.set_section_option(\"alembic\", \"sqlalchemy.url\", settings.DATABASE_URL)\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\n# target_metadata = orm_storage.mapper_registry.metadata\ntarget_metadata = [\n    NetworkBase.metadata,\n    StorageBase.metadata,\n    UserBase.metadata,\n    VolumeBase.metadata,\n    VMBase.metadata,\n    ImageBase.metadata,\n    EventBase.metadata,\n    NotificationBase.metadata,\n    VirtualNetworkBase.metadata,\n    BlockDeviceBase.metadata,\n]\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    url = config.get_main_option('sqlalchemy.url')\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={'paramstyle': 'named'},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section),\n        prefix='sqlalchemy.',\n        poolclass=pool.NullPool,\n    )\n\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection, target_metadata=target_metadata\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n"}
{"type": "source_file", "path": "openvair/abstracts/exceptions.py", "content": "\"\"\"Module contains exceptions for the abstract classes of the entire project.\n\nClasses:\n    DBCannotBeConnectedError: Exception raised when the database cannot\n        be connected.\n\"\"\"\n\nfrom typing import Any\n\nfrom openvair.abstracts.base_exception import BaseCustomException\n\n\nclass DBCannotBeConnectedError(Exception):\n    \"\"\"Exception raised when database cannot be connected\"\"\"\n\n    def __init__(self, message: str) -> None:\n        \"\"\"Initialize the exception with a message\n\n        Args:\n            message (str): Message with additional information about\n                the exception.\n        \"\"\"\n        self.message = message\n        super().__init__(message)\n\n    def __str__(self) -> str:\n        \"\"\"Return the exception message.\n\n        Returns:\n            str: The exception message.\n        \"\"\"\n        return self.message\n\n\nclass ConfigParameterNotSpecifiedError(BaseCustomException):\n    \"\"\"Raised when exception KeyError while getting from project config\"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the ConfigParameterNotSpecifiedError exception.\"\"\"\n        super().__init__(message, *args)\n"}
{"type": "source_file", "path": "openvair/common/schemas.py", "content": "\"\"\"Common schemas for standardizing API responses.\n\nThis module defines a generic Pydantic schema for creating consistent\nAPI response structures across the application.\n\nClasses:\n    BaseResponse: A generic schema for API responses, supporting customizable\n        data, status, and error messages.\n\"\"\"\n\nfrom typing import Generic, TypeVar, Optional\n\nfrom pydantic import BaseModel\n\nT = TypeVar('T')\n\n\nclass BaseResponse(BaseModel, Generic[T]):\n    \"\"\"Generic schema for API responses.\n\n    This schema is designed to standardize API responses by including\n    a status, optional data, and an optional error message.\n\n    Attributes:\n        status (str): The status of the response (e.g., \"success\", \"error\").\n        data (Optional[T]): The data payload of the response, if applicable.\n        error (Optional[str]): An error message, if applicable.\n    \"\"\"\n\n    status: str\n    data: Optional[T] = None\n    error: Optional[str] = None\n"}
{"type": "source_file", "path": "openvair/libs/client/prometheus_client.py", "content": "\"\"\"Prometheus client module.\n\nThis module defines the `PrometheusClient` class, which provides methods\nfor interacting with the Prometheus monitoring service. It includes methods\nfor querying metrics and retrieving node information from Prometheus.\n\nClasses:\n    PrometheusClient: A client class for interacting with the Prometheus API.\n\"\"\"\n\nfrom typing import Dict, List\n\nfrom requests import RequestException\n\nfrom openvair.libs.log import get_logger\nfrom openvair.libs.client.config import PROMETHEUS_QUERIES\nfrom openvair.libs.client.base_client import PrometheusBaseClient\n\nLOG = get_logger(__name__)\n\n\nclass PrometheusClient(PrometheusBaseClient):\n    \"\"\"A client class for interacting with the Prometheus API.\n\n    This class provides methods to query data from Prometheus and retrieve\n    specific node information based on predefined metrics.\n    \"\"\"\n\n    def get_prometheus_data(self, query: str) -> Dict:\n        \"\"\"Retrieve data from Prometheus based on the specified query option.\n\n        Args:\n            query (str): The query to be used in the Prometheus API call.\n\n        Returns:\n            Dict: The JSON response from Prometheus as a dictionary.\n        \"\"\"\n        query_url = f'{self.source_url}/api/v1/query?query={query}'\n        result = self.session.get(query_url, verify=False)\n        return result.json()\n\n    def ping(self) -> None:\n        \"\"\"Ping the Prometheus service to check its availability.\n\n        This method sends a simple GET request to the Prometheus service URL\n        to verify its availability.\n\n        Returns:\n            Dict: The response from Prometheus, typically the status or health\n                check data.\n        \"\"\"\n        self.session.get(self.source_url, verify=False)\n\n    def get_node_info(self, option: str) -> float:\n        \"\"\"Retrieve node information from Prometheus based on a metric name.\n\n        This method fetches node information from Prometheus using a predefined\n        metric query. It returns the result of the query as a float.\n\n        Args:\n            option (str): The metric name for which to retrieve node\n                information.\n\n        Returns:\n            float: The result of the Prometheus query, or 0.0 if the query\n                fails.\n        \"\"\"\n        LOG.info(f'Start getting node info from Prometheus. Option: {option}')\n\n        node_info_values_sum = 0.0\n        try:\n            query_result = self.get_prometheus_data(\n                PROMETHEUS_QUERIES[option]['query']\n            )\n\n            data_result: List[Dict] = query_result['data']['result']\n            for row in data_result:\n                node_info_values_sum += float(row['value'][1])\n        except (KeyError, RequestException) as err:\n            LOG.warning(err)\n            LOG.warning(\n                f'Failed to get node info from Prometheus with option: {option}'\n            )\n            LOG.error('Prometheus API request failed.')\n            return 0.0\n        else:\n            LOG.info('Finished getting node info from Prometheus successfully.')\n            return node_info_values_sum\n"}
{"type": "source_file", "path": "openvair/libs/cli/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/libs/cli/exceptions.py", "content": "\"\"\"Defines custom exceptions for handling errors during command execution.\n\nClasses:\n    ExecuteTimeoutExpiredError: Raised when a command execution exceeds the\n        specified timeout.\n    ExecuteError: General exception for command execution errors.\n\nDependencies:\n    openvair.abstracts.base_exception: Provides the BaseCustomException class\n        for creating custom exceptions.\n\"\"\"\n\nfrom openvair.abstracts.base_exception import BaseCustomException\n\n\nclass ExecuteError(BaseCustomException):\n    \"\"\"General exception for command execution errors.\"\"\"\n\n    ...\n\n\nclass ExecuteTimeoutExpiredError(ExecuteError):\n    \"\"\"Raised when a command execution reaches its timeout.\"\"\"\n\n    ...\n\n\nclass UnsuccessReturnCodeError(ExecuteError):\n    \"\"\"Raised when getting unsuccesses return code\"\"\"\n\n    ...\n"}
{"type": "source_file", "path": "openvair/libs/client/base_client.py", "content": "\"\"\"Base client module for HTTP requests.\n\nThis module provides base classes for creating clients that interact with\nvarious web services, including a general `BaseClient` for web applications\nand a `PrometheusBaseClient` for interacting with Prometheus.\n\nClasses:\n    NotAuthorizedError: Custom exception for handling authorization errors.\n    BaseClient: Base class for creating clients that interact with web services.\n    PrometheusBaseClient: Base class for creating clients that interact with\n        Prometheus.\n\"\"\"\n\nfrom typing import Any, Optional\n\nimport requests\nfrom requests.adapters import HTTPAdapter\n\nfrom openvair.libs.client.config import (\n    get_web_app_url,\n    get_default_user,\n    get_prometheus_url,\n)\n\n\nclass NotAuthorizedError(Exception):\n    \"\"\"Exception raised for authorization errors.\n\n    This exception is raised when authentication fails due to incorrect\n    credentials or other authorization issues.\n\n    Args:\n        message (str): A message describing the error.\n    \"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the NotAuthorizedError with a message.\n\n        Args:\n            message (str): A message describing the authorization error.\n            *args: Additional arguments passed to the base Exception class.\n        \"\"\"\n        self.message = message\n        super().__init__(args)\n\n\nclass BaseClient:\n    \"\"\"Base class for creating clients that interact with web services.\n\n    This class sets up a session for making HTTP requests to a web service,\n    handles authentication, and retries on failed requests.\n\n    Attributes:\n        adapter (HTTPAdapter): Adapter for configuring retries on HTTP requests.\n        session (requests.Session): Session object for making HTTP requests.\n        source_url (str): Base URL of the web service.\n        service (str): Specific service endpoint.\n        url (str): Full URL of the service endpoint.\n        access_token (str): Bearer token for authorization.\n        header (dict): Authorization header for HTTP requests.\n    \"\"\"\n\n    def __init__(\n        self, service: str, access_token: Optional[str] = None, retries: int = 3\n    ):\n        \"\"\"Initialize the BaseClient.\n\n        Args:\n            service (str): The specific service endpoint to interact with.\n            access_token (Optional[str]): Bearer token for authorization.\n                If not provided, the client will attempt to authenticate\n                using default credentials.\n            retries (int): The number of retries for failed HTTP requests.\n                Defaults to 3.\n        \"\"\"\n        self.adapter = HTTPAdapter(max_retries=retries)\n        self.session = requests.Session()\n        self.source_url = get_web_app_url()\n        self.service = service\n        self.url = f'{self.source_url}/{self.service}'\n        self.session.mount(self.url, self.adapter)\n\n        self.access_token = access_token if access_token else self._auth()\n        self.header = {'Authorization': f'Bearer {self.access_token}'}\n\n    def _auth(self) -> str:\n        \"\"\"Authenticate the client using default credentials.\n\n        This method attempts to authenticate the client by sending a POST\n        request with the default username and password to the authentication\n        endpoint. If successful, it retrieves an access token.\n\n        Returns:\n            str: The retrieved access token.\n\n        Raises:\n            NotAuthorizedError: If authentication fails due to incorrect\n                credentials or other issues.\n        \"\"\"\n        login, password = get_default_user()\n        auth_url = f'{self.source_url}/auth/'\n        response = self.session.post(\n            auth_url, data={'username': login, 'password': password}\n        )\n        token: str = response.json().get('access_token', '')\n        if not token:\n            msg = 'Incorrect login or password.'\n            raise NotAuthorizedError(msg)\n        return token\n\n\nclass PrometheusBaseClient:\n    \"\"\"Base class for creating clients that interact with Prometheus.\n\n    This class sets up a session for making HTTP requests to the Prometheus\n    service and configures retries for failed requests.\n\n    Attributes:\n        adpter (HTTPAdapter): Adapter for configuring retries on HTTP requests.\n        session (requests.Session): Session object for making HTTP requests.\n        source_url (str): Base URL of the Prometheus service.\n    \"\"\"\n\n    def __init__(self, retries: int = 3):\n        \"\"\"Initialize the PrometheusBaseClient.\n\n        Args:\n            retries (int): The number of retries for failed HTTP requests.\n                Defaults to 3.\n        \"\"\"\n        self.adpter = HTTPAdapter(max_retries=retries)\n        self.session = requests.Session()\n        self.source_url = get_prometheus_url()\n"}
{"type": "source_file", "path": "openvair/libs/messaging/clients/rpc_clients/volume_rpc_client.py", "content": "\"\"\"Proxy implementation for the Volume Service Layer.\n\nThis module defines the `VolumeServiceLayerRPCClient` class, which serves as a\nproxy for interacting with the Volume Service Layer. The proxy class\nencapsulates the details of the RPC communication with the service layer,\nproviding a consistent and easy-to-use interface for external code.\n\nThe `VolumeServiceLayerRPCClient` class implements the\n`VolumeServiceLayerProtocolInterface`, which defines the contract for\ninteracting with the volume service layer. This allows the external code\nto work with the proxy class without needing to know the underlying\nimplementation details.\n\nClasses:\n    VolumeServiceLayerRPCClient: Proxy implementation for the Volume Service\n        Layer, providing a consistent interface for interacting with the\n        volume service.\n\"\"\"\n\nfrom typing import Dict, List\n\nfrom openvair.rpc_queues import RPCQueueNames\nfrom openvair.libs.messaging.messaging_agents import MessagingClient\nfrom openvair.libs.messaging.service_interfaces.volume import (\n    VolumeServiceLayerProtocolInterface,\n)\n\n\nclass VolumeServiceLayerRPCClient(VolumeServiceLayerProtocolInterface):\n    \"\"\"Proxy implementation for VolumeServiceLayerProtocolInterface\n\n    This class provides methods to interact with the Volume Service Layer\n    through RPC calls.\n\n    Attributes:\n        volume_service_rpc (RabbitRPCClient): RPC client for communicating with\n            the Volume Service Layer.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the VolumeServiceLayerRPCClient.\n\n        This method sets up the necessary components for the\n        VolumeServiceLayerRPCClient, including the RabbitMQ RPC client for\n        communicating with the Volume Service Layer.\n        \"\"\"\n        self.service_rpc_client = MessagingClient(\n            queue_name=RPCQueueNames.Volume.SERVICE_LAYER\n        )\n\n    def get_volume(self, data: Dict) -> Dict:\n        \"\"\"Retrieve a volume by its ID.\n\n        Args:\n            data (Dict): Data containing the volume ID.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VolumeServiceLayerProtocolInterface.get_volume.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def get_all_volumes(self, data: Dict) -> List[Dict]:\n        \"\"\"Retrieve all volumes from the database.\n\n        Args:\n            data (Dict): Data for filtering volumes.\n\n        Returns:\n            List[Dict]: List of serialized volume data.\n        \"\"\"\n        result: List[Dict] = self.service_rpc_client.call(\n            VolumeServiceLayerProtocolInterface.get_all_volumes.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def create_volume(self, volume_info: Dict) -> Dict:\n        \"\"\"Create a new volume.\n\n        Args:\n            volume_info (Dict): Information about the volume to be created.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VolumeServiceLayerProtocolInterface.create_volume.__name__,\n            data_for_method=volume_info,\n        )\n        return result\n\n    def extend_volume(self, data: Dict) -> Dict:\n        \"\"\"Extend the size of an existing volume.\n\n        Args:\n            data (Dict): Data containing the volume ID and new size.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VolumeServiceLayerProtocolInterface.extend_volume.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def delete_volume(self, data: Dict) -> Dict:\n        \"\"\"Delete an existing volume.\n\n        Args:\n            data (Dict): Data containing the volume ID.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VolumeServiceLayerProtocolInterface.delete_volume.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def edit_volume(self, data: Dict) -> Dict:\n        \"\"\"Edit the details of an existing volume.\n\n        Args:\n            data (Dict): Data containing the volume ID and new details.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VolumeServiceLayerProtocolInterface.edit_volume.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def attach_volume(self, data: Dict) -> Dict:\n        \"\"\"Attach a volume to a virtual machine.\n\n        Args:\n            data (Dict): Data containing the volume ID and VM details.\n\n        Returns:\n            Dict: Result of the attach operation.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VolumeServiceLayerProtocolInterface.attach_volume.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def detach_volume(self, data: Dict) -> Dict:\n        \"\"\"Detach a volume from a virtual machine.\n\n        Args:\n            data (Dict): Data containing the volume ID and VM details.\n\n        Returns:\n            Dict: Result of the detach operation.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VolumeServiceLayerProtocolInterface.detach_volume.__name__,\n            data_for_method=data,\n        )\n        return result\n"}
{"type": "source_file", "path": "openvair/libs/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/libs/messaging/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/libs/log/__init__.py", "content": "\"\"\"Logging module initialization.\n\nThis module provides a `get_logger` function to retrieve a configured logger\ninstance. The logger is set up based on a configuration file, which is\ntypically in TOML format.\n\nFunctions:\n    get_logger: Returns a logger instance configured according to the\n        provided or default configuration file.\n\"\"\"\n\nimport logging\nfrom pathlib import Path\n\nfrom openvair.libs.log.setup import setup_logging\nfrom openvair.libs.client.config import get_sentry_dsn\n\ntoml_path = Path(__file__).parent / 'logging_config.toml'\n\n\ndef get_logger(\n    name: str,\n    config_path: Path = toml_path,\n) -> logging.Logger:\n    \"\"\"Get a logger instance with the specified name.\n\n    This function initializes the logger using settings from a TOML\n    configuration file. If the configuration file is not found, it falls\n    back to a basic logging setup.\n\n    Args:\n        name (str): The name of the logger. It's common practice to use\n            `__name__` for the logger name.\n        config_path (str): The path to the TOML configuration file for\n            logger settings. Defaults to `logging_config.toml` in the log\n            package directory.\n\n    Returns:\n        logging.Logger: An initialized logger instance configured according\n        to the specified or default configuration file.\n    \"\"\"\n    get_sentry_dsn()\n    setup_logging(log_config_path=config_path)\n    return logging.getLogger(name)\n"}
{"type": "source_file", "path": "openvair/libs/log/setup.py", "content": "\"\"\"Logging setup utilities.\n\nThis module provides functions for setting up logging configurations\nfrom a TOML configuration file. If the file is not found or is invalid,\na basic logging setup is applied.\n\nFunctions:\n    setup_logging: Configures logging based on a TOML configuration file.\n    _base_setup_logging: Applies a basic logging setup if configuration\n        file loading fails.\n\"\"\"\n\nimport logging.config\nfrom pathlib import Path\n\nimport toml\n\n\ndef _base_setup_logging() -> None:\n    \"\"\"Apply a basic logging configuration.\n\n    This function sets up a simple logging configuration that outputs\n    logs to the console with a default format. It is used as a fallback\n    if the TOML configuration file cannot be loaded.\n    \"\"\"\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.DEBUG)\n    formatter = logging.Formatter(\n        fmt='(%(asctime)s) (%(name)s) (%(levelname)s) > %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S',\n    )\n    console_handler.setFormatter(formatter)\n\n    logging.basicConfig(level=10, handlers=[console_handler])\n    logging.getLogger('pika').setLevel('CRITICAL')\n\n\ndef setup_logging(\n    log_config_path: Path,\n) -> None:\n    \"\"\"Set up logging from a TOML configuration file.\n\n    This function attempts to configure logging using a TOML configuration\n    file. If the file does not exist or contains invalid data, it applies\n    a basic logging configuration instead.\n\n    Args:\n        log_config_path (str): The path to the TOML configuration file\n            for logging.\n\n    Returns:\n        None\n    \"\"\"\n    if log_config_path.exists():\n        try:\n            config = toml.load(log_config_path)\n            logging.config.dictConfig(config)\n        except ValueError:\n            _base_setup_logging()\n        finally:\n            logging.getLogger('pika').setLevel('CRITICAL')\n    else:\n        _base_setup_logging()\n"}
{"type": "source_file", "path": "openvair/libs/messaging/clients/rpc_clients/image_rpc_client.py", "content": "\"\"\"Proxy implementation for the Image Service Layer.\n\nThis module defines the `ImageServiceLayerRPCClient` class, which serves as a\nproxy for interacting with the Image Service Layer. The proxy class\nencapsulates the details of the RPC communication with the service layer,\nproviding a consistent and easy-to-use interface for external code.\n\nThe `ImageServiceLayerRPCClient` class implements the\n`ImageServiceLayerProtocolInterface`, which defines the contract for\ninteracting with the image service layer. This allows the external code\nto work with the proxy class without needing to know the underlying\nimplementation details.\n\nClasses:\n    ImageServiceLayerRPCClient: Proxy implementation for the Image Service\n        Layer, providing a consistent interface for interacting with the\n        image service.\n\"\"\"\n\nfrom typing import Dict, List\n\nfrom openvair.rpc_queues import RPCQueueNames\nfrom openvair.libs.messaging.messaging_agents import MessagingClient\nfrom openvair.libs.messaging.service_interfaces.image import (\n    ImageServiceLayerProtocolInterface,\n)\n\n\nclass ImageServiceLayerRPCClient(ImageServiceLayerProtocolInterface):\n    \"\"\"Proxy implementation for ImageServiceLayerProtocolInterface\n\n    This class provides methods to interact with the Image Service Layer\n    through RPC calls.\n\n    Attributes:\n        image_service_rpc (RabbitRPCClient): RPC client for communicating with\n            the Image Service Layer.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the ImageServiceLayerRPCClient.\n\n        This method sets up the necessary components for the\n        ImageServiceLayerRPCClient, including the RabbitMQ RPC client for\n        communicating with the Image Service Layer.\n        \"\"\"\n        self.service_rpc_client = MessagingClient(\n            queue_name=RPCQueueNames.Image.SERVICE_LAYER\n        )\n\n    def get_image(self, data: Dict) -> Dict:\n        \"\"\"Retrieve an image by its ID.\n\n        Args:\n            data (Dict): Data containing the image ID.\n\n        Returns:\n            Dict: Serialized image data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            ImageServiceLayerProtocolInterface.get_image.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def get_all_images(self, data: Dict) -> List[Dict]:\n        \"\"\"Retrieve all images from the database.\n\n        Args:\n            data (Dict): Data for filtering images.\n\n        Returns:\n            List[Dict]: List of serialized image data.\n        \"\"\"\n        result: List[Dict] = self.service_rpc_client.call(\n            ImageServiceLayerProtocolInterface.get_all_images.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def upload_image(self, image_info: Dict) -> Dict:\n        \"\"\"Upload a new image.\n\n        Args:\n            image_info (Dict): Information about the image to be uploaded.\n\n        Returns:\n            Dict: Serialized image data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            ImageServiceLayerProtocolInterface.upload_image.__name__,\n            data_for_method=image_info,\n        )\n        return result\n\n    def delete_image(self, data: Dict) -> None:\n        \"\"\"Delete an existing image.\n\n        Args:\n            data (Dict): Data containing the image ID.\n\n        Returns:\n            None\n        \"\"\"\n        self.service_rpc_client.call(\n            ImageServiceLayerProtocolInterface.delete_image.__name__,\n            data_for_method=data,\n        )\n\n    def attach_image(self, data: Dict) -> Dict:\n        \"\"\"Attach an image to a virtual machine.\n\n        Args:\n            data (Dict): Data containing the image ID and VM details.\n\n        Returns:\n            Dict: Result of the attach operation.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            ImageServiceLayerProtocolInterface.attach_image.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def detach_image(self, data: Dict) -> Dict:\n        \"\"\"Detach an image from a virtual machine.\n\n        Args:\n            data (Dict): Data containing the image ID and VM details.\n\n        Returns:\n            Dict: Result of the detach operation.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            ImageServiceLayerProtocolInterface.detach_image.__name__,\n            data_for_method=data,\n        )\n        return result\n"}
{"type": "source_file", "path": "openvair/libs/client/storage_client.py", "content": "# noqa: D100\n# in current moment this module is unused. It need to be adopted with actual rpc\n# client functionality\nfrom typing import Optional\n\nfrom openvair.libs.client.base_client import BaseClient\n\n\n# Unuse in current version need to be implemented from service interfaces and\n# make polymorphic use for all clients\nclass StorageClient(BaseClient):  # noqa: D101\n    def __init__(self, access_token: Optional[str] = None):  # noqa: D107\n        super().__init__(service='storages', access_token=access_token)\n\n    def get_storage_by_id(self, storage_id):  # noqa: D102, ANN201, ANN001\n        storage_url = f'{self.url}/{storage_id}/'\n        result = self.session.get(storage_url, headers=self.header)\n        return result.json()\n\n    def get_all_storages(self):  # noqa: D102, ANN201\n        storage_url = f'{self.url}/'\n        result = self.session.get(storage_url, headers=self.header)\n        return result.json().get('items', [])\n"}
{"type": "source_file", "path": "openvair/libs/client/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/libs/cli/executor.py", "content": "\"\"\"Executor module for running shell commands with advanced error handling.\n\nFunctions:\n    __terminate_process: Attempts to gracefully terminate a subprocess and\n        forcefully kills it if necessary.\n    __prepare_env: Prepares the environment variables for command execution.\n    execute: Executes a shell command with optional root privileges,\n        timeout, and error handling.\n\"\"\"\n\nimport os\nfrom typing import Dict, List\nfrom subprocess import PIPE, Popen, TimeoutExpired\n\nfrom openvair.libs.log import get_logger\nfrom openvair.libs.cli.models import ExecuteParams, ExecutionResult\nfrom openvair.libs.cli.exceptions import (\n    UnsuccessReturnCodeError,\n    ExecuteTimeoutExpiredError,\n)\n\nLOG = get_logger(__name__)\n\n\ndef __terminate_process(proc: Popen, cmd_str: str) -> str:\n    \"\"\"Terminates a subprocess gracefully, kills it if termination fails.\n\n    Attempts to gracefully terminate a subprocess and forcefully kill it\n    if termination fails.\n\n    Args:\n        proc (Popen): The subprocess to be terminated.\n        cmd_str (str): The command string representing the subprocess for\n            logging purposes.\n\n    Returns:\n        str: The standard error output (stderr) collected from the subprocess\n            after termination.\n    \"\"\"\n    LOG.warning(f\"Command '{cmd_str}' timed out. Terminating process.\")\n    proc.terminate()\n    try:\n        proc.wait(timeout=5)\n    except TimeoutExpired:\n        LOG.error(f\"Command '{cmd_str}' did not terminate. Killing it.\")\n        proc.kill()\n    _, stderr = proc.communicate()\n    return str(stderr)\n\n\ndef __prepare_env(env_params: Dict[str, str]) -> Dict[str, str]:\n    \"\"\"Prepares the environment variables for the command execution.\n\n    Args:\n        env_params (Dict[str, str]): Key-value pairs representing environment\n            variables to be added or overridden.\n\n    Returns:\n        Dict[str, str]: The merged environment variables, combining the current\n        environment and the provided `env_params`.\n    \"\"\"\n    env_vars = os.environ.copy()  # Copy current environment\n    for var, val in env_params.items():\n        env_vars[var] = val\n    return env_vars\n\n\ndef execute(\n    *args: str,\n    params: ExecuteParams = ExecuteParams(),\n) -> ExecutionResult:\n    \"\"\"Executes a shell command and returns its stdout, stderr, and exit code.\n\n    Args:\n        *args (str): The command and its arguments to execute. Each argument\n            must be passed as a separate string.\n        params (ExecuteParams): A Pydantic model containing command execution\n            parameters such as `shell`, `timeout`, `env`, etc.\n\n    Returns:\n        ExecutionResult: A model containing:\n            - `returncode` (int): The exit code of the command.\n            - `stdout` (str): Standard output of the command.\n            - `stderr` (str): Standard error output of the command.\n\n    Raises:\n        ExecuteTimeoutExpiredError: Raised if the command execution exceeds the\n            specified timeout.\n        UnsuccessReturnCodeError: Raised if the command exits with a non-zero\n            return code and `raise_on_error` is True.\n        OSError: Raised for system-level errors, such as command not found or\n            permission issues.\n\n    Example:\n        >>> params = ExecuteParams(shell=True, timeout=10, raise_on_error=True)\n        >>> result = execute('ls', '-la', params=params)\n        >>> print(result.stdout)\n    \"\"\"\n    cmd: List[str] = list(args)\n    if params.run_as_root and hasattr(os, 'geteuid') and os.geteuid() != 0:\n        cmd = [params.root_helper, *cmd]\n\n    cmd_str = ' '.join(cmd)\n    LOG.info(f'Executing command: {cmd_str}')\n    try:\n        with Popen(  # noqa: S603\n            cmd_str if params.shell else cmd,\n            shell=params.shell,\n            stdout=PIPE,\n            stderr=PIPE,\n            stdin=PIPE,\n            text=True,\n            env=__prepare_env(params.env) if params.env else None,\n        ) as proc:\n            try:\n                stdout, stderr = proc.communicate(timeout=params.timeout)\n                returncode = proc.returncode\n                LOG.info(\n                    f\"Command '{cmd_str}' completed with return code: \"\n                    f'{returncode}'\n                )\n\n                if params.raise_on_error and returncode != 0:\n                    message = (\n                        f\"Command '{cmd_str}' failed with return code \"\n                        f'{returncode}'\n                    )\n                    LOG.error(message)\n                    raise UnsuccessReturnCodeError(message)\n\n                return ExecutionResult(\n                    returncode=returncode,\n                    stdout=stdout.strip() or '',\n                    stderr=stderr.strip() or '',\n                )\n            except TimeoutExpired:\n                stderr = __terminate_process(proc, cmd_str)\n                message = (\n                    f\"Command '{cmd_str}' timed out and was killed.\\n\"\n                    f'Error: {stderr}'\n                )\n                raise ExecuteTimeoutExpiredError(message)\n    except OSError as err:\n        LOG.error(f\"OS error for command '{cmd_str}': {err}\")\n        raise\n"}
{"type": "source_file", "path": "openvair/libs/messaging/config.py", "content": "\"\"\"Messaging configuration module.\n\nThis module provides utility functions to retrieve RabbitMQ connection\nparameters and messaging configuration details.\n\nFunctions:\n    get_rabbitmq_url: Returns the RabbitMQ connection URL.\n    get_messaging_type_and_transport: Retrieves the messaging type and transport\n    method.\n\"\"\"\n\nfrom typing import Tuple\n\nfrom openvair import config\n\n\ndef get_rabbitmq_url() -> str:\n    \"\"\"Get the RabbitMQ connection URL.\n\n    This function constructs the RabbitMQ connection URL from configuration\n    settings including the user, password, host, and port.\n\n    Returns:\n        str: The RabbitMQ connection URL.\n    \"\"\"\n    rabbitmq = config.data.get('rabbitmq', {})\n    user = rabbitmq.get('user', 'guest')\n    password = rabbitmq.get('password', 'guest')\n    host = rabbitmq.get('host', 'localhost')\n    port = rabbitmq.get('port', 5672)\n    return f'amqp://{user}:{password}@{host}:{port}'\n\n\ndef get_messaging_type_and_transport() -> Tuple[str, str]:\n    \"\"\"Get the messaging type and transport method.\n\n    This function retrieves the messaging type and transport method from\n    configuration settings.\n\n    Returns:\n        tuple: A tuple containing the messaging type and transport method.\n    \"\"\"\n    messaging = config.data.get('messaging', {})\n    return messaging.get('type', ''), messaging.get('transport', '')\n"}
{"type": "source_file", "path": "openvair/libs/messaging/clients/rpc_clients/storage_rpc_client.py", "content": "\"\"\"Proxy implementation for the Storage Service Layer.\n\nThis module defines the `StorageServiceLayerClient` class, which serves as a\nproxy for interacting with the Storage Service Layer. The proxy class\nencapsulates the details of the RPC communication with the service layer,\nproviding a consistent and easy-to-use interface for external code.\n\nThe `StorageServiceLayerClient` class implements the\n`StorageServiceLayerProtocolInterface`, which defines the contract for\ninteracting with the storage service layer. This allows the external code\nto work with the proxy class without needing to know the underlying\nimplementation details.\n\nClasses:\n    StorageServiceLayerClient: Proxy implementation for the Storage Service\n        Layer, providing a consistent interface for interacting with the\n        storage service.\n\"\"\"\n\nfrom typing import Dict, List\n\nfrom openvair.rpc_queues import RPCQueueNames\nfrom openvair.libs.messaging.messaging_agents import MessagingClient\nfrom openvair.libs.messaging.service_interfaces.storage import (\n    StorageServiceLayerProtocolInterface,\n)\n\n\nclass StorageServiceLayerRPCClient(StorageServiceLayerProtocolInterface):\n    \"\"\"Proxy implementation for StorageServiceLayerProtocolInterface\n\n    This class provides methods to interact with the Storage Service Layer\n    through RPC calls.\n\n    Attributes:\n        storage_service_rpc (RabbitRPCClient): RPC client for communicating with\n            the Storage Service Layer.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the StorageServiceLayerClient.\n\n        This method sets up the necessary components for the\n        StorageServiceLayerClient, including the RabbitMQ RPC client for\n        communicating with the Storage Service Layer.\n        \"\"\"\n        self.service_rpc_client = MessagingClient(\n            queue_name=RPCQueueNames.Storage.SERVICE_LAYER\n        )\n\n    def get_storage(self, data: Dict) -> Dict:\n        \"\"\"Retrieve a storage by its ID.\n\n        Args:\n            data (Dict): Data containing the storage ID.\n\n        Returns:\n            Dict: Serialized storage data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            StorageServiceLayerProtocolInterface.get_storage.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def get_all_storages(self) -> List[Dict]:\n        \"\"\"Retrieve all storages from the database.\n\n        Returns:\n            List[Dict]: List of serialized storage data.\n        \"\"\"\n        result: List[Dict] = self.service_rpc_client.call(\n            StorageServiceLayerProtocolInterface.get_all_storages.__name__,\n            data_for_method={},\n        )\n        return result\n\n    def create_local_partition(self, data: Dict) -> Dict:\n        \"\"\"Create a local partition on the disk.\n\n        Args:\n            data (Dict): Data containing details for creating the partition.\n\n        Returns:\n            Dict: Serialized partition data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            StorageServiceLayerProtocolInterface.create_local_partition.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def get_local_disk_partitions_info(self, data: Dict) -> Dict:\n        \"\"\"Get information about local disk partitions.\n\n        Args:\n            data (Dict): Data containing the disk path.\n\n        Returns:\n            Dict: Partition information.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            StorageServiceLayerProtocolInterface.get_local_disk_partitions_info.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def delete_local_partition(self, data: Dict) -> Dict:\n        \"\"\"Delete a local partition.\n\n        Args:\n            data (Dict): Data containing details for deleting the partition.\n\n        Returns:\n            Dict: Result of the delete operation.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            StorageServiceLayerProtocolInterface.delete_local_partition.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def create_storage(self, data: Dict) -> Dict:\n        \"\"\"Create a new storage.\n\n        Args:\n            data (Dict): Data containing details for creating the storage.\n\n        Returns:\n            Dict: Serialized storage data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            StorageServiceLayerProtocolInterface.create_storage.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def delete_storage(self, data: Dict) -> Dict:\n        \"\"\"Delete a storage.\n\n        Args:\n            data (Dict): Data containing the storage ID.\n\n        Returns:\n            Dict: Serialized storage data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            StorageServiceLayerProtocolInterface.delete_storage.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def get_local_disks(self, data: Dict) -> List:\n        \"\"\"Retrieve local disks information.\n\n        Args:\n            data (Dict): Data containing details for filtering disks.\n\n        Returns:\n            List: List of local disks.\n        \"\"\"\n        result: List = self.service_rpc_client.call(\n            StorageServiceLayerProtocolInterface.get_local_disks.__name__,\n            data_for_method=data,\n        )\n        return result\n"}
{"type": "source_file", "path": "openvair/libs/cli/models.py", "content": "\"\"\"This module defines the models for command execution parameters and results.\n\nClasses:\n    ExecutionResult: Represents the outcome of a command execution.\n    ExecuteParams: Encapsulates parameters for executing a shell command.\n\"\"\"\n\nfrom typing import Dict, Optional\n\nfrom pydantic import Field, BaseModel\n\n\nclass ExecutionResult(BaseModel):\n    \"\"\"Represents the result of a command execution.\n\n    Attributes:\n        returncode (int): The exit code of the executed command.\n        stdout (str): The standard output produced by the command.\n        stderr (str): The standard error output produced by the command.\n    \"\"\"\n\n    returncode: int\n    stdout: str\n    stderr: str\n\n\nclass ExecuteParams(BaseModel):\n    \"\"\"Encapsulates parameters for executing a shell command.\n\n    Attributes:\n        shell (bool): If True, the command will be executed through the shell.\n        run_as_root (bool): If True, the command will be executed with root\n            privileges.\n        root_helper (str): Command used to elevate privileges, such as 'sudo'.\n        timeout (Optional[float]): Maximum time in seconds to wait for the\n            command to complete.\n        env (Optional[Dict[str, str]]): Environment variables for the command.\n        raise_on_error (bool): If True, raises an exception if the command\n            fails.\n    \"\"\"\n\n    shell: bool = Field(\n        default=False,\n        description='If True, the command will be executed through the shell.',\n    )\n    run_as_root: bool = Field(\n        default=False,\n        description=(\n            'If True, the command will be executed with root privileges.'\n        ),\n    )\n    root_helper: str = Field(\n        default='sudo',\n        description=\"Command used to elevate privileges, such as 'sudo'.\",\n    )\n    timeout: Optional[float] = Field(\n        default=None,\n        description=(\n            'Maximum time in seconds to wait for the command to complete.'\n        ),\n    )\n    env: Optional[Dict[str, str]] = Field(\n        default=None, description='Environment variables for the command.'\n    )\n    raise_on_error: bool = Field(\n        default=False,\n        description='If True, raises an exception if the command fails.',\n    )\n"}
{"type": "source_file", "path": "openvair/libs/client/volume_client.py", "content": "# noqa: D100\n# in current moment this module is unused. It need to be adopted with actual rpc\n# client functionality\nfrom openvair.libs.client.base_client import BaseClient\n\n\n# Unuse in current version need to be implemented from service interfaces and\n# make polymorphic use for all clients\nclass VolumeClient(BaseClient):  # noqa: D101\n    def __init__(self, access_token: str):  # noqa: D107\n        super().__init__(service='volumes', access_token=access_token)\n\n    def get_volume(self, volume_id):  # noqa: D102, ANN201, ANN001\n        volume_get_url = f'{self.url}/{volume_id}/'\n        result = self.session.get(volume_get_url, headers=self.header)\n        return result.json()\n\n    def get_volumes_by_storage_id(self, storage_id: str):  # noqa: ANN201, D102\n        volume_get_url = f'{self.url}/'\n        result = self.session.get(\n            volume_get_url,\n            params={'storage_id': storage_id},\n            headers=self.header,\n        )\n        return result.json().get('items', [])\n\n    def create_volume(self, volume_info: dict):  # noqa: ANN201, D102\n        volume_create_url = f'{self.url}/create/'\n        result = self.session.post(\n            volume_create_url, json=volume_info, headers=self.header\n        )\n        return result.json()\n\n    def attach_volume(self, volume_id: str, attach_info: dict):  # noqa: ANN201, D102\n        volume_attach_url = f'{self.url}/{volume_id}/attach/'\n        result = self.session.post(\n            volume_attach_url, json=attach_info, headers=self.header\n        )\n        return result.json()\n\n    def detach_volume(self, volume_id: str, detach_info: dict):  # noqa: ANN201, D102\n        volume_detach_url = f'{self.url}/{volume_id}/detach/'\n        result = self.session.delete(\n            volume_detach_url, json=detach_info, headers=self.header\n        )\n        return result.json()\n\n    def delete_volume(self, volume_id: str):  # noqa: ANN201, D102\n        volume_delete_url = f'{self.url}/{volume_id}/delete/'\n        result = self.session.delete(volume_delete_url, headers=self.header)\n        return result.json()\n"}
{"type": "source_file", "path": "openvair/libs/messaging/exceptions.py", "content": "\"\"\"Messaging exceptions module.\n\nThis module defines custom exceptions for handling errors in the messaging\nsystem, particularly in the context of RPC communication.\n\nClasses:\n    RpcCallException: Exception raised when an RPC call fails.\n    RpcCallTimeoutException: Exception raised when an RPC call times out.\n    RpcClientInitializedException: Exception raised during RPC client\n        initialization.\n    RpcServerInitializedException: Exception raised during RPC server\n        initialization.\n\"\"\"\n\nfrom typing import Any\n\nfrom openvair.abstracts.base_exception import BaseCustomException\n\n\nclass RpcException(BaseCustomException):\n    \"\"\"Exception raised when an RPC call fails.\"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the RpcCallException.\"\"\"\n        super().__init__(message, *args)\n\nclass RpcCallException(RpcException):\n    \"\"\"Exception raised when an RPC call fails.\"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the RpcCallException.\"\"\"\n        super().__init__(message, *args)\n\n\nclass RpcCallTimeoutException(RpcException):\n    \"\"\"Exception raised when an RPC call times out.\"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the RpcCallTimeoutException.\"\"\"\n        self.message = 'Timed out waiting for a response'\n        super().__init__(message, *args)\n\n\nclass RpcClientInitializedException(RpcException):\n    \"\"\"Exception raised during RPC client initialization.\"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the RpcClientInitializedException.\"\"\"\n        self.message = 'An error occurred during client initialization'\n        super().__init__(message, *args)\n\n\nclass RpcServerInitializedException(RpcException):\n    \"\"\"Exception raised during RPC server initialization.\"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the RpcServerInitializedException.\"\"\"\n        self.message = 'An error occurred during server initialization'\n        super().__init__(message, *args)\n\n\nclass RpcDeserializeMessageException(RpcException):\n    \"\"\"Exception raised when get error while parsing rpc message.\"\"\"\n\n    def __init__(self, message: str, *args: Any) -> None:  # noqa: ANN401 # TODO need to parameterize the arguments correctly, in accordance with static typing\n        \"\"\"Initialize the RpcDeserializeMessageException.\"\"\"\n        super().__init__(message, *args)\n"}
{"type": "source_file", "path": "openvair/libs/client/vm_client.py", "content": "# noqa: D100\n# in current moment this module is unused. It need to be adopted with actual rpc\n# client functionality\nfrom openvair.libs.client.base_client import BaseClient\n\n\n# Unuse in current version need to be implemented from service interfaces and\n# make polymorphic use for all clients\nclass VMClient(BaseClient):  # noqa: D101\n    def __init__(self, access_token: str):  # noqa: D107\n        super().__init__(service='virtual-machines', access_token=access_token)\n\n    def get_vm(self, vm_id):  # noqa: ANN201, D102, ANN001\n        vm_get_url = f'{self.url}/{vm_id}/'\n        result = self.session.get(vm_get_url, headers=self.header)\n        return result.json()\n"}
{"type": "source_file", "path": "openvair/config.py", "content": "\"\"\"Configuration settings and utility functions for the OpenVair project.\n\nThis module handles the loading of configuration from a TOML file and provides\nutility functions to generate PostgreSQL database URIs and SQLAlchemy session\nfactories.\n\nConstants:\n    PROJECT_ROOT (Path): Root directory of the project.\n    toml_path (Path): Path to the TOML configuration file.\n\nFunctions:\n    get_postgres_uri() -> str: Generates a PostgreSQL URI from configuration\n        settings.\n    get_default_session_factory() -> sessionmaker: creates and returns a\n        SQLAlchemy session factory with the given parameters.\n\"\"\"\n\nimport pathlib\nimport tempfile\nfrom typing import Dict, Type\n\nimport toml\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\nfrom openvair.rpc_queues import RPCQueueNames\nfrom openvair.abstracts.exceptions import ConfigParameterNotSpecifiedError\n\nPROJECT_ROOT = pathlib.Path(__file__).parent.parent\nTMP_DIR = tempfile.gettempdir()\n\n# Path to the TOML configuration file\ntoml_path = pathlib.Path(__file__).parent.parent / 'project_config.toml'\n\nRPC_QUEUES: Type[RPCQueueNames] = RPCQueueNames\n\nwith pathlib.Path.open(toml_path, 'r') as config_toml:\n    data = toml.load(config_toml)\n\ndatabase: Dict = data.get('database', {})\nDB_CONTAINER: str = data['docker']['db_container']\n\ndef get_postgres_uri() -> str:\n    \"\"\"Generates a PostgreSQL URI from configuration settings.\n\n    Returns:\n        str: PostgreSQL URI for connecting to the database.\n    \"\"\"\n    try:\n        port: int = database['port']\n        host: str = database['host']\n        password: str = database['password']\n        user: str = database['user']\n        db_name: str = database['db_name']\n    except KeyError as err:\n        msg = f'{err} - for database section'\n        raise ConfigParameterNotSpecifiedError(msg)\n    return f'postgresql://{user}:{password}@{host}:{port}/{db_name}'\n\n\ndef get_default_session_factory(\n    pool_size: int = 10,\n    max_overflow: int = 10,\n    pool_timeout: int = 60,\n    pool_recycle: int = 1800,  # refresh connections every 30 minutes\n    *,\n    pool_pre_ping: bool = True,\n) -> sessionmaker:\n    \"\"\"Creates and returns SQLAlchemy session factory with the given parameters.\n\n    Args:\n        pool_size (int): The size of the connection pool.\n        max_overflow (int): The maximum number of connections to allow\n            beyond pool_size.\n        pool_timeout (int): The number of seconds to wait before giving up\n            on acquiring a connection.\n        pool_recycle (int): The number of seconds after which to recycle\n            connections.\n        pool_pre_ping (bool): Whether to check connections before using them.\n\n    Returns:\n        sessionmaker: A SQLAlchemy session factory.\n    \"\"\"\n    return sessionmaker(\n        expire_on_commit=False,\n        bind=create_engine(\n            get_postgres_uri(),\n            isolation_level='REPEATABLE READ',\n            pool_size=pool_size,\n            max_overflow=max_overflow,\n            pool_timeout=pool_timeout,\n            pool_pre_ping=pool_pre_ping,\n            pool_recycle=pool_recycle,\n        ),\n    )\n"}
{"type": "source_file", "path": "openvair/libs/messaging/clients/rpc_clients/vm_rpc_client.py", "content": "\"\"\"Proxy implementation for the VM Service Layer.\n\nThis module defines the `VMServiceLayerRPCClient` class, which serves as a\nproxy for interacting with the VM Service Layer. The proxy class\nencapsulates the details of the RPC communication with the service layer,\nproviding a consistent and easy-to-use interface for external code.\n\nThe `VMServiceLayerRPCClient` class implements the\n`VMServiceLayerProtocolInterface`, which defines the contract for\ninteracting with the VM service layer. This allows the external code\nto work with the proxy class without needing to know the underlying\nimplementation details.\n\nClasses:\n    VMServiceLayerRPCClient: Proxy implementation for the VM Service\n        Layer, providing a consistent interface for interacting with the\n        VM service.\n\"\"\"\n\nfrom typing import Dict, List\n\nfrom openvair.rpc_queues import RPCQueueNames\nfrom openvair.libs.messaging.messaging_agents import MessagingClient\nfrom openvair.libs.messaging.service_interfaces.vm import (\n    VMServiceLayerProtocolInterface,\n)\n\n\nclass VMServiceLayerRPCClient(VMServiceLayerProtocolInterface):\n    \"\"\"Proxy implementation for VMServiceLayerProtocolInterface\n\n    This class provides methods to interact with the VM Service Layer\n    through RPC calls.\n\n    Attributes:\n        vm_service_rpc (RabbitRPCClient): RPC client for communicating with\n            the VM Service Layer.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the VMServiceLayerRPCClient.\n\n        This method sets up the necessary components for the\n        VMServiceLayerRPCClient, including the RabbitMQ RPC client for\n        communicating with the VM Service Layer.\n        \"\"\"\n        self.service_rpc_client = MessagingClient(\n            queue_name=RPCQueueNames.VMS.SERVICE_LAYER\n        )\n\n    def get_vm(self, data: Dict) -> Dict:\n        \"\"\"Retrieve a VM by its ID.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VMServiceLayerProtocolInterface.get_vm.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def get_all_vms(self) -> List[Dict]:\n        \"\"\"Retrieve all VMs from the database.\n\n        Returns:\n            List[Dict]: List of serialized VM data.\n        \"\"\"\n        result: List[Dict] = self.service_rpc_client.call(\n            VMServiceLayerProtocolInterface.get_all_vms.__name__,\n            data_for_method={},\n        )\n        return result\n\n    def create_vm(self, data: Dict) -> Dict:\n        \"\"\"Create a new VM.\n\n        Args:\n            data (Dict): Information about the VM to be created.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VMServiceLayerProtocolInterface.create_vm.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def delete_vm(self, data: Dict) -> Dict:\n        \"\"\"Delete an existing VM.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VMServiceLayerProtocolInterface.delete_vm.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def start_vm(self, data: Dict) -> Dict:\n        \"\"\"Start a VM.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VMServiceLayerProtocolInterface.start_vm.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def shut_off_vm(self, data: Dict) -> Dict:\n        \"\"\"Shut off a VM.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VMServiceLayerProtocolInterface.shut_off_vm.__name__,\n            data_for_method=data,\n        )\n        return result\n\n    def edit_vm(self, edit_info: Dict) -> Dict:\n        \"\"\"Edit an existing VM.\n\n        Args:\n            edit_info (Dict): Information about the VM to be edited.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VMServiceLayerProtocolInterface.edit_vm.__name__,\n            data_for_method=edit_info,\n        )\n        return result\n\n    def vnc(self, data: Dict) -> Dict:\n        \"\"\"Retrieve VNC information for a VM.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: VNC connection data.\n        \"\"\"\n        result: Dict = self.service_rpc_client.call(\n            VMServiceLayerProtocolInterface.vnc.__name__,\n            data_for_method=data,\n        )\n        return result\n"}
{"type": "source_file", "path": "openvair/libs/client/image_client.py", "content": "# noqa: D100\n# in current moment this module is unused. It need to be adopted with actual rpc\n# client functionality\nfrom openvair.libs.client.base_client import BaseClient\n\n\n# Unuse in current version need to be implemented from service interfaces and\n# make polymorphic use for all clients\nclass ImageClient(BaseClient):  # noqa: D101\n    def __init__(self, access_token: str):  # noqa: D107\n        super().__init__(service='images', access_token=access_token)\n\n    def attach_image(self, image_id: str, attach_info: dict):  # noqa: D102, ANN201\n        image_attach_url = f'{self.url}/{image_id}/attach/'\n        result = self.session.post(\n            image_attach_url, json=attach_info, headers=self.header\n        )\n        return result.json()\n\n    def get_images_by_storage_id(self, storage_id: str):  # noqa: ANN201, D102\n        image_get_url = f'{self.url}/'\n        result = self.session.get(\n            image_get_url,\n            params={'storage_id': storage_id},\n            headers=self.header,\n        )\n        return result.json().get('items', [])\n\n    def detach_image(self, image_id: str, detach_info: dict):  # noqa: D102, ANN201\n        image_detach_url = f'{self.url}/{image_id}/detach/'\n        result = self.session.delete(\n            image_detach_url, json=detach_info, headers=self.header\n        )\n        return result.json()\n"}
{"type": "source_file", "path": "openvair/libs/client/config.py", "content": "\"\"\"Module for handling configuration-related utilities.\n\nThis module provides various utility functions for retrieving configuration\ndata such as URLs, credentials, and settings from the project configuration.\nIt also handles the initialization of external services like Sentry.\n\nFunctions:\n    get_web_app_url: Retrieves the web application URL from the config.\n    get_prometheus_url: Retrieves the Prometheus service URL from the config.\n    get_default_user: Retrieves the default user credentials.\n    get_snmp_agent: Retrieves the SNMP agent type.\n    get_os_type: Retrieves the operating system type.\n    get_routes: Retrieves the routes for the documentation, if available.\n    get_sentry_dsn: Initializes Sentry if a DSN is provided in the config.\n    _check_docs_routes: Checks if the documentation routes exist.\n    _set_sentry_dsn: Sets the Sentry DSN for error tracking.\n\"\"\"\n\nimport pathlib\nfrom typing import Any, Dict, Tuple\n\nimport sentry_sdk\n\nfrom openvair import config\n\n\ndef get_web_app_url() -> str:\n    \"\"\"Retrieve the web application URL from the config.\n\n    This function reads the `web_app` configuration and constructs the URL\n    for the web application based on the host and port specified.\n\n    Returns:\n        str: The URL of the web application.\n    \"\"\"\n    web_app = config.data.get('web_app', {})\n    host = web_app.get('host', 'localhost')\n    port = web_app.get('port', 8000)\n    return f'https://{host}:{port}'\n\n\ndef get_prometheus_url() -> str:\n    \"\"\"Retrieve the Prometheus service URL from the config.\n\n    This function reads the `prometheus` configuration and constructs the URL\n    for the Prometheus service based on the host and port specified.\n\n    Returns:\n        str: The URL of the Prometheus service.\n    \"\"\"\n    prometheus_app = config.data.get('prometheus', {})\n    host = prometheus_app.get('host', 'localhost')\n    port = prometheus_app.get('port', 9090)\n    return f'https://{host}:{port}'\n\n\ndef get_default_user() -> Tuple[str, str]:\n    \"\"\"Retrieve the default user credentials from the config.\n\n    This function reads the `default_user` configuration and returns the\n    login and password for the default user.\n\n    Returns:\n        Tuple[str, str]: A tuple containing the login and password.\n    \"\"\"\n    default_user = config.data.get('default_user', {})\n    login = default_user.get('login', '')\n    password = default_user.get('password', '')\n    return login, password\n\n\ndef get_snmp_agent() -> str:\n    \"\"\"Retrieve the SNMP agent type from the config.\n\n    This function reads the `snmp` configuration and returns the specified\n    SNMP agent type.\n\n    Returns:\n        str: The type of SNMP agent.\n    \"\"\"\n    snmp: Dict[str, str] = config.data.get('snmp', {})\n    return snmp.get('agent_type', '')\n\n\ndef get_os_type() -> str:\n    \"\"\"Retrieve the operating system type from the config.\n\n    This function reads the `OS_data` configuration and returns the specified\n    operating system type.\n\n    Returns:\n        str: The name of the operating system.\n    \"\"\"\n    os_data: Dict[str, str] = config.data.get('OS_data', {})\n    return os_data.get('os_type', 'ubuntu')\n\n\ndef _check_docs_routes() -> bool:\n    \"\"\"Check if the documentation routes exist.\n\n    This function checks the existence of specific directories related to the\n    documentation routes.\n\n    Returns:\n        bool: True if the documentation routes exist, False otherwise.\n    \"\"\"\n    docs_folder_path = f'{config.PROJECT_ROOT}/docs'\n    build_folder_path = f'{docs_folder_path}/build'\n    entrypoints_folder_path = f'{build_folder_path}/entrypoints'\n\n    return any(\n        [\n            pathlib.Path(docs_folder_path).exists(),\n            pathlib.Path(build_folder_path).exists(),\n            pathlib.Path(entrypoints_folder_path).exists(),\n        ]\n    )\n\n\ndef get_routes() -> Any:  # noqa: ANN401\n    \"\"\"Retrieve the routes for the documentation, if available.\n\n    This function checks if the documentation routes exist and returns them.\n    If they do not exist or if there is an error, it returns None.\n\n    Returns:\n        Optional: Documentation routes if available, otherwise None.\n    \"\"\"\n    routes = None\n\n    try:\n        if _check_docs_routes():\n            from docs.entrypoints.api import docs_routes  # noqa: I001 # type: ignore\n\n            routes = docs_routes()\n    except ImportError:\n        pass\n\n    return routes\n\n\ndef get_sentry_dsn() -> None:\n    \"\"\"Initialize Sentry if a DSN is provided in the config.\n\n    This function retrieves the Sentry DSN from the configuration and\n    initializes Sentry for error tracking if the DSN is specified.\n    \"\"\"\n    sentry_dsn = config.data.get('sentry', {}).get('dsn')\n    if sentry_dsn:\n        _set_sentry_dsn(sentry_dsn)\n\n\ndef _set_sentry_dsn(sentry_dsn: str) -> None:\n    \"\"\"Set the Sentry DSN for error tracking.\n\n    This function configures Sentry with the provided DSN token.\n\n    Args:\n        sentry_dsn (str): The Sentry DSN token.\n    \"\"\"\n    sentry_sdk.init(\n        dsn=sentry_dsn,\n        traces_sample_rate=1.0,\n    )\n\n\nPROMETHEUS_QUERIES = {\n    # Prometheus queries for various metrics.\n    'io-read-ps': {\n        'query': 'sum(rate(node_disk_reads_completed_total[30s]))',\n        'unit': 'io-ps',\n    },\n    'io-write-ps': {\n        'query': 'sum(rate(node_disk_writes_completed_total[30s]))',\n        'unit': 'io-ps',\n    },\n    'bandwidth-read': {\n        'query': (\n            'sum(rate(node_network_receive_bytes_total[30s])) / 1024 / 1024'\n        ),\n        'unit': 'b/s',\n    },\n    'bandwidth-write': {\n        'query': (\n            'sum(rate(node_network_transmit_bytes_total[30s])) / 1024 / 1024'\n        ),\n        'unit': 'b/s',\n    },\n    'disk-read': {\n        'query': 'sum(rate(node_disk_read_bytes_total[30s])) / 1024 / 1024',\n        'unit': 'b/s',\n    },\n    'disk-write': {\n        'query': 'sum(rate(node_disk_written_bytes_total[30s])) / 1024 / 1024',\n        'unit': 'b/s',\n    },\n    'latency': {\n        'query': 'irate(node_pressure_io_waiting_seconds_total[30s])',\n        'unit': 's',\n    },\n    'ram-total': {\n        'query': 'node_memory_MemTotal_bytes',\n        'unit': 'B',\n    },\n    'ram-free': {\n        'query': 'node_memory_MemFree_bytes',\n        'unit': 'B',\n    },\n    'ram-used': {\n        # This query calculates the total amount of memory used by the node or\n        # computer in bytes by subtracting free memory, buffered memory,\n        # cached memory, and reclaimable memory from total memory.\n        'query': 'node_memory_MemTotal_bytes - node_memory_MemFree_bytes'\n        '- node_memory_Buffers_bytes - node_memory_Cached_bytes'\n        '- node_memory_SReclaimable_bytes',\n        'unit': 'B',\n    },\n    'ram-available': {'query': 'node_memory_MemAvailable_bytes', 'unit': 'B'},\n    'ram-commited': {'query': 'node_memory_Committed_AS_bytes', 'unit': 'B'},\n    'cpu-seconds-total': {\n        'query': 'sum(node_cpu_scaling_frequency_hertz)',\n        'unit': 'Hz',\n    },\n    # To get CPU usage percentage in Prometheus, you can use the\n    # node_cpu_seconds_total metric, which provides a counter of CPU usage time.\n    # To calculate usage percentage, you can use the following query:\n    # avg(irate(node_cpu_seconds_total{mode='idle'}[30s])) * 100\n    # This query uses the irate() function to calculate the rate of change of\n    # the metric over the last interval (in this case, 30 seconds). Then the\n    # avg() function calculates the average rate of change across all node\n    # instances (as specified in the metric), selecting only the value of the\n    # metric for mode=\"idle\", i.e., unused CPU resources. The resulting value\n    # is multiplied by 100 to get the CPU usage percentage.\n    'cpu-usage-percentage': {\n        'query': \"avg(irate(node_cpu_seconds_total{mode='idle'}[30s])) * 100\",\n        'unit': 'Hz',\n    },\n    'cpu-counts-cores': {\n        'query': 'count(node_cpu_seconds_total{mode=~\"system\"})',\n        'unit': 'Hz',\n    },\n    'cpu-max-frequency': {\n        'query': 'sum(node_cpu_frequency_max_hertz)',\n        'unit': 'Hz',\n    },\n    'size-total': {\n        # 'query': 'sum(node_filesystem_size_bytes)',\n        # # hard disc\n        'query': 'sum(node_filesystem_size_bytes{mountpoint=~\"/opt/aero/openvair/data/mnt.*\"})',  # NFS  # noqa: E501\n        'unit': 'B',\n    },\n    'size-used': {\n        # 'query': 'sum(node_filesystem_size_bytes)-sum(node_filesystem_avail_bytes)',  # hard disc  # noqa: E501, W505\n        'query': 'sum(node_filesystem_size_bytes{mountpoint=~\"/opt/aero/openvair/data/mnt.*\"})'  # NFS + localfs  # noqa: E501\n        '-sum(node_filesystem_avail_bytes{mountpoint=~\"/opt/aero/openvair/data/mnt.*\"})',\n        'unit': 'B',\n    },\n    'size-free': {\n        # 'query': 'sum(node_filesystem_avail_bytes)',# hard disc\n        'query': 'sum(node_filesystem_avail_bytes{mountpoint=~\"/opt/aero/openvair/data/mnt.*\"})',  # NFS + localfs  # noqa: E501\n        'unit': 'B',\n    },\n    'size-free-system': {\n        'query': 'node_filesystem_avail_bytes{mountpoint=~\"/\"}',\n        'unit': 'B',\n    },\n    'size-system': {\n        'query': 'node_filesystem_size_bytes{mountpoint=~\"/\"}',\n        'unit': 'B',\n    },\n}\n"}
{"type": "source_file", "path": "openvair/libs/messaging/rpc/rabbit_rpc.py", "content": "\"\"\"RPC client and server implementation module.\n\nThis module provides classes for implementing an RPC client and server\nusing RabbitMQ as the transport layer.\n\nUsage example:\n    1.\n        rpc_client = RabbitRPCClient('queue_name_1')\n        # issubclass(data_for_manager, dict) == True\n        result = rpc_client.call('manager_method_name', data_for_method)\n\n        # Manager is a class that implements business logic or domain logic\n        rpc_server = rpc.RPCServer('queue_name_1', Manager)\n\n    2.\n        self.rpc_client = rpc.RabbitRPCClient('queue_name_2')\n        # issubclass(data_for_manager, dict) == True\n        # data_for_manager is a parameter that will be passed to the manager\n        # for its initialization. Additionally, method data can be passed here.\n        result = self.rpc_client.call('method_name', data_for_manager=data)\n\n        rpc_server = rpc.RabbitRPCServer('queue_name_2', manager)\n\nClasses:\n    RabbitRPCClient: Concrete implementation for rabbit rpc client.\n    RabbitRPCServer: Concrete implementation for rabbit rpc server.\n\"\"\"\n\nimport uuid\nfrom typing import (\n    Any,\n    Dict,\n    TypeVar,\n    Callable,\n    Optional,\n    cast,\n)\n\nimport pika\nfrom pika.spec import Basic\nfrom pika.adapters.blocking_connection import BlockingChannel\n\nfrom openvair.libs.messaging import utils\nfrom openvair.libs.messaging.exceptions import (\n    RpcCallException,\n    RpcCallTimeoutException,\n)\nfrom openvair.libs.messaging.rpc.rabbit_base import (\n    BaseRabbitRPCClient,\n    BaseRabbitRPCServer,\n)\n\nT = TypeVar('T')\n\n\nclass RabbitRPCClient(BaseRabbitRPCClient):\n    \"\"\"Concrete implementation for rabbit rpc client.\n\n    This class sends messages to the RPC server and processes responses.\n\n    Attributes:\n        queue_name (str): Name of the queue to send messages to.\n    \"\"\"\n\n    def __init__(self, queue_name: str, callback_queue_name: str = ''):\n        \"\"\"Initialize the RPC client with a specific queue.\n\n        Args:\n            queue_name (str): The name of the queue to send messages to.\n            callback_queue_name (str): The name of the callback queue.\n                Defaults to an empty string, which triggers automatic\n                generation of a unique queue name.\n        \"\"\"\n        super().__init__(queue_name, callback_queue_name)\n        self.corr_id: Optional[str]\n\n    def on_response(\n        self,\n        channel: BlockingChannel,  # noqa: ARG002 need for rabbitmq basic_consume\n        method: Basic.Deliver,  # noqa: ARG002 need for rabbitmq basic_consume\n        props: pika.BasicProperties,\n        body: bytes,\n    ) -> None:\n        \"\"\"Process incoming responses from the RPC server.\n\n        This method deserializes the message body and stores the result in\n        the `self.response` attribute.\n\n        Args:\n            channel: The channel on which the message was received.\n            method: Delivery method.\n            props: Message properties.\n            body: The body of the message.\n        \"\"\"\n        if self.corr_id == props.correlation_id:\n            self.response = utils.deserialize(body)\n\n    def call(\n        self,\n        method_name: str,\n        data_for_method: Optional[Dict] = None,\n        data_for_manager: Optional[Dict] = None,\n        *,\n        priority: int = 1,\n        time_limit: int = 100,\n    ) -> Any:  # noqa: ANN401 TODO need to spicify response by pydantic\n        \"\"\"Send a request to the RPC server and wait for a response.\n\n        Args:\n            method_name (str): The name of the method to be called on the\n                server.\n            data_for_method (Optional[Dict]): The data to be passed to the\n                method.\n            data_for_manager (Optional[Dict]): The data for initializing the\n                manager.\n            priority (int): The priority of the message. Defaults to 1.\n            time_limit (int): The time limit for waiting for a response.\n                Defaults to 100.\n\n        Returns:\n            Dict: The result of the method call on the RPC server.\n\n        Raises:\n            RpcCallTimeoutException: If the response is not received within the\n                time limit.\n            RpcCallException: If the RPC server returns an error.\n        \"\"\"\n        self.response = {}\n        self.corr_id = str(uuid.uuid4())\n        self.channel.basic_publish(\n            exchange='',\n            routing_key=self.queue_name,\n            properties=pika.BasicProperties(\n                reply_to=self.callback_queue,\n                correlation_id=self.corr_id,\n                priority=priority,\n            ),\n            body=utils.serialize(\n                {\n                    'method_name': method_name,\n                    'data_for_method': data_for_method,\n                    'data_for_manager': data_for_manager,\n                }\n            ).encode(),\n        )\n        # Wait for a response from the RPC server\n        self.connection.process_data_events(time_limit=time_limit)\n        if not self.response:\n            message = (\n                f'connection timeout expired: '\n                f'{self.params.blocked_connection_timeout}'\n            )\n            raise RpcCallTimeoutException(message)\n        if self.response.get('err'):\n            raise RpcCallException(str(self.response['err']))\n        return self.response.get('data', {})\n\n    def cast(\n        self,\n        method_name: str,\n        data_for_method: Optional[Dict] = None,\n        data_for_manager: Optional[Dict] = None,\n        *,\n        priority: int = 10,\n    ) -> None:\n        \"\"\"Send a request to the RPC server without waiting for a response.\n\n        Args:\n            method_name (str): The name of the method to be called on the\n                server.\n            data_for_method (Optional[Dict]): The data to be passed to the\n                method.\n            data_for_manager (Optional[Dict]): The data for initializing the\n                manager.\n            priority (int): The priority of the message. Defaults to 10.\n        \"\"\"\n        self.corr_id = str(uuid.uuid4())\n        self.channel.basic_publish(\n            exchange='',\n            routing_key=self.queue_name,\n            properties=pika.BasicProperties(\n                correlation_id=self.corr_id, priority=priority\n            ),\n            body=utils.serialize(\n                {\n                    'method_name': method_name,\n                    'data_for_method': data_for_method,\n                    'data_for_manager': data_for_manager,\n                }\n            ).encode(),\n        )\n\n\nclass RabbitRPCServer(BaseRabbitRPCServer):\n    \"\"\"Concrete implementation for rabbit rpc server.\n\n    This class listens for incoming messages, initializes a manager, and\n    executes the appropriate method on the manager.\n\n    Attributes:\n        manager: The manager class whose methods will be executed.\n    \"\"\"\n\n    def __init__(self, queue_name: str, manager: Callable):\n        \"\"\"Initialize the RPC server and start listening to the queue.\n\n        Args:\n            queue_name (str): The name of the queue to listen to.\n            manager (Type): The manager class whose methods will be executed.\n        \"\"\"\n        super().__init__(queue_name, manager)\n        self.channel.basic_qos(prefetch_count=1)\n        self.channel.basic_consume(\n            queue=queue_name, on_message_callback=self.on_request\n        )\n\n    def start(self) -> None:\n        \"\"\"Starts server instance\"\"\"\n        self.channel.start_consuming()\n\n    def on_request(\n        self,\n        channel: BlockingChannel,\n        method: Basic.Deliver,\n        props: pika.BasicProperties,\n        body: bytes,\n    ) -> None:\n        \"\"\"Process incoming requests from the RPC client.\n\n        This method deserializes the message, initializes the manager,\n        and executes the appropriate method. The result is sent back\n        to the client.\n\n        Args:\n            channel: The channel on which the message was received.\n            method: Delivery method.\n            props: Message properties.\n            body: The body of the message.\n        \"\"\"\n        deserialized_body = utils.deserialize(body)\n        method_name = deserialized_body.get('method_name', None)\n        data_for_method = deserialized_body.get('data_for_method', {})\n        data_for_manager = deserialized_body.get('data_for_manager', {})\n        request = {}\n        try:\n            inited_manager = (\n                self.manager(data_for_manager)\n                if data_for_manager\n                else self.manager()\n            )\n            managers_method = getattr(inited_manager, method_name)\n            result = (\n                managers_method(data_for_method)\n                if data_for_method\n                else managers_method()\n            )\n            request.update({'data': result})\n        except Exception as err:  # noqa: BLE001 because it's catching all exceptions\n            request.update({'err': str(err)})\n        try:\n            serialized_request = utils.serialize(request)\n        except TypeError as err:\n            serialized_request = utils.serialize({'err': str(err)})\n        if props.reply_to:\n            channel.basic_publish(\n                exchange='',\n                routing_key=props.reply_to,\n                properties=pika.BasicProperties(\n                    correlation_id=props.correlation_id\n                ),\n                body=serialized_request.encode(),\n            )\n        channel.basic_ack(delivery_tag=cast(int, method.delivery_tag))\n"}
{"type": "source_file", "path": "openvair/libs/messaging/service_interfaces/image.py", "content": "\"\"\"Module for managing image-related operations in the service layer.\n\nThis module provides functionality for handling image operations such as\nuploading, retrieving, and managing image metadata. It serves as an\nintermediary between the API layer and the domain layer, coordinating\nimage-related tasks and managing database interactions.\n\nThe module includes an interface definition for the image service layer manager,\nwhich outlines the methods that should be implemented by any class responsible\nfor handling image operations.\n\nClasses:\n    ImageServiceLayerProtocolInterface: Interface for handling image service\n        layer operations.\n\"\"\"\n\nfrom typing import Dict, List, Protocol\n\n\nclass ImageServiceLayerProtocolInterface(Protocol):\n    \"\"\"Interface for the ImageServiceLayerManager.\n\n    This interface defines the methods that should be implemented by any class\n    that manages image-related operations in the service layer.\n    \"\"\"\n\n    def get_image(self, data: Dict) -> Dict:\n        \"\"\"Retrieve an image by its ID.\n\n        Args:\n            data (Dict): Data containing the image ID.\n\n        Returns:\n            Dict: Serialized image data.\n        \"\"\"\n        ...\n\n    def get_all_images(self, data: Dict) -> List[Dict]:\n        \"\"\"Retrieve all images from the database.\n\n        Args:\n            data (Dict): Data for filtering images.\n\n        Returns:\n            List[Dict]: List of serialized image data.\n        \"\"\"\n        ...\n\n    def upload_image(self, image_info: Dict) -> Dict:\n        \"\"\"Upload a new image.\n\n        Args:\n            image_info (Dict): Information about the image to be uploaded.\n\n        Returns:\n            Dict: Serialized image data.\n        \"\"\"\n        ...\n\n    def delete_image(self, data: Dict) -> None:\n        \"\"\"Delete an existing image.\n\n        Args:\n            data (Dict): Data containing the image ID.\n\n        Returns:\n            None\n        \"\"\"\n        ...\n\n    def attach_image(self, data: Dict) -> Dict:\n        \"\"\"Attach an image to a virtual machine.\n\n        Args:\n            data (Dict): Data containing the image ID and VM details.\n\n        Returns:\n            Dict: Result of the attach operation.\n        \"\"\"\n        ...\n\n    def detach_image(self, data: Dict) -> Dict:\n        \"\"\"Detach an image from a virtual machine.\n\n        Args:\n            data (Dict): Data containing the image ID and VM details.\n\n        Returns:\n            Dict: Result of the detach operation.\n        \"\"\"\n        ...\n"}
{"type": "source_file", "path": "openvair/libs/messaging/rpc/base.py", "content": "\"\"\"Base classes for RPC clients and servers.\n\nThis module contains basic classes (interfaces) to create specific\nimplementations of RPC entity classes\n\nClasses:\n    BaseRPCClient: Base class for implementing an RPC client.\n    BaseRPCServer: Base class for implementing an RPC server.\n\"\"\"\n\nfrom abc import ABCMeta, abstractmethod\nfrom typing import Any, Dict, Optional\n\n\nclass BaseRPCClient(metaclass=ABCMeta):\n    \"\"\"Base class for implementing an RPC client.\"\"\"\n\n    @abstractmethod\n    def __init__(self, *args: Any, **kwargs: Any) -> None:  # noqa: ANN401 # casue its base class\n        \"\"\"Initialize RPC Client\"\"\"\n        pass\n\n    @abstractmethod\n    def on_response(self, *args: Any, **kwargs: Any) -> None:  # noqa: ANN401 # casue its base class\n        \"\"\"Handles incoming responses from the RPC server.\"\"\"\n        ...\n\n    @abstractmethod\n    def call(\n        self,\n        method_name: str,\n        data_for_method: Optional[Dict] = None,\n        data_for_manager: Optional[Dict] = None,\n    ) -> Any:  # noqa: ANN401 TODO need to spicify response by pydantic\n        \"\"\"Sends a request to the RPC server and wait for a response.\"\"\"\n        ...\n\n    @abstractmethod\n    def cast(\n        self,\n        method_name: str,\n        data_for_method: Optional[Dict] = None,\n        data_for_manager: Optional[Dict] = None,\n    ) -> None:\n        \"\"\"Sends a request to the RPC server without waiting for a response.\"\"\"\n        ...\n\n\nclass BaseRPCServer(metaclass=ABCMeta):\n    \"\"\"Base class for implementing an RPC server.\"\"\"\n\n    @abstractmethod\n    def __init__(self, *args: Any, **kwargs: Any) -> None:  # noqa: ANN401 # casue its base class\n        \"\"\"Initialize RPC Server\"\"\"\n        pass\n\n    @abstractmethod\n    def on_request(self, *args: Any, **kwargs: Any) -> None:  # noqa: ANN401 # casue its base class\n        \"\"\"Handles incoming requests from the RPC client.\"\"\"\n        ...\n\n    @abstractmethod\n    def start(self) -> None:\n        \"\"\"Starts server instance\"\"\"\n        ...\n"}
{"type": "source_file", "path": "openvair/libs/messaging/messaging_agents.py", "content": "\"\"\"Messaging protocol module.\n\nThis module defines classes for selecting and initializing the appropriate\nprotocol for RPC clients and servers, based on the messaging type and transport.\n\nClasses:\n    BaseAgentMessagingFabric: Abstract base class for selecting messaging agent.\n    ClientMessagingFabric: Class for selecting a client.\n    ServerMessagingFabric: Class for selecting a server.\n    MessagingClient: Class for creating and interacting with an RPC client.\n    MessagingServer: Class for creating and running an RPC server.\n\"\"\"\n\nimport abc\nfrom typing import Any, Dict, Type, Callable, Optional\n\nfrom openvair.libs.messaging import exceptions\nfrom openvair.libs.messaging.config import get_messaging_type_and_transport\nfrom openvair.libs.messaging.rpc.base import BaseRPCClient, BaseRPCServer\nfrom openvair.libs.messaging.rpc.rabbit_rpc import (\n    RabbitRPCClient,\n    RabbitRPCServer,\n)\n\n\nclass BaseAgentMessagingFabric(metaclass=abc.ABCMeta):\n    \"\"\"Abstract base class for selecting messaging agent.\"\"\"\n\n    @staticmethod\n    @abc.abstractmethod\n    def get_rpc_agent(transport: str) -> Type:\n        \"\"\"Get the appropriate protocol class based on the transport.\n\n        Args:\n            transport (str): The transport method (e.g., 'rabbitmq').\n\n        Returns:\n            Type: The protocol class.\n        \"\"\"\n        ...\n\n\nclass ClientMessagingFabric(BaseAgentMessagingFabric):\n    \"\"\"Class for selecting a client.\"\"\"\n\n    @staticmethod\n    def get_rpc_agent(transport: str) -> Type[BaseRPCClient]:\n        \"\"\"Get the client class based on the transport method.\n\n        Args:\n            transport (str): The transport method (e.g., 'rabbitmq').\n\n        Returns:\n            Type: The RPC client class.\n\n        Raises:\n            RpcServerInitializedException: If the server initialization fails.\n        \"\"\"\n        rpc_client_classes: Dict[str, Type[BaseRPCClient]] = {\n            'rabbitmq': RabbitRPCClient,\n        }\n        try:\n            return rpc_client_classes[transport]\n        except KeyError as err:\n            raise exceptions.RpcServerInitializedException(str(err))\n\n\nclass ServerMessagingFabric(BaseAgentMessagingFabric):\n    \"\"\"Class for selecting a server.\"\"\"\n\n    @staticmethod\n    def get_rpc_agent(transport: str) -> Type[BaseRPCServer]:\n        \"\"\"Get the server class based on the transport method.\n\n        Args:\n            transport (str): The transport method (e.g., 'rabbitmq').\n\n        Returns:\n            Type: The RPC server class.\n\n        Raises:\n            RpcClientInitializedException: If the client initialization fails.\n        \"\"\"\n        rpc_server_classes: Dict[str, Type[BaseRPCServer]] = {\n            'rabbitmq': RabbitRPCServer,\n        }\n        try:\n            return rpc_server_classes[transport]\n        except KeyError as err:\n            raise exceptions.RpcClientInitializedException(str(err))\n\n\nclass MessagingServer:\n    \"\"\"Class for creating and running a server.\n\n    This class initializes server based on the specified messaging\n    type and transport, then provides a method to start the server.\n\n    Attributes:\n        queue_name (str): Name of the server's message queue.\n        manager (Type): Manager class to handle server-side operations.\n        server (BaseRPCServer): Instance of the server class.\n    \"\"\"\n\n    messaging_type, transport = get_messaging_type_and_transport()\n\n    def __init__(self, *, queue_name: str, manager: Callable) -> None:\n        \"\"\"Initialize the messaging server with the specified queue and manager.\n\n        Args:\n            queue_name (str): Name of the server's message queue.\n            manager (Type): The manager class to handle operations on the\n                server.\n\n        Raises:\n            AttributeError: If the messaging type is unsupported.\n        \"\"\"\n        self.queue_name = queue_name\n        self.manager = manager\n        if self.messaging_type == 'rpc':\n            server_class = ServerMessagingFabric.get_rpc_agent(self.transport)\n            self.server = server_class(self.queue_name, self.manager)\n        else:\n            msg = f'Unsupported messaging type: {self.messaging_type}'\n            raise AttributeError(msg)\n\n    def start(self) -> None:\n        \"\"\"Start the server to listen for incoming messages.\"\"\"\n        self.server.start()\n\n\nclass MessagingClient:\n    \"\"\"Class for creating and interacting with client.\n\n    This class initializes client based on the specified messaging\n    type and transport, allowing method calls and asynchronous casts.\n\n    Attributes:\n        queue_name (str): Name of the client's message queue.\n        callback_queue_name (str): Name of the client's callback queue for RPC\n            responses.\n        client (BaseRPCClient): Instance of the RPC client class.\n    \"\"\"\n\n    messaging_type, transport = get_messaging_type_and_transport()\n\n    def __init__(\n        self,\n        *,\n        queue_name: str,\n        callback_queue_name: str = '',\n    ) -> None:\n        \"\"\"Initialize the messaging client with the specified queues.\n\n        Args:\n            queue_name (str): Name of the client's message queue.\n            callback_queue_name (str): Optional name of the client's callback\n                queue for responses.\n        \"\"\"\n        self.queue_name = queue_name\n        self.callback_queue_name = callback_queue_name\n        if self.messaging_type == 'rpc':\n            client_class = ClientMessagingFabric.get_rpc_agent(self.transport)\n            self.client = client_class(\n                self.queue_name,\n                self.callback_queue_name,\n            )\n\n    def call(\n        self,\n        method_name: str,\n        data_for_method: Optional[Dict] = None,\n        data_for_manager: Optional[Dict] = None,\n        **kwargs: Any,  # noqa: ANN401 if income spicific args like timout for Rabbit\n    ) -> Any:  # noqa: ANN401 TODO need to spicify response by pydantic\n        \"\"\"Call a method on the RPC server and wait for a response.\n\n        Args:\n            method_name (str): Name of the method to call on the server.\n            data_for_method (Optional[Dict]): Data to pass to the method.\n            data_for_manager (Optional[Dict]): Additional data for the manager.\n            **kwargs: Additional arguments for specific configurations\n                (e.g., timeout).\n\n        Returns:\n            Any: Response from the server.\n        \"\"\"\n        return self.client.call(\n            method_name=method_name,\n            data_for_method=data_for_method,\n            data_for_manager=data_for_manager,\n            **kwargs,\n        )\n\n    def cast(\n        self,\n        method_name: str,\n        data_for_method: Optional[Dict] = None,\n        data_for_manager: Optional[Dict] = None,\n        **kwargs: Any,  # noqa: ANN401 if income spicific args like timout for Rabbit\n    ) -> None:\n        \"\"\"Send a method to the RPC server without waiting for a response.\n\n        Args:\n            method_name (str): Name of the method to invoke on the server.\n            data_for_method (Optional[Dict]): Data to pass to the method.\n            data_for_manager (Optional[Dict]): Additional data for the manager.\n            **kwargs: Additional arguments for specific configurations (e.g.,\n                timeout).\n        \"\"\"\n        self.client.cast(\n            method_name=method_name,\n            data_for_method=data_for_method,\n            data_for_manager=data_for_manager,\n            **kwargs,\n        )\n"}
{"type": "source_file", "path": "openvair/libs/messaging/service_interfaces/backup.py", "content": "\"\"\"Module for managing backup-related operations in the service layer.\n\nThe module includes an interface definition for the backup service layer\nmanager, which outlines the methods that should be implemented by any class\nresponsible for managing backup operations.\n\"\"\"\n\nfrom typing import Protocol\n\n\nclass BackupServiceLayerManagerProtocolInterface(Protocol):\n    \"\"\"Interface for the BackupServiceLayerManager.\n\n    This interface defines the methods that should be implemented by any class\n    that manages backup-related operations in the service layer.\n    \"\"\"\n    ...\n"}
{"type": "source_file", "path": "openvair/libs/messaging/rpc/rabbit_base.py", "content": "\"\"\"RabbitMQ base classes module.\n\nThis module provides a base classes for creating concrete RabbitRPC entities.\nUses the `pika` library\n\nClasses:\n    BaseRabbitRPC: The base class for creating a BaseRabbitRPC client\n        and server\n    BaseRabbitRPCClient: The base class for creating concrete implementation of\n        RabbitRPCClient.\n    BaseRabbitRPCServer:The base class for creating concrete implementation of\n        RabbitRPCServer.\n\"\"\"\n\nfrom abc import abstractmethod\nfrom typing import Any, Dict, Callable, Optional\n\nimport pika\n\nfrom openvair.libs.messaging import config\nfrom openvair.libs.messaging.rpc.base import BaseRPCClient, BaseRPCServer\n\n\nclass BaseRabbitRPC:\n    \"\"\"The base class for creating a Rabbit RPC client and server.\n\n    This class initializes the connection, channel, and sets parameters for\n    working with rabbitmq\n\n    Attributes:\n        params (pika.URLParameters): Connection parameters for the RabbitMQ URL.\n        connection (pika.BlockingConnection): The established blocking\n            connection to RabbitMQ.\n        channel (pika.channel.Channel): The channel for communication with\n            RabbitMQ.\n    \"\"\"\n\n    params = pika.URLParameters(config.get_rabbitmq_url())\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the RabbitMQ connection and channel.\"\"\"\n        self.params.blocked_connection_timeout = 10.0  # type: ignore\n        self.connection = pika.BlockingConnection(self.params)\n        self.channel = self.connection.channel()\n\n\nclass BaseRabbitRPCClient(BaseRabbitRPC, BaseRPCClient):\n    \"\"\"The base class for creating concrete implementation of RabbitRPCClient.\n\n    This class creates a callback queue for receiving responses from the\n    RPC server.\n\n    Attributes:\n        callback_queue_name (str): Name of the callback queue.\n        callback_queue (str): The declared callback queue.\n        response (dict): Stores the server response.\n        corr_id (str): Correlation ID for matching responses.\n    \"\"\"\n\n    def __init__(self, queue_name: str, callback_queue_name: str = ''):\n        \"\"\"Initialize the RPC client with a callback queue.\n\n        Args:\n            queue_name (str): The name of the queue to send messages to.\n            callback_queue_name (str): The name of the callback queue.\n                Defaults to an empty string, which triggers automatic\n                generation of a unique queue name.\n        \"\"\"\n        self.queue_name = queue_name\n        self.callback_queue_name = callback_queue_name\n        super().__init__()\n        result = self.channel.queue_declare(\n            queue=self.callback_queue_name,\n            exclusive=True,\n            arguments={'x-max-priority': 10, 'x-max-length': 200},  # type: ignore\n        )\n        self.callback_queue = result.method.queue\n        self.channel.basic_consume(\n            queue=self.callback_queue,\n            on_message_callback=self.on_response,\n            auto_ack=True,\n        )\n\n        self.response: Dict[str, Dict] = {}\n        self.corr_id: Optional[str] = None\n\n    @abstractmethod\n    def on_response(\n        self,\n        channel: pika.adapters.blocking_connection.BlockingChannel,\n        method: pika.spec.Basic.Deliver,\n        props: pika.BasicProperties,\n        body: bytes,\n    ) -> None:\n        \"\"\"Handles incoming responses from the RPC server.\n\n        This method deserializes the message body and stores the result in\n        the `self.response` attribute.\n\n        Args:\n            channel: The channel on which the message was received.\n            method: Delivery method.\n            props: Message properties.\n            body: The body of the message.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def call(\n        self,\n        method_name: str,\n        data_for_method: Optional[Dict] = None,\n        data_for_manager: Optional[Dict] = None,\n        *,\n        priority: int = 1,\n        time_limit: int = 100,\n    ) -> Any:  # noqa: ANN401 TODO need to spicify response by pydantic\n        \"\"\"Send a request to the RPC server and wait for a response.\n\n        Args:\n            method_name (str): The name of the method to be called on the\n                server.\n            data_for_method (Optional[Dict]): The data to be passed to the\n                method.\n            data_for_manager (Optional[Dict]): The data for initializing the\n                manager.\n            priority (int): The priority of the message. Defaults to 1.\n            time_limit (int): The time limit for waiting for a response.\n                Defaults to 100.\n\n        Returns:\n            Dict: The result of the method call on the RPC server.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def cast(\n        self,\n        method_name: str,\n        data_for_method: Optional[Dict] = None,\n        data_for_manager: Optional[Dict] = None,\n        *,\n        priority: int = 10,\n    ) -> None:\n        \"\"\"Send a request to the RPC server without waiting for a response.\n\n        Args:\n            method_name (str): The name of the method to be called on the\n                server.\n            data_for_method (Optional[Dict]): The data to be passed to the\n                method.\n            data_for_manager (Optional[Dict]): The data for initializing the\n                manager.\n            priority (int): The priority of the message. Defaults to 10.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass BaseRabbitRPCServer(BaseRabbitRPC, BaseRPCServer):\n    \"\"\"The base class for creating concrete implementation of RabbitRPCServer.\n\n    This class declares the queue for listening to incoming messages.\n    \"\"\"\n\n    def __init__(self, queue_name: str, manager: Callable):\n        \"\"\"Initialize the RPC server with a specific queue.\n\n        Args:\n            queue_name (str): The name of the queue to listen to.\n            manager: The manager class whose methods will be executed.\n        \"\"\"\n        super().__init__()\n        self.manager = manager\n        self.channel.queue_declare(\n            queue=queue_name,\n            arguments={'x-max-priority': 10, 'x-max-length': 200},  # type: ignore\n        )\n\n    @abstractmethod\n    def on_request(\n        self,\n        channel: pika.adapters.blocking_connection.BlockingChannel,\n        method: pika.spec.Basic.Deliver,\n        props: pika.BasicProperties,\n        body: bytes,\n    ) -> None:\n        \"\"\"Process incoming requests from the RPC client.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def start(self) -> None:\n        \"\"\"Start the server to listen for incoming messages.\"\"\"\n        raise NotImplementedError\n"}
{"type": "source_file", "path": "openvair/libs/messaging/rpc/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/libs/messaging/service_interfaces/volume.py", "content": "\"\"\"Module for managing the Volume Service Layer.\n\nThis module defines the `VolumeServiceLayerManagerInterface`, which serves as\nthe contract for handling volume-related operations in the service layer.\nAny class implementing this interface is responsible for interacting with the\ndomain layer and the event store to perform various tasks, such as retrieving\nvolume information, creating, extending, deleting, and attaching volumes.\n\nClasses:\n    VolumeServiceLayerManagerInterface: Interface for handling volume service\n        layer operations.\n\"\"\"\n\nfrom typing import Dict, List, Protocol\n\n\nclass VolumeServiceLayerProtocolInterface(Protocol):\n    \"\"\"Interface for the VolumeServiceLayerManager.\n\n    This interface defines the methods that should be implemented by any class\n    that manages volume-related operations in the service layer.\n    \"\"\"\n\n    def get_volume(self, data: Dict) -> Dict:\n        \"\"\"Retrieve a volume by its ID.\n\n        Args:\n            data (Dict): Data containing the volume ID.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        ...\n\n    def get_all_volumes(self, data: Dict) -> List[Dict]:\n        \"\"\"Retrieve all volumes from the database.\n\n        Args:\n            data (Dict): Data for filtering volumes.\n\n        Returns:\n            List[Dict]: List of serialized volume data.\n        \"\"\"\n        ...\n\n    def create_volume(self, volume_info: Dict) -> Dict:\n        \"\"\"Create a new volume.\n\n        Args:\n            volume_info (Dict): Information about the volume to be created.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        ...\n\n    def extend_volume(self, data: Dict) -> Dict:\n        \"\"\"Extend the size of an existing volume.\n\n        Args:\n            data (Dict): Data containing the volume ID and new size.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        ...\n\n    def delete_volume(self, data: Dict) -> Dict:\n        \"\"\"Delete an existing volume.\n\n        Args:\n            data (Dict): Data containing the volume ID.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        ...\n\n    def edit_volume(self, data: Dict) -> Dict:\n        \"\"\"Edit the details of an existing volume.\n\n        Args:\n            data (Dict): Data containing the volume ID and new details.\n\n        Returns:\n            Dict: Serialized volume data.\n        \"\"\"\n        ...\n\n    def attach_volume(self, data: Dict) -> Dict:\n        \"\"\"Attach a volume to a virtual machine.\n\n        Args:\n            data (Dict): Data containing the volume ID and VM details.\n\n        Returns:\n            Dict: Result of the attach operation.\n        \"\"\"\n        ...\n\n    def detach_volume(self, data: Dict) -> Dict:\n        \"\"\"Detach a volume from a virtual machine.\n\n        Args:\n            data (Dict): Data containing the volume ID and VM details.\n\n        Returns:\n            Dict: Result of the detach operation.\n        \"\"\"\n        ...\n"}
{"type": "source_file", "path": "openvair/modules/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/modules/backup/adapters/restic/restic.py", "content": "\"\"\"Adapter for interacting with restic by executing bash command.\n\nThis module provides the `ResticAdapter` class, which is used to manage\nbackuping through the restic app.\n\nClasses:\n    ResticAdapter: Adapter class for managing backups.\n\"\"\"\n\nimport json\nfrom typing import Dict, List, Union, Optional\nfrom pathlib import Path\n\nfrom openvair.libs.log import get_logger\nfrom openvair.libs.cli.models import ExecutionResult\nfrom openvair.modules.tools.utils import change_directory\nfrom openvair.modules.backup.adapters.restic.exceptions import (\n    ResticError,\n    ResticBackupError,\n    ResticRestoreError,\n    ResticInitRepoError,\n)\nfrom openvair.modules.backup.adapters.restic.return_codes import ReturnCode\nfrom openvair.modules.backup.adapters.restic.restic_executor import (\n    ResticCommandExecutor,\n)\n\nLOG = get_logger(__name__)\n\n\nclass ResticAdapter:\n    \"\"\"Encapsulates business logic for interacting with restic.\n\n    This class provides methods for initializing repositories, performing\n    backups, restoring data, and fetching snapshots, leveraging the\n    ResticCommandExecutor to execute commands and validate results.\n\n    Attributes:\n        INIT_SUBCOMMAND (str): Subcommand for initializing a repository.\n        BACKUP_SUBCOMMAND (str): Subcommand for creating backups.\n        RESTORE_SUBCOMMAND (str): Subcommand for restoring data.\n        SNAPSHOTS_SUBCOMMAND (str): Subcommand for listing snapshots.\n        restic_dir (Path): Path to the restic repository.\n        restic_pass (str): Password for the restic repository.\n        executor (ResticCommandExecutor): The command executor for restic.\n    \"\"\"\n\n    INIT_SUBCOMMAND = 'init'\n    BACKUP_SUBCOMMAND = 'backup --skip-if-unchanged'\n    RESTORE_SUBCOMMAND = 'restore --target'\n    SNAPSHOTS_SUBCOMMAND = 'snapshots'\n\n    def __init__(self, restic_dir: Path, restic_pass: str) -> None:\n        \"\"\"Initialize a ResticAdapter instance.\n\n        This initializes the adapter with the repository path and password\n        from the configuration, and sets up the ResticCommandExecutor.\n        \"\"\"\n        self.restic_dir = restic_dir\n        self.restic_pass = restic_pass\n        self.executor = ResticCommandExecutor(\n            str(self.restic_dir),\n            self.restic_pass,\n        )\n\n    def init_repository(self) -> None:\n        \"\"\"Executes the command to initialize a restic repository.\n\n        Raises:\n            ResticInitRepoError: If the repository initialization fails.\n        \"\"\"\n        result = self.executor.execute(self.INIT_SUBCOMMAND)\n\n        try:\n            self._check_result(\n                self.INIT_SUBCOMMAND,\n                result,\n                ReturnCode.from_code(result.returncode),\n            )\n        except ResticError as err:\n            actual_error = ResticInitRepoError(f'{err!s}')\n            LOG.error(actual_error)\n            raise actual_error from err\n\n    def backup(self, source_path: Path) -> Dict[str, Union[str, int]]:\n        \"\"\"Performs a backup of the specified source path.\n\n        Args:\n            source_path (Path): Path to the directory or files to back up.\n\n        Returns:\n            Dict[str, Union[str, int]]: Information about the backup, parsed\n                from the JSON output of the restic command.\n                - message_type: Always “summary”\n                - files_new: Number of new files\n                - files_changed: Number of files that changed\n                - files_unmodified: Number of files that did not change\n                - dirs_new: Number of new directories\n                - dirs_changed: Number of directories that changed\n                - dirs_unmodified: Number of directories that did not change\n                - data_blobs: Number of data blobs added\n                - tree_blobs: Number of tree blobs added\n                - data_added: Amount of (uncompressed) data added, in bytes\n                - data_added_packed: Amount of data added (after compression),\n                    in bytes\n                - total_files_processed: Total number of files processed\n                - total_bytes_processed: Total number of bytes processed\n                - total_duration: Total time it took for the operation to\n                    complete\n                - snapshot_id: ID of the new snapshot. Field is omitted if\n                    snapshot creation was skipped\n        Raises:\n            ResticBackupError: If the backup operation fails.\n        \"\"\"\n        with change_directory(source_path):\n            result = self.executor.execute(f'{self.BACKUP_SUBCOMMAND} * ')\n\n        try:\n            self._check_result(\n                self.BACKUP_SUBCOMMAND,\n                result,\n                ReturnCode.from_code(result.returncode),\n            )\n        except ResticError as err:\n            actual_error = ResticBackupError(f'{err!s}')\n            LOG.error(actual_error)\n            raise actual_error from err\n\n        backup_info: Dict[str, Union[str, int]] = json.loads(result.stdout)\n        return backup_info\n\n    def snapshots(self) -> List[Dict[str, Union[str, int]]]:\n        \"\"\"Fetches a list of snapshots from the restic repository.\n\n        Returns:\n            List[Dict[str, Union[str, int]]]: List of snapshot details, parsed\n                from the JSON output of the restic command.\n                snapshot details:\n                - time: Timestamp of when the backup was started\n                - parent: ID of the parent snapshot\n                - tree: ID of the root tree blob\n                - paths: List of paths included in the backup\n                - hostname: Hostname of the backed up machine\n                - username: Username the backup command was run as\n                - uid: ID of owner\n                - gid: ID of group\n                - excludes: List of paths and globs excluded from the backup\n                - tags: List of tags for the snapshot in question\n                - program_version: restic version used to create snapshot\n                - summary: Snapshot statistics, see “Summary object”\n                - id: Snapshot ID\n                - short_id: Snapshot ID, short form\n        \"\"\"\n        result = self.executor.execute(self.SNAPSHOTS_SUBCOMMAND)\n\n        self._check_result(\n            self.SNAPSHOTS_SUBCOMMAND,\n            result,\n            ReturnCode.from_code(result.returncode),\n        )\n\n        snapshots_info: List[Dict[str, Union[str, int]]] = json.loads(\n            result.stdout\n        )\n        return snapshots_info\n\n    def restore(\n        self,\n        target_path: Path,\n        backup_id: str,\n    ) -> Dict[str, Union[str, int]]:\n        \"\"\"Restores data from a specified backup.\n\n        Args:\n            target_path (Path): Path to restore data to.\n            backup_id (str, optional): ID of the backup to restore. Defaults to\n                'latest'.\n\n        Returns:\n            Dict[str, Union[str, int]]: Information about the restore process,\n            parsed from the JSON output of the restic command.\n            - message_type: Always “summary”\n            - seconds_elapsed: Time since restore started\n            - total_files: Total number of files detected\n            - files_restored: Files restored\n            - files_skipped: Files skipped due to overwrite setting\n            - total_bytes: Total number of bytes in restore set\n            - bytes_restored: Number of bytes restored\n            - bytes_skipped: Total size of skipped files\n        Raises:\n            ResticRestoreError: If the restore operation fails.\n        \"\"\"\n        result = self.executor.execute(\n            f'{self.RESTORE_SUBCOMMAND} {target_path} {backup_id}'\n        )\n\n        try:\n            self._check_result(\n                self.BACKUP_SUBCOMMAND,\n                result,\n                ReturnCode.from_code(result.returncode),\n            )\n        except ResticError as err:\n            actual_error = ResticRestoreError(f'{err!s}')\n            LOG.error(actual_error)\n            raise actual_error from err\n\n        restore_info: Dict[str, Union[str, int]] = json.loads(result.stdout)\n        return restore_info\n\n    def _check_result(\n        self,\n        operation: str,\n        result: ExecutionResult,\n        return_code: Optional[ReturnCode],\n    ) -> None:\n        \"\"\"Checks the result of a restic command and validates its success.\n\n        Args:\n            operation (str): The operation being performed (e.g., \"backup\").\n            result (ExecutionResult): The result of the executed command.\n            return_code (Optional[ReturnCode]): The return code of the command.\n\n        Raises:\n            ResticError: If the command result is unsuccessful or the return\n                code indicates failure.\n        \"\"\"\n        if return_code is None or return_code != ReturnCode.SUCCESS:\n            description = (\n                return_code.description if return_code else 'Unknown exit code'\n            )\n            message = (\n                f'Operation {operation} not success '\n                f'(exit code: {result.returncode}, description: {description})'\n                f'\\n\\tstderr: {result.stderr}'\n            )\n            error = ResticError(message)\n            raise error\n"}
{"type": "source_file", "path": "openvair/modules/backup/adapters/restic/exceptions.py", "content": "\"\"\"Module for custom exceptions in the restic adapters.\"\"\"\n\nfrom typing import Any\n\nfrom openvair.abstracts.base_exception import BaseCustomException\n\n\nclass ResticError(BaseCustomException):\n    \"\"\"Base errro class for error in restic adapter\"\"\"\n\n    def __init__(self, message: str, *args: Any):  # noqa: ANN401\n        \"\"\"Initialize ResticAdapterException\"\"\"\n        super().__init__(message, args)\n\n\nclass ResticExecutorError(ResticError):\n    \"\"\"Raises when execution failed\"\"\"\n\n    ...\n\n\nclass ResticInitRepoError(ResticError):\n    \"\"\"Raises when getting error while initialize restic repository\"\"\"\n\n    ...\n\n\nclass ResticBackupError(ResticError):\n    \"\"\"Raises when error while backup restic operation\"\"\"\n\n    ...\n\nclass ResticRestoreError(ResticError):\n    \"\"\"Raises when error while restoring restic operation\"\"\"\n\n    ...\n"}
{"type": "source_file", "path": "openvair/modules/backup/adapters/restic/return_codes.py", "content": "\"\"\"Module for defining and managing restic return codes.\n\nThis module provides an Enum class to represent the various exit codes\nproduced by restic commands. Each exit code is associated with a textual\ndescription, allowing for better readability and error handling in\nrestic-based applications.\n\nTypical usage example:\n    result_code = ReturnCode.from_code(0)\n    if result_code == ReturnCode.SUCCESS:\n        print(\"Command executed successfully.\")\n\"\"\"\n\nfrom enum import Enum\nfrom typing import Optional\n\nfrom typing_extensions import Self\n\n\nclass ReturnCode(Enum):\n    \"\"\"Represents exit codes for commands and their descriptions.\n\n    This Enum maps numerical exit codes to their corresponding textual\n    descriptions. These exit codes help interpret the results of restic\n    commands and provide meaningful messages for debugging or error handling.\n\n    Attributes:\n        code (int): The numerical exit code associated with a command.\n        description (str): A textual description explaining the exit code.\n    \"\"\"\n\n    SUCCESS = 0, 'Command was successful'\n    COMMAND_FAILED = 1, 'Command failed'\n    GO_RUNTIME_ERROR = 2, 'Go runtime error'\n    PARTIAL_BACKUP = 3, 'Backup command could not read some source data'\n    REPO_NOT_EXIST = 10, 'Repository does not exist'\n    REPO_LOCK_FAILED = 11, 'Failed to lock repository'\n    WRONG_PASSWORD = 12, 'Wrong password'\n    INTERRUPTED = 130, 'Restic was interrupted using SIGINT or SIGSTOP'\n\n    def __init__(self, code: int, description: str) -> None:\n        \"\"\"Initializes a ReturnCode instance with a code and description.\n\n        Args:\n            code (int): The numerical exit code associated with the command.\n            description (str): A textual description of the exit code.\n        \"\"\"\n        self.code: int = code\n        self.description: str = description\n\n    @classmethod\n    def from_code(cls, code: int) -> Optional[Self]:\n        \"\"\"Finds the corresponding ReturnCode by numerical exit code.\n\n        Args:\n            code (int): The numerical exit code to look up.\n\n        Returns:\n            Optional[Self]: The matching ReturnCode instance if found, or None\n                if the code does not correspond to a defined ReturnCode.\n        \"\"\"\n        return next((rc for rc in cls if rc.code == code), None)\n"}
{"type": "source_file", "path": "openvair/main.py", "content": "\"\"\"Main entry point for the OpenVair application.\n\nThis module sets up the FastAPI application, including routing, middleware,\nand exception handling. It also configures the CORS settings and initializes\nthe web server with Uvicorn.\n\nRoutes:\n    Includes routers for various modules such as user, image, volume, network,\n    and more.\n\nMiddleware:\n    Adds logging middleware to log each incoming request.\n\nException Handlers:\n    Defines custom exception handlers for handling RPC call errors,\n    initialization errors, and validation errors.\n\nFunctions:\n    log_middleware: Middleware to log HTTP requests.\n    root: The root endpoint that serves the index.html template.\n    rpc_call_exception_handler: Handles RpcCallException.\n    rpc_call_timeout_exception_handler: Handles RpcCallTimeoutException.\n    rpc_init_exception_handler: Handles RpcClientInitializedException.\n    validate_exception_handler: Handles TypeError, ValueError, and\n        AssertionError.\n\"\"\"\n\nfrom typing import Callable, Awaitable\nfrom pathlib import Path\nfrom datetime import datetime\n\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import Response, JSONResponse\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi_pagination import add_pagination\nfrom fastapi.staticfiles import StaticFiles\n\nfrom openvair.libs.log import get_logger\nfrom openvair.libs.client.config import get_routes\nfrom openvair.libs.messaging.exceptions import (\n    RpcCallException,\n    RpcCallTimeoutException,\n    RpcClientInitializedException,\n)\n\nLOG = get_logger(__name__)\n\napp = FastAPI(\n    routes=get_routes(),\n    docs_url='/swagger',\n    redoc_url=None,\n)\nadd_pagination(app)\n\nfrom fastapi.middleware.cors import CORSMiddleware\n\n# Configure CORS settings to allow specified origins\norigins = [\n    'https://localhost',\n    'https://localhost:8080',\n    'https://localhost:8081',\n    'https://localhost:8082',\n    'https://0.0.0.0:8000',\n    'https://0.0.0.0:8000/dashboard/',\n]\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins,\n    allow_credentials=True,\n    allow_methods=['*'],\n    allow_headers=['*'],\n)\n\nfrom openvair.modules.user.entrypoints.api import router as user\nfrom openvair.modules.image.entrypoints.api import router as image\nfrom openvair.modules.user.entrypoints.auth import router as auth\nfrom openvair.modules.backup.entrypoints.api import router as backup_router\nfrom openvair.modules.volume.entrypoints.api import router as volume\nfrom openvair.modules.network.entrypoints.api import router as network\nfrom openvair.modules.storage.entrypoints.api import router as storage\nfrom openvair.modules.dashboard.entrypoints.api import router as dashboard\nfrom openvair.modules.event_store.entrypoints.api import router as event_store\nfrom openvair.modules.block_device.entrypoints.api import router as block_router\nfrom openvair.modules.notification.entrypoints.api import (\n    router as notification_router,\n)\nfrom openvair.modules.virtual_network.entrypoints.api import router as vn_router\nfrom openvair.modules.virtual_machines.entrypoints.api import (\n    router as vm_router,\n)\n\n# Include routers for different modules\napp.include_router(network)\napp.include_router(dashboard)\napp.include_router(storage)\napp.include_router(user)\napp.include_router(auth)\napp.include_router(volume)\napp.include_router(image)\napp.include_router(vm_router)\napp.include_router(event_store)\napp.include_router(notification_router)\napp.include_router(block_router)\napp.include_router(vn_router)\napp.include_router(backup_router)\n\nproject_dir = Path(__file__).parent\ntemplates = Jinja2Templates(directory=project_dir / 'dist')\napp.mount('/assets', StaticFiles(directory=project_dir / 'dist/assets'))\n\n\n@app.middleware('http')\nasync def log_middleware(\n    request: Request,\n    call_next: Callable[[Request], Awaitable[Response]],\n) -> Response:\n    \"\"\"Middleware to log each HTTP request.\n\n    Logs the URL and method of each incoming request.\n\n    Args:\n        request (Request): The incoming HTTP request.\n        call_next (function): The next middleware or route handler.\n\n    Returns:\n        Response: The response returned by the next handler.\n    \"\"\"\n    log_dict = {'url': request.url.path, 'method': request.method}\n    LOG.info(log_dict, extra=log_dict)\n    return await call_next(request)\n\n\n@app.get('/')\ndef root(request: Request) -> Response:\n    \"\"\"Serve the root endpoint.\n\n    Returns the index.html template.\n\n    Args:\n        request (Request): The incoming HTTP request.\n\n    Returns:\n        TemplateResponse: The rendered index.html template.\n    \"\"\"\n    return templates.TemplateResponse(\n        'index.html', {'request': request, 'success': True}\n    )\n\n\n@app.exception_handler(RpcCallException)\nasync def rpc_call_exception_handler(\n    _request: Request,\n    exc: RpcCallException,\n) -> JSONResponse:\n    \"\"\"Handle RpcCallException.\n\n    Logs the exception and returns a JSON response with error details.\n\n    Args:\n        request (Request): The incoming HTTP request.\n        exc (RpcCallException): The exception that was raised.\n\n    Returns:\n        JSONResponse: The response containing error details.\n    \"\"\"\n    LOG.error('handle error: %s.' % str(exc))\n    return JSONResponse(\n        status_code=500,\n        content={\n            'timestamp': str(datetime.now()),\n            'error': type(exc).__name__,\n            'message': str(exc),\n        },\n    )\n\n\n@app.exception_handler(RpcCallTimeoutException)\nasync def rpc_call_timeout_exception_handler(\n    _request: Request,\n    exc: RpcCallTimeoutException,\n) -> JSONResponse:\n    \"\"\"Handle RpcCallTimeoutException.\n\n    Logs the exception and returns a JSON response with error details.\n\n    Args:\n        request (Request): The incoming HTTP request.\n        exc (RpcCallTimeoutException): The exception that was raised.\n\n    Returns:\n        JSONResponse: The response containing error details.\n    \"\"\"\n    LOG.error('handle error: %s.' % str(exc))\n    return JSONResponse(\n        status_code=500,\n        content={\n            'timestamp': str(datetime.now()),\n            'error': type(exc).__name__,\n            'message': str(exc),\n        },\n    )\n\n\n@app.exception_handler(RpcClientInitializedException)\nasync def rpc_init_exception_handler(\n    _request: Request,\n    exc: RpcClientInitializedException,\n) -> JSONResponse:\n    \"\"\"Handle RpcClientInitializedException.\n\n    Logs the exception and returns a JSON response with error details.\n\n    Args:\n        request (Request): The incoming HTTP request.\n        exc (RpcClientInitializedException): The exception that was raised.\n\n    Returns:\n        JSONResponse: The response containing error details.\n    \"\"\"\n    LOG.error('handle error: %s.' % str(exc))\n    return JSONResponse(\n        status_code=500,\n        content={\n            'timestamp': str(datetime.now()),\n            'error': type(exc).__name__,\n            'message': str(exc),\n        },\n    )\n\n\n@app.exception_handler(TypeError)\nasync def type_error_exception_handler(\n    _request: Request,\n    exc: TypeError,\n) -> JSONResponse:\n    \"\"\"Handle TypeError.\n\n    Logs the exception and returns a JSON response with error details.\n\n    Args:\n        request (Request): The incoming HTTP request.\n        exc (TypeError): The exception that was raised.\n\n    Returns:\n        JSONResponse: The response containing error details.\n    \"\"\"\n    LOG.error('Validate request error: %s.' % str(exc))\n    return JSONResponse(\n        status_code=409,\n        content={\n            'timestamp': str(datetime.now()),\n            'error': type(exc).__name__,\n            'message': str(exc),\n        },\n    )\n\n\n@app.exception_handler(ValueError)\nasync def value_error_exception_handler(\n    _request: Request,\n    exc: ValueError,\n) -> JSONResponse:\n    \"\"\"Handle ValueError.\n\n    Logs the exception and returns a JSON response with error details.\n\n    Args:\n        request (Request): The incoming HTTP request.\n        exc (ValueError): The exception that was raised.\n\n    Returns:\n        JSONResponse: The response containing error details.\n    \"\"\"\n    LOG.error('Validate request error: %s.' % str(exc))\n    return JSONResponse(\n        status_code=409,\n        content={\n            'timestamp': str(datetime.now()),\n            'error': type(exc).__name__,\n            'message': str(exc),\n        },\n    )\n\n\n@app.exception_handler(AssertionError)\nasync def assertion_error_exception_handler(\n    _request: Request,\n    exc: AssertionError,\n) -> JSONResponse:\n    \"\"\"Handle AssertionError.\n\n    Logs the exception and returns a JSON response with error details.\n\n    Args:\n        request (Request): The incoming HTTP request.\n        exc (AssertionError): The exception that was raised.\n\n    Returns:\n        JSONResponse: The response containing error details.\n    \"\"\"\n    LOG.error('Validate request error: %s.' % str(exc))\n    return JSONResponse(\n        status_code=409,\n        content={\n            'timestamp': str(datetime.now()),\n            'error': type(exc).__name__,\n            'message': str(exc),\n        },\n    )\n\n\nif __name__ == '__main__':\n    import uvicorn\n\n    from openvair import config\n\n    HOST = config.data['web_app'].get('host')\n    PORT = config.data['web_app'].get('port')\n\n    uvicorn.run(\n        'main:app',\n        host=HOST,\n        port=PORT,\n        workers=4,\n        backlog=65535,\n        limit_concurrency=1000,\n        limit_max_requests=10000,\n        ssl_keyfile='/opt/aero/openvair/key.pem',\n        ssl_certfile='/opt/aero/openvair/cert.pem',\n    )\n"}
{"type": "source_file", "path": "openvair/libs/messaging/service_interfaces/vm.py", "content": "\"\"\"Module for managing the Virtual Machine (VM) Service Layer.\n\nThis module defines the `VMServiceLayerProtocolInterface`, which serves as\nthe contract for handling VM-related operations in the service layer.\nAny class implementing this interface is responsible for interacting with the\ndomain layer and the event store to perform various tasks, such as retrieving\nVM information, creating, editing, deleting, starting, and stopping VMs.\n\nClasses:\n    VMServiceLayerProtocolInterface: Interface for handling VM service\n        layer operations.\n\"\"\"\n\nfrom typing import Dict, List, Protocol\n\n\nclass VMServiceLayerProtocolInterface(Protocol):\n    \"\"\"Interface for the VMServiceLayerManager.\n\n    This interface defines the methods that should be implemented by any class\n    that manages VM-related operations in the service layer.\n    \"\"\"\n\n    def get_vm(self, data: Dict) -> Dict:\n        \"\"\"Retrieve a VM by its ID.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        ...\n\n    def get_all_vms(self) -> List[Dict]:\n        \"\"\"Retrieve all VMs from the database.\n\n        Returns:\n            List[Dict]: List of serialized VM data.\n        \"\"\"\n        ...\n\n    def create_vm(self, data: Dict) -> Dict:\n        \"\"\"Create a new VM.\n\n        Args:\n            data (Dict): Information about the VM to be created.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        ...\n\n    def delete_vm(self, data: Dict) -> Dict:\n        \"\"\"Delete an existing VM.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        ...\n\n    def start_vm(self, data: Dict) -> Dict:\n        \"\"\"Start a VM.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        ...\n\n    def shut_off_vm(self, data: Dict) -> Dict:\n        \"\"\"Shut off a VM.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        ...\n\n    def edit_vm(self, edit_info: Dict) -> Dict:\n        \"\"\"Edit an existing VM.\n\n        Args:\n            edit_info (Dict): Information about the VM to be edited.\n\n        Returns:\n            Dict: Serialized VM data.\n        \"\"\"\n        ...\n\n    def vnc(self, data: Dict) -> Dict:\n        \"\"\"Retrieve VNC information for a VM.\n\n        Args:\n            data (Dict): Data containing the VM ID.\n\n        Returns:\n            Dict: VNC connection data.\n        \"\"\"\n        ...\n"}
{"type": "source_file", "path": "openvair/modules/backup/adapters/restic/restic_executor.py", "content": "\"\"\"Module to execute and manage restic commands.\n\nThis module provides a class for building and executing restic commands\nwhile handling errors. It includes logging, command formatting, and result\nvalidation functionalities.\n\nDependencies:\n    - openvair.libs.log: For logging command execution.\n    - openvair.libs.cli.models: For execution parameters and results.\n    - openvair.libs.cli.executor: For command execution logic.\n\nTypical usage example:\n    executor = ResticCommandExecutor('/path/to/repo', 'password')\n    result = executor.execute('backup /path/to/files')\n\"\"\"\n\nfrom typing import Optional\n\nfrom openvair.libs.log import get_logger\nfrom openvair.libs.cli.models import ExecuteParams, ExecutionResult\nfrom openvair.libs.cli.executor import execute\n\nLOG = get_logger(__name__)\n\n\nclass ResticCommandExecutor:\n    \"\"\"Executes restic commands and handles errors.\n\n    This class is responsible for constructing and executing restic commands\n    with specified parameters. It ensures commands are properly formatted and\n    securely executed, leveraging environment variables for authentication.\n\n    Attributes:\n        COMMAND_FORMAT (str): The base command format for restic execution.\n        restic_dir (str): Path to the restic repository.\n        restic_pass (str): Password for the restic repository.\n    \"\"\"\n    COMMAND_FORMAT = 'restic --json -q'\n\n    def __init__(self, restic_dir: str, restic_pass: str) -> None:\n        \"\"\"Initialize the executor with the repository path.\n\n        Args:\n            restic_dir (str): Path to the restic repository.\n            restic_pass (str): Password for the restic repository.\n        \"\"\"\n        self.restic_dir = str(restic_dir)\n        self.restic_pass = restic_pass\n\n    def _build_command(self, subcommand: str) -> str:\n        \"\"\"Build the full restic command with necessary options.\n\n        Args:\n            subcommand (str): The subcommand to execute with restic.\n\n        Returns:\n            str: The complete command string.\n        \"\"\"\n        return f'{self.COMMAND_FORMAT} -r {self.restic_dir} {subcommand}'\n\n    def execute(\n        self, subcommand: str, timeout: Optional[float] = None\n    ) -> ExecutionResult:\n        \"\"\"Executes a command and checks the result.\n\n        Args:\n            subcommand (str): Subcommand to execute with restic.\n            timeout (Optional[float]): Timeout for the command, in seconds.\n\n        Returns:\n            ExecutionResult: The result of the command execution.\n\n        Raises:\n            ResticAdapterException: If the command fails or encounters an error.\n        \"\"\"\n        command = self._build_command(subcommand)\n        LOG.debug(f'Executing command: {command}')\n        result: ExecutionResult = execute(\n            command,\n            params=ExecuteParams(  # noqa: S604\n                run_as_root=True,\n                timeout=timeout,\n                shell=True,\n                root_helper='sudo -E',\n                env={\n                    'RESTIC_PASSWORD': self.restic_pass,\n                    'RESTIC_REPOSITORY': self.restic_dir,\n                },\n            ),\n        )\n        return result\n"}
{"type": "source_file", "path": "openvair/modules/backup/adapters/repository.py", "content": "\"\"\"Repository module for managing PostgreSQL databases.\n\nThis module defines an abstract base class for database repositories and\nprovides a concrete implementation using SQLAlchemy to manage PostgreSQL\ndatabases. It includes methods for terminating connections, dropping databases,\ncreating databases\n\"\"\"\n\nfrom abc import ABCMeta, abstractmethod\nfrom typing import TYPE_CHECKING\n\nfrom sqlalchemy import text, create_engine\n\nfrom openvair.config import database, get_postgres_uri\n\nif TYPE_CHECKING:\n    from sqlalchemy.orm import Session\n\n\nclass AbstractRepository(metaclass=ABCMeta):\n    \"\"\"Abstract base class for database repositories.\n\n    Defines the interface for database operations such as terminating\n    connections, dropping databases, creating databases, and restoring data.\n    \"\"\"\n\n    @abstractmethod\n    def terminate_all_connections(self, db_name: str) -> None:\n        \"\"\"Terminate all active connections to a specified database.\n\n        Args:\n            db_name (str): Name of the database whose connections should be\n                terminated.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def drop_db(self, db_name: str) -> None:\n        \"\"\"Drop a specified database.\n\n        Args:\n            db_name (str): Name of the database to drop.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def create_db(self, db_name: str) -> None:\n        \"\"\"Create a new database.\n\n        Args:\n            db_name (str): Name of the database to create.\n        \"\"\"\n        ...\n\n\nclass SqlAlchemyRepository(AbstractRepository):\n    \"\"\"SQLAlchemy implementation of a database repository.\n\n    This class provides concrete implementations of database operations\n    using SQLAlchemy, tailored for PostgreSQL.\n\n    Attributes:\n        session (Session): SQLAlchemy session for database interactions.\n        engine (Engine): SQLAlchemy engine for executing database commands.\n    \"\"\"\n    def __init__(self, session: 'Session'):\n        \"\"\"Initialize the SQLAlchemy repository.\n\n        Args:\n            session (Session): SQLAlchemy session for database interactions.\n        \"\"\"\n        self.session: Session = session\n        self.engine = create_engine(\n            get_postgres_uri().replace(\n                database['db_name'], 'postgres'\n            )  # for connection to 'postgres' db, instead 'openvair'\n        )\n\n    def terminate_all_connections(self, db_name: str) -> None:\n        \"\"\"Terminate all active connections to a specified database.\n\n        Uses a SQL query to terminate all connections to the specified database,\n        except the current session.\n\n        Args:\n            db_name (str): Name of the database whose connections should be\n                terminated.\n        \"\"\"\n        with self.session.connection() as conn:\n            conn.execute(\n                text(\"\"\"\n                        SELECT pg_terminate_backend(pg_stat_activity.pid)\n                        FROM pg_stat_activity\n                        WHERE pg_stat_activity.datname = :db_name\n                        AND pid <> pg_backend_pid();\n                    \"\"\"),\n                {'db_name': db_name},\n            )\n\n    def drop_db(self, db_name: str) -> None:\n        \"\"\"Drop a specified database.\n\n        Executes a SQL command to drop the database. All connections to the\n        database are terminated before the drop operation.\n\n        Args:\n            db_name (str): Name of the database to drop.\n        \"\"\"\n        with self.engine.connect().execution_options(\n            isolation_level='AUTOCOMMIT'\n        ) as conn:  # connect withot transaction\n            # Stop all connections\n            conn.execute(\n                text(\"\"\"\n                    SELECT pg_terminate_backend(pg_stat_activity.pid)\n                    FROM pg_stat_activity\n                    WHERE pg_stat_activity.datname = :db_name\n                    AND pid <> pg_backend_pid();\n                \"\"\"),\n                {'db_name': db_name},\n            )\n\n            conn.execute(text(f'DROP DATABASE \"{db_name}\";'))\n\n    def create_db(self, db_name: str) -> None:\n        \"\"\"Create a new database.\n\n        Executes a SQL command to create a new database.\n\n        Args:\n            db_name (str): Name of the database to create.\n        \"\"\"\n        with self.engine.connect().execution_options(\n            isolation_level='AUTOCOMMIT'\n        ) as conn:  # Connect without transaction\n            conn.execute(text(f'CREATE DATABASE \"{db_name}\";'))\n\n"}
{"type": "source_file", "path": "openvair/libs/messaging/utils.py", "content": "\"\"\"Messaging utilities module.\n\nThis module provides utility functions for serializing and deserializing\nmessages between the RPC client and server.\n\nFunctions:\n    serialize: Converts a dictionary to a JSON string for transmission.\n    deserialize: Converts a JSON string to a dictionary after receiving a\n        message.\n\"\"\"\n\nimport json\nfrom typing import Dict\n\nfrom openvair.libs.messaging.exceptions import RpcDeserializeMessageException\n\n\ndef serialize(data: Dict) -> str:\n    \"\"\"Convert a dictionary to a JSON string.\n\n    This function serializes a dictionary into a JSON string for sending\n    as a message to the RPC server.\n\n    Args:\n        data (Dict): The dictionary to be serialized.\n\n    Returns:\n        str: The serialized JSON string.\n    \"\"\"\n    return str(json.dumps(data, skipkeys=True))\n\n\ndef deserialize(message: bytes) -> Dict:\n    \"\"\"Convert a JSON string to a dictionary.\n\n    This function deserializes a JSON string received from the RPC server\n    back into a dictionary.\n\n    Args:\n        message (bytes): The JSON string received from the RPC server.\n\n    Returns:\n        Dict: The deserialized dictionary.\n    \"\"\"\n    try:\n        deserialized_message: Dict = json.loads(message.decode('utf-8'))\n    except (json.JSONDecodeError, TypeError) as err:\n        raise RpcDeserializeMessageException(str(err))\n    else:\n        return deserialized_message\n"}
{"type": "source_file", "path": "openvair/libs/messaging/service_interfaces/storage.py", "content": "\"\"\"Module for managing the Storage Service Layer.\n\nThis module defines the `StorageServiceLayerManagerInterface`, which serves as\nthe contract for handling storage-related operations in the service layer.\nAny class implementing this interface is responsible for interacting with the\ndomain layer and the event store to perform various tasks, such as retrieving\nstorage information, creating and deleting.\n\nClasses:\n    StorageServiceLayerManagerInterface: Interface for handling storage service\n        layer operations.\n\"\"\"\n\nfrom typing import Dict, List, Protocol\n\n\nclass StorageServiceLayerProtocolInterface(Protocol):\n    \"\"\"Interface for the StorageServiceLayerManager.\n\n    This interface defines the methods that should be implemented by any class\n    that manages storage-related operations in the service layer.\n    \"\"\"\n\n    def get_storage(self, data: Dict) -> Dict:\n        \"\"\"Retrieve a storage by its ID.\n\n        Args:\n            data (Dict): Data containing the storage ID.\n\n        Returns:\n            Dict: Serialized storage data.\n        \"\"\"\n        ...\n\n    def get_all_storages(self) -> List[Dict]:\n        \"\"\"Retrieve all storages from the database.\n\n        Returns:\n            List[Dict]: List of serialized storage data.\n        \"\"\"\n        ...\n\n    def create_local_partition(self, data: Dict) -> Dict:\n        \"\"\"Create a local partition on the disk.\n\n        Args:\n            data (Dict): Data containing details for creating the partition.\n\n        Returns:\n            Dict: Serialized partition data.\n        \"\"\"\n        ...\n\n    def get_local_disk_partitions_info(self, data: Dict) -> Dict:\n        \"\"\"Get information about local disk partitions.\n\n        Args:\n            data (Dict): Data containing the disk path.\n\n        Returns:\n            Dict: Partition information.\n        \"\"\"\n        ...\n\n    def delete_local_partition(self, data: Dict) -> Dict:\n        \"\"\"Delete a local partition.\n\n        Args:\n            data (Dict): Data containing details for deleting the partition.\n\n        Returns:\n            Dict: Result of the delete operation.\n        \"\"\"\n        ...\n\n    def create_storage(self, data: Dict) -> Dict:\n        \"\"\"Create a new storage.\n\n        Args:\n            data (Dict): Data containing details for creating the storage.\n\n        Returns:\n            Dict: Serialized storage data.\n        \"\"\"\n        ...\n\n    def delete_storage(self, data: Dict) -> Dict:\n        \"\"\"Delete a storage.\n\n        Args:\n            data (Dict): Data containing the storage ID.\n\n        Returns:\n            Dict: Serialized storage data.\n        \"\"\"\n        ...\n\n    def get_local_disks(self, data: Dict) -> List:\n        \"\"\"Retrieve local disks information.\n\n        Args:\n            data (Dict): Data containing details for filtering disks.\n\n        Returns:\n            List: List of local disks.\n        \"\"\"\n        ...\n"}
{"type": "source_file", "path": "openvair/modules/backup/adapters/restic/__init__.py", "content": ""}
{"type": "source_file", "path": "openvair/modules/backup/adapters/__init__.py", "content": ""}
