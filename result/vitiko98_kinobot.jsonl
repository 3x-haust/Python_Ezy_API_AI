{"repo_info": {"repo_name": "kinobot", "repo_owner": "vitiko98", "repo_url": "https://github.com/vitiko98/kinobot"}}
{"type": "source_file", "path": "kinobot/constants.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport os\n\nfrom discord import Embed\n\nfrom .config import config\nfrom .config import PATH\n\n\ndef _create_dirs(dir_tuple):\n    for to_create in dir_tuple:\n        if os.path.isdir(to_create):\n            continue\n\n        os.makedirs(to_create, exist_ok=True)\n        print(f\"Directory created: {to_create}\")\n\n\nTEST = config.test\n\n_image_extensions_registry = {\"png\", \"jpg\"}\n\nIMAGE_EXTENSION = config.image_extension\nif IMAGE_EXTENSION not in _image_extensions_registry:\n    raise ValueError(f\"Invalid image extension: {IMAGE_EXTENSION}\")\n\n\nAPP_DIR = config.app_dir\n\n\nKINOBASE = config.db # fixme\nCACHE_DIR = os.path.join(APP_DIR, \"cache\")\nDATA_DIR = APP_DIR\nLOGS_DIR = os.path.join(APP_DIR, \"logs\")\n\n\n_create_dirs((CACHE_DIR, DATA_DIR, LOGS_DIR))\n\nYAML_CONFIG = PATH\n\n\nTWITTER = \"https://twitter.com/kinobot2001\"\nPATREON = \"https://patreon.com/kinobot\"\nWEBSITE = \"https://kino.caretas.club\"\nGITHUB_REPO = \"https://github.com/vitiko98/kinobot\"\nDISCORD_INVITE = \"https://discord.gg/ZUfxf22Wqn\"\nTMDB_IMG_BASE = \"https://image.tmdb.org/t/p/original\"\nTMDB_BASE = \"https://www.themoviedb.org/movie\"\nFANART_BASE = \"http://webservice.fanart.tv/v3\"\nYOUTUBE_API_BASE = \"https://www.googleapis.com/youtube/v3/videos\"\nPATREON_API_BASE = \"https://www.patreon.com/api/oauth2/v2\"\nDISCORD_BOT_INVITE = \"https://discord.com/api/oauth2/authorize?client_id=849454773047656459&permissions=2148006976&scope=bot\"\nPATREON_CAMPAIGN_ID = \"6141662\"\nDISCORD_PERMISSIONS_INTEGER = \"2148006976\"\nVERIFIER_ROLE_ID = \"806562776847220798\"\n\n\nSTORIES_DIR = config.stories_dir\n\nSTARS_DIR = os.path.join(STORIES_DIR, \"stars\")\n\nFRAMES_DIR = os.path.join(DATA_DIR, \"frames\")\nCACHED_FRAMES_DIR = os.path.join(CACHE_DIR, \"frames\")\n\nLOGOS_DIR = os.path.join(DATA_DIR, \"logos\")\n\nSTORY_FONT = os.path.join(config.fonts_dir, \"GothamMedium_1.ttf\")\nSTARS_PATH = os.path.join(STORIES_DIR, \"stars\")\n\nBACKDROPS_DIR = os.path.join(DATA_DIR, \"backdrops\")\n\nBUGS_DIR = os.path.join(LOGS_DIR, \"bugs\")\n\nDIRS = (FRAMES_DIR, CACHED_FRAMES_DIR, BACKDROPS_DIR, LOGOS_DIR, BUGS_DIR)\n\n\n_create_dirs(DIRS)\n\n\nCATEGORY_IDS = {\n    \"peak cringe\": 1,\n    \"certified cringe\": 2,\n    \"borderline kino\": 3,\n    \"high kino\": 4,\n    \"pleb-oriented kinema\": 5,\n    \"cringema\": 6,\n    \"peak kino\": 7,\n    \"certified kino\": 8,\n    \"hi mark kinema\": 9,\n    \"citizen kino\": 10,\n}\n\nLANGUAGE_SUFFIXES = {\n    \"en\": \"en\",\n    \"es\": \"es-MX\",\n    \"pt\": \"pt-BR\",\n}\n\nPATREON_TIER_IDS = {\"6672690\": \"auteur\", \"6672568\": \"director\"}\n\nFB_INFO = (\n    f\"ðŸ’— Support Kinobot: {PATREON}\\nðŸŽ¬ Explore the collection (~1000 movies): {WEBSITE}\"\n)\n\n_PERMISSIONS = (\n    \"You reached your free daily limit (7 requests)! Please support the bot becoming a \"\n    f\"[patron]({PATREON}) and get access to **unlimited requests**. \"\n    \"Here's the list of available roles and perks:\"\n)\n\nPERMISSIONS_EMBED = Embed(\n    title=\"Supporters-only feature\",\n    url=PATREON,\n    description=_PERMISSIONS,\n)\nPERMISSIONS_EMBED.add_field(\n    name=\"Director\",\n    value=\"3$/mo - Unlimited classic requests, parallels, and palettes\",\n    inline=True,\n)\nPERMISSIONS_EMBED.add_field(\n    name=\"Auteur\",\n    value=\"6$/mo - Same as director, but with more love and access to future features\",\n    inline=True,\n)\nPERMISSIONS_EMBED.add_field(\n    name='\"I\\'m already subscribed!\"',\n    value=\"If you already paid and this keeps showing, don't forget to link your Discord\"\n    \" account to your Patreon account.\",\n    inline=False,\n)\nPERMISSIONS_EMBED.set_footer(\n    text=\"Note: Subscriptions can take up to 10 minuted to get activated.\"\n)\nPERMISSIONS_EMBED.add_field(\n    name=\"Links\",\n    value=f\"[Kinobot's Patreon]({PATREON}). \"\n    f\"If you still have problems, ask for support: [Official Discord server]({DISCORD_INVITE})\",\n    inline=False,\n)\n\nAPI_HELP_EMBED = Embed(title=\"Human readable documentation links\")\nAPI_HELP_EMBED.add_field(\n    name=\"Documentation main page\",\n    value=f\"[Link]({WEBSITE}/docs)\",\n    inline=False,\n)\nAPI_HELP_EMBED.add_field(\n    name=\"Bracket flags (e.g. [quote --plus 700])\",\n    value=f\"[Link]({WEBSITE}/docs/brackets.html)\",\n    inline=False,\n)\nAPI_HELP_EMBED.add_field(\n    name=\"Full request flags (e.g. !req Movie [quote] --font helvetica)\",\n    value=f\"[Link]({WEBSITE}/docs/postprocessing.html)\",\n    inline=False,\n)\n\n# Just for fun\nWEBHOOK_PROFILES = (\n    {\n        \"username\": \"Ye\",\n        \"avatar_url\": \"https://i.ytimg.com/vi/fEHcsNmu6Yc/hqdefault.jpg\",\n    },\n    {\n        \"username\": \"Among Us\",\n        \"avatar_url\": \"https://pioneeroptimist.com/wp-content/uploads/2021/03/among-us-6008615_1920-838x900.png\",\n    },\n    {\n        \"username\": \"Future\",\n        \"avatar_url\": \"https://lastfm.freetls.fastly.net/i/u/300x300/443f94378a1e4642c62c2b039df1ecad.png\",\n    },\n    {\n        \"username\": \"Young Thug\",\n        \"avatar_url\": \"https://lastfm.freetls.fastly.net/i/u/300x300/0bddfa49e1d95f620267fac8f4663a60.png\",\n    },\n    {\"username\": \"Tyler\", \"avatar_url\": \"https://i.imgur.com/b9c8AXm.png\"},\n    {\n        \"username\": \"Xi Jinping\",\n        \"avatar_url\": \"https://asiasociety.org/sites/default/files/styles/1200w/public/1/150827_xi_0.jpg\",\n    },\n    {\n        \"username\": \"Lenin\",\n        \"avatar_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Vladimir_Lenin.jpg/1200px-Vladimir_Lenin.jpg\",\n    },\n)\n\nprint(f\"Test mode: {TEST}; Image extension: {IMAGE_EXTENSION}; DB path: {config.db}\")\n"}
{"type": "source_file", "path": "kinobot/cache.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport datetime\nimport os\n\nfrom dogpile.cache import make_region\n\nfrom .constants import CACHE_DIR\n\nMEDIA_LIST_TIME = datetime.timedelta(hours=1).total_seconds()\nPATREON_MEMBERS_TIME = datetime.timedelta(minutes=10).total_seconds()\nTOP_TIME = MEDIA_LIST_TIME  # Temporary\n\nos.makedirs(CACHE_DIR, exist_ok=True)\n\nregion = make_region().configure(\n    \"dogpile.cache.dbm\",\n    arguments={\"filename\": os.path.join(CACHE_DIR, \"cache.db\")},\n)\n"}
{"type": "source_file", "path": "kinobot/bracket.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport copy\nimport datetime\nimport logging\nimport os\nimport re\nfrom typing import Dict, Generator, List, Optional, Sequence, Tuple, Union\n\nimport numpy as np\nfrom pydantic import BaseModel, ConfigDict\nfrom pydantic import ValidationError\nfrom pydantic import validator\nfrom srt import Subtitle\n\nfrom .config import config\n\nFONTS_DIR = config.fonts_dir\n\nimport kinobot.exceptions as exceptions\n\nfrom .utils import get_args_and_clean\nfrom .utils import normalize_request_str\n\nlogger = logging.getLogger(__name__)\n\n_DEFAULT_FONT_SIZE = 22\n\n# This dict is hardcoded here for legacy purposes\n\nFONTS_DICT = {\n    \"nfsans\": os.path.join(FONTS_DIR, \"NS_Medium.otf\"),\n    \"helvetica\": os.path.join(FONTS_DIR, \"helvetica.ttf\"),\n    \"helvetica-italic\": os.path.join(FONTS_DIR, \"helvetica-italic.ttf\"),\n    \"clearsans\": os.path.join(FONTS_DIR, \"ClearSans-Medium.ttf\"),\n    \"clearsans-regular\": os.path.join(FONTS_DIR, \"clearsans-regular.ttf\"),\n    \"clearsans-italic\": os.path.join(FONTS_DIR, \"clearsans-italic.ttf\"),\n    \"opensans\": os.path.join(FONTS_DIR, \"opensans.ttf\"),\n    \"comicsans\": os.path.join(FONTS_DIR, \"comic_sans_ms.ttf\"),\n    \"impact\": os.path.join(FONTS_DIR, \"impact.ttf\"),\n    \"segoe\": os.path.join(FONTS_DIR, \"Segoe_UI.ttf\"),\n    \"segoe-italic\": os.path.join(FONTS_DIR, \"segoe-italic.ttf\"),\n    \"segoesm\": os.path.join(FONTS_DIR, \"segoe_semi_bold.ttf\"),\n    \"papyrus\": os.path.join(FONTS_DIR, \"papyrus.ttf\"),\n    \"bangers\": os.path.join(FONTS_DIR, \"Bangers-Regular.ttf\"),\n    \"timesnewroman\": os.path.join(FONTS_DIR, \"TimesNewRoman.ttf\"),\n    \"oldenglish\": os.path.join(FONTS_DIR, \"OldEnglish.ttf\"),\n    \"segoe-bold-italic\": os.path.join(FONTS_DIR, \"segoe-bold-italic.ttf\"),\n    \"tahoma\": os.path.join(FONTS_DIR, \"tahoma.ttf\"),\n    \"whisper\": os.path.join(FONTS_DIR, \"whisper.otf\"),\n}\n\n_FONT_TO_KEY_RE = re.compile(r\"[\\s_-]|\\.[ot]tf\")\n\n\ndef _generate_fonts(font_dir=None):\n    old_values = list(FONTS_DICT.values())\n\n    for file_ in os.listdir(font_dir or FONTS_DIR):\n        if not file_.endswith((\".otf\", \"ttf\")):\n            continue\n\n        key = _FONT_TO_KEY_RE.sub(\"\", file_).lower()\n        font_path = os.path.join(FONTS_DIR, file_)\n\n        if font_path in old_values:\n            continue\n\n        FONTS_DICT[key] = font_path\n\n\n_generate_fonts()\n\n\nclass _ProcBase(BaseModel):\n    font: str = \"clearsans\"  # \"segoesm\"\n    font_size: float = _DEFAULT_FONT_SIZE\n    font_color: str = \"white\"\n    text_spacing: float = 1.0\n    text_align: str = \"center\"\n    y_offset: int = 75\n    stroke_width: float = 0.5\n    stroke_color: str = \"black\"\n    palette_color_count: int = 10\n    palette_dither: str = \"floyd_steinberg\"\n    palette_colorspace: Optional[str] = None\n    palette_height: int = 33\n    palette_position: str = \"bottom\"\n    palette: bool = False\n    raw: bool = False\n    no_trim: bool = False\n    ultraraw: bool = False\n    merge: bool = False\n    keep: bool = False\n    merge_join: Optional[str] = None\n    flip: Optional[str] = None\n    # aspect_quotient: Optional[float] = None # Unsupported\n    mirror: bool = False\n    mirror_after: bool = False\n    contrast: int = 20\n    color: int = 0\n    brightness: int = 0\n    sharpness: int = 0\n    border: Union[str, tuple, None] = None\n    border_color: str = \"white\"\n    text_background: Optional[str] = None\n    text_shadow: int = 10\n    text_shadow_color: str = \"black\"\n    text_shadow_offset: Union[str, tuple, None] = (5, 5)\n    text_xy: Union[str, tuple, None] = None\n    text_shadow_blur: str = \"boxblur\"\n    text_shadow_stroke: int = 2\n    text_shadow_font_plus: int = 0\n    zoom_factor: Optional[float] = None\n    wrap_width: Optional[int] = None\n    tint: Optional[str] = None\n    tint_alpha: float = 0.5\n    debug: bool = False\n    debug_color: Optional[str] = None\n    no_scale: bool = False\n    og_dict: dict = {}\n    context: dict = {}\n    profiles: List = []\n    _og_instance_dict: Dict = {}\n\n    model_config = ConfigDict(frozen=False, arbitrary_types_allowed=True)\n\n    def __init__(self, **data) -> None:\n        super().__init__(**data)\n        if \"og_dict\" not in data:\n            self.og_dict = data\n\n        self._og_instance_dict = self.dict().copy()\n\n    def _analize_profiles(self):\n        for profile in self.profiles:\n            profile.visit(self)\n\n        self._overwrite_from_og()\n\n    def _overwrite_from_og(self):\n        for key in self.og_dict.keys():\n            og_parsed_value = self._og_instance_dict.get(key)\n            if og_parsed_value is None:\n                continue\n\n            logger.debug(\"Overwriting value from og dict: %s: %s\", key, og_parsed_value)\n            setattr(self, key, og_parsed_value)\n\n    def copy(self, data):\n        new_data = self.dict().copy()\n        new_data.update(data)\n\n        return _ProcBase.model_validate(new_data)\n\n    @validator(\"stroke_width\", \"text_spacing\", \"text_shadow\")\n    @classmethod\n    def _check_stroke_spacing(cls, val):\n        if val > 30:\n            raise exceptions.InvalidRequest(f\"Dangerous value found: {val}\")\n\n        return val\n\n    @validator(\"text_shadow_offset\", \"text_xy\")\n    def _check_shadow_offset(cls, val):\n        if val is None:\n            return None\n\n        if isinstance(val, tuple):\n            return val\n\n        try:\n            x_border, y_border = [int(item) for item in val.split(\",\")]\n        except ValueError:\n            raise exceptions.InvalidRequest(f\"`{val}`\") from None\n\n        if any(item > 100 for item in (x_border, y_border)):\n            pass\n            # raise exceptions.InvalidRequest(\"Expected `<100` value\")\n\n        return x_border, y_border\n\n    @validator(\"y_offset\")\n    @classmethod\n    def _check_y_offset(cls, val):\n        if val > 500:\n            raise exceptions.InvalidRequest(f\"Dangerous value found: {val}\")\n\n        return val\n\n    @validator(\n        \"contrast\", \"brightness\", \"color\", \"sharpness\", \"font_size\", \"palette_height\"\n    )\n    @classmethod\n    def _check_100(cls, val):\n        if abs(val) > 100:\n            raise exceptions.InvalidRequest(\"Values greater than 100 are not allowed\")\n\n        return val\n\n    @validator(\"palette_color_count\")\n    @classmethod\n    def _check_palette_color_count(cls, val):\n        if val < 2 or val > 20:\n            raise exceptions.InvalidRequest(\"Choose between 2 and 20\")\n\n        return val\n\n    @validator(\"zoom_factor\")\n    @classmethod\n    def _check_zoom_factor(cls, val):\n        if val is None:\n            return val\n\n        if val < 1 or val > 4:\n            raise exceptions.InvalidRequest(\"Choose between 1 and 4\")\n\n        return val\n\n    @validator(\"font\")\n    @classmethod\n    def _check_font(cls, val):\n        if val not in FONTS_DICT:\n            return \"clearsans\"\n\n        return val\n\n    @validator(\"border\")\n    @classmethod\n    def _check_border(cls, val):\n        if val is None:\n            return None\n\n        if isinstance(val, tuple):\n            return val\n\n        try:\n            x_border, y_border = [int(item) for item in val.split(\",\")]\n        except ValueError:\n            raise exceptions.InvalidRequest(f\"`{val}`\") from None\n\n        if any(item > 20 for item in (x_border, y_border)):\n            raise exceptions.InvalidRequest(\"Expected `<20` value\")\n\n        return x_border, y_border\n\n\nclass BracketPostProc(_ProcBase):\n    \"Class for post-processing options for single brackets.\"\n\n    remove_first: bool = False\n    remove_second: bool = False\n    plus: int = 0\n    minus: int = 0\n    text_wrap: int = 0\n    x_crop_offset: int = 0\n    y_crop_offset: int = 0\n    no_merge: bool = False\n    wild_merge: bool = False\n    empty: bool = False\n    merge_chars: int = 60\n    keep: bool = False\n    no_split_dialogue: bool = False\n    text_lines: Optional[int] = None\n    append_punctuation: Optional[str] = None\n    custom_crop: Union[str, list, None] = None\n    split: Optional[str] = None\n    total_split: Optional[str] = None\n    image_url: Optional[str] = None\n    image_size: Union[str, float, None] = None\n    image_position: Union[str, list, None] = None\n    image_rotate: Union[str, int, None] = None\n\n    @validator(\"x_crop_offset\", \"y_crop_offset\")\n    @classmethod\n    def _check_crop_crds(cls, val):\n        if abs(val) > 100:\n            raise exceptions.InvalidRequest(f\"Value greater than 100 found: {val}\")\n\n        return val\n\n    @validator(\"plus\", \"minus\")\n    def _check_milli(cls, val):\n        if abs(val) > 10000:\n            raise exceptions.InvalidRequest(f\"10000ms limit exceeded: {val}\")\n\n        return val\n\n    @validator(\"text_lines\")\n    def _check_text_lines(cls, val):\n        if val is None:\n            return val\n\n        val = abs(int(val))\n        if val > 30:\n            raise exceptions.InvalidRequest(\"Text lines amount not allowed\")\n\n        return val\n\n    @validator(\"append_punctuation\", \"merge_join\")\n    def _check_punct(cls, val):\n        if val is None:\n            return val\n\n        if val in (\".\", \"!\", \"?\", \"...\"):\n            return val\n\n        raise exceptions.InvalidRequest(\"Invalid punctuation mark: %s\", val)\n\n    @validator(\"custom_crop\")\n    @classmethod\n    def _check_custom_crop(cls, val):\n        if val is None:\n            return val\n\n        box = _get_box(val)\n\n        if box[0] >= box[2] or box[1] >= box[3]:\n            raise exceptions.InvalidRequest(\n                \"The next coordinate (e.g. left -> right) can't have an \"\n                f\"equal or lesser value: {val}\"\n            )\n\n        return box\n\n    @validator(\"image_position\")\n    @classmethod\n    def _check_image_position(cls, val):\n        if val is None:\n            return val\n\n        return _get_box(val, 2)\n\n    @validator(\"image_rotate\")\n    @classmethod\n    def _check_image_rotate(cls, val):\n        if val is None:\n            return val\n\n        try:\n            value = float(val.strip())\n        except ValueError:\n            return None\n\n        if abs(value) > 360:\n            raise exceptions.InvalidRequest(value)\n\n        return value\n\n    @validator(\"image_size\")\n    @classmethod\n    def _check_image_size(cls, val):\n        if val is None:\n            return val\n\n        if isinstance(val, float):\n            value = val\n        else:\n            try:\n                value = float(val.strip())\n            except ValueError as error:\n                raise exceptions.InvalidRequest(error) from None\n\n        if value > 3:\n            raise exceptions.InvalidRequest(f\"Expected =<3, found {value}\")\n\n        return value\n\n\nclass Bracket:\n    \"Class for raw brackets parsing.\"\n\n    __args_tuple__ = (\n        \"--remove-first\",\n        \"--remove-second\",\n        \"--text-wrap\",\n        \"--plus\",\n        \"--minus\",\n        \"--x-crop-offset\",\n        \"--y-crop-offset\",\n        \"--custom-crop\",\n        \"--no-merge\",\n        \"--wild-merge\",\n        \"--merge-chars\",\n        \"--empty\",\n        \"--image-url\",\n        \"--image-size\",\n        \"--image-position\",\n        \"--image-rotate\",\n        \"--split\",\n        \"--total-split\",\n        \"--raw\",\n        \"--ultraraw\",\n        \"--font\",\n        \"--font-color\",\n        \"--font-size\",\n        \"--text-spacing\",\n        \"--text-align\",\n        \"--y-offset\",\n        \"--stroke-width\",\n        \"--stroke-color\",\n        \"--append-punctuation\",\n        \"--text-lines\",\n        \"--wrap-width\",\n        \"--palette\",\n        \"--palette-color-count\",\n        \"--palette-colorspace\",\n        \"--palette-dither\",\n        \"--palette-height\",\n        # \"--palette-position\",\n        \"--mirror\",\n        \"--mirror-after\",\n        \"--flip\",\n        \"--color\",\n        \"--contrast\",\n        \"--brightness\",\n        \"--sharpness\",\n        \"--border\",\n        \"--border-color\",\n        \"--merge\",\n        \"--merge-join\",\n        \"--no-trim\",\n        \"--text-background\",\n        \"--text-shadow\",\n        \"--text-shadow-color\",\n        \"--text-shadow-offset\",\n        \"--text-shadow-stroke\",\n        \"--text-shadow-blur\",\n        \"--text-shadow-font-plus\",\n        \"--zoom-factor\",\n        \"--debug\",\n        \"--debug-color\",\n        \"--text-xy\",\n        \"--no-scale\",\n        \"--keep\",\n        \"--tint\",\n        \"--tint-alpha\",\n    )\n\n    def __init__(\n        self, content: str, index=None, postproc: Optional[BracketPostProc] = None\n    ):\n        self._content = content\n        self._timestamp = True\n        self._index = index or 0\n        self._subtitle_index = 0\n\n        self.postproc = postproc or BracketPostProc()\n        self.content: Union[str, int, tuple, Subtitle, None, List[int]] = None\n        self.gif = False\n        self.milli = 0\n\n        self._load()\n\n    @property\n    def subtitle_quote(self):\n        if isinstance(self.content, Subtitle):\n            return self.content.content\n\n        return None\n\n    @property\n    def subtitle_timestamp(self):\n        if isinstance(self.content, Subtitle):\n            return self.content.start.total_seconds() * 1000\n\n        return None\n\n    @property\n    def subtitle_timestamp_end(self):\n        if isinstance(self.content, Subtitle):\n            return self.content.end.total_seconds() * 1000\n\n        return None\n\n    @property\n    def index(self):\n        return self._index\n\n    @property\n    def subtitle_index(self):\n        return self._subtitle_index\n\n    def is_timestamp(self):\n        return isinstance(self.content, int)\n\n    def copy(self):\n        return copy.copy(self)\n\n    def process_subtitle(self, subtitle: Subtitle) -> Sequence[Subtitle]:\n        \"\"\"Try to split a subtitle taking into account the post-processing\n        options.\n\n        :param subtitle:\n        :type subtitle: Subtitle\n        :rtype: Sequence[Subtitle]\n        \"\"\"\n        split = self.postproc.split or self.postproc.total_split\n        self._subtitle_index = subtitle.index\n\n        if split is None:\n            logger.debug(\"Running regular process\")\n            return self._regular_process(subtitle)\n        else:\n            logger.debug(\"Running split process\")\n            return self._split_process(subtitle, split)\n\n    def _split_process(self, subtitle: Subtitle, split=None):\n        subtitle.start = datetime.timedelta(\n            seconds=subtitle.start.seconds,\n            microseconds=subtitle.start.microseconds + (self.milli * 1000),\n        )\n\n        total_split = self.postproc.total_split is not None\n\n        quotes = subtitle.content.split(split)\n        split = split.strip()\n        new_quotes = []\n        for n, quote in enumerate(quotes):\n            if len(quotes) == n + 1:\n                new_quotes.append(quote)\n            else:\n                new_quotes.append(quote.strip() + (split if not total_split else \"\"))\n\n        new_quotes = [q.strip() for q in new_quotes if q.strip()]\n        logger.debug(\"Split: %s\", new_quotes)\n\n        return _split_subtitles(subtitle, new_quotes)\n\n    def _regular_process(self, subtitle: Subtitle) -> Sequence[Subtitle]:\n        subtitle.start = datetime.timedelta(\n            seconds=subtitle.start.seconds,\n            microseconds=subtitle.start.microseconds + (self.milli * 1000),\n        )\n        subtitle.content = normalize_request_str(subtitle.content, False)\n\n        if self.postproc.no_split_dialogue:\n            return [subtitle]\n\n        split_sub = _split_dialogue(subtitle)\n\n        if len(split_sub) == 2:\n            if self.postproc.remove_first:\n                logger.debug(\"Removing first quote: %s\", split_sub)\n                return [split_sub[1]]\n\n            if self.postproc.remove_second:\n                logger.debug(\"Removing second quote %s\", split_sub)\n                return [split_sub[0]]\n\n        return split_sub\n\n    def update_from_swap(self, old):  # content is Subtitle\n        # This class is the new (content is either Subtitle or int)\n        if not isinstance(old.content, Subtitle):\n            raise exceptions.InvalidRequest(\"Source isn't a subtitle\")\n\n        og_ = copy.copy(self)\n        self.postproc = old.postproc\n\n        mss = self.milli * 1000\n        if isinstance(self.content, int):\n            self.content = old.content\n            self.content.start = datetime.timedelta(\n                seconds=og_.content,  # type: ignore\n                microseconds=mss,\n            )\n        else:\n            self.content = old.content\n            micro = og_.content.start.microseconds + mss  # type: ignore\n            self.content.start = datetime.timedelta(\n                seconds=og_.content.start.seconds,  # type: ignore\n                microseconds=micro,\n            )\n\n    def get_indexes(self):\n        return _parse_index(self.content)  # type: ignore\n\n    def is_index(self) -> bool:\n        \"\"\"Check if the bracket contains an index.\n\n        :rtype: bool\n        \"\"\"\n        if not isinstance(self.content, str):\n            return False\n\n        logger.debug(\"Checking for indexed content: %s\", self.content)\n        split_content = self.content.split(\"-\")\n\n        logger.debug(\"Looking for possible index-only request: %s\", split_content)\n        return not any(not index.strip().isdigit() for index in split_content)\n\n    def _load(self):\n        logger.debug(\"Loading bracket: %s\", self._content)\n\n        self._content, args = get_args_and_clean(self._content, self.__args_tuple__)\n        logger.debug(\"OG Content: %s\", self._content)\n        try:\n            self.postproc = BracketPostProc(**args)\n        except ValidationError as error:\n            raise exceptions.InvalidRequest(error) from None\n\n        self._guess_type()\n\n        if self._possible_gif_timestamp():\n            self.gif = True\n            self._get_gif_tuple()\n\n        elif self._timestamp:\n            self._get_timestamp()\n\n        else:  # Quote or index\n            self.content = self._content\n\n        self.milli -= self.postproc.minus\n        self.milli += self.postproc.plus\n\n    def _guess_type(self):\n        split_timestamp = self._content.split(\":\")\n\n        if any(not digit.strip().isdigit() for digit in split_timestamp):\n            self._timestamp = False\n\n        # Single index requests\n        if len(split_timestamp) == 1 and split_timestamp[0].strip().isdigit():\n            self._timestamp = False\n\n    def _possible_gif_timestamp(self) -> bool:\n        split_content = self._content.split(\"-\")\n        logger.debug(\"Split: %s\", split_content)\n\n        if len(split_content) != 2:  # ! [xx:xx - xx:xx] (almost always returned)\n            return False\n\n        if len(split_content[0].strip()) != len(split_content[1].strip()):\n            return False\n\n        return split_content[1].strip()[0].isdigit() and \":\" in split_content[0]\n\n    def _get_timestamp(self):\n        logger.debug(\"Loading timestamp info: %s\", self._content)\n        self.content = _get_seconds(self._content.split(\":\"))\n        possible_milli = self._content.split(\".\")[-1].strip()  # \"23:32.[200]\"\n\n        if possible_milli.isdigit():\n            self.milli = int(possible_milli)\n\n    def _get_gif_tuple(self):\n        logger.debug(\"Loading GIF tuple: %s\", self._content)\n\n        tuple_ = [_get_seconds(_sec.split(\":\")) for _sec in self._content.split(\"-\")]\n\n        if len(tuple_) == 2:\n            start, end = tuple_\n            if (end - start) > 7:\n                raise exceptions.InvalidRequest(\n                    \"Too long GIF request (expected less than 8 seconds)\"\n                )\n            if start > end:\n                raise exceptions.InvalidRequest(\"Negative range found\")\n\n            self.content = tuple(tuple_)\n\n        else:\n            raise exceptions.InvalidRequest(\n                f\"Invalid GIF range request: {self._content}\"\n            )\n\n    def dump(self):\n        flags = self.postproc.dict(exclude_unset=True)\n        if \"og_dict\" in flags:\n            flags.pop(\"og_dict\")\n\n        items = []\n        for key, val in flags.items():\n            kb_compliant = \"--\" + key.replace(\"_\", \"-\")\n            if isinstance(val, bool) and val is True:\n                flag = kb_compliant\n\n            elif isinstance(val, tuple):\n                flag = kb_compliant + \" \" + \",\".join(str(i) for i in val)\n\n            elif isinstance(val, (str, float, int)):\n                flag = f\"{kb_compliant} {val}\"\n\n            else:\n                logger.debug(\"val type is not supported: %s\", val)\n                continue\n\n            logger.debug(\"Appending flag: %s\", flag)\n            items.append(flag)\n\n        content = f'{self._content.strip()} {\" \".join(items)}'.strip()\n        return f\"[{content}]\"\n\n    def __repr__(self):\n        return f\"<Bracket {self.content} [{self.index}]>\"\n\n\ndef _get_seconds(split_timestamp: Sequence[str]) -> int:\n    \"\"\"\n    :param split_timestamp:\n    :type split_timestamp: Sequence[str]\n    :raises exceptions.InvalidRequest\n    \"\"\"\n    if len(split_timestamp) == 2:  # mm:ss\n        return int(split_timestamp[0]) * 60 + int(split_timestamp[1])\n\n    if len(split_timestamp) == 3:  # hh:mm:ss\n        return (\n            (int(split_timestamp[0]) * 3600)\n            + (int(split_timestamp[1]) * 60)\n            + int(split_timestamp[2])\n        )\n\n    raise exceptions.InvalidRequest(\n        f\"Invalid format: {split_timestamp}. Use mm:ss or hh:mm:ss\"\n    )\n\n\ndef _guess_timestamps(\n    og_quote: Subtitle, quotes: Sequence[str]\n) -> Tuple[Subtitle, Subtitle]:\n    \"\"\"Guess new timestamps in order to split dialogue.\n\n    :param og_quote:\n    :type og_quote: Subtitle\n    :param quotes:\n    :type quotes: Sequence[str]\n    \"\"\"\n    start_sec = og_quote.start.seconds\n    end_sec = og_quote.end.seconds\n    start_micro = og_quote.start.microseconds\n    end_micro = og_quote.end.microseconds\n\n    extra_secs = (start_micro * 0.000001) + (end_micro * 0.000001)\n    total_secs = end_sec - start_sec + extra_secs\n\n    new_time = list(_gen_quote_time(quotes, total_secs))\n\n    first_new = Subtitle(\n        index=og_quote.index,\n        start=datetime.timedelta(seconds=start_sec + 1, microseconds=0),\n        end=og_quote.end,\n        content=quotes[0],\n    )\n\n    index = first_new.index + 0\n    content = quotes[1]\n    start = datetime.timedelta(\n        seconds=new_time[0][0] + start_sec, microseconds=new_time[1][1]\n    )\n    end = datetime.timedelta(seconds=new_time[0][0] + start_sec + 1, microseconds=0)\n\n    second_new = Subtitle(index, start, end, content)\n\n    return first_new, second_new\n\n\ndef _split_subtitles(og_quote: Subtitle, quotes: Sequence[str]) -> List[Subtitle]:\n    \"\"\"Guess new timestamps in order to split dialogue.\n\n    :param og_quote:\n    :type og_quote: Subtitle\n    :param quotes:\n    :type quotes: Sequence[str]\n    \"\"\"\n    if len(quotes) == 1:\n        return [og_quote]\n\n    total_micros = (og_quote.end - og_quote.start) / datetime.timedelta(microseconds=1)\n    new_subs = []\n    last_new = None\n\n    for new_end, q in _gen_quote_times(quotes, total_micros):\n        if last_new is None:\n            new_start = og_quote.start\n        else:\n            new_start = last_new.end\n\n        new_ = Subtitle(\n            index=og_quote.index,\n            start=new_start,\n            end=new_start + datetime.timedelta(microseconds=new_end),\n            content=q,\n        )\n        new_subs.append(new_)\n        last_new = new_\n\n    return new_subs\n\n\ndef _gen_quote_times(\n    quotes: Sequence[str], total_micro: int\n) -> Generator[Tuple[int, str], None, None]:\n    \"\"\"Generate microseconds from quote string lengths.\n\n    :param quotes:\n    :type quotes: List[str]\n    :param total_secs:\n    :type total_secs: int\n    :rtype: Generator[Tuple[int, int], None, None]\n    \"\"\"\n    for quote in quotes:\n        percent = ((len(quote) * 100) / len(\"\".join(quotes))) * 0.01\n\n        diff = total_micro * percent\n        real = np.array([diff])\n\n        inte, _ = int(np.floor(real)), (real % 1).item()\n\n        yield inte, quote\n\n\ndef _gen_quote_time(\n    quotes: Sequence[str], total_secs: int\n) -> Generator[Tuple[int, int], None, None]:\n    \"\"\"Generate microseconds from quote string lengths.\n\n    :param quotes:\n    :type quotes: List[str]\n    :param total_secs:\n    :type total_secs: int\n    :rtype: Generator[Tuple[int, int], None, None]\n    \"\"\"\n    quote_lengths = [len(quote) for quote in quotes]\n\n    for q_len in quote_lengths:\n        percent = ((q_len * 100) / len(\"\".join(quotes))) * 0.01\n\n        diff = total_secs * percent\n        real = np.array([diff])\n\n        inte, dec = int(np.floor(real)), (real % 1).item()\n\n        new_micro = int(dec / 0.000001)\n\n        yield (inte, new_micro)\n\n\ndef _is_normal(quotes: Sequence[str]) -> bool:\n    \"\"\"\n    :param quotes:\n    :type quotes: Sequence[str]\n    \"\"\"\n    return any(len(quote) < 2 for quote in quotes) or len(quotes) != 2\n\n\ndef _split_dialogue(subtitle: Subtitle) -> Sequence[Subtitle]:\n    \"\"\"\n    :param subtitle:\n    :type subtitle: Subtitle\n    \"\"\"\n    logger.debug(\"Checking if the subtitle contains dialogue\")\n    quote = subtitle.content.replace(\"\\n-\", \" -\")\n\n    quotes = quote.split(\" - \")\n    if _is_normal(quotes):\n        quotes = quote.split(\" - \")\n        if _is_normal(quotes):\n            return [subtitle]\n\n    else:\n        if quotes[0].startswith(\"- \"):\n            fixed_quotes = [\n                fixed.replace(\"- \", \"\").strip() for fixed in quotes if len(fixed) > 2\n            ]\n            if len(fixed_quotes) == 1:\n                return [subtitle]\n            logger.debug(\"Dialogue found: %s\", fixed_quotes)\n\n            return _guess_timestamps(subtitle, fixed_quotes)\n\n    return [subtitle]\n\n\ndef _get_box(val, limit=4) -> list:\n    try:\n        box = [int(item.strip()) for item in val.split(\",\")]\n    except ValueError:\n        raise exceptions.InvalidRequest(f\"Non-int values found: {val}\") from None\n\n    if len(box) != limit:\n        raise exceptions.InvalidRequest(f\"Expected {limit} values, found {len(box)}\")\n\n    if any(0 < value > 100 for value in box):\n        pass\n        # raise exceptions.InvalidRequest(\n        #    f\"Negative or greater than 100 value found: {box}\"\n        # )\n\n    return box\n\n\n# _INDEX_RE = re.compile(r\"^(?=[\\d,-]*$)\\b(?:(\\d+-\\d+)|(\\d+))(?:,(?:(\\d+-\\d+)|(\\d+)))*\\b\")\n_INDEX_RE = re.compile(r\"(\\d+-\\d+|\\d+)(?:,|$)\")\n_NON_INDEX = re.compile(r\"^[\\d,-]*$\")\n_TOTAL_SPLIT = re.compile(r\"(\\s)[.,?!-](\\s)$\")\n\n\ndef _parse_index(text: str) -> Optional[List[int]]:\n    text = text.strip()\n    if _NON_INDEX.search(text) is None:\n        return None\n\n    items = _INDEX_RE.findall(text)\n\n    if not items:\n        return None\n\n    indexes = []\n    for item in items:\n        item = item.strip()\n\n        if \"-\" in item:\n            val = [int(i) for i in item.split(\"-\")]\n            if val[1] < val[0]:\n                raise exceptions.InvalidRequest(\"Invalid range: %s\", val)\n            indexes.extend(range(val[0], val[1] + 1))\n        else:\n            indexes.append(int(item))\n\n    return indexes\n"}
{"type": "source_file", "path": "kinobot/discord/comics.py", "content": "import asyncio\nimport logging\nimport os\nimport shutil\nimport tempfile\n\nfrom discord.ext import commands\nfrom libgenmics import client as libgen\nfrom libgenmics import comicinfo\nfrom libgenmics import comicvine\nfrom libgenmics import zipping\nimport requests\nfrom requests.exceptions import HTTPError\n\nfrom kinobot.sources.comics import client as kvt_client\nfrom kinobot.utils import get_yaml_config\n\nfrom .utils import ask\nfrom .utils import ask_to_confirm\nfrom .utils import call_with_typing\nfrom .utils import paginated_list\n\nlogger = logging.getLogger(__name__)\n\n\ndef _pretty_print(l):\n    return f\"{l.title} [{l.issue}] [{l.size}]\"\n\n\ndef _cv_pretty_print(issue: comicvine.ComicIssue):\n    return f\"{issue.volume.name} [Issue #{issue.issue_number}]\"\n\n\nasync def curate(bot, ctx: commands.Context, query, bytes_callback=None, config=None):\n    config = config or get_yaml_config(os.environ[\"YAML_CONFIG\"], \"comics\")\n\n    client = libgen.Client()\n\n    loop = asyncio.get_event_loop()\n    results = await call_with_typing(ctx, loop, client.search, query)\n\n    if not results:\n        await ctx.send(\"No results.\")\n\n    item = await paginated_list(\n        bot, ctx, f\"Results for `{query}`\", results, _pretty_print\n    )\n    if item is None:\n        return None\n\n    if not item.bytes:\n        await ctx.send(\"Unknown size. Couldn't continue.\")\n        return None\n\n    if bytes_callback is not None and bytes_callback(item.bytes) is False:\n        await ctx.send(\"You don't have enough GBs to continue.\")\n        return None\n\n    await ctx.send(\n        f\"**{_pretty_print(item)}**\"\n        \"\\n\\nPlease give me the ComicVine URL of the issue so I can add tags correctly.\"\n    )\n\n    url = await ask(bot, ctx, timeout=600)\n    if not url:\n        return None\n\n    cv_client = comicvine.Client(config[\"comicvine\"][\"api_key\"])\n\n    try:\n        cv_issue = await call_with_typing(\n            ctx, loop, cv_client.issue, url.strip()\n        )  # type: comicvine.ComicIssue\n    except requests.HTTPError:\n        await ctx.send(\"Invalid URL.\")\n        return None\n\n    correct = await ask_to_confirm(\n        bot,\n        ctx,\n        f\"Tagging\\n{_pretty_print(item)}\\n->\\n{_cv_pretty_print(cv_issue)}\\n\\nIs this correct? (y/n)\",\n    )\n    if not correct:\n        await ctx.send(\"Bye.\")\n        return None\n\n    await ctx.send(\"Trying to import automatically...\")\n    try:\n        await loop.run_in_executor(None, _download, item, cv_issue, config[\"root_dir\"])\n    except HTTPError:\n        if not any(\"annas\" in i for i in item.mirrors):\n            return await ctx.send(\"No files to import. Please, try another.\")\n\n        annas_mirror = [i for i in item.mirrors if \"annas\" in i][0]\n\n        await ctx.send(\n            \"Automatic import failed. Please, open the following link and copy \"\n            'the url of \"Download now\", usually placed in a line like this: '\n            \"***Use the following URL to download: Download now***.\"\n        )\n        await ctx.send(annas_mirror, delete_after=120)\n\n        await ctx.send(\"Give me the URL.\")\n\n        url_ = await ask(bot, ctx, delete=True)\n        if url_ is None:\n            await ctx.send(\"Bye.\")\n        else:\n            await ctx.send(\"Import queued.\")\n\n        try:\n            await loop.run_in_executor(\n                None, _download, item, cv_issue, config[\"root_dir\"], url_\n            )\n        except HTTPError as error:\n            logger.exception(error)\n            return await ctx.send(\"Download failed. Please, try another.\")\n\n    await ctx.reply(\"Import finished successfully! Updating library...\")\n\n    kvt_client_ = await _get_kvt_client(loop)\n    await call_with_typing(ctx, loop, kvt_client_.scan_all)\n\n    await ctx.send(\"Ok.\")\n\n    return item\n\n\ndef _download(item, cv_issue, root_dir, url=None):\n    with tempfile.NamedTemporaryFile(prefix=__name__) as temp_f:\n        url = url or item.mirrors[0]\n        if not url.startswith(\"http\"):\n            url = f\"https://libgen.gs/\" + url.lstrip(\"/\")\n\n        logger.info(\"URL to download: %s\", url)\n        _safe_download(url, temp_f.name)\n\n        with tempfile.NamedTemporaryFile(prefix=__name__, suffix=\".cbz\") as temp_f_2:\n            _extract_and_zip(temp_f.name, cv_issue, temp_f_2.name)\n\n            logger.debug(\"OK: %s\", temp_f_2.name)\n\n            parent_dir = os.path.join(root_dir, cv_issue.volume.name)\n            logger.debug(\"Parent dir: %s\", parent_dir)\n            os.makedirs(parent_dir, exist_ok=True)\n\n            final_path = os.path.join(parent_dir, f\"{cv_issue.issue_number}.cbz\")\n            shutil.copy(temp_f_2.name, final_path)\n            logger.debug(\"Final path: %s\", final_path)\n\n\ndef _safe_download(url, output, chunk_size=8192):\n    logger.debug(\"Downloading %s to %s\", url, output)\n    response = requests.get(url, stream=True)\n    response.raise_for_status()\n\n    with open(output, \"wb\") as file:\n        for chunk in response.iter_content(chunk_size=chunk_size):\n            if chunk:\n                file.write(chunk)\n\n\ndef _extract_and_zip(zipped, cv_issue: comicvine.ComicIssue, output_file):\n    with tempfile.TemporaryDirectory(prefix=__name__) as temp_d:\n        zipping.extract(zipped, temp_d)\n        comicinfo.make(\n            os.path.join(temp_d, \"ComicInfo.xml\"), **cv_issue.to_comic_info_xml_params()\n        )\n        zipping.make_cbz(temp_d, output_file)\n\n\nasync def _get_kvt_client(loop):\n    return await loop.run_in_executor(None, kvt_client.Client.from_config)\n\n\nasync def explorecomics(bot, ctx: commands.Context, *args):\n    loop = asyncio.get_running_loop()\n\n    query = \" \".join(args)\n    query = kvt_client.ComicQuery.from_str(query)\n    client = await _get_kvt_client(loop)\n\n    if not query.title:\n        return await ctx.send(\"No title provided\")\n\n    item = await call_with_typing(ctx, loop, client.first_series_matching, query.title)\n    if not item:\n        return await ctx.send(\n            \"Comic not found in db.\\n\\nNote that library updates are made every 15 minutes.\"\n        )\n\n    if not item.chapters:\n        return await ctx.send(\"This comic doesn't have any issues.\")\n\n    rec = f\"\"\"The issues shown above are available to request. You may get the page numbers to request\nby your own mediums - be it physical copies, e-readers, or digital platforms.\n\nRequest example: {item.name} issue X page X !comic [0:0]\"\"\"\n    issues = \", \".join([chapter.number for chapter in item.chapters])[:1000]\n    await ctx.send(f\"**Title:** {item.name}\\n**Issues:** {issues}\\n\\n*{rec}*\")\n"}
{"type": "source_file", "path": "kinobot/discord/admin.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\n# Discord bot for admin tasks.\n\nimport asyncio\nimport datetime\nimport functools\nimport logging\nimport os\nimport re\nimport subprocess\nfrom typing import Optional\n\nfrom discord import channel\nfrom discord import Member\nfrom discord.ext import commands\nimport pysubs2\n\nfrom kinobot.discord.extras import subtitles as d_subtitles\nfrom kinobot.discord.utils import paginated_list\nfrom kinobot.misc import bonus\n\nfrom . import anime\nfrom . import review\nfrom . import sports\nfrom . import utils\nfrom . import jackpot\nfrom . import wrapped as wrapped_module\nfrom ..constants import KINOBASE\nfrom ..constants import YAML_CONFIG\nfrom ..db import Execute\nfrom ..exceptions import InvalidRequest\nfrom ..frame import FONTS_DICT\nfrom ..jobs import post_to_facebook\nfrom ..jobs import register_media\nfrom ..media import Episode\nfrom ..media import Movie\nfrom ..post import register_posts_metadata\nfrom ..register import FacebookRegister\nfrom ..request import get_cls\nfrom ..request import Request\nfrom ..user import User\nfrom ..utils import get_yaml_config\nfrom ..utils import is_episode\nfrom ..utils import sync_local_subtitles\nfrom .chamber import Chamber\nfrom .chamber import CollaborativeChamber\nfrom .comics import curate as comic_curate\nfrom .comics import explorecomics\nfrom .common import get_req_id_from_ctx\nfrom . import video as video_module\nfrom .common import handle_error\nfrom .extras.announcements import top_contributors\nfrom .extras.curator import MovieView\nfrom .extras.curator import RadarrClient\nfrom .extras.curator import register_movie_addition\nfrom .extras.curator import register_tv_show_season_addition\nfrom .extras.curator import ReleaseModel\nfrom .extras.curator import ReleaseModelSonarr\nfrom .extras.curator import SonarrClient\nfrom .extras.curator import SonarrTVShowModel\nfrom .extras.curator_user import AnimeCurator\nfrom .extras.curator_user import Curator\nfrom .extras.verification import IGUserDB as IGVerificationUser\nfrom .extras.verification import UserDB as VerificationUser\nfrom .extras.verifier import Poster\nfrom .extras.verifier import Verifier\nfrom .games import addgame\nfrom .games import deletecutscene\nfrom .games import explorecutscenes\nfrom .games import exploregames\nfrom .instagram import ig_poster\nfrom .instagram import make_post\nfrom .mangas import addchapter\nfrom .mangas import addmanga\nfrom .mangas import exploremangas\nfrom .ochamber import OldiesChamber\nfrom .request_trace import trace_checks\nfrom .songs import addsong\nfrom .songs import exploresongs\nfrom .tickets import approve as approve_\nfrom .tickets import reject as reject_\nfrom .tickets import verify as verify_\nfrom . import emby\n\nlogging.getLogger(\"discord\").setLevel(logging.INFO)\n\nlogger = logging.getLogger(__name__)\n\nbot = commands.Bot(command_prefix=\"!\")\n\n\ndef _get_cls_from_ctx(ctx):\n    return get_cls(get_req_id_from_ctx(ctx))\n\n\n@bot.command(name=\"bonus\", help=\"Check bonus.\")\n@commands.has_any_role(\"botmin\")\nasync def run_bonus(ctx):\n    loop = asyncio.get_running_loop()\n\n    await call_with_typing(ctx, loop, None, bonus.run)\n    await ctx.send(\"Ok.\")\n\n\n@bot.command(name=\"averify\", help=\"Verify a request by ID.\")\n@commands.has_any_role(\"botmin\")\nasync def admin_verify(ctx: commands.Context, id_: str):\n    req = _get_cls_from_ctx(ctx).from_db_id(id_)\n    req.mark_as_unused()\n    req.verify()\n\n    await ctx.send(f\"Verified: {req.pretty_title}\")\n\n\n@bot.command(name=\"aigverify\", help=\"Verify an IG request by ID.\")\n@commands.has_any_role(\"botmin\")\nasync def admin_ig_verify(ctx: commands.Context, id_: str):\n    req = _get_cls_from_ctx(ctx).from_db_id(id_)\n    req.add_tag(\"ig\")\n    req.verify()\n\n    await ctx.send(f\"Verified: {req.pretty_title}\")\n\n\n@bot.command(name=\"review\", help=\"Review requests from the FB queue.\")\n@commands.has_any_role(\"botmin\", \"verifier\")\nasync def review_(ctx: commands.Context):\n    await review.review(ctx)\n\n\n@bot.command(name=\"esub\", help=\"Upload subtitles\")\n@commands.has_any_role(\"botmin\", \"subtitles\")\nasync def esub(ctx: commands.Context):\n    await d_subtitles.edit(bot, ctx)\n\n\n@bot.command(name=\"usub\", help=\"Upload subtitles\")\n@commands.has_any_role(\"botmin\", \"subtitles\")\nasync def usub(ctx: commands.Context):\n    await d_subtitles.upload(bot, ctx)\n\n\n@bot.command(name=\"ssub\", help=\"Shift subtitles by milliseconds\")\n@commands.has_any_role(\"botmin\", \"subtitles\")\nasync def ssub(ctx: commands.Context):\n    await d_subtitles.shift(bot, ctx)\n\n\n@bot.command(name=\"asub\", help=\"Try to sync subtitles automatically with alass\")\n@commands.has_any_role(\"botmin\", \"subtitles\")\nasync def asub(ctx: commands.Context):\n    await d_subtitles.autosync(bot, ctx)\n\n\n@bot.command(name=\"clone\", help=\"Clone a request to queue.\")\n@commands.has_any_role(\"botmin\")\nasync def clone(ctx: commands.Context, id_: str, tag=None):\n    request = _get_cls_from_ctx(ctx).from_db_id(id_)\n    new = request.clone()\n\n    if tag is None:\n        new.add_tag(tag)\n\n    new.verify()\n\n    await ctx.send(str(new.id))\n\n\n@bot.command(name=\"verify\", help=\"Verify a request by ID.\")\n@commands.has_any_role(\"botmin\", \"maoist\", \"super-maoist\", \"sponsor\", \"ticketer\")\nasync def verify(ctx: commands.Context, id_: str):\n    await verify_(ctx, id_)\n\n\n@bot.command(name=\"approve\", help=\"Approve a request by ID.\")\n@commands.has_any_role(\"botmin\", \"certified verifier\")\nasync def approve(ctx: commands.Context, id_: str):\n    await approve_(ctx, id_)\n\n\n@bot.command(name=\"reject\", help=\"Reject a request by ID.\")\n@commands.has_any_role(\"botmin\", \"certified verifier\")\nasync def reject(ctx: commands.Context, id_: str, *args):\n    await reject_(ctx, id_, *args)\n\n\n# @bot.command(name=\"igverify\", help=\"Verify an IG request by ID.\")\nasync def igverify(ctx: commands.Context, id_: str):\n    request = _get_cls_from_ctx(ctx).from_db_id(id_)\n    if request.verified:\n        return await ctx.send(\"This request was already verified\")\n\n    loop = asyncio.get_running_loop()\n\n    await ctx.send(\"Loading request...\")\n    handler = await call_with_typing(ctx, loop, None, request.get_handler)\n    await call_with_typing(ctx, loop, None, handler.get)\n\n    bad = await trace_checks(ctx, handler.make_trace())\n\n    if bad is False:\n        risk = request.facebook_risk()\n        if risk is not None:\n            await ctx.send(\n                f\"WARNING: there's a possible facebook-risky pattern: `{risk}`.\"\n            )\n            bad = True\n\n    if bad is True:\n        return await ctx.send(\n            \"You are not allowed to verify this. If you believe this request is fine, ask the administrator \"\n            \"for manual verification. You can also remove the offending content/flag and try verifying again.\"\n        )\n\n    with IGVerificationUser(ctx.author.id, KINOBASE) as user:\n        used_ticket = user.log_ticket(request.id)\n        request.add_tag(\"ig\")\n        request.verify()\n\n    await ctx.send(f\"{request.pretty_title} **verified with ticket**: {used_ticket}\")\n\n\n@bot.command(name=\"emsetup\", help=\"Setup your Jellyfin/Emby wrapped data.\")\nasync def emsetup(ctx: commands.Context):\n    await emby.setup(bot, ctx)\n\n\n@bot.command(name=\"vid\", help=\"Run video command.\")\nasync def video(ctx: commands.Context, *args):\n    try:\n        with video_module.deduct_token(ctx.author.id):\n            await video_module.make(ctx, args)\n    except video_module.NoBalance:\n        await ctx.send(\n            \"You don't have any tokens to use. Donate to get tokens https://ko-fi.com/vitiko\"\n        )\n\n\n@bot.command(name=\"lastplayed\", help=\"Run your last played.\")\nasync def lastplayed(ctx: commands.Context, *args):\n    await emby.run(bot, ctx, \" \".join(args))\n\n\n@bot.command(name=\"tickets\", help=\"Show tickets count.\")\nasync def tickets(ctx: commands.Context):\n    if str(ctx.author.id) == \"336777437646028802\":\n        return await ctx.send(\"This user has unlimited tickets\")\n\n    with VerificationUser(ctx.author.id, KINOBASE) as user:\n        available_tickets = user.available_tickets()\n        expired_tickets = user.expired_tickets()\n\n    await ctx.send(\n        f\"Available tickets: {len(available_tickets)}\\n\"\n        f\"Expired tickets: {len(expired_tickets)}\\n\\n\"\n    )\n\n\n@bot.command(name=\"fonts\", help=\"Get the list of available fonts\")\nasync def fonts(ctx: commands.Context):\n    fonts = sorted(list(FONTS_DICT.keys()))\n    keys = [f\"**{font}**\" for font in fonts]\n    await ctx.send(f\"Available fonts:\\n\\n{', '.join(keys)}\"[:999])\n\n\n@bot.command(name=\"rfi\", help=\"Get request string from ID\")\nasync def req_from_id(ctx: commands.Context, id: str):\n    req = _get_cls_from_ctx(ctx).from_db_id(id)\n    await ctx.send(req.comment)\n\n\n@bot.command(name=\"collab\", help=\"Add an user to a request as a collaborator\")\nasync def collab(ctx: commands.Context, user: Member, request_id: str):\n    req = Request.from_db_id(request_id)\n\n    author_id = str(ctx.author.id)\n    if req.user_id != author_id:\n        return await ctx.send(\"You are not the author of the request.\")\n\n    req.add_collaborator(user.id)\n    await ctx.send(f\"Added *{user.id}* as a collaborator for {req.comment}\")\n\n\n@bot.command(name=\"gpayout\", help=\"Add payout\")\n@commands.has_any_role(\"botmin\")\nasync def gpayout(ctx: commands.Context, user: Member, amount: int):\n    result = jackpot.add_payout(user.id, amount * 100)\n    return await ctx.send(str(result))\n\n\n@bot.command(name=\"gticket\", help=\"Give verification tickets\")\n@commands.has_any_role(\"botmin\")\nasync def gticket(ctx: commands.Context, user: Member, tickets, days=90):\n    summary = (\n        f\"Gave by admin in {datetime.datetime.now().strftime('%m/%d/%Y, %H:%M:%S')}\"\n    )\n\n    with VerificationUser(user.id, KINOBASE) as v_user:\n        for _ in range(int(tickets)):\n            v_user.append_ticket(\n                summary=summary, expires_in=datetime.timedelta(days=int(days))\n            )\n\n        available_tickets = v_user.available_tickets()\n\n    await ctx.send(\n        f\"{tickets} tickets registered for {user.display_name}\\n\"\n        f\"Available tickets: {len(available_tickets)}\"\n    )\n\n\n@bot.command(name=\"givejackpot\", help=\"Give yesterday's jackpot\")\n@commands.has_any_role(\"botmin\")\nasync def givejackpot(ctx: commands.Context):\n    jackpot.give_jackpot()\n\n\n@bot.command(name=\"currentjackpot\", help=\"See current jackpot\")\n@commands.has_any_role(\"botmin\")\nasync def currentjackpot(ctx: commands.Context):\n    jackpot.get_current_jackpot()\n\n\n@bot.command(name=\"gigticket\", help=\"Give verification tickets\")\n@commands.has_any_role(\"botmin\")\nasync def gigticket(ctx: commands.Context, user: Member, tickets, days=90):\n    summary = (\n        f\"Gave by admin in {datetime.datetime.now().strftime('%m/%d/%Y, %H:%M:%S')}\"\n    )\n\n    with IGVerificationUser(user.id, KINOBASE) as v_user:\n        for _ in range(int(tickets)):\n            v_user.append_ticket(\n                summary=summary, expires_in=datetime.timedelta(days=int(days))\n            )\n\n        available_tickets = v_user.available_tickets()\n\n    await ctx.send(\n        f\"{tickets} IG tickets registered for {user.display_name}\\n\"\n        f\"Available IG tickets: {len(available_tickets)}\"\n    )\n\n\n@bot.command(name=\"gpack\", help=\"Give pack from currency\")\n@commands.has_any_role(\"botmin\")\nasync def gpack(ctx: commands.Context, currency, *users: Member):\n    days = 90\n    currency = float(currency)\n    for user in users:\n        await gkey(ctx, user, currency * 3, days=int(days))\n        await gticket(ctx, user, int(currency), days=int(days))\n        await video_module.give_tokens(ctx, user, int(currency * 20))\n\n\n@bot.command(name=\"gtokens\", help=\"Give tokens\")\n@commands.has_any_role(\"botmin\")\nasync def gtokens(ctx: commands.Context, user: Member, amount, *args):\n    await video_module.give_tokens(ctx, user, int(amount * 20))\n\n\n@bot.command(name=\"rtokens\", help=\"Remove available tokens\")\n@commands.has_any_role(\"botmin\")\nasync def rtokens(ctx: commands.Context, user: Member, amount, *args):\n    await video_module.remove_tokens(ctx, user, amount)\n\n\n@bot.command(name=\"rticket\", help=\"Remove available tickets\")\n@commands.has_any_role(\"botmin\")\nasync def rticket(ctx: commands.Context, user: Member, tickets, *args):\n    with VerificationUser(user.id, KINOBASE) as v_user:\n        v_user.delete_tickets(int(tickets))\n        available_tickets = v_user.available_tickets()\n\n    await ctx.send(\n        f\"{tickets} tickets removed for {user.display_name}.\\n\"\n        f\"Available tickets: {len(available_tickets)}\"\n    )\n\n\n@bot.command(name=\"delete\", help=\"Mark as used a request by ID.\")\n@commands.has_any_role(\"botmin\", \"verifier\")\nasync def delete(ctx: commands.Context, id_: str):\n    req = _get_cls_from_ctx(ctx).from_db_id(id_)\n    req.mark_as_used()\n    await ctx.send(f\"Marked as used: {req.pretty_title}\")\n\n\n@commands.has_any_role(\"botmin\", \"verifier\")\n@bot.command(name=\"chamber\", help=\"Enter the verification chamber.\")\nasync def chamber(ctx: commands.Context, *args):\n    chamber = await CollaborativeChamber.from_bot(bot, ctx, args)\n    await chamber.start()\n\n\n@commands.has_any_role(\"botmin\", \"certified verifier\")\n@bot.command(name=\"schamber\", help=\"Enter the verification chamber.\")\nasync def schamber(ctx: commands.Context):\n    await ctx.send(\n        \"Requests newer than N days. Send any alphabetical character to allow any request.\"\n    )\n    msg = await utils.ask(bot, ctx)\n\n    try:\n        newer_than = datetime.timedelta(days=int(msg))\n    except:\n        newer_than = None\n\n    await ctx.send(\"Private chamber? (y/n)\")\n    msg = await utils.ask(bot, ctx)\n\n    try:\n        private = msg.lower() == \"y\"\n    except:\n        private = False\n\n    await ctx.send(\"Avoid multiple images (y/n)\")\n    msg = await utils.ask(bot, ctx)\n\n    try:\n        no_multiple_images = msg.lower() == \"y\"\n    except:\n        no_multiple_images = False\n\n    await ctx.send(\n        \"Exclude requests containing the following keywords. Send a single character to allow any request.\"\n    )\n    msg = await utils.ask(bot, ctx)\n    exclude_list = None\n    if msg:\n        exclude_list = [item for item in msg.split() if len(item.strip()) > 1]\n        if not exclude_list:\n            exclude_list = None\n\n    chamber = Chamber(\n        bot,\n        ctx,\n        newer_than=newer_than,\n        exclude_if_contains=exclude_list,\n        no_multiple_images=no_multiple_images,\n        private=private,\n    )\n    await chamber.start()\n\n\n@commands.has_any_role(\"botmin\")\n@bot.command(name=\"ochamber\", help=\"Enter the oldies verification chamber.\")\nasync def ochamber(ctx: commands.Context):\n    chamber = OldiesChamber(bot, ctx)\n    await chamber.start()\n\n\n@bot.command(name=\"count\", help=\"Show the count of verified requests.\")\nasync def count(ctx: commands.Context):\n    req_cls = _get_cls_from_ctx(ctx)\n    await ctx.send(\n        f\"Verified requests: {Execute().queued_requets(table=req_cls.table)}\"\n    )\n\n    await ctx.send(\n        f\"Verified requests (300k): {Execute().queued_requets(table=req_cls.table, tag='300k')}\"\n    )\n\n\n@commands.has_any_role(\"botmin\")\n@bot.command(name=\"makeig\")\nasync def makeig(ctx: commands.Context, id=None):\n    loop = asyncio.get_running_loop()\n    await call_with_typing(ctx, loop, None, ig_poster, id)\n    await ctx.send(\"Ok.\")\n\n\n@bot.command(name=\"ig\")\nasync def ig(ctx: commands.Context, *args):\n    req = _get_cls_from_ctx(ctx)(\n        \" \".join(args), ctx.author.id, ctx.author.name, ctx.message.id\n    )\n    req.register()\n    req.add_tag(\"ig\")\n\n    await ctx.send(req.id)\n\n\n@commands.has_any_role(\"botmin\")\n@bot.command(name=\"scan\", help=\"Scan facebook comments\")\nasync def scan(ctx: commands.Context, count: int):\n    await ctx.send(f\"Scanning {count} posts per page...\")\n\n    loop = asyncio.get_running_loop()\n\n    for identifier in (\"en\", \"es\", \"pt\"):\n        register = FacebookRegister(int(count), identifier)\n        await call_with_typing(ctx, loop, None, register.requests)\n\n    await ctx.send(\"Done.\")\n\n\ndef _media_from_query(query):\n    if is_episode(query):\n        return Episode.from_query(query)\n\n    return Movie.from_query(query)\n\n\n@commands.has_any_role(\"botmin\")\n@bot.command(name=\"blacklist\", help=\"Blacklist a movie or an episode\")\nasync def blacklist(ctx: commands.Context, *args):\n    query = \" \".join(args)\n    item = _media_from_query(query)\n    item.hidden = True\n    item.update()\n    await ctx.send(f\"Blacklisted: {item.simple_title}.\")\n\n\n@commands.has_any_role(\"botmin\")\n@bot.command(name=\"media\", help=\"Register media\")\nasync def media(ctx: commands.Context):\n    await ctx.send(\"Registering media\")\n    loop = asyncio.get_running_loop()\n    await loop.run_in_executor(None, register_media)\n    await ctx.send(\"Ok\")\n\n\n@commands.has_any_role(\"botmin\")\n@bot.command(name=\"fbpost\", help=\"Post to Facebook\")\nasync def fbpost(ctx: commands.Context):\n    await ctx.send(\"Running Facebook loop...\")\n    loop = asyncio.get_running_loop()\n    await loop.run_in_executor(None, post_to_facebook)\n    await ctx.send(\"Ok\")\n\n\n@commands.has_any_role(\"botmin\")\n@bot.command(name=\"insights\", help=\"Register insights\")\nasync def insights(ctx: commands.Context, days: str, to_hours=12):\n    from_ = datetime.datetime.now() - datetime.timedelta(days=int(days))\n    to_ = datetime.datetime.now() - datetime.timedelta(hours=int(to_hours))\n\n    config = get_yaml_config(YAML_CONFIG, \"facebook\")\n\n    loop = asyncio.get_running_loop()\n\n    for key, val in config.items():\n        await ctx.send(f\"Scanning '{key}' insights\")\n        await loop.run_in_executor(\n            None,\n            functools.partial(\n                register_posts_metadata, val[\"insights_token\"], from_, to_, False\n            ),\n        )\n\n    await ctx.send(\"Done.\")\n\n\n@commands.has_any_role(\"botmin\")\n@bot.command(name=\"syncsubs\", help=\"Sync local subtitles\")\nasync def syncsubs(ctx: commands.Context):\n    await ctx.send(\"Syncing local subtitles\")\n    loop = asyncio.get_running_loop()\n    await loop.run_in_executor(None, sync_local_subtitles)\n    await ctx.send(\"Ok\")\n\n\ndef _check_author(author):\n    return lambda message: message.author == author\n\n\nasync def _interactive_index(ctx, items):\n    chosen_index = 0\n\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        try:\n            chosen_index = int(msg.content.lower().strip()) - 1\n            items[chosen_index]\n        except (ValueError, IndexError):\n            await ctx.send(\"Invalid index! Bye\")\n            return None\n\n    except asyncio.TimeoutError:\n        await ctx.send(\"Timeout! Bye\")\n        return None\n\n    return chosen_index\n\n\nasync def _interactive_int_index(ctx, items):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        try:\n            selected = int(msg.content.lower().strip())\n            if selected not in items:\n                raise ValueError\n\n            return selected\n        except ValueError:\n            await ctx.send(\"Invalid index! Bye\")\n            return None\n\n    except asyncio.TimeoutError:\n        await ctx.send(\"Timeout! Bye\")\n        return None\n\n\nasync def _interactive_y_n(ctx):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        return msg.content.lower().strip() == \"y\"\n    except asyncio.TimeoutError:\n        return await ctx.send(\"Timeout! Bye\")\n\n\nasync def _pretty_title_list(ctx, items, append=None):\n    str_list = \"\\n\".join(f\"{n}. {m.pretty_title()}\" for n, m in enumerate(items, 1))\n    msg = f\"Choose the item you want to add ('n' to ignore):\\n\\n{str_list}\"\n\n    if append is not None:\n        msg = f\"{msg}\\n\\n{append}\"\n\n    await ctx.send(msg[:1999])\n\n\nasync def call_with_typing(ctx, loop, *args):\n    result = None\n    async with ctx.typing():\n        result = await loop.run_in_executor(*args)\n\n    return result\n\n\n_MIN_BYTES = 1e9\n\n\ndef _pretty_gbs(bytes_):\n    return f\"{bytes_/float(1<<30):,.1f} GBs\"\n\n\n@bot.command(name=\"updateanime\", help=\"Update anime\")\nasync def updateanime(ctx: commands.Context, *args):\n    await anime.update(bot, ctx)\n\n\n# @bot.command(name=\"addan\", help=\"Add anime\")\nasync def addan(ctx: commands.Context, *args):\n    await anime.add(bot, ctx, *args)\n\n\n@bot.command(name=\"addc\", help=\"Add comic issues\")\nasync def addc(ctx: commands.Context, *args):\n    with Curator(ctx.author.id, KINOBASE) as curator:\n        size_left = curator.size_left()\n\n    def bytes_callback(bytes_):\n        return size_left >= bytes_\n\n    item = await comic_curate(bot, ctx, \" \".join(args), bytes_callback)\n    try:\n        assert item.bytes\n    except AttributeError:\n        return None\n\n    with Curator(ctx.author.id, KINOBASE) as curator:\n        curator.register_addition(item.bytes, note=\"comic\")\n\n\n@bot.command(name=\"cutscenes\", help=\"Search for cutscenes from a game\")\nasync def cutscene_(ctx: commands.Context, *args):\n    return await explorecutscenes(bot, ctx, *args)\n\n\n@bot.command(name=\"addmatch\", help=\"Add a sports match\")\nasync def addmatch(ctx: commands.Context, video_url):\n    return await sports.add(bot, ctx, video_url)\n\n\n@bot.command(name=\"matches\", help=\"Explore sports matches\")\nasync def matches(ctx: commands.Context, *args):\n    return await sports.explore(bot, ctx, *args)\n\n\n@bot.command(name=\"games\", help=\"Search for games\")\nasync def games_(ctx: commands.Context, *args):\n    return await exploregames(bot, ctx, *args)\n\n\n@bot.command(name=\"delcutscene\", help=\"Delete a cutscene\")\nasync def delcutscene(ctx: commands.Context, *args):\n    return await deletecutscene(bot, ctx, \" \".join(args))\n\n\n@bot.command(name=\"addg\", help=\"Add a game cutscene to the database.\")\nasync def addgame_(ctx: commands.Context, video_url, *args):\n    return await addgame(bot, ctx, video_url, *args)\n\n\n@bot.command(name=\"addmangach\", help=\"Add a manga chapter by ID or URL.\")\nasync def addmangach_(ctx: commands.Context, url):\n    return await addchapter(bot, ctx, url)\n\n\n@bot.command(name=\"addmanga\", help=\"Add a manga title to the database.\")\nasync def addmanga_(ctx: commands.Context, video_url, *args):\n    return await addmanga(bot, ctx, video_url, *args)\n\n\n@bot.command(name=\"mangas\", help=\"Search for manga titles\")\nasync def mangas_(ctx: commands.Context, video_url, *args):\n    return await exploremangas(bot, ctx, video_url, *args)\n\n\n@bot.command(name=\"comics\", help=\"Search for comics\")\nasync def comics_(ctx: commands.Context, *args):\n    return await explorecomics(bot, ctx, *args)\n\n\n@bot.command(name=\"adds\", help=\"Add a song music video to the database.\")\n@commands.has_any_role(\"botmin\", \"music_curator\")\nasync def addsong_(ctx: commands.Context, video_url, *args):\n    return await addsong(bot, ctx, video_url, *args)\n\n\n@bot.command(name=\"contribs\")\n@commands.has_any_role(\"botmin\")\nasync def contribs(ctx: commands.Context):\n    top_contributors()\n\n\n@bot.command(name=\"songs\", help=\"Search for songs by artist or title\")\nasync def songs_(ctx: commands.Context, *args):\n    return await exploresongs(bot, ctx, *args)\n\n\n@bot.command(name=\"addm\", help=\"Add a movie to the database.\")\nasync def addmovie(ctx: commands.Context, *args):\n    with Curator(ctx.author.id, KINOBASE) as curator:\n        size_left = curator.size_left()\n\n    if size_left < _MIN_BYTES:\n        return await ctx.send(\n            f\"You need at least a quota of 1 GB to use this feature. You have {_pretty_gbs(size_left)}.\"\n        )\n\n    query = \" \".join(args)\n\n    user = User.from_discord(ctx.author)\n    user.load()\n\n    loop = asyncio.get_running_loop()\n\n    try:\n        client = await call_with_typing(ctx, loop, None, RadarrClient.from_constants)\n    except Exception as error:\n        logger.error(error, exc_info=True)\n        return await ctx.send(\n            \"This curator feature is not available at the moment. Please \"\n            \"try again later.\"\n        )\n\n    movies = await call_with_typing(ctx, loop, None, client.lookup, query)\n    movies = movies[:10]\n\n    movie_views = [MovieView(movie) for movie in movies]\n\n    chosen_movie_view = await paginated_list(\n        bot, ctx, \"Movies\", movie_views, lambda d: d.pretty_title()\n    )\n    if chosen_movie_view is None:\n        return None\n\n    chosen_movie = [\n        movie\n        for movie in movies\n        if movie.get(\"tmdbId\") == chosen_movie_view.data.get(\"tmdbId\")\n    ][0]\n\n    if chosen_movie_view.already_added():  # or chosen_movie_view.to_be_added():\n        await ctx.send(\n            \"WARNING. This movie is already in the database. \"\n            \"Update it only if it's an upgrade, otherwise it will fail.\"\n        )\n\n    await ctx.send(embed=chosen_movie_view.embed())\n    await ctx.send(\"Are you sure? (y/n)\")\n\n    sure = await _interactive_y_n(ctx)\n    if not sure:\n        await ctx.send(\"Bye.\")\n        return None\n\n    result = await call_with_typing(ctx, loop, None, client.add, chosen_movie, False)\n\n    pretty_title = f\"**{chosen_movie_view.pretty_title()}**\"\n\n    await ctx.send(\"Looking for releases\")\n    manual_r = await call_with_typing(\n        ctx, loop, None, client.manual_search, result[\"id\"]\n    )\n\n    models = [ReleaseModel(**item) for item in manual_r]\n    models = [\n        model for model in models if model.seeders and \"Unknown\" != model.quality.name\n    ]\n    if not models:\n        return await ctx.send(\"No releases found.\")\n\n    models.sort(key=lambda x: x.size, reverse=False)\n\n    append_txt = (\n        \"Expected quality: **Blu-ray > WEB-DL > WEBrip/DVD > Others**.\\n**Bitrate > Resolution** \"\n        \"(most cases).\\nAsk admin if you are not sure about releases \"\n        \"that require manual import; your GBs won't be recovered.\"\n    )\n    chosen_model = await paginated_list(\n        bot, ctx, \"Releases\", models, lambda d: d.pretty_title(), slice_in=10\n    )\n    #    await _pretty_title_list(ctx, models[:20], append_txt)\n\n    if not chosen_model:\n        return None\n    #    chosen_index = await _interactive_index(ctx, models)\n    #    if chosen_index is None:\n    #        return None\n\n    await ctx.send(\"Are you sure? (y/n)\")\n\n    model_1 = chosen_model\n\n    if model_1.size > size_left:\n        return await ctx.send(\"You don't have enough GBs available.\")\n\n    sure = await _interactive_y_n(ctx)\n    if not sure:\n        return await ctx.send(\"Bye.\")\n\n    await loop.run_in_executor(\n        None,\n        client.add_to_download_queue,\n        model_1.movie_id,\n        model_1.guid,\n        model_1.indexer_id,\n    )\n\n    register_movie_addition(user.id, chosen_movie_view.tmdb_id)\n\n    with Curator(ctx.author.id, KINOBASE) as curator:\n        curator.register_addition(model_1.size, \"Made via curator command\")\n        new_size_left = curator.size_left()\n\n    await ctx.send(\n        f\"Getting the release. Let's wait.\\nGBs left: {_pretty_gbs(new_size_left)}\"\n    )\n\n    await asyncio.sleep(10)\n\n    retries = 0\n    grabbed_event_sent = False\n\n    while 45 > retries:\n        events = await loop.run_in_executor(\n            None, client.events_in_history, result[\"id\"]\n        )\n        for event in events:\n            if event == \"downloadFolderImported\":\n                return await ctx.reply(f\"{pretty_title} is ready!\")\n\n            if event == \"grabbed\" and not grabbed_event_sent:\n                grabbed_event_sent = True\n                # await ctx.reply(\n                #    f\"Good news: {pretty_title} is being imported. Let's wait...\"\n                # )\n            else:\n                logger.debug(\"Unknown event: %s\", event)\n\n        retries += 1\n        await asyncio.sleep(60)\n\n    if grabbed_event_sent:\n        await ctx.reply(\n            f\"{pretty_title} is taking too much time to import. Botmin will \"\n            \"have a look if the issue persists.\"\n        )\n    else:\n        await ctx.reply(\n            f\"Impossible to add {pretty_title} automatically. Botmin will check it manually.\"\n        )\n\n\n@bot.command(name=\"addtv\", help=\"Add a TV Show's season to the database.\")\nasync def addtvshow(ctx: commands.Context, *args):\n    with Curator(ctx.author.id, KINOBASE) as curator:\n        size_left = curator.size_left()\n\n    if size_left < _MIN_BYTES:\n        return await ctx.send(\n            f\"You need at least a quota of 1 GB to use this feature. You have {_pretty_gbs(size_left)}.\"\n        )\n\n    query = \" \".join(args)\n\n    user = User.from_discord(ctx.author)\n    user.load()\n\n    loop = asyncio.get_running_loop()\n\n    try:\n        client = await call_with_typing(ctx, loop, None, SonarrClient.from_constants)\n    except Exception as error:\n        logger.error(error, exc_info=True)\n        return await ctx.send(\n            \"This curator feature is not available at the moment. Please \"\n            \"try again later.\"\n        )\n\n    items = await call_with_typing(ctx, loop, None, client.lookup, query)\n    tv_models = [SonarrTVShowModel(**item) for item in items[:10]]\n\n    await _pretty_title_list(ctx, tv_models)\n\n    chosen_index = await _interactive_index(ctx, tv_models)\n\n    if chosen_index is None:\n        return None\n\n    chosen_tv = tv_models[chosen_index]\n\n    await ctx.send(embed=chosen_tv.embed())\n    await ctx.send(\"Are you sure? (y/n)\")\n\n    sure = await _interactive_y_n(ctx)\n    if not sure:\n        return await ctx.send(\"Bye\")\n\n    result = await call_with_typing(\n        ctx, loop, None, client.add, items[chosen_index], False\n    )\n    series_id = result[\"id\"]\n\n    valid_seasons = [i.season_number for i in chosen_tv.seasons if i.season_number]\n    await ctx.send(f\"Select the season: {', '.join(str(i) for i in valid_seasons)}\")\n    chosen_season = await _interactive_int_index(ctx, valid_seasons)\n    if chosen_season is None:\n        return None\n\n    await ctx.send(\n        f\"Looking for releases [{chosen_tv.pretty_title()} Season {chosen_season}]\"\n    )\n    manual_r = await call_with_typing(\n        ctx,\n        loop,\n        None,\n        client.manual_search,\n        result[\"id\"],\n        chosen_season,\n    )\n\n    models = [ReleaseModelSonarr(**item, seriesId=series_id) for item in manual_r]  # type: ignore\n    models = [model for model in models if model.seeders]\n    if not models:\n        return await ctx.send(\"No releases found.\")\n\n    models.sort(key=lambda x: x.size, reverse=False)\n\n    # append_txt = (\n    #   \"Expected quality: **Blu-ray > WEB-DL > WEBrip/DVD > Others**.\\n**Bitrate > Resolution** \"\n    #   \"(most cases). Subtitles are harder to get for HDTV releases.\\nAsk admin if you are not \"\n    #   \"sure about releases that require manual import.\"\n\n    # )\n    model_1 = await paginated_list(\n        bot, ctx, \"Releases\", models, lambda d: d.pretty_title(), slice_in=10\n    )\n    if model_1 is None:\n        return None\n\n    await ctx.send(\"Are you sure? (y/n)\")\n\n    if model_1.size > size_left:\n        return await ctx.send(\"You don't have enough GBs available.\")\n\n    sure = await _interactive_y_n(ctx)\n    if not sure:\n        return await ctx.send(\"Bye.\")\n\n    await loop.run_in_executor(\n        None,\n        client.add_to_download_queue,\n        model_1.guid,\n        model_1.indexer_id,\n    )\n\n    register_tv_show_season_addition(user.id, chosen_tv.tvdb_id, chosen_season)\n\n    with Curator(ctx.author.id, KINOBASE) as curator:\n        curator.register_addition(model_1.size, \"Made via curator command\")\n        new_size_left = curator.size_left()\n\n    await ctx.send(\n        f\"Getting the release. Let's wait.\\nGBs left: {_pretty_gbs(new_size_left)} \"\n        \"Check #announcements.\"\n    )\n\n\n_GB = float(1 << 30)\n\n\n@bot.command(name=\"gkey\", help=\"Give a curator key\")\n@commands.has_any_role(\"botmin\")\nasync def gkey(ctx: commands.Context, user: Member, gbs, days=90, *args):\n    await _gkey(ctx, gbs, user.id, \" \".join(args), days=int(days))\n\n\n@bot.command(name=\"gkeya\", help=\"Give an anime curator key\")\n@commands.has_any_role(\"botmin\")\nasync def gkeya(ctx: commands.Context, user: Member, gbs, days=90, *args):\n    await _gkey(ctx, gbs, user.id, \" \".join(args), days=int(days), cls_=AnimeCurator)\n\n\n@bot.command(name=\"vtop\", help=\"Show verifiers top\")\nasync def vtop(ctx: commands.Context):\n    with Verifier(ctx.author.id, KINOBASE) as verifier:\n        result = verifier.get_top(\n            between=(None, datetime.datetime.now() - datetime.timedelta(hours=12))\n        )\n\n    await ctx.send(f\"```{result.as_table()}```\")\n\n\n@bot.command(name=\"utop\", help=\"Show users top\")\nasync def utop(ctx: commands.Context):\n    with Poster(ctx.author.id, KINOBASE) as poster:\n        result = poster.get_top(\n            between=(None, datetime.datetime.now() - datetime.timedelta(hours=12))\n        )\n\n    await ctx.send(f\"```{result.as_table()}```\")\n\n\n@bot.command(name=\"ucard\", help=\"Show users top card\")\nasync def ucard(ctx: commands.Context):\n    with Poster(ctx.author.id, KINOBASE) as poster:\n        result = poster.get_top_card(\n            between=(None, datetime.datetime.now() - datetime.timedelta(hours=12))\n        )\n\n    await ctx.send(f\"```{result}```\")\n\n\nasync def _gkey(ctx, gbs, user_id, note, days=90, cls_=None):\n    bytes_ = int(_GB * float(gbs))\n    cls_ = cls_ or Curator\n\n    with cls_(user_id, KINOBASE) as curator:\n        curator.register_key(\n            bytes_, note, expires_in=datetime.timedelta(days=int(days))\n        )\n\n    await ctx.send(\n        f\"Key of {gbs} [{type(cls_).__name__}] GBs registered for user:{user_id}\"\n    )\n\n\n@bot.command(name=\"topyear\", help=\"Get current year's top posts\")\nasync def topyear(ctx: commands.Context, user: Optional[Member] = None):\n    if user is None:\n        user_ = User.from_discord(ctx.author)\n    else:\n        user_ = User.from_discord(user)\n\n    user_.load()\n\n    result = jackpot.get_yearly_top(user_.id, user_.name)\n    await ctx.send(result)\n\n\n@bot.command(name=\"wrapped\", help=\"Get current year's wrapped\")\nasync def wrapped(ctx: commands.Context, user: Optional[Member] = None):\n    if user is None:\n        avatar_url = ctx.author.avatar_url\n        user = User.from_discord(ctx.author)\n    else:\n        avatar_url = user.avatar_url\n        user = User.from_discord(user)\n\n    user.load()\n\n    try:\n        await wrapped_module.make(ctx, user.id, user.name, avatar_url)\n    except wrapped_module.NoData:\n        await ctx.send(\"Not enough data for this user.\")\n\n\n@bot.command(name=\"wrappedall\", help=\"Get all time wrapped\")\nasync def wrapped_all(ctx: commands.Context, user: Optional[Member] = None):\n    if user is None:\n        avatar_url = ctx.author.avatar_url\n        user = User.from_discord(ctx.author)\n    else:\n        avatar_url = user.avatar_url\n        user = User.from_discord(user)\n\n    user.load()\n\n    await wrapped_module.make(ctx, user.id, user.name, avatar_url, True)\n\n\n@bot.command(name=\"tokens\", help=\"Get tokens free to use\")\nasync def tokens(ctx: commands.Context):\n    await video_module.get_balance(ctx, ctx.author)\n\n\n@bot.command(name=\"gbs\", help=\"Get GBs free to use for curator tasks\")\nasync def gbs(ctx: commands.Context):\n    if str(ctx.author.id) == \"336777437646028802\":\n        return await ctx.send(\"This user has unlimited GBs\")\n\n    with Curator(ctx.author.id, KINOBASE) as curator:\n        size_left = curator.size_left()\n        # expired_size_left = curator.expired_bytes_no_use()\n        # lifetime = curator.lifetime_used_bytes()\n\n    with AnimeCurator(ctx.author.id, KINOBASE) as curator:\n        size_left_anime = curator.size_left()\n\n    await ctx.send(\n        f\"Available GBs: {_pretty_gbs(size_left)}\\n\"\n        f\"Available Anime GBs: {_pretty_gbs(size_left_anime)}\"\n    )\n\n\n@bot.command(name=\"gbsa\", help=\"Get Anime GBs free to use for curator tasks\")\nasync def gbsa(ctx: commands.Context):\n    with AnimeCurator(ctx.author.id, KINOBASE) as curator:\n        size_left = curator.size_left()\n        # expired_size_left = curator.expired_bytes_no_use()\n        # lifetime = curator.lifetime_used_bytes()\n\n    await ctx.send(f\"Available Anime GBs: {_pretty_gbs(size_left)}\")\n\n\nasync def _ask(ctx, timeout=120, return_none_string=\"no\"):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=timeout, check=_check_author(ctx.author)\n        )\n        content = msg.content.strip()\n        if content.lower() == return_none_string:\n            return None\n\n        return content\n    except asyncio.TimeoutError:\n        return None\n\n\ndef _pretty_subtitles_list(subtitles):\n    strs = [\n        f\"**{num}.** {sub.release_info} (score: {sub.score})\"\n        for num, sub in enumerate(subtitles, 1)\n    ]\n    return \"\\n\".join(strs)\n\n\n@bot.command(name=\"getid\", help=\"Get an user ID by search query.\")\n@commands.has_any_role(\"botmin\", \"verifier\")\nasync def getid(ctx: commands.Context, *args):\n    user = User.from_query(\" \".join(args))\n    await ctx.send(f\"{user.name} ID: {user.id}\")\n\n\n@bot.command(name=\"checkfont\", help=\"Check fonts.\")\n@commands.has_any_role(\"botmin\")\nasync def checkfont(ctx: commands.Context, *args):\n    req_str = \" \".join(args)\n\n    from kinobot.frame import FONTS_DICT\n    from .request import Static\n\n    filtered = (\"heavy\", \"bold\", \"hinted\", \"semi\", \"black\")\n    filtered_2 = (\"obliq\", \"italic\")\n    fonts = []\n    for font in FONTS_DICT.keys():\n        if any(fd in font.lower() for fd in filtered) and not any(\n            fd in font.lower() for fd in filtered_2\n        ):\n            fonts.append(font)\n\n    await ctx.send(f\"About to check {len(fonts)} fonts!\")\n\n    for item in fonts:\n        new_req_str = f\"{req_str} --font {item}\"\n        static = Static(bot, ctx, \"en\", \"!req\", *new_req_str.split())\n        await ctx.send(\"-------------\\n\" + item)\n        try:\n            await static.on_demand(embed=False)\n        except:\n            await ctx.send(\"Error\")\n\n\n@bot.command(name=\"maintenance\", help=\"Maintenance.\")\n@commands.has_any_role(\"botmin\", \"sponsor\")\nasync def maintenance(ctx: commands.Context, *args):\n    await ctx.send(\"Checking system status...\")\n\n    def _run():\n        subprocess.run(os.environ[\"MAINTENANCE_COMMAND\"])\n\n    loop = asyncio.get_running_loop()\n    await call_with_typing(ctx, loop, _run)\n\n    await ctx.send(\"Everything seems okay for now.\")\n\n\n@bot.event\nasync def on_command_error(ctx: commands.Context, error):\n    await handle_error(ctx, error)\n\n\n_SHUT_UP_BOI = \"Bra shut up boi ðŸ’¯\"\n_GOAT_RE = re.compile(r\"\\b(yeat|bad bunny|kanye|ye|lizard)\\b\")\n\n\n@bot.listen(\"on_message\")\nasync def shut_up_boi(message):\n    if message.content.startswith(\"!\"):\n        return None\n\n    if (message.author.id in (bot.user.id, \"597554387212304395\")) or message.webhook_id:\n        return None\n\n    if \"840093068711165982\" != str(message.channel.id):\n        return None\n\n    if \"ðŸ’¯\" in message.content:\n        await message.channel.send(_SHUT_UP_BOI, reference=message)\n\n    elif _GOAT_RE.search(message.content.lower()):\n        await message.channel.send(\"ðŸ\", reference=message)\n\n    return None\n\n\ndef _check_botmin(message):\n    return str(message.author.top_role) == \"botmin\"\n\n\ndef run(token: str, prefix: str):\n    bot.command_prefix = prefix\n\n    bot.run(token)\n"}
{"type": "source_file", "path": "kinobot/__init__.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n__author__ = \"Vitiko\"\n\nimport config as _\n"}
{"type": "source_file", "path": "kinobot/cli.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport logging\nimport os\nimport shutil\nfrom typing import Optional\n\nimport click\n\n\nfrom .config import config\nfrom .db import Kinobase\nfrom .discord.admin import run as arun\nfrom .discord.public import run as prun\nfrom .jobs import fb_sched\nfrom .jobs import sched\nfrom .register import EpisodeRegister\nfrom .register import MediaRegister\nfrom .utils import create_needed_folders\nfrom .utils import init_log\nfrom .utils import init_rotating_log\nfrom .infra import _migration\n\nlogger = logging.getLogger(__name__)\n\n\ndef run_alembic():\n    _migration.run_alembic()\n\n\n_BOTS = {\n    \"foreign\": config.discord.token_public_foreign,\n    \"public\": config.discord.token_public,\n    \"test\": config.discord.token_patreon_test,\n}\n\n\n@click.group()\n@click.option(\"--test-db\", is_flag=True, help=\"Use a test database.\")\n@click.option(\"--log\", help=\"Rotating log path.\", metavar=\"PATH\")\n@click.option(\"--log-level\", help=\"Logging level.\", metavar=\"INFO\")\ndef cli(\n    test_db: bool = False, log: Optional[str] = None, log_level: Optional[str] = None\n):\n    \"Aesthetically perfectionist bot for cinephiles.\"\n    init_log(level=log_level or \"INFO\")\n    run_alembic()\n\n    if log is not None:\n        init_rotating_log(log, level=log_level or \"INFO\")\n\n    if test_db:\n        new_db = config.db + \".save\"\n        if not os.path.isfile(new_db):\n            logger.info(\"Created test database: %s\", new_db)\n            shutil.copy(config.db, new_db)\n\n        Kinobase.__database__ = new_db\n\n    logger.warning(\"Active database: %s\", Kinobase.__database__)\n\n    create_needed_folders()\n\n\n@click.command()\ndef migration():\n    run_alembic()\n\n\n@click.command()\n@click.option(\"--prefix\", default=\"!\", help=\"Command prefix.\")\n@click.option(\"--token\", help=\"Server token.\")\ndef admin(prefix: str, token: Optional[str] = None):\n    \"Run the admin tasks Discord bot.\"\n    arun(token or config.discord.token_admin, prefix)\n\n\n@click.command()\n@click.option(\"--prefix\", default=None, help=\"Bot's prefix\")\n@click.option(\"--name\", default=\"test\", help=\"Bot's name (public, test, foreign)\")\ndef public(name: str, prefix: Optional[str] = None):\n    \"Run the public Discord bot.\"\n    token = _BOTS[name]\n    logger.debug(\"Starting %s bot\", name)\n    prun(token, token == config.discord.token_public_foreign, custom_prefix=prefix)\n\n\n@click.command()\n@click.option(\"--all-media\", is_flag=True, help=\"Add media without subtitles.\")\ndef register(all_media: bool = False):\n    \"Register media to the database.\"\n    for media in (MediaRegister, EpisodeRegister):\n        handler = media(only_w_subtitles=not all_media)\n        handler.load_new_and_deleted()\n        handler.handle()\n\n\n@click.command()\ndef bot():\n    \"Run the Facebook bot.\"\n    sched.start()\n\n\n@click.command()\ndef fb():\n    \"Run the Facebook loop.\"\n    fb_sched.start()\n\n\n@click.command()\n@click.option(\"--config\", default=None, help=\"Server yaml config\")\ndef server(config: Optional[str] = None):\n    import uvicorn\n\n    from .server import builders\n\n    config_ = builders.config.load(config)\n    rest_config = config_.rest\n    app = builders.get_app(config_)\n\n    uvicorn.run(app, port=rest_config.port, host=rest_config.host)\n"}
{"type": "source_file", "path": "kinobot/config.py", "content": "import os\n\nfrom dynaconf import Dynaconf\n\n\n_CONFIG = os.environ.get(\"YAML_CONFIG\", \"config.yml\")\n\nprint(f\"YAML config: {_CONFIG} (exists: {os.path.exists(_CONFIG or '')})\")\n\nconfig = Dynaconf(envvar_prefix=\"KINOBOT\", settings_files=[_CONFIG])\nsettings = config\n\nPATH = _CONFIG\n"}
{"type": "source_file", "path": "kinobot/discord/chamber.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport asyncio\nimport copy\nimport datetime\nimport logging\nimport re\n\nfrom discord import File, Message\nfrom discord.ext import commands\n\nfrom kinobot.config import config\n\nfrom ..db import Execute\nfrom ..exceptions import KinoException\nfrom ..exceptions import KinoUnwantedException\nfrom ..exceptions import SubtitlesNotFound\nfrom ..exceptions import TempUnavailable\nfrom ..request import get_cls\nfrom ..user import User\nfrom ..utils import handle_general_exception\nfrom ..utils import send_webhook\nfrom .common import get_req_id_from_ctx\nfrom .request_trace import trace_checks\n\n_GOOD_BAD_NEUTRAL_EDIT = (\"ðŸ‡¼\", \"ðŸ‡±\", \"ðŸ§Š\", \"âœï¸\")\n_ICE_DELAY = datetime.timedelta(days=1)\n\n\nlogger = logging.getLogger(__name__)\n\n_CONTENT_RE = re.compile(r\"(?P<title>.*?) (?P<operator>not in|in) content\", re.DOTALL)\n_USER_RE = re.compile(r\"(?P<title>.*?) (?P<operator>not in|in) user\", re.DOTALL)\n\n\nclass Chamber:\n    \"Class for the verification chamber used in the admin's Discord server.\"\n\n    def __init__(\n        self,\n        bot: commands.Bot,\n        ctx: commands.Context,\n        newer_than=None,\n        exclude_if_contains=None,\n        no_multiple_images=False,\n        private=False,\n    ):\n        self.bot = bot\n        self.ctx = ctx\n        self._newer_than = newer_than\n        self._exclude_if_contains = exclude_if_contains\n        self._user_roles = [role.name for role in ctx.author.roles]\n        self._private = private\n        self._user_id = str(ctx.author.id)  # type: ignore\n        self._identifier = get_req_id_from_ctx(ctx)\n        self._req_cls = get_cls(self._identifier)\n        self._req = None\n        self._seen_ids = set()\n        self._images = []\n        self._rejected = []\n        self._verified = []\n        self._iced = []\n        self._edited = []\n        self._no_multiple_images = no_multiple_images\n        self._started = datetime.datetime.now()\n\n        logger.debug(\"Req class: %s\", self._req_cls)\n\n    async def start(self):\n        \"Start the chamber loop.\"\n\n        await self.ctx.send(\n            f\"newer than={self._newer_than}; exclude={self._exclude_if_contains}\"\n        )\n\n        exc_count = 0\n\n        while True:\n            if exc_count > 500:\n                await self.ctx.send(\"Exception count exceeded. Breaking loop.\")\n                break\n\n            if not await self._loaded_req():\n                exc_count += 1\n                continue\n\n            exc_count = 0\n\n            await self._send_info()\n\n            try:\n                await self._verdict()\n            except asyncio.TimeoutError:\n                break\n\n            # await self.ctx.send(\n            #    'Continuing the chamber. Type **\"q\"** after a request is shown to quit the chamber'\n            # )\n            # if not await self._continue():\n            #    break\n\n        await self.ctx.send(\"Chamber loop finished\")\n\n        self._send_webhook()\n\n    async def _loaded_req(self) -> bool:\n        \"\"\"\n        Load the request and the handler. Send the exception info if the\n        handler fails.\n\n        raises exceptions.NothingFound\n        \"\"\"\n        self._req = self._req_cls.random_from_queue(verified=False)\n\n        if self._newer_than is not None:\n            now_ = datetime.datetime.now()\n            if (now_ - self._req.added) > self._newer_than:\n                logger.debug(\"Too old request\")\n                return False\n\n        if self._exclude_if_contains is not None:\n            user = User(id=self._req.user_id)\n            user.load(register=True)\n            for exclude in self._exclude_if_contains:\n                if exclude in self._req.comment + \" \" + user.name:\n                    logger.debug(\"Excluding: %s\", exclude)\n                    return False\n\n        if str(self._req.user.id) == self._user_id:\n            logger.debug(\"Ignoring own request\")\n            return False\n\n        if self._req.id in self._seen_ids:\n            return False\n\n        self._seen_ids.add(self._req.id)\n\n        iced = await self._handle_iced()\n        if iced is False:\n            return False\n\n        if self._req.find_dupe(verified=True):\n            await self.ctx.send(f\"Ignoring potential dupe post: {self._req.comment}\")\n            self._req.mark_as_used()\n            return False\n\n        return await self._process_req()\n\n    async def _handle_iced(self):\n        assert self._req is not None\n\n        ices = self._req.get_ices()\n\n        if ices:\n            logger.debug(\"Ices: %s\", ices)\n            if len(ices) > 5:\n                await self.ctx.send(\n                    f\"`{self._req.comment}` has been already iced {len(ices)} times. Marking as used.\"\n                )\n                self._req.mark_as_used()\n                return False\n\n            # last_ice = ices[-1]\n            # if last_ice[\"ago\"] > _ICE_DELAY:\n            #    await self.ctx.send(\n            #        f\"Skipping recently iced request: {last_ice} ({len(ices)} ices) [Ice delay: {_ICE_DELAY}]\"\n            #    )\n            #    return False\n        else:\n            logger.debug(\"This request doesn't have any ices registered\")\n\n        return True\n\n    def _is_multiple(self, handler):\n        count = 0\n        for request in handler.items:\n            new_r = copy.deepcopy(request)\n            new_r.compute_brackets()\n\n            for _ in new_r.brackets:\n                count += 1\n\n        return count > 4 and self._no_multiple_images\n\n    async def _process_req(self, raise_kino_exception=False):\n        loop = asyncio.get_running_loop()\n\n        async with self.ctx.typing():\n            try:\n                handler = await loop.run_in_executor(None, self._req.get_handler)\n                if self._is_multiple(handler):\n                    await self.ctx.send(\"Avoiding multiple image request\")\n                    return False\n\n                self._images = await loop.run_in_executor(None, handler.get)\n\n                # await trace_checks(self.ctx, handler.make_trace())\n\n                risk = self._req.facebook_risk()\n\n                if risk is not None:\n                    await self.ctx.send(\n                        f\"WARNING: Facebook risk: `{risk}`.\\n\\nPLEASE BE CAREFUL! \"\n                        \"DON'T GET THE PAGE BANNED!\"\n                    )\n\n                return True\n\n            except KinoUnwantedException as error:\n                await self.ctx.send(self._format_exc(error))\n                self._req.mark_as_used()\n\n            except (SubtitlesNotFound, FileNotFoundError):\n                await self.ctx.send(\"Possible data loss related request. Ignoring.\")\n\n            except KinoException as error:\n                await self.ctx.send(self._format_exc(error))\n\n                if raise_kino_exception:\n                    raise\n\n                self._req.mark_as_used()\n\n            except Exception as error:  # Fatal\n                handle_general_exception(error)\n                await self.ctx.send(\n                    f\"**Fatal!!!** {self._format_exc(error)}. \"\n                    \"**Marking as used. REPORT ADMIN if you see this error too often!!!**\"\n                )\n\n                self._req.mark_as_used()\n\n            return False\n\n    async def _send_info(self):\n        \"Send the request metadata and the images.\"\n        user = User(id=self._req.user_id)\n        user.load(register=True)\n\n        message = None\n        # await self.ctx.send(\n        #    f\"**{user.name} ({self._req.time_ago})**: {self._req.pretty_title}\"[:1999]\n        # )\n        await self.ctx.send(\n            self._req.facebook_pretty_title + \"\\n\" + self._req.handler_title\n        )\n\n        for image in self._images:\n            logger.info(\"Sending image: %s\", image)\n            message = await self.ctx.send(file=File(image))\n\n        assert [await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT]\n\n    def _check_recurring_user(self):\n        if self._verified.count(self._req.user.name) >= 2:\n            logger.debug(\"%s has already two verified requests\", self._req.user)\n            return True\n\n        return False\n\n    async def _multi_wait(self):\n        def _check_msg(m):\n            return m.content.startswith(\"exit\") and str(m.author.id) == str(\n                self._user_id\n            )\n\n        try:\n            t_1 = asyncio.create_task(\n                self.bot.wait_for(\"reaction_add\", timeout=300, check=self._check_react)\n            )\n            t_2 = asyncio.create_task(\n                self.bot.wait_for(\"message\", timeout=300, check=_check_msg)\n            )\n\n            done, pending = await asyncio.wait(\n                [t_1, t_2], return_when=asyncio.FIRST_COMPLETED\n            )\n\n            for task in pending:\n                task.cancel()\n\n            return done.pop().result()\n        except asyncio.TimeoutError:\n            await self.ctx.send(\n                \"No reaction or message received within the time limit.\"\n            )\n\n    async def _verdict(self):\n        \"raises asyncio.TimeoutError\"\n        response = await self._multi_wait()\n        if response is None:\n            raise asyncio.TimeoutError\n\n        if isinstance(response, Message) and str(response.content) == \"exit\":\n            raise asyncio.TimeoutError\n\n        #        reaction, user = await self.bot.wait_for(\n        #          \"reaction_add\", timeout=300, check=self._check_react\n        #       )\n        reaction, user = response  # type: ignore\n        assert user\n\n        if str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[0]):\n            if str(self._req.user.id) == self._user_id:\n                await self.ctx.send(\"You can't verify your own request.\")\n            else:\n                self._req.verify()\n                self._log_user(verified=True)\n                await self._take_reason(True)\n        #       await self.ctx.send(\"Verified.\")\n\n        elif str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[1]):\n            self._req.mark_as_used()\n            self._log_user()\n            await self._take_reason(False)\n            await self.ctx.send(\"Marked as used.\")\n\n        elif str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[3]):\n            if not await self._edit_loop():\n                pass\n            else:\n                await self._verdict()\n        else:\n            self._req.register_ice()\n            self._log_user(iced=True)\n            await self.ctx.send(\"Ignored.\")\n\n    async def _take_reason(self, verified: bool):\n        self._req.register_verifications([self.ctx.author.id], verified, \"automatic\")\n        return\n\n        await self.ctx.send(\n            \"Please explain shortly why:\\n\"\n            \"(The bot will take the FIRST MESSAGE PREFIXED WITH 'bc' or 'because').\"\n        )\n        try:\n            message = await self.bot.wait_for(\n                \"message\", timeout=300, check=self._check_reason_msg(self.ctx.author)\n            )\n            reason = str(message.content).lstrip(\"bc\").lstrip(\"because\")\n            self._req.register_verifications([self.ctx.author.id], verified, reason)\n\n            return True\n\n        except asyncio.TimeoutError:\n            return False\n\n    def _check_msg_author(self, author):\n        return lambda message: str(message.author.id) == str(self.ctx.author.id)\n\n    def _check_exit_msg(self, author):\n        return lambda message: str(message.content).startswith(\"exit\") and str(\n            message.author.id\n        ) == str(self.ctx.author.id)\n\n    def _check_reason_msg(self, author):\n        return lambda message: str(message.content).startswith(\n            (\"bc\", \"because\")\n        ) and str(message.author.id) == str(self.ctx.author.id)\n\n    async def _edit_loop(self):\n        while True:\n            edited = await self._edit_req()\n            if not edited:\n                return False\n\n            # Send the request\n            try:\n                processed = await self._process_req(raise_kino_exception=True)\n            except KinoException:\n                continue\n            else:\n                if not processed:\n                    return False\n                else:\n                    await self._send_info()\n                    return True\n\n    async def _edit_req(self):\n        try:\n            message = await self.bot.wait_for(\n                \"message\", timeout=300, check=_check_msg_author(self.ctx.author)\n            )\n\n            if message.content.lower() == \"no\":\n                return False\n\n            if message.content.lower() == \"reset\":\n                self._req.reset_global_flags()\n                self._req.update()\n                return True\n\n            if self._req.edited:\n                self._req.reset_append()\n\n            self._req.append_text(str(message.content))\n\n            return True\n\n        except asyncio.TimeoutError:\n            return False\n\n    async def _continue(self) -> bool:\n        queued = Execute().queued_requets(table=self._req_cls.table)\n        message = await self.ctx.send(\n            f\"Continue in the chamber of {self._req_cls.table}? ({queued} verified).\"\n        )\n        assert [\n            await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT[:2]\n        ]\n\n        try:\n            reaction, user = await self.bot.wait_for(\n                \"reaction_add\", timeout=30, check=self._check_react\n            )\n            assert user\n\n            if str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[0]):\n                return True\n\n            await self.ctx.send(\"Bye.\")\n            return False\n\n        except asyncio.TimeoutError:\n            await self.ctx.send(\"Timeout. Exiting...\")\n            return False\n\n    def _check_react(self, reaction, user):\n        assert reaction\n        return user == self.ctx.author\n\n    def _log_user(self, verified: bool = False, edited=False, iced=False):\n        user = User(id=self._req.user_id)  # Temporary\n        user.load(register=True)\n\n        if iced:\n            self._iced.append(user.name)\n            return None\n\n        if verified:\n            self._verified.append(user.name)\n        else:\n            self._rejected.append(user.name)\n\n        if edited:\n            self._edited.append(user.name)\n\n    def _verdict_author(self):\n        return self.ctx.author.display_name\n\n    def _announce_meta(self):\n        ended = datetime.datetime.now()\n        elapsed = (ended - self._started).total_seconds() / 60\n\n        elapsed_str = f\"{elapsed:.2f} minutes\"\n\n        return (\n            f\"newer than: `{self._newer_than}`; exclude: `{self._exclude_if_contains}`; \"\n            f\"multiple images: {not self._no_multiple_images}; unique IDs: {self.unique_count}\\nElapsed time: {elapsed_str}\"\n        )\n\n    def _send_webhook(self):\n        if self._private:\n            return None\n\n        msgs = [f\"`{self._verdict_author()}` verdict. Authors with:\"]\n\n        if self._verified:\n            msgs.append(f\"**Verified** requests: `{_user_str_list(self._verified)}`\")\n\n        if self._rejected:\n            msgs.append(f\"**Rejected** requests: `{_user_str_list(self._rejected)}`\")\n\n        if self._iced:\n            msgs.append(f\"**Iced (skipped)** requests: `{_user_str_list(self._iced)}`\")\n\n        msgs.append(self._announce_meta())\n\n        if len(msgs) > 1:\n            send_webhook(config.webhooks.announcer, \"\\n\\n\".join(msgs))\n\n    @property\n    def unique_count(self):\n        return len(self._seen_ids)\n\n    @staticmethod\n    def _format_exc(error: Exception) -> str:\n        return f\"{type(error).__name__} raised: {error}\"\n\n\nclass _FakeChamber(Chamber):\n    async def _process_req(self, raise_kino_exception=False):\n        return True\n\n    async def _send_info(self):\n        message = await self.ctx.send(\"This is a fake request.\")\n        assert [await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT]\n\n\n# class Chamber(_FakeChamber):\n#    pass\n\n\nclass CollaborativeChamber(Chamber):\n    def __init__(self, bot, ctx, members):\n        super().__init__(bot, ctx)\n        self._members = members\n        self._first_req = True\n\n    @classmethod\n    async def from_bot(cls, bot, ctx, partners, roles=(\"verifier\", \"botmin\")):\n        if not partners:\n            raise KinoException(\n                f\"You need to tag at least one verifier partner (e.g. !chamber @dummy @dummy_2)\"\n            )\n\n        members = [ctx.author]\n\n        for partner in partners:\n            partner = partner.strip()\n\n            if not partner.startswith(\"<@\"):\n                raise KinoException(f\"Invalid partner: {partner}\")\n\n            id_ = partner.lstrip(\"<@\").rstrip(\">\")\n\n            member = await ctx.message.guild.fetch_member(id_)\n\n            if not any(str(role.name) in roles for role in member.roles):\n                raise KinoException(f\"{partner} isn't allowed to enter the chamber\")\n\n            if str(member.id) in (str(mem.id) for mem in members):\n                raise KinoException(f\"You can't add duplicate verifiers.\")\n\n            members.append(member)\n\n        return cls(bot, ctx, members)\n\n    async def _loaded_req(self) -> bool:\n        self._req = self._req_cls.random_from_queue(verified=False)\n\n        self._req.user.load()\n\n        if self._req.id in self._seen_ids:\n            return False\n\n        self._seen_ids.add(self._req.id)\n\n        # if str(self._req.user.id) in self._member_ids():\n        #    await self.ctx.send(\n        #        f\"Ignoring **{self._req.pretty_title}** as the author is in the chamber.\"\n        #    )\n        #    return False\n\n        iced = self._handle_iced()\n        if iced is False:\n            return False\n\n        if self._req.find_dupe(verified=True):\n            await self.ctx.send(\n                f\"Ignoring potential dupe post: **{self._req.comment}**\"\n            )\n            return False\n\n        return await self._process_req()\n\n    async def _continue(self) -> bool:\n        queued = Execute().queued_requets(table=self._req_cls.table)\n        message = await self.ctx.send(\n            f\"{self._mentions_str()} Continue in the chamber of {self._req_cls.table}? \"\n            f\"({queued} verified). Absolute majority!\"\n        )\n        assert [\n            await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT[:2]\n        ]\n\n        collected_reacts = await self._collect_reacts()\n\n        min_ = len(self._members) / 2\n        return collected_reacts.count(_GOOD_BAD_NEUTRAL_EDIT[0]) > min_\n\n    async def _collect_reacts(self, timeout=300):\n        collected_reacts = []\n        user_ids = set()\n\n        while True:\n            try:\n                reaction, user = await self.bot.wait_for(\n                    \"reaction_add\", timeout=timeout, check=self._check_react\n                )\n\n                if str(user.id) in user_ids:\n                    continue\n\n                user_ids.add(str(user.id))\n                collected_reacts.append(str(reaction))\n\n                if len(collected_reacts) >= len(self._members):\n                    return collected_reacts\n\n            except asyncio.TimeoutError:\n                await self.ctx.send(\"Timeout!\")\n                return []\n\n    async def _verdict(self):\n        if self._first_req:\n            await self.ctx.send(\n                f\"{self._mentions_str()} you got 3 minutes to react to the last image. React \"\n                \"with the ice cube to deal with the request later; react with \"\n                \"the pencil to append flags to the request. Absolute majority!\"\n            )\n            self._first_req = False\n        else:\n            await self.ctx.send(\n                f\"{self._mentions_str()} you got 3 minutes to react to the last image.\"\n            )\n\n        collected_reacts = await self._collect_reacts()\n\n        min_ = len(self._members) / 2\n\n        verified = collected_reacts.count(_GOOD_BAD_NEUTRAL_EDIT[0]) > min_\n        rejected = collected_reacts.count(_GOOD_BAD_NEUTRAL_EDIT[1]) > min_\n        to_edit = collected_reacts.count(_GOOD_BAD_NEUTRAL_EDIT[3]) > min_\n\n        if verified:\n            self._req.verify()\n            self._log_user(verified=True)\n            await self._take_reason(True)\n            await self.ctx.send(\"Verified.\")\n\n        elif rejected:\n            self._req.mark_as_used()\n            self._log_user()\n            await self._take_reason(False)\n            await self.ctx.send(\"Marked as used.\")\n\n        elif to_edit:\n            if not await self._edit_loop():\n                await self.ctx.send(\"Ignored\")\n            else:\n                await self._verdict()\n        else:\n            self._req.register_ice()\n            self._log_user(iced=True)\n            await self.ctx.send(\"Ignored.\")\n\n    async def _edit_req(self):\n        await self.ctx.send(\n            \"Type the flags to append. Type 'no' to cancel. Type 'reset' to reset all flags set. \"\n            \"(The bot will take the FIRST MESSAGE).\"\n        )\n        try:\n            message = await self.bot.wait_for(\n                \"message\", timeout=300, check=self._check_msg_author(self.ctx.author)\n            )\n\n            if message.content.lower() == \"no\":\n                return False\n\n            if message.content.lower() == \"reset\":\n                self._req.reset_global_flags()\n                self._req.update()\n                return True\n\n            if self._req.edited:\n                self._req.reset_append()\n\n            self._req.append_text(str(message.content))\n\n            return True\n\n        except asyncio.TimeoutError:\n            return False\n\n    async def _take_reason(self, verified: bool):\n        await self.ctx.send(\n            \"Please explain shortly why:\\n\"\n            \"(The bot will take the FIRST MESSAGE PREFIXED WITH 'bc' or 'because').\"\n        )\n        try:\n            message = await self.bot.wait_for(\n                \"message\", timeout=300, check=self._check_reason_msg(self.ctx.author)\n            )\n            reason = str(message.content).lstrip(\"bc\").lstrip(\"because\")\n            self._req.register_verifications(self._member_ids(), verified, reason)\n\n            return True\n\n        except asyncio.TimeoutError:\n            return False\n\n    def _check_react(self, reaction, user):\n        return (\n            str(user.id) in self._member_ids()\n            and str(reaction) in _GOOD_BAD_NEUTRAL_EDIT\n        )\n\n    def _check_msg_author(self, author):\n        return lambda message: str(message.author.id) in self._member_ids()\n\n    def _check_reason_msg(self, author):\n        return (\n            lambda message: str(message.content).startswith((\"bc\", \"because\"))\n            and str(message.author.id) in self._member_ids()\n        )\n\n    def _member_ids(self):\n        return (str(member.id) for member in self._members)\n\n    def _mentions_str(self):\n        return \" \".join(f\"<@{member.id}>\" for member in self._members)\n\n    def _verdict_author(self):\n        return \", \".join(member.display_name for member in self._members)\n\n\ndef _user_str_list(user_list):\n    user_list = {user: user_list.count(user) for user in user_list}\n    user_list = {\n        k: v\n        for k, v in sorted(user_list.items(), key=lambda item: item[1], reverse=True)\n    }\n    str_list = [f\"{key} ({val})\" for key, val in user_list.items()]\n    return \", \".join(str_list)\n    # return \", \".join(list(dict.fromkeys(user_list)))\n\n\ndef _check_msg_author(author):\n    return lambda message: message.author == author\n"}
{"type": "source_file", "path": "kinobot/discord/anime.py", "content": "import asyncio\nimport logging\nimport os\nimport tempfile\nfrom typing import List\n\nfrom discord.ext import commands\n\nfrom kinobot.config import settings\nfrom kinobot.misc import ab\nfrom kinobot.misc import anime\n\nfrom . import utils\nfrom .extras.curator_user import AnimeCurator\n\nlogger = logging.getLogger(__name__)\n\n\ndef _update_anime():\n    anime.handle_downloaded()\n    anime.scan_subs()\n\n\nasync def update(bot, ctx):\n    loop = asyncio.get_event_loop()\n    await utils.call_with_typing(ctx, loop, _update_anime)\n    await ctx.send(\"Done.\")\n\n\nasync def add(bot, ctx: commands.Context, *args):\n    with AnimeCurator(ctx.author.id, settings.db) as curator:\n        size_left = curator.size_left()\n\n    query = \" \".join(args)\n    client = ab.Client(settings.anime.username, settings.anime.passkey)\n    loop = asyncio.get_event_loop()\n    items = await utils.call_with_typing(\n        ctx, loop, client.search, query\n    )  # type: List[ab.AnimeSeries]\n    if not items:\n        await ctx.send(\"Nothing found.\")\n        return\n\n    item = await utils.paginated_list(\n        bot, ctx, \"Choose the group\", items, lambda i: i.pretty_title\n    )\n    if item is None:\n        return await ctx.send(\"Bye.\")\n\n    series_name = item.series_name\n\n    filtered = list(filter(lambda p: \"m2ts\" not in p.property_.lower(), item.torrents))\n\n    item = await utils.paginated_list(\n        bot,\n        ctx,\n        \"Now choose what item to import\",\n        filtered,\n        lambda i: i.pretty_title,\n    )\n    if not item:\n        return await ctx.send(\"Bye.\")\n\n    if item.size > size_left:\n        return await ctx.send(\"Not enough GBs to perform this.\")\n\n    if not await utils.ask_to_confirm(bot, ctx):\n        return await ctx.send(\"Bye.\")\n\n    downloaded_t = os.path.join(tempfile.gettempdir(), f\"{item.id}.torrent\")\n\n    await utils.call_with_typing(ctx, loop, client.download, item.link, downloaded_t)\n    del_client = anime.Client.from_config()\n    torrent_id = await utils.call_with_typing(\n        ctx, loop, del_client.add_torrent_file, downloaded_t\n    )\n    anime.register_torrent(torrent_id, series_name)\n\n    with AnimeCurator(ctx.author.id, settings.db) as curator:\n        curator.register_addition(item.size)\n\n    await ctx.send(\"Added to queue. Let's wait.\")\n"}
{"type": "source_file", "path": "kinobot/db.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport logging\nimport sqlite3\nfrom typing import List, Optional, Sequence\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import scoped_session\nfrom sqlalchemy.orm import sessionmaker\n\nfrom kinobot import orm\n\nfrom .constants import KINOBASE\n\nlogger = logging.getLogger(__name__)\n\n\nsession = scoped_session(sessionmaker())\n\nengine = create_engine(f\"sqlite:///{KINOBASE}\")\norm.Base.metadata.create_all(bind=engine)\nsession.configure(bind=engine)\n\n\nclass Kinobase:\n    \"Base class for Kinobot's database interaction.\"\n\n    __database__ = KINOBASE\n    __insertables__ = ()\n\n    table = \"movies\"\n\n    def _execute_many(self, sql: str, seq_of_params: Sequence[tuple]):\n        with sqlite3.connect(self.__database__) as conn:\n            conn.execute(\"PRAGMA journal_mode=WAL\")\n            conn.set_trace_callback(logger.debug)\n            conn.executemany(sql, seq_of_params)\n\n    def _fetch(self, sql: str, params: tuple) -> tuple:\n        with sqlite3.connect(self.__database__) as conn:\n            conn.execute(\"PRAGMA journal_mode=WAL\")\n            conn.set_trace_callback(logger.debug)\n            return conn.execute(sql, params).fetchone()\n\n    def _execute_sql(self, sql: str, params: tuple):\n        logger.debug(\"Database path: %s\", self.__database__)\n        with sqlite3.connect(self.__database__) as conn:\n            conn.execute(\"PRAGMA journal_mode=WAL\")\n            conn.set_trace_callback(logger.debug)\n            conn.execute(sql, params)\n\n    def _db_command_to_dict(\n        self,\n        sql: str,\n        params: tuple = (),\n    ) -> List[dict]:\n        logger.debug(\"Database path: %s\", self.__database__)\n        return sql_to_dict(self.__database__, sql, params)\n\n    def _insert(self):\n        self._execute_sql(self._get_insert_command(), self._get_sqlite_tuple())\n\n    def _update(self, id_):\n        command = (\n            f\"update {self.table} set {'=?, '.join(self.__insertables__)}=? where id=?\"\n        )\n        params = self._get_sqlite_tuple() + (id_,)\n        self._execute_sql(command, params)\n\n    def _get_insert_command(self) -> str:\n        columns = \",\".join(self.__insertables__)\n        placeholders = \",\".join(\"?\" * len(self.__insertables__))\n        gen = f\"insert or ignore into {self.table} ({columns}) values ({placeholders})\"\n        logger.debug(\"Generated insert command: %s\", gen)\n        return gen\n\n    def _get_sqlite_tuple(self) -> tuple:\n        return tuple(getattr(self, attr) for attr in self.__insertables__)\n\n    def _sql_to_dict(self, sql: str, params: tuple = ()):\n        with sqlite3.connect(self.__database__) as conn:\n            conn.execute(\"PRAGMA journal_mode=WAL\")\n            conn.set_trace_callback(logger.debug)\n            conn.row_factory = sqlite3.Row\n\n            conn_ = conn.cursor()\n\n            conn_.execute(sql, params)\n            logger.debug(\"Params: %s\", params)\n\n            fetched = conn_.fetchall()\n\n            return [dict(row) for row in fetched]\n\n    def _set_attrs_to_values(self, item: dict):\n        for key, val in item.items():\n            # logger.debug(\"%s: %s\", key, val)\n            if hasattr(self, key):\n                setattr(self, key, val)\n\n\nclass Execute(Kinobase):\n    \"Class for predefined database tasks.\"\n\n    def reset_limits(self):\n        \"Reset role limits for users IDs.\"\n        self._execute_sql(\"update role_limits set hits=1\", ())\n\n    def queued_requets(\n        self, verified: bool = True, table: str = \"requests\", tag=None\n    ) -> int:\n        if tag is not None:\n            req = self._fetch(\n                f\"select count(*) from {table} left join request_tag on requests.id=request_tag.request_id where used=0 and verified=? and request_tag.name=?\",\n                (verified, tag),\n            )[0]\n            return req\n\n        sql = f\"select count(id) from {table} where used='0' and verified=?\"\n        return self._fetch(sql, (verified,))[0]\n\n\ndef sql_to_dict(\n    database: Optional[str],\n    sql: str,\n    params: tuple = (),\n) -> List[dict]:\n    \"\"\"Convert a SQL query to a list of dictionaries.\n\n    :param sql:\n    :type sql: str\n    :param params:\n    :type params: tuple\n    :rtype: List[dict]\n    \"\"\"\n    database = database or KINOBASE\n    with sqlite3.connect(database) as conn:\n        conn.execute(\"PRAGMA journal_mode=WAL\")\n        conn.set_trace_callback(logger.debug)\n        conn.row_factory = sqlite3.Row\n\n        conn_ = conn.cursor()\n\n        conn_.execute(sql, params)\n        logger.debug(\"Params: %s\", params)\n\n        fetched = conn_.fetchall()\n\n        return [dict(row) for row in fetched]\n"}
{"type": "source_file", "path": "kinobot/discord/__init__.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n"}
{"type": "source_file", "path": "kinobot/instagram/config.py", "content": "import os\nfrom typing import Dict, List\n\nfrom dynaconf import Dynaconf\nfrom pydantic import BaseModel\nimport yaml\n\nsettings = Dynaconf(\n    envvar_prefix=\"KINOBOT_IG\", settings_files=[os.environ.get(\"KINOBOT_IG_CONFIG\")]\n)\n\n\nclass Publisher(BaseModel):\n    enabled: bool = False\n    handler: str\n    constructor: Dict\n\n\nclass Config(BaseModel):\n    db_url: str\n    ig_client: Dict\n    client: Dict\n    publishers: List[Publisher] = []\n\n    class Config:\n        orm_mode = True\n\n    @classmethod\n    def from_yaml(cls, path):\n        with open(path, \"r\") as f:\n            data = yaml.safe_load(f.read())\n\n        return cls.parse_obj(data)\n\n    @classmethod\n    def default_factory(cls):\n        return cls.from_orm(settings)\n"}
{"type": "source_file", "path": "kinobot/exceptions.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nfrom discord import Embed\n\n\nclass KinoException(Exception):\n    'Base class for \"public\" exceptions.'\n\n    @property\n    def embed(self) -> Embed:\n        \"\"\"Discord embed containing the exception info.\n\n        :rtype: Embed\n        \"\"\"\n        title = f\"{type(self).__name__} exception raised!\"\n        return Embed(title=title, description=str(self)[:200])\n\n\nclass KinoUnwantedException(KinoException):\n    \"Base class for exceptions that require attention.\"\n\n\nclass SubtitlesNotFound(KinoUnwantedException):\n    pass\n\n\nclass TempUnavailable(KinoException):\n    pass\n\n\nclass QuoteNotFound(KinoException):\n    pass\n\n\nclass MovieNotFound(KinoException):\n    pass\n\n\nclass EpisodeNotFound(KinoException):\n    pass\n\n\nclass FailedQuery(KinoException):\n    pass\n\n\nclass DuplicateRequest(KinoException):\n    pass\n\n\nclass OffensiveWord(KinoException):\n    pass\n\n\nclass RestingMovie(KinoException):\n    pass\n\n\nclass TooShortQuery(KinoException):\n    pass\n\n\nclass BadKeywords(KinoException):\n    pass\n\n\nclass TooLongRequest(KinoException):\n    pass\n\n\nclass InvalidRequest(KinoException):\n    pass\n\n\nclass DifferentSource(KinoException):\n    pass\n\n\nclass NotAvailableForCommand(KinoException):\n    pass\n\n\nclass InconsistentSubtitleChain(KinoException):\n    pass\n\n\nclass ChainRequest(KinoException):\n    pass\n\n\nclass NotEnoughColors(KinoException):\n    pass\n\n\nclass NSFWContent(KinoException):\n    pass\n\n\nclass InexistentTimestamp(KinoException):\n    pass\n\n\nclass ImageNotFound(KinoException):\n    pass\n\n\nclass NothingFound(KinoException):\n    pass\n\n\nclass LimitExceeded(KinoException):\n    pass\n\n\nclass DiscordAccountNotLinked(KinoException):\n    pass\n\n\nclass RecentPostFound(KinoUnwantedException):\n    pass\n\n\nclass FrameTimeoutExpired(KinoUnwantedException):\n    pass\n"}
{"type": "source_file", "path": "kinobot/discord/public.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\n# Discord bot for the official Kinobot server.\n\nimport asyncio\nimport logging\nfrom operator import attrgetter\nfrom typing import Optional\n\nfrom discord import Embed\nfrom discord import Member\nfrom discord.ext import commands\nfrom tabulate import tabulate\n\nimport kinobot.exceptions as exceptions\n\nfrom ..constants import API_HELP_EMBED\nfrom ..constants import DISCORD_BOT_INVITE\nfrom ..constants import DISCORD_INVITE\nfrom ..media import Movie\nfrom ..request import ClassicRequest\nfrom ..request import PaletteRequest\nfrom ..request import ParallelRequest\nfrom ..request import SwapRequest\nfrom ..search import CategorySearch\nfrom ..search import CountrySearch\nfrom ..search import GenreSearch\nfrom ..search import MediaFuzzySearch\nfrom ..search import PersonSearch\nfrom ..search import QuoteSearch\nfrom ..search import RequestSearch\nfrom ..search import SongSearch\nfrom ..top import TopMovies\nfrom ..user import User\nfrom ..utils import get_args_and_clean\nfrom .common import get_req_id_from_ctx\nfrom .common import handle_error\nfrom .request import Static\nfrom .request import StaticForeign\n\nlogging.getLogger(\"discord\").setLevel(logging.INFO)\n\nlogger = logging.getLogger(__name__)\n\nbot = commands.Bot(command_prefix=\"!\")\n\n\nclass OnDemand(commands.Cog, name=\"On-demand requests\"):\n    \"\"\"On-demand = executed instantly.\n\n    Every user has three requests per day (one for GIFs). Patrons have\n    unlimited requests.\"\"\"\n\n    static_handler = Static\n\n    @commands.cooldown(1, 5, commands.BucketType.guild)\n    @commands.command(name=\"req\", **ClassicRequest.discord_help)\n    async def request(self, ctx: commands.Context, *args):\n        await self._handle_static(ctx, \"!req\", *args)\n\n    @commands.cooldown(1, 5, commands.BucketType.guild)\n    @commands.command(name=\"parallel\", **ParallelRequest.discord_help)\n    async def parallel(self, ctx: commands.Context, *args):\n        await self._handle_static(ctx, \"!parallel\", *args)\n\n    @commands.cooldown(1, 5, commands.BucketType.guild)\n    @commands.command(name=\"palette\", **PaletteRequest.discord_help)\n    async def palette(self, ctx: commands.Context, *args):\n        await self._handle_static(ctx, \"!palette\", *args)\n\n    @commands.cooldown(1, 5, commands.BucketType.guild)\n    @commands.command(name=\"swap\", **SwapRequest.discord_help)\n    async def swap(self, ctx: commands.Context, *args):\n        await self._handle_static(ctx, \"!swap\", *args)\n\n    @commands.cooldown(1, 5, commands.BucketType.guild)\n    @commands.command(name=\"card\")\n    async def card(self, ctx: commands.Context, *args):\n        await self._handle_static(ctx, \"!card\", *args)\n\n    async def _handle_static(self, ctx: commands.Context, prefix, *args):\n        language_code = get_req_id_from_ctx(ctx)\n        req = self.static_handler(bot, ctx, language_code, prefix, *args)\n        await req.on_demand()\n\n\nclass OnDemandForeign(OnDemand):\n    static_handler = StaticForeign\n\n\nclass Queue(commands.Cog, name=\"Queue requests to post on Facebook\"):\n    \"\"\"Requests that will be added to the queue in order to get posted on\n    the Facebook page.\n\n    Every user has unlimited queue requests.\"\"\"\n\n    @commands.command(name=\"freq\", **ClassicRequest.discord_help)\n    async def request(self, ctx: commands.Context, *args):\n        await self._handle_register(ctx, \"!req\", *args)\n\n    @commands.command(name=\"fparallel\", **ParallelRequest.discord_help)\n    async def parallel(self, ctx: commands.Context, *args):\n        await self._handle_register(ctx, \"!parallel\", *args)\n\n    @commands.command(name=\"fpalette\", **PaletteRequest.discord_help)\n    async def palette(self, ctx: commands.Context, *args):\n        await self._handle_register(ctx, \"!palette\", *args)\n\n    @commands.command(name=\"fswap\", **SwapRequest.discord_help)\n    async def swap(self, ctx: commands.Context, *args):\n        await self._handle_register(ctx, \"!swap\", *args)\n\n    @commands.command(name=\"fcard\", **SwapRequest.discord_help)\n    async def card(self, ctx: commands.Context, *args):\n        await self._handle_register(ctx, \"!card\", *args)\n\n    @staticmethod\n    async def _handle_register(ctx: commands.Context, prefix, *args):\n        language_code = get_req_id_from_ctx(ctx)\n        req = Static(bot, ctx, language_code, prefix, *args)\n        await req.register()\n\n\nclass Search(commands.Cog, name=\"Search in the database\"):\n    @commands.command(name=\"person\", help=\"Search for cast and crew people.\")\n    async def person(self, ctx: commands.Context, *args):\n        search = PersonSearch(\" \".join(args), limit=1)\n        search.search()\n\n        for embed in search.embeds:\n            await ctx.send(embed=embed)\n\n    @commands.command(name=\"country\", help=\"Search for a country.\")\n    async def country(self, ctx: commands.Context, *args):\n        await self._meta_search_handler(ctx, args, CountrySearch)\n\n    @commands.command(name=\"category\", help=\"Search for a category.\")\n    async def category(self, ctx: commands.Context, *args):\n        await self._meta_search_handler(ctx, args, CategorySearch)\n\n    @commands.command(name=\"genre\", help=\"Search for a genre.\")\n    async def genre(self, ctx: commands.Context, *args):\n        await self._meta_search_handler(ctx, args, GenreSearch)\n\n    @commands.command(name=\"movie\", help=\"Search for movies.\")\n    async def movie(self, ctx: commands.Context, *args):\n        movie = Movie.from_query(\" \".join(args))\n        await ctx.send(embed=movie.embed)\n\n    @commands.command(name=\"tvshow\", help=\"Search for TV Shows.\")\n    async def tvshow(self, ctx: commands.Context, *args):\n        msearch = MediaFuzzySearch(\" \".join(args), limit=1)\n        msearch.search(table=\"tv_shows\")\n\n        for item in msearch.items:\n            await ctx.send(embed=item.embed)\n\n    @commands.command(name=\"request\", help=\"Search for requests by content.\")\n    async def request(self, ctx: commands.Context, *args):\n        rsearch = RequestSearch(\" \".join(args))\n        rsearch.search()\n\n        await ctx.send(embed=rsearch.embed)\n\n    @commands.cooldown(1, 15, commands.BucketType.guild)\n    @commands.command(name=\"quote\", help=\"Search for quotes.\")\n    async def quote(self, ctx: commands.Context, *args):\n        language = get_req_id_from_ctx(ctx)\n        query, args = get_args_and_clean(\" \".join(args), (\"--filter\",))\n\n        qsearch = QuoteSearch(query, filter_=args.get(\"filter\", \"\"), lang=language)\n\n        loop = asyncio.get_running_loop()\n\n        await loop.run_in_executor(None, qsearch.search)\n\n        await ctx.send(embed=qsearch.embed)\n\n    @commands.command(name=\"song\", help=\"Search for songs.\")\n    async def song(self, ctx: commands.Context, *args):\n        ssearch = SongSearch(\" \".join(args))\n        ssearch.search()\n\n        await ctx.send(embed=ssearch.embed)\n\n    @commands.command(name=\"top\", help=\"Show the top 10.\", usage=\"FROM TO\")\n    async def top(self, ctx: commands.Context, from_=1, to_=10):\n        top = TopMovies(limit=45)\n        await ctx.send(top.discord((from_ - 1, to_)))\n\n    @staticmethod\n    async def _meta_search_handler(ctx: commands.Context, args, search_cls):\n        search = search_cls(\" \".join(args))\n        search.search()\n\n        await ctx.send(embed=search.embed)\n\n\n_LANGUAGES_INDEX = {1: \"en\", 2: \"es\", 3: \"pt\"}\n\n\nclass MyUser(commands.Cog, name=\"User management\"):\n    @commands.command(name=\"queue\", help=\"Show your queued requests.\", usage=\"[User]\")\n    async def queue(self, ctx: commands.Context, *, member: Optional[Member] = None):\n        if member is None:\n            user = User.from_discord(ctx.author)\n        else:\n            user = User.from_discord(member)\n\n        requests = [ClassicRequest(**item) for item in user.get_queued_requests()]\n\n        await ctx.send(\"\\n\".join(req.pretty_title for req in requests)[:1000])\n\n    @commands.command(name=\"stats\", help=\"Show your posts stats.\", usage=\"[User] KEY\")\n    async def stats(\n        self,\n        ctx: commands.Context,\n        member: Optional[Member] = None,\n        *,\n        key=\"impressions\",\n    ):\n        if member is None:\n            user = User.from_discord(ctx.author)\n        else:\n            user = User.from_discord(member)\n\n        count = user.posts_stats_count(key)\n\n        pretty_word = key.title().replace(\"_\", \" \")\n        if not pretty_word.endswith(\"s\"):\n            pretty_word += \"s\"\n\n        message = f\"**{user.name}** has produced **{count:,} {pretty_word}** on posts\"\n        await ctx.send(message)\n\n    @commands.cooldown(1, 5, commands.BucketType.user)\n    @commands.command(name=\"rate\", help=\"Rate a movie (0.5-5).\", usage=\"MOVIE X.X\")\n    async def rate(self, ctx: commands.Context, *args):\n        try:\n            rating = args[-1].split(\"/\")[0]\n        except IndexError:\n            raise exceptions.InvalidRequest from None\n\n        try:\n            rating = float(rating)\n        except ValueError:\n            raise exceptions.InvalidRequest(\"Number not found: {rating}\") from None\n\n        logger.debug(\"Passed rating: %s\", rating)\n\n        movie = Movie.from_query(\" \".join(args))\n        user = User.from_discord(ctx.author)\n\n        user.rate_media(movie, rating)\n        await ctx.send(f\"You rating for `{movie.simple_title}`: **{rating}/5**\")\n\n    @commands.command(name=\"upname\", help=\"Update your username.\")\n    async def upname(self, ctx: commands.Context, *args):\n        name = \" \".join(args)\n\n        user = User.from_discord(ctx.author)\n        user.register()\n        user.update_name(name)\n\n        await ctx.send(f\"Update name to `{name}` for user with `{user.id}` ID.\")\n\n    @commands.command(name=\"lang\", help=\"Update the perma-language for your requests.\")\n    async def lang(self, ctx: commands.Context):\n        def check_author(message):\n            return message.author == ctx.author\n\n        await ctx.send(\n            f\"Choose the language number (default: `1`):\\n\\n\"\n            \"1. English\\n2. Spanish\\n3. Portuguese (Brazil)\"\n        )\n        try:\n            msg = await bot.wait_for(\"message\", timeout=60, check=check_author)\n            index = None\n            try:\n                index = int(msg.content.strip())\n            except ValueError:\n                pass\n\n            if index is None or index not in _LANGUAGES_INDEX:\n                raise exceptions.InvalidRequest(\"Invalid index\")\n\n            lang = _LANGUAGES_INDEX[index]\n            user = User.from_discord(ctx.author)\n            user.update_language(lang)\n            await ctx.send(f\"Your default language was updated to `{lang}`.\")\n\n        except asyncio.TimeoutError:\n            pass\n\n\n# No category\n@commands.command(name=\"docs\", help=\"Show documentation links.\")\nasync def docs(ctx: commands.Context):\n    await ctx.send(embed=API_HELP_EMBED)\n\n\n@commands.command(name=\"server\", help=\"Join Kinobot's official server.\")\nasync def server(ctx: commands.Context):\n    await ctx.send(DISCORD_INVITE)\n\n\n@commands.command(name=\"invite\", help=\"Invite the bot to your server.\")\nasync def invite(ctx: commands.Context):\n    await ctx.send(\n        \"The bot is under a verification process from Discord. \"\n        \"This means you are no longer allowed to add the bot to \"\n        \"any server until it gets verified. Starting the verification \"\n        \"process at Jun 6, the process can take up four weeks. \"\n        \"Please stay tuned.\"\n    )\n\n\n#    embed = Embed(title=\"Invite Kinobot to your server!\")\n#    embed.add_field(name=\"Prefixes\", value=\"`k!`, `k.`\", inline=False)\n#    embed.add_field(\n#        name=\"Invitation link\",\n#        value=f\"[Click here]({DISCORD_BOT_INVITE})\",\n#        inline=False,\n#    )\n#    await ctx.send(embed=embed)\n\n\n@commands.has_permissions(administrator=True)\n@commands.command(name=\"where\", help=\"Show bot guilds.\")\nasync def where(ctx: commands.Context):\n    guild_strs = [item.name for item in bot.guilds]\n    msg = f\"`Guilds: {', '.join(guild_strs[:1900])}\\n\\nTotal: {len(guild_strs)}`\"\n    await ctx.send(msg)\n\n\n@bot.event\nasync def on_command_error(ctx: commands.Context, error):\n    await handle_error(ctx, error)\n\n\n@bot.event\nasync def on_ready():\n    logger.info(\"Running on: %s (%s)\", bot.user.name, bot.user.id)\n    guild_strs = [item.name for item in bot.guilds]\n    logger.info(\"Bot is ready. Guilds: %s\", guild_strs)\n\n\ndef run(token: str, foreign: bool = False, custom_prefix=None):\n    bot.command_prefix = custom_prefix or ([\"k!\", \"k.\"] if foreign else \"!\")\n    reqs = OnDemandForeign if foreign else OnDemand\n\n    logger.debug(\"Bot prefix: %s\", bot.command_prefix)\n\n    for cog in (reqs, Queue, MyUser, Search):\n        bot.add_cog(cog(bot))\n\n    for command in (docs, server, invite):\n        bot.add_command(command)\n\n    bot.run(token)\n"}
{"type": "source_file", "path": "kinobot/discord/extras/subtitles.py", "content": "import asyncio\nimport asyncio.subprocess\nimport logging\nimport os\nimport re\nimport shutil\nimport tempfile\n\nfrom discord.ext import commands\nimport pysubs2\nimport requests\n\nfrom kinobot.media import Episode\nfrom kinobot.media import is_episode\nfrom kinobot.media import Movie\n\nfrom ..utils import ask\nfrom ..utils import ask_to_confirm\nfrom ..utils import call_with_typing\nfrom ..utils import ExitStatus\nfrom ..utils import on_excs_send\n\nALASS_PATH = os.environ.get(\"ALASS_PATH\", \"alass\")\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass SubtitleError(Exception):\n    pass\n\n\nclass SubprocessError(SubtitleError):\n    pass\n\n\nasync def _ask_for_media(bot, ctx):\n    await ctx.send(\"Tell me the movie or episode\")\n    response = await ask(bot, ctx)\n    if response is None:\n        raise ExitStatus\n\n    if is_episode(response):\n        media = Episode.from_query(response)\n    else:\n        media = Movie.from_query(response)\n\n    return media\n\n\n@on_excs_send((ExitStatus))\nasync def autosync(bot, ctx: commands.Context):\n    media = await _ask_for_media(bot, ctx)\n    if not await ask_to_confirm(bot, ctx, f\"{media.pretty_title}. Are you sure?\"):\n        raise ExitStatus\n\n    assert media.path is not None\n    subs_path = _subs_from_video(media.path)\n    if subs_path is None:\n        return await ctx.send(\"This media item doesn't have any subtitles\")\n\n    async def _callback(line):\n        if len(line) > 200:\n            return None\n\n        await ctx.send(_redact_line(line))\n\n    await automatic_sync(subs_path, media.path, line_callback=_callback)\n    await ctx.send(\"Ok.\")\n\n\n@on_excs_send((ExitStatus))\nasync def upload(bot, ctx: commands.Context):\n    try:\n        attachment_url = ctx.message.attachments[0].url\n    except IndexError:\n        return await ctx.send(\"No attachment provided\")\n\n    loop = asyncio.get_running_loop()\n    await ctx.send(\"Checking SRT file...\")\n\n    try:\n        subtitles = await call_with_typing(ctx, loop, _download_srt, attachment_url)\n    finally:\n        await ctx.send(\"Deleting your attachment...\")\n        await ctx.message.delete()\n\n    await ctx.send(\n        \"Check done. Don't forget that you'll be banned forever from this feature if you upload abusive content.\"\n    )\n\n    media = await _ask_for_media(bot, ctx)\n    subs_path = _subs_from_video(media.path, check_exists=False)  # type: ignore\n\n    shutil.move(subtitles, subs_path)  # type: ignore\n    await ctx.send(\"Ok.\")\n\n\n@on_excs_send((ExitStatus))\nasync def edit(bot, ctx: commands.Context):\n    media = await _ask_for_media(bot, ctx)\n\n    await ctx.send(\n        f\"Media item: {media.pretty_title}\\n\\n\"\n        \"Now tell me the index of the subtitle to edit. ('no to exit)\"\n    )\n    response = await ask(bot, ctx)\n    if response is None or response.lower() == \"no\":\n        raise ExitStatus\n\n    try:\n        index = int(response) - 1\n    except ValueError:\n        await ctx.send(\"Invalid index number.\")\n        raise ExitStatus\n\n    assert media.path\n    subs_path = _subs_from_video(media.path)\n\n    if subs_path is None:\n        await ctx.send(\"This media item doesn't have any subtitles.\")\n        raise ExitStatus\n\n    subs = pysubs2.load(subs_path)\n    line = subs[index]\n    await ctx.send(\n        f\"{line.text}\\n\\nThis is the line you are gonna edit. Remember: vandalizing \"\n        \"subtitles will get you banned from this feature. Now, type your modification.\"\n    )\n    response = await ask(bot, ctx)\n    if response is None or response.lower() == \"no\":\n        raise ExitStatus\n\n    if not await ask_to_confirm(bot, ctx, f\"{response}\\n\\nAre you sure? (y/n)\"):\n        raise ExitStatus\n\n    line.text = response.strip()\n    subs[index] = line\n    subs.save(subs_path)\n\n    await ctx.send(\"Saved.\")\n\n\n@on_excs_send((ExitStatus))\nasync def shift(bot, ctx: commands.Context):\n    media = await _ask_for_media(bot, ctx)\n\n    await ctx.send(\n        f\"Media item: {media.pretty_title}\\n\\n\"\n        \"Now tell me the offset in milliseconds (it can be negative or positive). \"\n        \"Reply with 'no' to cancel this operation.\"\n    )\n    response = await ask(bot, ctx)\n    if response is None or response.lower() == \"no\":\n        raise ExitStatus\n\n    try:\n        offset = int(response)\n    except ValueError:\n        await ctx.send(\"Invalid offset number.\")\n        raise ExitStatus\n\n    assert media.path is not None\n\n    subs = _subs_from_video(media.path)\n    if subs is None:\n        await ctx.send(\"This media item doesn't have any subtitles.\")\n        raise ExitStatus\n\n    _offset_subtitles(subs, offset)\n    await ctx.send(\"Done.\")\n\n\ndef _offset_subtitles(subs_path: str, offset: float, output=None):\n    subs = pysubs2.load(subs_path)\n    subs.shift(ms=offset)\n    output = output or subs_path\n    subs.save(output)\n    logger.info(\"Shift of %sms complete for %s\", offset, output)\n\n\ndef _subs_from_video(video_path: str, ext=\".en.srt\", check_exists=True):\n    subs = os.path.splitext(video_path)[0] + ext\n    if not check_exists:\n        return subs\n\n    if os.path.isfile(subs):\n        return subs\n\n    return None\n\n\nasync def upload_file(ctx):\n    try:\n        attachment_url = ctx.message.attachments[0].url\n    except IndexError:\n        return await ctx.send(\"No attachment provided\")\n\n    _download_srt(attachment_url)\n\n\ndef _download_srt(url):\n    response = requests.head(url)\n    content_length = int(response.headers.get(\"content-length\", 0))\n\n    mbs = content_length / (1024 * 1024)\n    if mbs > 1:\n        raise SubtitleError(\"File is bigger than 1mb. Can't download\")\n\n    r = requests.get(url)\n    r.raise_for_status()\n\n    with tempfile.NamedTemporaryFile(suffix=\".srt\", delete=False) as f:\n        f.write(r.content)\n        assert pysubs2.load(f.name)\n        logger.info(\"Downloaded: %s\", f.name)\n        return f.name\n\n\nasync def _readline(stream: asyncio.StreamReader, timeout: float):\n    try:\n        return await asyncio.wait_for(stream.readuntil(), timeout=timeout)\n    except asyncio.exceptions.LimitOverrunError:\n        return b\"\"\n\n\n_FILE_RE = re.compile(r\"(/[a-zA-Z\\./]*[\\s]?)\")\n\n\ndef _redact_line(line):\n    return _FILE_RE.sub(\"REDACTED\", line)\n\n\nasync def automatic_sync(\n    subs_path: str,\n    reference_file: str,\n    output_file=None,\n    line_callback=None,\n    timeout=2000,\n):\n    output_file = output_file or subs_path\n\n    command = [ALASS_PATH, reference_file, subs_path, output_file]\n    proc = await asyncio.subprocess.create_subprocess_exec(\n        *command,\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.PIPE,\n    )\n    assert proc.stdout is not None\n\n    while True:\n        try:\n            line = await _readline(proc.stdout, timeout=timeout)\n            if proc.returncode is not None and proc.returncode != 0:\n                raise SubprocessError\n\n            line = line.decode().strip()\n\n            if line_callback is not None and line:\n                await line_callback(line)\n\n        except asyncio.exceptions.IncompleteReadError:\n            break\n"}
{"type": "source_file", "path": "kinobot/discord/emby.py", "content": "import asyncio\nimport json\nimport os\nimport tempfile\nimport datetime\nimport logging\n\nfrom typing import Literal, Optional\n\nfrom discord import Embed, File\nfrom discord.ext import commands\nfrom pydantic import BaseModel, Field, ValidationError\nfrom kinobot.misc import emby\nfrom kinobot.infra import misc\nfrom kinobot.config import config\nfrom kinobot.misc.poster import create_video_from_images\nfrom kinobot.utils import get_args_and_clean\n\n\nfrom .utils import ask\nfrom .utils import ask_to_confirm\nfrom .utils import call_with_typing\nfrom .utils import paginated_list\n\n\nlogger = logging.getLogger(__name__)\n\n\ndef _calculate_timezone_from_hour(input_hour_str):\n    try:\n        input_hour = int(input_hour_str)\n\n        now = datetime.datetime.now().astimezone()\n        system_hour = now.hour\n\n        offset_hours = input_hour - system_hour\n\n        if offset_hours > 12:\n            offset_hours -= 24\n        elif offset_hours < -12:\n            offset_hours += 24\n\n        return offset_hours\n\n    except ValueError:\n        raise ValueError(\n            \"Invalid input. Please provide a valid hour as a string (e.g., '10').\"\n        )\n\n\nasync def setup(bot, ctx: commands.Context):\n    await ctx.send(\"Give me your Emby username. Type 'n' if you don't use it\")\n    emby_username = await ask(bot, ctx, none_if=\"n\")\n\n    await ctx.send(\"Give me your Jellyfin username. Type 'n' if you don't use it\")\n    jellyfin_username = await ask(bot, ctx, none_if=\"n\")\n\n    await ctx.send(\n        \"Tell me the current hour of your clock (0-24 format). This will be used to calculate your timezone.\"\n    )\n    current_hour = await ask(bot, ctx) or \"0\"\n    offset = _calculate_timezone_from_hour(current_hour)\n\n    model = misc.UserEmbyData(\n        timezone_offset=offset,\n        jellyfin_username=jellyfin_username,\n        emby_username=emby_username,\n        user_id=ctx.author.id,\n    )\n    misc.update_or_create_emby_data(model)\n    await ctx.send(f\"Setup complete: {model}\")\n\n\ndef _make_emby():\n    return emby.Client(config.emby.host, config.emby.api_key)\n\n\ndef _make_jellyfin():\n    return emby.Client(\n        config.jellyfin.host, config.jellyfin.api_key, factory=\"jellyfin\"\n    )\n\n\ndef _make(\n    data_model,\n    username,\n    backdrops=False,\n    period_key=\"month\",\n    type=\"movie\",\n    emby_username=None,\n    jellyfin_username=None,\n    multiple=False,\n):\n    jellyfin_username_default = data_model.jellyfin_username\n    emby_username_default = data_model.emby_username\n    if emby_username is not None:\n        jellyfin_username_default = None\n        emby_username_default = emby_username\n\n    if jellyfin_username is not None:\n        emby_username_default = None\n        jellyfin_username_default = jellyfin_username\n\n    return emby.make(\n        _make_emby(),\n        _make_jellyfin(),\n        emby_username_default,\n        jellyfin_username_default,\n        username,\n        backdrops=backdrops,\n        period_key=period_key,\n        multiple=multiple,\n        type=type,\n    )\n\n\nclass LastPlayedArgs(BaseModel):\n    period: Literal[\"month\", \"week\", \"3month\", \"year\", \"day\", \"all\"] = \"month\"\n    backdrops: bool = False\n    type: Literal[\"movie\", \"series\", \"all\"] = \"movie\"\n    emby_user: Optional[str] = None\n    jellyfin_user: Optional[str] = None\n    video: bool = False\n\n    @classmethod\n    def parse(cls, str_: str):\n        _, data = get_args_and_clean(\n            str_,\n            args=(\n                \"--period\",\n                \"--backdrops\",\n                \"--type\",\n                \"--emby-user\",\n                \"--jellyfin-user\",\n                \"--video\",\n            ),\n        )\n        return cls.model_validate(data)\n\n\nasync def run(bot, ctx: commands.Context, content: str):\n    data_model = misc.get_emby_data(ctx.author.id)\n    if not data_model:\n        return await ctx.send(\n            \"No data found for your user. Setup your data running !emsetup\"\n        )\n\n    try:\n        config = LastPlayedArgs.parse(f\"dummy {content}\")\n    except ValidationError as error:\n        error_data = json.loads(error.json())[0]\n        msg = error_data[\"msg\"]\n        loc = error_data[\"loc\"]\n        return await ctx.send(\n            f\"{loc}: {msg}\" + \"\\n\\nUsage:\\n\"\n            \"!lastplayed [--period {month,week,3month,year,day,all}] [--backdrops] [--type {movie,series,all}]\"\n        )\n\n    def _run():\n        username_title = (\n            config.emby_user\n            or config.jellyfin_user\n            or data_model.emby_username\n            or data_model.jellyfin_username\n        )\n        result = _make(\n            data_model,\n            username_title,\n            config.backdrops,\n            period_key=config.period,\n            type=config.type,\n            emby_username=config.emby_user,\n            jellyfin_username=config.jellyfin_user,\n            multiple=config.video,\n        )\n        if isinstance(result, list):\n            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as tf:\n                create_video_from_images(result, tf.name)\n                return tf.name\n        else:\n            with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as tf:\n                result.save(tf.name)\n                return tf.name\n\n    loop = asyncio.get_event_loop()\n    result = await call_with_typing(ctx, loop, _run)\n\n    with open(result, \"rb\") as file:\n        await ctx.send(file=File(file, filename=os.path.basename(result)))\n\n    os.remove(result)\n"}
{"type": "source_file", "path": "kinobot/discord/games.py", "content": "import asyncio\nimport logging\n\nfrom discord import Embed\nfrom discord.ext import commands\n\nfrom kinobot.sources.games import registry\nfrom kinobot.user import User\n\nlogger = logging.getLogger(__name__)\n\n\nasync def call_with_typing(ctx, loop, *args):\n    result = None\n    async with ctx.typing():\n        result = await loop.run_in_executor(*args)\n\n    return result\n\n\ndef _check_author(author):\n    return lambda message: message.author == author\n\n\nasync def _interactive_index(bot, ctx, items):\n    chosen_index = 0\n\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        try:\n            chosen_index = int(msg.content.lower().strip()) - 1\n            items[chosen_index]\n        except (ValueError, IndexError):\n            await ctx.send(\"Invalid index! Bye\")\n            return None\n\n    except asyncio.TimeoutError:\n        await ctx.send(\"Timeout! Bye\")\n        return None\n\n    return chosen_index\n\n\nasync def _pretty_title_list(\n    ctx, items, append=None, msg=\"Choose the item you want to add ('n' to ignore):\"\n):\n    str_list = \"\\n\".join(f\"{n}. {m.pretty_title()}\" for n, m in enumerate(items, 1))\n    msg = f\"{msg}\\n\\n{str_list}\"\n\n    if append is not None:\n        msg = f\"{msg}\\n\\n{append}\"\n\n    await ctx.send(msg)\n\n\nasync def _interactive_y_n(bot, ctx):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        return msg.content.lower().strip() == \"y\"\n    except asyncio.TimeoutError:\n        return await ctx.send(\"Timeout! Bye\")\n\n\nasync def _ask_msg(bot, ctx):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        return msg.content.strip()\n    except asyncio.TimeoutError:\n        return await ctx.send(\"Timeout! Bye\")\n\n\ndef _get_cutscenes_embed(game: registry.Game) -> Embed:\n    embed = Embed(title=game.pretty_title(), url=game.url)\n\n    str_list = \"\\n\".join(\n        f\"{n}. {m.markdown_url} ({m.uri_query})\"\n        for n, m in enumerate(game.cutscenes, 1)\n    )\n\n    embed.add_field(name=\"Cutscenes\", value=str_list[:999])\n    return embed\n\n\nasync def deletecutscene(bot, ctx: commands.Context, game_uri):\n    repo = registry.Repository.from_constants()\n    cutscene = repo.search_cutscene(game_uri)\n    repo.delete_cutscene(cutscene.id)\n    await ctx.send(\n        f\"{ctx.author.display_name} ({ctx.author.id}) deleted the following cutscene: {cutscene}\"\n    )\n\n\nasync def explorecutscenes(bot, ctx: commands.Context, *args):\n    query = \" \".join(args)\n    repo = registry.Repository.from_constants()\n    items = repo.simple_search(query)\n    if not items:\n        return await ctx.send(\"Nothing found.\")\n    else:\n        item = items[0]\n\n    await ctx.send(embed=_get_cutscenes_embed(item))\n\n\nasync def exploregames(bot, ctx: commands.Context, *args):\n    query = \" \".join(args)\n    repo = registry.Repository.from_constants()\n    items = repo.simple_search(query)\n    if not items:\n        return await ctx.send(\"Nothing found.\")\n\n    await _pretty_title_list(ctx, items, msg=\"\")\n\n\nasync def addgame(bot, ctx: commands.Context, video_url, *args):\n    video_url = video_url.strip()\n    if not video_url:\n        return await ctx.send(\"You need to provide an URL\")\n\n    query = \" \".join(args)\n\n    user = User.from_discord(ctx.author)\n    user.load()\n\n    loop = asyncio.get_running_loop()\n\n    client = registry.Client.from_config()\n\n    items = await call_with_typing(ctx, loop, None, client.search, query)\n\n    if not items:\n        return await ctx.send(\"Nothing found\")\n\n    msg = \"Choose the item you want to add ('n' to ignore). Avoid titles with special tags (editions, etc) or you'll get banned!\"\n    await _pretty_title_list(ctx, items, msg=msg)\n\n    chosen_index = await _interactive_index(bot, ctx, items)\n    if chosen_index is None:\n        return None\n\n    chosen_item = items[chosen_index]\n\n    await ctx.send(f\"**{chosen_item.pretty_title()}**\\n\\nAdd item? (y/n)\")\n\n    if not await _interactive_y_n(bot, ctx):\n        return None\n\n    await call_with_typing(ctx, loop, None, chosen_item.fetch_companies, client)\n    repo = registry.Repository.from_constants()\n\n    try:\n        repo.add_game(chosen_item)\n    except registry.AlreadyAdded:\n        pass\n\n    await ctx.send(\n        \"Type the name of the cutscene (this will be used to search the cutscene in requests).\"\n    )\n\n    msg = await _ask_msg(bot, ctx)\n    if not msg:\n        return await ctx.send(\"Invalid name\")\n\n    cutscene_ = registry.Cutscene(uri=video_url, name=msg, game_id=chosen_item.id)\n    new = repo.add_cutscene(cutscene_)\n    await ctx.send(f\"Cutscene saved. You can request it with '{new.uri_query}'\")\n"}
{"type": "source_file", "path": "kinobot/discord/utils.py", "content": "import asyncio\nfrom datetime import datetime\nimport logging\nimport sqlite3\nfrom typing import Any, Callable, List, Optional\n\nfrom discord.ext import commands\n\nlogger = logging.getLogger(__name__)\n\n\nclass ExitStatus(Exception):\n    pass\n\n\ndef on_excs_send(excs, message=\"Command finished\"):\n    def decorator(func):\n        async def wrapper(bot, ctx, *args, **kwargs):\n            try:\n                return await func(bot, ctx, *args, **kwargs)\n            except excs as error:\n                logger.exception(error)\n                await ctx.send(message)\n\n        return wrapper\n\n    return decorator\n\n\nasync def call_with_typing(ctx, loop, *args):\n    result = None\n    async with ctx.typing():\n        result = await loop.run_in_executor(None, *args)\n\n    return result\n\n\ndef _slice_list(list_, n):\n    groups = []\n    for i in range(0, len(list_), n):\n        groups.append(list_[i : i + n])\n\n    return groups\n\n\ndef _check_author(author):\n    return lambda message: message.author == author\n\n\nasync def ask(bot, ctx, timeout=120, custom_check=None, delete=False, none_if=None):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=timeout, check=custom_check or _check_author(ctx.author)\n        )\n        if delete:\n            await msg.delete()\n            await ctx.send(\"Message deleted.\", delete_after=10)\n\n        if none_if is not None and none_if.lower() == str(msg.content).strip().lower():\n            return None\n\n        return str(msg.content).strip()\n    except asyncio.TimeoutError:\n        return None\n\n\nasync def ask_to_confirm(\n    bot,\n    ctx,\n    question=\"Are you sure? (y/n)\",\n    confirm_str=\"y\",\n    timeout=120,\n    custom_check=None,\n):\n    await ctx.send(question)\n\n    response = await ask(bot, ctx, timeout, custom_check)\n    if response is None:\n        return False\n\n    return response.lower() == confirm_str\n\n\n_PAG_HELP = f\"Type the number of the item to pick; `n` to go to the next page; `p` to go the previous page; anything else to quit.\"\n\n\nasync def paginated_list(\n    bot,\n    ctx: commands.Context,\n    header: str,\n    items: List[Any],\n    to_str_callback: Callable[[Any], str] = lambda l: str(l),\n    slice_in=20,\n    timeout=60,\n) -> Optional[Any]:\n    if not items:\n        logger.debug(\"No items to generate.\")\n        return None\n\n    str_items = [f\"{n}. {to_str_callback(i)}\" for n, i in enumerate(items, start=1)]\n    lists = _slice_list(str_items, slice_in)\n    requested_index = 0\n\n    max_index = len(lists) - 1\n    strs = \"\\n\".join(lists[requested_index])\n    message = await ctx.send(f\"{header} (page 1/{max_index+1}). {_PAG_HELP}\\n{strs}\")\n\n    while True:\n        response = await ask(bot, ctx, timeout=timeout)\n\n        if response is None:\n            break\n\n        if response not in (\"b\", \"n\"):\n            try:\n                return items[int(response) - 1]\n            except (ValueError, IndexError):\n                await ctx.send(\"Invalid index. Bye.\")\n                return None\n\n        should_change = False\n        if response == \"p\":\n            if requested_index > 0:\n                requested_index -= 1\n                should_change = True\n\n        elif response == \"n\":\n            if requested_index < max_index:\n                requested_index += 1\n                should_change = True\n\n        if should_change:\n            strs = \"\\n\".join(lists[requested_index])\n            await message.edit(\n                content=f\"{header} (page {requested_index+1}/{max_index+1}), {_PAG_HELP}\\n{strs}\"\n            )\n\n\nclass IDLogger:\n    def __init__(self, db_name, table_name=\"seen_ids\"):\n        self._db_name = db_name\n        self._table_name = table_name\n        self._conn = sqlite3.connect(db_name)\n        self._create_table()\n\n    def _create_table(self):\n        with self._conn:\n            self._conn.execute(\n                f\"\"\"CREATE TABLE IF NOT EXISTS {self._table_name}\n                                 (id CHAR PRIMARY KEY,\n                                  seen_at TIMESTAMP)\"\"\"\n            )\n\n    def mark_as_seen(self, id, seen_at=None):\n        if seen_at is None:\n            seen_at = datetime.now()\n        with self._conn:\n            self._conn.execute(\n                f\"INSERT INTO {self._table_name} (id, seen_at) VALUES (?, ?)\",\n                (id, seen_at),\n            )\n\n    def has_seen(self, id, within_last=None):\n        if within_last is None:\n            with self._conn:\n                cursor = self._conn.execute(\n                    f\"SELECT id FROM {self._table_name} WHERE id=?\", (id,)\n                )\n                return cursor.fetchone() is not None\n        else:\n            since = datetime.now() - within_last\n            with self._conn:\n                cursor = self._conn.execute(\n                    f\"SELECT id FROM {self._table_name} WHERE id=? AND seen_at >= ?\",\n                    (id, since),\n                )\n                return cursor.fetchone() is not None\n\n    def __str__(self) -> str:\n        return f\"<IDLogger {self._table_name}@{self._db_name}>\"\n"}
{"type": "source_file", "path": "kinobot/discord/songs.py", "content": "import asyncio\nimport logging\n\nfrom discord.ext import commands\n\nfrom kinobot.sources.music import registry\nfrom kinobot.user import User\n\nlogger = logging.getLogger(__name__)\n\n\nasync def call_with_typing(ctx, loop, *args):\n    result = None\n    async with ctx.typing():\n        result = await loop.run_in_executor(*args)\n\n    return result\n\n\ndef _check_author(author):\n    return lambda message: message.author == author\n\n\nasync def _interactive_index(bot, ctx, items):\n    chosen_index = 0\n\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        try:\n            chosen_index = int(msg.content.lower().strip()) - 1\n            items[chosen_index]\n        except (ValueError, IndexError):\n            await ctx.send(\"Invalid index! Bye\")\n            return None\n\n    except asyncio.TimeoutError:\n        await ctx.send(\"Timeout! Bye\")\n        return None\n\n    return chosen_index\n\n\nasync def _pretty_title_list(\n    ctx, items, append=None, msg=\"Choose the item you want to add ('n' to ignore):\"\n):\n    str_list = \"\\n\".join(f\"{n}. {m.pretty_title()}\" for n, m in enumerate(items, 1))\n    msg = f\"{msg}\\n\\n{str_list}\"\n\n    if append is not None:\n        msg = f\"{msg}\\n\\n{append}\"\n\n    await ctx.send(msg)\n\n\nasync def _interactive_y_n(bot, ctx):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        return msg.content.lower().strip() == \"y\"\n    except asyncio.TimeoutError:\n        return await ctx.send(\"Timeout! Bye\")\n\n\nasync def exploresongs(bot, ctx: commands.Context, *args):\n    query = \" \".join(args)\n    repo = registry.Repository.from_constants()\n    items = repo.simple_search(query)\n    if not items:\n        return await ctx.send(\"Nothing found.\")\n\n    await _pretty_title_list(ctx, items, msg=\"\")\n\n\nasync def addsong(bot, ctx: commands.Context, video_url, *args):\n    video_url = video_url.strip()\n    query = \" \".join(args)\n\n    user = User.from_discord(ctx.author)\n    user.load()\n\n    loop = asyncio.get_running_loop()\n\n    client = registry.Client.from_constants()\n\n    items = await call_with_typing(ctx, loop, None, client.search_track, query)\n    await _pretty_title_list(ctx, items)\n\n    chosen_index = await _interactive_index(bot, ctx, items)\n    if chosen_index is None:\n        return None\n\n    chosen_item = items[chosen_index]\n\n    await ctx.send(f\"**{chosen_item.pretty_title()}**\\n\\nAdd item? (y/n)\")\n\n    if not await _interactive_y_n(bot, ctx):\n        return None\n\n    new_track = registry.DbTrack(\n        artist=chosen_item.artist, name=chosen_item.name, uri=video_url\n    )\n\n    repo = registry.Repository.from_constants()\n    id_ = repo.add(new_track)\n    await ctx.send(f\"Added item with {id_} ID\")\n"}
{"type": "source_file", "path": "kinobot/discord/extras/verifier.py", "content": "# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport datetime\nimport locale\nimport logging\nimport sqlite3\nfrom typing import List\n\nimport numpy\nimport pydantic\n\nfrom kinobot.exceptions import NothingFound\n\nlogger = logging.getLogger(__name__)\n\nlocale.setlocale(locale.LC_ALL, \"\")\n\n\ndef _format_int(i):\n    return format(i, \",d\")\n\n\nclass UserBasic(pydantic.BaseModel):\n    position: int\n    id: str\n    name: str\n    rating: float\n    level: str\n\n    def __str__(self) -> str:\n        return f\"{self.position:02}. {self.name}: {_format_int(int(self.rating))}\"\n\n\nclass VerifierTop(pydantic.BaseModel):\n    users: List[UserBasic]\n    column: str\n    users_count: int\n    from_: datetime.datetime\n    to_: datetime.datetime\n\n    def as_table(self):\n        string = f\"Verifiers top by {self.column} (from {self.from_} to {self.to_})\"\n        users_str = \"\\n\".join(str(user) for user in self.users)\n        return f\"{string}\\n\\n{users_str}\"\n\n\nclass PosterTop(VerifierTop):\n    min_posts: int\n\n    def as_table(self, limit=25):\n        string = f\"Posters top by {self.column} (from {self.from_} to {self.to_})\\n(min posts to qualify: {self.min_posts})\"\n        users_str = \"\\n\".join(str(user) for user in self.users[:limit])\n        return f\"{string}\\n\\n{users_str}\"\n\n\n_LEVELS = (\"expert\", \"competent\", \"beginner\")\n\n\ndef _get_levels(users):\n    sliced = numpy.array_split(users, len(_LEVELS))\n    levels = {}\n    index = 0\n    for user_list, level in zip(sliced, _LEVELS):\n        for _ in user_list:\n            levels[index] = level\n            index += 1\n\n    return levels\n\n\ndef _dt_to_sql(dt):\n    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n\ndef _get_between(between):\n    from_ = _dt_to_sql(between[0] or datetime.datetime(2019, 1, 1))\n    if between[1] is None:\n        to_ = \"now\"\n    else:\n        to_ = _dt_to_sql(between[1])\n\n    return from_, to_\n\n\nclass Verifier:\n    def __init__(self, user_id, db_path):\n        self._conn = sqlite3.connect(db_path)\n        self._conn.set_trace_callback(logger.debug)\n        self.user_id = str(user_id)\n\n    def get_top(self, column=\"impressions\", between=(None, None)):\n        between = _get_between(between)\n        sql = (\n            f\"select avg(posts.{column}) as rating, count(posts.id) \"\n            \"as posts_count, users.name as user_name, users.id as user_id from posts \"\n            \"inner join requests on posts.request_id=requests.id inner join \"\n            \"request_verifications on requests.user_id=request_verifications.user_id \"\n            \"inner join users on request_verifications.user_id=users.id where \"\n            \"(posts.added between date(?) and date(?)) group by request_verifications.user_id \"\n            \"order by rating desc\"\n        )\n        result = self._conn.execute(sql, between).fetchall()\n        levels = _get_levels(result)\n\n        users = []\n        for num, item in enumerate(result, start=1):\n            users.append(\n                UserBasic(\n                    position=num,\n                    rating=item[0],\n                    name=item[2],\n                    id=item[3],\n                    level=levels[num - 1],\n                )\n            )\n\n        return VerifierTop(\n            users=users,\n            column=column,\n            users_count=len(users),\n            from_=between[0],\n            to_=between[1],\n        )\n\n    def get_top_card(self, column=\"impressions\", between=(None, None)) -> UserBasic:\n        top = self.get_top(column, between)\n        users = top.users\n        try:\n            return [user for user in users if user.id == self.user_id][0]\n        except IndexError:\n            raise NothingFound(\"User ID not found in verifiers\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self._conn.close()\n\n    def close(self):\n        self._conn.close()\n\n\nclass Poster:\n    def __init__(self, user_id, db_path):\n        self._conn = sqlite3.connect(db_path)\n        self._conn.set_trace_callback(logger.debug)\n        self.user_id = str(user_id)\n\n    def get_top(self, column=\"impressions\", between=(None, None), min_posts=7):\n        between = _get_between(between)\n        sql = (\n            f\"select avg(posts.{column}) as rating, count(posts.id) \"\n            \"as posts_count, users.name as user_name, users.id as user_id from posts \"\n            \"inner join requests on posts.request_id=requests.id \"\n            \"inner join users on requests.user_id=users.id where \"\n            \"(posts.added between date(?) and date(?)) group by requests.user_id having \"\n            f\"count(posts.id) >= {min_posts} order by rating desc\"\n        )\n        result = self._conn.execute(sql, between).fetchall()\n        levels = _get_levels(result)\n\n        users = []\n        for num, item in enumerate(result, start=1):\n            if item[3] == \"1234567890\":\n                continue\n\n            users.append(\n                UserBasic(\n                    position=num,\n                    rating=item[0],\n                    name=item[2],\n                    id=item[3],\n                    level=levels[num - 1],\n                )\n            )\n\n        return PosterTop(\n            users=users,\n            column=column,\n            users_count=len(users),\n            from_=between[0],\n            to_=between[1],\n            min_posts=min_posts,\n        )\n\n    def get_top_total(self, column=\"impressions\", between=(None, None), min_posts=7):\n        between = _get_between(between)\n        sql = (\n            f\"select sum(posts.{column}) as rating, count(posts.id) \"\n            \"as posts_count, users.name as user_name, users.id as user_id from posts \"\n            \"inner join requests on posts.request_id=requests.id \"\n            \"inner join users on requests.user_id=users.id where \"\n            \"(posts.added between date(?) and date(?)) group by requests.user_id having \"\n            f\"count(posts.id) >= {min_posts} order by rating desc\"\n        )\n        result = self._conn.execute(sql, between).fetchall()\n        levels = _get_levels(result)\n\n        users = []\n        for num, item in enumerate(result, start=1):\n            if item[3] == \"1234567890\":\n                continue\n\n            users.append(\n                UserBasic(\n                    position=num,\n                    rating=item[0],\n                    name=item[2],\n                    id=item[3],\n                    level=levels[num - 1],\n                )\n            )\n\n        return PosterTop(\n            users=users,\n            column=column,\n            users_count=len(users),\n            from_=between[0],\n            to_=between[1],\n            min_posts=min_posts,\n        )\n\n    def get_top_card(\n        self, column=\"impressions\", between=(None, None), min_posts=7\n    ) -> UserBasic:\n        top = self.get_top(column, between, min_posts)\n        users = top.users\n        try:\n            return [user for user in users if user.id == self.user_id][0]\n        except IndexError:\n            raise NothingFound(\n                f\"User not found in top. Requirements are at least {min_posts} posts between {between}\"\n            )\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self._conn.close()\n\n    def close(self):\n        self._conn.close()\n"}
{"type": "source_file", "path": "kinobot/infra/__init__.py", "content": "import functools\nfrom typing import Callable, Optional, Type\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\nfrom kinobot.config import config\nfrom kinobot.exceptions import KinoException\n\n\ndef maker():\n    engine = create_engine(config.infra.sqlalchemy_url)\n    return sessionmaker(bind=engine)\n\n\nclass DuplicateError(KinoException):\n    pass\n\n\ndef translate_exc(\n    exc_cls: Type[Exception],\n    output_exc_cls: Type[Exception] = KinoException,\n    checker: Optional[Callable] = None,\n    output_maker: Optional[Callable] = None,\n):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except exc_cls as e:\n                if checker is not None:\n                    if checker(e):\n                        raise output_exc_cls((output_maker or str)(e)) from e\n                else:\n                    raise\n\n        return wrapper\n\n    return decorator\n"}
{"type": "source_file", "path": "kinobot/discord/review.py", "content": "import asyncio\n\nfrom discord.ext.commands import Context\nfrom discord.file import File\n\nfrom kinobot.request import Request\nfrom kinobot.user import User\n\n\nasync def review(ctx: Context):\n    requests = Request.randoms_from_queue(verified=True)\n    loop = asyncio.get_event_loop()\n\n    for request in requests:\n        await ctx.send(f\"Loading request [{request.id}]...\")\n\n        try:\n            handler = await loop.run_in_executor(None, request.get_handler)\n            images = await loop.run_in_executor(None, handler.get)\n        except Exception as error:\n            await ctx.send(f\"{type(error).__name__} raised\")\n            await ctx.send(str(request.id))\n            await ctx.send(f\"{'x'*20}\\nNEXT\\n{'x'*20}\")\n            continue\n\n        user = User(id=request.user_id)\n        user.load(register=True)\n        msg = f\"**{user.name}**\\nRequest title: **{request.facebook_pretty_title}**\\nPost title: **{handler.title}**\\nID:\"\n\n        await ctx.send(msg)\n        await ctx.send(str(request.id))\n\n        for image in images:\n            await ctx.send(file=File(image))\n\n        await ctx.send(f\"{'x'*20}\\nNEXT\\n{'x'*20}\")\n\n    await ctx.send(\n        \"Please check carefully titles, usernames, quotes and images.\\nDelete any offending requests with !delete <ID>.\"\n    )\n"}
{"type": "source_file", "path": "kinobot/instagram/models.py", "content": "from datetime import datetime\nfrom datetime import timedelta\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Label(BaseModel):\n    id: int\n    verdict: str\n    request_id: int\n    user_id: str\n\n    class Config:\n        orm_mode = True\n\n\nclass Schedule(BaseModel):\n    id: int\n    request_id: int\n    start_time: datetime\n    expiration: timedelta\n\n    class Config:\n        orm_mode = True\n\n\nclass Ticket(BaseModel):\n    id: int\n    user_id: int\n    used: bool\n    added: datetime\n    expires_in: timedelta\n\n    class Config:\n        orm_mode = True\n\n\nclass User(BaseModel):\n    id: str\n    name: str\n    role: Optional[str] = None\n    source: Optional[str] = None\n    # requests: List[Request] = []\n\n    class Config:\n        orm_mode = True\n\n\nclass Request(BaseModel):\n    id: str\n    content: str\n    user_id: str\n    added: datetime\n    schedules: List[Schedule] = []\n    labels: List[Label] = []\n    user: User\n    verified: bool = False\n    used: bool = False\n\n    class Config:\n        orm_mode = True\n\n\nclass Post(BaseModel):\n    id: int\n    request: Request\n    added: datetime\n    ig_id: str\n\n    class Config:\n        orm_mode = True\n\n\nclass MediaItem(BaseModel):\n    id: str\n    pretty_title: str\n    simple_title: str\n    parallel_title: str\n    sub_title: Optional[str] = None\n    keywords: List[str] = []\n    type: str\n\n    class Config:\n        orm_mode = True\n\n\nclass RequestData(BaseModel):\n    type: str\n    comment: str\n\n    class Config:\n        orm_mode = True\n\n\nclass FinishedRequest(BaseModel):\n    media_items: List[MediaItem]\n    request_data: RequestData\n    image_uris: List[str]\n\n    def multiple_images(self):\n        return len(self.image_uris) > 1\n"}
{"type": "source_file", "path": "kinobot/discord/jackpot.py", "content": "from kinobot.config import config\nfrom kinobot.infra import misc\nfrom kinobot.misc import jackpot\nfrom kinobot.utils import send_webhook\nfrom kinobot.infra import misc as infra_misc\n\n\ndef _format_number(num: int) -> str:\n    if num < 1000:\n        return str(num)\n    elif num < 1_000_000:\n        return f\"{num / 1_000:.1f}\".rstrip(\"0\").rstrip(\".\") + \"k\"\n    elif num < 1_000_000_000:\n        return f\"{num / 1_000_000:.1f}\".rstrip(\"0\").rstrip(\".\") + \"M\"\n    else:\n        return f\"{num / 1_000_000_000:.1f}\".rstrip(\"0\").rstrip(\".\") + \"B\"\n\n\ndef get_yearly_top(user_id, user_name):\n    results = infra_misc.get_top_posts_by_impressions_current_year(user_id, limit=15)\n    if not results:\n        return None\n\n    def _one_line(item):\n        return f\"{item.facebook_url} (**{_format_number(item.impressions)}** views)\"\n\n    lines = \"\\n\".join([_one_line(i) for i in results])\n\n    return f\"{user_name}'s TOP POSTS from 2024\\n\\n{lines}\"\n\n\ndef add_payout(user_id, amount):\n    misc.add_payout(user_id, amount=amount)\n    return misc.get_bonus_balance_dict(user_id)\n\n\ndef give_jackpot():\n    def callback(jackpot, winner):\n        misc.add_money_bonus(\n            winner[\"user_id\"], winner[\"id\"], jackpot * 100, key=\"jackpot\"\n        )\n        send_webhook(\n            config.webhooks.announcer,\n            f\"**{winner['name']}** JUST WON YESTERDAY'S JACKPOT: **${round(jackpot, 3)}** ðŸ¤‘\",\n        )\n\n    jackpot.give(callback)\n\n\ndef get_current_jackpot():\n    current = jackpot.get_current_day_jackpot()\n    send_webhook(\n        config.webhooks.announcer, f\"Current day's jackpot: **${round(current, 3)}** ðŸ¤‘\"\n    )\n"}
{"type": "source_file", "path": "kinobot/infra/_orm.py", "content": "import datetime\nimport enum\n\nfrom sqlalchemy import JSON, Boolean, DateTime, Integer\nfrom sqlalchemy import Column\nfrom sqlalchemy import Date\nfrom sqlalchemy import Enum\nfrom sqlalchemy import ForeignKey\nfrom sqlalchemy import String\nfrom sqlalchemy import Table\nfrom sqlalchemy import Text\nfrom sqlalchemy import UniqueConstraint\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\n# Define the database model\nBase = declarative_base()\n\n\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(String, primary_key=True)\n    name = Column(Text, nullable=False)\n    role = Column(String, default=\"Unknown\")\n    source = Column(String, default=\"Unknown\")\n\n\nclass Request(Base):\n    __tablename__ = \"requests\"\n    id = Column(String, primary_key=True)\n    user_id = Column(String, ForeignKey(\"users.id\"), nullable=False)\n    comment = Column(Text, nullable=False)\n    type = Column(String, nullable=False)\n    used = Column(Boolean, default=False, nullable=False)\n    verified = Column(Boolean, default=False, nullable=False)\n    music = Column(Boolean, default=False, nullable=False)\n    added = Column(DateTime, default=lambda: datetime.date.today(), nullable=False)\n    language = Column(String, default=\"en\", nullable=False)\n    data = Column(JSON, nullable=True, default=dict)\n\n    user = relationship(\"User\", lazy=False)\n\n\nuser_collab = Table(\n    \"user_collab\",\n    Base.metadata,\n    Column(\"user_id\", String, ForeignKey(\"users.id\")),\n    Column(\"request_id\", String, ForeignKey(\"requests.id\")),\n    UniqueConstraint(\"user_id\", \"request_id\", name=\"uq_user_collab\"),\n)\n\n\nclass PostComplete(Base):\n    __tablename__ = \"post_complete\"\n\n    id = Column(String, primary_key=True)\n    request_id = Column(String, ForeignKey(\"requests.id\"))\n    insights = Column(JSON, default=dict)\n    page = Column(String)\n    added = Column(DateTime, default=lambda: datetime.datetime.now(), nullable=False)\n\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n\n    id = Column(String, primary_key=True, nullable=False)\n    added = Column(DateTime, server_default=\"CURRENT_TIMESTAMP\", nullable=False)\n    request_id = Column(String, ForeignKey(\"requests.id\"))\n    shares = Column(Integer, default=0)\n    comments = Column(Integer, default=0)\n    impressions = Column(Integer, default=0)\n    other_clicks = Column(Integer, default=0)\n    photo_view = Column(Integer, default=0)\n    engaged_users = Column(Integer, default=0)\n    haha = Column(Integer, default=0)\n    like = Column(Integer, default=0)\n    love = Column(Integer, default=0)\n    sad = Column(Integer, default=0)\n    angry = Column(Integer, default=0)\n    wow = Column(Integer, default=0)\n    care = Column(Integer, default=0)\n    last_scan = Column(DateTime, server_default=\"CURRENT_TIMESTAMP\")\n    request: Mapped[\"Request\"] = relationship()\n\n\nclass UserMoneyBonus(Base):\n    __tablename__ = \"user_money_bonus\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n    user_id: Mapped[str]\n    amount: Mapped[int]\n    post_id: Mapped[str]\n    added = Column(DateTime, default=lambda: datetime.date.today(), nullable=False)\n\n\n#    __table_args__ = (UniqueConstraint(\"user_id\", \"post_id\", name=\"umbp_constraint\"),)\n\n\nclass UserPayout(Base):\n    __tablename__ = \"user_payout\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n    user_id: Mapped[str]\n    amount: Mapped[int]\n    added = Column(DateTime, default=lambda: datetime.date.today(), nullable=False)\n\n\nclass UserEmby(Base):\n    __tablename__ = \"user_emby\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n    user_id: Mapped[str]\n    data = Column(JSON, nullable=False)\n\n\nclass _CuratorKey:\n    __tablename__ = \"curator_keys\"\n\n    user_id = Column(String, primary_key=True)\n    size = Column(Integer, default=0)\n    added = Column(DateTime, default=datetime.datetime.now())\n    note = Column(Text, default=\"\")\n    days_expires_in = Column(Integer, default=90)\n\n\nclass UserVideoToken(Base):\n    __tablename__ = \"user_video_token\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n    user_id: Mapped[str]\n    amount: Mapped[int]\n    added = Column(DateTime, default=lambda: datetime.date.today(), nullable=False)\n\n\nclass TransactionType(enum.Enum):\n    CREDIT = \"credit\"\n    DEBIT = \"debit\"\n\n\nclass VideoTokenTransaction(Base):\n    __tablename__ = \"video_token_transactions\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n    user_id: Mapped[str]\n    amount: Mapped[int]\n    transaction_type: Mapped[TransactionType] = mapped_column(Enum(TransactionType))\n    description: Mapped[str] = mapped_column(String(255))\n    timestamp = Column(\n        DateTime, default=lambda: datetime.datetime.now(), nullable=False\n    )\n"}
{"type": "source_file", "path": "kinobot/discord/oldies.py", "content": "import datetime\nimport sqlite3\nfrom typing import Tuple\n\nimport pydantic\n\nfrom kinobot.constants import KINOBASE\n\n\nclass Oldie(pydantic.BaseModel):\n    request_id: str\n    comment: str\n    added: datetime.datetime\n    impressions: int\n    engaged_users: int\n    shares: int\n    type: str\n\n    @property\n    def content(self):\n        if not self.comment.startswith(\"!\"):\n            return f\"{self.type} {self.comment}\"\n\n        return self.comment\n\n    def __str__(self) -> str:\n        return f\"content='{self.content}' \" + super().__str__()\n\n\nclass Repo:\n    def __init__(self, path) -> None:\n        self._path = path\n\n    def get(\n        self,\n        from_: Tuple[str, str],\n        to_: Tuple[str, str],\n        limit=100,\n        random=True,\n    ):\n        with sqlite3.connect(self._path) as conn:\n            items = conn.execute(\n                (\n                    \"SELECT r.id,r.comment,r.added,p.engaged_users,p.impressions,p.shares,r.type FROM requests r JOIN (SELECT * FROM posts WHERE \"\n                    \"added BETWEEN datetime(?,?) AND datetime(?,?) ORDER BY \"\n                    \"engaged_users DESC LIMIT ?) p ON r.id = p.request_id ORDER BY RANDOM();\"\n                ),\n                (\n                    *from_,\n                    *to_,\n                    limit,\n                ),\n            ).fetchall()\n\n        oldies = []\n        for i in items:\n            oldies.append(\n                Oldie(\n                    request_id=i[0],\n                    comment=i[1],\n                    added=i[2],\n                    engaged_users=i[3],\n                    impressions=i[4],\n                    shares=i[5],\n                    type=i[6],\n                )\n            )\n\n        return oldies\n\n    @classmethod\n    def from_constants(cls):\n        return cls(KINOBASE)\n"}
{"type": "source_file", "path": "kinobot/discord/wrapped.py", "content": "import asyncio\nimport requests\nimport hashlib\nimport logging\nimport os\nimport tempfile\n\nfrom discord import File\n\nfrom kinobot.db import sql_to_dict\nfrom kinobot.discord.extras.curator_user import Curator\nfrom kinobot.discord.extras.verification import UserDB\nfrom kinobot.misc import wrapped, poster\nfrom kinobot.utils import download_image\n\nfrom .utils import call_with_typing\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass NoData(Exception):\n    pass\n\n\ndef _download_pp(user_id, url):\n    path = os.path.join(tempfile.gettempdir(), f\"wrapped_{user_id}\")\n    if os.path.exists(path):\n        return path\n\n    return download_image(url, path)\n\n\ndef make_wrapped(user_id, name=\"Unknown\", profile_picture=\"\", all_time=False):\n    data = dict()\n\n    data[\"name\"] = name\n    data[\"profile_picture\"] = _download_pp(user_id, profile_picture)\n\n    t_user = UserDB(user_id)\n    data[\"tickets\"] = len(t_user.available_tickets())\n\n    curator_user = Curator(user_id)\n    data[\"bytes\"] = curator_user.size_left()\n    curator_user.close()\n\n    added_movies = sql_to_dict(\n        None,\n        wrapped.MOVIE_ADDITIONS_COUNT if not all_time else wrapped.MOVIE_ADDITIONS_ALL,\n        (user_id,),\n    )\n    try:\n        data.update(added_movies[0])\n    except IndexError:\n        pass\n\n    stats = sql_to_dict(\n        None,\n        wrapped.POST_STATS_SQL if not all_time else wrapped.POST_STATS_SQL_ALL,\n        (user_id,),\n    )\n    try:\n        data.update(stats[0])\n    except IndexError:\n        pass\n\n    data = {k: v for k, v in data.items() if v is not None}\n    data[\"title\"] = \"#Wrapped\" if all_time else None\n\n    wrapped_ = wrapped.Wrapped.parse_obj(data)\n\n    img = wrapped.make(wrapped_)\n\n    with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as tf:\n        img.save(tf.name)\n        return tf.name\n\n\nasync def make(ctx, user_id, name, profile_picture, all_time=False):\n    loop = asyncio.get_event_loop()\n    img = await call_with_typing(\n        ctx, loop, make_wrapped_2, user_id, name, profile_picture, all_time\n    )\n    with open(img, \"rb\") as file:\n        await ctx.send(file=File(file, filename=os.path.basename(img)))\n\n    try:\n        os.remove(img)\n    except:\n        pass\n\n\n# 2024\nSQL_TOP_MOVIE = \"\"\"SELECT\n    m.id AS id,\n    m.title AS title, m.poster as poster,\n    COUNT(p.id) AS post_count\nFROM\n    users u\nJOIN\n    requests r ON u.id = r.user_id\nJOIN\n    posts p ON r.id = p.request_id\nJOIN\n    movie_posts mp ON p.id = mp.post_id\nJOIN\n    movies m ON mp.movie_id = m.id\nWHERE\n    u.id = ?\n    AND strftime('%Y', p.added) = '2024'\n    AND r.comment NOT LIKE '%!swap%'\nGROUP BY\n    m.id, m.title\nORDER BY\n    post_count DESC\"\"\"\n\n# AND strftime('%Y', p.added) = strftime('%Y', 'now')\n\nSQL_TOP_TV = \"\"\" SELECT\n    ts.id AS id,\n    ts.name AS title, ts.poster_path as poster,\n    COUNT(p.id) AS post_count\nFROM\n    users u\nJOIN\n    requests r ON u.id = r.user_id\nJOIN\n    posts p ON r.id = p.request_id\nJOIN\n    episode_posts ep ON p.id = ep.post_id\nJOIN\n    episodes e ON ep.episode_id = e.id\nJOIN\n    tv_shows ts ON e.tv_show_id = ts.id\nWHERE\n    u.id = ?\n    AND strftime('%Y', p.added) = '2024'\n    AND r.comment NOT LIKE '%!swap%'\nGROUP BY\n    ts.id\nORDER BY\n    post_count DESC\"\"\"\n\nIMG_BASE = \"https://image.tmdb.org/t/p/original\"\n\n\ndef _get_posters(items):\n    posters = []\n    for item in items:\n        if not item[\"poster\"]:\n            continue\n\n        if not item[\"poster\"].startswith(\"https\"):\n            poster_path = IMG_BASE + item[\"poster\"]\n        else:\n            poster_path = item[\"poster\"]\n\n        posters.append(poster_path)\n\n    return posters\n\n\ndef _download_image(url, cache_dir=\"/tmp\", retries=2):\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    file_name = hashlib.md5(url.encode()).hexdigest() + \".jpg\"\n    file_path = os.path.join(cache_dir, file_name)\n    failed_marker = os.path.join(cache_dir, file_name + \".failed\")\n\n    if os.path.exists(failed_marker):\n        logger.debug(f\"Image has failed previously, skipping: {url}\")\n        return None\n\n    if os.path.exists(file_path):\n        logger.debug(f\"Image already cached: {file_path}\")\n        return file_path\n\n    for attempt in range(retries + 1):\n        try:\n            logger.debug(f\"Downloading {url}, Attempt {attempt + 1}\")\n            response = requests.get(url, stream=True)\n            response.raise_for_status()\n\n            with open(file_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n\n            logger.debug(f\"Image downloaded and cached at: {file_path}\")\n            return file_path\n\n        except requests.exceptions.RequestException as e:\n            logger.error(f\"Error downloading the image on attempt {attempt + 1}: {e}\")\n            if attempt == retries:\n                with open(failed_marker, \"w\") as f:\n                    f.write(\"failed\\n\")\n                logger.error(\n                    f\"Image failed to download after {retries + 1} attempts: {url}\"\n                )\n\n    return None\n\n\ndef _get_top_media(user_id):\n    movies = sql_to_dict(None, SQL_TOP_MOVIE, (user_id,))\n    tv_shows = sql_to_dict(None, SQL_TOP_TV, (user_id,))\n\n    sorted_combined_list = sorted(\n        movies + tv_shows, key=lambda x: x[\"post_count\"], reverse=True\n    )\n\n    posters = _get_posters(sorted_combined_list)\n    finished = []\n    for poster in posters[:6]:\n        path = _download_image(poster, \"/tmp\")\n        finished.append(path)\n\n    try:\n        top_movie = movies[0][\"title\"]\n    except:\n        top_movie = \"N/A\"\n\n    try:\n        top_tv_show = tv_shows[0][\"title\"]\n    except:\n        top_tv_show = \"N/A\"\n\n    return dict(poster_paths=finished, top_movie=top_movie, top_tv_show=top_tv_show)\n\n\ndef _truncate_title(title, max_length=19):\n    if len(title) > max_length:\n        return title[: max_length - 3] + \"...\"\n\n    return title\n\n\ndef make_wrapped_2(user_id, name=\"Unknown\", profile_picture=\"\", all_time=False):\n    data = dict()\n\n    data[\"name\"] = name\n\n    t_user = UserDB(user_id)\n    data[\"tickets\"] = len(t_user.available_tickets())\n\n    curator_user = Curator(user_id)\n    data[\"bytes\"] = curator_user.size_left()\n    curator_user.close()\n\n    stats = sql_to_dict(\n        None,\n        wrapped.POST_STATS_SQL if not all_time else wrapped.POST_STATS_SQL_ALL,\n        (user_id,),\n    )\n    try:\n        data.update(stats[0])\n    except IndexError:\n        pass\n\n    try:\n        top_media = _get_top_media(user_id)\n    except Exception as error:\n        logger.exception(error)\n        raise NoData(\"No media data\") from error\n\n    poster_d = poster.KinoReview(\n        header=data[\"name\"],\n        sub_header=\"Kino'24\",\n        poster_paths=list(top_media[\"poster_paths\"]),\n        title=\"2024\",\n        place_1=(_truncate_title(top_media[\"top_movie\"]), \"Top Posted Movie\"),\n        place_2=(_truncate_title(top_media[\"top_tv_show\"]), \"Top Posted Series\"),\n        place_3=(poster.format_number(data[\"views\"]), \"Views\"),\n        place_4=(poster.format_number(data[\"total_posts\"]), \"Total Posts\"),\n        place_5=(poster.format_bytes(data[\"bytes\"]), \"Buffer\"),\n        place_6=(poster.format_number(data[\"tickets\"]), \"Tickets\"),\n    )\n\n    try:\n        img = poster.make(poster_d)\n    except ZeroDivisionError:\n        raise NoData\n\n    with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as tf:\n        img.save(tf.name)\n        return tf.name\n"}
{"type": "source_file", "path": "kinobot/discord/video.py", "content": "from contextlib import contextmanager\nfrom typing import Any\nfrom kinobot.infra import misc\nfrom kinobot.request import VideoRequest\nimport logging\nimport asyncio\nfrom discord import File\nimport os\nfrom .utils import call_with_typing\nimport tempfile\n\nfrom kinobot.sources import video\nfrom discord.ext import commands\n\nlogger = logging.getLogger(__name__)\n\n\ndef _is_file_too_large(file_path, max_size_mb=8):\n    max_size_bytes = max_size_mb * 1024 * 1024\n    return os.path.getsize(file_path) > max_size_bytes\n\n\nasync def make(ctx: commands.Context, args):\n    def _make():\n        req = VideoRequest.from_discord(args, ctx)  # type: VideoRequest\n        no_subs = req.args.get(\"no_subs\", False)\n        data = req.compute()\n\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".srt\", mode=\"w\") as tf:\n            to_write = video.make_subs(data)\n            tf.writelines(to_write)\n\n        if not to_write or no_subs:\n            subtitle_file = None\n        else:\n            subtitle_file = tf.name\n\n        multiple = len(data) > 1\n\n        clips = []\n        for d in data:\n            instance = video.ClipExtractor(d[\"path\"])\n\n            if multiple:\n                subtitle_input = None\n            else:\n                subtitle_input = subtitle_file\n\n            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as tf:\n                instance.extract_clip(\n                    d[\"start_ms\"], d[\"end_ms\"], tf.name, subtitle_file=subtitle_input\n                )\n                if _is_file_too_large(tf.name):\n                    raise ValueError(\"File is too large\")\n\n                clips.append(tf.name)\n\n        def remove_subs():\n            if subtitle_file is not None:\n                try:\n                    os.remove(subtitle_file)\n                except:\n                    pass\n\n        if len(clips) < 2:\n            remove_subs()\n            return clips[0]\n\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as tf:\n            video.concatenate_videos(clips, tf.name, subtitle_file=subtitle_file)\n\n            for clip in clips:\n                try:\n                    os.remove(clip)\n                except:\n                    pass\n\n            remove_subs()\n            return tf.name\n\n    loop = asyncio.get_event_loop()\n\n    result = await call_with_typing(ctx, loop, _make)\n    try:\n        await ctx.send(\"Here is your video! ðŸŽ¥\")\n        await ctx.send(file=File(result))\n    except Exception as e:\n        logger.error(e)\n        await ctx.send(f\"Failed to upload video: {e}\")\n    finally:\n        os.remove(result)\n\n\nclass NoBalance(Exception):\n    pass\n\n\nasync def give_tokens(ctx: commands.Context, user: Any, amount: int):\n    misc.add_token_transaction(user.id, amount, \"CREDIT\")\n    balance = misc.get_user_token_balance(user.id)\n    msg = f\"Credit of {amount} video tokens. New balance: {balance}\"\n    await ctx.send(msg)\n\n\nasync def remove_tokens(ctx: commands.Context, user: Any, amount: int):\n    misc.add_token_transaction(user.id, amount, \"DEBIT\")\n    balance = misc.get_user_token_balance(user.id)\n    msg = f\"DEBIT of {amount} video tokens. New balance: {balance}\"\n    await ctx.send(msg)\n\n\nasync def get_balance(ctx: commands.Context, user: Any):\n    balance = misc.get_user_token_balance(user.id)\n    await ctx.send(f\"Your token balance is **{balance}**\")\n\n\n@contextmanager\ndef deduct_token(user_id):\n    balance = misc.get_user_token_balance(user_id)\n    if balance < 1:\n        raise NoBalance(\"Insufficient balance to deduct credit.\")\n\n    misc.add_token_transaction(user_id, 1, \"DEBIT\", \"Default\")\n\n    yield balance\n"}
{"type": "source_file", "path": "kinobot/discord/oldies_chamber.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport asyncio\nimport datetime\nimport locale\nimport logging\nfrom typing import Dict\n\nfrom discord import File\nfrom discord.ext import commands\n\nfrom . import oldies\nfrom ..db import Execute\nfrom ..db import sql_to_dict\nfrom ..exceptions import KinoException\nfrom ..exceptions import KinoUnwantedException\nfrom ..exceptions import MovieNotFound\nfrom ..exceptions import TempUnavailable\nfrom ..media import Movie\nfrom ..request import get_cls\nfrom ..user import User\nfrom ..utils import handle_general_exception\nfrom ..utils import send_webhook\nfrom .common import get_req_id_from_ctx\n\n_GOOD_BAD_NEUTRAL_EDIT = (\"ðŸ‡¼\", \"ðŸ‡±\", \"ðŸ§Š\", \"âœï¸\")\n_ICE_DELAY = datetime.timedelta(days=1)\n\n\nlogger = logging.getLogger(__name__)\n\n\ndef _custom_movie(req_cls, query, *args, **kwargs):\n    sql1 = (\n        \"select movies.id as id from movies join movie_credits on movie_credits.movie_id == movies.id \"\n        \"join people on people.id=movie_credits.people_id where people.name like ? group by movies.id\"\n    )\n    ids = [i[\"id\"] for i in sql_to_dict(None, sql1, (f\"%{query}%\",))]\n\n    try:\n        movie = Movie.from_query(query)\n    except Exception as error:\n        if not ids:\n            raise\n    else:\n        ids.append(str(movie.id))\n\n    if not ids:\n        raise MovieNotFound\n\n    marks = (\"?,\" * len(ids)).rstrip(\",\")\n\n    sql = (\n        \"select requests.id as request_id, posts.engaged_users as engaged from requests left join posts\"\n        \" on posts.request_id=requests.id left join movie_posts on movie_posts.post_id=posts.id \"\n        f\"where movie_posts.movie_id in ({marks}) order by posts.engaged_users desc\"\n    )\n    return sql_to_dict(None, sql, tuple(ids))\n\n\ndef _log(req_id):\n    Execute()._execute_sql(\"insert into chamber_log (request_id) values (?)\", (req_id,))\n\n\ndef _is_available(req_id):\n    items = sql_to_dict(None, \"select * from chamber_log where request_id=?\", (req_id,))\n    if items:\n        return False\n\n    return True\n\n\ndef _older(*args):\n    # fixme\n    msg = \"[{self._tag}] Give the range of dates\\nFormat: START_FROM, START_TO, END_FROM, END_TO\\nExample: now, -1 year, now, -6 months\"\n    args = [a.strip() for a in str(msg.content).split(\",\")]\n\n\n_FACTORIES = {\"custom_movie\": _custom_movie}\n\n\nclass OldiesChamber:\n    \"Class for the verification chamber used in the admin's Discord server.\"\n\n    def __init__(\n        self,\n        bot: commands.Bot,\n        ctx: commands.Context,\n        tag=None,\n        request_factory=\"custom_movie\",\n    ):\n        self._tag = tag\n        self.bot = bot\n        self.ctx = ctx\n        self._request_factory = request_factory\n        self._factory = _FACTORIES[request_factory]\n        self._user_roles = [role.name for role in ctx.author.roles]\n        self._user_id = str(ctx.author.id)  # type: ignore\n        self._identifier = get_req_id_from_ctx(ctx)\n        self._req_cls = get_cls(self._identifier)\n        self._req = None\n        self._seen_ids = set()\n        self._images = []\n        self._rejected = []\n        self._verified = []\n        self._iced = []\n        self._edited = []\n\n        logger.debug(\"Req class: %s\", self._req_cls)\n\n    async def _get_msg(self):\n        try:\n            message = await self.bot.wait_for(\n                \"message\", timeout=300, check=self._check_msg(self.ctx.author)\n            )\n            return message\n        except asyncio.TimeoutError:\n            await self.ctx.send(\"Timeout!\")\n            return None\n\n    async def _take_args(self):\n        await self.ctx.send(\n            f\"[{self._tag}] [{self._request_factory}] Give me the query for this factory.\"\n        )\n        user_msg = await self._get_msg()\n        if user_msg is None:\n            return None\n\n        return str(user_msg.content).strip()\n\n    async def start(self):\n        \"Start the chamber loop.\"\n        args = await self._take_args()\n        if not args:\n            return await self.ctx.send(\"Bye.\")\n\n        self._items = self._factory(self._req_cls, args)\n        if not self._items:\n            return await self.ctx.send(\"Nothing found.\")\n\n        exc_count = 0\n\n        for item in self._items:\n            if exc_count > 10:\n                await self.ctx.send(\"Exception count exceeded. Breaking loop.\")\n                break\n\n            if not await self._loaded_req(item):\n                exc_count += 1\n                continue\n\n            exc_count = 0\n\n            await self._send_info()\n\n            try:\n                await self._verdict()\n            except asyncio.TimeoutError:\n                break\n\n            if not await self._continue():\n                break\n\n        await self.ctx.send(\"Chamber loop finished\")\n\n        # self._send_webhook()\n\n    async def _loaded_req(self, item: Dict) -> bool:\n        \"\"\"\n        Load the request and the handler. Send the exception info if the\n        handler fails.\n\n        raises exceptions.NothingFound\n        \"\"\"\n        self._req = self._req_cls.from_db_id(item[\"request_id\"])\n        self._metadata = item\n\n        if str(self._req.user.id) == self._user_id:\n            logger.debug(\"Ignoring own request\")\n            return False\n\n        if _is_available(self._req.id) is False:\n            logger.debug(\"Request was already logged\")\n            return False\n\n        if self._req.id in self._seen_ids:\n            return False\n\n        _log(self._req.id)\n        self._seen_ids.add(self._req.id)\n\n        return await self._process_req()\n\n    async def _handle_iced(self):\n        assert self._req is not None\n\n        ices = self._req.get_ices()\n\n        if ices:\n            logger.debug(\"Ices: %s\", ices)\n            if len(ices) > 5:\n                await self.ctx.send(\n                    f\"`{self._req.comment}` has been already iced {len(ices)} times. Marking as used.\"\n                )\n                self._req.mark_as_used()\n                return False\n\n            last_ice = ices[-1]\n            if last_ice[\"ago\"] > _ICE_DELAY:\n                await self.ctx.send(\n                    f\"Skipping recently iced request: {last_ice} ({len(ices)} ices) [Ice delay: {_ICE_DELAY}]\"\n                )\n                return False\n        else:\n            logger.debug(\"This request doesn't have any ices registered\")\n\n        return True\n\n    async def _process_req(self, raise_kino_exception=False):\n        loop = asyncio.get_running_loop()\n\n        async with self.ctx.typing():\n            try:\n                handler = await loop.run_in_executor(None, self._req.get_handler)\n                self._images = await loop.run_in_executor(None, handler.get)\n                risk = self._req.facebook_risk()\n\n                if risk is not None:\n                    await self.ctx.send(\n                        f\"WARNING: Facebook risk: `{risk}`.\\n\\nPLEASE BE CAREFUL! \"\n                        \"DON'T GET THE PAGE BANNED!\"\n                    )\n\n                return True\n\n            except KinoUnwantedException as error:\n                await self.ctx.send(self._format_exc(error))\n                self._req.mark_as_used()\n\n            except TempUnavailable:\n                await self.ctx.send(\"TempUnavailable\")\n\n            except KinoException as error:\n                await self.ctx.send(self._format_exc(error))\n\n                if raise_kino_exception:\n                    raise\n\n                self._req.mark_as_used()\n\n            except Exception as error:  # Fatal\n                handle_general_exception(error)\n                await self.ctx.send(\n                    f\"**Fatal!!!** {self._format_exc(error)}. \"\n                    \"**Marking as used. REPORT ADMIN if you see this error too often!!!**\"\n                )\n\n                self._req.mark_as_used()\n\n            return False\n\n    async def _send_info(self):\n        \"Send the request metadata and the images.\"\n        user = User(id=self._req.user_id)\n        user.load(register=True)\n\n        message = None\n        metadata = f\"metadata: {self._metadata}\"\n        await self.ctx.send(\n            f\"**{user.name} ({self._req.time_ago})**: {self._req.pretty_title}\\n\\n{metadata}\"\n        )\n        await self.ctx.send(f\"{self._req.id}\")\n\n        for image in self._images:\n            logger.info(\"Sending image: %s\", image)\n            message = await self.ctx.send(file=File(image))\n\n        assert [await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT]\n\n    def _check_recurring_user(self):\n        if self._verified.count(self._req.user.name) >= 2:\n            logger.debug(\"%s has already two verified requests\", self._req.user)\n            return True\n\n        return False\n\n    async def _verdict(self):\n        \"raises asyncio.TimeoutError\"\n        await self.ctx.send(\n            \"You got 120 seconds to react to the last image. React \"\n            \"with the ice cube to deal with the request later; react with \"\n            \"the pencil to append flags to the request.\"\n        )\n\n        reaction, user = await self.bot.wait_for(\n            \"reaction_add\", timeout=120, check=self._check_react\n        )\n        assert user\n\n        if str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[0]):\n            if str(self._req.user.id) == self._user_id:\n                await self.ctx.send(\"You can't verify your own request.\")\n            else:\n                cloned = self._req.clone()\n                self._req = cloned\n                self._req.verify()\n\n                if self._tag is not None:\n                    self._req.add_tag(self._tag)\n\n                self._log_user(verified=True)\n                await self._take_reason(True)\n                await self.ctx.send(\"Verified.\")\n\n        elif str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[1]):\n            # self._req.mark_as_used()\n            # self._log_user()\n            # await self._take_reason(False)\n            await self.ctx.send(\"Marked as used.\")\n\n        elif str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[3]):\n            if not await self._edit_loop():\n                await self.ctx.send(\"Ignored\")\n            else:\n                await self._verdict()\n        else:\n            self._req.register_ice()\n            self._log_user(iced=True)\n            await self.ctx.send(\"Ignored.\")\n\n    async def _take_reason(self, verified: bool):\n        self._req.register_verifications([self.ctx.author.id], verified, \"automatic\")\n\n    def _check_msg_author(self, author):\n        return lambda message: str(message.author.id) == str(self.ctx.author.id)\n\n    def _check_msg(self, author):\n        return lambda message: str(message.author.id) == str(self.ctx.author.id)\n\n    async def _edit_loop(self):\n        while True:\n            edited = await self._edit_req()\n            if not edited:\n                await self.ctx.reply(\"Bad input.\")\n                return False\n\n            # Send the request\n            try:\n                processed = await self._process_req(raise_kino_exception=True)\n            except KinoException:\n                continue\n            else:\n                if not processed:\n                    return False\n                else:\n                    await self._send_info()\n                    return True\n\n    async def _edit_req(self):\n        await self.ctx.send(\n            \"Type the flags you want to append. Type 'no' to cancel. \"\n            \"Type 'reset' to remove all global flags set.\"\n        )\n        try:\n            message = await self.bot.wait_for(\n                \"message\", timeout=300, check=_check_msg_author(self.ctx.author)\n            )\n\n            if message.content.lower() == \"no\":\n                return False\n\n            if message.content.lower() == \"reset\":\n                self._req.reset_global_flags()\n                self._req.update()\n                return True\n\n            if self._req.edited:\n                self._req.reset_append()\n\n            self._req.append_text(str(message.content))\n\n            return True\n\n        except asyncio.TimeoutError:\n            return False\n\n    async def _continue(self) -> bool:\n        queued = Execute().queued_requets(table=self._req_cls.table)\n        message = await self.ctx.send(\n            f\"Continue in the chamber of {self._req_cls.table}? ({queued} verified).\"\n        )\n        assert [\n            await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT[:2]\n        ]\n\n        try:\n            reaction, user = await self.bot.wait_for(\n                \"reaction_add\", timeout=30, check=self._check_react\n            )\n            assert user\n\n            if str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[0]):\n                return True\n\n            await self.ctx.send(\"Bye.\")\n            return False\n\n        except asyncio.TimeoutError:\n            await self.ctx.send(\"Timeout. Exiting...\")\n            return False\n\n    def _check_react(self, reaction, user):\n        assert reaction\n        return user == self.ctx.author\n\n    def _log_user(self, verified: bool = False, edited=False, iced=False):\n        user = User(id=self._req.user_id)  # Temporary\n        user.load(register=True)\n\n        if iced:\n            self._iced.append(user.name)\n            return None\n\n        if verified:\n            self._verified.append(user.name)\n        else:\n            self._rejected.append(user.name)\n\n        if edited:\n            self._edited.append(user.name)\n\n    def _verdict_author(self):\n        return self.ctx.author.display_name\n\n    def _send_webhook(self):\n        msgs = [\n            f\"`{self._verdict_author()}` verdict for oldies chamber {self._identifier}:\"\n        ]\n\n        if self._verified:\n            msgs.append(\n                f\"Authors with **verified** requests: `{_user_str_list(self._verified)}`\"\n            )\n\n        if self._rejected:\n            msgs.append(\n                f\"Authors with **rejected** requests: `{_user_str_list(self._rejected)}`\"\n            )\n\n        if self._iced:\n            msgs.append(\n                f\"Authors with **iced (skipped)** requests: `{_user_str_list(self._iced)}`\"\n            )\n\n        msgs.append(f\"Total unique IDs: {self.unique_count}\")\n\n        if len(msgs) > 1:\n            pass\n            # send_webhook(DISCORD_ANNOUNCER_WEBHOOK, \"\\n\\n\".join(msgs))\n\n    @property\n    def unique_count(self):\n        return len(self._seen_ids)\n\n    @staticmethod\n    def _format_exc(error: Exception) -> str:\n        return f\"{type(error).__name__} raised: {error}\"\n\n\nclass _FakeChamber(OldiesChamber):\n    async def _process_req(self, raise_kino_exception=False):\n        return True\n\n    async def _send_info(self):\n        message = await self.ctx.send(\"This is a fake request.\")\n        user = User(id=self._req.user_id)\n        user.load(register=True)\n        await self.ctx.send(\n            f\"**{user.name} ({self._req.time_ago})**: {self._req.pretty_title}\\n\\nMetadata: {self._metadata}\"\n        )\n        assert [await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT]\n\n\n# class OldiesChamber(_FakeChamber):\n#    pass\n\n\ndef _user_str_list(user_list):\n    user_list = {user: user_list.count(user) for user in user_list}\n    user_list = {\n        k: v\n        for k, v in sorted(user_list.items(), key=lambda item: item[1], reverse=True)\n    }\n    str_list = [f\"{key} ({val})\" for key, val in user_list.items()]\n    return \", \".join(str_list)\n    # return \", \".join(list(dict.fromkeys(user_list)))\n\n\ndef _check_msg_author(author):\n    return lambda message: message.author == author\n\n\nlocale.setlocale(locale.LC_ALL, \"\")\n\n\ndef _format_int(i):\n    return format(i, \",d\")\n"}
{"type": "source_file", "path": "kinobot/discord/tickets.py", "content": "from discord.ext import commands\n\nfrom kinobot.config import config\nfrom kinobot.constants import KINOBASE\nfrom kinobot.request import Request\nfrom kinobot.user import User\nfrom kinobot.utils import send_webhook\n\nfrom .extras.verification import UserDB as VerificationUser\n\n\nasync def verify(ctx: commands.Context, id_: str):\n    request = Request.from_db_id(id_)\n    if request.verified:\n        return await ctx.send(\"This request was already verified\")\n\n    cost = 4 if request.page == \"300k\" else 1\n    for item in (\"!manga\", \"!comic\", \"!yt\"):\n        if item in request.comment:\n            return await ctx.send(f\"{item} forbidden for tickets\")\n\n    with VerificationUser(ctx.author.id, KINOBASE) as user:\n        for _ in range(cost):\n            used_ticket = user.log_ticket(request.id)\n\n        request.verify()\n\n    await ctx.send(\n        f\"{request.pretty_title} **verified with ticket**: {used_ticket}.\\n\\nCOST: {cost}\"\n    )\n\n    request.load_user()\n    send_webhook(config.webhooks.ticket_filter, f\"{request.user.name} | {request.id}\")\n    send_webhook(config.webhooks.ticket_filter, request.comment)\n\n\nasync def approve(ctx: commands.Context, id):\n    request = Request.from_db_id(id)\n    if request.verified:\n        return await ctx.send(\"This request was already verified\")\n\n    request.user.load()\n\n    request.verify()\n\n    send_webhook(\n        config.webhooks.tickets,\n        f\"**[Check passed]**\\n{request.comment[:400]}\\n**by**\\n{request.user.name}\",\n    )\n    await ctx.send(f\"OK: {request.comment}\")\n\n\nasync def reject(ctx: commands.Context, id, *args):\n    if not args:\n        return await ctx.send(\"Need a reason.\")\n\n    reason = \" \".join(args)\n    request = Request.from_db_id(id)\n    if request.verified:\n        request.mark_as_used()\n\n    request.mark_as_used()\n\n    request.user.load()\n\n    with VerificationUser(request.user.id, KINOBASE) as user:\n        user.append_ticket(summary=\"Refund\")\n\n    send_webhook(\n        config.webhooks.tickets,\n        f\"**[Check not passed - Ticket refunded]**\\n{request.comment[:400]}\\n**by**\\n{request.user.name}\\n\\nReason: {reason}\",\n    )\n    await ctx.send(\"Ok.\")\n"}
{"type": "source_file", "path": "kinobot/discord/mangas.py", "content": "import asyncio\nimport logging\nimport re\nfrom typing import List\n\nfrom discord import Embed\nfrom discord.ext import commands\n\nfrom kinobot.sources.manga import registry\nfrom kinobot.user import User\n\nlogger = logging.getLogger(__name__)\n\n\nasync def call_with_typing(ctx, loop, *args):\n    result = None\n    async with ctx.typing():\n        result = await loop.run_in_executor(*args)\n\n    return result\n\n\ndef _check_author(author):\n    return lambda message: message.author == author\n\n\nasync def _interactive_index(bot, ctx, items):\n    chosen_index = 0\n\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        try:\n            chosen_index = int(msg.content.lower().strip()) - 1\n            items[chosen_index]\n        except (ValueError, IndexError):\n            await ctx.send(\"Invalid index! Bye\")\n            return None\n\n    except asyncio.TimeoutError:\n        await ctx.send(\"Timeout! Bye\")\n        return None\n\n    return chosen_index\n\n\nasync def _pretty_title_list(\n    ctx, items, append=None, msg=\"Choose the item you want to add ('n' to ignore):\"\n):\n    str_list = \"\\n\".join(f\"{n}. {m.pretty_title()}\" for n, m in enumerate(items, 1))\n    msg = f\"{msg}\\n\\n{str_list}\"\n\n    if append is not None:\n        msg = f\"{msg}\\n\\n{append}\"\n\n    await ctx.send(msg)\n\n\nasync def _interactive_y_n(bot, ctx):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        return msg.content.lower().strip() == \"y\"\n    except asyncio.TimeoutError:\n        return await ctx.send(\"Timeout! Bye\")\n\n\nasync def _ask_msg(bot, ctx):\n    try:\n        msg = await bot.wait_for(\n            \"message\", timeout=120, check=_check_author(ctx.author)\n        )\n        return msg.content.strip()\n    except asyncio.TimeoutError:\n        return await ctx.send(\"Timeout! Bye\")\n\n\ndef _get_mangas_embed(items: List[registry.Manga]) -> Embed:\n    embed = Embed(title=\"Mangas found\")\n\n    str_list = \"\\n\".join(f\"{n}. {m.markdown_url}\" for n, m in enumerate(items, 1))\n\n    embed.add_field(name=\"Titles\", value=str_list)\n    return embed\n\n\nasync def exploremangas(bot, ctx: commands.Context, *args):\n    query = \" \".join(args)\n    repo = registry.Repository.from_constants()\n    items = repo.simple_search(query)\n    if not items:\n        return await ctx.send(\"Nothing found.\")\n\n    await ctx.send(embed=_get_mangas_embed(items))\n\n\n_CHAPTER_RE = re.compile(r\"chapter/(?P<x>\\S+)[/$]\")\n\n\nasync def addchapter(bot, ctx: commands.Context, url):\n    try:\n        id_ = _CHAPTER_RE.search(url).group(\"x\")\n    except (AttributeError, IndexError):\n        id_ = url\n\n    client = registry.Client()\n    loop = asyncio.get_running_loop()\n\n    chapter = await call_with_typing(\n        ctx, loop, None, client.chapter, id_\n    )  # type: registry.Chapter\n\n    repo = registry.Repository.from_constants()\n    repo.add_manga_chapters(chapter.manga_id, [chapter])\n\n    await ctx.send(f\"Chapter registered: {chapter}\")\n\n\nasync def addmanga(bot, ctx: commands.Context, *args):\n    query = \" \".join(args)\n\n    user = User.from_discord(ctx.author)\n    user.load()\n\n    loop = asyncio.get_running_loop()\n\n    client = registry.Client()\n\n    items = await call_with_typing(ctx, loop, None, client.search, query)\n\n    if not items:\n        return await ctx.send(\"Nothing found\")\n\n    msg = \"Choose the item you want to add ('n' to ignore). Avoid titles with special tags or spam or you'll get banned!\"\n    await _pretty_title_list(ctx, items, msg=msg)\n\n    chosen_index = await _interactive_index(bot, ctx, items)\n    if chosen_index is None:\n        return None\n\n    chosen_item = items[chosen_index]  # type: registry.Manga\n\n    await ctx.send(f\"**{chosen_item.pretty_title()}**\\n\\nAdd item? (y/n)\")\n\n    if not await _interactive_y_n(bot, ctx):\n        return None\n\n    await ctx.send(\"Fetching chapters...\")\n    await call_with_typing(ctx, loop, None, chosen_item.fetch_chapters, client)\n    repo = registry.Repository.from_constants()\n\n    try:\n        repo.add_manga(chosen_item, True)\n    except registry.AlreadyAdded:\n        pass\n\n    await ctx.send(f\"Manga registered with {chosen_item.id} ID\")\n"}
{"type": "source_file", "path": "kinobot/infra/user.py", "content": "from typing import Optional\n\nfrom pydantic import BaseModel\nfrom pydantic import ConfigDict\nfrom sqlalchemy.exc import IntegrityError\n\nfrom . import maker\nfrom . import translate_exc\nfrom ._orm import Request\nfrom ._orm import User\nfrom ._orm import user_collab\n\n\nclass UserModel(BaseModel):\n    id: str\n    name: str\n    role: Optional[str]  # Legacy trash\n    source: Optional[str]  # Legacy trash\n    model_config = ConfigDict(from_attributes=True)\n\n\nclass UserCollabService:\n    def __init__(self, session_factory):\n        self._session_factory = session_factory\n\n    def get_collaborators(self, request_id: str) -> list:\n        with self._session_factory() as session:\n            users = (\n                session.query(User)\n                .join(user_collab)\n                .join(Request)\n                .filter(Request.id == request_id)\n                .all()\n            )\n            return [UserModel.from_orm(user) for user in users]\n\n    @translate_exc(\n        IntegrityError,\n        checker=lambda e: \"unique constraint\" in str(e).lower(),\n        output_maker=lambda _: \"Duplicate item\",\n    )\n    def create_collaboration(self, user_id: str, request_id: str) -> None:\n        with self._session_factory() as session:\n            collaboration = user_collab.insert().values(\n                user_id=user_id, request_id=request_id\n            )\n            session.execute(collaboration)\n            session.commit()\n\n    def delete_collaboration(self, user_id: str, request_id: str) -> None:\n        with self._session_factory() as session:\n            session.query(user_collab).filter_by(\n                user_id=user_id, request_id=request_id\n            ).delete()\n            session.commit()\n\n    @classmethod\n    def default(cls):\n        return cls(maker())\n"}
{"type": "source_file", "path": "kinobot/instagram/__init__.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom datetime import datetime\nimport logging\nfrom typing import List, Optional\n\nimport pydantic\nimport requests\n\nlogger = logging.getLogger(__name__)\n\nCARROUSEL = \"CAROUSEL\"\nBASE_URL = \"https://graph.facebook.com/v15.0\"\n\n\nclass LimitExceeded(Exception):\n    pass\n\n\nclass IGClientError(Exception):\n    def __init__(self, *args: object, status_code=None) -> None:\n        super().__init__(*args)\n\n        self.status_code = status_code\n\n\nclass GenericResponse(pydantic.BaseModel):\n    id: str\n\n\nclass IGFrom(pydantic.BaseModel):\n    id: str\n    username: str\n\n\nclass IGComment(pydantic.BaseModel):\n    text: str\n    id: str\n    from_: IGFrom\n\n\nclass Media(pydantic.BaseModel):\n    id: str\n    media_type: str = \"unknown\"\n    timestamp: datetime\n    comments: List[IGComment] = []\n    permalink: Optional[str] = None\n    like_count: Optional[int] = None\n\n\nclass AbstractClient(ABC):\n    @abstractmethod\n    def get_media_list(self) -> List[Media]:\n        raise NotImplementedError\n\n    @abstractmethod\n    def media_publish(self, creation_id):\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_media(self, id) -> Media:\n        raise NotImplementedError\n\n    @abstractmethod\n    def any_media(self, images: List[str], caption=None) -> GenericResponse:\n        \"\"\"Convenience method to handle carousels and single items automatically.\n\n        raises: LimitExceeded, requests.HTTPError\"\"\"\n        raise NotImplementedError\n\n\ndef _catch_error(response):\n    try:\n        response.raise_for_status()\n    except requests.HTTPError as error:\n        raise IGClientError(response.text, status_code=response.status_code) from error\n\n\nclass Client(AbstractClient):\n    def __init__(self, id, token, session=None) -> None:\n        self._id = id\n        self._token = token\n        self._session = session or requests.Session()\n\n    def media(\n        self,\n        image_url: str,\n        caption=None,\n        media_type=None,\n        is_carousel_item=None,\n    ):\n        payload = {\"image_url\": image_url, \"access_token\": self._token}\n\n        if caption is not None:\n            payload[\"caption\"] = caption\n\n        if media_type is not None:\n            payload[\"media_type\"] = media_type\n\n        if is_carousel_item is not None:\n            payload[\"is_carousel_item\"] = is_carousel_item\n\n        response = self._session.post(f\"{BASE_URL}/{self._id}/media\", params=payload)\n\n        _catch_error(response)\n\n        return GenericResponse(**response.json())\n\n    def get_media_list(self):\n        params = {\"access_token\": self._token}\n        response = self._session.get(\n            f\"{BASE_URL}/{self._id}/media?fields=media_type,timestamp,like_count,permalink\",\n            params=params,\n        )\n        _catch_error(response)\n\n        return [Media(**data) for data in response.json()[\"data\"]]\n\n    def media_publish(self, creation_id):\n        payload = {\"creation_id\": creation_id, \"access_token\": self._token}\n        response = self._session.post(\n            f\"{BASE_URL}/{self._id}/media_publish\", params=payload\n        )\n        _catch_error(response)\n\n        return GenericResponse(**response.json())\n\n    def carousel(self, image_urls, caption=None):\n        if len(image_urls) > 10:\n            raise LimitExceeded\n\n        containers = []\n\n        for image_url in image_urls:\n            containers.append(self.media(image_url, is_carousel_item=True).id)\n\n        children = \",\".join(containers)\n\n        payload = {\n            \"children\": children,\n            \"caption\": caption,\n            \"media_type\": CARROUSEL,\n            \"access_token\": self._token,\n        }\n\n        response = self._session.post(f\"{BASE_URL}/{self._id}/media\", params=payload)\n        _catch_error(response)\n\n        return GenericResponse(**response.json())\n\n    def get_media(self, id):\n        response = self._session.get(\n            f\"{BASE_URL}/{id}\"\n            + \"?fields=media_type,comments{from,text},media_url,like_count,timestamp,permalink\",\n            params={\"access_token\": self._token},\n        )\n        _catch_error(response)\n\n        data = response.json()\n        try:\n            comments = [\n                IGComment(**item, from_=item[\"from\"])\n                for item in data[\"comments\"][\"data\"]\n            ]\n            data.pop(\"comments\", None)\n        except KeyError:\n            comments = []\n\n        return Media(**data, comments=comments)\n\n    def any_media(\n        self, images: List[str], caption=None, publish=True\n    ) -> GenericResponse:\n        if len(images) > 1:\n            response = self.carousel(images, caption=caption)\n        else:\n            response = self.media(images[0], caption=caption)\n\n        logger.info(\"Uploaded: %s\", response)\n\n        if publish:\n            response = self.media_publish(response.id)\n            logger.info(\"Published: %s\", response)\n        else:\n            logger.info(\"Not publishing\")\n\n        return response\n"}
{"type": "source_file", "path": "kinobot/discord/ochamber.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport asyncio\nimport datetime\nimport locale\nimport logging\n\nfrom discord import File\nfrom discord.ext import commands\n\nfrom . import oldies\nfrom ..config import settings\nfrom ..db import Execute\nfrom ..exceptions import KinoException\nfrom ..exceptions import KinoUnwantedException\nfrom ..request import get_cls\nfrom ..user import User\nfrom ..utils import handle_general_exception\nfrom ..utils import send_webhook\nfrom .common import get_req_id_from_ctx\nfrom .utils import IDLogger\n\n_GOOD_BAD_NEUTRAL_EDIT = (\"ðŸ‡¼\", \"ðŸ‡±\", \"ðŸ§Š\", \"âœï¸\")\n_ICE_DELAY = datetime.timedelta(days=1)\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass OldiesChamber:\n    \"Class for the verification chamber used in the admin's Discord server.\"\n\n    def __init__(\n        self, bot: commands.Bot, ctx: commands.Context, tag=None, log_ids=True\n    ):\n        self._tag = tag\n        self.bot = bot\n        self.ctx = ctx\n        self._log_ids = log_ids\n        self._logger = IDLogger(settings.discord.logger, \"ochamber\")\n        self._user_roles = [role.name for role in ctx.author.roles]\n        self._user_id = str(ctx.author.id)  # type: ignore\n        self._identifier = get_req_id_from_ctx(ctx)\n        self._req_cls = get_cls(self._identifier)\n        self._req = None\n        self._seen_ids = set()\n        self._images = []\n        self._rejected = []\n        self._verified = []\n        self._iced = []\n        self._edited = []\n\n    async def _get_msg(self):\n        try:\n            message = await self.bot.wait_for(\n                \"message\", timeout=300, check=self._check_msg(self.ctx.author)\n            )\n            return message\n        except asyncio.TimeoutError:\n            await self.ctx.send(\"Timeout!\")\n            return None\n\n    async def _take_args(self):\n        await self.ctx.send(\n            f\"[{self._tag}] Give the range of dates\\nFormat: START_FROM, START_TO, END_FROM, END_TO\\nExample: now, -1 year, now, -6 months\"\n        )\n        user_msg = await self._get_msg()\n        if user_msg is None:\n            return None\n\n        args = [a.strip() for a in str(user_msg.content).split(\",\")]\n        if len(args) != 4:\n            await self.ctx.send(\"Invalid format. Plesae read the instructions again.\")\n            return None\n\n        return args\n\n    async def start(self):\n        \"Start the chamber loop.\"\n        args = await self._take_args()\n        if not args:\n            return await self.ctx.send(\"Bye.\")\n\n        await self.ctx.send(\"Give me the limit of requests (eg. 25)\")\n        msg = await self._get_msg()\n        try:\n            limit = int(msg.content.strip())\n        except ValueError:\n            return await self.ctx.send(\"Invalid integer limit\")\n\n        oldie = oldies.Repo.from_constants()\n\n        self._oldies = oldie.get((args[0], args[1]), (args[2], args[3]), limit=limit)\n        if not self._oldies:\n            return await self.ctx.send(\"Nothing found\")\n\n        exc_count = 0\n\n        for oldie in self._oldies:\n            if exc_count > 10:\n                await self.ctx.send(\"Exception count exceeded. Breaking loop.\")\n                break\n\n            if not await self._loaded_req(oldie):\n                exc_count += 1\n                continue\n\n            exc_count = 0\n\n            await self._send_info()\n\n            try:\n                await self._verdict()\n            except asyncio.TimeoutError:\n                break\n\n            if not await self._continue():\n                break\n\n        await self.ctx.send(\"Chamber loop finished\")\n\n        # self._send_webhook()\n\n    async def _loaded_req(self, oldie) -> bool:\n        \"\"\"\n        Load the request and the handler. Send the exception info if the\n        handler fails.\n\n        raises exceptions.NothingFound\n        \"\"\"\n        self._req = self._req_cls.from_db_id(oldie.request_id)\n        self._oldie = oldie\n\n        if self._req.id in self._seen_ids:\n            return False\n\n        if self._log_ids:\n            if self._logger.has_seen(self._req.id):\n                return False\n\n            self._logger.mark_as_seen(self._req.id)\n\n        self._seen_ids.add(self._req.id)\n\n        return await self._process_req()\n\n    async def _handle_iced(self):\n        assert self._req is not None\n\n        ices = self._req.get_ices()\n\n        if ices:\n            logger.debug(\"Ices: %s\", ices)\n            if len(ices) > 5:\n                await self.ctx.send(\n                    f\"`{self._req.comment}` has been already iced {len(ices)} times. Marking as used.\"\n                )\n                self._req.mark_as_used()\n                return False\n\n            last_ice = ices[-1]\n            if last_ice[\"ago\"] > _ICE_DELAY:\n                await self.ctx.send(\n                    f\"Skipping recently iced request: {last_ice} ({len(ices)} ices) [Ice delay: {_ICE_DELAY}]\"\n                )\n                return False\n        else:\n            logger.debug(\"This request doesn't have any ices registered\")\n\n        return True\n\n    async def _process_req(self, raise_kino_exception=False):\n        loop = asyncio.get_running_loop()\n\n        async with self.ctx.typing():\n            try:\n                handler = await loop.run_in_executor(None, self._req.get_handler)\n                self._images = await loop.run_in_executor(None, handler.get)\n                risk = self._req.facebook_risk()\n\n                if risk is not None:\n                    await self.ctx.send(\n                        f\"WARNING: Facebook risk: `{risk}`.\\n\\nPLEASE BE CAREFUL! \"\n                        \"DON'T GET THE PAGE BANNED!\"\n                    )\n\n                return True\n\n            except KinoUnwantedException as error:\n                await self.ctx.send(self._format_exc(error))\n                self._req.mark_as_used()\n\n            except KinoException as error:\n                await self.ctx.send(self._format_exc(error))\n\n                if raise_kino_exception:\n                    raise\n\n                self._req.mark_as_used()\n\n            except Exception as error:  # Fatal\n                handle_general_exception(error)\n                await self.ctx.send(\n                    f\"**Fatal!!!** {self._format_exc(error)}. \"\n                    \"**Marking as used. REPORT ADMIN if you see this error too often!!!**\"\n                )\n\n                self._req.mark_as_used()\n\n            return False\n\n    async def _send_info(self):\n        \"Send the request metadata and the images.\"\n        user = User(id=self._req.user_id)\n        user.load(register=True)\n\n        message = None\n        stats = f\"impressions: **{_format_int(self._oldie.impressions)}**; engaged users: **{_format_int(self._oldie.engaged_users)}**\"\n        await self.ctx.send(\n            f\"**{user.name} ({self._req.time_ago})**: {self._req.pretty_title}\\n\\nStats: {stats}\"\n        )\n        await self.ctx.send(f\"{self._req.id}\")\n\n        for image in self._images:\n            logger.info(\"Sending image: %s\", image)\n            message = await self.ctx.send(file=File(image))\n\n        assert [await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT]\n\n    def _check_recurring_user(self):\n        if self._verified.count(self._req.user.name) >= 2:\n            logger.debug(\"%s has already two verified requests\", self._req.user)\n            return True\n\n        return False\n\n    async def _verdict(self):\n        \"raises asyncio.TimeoutError\"\n        await self.ctx.send(\n            \"You got 120 seconds to react to the last image. React \"\n            \"with the ice cube to deal with the request later; react with \"\n            \"the pencil to append flags to the request.\"\n        )\n\n        reaction, user = await self.bot.wait_for(\n            \"reaction_add\", timeout=120, check=self._check_react\n        )\n        assert user\n\n        if str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[0]):\n            if str(self._req.user.id) == self._user_id:\n                await self.ctx.send(\"You can't verify your own request.\")\n            else:\n                cloned = self._req.clone()\n                self._req = cloned\n                self._req.verify()\n\n                if self._tag is not None:\n                    self._req.add_tag(self._tag)\n\n                self._log_user(verified=True)\n                await self._take_reason(True)\n                await self.ctx.send(\"Verified.\")\n\n        elif str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[1]):\n            # self._req.mark_as_used()\n            # self._log_user()\n            # await self._take_reason(False)\n            await self.ctx.send(\"Marked as used.\")\n\n        elif str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[3]):\n            if not await self._edit_loop():\n                await self.ctx.send(\"Ignored\")\n            else:\n                await self._verdict()\n        else:\n            self._req.register_ice()\n            self._log_user(iced=True)\n            await self.ctx.send(\"Ignored.\")\n\n    async def _take_reason(self, verified: bool):\n        self._req.register_verifications([self.ctx.author.id], verified, \"automatic\")\n\n    def _check_msg_author(self, author):\n        return lambda message: str(message.author.id) == str(self.ctx.author.id)\n\n    def _check_msg(self, author):\n        return lambda message: str(message.author.id) == str(self.ctx.author.id)\n\n    async def _edit_loop(self):\n        while True:\n            edited = await self._edit_req()\n            if not edited:\n                await self.ctx.reply(\"Bad input.\")\n                return False\n\n            # Send the request\n            try:\n                processed = await self._process_req(raise_kino_exception=True)\n            except KinoException:\n                continue\n            else:\n                if not processed:\n                    return False\n                else:\n                    await self._send_info()\n                    return True\n\n    async def _edit_req(self):\n        await self.ctx.send(\n            \"Type the flags you want to append. Type 'no' to cancel. \"\n            \"Type 'reset' to remove all global flags set.\"\n        )\n        try:\n            message = await self.bot.wait_for(\n                \"message\", timeout=300, check=_check_msg_author(self.ctx.author)\n            )\n\n            if message.content.lower() == \"no\":\n                return False\n\n            if message.content.lower() == \"reset\":\n                self._req.reset_global_flags()\n                self._req.update()\n                return True\n\n            if self._req.edited:\n                self._req.reset_append()\n\n            self._req.append_text(str(message.content))\n\n            return True\n\n        except asyncio.TimeoutError:\n            return False\n\n    async def _continue(self) -> bool:\n        queued = Execute().queued_requets(table=self._req_cls.table)\n        message = await self.ctx.send(\n            f\"Continue in the chamber of {self._req_cls.table}? ({queued} verified).\"\n        )\n        assert [\n            await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT[:2]\n        ]\n\n        try:\n            reaction, user = await self.bot.wait_for(\n                \"reaction_add\", timeout=30, check=self._check_react\n            )\n            assert user\n\n            if str(reaction) == str(_GOOD_BAD_NEUTRAL_EDIT[0]):\n                return True\n\n            await self.ctx.send(\"Bye.\")\n            return False\n\n        except asyncio.TimeoutError:\n            await self.ctx.send(\"Timeout. Exiting...\")\n            return False\n\n    def _check_react(self, reaction, user):\n        assert reaction\n        return user == self.ctx.author\n\n    def _log_user(self, verified: bool = False, edited=False, iced=False):\n        user = User(id=self._req.user_id)  # Temporary\n        user.load(register=True)\n\n        if iced:\n            self._iced.append(user.name)\n            return None\n\n        if verified:\n            self._verified.append(user.name)\n        else:\n            self._rejected.append(user.name)\n\n        if edited:\n            self._edited.append(user.name)\n\n    def _verdict_author(self):\n        return self.ctx.author.display_name\n\n    def _send_webhook(self):\n        msgs = [\n            f\"`{self._verdict_author()}` verdict for oldies chamber {self._identifier}:\"\n        ]\n\n        if self._verified:\n            msgs.append(\n                f\"Authors with **verified** requests: `{_user_str_list(self._verified)}`\"\n            )\n\n        if self._rejected:\n            msgs.append(\n                f\"Authors with **rejected** requests: `{_user_str_list(self._rejected)}`\"\n            )\n\n        if self._iced:\n            msgs.append(\n                f\"Authors with **iced (skipped)** requests: `{_user_str_list(self._iced)}`\"\n            )\n\n        msgs.append(f\"Total unique IDs: {self.unique_count}\")\n\n        if len(msgs) > 1:\n            send_webhook(settings.webhooks.announcer, \"\\n\\n\".join(msgs))\n\n    @property\n    def unique_count(self):\n        return len(self._seen_ids)\n\n    @staticmethod\n    def _format_exc(error: Exception) -> str:\n        return f\"{type(error).__name__} raised: {error}\"\n\n\nclass _FakeChamber(OldiesChamber):\n    async def _process_req(self, raise_kino_exception=False):\n        return True\n\n    async def _send_info(self):\n        message = await self.ctx.send(\"This is a fake request.\")\n        user = User(id=self._req.user_id)\n        user.load(register=True)\n        stats = f\"impressions: **{_format_int(self._oldie.impressions)}**; engaged users: **{_format_int(self._oldie.engaged_users)}**\"\n        await self.ctx.send(\n            f\"**{user.name} ({self._req.time_ago})**: {self._req.pretty_title}\\n\\nStats: {stats}\"\n        )\n        assert [await message.add_reaction(emoji) for emoji in _GOOD_BAD_NEUTRAL_EDIT]\n\n\n# class OldiesChamber(_FakeChamber):\n#    pass\n\n\ndef _user_str_list(user_list):\n    user_list = {user: user_list.count(user) for user in user_list}\n    user_list = {\n        k: v\n        for k, v in sorted(user_list.items(), key=lambda item: item[1], reverse=True)\n    }\n    str_list = [f\"{key} ({val})\" for key, val in user_list.items()]\n    return \", \".join(str_list)\n    # return \", \".join(list(dict.fromkeys(user_list)))\n\n\ndef _check_msg_author(author):\n    return lambda message: message.author == author\n\n\nlocale.setlocale(locale.LC_ALL, \"\")\n\n\ndef _format_int(i):\n    return format(i, \",d\")\n"}
{"type": "source_file", "path": "kinobot/instagram/publishers.py", "content": "import logging\n\nfrom discord_webhook import DiscordEmbed\nfrom discord_webhook import DiscordWebhook\n\nfrom .db import RequestRepository\nfrom .events import PostCreated\n\nlogger = logging.getLogger(__name__)\n\n\npublishers = {}\n\n\ndef register(key):\n    def decorator(cls):\n        publishers[key] = cls\n        return cls\n\n    return decorator\n\n\n@register(\"post_webhooks\")\nclass PostCreatedWebhooks:\n    def __init__(self, urls=None) -> None:\n        self._urls = urls or []\n\n    def _get_embed(self, post_created: PostCreated):\n        embed = DiscordEmbed(\n            title=f\"by {post_created.request.user.name}\",\n            description=post_created.request.content[:500],\n        )\n        embed.set_author(name=\"Instagram post\", url=post_created.permalink)\n        embed.set_image(url=post_created.finished_request.image_uris[0])\n        embed.set_timestamp()\n        return embed\n\n    def __call__(self, post_created: PostCreated):\n        embed = self._get_embed(post_created)\n\n        for url in self._urls:\n            try:\n                wh = DiscordWebhook(url=url)\n                wh.add_embed(embed)\n                wh.execute()\n            except Exception as error:\n                logger.error(error)\n\n\n@register(\"post_register\")\nclass RegisterPost:\n    def __init__(self, repository: RequestRepository) -> None:\n        self._repository = repository\n\n    def __call__(self, post_created: PostCreated):\n        self._repository.post(post_created.ig_id, post_created.request.id)\n\n\n@register(\"post_quarantine\")\nclass QuarantineRequest:\n    def __init__(self, repository: RequestRepository) -> None:\n        self._repository = repository\n\n    def __call__(self, post_created: PostCreated):\n        self._repository.quarantine(post_created.request.id)\n"}
{"type": "source_file", "path": "kinobot/frame.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport datetime\nfrom functools import cached_property\nimport logging\nimport os\nfrom pprint import pprint\nimport re\nimport textwrap\nfrom typing import Any, Generator, List, Optional, Sequence, Tuple, Union\nimport uuid\n\nfrom cv2 import cv2\nimport numpy as np\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom PIL import ImageEnhance\nfrom PIL import ImageFilter\nfrom PIL import ImageFont\nfrom PIL import ImageOps\nfrom PIL import ImageStat\nfrom PIL import UnidentifiedImageError\nfrom pydantic import BaseModel\nfrom pydantic import ValidationError\nfrom pydantic import validator\nfrom srt import Subtitle\n\nfrom kinobot import profiles\nimport kinobot.exceptions as exceptions\nfrom kinobot.playhouse.lyric_card import make_card\n\nfrom . import request_trace\nfrom .bracket import Bracket\nfrom .config import config\nfrom .constants import CACHED_FRAMES_DIR\nfrom .constants import FRAMES_DIR\nfrom .constants import IMAGE_EXTENSION\nfrom .item import RequestItem\nfrom .media import Episode\nfrom .media import hints\nfrom .media import Movie\nfrom .palette import draw_palette_from_config\nfrom .palette import LegacyPalette\nfrom .palette import Palette\nfrom .profiles import Profile\nfrom .story import Story\nfrom .utils import download_image\n\n_UPPER_SPLIT = re.compile(r\"(\\s*[.!?â™ª\\-]\\s*)\")\n_STRANGE_RE = re.compile(r\"[^a-zA-ZÃ€-Ãº0-9?!\\.\\ \\Â¿\\?',&-_*(\\n)]\")\n_BAD_DOTS = re.compile(r\"(?u)\\.{2,}\")\n_STYLE = re.compile(r\"<.*?>\")\n_EXTRA_SPACE = re.compile(\" +\")\n\n_REPLACEMENTS = (\n    (_STYLE, \"\"),\n    # (_STRANGE_RE, \"\"),\n    # (_BAD_DOTS, \"...\"),\n    (_EXTRA_SPACE, \" \"),\n)\n\n_POSSIBLES = {\n    1: (1, 1),\n    2: (1, 2),\n    3: (1, 3),\n    4: (1, 4),\n}\n\n_VALID_COLLAGES = [\n    (1, 2),\n    (1, 3),\n    (2, 1),\n    (2, 2),\n    (1, 4),\n    (1, 5),\n    (2, 3),\n    (2, 4),\n    (3, 3),\n]\n_LATERAL_COLLAGES = [(2, 1), (2, 2), (2, 3), (2, 4)]\n\n_DEFAULT_FONT_SIZE = 22\n\nFONTS_DIR = config.fonts_dir\n\n# TODO: generate this dict automatically from the fonts directory\n\nFONTS_DICT = {\n    \"nfsans\": os.path.join(FONTS_DIR, \"NS_Medium.otf\"),\n    \"helvetica\": os.path.join(FONTS_DIR, \"helvetica.ttf\"),\n    \"helvetica-italic\": os.path.join(FONTS_DIR, \"helvetica-italic.ttf\"),\n    \"clearsans\": os.path.join(FONTS_DIR, \"ClearSans-Medium.ttf\"),\n    \"clearsans-regular\": os.path.join(FONTS_DIR, \"clearsans-regular.ttf\"),\n    \"clearsans-italic\": os.path.join(FONTS_DIR, \"clearsans-italic.ttf\"),\n    \"opensans\": os.path.join(FONTS_DIR, \"opensans.ttf\"),\n    \"comicsans\": os.path.join(FONTS_DIR, \"comic_sans_ms.ttf\"),\n    \"impact\": os.path.join(FONTS_DIR, \"impact.ttf\"),\n    \"segoe\": os.path.join(FONTS_DIR, \"Segoe_UI.ttf\"),\n    \"segoe-italic\": os.path.join(FONTS_DIR, \"segoe-italic.ttf\"),\n    \"segoesm\": os.path.join(FONTS_DIR, \"segoe_semi_bold.ttf\"),\n    \"papyrus\": os.path.join(FONTS_DIR, \"papyrus.ttf\"),\n    \"bangers\": os.path.join(FONTS_DIR, \"Bangers-Regular.ttf\"),\n    \"timesnewroman\": os.path.join(FONTS_DIR, \"TimesNewRoman.ttf\"),\n    \"oldenglish\": os.path.join(FONTS_DIR, \"OldEnglish.ttf\"),\n    \"segoe-bold-italic\": os.path.join(FONTS_DIR, \"segoe-bold-italic.ttf\"),\n    \"tahoma\": os.path.join(FONTS_DIR, \"tahoma.ttf\"),\n    \"whisper\": os.path.join(FONTS_DIR, \"whisper.otf\"),\n}\n\n_DEFAULT_FONT = os.path.join(FONTS_DIR, \"helvetica.ttf\")\n\n\n_FONT_TO_KEY_RE = re.compile(r\"[\\s_-]|\\.[ot]tf\")\n\n\ndef _generate_fonts(font_dir=None):\n    old_values = list(FONTS_DICT.values())\n\n    for file_ in os.listdir(font_dir or FONTS_DIR):\n        if not file_.endswith((\".otf\", \"ttf\")):\n            continue\n\n        key = _FONT_TO_KEY_RE.sub(\"\", file_).lower()\n        font_path = os.path.join(FONTS_DIR, file_)\n\n        if font_path in old_values:\n            continue\n\n        FONTS_DICT[key] = font_path\n\n\n_generate_fonts()\n\nlogger = logging.getLogger(__name__)\n\n\nclass Frame:\n    \"\"\"Class for single frames with intended post-processing.\"\"\"\n\n    def __init__(self, media: hints, bracket: Bracket, pp=None):\n        self.media = media\n        self.bracket = bracket\n        self.message: Union[str, None] = None\n\n        content = self.bracket.content\n        if isinstance(content, Subtitle):\n            self.seconds = content.start.seconds\n            self.milliseconds = content.start.microseconds / 1000\n            self.message = content.content  # Subtitle message\n        elif isinstance(content, int):\n            self.seconds = content\n            self.milliseconds = bracket.milli\n        else:\n            raise exceptions.InvalidRequest(\"Frames must contain quotes or timestamps\")\n\n        self._pp = pp or PostProc()\n        self._cv2: np.ndarray\n        self.pil: Image.Image\n        self.finished_quote: Optional[str] = None\n\n    def load_frame(self):\n        \"Load the cv2 array and the PIL image object.\"\n        if self._is_cached():\n            self._load_pil_from_cv2()\n        else:\n            self._cv2 = self.media.get_frame((self.seconds, self.milliseconds))\n\n            if not self._pp.no_trim:\n                self._cv2_trim()\n\n            self._load_pil_from_cv2()\n\n            self._cache_image()\n\n    def make_trace(self) -> request_trace.Frame:\n        data = dict()\n\n        data[\"text\"] = self.finished_quote\n        data[\"dimensions\"] = self.pil.size\n        data[\"timestamp\"] = datetime.timedelta(seconds=1)\n        data[\"media_uri\"] = \"foo://123\"  # TODO\n        data[\"postproc\"] = (self._pp or PostProc()).dict()\n\n        return request_trace.Frame(**data)\n\n    def load_palette(self, classic: bool = True):\n        palette_cls = Palette if classic else LegacyPalette\n\n        if classic and self.grayscale:\n            logger.info(\"Grayscale image found. Ignoring palette draw\")\n        else:\n            palette = palette_cls(self.pil, discriminator=self.discriminator)\n            palette.draw()\n            self.pil = palette.image\n\n    @property\n    def pretty_content(self) -> str:\n        if self.message is not None:\n            return self.message  # Subtitle message\n\n        return str(datetime.timedelta(seconds=self.seconds))  # hh:mm:ss\n\n    @property\n    def is_timestamp(self) -> bool:\n        return isinstance(self.bracket.content, int)\n\n    @cached_property\n    def grayscale(self) -> bool:\n        hsv = ImageStat.Stat(self.pil.convert(\"HSV\"))\n        return hsv.mean[1] < 35\n\n    @cached_property\n    def discriminator(self) -> str:\n        prefix = f\"{self.media.type}_{self.media.id}_nt_{self._pp.no_trim}\"\n        return f\"{prefix}_{self.seconds}_{self.milliseconds}.{IMAGE_EXTENSION}\"\n\n    def _cache_image(self):\n        image_path = os.path.join(CACHED_FRAMES_DIR, self.discriminator)\n        logger.info(\"Caching image: %s\", image_path)\n\n        self.pil.save(image_path)\n\n    def _is_cached(self) -> bool:\n        image_path = os.path.join(CACHED_FRAMES_DIR, self.discriminator)\n        if os.path.isfile(image_path) and os.path.getsize(image_path) >= 2048:\n            logger.info(\"Nothing to do. Cached image found: %s\", self.discriminator)\n            self._cv2 = cv2.imread(image_path)\n            return True\n\n        return False\n\n    def _load_pil_from_cv2(self):\n        self.pil = _pretty_scale(_load_pil_from_cv2(self._cv2), 1920)\n\n    def _cv2_trim(self) -> bool:\n        \"\"\"\n        Remove black borders from a cv2 image array.\n\n        This method is a fucking waste of time as most sources are already\n        properly cropped. We need to use it because of a few shitty WEB sources.\n        Fucking unbelievable.\n\n        :param cv2_image: cv2 image array\n        \"\"\"\n        logger.info(\"Trying to remove black borders with cv2\")\n        og_w, og_h = self._cv2.shape[1], self._cv2.shape[0]\n        logger.debug(\"Original dimensions: %dx%d\", og_w, og_h)\n        og_quotient = og_w / og_h\n\n        first_img = _remove_lateral_cv2(self._cv2)\n\n        tmp_img = cv2.transpose(first_img)\n        tmp_img = cv2.flip(tmp_img, flipCode=1)\n\n        if tmp_img is None:\n            raise exceptions.InvalidRequest(\"Possible all-black image found\")\n\n        final = _remove_lateral_cv2(tmp_img)\n\n        out = cv2.transpose(final)\n\n        final_img = cv2.flip(out, flipCode=0)\n        if final_img is None:\n            raise exceptions.InvalidRequest(\"Possible all-black image found\")\n\n        new_w, new_h = final_img.shape[1], final_img.shape[0]\n\n        logger.debug(\"New dimensions: %dx%d\", new_w, new_h)\n        new_quotient = new_w / new_h\n\n        if abs(new_quotient - og_quotient) > 0.9:\n            logger.info(\n                \"Possible bad quotient found: %s -> %s\", og_quotient, new_quotient\n            )\n            return False\n\n        width_percent = (100 / og_w) * new_w\n        height_percent = (100 / og_h) * new_h\n\n        if any(percent <= 65 for percent in (width_percent, height_percent)):\n            logger.info(\n                \"Possible bad trim found: %s -> %s\", width_percent, height_percent\n            )\n            return False\n\n        self._cv2 = final_img\n        return True\n\n    def __repr__(self):\n        return f\"<Frame: {self.media} - {self.pretty_content}>\"\n\n\nclass GIF:\n    \"\"\"Class for GIF requests with minimal post-processing.\"\"\"\n\n    def __init__(\n        self,\n        media: Union[Movie, Episode],\n        content_list,\n        id: str,\n    ):\n        raise NotImplementedError\n\n    @property\n    def title(self) -> str:\n        raise NotImplementedError\n\n    @classmethod\n    def from_request(cls, request):\n        raise NotImplementedError\n\n    def get(self, path: Optional[str] = None) -> List[str]:  # Consistency\n        raise NotImplementedError\n\n\nclass PostProc(BaseModel):\n    \"Class for post-processing options applied in an entire request.\"\n\n    frame: Optional[Frame] = None\n    font: str = \"clearsans\"  # \"segoesm\"\n    font_size: float = _DEFAULT_FONT_SIZE\n    font_color: str = \"white\"\n    text_spacing: float = 1.0\n    text_align: str = \"center\"\n    y_offset: int = 15\n    stroke_width: float = 0.5\n    stroke_color: str = \"black\"\n    palette_color_count: int = 10\n    palette_dither: str = \"floyd_steinberg\"\n    palette_colorspace: Optional[str] = None\n    palette_height: int = 33\n    palette_position: str = \"bottom\"\n    palette: bool = False\n    mirror: bool = False\n    mirror_after: bool = False\n    raw: bool = False\n    no_trim: bool = False\n    ultraraw: bool = False\n    no_collage: bool = False\n    dimensions: Union[None, str, tuple] = None\n    aspect_quotient: Optional[float] = None\n    contrast: int = 20\n    color: int = 0\n    brightness: int = 0\n    sharpness: int = 0\n    tint: Optional[str] = None\n    tint_alpha: float = 0.5\n    wrap_width: Optional[int] = None\n    glitch: Union[str, dict, None] = None\n    apply_to: Union[str, tuple, None] = None\n    border: Union[str, tuple, None] = None\n    border_color: str = \"white\"\n    text_background: Optional[str] = None\n    text_shadow: int = 10\n    text_shadow_color: str = \"black\"\n    text_shadow_offset: Union[str, tuple, None] = (5, 5)\n    text_xy: Union[str, tuple, None] = None\n    text_shadow_blur: str = \"boxblur\"\n    text_shadow_stroke: int = 2\n    text_shadow_font_plus: int = 0\n    zoom_factor: Optional[float] = None\n    flip: Optional[str] = None\n    no_collage_resize: bool = False\n    static_title: Optional[str] = None\n    og_dict: dict = {}\n    context: dict = {}\n    debug: bool = False\n    debug_color: Optional[str] = None\n    profiles: List = []\n    _og_instance_dict: dict = {}\n\n    class Config:\n        arbitrary_types_allowed = True\n        underscore_attrs_are_private = True\n        allow_mutation = True\n\n    def __init__(self, **data: Any) -> None:\n        super().__init__(**data)\n        self._og_instance_dict = self.dict().copy()\n\n    def _analize_profiles(self):\n        if not self.profiles:\n            logger.debug(\"No profiles to analize\")\n            return None\n        else:\n            for profile in self.profiles:\n                profile.visit(self)\n\n        self._overwrite_from_og()\n\n    def process(\n        self, frame: Frame, draw: bool = True, only_crop: bool = False, no_debug=False\n    ) -> Image.Image:\n        \"\"\"Process a frame and return a PIL Image object.\n\n        :param frame:\n        :type frame: Frame\n        :param draw:\n        :type draw: bool\n        :param only_crop:\n        :type only_crop: bool\n        :rtype: Image.Image\n        \"\"\"\n        logger.debug(\"Processing frame: %s\", frame)\n        self.frame = frame\n\n        self._analize_profiles()\n\n        self.raw = self.ultraraw or self.raw\n\n        if not self.raw:\n            self._crop()\n            if not only_crop:\n                self._pil_enhanced()\n\n        self._analize_profiles()\n\n        if draw and not self.ultraraw:\n            self._draw_quote()\n\n        if not no_debug and self.debug:\n            info = self.dict(exclude_unset=True).copy()\n            info.update(self.frame.bracket.postproc.dict(exclude_unset=True))\n            self.frame.pil = _get_debug(\n                self.frame.pil, info, grid_color=info.get(\"debug_color\")\n            )\n\n        if self.palette:\n            self.frame.pil = draw_palette_from_config(self.frame.pil, **self.dict())\n\n        return self.frame.pil\n\n    def _mirror_image(self, img: Image.Image, flip: str):\n        if flip is None:\n            logger.debug(\"Nothing to flip\")\n            return img\n\n        if flip == \"right\":\n            return img.transpose(Image.FLIP_LEFT_RIGHT)\n        elif flip == \"bottom\":\n            return img.transpose(Image.FLIP_TOP_BOTTOM)\n        else:\n            logger.info(\"Unsupported flip\")\n\n        return img\n\n    def _overwrite_from_og(self):\n        for key in self.og_dict.keys():\n            og_parsed_value = self._og_instance_dict.get(key)\n            if og_parsed_value is None:\n                continue\n\n            logger.debug(\"Overwriting value from og dict: %s: %s\", key, og_parsed_value)\n            setattr(self, key, og_parsed_value)\n\n    def pixel_intensity(self):\n        if self.frame is None or self.frame.message is None:\n            return None\n\n        quote = self.frame.message.split(\"\\n\")[0]\n        text_box = _get_text_area_box(self.frame.pil, quote, **self.dict())\n        logger.debug(\"Text area box: %s\", text_box)\n        return _get_white_level(self.frame.pil.crop(text_box))\n\n    def copy(self, data):\n        new_data = self.dict().copy()\n        new_data.update(data)\n\n        return PostProc(**new_data)\n\n    def process_list(self, frames: List[Frame] = None) -> List[Image.Image]:\n        \"\"\"Handle a list of frames, taking into account the post-processing\n        flags.\n\n        :param frames:\n        :type frames: List[Frame]\n        :rtype: List[Image.Image]\n        \"\"\"\n        frames = frames or []\n\n        self._image_list_check(frames)\n\n        apply_to = self.apply_to or tuple(range(len(frames)))\n\n        logger.debug(\"Index list to apply post-processing: %s\", apply_to)\n        pils = []\n        for index, frame in enumerate(frames):\n            only_crop = not index in apply_to  # type: ignore\n            pils.append(\n                self.process(frame, draw=False, only_crop=only_crop, no_debug=True)\n            )\n\n        if not self.no_collage_resize:\n            pils = _homogenize_images(pils)\n\n        assert len(pils) == len(frames)\n\n        if not self.ultraraw:  # Don't even bother\n            for n, pil, frame in zip(range(len(pils)), pils, frames):\n                if frame.message is not None:\n                    config_ = self.dict().copy()\n                    config_.update(frame.bracket.postproc.dict(exclude_unset=True))\n\n                    quote = _prettify_quote(\n                        _clean_sub(frame.message),\n                        wrap_width=config_.get(\"wrap_width\"),\n                        text_lines=config_.get(\"text_lines\"),\n                    )\n                    frame.finished_quote = quote\n\n                    _draw_quote(pil, quote, **config_)\n\n                    if config_.get(\"debug\"):\n                        debug_ = self.dict(exclude_unset=True).copy()\n                        debug_.update(frame.bracket.postproc.dict(exclude_unset=True))\n\n                        self.no_collage = True\n                        debugged = _get_debug(\n                            pil, debug_, grid_color=debug_.get(\"debug_color\")\n                        )\n                        pils[n] = debugged\n\n        if self.no_collage or (self.dimensions is None and len(frames) > 4):\n            return pils\n\n        collage = Collage(pils, self.dimensions)  # type: ignore\n        if self.border is not None:\n            collage.add_borders(self.border, self.border_color)  # type: ignore\n\n        return [collage.get()]\n\n    def _image_list_check(self, frames):\n        if (\n            self.dimensions is not None\n            and len(frames) != (self.dimensions[0] * self.dimensions[1])  # type: ignore\n            and self.no_collage is False\n        ):\n            raise exceptions.InvalidRequest(\n                f\"Kinobot returned {len(frames)} frames; such amount is compatible\"\n                f\" with the requested collage dimensions: {self.dimensions}\"\n            )\n\n        logger.debug(\"Requested dimensions: %s\", self.dimensions)\n\n        if self.dimensions is None:\n            self.dimensions = _POSSIBLES.get(len(frames))  # Still can be None\n\n        if (\n            self.dimensions is not None\n            and self.dimensions in _LATERAL_COLLAGES\n            and self.font_size == _DEFAULT_FONT_SIZE\n        ):\n            self.font_size += 2\n\n        logger.debug(\"Found dimensions: %s\", self.dimensions)\n\n    _enhance = {\n        \"contrast\": ImageEnhance.Contrast,\n        \"brightness\": ImageEnhance.Brightness,\n        \"sharpness\": ImageEnhance.Sharpness,\n        \"color\": ImageEnhance.Color,\n    }\n\n    def _pil_enhanced(self):\n        config_ = self.dict().copy()\n        config_.update(self.frame.bracket.postproc.dict(exclude_unset=True))\n\n        for key, cls_ in self._enhance.items():\n            value = config_[key]\n            if not value:\n                continue\n\n            value = 1 + value * 0.01\n            logger.debug(\"Applying %s: %s\", key, value)\n            instance = cls_(self.frame.pil)\n            self.frame.pil = instance.enhance(value)\n\n        # Fixme\n        if config_[\"zoom_factor\"]:\n            self.frame.pil = _zoom_img(self.frame.pil, config_[\"zoom_factor\"])\n\n        self.frame.pil = self._mirror_image(self.frame.pil, config_.get(\"flip\"))\n\n        if config_.get(\"mirror\"):\n            self.frame.pil = _funny_mirror(self.frame.pil)\n\n        if config_.get(\"tint\"):\n            self.frame.pil = _tint_image(\n                self.frame.pil, config_[\"tint\"], config_.get(\"tint_alpha\", 0.5)\n            )\n\n    def _draw_quote(self):\n        if self.frame.message is not None:\n            config_ = self.dict().copy()\n            config_.update(self.frame.bracket.postproc.dict(exclude_unset=True))\n\n            quote = _prettify_quote(\n                _clean_sub(self.frame.message),\n                wrap_width=config_.get(\"wrap_width\"),\n                text_lines=config_.get(\"text_lines\"),\n            )\n            self.frame.finished_quote = quote\n\n            _draw_quote(self.frame.pil, quote, **config_)\n\n            if config_.get(\"mirror_after\"):\n                self.frame.pil = _funny_mirror(self.frame.pil)\n\n    def _crop(self):\n        custom_crop = self.frame.bracket.postproc.custom_crop\n        if custom_crop is not None:\n            self.frame.pil = _scaled_crop(\n                self.frame.pil, custom_crop, self.frame.bracket.postproc.no_scale\n            )\n\n        if self.frame.bracket.postproc.image_url is not None:\n            self._handle_paste(self.frame)  # type: ignore\n\n        elif self.aspect_quotient is not None:\n            x_off = self.frame.bracket.postproc.x_crop_offset\n            y_off = self.frame.bracket.postproc.y_crop_offset\n\n            self.frame.pil = _crop_by_threshold(\n                self.frame.pil,\n                self.aspect_quotient,\n                x_off=x_off,\n                y_off=y_off,\n                custom_crop=custom_crop,\n            )\n\n    @staticmethod\n    def _handle_paste(frame: Frame):\n        image, non_transparent = _get_from_image_url(\n            frame.bracket.postproc.image_url.strip(\"<>\")\n        )\n        size = image.size\n\n        og_image = frame.pil\n        image.thumbnail((og_image.size))\n\n        logger.debug(\"Url image size: %s\", size)\n\n        resize = frame.bracket.postproc.image_size or 1\n        rotate = frame.bracket.postproc.image_rotate\n\n        position = frame.bracket.postproc.image_position or [0, 0]\n        if frame.bracket.postproc.no_scale is False:\n            position = (\n                int(og_image.size[0] * (position[0] / 100)),  # type: ignore\n                int(og_image.size[1] * (position[1] / 100)),  # type: ignore\n            )\n\n        if resize != 1:\n            logger.debug(\"Resizing image: %s * %s\", size, resize)\n            image = image.resize((int(size[0] * resize), int(size[1] * resize)))\n\n        if rotate:\n            logger.debug(\"Rotating image: %s\", rotate)\n            image = image.rotate(int(rotate))\n\n        logger.debug(\"Pasting image: %s\", position)\n        if non_transparent is False:\n            frame.pil.paste(image, position, image)\n        else:\n            frame.pil.paste(image, position)\n\n    @validator(\"stroke_width\", \"text_spacing\", \"text_shadow\")\n    @classmethod\n    def _check_stroke_spacing(cls, val):\n        if val > 30:\n            raise exceptions.InvalidRequest(f\"Dangerous value found: {val}\")\n\n        return val\n\n    @validator(\"y_offset\")\n    @classmethod\n    def _check_y_offset(cls, val):\n        if val > 500:\n            raise exceptions.InvalidRequest(f\"Dangerous value found: {val}\")\n\n        return val\n\n    @validator(\"zoom_factor\")\n    @classmethod\n    def _check_zoom_factor(cls, val):\n        if val is None:\n            return val\n\n        if val < 1 or val > 4:\n            raise exceptions.InvalidRequest(\"Choose between 1 and 4\")\n\n        return val\n\n    @validator(\n        \"contrast\", \"brightness\", \"color\", \"sharpness\", \"font_size\", \"palette_height\"\n    )\n    @classmethod\n    def _check_100(cls, val):\n        if abs(val) > 100:\n            raise exceptions.InvalidRequest(\"Values greater than 100 are not allowed\")\n\n        return val\n\n    @validator(\"palette_color_count\")\n    @classmethod\n    def _check_palette_color_count(cls, val):\n        if val < 2 or val > 20:\n            raise exceptions.InvalidRequest(\"Choose between 2 and 20\")\n\n        return val\n\n    @validator(\"aspect_quotient\")\n    @classmethod\n    def _check_ap(cls, val):\n        if val is None:\n            return None\n\n        if 1 > val < 2.5:\n            raise exceptions.InvalidRequest(f\"Expected 1>|<2.5, found {val}\")\n\n        return val\n\n    @validator(\"font\")\n    @classmethod\n    def _check_font(cls, val):\n        if val not in FONTS_DICT:\n            return \"clearsans\"\n\n        return val\n\n    @validator(\"dimensions\")\n    @classmethod\n    def _check_dimensions(cls, val):\n        if val is None:\n            return None\n\n        if isinstance(val, tuple):\n            return val\n\n        values = [number.strip() for number in val.split(\"x\")]\n\n        if len(values) != 2 or any(not val.isdigit() for val in values):\n            raise exceptions.InvalidRequest(f\"Invalid dimensions: {val}\")\n\n        values = int(values[0]), int(values[1])\n\n        if values not in _VALID_COLLAGES:\n            raise exceptions.InvalidRequest(\n                f\"Invalid collage. Choose between: `{_VALID_COLLAGES}`\"\n            )\n\n        logger.debug(\"Found dimensions value: %s\", values)\n        return values\n\n    @validator(\"glitch\")\n    @classmethod\n    def _check_glitch(cls, val):\n        # --glitch glitch_amount=3,color_offset=True,scan_lines=True\n        if val is None:\n            return None\n\n        glitch_dict = {\"glitch_amount\": 4, \"color_offset\": True, \"scan_lines\": True}\n\n        fields = val.split(\",\")\n        for field in fields:\n            field_split = field.split(\"=\")\n            key = field_split[0]\n\n            if key not in glitch_dict:\n                continue\n\n            if len(field_split) != 2:\n                raise exceptions.InvalidRequest(f\"`{field_split}`\")\n\n            if key == \"glitch_amount\":\n                try:\n                    value = abs(int(field_split[-1]))\n                    if value > 10:\n                        raise exceptions.InvalidRequest(\"Expected <10\") from None\n                except ValueError:\n                    raise exceptions.InvalidRequest(\"Expected integer\") from None\n                glitch_dict[\"glitch_amount\"] = value or 1\n            else:\n                glitch_dict[key] = \"true\" in field_split[-1].lower()\n\n        logger.debug(\"Updated glitch dict: %s\", glitch_dict)\n        return glitch_dict\n\n    @validator(\"apply_to\")\n    @classmethod\n    def _check_apply_to(cls, val):\n        if not val:  # Falsy\n            return None\n\n        if isinstance(val, tuple):\n            return val\n\n        range_ = val.split(\"-\")\n        try:\n            if len(range_) == 1:  # --apply-to x\n                num = int(range_[0].split(\".\")[0])\n                final = tuple(range(num - 1, num))\n            else:  # --apply-to x-x\n                final = tuple(range(int(range_[0]) - 1, int(range_[1])))\n        except ValueError:\n            raise exceptions.InvalidRequest(f\"`{range_}`\") from None\n\n        logger.debug(\"Parsed apply to: %s\", final)\n        return final\n\n    @validator(\"border\")\n    @classmethod\n    def _check_border(cls, val):\n        if val is None:\n            return None\n\n        if isinstance(val, tuple):\n            return val\n\n        try:\n            x_border, y_border = [int(item) for item in val.split(\",\")]\n        except ValueError:\n            raise exceptions.InvalidRequest(f\"`{val}`\") from None\n\n        if any(item > 20 for item in (x_border, y_border)):\n            raise exceptions.InvalidRequest(\"Expected `<20` value\")\n\n        return x_border, y_border\n\n    @validator(\"text_shadow_offset\", \"text_xy\")\n    def _check_shadow_offset(cls, val):\n        if val is None:\n            return None\n\n        if isinstance(val, tuple):\n            return val\n\n        try:\n            x_border, y_border = [int(item) for item in val.split(\",\")]\n        except ValueError:\n            raise exceptions.InvalidRequest(f\"`{val}`\") from None\n\n        if any(item > 100 for item in (x_border, y_border)):\n            pass\n            # raise exceptions.InvalidRequest(\"Expected `<100` value\")\n\n        return x_border, y_border\n\n\ndef _tint_image(img: Image.Image, tint_color, alpha=0.5):\n    image = img.convert(\"RGBA\")\n\n    tint = Image.new(\"RGBA\", image.size, tint_color)\n\n    blended_image = Image.blend(image, tint, alpha=alpha)\n\n    return blended_image.convert(\"RGB\")\n\n\ndef _funny_mirror(img: Image.Image):\n    width, height = img.size\n\n    left_half = img.crop((0, 0, width // 2, height))\n\n    right_half = left_half.transpose(Image.FLIP_LEFT_RIGHT)\n\n    width_left, height_left = left_half.size\n\n    width_right, height_right = right_half.size\n\n    new_width = width_left + width_right\n    new_height = max(height_left, height_right)\n    combined_image = Image.new(\"RGB\", (new_width, new_height))\n\n    combined_image.paste(left_half, (0, 0))\n\n    combined_image.paste(right_half, (width_left, 0))\n\n    return combined_image\n\n\nclass Static:\n    \"\"\"Class for static requests with advanced post-processing.\"\"\"\n\n    def __init__(self, items: Sequence[RequestItem], type_: str, id_: str, **kwargs):\n        self.items = items\n        self.id: str = id_\n        self.type: str = type_\n\n        self.frames: List[Frame] = []\n\n        self._paths = []\n\n        try:\n            self.postproc = PostProc(**kwargs)\n        except ValidationError as error:\n            raise exceptions.InvalidRequest(error) from None\n\n        self._raw: Optional[Image.Image] = None\n        self._request_trace = None\n\n    @classmethod\n    def from_request(cls, request):\n        custom_profiles = request.args.get(\"custom_profiles\")\n        if custom_profiles is None:\n            profiles_path = config.profiles_path\n        else:\n            profiles_path = os.path.join(\n                os.path.dirname(config.profiles_path or \"\"), custom_profiles\n            )\n\n        try:\n            profiles_ = profiles.Profile.from_yaml_file(profiles_path)\n        except (TypeError, FileNotFoundError) as error:\n            logger.error(\n                \"Couldn't load profiles from file: %s (%s)\", profiles_path, error\n            )\n            profiles_ = []\n\n        return cls(\n            request.items,\n            request.type,\n            request.id,\n            **request.args,\n            og_dict=request.args,\n            profiles=profiles_,\n        )\n\n    def get(self, path: Optional[str] = None) -> List[str]:\n        \"\"\"Load and get the image paths for the request.\n\n        :param path:\n        :type path: Optional[str]\n        :rtype: List[str]\n        \"\"\"\n        path = path or os.path.join(FRAMES_DIR, str(self.id))\n\n        os.makedirs(path, exist_ok=True)\n\n        logger.debug(\"Request folder created: %s\", path)\n\n        self._load_frames()\n\n        self.postproc.context.update({\"frame_count\": len(self.frames)})\n\n        single_img = os.path.join(path, f\"00.{IMAGE_EXTENSION}\")\n        self._paths.append(single_img)\n\n        if len(self.frames) == 1:\n            logger.debug(\"Single static image found: %s\", single_img)\n\n            frame = self.frames[0]\n            palette = self.type == \"!palette\"\n            image = self.postproc.process(frame, draw=not palette)\n\n            if palette:\n                palette = LegacyPalette(image)\n                palette.draw()\n                image = palette.image\n\n            image.save(single_img)\n\n        else:\n            images = self.postproc.process_list(self.frames)\n\n            if len(images) == 1:\n                images[0].save(single_img)\n            else:\n                self._paths.pop(0)\n                for num, image in enumerate(images):\n                    path_ = os.path.join(path, f\"{num:02}.{IMAGE_EXTENSION}\")\n                    image.save(path_)\n                    self._paths.append(path_)\n\n        logger.debug(\"Final paths: %s\", self._paths)\n\n        return self._paths\n\n    def make_trace(self) -> request_trace.RequestTrace:\n        data = dict()\n        data[\"frames\"] = [frame.make_trace() for frame in self.frames]\n        data[\"single_image\"] = len(self._paths) == 1\n        data[\"command\"] = self.type\n        data[\"postproc\"] = self.postproc.dict()\n        data[\"postproc_raw\"] = self.postproc.dict(exclude_unset=True)\n\n        return request_trace.RequestTrace(**data)\n\n    @property\n    def initial_item(self) -> RequestItem:\n        \"\"\"Initial item of a RequestItem list (always used for non-parallel\n        requests).\n\n        :rtype: RequestItem\n        \"\"\"\n        return self.items[0]\n\n    @cached_property\n    def story(self) -> Story:\n        \"\"\"Story object ready to get images. Takes only the first media item\n        for parallel requests.\n\n        :rtype: Story\n        \"\"\"\n        assert len(self._paths) > 0\n        return Story(self.initial_item.media, self._paths[0], raw=self._raw)\n\n    @property\n    def content(self) -> str:\n        \"\"\"The content string of the frames.\n\n        Example:\n            TIMESTAMP | QUOTE\n\n        :rtype: str\n        \"\"\"\n        return \" | \".join(frame.pretty_content for frame in self.frames)\n\n    @property\n    def title(self) -> str:\n        \"\"\"The title of the handler.\n\n        Examples:\n            MOVIE (YEAR) dir. DIRECTOR\n            Category: CATEGORY\n\n            MOVIE (YEAR) | EPISODE\n            Category: Kinema Parallels\n\n        :rtype: str\n        \"\"\"\n        if self.postproc.static_title is not None:\n            return self.postproc.static_title\n\n        logger.debug(\"Type: %s\", self.type)\n        if self.type == \"!parallel\":\n            header = self._get_parallel_header()\n            if \" | \" in header:  # Ensure that the request is a parallel\n                return \"\\n\".join((header, self._category_str()))\n\n        header = self.initial_item.media.pretty_title\n        sub = \"\"\n\n        if self.initial_item.media.metadata is not None:\n            sub = self.initial_item.media.metadata.request_title\n\n        return \"\\n\".join((header, sub))\n\n    @property\n    def images(self) -> List[str]:  # Consistency\n        \"List of generated image paths.\"\n        return self._paths\n\n    def _category_str(self) -> str:\n        return \"Category: Parallels\"\n\n    def _load_frames(self):\n        logger.debug(\"Items: %s\", self.items)\n        for request in self.items:\n            request.compute_brackets()\n\n            for frame in request.brackets:\n                frame_ = Frame(request.media, frame, self.postproc)\n                frame_.load_frame()\n\n                logger.debug(\"Appending frame: %s\", frame_)\n\n                self.frames.append(frame_)\n\n        if not self.frames:\n            raise exceptions.NothingFound(\"No valid frames found\")\n\n        # For stories\n        self._raw = self.frames[0].pil\n\n        logger.debug(\"Loaded frames: %s\", len(self.frames))\n\n    def _get_parallel_header(self) -> str:\n        titles = [item.media.parallel_title for item in self.items]\n        # Remove dupes\n        return \" | \".join(list(dict.fromkeys(titles)))\n\n    def __repr__(self) -> str:\n        return f\"<Static ({len(self.items)} items)>\"\n\n\nclass Card(Static):\n    \"Class for the swap handler.\"\n\n    def __init__(self, items: Sequence[RequestItem], type_: str, id_: str, **kwargs):\n        super().__init__(items, type_, id_, **kwargs)\n        self.type = \"!parallel\"  # Temporary\n\n        if len(self.items) != 2:\n            raise exceptions.InvalidRequest(\"Expected only two media items\")\n\n        self._lyrics_item = None\n        self._generic_item = None\n        self._lyrics = \"\"\n\n        for item in items:\n            if item.media.type == \"lyrics\":\n                self._lyrics_item = item\n            else:\n                self._generic_item = item\n\n        if self._lyrics_item is None:\n            raise exceptions.InvalidRequest(\"No lyics media item set\")\n\n    def _load_frames(self):\n        logger.debug(\"Items: %s\", self.items)\n        self._lyrics_item.compute_brackets()  # type: ignore\n\n        lyrics = []\n        for bracket in self._lyrics_item.brackets:\n            lyrics.append(bracket.content.content.replace(\"\\n\", \" \").strip())\n\n        self._lyrics = \"\\n\".join(lyrics)\n\n        self._generic_item.compute_brackets()  # type: ignore\n\n        for frame in self._generic_item.brackets:\n            frame_ = Frame(self._generic_item.media, frame, self.postproc)\n            frame_.load_frame()\n\n            logger.debug(\"Appending frame: %s\", frame_)\n\n            self.frames.append(frame_)\n\n        if not self.frames:\n            raise exceptions.NothingFound(\"No valid frames found\")\n\n        # For stories\n        self._raw = self.frames[0].pil\n\n        logger.debug(\"Loaded frames: %s\", len(self.frames))\n\n    @property\n    def title(self):\n        if self._generic_item.media.type in (\"song\", \"cover\"):\n            titles = str(self._lyrics_item.media)\n        else:\n            titles = (\n                f\"{self._lyrics_item.media} | {self._generic_item.media.simple_title}\"\n            )\n\n        return f\"{titles}\\nCategory: Lyrics Cards\"\n\n    def get(self, path: Optional[str] = None) -> List[str]:\n        image = super().get(path)[0]\n\n        title = f\"{self._lyrics_item.media.simple_title} | {self._generic_item.media.simple_title}\"\n        if len(title) > 70:\n            title = f\"{self._lyrics_item.media.simple_title}\\n{self._generic_item.media.simple_title}\"\n\n        if self._generic_item.media.type in (\"song\", \"cover\"):\n            title = self._lyrics_item.media.simple_title\n\n        lyrics_font = os.path.join(FONTS_DIR, \"programme_light.otf\")\n        title_font = os.path.join(FONTS_DIR, \"Programme-Regular.ttf\")\n\n        make_card(\n            Image.open(image),\n            title.upper(),\n            self._lyrics,\n            lyrics_font=lyrics_font,\n            title_font=title_font,\n        ).save(image)\n\n        return [image]\n\n\nclass Swap(Static):\n    \"Class for the swap handler.\"\n\n    def __init__(self, items: Sequence[RequestItem], type_: str, id_: str, **kwargs):\n        super().__init__(items, type_, id_, **kwargs)\n        self.type = \"!parallel\"  # Temporary\n\n    def _load_frames(self):\n        if len(self.items) != 2:\n            raise exceptions.InvalidRequest(\"Expected 2 items for swap\")\n\n        ids = [item.media.id for item in self.items]\n        if ids[0] == ids[1]:\n            raise exceptions.InvalidRequest(\"Can't swap the same movie\")\n\n        brackets = self._get_brackets()\n\n        # Just left the last media item\n        temp_item = self.items[-1]\n        sliced = np.array_split(brackets, 2)\n\n        source, dest = sliced\n        for old, new in zip(source, dest):\n            if not new.postproc.empty and not old.postproc.keep:\n                new.update_from_swap(old)\n            else:\n                logger.debug(\"Ignoring swap for bracket: %s\", new)\n\n            if old.postproc.keep:\n                logger.debug(\"Keeping source: %s\", old)\n                frame_ = Frame(self.items[0].media, old, self.postproc)\n                frame_.load_frame()\n            else:\n                frame_ = Frame(temp_item.media, new, self.postproc)\n                frame_.load_frame()\n\n            logger.debug(\"Appending frame: %s\", frame_)\n\n            self.frames.append(frame_)\n\n        # For stories\n        self._raw = self.frames[0].pil\n\n        logger.debug(\"Loaded frames: %s\", len(self.frames))\n\n    def _get_brackets(self):\n        brackets = []\n        brackets_len = None\n\n        logger.debug(\"Brackets len: %s\", brackets_len)\n\n        for request in self.items:\n            request.compute_brackets()\n\n            new_len = len(request.brackets)\n\n            if brackets_len is None:\n                brackets_len = new_len\n\n            elif new_len != brackets_len:\n                msg = f\"Inconsistent amount of frames: {brackets_len} -> {new_len}\"\n                if brackets_len != new_len:\n                    raise exceptions.InvalidRequest(msg)\n\n                brackets_len = new_len\n\n            brackets.extend(request.brackets)\n\n        return brackets\n\n    def _category_str(self) -> str:\n        if any(item.media.type != \"movie\" for item in self.items):\n            return \"Category: Swapped Parallels\"\n\n        return \"Category: Swapped Parallels\"\n\n\ndef _scaled_crop(image: Image.Image, custom_crop, no_scale):\n    if no_scale is False:\n        width, height = image.size\n        box = _scale_from_100(custom_crop, width, height)\n        logger.debug(\"Generated custom box: %s\", box)\n        return image.crop(box)\n\n    return image.crop(custom_crop)\n\n\ndef _crop_by_threshold(\n    image: Image.Image, threshold: float = 1.65, **kwargs\n) -> Image.Image:\n    width, height = image.size\n    init_w, init_h = width, height\n    quotient = width / height\n    inc = 0\n    limit = 500\n\n    while True:\n        inc += 1\n        if quotient > threshold:\n            width -= 7\n            quotient = (width - (init_w - width)) / init_h\n            crop_tuple = (init_w - width, 0, width, init_h)\n        else:\n            height -= 7\n            off = init_h - height\n            quotient = init_w / (init_h - off)\n            crop_tuple = (0, off / 2, init_w, init_h - (off / 2))\n\n        if abs(quotient - threshold) < 0.03:\n            crop_tuple = list(crop_tuple)\n\n            # Doing the logic here to avoid making operations on every loop\n            if kwargs.get(\"x_off\"):\n                total_removed = crop_tuple[0]\n                offset = total_removed * (kwargs[\"x_off\"] / 100)\n                crop_tuple[0], crop_tuple[2] = (\n                    crop_tuple[0] + offset,\n                    crop_tuple[2] + offset,\n                )\n\n            if kwargs.get(\"y_off\"):\n                total_removed = crop_tuple[1]\n                offset = total_removed * (kwargs[\"y_off\"] / 100)\n                crop_tuple[1], crop_tuple[3] = (\n                    crop_tuple[1] - offset,\n                    crop_tuple[3] - offset,\n                )\n\n            crop_tuple = tuple(crop_tuple)\n            logger.debug(\"Final quotient and crop tuple: %s - %s\", quotient, crop_tuple)\n            logger.debug(\"Total loops: %d\", inc)\n            return image.crop(crop_tuple)\n\n        if inc > limit:\n            raise NotImplementedError(\n                f\"An infinite loop was prevented: {init_w}/{init_w}\"\n            )\n\n\ndef _scale_from_100(box: list, width: int, height: int) -> tuple:\n    left = width * (box[0] / 100)\n    upper = height * (box[1] / 100)\n    right = width * (box[2] / 100)\n    lower = height * (box[3] / 100)\n\n    return (left, upper, right, lower)\n\n\ndef _crop_image(image: Image.Image, new_width=720, new_height=480) -> Image.Image:\n    width, height = image.size\n\n    left = (width - new_width) / 2\n    right = (width + new_width) / 2\n    top = (height - new_height) / 2\n    bottom = (height + new_height) / 2\n\n    return image.crop((int(left), int(top), int(right), int(bottom)))\n\n\ndef _thumbnail_images(images: List[Image.Image]):\n    \"\"\"\n    :param images: list of PIL.Image objects\n    \"\"\"\n    sizes = [image.size for image in images]\n\n    for image in images:\n        if image.size != min(sizes):\n            image.thumbnail(min(sizes))\n        yield image\n\n\ndef _homogenize_images(images: List[Image.Image]) -> list:\n    \"\"\"\n    :param images: list of PIL.Image objects\n    \"\"\"\n    images = list(_thumbnail_images(images))\n\n    first_min = min([image.size for image in images], key=lambda t: t[0])\n    second_min = min([image.size for image in images], key=lambda t: t[1])\n\n    return [_crop_image(image, first_min[0], second_min[1]) for image in images]\n\n\ndef _fix_dar(cv2_image, dar: float):\n    \"\"\"\n    Fix aspect ratio from cv2 image array.\n    \"\"\"\n    logger.debug(\"Fixing image with DAR: %s\", dar)\n\n    width, height = cv2_image.shape[:2]\n\n    # fix width\n    fixed_aspect = dar / (width / height)\n    width = int(width * fixed_aspect)\n    # resize with fixed width (cv2)\n    return cv2.resize(cv2_image, (width, height))\n\n\ndef _draw_quote(image: Image.Image, quote: str, modify_text: bool = True, **kwargs):\n    scale = kwargs.get(\"font_size\", 27.5) * 0.001\n    font_size = int((image.size[0] * scale) + (image.size[1] * scale))\n    logger.debug(\"Guessed font size: %s\", font_size)\n    y_offset = kwargs.get(\"y_offset\", 15)\n\n    lines_count = len(quote.split(\"\\n\"))\n\n    if lines_count > 1:\n        text_height = _get_text_height(image, quote.split(\"\\n\")[0], **kwargs)\n        to_add = _get_percentage_of(text_height, image.size[1]) * lines_count\n\n        new_y_offset = y_offset + ((to_add / lines_count) * (lines_count - 1))\n\n        logger.debug(\"New y offset: %s -> %s\", y_offset, new_y_offset)\n\n        kwargs.update({\"y_offset\": new_y_offset})\n\n    plus_y = 0\n\n    for line in quote.split(\"\\n\"):\n        plus_y += __draw_quote(image, line, plus_y=plus_y, **kwargs)\n\n\ndef _get_text_height(image, quote, **kwargs):\n    font = FONTS_DICT.get(kwargs.get(\"font\", \"\")) or _DEFAULT_FONT\n    draw = ImageDraw.Draw(image)\n\n    width, height = image.size\n\n    scale = kwargs.get(\"font_size\", 27.5) * 0.001\n\n    font_size = int((width * scale) + (height * scale))\n    font = ImageFont.truetype(font, font_size)\n\n    _, txt_h = draw.textsize(quote, font)  # type: ignore\n    return txt_h\n\n\ndef _get_text_area_box(image, quote, **kwargs):\n    font = FONTS_DICT.get(kwargs.get(\"font\", \"\")) or _DEFAULT_FONT\n    draw = ImageDraw.Draw(image)\n\n    width, height = image.size\n\n    scale = kwargs.get(\"font_size\", 27.5) * 0.001\n\n    font_size = int((width * scale) + (height * scale))\n    font = ImageFont.truetype(font, font_size)\n\n    off = _get_percentage(kwargs.get(\"y_offset\", 15), height)\n\n    txt_w, txt_h = draw.textsize(quote, font)  # type: ignore\n    txt_h = font_size\n\n    draw_h = height - txt_h - off\n    x1 = (width - txt_w) / 2\n\n    # return _TextAreaData(x1=x1, y1=draw_h, x2=x1 + txt_w, y2=draw_h + txt_h)\n    return (x1, draw_h, x1 + txt_w, draw_h + txt_h)\n\n\ndef _get_percentage_of(value, total):\n    return int((value / total) * 100)\n\n\ndef _get_percentage(percentage, total) -> int:\n    return int((percentage / 100) * total)\n\n\ndef __draw_quote(image: Image.Image, quote: str, plus_y=0, **kwargs):\n    \"\"\"Draw a quote into a PIL Image object.\n\n    :param image:\n    :type image: Image.Image\n    :param quote:\n    :type quote: str\n    :param kwargs:\n        * font\n        * font_size\n        * font_color\n        * text_spacing\n        * text_align\n        * y_offset\n        * stroke_width\n        * stroke_color\n        * text_background\n    \"\"\"\n    font = FONTS_DICT.get(kwargs.get(\"font\", \"\")) or _DEFAULT_FONT\n    draw = ImageDraw.Draw(image)\n\n    text_xy = kwargs.get(\"text_xy\")\n    logger.debug(\"About to draw quote: %s (font: %s)\", quote, font)\n\n    width, height = image.size\n    logger.debug(\"Width, height: %s\", (width, height))\n\n    scale = kwargs.get(\"font_size\", 27.5) * 0.001\n\n    font_size = int((width * scale) + (height * scale))\n\n    try:\n        font = ImageFont.truetype(font, font_size)\n    except OSError:\n        raise exceptions.InvalidRequest(f\"Ivalid font: {font}\")\n\n    off = _get_percentage(kwargs.get(\"y_offset\", 15), height)\n    logger.debug(\"Offset: %s\", off)\n\n    txt_w, txt_h = draw.textsize(quote, font)\n    txt_h = font_size\n\n    draw_h = height - txt_h - off\n    if kwargs.get(\"text_background\"):\n        kwargs[\"stroke_width\"] = 0\n        x = (width - txt_w) / 2\n        div = draw_h * 0.033  # IDK\n        y = draw_h + div\n        box = (x, y - div, x + txt_w, y + txt_h)\n        draw.rectangle(box, fill=kwargs[\"text_background\"])\n\n    stroke_width = 0\n    logger.debug((txt_w, txt_h))\n    logger.debug(\n        (((width - txt_w) / 2), draw_h + plus_y),\n    )\n\n    if kwargs.get(\"text_shadow\"):\n        blurred = Image.new(\"RGBA\", image.size)\n        draw_1 = ImageDraw.Draw(blurred)\n        offset = [int(i) for i in kwargs.get(\"text_shadow_offset\", (5, 5))]\n\n        stroke_width = int(kwargs.get(\"text_shadow_stroke\", 2))\n        if not text_xy:\n            box_ = (((width - txt_w) / 2) + offset[0], draw_h + offset[1] + plus_y)\n        else:\n            box_ = text_xy[0] + offset[0], text_xy[1] + offset[1] + plus_y\n\n        draw_1.text(\n            box_,\n            quote,\n            kwargs.get(\"text_shadow_color\", \"black\"),\n            font=font,\n            align=kwargs.get(\"text_align\", \"center\"),\n            spacing=kwargs.get(\"text_spacing\", 0.8),\n            stroke_width=stroke_width,\n            stroke_fill=kwargs.get(\"stroke_color\", \"black\"),\n        )\n        blur_type = kwargs.get(\"text_shadow_blur\", \"boxblur\")\n\n        if blur_type == \"gaussian\":\n            blurred = blurred.filter(ImageFilter.GaussianBlur(kwargs[\"text_shadow\"]))\n        else:\n            blurred = blurred.filter(ImageFilter.BoxBlur(kwargs[\"text_shadow\"]))\n\n        image.paste(blurred, blurred)\n\n    if not text_xy:\n        draw_box = (width - txt_w) / 2, draw_h + plus_y\n    else:\n        draw_box = text_xy[0], text_xy[1] + plus_y\n\n    draw.text(\n        # ((width - txt_w) / 2, draw_h),\n        draw_box,\n        quote,\n        kwargs.get(\"font_color\", \"white\"),\n        font=font,\n        align=kwargs.get(\"text_align\", \"center\"),\n        spacing=kwargs.get(\"text_spacing\", 0.8),\n        stroke_width=int(width * (kwargs.get(\"stroke_width\", 3) * 0.001)),\n        stroke_fill=kwargs.get(\"stroke_color\", \"black\"),\n    )\n    return txt_h\n\n\ndef _load_pil_from_cv2(cv2_img: np.ndarray):\n    \"\"\"\n    Convert an array to a PIL.Image object.\n    \"\"\"\n    image = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)\n    return Image.fromarray(image)\n\n\n# A better way?\ndef _scale_to_gif(frame) -> np.ndarray:\n    \"\"\"Scale an image to make it suitable for GIFs.\"\n\n    :param frame:\n    :rtype: np.ndarray\n    \"\"\"\n    w, h = frame.shape[1], frame.shape[0]\n    inc = 0.5\n    while True:\n        if w * inc < 600:\n            break\n        inc -= 0.1\n\n    return cv2.resize(frame, (int(w * inc), int(h * inc)))\n\n\ndef _prettify_quote(text: str, wrap_width=None, text_lines=None) -> str:\n    \"\"\"\n    Adjust line breaks to correctly draw a subtitle.\n\n    :param text: text\n    \"\"\"\n    lines = [\" \".join(line.split()) for line in text.split(\"\\n\")]\n    if not lines:\n        return text\n\n    final_text = \"\\n\".join(lines)\n\n    if text_lines is not None:\n        logger.debug(\"Running wrap based on %s text lines\", text_lines)\n        param = len(final_text) // text_lines\n        return _harmonic_wrap(text, param, param)\n\n    if wrap_width is not None:\n        logger.debug(\"Using wrap width: %s\", wrap_width)\n        return textwrap.fill(final_text, width=wrap_width)\n\n    if any(\"- \" in line for line in lines):\n        logger.debug(\"Dialogue found. Not modifying text\")\n        return final_text\n\n    if len(lines) == 2:\n        return final_text\n\n    if len(lines) > 2 or (len(lines) == 1 and len(lines[0]) > 38):\n        logger.debug(\"len(lines) >= 2 or (len(lines) == 1 and len(lines[0]) > 38) met\")\n        return _harmonic_wrap(final_text)\n\n    logger.debug(\"Nothing to modify\")\n    return final_text\n\n\ndef __justify(txt: str, width: int) -> str:\n    # https://stackoverflow.com/a/66087666\n    prev_txt = txt\n    while (l := width - len(txt)) > 0:\n        txt = re.sub(r\"(\\s+)\", r\"\\1 \", txt, count=l)\n        if txt == prev_txt:\n            break\n    return txt.rjust(width)\n\n\ndef _handle_text_justify(text: str, wrap_width=30, text_len_diff_tolerancy=10):\n    text = text.replace(\"\\n\", \" \")\n\n    wrapper = textwrap.TextWrapper(width=wrap_width)\n    dedented_text = textwrap.dedent(text=text)\n\n    txt = wrapper.fill(text=dedented_text)\n\n    for l in txt.splitlines():\n        print(__justify(l, wrap_width // 2))\n\n\ndef __prettify_quote(text: str) -> str:\n    \"\"\"\n    Adjust line breaks to correctly draw a subtitle.\n\n    :param text: text\n    \"\"\"\n    lines = [\" \".join(line.split()) for line in text.split(\"\\n\")]\n    final_text = \"\\n\".join(lines)\n\n    if len(lines) == 2 and not any(\"-\" in line for line in lines):\n        # if abs(len(lines[0]) - len(lines[1])) > 30:\n        final_text = _harmonic_wrap(final_text.replace(\"\\n\", \" \"))\n\n    if (len(lines) == 1 and len(text) > 35) or len(lines) > 2:\n        final_text = _harmonic_wrap(final_text)\n\n    if len(re.findall(\"-\", final_text)) == 1 and final_text.startswith(\"-\"):\n        final_text = final_text.replace(\"-\", \"\").strip()\n\n    return final_text\n\n\ndef _harmonic_wrap(text, limit=50, start=25):\n    \"\"\"\n    Harmonically wrap long text so it looks good on the frame.\n    :param text\n    \"\"\"\n    text_len = len(text)\n    text_len_half = text_len / 2\n\n    inc = start\n    while True:\n        split_text = textwrap.wrap(text, width=inc)\n\n        if abs(text_len - inc) < text_len_half and len(split_text) < 3:\n            break\n\n        if len(split_text) == 1 or inc > limit:\n            break\n\n        if len(split_text) != 2:\n            inc += 3\n            continue\n\n        text1, text2 = split_text\n\n        if abs(len(text1) - len(text2)) <= 5:\n            logger.debug(\"Optimal text wrap width found: %d\", inc)\n            break\n\n        inc += 3\n\n    return \"\\n\".join(split_text)\n\n\ndef _remove_lateral_cv2(cv2_image):\n    \"\"\"\n    :param cv2_image: cv2 image array\n    \"\"\"\n    width = cv2_image.shape[1]\n\n    checks = 0\n    for i in range(width):\n        if np.mean(cv2_image[:, i, :]) > 1.7:\n            break\n        checks += 1\n\n    for j in range(width - 1, 0, -1):\n        if np.mean(cv2_image[:, j, :]) > 1.7:\n            break\n        checks += 1\n\n    if checks < 10:\n        return cv2_image  # Why even bother copying?\n\n    return cv2_image[:, i : j + 1, :].copy()  # type: ignore\n\n\ndef _clean_sub(text: str) -> str:\n    \"\"\"\n    Remove unwanted characters from a subtitle string.\n\n    :param text: text\n    \"\"\"\n    logger.debug(\"About to clean subtitle: %s\", text)\n\n    for replacement in _REPLACEMENTS:\n        logger.debug(\"Using %s replacement. Og text: %s\", replacement[0], text)\n        text = re.sub(replacement[0], replacement[1], text)\n\n    logger.debug(\"Result: %s\", text)\n    return text.strip()\n\n\ndef _pretty_scale(image: Image.Image, min_w=1500):\n    if image.size[0] >= min_w:\n        logger.debug(\"Image already met %s requirement: %s\", min_w, image.size)\n        return image\n\n    to_scale = min_w / image.size[0]\n    new_size = tuple(int(item * to_scale) for item in image.size)\n    logger.debug(\"Scaling to new size: %s\", new_size)\n    return image.resize(new_size)\n\n\nclass Collage:\n    \"Class for image collages with support for borders and multiple dimensions.\"\n\n    def __init__(\n        self,\n        images: List[Image.Image],\n        dimensions: Optional[Tuple[int, int]] = None,\n    ):\n        self._images = images\n        self._dimensions = dimensions or _POSSIBLES[len(images)]\n        self._lateral = self._dimensions in _LATERAL_COLLAGES\n        self._border_x: Optional[int] = None\n        self._border_y: Optional[int] = None\n        self._color: Optional[str] = None\n\n    @property\n    def lateral(self) -> bool:\n        return self._dimensions in _LATERAL_COLLAGES\n\n    def add_borders(self, borders: Tuple[int, int] = (10, 10), color: str = \"white\"):\n        \"\"\"Add borders to every image.\n\n        :param borders:\n        :type borders: Tuple[int, int]\n        \"\"\"\n        self._color = color\n\n        width = self._images[0].size[1]  # Use width as a reference\n\n        self._border_x = int(width * (borders[1] / 100))\n        self._border_y = int(width * (borders[0] / 100))\n\n        logger.debug(\"Borders: %s\", (self._border_x, self._border_y))\n\n        imgs_len = len(self._images)\n        new_imgs = []\n\n        for index in range(imgs_len):\n            image = self._images[index]\n\n            bottom = 0 if index != (imgs_len - 1) else self._border_y\n            right = 0 if self.lateral and index not in (1, 3, 5) else self._border_x\n\n            box = (self._border_x, self._border_y, right, bottom)\n\n            logger.debug(\"Applying border: %s\", box)\n            new_imgs.append(ImageOps.expand(image, border=box, fill=self._color))\n\n        self._images = new_imgs\n\n    def get(self) -> Image.Image:\n        \"\"\"Create the collage.\"\"\"\n        width, height = self._images[0].size\n\n        row, col = self._dimensions\n        logger.debug(\"rXc: %s\", (row, col))\n\n        collage_width = row * width\n        collage_height = col * height\n        new_image = Image.new(\"RGB\", (collage_width, collage_height))\n        cursor = (0, 0)\n\n        for image in self._images:\n            new_image.paste(image, cursor)\n            y = cursor[1]\n            x = cursor[0] + width\n            if cursor[0] >= (collage_width - width):\n                y = cursor[1] + height\n                x = 0\n            cursor = (x, y)\n\n        logger.debug(\"Dimmensions: %s\", new_image.size)\n\n        if self._border_x is not None:\n            return self._fix_bordered(new_image)\n\n        return new_image\n\n    def _fix_bordered(self, image: Image.Image):\n        box = (0, 0, self._border_x if self.lateral else 0, self._border_y)\n        return ImageOps.expand(image, border=box, fill=self._color)\n\n\ndef _zoom_img(img: Image.Image, zoom_factor=1.3):\n    width, height = img.size\n\n    new_width = int(width * zoom_factor)\n    new_height = int(height * zoom_factor)\n\n    resized_img = img.resize((new_width, new_height))\n\n    x = int((new_width - width) / 2)\n    y = int((new_height - height) / 2)\n\n    cropped_img = resized_img.crop((x, y, x + width, y + height))\n    return cropped_img\n\n\ndef _get_from_image_url(url: str):\n    name = f\"{uuid.uuid3(uuid.NAMESPACE_URL, url)}.png\"\n    path = os.path.join(CACHED_FRAMES_DIR, name)\n\n    if not os.path.isfile(path):\n        download_image(url, path)\n\n    non_transparent = False\n\n    try:\n        image = Image.open(path)\n    except UnidentifiedImageError:\n        raise exceptions.InvalidRequest(f\"Not a valid image: {url}\")\n    else:\n        try:\n            _test_transparency_mask(image)\n        except ValueError:\n            logger.debug(\"Non transparent image found: %s\", url)\n            non_transparent = True\n\n    image = image.crop(image.getbbox())\n    image.thumbnail((1280, 720))\n    return image, non_transparent\n\n\ndef _test_transparency_mask(image):\n    \"\"\"\n    :raises ValueError\n    \"\"\"\n    white = Image.new(size=(100, 100), mode=\"RGB\")\n    white.paste(image, (0, 0), image)\n\n\ndef _get_white_level(image):\n    grayscale_image = image.convert(\"L\")\n\n    pixel_data = list(grayscale_image.getdata())\n    average_intensity = sum(pixel_data) / len(pixel_data)\n\n    whiteness_level = (average_intensity / 255) * 100\n\n    return whiteness_level\n\n\ndef _draw_pixel_grid(image, grid_color=None):\n    draw = ImageDraw.Draw(image)\n\n    grid_color = grid_color or \"white\"  # (255, 0, 0)\n    grid_thickness = 1\n    font_size = 30\n    font = ImageFont.truetype(_DEFAULT_FONT, font_size)\n\n    width, height = image.size\n\n    x_interval = width // 15\n    y_interval = height // 15\n\n    for x in range(0, width, x_interval):\n        draw.line([(x, 0), (x, height)], fill=grid_color, width=grid_thickness)\n        draw.text((x + 2, 2), str(x), fill=grid_color, font=font)\n\n    for y in range(0, height, y_interval):\n        draw.line([(0, y), (width, y)], fill=grid_color, width=grid_thickness)\n        draw.text((2, y + 2), str(y), fill=grid_color, font=font)\n\n    return image\n\n\ndef _get_used_profiles(value):\n    used = [prof for prof in value if prof.get(\"used\") and prof.get(\"requirements\")]\n    return \"; \".join(str(i.get(\"name\", \"n/a\")) for i in used)\n\n\ndef _get_info_str(width, height, item: dict):\n    image_info = (\n        f\"Image Size: {width}x{height}\\nAspect quotient: {round(width / height, 3)}\"\n    )\n\n    lines = []\n    for key, val in item.items():\n        if key == \"profiles\" and val:\n            lines.append(f\"Used profiles: {_get_used_profiles(val)}\")\n            continue\n\n        if not isinstance(val, (str, float, int, bool, tuple)):\n            continue\n\n        lines.append(f\"{key.replace('_', ' ').capitalize()}: {val}\")\n\n    lines = \"\\n\".join(lines)\n    return f\"{image_info}\\n------------------\\nCustom post-processing applied:\\n{lines}\"\n\n\ndef _draw_image_info(image, info=None):\n    original_image = image\n    width, height = original_image.size\n    white_base = Image.new(\"RGB\", (width, height), color=\"white\")\n\n    draw = ImageDraw.Draw(white_base)\n\n    font_size = 25\n    font = ImageFont.truetype(_DEFAULT_FONT, size=font_size)\n\n    image_info = _get_info_str(width, height, info or {})\n\n    _, text_height = draw.textsize(image_info, font=font)\n\n    extra_height = text_height + 20\n    white_base = white_base.resize((width, height + extra_height))\n\n    white_base.paste(original_image, (0, 0))\n\n    draw = ImageDraw.Draw(white_base)\n\n    draw.text((10, height + 10), image_info, fill=\"black\", font=font)\n\n    return white_base\n\n\ndef _get_debug(image, info=None, grid_color=None):\n    _draw_pixel_grid(image, grid_color=grid_color)\n    return _draw_image_info(image, info)\n"}
{"type": "source_file", "path": "kinobot/instagram/factory.py", "content": "import logging\nfrom typing import List\n\nfrom . import Client\nfrom . import config\nfrom . import db\nfrom . import publishers\nfrom . import services\n\nlogger = logging.getLogger(__name__)\n\n_mapped_params = {\n    \"request\": db.RequestRepository,\n    \"user\": db.UserRepository,\n    \"post\": db.PostRepository,\n}\n\n\n_func_map = {\"make_repository\": lambda a, b=None: [db.make_repository(a, b)]}\n\n\ndef _handle_factory(data: dict, publisher_name):\n    func_ = _func_map[data[\"func\"]]\n    publisher = publishers.publishers[publisher_name]\n    args = []\n\n    for arg in data.get(\"args\", []):\n        if isinstance(arg, str) and arg.startswith(\"mapped.\"):\n            args.append(_mapped_params[arg.lstrip(\"mapped.\")])\n        else:\n            args.append(arg)\n\n    args = func_(*args, **data.get(\"kwargs\", {}))\n    return publisher(*args)\n\n\ndef _handle_default(data: dict, publisher_name):\n    publisher = publishers.publishers[publisher_name]\n    return publisher(*data.get(\"args\", []), **data.get(\"kwargs\", {}))\n\n\ndef make_post_kwargs(config: config.Config):\n    handler = services.Handler(**config.client)\n    #  req_repo = db.make_repository(db.RequestRepository, config.db_url)\n    client = Client(**config.ig_client)\n\n    def _event_publisher(finished):\n        pubs = make_post_publishers(config.publishers)\n        for pub in pubs:\n            logger.debug(\"Running %s\", pub)\n            pub(finished)\n\n    return dict(\n        client=client,\n        # picker=req_repo.get_random_active_request,\n        req_handler=handler,\n        event_publisher=_event_publisher,\n    )\n\n\ndef make_post_publishers(publisher_configs: List[config.Publisher]):\n    items = []\n    for publisher in publisher_configs:\n        logger.debug(publisher)\n        if publisher.enabled is False:\n            logger.debug(\"Not enabled: %s\", publisher)\n            continue\n\n        if publisher.handler not in publishers.publishers:\n            logger.debug(\"Handler not registered: %s\", publisher.handler)\n            continue\n\n        constructor = publisher.constructor\n        if not constructor:\n            logger.debug(\"Invalid constructor: %s\", constructor)\n            continue\n\n        if \"factory\" in constructor:\n            logger.debug(\"Mapped factory\")\n            item = _handle_factory(constructor[\"factory\"], publisher.handler)\n        else:\n            logger.debug(\"Default factory\")\n            item = _handle_default(constructor, publisher.handler)\n\n        logger.debug(\"Created publisher: %s\", item)\n        items.append(item)\n\n    return items\n"}
{"type": "source_file", "path": "kinobot/discord/extras/curator.py", "content": "import datetime\nimport logging\nfrom typing import Dict, List, Optional\n\nfrom discord import Embed\nimport pydantic\nfrom pydantic import ConfigDict\nimport requests\n\nfrom kinobot.config import config\nfrom kinobot.db import Kinobase\nfrom kinobot.exceptions import KinoException\n\nlogger = logging.getLogger(__name__)\n\n\ndef _to_camel(string: str) -> str:\n    result = \"\".join(word.capitalize() for word in string.split(\"_\"))\n    return result[0].lower() + result[1:]\n\n\nclass RadarrMovie(pydantic.BaseModel):\n    model_config = ConfigDict(alias_generator=_to_camel)\n    added: Optional[datetime.datetime]\n    clean_title: str\n    folder_name: str\n    id: int\n    imdb_id: Optional[str]\n    is_available: bool\n    minimum_availability: str\n    monitored: bool\n    movie_file: Optional[Dict] = None\n    original_title: str\n    path: str\n    quality_profile_id: int\n    runtime: int\n    size_on_disk: int\n    sort_title: str\n    status: str\n    studio: str\n    title: str\n    title_slug: str\n    tmdb_id: int\n    website: str\n    year: int\n    og_dict: dict\n\n    @property\n    def has_file(self):\n        return self.movie_file is not None\n\n\nclass RadarrMovieModel(pydantic.BaseModel):\n    model_config = ConfigDict(alias_generator=_to_camel)\n    added: str\n    title: str\n    folder: str\n    tmdb_id: int\n    movie_file: Optional[dict] = None\n    overview: str\n    year: int\n    imdb_id: Optional[str] = None\n    remote_poster: Optional[str] = None\n    original_title: Optional[str] = None\n\n    @property\n    def has_file(self):\n        return self.movie_file is not None\n\n\n_IMDB_BASE = \"https://www.imdb.com/title\"\n\n\nclass SonarrEpisodeFileModel(pydantic.BaseModel):\n    season_number: int\n    model_config = ConfigDict(alias_generator=_to_camel)\n\n\nclass _Season(pydantic.BaseModel):\n    season_number: int\n    model_config = ConfigDict(alias_generator=_to_camel)\n\n\nclass SonarrTVShowModel(pydantic.BaseModel):\n    added: str\n    title: str\n    folder: str\n    tvdb_id: int\n    path: Optional[str] = None\n    year: int = 0\n    overview: str = \"\"\n    imdb_id: Optional[str] = None\n    remote_poster: Optional[str] = None\n    seasons: List[_Season]\n    model_config = ConfigDict(alias_generator=_to_camel)\n\n    def already_added(self):\n        return self.path is not None\n\n    def embed(self) -> Embed:\n        \"\"\"Discord embed used for Discord searchs.\n\n        :rtype: Embed\n        \"\"\"\n        embed = Embed(\n            title=self.title,\n            description=self.overview,\n        )\n\n        if self.remote_poster is not None:\n            embed.set_image(url=self.remote_poster)\n\n        return embed\n\n    def pretty_title(self):\n        return f\"{self.title} ({self.year})\"\n\n    def markdown(self):\n        return f\"[{self.title}]({self._imdb_url()})\"\n\n    def _imdb_url(self):\n        return f\"{_IMDB_BASE}/{self.imdb_id}\"\n\n\nclass MovieView:\n    def __init__(self, data: dict):\n        self._model = RadarrMovieModel.model_validate(data)\n        self.data = data\n\n    def pretty_title(self):\n        if (\n            self._model.original_title is None\n            or self._model.title.lower() == self._model.original_title.lower()\n        ):\n            title = self._model.title\n        else:\n            title = f\"{self._model.original_title} [{self._model.title}]\"\n\n        title = f\"{title} ({self._model.year})\"\n\n        if self.already_added():\n            title = f\"{title} (Available on Kinobot)\"\n\n        # if self.to_be_added():\n        #    title = f\"{title} (To be added)\"\n\n        return title\n\n    def already_added(self):\n        return self._model.has_file\n\n    def to_be_added(self):\n        return not self._model.has_file and self._model.added != \"0001-01-01T00:00:00Z\"\n\n    def embed(self) -> Embed:\n        \"\"\"Discord embed used for Discord searchs.\n\n        :rtype: Embed\n        \"\"\"\n        embed = Embed(\n            title=self.pretty_title(),\n            url=self._imdb_url(),\n            description=self._model.overview,\n        )\n\n        if self._model.remote_poster is not None:\n            embed.set_image(url=self._model.remote_poster)\n\n        return embed\n\n    def markdown(self):\n        return f\"[{self.pretty_title()}]({self._imdb_url()})\"\n\n    def _imdb_url(self):\n        return f\"{_IMDB_BASE}/{self._model.imdb_id}\"\n\n    @property\n    def tmdb_id(self):\n        return self._model.tmdb_id\n\n\nclass _Quality(pydantic.BaseModel):\n    name: str = \"Unknown\"\n    resolution: int = 480\n\n\nclass ReleaseModel(pydantic.BaseModel):\n    size: int\n    guid: str\n    indexer_id: int\n    indexer_flags: List\n    movie_id: int\n    rejected: bool\n    rejections: list = []\n    seeders: int\n    quality: _Quality\n    title: str = \"Unknown\"\n    model_config = ConfigDict(alias_generator=_to_camel)\n\n    @pydantic.validator(\"quality\", pre=True, always=True)\n    def set_ts_now(cls, v):\n        try:\n            return _Quality(**v[\"quality\"])\n        except KeyError:\n            return _Quality()\n\n    def pretty_title(self):\n        title = f\"{self.title} (**{self.size/float(1<<30):,.1f} GB**)\"\n\n        strike = False\n\n        if self.rejected:\n            strike = True\n\n        if \"extras\" in self.title.lower():\n            strike = True\n\n        if (\n            \"DV\" in self.title or \"HDR\" in self.title\n        ) and \"dvd\" not in self.title.lower():\n            strike = True\n\n        if \"remux\" in self.title.lower():\n            strike = True\n\n        if strike:\n            return f\"~~{title}~~\"\n\n        return title\n\n\nclass ReleaseModelSonarr(pydantic.BaseModel):\n    size: int\n    guid: str\n    indexer_id: int\n    series_id: int\n    full_season: bool\n    rejected: bool\n    rejections: list = []\n    seeders: int\n    quality: _Quality\n    title: str = \"Unknown\"\n    model_config = ConfigDict(alias_generator=_to_camel)\n\n    @pydantic.validator(\"quality\", pre=True, always=True)\n    def set_ts_now(cls, v):\n        try:\n            return _Quality(**v[\"quality\"])\n        except KeyError:\n            return _Quality()\n\n    def pretty_title(self):\n        title = f\"{self.title} (**{self.size/float(1<<30):,.1f} GB**)\"\n\n        strike = False\n        if self.rejected:\n            strike = True\n\n        if \"extras\" in self.title.lower():\n            strike = True\n\n        if (\n            \"DV\" in self.title or \"HDR\" in self.title\n        ) and \"dvd\" not in self.title.lower():\n            strike = True\n\n        if \"remux\" in self.title.lower():\n            strike = True\n\n        if strike:\n            return f\"~~{title}~~\"\n\n        return title\n\n\nclass Statistics(pydantic.BaseModel):\n    size_on_disk: int = 0\n    model_config = ConfigDict(alias_generator=_to_camel)\n\n\nclass SonarrTVShow(pydantic.BaseModel):\n    id: int\n    title: str\n    tvdb_id: Optional[int]\n    series_type: Optional[str]\n    imdb_id: Optional[str]\n    added: Optional[datetime.datetime]\n    statistics: Optional[Statistics]\n    model_config = ConfigDict(alias_generator=_to_camel)\n\n\nclass CuratorException(KinoException):\n    pass\n\n\nclass MovieAlreadyAdded(CuratorException):\n    pass\n\n\nclass MovieNotFound(CuratorException):\n    pass\n\n\nclass RadarrClient:\n    def __init__(self, url, api_key, root_folder_path=None):\n        self._base = f\"{url}/api/v3\"\n\n        self._session = requests.Session()\n        self._session.headers.update(\n            {\n                \"Connection\": \"keep-alive\",\n                \"Sec-GPC\": \"1\",\n                \"X-Api-Key\": api_key,\n            }\n        )\n        if root_folder_path is None:\n            self._root_folder_path = self._get_root_folder()\n        else:\n            self._root_folder_path = root_folder_path\n\n        logger.debug(\"Client started: %s (%s)\", self._base, self._root_folder_path)\n\n    def _get_root_folder(self):\n        response = self._session.get(f\"{self._base}/rootFolder\", verify=False)\n        response.raise_for_status()\n\n        try:\n            return response.json()[0][\"path\"]\n        except (IndexError, KeyError) as error:\n            logger.error(\"Error trying to get root foolder: %s\", error)\n            return None\n\n    @classmethod\n    def from_constants(cls):\n        return cls(config.curator.radarr.url, config.curator.radarr.token)\n\n    def movie(self):\n        response = self._session.get(f\"{self._base}/movie\")\n        return [\n            RadarrMovie.model_validate({**item, **{\"og_dict\": item}})\n            for item in response.json()\n        ]\n\n    def add(\n        self,\n        movie: dict,\n        search_for_movie=False,\n        quality_profile_id=1,\n        monitored=False,\n        minimum_availability=\"announced\",\n        root_folder_path=None,\n    ):\n        if movie.get(\"id\"):\n            logger.debug(\"Movie already added\")\n            return movie\n            # raise MovieAlreadyAdded(movie[\"title\"])\n\n        movie.update(\n            {\n                \"addOptions\": {\n                    \"searchForMovie\": search_for_movie,\n                },\n                \"rootFolderPath\": root_folder_path or self._root_folder_path,\n                \"qualityProfileId\": quality_profile_id,\n                \"monitored\": monitored,\n                \"minimumAvailability\": minimum_availability,\n            }\n        )\n\n        response = self._session.post(f\"{self._base}/movie\", json=movie, verify=False)\n        response.raise_for_status()\n        return response.json()\n\n    def manual_search(self, movie_id):\n        response = self._session.get(\n            f\"{self._base}/release\", params={\"movieId\": movie_id}\n        )\n        response.raise_for_status()\n        result = response.json()\n        for release in result:\n            release[\"movieId\"] = movie_id\n\n        return result\n\n    def add_to_download_queue(self, movie_id, guid, indexer_id):\n        json_data = {\n            \"guid\": guid,\n            \"indexerId\": indexer_id,\n            \"movieId\": movie_id,\n        }\n\n        response = self._session.post(\n            f\"{self._base}/release\", json=json_data, verify=False\n        )\n        try:\n            logger.debug(response.json())\n        except:\n            pass\n\n        response.raise_for_status()\n        return response.json()\n\n    def delete(self, movie_id, delete_files=True, add_import_exclusion=False):\n        params = {\n            \"deleteFiles\": delete_files,\n            \"addImportExclusion\": add_import_exclusion,\n            \"queryParams\": \"[object Object]\",\n        }\n        response = self._session.delete(\n            f\"{self._base}/movie/{movie_id}\", params=params, verify=False\n        )\n        response.raise_for_status()\n        return None\n\n    def events_in_history(\n        self,\n        movie_id,\n        page=1,\n        page_size=40,\n    ):\n        params = {\n            \"page\": page,\n            \"pageSize\": page_size,\n            \"sortDirection\": \"descending\",\n            \"sortKey\": \"date\",\n        }\n\n        response = self._session.get(f\"{self._base}/history\", params=params)\n        response.raise_for_status()\n        history = response.json()\n        try:\n            events = [\n                item[\"eventType\"]\n                for item in history[\"records\"]\n                if str(item[\"movieId\"]) == str(movie_id)\n            ]\n        except (KeyError, IndexError):\n            return []\n\n        return events\n\n    def lookup(self, term: str):\n        if not term.strip():\n            raise MovieNotFound(term)\n\n        params = {\"term\": term}\n        response = self._session.get(f\"{self._base}/movie/lookup\", params=params)\n        response.raise_for_status()\n        results = response.json()\n        if not results:\n            raise MovieNotFound(term)\n\n        return results\n\n\nclass SonarrClient:\n    def __init__(self, url, api_key, root_folder_path=None):\n        self._session = requests.Session()\n        self._base = f\"{url}/api/v3\"\n\n        self._session = requests.Session()\n        self._session.headers.update(\n            {\n                \"Connection\": \"keep-alive\",\n                \"Sec-GPC\": \"1\",\n                \"X-Api-Key\": api_key,\n            }\n        )\n        if root_folder_path is None:\n            self._root_folder_path = self._get_root_folder()\n        else:\n            self._root_folder_path = root_folder_path\n\n        logger.debug(\"Client started: %s (%s)\", self._base, self._root_folder_path)\n\n    def _get_root_folder(self):\n        response = self._session.get(f\"{self._base}/rootFolder\", verify=False)\n        response.raise_for_status()\n\n        try:\n            return response.json()[0][\"path\"]\n        except (IndexError, KeyError) as error:\n            logger.error(\"Error trying to get root foolder: %s\", error)\n            return None\n\n    @classmethod\n    def from_constants(cls):\n        return cls(config.curator.sonarr.url, config.curator.sonarr.token)\n\n    def lookup(self, term: str):\n        params = {\n            \"term\": term,\n        }\n        response = self._session.get(\n            f\"{self._base}/series/lookup\", params=params, verify=False\n        )\n        response.raise_for_status()\n        return response.json()\n\n    def add(\n        self,\n        tv_show: dict,\n        search_for_missing_episodes=False,\n        quality_profile_id=1,\n        language_profile_id=1,\n        monitored=False,\n        root_folder_path=None,\n    ):\n        if tv_show.get(\"id\"):\n            return tv_show\n\n        tv_show.update(\n            {\n                \"addOptions\": {\n                    \"searchForMissingEpisodes\": search_for_missing_episodes,\n                    \"searchForCutoffUnmetEpisodes\": False,\n                },\n                \"rootFolderPath\": root_folder_path or self._root_folder_path,\n                \"qualityProfileId\": quality_profile_id,\n                \"languageProfileId\": language_profile_id,\n                \"monitored\": monitored,\n            }\n        )\n\n        response = self._session.post(\n            f\"{self._base}/series\", json=tv_show, verify=False\n        )\n        response.raise_for_status()\n        return response.json()\n\n    def manual_search(self, series_id, season_number):\n        params = {\n            \"seriesId\": series_id,\n            \"seasonNumber\": season_number,\n        }\n\n        response = self._session.get(f\"{self._base}/release\", params=params)\n        response.raise_for_status()\n        return response.json()\n\n    def add_to_download_queue(self, guid, indexer_id):\n        json_data = {\"guid\": guid, \"indexerId\": indexer_id}\n\n        response = self._session.post(\n            f\"{self._base}/release\", json=json_data, verify=False\n        )\n\n        response.raise_for_status()\n        return response.json()\n\n    def episode_file(self, series_id):\n        params = {\n            \"seriesId\": series_id,\n        }\n        response = self._session.get(\n            f\"{self._base}/episodeFile\", params=params, verify=False\n        )\n        return response.json()\n\n    def events_in_history(\n        self,\n        series_id,\n        page=1,\n        page_size=40,\n    ):\n        params = {\n            \"page\": page,\n            \"pageSize\": page_size,\n            \"sortDirection\": \"descending\",\n            \"sortKey\": \"date\",\n        }\n\n        response = self._session.get(f\"{self._base}/history\", params=params)\n        response.raise_for_status()\n        history = response.json()\n        try:\n            events = [\n                item\n                for item in history[\"records\"]\n                if str(item[\"seriesId\"]) == str(series_id)\n            ]\n        except (KeyError, IndexError):\n            return []\n\n        return events\n\n    def series(self):\n        response = self._session.get(f\"{self._base}/series\")\n\n        response.raise_for_status()\n\n        return [SonarrTVShow.model_validate(item) for item in response.json()]\n\n    def series_delete(self, id, delete_files=True, add_import_exclusion=False):\n        params = {\n            \"deleteFiles\": delete_files,\n            \"addImportListExclusion\": add_import_exclusion,\n            \"queryParams\": \"[object Object]\",\n        }\n\n        response = self._session.delete(\n            f\"{self._base}/series/{id}\", params=params, verify=False\n        )\n        response.raise_for_status()\n        return None\n\n\ndef register_movie_addition(user_id, movie_id):\n    # This is awful\n    Kinobase()._execute_sql(\n        \"insert into movie_additions (user_id,movie_id) values (?,?)\",\n        (user_id, movie_id),\n    )\n\n\ndef register_tv_show_season_addition(user_id, tv_show_id, season_number):\n    # This is awful\n    Kinobase()._execute_sql(\n        \"insert into tv_show_season_additions (user_id,tv_show_id,season_number) values (?,?,?)\",\n        (user_id, tv_show_id, season_number),\n    )\n"}
{"type": "source_file", "path": "kinobot/discord/extras/verification.py", "content": "from abc import ABC\nimport datetime\nimport logging\nimport sqlite3\nfrom typing import Optional\n\nimport pydantic\n\nfrom kinobot.constants import KINOBASE\nfrom kinobot.exceptions import KinoException\n\nlogger = logging.getLogger(__name__)\n\nMIN_BYTES = None\n\n\nclass MissingPermission(KinoException):\n    pass\n\n\nclass TicketLog(pydantic.BaseModel):\n    ticket_id: int\n    request_id: str\n    added: datetime.datetime\n\n\nclass Ticket(pydantic.BaseModel):\n    id: int\n    user_id: str\n    added: datetime.datetime\n    summary: Optional[str] = None\n    log: Optional[TicketLog] = None\n    expires_in: datetime.timedelta = datetime.timedelta(days=90)\n\n\nclass User(ABC):\n    def __init__(self, user_id):\n        self.user_id = user_id\n\n    def is_curator(self):\n        return False\n\n    def tickets(self):\n        raise NotImplementedError\n\n    def available_tickets(self):\n        raise NotImplementedError\n\n    def used_tickets(self):\n        raise NotImplementedError\n\n    def append_ticket(self, id=None, summary=None):\n        raise NotImplementedError\n\n    def log_ticket(self, ticket_id, request_id):\n        raise NotImplementedError\n\n    def delete_tickets(self, count=1):\n        raise NotImplementedError\n\n\nclass UserTest(User):\n    def __init__(self, user_id, tickets=None, tickets_log=None):\n        self.user_id = str(user_id)\n        self._tickets = tickets or []\n        self._tickets_log = tickets_log or []\n\n    def tickets(self):\n        return self._tickets\n\n    def available_tickets(self):\n        ticket_log_ids = [tl.ticket_id for tl in self._tickets_log]\n        return [ticket for ticket in self._tickets if ticket.id not in ticket_log_ids]\n\n    def used_tickets(self):\n        ticket_log_ids = [tl.ticket_id for tl in self._tickets_log]\n        return [ticket for ticket in self._tickets if ticket.id in ticket_log_ids]\n\n    def append_ticket(\n        self, id=None, summary=None, expires_in=datetime.timedelta(days=90)\n    ):\n        ticket = Ticket(\n            id=id or 123,\n            user_id=self.user_id,\n            added=datetime.datetime.now(),\n            summary=summary,\n            expires_in=expires_in,\n        )\n        self._tickets.append(ticket)\n\n    def log_ticket(self, ticket_id, request_id):\n        ticket_log = TicketLog(\n            ticket_id=ticket_id, request_id=request_id, added=datetime.datetime.now()\n        )\n        self._tickets_log.append(ticket_log)\n\n    def delete_tickets(self, count=1):\n        pass\n\n\nclass UserDB(User):\n    ticket_table = \"verification_ticket\"\n    ticket_log_table = \"verification_ticket_log\"\n\n    def __init__(self, user_id, db_path=None):\n        self._conn = sqlite3.connect(db_path or KINOBASE)\n        self._conn.set_trace_callback(logger.debug)\n        self._conn.row_factory = sqlite3.Row\n        self.user_id = str(user_id)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self._conn.close()\n\n    def expired_tickets(self):\n        sql = (\n            f\"select * from {self.ticket_table} left join {self.ticket_log_table} on {self.ticket_table}.id \"\n            f\"= {self.ticket_log_table}.ticket_id where {self.ticket_table}.user_id=? \"\n            f\"and datetime({self.ticket_table}.added, '+' || {self.ticket_table}.days_expires_in || ' days') < datetime('now')\"\n        )\n        result = [\n            dict(row) for row in self._conn.execute(sql, (self.user_id,)).fetchall()\n        ]\n\n        tickets = []\n        for item in result:\n            if item[\"ticket_id\"] is not None:\n                log = TicketLog(\n                    ticket_id=item[\"ticket_id\"],\n                    request_id=item[\"request_id\"],\n                    added=item[\"added\"],\n                )\n            else:\n                log = None\n\n            tickets.append(\n                Ticket(\n                    id=item[\"id\"],\n                    user_id=self.user_id,\n                    added=item[\"added\"],\n                    summary=item[\"summary\"],\n                    expires_in=datetime.timedelta(days=item[\"days_expires_in\"]),\n                    log=log,\n                )\n            )\n\n        return tickets\n\n    def tickets(self, include_expired=False):\n        if include_expired:\n            sql = (\n                f\"select * from {self.ticket_table} left join {self.ticket_log_table} on {self.ticket_table}.id \"\n                f\"= {self.ticket_log_table}.ticket_id where {self.ticket_table}.user_id=?\"\n            )\n        else:\n            sql = (\n                f\"select * from {self.ticket_table} left join {self.ticket_log_table} on {self.ticket_table}.id \"\n                f\"= {self.ticket_log_table}.ticket_id where {self.ticket_table}.user_id=? \"\n                f\"and datetime({self.ticket_table}.added, '+' || {self.ticket_table}.days_expires_in || ' days') >= datetime('now')\"\n            )\n        result = [\n            dict(row) for row in self._conn.execute(sql, (self.user_id,)).fetchall()\n        ]\n\n        tickets = []\n        for item in result:\n            if item[\"ticket_id\"] is not None:\n                log = TicketLog(\n                    ticket_id=item[\"ticket_id\"],\n                    request_id=item[\"request_id\"],\n                    added=item[\"added\"],\n                )\n            else:\n                log = None\n\n            tickets.append(\n                Ticket(\n                    id=item[\"id\"],\n                    user_id=self.user_id,\n                    added=item[\"added\"],\n                    summary=item[\"summary\"],\n                    expires_in=datetime.timedelta(days=item[\"days_expires_in\"]),\n                    log=log,\n                )\n            )\n\n        return tickets\n\n    def available_tickets(self):\n        return [ticket for ticket in self.tickets() if ticket.log is None]\n\n    def used_tickets(self):\n        return [ticket for ticket in self.tickets(include_expired=True) if ticket.log]\n\n    def append_ticket(\n        self, id=None, summary=None, expires_in=datetime.timedelta(days=90)\n    ):\n        self._conn.execute(\n            f\"insert into {self.ticket_table} (user_id,summary,days_expires_in) values (?,?,?)\",\n            (self.user_id, summary, expires_in.days),\n        )\n        self._conn.commit()\n\n    def delete_tickets(self, count=1):\n        deleted = 0\n        for ticket in self.available_tickets():\n            self._conn.execute(\n                f\"delete from {self.ticket_table} where id=?\", (ticket.id,)\n            )\n            self._conn.commit()\n            deleted += 1\n            if deleted >= count:\n                break\n\n        logger.debug(\"Deleted %d tickets\", deleted)\n\n    def log_ticket(self, request_id):\n        available_tickets = self.available_tickets()\n        if not available_tickets:\n            raise MissingPermission(\n                \"You don't have any available tickets to verify this request.\"\n            )\n\n        ticket = available_tickets[0]\n        logger.debug(\"Using %s\", ticket)\n\n        self._conn.execute(\n            f\"insert into {self.ticket_log_table} (ticket_id,request_id) values (?,?)\",\n            (ticket.id, request_id),\n        )\n        self._conn.commit()\n\n        return ticket\n\n\nclass IGUserDB(UserDB):\n    ticket_table = \"verification_ticket_ig\"\n    ticket_log_table = \"verification_ticket_log_ig\"\n"}
{"type": "source_file", "path": "kinobot/instagram/db.py", "content": "from datetime import datetime\nfrom datetime import timedelta\nfrom typing import Optional\n\nfrom sqlalchemy import and_\nfrom sqlalchemy import Boolean\nfrom sqlalchemy import Column\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import DateTime\nfrom sqlalchemy import desc\nfrom sqlalchemy import ForeignKey\nfrom sqlalchemy import Integer\nfrom sqlalchemy import Interval\nfrom sqlalchemy import String\nfrom sqlalchemy import Text\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy.sql import func\n\nfrom . import models\nfrom .config import settings\n\nBase = declarative_base()\n\n\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(String, primary_key=True, nullable=False)\n    name = Column(String, nullable=False)\n    added = Column(DateTime, default=datetime.utcnow)\n\n\nclass IGPost(Base):\n    __tablename__ = \"ig_posts\"\n    id = Column(Integer, primary_key=True)\n    ig_id = Column(String, unique=True)\n    request_id = Column(Integer, ForeignKey(\"ig_requests.id\"))\n    request = relationship(\"IGRequest\", back_populates=\"posts\")\n    added = Column(DateTime, default=datetime.utcnow)\n\n\nclass IGTicket(Base):\n    __tablename__ = \"ig_tickets\"\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    user_id = Column(Text, ForeignKey(\"users.id\"))\n    user = relationship(\"User\")\n    added = Column(DateTime, default=datetime.utcnow)\n    used = Column(Boolean, default=False)\n    expires_in = Column(Interval, default=timedelta(weeks=8))\n\n\nclass IGRequest(Base):\n    __tablename__ = \"ig_requests\"\n    id = Column(Integer, primary_key=True)\n    content = Column(Text)\n    posts = relationship(\"IGPost\", back_populates=\"request\")\n    user_id = Column(Text, ForeignKey(\"users.id\"))\n    user = relationship(\"User\")  # , back_populates=\"requests\")\n    added = Column(DateTime, default=datetime.utcnow)\n    schedules = relationship(\"Schedule\", back_populates=\"request\")\n    labels = relationship(\"Label\", back_populates=\"request\")\n    used = Column(Boolean, default=False)\n    verified = Column(Boolean, default=False)\n\n\nclass IGUsedTicket(Base):\n    __tablename__ = \"ig_used_tickets\"\n\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    request_id = Column(Integer, ForeignKey(\"ig_requests.id\"))\n    ticket_id = Column(Integer, ForeignKey(\"ig_tickets.id\"))\n    added = Column(DateTime, default=datetime.utcnow)\n    used = Column(Boolean, default=False)\n\n\nclass Label(Base):\n    __tablename__ = \"ig_labels\"\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    verdict = Column(String)\n    request_id = Column(Integer, ForeignKey(\"ig_requests.id\"))\n    request = relationship(\"IGRequest\", back_populates=\"labels\")\n    user_id = Column(Text, ForeignKey(\"users.id\"))\n\n\nclass Schedule(Base):\n    __tablename__ = \"ig_schedules\"\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    comment = Column(String, nullable=True)\n    start_time = Column(DateTime)\n    expiration = Column(Interval)\n    request_id = Column(Integer, ForeignKey(\"ig_requests.id\"))\n    request = relationship(\"IGRequest\", back_populates=\"schedules\")\n\n\nclass PostRepository:\n    def __init__(self, session):\n        self.session = session\n\n    def get_all(self):\n        return self.session.query(IGPost).all()\n\n    def get_last(self):\n        item = self.session.query(IGPost).order_by(desc(IGPost.added)).first()\n        if item is None:\n            return item\n\n        return models.Post.from_orm(item)\n\n    def get_by_id(self, id):\n        return self.session.query(IGPost).filter_by(id=id).first()\n\n\nclass RequestRepository:\n    def __init__(self, session):\n        self.session = session\n\n    def get_all(self):\n        return self.session.query(IGRequest).all()\n\n    def get(self, id):\n        item = self.session.query(IGRequest).filter_by(id=id).first()\n        if item is None:\n            return item\n\n        return models.Request.from_orm(item)\n\n    def get_by_id(self, id):\n        return self.session.query(IGRequest).filter_by(id=id).first()\n\n    def get_random_active_request(self):\n        item = (\n            self.session.query(IGRequest)\n            .filter(\n                and_(\n                    IGRequest.verified == True,\n                    IGRequest.used == False,\n                )\n            )\n            .order_by(func.random())\n            .first()\n        )\n        if item is not None:\n            return models.Request.from_orm(item)\n\n    def get_active_requests_for_user(self, user_id):\n        items = (\n            self.session.query(IGRequest)\n            .filter(\n                and_(\n                    IGRequest.verified == True,\n                    IGRequest.used == False,\n                    IGRequest.user_id == user_id,\n                )\n            )\n            .all()\n        ) or []\n        return [models.Request.from_orm(req) for req in items]\n\n    def get_all_active_requests(self):\n        items = (\n            self.session.query(IGRequest)\n            .filter(\n                and_(\n                    IGRequest.verified == True,\n                    IGRequest.used == False,\n                )\n            )\n            .all()\n        ) or []\n        return [models.Request.from_orm(req) for req in items]\n\n    def create(self, content, user_id):\n        req = IGRequest(content=content, user_id=user_id)\n        self.session.add(req)\n        self.session.commit()\n        self.session.refresh(req)\n        return models.Request.from_orm(req)\n\n    def label(self, request_id, user_id, verdict=\"verified\"):\n        label = Label(request_id=request_id, user_id=user_id, verdict=verdict)\n        self.session.add(label)\n        self.session.commit()\n        self.session.refresh(label)\n\n        return models.Label.from_orm(label)\n\n    def verify(self, request_id):\n        req = self.get_by_id(request_id)\n        req.verified = True\n        req.used = False\n        self.session.commit()\n        self.session.refresh(req)\n\n    def schedule(self, request_id, start_time=None, expiration=timedelta(weeks=1)):\n        schedule = Schedule(\n            request_id=request_id,\n            start_time=start_time or datetime.utcnow(),\n            expiration=expiration,\n        )\n        self.session.add(schedule)\n        self.session.commit()\n        self.session.refresh(schedule)\n        return models.Schedule.from_orm(schedule)\n\n    def quarantine(self, request_id):\n        req = self.get_by_id(request_id)\n        req.quarantine = True\n        req.used = True\n        self.session.commit()\n\n    def delete(self, request_id):\n        req = self.get_by_id(request_id)\n        self.session.delete(req)\n        self.session.commit()\n\n    def post(self, ig_id, request_id):\n        post = IGPost(ig_id=ig_id, request_id=request_id)\n        self.session.add(post)\n        self.session.commit()\n        self.session.refresh(post)\n        return models.Post.from_orm(post)\n\n\nclass UserRepository:\n    def __init__(self, db):\n        self.db = db\n\n    def create_user(self, id, name) -> models.User:\n        db_user = User(id=id, name=name)\n        self.db.add(db_user)\n        self.db.commit()\n        self.db.refresh(db_user)\n        return models.User.from_orm(db_user)\n\n    def get_user_by_id(self, user_id: str) -> Optional[models.User]:\n        db_user = self.db.query(User).filter(User.id == user_id).first()\n        if db_user is None:\n            return db_user\n\n        return models.User.from_orm(db_user)\n\n    def add_tickets(self, user_id, count):\n        for _ in range(count):\n            ticket = IGTicket(user_id=user_id)\n            self.db.add(ticket)\n\n        self.db.commit()\n\n    def get_all_tickets(self, user_id):\n        result = self.db.query(IGTicket).filter(and_(IGTicket.user_id == user_id)).all()\n        return [models.Ticket.from_orm(item) for item in result]\n\n    def get_available_tickets(self, user_id):\n        result = (\n            self.db.query(IGTicket)\n            .filter(and_(IGTicket.user_id == user_id, IGTicket.used == False))\n            .all()\n        )\n        return [models.Ticket.from_orm(item) for item in result]\n\n    def register_ticket(self, ticket_id, request_id):\n        ticket = self.db.query(IGTicket).filter_by(id=ticket_id).first()\n        ticket.used = True\n        self.db.add(ticket)\n\n        used = IGUsedTicket(ticket_id=ticket.id, request_id=request_id)\n        self.db.add(used)\n        self.db.commit()\n\n    def delete_tickets(self, user_id, count):\n        subquery = (\n            self.db.query(IGTicket.id)\n            .filter(and_(IGTicket.user_id == user_id, IGTicket.used == False))\n            .limit(count)\n            .subquery()\n        )\n        self.db.query(IGTicket).filter(IGTicket.id.in_(subquery)).delete(\n            synchronize_session=False\n        )\n\n\ndef make_repository(repo_cls, db_url=None):\n    engine = create_engine(db_url or settings.db_url)\n    Session = sessionmaker(bind=engine)\n    session = Session()\n    return repo_cls(session)\n"}
{"type": "source_file", "path": "kinobot/instagram/events.py", "content": "from datetime import datetime\nfrom typing import Optional\n\nimport pydantic\n\nfrom . import models\n\n\nclass Event(pydantic.BaseModel):\n    timestamp: datetime = datetime.utcnow()\n\n\nclass PostCreated(Event):\n    finished_request: models.FinishedRequest\n    request: models.Request\n    ig_id: str\n    caption: Optional[str] = None\n    permalink: Optional[str] = None\n"}
{"type": "source_file", "path": "kinobot/discord/sports.py", "content": "import asyncio\nimport logging\n\nfrom discord import Embed\nfrom discord.ext import commands\nimport requests\n\nfrom kinobot.sources.sports import registry\n\nfrom .utils import ask\nfrom .utils import ask_to_confirm\nfrom .utils import call_with_typing\nfrom .utils import paginated_list\n\nlogger = logging.getLogger(__name__)\n\n\nasync def add(bot, ctx: commands.Context, video_url):\n    video_url = video_url.strip()\n\n    await ctx.send(\n        \"Give me the title of the match. It's usually TEAM 1 vs. TEAM 2, except for certain sports.\\n\"\n        \"Examples: `Liverpool vs. Everton`; `New York Knicks vs. Brooklyn Nets`; `Montreal Canadiens vs. Toronto Maple Leafs`; `Usain Bolt - Men's 100 metres`\\n\"\n        \"Please check your grammar.\"\n    )\n    title = await ask(bot, ctx)\n\n    await ctx.send(\n        \"Now the tournament of the event. It's usually a title followed by its season identifier or its year.\\n\"\n        \"Examples: `Premier League 2021-22; NBA 2021-22; NHL 2021-22; 2008 Beijing Summer Olympics`\"\n    )\n    tournament = await ask(bot, ctx)\n\n    confirmed = await ask_to_confirm(\n        bot, ctx, f\"{title} - {tournament}\\n\\nThis will be the title. Are you sure?\"\n    )\n    if not confirmed:\n        return await ctx.send(\"Bye.\")\n\n    repo = registry.Repository.from_db_url()\n    result = repo.create(tournament, title, video_url)\n    await ctx.send(f\"Added: {result.pretty_title}\")\n\n\ndef _get_embed(items):\n    embed = Embed(title=\"Matches found\")\n\n    str_list = \"\\n\".join(f\"{n}. {m.markdown_url}\" for n, m in enumerate(items, 1))\n\n    embed.add_field(name=\"Titles\", value=str_list)\n    return embed\n\n\nasync def explore(bot, ctx: commands.Context, *args):\n    loop = asyncio.get_running_loop()\n\n    query = \" \".join(args)\n    repo = registry.Repository.from_db_url()\n    results = repo.partial_search(query)\n\n    if not results:\n        return await ctx.send(\"Nothing found\")\n\n    results = results[:20]\n\n    await ctx.send(embed=_get_embed(results))\n"}
{"type": "source_file", "path": "kinobot/instagram/services.py", "content": "from datetime import datetime\nfrom datetime import timedelta\nimport logging\nfrom typing import Callable, Optional\n\nimport requests\n\nfrom kinobot.instagram import AbstractClient\n\nfrom . import events\nfrom . import models\nfrom .db import PostRepository\nfrom .templates import render\n\nlogger = logging.getLogger(__name__)\n\n\ndef _is_interval_acceptable(\n    last_record: datetime, reference: datetime, interval: timedelta\n):\n    if last_record > reference:\n        logger.debug(\"Last record is newer than reference. Returning False.\")\n        return False\n\n    record_interval = reference - last_record\n    acceptable = record_interval >= interval\n    logger.debug(\n        \"Acceptable? '%s' -> '%s' (interval:%s) ::: %s\",\n        last_record,\n        reference,\n        interval,\n        acceptable,\n    )\n    return acceptable\n\n\nclass NotAcceptableToPost(Exception):\n    pass\n\n\nclass Handler:\n    def __init__(self, host, api_key) -> None:\n        self._host = host\n        self._api_key = api_key\n        self._session = requests.Session()\n\n    def request(self, content):\n        response = self._session.get(\n            f\"{self._host}/request\",\n            params={\"api_key\": self._api_key, \"content\": content},\n        )\n        response.raise_for_status()\n\n        return models.FinishedRequest.parse_obj(response.json())\n\n\nreq_picker = Callable[..., models.Request]\nhandler = Callable[[str], models.FinishedRequest]\n\n\ndef is_acceptable_interval(client, post_repo, acceptable_interval):\n    if acceptable_interval is not None:\n        logger.debug(\"Getting last post\")\n        try:\n            datetimes = [client.get_media_list()[0].timestamp]\n        except IndexError:\n            datetimes = []\n\n        try:\n            last_db_post = post_repo.get_last()\n            if last_db_post:\n                datetimes.append(last_db_post.added)\n        except:\n            pass\n\n        acceptable = True\n        for dt in datetimes:\n            acceptable = _is_interval_acceptable(\n                dt, datetime.utcnow(), acceptable_interval\n            )\n\n        if not acceptable:\n            raise NotAcceptableToPost(f\"{acceptable_interval} -> {datetimes}\")\n\n\ndef post(\n    client: AbstractClient,\n    picker: req_picker,\n    req_handler: handler,\n    renderer: Optional[Callable[..., str]] = None,\n    event_publisher=None,\n):\n    \"raises NotAcceptableToPost\"\n    request_ = picker()\n    if request_ is None:\n        logger.info(\"No requests to post from %s\", picker)\n        return None\n\n    logger.info(\"Got request: %s\", request_)\n    finished_request = req_handler(request_.content)\n    caption = (renderer or render)(finished_request, request_)\n    response = client.any_media(finished_request.image_uris, caption)\n    media = client.get_media(response.id)\n\n    if event_publisher is not None:\n        event_publisher(\n            events.PostCreated(\n                finished_request=finished_request,\n                request=request_,\n                ig_id=response.id,\n                caption=caption,\n                permalink=media.permalink,\n            )\n        )\n\n    return response\n"}
{"type": "source_file", "path": "kinobot/discord/extras/curator_user.py", "content": "from abc import ABC\nimport datetime\nimport logging\nimport sqlite3\nfrom typing import Optional\n\nimport pydantic\n\nfrom kinobot.constants import KINOBASE\n\nlogger = logging.getLogger(__name__)\n\nMIN_BYTES = None\n\n\nclass LogModel(pydantic.BaseModel):\n    user_id: str\n    size: int\n    added: datetime.datetime\n    note: Optional[str] = None\n\n\nclass Key(LogModel):\n    user_id: str\n    size: int\n    added: datetime.datetime\n    expires_in: datetime.timedelta = datetime.timedelta(days=90)\n    note: Optional[str] = None\n\n\nclass CuratorABC(ABC):\n    def __init__(self, user_id):\n        self.user_id = user_id\n\n    def is_curator(self):\n        return False\n\n    def keys(self):\n        raise NotImplementedError\n\n    def additions(self):\n        raise NotImplementedError\n\n    def can_add(self, size):\n        raise NotImplementedError\n\n    def size_left(self):\n        raise NotImplementedError\n\n    def register_addition(self, size, note=None):\n        raise NotImplementedError\n\n    def register_key(self, size, note=None):\n        raise NotImplementedError\n\n\nclass CuratorTest(CuratorABC):\n    def __init__(self, user_id, keys=None, additions=None):\n        self.user_id = user_id\n        self._keys = keys or []\n        self._additions = additions or []\n\n    def is_curator(self):\n        return sum(self._keys) > 0\n\n    def can_add(self, size):\n        return self.size_left() > size\n\n    def size_left(self):\n        return sum(self._keys) - sum(self._additions)\n\n    def register_addition(self, size, note=None):\n        self._additions.append(size)\n\n    def register_key(self, size, note=None):\n        self._keys.append(size)\n\n\nclass Curator(CuratorABC):\n    _keys = \"curator_keys\"\n    _additions = \"curator_additions\"\n\n    def __init__(self, user_id, db_path=None):\n        self._conn = sqlite3.connect(db_path or KINOBASE)\n        self._conn.set_trace_callback(logger.debug)\n        self.user_id = user_id\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self._conn.close()\n\n    def keys(self, include_expired=False):\n        # select * from curator_keys where user_id = '291667438314192896' and datetime(added, '+' || 1000 || ' days') > datetime('now');\n        if include_expired:\n            result = self._conn.execute(\n                f\"select * from {self._keys} where user_id=?\", (self.user_id,)\n            ).fetchall()\n        else:\n            result = self._conn.execute(\n                f\"select * from {self._keys} where user_id = ? and datetime(added, '+' || days_expires_in || ' days') >= datetime('now')\",\n                (self.user_id,),\n            )\n        return [\n            Key(\n                user_id=self.user_id,\n                size=item[1],\n                added=item[2],\n                note=item[3],\n                expires_in=datetime.timedelta(days=item[4]),\n            )\n            for item in result\n        ]\n\n    def lifetime_used_bytes(self):\n        result = self._conn.execute(\n            (\n                f\"select coalesce((select sum(size) from {self._additions} where user_id=?), 0) from {self._keys} where user_id=?\"\n            ),\n            (\n                self.user_id,\n                self.user_id,\n            ),\n        ).fetchone()\n        if result:\n            return result[0] or 0\n\n        return 0\n\n    def expired_bytes_no_use(self):\n        result = self._conn.execute(\n            (\n                f\"select sum(size) - coalesce((select sum(size) from {self._additions} where user_id=? AND \"\n                f\"added < datetime('now', '-' || days_expires_in || ' days')), 0) from {self._keys} where user_id=? \"\n                \"and datetime(added, '+' || days_expires_in || ' days') < datetime('now')\"\n            ),\n            (\n                self.user_id,\n                self.user_id,\n            ),\n        ).fetchone()\n        if result:\n            return result[0] or 0\n\n        return 0\n\n    def additions(self):\n        result = self._conn.execute(\n            f\"select * from {self._additions} where user_id=?\", (self.user_id,)\n        ).fetchall()\n        return [\n            LogModel(\n                user_id=self.user_id,\n                size=item[1],\n                added=item[2],\n                note=item[3],\n            )\n            for item in result\n        ]\n\n    def size_left(self):\n        result = self._conn.execute(\n            f\"select sum(size) - coalesce((select sum(size) from {self._additions} where user_id=?), 0) from {self._keys} where user_id=?\",\n            (\n                self.user_id,\n                self.user_id,\n            ),\n        ).fetchone()\n        if result:\n            return result[0] or 0\n\n        return 0\n\n    def can_add(self, size):\n        return self.size_left() > size\n\n    def close(self):\n        self._conn.close()\n\n    def register_addition(self, size, note=None):\n        self._conn.execute(\n            f\"insert into {self._additions} (user_id,size,note) values (?,?,?)\",\n            (self.user_id, size, note),\n        )\n        self._conn.commit()\n\n    def register_key(self, size, note=None, expires_in=datetime.timedelta(days=90)):\n        self._conn.execute(\n            f\"insert into {self._keys} (user_id,size,note,days_expires_in) values (?,?,?,?)\",\n            (self.user_id, size, note, expires_in.days),\n        )\n        self._conn.commit()\n\nclass AnimeCurator(Curator):\n    _keys = \"curator_keys_anime\"\n    _additions = \"curator_additions_anime\"\n"}
{"type": "source_file", "path": "kinobot/discord/instagram.py", "content": "import asyncio\nimport logging\n\nfrom discord import Embed\nfrom discord.ext import commands\nimport requests\n\nfrom kinobot.instagram import Client as IGCLient\nfrom kinobot.instagram import config\nfrom kinobot.instagram import events\nfrom kinobot.instagram import factory\nfrom kinobot.instagram import services\nfrom kinobot.instagram.events import PostCreated\nfrom kinobot.instagram.models import Request as RequestModel\nfrom kinobot.instagram.models import User as UserModel\nfrom kinobot.request import NothingFound\nfrom kinobot.request import Request\n\nfrom .utils import ask\nfrom .utils import ask_to_confirm\nfrom .utils import call_with_typing\nfrom .utils import paginated_list\n\nlogger = logging.getLogger(__name__)\n\n\ndef _quarantine(request):\n    logger.debug(\"Running quarantine for %s\", request)\n    req = Request.from_db_id(request.id)\n    req.mark_as_used()\n\n\ndef _other_publishers(pc: PostCreated):\n    cfg = config.Config.default_factory()\n    try:\n        pubs = factory.make_post_publishers(cfg.publishers)\n    except Exception as error:\n        logger.error(error)\n        return None\n\n    for pub in pubs:\n        try:\n            pub(pc)\n        except Exception as error:\n            logger.debug(\"Error runing %s: %s\", pub, error)\n\n\ndef _picker(id=None):\n    if id is None:\n        try:\n            req_ = Request.random_from_queue(verified=True, tag=\"ig\")\n        except NothingFound:\n            logger.debug(\"No verified request found\")\n            return None\n    else:\n        req_ = Request.from_db_id(id)\n\n    req_.user.load()\n    req = RequestModel(\n        id=req_.id,  # type: ignore\n        content=req_.comment,\n        user_id=req_.user.id,\n        added=req_.added,\n        user=UserModel(id=req_.user.id, name=req_.user.name),\n    )\n    return req\n\n\nclass NotPostedError(Exception):\n    pass\n\n\ndef ig_poster(request_id=None, retry=2):\n    cfg = config.Config.default_factory()\n    client = IGCLient(**cfg.ig_client)\n    handler = services.Handler(**cfg.client)\n\n    for _ in range(retry):\n        request_ = _picker(request_id)\n        if request_ is None:\n            logger.info(\"No request found from picker\")\n            return None\n\n        logger.info(\"Got request: %s\", request_)\n        try:\n            finished_request = handler.request(request_.content)\n            caption = services.render(finished_request, request_)\n            logger.info(\"Running pre-publishers\")\n            _quarantine(request_)\n        except Exception as error:\n            logger.error(\"%s for %s\", error, request_)\n            continue\n\n        response = client.any_media(finished_request.image_uris, caption)\n        media = client.get_media(response.id)\n\n        pc = events.PostCreated(\n            finished_request=finished_request,\n            request=request_,\n            ig_id=response.id,\n            caption=caption,\n            permalink=media.permalink,\n        )\n\n        try:\n            _other_publishers(pc)\n        except Exception as error:\n            logger.error(\"Error running other publishers: %s\", error)\n\n        break\n\n\ndef make_post(request_id=None):\n    cfg = config.Config.default_factory()\n    client = IGCLient(**cfg.ig_client)\n    handler = services.Handler(**cfg.client)\n\n    def _publishers(pc):\n        for pub in (_quarantine, _other_publishers):\n            try:\n                pub(pc)\n            except Exception as error:\n                logger.debug(\"Error running %s: %s\", error)\n\n    services.post(\n        client,\n        lambda: _picker(request_id),\n        handler.request,\n        event_publisher=_publishers,\n    )\n"}
{"type": "source_file", "path": "kinobot/discord/extras/announcements.py", "content": "from pydantic import BaseModel\n\nfrom kinobot.config import config\nfrom kinobot.db import KINOBASE\nfrom kinobot.db import sql_to_dict\nfrom kinobot.utils import send_webhook\n\n\nclass _Contributor(BaseModel):\n    name: str\n    records: int\n\n    def line(self, n):\n        return f\"**{n}. {self.name}** - ***{self.records}*** active tickets\"\n\n\ndef top_contributors(db=None):\n    sql = (\n        \"select users.name, users.id, count(*) as records from verification_ticket left \"\n        \"join verification_ticket_log on verification_ticket.id = verification_ticket_log.ticket_id \"\n        \"left join users on verification_ticket.user_id=users.id where datetime(verification_ticket.added, \"\n        \"'+' || verification_ticket.days_expires_in || ' days') >= datetime('now') group by users.id order by records desc;\"\n    )\n    sql_ = (\n        \"select users.name, count(*) as records from verification_ticket \"\n        \"left join users on verification_ticket.user_id = users.id where \"\n        \"verification_ticket.added >= DATE('now', '-28 day') group by users.name order by records desc;\"\n    )\n    result = sql_to_dict(db or KINOBASE, sql)[:7]\n    if not result:\n        return None\n    lines = \"\\n\".join(\n        [_Contributor(**item).line(n) for n, item in enumerate(result, start=1)]\n    )\n    str_ = f\"## Top active tickets\\n\\n{lines}\"\n    send_webhook(config.webhook.announcer, str_)\n"}
{"type": "source_file", "path": "kinobot/discord/request_trace.py", "content": "import os\n\nfrom kinobot.request_trace import CheckerConfig\nfrom kinobot.request_trace import get_not_passed\nfrom kinobot.request_trace import RequestTrace\nfrom kinobot.config import config\n\n\nasync def trace_checks(ctx, trace: RequestTrace):\n    configs = CheckerConfig.from_yaml_file(config.trace_config)\n    not_passed = get_not_passed(trace, configs)\n    found = False\n\n    for item in not_passed:\n        found = True\n        await ctx.reply(\n            f\"***{item.name}***\\n\\n{item.description}\\n\\nPlease think twice before verifying this!\"\n        )\n\n    return found\n"}
{"type": "source_file", "path": "kinobot/discord/common.py", "content": "import logging\n\nimport aiohttp\nfrom discord import DiscordException\nfrom discord import Embed\nfrom discord import Forbidden\nfrom discord.ext import commands\n\nimport kinobot.exceptions as exceptions\n\nfrom ..constants import PERMISSIONS_EMBED\nfrom ..constants import WEBSITE\nfrom ..utils import handle_general_exception\n\nlogger = logging.getLogger(__name__)\n\n_SHUT_UP_BOI = \"Bra shut up boi ðŸ’¯\"\n\n\nasync def handle_error(ctx, error):\n    if hasattr(error, \"original\"):\n        error = error.original\n\n    name = type(error).__name__\n\n    if isinstance(error, commands.CommandOnCooldown):\n        await ctx.send(\n            f\"Please cool down; try again in `{error.retry_after:.2f}\"\n            \" seconds`. Thanks for understanding.\"\n        )\n        await ctx.send(_SHUT_UP_BOI)\n\n    elif isinstance(error, exceptions.LimitExceeded):\n        await ctx.send(embed=PERMISSIONS_EMBED)\n\n    elif isinstance(error, exceptions.NothingFound):\n        if not str(error).strip():\n            await ctx.send(\"Nothing found.\")\n        else:\n            await ctx.send(embed=_exception_embed(error))\n\n    elif isinstance(error, exceptions.KinoUnwantedException):\n        handle_general_exception(error)\n        await ctx.send(\n            f\"Unexpected exception raised: {name}. **This is a bug!** Please \"\n            \"reach #support on the official Discord server (run `!server`).\"\n        )\n\n    elif isinstance(error, exceptions.KinoException):\n        await ctx.send(embed=_exception_embed(error))\n        await ctx.send(_SHUT_UP_BOI)\n\n    # TODO: make this more elegant\n    elif isinstance(error, (commands.CommandError, Forbidden)):\n        if isinstance(error, Forbidden):\n            await ctx.send(\"Without permissions to perform this.\")\n        elif not isinstance(error, commands.CommandNotFound):\n            await ctx.send(f\"Command exception `{name}` raised: {error}\")\n\n    elif isinstance(error, aiohttp.ClientError):\n        await ctx.send(\"Please try again. The server was suffering overload.\")\n\n    else:\n        handle_general_exception(error)\n        await ctx.send(\n            f\"Unexpected exception raised: {name}. **This is a bug!** Please \"\n            \"reach #support on the official Discord server (run `!server`).\"\n        )\n\n\ndef _exception_embed(exception):\n    title = f\"{type(exception).__name__} exception raised!\"\n    embed = Embed(title=title, description=str(exception))\n    embed.add_field(name=\"Kinobot's documentation\", value=f\"{WEBSITE}/docs\")\n    return embed\n\n\n_req_id_map = {\"spanish\": \"es\", \"brazilian\": \"pt\", \"old-page\": \"main\"}\n\n\ndef get_req_id_from_ctx(ctx):\n    channel_name = ctx.channel.name.lower()\n    for key, val in _req_id_map.items():\n        if channel_name.startswith(key):\n            return val\n\n    return \"en\"\n"}
{"type": "source_file", "path": "kinobot/discord/request.py", "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# License: GPL\n# Author : Vitiko <vhnz98@gmail.com>\n\nimport asyncio\nimport functools\nimport logging\nimport time\n\nfrom discord import Embed\nfrom discord import File\nfrom discord.ext import commands\n\nfrom ..request import Request\nfrom ..user import ForeignUser\nfrom ..user import User\n\n_GOOD_BAD = (\"ðŸ‘\", \"ðŸ’©\")\n\nlogging.getLogger(\"discord\").setLevel(logging.INFO)\n\nlogger = logging.getLogger(__name__)\n\n\nclass Static:\n    \"Class for the Discord request commands.\"\n    user_handler = User\n\n    def __init__(\n        self,\n        bot: commands.Bot,\n        ctx: commands.Context,\n        identifier=\"en\",\n        prefix=\"!req\",\n        *args,\n    ):\n        self.bot = bot\n        self.ctx = ctx\n        self._identifier = identifier\n        self._req = Request.from_discord(args, self.ctx, identifier, prefix)\n\n        logger.debug(\"Request instance: %s\", self._req)\n\n        self._handler = None\n        self._started = time.time()\n\n    async def on_demand(self, embed=True):\n        \"Perform an on-demand request.\"\n        await self._load_handler()\n\n        if embed:\n            await self.ctx.send(embed=self.embed)\n\n        await self._send_images()\n\n    async def register(self):\n        \"Register the request and the user. Ask for removal once registered.\"\n        self._req.register()\n        await self._ask_remove()\n\n    @property\n    def finished(self) -> str:\n        \"\"\"A message showing the time passed since the instance's start.\n\n        :rtype: str\n        \"\"\"\n        return f\"Task finished in {round(time.time() - self._started, 2)} seconds\"\n\n    @property\n    def embed(self) -> Embed:\n        \"\"\"An embed containing the handler title and the finished time.\n\n        :rtype: Embed\n        \"\"\"\n        assert self._handler is not None\n\n        embed = Embed(title=self._handler.title[:250])\n        embed.set_footer(\n            text=f\"{self.finished} | {self._req.user.remain_requests} | {self._identifier}\"\n        )\n\n        return embed\n\n    async def _load_handler(self):\n        loop = asyncio.get_running_loop()\n\n        user = self.user_handler.from_discord(self.ctx.author)\n        self._handler = await loop.run_in_executor(\n            None, functools.partial(self._req.get_handler, user=user)\n        )\n        async with self.ctx.typing():\n            # Temporary catch\n            try:\n                assert await loop.run_in_executor(None, self._handler.get)\n            except:\n                if user.unlimited is False:\n                    user.substract_role_limit()\n                raise\n\n    async def _send_images(self):\n        for image in self._handler.images:\n            logger.info(\"Sending info: %s\", image)\n            await self.ctx.send(file=File(image))\n\n    async def _ask_remove(self):\n        msg = await self.ctx.send(str(self._req.id))\n        await msg.add_reaction(_GOOD_BAD[1])\n\n        try:\n            reaction, user = await self.bot.wait_for(\n                \"reaction_add\", timeout=60, check=self._check_react\n            )\n            assert user\n\n            if str(reaction) == str(_GOOD_BAD[1]):\n                self._req.mark_as_used()\n                await self.ctx.send(\"Deleted.\")\n        except asyncio.TimeoutError:\n            pass\n\n    def _check_react(self, reaction, user):\n        assert reaction\n        return user == self.ctx.author\n\n\nclass StaticForeign(Static):\n    user_handler = ForeignUser\n"}
