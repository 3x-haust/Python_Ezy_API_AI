{"repo_info": {"repo_name": "ExecutionAgent", "repo_owner": "sola-st", "repo_url": "https://github.com/sola-st/ExecutionAgent"}}
{"type": "source_file", "path": "autogpt/__init__.py", "content": "import os\nimport random\nimport sys\n\nfrom dotenv import load_dotenv\n\nif \"pytest\" in sys.argv or \"pytest\" in sys.modules or os.getenv(\"CI\"):\n    print(\"Setting random seed to 42\")\n    random.seed(42)\n\n# Load the users .env file into environment variables\nload_dotenv(verbose=True, override=True)\n\ndel load_dotenv\n"}
{"type": "source_file", "path": "autogpt/commands/file_operations_utils.py", "content": "import json\nimport os\n\nimport charset_normalizer\nimport docx\nimport markdown\nimport PyPDF2\nimport yaml\nfrom bs4 import BeautifulSoup\nfrom pylatexenc.latex2text import LatexNodes2Text\n\nfrom autogpt import logs\nfrom autogpt.logs import logger\n\n\nclass ParserStrategy:\n    def read(self, file_path: str) -> str:\n        raise NotImplementedError\n\n\n# Basic text file reading\nclass TXTParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        charset_match = charset_normalizer.from_path(file_path).best()\n        logger.debug(f\"Reading '{file_path}' with encoding '{charset_match.encoding}'\")\n        return str(charset_match)\n\n\n# Reading text from binary file using pdf parser\nclass PDFParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        parser = PyPDF2.PdfReader(file_path)\n        text = \"\"\n        for page_idx in range(len(parser.pages)):\n            text += parser.pages[page_idx].extract_text()\n        return text\n\n\n# Reading text from binary file using docs parser\nclass DOCXParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        doc_file = docx.Document(file_path)\n        text = \"\"\n        for para in doc_file.paragraphs:\n            text += para.text\n        return text\n\n\n# Reading as dictionary and returning string format\nclass JSONParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        with open(file_path, \"r\") as f:\n            data = json.load(f)\n            text = str(data)\n        return text\n\n\nclass XMLParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        with open(file_path, \"r\") as f:\n            soup = BeautifulSoup(f, \"xml\")\n            text = soup.get_text()\n        return text\n\n\n# Reading as dictionary and returning string format\nclass YAMLParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        with open(file_path, \"r\") as f:\n            data = yaml.load(f, Loader=yaml.FullLoader)\n            text = str(data)\n        return text\n\n\nclass HTMLParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        with open(file_path, \"r\") as f:\n            soup = BeautifulSoup(f, \"html.parser\")\n            text = soup.get_text()\n        return text\n\n\nclass MarkdownParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        with open(file_path, \"r\") as f:\n            html = markdown.markdown(f.read())\n            text = \"\".join(BeautifulSoup(html, \"html.parser\").findAll(string=True))\n        return text\n\n\nclass LaTeXParser(ParserStrategy):\n    def read(self, file_path: str) -> str:\n        with open(file_path, \"r\") as f:\n            latex = f.read()\n        text = LatexNodes2Text().latex_to_text(latex)\n        return text\n\n\nclass FileContext:\n    def __init__(self, parser: ParserStrategy, logger: logs.Logger):\n        self.parser = parser\n        self.logger = logger\n\n    def set_parser(self, parser: ParserStrategy) -> None:\n        self.logger.debug(f\"Setting Context Parser to {parser}\")\n        self.parser = parser\n\n    def read_file(self, file_path) -> str:\n        self.logger.debug(f\"Reading file {file_path} with parser {self.parser}\")\n        return self.parser.read(file_path)\n\n\nextension_to_parser = {\n    \".txt\": TXTParser(),\n    \".csv\": TXTParser(),\n    \".pdf\": PDFParser(),\n    \".docx\": DOCXParser(),\n    \".json\": JSONParser(),\n    \".xml\": XMLParser(),\n    \".yaml\": YAMLParser(),\n    \".yml\": YAMLParser(),\n    \".html\": HTMLParser(),\n    \".htm\": HTMLParser(),\n    \".xhtml\": HTMLParser(),\n    \".md\": MarkdownParser(),\n    \".markdown\": MarkdownParser(),\n    \".tex\": LaTeXParser(),\n}\n\n\ndef is_file_binary_fn(file_path: str):\n    \"\"\"Given a file path load all its content and checks if the null bytes is present\n\n    Args:\n        file_path (_type_): _description_\n\n    Returns:\n        bool: is_binary\n    \"\"\"\n    with open(file_path, \"rb\") as f:\n        file_data = f.read()\n    if b\"\\x00\" in file_data:\n        return True\n    return False\n\n\ndef read_textual_file(file_path: str, logger: logs.Logger) -> str:\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(\n            f\"read_file {file_path} failed: no such file or directory\"\n        )\n    is_binary = is_file_binary_fn(file_path)\n    file_extension = os.path.splitext(file_path)[1].lower()\n    parser = extension_to_parser.get(file_extension)\n    if not parser:\n        if is_binary:\n            raise ValueError(f\"Unsupported binary file format: {file_extension}\")\n        # fallback to txt file parser (to support script and code files loading)\n        parser = TXTParser()\n    file_context = FileContext(parser, logger)\n    return file_context.read_file(file_path)\n"}
{"type": "source_file", "path": "autogpt/config/__init__.py", "content": "\"\"\"\nThis module contains the configuration classes for AutoGPT.\n\"\"\"\nfrom .ai_config import AIConfig\nfrom .config import Config, ConfigBuilder, check_openai_api_key\n\n__all__ = [\n    \"check_openai_api_key\",\n    \"AIConfig\",\n    \"Config\",\n    \"ConfigBuilder\",\n]\n"}
{"type": "source_file", "path": "autogpt/config/config.py", "content": "\"\"\"Configuration class to store the state of bools for different scripts access.\"\"\"\nfrom __future__ import annotations\n\nimport contextlib\nimport os\nimport re\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Union\n\nimport yaml\nfrom auto_gpt_plugin_template import AutoGPTPluginTemplate\nfrom colorama import Fore\nfrom pydantic import Field, validator\n\nfrom autogpt.core.configuration.schema import Configurable, SystemSettings\nfrom autogpt.llm.providers.openai import OPEN_AI_CHAT_MODELS\nfrom autogpt.plugins.plugins_config import PluginsConfig\n\nAI_SETTINGS_FILE = \"ai_settings.yaml\"\nAZURE_CONFIG_FILE = \"azure.yaml\"\nPLUGINS_CONFIG_FILE = \"plugins_config.yaml\"\nPROMPT_SETTINGS_FILE = \"prompt_settings.yaml\"\n\nGPT_4_MODEL = \"gpt-4\"\nGPT_3_MODEL = \"gpt-3.5-turbo-0125\"\n\n\nclass Config(SystemSettings, arbitrary_types_allowed=True):\n    name: str = \"Auto-GPT configuration\"\n    description: str = \"Default configuration for the Auto-GPT application.\"\n    ########################\n    # Application Settings #\n    ########################\n    skip_news: bool = False\n    skip_reprompt: bool = False\n    authorise_key: str = \"y\"\n    exit_key: str = \"n\"\n    debug_mode: bool = False\n    plain_output: bool = False\n    chat_messages_enabled: bool = True\n    # TTS configuration\n    speak_mode: bool = False\n    text_to_speech_provider: str = \"gtts\"\n    streamelements_voice: str = \"Brian\"\n    elevenlabs_voice_id: Optional[str] = None\n\n    ##########################\n    # Agent Control Settings #\n    ##########################\n    # Paths\n    ai_settings_file: str = AI_SETTINGS_FILE\n    prompt_settings_file: str = PROMPT_SETTINGS_FILE\n    workdir: Path = None\n    workspace_path: Optional[Path] = None\n    file_logger_path: Optional[Path] = None\n    # Model configuration\n    fast_llm: str = \"gpt-3.5-turbo-0125\"\n    smart_llm: str = \"gpt-4o-mini\"\n    temperature: float = 0\n    openai_functions: bool = False\n    embedding_model: str = \"text-embedding-ada-002\"\n    browse_spacy_language_model: str = \"en_core_web_sm\"\n    # Run loop configuration\n    continuous_mode: bool = False\n    continuous_limit: int = 0\n\n    ##########\n    # Memory #\n    ##########\n    memory_backend: str = \"json_file\"\n    memory_index: str = \"auto-gpt-memory\"\n    redis_host: str = \"localhost\"\n    redis_port: int = 6379\n    redis_password: str = \"\"\n    wipe_redis_on_start: bool = True\n\n    ############\n    # Commands #\n    ############\n    # General\n    disabled_command_categories: list[str] = Field(default_factory=list)\n    # File ops\n    restrict_to_workspace: bool = True\n    allow_downloads: bool = False\n    # Shell commands\n    shell_command_control: str = \"denylist\"\n    execute_local_commands: bool = False\n    shell_denylist: list[str] = Field(default_factory=lambda: [\"sudo\", \"su\"])\n    shell_allowlist: list[str] = Field(default_factory=list)\n    # Text to image\n    image_provider: Optional[str] = None\n    huggingface_image_model: str = \"CompVis/stable-diffusion-v1-4\"\n    sd_webui_url: Optional[str] = \"http://localhost:7860\"\n    image_size: int = 256\n    # Audio to text\n    audio_to_text_provider: str = \"huggingface\"\n    huggingface_audio_to_text_model: Optional[str] = None\n    # Web browsing\n    selenium_web_browser: str = \"chrome\"\n    selenium_headless: bool = True\n    user_agent: str = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"\n\n    ###################\n    # Plugin Settings #\n    ###################\n    plugins_dir: str = \"plugins\"\n    plugins_config_file: str = PLUGINS_CONFIG_FILE\n    plugins_config: PluginsConfig = Field(\n        default_factory=lambda: PluginsConfig(plugins={})\n    )\n    plugins: list[AutoGPTPluginTemplate] = Field(default_factory=list, exclude=True)\n    plugins_allowlist: list[str] = Field(default_factory=list)\n    plugins_denylist: list[str] = Field(default_factory=list)\n    plugins_openai: list[str] = Field(default_factory=list)\n\n    ###############\n    # Credentials #\n    ###############\n    # OpenAI\n    openai_api_key: Optional[str] = None\n    openai_api_type: Optional[str] = None\n    openai_api_base: Optional[str] = None\n    openai_api_version: Optional[str] = None\n    openai_organization: Optional[str] = None\n    use_azure: bool = False\n    azure_config_file: Optional[str] = AZURE_CONFIG_FILE\n    azure_model_to_deployment_id_map: Optional[Dict[str, str]] = None\n    # Elevenlabs\n    elevenlabs_api_key: Optional[str] = None\n    # Github\n    github_api_key: Optional[str] = None\n    github_username: Optional[str] = None\n    # Google\n    google_api_key: Optional[str] = None\n    google_custom_search_engine_id: Optional[str] = None\n    # Huggingface\n    huggingface_api_token: Optional[str] = None\n    # Stable Diffusion\n    sd_webui_auth: Optional[str] = None\n\n    @validator(\"plugins\", each_item=True)\n    def validate_plugins(cls, p: AutoGPTPluginTemplate | Any):\n        assert issubclass(\n            p.__class__, AutoGPTPluginTemplate\n        ), f\"{p} does not subclass AutoGPTPluginTemplate\"\n        assert (\n            p.__class__.__name__ != \"AutoGPTPluginTemplate\"\n        ), f\"Plugins must subclass AutoGPTPluginTemplate; {p} is a template instance\"\n        return p\n\n    @validator(\"openai_functions\")\n    def validate_openai_functions(cls, v: bool, values: dict[str, Any]):\n        if v:\n            smart_llm = values[\"smart_llm\"]\n            assert OPEN_AI_CHAT_MODELS[smart_llm].supports_functions, (\n                f\"Model {smart_llm} does not support OpenAI Functions. \"\n                \"Please disable OPENAI_FUNCTIONS or choose a suitable model.\"\n            )\n\n    def get_openai_credentials(self, model: str) -> dict[str, str]:\n        credentials = {\n            \"api_key\": self.openai_api_key,\n            \"api_base\": self.openai_api_base,\n            \"organization\": self.openai_organization,\n        }\n        if self.use_azure:\n            azure_credentials = self.get_azure_credentials(model)\n            credentials.update(azure_credentials)\n        return credentials\n\n    def get_azure_credentials(self, model: str) -> dict[str, str]:\n        \"\"\"Get the kwargs for the Azure API.\"\"\"\n\n        # Fix --gpt3only and --gpt4only in combination with Azure\n        fast_llm = (\n            self.fast_llm\n            if not (\n                self.fast_llm == self.smart_llm\n                and self.fast_llm.startswith(GPT_4_MODEL)\n            )\n            else f\"not_{self.fast_llm}\"\n        )\n        smart_llm = (\n            self.smart_llm\n            if not (\n                self.smart_llm == self.fast_llm\n                and self.smart_llm.startswith(GPT_3_MODEL)\n            )\n            else f\"not_{self.smart_llm}\"\n        )\n\n        deployment_id = {\n            fast_llm: self.azure_model_to_deployment_id_map.get(\n                \"fast_llm_deployment_id\",\n                self.azure_model_to_deployment_id_map.get(\n                    \"fast_llm_model_deployment_id\"  # backwards compatibility\n                ),\n            ),\n            smart_llm: self.azure_model_to_deployment_id_map.get(\n                \"smart_llm_deployment_id\",\n                self.azure_model_to_deployment_id_map.get(\n                    \"smart_llm_model_deployment_id\"  # backwards compatibility\n                ),\n            ),\n            self.embedding_model: self.azure_model_to_deployment_id_map.get(\n                \"embedding_model_deployment_id\"\n            ),\n        }.get(model, None)\n\n        kwargs = {\n            \"api_type\": self.openai_api_type,\n            \"api_base\": self.openai_api_base,\n            \"api_version\": self.openai_api_version,\n        }\n        if model == self.embedding_model:\n            kwargs[\"engine\"] = deployment_id\n        else:\n            kwargs[\"deployment_id\"] = deployment_id\n        return kwargs\n\n\nclass ConfigBuilder(Configurable[Config]):\n    default_settings = Config()\n\n    @classmethod\n    def build_config_from_env(cls, workdir: Path) -> Config:\n        \"\"\"Initialize the Config class\"\"\"\n        config_dict = {\n            \"workdir\": workdir,\n            \"authorise_key\": os.getenv(\"AUTHORISE_COMMAND_KEY\"),\n            \"exit_key\": os.getenv(\"EXIT_KEY\"),\n            \"plain_output\": os.getenv(\"PLAIN_OUTPUT\", \"False\") == \"True\",\n            \"shell_command_control\": os.getenv(\"SHELL_COMMAND_CONTROL\"),\n            \"ai_settings_file\": os.getenv(\"AI_SETTINGS_FILE\", AI_SETTINGS_FILE),\n            \"prompt_settings_file\": os.getenv(\n                \"PROMPT_SETTINGS_FILE\", PROMPT_SETTINGS_FILE\n            ),\n            \"fast_llm\": os.getenv(\"FAST_LLM\", os.getenv(\"FAST_LLM_MODEL\")),\n            \"smart_llm\": os.getenv(\"SMART_LLM\", os.getenv(\"SMART_LLM_MODEL\")),\n            \"embedding_model\": os.getenv(\"EMBEDDING_MODEL\"),\n            \"browse_spacy_language_model\": os.getenv(\"BROWSE_SPACY_LANGUAGE_MODEL\"),\n            \"openai_api_key\": os.getenv(\"OPENAI_API_KEY\"),\n            \"use_azure\": os.getenv(\"USE_AZURE\") == \"True\",\n            \"azure_config_file\": os.getenv(\"AZURE_CONFIG_FILE\", AZURE_CONFIG_FILE),\n            \"execute_local_commands\": os.getenv(\"EXECUTE_LOCAL_COMMANDS\", \"False\")\n            == \"True\",\n            \"restrict_to_workspace\": os.getenv(\"RESTRICT_TO_WORKSPACE\", \"True\")\n            == \"True\",\n            \"openai_functions\": os.getenv(\"OPENAI_FUNCTIONS\", \"False\") == \"True\",\n            \"elevenlabs_api_key\": os.getenv(\"ELEVENLABS_API_KEY\"),\n            \"streamelements_voice\": os.getenv(\"STREAMELEMENTS_VOICE\"),\n            \"text_to_speech_provider\": os.getenv(\"TEXT_TO_SPEECH_PROVIDER\"),\n            \"github_api_key\": os.getenv(\"GITHUB_API_KEY\"),\n            \"github_username\": os.getenv(\"GITHUB_USERNAME\"),\n            \"google_api_key\": os.getenv(\"GOOGLE_API_KEY\"),\n            \"image_provider\": os.getenv(\"IMAGE_PROVIDER\"),\n            \"huggingface_api_token\": os.getenv(\"HUGGINGFACE_API_TOKEN\"),\n            \"huggingface_image_model\": os.getenv(\"HUGGINGFACE_IMAGE_MODEL\"),\n            \"audio_to_text_provider\": os.getenv(\"AUDIO_TO_TEXT_PROVIDER\"),\n            \"huggingface_audio_to_text_model\": os.getenv(\n                \"HUGGINGFACE_AUDIO_TO_TEXT_MODEL\"\n            ),\n            \"sd_webui_url\": os.getenv(\"SD_WEBUI_URL\"),\n            \"sd_webui_auth\": os.getenv(\"SD_WEBUI_AUTH\"),\n            \"selenium_web_browser\": os.getenv(\"USE_WEB_BROWSER\"),\n            \"selenium_headless\": os.getenv(\"HEADLESS_BROWSER\", \"True\") == \"True\",\n            \"user_agent\": os.getenv(\"USER_AGENT\"),\n            \"memory_backend\": os.getenv(\"MEMORY_BACKEND\"),\n            \"memory_index\": os.getenv(\"MEMORY_INDEX\"),\n            \"redis_host\": os.getenv(\"REDIS_HOST\"),\n            \"redis_password\": os.getenv(\"REDIS_PASSWORD\"),\n            \"wipe_redis_on_start\": os.getenv(\"WIPE_REDIS_ON_START\", \"True\") == \"True\",\n            \"plugins_dir\": os.getenv(\"PLUGINS_DIR\"),\n            \"plugins_config_file\": os.getenv(\n                \"PLUGINS_CONFIG_FILE\", PLUGINS_CONFIG_FILE\n            ),\n            \"chat_messages_enabled\": os.getenv(\"CHAT_MESSAGES_ENABLED\") == \"True\",\n        }\n\n        config_dict[\"disabled_command_categories\"] = _safe_split(\n            os.getenv(\"DISABLED_COMMAND_CATEGORIES\")\n        )\n\n        config_dict[\"shell_denylist\"] = _safe_split(\n            os.getenv(\"SHELL_DENYLIST\", os.getenv(\"DENY_COMMANDS\"))\n        )\n        config_dict[\"shell_allowlist\"] = _safe_split(\n            os.getenv(\"SHELL_ALLOWLIST\", os.getenv(\"ALLOW_COMMANDS\"))\n        )\n\n        config_dict[\"google_custom_search_engine_id\"] = os.getenv(\n            \"GOOGLE_CUSTOM_SEARCH_ENGINE_ID\", os.getenv(\"CUSTOM_SEARCH_ENGINE_ID\")\n        )\n\n        config_dict[\"elevenlabs_voice_id\"] = os.getenv(\n            \"ELEVENLABS_VOICE_ID\", os.getenv(\"ELEVENLABS_VOICE_1_ID\")\n        )\n        if not config_dict[\"text_to_speech_provider\"]:\n            if os.getenv(\"USE_MAC_OS_TTS\"):\n                default_tts_provider = \"macos\"\n            elif config_dict[\"elevenlabs_api_key\"]:\n                default_tts_provider = \"elevenlabs\"\n            elif os.getenv(\"USE_BRIAN_TTS\"):\n                default_tts_provider = \"streamelements\"\n            else:\n                default_tts_provider = \"gtts\"\n            config_dict[\"text_to_speech_provider\"] = default_tts_provider\n\n        config_dict[\"plugins_allowlist\"] = _safe_split(os.getenv(\"ALLOWLISTED_PLUGINS\"))\n        config_dict[\"plugins_denylist\"] = _safe_split(os.getenv(\"DENYLISTED_PLUGINS\"))\n\n        with contextlib.suppress(TypeError):\n            config_dict[\"image_size\"] = int(os.getenv(\"IMAGE_SIZE\"))\n        with contextlib.suppress(TypeError):\n            config_dict[\"redis_port\"] = int(os.getenv(\"REDIS_PORT\"))\n        with contextlib.suppress(TypeError):\n            config_dict[\"temperature\"] = float(os.getenv(\"TEMPERATURE\"))\n\n        if config_dict[\"use_azure\"]:\n            azure_config = cls.load_azure_config(\n                workdir / config_dict[\"azure_config_file\"]\n            )\n            config_dict.update(azure_config)\n\n        elif os.getenv(\"OPENAI_API_BASE_URL\"):\n            config_dict[\"openai_api_base\"] = os.getenv(\"OPENAI_API_BASE_URL\")\n\n        openai_organization = os.getenv(\"OPENAI_ORGANIZATION\")\n        if openai_organization is not None:\n            config_dict[\"openai_organization\"] = openai_organization\n\n        config_dict_without_none_values = {\n            k: v for k, v in config_dict.items() if v is not None\n        }\n\n        config = cls.build_agent_configuration(config_dict_without_none_values)\n\n        # Set secondary config variables (that depend on other config variables)\n\n        config.plugins_config = PluginsConfig.load_config(\n            config.workdir / config.plugins_config_file,\n            config.plugins_denylist,\n            config.plugins_allowlist,\n        )\n\n        return config\n\n    @classmethod\n    def load_azure_config(cls, config_file: Path) -> Dict[str, str]:\n        \"\"\"\n        Loads the configuration parameters for Azure hosting from the specified file\n          path as a yaml file.\n\n        Parameters:\n            config_file (Path): The path to the config yaml file.\n\n        Returns:\n            Dict\n        \"\"\"\n        with open(config_file) as file:\n            config_params = yaml.load(file, Loader=yaml.FullLoader) or {}\n\n        return {\n            \"openai_api_type\": config_params.get(\"azure_api_type\", \"azure\"),\n            \"openai_api_base\": config_params.get(\"azure_api_base\", \"\"),\n            \"openai_api_version\": config_params.get(\n                \"azure_api_version\", \"2023-03-15-preview\"\n            ),\n            \"azure_model_to_deployment_id_map\": config_params.get(\n                \"azure_model_map\", {}\n            ),\n        }\n\n\ndef check_openai_api_key(config: Config) -> None:\n    \"\"\"Check if the OpenAI API key is set in config.py or as an environment variable.\"\"\"\n    if not config.openai_api_key:\n        print(\n            Fore.RED\n            + \"Please set your OpenAI API key in .env or as an environment variable.\"\n            + Fore.RESET\n        )\n        print(\"You can get your key from https://platform.openai.com/account/api-keys\")\n        openai_api_key = input(\n            \"If you do have the key, please enter your OpenAI API key now:\\n\"\n        )\n        key_pattern = r\"^sk-\\w{48}\"\n        openai_api_key = openai_api_key.strip()\n        if re.search(key_pattern, openai_api_key):\n            os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n            config.openai_api_key = openai_api_key\n            print(\n                Fore.GREEN\n                + \"OpenAI API key successfully set!\\n\"\n                + Fore.YELLOW\n                + \"NOTE: The API key you've set is only temporary.\\n\"\n                + \"For longer sessions, please set it in .env file\"\n                + Fore.RESET\n            )\n        else:\n            print(\"Invalid OpenAI API key!\")\n            exit(1)\n\n\ndef _safe_split(s: Union[str, None], sep: str = \",\") -> list[str]:\n    \"\"\"Split a string by a separator. Return an empty list if the string is None.\"\"\"\n    if s is None:\n        return []\n    return s.split(sep)\n"}
{"type": "source_file", "path": "autogpt/commands/search_documentation.py", "content": "import os\nimport requests\nfrom googlesearch import search\nimport openai\nimport json\n\n# Set your OpenAI API key here\nopenai.api_key = 'your_openai_api_key'\n\ndef google_search(query, num_results=5):\n    \"\"\"Perform Google search and return top results.\"\"\"\n    results = []\n    for url in search(query, num_results=num_results):\n        results.append(url)\n    return results\n\nfrom bs4 import BeautifulSoup\n\ndef clean_html(html_content):\n    \"\"\"Clean HTML content using BeautifulSoup by removing unnecessary tags.\"\"\"\n    # Parse the HTML content with BeautifulSoup\n    soup = BeautifulSoup(html_content, 'html.parser')\n\n    # Remove script, style, and other unnecessary elements\n    for tag in soup(['script', 'style', 'header', 'footer', 'nav', 'aside', 'form']):\n        tag.decompose()  # Completely remove the tag and its content\n\n    # Get the text from the remaining content\n    cleaned_text = soup.get_text(separator=' ', strip=True)\n\n    # Remove excessive newlines or whitespace\n    cleaned_text = ' '.join(cleaned_text.split())\n\n    return cleaned_text\n\ndef fetch_webpage(url):\n    \"\"\"Fetch webpage content and clean the HTML to extract the main text.\"\"\"\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise exception if there's an error\n\n        # Clean the HTML content to extract main text\n        raw_html = response.text\n        cleaned_content = clean_html(raw_html)\n\n        return cleaned_content\n    except requests.RequestException as e:\n        print(f\"Error fetching {url}: {e}\")\n        return None\n\n\nimport subprocess\ndef analyze_content_with_gpt3(content, prompt):\n    \"\"\"Analyze the webpage content using GPT-3.5 via a curl request to the /chat/completions endpoint.\"\"\"\n    with open(\"openai_token.txt\") as opt:\n        token = opt.read()\n    try:\n        # Prepare the messages data in JSON format\n        messages = [\n            {\"role\": \"user\", \"content\": prompt + \"\\n\\nWebpage Content:\\n\" + content[:12000]}  # Limiting content length\n        ]\n\n        # Prepare the request data for the /chat/completions endpoint\n        data = {\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": messages\n        }\n\n        # Convert the data to a JSON string\n        data_json = json.dumps(data)\n\n        # Prepare the curl command\n        curl_command = [\n            \"curl\", \"https://api.openai.com/v1/chat/completions\",\n            \"-H\", \"Content-Type: application/json\",\n            \"-H\", \"Authorization: Bearer {}\".format(token),  # Replace with your API key\n            \"-d\", data_json\n        ]\n\n        # Execute the curl command and capture the response\n        result = subprocess.run(curl_command, capture_output=True, text=True)\n\n        # Check if the request was successful\n        if result.returncode == 0:\n            # Parse the JSON response\n            response_data = json.loads(result.stdout)\n            return response_data['choices'][0]['message']['content'].strip()\n        else:\n            print(f\"Error with curl request: {result.stderr}\")\n            return None\n\n    except Exception as e:\n        print(f\"Error analyzing content with GPT-3.5 (via curl): {e}\")\n        return None\n\ndef save_search_results(project_id, search_query, results):\n    \"\"\"Save the search query and extracted information to a file.\"\"\"\n    folder_path = f'search_logs/{project_id}'\n    os.makedirs(folder_path, exist_ok=True)  # Create the directory if it doesn't exist\n    file_path = os.path.join(folder_path, f'{search_query.replace(\" \", \"_\")}.json')\n\n    # Write the data to a JSON file\n    with open(file_path, 'w') as f:\n        json.dump(results, f, indent=4)\n\ndef search_install_doc(project_id):\n    search_query = \"{} build install from source\".format(project_id)\n    prompt = \"Extract instructions relevant to install or building the project '{}' on a Debian/Ubuntu Linux system from source code (extract a list of steps/requirements in a structered way and also the commands that needs to be installed). If the web page does not provide such information then just say that it does not.\".format(project_id)\n    # Step 1: Perform Google search\n    print(f\"Searching Google for: {search_query}\")\n    urls = google_search(search_query)\n\n    # Step 2: Retrieve and analyze each web page\n    results = []\n    for url in set(urls):\n        print(f\"Fetching content from: {url}\")\n        content = fetch_webpage(url)\n        if content:\n            print(f\"Analyzing content from: {url}\")\n            analysis = analyze_content_with_gpt3(content, prompt)\n            results.append({\n                    'url': url,\n                    'analysis': analysis\n                })\n    \n    # Step 3: Save the search query and analysis results to a folder\n    print(f\"Saving results to folder: search_logs/{project_id}\")\n    save_search_results(project_id, search_query, results)\n\n    return results\nif __name__ == \"__main__\":\n    # Example usage:\n    project_id = \"scipy\"\n    main(project_id)\n"}
{"type": "source_file", "path": "autogpt/core/__init__.py", "content": ""}
{"type": "source_file", "path": "autogpt/commands/git_operations.py", "content": "\"\"\"Commands to perform Git operations\"\"\"\n\nCOMMAND_CATEGORY = \"git_operations\"\nCOMMAND_CATEGORY_TITLE = \"Git Operations\"\n\nfrom git.repo import Repo\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.url_utils.validators import validate_url\n\nfrom .decorators import sanitize_path_arg\n\n\n@command(\n    \"clone_repository\",\n    \"Clones a Repository\",\n    {\n        \"url\": {\n            \"type\": \"string\",\n            \"description\": \"The URL of the repository to clone\",\n            \"required\": True,\n        },\n        \"clone_path\": {\n            \"type\": \"string\",\n            \"description\": \"The path to clone the repository to\",\n            \"required\": True,\n        },\n    },\n    lambda config: bool(config.github_username and config.github_api_key),\n    \"Configure github_username and github_api_key.\",\n)\n@sanitize_path_arg(\"clone_path\")\n@validate_url\ndef clone_repository(url: str, clone_path: str, agent: Agent) -> str:\n    \"\"\"Clone a GitHub repository locally.\n\n    Args:\n        url (str): The URL of the repository to clone.\n        clone_path (str): The path to clone the repository to.\n\n    Returns:\n        str: The result of the clone operation.\n    \"\"\"\n    split_url = url.split(\"//\")\n    auth_repo_url = (\n        f\"//{agent.config.github_username}:{agent.config.github_api_key}@\".join(\n            split_url\n        )\n    )\n    try:\n        Repo.clone_from(url=auth_repo_url, to_path=clone_path)\n        return f\"\"\"Cloned {url} to {clone_path}\"\"\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n"}
{"type": "source_file", "path": "autogpt/app/configurator.py", "content": "\"\"\"Configurator module.\"\"\"\nfrom __future__ import annotations\n\nfrom typing import Literal\n\nimport click\nfrom colorama import Back, Fore, Style\n\nfrom autogpt import utils\nfrom autogpt.config import Config\nfrom autogpt.config.config import GPT_3_MODEL, GPT_4_MODEL\nfrom autogpt.llm.api_manager import ApiManager\nfrom autogpt.logs import logger\nfrom autogpt.memory.vector import get_supported_memory_backends\n\n\ndef create_config(\n    config: Config,\n    continuous: bool,\n    continuous_limit: int,\n    ai_settings_file: str,\n    prompt_settings_file: str,\n    skip_reprompt: bool,\n    speak: bool,\n    debug: bool,\n    gpt3only: bool,\n    gpt4only: bool,\n    memory_type: str,\n    browser_name: str,\n    allow_downloads: bool,\n    skip_news: bool,\n) -> None:\n    \"\"\"Updates the config object with the given arguments.\n\n    Args:\n        continuous (bool): Whether to run in continuous mode\n        continuous_limit (int): The number of times to run in continuous mode\n        ai_settings_file (str): The path to the ai_settings.yaml file\n        prompt_settings_file (str): The path to the prompt_settings.yaml file\n        skip_reprompt (bool): Whether to skip the re-prompting messages at the beginning of the script\n        speak (bool): Whether to enable speak mode\n        debug (bool): Whether to enable debug mode\n        gpt3only (bool): Whether to enable GPT3.5 only mode\n        gpt4only (bool): Whether to enable GPT4 only mode\n        memory_type (str): The type of memory backend to use\n        browser_name (str): The name of the browser to use when using selenium to scrape the web\n        allow_downloads (bool): Whether to allow Auto-GPT to download files natively\n        skips_news (bool): Whether to suppress the output of latest news on startup\n    \"\"\"\n    config.debug_mode = False\n    config.continuous_mode = False\n    config.speak_mode = False\n\n    if debug:\n        logger.typewriter_log(\"Debug Mode: \", Fore.GREEN, \"ENABLED\")\n        config.debug_mode = True\n\n    if continuous:\n        logger.typewriter_log(\"Continuous Mode: \", Fore.RED, \"ENABLED\")\n        logger.typewriter_log(\n            \"WARNING: \",\n            Fore.RED,\n            \"Continuous mode is not recommended. It is potentially dangerous and may\"\n            \" cause your AI to run forever or carry out actions you would not usually\"\n            \" authorise. Use at your own risk.\",\n        )\n        config.continuous_mode = True\n\n        if continuous_limit:\n            logger.typewriter_log(\n                \"Continuous Limit: \", Fore.GREEN, f\"{continuous_limit}\"\n            )\n            config.continuous_limit = continuous_limit\n\n    # Check if continuous limit is used without continuous mode\n    if continuous_limit and not continuous:\n        raise click.UsageError(\"--continuous-limit can only be used with --continuous\")\n\n    if speak:\n        logger.typewriter_log(\"Speak Mode: \", Fore.GREEN, \"ENABLED\")\n        config.speak_mode = True\n\n    # Set the default LLM models\n    if gpt3only:\n        logger.typewriter_log(\"GPT3.5 Only Mode: \", Fore.GREEN, \"ENABLED\")\n        # --gpt3only should always use gpt-3.5-turbo, despite user's FAST_LLM config\n        config.fast_llm = GPT_3_MODEL\n        config.smart_llm = GPT_3_MODEL\n    elif (\n        gpt4only\n        and check_model(GPT_4_MODEL, model_type=\"smart_llm\", config=config)\n        == GPT_4_MODEL\n    ):\n        logger.typewriter_log(\"GPT4 Only Mode: \", Fore.GREEN, \"ENABLED\")\n        # --gpt4only should always use gpt-4, despite user's SMART_LLM config\n        config.fast_llm = GPT_4_MODEL\n        config.smart_llm = GPT_4_MODEL\n    else:\n        config.fast_llm = check_model(config.fast_llm, \"fast_llm\", config=config)\n        config.smart_llm = check_model(config.smart_llm, \"smart_llm\", config=config)\n\n    if memory_type:\n        supported_memory = get_supported_memory_backends()\n        chosen = memory_type\n        if chosen not in supported_memory:\n            logger.typewriter_log(\n                \"ONLY THE FOLLOWING MEMORY BACKENDS ARE SUPPORTED: \",\n                Fore.RED,\n                f\"{supported_memory}\",\n            )\n            logger.typewriter_log(\"Defaulting to: \", Fore.YELLOW, config.memory_backend)\n        else:\n            config.memory_backend = chosen\n\n    if skip_reprompt:\n        logger.typewriter_log(\"Skip Re-prompt: \", Fore.GREEN, \"ENABLED\")\n        config.skip_reprompt = True\n\n    if ai_settings_file:\n        file = ai_settings_file\n\n        # Validate file\n        (validated, message) = utils.validate_yaml_file(file)\n        if not validated:\n            logger.typewriter_log(\"FAILED FILE VALIDATION\", Fore.RED, message)\n            logger.double_check()\n            exit(1)\n\n        logger.typewriter_log(\"Using AI Settings File:\", Fore.GREEN, file)\n        config.ai_settings_file = file\n        config.skip_reprompt = True\n\n    if prompt_settings_file and False:\n        file = prompt_settings_file\n\n        # Validate file\n        (validated, message) = utils.validate_yaml_file(file)\n        if not validated:\n            logger.typewriter_log(\"FAILED FILE VALIDATION\", Fore.RED, message)\n            logger.double_check()\n            exit(1)\n\n        logger.typewriter_log(\"Using Prompt Settings File:\", Fore.GREEN, file)\n        config.prompt_settings_file = file\n\n    if browser_name:\n        config.selenium_web_browser = browser_name\n\n    if allow_downloads:\n        logger.typewriter_log(\"Native Downloading:\", Fore.GREEN, \"ENABLED\")\n        logger.typewriter_log(\n            \"WARNING: \",\n            Fore.YELLOW,\n            f\"{Back.LIGHTYELLOW_EX}Auto-GPT will now be able to download and save files to your machine.{Back.RESET} \"\n            + \"It is recommended that you monitor any files it downloads carefully.\",\n        )\n        logger.typewriter_log(\n            \"WARNING: \",\n            Fore.YELLOW,\n            f\"{Back.RED + Style.BRIGHT}ALWAYS REMEMBER TO NEVER OPEN FILES YOU AREN'T SURE OF!{Style.RESET_ALL}\",\n        )\n        config.allow_downloads = True\n\n    if skip_news:\n        config.skip_news = True\n\n\ndef check_model(\n    model_name: str,\n    model_type: Literal[\"smart_llm\", \"fast_llm\"],\n    config: Config,\n) -> str:\n    \"\"\"Check if model is available for use. If not, return gpt-3.5-turbo.\"\"\"\n    openai_credentials = config.get_openai_credentials(model_name)\n    api_manager = ApiManager()\n    models = api_manager.get_models(**openai_credentials)\n\n    if any(model_name in m[\"id\"] for m in models):\n        return model_name\n\n    logger.typewriter_log(\n        \"WARNING: \",\n        Fore.YELLOW,\n        f\"You do not have access to {model_name}. Setting {model_type} to \"\n        f\"gpt-3.5-turbo.\",\n    )\n    return \"gpt-3.5-turbo\"\n"}
{"type": "source_file", "path": "autogpt/commands/image_gen.py", "content": "\"\"\"Commands to generate images based on text input\"\"\"\n\nCOMMAND_CATEGORY = \"text_to_image\"\nCOMMAND_CATEGORY_TITLE = \"Text to Image\"\n\nimport io\nimport json\nimport time\nimport uuid\nfrom base64 import b64decode\n\nimport openai\nimport requests\nfrom PIL import Image\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.logs import logger\n\n\n@command(\n    \"generate_image\",\n    \"Generates an Image\",\n    {\n        \"prompt\": {\n            \"type\": \"string\",\n            \"description\": \"The prompt used to generate the image\",\n            \"required\": True,\n        },\n    },\n    lambda config: bool(config.image_provider),\n    \"Requires a image provider to be set.\",\n)\ndef generate_image(prompt: str, agent: Agent, size: int = 256) -> str:\n    \"\"\"Generate an image from a prompt.\n\n    Args:\n        prompt (str): The prompt to use\n        size (int, optional): The size of the image. Defaults to 256. (Not supported by HuggingFace)\n\n    Returns:\n        str: The filename of the image\n    \"\"\"\n    filename = agent.config.workspace_path / f\"{str(uuid.uuid4())}.jpg\"\n\n    # DALL-E\n    if agent.config.image_provider == \"dalle\":\n        return generate_image_with_dalle(prompt, filename, size, agent)\n    # HuggingFace\n    elif agent.config.image_provider == \"huggingface\":\n        return generate_image_with_hf(prompt, filename, agent)\n    # SD WebUI\n    elif agent.config.image_provider == \"sdwebui\":\n        return generate_image_with_sd_webui(prompt, filename, agent, size)\n    return \"No Image Provider Set\"\n\n\ndef generate_image_with_hf(prompt: str, filename: str, agent: Agent) -> str:\n    \"\"\"Generate an image with HuggingFace's API.\n\n    Args:\n        prompt (str): The prompt to use\n        filename (str): The filename to save the image to\n\n    Returns:\n        str: The filename of the image\n    \"\"\"\n    API_URL = f\"https://api-inference.huggingface.co/models/{agent.config.huggingface_image_model}\"\n    if agent.config.huggingface_api_token is None:\n        raise ValueError(\n            \"You need to set your Hugging Face API token in the config file.\"\n        )\n    headers = {\n        \"Authorization\": f\"Bearer {agent.config.huggingface_api_token}\",\n        \"X-Use-Cache\": \"false\",\n    }\n\n    retry_count = 0\n    while retry_count < 10:\n        response = requests.post(\n            API_URL,\n            headers=headers,\n            json={\n                \"inputs\": prompt,\n            },\n        )\n\n        if response.ok:\n            try:\n                image = Image.open(io.BytesIO(response.content))\n                logger.info(f\"Image Generated for prompt:{prompt}\")\n                image.save(filename)\n                return f\"Saved to disk:{filename}\"\n            except Exception as e:\n                logger.error(e)\n                break\n        else:\n            try:\n                error = json.loads(response.text)\n                if \"estimated_time\" in error:\n                    delay = error[\"estimated_time\"]\n                    logger.debug(response.text)\n                    logger.info(\"Retrying in\", delay)\n                    time.sleep(delay)\n                else:\n                    break\n            except Exception as e:\n                logger.error(e)\n                break\n\n        retry_count += 1\n\n    return f\"Error creating image.\"\n\n\ndef generate_image_with_dalle(\n    prompt: str, filename: str, size: int, agent: Agent\n) -> str:\n    \"\"\"Generate an image with DALL-E.\n\n    Args:\n        prompt (str): The prompt to use\n        filename (str): The filename to save the image to\n        size (int): The size of the image\n\n    Returns:\n        str: The filename of the image\n    \"\"\"\n\n    # Check for supported image sizes\n    if size not in [256, 512, 1024]:\n        closest = min([256, 512, 1024], key=lambda x: abs(x - size))\n        logger.info(\n            f\"DALL-E only supports image sizes of 256x256, 512x512, or 1024x1024. Setting to {closest}, was {size}.\"\n        )\n        size = closest\n\n    response = openai.Image.create(\n        prompt=prompt,\n        n=1,\n        size=f\"{size}x{size}\",\n        response_format=\"b64_json\",\n        api_key=agent.config.openai_api_key,\n    )\n\n    logger.info(f\"Image Generated for prompt:{prompt}\")\n\n    image_data = b64decode(response[\"data\"][0][\"b64_json\"])\n\n    with open(filename, mode=\"wb\") as png:\n        png.write(image_data)\n\n    return f\"Saved to disk:{filename}\"\n\n\ndef generate_image_with_sd_webui(\n    prompt: str,\n    filename: str,\n    agent: Agent,\n    size: int = 512,\n    negative_prompt: str = \"\",\n    extra: dict = {},\n) -> str:\n    \"\"\"Generate an image with Stable Diffusion webui.\n    Args:\n        prompt (str): The prompt to use\n        filename (str): The filename to save the image to\n        size (int, optional): The size of the image. Defaults to 256.\n        negative_prompt (str, optional): The negative prompt to use. Defaults to \"\".\n        extra (dict, optional): Extra parameters to pass to the API. Defaults to {}.\n    Returns:\n        str: The filename of the image\n    \"\"\"\n    # Create a session and set the basic auth if needed\n    s = requests.Session()\n    if agent.config.sd_webui_auth:\n        username, password = agent.config.sd_webui_auth.split(\":\")\n        s.auth = (username, password or \"\")\n\n    # Generate the images\n    response = requests.post(\n        f\"{agent.config.sd_webui_url}/sdapi/v1/txt2img\",\n        json={\n            \"prompt\": prompt,\n            \"negative_prompt\": negative_prompt,\n            \"sampler_index\": \"DDIM\",\n            \"steps\": 20,\n            \"config_scale\": 7.0,\n            \"width\": size,\n            \"height\": size,\n            \"n_iter\": 1,\n            **extra,\n        },\n    )\n\n    logger.info(f\"Image Generated for prompt:{prompt}\")\n\n    # Save the image to disk\n    response = response.json()\n    b64 = b64decode(response[\"images\"][0].split(\",\", 1)[0])\n    image = Image.open(io.BytesIO(b64))\n    image.save(filename)\n\n    return f\"Saved to disk:{filename}\"\n"}
{"type": "source_file", "path": "autogpt/config/ai_config.py", "content": "\"\"\"A module that contains the AIConfig class object that contains the configuration\"\"\"\nfrom __future__ import annotations\n\nimport platform\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Optional\n\nimport distro\nimport yaml\n\nif TYPE_CHECKING:\n    from autogpt.models.command_registry import CommandRegistry\n    from autogpt.prompts.generator import PromptGenerator\n\n    from .config import Config\n\n\nclass AIConfig:\n    \"\"\"\n    A class object that contains the configuration information for the AI\n\n    Attributes:\n        ai_name (str): The name of the AI.\n        ai_role (str): The description of the AI's role.\n        ai_goals (list): The list of objectives the AI is supposed to complete.\n        api_budget (float): The maximum dollar value for API calls (0.0 means infinite)\n    \"\"\"\n\n    def __init__(\n        self,\n        ai_name: str = \"\",\n        ai_role: str = \"\",\n        ai_goals: list[str] = [],\n        api_budget: float = 0.0,\n    ) -> None:\n        \"\"\"\n        Initialize a class instance\n\n        Parameters:\n            ai_name (str): The name of the AI.\n            ai_role (str): The description of the AI's role.\n            ai_goals (list): The list of objectives the AI is supposed to complete.\n            api_budget (float): The maximum dollar value for API calls (0.0 means infinite)\n        Returns:\n            None\n        \"\"\"\n        self.ai_name = ai_name\n        self.ai_role = ai_role\n        self.ai_goals = ai_goals\n        self.api_budget = api_budget\n        self.prompt_generator: PromptGenerator | None = None\n        self.command_registry: CommandRegistry | None = None\n\n    @staticmethod\n    def load(ai_settings_file: str | Path) -> \"AIConfig\":\n        \"\"\"\n        Returns class object with parameters (ai_name, ai_role, ai_goals, api_budget)\n        loaded from yaml file if yaml file exists, else returns class with no parameters.\n\n        Parameters:\n            ai_settings_file (Path): The path to the config yaml file.\n\n        Returns:\n            cls (object): An instance of given cls object\n        \"\"\"\n\n        try:\n            with open(ai_settings_file, encoding=\"utf-8\") as file:\n                config_params = yaml.load(file, Loader=yaml.FullLoader) or {}\n        except FileNotFoundError:\n            config_params = {}\n\n        ai_name = config_params.get(\"ai_name\", \"\")\n        ai_role = config_params.get(\"ai_role\", \"\")\n        ai_goals = [\n            str(goal).strip(\"{}\").replace(\"'\", \"\").replace('\"', \"\")\n            if isinstance(goal, dict)\n            else str(goal)\n            for goal in config_params.get(\"ai_goals\", [])\n        ]\n        api_budget = config_params.get(\"api_budget\", 0.0)\n\n        return AIConfig(ai_name, ai_role, ai_goals, api_budget)\n\n    def save(self, ai_settings_file: str | Path) -> None:\n        \"\"\"\n        Saves the class parameters to the specified file yaml file path as a yaml file.\n\n        Parameters:\n            ai_settings_file (Path): The path to the config yaml file.\n\n        Returns:\n            None\n        \"\"\"\n\n        config = {\n            \"ai_name\": self.ai_name,\n            \"ai_role\": self.ai_role,\n            \"ai_goals\": self.ai_goals,\n            \"api_budget\": self.api_budget,\n        }\n        with open(ai_settings_file, \"w\", encoding=\"utf-8\") as file:\n            yaml.dump(config, file, allow_unicode=True)\n\n    def construct_full_prompt(\n        self, config: Config, prompt_generator: Optional[PromptGenerator] = None\n    ) -> str:\n        \"\"\"\n        Returns a prompt to the user with the class information in an organized fashion.\n\n        Parameters:\n            None\n\n        Returns:\n            full_prompt (str): A string containing the initial prompt for the user\n              including the ai_name, ai_role, ai_goals, and api_budget.\n        \"\"\"\n\n        from autogpt.prompts.prompt import build_default_prompt_generator\n\n        prompt_generator = prompt_generator or self.prompt_generator\n        if prompt_generator is None:\n            prompt_generator = build_default_prompt_generator(config)\n            prompt_generator.command_registry = self.command_registry\n            self.prompt_generator = prompt_generator\n\n        for plugin in config.plugins:\n            if not plugin.can_handle_post_prompt():\n                continue\n            prompt_generator = plugin.post_prompt(prompt_generator)\n\n        # Construct full prompt\n        full_prompt_parts = {\n            \n            \"role\": f\"You are {self.ai_name}, {self.ai_role.rstrip('.')}.\" +\\\n            \"Your decisions must always be made independently without seeking \" +\\\n            \"user assistance. Play to your strengths as an LLM and pursue \" +\\\n            \"simple strategies with no legal complications.\"\n        }\n\n        if config.execute_local_commands:\n            # add OS info to prompt\n            os_name = platform.system()\n            os_info = (\n                platform.platform(terse=True)\n                if os_name != \"Linux\"\n                else distro.name(pretty=True)\n            )\n\n            full_prompt_parts.append(f\"The OS you are running on is: {os_info}\")\n\n        if self.ai_goals:\n            full_prompt_parts[\"goals\"] = [\n                        \"## Goals\",\n                        \"For your task, you must fulfill the following goals:\",\n                        *[f\"{i+1}. {goal}\" for i, goal in enumerate(self.ai_goals)],\n                    ]\n            \n        additional_constraints: list[str] = []\n        if self.api_budget > 0.0:\n            additional_constraints[\"additional constraints\"] = (\n                f\"It takes money to let you run. \"\n                f\"Your API budget is ${self.api_budget:.3f}\"\n            )\n\n        full_prompt_parts.update(\n            prompt_generator.generate_prompt_string(\n            )\n        )\n\n        return full_prompt_parts\n"}
{"type": "source_file", "path": "autogpt/commands/system.py", "content": "\"\"\"Commands to control the internal state of the program\"\"\"\n\nfrom __future__ import annotations\n\nCOMMAND_CATEGORY = \"system\"\nCOMMAND_CATEGORY_TITLE = \"System\"\n\nfrom typing import NoReturn\nimport os\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.commands.docker_helpers_static import execute_command_in_container, stop_and_remove\nfrom autogpt.logs import logger\n\n@command(\n    \"goals_accomplished\",\n    \"Goals are accomplished and there is nothing left to do\",\n    {\n        \"reason\": {\n            \"type\": \"string\",\n            \"description\": \"A summary to the user of how the goals were accomplished\",\n            \"required\": True,\n        }\n    },\n)\ndef task_complete(reason: str, agent: Agent) -> NoReturn:\n    \"\"\"\n    A function that takes in a string and exits the program\n\n    Parameters:\n        reason (str): A summary to the user of how the goals were accomplished.\n    Returns:\n        A result string from create chat completion. A list of suggestions to\n            improve the code.\n    \"\"\"\n    project_path = agent.project_path\n    workspace = \"execution_agent_workspace/\"\n    files_list = [x[0].lower() for x in agent.written_files]\n    #if \"coverage_results.txt\" not in files_list:\n    #    return \"You cannot claim goal accomplished without running test cases, measuring coverage and saving them to the file 'coverage_results.txt'\"\n    if \"dockerfile\" not in files_list:\n        return \"You have not created a docker file that creates a docker images and installs the project within that image, installs the dependencies and run tests\"\n    #if not any(\"coverage\" in x for x in files_list):\n    #    return \"You should write test results into a file called: coverage_results.txt\"\n    #else:\n    #    for file in agent.written_files:\n    #        if \"coverage\" in file[0].lower():\n    #            condition1 = \"coverage\" in file[0].lower()\n    #            condition2 = any(x not in files[1].lower() for x in [\"Tests run:\", \"Tests passed:\", \"Tests failed:\", \"Tests skipped:\"])\n    #            if not condition1 and not condition2:\n    #                pass\n    #            break\n    #    else:\n    #        if condition1:\n    #            return \"You have to measure test suite coverage, N/A is not an acceptable value\"\n    #        elif condition2:\n    #            return \"The coverage_results file should have the following format:\\n\"+ \"\"\"Tests run: [PUT CONCRETE VALUE HERE]\n#Tests passed: [PUT CONCRETE VALUE HERE]\n#Tests failed: [PUT CONCRETE VALUE HERE]\n#Tests skipped: [PUT CONCRETE VALUE HERE]\n#Average coverage: [PUT CONCRETE VALUE HERE]\n#                    \"\"\"\n    logger.info(title=\"Shutting down...\\n\", message=reason)\n    if not agent.keep_container and agent.container:\n        stop_and_remove(agent.container)\n        os.system(\"docker system prune -af\")\n    with open(os.path.join(\"experimental_setups\", agent.exp_number, \"saved_contexts\", project_path, \"SUCCESS\"), \"w\") as ssf:\n        ssf.write(\"SUCCESS\")\n    quit()\n"}
{"type": "source_file", "path": "autogpt/commands/steps_commands.py", "content": "\"\"\"Commands to execute code\"\"\"\n\nCOMMAND_CATEGORY = \"steps_commands\"\nCOMMAND_CATEGORY_TITLE = \"STEPS COMMANDS\"\n\nimport os\nimport subprocess\nimport re\nimport json\nimport random\nimport time\n\nimport docker\nfrom docker.errors import DockerException, ImageNotFound\nfrom docker.models.containers import Container as DockerContainer\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.logs import logger\n\nfrom create_files_index import list_java_files\n\nALLOWLIST_CONTROL = \"allowlist\"\nDENYLIST_CONTROL = \"denylist\"\nworkspace_folder = \"execution_agent_workspace\"\n\n\"\"\"\n    Step 1:\n        extract_python_version\n        write_python_version_to_file\n\n    Step 2:\n        extract_dependencies\n        list_files\n        read_file\n        write_dependencies_to_file\n\n    Step 3:\n        create_virtual_environment\n\n    Step 4:\n        linux_terminal\n\n    Step 5:\n        extract_test_info_from_readme\n        list_files\n        write_test_commands\n\n    Step 6:\n        linux_terminal\n\n    Step 7:\n        linux_terminal\n\n    Step 8:\n        write_installation_script\n\n    Step 9:\n        git (for cloning the repository)\n        Dockerfile (for Docker image configuration)\n\n\n\"\"\"\n\n\"\"\"@command(\n    \"extract_language_and_version\",\n    \"\",\n    {\n    },\n)\"\"\"\ndef extract_language_and_version(agent: Agent) -> str:\n    project_path = agent.project_path\n    system_prompt = \"You are an assitant that helps analyze README file of a project to extract information relevant to the language of the project and the version.\"\n    query = \"Here is the content of the README file of a project on GitHub, your task is to extract information related to the language/version required to install and run the project.\\n\"\n    project_path = agent.project_path\n    root_files = os.listdir(os.path.join(workspace_folder, project_path))\n    readme_name = \"\"\n    for f in root_files:\n        if f.lower() == \"readme.md\":\n            readme_name = f\n            break\n    else:\n        for f in root_files:\n            if \"readme\" in f:\n                readme_name = f\n                break\n        else:\n            return \"Error: no readme files found\"\n    with open(os.path.join(workspace_folder, project_path, readme_name)) as fpp:\n        readme_content = fpp.read()\n    query += readme_content\n\n    return ask_chatgpt(query, system_prompt)\n\n\"\"\"@command(\n    \"write_language_version_to_file\",\n    \"\",\n    {\n        \"language_version\": {\n            \"type\": \"string\",\n            \"description\": \"\",\n            \"required\": True\n        }\n    },\n)\"\"\"\ndef write_language_version_to_file(language_version: str, agent: Agent) -> str:\n    project_path = agent.project_path\n    with open(os.path.join(workspace_folder, project_path, \"LANGUAGE_VERSION.txt\"), \"w\") as lvt:\n        lvt.write(language_version)\n    return \"Language version written successfully\"\n\n\"\"\"@command(\n    \"extract_dependencies\",\n    \"\",\n    {\n    },\n)\"\"\"\ndef extract_dependencies(agent: Agent) -> str:\n    project_path = agent.project_path\n    system_prompt = \"You are an assitant that helps analyze README file of a project to extract information relevant to the required dependencies to install and run the project.\"\n    query = \"Here is the content of the README file of a project on GitHub, your task is to extract information related to the required dependencies (packages, modules, software, system applications...)\\n\"\n    project_path = agent.project_path\n    root_files = os.listdir(os.path.join(workspace_folder, project_path))\n    readme_name = \"\"\n    for f in root_files:\n        if f.lower() == \"readme.md\":\n            readme_name = f\n            break\n    else:\n        for f in root_files:\n            if \"readme\" in f:\n                readme_name = f\n                break\n        else:\n            return \"Error: no readme files found\"\n    with open(os.path.join(workspace_folder, project_path, readme_name)) as fpp:\n        readme_content = fpp.read()\n    query += readme_content\n\n    return ask_chatgpt(query, system_prompt)\n\n\"\"\"@command(\n    \"list_files\",\n    \"\",\n    {\n        \n    },\n)\"\"\"\ndef list_files(agent: Agent) -> str:\n    return os.listdir(os.path.join(workspace_folder, agent.project_path))\n\n@command(\n    \"read_file\",\n    \"\",\n    {\n        \"file_path\": {\n            \"type\": \"string\",\n            \"description\": \"\",\n            \"required\": True,\n        }\n    },\n)\ndef read_file(file_path: str, agent: Agent) -> str:\n    project_path = agent.project_path\n    with open(os.path.join(workspace_folder, project_path, file_path)) as fpp:\n        return \"The result of reading the file {}:\\n{}\".format(file_path, fpp.read())\n\n\"\"\"@command(\n    \"write_dependencies_to_file\",\n    \"\",\n    {\n        \"dependecies list\": {\n            \"type\": \"string\",\n            \"description\": \"\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\ndef write_dependencies_to_file(dependencies_list: str, agent: Agent) -> str:\n    project_path = agent.project_path\n    with open(workspace_folder, project_path, \"DEPENDENCIES_LIST.txt\", \"w\") as dlt:\n        dlt.write(dependencies_list)\n    return \"Dependencies written successfully\"\n\n\"\"\"@command(\n    \"write_setup_environment_commands\",\n    \"\",\n    {\n        \"commands_list\": {\n            \"type\": \"string\",\n            \"description\": \"\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\ndef write_setup_environment_commands(commands_list:str, agent: Agent) -> str:\n    project_path = agent.project_path\n    with open(os.path.join(workspace_folder, project_path, \"ENVIRONMENT_SETUP.txt\"), \"w\") as est:\n        est.write(commands_list)\n\n    commands_list_split = commands_list.split(\"\\n\")\n    for cmd in commands_list_split:\n        execute_shell(cmd)\n\n    return \"The setup environment commands were saved into a file and executed\"\n\n\"\"\"@command(\n    \"extract_build_and_test_info_from_readme\",\n    \"\",\n    {\n    },\n)\"\"\"\ndef extract_build_and_test_info_from_readme(agent: Agent) -> str:\n    project_path = agent.project_path\n    system_prompt = \"You are an assitant that helps analyze README file of a project to extract information relevant to the steps and tools used to build and run tests of the project.\"\n    query = \"Here is the content of the README file of a project on GitHub, your task is to extract information about the process/tools used to build and test the project.\\n\"\n    project_path = agent.project_path\n    root_files = os.listdir(os.path.join(workspace_folder, project_path))\n    readme_name = \"\"\n    for f in root_files:\n        if f.lower() == \"readme.md\":\n            readme_name = f\n            break\n    else:\n        for f in root_files:\n            if \"readme\" in f:\n                readme_name = f\n                break\n        else:\n            return \"Error: no readme files found\"\n    with open(os.path.join(workspace_folder, project_path, readme_name)) as fpp:\n        readme_content = fpp.read()\n    query += readme_content\n    return ask_chatgpt(query, system_prompt)\n\n\"\"\"@command(\n    \"write_build_test_commands\",\n    \"\",\n    {\n        \"commands\": {\n            \"type\": \"string\",\n            \"description\": \"\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\ndef write_build_test_commands(commands: str, agent: Agent) -> str:\n    project_path = agent.project_path\n    with open(os.path.join(workspace_folder, project_path, \"BUILD_TEST_COMMANDS.txt\"), \"w\") as btc:\n        btc.write(commands)\n    \n    cmds_split = commands.split(\"\\n\")\n\n    execution_results = \"\"\n    for cmd in cmds_split:\n        execution_results += execute_shell(cmd)\n\n    with open(os.path.join(workspace_folder, project_path, \"BUILD_TEST_RESULTS.txt\"), \"w\") as btr:\n        btr.write(execution_results)\n    return \"Build and test commands were written successfully.\"\n\n\"\"\"@command(\n    \"write_installation_script\",\n    \"\",\n    {\n        \"installation_script\": {\n            \"type\": \"string\",\n            \"description\": \"\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\n\n\ndef write_installation_script(installation_script: str, agent: Agent) -> str:\n    project_path = agent.project_path\n    with open(os.path.join(workspace_folder, project_path, \"INSTALLATION_SCRIPT.sh\"), \"w\") as insts:\n        insts.write(installation_script)\n\n    return \"The installation script was written successfully\"\n\n\"\"\"@command(\n    \"write_Dockerfile_script\",\n    \"\",\n    {\n        \"docker_script\": {\n            \"type\": \"string\",\n            \"description\": \"\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\ndef write_Dockerfile_script(docker_script: str, agent: Agent) -> str:\n    project_path = agent.project_path\n    with open(os.path.join(workspace_folder, project_path, \"DOCKER_SCRIPT.sh\"), \"w\") as insts:\n        insts.write(installation_script)\n\n    return \"The docker script was written successfully\"\n\n\ndef execute_shell(command_line: str) -> str:\n    current_dir = Path.cwd()\n    # Change dir into workspace if necessary\n    if not current_dir.is_relative_to(workspace_folder):\n        os.chdir(workspace_folder)\n\n    logger.info(\n        f\"Executing command '{command_line}' in working directory '{os.getcwd()}'\"\n    )\n\n    result = subprocess.run(command_line, capture_output=True, shell=True)\n    output = f\"STDOUT:\\n{result.stdout}\\nSTDERR:\\n{result.stderr}\"\n\n    # Change back to whatever the prior working dir was\n\n    os.chdir(current_dir)\n    return output"}
{"type": "source_file", "path": "autogpt/commands/states.py", "content": "COMMAND_CATEGORY = \"states\"\nCOMMAND_CATEGORY_TITLE = \"STATES\"\nALLOWLIST_CONTROL = \"allowlist\"\nDENYLIST_CONTROL = \"denylist\"\n\nfrom autogpt.command_decorator import command\nfrom autogpt.agents.agent import Agent\n\n\n@command(\n        \"express_hypothesis\",\n        \"This command allows to express a hypothesis about what exactly is the bug. Call this command after you have collected enough information about the bug in the project\",\n        {\n            \"hypothesis\":{\n                \"type\": \"string\",\n                \"description\": \"The hypothesis that youo should express in text\",\n                \"required\": True\n            }\n        }\n)\ndef express_hypothesis(hypothesis: str, agent: Agent) -> str:\n    return \"Since you have a hypothesis about the bug, the current state have been changed from 'collect information to understand the bug' to 'collect information to fix the bug'\"\n\n@command(\n        \"discard_hypothesis\",\n        \"This command allows you to discard the hypothesis that you made earlier about the bug and automatically return back again to the state 'collect information to uderstand the bug' where you can express a new hypothesis\",\n        {\n            \"reason_for_discarding\":{\n                \"type\": \"string\",\n                \"description\": \"Give your reason for discarding the hypothesis\",\n                \"required\": True\n            }\n        }\n)\ndef discard_hypothesis(reason_for_discarding: str, agent: Agent) -> str:\n    return \"Hypothesis discarded! You are now back at the state 'collect information to understand the bug'\"\n\n@command(\n        \"go_back_to_collect_more_info\",\n        \"This command allows you to go back to the state 'collect information to fix the bug'. Call this command when you suggest many fixes but none of them work.\",\n        {\n            \"reason_for_going_back\":{\n                \"type\": \"string\",\n                \"description\": \"Give your reason for going back to a previous state\",\n                \"required\": True\n            }\n        }\n)\ndef go_back_to_collect_more_info(reason_for_going_back: str, agent: Agent) -> str:\n    return \"You are now back at the state 'collect information to fix the bug'\"\n\n\n@command(\n    \"change_state\",\n    \"this command allows you to change the current state based on info that you collected and the next steps that you want to make. As intput to this function, give the name of your current state and the name of the state that you want to switch to. Current state and next state should be two different states (cannot change to the same state).\",\n    {\n        \"next_state_name\": {\n            \"type\": \"string\",\n            \"description\": \"The name the next_state\",\n            \"required\": True,\n        }\n    },\n)\ndef change_state(current_state:str, next_state_name: str, agent:Agent) -> str:\n    change_possibilities = {\n        \"collect information to understand the bug\": [\"collect information to fix the bug\"],\n        \"collect information to fix the bug\":[\"trying out candidate fixes\"],\n        \"trying out candidate fixes\": [\"collect information to understand the bug\", \"collect information to fix the bug\"]\n    }\n    if current_state not in change_possibilities:\n        return \"Uknown current state, please provide the correct current state name\"\n    elif next_state_name not in change_possibilities[current_state]:\n        return \"Impossibel to switch state from {} to {}. It is not allowed.\".format(current_state, next_state_name)\n    else:\n        return \"State changed successfully.\"\n    \n\"\"\"\ns1: collect information to understand the bug\ns2: collect information to fix the bug\ns3: trying out candidate fixes\n\ns3 to s1: discard hypothesis\ns3 to s2: need more info\n\"\"\"\n\n## TODO SAVE THE HYPOTHESIS IN THE PROMPT\n\n\n@command(\n        \"go_back_to_collect_more_info\",\n        \"\",\n        {\n            \n        }\n)\ndef go_back_to_collect_more_info(agent: Agent) -> str:\n    return \"You are now back to the state 'collect information for environement setup'\"\n\n@command(\n        \"goto_tests_results_analysis\",\n        \"\",\n        {\n            \n        }\n)\ndef goto_tests_results_analysis(agent: Agent) -> str:\n    return \"You are now at the state 'analyzing test suite results'\"\n\n\n@command(\n        \"goto_setup_automation\",\n        \"\",\n        {\n            \n        }\n)\ndef goto_setup_automation(agent: Agent) -> str:\n    return \"You are now at the state 'Setting up the environement and installing the project'\""}
{"type": "source_file", "path": "autogpt/app/spinner.py", "content": "\"\"\"A simple spinner module\"\"\"\nimport itertools\nimport sys\nimport threading\nimport time\n\n\nclass Spinner:\n    \"\"\"A simple spinner class\"\"\"\n\n    def __init__(\n        self,\n        message: str = \"Loading...\",\n        delay: float = 0.1,\n        plain_output: bool = False,\n    ) -> None:\n        \"\"\"Initialize the spinner class\n\n        Args:\n            message (str): The message to display.\n            delay (float): The delay between each spinner update.\n            plain_output (bool): Whether to display the spinner or not.\n        \"\"\"\n        self.plain_output = plain_output\n        self.spinner = itertools.cycle([\"-\", \"/\", \"|\", \"\\\\\"])\n        self.delay = delay\n        self.message = message\n        self.running = False\n        self.spinner_thread = None\n\n    def spin(self) -> None:\n        \"\"\"Spin the spinner\"\"\"\n        if self.plain_output:\n            self.print_message()\n            return\n        while self.running:\n            self.print_message()\n            time.sleep(self.delay)\n\n    def print_message(self):\n        sys.stdout.write(f\"\\r{' ' * (len(self.message) + 2)}\\r\")\n        sys.stdout.write(f\"{next(self.spinner)} {self.message}\\r\")\n        sys.stdout.flush()\n\n    def start(self):\n        self.running = True\n        self.spinner_thread = threading.Thread(target=self.spin)\n        self.spinner_thread.start()\n\n    def stop(self):\n        self.running = False\n        if self.spinner_thread is not None:\n            self.spinner_thread.join()\n        sys.stdout.write(f\"\\r{' ' * (len(self.message) + 2)}\\r\")\n        sys.stdout.flush()\n\n    def __enter__(self):\n        \"\"\"Start the spinner\"\"\"\n        self.start()\n        return self\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -> None:\n        \"\"\"Stop the spinner\n\n        Args:\n            exc_type (Exception): The exception type.\n            exc_value (Exception): The exception value.\n            exc_traceback (Exception): The exception traceback.\n        \"\"\"\n        self.stop()\n"}
{"type": "source_file", "path": "autogpt/commands/web_search.py", "content": "\"\"\"Commands to search the web with\"\"\"\n\nfrom __future__ import annotations\n\nCOMMAND_CATEGORY = \"web_search\"\nCOMMAND_CATEGORY_TITLE = \"Web Search\"\n\nimport json\nimport time\nfrom itertools import islice\nimport os\nimport subprocess\n\nfrom duckduckgo_search import DDGS\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\n\nDUCKDUCKGO_MAX_ATTEMPTS = 3\n\n@command(\n    \"search_docker_image\",\n    \"Search for docker images on docker hub\",\n    {\n        \"search_term\": {\n            \"type\": \"string\",\n            \"description\": \"the search terms\",\n            \"required\": True,\n        }\n    },\n)\ndef search_docker_image(search_term: str, agent):\n    \"\"\"\n    Searches for a Docker image using the specified search term.\n\n    Args:\n    - search_term (str): The term to search for Docker images.\n\n    Returns:\n    - str: The output from the Docker search command.\n    \"\"\"\n    # Prepare the Docker search command\n    command = [\"docker\", \"search\", search_term]\n\n    # Execute the command and capture the output\n    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n\n    # Check for errors\n    if result.returncode != 0:\n        raise Exception(f\"Error executing docker search: {result.stderr}\")\n\n    # Return the output\n    return result.stdout\n\n@command(\n    \"web_search\",\n    \"Searches the web\",\n    {\n        \"query\": {\n            \"type\": \"string\",\n            \"description\": \"The search query\",\n            \"required\": True,\n        }\n    },\n    aliases=[\"search\"],\n)\ndef web_search(query: str, agent: Agent, num_results: int = 8) -> str:\n    \"\"\"Return the results of a Google search\n\n    Args:\n        query (str): The search query.\n        num_results (int): The number of results to return.\n\n    Returns:\n        str: The results of the search.\n    \"\"\"\n    search_results = []\n    attempts = 0\n\n    while attempts < DUCKDUCKGO_MAX_ATTEMPTS:\n        if not query:\n            return json.dumps(search_results)\n\n        results = DDGS().text(query)\n        search_results = list(islice(results, num_results))\n\n        if search_results:\n            break\n\n        time.sleep(1)\n        attempts += 1\n\n    results = json.dumps(search_results, ensure_ascii=False, indent=4)\n    return safe_google_results(results)\n\n\n@command(\n    \"google\",\n    \"Google Search\",\n    {\n        \"query\": {\n            \"type\": \"string\",\n            \"description\": \"The search query\",\n            \"required\": True,\n        }\n    },\n    lambda config: bool(config.google_api_key)\n    and bool(config.google_custom_search_engine_id),\n    \"Configure google_api_key and custom_search_engine_id.\",\n    aliases=[\"search\"],\n)\ndef google(query: str, agent: Agent, num_results: int = 8) -> str | list[str]:\n    \"\"\"Return the results of a Google search using the official Google API\n\n    Args:\n        query (str): The search query.\n        num_results (int): The number of results to return.\n\n    Returns:\n        str: The results of the search.\n    \"\"\"\n\n    from googleapiclient.discovery import build\n    from googleapiclient.errors import HttpError\n\n    try:\n        # Get the Google API key and Custom Search Engine ID from the config file\n        api_key = agent.config.google_api_key\n        custom_search_engine_id = agent.config.google_custom_search_engine_id\n\n        # Initialize the Custom Search API service\n        service = build(\"customsearch\", \"v1\", developerKey=api_key)\n\n        # Send the search query and retrieve the results\n        result = (\n            service.cse()\n            .list(q=query, cx=custom_search_engine_id, num=num_results)\n            .execute()\n        )\n\n        # Extract the search result items from the response\n        search_results = result.get(\"items\", [])\n\n        # Create a list of only the URLs from the search results\n        search_results_links = [item[\"link\"] for item in search_results]\n\n    except HttpError as e:\n        # Handle errors in the API call\n        error_details = json.loads(e.content.decode())\n\n        # Check if the error is related to an invalid or missing API key\n        if error_details.get(\"error\", {}).get(\n            \"code\"\n        ) == 403 and \"invalid API key\" in error_details.get(\"error\", {}).get(\n            \"message\", \"\"\n        ):\n            return \"Error: The provided Google API key is invalid or missing.\"\n        else:\n            return f\"Error: {e}\"\n    # google_result can be a list or a string depending on the search results\n\n    # Return the list of search result URLs\n    return safe_google_results(search_results_links)\n\n\ndef safe_google_results(results: str | list) -> str:\n    \"\"\"\n        Return the results of a Google search in a safe format.\n\n    Args:\n        results (str | list): The search results.\n\n    Returns:\n        str: The results of the search.\n    \"\"\"\n    if isinstance(results, list):\n        safe_message = json.dumps(\n            [result.encode(\"utf-8\", \"ignore\").decode(\"utf-8\") for result in results]\n        )\n    else:\n        safe_message = results.encode(\"utf-8\", \"ignore\").decode(\"utf-8\")\n    return safe_message\n"}
{"type": "source_file", "path": "autogpt/app/__init__.py", "content": ""}
{"type": "source_file", "path": "autogpt/commands/info_collection_static.py", "content": "import os\n\n\ndef collect_requirements(project_path):\n    os.system(\"cd execution_agent_workspace/{} && detect-requirements . > special_file_1.txt\".format(project_path))\n\ndef infer_requirements(project_path):\n    os.system(\"cd execution_agent_workspace/{} && pipreqs . --savepath special_file_2.txt\".format(project_path))\n\ndef extract_instructions_from_readme(project_path) -> str:\n    \"\"\"\n    \"\"\"\n    workspace = \"execution_agent_workspace/\"\n    files_at_root = os.listdir(os.path.join(workspace, project_path))\n\n    readme_files = []\n    for f in files_at_root:\n        if \"readme\" in f.lower():\n            readme_files.append(f)\n\n    readme_text = \"\"\n\n    for f in readme_files:\n        with open(os.path.join(workspace, project_path, f)) as wpf:\n            readme_text += \"------>File: {}\\n{}\\n\".format(f, wpf.read())\n    \n    if readme_text == \"\":\n        return \"No readme file found\"\n    \n    system_prompt = \"You are an AI assistant that would help a develper in the mission of installing a python project an getting to run. Your task for now is to analyze the text of the readme file of the target project and extract installation related instructions from the given text of readme file(s).\"\n\n    query = \"Here is the content of the readme file(s). Please extract any information related to installation including step-by-step points, environement, required software and their versions and also any manaual steps that needs to be done.\\n\\n\" + readme_text[:40000]\n\n    return ask_chatgpt(query, system_prompt)\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema.messages import HumanMessage, SystemMessage, AIMessage\ndef ask_chatgpt(query, system_message, model=\"gpt-4o-mini\"):\n    with open(\"openai_token.txt\") as opt:\n        token = opt.read()\n    chat = ChatOpenAI(openai_api_key=token, model=model)\n\n    messages = [\n        SystemMessage(\n            content= system_message\n                    ),\n        HumanMessage(\n            content=query\n            )  \n    ]\n    #response_format={ \"type\": \"json_object\" }\n    response = chat.invoke(messages)\n\n    return response.content\n\nif __name__ == \"__main__\":\n    print(extract_instructions_from_readme(\"code2flow\"))"}
{"type": "source_file", "path": "autogpt/config/prompt_config.py", "content": "# sourcery skip: do-not-use-staticmethod\n\"\"\"\nA module that contains the PromptConfig class object that contains the configuration\n\"\"\"\nimport yaml\nfrom colorama import Fore\n\nfrom autogpt import utils\nfrom autogpt.logs import logger\n\n\nclass PromptConfig:\n    \"\"\"\n    A class object that contains the configuration information for the prompt, which will be used by the prompt generator\n\n    Attributes:\n        constraints (list): Constraints list for the prompt generator.\n        resources (list): Resources list for the prompt generator.\n        performance_evaluations (list): Performance evaluation list for the prompt generator.\n    \"\"\"\n\n    def __init__(self, prompt_settings_file: str) -> None:\n        \"\"\"\n        Initialize a class instance with parameters (constraints, resources, performance_evaluations) loaded from\n          yaml file if yaml file exists,\n        else raises error.\n\n        Parameters:\n            constraints (list): Constraints list for the prompt generator.\n            resources (list): Resources list for the prompt generator.\n            performance_evaluations (list): Performance evaluation list for the prompt generator.\n        Returns:\n            None\n        \"\"\"\n        self.general_guidelines = []\n        return None\n        # Validate file\n        (validated, message) = utils.validate_yaml_file(prompt_settings_file)\n        if not validated:\n            logger.typewriter_log(\"FAILED FILE VALIDATION\", Fore.RED, message)\n            logger.double_check()\n            exit(1)\n\n        with open(prompt_settings_file, encoding=\"utf-8\") as file:\n            config_params = yaml.load(file, Loader=yaml.FullLoader)\n\n        self.general_guidelines = config_params.get(\"general_guidelines\", [])\n        #self.simple_patterns = config_params.get(\"simple_patterns\", [])\n"}
{"type": "source_file", "path": "autogpt/app/main.py", "content": "\"\"\"The application entry point.  Can be invoked by a CLI or any other front end application.\"\"\"\nimport time\nimport json\nimport os\n\nimport enum\nimport logging\nimport math\nimport signal\nimport sys\nfrom pathlib import Path\nfrom types import FrameType\nfrom typing import Optional\n\nfrom colorama import Fore, Style\n\nfrom autogpt.agents import Agent, AgentThoughts, CommandArgs, CommandName\nfrom autogpt.app.configurator import create_config\nfrom autogpt.app.setup import prompt_user\nfrom autogpt.app.spinner import Spinner\nfrom autogpt.app.utils import (\n    clean_input,\n    get_current_git_branch,\n    get_latest_bulletin,\n    get_legal_warning,\n    markdown_to_ansi_style,\n)\nfrom autogpt.commands import COMMAND_CATEGORIES\nfrom autogpt.config import AIConfig, Config, ConfigBuilder, check_openai_api_key\nfrom autogpt.llm.api_manager import ApiManager\nfrom autogpt.logs import logger\nfrom autogpt.memory.vector import get_memory\nfrom autogpt.models.command_registry import CommandRegistry\nfrom autogpt.plugins import scan_plugins\nfrom autogpt.prompts.prompt import DEFAULT_TRIGGERING_PROMPT\nfrom autogpt.speech import say_text\nfrom autogpt.workspace import Workspace\nfrom scripts.install_plugin_deps import install_plugin_dependencies\nfrom autogpt.commands.docker_helpers_static import stop_and_remove\n\n\ndef run_auto_gpt(\n    continuous: bool,\n    continuous_limit: int,\n    ai_settings: str,\n    prompt_settings: str,\n    skip_reprompt: bool,\n    speak: bool,\n    debug: bool,\n    gpt3only: bool,\n    gpt4only: bool,\n    memory_type: str,\n    browser_name: str,\n    allow_downloads: bool,\n    skip_news: bool,\n    working_directory: Path,\n    workspace_directory: str | Path,\n    install_plugin_deps: bool,\n    ai_name: Optional[str] = None,\n    ai_role: Optional[str] = None,\n    ai_goals: tuple[str] = tuple(),\n    experiment_file: str = None\n):\n    if not experiment_file:\n        raise ValueError(\"Cannot proceed without experiment file\")\n    # Configure logging before we do anything else.\n    logger.set_level(logging.DEBUG if debug else logging.INFO)\n\n    config = ConfigBuilder.build_config_from_env(workdir=working_directory)\n\n    # HACK: This is a hack to allow the config into the logger without having to pass it around everywhere\n    # or import it directly.\n    logger.config = config\n\n    # TODO: fill in llm values here\n    check_openai_api_key(config)\n\n    create_config(\n        config,\n        continuous,\n        continuous_limit,\n        ai_settings,\n        prompt_settings,\n        skip_reprompt,\n        speak,\n        debug,\n        gpt3only,\n        gpt4only,\n        memory_type,\n        browser_name,\n        allow_downloads,\n        skip_news,\n    )\n\n    if config.continuous_mode:\n        for line in get_legal_warning().split(\"\\n\"):\n            pass\n            #logger.warn(markdown_to_ansi_style(line), \"LEGAL:\", Fore.RED)\n\n    if not config.skip_news:\n        motd, is_new_motd = get_latest_bulletin()\n        if motd:\n            motd = markdown_to_ansi_style(motd)\n            for motd_line in motd.split(\"\\n\"):\n                logger.info(motd_line, \"NEWS:\", Fore.GREEN)\n            if is_new_motd and not config.chat_messages_enabled:\n                input(\n                    Fore.MAGENTA\n                    + Style.BRIGHT\n                    + \"NEWS: Bulletin was updated! Press Enter to continue...\"\n                    + Style.RESET_ALL\n                )\n\n        git_branch = get_current_git_branch()\n        if git_branch and git_branch != \"stable\":\n            logger.typewriter_log(\n                \"WARNING: \",\n                Fore.RED,\n                f\"You are running on `{git_branch}` branch \"\n                \"- this is not a supported branch.\",\n            )\n        if sys.version_info < (3, 10):\n            logger.typewriter_log(\n                \"WARNING: \",\n                Fore.RED,\n                \"You are running on an older version of Python. \"\n                \"Some people have observed problems with certain \"\n                \"parts of Auto-GPT with this version. \"\n                \"Please consider upgrading to Python 3.10 or higher.\",\n            )\n\n    if install_plugin_deps:\n        install_plugin_dependencies()\n\n    # TODO: have this directory live outside the repository (e.g. in a user's\n    #   home directory) and have it come in as a command line argument or part of\n    #   the env file.\n    config.workspace_path = Workspace.init_workspace_directory(\n        config, workspace_directory\n    )\n\n    # HACK: doing this here to collect some globals that depend on the workspace.\n    config.file_logger_path = Workspace.build_file_logger_path(config.workspace_path)\n\n    config.plugins = scan_plugins(config, config.debug_mode)\n\n    # Create a CommandRegistry instance and scan default folder\n    command_registry = CommandRegistry.with_command_modules(COMMAND_CATEGORIES, config)\n\n    ai_config = construct_main_ai_config(\n        config,\n        name=ai_name,\n        role=ai_role,\n        goals=ai_goals,\n    )\n    ai_config.command_registry = command_registry\n    # print(prompt)\n\n    # add chat plugins capable of report to logger\n    if config.chat_messages_enabled:\n        for plugin in config.plugins:\n            if hasattr(plugin, \"can_handle_report\") and plugin.can_handle_report():\n                logger.info(f\"Loaded plugin into logger: {plugin.__class__.__name__}\")\n                logger.chat_plugins.append(plugin)\n\n    # Initialize memory and make sure it is empty.\n    # this is particularly important for indexing and referencing pinecone memory\n    memory = get_memory(config)\n    memory.clear()\n    logger.typewriter_log(\n        \"Using memory of type:\", Fore.GREEN, f\"{memory.__class__.__name__}\"\n    )\n    logger.typewriter_log(\"Using Browser:\", Fore.GREEN, config.selenium_web_browser)\n\n    agent = Agent(\n        memory=memory,\n        command_registry=command_registry,\n        triggering_prompt=DEFAULT_TRIGGERING_PROMPT,\n        ai_config=ai_config,\n        config=config,\n        experiment_file = experiment_file\n    )\n\n    run_interaction_loop(agent)\n\n\ndef _get_cycle_budget(continuous_mode: bool, continuous_limit: int) -> int | None:\n    # Translate from the continuous_mode/continuous_limit config\n    # to a cycle_budget (maximum number of cycles to run without checking in with the\n    # user) and a count of cycles_remaining before we check in..\n    if continuous_mode:\n        cycle_budget = continuous_limit if continuous_limit else math.inf\n    else:\n        cycle_budget = 1\n\n    return cycle_budget\n\n\nclass UserFeedback(str, enum.Enum):\n    \"\"\"Enum for user feedback.\"\"\"\n\n    AUTHORIZE = \"GENERATE NEXT COMMAND JSON\"\n    EXIT = \"EXIT\"\n    TEXT = \"TEXT\"\n\n\ndef run_interaction_loop(\n    agent: Agent,\n) -> None:\n    \"\"\"Run the main interaction loop for the agent.\n\n    Args:\n        agent: The agent to run the interaction loop for.\n\n    Returns:\n        None\n    \"\"\"\n    # These contain both application config and agent config, so grab them here.\n    config = agent.config\n    ai_config = agent.ai_config\n    logger.debug(f\"{ai_config.ai_name} System Prompt: {str(agent.prompt_dictionary)}\")\n\n    cycle_budget = cycles_remaining = _get_cycle_budget(\n        config.continuous_mode, config.continuous_limit\n    )\n    spinner = Spinner(\"Thinking...\", plain_output=config.plain_output)\n\n    def graceful_agent_interrupt(signum: int, frame: Optional[FrameType]) -> None:\n        nonlocal cycle_budget, cycles_remaining, spinner\n        if cycles_remaining in [0, 1, math.inf]:\n            logger.typewriter_log(\n                \"Interrupt signal received. Stopping continuous command execution \"\n                \"immediately.\",\n                Fore.RED,\n            )\n            sys.exit()\n        else:\n            restart_spinner = spinner.running\n            if spinner.running:\n                spinner.stop()\n\n            logger.typewriter_log(\n                \"Interrupt signal received. Stopping continuous command execution.\",\n                Fore.RED,\n            )\n            cycles_remaining = 1\n            if restart_spinner:\n                spinner.start()\n\n    # Set up an interrupt signal for the agent.\n    signal.signal(signal.SIGINT, graceful_agent_interrupt)\n\n    #########################\n    # Application Main Loop #\n    #########################\n\n\n    ## create log file\n    project_path = agent.project_path\n    current_ts = time.time()\n    parsable_log_file = \"parsable_logs/{}\".format(project_path+str(current_ts)) + \".json\"\n    \n    with open(parsable_log_file, \"w\") as plf:\n        json.dump({\n            \"project\": project_path,\n            \"language\": agent.hyperparams[\"language\"],\n            \"ExecutionAgent_attempt\": []\n        }, plf)\n\n    while cycles_remaining > 0:\n        logger.debug(f\"Cycle budget: {cycle_budget}; remaining: {cycles_remaining}\")\n        #logger.info(\"XXXXXXXXXXXXXXXXXXX {} XXXXXXXXXXXXXXXXXXXX\".format(agent.cycle_type))\n        if agent.cycle_type != \"CMD\":\n            #agent.think()\n            agent.cycle_type = \"CMD\"\n            #logger.info(\" YYYYYYYYYYYYYYYYY SUMMARY CYCLE EXECUTED YYYYYYYYYYYYYYYYYYYY\")\n            logger.info(str(agent.summary_result))\n            continue\n        ########\n        # Plan #\n        ########\n        # Have the agent determine the next action to take.\n        with spinner:\n            command_name, command_args, assistant_reply_dict = agent.think()\n\n        ###############\n        # Update User #\n        ###############\n        # Print the assistant's thoughts and the next command to the user.\n        update_user(config, ai_config, command_name, command_args, assistant_reply_dict)\n\n        ##################\n        # Get user input #\n        ##################\n        if cycles_remaining == 1:  # Last cycle\n            if not agent.keep_container:\n                stop_and_remove(agent.container)\n                os.system(\"docker system prune -af\")\n            exit()\n            user_feedback, user_input, new_cycles_remaining = get_user_feedback(\n                config,\n                ai_config,\n            )\n\n            if user_feedback == UserFeedback.AUTHORIZE:\n                if new_cycles_remaining is not None:\n                    # Case 1: User is altering the cycle budget.\n                    if cycle_budget > 1:\n                        cycle_budget = new_cycles_remaining + 1\n                    # Case 2: User is running iteratively and\n                    #   has initiated a one-time continuous cycle\n                    cycles_remaining = new_cycles_remaining + 1\n                else:\n                    # Case 1: Continuous iteration was interrupted -> resume\n                    if cycle_budget > 1:\n                        logger.typewriter_log(\n                            \"RESUMING CONTINUOUS EXECUTION: \",\n                            Fore.MAGENTA,\n                            f\"The cycle budget is {cycle_budget}.\",\n                        )\n                    # Case 2: The agent used up its cycle budget -> reset\n                    cycles_remaining = cycle_budget + 1\n                logger.typewriter_log(\n                    \"-=-=-=-=-=-=-= COMMAND AUTHORISED BY USER -=-=-=-=-=-=-=\",\n                    Fore.MAGENTA,\n                    \"\",\n                )\n            elif user_feedback == UserFeedback.EXIT:\n                logger.typewriter_log(\"Exiting...\", Fore.YELLOW)\n                exit()\n            else:  # user_feedback == UserFeedback.TEXT\n                command_name = \"human_feedback\"\n        else:\n            user_input = None\n            # First log new-line so user can differentiate sections better in console\n            logger.typewriter_log(\"\\n\")\n            if cycles_remaining != math.inf:\n                # Print authorized commands left value\n                logger.typewriter_log(\n                    \"AUTHORISED COMMANDS LEFT: \", Fore.CYAN, f\"{cycles_remaining}\"\n                )\n\n        ###################\n        # Execute Command #\n        ###################\n        # Decrement the cycle counter first to reduce the likelihood of a SIGINT\n        # happening during command execution, setting the cycles remaining to 1,\n        # and then having the decrement set it to 0, exiting the application.\n        agent.left_commands = cycles_remaining\n        if agent.max_budget == -1:\n            agent.max_budget = cycles_remaining\n        if command_name != \"human_feedback\":\n            cycles_remaining -= 1\n        if agent.cycle_type == \"CMD\":\n            if command_name == \"write_to_file\":\n                simple_name = command_args[\"filename\"].split(\"/\")[-1] if \"/\" in command_args[\"filename\"] else command_args[\"filename\"]\n                # todo save written files here\n                if not os.path.exists(\"experimental_setups/{}/files/{}\".format(agent.exp_number, agent.project_path)):\n                    os.system(\"mkdir experimental_setups/{}/files/{}\".format(agent.exp_number, agent.project_path))\n\n                files_list = os.listdir(\"experimental_setups/{}/files/{}\".format(agent.exp_number, agent.project_path))\n\n                with open(\"experimental_setups/{}/files/{}/{}\".format(agent.exp_number, agent.project_path, simple_name+\"_{}\".format(len(files_list))), \"w\") as wrf:\n                    wrf.write(command_args[\"text\"])\n\n            result = agent.execute(command_name, command_args, user_input)\n\n            with open(parsable_log_file) as plf:\n                parsable_content = json.load(plf)\n\n            parsable_content[\"ExecutionAgent_attempt\"].append(\n                {\n                    \"command_name\": command_name,\n                    \"command_args\": command_args,\n                    \"command_result\": result,\n                    \"prompt_content\": agent.prompt_text\n                }\n            )\n\n            with open(parsable_log_file, \"w\") as plf:\n                json.dump(parsable_content, plf)\n\n            if result is not None:\n                logger.typewriter_log(\"SYSTEM: \", Fore.YELLOW, result)\n                agent.cycle_type = \"SUMMARY\"\n                agent.think()\n                agent.history = agent.history[:-2]\n                \n                agent.commands_and_summary.append((\"Call to tool {} with arguments {}\".format(command_name, command_args), agent.summary_result))\n                with open(parsable_log_file) as plf:\n                    parsable_content = json.load(plf)\n\n                parsable_content[\"ExecutionAgent_attempt\"][-1][\"result_summary\"] = agent.summary_result\n\n                with open(parsable_log_file, \"w\") as plf:\n                    json.dump(parsable_content, plf)\n\n                agent.cycle_type = \"CMD\"\n                parsing_tests = parse_test_results(str(result))\n                if parsing_tests != \"No test results found in log file.\":\n                    agent.tests_executed = True\n            else:\n                logger.typewriter_log(\"SYSTEM: \", Fore.YELLOW, \"Unable to execute command\")\n\n            if not os.path.exists(\"experimental_setups/{}/saved_contexts/{}\".format(agent.exp_number, agent.project_path)):\n                os.system(\"mkdir experimental_setups/{}/saved_contexts/{}\".format(agent.exp_number, agent.project_path))\n            agent.save_to_file(\"experimental_setups/{}/saved_contexts/{}/cycle_{}\".format(agent.exp_number, agent.project_path, cycle_budget - cycles_remaining))\n\nimport re\n\ndef parse_test_results(log_content):\n\n    # Define patterns to match different parts of the log\n    test_case_pattern = re.compile(r'Test Case: (.+)')\n    result_pattern = re.compile(r'Result: (.+)')\n    error_pattern = re.compile(r'Error: (.+)')\n    exception_pattern = re.compile(r'Exception: (.+)')\n\n    # Initialize variables to store results\n    test_results = {}\n    errors = []\n    exceptions = []\n\n    # Parse log content\n    lines = log_content.split('\\n')\n    for line in lines:\n        test_case_match = test_case_pattern.match(line)\n        result_match = result_pattern.match(line)\n        error_match = error_pattern.match(line)\n        exception_match = exception_pattern.match(line)\n\n        if test_case_match:\n            test_case = test_case_match.group(1)\n        else:\n            test_case = None\n\n        if test_case_match:\n            test_case = test_case_match.group(1)\n            if test_case not in test_results:\n                test_results[test_case] = None\n        elif result_match:\n            result = result_match.group(1)\n            if test_case:\n                test_results[test_case] = result\n        elif error_match:\n            error = error_match.group(1)\n            errors.append(error)\n        elif exception_match:\n            exception = exception_match.group(1)\n            exceptions.append(exception)\n\n    # Check if any unexpected output exists\n    if not test_results and not errors and not exceptions:\n        return \"No test results found in log file.\"\n\n    # Construct summary\n    summary = \"\"\n    if test_results:\n        summary += \"Test Results:\\n\"\n        for test_case, result in test_results.items():\n            summary += f\"- {test_case}: {result}\\n\"\n    if errors:\n        summary += \"Errors:\\n\"\n        for error in errors:\n            summary += f\"- {error}\\n\"\n    if exceptions:\n        summary += \"Exceptions:\\n\"\n        for exception in exceptions:\n            summary += f\"- {exception}\\n\"\n\n    return summary\n\n\ndef update_user(\n    config: Config,\n    ai_config: AIConfig,\n    command_name: CommandName | None,\n    command_args: CommandArgs | None,\n    assistant_reply_dict: AgentThoughts,\n) -> None:\n    \"\"\"Prints the assistant's thoughts and the next command to the user.\n\n    Args:\n        config: The program's configuration.\n        ai_config: The AI's configuration.\n        command_name: The name of the command to execute.\n        command_args: The arguments for the command.\n        assistant_reply_dict: The assistant's reply.\n    \"\"\"\n\n    print_assistant_thoughts(ai_config.ai_name, assistant_reply_dict, config)\n\n    if command_name is not None:\n        if command_name.lower().startswith(\"error\"):\n            logger.typewriter_log(\n                \"ERROR: \",\n                Fore.RED,\n                f\"The Agent failed to select an action. \"\n                f\"Error message: {command_name}\",\n            )\n        else:\n            if config.speak_mode:\n                say_text(f\"I want to execute {command_name}\", config)\n\n            # First log new-line so user can differentiate sections better in console\n            logger.typewriter_log(\"\\n\")\n            logger.typewriter_log(\n                \"NEXT ACTION: \",\n                Fore.CYAN,\n                f\"COMMAND = {Fore.CYAN}{remove_ansi_escape(command_name)}{Style.RESET_ALL}  \"\n                f\"ARGUMENTS = {Fore.CYAN}{command_args}{Style.RESET_ALL}\",\n            )\n    else:\n        logger.typewriter_log(\n            \"NO ACTION SELECTED: \",\n            Fore.RED,\n            f\"The Agent failed to select an action.\",\n        )\n\n\ndef get_user_feedback(\n    config: Config,\n    ai_config: AIConfig,\n) -> tuple[UserFeedback, str, int | None]:\n    \"\"\"Gets the user's feedback on the assistant's reply.\n\n    Args:\n        config: The program's configuration.\n        ai_config: The AI's configuration.\n\n    Returns:\n        A tuple of the user's feedback, the user's input, and the number of\n        cycles remaining if the user has initiated a continuous cycle.\n    \"\"\"\n    # ### GET USER AUTHORIZATION TO EXECUTE COMMAND ###\n    # Get key press: Prompt the user to press enter to continue or escape\n    # to exit\n    logger.info(\n        f\"Enter '{config.authorise_key}' to authorise command, \"\n        f\"'{config.authorise_key} -N' to run N continuous commands, \"\n        f\"'{config.exit_key}' to exit program, or enter feedback for \"\n        f\"{ai_config.ai_name}...\"\n    )\n\n    user_feedback = None\n    user_input = \"\"\n    new_cycles_remaining = None\n\n    while user_feedback is None:\n        # Get input from user\n        if config.chat_messages_enabled:\n            console_input = clean_input(config, \"Waiting for your response...\")\n        else:\n            console_input = clean_input(\n                config, Fore.MAGENTA + \"Input:\" + Style.RESET_ALL\n            )\n\n        # Parse user input\n        if console_input.lower().strip() == config.authorise_key:\n            user_feedback = UserFeedback.AUTHORIZE\n        elif console_input.lower().strip() == \"\":\n            logger.warn(\"Invalid input format.\")\n        elif console_input.lower().startswith(f\"{config.authorise_key} -\"):\n            try:\n                user_feedback = UserFeedback.AUTHORIZE\n                new_cycles_remaining = abs(int(console_input.split(\" \")[1]))\n            except ValueError:\n                logger.warn(\n                    f\"Invalid input format. \"\n                    f\"Please enter '{config.authorise_key} -N'\"\n                    \" where N is the number of continuous tasks.\"\n                )\n        elif console_input.lower() in [config.exit_key, \"exit\"]:\n            user_feedback = UserFeedback.EXIT\n        else:\n            user_feedback = UserFeedback.TEXT\n            user_input = console_input\n\n    return user_feedback, user_input, new_cycles_remaining\n\n\ndef construct_main_ai_config(\n    config: Config,\n    name: Optional[str] = None,\n    role: Optional[str] = None,\n    goals: tuple[str] = tuple(),\n) -> AIConfig:\n    \"\"\"Construct the prompt for the AI to respond to\n\n    Returns:\n        str: The prompt string\n    \"\"\"\n    ai_config = AIConfig.load(config.workdir / config.ai_settings_file)\n\n    # Apply overrides\n    if name:\n        ai_config.ai_name = name\n    if role:\n        ai_config.ai_role = role\n    if goals:\n        ai_config.ai_goals = list(goals)\n\n    if (\n        all([name, role, goals])\n        or config.skip_reprompt\n        and all([ai_config.ai_name, ai_config.ai_role, ai_config.ai_goals])\n    ):\n        logger.typewriter_log(\"Name :\", Fore.GREEN, ai_config.ai_name)\n        logger.typewriter_log(\"Role :\", Fore.GREEN, ai_config.ai_role)\n        logger.typewriter_log(\"Goals:\", Fore.GREEN, f\"{ai_config.ai_goals}\")\n        logger.typewriter_log(\n            \"API Budget:\",\n            Fore.GREEN,\n            \"infinite\" if ai_config.api_budget <= 0 else f\"${ai_config.api_budget}\",\n        )\n    elif all([ai_config.ai_name, ai_config.ai_role, ai_config.ai_goals]):\n        logger.typewriter_log(\n            \"Welcome back! \",\n            Fore.GREEN,\n            f\"Would you like me to return to being {ai_config.ai_name}?\",\n            speak_text=True,\n        )\n        should_continue = clean_input(\n            config,\n            f\"\"\"Continue with the last settings?\nName:  {ai_config.ai_name}\nRole:  {ai_config.ai_role}\nGoals: {ai_config.ai_goals}\nAPI Budget: {\"infinite\" if ai_config.api_budget <= 0 else f\"${ai_config.api_budget}\"}\nContinue ({config.authorise_key}/{config.exit_key}): \"\"\",\n        )\n        if should_continue.lower() == config.exit_key:\n            ai_config = AIConfig()\n\n    if any([not ai_config.ai_name, not ai_config.ai_role, not ai_config.ai_goals]):\n        ai_config = prompt_user(config)\n        ai_config.save(config.workdir / config.ai_settings_file)\n\n    if config.restrict_to_workspace:\n        logger.typewriter_log(\n            \"NOTE:All files/directories created by this agent can be found inside its workspace at:\",\n            Fore.YELLOW,\n            f\"{config.workspace_path}\",\n        )\n    # set the total api budget\n    api_manager = ApiManager()\n    api_manager.set_total_budget(ai_config.api_budget)\n\n    # Agent Created, print message\n    logger.typewriter_log(\n        ai_config.ai_name,\n        Fore.LIGHTBLUE_EX,\n        \"has been created with the following details:\",\n        speak_text=True,\n    )\n\n    # Print the ai_config details\n    # Name\n    logger.typewriter_log(\"Name:\", Fore.GREEN, ai_config.ai_name, speak_text=False)\n    # Role\n    logger.typewriter_log(\"Role:\", Fore.GREEN, ai_config.ai_role, speak_text=False)\n    # Goals\n    logger.typewriter_log(\"Goals:\", Fore.GREEN, \"\", speak_text=False)\n    for goal in ai_config.ai_goals:\n        logger.typewriter_log(\"-\", Fore.GREEN, goal, speak_text=False)\n\n    return ai_config\n\n\ndef print_assistant_thoughts(\n    ai_name: str,\n    assistant_reply_json_valid: dict,\n    config: Config,\n) -> None:\n    from autogpt.speech import say_text\n\n    assistant_thoughts_reasoning = None\n    assistant_thoughts_plan = None\n    assistant_thoughts_speak = None\n    assistant_thoughts_criticism = None\n\n    assistant_thoughts = assistant_reply_json_valid.get(\"thoughts\", {})\n    #assistant_thoughts_text = remove_ansi_escape(assistant_thoughts.get(\"text\", \"\"))\n    if assistant_thoughts:\n        \"\"\"assistant_thoughts_reasoning = remove_ansi_escape(\n            assistant_thoughts.get(\"reasoning\", \"\")\n        )\n        assistant_thoughts_plan = remove_ansi_escape(assistant_thoughts.get(\"plan\", \"\"))\n        assistant_thoughts_criticism = remove_ansi_escape(\n            assistant_thoughts.get(\"criticism\", \"\")\n        )\n        assistant_thoughts_speak = remove_ansi_escape(\n            assistant_thoughts.get(\"speak\", \"\")\n        )\"\"\"\n    logger.typewriter_log(\n        f\"{ai_name.upper()} THOUGHTS:\", Fore.YELLOW, str(assistant_thoughts)\n    )\n    #logger.typewriter_log(\"REASONING:\", Fore.YELLOW, str(assistant_thoughts_reasoning))\n    \"\"\"\n    if assistant_thoughts_plan:\n        logger.typewriter_log(\"PLAN:\", Fore.YELLOW, \"\")\n        # If it's a list, join it into a string\n        if isinstance(assistant_thoughts_plan, list):\n            assistant_thoughts_plan = \"\\n\".join(assistant_thoughts_plan)\n        elif isinstance(assistant_thoughts_plan, dict):\n            assistant_thoughts_plan = str(assistant_thoughts_plan)\n\n        # Split the input_string using the newline character and dashes\n        lines = assistant_thoughts_plan.split(\"\\n\")\n        for line in lines:\n            line = line.lstrip(\"- \")\n            logger.typewriter_log(\"- \", Fore.GREEN, line.strip())\n    logger.typewriter_log(\"CRITICISM:\", Fore.YELLOW, f\"{assistant_thoughts_criticism}\")\n    # Speak the assistant's thoughts\n    if assistant_thoughts_speak:\n        if config.speak_mode:\n            say_text(assistant_thoughts_speak, config)\n        else:\n            logger.typewriter_log(\"SPEAK:\", Fore.YELLOW, f\"{assistant_thoughts_speak}\")\n    \"\"\"\ndef remove_ansi_escape(s: str) -> str:\n    return s.replace(\"\\x1B\", \"\")\n"}
{"type": "source_file", "path": "autogpt/commands/web_selenium.py", "content": "\"\"\"Commands for browsing a website\"\"\"\n\nfrom __future__ import annotations\n\nfrom autogpt.llm.utils.token_counter import count_string_tokens\n\nCOMMAND_CATEGORY = \"web_browse\"\nCOMMAND_CATEGORY_TITLE = \"Web Browsing\"\n\nimport logging\nfrom pathlib import Path\nfrom sys import platform\nfrom typing import Optional\n\nfrom bs4 import BeautifulSoup\nfrom selenium.common.exceptions import WebDriverException\nfrom selenium.webdriver.chrome.options import Options as ChromeOptions\nfrom selenium.webdriver.chrome.service import Service as ChromeDriverService\nfrom selenium.webdriver.chrome.webdriver import WebDriver as ChromeDriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.options import ArgOptions as BrowserOptions\nfrom selenium.webdriver.edge.options import Options as EdgeOptions\nfrom selenium.webdriver.edge.service import Service as EdgeDriverService\nfrom selenium.webdriver.edge.webdriver import WebDriver as EdgeDriver\nfrom selenium.webdriver.firefox.options import Options as FirefoxOptions\nfrom selenium.webdriver.firefox.service import Service as GeckoDriverService\nfrom selenium.webdriver.firefox.webdriver import WebDriver as FirefoxDriver\nfrom selenium.webdriver.remote.webdriver import WebDriver\nfrom selenium.webdriver.safari.options import Options as SafariOptions\nfrom selenium.webdriver.safari.webdriver import WebDriver as SafariDriver\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.support.wait import WebDriverWait\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom webdriver_manager.firefox import GeckoDriverManager\nfrom webdriver_manager.microsoft import EdgeChromiumDriverManager as EdgeDriverManager\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.logs import logger\nfrom autogpt.memory.vector import MemoryItem, get_memory\nfrom autogpt.processing.html import extract_hyperlinks, format_hyperlinks\nfrom autogpt.url_utils.validators import validate_url\n\nFILE_DIR = Path(__file__).parent.parent\nTOKENS_TO_TRIGGER_SUMMARY = 50\nLINKS_TO_RETURN = 20\n\n\n@command(\n    \"browse_website\",\n    \"Browses a Website\",\n    {\n        \"url\": {\"type\": \"string\", \"description\": \"The URL to visit\", \"required\": True},\n        \"question\": {\n            \"type\": \"string\",\n            \"description\": \"What you want to find on the website\",\n            \"required\": True,\n        },\n    },\n)\n@validate_url\ndef browse_website(url: str, question: str, agent: Agent) -> str:\n    \"\"\"Browse a website and return the answer and links to the user\n\n    Args:\n        url (str): The url of the website to browse\n        question (str): The question asked by the user\n\n    Returns:\n        str: The answer and links to the user and the webdriver\n    \"\"\"\n    driver = None\n    try:\n        driver, text = scrape_text_with_selenium(url, agent)\n        add_header(driver)\n        if TOKENS_TO_TRIGGER_SUMMARY < count_string_tokens(text, agent.llm.name):\n            text = summarize_memorize_webpage(url, text + \"\\n Return your answer in a json format.\", question, agent, driver)\n\n        links = scrape_links_with_selenium(driver, url)\n\n        # Limit links to LINKS_TO_RETURN\n        if len(links) > LINKS_TO_RETURN:\n            links = links[:LINKS_TO_RETURN]\n\n        return f\"Answer gathered from website: {text}\\n\\nLinks: {links}\"\n    except WebDriverException as e:\n        # These errors are often quite long and include lots of context.\n        # Just grab the first line.\n        msg = e.msg.split(\"\\n\")[0]\n        return f\"Error: {msg}\"\n    finally:\n        if driver:\n            close_browser(driver)\n\n\ndef scrape_text_with_selenium(url: str, agent: Agent) -> tuple[WebDriver, str]:\n    \"\"\"Scrape text from a website using selenium\n\n    Args:\n        url (str): The url of the website to scrape\n\n    Returns:\n        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\n    \"\"\"\n    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\n\n    options_available: dict[str, BrowserOptions] = {\n        \"chrome\": ChromeOptions,\n        \"edge\": EdgeOptions,\n        \"firefox\": FirefoxOptions,\n        \"safari\": SafariOptions,\n    }\n\n    options: BrowserOptions = options_available[agent.config.selenium_web_browser]()\n    options.add_argument(\n        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\n    )\n\n    if agent.config.selenium_web_browser == \"firefox\":\n        if agent.config.selenium_headless:\n            options.headless = True\n            options.add_argument(\"--disable-gpu\")\n        driver = FirefoxDriver(\n            service=GeckoDriverService(GeckoDriverManager().install()), options=options\n        )\n    elif agent.config.selenium_web_browser == \"edge\":\n        driver = EdgeDriver(\n            service=EdgeDriverService(EdgeDriverManager().install()), options=options\n        )\n    elif agent.config.selenium_web_browser == \"safari\":\n        # Requires a bit more setup on the users end\n        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\n        driver = SafariDriver(options=options)\n    else:\n        if platform == \"linux\" or platform == \"linux2\":\n            options.add_argument(\"--disable-dev-shm-usage\")\n            options.add_argument(\"--remote-debugging-port=9222\")\n\n        options.add_argument(\"--no-sandbox\")\n        if agent.config.selenium_headless:\n            options.add_argument(\"--headless=new\")\n            options.add_argument(\"--disable-gpu\")\n\n        chromium_driver_path = Path(\"/usr/bin/chromedriver\")\n\n        driver = ChromeDriver(\n            service=ChromeDriverService(str(chromium_driver_path))\n            if chromium_driver_path.exists()\n            else ChromeDriverService(ChromeDriverManager().install()),\n            options=options,\n        )\n    driver.get(url)\n\n    WebDriverWait(driver, 10).until(\n        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n    )\n\n    # Get the HTML content directly from the browser's DOM\n    page_source = driver.execute_script(\"return document.body.outerHTML;\")\n    soup = BeautifulSoup(page_source, \"html.parser\")\n\n    for script in soup([\"script\", \"style\"]):\n        script.extract()\n\n    text = soup.get_text()\n    lines = (line.strip() for line in text.splitlines())\n    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n    text = \"\\n\".join(chunk for chunk in chunks if chunk)\n    return driver, text\n\n\ndef scrape_links_with_selenium(driver: WebDriver, url: str) -> list[str]:\n    \"\"\"Scrape links from a website using selenium\n\n    Args:\n        driver (WebDriver): The webdriver to use to scrape the links\n\n    Returns:\n        List[str]: The links scraped from the website\n    \"\"\"\n    page_source = driver.page_source\n    soup = BeautifulSoup(page_source, \"html.parser\")\n\n    for script in soup([\"script\", \"style\"]):\n        script.extract()\n\n    hyperlinks = extract_hyperlinks(soup, url)\n\n    return format_hyperlinks(hyperlinks)\n\n\ndef close_browser(driver: WebDriver) -> None:\n    \"\"\"Close the browser\n\n    Args:\n        driver (WebDriver): The webdriver to close\n\n    Returns:\n        None\n    \"\"\"\n    driver.quit()\n\n\ndef add_header(driver: WebDriver) -> None:\n    \"\"\"Add a header to the website\n\n    Args:\n        driver (WebDriver): The webdriver to use to add the header\n\n    Returns:\n        None\n    \"\"\"\n    try:\n        with open(f\"{FILE_DIR}/js/overlay.js\", \"r\") as overlay_file:\n            overlay_script = overlay_file.read()\n        driver.execute_script(overlay_script)\n    except Exception as e:\n        print(f\"Error executing overlay.js: {e}\")\n\n\ndef summarize_memorize_webpage(\n    url: str,\n    text: str,\n    question: str,\n    agent: Agent,\n    driver: Optional[WebDriver] = None,\n) -> str:\n    \"\"\"Summarize text using the OpenAI API\n\n    Args:\n        url (str): The url of the text\n        text (str): The text to summarize\n        question (str): The question to ask the model\n        driver (WebDriver): The webdriver to use to scroll the page\n\n    Returns:\n        str: The summary of the text\n    \"\"\"\n    if not text:\n        return \"Error: No text to summarize\"\n\n    text_length = len(text)\n    logger.info(f\"Text length: {text_length} characters\")\n\n    memory = get_memory(agent.config)\n\n    new_memory = MemoryItem.from_webpage(text, url, agent.config, question=question)\n    memory.add(new_memory)\n    return new_memory.summary\n"}
{"type": "source_file", "path": "autogpt/commands/file_operations.py", "content": "\"\"\"Commands to perform operations on files\"\"\"\n\nfrom __future__ import annotations\n\nCOMMAND_CATEGORY = \"file_operations\"\nCOMMAND_CATEGORY_TITLE = \"File Operations\"\n\nimport contextlib\nimport hashlib\nimport os\nimport os.path\nfrom pathlib import Path\nfrom typing import Generator, Literal\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.logs import logger\nfrom autogpt.memory.vector import MemoryItem, VectorMemory\nfrom autogpt.commands.docker_helpers_static import build_image, start_container, execute_command_in_container, write_string_to_file, read_file_from_container, check_image_exists\nfrom .decorators import sanitize_path_arg\nfrom .file_operations_utils import read_textual_file\n\nimport xml.etree.ElementTree as ET\nimport yaml\n\ndef xml_to_dict(element):\n    \"\"\" Recursively converts XML elements to a dictionary. \"\"\"\n    if len(element) == 0:\n        return element.text\n    return {\n        element.tag: {\n            child.tag: xml_to_dict(child) for child in element\n        }\n    }\n\ndef convert_xml_to_yaml(xml_file):\n    # Parse the XML file\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    \n    # Convert XML to a dictionary\n    xml_dict = xml_to_dict(root)\n    \n    # Convert the dictionary to a YAML string\n    yaml_str = yaml.dump(xml_dict, default_flow_style=False)\n    \n    return yaml_str\n\nOperation = Literal[\"write\", \"append\", \"delete\"]\n\n\ndef text_checksum(text: str) -> str:\n    \"\"\"Get the hex checksum for the given text.\"\"\"\n    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n\n\ndef operations_from_log(\n    log_path: str | Path,\n) -> Generator[tuple[Operation, str, str | None], None, None]:\n    \"\"\"Parse the file operations log and return a tuple containing the log entries\"\"\"\n    try:\n        log = open(log_path, \"r\", encoding=\"utf-8\")\n    except FileNotFoundError:\n        return\n\n    for line in log:\n        line = line.replace(\"File Operation Logger\", \"\").strip()\n        if not line:\n            continue\n        operation, tail = line.split(\": \", maxsplit=1)\n        operation = operation.strip()\n        if operation in (\"write\", \"append\"):\n            try:\n                path, checksum = (x.strip() for x in tail.rsplit(\" #\", maxsplit=1))\n            except ValueError:\n                logger.warn(f\"File log entry lacks checksum: '{line}'\")\n                path, checksum = tail.strip(), None\n            yield (operation, path, checksum)\n        elif operation == \"delete\":\n            yield (operation, tail.strip(), None)\n\n    log.close()\n\n\ndef file_operations_state(log_path: str | Path) -> dict[str, str]:\n    \"\"\"Iterates over the operations log and returns the expected state.\n\n    Parses a log file at config.file_logger_path to construct a dictionary that maps\n    each file path written or appended to its checksum. Deleted files are removed\n    from the dictionary.\n\n    Returns:\n        A dictionary mapping file paths to their checksums.\n\n    Raises:\n        FileNotFoundError: If config.file_logger_path is not found.\n        ValueError: If the log file content is not in the expected format.\n    \"\"\"\n    state = {}\n    for operation, path, checksum in operations_from_log(log_path):\n        if operation in (\"write\", \"append\"):\n            state[path] = checksum\n        elif operation == \"delete\":\n            del state[path]\n    return state\n\n\n@sanitize_path_arg(\"filename\")\ndef is_duplicate_operation(\n    operation: Operation, filename: str, agent: Agent, checksum: str | None = None\n) -> bool:\n    \"\"\"Check if the operation has already been performed\n\n    Args:\n        operation: The operation to check for\n        filename: The name of the file to check for\n        agent: The agent\n        checksum: The checksum of the contents to be written\n\n    Returns:\n        True if the operation has already been performed on the file\n    \"\"\"\n    # Make the filename into a relative path if possible\n    with contextlib.suppress(ValueError):\n        filename = str(Path(filename).relative_to(agent.workspace.root))\n\n    state = file_operations_state(agent.config.file_logger_path)\n    if operation == \"delete\" and filename not in state:\n        return True\n    if operation == \"write\" and state.get(filename) == checksum:\n        return True\n    return False\n\n\n@sanitize_path_arg(\"filename\")\ndef log_operation(\n    operation: Operation, filename: str, agent: Agent, checksum: str | None = None\n) -> None:\n    \"\"\"Log the file operation to the file_logger.txt\n\n    Args:\n        operation: The operation to log\n        filename: The name of the file the operation was performed on\n        checksum: The checksum of the contents to be written\n    \"\"\"\n    # Make the filename into a relative path if possible\n    with contextlib.suppress(ValueError):\n        filename = str(Path(filename).relative_to(agent.workspace.root))\n\n    log_entry = f\"{operation}: {filename}\"\n    if checksum is not None:\n        log_entry += f\" #{checksum}\"\n    logger.debug(f\"Logging file operation: {log_entry}\")\n    append_to_file(\n        agent.config.file_logger_path, f\"{log_entry}\\n\", agent, should_log=False\n    )\n\n\n\"\"\"@command(\n    \"read_file\",\n    \"Read an existing file\",\n    {\n        \"file_path\": {\n            \"type\": \"string\",\n            \"description\": \"The path of the file to read\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\n#@sanitize_path_arg(\"file_path\")\ndef read_file(file_path: str, agent: Agent) -> str:\n    \"\"\"Read a file and return the contents\n\n    Args:\n        filename (str): The name of the file to read\n\n    Returns:\n        str: The contents of the file\n    \"\"\"\n    if not agent.container:\n        print(\"READING FILE FROM OUTSIDE CONTAINER CRAZZZZZZZZZZZZZZZZZZZZZY\")\n        try:\n            workspace = agent.workspace_path\n            project_path = agent.project_path\n            if file_path.lower().endswith(\"xml\"):\n                yaml_content = convert_xml_to_yaml(os.path.join(workspace, project_path, file_path))\n                return \"The xml file was converted to yaml format for better readability:\\n\"+ yaml_content\n        \n            content = read_textual_file(os.path.join(workspace, project_path, file_path), logger)\n            return content\n            # TODO: invalidate/update memory when file is edited\n            file_memory = MemoryItem.from_text_file(content, file_path, agent.config)\n            if len(file_memory.chunks) > 1:\n                return file_memory.summary\n\n            return content\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n    else:\n        return read_file_from_container(agent.container, os.path.join(\"/app\", agent.project_path, file_path.split(\"/\")[-1]))\n\n\ndef ingest_file(\n    filename: str,\n    memory: VectorMemory,\n) -> None:\n    \"\"\"\n    Ingest a file by reading its content, splitting it into chunks with a specified\n    maximum length and overlap, and adding the chunks to the memory storage.\n\n    Args:\n        filename: The name of the file to ingest\n        memory: An object with an add() method to store the chunks in memory\n    \"\"\"\n    try:\n        logger.info(f\"Ingesting file {filename}\")\n        content = read_file(filename)\n\n        # TODO: differentiate between different types of files\n        file_memory = MemoryItem.from_text_file(content, filename)\n        logger.debug(f\"Created memory: {file_memory.dump(True)}\")\n        memory.add(file_memory)\n\n        logger.info(f\"Ingested {len(file_memory.e_chunks)} chunks from {filename}\")\n    except Exception as err:\n        logger.warn(f\"Error while ingesting file '{filename}': {err}\")\n\ndef update_dockerfile_content(dockerfile_content: str) -> str:\n    lines = dockerfile_content.splitlines()\n    modified_lines = []\n    in_run_command = False\n\n    for line in lines:\n        stripped_line = line.strip()\n        \n        # Check if the line starts with 'RUN' and is not a continuation of a previous 'RUN' command\n        if stripped_line.startswith(\"RUN \") and not in_run_command:\n            in_run_command = True\n            if stripped_line.endswith(\"\\\\\"):\n                modified_lines.append(line.rstrip())\n            else:\n                # Add || exit 0 with an error message\n                modified_lines.append(line.rstrip() + \" || { echo \\\"Command failed with exit code $?\\\"; exit 0; }\")\n                in_run_command = False\n        elif in_run_command:\n            # Check if the line ends with '\\', which indicates continuation\n            if stripped_line.endswith(\"\\\\\"):\n                modified_lines.append(line)\n            else:\n                in_run_command = False\n                # Add || exit 0 with an error message\n                modified_lines.append(line.rstrip() + \" || { echo \\\"Command failed with exit code $?\\\"; exit 0; }\")\n        else:\n            modified_lines.append(line)\n\n    return \"\\n\".join(modified_lines)\n\n@command(\n    \"write_to_file\",\n    \"Writes to a file\",\n    {\n        \"filename\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the file to write to\",\n            \"required\": True,\n        },\n        \"text\": {\n            \"type\": \"string\",\n            \"description\": \"The text to write to the file\",\n            \"required\": True,\n        },\n    },\n    aliases=[\"write_file\", \"create_file\"],\n)\n#@sanitize_path_arg(\"filename\")\ndef write_to_file(filename: str, text: str, agent: Agent) -> str:\n    \"\"\"Write text to a file\n\n    Args:\n        filename (str): The name of the file to write to\n        text (str): The text to write to the file\n\n    Returns:\n        str: A message indicating success or failure\n    \"\"\"\n    if \"COPY\" in text:\n        return \"The usage of command 'COPY' is prohibited inside the Dockerfile script. You should just clone the repository inside the docker images and all the files of that repository would be there. No need to copy.\"\n    #checksum = text_checksum(text)\n    #if is_duplicate_operation(\"write\", filename, agent, checksum):\n    #    return \"Error: File has already been updated.\"\n    agent.written_files.append((filename, text))\n    if not agent.container:\n        try:\n            #directory = os.path.dirname(filename)\n            #os.makedirs(directory, exist_ok=True)\n            workspace = agent.workspace_path\n            print(\"AGENT RPOJECT PATH:::::::\", agent.project_path)\n            if (agent.project_path + \"/\") in filename:\n                print(\"PATH TAKEN FROM HERE 1111\")\n                full_path = os.path.join(workspace, filename)\n            else:\n                full_path = os.path.join(workspace, agent.project_path, filename)\n                #print(\"PATH TAKEN FROM HERE 2222\")\n                #print(\"FULL PATH++++++\", full_path)\n                #print(workspace)\n                #print(agent.project_path)\n                #print(filename)\n            #if \"dockerfile\" in filename.lower():\n            #    text = update_dockerfile_content(text)\n\n            with open(full_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(text)\n            \n            log_operation(\"write\", filename, agent, \"STATIC CHECK SUM WAS WRITTEN FROM file_operations:write_to_file\")\n            \n            print(\"DOCKER FILE WAS WRITTEN TO ------ \", full_path)\n            \n            if \"dockerfile\" in filename.lower():\n                image_log = \"IMAGE ALREADY EXISTS\"\n                if not check_image_exists(agent.project_path.lower()+\"_image:ExecutionAgent\"):\n                    image_log = build_image(os.path.join(workspace, agent.project_path), agent.project_path.lower()+\"_image:ExecutionAgent\")\n                    if image_log.startswith(\"An error occurred while building the Docker image\"):\n                        return \"The following error occured while trying to build a docker image from the docker script you provide (if the error persists, try to simplify your docker script), please fix it:\\n\" + image_log\n                container = start_container(agent.project_path.lower()+\"_image:ExecutionAgent\")\n                if container is not None:\n                    agent.container = container\n                    cwd = execute_command_in_container(container, \"pwd\")\n                    return image_log + \"\\nContainer launched successfuly\\n\" + \"\\nThe current working directory within the container is: {}\".format(cwd)\n                else:\n                    return str(image_log) + \"\\n\" + str(container)\n            return \"File written to successfully.\"\n        except Exception as err:\n            return f\"Error: {err}\"\n    else:\n        print(\"I am HERE TRYING TO WRITE FILE IN CONTAINER 191919191919191919919191919119999911111111111111119\")\n        print(\"PROJECT_PATH:\", agent.project_path)\n        print(\"FILENAME:\", filename)\n        if \"dockerfile\" in filename.lower():\n            return \"You cannot create another docker image, you already have access to a running container. If a pacakge is missing or error happened during installation, you can debug and fix the problem inside the running container by interacting with the linux_terminal tool.\"\n        write_result = str(write_string_to_file(agent.container, text, os.path.join(\"/app\", agent.project_path, filename.split(\"/\")[-1])))\n        if write_result==\"None\":\n            if \"setup\" in filename.lower() or \"install\" in filename.lower() or \".sh\" in filename.lower():\n                return \"installation script was written successfully, you should not run this script. If test cases were not yet run, you should do that with the help of linux_terminal. If you arleady run test cases successfully, you are done with the task.\"\n            else:\n                return \"File written successfully.\"\n        else:\n            return write_result\n@sanitize_path_arg(\"filename\")\ndef append_to_file(\n    filename: str, text: str, agent: Agent, should_log: bool = True\n) -> str:\n    \"\"\"Append text to a file\n\n    Args:\n        filename (str): The name of the file to append to\n        text (str): The text to append to the file\n        should_log (bool): Should log output\n\n    Returns:\n        str: A message indicating success or failure\n    \"\"\"\n    try:\n        directory = os.path.dirname(filename)\n        os.makedirs(directory, exist_ok=True)\n        with open(filename, \"a\", encoding=\"utf-8\") as f:\n            f.write(text)\n\n        if should_log:\n            with open(filename, \"r\", encoding=\"utf-8\") as f:\n                checksum = text_checksum(f.read())\n            log_operation(\"append\", filename, agent, checksum=checksum)\n\n        return \"Text appended successfully.\"\n    except Exception as err:\n        return f\"Error: {err}\"\n\n\n@command(\n    \"list_files\",\n    \"Lists Files in a Directory\",\n    {\n        \"directory\": {\n            \"type\": \"string\",\n            \"description\": \"The directory to list files in\",\n            \"required\": True,\n        }\n    },\n)\n@sanitize_path_arg(\"directory\")\ndef list_files(directory: str, agent: Agent) -> list[str]:\n    \"\"\"lists files in a directory recursively\n\n    Args:\n        directory (str): The directory to search in\n\n    Returns:\n        list[str]: A list of files found in the directory\n    \"\"\"\n    found_files = []\n\n    for root, _, files in os.walk(directory):\n        for file in files:\n            if file.startswith(\".\"):\n                continue\n            relative_path = os.path.relpath(\n                os.path.join(root, file), agent.config.workspace_path\n            )\n            found_files.append(relative_path)\n\n    return found_files\n"}
{"type": "source_file", "path": "autogpt/commands/automate_installation.py", "content": "\"\"\"Commands to execute code\"\"\"\n\nCOMMAND_CATEGORY = \"automate_installation\"\nCOMMAND_CATEGORY_TITLE = \"AUTO INSTALL\"\n\nimport os\nimport subprocess\nimport re\nimport json\nimport random\nimport time\n\nimport docker\nfrom docker.errors import DockerException, ImageNotFound\nfrom docker.models.containers import Container as DockerContainer\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.logs import logger\n\nimport javalang\nfrom create_files_index import list_java_files\n\nALLOWLIST_CONTROL = \"allowlist\"\nDENYLIST_CONTROL = \"denylist\"\n\n\n\n\"\"\"@command(\n    \"write_to_file\",\n    \"A\",\n    {\n        \"content_to_write\": {\n            \"type\": \"string\",\n            \"description\": \"The content that you want to write into the file\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\ndef write_to_file(file_path: str, content_to_write: str, mode: str, agent: Agent) -> str:\n    \"\"\"\n    \"\"\"\n    ai_name = agent.ai_config.ai_name\n    project_path = agent.project_path\n    workspace = \"execution_agent_workspace/\"\n    try:\n        with open(os.path.join(workspace, project_path, file_path), mode) as t_file:\n            t_file.write(content_to_write)\n        return \"Content was successfully written to the file {}\".format(file_path)\n    except Exception as e:\n        return str(e)"}
{"type": "source_file", "path": "autogpt/command_decorator.py", "content": "from __future__ import annotations\n\nimport functools\nfrom typing import TYPE_CHECKING, Any, Callable, Optional, TypedDict\n\nif TYPE_CHECKING:\n    from autogpt.config import Config\n\nfrom autogpt.models.command import Command, CommandParameter\n\n# Unique identifier for auto-gpt commands\nAUTO_GPT_COMMAND_IDENTIFIER = \"auto_gpt_command\"\n\n\nclass CommandParameterSpec(TypedDict):\n    type: str\n    description: str\n    required: bool\n\n\ndef command(\n    name: str,\n    description: str,\n    parameters: dict[str, CommandParameterSpec],\n    enabled: bool | Callable[[Config], bool] = True,\n    disabled_reason: Optional[str] = None,\n    aliases: list[str] = [],\n) -> Callable[..., Any]:\n    \"\"\"The command decorator is used to create Command objects from ordinary functions.\"\"\"\n\n    def decorator(func: Callable[..., Any]) -> Command:\n        typed_parameters = [\n            CommandParameter(\n                name=param_name,\n                description=parameter.get(\"description\"),\n                type=parameter.get(\"type\", \"string\"),\n                required=parameter.get(\"required\", False),\n            )\n            for param_name, parameter in parameters.items()\n        ]\n        cmd = Command(\n            name=name,\n            description=description,\n            method=func,\n            parameters=typed_parameters,\n            enabled=enabled,\n            disabled_reason=disabled_reason,\n            aliases=aliases,\n        )\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            return func(*args, **kwargs)\n\n        wrapper.command = cmd\n\n        setattr(wrapper, AUTO_GPT_COMMAND_IDENTIFIER, True)\n\n        return wrapper\n\n    return decorator\n"}
{"type": "source_file", "path": "autogpt/agents/__init__.py", "content": "from .agent import Agent\nfrom .base import AgentThoughts, BaseAgent, CommandArgs, CommandName\n\n__all__ = [\"BaseAgent\", \"Agent\", \"CommandName\", \"CommandArgs\", \"AgentThoughts\"]\n"}
{"type": "source_file", "path": "autogpt/commands/decorators.py", "content": "import functools\nfrom pathlib import Path\nfrom typing import Callable\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.logs import logger\n\n\ndef sanitize_path_arg(arg_name: str):\n    def decorator(func: Callable):\n        # Get position of path parameter, in case it is passed as a positional argument\n        try:\n            arg_index = list(func.__annotations__.keys()).index(arg_name)\n        except ValueError:\n            raise TypeError(\n                f\"Sanitized parameter '{arg_name}' absent or not annotated on function '{func.__name__}'\"\n            )\n\n        # Get position of agent parameter, in case it is passed as a positional argument\n        try:\n            agent_arg_index = list(func.__annotations__.keys()).index(\"agent\")\n        except ValueError:\n            raise TypeError(\n                f\"Parameter 'agent' absent or not annotated on function '{func.__name__}'\"\n            )\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            logger.debug(f\"Sanitizing arg '{arg_name}' on function '{func.__name__}'\")\n            logger.debug(f\"Function annotations: {func.__annotations__}\")\n\n            # Get Agent from the called function's arguments\n            agent = kwargs.get(\n                \"agent\", len(args) > agent_arg_index and args[agent_arg_index]\n            )\n            logger.debug(f\"Args: {args}\")\n            logger.debug(f\"KWArgs: {kwargs}\")\n            logger.debug(f\"Agent argument lifted from function call: {agent}\")\n            if not isinstance(agent, Agent):\n                raise RuntimeError(\"Could not get Agent from decorated command's args\")\n\n            # Sanitize the specified path argument, if one is given\n            given_path: str | Path | None = kwargs.get(\n                arg_name, len(args) > arg_index and args[arg_index] or None\n            )\n            if given_path:\n                if given_path in {\"\", \"/\"}:\n                    sanitized_path = str(agent.workspace.root)\n                else:\n                    sanitized_path = str(agent.workspace.get_path(given_path))\n\n                if arg_name in kwargs:\n                    kwargs[arg_name] = sanitized_path\n                else:\n                    # args is an immutable tuple; must be converted to a list to update\n                    arg_list = list(args)\n                    arg_list[arg_index] = sanitized_path\n                    args = tuple(arg_list)\n\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n"}
{"type": "source_file", "path": "autogpt/commands/__init__.py", "content": "COMMAND_CATEGORIES = [\n    \"autogpt.commands.execute_code\",\n    \"autogpt.commands.file_operations\",\n    \"autogpt.commands.web_search\",\n    \"autogpt.commands.web_selenium\",\n    \"autogpt.commands.system\",\n    \"autogpt.commands.steps_commands\",\n    #\"autogpt.commands.collect_info\",\n    #\"autogpt.commands.analyze_test_execution\",\n    #\"autogpt.commands.automate_installation\"\n]"}
{"type": "source_file", "path": "autogpt/__main__.py", "content": "\"\"\"Auto-GPT: A GPT powered AI Assistant\"\"\"\nimport autogpt.app.cli\n\nif __name__ == \"__main__\":\n    autogpt.app.cli.main()\n"}
{"type": "source_file", "path": "autogpt/commands/times.py", "content": "from datetime import datetime\n\n\ndef get_datetime() -> str:\n    \"\"\"Return the current date and time\n\n    Returns:\n        str: The current date and time\n    \"\"\"\n    return \"Current date and time: \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n"}
{"type": "source_file", "path": "autogpt/commands/execute_code.py", "content": "\"\"\"Commands to execute code\"\"\"\n\nCOMMAND_CATEGORY = \"execute_code\"\nCOMMAND_CATEGORY_TITLE = \"Execute Code\"\n\nimport os\nimport subprocess\nfrom pathlib import Path\n\nimport docker\nfrom docker.errors import DockerException, ImageNotFound\nfrom docker.models.containers import Container as DockerContainer\nfrom autogpt.commands.docker_helpers_static import execute_command_in_container, read_file_from_container, remove_progress_bars, textify_output, extract_test_sections\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.config import Config\nfrom autogpt.logs import logger\n\nfrom .decorators import sanitize_path_arg\n\nALLOWLIST_CONTROL = \"allowlist\"\nDENYLIST_CONTROL = \"denylist\"\n\n\n@command(\n    \"execute_python_code\",\n    \"Creates a Python file and executes it\",\n    {\n        \"code\": {\n            \"type\": \"string\",\n            \"description\": \"The Python code to run\",\n            \"required\": True,\n        },\n        \"name\": {\n            \"type\": \"string\",\n            \"description\": \"A name to be given to the python file\",\n            \"required\": True,\n        },\n    },\n)\ndef execute_python_code(code: str, name: str, agent: Agent) -> str:\n    \"\"\"Create and execute a Python file in a Docker container and return the STDOUT of the\n    executed code. If there is any data that needs to be captured use a print statement\n\n    Args:\n        code (str): The Python code to run\n        name (str): A name to be given to the Python file\n\n    Returns:\n        str: The STDOUT captured from the code when it ran\n    \"\"\"\n    ai_name = agent.ai_config.ai_name\n    code_dir = agent.workspace.get_path(Path(ai_name, \"executed_code\"))\n    os.makedirs(code_dir, exist_ok=True)\n\n    if not name.endswith(\".py\"):\n        name = name + \".py\"\n\n    # The `name` arg is not covered by @sanitize_path_arg,\n    # so sanitization must be done here to prevent path traversal.\n    file_path = agent.workspace.get_path(code_dir / name)\n    if not file_path.is_relative_to(code_dir):\n        return \"Error: 'name' argument resulted in path traversal, operation aborted\"\n\n    try:\n        with open(file_path, \"w+\", encoding=\"utf-8\") as f:\n            f.write(code)\n\n        return execute_python_file(str(file_path), agent)\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n\n@command(\n    \"execute_python_file\",\n    \"Executes an existing Python file\",\n    {\n        \"filename\": {\n            \"type\": \"string\",\n            \"description\": \"The name of te file to execute\",\n            \"required\": True,\n        },\n    },\n)\n@sanitize_path_arg(\"filename\")\ndef execute_python_file(filename: str, agent: Agent) -> str:\n    \"\"\"Execute a Python file in a Docker container and return the output\n\n    Args:\n        filename (str): The name of the file to execute\n\n    Returns:\n        str: The output of the file\n    \"\"\"\n    logger.info(\n        f\"Executing python file '{filename}' in working directory '{agent.config.workspace_path}'\"\n    )\n\n    if not filename.endswith(\".py\"):\n        return \"Error: Invalid file type. Only .py files are allowed.\"\n\n    file_path = Path(filename)\n    if not file_path.is_file():\n        # Mimic the response that you get from the command line so that it's easier to identify\n        return (\n            f\"python: can't open file '{filename}': [Errno 2] No such file or directory\"\n        )\n\n    if we_are_running_in_a_docker_container():\n        logger.debug(\n            f\"Auto-GPT is running in a Docker container; executing {file_path} directly...\"\n        )\n        result = subprocess.run(\n            [\"python\", str(file_path)],\n            capture_output=True,\n            encoding=\"utf8\",\n            cwd=agent.config.workspace_path,\n        )\n        if result.returncode == 0:\n            return result.stdout\n        else:\n            return f\"Error: {result.stderr}\"\n\n    logger.debug(\"Auto-GPT is not running in a Docker container\")\n    try:\n        client = docker.from_env()\n        # You can replace this with the desired Python image/version\n        # You can find available Python images on Docker Hub:\n        # https://hub.docker.com/_/python\n        image_name = \"python:3-alpine\"\n        try:\n            client.images.get(image_name)\n            logger.debug(f\"Image '{image_name}' found locally\")\n        except ImageNotFound:\n            logger.info(\n                f\"Image '{image_name}' not found locally, pulling from Docker Hub...\"\n            )\n            # Use the low-level API to stream the pull response\n            low_level_client = docker.APIClient()\n            for line in low_level_client.pull(image_name, stream=True, decode=True):\n                # Print the status and progress, if available\n                status = line.get(\"status\")\n                progress = line.get(\"progress\")\n                if status and progress:\n                    logger.info(f\"{status}: {progress}\")\n                elif status:\n                    logger.info(status)\n\n        logger.debug(f\"Running {file_path} in a {image_name} container...\")\n        container: DockerContainer = client.containers.run(\n            image_name,\n            [\n                \"python\",\n                file_path.relative_to(agent.workspace.root).as_posix(),\n            ],\n            volumes={\n                str(agent.config.workspace_path): {\n                    \"bind\": \"/workspace\",\n                    \"mode\": \"rw\",\n                }\n            },\n            working_dir=\"/workspace\",\n            stderr=True,\n            stdout=True,\n            detach=True,\n        )  # type: ignore\n\n        container.wait()\n        logs = container.logs().decode(\"utf-8\")\n        container.remove()\n\n        # print(f\"Execution complete. Output: {output}\")\n        # print(f\"Logs: {logs}\")\n\n        return logs\n\n    except DockerException as e:\n        logger.warn(\n            \"Could not run the script in a container. If you haven't already, please install Docker https://docs.docker.com/get-docker/\"\n        )\n        return f\"Error: {str(e)}\"\n\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n\ndef validate_command(command: str, config: Config) -> bool:\n    \"\"\"Validate a command to ensure it is allowed\n\n    Args:\n        command (str): The command to validate\n        config (Config): The config to use to validate the command\n\n    Returns:\n        bool: True if the command is allowed, False otherwise\n    \"\"\"\n    if not command:\n        return False\n    return True\n    command_name = command.split()[0]\n\n    if config.shell_command_control == ALLOWLIST_CONTROL:\n        return command_name in config.shell_allowlist\n    else:\n        return command_name not in config.shell_denylist\n\n\nimport time\nimport timeout_decorator\n\n@command(\n    \"linux_terminal\",\n    \"Executes a Shell Command, non-interactive commands only\",\n    {\n        \"command\": {\n            \"type\": \"string\",\n            \"description\": \"The command line to execute\",\n            \"required\": True,\n        }\n    },\n    enabled=True,\n    disabled_reason=\"You are not allowed to run local shell commands. To execute\"\n    \" shell commands, EXECUTE_LOCAL_COMMANDS must be set to 'True' \"\n    \"in your config file: .env - do not attempt to bypass the restriction.\",\n)\ndef execute_shell(command: str, agent: Agent) -> str:\n    \"\"\"Execute a shell command and return the output\n\n    Args:\n        command (str): The command line to execute\n\n    Returns:\n        str: The output of the command\n    \"\"\"\n    if \"nano \" in command:\n        return \"You cannot execute call nano because it's an interactive command.\"\n    elif \"docker \" in command:\n        if agent.container:\n            return \"You cannot execute docker commands. You already have access to a running container. If you are facing issues such as missing requirement or need to install a package, you can use linux_terminal to interact with the already running container and install or change whatever you want there. You cannot create another container\"\n        else:\n            return \"You cannot execute docker commands. Use the command write_to_file to create a dockerfile script which will automatically build and launch a container. If you are facing build error or issues, you can simplify your dockerfile script to reduce the source of errors\"\n    elif command.startswith(\"bash \"):\n        command = command.replace(\"bash \", \"\")\n    if not validate_command(command, agent.config):\n        logger.info(f\"Command '{command}' not allowed\")\n        return \"Error: This Shell Command is not allowed.\"\n    \n    if command == \"ls -R\":\n        return \"This command usually returns too much output, hence, it is not allowed.\"\n    #current_dir = Path.cwd()\n    # Change dir into workspace if necessary\n    #if not current_dir.is_relative_to(agent.config.workspace_path):\n    #    os.chdir(os.path.join(agent.config.workspace_path, agent.project_path))\n\n    #logger.info(\n    #    f\"Executing command '{command}' in working directory '{os.getcwd()}'\"\n    #)\n\n    #result = subprocess.run(command, capture_output=True, shell=True)\n    #output = f\"STDOUT:\\n{result.stdout}\\nSTDERR:\\n{result.stderr}\"\n\n    # Change back to whatever the prior working dir was\n\n    #os.chdir(current_dir)\n    #return output\n\n    WAIT_TIME = 300\n\n    if not agent.container:\n        ret_val = agent.interact_with_shell(command)\n    else:\n        if agent.command_stuck:\n            if not (command.startswith(\"TERMINATE\") or command.startswith(\"WAIT\") or command.startswith(\"WRITE:\")):\n                return \"\"\"The terminal is stuck at command before this one. You cannot request executing a new command before terminating the previous one. To do that, you can make the following as your next output action: {\"command\": {\"name\": \"linux_terminal\", \"args\": {\"command\": \"TERMINATE\"}}}\"\"\"\n            elif command == \"WAIT\":\n                old_output = read_file_from_container(agent.container, \"/tmp/cmd_result\")\n                time.sleep(WAIT_TIME)\n                new_output = read_file_from_container(agent.container, \"/tmp/cmd_result\")\n                if old_output == new_output:\n                    with open(\"prompt_files/command_stuck\") as cst:\n                        stuck_m = cst.read()\n                    return \"The command is still stuck somewhere, here is the output that the command has so far (it did not change for the last {} seconds):\\n\".format(60) + old_output + \"\\n\\n\" + stuck_m\n                else:\n                    agent.command_stuck = False\n                    return \"The command is no longer stuck, here is the final output:\\n\" + new_output + \"\\n\"\n            elif command == \"TERMINATE\":\n                execute_command_in_container_screen(agent.container, \"screen -X -S my_screen_session quit\")\n                create_screen_session(agent.container)\n                agent.command_stuck = False\n                return \"The previous command was terminated, a fresh terminal has been instantiated.\"\n            elif command.startswith(\"WRITE:\"):\n                write_input = command.replace(\"WRITE:\", \"\")\n                interact_command = \"screen -S my_screen_session -X stuff '{}\\n'\".format(write_input)\n                interact_ret_val = execute_command_in_container(agent.container, interact_command)\n                if ret_val[0].startswith(\"The command you executed seems to take some time to finish..\"):\n                    agent.command_stuck = True\n                    return ret_val[0]\n                else:\n                    agent.command_stuck = False\n                    return \"The text that appears on the terminal after executing your command is:\\n\" + str(ret_val[0])\n                    \n        new_command = \"screen -S my_screen_session -X stuff '{} 2>&1 | tee /tmp/cmd_result\\n'\".format(command)\n        ret_val = execute_command_in_container(agent.container, new_command)\n        #print(\"----- OUTPUT ON DOCKER LEVEL: {}\".format(ret_val))\n        try:\n            cmd_result = read_file_from_container(agent.container, \"/tmp/cmd_result\")\n        except Exception as e:\n            print(\"ERROR HAPPENED WHILE TRYING TO READ RESULT FILE FROM CONTAINER--------\", e)\n            cmd_result = str(e)\n        #print(\"----- OUTPUT ON SCREEN LEVEL: {}\".format(cmd_result))\n        cmd_result = textify_output(cmd_result)\n        print(\"----- OUTPUT AFTER TEXTIFYING:\", cmd_result)\n        if len(cmd_result) > 2000:\n            cmd_result_temp = remove_progress_bars(cmd_result)\n            #print(\"------ OUTPUT AFTER REMOVING PROGRESS BARS:\", cmd_result_temp)\n        else:\n            cmd_result_temp = cmd_result\n        #cmd_result = extract_test_sections(cmd_result)\n        ret_val = [cmd_result_temp, None]\n\n        if ret_val[0].startswith(\"The command you executed seems to take some time to finish..\"):\n            agent.command_stuck = True\n            return ret_val[0]\n        else:\n            agent.command_stuck = False\n    return \"The text that appears on the terminal after executing your command is:\\n\" + str(ret_val[0])\n\n@command(\n    \"execute_shell_popen\",\n    \"Executes a Shell Command, non-interactive commands only\",\n    {\n        \"command_line\": {\n            \"type\": \"string\",\n            \"description\": \"The command line to execute\",\n            \"required\": True,\n        }\n    },\n    lambda config: config.execute_local_commands,\n    \"You are not allowed to run local shell commands. To execute\"\n    \" shell commands, EXECUTE_LOCAL_COMMANDS must be set to 'True' \"\n    \"in your config. Do not attempt to bypass the restriction.\",\n)\ndef execute_shell_popen(command_line, agent: Agent) -> str:\n    \"\"\"Execute a shell command with Popen and returns an english description\n    of the event and the process id\n\n    Args:\n        command_line (str): The command line to execute\n\n    Returns:\n        str: Description of the fact that the process started and its id\n    \"\"\"\n    if not validate_command(command_line, agent.config):\n        logger.info(f\"Command '{command_line}' not allowed\")\n        return \"Error: This Shell Command is not allowed.\"\n\n    current_dir = os.getcwd()\n    # Change dir into workspace if necessary\n    if agent.config.workspace_path not in current_dir:\n        os.chdir(agent.config.workspace_path)\n\n    logger.info(\n        f\"Executing command '{command_line}' in working directory '{os.getcwd()}'\"\n    )\n\n    do_not_show_output = subprocess.DEVNULL\n    process = subprocess.Popen(\n        command_line, shell=True, stdout=do_not_show_output, stderr=do_not_show_output\n    )\n\n    # Change back to whatever the prior working dir was\n\n    os.chdir(current_dir)\n\n    return f\"Subprocess started with PID:'{str(process.pid)}'\"\n\n\ndef we_are_running_in_a_docker_container() -> bool:\n    \"\"\"Check if we are running in a Docker container\n\n    Returns:\n        bool: True if we are running in a Docker container, False otherwise\n    \"\"\"\n    return os.path.exists(\"/.dockerenv\")\n"}
{"type": "source_file", "path": "autogpt/core/ability/builtins/query_language_model.py", "content": "import logging\n\nfrom autogpt.core.ability.base import Ability, AbilityConfiguration\nfrom autogpt.core.ability.schema import AbilityResult\nfrom autogpt.core.planning.simple import LanguageModelConfiguration\nfrom autogpt.core.plugin.simple import PluginLocation, PluginStorageFormat\nfrom autogpt.core.resource.model_providers import (\n    LanguageModelMessage,\n    LanguageModelProvider,\n    MessageRole,\n    ModelProviderName,\n    OpenAIModelName,\n)\n\n\nclass QueryLanguageModel(Ability):\n    default_configuration = AbilityConfiguration(\n        location=PluginLocation(\n            storage_format=PluginStorageFormat.INSTALLED_PACKAGE,\n            storage_route=\"autogpt.core.ability.builtins.QueryLanguageModel\",\n        ),\n        language_model_required=LanguageModelConfiguration(\n            model_name=OpenAIModelName.GPT3,\n            provider_name=ModelProviderName.OPENAI,\n            temperature=0.9,\n        ),\n    )\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        configuration: AbilityConfiguration,\n        language_model_provider: LanguageModelProvider,\n    ):\n        self._logger = logger\n        self._configuration = configuration\n        self._language_model_provider = language_model_provider\n\n    @classmethod\n    def description(cls) -> str:\n        return \"Query a language model. A query should be a question and any relevant context.\"\n\n    @classmethod\n    def arguments(cls) -> dict:\n        return {\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"A query for a language model. A query should contain a question and any relevant context.\",\n            },\n        }\n\n    @classmethod\n    def required_arguments(cls) -> list[str]:\n        return [\"query\"]\n\n    async def __call__(self, query: str) -> AbilityResult:\n        messages = [\n            LanguageModelMessage(\n                content=query,\n                role=MessageRole.USER,\n            ),\n        ]\n        model_response = await self._language_model_provider.create_language_completion(\n            model_prompt=messages,\n            functions=[],\n            model_name=self._configuration.language_model_required.model_name,\n            completion_parser=self._parse_response,\n        )\n        return AbilityResult(\n            ability_name=self.name(),\n            ability_args={\"query\": query},\n            success=True,\n            message=model_response.content[\"content\"],\n        )\n\n    @staticmethod\n    def _parse_response(response_content: dict) -> dict:\n        return {\"content\": response_content[\"content\"]}\n"}
{"type": "source_file", "path": "autogpt/app/cli.py", "content": "\"\"\"Main script for the autogpt package.\"\"\"\nfrom pathlib import Path\nfrom typing import Optional\n\nimport click\n\n\n@click.group(invoke_without_command=True)\n@click.option(\"-c\", \"--continuous\", is_flag=True, help=\"Enable Continuous Mode\")\n@click.option(\n    \"--skip-reprompt\",\n    \"-y\",\n    is_flag=True,\n    help=\"Skips the re-prompting messages at the beginning of the script\",\n)\n@click.option(\n    \"--ai-settings\",\n    \"-C\",\n    help=(\n        \"Specifies which ai_settings.yaml file to use, relative to the Auto-GPT\"\n        \" root directory. Will also automatically skip the re-prompt.\"\n    ),\n)\n@click.option(\n    \"--prompt-settings\",\n    \"-P\",\n    help=\"Specifies which prompt_settings.yaml file to use.\",\n)\n@click.option(\n    \"-l\",\n    \"--continuous-limit\",\n    type=int,\n    help=\"Defines the number of times to run in continuous mode\",\n)\n@click.option(\"--speak\", is_flag=True, help=\"Enable Speak Mode\")\n@click.option(\"--debug\", is_flag=True, help=\"Enable Debug Mode\")\n@click.option(\"--gpt3only\", is_flag=True, help=\"Enable GPT3.5 Only Mode\")\n@click.option(\"--gpt4only\", is_flag=True, help=\"Enable GPT4 Only Mode\")\n@click.option(\n    \"--use-memory\",\n    \"-m\",\n    \"memory_type\",\n    type=str,\n    help=\"Defines which Memory backend to use\",\n)\n@click.option(\n    \"-b\",\n    \"--browser-name\",\n    help=\"Specifies which web-browser to use when using selenium to scrape the web.\",\n)\n@click.option(\n    \"--allow-downloads\",\n    is_flag=True,\n    help=\"Dangerous: Allows Auto-GPT to download files natively.\",\n)\n@click.option(\n    \"--skip-news\",\n    is_flag=True,\n    help=\"Specifies whether to suppress the output of latest news on startup.\",\n)\n@click.option(\n    # TODO: this is a hidden option for now, necessary for integration testing.\n    #   We should make this public once we're ready to roll out agent specific workspaces.\n    \"--workspace-directory\",\n    \"-w\",\n    type=click.Path(),\n    hidden=True,\n)\n@click.option(\n    \"--install-plugin-deps\",\n    is_flag=True,\n    help=\"Installs external dependencies for 3rd party plugins.\",\n)\n@click.option(\n    \"--ai-name\",\n    type=str,\n    help=\"AI name override\",\n)\n@click.option(\n    \"--ai-role\",\n    type=str,\n    help=\"AI role override\",\n)\n@click.option(\n    \"--ai-goal\",\n    type=str,\n    multiple=True,\n    help=\"AI goal override; may be used multiple times to pass multiple goals\",\n)\n@click.option(\n    \"--experiment-file\",\n    type=str,\n    multiple=False,\n    help=\"the path to the file containing the configuration of the agent for the experiment.\",\n)\n@click.pass_context\ndef main(\n    ctx: click.Context,\n    continuous: bool,\n    continuous_limit: int,\n    ai_settings: str,\n    prompt_settings: str,\n    skip_reprompt: bool,\n    speak: bool,\n    debug: bool,\n    gpt3only: bool,\n    gpt4only: bool,\n    memory_type: str,\n    browser_name: str,\n    allow_downloads: bool,\n    skip_news: bool,\n    workspace_directory: str,\n    install_plugin_deps: bool,\n    ai_name: Optional[str],\n    ai_role: Optional[str],\n    ai_goal: tuple[str],\n    experiment_file: str\n) -> None:\n    \"\"\"\n    Welcome to AutoGPT an experimental open-source application showcasing the capabilities of the GPT-4 pushing the boundaries of AI.\n\n    Start an Auto-GPT assistant.\n    \"\"\"\n    # Put imports inside function to avoid importing everything when starting the CLI\n    from autogpt.app.main import run_auto_gpt\n\n    if ctx.invoked_subcommand is None:\n        run_auto_gpt(\n            continuous=continuous,\n            continuous_limit=continuous_limit,\n            ai_settings=ai_settings,\n            prompt_settings=prompt_settings,\n            skip_reprompt=skip_reprompt,\n            speak=speak,\n            debug=debug,\n            gpt3only=gpt3only,\n            gpt4only=gpt4only,\n            memory_type=memory_type,\n            browser_name=browser_name,\n            allow_downloads=allow_downloads,\n            skip_news=skip_news,\n            working_directory=Path(\n                __file__\n            ).parent.parent.parent,  # TODO: make this an option\n            workspace_directory=workspace_directory,\n            install_plugin_deps=install_plugin_deps,\n            ai_name=ai_name,\n            ai_role=ai_role,\n            ai_goals=ai_goal,\n            experiment_file=experiment_file\n        )\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "autogpt/commands/docker_helpers_static.py", "content": "import docker\nfrom docker.errors import ImageNotFound\nimport os\nimport subprocess\nimport re\nimport time\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema.messages import HumanMessage, SystemMessage, AIMessage\n\nACTIVE_SCREEN = {\n    \"name\": \"my_screen_session\",\n    \"id\": None,\n    \"default_process_list\": None,\n    \"prep_end\": False\n}\n\ndef ask_chatgpt(query, system_message, model=\"gpt-4o-mini\"):\n    with open(\"openai_token.txt\") as opt:\n        token = opt.read()\n    chat = ChatOpenAI(openai_api_key=token, model=model)\n\n    messages = [\n        SystemMessage(\n            content= system_message\n                    ),\n        HumanMessage(\n            content=query\n            )  \n    ]\n    #response_format={ \"type\": \"json_object\" }\n    response = chat.invoke(messages)\n\n    return response.content\n\nimport xml.etree.ElementTree as ET\nimport yaml\n\ndef xml_to_dict(element):\n    \"\"\" Recursively converts XML elements to a dictionary. \"\"\"\n    if len(element) == 0:\n        return element.text\n    return {\n        element.tag: {\n            child.tag: xml_to_dict(child) for child in element\n        }\n    }\n\ndef convert_xml_to_yaml(xml_content):\n    \"\"\" Converts XML content (as a string) to a YAML string. \"\"\"\n    # Parse the XML content from the string\n    root = ET.fromstring(xml_content)\n    \n    # Convert XML to a dictionary\n    xml_dict = xml_to_dict(root)\n    \n    # Convert the dictionary to a YAML string\n    yaml_str = yaml.dump(xml_dict, default_flow_style=False)\n    \n    return yaml_str\n\ndef send_command_to_shell(container, command):\n    try:\n        # Send a command to the shell session\n        exec_result = container.exec_run(f\"bash -c '{command}'\")\n        \n        output = exec_result.output.decode('utf-8')\n        print(f\"Command output:\\n{output}\")\n        return output\n    \n    except Exception as e:\n        return f\"An error occurred while sending the command: {e}\"\n\ndef get_screen_process_list(container, screen_id):\n    command = \"pstree -p {}\".format(screen_id)\n    output = execute_command_in_container_screen(container, command)\n    return output\n\ndef create_screen_session(container):\n    command = \"apt update && apt install -y screen\"\n    execute_command_in_container_screen(container, command)\n\n    command = \"apt install psmisc\"\n    execute_command_in_container_screen(container, command)\n\n    command = \"touch /tmp/cmd_result\"\n    execute_command_in_container_screen(container, command)\n\n    command = \"screen -dmS my_screen_session\"\n    execute_command_in_container_screen(container, command)\n\n    command = \"screen -ls\"\n    output = execute_command_in_container_screen(container, command)\n    \n    \n    session_id = parse_screen_sesssion_id(output)\n     \n    ACTIVE_SCREEN[\"id\"] = session_id\n    ACTIVE_SCREEN[\"default_process_list\"] = get_screen_process_list(container, session_id)\n    ACTIVE_SCREEN[\"prep_end\"] = True\n\n    command = \"TZ=Europe/Berlin && ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\"\n    output = execute_command_in_container_screen(container, command)\n\ndef parse_screen_sesssion_id(screen_ls):\n    lines = screen_ls.splitlines()\n    \n    for line in lines:\n        if \".my_screen_session\" in line:\n            wanted_line = line\n            break\n    else:\n        raise ValueError(\"ERROR: This is not possible, my_screen_session should be there\")\n\n    line_parts = wanted_line.split()\n    for part in line_parts:\n        if \".my_screen_session\" in part:\n            wanted_part = part\n            break\n    else:\n        raise ValueError(\"ERROR 2: This is not possible, my_screen_session should be there\")\n\n    return wanted_part.split(\".\")[0]\n\n\ndef remove_duplicate_consecutive_lines(text):\n    lines = text.split('\\n')  # Split the text into individual lines\n    result_lines = []         # List to store the unique lines\n    previous_line = None       # Keep track of the last processed line\n\n    for line in lines:\n        if line != previous_line:  # Only append the line if it's different from the last one\n            result_lines.append(line)\n        previous_line = line       # Update the last processed line\n    \n    return '\\n'.join(result_lines)  # Join the unique lines back into a single text block\n\ndef remove_progress_bars(text):\n    try:\n        with open(\"prompt_files/remove_progress_bars\") as rpb:\n            system_prompt= rpb.read()\n        summary = \"\"\n        for i in range(int(len(text)/100000)+1):\n            query= \"Here is the output of a command that you should clean:\\n\"+ text[i*100000: (i+1)*100000]\n            summary += \"\\n\" + ask_chatgpt(query, system_prompt)\n            print(\"CLEANED 100K CHARACTERS.........\")\n            print(\"LEN CLEANED:\", len(summary))\n    except Exception as e:\n        print(\"ERRRRRROOOOOOOOOOOR IN PROGRESSSSSSSSSS:\", e)\n\n    return summary\n\ndef remove_ansi_escape_sequences(text):\n    \"\"\"\n    Removes ANSI escape sequences from a given string.\n    \n    Parameters:\n    text (str): The string containing ANSI escape sequences.\n    \n    Returns:\n    str: The cleaned string without ANSI escape sequences.\n    \"\"\"\n    # Regular expression to match ANSI escape sequences\n    ansi_escape = re.compile(r'\\x1b\\[[0-9;?]*[a-zA-Z]')\n    \n    # Removing ANSI escape sequences\n    clean_text = ansi_escape.sub('', text)\n    \n    return clean_text\n\ndef check_image_exists(image_name):\n    client = docker.from_env()\n    try:\n        client.images.get(image_name)\n        print(f\"Image '{image_name}' exists.\")\n        return True\n    except ImageNotFound:\n        print(f\"Image '{image_name}' does not exist.\")\n        return False\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False\n\ndef textify_output(output):\n    # Decode bytes to string\n    output_str = output\n\n    # Regular expression pattern to match ANSI escape sequences\n    ansi_escape = re.compile(r'\\x1b\\[([0-9;]*[A-Za-z])')\n\n    # Remove ANSI escape sequences\n    clean_output = ansi_escape.sub('', output_str)\n\n    # Remove extra whitespace characters like \\r and \\n\n    clean_output = clean_output\n    return clean_output\n\ndef extract_test_sections(maven_output):\n    # Regular expressions to match the start and end of test sections\n    test_section_start = re.compile(r'Tests run: \\d+, Failures: \\d+, Errors: \\d+, Skipped: \\d+')\n    test_section_end = re.compile(r'\\[INFO\\] .*')\n\n    # Find all the indices where the test sections start and end\n    starts = [match.start() for match in test_section_start.finditer(maven_output)]\n    ends = [match.start() for match in test_section_end.finditer(maven_output)]\n\n    # Ensure each start has a corresponding end\n    sections = []\n    for start in starts:\n        end = next((e for e in ends if e > start), None)\n        if end:\n            sections.append(maven_output[start:end])\n    \n    # If no test sections are detected, return the original output\n    if not sections:\n        return maven_output\n\n    # Join all extracted sections into a single string\n    return \"\\n\".join(sections)\n\ndef build_image(dockerfile_path, tag):\n    client = docker.from_env()\n    try:\n        log_text = \"\"\n        print(f\"Building Docker image from {dockerfile_path} with tag {tag}...\")\n        image, logs = client.images.build(path=dockerfile_path, tag=tag, rm=True, nocache=True)\n        for log in logs:\n            if 'stream' in log:\n                log_text += log['stream'].strip()\n        return \"Docker image built successfully.\\n\"\n    except Exception as e:\n        return f\"An error occurred while building the Docker image: {e}\"\n        return None\nimport docker\n\ndef start_container(image_tag):\n    client = docker.from_env()\n    try:\n        print(f\"Running container from image {image_tag}...\")\n        container = client.containers.run(image_tag, detach=True, tty=True)\n        print(f\"Container {container.short_id} is running.\")\n        print(\"CREATING SCREEN SESSION\")\n        create_screen_session(container)\n        execute_command_in_container(container, \"screen -S my_screen_session -X stuff 'apt install coreutils'\")\n        return container\n    except Exception as e:\n        print(f\"ERRRRRRRRRRRR: An error occurred while running the container: {e}\")\n        return None\n\ndef execute_command_in_container_old(container, command):\n    try:\n        print(f\"Executing command '{command}' in container {container.short_id}...\")\n        exec_result = container.exec_run(command, tty=True)\n        print(f\"Command output:\\n{exec_result.output.decode('utf-8')}\")\n        clean_output = remove_progress_bars(textify_output(exec_result.output.decode('utf-8')))\n        test_sections = extract_test_sections(clean_output)\n        return test_sections\n    except Exception as e:\n        return f\"An error occurred while executing the command: {e}\"\n        return None\n\ndef execute_command_in_container(container, command):\n    try:\n        # Wrap the command in a shell execution context\n        shell_command = \"/bin/sh -c \\\"{}\\\"\".format(command)\n        #print(f\"Executing command '{command}' in container {container.short_id}...\")\n\n        # Execute the command without a TTY, but with streaming output\n        exec_result = container.exec_run(shell_command, tty=False)\n\n        # Decode and process the output\n        output = exec_result.output.decode('utf-8')\n        #print(f\"Command output:\\n{output}\")\n        \n        THRESH = 600\n        WAIT = 1\n        command_threshold = THRESH\n        old_command_output = read_file_from_container(container, \"/tmp/cmd_result\")\n\n        while get_screen_process_list(container, ACTIVE_SCREEN[\"id\"]) != ACTIVE_SCREEN[\"default_process_list\"]:\n            print(\"WAITING FOR PROCESS TO FINISH...\")\n            print(ACTIVE_SCREEN[\"default_process_list\"])\n            print(get_screen_process_list(container, ACTIVE_SCREEN[\"id\"]))\n            time.sleep(WAIT)\n            new_command_output =  read_file_from_container(container, \"/tmp/cmd_result\")\n\n            if new_command_output == old_command_output:\n                command_threshold -= WAIT\n            else:\n                command_threshold = THRESH\n            \n            if command_threshold <= 0:\n                with open(\"prompt_files/command_stuck\") as cst:\n                    stuck_m = cst.read()\n                return \"The command you executed seems to take some time to finish.. Here is the output that the command has so far (it did not change for the last {} seconds):\\n\".format(THRESH) + old_command_output + \"\\n\\n\" + stuck_m\n        return output\n\n    except Exception as e:\n        return f\"An error occurred while executing the command: {e}\"\n\ndef execute_command_in_container_screen(container, command):\n    try:\n        # Wrap the command in a shell execution context\n        shell_command = \"/bin/sh -c \\\"{}\\\"\".format(command)\n        #print(f\"Executing command '{command}' in container {container.short_id}...\")\n\n        # Execute the command without a TTY, but with streaming output\n        exec_result = container.exec_run(shell_command, tty=False)\n\n        # Decode and process the output\n        output = exec_result.output.decode('utf-8')\n        #print(f\"Command output:\\n{output}\")\n        return output\n\n    except Exception as e:\n        return f\"An error occurred while executing the command: {e}\"\n\n# Example usage:\n# Start a container\n#container = start_container('your_image_tag')\ndef stop_and_remove(container):\n    container.stop()\n    container.remove()\n    return \"Container stopped and removed successfully\"\n    \ndef run_container(image_tag, script_path):\n    client = docker.from_env()\n    try:\n        print(f\"Running container from image {image_tag}...\")\n        container = client.containers.run(image_tag, detach=True, tty=True)\n        print(f\"Container {container.short_id} is running.\")\n        \n        # Use docker cp to copy the script into the cloned repository folder inside the container\n        script_name = os.path.basename(script_path)\n        container_id = container.short_id\n        subprocess.run(['docker', 'cp', script_path, f'{container_id}:/app/code2flow/{script_name}'])\n        print(f\"Copied {script_name} to /app/code2flow/ in the container.\")\n\n        # Execute the script inside the container\n        exec_result = container.exec_run(f\"sh /app/code2flow/{script_name}\", stderr=True, stdout=True)\n        stdout = exec_result.output.decode()\n        exit_code = exec_result.exit_code\n        print(f\"Script executed with exit code {exit_code}. Output:\")\n        print(stdout)\n        \n        return exit_code, stdout\n    except Exception as e:\n        print(f\"An error occurred while running the container: {e}\")\n        return None, None\n    finally:\n        container.remove(force=True)\n        print(f\"Container {container.short_id} has been removed.\")\n\nimport tarfile\nimport io\n\ndef create_file_tar(file_path, file_content):\n    data = io.BytesIO()\n    with tarfile.TarFile(fileobj=data, mode='w') as tar:\n        tarinfo = tarfile.TarInfo(name=file_path)\n        tarinfo.size = len(file_content)\n        tar.addfile(tarinfo, io.BytesIO(file_content.encode('utf-8')))\n    data.seek(0)\n    return data\n\ndef write_string_to_file(container, file_content, file_path):\n    try:\n        # Create a tarball with the file\n        tar_data = create_file_tar(file_path, file_content)\n\n        # Copy the tarball into the container\n        container.put_archive('/', tar_data)\n\n        # Verify the file was written\n        exit_code, output = container.exec_run(f\"cat {file_path}\")\n        if exit_code == 0:\n            print(f\"File content in container: {output.decode('utf-8')}\", file_path)\n        else:\n            print(f\"Failed to verify the file in the container: {output.decode('utf-8')}\")\n    finally:\n        # Stop and remove the container\n        pass\n\ndef read_file_from_container(container, file_path):\n    \"\"\"\n    Reads the content of a file within a Docker container and returns it as a string.\n\n    Args:\n    - container: The Docker container instance.\n    - file_path: The path to the file inside the container.\n\n    Returns:\n    - The content of the file as a string.\n    \"\"\"\n    # Construct the command to read the file content\n    command = f'cat {file_path}'\n\n    # Execute the command within the container\n    exit_code, output = container.exec_run(cmd=command, tty=True)\n    \n    if exit_code == 0:\n        if file_path.lower().endswith(\"xml\"):\n            return convert_xml_to_yaml(output.decode('utf-8'))\n        return output.decode('utf-8')\n    else:\n        return f'Failed to read {file_path} in the container. Output: {output.decode(\"utf-8\")}'\n\nif __name__ == \"__main__\":\n    screen_text = \"\"\"There is a screen on:\n        37.my_screen_session    (09/13/24 10:12:26)     (Detached)\n1 Socket in /run/screen/S-root.\"\"\"\n\n    print(parse_screen_sesssion_id(screen_text))\n"}
{"type": "source_file", "path": "autogpt/core/ability/__init__.py", "content": "\"\"\"The command system provides a way to extend the functionality of the AI agent.\"\"\"\nfrom autogpt.core.ability.base import Ability, AbilityRegistry\nfrom autogpt.core.ability.schema import AbilityResult\nfrom autogpt.core.ability.simple import AbilityRegistrySettings, SimpleAbilityRegistry\n"}
{"type": "source_file", "path": "autogpt/core/ability/simple.py", "content": "import logging\n\nfrom autogpt.core.ability.base import Ability, AbilityConfiguration, AbilityRegistry\nfrom autogpt.core.ability.builtins import BUILTIN_ABILITIES\nfrom autogpt.core.ability.schema import AbilityResult\nfrom autogpt.core.configuration import Configurable, SystemConfiguration, SystemSettings\nfrom autogpt.core.memory.base import Memory\nfrom autogpt.core.plugin.simple import SimplePluginService\nfrom autogpt.core.resource.model_providers import (\n    LanguageModelProvider,\n    ModelProviderName,\n)\nfrom autogpt.core.workspace.base import Workspace\n\n\nclass AbilityRegistryConfiguration(SystemConfiguration):\n    \"\"\"Configuration for the AbilityRegistry subsystem.\"\"\"\n\n    abilities: dict[str, AbilityConfiguration]\n\n\nclass AbilityRegistrySettings(SystemSettings):\n    configuration: AbilityRegistryConfiguration\n\n\nclass SimpleAbilityRegistry(AbilityRegistry, Configurable):\n    default_settings = AbilityRegistrySettings(\n        name=\"simple_ability_registry\",\n        description=\"A simple ability registry.\",\n        configuration=AbilityRegistryConfiguration(\n            abilities={\n                ability_name: ability.default_configuration\n                for ability_name, ability in BUILTIN_ABILITIES.items()\n            },\n        ),\n    )\n\n    def __init__(\n        self,\n        settings: AbilityRegistrySettings,\n        logger: logging.Logger,\n        memory: Memory,\n        workspace: Workspace,\n        model_providers: dict[ModelProviderName, LanguageModelProvider],\n    ):\n        self._configuration = settings.configuration\n        self._logger = logger\n        self._memory = memory\n        self._workspace = workspace\n        self._model_providers = model_providers\n        self._abilities = []\n        for (\n            ability_name,\n            ability_configuration,\n        ) in self._configuration.abilities.items():\n            self.register_ability(ability_name, ability_configuration)\n\n    def register_ability(\n        self, ability_name: str, ability_configuration: AbilityConfiguration\n    ) -> None:\n        ability_class = SimplePluginService.get_plugin(ability_configuration.location)\n        ability_args = {\n            \"logger\": self._logger.getChild(ability_name),\n            \"configuration\": ability_configuration,\n        }\n        if ability_configuration.packages_required:\n            # TODO: Check packages are installed and maybe install them.\n            pass\n        if ability_configuration.memory_provider_required:\n            ability_args[\"memory\"] = self._memory\n        if ability_configuration.workspace_required:\n            ability_args[\"workspace\"] = self._workspace\n        if ability_configuration.language_model_required:\n            ability_args[\"language_model_provider\"] = self._model_providers[\n                ability_configuration.language_model_required.provider_name\n            ]\n        ability = ability_class(**ability_args)\n        self._abilities.append(ability)\n\n    def list_abilities(self) -> list[str]:\n        return [\n            f\"{ability.name()}: {ability.description()}\" for ability in self._abilities\n        ]\n\n    def dump_abilities(self) -> list[dict]:\n        return [ability.dump() for ability in self._abilities]\n\n    def get_ability(self, ability_name: str) -> Ability:\n        for ability in self._abilities:\n            if ability.name() == ability_name:\n                return ability\n        raise ValueError(f\"Ability '{ability_name}' not found.\")\n\n    async def perform(self, ability_name: str, **kwargs) -> AbilityResult:\n        ability = self.get_ability(ability_name)\n        return await ability(**kwargs)\n"}
{"type": "source_file", "path": "autogpt/agents/agent.py", "content": "from __future__ import annotations\n\nimport json\nimport time\nimport os\nfrom datetime import datetime\nfrom typing import TYPE_CHECKING, Any, Optional\n\nif TYPE_CHECKING:\n    from autogpt.config import AIConfig, Config\n    from autogpt.llm.base import ChatModelResponse, ChatSequence\n    from autogpt.memory.vector import VectorMemory\n    from autogpt.models.command_registry import CommandRegistry\n\nfrom autogpt.json_utils.utilities import extract_dict_from_response, validate_dict\nfrom autogpt.llm.api_manager import ApiManager\nfrom autogpt.llm.base import Message\nfrom autogpt.llm.utils import count_string_tokens\nfrom autogpt.logs import logger\nfrom autogpt.logs.log_cycle import (\n    CURRENT_CONTEXT_FILE_NAME,\n    FULL_MESSAGE_HISTORY_FILE_NAME,\n    NEXT_ACTION_FILE_NAME,\n    USER_INPUT_FILE_NAME,\n    LogCycleHandler,\n)\nfrom autogpt.workspace import Workspace\n\nfrom .base import AgentThoughts, BaseAgent, CommandArgs, CommandName\n\n\nclass Agent(BaseAgent):\n    \"\"\"Agent class for interacting with Auto-GPT.\"\"\"\n\n    def __init__(\n        self,\n        ai_config: AIConfig,\n        command_registry: CommandRegistry,\n        memory: VectorMemory,\n        triggering_prompt: str,\n        config: Config,\n        cycle_budget: Optional[int] = None,\n        experiment_file: str = None\n    ):\n        super().__init__(\n            ai_config=ai_config,\n            command_registry=command_registry,\n            config=config,\n            default_cycle_instruction=triggering_prompt,\n            cycle_budget=cycle_budget,\n            experiment_file = experiment_file\n        )\n\n        self.memory = memory\n        \"\"\"VectorMemoryProvider used to manage the agent's context (TODO)\"\"\"\n\n        self.workspace = Workspace(config.workspace_path, config.restrict_to_workspace)\n        \"\"\"Workspace that the agent has access to, e.g. for reading/writing files.\"\"\"\n\n        self.created_at = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        \"\"\"Timestamp the agent was created; only used for structured debug logging.\"\"\"\n\n        self.log_cycle_handler = LogCycleHandler()\n        \"\"\"LogCycleHandler for structured debug logging.\"\"\"\n\n    def construct_base_prompt(self, *args, **kwargs) -> ChatSequence:\n        if kwargs.get(\"prepend_messages\") is None:\n            kwargs[\"prepend_messages\"] = []\n\n        # Clock\n        #kwargs[\"prepend_messages\"].append(\n        #    Message(\"system\", f\"The current time and date is {time.strftime('%c')}\"),\n        #)\n\n        # Add budget information (if any) to prompt\n        api_manager = ApiManager()\n        if api_manager.get_total_budget() > 0.0:\n            remaining_budget = (\n                api_manager.get_total_budget() - api_manager.get_total_cost()\n            )\n            if remaining_budget < 0:\n                remaining_budget = 0\n\n            budget_msg = Message(\n                \"system\",\n                f\"Your remaining API budget is ${remaining_budget:.3f}\"\n                + (\n                    \" BUDGET EXCEEDED! SHUT DOWN!\\n\\n\"\n                    if remaining_budget == 0\n                    else \" Budget very nearly exceeded! Shut down gracefully!\\n\\n\"\n                    if remaining_budget < 0.005\n                    else \" Budget nearly exceeded. Finish up.\\n\\n\"\n                    if remaining_budget < 0.01\n                    else \"\"\n                ),\n            )\n            logger.debug(budget_msg)\n\n            if kwargs.get(\"append_messages\") is None:\n                kwargs[\"append_messages\"] = []\n            kwargs[\"append_messages\"].append(budget_msg)\n\n        return super().construct_base_prompt(*args, **kwargs)\n\n    def on_before_think(self, *args, **kwargs) -> ChatSequence:\n        prompt = super().on_before_think(*args, **kwargs)\n\n        self.log_cycle_handler.log_count_within_cycle = 0\n        self.log_cycle_handler.log_cycle(\n            self.ai_config.ai_name,\n            self.created_at,\n            self.cycle_count,\n            self.history.raw(),\n            FULL_MESSAGE_HISTORY_FILE_NAME,\n        )\n        self.log_cycle_handler.log_cycle(\n            self.project_path,\n            self.created_at,\n            self.cycle_count,\n            prompt.raw(),\n            CURRENT_CONTEXT_FILE_NAME,\n        )\n        return prompt\n\n    def execute(\n        self,\n        command_name: str | None,\n        command_args: dict[str, str] | None,\n        user_input: str | None,\n    ) -> str:\n        # Execute command\n        if command_name is not None and command_name.lower().startswith(\"error\"):\n            result = f\"Could not execute command: {command_name}{command_args}\"\n        elif command_name == \"human_feedback\":\n            result = f\"Human feedback: {user_input}\"\n            self.log_cycle_handler.log_cycle(\n                self.ai_config.ai_name,\n                self.created_at,\n                self.cycle_count,\n                user_input,\n                USER_INPUT_FILE_NAME,\n            )\n\n        else:\n            for plugin in self.config.plugins:\n                if not plugin.can_handle_pre_command():\n                    continue\n                command_name, arguments = plugin.pre_command(command_name, command_args)\n            command_result = execute_command(\n                command_name=command_name,\n                arguments=command_args,\n                agent=self,\n            )\n\n            if len(str(command_result)) < 15000:\n                result = f\"Command {command_name} returned: \" f\"{command_result}\"\n            else:\n                result = f\"Command {command_name} returned a lengthy response, we truncated it to the first 15000 characters: \" f\"{str(command_result)[:15000]}\"\n            result_tlength = count_string_tokens(str(command_result), self.llm.name)\n            memory_tlength = count_string_tokens(\n                str(self.history.summary_message()), self.llm.name\n            )\n            #if result_tlength + memory_tlength > self.send_token_limit:\n            #    result = f\"Failure: command {command_name} returned too much output. \\\n            #        Do not execute this command again with the same arguments.\"\n\n            for plugin in self.config.plugins:\n                if not plugin.can_handle_post_command():\n                    continue\n                result = plugin.post_command(command_name, result)\n        # Check if there's a result from the command append it to the message\n        if result is None:\n            self.history.add(\"user\", \"Unable to execute command\", \"action_result\")\n        else:\n            self.history.add(\"user\", result, \"action_result\")\n\n        return result\n\n\n    def parse_and_process_response(\n        self, llm_response: ChatModelResponse, *args, **kwargs\n    ) -> tuple[CommandName | None, CommandArgs | None, AgentThoughts]:\n        if not llm_response.content:\n            raise SyntaxError(\"Assistant response has no text content\")\n        with open(\"experimental_setups/experiments_list.txt\") as eht:\n            exps = eht.read().splitlines()\n\n        with open(os.path.join(\"experimental_setups\", exps[-1], \"responses\", \"model_responses_{}\".format(self.project_path)), \"a+\") as patf:\n            patf.write(llm_response.content)\n        assistant_reply_dict = extract_dict_from_response(llm_response.content)\n\n        if \"command\" not in assistant_reply_dict:\n            assistant_reply_dict[\"command\"] = {\"name\": \"missing_command\", \"args\":{}}\n        command_dict = assistant_reply_dict[\"command\"]\n\n        with open(\"commands_interface.json\") as cif:\n            commands_interface = json.load(cif)\n\n        if command_dict[\"name\"] in list(commands_interface.keys()):\n            ref_args = commands_interface[command_dict[\"name\"]]\n            if isinstance(command_dict[\"args\"], dict):\n                command_args = list(command_dict[\"args\"].keys())\n                new_command_dict = {\"name\": command_dict[\"name\"], \"args\":{}}\n                for k in command_args:\n                    if k in ref_args:\n                        new_command_dict[\"args\"][k] = command_dict[\"args\"][k]\n                \n                unmatched_args = [arg for arg in command_args if arg not in ref_args]\n                unmatched_ref = [arg for arg in ref_args if arg not in list(new_command_dict[\"args\"].keys())]\n\n                for uarg in unmatched_args:\n                    for uref in unmatched_ref:\n                        if uarg in uref:\n                            new_command_dict[\"args\"][uref] = command_dict[\"args\"][uarg]\n                            break\n                \n                if \"project_name\" in new_command_dict[\"args\"]:\n                    if \"_\" in new_command_dict[\"args\"][\"project_name\"]:\n                        name_only = new_command_dict[\"args\"][\"project_name\"].split(\"_\")[0]\n                        new_command_dict[\"args\"][\"project_name\"] = name_only\n                if new_command_dict[\"name\"] in [\n                    \"write_fix\", \n                    \"try_fixes\", \n                    \"read_range\", \n                    \"search_code_base\", \n                    \"get_classes_and_methods\",\n                    \"extract_similar_functions_calls\",\n                    \"extract_method_code\",\n                    \"extract_test_code\"]:\n                    new_command_dict[\"args\"][\"project_name\"] = self.project_name\n                    new_command_dict[\"args\"][\"bug_index\"] = self.bug_index\n\n                assistant_reply_dict[\"command\"] = new_command_dict\n            else:\n                assistant_reply_dict[\"command\"] = {\"name\": \"unknown_command\", \"args\":{}}\n        valid, errors = validate_dict(assistant_reply_dict, self.config)\n        if not valid:\n            raise SyntaxError(\n                \"Validation of response failed:\\n  \"\n                + \";\\n  \".join([str(e) for e in errors])\n            )\n\n        for plugin in self.config.plugins:\n            if not plugin.can_handle_post_planning():\n                continue\n            assistant_reply_dict = plugin.post_planning(assistant_reply_dict)\n\n        response = None, None, assistant_reply_dict\n\n        # Print Assistant thoughts\n        if assistant_reply_dict != {}:\n            # Get command name and arguments\n            try:\n                command_name, arguments = extract_command(\n                    assistant_reply_dict, llm_response, self.config\n                )\n                response = command_name, arguments, assistant_reply_dict\n            except Exception as e:\n                logger.error(\"Error: \\n\", str(e))\n\n        self.log_cycle_handler.log_cycle(\n            self.ai_config.ai_name,\n            self.created_at,\n            self.cycle_count,\n            assistant_reply_dict,\n            NEXT_ACTION_FILE_NAME,\n        )\n        return response\n\ndef extract_command(\n    assistant_reply_json: dict, assistant_reply: ChatModelResponse, config: Config\n) -> tuple[str, dict[str, str]]:\n    \"\"\"Parse the response and return the command name and arguments\n\n    Args:\n        assistant_reply_json (dict): The response object from the AI\n        assistant_reply (ChatModelResponse): The model response from the AI\n        config (Config): The config object\n\n    Returns:\n        tuple: The command name and arguments\n\n    Raises:\n        json.decoder.JSONDecodeError: If the response is not valid JSON\n\n        Exception: If any other error occurs\n    \"\"\"\n    if config.openai_functions:\n        if assistant_reply.function_call is None:\n            return \"Error:\", {\"message\": \"No 'function_call' in assistant reply\"}\n        assistant_reply_json[\"command\"] = {\n            \"name\": assistant_reply.function_call.name,\n            \"args\": json.loads(assistant_reply.function_call.arguments),\n        }\n    try:\n        if \"command\" not in assistant_reply_json:\n            return \"Error:\", {\"message\": \"Missing 'command' object in JSON\"}\n\n        if not isinstance(assistant_reply_json, dict):\n            return (\n                \"Error:\",\n                {\n                    \"message\": f\"The previous message sent was not a dictionary {assistant_reply_json}\"\n                },\n            )\n\n        command = assistant_reply_json[\"command\"]\n        if not isinstance(command, dict):\n            return \"Error:\", {\"message\": \"'command' object is not a dictionary\"}\n\n        if \"name\" not in command:\n            return \"Error:\", {\"message\": \"Missing 'name' field in 'command' object\"}\n\n        command_name = command[\"name\"]\n\n        # Use an empty dictionary if 'args' field is not present in 'command' object\n        arguments = command.get(\"args\", {})\n\n        return command_name, arguments\n    except json.decoder.JSONDecodeError:\n        return \"Error:\", {\"message\": \"Invalid JSON\"}\n    # All other errors, return \"Error: + error message\"\n    except Exception as e:\n        return \"Error:\", {\"message\": str(e)}\n\n\ndef execute_command(\n    command_name: str,\n    arguments: dict[str, str],\n    agent: Agent,\n) -> Any:\n    \"\"\"Execute the command and return the result\n\n    Args:\n        command_name (str): The name of the command to execute\n        arguments (dict): The arguments for the command\n        agent (Agent): The agent that is executing the command\n\n    Returns:\n        str: The result of the command\n    \"\"\"\n    try:\n        # Execute a native command with the same name or alias, if it exists\n        if command := agent.command_registry.get_command(command_name):\n            return command(**arguments, agent=agent)\n\n        # Handle non-native commands (e.g. from plugins)\n        for command in agent.ai_config.prompt_generator.commands:\n            if (\n                command_name == command.label.lower()\n                or command_name == command.name.lower()\n            ):\n                return command.function(**arguments)\n\n        return f\"Cannot execute '{command_name}': unknown command.\" + \" Do not try to use this command again.\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n"}
{"type": "source_file", "path": "autogpt/app/utils.py", "content": "import os\nimport re\n\nimport requests\nfrom colorama import Fore, Style\nfrom git.repo import Repo\nfrom prompt_toolkit import ANSI, PromptSession\nfrom prompt_toolkit.history import InMemoryHistory\n\nfrom autogpt.config import Config\nfrom autogpt.logs import logger\n\nsession = PromptSession(history=InMemoryHistory())\n\n\ndef clean_input(config: Config, prompt: str = \"\", talk=False):\n    try:\n        if config.chat_messages_enabled:\n            for plugin in config.plugins:\n                if not hasattr(plugin, \"can_handle_user_input\"):\n                    continue\n                if not plugin.can_handle_user_input(user_input=prompt):\n                    continue\n                plugin_response = plugin.user_input(user_input=prompt)\n                if not plugin_response:\n                    continue\n                if plugin_response.lower() in [\n                    \"yes\",\n                    \"yeah\",\n                    \"y\",\n                    \"ok\",\n                    \"okay\",\n                    \"sure\",\n                    \"alright\",\n                ]:\n                    return config.authorise_key\n                elif plugin_response.lower() in [\n                    \"no\",\n                    \"nope\",\n                    \"n\",\n                    \"negative\",\n                ]:\n                    return config.exit_key\n                return plugin_response\n\n        # ask for input, default when just pressing Enter is y\n        logger.info(\"Asking user via keyboard...\")\n\n        # handle_sigint must be set to False, so the signal handler in the\n        # autogpt/main.py could be employed properly. This referes to\n        # https://github.com/Significant-Gravitas/Auto-GPT/pull/4799/files/3966cdfd694c2a80c0333823c3bc3da090f85ed3#r1264278776\n        answer = session.prompt(ANSI(prompt), handle_sigint=False)\n        return answer\n    except KeyboardInterrupt:\n        logger.info(\"You interrupted Auto-GPT\")\n        logger.info(\"Quitting...\")\n        exit(0)\n\n\ndef get_bulletin_from_web():\n    try:\n        response = requests.get(\n            \"https://raw.githubusercontent.com/Significant-Gravitas/Auto-GPT/master/BULLETIN.md\"\n        )\n        if response.status_code == 200:\n            return response.text\n    except requests.exceptions.RequestException:\n        pass\n\n    return \"\"\n\n\ndef get_current_git_branch() -> str:\n    try:\n        repo = Repo(search_parent_directories=True)\n        branch = repo.active_branch\n        return branch.name\n    except:\n        return \"\"\n\n\ndef get_latest_bulletin() -> tuple[str, bool]:\n    exists = os.path.exists(\"data/CURRENT_BULLETIN.md\")\n    current_bulletin = \"\"\n    if exists:\n        current_bulletin = open(\n            \"data/CURRENT_BULLETIN.md\", \"r\", encoding=\"utf-8\"\n        ).read()\n    new_bulletin = get_bulletin_from_web()\n    is_new_news = new_bulletin != \"\" and new_bulletin != current_bulletin\n\n    news_header = Fore.YELLOW + \"Welcome to Auto-GPT!\\n\"\n    if new_bulletin or current_bulletin:\n        news_header += (\n            \"Below you'll find the latest Auto-GPT News and updates regarding features!\\n\"\n            \"If you don't wish to see this message, you \"\n            \"can run Auto-GPT with the *--skip-news* flag.\\n\"\n        )\n\n    if new_bulletin and is_new_news:\n        open(\"data/CURRENT_BULLETIN.md\", \"w\", encoding=\"utf-8\").write(new_bulletin)\n        current_bulletin = f\"{Fore.RED}::NEW BULLETIN::{Fore.RESET}\\n\\n{new_bulletin}\"\n\n    return f\"{news_header}\\n{current_bulletin}\", is_new_news\n\n\ndef markdown_to_ansi_style(markdown: str):\n    ansi_lines: list[str] = []\n    for line in markdown.split(\"\\n\"):\n        line_style = \"\"\n\n        if line.startswith(\"# \"):\n            line_style += Style.BRIGHT\n        else:\n            line = re.sub(\n                r\"(?<!\\*)\\*(\\*?[^*]+\\*?)\\*(?!\\*)\",\n                rf\"{Style.BRIGHT}\\1{Style.NORMAL}\",\n                line,\n            )\n\n        if re.match(r\"^#+ \", line) is not None:\n            line_style += Fore.CYAN\n            line = re.sub(r\"^#+ \", \"\", line)\n\n        ansi_lines.append(f\"{line_style}{line}{Style.RESET_ALL}\")\n    return \"\\n\".join(ansi_lines)\n\n\ndef get_legal_warning() -> str:\n    legal_text = \"\"\"\n## DISCLAIMER AND INDEMNIFICATION AGREEMENT\n### PLEASE READ THIS DISCLAIMER AND INDEMNIFICATION AGREEMENT CAREFULLY BEFORE USING THE AUTOGPT SYSTEM. BY USING THE AUTOGPT SYSTEM, YOU AGREE TO BE BOUND BY THIS AGREEMENT.\n\n## Introduction\nAutoGPT (the \"System\") is a project that connects a GPT-like artificial intelligence system to the internet and allows it to automate tasks. While the System is designed to be useful and efficient, there may be instances where the System could perform actions that may cause harm or have unintended consequences.\n\n## No Liability for Actions of the System\nThe developers, contributors, and maintainers of the AutoGPT project (collectively, the \"Project Parties\") make no warranties or representations, express or implied, about the System's performance, accuracy, reliability, or safety. By using the System, you understand and agree that the Project Parties shall not be liable for any actions taken by the System or any consequences resulting from such actions.\n\n## User Responsibility and Respondeat Superior Liability\nAs a user of the System, you are responsible for supervising and monitoring the actions of the System while it is operating on your\nbehalf. You acknowledge that using the System could expose you to potential liability including but not limited to respondeat superior and you agree to assume all risks and liabilities associated with such potential liability.\n\n## Indemnification\nBy using the System, you agree to indemnify, defend, and hold harmless the Project Parties from and against any and all claims, liabilities, damages, losses, or expenses (including reasonable attorneys' fees and costs) arising out of or in connection with your use of the System, including, without limitation, any actions taken by the System on your behalf, any failure to properly supervise or monitor the System, and any resulting harm or unintended consequences.\n            \"\"\"\n    return legal_text\n"}
{"type": "source_file", "path": "autogpt/core/ability/builtins/__init__.py", "content": "from autogpt.core.ability.builtins.create_new_ability import CreateNewAbility\nfrom autogpt.core.ability.builtins.query_language_model import QueryLanguageModel\n\nBUILTIN_ABILITIES = {\n    QueryLanguageModel.name(): QueryLanguageModel,\n}\n"}
{"type": "source_file", "path": "autogpt/commands/collect_info.py", "content": "\"\"\"Commands to execute code\"\"\"\n\nCOMMAND_CATEGORY = \"collect_info\"\nCOMMAND_CATEGORY_TITLE = \"INFO COLLECTION\"\n\nimport os\nimport subprocess\nimport re\nimport json\nimport random\nimport time\n\nimport docker\nfrom docker.errors import DockerException, ImageNotFound\nfrom docker.models.containers import Container as DockerContainer\n\nfrom autogpt.agents.agent import Agent\nfrom autogpt.command_decorator import command\nfrom autogpt.logs import logger\n\nimport javalang\nfrom create_files_index import list_java_files\n\nALLOWLIST_CONTROL = \"allowlist\"\nDENYLIST_CONTROL = \"denylist\"\n\n\n\"\"\"@command(\n    \"extract_installation_instructions_from_readme_file\",\n    \"Allows you to extract any installation related instructions that are metioned in the README file of the project\",\n    {\n        \"project_path\": {\n            \"type\": \"string\",\n            \"description\": \"The name/path of the project under scope\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\ndef extract_instructions_from_readme(agent: Agent) -> str:\n    \"\"\"\n    \"\"\"\n    ai_name = agent.ai_config.ai_name\n    workspace = \"execution_agent_workspace/\"\n    files_at_root = os.listdir(os.path.join(workspace, project_path))\n    project_path = agent.project_path\n\n    readme_files = []\n    for f in files_at_root:\n        if \"readme\" in f.lower():\n            readme_files.append(f)\n\n    readme_text = \"\"\n\n    for f in readme_files:\n        with open(os.path.join(workspace, project_path, f)) as wpf:\n            readme_text += \"------>File: {}\\n{}\\n\".format(f, wpf.read())\n    \n    if readme_text == \"\":\n        return \"No readme file found\"\n    \n    system_prompt = \"You are an AI assistant that would help a develper in the mission of installing a python project an getting to run. Your task for now is to analyze the text of the readme file of the target project and extract installation related instructions from the given text of readme file(s).\"\n\n    query = \"Here is the content of the readme file(s). Please extract any information related to installation including step-by-step points, environement, required software and their versions and also any manaual steps that needs to be done.\\n\\n\" + readme_text\n\n    return ask_chatgpt(query, system_prompt)\n\n\"\"\"@command(\n    \"identify_testing_framework\",\n    \"Read all the requirements from requirements files\",\n    {\n        \"project_path\": {\n            \"type\": \"string\",\n            \"description\": \"The name/path of the project under scope\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\n\ndef identify_testing_framework(project_path: str, agent: Agent) -> str:\n    \"\"\"\n    \"\"\"\n\n    ai_name = agent.ai_config.ai_name\n    pass\n\n\n\"\"\"@command(\n    \"extract_installation_documentation\",\n    \"Read all the requirements from requirements files\",\n    {\n        \"project_path\": {\n            \"type\": \"string\",\n            \"description\": \"The name/path of the project under scope\",\n            \"required\": True,\n        }\n    },\n)\"\"\"\ndef extract_installation_documentation(project_path: str, agent: Agent) -> str:\n    \"\"\"\n    \"\"\"\n\n    ai_name = agent.ai_config.ai_name\n    pass\n\n\ndef ask_chatgpt(query, system_message, model=\"gpt-4o-mini\"):\n    with open(\"openai_token.txt\") as opt:\n        token = opt.read()\n    chat = ChatOpenAI(openai_api_key=token, model=model)\n\n    messages = [\n        SystemMessage(\n            content= system_message\n                    ),\n        HumanMessage(\n            content=query\n            )  \n    ]\n    #response_format={ \"type\": \"json_object\" }\n    response = chat.invoke(messages)\n\n    return response.content\n"}
{"type": "source_file", "path": "autogpt/core/ability/builtins/file_operations.py", "content": "import logging\nimport os\n\nfrom autogpt.core.ability.base import Ability, AbilityConfiguration\nfrom autogpt.core.ability.schema import AbilityResult, ContentType, Knowledge\nfrom autogpt.core.workspace import Workspace\n\n\nclass ReadFile(Ability):\n    default_configuration = AbilityConfiguration(\n        packages_required=[\"unstructured\"],\n        workspace_required=True,\n    )\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        workspace: Workspace,\n    ):\n        self._logger = logger\n        self._workspace = workspace\n\n    @property\n    def description(self) -> str:\n        return \"Read and parse all text from a file.\"\n\n    @property\n    def arguments(self) -> dict:\n        return {\n            \"filename\": {\n                \"type\": \"string\",\n                \"description\": \"The name of the file to read.\",\n            },\n        }\n\n    def _check_preconditions(self, filename: str) -> AbilityResult | None:\n        message = \"\"\n        try:\n            pass\n        except ImportError:\n            message = \"Package charset_normalizer is not installed.\"\n\n        try:\n            file_path = self._workspace.get_path(filename)\n            if not file_path.exists():\n                message = f\"File {filename} does not exist.\"\n            if not file_path.is_file():\n                message = f\"{filename} is not a file.\"\n        except ValueError as e:\n            message = str(e)\n\n        if message:\n            return AbilityResult(\n                ability_name=self.name(),\n                ability_args={\"filename\": filename},\n                success=False,\n                message=message,\n                data=None,\n            )\n\n    def __call__(self, filename: str) -> AbilityResult:\n        if result := self._check_preconditions(filename):\n            return result\n\n        from unstructured.partition.auto import partition\n\n        file_path = self._workspace.get_path(filename)\n        try:\n            elements = partition(str(file_path))\n            # TODO: Lots of other potentially useful information is available\n            #   in the partitioned file. Consider returning more of it.\n            new_knowledge = Knowledge(\n                content=\"\\n\\n\".join([element.text for element in elements]),\n                content_type=ContentType.TEXT,\n                content_metadata={\"filename\": filename},\n            )\n            success = True\n            message = f\"File {file_path} read successfully.\"\n        except IOError as e:\n            new_knowledge = None\n            success = False\n            message = str(e)\n\n        return AbilityResult(\n            ability_name=self.name(),\n            ability_args={\"filename\": filename},\n            success=success,\n            message=message,\n            new_knowledge=new_knowledge,\n        )\n\n\nclass WriteFile(Ability):\n    default_configuration = AbilityConfiguration(\n        packages_required=[\"unstructured\"],\n        workspace_required=True,\n    )\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        workspace: Workspace,\n    ):\n        self._logger = logger\n        self._workspace = workspace\n\n    @property\n    def description(self) -> str:\n        return \"Write text to a file.\"\n\n    @property\n    def arguments(self) -> dict:\n        return {\n            \"filename\": {\n                \"type\": \"string\",\n                \"description\": \"The name of the file to write.\",\n            },\n            \"contents\": {\n                \"type\": \"string\",\n                \"description\": \"The contents of the file to write.\",\n            },\n        }\n\n    def _check_preconditions(\n        self, filename: str, contents: str\n    ) -> AbilityResult | None:\n        message = \"\"\n        try:\n            file_path = self._workspace.get_path(filename)\n            if file_path.exists():\n                message = f\"File {filename} already exists.\"\n            if len(contents):\n                message = f\"File {filename} was not given any content.\"\n        except ValueError as e:\n            message = str(e)\n\n        if message:\n            return AbilityResult(\n                ability_name=self.name(),\n                ability_args={\"filename\": filename, \"contents\": contents},\n                success=False,\n                message=message,\n                data=None,\n            )\n\n    def __call__(self, filename: str, contents: str) -> AbilityResult:\n        if result := self._check_preconditions(filename, contents):\n            return result\n\n        file_path = self._workspace.get_path(filename)\n        try:\n            directory = os.path.dirname(file_path)\n            os.makedirs(directory)\n            with open(filename, \"w\", encoding=\"utf-8\") as f:\n                f.write(contents)\n            success = True\n            message = f\"File {file_path} written successfully.\"\n        except IOError as e:\n            success = False\n            message = str(e)\n\n        return AbilityResult(\n            ability_name=self.name(),\n            ability_args={\"filename\": filename},\n            success=success,\n            message=message,\n        )\n"}
{"type": "source_file", "path": "autogpt/core/agent/base.py", "content": "import abc\nimport logging\nfrom pathlib import Path\n\n\nclass Agent(abc.ABC):\n    @abc.abstractmethod\n    def __init__(self, *args, **kwargs):\n        ...\n\n    @classmethod\n    @abc.abstractmethod\n    def from_workspace(\n        cls,\n        workspace_path: Path,\n        logger: logging.Logger,\n    ) -> \"Agent\":\n        ...\n\n    @abc.abstractmethod\n    async def determine_next_ability(self, *args, **kwargs):\n        ...\n\n    @abc.abstractmethod\n    def __repr__(self):\n        ...\n"}
{"type": "source_file", "path": "autogpt/agents/base.py", "content": "from __future__ import annotations\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport pexpect\nimport time\n\nimport re\nfrom abc import ABCMeta, abstractmethod\nfrom typing import TYPE_CHECKING, Any, Literal, Optional\nimport json\nimport os\nimport subprocess\n\nif TYPE_CHECKING:\n    from autogpt.config import AIConfig, Config\n\n    from autogpt.models.command_registry import CommandRegistry\n\nfrom autogpt.llm.base import ChatModelResponse, ChatSequence, Message\nfrom autogpt.llm.providers.openai import OPEN_AI_CHAT_MODELS, get_openai_command_specs\nfrom autogpt.llm.utils import count_message_tokens, create_chat_completion\nfrom autogpt.logs import logger\nfrom autogpt.memory.message_history import MessageHistory\nfrom autogpt.prompts.prompt import DEFAULT_TRIGGERING_PROMPT\nfrom autogpt.json_utils.utilities import extract_dict_from_response\nfrom autogpt.commands.info_collection_static import collect_requirements, infer_requirements, extract_instructions_from_readme\nfrom autogpt.commands.docker_helpers_static import start_container, remove_ansi_escape_sequences, ask_chatgpt\nfrom autogpt.commands.search_documentation import search_install_doc\n\nCommandName = str\nCommandArgs = dict[str, str]\nAgentThoughts = dict[str, Any]\n\nclass BaseAgent(metaclass=ABCMeta):\n    \"\"\"Base class for all Auto-GPT agents.\"\"\"\n\n    ThoughtProcessID = Literal[\"one-shot\"]\n\n    def __init__(\n        self,\n        ai_config: AIConfig,\n        command_registry: CommandRegistry,\n        config: Config,\n        big_brain: bool = True,\n        default_cycle_instruction: str = DEFAULT_TRIGGERING_PROMPT,\n        cycle_budget: Optional[int] = 1,\n        send_token_limit: Optional[int] = None,\n        summary_max_tlength: Optional[int] = None,\n        experiment_file: str = None\n    ):\n        self.experiment_file = experiment_file\n        self.ai_config = ai_config\n        \"\"\"The AIConfig or \"personality\" object associated with this agent.\"\"\"\n\n        self.command_registry = command_registry\n        \"\"\"The registry containing all commands available to the agent.\"\"\"\n\n        self.config = config\n        \"\"\"The applicable application configuration.\"\"\"\n\n        self.big_brain = big_brain\n        \"\"\"\n        Whether this agent uses the configured smart LLM (default) to think,\n        as opposed to the configured fast LLM.\n        \"\"\"\n\n        self.default_cycle_instruction = default_cycle_instruction\n        \"\"\"The default instruction passed to the AI for a thinking cycle.\"\"\"\n\n        self.cycle_budget = cycle_budget\n        \"\"\"\n        The number of cycles that the agent is allowed to run unsupervised.\n\n        `None` for unlimited continuous execution,\n        `1` to require user approval for every step,\n        `0` to stop the agent.\n        \"\"\"\n\n        self.cycles_remaining = cycle_budget\n        \"\"\"The number of cycles remaining within the `cycle_budget`.\"\"\"\n\n        self.cycle_count = 0\n        \"\"\"The number of cycles that the agent has run since its initialization.\"\"\"\n        \n        with open(experiment_file) as hper:\n            self.hyperparams = json.load(hper)\n\n        ## Newly added experimental\n        with open(\"customize.json\") as cfile:\n            self.customize = json.load(cfile)\n\n        self.prompt_dictionary = ai_config.construct_full_prompt(config)\n        \n\n        ### Read static prompt files\n        prompt_files = \"./prompt_files\"\n        with open(os.path.join(prompt_files, \"python_guidelines\")) as pgl:\n            self.python_guidelines = pgl.read()\n        with open(os.path.join(prompt_files, \"java_guidelines\")) as pgl:\n            self.java_guidelines = pgl.read()\n        with open(os.path.join(prompt_files, \"javascript_guidelines\")) as pgl:\n            self.javascript_guidelines = pgl.read()\n        with open(os.path.join(prompt_files, \"c_guidelines\")) as pgl:\n            self.c_guidelines = pgl.read()\n        with open(os.path.join(prompt_files, \"cpp_guidelines\")) as pgl:\n            self.cpp_guidelines = pgl.read()\n        with open(os.path.join(prompt_files, \"rust_guidelines\")) as pgl:\n            self.rust_guidelines = pgl.read()\n\n        with open(os.path.join(prompt_files, \"tools_list\")) as tls:\n            self.prompt_dictionary[\"commands\"] = tls.read()\n\n        if self.customize[\"LANGUAGE_GUIDELINES\"]:\n            if self.hyperparams[\"language\"].lower() == \"python\":\n                self.prompt_dictionary[\"general_guidelines\"]= self.python_guidelines\n            elif self.hyperparams[\"language\"].lower() == \"java\":\n                self.prompt_dictionary[\"general_guidelines\"]= self.java_guidelines\n            elif self.hyperparams[\"language\"].lower() == \"javascript\":\n                self.prompt_dictionary[\"general_guidelines\"]= self.javascript_guidelines\n            elif self.hyperparams[\"language\"].lower() in [\"c\", \"c++\"]:\n                self.prompt_dictionary[\"general_guidelines\"]= self.c_guidelines\n        else:\n            self.prompt_dictionary[\"general_guidelines\"]= \"\"\n        \n        if self.customize[\"GENERAL_GUIDELINES\"]:\n            self.prompt_dictionary[\"general_guidelines\"]  += \"\\nWhen debugging a problem, if an approach does not work for multiple consecutibe iterations, think of changing your approach of addressing the problem.\\n\"\n            \n        #self.prompt_dictionary[\"general_guidelines\"] = \"\"\n        \n        \"\"\"\n        The system prompt sets up the AI's personality and explains its goals,\n        available resources, and restrictions.\"\"\"\n\n        llm_name = self.config.smart_llm if self.big_brain else self.config.fast_llm\n        self.llm = OPEN_AI_CHAT_MODELS[llm_name]\n        \"\"\"The LLM that the agent uses to think.\"\"\"\n\n        self.send_token_limit = send_token_limit or self.llm.max_tokens * 3 // 4\n        \"\"\"\n        The token limit for prompt construction. Should leave room for the completion;\n        defaults to 75% of `llm.max_tokens`.\n        \"\"\"\n\n        self.history = MessageHistory(\n            self.llm,\n            max_summary_tlength=summary_max_tlength or self.send_token_limit // 6,\n        )\n\n        self.project_path = self.hyperparams[\"project_path\"]\n        self.project_url = self.hyperparams[\"project_url\"]\n        self.language = self.hyperparams[\"language\"]\n        self.workspace_path = \"execution_agent_workspace\"\n        self.keep_container = True if self.hyperparams[\"keep_container\"] == \"TRUE\" else False\n        \n        self.current_step = \"1\"\n        self.steps_list = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n        \n        with open(os.path.join(prompt_files, \"steps_list.json\")) as slj:\n            self.steps_object = json.load(slj)\n        \n        self.cycle_type = \"CMD\"\n        self.tests_executed = False\n\n        with open(os.path.join(prompt_files, \"cycle_instruction\")) as cit:\n            self.cmd_cycle_instruction = cit.read()\n\n        with open(os.path.join(prompt_files, \"summarize_cycle\")) as cit:\n            self.summary_cycle_instruction = cit.read()\n        \n        with open(\"experimental_setups/experiments_list.txt\") as eht:\n            self.exp_number = eht.read().splitlines()[-1]\n\n        self.track_budget = True\n        self.left_commands = 0\n        self.max_budget = -1\n\n        self.shell = pexpect.spawnu('/bin/bash')\n        self.interact_with_shell(\"cd {}\".format(os.path.join(self.workspace_path, self.project_path)))\n\n        self.commands_and_summary = []\n        self.written_files = []\n\n        self.container = None\n\n        if self.hyperparams[\"image\"] != \"NIL\" and 1 == 0:\n            self.container = start_container(self.hyperparams[\"image\"])\n            if self.container == None:\n                logger.info(\"ERROR HAPPENED WHILE CREATING THE CONTAINER\")\n                self.hyperparams[\"image\"] = \"NIL\"\n\n        self.found_workflows = self.find_workflows(self.project_path)\n        self.search_results = self.search_documentation()\n        self.dockerfiles = self.find_dockerfiles()\n        self.command_stuck = False\n\n\n    def to_dict(self):\n        return {\n            \"experiment_file\": self.experiment_file,\n            \"ai_config\": str(self.ai_config),  # Assuming this is a complex object\n            \"command_registry\": str(self.command_registry),  # Assuming this is a complex object\n            \"config\": str(self.config),  # Assuming this is a complex object\n            \"big_brain\": self.big_brain,\n            \"default_cycle_instruction\": self.default_cycle_instruction,\n            \"cycle_budget\": self.cycle_budget,\n            \"cycles_remaining\": self.cycles_remaining,\n            \"cycle_count\": self.cycle_count,\n            \"hyperparams\": self.hyperparams,\n            \"prompt_dictionary\": self.prompt_dictionary,\n            \"llm\": str(self.llm),  # Assuming this is a complex object\n            \"send_token_limit\": self.send_token_limit,\n            \"project_path\": self.project_path,\n            \"project_url\": self.project_url,\n            \"language\": self.language,\n            \"workspace_path\": self.workspace_path,\n            \"current_step\": self.current_step,\n            \"steps_list\": self.steps_list,\n            \"steps_object\": self.steps_object,\n            \"cycle_type\": self.cycle_type,\n            \"tests_executed\": self.tests_executed,\n            \"cmd_cycle_instruction\": self.cmd_cycle_instruction,\n            \"summary_cycle_instruction\": self.summary_cycle_instruction,\n            \"exp_number\": self.exp_number,\n            \"track_budget\": self.track_budget,\n            \"left_commands\": self.left_commands,\n            \"max_budget\": self.max_budget,\n            \"container\": str(self.container),  # Assuming this is a complex object\n            \"found_workflows\": self.found_workflows,\n            \"search_results\": self.search_results,\n            \"dockerfiles\": self.dockerfiles,\n        }\n\n    def save_to_file(self, filename):\n        # Save object attributes as JSON to a file\n        with open(filename, 'w') as file:\n            json.dump(self.to_dict(), file, indent=4)\n\n    def workflow_to_script(self, workflow_path):\n        system_prompt = \"This is the content of a workflow file used to run a test workflow for a repository. I want you to turn the file into a '.sh' script that I can use on my machine to prepare and run tests of that specific repository (the file might contain multiple configurations, I want a simple configuration for linux ubuntu). The workflow might be irrelevant or contain no steps for building and testing. In such case, just mention that the script is not about setting up the project for running tests.\"\n\n        with open(workflow_path) as wpth:\n            query = wpth.read()\n\n        return ask_chatgpt(system_prompt, query)\n\n    def search_documentation(self,):\n        if os.path.exists(\"search_logs/{}\".format(self.project_path)):\n            with open(os.path.join(\"search_logs\", self.project_path, \"{}_build_install_from_source.json\".format(self.project_path))) as bifs:\n                results = json.load(bifs)\n            return json.dumps(results)\n        results = search_install_doc(self.project_path)\n        return json.dumps(results)\n\n    def find_dockerfiles(self,):\n        DOCKERFILE_NAME = \"Dockerfile\"\n        PROJ_DIR = \"execution_agent_workspace/{}\".format(self.project_path)\n        try:\n            # Run the find command to locate Dockerfile scripts\n            result = subprocess.run(\n                [\"find\", PROJ_DIR, \"-name\", DOCKERFILE_NAME],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True\n            )\n\n            if result.returncode != 0:\n                print(f\"Error finding Dockerfiles: {result.stderr}\")\n                return\n\n            # Process the list of found files\n            dockerfiles = result.stdout.splitlines()\n\n            return dockerfiles\n\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return []\n            \n    def find_workflows(self, project_name):\n        found_files = []\n        WORKFLOW_DIR = \"execution_agent_workspace/{}/.github/workflows\".format(project_name)\n        KEYWORDS = [\"test\", \"build\", \"linux\", \"unittest\", \"integration\", \"deploy\"]\n        if not os.path.isdir(WORKFLOW_DIR):\n            print(f\"The directory {WORKFLOW_DIR} does not exist.\")\n            return\n\n        print(f\"Searching for test-related workflows in {WORKFLOW_DIR}...\")\n\n        # Find all YAML workflow files in the .github/workflows directory\n        try:\n            result = subprocess.run(\n                [\"find\", WORKFLOW_DIR, \"-name\", \"*.yml\", \"-o\", \"-name\", \"*.yaml\"],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True\n            )\n\n            if result.returncode != 0:\n                print(f\"Error finding files: {result.stderr}\")\n                return []\n\n            # Process the list of found files\n            workflow_files = result.stdout.splitlines()\n\n            for file in workflow_files:\n                # Extract the file name from the full path\n                filename = os.path.basename(file).lower()\n                # Check if any of the keywords are in the file name\n                if any(keyword in filename for keyword in KEYWORDS):\n                    found_files.append(file)\n\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n\n        return found_files\n\n\n    def remove_progress_bars(self, text):\n        try:\n            with open(\"prompt_files/remove_progress_bars\") as rpb:\n                system_prompt= rpb.read()\n            summary = \"\"\n            for i in range(int(len(text)/100000)+1):\n                query= \"Here is the output of a command that you should clean:\\n\"+ text[i*100000: (i+1)*100000]\n                summary += \"\\n\" + ask_chatgpt(query, system_prompt)\n                print(\"CLEANED 100K CHARACTERS.........\")\n                print(\"LEN CLEANED:\", len(summary))\n        except Exception as e:\n            print(\"ERRRRRROOOOOOOOOOOR IN PROGRESSSSSSSSSS:\", e)\n        return summary\n\n\n    def interact_with_shell(self, command):\n        try:\n            self.shell.sendline(command)\n            self.shell.expect(\"\\$ \", timeout=1500)\n            self.shell.sendline(\"pwd\")\n            self.shell.expect(\"\\$ \", timeout=1500)\n        except Exception as e:\n            return (\"Error happened: {}\".format(e), None)\n        return remove_ansi_escape_sequences(self.shell.before), remove_ansi_escape_sequences(self.shell.after)\n\n    def validate_command_parsing(self, command_dict):\n        with open(\"commands_interface.json\") as cif:\n            commands_interface = json.load(cif)\n\n        command_dict = command_dict[\"command\"]\n        if command_dict[\"name\"] in list(commands_interface.keys()):\n            ref_args = commands_interface[command_dict[\"name\"]]\n            if isinstance(command_dict[\"args\"], dict):\n                command_args = list(command_dict[\"args\"].keys())\n                if set(command_args) == set(ref_args):\n                    return True\n                else:\n                    return False\n            else:\n                return False\n        else:\n            return False\n        \n    def detect_command_repetition(self, ref_cmd):\n        #TODO(\"change this\")\n        return False\n        assistant_outputs = [str(extract_dict_from_response(msg.content)[\"command\"]) for msg in self.history if msg.role == \"assistant\"]\n        with open(\"assistant_output_from_command_repetition.json\", \"w\") as aocr:\n            json.dump(assistant_outputs+[str(ref_cmd[\"command\"])], aocr)\n        try:\n            if str(ref_cmd[\"command\"]) in assistant_outputs:\n                logger.info(\"REPETITION DETECTED !!! CODE 2\")\n                return True\n            else:\n                return False\n        except Exception as e:\n            with open(\"exception_files.txt\", \"w\") as ef:\n                ef.write(str(e))\n            print(\"Exception raised,\", e)\n            return False\n        \n    def handle_command_repitition(self, repeated_command: dict, handling_strategy: str = \"\"):\n        if handling_strategy == \"\":\n            return \"\"\n        elif handling_strategy == \"RESTRICT\":\n            return \"Your next command should be totally different from this command: {}\".format(repeated_command[\"command\"])\n        elif handling_strategy == \"TOP3\":\n            return \"Suggest three commands that would make sense to execute given your current input. Give the full json object of each command with all attributes, put the three commands in a list, i.e, [{...}, {...}, {...}]. Do not add any text explanataion before or after the list of the three commands.\"\n        else:\n            raise ValueError(\"The value given to the param handling_strategy is unsuported: {}\".format(handling_strategy))\n\n    def think(\n        self,\n        instruction: Optional[str] = None,\n        thought_process_id: ThoughtProcessID = \"one-shot\",\n    ) -> tuple[CommandName | None, CommandArgs | None, AgentThoughts]:\n        \"\"\"Runs the agent for one cycle.\n\n        Params:\n            instruction: The instruction to put at the end of the prompt.\n\n        Returns:\n            The command name and arguments, if any, and the agent's thoughts.\n        \"\"\"\n\n        instruction = instruction or self.default_cycle_instruction\n\n        prompt: ChatSequence = self.construct_prompt(instruction, thought_process_id)\n        prompt = self.on_before_think(prompt, thought_process_id, instruction)\n        \n        ## This is a line added by me to save prompts at each step\n        self.prompt_text = prompt.dump()\n        #logger.info(\"CURRENT DIRECTORY {}\".format(os.getcwd()))\n        \n\n        with open(os.path.join(\"experimental_setups\", self.exp_number, \"logs\", \"prompt_history_{}\".format(self.project_path.replace(\"/\", \"\"))), \"a+\") as patf:\n            patf.write(prompt.dump())\n        \n        with open(os.path.join(\"experimental_setups\", self.exp_number, \"logs\", \"cycles_list_{}\".format(self.project_path.replace(\"/\", \"\"))), \"a+\") as patf:\n            patf.write(self.cycle_type+\"\\n\")\n        # handle querying strategy\n        # For now, we do not evaluate the external query\n        # we just want to observe how good is it\n    \n        raw_response = create_chat_completion(\n            prompt,\n            self.config,\n            functions=get_openai_command_specs(self.command_registry)\n            if self.config.openai_functions\n            else None,\n        )\n        \n        try:\n            response_dict = extract_dict_from_response(\n                raw_response.content\n            )\n            repetition = self.detect_command_repetition(response_dict)\n            if repetition:\n                logger.info(\"REPETITION DETECTED, WARNING CODE RR1\")\n                logger.info(str(self.handle_command_repitition(response_dict, self.hyperparams[\"repetition_handling\"])))\n                prompt.extend([Message(\"user\", self.handle_command_repitition(response_dict, self.hyperparams[\"repetition_handling\"]))])\n                new_response = create_chat_completion(\n                        prompt,\n                        self.config,\n                        functions=get_openai_command_specs(self.command_registry)\n                        if self.config.openai_functions\n                        else None,\n                    )\n                if self.hyperparams[\"repetition_handling\"] == \"TOP3\":\n                    top3_list = json.loads(new_response.content)\n                    for r in top3_list:\n                        repetition = self.detect_command_repetition(r)\n                        if not repetition:\n                            raw_response = Message(\"assistant\", str(r))\n                elif self.hyperparams[\"repetition_handling\"] == \"RESTRICT\":\n                    raw_response = new_response\n            self.cycle_count += 1\n\n            return self.on_response(raw_response, thought_process_id, prompt, instruction)\n        except SyntaxError as e:\n            return self.on_response(raw_response, thought_process_id, prompt, instruction)\n        \n    @abstractmethod\n    def execute(\n        self,\n        command_name: str | None,\n        command_args: dict[str, str] | None,\n        user_input: str | None,\n    ) -> str:\n        \"\"\"Executes the given command, if any, and returns the agent's response.\n\n        Params:\n            command_name: The name of the command to execute, if any.\n            command_args: The arguments to pass to the command, if any.\n            user_input: The user's input, if any.\n\n        Returns:\n            The results of the command.\n        \"\"\"\n        ...\n\n    def construct_executed_steps_text(self,):\n        text = \"# List of Steps to Achieve Your Goals:\\n\"\n        text = \"Here is the overall list of steps that you might need to fulfill inorder to achieve your goals:\\n\"\n        for k in self.steps_list:\n            text += self.steps_object[k][\"static_header\"] + self.steps_object[k][\"step_line\"] + \"\\n\"\n\n        text += \"\\nBelow is a list of commands that you have executed so far and summary of the result of each command:\\n\"\n        for command, summary in self.commands_and_summary:\n            text += command + \"\\nThe summary of the output of above command: \" + str(summary)+\"\\n\\n\" \n        return text\n\n\n    def go_to_next_step(self,):\n        step_ind = self.steps_list.index(self.current_step)\n        if step_ind < 0:\n            raise ValueError(\"DETECTED IMPOSSIBLE STEP NUMBER.\")\n        elif step_ind == len(self.steps_list) - 1:\n            raise ValueError(\"END OF STEPS, THERE IS NO NEXT STEP\")\n        \n        self.current_step = self.steps_list[step_ind+1]\n\n    def construct_base_prompt(\n        self,\n        thought_process_id: ThoughtProcessID,\n        prepend_messages: list[Message] = [],\n        append_messages: list[Message] = [],\n        reserve_tokens: int = 0,\n    ) -> ChatSequence:\n        \"\"\"Constructs and returns a prompt with the following structure:\n        1. System prompt\n        2. `prepend_messages`\n        3. Message history of the agent, truncated & prepended with running summary as needed\n        4. `append_messages`\n\n        Params:\n            prepend_messages: Messages to insert between the system prompt and message history\n            append_messages: Messages to insert after the message history\n            reserve_tokens: Number of tokens to reserve for content that is added later\n        \"\"\"\n\n        ## added this part to change the prompt structure\n\n        if self.customize[\"GENERAL_GUIDELINES\"]:\n            steps_text = self.construct_executed_steps_text()\n        else:\n            steps_text = \"\\n\"\n\n        prompt = ChatSequence.for_model(\n            self.llm.name,\n            [Message(\"system\", self.prompt_dictionary[\"role\"])])\n        \n        definitions_prompt = \"\"\n        static_sections_names = [\"goals\", \"commands\", \"general_guidelines\"]\n\n        for key in static_sections_names:\n            if isinstance(self.prompt_dictionary[key], list):\n                definitions_prompt += \"\\n\".join(self.prompt_dictionary[key]) + \"\\n\"\n            elif isinstance(self.prompt_dictionary[key], str):\n                definitions_prompt += self.prompt_dictionary[key] + \"\\n\"\n            else:\n                raise TypeError(\"For now we only support list and str types.\")\n        \n        definitions_prompt += \"\\nProject path: the project under scope has the following path/name within the file system, which you should use when calling the tools: {}\".format(self.project_path) + \"\\n\"\n        definitions_prompt += \"\\nProject github url (needed for dockerfile script): {}\\n\".format(self.project_url)\n        \n        if os.path.exists(\"problems_memory/{}\".format(self.project_path)):\n            with open(\"problems_memory/{}\".format(self.project_path)) as pm:\n                previous_memory = pm.read()\n            definitions_prompt += \"\\nFrom previous attempts we learned that: {}\\n\".format(previous_memory)\n        \n        if self.found_workflows and self.customize[\"WORKFLOWS_SEARCH\"]:\n            definitions_prompt += \"\\nThe following workflow files might contain information on how to setup the project and run test cases. We extracted the most important installation steps found in those workflows and turned them into a bash script. This might be useful later on when building/installing and testing the project:\\n\"\n            for w in self.found_workflows:\n                definitions_prompt += \"\\nWorkflow file: {}\\nExtracted installation steps:\\n{}\\n\".format(w, self.workflow_to_script(w))\n        \n        if self.dockerfiles and self.customize[\"WORKFLOWS_SEARCH\"]:\n            definitions_prompt += \"\\nWe found the following dockerfile scripts within the repo. The dockerfile scripts might help you build a suitable docker image for this repository: \"+ \" ,\".join(self.dockerfiles) + \"\\n\"\n        \n        if self.search_results and self.customize[\"WEB_SEARCH\"]:\n            definitions_prompt += \"\\nWe searched on google for installing / building {} from source code on Ubuntu/Debian.\".format(self.project_path)\n            definitions_prompt += \"Here is the summary of the top 5 results:\\n\" + self.search_results + \"\\n\"\n        \n        \n        #if self.hyperparams[\"image\"]!=\"NIL\":\n        #    definitions_prompt += \"For this particular project, the docker image have been already created and the container have been launched, you can #skip steps 1 and 2; You can start directly from step 3 (see the steps list below).\\n\"\n        #definitions_prompt += steps_text + \"\\n\"\n        \n        if len(self.history) > 2:\n            last_command = self.history[-2]\n            command_result = self.history[-1]\n            last_command_section = \"{}\\n\".format(last_command.content)\n            append_messages.append(Message(\"assistant\", last_command_section))\n            result_last_command = \"The result of executing that last command is:\\n {}\".format(command_result.content)\n            append_messages.append((Message(\"user\", result_last_command)))\n\n        if self.cycle_type == \"CMD\":\n            cycle_instruction = self.cmd_cycle_instruction\n            if self.track_budget:\n                cycle_instruction += \"\\n\" + \"In this conversation you can only have a limited number of calls tools. You have so far consumed {} call and {} left.\\n\".format(self.max_budget - self.left_commands, self.left_commands) + \"\\n Consider this limitation, so you repeat the same commands unless it is really necessary, such as for debugging and resolving issues.\\n\"\n            prompt.extend(ChatSequence.for_model(\n                self.llm.name,\n                [Message(\"user\", definitions_prompt + \"\\n\" + steps_text + \"\\n\\n\" + cycle_instruction)] + prepend_messages,\n            ))\n        \n            if append_messages:\n                prompt.extend(append_messages)\n        else:\n            cycle_instruction = self.summary_cycle_instruction\n            prompt.extend(ChatSequence.for_model(\n                self.llm.name,\n                [Message(\"user\", definitions_prompt + \"\\n\" + steps_text + \"\\n\\n\" + cycle_instruction+\"\\n\" + command_result.content)]\n            ))\n        return prompt\n\n    def construct_prompt(\n        self,\n        cycle_instruction: str,\n        thought_process_id: ThoughtProcessID,\n    ) -> ChatSequence:\n        \"\"\"Constructs and returns a prompt with the following structure:\n        1. System prompt\n        2. Message history of the agent, truncated & prepended with running summary as needed\n        3. `cycle_instruction`\n\n        Params:\n            cycle_instruction: The final instruction for a thinking cycle\n        \"\"\"\n\n        if not cycle_instruction:\n            raise ValueError(\"No instruction given\")\n\n        #cycle_instruction_msg = Message(\"user\", cycle_instruction)\n        cycle_instruction_tlength = 0\n        #count_message_tokens(\n        #    cycle_instruction_msg, self.llm.name\n        #)\n\n        append_messages: list[Message] = []\n\n        response_format_instr = self.response_format_instruction(thought_process_id)\n        #if response_format_instr:\n        #s    append_messages.append(Message(\"user\", response_format_instr))\n\n        prompt = self.construct_base_prompt(\n            thought_process_id,\n            append_messages=append_messages,\n            reserve_tokens=cycle_instruction_tlength,\n        )\n\n        # ADD user input message (\"triggering prompt\")\n        #prompt.append(cycle_instruction_msg)\n\n        return prompt\n\n    # This can be expanded to support multiple types of (inter)actions within an agent\n    def response_format_instruction(self, thought_process_id: ThoughtProcessID) -> str:\n        if thought_process_id != \"one-shot\":\n            raise NotImplementedError(f\"Unknown thought process '{thought_process_id}'\")\n\n        RESPONSE_FORMAT_WITH_COMMAND = \"\"\"```ts\n        interface Response {\n            // Express your thoughts based on the information that you have collected so far, the possible steps that you could do next and also your reasoning about fixing the bug in question\"\n            thoughts: string;\n            command: {\n                name: string;\n                args: Record<string, any>;\n            };\n        }\n        ```\n        Here is an example of command call that you can output:\n        {\n            \"thoughts\": \"I have information about the bug, but I need to run the test cases to understand the bug better.\",\n            \"command\": {\n                \"name\": \"run_tests\",\n                \"args\": {\n                \"name\": \"Chart\",\n                \"index\": 1\n                }\n            }\n        }\n        \"\"\"\n\n        RESPONSE_FORMAT_WITHOUT_COMMAND = \"\"\"```ts\n        interface Response {\n            thoughts: {\n                // Thoughts\n                text: string;\n                reasoning: string;\n                // Short markdown-style bullet list that conveys the long-term plan\n                plan: string;\n                // Constructive self-criticism\n                criticism: string;\n                // Summary of thoughts to say to the user\n                speak: string;\n            };\n        }\n        ```\"\"\"\n\n        response_format = re.sub(\n            r\"\\n\\s+\",\n            \"\\n\",\n            RESPONSE_FORMAT_WITHOUT_COMMAND\n            if self.config.openai_functions\n            else RESPONSE_FORMAT_WITH_COMMAND,\n        )\n\n        use_functions = self.config.openai_functions and self.command_registry.commands\n        return (\n            f\"Respond strictly with JSON{', and also specify a command to use through a function_call' if use_functions else ''}. \"\n            \"The JSON should be compatible with the TypeScript type `Response` from the following:\\n\"\n            f\"{response_format}\\n\"\n        )\n\n    def on_before_think(\n        self,\n        prompt: ChatSequence,\n        thought_process_id: ThoughtProcessID,\n        instruction: str,\n    ) -> ChatSequence:\n        \"\"\"Called after constructing the prompt but before executing it.\n\n        Calls the `on_planning` hook of any enabled and capable plugins, adding their\n        output to the prompt.\n\n        Params:\n            instruction: The instruction for the current cycle, also used in constructing the prompt\n\n        Returns:\n            The prompt to execute\n        \"\"\"\n        current_tokens_used = prompt.token_length\n        plugin_count = len(self.config.plugins)\n        for i, plugin in enumerate(self.config.plugins):\n            if not plugin.can_handle_on_planning():\n                continue\n            plugin_response = plugin.on_planning(\n                self.ai_config.prompt_generator, prompt.raw()\n            )\n            if not plugin_response or plugin_response == \"\":\n                continue\n            message_to_add = Message(\"system\", plugin_response)\n            tokens_to_add = count_message_tokens(message_to_add, self.llm.name)\n            if current_tokens_used + tokens_to_add > self.send_token_limit:\n                logger.debug(f\"Plugin response too long, skipping: {plugin_response}\")\n                logger.debug(f\"Plugins remaining at stop: {plugin_count - i}\")\n                break\n            prompt.insert(\n                -1, message_to_add\n            )  # HACK: assumes cycle instruction to be at the end\n            current_tokens_used += tokens_to_add\n        return prompt\n\n    def on_response(\n        self,\n        llm_response: ChatModelResponse,\n        thought_process_id: ThoughtProcessID,\n        prompt: ChatSequence,\n        instruction: str,\n    ) -> tuple[CommandName | None, CommandArgs | None, AgentThoughts]:\n        \"\"\"Called upon receiving a response from the chat model.\n\n        Adds the last/newest message in the prompt and the response to `history`,\n        and calls `self.parse_and_process_response()` to do the rest.\n\n        Params:\n            llm_response: The raw response from the chat model\n            prompt: The prompt that was executed\n            instruction: The instruction for the current cycle, also used in constructing the prompt\n\n        Returns:\n            The parsed command name and command args, if any, and the agent thoughts.\n        \"\"\"\n\n        # Save assistant reply to message history\n        self.history.append(prompt[-1])\n        self.history.add(\n            \"assistant\", llm_response.content, \"ai_response\"\n        )  # FIXME: support function calls\n\n        if self.cycle_type != \"CMD\":\n            self.summary_result = json.loads(llm_response.content)\n            self.steps_object[self.current_step][\"result_of_step\"].append(self.summary_result)\n            return\n        \n        try:\n            return self.parse_and_process_response(\n                llm_response, thought_process_id, prompt, instruction\n            )\n        except SyntaxError as e:\n            logger.error(f\"Response could not be parsed: {e}\")\n            with open(\"parsing_erros_responses.txt\", \"a\") as pers:\n                pers.write(llm_response.content+\"\\n\")\n            # TODO: tune this message\n            self.history.add(\n                \"system\",\n                f\"Your response could not be parsed.\"\n                \"\\n\\nRemember to only respond using the specified format above!\",\n            )\n            return None, None, {}\n\n        # TODO: update memory/context\n\n    @abstractmethod\n    def parse_and_process_response(\n        self,\n        llm_response: ChatModelResponse,\n        thought_process_id: ThoughtProcessID,\n        prompt: ChatSequence,\n        instruction: str,\n    ) -> tuple[CommandName | None, CommandArgs | None, AgentThoughts]:\n        \"\"\"Validate, parse & process the LLM's response.\n\n        Must be implemented by derivative classes: no base implementation is provided,\n        since the implementation depends on the role of the derivative Agent.\n\n        Params:\n            llm_response: The raw response from the chat model\n            prompt: The prompt that was executed\n            instruction: The instruction for the current cycle, also used in constructing the prompt\n\n        Returns:\n            The parsed command name and command args, if any, and the agent thoughts.\n        \"\"\"\n        pass\n\n\ndef add_history_upto_token_limit(\n    prompt: ChatSequence, history: MessageHistory, t_limit: int\n) -> list[Message]:\n    current_prompt_length = prompt.token_length\n    insertion_index = len(prompt)\n    limit_reached = False\n    trimmed_messages: list[Message] = []\n    for cycle in reversed(list(history.per_cycle())):\n        messages_to_add = [msg for msg in cycle if msg is not None]\n        tokens_to_add = count_message_tokens(messages_to_add, prompt.model.name)\n        if current_prompt_length + tokens_to_add > t_limit:\n            limit_reached = True\n\n        if not limit_reached:\n            # Add the most recent message to the start of the chain,\n            #  after the system prompts.\n            prompt.insert(insertion_index, *messages_to_add)\n            current_prompt_length += tokens_to_add\n        else:\n            trimmed_messages = messages_to_add + trimmed_messages\n\n    return trimmed_messages"}
{"type": "source_file", "path": "autogpt/core/configuration/schema.py", "content": "import abc\nimport typing\nfrom typing import Any, Generic, TypeVar\n\nfrom pydantic import BaseModel, Field\n\n\ndef UserConfigurable(*args, **kwargs):\n    return Field(*args, **kwargs, user_configurable=True)\n\n\nclass SystemConfiguration(BaseModel):\n    def get_user_config(self) -> dict[str, Any]:\n        return _get_user_config_fields(self)\n\n    class Config:\n        extra = \"forbid\"\n        use_enum_values = True\n\n\nclass SystemSettings(BaseModel):\n    \"\"\"A base class for all system settings.\"\"\"\n\n    name: str\n    description: str\n\n    class Config:\n        extra = \"forbid\"\n        use_enum_values = True\n\n\nS = TypeVar(\"S\", bound=SystemSettings)\n\n\nclass Configurable(abc.ABC, Generic[S]):\n    \"\"\"A base class for all configurable objects.\"\"\"\n\n    prefix: str = \"\"\n    default_settings: typing.ClassVar[S]\n\n    @classmethod\n    def get_user_config(cls) -> dict[str, Any]:\n        return _get_user_config_fields(cls.default_settings)\n\n    @classmethod\n    def build_agent_configuration(cls, configuration: dict) -> S:\n        \"\"\"Process the configuration for this object.\"\"\"\n\n        defaults = cls.default_settings.dict()\n        final_configuration = deep_update(defaults, configuration)\n\n        return cls.default_settings.__class__.parse_obj(final_configuration)\n\n\ndef _get_user_config_fields(instance: BaseModel) -> dict[str, Any]:\n    \"\"\"\n    Get the user config fields of a Pydantic model instance.\n\n    Args:\n        instance: The Pydantic model instance.\n\n    Returns:\n        The user config fields of the instance.\n    \"\"\"\n    user_config_fields = {}\n\n    for name, value in instance.__dict__.items():\n        field_info = instance.__fields__[name]\n        if \"user_configurable\" in field_info.field_info.extra:\n            user_config_fields[name] = value\n        elif isinstance(value, SystemConfiguration):\n            user_config_fields[name] = value.get_user_config()\n        elif isinstance(value, list) and all(\n            isinstance(i, SystemConfiguration) for i in value\n        ):\n            user_config_fields[name] = [i.get_user_config() for i in value]\n        elif isinstance(value, dict) and all(\n            isinstance(i, SystemConfiguration) for i in value.values()\n        ):\n            user_config_fields[name] = {\n                k: v.get_user_config() for k, v in value.items()\n            }\n\n    return user_config_fields\n\n\ndef deep_update(original_dict: dict, update_dict: dict) -> dict:\n    \"\"\"\n    Recursively update a dictionary.\n\n    Args:\n        original_dict (dict): The dictionary to be updated.\n        update_dict (dict): The dictionary to update with.\n\n    Returns:\n        dict: The updated dictionary.\n    \"\"\"\n    for key, value in update_dict.items():\n        if (\n            key in original_dict\n            and isinstance(original_dict[key], dict)\n            and isinstance(value, dict)\n        ):\n            original_dict[key] = deep_update(original_dict[key], value)\n        else:\n            original_dict[key] = value\n    return original_dict\n"}
{"type": "source_file", "path": "autogpt/core/configuration/__init__.py", "content": "\"\"\"The configuration encapsulates settings for all Agent subsystems.\"\"\"\nfrom autogpt.core.configuration.schema import (\n    Configurable,\n    SystemConfiguration,\n    SystemSettings,\n    UserConfigurable,\n)\n"}
{"type": "source_file", "path": "autogpt/core/ability/schema.py", "content": "import enum\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\n\nclass ContentType(str, enum.Enum):\n    # TBD what these actually are.\n    TEXT = \"text\"\n    CODE = \"code\"\n\n\nclass Knowledge(BaseModel):\n    content: str\n    content_type: ContentType\n    content_metadata: dict[str, Any]\n\n\nclass AbilityResult(BaseModel):\n    \"\"\"The AbilityResult is a standard response struct for an ability.\"\"\"\n\n    ability_name: str\n    ability_args: dict[str, str]\n    success: bool\n    message: str\n    new_knowledge: Knowledge = None\n\n    def summary(self) -> str:\n        kwargs = \", \".join(f\"{k}={v}\" for k, v in self.ability_args.items())\n        return f\"{self.ability_name}({kwargs}): {self.message}\"\n"}
{"type": "source_file", "path": "autogpt/core/ability/base.py", "content": "import abc\nfrom pprint import pformat\nfrom typing import Any, ClassVar\n\nimport inflection\nfrom pydantic import Field\n\nfrom autogpt.core.ability.schema import AbilityResult\nfrom autogpt.core.configuration import SystemConfiguration\nfrom autogpt.core.planning.simple import LanguageModelConfiguration\n\n\nclass AbilityConfiguration(SystemConfiguration):\n    \"\"\"Struct for model configuration.\"\"\"\n\n    from autogpt.core.plugin.base import PluginLocation\n\n    location: PluginLocation\n    packages_required: list[str] = Field(default_factory=list)\n    language_model_required: LanguageModelConfiguration = None\n    memory_provider_required: bool = False\n    workspace_required: bool = False\n\n\nclass Ability(abc.ABC):\n    \"\"\"A class representing an agent ability.\"\"\"\n\n    default_configuration: ClassVar[AbilityConfiguration]\n\n    @classmethod\n    def name(cls) -> str:\n        \"\"\"The name of the ability.\"\"\"\n        return inflection.underscore(cls.__name__)\n\n    @classmethod\n    @abc.abstractmethod\n    def description(cls) -> str:\n        \"\"\"A detailed description of what the ability does.\"\"\"\n        ...\n\n    @classmethod\n    @abc.abstractmethod\n    def arguments(cls) -> dict:\n        \"\"\"A dict of arguments in standard json schema format.\"\"\"\n        ...\n\n    @classmethod\n    def required_arguments(cls) -> list[str]:\n        \"\"\"A list of required arguments.\"\"\"\n        return []\n\n    @abc.abstractmethod\n    async def __call__(self, *args: Any, **kwargs: Any) -> AbilityResult:\n        ...\n\n    def __str__(self) -> str:\n        return pformat(self.dump())\n\n    def dump(self) -> dict:\n        return {\n            \"name\": self.name(),\n            \"description\": self.description(),\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": self.arguments(),\n                \"required\": self.required_arguments(),\n            },\n        }\n\n\nclass AbilityRegistry(abc.ABC):\n    @abc.abstractmethod\n    def register_ability(\n        self, ability_name: str, ability_configuration: AbilityConfiguration\n    ) -> None:\n        ...\n\n    @abc.abstractmethod\n    def list_abilities(self) -> list[str]:\n        ...\n\n    @abc.abstractmethod\n    def dump_abilities(self) -> list[dict]:\n        ...\n\n    @abc.abstractmethod\n    def get_ability(self, ability_name: str) -> Ability:\n        ...\n\n    @abc.abstractmethod\n    async def perform(self, ability_name: str, **kwargs: Any) -> AbilityResult:\n        ...\n"}
{"type": "source_file", "path": "autogpt/core/memory/__init__.py", "content": "\"\"\"The memory subsystem manages the Agent's long-term memory.\"\"\"\nfrom autogpt.core.memory.base import Memory\nfrom autogpt.core.memory.simple import MemorySettings, SimpleMemory\n"}
{"type": "source_file", "path": "autogpt/core/ability/builtins/create_new_ability.py", "content": "import logging\n\nfrom autogpt.core.ability.base import Ability, AbilityConfiguration\nfrom autogpt.core.ability.schema import AbilityResult\nfrom autogpt.core.plugin.simple import PluginLocation, PluginStorageFormat\n\n\nclass CreateNewAbility(Ability):\n    default_configuration = AbilityConfiguration(\n        location=PluginLocation(\n            storage_format=PluginStorageFormat.INSTALLED_PACKAGE,\n            storage_route=\"autogpt.core.ability.builtins.CreateNewAbility\",\n        ),\n    )\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        configuration: AbilityConfiguration,\n    ):\n        self._logger = logger\n        self._configuration = configuration\n\n    @classmethod\n    def description(cls) -> str:\n        return \"Create a new ability by writing python code.\"\n\n    @classmethod\n    def arguments(cls) -> dict:\n        return {\n            \"ability_name\": {\n                \"type\": \"string\",\n                \"description\": \"A meaningful and concise name for the new ability.\",\n            },\n            \"description\": {\n                \"type\": \"string\",\n                \"description\": \"A detailed description of the ability and its uses, including any limitations.\",\n            },\n            \"arguments\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"name\": {\n                            \"type\": \"string\",\n                            \"description\": \"The name of the argument.\",\n                        },\n                        \"type\": {\n                            \"type\": \"string\",\n                            \"description\": \"The type of the argument. Must be a standard json schema type.\",\n                        },\n                        \"description\": {\n                            \"type\": \"string\",\n                            \"description\": \"A detailed description of the argument and its uses.\",\n                        },\n                    },\n                },\n                \"description\": \"A list of arguments that the ability will accept.\",\n            },\n            \"required_arguments\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"string\",\n                    \"description\": \"The names of the arguments that are required.\",\n                },\n                \"description\": \"A list of the names of the arguments that are required.\",\n            },\n            \"package_requirements\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"string\",\n                    \"description\": \"The of the Python package that is required to execute the ability.\",\n                },\n                \"description\": \"A list of the names of the Python packages that are required to execute the ability.\",\n            },\n            \"code\": {\n                \"type\": \"string\",\n                \"description\": \"The Python code that will be executed when the ability is called.\",\n            },\n        }\n\n    @classmethod\n    def required_arguments(cls) -> list[str]:\n        return [\n            \"ability_name\",\n            \"description\",\n            \"arguments\",\n            \"required_arguments\",\n            \"package_requirements\",\n            \"code\",\n        ]\n\n    async def __call__(\n        self,\n        ability_name: str,\n        description: str,\n        arguments: list[dict],\n        required_arguments: list[str],\n        package_requirements: list[str],\n        code: str,\n    ) -> AbilityResult:\n        raise NotImplementedError\n"}
{"type": "source_file", "path": "autogpt/core/agent/simple.py", "content": "import logging\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom autogpt.core.ability import (\n    AbilityRegistrySettings,\n    AbilityResult,\n    SimpleAbilityRegistry,\n)\nfrom autogpt.core.agent.base import Agent\nfrom autogpt.core.configuration import Configurable, SystemConfiguration, SystemSettings\nfrom autogpt.core.memory import MemorySettings, SimpleMemory\nfrom autogpt.core.planning import PlannerSettings, SimplePlanner, Task, TaskStatus\nfrom autogpt.core.plugin.simple import (\n    PluginLocation,\n    PluginStorageFormat,\n    SimplePluginService,\n)\nfrom autogpt.core.resource.model_providers import OpenAIProvider, OpenAISettings\nfrom autogpt.core.workspace.simple import SimpleWorkspace, WorkspaceSettings\n\n\nclass AgentSystems(SystemConfiguration):\n    ability_registry: PluginLocation\n    memory: PluginLocation\n    openai_provider: PluginLocation\n    planning: PluginLocation\n    workspace: PluginLocation\n\n\nclass AgentConfiguration(SystemConfiguration):\n    cycle_count: int\n    max_task_cycle_count: int\n    creation_time: str\n    name: str\n    role: str\n    goals: list[str]\n    systems: AgentSystems\n\n\nclass AgentSystemSettings(SystemSettings):\n    configuration: AgentConfiguration\n\n\nclass AgentSettings(BaseModel):\n    agent: AgentSystemSettings\n    ability_registry: AbilityRegistrySettings\n    memory: MemorySettings\n    openai_provider: OpenAISettings\n    planning: PlannerSettings\n    workspace: WorkspaceSettings\n\n    def update_agent_name_and_goals(self, agent_goals: dict) -> None:\n        self.agent.configuration.name = agent_goals[\"agent_name\"]\n        self.agent.configuration.role = agent_goals[\"agent_role\"]\n        self.agent.configuration.goals = agent_goals[\"agent_goals\"]\n\n\nclass SimpleAgent(Agent, Configurable):\n    default_settings = AgentSystemSettings(\n        name=\"simple_agent\",\n        description=\"A simple agent.\",\n        configuration=AgentConfiguration(\n            name=\"Entrepreneur-GPT\",\n            role=(\n                \"An AI designed to autonomously develop and run businesses with \"\n                \"the sole goal of increasing your net worth.\"\n            ),\n            goals=[\n                \"Increase net worth\",\n                \"Grow Twitter Account\",\n                \"Develop and manage multiple businesses autonomously\",\n            ],\n            cycle_count=0,\n            max_task_cycle_count=3,\n            creation_time=\"\",\n            systems=AgentSystems(\n                ability_registry=PluginLocation(\n                    storage_format=PluginStorageFormat.INSTALLED_PACKAGE,\n                    storage_route=\"autogpt.core.ability.SimpleAbilityRegistry\",\n                ),\n                memory=PluginLocation(\n                    storage_format=PluginStorageFormat.INSTALLED_PACKAGE,\n                    storage_route=\"autogpt.core.memory.SimpleMemory\",\n                ),\n                openai_provider=PluginLocation(\n                    storage_format=PluginStorageFormat.INSTALLED_PACKAGE,\n                    storage_route=\"autogpt.core.resource.model_providers.OpenAIProvider\",\n                ),\n                planning=PluginLocation(\n                    storage_format=PluginStorageFormat.INSTALLED_PACKAGE,\n                    storage_route=\"autogpt.core.planning.SimplePlanner\",\n                ),\n                workspace=PluginLocation(\n                    storage_format=PluginStorageFormat.INSTALLED_PACKAGE,\n                    storage_route=\"autogpt.core.workspace.SimpleWorkspace\",\n                ),\n            ),\n        ),\n    )\n\n    def __init__(\n        self,\n        settings: AgentSystemSettings,\n        logger: logging.Logger,\n        ability_registry: SimpleAbilityRegistry,\n        memory: SimpleMemory,\n        openai_provider: OpenAIProvider,\n        planning: SimplePlanner,\n        workspace: SimpleWorkspace,\n    ):\n        self._configuration = settings.configuration\n        self._logger = logger\n        self._ability_registry = ability_registry\n        self._memory = memory\n        # FIXME: Need some work to make this work as a dict of providers\n        #  Getting the construction of the config to work is a bit tricky\n        self._openai_provider = openai_provider\n        self._planning = planning\n        self._workspace = workspace\n        self._task_queue = []\n        self._completed_tasks = []\n        self._current_task = None\n        self._next_ability = None\n\n    @classmethod\n    def from_workspace(\n        cls,\n        workspace_path: Path,\n        logger: logging.Logger,\n    ) -> \"SimpleAgent\":\n        agent_settings = SimpleWorkspace.load_agent_settings(workspace_path)\n        agent_args = {}\n\n        agent_args[\"settings\"] = agent_settings.agent\n        agent_args[\"logger\"] = logger\n        agent_args[\"workspace\"] = cls._get_system_instance(\n            \"workspace\",\n            agent_settings,\n            logger,\n        )\n        agent_args[\"openai_provider\"] = cls._get_system_instance(\n            \"openai_provider\",\n            agent_settings,\n            logger,\n        )\n        agent_args[\"planning\"] = cls._get_system_instance(\n            \"planning\",\n            agent_settings,\n            logger,\n            model_providers={\"openai\": agent_args[\"openai_provider\"]},\n        )\n        agent_args[\"memory\"] = cls._get_system_instance(\n            \"memory\",\n            agent_settings,\n            logger,\n            workspace=agent_args[\"workspace\"],\n        )\n\n        agent_args[\"ability_registry\"] = cls._get_system_instance(\n            \"ability_registry\",\n            agent_settings,\n            logger,\n            workspace=agent_args[\"workspace\"],\n            memory=agent_args[\"memory\"],\n            model_providers={\"openai\": agent_args[\"openai_provider\"]},\n        )\n\n        return cls(**agent_args)\n\n    async def build_initial_plan(self) -> dict:\n        plan = await self._planning.make_initial_plan(\n            agent_name=self._configuration.name,\n            agent_role=self._configuration.role,\n            agent_goals=self._configuration.goals,\n            abilities=self._ability_registry.list_abilities(),\n        )\n        tasks = [Task.parse_obj(task) for task in plan.content[\"task_list\"]]\n\n        # TODO: Should probably do a step to evaluate the quality of the generated tasks,\n        #  and ensure that they have actionable ready and acceptance criteria\n\n        self._task_queue.extend(tasks)\n        self._task_queue.sort(key=lambda t: t.priority, reverse=True)\n        self._task_queue[-1].context.status = TaskStatus.READY\n        return plan.content\n\n    async def determine_next_ability(self, *args, **kwargs):\n        if not self._task_queue:\n            return {\"response\": \"I don't have any tasks to work on right now.\"}\n\n        self._configuration.cycle_count += 1\n        task = self._task_queue.pop()\n        self._logger.info(f\"Working on task: {task}\")\n\n        task = await self._evaluate_task_and_add_context(task)\n        next_ability = await self._choose_next_ability(\n            task,\n            self._ability_registry.dump_abilities(),\n        )\n        self._current_task = task\n        self._next_ability = next_ability.content\n        return self._current_task, self._next_ability\n\n    async def execute_next_ability(self, user_input: str, *args, **kwargs):\n        if user_input == \"y\":\n            ability = self._ability_registry.get_ability(\n                self._next_ability[\"next_ability\"]\n            )\n            ability_response = await ability(**self._next_ability[\"ability_arguments\"])\n            await self._update_tasks_and_memory(ability_response)\n            if self._current_task.context.status == TaskStatus.DONE:\n                self._completed_tasks.append(self._current_task)\n            else:\n                self._task_queue.append(self._current_task)\n            self._current_task = None\n            self._next_ability = None\n\n            return ability_response.dict()\n        else:\n            raise NotImplementedError\n\n    async def _evaluate_task_and_add_context(self, task: Task) -> Task:\n        \"\"\"Evaluate the task and add context to it.\"\"\"\n        if task.context.status == TaskStatus.IN_PROGRESS:\n            # Nothing to do here\n            return task\n        else:\n            self._logger.debug(f\"Evaluating task {task} and adding relevant context.\")\n            # TODO: Look up relevant memories (need working memory system)\n            # TODO: Evaluate whether there is enough information to start the task (language model call).\n            task.context.enough_info = True\n            task.context.status = TaskStatus.IN_PROGRESS\n            return task\n\n    async def _choose_next_ability(self, task: Task, ability_schema: list[dict]):\n        \"\"\"Choose the next ability to use for the task.\"\"\"\n        self._logger.debug(f\"Choosing next ability for task {task}.\")\n        if task.context.cycle_count > self._configuration.max_task_cycle_count:\n            # Don't hit the LLM, just set the next action as \"breakdown_task\" with an appropriate reason\n            raise NotImplementedError\n        elif not task.context.enough_info:\n            # Don't ask the LLM, just set the next action as \"breakdown_task\" with an appropriate reason\n            raise NotImplementedError\n        else:\n            next_ability = await self._planning.determine_next_ability(\n                task, ability_schema\n            )\n            return next_ability\n\n    async def _update_tasks_and_memory(self, ability_result: AbilityResult):\n        self._current_task.context.cycle_count += 1\n        self._current_task.context.prior_actions.append(ability_result)\n        # TODO: Summarize new knowledge\n        # TODO: store knowledge and summaries in memory and in relevant tasks\n        # TODO: evaluate whether the task is complete\n\n    def __repr__(self):\n        return \"SimpleAgent()\"\n\n    ################################################################\n    # Factory interface for agent bootstrapping and initialization #\n    ################################################################\n\n    @classmethod\n    def build_user_configuration(cls) -> dict[str, Any]:\n        \"\"\"Build the user's configuration.\"\"\"\n        configuration_dict = {\n            \"agent\": cls.get_user_config(),\n        }\n\n        system_locations = configuration_dict[\"agent\"][\"configuration\"][\"systems\"]\n        for system_name, system_location in system_locations.items():\n            system_class = SimplePluginService.get_plugin(system_location)\n            configuration_dict[system_name] = system_class.get_user_config()\n        configuration_dict = _prune_empty_dicts(configuration_dict)\n        return configuration_dict\n\n    @classmethod\n    def compile_settings(\n        cls, logger: logging.Logger, user_configuration: dict\n    ) -> AgentSettings:\n        \"\"\"Compile the user's configuration with the defaults.\"\"\"\n        logger.debug(\"Processing agent system configuration.\")\n        configuration_dict = {\n            \"agent\": cls.build_agent_configuration(\n                user_configuration.get(\"agent\", {})\n            ).dict(),\n        }\n\n        system_locations = configuration_dict[\"agent\"][\"configuration\"][\"systems\"]\n\n        # Build up default configuration\n        for system_name, system_location in system_locations.items():\n            logger.debug(f\"Compiling configuration for system {system_name}\")\n            system_class = SimplePluginService.get_plugin(system_location)\n            configuration_dict[system_name] = system_class.build_agent_configuration(\n                user_configuration.get(system_name, {})\n            ).dict()\n\n        return AgentSettings.parse_obj(configuration_dict)\n\n    @classmethod\n    async def determine_agent_name_and_goals(\n        cls,\n        user_objective: str,\n        agent_settings: AgentSettings,\n        logger: logging.Logger,\n    ) -> dict:\n        logger.debug(\"Loading OpenAI provider.\")\n        provider: OpenAIProvider = cls._get_system_instance(\n            \"openai_provider\",\n            agent_settings,\n            logger=logger,\n        )\n        logger.debug(\"Loading agent planner.\")\n        agent_planner: SimplePlanner = cls._get_system_instance(\n            \"planning\",\n            agent_settings,\n            logger=logger,\n            model_providers={\"openai\": provider},\n        )\n        logger.debug(\"determining agent name and goals.\")\n        model_response = await agent_planner.decide_name_and_goals(\n            user_objective,\n        )\n\n        return model_response.content\n\n    @classmethod\n    def provision_agent(\n        cls,\n        agent_settings: AgentSettings,\n        logger: logging.Logger,\n    ):\n        agent_settings.agent.configuration.creation_time = datetime.now().strftime(\n            \"%Y%m%d_%H%M%S\"\n        )\n        workspace: SimpleWorkspace = cls._get_system_instance(\n            \"workspace\",\n            agent_settings,\n            logger=logger,\n        )\n        return workspace.setup_workspace(agent_settings, logger)\n\n    @classmethod\n    def _get_system_instance(\n        cls,\n        system_name: str,\n        agent_settings: AgentSettings,\n        logger: logging.Logger,\n        *args,\n        **kwargs,\n    ):\n        system_locations = agent_settings.agent.configuration.systems.dict()\n\n        system_settings = getattr(agent_settings, system_name)\n        system_class = SimplePluginService.get_plugin(system_locations[system_name])\n        system_instance = system_class(\n            system_settings,\n            *args,\n            logger=logger.getChild(system_name),\n            **kwargs,\n        )\n        return system_instance\n\n\ndef _prune_empty_dicts(d: dict) -> dict:\n    \"\"\"\n    Prune branches from a nested dictionary if the branch only contains empty dictionaries at the leaves.\n\n    Args:\n        d: The dictionary to prune.\n\n    Returns:\n        The pruned dictionary.\n    \"\"\"\n    pruned = {}\n    for key, value in d.items():\n        if isinstance(value, dict):\n            pruned_value = _prune_empty_dicts(value)\n            if (\n                pruned_value\n            ):  # if the pruned dictionary is not empty, add it to the result\n                pruned[key] = pruned_value\n        else:\n            pruned[key] = value\n    return pruned\n"}
{"type": "source_file", "path": "autogpt/core/agent/__init__.py", "content": "\"\"\"The Agent is an autonomouos entity guided by a LLM provider.\"\"\"\nfrom autogpt.core.agent.base import Agent\nfrom autogpt.core.agent.simple import AgentSettings, SimpleAgent\n"}
{"type": "source_file", "path": "autogpt/app/setup.py", "content": "\"\"\"Set up the AI and its goals\"\"\"\nimport re\nfrom typing import Optional\n\nfrom colorama import Fore, Style\nfrom jinja2 import Template\n\nfrom autogpt.app import utils\nfrom autogpt.config import Config\nfrom autogpt.config.ai_config import AIConfig\nfrom autogpt.llm.base import ChatSequence, Message\nfrom autogpt.llm.utils import create_chat_completion\nfrom autogpt.logs import logger\nfrom autogpt.prompts.default_prompts import (\n    DEFAULT_SYSTEM_PROMPT_AICONFIG_AUTOMATIC,\n    DEFAULT_TASK_PROMPT_AICONFIG_AUTOMATIC,\n    DEFAULT_USER_DESIRE_PROMPT,\n)\n\n\ndef prompt_user(\n    config: Config, ai_config_template: Optional[AIConfig] = None\n) -> AIConfig:\n    \"\"\"Prompt the user for input\n\n    Params:\n        config (Config): The Config object\n        ai_config_template (AIConfig): The AIConfig object to use as a template\n\n    Returns:\n        AIConfig: The AIConfig object tailored to the user's input\n    \"\"\"\n\n    # Construct the prompt\n    logger.typewriter_log(\n        \"Welcome to Auto-GPT! \",\n        Fore.GREEN,\n        \"run with '--help' for more information.\",\n        speak_text=True,\n    )\n\n    ai_config_template_provided = ai_config_template is not None and any(\n        [\n            ai_config_template.ai_goals,\n            ai_config_template.ai_name,\n            ai_config_template.ai_role,\n        ]\n    )\n\n    user_desire = \"\"\n    if not ai_config_template_provided:\n        # Get user desire if command line overrides have not been passed in\n        logger.typewriter_log(\n            \"Create an AI-Assistant:\",\n            Fore.GREEN,\n            \"input '--manual' to enter manual mode.\",\n            speak_text=True,\n        )\n\n        user_desire = utils.clean_input(\n            config, f\"{Fore.LIGHTBLUE_EX}I want Auto-GPT to{Style.RESET_ALL}: \"\n        )\n\n    if user_desire.strip() == \"\":\n        user_desire = DEFAULT_USER_DESIRE_PROMPT  # Default prompt\n\n    # If user desire contains \"--manual\" or we have overridden any of the AI configuration\n    if \"--manual\" in user_desire or ai_config_template_provided:\n        logger.typewriter_log(\n            \"Manual Mode Selected\",\n            Fore.GREEN,\n            speak_text=True,\n        )\n        return generate_aiconfig_manual(config, ai_config_template)\n\n    else:\n        try:\n            return generate_aiconfig_automatic(user_desire, config)\n        except Exception as e:\n            logger.typewriter_log(\n                \"Unable to automatically generate AI Config based on user desire.\",\n                Fore.RED,\n                \"Falling back to manual mode.\",\n                speak_text=True,\n            )\n            logger.debug(f\"Error during AIConfig generation: {e}\")\n\n            return generate_aiconfig_manual(config)\n\n\ndef generate_aiconfig_manual(\n    config: Config, ai_config_template: Optional[AIConfig] = None\n) -> AIConfig:\n    \"\"\"\n    Interactively create an AI configuration by prompting the user to provide the name, role, and goals of the AI.\n\n    This function guides the user through a series of prompts to collect the necessary information to create\n    an AIConfig object. The user will be asked to provide a name and role for the AI, as well as up to five\n    goals. If the user does not provide a value for any of the fields, default values will be used.\n\n    Params:\n        config (Config): The Config object\n        ai_config_template (AIConfig): The AIConfig object to use as a template\n\n    Returns:\n        AIConfig: An AIConfig object containing the user-defined or default AI name, role, and goals.\n    \"\"\"\n\n    # Manual Setup Intro\n    logger.typewriter_log(\n        \"Create an AI-Assistant:\",\n        Fore.GREEN,\n        \"Enter the name of your AI and its role below. Entering nothing will load\"\n        \" defaults.\",\n        speak_text=True,\n    )\n\n    if ai_config_template and ai_config_template.ai_name:\n        ai_name = ai_config_template.ai_name\n    else:\n        ai_name = \"\"\n        # Get AI Name from User\n        logger.typewriter_log(\n            \"Name your AI: \", Fore.GREEN, \"For example, 'Entrepreneur-GPT'\"\n        )\n        ai_name = utils.clean_input(config, \"AI Name: \")\n    if ai_name == \"\":\n        ai_name = \"Entrepreneur-GPT\"\n\n    logger.typewriter_log(\n        f\"{ai_name} here!\", Fore.LIGHTBLUE_EX, \"I am at your service.\", speak_text=True\n    )\n\n    if ai_config_template and ai_config_template.ai_role:\n        ai_role = ai_config_template.ai_role\n    else:\n        # Get AI Role from User\n        logger.typewriter_log(\n            \"Describe your AI's role: \",\n            Fore.GREEN,\n            \"For example, 'an AI designed to autonomously develop and run businesses with\"\n            \" the sole goal of increasing your net worth.'\",\n        )\n        ai_role = utils.clean_input(config, f\"{ai_name} is: \")\n    if ai_role == \"\":\n        ai_role = \"an AI designed to autonomously develop and run businesses with the\"\n        \" sole goal of increasing your net worth.\"\n\n    if ai_config_template and ai_config_template.ai_goals:\n        ai_goals = ai_config_template.ai_goals\n    else:\n        # Enter up to 5 goals for the AI\n        logger.typewriter_log(\n            \"Enter up to 5 goals for your AI: \",\n            Fore.GREEN,\n            \"For example: \\nIncrease net worth, Grow Twitter Account, Develop and manage\"\n            \" multiple businesses autonomously'\",\n        )\n        logger.info(\"Enter nothing to load defaults, enter nothing when finished.\")\n        ai_goals = []\n        for i in range(5):\n            ai_goal = utils.clean_input(\n                config, f\"{Fore.LIGHTBLUE_EX}Goal{Style.RESET_ALL} {i+1}: \"\n            )\n            if ai_goal == \"\":\n                break\n            ai_goals.append(ai_goal)\n    if not ai_goals:\n        ai_goals = [\n            \"Increase net worth\",\n            \"Grow Twitter Account\",\n            \"Develop and manage multiple businesses autonomously\",\n        ]\n\n    # Get API Budget from User\n    logger.typewriter_log(\n        \"Enter your budget for API calls: \",\n        Fore.GREEN,\n        \"For example: $1.50\",\n    )\n    logger.info(\"Enter nothing to let the AI run without monetary limit\")\n    api_budget_input = utils.clean_input(\n        config, f\"{Fore.LIGHTBLUE_EX}Budget{Style.RESET_ALL}: $\"\n    )\n    if api_budget_input == \"\":\n        api_budget = 0.0\n    else:\n        try:\n            api_budget = float(api_budget_input.replace(\"$\", \"\"))\n        except ValueError:\n            logger.typewriter_log(\n                \"Invalid budget input. Setting budget to unlimited.\", Fore.RED\n            )\n            api_budget = 0.0\n\n    return AIConfig(ai_name, ai_role, ai_goals, api_budget)\n\n\ndef generate_aiconfig_automatic(user_prompt: str, config: Config) -> AIConfig:\n    \"\"\"Generates an AIConfig object from the given string.\n\n    Returns:\n    AIConfig: The AIConfig object tailored to the user's input\n    \"\"\"\n\n    system_prompt = DEFAULT_SYSTEM_PROMPT_AICONFIG_AUTOMATIC\n    prompt_ai_config_automatic = Template(\n        DEFAULT_TASK_PROMPT_AICONFIG_AUTOMATIC\n    ).render(user_prompt=user_prompt)\n    # Call LLM with the string as user input\n    output = create_chat_completion(\n        ChatSequence.for_model(\n            config.fast_llm,\n            [\n                Message(\"system\", system_prompt),\n                Message(\"user\", prompt_ai_config_automatic),\n            ],\n        ),\n        config,\n    ).content\n\n    # Debug LLM Output\n    logger.debug(f\"AI Config Generator Raw Output: {output}\")\n\n    # Parse the output\n    ai_name = re.search(r\"Name(?:\\s*):(?:\\s*)(.*)\", output, re.IGNORECASE).group(1)\n    ai_role = (\n        re.search(\n            r\"Description(?:\\s*):(?:\\s*)(.*?)(?:(?:\\n)|Goals)\",\n            output,\n            re.IGNORECASE | re.DOTALL,\n        )\n        .group(1)\n        .strip()\n    )\n    ai_goals = re.findall(r\"(?<=\\n)-\\s*(.*)\", output)\n    api_budget = 0.0  # TODO: parse api budget using a regular expression\n\n    return AIConfig(ai_name, ai_role, ai_goals, api_budget)\n"}
