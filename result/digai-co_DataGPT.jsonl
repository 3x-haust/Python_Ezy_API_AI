{"repo_info": {"repo_name": "DataGPT", "repo_owner": "digai-co", "repo_url": "https://github.com/digai-co/DataGPT"}}
{"type": "source_file", "path": "datagpt/__init__.py", "content": ""}
{"type": "source_file", "path": "datagpt/config.py", "content": "import os\n\nimport yaml\n\nfrom datagpt.util import root\n\n\nclass Config:\n    \"\"\"Usage：\n    config = Config(\"config.yaml\")\n    secret_key = config.get_key(\"MY_SECRET_KEY\")\n    print(\"Secret key:\", secret_key)\n    \"\"\"\n\n    default_yaml_file = root / \"config/config.yaml\"\n\n    def __init__(self, yaml_file=default_yaml_file):\n        self._config = {}\n        self.__init_with_config_files_and_env(self._config, yaml_file)\n\n    def __init_with_config_files_and_env(self, configs: dict, yaml_file):\n        for _yaml_file in [yaml_file]:\n            if not _yaml_file.exists():\n                continue\n\n            with open(_yaml_file, \"r\", encoding=\"utf-8\") as file:\n                yaml_data = yaml.safe_load(file)\n                if not yaml_data:\n                    continue\n\n                configs.update(yaml_data)\n\n        configs.update(os.environ)\n\n    def __lookup(self, dct, key):\n        if \".\" in key:\n            key, node = key.split(\".\", 1)\n            return self.__lookup(dct[key], node)\n        elif key in dct:\n            return dct[key]\n        else:\n            return None\n\n    def get(self, *keys: str, default=None):\n        for key in keys:\n            value = self._config.get(key)\n            if value is not None:\n                return value\n            value = self.__lookup(self._config, key)\n            if value is not None:\n                return value\n        return default\n\n\nconfig = Config()\n"}
{"type": "source_file", "path": "datagpt/action/text2sql.py", "content": "from datagpt.config import config\nfrom datagpt.util import root\nfrom datagpt.memory.faiss import FaissStore\nfrom datagpt.tool.llm_openai import OpenAI\nfrom datagpt.log import logger\nfrom datagpt.tool.db import db\n\nTEXT2SQL_PROMPT = \"\"\"\n## Description\nYou are a data engineer responsible for translating the requirements of management or business \npersonnel into SQL statements that can be executed in {database_type}. Information about each table \nin the database will be provided to you, including table names, table descriptions, field names, \ntypes, and descriptions for each field. You need to select the relevant tables based on this \ninformation and write the corresponding SQL statements. If the requirements go beyond the information \nprovided by these tables, please be sure to return: \"BeyondError.\"\n\nNote: ONLY ONE sql statement for each requirement.\n\n\n## Examples\nRequirement: Find the name, employee ID, and age of the oldest employee.\nSQL: SELECT employee_id, name FROM staff ORDER BY age DESC LIMIT 1;\n\nRequirement: Who is my best friend?\nSQL: BeyondError\n\n## Database Information\n{database_schema}\n\n## Task to solve\nRequirement: {requirement}\nSQL:\n\"\"\"\n\n\nclass Text2SQL:\n    def __init__(self):\n        self.llm = OpenAI()\n\n    def gen_sql(self, requirement: str) -> str:\n        # Search top k tables related to this requirement from long-term memory\n        memory_dir = config.get(\"memory.dir\")\n        schema_file = config.get(\"memory.schema_file\")\n        if not (root / memory_dir / f\"{schema_file}.pkl\").exists():\n            self._cache_schema(memory_dir, schema_file)\n\n        schema_store = FaissStore(memory_dir, schema_file)\n        schema = schema_store.search(requirement)\n        \n        # Generate sql for this requirement\n        prompt = TEXT2SQL_PROMPT.format(\n            database_type=db.get_type(), database_schema=schema, requirement=requirement\n        )\n        sql = self.llm.ask(prompt)\n        if sql == \"BeyondError\":\n            logger.error(f\"Error on generating sql for [{requirement}]\")\n\n        return sql\n\n    def _cache_schema(self, memory_dir: str, schema_file: str):\n        \"\"\"Cache schemas of all tables to long-term memory\"\"\"\n        schemas = {}\n\n        tables = db.get_tables()\n        for table in tables:\n            fields = db.get_fields(table.name)\n            schema = \"\\n\".join(\n                [\n                    f\"col:{f.col_name}, type:{f.col_type}, description:{f.col_comment}\"\n                    for f in fields\n                ]\n            )\n            schemas[\n                f\"{table.name}:{table.comment}\"\n            ] = f\"table: {table.name}\\ntable description: {table.comment}\\ncolumns information:\\n{schema}\\n\"\n\n        schema_store = FaissStore(memory_dir, schema_file)\n        schema_store.write(schemas)\n"}
{"type": "source_file", "path": "datagpt/action/data2chart.py", "content": "from datagpt.tool.llm_openai import OpenAI\nfrom datagpt.log import logger\nimport json\n\n\n# Plan 1: Stable output of config configuration\nDATA2CHART_PROMPT_CONFIG = \"\"\"\n\n## Description\nYou are a JS engineer proficient in the latest \"EChart\" framework, responsible for converting data into EChart charts. If the requirement cannot produce content in the appropriate format, please return directly: \"ChartError\".\n\nMy original question was to your \"Requirement\"\nSQL Result comes from the SQL query and is given to you in the task to be solved at the end of this paragraph.\n\nIn order to correctly render the results into the EChart chart, please carefully analyze the core query target and SQL Result of the original question.\n\nFirst, based on the requirements, original question, and the resulting data, consider the following 6 points to analyze which chart type is more suitable:\n\nThe range of chart types includes (in order of priority):\n\n1.Gauge chart (if there is only one data point in the array, prioritize using a gauge chart).\n2.Pie chart (if the original question involves querying proportions or percentages, prioritize using a pie chart).\n3.Radar chart (if the data has a single dimension and the number of data points is <= 6, prioritize generating a radar chart. In this case, the series' data array should contain only one object that includes all the values, and generate a matching indicator array based on the data in the series).\n4.Line chart.\n5.Scatter plot.\n6.Multi-series bar chart (if there are multiple series in the array, prioritize using a bar chart. Additionally, if none of the above 1-5 situations apply, use a bar chart).\nIf the conditions stated in the parentheses above are met, the corresponding type of graph should be chosen as a priority.\n\nReturn all numerical values with a maximum precision of two decimal places.\nNext, you can optimize the format of the \"result\" field, adjusting it to the data structure that you believe is most suitable for rendering the chart of the previously determined TYPE. You can replace the fields as needed.\n\nThen, based on the optimized \"result\" field, provide me with the complete JS code for the options parameter required by ECharts in the setOption function, ensuring that all dimension axes and titles meet the requirements of the original problem.\n\nYou should strictly return three items to me in the following order, adhering to the specific requirements for each field as mentioned in the comments of the JSON format.\nThe optimized \"result\" field.\nThe correct parameters required in the options used for rendering, including: x (corresponding to the field name of the x-axis), y (corresponding to the field name of the y-axis), names of the x-axis and y-axis, title, tooltip, etc. Please do not disclose any other code or comments to me.\nThe final data format you return should strictly adhere to the following requirements for JSON format. The number of elements in the array should match the number returned by the API, and there should be no additional descriptive text included.\n{{\n     \"result\" :{{\n           \"a\":[\"value1\"],\n           \"b\":[\"value2\"]\n      }},\n     \"option\":{{\n                \"type\":TYPE,\n                \"color\":[\"#95a5fd\", \"#fd7f82\", \"#fec077\", \"#fee77d\", \"#95e38f\", \"#37bbff\", \"#74b6ff\", \"#d09dff\",\"#444547\"],\n                \"grid\": {{\n                    \"top\": \"10%\"\n                }},\n                \"title\": {{\n                    \"text\": \"XXX\",//Replace the original question with more appropriate and concise wording.\n                    \"left\": \"center\"\n                }},\n                \"legend\": {{\n                    \"orient\": \"horizontal\",\n                    \"top\": \"bottom\"\n                }}\n                \"xAxis\": //only exists when TYPE is bar or lines\n                {{\n                    \"data\": [...],//you should realize a function to put all item's name into the array when type is bar or lines\n                    \"axisLabel\": {{\n                        \"rotate\": XXX,//If the number of data points is less than 5, set the value to 0. If it is less than 10, set the value to 30. If it is greater than 15, set the value to 45.\n                        \"interval\": 0\n                    }},\n                    \"show\":bool//set true when TYPE is bar or lines.others set false\n                }},\n                \"yAxis\": {{}},//only exists when TYPE is bar or lines.\n                \"series\": [{{\n                    \"name\": \"Title Based on Your Understanding\",\n                    \"type\": TYPE,\n                    \"radius\": \"40%\",//(gauge:80%,other:40%)                   \n                   \n                    \"data(only exists when TYPE is radar)\":\n                    [\n                        //Only this ONE object exists if TYPE is radar.\n                        {{\n                            \"name\":\"\",\n                            \"value\":number1,number2,...,numberN  // Put all values in the array if TYPE is radar.\n                        }}\n                        //No more objects! if TYPE is radar\n                    ]\n\n                }},{{}}],\n                \"radar\"://only exists when TYPE is radar \n                {{\n                    \"indicator\":\n                    [\n                        {{\n                            \"name\":\"series[0].name\",\n                            \"max\":MAX//Retrieve the maximum value from the 'value' array inside the 'series.data' automatically.\n                        }},{{\n                            \"name\":\"series[1].name\",\n                            \"max\":MAX//Ensure that the MAX value equals the previous MAX value\n                        }}……\n                    ]\n                }}\n        }}\n}}\n\n## Examples\nRequirement: Proportion of the area occupied by the top 6 parking spaces in terms of total area.\nSQL Result：[[\"space_name\", \"space_area\"], [\"MUJI无印良品\", 200.0], [\"优衣库\", 140.0], [\"105\", 50.0], [\"奈雪の茶\", 40.0], [\"103\", 35.0], [\"机房\", 35.0]]\nResult: {{}}\n\nRequirement: Empty data or data with excessively high dimensions\nSQL Result:empty or error format\nResult: ChartError\n\n## Task to solve\nRequirement: {requirement}\nSQL Result：{result}\nResult:\n\"\"\"\n\n\n# plan2: More aggressive dynamic function configuration\nDATA2CHART_PROMPT_FUNCTION = \"\"\"\n\n## Description\nYou are a JS engineer proficient in the latest \"EChart\" framework, responsible for converting data into EChart charts. If the requirement cannot produce content in the appropriate format, please return directly: \"ChartError\".\n\nMy original question was to your \"Requirement\"\nSQL Result comes from the SQL query and is given to you in the task to be solved at the end of this paragraph.\nIn order to correctly render the results into the EChart chart, please carefully analyze the core query target and SQL Result of the original question.\n\nFirst, based on the requirements, original question, and the resulting data, consider the following 6 points to analyze which chart type is more suitable:\n\nThe range of chart types includes (in order of priority):\n\n1.Gauge chart (if there is only one data point in the array, prioritize using a gauge chart).\n2.Pie chart (if the original question involves querying proportions or percentages, prioritize using a pie chart).\n3.Radar chart (if the data has a single dimension and the number of data points is <= 6, prioritize generating a radar chart. In this case, the series' data array should contain only one object that includes all the values, and generate a matching indicator array based on the data in the series).\n4.Line chart.\n5.Scatter plot.\n6.Multi-series bar chart (if there are multiple series in the array, prioritize using a bar chart. Additionally, if none of the above 1-5 situations apply, use a bar chart).\nIf the conditions stated in the parentheses above are met, the corresponding type of graph should be chosen as a priority.\n\nThen, you can optimize the format of the 'result' field and adjust it to the data structure that you consider most suitable for rendering the chart of the type determined in the previous step. You can use '...' to indicate the omission of a large amount of data content. You can replace the fields as needed.\nNext, based on the optimized 'result' field, please provide me with the complete dynamic JavaScript function that is required to generate the 'option' JSON string parameter for the setOption method in ECharts. In other words, I need you to return dynamic JS code. The requirements for this code are as follows:\n\n1.The first parameter is SQL Result, and in the provided code, this result needs to be dynamically transformed into key data required for various parameters in the options.\n2.The type field, which represents the table type, should be defined at the beginning of the function. Determine the specific type based on the above requirements, and directly use this type within the following JSON.\n3.The algorithm supports multiple series to ensure that the chart can display the complete data when it comes in.\n4.You only return the function code. Once the code is returned, please immediately stop answering.\n5.The returned result must adhere to the JSON format required by ECharts options to ensure the complete rendering of the chart.\n6.The XXX characters in the JSON example below need to be replaced with the most appropriate content based on your understanding of the requirements.\n7.For specific requirements of each field in the returned option, please refer to the comments in the JSON format requirements below.\n8.The data format returned by this function must strictly adhere to the following JSON format requirements, and the number of elements in the array should be the same as the data quantity returned by the API (i.e., consistent with the data volume of the first parameter of this function):\n{{\n                \"type\":TYPE,\n                \"color\":[\"#95a5fd\", \"#fd7f82\", \"#fec077\", \"#fee77d\", \"#95e38f\", \"#37bbff\", \"#74b6ff\", \"#d09dff\",\"#444547\"],\n                \"grid\": {{\n                    \"top\": \"10%\"\n                }},\n                \"title\": {{\n                    \"text\": \"XXX\",//Replace the original question with more appropriate and concise wording.\n                    \"left\": \"center\"\n                }},\n                \"legend\": {{\n                    \"orient\": \"horizontal\",\n                    \"top\": \"bottom\"\n                }}\n                \"xAxis\": //only exists when TYPE is bar or lines\n                {{\n                    \"data\": [...],//you should realize a function to put all item's name into the array when type is bar or lines\n                    \"axisLabel\": {{\n                        \"rotate\": XXX,//If the number of data points is less than 5, set the value to 0. If it is less than 10, set the value to 30. If it is greater than 15, set the value to 45.\n                        \"interval\": 0\n                    }},\n                    \"show\":bool//set true when TYPE is bar or lines.others set false\n                }},\n                \"yAxis\": {{}},//only exists when TYPE is bar or lines.\n                \"series\": [{{\n                    \"name\": \"Title Based on Your Understanding\",\n                    \"type\": TYPE,\n                    \"radius\": \"40%\",//(gauge:80%,other:40%)                   \n                   \n                    \"data(only exists when TYPE is radar)\":\n                    [\n                        //Only this ONE object exists if TYPE is radar.\n                        {{\n                            \"name\":\"\",\n                            \"value\":[number1,number2,...,numberN]//Put all values in the array if TYPE is radar.\n                        }}\n                        //No more objects! if TYPE is radar\n                    ]\n\n                }},{{}}],\n                \"radar\"://only exists when TYPE is radar \n                {{\n                    \"indicator\":\n                    [\n                        {{\n                            \"name\":\"series[0].name\",\n                            \"max\":MAX//Retrieve the maximum value from the 'value' array inside the 'series.data' automatically.\n                        }},{{\n                            \"name\":\"series[1].name\",\n                            \"max\":MAX//Ensure that the MAX value equals the previous MAX value\n                        }}……\n                    ]\n                }}\n}}\n\n\n## Examples\nRequirement: Proportion of the area occupied by the top 6 parking spaces in terms of total area.\nSql Result:[[\"space_name\", \"space_area\"], [\"nameAA\", 200.0], ……, [\"nameYY\", 35.0], [\"nameZZ\", 35.0]]\nResult: \nfunction generateOption(apiResultList){{\n    var option= {{}};// Initialization of the entire options content, it must be in JSON format.\n    var type = \"pie\";//Here, the comment explains the reasons for choosing the chart type.\n    //This is the specific algorithm to break down the apiResultList data.\n    //Here is the complete content that meets the requirements of the option:\n    //1、build option basic structure by template before\n    //2、filling all the titles and data by a dynamic function\n    //3、check the option again and promise it works currectly\n    return option;\n}}\n//NO Note!\n\nRequirement: An illogical question\nSql Result:Empty data or data with excessively high dimensions\nResult: ChartError\n//NO Note!\n\n## Task to solve\nRequirement: {requirement}\nSql Result:{result}\nResult:\n\"\"\"\n\n\nclass Data2Chart:\n    def __init__(self):\n        self.llm = OpenAI()\n\n    def gen_chart(self, requirement: str, result: list, render_mode: str) -> str:\n        if render_mode == \"Config\":\n            result = json.dumps(result)\n            prompt = DATA2CHART_PROMPT_CONFIG.format(\n                requirement=requirement, result=result\n            )\n        elif render_mode == \"Function\":\n            # TODO:Provide fewer data samples and allow AI to know the format based on limited data\n            # if len(result) >= 3:\n            #     result = [result[0],result[1],result[-1]]\n            result = json.dumps(result)\n            prompt = DATA2CHART_PROMPT_FUNCTION.format(\n                requirement=requirement, result=result\n            )\n\n        return self.llm.ask(prompt)\n"}
{"type": "source_file", "path": "datagpt/memory/__init__.py", "content": ""}
{"type": "source_file", "path": "datagpt/memory/faiss.py", "content": "import os\nimport pickle\n\nimport faiss\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import FAISS\n\nfrom datagpt.config import config\nfrom datagpt.util import root\n\n\nclass FaissStore:\n    def __init__(self, dir: str, name: str):\n        self.name = name\n        if not os.path.exists(root / dir):\n            os.mkdir(root / dir)\n\n        self.store_file = root / dir / f\"{name}.pkl\"\n        self.index_file = root / dir / f\"{name}.index\"\n\n        if not (self.index_file.exists() and self.store_file.exists()):\n            self.store = None\n        else:\n            with open(str(self.store_file), \"rb\") as f:\n                self.store = pickle.load(f)\n            self.store.index = faiss.read_index(str(self.index_file))\n\n    def _persist(self):\n        faiss.write_index(self.store.index, str(self.index_file))\n        index = self.store.index\n        self.store.index = None\n        with open(self.store_file, \"wb\") as f:\n            pickle.dump(self.store, f)\n        self.store.index = index\n\n    def write(self, schemas: dict):\n        \"\"\"batch writing all table schemas into long-term memory\n        schemas should be\n          {\n            'table description': 'table schema',\n            'table description': 'table schema'\n          }\n        \"\"\"\n        if config.get(\"llm.openai.azure\") is not None:\n            embeddings = OpenAIEmbeddings(\n                deployment=config.get(\"llm.openai.azure.embedding_deployment\"),\n                openai_api_base=config.get(\n                    \"llm.openai.api_base\", default=\"https://api.openai.com/v1\"\n                ),\n                openai_api_key=config.get(\"llm.openai.api_key\"),\n                openai_api_type=\"azure\",\n                chunk_size=16,\n            )\n        else:\n            embeddings = OpenAIEmbeddings(\n                openai_api_key=config.get(\"llm.openai.api_key\"), chunk_size=16\n            )\n\n        self.store = FAISS.from_texts(\n            list(schemas.keys()),\n            embeddings,\n            metadatas=[{k: schemas[k]} for k in schemas],\n        )\n        self._persist()\n\n    def search(self, query, k=10):\n        \"\"\"search top k tables that most relating to the query\"\"\"\n        r = self.store.similarity_search(query, k=k)\n        return str(\"\\n\".join([f\"{x.metadata}\" for x in r]))\n"}
{"type": "source_file", "path": "datagpt/action/__init__.py", "content": ""}
{"type": "source_file", "path": "datagpt/tool/db/__init__.py", "content": "from datagpt.config import config\nfrom datagpt.log import logger\nfrom datagpt.tool.db.mysql import MySQL\nfrom datagpt.tool.db.postgres import PostgreSQL\n\n\ndef get_db():\n    db_type = config.get(\"database.type\")\n    db_uri = config.get(\"database.uri\")\n    if db_type == \"postgresql\":\n        return PostgreSQL(db_uri)\n    elif db_type == \"mysql\":\n        return MySQL(db_uri)\n    else:\n        logger.exception(\"No vaild database config\")\n\n\ndb = get_db()\n\n__all__ = [\"db\"]\n"}
{"type": "source_file", "path": "datagpt/log.py", "content": "import sys\n\nfrom loguru import logger as _logger\n\nfrom datagpt.util import root\n\n\ndef get_logger(print_level=\"INFO\", logfile_level=\"DEBUG\"):\n    _logger.remove()\n    _logger.add(sys.stderr, level=print_level)\n\n    _logger.add(root / \"logs/log.txt\", level=logfile_level)\n    return _logger\n\n\nlogger = get_logger()\n"}
{"type": "source_file", "path": "datagpt/tool/db/mysql.py", "content": "from typing import Iterable, List\nfrom datagpt.tool.db.base import RDBMS, FieldInfo, TableInfo\n\nfrom urllib.parse import urlparse\nimport mysql.connector\n\nfrom datagpt.log import logger\n\n\nclass MySQL(RDBMS):\n    def __init__(self, uri: str):\n        self._uri = uri\n\n        o = urlparse(uri)\n        config = {\n            \"host\": o.hostname,\n            \"port\": o.port,\n            \"user\": o.username,\n            \"password\": o.password,\n            \"database\": o.path[1:],\n        }\n\n        self._conn = mysql.connector.connect(**config)\n\n    def get_type(self) -> str:\n        return \"MySQL\"\n\n    def get_tables(self) -> Iterable[TableInfo]:\n        cur = self._conn.cursor()\n        cur.execute(\n            \"\"\"\n            SELECT table_name, table_comment\n            FROM information_schema.tables\n            WHERE table_schema = DATABASE();\n        \"\"\"\n        )\n        tb_infos = cur.fetchall()\n        cur.close()\n\n        return [TableInfo(name, comment) for name, comment in tb_infos]\n\n    def get_fields(\n        self, table_name: str, schema: str = \"public\"\n    ) -> Iterable[FieldInfo]:\n        cur = self._conn.cursor()\n        cur.execute(\n            \"\"\"\n            SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH, COLUMN_DEFAULT, IS_NULLABLE, COLUMN_COMMENT\n            FROM information_schema.columns\n            WHERE table_schema = DATABASE() AND table_name = %s\n            ORDER BY ORDINAL_POSITION;\n        \"\"\",\n            (table_name,),\n        )\n        fields = cur.fetchall()\n        cur.close()\n\n        return [\n            FieldInfo(name, type, length, default, nullable, comment)\n            for name, type, length, default, nullable, comment in fields\n        ]\n\n    def run(self, command: str) -> List:\n        try:\n            cur = self._conn.cursor()\n            cur.execute(command)\n            rows = cur.fetchall()\n            cols = cur.description\n            rows.insert(0, tuple([col[0] for col in cols]))\n            return rows\n        except Exception as e:\n            logger.error(\"run sql error: \" + str(e))\n            return \"SqlError\"\n        finally:\n            cur.close()\n"}
{"type": "source_file", "path": "datagpt/tool/__init__.py", "content": ""}
{"type": "source_file", "path": "datagpt/action/fetch_data.py", "content": "from datagpt.config import config\nfrom datagpt.tool.db import db\n\n\nclass FetchData:\n    def __init__(self):\n        self.db = db\n\n    def fetch(self, sql: str):\n        return self.db.run(sql)\n"}
{"type": "source_file", "path": "datagpt/datagpt.py", "content": "from datagpt.action import text2sql, fetch_data, data2chart\nfrom datagpt.log import logger\n\n\nclass DataGPT:\n    def __init__(self):\n        self.text2sql = text2sql.Text2SQL()\n        self.fetchdata = fetch_data.FetchData()\n        self.data2chart = data2chart.Data2Chart()\n\n    def run(self, text: str, render_mode: str):\n        \"\"\"from text to chart\"\"\"\n\n        logger.debug(f\"input text: {text}\")\n        sql = self.text2sql.gen_sql(text)\n        if sql == \"BeyondError\":\n            return sql, None, None\n\n        logger.debug(f\"generated sql: {sql}\")\n        return self.__excute_sql(sql, text, render_mode)\n\n    def run_sql(self, text: str, sql: str, render_mode: str):\n        \"\"\"from sql to chart\"\"\"\n\n        logger.debug(f\"input sql: {sql}\")\n        return self.__excute_sql(sql, text, render_mode)\n\n    def __excute_sql(self, sql, text, render_mode):\n        data = self.fetchdata.fetch(sql)\n        if data == \"SqlError\":\n            return sql, data, None\n\n        logger.debug(f\"fetched data: {data}\")\n        chart = self.data2chart.gen_chart(text, data, render_mode)\n        logger.debug(f\"rendered chart: {chart}\")\n\n        return sql, data, chart\n"}
{"type": "source_file", "path": "datagpt/tool/db/postgres.py", "content": "from typing import Iterable, List\n\nfrom psycopg_pool import ConnectionPool\n\nfrom datagpt.tool.db.base import RDBMS, FieldInfo, TableInfo\nfrom datagpt.log import logger\n\n\nclass PostgreSQL(RDBMS):\n    def __init__(self, uri: str):\n        self._pool = ConnectionPool(uri)\n\n    def get_type(self) -> str:\n        return \"PostgreSQL\"\n\n    def get_tables(self) -> Iterable[TableInfo]:\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                tb_infos = cur.execute(\n                    \"\"\"\n                    SELECT tb.table_name, d.description\n                    FROM information_schema.tables tb\n                        LEFT JOIN pg_namespace b ON b.nspname = tb.table_schema\n                        LEFT JOIN pg_class c ON c.relname = tb.table_name AND c.relnamespace = b.oid\n                        LEFT JOIN pg_description d ON d.objoid = c.oid AND d.objsubid = '0'\n                    WHERE tb.table_schema = 'public' and tb.table_type = 'BASE TABLE';\n                \"\"\"\n                ).fetchall()\n                return [TableInfo(name, comment) for name, comment in tb_infos]\n\n    def get_fields(\n        self, table_name: str, schema: str = \"public\"\n    ) -> Iterable[FieldInfo]:\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                fields = cur.execute(\n                    \"\"\"\n                    SELECT\n                        c.column_name,\n                        c.udt_name,\n                        character_maximum_length,\n                        c.column_default,\n                        c.is_nullable,\n                        pgd.description AS column_comment\n                    FROM\n                        information_schema.columns c\n                    LEFT JOIN\n                        pg_catalog.pg_description pgd ON pgd.objoid = (select oid from pg_class where relnamespace=(select oid from pg_namespace where nspname=%(schema)s) and relname=%(table)s) AND pgd.objsubid = c.ordinal_position\n                    WHERE\n                        c.table_schema = %(schema)s AND c.table_name = %(table)s\n                    ORDER BY\n                        c.ordinal_position;\n                \"\"\",\n                    {\"table\": table_name, \"schema\": schema},\n                ).fetchall()\n\n                return [\n                    FieldInfo(name, type, length, default, nullable, comment)\n                    for name, type, length, default, nullable, comment in fields\n                ]\n\n    def run(self, command: str) -> List:\n        try:\n            with self._pool.connection() as conn:\n                with conn.cursor() as cur:\n                    rows = cur.execute(command).fetchall()\n                    cols = cur.description\n                    rows.insert(0, tuple([col.name for col in cols]))\n                    return rows\n        except Exception as e:\n            logger.error(\"run sql error: \" + str(e))\n            return \"SqlError\"\n"}
{"type": "source_file", "path": "datagpt/util.py", "content": "from pathlib import Path\n\n\ndef get_project_root():\n    current_path = Path.cwd()\n    while True:\n        if (current_path / \".project_root\").exists():\n            return current_path\n        parent_path = current_path.parent\n        if parent_path == current_path:\n            raise Exception(\"Project root not found.\")\n        current_path = parent_path\n\n\nroot = get_project_root()\n"}
{"type": "source_file", "path": "server/app.py", "content": "import sys, os\n\nsys.path.append((os.path.abspath(os.path.join(os.path.dirname(__file__), \"../\"))))\n\n\nimport json\nimport gradio as gr\n\nfrom datagpt.datagpt import DataGPT\n\n# Config Mode: Genrating echart option config directly\n# Function Mode:Generating option render function which be called to generate option config\nrender_mode = \"Config\"\ndatagpt = DataGPT()\n\n\ndef search(prompt):\n    if prompt == \"error\":\n        raise gr.Error(\"Error!\")\n    sql, data, chart = datagpt.run(prompt, render_mode)\n    return render_chart(sql, data, chart)\n\n\ndef reexcute_sql(prompt, sql):\n    sql, data, chart = datagpt.run_sql(prompt, sql, render_mode)\n    return render_chart(sql, data, chart)\n\n\ndef render_chart(sql, data, chart):\n    if sql == \"BeyondError\":\n        raise gr.Error(\"Unable to generate SQL statement, please ask in another way!\")\n    elif data == \"SqlError\":\n        return [\n            sql,  # SQL statement\n            gr.update(visible=True),\n            \"\",  # chart iframe\n            \"\",  # chart source code\n            \"\",  # data table\n            [\n                {\n                    \"\": \"\",\n                    \"SQL execution encountered an error, You can modify it below and execute it again.\": \"red\",\n                },\n            ],\n            gr.Highlight.update(visible=True),\n        ]\n    else:\n        chart_iframe, chart_source_code = gen_chart_iframe(chart, json.dumps(data))\n        return [\n            sql,  # SQL statement\n            gr.update(visible=True),  # sql data result\n            chart_iframe,  # chart iframe\n            chart_source_code,  # chart source code\n            gen_table_iframe(data),  # data table\n            [],\n            gr.Highlight.update(visible=False),\n        ]\n\n\ndef gen_chart_iframe(echart_option, result_data):\n    html = \"\"\n    # Solution 1: Fill with AI-generated Options\n    if render_mode == \"Config\":\n        echart_option = json.loads(echart_option.encode(\"utf-8\"))\n        echart_option = echart_option[\"option\"]\n\n        html = \"\"\"\n<head>\n    <title>DataGPT</title>\n        <script src=\"https://cdn.jsdelivr.net/npm/echarts@5.4.1/dist/echarts.min.js\"></script>\n</head>\n    <body>\n        <div id=\"main\" style=\"width: 100%;height:350px;\"></div>\n            <script>\n                var chart = echarts.init(document.getElementById(\"main\"));\n                var option = {option}   \n                chart.setOption(option);\n            </script>\n    </body>\n            \"\"\"\n        html = html.format(option=json.dumps(echart_option))\n\n    # Solution 2: Using AI-generated dynamic functions combined with real data to dynamically generate options\n    elif render_mode == \"Function\":\n        html = \"\"\"\n<head>\n    <title>DataGPT</title>\n        <script src=\"https://cdn.jsdelivr.net/npm/echarts@5.4.1/dist/echarts.min.js\"></script>\n</head>\n<body>\n        <div id=\"main\" style=\"width: 100%;height:350px;\"></div>\n            <script>\n                var chart = echarts.init(document.getElementById(\"main\"));\n                {generate_option}\n                var sql_result = {result_data}\n                var option = generateOption(sql_result);  \n                console.log(JSON.stringify(option));\n                chart.setOption(option);\n            </script>\n</body>\n            \"\"\"\n        html = html.format(generate_option=echart_option, result_data=result_data)\n\n    return [\n        f\"\"\"<iframe style=\"width: 100%; height: 400px\" srcdoc='{html}'></iframe>\"\"\",\n        f\"\"\"```html{html}\"\"\",\n    ]\n\n\ndef gen_table_iframe(data):\n    html = \"\"\"\n<head>\n</head>\n<body>\n  <table style=\"width:100%; border-radius:10px; border:#eee 1px solid; border-spacing:0px; border-collapse:separate; font-size:13px; font-family:Arial;\">\n    <tr style=\"background-color:transparent; border:0; height:40px\">\n        {tds}\n    </tr>\n    {trs}   \n  </table>\n</body>\n\"\"\"\n    tds_html = \"\"\n    trs_html = \"\"\n    columns = data[0]\n\n    # render headers\n    for col in columns:\n        td = \"\"\"<td style=\"padding-left:10px;\"><strong>{value}<strong></td>\"\"\"\n        td = td.format(value=str(col))\n        tds_html += td\n\n    # render rows\n    if len(data) >= 1:\n        data = data[1:]\n        index = 0\n        for row in data:\n            tr = \"\"\"\n                <tr style=\"background-color:{bg_color};border:0;height:40px;\">\n                    {tds}\n                </tr>\"\"\"\n\n            bg_color = \"\"\n            if index % 2 == 1:\n                bg_color = \"transparent\"\n            else:\n                bg_color = \"#f9fafb\"\n\n            tds = \"\"\n            for col in row:\n                td = \"\"\"<td style=\"padding-left:10px;\">{value}</td>\"\"\"\n                td = td.format(value=str(col))\n                tds += td\n            tr = tr.format(tds=tds, bg_color=bg_color)\n            trs_html += tr\n            index += 1\n\n    html = html.format(tds=tds_html, trs=trs_html)\n    return (\n        f\"\"\"<iframe style=\"width: 100%; min-height: 640px\" srcdoc='{html}'></iframe>\"\"\"\n    )\n\n\ndef change_mode(mode):\n    global render_mode\n    render_mode = mode\n    if mode == \"Config\":\n        return gr.update(info=\"Config Mode: Genrating echart option config directly\")\n    elif mode == \"Function\":\n        return gr.update(\n            info=\"Function Mode:Generating option render function which be called to generate option config\"\n        )\n\n\ndef launch_app():\n    chart_iframe = gr.HTML(\"Chart\")\n    chart_source_code = gr.Markdown(\"Chart source code\")\n\n    with gr.Blocks(title=\"DataGPT\", css=\"label {font-size:12px}\") as ui:\n        gr.Markdown(\n            \"\"\"\n            # DataGPT\n            AI Agent for Natural Language Queries to Generate Charts from a Database.\n            \"\"\"\n        )\n\n        with gr.Row():\n            with gr.Column(scale=2):\n                input_prompt = gr.Textbox(\n                    value=\"What are the specific grades of each student in each course?\",\n                    label=\"Question\",\n                    placeholder=\"Please input question\",\n                )\n                radio = gr.Radio(\n                    choices=[\"Config\", \"Function\"],\n                    type=\"value\",\n                    value=\"Config\",\n                    label=\"Render Mode\",\n                    info=\"Option Config Mode:Genrating echart option config directly\",\n                )\n                btn = gr.Button(value=\"Submit\", variant=\"primary\")\n                error_info = gr.HighlightedText(\n                    label=\"\",\n                    visible=False,\n                    combine_adjacent=True,\n                    show_legend=True,\n                    color_map={\n                        \"SQL execution encountered an error, You can modify it below and execute it again.\": \"red\"\n                    },\n                )\n                lbl_sql = gr.Code(\n                    value=\"The sql will be displayed here.\",\n                    language=\"markdown\",\n                    interactive=True,\n                    lines=1,\n                )\n                btn_exe_sql = gr.Button(\n                    value=\"Modify and Re-execute the SQL Statement\",\n                    size=\"sm\",\n                    visible=False,\n                )\n            with gr.Column(scale=2):\n                demo = gr.TabbedInterface(\n                    [chart_iframe, chart_source_code], [\"Chart\", \"Source Code\"]\n                )\n        with gr.Row():\n            table_iframe = gr.HTML(\"\")\n\n        radio.change(change_mode, inputs=[radio], outputs=[radio])\n        btn.click(\n            search,\n            inputs=input_prompt,\n            outputs=[\n                lbl_sql,\n                btn_exe_sql,\n                chart_iframe,\n                chart_source_code,\n                table_iframe,\n                error_info,\n                error_info,\n            ],\n        )\n        btn_exe_sql.click(\n            reexcute_sql,\n            inputs=[input_prompt, lbl_sql],\n            outputs=[\n                lbl_sql,\n                btn_exe_sql,\n                chart_iframe,\n                chart_source_code,\n                table_iframe,\n                error_info,\n                error_info,\n            ],\n        )\n        ui.launch(share=True)\n\n\nlaunch_app()\n"}
{"type": "source_file", "path": "datagpt/tool/llm_openai.py", "content": "import openai\nfrom datagpt.log import logger\nfrom datagpt.config import config\n\n\nclass OpenAI:\n    \"\"\"LLM api to OpenAI ChatGPT models.\"\"\"\n\n    def __init__(self) -> None:\n        if config.get(\"llm.openai.azure\") is not None:\n            openai.api_type = \"azure\"\n            openai.api_version = config.get(\n                \"llm.openai.azure.api_version\", default=\"2023-05-15\"\n            )\n        openai.api_base = config.get(\n            \"llm.openai.api_base\", default=\"https://api.openai.com/v1\"\n        )\n        openai.api_key = config.get(\"llm.openai.api_key\")\n\n    def completion(self, messages: list[dict]) -> str:\n        if openai.api_type == \"azure\":\n            engine = config.get(\"llm.openai.azure.engine\")\n            chat_completion = openai.ChatCompletion.create(\n                engine=engine, messages=messages, temperature=0\n            )\n        else:\n            model = config.get(\"llm.openai.api_model\")\n            chat_completion = openai.ChatCompletion.create(\n                model=model, messages=messages, temperature=0\n            )\n        return chat_completion.choices[0].message.content\n\n    def ask(self, prompt: str) -> str:\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        return self.completion(messages)"}
{"type": "source_file", "path": "datagpt/tool/db/base.py", "content": "from abc import ABCMeta, abstractmethod\nfrom typing import Iterable, List, Optional\n\n\nclass TableInfo:\n    name: str\n    comment: str\n\n    def __init__(self, name: str, comment: Optional[str] = None):\n        self.name = name\n        self.comment = comment\n\n    def __str__(self):\n        return f\"TableInfo(name={self.name}, comment={self.comment})\"\n\n\nclass FieldInfo:\n    col_name: str\n    col_type: str\n    col_length: Optional[int]\n    col_default: str\n    is_nullable: bool\n    col_comment: str\n\n    def __init__(\n        self,\n        col_name: str,\n        col_type: str,\n        col_length: Optional[int],\n        col_default: str,\n        is_nullable: bool = False,\n        col_comment: Optional[str] = None,\n    ):\n        self.col_name = col_name\n        self.col_type = col_type\n        self.col_length = col_length\n        self.col_default = col_default\n        self.is_nullable = is_nullable\n        self.col_comment = col_comment\n\n    def __str__(self):\n        return f\"FieldInfo(col_name={self.col_name}, col_type={self.col_type}, col_length={self.col_length}, col_default={self.col_default}, is_nullable={self.is_nullable}, col_comment={self.col_comment})\"\n\n\nclass RDBMS(metaclass=ABCMeta):\n    @abstractmethod\n    def get_type(self) -> str:\n        pass\n\n    @abstractmethod\n    def get_tables(self) -> Iterable[TableInfo]:\n        pass\n\n    @abstractmethod\n    def get_fields(\n        self, table_name: str, schema: str = \"public\"\n    ) -> Iterable[FieldInfo]:\n        pass\n\n    @abstractmethod\n    def run(self, command: str) -> List:\n        pass\n"}
