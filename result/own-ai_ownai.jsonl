{"repo_info": {"repo_name": "ownai", "repo_owner": "own-ai", "repo_url": "https://github.com/own-ai/ownai"}}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/test_auth.py", "content": "\"\"\"Test the authentication.\"\"\"\nimport pytest\nfrom flask import g, session\n\nfrom backaind.auth import (\n    add_user,\n    is_password_correct,\n    set_password,\n    set_password_command,\n    login_required,\n)\nfrom backaind.extensions import db\nfrom backaind.models import User\n\n\ndef test_login(client, auth):\n    \"\"\"Test whether login works and redirects to index page.\"\"\"\n    assert client.get(\"/auth/login\").status_code == 200\n    response = auth.login()\n    assert response.headers[\"Location\"] == \"/\"\n\n    with client:\n        client.get(\"/\")\n        assert session[\"user_id\"] == 1\n        assert g.user.username == \"test\"\n\n\n@pytest.mark.parametrize(\n    (\"username\", \"password\", \"message\"),\n    (\n        (\"a\", \"test\", b\"Incorrect username or password.\"),\n        (\"test\", \"a\", b\"Incorrect username or password.\"),\n    ),\n)\ndef test_login_validate_input(auth, username, password, message):\n    \"\"\"Test whether entering invalid credentials returns an error message.\"\"\"\n    response = auth.login(username, password)\n    assert message in response.data\n\n\ndef test_logout(client, auth):\n    \"\"\"Test whether logout removes the user from session.\"\"\"\n    auth.login()\n\n    with client:\n        auth.logout()\n        assert \"user_id\" not in session\n\n\ndef test_is_password_correct(app):\n    \"\"\"Test whether checking the password works.\"\"\"\n    with app.app_context():\n        assert not is_password_correct(\"test\", \"a\")\n        assert not is_password_correct(\"a\", \"test\")\n        assert is_password_correct(\"test\", \"test\")\n\n\ndef test_set_password(app):\n    \"\"\"Test whether setting the password works.\"\"\"\n    with app.app_context():\n        set_password(\"test\", \"a\")\n        assert not is_password_correct(\"test\", \"test\")\n        assert is_password_correct(\"test\", \"a\")\n        set_password(\"test\", \"test\")\n        assert is_password_correct(\"test\", \"test\")\n\n\ndef test_login_required_redirects_if_not_logged_in(app, client):\n    \"\"\"Test whether the login_required decorator redirects to login page.\"\"\"\n    with app.app_context(), app.test_request_context():\n        client.get(\"/\")\n        response = login_required(lambda: \"the_view\")()\n        assert (\n            not isinstance(response, str)\n            and response.headers[\"Location\"] == \"/auth/login\"\n        )\n\n\ndef test_login_required_accepts_user(app, client, auth):\n    \"\"\"Test whether the login_required decorator allows signed in users.\"\"\"\n    with app.app_context(), app.test_request_context():\n        auth.login()\n        client.get(\"/\")\n        response = login_required(lambda: \"the_view\")()\n        assert response == \"the_view\"\n\n\ndef test_add_user_command(app, runner):\n    \"\"\"Test whether registering a new user works.\"\"\"\n    username = \"a-new-user\"\n    password = \"a-password\"\n    with app.app_context():\n        user = db.session.query(User).filter_by(username=username).first()\n        assert user is None\n\n        result = runner.invoke(add_user, input=f\"{username}\\n{password}\\n{password}\\n\")\n        assert \"Registration successful\" in result.output\n\n        user = db.session.query(User).filter_by(username=username).first()\n        assert user is not None\n\n        result = runner.invoke(add_user, input=f\"{username}\\n{password}\\n{password}\\n\")\n        assert \"already registered\" in result.output\n\n\ndef test_set_password_command(app, runner):\n    \"\"\"Test whether setting the password works.\"\"\"\n    username = \"test\"\n    password = \"a-password\"\n    with app.app_context():\n        assert is_password_correct(username, \"test\")\n        result = runner.invoke(\n            set_password_command, input=f\"{username}\\n{password}\\n{password}\\n\"\n        )\n        assert \"Successfully set the password\" in result.output\n        assert is_password_correct(username, password)\n        assert not is_password_correct(username, \"test\")\n        set_password(\"test\", \"test\")\n"}
{"type": "test_file", "path": "tests/test_settings.py", "content": "\"\"\"Test the settings blueprint.\"\"\"\nimport pytest\nfrom flask import session\nfrom backaind.auth import is_password_correct, set_password\nfrom backaind.settings import EXTERNAL_PROVIDER_ENVVARS, get_settings\n\nSETTINGS_PATHS = (\n    \"/settings/password\",\n    \"/settings/external-providers\",\n)\n\n\n@pytest.mark.parametrize(\"path\", SETTINGS_PATHS)\ndef test_login_required(client, path):\n    \"\"\"Test whether login is required to view all settings paths.\"\"\"\n    response = client.get(path)\n    assert response.headers[\"Location\"] == \"/auth/login\"\n\n\ndef test_get_password_change_page(client, auth):\n    \"\"\"Test whether the password change page gets displayed.\"\"\"\n    auth.login()\n    response = client.get(\"/settings/password\")\n    assert b\"Change Password\" in response.data\n\n\ndef test_password_change_fails_on_incorrect_current_password(auth, app, client):\n    \"\"\"Test whether the password does not get changed when the current password is incorrect.\"\"\"\n    with app.app_context():\n        auth.login()\n        assert is_password_correct(\"test\", \"test\")\n        response = client.post(\n            \"/settings/password\",\n            data={\n                \"current-password\": \"a\",\n                \"new-password\": \"test\",\n                \"new-password-confirmation\": \"test\",\n            },\n        )\n        assert b\"Incorrect current password.\" in response.data\n        assert not is_password_correct(\"test\", \"a\")\n        assert is_password_correct(\"test\", \"test\")\n\n\ndef test_password_change_fails_on_non_matching_passwords(auth, app, client):\n    \"\"\"\n    Test whether the password does not get changed when the password and\n    the password confirmation do not match.\n    \"\"\"\n    with app.app_context():\n        auth.login()\n        assert is_password_correct(\"test\", \"test\")\n        response = client.post(\n            \"/settings/password\",\n            data={\n                \"current-password\": \"test\",\n                \"new-password\": \"a\",\n                \"new-password-confirmation\": \"b\",\n            },\n        )\n        assert b\"Password and confirmation do not match.\" in response.data\n        assert not is_password_correct(\"test\", \"a\")\n        assert is_password_correct(\"test\", \"test\")\n\n\ndef test_password_change_fails_on_too_short_password(auth, app, client):\n    \"\"\"Test whether the password does not get changed when the new password is too short.\"\"\"\n    with app.app_context():\n        auth.login()\n        assert is_password_correct(\"test\", \"test\")\n        response = client.post(\n            \"/settings/password\",\n            data={\n                \"current-password\": \"test\",\n                \"new-password\": \"a\",\n                \"new-password-confirmation\": \"a\",\n            },\n        )\n        assert b\"Password must be at least 10 characters long.\" in response.data\n        assert not is_password_correct(\"test\", \"a\")\n        assert is_password_correct(\"test\", \"test\")\n\n\ndef test_password_change_works(auth, app, client):\n    \"\"\"Test whether the password change works.\"\"\"\n    with app.app_context():\n        auth.login()\n        assert is_password_correct(\"test\", \"test\")\n        response = client.post(\n            \"/settings/password\",\n            data={\n                \"current-password\": \"test\",\n                \"new-password\": \"a\" * 10,\n                \"new-password-confirmation\": \"a\" * 10,\n            },\n        )\n        assert b\"Password changed successfully.\" in response.data\n        assert not is_password_correct(\"test\", \"test\")\n        assert is_password_correct(\"test\", \"a\" * 10)\n        set_password(\"test\", \"test\")\n        assert not is_password_correct(\"test\", \"a\" * 10)\n        assert is_password_correct(\"test\", \"test\")\n\n\ndef test_get_external_providers_page(client, auth):\n    \"\"\"Test whether the external providers page gets displayed.\"\"\"\n    auth.login()\n    response = client.get(\"/settings/external-providers\")\n    assert b\"<h3>Connect to external AI providers</h3>\" in response.data\n\n\ndef test_save_external_providers(auth, client):\n    \"\"\"Test whether external providers get inserted, updated and deleted correctly.\"\"\"\n    with client:\n        auth.login()\n        user_id = session[\"user_id\"]\n        provider1 = EXTERNAL_PROVIDER_ENVVARS[0]\n        provider2 = EXTERNAL_PROVIDER_ENVVARS[1]\n        assert get_settings(user_id).get(\"external-providers\", {}) == {}\n\n        response = client.post(\n            \"/settings/external-providers\",\n            data={\n                provider1: \"test1\",\n                provider2: \"test2\",\n            },\n        )\n        assert b\"Settings saved successfully.\" in response.data\n        assert (\n            get_settings(user_id).get(\"external-providers\", {}).get(provider1)\n            == \"test1\"\n        )\n        assert (\n            get_settings(user_id).get(\"external-providers\", {}).get(provider2)\n            == \"test2\"\n        )\n\n        response = client.post(\n            \"/settings/external-providers\",\n            data={\n                provider2: \"test2_new\",\n            },\n        )\n        assert b\"Settings saved successfully.\" in response.data\n        assert (\n            get_settings(user_id).get(\"external-providers\", {}).get(provider1) is None\n        )\n        assert (\n            get_settings(user_id).get(\"external-providers\", {}).get(provider2)\n            == \"test2_new\"\n        )\n\n        response = client.post(\n            \"/settings/external-providers\",\n            data={},\n        )\n        assert b\"Settings saved successfully.\" in response.data\n        assert get_settings(user_id).get(\"external-providers\", {}) == {}\n"}
{"type": "test_file", "path": "tests/test_aifile.py", "content": "\"\"\"Test loading and validation of aifiles.\"\"\"\nimport pytest\n\nfrom backaind.aifile import (\n    add_ai,\n    download_model,\n    get_input_keys,\n    read_aifile_from_path,\n    validate_aifile,\n    InvalidAifileError,\n)\nfrom backaind.extensions import db\nfrom backaind.models import Ai\n\n\n@pytest.mark.parametrize(\n    \"aifile\",\n    (\n        {},\n        {\"name\": \"test\"},\n        {\"aifileversion\": 1},\n        {\"chain\": {}},\n        {\"name\": \"test\", \"aifileversion\": 1},\n        {\"name\": \"test\", \"chain\": {}},\n        {\"aifileversion\": 1, \"chain\": {}},\n    ),\n)\ndef test_validate_aifile_raises_on_missing_fields(aifile):\n    \"\"\"Test if the validation complains on missing fields.\"\"\"\n    with pytest.raises(InvalidAifileError) as error:\n        validate_aifile(aifile)\n\n    assert \"Missing field\" in str(error.value)\n\n\ndef test_validate_aifile_raises_on_newer_aifileversion():\n    \"\"\"Test if the validation complains if the aifile version is too new.\"\"\"\n    with pytest.raises(InvalidAifileError) as error:\n        validate_aifile({\"name\": \"test\", \"aifileversion\": 2, \"chain\": {}})\n\n    assert \"This aifile requires a newer version of ownAI.\" in str(error.value)\n\n\ndef test_validate_aifile_raises_on_unknown_input_keys():\n    \"\"\"Test if the validation complains on unknown input types.\"\"\"\n    with pytest.raises(InvalidAifileError) as error:\n        validate_aifile(\n            {\"name\": \"test\", \"aifileversion\": 1, \"chain\": {\"input_key\": \"input_money\"}}\n        )\n\n    assert \"Unknown input key\" in str(error.value)\n\n\ndef test_get_input_keys_always_returns_set():\n    \"\"\"Test if get_input_keys always returns a (possibly empty) set.\"\"\"\n    assert get_input_keys(None) == set()\n\n\ndef test_get_input_keys_returns_nested_inputs():\n    \"\"\"Test if get_input_keys returns nested inputs and only inputs.\"\"\"\n    aifile = {\n        \"chain\": {\n            \"nested_list\": [\n                {\"chain1\": {\"input_key\": \"input_a\"}},\n                {\"chain2\": {\"input_variables\": [\"input_b\", \"input_c\", \"not_an_input\"]}},\n            ]\n        }\n    }\n    assert get_input_keys(aifile) == {\"input_a\", \"input_b\", \"input_c\"}\n\n\ndef test_read_aifile_from_path_returns_aifile():\n    \"\"\"Test if reading an aifile from a file works.\"\"\"\n    aifile = read_aifile_from_path(\n        \"examples/huggingface_hub/OpenAssistant_SFT-4_12B.aifile\"\n    )\n    assert \"OpenAssistant\" in aifile[\"name\"]\n\n\ndef test_add_ai_command_adds_ai(app, runner):\n    \"\"\"Test if the add-ai command adds a new AI to the database.\"\"\"\n    ai_file = \"examples/huggingface_hub/OpenAssistant_SFT-4_12B.aifile\"\n    ai_name = \"OpenAssistant SFT-4 12B @HuggingFace-Hub\"\n    with app.app_context():\n        existing_ai = db.session.query(Ai).filter_by(name=ai_name).first()\n        db.session.delete(existing_ai)\n        db.session.commit()\n\n        ai_entry = db.session.query(Ai).filter_by(name=ai_name).first()\n        assert ai_entry is None\n\n        result = runner.invoke(add_ai, input=f\"{ai_file}\\n\")\n        assert f\"Added {ai_name}\" in result.output\n\n        ai_entry = db.session.query(Ai).filter_by(name=ai_name).first()\n        assert ai_entry is not None\n\n\ndef test_add_ai_command_updates_ai(app, runner):\n    \"\"\"Test if the add-ai command updates an AI with the same name.\"\"\"\n    ai_file = \"examples/huggingface_hub/OpenAssistant_SFT-4_12B.aifile\"\n    ai_name = \"OpenAssistant SFT-4 12B @HuggingFace-Hub\"\n    with app.app_context():\n        ai_entry = db.session.query(Ai).filter_by(name=ai_name).one()\n        ai_entry.chain = \"old_chain\"\n        db.session.commit()\n\n        result = runner.invoke(add_ai, input=f\"{ai_file}\\n\")\n        assert f\"Updated {ai_name}\" in result.output\n\n        ai_entry = db.session.query(Ai).filter_by(name=ai_name).one()\n        assert ai_entry.chain != \"old_chain\"\n\n\ndef test_download_model_command_calls_hf_hub_download(app, runner, monkeypatch):\n    \"\"\"Test if the download-model command calls the hf_hub_download function.\"\"\"\n\n    class HfHubDownloadRecorder:\n        \"\"\"Helper class to record function call to hf_hub_download().\"\"\"\n\n        kwargs = {}\n\n    def fake_hf_hub_download(**kwargs):\n        HfHubDownloadRecorder.kwargs = kwargs\n\n    monkeypatch.setattr(\"huggingface_hub.hf_hub_download\", fake_hf_hub_download)\n    with app.app_context():\n        runner.invoke(download_model, input=\"testrepo\\ntestfilename\\n\")\n        assert HfHubDownloadRecorder.kwargs[\"repo_id\"] == \"testrepo\"\n        assert HfHubDownloadRecorder.kwargs[\"filename\"] == \"testfilename\"\n        assert HfHubDownloadRecorder.kwargs[\"local_dir\"] == app.instance_path\n        assert HfHubDownloadRecorder.kwargs[\"local_dir_use_symlinks\"] is True\n"}
{"type": "test_file", "path": "tests/test_factory.py", "content": "\"\"\"Test the Flask server app factory.\"\"\"\nimport os\nfrom backaind import create_app\n\n\ndef test_config():\n    \"\"\"Test whether the app factory takes an external test configuration.\"\"\"\n    os.environ[\"OWNAI_SQLALCHEMY_DATABASE_URI\"] = \"sqlite:///testing.db\"\n    assert not create_app().testing\n    assert create_app(\n        {\"SQLALCHEMY_DATABASE_URI\": \"sqlite:///testing.db\", \"TESTING\": True}\n    ).testing\n"}
{"type": "test_file", "path": "tests/api/test_knowledge_api.py", "content": "\"\"\"Test the Knowledge API.\"\"\"\nimport os\nimport json\nimport shutil\n\nfrom langchain.vectorstores.chroma import Chroma\nimport pytest\n\nfrom backaind.extensions import db\nfrom backaind.knowledge import get_knowledge\nfrom backaind.models import Knowledge\n\n\ndef test_auth_required(client):\n    \"\"\"Test whether authorization is required to access the API.\"\"\"\n    assert client.get(\"/api/knowledge/\").status_code == 401\n    assert client.get(\"/api/knowledge/2\").status_code == 401\n    assert client.post(\"/api/knowledge/\", json={}).status_code == 401\n    assert client.post(\"/api/knowledge/1/document/txt\", data={}).status_code == 401\n    assert client.post(\"/api/knowledge/1/document/pdf\", data={}).status_code == 401\n    assert client.post(\"/api/knowledge/1/document/docx\", data={}).status_code == 401\n    assert client.put(\"/api/knowledge/1\", json={}).status_code == 401\n    assert client.delete(\"/api/knowledge/1\").status_code == 401\n    assert client.get(\"/api/knowledge/1/document\").status_code == 401\n    assert client.delete(\"/api/knowledge/1/document/test\").status_code == 401\n\n\ndef test_get_all_knowledge(client, auth):\n    \"\"\"Test if GET /api/knowledge/ returns all knowledge from the database.\"\"\"\n    auth.login()\n    response = client.get(\"/api/knowledge/\")\n    assert 2 == len(json.loads(response.data))\n\n\ndef test_get_knowledge(client, auth):\n    \"\"\"Test if GET /api/knowledge/1 returns the knowledge entry with id 1.\"\"\"\n    auth.login()\n    response = client.get(\"/api/knowledge/1\")\n    assert 1 == json.loads(response.data)[\"id\"]\n\n\ndef test_get_unknown_knowledge_returns_404(client, auth):\n    \"\"\"Test if GET /api/knowledge/999 returns 404.\"\"\"\n    auth.login()\n    response = client.get(\"/api/knowledge/999\")\n    assert response.status_code == 404\n\n\ndef test_create_knowledge(client, auth, app):\n    \"\"\"Test if POST /api/knowledge/ creates a new knowledge entry.\"\"\"\n    auth.login()\n    response = client.post(\n        \"/api/knowledge/\",\n        json={\"name\": \"Test\", \"embeddings\": \"huggingface\", \"chunk_size\": 500},\n    )\n    assert json.loads(response.data)[\"id\"] == 3\n    with app.app_context():\n        entry = db.get_or_404(Knowledge, 3)\n        assert entry and entry.name == \"Test\"\n        shutil.rmtree(entry.persist_directory)\n\n\ndef test_update_knowledge(client, auth, app):\n    \"\"\"Test if PUT /api/knowledge/1 updates the entry.\"\"\"\n    auth.login()\n    response = client.put(\n        \"/api/knowledge/1\",\n        json={\"name\": \"Test\", \"embeddings\": \"huggingface\", \"chunk_size\": 500},\n    )\n    assert json.loads(response.data)[\"name\"] == \"Test\"\n    with app.app_context():\n        entry = db.get_or_404(Knowledge, 1)\n        assert entry and entry.name == \"Test\"\n\n\ndef test_update_knowledge_does_not_update_embeddings(client, auth, app):\n    \"\"\"Test if the embeddings type cannot be updated afterwards.\"\"\"\n    with app.app_context():\n        knowledge = db.session.get(Knowledge, 1)\n        assert knowledge\n        knowledge.embeddings = \"changed\"\n        db.session.commit()\n\n        auth.login()\n        response = client.put(\n            \"/api/knowledge/1\",\n            json={\"name\": \"Test\", \"embeddings\": \"huggingface\", \"chunk_size\": 500},\n        )\n        assert response.status_code == 400\n        assert (\n            json.loads(response.data)[\"error\"]\n            == \"Cannot change the embeddings type afterwards.\"\n        )\n\n\ndef test_delete_knowledge(client, auth, app):\n    \"\"\"Test if DELETE /api/knowledge/1 deletes the entry.\"\"\"\n    os.makedirs(\"instance/test-knowledge-2\")\n    auth.login()\n    response = client.delete(\"/api/knowledge/2\")\n    assert response.status_code == 204\n    with app.app_context():\n        entry = db.session.get(Knowledge, 2)\n        assert entry is None\n\n\ndef test_get_documents(client, auth):\n    \"\"\"Test if GET /api/knowledge/1/document returns all documents from the knowledge.\"\"\"\n    with client, open(\"tests/test_documents/test.txt\", \"rb\") as file:\n        auth.login()\n        client.post(\n            \"/api/knowledge/1/document/txt\",\n            data={\"file\": (file, \"test.txt\")},\n            buffered=True,\n            content_type=\"multipart/form-data\",\n        )\n        response = client.get(\"/api/knowledge/1/document\")\n        assert 1 == len(json.loads(response.data)[\"items\"])\n\n        knowledge = get_knowledge(1)\n        assert isinstance(knowledge, Chroma)\n        # pylint: disable-next=protected-access\n        knowledge._collection.delete(where_document={\"$contains\": \"test\"})\n\n\ndef test_delete_document(client, auth):\n    \"\"\"Test if DELETE /api/knowledge/1/document/<id> deletes the document.\"\"\"\n    with client, open(\"tests/test_documents/test.txt\", \"rb\") as file:\n        auth.login()\n        client.post(\n            \"/api/knowledge/1/document/txt\",\n            data={\"file\": (file, \"test.txt\")},\n            buffered=True,\n            content_type=\"multipart/form-data\",\n        )\n        response = client.get(\"/api/knowledge/1/document\")\n        document_id = json.loads(response.data)[\"items\"][0][\"id\"]\n        response = client.delete(\"/api/knowledge/1/document/\" + document_id)\n        assert response.status_code == 204\n        response = client.get(\"/api/knowledge/1/document\")\n        assert 0 == len(json.loads(response.data)[\"items\"])\n\n        knowledge = get_knowledge(1)\n        assert isinstance(knowledge, Chroma)\n        # pylint: disable-next=protected-access\n        knowledge._collection.delete(where_document={\"$contains\": \"test\"})\n\n\ndef test_upload_txt(client, auth):\n    \"\"\"Test uploading a txt document into knowledge.\"\"\"\n    with client, open(\"tests/test_documents/test.txt\", \"rb\") as file:\n        auth.login()\n        client.post(\n            \"/api/knowledge/1/document/txt\",\n            data={\"file\": (file, \"test.txt\")},\n            buffered=True,\n            content_type=\"multipart/form-data\",\n        )\n        knowledge = get_knowledge(1)\n        results = knowledge.similarity_search(\"txt\")\n        assert results.pop().page_content == \"This is a txt test file.\"\n\n        assert isinstance(knowledge, Chroma)\n        # pylint: disable-next=protected-access\n        knowledge._collection.delete(where_document={\"$contains\": \"test\"})\n\n\ndef test_upload_pdf(client, auth):\n    \"\"\"Test uploading a pdf document into knowledge.\"\"\"\n    with client, open(\"tests/test_documents/test.pdf\", \"rb\") as file:\n        auth.login()\n        client.post(\n            \"/api/knowledge/1/document/pdf\",\n            data={\"file\": (file, \"test.pdf\")},\n            buffered=True,\n            content_type=\"multipart/form-data\",\n        )\n        knowledge = get_knowledge(1)\n        results = knowledge.similarity_search(\"pdf\")\n        assert results.pop().page_content == \"This is a pdf test file.\"\n\n        assert isinstance(knowledge, Chroma)\n        # pylint: disable-next=protected-access\n        knowledge._collection.delete(where_document={\"$contains\": \"test\"})\n\n\ndef test_upload_docx(client, auth):\n    \"\"\"Test uploading a docx document into knowledge.\"\"\"\n    with client, open(\"tests/test_documents/test.docx\", \"rb\") as file:\n        auth.login()\n        client.post(\n            \"/api/knowledge/1/document/docx\",\n            data={\"file\": (file, \"test.docx\")},\n            buffered=True,\n            content_type=\"multipart/form-data\",\n        )\n        knowledge = get_knowledge(1)\n        results = knowledge.similarity_search(\"docx\")\n        assert results.pop().page_content == \"This is a docx test file.\"\n\n        assert isinstance(knowledge, Chroma)\n        # pylint: disable-next=protected-access\n        knowledge._collection.delete(where_document={\"$contains\": \"test\"})\n\n\ndef test_upload_no_file_fails(client, auth):\n    \"\"\"Test if uploading no file fails.\"\"\"\n    with client:\n        auth.login()\n        response = client.post(\n            \"/api/knowledge/1/document/pdf\",\n            data={},\n            buffered=True,\n            content_type=\"multipart/form-data\",\n        )\n        assert response.status_code == 400\n        assert json.loads(response.data)[\"error\"] == \"No file has been uploaded.\"\n\n\n@pytest.mark.parametrize(\n    \"data,message\",\n    (\n        (\n            {},\n            \"The knowledge data cannot be empty.\",\n        ),\n        (\n            {\"embeddings\": \"huggingface\", \"chunk_size\": 500},\n            'The property \"name\" is required.',\n        ),\n        (\n            {\"name\": 1, \"embeddings\": \"huggingface\", \"chunk_size\": 500},\n            'The property \"name\" has to be a string.',\n        ),\n        (\n            {\"name\": \"Test\", \"chunk_size\": 500},\n            'The property \"embeddings\" is required.',\n        ),\n        (\n            {\"name\": \"Test\", \"embeddings\": \"doesnotexist\", \"chunk_size\": 500},\n            \"Unknown embeddings type.\",\n        ),\n        (\n            {\"name\": \"Test\", \"embeddings\": \"huggingface\"},\n            'The property \"chunk_size\" is required.',\n        ),\n        (\n            {\"name\": \"Test\", \"embeddings\": \"huggingface\", \"chunk_size\": \"Test\"},\n            'The property \"chunk_size\" has to be a number.',\n        ),\n    ),\n)\ndef test_validation(client, auth, data, message):\n    \"\"\"Test if the knowledge JSON validation works.\"\"\"\n    auth.login()\n    response = client.put(\"/api/knowledge/1\", json=data)\n    assert response.status_code == 400\n    assert json.loads(response.data)[\"error\"] == message\n"}
{"type": "test_file", "path": "tests/test_workshop.py", "content": "\"\"\"Test the Workshop module to work on AIs and knowledge.\"\"\"\nimport pytest\n\nEXAMPLE_PATHS = (\n    \"/workshop/\",\n    \"/workshop/ai/\",\n    \"/workshop/ai/new\",\n    \"/workshop/ai/2\",\n    \"/workshop/knowledge/\",\n    \"/workshop/knowledge/new\",\n    \"/workshop/knowledge/2\",\n)\n\n\n@pytest.mark.parametrize(\"path\", EXAMPLE_PATHS)\ndef test_login_required(client, path):\n    \"\"\"Test whether login is required to view all workshop paths.\"\"\"\n    response = client.get(path)\n    assert response.headers[\"Location\"] == \"/auth/login\"\n\n\n@pytest.mark.parametrize(\"path\", EXAMPLE_PATHS)\ndef test_index(client, auth, path):\n    \"\"\"Test whether the workshop page gets displayed.\"\"\"\n    auth.login()\n    response = client.get(path)\n    assert b'id=\"workshop\"' in response.data\n"}
{"type": "test_file", "path": "tests/test_ainteraction.py", "content": "\"\"\"Test the Ainteraction module to interact with AI applications.\"\"\"\nimport pytest\n\nfrom backaind.ainteraction import (\n    handle_incoming_message,\n    get_ai_data,\n    get_knowledge_data,\n    is_ai_public,\n    is_knowledge_public,\n    send_progress,\n    send_next_token,\n    send_response,\n)\n\n\ndef test_no_public_ai_redirects_to_login(client, monkeypatch):\n    \"\"\"Test whether the ainteraction page redirects to the login page if no public AI exists.\"\"\"\n    monkeypatch.setattr(\n        \"backaind.ainteraction.get_ai_data\",\n        lambda only_public: [] if only_public else [\"error\"],\n    )\n    response = client.get(\"/\")\n    assert response.headers[\"Location\"] == \"/auth/login\"\n\n\ndef test_public_ai_shows_ainteraction_page(client, monkeypatch):\n    \"\"\"Test whether the ainteraction page loads if a public AI exists.\"\"\"\n    test_ai_data = [\n        {\n            \"id\": 123,\n            \"name\": \"Test AI\",\n            \"input_keys\": [\"input_text\"],\n            \"input_labels\": {\"input_text\": \"Input Text\"},\n            \"greeting\": \"Hello!\",\n        }\n    ]\n    monkeypatch.setattr(\n        \"backaind.ainteraction.get_ai_data\",\n        lambda only_public: [test_ai_data] if only_public else [\"error\"],\n    )\n    response = client.get(\"/\")\n    assert b\"Hello\" in response.data\n    assert b'id=\"ainteraction\"' in response.data\n\n\n@pytest.mark.parametrize(\"path\", (\"/\",))\ndef test_index(client, auth, path):\n    \"\"\"Test whether the ainteraction page loads if the user is logged in.\"\"\"\n    auth.login()\n    response = client.get(path)\n    assert b\"Hello\" in response.data\n    assert b'id=\"ainteraction\"' in response.data\n\n\ntest_incoming_message = {\n    \"responseId\": 1,\n    \"message\": {\n        \"id\": 2,\n        \"author\": {\n            \"species\": \"human\",\n        },\n        \"date\": \"2023-04-15T23:53:04.745556\",\n        \"text\": \"Fine and you?\",\n    },\n    \"history\": [\n        {\n            \"id\": 0,\n            \"author\": {\n                \"species\": \"human\",\n            },\n            \"date\": \"2023-04-15T23:53:04.745556\",\n            \"text\": \"Hi!\",\n        },\n        {\n            \"id\": 1,\n            \"author\": {\n                \"species\": \"ai\",\n            },\n            \"date\": \"2023-04-15T23:53:04.745556\",\n            \"text\": \"Hi, how are you?\",\n        },\n    ],\n}\n\n\ndef test_handle_incoming_message_without_login_disconnects(client, monkeypatch):\n    \"\"\"\n    Test whether the server disconnects on incoming socket.io messages without valid user\n    context if the AI or knowledge is not public.\n    \"\"\"\n\n    class DisconnectRecorder:\n        \"\"\"Helper class to record function call to disconnect().\"\"\"\n\n        called = 0\n\n    class EmitRecorder:\n        \"\"\"Helper class to record function call to emit().\"\"\"\n\n        called = 0\n\n    def fake_disconnect():\n        DisconnectRecorder.called += 1\n\n    def fake_emit(_event, _arg):\n        EmitRecorder.called += 1\n\n    monkeypatch.setattr(\"backaind.ainteraction.disconnect\", fake_disconnect)\n    monkeypatch.setattr(\"backaind.ainteraction.emit\", fake_emit)\n\n    with client:\n        client.get(\"/\")\n\n        # aiId is missing\n        handle_incoming_message(test_incoming_message)\n\n        # non-public AI\n        test_incoming_message[\"aiId\"] = 2\n        handle_incoming_message(test_incoming_message)\n\n        # public AI, but non-public knowledge\n        test_incoming_message[\"aiId\"] = 1\n        test_incoming_message[\"knowledgeId\"] = 2\n        handle_incoming_message(test_incoming_message)\n        del test_incoming_message[\"knowledgeId\"]\n\n    assert DisconnectRecorder.called == 3\n    assert EmitRecorder.called == 0\n\n\ndef test_handle_incoming_message(client, auth, monkeypatch):\n    \"\"\"Test whether the server emits a response for incoming socket.io messages.\"\"\"\n\n    class DisconnectRecorder:\n        \"\"\"Helper class to record function call to disconnect().\"\"\"\n\n        called = 0\n\n    class EmitRecorder:\n        \"\"\"Helper class to record function call to emit().\"\"\"\n\n        called_for_token = 0\n        called_for_message = 0\n\n    def fake_disconnect():\n        DisconnectRecorder.called += 1\n\n    def fake_emit(event, _arg):\n        if event == \"token\":\n            EmitRecorder.called_for_token += 1\n        elif event == \"message\":\n            EmitRecorder.called_for_message += 1\n\n    def fake_reply(\n        _ai_id,\n        _input_text,\n        _knowledge_id,\n        _memory,\n        on_token,\n        _on_progress,\n        _updated_environment,\n    ):\n        on_token(\"token\")\n        return \"Fake response\"\n\n    monkeypatch.setattr(\"backaind.ainteraction.disconnect\", fake_disconnect)\n    monkeypatch.setattr(\"backaind.ainteraction.emit\", fake_emit)\n    monkeypatch.setattr(\"backaind.ainteraction.reply\", fake_reply)\n\n    with client:\n        client.get(\"/\")\n\n        # public AI\n        test_incoming_message[\"aiId\"] = 1\n        handle_incoming_message(test_incoming_message)\n\n        # non-public AI after login\n        auth.login()\n        test_incoming_message[\"aiId\"] = 2\n        handle_incoming_message(test_incoming_message)\n\n    assert DisconnectRecorder.called == 0\n    assert EmitRecorder.called_for_token == 2\n    assert EmitRecorder.called_for_message == 2\n\n\ndef test_handle_incoming_message_sends_error_message(client, auth, monkeypatch):\n    \"\"\"Test whether exceptions during generation are returned as error message.\"\"\"\n\n    class EmitRecorder:\n        \"\"\"Helper class to record function call to emit().\"\"\"\n\n        text = None\n        status = None\n\n    def fake_emit(_event, _arg):\n        EmitRecorder.text = _arg[\"text\"]\n        EmitRecorder.status = _arg[\"status\"]\n\n    def fake_reply(*_args):\n        raise NotImplementedError(\"Test Exception\")\n\n    monkeypatch.setattr(\"backaind.ainteraction.emit\", fake_emit)\n    monkeypatch.setattr(\"backaind.ainteraction.reply\", fake_reply)\n\n    auth.login()\n    with client, pytest.raises(NotImplementedError):\n        client.get(\"/\")\n        test_incoming_message[\"aiId\"] = 1\n        handle_incoming_message(test_incoming_message)\n\n    assert EmitRecorder.text == \"Test Exception\"\n    assert EmitRecorder.status == \"error\"\n\n\ndef test_get_ai_data_returns_all_ais(app):\n    \"\"\"Test whether get_ai_data returns all AIs if only_public is false.\"\"\"\n    with app.app_context():\n        assert len(get_ai_data(False)) == 2\n\n\ndef test_get_ai_data_returns_only_public(app):\n    \"\"\"Test whether get_ai_data returns only public AIs if only_public is true.\"\"\"\n    with app.app_context():\n        assert len(get_ai_data(True)) == 1\n\n\ndef test_get_knowledge_data_returns_all_knowledge(app):\n    \"\"\"Test whether get_knowledge_data returns all knowledge if only_public is false.\"\"\"\n    with app.app_context():\n        assert len(get_knowledge_data(False)) == 2\n\n\ndef test_get_knowledge_data_returns_only_public(app):\n    \"\"\"Test whether get_knowledge_data returns only public knowledge if only_public is true.\"\"\"\n    with app.app_context():\n        assert len(get_knowledge_data(True)) == 1\n\n\ndef test_is_ai_public(app):\n    \"\"\"Test whether is_ai_public returns true only if the AI is public.\"\"\"\n    with app.app_context():\n        assert is_ai_public(1)\n        assert not is_ai_public(2)\n\n\ndef test_is_knowledge_public(app):\n    \"\"\"Test whether is_knowledge_public returns true only if the knowledge is public.\"\"\"\n    with app.app_context():\n        assert is_knowledge_public(1)\n        assert not is_knowledge_public(2)\n\n\ndef test_send_progress_emits_progress(monkeypatch):\n    \"\"\"Test if a call to send_progress emits the 'progress' event.\"\"\"\n\n    class EmitRecorder:\n        \"\"\"Helper class to record function call to emit().\"\"\"\n\n        event = None\n\n    def fake_emit(event, _arg):\n        EmitRecorder.event = event\n\n    monkeypatch.setattr(\"backaind.ainteraction.emit\", fake_emit)\n    send_progress(1, 100)\n\n    assert EmitRecorder.event == \"progress\"\n\n\ndef test_send_next_token_emits_token(monkeypatch):\n    \"\"\"Test if a call to send_next_token emits the 'token' event.\"\"\"\n\n    class EmitRecorder:\n        \"\"\"Helper class to record function call to emit().\"\"\"\n\n        event = None\n\n    def fake_emit(event, _arg):\n        EmitRecorder.event = event\n\n    monkeypatch.setattr(\"backaind.ainteraction.emit\", fake_emit)\n    send_next_token(1, \"token_text\")\n\n    assert EmitRecorder.event == \"token\"\n\n\ndef test_send_response_emits_message(monkeypatch):\n    \"\"\"Test if a call to send_response emits the 'message' event.\"\"\"\n\n    class EmitRecorder:\n        \"\"\"Helper class to record function call to emit().\"\"\"\n\n        event = None\n\n    def fake_emit(event, _arg):\n        EmitRecorder.event = event\n\n    monkeypatch.setattr(\"backaind.ainteraction.emit\", fake_emit)\n    send_response(1, \"message_text\")\n\n    assert EmitRecorder.event == \"message\"\n"}
{"type": "test_file", "path": "tests/test_knowledge.py", "content": "\"\"\"Test access to the vector store.\"\"\"\nimport pytest\n\nfrom langchain.docstore.document import Document\nfrom langchain.embeddings.base import Embeddings\nfrom langchain.vectorstores.base import VectorStore\nfrom langchain.vectorstores.chroma import Chroma\n\nfrom backaind.extensions import db\nfrom backaind.knowledge import (\n    add_knowledge,\n    add_to_knowledge,\n    get_embeddings,\n    get_knowledge,\n    KnowledgeConfigError,\n)\nimport backaind.knowledge\nfrom backaind.models import Knowledge\n\n\ndef test_get_embeddings_raises_on_unknown_embeddings(client):\n    \"\"\"Test if an exception is raised when requesting an unknown embedding function.\"\"\"\n    with client:\n        client.get(\"/\")\n        with pytest.raises(KnowledgeConfigError) as error:\n            get_embeddings(\"unknown\")\n\n        assert str(error.value) == \"Unknown embeddings type: unknown\"\n\n\ndef test_get_embeddings_returns_embeddings(client):\n    \"\"\"Test if get_embeddings() returns an Embeddings instance.\"\"\"\n    with client:\n        client.get(\"/\")\n        embeddings = get_embeddings(\"huggingface\")\n        assert isinstance(embeddings, Embeddings)\n\n\ndef test_get_knowledge_returns_vector_store(client):\n    \"\"\"Test if get_knowledge() returns a VectorStore instance.\"\"\"\n    with client:\n        client.get(\"/\")\n        knowledge = get_knowledge(1)\n        assert isinstance(knowledge, VectorStore)\n\n\ndef test_get_knowledge_loads_from_global_knowledge():\n    \"\"\"Test if get_knowledge() loads from the global knowledge instance.\"\"\"\n    backaind.knowledge.global_knowledge = \"NotRealKnowledge\"\n    backaind.knowledge.global_knowledge_id = 999\n    knowledge = get_knowledge(999)\n    assert knowledge == \"NotRealKnowledge\"\n\n\ndef test_add_to_knowledge_adds_documents(client):\n    \"\"\"Test if adding documents to knowledge works.\"\"\"\n    with client:\n        client.get(\"/\")\n        add_to_knowledge(\n            1, [Document(page_content=\"Test Document\", metadata={\"source\": \"Test\"})]\n        )\n        knowledge = get_knowledge(1)\n        result = knowledge.similarity_search(\"Test Document\").pop()\n        assert result.page_content == \"Test Document\"\n\n        assert isinstance(knowledge, Chroma)\n        # pylint: disable-next=protected-access\n        knowledge._collection.delete(where_document={\"$contains\": \"Test\"})\n\n\ndef test_add_knowledge_command_adds_knowledge(app, runner):\n    \"\"\"Test if the add-knowledge command adds a new knowledge entry to the database.\"\"\"\n    knowledge_name = \"Test\"\n    knowledge_embeddings = \"huggingface\"\n    knowledge_chunk_size = \"500\"\n    knowledge_persist_directory = \"instance/knowledge-test\"\n    with app.app_context():\n        knowledge_entry = (\n            db.session.query(Knowledge).filter_by(name=knowledge_name).first()\n        )\n        assert knowledge_entry is None\n\n        result = runner.invoke(\n            add_knowledge,\n            input=f\"{knowledge_name}\\n{knowledge_embeddings}\\n{knowledge_chunk_size}\\n\"\n            + f\"{knowledge_persist_directory}\",\n        )\n        assert f\"Added {knowledge_name}\" in result.output\n\n        knowledge_entry = (\n            db.session.query(Knowledge).filter_by(name=knowledge_name).first()\n        )\n        assert knowledge_entry is not None\n\n\ndef test_add_knowledge_command_updates_knowledge(app, runner):\n    \"\"\"Test if the add-knowledge command updates knowledge with the same name.\"\"\"\n    knowledge_name = \"Test 1\"\n    knowledge_embeddings = \"huggingface\"\n    knowledge_chunk_size = \"500\"\n    knowledge_persist_directory = \"instance/knowledge\"\n    with app.app_context():\n        knowledge_entry = (\n            db.session.query(Knowledge).filter_by(name=knowledge_name).one()\n        )\n        knowledge_entry.persist_directory = \"old_directory\"\n        db.session.commit()\n\n        result = runner.invoke(\n            add_knowledge,\n            input=f\"{knowledge_name}\\n{knowledge_embeddings}\\n{knowledge_chunk_size}\\n\"\n            + f\"{knowledge_persist_directory}\",\n        )\n        assert f\"Updated {knowledge_name}\" in result.output\n\n        knowledge_entry = (\n            db.session.query(Knowledge).filter_by(name=knowledge_name).one()\n        )\n        assert knowledge_entry.persist_directory == knowledge_persist_directory\n"}
{"type": "test_file", "path": "tests/test_brain.py", "content": "\"\"\"Test the handling of AI chains.\"\"\"\nimport os\nimport queue\n\nfrom langchain.chains.loading import load_chain_from_config\nfrom langchain.llms.huggingface_text_gen_inference import HuggingFaceTextGenInference\nfrom langchain.memory import ConversationBufferWindowMemory\nimport pytest\n\nfrom backaind.aifile import read_aifile_from_path\nfrom backaind.brain import (\n    find_instances,\n    get_chain,\n    reply,\n    reset_global_chain,\n    run_chain_on_gunicorn,\n    run_chain_on_multiprocessing,\n    run_chain_process,\n    set_text_generation_inference_token,\n    estimate_processing_time,\n    UpdatedEnvironment,\n)\nimport backaind.brain\nfrom backaind.models import Ai\n\n\nclass FakeChain:\n    \"\"\"Helper class to mock a chain.\"\"\"\n\n    def __call__(self, inputs, **kwargs):\n        \"\"\"Mock function for calling the chain.\"\"\"\n        if kwargs.get(\"callbacks\"):\n            for callback_handler in kwargs[\"callbacks\"]:\n                callback_handler.on_chat_model_start(None, None)\n                callback_handler.on_llm_start({}, [\"testprompt\"])\n                callback_handler.on_llm_new_token(\"testtoken\")\n        output = f\"{inputs['input_text']},{inputs['input_knowledge']},{inputs['input_history']}\"\n        return {\"output_text\": output}\n\n\ndef test_get_chain_loads_from_global_chain():\n    \"\"\"Test if the chain is loaded from the global chain instance.\"\"\"\n    backaind.brain.global_chain = \"NotARealChain\"\n    backaind.brain.global_chain_id = 1\n    backaind.brain.global_chain_input_keys = set(\"text_input\")\n    (chain, chain_input_keys) = get_chain(1)\n    assert chain == \"NotARealChain\"\n    assert chain_input_keys == set(\"text_input\")\n    reset_global_chain()\n\n\ndef test_get_chain_creates_new_chain(monkeypatch):\n    \"\"\"Test if the chain gets created if it doesn't exist yet.\"\"\"\n    reset_global_chain()\n    monkeypatch.setattr(\n        \"backaind.extensions.db.get_or_404\",\n        lambda _model, _model_id: Ai(\n            input_keys=[\"input_text\"],\n            chain={\"name\": \"NotARealChain\"},\n        ),\n    )\n    monkeypatch.setattr(\"backaind.brain.load_chain_from_config\", lambda chain: chain)\n    (chain, _chain_input_keys) = get_chain(1)\n    assert chain == {\"name\": \"NotARealChain\"}\n    assert backaind.brain.global_chain == {\"name\": \"NotARealChain\"}\n    reset_global_chain()\n\n\ndef test_reply_runs_the_chain(monkeypatch):\n    \"\"\"Test if the reply function runs the chain.\"\"\"\n\n    def fake_get_chain(_ai_id, _updated_environment):\n        return (FakeChain(), set((\"input_text\", \"input_knowledge\", \"input_history\")))\n\n    def fake_run(chain, inputs, _on_token, _on_progress):\n        return chain(inputs)[\"output_text\"]\n\n    monkeypatch.setattr(\"backaind.brain.get_chain\", fake_get_chain)\n    monkeypatch.setattr(\"backaind.brain.run_chain_on_multiprocessing\", fake_run)\n    response = reply(1, \"Hi\", None)\n\n    assert response == \"Hi,[],\"\n\n\ndef test_reply_sets_inputs(monkeypatch):\n    \"\"\"Test if the reply function correctly sets the inputs for the chain.\"\"\"\n\n    def fake_get_chain(_ai_id, _updated_environment):\n        return (\n            FakeChain(),\n            {\"input_text\", \"input_knowledge\", \"input_history\", \"input_unknown\"},\n        )\n\n    class FakeKnowledge:\n        \"\"\"Helper class for a fake knowledge interface.\"\"\"\n\n        def similarity_search(self, input_text, **_kwargs):\n            \"\"\"Mock function to check if the similarity_search is called.\"\"\"\n            return [input_text]\n\n    def fake_get_knowledge(_knowledge_id):\n        return FakeKnowledge()\n\n    def fake_run(chain, inputs, _on_token, _on_progress):\n        return chain(inputs)[\"output_text\"]\n\n    monkeypatch.setattr(\"backaind.brain.get_chain\", fake_get_chain)\n    monkeypatch.setattr(\"backaind.brain.get_knowledge\", fake_get_knowledge)\n    monkeypatch.setattr(\"backaind.brain.run_chain_on_multiprocessing\", fake_run)\n\n    response = reply(1, \"Hi\", 1)\n    assert response == \"Hi,['Hi'],\"\n\n    response = reply(1, \"Hi\", None)\n    assert response == \"Hi,[],\"\n\n    memory = ConversationBufferWindowMemory(k=3)\n    memory.chat_memory.add_ai_message(\"Hi user\")\n    memory.chat_memory.add_user_message(\"Hi AI\")\n    response = reply(1, \"Hi\", 1, memory)\n    assert response == \"Hi,['Hi'],AI: Hi user\\nHuman: Hi AI\"\n\n\ndef test_reply_chooses_the_right_way_of_processing(monkeypatch):\n    \"\"\"Test if the reply function chooses between gipc and multiprocessing.\"\"\"\n\n    class RunRecorder:\n        \"\"\"Helper class to record the call to run.\"\"\"\n\n        run_on_gunicorn = False\n        run_on_multiprocessing = False\n\n    def fake_get_chain(_ai_id, _updated_environment):\n        return (FakeChain(), set((\"input_text\", \"input_knowledge\", \"input_history\")))\n\n    def fake_run_chain_on_multiprocessing(chain, inputs, _on_token, _on_progress):\n        RunRecorder.run_on_multiprocessing = True\n        return chain(inputs)[\"output_text\"]\n\n    def fake_run_chain_on_gunicorn(chain, inputs, _on_token, _on_progress):\n        RunRecorder.run_on_gunicorn = True\n        return chain(inputs)[\"output_text\"]\n\n    monkeypatch.setattr(\"backaind.brain.get_chain\", fake_get_chain)\n    monkeypatch.setattr(\n        \"backaind.brain.run_chain_on_multiprocessing\", fake_run_chain_on_multiprocessing\n    )\n    monkeypatch.setattr(\n        \"backaind.brain.run_chain_on_gunicorn\", fake_run_chain_on_gunicorn\n    )\n\n    response = reply(1, \"Hi\", None)\n    assert response == \"Hi,[],\"\n    assert RunRecorder.run_on_multiprocessing\n    assert not RunRecorder.run_on_gunicorn\n\n    RunRecorder.run_on_multiprocessing = False\n    RunRecorder.run_on_gunicorn = False\n\n    with UpdatedEnvironment({\"SERVER_SOFTWARE\": \"gunicorn\"}):\n        response = reply(1, \"Hi\", None)\n        assert response == \"Hi,[],\"\n        assert not RunRecorder.run_on_multiprocessing\n        assert RunRecorder.run_on_gunicorn\n\n\ndef test_run_chain_on_gunicorn(monkeypatch):\n    \"\"\"Test if the runner function for gipc works.\"\"\"\n\n    def fake_start_process(**kwargs):\n        kwargs[\"args\"][2].put(None)\n        kwargs[\"args\"][2].put((\"prompts\", [\"testprompt\"]))\n        kwargs[\"args\"][2].put(None)\n        kwargs[\"args\"][2].put(None)\n        kwargs[\"args\"][2].put((\"token\", \"testtoken1\"))\n        kwargs[\"args\"][2].put((\"token\", \"testtoken2\"))\n        kwargs[\"args\"][2].put((\"test\", \"test\"))\n        kwargs[\"args\"][2].put((\"done\", \"testtext\"))\n\n    class FakeTimeout:\n        \"\"\"Helper class to mock a timeout.\"\"\"\n\n        def __init__(self, seconds, exception) -> None:\n            pass\n\n        def __enter__(self):\n            return None\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            pass\n\n    class OnTokenRecorder:\n        \"\"\"Helper class to record the call to on_token.\"\"\"\n\n        token = None\n\n    def fake_on_token(token):\n        OnTokenRecorder.token = token\n\n    def fake_on_progress(_progress):\n        pass\n\n    monkeypatch.setattr(\"gipc.start_process\", fake_start_process)\n    monkeypatch.setattr(\"gevent.Timeout\", FakeTimeout)\n\n    text = run_chain_on_gunicorn(\n        FakeChain(),\n        {\"input_text\": \"Hi\", \"input_knowledge\": \"\", \"input_history\": \"\"},\n        None,\n        None,\n    )\n    assert OnTokenRecorder.token is None\n    assert text == \"testtext\"\n\n    text = run_chain_on_gunicorn(\n        FakeChain(),\n        {\"input_text\": \"Hi\", \"input_knowledge\": \"\", \"input_history\": \"\"},\n        fake_on_token,\n        fake_on_progress,\n    )\n    assert OnTokenRecorder.token == \"testtoken2\"\n    assert text == \"testtext\"\n\n\ndef test_run_chain_on_multiprocessing(monkeypatch):\n    \"\"\"Test if the runner function for multiprocessing works.\"\"\"\n\n    def fake_process(**_kwargs):\n        class FakeProcess:\n            \"\"\"Helper class to mock a multiprocessing process.\"\"\"\n\n            def start(self):\n                \"\"\"Does nothing, but is called by the runner.\"\"\"\n\n        return FakeProcess()\n\n    def fake_queue():\n        class FakeQueue:\n            \"\"\"Helper class to mock a multiprocessing queue.\"\"\"\n\n            returns = [\n                None,\n                (\"prompts\", [\"testprompt\"]),\n                None,\n                None,\n                (\"token\", \"testtoken1\"),\n                (\"token\", \"testtoken2\"),\n                (\"other\", \"test\"),\n                (\"done\", \"testtext\"),\n            ]\n            index = 0\n\n            def get(self, _block, _timeout):\n                \"\"\"Return the next test item.\"\"\"\n                current = self.returns[self.index]\n                self.index += 1\n                if current is None:\n                    raise queue.Empty()\n                return current\n\n        return FakeQueue()\n\n    class OnTokenRecorder:\n        \"\"\"Helper class to record the call to on_token.\"\"\"\n\n        token = None\n\n    def fake_on_token(token):\n        OnTokenRecorder.token = token\n\n    def fake_on_progress(_progress):\n        pass\n\n    monkeypatch.setattr(\"backaind.brain.global_chain_ppwps\", 1)\n    monkeypatch.setattr(\"multiprocessing.Process\", fake_process)\n    monkeypatch.setattr(\"multiprocessing.Queue\", fake_queue)\n\n    text = run_chain_on_multiprocessing(\n        FakeChain(),\n        {\"input_text\": \"Hi\", \"input_knowledge\": \"\", \"input_history\": \"\"},\n        None,\n        None,\n    )\n    assert OnTokenRecorder.token is None\n    assert text == \"testtext\"\n\n    text = run_chain_on_multiprocessing(\n        FakeChain(),\n        {\"input_text\": \"Hi\", \"input_knowledge\": \"\", \"input_history\": \"\"},\n        fake_on_token,\n        fake_on_progress,\n    )\n    assert OnTokenRecorder.token == \"testtoken2\"\n    assert text == \"testtext\"\n\n\ndef test_run_chain_process():\n    \"\"\"Test if run_chain_process puts the results in the queue.\"\"\"\n    result_queue = queue.Queue()\n    run_chain_process(\n        FakeChain(),\n        {\"input_text\": \"Hi\", \"input_knowledge\": \"\", \"input_history\": \"\"},\n        result_queue,\n    )\n    result_type, result = result_queue.get()\n    assert result_type == \"prompts\"\n    assert result == [\"testprompt\"]\n    result_type, result = result_queue.get()\n    assert result_type == \"token\"\n    assert result == \"testtoken\"\n    result_type, result = result_queue.get()\n    assert result_type == \"done\"\n    assert result == \"Hi,,\"\n\n\ndef test_set_text_generation_inference_token():\n    \"\"\"Test if the text generation inference token is set correctly.\"\"\"\n    aifile = read_aifile_from_path(\n        \"examples/huggingface_textgen_inference/huggingface_textgen_inference.aifile\"\n    )\n    chain = load_chain_from_config(aifile[\"chain\"])\n    os.environ[\"TEXT_GENERATION_INFERENCE_TOKEN\"] = \"test_token\"\n    set_text_generation_inference_token(chain)\n    all_huggingface_instances = find_instances(chain, HuggingFaceTextGenInference)\n    assert len(all_huggingface_instances) == 1\n    assert all_huggingface_instances[0].client.headers == {\n        \"Authorization\": \"Bearer test_token\"\n    }\n\n\ndef test_estimate_processing_time(monkeypatch):\n    \"\"\"Test if the processing time is estimated correctly.\"\"\"\n    monkeypatch.setattr(\"backaind.brain.global_chain_ppwps\", 2)\n    assert estimate_processing_time(\"Hi\") == 1\n    assert estimate_processing_time(\"Hi Hi\") == 1\n    assert estimate_processing_time(\"Hi Hi Hi\") == 1\n    assert estimate_processing_time(\"Hi Hi Hi Hi\") == 2\n\n\ndef test_updated_environment_resets_values():\n    \"\"\"Test if the environment is reset after the context manager.\"\"\"\n    os.environ[\"EXISTING_VAR\"] = \"old_value\"\n    if \"NEW_VAR\" in os.environ:\n        del os.environ[\"NEW_VAR\"]\n\n    with UpdatedEnvironment({\"NEW_VAR\": \"new_value\", \"EXISTING_VAR\": \"new_value\"}):\n        assert os.getenv(\"NEW_VAR\") == \"new_value\"\n        assert os.getenv(\"EXISTING_VAR\") == \"new_value\"\n\n    assert os.getenv(\"NEW_VAR\") is None\n    assert os.getenv(\"EXISTING_VAR\") == \"old_value\"\n\n\ndef test_updated_environment_handles_exceptions():\n    \"\"\"Test if the environment is reset even if an exception is raised.\"\"\"\n    os.environ[\"EXISTING_VAR\"] = \"old_value\"\n    if \"NEW_VAR\" in os.environ:\n        del os.environ[\"NEW_VAR\"]\n\n    with pytest.raises(RuntimeError):\n        with UpdatedEnvironment({\"NEW_VAR\": \"new_value\", \"EXISTING_VAR\": \"new_value\"}):\n            assert os.getenv(\"NEW_VAR\") == \"new_value\"\n            assert os.getenv(\"EXISTING_VAR\") == \"new_value\"\n            raise RuntimeError(\"Test\")\n\n    assert os.getenv(\"NEW_VAR\") is None\n    assert os.getenv(\"EXISTING_VAR\") == \"old_value\"\n"}
{"type": "test_file", "path": "tests/conftest.py", "content": "\"\"\"Define test configuration and fixtures.\"\"\"\nimport json\n\nimport pytest\n\nfrom backaind import create_app\nfrom backaind.extensions import db\nfrom backaind.models import User, Ai, Knowledge\n\n\n@pytest.fixture(name=\"app\")\ndef fixture_app():\n    \"\"\"Factory function for the Flask server app fixture.\"\"\"\n    app = create_app(\n        {\n            \"TESTING\": True,\n            \"SQLALCHEMY_DATABASE_URI\": \"sqlite:///testing.db\",\n            \"SECRET_KEY\": \"Only4Testing\",\n        }\n    )\n\n    with app.app_context():\n        db.drop_all()\n        db.create_all()\n        insert_test_data()\n\n    yield app\n\n\n@pytest.fixture(name=\"client\")\ndef fixture_client(app):\n    \"\"\"Factory function for the test client fixture.\"\"\"\n    return app.test_client()\n\n\n@pytest.fixture(name=\"runner\")\ndef fixture_runner(app):\n    \"\"\"Factory function for the click CLI runner.\"\"\"\n    return app.test_cli_runner()\n\n\nclass AuthActions:\n    \"\"\"Helper class for authentication actions in tests.\"\"\"\n\n    def __init__(self, client):\n        self._client = client\n\n    def login(self, username=\"test\", password=\"test\"):\n        \"\"\"Perform a login.\"\"\"\n        return self._client.post(\n            \"/auth/login\", data={\"username\": username, \"password\": password}\n        )\n\n    def logout(self):\n        \"\"\"Perform a logout.\"\"\"\n        return self._client.get(\"/auth/logout\")\n\n\n@pytest.fixture\ndef auth(client):\n    \"\"\"Factory function for authentication actions.\"\"\"\n    return AuthActions(client)\n\n\ndef insert_test_data():\n    \"\"\"Insert test data into the database.\"\"\"\n    db.session.add(\n        User(\n            username=\"test\",\n            passhash=\"pbkdf2:sha256:\"\n            + \"50000$TCI4GzcX$0de171a4f4dac32e3364c7ddc7c14f3e2fa61f2d17574483f7ffbb431b4acb2f\",\n        )\n    )\n    db.session.add(\n        User(\n            username=\"other\",\n            passhash=\"pbkdf2:sha256:\"\n            + \"50000$kJPKsz6N$d2d4784f1b030a9761f5ccaeeaca413f27f2ecb76d6168407af962ddce849f79\",\n        )\n    )\n\n    db.session.add(\n        Ai(\n            name=\"OpenAssistant SFT-4 12B @HuggingFace-Hub\",\n            input_keys=[\"input_text\"],\n            chain=json.loads(\n                \"\"\"{\n                    \"memory\": null,\n                    \"verbose\": false,\n                    \"prompt\": {\n                        \"input_variables\": [\"input_text\"],\n                        \"output_parser\": null,\n                        \"partial_variables\": {},\n                        \"template\": \"<|prompter|>{input_text}<|endoftext|><|assistant|>\",\n                        \"template_format\": \"f-string\",\n                        \"validate_template\": true,\n                        \"_type\": \"prompt\"\n                    },\n                    \"llm\": {\n                        \"repo_id\": \"OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\",\n                        \"task\": null,\n                        \"model_kwargs\": {\"max_new_tokens\": 200},\n                        \"_type\": \"huggingface_hub\"\n                    },\n                    \"output_key\": \"output_text\",\n                    \"_type\": \"llm_chain\"\n                }\"\"\"\n            ),\n            is_public=True,\n        )\n    )\n    db.session.add(\n        Ai(\n            name=\"OpenAssistant SFT-4 12B with knowledge @HuggingFace-Hub\",\n            input_keys=[\"input_text\", \"input_knowledge\"],\n            chain=json.loads(\n                # pylint: disable=line-too-long\n                \"\"\"{\n                    \"memory\": null,\n                    \"callbacks\": null,\n                    \"callback_manager\": null,\n                    \"verbose\": false,\n                    \"input_key\": \"input_knowledge\",\n                    \"output_key\": \"output_text\",\n                    \"llm_chain\": {\n                        \"memory\": null,\n                        \"callbacks\": null,\n                        \"callback_manager\": null,\n                        \"verbose\": false,\n                        \"prompt\": {\n                            \"input_variables\": [\"summaries\", \"input_text\"],\n                            \"output_parser\": null,\n                            \"partial_variables\": {},\n                            \"template\": \"<|prompter|>Please answer this question: {input_text}\\\\nUse the following information:\\\\n{summaries}\\\\n<|endoftext|><|assistant|>\",\n                            \"template_format\": \"f-string\",\n                            \"validate_template\": true, \"_type\": \"prompt\"\n                        },\n                        \"llm\": {\n                            \"repo_id\": \"OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\",\n                            \"task\": null,\n                            \"model_kwargs\": {\"max_new_tokens\": 200},\n                            \"_type\": \"huggingface_hub\"\n                        },\n                        \"output_key\": \"text\",\n                        \"_type\": \"llm_chain\"\n                    },\n                    \"document_prompt\": {\n                        \"input_variables\": [\"page_content\", \"source\"],\n                        \"output_parser\": null,\n                        \"partial_variables\": {},\n                        \"template\": \"Context: {page_content}\\\\nSource: {source}\",\n                        \"template_format\": \"f-string\",\n                        \"validate_template\": true,\n                        \"_type\": \"prompt\"\n                    },\n                    \"document_variable_name\": \"summaries\",\n                    \"document_separator\": \"\\\\n\\\\n\",\n                    \"_type\": \"stuff_documents_chain\"\n                }\"\"\"\n                # pylint: enable=line-too-long\n            ),\n        )\n    )\n\n    db.session.add(\n        Knowledge(\n            name=\"Test 1\",\n            embeddings=\"huggingface\",\n            chunk_size=500,\n            persist_directory=\"instance/test-knowledge-1\",\n            is_public=True,\n        )\n    )\n    db.session.add(\n        Knowledge(\n            name=\"Test 2\",\n            embeddings=\"huggingface\",\n            chunk_size=500,\n            persist_directory=\"instance/test-knowledge-2\",\n        )\n    )\n\n    db.session.commit()\n"}
{"type": "test_file", "path": "tests/api/test_ai_api.py", "content": "\"\"\"Test the AI API.\"\"\"\nimport json\nimport pytest\nfrom backaind.extensions import db\nfrom backaind.models import Ai\n\n\ndef test_auth_required(client):\n    \"\"\"Test whether authorization is required to access the API.\"\"\"\n    assert client.get(\"/api/ai/\").status_code == 401\n    assert client.get(\"/api/ai/2\").status_code == 401\n    assert client.post(\"/api/ai/\", json={}).status_code == 401\n    assert client.put(\"/api/ai/1\", json={}).status_code == 401\n    assert client.delete(\"/api/ai/1\").status_code == 401\n\n\ndef test_get_all_ais(client, auth):\n    \"\"\"Test if GET /api/ai/ returns all AIs from the database.\"\"\"\n    auth.login()\n    response = client.get(\"/api/ai/\")\n    assert 2 == len(json.loads(response.data))\n\n\ndef test_get_ai(client, auth):\n    \"\"\"Test if GET /api/ai/1 returns the AI with id 1.\"\"\"\n    auth.login()\n    response = client.get(\"/api/ai/1\")\n    assert 1 == json.loads(response.data)[\"id\"]\n\n\ndef test_get_unknown_ai_returns_404(client, auth):\n    \"\"\"Test if GET /api/ai/999 returns 404.\"\"\"\n    auth.login()\n    response = client.get(\"/api/ai/999\")\n    assert response.status_code == 404\n\n\ndef test_create_ai(client, auth, app):\n    \"\"\"Test if POST /api/ai/ creates a new AI.\"\"\"\n    auth.login()\n    response = client.post(\n        \"/api/ai/\", json={\"name\": \"Test\", \"input_keys\": [\"input_text\"], \"chain\": {}}\n    )\n    assert json.loads(response.data)[\"id\"] == 3\n    with app.app_context():\n        entry = db.get_or_404(Ai, 3)\n        assert entry and entry.name == \"Test\"\n\n\ndef test_update_ai(client, auth, app):\n    \"\"\"Test if PUT /api/ai/1 updates the AI.\"\"\"\n    auth.login()\n    response = client.put(\n        \"/api/ai/1\", json={\"name\": \"Test\", \"input_keys\": [\"input_text\"], \"chain\": {}}\n    )\n    assert json.loads(response.data)[\"name\"] == \"Test\"\n    with app.app_context():\n        entry = db.get_or_404(Ai, 1)\n        assert entry and entry.name == \"Test\"\n\n\ndef test_delete_ai(client, auth, app):\n    \"\"\"Test if DELETE /api/ai/1 deletes the AI.\"\"\"\n    auth.login()\n    response = client.delete(\"/api/ai/1\")\n    assert response.status_code == 204\n    with app.app_context():\n        entry = db.session.get(Ai, 1)\n        assert entry is None\n\n\n@pytest.mark.parametrize(\n    \"data,message\",\n    (\n        (\n            {},\n            \"The AI file cannot be empty.\",\n        ),\n        (\n            {\"input_keys\": [], \"chain\": {}},\n            'The property \"name\" is required.',\n        ),\n        (\n            {\"name\": 1, \"input_keys\": [], \"chain\": {}},\n            'The property \"name\" has to be a string.',\n        ),\n        (\n            {\"name\": \"Test\", \"chain\": {}},\n            'The property \"input_keys\" is required.',\n        ),\n        (\n            {\"name\": \"Test\", \"input_keys\": \"input_text\", \"chain\": {}},\n            'The property \"input_keys\" has to be a list of strings.',\n        ),\n        (\n            {\"name\": \"Test\", \"input_keys\": []},\n            'The property \"chain\" is required.',\n        ),\n        (\n            {\"name\": \"Test\", \"input_keys\": [], \"chain\": []},\n            'The property \"chain\" has to be a chain object.',\n        ),\n        (\n            {\"name\": \"Test\", \"input_keys\": [], \"chain\": {}, \"input_labels\": \"Test\"},\n            'The property \"input_labels\" has to be an object assigning input keys to labels.',\n        ),\n        (\n            {\"name\": \"Test\", \"input_keys\": [], \"chain\": {}, \"greeting\": True},\n            'The property \"greeting\" has to be a string.',\n        ),\n    ),\n)\ndef test_validation(client, auth, data, message):\n    \"\"\"Test if the AI JSON validation works.\"\"\"\n    auth.login()\n    for response in (\n        client.post(\"/api/ai/\", json=data),\n        client.put(\"/api/ai/1\", json=data),\n    ):\n        assert response.status_code == 400\n        assert json.loads(response.data)[\"error\"] == message\n"}
{"type": "source_file", "path": "backaind/extensions.py", "content": "\"\"\"Make extensions available in all modules.\"\"\"\nfrom flask_socketio import SocketIO\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_migrate import Migrate\n\nsocketio = SocketIO()\ndb = SQLAlchemy()\nmigrate = Migrate()\n"}
{"type": "source_file", "path": "backaind/api/__init__.py", "content": "\"\"\"ownAI API\"\"\"\n"}
{"type": "source_file", "path": "backaind/__init__.py", "content": "\"\"\"Backaind is the ownAI Flask application to manage and run your own AI models.\"\"\"\nimport os\n\nfrom flask import Flask, g\n\nfrom . import aifile, ainteraction, auth, knowledge, settings, workshop\nfrom .api import ai as api_ai, knowledge as api_knowledge\nfrom .extensions import db, migrate, socketio\nfrom .models import *\n\n\ndef create_app(test_config=None):\n    \"\"\"Create a new ownAI Flask application.\"\"\"\n    app = Flask(__name__)\n\n    if test_config is None:\n        # load from environment when not testing\n        app.config.from_prefixed_env(\"OWNAI\")\n    else:\n        # load the test config if passed in\n        app.config.from_mapping(test_config)\n\n    # ensure the instance folder exists\n    try:\n        os.makedirs(app.instance_path)\n    except OSError:\n        pass\n\n    # init extensions and blueprints\n    app.before_request(register_vite_dev_server)\n    socketio.init_app(app)\n    db.init_app(app)\n    migrate.init_app(app, db)\n\n    auth.init_app(app)\n    aifile.init_app(app)\n    ainteraction.init_app(app)\n    knowledge.init_app(app)\n\n    # register blueprints\n    app.register_blueprint(auth.bp)\n    app.register_blueprint(ainteraction.bp)\n    app.register_blueprint(settings.bp)\n    app.register_blueprint(workshop.bp)\n    app.register_blueprint(api_ai.bp)\n    app.register_blueprint(api_knowledge.bp)\n    app.add_url_rule(\"/\", endpoint=\"index\")\n\n    return app\n\n\ndef register_vite_dev_server():\n    \"\"\"Make Vite port available if Vite dev server should be used.\"\"\"\n    g.vite_dev_server_enabled = \"VITE_PORT\" in os.environ\n    g.vite_dev_server_port = os.environ.get(\"VITE_PORT\")\n"}
{"type": "source_file", "path": "backaind/api/ai.py", "content": "\"\"\"API to create, read, update and delete AIs.\"\"\"\nfrom flask import Blueprint, jsonify, request, make_response, abort\n\nfrom ..auth import login_required\nfrom ..brain import reset_global_chain\nfrom ..extensions import db\nfrom ..models import Ai\n\nbp = Blueprint(\"api-ai\", __name__, url_prefix=\"/api/ai\")\n\n\ndef validate(ai_json):\n    \"\"\"Validate if the JSON is valid for an AI entry.\"\"\"\n    if not ai_json:\n        abort(make_response(jsonify(error=\"The AI file cannot be empty.\"), 400))\n    if not \"name\" in ai_json:\n        abort(make_response(jsonify(error='The property \"name\" is required.'), 400))\n    if not isinstance(ai_json[\"name\"], str):\n        abort(\n            make_response(jsonify(error='The property \"name\" has to be a string.'), 400)\n        )\n    if not \"input_keys\" in ai_json:\n        abort(\n            make_response(jsonify(error='The property \"input_keys\" is required.'), 400)\n        )\n    if not isinstance(ai_json[\"input_keys\"], list):\n        abort(\n            make_response(\n                jsonify(error='The property \"input_keys\" has to be a list of strings.'),\n                400,\n            )\n        )\n    if (\n        \"input_labels\" in ai_json\n        and ai_json[\"input_labels\"]\n        and not isinstance(ai_json[\"input_labels\"], dict)\n    ):\n        abort(\n            make_response(\n                jsonify(\n                    error='The property \"input_labels\" has to be an object'\n                    + \" assigning input keys to labels.\"\n                ),\n                400,\n            )\n        )\n    if not \"chain\" in ai_json:\n        abort(make_response(jsonify(error='The property \"chain\" is required.'), 400))\n    if not isinstance(ai_json[\"chain\"], dict):\n        abort(\n            make_response(\n                jsonify(error='The property \"chain\" has to be a chain object.'), 400\n            )\n        )\n    if (\n        \"greeting\" in ai_json\n        and ai_json[\"greeting\"]\n        and not isinstance(ai_json[\"greeting\"], str)\n    ):\n        abort(\n            make_response(\n                jsonify(error='The property \"greeting\" has to be a string.'), 400\n            )\n        )\n\n\n@bp.route(\"/\", methods=[\"GET\"])\n@login_required\ndef get_all_ais():\n    \"\"\"Get all AIs.\"\"\"\n    return [ai.as_dict() for ai in db.session.query(Ai).all()]\n\n\n@bp.route(\"/<int:ai_id>\", methods=[\"GET\"])\n@login_required\ndef get_ai(ai_id):\n    \"\"\"Get a specific AI.\"\"\"\n    aifile = db.get_or_404(Ai, ai_id)\n    return aifile.as_dict()\n\n\n@bp.route(\"/\", methods=[\"POST\"])\n@login_required\ndef create_ai():\n    \"\"\"Create a new AI.\"\"\"\n    validate(request.json)\n    assert request.json\n\n    name = request.json[\"name\"]\n    input_keys = request.json[\"input_keys\"]\n    input_labels = request.json.get(\"input_labels\")\n    chain = request.json[\"chain\"]\n    greeting = request.json.get(\"greeting\")\n    new_ai = Ai(\n        name=name,\n        input_keys=input_keys,\n        input_labels=input_labels,\n        chain=chain,\n        greeting=greeting,\n    )\n    db.session.add(new_ai)\n    db.session.commit()\n    return (\n        jsonify(new_ai.as_dict()),\n        201,\n    )\n\n\n@bp.route(\"/<int:ai_id>\", methods=[\"PUT\"])\n@login_required\ndef update_ai(ai_id):\n    \"\"\"Update an AI.\"\"\"\n    validate(request.json)\n    assert request.json\n\n    name = request.json[\"name\"]\n    input_keys = request.json[\"input_keys\"]\n    input_labels = request.json.get(\"input_labels\")\n    chain = request.json[\"chain\"]\n    greeting = request.json.get(\"greeting\")\n\n    existing_ai = db.get_or_404(Ai, ai_id)\n    existing_ai.name = name\n    existing_ai.input_keys = input_keys\n    existing_ai.input_labels = input_labels\n    existing_ai.chain = chain\n    existing_ai.greeting = greeting\n    db.session.commit()\n    reset_global_chain(ai_id)\n    return existing_ai.as_dict()\n\n\n@bp.route(\"/<int:ai_id>\", methods=[\"DELETE\"])\n@login_required\ndef delete_ai(ai_id):\n    \"\"\"Delete an AI.\"\"\"\n    existing_ai = db.get_or_404(Ai, ai_id)\n    db.session.delete(existing_ai)\n    db.session.commit()\n    reset_global_chain(ai_id)\n    return (\"\", 204)\n"}
{"type": "source_file", "path": "backaind/ainteraction.py", "content": "\"\"\"Allow interaction with an AI.\"\"\"\nfrom datetime import datetime\nimport json\n\nfrom flask import Blueprint, render_template, session, g, redirect, url_for\nfrom flask_socketio import emit, disconnect\nfrom langchain.memory import ConversationBufferWindowMemory\n\nfrom .brain import reply\nfrom .extensions import db, socketio\nfrom .models import Ai, Knowledge\nfrom .settings import get_settings\n\nbp = Blueprint(\"ainteraction\", __name__)\n\n\n@bp.route(\"/\")\n@bp.route(\"/<_ai>\")\ndef index(_ai=None):\n    \"\"\"Render the main ainteraction view.\"\"\"\n    is_public = g.get(\"user\") is None\n    ais = get_ai_data(only_public=is_public)\n\n    if is_public and not ais:\n        return redirect(url_for(\"auth.login\"))\n\n    return render_template(\n        \"ainteraction/index.html\",\n        ais=json.dumps(ais),\n        knowledges=json.dumps(get_knowledge_data(only_public=is_public)),\n    )\n\n\ndef handle_incoming_message(message):\n    \"\"\"Handle an incoming socket.io message from a user.\"\"\"\n    is_public = session.get(\"user_id\") is None\n    ai_id = message.get(\"aiId\")\n    knowledge_id = message.get(\"knowledgeId\")\n\n    if not ai_id:\n        disconnect()\n        return\n\n    if is_public and not is_ai_public(ai_id):\n        disconnect()\n        return\n\n    if is_public and knowledge_id and not is_knowledge_public(knowledge_id):\n        disconnect()\n        return\n\n    response_id = message.get(\"responseId\")\n    message_text = message.get(\"message\", {}).get(\"text\", \"\")\n\n    memory = ConversationBufferWindowMemory(k=3)\n    for history_message in message.get(\"history\", []):\n        if history_message.get(\"author\", {}).get(\"species\") == \"ai\":\n            memory.chat_memory.add_ai_message(history_message.get(\"text\", \"\"))\n        else:\n            memory.chat_memory.add_user_message(history_message.get(\"text\", \"\"))\n\n    try:\n        response = reply(\n            ai_id,\n            message_text,\n            knowledge_id,\n            memory,\n            lambda token: send_next_token(response_id, token),\n            lambda progress: send_progress(response_id, progress),\n            get_settings(session.get(\"user_id\", -1)).get(\"external-providers\", {}),\n        )\n        send_response(response_id, response.strip())\n    # pylint: disable=broad-exception-caught\n    except Exception as exception:\n        send_response(response_id, str(exception), \"error\")\n        raise exception\n\n\ndef init_app(_app):\n    \"\"\"Register handling of incoming socket.io messages.\"\"\"\n    socketio.on(\"message\")(handle_incoming_message)\n\n\ndef get_ai_data(only_public=True):\n    \"\"\"Get data for all AIs.\"\"\"\n    ai_query = db.session.query(Ai)\n    if only_public:\n        ai_query = ai_query.filter_by(is_public=True)\n    return [\n        {\n            \"id\": ai.id,\n            \"name\": ai.name,\n            \"input_keys\": ai.input_keys,\n            \"input_labels\": ai.input_labels,\n            \"greeting\": ai.greeting,\n        }\n        for ai in ai_query.all()\n    ]\n\n\ndef get_knowledge_data(only_public=True):\n    \"\"\"Get data for all knowledges.\"\"\"\n    knowledge_query = db.session.query(Knowledge)\n    if only_public:\n        knowledge_query = knowledge_query.filter_by(is_public=True)\n    return [\n        {\n            \"id\": knowledge.id,\n            \"name\": knowledge.name,\n        }\n        for knowledge in knowledge_query.all()\n    ]\n\n\ndef is_ai_public(ai_id: int):\n    \"\"\"Check if an AI is public.\"\"\"\n    ai = db.session.get(Ai, ai_id)\n    return bool(ai and ai.is_public)\n\n\ndef is_knowledge_public(knowledge_id: int):\n    \"\"\"Check if a knowledge is public.\"\"\"\n    knowledge = db.session.get(Knowledge, knowledge_id)\n    return bool(knowledge and knowledge.is_public)\n\n\ndef send_progress(response_id: int, progress: int):\n    \"\"\"Send the current progress to the user.\"\"\"\n    emit(\n        \"progress\",\n        {\n            \"messageId\": response_id,\n            \"progress\": progress,\n        },\n    )\n\n\ndef send_next_token(response_id: int, token_text: str):\n    \"\"\"Send the next response token to the user.\"\"\"\n    emit(\n        \"token\",\n        {\n            \"messageId\": response_id,\n            \"text\": token_text,\n        },\n    )\n\n\ndef send_response(response_id: int, message_text: str, status: str = \"done\"):\n    \"\"\"Send the full response message to the user.\"\"\"\n    emit(\n        \"message\",\n        {\n            \"id\": response_id,\n            \"author\": {\n                \"species\": \"ai\",\n            },\n            \"date\": datetime.now().isoformat(),\n            \"text\": message_text,\n            \"status\": status,\n        },\n    )\n"}
{"type": "source_file", "path": "backaind/aifile.py", "content": "\"\"\"Functions to read and validate Aifiles.\"\"\"\nimport json\n\nimport click\nfrom flask import current_app\n\nfrom .extensions import db\nfrom .models import Ai\n\nMAX_AIFILEVERSION = 1\n\n\nclass InvalidAifileError(Exception):\n    \"\"\"The Aifile has invalid or missing data.\"\"\"\n\n\ndef validate_aifile(aifile):\n    \"\"\"Validate an Aifile for required fields and correct version.\"\"\"\n    required_fields = [\"name\", \"aifileversion\", \"chain\"]\n    allowed_input_keys = [\"input_text\", \"input_knowledge\", \"input_history\"]\n\n    for field in required_fields:\n        if field not in aifile:\n            raise InvalidAifileError(f\"Missing field in aifile: {field}\")\n\n    for input_key in get_input_keys(aifile):\n        if input_key not in allowed_input_keys:\n            raise InvalidAifileError(f\"Unknown input key: {input_key}\")\n\n    if aifile[\"aifileversion\"] > MAX_AIFILEVERSION:\n        raise InvalidAifileError(\"This aifile requires a newer version of ownAI.\")\n\n\ndef get_input_keys(aifile):\n    \"\"\"Get all input keys for an aifile.\"\"\"\n\n    def iterate_json_key_values(json_obj, key_prefix=\"\"):\n        if isinstance(json_obj, dict):\n            for key, value in json_obj.items():\n                new_key_prefix = f\"{key_prefix}.{key}\" if key_prefix else key\n                if isinstance(value, (dict, list)):\n                    yield from iterate_json_key_values(value, new_key_prefix)\n                else:\n                    yield (new_key_prefix, value)\n        elif isinstance(json_obj, list):\n            for index, value in enumerate(json_obj):\n                new_key_prefix = f\"{key_prefix}[{index}]\"\n                if isinstance(value, (dict, list)):\n                    yield from iterate_json_key_values(value, new_key_prefix)\n                else:\n                    yield (new_key_prefix, value)\n\n    input_keys = set()\n    for key, value in iterate_json_key_values(aifile):\n        if (\"input_key\" in key or \"input_variables\" in key) and value.startswith(\n            \"input_\"\n        ):\n            input_keys.add(value)\n    return input_keys\n\n\ndef read_aifile_from_path(aifile_path):\n    \"\"\"Read an Aifile from the given path and validate its data. Return the Aifile as dictionary.\"\"\"\n    with open(aifile_path, \"r\", encoding=\"utf-8\") as file:\n        data = json.load(file)\n    validate_aifile(data)\n    return data\n\n\n@click.command(\"add-ai\")\n@click.option(\"--aifile\", \"aifile_path\", prompt=\"Aifile to import\")\ndef add_ai(aifile_path):\n    \"\"\"Register a new AI or update an AI with the same name.\"\"\"\n    aifile = read_aifile_from_path(aifile_path)\n    name = aifile[\"name\"]\n    input_keys = list(get_input_keys(aifile))\n    input_labels = aifile.get(\"input_labels\")\n    chain = aifile[\"chain\"]\n    greeting = aifile.get(\"greeting\")\n\n    existing_ai = db.session.query(Ai).filter_by(name=name).first()\n\n    if existing_ai is None:\n        new_ai = Ai(\n            name=name,\n            input_keys=input_keys,\n            input_labels=input_labels,\n            chain=chain,\n            greeting=greeting,\n        )\n        db.session.add(new_ai)\n        db.session.commit()\n        click.echo(f\"Added {name}. Say hello!\")\n    else:\n        existing_ai.input_keys = input_keys\n        existing_ai.input_labels = input_labels\n        existing_ai.chain = chain\n        existing_ai.greeting = greeting\n        existing_ai.name = name\n        db.session.commit()\n        click.echo(f\"Updated {name}. Say hello!\")\n\n\n@click.command(\"download-model\")\n@click.option(\"--repo\", \"repo_id\", prompt=\"Hugging Face Repository ID\")\n@click.option(\"--filename\", \"filename\", prompt=\"File within the repository\")\ndef download_model(repo_id, filename):\n    \"\"\"Download a model from Hugging Face and save it to the instance folder.\"\"\"\n    # pylint: disable-next=import-outside-toplevel\n    from huggingface_hub import hf_hub_download\n\n    hf_hub_download(\n        repo_id=repo_id,\n        filename=filename,\n        local_dir=current_app.instance_path,\n        local_dir_use_symlinks=True,\n    )\n\n\ndef init_app(app):\n    \"\"\"Register CLI commands with the application instance.\"\"\"\n    app.cli.add_command(add_ai)\n    app.cli.add_command(download_model)\n"}
{"type": "source_file", "path": "backaind/api/knowledge.py", "content": "\"\"\"API to create, read, update and delete knowledge.\"\"\"\nimport os\nimport shutil\nimport tempfile\nimport uuid\n\nfrom flask import Blueprint, jsonify, request, make_response, abort, current_app\nfrom langchain.document_loaders.base import BaseLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nfrom ..auth import login_required\nfrom ..extensions import db\nfrom ..knowledge import (\n    add_to_knowledge,\n    reset_global_knowledge,\n    get_from_knowledge,\n    delete_from_knowledge,\n)\nfrom ..models import Knowledge\n\nbp = Blueprint(\"api-knowledge\", __name__, url_prefix=\"/api/knowledge\")\n\n\ndef validate(knowledge_json):\n    \"\"\"Validate if the JSON is valid for a knowledge entry.\"\"\"\n    if not knowledge_json:\n        abort(make_response(jsonify(error=\"The knowledge data cannot be empty.\"), 400))\n    if not \"name\" in knowledge_json:\n        abort(make_response(jsonify(error='The property \"name\" is required.'), 400))\n    if not isinstance(knowledge_json[\"name\"], str):\n        abort(\n            make_response(jsonify(error='The property \"name\" has to be a string.'), 400)\n        )\n    if not \"embeddings\" in knowledge_json:\n        abort(\n            make_response(jsonify(error='The property \"embeddings\" is required.'), 400)\n        )\n    if not knowledge_json[\"embeddings\"] in (\"huggingface\",):\n        abort(make_response(jsonify(error=\"Unknown embeddings type.\"), 400))\n    if not \"chunk_size\" in knowledge_json:\n        abort(\n            make_response(jsonify(error='The property \"chunk_size\" is required.'), 400)\n        )\n    if not isinstance(knowledge_json[\"chunk_size\"], int):\n        abort(\n            make_response(\n                jsonify(error='The property \"chunk_size\" has to be a number.'), 400\n            )\n        )\n\n\n@bp.route(\"/\", methods=[\"GET\"])\n@login_required\ndef get_all_knowledge():\n    \"\"\"Get all knowledge.\"\"\"\n    return [knowledge.as_dict() for knowledge in db.session.query(Knowledge).all()]\n\n\n@bp.route(\"/<int:knowledge_id>\", methods=[\"GET\"])\n@login_required\ndef get_knowledge(knowledge_id):\n    \"\"\"Get a specific knowledge entry.\"\"\"\n    knowledge = db.get_or_404(Knowledge, knowledge_id)\n    return knowledge.as_dict()\n\n\n@bp.route(\"/\", methods=[\"POST\"])\n@login_required\ndef create_knowledge():\n    \"\"\"Create a new knowledge entry.\"\"\"\n    validate(request.json)\n    assert request.json\n\n    name = request.json[\"name\"]\n    embeddings = request.json[\"embeddings\"]\n    chunk_size = request.json[\"chunk_size\"]\n    persist_directory = os.path.join(\n        current_app.instance_path, \"knowledge-\" + uuid.uuid4().hex\n    )\n    os.makedirs(persist_directory)\n\n    new_knowledge = Knowledge(\n        name=name,\n        embeddings=embeddings,\n        chunk_size=chunk_size,\n        persist_directory=persist_directory,\n    )\n    db.session.add(new_knowledge)\n    db.session.commit()\n    return (\n        jsonify(new_knowledge.as_dict()),\n        201,\n    )\n\n\n@bp.route(\"/<int:knowledge_id>\", methods=[\"PUT\"])\n@login_required\ndef update_knowledge(knowledge_id):\n    \"\"\"Update a knowledge entry.\"\"\"\n    validate(request.json)\n    assert request.json\n\n    existing_knowledge = db.get_or_404(Knowledge, knowledge_id)\n    name = request.json[\"name\"]\n    chunk_size = request.json[\"chunk_size\"]\n    if request.json[\"embeddings\"] != existing_knowledge.embeddings:\n        abort(\n            make_response(\n                jsonify(error=\"Cannot change the embeddings type afterwards.\"), 400\n            )\n        )\n\n    existing_knowledge.name = name\n    existing_knowledge.chunk_size = chunk_size\n    db.session.commit()\n    reset_global_knowledge(knowledge_id)\n    return jsonify(\n        {\n            \"id\": knowledge_id,\n            \"name\": name,\n            \"embeddings\": existing_knowledge.embeddings,\n            \"chunk_size\": chunk_size,\n        }\n    )\n\n\n@bp.route(\"/<int:knowledge_id>\", methods=[\"DELETE\"])\n@login_required\ndef delete_knowledge(knowledge_id):\n    \"\"\"Delete a knowledge entry.\"\"\"\n    existing_knowledge = db.get_or_404(Knowledge, knowledge_id)\n    persist_directory = existing_knowledge.persist_directory\n    db.session.delete(existing_knowledge)\n    db.session.commit()\n    shutil.rmtree(persist_directory)\n    reset_global_knowledge(knowledge_id)\n    return (\"\", 204)\n\n\n@bp.route(\"/<int:knowledge_id>/document\", methods=[\"GET\"])\n@login_required\ndef get_documents(knowledge_id):\n    \"\"\"Get documents from the specific knowledge.\"\"\"\n    limit = request.args.get(\"limit\", 10, type=int)\n    offset = request.args.get(\"offset\", 0, type=int)\n    return get_from_knowledge(knowledge_id, limit, offset)\n\n\n@bp.route(\"/<int:knowledge_id>/document/<string:document_id>\", methods=[\"DELETE\"])\n@login_required\ndef delete_document(knowledge_id, document_id):\n    \"\"\"Delete a document from a knowledge.\"\"\"\n    delete_from_knowledge(knowledge_id, [document_id])\n    return (\"\", 204)\n\n\n@bp.route(\"/<int:knowledge_id>/document/txt\", methods=[\"POST\"])\n@login_required\ndef upload_txt(knowledge_id):\n    \"\"\"Add a txt file to a knowledge.\"\"\"\n    # pylint: disable=import-outside-toplevel\n    from langchain.document_loaders import TextLoader\n\n    file_path = handle_upload(request.files.get(\"file\"))\n    loader = TextLoader(file_path, encoding=\"utf8\")\n    load_into_knowledge(loader, knowledge_id)\n    return (\"\", 204)\n\n\n@bp.route(\"/<int:knowledge_id>/document/pdf\", methods=[\"POST\"])\n@login_required\ndef upload_pdf(knowledge_id):\n    \"\"\"Add a pdf file to a knowledge.\"\"\"\n    # pylint: disable=import-outside-toplevel\n    from langchain.document_loaders import PyPDFLoader\n\n    file_path = handle_upload(request.files.get(\"file\"))\n    loader = PyPDFLoader(file_path)\n    load_into_knowledge(loader, knowledge_id)\n    return (\"\", 204)\n\n\n@bp.route(\"/<int:knowledge_id>/document/docx\", methods=[\"POST\"])\n@login_required\ndef upload_docx(knowledge_id):\n    \"\"\"Add a docx file to a knowledge.\"\"\"\n    # pylint: disable=import-outside-toplevel\n    from langchain.document_loaders import Docx2txtLoader\n\n    file_path = handle_upload(request.files.get(\"file\"))\n    loader = Docx2txtLoader(file_path)\n    load_into_knowledge(loader, knowledge_id)\n    return (\"\", 204)\n\n\ndef handle_upload(file):\n    \"\"\"Save the uploaded file to a temporary directory.\"\"\"\n    if not file:\n        abort(make_response(jsonify(error=\"No file has been uploaded.\"), 400))\n    temp_dir = tempfile.mkdtemp()\n    file_path = os.path.join(temp_dir, file.filename)\n    file.save(file_path)\n    return file_path\n\n\ndef load_into_knowledge(loader: BaseLoader, knowledge_id: int):\n    \"\"\"Load content from the document loader into knowledge.\"\"\"\n    knowledge = db.get_or_404(Knowledge, knowledge_id)\n    chunks = loader.load_and_split(\n        RecursiveCharacterTextSplitter(chunk_size=knowledge.chunk_size)\n    )\n    add_to_knowledge(knowledge_id, chunks)\n"}
{"type": "source_file", "path": "backaind/brain.py", "content": "\"\"\"Provide AI data processing capabilities.\"\"\"\nimport os\nimport queue\nfrom threading import Lock\nfrom typing import Any, Callable, Dict, List, Optional, Set, Tuple\n\nfrom langchain.callbacks.base import BaseCallbackHandler\nfrom langchain.chains.base import Chain\nfrom langchain.chains.loading import load_chain_from_config\nfrom langchain.llms.huggingface_text_gen_inference import HuggingFaceTextGenInference\nfrom langchain.schema import BaseMemory\n\nfrom backaind.extensions import db\nfrom backaind.knowledge import get_knowledge\nfrom backaind.models import Ai\n\nDEFAULT_PPWPS = 2.0\n# pylint: disable=invalid-name\nglobal_chain = None\nglobal_chain_id = None\nglobal_chain_input_keys = None\n# prompt processing words per second\nglobal_chain_ppwps = DEFAULT_PPWPS\n# pylint: enable=invalid-name\nchain_lock = Lock()\n\n\ndef get_chain(\n    ai_id: int, updated_environment: Optional[dict] = None\n) -> Tuple[Chain, Set[str]]:\n    \"\"\"Load the AI chain or create a new chain if it doesn't exist.\"\"\"\n    # pylint: disable=global-statement\n    global global_chain, global_chain_id, global_chain_input_keys, global_chain_ppwps\n    with chain_lock:\n        chain = global_chain\n        chain_id = global_chain_id\n        chain_input_keys = global_chain_input_keys\n        if not chain or not chain_input_keys or chain_id != ai_id:\n            aifile = db.get_or_404(Ai, ai_id)\n            chain_input_keys = aifile.input_keys\n            with UpdatedEnvironment(updated_environment or {}):\n                chain = load_chain_from_config(aifile.chain)\n            set_text_generation_inference_token(chain)\n            global_chain = chain\n            global_chain_id = ai_id\n            global_chain_input_keys = chain_input_keys\n            global_chain_ppwps = DEFAULT_PPWPS\n    return (chain, chain_input_keys)\n\n\ndef reset_global_chain(ai_id=None):\n    \"\"\"\n    Drop the global chain instance.\n    If ai_id is set, it only drops the global chain instance if it matches this ID.\n    \"\"\"\n    # pylint: disable=global-statement\n    global global_chain, global_chain_id, global_chain_input_keys, global_chain_ppwps\n    with chain_lock:\n        if not ai_id or ai_id == global_chain_id:\n            global_chain = None\n            global_chain_id = None\n            global_chain_input_keys = None\n            global_chain_ppwps = DEFAULT_PPWPS\n\n\ndef reply(\n    ai_id: int,\n    input_text: str,\n    knowledge_id: Optional[int] = None,\n    memory: Optional[BaseMemory] = None,\n    on_token: Optional[Callable[[str], None]] = None,\n    on_progress: Optional[Callable[[int], None]] = None,\n    updated_environment: Optional[dict] = None,\n) -> str:\n    \"\"\"Run the chain with an input message and return the AI output.\"\"\"\n    (chain, chain_input_keys) = get_chain(ai_id, updated_environment)\n    inputs = {}\n    has_memory = (\n        memory\n        and \"input_history\" in chain_input_keys\n        and memory.load_memory_variables({})[\"history\"]\n    )\n    for input_key in chain_input_keys:\n        if input_key == \"input_text\":\n            inputs[\"input_text\"] = input_text\n        elif input_key == \"input_knowledge\":\n            if knowledge_id is None:\n                inputs[\"input_knowledge\"] = []\n            else:\n                with UpdatedEnvironment({\"TOKENIZERS_PARALLELISM\": \"false\"}):\n                    knowledge = get_knowledge(knowledge_id)\n                    inputs[\"input_knowledge\"] = knowledge.similarity_search(\n                        input_text, k=1 if has_memory else 4\n                    )\n        elif input_key == \"input_history\":\n            if memory is None:\n                inputs[\"input_history\"] = \"\"\n            else:\n                inputs[\"input_history\"] = memory.load_memory_variables({})[\"history\"]\n\n    if \"gunicorn\" in os.environ.get(\"SERVER_SOFTWARE\", \"\"):\n        return run_chain_on_gunicorn(chain, inputs, on_token, on_progress)\n    return run_chain_on_multiprocessing(chain, inputs, on_token, on_progress)\n\n\ndef run_chain_on_gunicorn(\n    chain: Chain,\n    inputs: dict,\n    on_token: Optional[Callable[[str], None]],\n    on_progress: Optional[Callable[[int], None]],\n):\n    \"\"\"Run the chain with gipc in the context of gevent.\"\"\"\n    # pylint: disable=import-outside-toplevel\n    import gevent\n    import gipc\n\n    with gipc.pipe() as (readend, writeend):\n        gipc.start_process(\n            target=run_chain_process, args=(chain, inputs, writeend), daemon=True\n        )\n        seconds_estimated = 0\n        seconds_passed = 0\n        prompt = \"\"\n        updated_global_chain_ppwps = False\n        while True:\n            message = None\n            with gevent.Timeout(1, False) as timeout:\n                message = readend.get(timeout=timeout)\n            if message is None:\n                if seconds_estimated:\n                    seconds_passed += 1\n                    if on_progress and seconds_passed <= seconds_estimated:\n                        on_progress(int(seconds_passed / seconds_estimated * 100))\n            else:\n                result_type, text = message\n                if result_type == \"token\":\n                    if on_token:\n                        on_token(text)\n                    if not updated_global_chain_ppwps:\n                        updated_global_chain_ppwps = True\n                        update_global_chain_ppwps(prompt, seconds_passed)\n                elif result_type == \"done\":\n                    return text\n                elif result_type == \"prompts\":\n                    prompt = \"\\n\".join(text)\n                    seconds_estimated = estimate_processing_time(prompt)\n\n\ndef run_chain_on_multiprocessing(\n    chain: Chain,\n    inputs: dict,\n    on_token: Optional[Callable[[str], None]],\n    on_progress: Optional[Callable[[int], None]],\n):\n    \"\"\"Run the chain with multiprocessing (won't work with gevent).\"\"\"\n    # pylint: disable-next=import-outside-toplevel\n    import multiprocessing\n\n    result_queue = multiprocessing.Queue()\n    multiprocessing.Process(\n        target=run_chain_process, args=(chain, inputs, result_queue), daemon=True\n    ).start()\n    seconds_estimated = 0\n    seconds_passed = 0\n    prompt = \"\"\n    updated_global_chain_ppwps = False\n    while True:\n        try:\n            result_type, text = result_queue.get(True, 1)\n            if result_type == \"token\":\n                if on_token:\n                    on_token(text)\n                if not updated_global_chain_ppwps:\n                    updated_global_chain_ppwps = True\n                    update_global_chain_ppwps(prompt, seconds_passed)\n            elif result_type == \"done\":\n                return text\n            elif result_type == \"prompts\":\n                prompt = \"\\n\".join(text)\n                seconds_estimated = estimate_processing_time(prompt)\n        except queue.Empty:\n            if seconds_estimated:\n                seconds_passed += 1\n                if on_progress and seconds_passed <= seconds_estimated:\n                    on_progress(int(seconds_passed / seconds_estimated * 100))\n\n\ndef run_chain_process(chain: Chain, inputs: dict, putable):\n    \"\"\"Run the chain in a separate process and put the results in the putable.\"\"\"\n\n    class CallbackHandler(BaseCallbackHandler):\n        \"\"\"Callback handler that puts tokens in the putable as they are generated.\"\"\"\n\n        def on_chat_model_start(self, serialized, messages, **kwargs):\n            pass\n\n        def on_llm_start(\n            self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n        ) -> Any:\n            putable.put((\"prompts\", prompts))\n\n        def on_llm_new_token(self, token: str, **kwargs) -> None:\n            putable.put((\"token\", token))\n\n    output_text = chain(inputs, callbacks=[CallbackHandler()])[\"output_text\"]\n    putable.put((\"done\", output_text))\n\n\ndef find_instances(obj, cls):\n    \"\"\"Find all instances of a class in an object.\"\"\"\n    instances = []\n    if isinstance(obj, cls):\n        instances.append(obj)\n    if isinstance(obj, list):\n        for item in obj:\n            instances.extend(find_instances(item, cls))\n    elif hasattr(obj, \"__dict__\"):\n        for prop in vars(obj).values():\n            instances.extend(find_instances(prop, cls))\n    return instances\n\n\ndef set_text_generation_inference_token(chain: Chain):\n    \"\"\"Set the token for all HuggingFaceTextGenInference instances in the chain.\"\"\"\n    token = os.environ.get(\"TEXT_GENERATION_INFERENCE_TOKEN\", None)\n    if not token:\n        return\n    all_huggingface_instances = find_instances(chain, HuggingFaceTextGenInference)\n    for instance in all_huggingface_instances:\n        instance.client.headers = {\"Authorization\": f\"Bearer {token}\"}\n\n\ndef estimate_processing_time(prompt: str) -> int:\n    \"\"\"Estimate the processing time for a prompt.\"\"\"\n    return int(len(prompt.split()) / global_chain_ppwps) or 1\n\n\ndef update_global_chain_ppwps(prompt: str, seconds_passed: int):\n    \"\"\"Update the global chain prompt processing words per second score.\"\"\"\n    # pylint: disable=global-statement\n    global global_chain_ppwps\n    global_chain_ppwps = len(prompt.split()) / (seconds_passed or 1)\n\n\nclass UpdatedEnvironment:\n    \"\"\"Temporarily update the environment variables.\"\"\"\n\n    def __init__(self, new_values):\n        self.new_values = new_values\n        self.old_values = {}\n\n    def __enter__(self):\n        for key, new_value in self.new_values.items():\n            if key in os.environ:\n                self.old_values[key] = os.environ[key]\n            os.environ[key] = new_value\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        for key in self.new_values.keys():\n            if key in self.old_values:\n                os.environ[key] = self.old_values[key]\n            else:\n                del os.environ[key]\n"}
{"type": "source_file", "path": "aifilemaker.py", "content": "#!/usr/bin/env python3\n\"\"\"Simple example how to quickly create Aifiles.\"\"\"\nimport json\nfrom langchain.chains import LLMChain\nfrom langchain.chains.loading import load_chain_from_config\nfrom langchain.llms.fake import FakeListLLM\nfrom langchain.prompts import PromptTemplate\n\n# 1. Set a name for your AI\nNAME = \"Fake AI\"\n\n# 2. Set up the LLM you want to use\n# (see https://python.langchain.com/en/latest/modules/models/llms/integrations.html for examples)\nllm = FakeListLLM(responses=[\"Hello\", \"Bye\"])\n\n# 3. Set up a prompt template for your LLM and task\n# (see https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html)\n# Consider using a template that suits your model!\n# Check the models page on Hugging Face etc. to get a correct prompting template.\nTEMPLATE = \"\"\"Question: {input_text}\nAnswer:\"\"\"\nprompt = PromptTemplate(template=TEMPLATE, input_variables=[\"input_text\"])\n\n# 4. Set up the chain\n# (see https://python.langchain.com/en/latest/modules/chains.html)\nllm_chain = LLMChain(prompt=prompt, llm=llm, output_key=\"output_text\")\n\n# Test if loading the chain again works\nload_chain_from_config(llm_chain.dict())\n\n# Export Aifile\naifile_dict = {\"name\": NAME, \"aifileversion\": 1, \"chain\": llm_chain.dict()}\naifile = json.dumps(aifile_dict, indent=2)\nprint(aifile)\n"}
{"type": "source_file", "path": "backaind/auth.py", "content": "\"\"\"Provide user authentication and registration.\"\"\"\nimport functools\n\nimport click\nfrom flask import (\n    Blueprint,\n    abort,\n    flash,\n    g,\n    redirect,\n    render_template,\n    request,\n    session,\n    url_for,\n)\nfrom sqlalchemy import exc\nfrom werkzeug.security import check_password_hash, generate_password_hash\n\nfrom .extensions import db\nfrom .models import User\n\n\nbp = Blueprint(\"auth\", __name__, url_prefix=\"/auth\")\n\n\n@bp.route(\"/login\", methods=(\"GET\", \"POST\"))\ndef login():\n    \"\"\"Render the login page or login a user.\"\"\"\n    if request.method == \"POST\":\n        username = request.form[\"username\"]\n        password = request.form[\"password\"]\n        user = db.session.query(User).filter_by(username=username).first()\n\n        if user is None or not check_password_hash(user.passhash, password):\n            flash(\"Incorrect username or password.\", \"danger\")\n        else:\n            session.clear()\n            session[\"user_id\"] = user.id\n            return redirect(url_for(\"index\"))\n\n    return render_template(\"auth/login.html\")\n\n\n@bp.route(\"/logout\")\ndef logout():\n    \"\"\"Logout the current user and redirect to index page.\"\"\"\n    session.clear()\n    return redirect(url_for(\"index\"))\n\n\n@bp.before_app_request\ndef load_logged_in_user():\n    \"\"\"Load the current user and add it to the global g instance.\"\"\"\n    user_id = session.get(\"user_id\")\n\n    if user_id is None:\n        g.user = None\n    else:\n        g.user = db.session.get(User, user_id)\n\n\ndef is_password_correct(username: str, password: str):\n    \"\"\"Check if the password for the given user is correct.\"\"\"\n    user = db.session.query(User).filter_by(username=username).first()\n\n    return user is not None and check_password_hash(user.passhash, password)\n\n\ndef set_password(username: str, password: str):\n    \"\"\"Set the (new) password for an user.\"\"\"\n    user = db.session.query(User).filter_by(username=username).one()\n    user.passhash = generate_password_hash(password)\n    db.session.commit()\n\n\ndef login_required(view):\n    \"\"\"\n    Wrap a view to instead redirect to login page if the user is not logged in.\n    For API requests, this does not redirect, but returns a 401 Unauthorized status code.\n    \"\"\"\n\n    @functools.wraps(view)\n    def wrapped_view(**kwargs):\n        if g.get(\"user\") is None:\n            if request.path.startswith(\"/api/\"):\n                abort(401)\n            return redirect(url_for(\"auth.login\"))\n\n        return view(**kwargs)\n\n    return wrapped_view\n\n\n@click.command(\"add-user\")\n@click.option(\"--username\", prompt=\"User name\")\n@click.password_option()\ndef add_user(username, password):\n    \"\"\"Register a new user for the application.\"\"\"\n    try:\n        user = User(username=username, passhash=generate_password_hash(password))\n        db.session.add(user)\n        db.session.commit()\n    except exc.IntegrityError as exception:\n        raise click.ClickException(\n            f\"User {username} is already registered.\"\n        ) from exception\n\n    click.echo(f\"Registration successful. Hello {username}, nice to meet you!\")\n\n\n@click.command(\"set-password\")\n@click.option(\"--username\", prompt=\"User name\")\n@click.password_option()\ndef set_password_command(username, password):\n    \"\"\"Command to set the (new) password for an user.\"\"\"\n    set_password(username, password)\n    click.echo(f\"Successfully set the password for {username}.\")\n\n\ndef init_app(app):\n    \"\"\"Register auth CLI commands with the application instance.\"\"\"\n    app.cli.add_command(add_user)\n    app.cli.add_command(set_password_command)\n"}
{"type": "source_file", "path": "backaind/knowledge.py", "content": "\"\"\"\n    Provide vector store capabilities to save and access 'knowledge'.\n    Currently only Chroma is supported as vector store.\n\"\"\"\nfrom typing import List\nfrom threading import Lock\nimport uuid\n\nimport click\nfrom langchain.docstore.document import Document\nfrom langchain.embeddings.base import Embeddings\nfrom langchain.vectorstores.base import VectorStore\nfrom langchain.vectorstores.chroma import Chroma\n\nfrom .extensions import db\nfrom .models import Knowledge\n\n# pylint: disable=invalid-name\nglobal_knowledge = None\nglobal_knowledge_id = None\n# pylint: enable=invalid-name\nknowledge_lock = Lock()\n\n\nclass KnowledgeConfigError(Exception):\n    \"\"\"Invalid or missing knowledge configuration.\"\"\"\n\n\ndef get_embeddings(embeddings_type: str) -> Embeddings:\n    \"\"\"Return an Embeddings instance for the given embeddings_type.\"\"\"\n    if embeddings_type.lower() == \"huggingface\":\n        # pylint: disable=import-outside-toplevel\n        from langchain.embeddings import HuggingFaceEmbeddings\n\n        return HuggingFaceEmbeddings()\n\n    raise KnowledgeConfigError(f\"Unknown embeddings type: {embeddings_type}\")\n\n\ndef get_knowledge(knowledge_id: int) -> VectorStore:\n    \"\"\"Return a vector store instance to be used for knowledge access.\"\"\"\n    # pylint: disable=global-statement\n    global global_knowledge, global_knowledge_id\n    with knowledge_lock:\n        knowledge = global_knowledge\n        if not knowledge or global_knowledge_id != knowledge_id:\n            knowledge_entry = db.get_or_404(Knowledge, knowledge_id)\n            knowledge = Chroma(\n                persist_directory=knowledge_entry.persist_directory,\n                embedding_function=get_embeddings(knowledge_entry.embeddings),\n            )\n            global_knowledge = knowledge\n            global_knowledge_id = knowledge_id\n    return knowledge\n\n\ndef reset_global_knowledge(knowledge_id=None):\n    \"\"\"\n    Drop the global knowledge instance.\n    If knowledge_id is set, it only drops the global knowledge instance if it matches this ID.\n    \"\"\"\n    # pylint: disable=global-statement\n    global global_knowledge, global_knowledge_id\n    with knowledge_lock:\n        if not knowledge_id or knowledge_id == global_knowledge_id:\n            global_knowledge = None\n            global_knowledge_id = None\n\n\ndef add_to_knowledge(knowledge_id: int, documents: List[Document]):\n    \"\"\"Add documents to the specified knowledge.\"\"\"\n    knowledge = get_knowledge(knowledge_id)\n    knowledge.add_documents(\n        documents, ids=[str(uuid.uuid4()) for _ in range(len(documents))]\n    )\n\n\ndef get_from_knowledge(knowledge_id: int, limit: int, offset: int):\n    \"\"\"Get documents from the specified knowledge.\"\"\"\n    knowledge = get_knowledge(knowledge_id)\n    assert isinstance(\n        knowledge, Chroma\n    ), \"Can only get documents from Chroma vector stores.\"\n    total = knowledge._collection.count()  # pylint: disable=protected-access\n    collection = knowledge.get(limit=limit, offset=offset)\n    return {\n        \"total\": total,\n        \"items\": [\n            {\"id\": id, \"text\": text}\n            for id, text in zip(collection[\"ids\"], collection[\"documents\"])\n        ],\n    }\n\n\ndef delete_from_knowledge(knowledge_id: int, document_ids: List[str]):\n    \"\"\"Delete documents from the specified knowledge.\"\"\"\n    knowledge = get_knowledge(knowledge_id)\n    knowledge.delete(document_ids)\n\n\n@click.command(\"add-knowledge\")\n@click.option(\"--name\", prompt=\"Name\")\n@click.option(\n    \"--embeddings\",\n    prompt=\"Embeddings\",\n    type=click.Choice([\"huggingface\"], case_sensitive=False),\n)\n@click.option(\"--chunk-size\", prompt=\"Chunk size in characters\", type=int, default=500)\n@click.option(\n    \"--persist-directory\", prompt=\"Directory to persist the knowledge database\"\n)\ndef add_knowledge(name, embeddings, chunk_size, persist_directory):\n    \"\"\"Register a new knowledge store or update a knowledge store with the same name.\"\"\"\n    embeddings = embeddings.lower()\n    existing_knowledge = db.session.query(Knowledge).filter_by(name=name).first()\n\n    if existing_knowledge is None:\n        new_knowledge = Knowledge(\n            name=name,\n            embeddings=embeddings,\n            chunk_size=chunk_size,\n            persist_directory=persist_directory,\n        )\n        db.session.add(new_knowledge)\n        db.session.commit()\n        click.echo(f\"Added {name}. Thank you for making me smarter!\")\n    else:\n        existing_knowledge.embeddings = embeddings\n        existing_knowledge.chunk_size = chunk_size\n        existing_knowledge.persist_directory = persist_directory\n        existing_knowledge.name = name\n        db.session.commit()\n        reset_global_knowledge()\n        click.echo(f\"Updated {name}. Thank you for making me smarter!\")\n\n\ndef init_app(app):\n    \"\"\"Register CLI commands with the application instance.\"\"\"\n    app.cli.add_command(add_knowledge)\n"}
{"type": "source_file", "path": "migrations/versions/58ae6bdf9d33_rename_settings_table.py", "content": "\"\"\"Rename settings table\n\nRevision ID: 58ae6bdf9d33\nRevises: 1328ef37e5dc\nCreate Date: 2023-09-05 21:09:36.337574\n\n\"\"\"\nfrom alembic import op\n\n\n# revision identifiers, used by Alembic.\nrevision = \"58ae6bdf9d33\"\ndown_revision = \"1328ef37e5dc\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade():\n    op.rename_table(\"settings\", \"setting\")\n\n\ndef downgrade():\n    op.rename_table(\"setting\", \"settings\")\n"}
{"type": "source_file", "path": "backaind/models.py", "content": "\"\"\"SQLAlchemy models\"\"\"\nfrom .extensions import db\n\n\nclass User(db.Model):\n    \"\"\"User model\"\"\"\n\n    id = db.Column(db.Integer, primary_key=True, autoincrement=True)\n    username = db.Column(db.String, unique=True, nullable=False)\n    passhash = db.Column(db.String, nullable=False)\n\n    settings = db.relationship(\n        \"Setting\", backref=\"user\", lazy=True, cascade=\"all, delete-orphan\"\n    )\n\n\nclass Ai(db.Model):\n    \"\"\"Ai model\"\"\"\n\n    id = db.Column(db.Integer, primary_key=True, autoincrement=True)\n    name = db.Column(db.String, nullable=False)\n    input_keys = db.Column(db.JSON, nullable=False)\n    input_labels = db.Column(db.JSON, nullable=True)\n    chain = db.Column(db.JSON, nullable=False)\n    greeting = db.Column(db.String, nullable=True)\n    is_public = db.Column(db.Boolean, nullable=False, default=False)\n\n    def as_dict(self):\n        \"\"\"Return the model as a dictionary\"\"\"\n        return {\n            \"id\": self.id,\n            \"name\": self.name,\n            \"input_keys\": self.input_keys,\n            \"input_labels\": self.input_labels,\n            \"chain\": self.chain,\n            \"greeting\": self.greeting,\n        }\n\n\nclass Knowledge(db.Model):\n    \"\"\"Knowledge model\"\"\"\n\n    id = db.Column(db.Integer, primary_key=True, autoincrement=True)\n    name = db.Column(db.String, nullable=False)\n    embeddings = db.Column(db.String, nullable=False)\n    chunk_size = db.Column(db.Integer, nullable=False)\n    persist_directory = db.Column(db.String, nullable=False)\n    is_public = db.Column(db.Boolean, nullable=False, default=False)\n\n    def as_dict(self):\n        \"\"\"Return the model as a dictionary\"\"\"\n        return {\n            \"id\": self.id,\n            \"name\": self.name,\n            \"embeddings\": self.embeddings,\n            \"chunk_size\": self.chunk_size,\n            # persist_directory is internal\n        }\n\n\nclass Setting(db.Model):\n    \"\"\"Setting model\"\"\"\n\n    user_id = db.Column(\n        db.Integer,\n        db.ForeignKey(\"user.id\", onupdate=\"CASCADE\", ondelete=\"CASCADE\"),\n        primary_key=True,\n        nullable=False,\n    )\n    domain = db.Column(db.String, primary_key=True, nullable=False)\n    name = db.Column(db.String, primary_key=True, nullable=False)\n    value = db.Column(db.String, nullable=False)\n\n    __table_args__ = (\n        db.UniqueConstraint(\n            \"user_id\", \"domain\", \"name\", name=\"settings_user_domain_name\"\n        ),\n    )\n"}
{"type": "source_file", "path": "backaind/settings.py", "content": "\"\"\"Allow users to see and change their settings.\"\"\"\nfrom flask import Blueprint, request, flash, render_template, g\n\nfrom .auth import (\n    login_required,\n    is_password_correct,\n    set_password,\n)\nfrom .extensions import db\nfrom .models import Setting\n\nbp = Blueprint(\"settings\", __name__, url_prefix=\"/settings\")\n\nEXTERNAL_PROVIDER_ENVVARS = [\n    \"AI21_API_KEY\",\n    \"ALEPH_ALPHA_API_KEY\",\n    \"ANYSCALE_SERVICE_URL\",\n    \"ANYSCALE_SERVICE_ROUTE\",\n    \"ANYSCALE_SERVICE_TOKEN\",\n    \"AVIARY_URL\",\n    \"AVIARY_TOKEN\",\n    \"BANANA_API_KEY\",\n    \"BEAM_CLIENT_ID\",\n    \"BEAM_CLIENT_SECRET\",\n    \"COHERE_API_KEY\",\n    \"DATABRICKS_HOST\",\n    \"DATABRICKS_API_TOKEN\",\n    \"DEEPINFRA_API_TOKEN\",\n    \"FOREFRONTAI_API_KEY\",\n    \"GOOGLE_API_KEY\",\n    \"GOOGLE_APPLICATION_CREDENTIALS\",\n    \"GOOSEAI_API_KEY\",\n    \"HUGGINGFACE_API_KEY\",\n    \"HUGGINGFACEHUB_API_TOKEN\",\n    \"MOSAICML_API_TOKEN\",\n    \"NLPCLOUD_API_KEY\",\n    \"OPENAI_API_KEY\",\n    \"REPLICATE_API_TOKEN\",\n    \"STOCHASTICAI_API_KEY\",\n    \"TEXT_GENERATION_INFERENCE_TOKEN\",\n    \"WRITER_API_KEY\",\n    \"WRITER_ORG_ID\",\n]\n\n\n@bp.route(\"/password\", methods=(\"GET\", \"POST\"))\n@login_required\ndef password():\n    \"\"\"Render the password change page or change the user's password.\"\"\"\n    if request.method == \"POST\":\n        current_password = request.form[\"current-password\"]\n        new_password = request.form[\"new-password\"]\n        new_password_confirmation = request.form[\"new-password-confirmation\"]\n\n        if new_password != new_password_confirmation:\n            flash(\"Password and confirmation do not match.\", \"danger\")\n        elif not is_password_correct(g.user.username, current_password):\n            flash(\"Incorrect current password.\", \"danger\")\n        elif len(new_password) < 10:\n            flash(\"Password must be at least 10 characters long.\", \"danger\")\n        else:\n            set_password(g.user.username, new_password)\n            flash(\"Password changed successfully.\", \"success\")\n\n    return render_template(\"settings/password.html\")\n\n\n@bp.route(\"/external-providers\", methods=(\"GET\", \"POST\"))\n@login_required\ndef external_providers():\n    \"\"\"Render the external providers page or save changed external providers settings.\"\"\"\n    if request.method == \"POST\":\n        for envvar in EXTERNAL_PROVIDER_ENVVARS:\n            setting = (\n                db.session.query(Setting)\n                .filter_by(user_id=g.user.id, domain=\"external-providers\", name=envvar)\n                .first()\n            )\n            if envvar in request.form and request.form[envvar].strip():\n                if setting is None:\n                    setting = Setting(\n                        user_id=g.user.id,\n                        domain=\"external-providers\",\n                        name=envvar,\n                        value=request.form[envvar].strip(),\n                    )\n                    db.session.add(setting)\n                else:\n                    setting.value = request.form[envvar].strip()\n            elif setting is not None:\n                db.session.delete(setting)\n        db.session.commit()\n        flash(\"Settings saved successfully.\", \"success\")\n\n    settings = get_settings(g.user.id)\n    return render_template(\n        \"settings/external_providers.html\",\n        envvars=EXTERNAL_PROVIDER_ENVVARS,\n        settings=settings.get(\"external-providers\", {}),\n    )\n\n\ndef get_settings(user_id: int):\n    \"\"\"Return the settings for a specified user.\"\"\"\n    settings = {}\n    for setting in db.session.query(Setting).filter_by(user_id=user_id):\n        settings.setdefault(setting.domain, {})[setting.name] = setting.value\n    return settings\n"}
{"type": "source_file", "path": "migrations/env.py", "content": "import logging\nfrom logging.config import fileConfig\n\nfrom flask import current_app\n\nfrom alembic import context\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nfileConfig(config.config_file_name)\nlogger = logging.getLogger(\"alembic.env\")\n\n\ndef get_engine():\n    try:\n        # this works with Flask-SQLAlchemy<3 and Alchemical\n        return current_app.extensions[\"migrate\"].db.get_engine()\n    except TypeError:\n        # this works with Flask-SQLAlchemy>=3\n        return current_app.extensions[\"migrate\"].db.engine\n\n\ndef get_engine_url():\n    try:\n        return get_engine().url.render_as_string(hide_password=False).replace(\"%\", \"%%\")\n    except AttributeError:\n        return str(get_engine().url).replace(\"%\", \"%%\")\n\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\nconfig.set_main_option(\"sqlalchemy.url\", get_engine_url())\ntarget_db = current_app.extensions[\"migrate\"].db\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef get_metadata():\n    if hasattr(target_db, \"metadatas\"):\n        return target_db.metadatas[None]\n    return target_db.metadata\n\n\ndef run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(url=url, target_metadata=get_metadata(), literal_binds=True)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n\n    # this callback is used to prevent an auto-migration from being generated\n    # when there are no changes to the schema\n    # reference: http://alembic.zzzcomputing.com/en/latest/cookbook.html\n    def process_revision_directives(context, revision, directives):\n        if getattr(config.cmd_opts, \"autogenerate\", False):\n            script = directives[0]\n            if script.upgrade_ops.is_empty():\n                directives[:] = []\n                logger.info(\"No changes in schema detected.\")\n\n    connectable = get_engine()\n\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=get_metadata(),\n            process_revision_directives=process_revision_directives,\n            **current_app.extensions[\"migrate\"].configure_args\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n"}
{"type": "source_file", "path": "migrations/versions/1328ef37e5dc_initial_table_setup.py", "content": "\"\"\"Initial table setup\n\nRevision ID: 1328ef37e5dc\nRevises: None\nCreate Date: 2023-09-05 20:21:47.676245\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\n\n# revision identifiers, used by Alembic.\nrevision = \"1328ef37e5dc\"\ndown_revision = None\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade():\n    op.create_table(\n        \"ai\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"name\", sa.String(), nullable=False),\n        sa.Column(\"input_keys\", sa.JSON(), nullable=False),\n        sa.Column(\"chain\", sa.JSON(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"knowledge\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"name\", sa.String(), nullable=False),\n        sa.Column(\"embeddings\", sa.String(), nullable=False),\n        sa.Column(\"chunk_size\", sa.Integer(), nullable=False),\n        sa.Column(\"persist_directory\", sa.String(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"user\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"username\", sa.String(), nullable=False),\n        sa.Column(\"passhash\", sa.String(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.UniqueConstraint(\"username\"),\n    )\n    op.create_table(\n        \"settings\",\n        sa.Column(\"user_id\", sa.Integer(), nullable=False),\n        sa.Column(\"domain\", sa.String(), nullable=False),\n        sa.Column(\"name\", sa.String(), nullable=False),\n        sa.Column(\"value\", sa.String(), nullable=False),\n        sa.ForeignKeyConstraint(\n            [\"user_id\"], [\"user.id\"], onupdate=\"CASCADE\", ondelete=\"CASCADE\"\n        ),\n        sa.PrimaryKeyConstraint(\"user_id\", \"domain\", \"name\"),\n        sa.UniqueConstraint(\n            \"user_id\", \"domain\", \"name\", name=\"settings_user_domain_name\"\n        ),\n    )\n\n\ndef downgrade():\n    op.drop_table(\"settings\")\n    op.drop_table(\"user\")\n    op.drop_table(\"knowledge\")\n    op.drop_table(\"ai\")\n"}
{"type": "source_file", "path": "migrations/versions/3dba1ccfa13d_add_public_ais_and_knowledge.py", "content": "\"\"\"Add public AIs and Knowledge\n\nRevision ID: 3dba1ccfa13d\nRevises: 16c3aa6e11aa\nCreate Date: 2023-09-14 13:30:34.551156\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\n\n# revision identifiers, used by Alembic.\nrevision = \"3dba1ccfa13d\"\ndown_revision = \"16c3aa6e11aa\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade():\n    with op.batch_alter_table(\"ai\", schema=None) as batch_op:\n        batch_op.add_column(\n            sa.Column(\n                \"is_public\", sa.Boolean(), nullable=False, server_default=sa.false()\n            )\n        )\n\n    with op.batch_alter_table(\"knowledge\", schema=None) as batch_op:\n        batch_op.add_column(\n            sa.Column(\n                \"is_public\", sa.Boolean(), nullable=False, server_default=sa.false()\n            )\n        )\n\n\ndef downgrade():\n    with op.batch_alter_table(\"knowledge\", schema=None) as batch_op:\n        batch_op.drop_column(\"is_public\")\n\n    with op.batch_alter_table(\"ai\", schema=None) as batch_op:\n        batch_op.drop_column(\"is_public\")\n"}
{"type": "source_file", "path": "migrations/versions/16c3aa6e11aa_add_greeting_and_input_labels_columns.py", "content": "\"\"\"Add greeting and input_labels columns\n\nRevision ID: 16c3aa6e11aa\nRevises: 58ae6bdf9d33\nCreate Date: 2023-09-13 12:08:56.515625\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\n\n# revision identifiers, used by Alembic.\nrevision = \"16c3aa6e11aa\"\ndown_revision = \"58ae6bdf9d33\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade():\n    with op.batch_alter_table(\"ai\", schema=None) as batch_op:\n        batch_op.add_column(sa.Column(\"input_labels\", sa.JSON(), nullable=True))\n        batch_op.add_column(sa.Column(\"greeting\", sa.String(), nullable=True))\n\n\ndef downgrade():\n    with op.batch_alter_table(\"ai\", schema=None) as batch_op:\n        batch_op.drop_column(\"greeting\")\n        batch_op.drop_column(\"input_labels\")\n"}
{"type": "source_file", "path": "backaind/workshop.py", "content": "\"\"\"Workshop is the place to invent, build, edit and work on AIs.\"\"\"\nfrom flask import Blueprint, render_template\nfrom backaind.auth import login_required\n\nbp = Blueprint(\"workshop\", __name__, url_prefix=\"/workshop\")\n\n\n@bp.route(\"/\")\n@bp.route(\"/ai/\")\n@bp.route(\"/ai/<_id>\")\n@login_required\ndef ai(_id=None):\n    \"\"\"Render the AI workshop view.\"\"\"\n    return render_template(\"workshop/ai.html\")\n\n\n@bp.route(\"/knowledge/\")\n@bp.route(\"/knowledge/<_id>\")\n@login_required\ndef knowledge(_id=None):\n    \"\"\"Render the knowledge workshop view.\"\"\"\n    return render_template(\"workshop/knowledge.html\")\n"}
{"type": "source_file", "path": "wsgi.py", "content": "#!/bin/env python\n\"\"\"ownAI WSGI entry point\"\"\"\nfrom backaind import create_app\nfrom backaind.extensions import socketio\n\napp = create_app()\n\nif __name__ == \"__main__\":\n    socketio.run(app)\n"}
{"type": "source_file", "path": "setup.py", "content": "\"\"\"ownAI is an open source platform to run your own AI applications.\"\"\"\nfrom pathlib import Path\nfrom setuptools import find_namespace_packages, setup\n\nsetup(\n    name=\"ownAI\",\n    version=\"0.4.0\",\n    description=\"Run your own AI\",\n    url=\"https://ownai.org\",\n    license=\"MIT\",\n    packages=find_namespace_packages(exclude=[\"tests\", \"tests.*\", \"venv\", \"venv.*\"]),\n    include_package_data=True,\n    install_requires=[\n        \"flask\",\n        \"flask-socketio\",\n        \"Flask-SQLAlchemy\",\n        \"Flask-Migrate\",\n        \"langchain\",\n    ],\n    long_description=(Path(__file__).parent / \"README.md\").read_text(),\n    long_description_content_type=\"text/markdown\",\n)\n"}
