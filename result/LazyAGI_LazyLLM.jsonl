{"repo_info": {"repo_name": "LazyLLM", "repo_owner": "LazyAGI", "repo_url": "https://github.com/LazyAGI/LazyLLM"}}
{"type": "test_file", "path": "tests/advanced_tests/full_test/test_deploy.py", "content": "import os\nimport time\nimport pytest\nimport httpx\nimport random\nfrom functools import wraps\nfrom gradio_client import Client\n\nimport lazyllm\nfrom lazyllm import deploy\nfrom lazyllm.launcher import cleanup\nfrom lazyllm.components.formatter import decode_query_with_filepaths\n\ndef reset_env(func):\n\n    env_vars_to_reset = [\n        \"LAZYLLM_OPENAI_API_KEY\",\n        \"LAZYLLM_KIMI_API_KEY\",\n        \"LAZYLLM_GLM_API_KEY\",\n        \"LAZYLLM_QWEN_API_KEY\",\n        \"LAZYLLM_SENSENOVA_API_KEY\",\n        \"LAZYLLM_SENSENOVA_SECRET_KEY\",\n        \"LAZYLLM_DOUBAO_API_KEY\",\n    ]\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        original_values = {var: os.environ.get(var, None) for var in env_vars_to_reset}\n        for var in env_vars_to_reset:\n            os.environ.pop(var, None)\n            lazyllm.config.refresh(var)\n        result = func(*args, **kwargs)\n        for var, value in original_values.items():\n            if value is None:\n                os.environ.pop(var, None)\n            else:\n                os.environ[var] = value\n                lazyllm.config.refresh(var)\n        return result\n    return wrapper\n\nclass TestDeploy(object):\n\n    def setup_method(self):\n        self.model_path = 'internlm2-chat-7b'\n        self.inputs = ['介绍一下你自己', '李白和李清照是什么关系', '说个笑话吧']\n        self.use_context = False\n        self.stream_output = False\n        self.append_text = False\n        self.webs = []\n        self.clients = []\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        yield\n        while self.clients:\n            client = self.clients.pop()\n            client.close()\n        while self.webs:\n            web = self.webs.pop()\n            web.stop()\n        cleanup()\n\n    def warp_into_web(self, module):\n        client = None\n        for _ in range(5):\n            try:\n                port = random.randint(10000, 30000)\n                web = lazyllm.WebModule(module, port=port)\n                web._work()\n                time.sleep(2)\n            except AssertionError as e:\n                # Port is occupied\n                if 'occupied' in e:\n                    continue\n                else:\n                    raise e\n            try:\n                client = Client(web.url, download_files=web.cach_path)\n                break\n            except httpx.ConnectError:\n                continue\n        assert client, \"Unable to create client\"\n        self.webs.append(web)\n        self.clients.append(client)\n        return web, client\n\n    def test_deploy_lightllm(self):\n        m = lazyllm.TrainableModule(self.model_path, '').deploy_method(deploy.lightllm)\n        m.evalset(self.inputs)\n        m.update_server()\n        m.eval()\n        assert len(m.eval_result) == len(self.inputs)\n\n    def test_deploy_auto(self):\n        m = lazyllm.TrainableModule(self.model_path, '').deploy_method(deploy.AutoDeploy)\n        assert m._deploy_type == lazyllm.deploy.AutoDeploy\n        m.evalset(self.inputs)\n        m.update_server()\n        m.eval()\n        assert m._deploy_type != lazyllm.deploy.AutoDeploy\n        assert len(m.eval_result) == len(self.inputs)\n\n    def test_deploy_auto_without_calling_method(self):\n        m = lazyllm.TrainableModule(self.model_path, '')\n        m.evalset(self.inputs)\n        m.update_server()\n        m.eval()\n        assert len(m.eval_result) == len(self.inputs)\n\n    def test_bark(self):\n        m = lazyllm.TrainableModule('bark')\n        m.update_server()\n        r = m('你好啊，很高兴认识你。')\n        res = decode_query_with_filepaths(r)\n        assert \"files\" in res\n        assert len(res['files']) == 1\n\n    @reset_env\n    def test_AutoModel(self):\n        # No model_name and key\n        chat = lazyllm.AutoModel()\n        assert isinstance(chat, lazyllm.TrainableModule)\n\n        # set framework\n        chat = lazyllm.AutoModel(framework='vllm')\n        assert isinstance(chat, lazyllm.TrainableModule)\n\n        lazyllm.config.add(\"openai_api_key\", str, \"123\", \"OPENAI_API_KEY\")\n\n        # set source\n        with pytest.raises(ValueError, match=\"Either configure both api_key and secret_key, \"\n                           \"or only configure api_key. Other configurations are not supported.\"):\n            chat = lazyllm.AutoModel('sensenova')\n        chat = lazyllm.AutoModel(source='openai')\n        assert isinstance(chat, lazyllm.OnlineChatModule)\n\n        # No model_name, but set key\n        chat = lazyllm.AutoModel()\n        assert isinstance(chat, lazyllm.OnlineChatModule)\n\n        # set model_name and key\n        chat = lazyllm.AutoModel('internlm2-chat-7b')\n        assert isinstance(chat, lazyllm.TrainableModule)\n"}
{"type": "test_file", "path": "tests/advanced_tests/full_test/test_example.py", "content": "import io\nimport os\nimport json\nimport re\nimport time\nimport httpx\nimport pytest\nimport random\nfrom gradio_client import Client\nfrom lazyllm.thirdparty import PIL\n\nimport lazyllm\nfrom lazyllm.launcher import cleanup\nfrom lazyllm.components.formatter import decode_query_with_filepaths\nfrom lazyllm.tools.rag.global_metadata import RAG_DOC_ID, RAG_DOC_PATH\n\n\nclass TestExamples(object):\n\n    def setup_method(self):\n        self.use_context = False\n        self.stream_output = False\n        self.append_text = False\n        self.webs = []\n        self.clients = []\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        yield\n        while self.clients:\n            client = self.clients.pop()\n            client.close()\n        while self.webs:\n            web = self.webs.pop()\n            web.stop()\n        cleanup()\n\n    def warp_into_web(self, module):\n        client = None\n        for _ in range(5):\n            try:\n                port = random.randint(10000, 30000)\n                web = lazyllm.WebModule(module, port=port)\n                web._work()\n                time.sleep(2)\n            except AssertionError as e:\n                # Port is occupied\n                if 'occupied' in e:\n                    continue\n                else:\n                    raise e\n            try:\n                client = Client(web.url, download_files=web.cach_path)\n                break\n            except httpx.ConnectError:\n                continue\n        assert client, \"Unable to create client\"\n        self.webs.append(web)\n        self.clients.append(client)\n        return web, client\n\n    def test_chat(self):\n        from examples.chatbot import chat\n        chat.start()\n        query = \"请原样英文输出：Hello world.\"\n        res = chat(query)\n        assert res == 'Hello world.'\n\n        # test chat warpped in web\n        _, client = self.warp_into_web(chat)\n        chat_history = [[query, None]]\n        ans = client.predict(self.use_context,\n                             chat_history,\n                             self.stream_output,\n                             self.append_text,\n                             api_name=\"/_respond_stream\")\n        assert ans[0][-1][-1] == 'Hello world.'\n\n    def test_story(self):\n        from examples.story import ppl\n        story = lazyllm.ActionModule(ppl)\n        story.start()\n        query = \"我的妈妈\"\n        res = story(query)\n        assert type(res) is str\n        assert len(res) >= 1024\n\n        # test story warpped in web\n        _, client = self.warp_into_web(story)\n        chat_history = [[query, None]]\n        ans = client.predict(self.use_context,\n                             chat_history,\n                             self.stream_output,\n                             self.append_text,\n                             api_name=\"/_respond_stream\")\n        res = ans[0][-1][-1]\n        assert type(res) is str\n        assert len(res) >= 1024\n\n    def test_rag(self):\n        from examples.rag import ppl\n        rag = lazyllm.ActionModule(ppl)\n        rag.start()\n        query = \"何为天道？\"\n        res = rag(query)\n        assert type(res) is str\n        assert \"天道\" in res\n        assert len(res) >= 16\n\n        # test rag warpped in web\n        _, client = self.warp_into_web(rag)\n        chat_history = [[query, None]]\n        ans = client.predict(self.use_context,\n                             chat_history,\n                             self.stream_output,\n                             self.append_text,\n                             api_name=\"/_respond_stream\")\n        res = ans[0][-1][-1]\n        assert type(res) is str\n        assert \"天道\" in res\n        assert len(res) >= 16\n\n    def test_painting(self):\n        from examples.painting import ppl\n        painting = lazyllm.ActionModule(ppl)\n        painting.start()\n        query = \"画只可爱的小猪\"\n        r = painting(query)\n        res = decode_query_with_filepaths(r)\n        assert type(res) is dict\n        assert \"files\" in res\n        assert len(res['files']) == 1\n        image = PIL.Image.open(res['files'][0])\n        assert image.size == (1024, 1024)\n\n        # test painting warpped in web\n        _, client = self.warp_into_web(painting)\n        chat_history = [[query, None]]\n        ans = client.predict(self.use_context,\n                             chat_history,\n                             self.stream_output,\n                             self.append_text,\n                             api_name=\"/_respond_stream\")\n        image_path = ans[0][0][-1]['value']\n        assert os.path.isfile(image_path)\n\n    def test_rag_map_store_with_milvus_index(self):\n        from examples.rag_map_store_with_milvus_index import run as rag_run\n        res = rag_run('何为天道？')\n        assert type(res) is str\n        assert \"天道\" in res\n        assert len(res) >= 16\n\nclass TestRagFilter(object):\n    def setup_class(self):\n        from examples.rag_milvus_store import ppl, documents, tmp_dir\n        self.tmp_dir = tmp_dir\n        self.documents = documents\n        self.rag = lazyllm.ActionModule(ppl)\n        self.rag.start()\n        url_pattern = r'(http://\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:\\d+)'\n        self.doc_server_addr = re.findall(url_pattern, documents.manager.url)[0]\n\n    def test_upload_and_filter(self):\n        files = [('files', ('test1.txt', io.BytesIO(b\"John's house is in Beijing\"), 'text/palin')),\n                 ('files', ('test2.txt', io.BytesIO(b\"John's house is in Shanghai\"), 'text/plain'))]\n        metadatas = [{\"comment\": \"comment1\"}, {\"signature\": \"signature2\"}]\n\n        params = dict(override='true', metadatas=json.dumps(metadatas))\n\n        url = f'{self.doc_server_addr}/upload_files'\n        response = httpx.post(url, params=params, files=files, timeout=10)\n        assert response.status_code == 200 and response.json().get('code') == 200, response.json()\n\n        time.sleep(30)  # waiting for worker thread to update newly uploaded files\n\n        res = self.rag(\"Where is John's house?\", filters={'comment': ['comment1']})\n        assert 'Beijing' in res and 'Shanghai' not in res\n\n        res = self.rag(\"Where is John's house?\", filters={'signature': ['signature2']})\n        assert 'Shanghai' in res and 'Beijing' not in res\n\n        store = self.documents._impl.store\n        nodes = store.get_nodes('block')\n        for node in nodes:\n            if node.global_metadata[RAG_DOC_PATH].endswith('test1.txt'):\n                test1_docid = node.global_metadata[RAG_DOC_ID]\n            elif node.global_metadata[RAG_DOC_PATH].endswith('test2.txt'):\n                test2_docid = node.global_metadata[RAG_DOC_ID]\n        assert test1_docid and test2_docid\n\n        res = self.rag(\"Where is John's house?\", filters={RAG_DOC_ID: [test1_docid]})\n        assert 'Beijing' in res and 'Shanghai' not in res\n\n        res = self.rag(\"Where is John's house?\", filters={RAG_DOC_ID: [test2_docid]})\n        assert 'Shanghai' in res and 'Beijing' not in res\n"}
{"type": "test_file", "path": "tests/advanced_tests/full_test/test_finetune.py", "content": "import os\n\nfrom lazyllm import finetune, launchers\n\nclass TestFinetune(object):\n\n    def test_finetune_alpacalora(self):\n        # test instantiation\n        f = finetune.alpacalora(base_model='internlm2-chat-7b', target_path='')\n        assert f.base_model == 'internlm2-chat-7b'\n\n    def test_finetune_collie(self):\n        # test instantiation\n        f = finetune.collie(base_model='internlm2-chat-7b', target_path='')\n        assert f.base_model == 'internlm2-chat-7b'\n\n    def test_auto_finetune(self):\n        # test instantiation\n        m = finetune.auto('internlm2-chat-7b', '', launcher=launchers.sco(ngpus=1))\n        assert isinstance(m.launcher, launchers.sco)\n        assert os.path.exists(m.base_model)\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_calculator.py", "content": "from lazyllm.tools.tools import Calculator\n\nclass TestCalculator(object):\n    def setup_method(self):\n        self._calc = Calculator()\n\n    def test_calculator(self):\n        res = self._calc('(12*13)/6')\n        assert res == 26\n\n    def test_invalid_import(self):\n        try:\n            value = 123\n            self._calc('import(os)')\n            value = 456\n        except Exception:\n            value = 789\n        finally:\n            assert value == 789\n\n    def test_math_func(self):\n        res = self._calc('fabs(-5)')\n        assert res == 5\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_engine.py", "content": "import os\nimport time\nimport pytest\n\nimport lazyllm\nfrom lazyllm.engine import LightEngine\n\n\nclass TestEngine(object):\n    # This test requires 4 GPUs and takes about 4 minutes to execute, skip this test to save time.\n    def _test_vqa(self):\n        resource = [dict(id='0', kind='web', name='web', args=dict(port=None, title='多模态聊天机器人', history=[], audio=True))]\n        node = [dict(id='1', kind='VQA', name='vqa', args=dict(base_model='Mini-InternVL-Chat-2B-V1-5'))]\n        edge = [dict(iid=\"__start__\", oid=\"1\"), dict(iid=\"1\", oid=\"__end__\")]\n        engine = LightEngine()\n        engine.start(node, edge, resource)\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        yield\n        LightEngine().reset()\n        lazyllm.FileSystemQueue().dequeue()\n        lazyllm.FileSystemQueue(klass=\"lazy_trace\").dequeue()\n\n    def test_http(self):\n        nodes = [\n            dict(\n                id=\"1\",\n                kind=\"HTTP\",\n                name=\"visit_sensetime\",\n                args=dict(\n                    method=\"GET\",\n                    url=\"https://www.sensetime.com/cn\",\n                    api_key=None,\n                    headers=None,\n                    params=None,\n                    body=None,\n                )\n            )\n        ]\n        edges = [dict(iid=\"__start__\", oid=\"1\"), dict(iid=\"1\", oid=\"__end__\")]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        ret = engine.run(gid)\n        assert '商汤科技' in ret['content']\n\n    def test_multimedia(self):\n        painter_prompt = 'Now you are a master of drawing prompts, capable of converting any Chinese content entered by the user into English drawing prompts. In this task, you need to convert any input content into English drawing prompts, and you can enrich and expand the prompt content.'  # noqa E501\n        musician_prompt = 'Now you are a master of music composition prompts, capable of converting any Chinese content entered by the user into English music composition prompts. In this task, you need to convert any input content into English music composition prompts, and you can enrich and expand the prompt content.'  # noqa E501\n        translator_prompt = 'Now you are a master of translation prompts, capable of converting any Chinese content entered by the user into English translation prompts. In this task, you need to convert any input content into English translation prompts, and you can enrich and expand the prompt content.'  # noqa E501\n\n        resources = [dict(id='llm', kind='LocalLLM', name='base', args=dict(base_model='internlm2-chat-7b')),\n                     dict(id='file-resource', kind='File', name='file', args=dict(id='file-resource')),\n                     dict(id='vqa', kind='VQA', name='vqa', args=dict(base_model='Mini-InternVL-Chat-2B-V1-5')),\n                     dict(id='web', kind='web', name='web', args=dict(port=None, title='多模态聊天机器人', audio=True))]\n\n        nodes1 = [\n            dict(id='2', kind='SharedLLM', name='draw_prompt', args=dict(llm='llm', prompt=painter_prompt)),\n            dict(id='3', kind='SD', name='sd', args=dict(base_model='stable-diffusion-3-medium')),\n            dict(id='5', kind='SharedLLM', name='vqa1', args=dict(llm='vqa')),\n            dict(id='6', kind='JoinFormatter', name='merge_sd_vqa2', args=dict(type='file')),\n        ]\n        edges1 = [\n            dict(iid='__start__', oid='2'), dict(iid='6', oid='__end__'), dict(iid=\"2\", oid=\"3\"),\n            dict(constant='描述图片', oid=\"5\"), dict(iid=\"3\", oid=\"5\"), dict(iid=\"3\", oid=\"6\"), dict(iid=\"5\", oid=\"6\"),\n        ]\n\n        nodes = [dict(id='7', kind='STT', name='stt', args=dict(base_model='SenseVoiceSmall')),\n                 dict(id='8', kind='Intention', name='intent', args=dict(base_model='llm', nodes={\n                     'Drawing': dict(id='9', kind='SubGraph', name='draw_vqa', args=dict(nodes=nodes1, edges=edges1)),\n                     'Translate': dict(id='10', kind='SharedLLM', name='translate_prompt',\n                                       args=dict(llm='llm', prompt=translator_prompt)),\n                     'Generate Music': [dict(id='11', kind='SharedLLM', name='translate',\n                                             args=dict(llm='llm', prompt=musician_prompt)),\n                                        dict(id='12', kind='TTS', name='music',\n                                             args=dict(base_model='musicgen-small'))],\n                     'Image Question Answering': dict(id='13', kind='SharedLLM', name='vqa2',\n                                                      args=dict(llm='vqa', file_resource_id='file-resource')),\n                     'Chat': dict(id='14', kind='SharedLLM', name='chat', args=dict(llm='llm'))}))]\n        edges = [dict(iid=\"__start__\", oid=\"7\"), dict(iid=\"7\", oid=\"8\"), dict(iid=\"8\", oid=\"__end__\")]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources)\n\n        r = engine.run(gid, '画个猪')\n        assert '.png' in r\n\n        r = engine.run(gid, '翻译：我喜欢敲代码。')\n        assert 'code' in r or 'coding' in r\n\n        r = engine.run(gid, \"\", _lazyllm_files=os.path.join(lazyllm.config['data_path'], 'ci_data/draw_pig.mp3'))\n        assert '.png' in r\n\n        r = engine.run(gid, \"这张图片描述的是什么？\", _lazyllm_files=os.path.join(lazyllm.config['data_path'], 'ci_data/ji.jpg'))\n        assert '鸡' in r or 'chicken' in r\n\n        r = engine.run(gid, \"这张图片描述的是什么？\",\n                       _file_resources={'file-resource': os.path.join(lazyllm.config['data_path'], 'ci_data/ji.jpg')})\n        assert '鸡' in r or 'chicken' in r\n\n        r = engine.run(gid, '你好，很高兴认识你')\n        assert '你好' in r\n\n        r = engine.run(gid, '生成音乐，长笛独奏，大自然之声。')\n        assert '.wav' in r\n\n    def test_stream_and_hostory(self):\n        resources = [dict(id='0', kind='LocalLLM', name='base', args=dict(base_model='internlm2-chat-7b'))]\n        builtin_history = [['水的沸点是多少？', '您好，我的答案是：水的沸点在标准大气压下是100摄氏度。'],\n                           ['世界上最大的动物是什么？', '您好，我的答案是：蓝鲸是世界上最大的动物。'],\n                           ['人一天需要喝多少水？', '您好，我的答案是：一般建议每天喝8杯水，大约2升。']]\n        nodes = [dict(id='1', kind='SharedLLM', name='m1', args=dict(llm='0', stream=True, prompt=dict(\n                      system='请将我的问题翻译成中文。请注意，请直接输出翻译后的问题，不要反问和发挥',\n                      user='问题: {query} \\n, 翻译:'))),\n                 dict(id='2', kind='SharedLLM', name='m2',\n                      args=dict(llm='0', stream=True,\n                                prompt=dict(system='请参考历史对话，回答问题，并保持格式不变。', user='{query}'))),\n                 dict(id='3', kind='JoinFormatter', name='join', args=dict(type='to_dict', names=['query', 'answer'])),\n                 dict(id='4', kind='SharedLLM', stream=False, name='m3',\n                      args=dict(llm='0', history=builtin_history,\n                                prompt=dict(system='你是一个问答机器人，会根据用户的问题作出回答。',\n                                            user=('请结合历史对话和本轮的问题，总结我们的全部对话，无论是否相关。'\n                                                  '本轮情况如下:\\n {query}, 回答: {answer}'))))]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges=[['__start__', '1'], ['1', '2'], ['1', '3'], ['2', '3'], ['3', '4'],\n                                         ['4', '__end__']], resources=resources, _history_ids=['2', '4'])\n        history = [['雨后为什么会有彩虹？', '您好，我的答案是：雨后阳光通过水滴发生折射和反射形成了彩虹。'],\n                   ['月亮会发光吗？', '您好，我的答案是：月亮本身不会发光，它反射太阳光。'],\n                   ['一年有多少天', '您好，我的答案是：一年有365天，闰年有366天。']]\n\n        stream_result = ''\n        with lazyllm.ThreadPoolExecutor(1) as executor:\n            future = executor.submit(engine.run, gid, 'How many hours are there in a day?', _lazyllm_history=history)\n            while True:\n                if value := lazyllm.FileSystemQueue().dequeue():\n                    stream_result += f\"{''.join(value)}\"\n                elif future.done():\n                    break\n            result = future.result()\n            assert '一天' in stream_result and '小时' in stream_result\n            assert '您好，我的答案是' in stream_result and '24' in stream_result\n            assert ('蓝鲸' in result or '动物' in result) and '水' in result\n\n    def test_engine_train_serve(self):\n        train_config = {\n            'finetune_model_name': 'my_super_model',\n            'base_model': 'qwen1.5-0.5b-chat',\n            'training_type': 'SFT',\n            'finetuning_type': 'LoRA',\n            'data_path': 'alpaca/alpaca_data_zh_128.json',\n            'val_size': 0.1,\n            'num_epochs': 1,\n            'learning_rate': 0.1,\n            'lr_scheduler_type': 'cosine',\n            'batch_size': 32,\n            'cutoff_len': 1024,\n            'lora_r': 8,\n            'lora_alpha': 32,\n            'lora_rate': 0.1,\n        }\n        engine = LightEngine()\n        engine.launch_localllm_train_service()\n\n        token = 'test'\n        job_id = None\n\n        # Launch train\n        res = engine.local_model_train(train_config, token=token)\n        job_id = res[0]\n        assert len(job_id) > 0\n        status = res[1]\n\n        n = 0\n        while status != 'Running':\n            time.sleep(1)\n            status = engine.local_model_get_training_status(token, job_id)\n            n += 1\n            assert n < 300, 'Launch training timeout.'\n\n        # After Launch, training 20s\n        time.sleep(20)\n\n        res = engine.local_model_cancel_training(token, job_id)\n        assert isinstance(res, bool)\n\n        res = engine.local_model_get_training_status(token, job_id)\n        assert res == 'Cancelled'\n\n        res = engine.local_model_get_training_log(token, job_id)\n        assert os.path.exists(res)\n\n        res = engine.local_model_get_all_trained_models(token)\n        assert len(res[0]) == 3\n\n        res = engine.local_model_get_training_cost(token, job_id)\n        assert res > 15\n\n    def test_engine_infer_server(self):\n        token = '123'\n        engine = LightEngine()\n        engine.launch_localllm_infer_service()\n        jobid, status = engine.deploy_model(token, 'internlm2-chat-7b')\n        engine.infer_client.wait_ready(token, jobid)\n        r = engine.get_infra_handle(token, jobid)\n        assert isinstance(r, lazyllm.TrainableModule) and r._impl._get_deploy_tasks.flag\n        assert '你好' in r('请重复下面一句话：你好')\n\n        nodes = [dict(id='0', kind='SharedLLM', name='m1', args=dict(\n            llm=jobid, local=False, token=token, stream=True, prompt=dict(\n                system='请根据输入帮我计算，不要反问和发挥', user='输入: {query} \\n, 答案:')))]\n        gid = engine.start(nodes)\n        assert '2' in engine.run(gid, '1 + 1 = ?')\n\n        engine.stop(gid)\n        nodes = [dict(id='1', kind='OnlineLLM', name='m1', args=dict(\n            source='lazyllm', base_model=jobid, token=token, stream=True, prompt=dict(\n                system='请根据输入帮我计算，不要反问和发挥', user='输入: {query} \\n, 答案:')))]\n        gid = engine.start(nodes)\n        assert '2' in engine.run(gid, '1 + 1 = ?')\n\n    def test_engine_infer_server_vqa(self):\n        token = '123'\n        engine = LightEngine()\n        engine.launch_localllm_infer_service()\n        jobid, _ = engine.deploy_model(token, 'Mini-InternVL-Chat-2B-V1-5')\n        engine.infer_client.wait_ready(token, jobid)\n        r = engine.get_infra_handle(token, jobid)\n        assert isinstance(r, lazyllm.TrainableModule) and r._impl._get_deploy_tasks.flag\n        assert '你好' in r('请重复下面一句话：你好')\n\n        nodes = [dict(id='0', kind='SharedLLM', name='vqa', args=dict(llm=jobid, local=False, token=token, stream=True))]\n        gid = engine.start(nodes)\n\n        r = engine.run(gid, \"这张图片描述的是什么？\", _lazyllm_files=os.path.join(lazyllm.config['data_path'], 'ci_data/ji.jpg'))\n        assert '鸡' in r or 'chicken' in r\n\n    def test_engine_infer_server_tts(self):\n        token = '123'\n        engine = LightEngine()\n        engine.launch_localllm_infer_service()\n        jobid, _ = engine.deploy_model(token, 'ChatTTS')\n        engine.infer_client.wait_ready(token, jobid)\n        r = engine.get_infra_handle(token, jobid)\n        assert isinstance(r, lazyllm.TrainableModule) and r._impl._get_deploy_tasks.flag\n        assert '.wav' in r('你好啊，很高兴认识你。')\n\n        nodes = [dict(id='0', kind='SharedLLM', name='chattts', args=dict(\n            llm=jobid, local=False, token=token, stream=False))]\n        gid = engine.start(nodes)\n\n        r = engine.run(gid, \"这张图片描述的是什么？\")\n        assert '.wav' in r\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_finetune.py", "content": "import os\nimport shutil\nimport pytest\n\nimport lazyllm\nfrom lazyllm import finetune\nfrom lazyllm.launcher import cleanup\n\nclass TestFinetune(object):\n\n    def setup_method(self):\n        self.data = 'alpaca/alpaca_data_zh_128.json'\n        self.model_path = 'qwen1.5-0.5b-chat'\n        self.save_path = os.path.join(os.getcwd(), '.temp')\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        if not os.path.exists(self.save_path):\n            os.makedirs(self.save_path)\n        yield\n        if os.path.exists(self.save_path):\n            shutil.rmtree(self.save_path)\n        cleanup()\n\n    def has_bin_file(self, path):\n        if not os.path.exists(path):\n            raise RuntimeError(f\"Cannot find model path: {path}\")\n        for filename in os.listdir(path):\n            if filename.endswith('.bin') or filename.endswith('.safetensors'):\n                return True\n        return False\n\n    def test_finetune_llamafactory(self):\n        ppl = lazyllm.pipeline(\n            lambda: 'alpaca/alpaca_data_zh_128.json',\n            finetune.llamafactory(\n                base_model='qwen1.5-0.5b-chat',\n                target_path=self.save_path,\n            )\n        )\n        ppl()\n        assert self.has_bin_file(os.path.join(self.save_path, 'lazyllm_lora'))\n        assert self.has_bin_file(os.path.join(self.save_path, 'lazyllm_merge'))\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_http_tool.py", "content": "from lazyllm.tools import HttpTool\n\nclass TestHttpTool(object):\n    def test_forward(self):\n        code_str = \"def identity(content): return content\"\n        tool = HttpTool(method='GET', url='http://www.baidu.com/', code_str=code_str)\n        ret = tool()\n        assert '百度' in ret['content']\n\n    def test_without_args(self):\n        tool = HttpTool()\n        assert tool() is None\n\n    def test_no_url(self):\n        code_str = \"def echo(s): return s\"\n        tool = HttpTool(code_str=code_str)\n        content = \"hello, world!\"\n        assert tool(content) == content\n\n    def test_math(self):\n        code_str = \"def exp(v, n): return v ** n\"\n        tool = HttpTool(code_str=code_str)\n        assert tool(v=10, n=2) == 100\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_intent_classifier.py", "content": "from lazyllm.tools import IntentClassifier\nimport lazyllm\nfrom lazyllm.launcher import cleanup\n\n\nclass TestIntentClassifier(object):\n    @classmethod\n    def setup_class(cls):\n        cls._llm = lazyllm.TrainableModule('internlm2-chat-7b')\n\n    @classmethod\n    def teardown_class(cls):\n        cleanup()\n\n    def test_intent_classifier(self):\n        intent_list = [\"Chat\", \"Financial Knowledge Q&A\", \"Employee Information Query\", \"Weather Query\"]\n        ic = IntentClassifier(self._llm, intent_list)\n        ic.start()\n        assert ic('What is the weather today') == 'Weather Query'\n        assert ic('Who are you') == 'Chat'\n        assert ic('What is the difference between stocks and funds') == 'Financial Knowledge Q&A'\n        assert ic('Check the work location of Macro in the Technology Department') == 'Employee Information Query'\n\n    def test_intent_classifier_example(self):\n        intent_list = [\"Chat\", \"Financial Knowledge Q&A\", \"Employee Information Query\", \"Weather Query\"]\n        ic = IntentClassifier(self._llm, intent_list, examples=[\n            ['Who are you', 'Chat'], ['What is the weather today', 'Weather Query']])\n        ic.start()\n        assert ic('What is the weather today') == 'Weather Query'\n        assert ic('Who are you') == 'Chat'\n        assert ic('What is the difference between stocks and funds') == 'Financial Knowledge Q&A'\n        assert ic('Check the work location of Macro in the Technology Department') == 'Employee Information Query'\n\n    def test_intent_classifier_prompt_and_constrain(self):\n        intent_list = [\"Chat\", \"Image Question and Answer\", \"Music\", \"Weather Query\"]\n        prompt = ('If the input contains attachments, the intent is determined with the highest priority based on the '\n                  'suffix type of the attachments: If it is an image suffix such as .jpg, .png, etc., then the output '\n                  'is: Image Question and Answer. If the audio suffix is .mp3, .wav, etc., the output is: Music')\n        examples = [['Hello world. <attachments>hello.jpg</attachments>', 'Image Question and Answer'],\n                    ['Happy lazyllm. <attachments>hello.wav</attachments>', 'Music']]\n        attention = ('Intent is determined with the highest priority based on the suffix type of the attachments '\n                     'provideded by <attachments>')\n        ic = IntentClassifier(self._llm, intent_list, prompt=prompt, attention=attention, examples=examples,\n                              constrain='intents outside the given intent list is not allowed')\n        ic.start()\n        assert ic('What is the weather today') == 'Weather Query'\n        assert ic('Who are you?') == 'Chat'\n        assert ic('Who are you picture<attachments>who.png</attachments>') == 'Image Question and Answer'\n        assert ic('Song of weather <attachments>weather.mp3</attachments>') == 'Music'\n\n    def test_intent_classifier_enter(self):\n        with IntentClassifier(self._llm) as ic:\n            ic.case['Weather Query', lambda x: '38.5°C']\n            ic.case['Chat', lambda x: 'permission denied']\n            ic.case['Financial Knowledge Q&A', lambda x: 'Calling Financial RAG']\n            ic.case['Employee Information Query', lambda x: 'Beijing']\n\n        ic.start()\n        assert ic('What is the weather today') == '38.5°C'\n        assert ic('Who are you') == 'permission denied'\n        assert ic('What is the difference between stocks and funds') == 'Calling Financial RAG'\n        assert ic('Check the work location of Macro in the Technology Department') == 'Beijing'\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_llm_parser.py", "content": "import unittest\nfrom unittest.mock import MagicMock\nfrom lazyllm import LLMParser, TrainableModule\nfrom lazyllm.launcher import cleanup\nfrom lazyllm.tools.rag import DocNode\n\n\nclass TestLLMParser(unittest.TestCase):\n    @classmethod\n    def setup_class(cls):\n        cls.llm = TrainableModule(\"internlm2-chat-7b\").start()\n        cls.mock_node = MagicMock()\n        cls.mock_node.get_text.return_value = (\n            \"Hello, I am an AI robot developed by SenseTime, named LazyLLM. \"\n            \"My mission is to assist you in building the most powerful large-scale model applications with minimal cost.\"\n        )\n\n        cls.summary_parser = LLMParser(cls.llm, language=\"en\", task_type=\"summary\")\n        cls.keywords_parser = LLMParser(cls.llm, language=\"en\", task_type=\"keywords\")\n        cls.qa_parser = LLMParser(cls.llm, language=\"en\", task_type=\"qa\")\n\n    @classmethod\n    def teardown_class(cls):\n        cleanup()\n\n    def test_summary_transform(self):\n        result = self.summary_parser.transform(self.mock_node)\n        assert isinstance(result, list)\n        assert isinstance(result[0], str)\n        assert len(result[0]) < 150\n        assert \"LazyLLM\" in result[0]\n\n    def test_keywords_transform(self):\n        result = self.keywords_parser.transform(self.mock_node)\n        assert isinstance(result, list)\n        assert 1 < len(result) < 10\n        assert isinstance(result[0], str)\n        assert len(result[0]) < 20\n        assert \"LazyLLM\" in result\n\n    def test_qa_transform(self):\n        result = self.qa_parser.transform(self.mock_node)\n        assert isinstance(result, list)\n        assert isinstance(result[0], DocNode)\n        text, content = result[0].text, result[0].get_content()\n        assert len(text) < len(content) and text in content\n        assert 'query:' in content and 'answer' in content\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_mongodb_manager.py", "content": "import unittest\nfrom lazyllm.tools import MongoDBManager, DBStatus, SqlCall\nimport lazyllm\nimport datetime\nimport re\nimport os\nimport uuid\n\nUUID_HEX = str(uuid.uuid4().hex)\nCURRENT_DAY = datetime.datetime.now().strftime(\"%Y%m%d\")\n\n\nclass MongoDBEgsData:\n    COLLECTION_NAME = f\"america_{CURRENT_DAY}_{UUID_HEX}\"\n    COLLECTION_SCHEMA_TYPE = {\n        \"_id\": \"string\",\n        \"city\": \"string\",\n        \"state\": \"string\",\n        \"pop\": \"int\",\n        \"loc\": {\"type\": \"string\", \"coordinates\": \"array of float\"},\n    }\n    COLLECTION_SCHEMA_DESC = {\n        \"city\": \"城市名\",\n        \"state\": \"两个字母的州名缩写\",\n        \"pop\": \"人口数量\",\n        \"loc\": \"城市的经纬度\",\n    }\n\n    COLLECTION_DATA = [\n        {\n            \"city\": \"New York\",\n            \"state\": \"NY\",\n            \"pop\": 8419600,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-74.0060, 40.7128]},\n        },\n        {\n            \"city\": \"Los Angeles\",\n            \"state\": \"CA\",\n            \"pop\": 3980400,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-118.2437, 34.0522]},\n        },\n        {\n            \"city\": \"Chicago\",\n            \"state\": \"IL\",\n            \"pop\": 2716000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-87.6298, 41.8781]},\n        },\n        {\n            \"city\": \"Houston\",\n            \"state\": \"TX\",\n            \"pop\": 2328000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-95.3698, 29.7604]},\n        },\n        {\n            \"city\": \"Phoenix\",\n            \"state\": \"AZ\",\n            \"pop\": 1690000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-112.0740, 33.4484]},\n        },\n        {\n            \"city\": \"Philadelphia\",\n            \"state\": \"PA\",\n            \"pop\": 1584200,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-75.1652, 39.9526]},\n        },\n        {\n            \"city\": \"San Antonio\",\n            \"state\": \"TX\",\n            \"pop\": 1547000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-98.4936, 29.4241]},\n        },\n        {\n            \"city\": \"San Diego\",\n            \"state\": \"CA\",\n            \"pop\": 1423800,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-117.1611, 32.7157]},\n        },\n        {\"city\": \"Dallas\", \"state\": \"TX\", \"pop\": 1343000, \"loc\": {\"type\": \"Point\", \"coordinates\": [-96.7970, 32.7767]}},\n        {\n            \"city\": \"San Jose\",\n            \"state\": \"CA\",\n            \"pop\": 1028000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-121.8863, 37.3382]},\n        },\n    ]\n\n\nclass TestMongoDBManager(unittest.TestCase):\n    @classmethod\n    def clean_obsolete_tables(cls, mongodb_manager: MongoDBManager):\n        today = datetime.datetime.now()\n        pattern = r\"^(?:america)_(\\d{8})_(\\w+)\"\n        OBSOLETE_DAYS = 2\n        with mongodb_manager.get_client() as client:\n            db = client[mongodb_manager.db_name]\n            existing_collections = db.list_collection_names()\n            for collection_name in existing_collections:\n                match = re.match(pattern, collection_name)\n                if not match:\n                    continue\n                table_create_date = datetime.datetime.strptime(match.group(1), \"%Y%m%d\")\n                delta = (today - table_create_date).days\n                if delta >= OBSOLETE_DAYS:\n                    db.drop_collection(collection_name)\n\n    @classmethod\n    def setUpClass(cls):\n        conn_url = os.environ.get(\"LAZYLLM_MongoDB_URL\", None)\n        assert conn_url is not None\n        pattern = r\"mongodb://(?P<username>[^:]+):(?P<password>[^@]+)@(?P<host>[^:]+):(?P<port>\\d+)/(?P<database>.+)\"\n        match = re.search(pattern, conn_url)\n        assert match is not None\n        username = match.group(\"username\")\n        password = match.group(\"password\")\n        host = match.group(\"host\")\n        port = match.group(\"port\")\n        database = match.group(\"database\")\n\n        cls.mongodb_manager = MongoDBManager(username, password, host, port, database, MongoDBEgsData.COLLECTION_NAME)\n        cls.clean_obsolete_tables(cls.mongodb_manager)\n        with cls.mongodb_manager.get_client() as client:\n            collection = client[cls.mongodb_manager.db_name][cls.mongodb_manager.collection_name]\n            collection.delete_many({})\n            collection.insert_many(MongoDBEgsData.COLLECTION_DATA)\n        cls.mongodb_manager.set_desc(\n            {\n                \"summary\": \"美国各个城市的人口情况\",\n                \"schema_type\": MongoDBEgsData.COLLECTION_SCHEMA_TYPE,\n                \"schema_desc\": MongoDBEgsData.COLLECTION_SCHEMA_DESC,\n            }\n        )\n\n        # Recommend to use sensenova, gpt-4o, qwen online model\n        sql_llm = lazyllm.OnlineChatModule(source=\"sensenova\")\n        cls.sql_call: SqlCall = SqlCall(sql_llm, cls.mongodb_manager, use_llm_for_sql_result=True)\n\n    @classmethod\n    def tearDownClass(cls):\n        # restore to clean database\n        with cls.mongodb_manager.get_client() as client:\n            collection = client[cls.mongodb_manager.db_name][cls.mongodb_manager.collection_name]\n            collection.drop()\n\n    def test_manager_status(self):\n        db_result = self.mongodb_manager.check_connection()\n        assert db_result.status == DBStatus.SUCCESS, db_result.detail\n\n    def test_manager_table_delete_insert_query(self):\n        # delete all documents\n        with self.mongodb_manager.get_client() as client:\n            collection = client[self.mongodb_manager.db_name][self.mongodb_manager.collection_name]\n            collection.delete_many({})\n            results = list(collection.find({}))\n            assert len(results) == 0\n\n            # insert one document\n            collection.insert_one(MongoDBEgsData.COLLECTION_DATA[0])\n            # insert many documents\n            collection.insert_many(MongoDBEgsData.COLLECTION_DATA[1:])\n\n            results = list(collection.find({}))\n            assert len(results) == len(MongoDBEgsData.COLLECTION_DATA)\n\n    def test_select(self):\n        with self.mongodb_manager.get_client() as client:\n            collection = client[self.mongodb_manager.db_name][self.mongodb_manager.collection_name]\n            results = list(collection.find({\"state\": \"TX\"}, projection={\"city\": True}))\n            match_count = sum([ele[\"state\"] == \"TX\" for ele in MongoDBEgsData.COLLECTION_DATA])\n            assert len(results) == match_count\n\n    def test_aggregate(self):\n        with self.mongodb_manager.get_client() as client:\n            collection = client[self.mongodb_manager.db_name][self.mongodb_manager.collection_name]\n            results = list(collection.aggregate([{'$group': {'_id': '$state', 'totalPop': {'$sum': '$pop'}}},\n                                                 {'$match': {'totalPop': {'$gt': 3000000}}}]))\n            print(f\"results: {results}\")\n\n    @unittest.skip(\"Just run local model in non-charge test\")\n    def test_llm_query_online(self):\n        str_results = self.sql_call(\"人口超过了300万的州有哪些?\")\n        self.assertIn(\"TX\", str_results)\n        self.assertIn(\"CA\", str_results)\n        self.assertIn(\"NY\", str_results)\n        print(f\"str_results:\\n{str_results}\")\n\n    # @unittest.skip(\"temporary skip test\")\n    def test_llm_query_local(self):\n        local_llm = lazyllm.TrainableModule(\"qwen2-72b-instruct-awq\").deploy_method(lazyllm.deploy.vllm).start()\n        sql_call = SqlCall(local_llm, self.mongodb_manager, use_llm_for_sql_result=True, return_trace=True)\n        str_results = sql_call(\"总人口超过了300万的州有哪些?\")\n        self.assertIn(\"TX\", str_results)\n        self.assertIn(\"CA\", str_results)\n        self.assertIn(\"NY\", str_results)\n        print(f\"str_results:\\n{str_results}\")\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_reranker.py", "content": "import unittest\nimport os\nimport lazyllm\nfrom lazyllm.tools.rag.doc_node import DocNode\nfrom lazyllm.tools.rag.rerank import Reranker, register_reranker\n\n\nclass TestReranker(unittest.TestCase):\n\n    def setUp(self):\n        self.doc1 = DocNode(text=\"This is a test document with the keyword apple.\")\n        self.doc2 = DocNode(\n            text=\"This is another test document with the keyword banana.\"\n        )\n        self.doc3 = DocNode(text=\"This document contains the keyword cherry.\")\n        self.nodes = [self.doc1, self.doc2, self.doc3]\n        self.query = \"test query\"\n\n    def test_keyword_filter_with_required_keys(self):\n        required_keys = [\"apple\"]\n        exclude_keys = []\n        reranker = Reranker(\n            name=\"KeywordFilter\", required_keys=required_keys, exclude_keys=exclude_keys\n        )\n        results = reranker.forward(self.nodes, query=self.query)\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0].get_text(), self.doc1.get_text())\n\n    def test_keyword_filter_with_exclude_keys(self):\n        required_keys = []\n        exclude_keys = [\"banana\"]\n        reranker = Reranker(\n            name=\"KeywordFilter\", required_keys=required_keys, exclude_keys=exclude_keys\n        )\n        results = reranker.forward(self.nodes, query=self.query)\n        self.assertEqual(len(results), 2)\n        self.assertNotIn(self.doc2, results)\n\n    def test_module_reranker(self):\n        env_key = 'LAZYLLM_DEFAULT_EMBEDDING_ENGINE'\n        test_cases = ['', 'transformers']\n        original_value = os.getenv(env_key, None)\n        for value in test_cases:\n            with self.subTest(value=value):\n                os.environ[env_key] = value\n                lazyllm.config.refresh(env_key)\n                reranker = Reranker(name=\"ModuleReranker\", model=\"bge-reranker-large\", topk=2)\n                reranker.start()\n                results = reranker.forward(self.nodes, query='cherry')\n\n                self.assertEqual(len(results), 2)\n                self.assertEqual(\n                    results[0].get_text(), self.doc3.get_text()\n                )  # highest score\n                assert results[0].relevance_score > results[1].relevance_score\n        if original_value:\n            os.environ[env_key] = original_value\n            lazyllm.config.refresh(env_key)\n\n    def test_register_reranker_decorator(self):\n        @register_reranker\n        def CustomReranker(node, **kwargs):\n            if \"custom\" in node.get_text():\n                return node\n            return None\n\n        custom_doc = DocNode(text=\"This document contains custom keyword.\")\n        nodes = [self.doc1, self.doc2, self.doc3, custom_doc]\n\n        reranker = Reranker(name=\"CustomReranker\")\n        results = reranker.forward(nodes)\n\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0].get_text(), custom_doc.get_text())\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_tools_manager.py", "content": "import re\nimport docstring_parser\nimport lazyllm\nfrom lazyllm.tools import ToolManager\nfrom lazyllm.tools.agent.toolsManager import (\n    _gen_empty_func_str_from_parsed_docstring,\n    _gen_func_from_str,\n    _check_return_type_is_the_same,\n    register,\n)\nfrom lazyllm.common import LazyLLMRegisterMetaClass\nfrom typing import Literal, get_type_hints\n\ndef _gen_wrapped_moduletool(func):\n    if \"tmp_tool\" not in LazyLLMRegisterMetaClass.all_clses:\n        register.new_group('tmp_tool')\n    register('tmp_tool')(func)\n    wrapped_module = getattr(lazyllm.tmp_tool, func.__name__)()\n    lazyllm.tmp_tool.remove(func.__name__)\n    return wrapped_module\n\nclass TestToolManager:\n    def test_gen_empty_func_str_from_parsed_docstring(self):\n        var_args_doc = '''\n        this is a function with *args and **kwargs.\n\n        Args:\n            a (int): this is an required integer.\n            b (Literal['foo', 'bar', 'baz']): this is a str with candidate values.\n            c (List[str]): this is a string list.\n\n        Returns:\n            str: returns a string\n        '''\n\n        parsed_doc = docstring_parser.parse(var_args_doc)\n        func_str = _gen_empty_func_str_from_parsed_docstring(parsed_doc)\n        expected_pattern = \"def f[0-9]+\\(a:int,b:Literal\\['foo', 'bar', 'baz'\\],c:List\\[str\\],\\)->str:\\n    pass\"  # noqa W605\n        res = re.match(expected_pattern, func_str)\n        assert res.span()\n        assert (res.span()[1] - res.span()[0]) == len(func_str)\n\n    def test_gen_func_from_str(self):\n        func_str1 = \"def add1(v):\\n    return v+1\"\n        func_doc1 = '''\n        this is a function returning value + 1.\n\n        Args:\n            v (int): value\n        '''\n        func = _gen_func_from_str(func_str1, func_doc1)\n        value = 5\n        assert func(value) == (value + 1)\n        assert func.__doc__ == func_doc1\n\n    def test_enum_func(self):\n        def func(s: Literal[\"a\", \"b\", \"c\"]):\n            '''\n            whatever\n            '''\n            pass\n\n        doc = '''\n        this is a function with Literal.\n\n        Args:\n            s (Literal['a', 'b', 'c']): a string\n        '''\n        parsed_doc = docstring_parser.parse(doc)\n        tool = _gen_wrapped_moduletool(func)\n        args = ToolManager._gen_args_info_from_moduletool_and_docstring(tool, parsed_doc)\n        info_of_s = args['s']\n        assert info_of_s['enum'] == ['a', 'b', 'c']\n\n    def test_check_return_type_is_the_same(self):\n        def add5(v: int) -> int:\n            '''\n            this is a function adding 5 to the value.\n\n            Args:\n                v (int): this is v's desc in function, different from that in doc\n\n            Returns:\n                int: value+5\n            '''\n            return v + 5\n\n        add5_doc1 = '''\n        this is a function adding 5 to the value.\n\n        Args:\n            v (int): this is v's desc\n\n        Returns:\n            int: value+5\n        '''\n\n        func_str = 'def add5(v:int) -> int:\\n    return v+5'\n        func_from_doc = _gen_func_from_str(func_str, add5_doc1)\n        tool = _gen_wrapped_moduletool(add5)\n        try:\n            value = 123\n            _check_return_type_is_the_same(\n                get_type_hints(func_from_doc, globals(), locals()),\n                get_type_hints(tool.__call__, globals(), locals()))\n            value = 456\n        except Exception:\n            value = 789\n        finally:\n            assert value == 456\n\n        # ----- #\n\n        str_without_arg_type = 'def identity(c) -> str:\\n    return c'\n        doc2 = \"\"\"\n        this is a function adding 5 to the value.\n\n        Args:\n            c (str): this is c's desc\n\n        Returns:\n            str: c itself\n        \"\"\"\n\n        func_from_doc2 = _gen_func_from_str(str_without_arg_type, doc2)\n        try:\n            value = 123\n            _check_return_type_is_the_same(\n                get_type_hints(func_from_doc2, globals(), locals()),\n                get_type_hints(tool.__call__, globals(), locals()))\n            value = 456\n        except Exception:\n            value = 789\n        finally:\n            assert value == 456\n\n        # ----- #\n\n        str_without_return_type = 'def identity3(c:str):\\n    return c'\n        doc3 = \"\"\"\n        this is a function desc.\n\n        Args:\n            c (str): this is c's desc\n\n        Returns:\n            str: c itself\n        \"\"\"\n\n        func_from_doc3 = _gen_func_from_str(str_without_return_type, doc3)\n        try:\n            value = 123\n            _check_return_type_is_the_same(\n                get_type_hints(func_from_doc3, globals(), locals()),\n                get_type_hints(tool.__call__, globals(), locals()))\n            value = 456\n        except Exception:\n            value = 789\n        finally:\n            assert value == 456\n\n    def test_invalid_typing(self):\n        invalid_doc1 = '''\n        this is an doc containing invalid types\n\n        Args:\n            v (Str): this is v desc\n\n        Returns:\n            int: return value\n        '''\n\n        parsed_docstring = docstring_parser.parse(invalid_doc1)\n        func_str = _gen_empty_func_str_from_parsed_docstring(parsed_docstring)\n        try:\n            test_value = 123\n            _gen_func_from_str(func_str, invalid_doc1)\n            test_value = 456\n        except Exception:\n            test_value = 789\n        finally:\n            assert test_value == 789\n\n    def test_case_sensitivity_of_generic_type(self):\n        invalid_doc1 = '''\n        this is an doc containing invalid types\n\n        Args:\n            v (union[str, Any]): this is v desc\n\n        Returns:\n            int: return value\n        '''\n\n        parsed_docstring = docstring_parser.parse(invalid_doc1)\n        func_str = _gen_empty_func_str_from_parsed_docstring(parsed_docstring)\n        try:\n            test_value = 111\n            _gen_func_from_str(func_str, invalid_doc1)\n            test_value = 222\n        except Exception:\n            test_value = 333\n        finally:\n            assert test_value == 333\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_thirdparty.py", "content": "import sys\nfrom lazyllm.thirdparty import faiss\n\nclass TestThirdparty(object):\n\n    def test_import(self, monkeypatch):\n        def check_installed(third_import_type):\n            try:\n                import faiss\n                # if env install real llama_index\n                return third_import_type == type(faiss)\n            except ImportError:\n                return False\n        third_import_type = type(faiss)\n        monkeypatch.delitem(sys.modules, \"faiss\", raising=False)\n        assert not check_installed(third_import_type)\n\n    def test_lazy_import(self, monkeypatch):\n        def check_lazy_import(faiss):\n            try:\n                faiss.a\n                return True\n            except AttributeError:\n                return False\n        monkeypatch.delitem(sys.modules, \"faiss\", raising=False)\n        assert faiss is not None\n        assert not check_lazy_import(faiss)\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_trainable_fc.py", "content": "import os\nimport json\nimport pytest\nimport random\nfrom typing import Literal\nimport wikipedia\n\nimport lazyllm\nfrom lazyllm import fc_register, deploy\nfrom lazyllm.tools import FunctionCall, FunctionCallAgent, ReactAgent, PlanAndSolveAgent, ReWOOAgent\nfrom lazyllm.launcher import cleanup\n\n@fc_register(\"tool\")\ndef get_current_weather(location: str,\n                        unit: Literal[\"Fahrenheit\", \"Celsius\", \"fahrenheit\", \"celsius\", \"C\", \"F\"] = 'fahrenheit'):\n    \"\"\"\n    Get the current weather in a given location\n\n    Args:\n        location (str): The city and state, e.g. San Francisco, CA.\n        unit (str): The temperature unit to use. Infer this from the users location.\n    \"\"\"\n    if 'tokyo' in location.lower():\n        return json.dumps({'location': 'Tokyo', 'temperature': '10', 'unit': 'celsius'})\n    elif 'san francisco' in location.lower():\n        return json.dumps({'location': 'San Francisco', 'temperature': '72', 'unit': 'fahrenheit'})\n    elif 'paris' in location.lower():\n        return json.dumps({'location': 'Paris', 'temperature': '22', 'unit': 'celsius'})\n    elif 'beijing' in location.lower():\n        return json.dumps({'location': 'Beijing', 'temperature': '90', 'unit': 'Fahrenheit'})\n    else:\n        return json.dumps({'location': location, 'temperature': 'unknown'})\n\n@fc_register(\"tool\")\ndef get_n_day_weather_forecast(location: str, num_days: int,\n                               unit: Literal[\"Celsius\", \"Fahrenheit\", \"celsius\", \"fahrenheit\", \"C\", \"F\"] = 'fahrenheit'):\n    \"\"\"\n    Get an N-day weather forecast\n\n    Args:\n        location (str): The city and state, e.g. San Francisco, CA.\n        num_days (int): The number of days to forecast.\n        unit (Literal['Celsius', 'Fahrenheit', 'celsius', 'fahrenheit', 'C', 'F']): The temperature unit to use. Infer this from the users location.\n    \"\"\"  # noqa E501\n    if 'tokyo' in location.lower():\n        return json.dumps({'location': 'Tokyo', 'temperature': '10', 'unit': 'celsius', \"num_days\": num_days})\n    elif 'san francisco' in location.lower():\n        return json.dumps({'location': 'San Francisco', 'temperature': '75', 'unit': 'fahrenheit', \"num_days\": num_days})\n    elif 'paris' in location.lower():\n        return json.dumps({'location': 'Paris', 'temperature': '25', 'unit': 'celsius', \"num_days\": num_days})\n    elif 'beijing' in location.lower():\n        return json.dumps({'location': 'Beijing', 'temperature': '85', 'unit': 'fahrenheit', \"num_days\": num_days})\n    else:\n        return json.dumps({'location': location, 'temperature': 'unknown'})\n\n@fc_register(\"tool\")\ndef multiply_tool(a: int, b: int) -> int:\n    \"\"\"\n    Multiply two integers and return the result integer\n\n    Args:\n        a (int): multiplier\n        b (int): multiplier\n\n    Returns:\n        int: result\n    \"\"\"\n    return a * b\n\n@fc_register(\"tool\")\ndef add_tool(a: int, b: int):\n    \"\"\"\n    Add two integers and returns the result integer\n\n    Args:\n        a (int): addend\n        b (int): addend\n    \"\"\"\n    return a + b\n\n@fc_register(\"tool\")\ndef is_even_or_odd(number):\n    '''\n    定义一个函数，用于判断一个数字是奇数还是偶数\n\n    Args:\n        number (int): 输入数值\n\n    Returns:\n        str: 输出\n    '''\n    if number % 2 == 0:\n        return f'{number}是偶数'\n    else:\n        return f'{number}是奇数'\n\n@fc_register(\"tool\")\ndef WikipediaWorker(input: str):\n    \"\"\"\n    Worker that search for similar page contents from Wikipedia. Useful when you need to get holistic knowledge \\\n    about people, places, companies, historical events, or other subjects. The response are long and might \\\n    contain some irrelevant information. Input should be a search query.\n\n    Args:\n        input (str): search query.\n    \"\"\"\n    https_proxy_bak = os.environ.get(\"https_proxy\", '')\n    http_proxy_bak = os.environ.get(\"http_proxy\", '')\n    os.environ['https_proxy'] = lazyllm.config['https_proxy']\n    os.environ['http_proxy'] = lazyllm.config['https_proxy']\n    print(f\"wikipedia input: {input}\")\n    try:\n        evidence = wikipedia.page(input).content\n        evidence = evidence.split(\"\\n\\n\")[0]\n    except wikipedia.PageError:\n        evidence = f\"Could not find [{input}]. Similar: {wikipedia.search(input)}\"\n    except wikipedia.DisambiguationError:\n        evidence = f\"Could not find [{input}]. Similar: {wikipedia.search(input)}\"\n    print(f\"wikipedia output: {evidence}\")\n    os.environ['https_proxy'] = https_proxy_bak\n    os.environ['http_proxy'] = http_proxy_bak\n    return evidence\n\n@fc_register(\"tool\")\ndef LLMWorker(input: str):\n    \"\"\"\n    A pretrained LLM like yourself. Useful when you need to act with general world knowledge and common sense. \\\n    Prioritize it when you are confident in solving the problem yourself. Input can be any instruction.\n\n    Args:\n        input (str): instruction\n    \"\"\"\n    llm = lazyllm.OnlineChatModule(source=\"glm\", stream=False)\n    query = f\"Respond in short directly with no extra words.\\n\\n{input}\"\n    print(f\"llm query: {query}, input: {input}\")\n    response = llm(query, llm_chat_history=[])\n    print(f\"llm res: {response}\")\n    return response\n\n@pytest.fixture()\ndef exe_trainable_single_function_call(request):\n    params = request.param if hasattr(request, 'param') else {}\n    tools = params.get(\"tools\", [])\n    query = params.get(\"query\", \"\")\n    llm = request.cls.llm\n    if not query or not tools:\n        raise ValueError(f\"query: {query} and {tools} cannot be empty.\")\n\n    print(f\"\\nStarting test 【{llm}】 function calling\")\n    fc = FunctionCall(llm, tools)\n    ret = fc(query)\n    yield ret\n    print(f\"\\n【{llm}】 function calling test done.\")\n\n@pytest.fixture()\ndef exe_trainable_parallel_function_call(request):\n    params = request.param if hasattr(request, 'param') else {}\n    tools = params.get(\"tools\", [])\n    query = params.get(\"query\", \"\")\n    llm = request.cls.llm\n    if not query or not tools:\n        raise ValueError(f\"query: {query} and tools: {tools} cannot be empty.\")\n\n    agent = FunctionCallAgent(llm, tools)\n    print(f\"\\nStarting test 【{llm}】parallel function calling\")\n    ret = agent(query)\n    yield ret\n    print(f\"\\n【{llm}】parallel function calling test done.\")\n\n@pytest.fixture()\ndef exe_trainable_advance_agent(request):\n    params = request.param if hasattr(request, 'param') else {}\n    tools = params.get('tools', [])\n    query = params.get('query', '')\n    Agent = params.get('Agent', None)\n    llm = request.cls.llm\n    if not query or not tools:\n        raise ValueError(f\"query: {query} and tools: {tools} cannot be empty.\")\n    if Agent is None:\n        raise ValueError(f\"Agent: {Agent} must be a valid value.\")\n\n    agent = Agent(llm, tools)\n    print(f\"\\nStarting test 【{llm}】 {Agent}.\")\n    ret = agent(query)\n    yield ret\n    print(f\"\\n【{llm}】 {Agent} test done.\")\n\ntools = [\"get_current_weather\", \"get_n_day_weather_forecast\"]\nsquery1 = \"What's the weather like today in celsius in Tokyo.\"\nsquery2 = \"What will the weather be like in celsius in Paris tomorrow?\"\nmquery1 = \"What's the weather like today in celsius in Tokyo and Paris.\"\nmquery2 = \"What will the weather be like in fahrenheit in san francisco and beijing tomorrow?\"\nagentQuery = \"计算 20*(45+23)*4, Calculate step by step.\"\nrewooquery = \"美国历届总统就职时年龄最大的是谁\"\nrewooquery2 = \"3是奇数还是偶数？\"\n\nclass TestTrainableFunctionCall(object):\n    @classmethod\n    def setup_class(cls):\n        models = [\"internlm2-chat-20b\", \"glm-4-9b-chat\", \"qwen2-7b-instruct\", \"qwen2-72b-instruct-awq\"]\n        model = random.choice(models)\n        cls.llm = lazyllm.TrainableModule(model).deploy_method(deploy.vllm).start()\n\n    @classmethod\n    def teardown_class(cls):\n        cleanup()\n\n    @pytest.mark.parametrize(\"exe_trainable_single_function_call\",\n                             [{\"tools\": tools, \"query\": squery1},\n                              {\"tools\": tools, \"query\": squery2}],\n                             indirect=True)\n    def test_trainable_single_function_call(self, exe_trainable_single_function_call):\n        ret = exe_trainable_single_function_call\n        assert isinstance(ret, list)\n\n    @pytest.mark.parametrize(\"exe_trainable_parallel_function_call\",\n                             [{'tools': tools, 'query': mquery1},\n                              {'tools': tools, 'query': mquery2}],\n                             indirect=True)\n    def test_trainable_parallel_function_call(self, exe_trainable_parallel_function_call):\n        ret = exe_trainable_parallel_function_call\n        assert isinstance(ret, str)\n\n    @pytest.mark.parametrize(\"exe_trainable_advance_agent\",\n                             [{'tools': ['multiply_tool', 'add_tool'], 'query': agentQuery, \"Agent\": ReactAgent},\n                              {'tools': ['multiply_tool', 'add_tool'], 'query': agentQuery, \"Agent\": PlanAndSolveAgent},\n                              {'tools': ['WikipediaWorker', 'LLMWorker'], 'query': rewooquery, \"Agent\": ReWOOAgent}],\n                             indirect=True)\n    def test_trainable_advance_agent(self, exe_trainable_advance_agent):\n        ret = exe_trainable_advance_agent\n        assert \"retrying\" not in ret\n\n    @pytest.mark.parametrize(\"exe_trainable_advance_agent\",\n                             [{'tools': ['add_tool', 'is_even_or_odd'], 'query': rewooquery2, \"Agent\": ReWOOAgent}],\n                             indirect=True)\n    def test_rewooagent_output_format(self, exe_trainable_advance_agent):\n        ret = exe_trainable_advance_agent\n        assert \"奇数\" in ret or 'odd' in ret\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_weather.py", "content": "import json\nfrom lazyllm.tools.tools import Weather\n\nclass TestWeather(object):\n    # skip\n    def _test_weather(self):\n        weather = Weather()\n        res = weather('海淀')\n        assert res['status_code'] == 200\n        content = json.loads(res['content'])\n        assert content['station']['city'] == '海淀'\n"}
{"type": "test_file", "path": "tests/basic_tests/conftest.py", "content": "import pytest\n\npytest_plugins = \"pytester\"\nfailed_test_classes = set()\n\n@pytest.hookimpl(tryfirst=True, hookwrapper=True)\ndef pytest_runtest_makereport(item, call):\n    outcome = yield\n    report = outcome.get_result()\n\n    if \"TestDocListServer\" in item.nodeid:\n        if report.failed:\n            failed_test_classes.add(\"TestDocListServer\")\n\n\n@pytest.hookimpl(trylast=True)\ndef pytest_sessionfinish(session, exitstatus):\n    if failed_test_classes:\n        last_failed = session.config.cache.get(\"cache/lastfailed\", {})\n\n        for item in session.items:\n            if \"TestDocListServer\" in item.nodeid:\n                last_failed[item.nodeid] = True\n\n        session.config.cache.set(\"cache/lastfailed\", last_failed)\n"}
{"type": "test_file", "path": "tests/basic_tests/test_bm25.py", "content": "import unittest\nfrom lazyllm.tools.rag.component.bm25 import BM25\nfrom lazyllm.tools.rag.doc_node import DocNode\nfrom lazyllm.thirdparty import numpy as np\n\n\nclass TestBM25(unittest.TestCase):\n    def setUp(self):\n        self.nodes = [\n            DocNode(text=\"This is a test document.\"),\n            DocNode(text=\"This document is for testing BM25.\"),\n            DocNode(text=\"BM25 is a ranking function used in information retrieval.\"),\n        ]\n\n        self.bm25_en = BM25(self.nodes, language=\"en\", topk=2)\n\n    def test_initialization(self):\n        self.assertIsInstance(self.bm25_en, BM25)\n        self.assertEqual(self.bm25_en.topk, 2)\n        self.assertEqual(len(self.bm25_en.nodes), 3)\n\n    def test_retrieve(self):\n        query = \"test document\"\n        results = self.bm25_en.retrieve(query)\n\n        self.assertEqual(len(results), 2)\n\n        for node, score in results:\n            self.assertIsInstance(node, DocNode)\n            self.assertIsInstance(score, np.float32)\n\n        self.assertIn(self.nodes[0], [result[0] for result in results])\n        self.assertIn(self.nodes[1], [result[0] for result in results])\n\n\nclass TestBM25Chinese(unittest.TestCase):\n    def setUp(self):\n        self.nodes = [\n            DocNode(text=\"这是一个测试文档。这个文档用于测试BM25。\"),\n            DocNode(\n                text=\"BM25是一种在信息检索中使用的排序函数。信息检索系统通过BM25算法来排序文档和分数。\"\n            ),\n            DocNode(text=\"中文文档的测试内容。测试文档中包含多个句子。\"),\n            DocNode(\n                text=\"这个测试是为了验证BM25在中文文档中的表现。我们需要对多个文档进行排序测试。\"\n            ),\n            DocNode(\n                text=\"文档的内容可以影响BM25的评分。排序函数的性能对于信息检索非常重要。\"\n            ),\n        ]\n\n        self.bm25_cn = BM25(self.nodes, language=\"zh\", topk=3)\n\n    def test_retrieve(self):\n        query = \"测试文档\"\n        results = self.bm25_cn.retrieve(query)\n\n        self.assertEqual(len(results), 3)\n\n        self.assertIn(self.nodes[0], [result[0] for result in results])\n        self.assertIn(self.nodes[2], [result[0] for result in results])\n        self.assertIn(self.nodes[3], [result[0] for result in results])\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/basic_tests/test_common.py", "content": "import random\nimport time\nimport pytest\nimport threading\n\nimport lazyllm\nfrom lazyllm.common import ArgsDict, compile_func\nfrom lazyllm.common import once_wrapper\nfrom lazyllm.components.formatter import lazyllm_merge_query, encode_query_with_filepaths, decode_query_with_filepaths\n\n\nclass TestCommon(object):\n\n    def test_common_argsdict(self):\n\n        my_ob = ArgsDict({'a': '1', 'b': '2'})\n        my_ob.check_and_update(my_ob)\n        expected_output = '--a=\"1\" --b=\"2\"'\n        assert my_ob.parse_kwargs() == expected_output\n\n    def test_common_bind(self):\n\n        def exam(a, b, c):\n            return [a, b, c]\n\n        num_list = [random.randint(1, 10) for _ in range(3)]\n        r1 = lazyllm.bind(exam, num_list[0], lazyllm._0, num_list[2])\n        ret_list = r1(num_list[1])\n        assert ret_list == num_list\n\n    def test_encode_and_decode_and_merge_query_with_filepaths(self):\n        # Test encode\n        query = 'hi'\n        path_list = ['a', 'b']\n        encode = encode_query_with_filepaths(query, path_list)\n        assert encode == '<lazyllm-query>{\"query\": \"hi\", \"files\": [\"a\", \"b\"]}'\n        assert encode_query_with_filepaths(query) == 'hi'\n\n        # Test decode\n        decode = decode_query_with_filepaths(encode)\n        assert isinstance(decode, dict)\n        assert 'query' in decode and 'files' in decode\n        assert decode['query'] == query\n        assert decode['files'] == path_list\n        assert decode_query_with_filepaths(query) == query\n\n        # Test Merge\n        assert lazyllm_merge_query(query) == query\n        assert lazyllm_merge_query(query, query, query) == query * 3\n        assert lazyllm_merge_query(query, encode) == '<lazyllm-query>{\"query\": \"hihi\", \"files\": [\"a\", \"b\"]}'\n        assert lazyllm_merge_query(encode, encode) == ('<lazyllm-query>{\"query\": \"hihi\", \"files\": '\n                                                       '[\"a\", \"b\", \"a\", \"b\"]}')\n        assert lazyllm_merge_query(encode, query, query) == ('<lazyllm-query>{\"query\": \"hihihi\", '\n                                                             '\"files\": [\"a\", \"b\"]}')\n\n    def test_common_cmd(self):\n\n        ret = lazyllm.LazyLLMCMD('python a --a=b --c=d', no_displays=['a'])\n        assert str(ret) == 'python a  --c=d'\n\n        ret = lazyllm.LazyLLMCMD('python a --a=b --c=d', no_displays=['c'])\n        assert str(ret) == 'python a --a=b '\n\n        ret = lazyllm.LazyLLMCMD('python a --a=b --c=d', no_displays=['d'])\n        assert str(ret) == 'python a --a=b --c=d'\n\n    def test_common_timeout(self):\n        from lazyllm.common.common import TimeoutException\n\n        with pytest.raises(TimeoutException):\n            with lazyllm.timeout(1, msg='hello'):\n                time.sleep(2)\n\n    def test_common_tread(self):\n\n        def is_equal2(x):\n            if x == 2:\n                return x\n            else:\n                raise Exception\n\n        ts = [lazyllm.Thread(target=is_equal2, args=(inp, )) for inp in [2, 3]]\n        [t.start() for t in ts]\n\n        assert ts[0].get_result() == 2\n        with pytest.raises(Exception):\n            ts[1].get_result()\n\n    def test_common_makerepr(self):\n\n        r1 = lazyllm.make_repr('a', 1)\n        r2 = lazyllm.make_repr('b', 2)\n        assert lazyllm.make_repr('c', 3, subs=[r1, r2]) == '<c type=3>'\n\n        with lazyllm.config.temp('repr_show_child', True):\n            assert lazyllm.make_repr('c', 3, subs=[r1, r2]) == '<c type=3>\\n |- <a type=1>\\n └- <b type=2>\\n'\n\n        assert lazyllm.make_repr('c', 3, subs=[r1, r2]) == '<c type=3>'\n\n    def test_compile_func(self):\n        str1 = \"def identity(v): return v\"\n        identity = compile_func(str1)\n        assert identity(\"abc\") == \"abc\"\n        assert identity(12345) == 12345\n\n        str2 = \"def square(v): return v * v\"\n        square = compile_func(str2)\n        assert square(3) == 9\n        assert square(18) == 324\n\n\nclass TestCommonOnce(object):\n\n    @once_wrapper\n    def once_func(self):\n        self._count += 1\n\n    @once_wrapper\n    def once_func_with_exception(self):\n        self._count += 1\n        raise RuntimeError('once exception')\n\n    def test_callonce(self):\n        self._count = 0\n        assert not self.once_func.flag\n        self.once_func()\n        assert self._count == 1\n        assert self.once_func.flag\n        self.once_func()\n        assert self._count == 1\n\n    def test_callonce_exception(self):\n        self._count = 0\n        assert not self.once_func_with_exception.flag\n        with pytest.raises(RuntimeError, match='once exception'):\n            self.once_func_with_exception()\n        assert self._count == 1\n        assert self.once_func_with_exception.flag\n        with pytest.raises(RuntimeError, match='once exception'):\n            self.once_func_with_exception()\n        assert self._count == 1\n\n\nclass TestCommonGlobals(object):\n\n    def _lazyllm_worker(self):\n        assert lazyllm.globals['a'] == 1\n        assert lazyllm.globals['chat_history'] == {}\n        assert lazyllm.globals['global_parameters']['key'] == 'value'\n\n    def _normal_worker(self):\n        assert 'a' not in lazyllm.globals\n        assert lazyllm.globals._sid == f'tid-{hex(threading.get_ident())}'\n        assert lazyllm.globals['chat_history'] == {}\n        assert lazyllm.globals['global_parameters'] == {}\n\n    def test_globals(self):\n        assert lazyllm.globals._sid == f'tid-{hex(threading.get_ident())}'\n        assert lazyllm.globals['chat_history'] == {}\n        assert lazyllm.globals['global_parameters'] == {}\n        lazyllm.globals['global_parameters']['key'] = 'value'\n        t = lazyllm.Thread(target=self._lazyllm_worker)\n        t.start()\n        t.join()\n        t = threading.Thread(target=self._normal_worker)\n        t.start()\n        t.join()\n\n\nclass TestCommonRegistry(object):\n    def test_component_registry(self):\n        lazyllm.component_register.new_group('mygroup')\n\n        @lazyllm.component_register('mygroup')\n        def myfunc(input):\n            return input\n\n        assert lazyllm.mygroup.myfunc()(1) == 1\n        assert lazyllm.mygroup.myfunc(launcher=lazyllm.launchers.empty)(1) == 1\n\n        lazyllm.mygroup.remove('myfunc')\n        with pytest.raises(AttributeError):\n            lazyllm.mygroup.myfunc()(1)\n\n        @lazyllm.component_register('mygroup.subgroup')\n        def myfunc2(input):\n            return input\n\n        assert lazyllm.mygroup.subgroup.myfunc2()(1) == 1\n        assert lazyllm.mygroup.subgroup.myfunc2(launcher=lazyllm.launchers.empty)(1) == 1\n\n    def test_custom_registry(self):\n        class CustomClass(object, metaclass=lazyllm.common.registry.LazyLLMRegisterMetaClass):\n            def __call__(self, a, b):\n                return self.forward(a + 1, b * 2)\n\n            def forward(self, a, b):\n                raise NotImplementedError('forward is not implemented')\n\n        reg = lazyllm.Register(CustomClass, 'forward')\n        reg.new_group('custom')\n\n        @reg('custom')\n        def test(a, b): return a + b\n\n        @reg.forward('custom')\n        def test2(a, b): return a * b\n\n        assert lazyllm.custom.test()(1, 2) == 6\n        assert lazyllm.custom.test2()(1, 2) == 8\n"}
{"type": "test_file", "path": "tests/basic_tests/test_component.py", "content": "import lazyllm\n\n\nclass TestPrompter(object):\n    def test_prompter(self):\n        p = lazyllm.Prompter(prompt='hello world2 <{input}>')\n        assert not p.is_empty(), \"Prompter should not be empty\"\n\n    def test_generate_prompt(self):\n        p = lazyllm.Prompter(prompt='hello world2 <{input}>')\n        result = p.generate_prompt('123')\n        assert result == 'hello world2 <123>', f\"Expected 'hello world2 <123>', but got '{result}'\"\n\n    def test_generate_prompt_dict_input(self):\n        p = lazyllm.Prompter(prompt='hello world2 <{input}>')\n        result_dict_input = p.generate_prompt({'input': '123'})\n        assert result_dict_input == 'hello world2 <123>', \\\n               f\"Expected 'hello world2 <123>', but got '{result_dict_input}'\"\n\n    def test_from_template(self):\n        p = lazyllm.Prompter.from_template('alpaca')\n        expected_prompt = (\n            \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n            \"Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### \"\n            \"Input:\\n{input}\\n\\n### Response:\\n\"\n        )\n        assert p._prompt == expected_prompt, f\"Expected prompt to be '{expected_prompt}', but got '{p._prompt}'\"\n\n    def test_generate_prompt_with_template(self):\n        p = lazyllm.Prompter.from_template('alpaca')\n        result = p.generate_prompt(dict(instruction='ins', input='inp'))\n        expected_result = (\n            \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n            \"Write a response that appropriately completes the request.\\n\\n### Instruction:\\nins\\n\\n### \"\n            \"Input:\\ninp\\n\\n### Response:\\n\"\n        )\n        assert result == expected_result, f\"Expected '{expected_result}', but got '{result}'\"\n\n\nclass TestAlpacaPrompter(object):\n    def test_basic_prompter(self):\n        p = lazyllm.AlpacaPrompter('请完成加法运算, 输入为{instruction}')\n        r = p.generate_prompt('a+b')\n        assert r == 'You are an AI-Agent developed by LazyLLM.\\nBelow is an instruction that describes a task, paired with extra messages such as input that provides further context if possible. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n请完成加法运算, 输入为a+b\\n\\n\\n\\n### Response:\\n'  # noqa E501\n        r = p.generate_prompt('a+b', return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\nBelow is an instruction that describes a task, paired with extra messages such as input that provides further context if possible. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n请完成加法运算, 输入为a+b\\n\\n'},  # noqa E501\n            {'role': 'user', 'content': ''}]}\n\n        p = lazyllm.AlpacaPrompter('请完成加法运算', extra_keys='input')\n        r = p.generate_prompt('a+b')\n        assert r == 'You are an AI-Agent developed by LazyLLM.\\nBelow is an instruction that describes a task, paired with extra messages such as input that provides further context if possible. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n请完成加法运算\\n\\nHere are some extra messages you can referred to:\\n\\n### input:\\na+b\\n\\n\\n\\n### Response:\\n'  # noqa E501\n        r = p.generate_prompt('a+b', return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\nBelow is an instruction that describes a task, paired with extra messages such as input that provides further context if possible. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n请完成加法运算\\n\\nHere are some extra messages you can referred to:\\n\\n### input:\\na+b\\n\\n'},  # noqa E501\n            {'role': 'user', 'content': ''}]}\n\n        p = lazyllm.AlpacaPrompter(dict(system='请完成加法运算', user='输入为{instruction}'))\n        r = p.generate_prompt('a+b')\n        assert r == 'You are an AI-Agent developed by LazyLLM.\\nBelow is an instruction that describes a task, paired with extra messages such as input that provides further context if possible. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n请完成加法运算\\n\\n输入为a+b### Response:\\n'  # noqa E501\n        r = p.generate_prompt('a+b', return_dict=True)\n        assert r == {'messages': [{'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\nBelow is an instruction that describes a task, paired with extra messages such as input that provides further context if possible. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n请完成加法运算'}, {'role': 'user', 'content': '输入为a+b'}]}  # noqa E501\n\n\nclass TestChatPrompter(object):\n    def test_basic_prompter(self):\n        p = lazyllm.ChatPrompter('请完成加法运算, 输入为{instruction}')\n        r = p.generate_prompt('a+b')\n        assert r == 'You are an AI-Agent developed by LazyLLM.请完成加法运算, 输入为a+b\\n\\n\\n\\n\\n\\n\\n\\n'\n        r = p.generate_prompt('a+b', return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\n请完成加法运算, 输入为a+b\\n\\n'},\n            {'role': 'user', 'content': ''}]}\n\n        p = lazyllm.ChatPrompter('请完成加法运算', extra_keys='input')\n        r = p.generate_prompt('a+b')\n        assert r == 'You are an AI-Agent developed by LazyLLM.请完成加法运算\\nHere are some extra messages you can referred to:\\n\\n### input:\\na+b\\n\\n\\n\\n\\n\\n\\n\\n\\n'  # noqa E501\n        r = p.generate_prompt('a+b', return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\n请完成加法运算\\nHere are some extra messages you can referred to:\\n\\n### input:\\na+b\\n\\n\\n'},  # noqa E501\n            {'role': 'user', 'content': ''}]}\n\n        p = lazyllm.ChatPrompter(dict(system='请完成加法运算', user='输入为{instruction}'))\n        r = p.generate_prompt('a+b')\n        assert r == 'You are an AI-Agent developed by LazyLLM.请完成加法运算\\n\\n\\n\\n输入为a+b\\n\\n'\n        r = p.generate_prompt('a+b', return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\n请完成加法运算'},\n            {'role': 'user', 'content': '输入为a+b'}]}\n\n    def test_history(self):\n        p = lazyllm.ChatPrompter(dict(system='请完成加法运算', user='输入为{instruction}'),\n                                 history=[['输入为a+b', 'a+b'], ['输入为c+d', 'c+d']])\n        r = p.generate_prompt('e+f')\n        assert r == 'You are an AI-Agent developed by LazyLLM.请完成加法运算\\n\\n输入为a+ba+b输入为c+dc+d\\n\\n输入为e+f\\n\\n'\n        r = p.generate_prompt('e+f', return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\n请完成加法运算'},\n            {'role': 'user', 'content': '输入为a+b'},\n            {'role': 'assistant', 'content': 'a+b'},\n            {'role': 'user', 'content': '输入为c+d'},\n            {'role': 'assistant', 'content': 'c+d'},\n            {'role': 'user', 'content': '输入为e+f'}]}\n\n        p = lazyllm.ChatPrompter(dict(system='请完成加法运算', user='输入为{instruction}'))\n        r = p.generate_prompt('e+f', history=[['输入为a+b', 'a+b'], ['输入为c+d', 'c+d']])\n        assert r == 'You are an AI-Agent developed by LazyLLM.请完成加法运算\\n\\n输入为a+ba+b输入为c+dc+d\\n\\n输入为e+f\\n\\n'\n\n        r = p.generate_prompt('e+f', history=[['输入为a+b', 'a+b'], ['输入为c+d', 'c+d']], return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\n请完成加法运算'},\n            {'role': 'user', 'content': '输入为a+b'},\n            {'role': 'assistant', 'content': 'a+b'},\n            {'role': 'user', 'content': '输入为c+d'},\n            {'role': 'assistant', 'content': 'c+d'},\n            {'role': 'user', 'content': '输入为e+f'}]}\n\n        p = lazyllm.ChatPrompter(dict(system='请完成加法运算', user='输入为{instruction}'), history=[['输入为a+b', 'a+b']])\n        r = p.generate_prompt('e+f', history=[{\"role\": \"user\", \"content\": '输入为c+d'},\n                                              {\"role\": \"assistant\", \"content\": 'c+d'}])\n        assert r == 'You are an AI-Agent developed by LazyLLM.请完成加法运算\\n\\n输入为a+ba+b输入为c+dc+d\\n\\n输入为e+f\\n\\n'\n\n        r = p.generate_prompt('e+f', history=[{\"role\": \"user\", \"content\": '输入为c+d'},\n                                              {\"role\": \"assistant\", \"content\": 'c+d'}], return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\n请完成加法运算'},\n            {'role': 'user', 'content': '输入为a+b'},\n            {'role': 'assistant', 'content': 'a+b'},\n            {'role': 'user', 'content': '输入为c+d'},\n            {'role': 'assistant', 'content': 'c+d'},\n            {'role': 'user', 'content': '输入为e+f'}]}\n\n    def test_empty_prompt_with_history(self):\n        p = lazyllm.ChatPrompter('', history=[['输入为a+b', 'a+b']])\n        r11 = p.generate_prompt('c+d')\n        r12 = p.generate_prompt('c+d', return_dict=True)\n\n        p = lazyllm.ChatPrompter(None, history=[['输入为a+b', 'a+b']])\n        r21 = p.generate_prompt('c+d')\n        r22 = p.generate_prompt('c+d', return_dict=True)\n\n        assert r11 == r21 == 'You are an AI-Agent developed by LazyLLM.\\n\\n输入为a+ba+b\\n\\nc+d\\n\\n'\n        assert r12 == r22 == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.'},\n            {'role': 'user', 'content': '输入为a+b'},\n            {'role': 'assistant', 'content': 'a+b'},\n            {'role': 'user', 'content': 'c+d'}]}\n\n    def test_configs(self):\n        p = lazyllm.ChatPrompter(dict(system='请完成加法运算', user='输入为{instruction}'))\n        p._set_model_configs(sos='<s>', eos='</s>')\n        r = p.generate_prompt('a+b')\n        assert r == '<s>You are an AI-Agent developed by LazyLLM.请完成加法运算</s>\\n\\n\\n\\n输入为a+b\\n\\n'\n        r = p.generate_prompt('a+b', return_dict=True)\n        assert r == {'messages': [{'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\n请完成加法运算'}, {'role': 'user', 'content': '输入为a+b'}]}  # noqa E501\n\n    def test_config_with_history(self):\n        p = lazyllm.ChatPrompter(dict(system='请完成加法运算', user='输入为{instruction}'), history=[['输入为a+b', 'a+b']])\n        p._set_model_configs(sos='<s>', eos='</s>', soh='<h>', eoh='</h>', soa='<a>', eoa='</a>')\n        r = p.generate_prompt('e+f', history=[{\"role\": \"user\", \"content\": '输入为c+d'},\n                                              {\"role\": \"assistant\", \"content\": 'c+d'}])\n        assert r == '<s>You are an AI-Agent developed by LazyLLM.请完成加法运算</s>\\n\\n<h>输入为a+b</h><a>a+b</a><h>输入为c+d</h><a>c+d</a>\\n<h>\\n输入为e+f\\n</h><a>\\n'  # noqa E501\n\n        r = p.generate_prompt('e+f', history=[{\"role\": \"user\", \"content\": '输入为c+d'},\n                                              {\"role\": \"assistant\", \"content\": 'c+d'}], return_dict=True)\n        assert r == {'messages': [\n            {'role': 'system', 'content': 'You are an AI-Agent developed by LazyLLM.\\n请完成加法运算'},\n            {'role': 'user', 'content': '输入为a+b'},\n            {'role': 'assistant', 'content': 'a+b'},\n            {'role': 'user', 'content': '输入为c+d'},\n            {'role': 'assistant', 'content': 'c+d'},\n            {'role': 'user', 'content': '输入为e+f'}]}\n"}
{"type": "test_file", "path": "tests/basic_tests/test_config.py", "content": "import lazyllm\nfrom lazyllm.configs import Mode\nimport os\nimport copy\nimport pytest\nimport contextlib\nimport inspect\n\n\nisolate_env = \"PARROTS_ISOLATE_STATUS\"\n\n\ndef isolated(func):\n    def run_subprocess(self, pytester):\n        # python_path = os.path.dirname(inspect.getfile(sys.modules[__name__]))\n        file_path = inspect.getfile(self.__class__)\n        class_name = self.__class__.__name__\n        method_name = func.__name__\n        test_func = file_path + '::' + class_name + '::' + method_name\n        with clear_env():\n            with set_env(isolate_env, \"IN_SUBPROCESS\"):\n                result = pytester.runpytest_subprocess(test_func)\n        assert result.ret == 0\n\n    if not inspect.isfunction(func):\n        raise TypeError(\"Decorator 'isolated' can only decorate functions.\")\n\n    fn_code = func.__code__\n    if 'self' not in fn_code.co_varnames or fn_code.co_argcount != 1:\n        raise TypeError(\"Decorated function should be method and \"\n                        \"have exactly one argument 'self'.\")\n\n    isolate_status = os.getenv(isolate_env)\n    if isolate_status == \"IN_SUBPROCESS\":\n        return func\n    # set environ variable to 'OFF' to skip all isolated tests.\n    elif isolate_status == \"OFF\":\n        return pytest.mark.skip(func)\n    else:\n        return pytest.mark.isolate(run_subprocess)\n\n\nclass TestConfig(object):\n    def test_refresh(self):\n        origin = copy.deepcopy(lazyllm.config.impl)\n        os.environ['LAZYLLM_GPU_TYPE'] = 'H100'\n        lazyllm.config.refresh('LAZYLLM_GPU_TYPE')\n        assert lazyllm.config.impl['gpu_type'] == 'H100'\n        os.environ['LAZYLLM_GPU_TYPE'] = origin['gpu_type']\n        lazyllm.config.refresh('gpu_type')\n        assert lazyllm.config.impl['gpu_type'] == origin['gpu_type']\n        lazyllm.config.refresh()\n        assert lazyllm.config.impl == origin\n\n    def test_config_mode(self):\n        print(os.environ.get('LAZYLLM_DISPLAY'))\n        assert lazyllm.config['mode'] == Mode.Normal\n\n    @isolated\n    def test_config_disp(self):\n        print(os.environ.get('LAZYLLM_DISPLAY'))\n        assert lazyllm.config['mode'] == Mode.Display\n\n@contextlib.contextmanager\ndef clear_env():\n    LAZYLLM_DISPLAY = \"LAZYLLM_DISPLAY\"\n\n    env_list = [\n        LAZYLLM_DISPLAY,\n    ]\n    env_flags = [os.getenv(env) for env in env_list]\n    print(env_flags)\n    for env, flag in zip(env_list, env_flags):\n        if flag is not None:\n            os.environ[env] = \"\"\n            if os.getenv(env) is not None:\n                del os.environ[env]\n\n    yield\n\n    for env, flag in zip(env_list, env_flags):\n        if flag is not None:\n            os.environ[env] = flag\n\n\n@contextlib.contextmanager\ndef set_env(environ, value):\n    assert isinstance(value, str)\n    original_value = os.getenv(environ)\n    os.environ['LAZYLLM_DISPLAY'] = '1'\n\n    os.environ[environ] = value\n    yield\n\n    if original_value is None:\n        os.environ.pop(environ)\n    else:\n        os.environ[environ] = original_value\n"}
{"type": "test_file", "path": "tests/basic_tests/test_doc_manager.py", "content": "import pytest\nimport lazyllm\nfrom lazyllm.tools.rag.utils import DocListManager\nfrom lazyllm.tools.rag.doc_manager import DocManager\nimport shutil\nimport hashlib\nimport sqlite3\nimport unittest\nimport requests\nimport io\nimport json\nimport time\n\n\n@pytest.fixture(autouse=True)\ndef setup_tmpdir(request, tmpdir):\n    request.cls.tmpdir = tmpdir\n\n\ndef get_fid(path):\n    if isinstance(path, (tuple, list)):\n        return type(path)(get_fid(p) for p in path)\n    else:\n        return hashlib.sha256(f'{path}'.encode()).hexdigest()\n\n\n@pytest.mark.usefixtures(\"setup_tmpdir\")\nclass TestDocListManager(unittest.TestCase):\n\n    def setUp(self):\n        self.test_dir = test_dir = self.tmpdir.mkdir(\"test_documents\")\n\n        test_file_1, test_file_2 = test_dir.join(\"test1.txt\"), test_dir.join(\"test2.txt\")\n        test_file_1.write(\"This is a test file 1.\")\n        test_file_2.write(\"This is a test file 2.\")\n        self.test_file_1, self.test_file_2 = str(test_file_1), str(test_file_2)\n\n        self.manager = DocListManager(str(test_dir), \"TestManager\")\n\n    def tearDown(self):\n        shutil.rmtree(str(self.test_dir))\n        self.manager.release()\n\n    def test_init_tables(self):\n        self.manager.init_tables()\n        assert self.manager.table_inited() is True\n\n    def test_add_files(self):\n        self.manager.init_tables()\n\n        self.manager.add_files([self.test_file_1, self.test_file_2])\n        files_list = self.manager.list_files(details=True)\n        assert len(files_list) == 2\n        assert any(self.test_file_1.endswith(row[1]) for row in files_list)\n        assert any(self.test_file_2.endswith(row[1]) for row in files_list)\n\n    def test_list_kb_group_files(self):\n        self.manager.init_tables()\n        # wait for files to be added\n        time.sleep(15)\n        files_list = self.manager.list_kb_group_files(DocListManager.DEFAULT_GROUP_NAME, details=True)\n        assert len(files_list) == 2\n        files_list = self.manager.list_kb_group_files('group1', details=True)\n        assert len(files_list) == 0\n\n        self.manager.add_files_to_kb_group(get_fid([self.test_file_1, self.test_file_2]),\n                                           DocListManager.DEFAULT_GROUP_NAME)\n        files_list = self.manager.list_kb_group_files(DocListManager.DEFAULT_GROUP_NAME, details=True)\n        assert len(files_list) == 2\n\n        self.manager.add_files_to_kb_group(get_fid([self.test_file_1, self.test_file_2]), 'group1')\n        files_list = self.manager.list_kb_group_files('group1', details=True)\n        assert len(files_list) == 2\n\n    def test_list_kb_groups(self):\n        self.manager.init_tables()\n        assert len(self.manager.list_all_kb_group()) == 1\n\n        self.manager.add_kb_group('group1')\n        self.manager.add_kb_group('group2')\n        r = self.manager.list_all_kb_group()\n        assert len(r) == 3 and self.manager.DEFAULT_GROUP_NAME in r and 'group2' in r\n\n    def test_delete_files(self):\n        self.manager.init_tables()\n\n        self.manager.add_files([self.test_file_1, self.test_file_2])\n        self.manager.delete_files([hashlib.sha256(f'{self.test_file_1}'.encode()).hexdigest()])\n        files_list = self.manager.list_files(details=True)\n        assert len(files_list) == 2\n        files_list = self.manager.list_files(details=True, exclude_status=DocListManager.Status.deleting)\n        assert len(files_list) == 1\n        assert not any(self.test_file_1.endswith(row[1]) for row in files_list)\n\n    def test_add_deleting_file(self):\n        self.manager.init_tables()\n\n        self.manager.add_files([self.test_file_1, self.test_file_2])\n        self.manager.delete_files([hashlib.sha256(f'{self.test_file_1}'.encode()).hexdigest()])\n        files_list = self.manager.list_files(details=True)\n        assert len(files_list) == 2\n        files_list = self.manager.list_files(details=True, status=DocListManager.Status.deleting)\n        assert len(files_list) == 1\n        documents = self.manager.add_files([self.test_file_1])\n        assert documents == []\n\n    def test_update_file_message(self):\n        self.manager.init_tables()\n\n        self.manager.add_files([self.test_file_1])\n        file_id = hashlib.sha256(f'{self.test_file_1}'.encode()).hexdigest()\n        self.manager.update_file_message(file_id, meta=\"New metadata\", status=\"processed\")\n\n        conn = sqlite3.connect(self.manager._db_path)\n        cursor = conn.execute(\"SELECT meta, status FROM documents WHERE doc_id = ?\", (file_id,))\n        row = cursor.fetchone()\n        conn.close()\n\n        assert row[0] == \"New metadata\"\n        assert row[1] == \"processed\"\n\n    def test_get_and_update_file_status(self):\n        self.manager.init_tables()\n\n        file_id = hashlib.sha256(f'{self.test_file_1}'.encode()).hexdigest()\n        status = self.manager.get_file_status(file_id)\n        assert status[0] == DocListManager.Status.success\n\n        self.manager.add_files([self.test_file_1], status=DocListManager.Status.waiting)\n        status = self.manager.get_file_status(file_id)\n        assert status[0] == DocListManager.Status.success\n\n        self.manager.update_file_status([file_id], DocListManager.Status.waiting)\n        status = self.manager.get_file_status(file_id)\n        assert status[0] == DocListManager.Status.waiting\n\n    def test_add_files_to_kb_group(self):\n        self.manager.init_tables()\n        files_list = self.manager.list_kb_group_files(\"group1\", details=True)\n        assert len(files_list) == 0\n\n        self.manager.add_files([self.test_file_1, self.test_file_2])\n        files_list = self.manager.list_kb_group_files(\"group1\", details=True)\n        assert len(files_list) == 0\n\n        self.manager.add_files_to_kb_group(get_fid([self.test_file_1, self.test_file_2]), group=\"group1\")\n        files_list = self.manager.list_kb_group_files(\"group1\", details=True)\n        assert len(files_list) == 2\n\n    def test_delete_files_from_kb_group(self):\n        self.manager.init_tables()\n\n        self.manager.add_files([self.test_file_1, self.test_file_2])\n        self.manager.add_files_to_kb_group(get_fid([self.test_file_1, self.test_file_2]), group=\"group1\")\n\n        self.manager.delete_files_from_kb_group([hashlib.sha256(f'{self.test_file_1}'.encode()).hexdigest()], \"group1\")\n        files_list = self.manager.list_kb_group_files(\"group1\", details=True)\n        # delete will literally erase the record\n        assert len(files_list) == 1\n\n\n@pytest.fixture(scope=\"class\", autouse=True)\ndef setup_tmpdir_class(request, tmpdir_factory):\n    request.cls.tmpdir = tmpdir_factory.mktemp(\"class_tmpdir\")\n\n\n@pytest.mark.usefixtures(\"setup_tmpdir_class\")\nclass TestDocListServer(object):\n\n    @classmethod\n    def setup_class(cls):\n        cls.test_dir = test_dir = cls.tmpdir.mkdir(\"test_server\")\n\n        test_file_1, test_file_2 = test_dir.join(\"test1.txt\"), test_dir.join(\"test2.txt\")\n        test_file_1.write(\"This is a test file 1.\")\n        test_file_2.write(\"This is a test file 2.\")\n        cls.test_file_1, cls.test_file_2 = str(test_file_1), str(test_file_2)\n\n        cls.manager = DocListManager(str(test_dir), \"TestManager\", False)\n        cls.manager.init_tables()\n        cls.manager.add_kb_group('group1')\n        cls.manager.add_kb_group('extra_group')\n        cls.server = lazyllm.ServerModule(DocManager(cls.manager))\n        cls.server.start()\n        cls._test_inited = True\n\n        test_file_extra = test_dir.join(\"test_extra.txt\")\n        test_file_extra.write(\"This is a test file extra.\")\n        cls.test_file_extra = str(test_file_extra)\n        cls.manager.add_files([cls.test_file_1, cls.test_file_2], status=DocListManager.Status.success)\n        time.sleep(15)\n\n    def get_url(self, url, **kw):\n        url = (self.server._url.rsplit(\"/\", 1)[0] + '/' + url).rstrip('/')\n        if kw: url += ('?' + '&'.join([f'{k}={v}' for k, v in kw.items()]))\n        return url\n\n    def teardown_class(cls):\n        cls.server.stop()\n        shutil.rmtree(str(cls.test_dir))\n        cls.manager.release()\n\n    @pytest.mark.order(0)\n    def test_redirect_to_docs(self):\n        assert requests.get(self.get_url('')).status_code == 200\n        assert requests.get(self.get_url('docs')).status_code == 200\n\n    @pytest.mark.order(1)\n    def test_list_kb_groups(self):\n        response = requests.get(self.get_url('list_kb_groups'))\n        assert response.status_code == 200\n        assert response.json().get('data') == [DocListManager.DEFAULT_GROUP_NAME, 'group1', 'extra_group']\n\n    @pytest.mark.order(2)\n    def test_list_files(self):\n        response = requests.get(self.get_url('list_files'))\n        assert len(response.json().get('data')) == 2\n        response = requests.get(self.get_url('list_files', limit=1))\n        assert len(response.json().get('data')) == 1\n        response = requests.get(self.get_url('list_files_in_group', group_name=DocListManager.DEFAULT_GROUP_NAME))\n        assert len(response.json().get('data')) == 2\n        response = requests.get(self.get_url('list_files_in_group', group_name='group1'))\n        assert len(response.json().get('data')) == 0\n\n    @pytest.mark.order(3)\n    def test_upload_files_and_upload_files_to_kb(self):\n        files = [('files', ('test1.txt', io.BytesIO(b\"file1 content\"), 'text/plain')),\n                 ('files', ('test2.txt', io.BytesIO(b\"file2 content\"), 'text/plain'))]\n\n        data = dict(override='true', metadatas=json.dumps([{\"key\": \"value\"}, {\"key\": \"value2\"}]), user_path='path')\n        response = requests.post(self.get_url('upload_files', **data), files=files)\n        assert response.status_code == 200 and response.json().get('code') == 200, response.json()\n        assert len(response.json().get('data')[0]) == 2\n\n        response = requests.get(self.get_url('list_files', details=False))\n        ids = response.json().get('data')\n        assert response.status_code == 200 and len(ids) == 4\n\n        # add_files_to_group\n        files = [('files', ('test3.txt', io.BytesIO(b\"file3 content\"), 'text/plain'))]\n        data = dict(override='false', metadatas=json.dumps([{\"key\": \"value\"}]), group_name='group1')\n        response = requests.post(self.get_url('add_files_to_group', **data), files=files)\n        assert response.status_code == 200\n\n        response = requests.get(self.get_url('list_files', details=True))\n        assert response.status_code == 200 and len(response.json().get('data')) == 5\n        response = requests.get(self.get_url('list_files_in_group', group_name='group1'))\n        assert response.status_code == 200 and len(response.json().get('data')) == 1\n\n    @pytest.mark.order(4)\n    def test_add_files_to_group_and_delete_files_from_group(self):\n        response = requests.get(self.get_url('list_files', details=False))\n        ids = response.json().get('data')\n        assert response.status_code == 200 and len(ids) == 5\n        requests.post(self.get_url('add_files_to_group_by_id'), json=dict(file_ids=ids[:2], group_name='group1'))\n        response = requests.get(self.get_url('list_files_in_group', group_name='group1'))\n        assert response.status_code == 200 and len(response.json().get('data')) == 3\n\n        requests.post(self.get_url('delete_files_from_group'), json=dict(file_ids=ids[:1], group_name='group1'))\n        response = requests.get(self.get_url('list_files_in_group', group_name='group1'))\n        assert response.status_code == 200 and len(response.json().get('data')) == 3\n        response = requests.get(self.get_url('list_files_in_group', group_name='group1', alive=True))\n        assert response.status_code == 200 and len(response.json().get('data')) == 2\n\n    @pytest.mark.order(5)\n    def test_delete_files(self):\n        response = requests.get(self.get_url('list_files', details=False))\n        ids = response.json().get('data')\n        assert response.status_code == 200 and len(ids) == 5\n\n        response = requests.post(self.get_url('delete_files'), json=dict(file_ids=ids[-1:]))\n        lazyllm.LOG.warning(response.json())\n        assert response.status_code == 200 and response.json().get('code') == 200\n\n        response = requests.get(self.get_url('list_files'))\n        assert response.status_code == 200 and len(response.json().get('data')) == 5\n        response = requests.get(self.get_url('list_files', alive=True))\n        assert response.status_code == 200 and len(response.json().get('data')) == 4\n\n        response = requests.get(self.get_url('list_files_in_group', group_name='group1'))\n        assert response.status_code == 200 and len(response.json().get('data')) == 3\n        response = requests.get(self.get_url('list_files_in_group', group_name='group1', alive=True))\n        assert response.status_code == 200 and len(response.json().get('data')) == 1\n\n    @pytest.mark.order(6)\n    def test_add_files(self):\n        json_data = {\n            'files': [self.test_file_extra, \"fake path\"],\n            'group_name': \"extra_group\",\n            'metadatas': json.dumps([{\"key\": \"value\"}, {\"key\": \"value\"}])\n        }\n        response = requests.post(self.get_url('add_files'), json=json_data)\n        assert response.status_code == 200\n        assert len(response.json().get('data')) == 2 and response.json().get('data')[1] is None\n"}
{"type": "test_file", "path": "tests/basic_tests/test_document.py", "content": "import lazyllm\nfrom lazyllm.tools.rag.doc_impl import DocImpl\nfrom lazyllm.tools.rag.transform import SentenceSplitter\nfrom lazyllm.tools.rag.store_base import LAZY_ROOT_NAME\nfrom lazyllm.tools.rag.doc_node import DocNode\nfrom lazyllm.tools.rag.global_metadata import RAG_DOC_PATH, RAG_DOC_ID\nfrom lazyllm.tools.rag import Document, Retriever, TransformArgs, AdaptiveTransform\nfrom lazyllm.tools.rag.doc_manager import DocManager\nfrom lazyllm.tools.rag.utils import DocListManager\nfrom lazyllm.launcher import cleanup\nfrom lazyllm import config\nfrom unittest.mock import MagicMock\nimport unittest\nimport httpx\nimport os\nimport shutil\nimport io\nimport re\nimport json\nimport time\nimport tempfile\n\n\nclass TestDocImpl(unittest.TestCase):\n\n    def setUp(self):\n        self.mock_embed = MagicMock()\n        self.mock_directory_reader = MagicMock()\n        # use temporary file as only existing files can be added to DocImpl\n        self.tmp_file_a = tempfile.NamedTemporaryFile()\n        self.tmp_file_b = tempfile.NamedTemporaryFile()\n        mock_node = DocNode(group=LAZY_ROOT_NAME, text=\"dummy text\")\n        mock_node._global_metadata = {RAG_DOC_PATH: self.tmp_file_a.name}\n        self.mock_directory_reader.load_data.return_value = [mock_node]\n\n        self.doc_impl = DocImpl(embed=self.mock_embed, doc_files=[self.tmp_file_a.name])\n        self.doc_impl._reader = self.mock_directory_reader\n\n    def tearDown(self):\n        self.tmp_file_a.close()\n        self.tmp_file_b.close()\n\n    def test_create_node_group_default(self):\n        self.doc_impl._create_builtin_node_group('MyChunk', transform=lambda x: ','.split(x))\n        self.doc_impl._lazy_init()\n        assert \"MyChunk\" in self.doc_impl.node_groups\n        assert \"CoarseChunk\" in self.doc_impl.node_groups\n        assert \"MediumChunk\" in self.doc_impl.node_groups\n        assert \"FineChunk\" in self.doc_impl.node_groups\n\n    def test_create_node_group(self):\n        self.doc_impl._lazy_init.flag.reset()\n        self.doc_impl.create_node_group(\n            name=\"CustomChunk\",\n            transform=SentenceSplitter,\n            chunk_size=512,\n            chunk_overlap=50,\n        )\n        assert \"CustomChunk\" in self.doc_impl.node_groups\n        node_group = self.doc_impl.node_groups[\"CustomChunk\"]\n        assert node_group[\"transform\"].f == SentenceSplitter\n        assert node_group[\"transform\"].kwargs[\"chunk_size\"] == 512\n        assert node_group[\"transform\"][\"kwargs\"][\"chunk_overlap\"] == 50\n\n    def test_retrieve(self):\n        self.mock_embed.return_value = \"[0.1, 0.2, 0.3]\"\n        result = self.doc_impl.retrieve(\n            query=\"test query\",\n            group_name=\"FineChunk\",\n            similarity=\"bm25\",\n            similarity_cut_off=-100,\n            index='default',\n            topk=1,\n            similarity_kws={},\n        )\n        node = result[0]\n        assert node.text == \"dummy text\"\n\n    def test_add_files(self):\n        assert self.doc_impl.store is None\n        self.doc_impl._lazy_init()\n        assert len(self.doc_impl.store.get_nodes(LAZY_ROOT_NAME)) == 1\n        new_doc = DocNode(text=\"new dummy text\", group=LAZY_ROOT_NAME)\n        new_doc._global_metadata = {RAG_DOC_PATH: self.tmp_file_b.name}\n        self.mock_directory_reader.load_data.return_value = [new_doc]\n        self.doc_impl._add_doc_to_store([self.tmp_file_b.name])\n        assert len(self.doc_impl.store.get_nodes(LAZY_ROOT_NAME)) == 2\n\nclass TestDocument(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.embed_model1 = lazyllm.TrainableModule(\"bge-large-zh-v1.5\").start()\n        cls.embed_model2 = lazyllm.TrainableModule(\"bge-m3\").start()\n\n    @classmethod\n    def tearDownClass(cls):\n        cleanup()\n\n    def test_register_global_and_local(self):\n        Document.create_node_group('Chunk1', transform=SentenceSplitter, chunk_size=512, chunk_overlap=50)\n        Document.create_node_group('Chunk2', transform=TransformArgs(\n            f=SentenceSplitter, kwargs=dict(chunk_size=256, chunk_overlap=25)))\n        doc1, doc2 = Document('rag_master'), Document('rag_master')\n        doc2.create_node_group('Chunk2', transform=dict(\n            f=SentenceSplitter, kwargs=dict(chunk_size=128, chunk_overlap=10)))\n        doc2.create_node_group('Chunk3', trans_node=True,\n                               transform=lazyllm.pipeline(SentenceSplitter(chunk_size=128, chunk_overlap=10)))\n        doc1._impl._lazy_init()\n        doc2._impl._lazy_init()\n        assert doc1._impl.node_groups['Chunk1']['transform']['kwargs']['chunk_size'] == 512\n        assert doc1._impl.node_groups['Chunk2']['transform']['kwargs']['chunk_size'] == 256\n        assert doc2._impl.node_groups['Chunk1']['transform']['kwargs']['chunk_size'] == 512\n        assert doc2._impl.node_groups['Chunk2']['transform']['kwargs']['chunk_size'] == 128\n        assert 'Chunk3' not in doc1._impl.node_groups\n        assert isinstance(doc2._impl.node_groups['Chunk3']['transform']['f'], lazyllm.pipeline)\n        assert doc2._impl.node_groups['Chunk3']['transform']['trans_node'] is True\n\n        retriever = Retriever([doc1, doc2], 'Chunk2', similarity='bm25', topk=2)\n        r = retriever('什么是道')\n        assert isinstance(r, list)\n        assert len(r) == 4\n        assert isinstance(r[0], DocNode)\n\n        retriever2 = Retriever([doc1, doc2], 'Chunk3', similarity='bm25', topk=2)\n        r = retriever2('什么是道')\n        assert isinstance(r, list)\n        assert len(r) == 2\n        assert isinstance(r[0], DocNode)\n\n    def test_create_document(self):\n        Document('rag_master')\n        Document('rag_master/')\n\n    def test_register_with_pattern(self):\n        Document.create_node_group('AdaptiveChunk1', transform=[\n            TransformArgs(f=SentenceSplitter, pattern='*.txt', kwargs=dict(chunk_size=512, chunk_overlap=50)),\n            dict(f=SentenceSplitter, kwargs=dict(chunk_size=256, chunk_overlap=25))])\n        Document.create_node_group('AdaptiveChunk2', transform=AdaptiveTransform([\n            dict(f=SentenceSplitter, pattern='*.txt', kwargs=dict(chunk_size=512, chunk_overlap=50)),\n            TransformArgs(f=SentenceSplitter, pattern=None, kwargs=dict(chunk_size=256, chunk_overlap=25))]))\n        doc = Document('rag_master')\n        doc._impl._lazy_init()\n        retriever = Retriever(doc, 'AdaptiveChunk1', similarity='bm25', topk=2)\n        retriever('什么是道')\n        retriever = Retriever(doc, 'AdaptiveChunk2', similarity='bm25', topk=2)\n        retriever('什么是道')\n\n    def test_multi_embedding_with_document(self):\n        Document(dataset_path=\"rag_master\")._impl._dlm.release()\n        document1 = Document(dataset_path=\"rag_master\", embed=self.embed_model1)\n        document1.create_node_group(name=\"sentences\", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)\n        retriever1 = Retriever(document1, group_name=\"sentences\", similarity=\"cosine\", topk=10)\n        nodes1 = retriever1(\"何为天道?\")\n        assert len(nodes1) == 10\n\n        document2 = Document(dataset_path=\"rag_master\", embed={\"m1\": self.embed_model1, \"m2\": self.embed_model2})\n        document2.create_node_group(name=\"sentences\", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)\n        retriever2 = Retriever(document2, group_name=\"sentences\", similarity=\"cosine\", topk=3)\n        nodes2 = retriever2(\"何为天道?\")\n        assert len(nodes2) >= 3\n\n        document3 = Document(dataset_path=\"rag_master\", embed={\"m1\": self.embed_model1, \"m2\": self.embed_model2})\n        document3.create_node_group(name=\"sentences\", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)\n        retriever3 = Retriever(document3, group_name=\"sentences\", similarity=\"cosine\",\n                               similarity_cut_off={\"m1\": 0.5, \"m2\": 0.55}, topk=3, output_format='content', join=True)\n        nodes3_text = retriever3(\"何为天道?\")\n        assert '观天之道' in nodes3_text or '天命之谓性' in nodes3_text\n\n    def test_find(self):\n        #       /- MediumChunk\n        #      /                /- chunk1 -- chunk11 -- chunk111\n        # root --- CoarseChunk <           /- chunk21\n        #      \\                \\- chunk2 <\n        #       \\- FineChunk               \\- chunk22\n        doc = Document('rag_master')\n        doc.create_node_group('chunk1', parent=Document.CoarseChunk,\n                              transform=dict(f=SentenceSplitter, kwargs=dict(chunk_size=256, chunk_overlap=25)))\n        doc.create_node_group('chunk11', parent='chunk1',\n                              transform=dict(f=SentenceSplitter, kwargs=dict(chunk_size=128, chunk_overlap=16)))\n        doc.create_node_group('chunk111', parent='chunk11',\n                              transform=dict(f=SentenceSplitter, kwargs=dict(chunk_size=64, chunk_overlap=12)))\n        doc.create_node_group('chunk2', parent=Document.CoarseChunk,\n                              transform=dict(f=SentenceSplitter, kwargs=dict(chunk_size=256, chunk_overlap=25)))\n        doc.create_node_group('chunk21', parent='chunk2',\n                              transform=dict(f=SentenceSplitter, kwargs=dict(chunk_size=64, chunk_overlap=8)))\n        doc.create_node_group('chunk22', parent='chunk2',\n                              transform=dict(f=SentenceSplitter, kwargs=dict(chunk_size=64, chunk_overlap=8)))\n\n        def _test_impl(group, target):\n            retriever = Retriever(doc, group, similarity='bm25', topk=3, target=target)\n            r = retriever('何为天道')\n            assert r[0]._group == target or group, f'expect {target or group}, bug get {r[0]._group}'\n\n        for group, target in [('chunk11', None), ('chunk11', 'chunk1'), (Document.CoarseChunk, 'chunk111'),\n                              ('chunk11', 'chunk22'), ('chunk111', 'chunk21'), ('chunk1', 'chunk21'),\n                              ('chunk111', 'chunk21'), ('chunk21', 'chunk1'), ('chunk22', Document.FineChunk)]:\n            _test_impl(group, target)\n\n    def test_doc_web_module(self):\n        import time\n        import requests\n        doc = Document('rag_master', manager='ui')\n        doc.create_kb_group(name='test_group')\n        doc2 = Document('rag_master', manager=doc.manager, name='test_group2')\n        doc.start()\n        time.sleep(4)\n        url = doc._manager._docweb.url\n        response = requests.get(url)\n        assert response.status_code == 200\n        assert doc2._curr_group == 'test_group2'\n        assert doc2.manager == doc.manager\n        doc.stop()\n\nclass TmpDir:\n    def __init__(self):\n        self.root_dir = os.path.expanduser(os.path.join(config['home'], 'rag_for_document_ut'))\n        self.rag_dir = os.path.join(self.root_dir, 'rag_master')\n        os.makedirs(self.rag_dir, exist_ok=True)\n\n    def __del__(self):\n        shutil.rmtree(self.root_dir)\n\nclass TestDocumentServer(unittest.TestCase):\n    def setUp(self):\n        self.dir = TmpDir()\n        self.dlm = DocListManager(path=self.dir.rag_dir, name=None, enable_path_monitoring=False)\n\n        self.doc_impl = DocImpl(embed=MagicMock(), dlm=self.dlm)\n        self.doc_impl._lazy_init()\n\n        doc_manager = DocManager(self.dlm)\n        self.server = lazyllm.ServerModule(doc_manager)\n\n        self.server.start()\n\n        url_pattern = r'(http://\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:\\d+)'\n        self.doc_server_addr = re.findall(url_pattern, self.server._url)[0]\n\n    def test_delete_files_in_store(self):\n        files = [('files', ('test1.txt', io.BytesIO(b\"John's house is in Beijing\"), 'text/palin')),\n                 ('files', ('test2.txt', io.BytesIO(b\"John's house is in Shanghai\"), 'text/plain'))]\n        metadatas = [{\"comment\": \"comment1\"}, {\"signature\": \"signature2\"}]\n        params = dict(override='true', metadatas=json.dumps(metadatas))\n\n        url = f'{self.doc_server_addr}/upload_files'\n        response = httpx.post(url, params=params, files=files, timeout=10)\n        assert response.status_code == 200 and response.json().get('code') == 200, response.json()\n        ids = response.json().get('data')[0]\n        lazyllm.LOG.error(f'debug!!! ids -> {ids}')\n        assert len(ids) == 2\n\n        time.sleep(20)  # waiting for worker thread to update newly uploaded files\n\n        # make sure that ids are written into the store\n        nodes = self.doc_impl.store.get_nodes(LAZY_ROOT_NAME)\n        for node in nodes:\n            if node.global_metadata[RAG_DOC_PATH].endswith('test1.txt'):\n                test1_docid = node.global_metadata[RAG_DOC_ID]\n            elif node.global_metadata[RAG_DOC_PATH].endswith('test2.txt'):\n                test2_docid = node.global_metadata[RAG_DOC_ID]\n        assert test1_docid and test2_docid\n        assert set([test1_docid, test2_docid]) == set(ids)\n\n        url = f'{self.doc_server_addr}/delete_files'\n        response = httpx.post(url, json=dict(file_ids=[test1_docid]))\n        assert response.status_code == 200 and response.json().get('code') == 200\n\n        time.sleep(20)  # waiting for worker thread to delete files\n\n        nodes = self.doc_impl.store.get_nodes(LAZY_ROOT_NAME)\n        assert len(nodes) == 1\n        assert nodes[0].global_metadata[RAG_DOC_ID] == test2_docid\n        cur_meta_dict = nodes[0].global_metadata\n\n        url = f'{self.doc_server_addr}/add_metadata'\n        response = httpx.post(url, json=dict(doc_ids=[test2_docid], kv_pair={\"title\": \"title2\"}))\n        assert response.status_code == 200 and response.json().get('code') == 200\n        time.sleep(20)\n        assert cur_meta_dict[\"title\"] == \"title2\"\n\n        response = httpx.post(url, json=dict(doc_ids=[test2_docid], kv_pair={\"title\": \"TITLE2\"}))\n        assert response.status_code == 200 and response.json().get('code') == 200\n        time.sleep(20)\n        assert cur_meta_dict[\"title\"] == [\"title2\", \"TITLE2\"]\n\n        url = f'{self.doc_server_addr}/delete_metadata_item'\n        response = httpx.post(url, json=dict(doc_ids=[test2_docid], keys=[\"signature\"]))\n        assert response.status_code == 200 and response.json().get('code') == 200\n        time.sleep(20)\n        assert \"signature\" not in cur_meta_dict\n\n        response = httpx.post(url, json=dict(doc_ids=[test2_docid], kv_pair={\"title\": \"TITLE2\"}))\n        assert response.status_code == 200 and response.json().get('code') == 200\n        time.sleep(20)\n        assert cur_meta_dict[\"title\"] == [\"title2\"]\n\n        url = f'{self.doc_server_addr}/update_or_create_metadata_keys'\n        response = httpx.post(url, json=dict(doc_ids=[test2_docid], kv_pair={\"signature\": \"signature2\"}))\n        assert response.status_code == 200 and response.json().get('code') == 200\n        time.sleep(20)\n        assert cur_meta_dict[\"signature\"] == \"signature2\"\n\n        url = f'{self.doc_server_addr}/reset_metadata'\n        response = httpx.post(url, json=dict(doc_ids=[test2_docid],\n                                             new_meta={\"author\": \"author2\", \"signature\": \"signature_new\"}))\n        assert response.status_code == 200 and response.json().get('code') == 200\n        time.sleep(20)\n        assert cur_meta_dict[\"signature\"] == \"signature_new\" and cur_meta_dict[\"author\"] == \"author2\"\n\n        url = f'{self.doc_server_addr}/query_metadata'\n        response = httpx.post(url, json=dict(doc_id=test2_docid))\n\n        # make sure that only one file is left\n        response = httpx.get(f'{self.doc_server_addr}/list_files')\n        assert response.status_code == 200 and len(response.json().get('data')) == 1\n\n    def tearDown(self):\n        # Must clean up the server as all uploaded files will be deleted as they are in tmp dir\n        self.dlm.release()\n\nif __name__ == \"__main__\":\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/basic_tests/test_formatter.py", "content": "from lazyllm import formatter\nimport lazyllm\n\nclass TestFormatter(object):\n\n    def test_jsonlike_formatter_base(self):\n        jsf = formatter.JsonLike\n\n        for tp in [list, tuple, lazyllm.package]:\n            origin = tp([1, 2, 3, 4, 5, 6, 7, 8])\n            assert jsf('[0]')(origin) == 1\n            assert jsf('[0, 3, 6]')(origin) == tp([1, 4, 7])\n            assert isinstance(jsf('[0, 3, 6]')(origin), tp)\n            assert jsf('[0:7:3]')(origin) == tp([1, 4, 7])\n            assert isinstance(jsf('[0:7:3]')(origin), tp)\n            assert jsf('[:]')(origin) == origin\n\n        origin = dict(a=1, b=2, c=3, d=4, e=5, f=6)\n        assert jsf('[a]')(origin) == 1\n        assert jsf('[a, c, e]')(origin) == [1, 3, 5]\n        assert jsf('[:]')(origin) == [1, 2, 3, 4, 5, 6]\n        assert jsf('{a}')(origin) == dict(a=1)\n        assert jsf('{a, b, c}')(origin) == dict(a=1, b=2, c=3)\n        assert jsf('{:}')(origin) == origin\n\n    def test_jsonlike_formatter_complex(self):\n        jsf = formatter.JsonLike\n        origin = [dict(a=[1, 2], b=[2, 3], c=[3, 4], d=[4, 5], e=[5, 6], f=[6, 7]),\n                  dict(a=[10, 20], b=[20, 30], c=[30, 40], d=[40, 50], e=[50, 60], f=[60, 70])]\n        assert jsf('[:]')(origin) == origin\n        assert jsf('[:]{:}')(origin) == origin\n        assert jsf('[:]{a, b, c, d, e, f}')(origin) == origin\n        assert jsf('[0, 1]{:}')(origin) == origin\n        assert jsf('[0, 1]{:}[:]')(origin) == origin\n        assert jsf('[0:]{:}[0, 1]')(origin) == origin\n        assert jsf('[:1]{:}[0, 1]')(origin) == [origin[0]]\n        assert jsf('[1]{a, b, c, d, e, f}[:]')(origin) == origin[1]\n        assert jsf('[0]{:}[0, 1]')(origin) == origin[0]\n\n        assert jsf('[:]{a, c, e}[0:2]')(origin) == [dict(a=[1, 2], c=[3, 4], e=[5, 6]),\n                                                    dict(a=[10, 20], c=[30, 40], e=[50, 60])]\n        assert jsf('[:]{a, c, e}[:1]')(origin) == [dict(a=[1], c=[3], e=[5]), dict(a=[10], c=[30], e=[50])]\n        assert jsf('[:]{a, c, e}[1]')(origin) == [dict(a=2, c=4, e=6), dict(a=20, c=40, e=60)]\n        assert jsf('[:][a, c, e]')(origin) == [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]]\n        assert jsf('[:][a, c, e][1:]')(origin) == [[[2], [4], [6]], [[20], [40], [60]]]\n        assert jsf('[:][e, c, a][1]')(origin) == [[6, 4, 2], [60, 40, 20]]\n\n    def test_file_formatter(self):\n        # Decode\n        filef = formatter.FileFormatter()\n        normal_output = 'hi'\n        encode_output = '<lazyllm-query>{\"query\": \"aha\", \"files\": [\"path/to/file\"]}'\n        other_output = ['a', 'b']\n        assert filef(normal_output) == normal_output\n        assert filef(other_output) == other_output\n        decode_output = filef(encode_output)\n        assert decode_output == {\"query\": \"aha\", \"files\": [\"path/to/file\"]}\n\n        # Encode\n        filef = formatter.FileFormatter(formatter='encode')\n        assert filef(normal_output) == normal_output\n        assert filef(encode_output) == encode_output\n        assert filef(other_output) == other_output\n        assert filef(decode_output) == encode_output\n\n        # Merge\n        filef = formatter.FileFormatter(formatter='merge')\n        assert filef(normal_output) == normal_output\n        assert filef(normal_output, normal_output, normal_output) == normal_output * 3\n        assert filef(normal_output, encode_output) == '<lazyllm-query>{\"query\": \"hiaha\", \"files\": [\"path/to/file\"]}'\n        assert filef(encode_output, encode_output) == ('<lazyllm-query>{\"query\": \"ahaaha\", \"files\": '\n                                                       '[\"path/to/file\", \"path/to/file\"]}')\n        assert filef(encode_output, normal_output, normal_output) == ('<lazyllm-query>{\"query\": \"ahahihi\", '\n                                                                      '\"files\": [\"path/to/file\"]}')\n"}
{"type": "test_file", "path": "tests/basic_tests/test_http_node.py", "content": "from lazyllm.tools.http_request.http_request import HttpRequest\n\nclass TestHTTPRequest(object):\n\n    def test_http_request(self):\n        http_request = HttpRequest('get', 'https://httpbin.org/ip', api_key='', headers={}, params={}, body='')\n        r = http_request()\n        assert r['status_code'] == 200\n        assert 'origin' in r['content']\n"}
{"type": "test_file", "path": "tests/basic_tests/test_index.py", "content": "import time\nimport unittest\nfrom unittest.mock import MagicMock\nfrom lazyllm.tools.rag.map_store import MapStore\nfrom lazyllm.tools.rag import DocNode, IndexBase, StoreBase, Document\nfrom lazyllm.tools.rag.default_index import DefaultIndex\nfrom lazyllm.tools.rag.similarity import register_similarity, registered_similarities\nfrom lazyllm.tools.rag.utils import parallel_do_embedding, generic_process_filters\nfrom typing import List, Optional, Dict\nfrom lazyllm.common import override\nfrom lazyllm import SentenceSplitter, Retriever\n\nclass TestDefaultIndex(unittest.TestCase):\n    def setUp(self):\n        self.mock_embed = {\n            'default': MagicMock(side_effect=self.delayed_embed),\n            'test1': MagicMock(return_value=[0, 1, 0]),\n            'test2': MagicMock(return_value=[0, 0, 1]),\n        }\n        self.mock_store = MapStore(node_groups=['group1'], embed=self.mock_embed)\n\n        # Create instance of DefaultIndex\n        self.index = DefaultIndex(embed=self.mock_embed, store=self.mock_store)\n\n        # Create mock DocNodes\n        self.doc_node_1 = DocNode(uid=\"text1\", group=\"group1\")\n        self.doc_node_1.embedding = {\"default\": [1, 0, 0], \"test1\": [1, 0, 0], \"test2\": [1, 0, 0]}\n        self.doc_node_2 = DocNode(uid=\"text2\", group=\"group1\")\n        self.doc_node_2.embedding = {\"default\": [0, 1, 0], \"test1\": [0, 1, 0], \"test2\": [0, 1, 0]}\n        self.doc_node_3 = DocNode(uid=\"text3\", group=\"group1\")\n        self.doc_node_3.embedding = {\"default\": [0, 0, 1], \"test1\": [0, 0, 1], \"test2\": [0, 0, 1]}\n        self.nodes = [self.doc_node_1, self.doc_node_2, self.doc_node_3]\n        self.mock_store.update_nodes(self.nodes)  # used by index\n\n    def delayed_embed(self, text):\n        time.sleep(3)\n        return [1, 1, 0]\n\n    def test_register_similarity(self):\n        # Register a custom similarity function\n        @register_similarity(mode=\"embedding\", batch=True)\n        def custom_similarity(query, nodes, **kwargs):\n            return [(node, 1.0) for node in nodes]\n\n        self.assertIn(\"custom_similarity\", registered_similarities)\n        self.assertEqual(\n            registered_similarities[\"custom_similarity\"][1], \"embedding\"\n        )\n\n    def test_query_cosine_similarity(self):\n        results = self.index.query(\n            query=\"test\",\n            group_name=\"group1\",\n            similarity_name=\"cosine\",\n            similarity_cut_off=0.0,\n            topk=2,\n            embed_keys=[\"default\"]\n        )\n        self.assertEqual(len(results), 2)\n        self.assertIn(self.doc_node_1, results)\n        self.assertIn(self.doc_node_2, results)\n\n    def test_invalid_similarity_name(self):\n        with self.assertRaises(ValueError):\n            self.index.query(\n                query=\"test\",\n                group_name=\"group1\",\n                similarity_name=\"invalid_similarity\",\n                similarity_cut_off=0.0,\n                topk=2,\n                embed_keys=[\"default\"]\n            )\n\n    def test_parallel_do_embedding(self):\n        for node in self.nodes:\n            node.has_embedding = MagicMock(return_value=False)\n        start_time = time.time()\n        parallel_do_embedding(self.index.embed, self.index.embed.keys(), self.nodes)\n        assert time.time() - start_time < 4, \"Parallel not used!\"\n\n    def test_query_multi_embed_similarity(self):\n        results = self.index.query(\n            query=\"test\",\n            group_name=\"group1\",\n            similarity_name=\"cosine\",\n            similarity_cut_off={\"default\": 0.8, \"test1\": 0.8, \"test2\": 0.8},\n            topk=2,\n        )\n        self.assertEqual(len(results), 2)\n        self.assertIn(self.doc_node_2, results)\n        self.assertIn(self.doc_node_3, results)\n\n    def test_query_multi_embed_one_thresholds(self):\n        results = self.index.query(\n            query=\"test\",\n            group_name=\"group1\",\n            similarity_name=\"cosine\",\n            similarity_cut_off=0.8,\n            embed_keys=[\"default\", \"test1\"],\n            topk=2,\n        )\n        print(f\"results: {results}\")\n        self.assertEqual(len(results), 1)\n        self.assertIn(self.doc_node_2, results)\n\nclass KeywordIndex(IndexBase):\n    def __init__(self, cstore: StoreBase):\n        self.store = cstore\n\n    @override\n    def update(self, nodes: List[DocNode]) -> None:\n        pass\n\n    @override\n    def remove(self, group_name: str, uids: List[str]) -> None:\n        pass\n\n    @override\n    def query(self, query: str, group_name: Optional[str] = None,\n              filters: Optional[Dict[str, List]] = None, topk: int = 5, **kwargs) -> List[DocNode]:\n        nodes = self.store.get_nodes(group_name)\n        if filters:\n            nodes = generic_process_filters(nodes, filters)\n\n        ranked_nodes = self._synthesize_answer(nodes, query)\n        return ranked_nodes[:topk]\n\n    def _synthesize_answer(self, nodes: List[DocNode], query: str) -> List[DocNode]:\n        relevant_nodes = [(node, self._is_relevant(node, query)) for node in nodes]\n        sorted_nodes = [node for node, count in sorted(relevant_nodes, key=lambda item: item[1], reverse=True)\n                        if count > 0]\n        return sorted_nodes\n\n    def _is_relevant(self, node: DocNode, query: str) -> int:\n        return node.text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\").casefold().count(\n            query.encode(\"utf-8\", \"ignore\").decode(\"utf-8\").casefold())\n\nclass TestIndex(unittest.TestCase):\n    def test_index_registration(self):\n        doc1 = Document(dataset_path=\"rag_master\", manager=False)\n        doc1.create_node_group(name=\"sentences\", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)\n        ret1 = Retriever(doc1, \"CoarseChunk\", \"bm25_chinese\", 0.003, topk=3)\n        query = \"道\"\n        nodes = ret1(query)\n        nums1 = []\n        for node in nodes:\n            nums1.append(node.text.lower().count(query.lower()))\n        assert len(nums1) == 0\n        doc2 = Document(dataset_path=\"rag_master\", manager=False)\n        doc2.create_node_group(name=\"sentences\", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)\n        doc2.register_index(\"keyword_index\", KeywordIndex, doc2.get_store())\n        ret2 = Retriever(doc2, \"CoarseChunk\", \"bm25_chinese\", 0.003, index=\"keyword_index\", topk=3)\n        nodes = ret2(query)\n        nums2 = []\n        for node in nodes:\n            nums2.append(node.text.casefold().count(query.casefold()))\n        assert all(query.casefold() in node.text.casefold() for node in nodes) and nums2 == sorted(nums2, reverse=True)\n\nif __name__ == \"__main__\":\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/basic_tests/test_launcher.py", "content": "import os\n\nimport lazyllm\nfrom lazyllm import launchers\n\n\nclass TestLauncher(object):\n\n    def test_slurm(self):\n        launcher = launchers.slurm(\n            partition='pat_rd',\n            nnode=1,\n            nproc=1,\n            ngpus=1,\n            sync=False\n        )\n        assert launcher.partition == 'pat_rd'\n\n    def test_empty(self):\n        launcher = launchers.empty()\n        assert not launcher.subprocess\n\n    def test_sco(self):\n        launcher = launchers.sco(\n            partition='pat_rd',\n            nnode=1,\n            nproc=1,\n            ngpus=1,\n            sync=False\n        )\n        assert launcher.partition == 'pat_rd'\n\n    def test_k8s(self):\n        launcher = launchers.k8s(\n            kube_config_path=\"~/.kube/config\",\n            namespace=\"lazyllm\",\n            host=\"myapp.lazyllm.com\"\n        )\n        assert launcher.namespace == \"lazyllm\"\n\n    def test_remote(self):\n        # empty launcher\n        origin_launcher = lazyllm.config.impl['launcher']\n        os.environ[\"LAZYLLM_DEFAULT_LAUNCHER\"] = 'empty'\n        lazyllm.config.add('launcher', str, 'empty', 'DEFAULT_LAUNCHER')\n        launcher = launchers.remote(\n            sync=False\n        )\n        assert type(launcher) is launchers.empty\n        assert not launcher.sync\n        os.environ[\"LAZYLLM_DEFAULT_LAUNCHER\"] = 'slurm'\n        lazyllm.config.add('launcher', str, 'empty', 'DEFAULT_LAUNCHER')\n        launcher = launchers.remote(\n            sync=False\n        )\n        assert type(launcher) is launchers.slurm\n        assert not launcher.sync\n        os.environ[\"LAZYLLM_DEFAULT_LAUNCHER\"] = 'sco'\n        lazyllm.config.add('launcher', str, 'empty', 'DEFAULT_LAUNCHER')\n        launcher = launchers.remote(\n            sync=False\n        )\n        assert type(launcher) is launchers.sco\n        assert not launcher.sync\n        os.environ[\"LAZYLLM_DEFAULT_LAUNCHER\"] = 'k8s'\n        lazyllm.config.add('launcher', str, 'empty', 'DEFAULT_LAUNCHER')\n        launcher = launchers.remote(\n            sync=True\n        )\n        assert type(launcher) is launchers.k8s\n        assert launcher.sync\n\n        os.environ[\"LAZYLLM_DEFAULT_LAUNCHER\"] = origin_launcher\n        lazyllm.config.add('launcher', str, 'empty', 'DEFAULT_LAUNCHER')\n"}
{"type": "test_file", "path": "tests/basic_tests/test_option.py", "content": "import lazyllm\n\nclass TestOption(object):\n\n    def test_option(self):\n        l1 = [1, 2]\n        l2 = [3, 4, 5]\n        o1 = lazyllm.Option(l1)\n        o2 = lazyllm.Option(l2)\n\n        expected_output = [[1, 3], [1, 4], [1, 5], [2, 3], [2, 4], [2, 5]]\n        assert list(lazyllm.OptionIter([o1, o2])) == expected_output\n\n    def test_test(self):\n\n        def get_options(x):\n            if isinstance(x, lazyllm.Option):\n                return [x]\n            else:\n                return []\n        o1 = lazyllm.Option([1, 2])\n        o2 = lazyllm.Option([o1, 3, 4])\n        o3 = lazyllm.Option([5, 6])\n\n        expected_output = ('[[<Option options=\"[1, 2]\" curr=\"1\">, 5, 1], [<Option options=\"[1, 2]\" curr=\"1\">, 5, 2], '\n                           '[<Option options=\"[1, 2]\" curr=\"1\">, 6, 1], [<Option options=\"[1, 2]\" curr=\"1\">, 6, 2], '\n                           '[3, 5], [3, 6], [4, 5], [4, 6]]')\n\n        assert str(list(lazyllm.OptionIter([o2, o3], get_options))) == expected_output\n"}
{"type": "test_file", "path": "tests/basic_tests/test_rag_reader.py", "content": "import os\nimport lazyllm\nfrom lazyllm.tools.rag.readers import ReaderBase\nfrom lazyllm.tools.rag import SimpleDirectoryReader, DocNode, Document\n\nclass YmlReader(ReaderBase):\n    def _load_data(self, file, extra_info=None, fs=None):\n        with open(file, 'r') as f:\n            data = f.read()\n            node = DocNode(text=data, metadata=extra_info or {})\n            node._content = \"Call the class YmlReader.\"\n            return [node]\n\ndef processYml(file, extra_info=None):\n    with open(file, 'r') as f:\n        data = f.read()\n        node = DocNode(text=data, metadata=extra_info or {})\n        node._content = \"Call the function processYml.\"\n        return [node]\n\nclass TestRagReader(object):\n    def setup_method(self):\n        self.doc1 = Document(dataset_path=\"ci_data/rag_reader_full\", manager=False)\n        self.doc2 = Document(dataset_path=\"ci_data/rag_reader_full\", manager=False)\n        self.datasets = os.path.join(lazyllm.config['data_path'], \"ci_data/rag_reader_full\")\n\n    def teardown_method(self):\n        self.doc1._impl._local_file_reader = {}\n        self.doc2._impl._local_file_reader = {}\n        type(self.doc1._impl)._registered_file_reader = {}\n\n    def test_reader_file(self):\n        files = [os.path.join(self.datasets, \"联网搜索.pdf\"), os.path.join(self.datasets, \"说明文档测试.docx\")]\n        reader = SimpleDirectoryReader(input_files=files)\n        docs = []\n        for doc in reader():\n            docs.append(doc)\n        assert len(docs) == 3\n\n    def test_reader_dir(self):\n        input_dir = self.datasets\n        reader = SimpleDirectoryReader(input_dir=input_dir,\n                                       exclude=[\"*.yml\", \"*.pdf\", \"*.docx\", \"*.mp4\"])\n        docs = []\n        for doc in reader():\n            docs.append(doc)\n        assert len(docs) == 23\n\n    def test_register_local_reader(self):\n        self.doc1.add_reader(\"**/*.yml\", processYml)\n        files = [os.path.join(self.datasets, \"reader_test.yml\")]\n        docs = self.doc1._impl._reader.load_data(input_files=files)\n        assert docs[0].text == \"Call the function processYml.\"\n\n    def test_register_global_reader(self):\n        Document.register_global_reader(\"**/*.yml\", processYml)\n        files = [os.path.join(self.datasets, \"reader_test.yml\")]\n        docs = self.doc1._impl._reader.load_data(input_files=files)\n        assert docs[0].text == \"Call the function processYml.\"\n\n    def test_register_local_and_global_reader(self):\n        files = [os.path.join(self.datasets, \"reader_test.yml\")]\n\n        docs1 = self.doc1._impl._reader.load_data(input_files=files)\n        assert docs1[0].text != \"Call the class YmlReader.\" and docs1[0].text != \"Call the function processYml.\"\n        Document.add_reader(\"**/*.yml\", processYml)\n        self.doc1.add_reader(\"**/*.yml\", YmlReader)\n        docs1 = self.doc1._impl._reader.load_data(input_files=files)\n        docs2 = self.doc2._impl._reader.load_data(input_files=files)\n        assert docs1[0].text == \"Call the class YmlReader.\" and docs2[0].text == \"Call the function processYml.\"\n"}
{"type": "test_file", "path": "tests/basic_tests/test_rag_utils.py", "content": "from lazyllm.tools.rag.utils import generic_process_filters\nfrom lazyllm.tools.rag.doc_node import DocNode\nfrom lazyllm.tools.rag.utils import _FileNodeIndex, sparse2normal, is_sparse\nfrom lazyllm.tools.rag.store_base import LAZY_ROOT_NAME\nfrom lazyllm.tools.rag.global_metadata import RAG_DOC_PATH\nimport unittest\n\nclass TestRagUtils:\n    def test_generic_process_filters(self):\n        nodes = [\n            DocNode(uid='1', global_metadata={'k1': 'v1', 'k2': 'v2', 'k4': 'v4'}),\n            DocNode(uid='2', global_metadata={'k1': 'v1', 'k3': 'v3', 'k5': 'v5'}),\n            DocNode(uid='3', global_metadata={'k2': 'v2', 'k3': 'v3', 'k6': 'v6'}),\n        ]\n\n        res = generic_process_filters(nodes, {'k1': 'v1'})\n        assert len(res) == 2\n        assert set([res[0]._uid, res[1]._uid]) == set([\"1\", \"2\"])\n\n        res = generic_process_filters(nodes, {'k6': 'v6'})\n        assert len(res) == 1\n        assert res[0]._uid == '3'\n\n        res = generic_process_filters(nodes, {'k2': 'v6'})\n        assert len(res) == 0\n\n    def test_sparse2normal(self):\n        embedding = {1: 3, 5: 12}\n        dim = 6\n        res = sparse2normal(embedding, dim)\n        assert len(res) == dim\n        assert res == [0, 3, 0, 0, 0, 12]\n\n        embedding = [(0, 9), (2, 14), (4, 28)]\n        dim = 8\n        res = sparse2normal(embedding, dim)\n        assert len(res) == dim\n        assert res == [9, 0, 14, 0, 28, 0, 0, 0]\n\n    def test_is_sparse(self):\n        embedding = {1: 3, 5: 12}\n        assert is_sparse(embedding)\n\n        embedding = [(0, 9), (2, 14), (4, 28)]\n        assert is_sparse(embedding)\n\n        embedding = [9, 0, 14, 0, 28, 0, 0, 0]\n        assert not is_sparse(embedding)\n\nclass TestFileNodeIndex(unittest.TestCase):\n    def setUp(self):\n        self.index = _FileNodeIndex()\n        self.node1 = DocNode(uid='1', group=LAZY_ROOT_NAME, global_metadata={RAG_DOC_PATH: \"d1\"})\n        self.node2 = DocNode(uid='2', group=LAZY_ROOT_NAME, global_metadata={RAG_DOC_PATH: \"d2\"})\n        self.files = [self.node1.global_metadata[RAG_DOC_PATH], self.node2.global_metadata[RAG_DOC_PATH]]\n\n    def test_update(self):\n        self.index.update([self.node1, self.node2])\n\n        nodes = self.index.query(self.files)\n        assert len(nodes) == len(self.files)\n\n        ret = [node.global_metadata[RAG_DOC_PATH] for node in nodes]\n        assert set(ret) == set(self.files)\n\n    def test_remove(self):\n        self.index.update([self.node1, self.node2])\n        self.index.remove([self.node2._uid])\n        ret = self.index.query([self.node2.global_metadata[RAG_DOC_PATH]])\n        assert len(ret) == 0\n\n    def test_query(self):\n        self.index.update([self.node1, self.node2])\n        ret = self.index.query([self.node2.global_metadata[RAG_DOC_PATH]])\n        assert len(ret) == 1\n        assert ret[0] is self.node2\n        ret = self.index.query([self.node1.global_metadata[RAG_DOC_PATH]])\n        assert len(ret) == 1\n        assert ret[0] is self.node1\n"}
{"type": "test_file", "path": "tests/basic_tests/test_registry.py", "content": "from lazyllm.tools import fc_register\n\ndef orig_func(self):\n    pass\n\n\nclass TestRegistry:\n    def test_register(self):\n        registered_func = fc_register('tool')(orig_func)\n        assert registered_func == orig_func\n\n    def test_register_with_new_func_name(self):\n        new_func_name = 'another_func_name'\n        registered_func = fc_register('tool')(orig_func, new_func_name)\n        assert registered_func != orig_func\n        assert registered_func.__name__ == new_func_name\n"}
{"type": "test_file", "path": "tests/basic_tests/test_transform.py", "content": "import lazyllm\nfrom lazyllm.tools.rag.transform import SentenceSplitter\nfrom lazyllm.tools.rag.doc_node import DocNode\n\n\nclass TestSentenceSplitter:\n    def setup_method(self):\n        \"\"\"Setup for tests: initialize the SentenceSplitter.\"\"\"\n        self.splitter = SentenceSplitter(chunk_size=30, chunk_overlap=10)\n\n    def test_forward(self):\n        text = \"\"\" Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\"\"\"  # noqa: E501\n        docs = [DocNode(text=text)]\n\n        result = self.splitter.batch_forward(docs, node_group='default')\n        result_texts = [n.get_text() for n in result]\n        expected_texts = [\n            \"Before college the two main things I worked on, outside of school, were writing and programming.I didn't write essays.\",  # noqa: E501\n            \"I didn't write essays.I wrote what beginning writers were supposed to write then, and probably still are: short stories.My stories were awful.\",  # noqa: E501\n            \"My stories were awful.They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\",  # noqa: E501\n        ]\n        assert result_texts == expected_texts\n\n        trans = lazyllm.pipeline(lambda x: x, self.splitter)\n        assert [n.get_text() for n in trans(docs[0])] == expected_texts\n"}
{"type": "test_file", "path": "tests/charge_tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/charge_tests/test_eval.py", "content": "import lazyllm\nfrom lazyllm.tools.eval import ResponseRelevancy, Faithfulness, LLMContextRecall, NonLLMContextRecall, ContextRelevance\n\nclass TestEvalRAG:\n\n    def setup_method(self):\n        self.data = [{\n            'question': '非洲的猴面包树果实的长度约是多少厘米？',\n            'answer': '非洲猴面包树的果实长约15至20厘米。它非常的长。',\n            'context': (\n                '非洲猴面包树是一种锦葵科猴面包树属的大型落叶乔木，原产于热带非洲，它的果实长约15至20厘米。'\n                '钙含量比菠菜高50％以上，含较高的抗氧化成分，维生素C含量是单个橙子的三倍。'),\n            'context_retrieved': ['非洲猴面包树是一种锦葵科猴面包树属的大型落叶乔木，原产于热带非洲，它的果实长约15至20厘米。',\n                                  '钙含量比菠菜高50％以上，含较高的抗氧化成分。',],\n            'context_reference': ['非洲猴面包树是一种锦葵科猴面包树属的大型落叶乔木，原产于热带非洲，它的果实长约15至20厘米。']\n        }]\n\n    def test_response_relevancy(self):\n        m = ResponseRelevancy(\n            lazyllm.OnlineChatModule(),\n            lazyllm.OnlineEmbeddingModule())\n        res = m(self.data)\n        assert isinstance(res, float)\n\n    def test_faithfulness(self):\n        m = Faithfulness(lazyllm.OnlineChatModule())\n        res = m(self.data)\n        assert isinstance(res, float)\n\n    def test_llm_context_recall(self):\n        m = LLMContextRecall(lazyllm.OnlineChatModule())\n        res = m(self.data)\n        assert isinstance(res, float)\n\n    def test_non_llm_context_recall(self):\n        m1 = NonLLMContextRecall()\n        res = m1(self.data)\n        assert res == 1.0\n\n        m2 = NonLLMContextRecall(binary=False)\n        res = m2(self.data)\n        assert res == 0.5\n\n    def test_context_relevance(self):\n        m1 = ContextRelevance()\n        res = m1(self.data)\n        assert res == 0.5\n\n        m2 = ContextRelevance(splitter='，')\n        res = m2(self.data)\n        assert res == 0.6\n"}
{"type": "test_file", "path": "tests/charge_tests/utils.py", "content": "import os\nimport re\nimport uuid\nimport datetime\n\n\nUUID_HEX = str(uuid.uuid4().hex)\nCURRENT_DAY = datetime.datetime.now().strftime(\"%Y%m%d\")\n\n\nclass SqlEgsData:\n    TEST_TABLES = [f\"employee_{CURRENT_DAY}_{UUID_HEX}\", f\"sales_{CURRENT_DAY}_{UUID_HEX}\"]\n    TEST_TABLES_INFO = {\n        \"tables\": [\n            {\n                \"name\": f\"{TEST_TABLES[0]}\",\n                \"comment\": \"员工信息表\",\n                \"columns\": [\n                    {\n                        \"name\": \"employee_id\",\n                        \"data_type\": \"Integer\",\n                        \"comment\": \"工号\",\n                        \"nullable\": False,\n                        \"is_primary_key\": True,\n                    },\n                    {\"name\": \"name\", \"data_type\": \"String\", \"comment\": \"姓名\", \"nullable\": False},\n                    {\"name\": \"department\", \"data_type\": \"String\", \"comment\": \"部门\", \"nullable\": False},\n                ],\n            },\n            {\n                \"name\": f\"{TEST_TABLES[1]}\",\n                \"comment\": \"销售额信息表\",\n                \"columns\": [\n                    {\n                        \"name\": \"employee_id\",\n                        \"data_type\": \"Integer\",\n                        \"comment\": \"工号\",\n                        \"nullable\": False,\n                        \"is_primary_key\": True,\n                    },\n                    {\"name\": \"q1_2023\", \"data_type\": \"Float\", \"comment\": \"2023年第1季度销售额\", \"nullable\": False},\n                    {\"name\": \"q2_2023\", \"data_type\": \"Float\", \"comment\": \"2023年第2季度销售额\", \"nullable\": False},\n                    {\"name\": \"q3_2023\", \"data_type\": \"Float\", \"comment\": \"2023年第3季度销售额\", \"nullable\": False},\n                    {\"name\": \"q4_2023\", \"data_type\": \"Float\", \"comment\": \"2023年第4季度销售额\", \"nullable\": False},\n                ],\n            },\n        ]\n    }\n    TEST_INSERT_SCRIPTS = [\n        f\"INSERT INTO {TEST_TABLES[0]} VALUES (1, '张三', '销售一部');\",\n        f\"INSERT INTO {TEST_TABLES[0]} VALUES (2, '李四', '销售二部');\",\n        f\"INSERT INTO {TEST_TABLES[0]} VALUES (11, '王五', '销售三部');\",\n        f\"INSERT INTO {TEST_TABLES[1]} VALUES (1, 8715.55, 8465.65, 24747.82, 3514.36);\",\n        f\"INSERT INTO {TEST_TABLES[1]} VALUES (2, 4989.23, 5103.22, 4897.98, 5322.05);\",\n        f\"INSERT INTO {TEST_TABLES[1]} VALUES (11, 5989.23, 6103.22, 2897.98, 3322.05);\",\n    ]\n    TEST_EMPLOYEE_INSERT_VALS = [\n        {\"employee_id\": 1111, \"name\": \"四一\", \"department\": \"IT\"},\n        {\"employee_id\": 11111, \"name\": \"五一\", \"department\": \"IT\"}\n    ]\n    TEST_QUERY_SCRIPTS = f\"SELECT department from {TEST_TABLES[0]} WHERE employee_id=1;\"\n\nclass MongoDBEgsData:\n    COLLECTION_NAME = f\"america_{CURRENT_DAY}_{UUID_HEX}\"\n    COLLECTION_SCHEMA_TYPE = {\n        \"_id\": \"string\",\n        \"city\": \"string\",\n        \"state\": \"string\",\n        \"pop\": \"int\",\n        \"loc\": {\"type\": \"string\", \"coordinates\": \"array of float\"},\n    }\n    COLLECTION_SCHEMA_DESC = {\n        \"city\": \"城市名\",\n        \"state\": \"两个字母的州名缩写\",\n        \"pop\": \"人口数量\",\n        \"loc\": \"城市的经纬度\",\n    }\n\n    COLLECTION_DATA = [\n        {\n            \"city\": \"New York\",\n            \"state\": \"NY\",\n            \"pop\": 8419600,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-74.0060, 40.7128]},\n        },\n        {\n            \"city\": \"Los Angeles\",\n            \"state\": \"CA\",\n            \"pop\": 3980400,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-118.2437, 34.0522]},\n        },\n        {\n            \"city\": \"Chicago\",\n            \"state\": \"IL\",\n            \"pop\": 2716000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-87.6298, 41.8781]},\n        },\n        {\n            \"city\": \"Houston\",\n            \"state\": \"TX\",\n            \"pop\": 2328000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-95.3698, 29.7604]},\n        },\n        {\n            \"city\": \"Phoenix\",\n            \"state\": \"AZ\",\n            \"pop\": 1690000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-112.0740, 33.4484]},\n        },\n        {\n            \"city\": \"Philadelphia\",\n            \"state\": \"PA\",\n            \"pop\": 1584200,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-75.1652, 39.9526]},\n        },\n        {\n            \"city\": \"San Antonio\",\n            \"state\": \"TX\",\n            \"pop\": 1547000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-98.4936, 29.4241]},\n        },\n        {\n            \"city\": \"San Diego\",\n            \"state\": \"CA\",\n            \"pop\": 1423800,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-117.1611, 32.7157]},\n        },\n        {\"city\": \"Dallas\", \"state\": \"TX\", \"pop\": 1343000, \"loc\": {\"type\": \"Point\", \"coordinates\": [-96.7970, 32.7767]}},\n        {\n            \"city\": \"San Jose\",\n            \"state\": \"CA\",\n            \"pop\": 1028000,\n            \"loc\": {\"type\": \"Point\", \"coordinates\": [-121.8863, 37.3382]},\n        },\n    ]\n\n\ndef get_db_init_keywords(db_type: str):\n    env_key = f\"LAZYLLM_{db_type.replace(' ', '_')}_URL\"\n    conn_url = os.environ.get(env_key, None)\n    assert conn_url is not None\n    pattern = (\n        rf\"{db_type.lower()}://(?P<username>[^:]+):(?P<password>.+)@(?P<host>[^:]+):(?P<port>\\d+)/(?P<database>.+)\"\n    )\n    match = re.search(pattern, conn_url)\n    assert match\n    username = match.group(\"username\")\n    password = match.group(\"password\")\n    host = match.group(\"host\")\n    port = match.group(\"port\")\n    database = match.group(\"database\")\n    return username, password, host, port, database\n"}
{"type": "test_file", "path": "tests/legacy/agent.py", "content": "import lazyllm\nfrom lazyllm import pipeline, parallel, diverter, switch, loop, ifs, Identity\n\ndef is_text(input):\n    return 'text' in input \n\ndef is_photo(input):\n    return 'photo' in input\n\ndef is_voice(input):\n    return 'voice' in input\n\ndef ptt(input):\n    assert 'photo' in input\n    return input.replace('photo', 'pttext')\n\ndef vtt(input):\n    assert 'voice' in input\n    return input.replace('voice', 'vttext')\n\ndef combine(context, input):\n    return f'{context}<eos>{input}'\n\ndef minganci(input):\n    return 'mgc' in input\n\ndef planner(input):\n    return f'<plan> {input}'\n\ndef act1(x):\n    return 'act1' in x\n\nexecutor = switch({\n    act1 : (lambda x: '<ActA-done>' + x),\n    (lambda x: 'act2' in x) : (lambda x: '<ActB-done>' + x),\n    (lambda x: 'act3' in x) : (lambda x: '<ActC-done>' + x),\n    'default' : (lambda x: '<No-action>' + x),\n})\n    \ndef chat(input):\n    return input\n\nduomotai = diverter(\n    Identity,\n    switch({\n        is_text: Identity,\n        is_photo: ptt,\n        is_voice: vtt,\n        'default': lambda x: 'invalid input'\n    })\n)\n \n# (ctx, input)\nm = lazyllm.ActionModule(\n    duomotai,\n    combine,\n    ifs(minganci, Identity, loop(\n            planner,\n            lazyllm.ActionModule(executor),\n            count=1\n        )\n    ),\n    chat\n)\n\nprint(m('ctx', 'text-act1'))\nprint(m('ctx', 'photo-act2'))\nprint(m('ctx', 'voice'))\nprint(m('mgc', 'photo'))\nprint(m.submodules)"}
{"type": "test_file", "path": "tests/doc_check/test_doc_example_check.py", "content": "import lazyllm\nfrom pathlib import Path\nimport pytest\nfrom typing import Union\nimport re\n\n\nglobal_func_names = set()\npattern = re.compile(r'^(add_english_doc\\(|add_chinese_doc\\(|add_example\\()')\n\n\ndef add_chinese_doc(obj_name, docstr, module=lazyllm):\n    pass\n\n\ndef add_english_doc(obj_name, docstr, module=lazyllm):\n    pass\n\n\ndef add_example(obj_name, docstr: Union[str, list], module=lazyllm):\n    func_name = \"test_\" + obj_name.replace(\".\", \"_\")\n    while func_name in global_func_names:\n        func_name = func_name + \"_\"\n    global_func_names.add(func_name)\n\n    if isinstance(docstr, list):\n        lines = [d for doc in docstr for d in doc.split(\"\\n\")]\n    elif isinstance(docstr, str):\n        lines = docstr.split(\"\\n\")\n    else:\n        raise TypeError(\"Expected str or list, got %s\" % type(docstr))\n    code_lines = []\n    for line in lines:\n        if line.startswith(\">>> \") or line.startswith(\"... \"):\n            code_lines.append(f\"    {line[4:]}\")\n    if len(code_lines) == 0:\n        return\n    xfail_decorator = \"@pytest.mark.xfail\"\n    func_code = f\"{xfail_decorator}\\ndef {func_name}():\\n\" + \"\\n\".join(code_lines)\n    lazyllm.LOG.info(f\"\\nTest example:\\n{func_code}\")\n    exec(func_code, globals())\n\n\ndef process_doc(doc_file):\n    with open(doc_file, \"r\", encoding=\"utf-8\") as f:\n        doc_lines = f.readlines()\n    st_idx = 0\n    for i in range(len(doc_lines)):\n        match = pattern.match(doc_lines[i])\n        if match:\n            st_idx = i\n            break\n    if st_idx == len(doc_lines):\n        return\n    doc_part = ''.join(doc_lines[st_idx:])\n    exec(doc_part, globals())\n\n\n# 先用一个运行快的例子试一下\ndoc_files = Path(\"lazyllm/docs/\").glob(\"flow.py\")\nfor doc_file in doc_files:\n    process_doc(doc_file)\n\n\nif __name__ == \"__main__\":\n    pytest.main()\n"}
{"type": "test_file", "path": "tests/basic_tests/test_module.py", "content": "import time\nimport requests\nimport pytest\n\nimport lazyllm\nimport multiprocessing\nfrom lazyllm.launcher import cleanup\n\nclass TestModule:\n\n    def setup_method(self):\n        self.base_model = 'internlm2-chat-7b'\n        self.target_path = ''\n        self.data_path = 'data_path'\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        yield\n        cleanup()\n\n    def test_ActionModule(self):\n        action_module = lazyllm.ActionModule(lambda x: x + 1)\n        assert action_module(1) == 2\n        assert action_module(10) == 11\n\n    def test_UrlModule(self):\n        def func(x):\n            return str(x) + ' after'\n        # Generate accessible URL service:\n        m1 = lazyllm.ServerModule(func)\n        m1.update()\n\n        m2 = lazyllm.UrlModule(url=m1._url)\n        assert m2._url == m1._url\n        m2.evalset([1, 'hi'])\n        m2.update()\n        assert m2.eval_result == ['1 after', 'hi after']\n\n    def test_ServerModule(self):\n        server_module = lazyllm.ServerModule(lambda x: x.upper())\n        server_module.start()\n        assert server_module('hello') == 'HELLO'\n        server_module.evalset(['input1', 'input2'])\n        server_module.eval()\n        assert server_module.eval_result == ['INPUT1', 'INPUT2']\n\n    def test_ServerModule_with_global(self):\n        lazyllm.globals['a'] = '1'\n        server_module = lazyllm.ServerModule(lambda x: x.upper() + lazyllm.globals['a'])\n        server_module.start()\n        assert server_module('hello') == 'HELLO1'\n        lazyllm.globals['a'] = '2'\n        server_module.evalset(['input1', 'input2'])\n        server_module.eval()\n        assert server_module.eval_result == ['INPUT12', 'INPUT22']\n\n    def test_TrainableModule(self):\n        tm1 = lazyllm.TrainableModule(self.base_model, self.target_path)\n        tm2 = tm1.share()\n        # tm1 and tm2 all use: ChatPrompter\n        assert tm1._prompt == tm2._prompt\n        tm1.finetune_method(lazyllm.finetune.dummy)\\\n            .deploy_method(lazyllm.deploy.dummy)\\\n            .mode('finetune').trainset(self.data_path)\n        tm1.prompt(prompt=None)\n        # tm1 use EmptyPrompter, tm2 use: ChatPrompter\n        assert tm1._prompt != tm2._prompt\n        assert type(tm2._prompt) is lazyllm.ChatPrompter\n        assert type(tm1._prompt) is lazyllm.prompter.EmptyPrompter\n        tm1.update()\n\n        res_template = \"reply for {}, and parameters is {{'do_sample': False, 'temperature': 0.1}}\"\n        inputs = 'input'\n        assert tm1(inputs) == res_template.format(inputs)\n\n        inputs = ['input1', 'input2']\n        tm1.evalset(inputs)\n        tm1.eval()\n        assert tm1.eval_result == [res_template.format(x) for x in inputs]\n        tm2.evalset(inputs)\n        tm2.eval()\n        assert tm2.eval_result == [\"\\n, and parameters is {'do_sample': False, 'temperature': 0.1}\"] * 2\n\n        tm3 = tm1.share()\n        # tm1 and tm3 use same: EmptyPrompter\n        assert type(tm3._prompt) is lazyllm.prompter.EmptyPrompter\n        assert tm1._prompt == tm3._prompt\n        tm3.evalset(inputs)\n        tm3.eval()\n        assert tm1.eval_result == tm3.eval_result\n\n        tm4 = tm2.share()\n        # tm2 and tm4 use same: ChatPrompter\n        assert type(tm4._prompt) is lazyllm.ChatPrompter\n        assert tm4._prompt == tm2._prompt\n        tm4.evalset(inputs)\n        tm4.eval()\n        assert tm4.eval_result == tm2.eval_result\n\n        # tm2 use EmptyPrompter, tm4 use: ChatPrompter\n        tm2.prompt(prompt=None)\n        assert tm2._prompt != tm4._prompt\n        assert type(tm4._prompt) is lazyllm.ChatPrompter\n        assert type(tm2._prompt) is lazyllm.prompter.EmptyPrompter\n\n        # tm5 use tm4's url\n        tm5 = lazyllm.TrainableModule(self.base_model).deploy_method(tm4._deploy_type, url=tm4._url)\n        tm5.evalset(inputs)\n        tm5.eval()\n        assert tm5.eval_result == tm4.eval_result\n\n        tm5.prompt(None)\n        tm5.evalset(inputs)\n        inputs = 'input-tm5'\n        assert tm5(inputs) == res_template.format(inputs)\n\n    def test_TrainableModule_stream(self):\n        tm = lazyllm.TrainableModule(self.base_model, self.target_path, stream=True).deploy_method(lazyllm.deploy.dummy)\n        assert tm._deploy_type == lazyllm.deploy.dummy\n        tm.prompt(None).start()\n\n        _ = tm('input')\n        re = ''.join(lazyllm.FileSystemQueue().dequeue())\n        assert re == \"reply for input, and parameters is {'do_sample': False, 'temperature': 0.1}\"\n\n        sm = lazyllm.ServerModule(tm)\n        sm.start()\n        _ = sm('input')\n        re = ''.join(lazyllm.FileSystemQueue().dequeue())\n        assert re == \"reply for input, and parameters is {'do_sample': False, 'temperature': 0.1}\"\n\n    def test_WebModule(self):\n        def func(x):\n            return 'reply ' + x\n        m = lazyllm.WebModule(func)\n        m.update()\n        time.sleep(4)\n        response = requests.get(m.url)\n        assert response.status_code == 200\n        m.stop()\n\n    # for mac\n    def test_WebModule_spawn(self):\n        m = multiprocessing.get_start_method()\n        if m != 'spawn':\n            multiprocessing.set_start_method('spawn', force=True)\n        self.test_WebModule()\n        if m != 'spawn':\n            multiprocessing.set_start_method(m, force=True)\n\n    def test_custom_module(self):\n        class MyModule(lazyllm.ModuleBase):\n            def forward(self, a, b):\n                return a + b\n\n        assert MyModule()(1, 2) == 3\n        assert lazyllm.pipeline(MyModule)(1, 2) == 3\n        assert lazyllm.pipeline(MyModule())(1, 2) == 3\n\n        class MyModule(lazyllm.ModuleBase):\n            def forward(self, a):\n                return a['a'] + a['b']\n\n        with lazyllm.parallel().sum as prl:\n            prl.m1 = MyModule\n            prl.m2 = MyModule()\n\n        assert prl(dict(a=1, b=2)) == 6\n\n        with lazyllm.warp().sum as prl:\n            prl.m1 = MyModule\n\n        assert prl([dict(a=1, b=2), dict(a=3, b=4)]) == 10\n        assert prl(dict(a=1, b=2), dict(a=3, b=4)) == 10\n"}
{"type": "test_file", "path": "tests/basic_tests/test_flow.py", "content": "import lazyllm\nfrom lazyllm import pipeline, parallel, diverter, warp, switch, ifs, loop, graph\nfrom lazyllm import barrier, bind\nimport time\nimport pytest\nimport random\n\ndef add_one(x): return x + 1\ndef xy2z(x, y, z=0): return x + y + 2 * z\ndef is_1(x): return True if x == 1 else False\ndef is_2(x): return True if x == 2 else False\ndef is_3(x): return True if x == 3 else False\ndef t1(x): return 2 * x\ndef t2(x): return 3 * x\ndef t3(x): return x\n\nclass TestFlow(object):\n\n    def test_pipeline(self):\n\n        fl = pipeline(add_one, add_one)(1)\n        assert fl == 3\n\n        with pipeline() as p:\n            p.f1 = add_one\n            p.f2 = add_one\n            p.f3 = xy2z | bind(y=p.input, z=p.f1)\n        # 2 + 4 + 2 * 3\n        assert p(2) == 12\n\n    def test_server_with_bind(self):\n        with pipeline() as ppl:\n            ppl.f1 = lambda x: str(len(x))\n            ppl.formatter = (lambda length, query: dict(length=length, query=query)) | bind(query=ppl.input)\n            ppl.f2 = lambda y: f\"The original query is : {y['query']}, length is : {y['length']}\"\n        sm = lazyllm.ServerModule(ppl)\n        sm.start()\n        query = \"Hello World\"\n        assert sm(query) == f\"The original query is : {query}, length is : {len(query)}\"\n\n    def test_parallel(self):\n        fl = parallel(add_one, add_one)(1)\n        assert fl == (2, 2)\n\n    def test_parallel_sequential(self):\n        fl = parallel.sequential(add_one, add_one)(1)\n        assert fl == (2, 2)\n\n    def test_diverter(self):\n\n        fl = diverter(add_one, add_one)(1, 2)\n        assert fl == (2, 3)\n\n        div = diverter(lambda x: x + 1, lambda x: x * 2, lambda x: -x)\n        assert div(1, 2, 3) == (2, 4, -3)\n\n        div = diverter(a=lambda x: x + 1, b=lambda x: x * 2, c=lambda x: -x).asdict\n        assert div(1, 2, 3) == {'a': 2, 'b': 4, 'c': -3}\n        assert div(dict(c=3, b=2, a=1)) == {'a': 2, 'b': 4, 'c': -3}\n\n    def test_warp(self):\n\n        fl = warp(add_one)(1, 2, 3)\n        assert fl == (2, 3, 4)\n\n    def test_switch(self):\n\n        assert switch({is_1: t1, is_2: t2}, judge_on_full_input=True)(1) == 2\n        assert switch({is_1: t1, is_2: t2}, judge_on_full_input=True)(2) == 6\n        assert not switch({is_1: t1, is_2: t2}, judge_on_full_input=True)(3)\n        assert switch({is_1: t1, is_2: t2, 'default': t3}, judge_on_full_input=True)(3) == 3\n\n        with switch(judge_on_full_input=True) as sw:\n            sw.case[is_1::t1]\n            sw.case(is_2, t2)\n            sw.case[is_3, t3]\n        assert sw(1) == 2 and sw(2) == 6 and sw(3) == 3\n\n        with switch(conversion=lambda x: x / 10, judge_on_full_input=True) as sw:\n            sw.case[is_1:t1]\n            sw.case(is_2, t2)\n            sw.case[is_3, t3]\n        assert sw(10) == 20 and sw(20) == 60 and sw(30) == 30\n\n        with switch(judge_on_full_input=False) as sw:\n            sw.case[is_1:t1]\n            sw.case(is_2, t2)\n            sw.case[is_3, t3]\n        assert sw(1, 30) == 60 and sw(2, 10) == 30 and sw(3, 5) == 5\n\n    def test_ifs(self):\n\n        assert ifs(is_1, t3, t1)(1) == 1\n        assert ifs(is_1, t3, t1)(2) == 4\n\n    def test_loop(self):\n\n        assert loop(add_one, count=2)(0) == 2\n\n        with loop(count=2) as lp:\n            lp.f1 = add_one\n            lp.f2 = add_one\n\n        assert lp(1) == 5\n\n        with loop(stop_condition=lambda x: x > 10) as lp:\n            lp.f1 = add_one\n            lp.f2 = add_one\n\n        assert lp(1) == 11\n\n    def test_barrier(self):\n        res = []\n\n        def get_data(idx):\n            res.append(idx)\n            return idx + 1\n\n        ppl = pipeline(\n            get_data,\n            parallel(\n                pipeline(\n                    get_data,\n                    barrier,\n                    get_data,\n                    barrier,\n                    get_data,\n                    get_data,\n                ),\n                pipeline(\n                    get_data,\n                    barrier,\n                    get_data,\n                    get_data,\n                    get_data,\n                    get_data,\n                    barrier,\n                    get_data,\n                ),\n            ),\n        )\n        ppl(0)\n        assert res[:3] == [0, 1, 1]\n        assert res[3:-3] in ([2, 2, 3, 4, 5], [2, 3, 2, 4, 5], [2, 3, 4, 2, 5], [2, 3, 4, 5, 2])\n        assert res[-3:] in ([6, 3, 4], [3, 6, 4], [3, 4, 6])\n\n    def test_graph(self):\n        def test1(x):\n            time.sleep(2)\n            return f'1 get {x};'\n\n        def test2(x): return f'2 get {x};'\n        def test3(x): return f'3 get {x};'\n        def add(x, y): return x + y\n        def concat(x, y): return [x, y]\n\n        with graph() as g:\n            g.test1 = test1\n            g.test2 = test2\n            g.test3 = test3\n            g.add = add\n            g.concat = concat\n\n        g.add_edge(g.start_node_name, ['test1', 'test2', 'test3'])\n        g.add_edge(['test1', 'test2'], 'add')\n        g.add_edge(['add', 'test3'], 'concat')\n        g.add_edge('concat', g.end_node_name)\n\n        assert g(1) == ['1 get 1;2 get 1;', '3 get 1;']\n\n\nclass TestFlowBind(object):\n    def test_bind_pipeline_basic(self):\n        with pipeline() as p:\n            p.f1 = add_one\n            p.f2 = add_one\n            p.f3 = xy2z | bind(y=p.input, z=p.f1)\n        assert p(2) == 12  # 4 + 2 + 2 * 3\n\n        with pipeline() as p:\n            p.f1 = add_one\n            p.f2 = add_one\n            p.f3 = xy2z | bind(y=p.input, z=p.output('f1'))\n        assert p(3) == 16  # 5 + 3 + 2 * 4\n\n    def test_bind_pipeline_unpack(self):\n        def func0(x, y, z): return lazyllm.package(x, y, z)\n        def func1(x, y, z): return lazyllm.package(x, y, z)\n        def func2(x, y, z): return lazyllm.package(x, y, z)\n        def func3(x, y, z): return lazyllm.package(x, y, z)\n\n        with lazyllm.pipeline() as ppl:\n            ppl.f1 = func1\n            with lazyllm.parallel() as ppl.pp:\n                ppl.pp.func2 = func2\n                ppl.pp.func3 = func3\n            ppl.fout = lazyllm.bind(func0, ppl.output('f1')[0], ppl.output('f1')[2], ppl.output('f1')[1])\n        assert ppl(1, 2, 3) == (1, 3, 2)\n\n        with lazyllm.pipeline() as ppl:\n            ppl.f1 = func1\n            with lazyllm.parallel() as ppl.pp:\n                ppl.pp.func2 = func2\n                ppl.pp.func3 = func3\n            ppl.fout = lazyllm.bind(func0, ppl.output('f1')[0], ppl.output('f1', unpack=True)[2:0:-1])\n        assert ppl(1, 2, 3) == (1, 3, 2)\n\n        with lazyllm.pipeline() as ppl:\n            ppl.f1 = func1\n            with lazyllm.parallel() as ppl.pp:\n                ppl.pp.func2 = func2\n                ppl.pp.func3 = func3\n            ppl.fout = lazyllm.bind(func0, ppl.output('f1', unpack=True))\n        assert ppl(1, 2, 3) == (1, 2, 3)\n\n    def test_bind_pipeline_nested(self):\n        with pipeline() as p:\n            p.f1 = add_one\n            p.f2 = add_one\n            with pipeline() as p.subp:\n                p.subp.f3 = xy2z | bind(y=p.input, z=p.output('f1'))\n\n        with pytest.raises(RuntimeError, match='pipeline.input/output can only be bind in direct member of pipeline!'):\n            p(3)\n\n        with lazyllm.save_pipeline_result():\n            assert p(3) == 16\n\n        with lazyllm.save_pipeline_result():\n            with pipeline() as p:\n                p.f1 = add_one\n                p.f2 = add_one\n                p.f3 = add_one\n                with parallel().sum as p.subp:\n                    p.subp.f3 = xy2z | bind(y=p.input, z=p.output(p.f1))\n                    p.subp.f4 = xy2z | bind(y=p.input, z=p.output('f2'))\n\n        assert p(3) == 36  # (6 + 3 + 8) + (6 + 3 + 10)\n\n        with lazyllm.save_pipeline_result(False):\n            with pytest.raises(RuntimeError,\n                               match='pipeline.input/output can only be bind in direct member of pipeline!'):\n                p(3)\n\n    def test_bind_pipeline_in_warp(self):\n        num = 5\n\n        with lazyllm.save_pipeline_result():\n            with pipeline() as ppl:\n                with warp().sum as ppl.wp:\n                    with pipeline() as ppl.wp.ppl:\n                        ppl.wp.ppl.bug = lambda x: time.sleep(random.randint(0, 30) / 1000)\n                        ppl.wp.ppl.for_output = lazyllm.ifs(lambda x, y: y is None,\n                                                            lambda x, y: [{'idx': i} for i in range(num)],\n                                                            lambda x, y: -1\n                                                            ) | bind(ppl.wp.ppl.input[\"idx\"], lazyllm._0)\n                        with warp() as ppl.wp.ppl.wp2:\n                            with pipeline() as ppl.wp.ppl.wp2.ppl:\n                                ppl.wp.ppl.wp2.ppl.bug = lambda x: time.sleep(random.randint(0, 30) / 1000)\n                                ppl.wp.ppl.wp2.ppl.for_output = lazyllm.ifs(lambda x, y, z: z is None,\n                                                                            lambda x, y, z: x * num + y,\n                                                                            lambda x, y, z: -1\n                                    ) | bind(ppl.wp.ppl.input[\"idx\"], ppl.wp.ppl.wp2.ppl.input[\"idx\"], lazyllm._0)\n\n        test_data = [{'idx': i} for i in range(num)]\n        assert ppl(test_data) == tuple(range(num * num))\n\n    def test_bind_pipeline_nested_kwargs(self):\n        with pipeline() as p:\n            p.f1 = add_one\n            p.f2 = add_one\n            with pipeline() as p.subp:\n                p.subp.f3 = xy2z | bind(y=p.kwargs['x'], z=p.output('f1'))\n\n        with pytest.raises(RuntimeError, match='pipeline.input/output can only be bind in direct member of pipeline!'):\n            p(x=3)\n\n        with lazyllm.save_pipeline_result():\n            assert p(x=3) == 16\n\n        def add(x, y): return x + y\n        with lazyllm.save_pipeline_result():\n            with pipeline() as p:\n                p.f1 = add\n                p.f2 = add_one\n                p.f3 = add_one\n                with parallel().sum as p.subp:\n                    p.subp.f3 = xy2z | bind(y=p.input, z=p.output(p.f1))\n                    p.subp.f4 = xy2z | bind(y=p.kwargs['y'], z=p.output('f2'))\n\n        assert p(1, y=3) == 34  # (6 + 1 + 8) + (6 + 3 + 10)\n\n    def test_bind_pipeline_nested_server(self):\n        def add_one(x): return x + 1\n        def xy2z(x, y, z=0): return x + y + 2 * z\n\n        with lazyllm.save_pipeline_result():\n            with pipeline() as p:\n                p.f1 = add_one\n                p.f2 = add_one\n                p.f3 = add_one\n                with parallel().sum as p.subp:\n                    p.subp.f3 = xy2z | bind(y=p.input, z=p.output('f1'))\n                    p.subp.f4 = xy2z | bind(y=p.input, z=p.output('f2'))\n\n        s = lazyllm.ServerModule(p)\n        s.start()\n        assert s(3) == 36  # (6 + 3 + 8) + (6 + 3 + 10)\n"}
{"type": "test_file", "path": "tests/basic_tests/test_store.py", "content": "import os\nimport shutil\nimport pytest\nimport tempfile\nimport unittest\nfrom unittest.mock import MagicMock\nfrom lazyllm.tools.rag.store_base import LAZY_ROOT_NAME\nfrom lazyllm.tools.rag.map_store import MapStore\nfrom lazyllm.tools.rag.chroma_store import ChromadbStore\nfrom lazyllm.tools.rag.milvus_store import MilvusStore\nfrom lazyllm.tools.rag.doc_node import DocNode\nfrom lazyllm.tools.rag.data_type import DataType\nfrom lazyllm.tools.rag.global_metadata import GlobalMetadataDesc\n\n\ndef clear_directory(directory_path):\n    if os.path.exists(directory_path):\n        for filename in os.listdir(directory_path):\n            file_path = os.path.join(directory_path, filename)\n            try:\n                if os.path.isfile(file_path) or os.path.islink(file_path):\n                    os.unlink(file_path)\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n            except Exception as e:\n                print(f\"Failed to delete {file_path}. Reason: {e}\")\n    else:\n        print(f\"The directory {directory_path} does not exist.\")\n\n# Test class for ChromadbStore\nclass TestChromadbStore(unittest.TestCase):\n    def setUp(self):\n        self.node_groups = [LAZY_ROOT_NAME, \"group1\", \"group2\"]\n        self.store_dir = tempfile.mkdtemp()\n        self.mock_embed = {\n            'default': MagicMock(return_value=[1.0, 2.0, 3.0]),\n        }\n        self.embed_dims = {\"default\": 3}\n\n        embed_keys = set(['default'])\n        group_embed_keys = {\n            LAZY_ROOT_NAME: embed_keys,\n            'group1': embed_keys,\n            'group2': embed_keys,\n        }\n        self.store = ChromadbStore(group_embed_keys=group_embed_keys, embed=self.mock_embed,\n                                   embed_dims=self.embed_dims, dir=self.store_dir)\n\n        self.store.update_nodes(\n            [DocNode(uid=\"1\", text=\"text1\", group=LAZY_ROOT_NAME, parent=None)],\n        )\n\n    def tearDown(self):\n        clear_directory(self.store_dir)\n\n    def test_initialization(self):\n        self.assertEqual(set(self.store._collections.keys()), set(self.node_groups))\n\n    def test_update_nodes(self):\n        node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\")\n        node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group2\")\n        self.store.update_nodes([node1, node2])\n        collection = self.store._collections[\"group1\"]\n        self.assertEqual(set(collection.peek(collection.count())[\"ids\"]), set([\"1\", \"2\"]))\n        nodes = self.store.get_nodes(\"group1\")\n        self.assertEqual(nodes, [node1])\n\n    def test_remove_group_nodes(self):\n        node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\")\n        node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group2\")\n        self.store.update_nodes([node1, node2])\n        collection = self.store._collections[\"group1\"]\n        self.assertEqual(collection.peek(collection.count())[\"ids\"], [\"1\", \"2\"])\n        self.store.remove_nodes(\"group1\", \"1\")\n        self.assertEqual(collection.peek(collection.count())[\"ids\"], [\"2\"])\n\n    def test_load_store(self):\n        # Set up initial data to be loaded\n        node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\", parent=None)\n        node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group1\", parent=node1)\n        self.store.update_nodes([node1, node2])\n\n        # Reset store and load from \"persistent\" storage\n        self.store._map_store._group2docs = {group: {} for group in self.node_groups}\n        self.store._load_store(self.embed_dims)\n\n        nodes = self.store.get_nodes(\"group1\")\n        self.assertEqual(len(nodes), 2)\n        self.assertEqual(nodes[0]._uid, \"1\")\n        self.assertEqual(nodes[1]._uid, \"2\")\n        self.assertEqual(nodes[1].parent._uid, \"1\")\n\n    def test_insert_dict_as_sparse_embedding(self):\n        node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\", embedding={'default': {1: 10, 2: 20}})\n        node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group1\", embedding={'default': {0: 30, 2: 50}})\n        orig_embedding_dict = {\n            node1._uid: [0, 10, 20],\n            node2._uid: [30, 0, 50],\n        }\n        self.store.update_nodes([node1, node2])\n\n        results = self.store._peek_all_documents('group1')\n        nodes = self.store._build_nodes_from_chroma(results, self.embed_dims)\n        nodes_dict = {\n            node._uid: node for node in nodes\n        }\n\n        assert nodes_dict.keys() == orig_embedding_dict.keys()\n        for uid, node in nodes_dict.items():\n            assert node.embedding['default'] == orig_embedding_dict.get(uid)\n\n    def test_all_groups(self):\n        self.assertEqual(set(self.store.all_groups()), set(self.node_groups))\n\n    def test_query(self):\n        node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\", parent=None)\n        node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group1\", parent=node1)\n        self.store.update_nodes([node1, node2])\n        res = self.store.query(query='text1', group_name='group1', embed_keys=['default'], topk=2,\n                               similarity_name='cosine', similarity_cut_off=0.000001)\n        self.assertEqual(set([node1, node2]), set(res))\n\n    def test_group_others(self):\n        node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\", parent=None)\n        node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group1\", parent=node1)\n        self.store.update_nodes([node1, node2])\n        self.assertEqual(self.store.is_group_active(\"group1\"), True)\n        self.assertEqual(self.store.is_group_active(\"group2\"), False)\n\nclass TestMapStore(unittest.TestCase):\n    def setUp(self):\n        self.mock_embed = {\n            'default': MagicMock(return_value=[1.0, 2.0, 3.0]),\n        }\n        self.node_groups = [LAZY_ROOT_NAME, \"group1\", \"group2\"]\n        self.store = MapStore(node_groups=self.node_groups, embed=self.mock_embed)\n        self.node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\", parent=None)\n        self.node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group1\", parent=self.node1)\n\n    def test_update_nodes(self):\n        self.store.update_nodes([self.node1, self.node2])\n        nodes = self.store.get_nodes(\"group1\")\n        self.assertEqual(len(nodes), 2)\n        self.assertEqual(nodes[0]._uid, \"1\")\n        self.assertEqual(nodes[1]._uid, \"2\")\n        self.assertEqual(nodes[1].parent._uid, \"1\")\n\n    def test_get_group_nodes(self):\n        self.store.update_nodes([self.node1, self.node2])\n        n1 = self.store.get_nodes(\"group1\", [\"1\"])[0]\n        self.assertEqual(n1.text, self.node1.text)\n        n2 = self.store.get_nodes(\"group1\", [\"2\"])[0]\n        self.assertEqual(n2.text, self.node2.text)\n        ids = set([self.node1._uid, self.node2._uid])\n        docs = self.store.get_nodes(\"group1\")\n        self.assertEqual(ids, set([doc._uid for doc in docs]))\n\n    def test_remove_group_nodes(self):\n        self.store.update_nodes([self.node1, self.node2])\n\n        n1 = self.store.get_nodes(\"group1\", [\"1\"])[0]\n        assert n1.text == self.node1.text\n        self.store.remove_nodes(\"group1\", [\"1\"])\n        n1 = self.store.get_nodes(\"group1\", [\"1\"])\n        assert not n1\n\n        n2 = self.store.get_nodes(\"group1\", [\"2\"])[0]\n        assert n2.text == self.node2.text\n        self.store.remove_nodes(\"group1\", [\"2\"])\n        n2 = self.store.get_nodes(\"group1\", [\"2\"])\n        assert not n2\n\n    def test_all_groups(self):\n        self.assertEqual(set(self.store.all_groups()), set(self.node_groups))\n\n    def test_query(self):\n        self.store.update_nodes([self.node1, self.node2])\n        res = self.store.query(query='text1', group_name='group1', embed_keys=['default'], topk=2,\n                               similarity_name='cosine', similarity_cut_off=0.000001)\n        self.assertEqual(set([self.node1, self.node2]), set(res))\n\n    def test_group_others(self):\n        self.store.update_nodes([self.node1, self.node2])\n        self.assertEqual(self.store.is_group_active(\"group1\"), True)\n        self.assertEqual(self.store.is_group_active(\"group2\"), False)\n\n@pytest.mark.skip_on_win\nclass TestMilvusStoreWithNormalEmbedding(unittest.TestCase):\n    def setUp(self):\n        self.mock_embed = {\n            'vec1': MagicMock(return_value=[1.0, 2.0, 3.0]),\n            'vec2': MagicMock(return_value=[400.0, 500.0, 600.0, 700.0, 800.0]),\n        }\n        self.global_metadata_desc = {\n            'comment': GlobalMetadataDesc(data_type=DataType.VARCHAR, max_size=65535, default_value=' '),\n            'signature': GlobalMetadataDesc(data_type=DataType.VARCHAR, max_size=256, default_value=' '),\n            'tags': GlobalMetadataDesc(data_type=DataType.ARRAY, element_type=DataType.INT32, max_size=128,\n                                       default_value=[]),\n        }\n\n        self.node_groups = [LAZY_ROOT_NAME, \"group1\", \"group2\"]\n        _, self.store_file = tempfile.mkstemp(suffix=\".db\")\n\n        embed_keys = set(['vec1', 'vec2'])\n        self.group_embed_keys = {\n            LAZY_ROOT_NAME: embed_keys,\n            'group1': embed_keys,\n            'group2': embed_keys,\n        }\n        self.embed_dims = {\n            \"vec1\": 3,\n            \"vec2\": 5,\n        }\n        self.embed_datatypes = {\n            'vec1': DataType.FLOAT_VECTOR,\n            'vec2': DataType.FLOAT_VECTOR,\n        }\n\n        self.kwargs = {\n            'uri': self.store_file,\n            'index_kwargs': {\n                'index_type': 'HNSW',\n                'metric_type': 'COSINE',\n            }\n        }\n\n        self.store = MilvusStore(group_embed_keys=self.group_embed_keys, embed=self.mock_embed,\n                                 embed_dims=self.embed_dims, embed_datatypes=self.embed_datatypes,\n                                 global_metadata_desc=self.global_metadata_desc, **self.kwargs)\n\n        self.node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\", parent=None,\n                             embedding={\"vec1\": [8.0, 9.0, 10.0], \"vec2\": [11.0, 12.0, 13.0, 14.0, 15.0]},\n                             metadata={'comment': 'comment1'},\n                             global_metadata={'comment': 'comment3', 'signature': 'node1', 'tags': [1, 3, 5]})\n        self.node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group1\", parent=self.node1,\n                             embedding={\"vec1\": [100.0, 200.0, 300.0], \"vec2\": [400.0, 500.0, 600.0, 700.0, 800.0]},\n                             metadata={'comment': 'comment2', 'signature': 'node2'})\n        self.node3 = DocNode(uid=\"3\", text=\"text3\", group=\"group1\", parent=None,\n                             embedding={\"vec1\": [4.0, 5.0, 6.0], \"vec2\": [16.0, 17.0, 18.0, 19.0, 20.0]},\n                             metadata={'comment': 'comment3', 'signature': 'node3'},\n                             global_metadata={'tags': [1, 2, 3]})\n\n    def tearDown(self):\n        os.remove(self.store_file)\n\n    def test_update_and_query(self):\n        self.store.update_nodes([self.node1])\n        ret = self.store.query(query='text1', group_name='group1', embed_keys=['vec2'], topk=1)\n        self.assertEqual(len(ret), 1)\n        self.assertEqual(ret[0]._uid, self.node1._uid)\n\n        self.store.update_nodes([self.node2])\n        ret = self.store.query(query='text2', group_name='group1', embed_keys=['vec2'], topk=1)\n        self.assertEqual(len(ret), 1)\n        self.assertEqual(ret[0]._uid, self.node2._uid)\n\n    def test_remove_and_query(self):\n        self.store.update_nodes([self.node1, self.node2])\n        ret = self.store.query(query='test', group_name='group1', embed_keys=['vec2'], topk=1)\n        self.assertEqual(len(ret), 1)\n        self.assertEqual(ret[0]._uid, self.node2._uid)\n\n        self.store.remove_nodes(\"group1\", [self.node2._uid])\n        ret = self.store.query(query='test', group_name='group1', embed_keys=['vec2'], topk=1)\n        self.assertEqual(len(ret), 1)\n        self.assertEqual(ret[0]._uid, self.node1._uid)\n\n    def test_all_groups(self):\n        self.assertEqual(set(self.store.all_groups()), set(self.node_groups))\n\n    def test_group_others(self):\n        self.store.update_nodes([self.node1, self.node2])\n        self.assertEqual(self.store.is_group_active(\"group1\"), True)\n        self.assertEqual(self.store.is_group_active(\"group2\"), False)\n\n    def test_query_with_filter_exist_1(self):\n        self.store.update_nodes([self.node1, self.node3])\n        ret = self.store.query(query='test', group_name='group1', embed_keys=['vec2'], topk=10,\n                               filters={'comment': ['comment3']})\n        self.assertEqual(len(ret), 1)\n        self.assertEqual(ret[0]._uid, self.node1._uid)\n\n    def test_query_with_filter_exist_2(self):\n        self.store.update_nodes([self.node1, self.node2, self.node3])\n        ret = self.store.query(query='test', group_name='group1', embed_keys=['vec2'], topk=10,\n                               filters={'comment': ['comment3']})\n        self.assertEqual(len(ret), 2)\n        self.assertEqual(set([ret[0]._uid, ret[1]._uid]), set([self.node1._uid, self.node2._uid]))\n\n    def test_query_with_filter_non_exist(self):\n        self.store.update_nodes([self.node1, self.node3])\n        ret = self.store.query(query='test', group_name='group1', embed_keys=['vec1'], topk=10,\n                               filters={'comment': ['non-exist']})\n        self.assertEqual(len(ret), 0)\n\n    def test_reload(self):\n        self.store.update_nodes([self.node1, self.node2, self.node3])\n        # reload from storage\n        del self.store\n        self.store = MilvusStore(group_embed_keys=self.group_embed_keys, embed=self.mock_embed,\n                                 embed_dims=self.embed_dims, global_metadata_desc=self.global_metadata_desc,\n                                 embed_datatypes=self.embed_datatypes, **self.kwargs)\n\n        nodes = self.store.get_nodes('group1')\n        orig_nodes = [self.node1, self.node2, self.node3]\n        self.assertEqual(set([node._uid for node in nodes]), set([node._uid for node in orig_nodes]))\n\n        for node in nodes:\n            for orig_node in orig_nodes:\n                if node._uid == orig_node._uid:\n                    self.assertEqual(node.text, orig_node.text)\n                    # builtin fields are not in orig node, so we can not use\n                    # node.global_metadata == orig_node.global_metadata\n                    for k, v in orig_node.global_metadata.items():\n                        self.assertEqual(node.global_metadata[k], v)\n                    break\n\n    # XXX `array_contains_any` is not supported in local(aka lite) mode. skip this ut\n    def _test_query_with_array_filter(self):\n        self.store.update_nodes([self.node1, self.node3])\n        ret = self.store.query(query='test', group_name='group1', embed_keys=['vec1'], topk=10,\n                               filters={'tags': [2]})\n        self.assertEqual(len(ret), 2)\n        self.assertEqual(set([ret[0]._uid, ret[1]._uid]), set([self.node1._uid, self.node2._uid]))\n\n\n@pytest.mark.skip_on_win\nclass TestMilvusStoreWithSparseEmbedding(unittest.TestCase):\n    def setUp(self):\n        self.mock_embed = {\n            'vec1': MagicMock(return_value={0: 1.0, 1: 2.0, 2: 3.0}),\n            'vec2': MagicMock(return_value={0: 400.0, 1: 500.0, 2: 600.0, 3: 700.0, 4: 800.0}),\n        }\n        self.global_metadata_desc = {\n            'comment': GlobalMetadataDesc(data_type=DataType.VARCHAR, max_size=65535, default_value=' '),\n        }\n\n        self.node_groups = [LAZY_ROOT_NAME, \"group1\", \"group2\"]\n        _, self.store_file = tempfile.mkstemp(suffix=\".db\")\n\n        embed_keys = set(['vec1', 'vec2'])\n        self.group_embed_keys = {\n            LAZY_ROOT_NAME: embed_keys,\n            'group1': embed_keys,\n            'group2': embed_keys,\n        }\n        self.embed_datatypes = {\n            'vec1': DataType.SPARSE_FLOAT_VECTOR,\n            'vec2': DataType.SPARSE_FLOAT_VECTOR,\n        }\n\n        self.kwargs = {\n            'uri': self.store_file,\n            'index_kwargs': [\n                {\n                    'embed_key': 'vec1',\n                    'index_type': 'SPARSE_INVERTED_INDEX',\n                    'metric_type': 'IP',\n                },\n                {\n                    'embed_key': 'vec2',\n                    'index_type': 'SPARSE_WAND',\n                    'metric_type': 'IP',\n                }\n            ]\n        }\n\n        self.store = MilvusStore(group_embed_keys=self.group_embed_keys, embed=self.mock_embed,\n                                 embed_dims=None, embed_datatypes=self.embed_datatypes,\n                                 global_metadata_desc=self.global_metadata_desc, **self.kwargs)\n\n        self.node1 = DocNode(uid=\"1\", text=\"text1\", group=\"group1\", parent=None,\n                             embedding={\"vec1\": {0: 1.0, 1: 2.0, 2: 3.0},\n                                        \"vec2\": {0: 400.0, 1: 500.0, 2: 600.0, 3: 700.0, 4: 800.0}})\n        self.node2 = DocNode(uid=\"2\", text=\"text2\", group=\"group1\", parent=None,\n                             embedding={\"vec1\": {0: 8.0, 1: 9.0, 2: 10.0},\n                                        \"vec2\": {0: 11.0, 1: 12.0, 2: 13.0, 3: 14.0, 4: 15.0}})\n\n    def tearDown(self):\n        os.remove(self.store_file)\n\n    def test_sparse_embedding(self):\n        self.store.update_nodes([self.node1, self.node2])\n\n        ret = self.store.query(query='test', group_name='group1', embed_keys=['vec1'], topk=1)\n        self.assertEqual(len(ret), 1)\n        self.assertEqual(ret[0]._uid, self.node2._uid)\n\n        ret = self.store.query(query='test', group_name='group1', embed_keys=['vec2'], topk=1)\n        self.assertEqual(len(ret), 1)\n        self.assertEqual(ret[0]._uid, self.node1._uid)\n"}
{"type": "test_file", "path": "tests/basic_tests/test_doc_node.py", "content": "from unittest.mock import MagicMock\nfrom lazyllm.tools.rag.doc_node import DocNode, MetadataMode\n\n\nclass TestDocNode:\n    def setup_method(self):\n        \"\"\"Setup for tests: initialize common test data.\"\"\"\n        self.text = \"This is a test document.\"\n        self.metadata = {\"author\": \"John Doe\", \"date\": \"2023-07-01\"}\n        self.embedding = [0.1, 0.2, 0.3]\n        self.node = DocNode(\n            text=self.text,\n            embedding={\"default\": self.embedding},\n        )\n        self.node.metadata = self.metadata\n        self.node.excluded_embed_metadata_keys = [\"author\"]\n        self.node.excluded_llm_metadata_keys = [\"date\"]\n\n    def test_do_embedding(self):\n        \"\"\"Test that do_embedding passes the correct content to the embed function.\"\"\"\n        mock_embed = MagicMock(return_value=[0.4, 0.5, 0.6])\n        self.node.do_embedding({\"mock\": mock_embed})\n        mock_embed.assert_called_once_with(self.node.get_text(MetadataMode.EMBED))\n\n    def test_multi_embedding(self):\n        mock_embed1 = MagicMock(return_value=[0.11, 0.12, 0.13])\n        mock_embed2 = MagicMock(return_value=[0.21, 0.22, 0.23])\n        embed = {\"test1\": mock_embed1, \"test2\": mock_embed2}\n        assert \"test1\" not in self.node.embedding.keys()\n        assert \"test2\" not in self.node.embedding.keys()\n        if miss_keys := self.node.has_missing_embedding(embed.keys()):\n            node_embed = {k: e for k, e in embed.items() if k in miss_keys}\n            self.node.do_embedding(node_embed)\n        assert \"test1\" in self.node.embedding.keys()\n        assert \"test2\" in self.node.embedding.keys()\n\n    def test_node_creation(self):\n        \"\"\"Test the creation of a DocNode.\"\"\"\n        assert self.node.text == self.text\n        assert self.node.metadata == self.metadata\n        assert self.node.embedding['default'] == self.embedding\n        assert self.node.excluded_embed_metadata_keys == [\"author\"]\n        assert self.node.excluded_llm_metadata_keys == [\"date\"]\n\n    def test_get_text(self):\n        \"\"\"Test the get_content method.\"\"\"\n        content = self.node.get_text(metadata_mode=MetadataMode.NONE)\n        assert content == self.text\n\n        content_with_metadata = self.node.get_text(metadata_mode=MetadataMode.ALL)\n        expected_content_set = {\"author: John Doe\", \"date: 2023-07-01\", self.text}\n        for s in expected_content_set:\n            assert s in content_with_metadata\n\n    def test_get_metadata_str(self):\n        \"\"\"Test the get_metadata_str method.\"\"\"\n        metadata_str_all = self.node.get_metadata_str(mode=MetadataMode.ALL)\n        expected_metadata_set = {\"author: John Doe\", \"date: 2023-07-01\"}\n        assert set(metadata_str_all.split(\"\\n\")) == expected_metadata_set\n\n        metadata_str_llm = self.node.get_metadata_str(mode=MetadataMode.LLM)\n        expected_metadata_str_llm = {\"author: John Doe\"}\n        assert set(metadata_str_llm.split(\"\\n\")) == expected_metadata_str_llm\n\n        metadata_str_embed = self.node.get_metadata_str(mode=MetadataMode.EMBED)\n        expected_metadata_str_embed = {\"date: 2023-07-01\"}\n        assert set(metadata_str_embed.split(\"\\n\")) == expected_metadata_str_embed\n\n        metadata_str_none = self.node.get_metadata_str(mode=MetadataMode.NONE)\n        assert metadata_str_none == \"\"\n\n    def test_root_node(self):\n        \"\"\"Test the root_node property.\"\"\"\n        child_node = DocNode(text=\"Child node\", parent=self.node)\n        assert child_node.root_node == self.node\n\n    def test_metadata_property(self):\n        \"\"\"Test the metadata property getter and setter.\"\"\"\n        new_metadata = {\"editor\": \"Jane Doe\"}\n        self.node.metadata = new_metadata\n        assert self.node.metadata == new_metadata\n"}
{"type": "test_file", "path": "tests/k8s_tests/test_pipeline_k8s.py", "content": "import lazyllm\nfrom lazyllm import launchers, pipeline\n\nclass TestPipelineK8s(object):\n    def test_single_pipeline(self):\n        def demo1(input): return input * 2\n\n        def demo2(input): return input * 3\n\n        def demo3(input): return input * 4\n\n        def demo4(input): return input * 5\n\n        with pipeline() as ppl:\n            ppl.m1 = lazyllm.ServerModule(demo1, launcher=launchers.k8s()).start()\n            ppl.m2 = lazyllm.ServerModule(demo2, launcher=launchers.k8s()).start()\n            ppl.m3 = lazyllm.ServerModule(demo3, launcher=launchers.k8s()).start()\n            ppl.m4 = lazyllm.ServerModule(demo4, launcher=launchers.k8s()).start()\n\n        assert ppl(2) == 240\n        lazyllm.launcher.cleanup()\n\n    def test_pipeline_server(self):\n        def demo1(input): return input * 2\n\n        def demo2(input): return input * 3\n\n        def demo3(input): return input * 4\n\n        def demo4(input): return input * 5\n\n        with pipeline() as p1:\n            p1.m1 = demo1\n            p1.m2 = demo2\n        module1 = lazyllm.ServerModule(p1, launcher=launchers.k8s())\n\n        with pipeline() as p2:\n            p2.m1 = module1\n            p2.m2 = demo3\n\n        module2 = lazyllm.ServerModule(p2, launcher=launchers.k8s())\n\n        with pipeline() as p3:\n            p3.m1 = module2\n            p3.m2 = demo4\n\n        module3 = lazyllm.ServerModule(p3, launcher=launchers.k8s())\n        module3.start()\n        assert module3(2) == 240\n        lazyllm.launcher.cleanup()\n\n    def test_nesting_pipeline(self):\n        def demo1(input): return input * 2\n\n        def demo2(input): return input * 3\n\n        def demo3(input): return input * 4\n\n        def demo4(input): return input * 5\n\n        with pipeline() as p:\n            with pipeline() as p.m1:\n                with pipeline() as p.m1.mm1:\n                    p.m1.mm1.m1 = lazyllm.ServerModule(demo1, launcher=launchers.k8s()).start()\n                    p.m1.mm1.m2 = lazyllm.ServerModule(demo2, launcher=launchers.k8s()).start()\n                p.m1.mm2 = lazyllm.ServerModule(demo3, launcher=launchers.k8s()).start()\n            p.m2 = lazyllm.ServerModule(demo4, launcher=launchers.k8s()).start()\n\n        assert p(2) == 240\n        lazyllm.launcher.cleanup()\n"}
{"type": "test_file", "path": "tests/charge_tests/test_sql_tool.py", "content": "import unittest\nfrom lazyllm.tools import SqlCall, SqlManager, DBStatus\nimport lazyllm\nfrom .utils import SqlEgsData, get_db_init_keywords\nimport datetime\nimport re\nimport pytest\n\n\n@pytest.mark.skip_on_win\n@pytest.mark.skip_on_mac\nclass TestSqlManager(unittest.TestCase):\n    @classmethod\n    def clean_obsolete_tables(cls, sql_manager: SqlManager):\n        today = datetime.datetime.now()\n        pattern = r\"^(?:employee|sales)_(\\d{8})_(\\w+)\"\n        OBSOLETE_DAYS = 2\n        existing_tables = sql_manager.get_all_tables()\n        for table_name in existing_tables:\n            match = re.match(pattern, table_name)\n            if not match:\n                continue\n            table_create_date = datetime.datetime.strptime(match.group(1), \"%Y%m%d\")\n            delta = (today - table_create_date).days\n            if delta >= OBSOLETE_DAYS:\n                sql_manager.drop_table(table_name)\n\n    @classmethod\n    def setUpClass(cls):\n        cls.sql_managers: list[SqlManager] = [SqlManager(\"SQLite\", None, None, None, None, db_name=\":memory:\",\n                                                         tables_info_dict=SqlEgsData.TEST_TABLES_INFO)]\n        # MySQL has been tested with online database.\n        for db_type in [\"PostgreSQL\"]:\n            username, password, host, port, database = get_db_init_keywords(db_type)\n            cls.sql_managers.append(SqlManager(db_type, username, password, host, port, database,\n                                               tables_info_dict=SqlEgsData.TEST_TABLES_INFO))\n        for sql_manager in cls.sql_managers:\n            cls.clean_obsolete_tables(sql_manager)\n\n            for table_name in SqlEgsData.TEST_TABLES:\n                sql_manager.execute_commit(f\"DELETE FROM {table_name}\")\n            for insert_script in SqlEgsData.TEST_INSERT_SCRIPTS:\n                sql_manager.execute_commit(insert_script)\n\n        # Recommend to use sensenova, gpt-4o, qwen online model\n        sql_llm = lazyllm.OnlineChatModule(source=\"qwen\")\n        cls.sql_calls: list[SqlCall] = []\n        for sql_manager in cls.sql_managers:\n            cls.sql_calls.append(SqlCall(sql_llm, sql_manager, use_llm_for_sql_result=True))\n\n    @classmethod\n    def tearDownClass(cls):\n        # restore to clean database\n        for sql_manager in cls.sql_managers:\n            for table_name in SqlEgsData.TEST_TABLES:\n                db_result = sql_manager.drop_table(table_name)\n                assert db_result.status == DBStatus.SUCCESS, db_result.detail\n\n    def test_manager_status(self):\n        for sql_manager in self.sql_managers:\n            db_result = sql_manager.check_connection()\n            assert db_result.status == DBStatus.SUCCESS, db_result.detail\n\n    def test_manager_orm_operation(self):\n        for sql_manager in self.sql_managers:\n            table_name = SqlEgsData.TEST_TABLES[0]\n            TableCls = sql_manager.get_table_orm_class(table_name)\n            sql_manager.insert_values(table_name, SqlEgsData.TEST_EMPLOYEE_INSERT_VALS)\n\n            with sql_manager.get_session() as session:\n                item = session.query(TableCls).filter(TableCls.employee_id == 1111).first()\n                assert item.name == \"四一\"\n\n    def test_manager_table_delete_insert_query(self):\n        # 1. Delete, as rows already exists during setUp\n        for sql_manager in self.sql_managers:\n            for table_name in SqlEgsData.TEST_TABLES:\n                sql_manager.execute_commit(f\"DELETE FROM {table_name}\")\n            str_results = sql_manager.execute_query(SqlEgsData.TEST_QUERY_SCRIPTS)\n            self.assertNotIn(\"销售一部\", str_results)\n\n        # 2. Insert, restore rows\n        for sql_manager in self.sql_managers:\n            for insert_script in SqlEgsData.TEST_INSERT_SCRIPTS:\n                sql_manager.execute_commit(insert_script)\n            str_results = sql_manager.execute_query(SqlEgsData.TEST_QUERY_SCRIPTS)\n            self.assertIn(\"销售一部\", f\"Query: {SqlEgsData.TEST_QUERY_SCRIPTS}; result: {str_results}\")\n\n    def test_llm_query_online(self):\n        for sql_call in self.sql_calls:\n            str_results = sql_call(\"去年一整年销售额最多的员工是谁，销售额是多少？\")\n            self.assertIn(\"张三\", str_results)\n\n            str_results = sql_call(\"删除员工信息表\")\n            self.assertIn(\"DROP TABLE\", str_results.upper())\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/charge_tests/test_onlineChat_fc.py", "content": "import os\nimport pytest\nimport lazyllm\nfrom lazyllm import ReactAgent, PlanAndSolveAgent, ReWOOAgent\nfrom lazyllm.tools import FunctionCall, FunctionCallAgent\nimport random\nfrom . import tools as _  # noqa F401\n\n\n@pytest.fixture()\ndef exe_onlinechat_chat(request):\n    params = request.param if hasattr(request, 'param') else {}\n    source = params.get('source', None)\n    model = params.get('model', None)\n    stream = params.get('stream', False)\n    query = params.get(\"query\", \"\")\n    if not query:\n        raise ValueError(f\"query: {query} cannot be empty.\")\n    sources = [\"kimi\", \"glm\", \"qwen\", \"sensenova\"]\n    if source is None or source not in sources:\n        raise ValueError(f\"The source {source} field must contain the value in the list {sources}\")\n    if model:\n        llm = lazyllm.OnlineChatModule(source=source, model=model, stream=stream)\n    else:\n        llm = lazyllm.OnlineChatModule(source=source, stream=stream)\n\n    print(f\"\\nStarting test 【{source}】chat\")\n    ret = llm(query, llm_chat_history=[])\n    yield ret\n    print(f\"\\n【{source}】chat test done.\")\n\n@pytest.fixture()\ndef exe_onlinechat_single_function_call(request):\n    params = request.param if hasattr(request, 'param') else {}\n    source = params.get('source', None)\n    model = params.get('model', None)\n    stream = params.get('stream', False)\n    tools = params.get(\"tools\", [])\n    query = params.get(\"query\", \"\")\n    if not query or not tools:\n        raise ValueError(f\"query: {query} and tools cannot be empty.\")\n    sources = [\"kimi\", \"glm\", \"qwen\", \"sensenova\"]\n    if source is None or source not in sources:\n        raise ValueError(f\"The source {source} field must contain the value in the list {sources}\")\n    if model:\n        llm = lazyllm.OnlineChatModule(source=source, model=model, stream=stream)\n    else:\n        llm = lazyllm.OnlineChatModule(source=source, stream=stream)\n\n    print(f\"\\nStarting test 【{source}】 function calling\")\n    fc = FunctionCall(llm, tools)\n    ret = fc(query, [])\n    yield ret\n    print(f\"\\n【{source}】 function calling test done.\")\n\n@pytest.fixture()\ndef exe_onlinechat_parallel_function_call(request):\n    params = request.param if hasattr(request, 'param') else {}\n    source = params.get('source', None)\n    model = params.get('model', None)\n    stream = params.get('stream', False)\n    tools = params.get(\"tools\", [])\n    query = params.get(\"query\", \"\")\n    if not query or not tools:\n        raise ValueError(f\"query: {query} and tools: {tools} cannot be empty.\")\n    sources = [\"kimi\", \"glm\", \"qwen\", \"sensenova\"]\n    if source is None or source not in sources:\n        raise ValueError(f\"The source {source} field must contain the value in the list {sources}\")\n    if model:\n        llm = lazyllm.OnlineChatModule(source=source, model=model, stream=stream)\n    else:\n        llm = lazyllm.OnlineChatModule(source=source, stream=stream)\n\n    agent = FunctionCallAgent(llm, tools)\n    print(f\"\\nStarting test 【{source}】parallel function calling\")\n    ret = agent(query, [])\n    yield ret\n    print(f\"\\n【{source}】parallel function calling test done.\")\n\n@pytest.fixture()\ndef exe_onlinechat_advance_agent(request):\n    params = request.param if hasattr(request, 'param') else {}\n    source = params.get('source', None)\n    model = params.get('model', None)\n    stream = params.get('stream', False)\n    tools = params.get('tools', [])\n    query = params.get('query', \"\")\n    Agent = params.get('Agent', None)\n    if not query or not tools:\n        raise ValueError(f\"query: {query} and tools: {tools} cannot be empty.\")\n    if Agent is None:\n        raise ValueError(f\"Agent: {Agent} must be a valid value.\")\n    sources = [\"kimi\", \"glm\", \"qwen\", \"sensenova\"]\n    if source is None or source not in sources:\n        raise ValueError(f\"The source {source} field must contain the value in the list {sources}\")\n    if model:\n        llm = lazyllm.OnlineChatModule(source=source, model=model, stream=stream)\n    else:\n        llm = lazyllm.OnlineChatModule(source=source, stream=stream)\n\n    agent = Agent(llm, tools)\n    print(f\"agent: {agent}\")\n    print(f\"\\nStarting test 【{source}】 {Agent}.\")\n    ret = agent(query)\n    print(f\"ret: {ret}\")\n    yield ret\n    print(f\"\\n 【{source}】{Agent} test done.\")\n\n\ntools = [\"get_current_weather\", \"get_n_day_weather_forecast\"]\nsquery = \"What's the weather like today in celsius in Tokyo.\"\nmquery = \"What's the weather like today in celsius in Tokyo and Paris.\"\nagentQuery = \"What is 20+(2*4)? Calculate step by step \"\nmodels = [\"kimi\", \"glm\", \"qwen\", \"sensenova\"]\nrewooquery = \"What is the name of the cognac house that makes the main ingredient in The Hennchata?\"\n\nclass TestOnlineChatFunctionCall(object):\n    def setup_class(self):\n        self.https_proxy_bak = os.environ.get(\"https_proxy\", '')\n        self.http_proxy_bak = os.environ.get(\"http_proxy\", '')\n        os.environ['https_proxy'] = lazyllm.config['https_proxy']\n        os.environ['http_proxy'] = lazyllm.config['https_proxy']\n\n    def teardown_class(self):\n        os.environ['https_proxy'] = self.https_proxy_bak\n        os.environ['http_proxy'] = self.http_proxy_bak\n\n    @pytest.mark.parametrize(\"exe_onlinechat_chat\",\n                             [{'source': 'sensenova', 'model': 'SenseChat-Turbo', 'query': squery}],\n                             indirect=True)\n    def test_onlinechat_chat(self, exe_onlinechat_chat):\n        ret = exe_onlinechat_chat\n        assert isinstance(ret, str, )\n\n    @pytest.mark.parametrize(\"exe_onlinechat_single_function_call\",\n                             [{'source': 'glm', \"model\": \"GLM-4-Flash\", \"tools\": tools, \"query\": squery},\n                              {'source': 'qwen', \"model\": \"qwen-turbo\", \"tools\": tools, \"query\": squery}],\n                             indirect=True)\n    def test_onlinechat_single_function_call(self, exe_onlinechat_single_function_call):\n        ret = exe_onlinechat_single_function_call\n        assert isinstance(ret, list)\n\n    @pytest.mark.parametrize(\"exe_onlinechat_parallel_function_call\",\n                             [{'source': 'kimi', 'tools': tools, 'query': mquery}],\n                             indirect=True)\n    def test_onlinechat_parallel_function_call(self, exe_onlinechat_parallel_function_call):\n        ret = exe_onlinechat_parallel_function_call\n        assert isinstance(ret, str)\n\n    @pytest.mark.parametrize(\"exe_onlinechat_advance_agent\",\n                             [{'source': random.choice(models), 'tools': ['WikipediaWorker', 'LLMWorker'],\n                               \"query\": rewooquery, \"Agent\": ReactAgent},\n                              {'source': random.choice(models), 'tools': ['multiply_tool', 'add_tool'],\n                               \"query\": agentQuery, \"Agent\": PlanAndSolveAgent},\n                              {'source': random.choice(models), 'tools': ['WikipediaWorker', 'LLMWorker'],\n                               \"query\": rewooquery, \"Agent\": ReWOOAgent}],\n                             indirect=True)\n    def test_onlinechat_advance_agent(self, exe_onlinechat_advance_agent):\n        ret = exe_onlinechat_advance_agent\n        assert \"retrying\" not in ret\n"}
{"type": "test_file", "path": "tests/advanced_tests/standard_test/test_deploy.py", "content": "import os\nimport json\nimport time\nimport pytest\nimport httpx\nimport random\nfrom gradio_client import Client\n\nimport lazyllm\nfrom lazyllm import deploy, globals\nfrom lazyllm.launcher import cleanup\nfrom lazyllm.components.formatter import encode_query_with_filepaths, decode_query_with_filepaths\nfrom lazyllm.components.utils.file_operate import image_to_base64\n\n@pytest.fixture()\ndef set_enviroment(request):\n    env_key, env_var = request.param\n    original_value = os.getenv(env_key, None)\n    os.environ[env_key] = env_var\n    lazyllm.config.refresh(env_key)\n    yield\n    if original_value:\n        os.environ[env_key] = original_value\n    else:\n        os.environ.pop(env_key, None)\n    lazyllm.config.refresh(env_key)\n\nclass TestDeploy(object):\n\n    def setup_method(self):\n        self.model_path = 'internlm2-chat-7b'\n        self.inputs = ['介绍一下你自己', '李白和李清照是什么关系', '说个笑话吧']\n        self.use_context = False\n        self.stream_output = False\n        self.append_text = False\n        self.webs = []\n        self.clients = []\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        yield\n        while self.clients:\n            client = self.clients.pop()\n            client.close()\n        while self.webs:\n            web = self.webs.pop()\n            web.stop()\n        cleanup()\n\n    def warp_into_web(self, module):\n        client = None\n        for _ in range(5):\n            try:\n                port = random.randint(10000, 30000)\n                web = lazyllm.WebModule(module, port=port)\n                web._work()\n                time.sleep(2)\n            except AssertionError as e:\n                # Port is occupied\n                if 'occupied' in e:\n                    continue\n                else:\n                    raise e\n            try:\n                client = Client(web.url, download_files=web.cach_path)\n                break\n            except httpx.ConnectError:\n                continue\n        assert client, \"Unable to create client\"\n        self.webs.append(web)\n        self.clients.append(client)\n        return web, client\n\n    def test_deploy_vllm(self):\n        m = lazyllm.TrainableModule(self.model_path, '').deploy_method(deploy.vllm)\n        m.evalset(self.inputs)\n        m.update_server()\n        m.eval()\n        assert len(m.eval_result) == len(self.inputs)\n\n    @pytest.mark.parametrize('set_enviroment',\n                             [('LAZYLLM_DEFAULT_EMBEDDING_ENGINE', ''),\n                              ('LAZYLLM_DEFAULT_EMBEDDING_ENGINE', 'transformers')],\n                             indirect=True)\n    def test_embedding(self, set_enviroment):\n        m = lazyllm.TrainableModule('bge-large-zh-v1.5').deploy_method(deploy.AutoDeploy)\n        m.update_server()\n        res = m('你好')\n        assert len(json.loads(res)) == 1024\n        res = m(['你好'])\n        assert len(json.loads(res)) == 1\n        res = m(['你好', '世界'])\n        assert len(json.loads(res)) == 2\n\n    def test_sparse_embedding(self):\n        m = lazyllm.TrainableModule('bge-m3').deploy_method((deploy.AutoDeploy, {'embed_type': 'sparse'}))\n        m.update_server()\n        res = m('你好')\n        assert isinstance(json.loads(res), dict)\n        res = m(['你好'])\n        assert len(json.loads(res)) == 1\n        res = m(['你好', '世界'])\n        assert len(json.loads(res)) == 2\n\n    def test_cross_modal_embedding(self):\n        m = lazyllm.TrainableModule('siglip')\n        m.update_server()\n        res = m('你好')\n        assert len(json.loads(res)) == 1152\n        res = m(['你好'])\n        assert len(json.loads(res)) == 1\n        res = m(['你好', '世界'])\n        assert len(json.loads(res)) == 2\n\n        image_url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n        image_path = os.path.join(lazyllm.config['data_path'], \"ci_data/ji.jpg\")\n        image_base64, mime = image_to_base64(image_path)\n        image_base64 = f'data:{mime};base64,{image_base64}'\n        res = m(image_url, modality='image')\n        assert len(json.loads(res)) == 1152\n        res = m([image_url], modality='image')\n        assert len(json.loads(res)) == 1\n        res = m([image_url, image_base64], modality='image')\n        assert len(json.loads(res)) == 2\n\n    def test_sd3(self):\n        m = lazyllm.TrainableModule('stable-diffusion-3-medium')\n        m.update_server()\n        r = m('a little cat')\n        res = decode_query_with_filepaths(r)\n        assert \"files\" in res\n        assert len(res['files']) == 1\n\n    def test_musicgen(self):\n        m = lazyllm.TrainableModule('musicgen-stereo-small')\n        m.update_server()\n        r = m('lo-fi music with a soothing melody')\n        res = decode_query_with_filepaths(r)\n        assert \"files\" in res\n        assert len(res['files']) == 1\n\n    def test_chattts(self):\n        m = lazyllm.TrainableModule('ChatTTS')\n        m.update_server()\n        r = m('你好啊，很高兴认识你。')\n        res = decode_query_with_filepaths(r)\n        assert \"files\" in res\n        assert len(res['files']) == 1\n\n    def test_stt_sensevoice(self):\n        chat = lazyllm.TrainableModule('sensevoicesmall')\n        m = lazyllm.ServerModule(chat)\n        m.update_server()\n        audio_path = os.path.join(lazyllm.config['data_path'], 'ci_data/shuidiaogetou.mp3')\n        res = m(audio_path)\n        assert '但愿人长久' in res\n        res = m(encode_query_with_filepaths(files=[audio_path]))\n        assert '但愿人长久' in res\n        res = m(f'<lazyllm-query>{{\"query\":\"hi\",\"files\":[\"{audio_path}\"]}}')\n        assert '但愿人长久' in res\n\n        _, client = self.warp_into_web(m)\n\n        def client_send(content):\n            chat_history = [[content, None]]\n            ans = client.predict(self.use_context,\n                                 chat_history,\n                                 self.stream_output,\n                                 self.append_text,\n                                 api_name=\"/_respond_stream\")\n            return ans\n        res = client_send(audio_path)[0][-1][-1]\n        assert type(res) is str\n        assert '但愿人长久' in res\n        res = client_send('hi')[0][-1][-1]\n        assert \"Only '.mp3' and '.wav' formats in the form of file paths or URLs are supported.\" == res\n\n    def test_stt_bind(self):\n        audio_path = os.path.join(lazyllm.config['data_path'], 'ci_data/shuidiaogetou.mp3')\n        with lazyllm.pipeline() as ppl:\n            ppl.m = lazyllm.TrainableModule('sensevoicesmall') | lazyllm.bind('No use inputs', lazyllm_files=ppl.input)\n        m = lazyllm.ActionModule(ppl)\n        m.update_server()\n        res = m(audio_path)\n        assert '但愿人长久' in res\n        res = m([audio_path])\n        assert '但愿人长久' in res\n        res = m(encode_query_with_filepaths(files=[audio_path]))\n        assert '但愿人长久' in res\n        res = m({\"query\": \"aha\", \"files\": [audio_path]})\n        assert '但愿人长久' in res\n\n    def test_vlm_and_lmdeploy(self):\n        chat = lazyllm.TrainableModule('Mini-InternVL-Chat-2B-V1-5')\n        m = lazyllm.ServerModule(chat)\n        m.update_server()\n        query = '这是啥？'\n        ji_path = os.path.join(lazyllm.config['data_path'], 'ci_data/ji.jpg')\n        pig_path = os.path.join(lazyllm.config['data_path'], 'ci_data/pig.png')\n\n        globals['lazyllm_files'][chat._module_id] = [pig_path]\n        assert '猪' in m(query)\n        globals['lazyllm_files'][chat._module_id] = None\n        assert '鸡' in m(f'<lazyllm-query>{{\"query\":\"{query}\",\"files\":[\"{ji_path}\"]}}')\n\n        _, client = self.warp_into_web(m)\n        # Add prefix 'lazyllm_img::' for client testing.\n        chat_history = [['lazyllm_img::' + ji_path, None], [query, None]]\n        ans = client.predict(self.use_context,\n                             chat_history,\n                             self.stream_output,\n                             self.append_text,\n                             api_name=\"/_respond_stream\")\n        res = ans[0][-1][-1]\n        assert '鸡' in res\n"}
{"type": "test_file", "path": "tests/charge_tests/test_example.py", "content": "import os\nimport time\nimport httpx\nimport pytest\nimport random\nfrom gradio_client import Client\n\nimport lazyllm\nfrom lazyllm.launcher import cleanup\nfrom lazyllm.components.formatter import encode_query_with_filepaths\n\n\nclass TestExamples(object):\n\n    def setup_method(self):\n        self.use_context = False\n        self.stream_output = False\n        self.append_text = False\n        self.env_vars = [\n            'LAZYLLM_OPENAI_API_KEY',\n            'LAZYLLM_KIMI_API_KEY',\n            'LAZYLLM_SENSENOVA_API_KEY',\n            'LAZYLLM_DOUBAO_API_KEY',\n        ]\n        self.webs = []\n        self.clients = []\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        env_vars = {}\n        for var in self.env_vars:\n            if var in os.environ:\n                env_vars[var] = os.environ[var]\n                del os.environ[var]\n                env_name = var[8:].lower()\n                lazyllm.config.add(env_name.lower(), str, \"\", env_name)\n        yield\n        for var, value in env_vars.items():\n            os.environ[var] = value\n            env_name = var[8:]\n            lazyllm.config.add(env_name.lower(), str, \"\", env_name)\n        while self.clients:\n            client = self.clients.pop()\n            client.close()\n        while self.webs:\n            web = self.webs.pop()\n            web.stop()\n        cleanup()\n\n    def warp_into_web(self, module, file_target=None):\n        client = None\n        for _ in range(5):\n            try:\n                port = random.randint(10000, 30000)\n                web = lazyllm.WebModule(module, port=port, files_target=file_target)\n                web._work()\n                time.sleep(2)\n            except AssertionError as e:\n                # Port is occupied\n                if 'occupied' in e:\n                    continue\n                else:\n                    raise e\n            try:\n                client = Client(web.url, download_files=web.cach_path)\n                break\n            except httpx.ConnectError:\n                continue\n        assert client, \"Unable to create client\"\n        self.webs.append(web)\n        self.clients.append(client)\n        return web, client\n\n    def test_chat(self):\n        from examples.chatbot_online import chat\n        chat.start()\n\n        # test chat warpped in web\n        web, client = self.warp_into_web(chat)\n        chat_history = [[query, None]]\n        ans = client.predict(self.use_context,\n                             chat_history,\n                             self.stream_output,\n                             self.append_text,\n                             api_name=\"/_respond_stream\")\n        assert ans[0][-1][-1] == 'Hello world.'\n\n    def test_vl_chat(self):\n        from examples.multimodal_chatbot_online import chat\n        chat.start()\n        query = \"图中的动物是猫吗？输出Y代表是，N代表不是。\"\n        file_path = os.path.join(lazyllm.config['data_path'], \"ci_data/ji.jpg\")\n        inputs = encode_query_with_filepaths(query, [file_path])\n        res = chat(inputs)\n        assert 'N' in res\n\n        # test vl chat warpped in web\n        web, client = self.warp_into_web(chat, file_target=chat)\n        chat_history = [[f\"lazyllm_img::{file_path}\", None], [query, None]]\n        ans = client.predict(self.use_context, chat_history, self.stream_output, self.append_text,\n                             api_name=\"/_respond_stream\")\n        assert 'N' in ans[0][-1][-1]\n\n    def test_story(self):\n        from examples.story_online import ppl\n        story = lazyllm.ActionModule(ppl)\n        story.start()\n        query = \"我的妈妈\"\n        res = story(query)\n        assert type(res) is str\n        assert len(res) >= 1024\n\n        # test story warpped in web\n        web, client = self.warp_into_web(story)\n        chat_history = [[query, None]]\n        ans = client.predict(self.use_context,\n                             chat_history,\n                             self.stream_output,\n                             self.append_text,\n                             api_name=\"/_respond_stream\")\n        res = ans[0][-1][-1]\n        assert type(res) is str\n        assert len(res) >= 1024\n\n    def test_rag(self):\n        from examples.rag_online import ppl\n        rag = lazyllm.ActionModule(ppl)\n        rag.start()\n        query = \"何为天道？\"\n        res = rag(query)\n        assert type(res) is str\n        assert len(res) >= 16\n\n        # test rag warpped in web\n        web, client = self.warp_into_web(rag)\n        chat_history = [[query, None]]\n        ans = client.predict(self.use_context,\n                             chat_history,\n                             self.stream_output,\n                             self.append_text,\n                             api_name=\"/_respond_stream\")\n        res = ans[0][-1][-1]\n        assert type(res) is str\n        assert len(res) >= 16\n\n@pytest.fixture()\ndef requestOnlineChatModule(request):\n    params = request.param if hasattr(request, \"param\") else {}\n    source = params.get(\"source\", None)\n    query = params.get(\"query\", \"\")\n    print(f\"\\nStarting test 【{source}】 Module.\")\n    chat = lazyllm.OnlineChatModule(source=source)\n    res = chat(query)\n    yield res\n    print(f\"\\n【{source}】Module test done.\")\n\nquery = \"不要发挥和扩展，请严格原样输出下面句子：Hello world.\"\n\nclass TestOnlineChatModule(object):\n    @pytest.mark.parametrize(\"requestOnlineChatModule\",\n                             [{\"source\": \"sensenova\", \"query\": query},\n                              {\"source\": \"glm\", \"query\": query},\n                              {\"source\": \"kimi\", \"query\": query},\n                              {\"source\": \"qwen\", \"query\": query},\n                              {\"source\": \"doubao\", \"query\": query}],\n                             indirect=True)\n    def test_online_chat(self, requestOnlineChatModule):\n        res = requestOnlineChatModule\n        assert res == 'Hello world.'\n"}
{"type": "test_file", "path": "tests/charge_tests/tools.py", "content": "import json\nimport lazyllm\nfrom typing import Literal\nfrom lazyllm import fc_register\nimport wikipedia\n\ndummy_code = \"def Dummy():\\n    return None\"\n\nget_current_weather_code = '''\ndef get_current_weather(location: str, unit: Literal[\"Fahrenheit\", \"Celsius\", \"C\", \"fahrenheit\", \"celsius\", \"F\"] = 'fahrenheit'):\n    \"\"\"\n    Get the current weather in a given location\n\n    Args:\n        location (str): The city and state, e.g. San Francisco, CA.\n        unit (Literal[\"Fahrenheit\", \"Celsius\", \"C\", \"fahrenheit\", \"celsius\", \"F\"]): The temperature unit to use. Infer this from the users location.\n    \"\"\"\n    if 'tokyo' in location.lower():\n        return json.dumps({'location': 'Tokyo', 'temperature': '10', 'unit': 'celsius'})\n    elif 'san francisco' in location.lower():\n        return json.dumps({'location': 'San Francisco', 'temperature': '72', 'unit': 'fahrenheit'})\n    elif 'paris' in location.lower():\n        return json.dumps({'location': 'Paris', 'temperature': '22', 'unit': 'celsius'})\n    else:\n        return json.dumps({'location': location, 'temperature': 'unknown'})\n'''  # noqa E501\n\nget_current_weather_doc = '''\nGet the current weather in a given location\n\nArgs:\n    location (str): The city and state, e.g. San Francisco, CA.\n    unit (Literal[\"Fahrenheit\", \"Celsius\", \"C\", \"fahrenheit\", \"celsius\", \"F\"]): The temperature unit to use. Infer this from the users location.\n'''  # noqa E501\n\nget_current_weather_vars = {\n    'Literal': Literal,\n    'json': json,\n}\n\n@fc_register(\"tool\")\ndef get_current_weather(location: str, unit: Literal[\"Fahrenheit\", \"Celsius\", \"C\", \"fahrenheit\", \"celsius\", \"F\"] = 'fahrenheit'):  # noqa E501\n    \"\"\"\n    Get the current weather in a given location\n\n    Args:\n        location (str): The city and state, e.g. San Francisco, CA.\n        unit (str): The temperature unit to use. Infer this from the users location.\n    \"\"\"\n    if 'tokyo' in location.lower():\n        return json.dumps({'location': 'Tokyo', 'temperature': '10', 'unit': 'celsius'})\n    elif 'san francisco' in location.lower():\n        return json.dumps({'location': 'San Francisco', 'temperature': '72', 'unit': 'fahrenheit'})\n    elif 'paris' in location.lower():\n        return json.dumps({'location': 'Paris', 'temperature': '22', 'unit': 'celsius'})\n    else:\n        return json.dumps({'location': location, 'temperature': 'unknown'})\n\nget_n_day_weather_forecast_code = '''\ndef get_n_day_weather_forecast(location: str, num_days: int, unit: Literal[\"Fahrenheit\", \"Celsius\", \"C\", \"celsius\", \"fahrenheit\", \"F\"] = 'fahrenheit'):\n    \"\"\"\n    Get an N-day weather forecast\n\n    Args:\n        location (str): The city and state, e.g. San Francisco, CA.\n        num_days (int): The number of days to forecast.\n        unit (Literal[\"Fahrenheit\", \"Celsius\", \"C\", \"celsius\", \"fahrenheit\", \"F\"]): The temperature unit to use. Infer this from the users location.\n    \"\"\"\n    if 'tokyo' in location.lower():\n        return json.dumps({'location': 'Tokyo', 'temperature': '10', 'unit': 'celsius', \"num_days\": num_days})\n    elif 'san francisco' in location.lower():\n        return json.dumps({'location': 'San Francisco', 'temperature': '72', 'unit': 'fahrenheit', \"num_days\": num_days})\n    elif 'paris' in location.lower():\n        return json.dumps({'location': 'Paris', 'temperature': '22', 'unit': 'celsius', \"num_days\": num_days})\n    else:\n        return json.dumps({'location': location, 'temperature': 'unknown'})\n'''  # noqa E501\n\nget_n_day_weather_forecast_vars = {\n    'Literal': Literal,\n    'json': json,\n}\n\n@fc_register(\"tool\")\ndef get_n_day_weather_forecast(location: str, num_days: int,\n                               unit: Literal[\"Fahrenheit\", \"Celsius\", \"C\", \"celsius\", \"fahrenheit\", \"F\"] = 'fahrenheit'):\n    \"\"\"\n    Get an N-day weather forecast\n\n    Args:\n        location (str): The city and state, e.g. San Francisco, CA.\n        num_days (int): The number of days to forecast.\n        unit (Literal[\"Fahrenheit\", \"Celsius\", \"C\", \"celsius\", \"fahrenheit\", \"F\"]): The temperature unit to use. Infer this from the users location.\n    \"\"\"  # noqa E501\n    if 'tokyo' in location.lower():\n        return json.dumps({'location': 'Tokyo', 'temperature': '10', 'unit': 'celsius', \"num_days\": num_days})\n    elif 'san francisco' in location.lower():\n        return json.dumps({'location': 'San Francisco', 'temperature': '72', 'unit': 'fahrenheit', \"num_days\": num_days})\n    elif 'paris' in location.lower():\n        return json.dumps({'location': 'Paris', 'temperature': '22', 'unit': 'celsius', \"num_days\": num_days})\n    else:\n        return json.dumps({'location': location, 'temperature': 'unknown'})\n\nmultiply_tool_code = '''\ndef multiply_tool(a: int, b: int) -> int:\n    \"\"\"\n    Multiply two integers and return the result integer\n\n    Args:\n        a (int): multiplier\n        b (int): multiplier\n\n    Returns:\n        int: result\n    \"\"\"\n    return a * b\n'''\n\n@fc_register(\"tool\")\ndef multiply_tool(a: int, b: int) -> int:\n    \"\"\"\n    Multiply two integers and return the result integer\n\n    Args:\n        a (int): multiplier\n        b (int): multiplier\n\n    Returns:\n        int: result\n    \"\"\"\n    return a * b\n\nadd_tool_code = '''\ndef add_tool(a: int, b: int):\n    \"\"\"\n    Add two integers and returns the result integer\n\n    Args:\n        a (int): addend\n        b (int): addend\n    \"\"\"\n    return a + b\n'''\n\n@fc_register(\"tool\")\ndef add_tool(a: int, b: int):\n    \"\"\"\n    Add two integers and returns the result integer\n\n    Args:\n        a (int): addend\n        b (int): addend\n    \"\"\"\n    return a + b\n\n@fc_register(\"tool\")\ndef WikipediaWorker(input: str):\n    \"\"\"\n    Worker that search for similar page contents from Wikipedia. Useful when you need to get holistic knowledge \\\n    about people, places, companies, historical events, or other subjects. The response are long and might \\\n    contain some irrelevant information. Input should be a search query.\n\n    Args:\n        input (str): search query.\n    \"\"\"\n    print(f\"wikipedia input: {input}\")\n    try:\n        evidence = wikipedia.page(input).content\n        evidence = evidence.split(\"\\n\\n\")[0]\n    except wikipedia.PageError:\n        evidence = f\"Could not find [{input}]. Similar: {wikipedia.search(input)}\"\n    except wikipedia.DisambiguationError:\n        evidence = f\"Could not find [{input}]. Similar: {wikipedia.search(input)}\"\n    print(f\"wikipedia output: {evidence}\")\n    return evidence\n\n@fc_register(\"tool\")\ndef LLMWorker(input: str):\n    \"\"\"\n    A pretrained LLM like yourself. Useful when you need to act with general world knowledge and common sense. \\\n    Prioritize it when you are confident in solving the problem yourself. Input can be any instruction.\n\n    Args:\n        input (str): instruction\n    \"\"\"\n    llm = lazyllm.OnlineChatModule(source=\"glm\", stream=False)\n    query = f\"Respond in short directly with no extra words.\\n\\n{input}\"\n    print(f\"llm query: {query}, input: {input}\")\n    response = llm(query, llm_chat_history=[])\n    print(f\"llm res: {response}\")\n    return response\n"}
{"type": "test_file", "path": "tests/charge_tests/test_engine.py", "content": "import lazyllm\nfrom lazyllm.engine import LightEngine, NodeMetaHook\nimport pytest\nfrom .utils import SqlEgsData, get_db_init_keywords\nfrom lazyllm.tools import SqlManager, DBStatus\nfrom .tools import (get_current_weather_code, get_current_weather_vars, get_current_weather_doc,\n                    get_n_day_weather_forecast_code, multiply_tool_code, add_tool_code, dummy_code)\nimport unittest\nfrom fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\nfrom fastapi.testclient import TestClient\nimport json\n\napp = FastAPI()\n\n\n@app.post(\"/mock_post\")\nasync def receive_json(data: dict):\n    return JSONResponse(content=data)\n\n\nclass TestEngine(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        client = TestClient(app)\n\n        def mock_report(self):\n            headers = {\"Content-Type\": \"application/json; charset=utf-8\"}\n            json_data = json.dumps(self._meta_info, ensure_ascii=False)\n            try:\n                lazyllm.LOG.info(f\"meta_info: {self._meta_info}\")\n                response = client.post(self.URL, data=json_data, headers=headers)\n                assert response.json() == self._meta_info, \"mock response should be same as input\"\n            except Exception as e:\n                lazyllm.LOG.warning(f\"Error sending collected data: {e}\")\n\n        NodeMetaHook.report = mock_report\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        yield\n        LightEngine().reset()\n        lazyllm.FileSystemQueue().dequeue()\n        lazyllm.FileSystemQueue(klass=\"lazy_trace\").dequeue()\n\n    def test_intent_classifier(self):\n        resources = [dict(id='0', kind='OnlineLLM', name='llm', args=dict(source=None))]\n        music = dict(id='1', kind='Code', name='m1',\n                     args=dict(code='def music(x): return f\"Music get {x}\"'))\n        draw = dict(id='2', kind='Code', name='m2',\n                    args=dict(code='def draw(x): return f\"Draw get {x}\"'))\n        chat = dict(id='3', kind='Code', name='m3',\n                    args=dict(code='def chat(x): return f\"Chat get {x}\"'))\n        nodes = [dict(id='4', kind='Intention', name='int1',\n                      args=dict(base_model='0', prompt='', constrain='', attention='',\n                                nodes={'music': music, 'draw': draw, 'chat': chat}))]\n        edges = [dict(iid=\"__start__\", oid=\"4\"), dict(iid=\"4\", oid=\"__end__\")]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources)\n        assert engine.run(gid, \"sing a song\") == 'Music get sing a song'\n        assert engine.run(gid, \"draw a hourse\") == 'Draw get draw a hourse'\n\n    def test_toolsforllm(self):\n        resources = [\n            dict(id=\"1001\", kind=\"Code\", name=\"get_current_weather\",\n                 args=(dict(code=get_current_weather_code,\n                            vars_for_code=get_current_weather_vars))),\n            dict(id=\"1002\", kind=\"Code\", name=\"get_n_day_weather_forecast\",\n                 args=dict(code=get_n_day_weather_forecast_code,\n                           vars_for_code=get_current_weather_vars)),\n            dict(id=\"1003\", kind=\"Code\", name=\"multiply_tool\",\n                 args=dict(code=multiply_tool_code)),\n            dict(id=\"1004\", kind=\"Code\", name=\"add_tool\",\n                 args=dict(code=add_tool_code)),\n        ]\n        nodes = [dict(id=\"1\", kind=\"ToolsForLLM\", name=\"fc\",\n                      args=dict(tools=['1001', '1002', '1003', '1004']))]\n        edges = [dict(iid=\"__start__\", oid=\"1\"), dict(iid=\"1\", oid=\"__end__\")]\n        engine = LightEngine()\n        engine.set_report_url(\"mock_post\")\n        gid = engine.start(nodes, edges, resources)\n        assert '22' in engine.run(gid, [dict(name='get_current_weather', arguments=dict(location='Paris'))])[0]\n\n    def test_fc(self):\n        resources = [\n            dict(id=\"0\", kind=\"OnlineLLM\", name=\"llm\", args=dict(source='glm')),\n            dict(id=\"1001\", kind=\"Code\", name=\"get_current_weather\",\n                 args=(dict(code=get_current_weather_code,\n                            vars_for_code=get_current_weather_vars))),\n            dict(id=\"1002\", kind=\"Code\", name=\"get_n_day_weather_forecast\",\n                 args=dict(code=get_n_day_weather_forecast_code,\n                           vars_for_code=get_current_weather_vars)),\n            dict(id=\"1003\", kind=\"Code\", name=\"multiply_tool\",\n                 args=dict(code=multiply_tool_code)),\n            dict(id=\"1004\", kind=\"Code\", name=\"add_tool\",\n                 args=dict(code=add_tool_code)),\n        ]\n        nodes = [dict(id=\"1\", kind=\"FunctionCall\", name=\"fc\",\n                      args=dict(llm='0', tools=['1001', '1002', '1003', '1004']))]\n        edges = [dict(iid=\"__start__\", oid=\"1\"), dict(iid=\"1\", oid=\"__end__\")]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources)\n        assert '10' in engine.run(gid, \"What's the weather like today in celsius in Tokyo.\")\n        assert '22' in engine.run(gid, \"What will the temperature be in degrees Celsius in Paris tomorrow?\")\n\n        nodes = [dict(id=\"2\", kind=\"FunctionCall\", name=\"re\",\n                      args=dict(llm='0', tools=['1003', '1004'], algorithm='React'))]\n        edges = [dict(iid=\"__start__\", oid=\"2\"), dict(iid=\"2\", oid=\"__end__\")]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources)\n        assert '5440' in engine.run(gid, \"Calculate 20*(45+23)*4, step by step.\")\n\n        nodes = [dict(id=\"3\", kind=\"FunctionCall\", name=\"re\",\n                      args=dict(llm='0', tools=['1003', '1004'], algorithm='PlanAndSolve'))]\n        edges = [dict(iid=\"__start__\", oid=\"3\"), dict(iid=\"3\", oid=\"__end__\")]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources)\n        assert '5440' in engine.run(gid, \"Calculate 20*(45+23)*(1+3), step by step.\")\n\n    def test_rag(self):\n        prompt = (\"作为国学大师，你将扮演一个人工智能国学问答助手的角色，完成一项对话任务。在这个任务中，你需要根据给定的已知国学篇章以及\"\n                  \"问题，给出你的结论。请注意，你的回答应基于给定的国学篇章，而非你的先验知识，且注意你回答的前后逻辑不要出现\"\n                  \"重复，且不需要提到具体文件名称。\\n任务示例如下：\\n示例国学篇章：《礼记 大学》大学之道，在明明德，在亲民，在止于至善\"\n                  \"。\\n问题：什么是大学？\\n回答：“大学”在《礼记》中代表的是一种理想的教育和社会实践过程，旨在通过个人的\"\n                  \"道德修养和社会实践达到最高的善治状态。\\n注意以上仅为示例，禁止在下面任务中提取或使用上述示例已知国学篇章。\"\n                  \"\\n现在，请对比以下给定的国学篇章和给出的问题。如果已知国学篇章中有该问题相关的原文，请提取相关原文出来。\\n\"\n                  \"已知国学篇章：{context_str}\\n\")\n        resources = [\n            dict(id='00', kind='OnlineEmbedding', name='e0', args=dict(source='glm')),\n            dict(id='01', kind='OnlineEmbedding', name='e1', args=dict(type='rerank')),\n            dict(id='0', kind='Document', name='d1', args=dict(dataset_path='rag_master', embed='00', node_group=[\n                dict(name='sentence', transform='SentenceSplitter', chunk_size=100, chunk_overlap=10)]))]\n        nodes = [dict(id='1', kind='Retriever', name='ret1',\n                      args=dict(doc='0', group_name='CoarseChunk', similarity='bm25_chinese', topk=3)),\n                 dict(id='2', kind='Retriever', name='ret2',\n                      args=dict(doc='0', group_name='sentence', similarity='cosine', topk=3)),\n                 dict(id='3', kind='JoinFormatter', name='c', args=dict(type='sum')),\n                 dict(id='4', kind='Reranker', name='rek1',\n                      args=dict(type='ModuleReranker', output_format='content', join=True,\n                                arguments=dict(model=\"01\", topk=3))),\n                 dict(id='5', kind='Code', name='c1',\n                      args='def test(nodes, query): return dict(context_str=nodes, query=query)'),\n                 dict(id='6', kind='OnlineLLM', name='m1',\n                      args=dict(source='glm', prompt=dict(system=prompt, user='问题: {query}')))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'), dict(iid='1', oid='3'),\n                 dict(iid='2', oid='3'), dict(iid='3', oid='4'), dict(iid='__start__', oid='4'),\n                 dict(iid='4', oid='5'), dict(iid='__start__', oid='5'), dict(iid='5', oid='6'),\n                 dict(iid='6', oid='__end__')]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources)\n        r = engine.run(gid, '何为天道?')\n        assert '观天之道，执天之行' in r or '天命之谓性，率性之谓道' in r or '执古之道，以御今之有' in r\n\n    def test_sql_call(self):\n        db_type = \"PostgreSQL\"\n        username, password, host, port, database = get_db_init_keywords(db_type)\n\n        # 1.  Init: insert data to database\n        tmp_sql_manager = SqlManager(db_type, username, password, host, port, database,\n                                     tables_info_dict=SqlEgsData.TEST_TABLES_INFO)\n        for table_name in SqlEgsData.TEST_TABLES:\n            tmp_sql_manager.execute_commit(f\"DELETE FROM {table_name}\")\n        for insert_script in SqlEgsData.TEST_INSERT_SCRIPTS:\n            tmp_sql_manager.execute_commit(insert_script)\n\n        # 2. Engine: build and chat\n        resources = [\n            dict(\n                id=\"0\",\n                kind=\"SqlManager\",\n                name=\"sql_manager\",\n                args=dict(\n                    db_type=db_type,\n                    user=username,\n                    password=password,\n                    host=host,\n                    port=port,\n                    db_name=database,\n                    options_str=\"\",\n                    tables_info_dict=SqlEgsData.TEST_TABLES_INFO,\n                ),\n            ),\n            dict(id=\"1\", kind=\"OnlineLLM\", name=\"llm\", args=dict(source=\"sensenova\")),\n        ]\n        nodes = [\n            dict(\n                id=\"2\",\n                kind=\"SqlCall\",\n                name=\"sql_call\",\n                args=dict(sql_manager=\"0\", llm=\"1\", sql_examples=\"\", _lazyllm_enable_report=True),\n            )\n        ]\n        edges = [dict(iid=\"__start__\", oid=\"2\"), dict(iid=\"2\", oid=\"__end__\")]\n        engine = LightEngine()\n        # Note: Set real http://ip:port/uri ...\n        engine.set_report_url(\"mock_post\")\n        gid = engine.start(nodes, edges, resources)\n        str_answer = engine.run(gid, \"员工编号是11的人来自哪个部门？\")\n        assert \"销售三部\" in str_answer\n\n        # 3. Release: delete data and table from database\n        for table_name in SqlEgsData.TEST_TABLES:\n            db_result = tmp_sql_manager.drop_table(table_name)\n            assert db_result.status == DBStatus.SUCCESS\n\n    def test_register_tools(self):\n        resources = [\n            dict(id=\"0\", kind=\"OnlineLLM\", name=\"llm\", args=dict(source='glm')),\n            dict(id=\"3\", kind=\"HttpTool\", name=\"weather_12345\",\n                 args=dict(code_str=get_current_weather_code,\n                           vars_for_code=get_current_weather_vars,\n                           doc=get_current_weather_doc)),\n            dict(id=\"2\", kind=\"HttpTool\", name=\"dummy_111\",\n                 args=dict(code_str=dummy_code, doc='dummy')),\n        ]\n        # `tools` in `args` is a list of ids in `resources`\n        nodes = [dict(id=\"1\", kind=\"FunctionCall\", name=\"fc\",\n                      args=dict(llm='0', tools=['3', '2']))]\n        edges = [dict(iid=\"__start__\", oid=\"1\"), dict(iid=\"1\", oid=\"__end__\")]\n        engine = LightEngine()\n        # TODO handle duplicated node id\n        gid = engine.start(nodes, edges, resources)\n\n        city_name = 'Tokyo'\n        unit = 'Celsius'\n        ret = engine.run(gid, f\"What is the temperature in {city_name} today in {unit}?\")\n        assert city_name in ret and unit in ret and '10' in ret\n\n    def test_stream_and_hostory(self):\n        builtin_history = [['水的沸点是多少？', '您好，我的答案是：水的沸点在标准大气压下是100摄氏度。'],\n                           ['世界上最大的动物是什么？', '您好，我的答案是：蓝鲸是世界上最大的动物。'],\n                           ['人一天需要喝多少水？', '您好，我的答案是：一般建议每天喝8杯水，大约2升。']]\n        nodes = [dict(id='1', kind='OnlineLLM', name='m1', args=dict(source='glm', stream=True, prompt=dict(\n                      system='请将我的问题翻译成中文。请注意，请直接输出翻译后的问题，不要反问和发挥',\n                      user='问题: {query} \\n, 翻译:'))),\n                 dict(id='2', kind='OnlineLLM', name='m2',\n                      args=dict(source='glm', stream=True,\n                                prompt=dict(system='请参考历史对话，回答问题，并保持格式不变。', user='{query}'))),\n                 dict(id='3', kind='JoinFormatter', name='join', args=dict(type='to_dict', names=['query', 'answer'])),\n                 dict(id='4', kind='OnlineLLM', stream=False, name='m3',\n                      args=dict(source='glm', history=builtin_history, prompt=dict(\n                          system='你是一个问答机器人，会根据用户的问题作出回答。',\n                          user='请结合历史对话和本轮的问题，总结我们的全部对话。本轮情况如下:\\n {query}, 回答: {answer}')))]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges=[['__start__', '1'], ['1', '2'], ['1', '3'], ['2', '3'],\n                                         ['3', '4'], ['4', '__end__']], _history_ids=['2', '4'])\n        history = [['雨后为什么会有彩虹？', '您好，我的答案是：雨后阳光通过水滴发生折射和反射形成了彩虹。'],\n                   ['月亮会发光吗？', '您好，我的答案是：月亮本身不会发光，它反射太阳光。'],\n                   ['一年有多少天', '您好，我的答案是：一年有365天，闰年有366天。']]\n\n        stream_result = ''\n        with lazyllm.ThreadPoolExecutor(1) as executor:\n            future = executor.submit(engine.run, gid, 'How many hours are there in a day?', _lazyllm_history=history)\n            while True:\n                if value := lazyllm.FileSystemQueue().dequeue():\n                    stream_result += f\"{''.join(value)}\"\n                elif future.done():\n                    break\n            result = future.result()\n            assert '一天' in stream_result and '小时' in stream_result\n            assert '您好，我的答案是' in stream_result and '24' in stream_result\n            assert ('蓝鲸' in result or '动物' in result) and '水' in result\n\n    def test_egine_online_serve_train(self):\n        envs = ['glm_api_key', 'qwen_api_key']\n        sources = ['glm', 'qwen']\n        engine = LightEngine()\n\n        for env, source in list(zip(envs, sources)):\n            token = lazyllm.config[env]\n            res = engine.online_model_get_all_trained_models(token, source=source)\n            assert isinstance(res, list)\n\n            res = engine.online_model_validate_api_key(token, source=source)\n            assert res is True\n\n            res = engine.online_model_validate_api_key(token + 'ss', source=source)\n            assert res is False\n"}
{"type": "test_file", "path": "tests/basic_tests/test_server.py", "content": "import os\nimport json\nimport requests\nfrom typing import Any\n\nimport pydantic\nfrom pydantic import BaseModel\nfrom starlette.responses import RedirectResponse\n\nimport lazyllm\nfrom lazyllm import FastapiApp as app\n\n\nclass BaseResponse(BaseModel):\n    code: int = pydantic.Field(200, description=\"API status code\")\n    msg: str = pydantic.Field(\"success\", description=\"API status message\")\n    data: Any = pydantic.Field(None, description=\"API data\")\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"code\": 200,\n                \"msg\": \"success\",\n            }\n        }\n\nclass Manager(object):\n\n    @app.get('/', response_model=BaseResponse, summary='docs')\n    def document(self):\n        return RedirectResponse(url='/docs')\n\n    @app.post('/getres')\n    def test(self):\n        return 'test'\n\n    @app.post('/getres2')\n    def test_overwrite(self):\n        return 'test_overwrite'\n\n    def __call__(self, inp):\n        return 'inps'\n\n\nclass Manager2(object):\n    @app.post('/manager2')\n    def test_manager2(self):\n        return 'manager2'\n\n\nclass Derived(Manager, Manager2):\n    def test_overwrite(self):\n        return 'test_overwrite'\n\n    @app.post('/subclass_api')\n    def test_subclass_api(self):\n        return 'subclass_api'\n\n\nclass TestServerModule(object):\n\n    def test_base_module(self):\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        m = lazyllm.ServerModule(Manager(), pythonpath=current_dir)\n        m.start()\n\n        response = requests.get(m._url.replace(\"generate\", \"docs\"))\n        assert response.status_code == 200\n\n        response = requests.post(m._url.replace(\"generate\", \"getres\"), data=json.dumps('ww'))\n        assert response.json() == \"test\"\n\n        response = requests.post(m._url.replace(\"generate\", \"getres2\"), data=json.dumps('ww'))\n        assert response.json() == \"test_overwrite\"\n\n    def test_derived_module(self):\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        m = lazyllm.ServerModule(Derived(), pythonpath=current_dir)\n        m.start()\n\n        response = requests.get(m._url.replace(\"generate\", \"docs\"))\n        assert response.status_code == 200\n\n        response = requests.post(m._url.replace(\"generate\", \"getres\"), data=json.dumps('ww'))\n        assert response.json() == \"test\"\n\n        response = requests.post(m._url.replace(\"generate\", \"manager2\"), data=json.dumps('ww'))\n        assert response.json() == \"manager2\"\n\n        response = requests.post(m._url.replace(\"generate\", \"getres2\"), data=json.dumps('ww'))\n        assert response.status_code == 404\n\n        response = requests.post(m._url.replace(\"generate\", \"subclass_api\"), data=json.dumps('ww'))\n        assert response.json() == \"subclass_api\"\n"}
{"type": "test_file", "path": "tests/basic_tests/test_engine.py", "content": "from lazyllm.engine import LightEngine\nimport pytest\nimport time\nfrom gradio_client import Client\nimport lazyllm\nimport urllib3\nfrom lazyllm.common.common import TimeoutException\nimport json\nimport unittest\nimport subprocess\nimport socket\nimport threading\nimport requests\n\nHOOK_PORT = 33733\nHOOK_ROUTE = \"mock_post\"\nfastapi_code = \"\"\"\nfrom fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\nfrom collections import deque\n\napp = FastAPI()\nreceived_datas = deque(maxlen=100)\n\n\n@app.post(\"/{route}\")\nasync def receive_json(data: dict):\n    print(\"Received json data:\", data)\n    received_datas.append(data)\n    return JSONResponse(content=data)\n\n@app.get(\"/get_last_report\")\nasync def get_last_report():\n    if len(received_datas) > 0:\n        return received_datas[-1]\n    else:\n        return {{}}\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port={port})\n\"\"\".format(\n    port=HOOK_PORT, route=HOOK_ROUTE\n)\n\n\nclass TestEngine(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.fastapi_process = subprocess.Popen(\n            [\"python\", \"-c\", fastapi_code],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n        hostname = socket.gethostname()\n        ip_address = socket.gethostbyname(hostname)\n        cls.report_url = f\"http://{ip_address}:{HOOK_PORT}/{HOOK_ROUTE}\"\n        cls.get_url = f\"http://{ip_address}:{HOOK_PORT}/get_last_report\"\n\n        def read_stdout(process):\n            for line in iter(process.stdout.readline, b''):\n                print(\"FastAPI Server Output: \", line.decode(), end='')\n\n        cls.report_print_thread = threading.Thread(\n            target=read_stdout, args=(cls.fastapi_process,)\n        )\n        cls.report_print_thread.daemon = True\n        cls.report_print_thread.start()\n\n    @classmethod\n    def tearDownClass(cls):\n        time.sleep(3)\n        cls.fastapi_process.terminate()\n        cls.fastapi_process.wait()\n\n    def get_last_report(self):\n        r = requests.get(self.get_url)\n        json_obj = {}\n        try:\n            json_obj = json.loads(r.content)\n        except Exception as e:\n            lazyllm.LOG.warning(str(e))\n        return json_obj\n\n    @pytest.fixture(autouse=True)\n    def run_around_tests(self):\n        yield\n        LightEngine().reset()\n        lazyllm.FileSystemQueue().dequeue()\n        lazyllm.FileSystemQueue(klass=\"lazy_trace\").dequeue()\n\n    def test_engine_subgraph(self):\n        resources = [dict(id='0', kind='LocalLLM', name='m1', args=dict(base_model='', deploy_method='dummy'))]\n        nodes = [dict(id='1', kind='SharedLLM', name='s1', args=dict(llm='0', prompt=None))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='1', oid='__end__')]\n\n        nodes = [dict(id='2', kind='SubGraph', name='s1', args=dict(nodes=nodes, edges=edges))]\n        edges = [dict(iid='__start__', oid='2'), dict(iid='2', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources)\n        r = engine.run(gid, '1234')\n        assert 'reply for You are an AI-Agent developed by LazyLLM' in r\n        assert '1234' in r\n\n    def test_engine_code(self):\n        nodes = [dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return 2 * x\\n'))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='1', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == 2\n        assert engine.run(gid, 2) == 4\n\n    def test_engine_switch_and_diverter(self):\n        plus1 = dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return 1 + x\\n'))\n        double = dict(id='2', kind='Code', name='m2', args=dict(code='def test(x: int):\\n    return 2 * x\\n'))\n        square = dict(id='3', kind='Code', name='m3',\n                      args=dict(code='def test(x: int):\\n    return x * x\\n', _lazyllm_enable_report=True))\n        switch = dict(id=\"4\", kind=\"Switch\", name=\"s1\", args=dict(\n            judge_on_full_input=True, nodes={1: [double], 2: [plus1, double], 3: [square]}, _lazyllm_enable_report=True))\n        edges = [dict(iid='__start__', oid='4'), dict(iid='4', oid='__end__')]\n        engine = LightEngine()\n        engine.set_report_url(self.report_url)\n        gid = engine.start([switch], edges)\n        assert engine.run(gid, 1) == 2\n        assert engine.run(gid, 2) == 6\n        assert engine.run(gid, 3) == 9\n\n        diverter = dict(id=\"5\", kind=\"Diverter\", name=\"d1\", args=dict(nodes=[[double], [plus1, double], square]))\n        edges2 = [dict(iid='__start__', oid='5'), dict(iid='5', oid='__end__')]\n        gid = engine.start([diverter], edges2)\n        assert engine.run(gid, [1, 2, 3]) == (2, 6, 9)\n\n        engine.reset()\n\n        switch = dict(\n            id=\"4\",\n            kind=\"Switch\",\n            name=\"s1\",\n            args=dict(\n                judge_on_full_input=False,\n                nodes={\"case1\": [double], \"case2\": [plus1, double], \"case3\": [square]},\n                _lazyllm_enable_report=True,\n            ),\n        )\n        gid = engine.start([switch], edges)\n        assert engine.run(gid, 'case1', 1) == 2\n        assert engine.run(gid, 'case2', 1) == 4\n        assert engine.run(gid, 'case3', 1) == 1\n        assert engine.run(gid, 'case1', 2) == 4\n        assert engine.run(gid, 'case2', 2) == 6\n        assert engine.run(gid, 'case3', 3) == 9\n        assert \"prompt_tokens\" in self.get_last_report()\n\n    def test_engine_ifs(self):\n        plus1 = dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return 1 + x\\n'))\n        double = dict(id='2', kind='Code', name='m2', args=dict(code='def test(x: int):\\n    return 2 * x\\n'))\n        square = dict(id='3', kind='Code', name='m3', args=dict(code='def test(x: int):\\n    return x * x\\n'))\n        ifs = dict(\n            id=\"4\",\n            kind=\"Ifs\",\n            name=\"i1\",\n            args=dict(\n                cond=\"def cond(x): return x < 10\",\n                true=[plus1, double],\n                false=[square],\n                _lazyllm_enable_report=True,\n            ),\n        )\n        nodes = [ifs]\n        edges = [dict(iid='__start__', oid='4'), dict(iid='4', oid='__end__')]\n        engine = LightEngine()\n        engine.set_report_url(self.report_url)\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == 4\n        assert engine.run(gid, 5) == 12\n        assert engine.run(gid, 10) == 100\n        assert \"prompt_tokens\" in self.get_last_report()\n\n    def test_data_reflow_in_server(self):\n        nodes = [\n            {\n                \"id\": \"1\",\n                \"kind\": \"Code\",\n                \"name\": \"f1\",\n                \"args\": {\n                    \"code\": \"def main(x): return int(x) + 1\",\n                    \"_lazyllm_enable_report\": True,\n                },\n            },\n            {\n                \"id\": \"2\",\n                \"kind\": \"Code\",\n                \"name\": \"f2\",\n                \"args\": {\n                    \"code\": \"def main(x): return int(x) + 2\",\n                    \"_lazyllm_enable_report\": True,\n                },\n            },\n            {\n                \"id\": \"3\",\n                \"kind\": \"Code\",\n                \"name\": \"f3\",\n                \"args\": {\n                    \"code\": \"def main(x): return int(x) + 3\",\n                    \"_lazyllm_enable_report\": True,\n                },\n            },\n        ]\n        edges = [\n            {\n                \"iid\": \"__start__\",\n                \"oid\": \"1\",\n            },\n            {\n                \"iid\": \"1\",\n                \"oid\": \"2\",\n            },\n            {\n                \"iid\": \"2\",\n                \"oid\": \"3\",\n            },\n            {\n                \"iid\": \"3\",\n                \"oid\": \"__end__\",\n            },\n        ]\n        resources = [\n            {\n                \"id\": \"4\",\n                \"kind\": \"server\",\n                \"name\": \"s1\",\n                \"args\": {},\n            }\n        ]\n        engine = LightEngine()\n        engine.set_report_url(self.report_url)\n        gid = engine.start(nodes, edges, resources)\n        assert engine.run(gid, 1) == 7\n        assert \"prompt_tokens\" in self.get_last_report()\n\n    def test_engine_loop(self):\n        nodes = [dict(id='1', kind='Code', name='code', args=dict(code='def square(x: int): return x * x'))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='1', oid='__end__')]\n\n        nodes = [\n            dict(\n                id=\"2\",\n                kind=\"Loop\",\n                name=\"loop\",\n                args=dict(\n                    stop_condition=\"def cond(x): return x > 10\",\n                    nodes=nodes,\n                    edges=edges,\n                    _lazyllm_enable_report=True,\n                ),\n            )\n        ]\n        edges = [dict(iid='__start__', oid='2'), dict(iid='2', oid='__end__')]\n\n        engine = LightEngine()\n        engine.set_report_url(self.report_url)\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 2) == 16\n        assert \"prompt_tokens\" in self.get_last_report()\n\n    def test_engine_warp(self):\n        nodes = [dict(id='1', kind='Code', name='code', args=dict(code='def square(x: int): return x * x'))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='1', oid='__end__')]\n\n        nodes = [\n            dict(\n                id=\"2\",\n                kind=\"Warp\",\n                name=\"warp\",\n                args=dict(\n                    nodes=nodes,\n                    edges=edges,\n                    _lazyllm_enable_report=True,\n                ),\n            )\n        ]\n        edges = [dict(iid='__start__', oid='2'), dict(iid='2', oid='__end__')]\n\n        engine = LightEngine()\n        engine.set_report_url(self.report_url)\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 2, 3, 4, 5) == (4, 9, 16, 25)\n        assert \"prompt_tokens\" in self.get_last_report()\n\n    def test_engine_formatter(self):\n        nodes = [dict(id='1', kind='Formatter', name='f1', args=dict(ftype='python', rule='[:]'))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='1', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, [1, 2]) == [1, 2]\n\n        engine.reset()\n        nodes = [dict(id='1', kind='Formatter', name='f1', args=dict(ftype='json', rule='{a, c}'))]\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, '{\"a\": 1, \"b\": 2, \"c\": 3}') == dict(a=1, c=3)\n\n        engine.reset()\n        nodes = [dict(id='1', kind='Formatter', name='f1', args=dict(ftype='yaml', rule='[:]{a}'))]\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, '- a: 1\\n  b: 2\\n- a: 3\\n  d: 4\\n') == [dict(a=1), dict(a=3)]\n\n        engine.reset()\n        nodes = [dict(id='1', kind='Formatter', name='f1', args=dict(ftype='file', rule='decode'))]\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 'hi') == 'hi'\n        assert engine.run(gid, '<lazyllm-query>{\"query\":\"aha\",\"files\":[\"path/to/file\"]}') == \\\n               {\"query\": \"aha\", \"files\": [\"path/to/file\"]}\n\n        engine.reset()\n        nodes = [dict(id='1', kind='Formatter', name='f1', args=dict(ftype='file', rule='encode'))]\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 'hi') == 'hi'\n        assert engine.run(gid, {\"query\": \"aha\", \"files\": [\"path/to/file\"]}) == \\\n               '<lazyllm-query>{\"query\": \"aha\", \"files\": [\"path/to/file\"]}'\n\n        engine.reset()\n        nodes = [dict(id='1', kind='Formatter', name='f1', args=dict(ftype='file', rule='merge'))]\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 'hi') == 'hi'\n        assert engine.run(gid, 'hi', '<lazyllm-query>{\"query\":\"aha\",\"files\":[\"path/to/file\"]}') == \\\n               '<lazyllm-query>{\"query\": \"hiaha\", \"files\": [\"path/to/file\"]}'\n\n    def test_engine_edge_formatter(self):\n        nodes = [dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return x\\n')),\n                 dict(id='2', kind='Code', name='m2',\n                      args=dict(code='def test(x: int):\\n    return [[x, 2*x], [3*x, 4*x]]\\n')),\n                 dict(id='3', kind='Code', name='m3',\n                 args=dict(code='def test(x: int):\\n    return dict(a=1, b=x * x)\\n')),\n                 dict(id='4', kind='Code', name='m4', args=dict(code='def test(x, y, z):\\n    return f\"{x}{y}{z}\"\\n'))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'), dict(iid='__start__', oid='3'),\n                 dict(iid='1', oid='4'), dict(iid='2', oid='4', formatter='[:][1]'),\n                 dict(iid='3', oid='4', formatter='[b]'), dict(iid='4', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == '1[2, 4]1'\n        assert engine.run(gid, 2) == '2[4, 8]4'\n\n    def test_engine_edge_formatter_start(self):\n        nodes = [dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int): return x')),\n                 dict(id='2', kind='Code', name='m2', args=dict(code='def test(x: int): return 2 * x')),\n                 dict(id='3', kind='Code', name='m3', args=dict(code='def test(x, y): return x + y'))]\n        edges = [dict(iid='__start__', oid='1', formatter='[0]'), dict(iid='__start__', oid='2', formatter='[1]'),\n                 dict(iid='1', oid='3'), dict(iid='2', oid='3'), dict(iid='3', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 3, 1) == 5\n        assert engine.run(gid, 5, 3, 1) == 11\n\n    def test_engine_formatter_end(self):\n        nodes = [dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return x\\n')),\n                 dict(id='2', kind='Code', name='m2',\n                      args=dict(code='def test1(x: int):\\n    return [[x, 2*x], [3*x, 4*x]]\\n')),\n                 # two unused node\n                 dict(id='3', kind='Code', name='m3',\n                      args=dict(code='def test2(x: int):\\n    return dict(a=1, b=x * x)\\n')),\n                 dict(id='4', kind='Code', name='m4', args=dict(code='def test3(x, y, z):\\n    return f\"{x}{y}{z}\"\\n'))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'), dict(iid='2', oid='__end__'),\n                 dict(iid='1', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        r = engine.run(gid, 1)\n        print(r, type(r))\n        print(isinstance(r, lazyllm.package))\n\n        engine.reset()\n\n        nodes = [dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return x\\n')),\n                 dict(id='2', kind='Code', name='m2',\n                      args=dict(code='def test1(x: int):\\n    return [[x, 2*x], [3*x, 4*x]]\\n')),\n                 dict(id='3', kind='JoinFormatter', name='join', args=dict(type='to_dict', names=['a', 'b']))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'), dict(iid='2', oid='3'),\n                 dict(iid='1', oid='3'), dict(iid='3', oid='__end__', formatter='*[a, b]')]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        r = engine.run(gid, 1)\n        print(r, type(r))\n        print(isinstance(r, lazyllm.package))\n\n    def test_engine_join_stack(self):\n        nodes = [dict(id='0', kind='Code', name='c1', args=dict(code='def test(x: int): return x')),\n                 dict(id='1', kind='JoinFormatter', name='join', args=dict(type='stack'))]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='0', oid='1'), dict(iid='1', oid='__end__')]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == [1]\n        assert engine.run(gid, '1') == ['1']\n        assert engine.run(gid, [1]) == [[1]]\n\n        engine.reset()\n\n        nodes = [dict(id='0', kind='Code', name='c1', args=dict(code='def test(x: int): return x')),\n                 dict(id='1', kind='Code', name='c2', args=dict(code='def test(x: int): return 2 * x')),\n                 dict(id='2', kind='Code', name='c3', args=dict(code='def test(x: int): return 3 * x')),\n                 dict(id='3', kind='JoinFormatter', name='join', args=dict(type='stack'))]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'),\n                 dict(iid='0', oid='3'), dict(iid='1', oid='3'), dict(iid='2', oid='3'), dict(iid='3', oid='__end__')]\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == [1, 2, 3]\n        assert engine.run(gid, '1') == ['1', '11', '111']\n        assert engine.run(gid, [1]) == [[1], [1, 1], [1, 1, 1]]\n\n    def test_engine_join_sum(self):\n        nodes = [dict(id='0', kind='Code', name='c1', args=dict(code='def test(x: int): return [x, 2 * x]')),\n                 dict(id='1', kind='JoinFormatter', name='join', args=dict(type='sum'))]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='0', oid='1'), dict(iid='1', oid='__end__')]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == 3\n        assert engine.run(gid, '1') == '111'\n        assert engine.run(gid, [1]) == [1, 1, 1]\n\n        engine.reset()\n\n        nodes = [dict(id='0', kind='Code', name='c1', args=dict(code='def test(x: int): return x')),\n                 dict(id='1', kind='Code', name='c2', args=dict(code='def test(x: int): return 2 * x')),\n                 dict(id='2', kind='Code', name='c3', args=dict(code='def test(x: int): return 3 * x')),\n                 dict(id='3', kind='JoinFormatter', name='join', args=dict(type='sum'))]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'),\n                 dict(iid='0', oid='3'), dict(iid='1', oid='3'), dict(iid='2', oid='3'), dict(iid='3', oid='__end__')]\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == 6\n        assert engine.run(gid, '1') == '111111'\n        assert engine.run(gid, [1]) == [1, 1, 1, 1, 1, 1]\n\n    def test_engine_join_todict(self):\n        nodes = [dict(id='0', kind='Code', name='c1', args=dict(code='def test(x: int): return x')),\n                 dict(id='1', kind='Code', name='c2', args=dict(code='def test(x: int): return 2 * x')),\n                 dict(id='2', kind='Code', name='c3', args=dict(code='def test(x: int): return 3 * x')),\n                 dict(id='3', kind='JoinFormatter', name='join', args=dict(type='to_dict', names=['a', 'b', 'c']))]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'),\n                 dict(iid='0', oid='3'), dict(iid='1', oid='3'), dict(iid='2', oid='3'), dict(iid='3', oid='__end__')]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == dict(a=1, b=2, c=3)\n        assert engine.run(gid, '1') == dict(a='1', b='11', c='111')\n        assert engine.run(gid, [1]) == dict(a=[1], b=[1, 1], c=[1, 1, 1])\n\n    def test_engine_update(self):\n        plus1 = dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return 1 + x\\n'))\n        double = dict(id='2', kind='Code', name='m2', args=dict(code='def test(x: int):\\n    return 2 * x\\n'))\n        square = dict(id='3', kind='Code', name='m3', args=dict(code='def test(x: int):\\n    return x * x\\n'))\n        ifs = dict(id='4', kind='Ifs', name='i1', args=dict(\n            cond='def cond(x): return x < 10', true=[plus1, double], false=[square]\n        ))\n        nodes = [ifs]\n        edges = [dict(iid='__start__', oid='4'), dict(iid='4', oid='__end__')]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, 1) == 4\n        assert engine.run(gid, 5) == 12\n        assert engine.run(gid, 10) == 100\n\n        double = dict(id='2', kind='Code', name='m2', args=dict(code='def test(x: int):\\n    return 3 * x\\n'))\n        ifs = dict(id='4', kind='Ifs', name='i1', args=dict(\n            cond='def cond(x): return x < 10', true=[plus1, double], false=[square]\n        ))\n        nodes = [ifs]\n        engine.update(gid, nodes, edges)\n\n        assert engine.run(gid, 1) == 6\n        assert engine.run(gid, 5) == 18\n        assert engine.run(gid, 10) == 100\n\n    def test_engine_join_join(self):\n        nodes = [dict(id='0', kind='Code', name='c1', args=dict(code='def test(x: int): return x')),\n                 dict(id='1', kind='Code', name='c2', args=dict(code='def test(x: int): return 2 * x')),\n                 dict(id='2', kind='Code', name='c3', args=dict(code='def test(x: int): return 3 * x')),\n                 dict(id='3', kind='JoinFormatter', name='join', args=dict(type='join'))]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'),\n                 dict(iid='0', oid='3'), dict(iid='1', oid='3'), dict(iid='2', oid='3'), dict(iid='3', oid='__end__')]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges)\n        assert engine.run(gid, '1') == '111111'\n\n        nodes[-1] = dict(id='3', kind='JoinFormatter', name='join', args=dict(type='join', symbol='\\n'))\n        engine.update(gid, nodes, edges)\n        assert engine.run(gid, '1') == '1\\n11\\n111'\n\n    def test_engine_server(self):\n        nodes = [dict(id='1', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return 2 * x\\n'))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='1', oid='__end__')]\n        resources = [dict(id='2', kind='server', name='s1', args=dict(port=None)),\n                     dict(id='3', kind='web', name='w1', args=dict(port=None, title='网页', history=[], audio=False))\n                    ]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources, gid='graph-1')\n        assert engine.status(gid) == {'1': 'running', '2': lazyllm.launcher.Status.Running, '3': 'running'}\n        assert engine.run(gid, 1) == 2\n        time.sleep(3)\n\n        server = engine.build_node('graph-1').func._g\n        assert isinstance(server, lazyllm.ServerModule)\n        m = lazyllm.UrlModule(url=server._url)\n        assert m(2) == 4\n\n        web = engine.build_node('graph-1').func._web\n        assert engine.build_node('graph-1').func.api_url is not None\n        assert engine.build_node('graph-1').func.web_url == web.url\n        client = Client(web.url, download_files=web.cach_path)\n        chat_history = [['123', None]]\n        ans = client.predict(False, chat_history, False, False, api_name=\"/_respond_stream\")\n        assert ans[0][-1][-1] == '123123'\n        client.close()\n        lazyllm.launcher.cleanup()\n        web.stop()\n\n    def test_engine_stop_and_restart(self):\n        resources = [dict(id='0', kind='LocalLLM', name='m1', args=dict(base_model='', deploy_method='dummy'))]\n        nodes = [dict(id='1', kind='SharedLLM', name='s1', args=dict(llm='0', prompt=None))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='1', oid='__end__')]\n\n        engine = LightEngine()\n        assert engine.status('123') == 'unknown'\n        gid = engine.start(nodes, edges, resources, gid='123')\n        assert gid == '123'\n\n        r = engine.run(gid, '1234')\n        assert 'reply for You are an AI-Agent developed by LazyLLM' in r\n        assert '1234' in r\n\n        assert engine.status(gid) == {'1': 'running', '0': lazyllm.launcher.Status.Running}\n        engine.stop('0')\n\n        assert engine.status(gid) == {'1': 'running', '0': lazyllm.launcher.Status.Cancelled}\n        with pytest.raises((TimeoutException, urllib3.exceptions.NewConnectionError, RuntimeError)):\n            with lazyllm.timeout(3):\n                engine.run(gid, '1234567')\n\n        engine.start('0')\n        assert engine.status(gid) == {'1': 'running', '0': lazyllm.launcher.Status.Running}\n        r = engine.run(gid, '12345')\n        assert 'reply for You are an AI-Agent developed by LazyLLM' in r\n        assert '12345' in r\n        engine.stop(gid)\n        assert engine.status(gid) == {'1': 'running', '0': lazyllm.launcher.Status.Cancelled}\n\n    def test_engine_httptool(self):\n        params = {'p1': '{{p1}}', 'p2': '{{p2}}'}\n        headers = {'h1': '{{h1}}'}\n        url = 'https://postman-echo.com/get'\n\n        nodes = [\n            dict(id='0', kind='Code', name='code1', args=dict(code='def p1(): return \"foo\"')),\n            dict(id='1', kind='Code', name='code2', args=dict(code='def p2(): return \"bar\"')),\n            dict(id='2', kind='Code', name='code3', args=dict(code='def h1(): return \"baz\"')),\n            dict(id='3', kind='HttpTool', name='http', args=dict(\n                method='GET', url=url, params=params, headers=headers, _lazyllm_arg_names=['p1', 'p2', 'h1']))\n        ]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'),\n                 dict(iid='0', oid='3'), dict(iid='1', oid='3'), dict(iid='2', oid='3'), dict(iid='3', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, gid='graph-1')\n        res = engine.run(gid)\n\n        assert res['headers']['h1'] == 'baz'\n        assert res['url'].endswith(f'{url[5:]}?p1=foo&p2=bar')\n\n    def test_engine_httptool_with_output(self):\n        params = {'p1': '{{p1}}', 'p2': '{{p2}}'}\n        headers = {'h1': '{{h1}}'}\n        url = 'https://postman-echo.com/get'\n\n        nodes = [\n            dict(id='0', kind='Code', name='code1', args=dict(code='def p1(): return \"foo\"')),\n            dict(id='1', kind='Code', name='code2', args=dict(code='def p2(): return \"bar\"')),\n            dict(id='2', kind='Code', name='code3', args=dict(code='def h1(): return \"baz\"')),\n            dict(id='3', kind='HttpTool', name='http', args=dict(\n                method='GET', url=url, params=params, headers=headers,\n                outputs=['headers', 'url'], _lazyllm_arg_names=['p1', 'p2', 'h1']))\n        ]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'),\n                 dict(iid='0', oid='3'), dict(iid='1', oid='3'), dict(iid='2', oid='3'), dict(iid='3', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, gid='graph-1')\n        res = engine.run(gid)\n\n        assert isinstance(res, lazyllm.package) and len(res) == 2\n        assert res[0]['h1'] == 'baz'\n        assert res[1].endswith(f'{url[5:]}?p1=foo&p2=bar')\n\n        engine.reset()\n\n        nodes[3]['args']['outputs'] = ['output']\n        gid = engine.start(nodes, edges)\n        res = engine.run(gid)\n        assert res['headers']['h1'] == 'baz'\n\n        engine.reset()\n\n        nodes[3]['args']['outputs'] = ['headers']\n        nodes[3]['args']['extract_from_result'] = True\n        gid2 = engine.start(nodes, edges)\n        res = engine.run(gid2)\n        assert res['h1'] == 'baz'\n\n    def test_engine_httptool_body(self):\n        body = {'b1': '{{b1}}', 'b2': '{{b2}}'}\n        headers = {'Content-Type': '{{h1}}'}\n        url = 'https://jsonplaceholder.typicode.com/posts'\n\n        nodes = [\n            dict(id='0', kind='Constant', name='header', args=\"application/json\"),\n            dict(id='1', kind='Constant', name='body1', args=\"body1\"),\n            dict(id='2', kind='Constant', name='body2', args=\"body2\"),\n            dict(id='3', kind='HttpTool', name='http', args=dict(\n                method='POST', url=url, body=body, headers=headers, _lazyllm_arg_names=['h1', 'b1', 'b2']))\n        ]\n        edges = [dict(iid='__start__', oid='0'), dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'),\n                 dict(iid='0', oid='3'), dict(iid='1', oid='3'), dict(iid='2', oid='3'), dict(iid='3', oid='__end__')]\n\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, gid='graph-1')\n        res = engine.run(gid)\n\n        assert res['b1'] == 'body1'\n        assert res['b2'] == 'body2'\n\n    def test_engine_status(self):\n        resources = [dict(id='0', kind='LocalLLM', name='m1', args=dict(base_model='', deploy_method='dummy'))]\n        llm_node = dict(id='1', kind='SharedLLM', name='s1', args=dict(llm='0', prompt=None))\n\n        plus1 = dict(id='2', kind='Code', name='m1', args=dict(code='def test(x: int):\\n    return 1 + x\\n'))\n        double = dict(id='3', kind='Code', name='m2', args=dict(code='def test(x: int):\\n    return 2 * x\\n'))\n        square = dict(id='4', kind='Code', name='m3', args=dict(code='def test(x: int):\\n    return x * x\\n'))\n\n        subgraph = dict(id='5', kind='SubGraph', name='subgraph', args=dict(nodes=[double, plus1]))\n        ifs = dict(id='6', kind='Ifs', name='i1', args=dict(\n            cond='def cond(x): return x % 2 == 0', true=plus1, false=[square]))\n        loop = dict(id='7', kind='Loop', name='loop', args=dict(\n            stop_condition='def cond(x): return x > 8', nodes=[double]))\n\n        switch = dict(id='8', kind='Switch', name='sw1', args=dict(judge_on_full_input=True, nodes={\n            1: [plus1, subgraph], 2: ifs, 3: loop, 5: [ifs]}))\n\n        warp = dict(id='9', kind='Warp', name='w1', args=dict(nodes=[switch, plus1]))\n        join = dict(id='10', kind='JoinFormatter', name='join', args=dict(type='join', symbol=', '))\n        nodes = [warp, join, llm_node]\n        engine = LightEngine()\n        gid = engine.start(nodes, [], resources)\n\n        assert '6, 4, 13, 26' in engine.run(gid, 1, 2, 3, 5)\n        assert engine.status(gid) == {'9': {'8': {'2': 'running',\n                                                  '5': {'3': 'running', '2': 'running'},\n                                                  '6': {'2': 'running', '4': 'running'},\n                                                  '7': {'3': 'running'}},\n                                            '2': 'running'},\n                                      '10': 'running',\n                                      '1': 'running',\n                                      '0': lazyllm.launcher.Status.Running}\n\n\nclass TestEngineRAG(object):\n\n    def test_rag(self):\n        resources = [\n            dict(id='0', kind='Document', name='d1', args=dict(dataset_path='rag_master', embed='00')),\n            dict(id='00', kind='LocalEmbedding', name='e1', args=dict(base_model='bge-large-zh-v1.5'))]\n        nodes = [dict(id='1', kind='Retriever', name='ret1',\n                      args=dict(doc='0', group_name='CoarseChunk', similarity='bm25_chinese', topk=3)),\n                 dict(id='4', kind='Reranker', name='rek1',\n                      args=dict(type='ModuleReranker', output_format='content', join=True,\n                                arguments=dict(model=\"bge-reranker-large\", topk=3))),\n                 dict(id='5', kind='Code', name='c1',\n                      args=dict(code='def test(nodes, query): return f\\'context_str={nodes}, query={query}\\'')),\n                 dict(id='6', kind='LocalLLM', name='m1', args=dict(base_model='', deploy_method='dummy'))]\n        edges = [dict(iid='__start__', oid='1'), dict(iid='1', oid='4'), dict(iid='__start__', oid='4'),\n                 dict(iid='4', oid='5'), dict(iid='__start__', oid='5'), dict(iid='5', oid='6'),\n                 dict(iid='6', oid='__end__')]\n        engine = LightEngine()\n        gid = engine.start(nodes, edges, resources)\n        r = engine.run(gid, '何为修身?')\n        assert '所谓修身在正其心者' in r\n\n        # test add doc_group\n        resources[0] = dict(id='0', kind='Document', name='d1', args=dict(\n            dataset_path='rag_master', server=True, node_group=[\n                dict(name='sentence', transform='SentenceSplitter', chunk_size=100, chunk_overlap=10)]))\n        nodes.extend([dict(id='2', kind='Retriever', name='ret2',\n                           args=dict(doc='0', group_name='sentence', similarity='bm25', topk=3)),\n                      dict(id='3', kind='JoinFormatter', name='c', args=dict(type='sum'))])\n        edges = [dict(iid='__start__', oid='1'), dict(iid='__start__', oid='2'), dict(iid='1', oid='3'),\n                 dict(iid='2', oid='3'), dict(iid='3', oid='4'), dict(iid='__start__', oid='4'),\n                 dict(iid='4', oid='5'), dict(iid='__start__', oid='5'), dict(iid='5', oid='6'),\n                 dict(iid='6', oid='__end__')]\n        engine = LightEngine()\n        engine.update(gid, nodes, edges, resources)\n        r = engine.run(gid, '何为修身?')\n        assert '所谓修身在正其心者' in r\n"}
{"type": "test_file", "path": "tests/doc_check/test_doc_api_check.py", "content": "import pytest # noqa E401\nimport re\nimport inspect\nimport lazyllm\nfrom typing import Callable\nimport warnings\n\n\ndef class_should_check(cls, module):\n    if not cls.__name__[0].isupper() or cls.__module__ != module.__name__:\n        return False\n    if cls.__module__ != module.__name__:\n        return False\n    all_methods = inspect.getmembers(cls, predicate=inspect.isfunction)\n    custom_methods = [name for name, func in all_methods if not name.startswith('_')]\n    return len(custom_methods) > 0\n\n\ndef get_sub_classes(module):\n    clsmembers = inspect.getmembers(module, inspect.isclass)\n    classes = set([ele[1] for ele in clsmembers if class_should_check(ele[1], module)])\n    for name, sub_module in inspect.getmembers(module, inspect.ismodule):\n        if sub_module.__name__.startswith(module.__name__):\n            classes.update(get_sub_classes(sub_module))\n    return classes\n\n\ndef is_method_overridden(cls, method: Callable):\n    method_name = method.__name__\n    for base in cls.__bases__:\n        if hasattr(base, method_name):\n            base_method = getattr(base, method_name)\n            current_method = getattr(cls, method_name)\n            if current_method != base_method:\n                return True\n    return False\n\n\ndef do_check_method(cls, func: Callable):\n    # As type is always missing in code signature and default value is not universal,\n    # Also Keyword argument is not universal. So we just check args parameter name\n    arg_spec = inspect.getfullargspec(func)\n    real_parms = arg_spec.args + arg_spec.kwonlyargs\n    real_vars = [arg_spec.varargs, arg_spec.varkw]\n    if real_parms[0] in ['self', 'cls']:\n        real_parms = real_parms[1:]\n    real_parms = set(real_parms + real_vars)\n    if func.__name__ == '__init__':\n        doc = cls.__doc__\n    else:\n        doc = func.__doc__\n    if doc is not None:\n        seg_pattern = r\"Args:\\s*(.*?)\\n\\s*\\n\"\n        match = re.search(seg_pattern, doc, re.DOTALL)\n        doc_parms = []\n        if match:\n            args_pattern = r\"^\\s*(\\w+)\\s*(?:\\(|:)\"\n            doc_parms = re.findall(args_pattern, match.group(1), re.MULTILINE)\n        for doc_param in doc_parms:\n            if doc_param in real_parms:\n                continue\n            assert doc_param in real_parms, f\"{doc_param} no found in real params: {real_parms}\"\n    else:\n        if len(real_parms) > 0:\n            warnings.warn(f\"doc is empty, real params: {real_parms}\", UserWarning)\n\n\ndef create_test_function(cls, func):\n    if func.__name__ == \"__init__\":\n        dynamic_func_name = f\"test_{cls.__name__}\"\n    else:\n        dynamic_func_name = f\"test_{cls.__name__}_{func.__name__}\"\n    while dynamic_func_name in global_func_names:\n        dynamic_func_name = dynamic_func_name + \"_\"\n    global_func_names.add(dynamic_func_name)\n    cls_path = f\"{cls.__module__}.{cls.__qualname__}\"\n    func_path = f\"{cls_path}.{func.__name__}\"\n    xfail_decorator = \"@pytest.mark.xfail\"\n    code = f\"{xfail_decorator}\\ndef {dynamic_func_name}():\\n    do_check_method({cls_path}, {func_path})\"\n    exec(code, globals())\n\n\ndef gen_check_cls_and_funtions():\n    all_classes = get_sub_classes(lazyllm)\n    for cls in all_classes:\n        all_methods = inspect.getmembers(cls, predicate=inspect.isfunction)\n        custom_methods = [func for name, func in all_methods if not name.startswith('_') or name == '__init__']\n        overridden_methods = [func for func in custom_methods if is_method_overridden(cls, func)]\n        for overridden_method in overridden_methods:\n            create_test_function(cls, overridden_method)\n\n\nglobal_func_names = set()\ngen_check_cls_and_funtions()\n"}
{"type": "source_file", "path": "examples/__init__.py", "content": ""}
{"type": "source_file", "path": "examples/chatbot.py", "content": "import lazyllm\n\n# Three ways to specify the model:\n#   1. Specify the model name (e.g. 'internlm2-chat-7b'):\n#           the model will be automatically downloaded from the Internet;\n#   2. Specify the model name (e.g. 'internlm2-chat-7b') ​​+ set\n#      the environment variable `export LAZYLLM_MODEL_PATH=\"/path/to/modelzoo\"`:\n#           the model will be found in `path/to/modelazoo/internlm2-chat-7b/`\n#   3. Directly pass the absolute path to TrainableModule:\n#           `path/to/modelazoo/internlm2-chat-7b`\n\nchat = lazyllm.TrainableModule('internlm2-chat-7b')\n\nif __name__ == '__main__':\n    lazyllm.WebModule(chat, port=range(23466, 23470)).start().wait()\n"}
{"type": "source_file", "path": "lazyllm/common/__init__.py", "content": "from .registry import LazyLLMRegisterMetaClass, _get_base_cls_from_registry, Register\nfrom .common import package, kwargs, arguments, LazyLLMCMD, timeout, final, ReadOnlyWrapper, DynamicDescriptor, override\nfrom .common import FlatList, Identity, ResultCollector, ArgsDict, CaseInsensitiveDict\nfrom .common import ReprRule, make_repr, modify_repr\nfrom .common import once_flag, call_once, once_wrapper, singleton, reset_on_pickle\nfrom .text import Color, colored_text\nfrom .option import Option, OptionIter\nfrom .threading import Thread, ThreadPoolExecutor\nfrom .multiprocessing import SpawnProcess, ForkProcess\nfrom .logger import LOG\nfrom .deprecated import deprecated\nfrom .globals import globals, LazyLlmResponse, LazyLlmRequest, encode_request, decode_request\nfrom .bind import root, Bind as bind, _0, _1, _2, _3, _4, _5, _6, _7, _8, _9\nfrom .queue import FileSystemQueue\nfrom .utils import compile_func, obj2str, str2obj\n\n__all__ = [\n    # registry\n    'LazyLLMRegisterMetaClass',\n    '_get_base_cls_from_registry',\n    'Register',\n\n    # utils\n    'FlatList',\n    'ReadOnlyWrapper',\n    'Identity',\n    'ResultCollector',\n    'ArgsDict',\n    'CaseInsensitiveDict',\n    'timeout',\n    'final',\n    'deprecated',\n    'compile_func',\n    'DynamicDescriptor',\n    'singleton',\n    'reset_on_pickle',\n    'Color',\n    'colored_text',\n    'obj2str',\n    'str2obj',\n\n    # arg praser\n    'LazyLLMCMD',\n    'package',\n    'kwargs',\n    'arguments',\n    'override',\n\n    # option\n    'Option',\n    'OptionIter',\n\n    # globals\n    'globals',\n    'LazyLlmResponse',\n    'LazyLlmRequest',\n    'encode_request',\n    'decode_request',\n\n    # multiprocessing\n    'ForkProcess',\n    'SpawnProcess',\n\n    # threading\n    'Thread',\n    'ThreadPoolExecutor',\n\n    # bind\n    'bind', 'root',\n    '_0', '_1', '_2', '_3', '_4',\n    '_5', '_6', '_7', '_8', '_9',\n\n    # call_once\n    'once_flag',\n    'call_once',\n    'once_wrapper',\n\n    # subprocess\n    'SpawnProcess', 'ForkProcess',\n\n    # representation\n    'ReprRule',\n    'make_repr',\n    'modify_repr',\n\n    # log\n    'LOG',\n\n    # file-system queue\n    'FileSystemQueue',\n]\n"}
{"type": "source_file", "path": "docs/add_docstrings.py", "content": "import sys\nimport argparse\n\nsys.path.append('.')\nsys.path.append('./docs/scripts')\nfrom lazynote.manager import SimpleManager\nimport lazyllm\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--replace', action='store_true', help='Execute the replace part of the code.')\nparser.add_argument('--clean', action='store_true', help='clean code docs.')\nargs = parser.parse_args()\n\nskip_list = [\n    'lazyllm.components.deploy.relay.server',\n    'lazyllm.components.deploy.relay.base',\n    'lazyllm.components.finetune.easyllm',\n    'lazyllm.tools.rag.component.bm25_retriever',\n]\n\nif args.replace or args.clean:\n    manager = SimpleManager(pattern='clear', skip_on_error=True)\n    manager.traverse(lazyllm, skip_modules=skip_list)\n\nif not args.clean:\n    manager = SimpleManager(pattern='fill', skip_on_error=True)\n    manager.traverse(lazyllm, skip_modules=skip_list)\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/editor/base.py", "content": "import inspect\nfrom typing import Callable, Optional, Any, Dict, Set\n\nimport libcst as cst\nimport libcst.matchers as m\n\n\nclass BaseEditor(cst.CSTTransformer):\n    \"\"\"\n    A tool for transforming code text and generating new code text.\n    \"\"\"\n\n    def __init__(self, gen_docstring: Callable[[Optional[str], str], str], pattern: str, module: Any) -> None:\n        \"\"\"\n        Initializes the BaseEditor.\n\n        Args:\n            gen_docstring (Callable[[Optional[str], str], str]): A function to generate docstrings.\n            pattern (str): A pattern to match.\n            module (Any): The module to be transformed.\n        \"\"\"\n        self.gen_docstring = gen_docstring\n        self.pattern = pattern\n        self.module = module\n        self.module_dict = self.create_module_dict(module)\n        self.current_class: Optional[str] = ''\n\n    def create_module_dict(self, module: Any) -> Dict[str, Any]:\n        \"\"\"\n        Creates a dictionary of module members.\n\n        Args:\n            module (Any): The module to inspect.\n\n        Returns:\n            Dict[str, Any]: A dictionary of module members.\n        \"\"\"\n        module_dict = {}\n        seen_objects: Set[Any] = set()\n        for name, obj in inspect.getmembers(module):\n            module_dict[name] = obj\n            if inspect.isclass(obj):\n                self.add_class_members_to_dict(module_dict, obj, name, seen_objects)\n        return module_dict\n\n    def add_class_members_to_dict(\n            self, module_dict: Dict[str, Any], cls: Any, parent_name: str, seen_objects: Set[Any]) -> None:\n        \"\"\"\n        Adds class members to the module dictionary.\n\n        Args:\n            module_dict (Dict[str, Any]): The module dictionary.\n            cls (Any): The class to inspect.\n            parent_name (str): The parent name of the class.\n            seen_objects (Set[Any]): A set of seen objects to avoid infinite recursion.\n        \"\"\"\n        if cls in seen_objects:\n            return\n        seen_objects.add(cls)\n        for name, obj in inspect.getmembers(cls):\n            full_name = f\"{parent_name}.{name}\"\n            module_dict[full_name] = obj\n            if inspect.isclass(obj):\n                self.add_class_members_to_dict(module_dict, obj, full_name, seen_objects)\n\n    def leave_FunctionDef(self, original_node: cst.FunctionDef, updated_node: cst.FunctionDef) -> cst.FunctionDef:\n        \"\"\"\n        Called when leaving a FunctionDef node.\n\n        Args:\n            original_node (cst.FunctionDef): The original FunctionDef node.\n            updated_node (cst.FunctionDef): The updated FunctionDef node.\n\n        Returns:\n            cst.FunctionDef: The updated FunctionDef node with a new docstring.\n        \"\"\"\n        full_name = (\n            f\"{self.current_class}.{original_node.name.value}\"\n            if self.current_class else original_node.name.value\n        )\n        obj = self._get_obj_by_name(full_name)\n        docstring = obj.__doc__ if obj else None\n        return self._update_node_with_new_docstring(original_node, updated_node, docstring)\n\n    def visit_ClassDef(self, node: cst.ClassDef) -> None:\n        \"\"\"\n        Called when visiting a ClassDef node.\n\n        Args:\n            node (cst.ClassDef): The ClassDef node.\n        \"\"\"\n        self.current_class = f'{self.current_class}.{node.name.value}'.lstrip('.')\n\n    def leave_ClassDef(self, original_node: cst.ClassDef, updated_node: cst.ClassDef) -> cst.ClassDef:\n        \"\"\"\n        Called when leaving a ClassDef node.\n\n        Args:\n            original_node (cst.ClassDef): The original ClassDef node.\n            updated_node (cst.ClassDef): The updated ClassDef node.\n\n        Returns:\n            cst.ClassDef: The updated ClassDef node with a new docstring.\n        \"\"\"\n        self.current_class = self.current_class[:(lambda x: 0 if x < 0 else x)(self.current_class.rfind('.'))]\n        obj = self._get_obj_by_name(original_node.name.value)\n        docstring = obj.__doc__ if obj else None\n        return self._update_node_with_new_docstring(original_node, updated_node, docstring)\n\n    def leave_Module(self, original_node: cst.Module, updated_node: cst.Module) -> cst.Module:\n        \"\"\"\n        Called when leaving a Module node.\n\n        Args:\n            original_node (cst.Module): The original Module node.\n            updated_node (cst.Module): The updated Module node.\n\n        Returns:\n            cst.Module: The updated Module node with a new docstring.\n        \"\"\"\n        return self._update_node_with_new_docstring(original_node, updated_node, self.module.__doc__)\n\n    def _get_obj_by_name(self, name: str) -> Optional[Any]:\n        \"\"\"\n        Gets an object by its name from the module dictionary.\n\n        Args:\n            name (str): The name of the object.\n\n        Returns:\n            Optional[Any]: The object if found, otherwise None.\n        \"\"\"\n        return self.module_dict.get(name, None)\n\n    def _update_node_with_new_docstring(\n            self, original_node: cst.CSTNode, updated_node: cst.CSTNode, docstring: Optional[str]) -> cst.CSTNode:\n        \"\"\"\n        Updates a node with a new docstring.\n\n        Args:\n            original_node (cst.CSTNode): The original node.\n            updated_node (cst.CSTNode): The updated node.\n            docstring (Optional[str]): The new docstring.\n\n        Returns:\n            cst.CSTNode: The updated node with the new docstring.\n        \"\"\"\n        node_code = cst.Module([]).code_for_node(original_node)\n        old_docstring = docstring\n        new_body = []\n\n        if isinstance(updated_node.body, tuple):\n            body = updated_node.body\n        else:\n            body = getattr(updated_node.body, 'body', [])\n\n        # Extract existing docstring if present and build new body without it\n        for stmt in body:\n            if m.matches(stmt, m.SimpleStatementLine(body=[m.Expr(m.SimpleString())])):\n                old_docstring = cst.ensure_type(stmt.body[0].value, cst.SimpleString).value.strip('\\\"\\'')\n            else:\n                new_body.append(stmt)\n\n        new_docstring = self.gen_docstring(old_docstring, node_code)\n\n        # Create a new docstring node if new_docstring is provided\n        new_docstring_node = (\n            cst.SimpleStatementLine([cst.Expr(cst.SimpleString(f'\"\"\"{new_docstring}\"\"\"'))]) if new_docstring else None\n        )\n\n        if new_docstring_node:\n            # Check if the function body is a SimpleStatementSuite (single-line function)\n            if isinstance(updated_node.body, cst.SimpleStatementSuite):\n                # Create a new IndentedBlock containing the original function body statements\n                new_body = cst.IndentedBlock(\n                    body=[\n                        new_docstring_node,\n                        cst.SimpleStatementLine(\n                            body=[\n                                cst.Expr(\n                                    value=updated_node.body.body[0]\n                                )\n                            ]\n                        )\n                    ]\n                )\n\n                # Replace the original function body with the new IndentedBlock\n                return updated_node.with_changes(body=new_body)\n            else:\n                new_body.insert(0, new_docstring_node)\n\n        # Update the body with the new list of statements\n        try:\n            if isinstance(updated_node.body, tuple):\n                updated_body = tuple(new_body)\n            else:\n                updated_body = updated_node.body.with_changes(body=new_body)\n        except Exception as e:\n            print(f\"Error updating body with new statements: {new_body}\")\n            print(f\"Error message: {e}\")\n            raise\n\n        return updated_node.with_changes(body=updated_body)\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/manager/custom.py", "content": "from typing import Optional\nfrom lazynote.manager.base import BaseManager\n\nclass CustomManager(BaseManager):\n    def gen_docstring(self, old_docstring: Optional[str], pattern: str, node_code: str) -> str:\n        \"\"\"\n        Custom logic to generate a new docstring.\n\n        Args:\n            old_docstring (Optional[str]): The old docstring.\n            pattern (str): The pattern string to be added.\n            node_code (str): The node code.\n\n        Returns:\n            str: The new docstring.\n        \"\"\"\n        if old_docstring:\n            return f\"{old_docstring}\\n\\n{pattern}\"\n        else:\n            return f\"{pattern}\"\n"}
{"type": "source_file", "path": "examples/rag_online.py", "content": "# -*- coding: utf-8 -*-\n# flake8: noqa: F821\n\nimport lazyllm\nfrom lazyllm import pipeline, parallel, bind, OnlineEmbeddingModule, SentenceSplitter, Document, Retriever, Reranker\n\n# Before running, set the environment variable:\n#\n# 1. `export LAZYLLM_GLM_API_KEY=xxxx`: the API key of Zhipu AI, default model \"glm-4\", `source=\"glm\"`.\n#     You can apply for the API key at https://open.bigmodel.cn/\n#     Also supports other API keys:\n#       - LAZYLLM_OPENAI_API_KEY: the API key of OpenAI, default model \"gpt-3.5-turbo\", `source=\"openai\"`.\n#           You can apply for the API key at https://openai.com/index/openai-api/\n#       - LAZYLLM_KIMI_API_KEY: the API key of Moonshot AI, default model \"moonshot-v1-8k\", `source=\"kimi\"`.\n#           You can apply for the API key at https://platform.moonshot.cn/console\n#       - LAZYLLM_QWEN_API_KEY: the API key of Alibaba Cloud, default model \"qwen-plus\", `source=\"qwen\"`.\n#           You can apply for the API key at https://home.console.aliyun.com/\n#       - LAZYLLM_SENSENOVA_API_KEY: the API key of SenseTime, default model \"SenseChat-5\", `source=\"sensenova\"`.\n#                                  You also have to set LAZYLLM_SENSENOVA_SECRET_KEY` togather.\n#           You can apply for the API key at https://platform.sensenova.cn/home\n#     * `source` needs to be specified for multiple API keys, but it does not need to be set for a single API key.\n#\n# 2. `export LAZYLLM_DATA_PATH=path/to/docs/folder/`: The parent folder of the document folder `rag_master`.\n#                                                    Alternatively, you can set the `dataset_path` of the Document\n#                                                    to `path/to/docs/folder/rag_master` to replace\n#                                                    the setting of this environment variable.\n\nprompt = 'You will play the role of an AI Q&A assistant and complete a dialogue task. In this task, you need to provide your answer based on the given context and question.'\n\ndocuments = Document(dataset_path=\"rag_master\", embed=OnlineEmbeddingModule(), manager=False)\ndocuments.create_node_group(name=\"sentences\", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)\n\nwith pipeline() as ppl:\n    with parallel().sum as ppl.prl:\n        prl.retriever1 = Retriever(documents, group_name=\"sentences\", similarity=\"cosine\", topk=3)\n        prl.retriever2 = Retriever(documents, \"CoarseChunk\", \"bm25_chinese\", 0.003, topk=3)\n    ppl.reranker = Reranker(\"ModuleReranker\", model=OnlineEmbeddingModule(type=\"rerank\"), topk=1, output_format='content', join=True) | bind(query=ppl.input)\n    ppl.formatter = (lambda nodes, query: dict(context_str=nodes, query=query)) | bind(query=ppl.input)\n    ppl.llm = lazyllm.OnlineChatModule(stream=False).prompt(lazyllm.ChatPrompter(prompt, extra_keys=[\"context_str\"]))\n\n\nif __name__ == \"__main__\":\n    lazyllm.WebModule(ppl, port=range(23467, 24000)).start().wait()\n"}
{"type": "source_file", "path": "examples/multimodal_agent.py", "content": "# -*- coding: utf-8 -*-\n# flake8: noqa: F501\n\n# Three ways to specify the model:\n#   1. Specify the model name (e.g. 'internlm2-chat-7b'):\n#           the model will be automatically downloaded from the Internet;\n#   2. Specify the model name (e.g. 'internlm2-chat-7b') ​​+ set\n#      the environment variable `export LAZYLLM_MODEL_PATH=\"/path/to/modelzoo\"`:\n#           the model will be found in `path/to/modelazoo/internlm2-chat-7b/`\n#   3. Directly pass the absolute path to TrainableModule:\n#           `path/to/modelazoo/internlm2-chat-7b`\n\nfrom lazyllm import TrainableModule, WebModule, deploy, pipeline, switch, _0\n\n# Write prompt words:\nchatflow_intent_list = [\"Chat\", \"Speech Recognition\", \"Image QA\", \"Drawing\", \"Generate Music\", \"Text to Speech\"]\nagent_prompt = f\"\"\"\nYou are now an intent classification engine, responsible for analyzing user input text based on dialogue information and determining a unique intent category.\\nOnly reply with the name of the intent, do not output any additional fields, and do not translate. \"intent_list\" is the list of all intent names.\\n\nIf the input contains attachments, determine the intent based on the attachment file extension with the highest priority: if it is an image extension like .jpg, .png, etc., then output: Image QA; if it is an audio extension like .mp3, .wav, etc., then output: Speech Recognition.\n## intent_list:\\n{chatflow_intent_list}\\n\\n## Example\\nUser: Hello\\nAssistant: Chat\n\"\"\"\npainter_prompt = 'Now you are a master of drawing prompts, capable of converting any Chinese content entered by the user into English drawing prompts. In this task, you need to convert any input content into English drawing prompts, and you can enrich and expand the prompt content.'\nmusician_prompt = 'Now you are a master of music composition prompts, capable of converting any Chinese content entered by the user into English music composition prompts. In this task, you need to convert any input content into English music composition prompts, and you can enrich and expand the prompt content.'\n# Large language model:\nbase = TrainableModule('internlm2-chat-7b').prompt(agent_prompt)\nchat = base.share().prompt()\n# Assemble application:\nwith pipeline() as ppl:\n    ppl.cls = base\n    ppl.cls_normalizer = lambda x: x if x in chatflow_intent_list else chatflow_intent_list[0]\n    with switch(judge_on_full_input=False).bind(_0, ppl.input) as ppl.sw:\n        ppl.sw.case[chatflow_intent_list[0], chat]\n        ppl.sw.case[chatflow_intent_list[1], TrainableModule('SenseVoiceSmall')]\n        ppl.sw.case[chatflow_intent_list[2], TrainableModule('internvl-chat-2b-v1-5').deploy_method(deploy.LMDeploy)]\n        ppl.sw.case[chatflow_intent_list[3], pipeline(base.share().prompt(painter_prompt), TrainableModule('stable-diffusion-3-medium'))]\n        ppl.sw.case[chatflow_intent_list[4], pipeline(base.share().prompt(musician_prompt), TrainableModule('musicgen-small'))]\n        ppl.sw.case[chatflow_intent_list[5], TrainableModule('ChatTTS')]\n# Start application:\nif __name__ == '__main__':\n    WebModule(ppl, history=[chat], audio=True, port=8847).start().wait()\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/schema.py", "content": "import inspect\nfrom enum import Enum\n\nclass MemberType(str, Enum):\n    \"\"\"Enumeration for different types of members in a module.\"\"\"\n    PACKAGE = \"package\"\n    MODULE = \"module\"\n    CLASS = \"class\"\n    METHOD = \"method\"\n    FUNCTION = \"function\"\n    ATTRIBUTE = \"attribute\"\n    PROPERTY = \"property\"\n\ndef get_member_type(member: object) -> MemberType:\n    \"\"\"\n    Determine the type of a given member.\n\n    Args:\n        member (object): The member to be checked.\n\n    Returns:\n        MemberType: The type of the member.\n    \"\"\"\n    member_checks = {\n        MemberType.PACKAGE: lambda m: inspect.ismodule(m) and hasattr(m, '__path__'),\n        MemberType.MODULE: inspect.ismodule,\n        MemberType.CLASS: inspect.isclass,\n        MemberType.METHOD: inspect.ismethod,\n        MemberType.FUNCTION: inspect.isfunction,\n        MemberType.PROPERTY: lambda m: isinstance(m, property)\n    }\n\n    for member_type, check in member_checks.items():\n        if check(member):\n            return member_type\n    return MemberType.ATTRIBUTE\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/manager/simple.py", "content": "from typing import Callable, Optional\nfrom lazynote.manager.base import BaseManager, DocstringMode\n\nclass DocstringHandler:\n    @staticmethod\n    def handle_translate(old_docstring: Optional[str], node_code: str) -> str:\n        \"\"\"\n        Handle translation of the docstring.\n\n        Args:\n            old_docstring (Optional[str]): The old docstring.\n            node_code (str): The node code.\n\n        Returns:\n            str: The translated docstring.\n        \"\"\"\n        # TODO: Implement translation logic\n        return f\"Translated: {old_docstring}\" or None\n\n    @staticmethod\n    def handle_polish(old_docstring: Optional[str], node_code: str) -> str:\n        \"\"\"\n        Handle polishing of the docstring.\n\n        Args:\n            old_docstring (Optional[str]): The old docstring.\n            node_code (str): The node code.\n\n        Returns:\n            str: The polished docstring.\n        \"\"\"\n        # TODO: Implement polishing logic\n        return f\"Polished: {old_docstring}\" or None\n\n    @staticmethod\n    def handle_clear(old_docstring: Optional[str], node_code: str) -> str:\n        \"\"\"\n        Handle clearing of the docstring.\n\n        Args:\n            old_docstring (Optional[str]): The old docstring.\n            node_code (str): The node code.\n\n        Returns:\n            str: None, indicating the docstring should be cleared.\n        \"\"\"\n        return None\n\n    @staticmethod\n    def handle_fill(old_docstring: Optional[str], node_code: str) -> str:\n        \"\"\"\n        Handle filling of the docstring.\n\n        Args:\n            old_docstring (Optional[str]): The old docstring.\n            node_code (str): The node code.\n\n        Returns:\n            str: The filled docstring.\n        \"\"\"\n        if old_docstring:\n            return f\"{old_docstring}\"\n        else:\n            return None\n\n    @staticmethod\n    def get_handler(pattern: DocstringMode) -> Callable[[Optional[str], str], str]:\n        \"\"\"\n        Get the handler function based on the docstring mode.\n\n        Args:\n            pattern (DocstringMode): The docstring handling pattern.\n\n        Returns:\n            Callable[[Optional[str], str], str]: The handler function.\n\n        Raises:\n            ValueError: If no handler is found for the given pattern.\n        \"\"\"\n        try:\n            handler_method_name = f\"handle_{pattern.value}\"\n            return getattr(DocstringHandler, handler_method_name)\n        except AttributeError:\n            raise ValueError(f\"No handler found for pattern: {pattern}\")\n\nclass SimpleManager(BaseManager):\n    \"\"\"\n    SimpleManager class to generate docstrings based on a given pattern.\n\n    Attributes:\n        pattern (DocstringMode): The docstring handling pattern.\n    \"\"\"\n\n    def gen_docstring(self, old_docstring: Optional[str], node_code: str) -> str:\n        \"\"\"\n        Generate a new docstring based on the given pattern.\n\n        Args:\n            old_docstring (Optional[str]): The old docstring.\n            node_code (str): The node code.\n\n        Returns:\n            str: The new docstring.\n        \"\"\"\n        handler = DocstringHandler.get_handler(self.pattern)\n        return handler(old_docstring, node_code)\n"}
{"type": "source_file", "path": "examples/rag_map_store_with_milvus_index.py", "content": "# -*- coding: utf-8 -*-\n\nimport os\nimport lazyllm\nfrom lazyllm import bind\nimport tempfile\n\ndef run(query):\n    _, store_file = tempfile.mkstemp(suffix=\".db\")\n\n    milvus_store_conf = {\n        'type': 'map',\n        'indices': {\n            'smart_embedding_index': {\n                'backend': 'milvus',\n                'kwargs': {\n                    'uri': store_file,\n                    'index_kwargs': {\n                        'index_type': 'HNSW',\n                        'metric_type': 'COSINE',\n                    }\n                },\n            },\n        },\n    }\n\n    documents = lazyllm.Document(dataset_path=\"rag_master\",\n                                 embed=lazyllm.TrainableModule(\"bge-large-zh-v1.5\"),\n                                 manager=False,\n                                 store_conf=milvus_store_conf)\n\n    documents.create_node_group(name=\"sentences\",\n                                transform=lambda s: '。'.split(s))\n\n    prompt = 'You will play the role of an AI Q&A assistant and complete a dialogue task.'\\\n        ' In this task, you need to provide your answer based on the given context and question.'\n\n    with lazyllm.pipeline() as ppl:\n        ppl.retriever = lazyllm.Retriever(doc=documents, group_name=\"sentences\", topk=3,\n                                          index='smart_embedding_index')\n\n        ppl.reranker = lazyllm.Reranker(name='ModuleReranker',\n                                        model=\"bge-reranker-large\",\n                                        topk=1,\n                                        output_format='content',\n                                        join=True) | bind(query=ppl.input)\n\n        ppl.formatter = (\n            lambda nodes, query: dict(context_str=nodes, query=query)\n        ) | bind(query=ppl.input)\n\n        ppl.llm = lazyllm.TrainableModule('internlm2-chat-7b').prompt(\n            lazyllm.ChatPrompter(instruction=prompt, extra_keys=['context_str']))\n\n        rag = lazyllm.ActionModule(ppl)\n        rag.start()\n        res = rag(query)\n\n    os.remove(store_file)\n\n    return res\n\nif __name__ == '__main__':\n    res = run('何为天道？')\n    print(f'answer: {res}')\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/manager/__init__.py", "content": "from lazynote.manager.base import BaseManager\nfrom lazynote.manager.simple import SimpleManager, DocstringMode\n\n__all__ = [\n    'BaseManager',\n    'SimpleManager',\n    'DocstringMode'\n]\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/config/__init__.py", "content": "import sys\nfrom pathlib import Path\n\nfrom dynaconf import Dynaconf\n\n\n_base_dir = Path(__file__).parent.parent\n\n_settings_files = [\n    # All config file will merge.\n    Path(__file__).parent / 'settings.yml',  # Load default config.\n]\n\n# User configuration. It will be created automatically by the pip installer .\n_external_files = [\n    Path(sys.prefix, 'etc', 'lazynote', 'settings.yml')\n]\n\nsettings = Dynaconf(\n    # Set env `LAZYNOTE_FOO='bar'`，use `settings.FOO` .\n    envvar_prefix='LAZYNOTE',\n    settings_files=_settings_files,  # load user configuration.\n    # environments=True,  # Enable multi-level configuration，eg: default, development, production\n    load_dotenv=True,  # Enable load .env\n    # env_switcher='LAZYNOTE_ENV',\n    lowercase_read=False,  # If true, can't use `settings.foo`, but can only use `settings.FOO`\n    includes=_external_files,  # Customs settings.\n    base_dir=_base_dir,  # `settings.BASE_DIR`\n)\n"}
{"type": "source_file", "path": "examples/rag.py", "content": "# -*- coding: utf-8 -*-\n# flake8: noqa: F821\n\nimport lazyllm\nfrom lazyllm import pipeline, parallel, bind, Document, Retriever, Reranker, SentenceSplitter\n\nprompt = (\n    \"作为国学大师，你将扮演一个人工智能国学问答助手的角色，完成一项对话任务。在这个任务中，你需要根据给定的已知国学篇章以及问题，给出你的结论。请注意，你的回答应基于给定的国学篇章，而非你的先验知识，且注意你回答的前后逻辑不要出现\"\n    \"重复，且不需要提到具体文件名称。\\n任务示例如下：\\n示例国学篇章：《礼记 大学》大学之道，在明明德，在亲民，在止于至善。\\n问题：什么是大学？\\n回答：“大学”在《礼记》中代表的是一种理想的教育和社会实践过程，旨在通过个人的\"\n    \"道德修养和社会实践达到最高的善治状态。\\n注意以上仅为示例，禁止在下面任务中提取或使用上述示例已知国学篇章。\\n现在，请对比以下给定的国学篇章和给出的问题。如果已知国学篇章中有该问题相关的原文，请提取相关原文出来。\\n\"\n    \"已知国学篇章：{context_str}\\n问题: {query}\\n回答：\\n\"\n)\n\n# Three ways to specify the model:\n#   1. Specify the model name (e.g. 'internlm2-chat-7b'):\n#           the model will be automatically downloaded from the Internet;\n#   2. Specify the model name (e.g. 'internlm2-chat-7b') ​​+ set\n#      the environment variable `export LAZYLLM_MODEL_PATH=\"/path/to/modelzoo\"`:\n#           the model will be found in `path/to/modelazoo/internlm2-chat-7b/`\n#   3. Directly pass the absolute path to TrainableModule:\n#           `path/to/modelazoo/internlm2-chat-7b`\nembed_model = lazyllm.TrainableModule(\"bge-large-zh-v1.5\")\ndocuments = Document(dataset_path=\"rag_master\", embed=embed_model, manager=False)\ndocuments.create_node_group(name=\"sentences\", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)\n\nwith pipeline() as ppl:\n    with parallel().sum as ppl.prl:\n        prl.retriever1 = Retriever(documents, group_name=\"sentences\", similarity=\"cosine\", topk=3)\n        prl.retriever2 = Retriever(documents, \"CoarseChunk\", \"bm25_chinese\", 0.003, topk=3)\n    ppl.reranker = Reranker(\"ModuleReranker\", model=\"bge-reranker-large\", topk=1, output_format='content', join=True) | bind(query=ppl.input)\n    ppl.formatter = (lambda nodes, query: dict(context_str=nodes, query=query)) | bind(query=ppl.input)\n    ppl.llm = lazyllm.TrainableModule(\"internlm2-chat-7b\").prompt(lazyllm.ChatPrompter(prompt, extra_keys=[\"context_str\"]))\n\n\nif __name__ == \"__main__\":\n    lazyllm.WebModule(ppl, port=range(23466, 24000)).start().wait()\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/parser/base.py", "content": "from lazynote.schema import MemberType, get_member_type\n\nclass BaseParser:\n    def __init__(self):\n        self.parsers = {\n            MemberType.MODULE: self.parse_module,\n            MemberType.CLASS: self.parse_class,\n            MemberType.METHOD: self.parse_method,\n            MemberType.FUNCTION: self.parse_function,\n            MemberType.PROPERTY: self.parse_property,\n            MemberType.ATTRIBUTE: self.parse_attribute\n        }\n\n    def parse(self, member, manager, **kwargs):\n        member_type = get_member_type(member)\n        parser = self.parsers.get(member_type)\n        if parser:\n            parser(member, manager, **kwargs)\n\n    def parse_module(self, module, manager, **kwargs):\n        print(f\"--Module: {module.__name__}--\")\n        manager.modify_docstring(module)\n\n    def parse_class(self, cls, manager, **kwargs):\n        print(f\"Class: {cls.__name__}\")\n\n    def parse_method(self, method, manager, **kwargs):\n        print(f\"  Method: {method.__name__}\")\n\n    def parse_function(self, func, manager, **kwargs):\n        print(f\"Function: {func.__name__}\")\n\n    def parse_property(self, prop, manager, **kwargs):\n        print(f\"  Property: {prop}\")\n\n    def parse_attribute(self, attr, manager, **kwargs):\n        print(f\"  Attribute: {attr}\")\n"}
{"type": "source_file", "path": "examples/painting.py", "content": "import lazyllm\nfrom lazyllm import pipeline\n\n# Three ways to specify the model:\n#   1. Specify the model name (e.g. 'internlm2-chat-7b'):\n#           the model will be automatically downloaded from the Internet;\n#   2. Specify the model name (e.g. 'internlm2-chat-7b') ​​+ set\n#      the environment variable `export LAZYLLM_MODEL_PATH=\"/path/to/modelzoo\"`:\n#           the model will be found in `path/to/modelazoo/internlm2-chat-7b/`\n#   3. Directly pass the absolute path to TrainableModule:\n#           `path/to/modelazoo/internlm2-chat-7b`\n\nprompt = ('You are a drawing prompt word master who can convert any Chinese content entered by '\n          'the user into English drawing prompt words. In this task, you need to convert any '\n          'input content into English drawing prompt words, and you can enrich and expand the '\n          'prompt word content.')\n\nwith pipeline() as ppl:\n    ppl.llm = lazyllm.TrainableModule('internlm2-chat-7b').prompt(lazyllm.ChatPrompter(prompt))\n    ppl.sd3 = lazyllm.TrainableModule('stable-diffusion-3-medium')\n\nif __name__ == '__main__':\n    lazyllm.WebModule(ppl, port=23466).start().wait()\n"}
{"type": "source_file", "path": "examples/chatbot_online_cli.py", "content": "import lazyllm\n\n# Before running, set the environment variable:\n#\n# 1. `export LAZYLLM_GLM_API_KEY=xxxx`: the API key of Zhipu AI, default model \"glm-4\", `source=\"glm\"`.\n#     You can apply for the API key at https://open.bigmodel.cn/\n#     Also supports other API keys:\n#       - LAZYLLM_OPENAI_API_KEY: the API key of OpenAI, default model \"gpt-3.5-turbo\", `source=\"openai\"`.\n#           You can apply for the API key at https://openai.com/index/openai-api/\n#       - LAZYLLM_KIMI_API_KEY: the API key of Moonshot AI, default model \"moonshot-v1-8k\", `source=\"kimi\"`.\n#           You can apply for the API key at https://platform.moonshot.cn/console\n#       - LAZYLLM_QWEN_API_KEY: the API key of Alibaba Cloud, default model \"qwen-plus\", `source=\"qwen\"`.\n#           You can apply for the API key at https://home.console.aliyun.com/\n#       - LAZYLLM_SENSENOVA_API_KEY: the API key of SenseTime, default model \"SenseChat-5\", `source=\"sensenova\"`.\n#                                  You also have to set LAZYLLM_SENSENOVA_SECRET_KEY` togather.\n#           You can apply for the API key at https://platform.sensenova.cn/home\n#     * `source` needs to be specified for multiple API keys, but it does not need to be set for a single API key.\n\nchat = lazyllm.OnlineChatModule()\n\n# history has the form of [[query1, answer1], [quer2, answer2], ...]\nhistory = []\n\nwhile True:\n    query = input(\"query(enter 'quit' to exit): \")\n    if query == \"quit\":\n        break\n    res = chat(query, llm_chat_history=history)\n    print(f\"answer: {str(res)}\\n\")\n    history.append([query, res])\n"}
{"type": "source_file", "path": "lazyllm/cli/run.py", "content": "import sys\nimport argparse\nimport json\n\nimport lazyllm\nfrom lazyllm.engine.lightengine import LightEngine\nfrom lazyllm.tools.train_service.serve import TrainServer\nfrom lazyllm.tools.infer_service.serve import InferServer\n\n# lazyllm run xx.json / xx.dsl / xx.lazyml\n# lazyllm run chatbot --model=xx --framework=xx --source=xx\n# lazyllm run rag --model=xx --framework=xx --source=xx --documents=''\n\ndef chatbot(llm):\n    import lazyllm\n    lazyllm.WebModule(llm, port=range(20000, 25000)).start().wait()\n\n\ndef rag(llm, docpath):\n    import lazyllm\n    from lazyllm import pipeline, parallel, bind, SentenceSplitter, Document, Retriever, Reranker\n    prompt = ('You will play the role of an AI Q&A assistant and complete a dialogue task. In this '\n              'task, you need to provide your answer based on the given context and question.')\n\n    documents = Document(dataset_path=docpath, embed=lazyllm.OnlineEmbeddingModule(), manager=False)\n    documents.create_node_group(name=\"sentences\", transform=SentenceSplitter, chunk_size=1024, chunk_overlap=100)\n\n    with pipeline() as ppl:\n        with parallel().sum as ppl.prl:\n            ppl.prl.retriever1 = Retriever(documents, group_name=\"sentences\", similarity=\"cosine\", topk=3)\n            ppl.prl.retriever2 = Retriever(documents, \"CoarseChunk\", \"bm25_chinese\", 0.003, topk=3)\n\n        ppl.reranker = Reranker(\"ModuleReranker\", model=\"bge-reranker-large\", topk=1) | bind(query=ppl.input)\n        ppl.formatter = (lambda nodes, query: dict(context_str=\"\".join([node.get_content() for node in nodes]),\n                                                   query=query)) | bind(query=ppl.input)\n        ppl.llm = llm.prompt(lazyllm.ChatPrompter(prompt, extra_keys=[\"context_str\"]))\n\n    lazyllm.WebModule(ppl, port=range(20000, 25000)).start().wait()\n\ndef graph(json_file):\n    with open(json_file) as fp:\n        engine_conf = json.load(fp)\n\n    engine = LightEngine()\n    eid = engine.start(engine_conf.get('nodes', []), engine_conf.get('edges', []),\n                       engine_conf.get('resources', []))\n    while True:\n        query = input(\"query(enter 'quit' to exit): \")\n        if query == 'quit':\n            break\n        res = engine.run(eid, query)\n        print(f'answer: {res}')\n\ndef training_service():\n    train_server = TrainServer()\n    local_server = lazyllm.ServerModule(train_server, launcher=lazyllm.launcher.EmptyLauncher(sync=False))\n    local_server.start()\n    local_server()\n    local_server.wait()\n\ndef infer_service():\n    infer_server = InferServer()\n    local_server = lazyllm.ServerModule(infer_server, launcher=lazyllm.launcher.EmptyLauncher(sync=False))\n    local_server.start()\n    local_server()\n    local_server.wait()\n\ndef run(commands):\n    if not commands:\n        print('Usage:\\n  lazyllm run graph.json\\n  lazyllm run chatbot\\n  '\n              'lazyllm run rag\\n  lazyllm run training_service\\n  '\n              'lazyllm run infer_service\\n')\n\n    parser = argparse.ArgumentParser(description='lazyllm deploy command')\n    parser.add_argument('command', type=str, help='command')\n\n    args, _ = parser.parse_known_args(commands)\n\n    if args.command in ('chatbot', 'rag'):\n        parser.add_argument('--model', type=str, default=None, help='model name')\n        parser.add_argument('--source', type=str, default=None, help='Online model source, conflict with framework',\n                            choices=['openai', 'sensenova', 'glm', 'kimi', 'qwen', 'doubao'])\n        parser.add_argument('--framework', type=str, default=None, help='Online model source, conflict with source',\n                            choices=['lightllm', 'vllm', 'lmdeploy'])\n        if args.command == 'rag':\n            parser.add_argument('--documents', required=True, type=str, help='document absolute path')\n\n        args = parser.parse_args(commands)\n        import lazyllm\n        llm = lazyllm.AutoModel(args.model, args.source, args.framework)\n\n        if args.command == 'chatbot':\n            chatbot(llm)\n        elif args.command == 'rag':\n            rag(llm, args.documents)\n    elif args.command.endswith('.json'):\n        graph(args.command)\n    elif args.command == 'training_service':\n        training_service()\n    elif args.command == 'infer_service':\n        infer_service()\n    else:\n        print('lazyllm run is not ready yet.')\n        sys.exit(0)\n"}
{"type": "source_file", "path": "examples/tts_chattts.py", "content": "import lazyllm\n\n# ChatTTS supports 30 seconds of voice. However, the stability of the voice roles is poor,\n# so a random number seed is set here to lock the voice role.\n\n# Three ways to specify the model:\n#   1. Specify the model name (e.g. 'ChatTTS'):\n#           the model will be automatically downloaded from the Internet;\n#   2. Specify the model name (e.g. 'ChatTTS') ​​+ set\n#      the environment variable `export LAZYLLM_MODEL_PATH=\"/path/to/modelzoo\"`:\n#           the model will be found in `path/to/modelazoo/ChatTTS/`\n#   3. Directly pass the absolute path to TrainableModule:\n#           `path/to/modelazoo/ChatTTS`\n\nm = lazyllm.TrainableModule('ChatTTS')\nm.name = \"tts\"\n\nif __name__ == '__main__':\n    lazyllm.WebModule(\n        m,\n        port=12498,\n        components={\n            m: [('spk_emb', 'Text', 12)]\n        }\n    ).start().wait()\n"}
{"type": "source_file", "path": "examples/stt_sensevoice.py", "content": "import lazyllm\n\n# Note that if you cannot access the microphone, you need to enter the\n# browser: chrome://flags/#unsafely-treat-insecure-origin-as-secure,\n# fill in the access address URL, and agree to enable the microphone.\n\n# Three ways to specify the model:\n#   1. Specify the model name (e.g. 'SenseVoiceSmall'):\n#           the model will be automatically downloaded from the Internet;\n#   2. Specify the model name (e.g. 'SenseVoiceSmall') ​​+ set\n#      the environment variable `export LAZYLLM_MODEL_PATH=\"/path/to/modelzoo\"`:\n#           the model will be found in `path/to/modelazoo/SenseVoiceSmall/`\n#   3. Directly pass the absolute path to TrainableModule:\n#           `path/to/modelazoo/SenseVoiceSmall`\n\nchat = lazyllm.TrainableModule('SenseVoiceSmall')\n\nif __name__ == '__main__':\n    # Note:\n    # 1. that audio is enabled here\n    # 2. If `files_target` is not set, then all acceptable file modules can access the input file.\n    #    If it is set, only the specified modules can access the input file.\n    lazyllm.WebModule(chat, port=8847, audio=True, files_target=chat).start().wait()\n"}
{"type": "source_file", "path": "examples/tts_bark.py", "content": "import lazyllm\n\n# Bark only supports 13-15 seconds of voice, and the Chinese voice is not very authentic.\n\n# Three ways to specify the model:\n#   1. Specify the model name (e.g. 'bark'):\n#           the model will be automatically downloaded from the Internet;\n#   2. Specify the model name (e.g. 'bark') ​​+ set\n#      the environment variable `export LAZYLLM_MODEL_PATH=\"/path/to/modelzoo\"`:\n#           the model will be found in `path/to/modelazoo/bark/`\n#   3. Directly pass the absolute path to TrainableModule:\n#           `path/to/modelazoo/bark`\n\nm = lazyllm.TrainableModule('bark')\nm.name = \"tts\"\n\nif __name__ == '__main__':\n    lazyllm.WebModule(\n        m,\n        port=8847,\n        components={\n            m: [('voice_preset', 'Dropdown', [\n                \"v2/zh_speaker_0\",\n                \"v2/zh_speaker_1\",\n                \"v2/zh_speaker_2\",\n                \"v2/zh_speaker_3\",\n                \"v2/zh_speaker_4\",\n                \"v2/zh_speaker_5\",\n                \"v2/zh_speaker_6\",\n                \"v2/zh_speaker_7\",\n                \"v2/zh_speaker_8\",\n                \"v2/zh_speaker_9\",\n            ])],\n        }\n    ).start().wait()\n"}
{"type": "source_file", "path": "lazyllm/cli/__init__.py", "content": ""}
{"type": "source_file", "path": "lazyllm/__init__.py", "content": "# -*- coding: utf-8 -*-\n\nfrom .configs import config\nfrom .configs import * # noqa F401 of Config\nfrom .common import *  # noqa F403\nfrom .launcher import LazyLLMLaunchersBase\nfrom .flow import *  # noqa F403\nfrom .components import (LazyLLMDataprocBase, LazyLLMFinetuneBase, LazyLLMDeployBase,\n                         LazyLLMValidateBase, register as component_register, Prompter,\n                         AlpacaPrompter, ChatPrompter, FastapiApp, JsonFormatter, FileFormatter)\n\nfrom .module import (ModuleBase, ModuleBase as Module, UrlModule, TrainableModule, ActionModule,\n                     ServerModule, TrialModule, register as module_register,\n                     OnlineChatModule, OnlineEmbeddingModule, AutoModel)\nfrom .client import redis_client\nfrom .hook import LazyLLMHook\nfrom .tools import (Document, Reranker, Retriever, WebModule, ToolManager, FunctionCall,\n                    FunctionCallAgent, fc_register, ReactAgent, PlanAndSolveAgent, ReWOOAgent, SentenceSplitter,\n                    LLMParser)\nfrom .docs import add_doc\n\nconfig.done()\n\n\ndel LazyLLMRegisterMetaClass  # noqa F821\ndel _get_base_cls_from_registry  # noqa F821\n\n\n__all__ = [\n    # components\n    'LazyLLMDataprocBase',  #\n    'LazyLLMFinetuneBase',        # finetune\n    'LazyLLMDeployBase',          # deploy\n    'LazyLLMValidateBase',        #\n    'component_register',\n    'Prompter',\n    'AlpacaPrompter',\n    'ChatPrompter',\n    'FastapiApp',\n    'JsonFormatter',\n    'FileFormatter',\n\n    # launcher\n    'LazyLLMLaunchersBase',        # empty, slurm, sco\n\n    # configs\n    'Mode',\n\n    # module\n    'ModuleBase',\n    'Module',\n    'UrlModule',\n    'TrainableModule',\n    'ActionModule',\n    'ServerModule',\n    'WebModule',\n    'TrialModule',\n    'module_register',\n    'OnlineChatModule',\n    'OnlineEmbeddingModule',\n    'AutoModel',\n\n    # client\n    'redis_client',\n\n    # hook\n    'LazyLLMHook',\n\n    # tools\n    'Document',\n    'Retriever',\n    'Reranker',\n    'ToolManager',\n    'FunctionCall',\n    'FunctionCallAgent',\n    'fc_register',\n    \"LLMParser\",\n    'ReactAgent',\n    'PlanAndSolveAgent',\n    'ReWOOAgent',\n    'SentenceSplitter',\n\n    # docs\n    'add_doc',\n]\n\n__all__ += common.__all__  # noqa F405\n__all__ += flow.__all__  # noqa F405\n"}
{"type": "source_file", "path": "examples/multimodal_chatbot_online.py", "content": "import lazyllm\n\n# Before running, set the environment variable:\n#\n# 1. `export LAZYLLM_GLM_API_KEY=xxxx`: the API key of Zhipu AI, you need to set `source=\"glm\"` and\n#     `model=\"glm-4v-flash\"`. You can apply for the API key at https://open.bigmodel.cn/\n#     Also supports other API keys:\n#       - LAZYLLM_OPENAI_API_KEY: the API key of OpenAI, set `source=\"openai\"` and `model=\"gpt-4o-mini\"`.\n#           You can apply for the API key at https://openai.com/index/openai-api/\n#       - LAZYLLM_KIMI_API_KEY: the API key of Moonshot AI, set `source=\"kimi\"` and\n#           `model=\"moonshot-v1-8k-vision-preview\"`.\n#           You can apply for the API key at https://platform.moonshot.cn/console\n#       - LAZYLLM_QWEN_API_KEY: the API key of Alibaba Cloud, set `source=\"qwen\"` and `model=\"qwenvl-max\"`.\n#           You can apply for the API key at https://home.console.aliyun.com/\n#       - LAZYLLM_SENSENOVA_API_KEY: the API key of SenseTime, set `source=\"sensenova\"` and `model=\"SenseChat-Vision\"`.\n#                                  You also have to set LAZYLLM_SENSENOVA_SECRET_KEY` togather.\n#           You can apply for the API key at https://platform.sensenova.cn/home\n#     * `source` needs to be specified for multiple API keys, but it does not need to be set for a single API key.\n\nchat = lazyllm.OnlineChatModule(source=\"glm\", model=\"glm-4v-flash\")\n\nif __name__ == '__main__':\n    lazyllm.WebModule(chat, port=range(23466, 23470), files_target=chat).start().wait()\n"}
{"type": "source_file", "path": "examples/story.py", "content": "# -*- coding: utf-8 -*-\n\nimport lazyllm\nfrom lazyllm import pipeline, warp, bind\nfrom lazyllm.components.formatter import JsonFormatter\n\n# Three ways to specify the model:\n#   1. Specify the model name (e.g. 'internlm2-chat-7b'):\n#           the model will be automatically downloaded from the Internet;\n#   2. Specify the model name (e.g. 'internlm2-chat-7b') ​​+ set\n#      the environment variable `export LAZYLLM_MODEL_PATH=\"/path/to/modelzoo\"`:\n#           the model will be found in `path/to/modelazoo/internlm2-chat-7b/`\n#   3. Directly pass the absolute path to TrainableModule:\n#           `path/to/modelazoo/internlm2-chat-7b`\n\ntoc_prompt = \"\"\"\nYou are now an intelligent assistant. Your task is to understand the user's input and convert the outline into a list of nested dictionaries. Each dictionary contains a `title` and a `describe`, where the `title` should clearly indicate the level using Markdown format, and the `describe` is a description and writing guide for that section.\n\nPlease generate the corresponding list of nested dictionaries based on the following user input:\n\nExample output:\n[\n    {\n        \"title\": \"# Level 1 Title\",\n        \"describe\": \"Please provide a detailed description of the content under this title, offering background information and core viewpoints.\"\n    },\n    {\n        \"title\": \"## Level 2 Title\",\n        \"describe\": \"Please provide a detailed description of the content under this title, giving specific details and examples to support the viewpoints of the Level 1 title.\"\n    },\n    {\n        \"title\": \"### Level 3 Title\",\n        \"describe\": \"Please provide a detailed description of the content under this title, deeply analyzing and providing more details and data support.\"\n    }\n]\nUser input is as follows:\n\"\"\"  # noqa: E501\n\ncompletion_prompt = \"\"\"\nYou are now an intelligent assistant. Your task is to receive a dictionary containing `title` and `describe`, and expand the writing according to the guidance in `describe`.\n\nInput example:\n{\n    \"title\": \"# Level 1 Title\",\n    \"describe\": \"This is the description for writing.\"\n}\n\nOutput(Do not repeat \"title\"):\nThis is the expanded content for writing.\nReceive as follows:\n\n\"\"\"  # noqa: E501\n\nwriter_prompt = {\"system\": completion_prompt, \"user\": '{\"title\": {title}, \"describe\": {describe}}'}\n\nwith pipeline() as ppl:\n    ppl.outline_writer = lazyllm.TrainableModule('internlm2-chat-7b').formatter(JsonFormatter()).prompt(toc_prompt)\n    ppl.story_generater = warp(ppl.outline_writer.share(prompt=writer_prompt).formatter())\n    ppl.synthesizer = (lambda *storys, outlines: \"\\n\".join([f\"{o['title']}\\n{s}\" for s, o in zip(storys, outlines)])) | bind(outlines=ppl.output(\"outline_writer\"))  # noqa: E501\n\nif __name__ == '__main__':\n    lazyllm.WebModule(ppl, port=range(23467, 24000)).start().wait()\n"}
{"type": "source_file", "path": "lazyllm/cli/deploy.py", "content": "import argparse\nimport time\n\ndef deploy(commands):\n    import lazyllm\n    parser = argparse.ArgumentParser(description=\"lazyllm deploy command\")\n    parser.add_argument(\"model\", help=\"model name\")\n    parser.add_argument(\"--framework\", help=\"deploy framework\", default=\"auto\",\n                        choices=[\"auto\", \"vllm\", \"lightllm\", \"lmdeploy\"])\n    parser.add_argument(\"--chat\", help=\"chat \", default='false',\n                        choices=[\"ON\", \"on\", \"1\", \"true\", \"True\", \"OFF\", \"off\", \"0\", \"False\", \"false\"])\n\n    args = parser.parse_args(commands)\n\n    t = lazyllm.TrainableModule(args.model).deploy_method(getattr(lazyllm.deploy, args.framework))\n    if args.chat in [\"ON\", \"on\", \"1\", \"true\", \"True\"]:\n        t = lazyllm.WebModule(t)\n    t.start()\n    if args.chat in [\"ON\", \"on\", \"1\", \"true\", \"True\"]:\n        t.wait()\n    else:\n        lazyllm.LOG.success(f'LazyLLM TrainableModule launched successfully:\\n  URL: {t._url}\\n  '\n                            f'Framework: {t._deploy_type.__name__}', flush=True)\n        while True:\n            time.sleep(10)\n"}
{"type": "source_file", "path": "lazyllm/cli/install.py", "content": "import sys\nimport subprocess\nimport toml\nimport requests\nimport platform\nimport os\n\nPYPROJECT_TOML_URL = \"https://raw.githubusercontent.com/LazyAGI/LazyLLM/main/pyproject.toml\"\n\ndef load_pyproject_from_lazyllm_path():\n    try:\n        import lazyllm\n        lazyllm_path = lazyllm.__path__[0]  # Get the path of the lazyllm package\n        pyproject_path = os.path.join(lazyllm_path, 'pyproject.toml')\n        if os.path.exists(pyproject_path):\n            with open(pyproject_path, 'r') as f:\n                return toml.load(f)\n        else:\n            return None\n    except (FileNotFoundError, toml.TomlDecodeError):\n        print(\"Could not find or parse pyproject.toml in lazyllm path.\")\n        return None\n\ndef load_local_pyproject():\n    try:\n        with open('pyproject.toml', 'r') as f:\n            return toml.load(f)\n    except (FileNotFoundError, toml.TomlDecodeError):\n        print(\"Could not find or parse the local pyproject.toml file.\")\n        sys.exit(1)\n\ndef load_remote_pyproject():\n    try:\n        response = requests.get(PYPROJECT_TOML_URL)\n        response.raise_for_status()\n        return toml.loads(response.text)\n    except (requests.RequestException, toml.TomlDecodeError) as e:\n        print(f\"Failed to download or parse remote pyproject.toml file: {e}\")\n        sys.exit(1)\n\ndef load_pyproject():\n    config = load_pyproject_from_lazyllm_path()\n    if config is not None:\n        return config\n    config = load_local_pyproject()\n    if config is not None:\n        return config\n    return load_remote_pyproject()\n\ndef load_packages():\n    config = load_pyproject()\n    try:\n        return config['tool']['poetry']['extras']\n    except KeyError:\n        print(\"No 'extras' information found in the pyproject.toml file.\")\n        sys.exit(1)\n\ndef load_dependencies():\n    config = load_pyproject()\n    try:\n        return config['tool']['poetry']['dependencies']\n    except KeyError:\n        print(\"No 'dependencies' information found in the pyproject.toml file.\")\n        sys.exit(1)\n\ndef install_packages(packages):\n    if isinstance(packages, str):\n        packages = [packages]\n    try:\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + packages)\n    except subprocess.CalledProcessError as e:\n        print(f\"安装失败: {e}\")\n        sys.exit(1)\n\ndef install_full():\n    packages = load_packages()\n    install_multiple_packages(packages['full'])\n    install_packages([\"flash-attn==2.7.0.post2\", \"transformers==4.46.1\"])\n\ndef install_standard():\n    packages = load_packages()\n    install_multiple_packages(packages['standard'])\n    install_packages(\"transformers==4.46.1\")\n\ndef parse_caret_to_tilde_version(version):\n    if version.startswith(\"^\"):\n        version_parts = version[1:].split(\".\")\n        if len(version_parts) > 1:\n            return f\"~={version_parts[0]}.{version_parts[1]}\"\n        else:\n            return f\"~={version_parts[0]}\"\n    return version\n\ndef process_package(package_name_with_version, dependencies):\n    if '==' in package_name_with_version:\n        package_name, _ = package_name_with_version.split('==', 1)\n        package_name = package_name.strip()\n    else:\n        package_name = package_name_with_version\n    if package_name in dependencies:\n        version_spec = dependencies[package_name]\n        if isinstance(version_spec, dict):\n            version_spec = version_spec.get('version', '')\n        elif isinstance(version_spec, str):\n            version_spec = version_spec.strip()\n        if version_spec == '*' or version_spec == '':\n            return package_name\n        elif version_spec.startswith(\"^\"):\n            version_spec = parse_caret_to_tilde_version(version_spec)\n        return f\"{package_name}{version_spec}\"\n    else:\n        print(f\"Error: Package '{package_name}' is not listed in the 'dependencies' section of pyproject.toml.\")\n        sys.exit(1)\n\ndef install_multiple_packages(package_names_with_versions):\n    dependencies = load_dependencies()\n    packages_to_install = []\n    for package in package_names_with_versions:\n        package_with_version = process_package(package, dependencies)\n        packages_to_install.append(package_with_version)\n    install_packages(packages_to_install)\n\ndef install(commands):\n    if not commands:\n        print(\"Usage: lazyllm install [full|standard|package_name]\")\n        sys.exit(1)\n\n    if platform.system() == \"Darwin\":\n        if any(command == \"full\" or command == \"standard\" for command in commands):\n            print(\"Installation of 'full' or 'standard' packages is not supported on macOS.\")\n            sys.exit(1)\n\n    if len(commands) == 1:\n        command = commands[0]\n        if command == \"full\":\n            install_full()\n        elif command == \"standard\":\n            install_standard()\n        else:\n            install_multiple_packages([command])\n    else:\n        install_multiple_packages(commands)\n"}
{"type": "source_file", "path": "examples/story_online.py", "content": "# -*- coding: utf-8 -*-\n\nimport lazyllm\nfrom lazyllm import pipeline, warp, bind\nfrom lazyllm.components.formatter import JsonFormatter\n\n# Before running, set the environment variable:\n#\n# 1. `export LAZYLLM_GLM_API_KEY=xxxx`: the API key of Zhipu AI, default model \"glm-4\", `source=\"glm\"`.\n#     You can apply for the API key at https://open.bigmodel.cn/\n#     Also supports other API keys:\n#       - LAZYLLM_OPENAI_API_KEY: the API key of OpenAI, default model \"gpt-3.5-turbo\", `source=\"openai\"`.\n#           You can apply for the API key at https://openai.com/index/openai-api/\n#       - LAZYLLM_KIMI_API_KEY: the API key of Moonshot AI, default model \"moonshot-v1-8k\", `source=\"kimi\"`.\n#           You can apply for the API key at https://platform.moonshot.cn/console\n#       - LAZYLLM_QWEN_API_KEY: the API key of Alibaba Cloud, default model \"qwen-plus\", `source=\"qwen\"`.\n#           You can apply for the API key at https://home.console.aliyun.com/\n#       - LAZYLLM_SENSENOVA_API_KEY: the API key of SenseTime, default model \"SenseChat-5\", `source=\"sensenova\"`.\n#                                  You also have to set LAZYLLM_SENSENOVA_SECRET_KEY` togather.\n#           You can apply for the API key at https://platform.sensenova.cn/home\n#     * `source` needs to be specified for multiple API keys, but it does not need to be set for a single API key.\n\ntoc_prompt = \"\"\"\nYou are now an intelligent assistant. Your task is to understand the user's input and convert the outline into a list of nested dictionaries. Each dictionary contains a `title` and a `describe`, where the `title` should clearly indicate the level using Markdown format, and the `describe` is a description and writing guide for that section.\n\nPlease generate the corresponding list of nested dictionaries based on the following user input:\n\nExample output:\n[\n    {\n        \"title\": \"# Level 1 Title\",\n        \"describe\": \"Please provide a detailed description of the content under this title, offering background information and core viewpoints.\"\n    },\n    {\n        \"title\": \"## Level 2 Title\",\n        \"describe\": \"Please provide a detailed description of the content under this title, giving specific details and examples to support the viewpoints of the Level 1 title.\"\n    },\n    {\n        \"title\": \"### Level 3 Title\",\n        \"describe\": \"Please provide a detailed description of the content under this title, deeply analyzing and providing more details and data support.\"\n    }\n]\nUser input is as follows:\n\"\"\"  # noqa: E50E\n\ncompletion_prompt = \"\"\"\nYou are now an intelligent assistant. Your task is to receive a dictionary containing `title` and `describe`, and expand the writing according to the guidance in `describe`.\n\nInput example:\n{\n    \"title\": \"# Level 1 Title\",\n    \"describe\": \"This is the description for writing.\"\n}\n\nOutput(Do not repeat \"title\"):\nThis is the expanded content for writing.\nReceive as follows:\n\n\"\"\"  # noqa: E50E\n\nwriter_prompt = {\"system\": completion_prompt, \"user\": '{\"title\": {title}, \"describe\": {describe}}'}\n\nwith pipeline() as ppl:\n    ppl.outline_writer = lazyllm.OnlineChatModule(stream=False).formatter(JsonFormatter()).prompt(toc_prompt)\n    ppl.story_generater = warp(lazyllm.OnlineChatModule(stream=False).prompt(writer_prompt))\n    ppl.synthesizer = (lambda *storys, outlines: \"\\n\".join([f\"{o['title']}\\n{s}\" for s, o in zip(storys, outlines)])) | bind(outlines=ppl.output('outline_writer'))  # noqa: E50E\n\nif __name__ == '__main__':\n    lazyllm.WebModule(ppl, port=range(23467, 24000)).start().wait()\n"}
{"type": "source_file", "path": "examples/distill_deepseek_r1.py", "content": "import os\nimport re\nimport json\nimport argparse\n\nimport lazyllm\nfrom lazyllm import finetune, deploy, launchers, warp\n\nfrom modelscope.msdatasets import MsDataset\n\n\ndef load_data(data_path):\n    with open(data_path, 'r') as file:\n        dataset = json.load(file)\n    return dataset\n\ndef save_res(data, file_path):\n    with open(file_path, 'w') as file:\n        json.dump(data, file, ensure_ascii=False, indent=4)\n\ndef build_data_path(file_name):\n    data_root = os.path.join(os.getcwd(), 'dataset')\n    if not os.path.exists(data_root):\n        os.makedirs(data_root)\n    save_path = os.path.join(data_root, file_name)\n    return save_path\n\ndef get_dataset(dataset_name):\n    train_path = build_data_path('train_set.json')\n    eval_path = build_data_path('eval_set.json')\n    ds = MsDataset.load(dataset_name, subset_name='main')\n    ds = ds.rename_column('question', 'instruction').rename_column('answer', 'output')\n    with open(train_path, 'w') as file:\n        json.dump(ds['train'].to_list(), file, ensure_ascii=False, indent=4)\n    with open(eval_path, 'w') as file:\n        json.dump(ds['test'].to_list(), file, ensure_ascii=False, indent=4)\n    return train_path, eval_path\n\ndef distill_dataset(data_path, model=None, demo=False):\n    inputs = load_data(data_path)[:1] if demo else load_data(data_path)\n    with warp(_concurrent=1) as wp:\n        wp.func = model\n    res_list = []\n    try_n = 0\n    while inputs:\n        print(\">>>\" * 12, f\"{try_n+1} times left: \", len(inputs))\n        querys = [item['instruction'] for item in inputs]\n        results = wp(querys)\n        valid_data, inputs = filter(inputs, results)\n        res_list.extend(valid_data)\n        try_n += 1\n        if try_n == 15:\n            break\n    res_list = res_list * 120 if demo else res_list\n    distilled_train_set_path = build_data_path('distilled_train_data.json')\n    save_res(res_list, distilled_train_set_path)\n    save_res(inputs, build_data_path('left_data.json'))\n    return distilled_train_set_path\n\ndef filter(inputs, results):\n    valid = []\n    retry = []\n    for i, item in enumerate(inputs):\n        true_v = item['output'].split('\\n#### ')[-1].strip()\n        if f'\\\\boxed{{{true_v}}}' in results[i] and '</think>' in results[i]:\n            valid.append({'instruction': item['instruction'], 'output': results[i], 'input': ''})\n        else:\n            retry.append(item)\n    return valid, retry\n\ndef extract_boxed_content(text):\n    pattern = r'boxed{((?:[^{}]*|{.*?})*)}'\n    contents = re.findall(pattern, text)\n    return contents\n\ndef caculate_score(eval_set, infer_set):\n    assert len(eval_set) == len(infer_set)\n    score = 0\n    for index, eval_item in enumerate(eval_set):\n        output = infer_set[index]\n        if 'boxed{' in output:\n            res = extract_boxed_content(output)\n            res = list(set(res))\n            res = res[0] if len(res) == 1 else res\n            if type(res) is list:\n                continue\n            true_v = eval_item['output'].split('\\n#### ')[-1].strip()\n            if true_v == res.strip():\n                score += 1\n    return f'{score}/{len(eval_set)}, {round(score/len(eval_set),4)*100}%'\n\ndef main(techer_name, student_name, dataset_name, demo=False, sft_data_path=None):\n    # Launcher Teacher\n    teacher_model = lazyllm.OnlineChatModule(techer_name)\n\n    # Load and Distill Dataset\n    train_set_path, eval_set_path = get_dataset(dataset_name)\n    eval_set = load_data(eval_set_path)\n    if not sft_data_path:\n        sft_data_path = distill_dataset(train_set_path, teacher_model, demo)\n\n    # Train and Infer\n    infer_data = [item['instruction'] for item in eval_set]\n    student_model = lazyllm.TrainableModule(student_name)\\\n        .mode('finetune')\\\n        .trainset(sft_data_path)\\\n        .finetune_method((finetune.llamafactory, {\n            'learning_rate': 1e-4,\n            'cutoff_len': 5120,\n            'max_samples': 20000,\n            'val_size': 0.01,\n            'per_device_train_batch_size': 2,\n            'num_train_epochs': 2.0,\n            'launcher': launchers.sco(nnode=1, nproc=8, ngpus=8)\n        }))\\\n        .prompt(dict(system='You are a helpful assistant.', drop_builtin_system=True))\\\n        .deploy_method(deploy.Vllm)\n    student_model._prompt._soa = '<|im_start|>assistant\\n\\n<think>'\n    student_model.evalset(infer_data)\n    student_model.update()\n\n    # Score\n    score = caculate_score(eval_set, student_model.eval_result)\n    print(\"All Done. Score is: \", score)\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description=\"Distill the model training script with given parameters.\")\n    parser.add_argument('--teacher_model_name', type=str, default='DeepSeek-R1', help='Name of the teacher model')\n    parser.add_argument('--student_model_name', type=str, default='internlm2-chat-7b', help='Name of the student model')\n    parser.add_argument('--dataset_name', type=str, default='modelscope/gsm8k', help='Name of the dataset')\n    parser.add_argument('--demo', type=bool, default=True, help='Demo mode flag')\n    parser.add_argument('--sft_data_path', type=str, default=None, help='Path to the SFT data')\n\n    args = parser.parse_args()\n\n    # Extracting arguments\n    teacher_model_name = args.teacher_model_name\n    student_model_name = args.student_model_name\n    dataset_name = args.dataset_name\n    demo = args.demo\n    sft_data_path = args.sft_data_path\n\n    # Calling the main function\n    main(teacher_model_name, student_model_name, dataset_name, demo, sft_data_path)\n"}
{"type": "source_file", "path": "docs/gen_mkdocs_yaml.py", "content": "import os\n\nlanguage = os.getenv('LAZYLLM_LANGUAGE', 'ENGLISH')\nassert language in ('ENGLISH', 'CHINESE')\n\nwith open(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'mkdocs.template.yml')) as f:\n    content = f.read()\n\ndoc_dir = 'en' if language == 'ENGLISH' else 'zh'\nen_default = 'true' if language == 'ENGLISH' else 'false'\nzh_default = 'true' if language == 'CHINESE' else 'false'\ncontent = content.format(doc_dir=doc_dir, en_default=en_default, zh_default=zh_default)\n\nwith open(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'mkdocs.yml'), 'w+') as f:\n    f.write(content)\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/parser/__init__.py", "content": "from lazynote.parser.base import BaseParser\n\n__all__ = [\n    'BaseParser',\n]\n"}
{"type": "source_file", "path": "examples/chatbot_online.py", "content": "import lazyllm\n\n# Before running, set the environment variable:\n#\n# 1. `export LAZYLLM_GLM_API_KEY=xxxx`: the API key of Zhipu AI, default model \"glm-4\", `source=\"glm\"`.\n#     You can apply for the API key at https://open.bigmodel.cn/\n#     Also supports other API keys:\n#       - LAZYLLM_OPENAI_API_KEY: the API key of OpenAI, default model \"gpt-3.5-turbo\", `source=\"openai\"`.\n#           You can apply for the API key at https://openai.com/index/openai-api/\n#       - LAZYLLM_KIMI_API_KEY: the API key of Moonshot AI, default model \"moonshot-v1-8k\", `source=\"kimi\"`.\n#           You can apply for the API key at https://platform.moonshot.cn/console\n#       - LAZYLLM_QWEN_API_KEY: the API key of Alibaba Cloud, default model \"qwen-plus\", `source=\"qwen\"`.\n#           You can apply for the API key at https://home.console.aliyun.com/\n#       - LAZYLLM_SENSENOVA_API_KEY: the API key of SenseTime, default model \"SenseChat-5\", `source=\"sensenova\"`.\n#                                  You also have to set LAZYLLM_SENSENOVA_SECRET_KEY` togather.\n#           You can apply for the API key at https://platform.sensenova.cn/home\n#     * `source` needs to be specified for multiple API keys, but it does not need to be set for a single API key.\n\nchat = lazyllm.OnlineChatModule()\n\nif __name__ == '__main__':\n    lazyllm.WebModule(chat, port=range(23466, 23470)).start().wait()\n"}
{"type": "source_file", "path": "lazyllm/client.py", "content": "import lazyllm\nfrom lazyllm.thirdparty import redis\n\nlazyllm.config.add(\"redis_url\", str, \"\", \"REDIS_URL\")\nlazyllm.config.add(\"redis_recheck_delay\", int, 5, \"REDIS_RECHECK_DELAY\")\n\nredis_url = lazyllm.config[\"redis_url\"]\n\nredis_client = None\n\nif redis_url:\n    redis_client = redis.Redis.from_url(redis_url)\n    assert (\n        redis_client.ping()\n    ), \"Found reids config but can not connect, please check your config `LAZYLLM_REDIS_URL`.\"\n\n\ndef get_redis(key):\n    url = redis_client.get(key)\n    return url.decode(\"utf-8\") if url else None\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/__init__.py", "content": ""}
{"type": "source_file", "path": "docs/scripts/lazynote/manager/base.py", "content": "import inspect\nimport textwrap\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, List\n\nimport libcst as cst\nfrom pydantic import BaseModel, Field\n\nfrom lazynote.parser import BaseParser\nfrom lazynote.schema import MemberType, get_member_type\nfrom lazynote.editor import BaseEditor\nfrom enum import Enum\nimport importlib\nimport pkgutil\nimport asyncio\nimport traceback\n\nclass DocstringMode(str, Enum):\n    \"\"\"Enumeration for different modes of handling docstrings.\"\"\"\n    TRANSLATE = \"translate\"\n    POLISH = \"polish\"\n    CLEAR = \"clear\"\n    FILL = \"fill\"\n\nclass BaseManager(BaseModel, ABC):\n    \"\"\"\n    Executor for modifying module docstrings. Currently supports module-level or file-level modifications.\n\n    Subclasses need to override the `gen_docstring` method to generate custom docstrings.\n\n    Attributes:\n        parser (Optional[BaseParser]): The parser used to parse the module. Defaults to an instance of BaseParser.\n        pattern (DocstringMode): The mode for handling docstrings.\n        skip_on_error (bool): Whether to skip errors or raise them. Defaults to False.\n    \"\"\"\n    parser: Optional[BaseParser] = Field(default_factory=BaseParser)\n    pattern: DocstringMode\n    skip_on_error: bool = False  # Add class attribute\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        if self.parser is None:\n            self.parser = BaseParser(skip_modules=kwargs.get('skip_modules', []))\n        self.skip_on_error = kwargs.get('skip_on_error', self.skip_on_error)\n\n    class Config:\n        arbitrary_types_allowed = True\n\n    @abstractmethod\n    def gen_docstring(self, old_docstring: Optional[str], node_code: str) -> str:\n        \"\"\"\n        Generate a new docstring. Subclasses must implement this method to provide custom logic.\n\n        Args:\n            old_docstring (Optional[str]): The old docstring.\n            node_code (str): The code of the node.\n\n        Returns:\n            str: The new docstring.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def is_defined_in_module(member: object, module: object) -> bool:\n        \"\"\"\n        Check if a member is defined in a given module.\n\n        Args:\n            member (object): The member to check.\n            module (object): The module to check against.\n\n        Returns:\n            bool: True if the member is defined in the module, False otherwise.\n        \"\"\"\n        if hasattr(member, '__module__'):\n            return member.__module__ == module.__name__\n        elif isinstance(member, property):\n            return member.fget.__module__ == module.__name__\n        elif isinstance(member, staticmethod):\n            return member.__func__.__module__ == module.__name__\n        elif isinstance(member, classmethod):\n            return member.__func__.__module__ == module.__name__\n        elif hasattr(member, '__wrapped__'):\n            return member.__wrapped__.__module__ == module.__name__\n        return False\n\n    def _handle_error(self, error_message: str, error: Exception) -> None:\n        \"\"\"\n        Handle errors according to the skip_on_error flag.\n\n        Args:\n            error_message (str): The error message to display.\n            error (Exception): The exception that was raised.\n        \"\"\"\n        if self.skip_on_error:\n            print(f\"{error_message}: {error}\")\n            traceback.print_exc()\n        else:\n            raise error\n\n    def _write_code_to_file(self, module: object, code: str) -> None:\n        \"\"\"\n        Write modified code back to the module file.\n\n        Args:\n            module (object): The module to write to.\n            code (str): The modified code.\n        \"\"\"\n        module_file_path = inspect.getfile(module)\n        with open(module_file_path, 'w', encoding='utf-8') as file:\n            file.write(code)\n\n    async def _sem_task(self, task, modname: str, semaphore: asyncio.Semaphore) -> None:\n        \"\"\"\n        Run a task with a semaphore to limit concurrency.\n\n        Args:\n            task: The task to run.\n            modname (str): The module name associated with the task.\n            semaphore (asyncio.Semaphore): The semaphore to limit concurrency.\n        \"\"\"\n        async with semaphore:\n            try:\n                await task\n            except Exception as e:\n                self._handle_error(f\"Skipping {modname} due to import error\", e)\n\n    def traverse(self, obj: object, skip_modules: Optional[List[str]] = None) -> None:\n        \"\"\"\n        Traverse through the package or module to process docstrings.\n\n        Args:\n            obj (object): The object to traverse.\n            skip_modules (Optional[List[str]]): List of modules to skip.\n        \"\"\"\n        if skip_modules is None:\n            skip_modules = []\n\n        if get_member_type(obj) == MemberType.PACKAGE:\n            for importer, modname, ispkg in pkgutil.walk_packages(obj.__path__, obj.__name__ + \".\"):\n                if any(modname.startswith(skip_mod) for skip_mod in skip_modules):\n                    continue\n                if ispkg:\n                    continue\n\n                try:\n                    submodule = importlib.import_module(modname)\n                    self.parser.parse(submodule, self)\n                except Exception as e:\n                    self._handle_error(f\"Skipping {modname} due to import error\", e)\n\n        elif get_member_type(obj) == MemberType.MODULE:\n            try:\n                self.parser.parse(obj, self)\n            except Exception as e:\n                self._handle_error(f\"Skipping {obj.__name__} due to import error\", e)\n\n    async def atraverse(self, obj: object, skip_modules: Optional[List[str]] = None, max_concurrency: int = 10) -> None:\n        \"\"\"\n        Asynchronously traverse through the package or module to process docstrings.\n\n        Args:\n            obj (object): The object to traverse.\n            skip_modules (Optional[List[str]]): List of modules to skip.\n            max_concurrency (int): Maximum number of concurrent tasks.\n        \"\"\"\n        if skip_modules is None:\n            skip_modules = []\n\n        semaphore = asyncio.Semaphore(max_concurrency)\n        loop = asyncio.get_event_loop()\n\n        if get_member_type(obj) == MemberType.PACKAGE:\n            tasks = []\n            for importer, modname, ispkg in pkgutil.walk_packages(obj.__path__, obj.__name__ + \".\"):\n                if any(modname.startswith(skip_mod) for skip_mod in skip_modules):\n                    continue\n                if ispkg:\n                    continue\n\n                try:\n                    submodule = importlib.import_module(modname)\n                    task = loop.run_in_executor(None, self.parser.parse, submodule, self)\n                    tasks.append(self._sem_task(task, modname, semaphore))\n                except Exception as e:\n                    self._handle_error(f\"Skipping {modname} due to import error\", e)\n            await asyncio.gather(*tasks)\n\n        elif get_member_type(obj) == MemberType.MODULE:\n            try:\n                task = loop.run_in_executor(None, self.parser.parse, obj, self)\n                await self._sem_task(task, obj.__name__, semaphore)\n            except Exception as e:\n                self._handle_error(f\"Skipping {obj.__name__} due to import error\", e)\n\n    def modify_docstring(self, module: object) -> Optional[str]:\n        \"\"\"\n        Modify the docstring of a given module.\n\n        Args:\n            module (object): The module to modify.\n\n        Returns:\n            Optional[str]: The modified code, or None if an error occurred.\n        \"\"\"\n        try:\n            source_code = inspect.getsource(module)\n            source_code = textwrap.dedent(source_code)\n            tree = cst.parse_module(source_code)\n            transformer = BaseEditor(\n                gen_docstring=self.gen_docstring, pattern=self.pattern, module=module)\n            modified_tree = tree.visit(transformer)\n            self._write_code_to_file(module, modified_tree.code)\n            return modified_tree.code\n        except Exception as e:\n            self._handle_error(f\"Skipping module {module.__name__} due to error\", e)\n            return None\n"}
{"type": "source_file", "path": "docs/scripts/lazynote/editor/__init__.py", "content": "from lazynote.editor.base import BaseEditor\n\n__all__ = [\n    'BaseEditor',\n]\n"}
{"type": "source_file", "path": "examples/rag_milvus_store.py", "content": "# -*- coding: utf-8 -*-\n\nimport os\nimport lazyllm\nfrom lazyllm import bind, config\nfrom lazyllm.tools.rag import DocField, DataType\nimport shutil\nimport traceback\n\ndef print_stack():\n    stack = traceback.format_stack()\n    for line in stack:\n        print(line.strip())\n\nclass TmpDir:\n    def __init__(self):\n        self.root_dir = os.path.expanduser(os.path.join(config['home'], 'rag_for_example_ut'))\n        self.rag_dir = os.path.join(self.root_dir, 'rag_master')\n        os.makedirs(self.rag_dir, exist_ok=True)\n        self.store_file = os.path.join(self.root_dir, \"milvus.db\")\n\ntmp_dir = TmpDir()\n\nmilvus_store_conf = {\n    'type': 'milvus',\n    'kwargs': {\n        'uri': tmp_dir.store_file,\n        'index_kwargs': {\n            'index_type': 'HNSW',\n            'metric_type': 'COSINE',\n        }\n    },\n}\n\ndoc_fields = {\n    'comment': DocField(data_type=DataType.VARCHAR, max_size=65535, default_value=' '),\n    'signature': DocField(data_type=DataType.VARCHAR, max_size=32, default_value=' '),\n}\n\nprompt = 'You will play the role of an AI Q&A assistant and complete a dialogue task.'\\\n    ' In this task, you need to provide your answer based on the given context and question.'\n\ndocuments = lazyllm.Document(dataset_path=tmp_dir.rag_dir,\n                             embed=lazyllm.TrainableModule(\"bge-large-zh-v1.5\"),\n                             manager=True,\n                             store_conf=milvus_store_conf,\n                             doc_fields=doc_fields)\n\ndocuments.create_node_group(name=\"block\", transform=lambda s: s.split(\"\\n\") if s else '')\n\nwith lazyllm.pipeline() as ppl:\n    ppl.retriever = lazyllm.Retriever(doc=documents, group_name=\"block\", topk=3)\n\n    ppl.reranker = lazyllm.Reranker(name='ModuleReranker',\n                                    model=\"bge-reranker-large\",\n                                    topk=1,\n                                    output_format='content',\n                                    join=True) | bind(query=ppl.input)\n\n    ppl.formatter = (\n        lambda nodes, query: dict(context_str=nodes, query=query)\n    ) | bind(query=ppl.input)\n\n    ppl.llm = lazyllm.TrainableModule('internlm2-chat-7b').prompt(\n        lazyllm.ChatPrompter(instruction=prompt, extra_keys=['context_str']))\n\nif __name__ == '__main__':\n    try:\n        rag = lazyllm.ActionModule(ppl)\n        rag.start()\n        res = rag('何为天道？')\n        print(f'answer: {res}')\n    finally:\n        shutil.rmtree(tmp_dir.root_dir)\n"}
{"type": "source_file", "path": "lazyllm/common/bind.py", "content": "import copy\nimport builtins\nimport itertools\nfrom typing import Callable, Any\nfrom .globals import globals\nfrom .common import package\n\n\nclass AttrTree(object):\n    def __init__(self, name=None, pres=[]):\n        self._path = copy.deepcopy(pres)\n        if name is not None:\n            self._path.append(name)\n\n    def __str__(self):\n        return '.'.join(self._path)\n\n    def __getattr__(self, name):\n        v = __class__(name, pres=self._path)\n        setattr(self, name, v)\n        return v\n\n    def get_from(self, obj):\n        v = obj\n        for name in self._path:\n            v = getattr(v, name)\n        return v\n\n    def __deepcopy__(self, memo):\n        return self\n\nroot = AttrTree()\n\n\nclass Placeholder(object):\n    _pool = dict()\n\n    def __new__(cls, idx):\n        if idx not in Placeholder._pool:\n            Placeholder._pool[idx] = super().__new__(cls)\n        return Placeholder._pool[idx]\n\n    def __init__(self, idx):\n        assert isinstance(idx, int)\n        self.idx = idx\n\n    def __deepcopy__(self, memo=None):\n        return self\n\n    def __repr__(self):\n        return f'placeholder._{self.idx}'\n\nfor i in range(10):\n    vars()[f'_{i}'] = Placeholder(i)\n\ndef _setattr(self, key, v):\n    raise RuntimeError('Cannot set attr for Placeholder')\nsetattr(Placeholder, '__setattr__', _setattr)\n\n\nclass _MetaBind(type):\n    def __instancecheck__(self, __instance):\n        if isinstance(__instance, Bind) and isinstance(__instance._f, self):\n            return True\n        return super(__class__, self).__instancecheck__(__instance)\n\n\nclass Bind(object):\n    class _None: pass\n\n    class Args(object):\n        class _None: pass\n        class Unpack(package): pass\n\n        def __init__(self, source_id: str, target_id: str = 'input', *, unpack: bool = False):\n            self._item_key, self._attr_key = Bind.Args._None, Bind.Args._None\n            self._source_id, self._target_id = source_id, target_id\n            self._unpack = unpack\n\n        def __getitem__(self, key: str):\n            self._item_key = key\n            return self\n\n        def __getattr__(self, key: str):\n            if key.startswith('__') and key.endswith('__'):\n                raise AttributeError(f'Args has no attribute {key}')\n            self._attr_key = key\n            return self\n\n        def __getstate__(self):\n            return self._item_key, self._attr_key, self._source_id, self._target_id\n\n        def __setstate__(self, state):\n            self._item_key, self._attr_key, self._source_id, self._target_id = state\n\n        def get_arg(self, source):\n            if (not source or self._source_id != source['source']) and self._source_id in globals['bind_args']:\n                source = globals['bind_args'][self._source_id]\n            if not source or source['source'] != self._source_id:\n                raise RuntimeError('Unable to find the bound parameter, possibly due to pipeline.input/output can only '\n                                   'be bind in direct member of pipeline! You may solve this by defining the pipeline '\n                                   'in a `with lazyllm.save_pipeline_result():` block.')\n            input = result = source[self._target_id]\n            source = source['source']\n            if self._item_key is not Bind.Args._None: result = input[self._item_key]\n            elif self._attr_key is not Bind.Args._None: result = getattr(input, self._attr_key)\n            if self._unpack and isinstance(result, package): result = Bind.Args.Unpack(result)\n            return result\n\n    def __init__(self, __bind_func=_None, *args, **kw):\n        self._f = __bind_func() if isinstance(__bind_func, type) and __bind_func is not Bind._None else __bind_func\n        self._args = args\n        self._kw = kw\n        self._has_root = (any([isinstance(a, AttrTree) for a in args])\n                          or any([isinstance(v, AttrTree) for v in kw.values()]))\n\n    def __ror__(self, __value: Callable):\n        if self._f is not Bind._None: self._args = (self._f,) + self._args\n        self._f = __value\n        return self\n\n    # _bind_args_source: dict(input=input, args=dict(key=value))\n    def __call__(self, *args, _bind_args_source=None, **kw):\n        if self._f is None: return None\n        keys = set(kw.keys()).intersection(set(self._kw.keys()))\n        assert len(keys) == 0, f'Keys `{keys}` are already bind!'\n        bind_args = args if len(self._args) == 0 else (\n            [args[a.idx] if isinstance(a, Placeholder) else a for a in self._args])\n        kwargs = {k: args[v.idx] if isinstance(v, Placeholder) else v for k, v in self._kw.items()}\n        bind_args = [a.get_arg(_bind_args_source) if isinstance(a, Bind.Args) else a for a in bind_args]\n        bind_args = list(itertools.chain.from_iterable(x if isinstance(x, Bind.Args.Unpack) else [x] for x in bind_args))\n        kwargs = {k: v.get_arg(_bind_args_source) if isinstance(v, Bind.Args) else v for k, v in kwargs.items()}\n        return self._f(*bind_args, **kwargs, **kw)\n\n    # TODO: modify it\n    def __repr__(self) -> str:\n        return self._f.__repr__() + '(bind args:{})'.format(\n            ', '.join([repr(a) if a is not self else 'self' for a in self._args]))\n\n    def __getattr__(self, name):\n        # name will be '_f' in copy.deepcopy\n        if name != '_f':\n            return getattr(self._f, name)\n        return super(__class__, self).__getattr__(name)\n\n    def __setattr__(self, __name: str, __value: Any) -> None:\n        if __name not in ('_f', '_args', '_kw', '_has_root'):\n            return setattr(self._f, __name, __value)\n        return super(__class__, self).__setattr__(__name, __value)\n\n\nsetattr(builtins, 'bind', Bind)\n"}
{"type": "source_file", "path": "lazyllm/common/option.py", "content": "from typing import Any\nimport copy\nimport multiprocessing\nfrom .logger import LOG\n\n\nclass _OptionIterator(object):\n    def __init__(self, m):\n        self.m = m\n        self.reset()\n\n    def reset(self): self.m._idx = -1\n    def __len__(self): return len(self.m._objs)\n    def __deepcopy__(self, *args, **kw): return self\n\n    def __iter__(self):\n        self.reset()\n        return self\n\n    def __next__(self):\n        self.m._next()\n        return self.m._obj\n\n\nclass Option(object):\n    def __init__(self, *obj):\n        if len(obj) == 1 and isinstance(obj[0], (tuple, list)): obj = obj[0]\n        assert isinstance(obj, (tuple, list)) and len(obj) > 1, 'More than one option shoule be given'\n        self._objs = obj\n        self._idx = 0\n        self._obj = self._objs[self._idx]\n\n    def _next(self):\n        self._idx += 1\n        if self._idx == len(self._objs):\n            self._idx = 0\n            raise StopIteration\n\n    def __setattr__(self, __name: str, __value: Any) -> None:\n        object.__setattr__(self, __name, __value)\n        if __name == '_idx' and 0 <= self._idx < len(self._objs):\n            self._obj = self._objs[self._idx]\n\n    def __deepcopy__(self, *args, **kw):\n        return copy.deepcopy(self._obj)\n\n    def __iter__(self):\n        return _OptionIterator(self)\n\n    def __repr__(self):\n        return f'<Option options=\"{self._objs}\" curr=\"{self._obj}\">'\n\n\ndef rebuild(x): return x\ndef reduce(x): return rebuild, (x._obj,)\nmultiprocessing.reducer.ForkingPickler.register(Option, reduce)\n\n\ndef OptionIter(list_of_options, suboption_func=lambda x: []):\n    LOG.info('Options:', list_of_options)\n\n    def impl(cur, remain):\n        for r in cur:\n            new_remain = remain + suboption_func(r)\n            if len(new_remain) == 0:\n                yield [r]\n            else:\n                for r2 in impl(new_remain[0], new_remain[1:]):\n                    yield [r] + r2\n    return impl(list_of_options[0], list_of_options[1:])\n"}
{"type": "source_file", "path": "lazyllm/common/logger.py", "content": "import inspect\nimport logging\nfrom json import JSONDecodeError, loads\nfrom os import getenv, getpid, listdir\nimport os\nfrom os.path import join\nfrom sys import stderr\nfrom typing import Dict\nfrom zipfile import ZipFile\nimport lazyllm\nimport platform\nfrom .utils import check_path\nfrom .common import call_once, once_flag\n\nfrom loguru import logger\n\nlazyllm.config.add(\"debug\", bool, False, \"DEBUG\")\nlazyllm.config.add(\"log_name\", str, \"lazyllm\", \"LOG_NAME\")\nlazyllm.config.add(\"log_level\", str, \"INFO\", \"LOG_LEVEL\")\nlazyllm.config.add(\n    \"log_format\",\n    str,\n    \"{process}: <green>{time:YYYY-MM-DD HH:mm:ss}</green> {extra[name]} \"\n    \"<level>{level}</level>: ({name}:{line}) <cyan>{message}</cyan>\",\n    \"LOG_FORMAT\",\n)\nlazyllm.config.add(\"log_dir\", str, os.path.join(os.path.expanduser('~'), '.lazyllm'), \"LOG_DIR\")\nlazyllm.config.add(\"log_file_level\", str, \"ERROR\", \"LOG_FILE_LEVEL\")\nlazyllm.config.add(\"log_file_size\", str, \"4 MB\", \"LOG_FILE_SIZE\")\nlazyllm.config.add(\"log_file_retention\", str, \"7 days\", \"LOG_FILE_RETENTION\")\nlazyllm.config.add(\"log_file_mode\", str, \"merge\", \"LOG_FILE_MODE\")\n\n\nclass _Log:\n    _stderr_initialized = False\n    _once_flags: Dict = {}\n\n    def __init__(self):\n        self._name = lazyllm.config[\"log_name\"]\n        self._pid = getpid()\n        self._log_dir_path = check_path(\n            lazyllm.config[\"log_dir\"], exist=False, file=False\n        )\n\n        if getenv(\"LOGURU_AUTOINIT\", \"true\").lower() in (\"1\", \"true\") and stderr:\n            try:\n                logger.remove(0)\n            except ValueError:\n                pass\n\n        if not _Log._stderr_initialized:\n            # A sink that will accumulate the log and output to stderr.\n            self.stderr: bool = bool(stderr)\n            self._stderr_i = logger.add(\n                stderr,\n                level=(\n                    lazyllm.config[\"log_level\"]\n                    if not lazyllm.config[\"debug\"]\n                    else \"DEBUG\"\n                ),\n                format=lazyllm.config[\"log_format\"],\n                filter=lambda record: (\n                    record[\"extra\"].get(\"name\") == self._name and self.stderr\n                ),\n                colorize=True,\n            )\n            _Log._stderr_initialized = True\n\n        self._logger = logger.bind(name=self._name, process=self._pid)\n\n    def log_once(self, message: str, level: str = \"warning\") -> None:\n        frame = inspect.currentframe().f_back\n        context = (frame.f_code.co_filename, frame.f_code.co_name, frame.f_lineno)\n        if context not in self._once_flags:\n            self._once_flags[context] = once_flag()\n        # opt depth for printing correct stack depth information\n        call_once(\n            self._once_flags[context],\n            getattr(self.opt(depth=2, record=True).bind(name=self._name), level),\n            message,\n        )\n\n    def read(self, limit: int = 10, level: str = \"error\"):\n        names = listdir(self._log_dir_path)\n        lines = []\n        for name in names:\n            if name.endswith(\".json.log\"):\n                with open(join(self._log_dir_path, name)) as file:\n                    lines = file.readlines()\n            elif name.endswith(\".json.log.zip\"):\n                with ZipFile(name) as zip_file:\n                    for n in zip_file.namelist():\n                        with zip_file.open(n, \"r\") as file:\n                            lines = file.readlines()\n        records = []\n        if isinstance(level, str):\n            level = getattr(logging, level.upper())\n        for line in lines:\n            try:\n                record = loads(line)\n                if record:\n                    record = record[\"record\"]\n                    no = record[\"level\"][\"no\"]\n                    if no >= level:\n                        records.append(record)\n            except JSONDecodeError:\n                pass\n        records = sorted(records, key=lambda r: r[\"time\"][\"timestamp\"])\n        if limit > 0:\n            records = records[-limit:]\n        return records\n\n    def __getattr__(self, attr):\n        if attr not in self.__dict__:\n            return getattr(self._logger, attr)\n        return getattr(self, attr)\n\n    def close(self):\n        logger.remove()\n\n    def __reduce__(self):\n        return (self.__class__, ())\n\n\nLOG = _Log()\n\n\ndef add_file_sink():\n    name = lazyllm.config[\"log_name\"]\n    pid = getpid()\n    log_dir_path = LOG._log_dir_path\n    if log_dir_path:\n        log_file_mode = lazyllm.config[\"log_file_mode\"]\n        if log_file_mode == \"merge\":\n            log_file_name = f\"{name}.json.log\"\n            enqueue = True\n        elif log_file_mode == \"split\":\n            log_file_name = f\"{name}.{pid}.json.log\"\n            enqueue = False\n        else:\n            raise ValueError(f\"Unexpected log_file_mode: {log_file_mode}\")\n\n        log_file_path = join(log_dir_path, log_file_name)\n        LOG.add(\n            log_file_path,\n            level=lazyllm.config[\"log_file_level\"],\n            format=\"{message}\",\n            encoding=\"utf-8\",\n            rotation=lazyllm.config[\"log_file_size\"],\n            retention=lazyllm.config[\"log_file_retention\"],\n            compression=\"zip\",\n            delay=True,\n            enqueue=enqueue,  # multiprocessing-safe\n            colorize=True,\n            serialize=True,\n            filter=lambda record: (record[\"extra\"].get(\"name\") == name),\n        )\n\n\nadd_file_sink()\n\nif platform.system() != \"Windows\":\n    os.register_at_fork(\n        after_in_child=add_file_sink,\n    )\n"}
{"type": "source_file", "path": "lazyllm/common/multiprocessing.py", "content": "import multiprocessing\nfrom contextlib import contextmanager\nimport time\nimport atexit\n\n@contextmanager\ndef _ctx(method='spawn'):\n    m = multiprocessing.get_start_method()\n    if m != method:\n        multiprocessing.set_start_method(method, force=True)\n    yield\n    if m != method:\n        multiprocessing.set_start_method(m, force=True)\n\n\nclass SpawnProcess(multiprocessing.Process):\n    def start(self):\n        with _ctx('spawn'):\n            return super().start()\n\n\nclass ForkProcess(multiprocessing.Process):\n    def __init__(self, group=None, target=None, name=None, args=(),\n                 kwargs={}, *, daemon=None, sync=True):\n        super().__init__(group, ForkProcess.work(target, sync), name, args, kwargs, daemon=daemon)\n\n    @staticmethod\n    def work(f, sync):\n        def impl(*args, **kw):\n            try:\n                f(*args, **kw)\n                if not sync:\n                    while True: time.sleep(1)\n            finally:\n                atexit._run_exitfuncs()\n        return impl\n\n    def start(self):\n        with _ctx('fork'):\n            return super().start()\n"}
{"type": "source_file", "path": "lazyllm/common/common.py", "content": "import re\nimport os\nimport builtins\nimport typing\nfrom typing import Any, Callable\nfrom contextlib import contextmanager\nimport copy\nimport threading\nimport types\nfrom ..configs import config\n\ntry:\n    from typing import final\nexcept ImportError:\n    _F = typing.TypeVar(\"_F\", bound=Callable[..., Any])\n    def final(f: _F) -> _F: return f\n\ntry:\n    from typing import override\nexcept ImportError:\n    def override(func: Callable):\n        return func\n\n\nclass FlatList(list):\n    def absorb(self, item):\n        if isinstance(item, list):\n            self.extend(item)\n        elif item is not None:\n            self.append(item)\n\n\nclass ArgsDict(dict):\n    def __init__(self, *args, **kwargs):\n        super(ArgsDict, self).__init__(*args, **kwargs)\n\n    def check_and_update(self, kw):\n        assert set(kw.keys()).issubset(set(self)), f'unexpected keys: {set(kw.keys()) - set(self)}'\n        self.update(kw)\n\n    def parse_kwargs(self):\n        string = ' '.join(f'--{k}={v}' if type(v) is not str else f'--{k}=\\\"{v}\\\"' for k, v in self.items())\n        return string\n\nclass CaseInsensitiveDict(dict):\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n        for key, value in dict(*args, **kwargs).items():\n            assert isinstance(key, str)\n            self[key] = value\n\n    def __getitem__(self, key):\n        assert isinstance(key, str)\n        return super().__getitem__(key.lower())\n\n    def __setitem__(self, key, value):\n        assert isinstance(key, str)\n        super().__setitem__(key.lower(), value)\n\n    def __contains__(self, key):\n        assert isinstance(key, str)\n        return super().__contains__(key.lower())\n\n# pack return value of modules used in pipeline / parallel.\n# will unpack when passing it to the next item.\nclass package(tuple):\n    def __new__(cls, *args):\n        if len(args) == 1 and isinstance(args[0], (tuple, list, types.GeneratorType)):\n            return super(__class__, cls).__new__(cls, args[0])\n        else:\n            return super(__class__, cls).__new__(cls, args)\n\n    def __getitem__(self, key):\n        if isinstance(key, slice):\n            return package(super(__class__, self).__getitem__(key))\n        return super(__class__, self).__getitem__(key)\n\n    def __add__(self, __other):\n        return package(super().__add__(__other))\n\n\nclass kwargs(dict):\n    pass\n\n\nclass arguments(object):\n    class _None: pass\n\n    def __init__(self, args=_None, kw=_None) -> None:\n        self.args = package() if args is arguments._None else args\n        if not isinstance(self.args, package): self.args = package((self.args,))\n        self.kw = kwargs() if kw is arguments._None else copy.copy(kw)\n\n    def append(self, x):\n        args, kw = package(), kwargs()\n        if isinstance(x, package):\n            args = x\n        elif isinstance(x, kwargs):\n            kw = x\n        elif isinstance(x, arguments):\n            args, kw = x.args, x.kw\n        else:\n            args = package((x,))\n        if args: self.args += args\n        if kw:\n            dup_keys = set(self.kw.keys()).intersection(set(kw.keys()))\n            assert len(dup_keys) == 0, f'Duplicated keys: {dup_keys}'\n            self.kw.update(kw)\n        return self\n\n\nsetattr(builtins, 'package', package)\n\n\nclass LazyLLMCMD(object):\n    def __init__(self, cmd, *, return_value=None, checkf=(lambda *a: True), no_displays=None):\n        if isinstance(cmd, (tuple, list)):\n            cmd = ' && '.join(cmd)\n        assert isinstance(cmd, str) or callable(cmd), 'cmd must be func or (list of) bash command str.'\n        self.cmd = cmd\n        self.return_value = return_value\n        self.checkf = checkf\n        self.no_displays = no_displays\n\n    def __hash__(self):\n        return hash(self.cmd)\n\n    def __str__(self):\n        assert not callable(self.cmd), f'Cannot convert cmd function {self.cmd} to str'\n        if self.no_displays:\n            cmd = self.cmd\n            for item in self.no_displays:\n                pattern = r'(-{1,2}' + re.escape(item) + r')(\\s|=|)(\\S+|)'\n                cmd = re.sub(pattern, \"\", cmd)\n            return cmd\n        else:\n            return self.cmd\n\n    def with_cmd(self, cmd):\n        # Attention: Cannot use copy.deepcopy because of class method.\n        new_instance = LazyLLMCMD(cmd, return_value=self.return_value,\n                                  checkf=self.checkf, no_displays=self.no_displays)\n        return new_instance\n\n    def get_args(self, key):\n        assert not callable(self.cmd), f'Cannot get args from function {self.cmd}'\n        pattern = r'*(-{1,2}' + re.escape(key) + r')(\\s|=|)(\\S+|)*'\n        return re.match(pattern, self.cmd)[3]\n\nclass TimeoutException(Exception):\n    pass\n\n@contextmanager\ndef timeout(duration, *, msg=''):\n    def raise_timeout_exception():\n        event.set()\n\n    event = threading.Event()\n    timer = threading.Timer(duration, raise_timeout_exception)\n    timer.start()\n\n    try:\n        yield\n    finally:\n        if not event.is_set():\n            timer.cancel()\n        else:\n            raise TimeoutException(f'{msg}, block timed out after {duration} s')\n\n\nclass ReadOnlyWrapper(object):\n    def __init__(self, obj=None):\n        self.obj = obj\n\n    def set(self, obj):\n        self.obj = obj\n\n    def __getattr__(self, key):\n        # key will be 'obj' in copy.deepcopy\n        if key != 'obj' and self.obj is not None:\n            return getattr(self.obj, key)\n        return super(__class__, self).__getattr__(key)\n\n    # TODO: modify it\n    def __repr__(self):\n        r = self.obj.__repr__()\n        return (f'{r[:-1]}' if r.endswith('>') else f'<{r}') + '(Readonly)>'\n\n    def __deepcopy__(self, memo):\n        # drop obj\n        return ReadOnlyWrapper()\n\n    def isNone(self):\n        return self.obj is None\n\n\nclass Identity():\n    def __init__(self, *args, **kw):\n        pass\n\n    def __call__(self, *inputs):\n        if len(inputs) == 1:\n            return inputs[0]\n        return package(*inputs)\n\n    def __repr__(self):\n        return make_repr('Module', 'Identity')\n\n\nclass ResultCollector(object):\n    class Impl(object):\n        def __init__(self, name, value): self._name, self._value = name, value\n\n        def __call__(self, *args, **kw):\n            assert (len(args) == 0) ^ (len(kw) == 0), f'args({len(args)}), kwargs({len(kw)})'\n            assert self._name is not None\n            if len(args) > 0:\n                self._value[self._name] = args[0] if len(args) == 1 else package(*args)\n                return self._value[self._name]\n            else:\n                self._value[self._name] = kw\n                return kwargs(kw)\n\n    def __init__(self): self._value = dict()\n    def __call__(self, name): return ResultCollector.Impl(name, self._value)\n    def __getitem__(self, name): return self._value[name]\n    def __repr__(self): return repr(self._value)\n    def keys(self): return self._value.keys()\n    def items(self): return self._value.items()\n\n\nclass ReprRule(object):\n    rules = {}\n\n    @classmethod\n    def add_rule(cls, cate, type, subcate, subtype=None):\n        if subtype:\n            cls.rules[f'{cate}:{type}'] = f'<{subcate} type={subtype}'\n        else:\n            cls.rules[f'{cate}:{type}'] = f'<{subcate}'\n\n    @classmethod\n    def check_combine(cls, cate, type, subs):\n        return f'{cate}:{type}' in cls.rules and subs.startswith(cls.rules[f'{cate}:{type}'])\n\n\ndef rreplace(s, old, new, count):\n    return (s[::-1].replace(old[::-1], new[::-1], count))[::-1]\n\ndef make_repr(category, type, *, name=None, subs=[], attrs=dict(), **kw):\n    if len(kw) > 0:\n        assert len(attrs) == 0, 'Cannot provide attrs and kwargs at the same time'\n        attrs = kw\n\n    if not config['repr_show_child']: subs = []\n\n    if isinstance(type, builtins.type): type = type.__name__\n    name = f' name={name}' if name else ''\n    attrs = ' ' + ' '.join([f'{k}={v}' for k, v in attrs.items()]) if attrs else ''\n    repr = f'<{category} type={type}{name}{attrs}>'\n\n    if len(subs) == 1 and ReprRule.check_combine(category, type, subs[0]):\n        if config['repr_ml']:\n            sub_cate = re.split('>| ', subs[0][1:])[0]\n            subs = rreplace(subs[0], f'</{sub_cate}>', f'</{category}>', 1)\n        else:\n            subs = subs[0]\n        return repr[:-1] + f' sub-category={subs[1:]}'\n\n    # ident\n    sub_repr = []\n    for idx, value in enumerate(subs):\n        for i, v in enumerate(value.strip().split('\\n')):\n            if not config['repr_ml']:\n                if idx != len(subs) - 1:\n                    sub_repr.append(f' |- {v}' if i == 0 else f' |  {v}')\n                else:\n                    sub_repr.append(f' └- {v}' if i == 0 else f'    {v}')\n            else:\n                sub_repr.append(f'    {v}')\n    if len(sub_repr) > 0: repr += ('\\n' + '\\n'.join(sub_repr) + '\\n')\n    if config['repr_ml']: repr += f'</{category}>'\n    return repr\n\n\n# if key is already in repr, then modify its value.\n# if ket is not in repr, add key to repr with value.\n# if value is None, remove key from repr.\ndef modify_repr(repr, key, value):\n    # TODO: impl this function\n    return repr\n\n\nclass once_flag(object):\n    def __init__(self, reset_on_pickle=False):\n        self._flag = False\n        self._exc = None\n        self._reset_on_pickle = reset_on_pickle\n        self._lock = threading.RLock()\n\n    def set(self, flag=True):\n        with self._lock:\n            self._flag = flag\n\n    def set_exception(self, exc):\n        self._exc = exc\n\n    def reset(self):\n        self.set(False)\n\n    def __bool__(self):\n        return self._flag\n\n    @classmethod\n    def rebuild(cls, flag, reset_on_pickle):\n        r = cls(reset_on_pickle)\n        if not reset_on_pickle: r._flag = flag\n        return r\n\n    def __reduce__(self):\n        return once_flag.rebuild, (self._flag, self._reset_on_pickle)\n\ndef call_once(flag: once_flag, func: Callable, *args, **kw):\n    with flag._lock:\n        if not flag:\n            try:\n                return func(*args, **kw)\n            except Exception as e:\n                flag.set_exception(e)\n            finally:\n                flag.set()\n        if flag._exc:\n            raise flag._exc\n    return None\n\ndef once_wrapper(reset_on_pickle):\n    flag = reset_on_pickle if isinstance(reset_on_pickle, bool) else False\n\n    class Wrapper:\n        class Impl:\n            def __init__(self, func, instance):\n                self._func, self._instance = func, instance\n                flag_name = f'_lazyllm_{func.__name__}_once_flag'\n                if instance and not hasattr(instance, flag_name): setattr(instance, flag_name, once_flag(flag))\n\n            def __call__(self, *args, **kw):\n                assert self._instance is not None, f'{self._func} can only be used as instance method'\n                return call_once(self.flag, self._func, self._instance, *args, **kw)\n\n            __doc__ = property(lambda self: self._func.__doc__)\n            def __repr__(self): return repr(self._func)\n\n            @__doc__.setter\n            def __doc__(self, value): self._func.__doc__ = value\n\n            @property\n            def flag(self) -> once_flag:\n                return getattr(self._instance, f'_lazyllm_{self._func.__name__}_once_flag')\n\n        def __init__(self, func):\n            self.__func__ = func\n\n        def __get__(self, instance, _):\n            return Wrapper.Impl(self.__func__, instance)\n\n    return Wrapper if isinstance(reset_on_pickle, bool) else Wrapper(reset_on_pickle)\n\n\nclass DynamicDescriptor:\n    class Impl:\n        def __init__(self, func, instance, owner):\n            self._func, self._instance, self._owner = func, instance, owner\n\n        def __call__(self, *args, **kw):\n            return self._func(self._instance, *args, **kw) if self._instance else self._func(self._owner, *args, **kw)\n\n        def __repr__(self): return repr(self._func)\n        __doc__ = property(lambda self: self._func.__doc__)\n\n        @__doc__.setter\n        def __doc__(self, value): self._func.__doc__ = value\n\n    def __init__(self, func):\n        self.__func__ = func\n\n    def __get__(self, instance, owner):\n        return DynamicDescriptor.Impl(self.__func__, instance, owner)\n\n\ndef singleton(cls):\n    instances = {}\n\n    def get_instance(*args, **kwargs):\n        if cls not in instances: instances[cls] = cls(*args, **kwargs)\n        return instances[cls]\n    return get_instance\n\ndef reset_on_pickle(*fields):\n    def decorator(cls):\n        original_getstate = cls.__getstate__ if hasattr(cls, '__getstate__') else lambda self: self.__dict__\n        original_setstate = (cls.__setstate__ if hasattr(cls, '__setstate__') else\n                             lambda self, state: self.__dict__.update(state))\n\n        def __getstate__(self):\n            state = original_getstate(self).copy()\n            for field, *_ in fields:\n                state[field] = None\n            return state\n\n        def __setstate__(self, state):\n            original_setstate(self, state)\n            for field in fields:\n                field, field_type = field if isinstance(field, (tuple, list)) else (field, None)\n                if field in state and state[field] is None and field_type is not None:\n                    setattr(self, field, field_type() if field_type else None)\n\n        cls.__getstate__ = __getstate__\n        cls.__setstate__ = __setstate__\n        return cls\n    return decorator\n\nclass EnvVarContextManager:\n    def __init__(self, env_vars_dict):\n        self.env_vars_dict = {var: value for var, value in env_vars_dict.items() if value is not None}\n        self.original_values = {}\n\n    def __enter__(self):\n        for var, value in self.env_vars_dict.items():\n            if var in os.environ:\n                self.original_values[var] = os.environ[var]\n            os.environ[var] = value\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        for var in self.env_vars_dict:\n            if var in self.original_values:\n                os.environ[var] = self.original_values[var]\n            else:\n                del os.environ[var]\n"}
{"type": "source_file", "path": "lazyllm/common/registry.py", "content": "import builtins\nimport functools\nimport lazyllm\nimport re\nfrom .bind import _MetaBind\nfrom ..configs import config\n\n# Special Dict for lazy programmer. Suppose we have a LazyDict as follows：\n#    >>> ld = LazyDict(name='ld', ALd=int)\n# 1. Use dot instead of ['str']\n#    >>> ld.ALd\n# 2. Support lowercase first character to make the sentence more like a function\n#    >>> ld.aLd\n# 3. Supports direct calls to dict when there is only one element\n#    >>> ld()\n# 4. Support dynamic default key\n#    >>> ld.set_default('ALd')\n#    >>> ld.default\n# 5. allowed to omit the group name if the group name appears in the name\n#    >>> ld.a\nclass LazyDict(dict):\n    def __init__(self, name='', base=None, *args, **kw):\n        super(__class__, self).__init__(*args, **kw)\n        self._default = None\n        self.name = name.capitalize()\n        self.base = base\n\n    def __setitem__(self, key, value):\n        assert key != 'default', 'LazyDict do not support key: default'\n        if '.' in key:\n            grp, key = key.rsplit('.', 1)\n            return self[grp].__setitem__(key, value)\n        return super().__setitem__(key, value)\n\n    def __getitem__(self, key):\n        if '.' in key:\n            grp, key = key.split('.', 1)\n            return self[grp][key]\n        return super().__getitem__(key)\n\n    # default -> self.default\n    # key -> Key, keyName, KeyName\n    # if self.name ends with 's' or 'es', ignor it\n    def _match(self, key):\n        key = self._default if key == 'default' else key\n        keys = [key, f'{key[0].upper()}{key[1:]}', f'{key}{self.name}', f'{key[0].upper()}{key[1:]}{self.name}',\n                f'{key}{self.name.lower()}', f'{key[0].upper()}{key[1:]}{self.name.lower()}']\n        if self.name.endswith('s'):\n            n = 2 if self.name.endswith('es') else 1\n            keys.extend([f'{key}{self.name[:-n]}', f'{key[0].upper()}{key[1:]}{self.name[:-n]}'])\n\n        for k in set(keys):\n            if k in self.keys():\n                return k\n        raise AttributeError(f'Attr {key} not found in {self}')\n\n    def __getattr__(self, key):\n        return self[self._match(key)]\n\n    def remove(self, key):\n        super(__class__, self).pop(self._match(key))\n\n    def __call__(self, *args, **kwargs):\n        assert self._default is not None or len(self.keys()) == 1\n        return self.default if self._default else self[list(self.keys())[0]](*args, **kwargs)\n\n    def set_default(self, key):\n        assert isinstance(key, str), 'default key must be str'\n        self._default = key\n\n\ngroup_template = '''\\\nclass LazyLLM{name}Base(LazyLLMRegisterMetaClass.all_clses[\\'{base}\\'.lower()].base):\n    pass\n'''\n\nconfig.add('use_builtin', bool, False, 'USE_BUILTIN')\n\nclass LazyLLMRegisterMetaClass(_MetaBind):\n    all_clses = LazyDict()\n\n    def __new__(metas, name, bases, attrs):\n        new_cls = type.__new__(metas, name, bases, attrs)\n        if name.startswith('LazyLLM') and name.endswith('Base'):\n            ori = re.match('(LazyLLM)(.*)(Base)', name.split('.')[-1])[2]\n            group = ori.lower()\n            new_cls._lazy_llm_group = f'{getattr(new_cls, \"_lazy_llm_group\", \"\")}.{group}'.strip('.')\n            ld = LazyDict(group, new_cls)\n            if new_cls._lazy_llm_group == group:\n                for m in (builtins, lazyllm) if config['use_builtin'] else (lazyllm,):\n                    assert not (hasattr(m, group) and hasattr(m, ori)), f'group name \\'{ori}\\' cannot be used'\n                for m in (builtins, lazyllm) if config['use_builtin'] else (lazyllm,):\n                    setattr(m, group, ld)\n                    setattr(m, ori, ld)\n            LazyLLMRegisterMetaClass.all_clses[new_cls._lazy_llm_group] = ld\n        elif hasattr(new_cls, '_lazy_llm_group'):\n            group = LazyLLMRegisterMetaClass.all_clses[new_cls._lazy_llm_group]\n            assert new_cls.__name__ not in group, (\n                f'duplicate class \\'{name}\\' in group {new_cls._lazy_llm_group}')\n            group[new_cls.__name__] = new_cls\n        return new_cls\n\n\ndef _get_base_cls_from_registry(cls_str, *, registry=LazyLLMRegisterMetaClass.all_clses):\n    if cls_str == '':\n        return registry.base\n    group, cls_str = cls_str.split('.', 1) if '.' in cls_str else (cls_str, '')\n    if not (registry is LazyLLMRegisterMetaClass.all_clses or group in registry):\n        exec(group_template.format(name=group.capitalize(), base=registry.base._lazy_llm_group))\n    return _get_base_cls_from_registry(cls_str, registry=registry[group])\n\n\nreg_template = '''\\\nclass {name}(LazyLLMRegisterMetaClass.all_clses[\\'{base}\\'.lower()].base):\n    pass\n'''\n\ndef bind_to_instance(func):\n    @functools.wraps(func)\n    def wrapper(instance, *args, **kwargs):\n        return func(*args, **kwargs)\n    return wrapper\n\nclass Register(object):\n    def __init__(self, base, fnames, template=reg_template):\n        self.basecls = base\n        self.fnames = [fnames] if isinstance(fnames, str) else fnames\n        self.template = template\n        assert len(self.fnames) > 0, 'At least one function should be given for overwrite.'\n\n    def __call__(self, cls, *, rewrite_func=None):\n        cls = cls.__name__ if isinstance(cls, type) else cls\n        cls = re.match('(LazyLLM)(.*)(Base)', cls.split('.')[-1])[2] \\\n            if (cls.startswith('LazyLLM') and cls.endswith('Base')) else cls\n        base = _get_base_cls_from_registry(cls.lower())\n        assert issubclass(base, self.basecls)\n        if rewrite_func is None:\n            rewrite_func = base.__reg_overwrite__ if getattr(base, '__reg_overwrite__', None) else self.fnames[0]\n        assert rewrite_func in self.fnames, f'Invalid function \"{rewrite_func}\" provived for rewrite.'\n\n        def impl(func, func_name=None):\n            if func_name:\n                func_for_wrapper = func  # avoid calling recursively\n\n                @functools.wraps(func)\n                def wrapper_func(*args, **kwargs):\n                    return func_for_wrapper(*args, **kwargs)\n\n                wrapper_func.__name__ = func_name\n                func = wrapper_func\n            else:\n                func_name = func.__name__\n            exec(self.template.format(\n                name=func_name + cls.split('.')[-1].capitalize(), base=cls))\n            # 'func' cannot be recognized by exec, so we use 'setattr' instead\n            f = LazyLLMRegisterMetaClass.all_clses[cls.lower()].__getattr__(func_name)\n            f.__name__ = func_name\n            setattr(f, rewrite_func, bind_to_instance(func))\n            return func\n        return impl\n\n    def __getattr__(self, name):\n        if name not in self.fnames:\n            raise AttributeError(f'class {self.__class__} has no attribute {name}')\n\n        def impl(cls):\n            return self(cls, rewrite_func=name)\n        return impl\n\n    def new_group(self, group_name):\n        exec('class LazyLLM{name}Base(self.basecls):\\n    pass\\n'.format(name=group_name))\n"}
{"type": "source_file", "path": "lazyllm/common/queue.py", "content": "import sqlite3\nimport threading\nfrom abc import ABC, abstractmethod\nfrom .globals import globals\nfrom ..configs import config\nimport os\nfrom typing import Type\nfrom lazyllm.thirdparty import redis\nfrom filelock import FileLock\n\nconfig.add(\"default_fsqueue\", str, \"sqlite\", \"DEFAULT_FSQUEUE\")\nconfig.add(\"fsqredis_url\", str, \"\", \"FSQREDIS_URL\")\n\nclass FileSystemQueue(ABC):\n\n    __queue_pool__ = dict()\n\n    def __init__(self, *, klass='__default__'):\n        super().__init__()\n        self._class = klass\n\n    def __new__(cls, *args, **kw):\n        klass = kw.get('klass', '__default__')\n        if klass not in __class__.__queue_pool__:\n            if cls is __class__:\n                __class__.__queue_pool__[klass] = cls.__default_queue__(*args, **kw)\n            else:\n                __class__.__queue_pool__[klass] = super().__new__(cls)\n        return __class__.__queue_pool__[klass]\n\n    @classmethod\n    def get_instance(cls, klass):\n        assert isinstance(klass, str) and klass != '__default__'\n        return cls(klass=klass)\n\n    @classmethod\n    def set_default(cls, queue: Type):\n        cls.__default_queue__ = queue\n\n    @property\n    def sid(self):\n        return f'{globals._sid}-{self._class}'\n\n    def enqueue(self, message): return self._enqueue(self.sid, message)\n    def dequeue(self, limit=None): return self._dequeue(self.sid, limit=limit)\n    def peek(self): return self._peek(self.sid)\n    def size(self): return self._size(self.sid)\n    def init(self): self.clear()\n\n    def clear(self):\n        self._clear(self.sid)\n\n    @abstractmethod\n    def _enqueue(self, id, message): pass\n\n    @abstractmethod\n    def _dequeue(self, id, limit=None): pass\n\n    @abstractmethod\n    def _peek(self, id): pass\n\n    @abstractmethod\n    def _size(self, id): pass\n\n    @abstractmethod\n    def _clear(self, id): pass\n\n# true means one connection can be used in multiple thread\n# refer to: https://sqlite.org/compile.html#threadsafe\ndef sqlite3_check_threadsafety() -> bool:\n    conn = sqlite3.connect(\":memory:\")\n    res = conn.execute(\"\"\"\n        select * from pragma_compile_options\n        where compile_options like 'THREADSAFE=%'\n    \"\"\").fetchall()\n    conn.close()\n    return True if res[0][0] == 'THREADSAFE=1' else False\n\nclass SQLiteQueue(FileSystemQueue):\n    def __init__(self, klass='__default__'):\n        super(__class__, self).__init__(klass=klass)\n        self.db_path = os.path.expanduser(os.path.join(config['home'], '.lazyllm_filesystem_queue.db'))\n        self._lock = FileLock(self.db_path + '.lock')\n        self._check_same_thread = not sqlite3_check_threadsafety()\n        self._initialize_db()\n\n    def _initialize_db(self):\n        with self._lock, sqlite3.connect(self.db_path, check_same_thread=self._check_same_thread) as conn:\n            cursor = conn.cursor()\n            cursor.execute('''\n            CREATE TABLE IF NOT EXISTS queue (\n                id TEXT NOT NULL,\n                position INTEGER NOT NULL,\n                message TEXT NOT NULL,\n                PRIMARY KEY (id, position)\n            )\n            ''')\n            conn.commit()\n\n    def _enqueue(self, id, message):\n        with self._lock:\n            with sqlite3.connect(self.db_path, check_same_thread=self._check_same_thread) as conn:\n                cursor = conn.cursor()\n                cursor.execute('''\n                SELECT MAX(position) FROM queue WHERE id = ?\n                ''', (id,))\n                max_pos = cursor.fetchone()[0]\n                next_pos = 0 if max_pos is None else max_pos + 1\n                cursor.execute('''\n                INSERT INTO queue (id, position, message)\n                VALUES (?, ?, ?)\n                ''', (id, next_pos, message))\n                conn.commit()\n\n    def _dequeue(self, id, limit=None):\n        \"\"\"Retrieve and remove all messages from the queue.\"\"\"\n        with self._lock:\n            with sqlite3.connect(self.db_path, check_same_thread=self._check_same_thread) as conn:\n                cursor = conn.cursor()\n                if limit:\n                    cursor.execute('SELECT message, position FROM queue WHERE id = ? '\n                                   'ORDER BY position ASC LIMIT ?', (id, limit))\n                else:\n                    cursor.execute('SELECT message, position FROM queue WHERE id = ? '\n                                   'ORDER BY position ASC', (id,))\n\n                rows = cursor.fetchall()\n                if not rows:\n                    return []\n                messages = [row[0] for row in rows]\n                cursor.execute('DELETE FROM queue WHERE id = ? AND position IN '\n                               f'({\",\".join([str(row[1]) for row in rows])})', (id, ))\n                conn.commit()\n                return messages\n\n    def _peek(self, id):\n        with self._lock:\n            with sqlite3.connect(self.db_path, check_same_thread=self._check_same_thread) as conn:\n                cursor = conn.cursor()\n                cursor.execute('''\n                SELECT message FROM queue WHERE id = ? ORDER BY position ASC LIMIT 1\n                ''', (id,))\n                row = cursor.fetchone()\n                if row is None:\n                    return None\n                return row[0]\n\n    def _size(self, id):\n        with self._lock:\n            with sqlite3.connect(self.db_path, check_same_thread=self._check_same_thread) as conn:\n                cursor = conn.cursor()\n                cursor.execute('''\n                SELECT COUNT(*) FROM queue WHERE id = ?\n                ''', (id,))\n                return cursor.fetchone()[0]\n\n    def _clear(self, id):\n        with self._lock:\n            with sqlite3.connect(self.db_path, check_same_thread=self._check_same_thread) as conn:\n                cursor = conn.cursor()\n                cursor.execute('''\n                DELETE FROM queue WHERE id = ?\n                ''', (id,))\n                conn.commit()\n\n\nclass RedisQueue(FileSystemQueue):\n    def __init__(self, klass='__default__'):\n        super(__class__, self).__init__(klass=klass)\n        self.redis_url = config[\"fsqredis_url\"]\n        self._lock = threading.Lock()\n        self._initialize_db()\n\n    def _initialize_db(self):\n        with self._lock:\n            conn = redis.Redis.from_url(self.redis_url)\n            assert (\n                conn.ping()\n            ), \"Found fsque reids config but can not connect, please check your config `LAZYLLM_FSQREDIS_URL`.\"\n            if not conn.exists(self.sid):\n                conn.rpush(self.sid, '<start>')\n\n    def _enqueue(self, id, message):\n        with self._lock:\n            conn = redis.Redis.from_url(self.redis_url)\n            conn.rpush(id, message)\n\n    def _dequeue(self, id, limit=None):\n        with self._lock:\n            conn = redis.Redis.from_url(self.redis_url)\n            if limit:\n                limit = limit + 1\n                vals = conn.lrange(id, 1, limit)\n                conn.ltrim(id, limit, -1)\n            else:\n                vals = conn.lrange(id, 1, -1)\n                conn.ltrim(id, 0, 0)\n            if not vals:\n                return []\n            return [val.decode('utf-8') for val in vals]\n\n    def _peek(self, id):\n        with self._lock:\n            conn = redis.Redis.from_url(self.redis_url)\n            val = conn.lindex(id, 1)\n            if val is None:\n                return None\n            return val.decode('utf-8')\n\n    def _size(self, id):\n        with self._lock:\n            conn = redis.Redis.from_url(self.redis_url)\n            rsize = conn.llen(id)\n            return rsize - 1  # empty : [ <start> ]\n\n    def _clear(self, id):\n        with self._lock:\n            conn = redis.Redis.from_url(self.redis_url)\n            conn.delete(id)\n\nfsquemap = {\n    'sqlite': SQLiteQueue,\n    'redis': RedisQueue\n}\n\nFileSystemQueue.set_default(fsquemap.get(config['default_fsqueue'].lower()))\n"}
{"type": "source_file", "path": "lazyllm/common/threading.py", "content": "import threading\nfrom queue import Queue\nimport functools\nfrom .globals import globals\nfrom concurrent.futures import ThreadPoolExecutor as TPE\n\ndef _sid_setter(sid):\n    globals._init_sid(sid)\n\nclass Thread(threading.Thread):\n    def __init__(self, group=None, target=None, name=None,\n                 args=(), kwargs=None, *, prehook=None, daemon=None):\n        self.q = Queue()\n        if not isinstance(prehook, (tuple, list)): prehook = [prehook] if prehook else []\n        prehook.insert(0, functools.partial(_sid_setter, sid=globals._sid))\n        super().__init__(group, self.work, name, (prehook, target, args), kwargs, daemon=daemon)\n\n    def work(self, prehook, target, args, **kw):\n        [p() for p in prehook]\n        try:\n            r = target(*args, **kw)\n        except Exception as e:\n            self.q.put(e)\n        else:\n            self.q.put(r)\n\n    def get_result(self):\n        r = self.q.get()\n        if isinstance(r, Exception):\n            raise r\n        return r\n\n\nclass ThreadPoolExecutor(TPE):\n    def submit(self, fn, /, *args, **kwargs):\n        def impl(sid, *a, **kw):\n            globals._init_sid(sid)\n            return fn(*a, **kw)\n\n        return super(__class__, self).submit(functools.partial(impl, globals._sid), *args, **kwargs)\n"}
{"type": "source_file", "path": "lazyllm/common/globals.py", "content": "import threading\nimport contextvars\nimport copy\nfrom typing import Any, Tuple, Optional, List, Dict\nfrom pydantic import BaseModel as struct\nfrom .common import package, kwargs\nfrom .deprecated import deprecated\nimport asyncio\nfrom .utils import obj2str, str2obj\n\n\nclass ReadWriteLock(object):\n    def __init__(self):\n        self._read_ready = threading.Condition(threading.Lock())\n        self._readers = 0\n\n    class ReadLock:\n        def __init__(self, rw_lock):\n            self.rw_lock = rw_lock\n\n        def __enter__(self):\n            with self.rw_lock._read_ready:\n                self.rw_lock._readers += 1\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            with self.rw_lock._read_ready:\n                self.rw_lock._readers -= 1\n                if self.rw_lock._readers == 0:\n                    self.rw_lock._read_ready.notify_all()\n\n    class WriteLock:\n        def __init__(self, rw_lock):\n            self.rw_lock = rw_lock\n\n        def __enter__(self):\n            self.rw_lock._read_ready.acquire()\n            while self.rw_lock._readers > 0:\n                self.rw_lock._read_ready.wait()\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            self.rw_lock._read_ready.release()\n\n    def read_lock(self):\n        return self.ReadLock(self)\n\n    def write_lock(self):\n        return self.WriteLock(self)\n\n    def __deepcopy__(self, *args, **kw):\n        return ReadWriteLock()\n\n    def __reduce__(self):\n        return ReadWriteLock, ()\n\n\nclass ThreadSafeDict(dict):\n    def __init__(self, *args, **kw):\n        super(__class__, self).__init__(*args, **kw)\n        self._lock = ReadWriteLock()\n\n    def __getitem__(self, key):\n        with self._lock.read_lock():\n            return super(__class__, self).__getitem__(key)\n\n    def __setitem__(self, key, value):\n        with self._lock.write_lock():\n            return super(__class__, self).__setitem__(key, value)\n\n    def __delitem__(self, key):\n        with self._lock.read_lock():\n            return super(__class__, self).__delitem__(key)\n\n    def __contains__(self, key):\n        with self._lock.read_lock():\n            return super(__class__, self).__contains__(key)\n\n    def get(self, key, __default=None):\n        with self._lock.read_lock():\n            return super(__class__, self).get(key, __default)\n\n    def keys(self):\n        with self._lock.read_lock():\n            return super(__class__, self).keys()\n\n    def values(self):\n        with self._lock.read_lock():\n            return super(__class__, self).values()\n\n    def items(self):\n        with self._lock.read_lock():\n            return super(__class__, self).items()\n\n    def update(self, *args, **kwargs):\n        with self._lock.write_lock():\n            return super(__class__, self).update(*args, **kwargs)\n\n    def clear(self):\n        with self._lock.write_lock():\n            return super(__class__, self).clear()\n\n    def pop(self, key, __default=None):\n        with self._lock.write_lock():\n            return super(__class__, self).pop(key, __default)\n\n    def __len__(self):\n        with self._lock.read_lock():\n            return super(__class__, self).__len__()\n\n    def __str__(self):\n        with self._lock.read_lock():\n            return super(__class__, self).__str__()\n\n    def __repr__(self):\n        with self._lock.read_lock():\n            return super(__class__, self).__repr__()\n\n    def __reduce__(self):\n        with self._lock.read_lock():\n            return (self.__class__, (dict(self),))\n\n\nclass Globals(object):\n    __global_attrs__ = ThreadSafeDict(\n        chat_history={}, global_parameters={}, bind_args={}, tool_delimiter=\"<|tool_calls|>\", lazyllm_files={}, usage={}\n    )\n\n    def __init__(self):\n        self.__data = ThreadSafeDict()\n        self.__sid = contextvars.ContextVar('local_var')\n        self._init_sid()\n\n    def _init_sid(self, sid: Optional[str] = None):\n        if sid is None:\n            try:\n                sid = f'aid-{hex(id(asyncio.current_task()))}'\n            except Exception:\n                sid = f'tid-{hex(threading.get_ident())}'\n        self.__sid.set(sid)\n        return sid\n\n    @property\n    def _sid(self) -> str:\n        try:\n            sid = self.__sid.get()\n        except Exception:\n            sid = self._init_sid()\n        if sid not in self.__data:\n            self.__data[sid] = copy.deepcopy(__class__.__global_attrs__)\n        return sid\n\n    @property\n    def _data(self): return self._get_data()\n\n    def _get_data(self, rois: Optional[List[str]] = None) -> dict:\n        if rois:\n            assert isinstance(rois, (tuple, list))\n            return {k: v for k, v in self.__data[self._sid].items() if k in rois}\n        return self.__data[self._sid]\n\n    @property\n    def _pickle_data(self):\n        exclude_keys = ['bind_args',]\n        return {k: v for k, v in self._data.items() if k not in exclude_keys}\n\n    def _update(self, d: Optional[Dict]) -> None:\n        if d:\n            self._data.update(d)\n\n    def __setitem__(self, __key: str, __value: Any):\n        self._data[__key] = __value\n\n    def __getitem__(self, __key: str):\n        try:\n            return self._data[__key]\n        except KeyError:\n            raise KeyError(f'Cannot find key {__key}, current session-id is {self._sid}')\n\n    def get(self, __key: str, default: Any = None):\n        try:\n            return self[__key]\n        except KeyError:\n            return default\n\n    def __setattr__(self, __name: str, __value: Any):\n        if __name in __class__.__global_attrs__:\n            self[__name] = __value\n        else:\n            super(__class__, self).__setattr__(__name, __value)\n\n    def __getattr__(self, __name: str) -> Any:\n        if __name in __class__.__global_attrs__:\n            return self[__name]\n        raise AttributeError(f'Attr {__name} not found in globals')\n\n    def clear(self):\n        self.__data.pop(self._sid, None)\n\n    def _clear_all(self):\n        self.__data.clear()\n\n    def __contains__(self, item):\n        return item in self.__data[self._sid]\n\n    def pop(self, *args, **kw):\n        return self._data.pop(*args, **kw)\n\nglobals = Globals()\n\n\n@deprecated\nclass LazyLlmRequest(object):\n    input: Any = package()\n    kwargs: Any = kwargs()\n    global_parameters: dict = dict()\n\n\n@deprecated\nclass LazyLlmResponse(struct):\n    messages: Any = None\n    trace: str = ''\n    err: Tuple[int, str] = (0, '')\n\n    def __repr__(self): return repr(self.messages)\n    def __str__(self): return str(self.messages)\n\n\ndef encode_request(input):\n    return obj2str(input)\n\n\ndef decode_request(input, default=None):\n    if input is None: return default\n    return str2obj(input)\n"}
{"type": "source_file", "path": "lazyllm/common/deprecated.py", "content": "from .logger import LOG\nimport functools\nfrom typing import overload, Callable, Any\n\n@overload\ndef deprecated(msg: str) -> Callable[[Callable], Callable]:\n    ...\n\n@overload\ndef deprecated(func: Callable) -> Callable[[Any], Any]:\n    ...\n\n@overload\ndef deprecated(flag: bool, msg: str) -> Callable[[Any], Any]:\n    ...\n\ndef deprecated(func_or_msg=None, item_name=''):\n    def impl(func):\n        msg = f'{func.__name__} is deprecated and will be removed in a future version.'\n        if isinstance(func_or_msg, str): msg += f' Use `{func_or_msg}` instead'\n        if isinstance(func, type):\n            orig_init = func.__init__\n\n            @functools.wraps(orig_init)\n            def new_init(self, *args, **kwargs):\n                LOG.warning(f'Class {msg}')\n                orig_init(self, *args, **kwargs)\n\n            func.__init__ = new_init\n            return func\n        else:\n            @functools.wraps(func)\n            def new_func(*args, **kwargs):\n                LOG.warning(f'Function {msg}')\n                return func(*args, **kwargs)\n            return new_func\n\n    if isinstance(func_or_msg, str):\n        return impl\n    elif isinstance(func_or_msg, bool):\n        if func_or_msg: LOG.warning(f'{item_name} is deprecated')\n    else:\n        return impl(func_or_msg)\n"}
{"type": "source_file", "path": "lazyllm/common/utils.py", "content": "from os import PathLike, makedirs\nfrom os.path import expanduser, expandvars, isfile, join, normpath\nfrom typing import Union, Dict, Callable, Any, Optional\nimport re\nimport ast\nimport pickle\nimport base64\n\ndef check_path(\n    path: Union[str, PathLike],\n    exist: bool = True,\n    file: bool = True,\n    parents: bool = True,\n) -> str:\n    \"\"\"\n    Check path and return corrected path.\n    \"\"\"\n    # normalize and expand a path\n    path = normpath(expandvars(expanduser(path)))\n    if exist and file and not isfile(path):\n        raise FileNotFoundError(path)\n    else:\n        if file:\n            dir_path = normpath(join(path, \"..\"))\n        else:\n            dir_path = path\n        if parents:\n            makedirs(dir_path, exist_ok=True)\n    return path\n\n\ndef compile_func(func_code: str, global_env: Optional[Dict[str, Any]] = None) -> Callable:\n    fname = re.search(r'def\\s+(\\w+)\\s*\\(', func_code).group(1)\n    module = ast.parse(func_code)\n    func = compile(module, filename=\"<ast>\", mode=\"exec\")\n    local_dict = {}\n    exec(func, global_env, local_dict)\n    return local_dict[fname]\n\ndef obj2str(obj: Any) -> str:\n    return base64.b64encode(pickle.dumps(obj)).decode('utf-8')\n\ndef str2obj(data: str) -> Any:\n    return None if data is None else pickle.loads(base64.b64decode(data.encode('utf-8')))\n"}
{"type": "source_file", "path": "lazyllm/common/text.py", "content": "class Color(object):\n    red: str = \"\\033[31m\"\n    green: str = \"\\033[32m\"\n    yellow: str = \"\\033[33m\"\n    blue: str = \"\\033[34m\"\n    magenta: str = \"\\033[35m\"\n    cyan: str = \"\\033[36m\"\n    reset: str = \"\\033[0m\"\n\ndef colored_text(text, color):\n    if not color: return text\n    color = color if color.startswith(\"\\033\") else Color.get(color, Color.reset)\n    return f'{color}{text}{Color.reset}'\n"}
{"type": "source_file", "path": "lazyllm/cli/main.py", "content": "import sys\ntry:\n    from install import install\n    from deploy import deploy\n    from run import run\nexcept ImportError:\n    from .install import install\n    from .deploy import deploy\n    from .run import run\n\ndef main():\n    def exit():\n        print('Usage:\\n  lazyllm install [full|standard|package_name]\\n'\n              '  lazyllm deploy modelname\\n  lazyllm run graph.json\\n'\n              '  lazyllm run chatbot\\n  lazyllm run rag\\n')\n        sys.exit(1)\n\n    if len(sys.argv) <= 1: exit()\n\n    commands = sys.argv[2:]\n    if sys.argv[1] == 'install':\n        install(commands)\n    elif sys.argv[1] == 'deploy':\n        deploy(commands)\n    elif sys.argv[1] == 'run':\n        run(commands)\n    else:\n        exit()\n\nif __name__ == \"__main__\":\n    main()\n"}
