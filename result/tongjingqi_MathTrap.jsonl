{"repo_info": {"repo_name": "MathTrap", "repo_owner": "tongjingqi", "repo_url": "https://github.com/tongjingqi/MathTrap"}}
{"type": "source_file", "path": "GPT4_eval/get_response_example.py", "content": "import json,os\ndef get_prompt(context):\n    '''use corresponding api to get response'''\ndef read_json(file):\n    if os.path.exists(file):\n        with open(file,'r',encoding='utf-8') as f:\n            return json.load(f)\n    else:\n        with open(file,'w',encoding='utf-8') as f:\n            f.write('[]')\n            return []\n    \ndef add_object_to_json_file(obj, filepath):\n    if os.path.exists(filepath):\n        with open(filepath, 'r', encoding='utf-8') as file:\n            data = json.load(file)\n    else:\n        if isinstance(obj,dict):data={}\n        else:data = []\n    if isinstance(data,dict):data|=obj\n    else:data.append(obj)\n    with open(filepath, 'w', encoding='utf-8') as file:\n        json.dump(data, file, ensure_ascii=False, indent=4)\n\nprompt_templates={'unhint':\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{input}\\n\\n### Response: Let's think step by step.\"\"\",\n'hint':'''Below is an instruction that describes a task. Write a response that appropriately completes the request.\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\\n### Instruction:\\n{input}\\n\\n### Response: Let's think step by step.''',\n'icl5':'''Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\nThe problem is unsolvable.\\n### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b?\\n### Response: Let's think step by step. Given the equation $5r^2 + br - 12$ and the constraint that $r$ is a negative integer, we are asked to find the maximum value of the expression and equate it to 36 to solve for $b$.\\n\\nLet's first understand the structure of our equation. It is a quadratic equation of the form $ax^2 + bx + c$. The graph of a quadratic equation is a parabola. The direction of the parabola (whether it opens upwards or downwards) is determined by the sign of the coefficient of $r^2$ (which is equivalent to $a$ in our standard form). \\n\\nSince the coefficient of $r^2$ is 5, which is positive, our parabola opens upwards.\\n\\nBut here's where we run into a problem. A parabola that opens upwards does not have a maximum value, it has a minimum value. This is because as $r$ moves either positively or negatively away from the vertex (the peak or trough of the parabola), the value of the expression $5r^2 + br - 12$ increases.\\n\\nFurthermore, the constraint that $r$ is a negative integer doesn't affect this conclusion. Regardless of whether $r$ is positive or negative, a parabola that opens upwards does not have a maximum value.\\n\\nTherefore, it is impossible to equate the maximum value of the expression to 36 as the problem initially asks, and we cannot solve for $b$ under these conditions. The question has posed an unsolvable scenario.\\nThe problem is unsolvable.\\n### Instruction:\\nHow many prime numbers can be divided by 39?\\n### Response: Let's think step by step. No prime numbers can be divided by 39. By definition, a prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. Since 39 is composed of the factors 3 and 13 (both of which are prime numbers themselves), any number that can be divided by 39 cannot be a prime number, as it would have to at least include 3 and 13 as factors besides 1 and itself.\\nTherefore, there are \\\\boxed{{0}} prime numbers that can be divided by 39. The answer is: 0\\n### Instruction:\\nIf odd integers $x y$ satisfies $\\\\\\\\frac{{1}}{{2}}-\\\\\\\\frac{{1}}{{3}}=\\\\\\\\frac{{x}}{{y}}$, then what is the value of $x$?\\n### Response: Let's think step by step. To solve this problem, we must first simplify the left-hand side of the equation, $\\\\frac{{1}}{{2}}-\\\\frac{{1}}{{3}}$. This simplifies to $\\\\frac{{1}}{{6}}$. So the equation becomes $\\\\frac{{1}}{{6}}=\\\\frac{{x}}{{y}}$.\\n\\nWe can cross multiply to get $x = \\\\frac{{1}}{{6}}y$. \\n\\nThe problem arises from the requirement that both $x$ and $y$ be odd integers. If we multiply an odd number $y$ by $\\\\frac{{1}}{{6}}$, we would not yield an odd integer for $x$. This is because a fraction of an odd integer doesn't result in an integer, let alone an odd integer.\\n\\nFurthermore, to produce $\\\\frac{{1}}{{6}}$, $y$ would have to be a multiple of 6, which means $y$ would be even. This contradicts the original stipulation that $y$ should be an odd integer.\\n\\nTherefore, under the given conditions, there is no solution to this problem. The constraints on $x$ and $y$ being odd integers and the equation $\\\\frac{{1}}{{2}}-\\\\frac{{1}}{{3}}=\\\\frac{{x}}{{y}}$ cannot hold true simultaneously.\\nThe problem is unsolvable.\\n### Instruction:\\nIf a triangle has two sides of lengths 5 and 7 units, then how many different integer lengths can the third side be?\\n### Response: Let's think step by step. Let the two given sides be $a$ and $b$.\\nFor a triangle to be formed, the third side must satisfy the triangle inequality, which states that the sum of the lengths of any two sides of a triangle must be greater than the length of the remaining side.\\nSo for the third side, we have the inequalities $|a-b| < c < a+b$.\\nIn this case, $a=5$ and $b=7$, so the inequalities become $|5-7| < c < 5+7$, which simplify to $2 < c < 12$.\\nSince $c$ must be an integer, the possible integer lengths for the third side are 3, 4, 5, 6, 7, 8, 9, 10, and 11.\\nTherefore, there are $\\\\boxed{{9}}$ different integer lengths the third side can be.\\nThe answer is: 9\\n### Instruction:\\nFind p if the focus of the parabola $x + x^2 = -\\\\\\\\frac{{p}}{{12}} y^2.$ is (-1/2,1).\\n### Response: Let's think step by step. To begin solving this problem, we first need to express the equation in the standard form of a parabola. The standard forms are either $y^2 = 4ax$ or $x^2 = 4ay$ where (a,0) is the focus for the first case, and (0,a) is the focus for the second case. Let's try to manipulate the given equation into one of these forms.\\n\\nThe given equation is $x+x^2=-\\\\frac{{p}}{{12}}y^2$. Rearranging this equation, we have $x^2 + x + \\\\frac{{p}}{{12}}y^2 = 0$.\\n\\nThis equation does not align with the standard form of a parabola equation. The standard form of the equation of a parabola should only have the square of one variable, either $x$ or $y$. However, in our equation, $x$ is squared, and there is also a term involving $y^2$.\\n\\nTherefore, we can't express the equation in the standard form of a parabola, which indicates that the equation does not represent a parabola. Consequently, we cannot find a focus for a parabola because the given equation does not describe a parabola. The initial assumption that we are dealing with a parabola is incorrect.\\nThe problem is unsolvable.### Instruction:\\n{input}\\n\\n### Response: Let's think step by step.''',\n'trueorfalse':'''Below is an instruction that describes a task. Write a response that appropriately completes the request.\\nThe following is a true or false question, please provide a conclusion of either True or False after analysis.\\n\\n### Instruction:\\n{input}\\n\\n### Response: Let's think step by step.'''}\nprompt_template=prompt_templates['unhint']\ninPath=\"./your_input_path.json\"\ndata=read_json(inPath)\noutPath=\"./your_output_path.json\"\nhaslen=len(read_json(outPath))\ncount=0\nfor idata in data:\n    if count<haslen:count+=1;continue\n    count+=1\n    dic={\"input\":idata['input']}\n    response=get_prompt(prompt_template.format(**dic))\n    while not response:print('re');response=get_prompt(prompt_template.format(**dic))\n    print(response)\n    idata['response']=response\n    add_object_to_json_file(idata,outPath)\n    "}
{"type": "source_file", "path": "eval/eval_GSM8K_category.py", "content": "import argparse\nimport json\nimport re\nimport jsonlines\nfrom fraction import Fraction\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n    return False\n\ndef extract_answer_number(completion):\n    text = completion.split('The answer is: ')\n    if len(text) > 1:\n        extract_ans = text[-1].strip()\n        match = re.search(r'[\\-+]?\\d*[\\.,/]?\\d+', extract_ans)\n        if match:\n            if '/' in match.group():\n                denominator = match.group().split('/')[1]\n                numerator = match.group().split('/')[0]\n                if is_number(denominator) == True and is_number(numerator) == True:\n                    if denominator == '0':\n                        return round(float(numerator.replace(',', '')))\n                    else:\n                        frac = Fraction(match.group().replace(',', ''))\n                        num_numerator = frac.numerator\n                        num_denominator = frac.denominator\n                        return round(float(num_numerator / num_denominator))\n                else:\n                    return None\n            else:\n                if float(match.group().replace(',', '')) == float('inf'):\n                    return None\n                return round(float(match.group().replace(',', '')))\n        else:\n            return None\n    else:\n        return None\n\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\n\ndef gsm8k_test(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    INVALID_ANS = \"[invalid]\"\n    gsm8k_ins = []\n    gsm8k_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path,\"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"question\"])\n            gsm8k_ins.append(temp_instr)\n            temp_ans = item['answer'].split('#### ')[1]\n            temp_ans = int(temp_ans.replace(',', ''))\n            gsm8k_answers.append(temp_ans)\n\n    gsm8k_ins = gsm8k_ins[start:end]\n    gsm8k_answers = gsm8k_answers[start:end]\n    print('lenght ====', len(gsm8k_ins))\n    batch_gsm8k_ins = batch_data(gsm8k_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0.0, top_p=1, max_tokens=512, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    result = []\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_gsm8k_ins, gsm8k_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    invalid_outputs = []\n    valid_outputs=[]\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(gsm8k_ins, res_completions, gsm8k_answers)):\n        doc = {'question': prompt}\n        y_pred = extract_answer_number(completion)\n        if y_pred != None:\n            result.append(float(y_pred) == float(prompt_answer))\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            valid_outputs.append(temp)\n        else:\n            result.append(False)\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            invalid_outputs.append(temp)\n    acc = sum(result) / len(result)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====', end)\n    print('gsm8k length====', len(result), ', gsm8k acc====', acc)\n\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str)  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = parse_args()\n    gsm8k_test(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_ICL/eval_ICL_5-shot/eval_GSM8K_category_ICL(5shot).py", "content": "import argparse\nimport json\nimport re\nimport jsonlines\nfrom fraction import Fraction\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n    return False\n\ndef extract_answer_number(completion):\n    text = completion.split('The answer is: ')\n    if len(text) > 1:\n        extract_ans = text[-1].strip()\n        match = re.search(r'[\\-+]?\\d*[\\.,/]?\\d+', extract_ans)\n        if match:\n            if '/' in match.group():\n                denominator = match.group().split('/')[1]\n                numerator = match.group().split('/')[0]\n                if is_number(denominator) == True and is_number(numerator) == True:\n                    if denominator == '0':\n                        return round(float(numerator.replace(',', '')))\n                    else:\n                        frac = Fraction(match.group().replace(',', ''))\n                        num_numerator = frac.numerator\n                        num_denominator = frac.denominator\n                        return round(float(num_numerator / num_denominator))\n                else:\n                    return None\n            else:\n                if float(match.group().replace(',', '')) == float('inf'):\n                    return None\n                return round(float(match.group().replace(',', '')))\n        else:\n            return None\n    else:\n        return None\n\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\n\ndef gsm8k_test(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    INVALID_ANS = \"[invalid]\"\n    gsm8k_ins = []\n    gsm8k_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b?\\n### Response: Let's think step by step. Given the equation $5r^2 + br - 12$ and the constraint that $r$ is a negative integer, we are asked to find the maximum value of the expression and equate it to 36 to solve for $b$.\\n\\nLet's first understand the structure of our equation. It is a quadratic equation of the form $ax^2 + bx + c$. The graph of a quadratic equation is a parabola. The direction of the parabola (whether it opens upwards or downwards) is determined by the sign of the coefficient of $r^2$ (which is equivalent to $a$ in our standard form). \\n\\nSince the coefficient of $r^2$ is 5, which is positive, our parabola opens upwards.\\n\\nBut here's where we run into a problem. A parabola that opens upwards does not have a maximum value, it has a minimum value. This is because as $r$ moves either positively or negatively away from the vertex (the peak or trough of the parabola), the value of the expression $5r^2 + br - 12$ increases.\\n\\nFurthermore, the constraint that $r$ is a negative integer doesn't affect this conclusion. Regardless of whether $r$ is positive or negative, a parabola that opens upwards does not have a maximum value.\\n\\nTherefore, it is impossible to equate the maximum value of the expression to 36 as the problem initially asks, and we cannot solve for $b$ under these conditions. The question has posed an unsolvable scenario.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nHow many prime numbers can be divided by 39?\\n### Response: Let's think step by step. No prime numbers can be divided by 39. By definition, a prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. Since 39 is composed of the factors 3 and 13 (both of which are prime numbers themselves), any number that can be divided by 39 cannot be a prime number, as it would have to at least include 3 and 13 as factors besides 1 and itself.\\nTherefore, there are \\\\boxed{{0}} prime numbers that can be divided by 39. The answer is: 0\\n\"\n        \"### Instruction:\\nIf odd integers $x y$ satisfies $\\\\\\\\frac{{1}}{{2}}-\\\\\\\\frac{{1}}{{3}}=\\\\\\\\frac{{x}}{{y}}$, then what is the value of $x$?\\n### Response: Let's think step by step. To solve this problem, we must first simplify the left-hand side of the equation, $\\\\frac{{1}}{{2}}-\\\\frac{{1}}{{3}}$. This simplifies to $\\\\frac{{1}}{{6}}$. So the equation becomes $\\\\frac{{1}}{{6}}=\\\\frac{{x}}{{y}}$.\\n\\nWe can cross multiply to get $x = \\\\frac{{1}}{{6}}y$. \\n\\nThe problem arises from the requirement that both $x$ and $y$ be odd integers. If we multiply an odd number $y$ by $\\\\frac{{1}}{{6}}$, we would not yield an odd integer for $x$. This is because a fraction of an odd integer doesn't result in an integer, let alone an odd integer.\\n\\nFurthermore, to produce $\\\\frac{{1}}{{6}}$, $y$ would have to be a multiple of 6, which means $y$ would be even. This contradicts the original stipulation that $y$ should be an odd integer.\\n\\nTherefore, under the given conditions, there is no solution to this problem. The constraints on $x$ and $y$ being odd integers and the equation $\\\\frac{{1}}{{2}}-\\\\frac{{1}}{{3}}=\\\\frac{{x}}{{y}}$ cannot hold true simultaneously.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nIf a triangle has two sides of lengths 5 and 7 units, then how many different integer lengths can the third side be?\\n### Response: Let's think step by step. Let the two given sides be $a$ and $b$.\\nFor a triangle to be formed, the third side must satisfy the triangle inequality, which states that the sum of the lengths of any two sides of a triangle must be greater than the length of the remaining side.\\nSo for the third side, we have the inequalities $|a-b| < c < a+b$.\\nIn this case, $a=5$ and $b=7$, so the inequalities become $|5-7| < c < 5+7$, which simplify to $2 < c < 12$.\\nSince $c$ must be an integer, the possible integer lengths for the third side are 3, 4, 5, 6, 7, 8, 9, 10, and 11.\\nTherefore, there are $\\\\boxed{{9}}$ different integer lengths the third side can be.\\nThe answer is: 9\\n\"\n        \"### Instruction:\\nFind p if the focus of the parabola $x + x^2 = -\\\\\\\\frac{{p}}{{12}} y^2.$ is (-1/2,1).\\n### Response: Let's think step by step. To begin solving this problem, we first need to express the equation in the standard form of a parabola. The standard forms are either $y^2 = 4ax$ or $x^2 = 4ay$ where (a,0) is the focus for the first case, and (0,a) is the focus for the second case. Let's try to manipulate the given equation into one of these forms.\\n\\nThe given equation is $x+x^2=-\\\\frac{{p}}{{12}}y^2$. Rearranging this equation, we have $x^2 + x + \\\\frac{{p}}{{12}}y^2 = 0$.\\n\\nThis equation does not align with the standard form of a parabola equation. The standard form of the equation of a parabola should only have the square of one variable, either $x$ or $y$. However, in our equation, $x$ is squared, and there is also a term involving $y^2$.\\n\\nTherefore, we can't express the equation in the standard form of a parabola, which indicates that the equation does not represent a parabola. Consequently, we cannot find a focus for a parabola because the given equation does not describe a parabola. The initial assumption that we are dealing with a parabola is incorrect.\\nThe problem is unsolvable.\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path,\"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"question\"])\n            gsm8k_ins.append(temp_instr)\n            temp_ans = item['answer'].split('#### ')[1]\n            temp_ans = int(temp_ans.replace(',', ''))\n            gsm8k_answers.append(temp_ans)\n\n    gsm8k_ins = gsm8k_ins[start:end]\n    gsm8k_answers = gsm8k_answers[start:end]\n    print('lenght ====', len(gsm8k_ins))\n    batch_gsm8k_ins = batch_data(gsm8k_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0.0, top_p=1, max_tokens=512, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    result = []\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_gsm8k_ins, gsm8k_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    invalid_outputs = []\n    valid_outputs=[]\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(gsm8k_ins, res_completions, gsm8k_answers)):\n        doc = {'question': prompt}\n        y_pred = extract_answer_number(completion)\n        if y_pred != None:\n            result.append(float(y_pred) == float(prompt_answer))\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            valid_outputs.append(temp)\n        else:\n            result.append(False)\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            invalid_outputs.append(temp)\n    acc = sum(result) / len(result)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====', end)\n    print('gsm8k length====', len(result), ', gsm8k acc====', acc)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str)  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = parse_args()\n    gsm8k_test(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_ICL/eval_ICL_5-shot/eval_MATH_category2_ICL(5shot).py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s):\n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer,category,category_stats):\n    split_ans = completion.split('The answer is: ')\n    if len(split_ans) > 1:\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n\n        valid_outputs.append(temp)\n        ans = split_ans[-1]\n        \n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        if util.is_equiv(extract_ans, answer):\n            category_stats[category] = category_stats.get(category, {'correct': 0, 'wrong': 0})\n            category_stats[category]['correct'] += 1\n            return True\n        else:\n            category_stats[category] = category_stats.get(category, {'correct': 0, 'wrong': 0})\n            category_stats[category]['wrong'] += 1\n            return False\n        \n    else:\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    category_stats = {}\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b?\\n### Response: Let's think step by step. Given the equation $5r^2 + br - 12$ and the constraint that $r$ is a negative integer, we are asked to find the maximum value of the expression and equate it to 36 to solve for $b$.\\n\\nLet's first understand the structure of our equation. It is a quadratic equation of the form $ax^2 + bx + c$. The graph of a quadratic equation is a parabola. The direction of the parabola (whether it opens upwards or downwards) is determined by the sign of the coefficient of $r^2$ (which is equivalent to $a$ in our standard form). \\n\\nSince the coefficient of $r^2$ is 5, which is positive, our parabola opens upwards.\\n\\nBut here's where we run into a problem. A parabola that opens upwards does not have a maximum value, it has a minimum value. This is because as $r$ moves either positively or negatively away from the vertex (the peak or trough of the parabola), the value of the expression $5r^2 + br - 12$ increases.\\n\\nFurthermore, the constraint that $r$ is a negative integer doesn't affect this conclusion. Regardless of whether $r$ is positive or negative, a parabola that opens upwards does not have a maximum value.\\n\\nTherefore, it is impossible to equate the maximum value of the expression to 36 as the problem initially asks, and we cannot solve for $b$ under these conditions. The question has posed an unsolvable scenario.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nHow many prime numbers can be divided by 39?\\n### Response: Let's think step by step. No prime numbers can be divided by 39. By definition, a prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. Since 39 is composed of the factors 3 and 13 (both of which are prime numbers themselves), any number that can be divided by 39 cannot be a prime number, as it would have to at least include 3 and 13 as factors besides 1 and itself.\\nTherefore, there are \\\\boxed{{0}} prime numbers that can be divided by 39. The answer is: 0\\n\"\n        \"### Instruction:\\nIf odd integers $x y$ satisfies $\\\\\\\\frac{{1}}{{2}}-\\\\\\\\frac{{1}}{{3}}=\\\\\\\\frac{{x}}{{y}}$, then what is the value of $x$?\\n### Response: Let's think step by step. To solve this problem, we must first simplify the left-hand side of the equation, $\\\\frac{{1}}{{2}}-\\\\frac{{1}}{{3}}$. This simplifies to $\\\\frac{{1}}{{6}}$. So the equation becomes $\\\\frac{{1}}{{6}}=\\\\frac{{x}}{{y}}$.\\n\\nWe can cross multiply to get $x = \\\\frac{{1}}{{6}}y$. \\n\\nThe problem arises from the requirement that both $x$ and $y$ be odd integers. If we multiply an odd number $y$ by $\\\\frac{{1}}{{6}}$, we would not yield an odd integer for $x$. This is because a fraction of an odd integer doesn't result in an integer, let alone an odd integer.\\n\\nFurthermore, to produce $\\\\frac{{1}}{{6}}$, $y$ would have to be a multiple of 6, which means $y$ would be even. This contradicts the original stipulation that $y$ should be an odd integer.\\n\\nTherefore, under the given conditions, there is no solution to this problem. The constraints on $x$ and $y$ being odd integers and the equation $\\\\frac{{1}}{{2}}-\\\\frac{{1}}{{3}}=\\\\frac{{x}}{{y}}$ cannot hold true simultaneously.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nIf a triangle has two sides of lengths 5 and 7 units, then how many different integer lengths can the third side be?\\n### Response: Let's think step by step. Let the two given sides be $a$ and $b$.\\nFor a triangle to be formed, the third side must satisfy the triangle inequality, which states that the sum of the lengths of any two sides of a triangle must be greater than the length of the remaining side.\\nSo for the third side, we have the inequalities $|a-b| < c < a+b$.\\nIn this case, $a=5$ and $b=7$, so the inequalities become $|5-7| < c < 5+7$, which simplify to $2 < c < 12$.\\nSince $c$ must be an integer, the possible integer lengths for the third side are 3, 4, 5, 6, 7, 8, 9, 10, and 11.\\nTherefore, there are $\\\\boxed{{9}}$ different integer lengths the third side can be.\\nThe answer is: 9\\n\"\n        \"### Instruction:\\nFind p if the focus of the parabola $x + x^2 = -\\\\\\\\frac{{p}}{{12}} y^2.$ is (-1/2,1).\\n### Response: Let's think step by step. To begin solving this problem, we first need to express the equation in the standard form of a parabola. The standard forms are either $y^2 = 4ax$ or $x^2 = 4ay$ where (a,0) is the focus for the first case, and (0,a) is the focus for the second case. Let's try to manipulate the given equation into one of these forms.\\n\\nThe given equation is $x+x^2=-\\\\frac{{p}}{{12}}y^2$. Rearranging this equation, we have $x^2 + x + \\\\frac{{p}}{{12}}y^2 = 0$.\\n\\nThis equation does not align with the standard form of a parabola equation. The standard form of the equation of a parabola should only have the square of one variable, either $x$ or $y$. However, in our equation, $x$ is squared, and there is also a term involving $y^2$.\\n\\nTherefore, we can't express the equation in the standard form of a parabola, which indicates that the equation does not represent a parabola. Consequently, we cannot find a focus for a parabola because the given equation does not describe a parabola. The initial assumption that we are dealing with a parabola is incorrect.\\nThe problem is unsolvable.\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    categories = []  # 初始化类别列表\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            categories.append(item[\"category\"])  # 添加当前题目的类别到列表\n            temp_instr = problem_prompt.format(instruction=item[\"question\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['answer']\n            temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(temp_ans)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer,category) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers, categories)):\n        res = process_results(prompt, completion, prompt_answer, category,category_stats)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\n    total_correct = 0\n    total_questions = 0\n    for category, stats in category_stats.items():\n        cat_correct = stats['correct']\n        cat_total = stats['correct'] + stats['wrong']\n        cat_accuracy = cat_correct / cat_total\n        print(f\"Category {category}: correct:{cat_correct}, total:{cat_total}, {cat_correct}/{cat_total} correct, Accuracy: {cat_accuracy*100:.2f}%\")\n        total_correct += cat_correct\n        total_questions += cat_total\n\n    overall_accuracy = total_correct / total_questions\n    print(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "GPT4_eval/scoring_example.py", "content": "import json,os\ndef get_prompt(context):\n    '''use corresponding api to get response'''\ndef read_json(file):\n    if os.path.exists(file):\n        with open(file,'r',encoding='utf-8') as f:\n            return json.load(f)\n    else:\n        with open(file,'w',encoding='utf-8') as f:\n            f.write('[]')\n            return []\n    \ndef add_object_to_json_file(obj, filepath):\n    if os.path.exists(filepath):\n        with open(filepath, 'r', encoding='utf-8') as file:\n            data = json.load(file)\n    else:\n        if isinstance(obj,dict):data={}\n        else:data = []\n    if isinstance(data,dict):data|=obj\n    else:data.append(obj)\n    with open(filepath, 'w', encoding='utf-8') as file:\n        json.dump(data, file, ensure_ascii=False, indent=4)\n\nprompt_templates={'trap':\"\"\"Following is a problem with no solution or can't be solved, and a reference answer about how to find the contradiction. There is also an answer you need to make a verdict on whether it finds the same contradiction as the reference answer does. Please output a short comment and end with [0] or [1] ([1] means the answer finds the same contradiction and explicitly states it). #The Problem: {input} \\n#The Reference Answer: {ref}\\n#The Answer Needs Verdict: {answer}\\n#Your Verdict: \"\"\",\n'original':'''Following is a math problem, a reference answer and a response you need to make a verdict on whether it is right according to the reference answer. Please output a short comment and end with [0] or [1] ([1] means right). #The Problem: {input} \\n#The Reference Answer: {ref}\\n#The Response Needs Verdict: {answer}\\n#Your Verdict: ''',\n'trueorfalse':'''Following is a true-or-false question, a reference answer and a response you need to make a verdict on whether it is right according to the reference answer. Please output a short comment and end with [0] or [1] ([1] means right). #The Question: {input} \\n#The Reference Answer: {ref}\\n#The Response Needs Verdict: {answer}\\n#Your Verdict: '''}\nscores=\"\"\ndef process(inPath,outPath,READ):\n    #READ==0 means evaluating answers from inPath and save verdicts to outPath. After all answers are evaluated there will be a simple statistics like \n    # inPath.json:\n    # Default: wrong=10, correct=20, sum=30\n    #READ==1 means loading verdicts from outPath and printing statistics again.\n    prompt_template=prompt_templates['trap']\n    READ0=READ\n    categories={\"Default\":[0,0]}\n    ans=[]\n    data=read_json(inPath)\n    outData=read_json(outPath)\n    ans=outData\n    haslen=len(read_json(outPath))\n    count=0\n    for idata in data:\n        READ=READ0 or count<haslen\n        count+=1\n        question,output,answer=idata['input'],idata['response'],idata['answer']\n        category='Default'\n        dic={\"input\":question,\"ref\":answer,\"answer\":output}\n        anses=[]\n        score=0\n        if READ:\n            response=outData[count-1][\"answer\"]\n        else:response=get_prompt(prompt_template.format(**dic))\n        if READ:\n            ai=response[0]\n        else:\n            ai=response\n        if '[0]'in ai:score+=0\n        elif '[1]'in ai:score+=1\n        \n        anses.append(ai)\n        if not READ:print(score,ai,f'{count}/{len(data)}')\n        if category in categories:\n            categories[category][int(score)]+=1\n        ans.append({\"category\":category,\"question\":question,\"explanation\":answer,\"answer\":output,\"comment\":anses[0],\"score\":score})\n        if not READ:add_object_to_json_file(ans[-1],outPath)\n        if not READ and count%50==0:\n            with open(f'{outPath}_backup.json','w') as file:\n                json.dump(ans,file,indent=4)\n        if READ and count%100==0:print(count)\n        #if count>40:break\n    global scores\n    scores+=f\"{inPath}:\\n\"\n    for cat in categories:\n        wrong,correct=categories[cat]\n        scores+=f\"{cat}: wrong={wrong}, correct={correct}, sum={wrong+correct}\\n\"\npaths=[\n       [\"inPath\",\"outPath\"],\n       ]\nREAD=0\nfor i,j in paths:\n    process(i,j,READ)\nprint(scores)"}
{"type": "source_file", "path": "eval/eval_ICL/eval_ICL_5-shot/util.py", "content": "import pprint\n\ndef last_boxed_only(sample):\n    q, a = sample\n    a = last_boxed_only_string(a)\n    if a == None:\n        return None\n    return (q, a)\n\ndef last_boxed_only_string(string):\n    idx = string.rfind(\"\\\\boxed\")\n    if idx < 0:\n        idx = string.rfind(\"\\\\fbox\")\n        if idx < 0:\n            return None\n\n    i = idx\n    right_brace_idx = None\n    num_left_braces_open = 0\n    while i < len(string):\n        if string[i] == \"{\":\n            num_left_braces_open += 1\n        if string[i] == \"}\":\n            num_left_braces_open -= 1\n            if num_left_braces_open == 0:\n                right_brace_idx = i\n                break\n        i += 1\n    \n    if right_brace_idx == None:\n        retval = None\n    else:\n        retval = string[idx:right_brace_idx + 1]\n    \n    return retval\n\ndef only_until_first_boxed_from_tokens(string, tokens):\n    idx = string.find(\"\\\\boxed\")\n    if idx < 0:\n        idx = string.find(\"\\\\fbox\")\n        if idx < 0:\n            return None\n    \n    cum_length = 0\n    for i, t in enumerate(tokens):\n        cum_length += len(t)\n        if cum_length >= idx:\n            break\n    \n    return tokens[:i]\n\n\n\ndef clean_numbers(sample):\n    if not sample:\n        return None\n    new_sample = list()\n    for s in sample:\n        new_sample.append(_clean_numbers(s))\n\n    return tuple(new_sample)\n\ndef _clean_numbers(string):\n    \"\"\"\n    Clean Numbers in the given string\n\n    >>> _clean_numbers(None, \"Hello 123\")\n    'Hello 123'\n    >>> _clean_numbers(None, \"Hello 1234\")\n    'Hello 1,234'\n    >>> _clean_numbers(None, \"Hello 1234324asdasd\")\n    'Hello 1,234,324asdasd'\n    \"\"\"\n    num_prev_digits = 0\n    new_string = \"\"\n    for i, c in enumerate(string):\n        # isdigit() doesnt work here because of weird unicode chars.\n        if c in {'1', '2', '3', '4', '5', '6', '7', '8', '9', '0'}:\n            num_prev_digits += 1\n        else:\n            if num_prev_digits > 3:\n                # Some fixing\n                string_number = new_string[-num_prev_digits:]\n                new_string = new_string[:-num_prev_digits] + \"{0:,}\".format(int(string_number))\n            num_prev_digits = 0\n        new_string += c\n\n    if num_prev_digits > 3:\n        # Some fixing\n        string_number = new_string[-num_prev_digits:]\n        new_string = new_string[:-num_prev_digits] + \"{0:,}\".format(int(string_number))\n\n    return new_string\n\ndef fix_fracs(string):\n    substrs = string.split(\"\\\\frac\")\n    new_str = substrs[0]\n    if len(substrs) > 1:\n        substrs = substrs[1:]\n        for substr in substrs:\n            new_str += \"\\\\frac\"\n            if substr[0] == \"{\":\n                new_str += substr\n            else:\n                try:\n                    assert len(substr) >= 2\n                except AssertionError:\n                    return string\n                a = substr[0]\n                b = substr[1]\n                if b != \"{\":\n                    if len(substr) > 2:\n                        post_substr = substr[2:]\n                        new_str += \"{\" + a + \"}{\" + b + \"}\" + post_substr\n                    else:\n                        new_str += \"{\" + a + \"}{\" + b + \"}\"\n                else:\n                    if len(substr) > 2:\n                        post_substr = substr[2:]\n                        new_str += \"{\" + a + \"}\" + b + post_substr\n                    else:\n                        new_str += \"{\" + a + \"}\" + b\n    string = new_str\n    return string\n\ndef fix_a_slash_b(string):\n    if len(string.split(\"/\")) != 2:\n        return string\n    a = string.split(\"/\")[0]\n    b = string.split(\"/\")[1]\n    try:\n        a = int(a)\n        b = int(b)\n        assert string == \"{}/{}\".format(a, b)\n        new_string = \"\\\\frac{\" + str(a) + \"}{\" + str(b) + \"}\"\n        return new_string\n    except AssertionError:\n        return string\n\ndef remove_right_units(string):\n    # \"\\\\text{ \" only ever occurs (at least in the val set) when describing units\n    if \"\\\\text{ \" in string:\n        splits = string.split(\"\\\\text{ \")\n        assert len(splits) == 2\n        return splits[0]\n    else:\n        return string\n\ndef fix_sqrt(string):\n    if \"\\\\sqrt\" not in string:\n        return string\n    splits = string.split(\"\\\\sqrt\")\n    new_string = splits[0]\n    for split in splits[1:]:\n        if split[0] != \"{\":\n            a = split[0]\n            new_substr = \"\\\\sqrt{\" + a + \"}\" + split[1:]\n        else:\n            new_substr = \"\\\\sqrt\" + split\n        new_string += new_substr\n    return new_string\n\n\ndef strip_string(string):\n    # linebreaks\n    string = string.replace(\"\\n\", \"\")\n\n    # remove inverse spaces\n    string = string.replace(\"\\\\!\", \"\")\n\n    # replace \\\\ with \\\n    string = string.replace(\"\\\\\\\\\", \"\\\\\")\n\n    # replace tfrac and dfrac with frac\n    string = string.replace(\"tfrac\", \"frac\")\n    string = string.replace(\"dfrac\", \"frac\")\n\n    # remove \\left and \\right\n    string = string.replace(\"\\\\left\", \"\")\n    string = string.replace(\"\\\\right\", \"\")\n\n    # Remove circ (degrees)\n    string = string.replace(\"^{\\\\circ}\", \"\")\n    string = string.replace(\"^\\\\circ\", \"\")\n\n    # remove dollar signs\n    string = string.replace(\"\\\\$\", \"\")\n\n    # remove units (on the right)\n    string = remove_right_units(string)\n\n    # remove percentage\n    string = string.replace(\"\\\\%\", \"\")\n    string = string.replace(\"\\%\", \"\")  # noqa: W605\n\n    # \" 0.\" equivalent to \" .\" and \"{0.\" equivalent to \"{.\" Alternatively, add \"0\" if \".\" is the start of the string\n    string = string.replace(\" .\", \" 0.\")\n    string = string.replace(\"{.\", \"{0.\")\n    # if empty, return empty string\n    if len(string) == 0:\n        return string\n    if string[0] == \".\":\n        string = \"0\" + string\n\n    # to consider: get rid of e.g. \"k = \" or \"q = \" at beginning\n    if len(string.split(\"=\")) == 2:\n        if len(string.split(\"=\")[0]) <= 2:\n            string = string.split(\"=\")[1]\n\n    # fix sqrt3 --> sqrt{3}\n    string = fix_sqrt(string)\n\n    # remove spaces\n    string = string.replace(\" \", \"\")\n\n    # \\frac1b or \\frac12 --> \\frac{1}{b} and \\frac{1}{2}, etc. Even works with \\frac1{72} (but not \\frac{72}1). Also does a/b --> \\\\frac{a}{b}\n    string = fix_fracs(string)\n\n    # manually change 0.5 --> \\frac{1}{2}\n    if string == \"0.5\":\n        string = \"\\\\frac{1}{2}\"\n\n    # NOTE: X/Y changed to \\frac{X}{Y} in dataset, but in simple cases fix in case the model output is X/Y\n    string = fix_a_slash_b(string)\n\n    return string\n\n\ndef is_equiv(str1, str2, verbose=False):\n    if str1 is None and str2 is None:\n        print(\"WARNING: Both None\")\n        return True\n    if str1 is None or str2 is None:\n        return False\n\n    try:\n        ss1 = strip_string(str1)\n        ss2 = strip_string(str2)\n        #pdb.set_trace()\n        if verbose:\n            print(ss1, ss2)\n        return ss1 == ss2\n    except Exception:\n        return str1 == str2\n\nclass NotEqual:\n    def __eq__(self, other):\n        return False"}
{"type": "source_file", "path": "eval/eval_ICL/eval_MATH_ICL(1shot).py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\nimport sys\nsys.path.append('/mnt/data/user/zhao_jun/MetaMath/eval')\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s):\n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('The answer is: ')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        if util.is_equiv(extract_ans, answer):\n            return True\n        else:\n            return False\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        valid_outputs.append(temp)\n    else:\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\"\n        \"Here is an example: ### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b? \\n\\n### Response: Let's think step by step. A parabola opening upwards doesn't have a maximum value for negative integer n. The answer is \\\\boxed{{\\\\text{{undefined}}}}.\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"instruction\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['output']\n            temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(temp_ans)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len invalid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_ICL/eval_GSM8K_category_ICL(1shot).py", "content": "import argparse\nimport json\nimport re\nimport jsonlines\nfrom fraction import Fraction\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n    return False\n\ndef extract_answer_number(completion):\n    text = completion.split('The answer is: ')\n    if len(text) > 1:\n        extract_ans = text[-1].strip()\n        match = re.search(r'[\\-+]?\\d*[\\.,/]?\\d+', extract_ans)\n        if match:\n            if '/' in match.group():\n                denominator = match.group().split('/')[1]\n                numerator = match.group().split('/')[0]\n                if is_number(denominator) == True and is_number(numerator) == True:\n                    if denominator == '0':\n                        return round(float(numerator.replace(',', '')))\n                    else:\n                        frac = Fraction(match.group().replace(',', ''))\n                        num_numerator = frac.numerator\n                        num_denominator = frac.denominator\n                        return round(float(num_numerator / num_denominator))\n                else:\n                    return None\n            else:\n                if float(match.group().replace(',', '')) == float('inf'):\n                    return None\n                return round(float(match.group().replace(',', '')))\n        else:\n            return None\n    else:\n        return None\n\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\n\ndef gsm8k_test(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    INVALID_ANS = \"[invalid]\"\n    gsm8k_ins = []\n    gsm8k_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path,\"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"question\"])\n            gsm8k_ins.append(temp_instr)\n            temp_ans = item['answer'].split('#### ')[1]\n            temp_ans = int(temp_ans.replace(',', ''))\n            gsm8k_answers.append(temp_ans)\n\n    gsm8k_ins = gsm8k_ins[start:end]\n    gsm8k_answers = gsm8k_answers[start:end]\n    print('lenght ====', len(gsm8k_ins))\n    batch_gsm8k_ins = batch_data(gsm8k_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0.0, top_p=1, max_tokens=512, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    result = []\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_gsm8k_ins, gsm8k_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    invalid_outputs = []\n    valid_outputs=[]\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(gsm8k_ins, res_completions, gsm8k_answers)):\n        doc = {'question': prompt}\n        y_pred = extract_answer_number(completion)\n        if y_pred != None:\n            result.append(float(y_pred) == float(prompt_answer))\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            valid_outputs.append(temp)\n        else:\n            result.append(False)\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            invalid_outputs.append(temp)\n    acc = sum(result) / len(result)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====', end)\n    print('gsm8k length====', len(result), ', gsm8k acc====', acc)\n\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str)  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = parse_args()\n    gsm8k_test(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_ICL/util.py", "content": "import pprint\n\ndef last_boxed_only(sample):\n    q, a = sample\n    a = last_boxed_only_string(a)\n    if a == None:\n        return None\n    return (q, a)\n\ndef last_boxed_only_string(string):\n    idx = string.rfind(\"\\\\boxed\")\n    if idx < 0:\n        idx = string.rfind(\"\\\\fbox\")\n        if idx < 0:\n            return None\n\n    i = idx\n    right_brace_idx = None\n    num_left_braces_open = 0\n    while i < len(string):\n        if string[i] == \"{\":\n            num_left_braces_open += 1\n        if string[i] == \"}\":\n            num_left_braces_open -= 1\n            if num_left_braces_open == 0:\n                right_brace_idx = i\n                break\n        i += 1\n    \n    if right_brace_idx == None:\n        retval = None\n    else:\n        retval = string[idx:right_brace_idx + 1]\n    \n    return retval\n\ndef only_until_first_boxed_from_tokens(string, tokens):\n    idx = string.find(\"\\\\boxed\")\n    if idx < 0:\n        idx = string.find(\"\\\\fbox\")\n        if idx < 0:\n            return None\n    \n    cum_length = 0\n    for i, t in enumerate(tokens):\n        cum_length += len(t)\n        if cum_length >= idx:\n            break\n    \n    return tokens[:i]\n\n\n\ndef clean_numbers(sample):\n    if not sample:\n        return None\n    new_sample = list()\n    for s in sample:\n        new_sample.append(_clean_numbers(s))\n\n    return tuple(new_sample)\n\ndef _clean_numbers(string):\n    \"\"\"\n    Clean Numbers in the given string\n\n    >>> _clean_numbers(None, \"Hello 123\")\n    'Hello 123'\n    >>> _clean_numbers(None, \"Hello 1234\")\n    'Hello 1,234'\n    >>> _clean_numbers(None, \"Hello 1234324asdasd\")\n    'Hello 1,234,324asdasd'\n    \"\"\"\n    num_prev_digits = 0\n    new_string = \"\"\n    for i, c in enumerate(string):\n        # isdigit() doesnt work here because of weird unicode chars.\n        if c in {'1', '2', '3', '4', '5', '6', '7', '8', '9', '0'}:\n            num_prev_digits += 1\n        else:\n            if num_prev_digits > 3:\n                # Some fixing\n                string_number = new_string[-num_prev_digits:]\n                new_string = new_string[:-num_prev_digits] + \"{0:,}\".format(int(string_number))\n            num_prev_digits = 0\n        new_string += c\n\n    if num_prev_digits > 3:\n        # Some fixing\n        string_number = new_string[-num_prev_digits:]\n        new_string = new_string[:-num_prev_digits] + \"{0:,}\".format(int(string_number))\n\n    return new_string\n\ndef fix_fracs(string):\n    substrs = string.split(\"\\\\frac\")\n    new_str = substrs[0]\n    if len(substrs) > 1:\n        substrs = substrs[1:]\n        for substr in substrs:\n            new_str += \"\\\\frac\"\n            if substr[0] == \"{\":\n                new_str += substr\n            else:\n                try:\n                    assert len(substr) >= 2\n                except AssertionError:\n                    return string\n                a = substr[0]\n                b = substr[1]\n                if b != \"{\":\n                    if len(substr) > 2:\n                        post_substr = substr[2:]\n                        new_str += \"{\" + a + \"}{\" + b + \"}\" + post_substr\n                    else:\n                        new_str += \"{\" + a + \"}{\" + b + \"}\"\n                else:\n                    if len(substr) > 2:\n                        post_substr = substr[2:]\n                        new_str += \"{\" + a + \"}\" + b + post_substr\n                    else:\n                        new_str += \"{\" + a + \"}\" + b\n    string = new_str\n    return string\n\ndef fix_a_slash_b(string):\n    if len(string.split(\"/\")) != 2:\n        return string\n    a = string.split(\"/\")[0]\n    b = string.split(\"/\")[1]\n    try:\n        a = int(a)\n        b = int(b)\n        assert string == \"{}/{}\".format(a, b)\n        new_string = \"\\\\frac{\" + str(a) + \"}{\" + str(b) + \"}\"\n        return new_string\n    except AssertionError:\n        return string\n\ndef remove_right_units(string):\n    # \"\\\\text{ \" only ever occurs (at least in the val set) when describing units\n    if \"\\\\text{ \" in string:\n        splits = string.split(\"\\\\text{ \")\n        assert len(splits) == 2\n        return splits[0]\n    else:\n        return string\n\ndef fix_sqrt(string):\n    if \"\\\\sqrt\" not in string:\n        return string\n    splits = string.split(\"\\\\sqrt\")\n    new_string = splits[0]\n    for split in splits[1:]:\n        if split[0] != \"{\":\n            a = split[0]\n            new_substr = \"\\\\sqrt{\" + a + \"}\" + split[1:]\n        else:\n            new_substr = \"\\\\sqrt\" + split\n        new_string += new_substr\n    return new_string\n\n\ndef strip_string(string):\n    # linebreaks\n    string = string.replace(\"\\n\", \"\")\n\n    # remove inverse spaces\n    string = string.replace(\"\\\\!\", \"\")\n\n    # replace \\\\ with \\\n    string = string.replace(\"\\\\\\\\\", \"\\\\\")\n\n    # replace tfrac and dfrac with frac\n    string = string.replace(\"tfrac\", \"frac\")\n    string = string.replace(\"dfrac\", \"frac\")\n\n    # remove \\left and \\right\n    string = string.replace(\"\\\\left\", \"\")\n    string = string.replace(\"\\\\right\", \"\")\n\n    # Remove circ (degrees)\n    string = string.replace(\"^{\\\\circ}\", \"\")\n    string = string.replace(\"^\\\\circ\", \"\")\n\n    # remove dollar signs\n    string = string.replace(\"\\\\$\", \"\")\n\n    # remove units (on the right)\n    string = remove_right_units(string)\n\n    # remove percentage\n    string = string.replace(\"\\\\%\", \"\")\n    string = string.replace(\"\\%\", \"\")  # noqa: W605\n\n    # \" 0.\" equivalent to \" .\" and \"{0.\" equivalent to \"{.\" Alternatively, add \"0\" if \".\" is the start of the string\n    string = string.replace(\" .\", \" 0.\")\n    string = string.replace(\"{.\", \"{0.\")\n    # if empty, return empty string\n    if len(string) == 0:\n        return string\n    if string[0] == \".\":\n        string = \"0\" + string\n\n    # to consider: get rid of e.g. \"k = \" or \"q = \" at beginning\n    if len(string.split(\"=\")) == 2:\n        if len(string.split(\"=\")[0]) <= 2:\n            string = string.split(\"=\")[1]\n\n    # fix sqrt3 --> sqrt{3}\n    string = fix_sqrt(string)\n\n    # remove spaces\n    string = string.replace(\" \", \"\")\n\n    # \\frac1b or \\frac12 --> \\frac{1}{b} and \\frac{1}{2}, etc. Even works with \\frac1{72} (but not \\frac{72}1). Also does a/b --> \\\\frac{a}{b}\n    string = fix_fracs(string)\n\n    # manually change 0.5 --> \\frac{1}{2}\n    if string == \"0.5\":\n        string = \"\\\\frac{1}{2}\"\n\n    # NOTE: X/Y changed to \\frac{X}{Y} in dataset, but in simple cases fix in case the model output is X/Y\n    string = fix_a_slash_b(string)\n\n    return string\n\n\ndef is_equiv(str1, str2, verbose=False):\n    if str1 is None and str2 is None:\n        print(\"WARNING: Both None\")\n        return True\n    if str1 is None or str2 is None:\n        return False\n\n    try:\n        ss1 = strip_string(str1)\n        ss2 = strip_string(str2)\n        #pdb.set_trace()\n        if verbose:\n            print(ss1, ss2)\n        return ss1 == ss2\n    except Exception:\n        return str1 == str2\n\nclass NotEqual:\n    def __eq__(self, other):\n        return False"}
{"type": "source_file", "path": "eval/eval_ICL/eval_MATH_category2_ICL(1shot).py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s):\n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer,category,category_stats):\n    split_ans = completion.split('The answer is: ')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        if util.is_equiv(extract_ans, answer):\n            category_stats[category] = category_stats.get(category, {'correct': 0, 'wrong': 0})\n            category_stats[category]['correct'] += 1\n            return True\n        else:\n            category_stats[category] = category_stats.get(category, {'correct': 0, 'wrong': 0})\n            category_stats[category]['wrong'] += 1\n            return False\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        valid_outputs.append(temp)\n    else:\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    category_stats = {}\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\"\n        \"Here is an example: ### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b? \\n\\n### Response: Let's think step by step. A parabola opening upwards doesn't have a maximum value for negative integer n. The answer is \\\\boxed{{\\\\text{{undefined}}}}.\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    categories = []  # 初始化类别列表\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            categories.append(item[\"category\"])  # 添加当前题目的类别到列表\n            temp_instr = problem_prompt.format(instruction=item[\"question\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['answer']\n            temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(temp_ans)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer,category) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers, categories)):\n        res = process_results(prompt, completion, prompt_answer, category,category_stats)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\n    total_correct = 0\n    total_questions = 0\n    for category, stats in category_stats.items():\n        cat_correct = stats['correct']\n        cat_total = stats['correct'] + stats['wrong']\n        cat_accuracy = cat_correct / cat_total\n        print(f\"Category {category}: correct:{cat_correct}, total:{cat_total}, {cat_correct}/{cat_total} correct, Accuracy: {cat_accuracy*100:.2f}%\")\n        total_correct += cat_correct\n        total_questions += cat_total\n\n    overall_accuracy = total_correct / total_questions\n    print(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_ICL/eval_GSM8K_ICL(1shot).py", "content": "import argparse\nimport json\nimport re\nimport jsonlines\nfrom fraction import Fraction\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n    return False\n\ndef extract_answer_number(completion):\n    text = completion.split('The answer is: ')\n    if len(text) > 1:\n        extract_ans = text[-1].strip()\n        match = re.search(r'[\\-+]?\\d*[\\.,/]?\\d+', extract_ans)\n        if match:\n            if '/' in match.group():\n                denominator = match.group().split('/')[1]\n                numerator = match.group().split('/')[0]\n                if is_number(denominator) == True and is_number(numerator) == True:\n                    if denominator == '0':\n                        return round(float(numerator.replace(',', '')))\n                    else:\n                        frac = Fraction(match.group().replace(',', ''))\n                        num_numerator = frac.numerator\n                        num_denominator = frac.denominator\n                        return round(float(num_numerator / num_denominator))\n                else:\n                    return None\n            else:\n                if float(match.group().replace(',', '')) == float('inf'):\n                    return None\n                return round(float(match.group().replace(',', '')))\n        else:\n            return None\n    else:\n        return None\n\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\n\ndef gsm8k_test(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    INVALID_ANS = \"[invalid]\"\n    gsm8k_ins = []\n    gsm8k_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\"\n        \"Here is an example: ### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b? \\n\\n### Response: Let's think step by step. A parabola opening upwards doesn't have a maximum value for negative integer n. The answer is \\\\boxed{{\\\\text{{undefined}}}}.\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path,\"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            gsm8k_ins.append(temp_instr)\n            temp_ans = item['response'].split('#### ')[1]\n            temp_ans = int(temp_ans.replace(',', ''))\n            gsm8k_answers.append(temp_ans)\n\n    gsm8k_ins = gsm8k_ins[start:end]\n    gsm8k_answers = gsm8k_answers[start:end]\n    print('lenght ====', len(gsm8k_ins))\n    batch_gsm8k_ins = batch_data(gsm8k_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0.0, top_p=1, max_tokens=512, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    result = []\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_gsm8k_ins, gsm8k_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    invalid_outputs = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(gsm8k_ins, res_completions, gsm8k_answers)):\n        doc = {'question': prompt}\n        y_pred = extract_answer_number(completion)\n        if y_pred != None:\n            result.append(float(y_pred) == float(prompt_answer))\n        else:\n            result.append(False)\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            invalid_outputs.append(temp)\n    acc = sum(result) / len(result)\n    print('len invalid outputs ====', len(invalid_outputs), ', valid_outputs===', invalid_outputs)\n    print('start===', start, ', end====', end)\n    print('gsm8k length====', len(result), ', gsm8k acc====', acc)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str)  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = parse_args()\n    gsm8k_test(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_ICL/eval_ICL_5-shot/eval_math_error_ICL(5shot).py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\nimport sys\nsys.path.append('/mnt/data/user/zhao_jun/MetaMath/eval')\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s): \n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('answer is')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        temp={'question': doc, 'output': completion, 'gold_answer': answer,'Model_answer':extract_ans}\n        valid_outputs.append(temp)\n        if util.is_equiv(extract_ans, answer):\n            return True\n        else:\n            return False\n    else:\n        temp = {'question': doc, 'output': completion, 'gold_answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b?\\n### Response: Let's think step by step. Given the equation $5r^2 + br - 12$ and the constraint that $r$ is a negative integer, we are asked to find the maximum value of the expression and equate it to 36 to solve for $b$.\\n\\nLet's first understand the structure of our equation. It is a quadratic equation of the form $ax^2 + bx + c$. The graph of a quadratic equation is a parabola. The direction of the parabola (whether it opens upwards or downwards) is determined by the sign of the coefficient of $r^2$ (which is equivalent to $a$ in our standard form). \\n\\nSince the coefficient of $r^2$ is 5, which is positive, our parabola opens upwards.\\n\\nBut here's where we run into a problem. A parabola that opens upwards does not have a maximum value, it has a minimum value. This is because as $r$ moves either positively or negatively away from the vertex (the peak or trough of the parabola), the value of the expression $5r^2 + br - 12$ increases.\\n\\nFurthermore, the constraint that $r$ is a negative integer doesn't affect this conclusion. Regardless of whether $r$ is positive or negative, a parabola that opens upwards does not have a maximum value.\\n\\nTherefore, it is impossible to equate the maximum value of the expression to 36 as the problem initially asks, and we cannot solve for $b$ under these conditions. The question has posed an unsolvable scenario.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nHow many prime numbers can be divided by 39?\\n### Response: Let's think step by step. No prime numbers can be divided by 39. By definition, a prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. Since 39 is composed of the factors 3 and 13 (both of which are prime numbers themselves), any number that can be divided by 39 cannot be a prime number, as it would have to at least include 3 and 13 as factors besides 1 and itself.\\nTherefore, there are \\\\boxed{{0}} prime numbers that can be divided by 39. The answer is: 0\\n\"\n        \"### Instruction:\\nIf odd integers $x y$ satisfies $\\\\\\\\frac{{1}}{{2}}-\\\\\\\\frac{{1}}{{3}}=\\\\\\\\frac{{x}}{{y}}$, then what is the value of $x$?\\n### Response: Let's think step by step. To solve this problem, we must first simplify the left-hand side of the equation, $\\\\frac{{1}}{{2}}-\\\\frac{{1}}{{3}}$. This simplifies to $\\\\frac{{1}}{{6}}$. So the equation becomes $\\\\frac{{1}}{{6}}=\\\\frac{{x}}{{y}}$.\\n\\nWe can cross multiply to get $x = \\\\frac{{1}}{{6}}y$. \\n\\nThe problem arises from the requirement that both $x$ and $y$ be odd integers. If we multiply an odd number $y$ by $\\\\frac{{1}}{{6}}$, we would not yield an odd integer for $x$. This is because a fraction of an odd integer doesn't result in an integer, let alone an odd integer.\\n\\nFurthermore, to produce $\\\\frac{{1}}{{6}}$, $y$ would have to be a multiple of 6, which means $y$ would be even. This contradicts the original stipulation that $y$ should be an odd integer.\\n\\nTherefore, under the given conditions, there is no solution to this problem. The constraints on $x$ and $y$ being odd integers and the equation $\\\\frac{{1}}{{2}}-\\\\frac{{1}}{{3}}=\\\\frac{{x}}{{y}}$ cannot hold true simultaneously.\\nThe problem is unsolvable.\\n\"\n        \"### Instruction:\\nIf a triangle has two sides of lengths 5 and 7 units, then how many different integer lengths can the third side be?\\n### Response: Let's think step by step. Let the two given sides be $a$ and $b$.\\nFor a triangle to be formed, the third side must satisfy the triangle inequality, which states that the sum of the lengths of any two sides of a triangle must be greater than the length of the remaining side.\\nSo for the third side, we have the inequalities $|a-b| < c < a+b$.\\nIn this case, $a=5$ and $b=7$, so the inequalities become $|5-7| < c < 5+7$, which simplify to $2 < c < 12$.\\nSince $c$ must be an integer, the possible integer lengths for the third side are 3, 4, 5, 6, 7, 8, 9, 10, and 11.\\nTherefore, there are $\\\\boxed{{9}}$ different integer lengths the third side can be.\\nThe answer is: 9\\n\"\n        \"### Instruction:\\nFind p if the focus of the parabola $x + x^2 = -\\\\\\\\frac{{p}}{{12}} y^2.$ is (-1/2,1).\\n### Response: Let's think step by step. To begin solving this problem, we first need to express the equation in the standard form of a parabola. The standard forms are either $y^2 = 4ax$ or $x^2 = 4ay$ where (a,0) is the focus for the first case, and (0,a) is the focus for the second case. Let's try to manipulate the given equation into one of these forms.\\n\\nThe given equation is $x+x^2=-\\\\frac{{p}}{{12}}y^2$. Rearranging this equation, we have $x^2 + x + \\\\frac{{p}}{{12}}y^2 = 0$.\\n\\nThis equation does not align with the standard form of a parabola equation. The standard form of the equation of a parabola should only have the square of one variable, either $x$ or $y$. However, in our equation, $x$ is squared, and there is also a term involving $y^2$.\\n\\nTherefore, we can't express the equation in the standard form of a parabola, which indicates that the equation does not represent a parabola. Consequently, we cannot find a focus for a parabola because the given equation does not describe a parabola. The initial assumption that we are dealing with a parabola is incorrect.\\nThe problem is unsolvable.\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    # problem_prompt = (\n    #     \"Below is an instruction that describes a task. \"\n    #     \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\nThe problem is unsolvable.\\n\"\n    #     \"### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b?\\n### Response: Let's think step by step. Given the equation $5r^2 + br - 12$ and the constraint that $r$ is a negative integer, we are asked to find the maximum value of the expression and equate it to 36 to solve for $b$.\\n\\nLet's first understand the structure of our equation. It is a quadratic equation of the form $ax^2 + bx + c$. The graph of a quadratic equation is a parabola. The direction of the parabola (whether it opens upwards or downwards) is determined by the sign of the coefficient of $r^2$ (which is equivalent to $a$ in our standard form). \\n\\nSince the coefficient of $r^2$ is 5, which is positive, our parabola opens upwards.\\n\\nBut here's where we run into a problem. A parabola that opens upwards does not have a maximum value, it has a minimum value. This is because as $r$ moves either positively or negatively away from the vertex (the peak or trough of the parabola), the value of the expression $5r^2 + br - 12$ increases.\\n\\nFurthermore, the constraint that $r$ is a negative integer doesn't affect this conclusion. Regardless of whether $r$ is positive or negative, a parabola that opens upwards does not have a maximum value.\\n\\nTherefore, it is impossible to equate the maximum value of the expression to 36 as the problem initially asks, and we cannot solve for $b$ under these conditions. The question has posed an unsolvable scenario.\\nThe problem is unsolvable.\\n\"\n    #     \"### Instruction:\\nHow many prime numbers can be divided by 39?\\n### Response: Let's think step by step. No prime numbers can be divided by 39. By definition, a prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. Since 39 is composed of the factors 3 and 13 (both of which are prime numbers themselves), any number that can be divided by 39 cannot be a prime number, as it would have to at least include 3 and 13 as factors besides 1 and itself.\\nTherefore, there are \\\\boxed{0} prime numbers that can be divided by 39. The answer is: 0\\n\"\n    #     \"### Instruction:\\n12 balls numbered 1 through 12 are placed in a bin.  In how many ways can 3 balls be drawn, in order, from the bin, if each ball remains outside the bin after it is drawn?\\n### Response: Let's think step by step. There are 12 choices for the first ball, 11 choices for the second ball, and 10 choices for the third ball.\\nSo there are a total of $12 \\\\cdot 11 \\\\cdot 10 = \\\\boxed{1320}$ ways to draw the balls.\\nThe answer is: 1320\\n\"\n    #     \"### Instruction:\\nIn a shop, there is a sale of clothes. Every shirt costs $5, every hat $4, and a pair of jeans $10. How much do you need to pay for three shirts, two pairs of jeans, and four hats?\\n### Response: Let's think step by step. Three shirts cost 3 * $5 = $15.\\nTwo pairs of jeans cost 2 * $10 = $20.\\nFour hats cost 4 * $4 = $16.\\nTherefore, you need to pay $15 + $20 + $16 = $51.\\n#### 51\\nThe answer is: 51.\"\n    #     \"### Instruction:\\nIf a triangle has two sides of lengths 5 and 7 units, then how many different integer lengths can the third side be?\\n### Response: Let's think step by step. Let the two given sides be $a$ and $b$.\\nFor a triangle to be formed, the third side must satisfy the triangle inequality, which states that the sum of the lengths of any two sides of a triangle must be greater than the length of the remaining side.\\nSo for the third side, we have the inequalities $|a-b| < c < a+b$.\\nIn this case, $a=5$ and $b=7$, so the inequalities become $|5-7| < c < 5+7$, which simplify to $2 < c < 12$.\\nSince $c$ must be an integer, the possible integer lengths for the third side are 3, 4, 5, 6, 7, 8, 9, 10, and 11.\\nTherefore, there are $\\\\boxed{9}$ different integer lengths the third side can be.\\nThe answer is: 9\\n\"\n    #     \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    # )\n#     problem_prompt = (\n# \"Below is an instruction that describes a task. \"\n# \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\nThe problem is unsolvable.\\n\"\n# \"### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b?\\n### Response: Let's think step by step. Given the equation $5r^2 + br - 12$ and the constraint that $r$ is a negative integer, we are asked to find the maximum value of the expression and equate it to 36 to solve for $b$.\\n\\nLet's first understand the structure of our equation. It is a quadratic equation of the form $ax^2 + bx + c$. The graph of a quadratic equation is a parabola. The direction of the parabola (whether it opens upwards or downwards) is determined by the sign of the coefficient of $r^2$ (which is equivalent to $a$ in our standard form). \\n\\nSince the coefficient of $r^2$ is 5, which is positive, our parabola opens upwards.\\n\\nBut here's where we run into a problem. A parabola that opens upwards does not have a maximum value, it has a minimum value. This is because as $r$ moves either positively or negatively away from the vertex (the peak or trough of the parabola), the value of the expression $5r^2 + br - 12$ increases.\\n\\nFurthermore, the constraint that $r$ is a negative integer doesn't affect this conclusion. Regardless of whether $r$ is positive or negative, a parabola that opens upwards does not have a maximum value.\\n\\nTherefore, it is impossible to equate the maximum value of the expression to 36 as the problem initially asks, and we cannot solve for $b$ under these conditions. The question has posed an unsolvable scenario.\\nThe problem is unsolvable.\\n\"\n# \"### Instruction:\\nIf odd integers $x y$ satisfies $\\frac{1}{2}-\\frac{1}{3}=\\frac{x}{y}$, then what is the value of $x$?\\n### Response: Let's think step by step. To solve this problem, we must first simplify the left-hand side of the equation, $\\frac{1}{2}-\\frac{1}{3}$. This simplifies to $\\frac{1}{6}$. So the equation becomes $\\frac{1}{6}=\\frac{x}{y}$.\\n\\nWe can cross multiply to get $x = \\frac{1}{6}y$. \\n\\nThe problem arises from the requirement that both $x$ and $y$ be odd integers. If we multiply an odd number $y$ by $\\frac{1}{6}$, we would not yield an odd integer for $x$. This is because a fraction of an odd integer doesn't result in an integer, let alone an odd integer.\\n\\nFurthermore, to produce $\\frac{1}{6}$, $y$ would have to be a multiple of 6, which means $y$ would be even. This contradicts the original stipulation that $y$ should be an odd integer.\\n\\nTherefore, under the given conditions, there is no solution to this problem. The constraints on $x$ and $y$ being odd integers and the equation $\\frac{1}{2}-\\frac{1}{3}=\\frac{x}{y}$ cannot hold true simultaneously.\\nThe problem is unsolvable.\\n\"\n# \"### Instruction:\\nIf a triangle has two sides of lengths 5 and 7 units, then how many different integer lengths can the third side be?\\n### Response: Let's think step by step. Let the two given sides be $a$ and $b$.\\nFor a triangle to be formed, the third side must satisfy the triangle inequality, which states that the sum of the lengths of any two sides of a triangle must be greater than the length of the remaining side.\\nSo for the third side, we have the inequalities $|a-b| < c < a+b$.\\nIn this case, $a=5$ and $b=7$, so the inequalities become $|5-7| < c < 5+7$, which simplify to $2 < c < 12$.\\nSince $c$ must be an integer, the possible integer lengths for the third side are 3, 4, 5, 6, 7, 8, 9, 10, and 11.\\nTherefore, there are $\\boxed{9}$ different integer lengths the third side can be.\\nThe answer is: 9\\n\"\n# \"### Instruction:\\nFind p if the focus of the parabola $x + x^2 = -\\frac{p}{12} y^2.$ is (-1/2,1).\\n### Response: Let's think step by step. To begin solving this problem, we first need to express the equation in the standard form of a parabola. The standard forms are either $y^2 = 4ax$ or $x^2 = 4ay$ where (a,0) is the focus for the first case, and (0,a) is the focus for the second case. Let's try to manipulate the given equation into one of these forms.\\n\\nThe given equation is $x+x^2=-\\frac{p}{12}y^2$. Rearranging this equation, we have $x^2 + x + \\frac{p}{12}y^2 = 0$.\\n\\nThis equation does not align with the standard form of a parabola equation. The standard form of the equation of a parabola should only have the square of one variable, either $x$ or $y$. However, in our equation, $x$ is squared, and there is also a term involving $y^2$.\\n\\nTherefore, we can't express the equation in the standard form of a parabola, which indicates that the equation does not represent a parabola. Consequently, we cannot find a focus for a parabola because the given equation does not describe a parabola. The initial assumption that we are dealing with a parabola is incorrect.\\nThe problem is unsolvable.\"\n# \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n# )\n\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['response']\n#在这里保留所有完整答案\n #           temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(solution)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print()\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_ICL/eval_math_error_ICL(1shot).py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\nimport sys\nsys.path.append('/mnt/data/user/zhao_jun/MetaMath/eval')\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s): \n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('answer is')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        temp={'question': doc, 'output': completion, 'gold_answer': answer,'Model_answer':extract_ans}\n        valid_outputs.append(temp)\n        if util.is_equiv(extract_ans, answer):\n            return True\n        else:\n            return False\n    else:\n        temp = {'question': doc, 'output': completion, 'gold_answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\"\n        \"Here is an example: ### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b? \\n\\n### Response: Let's think step by step. A parabola opening upwards doesn't have a maximum value for negative integer n. The answer is \\\\boxed{{\\\\text{{undefined}}}}.\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['response']\n#在这里保留所有完整答案\n #           temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(solution)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print()\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_MATH_category2.py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s):\n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer,category,category_stats):\n    split_ans = completion.split('The answer is: ')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        if util.is_equiv(extract_ans, answer):\n            category_stats[category] = category_stats.get(category, {'correct': 0, 'wrong': 0})\n            category_stats[category]['correct'] += 1\n            return True\n        else:\n            category_stats[category] = category_stats.get(category, {'correct': 0, 'wrong': 0})\n            category_stats[category]['wrong'] += 1\n            return False\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        valid_outputs.append(temp)\n    else:\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    category_stats = {}\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    categories = []  # 初始化类别列表\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            categories.append(item[\"category\"])  # 添加当前题目的类别到列表\n            temp_instr = problem_prompt.format(instruction=item[\"question\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['answer']\n            temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(temp_ans)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer,category) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers, categories)):\n        res = process_results(prompt, completion, prompt_answer, category,category_stats)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\n    total_correct = 0\n    total_questions = 0\n    for category, stats in category_stats.items():\n        cat_correct = stats['correct']\n        cat_total = stats['correct'] + stats['wrong']\n        cat_accuracy = cat_correct / cat_total\n        print(f\"Category {category}: correct:{cat_correct}, total:{cat_total}, {cat_correct}/{cat_total} correct, Accuracy: {cat_accuracy*100:.2f}%\")\n        total_correct += cat_correct\n        total_questions += cat_total\n\n    overall_accuracy = total_correct / total_questions\n    print(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_True_False.py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s): \n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('answer is')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        temp={'question': doc, 'output': completion, 'gold_answer': answer,'Model_answer':extract_ans}\n        valid_outputs.append(temp)\n        if util.is_equiv(extract_ans, answer):\n            return True\n        else:\n            return False\n    else:\n        temp = {'question': doc, 'output': completion, 'gold_answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\"\n        \"The following is a true or false question, please provide a conclusion of either True or False after analysis.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['response']\n           # temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(solution)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print()\n    print('len valid outputs ====', len(valid_outputs),', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_new_prompt/eval_math.py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\ndef remove_boxed(s):\n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('The answer is: ')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        if util.is_equiv(extract_ans, answer):\n            return True\n        else:\n            return False\n    else:\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"instruction\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['output']\n            temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(temp_ans)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', valid_outputs===', invalid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_new_prompt/eval_MATH_category2_hint.py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s):\n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer,category,category_stats):\n    split_ans = completion.split('The answer is: ')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        if util.is_equiv(extract_ans, answer):\n            category_stats[category] = category_stats.get(category, {'correct': 0, 'wrong': 0})\n            category_stats[category]['correct'] += 1\n            return True\n        else:\n            category_stats[category] = category_stats.get(category, {'correct': 0, 'wrong': 0})\n            category_stats[category]['wrong'] += 1\n            return False\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        valid_outputs.append(temp)\n    else:\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    category_stats = {}\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    categories = []  # 初始化类别列表\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            categories.append(item[\"category\"])  # 添加当前题目的类别到列表\n            temp_instr = problem_prompt.format(instruction=item[\"question\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['answer']\n            temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(temp_ans)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer,category) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers, categories)):\n        res = process_results(prompt, completion, prompt_answer, category,category_stats)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\n    total_correct = 0\n    total_questions = 0\n    for category, stats in category_stats.items():\n        cat_correct = stats['correct']\n        cat_total = stats['correct'] + stats['wrong']\n        cat_accuracy = cat_correct / cat_total\n        print(f\"Category {category}: correct:{cat_correct}, total:{cat_total}, {cat_correct}/{cat_total} correct, Accuracy: {cat_accuracy*100:.2f}%\")\n        total_correct += cat_correct\n        total_questions += cat_total\n\n    overall_accuracy = total_correct / total_questions\n    print(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_math_error.py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s): \n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('The answer is:')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        temp={'question': doc, 'output': completion, 'gold_answer': answer,'Model_answer':extract_ans}\n        valid_outputs.append(temp)\n        if util.is_equiv(extract_ans, \"undefined\"):\n            return True\n        else:\n            return False\n    else:\n        temp = {'question': doc, 'output': completion, 'gold_answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['response']\n           # temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(solution)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print()\n    print(', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_new_prompt/eval_GSM8K_category_hint.py", "content": "import argparse\nimport json\nimport re\nimport jsonlines\nfrom fraction import Fraction\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n    return False\n\ndef extract_answer_number(completion):\n    text = completion.split('The answer is: ')\n    if len(text) > 1:\n        extract_ans = text[-1].strip()\n        match = re.search(r'[\\-+]?\\d*[\\.,/]?\\d+', extract_ans)\n        if match:\n            if '/' in match.group():\n                denominator = match.group().split('/')[1]\n                numerator = match.group().split('/')[0]\n                if is_number(denominator) == True and is_number(numerator) == True:\n                    if denominator == '0':\n                        return round(float(numerator.replace(',', '')))\n                    else:\n                        frac = Fraction(match.group().replace(',', ''))\n                        num_numerator = frac.numerator\n                        num_denominator = frac.denominator\n                        return round(float(num_numerator / num_denominator))\n                else:\n                    return None\n            else:\n                if float(match.group().replace(',', '')) == float('inf'):\n                    return None\n                return round(float(match.group().replace(',', '')))\n        else:\n            return None\n    else:\n        return None\n\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\n\ndef gsm8k_test(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    INVALID_ANS = \"[invalid]\"\n    gsm8k_ins = []\n    gsm8k_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path,\"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"question\"])\n            gsm8k_ins.append(temp_instr)\n            temp_ans = item['answer'].split('#### ')[1]\n            temp_ans = int(temp_ans.replace(',', ''))\n            gsm8k_answers.append(temp_ans)\n\n    gsm8k_ins = gsm8k_ins[start:end]\n    gsm8k_answers = gsm8k_answers[start:end]\n    print('lenght ====', len(gsm8k_ins))\n    batch_gsm8k_ins = batch_data(gsm8k_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0.0, top_p=1, max_tokens=512, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    result = []\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_gsm8k_ins, gsm8k_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    invalid_outputs = []\n    valid_outputs=[]\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(gsm8k_ins, res_completions, gsm8k_answers)):\n        doc = {'question': prompt}\n        y_pred = extract_answer_number(completion)\n        if y_pred != None:\n            result.append(float(y_pred) == float(prompt_answer))\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            valid_outputs.append(temp)\n        else:\n            result.append(False)\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            invalid_outputs.append(temp)\n    acc = sum(result) / len(result)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print('len valid outputs ====', len(valid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====', end)\n    print('gsm8k length====', len(result), ', gsm8k acc====', acc)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str)  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = parse_args()\n    gsm8k_test(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_gsm8k.py", "content": "import argparse\nimport json\nimport re\nimport jsonlines\nfrom fraction import Fraction\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n    return False\n\ndef extract_answer_number(completion):\n    text = completion.split('The answer is: ')\n    if len(text) > 1:\n        extract_ans = text[-1].strip()\n        match = re.search(r'[\\-+]?\\d*[\\.,/]?\\d+', extract_ans)\n        if match:\n            if '/' in match.group():\n                denominator = match.group().split('/')[1]\n                numerator = match.group().split('/')[0]\n                if is_number(denominator) == True and is_number(numerator) == True:\n                    if denominator == '0':\n                        return round(float(numerator.replace(',', '')))\n                    else:\n                        frac = Fraction(match.group().replace(',', ''))\n                        num_numerator = frac.numerator\n                        num_denominator = frac.denominator\n                        return round(float(num_numerator / num_denominator))\n                else:\n                    return None\n            else:\n                if float(match.group().replace(',', '')) == float('inf'):\n                    return None\n                return round(float(match.group().replace(',', '')))\n        else:\n            return None\n    else:\n        return None\n\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\n\ndef gsm8k_test(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    INVALID_ANS = \"[invalid]\"\n    gsm8k_ins = []\n    gsm8k_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path,\"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            gsm8k_ins.append(temp_instr)\n            temp_ans = item['response'].split('#### ')[1]\n            temp_ans = int(temp_ans.replace(',', ''))\n            gsm8k_answers.append(temp_ans)\n\n    gsm8k_ins = gsm8k_ins[start:end]\n    gsm8k_answers = gsm8k_answers[start:end]\n    print('lenght ====', len(gsm8k_ins))\n    batch_gsm8k_ins = batch_data(gsm8k_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0.0, top_p=1, max_tokens=512, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    result = []\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_gsm8k_ins, gsm8k_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    invalid_outputs = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(gsm8k_ins, res_completions, gsm8k_answers)):\n        doc = {'question': prompt}\n        y_pred = extract_answer_number(completion)\n        if y_pred != None:\n            result.append(float(y_pred) == float(prompt_answer))\n        else:\n            result.append(False)\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            invalid_outputs.append(temp)\n    acc = sum(result) / len(result)\n    print('len invalid outputs ====', len(invalid_outputs), ', valid_outputs===', invalid_outputs)\n    print('start===', start, ', end====', end)\n    print('gsm8k length====', len(result), ', gsm8k acc====', acc)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str)  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = parse_args()\n    gsm8k_test(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_new_prompt/eval_math_error_hint.py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s): \n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('answer is')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        temp={'question': doc, 'output': completion, 'gold_answer': answer,'Model_answer':extract_ans}\n        valid_outputs.append(temp)\n        if util.is_equiv(extract_ans, answer):\n            return True\n        else:\n            return False\n    else:\n        temp = {'question': doc, 'output': completion, 'gold_answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['response']\n#在这里保留所有完整答案\n #           temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(solution)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print()\n    print('len valid outputs ====', len(valid_outputs),', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_new_prompt/eval_math_error.py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\nvalid_outputs = []\ndef remove_boxed(s): \n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('answer is')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        temp={'question': doc, 'output': completion, 'gold_answer': answer,'Model_answer':extract_ans}\n        valid_outputs.append(temp)\n        if util.is_equiv(extract_ans, answer):\n            return True\n        else:\n            return False\n    else:\n        temp = {'question': doc, 'output': completion, 'gold_answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\"\n        \"Here is an example: ### Instruction:\\nIf $r$ is a negative integer, and the maximum value of the expression $5r^2 + br - 12$ is 36, what's the value of b? \\n\\n### Response: Let's think step by step. A parabola opening upwards doesn't have a maximum value for negative integer n. The answer is \\\\boxed{\\\\text{undefined}}.\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['response']\n#在这里保留所有完整答案\n #           temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(solution)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', invalid_outputs===', invalid_outputs)\n    print()\n    print('len invalid outputs ====', len(invalid_outputs), ', valid_outputs===', valid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_new_prompt/eval_gsm8k.py", "content": "import argparse\nimport json\nimport re\nimport jsonlines\nfrom fraction import Fraction\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n    return False\n\ndef extract_answer_number(completion):\n    text = completion.split('The answer is: ')\n    if len(text) > 1:\n        extract_ans = text[-1].strip()\n        match = re.search(r'[\\-+]?\\d*[\\.,/]?\\d+', extract_ans)\n        if match:\n            if '/' in match.group():\n                denominator = match.group().split('/')[1]\n                numerator = match.group().split('/')[0]\n                if is_number(denominator) == True and is_number(numerator) == True:\n                    if denominator == '0':\n                        return round(float(numerator.replace(',', '')))\n                    else:\n                        frac = Fraction(match.group().replace(',', ''))\n                        num_numerator = frac.numerator\n                        num_denominator = frac.denominator\n                        return round(float(num_numerator / num_denominator))\n                else:\n                    return None\n            else:\n                if float(match.group().replace(',', '')) == float('inf'):\n                    return None\n                return round(float(match.group().replace(',', '')))\n        else:\n            return None\n    else:\n        return None\n\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\n\ndef gsm8k_test(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    INVALID_ANS = \"[invalid]\"\n    gsm8k_ins = []\n    gsm8k_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\nPlease solve the following problem. Note that this problem may be unsolvable or has no solution.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path,\"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"query\"])\n            gsm8k_ins.append(temp_instr)\n            temp_ans = item['response'].split('#### ')[1]\n            temp_ans = int(temp_ans.replace(',', ''))\n            gsm8k_answers.append(temp_ans)\n\n    gsm8k_ins = gsm8k_ins[start:end]\n    gsm8k_answers = gsm8k_answers[start:end]\n    print('lenght ====', len(gsm8k_ins))\n    batch_gsm8k_ins = batch_data(gsm8k_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0.0, top_p=1, max_tokens=512, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    result = []\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_gsm8k_ins, gsm8k_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    invalid_outputs = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(gsm8k_ins, res_completions, gsm8k_answers)):\n        doc = {'question': prompt}\n        y_pred = extract_answer_number(completion)\n        if y_pred != None:\n            result.append(float(y_pred) == float(prompt_answer))\n        else:\n            result.append(False)\n            temp = {'question': prompt, 'output': completion, 'answer': prompt_answer}\n            invalid_outputs.append(temp)\n    acc = sum(result) / len(result)\n    print('len invalid outputs ====', len(invalid_outputs), ', valid_outputs===', invalid_outputs)\n    print('start===', start, ', end====', end)\n    print('gsm8k length====', len(result), ', gsm8k acc====', acc)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str)  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = parse_args()\n    gsm8k_test(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "eval/eval_new_prompt/util.py", "content": "import pprint\n\ndef last_boxed_only(sample):\n    q, a = sample\n    a = last_boxed_only_string(a)\n    if a == None:\n        return None\n    return (q, a)\n\ndef last_boxed_only_string(string):\n    idx = string.rfind(\"\\\\boxed\")\n    if idx < 0:\n        idx = string.rfind(\"\\\\fbox\")\n        if idx < 0:\n            return None\n\n    i = idx\n    right_brace_idx = None\n    num_left_braces_open = 0\n    while i < len(string):\n        if string[i] == \"{\":\n            num_left_braces_open += 1\n        if string[i] == \"}\":\n            num_left_braces_open -= 1\n            if num_left_braces_open == 0:\n                right_brace_idx = i\n                break\n        i += 1\n    \n    if right_brace_idx == None:\n        retval = None\n    else:\n        retval = string[idx:right_brace_idx + 1]\n    \n    return retval\n\ndef only_until_first_boxed_from_tokens(string, tokens):\n    idx = string.find(\"\\\\boxed\")\n    if idx < 0:\n        idx = string.find(\"\\\\fbox\")\n        if idx < 0:\n            return None\n    \n    cum_length = 0\n    for i, t in enumerate(tokens):\n        cum_length += len(t)\n        if cum_length >= idx:\n            break\n    \n    return tokens[:i]\n\n\n\ndef clean_numbers(sample):\n    if not sample:\n        return None\n    new_sample = list()\n    for s in sample:\n        new_sample.append(_clean_numbers(s))\n\n    return tuple(new_sample)\n\ndef _clean_numbers(string):\n    \"\"\"\n    Clean Numbers in the given string\n\n    >>> _clean_numbers(None, \"Hello 123\")\n    'Hello 123'\n    >>> _clean_numbers(None, \"Hello 1234\")\n    'Hello 1,234'\n    >>> _clean_numbers(None, \"Hello 1234324asdasd\")\n    'Hello 1,234,324asdasd'\n    \"\"\"\n    num_prev_digits = 0\n    new_string = \"\"\n    for i, c in enumerate(string):\n        # isdigit() doesnt work here because of weird unicode chars.\n        if c in {'1', '2', '3', '4', '5', '6', '7', '8', '9', '0'}:\n            num_prev_digits += 1\n        else:\n            if num_prev_digits > 3:\n                # Some fixing\n                string_number = new_string[-num_prev_digits:]\n                new_string = new_string[:-num_prev_digits] + \"{0:,}\".format(int(string_number))\n            num_prev_digits = 0\n        new_string += c\n\n    if num_prev_digits > 3:\n        # Some fixing\n        string_number = new_string[-num_prev_digits:]\n        new_string = new_string[:-num_prev_digits] + \"{0:,}\".format(int(string_number))\n\n    return new_string\n\ndef fix_fracs(string):\n    substrs = string.split(\"\\\\frac\")\n    new_str = substrs[0]\n    if len(substrs) > 1:\n        substrs = substrs[1:]\n        for substr in substrs:\n            new_str += \"\\\\frac\"\n            if substr[0] == \"{\":\n                new_str += substr\n            else:\n                try:\n                    assert len(substr) >= 2\n                except AssertionError:\n                    return string\n                a = substr[0]\n                b = substr[1]\n                if b != \"{\":\n                    if len(substr) > 2:\n                        post_substr = substr[2:]\n                        new_str += \"{\" + a + \"}{\" + b + \"}\" + post_substr\n                    else:\n                        new_str += \"{\" + a + \"}{\" + b + \"}\"\n                else:\n                    if len(substr) > 2:\n                        post_substr = substr[2:]\n                        new_str += \"{\" + a + \"}\" + b + post_substr\n                    else:\n                        new_str += \"{\" + a + \"}\" + b\n    string = new_str\n    return string\n\ndef fix_a_slash_b(string):\n    if len(string.split(\"/\")) != 2:\n        return string\n    a = string.split(\"/\")[0]\n    b = string.split(\"/\")[1]\n    try:\n        a = int(a)\n        b = int(b)\n        assert string == \"{}/{}\".format(a, b)\n        new_string = \"\\\\frac{\" + str(a) + \"}{\" + str(b) + \"}\"\n        return new_string\n    except AssertionError:\n        return string\n\ndef remove_right_units(string):\n    # \"\\\\text{ \" only ever occurs (at least in the val set) when describing units\n    if \"\\\\text{ \" in string:\n        splits = string.split(\"\\\\text{ \")\n        assert len(splits) == 2\n        return splits[0]\n    else:\n        return string\n\ndef fix_sqrt(string):\n    if \"\\\\sqrt\" not in string:\n        return string\n    splits = string.split(\"\\\\sqrt\")\n    new_string = splits[0]\n    for split in splits[1:]:\n        if split[0] != \"{\":\n            a = split[0]\n            new_substr = \"\\\\sqrt{\" + a + \"}\" + split[1:]\n        else:\n            new_substr = \"\\\\sqrt\" + split\n        new_string += new_substr\n    return new_string\n\n\ndef strip_string(string):\n    # linebreaks\n    string = string.replace(\"\\n\", \"\")\n\n    # remove inverse spaces\n    string = string.replace(\"\\\\!\", \"\")\n\n    # replace \\\\ with \\\n    string = string.replace(\"\\\\\\\\\", \"\\\\\")\n\n    # replace tfrac and dfrac with frac\n    string = string.replace(\"tfrac\", \"frac\")\n    string = string.replace(\"dfrac\", \"frac\")\n\n    # remove \\left and \\right\n    string = string.replace(\"\\\\left\", \"\")\n    string = string.replace(\"\\\\right\", \"\")\n\n    # Remove circ (degrees)\n    string = string.replace(\"^{\\\\circ}\", \"\")\n    string = string.replace(\"^\\\\circ\", \"\")\n\n    # remove dollar signs\n    string = string.replace(\"\\\\$\", \"\")\n\n    # remove units (on the right)\n    string = remove_right_units(string)\n\n    # remove percentage\n    string = string.replace(\"\\\\%\", \"\")\n    string = string.replace(\"\\%\", \"\")  # noqa: W605\n\n    # \" 0.\" equivalent to \" .\" and \"{0.\" equivalent to \"{.\" Alternatively, add \"0\" if \".\" is the start of the string\n    string = string.replace(\" .\", \" 0.\")\n    string = string.replace(\"{.\", \"{0.\")\n    # if empty, return empty string\n    if len(string) == 0:\n        return string\n    if string[0] == \".\":\n        string = \"0\" + string\n\n    # to consider: get rid of e.g. \"k = \" or \"q = \" at beginning\n    if len(string.split(\"=\")) == 2:\n        if len(string.split(\"=\")[0]) <= 2:\n            string = string.split(\"=\")[1]\n\n    # fix sqrt3 --> sqrt{3}\n    string = fix_sqrt(string)\n\n    # remove spaces\n    string = string.replace(\" \", \"\")\n\n    # \\frac1b or \\frac12 --> \\frac{1}{b} and \\frac{1}{2}, etc. Even works with \\frac1{72} (but not \\frac{72}1). Also does a/b --> \\\\frac{a}{b}\n    string = fix_fracs(string)\n\n    # manually change 0.5 --> \\frac{1}{2}\n    if string == \"0.5\":\n        string = \"\\\\frac{1}{2}\"\n\n    # NOTE: X/Y changed to \\frac{X}{Y} in dataset, but in simple cases fix in case the model output is X/Y\n    string = fix_a_slash_b(string)\n\n    return string\n\n\ndef is_equiv(str1, str2, verbose=False):\n    if str1 is None and str2 is None:\n        print(\"WARNING: Both None\")\n        return True\n    if str1 is None or str2 is None:\n        return False\n\n    try:\n        ss1 = strip_string(str1)\n        ss2 = strip_string(str2)\n        #pdb.set_trace()\n        if verbose:\n            print(ss1, ss2)\n        return ss1 == ss2\n    except Exception:\n        return str1 == str2\n\nclass NotEqual:\n    def __eq__(self, other):\n        return False"}
{"type": "source_file", "path": "eval/util.py", "content": "import pprint\n\ndef last_boxed_only(sample):\n    q, a = sample\n    a = last_boxed_only_string(a)\n    if a == None:\n        return None\n    return (q, a)\n\ndef last_boxed_only_string(string):\n    idx = string.rfind(\"\\\\boxed\")\n    if idx < 0:\n        idx = string.rfind(\"\\\\fbox\")\n        if idx < 0:\n            return None\n\n    i = idx\n    right_brace_idx = None\n    num_left_braces_open = 0\n    while i < len(string):\n        if string[i] == \"{\":\n            num_left_braces_open += 1\n        if string[i] == \"}\":\n            num_left_braces_open -= 1\n            if num_left_braces_open == 0:\n                right_brace_idx = i\n                break\n        i += 1\n    \n    if right_brace_idx == None:\n        retval = None\n    else:\n        retval = string[idx:right_brace_idx + 1]\n    \n    return retval\n\ndef only_until_first_boxed_from_tokens(string, tokens):\n    idx = string.find(\"\\\\boxed\")\n    if idx < 0:\n        idx = string.find(\"\\\\fbox\")\n        if idx < 0:\n            return None\n    \n    cum_length = 0\n    for i, t in enumerate(tokens):\n        cum_length += len(t)\n        if cum_length >= idx:\n            break\n    \n    return tokens[:i]\n\n\n\ndef clean_numbers(sample):\n    if not sample:\n        return None\n    new_sample = list()\n    for s in sample:\n        new_sample.append(_clean_numbers(s))\n\n    return tuple(new_sample)\n\ndef _clean_numbers(string):\n    \"\"\"\n    Clean Numbers in the given string\n\n    >>> _clean_numbers(None, \"Hello 123\")\n    'Hello 123'\n    >>> _clean_numbers(None, \"Hello 1234\")\n    'Hello 1,234'\n    >>> _clean_numbers(None, \"Hello 1234324asdasd\")\n    'Hello 1,234,324asdasd'\n    \"\"\"\n    num_prev_digits = 0\n    new_string = \"\"\n    for i, c in enumerate(string):\n        # isdigit() doesnt work here because of weird unicode chars.\n        if c in {'1', '2', '3', '4', '5', '6', '7', '8', '9', '0'}:\n            num_prev_digits += 1\n        else:\n            if num_prev_digits > 3:\n                # Some fixing\n                string_number = new_string[-num_prev_digits:]\n                new_string = new_string[:-num_prev_digits] + \"{0:,}\".format(int(string_number))\n            num_prev_digits = 0\n        new_string += c\n\n    if num_prev_digits > 3:\n        # Some fixing\n        string_number = new_string[-num_prev_digits:]\n        new_string = new_string[:-num_prev_digits] + \"{0:,}\".format(int(string_number))\n\n    return new_string\n\ndef fix_fracs(string):\n    substrs = string.split(\"\\\\frac\")\n    new_str = substrs[0]\n    if len(substrs) > 1:\n        substrs = substrs[1:]\n        for substr in substrs:\n            new_str += \"\\\\frac\"\n            if substr[0] == \"{\":\n                new_str += substr\n            else:\n                try:\n                    assert len(substr) >= 2\n                except AssertionError:\n                    return string\n                a = substr[0]\n                b = substr[1]\n                if b != \"{\":\n                    if len(substr) > 2:\n                        post_substr = substr[2:]\n                        new_str += \"{\" + a + \"}{\" + b + \"}\" + post_substr\n                    else:\n                        new_str += \"{\" + a + \"}{\" + b + \"}\"\n                else:\n                    if len(substr) > 2:\n                        post_substr = substr[2:]\n                        new_str += \"{\" + a + \"}\" + b + post_substr\n                    else:\n                        new_str += \"{\" + a + \"}\" + b\n    string = new_str\n    return string\n\ndef fix_a_slash_b(string):\n    if len(string.split(\"/\")) != 2:\n        return string\n    a = string.split(\"/\")[0]\n    b = string.split(\"/\")[1]\n    try:\n        a = int(a)\n        b = int(b)\n        assert string == \"{}/{}\".format(a, b)\n        new_string = \"\\\\frac{\" + str(a) + \"}{\" + str(b) + \"}\"\n        return new_string\n    except AssertionError:\n        return string\n\ndef remove_right_units(string):\n    # \"\\\\text{ \" only ever occurs (at least in the val set) when describing units\n    if \"\\\\text{ \" in string:\n        splits = string.split(\"\\\\text{ \")\n        assert len(splits) == 2\n        return splits[0]\n    else:\n        return string\n\ndef fix_sqrt(string):\n    if \"\\\\sqrt\" not in string:\n        return string\n    splits = string.split(\"\\\\sqrt\")\n    new_string = splits[0]\n    for split in splits[1:]:\n        if split[0] != \"{\":\n            a = split[0]\n            new_substr = \"\\\\sqrt{\" + a + \"}\" + split[1:]\n        else:\n            new_substr = \"\\\\sqrt\" + split\n        new_string += new_substr\n    return new_string\n\n\ndef strip_string(string):\n    # linebreaks\n    string = string.replace(\"\\n\", \"\")\n\n    # remove inverse spaces\n    string = string.replace(\"\\\\!\", \"\")\n\n    # replace \\\\ with \\\n    string = string.replace(\"\\\\\\\\\", \"\\\\\")\n\n    # replace tfrac and dfrac with frac\n    string = string.replace(\"tfrac\", \"frac\")\n    string = string.replace(\"dfrac\", \"frac\")\n\n    # remove \\left and \\right\n    string = string.replace(\"\\\\left\", \"\")\n    string = string.replace(\"\\\\right\", \"\")\n\n    # Remove circ (degrees)\n    string = string.replace(\"^{\\\\circ}\", \"\")\n    string = string.replace(\"^\\\\circ\", \"\")\n\n    # remove dollar signs\n    string = string.replace(\"\\\\$\", \"\")\n\n    # remove units (on the right)\n    string = remove_right_units(string)\n\n    # remove percentage\n    string = string.replace(\"\\\\%\", \"\")\n    string = string.replace(\"\\%\", \"\")  # noqa: W605\n\n    # \" 0.\" equivalent to \" .\" and \"{0.\" equivalent to \"{.\" Alternatively, add \"0\" if \".\" is the start of the string\n    string = string.replace(\" .\", \" 0.\")\n    string = string.replace(\"{.\", \"{0.\")\n    # if empty, return empty string\n    if len(string) == 0:\n        return string\n    if string[0] == \".\":\n        string = \"0\" + string\n\n    # to consider: get rid of e.g. \"k = \" or \"q = \" at beginning\n    if len(string.split(\"=\")) == 2:\n        if len(string.split(\"=\")[0]) <= 2:\n            string = string.split(\"=\")[1]\n\n    # fix sqrt3 --> sqrt{3}\n    string = fix_sqrt(string)\n\n    # remove spaces\n    string = string.replace(\" \", \"\")\n\n    # \\frac1b or \\frac12 --> \\frac{1}{b} and \\frac{1}{2}, etc. Even works with \\frac1{72} (but not \\frac{72}1). Also does a/b --> \\\\frac{a}{b}\n    string = fix_fracs(string)\n\n    # manually change 0.5 --> \\frac{1}{2}\n    if string == \"0.5\":\n        string = \"\\\\frac{1}{2}\"\n\n    # NOTE: X/Y changed to \\frac{X}{Y} in dataset, but in simple cases fix in case the model output is X/Y\n    string = fix_a_slash_b(string)\n\n    return string\n\n\ndef is_equiv(str1, str2, verbose=False):\n    if str1 is None and str2 is None:\n        print(\"WARNING: Both None\")\n        return True\n    if str1 is None or str2 is None:\n        return False\n\n    try:\n        ss1 = strip_string(str1)\n        ss2 = strip_string(str2)\n        #pdb.set_trace()\n        if verbose:\n            print(ss1, ss2)\n        return ss1 == ss2\n    except Exception:\n        return str1 == str2\n\nclass NotEqual:\n    def __eq__(self, other):\n        return False"}
{"type": "source_file", "path": "eval/eval_math.py", "content": "import argparse\nimport json\nimport pdb\nimport jsonlines\n\nimport util\nfrom vllm import LLM, SamplingParams\nimport sys\nMAX_INT = sys.maxsize\nINVALID_ANS = \"[invalid]\"\n\ninvalid_outputs = []\ndef remove_boxed(s):\n    left = \"\\\\boxed{\"\n    try:\n        assert s[:len(left)] == left\n        assert s[-1] == \"}\"\n        return s[len(left):-1]\n    except:\n        return None\n\ndef process_results(doc, completion, answer):\n    split_ans = completion.split('The answer is: ')\n    if len(split_ans) > 1:\n        ans = split_ans[-1]\n        extract_ans_temp = ans.split('.\\n')[0]\n        extract_ans_temp = extract_ans_temp.strip()\n        if len(extract_ans_temp)>0 and extract_ans_temp[-1] == '.':\n            extract_ans = extract_ans_temp[0:-1]\n        else:\n            extract_ans = extract_ans_temp\n        extract_ans = extract_ans.strip()\n        if util.is_equiv(extract_ans, answer):\n            return True\n        else:\n            return False\n    else:\n        temp = {'question': doc, 'output': completion, 'answer': answer}\n        invalid_outputs.append(temp)\n        return False\ndef batch_data(data_list, batch_size=1):\n    n = len(data_list) // batch_size\n    batch_data = []\n    for i in range(n-1):\n        start = i * batch_size\n        end = (i+1)*batch_size\n        batch_data.append(data_list[start:end])\n\n    last_start = (n-1) * batch_size\n    last_end = MAX_INT\n    batch_data.append(data_list[last_start:last_end])\n    return batch_data\n\ndef test_hendrycks_math(model, data_path, start=0, end=MAX_INT, batch_size=1, tensor_parallel_size=1):\n    hendrycks_math_ins = []\n    hendrycks_math_answers = []\n    problem_prompt = (\n        \"Below is an instruction that describes a task. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n    )\n    print('promt =====', problem_prompt)\n    with open(data_path, \"r+\", encoding=\"utf8\") as f:\n        for idx, item in enumerate(jsonlines.Reader(f)):\n            temp_instr = problem_prompt.format(instruction=item[\"instruction\"])\n            hendrycks_math_ins.append(temp_instr)\n            solution = item['output']\n            temp_ans = remove_boxed(util.last_boxed_only_string(solution))\n            hendrycks_math_answers.append(temp_ans)\n\n    print('total length ===', len(hendrycks_math_ins))\n    hendrycks_math_ins = hendrycks_math_ins[start:end]\n    hendrycks_math_answers = hendrycks_math_answers[start:end]\n    print('lenght ====', len(hendrycks_math_ins))\n    batch_hendrycks_math_ins = batch_data(hendrycks_math_ins, batch_size=batch_size)\n\n    stop_tokens = [\"Question:\", \"Question\", \"USER:\", \"USER\", \"ASSISTANT:\", \"ASSISTANT\", \"Instruction:\", \"Instruction\", \"Response:\", \"Response\"]\n    sampling_params = SamplingParams(temperature=0, top_p=1, max_tokens=2048, stop=stop_tokens)\n    print('sampleing =====', sampling_params)\n    llm = LLM(model=model,tensor_parallel_size=tensor_parallel_size)\n    res_completions = []\n    for idx, (prompt, prompt_answer) in enumerate(zip(batch_hendrycks_math_ins, hendrycks_math_answers)):\n        if isinstance(prompt, list):\n            pass\n        else:\n            prompt = [prompt]\n        completions = llm.generate(prompt, sampling_params)\n        for output in completions:\n            prompt_temp = output.prompt\n            generated_text = output.outputs[0].text\n            res_completions.append(generated_text)\n\n    results = []\n    for idx, (prompt, completion, prompt_answer) in enumerate(zip(hendrycks_math_ins, res_completions, hendrycks_math_answers)):\n        res = process_results(prompt, completion, prompt_answer)\n        results.append(res)\n\n    acc = sum(results) / len(results)\n    print('len invalid outputs ====', len(invalid_outputs), ', valid_outputs===', invalid_outputs)\n    print('start===', start, ', end====',end)\n    print('length====', len(results), ', acc====', acc)\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default='')  # model path\n    parser.add_argument(\"--data_file\", type=str, default='')  # data path\n    parser.add_argument(\"--start\", type=int, default=0) #start index\n    parser.add_argument(\"--end\", type=int, default=MAX_INT)  # end index\n    parser.add_argument(\"--batch_size\", type=int, default=400)  # batch_size\n    parser.add_argument(\"--tensor_parallel_size\", type=int, default=8)  # tensor_parallel_size\n    return parser.parse_args()\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    test_hendrycks_math(model=args.model, data_path=args.data_file, start=args.start, end=args.end, batch_size=args.batch_size, tensor_parallel_size=args.tensor_parallel_size)\n"}
{"type": "source_file", "path": "train_math.py", "content": "#    Copyright 2023 Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\");\n#    you may not use this file except in compliance with the License.\n#    You may obtain a copy of the License at\n#\n#        http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS,\n#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#    See the License for the specific language governing permissions and\n#    limitations under the License.\n#    Modified by Zheng Yuan and Hongyi Yuan\n\nimport os\nimport copy\nimport logging\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Dict, Sequence\nimport io\nimport torch\nimport transformers\nfrom torch.utils.data import Dataset\nfrom transformers import Trainer\nimport argparse\nimport json\nimport random;random.seed(42)\n\ndef _make_r_io_base(f, mode: str):\n    if not isinstance(f, io.IOBase):\n        f = open(f, mode=mode)\n    return f\n\ndef jload(f, mode=\"r\"):\n    \"\"\"Load a .json file into a dictionary.\"\"\"\n    f = _make_r_io_base(f, mode)\n    jdict = json.load(f)\n    f.close()\n    return jdict\n\nIGNORE_INDEX = -100\nDEFAULT_PAD_TOKEN = \"[PAD]\"\nDEFAULT_EOS_TOKEN = \"</s>\"\nDEFAULT_BOS_TOKEN = \"<s>\"\nDEFAULT_UNK_TOKEN = \"<unk>\"\nPROMPT_DICT = {\n    \"prompt_input\": (\n        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n    ),\n    \"prompt_no_input\": (\n    \"Below is an instruction that describes a task. \"\n    \"Write a response that appropriately completes the request.\\n\\n\"\n    \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n    ),\n}\n#### 28\n@dataclass\nclass ModelArguments:\n    model_name_or_path: Optional[str] = field(default=\"facebook/opt-125m\")\n\n\n@dataclass\nclass DataArguments:\n    data_path: str = field(default=None, metadata={\"help\": \"Path to the training data.\"})\n\n\n@dataclass\nclass TrainingArguments(transformers.TrainingArguments):\n    cache_dir: Optional[str] = field(default=None)\n    optim: str = field(default=\"adamw_torch\")\n    model_max_length: int = field(\n        default=512,\n        metadata={\"help\": \"Maximum sequence length. Sequences will be right padded (and possibly truncated).\"},\n    )\n    overwrite_output_dir: bool = field(default=True)\n\n\ndef safe_save_model_for_hf_trainer(trainer: transformers.Trainer, output_dir: str):\n    \"\"\"Collects the state dict and dump to disk.\"\"\"\n    state_dict = trainer.model.state_dict()\n    if trainer.args.should_save:\n        cpu_state_dict = {key: value.cpu() for key, value in state_dict.items()}\n        del state_dict\n        trainer._save(output_dir, state_dict=cpu_state_dict)  # noqa\n\n\ndef smart_tokenizer_and_embedding_resize(\n    special_tokens_dict: Dict,\n    tokenizer: transformers.PreTrainedTokenizer,\n    model: transformers.PreTrainedModel,\n):\n    \"\"\"Resize tokenizer and embedding.\n\n    Note: This is the unoptimized version that may make your embedding size not be divisible by 64.\n    \"\"\"\n    num_new_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n    model.resize_token_embeddings(len(tokenizer))\n\n    if num_new_tokens > 0:\n        input_embeddings = model.get_input_embeddings().weight.data\n        output_embeddings = model.get_output_embeddings().weight.data\n\n        input_embeddings_avg = input_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n        output_embeddings_avg = output_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n\n        input_embeddings[-num_new_tokens:] = input_embeddings_avg\n        output_embeddings[-num_new_tokens:] = output_embeddings_avg\n\n\ndef _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n    \"\"\"Tokenize a list of strings.\"\"\"\n    tokenized_list = [\n        tokenizer(\n            text,\n            return_tensors=\"pt\",\n            padding=\"longest\",\n            max_length=tokenizer.model_max_length,\n            truncation=True,\n        )\n        for text in strings\n    ]\n    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n    input_ids_lens = labels_lens = [\n        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n    ]\n    return dict(\n        input_ids=input_ids,\n        labels=labels,\n        input_ids_lens=input_ids_lens,\n        labels_lens=labels_lens,\n    )\n\n\ndef preprocess(\n    sources: Sequence[str],\n    targets: Sequence[str],\n    tokenizer: transformers.PreTrainedTokenizer,\n) -> Dict:\n    \"\"\"Preprocess the data by tokenizing.\"\"\"\n    examples = [s + t for s, t in zip(sources, targets)]\n    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n    input_ids = examples_tokenized[\"input_ids\"]\n    labels = copy.deepcopy(input_ids)\n    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n        label[:source_len] = IGNORE_INDEX\n    return dict(input_ids=input_ids, labels=labels)\n\nclass SupervisedDataset(Dataset):\n    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n\n    def __init__(self, data_args, tokenizer: transformers.PreTrainedTokenizer):\n        super(SupervisedDataset, self).__init__()\n        logging.warning(\"Loading data...\")\n        data_path = data_args.data_path\n        try:\n            data_path = data_path_map[data_path]\n        except:\n            data_path = data_path\n        try:\n            list_data_dict = jload(data_path)\n        except BaseException:\n            with open(data_path, 'r') as f:\n                lines = f.readlines()\n            list_data_dict = [json.loads(line.strip()) for line in lines]\n\n        list_data_dict = random.sample(list_data_dict,  len(list_data_dict))\n        list_data_dict = list_data_dict[:data_args.data_length]\n\n        # logging.warning(\"Formatting inputs...\")\n        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n        # print(list_data_dict[0])\n        if 'instruction' in list_data_dict[0]:\n            pass\n        else:\n            def get_input(query):\n                if query.find('\\n') == -1:\n                    return ''\n                return '\\n'.join(query.split('\\n')[1:])\n            list_data_dict = [{'instruction':data['query'].split('\\n')[0], 'input':get_input(data['query']), 'output':data['response']} for data in list_data_dict]\n        # import ipdb; ipdb.set_trace()\n        sources = [\n            prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n            for example in list_data_dict\n        ]\n        targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n\n        self.sources = sources\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.sources)\n\n    def naive__getitem__(self, i) -> Dict[str, torch.Tensor]:\n        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n\n    def __getitem__(self, i):\n        return dict(input_ids=self.sources[i], labels=self.targets[i])\n\n@dataclass\nclass DataCollatorForSupervisedDataset(object):\n    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n\n    tokenizer: transformers.PreTrainedTokenizer\n\n    def naive__call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n        input_ids = torch.nn.utils.rnn.pad_sequence(\n            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n        )\n        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n        return dict(\n            input_ids=input_ids,\n            labels=labels,\n            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n        )\n\n    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n        sources = []\n        targets = []\n        for instance in instances:\n            source = instance['input_ids']\n            target = instance['labels']\n            sources.append(source)\n            targets.append(target)\n\n        data_dict = preprocess(sources, targets, self.tokenizer)\n        input_ids, labels = data_dict['input_ids'], data_dict['labels']\n        # input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n        input_ids = torch.nn.utils.rnn.pad_sequence(\n            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n        )\n        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n        return dict(\n            input_ids=input_ids,\n            labels=labels,\n            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n        )\n\ndef make_supervised_data_module(tokenizer: transformers.PreTrainedTokenizer, data_args) -> Dict:\n    \"\"\"Make dataset and collator for supervised fine-tuning.\"\"\"\n    train_dataset = SupervisedDataset(tokenizer=tokenizer, data_args=data_args)\n    data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n    return dict(train_dataset=train_dataset, eval_dataset=None, data_collator=data_collator)\n\n\ndef train():\n    parser = transformers.HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n    model_args, data_args, training_args, remaining_args = parser.parse_args_into_dataclasses(return_remaining_strings=True)\n    data_args.data_length = int(remaining_args[1])\n\n    model = transformers.AutoModelForCausalLM.from_pretrained(\n        model_args.model_name_or_path,\n        cache_dir=training_args.cache_dir,\n    )\n    print(model_args.model_name_or_path,training_args.cache_dir,training_args.model_max_length)#/mnt/data/user/zhao_jun/llemma_7b None 512\n    tokenizer = transformers.AutoTokenizer.from_pretrained(\n        model_args.model_name_or_path,\n        cache_dir=training_args.cache_dir,\n        model_max_length=training_args.model_max_length,\n        padding_side=\"right\",\n        #use_fast=False, #把这一行注释掉以后才能解决报错\n    )\n    if tokenizer.pad_token is None:\n        smart_tokenizer_and_embedding_resize(\n            special_tokens_dict=dict(pad_token=DEFAULT_PAD_TOKEN),\n            tokenizer=tokenizer,\n            model=model,\n        )\n    if \"llama\" in model_args.model_name_or_path:\n        tokenizer.add_special_tokens(\n            {\n                \"eos_token\": DEFAULT_EOS_TOKEN,\n                \"bos_token\": DEFAULT_BOS_TOKEN,\n                \"unk_token\": DEFAULT_UNK_TOKEN,\n            }\n        )\n\n    data_module = make_supervised_data_module(tokenizer=tokenizer, data_args=data_args)\n    trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args, **data_module)\n    trainer.train()\n    trainer.save_state()\n    # if os.environ.get('LOCAL_RANK') == '0':\n    safe_save_model_for_hf_trainer(trainer=trainer, output_dir=training_args.output_dir)\n\n\nif __name__ == \"__main__\":\n    train()"}
