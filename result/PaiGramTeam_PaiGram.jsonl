{"repo_info": {"repo_name": "PaiGram", "repo_owner": "PaiGramTeam", "repo_url": "https://github.com/PaiGramTeam/PaiGram"}}
{"type": "test_file", "path": "tests/integration/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/integration/test_redis.py", "content": "from typing import TYPE_CHECKING\n\nimport pytest\n\nif TYPE_CHECKING:\n    from core.dependence.redisdb import RedisDB\n\n\n@pytest.mark.asyncio\nasync def test_mysql(redis: \"RedisDB\"):\n    assert redis\n    assert redis.client\n\n\nasync def test_redis_ping(redis: \"RedisDB\"):\n    await redis.ping()\n"}
{"type": "test_file", "path": "tests/integration/test_player_service.py", "content": "import logging\n\nimport pytest_asyncio\n\nfrom core.basemodel import RegionEnum\nfrom core.services.players import PlayersService\nfrom core.services.players.models import PlayersDataBase\nfrom core.services.players.repositories import PlayersRepository\n\nlogger = logging.getLogger(\"TestPlayersService\")\n\n\n@pytest_asyncio.fixture(scope=\"class\", name=\"players_service\")\ndef service(database):\n    repository = PlayersRepository(database)\n    _players_service = PlayersService(repository)\n    return _players_service\n\n\nclass TestPlayersService:\n    @staticmethod\n    async def test_add_player(players_service: \"PlayersService\"):\n        data_base = PlayersDataBase(\n            user_id=1,\n            account_id=2,\n            player_id=3,\n            region=RegionEnum.HYPERION,\n            is_chosen=True,\n        )\n        await players_service.add(data_base)\n\n    @staticmethod\n    async def test_get_player_by_user_id(players_service: \"PlayersService\"):\n        result = await players_service.get(1)\n        assert isinstance(result, PlayersDataBase)\n        result = await players_service.get(1, region=RegionEnum.HYPERION)\n        assert isinstance(result, PlayersDataBase)\n        result = await players_service.get(1, region=RegionEnum.HOYOLAB)\n        assert not isinstance(result, PlayersDataBase)\n        assert result is None\n\n    @staticmethod\n    async def test_remove_all_by_user_id(players_service):\n        await players_service.remove_all_by_user_id(1)\n        result = await players_service.get(1)\n        assert not isinstance(result, PlayersDataBase)\n        assert result is None\n\n    @staticmethod\n    async def test_1(players_service: \"PlayersService\"):\n        \"\"\"测试 绑定时 账号不存在 账号添加 多账号添加\"\"\"\n        results = await players_service.get_all_by_user_id(10)\n        assert len(results) == 0  # 账号不存在\n        data_base = PlayersDataBase(\n            user_id=10,\n            account_id=2,\n            player_id=3,\n            region=RegionEnum.HYPERION,\n            is_chosen=1,\n        )\n        await players_service.add(data_base)  # 添加\n        result = await players_service.get(10)\n        assert result.user_id == 10\n        data_base = PlayersDataBase(\n            user_id=10,\n            account_id=3,\n            player_id=3,\n            region=RegionEnum.HYPERION,\n            is_chosen=True,\n        )\n        results = await players_service.get_all_by_user_id(10)  # 添加多账号，新的账号设置为主账号\n        assert len(results) == 1  # 账号存在只有一个\n        for result in results:\n            assert result.user_id == 10\n            if result.is_chosen == 1:\n                result.is_chosen = 0\n                await players_service.update(result)\n        await players_service.add(data_base)\n        results = await players_service.get_all_by_user_id(10)  # check all\n        assert len(results) == 2\n        for result in results:\n            assert result.user_id == 10\n            if result.account_id == 3:\n                assert result.is_chosen == 1\n            if result.account_id == 2:\n                assert result.is_chosen == 0\n        await players_service.remove_all_by_user_id(10)\n        results = await players_service.get_all_by_user_id(10)\n        assert len(results) == 0\n"}
{"type": "test_file", "path": "tests/unit/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/integration/test_database.py", "content": "import logging\n\nimport pytest\nfrom sqlmodel import SQLModel\n\nfrom core.services.players.models import PlayersDataBase\n\nlogger = logging.getLogger()\nlogger.info(\"%s\", PlayersDataBase.__name__)\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\nasync def test_mysql(database):\n    assert database\n\n\nasync def test_init_create_all(database):\n    async with database.engine.begin() as conn:\n        await conn.run_sync(SQLModel.metadata.drop_all)\n        await conn.run_sync(SQLModel.metadata.create_all)\n"}
{"type": "test_file", "path": "tests/unit/test_abyss_team_data.py", "content": "import logging\n\nimport pytest\nimport pytest_asyncio\nfrom flaky import flaky\n\nfrom modules.apihelper.client.components.abyss import AbyssTeam\nfrom modules.apihelper.models.genshin.abyss import TeamRateResult, TeamRate, FullTeamRate\n\nLOGGER = logging.getLogger(__name__)\n\n\n@pytest_asyncio.fixture\nasync def abyss_team_data():\n    _abyss_team_data = AbyssTeam()\n    yield _abyss_team_data\n    await _abyss_team_data.close()\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\n@flaky(3, 1)\nasync def test_abyss_team_data(abyss_team_data: AbyssTeam):\n    team_data = await abyss_team_data.get_data()\n    assert isinstance(team_data, TeamRateResult)\n    assert isinstance(team_data.rate_list_up[0], TeamRate)\n    assert isinstance(team_data.rate_list_up[-1], TeamRate)\n    assert isinstance(team_data.rate_list_down[0], TeamRate)\n    assert isinstance(team_data.rate_list_down[-1], TeamRate)\n    assert team_data.user_count > 0\n    team_data.sort([\"迪奥娜\", \"芭芭拉\", \"凯亚\", \"琴\"])\n    assert isinstance(team_data.rate_list_full[0], FullTeamRate)\n    assert isinstance(team_data.rate_list_full[-1], FullTeamRate)\n    random_team = team_data.random_team()[0]\n    assert isinstance(random_team, FullTeamRate)\n    member_up = {i.name for i in random_team.up.formation}\n    member_down = {i.name for i in random_team.down.formation}\n    assert not member_up & member_down\n    for i in team_data.rate_list_full[0].down.formation:\n        LOGGER.info(\"rate down info:name %s star %s\", i.name, i.star)\n    for i in team_data.rate_list_full[0].up.formation:\n        LOGGER.info(\"rate up info:name %s star %s\", i.name, i.star)\n"}
{"type": "test_file", "path": "tests/integration/conftest.py", "content": "import asyncio\n\nimport pytest\nimport pytest_asyncio\n\nfrom core.config import config\nfrom core.dependence.database import Database\nfrom core.dependence.redisdb import RedisDB\n\n\n@pytest_asyncio.fixture(scope=\"session\")\ndef event_loop():\n    policy = asyncio.get_event_loop_policy()\n    res = policy.new_event_loop()\n    asyncio.set_event_loop(res)\n    yield res\n    res.close()\n\n\n@pytest.fixture(scope=\"session\")\ndef database():\n    return Database.from_config(config=config)\n\n\n@pytest.fixture(scope=\"session\")\ndef redis():\n    return RedisDB.from_config(config=config)\n"}
{"type": "test_file", "path": "tests/unit/test_hyperion.py", "content": "import pytest\nimport pytest_asyncio\nfrom flaky import flaky\n\nfrom modules.apihelper.client.components.hyperion import Hyperion\n\n\n@pytest_asyncio.fixture\nasync def hyperion():\n    _hyperion = Hyperion()\n    yield _hyperion\n    await _hyperion.close()\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\n@flaky(3, 1)\nasync def test_get_strategy(hyperion):\n    test_collection_id_list = [839176, 839179, 839181, 1180811]\n    test_result = [\"温迪\", \"胡桃\", \"雷电将军\", \"柯莱\"]\n\n    async def get_post_id(_collection_id: int, character_name: str) -> str:\n        post_full_in_collection = await hyperion.get_post_full_in_collection(_collection_id)\n        for post_data in post_full_in_collection[\"posts\"]:\n            topics = post_data[\"topics\"]\n            for topic in topics:\n                if character_name == topic[\"name\"]:\n                    return topic[\"name\"]\n        return \"\"\n\n    for index, _ in enumerate(test_collection_id_list):\n        second = test_result[index]\n        first = await get_post_id(test_collection_id_list[index], second)\n        assert first == second\n"}
{"type": "test_file", "path": "tests/unit/test_hyperion_bbs.py", "content": "\"\"\"Test Url\nhttps://bbs.mihoyo.com/ys/article/29023709\n\"\"\"\n\nimport logging\n\nimport pytest\nimport pytest_asyncio\nfrom bs4 import BeautifulSoup\nfrom flaky import flaky\n\nfrom modules.apihelper.client.components.hyperion import Hyperion\nfrom modules.apihelper.models.genshin.hyperion import PostInfo\n\nLOGGER = logging.getLogger(__name__)\n\n\n@pytest_asyncio.fixture\nasync def hyperion():\n    _hyperion = Hyperion()\n    yield _hyperion\n    await _hyperion.close()\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\n@flaky(3, 1)\nasync def test_get_post_info(hyperion):\n    post_info = await hyperion.get_post_info(2, 29023709)\n    assert post_info\n    assert isinstance(post_info, PostInfo)\n    assert post_info[\"post\"][\"post\"][\"post_id\"] == \"29023709\"\n    assert post_info.post_id == 29023709\n    assert post_info[\"post\"][\"post\"][\"subject\"] == \"《原神》长期项目启动·概念PV\"\n    assert post_info.subject == \"《原神》长期项目启动·概念PV\"\n    assert len(post_info[\"post\"][\"post\"][\"images\"]) == 1\n    post_soup = BeautifulSoup(post_info[\"post\"][\"post\"][\"content\"], features=\"html.parser\")\n    assert post_soup.find_all(\"p\")\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\n@flaky(3, 1)\nasync def test_get_video_post_info(hyperion):\n    post_info = await hyperion.get_post_info(2, 33846648)\n    assert post_info\n    assert isinstance(post_info, PostInfo)\n    assert post_info[\"post\"][\"post\"][\"post_id\"] == \"33846648\"\n    assert post_info.post_id == 33846648\n    assert post_info[\"post\"][\"post\"][\"subject\"] == \"当然是原神了\"\n    assert post_info.subject == \"当然是原神了\"\n    assert len(post_info.video_urls) == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\n@flaky(3, 1)\nasync def test_get_images_by_post_id(hyperion):\n    post_images = await hyperion.get_images_by_post_id(2, 29023709)\n    assert len(post_images) == 1\n\n\n# noinspection PyShadowingNames\n@pytest.mark.asyncio\n@flaky(3, 1)\nasync def test_official_recommended_posts(hyperion):\n    official_recommended_posts = await hyperion.get_official_recommended_posts(2)\n    assert len(official_recommended_posts[\"list\"]) > 0\n    for data_list in official_recommended_posts[\"list\"]:\n        post_info = await hyperion.get_post_info(2, data_list[\"post_id\"])\n        assert post_info.post_id\n        assert post_info.subject\n        LOGGER.info(\"official_recommended_posts: post_id[%s] subject[%s]\", post_info.post_id, post_info.subject)\n"}
{"type": "test_file", "path": "tests/unit/test_wiki.py", "content": "import asyncio\nimport logging\nfrom random import randint, sample\nfrom typing import Type\n\nimport pytest\nfrom flaky import flaky\n\nfrom modules.wiki.base import WikiModel\nfrom modules.wiki.character import Character\nfrom modules.wiki.material import Material\nfrom modules.wiki.weapon import Weapon\n\nLOGGER = logging.getLogger(__name__)\n\n\n@pytest.fixture(scope=\"session\")\ndef event_loop():\n    loop = asyncio.get_event_loop()\n    asyncio.set_event_loop(loop)\n    yield loop\n    loop.close()\n\n\n@pytest.mark.asyncio\nclass TestWeapon:\n    @staticmethod\n    @flaky(3, 1)\n    async def test_get_by_id():\n        weapon = await Weapon.get_by_id(\"i_n11417\")\n        assert weapon.name == \"原木刀\"\n        assert weapon.rarity == 4\n        assert weapon.attack == 43.73\n        assert weapon.attribute.type.value == \"元素充能效率\"\n        assert weapon.affix.name == \"森林的瑞佑\"\n\n    @staticmethod\n    @flaky(3, 1)\n    async def test_get_by_name():\n        weapon = await Weapon.get_by_name(\"风鹰剑\")\n        assert weapon.id == \"i_n11501\"\n        assert weapon.rarity == 5\n        assert weapon.attack == 47.54\n        assert weapon.attribute.type.value == \"物理伤害加成\"\n        assert weapon.affix.name == \"西风之鹰的抗争\"\n        assert \"听凭风引，便是正义与自由之风\" in weapon.story\n\n    @staticmethod\n    @flaky(3, 1)\n    async def test_name_list():\n        from httpx import URL\n\n        async for name in Weapon._name_list_generator(with_url=True):\n            assert isinstance(name[0], str)\n            assert isinstance(name[1], URL)\n\n\n@pytest.mark.asyncio\nclass TestCharacter:\n    @staticmethod\n    @flaky(3, 1)\n    async def test_get_by_id():\n        character = await Character.get_by_id(\"ayaka_002\")\n        assert character.name == \"神里绫华\"\n        assert character.title == \"白鹭霜华\"\n        assert character.occupation == \"社奉行\"\n        assert character.association.value == \"稻妻\"\n        assert character.cn_cv == \"小N\"\n\n    @staticmethod\n    @flaky(3, 1)\n    async def test_get_by_name():\n        character = await Character.get_by_name(\"神里绫华\")\n        assert character.name == \"神里绫华\"\n        assert character.title == \"白鹭霜华\"\n        assert character.occupation == \"社奉行\"\n        assert character.association.value == \"稻妻\"\n        assert character.cn_cv == \"小N\"\n        main_character = await Character.get_by_name(\"荧\")\n        assert main_character.constellation == \"旅人座\"\n        assert main_character.cn_cv == \"宴宁&多多poi\"\n\n    @staticmethod\n    @flaky(3, 1)\n    async def test_name_list():\n        from httpx import URL\n\n        async for name in Character._name_list_generator(with_url=True):\n            assert isinstance(name[0], str)\n            assert isinstance(name[1], URL)\n\n\n@pytest.mark.asyncio\nclass TestMaterial:\n    @staticmethod\n    @flaky(3, 1)\n    async def test_get_by_id():\n        material = await Material.get_by_id(\"i_504\")\n        assert material.name == \"高塔孤王的碎梦\"\n        assert material.type == \"武器突破素材\"\n        assert \"合成获得\" in material.source\n        assert \"巴巴托斯\" in material.description\n\n        material = await Material.get_by_id(\"i_483\")\n        assert material.name == \"凶将之手眼\"\n        assert material.type == \"角色培养素材\"\n        assert \"70级以上永恒的守护者挑战奖励\" in material.source\n        assert \"所见即所为\" in material.description\n\n    @staticmethod\n    @flaky(3, 1)\n    async def test_get_by_name():\n        material = await Material.get_by_name(\"地脉的新芽\")\n        assert material.id == \"i_73\"\n        assert material.type == \"角色与武器培养素材\"\n        assert \"60级以上深渊法师掉落\" in material.source\n        assert \"勃发\" in material.description\n\n        material = await Material.get_by_name(\"「黄金」的教导\")\n        assert material.id == \"i_431\"\n        assert material.type == \"角色天赋素材\"\n        assert 2 in material.weekdays\n        assert \"土的象\" in material.description\n\n    @staticmethod\n    @flaky(3, 1)\n    async def test_name_list():\n        from httpx import URL\n\n        async for name in Material._name_list_generator(with_url=True):\n            assert isinstance(name[0], str)\n            assert isinstance(name[1], URL)\n\n\n@pytest.mark.asyncio\nclass TestAll:\n    @staticmethod\n    @flaky(3, 1)\n    async def make_test(target: Type[WikiModel]):\n        from httpx import URL\n\n        name_list = await target.get_name_list(with_url=True)\n        name_len = len(name_list)\n        assert name_len != 0\n        test_len = randint(1, max(2, int(len(name_list) * 0.3)))  # nosec\n        LOGGER.info(\"得到了 %d 条 %s 的数据, 将会测试其中的 %s 条数据\", name_len, target.__name__, test_len)\n        for name, url in sample(name_list, test_len):\n            assert isinstance(name, str)\n            assert isinstance(url, URL)\n            instance = await target._scrape(url)\n            assert isinstance(instance, target)\n            LOGGER.info(\"%s is ok.\", instance.name)\n\n    @flaky(3, 1)\n    async def test_random_material(self):\n        await self.make_test(Material)\n\n    @flaky(3, 1)\n    async def test_random_weapon(self):\n        await self.make_test(Weapon)\n\n    @flaky(3, 1)\n    async def test_random_character(self):\n        await self.make_test(Character)\n"}
{"type": "source_file", "path": "alembic/versions/87c6195e5306_history_data.py", "content": "\"\"\"history_data\n\nRevision ID: 87c6195e5306\nRevises: 369fb74daad9\nCreate Date: 2024-04-26 22:57:42.309397\n\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n# revision identifiers, used by Alembic.\nrevision = \"87c6195e5306\"\ndown_revision = \"369fb74daad9\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        \"history_data\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\"data_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\n            \"time_created\",\n            sa.DateTime(),\n            server_default=sa.text(\"now()\"),\n            nullable=True,\n        ),\n        sa.Column(\"time_updated\", sa.DateTime(), nullable=True),\n        sa.Column(\"type\", sa.Integer(), nullable=False),\n        sa.Column(\"data\", sa.JSON(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\", \"user_id\", \"type\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    op.create_index(\n        op.f(\"ix_history_data_user_id\"),\n        \"history_data\",\n        [\"user_id\"],\n        unique=False,\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_index(op.f(\"ix_history_data_user_id\"), table_name=\"history_data\")\n    op.drop_table(\"history_data\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "core/handler/hookhandler.py", "content": "from gram_core.handler.hookhandler import HookHandler\n\n__all__ = (\"HookHandler\",)\n"}
{"type": "source_file", "path": "core/basemodel.py", "content": "from gram_core.basemodel import RegionEnum, Settings\n\n__all__ = (\"RegionEnum\", \"Settings\")\n"}
{"type": "source_file", "path": "core/dependence/__init__.py", "content": "\"\"\"基础服务\"\"\"\n"}
{"type": "source_file", "path": "alembic/versions/27aaa52f9d4a_groups.py", "content": "\"\"\"groups\n\nRevision ID: 27aaa52f9d4a\nRevises: c6282bc5bf67\nCreate Date: 2024-01-16 13:54:37.980830\n\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlmodel\n\n# revision identifiers, used by Alembic.\nrevision = \"27aaa52f9d4a\"\ndown_revision = \"c6282bc5bf67\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        \"groups\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"chat_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\n            \"type\",\n            sa.Enum(\n                \"SENDER\",\n                \"PRIVATE\",\n                \"GROUP\",\n                \"SUPERGROUP\",\n                \"CHANNEL\",\n                name=\"chattypeenum\",\n            ),\n            nullable=True,\n        ),\n        sa.Column(\"description\", sa.TEXT(), nullable=True),\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_left\", sa.Integer(), nullable=True),\n        sa.Column(\"is_banned\", sa.Integer(), nullable=True),\n        sa.Column(\"title\", sqlmodel.AutoString(), nullable=False),\n        sa.Column(\"username\", sqlmodel.AutoString(), nullable=True),\n        sa.Column(\"big_photo_id\", sqlmodel.AutoString(), nullable=True),\n        sa.Column(\"small_photo_id\", sqlmodel.AutoString(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.UniqueConstraint(\"chat_id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table(\"groups\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "alembic/versions/c6282bc5bf67_devices_valid.py", "content": "\"\"\"devices_valid\n\nRevision ID: c6282bc5bf67\nRevises: 1df05b897d3f\nCreate Date: 2023-10-19 14:54:35.164497\n\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n# revision identifiers, used by Alembic.\nrevision = \"c6282bc5bf67\"\ndown_revision = \"1df05b897d3f\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(\"devices\", sa.Column(\"is_valid\", sa.Boolean(), nullable=False, server_default=\"1\"))\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_column(\"devices\", \"is_valid\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "alembic/versions/a9c8cde17cd8_tasks_player_id.py", "content": "\"\"\"tasks_player_id\n\nRevision ID: a9c8cde17cd8\nRevises: 1220c5c80757\nCreate Date: 2024-11-18 15:47:51.218077\n\n\"\"\"\n\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy import text\nfrom sqlalchemy.dialects import mysql\nfrom sqlalchemy.exc import NoSuchTableError\n\n# revision identifiers, used by Alembic.\nrevision = \"a9c8cde17cd8\"\ndown_revision = \"1220c5c80757\"\nbranch_labels = None\ndepends_on = None\n\nlogger = logging.getLogger(__name__)\n\n\ndef update_player_id():\n    connection = op.get_bind()\n    try:\n        statement = \"SELECT user_id FROM task;\"\n        task_table_data = connection.execute(text(statement))\n        need_check_user_id = []\n        if task_table_data is not None:\n            for row in task_table_data:\n                need_check_user_id.append(row[0])\n        need_check_user_id = list(set(need_check_user_id))\n    except NoSuchTableError:\n        logger.warning(\"Table 'task' doesn't exist\")\n        return  # should not happen\n    try:\n        statement = \"SELECT user_id, player_id, is_chosen FROM players;\"\n        players_table_data = connection.execute(text(statement))\n        player_id_map = {}\n        if players_table_data is not None:\n            for row in players_table_data:\n                if not row[2]:\n                    continue\n                uid, pid = row[0], row[1]\n                if uid not in player_id_map:\n                    player_id_map[uid] = pid\n    except NoSuchTableError:\n        logger.warning(\"Table 'players' doesn't exist\")\n        return  # should not happen\n\n    update = \"UPDATE task SET player_id=:player_id WHERE user_id=:user_id;\"\n\n    for uid in need_check_user_id:\n        player_id = player_id_map.get(uid, None)\n        if player_id is None:\n            logger.warning(\"user_id %s doesn't exist player\", uid)\n            continue\n        try:\n            with op.get_context().autocommit_block():\n                connection.execute(text(update), dict(player_id=player_id, user_id=uid))\n        except Exception as exc:  # pylint: disable=W0703\n            logger.error(\"Process sign->task Exception\", exc_info=exc)  # pylint: disable=W0703\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(\"task\", sa.Column(\"player_id\", sa.BigInteger(), nullable=False))\n    op.alter_column(\"task\", \"user_id\", existing_type=mysql.BIGINT(), nullable=False)\n    op.create_index(op.f(\"ix_task_player_id\"), \"task\", [\"player_id\"], unique=False)\n    update_player_id()\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_index(op.f(\"ix_task_player_id\"), table_name=\"task\")\n    op.alter_column(\"task\", \"user_id\", existing_type=mysql.BIGINT(), nullable=True)\n    op.drop_column(\"task\", \"player_id\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "core/dependence/assets.py", "content": "\"\"\"用于下载和管理角色、武器、材料等的图标\"\"\"\n\nfrom __future__ import annotations\nfrom abc import ABC, abstractmethod\nimport asyncio\nfrom functools import cached_property, lru_cache, partial\nfrom multiprocessing import RLock as Lock\nfrom pathlib import Path\nimport re\nfrom ssl import SSLZeroReturnError\nfrom typing import (\n    AsyncIterator,\n    ClassVar,\n    Dict,\n    Optional,\n    Protocol,\n    TYPE_CHECKING,\n    TypeVar,\n    Union,\n)\n\nfrom aiofiles import open as async_open\nfrom aiofiles.os import remove as async_remove\nfrom enkanetwork import Assets as EnkaAssets\nfrom enkanetwork.model.assets import CharacterAsset as EnkaCharacterAsset\nfrom httpx import AsyncClient, HTTPError, HTTPStatusError, TransportError, URL\nfrom typing_extensions import Self\n\nfrom core.base_service import BaseService\nfrom core.config import config\nfrom metadata.genshin import (\n    AVATAR_DATA,\n    HONEY_DATA,\n    MATERIAL_DATA,\n    NAMECARD_DATA,\n    WEAPON_DATA,\n)\nfrom metadata.scripts.honey import update_honey_metadata\nfrom metadata.scripts.metadatas import (\n    update_metadata_from_ambr,\n    update_metadata_from_github,\n)\nfrom metadata.shortname import roleToId, weaponToId\nfrom modules.wiki.base import HONEY_HOST\nfrom utils.const import AMBR_HOST, ENKA_HOST, PROJECT_ROOT\nfrom utils.log import logger\nfrom utils.typedefs import StrOrInt, StrOrURL\n\nif TYPE_CHECKING:\n    from httpx import Response\n    from multiprocessing.synchronize import RLock\n\n__all__ = (\"AssetsServiceType\", \"AssetsService\", \"AssetsServiceError\", \"AssetsCouldNotFound\", \"DEFAULT_EnkaAssets\")\n\n\nclass ICON_TYPE(Protocol):\n    async def __call__(self, overwrite: bool = False) -> Path | None: ...\n\n\nNAME_MAP_TYPE = Dict[str, StrOrURL]\n\nASSETS_PATH = PROJECT_ROOT.joinpath(\"resources/assets\")\nASSETS_PATH.mkdir(exist_ok=True, parents=True)\n\nDATA_MAP = {\"avatar\": AVATAR_DATA, \"weapon\": WEAPON_DATA, \"material\": MATERIAL_DATA}\n\nDEFAULT_EnkaAssets = EnkaAssets(lang=\"chs\")\n\n\nclass AssetsServiceError(Exception):\n    pass\n\n\nclass AssetsCouldNotFound(AssetsServiceError):\n    def __init__(self, message: str, target: str):\n        self.message = message\n        self.target = target\n        super().__init__(f\"{message}: target={target}\")\n\n\nclass _AssetsService(ABC):\n    _lock: ClassVar[\"RLock\"] = Lock()\n    _dir: ClassVar[Path]\n    icon_types: ClassVar[list[str]]\n\n    _client: Optional[AsyncClient] = None\n    _links: dict[str, str] = {}\n\n    id: int\n    type: str\n\n    icon: ICON_TYPE\n    \"\"\"图标\"\"\"\n\n    @abstractmethod\n    @cached_property\n    def game_name(self) -> str:\n        \"\"\"游戏数据中的名称\"\"\"\n\n    @cached_property\n    def honey_id(self) -> str:\n        \"\"\"当前资源在 Honey Impact 所对应的 ID\"\"\"\n        return HONEY_DATA[self.type].get(str(self.id), [\"\"])[0]\n\n    @property\n    def path(self) -> Path:\n        \"\"\"当前资源的文件夹\"\"\"\n        result = self._dir.joinpath(str(self.id)).resolve()\n        result.mkdir(exist_ok=True, parents=True)\n        return result\n\n    @property\n    def client(self) -> AsyncClient:\n        with self._lock:\n            if self._client is None or self._client.is_closed:\n                self._client = AsyncClient()\n        return self._client\n\n    def __init__(self, client: Optional[AsyncClient] = None) -> None:\n        self._client = client\n\n    def __call__(self, target: int) -> Self:\n        \"\"\"用于生成与 target 对应的 assets\"\"\"\n        result = self.__class__(self.client)\n        result.id = target\n        return result\n\n    def __init_subclass__(cls, **kwargs) -> None:\n        \"\"\"初始化一些类变量\"\"\"\n        from itertools import chain\n\n        cls.icon_types = [  # 支持的图标类型\n            k\n            for k, v in chain(cls.__annotations__.items(), *map(lambda x: x.__annotations__.items(), cls.__bases__))\n            if v in [ICON_TYPE, \"ICON_TYPE\"]\n        ]\n        cls.type = cls.__name__.lstrip(\"_\").split(\"Assets\")[0].lower()  # 当前 assert 的类型\n        cls._dir = ASSETS_PATH.joinpath(cls.type)  # 图标保存的文件夹\n        cls._dir.mkdir(exist_ok=True, parents=True)\n\n    async def _request(self, url: str, interval: float = 0.2) -> \"Response\":\n        error = None\n        for _ in range(5):\n            try:\n                response = await self.client.get(url, follow_redirects=False)\n                if response.headers.get(\"content-length\", None) == \"2358\":\n                    continue\n                return response\n            except (TransportError, SSLZeroReturnError) as e:\n                error = e\n                await asyncio.sleep(interval)\n                continue\n        if error is not None:\n            raise error\n\n    async def _download(self, url: StrOrURL, path: Path, retry: int = 5) -> Path | None:\n        \"\"\"从 url 下载图标至 path\"\"\"\n        logger.debug(\"正在从 %s 下载图标至 %s\", url, path)\n        headers = None\n        if config.enka_network_api_agent is not None and URL(url).host == \"enka.network\":\n            headers = {\"user-agent\": config.enka_network_api_agent}\n        for time in range(retry):\n            try:\n                response = await self.client.get(url, follow_redirects=False, headers=headers)\n            except Exception as error:  # pylint: disable=W0703\n                if not isinstance(error, (HTTPError, SSLZeroReturnError)):\n                    logger.error(error)  # 打印未知错误\n                if time != retry - 1:  # 未达到重试次数\n                    await asyncio.sleep(1)\n                else:\n                    raise error\n                continue\n            if response.status_code != 200:  # 判定页面是否正常\n                return None\n            async with async_open(path, \"wb\") as file:\n                await file.write(response.content)  # 保存图标\n            return path.resolve()\n\n    async def _get_from_ambr(self, item: str) -> AsyncIterator[str | None]:  # pylint: disable=W0613,R0201\n        \"\"\"从 ambr.top 上获取目标链接\"\"\"\n        yield None\n\n    async def _get_from_enka(self, item: str) -> AsyncIterator[str | None]:  # pylint: disable=W0613,R0201\n        \"\"\"从 enke.network 上获取目标链接\"\"\"\n        yield None\n\n    async def _get_from_honey(self, item: str) -> AsyncIterator[str | None]:\n        \"\"\"从 honey 上获取目标链接\"\"\"\n        if (honey_name := self.honey_name_map.get(item, None)) is not None:\n            yield HONEY_HOST.join(f\"img/{honey_name}.png\")\n            yield HONEY_HOST.join(f\"img/{honey_name}.webp\")\n\n    async def _download_url_generator(self, item: str) -> AsyncIterator[str]:\n        # 获取当前 `AssetsService` 的所有爬虫\n        for func in map(lambda x: getattr(self, x), sorted(filter(lambda x: x.startswith(\"_get_from_\"), dir(self)))):\n            async for url in func(item):\n                if url is not None:\n                    try:\n                        if (response := await self._request(url := str(url))) is None:\n                            continue\n                        response.raise_for_status()\n                        yield url\n                    except HTTPStatusError:\n                        continue\n\n    async def _get_download_url(self, item: str) -> str | None:\n        \"\"\"获取图标的下载链接\"\"\"\n        async for url in self._download_url_generator(item):\n            if url is not None:\n                return url\n\n    async def _get_img(self, overwrite: bool = False, *, item: str) -> Path | None:\n        \"\"\"获取图标\"\"\"\n        path = next(filter(lambda x: x.stem == item, self.path.iterdir()), None)\n        if not overwrite and path:  # 如果需要下载的图标存在且不覆盖( overwrite )\n            return path.resolve()\n        if path is not None and path.exists():\n            if overwrite:  # 如果覆盖\n                await async_remove(path)  # 删除已存在的图标\n            else:\n                return path\n        # 依次从使用当前 assets class 中的爬虫下载图标，顺序为爬虫名的字母顺序\n        async for url in self._download_url_generator(item):\n            if url is not None:\n                path = self.path.joinpath(f\"{item}{Path(url).suffix}\")\n                if (result := await self._download(url, path)) is not None:\n                    return result\n\n    @lru_cache\n    async def get_link(self, item: str) -> str | None:\n        \"\"\"获取相应图标链接\"\"\"\n        return await self._get_download_url(item)\n\n    def __getattr__(self, item: str):\n        \"\"\"魔法\"\"\"\n        if item in self.icon_types:\n            return partial(self._get_img, item=item)\n        object.__getattribute__(self, item)\n        return None\n\n    @abstractmethod\n    @cached_property\n    def game_name_map(self) -> dict[str, str]:\n        \"\"\"游戏中的图标名\"\"\"\n\n    @abstractmethod\n    @cached_property\n    def honey_name_map(self) -> dict[str, str]:\n        \"\"\"来自honey的图标名\"\"\"\n\n\nclass _AvatarAssets(_AssetsService):\n    enka: EnkaCharacterAsset | None\n\n    side: ICON_TYPE\n    \"\"\"侧视图图标\"\"\"\n\n    card: ICON_TYPE\n    \"\"\"卡片图标\"\"\"\n\n    gacha: ICON_TYPE\n    \"\"\"抽卡立绘\"\"\"\n\n    gacha_card: ICON_TYPE\n    \"\"\"抽卡卡片\"\"\"\n\n    AVATAR_DEFAULT: int = 10000005\n    \"\"\"默认角色ID\"\"\"\n\n    @cached_property\n    def game_name(self) -> str:\n        icon = \"UI_AvatarIcon_\"\n        if (avatar := AVATAR_DATA.get(str(self.id), None)) is not None:\n            icon = avatar[\"icon\"]\n        else:\n            for aid, avatar in AVATAR_DATA.items():\n                if aid.startswith(str(self.id)):\n                    icon = avatar[\"icon\"]\n        return re.findall(r\"UI_AvatarIcon_(.*)\", icon)[0]\n\n    @cached_property\n    def honey_id(self) -> str:\n        return HONEY_DATA[\"avatar\"].get(str(self.id), \"\")[0]\n\n    @cached_property\n    def enka(self) -> Optional[EnkaCharacterAsset]:\n        api = getattr(self, \"_enka_api\", None)\n        cid = getattr(self, \"id\", None)\n        return None if api is None or cid is None else api.character(cid)\n\n    def __init__(self, client: Optional[AsyncClient] = None, enka: Optional[EnkaAssets] = None):\n        super().__init__(client)\n        self._enka_api = enka or DEFAULT_EnkaAssets\n\n    def __call__(self, target: StrOrInt) -> \"_AvatarAssets\":\n        if target == 0:\n            target = self.AVATAR_DEFAULT\n        temp = target\n        result = _AvatarAssets(self.client)\n        if isinstance(target, str):\n            try:\n                target = int(target)\n            except ValueError:\n                target = roleToId(target)\n        if isinstance(target, str) or target is None:\n            raise AssetsCouldNotFound(\"找不到对应的角色\", temp)\n        result.id = target\n        result._enka_api = self._enka_api\n        return result\n\n    async def _get_from_ambr(self, item: str) -> AsyncIterator[str | None]:\n        if item in {\"icon\", \"side\", \"gacha\"}:\n            yield str(AMBR_HOST.join(f\"assets/UI/{self.game_name_map[item]}.png\"))\n\n    async def _get_from_enka(self, item: str) -> AsyncIterator[str | None]:\n        if (item_id := self.game_name_map.get(item)) is not None:\n            yield str(ENKA_HOST.join(f\"ui/{item_id}.png\"))\n\n    @cached_property\n    def honey_name_map(self) -> dict[str, str]:\n        return {\n            \"icon\": f\"{self.honey_id}_icon\",\n            \"side\": f\"{self.honey_id}_side_icon\",\n            \"gacha\": f\"{self.honey_id}_gacha_splash\",\n            \"gacha_card\": f\"{self.honey_id}_gacha_card\",\n        }\n\n    @cached_property\n    def game_name_map(self) -> dict[str, str]:\n        return {\n            \"icon\": f\"UI_AvatarIcon_{self.game_name}\",\n            \"card\": f\"UI_AvatarIcon_{self.game_name}_Card\",\n            \"side\": f\"UI_AvatarIcon_Side_{self.game_name}\",\n            \"gacha\": f\"UI_Gacha_AvatarImg_{self.game_name}\",\n        }\n\n\nclass _WeaponAssets(_AssetsService):\n    awaken: ICON_TYPE\n    \"\"\"突破后图标\"\"\"\n\n    gacha: ICON_TYPE\n    \"\"\"抽卡立绘\"\"\"\n\n    @cached_property\n    def game_name(self) -> str:\n        return re.findall(r\"UI_EquipIcon_(.*)\", WEAPON_DATA[str(self.id)][\"icon\"])[0]\n\n    @cached_property\n    def game_name_map(self) -> dict[str, str]:\n        return {\n            \"icon\": f\"UI_EquipIcon_{self.game_name}\",\n            \"awaken\": f\"UI_EquipIcon_{self.game_name}_Awaken\",\n            \"gacha\": f\"UI_Gacha_EquipIcon_{self.game_name}\",\n        }\n\n    @cached_property\n    def honey_id(self) -> str:\n        return f\"i_n{self.id}\"\n\n    def __call__(self, target: StrOrInt) -> Self:\n        temp = target\n        result = _WeaponAssets(self.client)\n        if isinstance(target, str):\n            target = int(target) if target.isnumeric() else weaponToId(target)\n        if isinstance(target, str) or target is None:\n            raise AssetsCouldNotFound(\"找不到对应的武器\", temp)\n        result.id = target\n        return result\n\n    async def _get_from_ambr(self, item: str) -> AsyncIterator[str | None]:\n        if item == \"icon\":\n            yield str(AMBR_HOST.join(f\"assets/UI/{self.game_name_map.get(item)}.png\"))\n\n    async def _get_from_enka(self, item: str) -> AsyncIterator[str | None]:\n        if item in self.game_name_map:\n            yield str(ENKA_HOST.join(f\"ui/{self.game_name_map.get(item)}.png\"))\n\n    @cached_property\n    def honey_name_map(self) -> dict[str, str]:\n        return {\n            \"icon\": f\"{self.honey_id}\",\n            \"awaken\": f\"{self.honey_id}_awaken_icon\",\n            \"gacha\": f\"{self.honey_id}_gacha_icon\",\n        }\n\n\nclass _MaterialAssets(_AssetsService):\n    @cached_property\n    def game_name(self) -> str:\n        return str(self.id)\n\n    @cached_property\n    def game_name_map(self) -> dict[str, str]:\n        return {\"icon\": f\"UI_ItemIcon_{self.game_name}\"}\n\n    @cached_property\n    def honey_name_map(self) -> dict[str, str]:\n        return {\"icon\": self.honey_id}\n\n    def __call__(self, target: StrOrInt) -> Self:\n        temp = target\n        result = _MaterialAssets(self.client)\n        if isinstance(target, str):\n            if target.isnumeric():\n                target = int(target)\n            else:\n                target = {v[\"name\"]: int(k) for k, v in MATERIAL_DATA.items()}.get(target)\n        if isinstance(target, str) or target is None:\n            raise AssetsCouldNotFound(\"找不到对应的素材\", temp)\n        result.id = target\n        return result\n\n    async def _get_from_ambr(self, item: str) -> AsyncIterator[str | None]:\n        if item == \"icon\":\n            yield str(AMBR_HOST.join(f\"assets/UI/{self.game_name_map.get(item)}.png\"))\n\n    async def _get_from_honey(self, item: str) -> AsyncIterator[str | None]:\n        yield HONEY_HOST.join(f\"/img/{self.honey_name_map.get(item)}.png\")\n        yield HONEY_HOST.join(f\"/img/{self.honey_name_map.get(item)}.webp\")\n\n\nclass _ArtifactAssets(_AssetsService):\n    flower: ICON_TYPE\n    \"\"\"生之花\"\"\"\n\n    plume: ICON_TYPE\n    \"\"\"死之羽\"\"\"\n\n    sands: ICON_TYPE\n    \"\"\"时之沙\"\"\"\n\n    goblet: ICON_TYPE\n    \"\"\"空之杯\"\"\"\n\n    circlet: ICON_TYPE\n    \"\"\"理之冠\"\"\"\n\n    @cached_property\n    def honey_id(self) -> str:\n        return HONEY_DATA[\"artifact\"][str(self.id)][0]\n\n    @cached_property\n    def game_name(self) -> str:\n        return f\"UI_RelicIcon_{self.id}\"\n\n    async def _get_from_enka(self, item: str) -> AsyncIterator[str | None]:\n        if item in self.game_name_map:\n            yield str(ENKA_HOST.join(f\"ui/{self.game_name_map.get(item)}.png\"))\n\n    async def _get_from_ambr(self, item: str) -> AsyncIterator[str | None]:\n        if item in self.game_name_map:\n            yield str(AMBR_HOST.join(f\"assets/UI/reliquary/{self.game_name_map[item]}.png\"))\n\n    @cached_property\n    def game_name_map(self) -> dict[str, str]:\n        return {\n            \"icon\": f\"UI_RelicIcon_{self.id}_4\",\n            \"flower\": f\"UI_RelicIcon_{self.id}_4\",\n            \"plume\": f\"UI_RelicIcon_{self.id}_2\",\n            \"sands\": f\"UI_RelicIcon_{self.id}_5\",\n            \"goblet\": f\"UI_RelicIcon_{self.id}_1\",\n            \"circlet\": f\"UI_RelicIcon_{self.id}_3\",\n        }\n\n    @cached_property\n    def honey_name_map(self) -> dict[str, str]:\n        first_id = int(re.findall(r\"\\d+\", HONEY_DATA[\"artifact\"][str(self.id)][-1])[0])\n        return {\n            \"icon\": f\"i_n{first_id + 30}\",\n            \"flower\": f\"i_n{first_id + 30}\",\n            \"plume\": f\"i_n{first_id + 10}\",\n            \"sands\": f\"i_n{first_id + 40}\",\n            \"goblet\": f\"i_n{first_id}\",\n            \"circlet\": f\"i_n{first_id + 20}\",\n        }\n\n\nclass _NamecardAssets(_AssetsService):\n    enka: EnkaCharacterAsset | None\n\n    navbar: ICON_TYPE\n    \"\"\"好友名片背景\"\"\"\n\n    profile: ICON_TYPE\n    \"\"\"个人资料名片背景\"\"\"\n\n    NAME_CARD_DEFAULT: int = 210189\n    \"\"\"默认名片 ID\"\"\"\n\n    @cached_property\n    def honey_id(self) -> str:\n        return HONEY_DATA[\"namecard\"][str(self.id)][0]\n\n    @cached_property\n    def game_name(self) -> str:\n        return NAMECARD_DATA[str(self.id)][\"icon\"]\n\n    @lru_cache\n    def _get_id_from_avatar_id(self, avatar_id: Union[int, str]) -> int:\n        avatar_icon_name = AVATAR_DATA[str(avatar_id)][\"icon\"].split(\"_\")[-1]\n        fallback = None\n        for namecard_id, namecard_data in NAMECARD_DATA.items():\n            if namecard_data[\"icon\"].split(\"_\")[-1] == avatar_icon_name:\n                return int(namecard_id)\n            if avatar_icon_name in namecard_data[\"icon\"].split(\"_\")[-1]:\n                fallback = int(namecard_id)\n        if fallback:\n            return fallback\n        raise ValueError(avatar_id)\n\n    def __call__(self, target: int) -> \"_NamecardAssets\":\n        if target == 0:\n            target = self.NAME_CARD_DEFAULT\n        result = _NamecardAssets(self.client)\n        target = int(target) if not isinstance(target, int) else target\n        if target > 10000000:\n            target = self._get_id_from_avatar_id(target)\n        result.id = target\n        result.enka = DEFAULT_EnkaAssets.namecards(target)\n        return result\n\n    async def _get_from_ambr(self, item: str) -> AsyncIterator[str | None]:\n        if item == \"profile\":\n            yield AMBR_HOST.join(f\"assets/UI/namecard/{self.game_name_map[item]}.png.png\")\n\n    async def _get_from_enka(self, item: str) -> AsyncIterator[str | None]:\n        if (url := getattr(self.enka, {\"profile\": \"banner\"}.get(item, item), None)) is not None:\n            yield url.url\n\n    @cached_property\n    def game_name_map(self) -> dict[str, str]:\n        return {\n            \"icon\": self.game_name,\n            \"navbar\": NAMECARD_DATA[str(self.id)][\"navbar\"],\n            \"profile\": NAMECARD_DATA[str(self.id)][\"profile\"],\n        }\n\n    @cached_property\n    def honey_name_map(self) -> dict[str, str]:\n        return {\n            \"icon\": self.honey_id,\n            \"navbar\": f\"{self.honey_id}_back\",\n            \"profile\": f\"{self.honey_id}_profile\",\n        }\n\n\nclass AssetsService(BaseService.Dependence):\n    \"\"\"asset服务\n\n    用于储存和管理 asset :\n        当对应的 asset (如某角色图标)不存在时，该服务会先查找本地。\n        若本地不存在，则从网络上下载；若存在，则返回其路径\n    \"\"\"\n\n    avatar: _AvatarAssets\n    \"\"\"角色\"\"\"\n\n    weapon: _WeaponAssets\n    \"\"\"武器\"\"\"\n\n    material: _MaterialAssets\n    \"\"\"素材\"\"\"\n\n    artifact: _ArtifactAssets\n    \"\"\"圣遗物\"\"\"\n\n    namecard: _NamecardAssets\n    \"\"\"名片\"\"\"\n\n    def __init__(self):\n        for attr, assets_type_name in filter(\n            lambda x: (not x[0].startswith(\"_\")) and x[1].endswith(\"Assets\"), self.__annotations__.items()\n        ):\n            setattr(self, attr, globals()[assets_type_name]())\n\n    async def initialize(self) -> None:  # pylint: disable=R0201\n        \"\"\"启动 AssetsService 服务，刷新元数据\"\"\"\n        logger.info(\"正在刷新元数据\")\n        # todo 这3个任务同时异步下载\n        await update_metadata_from_github(False)\n        await update_metadata_from_ambr(False)\n        await update_honey_metadata(False)\n        logger.info(\"刷新元数据成功\")\n\n\nAssetsServiceType = TypeVar(\"AssetsServiceType\", bound=_AssetsService)\n"}
{"type": "source_file", "path": "core/dependence/aiobrowser.py", "content": "from gram_core.dependence.aiobrowser import AioBrowser\n\n__all__ = (\"AioBrowser\",)\n"}
{"type": "source_file", "path": "core/__init__.py", "content": ""}
{"type": "source_file", "path": "alembic/env.py", "content": "import asyncio\nimport os\nfrom importlib import import_module\nfrom itertools import chain\nfrom logging.config import fileConfig\nfrom typing import Iterator\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\nfrom sqlalchemy.engine import Connection, URL\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom sqlmodel import SQLModel\n\nfrom core.config import config as application_config\nfrom utils.const import CORE_DIR, PLUGIN_DIR, PROJECT_ROOT\nfrom utils.log import logger\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nalembic_cfg = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif alembic_cfg.config_file_name is not None:\n    fileConfig(alembic_cfg.config_file_name)  # skipcq: PY-A6006\n\n\ndef scan_models() -> Iterator[str]:\n    \"\"\"扫描 core 和 plugins 目录下所有 models.py 模块。\n    我们规定所有插件的 model 都需要放在名为 models.py 的文件里。\"\"\"\n    dirs = [CORE_DIR, PLUGIN_DIR]\n\n    for path in chain(*[d.glob(\"**/models.py\") for d in dirs]):\n        yield str(path.relative_to(PROJECT_ROOT).with_suffix(\"\")).replace(os.sep, \".\")\n\n\ndef import_models():\n    \"\"\"导入我们所有的 models，使 alembic 可以自动对比 db scheme 创建 migration revision\"\"\"\n    for pkg in scan_models():\n        try:\n            import_module(pkg)  # 导入 models\n        except Exception as e:  # pylint: disable=W0703\n            logger.error(\n                \"在导入文件 %s 的过程中遇到了错误: \\n[red bold]%s: %s[/]\",\n                pkg,\n                type(e).__name__,\n                e,\n                extra={\"markup\": True},\n            )\n\n\n# register our models for alembic to auto-generate migrations\nimport_models()\n\ntarget_metadata = SQLModel.metadata\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n# here we allow ourselves to pass interpolation vars to alembic.ini\n# from the application config module\n\nsqlalchemy_url = alembic_cfg.get_main_option(\"sqlalchemy.url\")\nif sqlalchemy_url is None:\n    new_url = URL.create(\n        application_config.database.driver_name,\n        username=application_config.database.username,\n        password=application_config.database.password,\n        host=application_config.database.host,\n        port=application_config.database.port,\n        database=application_config.database.database,\n    )\n    alembic_cfg.set_main_option(\"sqlalchemy.url\", new_url.render_as_string(hide_password=False))\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    url = alembic_cfg.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef do_run_migrations(connection: Connection) -> None:\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\nasync def run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    connectable = AsyncEngine(\n        engine_from_config(\n            alembic_cfg.get_section(alembic_cfg.config_ini_section),\n            prefix=\"sqlalchemy.\",\n            poolclass=pool.NullPool,\n            future=True,\n        )\n    )\n\n    async with connectable.connect() as connection:\n        await connection.run_sync(do_run_migrations)\n\n    await connectable.dispose()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    asyncio.run(run_migrations_online())\n"}
{"type": "source_file", "path": "core/services/channels/cache.py", "content": "from gram_core.services.channels.cache import ChannelAliasCache\n\n__all__ = (\"ChannelAliasCache\",)\n"}
{"type": "source_file", "path": "core/application.py", "content": "\"\"\"BOT\"\"\"\n\nfrom gram_core.application import Application\n\n__all__ = (\"Application\",)\n"}
{"type": "source_file", "path": "core/handler/adminhandler.py", "content": "from gram_core.handler.adminhandler import AdminHandler\n\n__all__ = (\"AdminHandler\",)\n"}
{"type": "source_file", "path": "core/config.py", "content": "from gram_core.config import ApplicationConfig, config, JoinGroups\n\n__all__ = (\"ApplicationConfig\", \"config\", \"JoinGroups\")\n"}
{"type": "source_file", "path": "core/dependence/mtproto.py", "content": "from gram_core.dependence.mtproto import MTProto\n\n__all__ = (\"MTProto\",)\n"}
{"type": "source_file", "path": "core/dependence/redisdb.py", "content": "from gram_core.dependence.redisdb import RedisDB\n\n__all__ = [\"RedisDB\"]\n"}
{"type": "source_file", "path": "alembic/versions/89dcb9109475_tasks_daily.py", "content": "\"\"\"tasks_daily\n\nRevision ID: 89dcb9109475\nRevises: 27aaa52f9d4a\nCreate Date: 2024-03-10 10:48:10.227236\n\n\"\"\"\n\nfrom alembic import op\nfrom sqlalchemy.dialects import mysql\n\n# revision identifiers, used by Alembic.\nrevision = \"89dcb9109475\"\ndown_revision = \"27aaa52f9d4a\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.alter_column(\n        \"task\",\n        \"type\",\n        existing_type=mysql.ENUM(\n            \"SIGN\",\n            \"RESIN\",\n            \"REALM\",\n            \"EXPEDITION\",\n            \"TRANSFORMER\",\n            \"CARD\",\n            \"DAILY\",\n            collation=\"utf8mb4_general_ci\",\n        ),\n        nullable=False,\n    )\n    op.drop_index(\"task_1\", table_name=\"task\")\n    op.create_index(op.f(\"ix_task_user_id\"), \"task\", [\"user_id\"], unique=False)\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_index(op.f(\"ix_task_user_id\"), table_name=\"task\")\n    op.create_index(\"task_1\", \"task\", [\"user_id\"], unique=False)\n    op.alter_column(\n        \"task\",\n        \"type\",\n        existing_type=mysql.ENUM(\n            \"SIGN\",\n            \"RESIN\",\n            \"REALM\",\n            \"EXPEDITION\",\n            \"TRANSFORMER\",\n            \"CARD\",\n            collation=\"utf8mb4_general_ci\",\n        ),\n        nullable=True,\n    )\n    op.alter_column(\"task\", \"user_id\", existing_type=mysql.BIGINT(), nullable=True)\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "alembic/versions/9e9a36470cd5_init.py", "content": "\"\"\"init\n\nRevision ID: 9e9a36470cd5\nRevises:\nCreate Date: 2022-09-01 16:55:20.372560\n\n\"\"\"\n\nfrom base64 import b64decode\n\nimport sqlalchemy as sa\nimport sqlmodel\nfrom alembic import op\n\n# revision identifiers, used by Alembic.\nrevision = \"9e9a36470cd5\"\ndown_revision = None\nbranch_labels = None\ndepends_on = None\nold_cookies_database_name1 = b64decode(\"bWlob3lvX2Nvb2tpZXM=\").decode()\nold_cookies_database_name2 = b64decode(\"aG95b3ZlcnNlX2Nvb2tpZXM=\").decode()\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        \"question\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"text\", sqlmodel.AutoString(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    op.create_table(\n        \"user\",\n        sa.Column(\n            \"region\",\n            sa.Enum(\"NULL\", \"HYPERION\", \"HOYOLAB\", name=\"regionenum\"),\n            nullable=True,\n        ),\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\"yuanshen_uid\", sa.Integer(), nullable=True),\n        sa.Column(\"genshin_uid\", sa.Integer(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.UniqueConstraint(\"user_id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    op.create_table(\n        \"admin\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=False),\n        sa.ForeignKeyConstraint(\n            [\"user_id\"],\n            [\"user.user_id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    op.create_table(\n        \"answer\",\n        sa.Column(\"question_id\", sa.Integer(), nullable=True),\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"is_correct\", sa.Boolean(), nullable=True),\n        sa.Column(\"text\", sqlmodel.AutoString(), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"question_id\"],\n            [\"question.id\"],\n            onupdate=\"RESTRICT\",\n            ondelete=\"RESTRICT\",\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    op.create_table(\n        old_cookies_database_name2,\n        sa.Column(\"cookies\", sa.JSON(), nullable=True),\n        sa.Column(\n            \"status\",\n            sa.Enum(\n                \"STATUS_SUCCESS\",\n                \"INVALID_COOKIES\",\n                \"TOO_MANY_REQUESTS\",\n                name=\"cookiesstatusenum\",\n            ),\n            nullable=True,\n        ),\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"user_id\"],\n            [\"user.user_id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    op.create_table(\n        old_cookies_database_name1,\n        sa.Column(\"cookies\", sa.JSON(), nullable=True),\n        sa.Column(\n            \"status\",\n            sa.Enum(\n                \"STATUS_SUCCESS\",\n                \"INVALID_COOKIES\",\n                \"TOO_MANY_REQUESTS\",\n                name=\"cookiesstatusenum\",\n            ),\n            nullable=True,\n        ),\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"user_id\"],\n            [\"user.user_id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    op.create_table(\n        \"sign\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\"chat_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\n            \"time_created\",\n            sa.DateTime(timezone=True),\n            nullable=True,\n        ),\n        sa.Column(\"time_updated\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\n            \"status\",\n            sa.Enum(\n                \"STATUS_SUCCESS\",\n                \"INVALID_COOKIES\",\n                \"ALREADY_CLAIMED\",\n                \"GENSHIN_EXCEPTION\",\n                \"TIMEOUT_ERROR\",\n                \"BAD_REQUEST\",\n                \"FORBIDDEN\",\n                name=\"signstatusenum\",\n            ),\n            nullable=True,\n        ),\n        sa.ForeignKeyConstraint([\"user_id\"], [\"user.user_id\"], \"sign_1\"),\n        sa.PrimaryKeyConstraint(\"id\", \"user_id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table(\"sign\")\n    op.drop_table(old_cookies_database_name1)\n    op.drop_table(old_cookies_database_name2)\n    op.drop_table(\"answer\")\n    op.drop_table(\"admin\")\n    op.drop_table(\"user\")\n    op.drop_table(\"question\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "core/plugin/__init__.py", "content": "\"\"\"插件\"\"\"\n\nfrom gram_core.plugin._handler import (\n    conversation,\n    error_handler,\n    handler,\n    ConversationDataType,\n    ConversationData,\n    HandlerData,\n)\nfrom gram_core.plugin._job import TimeType, job\nfrom gram_core.plugin._plugin import Plugin, PluginType, get_all_plugins\n\n__all__ = (\n    \"Plugin\",\n    \"PluginType\",\n    \"get_all_plugins\",\n    \"handler\",\n    \"error_handler\",\n    \"conversation\",\n    \"ConversationDataType\",\n    \"ConversationData\",\n    \"HandlerData\",\n    \"job\",\n    \"TimeType\",\n)\n"}
{"type": "source_file", "path": "alembic/versions/a1c10da5704b_devices.py", "content": "\"\"\"devices\n\nRevision ID: a1c10da5704b\nRevises: ddcfba3c7d5c\nCreate Date: 2023-06-13 19:34:47.189846\n\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlmodel\n\n# revision identifiers, used by Alembic.\nrevision = \"a1c10da5704b\"\ndown_revision = \"ddcfba3c7d5c\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        \"devices\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"account_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\"device_id\", sqlmodel.AutoString(), nullable=False),\n        sa.Column(\"device_fp\", sqlmodel.AutoString(), nullable=False),\n        sa.Column(\"device_name\", sqlmodel.AutoString(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table(\"devices\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "core/handler/callbackqueryhandler.py", "content": "from gram_core.handler.callbackqueryhandler import CallbackQueryHandler, OverlappingException, OverlappingContext\n\n__all__ = (\"CallbackQueryHandler\", \"OverlappingException\", \"OverlappingContext\")\n"}
{"type": "source_file", "path": "alembic/versions/1df05b897d3f_tasks.py", "content": "\"\"\"tasks\n\nRevision ID: 1df05b897d3f\nRevises: a1c10da5704b\nCreate Date: 2023-07-23 14:44:59.592519\n\n\"\"\"\n\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy import text\nfrom sqlalchemy.dialects import mysql\nfrom sqlalchemy.exc import NoSuchTableError\n\n# revision identifiers, used by Alembic.\nrevision = \"1df05b897d3f\"\ndown_revision = \"a1c10da5704b\"\nbranch_labels = None\ndepends_on = None\n\nlogger = logging.getLogger(__name__)\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    connection = op.get_bind()\n    task_table = op.create_table(\n        \"task\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\"chat_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\n            \"time_created\",\n            sa.DateTime(),\n            server_default=sa.text(\"(CURRENT_TIMESTAMP)\"),\n            nullable=True,\n        ),\n        sa.Column(\"time_updated\", sa.DateTime(), nullable=True),\n        sa.Column(\n            \"type\",\n            sa.Enum(\n                \"SIGN\",\n                \"RESIN\",\n                \"REALM\",\n                \"EXPEDITION\",\n                \"TRANSFORMER\",\n                \"CARD\",\n                name=\"tasktypeenum\",\n            ),\n            nullable=True,\n        ),\n        sa.Column(\n            \"status\",\n            sa.Enum(\n                \"STATUS_SUCCESS\",\n                \"INVALID_COOKIES\",\n                \"ALREADY_CLAIMED\",\n                \"NEED_CHALLENGE\",\n                \"GENSHIN_EXCEPTION\",\n                \"TIMEOUT_ERROR\",\n                \"BAD_REQUEST\",\n                \"FORBIDDEN\",\n                name=\"taskstatusenum\",\n            ),\n            nullable=True,\n        ),\n        sa.Column(\"data\", sa.JSON(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    op.create_index(\"task_1\", \"task\", [\"user_id\"], unique=False)\n    try:\n        statement = \"SELECT * FROM sign;\"\n        old_sign_table_data = connection.execute(text(statement))\n    except NoSuchTableError:\n        logger.warning(\"Table 'sign' doesn't exist\")\n        return  # should not happen\n    if old_sign_table_data is not None:\n        for row in old_sign_table_data:\n            try:\n                user_id = row[\"user_id\"]\n                chat_id = row[\"chat_id\"]\n                time_created = row[\"time_created\"]\n                time_updated = row[\"time_updated\"]\n                status = row[\"status\"]\n                task_type = \"SIGN\"\n                insert = task_table.insert().values(\n                    user_id=int(user_id),\n                    chat_id=int(chat_id),\n                    time_created=time_created,\n                    time_updated=time_updated,\n                    type=task_type,\n                    status=status,\n                )\n                with op.get_context().autocommit_block():\n                    connection.execute(insert)\n            except Exception as exc:  # pylint: disable=W0703\n                logger.error(\"Process sign->task Exception\", exc_info=exc)  # pylint: disable=W0703\n    op.drop_table(\"sign\")\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        \"sign\",\n        sa.Column(\"id\", mysql.INTEGER(), autoincrement=False, nullable=False),\n        sa.Column(\"user_id\", mysql.BIGINT(), autoincrement=False, nullable=False),\n        sa.Column(\"chat_id\", mysql.BIGINT(), autoincrement=False, nullable=True),\n        sa.Column(\"time_created\", mysql.DATETIME(), nullable=True),\n        sa.Column(\"time_updated\", mysql.DATETIME(), nullable=True),\n        sa.Column(\n            \"status\",\n            mysql.ENUM(\n                \"STATUS_SUCCESS\",\n                \"INVALID_COOKIES\",\n                \"ALREADY_CLAIMED\",\n                \"GENSHIN_EXCEPTION\",\n                \"TIMEOUT_ERROR\",\n                \"BAD_REQUEST\",\n                \"FORBIDDEN\",\n            ),\n            nullable=True,\n        ),\n        sa.PrimaryKeyConstraint(\"id\", \"user_id\"),\n        mysql_collate=\"utf8mb4_general_ci\",\n        mysql_default_charset=\"utf8mb4\",\n        mysql_engine=\"InnoDB\",\n    )\n    op.drop_index(\"task_1\", table_name=\"task\")\n    op.drop_table(\"task\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "core/services/cookies/models.py", "content": "from gram_core.services.cookies.models import Cookies, CookiesDataBase, CookiesStatusEnum\n\n__all__ = (\"Cookies\", \"CookiesDataBase\", \"CookiesStatusEnum\")\n"}
{"type": "source_file", "path": "core/dependence/database.py", "content": "from gram_core.dependence.database import Database\n\n__all__ = (\"Database\",)\n"}
{"type": "source_file", "path": "alembic/versions/1220c5c80757_gacha_log_rank.py", "content": "\"\"\"gacha_log_rank\n\nRevision ID: 1220c5c80757\nRevises: 87c6195e5306\nCreate Date: 2024-09-12 12:02:16.283418\n\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n# revision identifiers, used by Alembic.\nrevision = \"1220c5c80757\"\ndown_revision = \"87c6195e5306\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        \"gacha_log_rank\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"player_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\n            \"type\",\n            sa.Enum(\n                \"CHARACTER\",\n                \"WEAPON\",\n                \"DEFAULT\",\n                \"DEFAULT_WEAPON\",\n                \"HUN\",\n                \"PET\",\n                name=\"gachalogtypeenum\",\n            ),\n            nullable=False,\n        ),\n        sa.Column(\"score_1\", sa.BigInteger(), nullable=True),\n        sa.Column(\"score_2\", sa.BigInteger(), nullable=True),\n        sa.Column(\"score_3\", sa.BigInteger(), nullable=True),\n        sa.Column(\"score_4\", sa.BigInteger(), nullable=True),\n        sa.Column(\"score_5\", sa.BigInteger(), nullable=True),\n        sa.Column(\"data\", sa.JSON(), nullable=True),\n        sa.Column(\n            \"time_created\",\n            sa.DateTime(),\n            server_default=sa.text(\"now()\"),\n            nullable=True,\n        ),\n        sa.Column(\"time_updated\", sa.DateTime(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\", \"player_id\", \"type\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table(\"gacha_log_rank\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "core/error.py", "content": "\"\"\"此模块包含核心模块的错误的基类\"\"\"\n\nfrom gram_core.error import ServiceNotFoundError\n\n__all__ = (\"ServiceNotFoundError\",)\n"}
{"type": "source_file", "path": "core/services/cookies/__init__.py", "content": "\"\"\"CookieService\"\"\"\n\nfrom core.services.cookies.services import CookiesService, PublicCookiesService\n\n__all__ = (\"CookiesService\", \"PublicCookiesService\")\n"}
{"type": "source_file", "path": "core/services/cookies/error.py", "content": "from gram_core.services.cookies.error import CookieServiceError, CookiesCachePoolExhausted, TooManyRequestPublicCookies\n\n__all__ = (\"CookieServiceError\", \"CookiesCachePoolExhausted\", \"TooManyRequestPublicCookies\")\n"}
{"type": "source_file", "path": "core/handler/grouphandler.py", "content": "from gram_core.handler.grouphandler import GroupHandler\n\n\n__all__ = (\"GroupHandler\",)\n"}
{"type": "source_file", "path": "core/services/channels/repositories.py", "content": "from gram_core.services.channels.repositories import ChannelAliasRepository\n\n__all__ = (\"ChannelAliasRepository\",)\n"}
{"type": "source_file", "path": "core/handler/limiterhandler.py", "content": "from gram_core.handler.limiterhandler import LimiterHandler\n\n__all__ = (\"LimiterHandler\",)\n"}
{"type": "source_file", "path": "core/base_service.py", "content": "from gram_core.base_service import BaseService, BaseServiceType, DependenceType, ComponentType, get_all_services\n\n__all__ = (\"BaseService\", \"BaseServiceType\", \"DependenceType\", \"ComponentType\", \"get_all_services\")\n"}
{"type": "source_file", "path": "core/services/__init__.py", "content": ""}
{"type": "source_file", "path": "core/services/channels/models.py", "content": "from gram_core.services.channels.models import ChannelAlias, ChannelAliasDataBase\n\n__all__ = (\"ChannelAlias\", \"ChannelAliasDataBase\")\n"}
{"type": "source_file", "path": "core/services/channels/services.py", "content": "from gram_core.services.channels.services import ChannelAliasService\n\n__all__ = (\"ChannelAliasService\",)\n"}
{"type": "source_file", "path": "core/services/cookies/cache.py", "content": "from gram_core.services.cookies.cache import PublicCookiesCache\n\n__all__ = (\"PublicCookiesCache\",)\n"}
{"type": "source_file", "path": "alembic/versions/ddcfba3c7d5c_v4.py", "content": "\"\"\"v4\n\nRevision ID: ddcfba3c7d5c\nRevises: 9e9a36470cd5\nCreate Date: 2023-02-11 17:07:18.170175\n\n\"\"\"\n\nimport json\nimport logging\nfrom base64 import b64decode\n\nimport sqlalchemy as sa\nimport sqlmodel\nfrom alembic import op\nfrom sqlalchemy import text\nfrom sqlalchemy.exc import NoSuchTableError\n\n# revision identifiers, used by Alembic.\nrevision = \"ddcfba3c7d5c\"\ndown_revision = \"9e9a36470cd5\"\nbranch_labels = None\ndepends_on = None\n\nold_cookies_database_name1 = b64decode(\"bWlob3lvX2Nvb2tpZXM=\").decode()\nold_cookies_database_name2 = b64decode(\"aG95b3ZlcnNlX2Nvb2tpZXM=\").decode()\nlogger = logging.getLogger(__name__)\n\n\ndef upgrade() -> None:\n    connection = op.get_bind()\n    # ### commands auto generated by Alembic - please adjust! ###\n    cookies_table = op.create_table(\n        \"cookies\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\"account_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\"data\", sa.JSON(), nullable=True),\n        sa.Column(\n            \"status\",\n            sa.Enum(\n                \"STATUS_SUCCESS\",\n                \"INVALID_COOKIES\",\n                \"TOO_MANY_REQUESTS\",\n                name=\"cookiesstatusenum\",\n            ),\n            nullable=True,\n        ),\n        sa.Column(\n            \"region\",\n            sa.Enum(\"NULL\", \"HYPERION\", \"HOYOLAB\", name=\"regionenum\"),\n            nullable=True,\n        ),\n        sa.Column(\"is_share\", sa.Boolean(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.Index(\"index_user_account\", \"user_id\", \"account_id\", unique=True),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    for old_cookies_database_name in (old_cookies_database_name1, old_cookies_database_name2):\n        try:\n            statement = f\"SELECT * FROM {old_cookies_database_name};\"  # skipcq: BAN-B608\n            old_cookies_table_data = connection.execute(text(statement))\n        except NoSuchTableError:\n            logger.warning(\"Table '%s' doesn't exist\", old_cookies_database_name)\n            continue\n        if old_cookies_table_data is None:\n            logger.warning(\"Old Cookies Database is None\")\n            continue\n        for row in old_cookies_table_data:\n            try:\n                user_id = row[\"user_id\"]\n                status = row[\"status\"]\n                cookies_row = row[\"cookies\"]\n                cookies_data = json.loads(cookies_row)\n                account_id = cookies_data.get(\"account_id\")\n                if account_id is None:  # Cleaning Data 清洗数据\n                    account_id = cookies_data.get(\"ltuid\")\n                else:\n                    account_mid_v2 = cookies_data.get(\"account_mid_v2\")\n                    if account_mid_v2 is not None:\n                        cookies_data.pop(\"account_id\")\n                        cookies_data.setdefault(\"account_uid_v2\", account_id)\n                if old_cookies_database_name == old_cookies_database_name1:\n                    region = \"HYPERION\"\n                else:\n                    region = \"HOYOLAB\"\n                if account_id is None:\n                    logger.warning(\"Can not get user account_id, user_id :%s\", user_id)\n                    continue\n                insert = cookies_table.insert().values(\n                    user_id=int(user_id),\n                    account_id=int(account_id),\n                    status=status,\n                    data=cookies_data,\n                    region=region,\n                    is_share=True,\n                )\n                with op.get_context().autocommit_block():\n                    connection.execute(insert)\n            except Exception as exc:  # pylint: disable=W0703\n                logger.error(\n                    \"Process %s->cookies Exception\", old_cookies_database_name, exc_info=exc\n                )  # pylint: disable=W0703\n    players_table = op.create_table(\n        \"players\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\"account_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\"player_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\n            \"region\",\n            sa.Enum(\"NULL\", \"HYPERION\", \"HOYOLAB\", name=\"regionenum\"),\n            nullable=True,\n        ),\n        sa.Column(\"is_chosen\", sa.Boolean(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.Index(\"index_user_account_player\", \"user_id\", \"account_id\", \"player_id\", unique=True),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n\n    try:\n        statement = \"SELECT * FROM user;\"\n        old_user_table_data = connection.execute(text(statement))\n    except NoSuchTableError:\n        logger.warning(\"Table 'user' doesn't exist\")\n        return  # should not happen\n    if old_user_table_data is not None:\n        for row in old_user_table_data:\n            try:\n                user_id = row[\"user_id\"]\n                y_uid = row[\"yuanshen_uid\"]\n                g_uid = row[\"genshin_uid\"]\n                region = row[\"region\"]\n                if y_uid:\n                    account_id = None\n                    cookies_row = connection.execute(\n                        cookies_table.select()\n                        .where(cookies_table.c.user_id == user_id)\n                        .where(cookies_table.c.region == \"HYPERION\")\n                    ).first()\n                    if cookies_row is not None:\n                        account_id = cookies_row[\"account_id\"]\n                    insert = players_table.insert().values(\n                        user_id=int(user_id),\n                        player_id=int(y_uid),\n                        is_chosen=(region == \"HYPERION\"),\n                        region=\"HYPERION\",\n                        account_id=account_id,\n                    )\n                    with op.get_context().autocommit_block():\n                        connection.execute(insert)\n                if g_uid:\n                    account_id = None\n                    cookies_row = connection.execute(\n                        cookies_table.select()\n                        .where(cookies_table.c.user_id == user_id)\n                        .where(cookies_table.c.region == \"HOYOLAB\")\n                    ).first()\n                    if cookies_row is not None:\n                        account_id = cookies_row[\"account_id\"]\n                    insert = players_table.insert().values(\n                        user_id=int(user_id),\n                        player_id=int(g_uid),\n                        is_chosen=(region == \"HOYOLAB\"),\n                        region=\"HOYOLAB\",\n                        account_id=account_id,\n                    )\n                    with op.get_context().autocommit_block():\n                        connection.execute(insert)\n            except Exception as exc:  # pylint: disable=W0703\n                logger.error(\"Process user->player Exception\", exc_info=exc)\n    else:\n        logger.warning(\"Old User Database is None\")\n\n    users_table = op.create_table(\n        \"users\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=False, primary_key=True),\n        sa.Column(\n            \"permissions\",\n            sa.Enum(\"OWNER\", \"ADMIN\", \"PUBLIC\", name=\"permissionsenum\"),\n            nullable=True,\n        ),\n        sa.Column(\"locale\", sqlmodel.AutoString(), nullable=True),\n        sa.Column(\"is_banned\", sa.BigInteger(), nullable=True),\n        sa.Column(\"ban_end_time\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"ban_start_time\", sa.DateTime(timezone=True), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.UniqueConstraint(\"user_id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n\n    try:\n        statement = \"SELECT * FROM admin;\"\n        old_user_table_data = connection.execute(text(statement))\n    except NoSuchTableError:\n        logger.warning(\"Table 'admin' doesn't exist\")\n        return  # should not happen\n    if old_user_table_data is not None:\n        for row in old_user_table_data:\n            try:\n                user_id = row[\"user_id\"]\n                insert = users_table.insert().values(\n                    user_id=int(user_id),\n                    permissions=\"ADMIN\",\n                )\n                with op.get_context().autocommit_block():\n                    connection.execute(insert)\n            except Exception as exc:  # pylint: disable=W0703\n                logger.error(\"Process admin->users Exception\", exc_info=exc)\n    else:\n        logger.warning(\"Old User Database is None\")\n\n    op.create_table(\n        \"players_info\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\"player_id\", sa.BigInteger(), nullable=False),\n        sa.Column(\"nickname\", sqlmodel.AutoString(length=128), nullable=True),\n        sa.Column(\"signature\", sqlmodel.AutoString(length=255), nullable=True),\n        sa.Column(\"hand_image\", sa.Integer(), nullable=True),\n        sa.Column(\"name_card\", sa.Integer(), nullable=True),\n        sa.Column(\"extra_data\", sa.VARCHAR(length=512), nullable=True),\n        sa.Column(\n            \"create_time\",\n            sa.DateTime(timezone=True),\n            nullable=True,\n        ),\n        sa.Column(\"last_save_time\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_update\", sa.Boolean(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.Index(\"index_user_player\", \"user_id\", \"player_id\", unique=True),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n\n    op.drop_table(old_cookies_database_name1)\n    op.drop_table(old_cookies_database_name2)\n    op.drop_table(\"admin\")\n    context = op.get_context()\n    if context.dialect.name == \"sqlite\":\n        with op.batch_alter_table(\"sign\") as batch_op:\n            batch_op.drop_constraint(\"sign_1\", type_=\"foreignkey\")\n        op.drop_table(\"user\")\n        return\n    op.drop_constraint(\"sign_1\", \"sign\", type_=\"foreignkey\")\n    op.drop_index(\"sign_1\", table_name=\"sign\")\n    op.drop_table(\"user\")\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    op.create_table(\n        \"user\",\n        sa.Column(\"region\", sa.Enum(\"NULL\", \"HYPERION\", \"HOYOLAB\", name=\"regionenum\"), nullable=True),\n        sa.Column(\"id\", sa.INTEGER(), autoincrement=True, nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), autoincrement=False, nullable=False),\n        sa.Column(\"yuanshen_uid\", sa.INTEGER(), autoincrement=False, nullable=True),\n        sa.Column(\"genshin_uid\", sa.INTEGER(), autoincrement=False, nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_collate=\"utf8mb4_general_ci\",\n        mysql_default_charset=\"utf8mb4\",\n        mysql_engine=\"InnoDB\",\n    )\n    op.create_index(\"user_id\", \"user\", [\"user_id\"], unique=False)\n    op.create_table(\n        \"admin\",\n        sa.Column(\"id\", sa.INTEGER(), autoincrement=True, nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), autoincrement=False, nullable=False),\n        sa.ForeignKeyConstraint([\"user_id\"], [\"user.user_id\"], name=\"admin_ibfk_1\"),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_collate=\"utf8mb4_general_ci\",\n        mysql_default_charset=\"utf8mb4\",\n        mysql_engine=\"InnoDB\",\n    )\n    op.create_table(\n        old_cookies_database_name1,\n        sa.Column(\"cookies\", sa.JSON(), nullable=True),\n        sa.Column(\n            \"status\",\n            sa.Enum(\"STATUS_SUCCESS\", \"INVALID_COOKIES\", \"TOO_MANY_REQUESTS\", name=\"cookiesstatusenum\"),\n            nullable=True,\n        ),\n        sa.Column(\"id\", sa.INTEGER(), autoincrement=True, nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), autoincrement=False, nullable=True),\n        sa.ForeignKeyConstraint([\"user_id\"], [\"user.user_id\"], name=\"mihoyo_cookies_ibfk_1\"),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_collate=\"utf8mb4_general_ci\",\n        mysql_default_charset=\"utf8mb4\",\n        mysql_engine=\"InnoDB\",\n    )\n    op.create_table(\n        old_cookies_database_name2,\n        sa.Column(\"cookies\", sa.JSON(), nullable=True),\n        sa.Column(\n            \"status\",\n            sa.Enum(\"STATUS_SUCCESS\", \"INVALID_COOKIES\", \"TOO_MANY_REQUESTS\", name=\"cookiesstatusenum\"),\n            nullable=True,\n        ),\n        sa.Column(\"id\", sa.INTEGER(), autoincrement=True, nullable=False),\n        sa.Column(\"user_id\", sa.BigInteger(), autoincrement=False, nullable=True),\n        sa.ForeignKeyConstraint([\"user_id\"], [\"user.user_id\"], name=\"hoyoverse_cookies_ibfk_1\"),\n        sa.PrimaryKeyConstraint(\"id\"),\n        mysql_collate=\"utf8mb4_general_ci\",\n        mysql_default_charset=\"utf8mb4\",\n        mysql_engine=\"InnoDB\",\n    )\n    context = op.get_context()\n    if context.dialect.name == \"sqlite\":\n        with op.batch_alter_table(\"sign\") as batch_op:\n            batch_op.create_foreign_key(\"sign_1\", type_=\"foreignkey\")\n    else:\n        op.create_foreign_key(\"sign_1\", \"sign\", \"user\", [\"user_id\"], [\"user_id\"])\n        op.create_index(\"sign_1\", \"sign\", [\"user_id\"], unique=False)\n    op.drop_table(\"users\")\n    op.drop_table(\"players\")\n    op.drop_table(\"cookies\")\n    op.drop_table(\"players_info\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "core/handler/__init__.py", "content": ""}
{"type": "source_file", "path": "alembic/versions/369fb74daad9_groups_ignore.py", "content": "\"\"\"groups_ignore\n\nRevision ID: 369fb74daad9\nRevises: cb37027ecae8\nCreate Date: 2024-03-25 17:29:35.378726\n\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n# revision identifiers, used by Alembic.\nrevision = \"369fb74daad9\"\ndown_revision = \"cb37027ecae8\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(\"groups\", sa.Column(\"is_ignore\", sa.Integer(), nullable=True))\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_column(\"groups\", \"is_ignore\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "alembic/versions/cb37027ecae8_channel_alias.py", "content": "\"\"\"channel_alias\n\nRevision ID: cb37027ecae8\nRevises: 89dcb9109475\nCreate Date: 2024-03-10 17:08:14.167818\n\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n# revision identifiers, used by Alembic.\nrevision = \"cb37027ecae8\"\ndown_revision = \"89dcb9109475\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        \"channel_alias\",\n        sa.Column(\"id\", sa.Integer(), autoincrement=True, nullable=False),\n        sa.Column(\"chat_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\"user_id\", sa.BigInteger(), nullable=True),\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_valid\", sa.Boolean(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.UniqueConstraint(\"chat_id\"),\n        mysql_charset=\"utf8mb4\",\n        mysql_collate=\"utf8mb4_general_ci\",\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table(\"channel_alias\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "core/services/channels/__init__.py", "content": "\"\"\"CookieService\"\"\"\n\nfrom core.services.channels.services import ChannelAliasService\n\n__all__ = (\"ChannelAliasService\",)\n"}
{"type": "source_file", "path": "core/services/devices/__init__.py", "content": "\"\"\"DeviceService\"\"\"\n\nfrom core.services.devices.services import DevicesService\n\n__all__ = (\"DevicesService\",)\n"}
{"type": "source_file", "path": "core/services/cookies/repositories.py", "content": "from gram_core.services.cookies.repositories import CookiesRepository\n\n__all__ = (\"CookiesRepository\",)\n"}
{"type": "source_file", "path": "core/services/gacha_log_rank/__init__.py", "content": ""}
{"type": "source_file", "path": "core/services/devices/services.py", "content": "from gram_core.services.devices.services import DevicesService\n\n__all__ = (\"DevicesService\",)\n"}
{"type": "source_file", "path": "core/services/gacha_log_rank/cache.py", "content": "from gram_core.services.gacha_log_rank.cache import GachaLogRankCache\n\n__all__ = (\"GachaLogRankCache\",)\n"}
{"type": "source_file", "path": "core/services/devices/repositories.py", "content": "from gram_core.services.devices.repositories import DevicesRepository\n\n__all__ = (\"DevicesRepository\",)\n"}
{"type": "source_file", "path": "core/services/devices/models.py", "content": "from gram_core.services.devices.models import Devices, DevicesDataBase\n\n__all__ = (\"Devices\", \"DevicesDataBase\")\n"}
{"type": "source_file", "path": "core/services/cookies/services.py", "content": "from typing import Optional\n\nfrom gram_core.base_service import BaseService\nfrom gram_core.basemodel import RegionEnum\nfrom gram_core.services.cookies.error import CookieServiceError\nfrom gram_core.services.cookies.models import CookiesStatusEnum, CookiesDataBase as Cookies\nfrom gram_core.services.cookies.services import (\n    CookiesService,\n    PublicCookiesService as BasePublicCookiesService,\n    NeedContinue,\n)\n\nfrom simnet import GenshinClient, Region, Game\nfrom simnet.errors import InvalidCookies, TooManyRequests, BadRequest as SimnetBadRequest, NeedChallenge, InvalidDevice\n\nfrom utils.log import logger\n\n__all__ = (\"CookiesService\", \"PublicCookiesService\")\n\n\nclass PublicCookiesService(BaseService, BasePublicCookiesService):\n    async def initialize(self) -> None:\n        logger.info(\"正在初始化公共Cookies池\")\n        await self.refresh()\n        logger.success(\"刷新公共Cookies池成功\")\n\n    async def check_public_cookie(self, region: RegionEnum, cookies: Cookies, public_id: int):  # skipcq: PY-R1000 #\n        device_id: Optional[str] = None\n        device_fp: Optional[str] = None\n        devices = await self.devices_repository.get(cookies.account_id)\n        if devices:\n            device_id = devices.device_id\n            device_fp = devices.device_fp\n\n        if region == RegionEnum.HYPERION:\n            client = GenshinClient(\n                cookies=cookies.data, region=Region.CHINESE, device_id=device_id, device_fp=device_fp\n            )\n        elif region == RegionEnum.HOYOLAB:\n            client = GenshinClient(\n                cookies=cookies.data, region=Region.OVERSEAS, lang=\"zh-cn\", device_id=device_id, device_fp=device_fp\n            )\n        else:\n            raise CookieServiceError\n        try:\n            if client.account_id is None:\n                raise RuntimeError(\"account_id not found\")\n            record_cards = await client.get_record_cards()\n            for record_card in record_cards:\n                if record_card.game == Game.GENSHIN:\n                    await client.get_partial_genshin_user(record_card.uid)\n                    break\n            else:\n                accounts = await client.get_game_accounts()\n                for account in accounts:\n                    if account.game == Game.GENSHIN:\n                        await client.get_partial_genshin_user(account.uid)\n                        break\n        except InvalidCookies as exc:\n            if exc.ret_code in (10001, -100):\n                logger.warning(\"用户 [%s] Cookies无效\", public_id)\n            elif exc.ret_code == 10103:\n                logger.warning(\"用户 [%s] Cookies有效，但没有绑定到游戏帐户\", public_id)\n            else:\n                logger.warning(\"Cookies无效 \")\n                logger.exception(exc)\n            cookies.status = CookiesStatusEnum.INVALID_COOKIES\n            await self._repository.update(cookies)\n            await self._cache.delete_public_cookies(cookies.user_id, region)\n            raise NeedContinue\n        except TooManyRequests:\n            logger.warning(\"用户 [%s] 查询次数太多或操作频繁\", public_id)\n            cookies.status = CookiesStatusEnum.TOO_MANY_REQUESTS\n            await self._repository.update(cookies)\n            await self._cache.delete_public_cookies(cookies.user_id, region)\n            raise NeedContinue\n        except NeedChallenge:\n            logger.warning(\"用户 [%s] 触发验证\", public_id)\n            await self.set_device_valid(client.account_id, False)\n            await self._cache.delete_public_cookies(cookies.user_id, region)\n            raise NeedContinue\n        except InvalidDevice:\n            logger.warning(\"用户 [%s] 设备信息无效\", public_id)\n            await self.set_device_valid(client.account_id, False)\n            await self._cache.delete_public_cookies(cookies.user_id, region)\n            raise NeedContinue\n        except SimnetBadRequest as exc:\n            if \"invalid content type\" in exc.message:\n                raise exc\n            logger.warning(\"用户 [%s] 获取账号信息发生错误，错误信息为\", public_id)\n            logger.exception(exc)\n            await self._cache.delete_public_cookies(cookies.user_id, region)\n            raise NeedContinue\n        except RuntimeError as exc:\n            if \"account_id not found\" in str(exc):\n                cookies.status = CookiesStatusEnum.INVALID_COOKIES\n                await self._repository.update(cookies)\n                await self._cache.delete_public_cookies(cookies.user_id, region)\n                raise NeedContinue\n            raise exc\n        except Exception as exc:\n            await self._cache.delete_public_cookies(cookies.user_id, region)\n            raise exc\n        finally:\n            await client.shutdown()\n"}
