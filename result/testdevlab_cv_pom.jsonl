{"repo_info": {"repo_name": "cv_pom", "repo_owner": "testdevlab", "repo_url": "https://github.com/testdevlab/cv_pom"}}
{"type": "source_file", "path": "cv_pom/frameworks/adb.py", "content": "import time\n\nfrom pathlib import Path\nfrom cv_pom.cv_pom_driver import CVPOMDriver\nimport subprocess as sp\nimport cv2 as cv\n\nfrom numpy import ndarray\n\n\nclass AdbCVPOMDriver(CVPOMDriver):\n    def __init__(self, model_path: Path | str, url: str = None, udid: str = None) -> None:\n        super().__init__(model_path)\n        self.__udid = \"\"\n        if udid is not None:\n            self.__udid = f\"-s {udid} \"\n        if url is not None:\n            sp.run(f\"adb {self.__udid}shell am start -a android.intent.action.VIEW -d {url}\", shell=True)\n\n    def _click_coordinates(self, x: int, y: int, times=1, interval=0, button=\"PRIMARY\"):\n        for _ in range(times):\n            sp.run(f\"adb {self.__udid}shell input tap {x} {y}\", shell=True)\n            time.sleep(interval)\n\n    def _get_screenshot(self) -> ndarray:\n        sp.run(f\"adb {self.__udid}exec-out screencap -p > screen.png\", shell=True)\n        return cv.imread(\"screen.png\")\n\n    def _send_keys(self, keys: str):\n        sp.run(f\"adb {self.__udid}shell input text \\\"{keys}\\\"\", shell=True)\n\n    def _drag_drop(self, x: int, y: int, x_end: int, y_end: int, duration=0.1, button=\"PRIMARY\"):\n        sp.run(f\"adb {self.__udid}shell input touchscreen swipe {x} {y} {x_end} {y_end}\", shell=True)\n\n    def _hover_coordinates(self, x: int, y: int):\n        print(\"doesn't exist for ADB driver\")\n\n    def _swipe_coordinates(self, coords: tuple = None, direction: str = None, duration=None):\n        # duration var doesn't have an effect in this driver\n\n        if coords is not None:\n            x, y, x_end, y_end = coords\n        else:\n            h, w, ch = self._get_screenshot().shape\n            if direction.lower() == \"down\":\n                x, y, x_end, y_end = int(w / 2), int(4 * h / 6), int(w / 2), int(2 * h / 6)\n            elif direction.lower() == \"up\":\n                x, y, x_end, y_end = int(w / 2), int(2 * h / 6), int(w / 2), int(4 * h / 6)\n            elif direction.lower() == \"left\":\n                x, y, x_end, y_end = int(w / 4), int(h / 2), int(3 * w / 4), int(h / 2)\n            elif direction.lower() == \"right\":\n                x, y, x_end, y_end = int(3 * w / 4), int(h / 2), int(w / 4), int(h / 2)\n            else:\n                raise Exception(f\"direction has to be one of this: down, up, left, right. Was {direction}\")\n\n        sp.run(f\"adb {self.__udid}shell input touchscreen swipe {x} {y} {x_end} {y_end}\", shell=True)\n"}
{"type": "source_file", "path": "cv_pom/frameworks/__init__.py", "content": "from .testui import TestUICVPOMDriver\nfrom .os_gui import DesktopCVPOMDriver\nfrom .adb import AdbCVPOMDriver\n\n__all__ = [\"TestUICVPOMDriver\", \"DesktopCVPOMDriver\", \"AdbCVPOMDriver\"]\n"}
{"type": "source_file", "path": "cv_pom/cv_pom_driver.py", "content": "from __future__ import annotations\nimport time\nimport logging\nimport numpy as np\n\nfrom typing import Callable, Optional, Tuple\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom cv_pom.cv_pom import POM, POMElement\n\nempty_pom_element = POMElement(\"\", \"\", (0, 0), (0, 0), (0, 0), (0, 0, 0, 0), 0, {})\n\n# create logger\nlogger = logging.getLogger('cv_pom logger')\nlogger.setLevel(logging.DEBUG)\n# create console handler and set level to debug\nch = logging.StreamHandler()\nch.setLevel(logging.DEBUG)\n# create formatter\nformatter = logging.Formatter('[%(asctime)s] - %(levelname)s - %(message)s')\n# add formatter to ch\nch.setFormatter(formatter)\n# add ch to logger\nlogger.addHandler(ch)\n\n\nclass CVPOMDriverElement(POMElement):\n    \"\"\"This class extends POMElement by adding methods for interactions\"\"\"\n\n    def __init__(self, element: POMElement, query: dict, driver: \"CVPOMDriver\") -> None:\n        super().__init__(**element.as_dict())  # Init POMElement part (parent class)\n        self._query = query\n        self._driver = driver\n\n    def click(self, timeout=10, offset=(0, 0), times=1, interval=0, button=\"PRIMARY\") -> CVPOMDriverElement:\n        \"\"\"Click in the center of an element.\n\n        Will wait for element to be visible first.\n\n        Args:\n            timeout: Max wait time in seconds. Defaults to 10.\n            interval: interval when click times is more than 1\n            button: button to use for clicking\n            times: defaults to 1, and 2 performs double click for those frameworks that allows it\n            offset: Offset from the coordinates of the element (AX, AY)\n\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        self.wait_visible(timeout)\n        x, y = self.center\n        ax, ay = offset\n        logger.info(\n            f\"action: click - element coords: {self.center} - element label: \\\"{self.label}\\\" - element attrs: {self.attrs}\"\n        )\n        self._driver._click_coordinates(x + ax, y + ay, times, interval, button)\n\n        return self\n\n    def wait_visible(self, timeout=10) -> CVPOMDriverElement:\n        \"\"\"Wait until element is visible\n\n        Args:\n            timeout: Max wait time in seconds. Defaults to 10.\n\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        if self.center == (0, 0):\n            elements: list[CVPOMDriverElement] = self._driver.wait_until(\n                lambda: self._driver.elements(self._query),\n                lambda els: len(els),\n                f\"Element '{self._query}' not found after {timeout}s\",\n                timeout\n            )\n            self.__init__(elements[0], self._query, self._driver)\n\n        logger.info(\n            f\"action: wait_visible - element coords: {self.center} - \"\n            f\"element label: \\\"{self.label}\\\" - element attrs: {self.attrs}\"\n        )\n\n        return self\n\n    def wait_not_visible(self, timeout=10) -> CVPOMDriverElement:\n        \"\"\"Wait until element is not visible\n\n        Args:\n            timeout: Max wait time in seconds. Defaults to 10.\n\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        self._driver.wait_until(\n            lambda: self._driver.elements(self._query),\n            lambda els: len(els) == 0,\n            f\"Element '{self._query}' still visible after {timeout}s\",\n            timeout\n        )\n\n        logger.info(\n            f\"action: wait_not_visible - element coords: {self.center} - \"\n            f\"element label: \\\"{self.label}\\\" - element attrs: {self.attrs}\"\n        )\n\n        return self\n\n    def send_keys(self, keys: str, offset=(0, 0)) -> CVPOMDriverElement:\n        \"\"\"Send keys.\n\n        Will wait for element to be visible first.\n\n        Args:\n            keys: Key sequence (string) to send\n            offset: Offset from the coordinates of the element (AX, AY)\n\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        self.click(offset=offset)  # Focus the input element\n        logger.info(\n            f\"action: send_keys - element coords: {self.center} - \"\n            f\"element label: \\\"{self.label}\\\" - element attrs: {self.attrs}\"\n        )\n        self._driver._send_keys(keys)\n\n        return self\n\n    def swipe(self, offset: tuple = None, el: CVPOMDriverElement = None) -> CVPOMDriverElement:\n        \"\"\"Swipes or scrolls using coordinates, direction or an element.\n\n        Args:\n            el: if is not None then it will scroll from the el1 to the el\n            offset: if is not None then it will scroll from the el1 to the offset marked by (x, y)\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        el1 = self.wait_visible()\n        if offset is not None:\n            x, y = el1.center\n            delta_x, delta_y = offset\n            x_end, y_end = x + delta_x, y + delta_y\n        else:\n            x, y = el1.center\n            x_end, y_end = el.wait_visible().center\n        self._driver._swipe_coordinates(coords=(x, y, x_end, y_end))\n\n        return el1\n\n    def swipe_to(self, direction: str, limit: int = 50) -> CVPOMDriverElement:\n        \"\"\"Swipes or scrolls direction until it finds the element.\n\n        Args:\n            direction: if is not none then will scroll/swipe \"up\", \"down\", \"left\" and \"right\"\n            limit: amount of scrolls so that it does not loop infinitely, defaults to 50\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        i = 0\n        elements = self._driver.elements(self._query)\n        while len(elements) == 0 and i < limit:\n            self._driver._swipe_coordinates(direction=direction)\n            elements = self._driver.elements(self._query)\n            i += 1\n\n        el = self.wait_visible()\n        return el\n\n    def hover(self, timeout=10, offset=(0, 0)) -> CVPOMDriverElement:\n        \"\"\"Hover in the center of an element.\n\n        Will wait for element to be visible first.\n\n        Args:\n            timeout: Max wait time in seconds. Defaults to 10.\n            offset: Offset from the coordinates of the element (AX, AY)\n\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        self.wait_visible(timeout)\n        x, y = self.center\n        ax, ay = offset\n        logger.info(\n            f\"action: hover - element coords: {self.center} - element label: {self.label} - element attrs: {self.attrs}\"\n        )\n        self._driver._hover_coordinates(x + ax, y + ay)\n\n        return self\n\n    def drag_drop(self,\n                  end_coords: Optional[Tuple[int, int]] = None,\n                  delta: Optional[Tuple[int, int]] = None,\n                  duration=0.1\n                  ) -> CVPOMDriverElement:\n        \"\"\"Drag and Drop from an element to coordinates or a delta distance in pixels.\n\n        Will wait for element to be visible.\n\n        Args:\n            offset: Offset from the coordinates of the element (AX, AY)\n            end_coords: coordinates to end (optional)\n            delta: distance in pixels from the element (optional)\n            duration: duration for the action to take place\n\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        if end_coords is None and delta is None:\n            logger.error(\"action: drag_drop - either end_coords or delta must be specified - action not performed\")\n            return self\n\n        if end_coords is None:\n            self.wait_visible()\n            x, y = self.center\n            delta_x, delta_y = delta\n            x_end, y_end = x + delta_x, y + delta_y\n        else:\n            self.wait_visible()\n            x, y = self.center\n            x_end, y_end = end_coords\n\n        logger.info(f\"action: drag_drop - start coords: {(x, y)} - end coords: {(x_end, y_end)}\")\n        self._driver._drag_drop(x, y, x_end, y_end, duration)\n\n        return self\n\n    def drag_drop_to(self,\n                     start_coords: Optional[Tuple[int, int]] = None,\n                     delta: Optional[Tuple[int, int]] = None,\n                     duration=0.1\n                     ) -> CVPOMDriverElement:\n        \"\"\"Drag and Drop from coordinates or a delta distance in pixels to an element.\n\n        Will wait for element to be visible.\n\n        Args:\n            offset: Offset from the coordinates of the element (AX, AY)\n            start_coords: coordinates to start from (optional)\n            delta: distance in pixels from the element (optional)\n            duration: duration for the action to take place\n\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        if start_coords is None and delta is None:\n            logger.error(\"action: drag_drop - either start_coords or delta must be specified - action not performed\")\n            return self\n\n        if start_coords is None:\n            self.wait_visible()\n            x_end, y_end = self.center\n            delta_x, delta_y = delta\n            x, y = x_end + delta_x, y_end + delta_y\n\n        else:\n            self.wait_visible()\n            x_end, y_end = self.center\n            x, y = start_coords\n\n        logger.info(f\"action: drag_drop - start coords: {(x, y)} - end coords: {(x_end, y_end)}\")\n        self._driver._drag_drop(x, y, x_end, y_end, duration)\n\n        return self\n\n    def press(self,\n              coords: Optional[Tuple[int, int]] = None, duration=0.1, timeout=10, offset=(0, 0), button=\"PRIMARY\"\n              ) -> CVPOMDriverElement:\n        \"\"\"Drag and Drop from an element to coordinates or a delta distance in pixels.\n\n        Will wait for element to be visible.\n\n        Args:\n            offset: Offset from the coordinates of the element (AX, AY)\n            coords: coordinates to click (optional)\n            offset: distance in pixels from the element (optional)\n            duration: duration for the action to take place\n            timeout: Max wait time in seconds. Defaults to 10.\n            button: button to use for clicking\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n\n        if coords is None:\n            self.wait_visible(timeout=timeout)\n            x, y = self.center\n        else:\n            x, y = coords\n\n        ax, ay = offset\n        x, y = x + ax, y + ay\n        logger.info(f\"action: press - coords: {(x, y)} - duration - {duration}\")\n        self._driver._drag_drop(x, y, x, y, duration, button)\n\n        return self\n\n\nclass CVPOMPageDriver:\n    def __init__(self, pom: POM, driver: \"CVPOMDriver\", **kwargs) -> None:\n        self._pom = pom\n        self._driver = driver\n        self.kwargs = kwargs\n\n    def element(self, query: dict) -> CVPOMDriverElement:\n        elements = self._pom.get_elements(query)\n\n        if len(elements):\n            return CVPOMDriverElement(elements[0], query, self._driver)\n\n        # Even if element wasn't found, returns an Element. It can still be used to wait.\n        return CVPOMDriverElement(empty_pom_element, query, self._driver)\n\n    def elements(self, query: dict) -> list[CVPOMDriverElement]:\n        elements = self._pom.get_elements(query)\n\n        return [CVPOMDriverElement(el, query, self._driver) for el in elements]\n\n\nclass CVPOMDriver(ABC):\n    \"\"\"Driver class used to find elements in the POM\"\"\"\n\n    def __init__(self, model_path: Path | str, **kwargs) -> None:\n        self._pom = POM(model_path)\n        self.kwargs = kwargs\n\n    def element(self, query: dict) -> CVPOMDriverElement:\n        \"\"\"Get a single element.\n\n        This doesn't wait for element to be visible and will not fail.\n        The returned CVPOMDriverElement object will be interactable regardless\n        of the existence of the element at the time of calling this method.\n\n        Args:\n            query: Query dictionary\n\n        Returns:\n            CVPOMDriverElement\n        \"\"\"\n        ocr = None\n        if \"text\" in query:\n            ocr = {'paragraph': False}\n            if self.kwargs and self.kwargs['ocr']:\n                ocr = self.kwargs['ocr']\n        pom = self._pom.convert_to_cvpom(self._get_screenshot(), ocr)\n\n        return CVPOMPageDriver(pom, self).element(query)\n\n    def elements(self, query: dict) -> list[CVPOMDriverElement]:\n        \"\"\"Get a list of elements.\n\n        Args:\n            query: Query dictionary\n\n        Returns:\n            list[CVPOMDriverElement]: List of elements\n        \"\"\"\n        ocr = None\n        if \"text\" in query or \"ocr_element\" in query:\n            ocr = {'paragraph': False}\n            if self.kwargs and self.kwargs['ocr']:\n                ocr = self.kwargs['ocr']\n        pom = self._pom.convert_to_cvpom(self._get_screenshot(), ocr)\n\n        return CVPOMPageDriver(pom, self).elements(query)\n\n    def get_page(self) -> CVPOMPageDriver:\n        \"\"\"Get full page POM.\n\n        Args:\n\n        Returns:\n            POM: full CV_POM\n        \"\"\"\n        if self.kwargs:\n            pom = self._pom.convert_to_cvpom(self._get_screenshot(), self.kwargs['ocr'])\n        else:\n            pom = self._pom.convert_to_cvpom(self._get_screenshot())\n\n        return CVPOMPageDriver(pom, self)\n\n    def wait_until(self, func: Callable, condition: Callable, error_msg: str, timeout: float):\n        \"\"\"Wait until conditions passes and function is not raising errors.\n\n        Args:\n            func: Function to execute\n            condition: Condition that needs to be satisfied (uses return value of \"func\" as parameter)\n            error_msg: Error message in case of failure\n            timeout: Timeout in seconds\n\n        Raises:\n            Exception: Timeout\n\n        Returns:\n            Any: Whatever the given function returns\n        \"\"\"\n        error = None\n        timeout_start = time.time()\n        while time.time() < timeout_start + timeout:\n            try:\n                error = None\n                result = func()\n                if condition(result):\n                    return result\n            except Exception as e:\n                error = e\n\n        if error:\n            raise Exception(f\"{error_msg}, error: {error}\")\n        else:\n            raise Exception(f\"{error_msg}\")\n\n    @abstractmethod\n    def _get_screenshot(self) -> np.ndarray:\n        pass\n\n    @abstractmethod\n    def _click_coordinates(self, x: int, y: int, times=1, interval=0, button=\"PRIMARY\"):\n        pass\n\n    @abstractmethod\n    def _send_keys(self, keys: str):\n        pass\n\n    @abstractmethod\n    def _swipe_coordinates(self, coords: tuple = None, direction: str = None, duration: float = 0.1):\n        pass\n\n    @abstractmethod\n    def _hover_coordinates(self, x: int, y: int):\n        pass\n\n    @abstractmethod\n    def _drag_drop(self, x: int, y: int, x_end: int, y_end: int, duration=0.1, button=\"PRIMARY\"):\n        pass\n"}
{"type": "source_file", "path": "main.py", "content": "import argparse\nimport os\nimport sys\nimport cv2 as cv\nfrom cv_pom.cv_pom import POM\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\"CV POM wrapper\")\n    parser.add_argument(\"--model\", help=\"The CV model to be used [path]\")\n    parser.add_argument(\"--media\", help=\"The media file [path]\")\n    parsed_args = parser.parse_args()\n\n    if not parsed_args.model or not parsed_args.media:\n        print(\"Please specify both the model and media\")\n        exit(1)\n\n    parsed_args.model = os.path.expanduser(parsed_args.model)\n    parsed_args.media = os.path.expanduser(parsed_args.media)\n    if not os.path.exists(parsed_args.model):\n        print(\"The model path does not exist\")\n        exit(1)\n\n    if not os.path.exists(parsed_args.media):\n        print(\"The media path does not exist\")\n        exit(1)\n\n    return parsed_args\n\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    cv_pom = POM(args.model)\n    ocr_props_comb = {'paragraph': False}\n    cv_pom.convert_to_cvpom(args.media, ocr_props_comb)\n\n    if len(cv_pom.get_elements()) == 0:\n        print(f\"No object was found in the image: {args.media}\")\n        sys.exit()\n\n    print(cv_pom.to_json())\n\n    cv.imshow(\"Annotated image\", cv_pom.annotated_frame)\n    cv.waitKey(0)\n"}
{"type": "source_file", "path": "cv_pom/cv_pom.py", "content": "from __future__ import annotations\nimport dataclasses\nfrom dataclasses import dataclass\nimport json\nfrom pathlib import Path\nfrom typing import Any\nimport numpy as np\nfrom ultralytics import YOLO\nimport cv2 as cv\nimport easyocr\nfrom ultralytics.engine.results import Results\n\n\n@dataclass\nclass QueryValue:\n    value: str\n    case_sensitive: bool = True\n    contains: bool = False\n\n\n@dataclass\nclass Query:\n    label: QueryValue | None = None\n    text: QueryValue | None = None\n    parent: Query | None = None\n    child: Query | None = None\n    left: Query | None = None\n    right: Query | None = None\n    up: Query | None = None\n    down: Query | None = None\n\n\n@dataclass\nclass POMElement:\n    id: str\n    label: str\n    coords_tl: tuple[int, int]\n    coords_br: tuple[int, int]\n    center: tuple[int, int]\n    bounding_rect: tuple[int, int, int, int]\n    confidence: float\n    attrs: dict[str, Any]\n\n    def as_dict(self):\n        return dataclasses.asdict(self)\n\n    def __eq__(self, other):\n        if not isinstance(other, POMElement):\n            return False\n        return (self.id == other.id and self.label == other.label and\n                self.coords_tl == other.coords_tl and self.coords_br == other.coords_br and\n                self.center == other.center and self.bounding_rect == other.bounding_rect and\n                self.confidence == other.confidence and self.attrs == other.attrs)\n\n    def __hash__(self):\n        return hash((self.id, self.label, self.coords_tl, self.coords_br,\n                     self.center, self.bounding_rect, self.confidence,\n                     frozenset(self.attrs.items())))\n\n\nclass POM:\n    \"\"\"CV POM (Page Object Model) class.\n\n    Used to convert image source into POM and then query the elements.\n    \"\"\"\n\n    def __init__(self, model_path: str | Path) -> None:\n        self.model = YOLO(model_path)\n        self.elements: list[POMElement] = []\n        self.annotated_frame: np.ndarray = None\n        self._reader = easyocr.Reader(['en'])\n\n    def convert_to_cvpom(self, source, ocr_props=None) -> POM:\n        \"\"\"Convert image to CV POM.\n\n        Args:\n            source: Image source, supports same data types as YOLO \"predict\" method\n            ocr_props: properties for OCR to read text. Defaults to None.\n\n        Returns:\n            POM: self\n        \"\"\"\n        self.elements = []\n        self.annotated_frame = None\n\n        #  Object detection\n        self.elements = self._object_detection(source)\n\n        # Optical character recognition\n        if ocr_props:\n            ocr_props_comb = {'image': source, 'batch_size': 3, 'canvas_size': 1200, 'paragraph': False}\n            for prop in ocr_props:\n                ocr_props_comb[prop] = ocr_props[prop]\n            ref_elements_txt = []  # [([Coordinates], Text)]\n            output_txts = self._reader.readtext(**ocr_props_comb)\n            for output_txt in output_txts:\n                coordinates = [output_txt[0][0][0], output_txt[0][0][1], output_txt[0][2][0], output_txt[0][2][1]]\n                ref_elements_txt.append([[int(x) for x in coordinates], output_txt[1]])\n            # overlapping\n            for i in range(len(self.elements)):\n                output_overlap = self._find_overlapping_rects([\n                    self.elements[i].coords_tl[0],\n                    self.elements[i].coords_tl[1],\n                    self.elements[i].coords_br[0],\n                    self.elements[i].coords_br[1]], ref_elements_txt)\n                final_text = ''\n                for output_txt in output_overlap:\n                    final_text += output_txt[1] + ' '\n                self.elements[i].attrs['text'] = final_text[:-1]\n            # non - overlapping\n            ocr_elements = self._find_non_overlapping_rects(self.elements, ref_elements_txt)\n            for ocr_element in ocr_elements:\n                id_n = len(self.elements)\n                ocr_element.id = str(id_n)\n                self.annotated_frame = cv.rectangle(\n                    self.annotated_frame,\n                    pt1=ocr_element.coords_br,\n                    pt2=ocr_element.coords_tl,\n                    color=(0, 255, 0),\n                    thickness=3,\n                )\n                x, y = ocr_element.coords_tl\n                cv.putText(\n                    self.annotated_frame, 'ocr_element', (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 3\n                )\n                self.elements.append(ocr_element)\n\n        return self\n\n    def _object_detection(self, source) -> list[POMElement]:\n        \"\"\"Retrieves all the elements using Object Detection ML Algorithm.\n        Args:\n            source: Image\n        Returns:\n            list[POMElement]: List of elements\n        \"\"\"\n        elements: list[POMElement] = []\n\n        results: list[Results] = self.model.predict(source, verbose=False)\n\n        for result in results:\n            self.annotated_frame = result.plot()\n            for i in range(len(result.boxes.data.tolist())):\n                data = result.boxes.data.tolist()[i]\n                xmin, ymin, xmax, ymax, confidence, class_id = data\n                tl = (int(xmin), int(ymin))\n                br = (int(xmax), int(ymax))\n\n                element = POMElement(\n                    id=str(i),\n                    label=results[0].names[class_id],\n                    coords_tl=tl,\n                    coords_br=br,\n                    center=(\n                        (br[0] + tl[0]) // 2,\n                        (br[1] + tl[1]) // 2,\n                    ),\n                    bounding_rect=cv.boundingRect(np.array([tl, br])),\n                    confidence=confidence,\n                    attrs={},\n                )\n\n                elements.append(element)\n\n        return elements\n\n    def get_elements(self, query_dict: dict | None = None) -> list[POMElement]:\n        \"\"\"Get elements using a query.\n\n        Query examples:\n        - select by exact label:                {\"label\": \"my-label\"}\n        - select by label containing substring: {\"label\": {\"value: \"my-label\", \"contains\": True}}\n        - select by label not case sensitive:   {\"label\": {\"value: \"my-label\", \"case_sensitive\": False}}\n        - select by exact text:                 {\"text\": \"my-text\"}\n        - select by exact label and text:       {\"label\": \"my-label\", \"text\": \"my-text\"}\n\n        When not specified, \"case_sensitive\" defaults to True and \"contains\" defaults to False.\n\n        Args:\n            query_dict: Query dictionary. Pass None to select all elements. Defaults to None.\n\n        Returns:\n            list[POMElement]: List of elements\n        \"\"\"\n        if query_dict is None:\n            return self.elements\n\n        query = self._parse_query(query_dict)\n\n        return self._filter_query(query)\n\n    def to_json(self, indent=None) -> str:\n        return json.dumps([el.as_dict() for el in self.elements], indent=indent)\n\n    def _filter_query(self, query: Query) -> list[POMElement]:\n        filtered: list[POMElement] = []\n\n        for element in self.elements:\n            label = element.label\n            if not self._check_query_value(label, query.label):\n                continue\n\n            if query.text is not None and \"text\" not in element.attrs:\n                continue\n\n            if \"text\" in element.attrs:\n                text = element.attrs[\"text\"]\n                if not self._check_query_value(text, query.text):\n                    continue\n\n            filtered.append(element)\n\n        filtered_in: list[POMElement] = []\n        if query.child is not None:\n            filtered_child = self._filter_query(query.child)\n            for element in filtered:\n                for el in self._find_contained_rects(element, filtered_child):\n                    filtered_in.append(el)\n            filtered = filtered_in\n\n        filtered_in = []\n        if query.parent is not None:\n            filtered_parent = self._filter_query(query.parent)\n            for element in filtered_parent:\n                if len(self._find_contained_rects(element, filtered)) > 0:\n                    filtered_in.append(element)\n            filtered = list(dict.fromkeys(filtered_in))\n\n        filtered_in = []\n        if query.left is not None:\n            filtered_left = self._filter_query(query.left)\n            for element in filtered:\n                for el in self._find_rects_sides(element, filtered_left, \"left\"):\n                    filtered_in.append(el)\n            filtered = list(dict.fromkeys(filtered_in))\n\n        filtered_in = []\n        if query.right is not None:\n            filtered_right = self._filter_query(query.right)\n            for element in filtered:\n                for el in self._find_rects_sides(element, filtered_right, \"right\"):\n                    filtered_in.append(el)\n            filtered = list(dict.fromkeys(filtered_in))\n\n        filtered_in = []\n        if query.up is not None:\n            filtered_up = self._filter_query(query.up)\n            for element in filtered:\n                for el in self._find_rects_sides(element, filtered_up, \"up\"):\n                    filtered_in.append(el)\n            filtered = list(dict.fromkeys(filtered_in))\n\n        filtered_in = []\n        if query.down is not None:\n            filtered_down = self._filter_query(query.down)\n            for element in filtered:\n                for el in self._find_rects_sides(element, filtered_down, \"down\"):\n                    filtered_in.append(el)\n            filtered = list(dict.fromkeys(filtered_in))\n\n        return filtered\n\n    def _check_query_value(self, value: str, query_val: QueryValue | None) -> bool:\n        if query_val is None:\n            return True\n\n        expected = query_val.value\n        if not query_val.case_sensitive:\n            value = value.lower()\n            expected = expected.lower()\n\n        if query_val.contains:\n            if expected not in value:\n                return False\n        else:\n            if expected != value:\n                return False\n\n        return True\n\n    def _parse_query(self, query_dict: dict) -> Query:\n        \"\"\"While the user can pass query as a dictionary,\n        internally we want to work with concrete types.\n        \"\"\"\n        query = Query()\n        for [key, item] in query_dict.items():\n            if key == \"label\" or key == \"text\":\n                if isinstance(item, dict):\n                    if \"value\" not in item:\n                        raise Exception(\"Query object doesn't have 'value' field\")\n                    query_val = QueryValue(item[\"value\"])\n                    if \"case_sensitive\" in item:\n                        query_val.case_sensitive = bool(item[\"case_sensitive\"])\n                    if \"contains\" in item:\n                        query_val.contains = bool(item[\"contains\"])\n                    setattr(query, key, query_val)\n                else:\n                    setattr(query, key, QueryValue(item))\n            else:\n                if isinstance(item, dict):\n                    query_in = self._parse_query(item)\n                    setattr(query, key, query_in)\n\n        return query\n\n    def _do_rect_share_space(self, rect1, rect2) -> bool:\n        \"\"\"Check if rects share space by comparing their coordinates\n        rect = [xmin, ymin, xmax, ymax]\n\n        returns bool\n        \"\"\"\n        return not (rect1[2] < rect2[0] or  # rect1 is to the left of rect2\n                    rect1[0] > rect2[2] or  # rect1 is to the right of rect2\n                    rect1[3] < rect2[1] or  # rect1 is above rect2\n                    rect1[1] > rect2[3])\n\n    def _do_rect1_contain_rect2(self, rect1, rect2) -> bool:\n        \"\"\"Check if rect1 contains within rect2\n        rect = [xmin, ymin, xmax, ymax]\n\n        returns bool\n        \"\"\"\n        return (rect2[2] < rect1[2] and  # rect2 xmax is lower than rect1\n                rect2[0] > rect1[0] and  # rect2 xmin is bigger than rect1\n                rect2[3] < rect1[3] and  # rect2 ymax is lower than rect1\n                rect2[1] > rect1[1])\n\n    def _find_contained_rects(self, element_1: POMElement, elements: list[POMElement]) -> list[POMElement]:\n        \"\"\"Example usage:\n        rect1 = [xmin, ymin, xmax, ymax]\n        list[POMElement]\n\n        returns list\n        \"\"\"\n        rect1 = [element_1.coords_tl[0], element_1.coords_tl[1], element_1.coords_br[0], element_1.coords_br[1]]\n        contained_elements: list[POMElement] = []\n\n        for element in elements:\n            # Check for overlap in x-axis and y-axis\n            rect2 = [element.coords_tl[0], element.coords_tl[1], element.coords_br[0], element.coords_br[1]]\n            if self._do_rect1_contain_rect2(rect1, rect2):\n                # Rectangles overlap, add to the result\n                contained_elements.append(element)\n\n        return contained_elements\n\n    def _find_rects_sides(self, element_1: POMElement, elements: list[POMElement], side: str) -> list[POMElement]:\n        \"\"\"Example usage:\n        POMElement - [xmin, ymin, xmax, ymax]\n        list[POMElement] - [xmin, ymin, xmax, ymax]\n        left/right/up/down\n\n        returns list\n        \"\"\"\n        contained_elements: list[POMElement] = []\n\n        for element in elements:\n            if side == \"right\":\n                if (element.coords_tl[0] > element_1.coords_br[0]\n                        and element.coords_tl[1] < element_1.center[1] < element.coords_br[1]):\n                    contained_elements.append(element)\n            if side == \"left\":\n                if (element_1.coords_tl[0] > element.coords_br[0]\n                        and element.coords_tl[1] < element_1.center[1] < element.coords_br[1]):\n                    contained_elements.append(element)\n            if side == \"up\":\n                if (element_1.coords_tl[1] < element.coords_br[1]\n                        and element.coords_tl[0] < element_1.center[0] < element.coords_br[0]):\n                    contained_elements.append(element)\n            if side == \"down\":\n                if (element_1.coords_br[1] > element.coords_tl[1]\n                        and element.coords_tl[0] < element_1.center[0] < element.coords_br[0]):\n                    contained_elements.append(element)\n\n        return contained_elements\n\n    def _find_overlapping_rects(self, rect1: list, sq_w_txt: list) -> list:\n        \"\"\"Example usage:\n        rect1 = [4, 1, 6, 3]\n        sq_w_txt = [[[7, 4, 9, 2], 'text1'], [[11, 8, 13, 6], [5, 2, 7, 1], 'text2']]\n        _find_overlapping_rects(rects1, rects2)\n\n        returns list\n        \"\"\"\n        overlapping_rects = []\n\n        for sq_txt in sq_w_txt:\n            # Check for overlap in x-axis and y-axis\n            if self._do_rect_share_space(rect1, sq_txt[0]):\n                # Rectangles overlap, add to the result\n                overlapping_rects.append(sq_txt)\n\n        return overlapping_rects\n\n    def _find_non_overlapping_rects(self, pom_els: list[POMElement], ocr_els: list) -> list[POMElement]:\n        \"\"\"It will find all those elements from OCR that does not overlap with the\n        Yolo recognised elements\n\n        Example usage:\n        pom_els = [POMElement(...), ...]\n        ocr_els = [[11, 8, 13, 6], [5, 2, 7, 1], 'text2']]\n        _find_non_overlapping_rects(pom_els, ocr_els)\n\n        returns list[POMElement]\n        \"\"\"\n        non_overlapping_rects = []\n\n        for ocr_el in ocr_els:\n            is_overlapping = False\n            for pom_el in pom_els:\n                if self._do_rect_share_space(\n                        [pom_el.coords_tl[0],\n                         pom_el.coords_tl[1],\n                         pom_el.coords_br[0],\n                         pom_el.coords_br[1]], ocr_el[0]):\n                    is_overlapping = True\n\n            if not is_overlapping:\n                element = POMElement(\n                    id='',\n                    label='ocr_element',\n                    coords_tl=(ocr_el[0][0], ocr_el[0][1]),\n                    coords_br=(ocr_el[0][2], ocr_el[0][3]),\n                    center=(\n                        (ocr_el[0][0] + ocr_el[0][2]) // 2,\n                        (ocr_el[0][1] + ocr_el[0][3]) // 2,\n                    ),\n                    bounding_rect=(\n                        cv.boundingRect(np.array([(ocr_el[0][0], ocr_el[0][1]), (ocr_el[0][2], ocr_el[0][3])]))\n                    ),\n                    confidence=1.0,\n                    attrs={'text': ocr_el[1]},\n                )\n                non_overlapping_rects.append(element)\n\n        return non_overlapping_rects\n"}
{"type": "source_file", "path": "server.py", "content": "import argparse\nimport os\nimport uvicorn\nimport base64\nimport cv2\nimport numpy as np\n\nfrom cv_pom.cv_pom import POM\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI()\n# Put \"cv_pom\" inside of app object in order to make in testable (see cv_pom_text.py TestCVPOMServer test case)\napp.cv_pom = None\n\n\nclass ConvertBody(BaseModel):\n    image_base64: str\n    ocr: dict\n    query: dict\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\"CV POM wrapper\")\n    parser.add_argument(\"--model\", help=\"The CV model to be used [path]\")\n    args = parser.parse_args()\n\n    if not args.model:\n        print(\"Please specify the model\")\n        exit(1)\n\n    args.model = os.path.expanduser(args.model)\n    if not os.path.exists(args.model):\n        print(\"The model path does not exist\")\n        exit(1)\n\n    return args\n\n\n@app.post(\"/convert_to_cvpom\")\nasync def upload(args: ConvertBody):\n    try:\n        im_bytes = base64.b64decode(args.image_base64)\n        im_arr = np.frombuffer(im_bytes, dtype=np.uint8)  # im_arr is one-dim Numpy array\n        img = cv2.imdecode(im_arr, flags=cv2.IMREAD_COLOR)\n    except Exception as err:\n        raise HTTPException(\"400\", f\"Failed to uploading file: {err}\")\n\n    try:\n        app.cv_pom.convert_to_cvpom(img, args.ocr)\n    except Exception as err:\n        raise HTTPException(\"400\", f\"Failed to create POM: {err}\")\n\n    try:\n        elements = app.cv_pom.get_elements(args.query)\n    except Exception as err:\n        raise HTTPException(\"400\", f\"Failed to query elements: {err}\")\n\n    return [el.as_dict() for el in elements]\n\n\nif __name__ == \"__main__\":\n    model = parse_args().model\n    app.cv_pom = POM(model)\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"}
{"type": "source_file", "path": "cv_pom/frameworks/os_gui.py", "content": "from pathlib import Path\nfrom cv_pom.cv_pom_driver import CVPOMDriver\nimport numpy as np\nimport cv2 as cv\nfrom PIL import Image\n\ntry:\n    import pyautogui\nexcept ImportError:\n    pass\n\n\nclass DesktopCVPOMDriver(CVPOMDriver):\n    \"\"\"CVPOMDriver adapted for PyAutoGUI framework\"\"\"\n\n    def __init__(self, model_path: Path | str, **kwargs) -> None:\n        \"\"\"Initialize the driver\n\n        Args:\n            model_path: path to the CVPOM model\n            driver: path to the TestUIDriver\n        \"\"\"\n        super().__init__(model_path, **kwargs)\n        self.resize = 1\n        if kwargs and \"resize\" in kwargs:\n            self.resize = kwargs[\"resize\"]\n\n    def _get_screenshot(self) -> np.ndarray:\n        screenshot = pyautogui.screenshot()\n        width, height = screenshot.size\n        screenshot = screenshot.resize((round(width*self.resize), round(height*self.resize)), Image.LANCZOS)\n        pimg = np.array(screenshot)\n        return cv.cvtColor(np.array(pimg), cv.COLOR_RGB2BGR)\n\n    def _click_coordinates(self, x: int, y: int, times=1, interval=0, button=\"PRIMARY\"):\n        pyautogui.click(x=x, y=y, clicks=times, interval=interval, button=button)\n\n    def _send_keys(self, keys: str):\n        pyautogui.write(keys)\n\n    def _swipe_coordinates(self, coords: tuple = None, direction: str = None, duration=None):\n        # duration var doesn't have an effect in this driver\n\n        if coords:\n            print(\"Coordinates scroll not supported\")\n        if direction == 'up':\n            pyautogui.scroll(1)\n        elif direction == 'down':\n            pyautogui.scroll(-1)\n        elif direction == 'left':\n            pyautogui.hscroll(1)\n        elif direction == 'right':\n            pyautogui.hscroll(-1)\n\n    def _hover_coordinates(self, x: int, y: int):\n        pyautogui.moveTo(x, y)\n\n    def _drag_drop(self, x: int, y: int, x_end: int, y_end: int, duration=0.1, button=\"PRIMARY\"):\n        pyautogui.mouseDown(x, y, button=button)\n        pyautogui.moveTo(x, y, duration=duration)\n        pyautogui.mouseUp(x_end, y_end)\n"}
{"type": "source_file", "path": "cv_pom/__init__.py", "content": ""}
