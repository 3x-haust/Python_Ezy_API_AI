{"repo_info": {"repo_name": "food_delivery", "repo_owner": "bytesByHarsh", "repo_url": "https://github.com/bytesByHarsh/food_delivery"}}
{"type": "source_file", "path": "customer_service/app/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/alembic/env.py", "content": "# Built-in Dependencies\nfrom logging.config import fileConfig\nimport asyncio\n\n# Third-Party Dependencies\nfrom sqlalchemy.ext.asyncio import async_engine_from_config\nfrom sqlalchemy.engine import Connection\nfrom sqlalchemy import pool\nfrom alembic import context\n\n# Local Dependencies\nfrom app.core.config import settings\nfrom app.db.models.v1.common import Base\nfrom app.db.models.v1.db_auth import TokenBlacklist  # noqa\nfrom app.db.models.v1.db_user import User  # noqa\nfrom app.db.models.v1.db_order import Order, OrderAddOn, OrderItem  # noqa\n\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Set the SQLAlchemy URL using the Postgres async URI from settings.\nconfig.set_main_option(name=\"sqlalchemy.url\", value=f\"{settings.POSTGRES_ASYNC_URI}\")\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\n# Add your model's MetaData object here (for 'autogenerate' support)\ntarget_metadata = Base.metadata\n\n# Setting naming conventions for SQLModel/SQLAlchemy\ntarget_metadata.naming_convention = {\n    \"ix\": \"ix_%(column_0_label)s\",  # Index\n    \"uq\": \"uq_%(table_name)s_%(column_0_name)s\",  # Unique constraint\n    \"ck\": \"ck_%(table_name)s_%(constraint_name)s\",  # Check constraint\n    \"fk\": \"fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s\",  # Foreign key\n    \"pk\": \"pk_%(table_name)s\",  # Primary key\n}\n\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef filter_db_objects(\n    object,  # noqa: indirect usage\n    name,\n    type_,\n    *args,  # noqa: indirect usage\n    **kwargs,  # noqa: indirect usage\n):\n    \"\"\"\n    Filter the database objects based on the given criteria.\n\n    Args:\n        object: The database object to be filtered. # noqa: indirect usage\n        name: The name of the database object.\n        type_: The type of the database object.\n        *args: Additional positional arguments. # noqa: indirect usage\n        **kwargs: Additional keyword arguments. # noqa: indirect usage\n\n    Returns:\n        bool: True if the object should be included, False if it should be filtered out.\n    \"\"\"\n    if type_ == \"index\" and name.startswith(\"idx\") and name.endswith(\"geom\"):\n        return False\n\n    return True\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL and not an Engine, though an Engine is acceptable here as well.\n    By skipping the Engine creation, we don't even need a DBAPI to be available.\n\n    This function is responsible for running migrations when the application is not connected to a database.\n    \"\"\"\n    url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n        include_object=filter_db_objects,\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef do_run_migrations(connection: Connection) -> None:\n    \"\"\"Perform the actual migration process.\n\n    This function is responsible for running migrations when the application is connected to a database.\n    \"\"\"\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.configure(\n            connection=connection,\n            target_metadata=target_metadata,\n            include_object=filter_db_objects,\n        )\n        context.run_migrations()\n\n\nasync def run_async_migrations() -> None:\n    \"\"\"Run migrations asynchronously.\n\n    This function is responsible for running migrations in an asynchronous manner.\n    \"\"\"\n    connectable = async_engine_from_config(\n        config.get_section(config.config_ini_section, {}),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n        future=True,\n    )\n\n    async with connectable.connect() as connection:\n        await connection.run_sync(do_run_migrations)\n\n    await connectable.dispose()\n\n\ndef run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    asyncio.run(run_async_migrations())\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_10_28_1953-c259834fc460_init_migration.py", "content": "\"\"\"Init Migration\n\nRevision ID: c259834fc460\nRevises:\nCreate Date: 2024-10-28 19:53:48.901002\n\n\"\"\"\n\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlmodel\n\nfrom app.core.config import settings\n\n\n# revision identifiers, used by Alembic.\nrevision: str = \"c259834fc460\"\ndown_revision: Union[str, None] = None\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\naccesslevel_enum_name = \"accesslevel_enum\"\naccesslevel_enum = sa.Enum(\n    \"ADMIN\", \"USER\", \"GUEST\", \"MODERATOR\", name=accesslevel_enum_name\n)\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.execute(f\"DROP TYPE IF EXISTS {accesslevel_enum_name}\")\n\n    op.create_table(\n        \"system_token_blacklist\",\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"id\", sa.Uuid(), nullable=False),\n        sa.Column(\"token\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"expires_at\", sa.DateTime(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(\n        op.f(\"ix_system_token_blacklist_id\"),\n        \"system_token_blacklist\",\n        [\"id\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(\"ix_system_token_blacklist_token\"),\n        \"system_token_blacklist\",\n        [\"token\"],\n        unique=False,\n    )\n    op.create_table(\n        f\"{settings.DATABASE_USER_TABLE}\",\n        sa.Column(\n            \"user_role\",\n            accesslevel_enum,\n            nullable=False,\n        ),\n        sa.Column(\"deleted_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_deleted\", sa.Boolean(), nullable=False),\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"id\", sa.Uuid(), nullable=False),\n        sa.Column(\n            \"hashed_password\", sqlmodel.sql.sqltypes.AutoString(), nullable=False\n        ),\n        sa.Column(\"is_superuser\", sa.Boolean(), nullable=False),\n        sa.Column(\n            \"profile_image_url\", sqlmodel.sql.sqltypes.AutoString(), nullable=False\n        ),\n        sa.Column(\"name\", sqlmodel.sql.sqltypes.AutoString(length=100), nullable=False),\n        sa.Column(\n            \"username\", sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False\n        ),\n        sa.Column(\"email\", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_email\"),\n        f\"{settings.DATABASE_USER_TABLE}\",\n        [\"email\"],\n        unique=True,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_id\"),\n        f\"{settings.DATABASE_USER_TABLE}\",\n        [\"id\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_is_deleted\"),\n        f\"{settings.DATABASE_USER_TABLE}\",\n        [\"is_deleted\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_username\"),\n        f\"{settings.DATABASE_USER_TABLE}\",\n        [\"username\"],\n        unique=True,\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_username\"),\n        table_name=f\"{settings.DATABASE_USER_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_is_deleted\"),\n        table_name=f\"{settings.DATABASE_USER_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_id\"),\n        table_name=f\"{settings.DATABASE_USER_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_email\"),\n        table_name=f\"{settings.DATABASE_USER_TABLE}\",\n    )\n    op.drop_table(f\"{settings.DATABASE_USER_TABLE}\")\n    op.drop_index(\n        op.f(\"ix_system_token_blacklist_token\"), table_name=\"system_token_blacklist\"\n    )\n    op.drop_index(\n        op.f(\"ix_system_token_blacklist_id\"), table_name=\"system_token_blacklist\"\n    )\n    op.drop_table(\"system_token_blacklist\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_11_02_2011-80f2756fc73b_user_address.py", "content": "\"\"\"User Address\n\nRevision ID: 80f2756fc73b\nRevises: c259834fc460\nCreate Date: 2024-11-02 20:11:56.877433\n\n\"\"\"\n\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlmodel\n\nfrom app.core.config import settings\n\n\n# revision identifiers, used by Alembic.\nrevision: str = \"80f2756fc73b\"\ndown_revision: Union[str, None] = \"c259834fc460\"\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\nuseraddresstype_enum_name = \"useraddresstype_enum\"\nuseraddresstype_enum = sa.Enum(\n    \"HOME\", \"OFFICE\", \"OTHER\", name=f\"{useraddresstype_enum_name}\"\n)\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.execute(f\"DROP TYPE IF EXISTS {useraddresstype_enum_name}\")\n\n    op.create_table(\n        f\"{settings.DATABASE_USER_ADDRESS_TABLE}\",\n        sa.Column(\"deleted_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_deleted\", sa.Boolean(), nullable=False),\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"id\", sa.Uuid(), nullable=False),\n        sa.Column(\"latitude\", sa.Float(), nullable=False),\n        sa.Column(\"longitude\", sa.Float(), nullable=False),\n        sa.Column(\"address_line_1\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"address_line_2\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"city\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"state\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"postal_code\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"country\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"add_type\", useraddresstype_enum, nullable=False),\n        sa.Column(\"customer_id\", sa.Uuid(), nullable=False),\n        sa.ForeignKeyConstraint(\n            [\"customer_id\"],\n            [f\"{settings.DATABASE_USER_TABLE}.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_USER_ADDRESS_TABLE}_id\"),\n        f\"{settings.DATABASE_USER_ADDRESS_TABLE}\",\n        [\"id\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_USER_ADDRESS_TABLE}_is_deleted\"),\n        f\"{settings.DATABASE_USER_ADDRESS_TABLE}\",\n        [\"is_deleted\"],\n        unique=False,\n    )\n    op.add_column(\n        f\"{settings.DATABASE_USER_TABLE}\",\n        sa.Column(\n            \"phone\",\n            sqlmodel.sql.sqltypes.AutoString(),\n            nullable=False,\n            server_default=\"\",\n        ),\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_phone\"),\n        f\"{settings.DATABASE_USER_TABLE}\",\n        [\"phone\"],\n        unique=True,\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_USER_TABLE}_phone\"),\n        table_name=f\"{settings.DATABASE_USER_TABLE}\",\n    )\n    op.drop_column(f\"{settings.DATABASE_USER_TABLE}\", \"phone\")\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_USER_ADDRESS_TABLE}_is_deleted\"),\n        table_name=f\"{settings.DATABASE_USER_ADDRESS_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_USER_ADDRESS_TABLE}_id\"),\n        table_name=f\"{settings.DATABASE_USER_ADDRESS_TABLE}\",\n    )\n    op.drop_table(f\"{settings.DATABASE_USER_ADDRESS_TABLE}\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_11_09_1639-d65cd3f19a83_order_details.py", "content": "\"\"\"Order Details\n\nRevision ID: d65cd3f19a83\nRevises: 80f2756fc73b\nCreate Date: 2024-11-09 16:39:05.759605\n\n\"\"\"\n\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlmodel\n\nfrom app.core.config import settings\n\n\n# revision identifiers, used by Alembic.\nrevision: str = \"d65cd3f19a83\"\ndown_revision: Union[str, None] = \"80f2756fc73b\"\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\norder_status_enum_name = \"order_status_enum\"\norder_status_enum = sa.Enum(\n    \"PLACED\",\n    \"ORDERED\",\n    \"ACCEPTED\",\n    \"READY_FOR_PICKUP\",\n    \"ON_THE_WAY\",\n    \"REACHED\",\n    \"DELIVERED\",\n    \"CANCELLED\",\n    \"RETURNED\",\n    \"FAILED\",\n    name=f\"{order_status_enum_name}\",\n)\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.execute(f\"DROP TYPE IF EXISTS {order_status_enum_name}\")\n\n    op.create_table(\n        f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\",\n        sa.Column(\"deleted_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_deleted\", sa.Boolean(), nullable=False),\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"id\", sa.Uuid(), nullable=False),\n        sa.Column(\"name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"price\", sa.Float(), nullable=False),\n        sa.Column(\"order_item_id\", sa.Uuid(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}_id\"),\n        f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\",\n        [\"id\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}_is_deleted\"),\n        f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\",\n        [\"is_deleted\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}_order_item_id\"),\n        f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\",\n        [\"order_item_id\"],\n        unique=False,\n    )\n    op.create_table(\n        f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n        sa.Column(\"deleted_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_deleted\", sa.Boolean(), nullable=False),\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"id\", sa.Uuid(), nullable=False),\n        sa.Column(\"order_id\", sa.Uuid(), nullable=False),\n        sa.Column(\"product_id\", sa.Uuid(), nullable=False),\n        sa.Column(\"payment_id\", sa.Uuid(), nullable=True),\n        sa.Column(\"name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"quantity\", sa.Integer(), nullable=False),\n        sa.Column(\"price_per_unit\", sa.Float(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_TABLE}_id\"),\n        f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n        [\"id\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_TABLE}_is_deleted\"),\n        f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n        [\"is_deleted\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_TABLE}_order_id\"),\n        f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n        [\"order_id\"],\n        unique=False,\n    )\n    op.create_table(\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        sa.Column(\"deleted_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_deleted\", sa.Boolean(), nullable=False),\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"id\", sa.Uuid(), nullable=False),\n        sa.Column(\"customer_id\", sa.Uuid(), nullable=False),\n        sa.Column(\"status\", order_status_enum, nullable=False),\n        sa.Column(\"food_rating\", sa.Integer(), nullable=True),\n        sa.Column(\"delivery_rating\", sa.Integer(), nullable=True),\n        sa.Column(\"delivery_person_id\", sa.Uuid(), nullable=True),\n        sa.Column(\"address_id\", sa.Uuid(), nullable=False),\n        sa.ForeignKeyConstraint(\n            [\"address_id\"],\n            [f\"{settings.DATABASE_USER_ADDRESS_TABLE}.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_TABLE}_customer_id\"),\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        [\"customer_id\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_TABLE}_id\"),\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        [\"id\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_TABLE}_is_deleted\"),\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        [\"is_deleted\"],\n        unique=False,\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_TABLE}_is_deleted\"),\n        table_name=f\"{settings.DATABASE_ORDER_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_TABLE}_id\"),\n        table_name=f\"{settings.DATABASE_ORDER_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_TABLE}_customer_id\"),\n        table_name=f\"{settings.DATABASE_ORDER_TABLE}\",\n    )\n    op.drop_table(\"{settings.DATABASE_ORDER_TABLE}\")\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_TABLE}_order_id\"),\n        table_name=f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_TABLE}_is_deleted\"),\n        table_name=f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_TABLE}_id\"),\n        table_name=f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n    )\n    op.drop_table(\"{settings.DATABASE_ORDER_ITEM_TABLE}\")\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}_order_item_id\"),\n        table_name=f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}_is_deleted\"),\n        table_name=f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}_id\"),\n        table_name=f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\",\n    )\n    op.drop_table(f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_11_09_2038-068aa0a49d78_order_rating.py", "content": "\"\"\"Order Rating\n\nRevision ID: 068aa0a49d78\nRevises: d65cd3f19a83\nCreate Date: 2024-11-09 20:38:38.603919\n\n\"\"\"\n\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlmodel\n\nfrom app.core.config import settings\n\n\n# revision identifiers, used by Alembic.\nrevision: str = \"068aa0a49d78\"\ndown_revision: Union[str, None] = \"d65cd3f19a83\"\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        f\"{settings.DATABASE_ORDER_RATING_TABLE}\",\n        sa.Column(\"deleted_at\", sa.DateTime(timezone=True), nullable=True),\n        sa.Column(\"is_deleted\", sa.Boolean(), nullable=False),\n        sa.Column(\"created_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"updated_at\", sa.DateTime(timezone=True), nullable=False),\n        sa.Column(\"id\", sa.Uuid(), nullable=False),\n        sa.Column(\"food_rating\", sa.Integer(), nullable=True),\n        sa.Column(\"delivery_rating\", sa.Integer(), nullable=True),\n        sa.Column(\n            \"delivery_person_id\", sqlmodel.sql.sqltypes.AutoString(), nullable=True\n        ),\n        sa.Column(\"order_id\", sa.Uuid(), nullable=False),\n        sa.Column(\"user_id\", sa.Uuid(), nullable=False),\n        sa.Column(\"restaurant_id\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.ForeignKeyConstraint(\n            [\"order_id\"],\n            [f\"{settings.DATABASE_ORDER_TABLE}.id\"],\n        ),\n        sa.ForeignKeyConstraint(\n            [\"user_id\"],\n            [f\"{settings.DATABASE_USER_TABLE}.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_RATING_TABLE}_id\"),\n        f\"{settings.DATABASE_ORDER_RATING_TABLE}\",\n        [\"id\"],\n        unique=False,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_RATING_TABLE}_is_deleted\"),\n        f\"{settings.DATABASE_ORDER_RATING_TABLE}\",\n        [\"is_deleted\"],\n        unique=False,\n    )\n    op.add_column(\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        sa.Column(\"restaurant_id\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n    )\n    op.alter_column(\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        \"delivery_person_id\",\n        existing_type=sa.UUID(),\n        type_=sqlmodel.sql.sqltypes.AutoString(),\n        existing_nullable=True,\n    )\n    op.create_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_TABLE}_restaurant_id\"),\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        [\"restaurant_id\"],\n        unique=False,\n    )\n    op.drop_column(f\"{settings.DATABASE_ORDER_TABLE}\", \"delivery_rating\")\n    op.drop_column(f\"{settings.DATABASE_ORDER_TABLE}\", \"food_rating\")\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        sa.Column(\"food_rating\", sa.INTEGER(), autoincrement=False, nullable=True),\n    )\n    op.add_column(\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        sa.Column(\"delivery_rating\", sa.INTEGER(), autoincrement=False, nullable=True),\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_TABLE}_restaurant_id\"),\n        table_name=f\"{settings.DATABASE_ORDER_TABLE}\",\n    )\n    op.alter_column(\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        \"delivery_person_id\",\n        existing_type=sqlmodel.sql.sqltypes.AutoString(),\n        type_=sa.UUID(),\n        existing_nullable=True,\n    )\n    op.drop_column(f\"{settings.DATABASE_ORDER_TABLE}\", \"restaurant_id\")\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_RATING_TABLE}_is_deleted\"),\n        table_name=f\"{settings.DATABASE_ORDER_RATING_TABLE}\",\n    )\n    op.drop_index(\n        op.f(f\"ix_{settings.DATABASE_ORDER_RATING_TABLE}_id\"),\n        table_name=f\"{settings.DATABASE_ORDER_RATING_TABLE}\",\n    )\n    op.drop_table(f\"{settings.DATABASE_ORDER_RATING_TABLE}\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_11_09_2122-63dc14b49234_add_fk.py", "content": "\"\"\"Add FK\n\nRevision ID: 63dc14b49234\nRevises: 6c898a1d906f\nCreate Date: 2024-11-09 21:22:24.499932\n\n\"\"\"\n\nfrom typing import Sequence, Union\n\nfrom alembic import op\n\nfrom app.core.config import settings\n\n\n# revision identifiers, used by Alembic.\nrevision: str = \"63dc14b49234\"\ndown_revision: Union[str, None] = \"6c898a1d906f\"\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_foreign_key(\n        None,\n        f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\",\n        f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n        [\"order_item_id\"],\n        [\"id\"],\n    )\n    op.create_foreign_key(\n        None,\n        f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        [\"order_id\"],\n        [\"id\"],\n    )\n    op.create_foreign_key(\n        None, f\"{settings.DATABASE_ORDER_TABLE}\", \"users\", [\"customer_id\"], [\"id\"]\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_constraint(None, f\"{settings.DATABASE_ORDER_TABLE}\", type_=\"foreignkey\")  # type:ignore\n    op.drop_constraint(\n        None, f\"{settings.DATABASE_ORDER_ITEM_TABLE}\", type_=\"foreignkey\"\n    )  # type:ignore\n    op.drop_constraint(\n        None, f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\", type_=\"foreignkey\"\n    )  # type:ignore\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_11_09_2057-6c898a1d906f_payment_uuid.py", "content": "\"\"\"Payment UUID\n\nRevision ID: 6c898a1d906f\nRevises: 068aa0a49d78\nCreate Date: 2024-11-09 20:57:29.481534\n\n\"\"\"\n\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\n\nfrom app.core.config import settings\n\n\n# revision identifiers, used by Alembic.\nrevision: str = \"6c898a1d906f\"\ndown_revision: Union[str, None] = \"068aa0a49d78\"\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_column(f\"{settings.DATABASE_ORDER_ITEM_TABLE}\", \"payment_id\")\n    op.add_column(\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        sa.Column(\"payment_id\", sa.Uuid(), nullable=True),\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_column(f\"{settings.DATABASE_ORDER_TABLE}\", \"payment_id\")\n    op.add_column(\n        f\"{settings.DATABASE_ORDER_ITEM_TABLE}\",\n        sa.Column(\"payment_id\", sa.UUID(), autoincrement=False, nullable=True),\n    )\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_11_11_2348-537701cdcb89_add_total_pricein_order.py", "content": "\"\"\"Add total pricein order\n\nRevision ID: 537701cdcb89\nRevises: 63dc14b49234\nCreate Date: 2024-11-11 23:48:43.014105\n\n\"\"\"\n\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\n\nfrom app.core.config import settings\n\n\n# revision identifiers, used by Alembic.\nrevision: str = \"537701cdcb89\"\ndown_revision: Union[str, None] = \"63dc14b49234\"\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.add_column(\n        f\"{settings.DATABASE_ORDER_TABLE}\",\n        sa.Column(\"total_cost\", sa.Float(), nullable=False, server_default=\"0.0\"),\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_column(f\"{settings.DATABASE_ORDER_TABLE}\", \"total_cost\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_11_15_1104-868c2adca258_update_driver_details.py", "content": "\"\"\"Update driver details\n\nRevision ID: 868c2adca258\nRevises: 537701cdcb89\nCreate Date: 2024-11-15 11:04:46.372833\n\n\"\"\"\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlmodel\n\nfrom app.core.config import settings\n\n\n\n# revision identifiers, used by Alembic.\nrevision: str = '868c2adca258'\ndown_revision: Union[str, None] = '537701cdcb89'\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.execute(f\"\"\"\n        ALTER TABLE {settings.DATABASE_ORDER_TABLE}\n        ALTER COLUMN delivery_person_id TYPE INTEGER\n        USING delivery_person_id::integer\n    \"\"\")\n    op.add_column(f\"{settings.DATABASE_ORDER_TABLE}\", sa.Column('delivery_person_name', sqlmodel.sql.sqltypes.AutoString(), nullable=True))\n    op.alter_column(f\"{settings.DATABASE_ORDER_TABLE}\", 'delivery_person_id',\n               existing_type=sa.VARCHAR(),\n               type_=sa.Integer(),\n               existing_nullable=True,\n               server_default=None)\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.alter_column(f\"{settings.DATABASE_ORDER_TABLE}\", 'delivery_person_id',\n               existing_type=sa.Integer(),\n               type_=sa.VARCHAR(),\n               existing_nullable=True)\n    op.drop_column(f\"{settings.DATABASE_ORDER_TABLE}\", 'delivery_person_name')\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/apis/base.py", "content": "from fastapi import APIRouter\n\nfrom app.apis.v1 import route_login\nfrom app.apis.v1 import route_user\nfrom app.apis.v1 import route_address\nfrom app.apis.v1 import route_order\nfrom app.apis.v1 import route_restaurant\n\napi_router = APIRouter()\n\napi_router.include_router(route_login.router, prefix=\"/auth\", tags=[\"Login\"])\napi_router.include_router(route_user.router, prefix=\"/users\", tags=[\"Users\"])\napi_router.include_router(\n    route_address.router, prefix=\"/user_address\", tags=[\"User Address\"]\n)\napi_router.include_router(route_order.router, prefix=\"/orders\")\napi_router.include_router(route_restaurant.router, prefix=\"/restaurants\")\n"}
{"type": "source_file", "path": "customer_service/app/apis/v1/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/apis/v1/route_address.py", "content": "# Built-in Dependencies\nfrom typing import Annotated\nfrom uuid import UUID\n\n# Third-Party Dependencies\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom fastapi import Depends, Request\nimport fastapi\n\n# Local Dependencies\nfrom app.core.dependencies import CurrentUser\nfrom app.db.session import async_get_db\nfrom app.core.http_exceptions import (\n    ForbiddenException,\n)\n\nfrom app.schemas.v1.schema_address import UserAddressCreate, UserAddressRead\n\nfrom app.utils.paginated import (\n    PaginatedListResponse,\n)\n\nfrom app.db.crud.crud_user_address import (\n    add_new_address,\n    get_address_details,\n    get_address_list_details,\n    remove_address,\n)\n\nrouter = fastapi.APIRouter(tags=[\"User Address\"])\n\n\n@router.post(\"\", response_model=UserAddressRead, status_code=201)\nasync def add_address(\n    request: Request,\n    address: UserAddressCreate,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n):\n    if current_user.id != address.customer_id:\n        raise ForbiddenException(\"Cannot add address for different user\")\n    return await add_new_address(user=current_user, address=address, db=db)\n\n\n@router.get(\"/{address_id}\", response_model=UserAddressRead, status_code=200)\nasync def get_address(\n    request: Request,\n    address_id: UUID,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n):\n    return await get_address_details(user=current_user, id=address_id, db=db)\n\n\n@router.get(\"\", status_code=200, response_model=PaginatedListResponse[UserAddressRead])\nasync def get_address_list(\n    request: Request,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n    page: int = 1,\n    items_per_page: int = 10,\n):\n    return await get_address_list_details(\n        user=current_user, db=db, page=page, items_per_page=items_per_page\n    )\n\n\n@router.delete(\"/{address_id}\")\nasync def delete_address(\n    request: Request,\n    address_id: UUID,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n):\n    status = await remove_address(db=db, id=address_id, user=current_user)\n    if status:\n        return \"Address Deleted\"\n    return \"Address Not deleted\"\n"}
{"type": "source_file", "path": "customer_service/app/apis/v1/route_login.py", "content": "# Built-in Dependencies\n\n# Built-in Dependencies\nfrom typing import Annotated, Dict\nfrom datetime import timedelta\n\n# Third-party Dependencies\nfrom fastapi.security import OAuth2PasswordRequestForm\nfrom jose import JWTError\nfrom fastapi import Response, Request, Depends, APIRouter\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n\n# Local Dependencies\nfrom app.core.http_exceptions import UnauthorizedException\nfrom app.core.config import settings\nfrom app.schemas.v1.schema_auth import Token\nfrom app.db.session import async_get_db\nfrom app.core.security import (\n    create_access_token,\n    authenticate_user,\n    create_refresh_token,\n    verify_token,\n    oauth2_scheme,\n    blacklist_token,\n)\n\nrouter = APIRouter(tags=[\"Login\"])\n\n\n@router.post(\"/login\", response_model=Token)\nasync def login_for_access_token(\n    response: Response,\n    form_data: Annotated[OAuth2PasswordRequestForm, Depends()],\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n) -> Dict[str, str]:\n    user = await authenticate_user(\n        username_or_email=form_data.username, password=form_data.password, db=db\n    )\n    if not user:\n        raise UnauthorizedException(\"Wrong username, email or password.\")\n\n    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n    access_token = await create_access_token(\n        data={\"sub\": user[\"username\"]}, expires_delta=access_token_expires\n    )\n\n    refresh_token = await create_refresh_token(data={\"sub\": user[\"username\"]})\n    max_age = settings.ACCESS_TOKEN_EXPIRE_MINUTES * 24 * 60 * 60\n\n    response.set_cookie(\n        key=\"refresh_token\",\n        value=refresh_token,\n        # httponly=True,\n        secure=settings.COOKIES_SECURE_SETTINGS,\n        samesite=\"lax\",\n        max_age=max_age,\n    )\n    response.set_cookie(\n        key=\"access_token\",\n        value=f\"Bearer {access_token}\",\n        # httponly=True,\n        secure=settings.COOKIES_SECURE_SETTINGS,\n        samesite=\"lax\",\n        max_age=max_age,\n    )\n\n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}\n\n\n@router.post(\"/refresh\")\nasync def refresh_access_token(\n    request: Request, db: AsyncSession = Depends(async_get_db)\n) -> Dict[str, str]:\n    refresh_token = request.cookies.get(\"refresh_token\")\n    if not refresh_token:\n        raise UnauthorizedException(\"Refresh token missing.\")\n\n    user_data = await verify_token(refresh_token, db)\n    if not user_data:\n        raise UnauthorizedException(\"Invalid refresh token.\")\n\n    new_access_token = await create_access_token(\n        data={\"sub\": user_data.username_or_email}\n    )\n    return {\"access_token\": new_access_token, \"token_type\": \"bearer\"}\n\n\n@router.post(\"/logout\")\nasync def logout(\n    response: Response,\n    access_token: str = Depends(oauth2_scheme),\n    db: AsyncSession = Depends(async_get_db),\n) -> Dict[str, str]:\n    try:\n        await blacklist_token(token=access_token, db=db)\n        response.delete_cookie(key=\"access_token\")\n        response.delete_cookie(key=\"refresh_token\")\n\n        return {\"message\": \"Logged out successfully\"}\n\n    except JWTError:\n        raise UnauthorizedException(\"Invalid token.\")\n"}
{"type": "source_file", "path": "customer_service/app/apis/v1/route_user.py", "content": "# Built-in Dependencies\nfrom typing import Annotated, Dict, Any\nimport os\n\n# Third-Party Dependencies\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom fastapi import Depends, Request, File, UploadFile\nimport fastapi\nfrom PIL import Image\nfrom sqlalchemy.sql import text\n\n# Local Dependencies\nfrom app.core.dependencies import CurrentUser, CurrentSuperUser\nfrom app.db.crud.crud_user import crud_users, create_new_user, get_full_user_details\nfrom app.db.session import async_get_db\nfrom app.core.http_exceptions import (\n    DuplicateValueException,\n    NotFoundException,\n    ForbiddenException,\n    # RateLimitException\n)\nfrom app.schemas.v1.schema_user import UserCreate, UserUpdate, UserRead, UserReadFull\nfrom app.db.models.v1.db_user import AccessLevel_Enum\n\nfrom app.utils.paginated import (\n    PaginatedListResponse,\n    paginated_response,\n    compute_offset,\n)\nfrom app.core.security import blacklist_token, oauth2_scheme\nfrom app.core.config import settings\n\nrouter = fastapi.APIRouter(tags=[\"Users\"])\n\n\n@router.post(\"\", response_model=UserRead, status_code=201)\nasync def signup_user(\n    request: Request,\n    user: UserCreate,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n) -> Any:\n    # For new user make these default\n    user.user_role = AccessLevel_Enum.USER\n    return await create_new_user(user, db)\n\n\n@router.post(\"/create_user\", response_model=UserRead, status_code=201)\nasync def create_user(\n    request: Request,\n    user: UserCreate,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n) -> Any:\n    # For new user make these default\n    try:\n        if current_user.user_role != AccessLevel_Enum.ADMIN.value:\n            raise ForbiddenException(\"Don't have proper access to create user\")\n        return await create_new_user(user, db)\n    except Exception:\n        raise ForbiddenException(\"Wrong Input Details\")\n\n\n@router.get(\"/search\", response_model=PaginatedListResponse[UserRead])\nasync def search_users(\n    request: Request,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n    search: str,\n    page: int = 1,\n    items_per_page: int = 10,\n) -> dict:\n    filters = []\n\n    if search:\n        filters.append(text(f\"username ILIKE '%{search}%'\"))\n\n    if current_user.user_role == AccessLevel_Enum.ADMIN.value:\n        users_data = await crud_users.get_multi_on_filters(\n            db=db,\n            offset=compute_offset(page, items_per_page),\n            limit=items_per_page,\n            schema_to_select=UserRead,\n            filters=filters,\n        )\n    else:\n        users_data = await crud_users.get_multi_on_filters(\n            db=db,\n            offset=compute_offset(page, items_per_page),\n            limit=items_per_page,\n            schema_to_select=UserRead,\n            filters=filters,\n        )\n\n    if not users_data[\"data\"]:\n        raise NotFoundException(\"No User Found\")\n\n    return paginated_response(\n        crud_data=users_data, page=page, items_per_page=items_per_page\n    )\n\n\n@router.get(\"/list\", response_model=PaginatedListResponse[UserRead])\nasync def read_users(\n    request: Request,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n    page: int = 1,\n    items_per_page: int = 10,\n) -> dict:\n    users_data = None\n    if current_user.user_role == AccessLevel_Enum.ADMIN.value:\n        users_data = await crud_users.get_multi(\n            db=db,\n            offset=compute_offset(page, items_per_page),\n            limit=items_per_page,\n            schema_to_select=UserRead,\n            is_deleted=False,\n        )\n    else:\n        users_data = await crud_users.get_multi(\n            db=db,\n            offset=compute_offset(page, items_per_page),\n            limit=items_per_page,\n            schema_to_select=UserRead,\n            is_deleted=False,\n        )\n\n    if users_data is None:\n        raise NotFoundException(\"No User Found\")\n\n    return paginated_response(\n        crud_data=users_data, page=page, items_per_page=items_per_page\n    )\n\n\n@router.get(\"/me\", response_model=UserRead)\nasync def read_user_me(\n    request: Request,\n    current_user: CurrentUser,\n) -> UserRead:\n    return current_user\n\n\n@router.get(\"/me/full\", response_model=UserReadFull)\nasync def read_user_me_full(\n    request: Request,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n) -> UserReadFull:\n    return await get_full_user_details(user=current_user, db=db)\n\n\n@router.get(\"/{username}\", response_model=UserRead)\nasync def read_user(\n    request: Request,\n    username: str,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n) -> dict:\n    if current_user.user_role == AccessLevel_Enum.ADMIN.value:\n        db_user = await crud_users.get(\n            db=db,\n            schema_to_select=UserRead,\n            username=username,\n            is_deleted=False,\n        )\n    else:\n        db_user = await crud_users.get(\n            db=db,\n            schema_to_select=UserRead,\n            username=username,\n            is_deleted=False,\n        )\n    if db_user is None:\n        raise NotFoundException(\"User not found\")\n\n    return db_user\n\n\n@router.patch(\"/{username}\")\nasync def patch_user(\n    request: Request,\n    values: UserUpdate,\n    username: str,\n    current_user: CurrentUser,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n) -> Dict[str, str]:\n    db_user = await crud_users.get(db=db, schema_to_select=UserRead, username=username)\n    if db_user is None:\n        raise NotFoundException(\"User not found\")\n\n    if current_user.username != values.username:\n        # Trying to change for some other user\n        if current_user.user_role != AccessLevel_Enum.ADMIN.value:\n            # Don't have permission\n            raise ForbiddenException(\n                \"Don't have proper access to change other user details\"\n            )\n    else:\n        if current_user.user_role != values.user_role:\n            # Person cannot change his user role on it's own\n            raise ForbiddenException(\"Cannot change own Role, contact admin\")\n\n    # if db_user[\"username\"] != current_user[\"username\"]:\n    #     raise ForbiddenException()\n\n    if values.username != db_user[\"username\"]:\n        existing_username = await crud_users.exists(db=db, username=values.username)\n        if existing_username:\n            raise DuplicateValueException(\"Username not available\")\n\n    if values.email != db_user[\"email\"]:\n        existing_email = await crud_users.exists(db=db, email=values.email)\n        if existing_email:\n            raise DuplicateValueException(\"Email is already registered\")\n\n    await crud_users.update(db=db, object=values, username=username)\n    return {\"message\": \"User updated\"}\n\n\n@router.post(\"/update_profile_image\")\nasync def update_profile_image(\n    request: Request,\n    current_user: CurrentUser,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    file: UploadFile = File(...),\n):\n    db_user = await crud_users.get(\n        db=db, schema_to_select=UserRead, username=current_user.username\n    )\n    if not db_user:\n        raise NotFoundException(\"User not found\")\n\n    FILEPATH = settings.IMAGE_FILE_PATH\n    filename = file.filename\n\n    if filename is None:\n        raise NotFoundException(\"File Not Found\")\n\n    parts: list[str] = filename.split(\".\")\n    if len(parts) < 2:\n        raise ForbiddenException()\n    extension = parts[-1]\n\n    if extension not in [\"png\", \"jpg\"]:\n        raise ForbiddenException(\"Image Type not supported\")\n\n    token_name = current_user.username + \".\" + extension\n    generated_name = os.path.join(FILEPATH, token_name)\n    file_content = await file.read()\n\n    with open(generated_name, \"wb\") as f:\n        f.write(file_content)\n        f.close()\n\n    await file.close()\n\n    # Pillow\n    imgFile = Image.open(generated_name)\n    img = imgFile.resize(size=(200, 200))\n    img.save(generated_name)\n\n    value = UserUpdate(\n        username=current_user.username,\n        user_role=current_user.user_role,\n        email=current_user.email,\n        name=current_user.name,\n        profile_image_url=os.path.join(settings.SERVER_LINK, generated_name),\n    )\n    await crud_users.update(db=db, object=value, username=current_user.username)\n    return {\"message\": \"User Profile Image Updated\"}\n\n\n@router.post(\"/reset_profile_image\")\nasync def reset_profile_image(\n    request: Request,\n    current_user: CurrentUser,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n):\n    db_user = await crud_users.get(\n        db=db, schema_to_select=UserRead, username=current_user.username\n    )\n    if not db_user:\n        raise NotFoundException(\"User not found\")\n\n    value = UserUpdate(\n        username=current_user.username,\n        user_role=current_user.user_role,\n        email=current_user.email,\n        name=current_user.name,\n        profile_image_url=settings.DEFAULT_USER_IMAGE,\n    )\n    await crud_users.update(db=db, object=value, username=current_user.username)\n    return {\"message\": \"User Profile Image Updated\"}\n\n\n@router.delete(\"/delete_user/{username}\")\nasync def erase_user(\n    request: Request,\n    username: str,\n    current_user: CurrentUser,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    token: str = Depends(oauth2_scheme),\n) -> Dict[str, str]:\n    if current_user.user_role != AccessLevel_Enum.ADMIN.value:\n        raise ForbiddenException(\"Don't have access to delete user\")\n    db_user = await crud_users.get(db=db, schema_to_select=UserRead, username=username)\n    if not db_user:\n        raise NotFoundException(\"User not found\")\n\n    await crud_users.delete(db=db, db_row=db_user, username=username)\n    await blacklist_token(token=token, db=db)\n    return {\"message\": \"User deleted\"}\n\n\n@router.delete(\"/delete_user/db_user/{username}\")\nasync def erase_db_user(\n    request: Request,\n    username: str,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentSuperUser,\n) -> Dict[str, str]:\n    db_user = await crud_users.exists(db=db, username=username)\n    if not db_user:\n        raise NotFoundException(\"User not found\")\n\n    # Delete user from the database\n    await crud_users.db_delete(db=db, username=username)\n    return {\"message\": \"User deleted from the database\"}\n"}
{"type": "source_file", "path": "customer_service/app/apis/v1/route_restaurant.py", "content": "# Built-in Dependencies\nfrom typing import Annotated, Any\nfrom uuid import UUID\nimport requests\n\n# Third-Party Dependencies\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom fastapi import Depends, Request\nimport fastapi\n\n# Local Dependencies\nfrom app.core.dependencies import CurrentUser\nfrom app.core.config import settings\nfrom app.db.session import async_get_db\n\nfrom app.utils.paginated import (\n    PaginatedListResponse,\n)\n\nrouter = fastapi.APIRouter(tags=[\"Restaurants\"])\n\n@router.get(\"/list\")\nasync def get_restaurant_list(\n    request: Request,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n    items_per_page: int = 10,\n    page:int = 1\n):\n    url = f\"{settings.RESTAURANT_BASE_API}/api/v1/restaurants/list\"\n    query_params = {\n        \"items_per_page\":items_per_page,\n        \"page\": page\n    }\n    response = requests.get(url, params=query_params)\n    return response.json()\n\n@router.get(\"/menu/{restaurant_id}\")\nasync def get_restaurant_list(\n    request: Request,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    restaurant_id:UUID,\n    current_user: CurrentUser,\n    items_per_page: int = 10,\n    page:int = 1\n):\n    url = f\"{settings.RESTAURANT_BASE_API}/api/v1/menus/{restaurant_id}\"\n    query_params = {\n        \"items_per_page\":items_per_page,\n        \"page\": page\n    }\n    response = requests.get(url, params=query_params)\n    return response.json()"}
{"type": "source_file", "path": "customer_service/app/core/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/core/config.py", "content": "import os\nimport warnings\nfrom typing import Annotated, Any, Literal\n\nfrom pydantic import (\n    AnyUrl,\n    BeforeValidator,\n    computed_field,\n    model_validator,\n)\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\nfrom typing_extensions import Self\n\n\ndef unset_env():\n    all_env = os.environ\n    if \"POSTGRES_SERVER\" in all_env:\n        del os.environ[\"POSTGRES_SERVER\"]\n    if \"POSTGRES_PORT\" in all_env:\n        del os.environ[\"POSTGRES_PORT\"]\n    if \"POSTGRES_USER\" in all_env:\n        del os.environ[\"POSTGRES_USER\"]\n    if \"POSTGRES_PASSWORD\" in all_env:\n        del os.environ[\"POSTGRES_PASSWORD\"]\n    if \"POSTGRES_DB\" in all_env:\n        del os.environ[\"POSTGRES_DB\"]\n    if \"POSTGRES_ASYNC_URI\" in all_env:\n        del os.environ[\"POSTGRES_ASYNC_URI\"]\n    if \"DATABASE_URL\" in all_env:\n        del os.environ[\"DATABASE_URL\"]\n\n\ndef parse_cors(v: Any) -> list[str] | str:\n    if isinstance(v, str) and not v.startswith(\"[\"):\n        return [i.strip() for i in v.split(\",\")]\n    elif isinstance(v, list | str):\n        return v\n    raise ValueError(v)\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(\n        env_file=\"./.env\",\n        env_ignore_empty=True,\n        extra=\"ignore\",\n    )\n\n    API_V1_STR: str = \"/api/v1\"\n    SECRET_KEY: str = \"I_AM_BATMAN\"\n    ALGORITHM: str = \"HS256\"\n\n    # 60 minutes * 24 hours * 8 days = 8 days\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60 * 24 * 8\n    COOKIES_SECURE_SETTINGS: bool = False\n\n    FRONTEND_HOST: str = \"http://localhost:5173\"\n    ENVIRONMENT: Literal[\"local\", \"staging\", \"production\"] = \"local\"\n\n    BACKEND_CORS_ORIGINS: Annotated[\n        list[AnyUrl] | str, BeforeValidator(parse_cors)\n    ] = []\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def all_cors_origins(self) -> list[str]:\n        return [str(origin).rstrip(\"/\") for origin in self.BACKEND_CORS_ORIGINS] + [\n            self.FRONTEND_HOST\n        ]\n\n    PROJECT_NAME: str\n    PROJECT_VERSION: str = \"v0.0.1\"\n    CONTACT_NAME: str = \"Harsh Mittal\"\n    CONTACT_EMAIL: str = \"harsmittal2210@gmail.com\"\n\n    SERVER_IP: str = \"0.0.0.0\"\n    SERVER_PORT: int = 9000\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def SERVER_LINK(self) -> str:\n        return f\"http://{self.SERVER_IP}:{self.SERVER_PORT}/\"\n\n    POSTGRES_USER: str = \"postgres\"\n    POSTGRES_PASSWORD: str = \"postgres\"\n    POSTGRES_SERVER: str = \"localhost\"\n    POSTGRES_PORT: int = 5432\n    POSTGRES_DB: str = \"template_app\"\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def POSTGRES_ASYNC_URI(self) -> str:\n        return f\"postgresql+asyncpg://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}@{self.POSTGRES_SERVER}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}\"\n\n    FIRST_SUPERUSER_NAME: str = \"admin\"\n    FIRST_SUPERUSER_EMAIL: str = \"harshmittal2210@gmail.com\"\n    FIRST_SUPERUSER_USERNAME: str = \"admin\"\n    FIRST_SUPERUSER_PASSWORD: str\n    FIRST_SUPERUSER_PHONE: str = \"+910000000000\"\n    DEFAULT_USER_IMAGE: str = \"https://www.imageurl.com/profile_image.jpg\"\n\n    def _check_default_secret(self, var_name: str, value: str | None) -> None:\n        if value == \"changethis\":\n            message = (\n                f'The value of {var_name} is \"changethis\", '\n                \"for security, please change it, at least for deployments.\"\n            )\n            if self.ENVIRONMENT == \"local\":\n                warnings.warn(message, stacklevel=1)\n            else:\n                raise ValueError(message)\n\n    @model_validator(mode=\"after\")\n    def _enforce_non_default_secrets(self) -> Self:\n        self._check_default_secret(\"SECRET_KEY\", self.SECRET_KEY)\n        self._check_default_secret(\"POSTGRES_PASSWORD\", self.POSTGRES_PASSWORD)\n        self._check_default_secret(\n            \"FIRST_SUPERUSER_PASSWORD\", self.FIRST_SUPERUSER_PASSWORD\n        )\n\n        return self\n\n    DATABASE_USER_TABLE: str = \"users\"\n    DATABASE_USER_ADDRESS_TABLE: str = \"user_address\"\n    DATABASE_ORDER_TABLE: str = \"orders\"\n    DATABASE_ORDER_ITEM_TABLE: str = \"order_items\"\n    DATABASE_ORDER_ITEM_ADDON_TABLE: str = \"order_item_addons\"\n    DATABASE_ORDER_RATING_TABLE: str = \"order_rating\"\n\n    STATIC_FILE_FOLDER: str = \"static\"\n    PROFILE_IMAGE_FOLDER: str = \"profile_images\"\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def IMAGE_FILE_PATH(self) -> str:\n        return f\"{self.STATIC_FILE_FOLDER}/{self.PROFILE_IMAGE_FOLDER}\"\n\n    RESTAURANT_BASE_API: str = \"http://0.0.0.0:9001\"\n    DRIVER_BASE_API: str = \"http://0.0.0.0:3000/v1\"\n\nunset_env()\nsettings = Settings()  # type: ignore\nprint(settings.POSTGRES_DB)\n"}
{"type": "source_file", "path": "customer_service/app/core/dependencies.py", "content": "# Built-in Dependencies\nfrom typing import Annotated, Union, Any, Dict\nimport logging\nimport os\n\n# Third-Party Dependencies\nfrom fastapi import Depends, HTTPException, Request\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n# Local Dependencies\nfrom app.db.crud.crud_user import crud_users\nfrom app.core.http_exceptions import (\n    UnauthorizedException,\n    ForbiddenException,\n    # RateLimitException\n)\n\nfrom app.db.session import async_get_db\nfrom app.core.security import oauth2_scheme, verify_token\nfrom app.schemas.v1.schema_user import UserRead\n\n# Logger instance\nlogger = logging.getLogger(__name__)\n\n\nasync def get_current_user_base(\n    token: str = Depends(oauth2_scheme), db: AsyncSession = Depends(async_get_db)\n) -> UserRead | None:\n    user = await get_current_user(token=token, db=db)\n    if user:\n        return UserRead(**user)\n    return None\n\n\n# Function to get the current user based on the provided authentication token\nasync def get_current_user(\n    token: str = Depends(oauth2_scheme), db: AsyncSession = Depends(async_get_db)\n) -> Union[Dict[str, Any], None]:\n    credentials_exception = UnauthorizedException(\"User not authenticated.\")\n\n    token_data = await verify_token(token, db)\n    if token_data is None:\n        raise credentials_exception\n\n    # Check if the authentication token represents an email or username and retrieve the user information\n    if \"@\" in token_data.username_or_email:\n        user: dict = await crud_users.get(\n            db=db, email=token_data.username_or_email, is_deleted=False\n        )\n    else:\n        user = await crud_users.get(\n            db=db, username=token_data.username_or_email, is_deleted=False\n        )\n\n    if user:\n        # Return the user information if available\n        return user\n\n    # Raise an exception if the user is not authenticated\n    raise credentials_exception\n\n\n# Function to get the optional user based on the provided request\nasync def get_optional_user(\n    request: Request, db: AsyncSession = Depends(async_get_db)\n) -> dict | None:\n    token = request.headers.get(\"Authorization\")\n    if not token:\n        return None\n\n    try:\n        # Parse the Authorization token and verify it to obtain token data\n        token_type, _, token_value = token.partition(\" \")\n        if token_type.lower() != \"bearer\" or not token_value:\n            # Return None if the token is not a bearer token\n            return None\n\n        token_data = await verify_token(token_value, db)\n        if token_data is None:\n            # Return None if token verification fails\n            return None\n\n        # Retrieve the current user information based on the token data\n        return await get_current_user(token_value, db=db)\n\n    except HTTPException as http_exc:\n        if http_exc.status_code != 401:\n            # Log unexpected HTTPException with non-401 status code.\n            logger.error(\n                f\"Unexpected HTTPException in get_optional_user: {http_exc.detail}\"\n            )\n        return None\n\n    except Exception as exc:\n        # Log unexpected errors during execution.\n        logger.error(f\"Unexpected error in get_optional_user: {exc}\")\n        return None\n\n\n# Function to get the current superuser based on the provided current user information\nasync def get_current_superuser(\n    current_user: Annotated[dict, Depends(get_current_user)],\n) -> dict:\n    if not current_user[\"is_superuser\"]:\n        raise ForbiddenException(\"You do not have enough privileges.\")\n\n    return current_user\n\n\ndef create_folders(root_folder, sub_folders):\n    # Create the root folder if it doesn't exist\n    if not os.path.exists(root_folder):\n        os.makedirs(root_folder)\n\n    # Create sub_folders inside the root folder\n    for subfolder in sub_folders:\n        subfolder_path = os.path.join(root_folder, subfolder)\n        if not os.path.exists(subfolder_path):\n            os.makedirs(subfolder_path)\n\n\nCurrentUser = Annotated[UserRead, Depends(get_current_user_base)]\nCurrentSuperUser = Annotated[UserRead, Depends(get_current_superuser)]\n"}
{"type": "source_file", "path": "customer_service/app/core/security.py", "content": "from typing import Optional, Dict, Literal, Union, Any\nfrom datetime import datetime, timedelta, timezone\n\n\n# Third-Party Dependencies\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom fastapi.security import OAuth2\nfrom fastapi.openapi.models import OAuthFlows as OAuthFlowsModel, OAuthFlowPassword\nfrom fastapi import Request, HTTPException, status\nfrom fastapi.security.utils import get_authorization_scheme_param\nfrom jose import jwt, JWTError\n\n\n# Local Dependencies\nfrom app.core.config import settings\nfrom app.schemas.v1.schema_auth import TokenData, TokenBlacklistCreate\nfrom app.db.crud.crud_auth import crud_token_blacklist\nfrom app.db.crud.crud_user import crud_users, get_user\nfrom app.core.hashing import Hasher\n\n\nclass OAuth2PasswordBearerWithCookie(OAuth2):\n    def __init__(\n        self,\n        tokenUrl: str,\n        scheme_name: Optional[str] = None,\n        scopes: Optional[Dict[str, str]] = None,\n        description: Optional[str] = None,\n        auto_error: bool = True,\n    ):\n        if not scopes:\n            scopes = {}\n\n        flows = OAuthFlowsModel(\n            password=OAuthFlowPassword(tokenUrl=tokenUrl, scopes=scopes)\n        )\n        super().__init__(\n            flows=flows,\n            scheme_name=scheme_name,\n            description=description,\n            auto_error=auto_error,\n        )\n\n    async def __call__(self, request: Request) -> Optional[str]:\n        authorization: str | None = request.cookies.get(\"access_token\")\n        scheme, param = get_authorization_scheme_param(authorization)\n        if not authorization or scheme.lower() != \"bearer\":\n            if self.auto_error:\n                raise HTTPException(\n                    status_code=status.HTTP_401_UNAUTHORIZED,\n                    detail=\"Not authenticated\",\n                    headers={\"WWW-Authenticate\": \"Bearer\"},\n                )\n            else:\n                return None\n        return param\n\n\noauth2_scheme = OAuth2PasswordBearerWithCookie(tokenUrl=\"/auth/login\")\n\n\n# Function to authenticate a user based on provided credentials\nasync def authenticate_user(\n    username_or_email: str, password: str, db: AsyncSession\n) -> Union[Dict[str, Any], Literal[False]]:\n    db_user = await get_user(username_or_email, db)\n\n    if not db_user:\n        return False\n\n    elif not Hasher.verify_password(password, db_user[\"hashed_password\"]):\n        return False\n\n    return db_user\n\n\nasync def create_access_token(\n    data: dict, expires_delta: Optional[timedelta] = None\n) -> str:\n    to_encode = data.copy()\n    if expires_delta:\n        expire = datetime.now(timezone.utc).replace(tzinfo=None) + expires_delta\n    else:\n        expire = datetime.now(timezone.utc).replace(tzinfo=None) + timedelta(\n            minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES\n        )\n    to_encode.update({\"exp\": expire})\n    encoded_jwt = jwt.encode(\n        to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM\n    )\n    return encoded_jwt\n\n\n# Function to create a refresh token with optional expiration time\nasync def create_refresh_token(\n    data: Dict[str, Any], expires_delta: timedelta | None = None\n) -> str:\n    to_encode = data.copy()\n    if expires_delta:\n        expire = datetime.now(timezone.utc).replace(tzinfo=None) + expires_delta\n    else:\n        expire = datetime.now(timezone.utc).replace(tzinfo=None) + timedelta(\n            days=settings.ACCESS_TOKEN_EXPIRE_MINUTES\n        )\n    to_encode.update({\"exp\": expire})\n    encoded_jwt: str = jwt.encode(\n        to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM\n    )\n    return encoded_jwt\n\n\n# Function to verify the validity of a token and return TokenData if valid\nasync def verify_token(token: str, db: AsyncSession) -> TokenData | None:\n    \"\"\"\n    Verify a JWT token and return TokenData if valid.\n\n    Parameters\n    ----------\n    token: str\n        The JWT token to be verified.\n    db: AsyncSession\n        Database session for performing database operations.\n\n    Returns\n    ----------\n    TokenData | None\n        An instance of TokenData representing the user if the token is valid.\n        None is returned if the token is invalid or the user is not active.\n    \"\"\"\n    is_blacklisted = await crud_token_blacklist.exists(db, token=token)\n    if is_blacklisted:\n        return None\n\n    try:\n        # Decode the token payload and extract the subject (username or email)\n        payload = jwt.decode(\n            token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM]\n        )\n        username_or_email: str | None = payload.get(\"sub\")\n        if username_or_email is None:\n            return None\n\n        # Check if the Redis client is available\n        # if cache.client:\n        #     # Check if user is active in Redis\n        #     is_active = await cache.client.hget(\n        #         settings.REDIS_HASH_SYSTEM_AUTH_VALID_USERNAMES,\n        #         username_or_email,\n        #     )\n\n        #     if is_active:\n        #         return TokenData(username_or_email=username_or_email)\n\n        # If not active in Redis or Redis is not available, check PostgreSQL\n        user = await crud_users.get(db=db, username=username_or_email, is_deleted=False)\n\n        if user:\n            # Update Redis with user active status if Redis is available\n            # if cache.client:\n            #     await cache.client.hset(\n            #         settings.REDIS_HASH_SYSTEM_AUTH_VALID_USERNAMES,\n            #         username_or_email,\n            #         \"active\",\n            #     )\n\n            return TokenData(username_or_email=username_or_email)\n\n        # If user is not found in Redis or PostgreSQL, blacklist the token\n        await blacklist_token(token=token, db=db)\n\n        return None\n\n    except JWTError:\n        return None\n\n\n# Function to blacklist a token by storing it in the database\nasync def blacklist_token(token: str, db: AsyncSession) -> None:\n    payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])\n    expires_at = datetime.fromtimestamp(payload.get(\"exp\", 0.0))\n    await crud_token_blacklist.create(\n        db,\n        object=TokenBlacklistCreate(**{\"token\": token, \"expires_at\": expires_at}),\n    )\n"}
{"type": "source_file", "path": "customer_service/app/apis/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/apis/v1/route_order.py", "content": "# Built-in Dependencies\nfrom typing import Annotated, Any\nfrom uuid import UUID\nimport requests\n\n\n# Third-Party Dependencies\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom fastapi import Depends, Request\nimport fastapi\n\n# Local Dependencies\nfrom app.core.dependencies import CurrentUser\nfrom app.db.crud.crud_order import (\n    add_new_order,\n    update_order_status,\n    get_order_details,\n    get_order_list,\n    update_driver,\n    get_restaurant_order_list\n)\nfrom app.db.session import async_get_db\nfrom app.schemas.v1.schema_order import OrderCreate, OrderRead, OrderUpdateDriverDetails\n\nfrom app.db.models.v1.db_order import Order_Status_Enum\nfrom app.utils.paginated import (\n    PaginatedListResponse,\n)\nfrom app.core.config import settings\n\nrouter = fastapi.APIRouter(tags=[\"Orders\"])\n\n\n@router.post(\"/create\", response_model=OrderRead, status_code=201)\nasync def create_order(\n    request: Request,\n    order: OrderCreate,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n) -> Any:\n    order = await add_new_order(user=current_user, order=order, db=db)\n    ## Ask for driver\n    url = f\"{settings.DRIVER_BASE_API}/orders\"\n    query_params = {\n        \"cash_amount\":-1,\n        \"customer_addr\":\"Dummy Address\",\n        \"customer_id\": str(current_user.id),\n        \"customer_lat\": \"654.64565\",\n        \"customer_long\": \"66.6546565\",\n        \"customer_name\": current_user.name,\n        \"customer_phone\": str(current_user.phone) if current_user.phone != \"\" else \" \",\n        \"delivery_dist\": 88,\n        \"earning\":order.total_cost,\n        \"is_cash_payment\":True,\n        \"order_id\":str(order.id),\n        \"restaurant_addr\": \"Dummy Address 1\",\n        \"restaurant_id\":str(order.restaurant_id),\n        \"restaurant_lat\": \"78.654654\",\n        \"restaurant_long\": \"156.654564\",\n        \"restaurant_name\": \"Dummy Name 1\",\n        \"tip\":-1,\n    }\n\n    response = requests.post(url, json=query_params)\n    if response.status_code == 201:\n        print(\"New order created in driver service\")\n    else:\n        print(f\"Error in creating order in driver service : {response.content}\")\n    return order\n\n\n@router.get(\"/list\", response_model=PaginatedListResponse[OrderRead])\nasync def order_list(\n    request: Request,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    current_user: CurrentUser,\n    page: int = 1,\n    items_per_page: int = 10,\n):\n    return await get_order_list(\n        db=db, items_per_page=items_per_page, page=page, user=current_user\n    )\n\n@router.put(\"/assign/{order_id}\")\nasync def assign_order_driver(\n    request: Request,\n    order_id: UUID,\n    driver_details:OrderUpdateDriverDetails,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n):\n    await update_driver(db=db, driver_details=driver_details, order_id=order_id)\n    return {\"status\":\"Driver Assigned\"}\n\n\n@router.get(\"/{order_id}\", response_model=OrderRead)\nasync def get_order(\n    request: Request, order_id: UUID, db: Annotated[AsyncSession, Depends(async_get_db)]\n):\n    return await get_order_details(db=db, order_id=order_id)\n\n\n@router.put(\"/{order_id}\", status_code=200)\nasync def update_status(\n    request: Request,\n    order_id: UUID,\n    status: Order_Status_Enum,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    restaurant_id: str | None = None,\n    customer_id: UUID | None = None,\n    driver_id: str | None = None,\n):\n    status = await update_order_status(\n        customer_id=customer_id,\n        restaurant_id=restaurant_id,\n        driver_id=driver_id,\n        order_id=order_id,\n        status=status,\n        db=db,\n    )\n\n    if status:\n        return {\"status\": \"Updated\"}\n    return {\"status\": \"Not Updated, Check value sent\"}\n\n@router.get(\"/restaurant/list\", response_model=PaginatedListResponse[OrderRead])\nasync def order_list(\n    request: Request,\n    db: Annotated[AsyncSession, Depends(async_get_db)],\n    restaurant_id:str,\n    status:Order_Status_Enum,\n    page: int = 1,\n    items_per_page: int = 10,\n):\n    return await get_restaurant_order_list(\n        db=db, items_per_page=items_per_page, page=page, restaurant_id=restaurant_id, status=status\n    )"}
{"type": "source_file", "path": "customer_service/app/backend_pre_start.py", "content": "import logging\nimport asyncio\n\nfrom sqlalchemy import text\nfrom sqlmodel import select\nfrom tenacity import after_log, before_log, retry, stop_after_attempt, wait_fixed\n\nfrom app.db.session import async_get_db\nfrom app.core.config import settings\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nmax_tries = 60 * 5  # 5 minutes\nwait_seconds = 1\n\n\n@retry(\n    stop=stop_after_attempt(max_tries),\n    wait=wait_fixed(wait_seconds),\n    before=before_log(logger, logging.INFO),\n    after=after_log(logger, logging.WARN),\n)\nasync def init(get_db) -> None:\n    try:\n        async for db in get_db():\n            await db.exec(select(1))\n    except Exception as e:\n        if \"does not exist\" in e.__str__():\n            logger.info(\"Creating new database\")\n            await create_database(get_db)\n            return\n        logger.error(e)\n        raise e\n\n\n# TODO: Fix create database\nasync def create_database(get_db) -> None:\n    try:\n        async for db in get_db():\n            await db.exec(text(f\"CREATE DATABASE {settings.POSTGRES_DB}\"))\n            await db.commit()\n    except Exception as e:\n        logger.error(e)\n        raise e\n\n\ndef main() -> None:\n    logger.info(\"Initializing service\")\n    asyncio.run(init(async_get_db))\n    logger.info(\"Service finished initializing\")\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "customer_service/app/core/hashing.py", "content": "from passlib.context import CryptContext\n\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n\n\nclass Hasher:\n    @staticmethod\n    def verify_password(plain_password, hashed_password):\n        return pwd_context.verify(plain_password, hashed_password)\n\n    @staticmethod\n    def get_hash_password(plain_password):\n        return pwd_context.hash(plain_password)\n"}
{"type": "source_file", "path": "customer_service/app/alembic/versions/2024_12_11_1906-89954c68c8e5_update_driver_id.py", "content": "\"\"\"Update Driver ID\n\nRevision ID: 89954c68c8e5\nRevises: 868c2adca258\nCreate Date: 2024-12-11 19:06:40.361251\n\n\"\"\"\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\nimport sqlmodel\n\nfrom app.core.config import settings\n\n\n\n# revision identifiers, used by Alembic.\nrevision: str = '89954c68c8e5'\ndown_revision: Union[str, None] = '868c2adca258'\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    # op.execute(\"UPDATE orders SET delivery_person_id = NULL\")\n    # op.alter_column('orders', 'delivery_person_id',\n    #            existing_type=sa.INTEGER(),\n    #            type_=sa.Uuid(),\n    #            existing_nullable=True)\n    op.execute(f\"\"\"\n        ALTER TABLE {settings.DATABASE_ORDER_TABLE}\n        ALTER COLUMN delivery_person_id\n        TYPE UUID\n        USING NULL;\n    \"\"\")\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.execute(f\"\"\"\n        ALTER TABLE {settings.DATABASE_ORDER_TABLE}\n        ALTER COLUMN delivery_person_id\n        TYPE INTEGER\n        USING NULL;\n    \"\"\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "customer_service/app/db/crud/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/db/crud/crud_order.py", "content": "from uuid import UUID\n\n# Third-Party Dependencies\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n# Local Dependencies\nfrom app.db.crud.base import CRUDBase\nfrom app.schemas.v1.schema_user import UserRead\nfrom app.db.models.v1.db_order import Order, OrderItem, OrderAddOn, Order_Status_Enum\nfrom app.schemas.v1.schema_order import (\n    OrderCreateInternal,\n    OrderUpdate,\n    OrderUpdateInternal,\n    OrderDelete,\n    OrderCreate,\n    OrderRead,\n    OrderItemCreateInternal,\n    OrderItemUpdate,\n    OrderItemUpdateInternal,\n    OrderItemDelete,\n    OrderItemRead,\n    OrderAddOnCreateInternal,\n    OrderAddOnUpdate,\n    OrderAddOnUpdateInternal,\n    OrderAddOnDelete,\n    OrderAddOnRead,\n    OrderUpdateDriverDetails,\n)\nfrom app.core.http_exceptions import ForbiddenException, NotFoundException\n\nfrom app.utils.paginated import (\n    paginated_response,\n    compute_offset,\n)\n\n\n# CRUD operations for the 'Order' model\nCRUDOrder = CRUDBase[\n    Order,\n    OrderCreateInternal,\n    OrderUpdate,\n    OrderUpdateInternal,\n    OrderDelete,\n]\n\n# Create an instance of CRUDUser for the 'Order' model\ncrud_order = CRUDOrder(Order)\n\n# CRUD operations for the 'OrderItem' model\nCRUDOrderItem = CRUDBase[\n    OrderItem,\n    OrderItemCreateInternal,\n    OrderItemUpdate,\n    OrderItemUpdateInternal,\n    OrderItemDelete,\n]\n\n# Create an instance of CRUDUser for the 'OrderItem' model\ncrud_orderItem = CRUDOrderItem(OrderItem)\n\n# CRUD operations for the 'OrderAddOn' model\nCRUDOrderAddOn = CRUDBase[\n    OrderAddOn,\n    OrderAddOnCreateInternal,\n    OrderAddOnUpdate,\n    OrderAddOnUpdateInternal,\n    OrderAddOnDelete,\n]\n\n# Create an instance of CRUDUser for the 'OrderAddOn' model\ncrud_orderAddOn = CRUDOrderAddOn(OrderAddOn)\n\n\nasync def add_new_order(user: UserRead, order: OrderCreate, db: AsyncSession):\n    order_c = OrderCreateInternal(\n        customer_id=order.customer_id,\n        address_id=order.address_id,\n        restaurant_id=order.restaurant_id,\n        total_cost=0.0,\n    )\n\n    order_db = await crud_order.create(db=db, object=order_c)\n    total_price: float = 0\n    ## parse orders items\n    for item in order.items:\n        item_c = OrderItemCreateInternal(order_id=order_db.id, **item.model_dump())\n        item_db = await crud_orderItem.create(db=db, object=item_c)\n        for add_on in item.add_ons:\n            add_on_c = OrderAddOnCreateInternal(\n                order_item_id=item_db.id,\n                name=add_on.name,\n                price=add_on.price,\n            )\n            total_price += add_on.price\n            await crud_orderAddOn.create(db=db, object=add_on_c)\n        total_price += item.price_per_unit * item.quantity\n    order_db.total_cost = total_price\n    await crud_order.update(db=db, object=order_db, id=order_db.id)  # type:ignore\n    return order_db\n\n\nasync def get_order_details(\n    order_id: UUID,\n    db: AsyncSession,\n):\n    order_db = await crud_order.get(db=db, id=order_id)\n    if order_db == None:\n        raise NotFoundException(\"Order not found\")\n    items = await crud_orderItem.get_multi(\n        db=db,\n        limit=100,\n        offset=0,\n        is_deleted=False,\n        schema_to_select=OrderItemRead,\n        order_id=order_db[\"id\"],\n    )\n    items = items[\"data\"]\n    for item in items:\n        add_ons = await crud_orderAddOn.get_multi(\n            db=db,\n            limit=100,\n            offset=0,\n            is_deleted=False,\n            schema_to_select=OrderAddOnRead,\n            order_item_id=item[\"id\"],  # type:ignore\n        )\n        add_ons = add_ons[\"data\"]\n        item[\"add_ons\"] = add_ons  # type:ignore\n    order_db[\"items\"] = items\n\n    return order_db\n\n\nasync def get_order_list(\n    user: UserRead,\n    db: AsyncSession,\n    page: int = 1,\n    items_per_page: int = 10,\n):\n    order_data = await crud_order.get_multi(\n        db=db,\n        offset=compute_offset(page, items_per_page),\n        limit=items_per_page,\n        schema_to_select=OrderRead,\n        is_deleted=False,\n        customer_id=user.id,\n    )\n    return paginated_response(\n        crud_data=order_data, page=page, items_per_page=items_per_page\n    )\n\nasync def get_restaurant_order_list(\n    restaurant_id:str,\n    status:Order_Status_Enum,\n    db: AsyncSession,\n    page: int = 1,\n    items_per_page: int = 10,\n):\n    order_data = await crud_order.get_multi(\n        db=db,\n        offset=compute_offset(page, items_per_page),\n        limit=items_per_page,\n        schema_to_select=OrderRead,\n        is_deleted=False,\n        restaurant_id=restaurant_id,\n        status=status\n    )\n    return paginated_response(\n        crud_data=order_data, page=page, items_per_page=items_per_page\n    )\n\n\nasync def update_order_status(\n    order_id: UUID,\n    status: Order_Status_Enum,\n    db: AsyncSession,\n    customer_id: UUID | None = None,\n    restaurant_id: str | None = None,\n    driver_id: str | None = None,\n):\n    order_db = await crud_order.get(db=db, id=order_id)\n    check_fag: bool = False\n    if customer_id is not None:\n        check_fag = True\n        if order_db[\"customer_id\"] != customer_id:\n            raise ForbiddenException(\"Different Customer Trying to update order status\")\n\n    if restaurant_id is not None:\n        check_fag = True\n        if order_db[\"restaurant_id\"] != restaurant_id:\n            raise ForbiddenException(\n                \"Different Restaurant Trying to update order status\"\n            )\n\n    if driver_id is not None:\n        check_fag = True\n        if order_db[\"delivery_person_id\"] != int(driver_id):\n            raise ForbiddenException(\"Different Driver Trying to update order status\")\n    if check_fag is False:\n        raise ForbiddenException(\"Wrong Params Entered\")\n    order_db[\"status\"] = status\n    await crud_order.update(db=db, object=order_db, id=order_id)\n    return True\n\nasync def update_driver(\n    order_id: UUID,\n    driver_details: OrderUpdateDriverDetails,\n    db: AsyncSession,\n):\n    await crud_order.update(db=db, object=driver_details, id=order_id)\n"}
{"type": "source_file", "path": "customer_service/app/db/crud/crud_helper.py", "content": "# Built-in Dependencies\nfrom typing import Any, List, Type, Union, Optional\n\n# Third-Party Dependencies\nfrom sqlalchemy.orm import DeclarativeMeta\nfrom sqlalchemy.sql.elements import Label\nfrom sqlalchemy.sql import ColumnElement\nfrom sqlalchemy.sql.schema import Column\nfrom sqlmodel import inspect\nfrom pydantic import BaseModel\n\n# Local Dependencies\nfrom app.db.models.v1.common import Base\n\n\ndef _extract_matching_columns_from_schema(\n    model: Type[Base], schema: Union[Type[BaseModel], list, None]\n) -> List[Any]:\n    \"\"\"\n    Retrieves a list of ORM column objects from a SQLAlchemy model that match the field names in a given Pydantic schema.\n\n    Parameters\n    ----------\n    model: Type[Base]\n        The SQLAlchemy ORM model containing columns to be matched with the schema fields.\n    schema: Type[BaseModel]\n        The Pydantic schema containing field names to be matched with the model's columns.\n\n    Returns\n    ----------\n    List[Any]\n        A list of ORM column objects from the model that correspond to the field names defined in the schema.\n    \"\"\"\n    column_list = list(model.__table__.columns)  # type: ignore\n    if schema is not None:\n        if isinstance(schema, list):\n            schema_fields = schema\n        else:\n            schema_fields = schema.model_fields.keys()  # type: ignore\n\n        column_list = []\n        for column_name in schema_fields:\n            if hasattr(model, column_name):\n                column_list.append(getattr(model, column_name))\n\n    return column_list\n\n\ndef _extract_matching_columns_from_kwargs(model: Type[Base], kwargs: dict) -> List[Any]:\n    if kwargs is not None:\n        kwargs_fields = kwargs.keys()\n        column_list = []\n        for column_name in kwargs_fields:\n            if hasattr(model, column_name):\n                column_list.append(getattr(model, column_name))\n\n    return column_list\n\n\ndef _extract_matching_columns_from_column_names(\n    model: Type[Base], column_names: list\n) -> List[Any]:\n    column_list = []\n    for column_name in column_names:\n        if hasattr(model, column_name):\n            column_list.append(getattr(model, column_name))\n\n    return column_list\n\n\ndef _auto_detect_join_condition(\n    base_model: Type[DeclarativeMeta], join_model: Type[DeclarativeMeta]\n) -> Optional[ColumnElement]:\n    \"\"\"\n    Automatically detects the join condition for SQLAlchemy models based on foreign key relationships.\n    This function scans the foreign keys in the base model and tries to match them with columns in the join model.\n\n    Parameters\n    ----------\n    base_model : Type[DeclarativeMeta]\n        The base SQLAlchemy model from which to join.\n    join_model : Type[DeclarativeMeta]\n        The SQLAlchemy model to join with the base model.\n\n    Returns\n    ----------\n    Optional[ColumnElement]\n        A SQLAlchemy ColumnElement representing the join condition, if successfully detected.\n\n    Raises\n    ------\n    ValueError\n        If the join condition cannot be automatically determined, a ValueError is raised.\n\n    Example\n    ----------\n    # Assuming User has a foreign key reference to Tier:\n    join_condition = auto_detect_join_condition(User, Tier)\n    \"\"\"\n    fk_columns = [col for col in inspect(base_model).c if col.foreign_keys]  # type: ignore\n    join_on = next(\n        (\n            base_model.__table__.c[col.name]  # type: ignore\n            == join_model.__table__.c[list(col.foreign_keys)[0].column.name]  # type: ignore\n            for col in fk_columns\n            if list(col.foreign_keys)[0].column.table == join_model.__table__  # type: ignore\n        ),\n        None,\n    )\n\n    if join_on is None:\n        raise ValueError(\n            \"Could not automatically determine join condition. Please provide join_on.\"\n        )\n\n    return join_on\n\n\ndef _add_column_with_prefix(column: Column, prefix: Optional[str]) -> Label:\n    \"\"\"\n    Creates a SQLAlchemy column label with an optional prefix.\n\n    Parameters\n    ----------\n    column : Column\n        The SQLAlchemy Column object to be labeled.\n    prefix : Optional[str]\n        An optional prefix to prepend to the column's name.\n\n    Returns\n    ----------\n    Label\n        A labeled SQLAlchemy Column object.\n    \"\"\"\n    column_label = f\"{prefix}{column.name}\" if prefix else column.name\n    return column.label(column_label)\n"}
{"type": "source_file", "path": "customer_service/app/db/crud/crud_auth.py", "content": "# Local Dependencies\nfrom app.schemas.v1.schema_auth import (\n    TokenBlacklistCreate,\n    TokenBlacklistUpdate,\n)\nfrom app.db.models.v1.db_auth import TokenBlacklist\nfrom app.db.crud.base import CRUDBase\n\n# Define a CRUD (Create, Read, Update, Delete) interface for the TokenBlacklist model\nCRUDTokenBlacklist = CRUDBase[  # type: ignore\n    TokenBlacklist,\n    TokenBlacklistCreate,\n    TokenBlacklistUpdate,\n    TokenBlacklistUpdate,\n    None,\n]\n\n# Create an instance of the CRUDTokenBlacklist with the TokenBlacklist model\ncrud_token_blacklist = CRUDTokenBlacklist(TokenBlacklist)  # type: ignore\n"}
{"type": "source_file", "path": "customer_service/app/db/models/v1/db_auth.py", "content": "# Built-in Dependencies\nfrom datetime import datetime\n\n# Third-Party Dependencies\nfrom sqlmodel import Field\n\n# Local Dependencies\nfrom app.db.models.v1.common import TimestampMixin, UUIDMixin, Base\n\n\nclass TokenBlacklistBase(Base):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    'TokenBlacklistBase' pydantic class with information about blacklisted tokens.\n\n    Fields:\n    ----------\n    - 'token': Token value for authentication.\n    - 'expires_at': Timestamp indicating the expiration date and time of the token.\n\n    Examples:\n    ----------\n    Examples of valid data for each field:\n    - 'token': \"example_token_value\"\n    - 'expires_at': \"2024-01-20T12:00:00\"\n\n    Note: The 'expires_at' field should be provided in ISO 8601 format.\n    \"\"\"\n\n    # Data Columns\n    token: str = Field(\n        index=True,\n        nullable=False,\n        default=None,\n        description=\"Token value for authentication\",\n    )\n    expires_at: datetime = Field(\n        nullable=False,\n        default=None,\n        description=\"Timestamp indicating the expiration date and time of the token\",\n    )  # type: ignore\n\n\nclass TokenBlacklist(TokenBlacklistBase, UUIDMixin, TimestampMixin, table=True):\n    \"\"\"\n    SQLModel Table\n\n    Description:\n    ----------\n    'TokenBlacklist' ORM class representing the 'system_token_blacklist' database table.\n\n    Fields:\n    ----------\n    - 'token': Token value for authentication.\n    - 'expires_at': Timestamp indicating the expiration date and time of the token.\n    - 'id': Unique identifier (UUID) for the token blacklist entry.\n    - 'created_at': Timestamp for the creation of the token blacklist entry.\n    - 'updated_at': Timestamp for the last update of the token blacklist entry.\n\n    Table Name:\n    ----------\n    'system_token_blacklist'\n    \"\"\"\n\n    __tablename__ = \"system_token_blacklist\"\n"}
{"type": "source_file", "path": "customer_service/app/core/http_exceptions.py", "content": "# Built-in Dependencies\nfrom http import HTTPStatus\n\n# Third-Party Dependencies\nfrom fastapi import HTTPException, status\n\n\nclass CustomException(HTTPException):\n    \"\"\"\n    Custom base exception class for handling HTTP exceptions.\n\n    Parameters\n    ----------\n    status_code : int, optional\n        The HTTP status code for the exception. Defaults to 500 (Internal Server Error).\n    detail : str, optional\n        A detailed message providing information about the exception. If not provided, it defaults to the description\n        associated with the specified status code.\n    \"\"\"\n\n    def __init__(\n        self,\n        status_code: int = status.HTTP_500_INTERNAL_SERVER_ERROR,\n        detail: str | None = None,\n    ):\n        if not detail:\n            detail = HTTPStatus(status_code).description\n        super().__init__(status_code=status_code, detail=detail)\n\n\nclass BadRequestException(CustomException):\n    \"\"\"\n    Exception for bad client requests (HTTP 400 Bad Request).\n\n    Parameters\n    ----------\n    detail : str, optional\n        A detailed message providing information about the exception.\n    \"\"\"\n\n    def __init__(self, detail: str | None = None):\n        super().__init__(status_code=status.HTTP_400_BAD_REQUEST, detail=detail)\n\n\nclass NotFoundException(CustomException):\n    \"\"\"\n    Exception for not found resources (HTTP 404 Not Found).\n\n    Parameters\n    ----------\n    detail : str, optional\n        A detailed message providing information about the exception.\n    \"\"\"\n\n    def __init__(self, detail: str | None = None):\n        super().__init__(status_code=status.HTTP_404_NOT_FOUND, detail=detail)\n\n\nclass ForbiddenException(CustomException):\n    \"\"\"\n    Exception for forbidden access (HTTP 403 Forbidden).\n\n    Parameters\n    ----------\n    detail : str, optional\n        A detailed message providing information about the exception.\n    \"\"\"\n\n    def __init__(self, detail: str | None = None):\n        super().__init__(status_code=status.HTTP_403_FORBIDDEN, detail=detail)\n\n\nclass UnauthorizedException(CustomException):\n    \"\"\"\n    Exception for unauthorized access (HTTP 401 Unauthorized).\n\n    Parameters\n    ----------\n    detail : str, optional\n        A detailed message providing information about the exception.\n    \"\"\"\n\n    def __init__(self, detail: str | None = None):\n        super().__init__(status_code=status.HTTP_401_UNAUTHORIZED, detail=detail)\n\n\nclass UnprocessableEntityException(CustomException):\n    \"\"\"\n    Exception for unprocessable entities (HTTP 422 Unprocessable Entity).\n\n    Parameters\n    ----------\n    detail : str, optional\n        A detailed message providing information about the exception.\n    \"\"\"\n\n    def __init__(self, detail: str | None = None):\n        super().__init__(\n            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, detail=detail\n        )\n\n\nclass DuplicateValueException(CustomException):\n    \"\"\"\n    Exception for duplicate values (HTTP 422 Unprocessable Entity).\n\n    Parameters\n    ----------\n    detail : str, optional\n        A detailed message providing information about the exception.\n    \"\"\"\n\n    def __init__(self, detail: str | None = None):\n        super().__init__(\n            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, detail=detail\n        )\n\n\nclass RateLimitException(CustomException):\n    \"\"\"\n    Exception for rate limit exceeded (HTTP 429 Too Many Requests).\n\n    Parameters\n    ----------\n    detail : str, optional\n        A detailed message providing information about the exception.\n    \"\"\"\n\n    def __init__(self, detail: str | None = None):\n        super().__init__(status_code=status.HTTP_429_TOO_MANY_REQUESTS, detail=detail)\n"}
{"type": "source_file", "path": "customer_service/app/schemas/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/db/models/v1/db_address.py", "content": "# Built-in Dependencies\nfrom typing import Optional\nfrom uuid import UUID\n\n# Third-Party Dependencies\nfrom sqlmodel import Field, Relationship\nfrom enum import Enum\n\n# Local Dependencies\nfrom app.db.models.v1.common import (\n    SoftDeleteMixin,\n    TimestampMixin,\n    UUIDMixin,\n    Base,\n)\nfrom app.core.config import settings\n\n\nclass UserAddressType_Enum(str, Enum):\n    HOME = \"home\"\n    OFFICE = \"office\"\n    OTHER = \"other\"\n\n\nclass UserAddressLocation(Base):\n    latitude: float = Field(\n        default=0.0, nullable=False, description=\"Latitude coordinate of the address\"\n    )\n    longitude: float = Field(\n        default=0.0, nullable=False, description=\"Longitude coordinate of the address\"\n    )\n\n\nclass UserAddressInfoBase(Base):\n    address_line_1: str = Field(default=\"\", nullable=True)\n    address_line_2: Optional[str] = Field(default=None, nullable=False)\n    city: str = Field(default=\"\", nullable=True)\n    state: str = Field(default=\"\", nullable=True)\n    postal_code: str = Field(default=\"\", nullable=True)\n    country: str = Field(default=\"\", nullable=True)\n\n    add_type: UserAddressType_Enum = Field(\n        default=UserAddressType_Enum.OTHER, nullable=False\n    )\n\n    customer_id: UUID = Field(foreign_key=f\"{settings.DATABASE_USER_TABLE}.id\")\n\n\nclass UserAddressUserDetails(Base):\n    customer = Relationship(back_populates=\"user_addresses\")\n\n\nclass UserAddress(\n    UserAddressInfoBase,\n    UserAddressUserDetails,\n    UserAddressLocation,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n    table=True,\n):\n    __tablename__ = f\"{settings.DATABASE_USER_ADDRESS_TABLE}\"\n    # orders: List[\"Order\"] = Relationship(back_populates=\"delivery_address\") # List[\"Order\"]\n"}
{"type": "source_file", "path": "customer_service/app/db/crud/crud_user.py", "content": "from typing import Dict, Any, Literal, Union\n\n# Third-Party Dependencies\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n# Local Dependencies\nfrom app.db.crud.base import CRUDBase\nfrom app.db.models.v1.db_user import User\nfrom app.schemas.v1.schema_user import (\n    UserCreateInternal,\n    UserUpdate,\n    UserUpdateInternal,\n    UserDelete,\n    UserCreate,\n    UserReadFull,\n    UserRead,\n)\n\nfrom app.core.http_exceptions import DuplicateValueException\n\nfrom app.core.hashing import Hasher\nfrom app.db.crud.crud_user_address import get_address_list_details\n\n# CRUD operations for the 'User' model\nCRUDUser = CRUDBase[\n    User, UserCreateInternal, UserUpdate, UserUpdateInternal, UserDelete\n]\n\n# Create an instance of CRUDUser for the 'User' model\ncrud_users = CRUDUser(User)\n\n\nasync def create_new_user(user: UserCreate, db: AsyncSession) -> User:\n    email_row = await crud_users.exists(db=db, email=user.email)\n    if email_row:\n        raise DuplicateValueException(\"Email is already registered\")\n    username_row = await crud_users.exists(db=db, username=user.username)\n    if username_row:\n        raise DuplicateValueException(\"Username not available\")\n\n    user_internal_dict = user.model_dump()\n    user_internal_dict[\"hashed_password\"] = Hasher.get_hash_password(\n        plain_password=user_internal_dict[\"password\"]\n    )\n    del user_internal_dict[\"password\"]\n\n    user_internal = UserCreateInternal(**user_internal_dict)\n    return await crud_users.create(db=db, object=user_internal)\n\n\nasync def get_user(\n    username_or_email: str, db: AsyncSession\n) -> Union[Dict[str, Any], Literal[None]]:\n    if \"@\" in username_or_email:\n        db_user: dict = await crud_users.get(\n            db=db, email=username_or_email, is_deleted=False\n        )\n    else:\n        db_user = await crud_users.get(\n            db=db, username=username_or_email, is_deleted=False\n        )\n\n    if not db_user:\n        return None\n\n    return db_user\n\n\nasync def get_full_user_details(user: UserRead, db: AsyncSession):\n    address_list = await get_address_list_details(\n        user=user, db=db, items_per_page=100, page=1\n    )\n    address = address_list[\"data\"]\n\n    return UserReadFull(addresses=address, **user.model_dump())\n"}
{"type": "source_file", "path": "customer_service/app/schemas/v1/schema_order.py", "content": "# Built-in Dependencies\nfrom typing import List\nfrom datetime import datetime\n\n# Third-Party Dependencies\nfrom pydantic import BaseModel, Field, ConfigDict\n\n# Local Dependencies\nfrom app.db.models.v1.common import UUIDMixin, TimestampMixin, SoftDeleteMixin\nfrom app.utils.partial import optional\n\nfrom app.db.models.v1.db_order import (\n    OrderAddOnBaseInfo,\n    OrderItemBaseInfo,\n    OrderBaseInfo,\n    OrderBaseDeliveryBaseInfo,\n    OrderStatusInfo,\n    OrderPaymentDetails,\n    OrderItemRelations,\n    OrderAddOnRelation,\n)\n\n\nclass OrderAddOnBase(OrderAddOnBaseInfo):\n    pass\n\n\nclass OrderAddOn(\n    OrderAddOnBase,\n    OrderAddOnRelation,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n):\n    pass\n\n\nclass OrderAddOnRead(OrderAddOnBase, OrderAddOnRelation, UUIDMixin):\n    pass\n\n\nclass OrderAddOnCreate(\n    OrderAddOnBase,\n):\n    class Config:\n        extra = \"forbid\"\n\n\nclass OrderAddOnCreateInternal(OrderAddOnBase, OrderAddOnRelation):\n    pass\n\n\n@optional()\nclass OrderAddOnUpdate(\n    OrderAddOnBase,\n):\n    class Config:\n        extra = \"forbid\"\n\n\nclass OrderAddOnUpdateInternal(\n    OrderAddOnBase,\n):\n    updated_at: datetime\n\n\nclass OrderAddOnDelete(SoftDeleteMixin):\n    model_config = ConfigDict(extra=\"forbid\")  # type: ignore\n\n\nclass OrderAddOnRestoreDeleted(BaseModel):\n    is_deleted: bool\n\n\n## Order Item\nclass OrderItemBase(OrderItemBaseInfo):\n    pass\n\n\nclass OrderItem(\n    OrderItemBase,\n    OrderItemRelations,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n):\n    pass\n\n\nclass OrderItemRead(OrderItemBase, OrderItemRelations, UUIDMixin):\n    pass\n\n\nclass OrderItemCreate(\n    OrderItemBase,\n):\n    add_ons: List[OrderAddOnCreate] = Field(default=[])\n\n    class Config:\n        extra = \"forbid\"\n\n\nclass OrderItemCreateInternal(OrderItemBase, OrderItemRelations):\n    pass\n\n\n@optional()\nclass OrderItemUpdate(\n    OrderItemBase,\n):\n    class Config:\n        extra = \"forbid\"\n\n\nclass OrderItemUpdateInternal(\n    OrderItemBase,\n):\n    updated_at: datetime\n\n\nclass OrderItemDelete(SoftDeleteMixin):\n    model_config = ConfigDict(extra=\"forbid\")  # type: ignore\n\n\nclass OrderItemRestoreDeleted(BaseModel):\n    is_deleted: bool\n\n\n## Order\nclass OrderBase(OrderBaseInfo):\n    pass\n\n\nclass Order(\n    OrderBase,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n):\n    pass\n\n\nclass OrderRead(\n    OrderBase,\n    UUIDMixin,\n    OrderBaseDeliveryBaseInfo,\n    OrderStatusInfo,\n    OrderPaymentDetails,\n):\n    items: list = []\n    pass\n\n\nclass OrderCreate(\n    OrderBase,\n):\n    items: List[OrderItemCreate] = Field(default=[])\n\n    class Config:\n        extra = \"forbid\"\n\n\nclass OrderCreateInternal(\n    OrderBase,\n):\n    pass\n\n\n@optional()\nclass OrderUpdate(\n    OrderBase,\n):\n    class Config:\n        extra = \"forbid\"\n\n\nclass OrderUpdateInternal(\n    OrderBase, OrderBaseDeliveryBaseInfo, OrderStatusInfo, OrderPaymentDetails\n):\n    updated_at: datetime\n\n\nclass OrderDelete(SoftDeleteMixin):\n    model_config = ConfigDict(extra=\"forbid\")  # type: ignore\n\n\nclass OrderRestoreDeleted(BaseModel):\n    is_deleted: bool\n\n\nclass OrderUpdateDriverDetails(OrderBaseDeliveryBaseInfo):\n    # model_config = ConfigDict(extra=\"forbid\")  # type: ignore\n    pass"}
{"type": "source_file", "path": "customer_service/app/schemas/v1/schema_auth.py", "content": "from pydantic import BaseModel\n\n# Local Dependencies\nfrom app.db.models.v1.db_auth import TokenBlacklistBase\nfrom app.utils.partial import optional\n\n\nclass Token(BaseModel):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Response schema for representing a token.\n\n    Fields:\n    ----------\n    - 'access_token' (str): The access token.\n    - 'token_type' (str): The type of the token.\n    \"\"\"\n\n    access_token: str\n    token_type: str\n\n\nclass TokenData(BaseModel):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Response schema for representing token data.\n\n    Fields:\n    ----------\n    - 'username_or_email' (str): The username or email associated with the token.\n    \"\"\"\n\n    username_or_email: str\n\n\nclass TokenBlacklistCreate(TokenBlacklistBase):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Schema for creating a token blacklist entry.\n\n    Fields:\n    ----------\n    - 'token': Token value for authentication.\n    - 'expires_at': Timestamp indicating the expiration date and time of the token.\n    \"\"\"\n\n    pass\n\n\n# All these fields are optional\n@optional()\nclass TokenBlacklistUpdate(TokenBlacklistBase):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Schema for updating a token blacklist entry.\n\n    Optional Fields:\n    ----------\n    - 'token': Token value for authentication.\n    - 'expires_at': Timestamp indicating the expiration date and time of the token.\n    \"\"\"\n\n    pass\n"}
{"type": "source_file", "path": "customer_service/app/db/crud/base.py", "content": "# Built-in Dependencies\nfrom typing import Any, Dict, Generic, List, Type, TypeVar, Union\nfrom datetime import datetime, timezone\n\n\n# Third-Party Dependencies\nfrom sqlmodel import select, update, delete, func, and_, inspect\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom sqlalchemy.engine.row import Row\nfrom sqlalchemy.sql import Join\nfrom sqlmodel import SQLModel\n\n# Local Dependencies\nfrom app.db.crud.crud_helper import (\n    _extract_matching_columns_from_schema,\n    _extract_matching_columns_from_kwargs,\n    _auto_detect_join_condition,\n    _add_column_with_prefix,\n)\nfrom app.db.models.v1.common import Base\n\nModelType = TypeVar(\"ModelType\", bound=Base)\nCreateSchemaType = TypeVar(\"CreateSchemaType\", bound=SQLModel)\nUpdateSchemaType = TypeVar(\"UpdateSchemaType\", bound=SQLModel)\nUpdateSchemaInternalType = TypeVar(\"UpdateSchemaInternalType\", bound=SQLModel)\nDeleteSchemaType = TypeVar(\"DeleteSchemaType\", bound=SQLModel)\n\n\nclass CRUDBase(\n    Generic[\n        ModelType,\n        CreateSchemaType,\n        UpdateSchemaType,\n        UpdateSchemaInternalType,\n        DeleteSchemaType,\n    ]\n):\n    \"\"\"\n    Base class for CRUD operations on a model.\n\n    Parameters\n    ----------\n    model : Type[ModelType]\n        The SQLAlchemy model type.\n    \"\"\"\n\n    def __init__(self, model: Type[ModelType]) -> None:\n        self._model = model\n\n    async def create(self, db: AsyncSession, object: CreateSchemaType) -> ModelType:\n        \"\"\"\n        Create a new record in the database.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        object : CreateSchemaType\n            The SQLModel (Pydantic) schema containing the data to be saved.\n\n        Returns\n        ----------\n        ModelType\n            The created database object.\n        \"\"\"\n        object_dict = object.model_dump()\n        db_object: ModelType = self._model(**object_dict)\n        db.add(db_object)\n        await db.commit()\n        return db_object\n\n    async def get(\n        self,\n        db: AsyncSession,\n        schema_to_select: Union[Type[SQLModel], List, None] = None,\n        **kwargs: Any,\n    ) -> Dict:\n        \"\"\"\n        Fetch a single record based on filters.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        schema_to_select : Union[Type[SQLModel], List, None], optional\n            SQLModel (Pydantic) schema for selecting specific columns. Default is None to select all columns.\n        kwargs : dict\n            Filters to apply to the query.\n\n        Returns\n        ----------\n        Dict | None\n            The fetched database row or None if not found.\n        \"\"\"\n        to_select = _extract_matching_columns_from_schema(\n            model=self._model, schema=schema_to_select\n        )\n        stmt = select(*to_select).filter_by(**kwargs)\n\n        db_row = await db.exec(stmt)\n        result: Row = db_row.first()\n        if result is not None:\n            out: dict = dict(result._mapping)\n            return out\n\n        return None\n\n    async def exists(self, db: AsyncSession, **kwargs: Any) -> bool:\n        \"\"\"\n        Check if a record exists based on filters.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        kwargs : dict\n            Filters to apply to the query.\n\n        Returns\n        ----------\n        bool\n            True if a record exists, False otherwise.\n        \"\"\"\n        to_select = _extract_matching_columns_from_kwargs(\n            model=self._model, kwargs=kwargs\n        )\n        stmt = select(*to_select).filter_by(**kwargs).limit(1)\n\n        result = await db.exec(stmt)\n        return result.first() is not None\n\n    async def count(self, db: AsyncSession, **kwargs: Any) -> int | None:\n        \"\"\"\n        Count the records based on filters.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        kwargs : dict\n            Filters to apply to the query.\n\n        Returns\n        ----------\n        int\n            Total count of records that match the applied filters.\n\n        Note\n        ----\n        This method provides a quick way to get the count of records without retrieving the actual data.\n        \"\"\"\n        if kwargs:\n            conditions = [\n                getattr(self._model, key) == value for key, value in kwargs.items()\n            ]\n            combined_conditions = and_(*conditions)\n            count_query = (\n                select(func.count())\n                .select_from(self._model)\n                .filter(combined_conditions)\n            )\n        else:\n            count_query = select(func.count()).select_from(self._model)\n        total_count: int | None = await db.scalar(count_query)\n\n        return total_count\n\n    async def get_multi(\n        self,\n        db: AsyncSession,\n        offset: int = 0,\n        limit: int = 100,\n        schema_to_select: Union[Type[SQLModel], List[Type[SQLModel]], None] = None,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Fetch multiple records based on filters.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        offset : int, optional\n            Number of rows to skip before fetching. Default is 0.\n        limit : int, optional\n            Maximum number of rows to fetch. Default is 100.\n        schema_to_select : Union[Type[SQLModel], List[Type[SQLModel]], None], optional\n            SQLModel (Pydantic) schema for selecting specific columns. Default is None to select all columns.\n        kwargs : dict\n            Filters to apply to the query.\n\n        Returns\n        ----------\n        Dict[str, Any]\n            Dictionary containing the fetched rows under 'data' key and total count under 'total_count'.\n        \"\"\"\n        to_select = _extract_matching_columns_from_schema(\n            model=self._model, schema=schema_to_select\n        )\n        stmt = select(*to_select).filter_by(**kwargs).offset(offset).limit(limit)\n\n        result = await db.exec(stmt)\n        data = [dict(row) for row in result.mappings()]\n\n        total_count = await self.count(db=db, **kwargs)\n\n        return {\"data\": data, \"total_count\": total_count}\n\n    async def get_multi_on_filters(\n        self,\n        db: AsyncSession,\n        offset: int = 0,\n        limit: int = 100,\n        schema_to_select: Union[Type[SQLModel], List[Type[SQLModel]], None] = None,\n        filters: List[Any] | None = None,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Fetch multiple records based on filters.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        offset : int, optional\n            Number of rows to skip before fetching. Default is 0.\n        limit : int, optional\n            Maximum number of rows to fetch. Default is 100.\n        schema_to_select : Union[Type[SQLModel], List[Type[SQLModel]], None], optional\n            SQLModel (Pydantic) schema for selecting specific columns. Default is None to select all columns.\n        filters : Optional[List[Any]], optional\n            Additional filters to apply to the query. Default is None.\n        kwargs : dict\n            Filters to apply to the query.\n\n        Returns\n        ----------\n        Dict[str, Any]\n            Dictionary containing the fetched rows under 'data' key and total count under 'total_count'.\n        \"\"\"\n        to_select = _extract_matching_columns_from_schema(\n            model=self._model, schema=schema_to_select\n        )\n        stmt = select(*to_select).filter_by(**kwargs).offset(offset).limit(limit)\n\n        if filters:\n            stmt = stmt.filter(*filters)\n\n        result = await db.exec(stmt)\n        data = [dict(row) for row in result.mappings()]\n\n        total_count = await self.count(db=db, **kwargs)\n\n        return {\"data\": data, \"total_count\": total_count}\n\n    async def get_joined(\n        self,\n        db: AsyncSession,\n        join_model: Type[ModelType],\n        join_prefix: str | None = None,\n        join_on: Union[Join, None] = None,\n        schema_to_select: Union[Type[SQLModel], List, None] = None,\n        join_schema_to_select: Union[Type[SQLModel], List, None] = None,\n        join_type: str = \"left\",\n        **kwargs: Any,\n    ) -> dict | None:\n        \"\"\"\n        Fetches a single record with a join on another model. If 'join_on' is not provided, the method attempts\n        to automatically detect the join condition using foreign key relationships.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        join_model : Type[ModelType]\n            The model to join with.\n        join_prefix : Optional[str]\n            Optional prefix to be added to all columns of the joined model. If None, no prefix is added.\n        join_on : Join, optional\n            SQLAlchemy Join object for specifying the ON clause of the join. If None, the join condition is\n            auto-detected based on foreign keys.\n        schema_to_select : Union[Type[SQLModel], List, None], optional\n            SQLModel (Pydantic) schema for selecting specific columns from the primary model.\n        join_schema_to_select : Union[Type[SQLModel], List, None], optional\n            SQLModel (Pydantic) schema for selecting specific columns from the joined model.\n        join_type : str, default \"left\"\n            Specifies the type of join operation to perform. Can be \"left\" for a left outer join or \"inner\" for an inner join.\n        kwargs : dict\n            Filters to apply to the query.\n\n        Returns\n        ----------\n        Dict | None\n            The fetched database row or None if not found.\n\n        Examples\n        ----------\n        Simple example: Joining User and Tier models without explicitly providing join_on\n        ```python\n        result = await crud_user.get_joined(\n            db=session,\n            join_model=Tier,\n            schema_to_select=UserSchema,\n            join_schema_to_select=TierSchema\n        )\n        ```\n\n        Complex example: Joining with a custom join condition, additional filter parameters, and a prefix\n        ```python\n        from sqlalchemy import and_\n        result = await crud_user.get_joined(\n            db=session,\n            join_model=Tier,\n            join_prefix=\"tier_\",\n            join_on=and_(User.tier_id == Tier.id, User.is_superuser == True),\n            schema_to_select=UserSchema,\n            join_schema_to_select=TierSchema,\n            username=\"john_doe\"\n        )\n        ```\n\n        Return example: prefix added, no schema_to_select or join_schema_to_select\n        ```python\n        {\n            \"name\": \"John Doe\",\n            \"username\": \"john_doe\",\n            \"email\": \"johndoe@example.com\",\n            \"hashed_password\": \"hashed_password_example\",\n            \"profile_image_url\": \"https://profileimageurl.com/default.jpg\",\n            \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n            \"created_at\": \"2023-01-01T12:00:00\",\n            \"updated_at\": \"2023-01-02T12:00:00\",\n            \"deleted_at\": null,\n            \"is_deleted\": false,\n            \"is_superuser\": false,\n            \"tier_id\": \"123b4566-e89b-12d3-a456-426614174111\",\n            \"tier_name\": \"Premium\",\n            \"tier_created_at\": \"2022-12-01T10:00:00\",\n            \"tier_updated_at\": \"2023-01-01T11:00:00\"\n        }\n        ```\n        \"\"\"\n        if join_on is None:\n            join_on = _auto_detect_join_condition(self._model, join_model)  # type: ignore\n\n        # Extract columns to select from primary model based on schema\n        primary_select = _extract_matching_columns_from_schema(\n            model=self._model, schema=schema_to_select\n        )\n        join_select = []\n\n        # Extract columns to select from joined model based on schema or all columns if schema_to_select is not provided\n        if join_schema_to_select:\n            columns = _extract_matching_columns_from_schema(\n                model=join_model, schema=join_schema_to_select\n            )\n        else:\n            columns = inspect(join_model).c  # type: ignore\n\n        for column in columns:\n            labeled_column = _add_column_with_prefix(column, join_prefix)\n            if f\"{join_prefix}{column.name}\" not in [\n                col.name for col in primary_select\n            ]:\n                join_select.append(labeled_column)\n\n        # Build the select statement with the specified join type and join condition\n        if join_type == \"left\":\n            stmt = select(*primary_select, *join_select).outerjoin(join_model, join_on)\n        elif join_type == \"inner\":\n            stmt = select(*primary_select, *join_select).join(join_model, join_on)\n        else:\n            raise ValueError(\n                f\"Invalid join type: {join_type}. Only 'left' or 'inner' are valid.\"\n            )\n\n        # Apply additional filters based on kwargs\n        for key, value in kwargs.items():\n            if hasattr(self._model, key):\n                stmt = stmt.where(getattr(self._model, key) == value)\n\n        # Execute the statement and retrieve the result\n        db_row = await db.exec(stmt)\n        result: Row = db_row.first()\n        if result:\n            out: dict = dict(result._mapping)\n            return out\n\n        return None\n\n    async def get_multi_joined(\n        self,\n        db: AsyncSession,\n        join_model: Type[ModelType],\n        join_prefix: str | None = None,\n        join_on: Union[Join, None] = None,\n        schema_to_select: Union[Type[SQLModel], List[Type[SQLModel]], None] = None,\n        join_schema_to_select: Union[Type[SQLModel], List[Type[SQLModel]], None] = None,\n        join_type: str = \"left\",\n        offset: int = 0,\n        limit: int = 100,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Fetch multiple records with a join on another model, allowing for pagination.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        join_model : Type[ModelType]\n            The model to join with.\n        join_prefix : Optional[str]\n            Optional prefix to be added to all columns of the joined model. If None, no prefix is added.\n        join_on : Join, optional\n            SQLAlchemy Join object for specifying the ON clause of the join. If None, the join condition is\n            auto-detected based on foreign keys.\n        schema_to_select : Union[Type[SQLModel], List[Type[SQLModel]], None], optional\n            SQLModel (Pydantic) schema for selecting specific columns from the primary model.\n        join_schema_to_select : Union[Type[SQLModel], List[Type[SQLModel]], None], optional\n            SQLModel (Pydantic) schema for selecting specific columns from the joined model.\n        join_type : str, default \"left\"\n            Specifies the type of join operation to perform. Can be \"left\" for a left outer join or \"inner\" for an inner join.\n        offset : int, default 0\n            The offset (number of records to skip) for pagination.\n        limit : int, default 100\n            The limit (maximum number of records to return) for pagination.\n        kwargs : dict\n            Filters to apply to the primary query.\n\n        Returns\n        ----------\n        Dict[str, Any]\n            A dictionary containing the fetched rows under 'data' key and total count under 'total_count'.\n\n        Examples\n        ----------\n        # Fetching multiple User records joined with Tier records, using left join\n        users = await crud_user.get_multi_joined(\n            db=session,\n            join_model=Tier,\n            join_prefix=\"tier_\",\n            schema_to_select=UserSchema,\n            join_schema_to_select=TierSchema,\n            offset=0,\n            limit=10\n        )\n        \"\"\"\n        if join_on is None:\n            join_on = _auto_detect_join_condition(self._model, join_model)  # type: ignore\n\n        primary_select = _extract_matching_columns_from_schema(\n            model=self._model, schema=schema_to_select\n        )\n        join_select = []\n\n        if join_schema_to_select:\n            columns = _extract_matching_columns_from_schema(\n                model=join_model, schema=join_schema_to_select\n            )\n        else:\n            columns = inspect(join_model).c  # type: ignore\n\n        for column in columns:\n            labeled_column = _add_column_with_prefix(column, join_prefix)\n            if f\"{join_prefix}{column.name}\" not in [\n                col.name for col in primary_select\n            ]:\n                join_select.append(labeled_column)\n\n        if join_type == \"left\":\n            stmt = select(*primary_select, *join_select).outerjoin(join_model, join_on)\n        elif join_type == \"inner\":\n            stmt = select(*primary_select, *join_select).join(join_model, join_on)\n        else:\n            raise ValueError(\n                f\"Invalid join type: {join_type}. Only 'left' or 'inner' are valid.\"\n            )\n\n        for key, value in kwargs.items():\n            if hasattr(self._model, key):\n                stmt = stmt.where(getattr(self._model, key) == value)\n\n        stmt = stmt.offset(offset).limit(limit)\n\n        db_rows = await db.exec(stmt)\n        data = [dict(row._mapping) for row in db_rows]\n\n        total_count = await self.count(db=db, **kwargs)\n\n        return {\"data\": data, \"total_count\": total_count}\n\n    async def update(\n        self,\n        db: AsyncSession,\n        object: Union[UpdateSchemaType, Dict[str, Any]],\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"\n        Update an existing record in the database.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        object : Union[UpdateSchemaType, Dict[str, Any]]\n            The SQLModel (Pydantic) schema or dictionary containing the data to be updated.\n        kwargs : dict\n            Filters for the update.\n\n        Returns\n        ----------\n        None\n        \"\"\"\n        if isinstance(object, dict):\n            update_data = object\n        else:\n            update_data = object.model_dump(exclude_unset=True)\n\n        if \"updated_at\" in update_data.keys():\n            update_data[\"updated_at\"] = datetime.now(timezone.utc)\n\n        stmt = update(self._model).filter_by(**kwargs).values(update_data)\n\n        await db.exec(stmt)  # type: ignore\n        await db.commit()\n\n    async def db_delete(self, db: AsyncSession, **kwargs: Any) -> None:\n        \"\"\"\n        Delete a record in the database.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        kwargs : dict\n            Filters for the delete.\n\n        Returns\n        ----------\n        None\n        \"\"\"\n        stmt = delete(self._model).filter_by(**kwargs)\n        await db.exec(stmt)  # type: ignore\n        await db.commit()\n\n    async def delete(\n        self,\n        db: AsyncSession,\n        db_row: Row | None | dict[Any, Any] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"\n        Soft delete a record if it has \"is_deleted\" attribute, otherwise perform a hard delete.\n\n        Parameters\n        ----------\n        db : AsyncSession\n            The SQLModel async session.\n        db_row : Row | None, optional\n            Existing database row to delete. If None, it will be fetched based on `kwargs`. Default is None.\n        kwargs : dict\n            Filters for fetching the database row if not provided.\n\n        Returns\n        ----------\n        None\n        \"\"\"\n        db_row = db_row or await self.exists(db=db, **kwargs)  # type: ignore\n        if db_row:\n            if \"is_deleted\" in self._model.__table__.columns:  # type: ignore\n                object_dict = {\n                    \"is_deleted\": True,\n                    \"deleted_at\": datetime.now(timezone.utc),\n                }\n                stmt = update(self._model).filter_by(**kwargs).values(object_dict)\n\n                await db.exec(stmt)  # type: ignore\n                await db.commit()\n\n            else:\n                stmt = delete(self._model).filter_by(**kwargs)  # type: ignore\n                await db.exec(stmt)  # type: ignore\n                await db.commit()\n"}
{"type": "source_file", "path": "customer_service/app/db/init_db.py", "content": "# Built-in Dependencies\n\n# Third-Party Dependencies\nfrom sqlmodel import select\n\n# Local Dependencies\nfrom app.db.session import AsyncSession, local_session\nfrom app.db.session import async_engine as engine\nfrom app.db.models.v1.common import Base\n\nfrom app.core.config import settings\nfrom app.core.hashing import Hasher\nfrom app.db.models.v1.db_user import User, AccessLevel_Enum\n\n\nasync def create_first_super_user(session: AsyncSession) -> None:\n    name = settings.FIRST_SUPERUSER_NAME\n    email = settings.FIRST_SUPERUSER_EMAIL\n    username = settings.FIRST_SUPERUSER_USERNAME\n    phone = settings.FIRST_SUPERUSER_PHONE\n    # userRole = settings.FIRST_SUPERUSER_ROLE\n    hashed_pass = Hasher.get_hash_password(settings.FIRST_SUPERUSER_PASSWORD)\n\n    # check if already existing\n    query = select(User).filter_by(email=email)\n    result = await session.exec(query)\n    user = result.one_or_none()\n\n    if user is None:\n        session.add(\n            User(\n                name=name,\n                email=email,\n                username=username,\n                phone=phone,\n                hashed_password=hashed_pass,\n                is_superuser=True,\n                profile_image_url=\"https://www.imageurl.com/first_user.jpg\",\n                user_role=AccessLevel_Enum.ADMIN,\n            )\n        )\n        await session.commit()\n    pass\n\n\nasync def init_tables() -> None:\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n\nasync def init_db() -> None:\n    await init_tables()\n    async with local_session() as session:\n        await create_first_super_user(session=session)\n"}
{"type": "source_file", "path": "customer_service/app/schemas/v1/schema_user.py", "content": "# Built-in Dependencies\nfrom typing import Annotated, List\nfrom datetime import datetime\n\n# Third-Party Dependencies\nfrom pydantic import BaseModel, Field, ConfigDict\n\n# Local Dependencies\nfrom app.db.models.v1.common import UUIDMixin, TimestampMixin, SoftDeleteMixin\nfrom app.utils.partial import optional\nfrom app.db.models.v1.db_user import (\n    UserPersonalInfoBase,\n    UserMediaBase,\n    UserPermissionBase,\n    UserRoleBase,\n    UserSecurityBase,\n)\nfrom app.schemas.v1.schema_address import UserAddressRead\n\n\nclass UserBase(UserPersonalInfoBase):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Base schema for representing a user personal info.\n\n    Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n    \"\"\"\n\n    pass\n\n\nclass User(\n    UserBase,\n    UserMediaBase,\n    UserPermissionBase,\n    UserSecurityBase,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Schema representing a user, including media, tier, permission, and security information.\n\n    Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n    - 'profile_image_url': URL of the user's profile image.\n    - 'is_superuser': Indicates whether the user has superuser privileges.\n    - 'hashed_password': Hashed password for user authentication.\n    - 'id': Unique identifier (UUID) for the user.\n    - 'created_at': Timestamp for the creation of the user record.\n    - 'updated_at': Timestamp for the last update of the user record.\n    - 'deleted_at': Timestamp for the deletion of the user record (soft deletion).\n    - 'is_deleted': Flag indicating whether the user record is deleted (soft deletion).\n    \"\"\"\n\n    pass\n\n\nclass UserRead(\n    UserBase,\n    UserMediaBase,\n    UserRoleBase,\n    UUIDMixin,\n):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Read-only schema for retrieving information about a user, including media and tier details.\n\n    Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n    - 'profile_image_url': URL of the user's profile image.\n    - 'id': Unique identifier (UUID) for the user.\n    - 'user_role' : role of user.\n    \"\"\"\n\n    pass\n\n\nclass UserReadFull(UserRead):\n    addresses: List[UserAddressRead]\n\n\nclass UserCreate(\n    UserBase,\n    UserMediaBase,\n    UserRoleBase,\n):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Schema for creating a new user.\n\n    Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n    - 'password': User's password.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")  # type: ignore\n\n    password: Annotated[\n        str,\n        Field(\n            default=\"Pass@123\",\n            pattern=r\"^.{8,}|[0-9]+|[A-Z]+|[a-z]+|[^a-zA-Z0-9]+$\",\n            examples=[\"Str1ngst!\"],\n        ),\n    ]\n\n\nclass UserCreateInternal(UserBase, UserMediaBase, UserRoleBase, UserSecurityBase):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Internal schema for creating a new user, including security information.\n\n    Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n    - 'hashed_password': Hashed password for user authentication.\n    \"\"\"\n\n    pass\n\n\n@optional()\nclass UserUpdate(\n    UserBase,\n    UserMediaBase,\n    UserRoleBase,\n):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Schema for updating an existing user, including media information.\n\n    Optional Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n    - 'profile_image_url': URL of the user's profile image.\n    - 'user_role' : User role\n    \"\"\"\n\n    class Config:\n        extra = \"forbid\"\n\n\nclass UserUpdateInternal(UserUpdate):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Internal schema for updating an existing user, including media information and the last update timestamp.\n\n    Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n    - 'profile_image_url': URL of the user's profile image.\n    - 'updated_at': Timestamp for the last update of the user record.\n    \"\"\"\n\n    updated_at: datetime\n\n\nclass UserDelete(SoftDeleteMixin):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Schema for logically deleting a user.\n\n    Fields:\n    ----------\n    - 'is_deleted': Flag indicating whether the user record is deleted (soft deletion).\n    \"\"\"\n\n    class Config:\n        extra = \"forbid\"\n\n\nclass UserRestoreDeleted(BaseModel):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Schema for restoring a deleted user.\n\n    Fields:\n    ----------\n    - 'is_deleted': Flag indicating whether the user record is deleted (soft deletion).\n    \"\"\"\n\n    is_deleted: bool\n"}
{"type": "source_file", "path": "customer_service/app/db/models/v1/db_order.py", "content": "# Built-in Dependencies\nfrom uuid import UUID\n\n# Third-Party Dependencies\nfrom sqlmodel import Field, Relationship, Integer, Column\nfrom enum import Enum\n\n# Local Dependencies\nfrom app.db.models.v1.common import (\n    SoftDeleteMixin,\n    TimestampMixin,\n    UUIDMixin,\n    Base,\n    Rating_enum,\n)\nfrom app.core.config import settings\n# from app.db.models.v1.db_address import UserAddress\n\n\nclass OrderAddOnRelation(Base):\n    order_item_id: UUID = Field(\n        nullable=False,\n        index=True,\n        foreign_key=f\"{settings.DATABASE_ORDER_ITEM_TABLE}.id\",\n    )\n    order_item = Relationship(\n        back_populates=\"add_ons\",\n    )\n\n\nclass OrderAddOnBaseInfo(Base):\n    name: str = Field(nullable=False, default=\"\")\n    price: float = Field(nullable=False, default=0.0)\n\n\nclass OrderAddOn(\n    OrderAddOnBaseInfo,\n    OrderAddOnRelation,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n    table=True,\n):\n    __tablename__ = f\"{settings.DATABASE_ORDER_ITEM_ADDON_TABLE}\"\n\n\nclass OrderItemRelations(Base):\n    order_id: UUID = Field(\n        nullable=False, index=True, foreign_key=f\"{settings.DATABASE_ORDER_TABLE}.id\"\n    )\n    order = Relationship(back_populates=\"items\")\n\n\nclass OrderItemBaseInfo(Base):\n    product_id: UUID = Field(nullable=False, index=False)\n    name: str = Field(nullable=False, default=\"\")\n    quantity: int = Field(nullable=False, default=1)\n    price_per_unit: float = Field(nullable=False, default=0.0)\n\n    # add_ons: List[OrderAddOn] = Relationship(back_populates=\"order_item\",  )\n\n\nclass OrderItem(\n    OrderItemBaseInfo,\n    OrderItemRelations,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n    table=True,\n):\n    # order: \"Order\" = Relationship(back_populates=\"items\", sa_relationship=True)\n    __tablename__ = f\"{settings.DATABASE_ORDER_ITEM_TABLE}\"\n\n\nclass Order_Status_Enum(str, Enum):\n    PLACED = \"placed\"\n    ORDERED = \"ordered\"\n    ACCEPTED = \"accepted\"\n    READY_FOR_PICKUP = \"ready_for_pickup\"\n    ON_THE_WAY = \"on_the_way\"\n    REACHED = \"reached\"\n    DELIVERED = \"delivered\"\n    CANCELLED = \"cancelled\"\n    RETURNED = \"returned\"\n    FAILED = \"failed\"\n\n\nclass OrderBaseInfo(Base):\n    customer_id: UUID = Field(\n        nullable=False, index=True, foreign_key=f\"{settings.DATABASE_USER_TABLE}.id\"\n    )\n    address_id: UUID = Field(\n        nullable=False,\n        index=False,\n        foreign_key=f\"{settings.DATABASE_USER_ADDRESS_TABLE}.id\",\n    )\n    restaurant_id: str = Field(nullable=False, index=True)\n    total_cost: float = Field(nullable=False, default=0)\n    # items: List[OrderItem] = Relationship(back_populates=\"order\" , )\n    # delivery_address: \"UserAddress\" = Relationship(back_populates=\"orders\", sa_relationship=True)\n\n\nclass OrderBaseDeliveryBaseInfo(Base):\n    delivery_person_id: UUID | None = Field(nullable=True, index=False, default=None)\n    delivery_person_name: str | None = Field(nullable=True, index=False, default=None)\n\n\nclass OrderStatusInfo(Base):\n    status: Order_Status_Enum = Field(\n        nullable=False, index=False, default=Order_Status_Enum.ORDERED\n    )\n\n\nclass OrderPaymentDetails(Base):\n    payment_id: UUID | None = Field(nullable=True, index=False)\n\n\nclass Order(\n    OrderBaseInfo,\n    OrderBaseDeliveryBaseInfo,\n    OrderStatusInfo,\n    OrderPaymentDetails,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n    table=True,\n):\n    __tablename__ = f\"{settings.DATABASE_ORDER_TABLE}\"\n\n\nclass OrderRatingInfoBase(Base):\n    food_rating: Rating_enum | None = Field(\n        sa_column=Column(Integer, nullable=True, index=False, default=None)\n    )\n    delivery_rating: Rating_enum | None = Field(\n        sa_column=Column(Integer, nullable=True, index=False, default=None)\n    )\n    delivery_person_id: str | None = Field(nullable=True, index=False, default=None)\n    order_id: UUID = Field(\n        nullable=False, foreign_key=f\"{settings.DATABASE_ORDER_TABLE}.id\"\n    )\n    user_id: UUID = Field(\n        nullable=False, foreign_key=f\"{settings.DATABASE_USER_TABLE}.id\"\n    )\n    restaurant_id: str = Field(nullable=False)\n\n\nclass OrderRating(\n    OrderRatingInfoBase,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n    table=True,\n):\n    __tablename__ = f\"{settings.DATABASE_ORDER_RATING_TABLE}\"\n"}
{"type": "source_file", "path": "customer_service/app/db/models/v1/common.py", "content": "# Built-in Dependencies\nfrom datetime import datetime, timezone\nfrom uuid import UUID, uuid4\nfrom typing import Optional, Any\nfrom enum import Enum, IntEnum\n\n\n# Third-Party Dependencies\nfrom sqlmodel import SQLModel, Field, DateTime\nfrom pydantic import field_serializer\n\n\n# Define a base class for declarative models with support for dataclasses\nclass Base(SQLModel):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    Main base class for generating Pydantic models and database tables with SQLModel.\n    \"\"\"\n\n    pass\n\n\nclass UUIDMixin(SQLModel):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    'UUIDMixin' pydantic class with a UUID column as the primary key.\n\n    Fields:\n    ----------\n    - 'id': Unique identifier (UUID) for the record.\n\n    Examples:\n    ----------\n    Example of a valid data:\n    - 'id': UUID(\"123e4567-e89b-12d3-a456-426614174001\")\n    \"\"\"\n\n    # Data Columns\n    id: UUID = Field(\n        default_factory=uuid4,\n        primary_key=True,\n        index=True,\n        description=\"Unique identifier (UUID) for the record\",\n    )\n\n\nclass TimestampMixin(SQLModel):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    'TimestampMixin' pydantic class.\n\n    Fields:\n    - 'created_at': Timestamp for the creation of the record.\n    - 'updated_at': Timestamp for the last update of the record.\n\n    Examples:\n    ---------\n    Examples of valid data for each field:\n    - 'created_at': \"2024-01-20T12:00:00\"\n    - 'updated_at': \"2024-01-20T12:30:00\"\n\n    Extra Info:\n    ----------\n    Adds 'created_at' and 'updated_at' fields with default values for the creation timestamp and update timestamp.\n\n    Note: By default, 'updated_at' is set to the current timestamp on every update, which is useful for tracking the last\n    modification time. However, in scenarios where soft deletion is performed and records may be restored, you might want\n    to consider the following options:\n\n    ----------------------------------------------------------\n\n    Option 1 (Recommended for most scenarios):\n    - Pros:\n        - Keeps 'updated_at' always up-to-date, providing an accurate timestamp for the last modification.\n        - Suitable for most use cases where soft deletion is not a common scenario.\n\n    - Cons:\n        - May lead to inaccurate information if soft deletion and restoration are part of the system's workflow.\n\n    updated_at: datetime = Field(\n        sa_type=DateTime(timezone=True),\n        default_factory=lambda: datetime.now(UTC),\n        sa_column_kwargs={\"onupdate\": datetime.now(UTC)},\n        description=\"Timestamp for the last update of the record\",\n    )\n\n    ----------------------------------------------------------\n\n    Option 2 (Recommended for scenarios with frequent soft deletions and restorations):\n    - Pros:\n        - Preserves the original timestamp of the last real modification even after a soft delete and restore.\n        - Avoids potential inaccuracies caused by automatic updates to 'updated_at' during soft deletions.\n\n    - Cons:\n        - 'updated_at' will not be automatically updated on every change, potentially affecting accuracy if the field\n        needs to reflect every modification.\n        - Currently, the BaseCRUD's update method in the API automatically handles the update of 'updated_at'. If other\n        update methods are used that do not go through this mechanism, 'updated_at' may not be updated as expected.\n\n    updated_at: Optional[datetime] = Field(\n        sa_type=DateTime(timezone=True),\n        default_factory=lambda: datetime.now(UTC),\n        description=\"Timestamp for the last update of the record\",\n    )\n    \"\"\"\n\n    # Data Columns\n    created_at: datetime = Field(\n        sa_type=DateTime(timezone=True),\n        default_factory=lambda: datetime.now(timezone.utc),\n        description=\"Timestamp for the creation of the record\",\n    )  # type: ignore\n    updated_at: datetime = Field(\n        sa_type=DateTime(timezone=True),\n        default_factory=lambda: datetime.now(timezone.utc),\n        sa_column_kwargs={\"onupdate\": datetime.now(timezone.utc)},\n        description=\"Timestamp for the last update of the record\",\n    )  # type: ignore\n\n    @field_serializer(\"created_at\")\n    def serialize_dt(self, created_at: datetime, _info: Any) -> str:\n        if created_at is not None:\n            return created_at.isoformat()\n\n        return None\n\n    @field_serializer(\"updated_at\")\n    def serialize_updated_at(self, updated_at: datetime, _info: Any) -> str:\n        if updated_at is not None:\n            return updated_at.isoformat()\n\n        return None\n\n\nclass SoftDeleteMixin(SQLModel):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    'SoftDeleteMixin' pydantic class.\n\n    Fields:\n    - 'deleted_at': Timestamp for the deletion of the record (soft deletion).\n    - 'is_deleted': Flag indicating whether the record is deleted (soft deletion).\n\n    Examples:\n    ---------\n    Examples of valid data for each field:\n    - 'deleted_at': \"2024-01-20T13:00:00\"\n    - 'is_deleted': True\n\n    Extra Info:\n    ----------\n    Adds 'deleted_at' and 'is_deleted' fields for soft deletion functionality.\n    \"\"\"\n\n    # Data Columns\n    deleted_at: Optional[datetime] = Field(\n        sa_type=DateTime(timezone=True),\n        default=None,\n        description=\"Timestamp for the deletion of the record (soft deletion)\",\n    )  # type: ignore\n    is_deleted: bool = Field(\n        default=False,\n        index=True,\n        description=\"Flag indicating whether the record is deleted (soft deletion)\",\n    )\n\n    @field_serializer(\"deleted_at\")\n    def serialize_dates(self, deleted_at: datetime, _info: Any) -> str:\n        if deleted_at is not None:\n            return deleted_at.isoformat()\n\n        return None\n\n\nclass Transaction_Status_Enum(str, Enum):\n    PASS = \"pass\"\n    FAIL = \"fail\"\n    IN_PROGRESS = \"in-Progress\"\n    HOLD = \"hold\"\n    IN_REVIEW = \"in-review\"\n    REQUEST = \"request\"\n\n\nclass TransactionStatus(Base):\n    status: Transaction_Status_Enum = Field(\n        nullable=False,\n        description=\"Status Enum for transactions\",\n        schema_extra={\"examples\": [f\"{Transaction_Status_Enum.REQUEST.value}\"]},\n    )\n\n    msg: str | None = Field(\n        nullable=True,\n        description=\"Any information related to transactions\",\n        default_factory=None,\n    )\n\n\nclass Rating_enum(IntEnum):\n    ONE = 1\n    TWO = 2\n    THREE = 3\n    FOUR = 4\n    FIVE = 5\n"}
{"type": "source_file", "path": "customer_service/app/schemas/v1/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/db/session.py", "content": "from typing import AsyncGenerator\n\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncEngine\nfrom sqlalchemy.orm import sessionmaker\n\nfrom app.core.config import settings\n\nasync_engine: AsyncEngine = create_async_engine(\n    settings.POSTGRES_ASYNC_URI, echo=False, future=True\n)\n\n\nlocal_session = sessionmaker(\n    bind=async_engine, class_=AsyncSession, expire_on_commit=False\n)  # type: ignore\n\n\nasync def async_get_db() -> AsyncGenerator[AsyncSession, None]:\n    async_session = local_session\n\n    async with async_session() as db:\n        yield db\n        await db.commit()\n"}
{"type": "source_file", "path": "customer_service/app/db/crud/crud_user_address.py", "content": "from uuid import UUID\n\n# Third-Party Dependencies\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n# Local Dependencies\nfrom app.db.crud.base import CRUDBase\nfrom app.schemas.v1.schema_user import UserRead\nfrom app.db.models.v1.db_address import UserAddress\nfrom app.schemas.v1.schema_address import (\n    UserAddressCreateInternal,\n    UserAddressUpdate,\n    UserAddressUpdateInternal,\n    UserAddressDelete,\n    UserAddressCreate,\n    UserAddressRead,\n)\nfrom app.core.http_exceptions import NotFoundException, ForbiddenException\n\nfrom app.utils.paginated import (\n    paginated_response,\n    compute_offset,\n)\n\n\n# CRUD operations for the 'UserAddress' model\nCRUDUserAddress = CRUDBase[\n    UserAddress,\n    UserAddressCreateInternal,\n    UserAddressUpdate,\n    UserAddressUpdateInternal,\n    UserAddressDelete,\n]\n\n# Create an instance of CRUDUser for the 'UserAddress' model\ncrud_userAddress = CRUDUserAddress(UserAddress)\n\n\nasync def add_new_address(\n    user: UserRead, address: UserAddressCreate, db: AsyncSession\n) -> UserAddress:\n    address.customer_id = user.id\n\n    data_internal = UserAddressCreateInternal(**address.model_dump())\n    return await crud_userAddress.create(db=db, object=data_internal)\n\n\nasync def get_address_details(user: UserRead, id: UUID, db: AsyncSession) -> dict:\n    address = await crud_userAddress.get(\n        db=db, schema_to_select=UserAddress, id=id, customer_id=user.id\n    )\n    if not address:\n        raise NotFoundException(\"Address ID not found\")\n    if address[\"customer_id\"] != user.id:\n        raise ForbiddenException(\"User does not have permission to delete this address\")\n    return address\n\n\nasync def get_address_list_details(\n    user: UserRead,\n    db: AsyncSession,\n    page: int = 1,\n    items_per_page: int = 10,\n) -> dict:\n    address_data = await crud_userAddress.get_multi(\n        db=db,\n        offset=compute_offset(page, items_per_page),\n        limit=items_per_page,\n        schema_to_select=UserAddressRead,\n        is_deleted=False,\n        customer_id=user.id,\n    )\n    return paginated_response(\n        crud_data=address_data, page=page, items_per_page=items_per_page\n    )\n\n\nasync def remove_address(user: UserRead, id: UUID, db: AsyncSession) -> bool:\n    try:\n        address = await get_address_details(user, id, db)\n        await crud_userAddress.delete(db=db, db_row=address, id=id)\n        return True\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return False\n\n\nasync def update_address(user: UserRead, address: UserAddressUpdate, db: AsyncSession):\n    pass\n"}
{"type": "source_file", "path": "customer_service/app/db/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/initial_data.py", "content": "import logging\nimport asyncio\n\n\nfrom app.db.init_db import init_db\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nasync def init() -> None:\n    try:\n        await init_db()\n    except Exception as e:\n        logger.error(e)\n        raise e\n\n\ndef main() -> None:\n    logger.info(\"Creating initial data\")\n    asyncio.run(init())\n    logger.info(\"Initial data created\")\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "customer_service/app/db/models/v1/db_user.py", "content": "# Built-in Dependencies\nfrom typing import List\n\n# Third-Party Dependencies\nfrom sqlmodel import Field, Relationship\nfrom enum import Enum\n\n# Local Dependencies\nfrom app.db.models.v1.common import (\n    SoftDeleteMixin,\n    TimestampMixin,\n    UUIDMixin,\n    Base,\n)\nfrom app.core.config import settings\nfrom app.db.models.v1.db_address import UserAddress\n\n\nclass UserPersonalInfoBase(Base):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    'UserPersonalInfoBase' pydantic class with personal information for a user.\n\n    Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n\n    Examples:\n    ----------\n    Examples of valid data for each field:\n    - 'name': \"Harsh Mittal\"\n    - 'username': \"hm\"\n    - 'email': \"harshmittal2210@gmail.com\"\n    - 'phone': \"+919876543210\"\n    \"\"\"\n\n    # Data Columns\n    name: str = Field(\n        min_length=2,\n        max_length=100,\n        nullable=False,\n        description=\"User's full name\",\n        schema_extra={\"examples\": [\"Test User\"]},\n    )\n    username: str = Field(\n        min_length=2,\n        max_length=20,\n        unique=True,\n        index=True,\n        nullable=False,\n        regex=r\"^[a-z0-9]+$\",\n        description=\"User's username\",\n        schema_extra={\"examples\": [\"test\"]},\n    )\n    email: str = Field(\n        max_length=50,\n        unique=True,\n        index=True,\n        nullable=False,\n        regex=r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\",\n        description=\"User's email address\",\n        schema_extra={\"examples\": [\"test@example.com\"]},\n    )  # Todo: Use EmailStr when it's supported by SQLModel (https://github.com/tiangolo/sqlmodel/pull/762)\n\n    phone: str = Field(\n        unique=True,\n        index=True,\n        nullable=False,\n        regex=r\"^\\+?[1-9]\\d{1,14}$\",\n        description=\"Phone number in international format, e.g., +919876543210\",\n        schema_extra={\"examples\": [\"+919876543210\"]},\n    )\n\n\nclass UserMediaBase(Base):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    'UserMediaBase' pydantic class with media-related information for a user.\n\n    Fields:\n    ----------\n    - 'profile_image_url': URL of the user's profile image.\n\n    Examples:\n    ----------\n    Example of a valid data:\n    - 'profile_image_url': \"https://www.imageurl.com/profile_image.jpg\"\n    \"\"\"\n\n    # Data Columns\n    profile_image_url: str = Field(\n        default=f\"{settings.DEFAULT_USER_IMAGE}\",\n        description=\"URL of the user's profile image\",\n        schema_extra={\"examples\": [settings.DEFAULT_USER_IMAGE]},\n    )\n\n\nclass UserPermissionBase(Base):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    'UserPermissionBase' pydantic class with permission-related information for a user.\n\n    Fields:\n    ----------\n    - 'is_superuser': Indicates whether the user has superuser privileges.\n\n    Examples:\n    ----------\n    Example of a valid data:\n    - 'is_superuser': False\n    \"\"\"\n\n    # Data Columns\n    is_superuser: bool = Field(\n        default=False, description=\"Indicates whether the user has superuser privileges\"\n    )\n\n\nclass UserSecurityBase(Base):\n    \"\"\"\n    SQLModel Base\n\n    Description:\n    ----------\n    'UserSecurityBase' pydantic class with security-related information for a user.\n\n    Fields:\n    ----------\n    - 'hashed_password': Hashed password for user authentication.\n\n    Examples:\n    ----------\n    Example of a valid data:\n    - 'hashed_password': \"hashed_password_value\"\n    \"\"\"\n\n    # Data Columns\n    hashed_password: str = Field(\n        nullable=False, description=\"Hashed password for user authentication\"\n    )\n\n\nclass AccessLevel_Enum(str, Enum):\n    \"\"\"\n    User Role Enum\n    \"\"\"\n\n    ADMIN = \"admin\"\n    USER = \"user\"\n    GUEST = \"guest\"\n    MODERATOR = \"moderator\"\n\n\nclass UserRoleBase(Base):\n    \"\"\"\n    Pydantic Base Model for User Role\n\n    Attributes:\n    ----------\n    - user_role (AccessLevel_Enum): Role of the user.\n        Examples:\n        - admin: ADMIN\n    \"\"\"\n\n    user_role: AccessLevel_Enum = Field(\n        default=AccessLevel_Enum.GUEST.value,\n        description=\"Role of the user.\",\n        schema_extra={\"Examples\": AccessLevel_Enum.GUEST.value},\n    )\n\n\nclass UserDeliveryAddress(Base):\n    delivery_addresses: List[\"UserAddress\"] = Relationship(back_populates=\"customer\")\n\n\n# class UserPaymentMethods(Base):\n#     payment_details: List[\"PaymentDetail\"] = Relationship(back_populates=\"customer\")\n\n# class UserOrderList(Base):\n#     orders: List[\"Order\"] = Relationship(back_populates=\"customer\")\n\n\nclass User(\n    UserPersonalInfoBase,\n    UserMediaBase,\n    UserPermissionBase,\n    UserSecurityBase,\n    UserRoleBase,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n    table=True,\n):\n    \"\"\"\n    SQLModel Table: User\n\n    Description:\n    ----------\n    'User' ORM class representing the 'system_user' database table.\n\n    Fields:\n    ----------\n    - 'name': User's full name.\n    - 'username': User's unique username.\n    - 'email': User's unique email address.\n    - 'phone': User's unique phone number.\n    - 'profile_image_url': URL of the user's profile image.\n    - 'is_superuser': Indicates whether the user has superuser privileges.\n    - 'hashed_password': Hashed password for user authentication.\n    - 'id': Unique identifier (UUID) for the user.\n    - 'created_at': Timestamp for the creation of the user record.\n    - 'updated_at': Timestamp for the last update of the user record.\n    - 'deleted_at': Timestamp for the deletion of the user record (soft deletion).\n    - 'is_deleted': Flag indicating whether the user record is deleted (soft deletion).\n    - 'user_role' : role of user.\n    - 'sessions': list of all session of user\n    Relationships:\n    ----------\n\n    Table Name:\n    ----------\n    'system_user'\n    \"\"\"\n\n    __tablename__ = f\"{settings.DATABASE_USER_TABLE}\"\n"}
{"type": "source_file", "path": "customer_service/app/db/models/v1/__init__.py", "content": ""}
{"type": "source_file", "path": "customer_service/app/main.py", "content": "# Built-in Dependencies\nimport sys\nimport os\n\n# Third-Party Dependencies\nimport fastapi\nimport uvicorn\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.staticfiles import StaticFiles\n\n# Add the project directory to the sys.path\nsys.path.append(os.path.abspath(os.path.dirname(__file__)))\n\n\n# Local Dependencies\nfrom app.core.config import settings\nfrom app.db import init_db\nfrom app.core.dependencies import create_folders\n\nfrom app.apis.base import api_router\n\n\ndescription = \"\"\"\nCustomer Microservice\n## API Supported\n- User APIs\n- Order APIs\n- User Address APIs\n\"\"\"\n\ntags_metadata = [\n    {\"name\": \"Login\", \"description\": \"This is user login route\"},\n    {\"name\": \"User\", \"description\": \"This is user route\"},\n]\n\n\ndef include_router(app: fastapi.FastAPI):\n    app.include_router(api_router, prefix=settings.API_V1_STR)\n\n\nasync def startup_event():\n    print(\"Executing startup event\")\n    await init_db.init_db()\n\n\ndef start_application():\n    app = fastapi.FastAPI(\n        title=settings.PROJECT_NAME,\n        version=settings.PROJECT_VERSION,\n        description=description,\n        contact={\"name\": settings.CONTACT_NAME, \"email\": settings.CONTACT_EMAIL},\n    )\n\n    if settings.all_cors_origins:\n        app.add_middleware(\n            CORSMiddleware,\n            allow_origins=[\n                str(origin).strip(\"/\") for origin in settings.all_cors_origins\n            ],\n            allow_credentials=True,\n            allow_methods=[\"*\"],\n            allow_headers=[\"*\"],\n        )\n\n    create_folders(\n        f\"./{settings.STATIC_FILE_FOLDER}\", [f\"{settings.PROFILE_IMAGE_FOLDER}\"]\n    )\n    app.mount(\n        f\"/{settings.STATIC_FILE_FOLDER}\",\n        StaticFiles(directory=f\"{settings.STATIC_FILE_FOLDER}\"),\n        name=f\"{settings.STATIC_FILE_FOLDER}\",\n    )\n\n    include_router(app)\n    app.add_event_handler(\"startup\", startup_event)\n    return app\n\n\nif __name__ == \"__main__\":\n    try:\n        print(\n            f\"[INFO] Starting Application at: host={settings.SERVER_IP}, port={settings.SERVER_PORT}\"\n        )\n        uvicorn.run(\n            \"main:start_application\",\n            host=settings.SERVER_IP,\n            port=settings.SERVER_PORT,\n            reload=True,\n        )\n    except Exception as e:\n        print(f\"[ERROR] Main Error: {e}\")\n"}
{"type": "source_file", "path": "customer_service/app/schemas/v1/schema_address.py", "content": "# Built-in Dependencies\nfrom datetime import datetime\n\n# Third-Party Dependencies\nfrom pydantic import BaseModel, ConfigDict\n\n# Local Dependencies\nfrom app.db.models.v1.common import UUIDMixin, TimestampMixin, SoftDeleteMixin\nfrom app.utils.partial import optional\nfrom app.db.models.v1.db_address import (\n    UserAddressInfoBase,\n    UserAddressLocation,\n    UserAddressUserDetails,\n)\n\n\nclass UserAddressBase(UserAddressInfoBase, UserAddressLocation):\n    pass\n\n\nclass UserAddress(\n    UserAddressInfoBase,\n    UserAddressUserDetails,\n    UUIDMixin,\n    TimestampMixin,\n    SoftDeleteMixin,\n):\n    pass\n\n\nclass UserAddressRead(UserAddressBase, UUIDMixin):\n    pass\n\n\nclass UserAddressCreate(\n    UserAddressBase,\n):\n    class Config:\n        extra = \"forbid\"\n\n\nclass UserAddressCreateInternal(\n    UserAddressBase,\n):\n    pass\n\n\n@optional()\nclass UserAddressUpdate(\n    UserAddressBase,\n):\n    class Config:\n        extra = \"forbid\"\n\n\nclass UserAddressUpdateInternal(\n    UserAddressBase,\n):\n    updated_at: datetime\n\n\nclass UserAddressDelete(SoftDeleteMixin):\n    model_config = ConfigDict(extra=\"forbid\")  # type: ignore\n\n\nclass UserAddressRestoreDeleted(BaseModel):\n    \"\"\"\n    API Schema\n\n    Description:\n    ----------\n    Schema for restoring a deleted user address.\n\n    Fields:\n    ----------\n    - 'is_deleted': Flag indicating whether the user address record is deleted (soft deletion).\n    \"\"\"\n\n    is_deleted: bool\n"}
