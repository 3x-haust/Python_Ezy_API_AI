{"repo_info": {"repo_name": "dimos-unitree", "repo_owner": "dimensionalOS", "repo_url": "https://github.com/dimensionalOS/dimos-unitree"}}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/test_ice.py", "content": "import asyncio\nimport functools\nimport os\nimport unittest\nfrom unittest import mock\n\nimport ifaddr\nfrom aioice import Candidate, TransportPolicy, ice, mdns, stun\n\nfrom .turnserver import run_turn_server\nfrom .utils import asynctest, invite_accept\n\nRUNNING_ON_CI = os.environ.get(\"GITHUB_ACTIONS\") == \"true\"\n\n\nasync def delay(coro):\n    await asyncio.sleep(1)\n    await coro()\n\n\nclass ProtocolMock:\n    local_candidate = Candidate(\n        foundation=\"some-foundation\",\n        component=1,\n        transport=\"udp\",\n        priority=1234,\n        host=\"1.2.3.4\",\n        port=1234,\n        type=\"host\",\n    )\n\n    sent_message = None\n\n    async def request(self, message, addr, integrity_key=None):\n        return (self.response_message, self.response_addr)\n\n    def send_stun(self, message, addr):\n        self.sent_message = message\n\n\nclass IceComponentTest(unittest.TestCase):\n    @asynctest\n    async def test_peer_reflexive(self):\n        connection = ice.Connection(ice_controlling=True)\n        connection.remote_password = \"remote-password\"\n        connection.remote_username = \"remote-username\"\n\n        protocol = ProtocolMock()\n        protocol.response_addr = (\"2.3.4.5\", 2345)\n        protocol.response_message = \"bad\"\n\n        request = stun.Message(\n            message_method=stun.Method.BINDING, message_class=stun.Class.REQUEST\n        )\n        request.attributes[\"PRIORITY\"] = 456789\n\n        connection.check_incoming(request, (\"2.3.4.5\", 2345), protocol)\n        self.assertIsNone(protocol.sent_message)\n\n        # check we have discovered a peer-reflexive candidate\n        self.assertEqual(len(connection.remote_candidates), 1)\n        candidate = connection.remote_candidates[0]\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"udp\")\n        self.assertEqual(candidate.priority, 456789)\n        self.assertEqual(candidate.host, \"2.3.4.5\")\n        self.assertEqual(candidate.port, 2345)\n        self.assertEqual(candidate.type, \"prflx\")\n        self.assertEqual(candidate.generation, None)\n\n        # check a new pair was formed\n        self.assertEqual(len(connection._check_list), 1)\n        pair = connection._check_list[0]\n        self.assertEqual(pair.protocol, protocol)\n        self.assertEqual(pair.remote_candidate, candidate)\n\n        # check a triggered check was scheduled\n        self.assertIsNotNone(pair.task)\n        await pair.task\n\n    @asynctest\n    async def test_request_with_invalid_method(self):\n        connection = ice.Connection(ice_controlling=True)\n\n        protocol = ProtocolMock()\n\n        request = stun.Message(\n            message_method=stun.Method.ALLOCATE, message_class=stun.Class.REQUEST\n        )\n\n        connection.request_received(\n            request, (\"2.3.4.5\", 2345), protocol, bytes(request)\n        )\n        self.assertIsNotNone(protocol.sent_message)\n        self.assertEqual(protocol.sent_message.message_method, stun.Method.ALLOCATE)\n        self.assertEqual(protocol.sent_message.message_class, stun.Class.ERROR)\n        self.assertEqual(\n            protocol.sent_message.attributes[\"ERROR-CODE\"], (400, \"Bad Request\")\n        )\n\n    @asynctest\n    async def test_response_with_invalid_address(self):\n        connection = ice.Connection(ice_controlling=True)\n        connection.remote_password = \"remote-password\"\n        connection.remote_username = \"remote-username\"\n\n        protocol = ProtocolMock()\n        protocol.response_addr = (\"3.4.5.6\", 3456)\n        protocol.response_message = \"bad\"\n\n        pair = ice.CandidatePair(\n            protocol,\n            Candidate(\n                foundation=\"some-foundation\",\n                component=1,\n                transport=\"udp\",\n                priority=2345,\n                host=\"2.3.4.5\",\n                port=2345,\n                type=\"host\",\n            ),\n        )\n        self.assertEqual(\n            repr(pair), \"CandidatePair(('1.2.3.4', 1234) -> ('2.3.4.5', 2345))\"\n        )\n\n        await connection.check_start(pair)\n        self.assertEqual(pair.state, ice.CandidatePair.State.FAILED)\n\n\nclass IceConnectionTest(unittest.TestCase):\n    def assertCandidateTypes(self, conn, expected):\n        types = set([c.type for c in conn.local_candidates])\n        self.assertEqual(types, expected)\n\n    def tearDown(self):\n        ice.CONSENT_FAILURES = 6\n        ice.CONSENT_INTERVAL = 5\n        stun.RETRY_MAX = 6\n\n    @mock.patch(\"ifaddr.get_adapters\")\n    def test_get_host_addresses(self, mock_get_adapters):\n        mock_get_adapters.return_value = [\n            ifaddr.Adapter(\n                ips=[\n                    ifaddr.IP(ip=\"127.0.0.1\", network_prefix=8, nice_name=\"lo\"),\n                    ifaddr.IP(ip=(\"::1\", 0, 0), network_prefix=128, nice_name=\"lo\"),\n                ],\n                name=\"lo\",\n                nice_name=\"lo\",\n            ),\n            ifaddr.Adapter(\n                ips=[\n                    ifaddr.IP(\n                        ip=\"1.2.3.4\",\n                        network_prefix=24,\n                        nice_name=\"eth0\",\n                    ),\n                    ifaddr.IP(\n                        ip=(\"2a02:0db8:85a3:0000:0000:8a2e:0370:7334\", 0, 0),\n                        network_prefix=64,\n                        nice_name=\"eth0\",\n                    ),\n                    ifaddr.IP(\n                        ip=(\"fe80::1234:5678:9abc:def0\", 0, 2),\n                        network_prefix=64,\n                        nice_name=\"eth0\",\n                    ),\n                ],\n                name=\"eth0\",\n                nice_name=\"eth0\",\n            ),\n        ]\n\n        # IPv4 only\n        addresses = ice.get_host_addresses(use_ipv4=True, use_ipv6=False)\n        self.assertEqual(addresses, [\"1.2.3.4\"])\n\n        # IPv6 only\n        addresses = ice.get_host_addresses(use_ipv4=False, use_ipv6=True)\n        self.assertEqual(addresses, [\"2a02:0db8:85a3:0000:0000:8a2e:0370:7334\"])\n\n        # both\n        addresses = ice.get_host_addresses(use_ipv4=True, use_ipv6=True)\n        self.assertEqual(\n            addresses, [\"1.2.3.4\", \"2a02:0db8:85a3:0000:0000:8a2e:0370:7334\"]\n        )\n\n    @asynctest\n    async def test_close(self):\n        conn_a = ice.Connection(ice_controlling=True)\n\n        # close\n        event, _ = await asyncio.gather(conn_a.get_event(), conn_a.close())\n        self.assertTrue(isinstance(event, ice.ConnectionClosed))\n\n        # no more events\n        event = await conn_a.get_event()\n        self.assertIsNone(event)\n\n        # close again\n        await conn_a.close()\n\n    @asynctest\n    async def test_connect(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # there should be a default candidate for component 1\n        candidate = conn_a.get_default_candidate(1)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # there should not be a default candidate for component 2\n        candidate = conn_a.get_default_candidate(2)\n        self.assertIsNone(candidate)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_close(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # close while connecting\n        await conn_b.close()\n        done, pending = await asyncio.wait(\n            [\n                asyncio.create_task(conn_a.connect()),\n                asyncio.create_task(delay(conn_a.close)),\n            ]\n        )\n        for task in pending:\n            task.cancel()\n        self.assertEqual(len(done), 2)\n\n        exceptions = [x.exception() for x in done if x.exception()]\n        self.assertEqual(len(exceptions), 1)\n        self.assertTrue(isinstance(exceptions[0], ConnectionError))\n\n    @asynctest\n    async def test_connect_early_checks(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await conn_a.connect()\n        await asyncio.sleep(1)\n        await conn_b.connect()\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_early_checks_2(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # both sides gather local candidates and exchange credentials\n        await conn_a.gather_candidates()\n        await conn_b.gather_candidates()\n        conn_a.remote_username = conn_b.local_username\n        conn_a.remote_password = conn_b.local_password\n        conn_b.remote_username = conn_a.local_username\n        conn_b.remote_password = conn_a.local_password\n\n        async def connect_b():\n            # side B receives offer and connects\n            for candidate in conn_a.local_candidates:\n                await conn_b.add_remote_candidate(candidate)\n            await conn_b.add_remote_candidate(None)\n            await conn_b.connect()\n\n            # side A receives candidates\n            for candidate in conn_b.local_candidates:\n                await conn_a.add_remote_candidate(candidate)\n            await conn_a.add_remote_candidate(None)\n\n        # The sequence is:\n        # - side A starts connecting immediately, but has no candidates\n        # - side B receives candidates and connects\n        # - side A receives candidates, and connection completes\n        await asyncio.gather(conn_a.connect(), connect_b())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_two_components(self):\n        conn_a = ice.Connection(ice_controlling=True, components=2)\n        conn_b = ice.Connection(ice_controlling=False, components=2)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # there should be a default candidate for component 1\n        candidate = conn_a.get_default_candidate(1)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # there should be a default candidate for component 2\n        candidate = conn_a.get_default_candidate(2)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(conn_a._components, set([1, 2]))\n        self.assertEqual(conn_b._components, set([1, 2]))\n\n        # send data a -> b (component 1)\n        await conn_a.sendto(b\"howdee\", 1)\n        data, component = await conn_b.recvfrom()\n        self.assertEqual(data, b\"howdee\")\n        self.assertEqual(component, 1)\n\n        # send data b -> a (component 1)\n        await conn_b.sendto(b\"gotcha\", 1)\n        data, component = await conn_a.recvfrom()\n        self.assertEqual(data, b\"gotcha\")\n        self.assertEqual(component, 1)\n\n        # send data a -> b (component 2)\n        await conn_a.sendto(b\"howdee 2\", 2)\n        data, component = await conn_b.recvfrom()\n        self.assertEqual(data, b\"howdee 2\")\n        self.assertEqual(component, 2)\n\n        # send data b -> a (component 2)\n        await conn_b.sendto(b\"gotcha 2\", 2)\n        data, component = await conn_a.recvfrom()\n        self.assertEqual(data, b\"gotcha 2\")\n        self.assertEqual(component, 2)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_two_components_vs_one_component(self):\n        \"\"\"\n        It is possible that some of the local candidates won't get paired with\n        remote candidates, and some of the remote candidates won't get paired\n        with local candidates.  This can happen if one agent doesn't include\n        candidates for the all of the components for a media stream.  If this\n        happens, the number of components for that media stream is effectively\n        reduced, and considered to be equal to the minimum across both agents\n        of the maximum component ID provided by each agent across all\n        components for the media stream.\n        \"\"\"\n        conn_a = ice.Connection(ice_controlling=True, components=2)\n        conn_b = ice.Connection(ice_controlling=False, components=1)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n        self.assertTrue(len(conn_a.local_candidates) > 0)\n        for candidate in conn_a.local_candidates:\n            self.assertEqual(candidate.type, \"host\")\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(conn_a._components, set([1]))\n        self.assertEqual(conn_b._components, set([1]))\n\n        # send data a -> b (component 1)\n        await conn_a.sendto(b\"howdee\", 1)\n        data, component = await conn_b.recvfrom()\n        self.assertEqual(data, b\"howdee\")\n        self.assertEqual(component, 1)\n\n        # send data b -> a (component 1)\n        await conn_b.sendto(b\"gotcha\", 1)\n        data, component = await conn_a.recvfrom()\n        self.assertEqual(data, b\"gotcha\")\n        self.assertEqual(component, 1)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_to_ice_lite(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_a.remote_is_lite = True\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # there should be a default candidate for component 1\n        candidate = conn_a.get_default_candidate(1)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # there should not be a default candidate for component 2\n        candidate = conn_a.get_default_candidate(2)\n        self.assertIsNone(candidate)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_to_ice_lite_nomination_fails(self):\n        def mock_request_received(self, message, addr, protocol, raw_data):\n            if \"USE-CANDIDATE\" in message.attributes:\n                self.respond_error(message, addr, protocol, (500, \"Internal Error\"))\n            else:\n                self.real_request_received(message, addr, protocol, raw_data)\n\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_a.remote_is_lite = True\n        conn_b = ice.Connection(ice_controlling=False)\n        conn_b.real_request_received = conn_b.request_received\n        conn_b.request_received = functools.partial(mock_request_received, conn_b)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        with self.assertRaises(ConnectionError) as cm:\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(str(cm.exception), \"ICE negotiation failed\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @unittest.skipIf(RUNNING_ON_CI, \"CI lacks ipv6\")\n    @asynctest\n    async def test_connect_ipv6(self):\n        conn_a = ice.Connection(ice_controlling=True, use_ipv4=False, use_ipv6=True)\n        conn_b = ice.Connection(ice_controlling=False, use_ipv4=False, use_ipv6=True)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n        self.assertTrue(len(conn_a.local_candidates) > 0)\n        for candidate in conn_a.local_candidates:\n            self.assertEqual(candidate.type, \"host\")\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_reverse_order(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # introduce a delay so that B's checks complete before A's\n        await asyncio.gather(delay(conn_a.connect), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_invalid_password(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite\n        await conn_a.gather_candidates()\n        for candidate in conn_a.local_candidates:\n            await conn_b.add_remote_candidate(candidate)\n        await conn_b.add_remote_candidate(None)\n        conn_b.remote_username = conn_a.local_username\n        conn_b.remote_password = conn_a.local_password\n\n        # accept\n        await conn_b.gather_candidates()\n        for candidate in conn_b.local_candidates:\n            await conn_a.add_remote_candidate(candidate)\n        await conn_a.add_remote_candidate(None)\n        conn_a.remote_username = conn_b.local_username\n        conn_a.remote_password = \"wrong-password\"\n\n        # connect\n        done, pending = await asyncio.wait(\n            [\n                asyncio.create_task(conn_a.connect()),\n                asyncio.create_task(conn_b.connect()),\n            ],\n            return_when=asyncio.FIRST_EXCEPTION,\n        )\n        for task in pending:\n            task.cancel()\n        self.assertEqual(len(done), 1)\n        self.assertTrue(isinstance(done.pop().exception(), ConnectionError))\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_invalid_username(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite\n        await conn_a.gather_candidates()\n        for candidate in conn_a.local_candidates:\n            await conn_b.add_remote_candidate(candidate)\n        await conn_b.add_remote_candidate(None)\n        conn_b.remote_username = conn_a.local_username\n        conn_b.remote_password = conn_a.local_password\n\n        # accept\n        await conn_b.gather_candidates()\n        for candidate in conn_b.local_candidates:\n            await conn_a.add_remote_candidate(candidate)\n        await conn_a.add_remote_candidate(None)\n        conn_a.remote_username = \"wrong-username\"\n        conn_a.remote_password = conn_b.local_password\n\n        # connect\n        done, pending = await asyncio.wait(\n            [\n                asyncio.create_task(conn_a.connect()),\n                asyncio.create_task(conn_b.connect()),\n            ]\n        )\n        for task in pending:\n            task.cancel()\n        self.assertEqual(len(done), 2)\n        self.assertTrue(isinstance(done.pop().exception(), ConnectionError))\n        self.assertTrue(isinstance(done.pop().exception(), ConnectionError))\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_no_gather(self):\n        \"\"\"\n        If local candidates gathering was not performed, connect fails.\n        \"\"\"\n        conn = ice.Connection(ice_controlling=True)\n        await conn.add_remote_candidate(\n            Candidate.from_sdp(\n                \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n            )\n        )\n        await conn.add_remote_candidate(None)\n        conn.remote_username = \"foo\"\n        conn.remote_password = \"bar\"\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(\n            str(cm.exception), \"Local candidates gathering was not performed\"\n        )\n        await conn.close()\n\n    @asynctest\n    async def test_connect_no_local_candidates(self):\n        \"\"\"\n        If local candidates gathering yielded no candidates, connect fails.\n        \"\"\"\n        conn = ice.Connection(ice_controlling=True)\n        conn._local_candidates_end = True\n        await conn.add_remote_candidate(\n            Candidate.from_sdp(\n                \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n            )\n        )\n        await conn.add_remote_candidate(None)\n        conn.remote_username = \"foo\"\n        conn.remote_password = \"bar\"\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(str(cm.exception), \"ICE negotiation failed\")\n        await conn.close()\n\n    @asynctest\n    async def test_connect_no_remote_candidates(self):\n        \"\"\"\n        If no remote candidates were provided, connect fails.\n        \"\"\"\n        conn = ice.Connection(ice_controlling=True)\n        await conn.gather_candidates()\n        await conn.add_remote_candidate(None)\n        conn.remote_username = \"foo\"\n        conn.remote_password = \"bar\"\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(str(cm.exception), \"ICE negotiation failed\")\n        await conn.close()\n\n    @asynctest\n    async def test_connect_no_remote_credentials(self):\n        \"\"\"\n        If remote credentials have not been provided, connect fails.\n        \"\"\"\n        conn = ice.Connection(ice_controlling=True)\n        await conn.gather_candidates()\n        await conn.add_remote_candidate(\n            Candidate.from_sdp(\n                \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n            )\n        )\n        await conn.add_remote_candidate(None)\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(str(cm.exception), \"Remote username or password is missing\")\n        await conn.close()\n\n    @asynctest\n    async def test_connect_role_conflict_both_controlling(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=True)\n\n        # set tie breaker for a deterministic outcome\n        conn_a._tie_breaker = 1\n        conn_b._tie_breaker = 2\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertFalse(conn_a.ice_controlling)\n        self.assertTrue(conn_b.ice_controlling)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_role_conflict_both_controlled(self):\n        conn_a = ice.Connection(ice_controlling=False)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # set tie breaker for a deterministic outcome\n        conn_a._tie_breaker = 1\n        conn_b._tie_breaker = 2\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertFalse(conn_a.ice_controlling)\n        self.assertTrue(conn_b.ice_controlling)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_timeout(self):\n        # lower STUN retries\n        stun.RETRY_MAX = 1\n\n        conn = ice.Connection(ice_controlling=True)\n        await conn.gather_candidates()\n        await conn.add_remote_candidate(\n            Candidate.from_sdp(\n                \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n            )\n        )\n        await conn.add_remote_candidate(None)\n        conn.remote_username = \"foo\"\n        conn.remote_password = \"bar\"\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(str(cm.exception), \"ICE negotiation failed\")\n        await conn.close()\n\n    @asynctest\n    async def test_connect_with_stun_server(self):\n        async with run_turn_server() as stun_server:\n            conn_a = ice.Connection(\n                ice_controlling=True, stun_server=stun_server.udp_address\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould have both host and server-reflexive candidates\n            self.assertCandidateTypes(conn_a, set([\"host\", \"srflx\"]))\n            self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n            # the default candidate should be server-reflexive\n            candidate = conn_a.get_default_candidate(1)\n            self.assertIsNotNone(candidate)\n            self.assertEqual(candidate.type, \"srflx\")\n            self.assertIsNotNone(candidate.related_address)\n            self.assertIsNotNone(candidate.related_port)\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_connect_with_stun_server_dns_lookup_error(self):\n        conn_a = ice.Connection(ice_controlling=True, stun_server=(\"invalid.\", 1234))\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we whould have only host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_with_stun_server_timeout(self):\n        async with run_turn_server() as stun_server:\n            # immediately stop turn server\n            await stun_server.close()\n\n            conn_a = ice.Connection(\n                ice_controlling=True, stun_server=stun_server.udp_address\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould have only host candidates\n            self.assertCandidateTypes(conn_a, set([\"host\"]))\n            self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @unittest.skipIf(RUNNING_ON_CI, \"CI lacks ipv6\")\n    @asynctest\n    async def test_connect_with_stun_server_ipv6(self):\n        async with run_turn_server() as stun_server:\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                stun_server=stun_server.udp_address,\n                use_ipv4=False,\n                use_ipv6=True,\n            )\n            conn_b = ice.Connection(\n                ice_controlling=False, use_ipv4=False, use_ipv6=True\n            )\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we only want host candidates : no STUN for IPv6\n            self.assertTrue(len(conn_a.local_candidates) > 0)\n            for candidate in conn_a.local_candidates:\n                self.assertEqual(candidate.type, \"host\")\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_connect_with_turn_server_tcp(self):\n        async with run_turn_server(users={\"foo\": \"bar\"}) as turn_server:\n            # create connections\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                turn_server=turn_server.tcp_address,\n                turn_username=\"foo\",\n                turn_password=\"bar\",\n                turn_transport=\"tcp\",\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould have both host and relayed candidates\n            self.assertCandidateTypes(conn_a, set([\"host\", \"relay\"]))\n            self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n            # the default candidate should be relayed\n            candidate = conn_a.get_default_candidate(1)\n            self.assertIsNotNone(candidate)\n            self.assertEqual(candidate.type, \"relay\")\n            self.assertIsNotNone(candidate.related_address)\n            self.assertIsNotNone(candidate.related_port)\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_connect_with_turn_server_udp(self):\n        async with run_turn_server(users={\"foo\": \"bar\"}) as turn_server:\n            # create connections\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                turn_server=turn_server.udp_address,\n                turn_username=\"foo\",\n                turn_password=\"bar\",\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould have both host and relayed candidates\n            self.assertCandidateTypes(conn_a, set([\"host\", \"relay\"]))\n            self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n            # the default candidate should be relayed\n            candidate = conn_a.get_default_candidate(1)\n            self.assertIsNotNone(candidate)\n            self.assertEqual(candidate.type, \"relay\")\n            self.assertIsNotNone(candidate.related_address)\n            self.assertIsNotNone(candidate.related_port)\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_consent_expired(self):\n        # lower consent timer\n        ice.CONSENT_FAILURES = 1\n        ice.CONSENT_INTERVAL = 1\n\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(len(conn_a._nominated), 1)\n\n        # let consent expire\n        await conn_b.close()\n        await asyncio.sleep(2)\n        self.assertEqual(len(conn_a._nominated), 0)\n\n        # close\n        await conn_a.close()\n\n    @asynctest\n    async def test_consent_valid(self):\n        # lower consent timer\n        ice.CONSENT_FAILURES = 1\n        ice.CONSENT_INTERVAL = 1\n\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(len(conn_a._nominated), 1)\n\n        # check consent\n        await asyncio.sleep(2)\n        self.assertEqual(len(conn_a._nominated), 1)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_set_selected_pair(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # force selected pair\n        default_a = conn_a.get_default_candidate(1)\n        default_b = conn_a.get_default_candidate(1)\n        conn_a.set_selected_pair(1, default_a.foundation, default_b.foundation)\n        conn_b.set_selected_pair(1, default_b.foundation, default_a.foundation)\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_recv_not_connected(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        with self.assertRaises(ConnectionError) as cm:\n            await conn_a.recv()\n        self.assertEqual(str(cm.exception), \"Cannot receive data, not connected\")\n\n    @asynctest\n    async def test_recv_connection_lost(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # disconnect while receiving\n        with self.assertRaises(ConnectionError) as cm:\n            await asyncio.gather(conn_a.recv(), delay(conn_a.close))\n        self.assertEqual(str(cm.exception), \"Connection lost while receiving data\")\n\n        # close\n        await conn_b.close()\n\n    @asynctest\n    async def test_send_not_connected(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        with self.assertRaises(ConnectionError) as cm:\n            await conn_a.send(b\"howdee\")\n        self.assertEqual(str(cm.exception), \"Cannot send data, not connected\")\n\n    @asynctest\n    async def test_add_remote_candidate(self):\n        conn_a = ice.Connection(ice_controlling=True)\n\n        remote_candidate = Candidate(\n            foundation=\"some-foundation\",\n            component=1,\n            transport=\"udp\",\n            priority=1234,\n            host=\"1.2.3.4\",\n            port=1234,\n            type=\"host\",\n        )\n\n        # add candidate\n        await conn_a.add_remote_candidate(remote_candidate)\n        self.assertEqual(len(conn_a.remote_candidates), 1)\n        self.assertEqual(conn_a.remote_candidates[0].host, \"1.2.3.4\")\n        self.assertEqual(conn_a._remote_candidates_end, False)\n\n        # end-of-candidates\n        await conn_a.add_remote_candidate(None)\n        self.assertEqual(len(conn_a.remote_candidates), 1)\n        self.assertEqual(conn_a._remote_candidates_end, True)\n\n        # try adding another candidate\n        with self.assertRaises(ValueError) as cm:\n            await conn_a.add_remote_candidate(remote_candidate)\n        self.assertEqual(\n            str(cm.exception), \"Cannot add remote candidate after end-of-candidates.\"\n        )\n        self.assertEqual(len(conn_a.remote_candidates), 1)\n        self.assertEqual(conn_a._remote_candidates_end, True)\n\n    @asynctest\n    async def test_add_remote_candidate_mdns_bad(self):\n        \"\"\"\n        Add an mDNS candidate which cannot be resolved.\n        \"\"\"\n        conn_a = ice.Connection(ice_controlling=True)\n\n        await conn_a.add_remote_candidate(\n            Candidate(\n                foundation=\"some-foundation\",\n                component=1,\n                transport=\"udp\",\n                priority=1234,\n                host=mdns.create_mdns_hostname(),\n                port=1234,\n                type=\"host\",\n            )\n        )\n        self.assertEqual(len(conn_a.remote_candidates), 0)\n        self.assertEqual(conn_a._remote_candidates_end, False)\n\n        # close\n        await conn_a.close()\n\n    @asynctest\n    async def test_add_remote_candidate_mdns_good(self):\n        \"\"\"\n        Add an mDNS candidate which can be resolved.\n        \"\"\"\n        hostname = mdns.create_mdns_hostname()\n        publisher = await mdns.create_mdns_protocol()\n        await publisher.publish(hostname, \"1.2.3.4\")\n\n        conn_a = ice.Connection(ice_controlling=True)\n\n        await conn_a.add_remote_candidate(\n            Candidate(\n                foundation=\"some-foundation\",\n                component=1,\n                transport=\"udp\",\n                priority=1234,\n                host=hostname,\n                port=1234,\n                type=\"host\",\n            )\n        )\n        self.assertEqual(len(conn_a.remote_candidates), 1)\n        self.assertEqual(conn_a.remote_candidates[0].host, \"1.2.3.4\")\n        self.assertEqual(conn_a._remote_candidates_end, False)\n\n        # close\n        await conn_a.close()\n        await publisher.close()\n\n    @asynctest\n    async def test_add_remote_candidate_unknown_type(self):\n        conn_a = ice.Connection(ice_controlling=True)\n\n        await conn_a.add_remote_candidate(\n            Candidate(\n                foundation=\"some-foundation\",\n                component=1,\n                transport=\"udp\",\n                priority=1234,\n                host=\"1.2.3.4\",\n                port=1234,\n                type=\"bogus\",\n            )\n        )\n        self.assertEqual(len(conn_a.remote_candidates), 0)\n        self.assertEqual(conn_a._remote_candidates_end, False)\n\n    @mock.patch(\"asyncio.base_events.BaseEventLoop.create_datagram_endpoint\")\n    @asynctest\n    async def test_gather_candidates_oserror(self, mock_create):\n        exc = OSError()\n        exc.errno = 99\n        exc.strerror = \"Cannot assign requested address\"\n        mock_create.side_effect = exc\n\n        conn = ice.Connection(ice_controlling=True)\n        await conn.gather_candidates()\n        self.assertEqual(conn.local_candidates, [])\n\n    @asynctest\n    async def test_gather_candidates_relay_only_no_servers(self):\n        with self.assertRaises(ValueError) as cm:\n            ice.Connection(ice_controlling=True, transport_policy=TransportPolicy.RELAY)\n        self.assertEqual(\n            str(cm.exception),\n            \"Relay transport policy requires a STUN and/or TURN server.\",\n        )\n\n    @asynctest\n    async def test_gather_candidates_relay_only_with_stun_server(self):\n        async with run_turn_server() as stun_server:\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                stun_server=stun_server.udp_address,\n                transport_policy=TransportPolicy.RELAY,\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould only have a server-reflexive candidate in connection a\n            self.assertCandidateTypes(conn_a, set([\"srflx\"]))\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_gather_candidates_relay_only_with_turn_server(self):\n        async with run_turn_server(users={\"foo\": \"bar\"}) as turn_server:\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                turn_server=turn_server.udp_address,\n                turn_username=\"foo\",\n                turn_password=\"bar\",\n                transport_policy=TransportPolicy.RELAY,\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould only have a server-reflexive candidate in connection a\n            self.assertCandidateTypes(conn_a, set([\"relay\"]))\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_repr(self):\n        conn = ice.Connection(ice_controlling=True)\n        conn._id = 1\n        self.assertEqual(repr(conn), \"Connection(1)\")\n\n\nclass StunProtocolTest(unittest.TestCase):\n    @asynctest\n    async def test_error_received(self):\n        protocol = ice.StunProtocol(None)\n        protocol.error_received(OSError(\"foo\"))\n\n    @asynctest\n    async def test_repr(self):\n        protocol = ice.StunProtocol(None)\n        protocol.id = 1\n        self.assertEqual(repr(protocol), \"protocol(1)\")\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/test_exceptions.py", "content": "import unittest\n\nfrom aioice import stun\n\n\nclass ExceptionTest(unittest.TestCase):\n    def test_transaction_failed(self):\n        response = stun.Message(\n            message_method=stun.Method.BINDING, message_class=stun.Class.RESPONSE\n        )\n        response.attributes[\"ERROR-CODE\"] = (487, \"Role Conflict\")\n\n        exc = stun.TransactionFailed(response)\n        self.assertEqual(str(exc), \"STUN transaction failed (487 - Role Conflict)\")\n\n    def test_transaction_timeout(self):\n        exc = stun.TransactionTimeout()\n        self.assertEqual(str(exc), \"STUN transaction timed out\")\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/test_mdns.py", "content": "import asyncio\nimport contextlib\nimport unittest\n\nfrom aioice import mdns\n\nfrom .utils import asynctest\n\n\n@contextlib.asynccontextmanager\nasync def querier_and_responder():\n    querier = await mdns.create_mdns_protocol()\n    responder = await mdns.create_mdns_protocol()\n\n    try:\n        yield querier, responder\n    finally:\n        await querier.close()\n        await responder.close()\n\n\nclass MdnsTest(unittest.TestCase):\n    @asynctest\n    async def test_receive_junk(self):\n        async with querier_and_responder() as (querier, _):\n            querier.datagram_received(b\"junk\", None)\n\n    @asynctest\n    async def test_resolve_bad(self):\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, _):\n            result = await querier.resolve(hostname)\n            self.assertEqual(result, None)\n\n    @asynctest\n    async def test_resolve_close(self):\n        hostname = mdns.create_mdns_hostname()\n\n        # close the querier while the query is ongoing\n        async with querier_and_responder() as (querier, _):\n            result = await asyncio.gather(\n                querier.resolve(hostname, timeout=None), querier.close()\n            )\n            self.assertEqual(result, [None, None])\n\n    @asynctest\n    async def test_resolve_good_ipv4(self):\n        hostaddr = \"1.2.3.4\"\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, responder):\n            await responder.publish(hostname, hostaddr)\n\n            result = await querier.resolve(hostname)\n            self.assertEqual(result, hostaddr)\n\n    @asynctest\n    async def test_resolve_good_ipv6(self):\n        hostaddr = \"::ffff:1.2.3.4\"\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, responder):\n            await responder.publish(hostname, hostaddr)\n\n            result = await querier.resolve(hostname)\n            self.assertEqual(result, hostaddr)\n\n    @asynctest\n    async def test_resolve_simultaneous_bad(self):\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, _):\n            results = await asyncio.gather(\n                querier.resolve(hostname), querier.resolve(hostname)\n            )\n            self.assertEqual(results, [None, None])\n\n    @asynctest\n    async def test_resolve_simultaneous_good(self):\n        hostaddr = \"1.2.3.4\"\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, responder):\n            await responder.publish(hostname, hostaddr)\n\n            results = await asyncio.gather(\n                querier.resolve(hostname), querier.resolve(hostname)\n            )\n            self.assertEqual(results, [hostaddr, hostaddr])\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/test/test_flake8.py", "content": "# Copyright 2017 Open Source Robotics Foundation, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom ament_flake8.main import main_with_errors\nimport pytest\n\n\n@pytest.mark.flake8\n@pytest.mark.linter\ndef test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/utils.py", "content": "import asyncio\nimport functools\nimport logging\nimport os\n\n\ndef asynctest(coro):\n    @functools.wraps(coro)\n    def wrap(*args, **kwargs):\n        asyncio.run(coro(*args, **kwargs))\n\n    return wrap\n\n\nasync def invite_accept(conn_a, conn_b):\n    # invite\n    await conn_a.gather_candidates()\n    for candidate in conn_a.local_candidates:\n        await conn_b.add_remote_candidate(candidate)\n    await conn_b.add_remote_candidate(None)\n    conn_b.remote_username = conn_a.local_username\n    conn_b.remote_password = conn_a.local_password\n\n    # accept\n    await conn_b.gather_candidates()\n    for candidate in conn_b.local_candidates:\n        await conn_a.add_remote_candidate(candidate)\n    await conn_a.add_remote_candidate(None)\n    conn_a.remote_username = conn_b.local_username\n    conn_a.remote_password = conn_b.local_password\n\n\ndef read_message(name):\n    path = os.path.join(os.path.dirname(__file__), \"data\", name)\n    with open(path, \"rb\") as fp:\n        return fp.read()\n\n\nif os.environ.get(\"AIOICE_DEBUG\"):\n    logging.basicConfig(level=logging.DEBUG)\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/test/test_pep257.py", "content": "# Copyright 2015 Open Source Robotics Foundation, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom ament_pep257.main import main\nimport pytest\n\n\n@pytest.mark.linter\n@pytest.mark.pep257\ndef test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/test_turn.py", "content": "import asyncio\nimport ssl\nimport unittest\n\nfrom aioice import stun, turn\n\nfrom .echoserver import run_echo_server\nfrom .turnserver import run_turn_server\nfrom .utils import asynctest, read_message\n\nPROTOCOL_KWARGS = {\n    \"username\": \"foo\",\n    \"password\": \"bar\",\n    \"lifetime\": turn.DEFAULT_ALLOCATION_LIFETIME,\n    \"channel_refresh_time\": turn.DEFAULT_CHANNEL_REFRESH_TIME,\n}\n\n\nclass DummyClientProtocol(asyncio.DatagramProtocol):\n    def __init__(self):\n        self.received = []\n\n    def datagram_received(self, data, addr):\n        self.received.append((data, addr))\n\n\nclass TurnClientTcpProtocolTest(unittest.TestCase):\n    def setUp(self):\n        class MockProtocol:\n            def get_extra_info(self, name):\n                return (\"1.2.3.4\", 1234)\n\n        self.protocol = turn.TurnClientTcpProtocol((\"1.2.3.4\", 1234), **PROTOCOL_KWARGS)\n        self.protocol.connection_made(MockProtocol())\n\n    def test_receive_stun_fragmented(self):\n        data = read_message(\"binding_request.bin\")\n        self.protocol.data_received(data[0:10])\n        self.protocol.data_received(data[10:])\n\n    def test_receive_junk(self):\n        self.protocol.data_received(b\"\\x00\" * 20)\n\n    def test_repr(self):\n        self.assertEqual(repr(self.protocol), \"turn/tcp\")\n\n\nclass TurnClientUdpProtocolTest(unittest.TestCase):\n    def setUp(self):\n        self.protocol = turn.TurnClientUdpProtocol((\"1.2.3.4\", 1234), **PROTOCOL_KWARGS)\n\n    def test_receive_junk(self):\n        self.protocol.datagram_received(b\"\\x00\" * 20, (\"1.2.3.4\", 1234))\n\n    def test_repr(self):\n        self.assertEqual(repr(self.protocol), \"turn/udp\")\n\n\nclass TurnTest(unittest.TestCase):\n    @asynctest\n    async def test_tcp_transport(self):\n        await self._test_transport(\"tcp\", \"tcp_address\")\n\n    @asynctest\n    async def test_tls_transport(self):\n        ssl_context = ssl.SSLContext(protocol=ssl.PROTOCOL_TLS_CLIENT)\n        ssl_context.check_hostname = False\n        ssl_context.verify_mode = ssl.CERT_NONE\n\n        await self._test_transport(\"tcp\", \"tls_address\", ssl=ssl_context)\n\n    @asynctest\n    async def test_udp_transport(self):\n        await self._test_transport(\"udp\", \"udp_address\")\n\n    async def _test_transport(self, transport, server_addr_attr, ssl=False):\n        await self._test_transport_ok(\n            transport=transport, server_addr_attr=server_addr_attr, ssl=ssl\n        )\n        await self._test_transport_ok_multi(\n            transport=transport, server_addr_attr=server_addr_attr, ssl=ssl\n        )\n        await self._test_transport_allocate_failure(\n            transport=transport, server_addr_attr=server_addr_attr, ssl=ssl\n        )\n        await self._test_transport_delete_failure(\n            transport=transport, server_addr_attr=server_addr_attr, ssl=ssl\n        )\n\n    async def _test_transport_ok(self, *, transport, server_addr_attr, ssl):\n        async with run_turn_server(realm=\"test\", users={\"foo\": \"bar\"}) as turn_server:\n            transport, protocol = await turn.create_turn_endpoint(\n                DummyClientProtocol,\n                server_addr=getattr(turn_server, server_addr_attr),\n                username=\"foo\",\n                password=\"bar\",\n                channel_refresh_time=5,\n                lifetime=6,\n                ssl=ssl,\n                transport=transport,\n            )\n            self.assertIsNone(transport.get_extra_info(\"peername\"))\n            self.assertIsNotNone(transport.get_extra_info(\"sockname\"))\n\n            async with run_echo_server() as echo_server:\n                # bind channel, send ping, expect pong\n                transport.sendto(b\"ping\", echo_server.udp_address)\n                await asyncio.sleep(1)\n                self.assertEqual(\n                    protocol.received, [(b\"ping\", echo_server.udp_address)]\n                )\n\n                # wait some more to allow allocation refresh\n                protocol.received.clear()\n                await asyncio.sleep(5)\n\n                # refresh channel, send ping, expect pong\n                transport.sendto(b\"ping\", echo_server.udp_address)\n                await asyncio.sleep(1)\n                self.assertEqual(\n                    protocol.received, [(b\"ping\", echo_server.udp_address)]\n                )\n\n            # close\n            transport.close()\n            await asyncio.sleep(0)\n\n    async def _test_transport_ok_multi(self, *, transport, server_addr_attr, ssl):\n        async with run_turn_server(realm=\"test\", users={\"foo\": \"bar\"}) as turn_server:\n            transport, protocol = await turn.create_turn_endpoint(\n                DummyClientProtocol,\n                server_addr=getattr(turn_server, server_addr_attr),\n                username=\"foo\",\n                password=\"bar\",\n                channel_refresh_time=5,\n                lifetime=6,\n                ssl=ssl,\n                transport=transport,\n            )\n            self.assertIsNone(transport.get_extra_info(\"peername\"))\n            self.assertIsNotNone(transport.get_extra_info(\"sockname\"))\n\n            # Bind channel, send ping, expect pong.\n            #\n            # We use different lengths to trigger both padded an unpadded\n            # ChannelData messages over TCP.\n            async with run_echo_server() as echo_server1:\n                async with run_echo_server() as echo_server2:\n                    transport.sendto(b\"ping\", echo_server1.udp_address)  # never padded\n                    transport.sendto(b\"ping11\", echo_server1.udp_address)\n                    transport.sendto(b\"ping20\", echo_server2.udp_address)\n                    transport.sendto(b\"ping21\", echo_server2.udp_address)\n                    await asyncio.sleep(1)\n                    self.assertEqual(\n                        sorted(protocol.received),\n                        [\n                            (b\"ping\", echo_server1.udp_address),\n                            (b\"ping11\", echo_server1.udp_address),\n                            (b\"ping20\", echo_server2.udp_address),\n                            (b\"ping21\", echo_server2.udp_address),\n                        ],\n                    )\n\n            # close\n            transport.close()\n            await asyncio.sleep(0)\n\n    async def _test_transport_allocate_failure(\n        self, *, transport, server_addr_attr, ssl\n    ):\n        async with run_turn_server(realm=\"test\", users={\"foo\": \"bar\"}) as turn_server:\n            # make the server reject the ALLOCATE request\n            turn_server.simulated_failure = (403, \"Forbidden\")\n\n            with self.assertRaises(stun.TransactionFailed) as cm:\n                await turn.create_turn_endpoint(\n                    DummyClientProtocol,\n                    server_addr=getattr(turn_server, server_addr_attr),\n                    username=\"foo\",\n                    password=\"bar\",\n                    ssl=ssl,\n                    transport=transport,\n                )\n        self.assertEqual(str(cm.exception), \"STUN transaction failed (403 - Forbidden)\")\n\n    async def _test_transport_delete_failure(self, *, transport, server_addr_attr, ssl):\n        async with run_turn_server(realm=\"test\", users={\"foo\": \"bar\"}) as turn_server:\n            transport, protocol = await turn.create_turn_endpoint(\n                DummyClientProtocol,\n                server_addr=getattr(turn_server, server_addr_attr),\n                username=\"foo\",\n                password=\"bar\",\n                ssl=ssl,\n                transport=transport,\n            )\n            self.assertIsNone(transport.get_extra_info(\"peername\"))\n            self.assertIsNotNone(transport.get_extra_info(\"sockname\"))\n\n            # make the server reject the final REFRESH request\n            turn_server.simulated_failure = (403, \"Forbidden\")\n\n            # close client\n            transport.close()\n            await asyncio.sleep(0)\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/test_stun.py", "content": "import unittest\nfrom binascii import unhexlify\nfrom collections import OrderedDict\n\nfrom aioice import stun\n\nfrom .utils import asynctest, read_message\n\n\nclass AttributeTest(unittest.TestCase):\n    def test_unpack_error_code(self):\n        data = unhexlify(\"00000457526f6c6520436f6e666c696374\")\n        code, reason = stun.unpack_error_code(data)\n        self.assertEqual(code, 487)\n        self.assertEqual(reason, \"Role Conflict\")\n\n    def test_unpack_error_code_too_short(self):\n        data = unhexlify(\"000004\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_error_code(data)\n        self.assertEqual(str(cm.exception), \"STUN error code is less than 4 bytes\")\n\n    def test_unpack_xor_address_ipv4(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        address, port = stun.unpack_xor_address(\n            unhexlify(\"0001a147e112a643\"), transaction_id\n        )\n        self.assertEqual(address, \"192.0.2.1\")\n        self.assertEqual(port, 32853)\n\n    def test_unpack_xor_address_ipv4_truncated(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_xor_address(unhexlify(\"0001a147e112a6\"), transaction_id)\n        self.assertEqual(str(cm.exception), \"STUN address has invalid length for IPv4\")\n\n    def test_unpack_xor_address_ipv6(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        address, port = stun.unpack_xor_address(\n            unhexlify(\"0002a1470113a9faa5d3f179bc25f4b5bed2b9d9\"), transaction_id\n        )\n        self.assertEqual(address, \"2001:db8:1234:5678:11:2233:4455:6677\")\n        self.assertEqual(port, 32853)\n\n    def test_unpack_xor_address_ipv6_truncated(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_xor_address(\n                unhexlify(\"0002a1470113a9faa5d3f179bc25f4b5bed2b9\"), transaction_id\n            )\n        self.assertEqual(str(cm.exception), \"STUN address has invalid length for IPv6\")\n\n    def test_unpack_xor_address_too_short(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_xor_address(unhexlify(\"0001\"), transaction_id)\n        self.assertEqual(str(cm.exception), \"STUN address length is less than 4 bytes\")\n\n    def test_unpack_xor_address_unknown_protocol(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_xor_address(unhexlify(\"0003a147e112a643\"), transaction_id)\n        self.assertEqual(str(cm.exception), \"STUN address has unknown protocol\")\n\n    def test_pack_error_code(self):\n        data = stun.pack_error_code((487, \"Role Conflict\"))\n        self.assertEqual(data, unhexlify(\"00000457526f6c6520436f6e666c696374\"))\n\n    def test_pack_xor_address_ipv4(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        data = stun.pack_xor_address((\"192.0.2.1\", 32853), transaction_id)\n        self.assertEqual(data, unhexlify(\"0001a147e112a643\"))\n\n    def test_pack_xor_address_ipv6(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        data = stun.pack_xor_address(\n            (\"2001:db8:1234:5678:11:2233:4455:6677\", 32853), transaction_id\n        )\n        self.assertEqual(data, unhexlify(\"0002a1470113a9faa5d3f179bc25f4b5bed2b9d9\"))\n\n    def test_pack_xor_address_unknown_protocol(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.pack_xor_address((\"foo\", 32853), transaction_id)\n        self.assertEqual(\n            str(cm.exception), \"'foo' does not appear to be an IPv4 or IPv6 address\"\n        )\n\n\nclass MessageTest(unittest.TestCase):\n    def test_binding_request(self):\n        data = read_message(\"binding_request.bin\")\n\n        message = stun.parse_message(data)\n        self.assertEqual(message.message_method, stun.Method.BINDING)\n        self.assertEqual(message.message_class, stun.Class.REQUEST)\n        self.assertEqual(message.transaction_id, b\"Nvfx3lU7FUBF\")\n        self.assertEqual(message.attributes, OrderedDict())\n\n        self.assertEqual(bytes(message), data)\n        self.assertEqual(\n            repr(message),\n            \"Message(message_method=Method.BINDING, message_class=Class.REQUEST, \"\n            \"transaction_id=b'Nvfx3lU7FUBF')\",\n        )\n\n    def test_binding_request_ice_controlled(self):\n        data = read_message(\"binding_request_ice_controlled.bin\")\n\n        message = stun.parse_message(data)\n        self.assertEqual(message.message_method, stun.Method.BINDING)\n        self.assertEqual(message.message_class, stun.Class.REQUEST)\n        self.assertEqual(message.transaction_id, b\"wxaNbAdXjwG3\")\n        self.assertEqual(\n            message.attributes,\n            OrderedDict(\n                [\n                    (\"USERNAME\", \"AYeZ:sw7YvCSbcVex3bhi\"),\n                    (\"PRIORITY\", 1685987071),\n                    (\"SOFTWARE\", \"FreeSWITCH (-37-987c9b9 64bit)\"),\n                    (\"ICE-CONTROLLED\", 5491930053772927353),\n                    (\n                        \"MESSAGE-INTEGRITY\",\n                        unhexlify(\"1963108a4f764015a66b3fea0b1883dfde1436c8\"),\n                    ),\n                    (\"FINGERPRINT\", 3230414530),\n                ]\n            ),\n        )\n\n        self.assertEqual(bytes(message), data)\n\n    def test_binding_request_ice_controlled_bad_fingerprint(self):\n        data = read_message(\"binding_request_ice_controlled.bin\")[0:-1] + b\"z\"\n\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(data)\n        self.assertEqual(str(cm.exception), \"STUN message fingerprint does not match\")\n\n    def test_binding_request_ice_controlled_bad_integrity(self):\n        data = read_message(\"binding_request_ice_controlled.bin\")\n\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(data, integrity_key=b\"bogus-key\")\n        self.assertEqual(str(cm.exception), \"STUN message integrity does not match\")\n\n    def test_binding_request_ice_controlling(self):\n        data = read_message(\"binding_request_ice_controlling.bin\")\n\n        message = stun.parse_message(data)\n        self.assertEqual(message.message_method, stun.Method.BINDING)\n        self.assertEqual(message.message_class, stun.Class.REQUEST)\n        self.assertEqual(message.transaction_id, b\"JEwwUxjLWaa2\")\n        self.assertEqual(\n            message.attributes,\n            OrderedDict(\n                [\n                    (\"USERNAME\", \"sw7YvCSbcVex3bhi:AYeZ\"),\n                    (\"ICE-CONTROLLING\", 5943294521425135761),\n                    (\"USE-CANDIDATE\", None),\n                    (\"PRIORITY\", 1853759231),\n                    (\n                        \"MESSAGE-INTEGRITY\",\n                        unhexlify(\"c87b58eccbacdbc075d497ad0c965a82937ab587\"),\n                    ),\n                    (\"FINGERPRINT\", 1347006354),\n                ]\n            ),\n        )\n\n    def test_binding_response(self):\n        data = read_message(\"binding_response.bin\")\n\n        message = stun.parse_message(data)\n        self.assertEqual(message.message_method, stun.Method.BINDING)\n        self.assertEqual(message.message_class, stun.Class.RESPONSE)\n        self.assertEqual(message.transaction_id, b\"Nvfx3lU7FUBF\")\n        self.assertEqual(\n            message.attributes,\n            OrderedDict(\n                [\n                    (\"XOR-MAPPED-ADDRESS\", (\"80.200.136.90\", 53054)),\n                    (\"MAPPED-ADDRESS\", (\"80.200.136.90\", 53054)),\n                    (\"RESPONSE-ORIGIN\", (\"52.17.36.97\", 3478)),\n                    (\"OTHER-ADDRESS\", (\"52.17.36.97\", 3479)),\n                    (\"SOFTWARE\", \"Citrix-3.2.4.5 'Marshal West'\"),\n                ]\n            ),\n        )\n\n        self.assertEqual(bytes(message), data)\n\n    def test_message_body_length_mismatch(self):\n        data = read_message(\"binding_response.bin\") + b\"123\"\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(data)\n        self.assertEqual(str(cm.exception), \"STUN message length does not match\")\n\n    def test_message_shorter_than_header(self):\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(b\"123\")\n        self.assertEqual(str(cm.exception), \"STUN message length is less than 20 bytes\")\n\n    def test_message_with_unknown_method(self):\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(bytes(20))\n        self.assertEqual(str(cm.exception), \"0 is not a valid Method\")\n\n\nclass TransactionTest(unittest.TestCase):\n    def setUp(self):\n        stun.RETRY_MAX = 0\n        stun.RETRY_RTO = 0\n\n    def tearDown(self):\n        stun.RETRY_MAX = 6\n        stun.RETRY_RTO = 0.5\n\n    @asynctest\n    async def test_timeout(self):\n        class DummyProtocol:\n            def send_stun(self, message, address):\n                pass\n\n        request = stun.Message(\n            message_method=stun.Method.BINDING, message_class=stun.Class.REQUEST\n        )\n        transaction = stun.Transaction(request, (\"127.0.0.1\", 1234), DummyProtocol())\n\n        # timeout\n        with self.assertRaises(stun.TransactionTimeout):\n            await transaction.run()\n\n        # receive response after timeout\n        response = stun.Message(\n            message_method=stun.Method.BINDING, message_class=stun.Class.RESPONSE\n        )\n        transaction.response_received(response, (\"127.0.0.1\", 1234))\n"}
{"type": "test_file", "path": "tests/simple_agent_test.py", "content": "from dimos.robot.unitree.unitree_go2 import UnitreeGo2\nfrom dimos.robot.unitree.unitree_skills import MyUnitreeSkills\nfrom dimos.robot.unitree.unitree_ros_control import UnitreeROSControl\nfrom dimos.agents.agent import OpenAIAgent\nimport os\n\n# Initialize robot\nrobot = UnitreeGo2(ip=os.getenv('ROBOT_IP'),\n                  ros_control=UnitreeROSControl(),\n                  skills=MyUnitreeSkills())\n\n# Initialize agent\nagent = OpenAIAgent(\n            dev_name=\"UnitreeExecutionAgent\",\n            input_video_stream=robot.get_ros_video_stream(),\n            skills=robot.get_skills(),\n            system_query=\"Wiggle when you see a person! Jump when you see a person waving!\"\n        )\n\ntry:\n    input(\"Press ESC to exit...\")\nexcept KeyboardInterrupt:\n    print(\"\\nExiting...\")"}
{"type": "test_file", "path": "tests/test_planning_agent_web_interface.py", "content": "\"\"\"Planning agent demo with FastAPI server and robot integration.\n\nConnects a planning agent, execution agent, and robot with a web interface.\n\nEnvironment Variables:\n    OPENAI_API_KEY: Required. OpenAI API key.\n    ROBOT_IP: Required. IP address of the robot.\n    CONN_TYPE: Required. Connection method to the robot.\n    ROS_OUTPUT_DIR: Optional. Directory for ROS output files.\n\"\"\"\n\nimport sys\nimport os\n\n# Add the parent directory of 'demos' to the Python path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nprint(f\"Hi from {os.path.basename(__file__)}\\n\")\n\n# -----\n\nfrom textwrap import dedent\nimport threading\nimport time\nimport reactivex as rx\nimport reactivex.operators as ops\n\n# Local application imports\nfrom dimos.agents.agent import OpenAIAgent\nfrom dimos.agents.planning_agent import PlanningAgent\nfrom dimos.robot.unitree.unitree_go2 import UnitreeGo2\nfrom dimos.robot.unitree.unitree_skills import MyUnitreeSkills\nfrom dimos.utils.logging_config import logger\n# from dimos.web.fastapi_server import FastAPIServer\nfrom dimos.web.robot_web_interface import RobotWebInterface\nfrom dimos.utils.threadpool import make_single_thread_scheduler\n\ndef main():\n    # Get environment variables\n    robot_ip = os.getenv(\"ROBOT_IP\")\n    if not robot_ip:\n        raise ValueError(\"ROBOT_IP environment variable is required\")\n    connection_method = os.getenv(\"CONN_TYPE\") or 'webrtc'\n    output_dir = os.getenv(\"ROS_OUTPUT_DIR\",\n                           os.path.join(os.getcwd(), \"assets/output/ros\"))\n\n    # Initialize components as None for proper cleanup\n    robot = None\n    web_interface = None\n    planner = None\n    executor = None\n\n    try:\n        # Initialize robot\n        logger.info(\"Initializing Unitree Robot\")\n        robot = UnitreeGo2(ip=robot_ip,\n                           connection_method=connection_method,\n                           output_dir=output_dir,\n                           mock_connection=False,\n                           skills=MyUnitreeSkills())\n        # Set up video stream\n        logger.info(\"Starting video stream\")\n        video_stream = robot.get_ros_video_stream()\n\n        # Initialize robot skills\n        logger.info(\"Initializing robot skills\")\n\n        # Create subjects for planner and executor responses\n        logger.info(\"Creating response streams\")\n        planner_response_subject = rx.subject.Subject()\n        planner_response_stream = planner_response_subject.pipe(ops.share())\n        \n        executor_response_subject = rx.subject.Subject()\n        executor_response_stream = executor_response_subject.pipe(ops.share())\n        \n        # Web interface mode with FastAPI server\n        logger.info(\"Initializing FastAPI server\")\n        streams = {\"unitree_video\": video_stream}\n        text_streams = {\n            \"planner_responses\": planner_response_stream,\n            \"executor_responses\": executor_response_stream,\n        }\n        \n        web_interface = RobotWebInterface(\n            port=5555, text_streams=text_streams, **streams)\n\n        logger.info(\"Starting planning agent with web interface\")\n        planner = PlanningAgent(\n            dev_name=\"TaskPlanner\",\n            model_name=\"gpt-4o\",\n            input_query_stream=web_interface.query_stream,\n            skills=robot.get_skills()\n        )\n    \n        # Get planner's response observable\n        logger.info(\"Setting up agent response streams\")\n        planner_responses = planner.get_response_observable()\n        \n        # Connect planner to its subject\n        planner_responses.subscribe(\n            lambda x: planner_response_subject.on_next(x)\n        )\n\n        planner_responses.subscribe(\n            on_next=lambda x: logger.info(f\"Planner response: {x}\"),\n            on_error=lambda e: logger.error(f\"Planner error: {e}\"),\n            on_completed=lambda: logger.info(\"Planner completed\")\n        )\n        \n        # Initialize execution agent with robot skills\n        logger.info(\"Starting execution agent\")\n        system_query=dedent(\n            \"\"\"\n            You are a robot execution agent that can execute tasks on a virtual\n            robot. The sole text you will be given is the task to execute.\n            You will be given a list of skills that you can use to execute the task.\n            ONLY OUTPUT THE SKILLS TO EXECUTE, NOTHING ELSE.\n            \"\"\"\n        )\n        executor = OpenAIAgent(\n            dev_name=\"StepExecutor\",\n            input_query_stream=planner_responses,\n            output_dir=output_dir,\n            skills=robot.get_skills(),\n            system_query=system_query,\n            pool_scheduler=make_single_thread_scheduler()\n        )\n\n        # Get executor's response observable\n        executor_responses = executor.get_response_observable()\n\n        # Subscribe to responses for logging\n        executor_responses.subscribe(\n            on_next=lambda x: logger.info(f\"Executor response: {x}\"),\n            on_error=lambda e: logger.error(f\"Executor error: {e}\"),\n            on_completed=lambda: logger.info(\"Executor completed\")\n        )\n        \n        # Connect executor to its subject\n        executor_responses.subscribe(\n            lambda x: executor_response_subject.on_next(x)\n        )\n\n        # Start web server (blocking call)\n        logger.info(\"Starting FastAPI server\")\n        web_interface.run()\n\n    except KeyboardInterrupt:\n        print(\"Stopping demo...\")\n    except Exception as e:\n        logger.error(f\"Error: {e}\")\n        return 1\n    finally:\n        # Clean up all components\n        logger.info(\"Cleaning up components\")\n        if executor:\n            executor.dispose_all()\n        if planner:\n            planner.dispose_all()\n        if web_interface:\n            web_interface.dispose_all()\n        if robot:\n            robot.cleanup()\n        # Halt execution forever\n        while True:\n            time.sleep(1)\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n\n# Example Task: Move the robot forward by 1 meter, then turn 90 degrees clockwise, then move backward by 1 meter, then turn a random angle counterclockwise, then repeat this sequence 5 times.\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/turnserver.py", "content": "import argparse\nimport asyncio\nimport contextlib\nimport logging\nimport os\nimport ssl\nimport struct\nimport time\nfrom typing import Optional, Tuple\n\nfrom aioice import stun\nfrom aioice.ice import get_host_addresses\nfrom aioice.turn import (\n    DEFAULT_ALLOCATION_LIFETIME,\n    UDP_TRANSPORT,\n    TurnStreamMixin,\n    is_channel_data,\n    make_integrity_key,\n)\nfrom aioice.utils import random_string\n\nlogger = logging.getLogger(\"turn\")\n\nCHANNEL_RANGE = range(0x4000, 0x7FFF)\n\nROOT = os.path.dirname(__file__)\nCERT_FILE = os.path.join(ROOT, \"turnserver.crt\")\nKEY_FILE = os.path.join(ROOT, \"turnserver.key\")\n\n\ndef create_self_signed_cert(name=\"localhost\"):\n    from OpenSSL import crypto\n\n    # create key pair\n    key = crypto.PKey()\n    key.generate_key(crypto.TYPE_RSA, 2048)\n\n    # create self-signed certificate\n    cert = crypto.X509()\n    cert.get_subject().CN = name\n    cert.set_serial_number(1000)\n    cert.gmtime_adj_notBefore(0)\n    cert.gmtime_adj_notAfter(10 * 365 * 86400)\n    cert.set_issuer(cert.get_subject())\n    cert.set_pubkey(key)\n    cert.sign(key, \"sha1\")\n\n    with open(CERT_FILE, \"wb\") as fp:\n        fp.write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert))\n    with open(KEY_FILE, \"wb\") as fp:\n        fp.write(crypto.dump_privatekey(crypto.FILETYPE_PEM, key))\n\n\nclass Allocation(asyncio.DatagramProtocol):\n    def __init__(self, client_address, client_protocol, expiry, username):\n        self.channel_to_peer = {}\n        self.peer_to_channel = {}\n\n        self.client_address = client_address\n        self.client_protocol = client_protocol\n        self.expiry = expiry\n        self.username = username\n\n    def connection_made(self, transport):\n        self.relayed_address = transport.get_extra_info(\"sockname\")\n        self.transport = transport\n\n    def datagram_received(self, data, addr):\n        \"\"\"\n        Relay data from peer to client.\n        \"\"\"\n        channel = self.peer_to_channel.get(addr)\n        if channel:\n            self.client_protocol._send(\n                struct.pack(\"!HH\", channel, len(data)) + data, self.client_address\n            )\n\n\nclass TurnServerMixin:\n    def __init__(self, server):\n        self.server = server\n\n    def connection_made(self, transport):\n        self.transport = transport\n\n    def datagram_received(self, data, addr):\n        # demultiplex channel data\n        if len(data) >= 4 and is_channel_data(data):\n            channel, length = struct.unpack(\"!HH\", data[0:4])\n            allocation = self.server.allocations.get((self, addr))\n\n            if len(data) >= length + 4 and allocation:\n                peer_address = allocation.channel_to_peer.get(channel)\n                if peer_address:\n                    payload = data[4 : 4 + length]\n                    allocation.transport.sendto(payload, peer_address)\n\n            return\n\n        try:\n            message = stun.parse_message(data)\n        except ValueError:\n            return\n        logger.debug(\"< %s %s\", addr, message)\n\n        assert message.message_class == stun.Class.REQUEST\n\n        if message.message_method == stun.Method.BINDING:\n            response = self.handle_binding(message, addr)\n            self.send_stun(response, addr)\n            return\n\n        # generate failure for test purposes\n        if self.server.simulated_failure:\n            response = self.error_response(message, *self.server.simulated_failure)\n            self.server.simulated_failure = None\n            self.send_stun(response, addr)\n            return\n\n        if \"USERNAME\" not in message.attributes:\n            response = self.error_response(message, 401, \"Unauthorized\")\n            response.attributes[\"NONCE\"] = random_string(16).encode(\"ascii\")\n            response.attributes[\"REALM\"] = self.server.realm\n            self.send_stun(response, addr)\n            return\n\n        # check credentials\n        username = message.attributes[\"USERNAME\"]\n        password = self.server.users[username]\n        integrity_key = make_integrity_key(username, self.server.realm, password)\n        try:\n            stun.parse_message(data, integrity_key=integrity_key)\n        except ValueError:\n            return\n\n        if message.message_method == stun.Method.ALLOCATE:\n            asyncio.create_task(self.handle_allocate(message, addr, integrity_key))\n            return\n        elif message.message_method == stun.Method.REFRESH:\n            response = self.handle_refresh(message, addr)\n        elif message.message_method == stun.Method.CHANNEL_BIND:\n            response = self.handle_channel_bind(message, addr)\n        else:\n            response = self.error_response(\n                message, 400, \"Unsupported STUN request method\"\n            )\n\n        response.add_message_integrity(integrity_key)\n        self.send_stun(response, addr)\n\n    async def handle_allocate(self, message, addr, integrity_key):\n        key = (self, addr)\n        if key in self.server.allocations:\n            response = self.error_response(message, 437, \"Allocation already exists\")\n        elif \"REQUESTED-TRANSPORT\" not in message.attributes:\n            response = self.error_response(\n                message, 400, \"Missing REQUESTED-TRANSPORT attribute\"\n            )\n        elif message.attributes[\"REQUESTED-TRANSPORT\"] != UDP_TRANSPORT:\n            response = self.error_response(\n                message, 442, \"Unsupported transport protocol\"\n            )\n        else:\n            lifetime = message.attributes.get(\"LIFETIME\", DEFAULT_ALLOCATION_LIFETIME)\n            lifetime = min(lifetime, self.server.maximum_lifetime)\n\n            # create allocation\n            loop = asyncio.get_event_loop()\n            _, allocation = await loop.create_datagram_endpoint(\n                lambda: Allocation(\n                    client_address=addr,\n                    client_protocol=self,\n                    expiry=time.time() + lifetime,\n                    username=message.attributes[\"USERNAME\"],\n                ),\n                local_addr=(\"127.0.0.1\", 0),\n            )\n            self.server.allocations[key] = allocation\n\n            logger.info(\"Allocation created %s\", allocation.relayed_address)\n\n            # build response\n            response = stun.Message(\n                message_method=message.message_method,\n                message_class=stun.Class.RESPONSE,\n                transaction_id=message.transaction_id,\n            )\n            response.attributes[\"LIFETIME\"] = lifetime\n            response.attributes[\"XOR-MAPPED-ADDRESS\"] = addr\n            response.attributes[\"XOR-RELAYED-ADDRESS\"] = allocation.relayed_address\n\n        # send response\n        response.add_message_integrity(integrity_key)\n        self.send_stun(response, addr)\n\n    def handle_binding(self, message, addr):\n        response = stun.Message(\n            message_method=message.message_method,\n            message_class=stun.Class.RESPONSE,\n            transaction_id=message.transaction_id,\n        )\n        response.attributes[\"XOR-MAPPED-ADDRESS\"] = addr\n        return response\n\n    def handle_channel_bind(self, message, addr):\n        try:\n            key = (self, addr)\n            allocation = self.server.allocations[key]\n        except KeyError:\n            return self.error_response(message, 437, \"Allocation does not exist\")\n\n        if message.attributes[\"USERNAME\"] != allocation.username:\n            return self.error_response(message, 441, \"Wrong credentials\")\n\n        for attr in [\"CHANNEL-NUMBER\", \"XOR-PEER-ADDRESS\"]:\n            if attr not in message.attributes:\n                return self.error_response(message, 400, \"Missing %s attribute\" % attr)\n\n        channel = message.attributes[\"CHANNEL-NUMBER\"]\n        peer_address = message.attributes[\"XOR-PEER-ADDRESS\"]\n        if channel not in CHANNEL_RANGE:\n            return self.error_response(\n                message, 400, \"Channel number is outside valid range\"\n            )\n\n        if allocation.channel_to_peer.get(channel) not in [None, peer_address]:\n            return self.error_response(\n                message, 400, \"Channel is already bound to another peer\"\n            )\n        if allocation.peer_to_channel.get(peer_address) not in [None, channel]:\n            return self.error_response(\n                message, 400, \"Peer is already bound to another channel\"\n            )\n\n        # register channel\n        allocation.channel_to_peer[channel] = peer_address\n        allocation.peer_to_channel[peer_address] = channel\n\n        # build response\n        response = stun.Message(\n            message_method=message.message_method,\n            message_class=stun.Class.RESPONSE,\n            transaction_id=message.transaction_id,\n        )\n        return response\n\n    def handle_refresh(self, message, addr):\n        try:\n            key = (self, addr)\n            allocation = self.server.allocations[key]\n        except KeyError:\n            return self.error_response(message, 437, \"Allocation does not exist\")\n\n        if message.attributes[\"USERNAME\"] != allocation.username:\n            return self.error_response(message, 441, \"Wrong credentials\")\n\n        if \"LIFETIME\" not in message.attributes:\n            return self.error_response(message, 400, \"Missing LIFETIME attribute\")\n\n        # refresh allocation\n        lifetime = min(message.attributes[\"LIFETIME\"], self.server.maximum_lifetime)\n        if lifetime:\n            logger.info(\"Allocation refreshed %s\", allocation.relayed_address)\n            allocation.expiry = time.time() + lifetime\n        else:\n            logger.info(\"Allocation deleted %s\", allocation.relayed_address)\n            self.server._remove_allocation(key)\n\n        # build response\n        response = stun.Message(\n            message_method=message.message_method,\n            message_class=stun.Class.RESPONSE,\n            transaction_id=message.transaction_id,\n        )\n        response.attributes[\"LIFETIME\"] = lifetime\n        return response\n\n    def error_response(self, request, code, message):\n        \"\"\"\n        Build an error response for the given request.\n        \"\"\"\n        response = stun.Message(\n            message_method=request.message_method,\n            message_class=stun.Class.ERROR,\n            transaction_id=request.transaction_id,\n        )\n        response.attributes[\"ERROR-CODE\"] = (code, message)\n        return response\n\n    def send_stun(self, message, addr):\n        logger.debug(\"> %s %s\", addr, message)\n        self._send(bytes(message), addr)\n\n\nclass TurnServerTcpProtocol(TurnServerMixin, TurnStreamMixin, asyncio.Protocol):\n    def _send(self, data, addr):\n        self.transport.write(self._padded(data))\n\n\nclass TurnServerUdpProtocol(TurnServerMixin, asyncio.DatagramProtocol):\n    def _send(self, data, addr):\n        self.transport.sendto(data, addr)\n\n\nclass TurnServer:\n    \"\"\"\n    STUN / TURN server.\n    \"\"\"\n\n    def __init__(self, realm=\"test\", users={}):\n        self.allocations = {}\n        self.maximum_lifetime = 3600\n        self.realm = realm\n        self.simulated_failure: Optional[Tuple[int, str]] = None\n        self.users = users\n\n        self._expire_task = None\n\n    async def close(self):\n        # stop expiry loop\n        if self._expire_task is not None:\n            self._expire_task.cancel()\n\n        # close allocations\n        for key in list(self.allocations.keys()):\n            self._remove_allocation(key)\n\n        # shutdown servers\n        self.tcp_server.close()\n        self.tls_server.close()\n        self.udp_server.transport.close()\n        await asyncio.gather(\n            self.tcp_server.wait_closed(), self.tls_server.wait_closed()\n        )\n\n    async def listen(self, port=0, tls_port=0):\n        loop = asyncio.get_event_loop()\n        hostaddr = get_host_addresses(use_ipv4=True, use_ipv6=False)[0]\n\n        # listen for TCP\n        self.tcp_server = await loop.create_server(\n            lambda: TurnServerTcpProtocol(server=self), host=hostaddr, port=port\n        )\n        self.tcp_address = self.tcp_server.sockets[0].getsockname()\n        logger.info(\"Listening for TCP on %s\", self.tcp_address)\n\n        # listen for UDP\n        transport, self.udp_server = await loop.create_datagram_endpoint(\n            lambda: TurnServerUdpProtocol(server=self), local_addr=(hostaddr, port)\n        )\n        self.udp_address = transport.get_extra_info(\"sockname\")\n        logger.info(\"Listening for UDP on %s\", self.udp_address)\n\n        # listen for TLS\n        ssl_context = ssl.SSLContext(protocol=ssl.PROTOCOL_TLS_SERVER)\n        ssl_context.load_cert_chain(CERT_FILE, KEY_FILE)\n        self.tls_server = await loop.create_server(\n            lambda: TurnServerTcpProtocol(server=self),\n            host=hostaddr,\n            port=tls_port,\n            ssl=ssl_context,\n        )\n        self.tls_address = self.tls_server.sockets[0].getsockname()\n        logger.info(\"Listening for TLS on %s\", self.tls_address)\n\n        # start expiry loop\n        self._expire_task = asyncio.create_task(self._expire_allocations())\n\n    async def _expire_allocations(self):\n        while True:\n            now = time.time()\n            for key, allocation in list(self.allocations.items()):\n                if allocation.expiry < now:\n                    logger.info(\"Allocation expired %s\", allocation.relayed_address)\n                    self.server._remove_allocation(key)\n\n            await asyncio.sleep(1)\n\n    def _remove_allocation(self, key):\n        allocation = self.allocations.pop(key)\n        allocation.transport.close()\n\n\n@contextlib.asynccontextmanager\nasync def run_turn_server(**kwargs):\n    server = TurnServer(**kwargs)\n    await server.listen()\n    try:\n        yield server\n    finally:\n        await server.close()\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"STUN / TURN server\")\n    parser.add_argument(\"--verbose\", \"-v\", action=\"count\")\n    args = parser.parse_args()\n\n    if args.verbose:\n        logging.basicConfig(level=logging.DEBUG)\n\n    srv = TurnServer(realm=\"test\", users={\"foo\": \"bar\"})\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(srv.listen(port=3478, tls_port=5349))\n    loop.run_forever()\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/test_candidate.py", "content": "import unittest\n\nfrom aioice import Candidate\n\n\nclass CandidateTest(unittest.TestCase):\n    def test_can_pair_ipv4(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 12345 typ host generation 0\"\n        )\n        self.assertTrue(candidate_a.can_pair_with(candidate_b))\n\n    def test_can_pair_ipv4_case_insensitive(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 UDP 659136 1.2.3.4 12345 typ host generation 0\"\n        )\n        self.assertTrue(candidate_a.can_pair_with(candidate_b))\n\n    def test_can_pair_ipv6(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 2a02:0db8:85a3:0000:0000:8a2e:0370:7334 31102\"\n            \" typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 2a02:0db8:85a3:0000:0000:8a2e:0370:7334 12345\"\n            \" typ host generation 0\"\n        )\n        self.assertTrue(candidate_a.can_pair_with(candidate_b))\n\n    def test_cannot_pair_ipv4_ipv6(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 2a02:0db8:85a3:0000:0000:8a2e:0370:7334 12345\"\n            \" typ host generation 0\"\n        )\n        self.assertFalse(candidate_a.can_pair_with(candidate_b))\n\n    def test_cannot_pair_different_components(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 2 udp 659136 1.2.3.4 12345 typ host generation 0\"\n        )\n        self.assertFalse(candidate_a.can_pair_with(candidate_b))\n\n    def test_cannot_pair_different_transports(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 tcp 659136 1.2.3.4 12345 typ host generation 0 tcptype active\"\n        )\n        self.assertFalse(candidate_a.can_pair_with(candidate_b))\n\n    def test_from_sdp_udp(self):\n        candidate = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        self.assertEqual(candidate.foundation, \"6815297761\")\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"udp\")\n        self.assertEqual(candidate.priority, 659136)\n        self.assertEqual(candidate.host, \"1.2.3.4\")\n        self.assertEqual(candidate.port, 31102)\n        self.assertEqual(candidate.type, \"host\")\n        self.assertEqual(candidate.generation, 0)\n\n        self.assertEqual(\n            candidate.to_sdp(),\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\",\n        )\n\n    def test_from_sdp_udp_srflx(self):\n        candidate = Candidate.from_sdp(\n            \"1 1 UDP 1686052863 1.2.3.4 42705 typ srflx raddr 192.168.1.101 rport 42705\"\n        )\n        self.assertEqual(candidate.foundation, \"1\")\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"UDP\")\n        self.assertEqual(candidate.priority, 1686052863)\n        self.assertEqual(candidate.host, \"1.2.3.4\")\n        self.assertEqual(candidate.port, 42705)\n        self.assertEqual(candidate.type, \"srflx\")\n        self.assertEqual(candidate.related_address, \"192.168.1.101\")\n        self.assertEqual(candidate.related_port, 42705)\n        self.assertEqual(candidate.generation, None)\n\n        self.assertEqual(\n            candidate.to_sdp(),\n            \"1 1 UDP 1686052863 1.2.3.4 42705 typ srflx raddr 192.168.1.101 \"\n            \"rport 42705\",\n        )\n\n    def test_from_sdp_tcp(self):\n        candidate = Candidate.from_sdp(\n            \"1936595596 1 tcp 1518214911 1.2.3.4 9 typ host \"\n            \"tcptype active generation 0 network-id 1 network-cost 10\"\n        )\n        self.assertEqual(candidate.foundation, \"1936595596\")\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"tcp\")\n        self.assertEqual(candidate.priority, 1518214911)\n        self.assertEqual(candidate.host, \"1.2.3.4\")\n        self.assertEqual(candidate.port, 9)\n        self.assertEqual(candidate.type, \"host\")\n        self.assertEqual(candidate.tcptype, \"active\")\n        self.assertEqual(candidate.generation, 0)\n\n        self.assertEqual(\n            candidate.to_sdp(),\n            \"1936595596 1 tcp 1518214911 1.2.3.4 9 typ host tcptype active \"\n            \"generation 0\",\n        )\n\n    def test_from_sdp_no_generation(self):\n        candidate = Candidate.from_sdp(\"6815297761 1 udp 659136 1.2.3.4 31102 typ host\")\n\n        self.assertEqual(candidate.foundation, \"6815297761\")\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"udp\")\n        self.assertEqual(candidate.priority, 659136)\n        self.assertEqual(candidate.host, \"1.2.3.4\")\n        self.assertEqual(candidate.port, 31102)\n        self.assertEqual(candidate.type, \"host\")\n        self.assertEqual(candidate.generation, None)\n\n        self.assertEqual(\n            candidate.to_sdp(), \"6815297761 1 udp 659136 1.2.3.4 31102 typ host\"\n        )\n\n    def test_from_sdp_truncated(self):\n        with self.assertRaises(ValueError):\n            Candidate.from_sdp(\"6815297761 1 udp 659136 1.2.3.4 31102 typ\")\n\n    def test_repr(self):\n        candidate = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        self.assertEqual(\n            repr(candidate),\n            \"Candidate(6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0)\",\n        )\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/turnserver.py", "content": "import argparse\nimport asyncio\nimport contextlib\nimport logging\nimport os\nimport ssl\nimport struct\nimport time\nfrom typing import Optional, Tuple\n\nfrom aioice import stun\nfrom aioice.ice import get_host_addresses\nfrom aioice.turn import (\n    DEFAULT_ALLOCATION_LIFETIME,\n    UDP_TRANSPORT,\n    TurnStreamMixin,\n    is_channel_data,\n    make_integrity_key,\n)\nfrom aioice.utils import random_string\n\nlogger = logging.getLogger(\"turn\")\n\nCHANNEL_RANGE = range(0x4000, 0x7FFF)\n\nROOT = os.path.dirname(__file__)\nCERT_FILE = os.path.join(ROOT, \"turnserver.crt\")\nKEY_FILE = os.path.join(ROOT, \"turnserver.key\")\n\n\ndef create_self_signed_cert(name=\"localhost\"):\n    from OpenSSL import crypto\n\n    # create key pair\n    key = crypto.PKey()\n    key.generate_key(crypto.TYPE_RSA, 2048)\n\n    # create self-signed certificate\n    cert = crypto.X509()\n    cert.get_subject().CN = name\n    cert.set_serial_number(1000)\n    cert.gmtime_adj_notBefore(0)\n    cert.gmtime_adj_notAfter(10 * 365 * 86400)\n    cert.set_issuer(cert.get_subject())\n    cert.set_pubkey(key)\n    cert.sign(key, \"sha1\")\n\n    with open(CERT_FILE, \"wb\") as fp:\n        fp.write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert))\n    with open(KEY_FILE, \"wb\") as fp:\n        fp.write(crypto.dump_privatekey(crypto.FILETYPE_PEM, key))\n\n\nclass Allocation(asyncio.DatagramProtocol):\n    def __init__(self, client_address, client_protocol, expiry, username):\n        self.channel_to_peer = {}\n        self.peer_to_channel = {}\n\n        self.client_address = client_address\n        self.client_protocol = client_protocol\n        self.expiry = expiry\n        self.username = username\n\n    def connection_made(self, transport):\n        self.relayed_address = transport.get_extra_info(\"sockname\")\n        self.transport = transport\n\n    def datagram_received(self, data, addr):\n        \"\"\"\n        Relay data from peer to client.\n        \"\"\"\n        channel = self.peer_to_channel.get(addr)\n        if channel:\n            self.client_protocol._send(\n                struct.pack(\"!HH\", channel, len(data)) + data, self.client_address\n            )\n\n\nclass TurnServerMixin:\n    def __init__(self, server):\n        self.server = server\n\n    def connection_made(self, transport):\n        self.transport = transport\n\n    def datagram_received(self, data, addr):\n        # demultiplex channel data\n        if len(data) >= 4 and is_channel_data(data):\n            channel, length = struct.unpack(\"!HH\", data[0:4])\n            allocation = self.server.allocations.get((self, addr))\n\n            if len(data) >= length + 4 and allocation:\n                peer_address = allocation.channel_to_peer.get(channel)\n                if peer_address:\n                    payload = data[4 : 4 + length]\n                    allocation.transport.sendto(payload, peer_address)\n\n            return\n\n        try:\n            message = stun.parse_message(data)\n        except ValueError:\n            return\n        logger.debug(\"< %s %s\", addr, message)\n\n        assert message.message_class == stun.Class.REQUEST\n\n        if message.message_method == stun.Method.BINDING:\n            response = self.handle_binding(message, addr)\n            self.send_stun(response, addr)\n            return\n\n        # generate failure for test purposes\n        if self.server.simulated_failure:\n            response = self.error_response(message, *self.server.simulated_failure)\n            self.server.simulated_failure = None\n            self.send_stun(response, addr)\n            return\n\n        if \"USERNAME\" not in message.attributes:\n            response = self.error_response(message, 401, \"Unauthorized\")\n            response.attributes[\"NONCE\"] = random_string(16).encode(\"ascii\")\n            response.attributes[\"REALM\"] = self.server.realm\n            self.send_stun(response, addr)\n            return\n\n        # check credentials\n        username = message.attributes[\"USERNAME\"]\n        password = self.server.users[username]\n        integrity_key = make_integrity_key(username, self.server.realm, password)\n        try:\n            stun.parse_message(data, integrity_key=integrity_key)\n        except ValueError:\n            return\n\n        if message.message_method == stun.Method.ALLOCATE:\n            asyncio.create_task(self.handle_allocate(message, addr, integrity_key))\n            return\n        elif message.message_method == stun.Method.REFRESH:\n            response = self.handle_refresh(message, addr)\n        elif message.message_method == stun.Method.CHANNEL_BIND:\n            response = self.handle_channel_bind(message, addr)\n        else:\n            response = self.error_response(\n                message, 400, \"Unsupported STUN request method\"\n            )\n\n        response.add_message_integrity(integrity_key)\n        self.send_stun(response, addr)\n\n    async def handle_allocate(self, message, addr, integrity_key):\n        key = (self, addr)\n        if key in self.server.allocations:\n            response = self.error_response(message, 437, \"Allocation already exists\")\n        elif \"REQUESTED-TRANSPORT\" not in message.attributes:\n            response = self.error_response(\n                message, 400, \"Missing REQUESTED-TRANSPORT attribute\"\n            )\n        elif message.attributes[\"REQUESTED-TRANSPORT\"] != UDP_TRANSPORT:\n            response = self.error_response(\n                message, 442, \"Unsupported transport protocol\"\n            )\n        else:\n            lifetime = message.attributes.get(\"LIFETIME\", DEFAULT_ALLOCATION_LIFETIME)\n            lifetime = min(lifetime, self.server.maximum_lifetime)\n\n            # create allocation\n            loop = asyncio.get_event_loop()\n            _, allocation = await loop.create_datagram_endpoint(\n                lambda: Allocation(\n                    client_address=addr,\n                    client_protocol=self,\n                    expiry=time.time() + lifetime,\n                    username=message.attributes[\"USERNAME\"],\n                ),\n                local_addr=(\"127.0.0.1\", 0),\n            )\n            self.server.allocations[key] = allocation\n\n            logger.info(\"Allocation created %s\", allocation.relayed_address)\n\n            # build response\n            response = stun.Message(\n                message_method=message.message_method,\n                message_class=stun.Class.RESPONSE,\n                transaction_id=message.transaction_id,\n            )\n            response.attributes[\"LIFETIME\"] = lifetime\n            response.attributes[\"XOR-MAPPED-ADDRESS\"] = addr\n            response.attributes[\"XOR-RELAYED-ADDRESS\"] = allocation.relayed_address\n\n        # send response\n        response.add_message_integrity(integrity_key)\n        self.send_stun(response, addr)\n\n    def handle_binding(self, message, addr):\n        response = stun.Message(\n            message_method=message.message_method,\n            message_class=stun.Class.RESPONSE,\n            transaction_id=message.transaction_id,\n        )\n        response.attributes[\"XOR-MAPPED-ADDRESS\"] = addr\n        return response\n\n    def handle_channel_bind(self, message, addr):\n        try:\n            key = (self, addr)\n            allocation = self.server.allocations[key]\n        except KeyError:\n            return self.error_response(message, 437, \"Allocation does not exist\")\n\n        if message.attributes[\"USERNAME\"] != allocation.username:\n            return self.error_response(message, 441, \"Wrong credentials\")\n\n        for attr in [\"CHANNEL-NUMBER\", \"XOR-PEER-ADDRESS\"]:\n            if attr not in message.attributes:\n                return self.error_response(message, 400, \"Missing %s attribute\" % attr)\n\n        channel = message.attributes[\"CHANNEL-NUMBER\"]\n        peer_address = message.attributes[\"XOR-PEER-ADDRESS\"]\n        if channel not in CHANNEL_RANGE:\n            return self.error_response(\n                message, 400, \"Channel number is outside valid range\"\n            )\n\n        if allocation.channel_to_peer.get(channel) not in [None, peer_address]:\n            return self.error_response(\n                message, 400, \"Channel is already bound to another peer\"\n            )\n        if allocation.peer_to_channel.get(peer_address) not in [None, channel]:\n            return self.error_response(\n                message, 400, \"Peer is already bound to another channel\"\n            )\n\n        # register channel\n        allocation.channel_to_peer[channel] = peer_address\n        allocation.peer_to_channel[peer_address] = channel\n\n        # build response\n        response = stun.Message(\n            message_method=message.message_method,\n            message_class=stun.Class.RESPONSE,\n            transaction_id=message.transaction_id,\n        )\n        return response\n\n    def handle_refresh(self, message, addr):\n        try:\n            key = (self, addr)\n            allocation = self.server.allocations[key]\n        except KeyError:\n            return self.error_response(message, 437, \"Allocation does not exist\")\n\n        if message.attributes[\"USERNAME\"] != allocation.username:\n            return self.error_response(message, 441, \"Wrong credentials\")\n\n        if \"LIFETIME\" not in message.attributes:\n            return self.error_response(message, 400, \"Missing LIFETIME attribute\")\n\n        # refresh allocation\n        lifetime = min(message.attributes[\"LIFETIME\"], self.server.maximum_lifetime)\n        if lifetime:\n            logger.info(\"Allocation refreshed %s\", allocation.relayed_address)\n            allocation.expiry = time.time() + lifetime\n        else:\n            logger.info(\"Allocation deleted %s\", allocation.relayed_address)\n            self.server._remove_allocation(key)\n\n        # build response\n        response = stun.Message(\n            message_method=message.message_method,\n            message_class=stun.Class.RESPONSE,\n            transaction_id=message.transaction_id,\n        )\n        response.attributes[\"LIFETIME\"] = lifetime\n        return response\n\n    def error_response(self, request, code, message):\n        \"\"\"\n        Build an error response for the given request.\n        \"\"\"\n        response = stun.Message(\n            message_method=request.message_method,\n            message_class=stun.Class.ERROR,\n            transaction_id=request.transaction_id,\n        )\n        response.attributes[\"ERROR-CODE\"] = (code, message)\n        return response\n\n    def send_stun(self, message, addr):\n        logger.debug(\"> %s %s\", addr, message)\n        self._send(bytes(message), addr)\n\n\nclass TurnServerTcpProtocol(TurnServerMixin, TurnStreamMixin, asyncio.Protocol):\n    def _send(self, data, addr):\n        self.transport.write(self._padded(data))\n\n\nclass TurnServerUdpProtocol(TurnServerMixin, asyncio.DatagramProtocol):\n    def _send(self, data, addr):\n        self.transport.sendto(data, addr)\n\n\nclass TurnServer:\n    \"\"\"\n    STUN / TURN server.\n    \"\"\"\n\n    def __init__(self, realm=\"test\", users={}):\n        self.allocations = {}\n        self.maximum_lifetime = 3600\n        self.realm = realm\n        self.simulated_failure: Optional[Tuple[int, str]] = None\n        self.users = users\n\n        self._expire_task = None\n\n    async def close(self):\n        # stop expiry loop\n        if self._expire_task is not None:\n            self._expire_task.cancel()\n\n        # close allocations\n        for key in list(self.allocations.keys()):\n            self._remove_allocation(key)\n\n        # shutdown servers\n        self.tcp_server.close()\n        self.tls_server.close()\n        self.udp_server.transport.close()\n        await asyncio.gather(\n            self.tcp_server.wait_closed(), self.tls_server.wait_closed()\n        )\n\n    async def listen(self, port=0, tls_port=0):\n        loop = asyncio.get_event_loop()\n        hostaddr = get_host_addresses(use_ipv4=True, use_ipv6=False)[0]\n\n        # listen for TCP\n        self.tcp_server = await loop.create_server(\n            lambda: TurnServerTcpProtocol(server=self), host=hostaddr, port=port\n        )\n        self.tcp_address = self.tcp_server.sockets[0].getsockname()\n        logger.info(\"Listening for TCP on %s\", self.tcp_address)\n\n        # listen for UDP\n        transport, self.udp_server = await loop.create_datagram_endpoint(\n            lambda: TurnServerUdpProtocol(server=self), local_addr=(hostaddr, port)\n        )\n        self.udp_address = transport.get_extra_info(\"sockname\")\n        logger.info(\"Listening for UDP on %s\", self.udp_address)\n\n        # listen for TLS\n        ssl_context = ssl.SSLContext(protocol=ssl.PROTOCOL_TLS_SERVER)\n        ssl_context.load_cert_chain(CERT_FILE, KEY_FILE)\n        self.tls_server = await loop.create_server(\n            lambda: TurnServerTcpProtocol(server=self),\n            host=hostaddr,\n            port=tls_port,\n            ssl=ssl_context,\n        )\n        self.tls_address = self.tls_server.sockets[0].getsockname()\n        logger.info(\"Listening for TLS on %s\", self.tls_address)\n\n        # start expiry loop\n        self._expire_task = asyncio.create_task(self._expire_allocations())\n\n    async def _expire_allocations(self):\n        while True:\n            now = time.time()\n            for key, allocation in list(self.allocations.items()):\n                if allocation.expiry < now:\n                    logger.info(\"Allocation expired %s\", allocation.relayed_address)\n                    self.server._remove_allocation(key)\n\n            await asyncio.sleep(1)\n\n    def _remove_allocation(self, key):\n        allocation = self.allocations.pop(key)\n        allocation.transport.close()\n\n\n@contextlib.asynccontextmanager\nasync def run_turn_server(**kwargs):\n    server = TurnServer(**kwargs)\n    await server.listen()\n    try:\n        yield server\n    finally:\n        await server.close()\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"STUN / TURN server\")\n    parser.add_argument(\"--verbose\", \"-v\", action=\"count\")\n    args = parser.parse_args()\n\n    if args.verbose:\n        logging.basicConfig(level=logging.DEBUG)\n\n    srv = TurnServer(realm=\"test\", users={\"foo\": \"bar\"})\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(srv.listen(port=3478, tls_port=5349))\n    loop.run_forever()\n"}
{"type": "test_file", "path": "tests/run_go2_ros.py", "content": "import os\nimport time\nimport cv2\n\nfrom dimos.robot.unitree.unitree_go2 import UnitreeGo2, WebRTCConnectionMethod\nfrom dimos.robot.unitree.unitree_ros_control import UnitreeROSControl\n\ndef get_env_var(var_name, default=None, required=False):\n    \"\"\"Get environment variable with validation.\"\"\"\n    value = os.getenv(var_name, default)\n    if value == '':\n        value = default\n    if required and not value:\n        raise ValueError(f\"{var_name} environment variable is required\")\n    return value\n\n\nif __name__ == \"__main__\":\n    # Get configuration from environment variables\n    robot_ip = get_env_var(\"ROBOT_IP\")\n    connection_method = get_env_var(\"CONNECTION_METHOD\", \"LocalSTA\")\n    serial_number = get_env_var(\"SERIAL_NUMBER\", None)\n    output_dir = get_env_var(\"ROS_OUTPUT_DIR\",\n                             os.path.join(os.getcwd(), \"assets/output/ros\"))\n\n    # Ensure output directory exists\n    os.makedirs(output_dir, exist_ok=True)\n    print(f\"Ensuring output directory exists: {output_dir}\")\n\n    use_ros = True\n    use_webrtc = False\n    # Convert connection method string to enum\n    connection_method = getattr(WebRTCConnectionMethod, connection_method)\n\n    print(\"Initializing UnitreeGo2...\")\n    print(f\"Configuration:\")\n    print(f\"  IP: {robot_ip}\")\n    print(f\"  Connection Method: {connection_method}\")\n    print(f\"  Serial Number: {serial_number if serial_number else 'Not provided'}\")\n    print(f\"  Output Directory: {output_dir}\")\n\n    if use_ros:\n        ros_control = UnitreeROSControl(node_name=\"unitree_go2\", use_raw=True)\n    else:\n        ros_control = None\n\n    robot = UnitreeGo2(ip=robot_ip,\n                       connection_method=connection_method,\n                       serial_number=serial_number,\n                       output_dir=output_dir,\n                       ros_control=ros_control,\n                       use_ros=use_ros,\n                       use_webrtc=use_webrtc)\n    time.sleep(5)\n    try:\n\n        # Start perception\n        print(\"\\nStarting perception system...\")\n\n        # Get the processed stream\n        processed_stream = robot.get_ros_video_stream(fps=30)\n\n        # Create frame counter for unique filenames\n        frame_count = 0\n\n        # Create a subscriber to handle the frames\n        def handle_frame(frame):\n            global frame_count\n            frame_count += 1\n\n            try:\n                # Save frame to output directory if desired for debugging frame streaming\n                # MAKE SURE TO CHANGE OUTPUT DIR depending on if running in ROS or local\n                #frame_path = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n                #success = cv2.imwrite(frame_path, frame)\n                #print(f\"Frame #{frame_count} {'saved successfully' if success else 'failed to save'} to {frame_path}\")\n                pass\n\n            except Exception as e:\n                print(f\"Error in handle_frame: {e}\")\n                import traceback\n                print(traceback.format_exc())\n\n        def handle_error(error):\n            print(f\"Error in stream: {error}\")\n\n        def handle_completion():\n            print(\"Stream completed\")\n\n        # Subscribe to the stream\n        print(\"Creating subscription...\")\n        try:\n            subscription = processed_stream.subscribe(\n                on_next=handle_frame,\n                on_error=lambda e: print(f\"Subscription error: {e}\"),\n                on_completed=lambda: print(\"Subscription completed\"))\n            print(\"Subscription created successfully\")\n        except Exception as e:\n            print(f\"Error creating subscription: {e}\")\n\n        time.sleep(5)\n\n        # First put the robot in a good starting state\n        print(\"Running recovery stand...\")\n        robot.webrtc_req(api_id=1006)  # RecoveryStand\n\n        # Queue 20 WebRTC requests back-to-back\n        print(\"\\n🤖 QUEUEING WEBRTC COMMANDS BACK-TO-BACK FOR TESTING UnitreeGo2🤖\\n\")\n\n        # Dance 1\n        robot.webrtc_req(api_id=1033)  \n        print(\"Queued: WiggleHips (1033)\")\n\n        robot.reverse(distance=0.2, speed=0.5)\n        print(\"Queued: Reverse 0.5m at 0.5m/s\")\n\n        # Wiggle Hips\n        robot.webrtc_req(api_id=1033)  \n        print(\"Queued: WiggleHips (1033)\")\n\n        robot.move(distance=0.2, speed=0.5)\n        print(\"Queued: Move forward 1.0m at 0.5m/s\")\n\n        robot.webrtc_req(api_id=1017) \n        print(\"Queued: Stretch (1017)\")\n\n        robot.move(distance=0.2, speed=0.5)\n        print(\"Queued: Move forward 1.0m at 0.5m/s\")\n\n        robot.webrtc_req(api_id=1017)  \n        print(\"Queued: Stretch (1017)\")\n\n        robot.reverse(distance=0.2, speed=0.5)\n        print(\"Queued: Reverse 0.5m at 0.5m/s\")\n\n        robot.webrtc_req(api_id=1017)  \n        print(\"Queued: Stretch (1017)\")\\\n        \n        robot.spin(degrees=-90.0, speed=45.0)\n        print(\"Queued: Spin right 90 degrees at 45 degrees/s\")\n\n        robot.spin(degrees=90.0, speed=45.0)    \n        print(\"Queued: Spin left 90 degrees at 45 degrees/s\")\n\n        # To prevent termination\n        while True:\n            time.sleep(0.1)\n\n    except KeyboardInterrupt:\n        print(\"\\nStopping perception...\")\n        if 'subscription' in locals():\n            subscription.dispose()\n    except Exception as e:\n        print(f\"Error in main loop: {e}\")\n    finally:\n        # Cleanup\n        print(\"Cleaning up resources...\")\n        if 'subscription' in locals():\n            subscription.dispose()\n        del robot\n        print(\"Cleanup complete.\")\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/echoserver.py", "content": "import asyncio\nimport contextlib\n\n\nclass EchoServerProtocol(asyncio.DatagramProtocol):\n    def connection_made(self, transport):\n        self.transport = transport\n\n    def datagram_received(self, data, addr):\n        self.transport.sendto(data, addr)\n\n\nclass EchoServer:\n    async def close(self):\n        self.udp_server.transport.close()\n\n    async def listen(self, host=\"127.0.0.1\", port=0):\n        loop = asyncio.get_event_loop()\n\n        # listen for UDP\n        transport, self.udp_server = await loop.create_datagram_endpoint(\n            EchoServerProtocol, local_addr=(host, port)\n        )\n        self.udp_address = transport.get_extra_info(\"sockname\")\n\n\n@contextlib.asynccontextmanager\nasync def run_echo_server(**kwargs):\n    server = EchoServer(**kwargs)\n    await server.listen()\n    try:\n        yield server\n    finally:\n        await server.close()\n"}
{"type": "test_file", "path": "tests/test_webrtc_queue.py", "content": "#!/usr/bin/env python3\n\nimport time\nfrom dimos.robot.unitree.unitree_go2 import UnitreeGo2, WebRTCConnectionMethod\nimport os\nfrom dimos.robot.unitree.unitree_ros_control import UnitreeROSControl\n\ndef main():\n    \"\"\"Test WebRTC request queue with a sequence of 20 back-to-back commands\"\"\"\n    \n    print(\"Initializing UnitreeGo2...\")\n    \n    # Get configuration from environment variables\n    robot_ip = os.getenv(\"ROBOT_IP\")\n    connection_method = getattr(WebRTCConnectionMethod, \n                               os.getenv(\"CONNECTION_METHOD\", \"LocalSTA\"))\n    \n    # Initialize ROS control\n    ros_control = UnitreeROSControl(\n        node_name=\"unitree_go2_test\",\n        use_raw=True\n    )\n    \n    # Initialize robot\n    robot = UnitreeGo2(\n        ip=robot_ip,\n        connection_method=connection_method,\n        ros_control=ros_control,\n        use_ros=True,\n        use_webrtc=False  # Using queue instead of direct WebRTC\n    )\n    \n    # Wait for initialization\n    print(\"Waiting for robot to initialize...\")\n    time.sleep(5)\n    \n    # First put the robot in a good starting state\n    print(\"Running recovery stand...\")\n    robot.webrtc_req(api_id=1006)  # RecoveryStand\n    \n    # Queue 20 WebRTC requests back-to-back\n    print(\"\\n🤖 QUEUEING 20 COMMANDS BACK-TO-BACK 🤖\\n\")\n    \n    # Dance 1\n    robot.webrtc_req(api_id=1022)  # Dance1\n    print(\"Queued: Dance1 (1022)\")\n    \n    # Wiggle Hips\n    robot.webrtc_req(api_id=1033)  # WiggleHips\n    print(\"Queued: WiggleHips (1033)\")\n    \n    # Stretch\n    robot.webrtc_req(api_id=1017)  # Stretch\n    print(\"Queued: Stretch (1017)\")\n    \n    # Hello\n    robot.webrtc_req(api_id=1016)  # Hello\n    print(\"Queued: Hello (1016)\")\n    \n    # Dance 2\n    robot.webrtc_req(api_id=1023)  # Dance2\n    print(\"Queued: Dance2 (1023)\")\n    \n    # Wallow\n    robot.webrtc_req(api_id=1021)  # Wallow\n    print(\"Queued: Wallow (1021)\")\n    \n    # Scrape\n    robot.webrtc_req(api_id=1029)  # Scrape\n    print(\"Queued: Scrape (1029)\")\n    \n    # Finger Heart\n    robot.webrtc_req(api_id=1036)  # FingerHeart\n    print(\"Queued: FingerHeart (1036)\")\n    \n    # Recovery Stand (base position)\n    robot.webrtc_req(api_id=1006)  # RecoveryStand\n    print(\"Queued: RecoveryStand (1006)\")\n    \n    # Hello again\n    robot.webrtc_req(api_id=1016)  # Hello\n    print(\"Queued: Hello (1016)\")\n    \n    # Wiggle Hips again\n    robot.webrtc_req(api_id=1033)  # WiggleHips\n    print(\"Queued: WiggleHips (1033)\")\n    \n    # Front Pounce\n    robot.webrtc_req(api_id=1032)  # FrontPounce\n    print(\"Queued: FrontPounce (1032)\")\n    \n    # Dance 1 again\n    robot.webrtc_req(api_id=1022)  # Dance1\n    print(\"Queued: Dance1 (1022)\")\n    \n    # Stretch again\n    robot.webrtc_req(api_id=1017)  # Stretch\n    print(\"Queued: Stretch (1017)\")\n    \n    # Front Jump\n    robot.webrtc_req(api_id=1031)  # FrontJump\n    print(\"Queued: FrontJump (1031)\")\n    \n    # Finger Heart again\n    robot.webrtc_req(api_id=1036)  # FingerHeart\n    print(\"Queued: FingerHeart (1036)\")\n    \n    # Scrape again\n    robot.webrtc_req(api_id=1029)  # Scrape\n    print(\"Queued: Scrape (1029)\")\n    \n    # Hello one more time\n    robot.webrtc_req(api_id=1016)  # Hello\n    print(\"Queued: Hello (1016)\")\n    \n    # Dance 2 again\n    robot.webrtc_req(api_id=1023)  # Dance2\n    print(\"Queued: Dance2 (1023)\")\n    \n    # Finish with recovery stand\n    robot.webrtc_req(api_id=1006)  # RecoveryStand\n    print(\"Queued: RecoveryStand (1006)\")\n    \n    print(\"\\nAll 20 commands queued successfully! Watch the robot perform them in sequence.\")\n    print(\"The WebRTC queue manager will process them one by one when the robot is ready.\")\n    print(\"Press Ctrl+C to stop the program when you've seen enough.\\n\")\n    \n    try:\n        # Keep the program running so the queue can be processed\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        print(\"\\nStopping the test...\")\n    finally:\n        # Cleanup\n        print(\"Cleaning up resources...\")\n        robot.cleanup()\n        print(\"Test completed.\")\n\nif __name__ == \"__main__\":\n    main() "}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/test/test_copyright.py", "content": "# Copyright 2015 Open Source Robotics Foundation, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom ament_copyright.main import main\nimport pytest\n\n\n# Remove the `skip` decorator once the source file(s) have a copyright header\n@pytest.mark.skip(reason='No copyright header has been placed in the generated source file.')\n@pytest.mark.copyright\n@pytest.mark.linter\ndef test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/test_candidate.py", "content": "import unittest\n\nfrom aioice import Candidate\n\n\nclass CandidateTest(unittest.TestCase):\n    def test_can_pair_ipv4(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 12345 typ host generation 0\"\n        )\n        self.assertTrue(candidate_a.can_pair_with(candidate_b))\n\n    def test_can_pair_ipv4_case_insensitive(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 UDP 659136 1.2.3.4 12345 typ host generation 0\"\n        )\n        self.assertTrue(candidate_a.can_pair_with(candidate_b))\n\n    def test_can_pair_ipv6(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 2a02:0db8:85a3:0000:0000:8a2e:0370:7334 31102\"\n            \" typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 2a02:0db8:85a3:0000:0000:8a2e:0370:7334 12345\"\n            \" typ host generation 0\"\n        )\n        self.assertTrue(candidate_a.can_pair_with(candidate_b))\n\n    def test_cannot_pair_ipv4_ipv6(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 2a02:0db8:85a3:0000:0000:8a2e:0370:7334 12345\"\n            \" typ host generation 0\"\n        )\n        self.assertFalse(candidate_a.can_pair_with(candidate_b))\n\n    def test_cannot_pair_different_components(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 2 udp 659136 1.2.3.4 12345 typ host generation 0\"\n        )\n        self.assertFalse(candidate_a.can_pair_with(candidate_b))\n\n    def test_cannot_pair_different_transports(self):\n        candidate_a = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        candidate_b = Candidate.from_sdp(\n            \"6815297761 1 tcp 659136 1.2.3.4 12345 typ host generation 0 tcptype active\"\n        )\n        self.assertFalse(candidate_a.can_pair_with(candidate_b))\n\n    def test_from_sdp_udp(self):\n        candidate = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        self.assertEqual(candidate.foundation, \"6815297761\")\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"udp\")\n        self.assertEqual(candidate.priority, 659136)\n        self.assertEqual(candidate.host, \"1.2.3.4\")\n        self.assertEqual(candidate.port, 31102)\n        self.assertEqual(candidate.type, \"host\")\n        self.assertEqual(candidate.generation, 0)\n\n        self.assertEqual(\n            candidate.to_sdp(),\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\",\n        )\n\n    def test_from_sdp_udp_srflx(self):\n        candidate = Candidate.from_sdp(\n            \"1 1 UDP 1686052863 1.2.3.4 42705 typ srflx raddr 192.168.1.101 rport 42705\"\n        )\n        self.assertEqual(candidate.foundation, \"1\")\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"UDP\")\n        self.assertEqual(candidate.priority, 1686052863)\n        self.assertEqual(candidate.host, \"1.2.3.4\")\n        self.assertEqual(candidate.port, 42705)\n        self.assertEqual(candidate.type, \"srflx\")\n        self.assertEqual(candidate.related_address, \"192.168.1.101\")\n        self.assertEqual(candidate.related_port, 42705)\n        self.assertEqual(candidate.generation, None)\n\n        self.assertEqual(\n            candidate.to_sdp(),\n            \"1 1 UDP 1686052863 1.2.3.4 42705 typ srflx raddr 192.168.1.101 \"\n            \"rport 42705\",\n        )\n\n    def test_from_sdp_tcp(self):\n        candidate = Candidate.from_sdp(\n            \"1936595596 1 tcp 1518214911 1.2.3.4 9 typ host \"\n            \"tcptype active generation 0 network-id 1 network-cost 10\"\n        )\n        self.assertEqual(candidate.foundation, \"1936595596\")\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"tcp\")\n        self.assertEqual(candidate.priority, 1518214911)\n        self.assertEqual(candidate.host, \"1.2.3.4\")\n        self.assertEqual(candidate.port, 9)\n        self.assertEqual(candidate.type, \"host\")\n        self.assertEqual(candidate.tcptype, \"active\")\n        self.assertEqual(candidate.generation, 0)\n\n        self.assertEqual(\n            candidate.to_sdp(),\n            \"1936595596 1 tcp 1518214911 1.2.3.4 9 typ host tcptype active \"\n            \"generation 0\",\n        )\n\n    def test_from_sdp_no_generation(self):\n        candidate = Candidate.from_sdp(\"6815297761 1 udp 659136 1.2.3.4 31102 typ host\")\n\n        self.assertEqual(candidate.foundation, \"6815297761\")\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"udp\")\n        self.assertEqual(candidate.priority, 659136)\n        self.assertEqual(candidate.host, \"1.2.3.4\")\n        self.assertEqual(candidate.port, 31102)\n        self.assertEqual(candidate.type, \"host\")\n        self.assertEqual(candidate.generation, None)\n\n        self.assertEqual(\n            candidate.to_sdp(), \"6815297761 1 udp 659136 1.2.3.4 31102 typ host\"\n        )\n\n    def test_from_sdp_truncated(self):\n        with self.assertRaises(ValueError):\n            Candidate.from_sdp(\"6815297761 1 udp 659136 1.2.3.4 31102 typ\")\n\n    def test_repr(self):\n        candidate = Candidate.from_sdp(\n            \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n        )\n        self.assertEqual(\n            repr(candidate),\n            \"Candidate(6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0)\",\n        )\n"}
{"type": "test_file", "path": "tests/__init__.py", "content": "\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/test_ice.py", "content": "import asyncio\nimport functools\nimport os\nimport unittest\nfrom unittest import mock\n\nimport ifaddr\nfrom aioice import Candidate, TransportPolicy, ice, mdns, stun\n\nfrom .turnserver import run_turn_server\nfrom .utils import asynctest, invite_accept\n\nRUNNING_ON_CI = os.environ.get(\"GITHUB_ACTIONS\") == \"true\"\n\n\nasync def delay(coro):\n    await asyncio.sleep(1)\n    await coro()\n\n\nclass ProtocolMock:\n    local_candidate = Candidate(\n        foundation=\"some-foundation\",\n        component=1,\n        transport=\"udp\",\n        priority=1234,\n        host=\"1.2.3.4\",\n        port=1234,\n        type=\"host\",\n    )\n\n    sent_message = None\n\n    async def request(self, message, addr, integrity_key=None):\n        return (self.response_message, self.response_addr)\n\n    def send_stun(self, message, addr):\n        self.sent_message = message\n\n\nclass IceComponentTest(unittest.TestCase):\n    @asynctest\n    async def test_peer_reflexive(self):\n        connection = ice.Connection(ice_controlling=True)\n        connection.remote_password = \"remote-password\"\n        connection.remote_username = \"remote-username\"\n\n        protocol = ProtocolMock()\n        protocol.response_addr = (\"2.3.4.5\", 2345)\n        protocol.response_message = \"bad\"\n\n        request = stun.Message(\n            message_method=stun.Method.BINDING, message_class=stun.Class.REQUEST\n        )\n        request.attributes[\"PRIORITY\"] = 456789\n\n        connection.check_incoming(request, (\"2.3.4.5\", 2345), protocol)\n        self.assertIsNone(protocol.sent_message)\n\n        # check we have discovered a peer-reflexive candidate\n        self.assertEqual(len(connection.remote_candidates), 1)\n        candidate = connection.remote_candidates[0]\n        self.assertEqual(candidate.component, 1)\n        self.assertEqual(candidate.transport, \"udp\")\n        self.assertEqual(candidate.priority, 456789)\n        self.assertEqual(candidate.host, \"2.3.4.5\")\n        self.assertEqual(candidate.port, 2345)\n        self.assertEqual(candidate.type, \"prflx\")\n        self.assertEqual(candidate.generation, None)\n\n        # check a new pair was formed\n        self.assertEqual(len(connection._check_list), 1)\n        pair = connection._check_list[0]\n        self.assertEqual(pair.protocol, protocol)\n        self.assertEqual(pair.remote_candidate, candidate)\n\n        # check a triggered check was scheduled\n        self.assertIsNotNone(pair.task)\n        await pair.task\n\n    @asynctest\n    async def test_request_with_invalid_method(self):\n        connection = ice.Connection(ice_controlling=True)\n\n        protocol = ProtocolMock()\n\n        request = stun.Message(\n            message_method=stun.Method.ALLOCATE, message_class=stun.Class.REQUEST\n        )\n\n        connection.request_received(\n            request, (\"2.3.4.5\", 2345), protocol, bytes(request)\n        )\n        self.assertIsNotNone(protocol.sent_message)\n        self.assertEqual(protocol.sent_message.message_method, stun.Method.ALLOCATE)\n        self.assertEqual(protocol.sent_message.message_class, stun.Class.ERROR)\n        self.assertEqual(\n            protocol.sent_message.attributes[\"ERROR-CODE\"], (400, \"Bad Request\")\n        )\n\n    @asynctest\n    async def test_response_with_invalid_address(self):\n        connection = ice.Connection(ice_controlling=True)\n        connection.remote_password = \"remote-password\"\n        connection.remote_username = \"remote-username\"\n\n        protocol = ProtocolMock()\n        protocol.response_addr = (\"3.4.5.6\", 3456)\n        protocol.response_message = \"bad\"\n\n        pair = ice.CandidatePair(\n            protocol,\n            Candidate(\n                foundation=\"some-foundation\",\n                component=1,\n                transport=\"udp\",\n                priority=2345,\n                host=\"2.3.4.5\",\n                port=2345,\n                type=\"host\",\n            ),\n        )\n        self.assertEqual(\n            repr(pair), \"CandidatePair(('1.2.3.4', 1234) -> ('2.3.4.5', 2345))\"\n        )\n\n        await connection.check_start(pair)\n        self.assertEqual(pair.state, ice.CandidatePair.State.FAILED)\n\n\nclass IceConnectionTest(unittest.TestCase):\n    def assertCandidateTypes(self, conn, expected):\n        types = set([c.type for c in conn.local_candidates])\n        self.assertEqual(types, expected)\n\n    def tearDown(self):\n        ice.CONSENT_FAILURES = 6\n        ice.CONSENT_INTERVAL = 5\n        stun.RETRY_MAX = 6\n\n    @mock.patch(\"ifaddr.get_adapters\")\n    def test_get_host_addresses(self, mock_get_adapters):\n        mock_get_adapters.return_value = [\n            ifaddr.Adapter(\n                ips=[\n                    ifaddr.IP(ip=\"127.0.0.1\", network_prefix=8, nice_name=\"lo\"),\n                    ifaddr.IP(ip=(\"::1\", 0, 0), network_prefix=128, nice_name=\"lo\"),\n                ],\n                name=\"lo\",\n                nice_name=\"lo\",\n            ),\n            ifaddr.Adapter(\n                ips=[\n                    ifaddr.IP(\n                        ip=\"1.2.3.4\",\n                        network_prefix=24,\n                        nice_name=\"eth0\",\n                    ),\n                    ifaddr.IP(\n                        ip=(\"2a02:0db8:85a3:0000:0000:8a2e:0370:7334\", 0, 0),\n                        network_prefix=64,\n                        nice_name=\"eth0\",\n                    ),\n                    ifaddr.IP(\n                        ip=(\"fe80::1234:5678:9abc:def0\", 0, 2),\n                        network_prefix=64,\n                        nice_name=\"eth0\",\n                    ),\n                ],\n                name=\"eth0\",\n                nice_name=\"eth0\",\n            ),\n        ]\n\n        # IPv4 only\n        addresses = ice.get_host_addresses(use_ipv4=True, use_ipv6=False)\n        self.assertEqual(addresses, [\"1.2.3.4\"])\n\n        # IPv6 only\n        addresses = ice.get_host_addresses(use_ipv4=False, use_ipv6=True)\n        self.assertEqual(addresses, [\"2a02:0db8:85a3:0000:0000:8a2e:0370:7334\"])\n\n        # both\n        addresses = ice.get_host_addresses(use_ipv4=True, use_ipv6=True)\n        self.assertEqual(\n            addresses, [\"1.2.3.4\", \"2a02:0db8:85a3:0000:0000:8a2e:0370:7334\"]\n        )\n\n    @asynctest\n    async def test_close(self):\n        conn_a = ice.Connection(ice_controlling=True)\n\n        # close\n        event, _ = await asyncio.gather(conn_a.get_event(), conn_a.close())\n        self.assertTrue(isinstance(event, ice.ConnectionClosed))\n\n        # no more events\n        event = await conn_a.get_event()\n        self.assertIsNone(event)\n\n        # close again\n        await conn_a.close()\n\n    @asynctest\n    async def test_connect(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # there should be a default candidate for component 1\n        candidate = conn_a.get_default_candidate(1)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # there should not be a default candidate for component 2\n        candidate = conn_a.get_default_candidate(2)\n        self.assertIsNone(candidate)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_close(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # close while connecting\n        await conn_b.close()\n        done, pending = await asyncio.wait(\n            [\n                asyncio.create_task(conn_a.connect()),\n                asyncio.create_task(delay(conn_a.close)),\n            ]\n        )\n        for task in pending:\n            task.cancel()\n        self.assertEqual(len(done), 2)\n\n        exceptions = [x.exception() for x in done if x.exception()]\n        self.assertEqual(len(exceptions), 1)\n        self.assertTrue(isinstance(exceptions[0], ConnectionError))\n\n    @asynctest\n    async def test_connect_early_checks(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await conn_a.connect()\n        await asyncio.sleep(1)\n        await conn_b.connect()\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_early_checks_2(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # both sides gather local candidates and exchange credentials\n        await conn_a.gather_candidates()\n        await conn_b.gather_candidates()\n        conn_a.remote_username = conn_b.local_username\n        conn_a.remote_password = conn_b.local_password\n        conn_b.remote_username = conn_a.local_username\n        conn_b.remote_password = conn_a.local_password\n\n        async def connect_b():\n            # side B receives offer and connects\n            for candidate in conn_a.local_candidates:\n                await conn_b.add_remote_candidate(candidate)\n            await conn_b.add_remote_candidate(None)\n            await conn_b.connect()\n\n            # side A receives candidates\n            for candidate in conn_b.local_candidates:\n                await conn_a.add_remote_candidate(candidate)\n            await conn_a.add_remote_candidate(None)\n\n        # The sequence is:\n        # - side A starts connecting immediately, but has no candidates\n        # - side B receives candidates and connects\n        # - side A receives candidates, and connection completes\n        await asyncio.gather(conn_a.connect(), connect_b())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_two_components(self):\n        conn_a = ice.Connection(ice_controlling=True, components=2)\n        conn_b = ice.Connection(ice_controlling=False, components=2)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # there should be a default candidate for component 1\n        candidate = conn_a.get_default_candidate(1)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # there should be a default candidate for component 2\n        candidate = conn_a.get_default_candidate(2)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(conn_a._components, set([1, 2]))\n        self.assertEqual(conn_b._components, set([1, 2]))\n\n        # send data a -> b (component 1)\n        await conn_a.sendto(b\"howdee\", 1)\n        data, component = await conn_b.recvfrom()\n        self.assertEqual(data, b\"howdee\")\n        self.assertEqual(component, 1)\n\n        # send data b -> a (component 1)\n        await conn_b.sendto(b\"gotcha\", 1)\n        data, component = await conn_a.recvfrom()\n        self.assertEqual(data, b\"gotcha\")\n        self.assertEqual(component, 1)\n\n        # send data a -> b (component 2)\n        await conn_a.sendto(b\"howdee 2\", 2)\n        data, component = await conn_b.recvfrom()\n        self.assertEqual(data, b\"howdee 2\")\n        self.assertEqual(component, 2)\n\n        # send data b -> a (component 2)\n        await conn_b.sendto(b\"gotcha 2\", 2)\n        data, component = await conn_a.recvfrom()\n        self.assertEqual(data, b\"gotcha 2\")\n        self.assertEqual(component, 2)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_two_components_vs_one_component(self):\n        \"\"\"\n        It is possible that some of the local candidates won't get paired with\n        remote candidates, and some of the remote candidates won't get paired\n        with local candidates.  This can happen if one agent doesn't include\n        candidates for the all of the components for a media stream.  If this\n        happens, the number of components for that media stream is effectively\n        reduced, and considered to be equal to the minimum across both agents\n        of the maximum component ID provided by each agent across all\n        components for the media stream.\n        \"\"\"\n        conn_a = ice.Connection(ice_controlling=True, components=2)\n        conn_b = ice.Connection(ice_controlling=False, components=1)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n        self.assertTrue(len(conn_a.local_candidates) > 0)\n        for candidate in conn_a.local_candidates:\n            self.assertEqual(candidate.type, \"host\")\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(conn_a._components, set([1]))\n        self.assertEqual(conn_b._components, set([1]))\n\n        # send data a -> b (component 1)\n        await conn_a.sendto(b\"howdee\", 1)\n        data, component = await conn_b.recvfrom()\n        self.assertEqual(data, b\"howdee\")\n        self.assertEqual(component, 1)\n\n        # send data b -> a (component 1)\n        await conn_b.sendto(b\"gotcha\", 1)\n        data, component = await conn_a.recvfrom()\n        self.assertEqual(data, b\"gotcha\")\n        self.assertEqual(component, 1)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_to_ice_lite(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_a.remote_is_lite = True\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # there should be a default candidate for component 1\n        candidate = conn_a.get_default_candidate(1)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # there should not be a default candidate for component 2\n        candidate = conn_a.get_default_candidate(2)\n        self.assertIsNone(candidate)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_to_ice_lite_nomination_fails(self):\n        def mock_request_received(self, message, addr, protocol, raw_data):\n            if \"USE-CANDIDATE\" in message.attributes:\n                self.respond_error(message, addr, protocol, (500, \"Internal Error\"))\n            else:\n                self.real_request_received(message, addr, protocol, raw_data)\n\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_a.remote_is_lite = True\n        conn_b = ice.Connection(ice_controlling=False)\n        conn_b.real_request_received = conn_b.request_received\n        conn_b.request_received = functools.partial(mock_request_received, conn_b)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        with self.assertRaises(ConnectionError) as cm:\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(str(cm.exception), \"ICE negotiation failed\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @unittest.skipIf(RUNNING_ON_CI, \"CI lacks ipv6\")\n    @asynctest\n    async def test_connect_ipv6(self):\n        conn_a = ice.Connection(ice_controlling=True, use_ipv4=False, use_ipv6=True)\n        conn_b = ice.Connection(ice_controlling=False, use_ipv4=False, use_ipv6=True)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n        self.assertTrue(len(conn_a.local_candidates) > 0)\n        for candidate in conn_a.local_candidates:\n            self.assertEqual(candidate.type, \"host\")\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_reverse_order(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # introduce a delay so that B's checks complete before A's\n        await asyncio.gather(delay(conn_a.connect), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_invalid_password(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite\n        await conn_a.gather_candidates()\n        for candidate in conn_a.local_candidates:\n            await conn_b.add_remote_candidate(candidate)\n        await conn_b.add_remote_candidate(None)\n        conn_b.remote_username = conn_a.local_username\n        conn_b.remote_password = conn_a.local_password\n\n        # accept\n        await conn_b.gather_candidates()\n        for candidate in conn_b.local_candidates:\n            await conn_a.add_remote_candidate(candidate)\n        await conn_a.add_remote_candidate(None)\n        conn_a.remote_username = conn_b.local_username\n        conn_a.remote_password = \"wrong-password\"\n\n        # connect\n        done, pending = await asyncio.wait(\n            [\n                asyncio.create_task(conn_a.connect()),\n                asyncio.create_task(conn_b.connect()),\n            ],\n            return_when=asyncio.FIRST_EXCEPTION,\n        )\n        for task in pending:\n            task.cancel()\n        self.assertEqual(len(done), 1)\n        self.assertTrue(isinstance(done.pop().exception(), ConnectionError))\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_invalid_username(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite\n        await conn_a.gather_candidates()\n        for candidate in conn_a.local_candidates:\n            await conn_b.add_remote_candidate(candidate)\n        await conn_b.add_remote_candidate(None)\n        conn_b.remote_username = conn_a.local_username\n        conn_b.remote_password = conn_a.local_password\n\n        # accept\n        await conn_b.gather_candidates()\n        for candidate in conn_b.local_candidates:\n            await conn_a.add_remote_candidate(candidate)\n        await conn_a.add_remote_candidate(None)\n        conn_a.remote_username = \"wrong-username\"\n        conn_a.remote_password = conn_b.local_password\n\n        # connect\n        done, pending = await asyncio.wait(\n            [\n                asyncio.create_task(conn_a.connect()),\n                asyncio.create_task(conn_b.connect()),\n            ]\n        )\n        for task in pending:\n            task.cancel()\n        self.assertEqual(len(done), 2)\n        self.assertTrue(isinstance(done.pop().exception(), ConnectionError))\n        self.assertTrue(isinstance(done.pop().exception(), ConnectionError))\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_no_gather(self):\n        \"\"\"\n        If local candidates gathering was not performed, connect fails.\n        \"\"\"\n        conn = ice.Connection(ice_controlling=True)\n        await conn.add_remote_candidate(\n            Candidate.from_sdp(\n                \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n            )\n        )\n        await conn.add_remote_candidate(None)\n        conn.remote_username = \"foo\"\n        conn.remote_password = \"bar\"\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(\n            str(cm.exception), \"Local candidates gathering was not performed\"\n        )\n        await conn.close()\n\n    @asynctest\n    async def test_connect_no_local_candidates(self):\n        \"\"\"\n        If local candidates gathering yielded no candidates, connect fails.\n        \"\"\"\n        conn = ice.Connection(ice_controlling=True)\n        conn._local_candidates_end = True\n        await conn.add_remote_candidate(\n            Candidate.from_sdp(\n                \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n            )\n        )\n        await conn.add_remote_candidate(None)\n        conn.remote_username = \"foo\"\n        conn.remote_password = \"bar\"\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(str(cm.exception), \"ICE negotiation failed\")\n        await conn.close()\n\n    @asynctest\n    async def test_connect_no_remote_candidates(self):\n        \"\"\"\n        If no remote candidates were provided, connect fails.\n        \"\"\"\n        conn = ice.Connection(ice_controlling=True)\n        await conn.gather_candidates()\n        await conn.add_remote_candidate(None)\n        conn.remote_username = \"foo\"\n        conn.remote_password = \"bar\"\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(str(cm.exception), \"ICE negotiation failed\")\n        await conn.close()\n\n    @asynctest\n    async def test_connect_no_remote_credentials(self):\n        \"\"\"\n        If remote credentials have not been provided, connect fails.\n        \"\"\"\n        conn = ice.Connection(ice_controlling=True)\n        await conn.gather_candidates()\n        await conn.add_remote_candidate(\n            Candidate.from_sdp(\n                \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n            )\n        )\n        await conn.add_remote_candidate(None)\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(str(cm.exception), \"Remote username or password is missing\")\n        await conn.close()\n\n    @asynctest\n    async def test_connect_role_conflict_both_controlling(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=True)\n\n        # set tie breaker for a deterministic outcome\n        conn_a._tie_breaker = 1\n        conn_b._tie_breaker = 2\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertFalse(conn_a.ice_controlling)\n        self.assertTrue(conn_b.ice_controlling)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_role_conflict_both_controlled(self):\n        conn_a = ice.Connection(ice_controlling=False)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # set tie breaker for a deterministic outcome\n        conn_a._tie_breaker = 1\n        conn_b._tie_breaker = 2\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertFalse(conn_a.ice_controlling)\n        self.assertTrue(conn_b.ice_controlling)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_timeout(self):\n        # lower STUN retries\n        stun.RETRY_MAX = 1\n\n        conn = ice.Connection(ice_controlling=True)\n        await conn.gather_candidates()\n        await conn.add_remote_candidate(\n            Candidate.from_sdp(\n                \"6815297761 1 udp 659136 1.2.3.4 31102 typ host generation 0\"\n            )\n        )\n        await conn.add_remote_candidate(None)\n        conn.remote_username = \"foo\"\n        conn.remote_password = \"bar\"\n        with self.assertRaises(ConnectionError) as cm:\n            await conn.connect()\n        self.assertEqual(str(cm.exception), \"ICE negotiation failed\")\n        await conn.close()\n\n    @asynctest\n    async def test_connect_with_stun_server(self):\n        async with run_turn_server() as stun_server:\n            conn_a = ice.Connection(\n                ice_controlling=True, stun_server=stun_server.udp_address\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould have both host and server-reflexive candidates\n            self.assertCandidateTypes(conn_a, set([\"host\", \"srflx\"]))\n            self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n            # the default candidate should be server-reflexive\n            candidate = conn_a.get_default_candidate(1)\n            self.assertIsNotNone(candidate)\n            self.assertEqual(candidate.type, \"srflx\")\n            self.assertIsNotNone(candidate.related_address)\n            self.assertIsNotNone(candidate.related_port)\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_connect_with_stun_server_dns_lookup_error(self):\n        conn_a = ice.Connection(ice_controlling=True, stun_server=(\"invalid.\", 1234))\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we whould have only host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_connect_with_stun_server_timeout(self):\n        async with run_turn_server() as stun_server:\n            # immediately stop turn server\n            await stun_server.close()\n\n            conn_a = ice.Connection(\n                ice_controlling=True, stun_server=stun_server.udp_address\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould have only host candidates\n            self.assertCandidateTypes(conn_a, set([\"host\"]))\n            self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @unittest.skipIf(RUNNING_ON_CI, \"CI lacks ipv6\")\n    @asynctest\n    async def test_connect_with_stun_server_ipv6(self):\n        async with run_turn_server() as stun_server:\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                stun_server=stun_server.udp_address,\n                use_ipv4=False,\n                use_ipv6=True,\n            )\n            conn_b = ice.Connection(\n                ice_controlling=False, use_ipv4=False, use_ipv6=True\n            )\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we only want host candidates : no STUN for IPv6\n            self.assertTrue(len(conn_a.local_candidates) > 0)\n            for candidate in conn_a.local_candidates:\n                self.assertEqual(candidate.type, \"host\")\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_connect_with_turn_server_tcp(self):\n        async with run_turn_server(users={\"foo\": \"bar\"}) as turn_server:\n            # create connections\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                turn_server=turn_server.tcp_address,\n                turn_username=\"foo\",\n                turn_password=\"bar\",\n                turn_transport=\"tcp\",\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould have both host and relayed candidates\n            self.assertCandidateTypes(conn_a, set([\"host\", \"relay\"]))\n            self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n            # the default candidate should be relayed\n            candidate = conn_a.get_default_candidate(1)\n            self.assertIsNotNone(candidate)\n            self.assertEqual(candidate.type, \"relay\")\n            self.assertIsNotNone(candidate.related_address)\n            self.assertIsNotNone(candidate.related_port)\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_connect_with_turn_server_udp(self):\n        async with run_turn_server(users={\"foo\": \"bar\"}) as turn_server:\n            # create connections\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                turn_server=turn_server.udp_address,\n                turn_username=\"foo\",\n                turn_password=\"bar\",\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould have both host and relayed candidates\n            self.assertCandidateTypes(conn_a, set([\"host\", \"relay\"]))\n            self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n            # the default candidate should be relayed\n            candidate = conn_a.get_default_candidate(1)\n            self.assertIsNotNone(candidate)\n            self.assertEqual(candidate.type, \"relay\")\n            self.assertIsNotNone(candidate.related_address)\n            self.assertIsNotNone(candidate.related_port)\n\n            # connect\n            await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n            # send data a -> b\n            await conn_a.send(b\"howdee\")\n            data = await conn_b.recv()\n            self.assertEqual(data, b\"howdee\")\n\n            # send data b -> a\n            await conn_b.send(b\"gotcha\")\n            data = await conn_a.recv()\n            self.assertEqual(data, b\"gotcha\")\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_consent_expired(self):\n        # lower consent timer\n        ice.CONSENT_FAILURES = 1\n        ice.CONSENT_INTERVAL = 1\n\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(len(conn_a._nominated), 1)\n\n        # let consent expire\n        await conn_b.close()\n        await asyncio.sleep(2)\n        self.assertEqual(len(conn_a._nominated), 0)\n\n        # close\n        await conn_a.close()\n\n    @asynctest\n    async def test_consent_valid(self):\n        # lower consent timer\n        ice.CONSENT_FAILURES = 1\n        ice.CONSENT_INTERVAL = 1\n\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n        self.assertEqual(len(conn_a._nominated), 1)\n\n        # check consent\n        await asyncio.sleep(2)\n        self.assertEqual(len(conn_a._nominated), 1)\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_set_selected_pair(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # force selected pair\n        default_a = conn_a.get_default_candidate(1)\n        default_b = conn_a.get_default_candidate(1)\n        conn_a.set_selected_pair(1, default_a.foundation, default_b.foundation)\n        conn_b.set_selected_pair(1, default_b.foundation, default_a.foundation)\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n\n    @asynctest\n    async def test_recv_not_connected(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        with self.assertRaises(ConnectionError) as cm:\n            await conn_a.recv()\n        self.assertEqual(str(cm.exception), \"Cannot receive data, not connected\")\n\n    @asynctest\n    async def test_recv_connection_lost(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite / accept\n        await invite_accept(conn_a, conn_b)\n\n        # connect\n        await asyncio.gather(conn_a.connect(), conn_b.connect())\n\n        # disconnect while receiving\n        with self.assertRaises(ConnectionError) as cm:\n            await asyncio.gather(conn_a.recv(), delay(conn_a.close))\n        self.assertEqual(str(cm.exception), \"Connection lost while receiving data\")\n\n        # close\n        await conn_b.close()\n\n    @asynctest\n    async def test_send_not_connected(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        with self.assertRaises(ConnectionError) as cm:\n            await conn_a.send(b\"howdee\")\n        self.assertEqual(str(cm.exception), \"Cannot send data, not connected\")\n\n    @asynctest\n    async def test_add_remote_candidate(self):\n        conn_a = ice.Connection(ice_controlling=True)\n\n        remote_candidate = Candidate(\n            foundation=\"some-foundation\",\n            component=1,\n            transport=\"udp\",\n            priority=1234,\n            host=\"1.2.3.4\",\n            port=1234,\n            type=\"host\",\n        )\n\n        # add candidate\n        await conn_a.add_remote_candidate(remote_candidate)\n        self.assertEqual(len(conn_a.remote_candidates), 1)\n        self.assertEqual(conn_a.remote_candidates[0].host, \"1.2.3.4\")\n        self.assertEqual(conn_a._remote_candidates_end, False)\n\n        # end-of-candidates\n        await conn_a.add_remote_candidate(None)\n        self.assertEqual(len(conn_a.remote_candidates), 1)\n        self.assertEqual(conn_a._remote_candidates_end, True)\n\n        # try adding another candidate\n        with self.assertRaises(ValueError) as cm:\n            await conn_a.add_remote_candidate(remote_candidate)\n        self.assertEqual(\n            str(cm.exception), \"Cannot add remote candidate after end-of-candidates.\"\n        )\n        self.assertEqual(len(conn_a.remote_candidates), 1)\n        self.assertEqual(conn_a._remote_candidates_end, True)\n\n    @asynctest\n    async def test_add_remote_candidate_mdns_bad(self):\n        \"\"\"\n        Add an mDNS candidate which cannot be resolved.\n        \"\"\"\n        conn_a = ice.Connection(ice_controlling=True)\n\n        await conn_a.add_remote_candidate(\n            Candidate(\n                foundation=\"some-foundation\",\n                component=1,\n                transport=\"udp\",\n                priority=1234,\n                host=mdns.create_mdns_hostname(),\n                port=1234,\n                type=\"host\",\n            )\n        )\n        self.assertEqual(len(conn_a.remote_candidates), 0)\n        self.assertEqual(conn_a._remote_candidates_end, False)\n\n        # close\n        await conn_a.close()\n\n    @asynctest\n    async def test_add_remote_candidate_mdns_good(self):\n        \"\"\"\n        Add an mDNS candidate which can be resolved.\n        \"\"\"\n        hostname = mdns.create_mdns_hostname()\n        publisher = await mdns.create_mdns_protocol()\n        await publisher.publish(hostname, \"1.2.3.4\")\n\n        conn_a = ice.Connection(ice_controlling=True)\n\n        await conn_a.add_remote_candidate(\n            Candidate(\n                foundation=\"some-foundation\",\n                component=1,\n                transport=\"udp\",\n                priority=1234,\n                host=hostname,\n                port=1234,\n                type=\"host\",\n            )\n        )\n        self.assertEqual(len(conn_a.remote_candidates), 1)\n        self.assertEqual(conn_a.remote_candidates[0].host, \"1.2.3.4\")\n        self.assertEqual(conn_a._remote_candidates_end, False)\n\n        # close\n        await conn_a.close()\n        await publisher.close()\n\n    @asynctest\n    async def test_add_remote_candidate_unknown_type(self):\n        conn_a = ice.Connection(ice_controlling=True)\n\n        await conn_a.add_remote_candidate(\n            Candidate(\n                foundation=\"some-foundation\",\n                component=1,\n                transport=\"udp\",\n                priority=1234,\n                host=\"1.2.3.4\",\n                port=1234,\n                type=\"bogus\",\n            )\n        )\n        self.assertEqual(len(conn_a.remote_candidates), 0)\n        self.assertEqual(conn_a._remote_candidates_end, False)\n\n    @mock.patch(\"asyncio.base_events.BaseEventLoop.create_datagram_endpoint\")\n    @asynctest\n    async def test_gather_candidates_oserror(self, mock_create):\n        exc = OSError()\n        exc.errno = 99\n        exc.strerror = \"Cannot assign requested address\"\n        mock_create.side_effect = exc\n\n        conn = ice.Connection(ice_controlling=True)\n        await conn.gather_candidates()\n        self.assertEqual(conn.local_candidates, [])\n\n    @asynctest\n    async def test_gather_candidates_relay_only_no_servers(self):\n        with self.assertRaises(ValueError) as cm:\n            ice.Connection(ice_controlling=True, transport_policy=TransportPolicy.RELAY)\n        self.assertEqual(\n            str(cm.exception),\n            \"Relay transport policy requires a STUN and/or TURN server.\",\n        )\n\n    @asynctest\n    async def test_gather_candidates_relay_only_with_stun_server(self):\n        async with run_turn_server() as stun_server:\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                stun_server=stun_server.udp_address,\n                transport_policy=TransportPolicy.RELAY,\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould only have a server-reflexive candidate in connection a\n            self.assertCandidateTypes(conn_a, set([\"srflx\"]))\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_gather_candidates_relay_only_with_turn_server(self):\n        async with run_turn_server(users={\"foo\": \"bar\"}) as turn_server:\n            conn_a = ice.Connection(\n                ice_controlling=True,\n                turn_server=turn_server.udp_address,\n                turn_username=\"foo\",\n                turn_password=\"bar\",\n                transport_policy=TransportPolicy.RELAY,\n            )\n            conn_b = ice.Connection(ice_controlling=False)\n\n            # invite / accept\n            await invite_accept(conn_a, conn_b)\n\n            # we whould only have a server-reflexive candidate in connection a\n            self.assertCandidateTypes(conn_a, set([\"relay\"]))\n\n            # close\n            await conn_a.close()\n            await conn_b.close()\n\n    @asynctest\n    async def test_repr(self):\n        conn = ice.Connection(ice_controlling=True)\n        conn._id = 1\n        self.assertEqual(repr(conn), \"Connection(1)\")\n\n\nclass StunProtocolTest(unittest.TestCase):\n    @asynctest\n    async def test_error_received(self):\n        protocol = ice.StunProtocol(None)\n        protocol.error_received(OSError(\"foo\"))\n\n    @asynctest\n    async def test_repr(self):\n        protocol = ice.StunProtocol(None)\n        protocol.id = 1\n        self.assertEqual(repr(protocol), \"protocol(1)\")\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/test_mdns.py", "content": "import asyncio\nimport contextlib\nimport unittest\n\nfrom aioice import mdns\n\nfrom .utils import asynctest\n\n\n@contextlib.asynccontextmanager\nasync def querier_and_responder():\n    querier = await mdns.create_mdns_protocol()\n    responder = await mdns.create_mdns_protocol()\n\n    try:\n        yield querier, responder\n    finally:\n        await querier.close()\n        await responder.close()\n\n\nclass MdnsTest(unittest.TestCase):\n    @asynctest\n    async def test_receive_junk(self):\n        async with querier_and_responder() as (querier, _):\n            querier.datagram_received(b\"junk\", None)\n\n    @asynctest\n    async def test_resolve_bad(self):\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, _):\n            result = await querier.resolve(hostname)\n            self.assertEqual(result, None)\n\n    @asynctest\n    async def test_resolve_close(self):\n        hostname = mdns.create_mdns_hostname()\n\n        # close the querier while the query is ongoing\n        async with querier_and_responder() as (querier, _):\n            result = await asyncio.gather(\n                querier.resolve(hostname, timeout=None), querier.close()\n            )\n            self.assertEqual(result, [None, None])\n\n    @asynctest\n    async def test_resolve_good_ipv4(self):\n        hostaddr = \"1.2.3.4\"\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, responder):\n            await responder.publish(hostname, hostaddr)\n\n            result = await querier.resolve(hostname)\n            self.assertEqual(result, hostaddr)\n\n    @asynctest\n    async def test_resolve_good_ipv6(self):\n        hostaddr = \"::ffff:1.2.3.4\"\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, responder):\n            await responder.publish(hostname, hostaddr)\n\n            result = await querier.resolve(hostname)\n            self.assertEqual(result, hostaddr)\n\n    @asynctest\n    async def test_resolve_simultaneous_bad(self):\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, _):\n            results = await asyncio.gather(\n                querier.resolve(hostname), querier.resolve(hostname)\n            )\n            self.assertEqual(results, [None, None])\n\n    @asynctest\n    async def test_resolve_simultaneous_good(self):\n        hostaddr = \"1.2.3.4\"\n        hostname = mdns.create_mdns_hostname()\n\n        async with querier_and_responder() as (querier, responder):\n            await responder.publish(hostname, hostaddr)\n\n            results = await asyncio.gather(\n                querier.resolve(hostname), querier.resolve(hostname)\n            )\n            self.assertEqual(results, [hostaddr, hostaddr])\n"}
{"type": "test_file", "path": "tests/test_unitree_agent_queries_fastapi.py", "content": "\"\"\"Unitree Go2 robot agent demo with FastAPI server integration.\n\nConnects a Unitree Go2 robot to an OpenAI agent with a web interface.\n\nEnvironment Variables:\n    OPENAI_API_KEY: Required. OpenAI API key.\n    ROBOT_IP: Required. IP address of the Unitree robot.\n    CONN_TYPE: Required. Connection method to the robot.\n    ROS_OUTPUT_DIR: Optional. Directory for ROS output files.\n\"\"\"\n\nimport os\nimport sys\nimport reactivex as rx\nimport reactivex.operators as ops\n\n# Add project root to Python path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\n# Local application imports\nfrom dimos.agents.agent import OpenAIAgent\nfrom dimos.robot.unitree.unitree_go2 import UnitreeGo2\nfrom dimos.robot.unitree.unitree_skills import MyUnitreeSkills\nfrom dimos.utils.logging_config import logger\nfrom dimos.web.robot_web_interface import RobotWebInterface\nfrom dimos.web.fastapi_server import FastAPIServer\n\n\ndef main():\n    # Get environment variables\n    robot_ip = os.getenv(\"ROBOT_IP\")\n    if not robot_ip:\n        raise ValueError(\"ROBOT_IP environment variable is required\")\n    connection_method = os.getenv(\"CONN_TYPE\") or 'webrtc'\n    output_dir = os.getenv(\"ROS_OUTPUT_DIR\",\n                           os.path.join(os.getcwd(), \"assets/output/ros\"))\n\n    try:\n        # Initialize robot\n        logger.info(\"Initializing Unitree Robot\")\n        robot = UnitreeGo2(ip=robot_ip,\n                           connection_method=connection_method,\n                           output_dir=output_dir,\n                           skills=MyUnitreeSkills())\n\n        # Set up video stream\n        logger.info(\"Starting video stream\")\n        video_stream = robot.get_ros_video_stream()\n\n        # Create FastAPI server with video stream and text streams\n        logger.info(\"Initializing FastAPI server\")\n        streams = {\"unitree_video\": video_stream}\n        \n        # Create a subject for agent responses\n        agent_response_subject = rx.subject.Subject()\n        agent_response_stream = agent_response_subject.pipe(ops.share())\n        \n        text_streams = {\n            \"agent_responses\": agent_response_stream,\n        }\n        \n        web_interface = FastAPIServer(port=5555, text_streams=text_streams, **streams)\n\n        logger.info(\"Starting action primitive execution agent\")\n        agent = OpenAIAgent(\n            dev_name=\"UnitreeQueryExecutionAgent\",\n            input_query_stream=web_interface.query_stream,\n            output_dir=output_dir,\n            skills=robot.get_skills(),\n        )\n        \n        # Subscribe to agent responses and send them to the subject\n        agent.get_response_observable().subscribe(\n            lambda x: agent_response_subject.on_next(x)\n        )\n\n        # Start server (blocking call)\n        logger.info(\"Starting FastAPI server\")\n        web_interface.run()\n\n    except KeyboardInterrupt:\n        print(\"Stopping demo...\")\n    except Exception as e:\n        logger.error(f\"Error: {e}\")\n        return 1\n    finally:\n        if robot:\n            robot.cleanup()\n\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/test_exceptions.py", "content": "import unittest\n\nfrom aioice import stun\n\n\nclass ExceptionTest(unittest.TestCase):\n    def test_transaction_failed(self):\n        response = stun.Message(\n            message_method=stun.Method.BINDING, message_class=stun.Class.RESPONSE\n        )\n        response.attributes[\"ERROR-CODE\"] = (487, \"Role Conflict\")\n\n        exc = stun.TransactionFailed(response)\n        self.assertEqual(str(exc), \"STUN transaction failed (487 - Role Conflict)\")\n\n    def test_transaction_timeout(self):\n        exc = stun.TransactionTimeout()\n        self.assertEqual(str(exc), \"STUN transaction timed out\")\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/test_turn.py", "content": "import asyncio\nimport ssl\nimport unittest\n\nfrom aioice import stun, turn\n\nfrom .echoserver import run_echo_server\nfrom .turnserver import run_turn_server\nfrom .utils import asynctest, read_message\n\nPROTOCOL_KWARGS = {\n    \"username\": \"foo\",\n    \"password\": \"bar\",\n    \"lifetime\": turn.DEFAULT_ALLOCATION_LIFETIME,\n    \"channel_refresh_time\": turn.DEFAULT_CHANNEL_REFRESH_TIME,\n}\n\n\nclass DummyClientProtocol(asyncio.DatagramProtocol):\n    def __init__(self):\n        self.received = []\n\n    def datagram_received(self, data, addr):\n        self.received.append((data, addr))\n\n\nclass TurnClientTcpProtocolTest(unittest.TestCase):\n    def setUp(self):\n        class MockProtocol:\n            def get_extra_info(self, name):\n                return (\"1.2.3.4\", 1234)\n\n        self.protocol = turn.TurnClientTcpProtocol((\"1.2.3.4\", 1234), **PROTOCOL_KWARGS)\n        self.protocol.connection_made(MockProtocol())\n\n    def test_receive_stun_fragmented(self):\n        data = read_message(\"binding_request.bin\")\n        self.protocol.data_received(data[0:10])\n        self.protocol.data_received(data[10:])\n\n    def test_receive_junk(self):\n        self.protocol.data_received(b\"\\x00\" * 20)\n\n    def test_repr(self):\n        self.assertEqual(repr(self.protocol), \"turn/tcp\")\n\n\nclass TurnClientUdpProtocolTest(unittest.TestCase):\n    def setUp(self):\n        self.protocol = turn.TurnClientUdpProtocol((\"1.2.3.4\", 1234), **PROTOCOL_KWARGS)\n\n    def test_receive_junk(self):\n        self.protocol.datagram_received(b\"\\x00\" * 20, (\"1.2.3.4\", 1234))\n\n    def test_repr(self):\n        self.assertEqual(repr(self.protocol), \"turn/udp\")\n\n\nclass TurnTest(unittest.TestCase):\n    @asynctest\n    async def test_tcp_transport(self):\n        await self._test_transport(\"tcp\", \"tcp_address\")\n\n    @asynctest\n    async def test_tls_transport(self):\n        ssl_context = ssl.SSLContext(protocol=ssl.PROTOCOL_TLS_CLIENT)\n        ssl_context.check_hostname = False\n        ssl_context.verify_mode = ssl.CERT_NONE\n\n        await self._test_transport(\"tcp\", \"tls_address\", ssl=ssl_context)\n\n    @asynctest\n    async def test_udp_transport(self):\n        await self._test_transport(\"udp\", \"udp_address\")\n\n    async def _test_transport(self, transport, server_addr_attr, ssl=False):\n        await self._test_transport_ok(\n            transport=transport, server_addr_attr=server_addr_attr, ssl=ssl\n        )\n        await self._test_transport_ok_multi(\n            transport=transport, server_addr_attr=server_addr_attr, ssl=ssl\n        )\n        await self._test_transport_allocate_failure(\n            transport=transport, server_addr_attr=server_addr_attr, ssl=ssl\n        )\n        await self._test_transport_delete_failure(\n            transport=transport, server_addr_attr=server_addr_attr, ssl=ssl\n        )\n\n    async def _test_transport_ok(self, *, transport, server_addr_attr, ssl):\n        async with run_turn_server(realm=\"test\", users={\"foo\": \"bar\"}) as turn_server:\n            transport, protocol = await turn.create_turn_endpoint(\n                DummyClientProtocol,\n                server_addr=getattr(turn_server, server_addr_attr),\n                username=\"foo\",\n                password=\"bar\",\n                channel_refresh_time=5,\n                lifetime=6,\n                ssl=ssl,\n                transport=transport,\n            )\n            self.assertIsNone(transport.get_extra_info(\"peername\"))\n            self.assertIsNotNone(transport.get_extra_info(\"sockname\"))\n\n            async with run_echo_server() as echo_server:\n                # bind channel, send ping, expect pong\n                transport.sendto(b\"ping\", echo_server.udp_address)\n                await asyncio.sleep(1)\n                self.assertEqual(\n                    protocol.received, [(b\"ping\", echo_server.udp_address)]\n                )\n\n                # wait some more to allow allocation refresh\n                protocol.received.clear()\n                await asyncio.sleep(5)\n\n                # refresh channel, send ping, expect pong\n                transport.sendto(b\"ping\", echo_server.udp_address)\n                await asyncio.sleep(1)\n                self.assertEqual(\n                    protocol.received, [(b\"ping\", echo_server.udp_address)]\n                )\n\n            # close\n            transport.close()\n            await asyncio.sleep(0)\n\n    async def _test_transport_ok_multi(self, *, transport, server_addr_attr, ssl):\n        async with run_turn_server(realm=\"test\", users={\"foo\": \"bar\"}) as turn_server:\n            transport, protocol = await turn.create_turn_endpoint(\n                DummyClientProtocol,\n                server_addr=getattr(turn_server, server_addr_attr),\n                username=\"foo\",\n                password=\"bar\",\n                channel_refresh_time=5,\n                lifetime=6,\n                ssl=ssl,\n                transport=transport,\n            )\n            self.assertIsNone(transport.get_extra_info(\"peername\"))\n            self.assertIsNotNone(transport.get_extra_info(\"sockname\"))\n\n            # Bind channel, send ping, expect pong.\n            #\n            # We use different lengths to trigger both padded an unpadded\n            # ChannelData messages over TCP.\n            async with run_echo_server() as echo_server1:\n                async with run_echo_server() as echo_server2:\n                    transport.sendto(b\"ping\", echo_server1.udp_address)  # never padded\n                    transport.sendto(b\"ping11\", echo_server1.udp_address)\n                    transport.sendto(b\"ping20\", echo_server2.udp_address)\n                    transport.sendto(b\"ping21\", echo_server2.udp_address)\n                    await asyncio.sleep(1)\n                    self.assertEqual(\n                        sorted(protocol.received),\n                        [\n                            (b\"ping\", echo_server1.udp_address),\n                            (b\"ping11\", echo_server1.udp_address),\n                            (b\"ping20\", echo_server2.udp_address),\n                            (b\"ping21\", echo_server2.udp_address),\n                        ],\n                    )\n\n            # close\n            transport.close()\n            await asyncio.sleep(0)\n\n    async def _test_transport_allocate_failure(\n        self, *, transport, server_addr_attr, ssl\n    ):\n        async with run_turn_server(realm=\"test\", users={\"foo\": \"bar\"}) as turn_server:\n            # make the server reject the ALLOCATE request\n            turn_server.simulated_failure = (403, \"Forbidden\")\n\n            with self.assertRaises(stun.TransactionFailed) as cm:\n                await turn.create_turn_endpoint(\n                    DummyClientProtocol,\n                    server_addr=getattr(turn_server, server_addr_attr),\n                    username=\"foo\",\n                    password=\"bar\",\n                    ssl=ssl,\n                    transport=transport,\n                )\n        self.assertEqual(str(cm.exception), \"STUN transaction failed (403 - Forbidden)\")\n\n    async def _test_transport_delete_failure(self, *, transport, server_addr_attr, ssl):\n        async with run_turn_server(realm=\"test\", users={\"foo\": \"bar\"}) as turn_server:\n            transport, protocol = await turn.create_turn_endpoint(\n                DummyClientProtocol,\n                server_addr=getattr(turn_server, server_addr_attr),\n                username=\"foo\",\n                password=\"bar\",\n                ssl=ssl,\n                transport=transport,\n            )\n            self.assertIsNone(transport.get_extra_info(\"peername\"))\n            self.assertIsNotNone(transport.get_extra_info(\"sockname\"))\n\n            # make the server reject the final REFRESH request\n            turn_server.simulated_failure = (403, \"Forbidden\")\n\n            # close client\n            transport.close()\n            await asyncio.sleep(0)\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/test_ice_trickle.py", "content": "import asyncio\nimport unittest\n\nfrom aioice import ice\n\nfrom .utils import asynctest\n\n\nclass IceTrickleTest(unittest.TestCase):\n    def assertCandidateTypes(self, conn, expected):\n        types = set([c.type for c in conn.local_candidates])\n        self.assertEqual(types, expected)\n\n    @asynctest\n    async def test_connect(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite\n        await conn_a.gather_candidates()\n        conn_b.remote_username = conn_a.local_username\n        conn_b.remote_password = conn_a.local_password\n\n        # accept\n        await conn_b.gather_candidates()\n        conn_a.remote_username = conn_b.local_username\n        conn_a.remote_password = conn_b.local_password\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # there should be a default candidate for component 1\n        candidate = conn_a.get_default_candidate(1)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # there should not be a default candidate for component 2\n        candidate = conn_a.get_default_candidate(2)\n        self.assertIsNone(candidate)\n\n        async def add_candidates_later(a, b):\n            await asyncio.sleep(0.1)\n            for candidate in b.local_candidates:\n                await a.add_remote_candidate(candidate)\n                await asyncio.sleep(0.1)\n            await a.add_remote_candidate(None)\n\n        # connect\n        await asyncio.gather(\n            conn_a.connect(),\n            conn_b.connect(),\n            add_candidates_later(conn_a, conn_b),\n            add_candidates_later(conn_b, conn_a),\n        )\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/test_stun.py", "content": "import unittest\nfrom binascii import unhexlify\nfrom collections import OrderedDict\n\nfrom aioice import stun\n\nfrom .utils import asynctest, read_message\n\n\nclass AttributeTest(unittest.TestCase):\n    def test_unpack_error_code(self):\n        data = unhexlify(\"00000457526f6c6520436f6e666c696374\")\n        code, reason = stun.unpack_error_code(data)\n        self.assertEqual(code, 487)\n        self.assertEqual(reason, \"Role Conflict\")\n\n    def test_unpack_error_code_too_short(self):\n        data = unhexlify(\"000004\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_error_code(data)\n        self.assertEqual(str(cm.exception), \"STUN error code is less than 4 bytes\")\n\n    def test_unpack_xor_address_ipv4(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        address, port = stun.unpack_xor_address(\n            unhexlify(\"0001a147e112a643\"), transaction_id\n        )\n        self.assertEqual(address, \"192.0.2.1\")\n        self.assertEqual(port, 32853)\n\n    def test_unpack_xor_address_ipv4_truncated(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_xor_address(unhexlify(\"0001a147e112a6\"), transaction_id)\n        self.assertEqual(str(cm.exception), \"STUN address has invalid length for IPv4\")\n\n    def test_unpack_xor_address_ipv6(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        address, port = stun.unpack_xor_address(\n            unhexlify(\"0002a1470113a9faa5d3f179bc25f4b5bed2b9d9\"), transaction_id\n        )\n        self.assertEqual(address, \"2001:db8:1234:5678:11:2233:4455:6677\")\n        self.assertEqual(port, 32853)\n\n    def test_unpack_xor_address_ipv6_truncated(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_xor_address(\n                unhexlify(\"0002a1470113a9faa5d3f179bc25f4b5bed2b9\"), transaction_id\n            )\n        self.assertEqual(str(cm.exception), \"STUN address has invalid length for IPv6\")\n\n    def test_unpack_xor_address_too_short(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_xor_address(unhexlify(\"0001\"), transaction_id)\n        self.assertEqual(str(cm.exception), \"STUN address length is less than 4 bytes\")\n\n    def test_unpack_xor_address_unknown_protocol(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.unpack_xor_address(unhexlify(\"0003a147e112a643\"), transaction_id)\n        self.assertEqual(str(cm.exception), \"STUN address has unknown protocol\")\n\n    def test_pack_error_code(self):\n        data = stun.pack_error_code((487, \"Role Conflict\"))\n        self.assertEqual(data, unhexlify(\"00000457526f6c6520436f6e666c696374\"))\n\n    def test_pack_xor_address_ipv4(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        data = stun.pack_xor_address((\"192.0.2.1\", 32853), transaction_id)\n        self.assertEqual(data, unhexlify(\"0001a147e112a643\"))\n\n    def test_pack_xor_address_ipv6(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        data = stun.pack_xor_address(\n            (\"2001:db8:1234:5678:11:2233:4455:6677\", 32853), transaction_id\n        )\n        self.assertEqual(data, unhexlify(\"0002a1470113a9faa5d3f179bc25f4b5bed2b9d9\"))\n\n    def test_pack_xor_address_unknown_protocol(self):\n        transaction_id = unhexlify(\"b7e7a701bc34d686fa87dfae\")\n        with self.assertRaises(ValueError) as cm:\n            stun.pack_xor_address((\"foo\", 32853), transaction_id)\n        self.assertEqual(\n            str(cm.exception), \"'foo' does not appear to be an IPv4 or IPv6 address\"\n        )\n\n\nclass MessageTest(unittest.TestCase):\n    def test_binding_request(self):\n        data = read_message(\"binding_request.bin\")\n\n        message = stun.parse_message(data)\n        self.assertEqual(message.message_method, stun.Method.BINDING)\n        self.assertEqual(message.message_class, stun.Class.REQUEST)\n        self.assertEqual(message.transaction_id, b\"Nvfx3lU7FUBF\")\n        self.assertEqual(message.attributes, OrderedDict())\n\n        self.assertEqual(bytes(message), data)\n        self.assertEqual(\n            repr(message),\n            \"Message(message_method=Method.BINDING, message_class=Class.REQUEST, \"\n            \"transaction_id=b'Nvfx3lU7FUBF')\",\n        )\n\n    def test_binding_request_ice_controlled(self):\n        data = read_message(\"binding_request_ice_controlled.bin\")\n\n        message = stun.parse_message(data)\n        self.assertEqual(message.message_method, stun.Method.BINDING)\n        self.assertEqual(message.message_class, stun.Class.REQUEST)\n        self.assertEqual(message.transaction_id, b\"wxaNbAdXjwG3\")\n        self.assertEqual(\n            message.attributes,\n            OrderedDict(\n                [\n                    (\"USERNAME\", \"AYeZ:sw7YvCSbcVex3bhi\"),\n                    (\"PRIORITY\", 1685987071),\n                    (\"SOFTWARE\", \"FreeSWITCH (-37-987c9b9 64bit)\"),\n                    (\"ICE-CONTROLLED\", 5491930053772927353),\n                    (\n                        \"MESSAGE-INTEGRITY\",\n                        unhexlify(\"1963108a4f764015a66b3fea0b1883dfde1436c8\"),\n                    ),\n                    (\"FINGERPRINT\", 3230414530),\n                ]\n            ),\n        )\n\n        self.assertEqual(bytes(message), data)\n\n    def test_binding_request_ice_controlled_bad_fingerprint(self):\n        data = read_message(\"binding_request_ice_controlled.bin\")[0:-1] + b\"z\"\n\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(data)\n        self.assertEqual(str(cm.exception), \"STUN message fingerprint does not match\")\n\n    def test_binding_request_ice_controlled_bad_integrity(self):\n        data = read_message(\"binding_request_ice_controlled.bin\")\n\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(data, integrity_key=b\"bogus-key\")\n        self.assertEqual(str(cm.exception), \"STUN message integrity does not match\")\n\n    def test_binding_request_ice_controlling(self):\n        data = read_message(\"binding_request_ice_controlling.bin\")\n\n        message = stun.parse_message(data)\n        self.assertEqual(message.message_method, stun.Method.BINDING)\n        self.assertEqual(message.message_class, stun.Class.REQUEST)\n        self.assertEqual(message.transaction_id, b\"JEwwUxjLWaa2\")\n        self.assertEqual(\n            message.attributes,\n            OrderedDict(\n                [\n                    (\"USERNAME\", \"sw7YvCSbcVex3bhi:AYeZ\"),\n                    (\"ICE-CONTROLLING\", 5943294521425135761),\n                    (\"USE-CANDIDATE\", None),\n                    (\"PRIORITY\", 1853759231),\n                    (\n                        \"MESSAGE-INTEGRITY\",\n                        unhexlify(\"c87b58eccbacdbc075d497ad0c965a82937ab587\"),\n                    ),\n                    (\"FINGERPRINT\", 1347006354),\n                ]\n            ),\n        )\n\n    def test_binding_response(self):\n        data = read_message(\"binding_response.bin\")\n\n        message = stun.parse_message(data)\n        self.assertEqual(message.message_method, stun.Method.BINDING)\n        self.assertEqual(message.message_class, stun.Class.RESPONSE)\n        self.assertEqual(message.transaction_id, b\"Nvfx3lU7FUBF\")\n        self.assertEqual(\n            message.attributes,\n            OrderedDict(\n                [\n                    (\"XOR-MAPPED-ADDRESS\", (\"80.200.136.90\", 53054)),\n                    (\"MAPPED-ADDRESS\", (\"80.200.136.90\", 53054)),\n                    (\"RESPONSE-ORIGIN\", (\"52.17.36.97\", 3478)),\n                    (\"OTHER-ADDRESS\", (\"52.17.36.97\", 3479)),\n                    (\"SOFTWARE\", \"Citrix-3.2.4.5 'Marshal West'\"),\n                ]\n            ),\n        )\n\n        self.assertEqual(bytes(message), data)\n\n    def test_message_body_length_mismatch(self):\n        data = read_message(\"binding_response.bin\") + b\"123\"\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(data)\n        self.assertEqual(str(cm.exception), \"STUN message length does not match\")\n\n    def test_message_shorter_than_header(self):\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(b\"123\")\n        self.assertEqual(str(cm.exception), \"STUN message length is less than 20 bytes\")\n\n    def test_message_with_unknown_method(self):\n        with self.assertRaises(ValueError) as cm:\n            stun.parse_message(bytes(20))\n        self.assertEqual(str(cm.exception), \"0 is not a valid Method\")\n\n\nclass TransactionTest(unittest.TestCase):\n    def setUp(self):\n        stun.RETRY_MAX = 0\n        stun.RETRY_RTO = 0\n\n    def tearDown(self):\n        stun.RETRY_MAX = 6\n        stun.RETRY_RTO = 0.5\n\n    @asynctest\n    async def test_timeout(self):\n        class DummyProtocol:\n            def send_stun(self, message, address):\n                pass\n\n        request = stun.Message(\n            message_method=stun.Method.BINDING, message_class=stun.Class.REQUEST\n        )\n        transaction = stun.Transaction(request, (\"127.0.0.1\", 1234), DummyProtocol())\n\n        # timeout\n        with self.assertRaises(stun.TransactionTimeout):\n            await transaction.run()\n\n        # receive response after timeout\n        response = stun.Message(\n            message_method=stun.Method.BINDING, message_class=stun.Class.RESPONSE\n        )\n        transaction.response_received(response, (\"127.0.0.1\", 1234))\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/echoserver.py", "content": "import asyncio\nimport contextlib\n\n\nclass EchoServerProtocol(asyncio.DatagramProtocol):\n    def connection_made(self, transport):\n        self.transport = transport\n\n    def datagram_received(self, data, addr):\n        self.transport.sendto(data, addr)\n\n\nclass EchoServer:\n    async def close(self):\n        self.udp_server.transport.close()\n\n    async def listen(self, host=\"127.0.0.1\", port=0):\n        loop = asyncio.get_event_loop()\n\n        # listen for UDP\n        transport, self.udp_server = await loop.create_datagram_endpoint(\n            EchoServerProtocol, local_addr=(host, port)\n        )\n        self.udp_address = transport.get_extra_info(\"sockname\")\n\n\n@contextlib.asynccontextmanager\nasync def run_echo_server(**kwargs):\n    server = EchoServer(**kwargs)\n    await server.listen()\n    try:\n        yield server\n    finally:\n        await server.close()\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_webrtc_connect/libs/aioice/tests/test_ice_trickle.py", "content": "import asyncio\nimport unittest\n\nfrom aioice import ice\n\nfrom .utils import asynctest\n\n\nclass IceTrickleTest(unittest.TestCase):\n    def assertCandidateTypes(self, conn, expected):\n        types = set([c.type for c in conn.local_candidates])\n        self.assertEqual(types, expected)\n\n    @asynctest\n    async def test_connect(self):\n        conn_a = ice.Connection(ice_controlling=True)\n        conn_b = ice.Connection(ice_controlling=False)\n\n        # invite\n        await conn_a.gather_candidates()\n        conn_b.remote_username = conn_a.local_username\n        conn_b.remote_password = conn_a.local_password\n\n        # accept\n        await conn_b.gather_candidates()\n        conn_a.remote_username = conn_b.local_username\n        conn_a.remote_password = conn_b.local_password\n\n        # we should only have host candidates\n        self.assertCandidateTypes(conn_a, set([\"host\"]))\n        self.assertCandidateTypes(conn_b, set([\"host\"]))\n\n        # there should be a default candidate for component 1\n        candidate = conn_a.get_default_candidate(1)\n        self.assertIsNotNone(candidate)\n        self.assertEqual(candidate.type, \"host\")\n\n        # there should not be a default candidate for component 2\n        candidate = conn_a.get_default_candidate(2)\n        self.assertIsNone(candidate)\n\n        async def add_candidates_later(a, b):\n            await asyncio.sleep(0.1)\n            for candidate in b.local_candidates:\n                await a.add_remote_candidate(candidate)\n                await asyncio.sleep(0.1)\n            await a.add_remote_candidate(None)\n\n        # connect\n        await asyncio.gather(\n            conn_a.connect(),\n            conn_b.connect(),\n            add_candidates_later(conn_a, conn_b),\n            add_candidates_later(conn_b, conn_a),\n        )\n\n        # send data a -> b\n        await conn_a.send(b\"howdee\")\n        data = await conn_b.recv()\n        self.assertEqual(data, b\"howdee\")\n\n        # send data b -> a\n        await conn_b.send(b\"gotcha\")\n        data = await conn_a.recv()\n        self.assertEqual(data, b\"gotcha\")\n\n        # close\n        await conn_a.close()\n        await conn_b.close()\n"}
{"type": "test_file", "path": "dimos/robot/unitree/external/go2_ros2_sdk/go2_robot_sdk/external_lib/aioice/tests/utils.py", "content": "import asyncio\nimport functools\nimport logging\nimport os\n\n\ndef asynctest(coro):\n    @functools.wraps(coro)\n    def wrap(*args, **kwargs):\n        asyncio.run(coro(*args, **kwargs))\n\n    return wrap\n\n\nasync def invite_accept(conn_a, conn_b):\n    # invite\n    await conn_a.gather_candidates()\n    for candidate in conn_a.local_candidates:\n        await conn_b.add_remote_candidate(candidate)\n    await conn_b.add_remote_candidate(None)\n    conn_b.remote_username = conn_a.local_username\n    conn_b.remote_password = conn_a.local_password\n\n    # accept\n    await conn_b.gather_candidates()\n    for candidate in conn_b.local_candidates:\n        await conn_a.add_remote_candidate(candidate)\n    await conn_a.add_remote_candidate(None)\n    conn_a.remote_username = conn_b.local_username\n    conn_a.remote_password = conn_b.local_password\n\n\ndef read_message(name):\n    path = os.path.join(os.path.dirname(__file__), \"data\", name)\n    with open(path, \"rb\") as fp:\n        return fp.read()\n\n\nif os.environ.get(\"AIOICE_DEBUG\"):\n    logging.basicConfig(level=logging.DEBUG)\n"}
{"type": "test_file", "path": "tests/isaacsim/stream_camera.py", "content": "import os\nfrom dimos.simulation.simulator import Simulator\nfrom dimos.simulation.stream import SimulationStream\n\ndef main():\n    # Initialize simulator\n    sim = Simulator(headless=True)\n    \n    # Create stream with custom settings\n    stream = SimulationStream(\n        simulator=sim,\n        width=1920,\n        height=1080,\n        fps=60,\n        camera_path=\"/World/alfred_parent_prim/alfred_base_descr/chest_cam_rgb_camera_frame/chest_cam\",\n        annotator='rgb',\n        transport='tcp',\n        rtsp_url=\"rtsp://mediamtx:8554/stream\",\n        usd_path=f\"{os.getcwd()}/assets/TestSim3.usda\"\n    )\n    \n    # Start streaming\n    stream.stream()\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "dimos/hardware/interface.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom dimos.hardware.end_effector import EndEffector\nfrom dimos.hardware.camera import Camera\nfrom dimos.hardware.stereo_camera import StereoCamera\nfrom dimos.hardware.ufactory import UFactoryEndEffector, UFactory7DOFArm\n\nclass HardwareInterface:\n    def __init__(self, end_effector: EndEffector = None, sensors: list = None, arm_architecture: UFactory7DOFArm = None):\n        self.end_effector = end_effector\n        self.sensors = sensors if sensors is not None else []\n        self.arm_architecture = arm_architecture\n\n    def get_configuration(self):\n        \"\"\"Return the current hardware configuration.\"\"\"\n        return {\n            'end_effector': self.end_effector,\n            'sensors': [sensor.get_sensor_type() for sensor in self.sensors],\n            'arm_architecture': self.arm_architecture\n        }\n\n    def set_configuration(self, configuration):\n        \"\"\"Set the hardware configuration.\"\"\"\n        self.end_effector = configuration.get('end_effector', self.end_effector)\n        self.sensors = configuration.get('sensors', self.sensors)\n        self.arm_architecture = configuration.get('arm_architecture', self.arm_architecture)\n\n    def add_sensor(self, sensor):\n        \"\"\"Add a sensor to the hardware interface.\"\"\"\n        if isinstance(sensor, (Camera, StereoCamera)):\n            self.sensors.append(sensor)\n        else:\n            raise ValueError(\"Sensor must be a Camera or StereoCamera instance.\")\n"}
{"type": "source_file", "path": "dimos/hardware/sensor.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom abc import ABC, abstractmethod\n\nclass AbstractSensor(ABC):\n    def __init__(self, sensor_type=None):\n        self.sensor_type = sensor_type\n\n    @abstractmethod\n    def get_sensor_type(self):\n        \"\"\"Return the type of sensor.\"\"\"\n        pass\n\n    @abstractmethod\n    def calculate_intrinsics(self):\n        \"\"\"Calculate the sensor's intrinsics.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_intrinsics(self):\n        \"\"\"Return the sensor's intrinsics.\"\"\"\n        pass\n"}
{"type": "source_file", "path": "dimos/hardware/stereo_camera.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom dimos.hardware.camera import Camera\n\nclass StereoCamera(Camera):\n    def __init__(self, baseline=None, **kwargs):\n        super().__init__(**kwargs)\n        self.baseline = baseline\n\n    def get_intrinsics(self):\n        intrinsics = super().get_intrinsics()\n        intrinsics['baseline'] = self.baseline\n        return intrinsics\n"}
{"type": "source_file", "path": "dimos/hardware/ufactory.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom dimos.hardware.end_effector import EndEffector\n\nclass UFactoryEndEffector(EndEffector):\n    def __init__(self, model=None, **kwargs):\n        super().__init__(**kwargs)\n        self.model = model\n\n    def get_model(self):\n        return self.model\n\nclass UFactory7DOFArm:\n    def __init__(self, arm_length=None):\n        self.arm_length = arm_length\n\n    def get_arm_length(self):\n        return self.arm_length\n"}
{"type": "source_file", "path": "dimos/models/pointcloud/pointcloud_utils.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pickle\nimport numpy as np\nimport open3d as o3d\nimport random\n\ndef save_pointcloud(pcd, file_path):\n    \"\"\"\n    Save a point cloud to a file using Open3D.\n    \"\"\"\n    o3d.io.write_point_cloud(file_path, pcd)\n\ndef restore_pointclouds(pointcloud_paths):\n    restored_pointclouds = []\n    for path in pointcloud_paths:\n        restored_pointclouds.append(o3d.io.read_point_cloud(path))\n    return restored_pointclouds\n\n\ndef create_point_cloud_from_rgbd(rgb_image, depth_image, intrinsic_parameters):\n    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        o3d.geometry.Image(rgb_image),\n        o3d.geometry.Image(depth_image),\n        depth_scale=0.125, #1000.0,\n        depth_trunc=10.0, #10.0,\n        convert_rgb_to_intensity=False\n    )\n    intrinsic = o3d.camera.PinholeCameraIntrinsic()\n    intrinsic.set_intrinsics(intrinsic_parameters['width'], intrinsic_parameters['height'],\n                             intrinsic_parameters['fx'], intrinsic_parameters['fy'],\n                             intrinsic_parameters['cx'], intrinsic_parameters['cy'])\n    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, intrinsic)\n    return pcd\n\ndef canonicalize_point_cloud(pcd, canonicalize_threshold=0.3):\n    # Segment the largest plane, assumed to be the floor\n    plane_model, inliers = pcd.segment_plane(distance_threshold=0.01, ransac_n=3, num_iterations=1000)\n\n    canonicalized = False\n    if len(inliers) / len(pcd.points) > canonicalize_threshold:\n        canonicalized = True\n\n        # Ensure the plane normal points upwards\n        if np.dot(plane_model[:3], [0, 1, 0]) < 0:\n            plane_model = -plane_model\n\n        # Normalize the plane normal vector\n        normal = plane_model[:3] / np.linalg.norm(plane_model[:3])\n\n        # Compute the new basis vectors\n        new_y = normal\n        new_x = np.cross(new_y, [0, 0, -1])\n        new_x /= np.linalg.norm(new_x)\n        new_z = np.cross(new_x, new_y)\n\n        # Create the transformation matrix\n        transformation = np.identity(4)\n        transformation[:3, :3] = np.vstack((new_x, new_y, new_z)).T\n        transformation[:3, 3] = -np.dot(transformation[:3, :3], pcd.points[inliers[0]])\n\n        # Apply the transformation\n        pcd.transform(transformation)\n\n        # Additional 180-degree rotation around the Z-axis\n        rotation_z_180 = np.array([[np.cos(np.pi), -np.sin(np.pi), 0],\n                                   [np.sin(np.pi), np.cos(np.pi), 0],\n                                   [0, 0, 1]])\n        pcd.rotate(rotation_z_180, center=(0, 0, 0))\n\n        return pcd, canonicalized, transformation\n    else:\n        return pcd, canonicalized, None\n\n\n# Distance calculations\ndef human_like_distance(distance_meters):\n    # Define the choices with units included, focusing on the 0.1 to 10 meters range\n    if distance_meters < 1:  # For distances less than 1 meter\n        choices = [\n            (\n                round(distance_meters * 100, 2),\n                \"centimeters\",\n                0.2,\n            ),  # Centimeters for very small distances\n            (\n                round(distance_meters * 39.3701, 2),\n                \"inches\",\n                0.8,\n            ),  # Inches for the majority of cases under 1 meter\n        ]\n    elif distance_meters < 3:  # For distances less than 3 meters\n        choices = [\n            (round(distance_meters, 2), \"meters\", 0.5),\n            (\n                round(distance_meters * 3.28084, 2),\n                \"feet\",\n                0.5,\n            ),  # Feet as a common unit within indoor spaces\n        ]\n    else:  # For distances from 3 up to 10 meters\n        choices = [\n            (\n                round(distance_meters, 2),\n                \"meters\",\n                0.7,\n            ),  # Meters for clarity and international understanding\n            (\n                round(distance_meters * 3.28084, 2),\n                \"feet\",\n                0.3,\n            ),  # Feet for additional context\n        ]\n\n    # Normalize probabilities and make a selection\n    total_probability = sum(prob for _, _, prob in choices)\n    cumulative_distribution = []\n    cumulative_sum = 0\n    for value, unit, probability in choices:\n        cumulative_sum += probability / total_probability  # Normalize probabilities\n        cumulative_distribution.append((cumulative_sum, value, unit))\n\n    # Randomly choose based on the cumulative distribution\n    r = random.random()\n    for cumulative_prob, value, unit in cumulative_distribution:\n        if r < cumulative_prob:\n            return f\"{value} {unit}\"\n\n    # Fallback to the last choice if something goes wrong\n    return f\"{choices[-1][0]} {choices[-1][1]}\"\n\ndef calculate_distances_between_point_clouds(A, B):\n    dist_pcd1_to_pcd2 = np.asarray(A.compute_point_cloud_distance(B))\n    dist_pcd2_to_pcd1 = np.asarray(B.compute_point_cloud_distance(A))\n    combined_distances = np.concatenate((dist_pcd1_to_pcd2, dist_pcd2_to_pcd1))\n    avg_dist = np.mean(combined_distances)\n    return human_like_distance(avg_dist)\n\ndef calculate_centroid(pcd):\n    \"\"\"Calculate the centroid of a point cloud.\"\"\"\n    points = np.asarray(pcd.points)\n    centroid = np.mean(points, axis=0)\n    return centroid\n\ndef calculate_relative_positions(centroids):\n    \"\"\"Calculate the relative positions between centroids of point clouds.\"\"\"\n    num_centroids = len(centroids)\n    relative_positions_info = []\n\n    for i in range(num_centroids):\n        for j in range(i + 1, num_centroids):\n            relative_vector = centroids[j] - centroids[i]\n\n            distance = np.linalg.norm(relative_vector)\n            relative_positions_info.append({\n                'pcd_pair': (i, j),\n                'relative_vector': relative_vector,\n                'distance': distance\n            })\n\n    return relative_positions_info\n\ndef get_bounding_box_height(pcd):\n    \"\"\"\n    Compute the height of the bounding box for a given point cloud.\n\n    Parameters:\n    pcd (open3d.geometry.PointCloud): The input point cloud.\n\n    Returns:\n    float: The height of the bounding box.\n    \"\"\"\n    aabb = pcd.get_axis_aligned_bounding_box()\n    return aabb.get_extent()[1]  # Assuming the Y-axis is the up-direction\n\ndef compare_bounding_box_height(pcd_i, pcd_j):\n    \"\"\"\n    Compare the bounding box heights of two point clouds.\n\n    Parameters:\n    pcd_i (open3d.geometry.PointCloud): The first point cloud.\n    pcd_j (open3d.geometry.PointCloud): The second point cloud.\n\n    Returns:\n    bool: True if the bounding box of pcd_i is taller than that of pcd_j, False otherwise.\n    \"\"\"\n    height_i = get_bounding_box_height(pcd_i)\n    height_j = get_bounding_box_height(pcd_j)\n\n    return height_i > height_j\n"}
{"type": "source_file", "path": "dimos/models/segmentation/segment_utils.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch\nimport numpy as np\n\ndef find_medoid_and_closest_points(points, num_closest=5):\n    \"\"\"\n    Find the medoid from a collection of points and the closest points to the medoid.\n\n    Parameters:\n    points (np.array): A numpy array of shape (N, D) where N is the number of points and D is the dimensionality.\n    num_closest (int): Number of closest points to return.\n\n    Returns:\n    np.array: The medoid point.\n    np.array: The closest points to the medoid.\n    \"\"\"\n    distances = np.sqrt(((points[:, np.newaxis, :] - points[np.newaxis, :, :]) ** 2).sum(axis=-1))\n    distance_sums = distances.sum(axis=1)\n    medoid_idx = np.argmin(distance_sums)\n    medoid = points[medoid_idx]\n    sorted_indices = np.argsort(distances[medoid_idx])\n    closest_indices = sorted_indices[1:num_closest + 1]\n    return medoid, points[closest_indices]\n\ndef sample_points_from_heatmap(heatmap, original_size, num_points=5, percentile=0.95):\n    \"\"\"\n    Sample points from the given heatmap, focusing on areas with higher values.\n    \"\"\"\n    width, height = original_size\n    threshold = np.percentile(heatmap.numpy(), percentile)\n    masked_heatmap = torch.where(heatmap > threshold, heatmap, torch.tensor(0.0))\n    probabilities = torch.softmax(masked_heatmap.flatten(), dim=0)\n\n    attn = torch.sigmoid(heatmap)\n    w = attn.shape[0]\n    sampled_indices = torch.multinomial(torch.tensor(probabilities.ravel()), num_points, replacement=True)\n\n    sampled_coords = np.array(np.unravel_index(sampled_indices, attn.shape)).T\n    medoid, sampled_coords = find_medoid_and_closest_points(sampled_coords)\n    pts = []\n    for pt in sampled_coords.tolist():\n        x, y = pt\n        x = height * x / w\n        y = width * y / w\n        pts.append([y, x])\n    return pts\n\n\ndef apply_mask_to_image(image, mask):\n    \"\"\"\n    Apply a binary mask to an image. The mask should be a binary array where the regions to keep are True.\n    \"\"\"\n    masked_image = image.copy()\n    for c in range(masked_image.shape[2]):\n        masked_image[:, :, c] = masked_image[:, :, c] * mask\n    return masked_image"}
{"type": "source_file", "path": "dimos/models/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/models/depth/metric3d.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport sys\nimport torch\nfrom PIL import Image\nimport cv2\nimport numpy as np\n\n# May need to add this back for import to work\n# external_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'external', 'Metric3D'))\n# if external_path not in sys.path:\n#     sys.path.append(external_path)\n\n\nclass Metric3D:\n    def __init__(self):\n        #self.conf = get_config(\"zoedepth\", \"infer\")\n        #self.depth_model = build_model(self.conf)\n        self.depth_model = torch.hub.load('yvanyin/metric3d', 'metric3d_vit_small', pretrain=True).cuda()\n        if torch.cuda.device_count() > 1:\n            print(f\"Using {torch.cuda.device_count()} GPUs!\")\n            #self.depth_model = torch.nn.DataParallel(self.depth_model)\n        self.depth_model.eval()\n\n        self.intrinsic = [707.0493, 707.0493, 604.0814, 180.5066]  \n        self.gt_depth_scale = 256.0  # And this\n        self.pad_info = None\n        self.rgb_origin = None\n    '''\n    Input: Single image in RGB format\n    Output: Depth map\n    '''\n\n    def update_intrinsic(self, intrinsic):\n        \"\"\"\n        Update the intrinsic parameters dynamically.\n        Ensure that the input intrinsic is valid.\n        \"\"\"\n        if len(intrinsic) != 4:\n            raise ValueError(\"Intrinsic must be a list or tuple with 4 values: [fx, fy, cx, cy]\")\n        self.intrinsic = intrinsic\n        print(f\"Intrinsics updated to: {self.intrinsic}\")\n\n    def infer_depth(self, img, debug=False):\n        if debug:\n            print(f\"Input image: {img}\")\n        try:\n            if isinstance(img, str):\n                print(f\"Image type string: {type(img)}\")\n                self.rgb_origin = cv2.imread(img)[:, :, ::-1]\n            else:\n                print(f\"Image type not string: {type(img)}, cv2 conversion assumed to be handled. If not, this will throw an error\")\n                self.rgb_origin = img\n        except Exception as e:\n            print(f\"Error parsing into infer_depth: {e}\")\n\n        img = self.rescale_input(img, self.rgb_origin)\n\n        with torch.no_grad():\n            pred_depth, confidence, output_dict = self.depth_model.inference({'input': img})\n        print(\"Inference completed.\")\n\n        # Convert to PIL format\n        depth_image = self.unpad_transform_depth(pred_depth)\n        out_16bit_numpy = (depth_image.squeeze().cpu().numpy() * 256).astype(np.uint16)\n        depth_map_pil = Image.fromarray(out_16bit_numpy)\n\n        return depth_map_pil\n    def save_depth(self, pred_depth):\n        # Save the depth map to a file\n        pred_depth_np = pred_depth.cpu().numpy()\n        output_depth_file = 'output_depth_map.png'\n        cv2.imwrite(output_depth_file, pred_depth_np)\n        print(f\"Depth map saved to {output_depth_file}\")\n\n    # Adjusts input size to fit pretrained ViT model\n    def rescale_input(self, rgb, rgb_origin):\n        #### ajust input size to fit pretrained model\n        # keep ratio resize\n        input_size = (616, 1064)  # for vit model\n        # input_size = (544, 1216) # for convnext model\n        h, w = rgb_origin.shape[:2]\n        scale = min(input_size[0] / h, input_size[1] / w)\n        rgb = cv2.resize(rgb_origin, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR)\n        # remember to scale intrinsic, hold depth\n        self.intrinsic = [self.intrinsic[0] * scale, self.intrinsic[1] * scale, self.intrinsic[2] * scale, self.intrinsic[3] * scale]\n        # padding to input_size\n        padding = [123.675, 116.28, 103.53]\n        h, w = rgb.shape[:2]\n        pad_h = input_size[0] - h\n        pad_w = input_size[1] - w\n        pad_h_half = pad_h // 2\n        pad_w_half = pad_w // 2\n        rgb = cv2.copyMakeBorder(rgb, pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half,\n                                 cv2.BORDER_CONSTANT, value=padding)\n        self.pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]\n\n        #### normalize\n        mean = torch.tensor([123.675, 116.28, 103.53]).float()[:, None, None]\n        std = torch.tensor([58.395, 57.12, 57.375]).float()[:, None, None]\n        rgb = torch.from_numpy(rgb.transpose((2, 0, 1))).float()\n        rgb = torch.div((rgb - mean), std)\n        rgb = rgb[None, :, :, :].cuda()\n        return rgb\n    def unpad_transform_depth(self, pred_depth):\n        # un pad\n        pred_depth = pred_depth.squeeze()\n        pred_depth = pred_depth[self.pad_info[0]: pred_depth.shape[0] - self.pad_info[1],\n                     self.pad_info[2]: pred_depth.shape[1] - self.pad_info[3]]\n\n        # upsample to original size\n        pred_depth = torch.nn.functional.interpolate(pred_depth[None, None, :, :], self.rgb_origin.shape[:2],\n                                                     mode='bilinear').squeeze()\n        ###################### canonical camera space ######################\n\n        #### de-canonical transform\n        canonical_to_real_scale = self.intrinsic[0] / 1000.0  # 1000.0 is the focal length of canonical camera\n        pred_depth = pred_depth * canonical_to_real_scale  # now the depth is metric\n        pred_depth = torch.clamp(pred_depth, 0, 300)\n        return pred_depth\n\n\n    \"\"\"Set new intrinsic value.\"\"\"\n    def update_intrinsic(self, intrinsic):\n        self.intrinsic = intrinsic\n\n    def eval_predicted_depth(self, depth_file, pred_depth):\n        if depth_file is not None:\n            gt_depth = cv2.imread(depth_file, -1)\n            gt_depth = gt_depth / self.gt_depth_scale\n            gt_depth = torch.from_numpy(gt_depth).float().cuda()\n            assert gt_depth.shape == pred_depth.shape\n\n            mask = (gt_depth > 1e-8)\n            abs_rel_err = (torch.abs(pred_depth[mask] - gt_depth[mask]) / gt_depth[mask]).mean()\n            print('abs_rel_err:', abs_rel_err.item())"}
{"type": "source_file", "path": "dimos/models/segmentation/clipseg.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom transformers import AutoProcessor, CLIPSegForImageSegmentation\nimport torch\nimport numpy as np\n\nclass CLIPSeg:\n    def __init__(self, model_name=\"CIDAS/clipseg-rd64-refined\"):\n        self.clipseg_processor = AutoProcessor.from_pretrained(model_name)\n        self.clipseg_model = CLIPSegForImageSegmentation.from_pretrained(model_name)\n\n    def run_inference(self, image, text_descriptions):\n        inputs = self.clipseg_processor(text=text_descriptions, images=[image] * len(text_descriptions), padding=True, return_tensors=\"pt\")\n        outputs = self.clipseg_model(**inputs)\n        logits = outputs.logits\n        return logits.detach().unsqueeze(1)"}
{"type": "source_file", "path": "dimos/models/pointcloud/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/agents/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/__init__.py", "content": "\n"}
{"type": "source_file", "path": "dimos/agents/agent.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Agent framework for LLM-based autonomous systems.\n\nThis module provides a flexible foundation for creating agents that can:\n- Process image and text inputs through LLM APIs\n- Store and retrieve contextual information using semantic memory\n- Handle tool/function calling\n- Process streaming inputs asynchronously\n\nThe module offers base classes (Agent, LLMAgent) and concrete implementations\nlike OpenAIAgent that connect to specific LLM providers.\n\"\"\"\n\nfrom __future__ import annotations\n\n# Standard library imports\nimport json\nimport os\nimport threading\nimport logging\nfrom typing import Any, Dict, List, Tuple, Optional\n\n# Third-party imports\nfrom dotenv import load_dotenv\nfrom openai import NOT_GIVEN, OpenAI\nfrom pydantic import BaseModel\nimport reactivex\nfrom reactivex import Observer, create, Observable, empty, operators as RxOps, throw, just\nfrom reactivex.disposable import CompositeDisposable, Disposable\nfrom reactivex.scheduler import ThreadPoolScheduler\nfrom reactivex.subject import Subject\n\n# Local imports\nfrom dimos.agents.memory.base import AbstractAgentSemanticMemory\nfrom dimos.agents.memory.chroma_impl import AgentSemanticMemory\nfrom dimos.agents.prompt_builder.impl import PromptBuilder\nfrom dimos.agents.tokenizer.openai_impl import AbstractTokenizer, OpenAI_Tokenizer\nfrom dimos.robot.skills import AbstractSkill\nfrom dimos.stream.frame_processor import FrameProcessor\nfrom dimos.stream.video_operators import Operators as MyOps, VideoOperators as MyVidOps\nfrom dimos.utils.threadpool import get_scheduler\nfrom dimos.utils.logging_config import setup_logger\n\n# Initialize environment variables\nload_dotenv()\n\n# Initialize logger for the agent module\nlogger = setup_logger(\"dimos.agents\", level=logging.DEBUG)\n\n# Constants\n_TOKEN_BUDGET_PARTS = 4  # Number of parts to divide token budget\n_MAX_SAVED_FRAMES = 100  # Maximum number of frames to save\n\n\n# -----------------------------------------------------------------------------\n# region Agent Base Class\n# -----------------------------------------------------------------------------\nclass Agent:\n    \"\"\"Base agent that manages memory and subscriptions.\"\"\"\n\n    def __init__(self,\n                 dev_name: str = \"NA\",\n                 agent_type: str = \"Base\",\n                 agent_memory: Optional[AbstractAgentSemanticMemory] = None,\n                 pool_scheduler: Optional[ThreadPoolScheduler] = None):\n        \"\"\"\n        Initializes a new instance of the Agent.\n\n        Args:\n            dev_name (str): The device name of the agent.\n            agent_type (str): The type of the agent (e.g., 'Base', 'Vision').\n            agent_memory (AbstractAgentSemanticMemory): The memory system for the agent.\n            pool_scheduler (ThreadPoolScheduler): The scheduler to use for thread pool operations.\n                If None, the global scheduler from get_scheduler() will be used.\n        \"\"\"\n        self.dev_name = dev_name\n        self.agent_type = agent_type\n        self.agent_memory = agent_memory or AgentSemanticMemory()\n        self.disposables = CompositeDisposable()\n        self.pool_scheduler = pool_scheduler if pool_scheduler else get_scheduler()\n        self.logger = setup_logger(\n            f\"dimos.agents.{self.agent_type}.{self.dev_name}\")\n\n    def dispose_all(self):\n        \"\"\"Disposes of all active subscriptions managed by this agent.\"\"\"\n        if self.disposables:\n            self.disposables.dispose()\n        else:\n            self.logger.info(\"No disposables to dispose.\")\n\n\n# endregion Agent Base Class\n\n\n# -----------------------------------------------------------------------------\n# region LLMAgent Base Class (Generic LLM Agent)\n# -----------------------------------------------------------------------------\nclass LLMAgent(Agent):\n    \"\"\"Generic LLM agent containing common logic for LLM-based agents.\n\n    This class implements functionality for:\n      - Updating the query\n      - Querying the agent's memory (for RAG)\n      - Building prompts via a prompt builder\n      - Handling tooling callbacks in responses\n      - Subscribing to image and query streams\n      - Emitting responses as an observable stream\n\n    Subclasses must implement the `_send_query` method, which is responsible\n    for sending the prompt to a specific LLM API.\n    \n    Attributes:\n        query (str): The current query text to process.\n        prompt_builder (PromptBuilder): Handles construction of prompts.\n        skills (AbstractSkill): Available tools/functions for the agent.\n        system_query (str): System prompt for RAG context situations.\n        image_detail (str): Detail level for image processing ('low','high','auto').\n        max_input_tokens_per_request (int): Maximum input token count.\n        max_output_tokens_per_request (int): Maximum output token count.\n        max_tokens_per_request (int): Total maximum token count.\n        rag_query_n (int): Number of results to fetch from memory.\n        rag_similarity_threshold (float): Minimum similarity for RAG results.\n        frame_processor (FrameProcessor): Processes video frames.\n        output_dir (str): Directory for output files.\n        response_subject (Subject): Subject that emits agent responses.\n        process_all_inputs (bool): Whether to process every input emission (True) or \n            skip emissions when the agent is busy processing a previous input (False).\n    \"\"\"\n    logging_file_memory_lock = threading.Lock()\n\n    def __init__(self,\n                 dev_name: str = \"NA\",\n                 agent_type: str = \"LLM\",\n                 agent_memory: Optional[AbstractAgentSemanticMemory] = None,\n                 pool_scheduler: Optional[ThreadPoolScheduler] = None, \n                 process_all_inputs: bool = False,\n                 system_query: Optional[str] = None):\n        \"\"\"\n        Initializes a new instance of the LLMAgent.\n\n        Args:\n            dev_name (str): The device name of the agent.\n            agent_type (str): The type of the agent.\n            agent_memory (AbstractAgentSemanticMemory): The memory system for the agent.\n            pool_scheduler (ThreadPoolScheduler): The scheduler to use for thread pool operations.\n                If None, the global scheduler from get_scheduler() will be used.\n            process_all_inputs (bool): Whether to process every input emission (True) or \n                skip emissions when the agent is busy processing a previous input (False).\n        \"\"\"\n        super().__init__(dev_name, agent_type, agent_memory or\n                         AgentSemanticMemory(), pool_scheduler)\n        # These attributes can be configured by a subclass if needed.\n        self.query: Optional[str] = None\n        self.prompt_builder: Optional[PromptBuilder] = None\n        self.skills: Optional[AbstractSkill] = None\n        self.system_query: Optional[str] = system_query\n        self.image_detail: str = \"low\"\n        self.max_input_tokens_per_request: int = 128000\n        self.max_output_tokens_per_request: int = 16384\n        self.max_tokens_per_request: int = (self.max_input_tokens_per_request +\n                                            self.max_output_tokens_per_request)\n        self.rag_query_n: int = 4\n        self.rag_similarity_threshold: float = 0.45\n        self.frame_processor: Optional[FrameProcessor] = None\n        self.output_dir: str = os.path.join(os.getcwd(), \"assets\", \"agent\")\n        self.process_all_inputs: bool = process_all_inputs\n        os.makedirs(self.output_dir, exist_ok=True)\n        \n        # Subject for emitting responses\n        self.response_subject = Subject()\n\n    def _update_query(self, incoming_query: Optional[str]) -> None:\n        \"\"\"Updates the query if an incoming query is provided.\n\n        Args:\n            incoming_query (str): The new query text.\n        \"\"\"\n        if incoming_query is not None:\n            self.query = incoming_query\n\n    def _get_rag_context(self) -> Tuple[str, str]:\n        \"\"\"Queries the agent memory to retrieve RAG context.\n\n        Returns:\n            Tuple[str, str]: A tuple containing the formatted results (for logging)\n            and condensed results (for use in the prompt).\n        \"\"\"\n        results = self.agent_memory.query(\n            query_texts=self.query,\n            n_results=self.rag_query_n,\n            similarity_threshold=self.rag_similarity_threshold)\n        formatted_results = \"\\n\".join(\n            f\"Document ID: {doc.id}\\nMetadata: {doc.metadata}\\nContent: {doc.page_content}\\nScore: {score}\\n\"\n            for (doc, score) in results)\n        condensed_results = \" | \".join(\n            f\"{doc.page_content}\" for (doc, _) in results)\n        self.logger.info(f\"Agent Memory Query Results:\\n{formatted_results}\")\n        self.logger.info(\"=== Results End ===\")\n        return formatted_results, condensed_results\n\n    def _build_prompt(self, base64_image: Optional[str],\n                      dimensions: Optional[Tuple[int, int]],\n                      override_token_limit: bool,\n                      condensed_results: str) -> list:\n        \"\"\"Builds a prompt message using the prompt builder.\n\n        Args:\n            base64_image (str): Optional Base64-encoded image.\n            dimensions (Tuple[int, int]): Optional image dimensions.\n            override_token_limit (bool): Whether to override token limits.\n            condensed_results (str): The condensed RAG context.\n\n        Returns:\n            list: A list of message dictionaries to be sent to the LLM.\n        \"\"\"\n        # Budget for each component of the prompt\n        budgets = {\n            \"system_prompt\":\n                self.max_input_tokens_per_request // _TOKEN_BUDGET_PARTS,\n            \"user_query\":\n                self.max_input_tokens_per_request // _TOKEN_BUDGET_PARTS,\n            \"image\":\n                self.max_input_tokens_per_request // _TOKEN_BUDGET_PARTS,\n            \"rag\":\n                self.max_input_tokens_per_request // _TOKEN_BUDGET_PARTS,\n        }\n\n        # Define truncation policies for each component\n        policies = {\n            \"system_prompt\": \"truncate_end\",\n            \"user_query\": \"truncate_middle\",\n            \"image\": \"do_not_truncate\",\n            \"rag\": \"truncate_end\",\n        }\n\n        return self.prompt_builder.build(\n            user_query=self.query,\n            override_token_limit=override_token_limit,\n            base64_image=base64_image,\n            image_width=dimensions[0] if dimensions is not None else None,\n            image_height=dimensions[1] if dimensions is not None else None,\n            image_detail=self.image_detail,\n            rag_context=condensed_results,\n            system_prompt=self.system_query,\n            budgets=budgets,\n            policies=policies,\n        )\n\n    def _handle_tooling(self, response_message, messages):\n        \"\"\"Handles tooling callbacks in the response message.\n\n        If tool calls are present, the corresponding functions are executed and\n        a follow-up query is sent.\n\n        Args:\n            response_message: The response message containing tool calls.\n            messages (list): The original list of messages sent.\n\n        Returns:\n            The final response message after processing tool calls, if any.\n        \"\"\"\n\n        # TODO: Make this more generic or move implementation to OpenAIAgent.\n        # This is presently OpenAI-specific.\n        def _tooling_callback(message, messages, response_message,\n                              skills: AbstractSkill):\n            has_called_tools = False\n            new_messages = []\n            for tool_call in message.tool_calls:\n                has_called_tools = True\n                name = tool_call.function.name\n                args = json.loads(tool_call.function.arguments)\n                result = skills.call_function(name, **args)\n                self.logger.info(f\"Function Call Results: {result}\")\n                new_messages.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"content\": str(result),\n                    \"name\": name\n                })\n            if has_called_tools:\n                self.logger.info(\"Sending Another Query.\")\n                messages.append(response_message)\n                messages.extend(new_messages)\n                # Delegate to sending the query again.\n                return self._send_query(messages)\n            else:\n                self.logger.info(\"No Need for Another Query.\")\n                return None\n\n        if response_message.tool_calls is not None:\n            return _tooling_callback(response_message, messages,\n                                     response_message, self.skills)\n        return None\n\n    def _observable_query(self,\n                          observer: Observer,\n                          base64_image: Optional[str] = None,\n                          dimensions: Optional[Tuple[int, int]] = None,\n                          override_token_limit: bool = False,\n                          incoming_query: Optional[str] = None):\n        \"\"\"Prepares and sends a query to the LLM, emitting the response to the observer.\n\n        Args:\n            observer (Observer): The observer to emit responses to.\n            base64_image (str): Optional Base64-encoded image.\n            dimensions (Tuple[int, int]): Optional image dimensions.\n            override_token_limit (bool): Whether to override token limits.\n            incoming_query (str): Optional query to update the agent's query.\n\n        Raises:\n            Exception: Propagates any exceptions encountered during processing.\n        \"\"\"\n        try:\n            self._update_query(incoming_query)\n            _, condensed_results = self._get_rag_context()\n            messages = self._build_prompt(base64_image, dimensions,\n                                          override_token_limit,\n                                          condensed_results)\n            # self.logger.debug(f\"Sending Query: {messages}\")\n            self.logger.info(\"Sending Query.\")\n            response_message = self._send_query(messages)\n            self.logger.info(f\"Received Response: {response_message}\")\n            if response_message is None:\n                raise Exception(\"Response message does not exist.\")\n\n            # TODO: Make this more generic. The parsed tag and tooling handling may be OpenAI-specific.\n            # If no skills are provided or there are no tool calls, emit the response directly.\n            if (self.skills is None or\n                    self.skills.get_tools() in (None, NOT_GIVEN) or\n                    response_message.tool_calls is None):\n                final_msg = (response_message.parsed\n                             if hasattr(response_message, 'parsed') and\n                             response_message.parsed else\n                             response_message.content)\n                observer.on_next(final_msg)\n                self.response_subject.on_next(final_msg)\n            else:\n                response_message_2 = self._handle_tooling(\n                    response_message, messages)\n                final_msg = response_message_2 if response_message_2 is not None else response_message\n                if isinstance(final_msg, BaseModel): # TODO: Test\n                    final_msg = str(final_msg.content)\n                observer.on_next(final_msg)\n                self.response_subject.on_next(final_msg)\n            observer.on_completed()\n        except Exception as e:\n            self.logger.error(f\"Query failed in {self.dev_name}: {e}\")\n            observer.on_error(e)\n            self.response_subject.on_error(e)\n\n    def _send_query(self, messages: list) -> Any:\n        \"\"\"Sends the query to the LLM API.\n\n        This method must be implemented by subclasses with specifics of the LLM API.\n\n        Args:\n            messages (list): The prompt messages to be sent.\n\n        Returns:\n            Any: The response message from the LLM.\n\n        Raises:\n            NotImplementedError: Always, unless overridden.\n        \"\"\"\n        raise NotImplementedError(\n            \"Subclasses must implement _send_query method.\")\n\n    def _log_response_to_file(self, response, output_dir: str = None):\n        \"\"\"Logs the LLM response to a file.\n\n        Args:\n            response: The response message to log.\n            output_dir (str): The directory where the log file is stored.\n        \"\"\"\n        if output_dir is None:\n            output_dir = self.output_dir\n        if response is not None:\n            with self.logging_file_memory_lock:\n                log_path = os.path.join(output_dir, 'memory.txt')\n                with open(log_path, 'a') as file:\n                    file.write(f\"{self.dev_name}: {response}\\n\")\n                self.logger.info(f\"LLM Response [{self.dev_name}]: {response}\")\n\n    def subscribe_to_image_processing(\n            self, frame_observable: Observable) -> Disposable:\n        \"\"\"Subscribes to a stream of video frames for processing.\n\n        This method sets up a subscription to process incoming video frames.\n        Each frame is encoded and then sent to the LLM by directly calling the\n        _observable_query method. The response is then logged to a file.\n\n        Args:\n            frame_observable (Observable): An observable emitting video frames.\n\n        Returns:\n            Disposable: A disposable representing the subscription.\n        \"\"\"\n        # Initialize frame processor if not already set\n        if self.frame_processor is None:\n            self.frame_processor = FrameProcessor(delete_on_init=True)\n\n        print_emission_args = {\n            \"enabled\": True,\n            \"dev_name\": self.dev_name,\n            \"counts\": {}\n        }\n\n        def _process_frame(frame) -> Observable:\n            \"\"\"\n            Processes a single frame by:\n            - Logging the receipt\n            - Exporting the frame as a JPEG\n            - Encoding the image\n            - Filtering out invalid results\n            - Sending the encoded image to the LLM via _observable_query\n            \n            Returns:\n                An observable that emits the response from _observable_query.\n            \"\"\"\n            return just(frame).pipe(\n                MyOps.print_emission(id='B', **print_emission_args),\n                RxOps.observe_on(self.pool_scheduler),\n                MyOps.print_emission(id='C', **print_emission_args),\n                RxOps.subscribe_on(self.pool_scheduler),\n                MyOps.print_emission(id='D', **print_emission_args),\n                MyVidOps.with_jpeg_export(self.frame_processor,\n                                          suffix=f\"{self.dev_name}_frame_\",\n                                          save_limit=_MAX_SAVED_FRAMES),\n                MyOps.print_emission(id='E', **print_emission_args),\n                MyVidOps.encode_image(),\n                MyOps.print_emission(id='F', **print_emission_args),\n                RxOps.filter(lambda base64_and_dims: base64_and_dims is not None\n                             and base64_and_dims[0] is not None and\n                             base64_and_dims[1] is not None),\n                MyOps.print_emission(id='G', **print_emission_args),\n                RxOps.flat_map(lambda base64_and_dims: create(\n                    lambda observer, _: self._observable_query(\n                        observer,\n                        base64_image=base64_and_dims[0],\n                        dimensions=base64_and_dims[1],\n                        incoming_query=self.system_query))),\n                MyOps.print_emission(id='H', **print_emission_args),\n            )\n\n        # Use a mutable flag to ensure only one frame is processed at a time.\n        is_processing = [False]\n\n        def process_if_free(frame):\n            if not self.process_all_inputs and is_processing[0]:\n                # Drop frame if a request is in progress and process_all_inputs is False\n                return empty()\n            else:\n                is_processing[0] = True\n                return _process_frame(frame).pipe(\n                    MyOps.print_emission(id='I', **print_emission_args),\n                    RxOps.observe_on(self.pool_scheduler),\n                    MyOps.print_emission(id='J', **print_emission_args),\n                    RxOps.subscribe_on(self.pool_scheduler),\n                    MyOps.print_emission(id='K', **print_emission_args),\n                    RxOps.do_action(\n                        on_completed=lambda: is_processing.__setitem__(\n                            0, False),\n                        on_error=lambda e: is_processing.__setitem__(0, False)),\n                    MyOps.print_emission(id='L', **print_emission_args),\n                )\n\n        observable = frame_observable.pipe(\n            MyOps.print_emission(id='A', **print_emission_args),\n            RxOps.flat_map(process_if_free),\n            MyOps.print_emission(id='M', **print_emission_args),\n        )\n\n        disposable = observable.subscribe(\n            on_next=lambda response: self._log_response_to_file(\n                response, self.output_dir),\n            on_error=lambda e: self.logger.error(f\"Error encountered: {e}\"),\n            on_completed=lambda: self.logger.info(\n                f\"Stream processing completed for {self.dev_name}\"))\n        self.disposables.add(disposable)\n        return disposable\n\n    def subscribe_to_query_processing(\n            self, query_observable: Observable) -> Disposable:\n        \"\"\"Subscribes to a stream of queries for processing.\n\n        This method sets up a subscription to process incoming queries by directly\n        calling the _observable_query method. The responses are logged to a file.\n\n        Args:\n            query_observable (Observable): An observable emitting queries.\n\n        Returns:\n            Disposable: A disposable representing the subscription.\n        \"\"\"\n        print_emission_args = {\n            \"enabled\": True,\n            \"dev_name\": self.dev_name,\n            \"counts\": {}\n        }\n\n        def _process_query(query) -> Observable:\n            \"\"\"\n            Processes a single query by logging it and passing it to _observable_query.\n            Returns an observable that emits the LLM response.\n            \"\"\"\n            return just(query).pipe(\n                MyOps.print_emission(id='Pr A', **print_emission_args),\n                RxOps.flat_map(lambda query: create(\n                    lambda observer, _: self._observable_query(\n                        observer, incoming_query=query))),\n                MyOps.print_emission(id='Pr B', **print_emission_args),\n            )\n\n        # A mutable flag indicating whether a query is currently being processed.\n        is_processing = [False]\n\n        def process_if_free(query):\n            self.logger.info(f\"Processing Query: {query}\")\n            if not self.process_all_inputs and is_processing[0]:\n                # Drop query if a request is already in progress and process_all_inputs is False\n                return empty()\n            else:\n                is_processing[0] = True\n                self.logger.info(\"Processing Query.\")\n                return _process_query(query).pipe(\n                    MyOps.print_emission(id='B', **print_emission_args),\n                    RxOps.observe_on(self.pool_scheduler),\n                    MyOps.print_emission(id='C', **print_emission_args),\n                    RxOps.subscribe_on(self.pool_scheduler),\n                    MyOps.print_emission(id='D', **print_emission_args),\n                    RxOps.do_action(\n                        on_completed=lambda: is_processing.__setitem__(\n                            0, False),\n                        on_error=lambda e: is_processing.__setitem__(0, False)),\n                    MyOps.print_emission(id='E', **print_emission_args),\n                )\n\n        observable = query_observable.pipe(\n            MyOps.print_emission(id='A', **print_emission_args),\n            RxOps.flat_map(lambda query: process_if_free(query)),\n            MyOps.print_emission(id='F', **print_emission_args))\n\n        disposable = observable.subscribe(\n            on_next=lambda response: self._log_response_to_file(\n                response, self.output_dir),\n            on_error=lambda e: self.logger.error(\n                f\"Error processing query for {self.dev_name}: {e}\"),\n            on_completed=lambda: self.logger.info(\n                f\"Stream processing completed for {self.dev_name}\"))\n        self.disposables.add(disposable)\n        return disposable\n\n    def get_response_observable(self) -> Observable:\n        \"\"\"Gets an observable that emits responses from this agent.\n        \n        Returns:\n            Observable: An observable that emits string responses from the agent.\n        \"\"\"\n        return self.response_subject.pipe(\n            RxOps.observe_on(self.pool_scheduler), \n            RxOps.subscribe_on(self.pool_scheduler),\n            RxOps.share())\n\n    def dispose_all(self):\n        \"\"\"Disposes of all active subscriptions managed by this agent.\"\"\"\n        super().dispose_all()\n        self.response_subject.on_completed()\n\n\n# endregion LLMAgent Base Class (Generic LLM Agent)\n\n\n# -----------------------------------------------------------------------------\n# region OpenAIAgent Subclass (OpenAI-Specific Implementation)\n# -----------------------------------------------------------------------------\nclass OpenAIAgent(LLMAgent):\n    \"\"\"OpenAI agent implementation that uses OpenAI's API for processing.\n\n    This class implements the _send_query method to interact with OpenAI's API.\n    It also sets up OpenAI-specific parameters, such as the client, model name,\n    tokenizer, and response model.\n    \"\"\"\n\n    def __init__(self,\n                 dev_name: str,\n                 agent_type: str = \"Vision\",\n                 query: str = \"What do you see?\",\n                 input_query_stream: Optional[Observable] = None,\n                 input_video_stream: Optional[Observable] = None,\n                 output_dir: str = os.path.join(os.getcwd(), \"assets\",\n                                                \"agent\"),\n                 agent_memory: Optional[AbstractAgentSemanticMemory] = None,\n                 system_query: Optional[str] = None,\n                 max_input_tokens_per_request: int = 128000,\n                 max_output_tokens_per_request: int = 16384,\n                 model_name: str = \"gpt-4o\",\n                 prompt_builder: Optional[PromptBuilder] = None,\n                 tokenizer: Optional[AbstractTokenizer] = None,\n                 rag_query_n: int = 4,\n                 rag_similarity_threshold: float = 0.45,\n                 skills: Optional[AbstractSkill] = None,\n                 response_model: Optional[BaseModel] = None,\n                 frame_processor: Optional[FrameProcessor] = None,\n                 image_detail: str = \"low\",\n                 pool_scheduler: Optional[ThreadPoolScheduler] = None,\n                 process_all_inputs: Optional[bool] = None):\n        \"\"\"\n        Initializes a new instance of the OpenAIAgent.\n\n        Args:\n            dev_name (str): The device name of the agent.\n            agent_type (str): The type of the agent.\n            query (str): The default query text.\n            input_query_stream (Observable): An observable for query input.\n            input_video_stream (Observable): An observable for video frames.\n            output_dir (str): Directory for output files.\n            agent_memory (AbstractAgentSemanticMemory): The memory system.\n            system_query (str): The system prompt to use with RAG context.\n            max_input_tokens_per_request (int): Maximum tokens for input.\n            max_output_tokens_per_request (int): Maximum tokens for output.\n            model_name (str): The OpenAI model name to use.\n            prompt_builder (PromptBuilder): Custom prompt builder.\n            tokenizer (AbstractTokenizer): Custom tokenizer for token counting.\n            rag_query_n (int): Number of results to fetch in RAG queries.\n            rag_similarity_threshold (float): Minimum similarity for RAG results.\n            skills (AbstractSkill): Skills available to the agent.\n            response_model (BaseModel): Optional Pydantic model for responses.\n            frame_processor (FrameProcessor): Custom frame processor.\n            image_detail (str): Detail level for images (\"low\", \"high\", \"auto\").\n            pool_scheduler (ThreadPoolScheduler): The scheduler to use for thread pool operations.\n                If None, the global scheduler from get_scheduler() will be used.\n            process_all_inputs (bool): Whether to process all inputs or skip when busy.\n                If None, defaults to True for text queries, False for video streams.\n        \"\"\"\n        # Determine appropriate default for process_all_inputs if not provided\n        if process_all_inputs is None:\n            # Default to True for text queries, False for video streams\n            if input_query_stream is not None and input_video_stream is None:\n                process_all_inputs = True\n            else:\n                process_all_inputs = False\n                \n        super().__init__(\n            dev_name=dev_name,\n            agent_type=agent_type,\n            agent_memory=agent_memory,\n            pool_scheduler=pool_scheduler,\n            process_all_inputs=process_all_inputs,\n            system_query=system_query\n        )\n        self.client = OpenAI()\n        self.query = query\n        self.output_dir = output_dir\n        os.makedirs(self.output_dir, exist_ok=True)\n\n        # Configure skills.\n        self.skills = skills\n\n        self.response_model = response_model if response_model is not None else NOT_GIVEN\n        self.model_name = model_name\n        self.prompt_builder = prompt_builder or PromptBuilder(self.model_name)\n        self.tokenizer = tokenizer or OpenAI_Tokenizer(\n            model_name=self.model_name)\n        self.rag_query_n = rag_query_n\n        self.rag_similarity_threshold = rag_similarity_threshold\n        self.image_detail = image_detail\n        self.max_output_tokens_per_request = max_output_tokens_per_request\n        self.max_input_tokens_per_request = max_input_tokens_per_request\n        self.max_tokens_per_request = max_input_tokens_per_request + max_output_tokens_per_request\n\n        # Add static context to memory.\n        self._add_context_to_memory()\n\n        self.frame_processor = frame_processor or FrameProcessor(\n            delete_on_init=True)\n        self.input_video_stream = input_video_stream\n        self.input_query_stream = input_query_stream\n\n        # Ensure only one input stream is provided.\n        if self.input_video_stream is not None and self.input_query_stream is not None:\n            raise ValueError(\n                \"More than one input stream provided. Please provide only one input stream.\"\n            )\n\n        if self.input_video_stream is not None:\n            self.logger.info(\"Subscribing to input video stream...\")\n            self.disposables.add(\n                self.subscribe_to_image_processing(self.input_video_stream))\n        if self.input_query_stream is not None:\n            self.logger.info(\"Subscribing to input query stream...\")\n            self.disposables.add(\n                self.subscribe_to_query_processing(self.input_query_stream))\n\n        self.logger.info(\"OpenAI Agent Initialized.\")\n\n    def _add_context_to_memory(self):\n        \"\"\"Adds initial context to the agent's memory.\"\"\"\n        context_data = [\n            (\"id0\",\n             \"Optical Flow is a technique used to track the movement of objects in a video sequence.\"\n             ),\n            (\"id1\",\n             \"Edge Detection is a technique used to identify the boundaries of objects in an image.\"\n             ),\n            (\"id2\",\n             \"Video is a sequence of frames captured at regular intervals.\"),\n            (\"id3\",\n             \"Colors in Optical Flow are determined by the movement of light, and can be used to track the movement of objects.\"\n             ),\n            (\"id4\",\n             \"Json is a data interchange format that is easy for humans to read and write, and easy for machines to parse and generate.\"\n             ),\n        ]\n        for doc_id, text in context_data:\n            self.agent_memory.add_vector(doc_id, text)\n\n    def _send_query(self, messages: list) -> Any:\n        \"\"\"Sends the query to OpenAI's API.\n\n        Depending on whether a response model is provided, the appropriate API\n        call is made.\n\n        Args:\n            messages (list): The prompt messages to send.\n\n        Returns:\n            The response message from OpenAI.\n\n        Raises:\n            Exception: If no response message is returned.\n            ConnectionError: If there's an issue connecting to the API.\n            ValueError: If the messages or other parameters are invalid.\n        \"\"\"\n        try:\n            if self.response_model is not NOT_GIVEN:\n                response = self.client.beta.chat.completions.parse(\n                    model=self.model_name,\n                    messages=messages,\n                    response_format=self.response_model,\n                    tools=(self.skills.get_tools() if self.skills is not None else NOT_GIVEN),\n                    max_tokens=self.max_output_tokens_per_request,\n                )\n            else:\n                response = self.client.chat.completions.create(\n                    model=self.model_name,\n                    messages=messages,\n                    max_tokens=self.max_output_tokens_per_request,\n                    tools=(self.skills.get_tools()\n                           if self.skills is not None else NOT_GIVEN),\n                )\n\n            response_message = response.choices[0].message\n            if response_message is None:\n                self.logger.error(\"Response message does not exist.\")\n                raise Exception(\"Response message does not exist.\")\n            return response_message\n        except ConnectionError as ce:\n            self.logger.error(f\"Connection error with API: {ce}\")\n            raise\n        except ValueError as ve:\n            self.logger.error(f\"Invalid parameters: {ve}\")\n            raise\n        except Exception as e:\n            self.logger.error(f\"Unexpected error in API call: {e}\")\n            raise\n\n    def stream_query(self, query_text: str) -> Observable:\n        \"\"\"Creates an observable that processes a text query and emits the response.\n        \n        This method provides a simple way to send a text query and get an observable\n        stream of the response. It's designed for one-off queries rather than\n        continuous processing of input streams.\n        \n        Args:\n            query_text (str): The query text to process.\n            \n        Returns:\n            Observable: An observable that emits the response as a string.\n        \"\"\"\n        return create(lambda observer, _: self._observable_query(\n            observer, incoming_query=query_text))\n\n\n# endregion OpenAIAgent Subclass (OpenAI-Specific Implementation)\n"}
{"type": "source_file", "path": "dimos/agents/memory/base.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom abc import ABC, abstractmethod\nimport logging\nfrom dimos.exceptions.agent_memory_exceptions import UnknownConnectionTypeError, AgentMemoryConnectionError\n\n# TODO\n# class AbstractAgentMemory(ABC):\n\n# TODO\n# class AbstractAgentSymbolicMemory(AbstractAgentMemory):\n\nclass AbstractAgentSemanticMemory(): # AbstractAgentMemory):\n    def __init__(self, connection_type='local', **kwargs):\n        \"\"\"\n        Initialize with dynamic connection parameters.\n        Args:\n            connection_type (str): 'local' for a local database, 'remote' for a remote connection.\n        Raises:\n            UnknownConnectionTypeError: If an unrecognized connection type is specified.\n            AgentMemoryConnectionError: If initializing the database connection fails.\n        \"\"\"\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.logger.info('Initializing AgentMemory with connection type: %s', connection_type)\n        self.connection_params = kwargs\n        self.db_connection = None  # Holds the conection, whether local or remote, to the database used.\n        \n        if connection_type not in ['local', 'remote']:\n            error = UnknownConnectionTypeError(f\"Invalid connection_type {connection_type}. Expected 'local' or 'remote'.\")\n            self.logger.error(str(error))\n            raise error\n\n        try:\n            if connection_type == 'remote':\n                self.connect()\n            elif connection_type == 'local':\n                self.create()\n        except Exception as e:\n            self.logger.error(\"Failed to initialize database connection: %s\", str(e), exc_info=True)\n            raise AgentMemoryConnectionError(\"Initialization failed due to an unexpected error.\", cause=e) from e\n\n    \n    @abstractmethod\n    def connect(self):\n        \"\"\"Establish a connection to the data store using dynamic parameters specified during initialization.\"\"\"\n\n    @abstractmethod\n    def create(self):\n        \"\"\"Create a local instance of the data store tailored to specific requirements.\"\"\"\n\n    ## Create ##\n    @abstractmethod\n    def add_vector(self, vector_id, vector_data):\n        \"\"\"Add a vector to the database.\n        Args:\n            vector_id (any): Unique identifier for the vector.\n            vector_data (any): The actual data of the vector to be stored.\n        \"\"\"\n\n    ## Read ##\n    @abstractmethod\n    def get_vector(self, vector_id):\n        \"\"\"Retrieve a vector from the database by its identifier.\n        Args:\n            vector_id (any): The identifier of the vector to retrieve.\n        \"\"\"\n    \n    @abstractmethod\n    def query(self, query_texts, n_results=4, similarity_threshold=None):\n        \"\"\"Performs a semantic search in the vector database.\n\n        Args:\n            query_texts (Union[str, List[str]]): The query text or list of query texts to search for.\n            n_results (int, optional): Number of results to return. Defaults to 4.\n            similarity_threshold (float, optional): Minimum similarity score for results to be included [0.0, 1.0]. Defaults to None.\n\n        Returns:\n            List[Tuple[Document, Optional[float]]]: A list of tuples containing the search results. Each tuple\n            contains:\n                Document: The retrieved document object.\n                Optional[float]: The similarity score of the match, or None if not applicable.\n\n        Raises:\n            ValueError: If query_texts is empty or invalid.\n            ConnectionError: If database connection fails during query.\n        \"\"\"\n\n    ## Update ##\n    @abstractmethod\n    def update_vector(self, vector_id, new_vector_data):\n        \"\"\"Update an existing vector in the database.\n        Args:\n            vector_id (any): The identifier of the vector to update.\n            new_vector_data (any): The new data to replace the existing vector data.\n        \"\"\"\n\n    ## Delete ##\n    @abstractmethod\n    def delete_vector(self, vector_id):\n        \"\"\"Delete a vector from the database using its identifier.\n        Args:\n            vector_id (any): The identifier of the vector to delete.\n        \"\"\"\n\n\n# query(string, metadata/tag, n_rets, kwargs)\n\n# query by string, timestamp, id, n_rets\n\n# (some sort of tag/metadata)\n\n# temporal\n\n"}
{"type": "source_file", "path": "dimos/models/depth/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/models/segmentation/sam.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom transformers import SamModel, SamProcessor\nimport torch\nimport numpy as np\n\nclass SAM:\n    def __init__(self, model_name=\"facebook/sam-vit-huge\", device=\"cuda\"):\n        self.device = device\n        self.sam_model = SamModel.from_pretrained(model_name).to(self.device)\n        self.sam_processor = SamProcessor.from_pretrained(model_name)\n\n    def run_inference_from_points(self, image, points):\n        sam_inputs = self.sam_processor(image, input_points=points, return_tensors=\"pt\").to(self.device)\n        with torch.no_grad():\n            sam_outputs = self.sam_model(**sam_inputs)\n        return self.sam_processor.image_processor.post_process_masks(sam_outputs.pred_masks.cpu(), sam_inputs[\"original_sizes\"].cpu(), sam_inputs[\"reshaped_input_sizes\"].cpu())\n"}
{"type": "source_file", "path": "dimos/agents/memory/chroma_impl.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom dimos.agents.memory.base import AbstractAgentSemanticMemory\n\nimport chromadb\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_chroma import Chroma\nimport os\n\nclass AgentSemanticMemory(AbstractAgentSemanticMemory):\n    def __init__(self, collection_name=\"my_collection\"):\n        \"\"\"Initialize the connection to the local Chroma DB.\"\"\"\n        self.collection_name = collection_name\n        super().__init__(connection_type='local')\n\n    def connect(self):\n        # Stub\n        return super().connect()\n\n    def create(self):\n        \"\"\"Connect locally, creating the ChromaDB client.\"\"\"\n\n        # Get OpenAI key\n        self.OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n        if not self.OPENAI_API_KEY:\n            raise Exception(\"OpenAI key was not specified.\")\n\n        # Set embeddings\n        self.embeddings = OpenAIEmbeddings(\n            model=\"text-embedding-3-large\",\n            dimensions=1024,\n            api_key=self.OPENAI_API_KEY,\n        )\n\n        # Create the local database\n        self.db_connection = Chroma(\n            collection_name=self.collection_name,\n            embedding_function=self.embeddings,\n            collection_metadata={\"hnsw:space\": \"cosine\"}\n        )\n\n    def add_vector(self, vector_id, vector_data):\n        \"\"\"Add a vector to the ChromaDB collection.\"\"\"\n        if not self.db_connection:\n            raise Exception(\"Collection not initialized. Call connect() first.\")\n        self.db_connection.add_texts(\n            ids=[vector_id],\n            texts=[vector_data],\n            metadatas=[{\"name\": vector_id}],\n        )\n\n    def get_vector(self, vector_id):\n        \"\"\"Retrieve a vector from the ChromaDB by its identifier.\"\"\"\n        result = self.db_connection.get(include=['embeddings'], ids=[vector_id])\n        return result\n\n    def query(self, query_texts, n_results=4, similarity_threshold=None):\n        \"\"\"Query the collection with a specific text and return up to n results.\"\"\"\n        if not self.db_connection:\n            raise Exception(\"Collection not initialized. Call connect() first.\")\n        \n        if similarity_threshold is not None:\n            if not (0 <= similarity_threshold <= 1):\n                raise ValueError(\"similarity_threshold must be between 0 and 1.\")\n            return self.db_connection.similarity_search_with_relevance_scores(\n                query=query_texts,\n                k=n_results,\n                score_threshold=similarity_threshold\n            )\n        else:\n            documents = self.db_connection.similarity_search(\n                query=query_texts,\n                k=n_results\n            )\n            return [(doc, None) for doc in documents]\n\n    def update_vector(self, vector_id, new_vector_data):\n        # TODO\n        return super().connect()\n\n    def delete_vector(self, vector_id):\n        \"\"\"Delete a vector from the ChromaDB using its identifier.\"\"\"\n        if not self.my_collection:\n            raise Exception(\"Collection not initialized. Call connect() first.\")\n        self.my_collection.delete(ids=[vector_id])\n    "}
{"type": "source_file", "path": "dimos/models/labels/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/agents/memory/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/agents/agent_config.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import List\nfrom dimos.agents.agent import Agent\n\nclass AgentConfig:\n    def __init__(self, agents: List[Agent] = None):\n        \"\"\"\n        Initialize an AgentConfig with a list of agents.\n\n        Args:\n            agents (List[Agent], optional): List of Agent instances. Defaults to empty list.\n        \"\"\"\n        self.agents = agents if agents is not None else []\n\n    def add_agent(self, agent: Agent):\n        \"\"\"\n        Add an agent to the configuration.\n\n        Args:\n            agent (Agent): Agent instance to add\n        \"\"\"\n        self.agents.append(agent)\n\n    def remove_agent(self, agent: Agent):\n        \"\"\"\n        Remove an agent from the configuration.\n\n        Args:\n            agent (Agent): Agent instance to remove\n        \"\"\"\n        if agent in self.agents:\n            self.agents.remove(agent)\n\n    def get_agents(self) -> List[Agent]:\n        \"\"\"\n        Get the list of configured agents.\n\n        Returns:\n            List[Agent]: List of configured agents\n        \"\"\"\n        return self.agents\n"}
{"type": "source_file", "path": "dimos/models/labels/llava-34b.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport os\n\n# llava v1.6\nfrom llama_cpp import Llama\nfrom llama_cpp.llama_chat_format import Llava15ChatHandler\n\nfrom vqasynth.datasets.utils import image_to_base64_data_uri\n\nclass Llava:\n    def __init__(self, mmproj=f\"{os.getcwd()}/models/mmproj-model-f16.gguf\", model_path=f\"{os.getcwd()}/models/llava-v1.6-34b.Q4_K_M.gguf\", gpu=True):\n        chat_handler = Llava15ChatHandler(clip_model_path=mmproj, verbose=True)\n        n_gpu_layers = 0\n        if gpu:\n           n_gpu_layers = -1\n        self.llm = Llama(model_path=model_path, chat_handler=chat_handler, n_ctx=2048, logits_all=True, n_gpu_layers=n_gpu_layers)\n\n    def run_inference(self, image, prompt, return_json=True):\n        data_uri = image_to_base64_data_uri(image)\n        res = self.llm.create_chat_completion(\n             messages = [\n                 {\"role\": \"system\", \"content\": \"You are an assistant who perfectly describes images.\"},\n                 {\n                     \"role\": \"user\",\n                     \"content\": [\n                         {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}},\n                         {\"type\" : \"text\", \"text\": prompt}\n                    ]\n                 }\n               ]\n             )\n        if return_json:\n\n            return list(set(self.extract_descriptions_from_incomplete_json(res[\"choices\"][0][\"message\"][\"content\"])))\n\n        return res[\"choices\"][0][\"message\"][\"content\"]\n\n    def extract_descriptions_from_incomplete_json(self, json_like_str):\n        last_object_idx = json_like_str.rfind(',\"object')\n\n        if last_object_idx != -1:\n            json_str = json_like_str[:last_object_idx] + '}'\n        else:\n            json_str = json_like_str.strip()\n            if not json_str.endswith('}'):\n                json_str += '}'\n\n        try:\n            json_obj = json.loads(json_str)\n            descriptions = [details['description'].replace(\".\",\"\") for key, details in json_obj.items() if 'description' in details]\n\n            return descriptions\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Error parsing JSON: {e}\")\n"}
{"type": "source_file", "path": "dimos/agents/planning_agent.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport threading\nfrom typing import List, Optional, Dict, Union, Literal\nimport json\nfrom reactivex import Subject, Observable, disposable, create\nfrom reactivex import operators as ops\nfrom openai import OpenAI, NOT_GIVEN\nimport time\nimport logging\nfrom dimos.robot.skills import AbstractSkill\nfrom dimos.agents.agent import OpenAIAgent\nfrom dimos.utils.logging_config import setup_logger\nfrom textwrap import dedent\nfrom pydantic import BaseModel, Field\n\n# For response validation\nclass PlanningAgentResponse(BaseModel):\n    type: Literal[\"dialogue\", \"plan\"]\n    content: List[str]\n    needs_confirmation: bool\n\nclass PlanningAgent(OpenAIAgent):\n    \"\"\"Agent that plans and breaks down tasks through dialogue.\n    \n    This agent specializes in:\n    1. Understanding complex tasks through dialogue\n    2. Breaking tasks into concrete, executable steps\n    3. Refining plans based on user feedback\n    4. Streaming individual steps to ExecutionAgents\n    \n    The agent maintains conversation state and can refine plans until\n    the user confirms they are ready to execute.\n    \"\"\"\n    \n    def __init__(self,\n                 dev_name: str = \"PlanningAgent\",\n                 model_name: str = \"gpt-4\",\n                 input_query_stream: Optional[Observable] = None,\n                 use_terminal: bool = False,\n                 skills: Optional[AbstractSkill] = None):\n        \"\"\"Initialize the planning agent.\n        \n        Args:\n            dev_name: Name identifier for the agent\n            model_name: OpenAI model to use\n            input_query_stream: Observable stream of user queries\n            use_terminal: Whether to enable terminal input\n            skills: Available skills/functions for the agent\n        \"\"\"\n        # Planning state\n        self.conversation_history = []\n        self.current_plan = []\n        self.plan_confirmed = False\n        self.latest_response = None\n        \n        # Build system prompt\n        skills_list = []\n        if skills is not None:\n            skills_list = skills.get_tools()\n        \n        system_query = dedent(f\"\"\"\n            You are a Robot planning assistant that helps break down tasks into concrete, executable steps.\n            Your goal is to:\n            1. Break down the task into clear, sequential steps\n            2. Refine the plan based on user feedback as needed\n            3. Only finalize the plan when the user explicitly confirms\n\n            You have the following skills at your disposal:\n            {skills_list}\n\n            IMPORTANT: You MUST ALWAYS respond with ONLY valid JSON in the following format, with no additional text or explanation:\n            {{\n                \"type\": \"dialogue\" | \"plan\",\n                \"content\": string | list[string],\n                \"needs_confirmation\": boolean\n            }}\n\n            Your goal is to:\n            1. Understand the user's task through dialogue\n            2. Break it down into clear, sequential steps\n            3. Refine the plan based on user feedback\n            4. Only finalize the plan when the user explicitly confirms\n\n            For dialogue responses, use:\n            {{\n                \"type\": \"dialogue\",\n                \"content\": \"Your message to the user\",\n                \"needs_confirmation\": false\n            }}\n\n            For plan proposals, use:\n            {{\n                \"type\": \"plan\",\n                \"content\": [\"Execute\", \"Execute\", ...],\n                \"needs_confirmation\": true\n            }}\n\n            Remember: ONLY output valid JSON, no other text.\"\"\")\n\n        # Initialize OpenAIAgent with our configuration\n        super().__init__(\n            dev_name=dev_name,\n            agent_type=\"Planning\",\n            query=\"\",  # Will be set by process_user_input\n            model_name=model_name,\n            input_query_stream=input_query_stream,\n            system_query=system_query,\n            max_output_tokens_per_request=1000,\n            response_model=PlanningAgentResponse\n        )\n        self.logger.info(\"Planning agent initialized\")\n\n        # Set up terminal mode if requested\n        self.use_terminal = use_terminal\n        use_terminal = False\n        if use_terminal:\n            # Start terminal interface in a separate thread\n            self.logger.info(\"Starting terminal interface in a separate thread\")\n            terminal_thread = threading.Thread(target=self.start_terminal_interface, daemon=True)\n            terminal_thread.start()\n            \n    def _handle_response(self, response) -> None:\n        \"\"\"Handle the agent's response and update state.\n        \n        Args:\n            response: ParsedChatCompletionMessage containing PlanningAgentResponse\n        \"\"\"\n        print(\"handle response\", response)\n        print(\"handle response type\", type(response))\n        \n        # Extract the PlanningAgentResponse from parsed field if available\n        planning_response = response.parsed if hasattr(response, 'parsed') else response\n        print(\"planning response\", planning_response)\n        print(\"planning response type\", type(planning_response))\n        # Convert to dict for storage in conversation history\n        response_dict = planning_response.model_dump()\n        self.conversation_history.append(response_dict)\n        \n        # If it's a plan, update current plan\n        if planning_response.type == \"plan\":\n            self.logger.info(f\"Updating current plan: {planning_response.content}\")\n            self.current_plan = planning_response.content\n            \n        # Store latest response\n        self.latest_response = response_dict\n            \n\n    def _stream_plan(self) -> None:\n        \"\"\"Stream each step of the confirmed plan.\"\"\"\n        self.logger.info(\"Starting to stream plan steps\")\n        self.logger.debug(f\"Current plan: {self.current_plan}\")\n\n        for i, step in enumerate(self.current_plan, 1):\n            self.logger.info(f\"Streaming step {i}: {step}\")\n            # Add a small delay between steps to ensure they're processed\n            time.sleep(0.5)\n            try:\n                self.response_subject.on_next(str(step))\n                self.logger.debug(f\"Successfully emitted step {i} to response_subject\")\n            except Exception as e:\n                self.logger.error(f\"Error emitting step {i}: {e}\")\n                \n        self.logger.info(\"Plan streaming completed\")\n        self.response_subject.on_completed()\n    \n    def _send_query(self, messages: list) -> PlanningAgentResponse:\n        \"\"\"Send query to OpenAI and parse the response.\n        \n        Extends OpenAIAgent's _send_query to handle planning-specific response formats.\n        \n        Args:\n            messages: List of message dictionaries\n            \n        Returns:\n            PlanningAgentResponse: Validated response with type, content, and needs_confirmation\n        \"\"\"\n        \n        try:\n            return super()._send_query(messages)\n        except Exception as e:\n            self.logger.error(f\"Caught exception in _send_query: {str(e)}\")\n            return PlanningAgentResponse(\n                type=\"dialogue\",\n                content=f\"Error: {str(e)}\",\n                needs_confirmation=False\n            )\n\n    def process_user_input(self, user_input: str) -> None:\n        \"\"\"Process user input and generate appropriate response.\n        \n        Args:\n            user_input: The user's message\n        \"\"\"\n        if not user_input:\n            return\n            \n        # Check for plan confirmation\n        if self.current_plan and user_input.lower() in [\"yes\", \"y\", \"confirm\"]:\n            self.logger.info(\"Plan confirmation received\")\n            self.plan_confirmed = True\n            # Create a proper PlanningAgentResponse with content as a list\n            confirmation_msg = PlanningAgentResponse(\n                type=\"dialogue\",\n                content=\"Plan confirmed! Streaming steps to execution...\",\n                needs_confirmation=False\n            )\n            self._handle_response(confirmation_msg)\n            self._stream_plan()\n            return\n            \n        # Build messages for OpenAI with conversation history\n        messages = [\n            {\"role\": \"system\", \"content\": self.system_query}  # Using system_query from OpenAIAgent\n        ]\n        \n        # Add the new user input to conversation history\n        self.conversation_history.append({\n            \"type\": \"user_message\",\n            \"content\": user_input\n        })\n        \n        # Add complete conversation history including both user and assistant messages\n        for msg in self.conversation_history:\n            if msg[\"type\"] == \"user_message\":\n                messages.append({\"role\": \"user\", \"content\": msg[\"content\"]})\n            elif msg[\"type\"] == \"dialogue\":\n                messages.append({\"role\": \"assistant\", \"content\": msg[\"content\"]})\n            elif msg[\"type\"] == \"plan\":\n                plan_text = \"Here's my proposed plan:\\n\" + \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(msg[\"content\"]))\n                messages.append({\"role\": \"assistant\", \"content\": plan_text})\n        \n        # Get and handle response\n        response = self._send_query(messages)\n        self._handle_response(response)\n\n    def start_terminal_interface(self):\n        \"\"\"Start the terminal interface for input/output.\"\"\"\n\n        time.sleep(5) # buffer time for clean terminal interface printing\n        print(\"=\" * 50)\n        print(\"\\nDimOS Action PlanningAgent\\n\")\n        print(\"I have access to your Robot() and Robot Skills()\")\n        print(\"Describe your task and I'll break it down into steps using your skills as a reference.\")\n        print(\"Once you're happy with the plan, type 'yes' to execute it.\")\n        print(\"Type 'quit' to exit.\\n\")\n        \n        while True:\n            try:\n                print(\"=\" * 50)\n                user_input = input(\"USER > \")\n                if user_input.lower() in ['quit', 'exit']:\n                    break\n                    \n                self.process_user_input(user_input)\n                \n                # Display response\n                if self.latest_response[\"type\"] == \"dialogue\":\n                    print(f\"\\nPlanner: {self.latest_response['content']}\")\n                elif self.latest_response[\"type\"] == \"plan\":\n                    print(\"\\nProposed Plan:\")\n                    for i, step in enumerate(self.latest_response[\"content\"], 1):\n                        print(f\"{i}. {step}\")\n                    if self.latest_response[\"needs_confirmation\"]:\n                        print(\"\\nDoes this plan look good? (yes/no)\")\n                        \n                if self.plan_confirmed:\n                    print(\"\\nPlan confirmed! Streaming steps to execution...\")\n                    break\n                    \n            except KeyboardInterrupt:\n                print(\"\\nStopping...\")\n                break\n            except Exception as e:\n                print(f\"\\nError: {e}\")\n                break\n    \n    def get_response_observable(self) -> Observable:\n        \"\"\"Gets an observable that emits responses from this agent.\n\n        This method processes the response stream from the parent class,\n        extracting content from `PlanningAgentResponse` objects and flattening\n        any lists of plan steps for emission.\n        \n        Returns:\n            Observable: An observable that emits plan steps from the agent.\n        \"\"\"\n        def extract_content(response) -> List[str]:\n            if isinstance(response, PlanningAgentResponse):\n                if response.type == \"plan\":\n                    return response.content  # List of steps to be emitted individually\n                else:  # dialogue type\n                    return [response.content]  # Wrap single dialogue message in a list\n            else:\n                return [str(response)]  # Wrap non-PlanningAgentResponse in a list\n\n        # Get base observable from parent class\n        base_observable = super().get_response_observable()\n\n        # Process the stream: extract content and flatten plan lists\n        return base_observable.pipe(\n            ops.map(extract_content),\n            ops.flat_map(lambda items: items)  # Flatten the list of items\n        )\n"}
{"type": "source_file", "path": "dimos/models/segmentation/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/environment/agent_environment.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport cv2\nimport numpy as np\nfrom pathlib import Path\nfrom typing import List, Union\nfrom .environment import Environment\n\nclass AgentEnvironment(Environment):\n    def __init__(self):\n        super().__init__()\n        self.environment_type = \"agent\"\n        self.frames = []\n        self.current_frame_idx = 0\n        self._depth_maps = []\n        self._segmentations = []\n        self._point_clouds = []\n\n    def initialize_from_images(self, images: Union[List[str], List[np.ndarray]]) -> bool:\n        \"\"\"Initialize environment from a list of image paths or numpy arrays.\n\n        Args:\n            images: List of image paths or numpy arrays representing frames\n\n        Returns:\n            bool: True if initialization successful, False otherwise\n        \"\"\"\n        try:\n            self.frames = []\n            for img in images:\n                if isinstance(img, str):\n                    frame = cv2.imread(img)\n                    if frame is None:\n                        raise ValueError(f\"Failed to load image: {img}\")\n                    self.frames.append(frame)\n                elif isinstance(img, np.ndarray):\n                    self.frames.append(img.copy())\n                else:\n                    raise ValueError(f\"Unsupported image type: {type(img)}\")\n            return True\n        except Exception as e:\n            print(f\"Failed to initialize from images: {e}\")\n            return False\n\n    def initialize_from_file(self, file_path: str) -> bool:\n        \"\"\"Initialize environment from a video file.\n\n        Args:\n            file_path: Path to the video file\n\n        Returns:\n            bool: True if initialization successful, False otherwise\n        \"\"\"\n        try:\n            if not Path(file_path).exists():\n                raise FileNotFoundError(f\"Video file not found: {file_path}\")\n\n            cap = cv2.VideoCapture(file_path)\n            self.frames = []\n            \n            while cap.isOpened():\n                ret, frame = cap.read()\n                if not ret:\n                    break\n                self.frames.append(frame)\n            \n            cap.release()\n            return len(self.frames) > 0\n        except Exception as e:\n            print(f\"Failed to initialize from video: {e}\")\n            return False\n\n    def initialize_from_directory(self, directory_path: str) -> bool:\n        \"\"\"Initialize environment from a directory of images.\"\"\"\n        # TODO: Implement directory initialization\n        raise NotImplementedError(\"Directory initialization not yet implemented\")\n\n    def label_objects(self) -> List[str]:\n        \"\"\"Implementation of abstract method to label objects.\"\"\"\n        # TODO: Implement object labeling using a detection model\n        raise NotImplementedError(\"Object labeling not yet implemented\")\n\n\n    def generate_segmentations(self, model: str = None, objects: List[str] = None, *args, **kwargs) -> List[np.ndarray]:\n        \"\"\"Generate segmentations for the current frame.\"\"\"\n        # TODO: Implement segmentation generation using specified model\n        raise NotImplementedError(\"Segmentation generation not yet implemented\")\n\n    def get_segmentations(self) -> List[np.ndarray]:\n        \"\"\"Return pre-computed segmentations for the current frame.\"\"\"\n        if self._segmentations:\n            return self._segmentations[self.current_frame_idx]\n        return []\n\n    def generate_point_cloud(self, object: str = None, *args, **kwargs) -> np.ndarray:\n        \"\"\"Generate point cloud from the current frame.\"\"\"\n        # TODO: Implement point cloud generation\n        raise NotImplementedError(\"Point cloud generation not yet implemented\")\n\n    def get_point_cloud(self, object: str = None) -> np.ndarray:\n        \"\"\"Return pre-computed point cloud.\"\"\"\n        if self._point_clouds:\n            return self._point_clouds[self.current_frame_idx]\n        return np.array([])\n\n    def generate_depth_map(self, stereo: bool = None, monocular: bool = None, model: str = None, *args, **kwargs) -> np.ndarray:\n        \"\"\"Generate depth map for the current frame.\"\"\"\n        # TODO: Implement depth map generation using specified method\n        raise NotImplementedError(\"Depth map generation not yet implemented\")\n\n    def get_depth_map(self) -> np.ndarray:\n        \"\"\"Return pre-computed depth map for the current frame.\"\"\"\n        if self._depth_maps:\n            return self._depth_maps[self.current_frame_idx]\n        return np.array([])\n\n    def get_frame_count(self) -> int:\n        \"\"\"Return the total number of frames.\"\"\"\n        return len(self.frames)\n\n    def get_current_frame_index(self) -> int:\n        \"\"\"Return the current frame index.\"\"\"\n        return self.current_frame_idx\n"}
{"type": "source_file", "path": "dimos/robot/recorder.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# UNDER DEVELOPMENT 🚧🚧🚧, NEEDS TESTING\n\nimport threading\nimport time\nfrom queue import Queue\nfrom typing import Any, Callable, Literal\n\n#from dimos.data.recording import Recorder\n\n\nclass RobotRecorder:\n    \"\"\"A class for recording robot observation and actions.\n\n    Recording at a specified frequency on the observation and action of a robot. It leverages a queue and a worker\n    thread to handle the recording asynchronously, ensuring that the main operations of the\n    robot are not blocked.\n\n    Robot class must pass in the `get_state`, `get_observation`, `prepare_action` methods.`\n    get_state() gets the current state/pose of the robot.\n    get_observation() captures the observation/image of the robot.\n    prepare_action() calculates the action between the new and old states.\n    \"\"\"\n\n    def __init__(\n        self,\n        get_state: Callable,\n        get_observation: Callable,\n        prepare_action: Callable,\n        frequency_hz: int = 5,\n        recorder_kwargs: dict = None,\n        on_static: Literal[\"record\", \"omit\"] = \"omit\",\n    ) -> None:\n        \"\"\"Initializes the RobotRecorder.\n\n        This constructor sets up the recording mechanism on the given robot, including the recorder instance,\n        recording frequency, and the asynchronous processing queue and worker thread. It also\n        initializes attributes to track the last recorded pose and the current instruction.\n\n        Args:\n            get_state: A function that returns the current state of the robot.\n            get_observation: A function that captures the observation/image of the robot.\n            prepare_action: A function that calculates the action between the new and old states.\n            frequency_hz: Frequency at which to record pose and image data (in Hz).\n            recorder_kwargs: Keyword arguments to pass to the Recorder constructor.\n            on_static: Whether to record on static poses or not. If \"record\", it will record when the robot is not moving.\n        \"\"\"\n        if recorder_kwargs is None:\n            recorder_kwargs = {}\n        self.recorder = Recorder(**recorder_kwargs)\n        self.task = None\n\n        self.last_recorded_state = None\n        self.last_image = None\n\n        self.recording = False\n        self.frequency_hz = frequency_hz\n        self.record_on_static = on_static == \"record\"\n        self.recording_queue = Queue()\n\n        self.get_state = get_state\n        self.get_observation = get_observation\n        self.prepare_action = prepare_action\n\n        self._worker_thread = threading.Thread(target=self._process_queue, daemon=True)\n        self._worker_thread.start()\n\n    def __enter__(self):\n        \"\"\"Enter the context manager, starting the recording.\"\"\"\n        self.start_recording(self.task)\n\n    def __exit__(self, exc_type, exc_value, traceback) -> None:\n        \"\"\"Exit the context manager, stopping the recording.\"\"\"\n        self.stop_recording()\n\n    def record(self, task: str) -> \"RobotRecorder\":\n        \"\"\"Set the task and return the context manager.\"\"\"\n        self.task = task\n        return self\n\n    def reset_recorder(self) -> None:\n        \"\"\"Reset the recorder.\"\"\"\n        while self.recording:\n            time.sleep(0.1)\n        self.recorder.reset()\n\n    def record_from_robot(self) -> None:\n        \"\"\"Records the current pose and captures an image at the specified frequency.\"\"\"\n        while self.recording:\n            start_time = time.perf_counter()\n            self.record_current_state()\n            elapsed_time = time.perf_counter() - start_time\n            # Sleep for the remaining time to maintain the desired frequency\n            sleep_time = max(0, (1.0 / self.frequency_hz) - elapsed_time)\n            time.sleep(sleep_time)\n\n    def start_recording(self, task: str = \"\") -> None:\n        \"\"\"Starts the recording of pose and image.\"\"\"\n        if not self.recording:\n            self.task = task\n            self.recording = True\n            self.recording_thread = threading.Thread(target=self.record_from_robot)\n            self.recording_thread.start()\n\n    def stop_recording(self) -> None:\n        \"\"\"Stops the recording of pose and image.\"\"\"\n        if self.recording:\n            self.recording = False\n            self.recording_thread.join()\n\n    def _process_queue(self) -> None:\n        \"\"\"Processes the recording queue asynchronously.\"\"\"\n        while True:\n            image, instruction, action, state = self.recording_queue.get()\n            self.recorder.record(observation={\"image\": image, \"instruction\": instruction}, action=action, state=state)\n            self.recording_queue.task_done()\n\n    def record_current_state(self) -> None:\n        \"\"\"Records the current pose and image if the pose has changed.\"\"\"\n        state = self.get_state()\n        image = self.get_observation()\n\n        # This is the beginning of the episode\n        if self.last_recorded_state is None:\n            self.last_recorded_state = state\n            self.last_image = image\n            return\n\n        if state != self.last_recorded_state or self.record_on_static:\n            action = self.prepare_action(self.last_recorded_state, state)\n            self.recording_queue.put(\n                (\n                    self.last_image,\n                    self.task,\n                    action,\n                    self.last_recorded_state,\n                ),\n            )\n            self.last_image = image\n            self.last_recorded_state = state\n\n    def record_last_state(self) -> None:\n        \"\"\"Records the final pose and image after the movement completes.\"\"\"\n        self.record_current_state()"}
{"type": "source_file", "path": "dimos/environment/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/environment/colmap_environment.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# UNDER DEVELOPMENT 🚧🚧🚧\n\nimport cv2\nimport pycolmap\nfrom pathlib import Path\nfrom dimos.environment.environment import Environment\n\nclass COLMAPEnvironment(Environment):\n    def initialize_from_images(self, image_dir):\n        \"\"\"Initialize the environment from a set of image frames or video.\"\"\"\n        image_dir = Path(image_dir)\n        output_path = Path(\"colmap_output\")\n        output_path.mkdir(exist_ok=True)\n        mvs_path = output_path / \"mvs\"\n        database_path = output_path / \"database.db\"\n\n        # Step 1: Feature extraction\n        pycolmap.extract_features(database_path, image_dir)\n\n        # Step 2: Feature matching\n        pycolmap.match_exhaustive(database_path)\n\n        # Step 3: Sparse reconstruction\n        maps = pycolmap.incremental_mapping(database_path, image_dir, output_path)\n        maps[0].write(output_path)\n\n        # Step 4: Dense reconstruction (optional)\n        pycolmap.undistort_images(mvs_path, output_path, image_dir)\n        pycolmap.patch_match_stereo(mvs_path)  # Requires compilation with CUDA\n        pycolmap.stereo_fusion(mvs_path / \"dense.ply\", mvs_path)\n\n        return maps\n\n    def initialize_from_video(self, video_path, frame_output_dir):\n        \"\"\"Extract frames from a video and initialize the environment.\"\"\"\n        video_path = Path(video_path)\n        frame_output_dir = Path(frame_output_dir)\n        frame_output_dir.mkdir(exist_ok=True)\n\n        # Extract frames from the video\n        self._extract_frames_from_video(video_path, frame_output_dir)\n\n        # Initialize from the extracted frames\n        return self.initialize_from_images(frame_output_dir)\n\n    def _extract_frames_from_video(self, video_path, frame_output_dir):\n        \"\"\"Extract frames from a video and save them to a directory.\"\"\"\n        cap = cv2.VideoCapture(str(video_path))\n        frame_count = 0\n\n        while cap.isOpened():\n            ret, frame = cap.read()\n            if not ret:\n                break\n            frame_filename = frame_output_dir / f\"frame_{frame_count:04d}.jpg\"\n            cv2.imwrite(str(frame_filename), frame)\n            frame_count += 1\n\n        cap.release()\n\n    def label_objects(self):\n        pass\n\n    def get_visualization(self, format_type):\n        pass\n\n    def get_segmentations(self):\n        pass\n\n    def get_point_cloud(self, object_id=None):\n        pass\n\n    def get_depth_map(self):\n        pass\n"}
{"type": "source_file", "path": "dimos/data/diffusion.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n"}
{"type": "source_file", "path": "dimos/agents/tokenizer/openai_impl.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom abc import ABC, abstractmethod\nimport tiktoken\nfrom dimos.utils.logging_config import setup_logger\n\n# TODO: Add a class for specific tokenizer exceptions\n# TODO: Build out testing and logging\n# TODO: Create proper doc strings after multiple tokenizers are implemented\n\n\nclass AbstractTokenizer(ABC):\n\n    @abstractmethod\n    def tokenize_text(self, text):\n        pass\n\n    @abstractmethod\n    def detokenize_text(self, tokenized_text):\n        pass\n\n    @abstractmethod\n    def token_count(self, text):\n        pass\n\n    @abstractmethod\n    def image_token_count(self, image_width, image_height, image_detail=\"low\"):\n        pass\n\n\nclass OpenAI_Tokenizer(AbstractTokenizer):\n\n    def __init__(self, model_name: str = \"gpt-4o\", **kwargs):\n        super().__init__(**kwargs)\n\n        # Initilize the tokenizer for the openai set of models\n        self.model_name = model_name\n        try:\n            self.tokenizer = tiktoken.encoding_for_model(self.model_name)\n        except Exception as e:\n            raise ValueError(\n                f\"Failed to initialize tokenizer for model {self.model_name}. Error: {str(e)}\"\n            )\n\n    def tokenize_text(self, text):\n        \"\"\"\n        Tokenize a text string using the openai tokenizer.\n        \"\"\"\n        return self.tokenizer.encode(text)\n\n    def detokenize_text(self, tokenized_text):\n        \"\"\"\n        Detokenize a text string using the openai tokenizer.\n        \"\"\"\n        try:\n            return self.tokenizer.decode(tokenized_text, errors=\"ignore\")\n        except Exception as e:\n            raise ValueError(f\"Failed to detokenize text. Error: {str(e)}\")\n\n    def token_count(self, text):\n        \"\"\"\n        Gets the token count of a text string using the openai tokenizer.\n        \"\"\"\n        return len(self.tokenize_text(text)) if text else 0\n\n    @staticmethod\n    def image_token_count(image_width, image_height, image_detail=\"high\"):\n        \"\"\"\n        Calculate the number of tokens in an image. Low detail is 85 tokens, high detail is 170 tokens per 512x512 square.\n        \"\"\"\n        logger = setup_logger(\n            \"dimos.agents.tokenizer.OpenAI_Tokenizer.image_token_count\")\n\n        if image_detail == \"low\":\n            return 85\n        elif image_detail == \"high\":\n            # Image dimensions\n            logger.debug(\n                f\"Image Width: {image_width}, Image Height: {image_height}\")\n            if image_width is None or image_height is None:\n                raise ValueError(\n                    \"Image width and height must be provided for high detail image token count calculation.\"\n                )\n\n            # Scale image to fit within 2048 x 2048\n            max_dimension = max(image_width, image_height)\n            if max_dimension > 2048:\n                scale_factor = 2048 / max_dimension\n                image_width = int(image_width * scale_factor)\n                image_height = int(image_height * scale_factor)\n\n            # Scale shortest side to 768px\n            min_dimension = min(image_width, image_height)\n            scale_factor = 768 / min_dimension\n            image_width = int(image_width * scale_factor)\n            image_height = int(image_height * scale_factor)\n\n            # Calculate number of 512px squares\n            num_squares = (image_width // 512) * (image_height // 512)\n            return 170 * num_squares + 85\n        else:\n            raise ValueError(\n                \"Detail specification of image is not 'low' or 'high'\")\n"}
{"type": "source_file", "path": "dimos/data/labels.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nfrom dimos.models.labels.llava_34b import Llava\nfrom PIL import Image\nfrom dimos.types.label import LabelType\n\nclass LabelProcessor:\n    def __init__(self, debug: bool = False):\n        self.model = None\n        self.prompt = 'Create a JSON representation where each entry consists of a key \"object\" with a numerical suffix starting from 1, and a corresponding \"description\" key with a value that is a concise, up to six-word sentence describing each main, distinct object or person in the image. Each pair should uniquely describe one element without repeating keys. An example: {\"object1\": { \"description\": \"Man in red hat walking.\" },\"object2\": { \"description\": \"Wooden pallet with boxes.\" },\"object3\": { \"description\": \"Cardboard boxes stacked.\" },\"object4\": { \"description\": \"Man in green vest standing.\" }}'\n        self.debug = debug\n\n    def _initialize_model(self):\n        if self.model is None:\n            from dimos.models.labels.llava_34b import Llava\n            self.model = Llava(mmproj=f\"{os.getcwd()}/models/mmproj-model-f16.gguf\", model_path=f\"{os.getcwd()}/models/llava-v1.6-34b.Q4_K_M.gguf\", gpu=True)\n            if self.debug:\n                print(\"Llava model initialized.\")\n\n    def caption_image_data(self, frame):\n        self._initialize_model()\n        try:\n            output = self.model.run_inference(frame, self.prompt, return_json=True)\n            if self.debug:\n                print(\"Output:\", output)\n            return LabelType(labels=output, metadata={\"frame_id\": frame.id})\n        except Exception as e:\n            print(f\"Error in captioning image: {e}\")\n            return LabelType(labels={}, metadata={\"error\": str(e)})"}
{"type": "source_file", "path": "dimos/data/segment.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport logging\nfrom dimos.models.segmentation.segment_utils import sample_points_from_heatmap\nfrom dimos.models.segmentation.sam import SAM\nfrom dimos.models.segmentation.clipseg import CLIPSeg\n\n# Setup logging\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\n\nclass SegmentProcessor:\n    def __init__(self, device='cuda'):\n        # Initialize CLIPSeg and SAM models\n        self.clipseg = CLIPSeg(model_name=\"CIDAS/clipseg-rd64-refined\", device=device)\n        self.sam = SAM(model_name=\"facebook/sam-vit-huge\", device=device)\n        self.logger = logger\n\n    def process_frame(self, image, captions):\n        \"\"\"\n        Process a single image and return segmentation masks.\n\n        Args:\n            image (PIL.Image.Image or np.ndarray): The input image to process.\n            captions (list of str): A list of captions for segmentation.\n\n        Returns:\n            list of np.ndarray: A list of segmentation masks corresponding to the captions.\n        \"\"\"\n        try:\n            self.logger.info(\"STARTING PROCESSING IMAGE ---------------------------------------\")\n            self.logger.info(f\"Processing image with captions: {captions}\")\n\n            # Convert image to PIL.Image if it's a numpy array\n            if isinstance(image, np.ndarray):\n                image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\n            preds = self.clipseg.run_inference(image, captions)\n            sampled_points = []\n            sam_masks = []\n\n            original_size = image.size  # (width, height)\n\n            for idx in range(preds.shape[0]):\n                points = sample_points_from_heatmap(preds[idx][0], original_size, num_points=10)\n                if points:\n                    sampled_points.append(points)\n                else:\n                    self.logger.info(f\"No points sampled for prediction index {idx}\")\n                    sampled_points.append([])\n\n            for idx in range(preds.shape[0]):\n                if sampled_points[idx]:\n                    mask_tensor = self.sam.run_inference_from_points(image, [sampled_points[idx]])\n                    if mask_tensor:\n                        # Convert mask tensor to a numpy array\n                        mask = (255 * mask_tensor[0].numpy().squeeze()).astype(np.uint8)\n                        sam_masks.append(mask)\n                    else:\n                        self.logger.info(f\"No mask tensor returned for sampled points at index {idx}\")\n                        sam_masks.append(np.zeros((original_size[1], original_size[0]), dtype=np.uint8))\n                else:\n                    self.logger.info(f\"No sampled points for prediction index {idx}, skipping mask inference\")\n                    sam_masks.append(np.zeros((original_size[1], original_size[0]), dtype=np.uint8))\n\n            self.logger.info(\"DONE PROCESSING IMAGE ---------------------------------------\")\n            return sam_masks\n        except Exception as e:\n            self.logger.error(f\"Error processing image: {e}\")\n            return []"}
{"type": "source_file", "path": "dimos/hardware/end_effector.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nclass EndEffector:\n    def __init__(self, effector_type=None):\n        self.effector_type = effector_type\n\n    def get_effector_type(self):\n        return self.effector_type\n"}
{"type": "source_file", "path": "dimos/environment/environment.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom abc import ABC, abstractmethod\nimport numpy as np\n\nclass Environment(ABC):\n    def __init__(self):\n        self.environment_type = None\n        self.graph = None\n\n    @abstractmethod\n    def label_objects(self) -> list[str]:\n        \"\"\"\n        Label all objects in the environment.\n        \n        Returns:\n            A list of string labels representing the objects in the environment.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_visualization(self, format_type):\n        \"\"\"Return different visualization formats like images, NERFs, or other 3D file types.\"\"\"\n        pass\n    \n    @abstractmethod\n    def generate_segmentations(self, model: str = None, objects: list[str] = None, *args, **kwargs) -> list[np.ndarray]:\n        \"\"\"\n        Generate object segmentations of objects[] using neural methods.\n\n        Args:\n            model (str, optional): The string of the desired segmentation model (SegmentAnything, etc.)\n            objects (list[str], optional): The list of strings of the specific objects to segment.\n            *args: Variable length argument list.\n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            list of numpy.ndarray: A list where each element is a numpy array\n            representing a binary mask for a segmented area of an object in the environment.\n\n        Note:\n            The specific arguments and their usage will depend on the subclass implementation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_segmentations(self) -> list[np.ndarray]:\n        \"\"\"\n        Get segmentations using a method like 'segment anything'.\n\n        Returns:\n            list of numpy.ndarray: A list where each element is a numpy array\n            representing a binary mask for a segmented area of an object in the environment.\n        \"\"\"\n        pass\n\n\n    @abstractmethod\n    def generate_point_cloud(self, object: str = None, *args, **kwargs) -> np.ndarray:\n        \"\"\"\n        Generate a point cloud for the entire environment or a specific object.\n\n        Args:\n            object (str, optional): The string of the specific object to get the point cloud for.\n                                    If None, returns the point cloud for the entire environment.\n            *args: Variable length argument list.\n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            np.ndarray: A numpy array representing the generated point cloud.\n                        Shape: (n, 3) where n is the number of points and each point is [x, y, z].\n\n        Note:\n            The specific arguments and their usage will depend on the subclass implementation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_point_cloud(self, object: str = None) -> np.ndarray:\n        \"\"\"\n        Return point clouds of the entire environment or a specific object.\n\n        Args:\n            object (str, optional): The string of the specific object to get the point cloud for. If None, returns the point cloud for the entire environment.\n\n        Returns:\n            np.ndarray: A numpy array representing the point cloud.\n                        Shape: (n, 3) where n is the number of points and each point is [x, y, z].\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate_depth_map(self, stereo: bool = None, monocular: bool = None, model: str = None, *args, **kwargs) -> np.ndarray:\n        \"\"\"\n        Generate a depth map using monocular or stereo camera methods.\n\n        Args:\n            stereo (bool, optional): Whether to stereo camera is avaliable for ground truth depth map generation.\n            monocular (bool, optional): Whether to use monocular camera for neural depth map generation.\n            model (str, optional): The string of the desired monocular depth model (Metric3D, ZoeDepth, etc.)\n            *args: Variable length argument list.\n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            np.ndarray: A 2D numpy array representing the generated depth map.\n                        Shape: (height, width) where each value represents the depth\n                        at that pixel location.\n\n        Note:\n            The specific arguments and their usage will depend on the subclass implementation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_depth_map(self) -> np.ndarray:\n        \"\"\"\n        Return a depth map of the environment.\n\n        Returns:\n            np.ndarray: A 2D numpy array representing the depth map.\n                        Shape: (height, width) where each value represents the depth\n                        at that pixel location. Typically, closer objects have smaller\n                        values and farther objects have larger values.\n\n        Note:\n            The exact range and units of the depth values may vary depending on the\n            specific implementation and the sensor or method used to generate the depth map.\n        \"\"\"\n        pass\n\n    def initialize_from_images(self, images):\n        \"\"\"Initialize the environment from a set of image frames or video.\"\"\"\n        raise NotImplementedError(\"This method is not implemented for this environment type.\")\n\n    def initialize_from_file(self, file_path):\n        \"\"\"Initialize the environment from a spatial file type.\n\n        Supported file types include:\n        - GLTF/GLB (GL Transmission Format)\n        - FBX (Filmbox)\n        - OBJ (Wavefront Object)\n        - USD/USDA/USDC (Universal Scene Description)\n        - STL (Stereolithography)\n        - COLLADA (DAE)\n        - Alembic (ABC)\n        - PLY (Polygon File Format)\n        - 3DS (3D Studio)\n        - VRML/X3D (Virtual Reality Modeling Language)\n\n        Args:\n            file_path (str): Path to the spatial file.\n\n        Raises:\n            NotImplementedError: If the method is not implemented for this environment type.\n        \"\"\"\n        raise NotImplementedError(\"This method is not implemented for this environment type.\")\n\n\n"}
{"type": "source_file", "path": "dimos/hardware/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/exceptions/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/data/pointcloud.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport cv2\nimport numpy as np\nimport open3d as o3d\nfrom pathlib import Path\nfrom PIL import Image\nimport logging\n\nfrom dimos.models.segmentation.segment_utils import apply_mask_to_image\nfrom dimos.models.pointcloud.pointcloud_utils import (\n    create_point_cloud_from_rgbd,\n    canonicalize_point_cloud\n)\nfrom dimos.types.pointcloud import PointCloudType\n\n# Setup logging\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\n\nclass PointCloudProcessor:\n    def __init__(self, output_dir, intrinsic_parameters=None):\n        \"\"\"\n        Initializes the PointCloudProcessor.\n\n        Args:\n            output_dir (str): The directory where point clouds will be saved.\n            intrinsic_parameters (dict, optional): Camera intrinsic parameters.\n                Defaults to None, in which case default parameters are used.\n        \"\"\"\n        self.output_dir = output_dir\n        os.makedirs(self.output_dir, exist_ok=True)\n        self.logger = logger\n\n        # Default intrinsic parameters\n        self.default_intrinsic_parameters = {\n            'width': 640,\n            'height': 480,\n            'fx': 960.0,\n            'fy': 960.0,\n            'cx': 320.0,\n            'cy': 240.0,\n        }\n        self.intrinsic_parameters = intrinsic_parameters if intrinsic_parameters else self.default_intrinsic_parameters\n\n    def process_frame(self, image, depth_map, masks):\n        \"\"\"\n        Process a single frame to generate point clouds.\n\n        Args:\n            image (PIL.Image.Image or np.ndarray): The RGB image.\n            depth_map (PIL.Image.Image or np.ndarray): The depth map corresponding to the image.\n            masks (list of np.ndarray): A list of binary masks for segmentation.\n\n        Returns:\n            list of PointCloudType: A list of point clouds for each mask.\n            bool: A flag indicating if the point clouds were canonicalized.\n        \"\"\"\n        try:\n            self.logger.info(\"STARTING POINT CLOUD PROCESSING ---------------------------------------\")\n\n            # Convert images to OpenCV format if they are PIL Images\n            if isinstance(image, Image.Image):\n                original_image_cv = cv2.cvtColor(np.array(image.convert('RGB')), cv2.COLOR_RGB2BGR)\n            else:\n                original_image_cv = image\n\n            if isinstance(depth_map, Image.Image):\n                depth_image_cv = cv2.cvtColor(np.array(depth_map.convert('RGB')), cv2.COLOR_RGB2BGR)\n            else:\n                depth_image_cv = depth_map\n\n            width, height = original_image_cv.shape[1], original_image_cv.shape[0]\n            intrinsic_parameters = self.intrinsic_parameters.copy()\n            intrinsic_parameters.update({\n                'width': width,\n                'height': height,\n                'cx': width / 2,\n                'cy': height / 2,      \n            })\n\n            point_clouds = []\n            point_cloud_data = []\n\n            # Create original point cloud\n            original_pcd = create_point_cloud_from_rgbd(original_image_cv, depth_image_cv, intrinsic_parameters)\n            pcd, canonicalized, transformation = canonicalize_point_cloud(original_pcd, canonicalize_threshold=0.3)\n\n            for idx, mask in enumerate(masks):\n                mask_binary = mask > 0\n\n                masked_rgb = apply_mask_to_image(original_image_cv, mask_binary)\n                masked_depth = apply_mask_to_image(depth_image_cv, mask_binary)\n\n                pcd = create_point_cloud_from_rgbd(masked_rgb, masked_depth, intrinsic_parameters)\n                # Remove outliers\n                cl, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n                inlier_cloud = pcd.select_by_index(ind)\n                if canonicalized:\n                    inlier_cloud.transform(transformation)\n\n                point_clouds.append(PointCloudType(point_cloud=inlier_cloud, metadata={\"mask_index\": idx}))\n                # Save point cloud to file\n                pointcloud_filename = f\"pointcloud_{idx}.pcd\"\n                pointcloud_filepath = os.path.join(self.output_dir, pointcloud_filename)\n                o3d.io.write_point_cloud(pointcloud_filepath, inlier_cloud)\n                point_cloud_data.append(pointcloud_filepath)\n                self.logger.info(f\"Saved point cloud {pointcloud_filepath}\")\n\n            self.logger.info(\"DONE POINT CLOUD PROCESSING ---------------------------------------\")\n            return point_clouds, canonicalized\n        except Exception as e:\n            self.logger.error(f\"Error processing frame: {e}\")\n            return [], False\n"}
{"type": "source_file", "path": "dimos/robot/robot.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Base module for all DIMOS robots.\n\nThis module provides the foundation for all DIMOS robots, including both physical \nand simulated implementations, with common functionality for movement, control, \nand video streaming.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, Type, TYPE_CHECKING\nfrom pydantic import Field\nfrom dimos.hardware.interface import HardwareInterface\nfrom dimos.robot.ros_control import ROSControl\nfrom dimos.stream.frame_processor import FrameProcessor\nfrom dimos.stream.video_operators import VideoOperators as vops\nfrom reactivex import Observable, operators as ops\nimport os\nfrom reactivex.disposable import CompositeDisposable\nfrom reactivex.scheduler import ThreadPoolScheduler\n\nfrom dimos.utils.threadpool import get_scheduler\n\n# Use TYPE_CHECKING to avoid circular imports\nif TYPE_CHECKING:\n    from dimos.robot.skills import AbstractSkill\nelse:\n    # Use a forward reference for runtime\n    AbstractSkill = 'AbstractSkill'\n\n\nclass Robot(ABC):\n    \"\"\"Base class for all DIMOS robots.\n    \n    This abstract base class defines the common interface and functionality for all\n    DIMOS robots, whether physical or simulated. It provides methods for movement,\n    rotation, video streaming, and hardware configuration management.\n    \n    Attributes:\n        agent_config: Configuration for the robot's agent.\n        hardware_interface: Interface to the robot's hardware components.\n        ros_control: ROS-based control system for the robot.\n        output_dir: Directory for storing output files.\n        disposables: Collection of disposable resources for cleanup.\n        pool_scheduler: Thread pool scheduler for managing concurrent operations.\n        skills: Robot skills instance for executing various robot actions.\n    \"\"\"\n\n    def __init__(self,\n                 hardware_interface: HardwareInterface = None,\n                 ros_control: ROSControl = None,\n                 output_dir: str = os.path.join(os.getcwd(), \"assets\", \"output\"),\n                 pool_scheduler: ThreadPoolScheduler = None,\n                 skills: Optional[AbstractSkill] = None):\n        \"\"\"Initialize a Robot instance.\n        \n        Args:\n            hardware_interface: Interface to the robot's hardware. Defaults to None.\n            ros_control: ROS-based control system. Defaults to None.\n            output_dir: Directory for storing output files. Defaults to \"./assets/output\".\n            pool_scheduler: Thread pool scheduler. If None, one will be created.\n            skills: Robot skills instance. Defaults to None.\n        \"\"\"\n        self.hardware_interface = hardware_interface\n        self.ros_control = ros_control\n        self.output_dir = output_dir\n        self.disposables = CompositeDisposable()\n        self.pool_scheduler = pool_scheduler if pool_scheduler else get_scheduler()\n        self.skills = None\n\n        # Create output directory if it doesn't exist\n        os.makedirs(self.output_dir, exist_ok=True)\n\n        # Handles skills initialization in Robot(..., skills=AbstractSkill()) AND standalone \n        # via skills_instance = AbstractSkill(robot=robot)\n        if skills is not None:\n            if hasattr(skills, '_robot') and skills._robot is not None:\n                # Skills already initialized with robot reference in AbstractSkill constructor\n                pass\n            else:\n                # New skills instance needs robot reference\n                self.skills = skills\n                self.skills.set_robot(self)\n\n    def get_ros_video_stream(self, fps: int = 30) -> Observable:\n        \"\"\"Get the ROS video stream with rate limiting and frame processing.\n        \n        Args:\n            fps: Frames per second for the video stream. Defaults to 30.\n            \n        Returns:\n            Observable: An observable stream of video frames.\n            \n        Raises:\n            RuntimeError: If no ROS video provider is available.\n        \"\"\"\n        if not self.ros_control or not self.ros_control.video_provider:\n            raise RuntimeError(\"No ROS video provider available\")\n\n        print(f\"Starting ROS video stream at {fps} FPS...\")\n\n        # Get base stream from video provider\n        video_stream = self.ros_control.video_provider.capture_video_as_observable(\n            fps=fps)\n\n        # Add minimal processing pipeline with proper thread handling\n        processed_stream = video_stream.pipe(\n            ops.subscribe_on(self.pool_scheduler),\n            ops.observe_on(self.pool_scheduler),  # Ensure thread safety\n            ops.share()  # Share the stream\n        )\n\n        return processed_stream\n\n    def move(self, distance: float, speed: float = 0.5) -> bool:\n        \"\"\"Move the robot using velocity commands.\n        \n        Args:\n            distance: Distance to move forward in meters (must be positive).\n            speed: Speed to move at in m/s. Defaults to 0.5.\n            \n        Returns:\n            bool: True if movement succeeded.\n            \n        Raises:\n            RuntimeError: If no ROS control interface is available.\n        \"\"\"\n        if self.ros_control is None:\n            raise RuntimeError(\n                \"No ROS control interface available for movement\")\n        return self.ros_control.move(distance, speed)\n\n    def reverse(self, distance: float, speed: float = 0.5) -> bool:\n        \"\"\"Move the robot backward by a specified distance.\n        \n        Args:\n            distance: Distance to move backward in meters (must be positive).\n            speed: Speed to move at in m/s. Defaults to 0.5.\n            \n        Returns:\n            bool: True if movement succeeded.\n            \n        Raises:\n            RuntimeError: If no ROS control interface is available.\n        \"\"\"\n        if self.ros_control is None:\n            raise RuntimeError(\n                \"No ROS control interface available for movement\")\n        return self.ros_control.reverse(distance, speed)\n\n    def spin(self, degrees: float, speed: float = 45.0) -> bool:\n        \"\"\"Rotate the robot by a specified angle.\n\n        Args:\n            degrees: Angle to rotate in degrees (positive for counter-clockwise, \n                negative for clockwise).\n            speed: Angular speed in degrees/second. Defaults to 45.0.\n            \n        Returns:\n            bool: True if rotation succeeded.\n            \n        Raises:\n            RuntimeError: If no ROS control interface is available.\n        \"\"\"\n        if self.ros_control is None:\n            raise RuntimeError(\n                \"No ROS control interface available for rotation\")\n        return self.ros_control.spin(degrees, speed)\n\n    def webrtc_req(self, api_id: int, topic: str = None, parameter: str = '', \n                  priority: int = 0, request_id: str = None, data=None, timeout: float = 1000.0) -> bool:\n        \"\"\"Send a WebRTC request command to the robot.\n        \n        Args:\n            api_id: The API ID for the command.\n            topic: The API topic to publish to. Defaults to ROSControl.webrtc_api_topic.\n            parameter: Optional parameter string. Defaults to ''.\n            priority: Priority level as defined by PriorityQueue(). Defaults to 0 (no priority).\n            data: Optional data dictionary.\n            timeout: Maximum time to wait for the command to complete.\n\n        Returns:\n            bool: True if command was sent successfully.\n            \n        Raises:\n            RuntimeError: If no ROS control interface is available.\n\n        \"\"\"\n        if self.ros_control is None:\n            raise RuntimeError(\"No ROS control interface available for WebRTC commands\")\n        return self.ros_control.queue_webrtc_req(\n            api_id=api_id, \n            topic=topic,\n            parameter=parameter, \n            priority=priority,\n            request_id=request_id,\n            data=data,\n            timeout=timeout\n        )\n\n    @abstractmethod\n    def do(self, *args, **kwargs):\n        \"\"\"Executes motion on the robot.\n        \n        This abstract method must be implemented by concrete robot subclasses\n        to provide robot-specific motion functionality.\n        \n        Args:\n            *args: Variable length argument list.\n            **kwargs: Arbitrary keyword arguments.\n            \n        Returns:\n            Implementation-dependent.\n        \"\"\"\n        pass\n\n    def update_hardware_interface(self,\n                                  new_hardware_interface: HardwareInterface):\n        \"\"\"Update the hardware interface with a new configuration.\n        \n        Args:\n            new_hardware_interface: New hardware interface to use for the robot.\n        \"\"\"\n        self.hardware_interface = new_hardware_interface\n\n    def get_hardware_configuration(self):\n        \"\"\"Retrieve the current hardware configuration.\n        \n        Returns:\n            The current hardware configuration from the hardware interface.\n            \n        Raises:\n            AttributeError: If hardware_interface is None.\n        \"\"\"\n        return self.hardware_interface.get_configuration()\n\n    def initialize_skills(self, skills: Optional[AbstractSkill]):\n        \"\"\"Initialize the robot's skills instance.\n        \n        Args:\n            skills: Skills instance to initialize for this robot.\n            \n        Returns:\n            The initialized skills instance.\n        \"\"\"\n        if skills is not None:\n            skills.initialize_skills()\n    \n    def get_skills(self) -> Optional[AbstractSkill]:\n        \"\"\"Get the robot's skills instance.\n        \n        Returns:\n            The robot's skills instance if one is set, None otherwise.\n        \"\"\"\n        return None if self.skills is None else self.skills\n\n    def set_hardware_configuration(self, configuration):\n        \"\"\"Set a new hardware configuration.\n        \n        Args:\n            configuration: The new hardware configuration to set.\n            \n        Raises:\n            AttributeError: If hardware_interface is None.\n        \"\"\"\n        self.hardware_interface.set_configuration(configuration)\n\n    def cleanup(self):\n        \"\"\"Clean up resources used by the robot.\n        \n        This method should be called when the robot is no longer needed to\n        ensure proper release of resources such as ROS connections and\n        subscriptions.\n        \"\"\"\n        if self.ros_control:\n            self.ros_control.cleanup()\n        self.disposables.dispose()\n"}
{"type": "source_file", "path": "dimos/agents/tokenizer/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/hardware/camera.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom dimos.hardware.sensor import AbstractSensor\n\nclass Camera(AbstractSensor):\n    def __init__(self, resolution=None, focal_length=None, sensor_size=None, sensor_type='Camera'):\n        super().__init__(sensor_type)\n        self.resolution = resolution  # (width, height) in pixels\n        self.focal_length = focal_length  # in millimeters\n        self.sensor_size = sensor_size  # (width, height) in millimeters\n\n    def get_sensor_type(self):\n        return self.sensor_type\n\n    def calculate_intrinsics(self):\n        if not self.resolution or not self.focal_length or not self.sensor_size:\n            raise ValueError(\"Resolution, focal length, and sensor size must be provided\")\n\n        # Calculate pixel size\n        pixel_size_x = self.sensor_size[0] / self.resolution[0]\n        pixel_size_y = self.sensor_size[1] / self.resolution[1]\n\n        # Calculate the principal point (assuming it's at the center of the image)\n        principal_point_x = self.resolution[0] / 2\n        principal_point_y = self.resolution[1] / 2\n\n        # Calculate the focal length in pixels\n        focal_length_x = self.focal_length / pixel_size_x\n        focal_length_y = self.focal_length / pixel_size_y\n\n        return {\n            'focal_length_x': focal_length_x,\n            'focal_length_y': focal_length_y,\n            'principal_point_x': principal_point_x,\n            'principal_point_y': principal_point_y\n        }\n\n    def get_intrinsics(self):\n        return self.calculate_intrinsics()\n"}
{"type": "source_file", "path": "dimos/robot/__init__.py", "content": "from .ros_control import ROSControl, RobotMode\n\n__all__ = ['ROSControl', 'RobotMode']\n"}
{"type": "source_file", "path": "dimos/robot/skill_library.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport logging\n\n# Configure logging for the module\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass SkillLibrary:\n    def __init__(self):\n        \"\"\"Initializes the SkillLibrary with available skills.\"\"\"\n        # A dictionary to map skill names to their respective functions and descriptions\n        self.skills = {\n            \"MoveX\": {\n                \"function\": self.MoveX,\n                \"description\": \"Moves the robot's arm along the X-axis by a specified distance.\"\n            },\n            \"MoveY\": {\n                \"function\": self.MoveY,\n                \"description\": \"Moves the robot's arm along the Y-axis by a specified distance.\"\n            },\n            \"GripArm\": {\n                \"function\": self.GripArm,\n                \"description\": \"Activates the robotic gripper to grasp an object.\"\n            }\n        }\n\n    def describe_skill(self, skill_name):\n        \"\"\"Returns the description of a given skill.\n\n        Args:\n            skill_name (str): The name of the skill.\n\n        Returns:\n            str: A description of the skill, or an error message if the skill is not found.\n        \"\"\"\n        skill = self.skills.get(skill_name)\n        if skill:\n            return skill[\"description\"]\n        else:\n            return f\"Skill '{skill_name}' not found.\"\n\n    def describe_all_skills(self):\n        \"\"\"Returns descriptions of all available skills.\n\n        Returns:\n            str: A formatted string containing all skill names and their descriptions.\n        \"\"\"\n        if not self.skills:\n            return \"No skills available.\"\n        \n        descriptions = \"\\n\".join(\n            f\"{name}: {info['description']}\" for name, info in self.skills.items()\n        )\n        return f\"Available skills:\\n{descriptions}\"\n\n    def call_skill(self, skill_name, *args, **kwargs):\n        \"\"\"Calls a specified skill with the provided arguments.\n\n        Args:\n            skill_name (str): The name of the skill to call.\n            *args: Positional arguments for the skill function.\n            **kwargs: Keyword arguments for the skill function.\n\n        Returns:\n            The result of the skill function, or an error message if the skill is not found.\n        \"\"\"\n        skill = self.skills.get(skill_name)\n        if skill:\n            return skill[\"function\"](*args, **kwargs)\n        else:\n            logger.error(f\"Skill '{skill_name}' not found.\")\n            return f\"Skill '{skill_name}' not found.\"\n\n    def MoveX(self, distance):\n        \"\"\"Moves the robot's arm along the X-axis.\n\n        Args:\n            distance (float): The distance to move along the X-axis.\n\n        Returns:\n            str: A message indicating the movement.\n        \"\"\"\n        logger.info(f\"Moving along X-axis by {distance} units.\")\n        return f\"Moved along X-axis by {distance} units.\"\n\n    def MoveY(self, distance):\n        \"\"\"Moves the robot's arm along the Y-axis.\n\n        Args:\n            distance (float): The distance to move along the Y-axis.\n\n        Returns:\n            str: A message indicating the movement.\n        \"\"\"\n        logger.info(f\"Moving along Y-axis by {distance} units.\")\n        return f\"Moved along Y-axis by {distance} units.\"\n\n    def GripArm(self):\n        \"\"\"Activates the robotic gripper.\n\n        Returns:\n            str: A message indicating the gripper action.\n        \"\"\"\n        logger.info(\"Gripping with robotic arm.\")\n        return \"Gripped with robotic arm.\"\n\n# Singleton instantiation will come at the robot class\n# Possibly two classes: Robot skills abstract & reasoning skills / perception skills\n# Reach skill will differ from object recognition skill (may need separate classes)\n# NavStack.export to skill func as well as other skills will use the same export function / helper\n\n"}
{"type": "source_file", "path": "dimos/robot/ros_skill_library.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport inspect\nfrom typing import Callable, Dict, Type\nfrom pydantic import BaseModel, create_model\nfrom dimos.robot.skills import AbstractSkill\n\nclass ROSSkillLibrary(AbstractSkill):\n    _instance = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(ROSSkillLibrary, cls).__new__(cls)\n            cls._instance.skills = {}  # ROS Skills\n            cls._instance.models = {}  # Pydantic models\n        return cls._instance\n\n    def register(self, name: str, func: Callable):\n        \"\"\"Registers a skill (function) into the library with a generated Pydantic model\"\"\"\n        if name in self.skills:\n            raise ValueError(f\"Skill '{name}' is already registered!\")\n        self.skills[name] = func\n        self.models[name] = self._generate_pydantic_model(name, func)\n\n    def _generate_pydantic_model(self, name: str, func: Callable) -> Type[BaseModel]:\n        \"\"\"Dynamically generate a Pydantic model from the function signature\"\"\"\n        signature = inspect.signature(func)\n        fields = {}\n        \n        for param_name, param in signature.parameters.items():\n            if param_name == \"self\":\n                continue  # Skip 'self' for instance methods\n            \n            annotation = param.annotation if param.annotation != inspect.Parameter.empty else str\n            default = param.default if param.default != inspect.Parameter.empty else ...\n            fields[param_name] = (annotation, default)\n        \n        return create_model(name + \"Model\", **fields)\n\n    def get_skill(self, name: str) -> Callable:\n        \"\"\"Retrieve a registered skill\"\"\"\n        return self.skills.get(name, None)\n\n    def get_model(self, name: str) -> Type[BaseModel]:\n        \"\"\"Retrieve the generated Pydantic model for validation\"\"\"\n        return self.models.get(name, None)\n\n    def list_skills(self) -> Dict[str, Callable]:\n        \"\"\"List all registered skills\"\"\"\n        return self.skills\n    \ndef register_skill(name: str = None):\n    \"\"\"Decorator to register a function into the SkillLibrary singleton\"\"\"\n    def decorator(func: Callable):\n        skill_name = name or func.__name__  # Default to function name if no name is given\n        library = ROSSkillLibrary()\n        #library.register(skill_name, func)\n\n        def wrapper(instance, *args, **kwargs):\n            \"\"\"Wrapper that validates input arguments using Pydantic\"\"\"\n            model = library.get_model(skill_name)  # Get the auto-generated Pydantic model\n            if model:\n                validated_args = model(**kwargs)  # Validate arguments with Pydantic\n                return func(instance, **validated_args.model_dump())  # Call the function with validated args\n            return func(instance, *args, **kwargs)  # If no model, call function normally\n\n        return wrapper\n    return decorator\n"}
{"type": "source_file", "path": "dimos/agents/prompt_builder/__init__.py", "content": ""}
{"type": "source_file", "path": "dimos/data/depth.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom dimos.models.depth.metric3d import Metric3D\nimport os\nimport pickle\nimport argparse\nimport pandas as pd\nfrom PIL import Image\nfrom io import BytesIO\nimport torch\nimport sys\nimport cv2\nimport tarfile\nimport logging\nimport time\nimport tempfile\nimport gc\nimport io\nimport csv\nimport numpy as np\nfrom dimos.types.depth_map import DepthMapType\n\nclass DepthProcessor:\n    def __init__(self, debug=False):\n        self.debug = debug\n        self.metric_3d = Metric3D()\n        self.depth_count = 0\n        self.valid_depth_count = 0\n        self.logger = logging.getLogger(__name__)\n        self.intrinsic = [707.0493, 707.0493, 604.0814, 180.5066]  # Default intrinsic\n\n        print(\"DepthProcessor initialized\")\n\n        if debug:\n            print(\"Running in debug mode\")\n            self.logger.info(\"Running in debug mode\")\n\n\n    def process(self, frame: Image.Image, intrinsics=None):\n        \"\"\"Process a frame to generate a depth map.\n        \n        Args:\n            frame: PIL Image to process\n            intrinsics: Optional camera intrinsics parameters\n        \n        Returns:\n            DepthMapType containing the depth map\n        \"\"\"\n        if intrinsics:\n            self.metric_3d.update_intrinsic(intrinsics)\n        else:\n            self.metric_3d.update_intrinsic(self.intrinsic)\n\n        # Convert frame to numpy array suitable for processing\n        if isinstance(frame, Image.Image):\n            image = frame.convert('RGB')\n        elif isinstance(frame, np.ndarray):\n            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n        else:\n            raise ValueError(\"Unsupported frame format. Must be PIL Image or numpy array.\")\n\n        image_np = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n        image_np = resize_image_for_vit(image_np)\n\n        # Process image and run depth via Metric3D\n        try:\n            with torch.no_grad():\n                depth_map = self.metric_3d.infer_depth(image_np)\n\n            self.depth_count += 1\n\n            # Validate depth map\n            if is_depth_map_valid(np.array(depth_map)):\n                self.valid_depth_count += 1\n            else:\n                self.logger.error(f\"Invalid depth map for the provided frame.\")\n                print(\"Invalid depth map for the provided frame.\")\n                return None\n\n            if self.debug:\n                # Save depth map locally or to S3 as needed\n                pass  # Implement saving logic if required\n\n            return DepthMapType(depth_data=depth_map, metadata={\"intrinsics\": intrinsics})\n\n        except Exception as e:\n            self.logger.error(f\"Error processing frame: {e}\")\n            return None"}
{"type": "source_file", "path": "dimos/robot/ros_command_queue.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nQueue-based command management system for robot commands.\n\nThis module provides a unified approach to queueing and processing all robot commands,\nincluding WebRTC requests and action client commands.\nCommands are processed sequentially and only when the robot is in IDLE state.\n\"\"\"\n\nimport threading\nimport time\nimport uuid\nfrom enum import Enum, auto\nfrom queue import PriorityQueue, Empty\nfrom typing import Callable, Optional, NamedTuple, Dict, Any, Tuple, List\nfrom dimos.utils.logging_config import setup_logger\nimport logging\n\n# Initialize logger for the ros command queue module\nlogger = setup_logger(\"dimos.robot.ros_command_queue\", level=logging.DEBUG)\n\nclass CommandType(Enum):\n    \"\"\"Types of commands that can be queued\"\"\"\n    WEBRTC = auto()  # WebRTC API requests\n    ACTION = auto()   # Any action client or function call\n\nclass WebRTCRequest(NamedTuple):\n    \"\"\"Class to represent a WebRTC request in the queue\"\"\"\n    id: str  # Unique ID for tracking\n    api_id: int  # API ID for the command\n    topic: str  # Topic to publish to\n    parameter: str  # Optional parameter string\n    priority: int  # Priority level\n    timeout: float  # How long to wait for this request to complete\n\nclass ROSCommand(NamedTuple):\n    \"\"\"Class to represent a command in the queue\"\"\"\n    id: str  # Unique ID for tracking\n    cmd_type: CommandType  # Type of command\n    execute_func: Callable  # Function to execute the command\n    params: Dict[str, Any]  # Parameters for the command (for debugging/logging)\n    priority: int  # Priority level (lower is higher priority)\n    timeout: float  # How long to wait for this command to complete\n\nclass ROSCommandQueue:\n    \"\"\"\n    Manages a queue of commands for the robot.\n    \n    Commands are executed sequentially, with only one command being processed at a time.\n    Commands are only executed when the robot is in the IDLE state.\n    \"\"\"\n    \n    def __init__(self, \n                 webrtc_func: Callable,\n                 is_ready_func: Callable[[], bool] = None,\n                 is_busy_func: Optional[Callable[[], bool]] = None,\n                 debug: bool = True):\n        \"\"\"\n        Initialize the ROSCommandQueue.\n        \n        Args:\n            webrtc_func: Function to send WebRTC requests\n            is_ready_func: Function to check if the robot is ready for a command\n            is_busy_func: Function to check if the robot is busy\n            debug: Whether to enable debug logging\n        \"\"\"\n        self._webrtc_func = webrtc_func\n        self._is_ready_func = is_ready_func or (lambda: True)\n        self._is_busy_func = is_busy_func\n        self._debug = debug\n        \n        # Queue of commands to process\n        self._queue = PriorityQueue()\n        self._current_command = None\n        self._last_command_time = 0\n        \n        # Last known robot state\n        self._last_ready_state = None\n        self._last_busy_state = None\n        self._stuck_in_busy_since = None\n        \n        # Command execution status\n        self._should_stop = False\n        self._queue_thread = None\n        \n        # Stats\n        self._command_count = 0\n        self._success_count = 0\n        self._failure_count = 0\n        self._command_history = []\n        \n        self._max_queue_wait_time = 30.0  # Maximum time to wait for robot to be ready before forcing\n        \n        logger.info(\"ROSCommandQueue initialized\")\n        \n    def start(self):\n        \"\"\"Start the queue processing thread\"\"\"\n        if self._queue_thread is not None and self._queue_thread.is_alive():\n            logger.warning(\"Queue processing thread already running\")\n            return\n            \n        self._should_stop = False\n        self._queue_thread = threading.Thread(target=self._process_queue, daemon=True)\n        self._queue_thread.start()\n        logger.info(\"Queue processing thread started\")\n        \n    def stop(self, timeout=2.0):\n        \"\"\"\n        Stop the queue processing thread\n        \n        Args:\n            timeout: Maximum time to wait for the thread to stop\n        \"\"\"\n        if self._queue_thread is None or not self._queue_thread.is_alive():\n            logger.warning(\"Queue processing thread not running\")\n            return\n            \n        self._should_stop = True\n        try:\n            self._queue_thread.join(timeout=timeout)\n            if self._queue_thread.is_alive():\n                logger.warning(f\"Queue processing thread did not stop within {timeout}s\")\n            else:\n                logger.info(\"Queue processing thread stopped\")\n        except Exception as e:\n            logger.error(f\"Error stopping queue processing thread: {e}\")\n        \n    def queue_webrtc_request(self, api_id: int, topic: str = None, parameter: str = '', \n                             request_id: str = None, data: Dict[str, Any] = None,\n                             priority: int = 0, timeout: float = 30.0) -> str:\n        \"\"\"\n        Queue a WebRTC request\n        \n        Args:\n            api_id: API ID for the command\n            topic: Topic to publish to\n            parameter: Optional parameter string\n            request_id: Unique ID for the request (will be generated if not provided)\n            data: Data to include in the request\n            priority: Priority level (lower is higher priority)\n            timeout: Maximum time to wait for the command to complete\n            \n        Returns:\n            str: Unique ID for the request\n        \"\"\"\n        request_id = request_id or str(uuid.uuid4())\n        \n        # Create a function that will execute this WebRTC request\n        def execute_webrtc():\n            try:\n                logger.info(f\"Executing WebRTC request: {api_id} (ID: {request_id})\")\n                if self._debug:\n                    logger.debug(f\"[WebRTC Queue] SENDING request: API ID {api_id}\")\n                \n                result = self._webrtc_func(\n                    api_id=api_id, \n                    topic=topic,\n                    parameter=parameter,\n                    request_id=request_id,\n                    data=data,\n                )\n                if not result:\n                    logger.warning(f\"WebRTC request failed: {api_id} (ID: {request_id})\")\n                    if self._debug:\n                        logger.debug(f\"[WebRTC Queue] Request API ID {api_id} FAILED to send\")\n                    return False\n                \n                if self._debug:\n                    logger.debug(f\"[WebRTC Queue] Request API ID {api_id} sent SUCCESSFULLY\")\n                \n                # Allow time for the robot to process the command\n                start_time = time.time()\n                stabilization_delay = 0.5  # Half-second delay for stabilization\n                time.sleep(stabilization_delay)\n                \n                # Wait for the robot to complete the command (timeout check)\n                while self._is_busy_func() and (time.time() - start_time) < timeout:\n                    if self._debug and (time.time() - start_time) % 5 < 0.1:  # Print every ~5 seconds\n                        logger.debug(f\"[WebRTC Queue] Still waiting on API ID {api_id} - elapsed: {time.time()-start_time:.1f}s\")\n                    time.sleep(0.1)\n                \n                # Check if we timed out\n                if self._is_busy_func() and (time.time() - start_time) >= timeout:\n                    logger.warning(f\"WebRTC request timed out: {api_id} (ID: {request_id})\")\n                    return False\n                \n                wait_time = time.time() - start_time\n                if self._debug:\n                    logger.debug(f\"[WebRTC Queue] Request API ID {api_id} completed after {wait_time:.1f}s\")\n                \n                logger.info(f\"WebRTC request completed: {api_id} (ID: {request_id})\")\n                return True\n            except Exception as e:\n                logger.error(f\"Error executing WebRTC request: {e}\")\n                if self._debug:\n                    logger.debug(f\"[WebRTC Queue] ERROR processing request: {e}\")\n                return False\n        \n        # Create the command and queue it\n        command = ROSCommand(\n            id=request_id,\n            cmd_type=CommandType.WEBRTC,\n            execute_func=execute_webrtc,\n            params={'api_id': api_id, 'topic': topic, 'request_id': request_id},\n            priority=priority,\n            timeout=timeout\n        )\n        \n        # Queue the command\n        self._queue.put((priority, self._command_count, command))\n        self._command_count += 1\n        if self._debug:\n            logger.debug(f\"[WebRTC Queue] Added request ID {request_id} for API ID {api_id} - Queue size now: {self.queue_size}\")\n        logger.info(f\"Queued WebRTC request: {api_id} (ID: {request_id}, Priority: {priority})\")\n        \n        return request_id\n        \n    def queue_action_client_request(self, action_name: str, execute_func: Callable,\n                               priority: int = 0, timeout: float = 30.0, **kwargs) -> str:\n        \"\"\"\n        Queue any action client request or function\n        \n        Args:\n            action_name: Name of the action for logging/tracking\n            execute_func: Function to execute the command\n            priority: Priority level (lower is higher priority)\n            timeout: Maximum time to wait for the command to complete\n            **kwargs: Additional parameters to pass to the execute function\n            \n        Returns:\n            str: Unique ID for the request\n        \"\"\"\n        request_id = str(uuid.uuid4())\n        \n        # Create the command\n        command = ROSCommand(\n            id=request_id,\n            cmd_type=CommandType.ACTION,\n            execute_func=execute_func,\n            params={'action_name': action_name, **kwargs},\n            priority=priority,\n            timeout=timeout\n        )\n        \n        # Queue the command\n        self._queue.put((priority, self._command_count, command))\n        self._command_count += 1\n        \n        action_params = ', '.join([f\"{k}={v}\" for k, v in kwargs.items()])\n        logger.info(f\"Queued action request: {action_name} (ID: {request_id}, Priority: {priority}, Params: {action_params})\")\n        \n        return request_id\n        \n    def _process_queue(self):\n        \"\"\"Process commands in the queue\"\"\"\n        logger.info(\"Starting queue processing\")\n        logger.info(\"[WebRTC Queue] Processing thread started\")\n        \n        while not self._should_stop:\n            # Print queue status\n            self._print_queue_status()\n            \n            # Check if we're ready to process a command\n            if not self._queue.empty() and self._current_command is None:\n                current_time = time.time()\n                is_ready = self._is_ready_func()\n                is_busy = self._is_busy_func() if self._is_busy_func else False\n                \n                if self._debug:\n                    logger.debug(f\"[WebRTC Queue] Status: {self.queue_size} requests waiting | Robot ready: {is_ready} | Robot busy: {is_busy}\")\n                \n                # Track robot state changes\n                if is_ready != self._last_ready_state:\n                    logger.debug(f\"Robot ready state changed: {self._last_ready_state} -> {is_ready}\")\n                    self._last_ready_state = is_ready\n                    \n                if is_busy != self._last_busy_state:\n                    logger.debug(f\"Robot busy state changed: {self._last_busy_state} -> {is_busy}\")\n                    self._last_busy_state = is_busy\n                    \n                    # If the robot has transitioned to busy, record the time\n                    if is_busy:\n                        self._stuck_in_busy_since = current_time\n                    else:\n                        self._stuck_in_busy_since = None\n                \n                # Check if we've been waiting too long for the robot to be ready\n                force_processing = False\n                if (not is_ready and is_busy and \n                    self._stuck_in_busy_since is not None and \n                    current_time - self._stuck_in_busy_since > self._max_queue_wait_time):\n                    logger.warning(\n                        f\"Robot has been busy for {current_time - self._stuck_in_busy_since:.1f}s, \"\n                        f\"forcing queue to continue\"\n                    )\n                    force_processing = True\n                \n                # Process the next command if ready or forcing\n                if is_ready or force_processing:\n                    if self._debug and is_ready:\n                        logger.debug(\"[WebRTC Queue] Robot is READY for next command\")\n                    \n                    try:\n                        # Get the next command\n                        _, _, command = self._queue.get(block=False)\n                        self._current_command = command\n                        self._last_command_time = current_time\n                        \n                        # Log the command\n                        cmd_info = f\"ID: {command.id}, Type: {command.cmd_type.name}\"\n                        if command.cmd_type == CommandType.WEBRTC:\n                            api_id = command.params.get('api_id')\n                            cmd_info += f\", API: {api_id}\"\n                            if self._debug:\n                                logger.debug(f\"[WebRTC Queue] DEQUEUED request: API ID {api_id}\")\n                        elif command.cmd_type == CommandType.ACTION:\n                            action_name = command.params.get('action_name')\n                            cmd_info += f\", Action: {action_name}\"\n                            if self._debug:\n                                logger.debug(f\"[WebRTC Queue] DEQUEUED action: {action_name}\")\n                        \n                        forcing_str = \" (FORCED)\" if force_processing else \"\"\n                        logger.info(f\"Processing command{forcing_str}: {cmd_info}\")\n                        \n                        # Execute the command\n                        try:\n                            # Where command execution occurs\n                            success = command.execute_func()\n                            \n                            if success:\n                                self._success_count += 1\n                                logger.info(f\"Command succeeded: {cmd_info}\")\n                                if self._debug:\n                                    logger.debug(f\"[WebRTC Queue] Command {command.id} marked as COMPLETED\")\n                            else:\n                                self._failure_count += 1\n                                logger.warning(f\"Command failed: {cmd_info}\")\n                                if self._debug:\n                                    logger.debug(f\"[WebRTC Queue] Command {command.id} FAILED\")\n                                \n                            # Record command history\n                            self._command_history.append({\n                                'id': command.id,\n                                'type': command.cmd_type.name,\n                                'params': command.params,\n                                'success': success,\n                                'time': time.time() - self._last_command_time\n                            })\n                            \n                        except Exception as e:\n                            self._failure_count += 1\n                            logger.error(f\"Error executing command: {e}\")\n                            if self._debug:\n                                logger.debug(f\"[WebRTC Queue] ERROR executing command: {e}\")\n                        \n                        # Mark the command as complete\n                        self._current_command = None\n                        if self._debug:\n                            logger.debug(\"[WebRTC Queue] Adding 0.5s stabilization delay before next command\")\n                            time.sleep(0.5)\n                            \n                    except Empty:\n                        pass\n            \n            # Sleep to avoid busy-waiting\n            time.sleep(0.1)\n        \n        logger.info(\"Queue processing stopped\")\n        \n    def _print_queue_status(self):\n        \"\"\"Print the current queue status\"\"\"\n        current_time = time.time()\n        \n        # Only print once per second to avoid spamming the log\n        if current_time - self._last_command_time < 1.0 and self._current_command is None:\n            return\n            \n        is_ready = self._is_ready_func()\n        is_busy = self._is_busy_func() if self._is_busy_func else False\n        queue_size = self.queue_size\n        \n        # Get information about the current command\n        current_command_info = \"None\"\n        if self._current_command is not None:\n            current_command_info = f\"{self._current_command.cmd_type.name}\"\n            if self._current_command.cmd_type == CommandType.WEBRTC:\n                api_id = self._current_command.params.get('api_id')\n                current_command_info += f\" (API: {api_id})\"\n            elif self._current_command.cmd_type == CommandType.ACTION:\n                action_name = self._current_command.params.get('action_name')\n                current_command_info += f\" (Action: {action_name})\"\n            \n        # Print the status\n        status = (\n            f\"Queue: {queue_size} items | \"\n            f\"Robot: {'READY' if is_ready else 'BUSY'} | \"\n            f\"Current: {current_command_info} | \"\n            f\"Stats: {self._success_count} OK, {self._failure_count} FAIL\"\n        )\n        \n        logger.debug(status)\n        self._last_command_time = current_time\n        \n    @property\n    def queue_size(self) -> int:\n        \"\"\"Get the number of commands in the queue\"\"\"\n        return self._queue.qsize()\n        \n    @property\n    def current_command(self) -> Optional[ROSCommand]:\n        \"\"\"Get the current command being processed\"\"\"\n        return self._current_command\n        "}
{"type": "source_file", "path": "dimos/robot/ros_control.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.executors import MultiThreadedExecutor\nfrom rclpy.action import ActionClient\nfrom geometry_msgs.msg import Twist\nfrom nav2_msgs.action import DriveOnHeading, Spin, BackUp\nfrom sensor_msgs.msg import Image, CompressedImage\nfrom cv_bridge import CvBridge\nfrom dimos.stream.video_provider import VideoProvider\nfrom enum import Enum, auto\nimport threading\nimport time\nfrom typing import Optional, Tuple, Dict, Any, Type\nfrom abc import ABC, abstractmethod\nfrom rclpy.qos import (\n    QoSProfile,\n    QoSReliabilityPolicy,\n    QoSHistoryPolicy,\n    QoSDurabilityPolicy\n)\nfrom dimos.stream.ros_video_provider import ROSVideoProvider\nimport math\nfrom nav2_simple_commander.robot_navigator import BasicNavigator\nfrom builtin_interfaces.msg import Duration\nfrom geometry_msgs.msg import Point\nfrom dimos.robot.ros_command_queue import ROSCommandQueue\nfrom dimos.utils.logging_config import setup_logger\nimport logging\n\nlogger = setup_logger(\"dimos.robot.ros_control\", level=logging.INFO)\n\n__all__ = ['ROSControl', 'RobotMode']\n\nclass RobotMode(Enum):\n    \"\"\"Enum for robot modes\"\"\"\n    UNKNOWN = auto()\n    INITIALIZING = auto()\n    IDLE = auto()\n    MOVING = auto()\n    ERROR = auto()\n\nclass ROSControl(ABC):\n    \"\"\"Abstract base class for ROS-controlled robots\"\"\"\n    \n    def __init__(self, \n                 node_name: str,\n                 camera_topics: Dict[str, str] = None,\n                 use_compressed_video: bool = False,\n                 max_linear_velocity: float = 1.0,\n                 mock_connection: bool = False,\n                 max_angular_velocity: float = 2.0,\n                 state_topic: str = None,\n                 imu_topic: str = None,\n                 state_msg_type: Type = None,\n                 imu_msg_type: Type = None,\n                 webrtc_topic: str = None,\n                 webrtc_api_topic: str = None,\n                 webrtc_msg_type: Type = None,\n                 debug: bool = False):\n      \n        \"\"\"\n        Initialize base ROS control interface\n        Args:\n            node_name: Name for the ROS node\n            camera_topics: Dictionary of camera topics\n            use_compressed_video: Whether to use compressed video\n            max_linear_velocity: Maximum linear velocity (m/s)\n            max_angular_velocity: Maximum angular velocity (rad/s)\n            state_topic: Topic name for robot state (optional)\n            imu_topic: Topic name for IMU data (optional)\n            state_msg_type: The ROS message type for state data\n            imu_msg_type: The ROS message type for IMU data\n            webrtc_topic: Topic for WebRTC commands\n            webrtc_api_topic: Topic for WebRTC API commands\n            webrtc_msg_type: The ROS message type for webrtc data\n        \"\"\"\n        # Initialize rclpy and ROS node if not already running\n        if not rclpy.ok():\n            rclpy.init()\n\n        self._state_topic = state_topic\n        self._imu_topic = imu_topic\n        self._state_msg_type = state_msg_type\n        self._imu_msg_type = imu_msg_type\n        self._webrtc_msg_type = webrtc_msg_type\n        self._webrtc_topic = webrtc_topic\n        self._webrtc_api_topic = webrtc_api_topic\n        self._node = Node(node_name)\n        self._logger = self._node.get_logger()\n        self._debug = debug\n        # Prepare a multi-threaded executor\n        self._executor = MultiThreadedExecutor()\n        \n        # Movement constraints\n        self.MAX_LINEAR_VELOCITY = max_linear_velocity\n        self.MAX_ANGULAR_VELOCITY = max_angular_velocity\n        \n        self._subscriptions = []\n        \n        # Track State variables \n        self._robot_state = None  # Full state message\n        self._imu_state = None  # Full IMU message\n        self._mode = RobotMode.INITIALIZING\n\n        # Create sensor data QoS profile\n        sensor_qos = QoSProfile(\n            reliability=QoSReliabilityPolicy.BEST_EFFORT,\n            history=QoSHistoryPolicy.KEEP_LAST,\n            durability=QoSDurabilityPolicy.VOLATILE,\n            depth=1\n        )\n        \n        command_qos = QoSProfile(\n            reliability=QoSReliabilityPolicy.RELIABLE,\n            history=QoSHistoryPolicy.KEEP_LAST,\n            durability=QoSDurabilityPolicy.VOLATILE,\n            depth=10  # Higher depth for commands to ensure delivery\n        )\n        \n        # Initialize data handling\n        self._video_provider = None\n        self._bridge = None\n        if camera_topics:\n            self._bridge = CvBridge()\n            self._video_provider = ROSVideoProvider(dev_name=f\"{node_name}_video\")\n            \n            # Create subscribers for each topic with sensor QoS\n            msg_type = CompressedImage if use_compressed_video else Image\n            for topic in camera_topics.values():\n                self._logger.info(f\"Subscribing to {topic} with BEST_EFFORT QoS\")\n                _camera_subscription = self._node.create_subscription(\n                    msg_type,\n                    topic,\n                    self._image_callback,\n                    sensor_qos\n                )\n                self._subscriptions.append(_camera_subscription)\n        \n        # Subscribe to state topic if provided\n        if self._state_topic and self._state_msg_type:\n            self._logger.info(f\"Subscribing to {state_topic} with BEST_EFFORT QoS\")\n            self._state_sub = self._node.create_subscription(\n                self._state_msg_type,\n                self._state_topic,\n                self._state_callback,\n                qos_profile=sensor_qos\n            )\n            self._subscriptions.append(self._state_sub)\n        else:\n            self._logger.warning(\"No state topic andor message type provided - robot state tracking will be unavailable\")\n\n        if self._imu_topic and self._imu_msg_type:\n            self._imu_sub = self._node.create_subscription(\n                self._imu_msg_type,\n                self._imu_topic,\n                self._imu_callback,\n                sensor_qos\n            )\n            self._subscriptions.append(self._imu_sub)\n        else:\n            self._logger.warning(\"No IMU topic and/or message type provided - IMU data tracking will be unavailable\")\n\n        # Nav2 Action Clients\n        self._drive_client = ActionClient(self._node, DriveOnHeading, 'drive_on_heading')\n        self._spin_client = ActionClient(self._node, Spin, 'spin')\n        self._backup_client = ActionClient(self._node, BackUp, 'backup')\n        \n        # Wait for action servers\n        if not mock_connection:\n            self._drive_client.wait_for_server()\n            self._spin_client.wait_for_server()\n            self._backup_client.wait_for_server()\n\n        # Publishers\n        if webrtc_msg_type:\n            self._webrtc_pub = self._node.create_publisher(\n                webrtc_msg_type, webrtc_topic, qos_profile=command_qos)\n            \n            # Initialize command queue\n            self._command_queue = ROSCommandQueue(\n                webrtc_func=self.webrtc_req,\n                is_ready_func=lambda: self._mode == RobotMode.IDLE,\n                is_busy_func=lambda: self._mode == RobotMode.MOVING,\n            )\n            # Start the queue processing thread\n            self._command_queue.start()\n        else:\n            self._logger.warning(\"No WebRTC message type provided - WebRTC commands will be unavailable\")\n            \n        # Start ROS spin in a background thread via the executor\n        self._spin_thread = threading.Thread(target=self._ros_spin, daemon=True)\n        self._spin_thread.start()\n        \n        self._logger.info(f\"{node_name} initialized with multi-threaded executor\")\n        print(f\"{node_name} initialized with multi-threaded executor\")\n    \n\n    def _imu_callback(self, msg):\n        \"\"\"Callback for IMU data\"\"\"\n        self._imu_state = msg\n        self._logger.debug(f\"IMU state updated: {self._imu_state}\")\n\n\n    def _state_callback(self, msg):\n        \"\"\"Callback for state messages to track mode and progress\"\"\"\n        \n        # Call the abstract method to update RobotMode enum based on the received state\n        self._robot_state = msg\n\n        logger.debug(f\"[ROSControl] State callback received: {msg}\")\n        self._update_mode(msg)\n        # Log state changes\n        self._logger.debug(f\"Robot state updated: {self._robot_state}\")\n    \n    @property\n    def robot_state(self) -> Optional[Any]:\n        \"\"\"Get the full robot state message\"\"\"\n        return self._robot_state\n    \n    def _ros_spin(self):\n        \"\"\"Background thread for spinning the multi-threaded executor.\"\"\"\n        self._executor.add_node(self._node)\n        try:\n            self._executor.spin()\n        finally:\n            self._executor.shutdown()\n    \n    def _clamp_velocity(self, velocity: float, max_velocity: float) -> float:\n        \"\"\"Clamp velocity within safe limits\"\"\"\n        return max(min(velocity, max_velocity), -max_velocity)\n    \n    @abstractmethod\n    def _update_mode(self, *args, **kwargs):\n        \"\"\"Update robot mode based on state - to be implemented by child classes\"\"\"\n        pass\n    \n    def get_state(self) -> Optional[Any]:\n        \"\"\"\n        Get current robot state\n        \n        Base implementation provides common state fields. Child classes should\n        extend this method to include their specific state information.\n        \n        Returns:\n            ROS msg containing the robot state information\n        \"\"\"            \n        if not self._state_topic:\n            self._logger.warning(\"No state topic provided - robot state tracking will be unavailable\")\n            return None\n        \n        return self._robot_state\n    \n    def get_imu_state(self) -> Optional[Any]:\n        \"\"\"\n        Get current IMU state\n        \n        Base implementation provides common state fields. Child classes should\n        extend this method to include their specific state information.\n        \n        Returns:\n            ROS msg containing the IMU state information\n        \"\"\"           \n        if not self._imu_topic:\n            self._logger.warning(\"No IMU topic provided - IMU data tracking will be unavailable\")\n            return None\n        return self._imu_state\n    \n    def _image_callback(self, msg):\n        \"\"\"Convert ROS image to numpy array and push to data stream\"\"\"\n        if self._video_provider and self._bridge:\n            try:\n                if isinstance(msg, CompressedImage):\n                    frame = self._bridge.compressed_imgmsg_to_cv2(msg)\n                else:\n                    frame = self._bridge.imgmsg_to_cv2(msg, \"bgr8\")\n                self._video_provider.push_data(frame)\n            except Exception as e:\n                self._logger.error(f\"Error converting image: {e}\")\n                print(f\"Full conversion error: {str(e)}\")\n    \n    @property\n    def video_provider(self) -> Optional[ROSVideoProvider]:\n        \"\"\"Data provider property for streaming data\"\"\"\n        return self._video_provider\n    \n\n    def _send_action_client_goal(self, client, goal_msg, description=None, time_allowance=20.0):\n        \"\"\"\n        Generic function to send any action client goal and wait for completion.\n        \n        Args:\n            client: The action client to use\n            goal_msg: The goal message to send\n            description: Optional description for logging\n            time_allowance: Maximum time to wait for completion\n            \n        Returns:\n            bool: True if action succeeded, False otherwise\n        \"\"\"\n        if description:\n            self._logger.info(description)\n            \n        print(f\"[ROSControl] Sending action client goal: {description}\")\n        print(f\"[ROSControl] Goal message: {goal_msg}\")\n            \n        # Reset action result tracking\n        self._action_success = None\n        \n        # Send the goal\n        send_goal_future = client.send_goal_async(\n            goal_msg, \n            feedback_callback=lambda feedback: None\n        )\n        send_goal_future.add_done_callback(self._goal_response_callback)\n        \n        # Wait for completion\n        start_time = time.time()\n        while self._action_success is None and time.time() - start_time < time_allowance:\n            time.sleep(0.1)\n            \n        elapsed = time.time() - start_time\n        print(f\"[ROSControl] Action completed in {elapsed:.2f}s with result: {self._action_success}\")\n            \n        # Check result    \n        if self._action_success is None:\n            self._logger.error(f\"Action timed out after {time_allowance}s\")\n            return False\n        elif self._action_success:\n            self._logger.info(f\"Action succeeded\")\n            return True\n        else:\n            self._logger.error(f\"Action failed\")\n            return False\n\n    def move(self, distance: float, speed: float = 0.5, time_allowance: float = 120) -> bool:\n        \"\"\"\n        Move the robot forward by a specified distance\n        \n        Args:\n            distance: Distance to move forward in meters (must be positive)\n            speed: Speed to move at in m/s (default 0.5)\n            time_allowance: Maximum time to wait for the request to complete\n            \n        Returns:\n            bool: True if movement succeeded\n        \"\"\"\n        try:\n            if distance <= 0:\n                self._logger.error(\"Distance must be positive\")\n                return False\n                \n            speed = min(abs(speed), self.MAX_LINEAR_VELOCITY)\n            \n            # Define function to execute the move\n            def execute_move():\n                # Create DriveOnHeading goal\n                goal = DriveOnHeading.Goal()\n                goal.target.x = distance\n                goal.target.y = 0.0\n                goal.target.z = 0.0\n                goal.speed = speed\n                goal.time_allowance = Duration(sec=time_allowance)\n                \n                self._logger.info(f\"Moving forward: distance={distance}m, speed={speed}m/s\")\n                \n                return self._send_action_client_goal(\n                    self._drive_client, \n                    goal, \n                    f\"Sending Action Client goal in ROSControl.execute_move for {distance}m at {speed}m/s\", \n                    time_allowance\n                )\n            \n            # Queue the action\n            cmd_id = self._command_queue.queue_action_client_request(\n                action_name=\"move\",\n                execute_func=execute_move,\n                priority=0,\n                timeout=time_allowance,\n                distance=distance,\n                speed=speed\n            )\n            self._logger.info(f\"Queued move command: {cmd_id} - Distance: {distance}m, Speed: {speed}m/s\")\n            return True\n                \n        except Exception as e:\n            self._logger.error(f\"Forward movement failed: {e}\")\n            import traceback\n            self._logger.error(traceback.format_exc())\n            return False\n\n    def reverse(self, distance: float, speed: float = 0.5, time_allowance: float = 120) -> bool:\n        \"\"\"\n        Move the robot backward by a specified distance\n        \n        Args:\n            distance: Distance to move backward in meters (must be positive)\n            speed: Speed to move at in m/s (default 0.5)\n            time_allowance: Maximum time to wait for the request to complete\n            \n        Returns:\n            bool: True if movement succeeded\n        \"\"\"\n        try:\n            if distance <= 0:\n                self._logger.error(\"Distance must be positive\")\n                return False\n                \n            speed = min(abs(speed), self.MAX_LINEAR_VELOCITY)\n            \n            # Define function to execute the reverse\n            def execute_reverse():\n                # Create BackUp goal\n                goal = BackUp.Goal()\n                goal.target = Point()\n                goal.target.x = -distance  # Negative for backward motion\n                goal.target.y = 0.0\n                goal.target.z = 0.0\n                goal.speed = speed  # BackUp expects positive speed\n                goal.time_allowance = Duration(sec=time_allowance)\n                \n                print(f\"[ROSControl] execute_reverse: Creating BackUp goal with distance={distance}m, speed={speed}m/s\")\n                print(f\"[ROSControl] execute_reverse: Goal details: x={goal.target.x}, y={goal.target.y}, z={goal.target.z}, speed={goal.speed}\")\n                \n                self._logger.info(f\"Moving backward: distance={distance}m, speed={speed}m/s\")\n                \n                result = self._send_action_client_goal(\n                    self._backup_client, \n                    goal, \n                    f\"Moving backward {distance}m at {speed}m/s\", \n                    time_allowance\n                )\n                \n                print(f\"[ROSControl] execute_reverse: BackUp action result: {result}\")\n                return result\n            \n            # Queue the action\n            cmd_id = self._command_queue.queue_action_client_request(\n                action_name=\"reverse\",\n                execute_func=execute_reverse,\n                priority=0,\n                timeout=time_allowance,\n                distance=distance,\n                speed=speed\n            )\n            self._logger.info(f\"Queued reverse command: {cmd_id} - Distance: {distance}m, Speed: {speed}m/s\")\n            return True\n                \n        except Exception as e:\n            self._logger.error(f\"Backward movement failed: {e}\")\n            import traceback\n            self._logger.error(traceback.format_exc())\n            return False\n\n    def spin(self, degrees: float, speed: float = 45.0, time_allowance: float = 120) -> bool:\n        \"\"\"\n        Rotate the robot by a specified angle\n        \n        Args:\n            degrees: Angle to rotate in degrees (positive for counter-clockwise, negative for clockwise)\n            speed: Angular speed in degrees/second (default 45.0)\n            time_allowance: Maximum time to wait for the request to complete\n            \n        Returns:\n            bool: True if movement succeeded\n        \"\"\"\n        try:\n            # Convert degrees to radians\n            angle = math.radians(degrees)\n            angular_speed = math.radians(abs(speed))\n            \n            # Clamp angular speed\n            angular_speed = min(angular_speed, self.MAX_ANGULAR_VELOCITY)\n            time_allowance = max(int(abs(angle) / angular_speed * 2), 20)  # At least 20 seconds or double the expected time\n            \n            # Define function to execute the spin\n            def execute_spin():\n                # Create Spin goal\n                goal = Spin.Goal()\n                goal.target_yaw = angle  # Nav2 Spin action expects radians\n                goal.time_allowance = Duration(sec=time_allowance)\n                \n                self._logger.info(f\"Spinning: angle={degrees}deg ({angle:.2f}rad)\")\n                \n                return self._send_action_client_goal(\n                    self._spin_client, \n                    goal, \n                    f\"Spinning {degrees} degrees at {speed} deg/s\", \n                    time_allowance\n                )\n            \n            # Queue the action\n            cmd_id = self._command_queue.queue_action_client_request(\n                action_name=\"spin\",\n                execute_func=execute_spin,\n                priority=0,\n                timeout=time_allowance,\n                degrees=degrees,\n                speed=speed\n            )\n            self._logger.info(f\"Queued spin command: {cmd_id} - Degrees: {degrees}, Speed: {speed}deg/s\")\n            return True\n                \n        except Exception as e:\n            self._logger.error(f\"Spin movement failed: {e}\")\n            import traceback\n            self._logger.error(traceback.format_exc())\n            return False\n\n    def _goal_response_callback(self, future):\n        \"\"\"Handle the goal response.\"\"\"\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self._logger.warn('Goal was rejected!')\n            print(\"[ROSControl] Goal was REJECTED by the action server\")\n            self._action_success = False\n            return\n\n        self._logger.info('Goal accepted')\n        print(\"[ROSControl] Goal was ACCEPTED by the action server\")\n        result_future = goal_handle.get_result_async()\n        result_future.add_done_callback(self._goal_result_callback)\n    \n    def _goal_result_callback(self, future):\n        \"\"\"Handle the goal result.\"\"\"\n        try:\n            result = future.result().result\n            self._logger.info('Goal completed')\n            print(f\"[ROSControl] Goal COMPLETED with result: {result}\")\n            self._action_success = True\n        except Exception as e:\n            self._logger.error(f'Goal failed with error: {e}')\n            print(f\"[ROSControl] Goal FAILED with error: {e}\")\n            self._action_success = False\n    \n    def stop(self) -> bool:\n        \"\"\"Stop all robot movement\"\"\"\n        try:\n            self.navigator.cancelTask()\n            self._current_velocity = {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}\n            self._is_moving = False\n            return True\n        except Exception as e:\n            self._logger.error(f\"Failed to stop movement: {e}\")\n            return False\n    \n    def cleanup(self):\n        \"\"\"Cleanup the executor, ROS node, and stop robot.\"\"\"\n        self.stop()\n\n        # Stop the WebRTC queue manager\n        if self._command_queue:\n            self._logger.info(\"Stopping WebRTC queue manager...\")\n            self._command_queue.stop()\n\n        # Shut down the executor to stop spin loop cleanly\n        self._executor.shutdown()\n\n        # Destroy node and shutdown rclpy\n        self._node.destroy_node()\n        rclpy.shutdown()\n\n    def webrtc_req(self, api_id: int,\n                   topic: str = None,\n                   parameter: str = '', \n                   priority: int = 0,\n                   request_id: str = None,\n                   data=None) -> bool:\n        \"\"\"\n        Send a WebRTC request command to the robot\n        \n        Args:\n            api_id: The API ID for the command\n            topic: The API topic to publish to (defaults to self._webrtc_api_topic)\n            parameter: Optional parameter string\n            priority: Priority level (0 or 1)\n            request_id: Optional request ID for tracking (not used in ROS implementation)\n            data: Optional data dictionary (not used in ROS implementation)\n            params: Optional params dictionary (not used in ROS implementation)\n            \n        Returns:\n            bool: True if command was sent successfully\n        \"\"\"\n        try:\n            # Create and send command\n            cmd = self._webrtc_msg_type()\n            cmd.api_id = api_id\n            cmd.topic = topic if topic is not None else self._webrtc_api_topic\n            cmd.parameter = parameter\n            cmd.priority = priority\n            \n            self._webrtc_pub.publish(cmd)\n            self._logger.info(f\"Sent WebRTC request: api_id={api_id}, topic={cmd.topic}\")\n            return True\n            \n        except Exception as e:\n            self._logger.error(f\"Failed to send WebRTC request: {e}\")\n            return False\n            \n    def get_robot_mode(self) -> RobotMode:\n        \"\"\"\n        Get the current robot mode\n        \n        Returns:\n            RobotMode: The current robot mode enum value\n        \"\"\"\n        return self._mode\n    \n    def print_robot_mode(self):\n        \"\"\"Print the current robot mode to the console\"\"\"\n        mode = self.get_robot_mode()\n        print(f\"Current RobotMode: {mode.name}\")\n        print(f\"Mode enum: {mode}\")\n\n    def queue_webrtc_req(self, api_id: int,\n                         topic: str = None,\n                         parameter: str = '',\n                         priority: int = 0, \n                         timeout: float = 90.0,\n                         request_id: str = None,\n                         data=None) -> str:\n        \"\"\"\n        Queue a WebRTC request to be sent when the robot is IDLE\n        \n        Args:\n            api_id: The API ID for the command\n            topic: The topic to publish to (defaults to self._webrtc_api_topic)\n            parameter: Optional parameter string\n            priority: Priority level (0 or 1)\n            timeout: Maximum time to wait for the request to complete\n            request_id: Optional request ID (if None, one will be generated)\n            data: Optional data dictionary (not used in ROS implementation)\n            \n        Returns:\n            str: Request ID that can be used to track the request\n        \"\"\"\n        return self._command_queue.queue_webrtc_request(\n            api_id=api_id,\n            topic=topic if topic is not None else self._webrtc_api_topic,\n            parameter=parameter,\n            priority=priority,\n            timeout=timeout,\n            request_id=request_id,\n            data=data\n        )"}
{"type": "source_file", "path": "dimos/data/data_pipeline.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nfrom dimos.stream.videostream import VideoStream\n\nimport warnings\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nfrom collections import deque\nfrom dimos.types.depth_map import DepthMapType\nfrom dimos.types.label import LabelType\nfrom dimos.types.pointcloud import PointCloudType\nfrom dimos.types.segmentation import SegmentationType\nimport os\n\nclass DataPipeline:\n    def __init__(self, video_stream: VideoStream,\n                 run_depth: bool = False,\n                 run_labels: bool = False,\n                 run_pointclouds: bool = False,\n                 run_segmentations: bool = False,\n                 max_workers: int = 4):\n        self.video_stream = video_stream\n        self.run_depth = run_depth\n        self.run_labels = run_labels\n        self.run_pointclouds = run_pointclouds\n        self.run_segmentations = run_segmentations\n        self.max_workers = max_workers\n\n        # Validate pipeline configuration\n        self._validate_pipeline()\n\n        # Initialize the pipeline\n        self._initialize_pipeline()\n\n        # Storage for processed data\n        self.generated_depth_maps = deque()\n        self.generated_labels = deque()\n        self.generated_pointclouds = deque()\n        self.generated_segmentations = deque()\n\n    def _validate_pipeline(self):\n        \"\"\"Validate the pipeline configuration based on dependencies.\"\"\"\n        if self.run_pointclouds and not self.run_depth:\n            raise ValueError(\"PointClouds generation requires Depth maps. \"\n                             \"Enable run_depth=True to use run_pointclouds=True.\")\n\n        if self.run_segmentations and not self.run_labels:\n            raise ValueError(\"Segmentations generation requires Labels. \"\n                             \"Enable run_labels=True to use run_segmentations=True.\")\n\n        if not any([self.run_depth, self.run_labels, self.run_pointclouds, self.run_segmentations]):\n            warnings.warn(\"No pipeline layers selected to run. The DataPipeline will be initialized without any processing.\")\n\n    def _initialize_pipeline(self):\n        \"\"\"Initialize necessary components based on selected pipeline layers.\"\"\"\n        if self.run_depth:\n            from .depth import DepthProcessor\n            self.depth_processor = DepthProcessor(debug=True)\n            print(\"Depth map generation enabled.\")\n        else:\n            self.depth_processor = None\n\n        if self.run_labels:\n            from .labels import LabelProcessor\n            self.labels_processor = LabelProcessor(debug=True)\n            print(\"Label generation enabled.\")\n        else:\n            self.labels_processor = None\n\n        if self.run_pointclouds:\n            from .pointcloud import PointCloudProcessor\n            self.pointcloud_processor = PointCloudProcessor(debug=True)\n            print(\"PointCloud generation enabled.\")\n        else:\n            self.pointcloud_processor = None\n\n        if self.run_segmentations:\n            from .segment import SegmentProcessor\n            self.segmentation_processor = SegmentProcessor(debug=True)\n            print(\"Segmentation generation enabled.\")\n        else:\n            self.segmentation_processor = None\n\n    def run(self):\n        \"\"\"Execute the selected pipeline layers.\"\"\"\n        try:\n            for frame in self.video_stream:\n                result = self._process_frame(frame)\n                depth_map, label, pointcloud, segmentation = result\n\n                if depth_map is not None:\n                    self.generated_depth_maps.append(depth_map)\n                if label is not None:\n                    self.generated_labels.append(label)\n                if pointcloud is not None:\n                    self.generated_pointclouds.append(pointcloud)\n                if segmentation is not None:\n                    self.generated_segmentations.append(segmentation)\n        except KeyboardInterrupt:\n            print(\"Pipeline interrupted by user.\")\n\n    def _process_frame(self, frame):\n        \"\"\"Process a single frame and return results.\"\"\"\n        depth_map = None\n        label = None\n        pointcloud = None\n        segmentation = None\n\n        if self.run_depth:\n            depth_map = self.depth_processor.process(frame)\n\n        if self.run_labels:\n            label = self.labels_processor.caption_image_data(frame)\n\n        if self.run_pointclouds and isinstance(depth_map, DepthMapType) and self.pointcloud_processor:\n            pointcloud = self.pointcloud_processor.process_frame(frame, depth_map.depth_data)\n\n        if self.run_segmentations and isinstance(label, LabelType) and self.segmentation_processor:\n            segmentation = self.segmentation_processor.process_frame(frame, label.labels)\n\n        return depth_map, label, pointcloud, segmentation\n\n    def save_all_processed_data(self, directory: str):\n        \"\"\"Save all processed data to files in the specified directory.\"\"\"\n        os.makedirs(directory, exist_ok=True)\n\n        for i, depth_map in enumerate(self.generated_depth_maps):\n            if isinstance(depth_map, DepthMapType):\n                depth_map.save_to_file(os.path.join(directory, f\"depth_map_{i}.npy\"))\n\n        for i, label in enumerate(self.generated_labels):\n            if isinstance(label, LabelType):\n                label.save_to_json(os.path.join(directory, f\"labels_{i}.json\"))\n\n        for i, pointcloud in enumerate(self.generated_pointclouds):\n            if isinstance(pointcloud, PointCloudType):\n                pointcloud.save_to_file(os.path.join(directory, f\"pointcloud_{i}.pcd\"))\n\n        for i, segmentation in enumerate(self.generated_segmentations):\n            if isinstance(segmentation, SegmentationType):\n                segmentation.save_masks(os.path.join(directory, f\"segmentation_{i}\"))\n"}
{"type": "source_file", "path": "dimos/exceptions/agent_memory_exceptions.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport traceback\n\nclass AgentMemoryError(Exception):\n    \"\"\"\n    Base class for all exceptions raised by AgentMemory operations.\n    All custom exceptions related to AgentMemory should inherit from this class.\n    \n    Args:\n        message (str): Human-readable message describing the error.\n    \"\"\"\n    def __init__(self, message=\"Error in AgentMemory operation\"):\n        super().__init__(message)\n\nclass AgentMemoryConnectionError(AgentMemoryError):\n    \"\"\"\n    Exception raised for errors attempting to connect to the database.\n    This includes failures due to network issues, authentication errors, or incorrect connection parameters.\n    \n    Args:\n        message (str): Human-readable message describing the error.\n        cause (Exception, optional): Original exception, if any, that led to this error.\n    \"\"\"\n    def __init__(self, message=\"Failed to connect to the database\", cause=None):\n        super().__init__(message)\n        if cause:\n            self.cause = cause\n        self.traceback = traceback.format_exc() if cause else None\n\n    def __str__(self):\n        return f\"{self.message}\\nCaused by: {repr(self.cause)}\" if self.cause else self.message\n\nclass UnknownConnectionTypeError(AgentMemoryConnectionError):\n    \"\"\"\n    Exception raised when an unknown or unsupported connection type is specified during AgentMemory setup.\n    \n    Args:\n        message (str): Human-readable message explaining that an unknown connection type was used.\n    \"\"\"\n    def __init__(self, message=\"Unknown connection type used in AgentMemory connection\"):\n        super().__init__(message)\n\nclass DataRetrievalError(AgentMemoryError):\n    \"\"\"\n    Exception raised for errors retrieving data from the database.\n    This could occur due to query failures, timeouts, or corrupt data issues.\n    \n    Args:\n        message (str): Human-readable message describing the data retrieval error.\n    \"\"\"\n    def __init__(self, message=\"Error in retrieving data during AgentMemory operation\"):\n        super().__init__(message)\n\nclass DataNotFoundError(DataRetrievalError):\n    \"\"\"\n    Exception raised when the requested data is not found in the database.\n    This is used when a query completes successfully but returns no result for the specified identifier.\n    \n    Args:\n        vector_id (int or str): The identifier for the vector that was not found.\n        message (str, optional): Human-readable message providing more detail. If not provided, a default message is generated.\n    \"\"\"\n    def __init__(self, vector_id, message=None):\n        message = message or f\"Requested data for vector ID {vector_id} was not found.\"\n        super().__init__(message)\n        self.vector_id = vector_id\n"}
{"type": "source_file", "path": "dimos/agents/prompt_builder/impl.py", "content": "# Copyright 2025 Dimensional Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nfrom textwrap import dedent\nfrom dimos.agents.tokenizer.openai_impl import AbstractTokenizer, OpenAI_Tokenizer\n\n# TODO: Make class more generic when implementing other tokenizers. Presently its OpenAI specific.\n# TODO: Build out testing and logging\n\nclass PromptBuilder():\n\n    DEFAULT_SYSTEM_PROMPT = dedent(\"\"\"\n    You are an AI assistant capable of understanding and analyzing both visual and textual information. \n    Your task is to provide accurate and insightful responses based on the data provided to you. \n    Use the following information to assist the user with their query. Do not rely on any internal \n    knowledge or make assumptions beyond the provided data.\n\n    Visual Context: You may have been given an image to analyze. Use the visual details to enhance your response.\n    Textual Context: There may be some text retrieved from a relevant database to assist you\n\n    Instructions:\n    - Combine insights from both the image and the text to answer the user's question.\n    - If the information is insufficient to provide a complete answer, acknowledge the limitation.\n    - Maintain a professional and informative tone in your response.\n    \"\"\")\n    \n    def __init__(self, model_name='gpt-4o', max_tokens=128000, tokenizer: AbstractTokenizer = None):\n        \"\"\"\n        Initialize the prompt builder.\n        Args:\n            model_name (str): Model used (e.g., 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo').\n            max_tokens (int): Maximum tokens allowed in the input prompt.\n            tokenizer (AbstractTokenizer): The tokenizer to use for token counting and truncation.\n        \"\"\"\n        self.model_name = model_name\n        self.max_tokens = max_tokens\n        self.tokenizer: AbstractTokenizer = tokenizer or OpenAI_Tokenizer(model_name=self.model_name)\n    \n    def truncate_tokens(self, text, max_tokens, strategy):\n        \"\"\"\n        Truncate text to fit within max_tokens using a specified strategy.\n        Args:\n            text (str): Input text to truncate.\n            max_tokens (int): Maximum tokens allowed.\n            strategy (str): Truncation strategy ('truncate_head', 'truncate_middle', 'truncate_end', 'do_not_truncate').\n        Returns:\n            str: Truncated text.\n        \"\"\"\n        if strategy == \"do_not_truncate\" or not text:\n            return text\n\n        tokens = self.tokenizer.tokenize_text(text)\n        if len(tokens) <= max_tokens:\n            return text\n\n        if strategy == \"truncate_head\":\n            truncated = tokens[-max_tokens:]\n        elif strategy == \"truncate_end\":\n            truncated = tokens[:max_tokens]\n        elif strategy == \"truncate_middle\":\n            half = max_tokens // 2\n            truncated = tokens[:half] + tokens[-half:]\n        else:\n            raise ValueError(f\"Unknown truncation strategy: {strategy}\")\n\n        return self.tokenizer.detokenize_text(truncated)\n    \n    def build(\n        self,\n        system_prompt=None,\n        user_query=None,\n        base64_image=None,\n        image_width=None,\n        image_height=None,\n        image_detail=\"low\",\n        rag_context=None,\n        budgets=None,\n        policies=None,\n        override_token_limit=False,\n    ):\n        \"\"\"\n        Builds a dynamic prompt tailored to token limits, respecting budgets and policies.\n\n        Args:\n            system_prompt (str): System-level instructions.\n            user_query (str, optional): User's query.\n            base64_image (str, optional): Base64-encoded image string.\n            image_width (int, optional): Width of the image.\n            image_height (int, optional): Height of the image.\n            image_detail (str, optional): Detail level for the image (\"low\" or \"high\").\n            rag_context (str, optional): Retrieved context.\n            budgets (dict, optional): Token budgets for each input type. Defaults to equal allocation.\n            policies (dict, optional): Truncation policies for each input type.\n            override_token_limit (bool, optional): Whether to override the token limit. Defaults to False.\n\n        Returns:\n            dict: Messages array ready to send to the OpenAI API.\n        \"\"\"\n        if user_query is None:\n            raise ValueError(\"User query is required.\")\n\n        # Debug:\n        # base64_image = None\n\n        budgets = budgets or {\n            \"system_prompt\": self.max_tokens // 4,\n            \"user_query\": self.max_tokens // 4,\n            \"image\": self.max_tokens // 4,\n            \"rag\": self.max_tokens // 4,\n        }\n        policies = policies or {\n            \"system_prompt\": \"truncate_end\",\n            \"user_query\": \"truncate_middle\",\n            \"image\": \"do_not_truncate\",\n            \"rag\": \"truncate_end\",\n        }\n\n        # Validate and sanitize image_detail\n        if image_detail not in {\"low\", \"high\"}:\n            image_detail = \"low\"  # Default to \"low\" if invalid or None\n\n        # Determine which system prompt to use\n        if system_prompt is None:\n            system_prompt = self.DEFAULT_SYSTEM_PROMPT\n\n        rag_context = rag_context or \"\"\n        \n        # Debug:\n        # print(\"system_prompt: \", system_prompt)\n        # print(\"rag_context: \", rag_context)\n\n        # region Token Counts\n        if not override_token_limit:\n            rag_token_cnt = self.tokenizer.token_count(rag_context)\n            system_prompt_token_cnt = self.tokenizer.token_count(system_prompt)\n            user_query_token_cnt = self.tokenizer.token_count(user_query)\n            image_token_cnt = self.tokenizer.image_token_count(image_width, image_height, image_detail) if base64_image else 0\n        else:\n            rag_token_cnt = 0\n            system_prompt_token_cnt = 0\n            user_query_token_cnt = 0\n            image_token_cnt = 0\n        # endregion Token Counts\n\n        # Create a component dictionary for dynamic allocation\n        components = {\n            \"system_prompt\": {\"text\": system_prompt, \"tokens\": system_prompt_token_cnt},\n            \"user_query\": {\"text\": user_query, \"tokens\": user_query_token_cnt},\n            \"image\": {\"text\": None, \"tokens\": image_token_cnt},\n            \"rag\": {\"text\": rag_context, \"tokens\": rag_token_cnt},\n        }\n\n        if not override_token_limit:\n            # Adjust budgets and apply truncation\n            total_tokens = sum(comp[\"tokens\"] for comp in components.values())\n            excess_tokens = total_tokens - self.max_tokens\n            if excess_tokens > 0:\n                for key, component in components.items():\n                    if excess_tokens <= 0:\n                        break\n                    if policies[key] != \"do_not_truncate\":\n                        max_allowed = max(0, budgets[key] - excess_tokens)\n                        components[key][\"text\"] = self.truncate_tokens(\n                            component[\"text\"], max_allowed, policies[key]\n                        )\n                        tokens_after = self.tokenizer.token_count(components[key][\"text\"])\n                        excess_tokens -= component[\"tokens\"] - tokens_after\n                        component[\"tokens\"] = tokens_after\n\n        # Build the `messages` structure (OpenAI specific)\n        messages = [{\"role\": \"system\", \"content\": components[\"system_prompt\"][\"text\"]}]\n\n        if components[\"rag\"][\"text\"]:\n            user_content = [{\"type\": \"text\", \"text\": f\"{components['rag']['text']}\\n\\n{components['user_query']['text']}\"}]\n        else:\n            user_content = [{\"type\": \"text\", \"text\": components[\"user_query\"][\"text\"]}]\n\n        if base64_image:\n            user_content.append({\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n                    \"detail\": image_detail,\n                },\n            })\n        messages.append({\"role\": \"user\", \"content\": user_content})\n\n        # Debug:\n        # print(\"system_prompt: \", system_prompt)\n        # print(\"user_query: \", user_query)\n        # print(\"user_content: \", user_content)\n        # print(f\"Messages: {messages}\")\n\n        return messages\n"}
{"type": "source_file", "path": "dimos/data/__init__.py", "content": ""}
