{"repo_info": {"repo_name": "netcheck", "repo_owner": "dannywade", "repo_url": "https://github.com/dannywade/netcheck"}}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/test_frontend.py", "content": "from fastapi.testclient import TestClient\nfrom netcheck.main import app\n\n# Initialize the test client\nclient = TestClient(app)\n\n\ndef test_index_page():\n    response = client.get(\"/\")\n    assert response.status_code == 200\n    assert response.template.name == \"index.html\"\n    assert \"request\" in response.context\n\n\ndef test_about_page():\n    response = client.get(\"/about\")\n    assert response.status_code == 200\n    assert response.template.name == \"about.html\"\n    assert \"request\" in response.context\n\n\ndef test_validation_page():\n    response = client.get(\"/validation\")\n    assert response.status_code == 200\n    assert response.template.name == \"validation.html\"\n    assert \"request\" in response.context\n\n\ndef test_analysis_page():\n    response = client.get(\"/analysis\")\n    assert response.status_code == 200\n    assert response.template.name == \"analysis.html\"\n    assert \"request\" in response.context\n"}
{"type": "test_file", "path": "tests/test_backend.py", "content": "from datetime import datetime\nfrom fastapi.testclient import TestClient\nfrom netcheck.main import app, create_test_results, create_inventory_devices\nfrom netcheck.backend.db import create_db_and_tables\n\n# Initialize the test client\nclient = TestClient(app)\n# Create test DB and dummy entries\ncreate_db_and_tables()\ncreate_test_results()\ncreate_inventory_devices()\n\n# Testing the API\ndef test_api_root():\n    response = client.get(\"/\")\n    assert response.status_code == 200\n\n\n### TESTS FOR VALIDATION ENDPOINTS ###\ndef test_api_validation_test_results():\n    response = client.get(\"/api/v1/validation/tests\")\n    assert response.status_code == 200\n\n\ndef test_api_validation_one_test_result():\n    response = client.get(\"/api/v1/validation/tests/1\")\n    assert response.status_code == 200\n\n\ndef test_api_validation_delete_test_result():\n    response = client.delete(\"/api/v1/validation/tests/1\")\n    assert response.status_code == 204\n\n\n### TESTS FOR INVENTORY ENDPOINTS ###\ndef test_api_inventory_device_results():\n    response = client.get(\"/api/v1/inventory/devices\")\n    assert response.status_code == 200\n\n\ndef test_api_inventory_one_device_result():\n    response = client.get(\"/api/v1/inventory/devices/1\")\n    assert response.status_code == 200\n\n\ndef test_api_inventory_delete_device_result():\n    response = client.delete(\"/api/v1/inventory/devices/1\")\n    assert response.status_code == 204\n"}
{"type": "source_file", "path": "netcheck/api/api_v1/api.py", "content": "from fastapi import APIRouter\nfrom api.api_v1.endpoints import analysis, validation, inventory\n\n## File to include all routers\n\napi_router = APIRouter()\n\n# Add analysis endpoints\napi_router.include_router(\n    analysis.router,\n    prefix=\"/analysis\",\n    tags=[\"analysis\"],\n    responses={404: {\"description\": \"Not found\"}},\n)\n\n# Add validation endpoints\napi_router.include_router(\n    validation.router,\n    prefix=\"/validation\",\n    tags=[\"validation\"],\n    responses={404: {\"description\": \"Not found\"}},\n)\n\n# Add inventory endpoints\napi_router.include_router(\n    inventory.router,\n    prefix=\"/inventory\",\n    tags=[\"inventory\"],\n    responses={404: {\"description\": \"Not found\"}},\n)\n"}
{"type": "source_file", "path": "netcheck/api/__init__.py", "content": ""}
{"type": "source_file", "path": "netcheck/api/api_v1/__init__.py", "content": ""}
{"type": "source_file", "path": "netcheck/api/api_v1/endpoints/analysis.py", "content": "from fastapi import APIRouter\n\nrouter = APIRouter()\n\n\n@router.get(\"/interfaces\", tags=[\"analysis\"])\nasync def read_interfaces():\n    return [{\"interfaces\": \"fake_interface_Gig1/0/1\"}]\n"}
{"type": "source_file", "path": "netcheck/api/api_v1/endpoints/__init__.py", "content": ""}
{"type": "source_file", "path": "netcheck/__init__.py", "content": ""}
{"type": "source_file", "path": "netcheck/api/api_v1/endpoints/inventory.py", "content": "from fastapi import APIRouter, HTTPException, Response\nfrom sqlmodel import Session, select\nfrom backend.models import DeviceInventory\nfrom backend.db import engine\nfrom fastapi_pagination import Page, add_pagination, paginate\nfrom starlette.status import HTTP_204_NO_CONTENT\n\nrouter = APIRouter()\n\n\n@router.get(\"/devices\", response_model=Page[DeviceInventory], tags=[\"inventory\"])\ndef get_inventory_results():\n    with Session(engine) as session:\n        results = session.exec(select(DeviceInventory)).all()\n        return paginate(results)\n\n\n@router.get(\"/devices/{device_id}\", response_model=DeviceInventory, tags=[\"inventory\"])\ndef get_single_test_result(device_id: int):\n    with Session(engine) as session:\n        test_result = session.get(DeviceInventory, device_id)\n        if not test_result:\n            raise HTTPException(status_code=404, detail=\"No test results found\")\n        return test_result\n\n\n@router.delete(\n    \"/devices/{device_id}\",\n    # response_model=DeviceInventory,\n    tags=[\"inventory\"],\n)\ndef delete_single_test_result(device_id: int):\n    with Session(engine) as session:\n        statement = select(DeviceInventory).where(\n            DeviceInventory.device_id == device_id\n        )\n        results = session.exec(statement)\n        device_result = results.one()\n\n        session.delete(device_result)\n        session.commit()\n\n        if device_result is None:\n            raise HTTPException(status_code=404, detail=\"No test results found\")\n\n        return Response(status_code=HTTP_204_NO_CONTENT)\n\n\nadd_pagination(router)\n"}
{"type": "source_file", "path": "netcheck/backend/__init__.py", "content": ""}
{"type": "source_file", "path": "netcheck/backend/db.py", "content": "from sqlmodel import SQLModel, create_engine, Session\nfrom datetime import datetime\nfrom .models import TestResults, DeviceInventory\n\nsqlite_file_name = \"database.db\"\nsqlite_url = f\"sqlite:///{sqlite_file_name}\"\n\nengine = create_engine(sqlite_url, echo=True)\n\n\ndef create_db_and_tables():\n    SQLModel.metadata.create_all(engine)\n\n\n# Adds data in as rows\ndef create_dummy_data():\n    current_date = datetime.now()\n    # current_date = get_time.strftime(\"%m/%d/%Y %H:%M:%S\")\n    result1 = TestResults(\n        name=\"circuit_upgrade\",\n        executed_at=current_date,\n        success_rate=100.0,\n        total_tests=3,\n        tests_passed=3,\n        tests_failed=0,\n    )\n    result2 = TestResults(\n        name=\"wan_check\",\n        executed_at=current_date,\n        success_rate=50.0,\n        total_tests=4,\n        tests_passed=2,\n        tests_failed=2,\n    )\n    result3 = TestResults(\n        name=\"l2_stp_check\",\n        executed_at=current_date,\n        success_rate=0,\n        total_tests=3,\n        tests_passed=0,\n        tests_failed=3,\n    )\n    result4 = DeviceInventory(\n        hostname=\"RT-1\",\n        mgmt_ip=\"10.1.1.1\",\n        vendor=\"cisco\",\n        model=\"9500\",\n        os_version=\"17.6.6\",\n        serial_number=\"ABC1234\",\n    )\n    result5 = DeviceInventory(\n        hostname=\"RT-2\",\n        mgmt_ip=\"10.1.1.2\",\n        vendor=\"cisco\",\n        model=\"9300\",\n        os_version=\"17.3.4a\",\n        serial_number=\"ABCD12346\",\n    )\n    result6 = DeviceInventory(\n        hostname=\"RT-3\",\n        mgmt_ip=\"10.1.1.3\",\n        vendor=\"cisco\",\n        model=\"9400\",\n        os_version=\"17.8.8\",\n        serial_number=\"QWERTY4321\",\n    )\n    result7 = DeviceInventory(\n        hostname=\"SW-1\",\n        mgmt_ip=\"10.1.1.2\",\n        vendor=\"cisco\",\n        model=\"9600\",\n        os_version=\"16.8.5\",\n        serial_number=\"ZYX6789\",\n    )\n\n    with Session(engine) as session:\n        session.add(result1)\n        session.add(result2)\n        session.add(result3)\n        session.add(result4)\n        session.add(result5)\n        session.add(result6)\n        session.add(result7)\n\n        session.commit()\n\n        session.refresh(result1)\n"}
{"type": "source_file", "path": "netcheck/helpers/validation.py", "content": "import os\nfrom datetime import datetime\nimport subprocess\nfrom zipfile import ZipFile\nfrom time import sleep\nimport json\nfrom genie.utils import Dq\nimport shutil\nimport yaml\n\nfrom backend.models import TestResults\n\n\"\"\"\nModule used for pyATS functions\n\"\"\"\n\n# Maps frontend values to testscript names for custom validation testing\nTASK_ID_MAPPER = {\n    \"Environment (CPU, Memory, etc.)\": \"environment\",\n    \"BGP Routing\": \"routing_bgp\",\n    \"OSPF Routing\": \"routing_ospf\",\n}\n\n# List of available groups\nGROUPS = [\"env\", \"bgp\", \"ospf\"]\n\n# Maps selected tests to group\nTEST_GROUP_MAPPER = {\n    \"Environment (CPU, Memory, etc.)\": \"env\",\n    \"BGP Routing\": \"bgp\",\n    \"OSPF Routing\": \"ospf\",\n}\n\n\ndef generate_testbed(hostname: str, device_ip: str, os_type: str) -> None:\n\n    tb = {\n        \"devices\": {\n            hostname: {\n                \"connections\": {\n                    \"cli\": {\"ip\": device_ip, \"protocol\": \"ssh\", \"port\": \"22\"}\n                },\n                \"credentials\": {\n                    \"default\": {\n                        \"username\": \"developer\",  # Hardcoded for testing only. Need to change back to env var\n                        \"password\": \"C1sco12345\",\n                    },\n                },\n                \"os\": os_type,\n                \"type\": \"testing_device\",\n                \"alias\": \"uut\",\n            }\n        }\n    }\n\n    # Create temp dir for testbed file\n    temp_path = \"./temp\"\n    if os.path.exists(temp_path):\n        shutil.rmtree(temp_path)\n    os.makedirs(temp_path)\n\n    # Create YAML testbed file\n    with open(f\"{temp_path}/testbed.yaml\", \"w\") as f:\n        yaml.dump(tb, f)\n\n\ndef generate_datafile(testcase_params: dict) -> None:\n    \"\"\"\n    Generate a datafile using a dict of testcase names and params as input.\n\n    Example:\n\n    testcase_params = {\n            bgp_routes: 25,\n            ebgp_neighbors: 2,\n            ibgp_neighbors: 1,\n            local_asn: 65000,\n            remote_asns: [65001, 65002]\n    }\n\n    \"\"\"\n    # Create temp dir for testbed file\n    temp_path = \"./temp\"\n    # Adding params as testscript params vs testcase params\n    # df = {\"testcases\": {**testcase_params}}\n    df = {\"parameters\": {**testcase_params}}\n    # Create YAML testbed file\n    with open(f\"{temp_path}/datafile.yaml\", \"w\") as f:\n        yaml.dump(df, f)\n\n\ndef run_pyats_job(jobfile_name: str, current_dir: str) -> str:\n    \"\"\"\n    Runs pyATS jobfile and stores result in custom archive folder\n    \"\"\"\n    # current_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Get current time\n    now = datetime.now()\n    current_time = now.strftime(\"%Y%b%d-%H:%M\")\n\n    archive_dir_name = current_time\n\n    # Run the pyATS job via Easypy execution\n    py_run = subprocess.run(\n        args=[\n            \"pyats\",\n            \"run\",\n            \"job\",\n            jobfile_name,\n            \"--no-archive-subdir\",\n            \"--archive-dir\",\n            f\"{current_dir}/pyats_logs\",\n            \"--archive-name\",\n            archive_dir_name,\n        ]\n    )\n    # Allow time for archive creation\n    sleep(3)\n    # Return the file path of the archived results\n    results_path = f\"{current_dir}/pyats_logs/{archive_dir_name}.zip\"\n\n    return results_path\n\n\ndef get_pyats_results(results_path: str) -> dict:\n    \"\"\"\n    Extracts the results.json and device CLI log from the archive folder and returns results.json as Python dict\n    \"\"\"\n    # Extracts only the results.json file and store in a temp dir\n    with ZipFile(results_path) as results_zip:\n        results_zip.extract(\"results.json\", \"temp_results\")\n\n        # Extract device logs from the archive and store in the temp dir\n        for fileName in results_zip.namelist():\n            if \"-cli-\" in fileName:\n                results_zip.extract(fileName, \"temp_results\")\n                print(\"Device logs file found and stored in temp dir!\")\n\n        # Open the results.json file and covert to a Python dict\n        with open(\"temp_results/results.json\", \"r\") as results:\n            results_dict = json.load(results)\n\n        return results_dict\n\n\ndef parse_pyats_results(job_results: dict, test_name: str = None) -> TestResults:\n    \"\"\"\n    Passes in pyATS job results as a Python dict and returns a dict of parsed values from results\n    \"\"\"\n\n    # Find success_rate, total, passed, and failed values under the TestSuite results\n    testsuite_results = Dq(job_results).contains_key_value(\"report\", \"summary\")\n    if test_name is None:\n        test_name = job_results[\"report\"][\"name\"]\n    execution_time = job_results[\"report\"][\"starttime\"]\n    success_rate = testsuite_results.get_values(\"success_rate\")  # float\n    total = testsuite_results.get_values(\"total\")\n    passed = testsuite_results.get_values(\"passed\")\n    failed = testsuite_results.get_values(\"failed\")\n\n    parsed_results = TestResults(\n        name=test_name,\n        executed_at=execution_time,\n        success_rate=success_rate[0],\n        total_tests=total[0],\n        tests_passed=passed[0],\n        tests_failed=failed[0],\n    )\n\n    return parsed_results\n\n\ndef read_device_logs() -> str:\n    \"\"\"\n    Reads and returns the device logs\n    \"\"\"\n    temp_results = os.listdir(\"./temp_results\")\n    for fileName in temp_results:\n        if \"-cli-\" in fileName:\n            device_log_file = fileName\n            print(\"Device logs file found and read from temp dir!\")\n\n    # Read device log and return it\n    with open(f\"./temp_results/{device_log_file}\") as f:\n        log = f.read()\n\n    return log\n\n\ndef cleanup_pyats_results() -> None:\n    \"\"\"\n    Remove the temp directory used to store the pyATS job results\n    \"\"\"\n    if os.path.exists(\"temp_results\"):\n        print(\"Temp results directory has been found!\")\n        # Delete the temp dir and all of its content\n        shutil.rmtree(\"temp_results\")\n        print(\"Temp results directory has been deleted!\")\n    else:\n        print(\"Temp results directory not found!\")\n\n\ndef cleanup_pyats_testbed() -> None:\n    \"\"\"\n    Remove the temp directory used to store the pyATS job results\n    \"\"\"\n    if os.path.exists(\"temp\"):\n        print(\"Temp results directory has been found!\")\n        # Delete the temp dir and all of its content\n        shutil.rmtree(\"temp\")\n        print(\"Temp testbed directory has been deleted!\")\n    else:\n        print(\"Temp testbed directory not found!\")\n\n\nif __name__ == \"__main__\":\n    testscript = \"bgp\"\n\n    tc_dict = {\n        \"bgp_routes_testcase\": {\n            \"parameters\": {\n                \"bgp_routes\": 25,\n            }\n        },\n        \"bgp_neighbors_testcase\": {\n            \"parameters\": {\n                \"ebgp_neighbors\": 2,\n                \"ibgp_neighbors\": 1,\n                \"local_asn\": 65000,\n                \"remote_asns\": [65001, 65002],\n            }\n        },\n    }\n\n    generate_datafile(tc_dict)\n    # update_datafile(\"environment\", tc_dict)\n"}
{"type": "source_file", "path": "netcheck/api/api_v1/endpoints/validation.py", "content": "from fastapi import APIRouter, HTTPException, Response\nfrom sqlmodel import Session, select\nfrom backend.models import TestResults, TestResultsRead, TestResultsDelete\nfrom backend.db import engine\nfrom fastapi_pagination import Page, add_pagination, paginate\nfrom starlette.status import HTTP_204_NO_CONTENT\n\nrouter = APIRouter()\n\n\n@router.get(\"/tests\", response_model=Page[TestResultsRead], tags=[\"validation\"])\ndef get_test_results():\n    with Session(engine) as session:\n        results = session.exec(select(TestResults)).all()\n        return paginate(results)\n\n\n@router.get(\"/tests/{test_id}\", response_model=TestResultsRead, tags=[\"validation\"])\ndef get_single_test_result(test_id: int):\n    with Session(engine) as session:\n        test_result = session.get(TestResults, test_id)\n        if not test_result:\n            raise HTTPException(status_code=404, detail=\"No test results found\")\n        return test_result\n\n\n@router.delete(\n    \"/tests/{test_id}\", response_model=TestResultsDelete, tags=[\"validation\"]\n)\ndef delete_single_test_result(test_id: int):\n    with Session(engine) as session:\n        statement = select(TestResults).where(TestResults.test_id == test_id)\n        results = session.exec(statement)\n        test_result = results.one()\n\n        session.delete(test_result)\n        session.commit()\n\n        if test_result is None:\n            raise HTTPException(status_code=404, detail=\"No test results found\")\n\n        return Response(status_code=HTTP_204_NO_CONTENT)\n\n\nadd_pagination(router)\n"}
{"type": "source_file", "path": "netcheck/helpers/__init__.py", "content": ""}
{"type": "source_file", "path": "netcheck/jobfiles/__init__.py", "content": ""}
{"type": "source_file", "path": "netcheck/jobfiles/circuit_jobfile.py", "content": "from pyats.easypy import run\nfrom genie import testbed\n\n\ndef main(runtime):\n\n    # TODO: Need to load testbed from DB or file\n    temp_tb = \"./temp_testbed/testbed.yaml\"\n    loaded_tb = testbed.load(temp_tb)\n    run(testscript=\"testscripts/circuit_upgrade.py\", runtime=runtime, testbed=loaded_tb)\n"}
{"type": "source_file", "path": "netcheck/helpers/runner.py", "content": "\"\"\"Module used for TestRunner class\"\"\"\nfrom datetime import datetime\nimport logging\nimport subprocess\nfrom time import sleep\nfrom pyats.topology import Testbed\nfrom genie.utils import Dq\nimport os\nfrom os.path import exists\nimport json\nfrom zipfile import ZipFile\nimport shutil\n\nfrom backend.models import TestResults\n\nlogger = logging.getLogger(__name__)\n\n# Maps frontend values to testscript names for custom validation testing\nTASK_GROUP_MAPPER = {\n    \"Environment (CPU, Memory, etc.)\": \"environment\",\n    \"BGP Routing\": \"routing_bgp\",\n    \"OSPF Routing\": \"routing_ospf\",\n}\n\n\nclass TestRunner:\n    \"\"\"\n    Instantiate a test runner object that will be used to run all pyATS test jobs and testcases.\n    \"\"\"\n\n    def __init__(self, test_name: str, tests: dict, testbed: Testbed = None) -> None:\n        self.test_name = test_name\n        self.tests = tests\n        self.testbed = testbed\n\n    def run_tests(self, jobfile_name: str, results_path: str) -> str:\n        \"\"\"Runs pyATS jobfile and stores result in a user-defined results path.\"\"\"\n        # Get current time\n        now = datetime.now()\n        current_time = now.strftime(\"%Y%b%d-%H:%M\")\n\n        # Map to proper testscript names and format to fit pyATS logic string input as CLI arg\n        test_names = []\n        for t in self.tests:\n            true_name = TASK_GROUP_MAPPER.get(t, None)\n            test_names.append(\"'\" + true_name + \"'\")\n\n        if not test_names:\n            raise IndexError(\"No group names passed to Easypy.\")\n\n        jobfile_dir = \"./jobfiles\"\n        jobfile_path = f\"{jobfile_dir}/{jobfile_name}\"\n        if not exists(jobfile_path):\n            raise FileNotFoundError(\"Jobfile not found.\")\n\n        archive_dir_name = current_time\n        temp_tb = \"./temp/testbed.yaml\"\n        generated_df = \"./datafiles/main_datafile.yaml\"\n        if not exists(temp_tb) or not exists(generated_df):\n            raise FileNotFoundError(\"Generated testbed or datafile not found.\")\n        # Run the pyATS job via Easypy execution\n        py_run = subprocess.run(\n            args=[\n                \"pyats\",\n                \"run\",\n                \"job\",\n                jobfile_path,\n                \"--testbed-file\",\n                temp_tb,\n                \"--groups\",\n                f\"Or({', '.join(str(x) for x in test_names)})\",\n                \"--datafile\",\n                generated_df,\n                \"--no-archive-subdir\",\n                \"--archive-dir\",\n                f\"{results_path}/pyats_logs\",\n                \"--archive-name\",\n                archive_dir_name,\n            ]\n        )\n        # Allow time for archive creation\n        sleep(3)\n        # Return the file path of the archived results\n        results_path = f\"{results_path}/pyats_logs/{archive_dir_name}.zip\"\n        self.results = results_path\n\n        return results_path\n\n    def get_results(self, results_path: str = None) -> dict:\n        \"\"\"\n        Extracts the results.json and device CLI log from the archive folder and returns results.json as Python dict\n        \"\"\"\n        if results_path is None:\n            results_path = self.results\n        # Extracts only the results.json file and store in a temp dir\n        with ZipFile(results_path) as results_zip:\n            results_zip.extract(\"results.json\", \"temp_results\")\n\n            # Extract device logs from the archive and store in the temp dir\n            for fileName in results_zip.namelist():\n                if \"-cli-\" in fileName:\n                    results_zip.extract(fileName, \"temp_results\")\n                    logger.info(\"Device logs file found and stored in temp dir!\")\n\n            # Open the results.json file and covert to a Python dict\n            with open(\"temp_results/results.json\", \"r\") as results:\n                results_dict = json.load(results)\n            self.job_results = results_dict\n\n            return results_dict\n\n    def parse_results(\n        self,\n        test_name: str = None,\n        job_results: dict = None,\n    ) -> TestResults:\n        \"\"\"\n        Passes in pyATS job results as a Python dict and returns a dict of parsed values from results\n        \"\"\"\n\n        if job_results is None:\n            job_results = self.job_results\n\n        # Find success_rate, total, passed, and failed values under the TestSuite results\n        testsuite_results = Dq(job_results).contains_key_value(\"report\", \"summary\")\n        if test_name is None:\n            test_name = job_results[\"report\"][\"name\"]\n        execution_time = job_results[\"report\"][\"starttime\"]\n        success_rate = testsuite_results.get_values(\"success_rate\")  # float\n        total = testsuite_results.get_values(\"total\")\n        passed = testsuite_results.get_values(\"passed\")\n        failed = testsuite_results.get_values(\"failed\")\n\n        parsed_results = TestResults(\n            name=test_name,\n            executed_at=execution_time,\n            success_rate=success_rate[0],\n            total_tests=total[0],\n            tests_passed=passed[0],\n            tests_failed=failed[0],\n        )\n\n        return parsed_results\n\n    def read_device_logs(self) -> str:\n        \"\"\"\n        Reads and returns the device logs\n        \"\"\"\n        temp_results = os.listdir(\"./temp_results\")\n        for fileName in temp_results:\n            if \"-cli-\" in fileName:\n                device_log_file = fileName\n                logger.info(\"Device logs file found and read from temp dir!\")\n\n        # Read device log and return it\n        with open(f\"./temp_results/{device_log_file}\") as f:\n            log = f.read()\n\n        return log\n\n    def _cleanup_pyats_results(self) -> None:\n        \"\"\"\n        Remove the temp directory used to store the pyATS job results\n        \"\"\"\n        if os.path.exists(\"temp_results\"):\n            logger.info(\"Temp results directory has been found!\")\n            # Delete the temp dir and all of its content\n            shutil.rmtree(\"temp_results\")\n            logger.info(\"Temp results directory has been deleted!\")\n        else:\n            logger.info(\"Temp results directory not found!\")\n\n    def _cleanup_pyats_testbed(self) -> None:\n        \"\"\"\n        Remove the temp directory used to store the pyATS testbed\n        \"\"\"\n        if os.path.exists(\"temp\"):\n            logger.info(\"Temp results directory has been found!\")\n            # Delete the temp dir and all of its content\n            shutil.rmtree(\"temp\")\n            logger.info(\"Temp testbed directory has been deleted!\")\n        else:\n            logger.info(\"Temp testbed directory not found!\")\n\n    def cleanup(self) -> None:\n        \"\"\"\n        Remove the temp directory and pyATS job results\n        \"\"\"\n        self._cleanup_pyats_results()\n        self._cleanup_pyats_testbed()\n"}
{"type": "source_file", "path": "netcheck/helpers/analysis.py", "content": "\"\"\"\nModule used for Batfish functions\n\"\"\"\n"}
{"type": "source_file", "path": "netcheck/backend/models.py", "content": "from typing import Optional\nfrom sqlmodel import Field, SQLModel\nfrom datetime import datetime\n\n# class Device(SQLModel):\n#     hostname: str\n#     ip: str\n#     os: Optional[str] = None\nclass TestResultsBase(SQLModel):\n    name: str\n    executed_at: datetime\n    success_rate: float\n    total_tests: int\n    tests_passed: int\n    tests_failed: int\n\n    def __iter__(self):\n        yield \"name\", self.name\n        yield \"executed_at\", self.executed_at\n        yield \"success_rate\", self.success_rate\n        yield \"total_tests\", self.total_tests\n        yield \"tests_passed\", self.tests_passed\n        yield \"tests_failed\", self.tests_failed\n\n\nclass TestResults(TestResultsBase, table=True):\n    test_id: Optional[int] = Field(default=None, primary_key=True)\n\n\nclass TestResultsRead(TestResultsBase):\n    test_id: int\n\n\nclass TestResultsDelete(TestResultsBase):\n    test_id: int\n\n\nclass InventoryBase(SQLModel):\n    hostname: str\n    mgmt_ip: str\n    vendor: str\n    model: str\n    os_version: str\n    serial_number: str\n\n\nclass DeviceInventory(InventoryBase, table=True):\n    device_id: Optional[int] = Field(default=None, primary_key=True)\n"}
{"type": "source_file", "path": "netcheck/jobfiles/switch_install_jobfile.py", "content": "from pyats.easypy import run\nfrom genie import testbed\n\n\ndef main(runtime):\n\n    temp_tb = \"./temp_testbed/testbed.yaml\"\n    loaded_tb = testbed.load(temp_tb)\n    run(testscript=\"testscripts/switch_install.py\", runtime=runtime, testbed=loaded_tb)\n"}
{"type": "source_file", "path": "netcheck/worker.py", "content": "import os\nimport redis\nfrom rq import Worker, Queue, Connection\n\n# List of queues for workers to listen on\nlisten = [\"default\"]\n\n# Looks for env var, but will default to localhost:6379\nredis_url = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n\n# Redis connection\nconn = redis.from_url(redis_url)\n\n# USED FOR TESTING\nif __name__ == \"__main__\":\n    # Creates worker, connects to the Redis server, and listens to 'default' queue\n    with Connection(conn):\n        worker = Worker(list(map(Queue, listen)))\n        worker.work()\n"}
{"type": "source_file", "path": "netcheck/tasks.py", "content": "from sqlmodel import Session\nfrom backend.db import engine\nfrom helpers.validation import (\n    run_pyats_job,\n    get_pyats_results,\n    parse_pyats_results,\n    cleanup_pyats_results,\n    cleanup_pyats_testbed,\n)\nfrom helpers.runner import TestRunner\nfrom datetime import datetime\nimport os\n\napp_dir = os.path.dirname(__file__)\n\n\ndef run_network_test(test_name: str = None):\n    current_time = datetime.now()\n\n    # TODO: Change jobfile name and pass in test name from user\n    job_results = run_pyats_job(\n        jobfile_name=\"./jobfiles/circuit_jobfile.py\", current_dir=app_dir\n    )\n\n    results_dict = get_pyats_results(results_path=job_results)\n    results_summary = parse_pyats_results(job_results=results_dict, test_name=test_name)\n    # device_logs = read_device_logs()\n\n    # Save test results summary to the database\n    with Session(engine) as session:\n        session.add(results_summary)\n        session.commit()\n        session.refresh(results_summary)\n\n    # TODO: Figure out what should be returned since HTML display is not necessary\n    # Convert test results to a dictionary to use in HTML J2 template\n    html_results = dict(results_summary)\n\n    # Remove temp files used in testing\n    cleanup_pyats_results()\n    cleanup_pyats_testbed()\n\n    return html_results\n\n\ndef run_network_tests(test_name: str = None, tests: list = None):\n    current_time = datetime.now()\n\n    runner = TestRunner(test_name=test_name, tests=tests)\n\n    runner.run_tests(jobfile_name=\"custom_jobfile.py\", results_path=app_dir)\n    runner.get_results()\n    results_summary = runner.parse_results()\n    # device_logs = read_device_logs()\n\n    # Save test results summary to the database\n    with Session(engine) as session:\n        session.add(results_summary)\n        session.commit()\n        session.refresh(results_summary)\n\n    # TODO: Figure out what should be returned since HTML display is not necessary\n    # Convert test results to a dictionary to use in HTML J2 template\n    html_results = dict(results_summary)\n\n    # Remove temp files used in testing\n    runner.cleanup()\n\n    return html_results\n"}
{"type": "source_file", "path": "netcheck/jobfiles/custom_jobfile.py", "content": "from pyats.easypy import run\n\n\ndef main(runtime):\n\n    run(\n        testscript=\"testscripts/custom_main.py\",\n        runtime=runtime,\n    )\n"}
{"type": "source_file", "path": "netcheck/inventory.py", "content": "from netmiko.exceptions import (\n    NetmikoAuthenticationException,\n    NetmikoTimeoutException,\n)\nfrom netmiko import ConnectHandler\nfrom netmiko.ssh_autodetect import SSHDetect\nfrom backend.models import DeviceInventory\n\n\ndef device_connection(ip_addr: str, credentials: dict) -> ConnectHandler:\n    remote_device = {\n        \"device_type\": \"autodetect\",\n        \"host\": ip_addr,\n        \"username\": credentials.get(\"username\"),\n        \"password\": credentials.get(\"password\"),\n    }\n\n    try:\n        guesser = SSHDetect(**remote_device)\n        best_match = guesser.autodetect()\n        remote_device[\"device_type\"] = best_match\n        connection = ConnectHandler(**remote_device)\n    except (\n        NetmikoTimeoutException,\n        NetmikoAuthenticationException,\n    ) as e:\n        print(f\"Could not connect to device due to the following error: {e}\")\n        connection = None\n\n    return connection\n\n\ndef discover_device(device_conn: ConnectHandler) -> DeviceInventory:\n    if (\n        device_conn.device_type == \"cisco_ios\"\n    ):  # May replace with regex exp to match on 'cisco'\n        try:\n            sh_ver = device_conn.send_command(\"show version\", use_genie=True)\n            discovered_device = DeviceInventory(\n                hostname=sh_ver[\"version\"][\"hostname\"],\n                mgmt_ip=device_conn.host,\n                vendor=\"Cisco\",\n                model=sh_ver[\"version\"][\"chassis\"],\n                os_version=sh_ver[\"version\"][\"version\"],\n                serial_number=sh_ver[\"version\"][\"chassis_sn\"],\n            )\n        except (\n            NetmikoTimeoutException,\n            NetmikoAuthenticationException,\n        ) as e:\n            print(f\"Could not connect to device due to the following error: {e}\")\n            discovered_device = None\n    else:\n        # Defaulting to None for now\n        discovered_device = None\n\n    return discovered_device\n"}
{"type": "source_file", "path": "netcheck/main.py", "content": "import ast\nimport uuid\nfrom dotenv import load_dotenv\nfrom fastapi import FastAPI, Request, Form\nfrom fastapi.params import Form\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.responses import HTMLResponse\nfrom sqlalchemy.future import select\nfrom sqlmodel import Session\nimport os\nfrom datetime import datetime\nfrom rq import Queue\n\n# Local imports\nfrom api.api_v1.api import api_router\nfrom backend.models import TestResults, DeviceInventory\nfrom backend.db import create_db_and_tables, create_dummy_data, engine\nfrom helpers.validation import (\n    generate_testbed,\n    generate_datafile,\n    run_pyats_job,\n    get_pyats_results,\n    parse_pyats_results,\n    cleanup_pyats_results,\n    cleanup_pyats_testbed,\n    read_device_logs,\n)\nfrom inventory import device_connection, discover_device\nfrom tasks import run_network_tests\nfrom worker import conn\n\n# Load .env values\nload_dotenv()\n\n# Run the app: uvicorn main:app --reload\n\napp_dir = os.path.dirname(__file__)\n\napi_description = \"API used to validate and performs tests against your network\"\n\napp = FastAPI(description=api_description, version=\"V1\", title=\"NetCheck API\")\n\n# Initializes RQ queue and connects to Redis\nq = Queue(connection=conn)  # no args implies the default queue\n\n# Initialize the SQLite DB\n@app.on_event(\"startup\")\ndef on_startup():\n    create_db_and_tables()\n    # Add dummy records for testing\n    create_dummy_data()\n\n\n# API router\napp.include_router(api_router, prefix=\"/api/v1\")\n\n# Link app to static files and templates\napp.mount(\n    \"/frontend/static\",\n    StaticFiles(directory=f\"{app_dir}/frontend/static\"),\n    name=\"static\",\n)\ntemplates = Jinja2Templates(directory=f\"{app_dir}/frontend/templates\")\n\n# Frontend views\n@app.get(\"/\")\nasync def index(request: Request):\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n\n@app.get(\"/about\", response_class=HTMLResponse)\nasync def about(request: Request):\n    return templates.TemplateResponse(\"about.html\", {\"request\": request})\n\n\n@app.get(\"/inventory\", response_class=HTMLResponse)\nasync def inventory(request: Request):\n    add_status = None\n    return templates.TemplateResponse(\n        \"inventory.html\", {\"request\": request, \"add_status\": add_status}\n    )\n\n\n@app.get(\"/validation\", response_class=HTMLResponse)\nasync def post_checks(request: Request):\n    return templates.TemplateResponse(\"validation.html\", {\"request\": request})\n\n\n@app.get(\"/custom-validation\", response_class=HTMLResponse)\nasync def custom_checks(request: Request):\n    return templates.TemplateResponse(\"custom_validation.html\", {\"request\": request})\n\n\n@app.get(\"/analysis\", response_class=HTMLResponse)\nasync def analysis(request: Request):\n    return templates.TemplateResponse(\"analysis.html\", {\"request\": request})\n\n\n@app.get(\"/custom-results\", response_class=HTMLResponse)\nasync def custom_results(request: Request):\n    return templates.TemplateResponse(\"custom_results.html\", {\"request\": request})\n\n\n@app.get(\"/partials/results-table\", response_class=HTMLResponse)\nasync def results_table(request: Request):\n    with Session(engine) as session:\n        all_test_results = session.exec(select(TestResults)).all()\n    return templates.TemplateResponse(\n        \"partial_results_table.html\", {\"request\": request, \"results\": all_test_results}\n    )\n\n\n@app.post(\"/search-inventory\", response_class=HTMLResponse)\nasync def inventory_table(request: Request, search: str = Form(None)):\n    if search is None:\n        with Session(engine) as session:\n            results = session.exec(select(DeviceInventory)).all()\n            return templates.TemplateResponse(\n                \"partial_inventory_table.html\",\n                {\"request\": request, \"results\": results},\n            )\n    else:\n        with Session(engine) as session:\n            search_match = select(DeviceInventory).where(\n                DeviceInventory.hostname.like(\"%\" + search + \"%\")\n            )\n            results = session.exec(search_match)\n            return templates.TemplateResponse(\n                \"partial_inventory_table.html\",\n                {\"request\": request, \"results\": results},\n            )\n\n\n@app.post(\"/validateForm\", response_class=HTMLResponse)\nasync def validation_results(\n    request: Request,\n    deviceHostname: str = Form(...),\n    osType: str = Form(...),\n    deviceIp: str = Form(...),\n):\n    current_time = datetime.now()\n\n    generate_testbed(hostname=deviceHostname, os_type=osType, device_ip=deviceIp)\n    job_results = run_pyats_job(\n        jobfile_name=\"./jobfiles/circuit_jobfile.py\", current_dir=app_dir\n    )\n    results_dict = get_pyats_results(results_path=job_results)\n    results_summary = parse_pyats_results(job_results=results_dict)\n    device_logs = read_device_logs()\n\n    # Save test results summary to the database\n    with Session(engine) as session:\n        session.add(results_summary)\n        session.commit()\n        session.refresh(results_summary)\n\n    # Convert test results to a dictionary to use in HTML J2 template\n    html_results = dict(results_summary)\n\n    # Remove temp files used in testing\n    cleanup_pyats_results()\n    cleanup_pyats_testbed()\n\n    return templates.TemplateResponse(\n        \"results.html\",\n        {\n            \"request\": request,\n            \"date\": current_time,\n            \"device_ip\": deviceIp,\n            \"output\": device_logs,\n            **html_results,\n        },\n    )\n\n\n@app.post(\"/validateSwitchInstall\", response_class=HTMLResponse)\nasync def validation_results(\n    request: Request,\n    switchHostname: str = Form(...),\n    switchOsType: str = Form(...),\n    switchIp: str = Form(...),\n):\n    current_time = datetime.now()\n\n    generate_testbed(hostname=switchHostname, os_type=switchOsType, device_ip=switchIp)\n    job_results = run_pyats_job(\n        jobfile_name=\"./jobfiles/switch_install_jobfile.py\", current_dir=app_dir\n    )\n    results_dict = get_pyats_results(results_path=job_results)\n    results_summary = parse_pyats_results(job_results=results_dict)\n    device_logs = read_device_logs()\n\n    # Save test results summary to the database\n    with Session(engine) as session:\n        session.add(results_summary)\n        session.commit()\n        session.refresh(results_summary)\n\n    # Convert test results to a dictionary to use in HTML J2 template\n    html_results = dict(results_summary)\n\n    # Remove temp files used in testing\n    # cleanup_pyats_results()\n    # cleanup_pyats_testbed()\n\n    return templates.TemplateResponse(\n        \"results.html\",\n        {\n            \"request\": request,\n            \"date\": current_time,\n            \"device_ip\": switchIp,\n            \"output\": device_logs,\n            **html_results,\n        },\n    )\n\n\n@app.post(\"/custom-post\")\nasync def custom_validation(request: Request):\n    \"\"\"\n    Receives user data from custom validation page, parses data, and runs testcases.\n\n    Example payload from frontend:\n    {\n        \"test_name\": \"test1\",\n        \"tests\": [\"Environment (CPU, Memory, etc.)\"],\n        \"test_details\": [\n            { \"param_name\": \"cpu_util\", \"param_value\": \"50\" },\n            { \"param_name\": \"mem_util\", \"param_value\": \"80\" }\n        ]\n    }\n    \"\"\"\n    # Receive data via XMLHttpRequest\n    test_names = await request.body()\n    # Convert bytes to Python dict for further parsing\n    dict_convert = test_names.decode(\"UTF-8\")\n    my_data = ast.literal_eval(dict_convert)\n\n    # TODO: Figure out better way to validate data (maybe in JS?)\n    if not my_data[\"test_name\"] and not my_data[\"tests\"]:\n        print(\"Form data was empty!\")\n        raise ValueError(\"Form was empty\")\n\n    # Create random ID for tests without user-provided test name\n    if not my_data[\"test_name\"]:\n        my_data[\"test_name\"] = str(uuid.uuid4())\n    print(my_data)\n\n    # Convert testcase parameters into dict for datafile\n    tc_params = {}\n    for item in my_data[\"test_details\"]:\n        param = {item[\"param_name\"]: item[\"param_value\"]}\n        tc_params.update(param)\n\n    print(tc_params)\n    # TODO: Replace static arg values with variables again\n    generate_testbed(\n        hostname=\"csr1000v-1\", os_type=\"iosxe\", device_ip=\"131.226.217.143\"\n    )\n    generate_datafile(tc_params)\n\n    # Pass in list of tests from frontend and execute testscript(s) via pyATS Easypy\n    job = q.enqueue(\n        run_network_tests,\n        test_name=my_data[\"test_name\"],\n        tests=my_data[\"tests\"],\n        job_timeout=\"3m\",\n    )\n\n    # TODO: Provide some additional feedback in logs on job status\n    print(\"Job is being processed!\")\n\n\n@app.post(\"/addDevice\", response_class=HTMLResponse)\nasync def add_inventory_device(\n    request: Request,\n    deviceHostname: str = Form(...),\n    deviceIp: str = Form(...),\n):\n    creds = {\"username\": os.getenv(\"NC_USER\"), \"password\": os.getenv(\"NC_PASSWORD\")}\n    # May make this an async task to allow for quicker response to user\n    device = device_connection(deviceIp, creds)\n    if device is not None:\n        device_record = discover_device(device)\n        # If hostname isn't discovered, use the user's form input\n        if device_record.hostname is None:\n            device_record.hostname = deviceHostname\n    else:\n        device_record = None\n\n    if device_record is not None:\n        # Save device to the device inventory table\n        with Session(engine) as session:\n            session.add(device_record)\n            session.commit()\n            session.refresh(device_record)\n            add_status = True\n    else:\n        add_status = False\n\n    return templates.TemplateResponse(\n        \"inventory.html\", {\"request\": request, \"add_status\": add_status}\n    )\n"}
