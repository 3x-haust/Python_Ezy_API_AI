{"repo_info": {"repo_name": "PicTrace", "repo_owner": "Solrikk", "repo_url": "https://github.com/Solrikk/PicTrace"}}
{"type": "source_file", "path": "assets/ORB/main.py", "content": "from fastapi import FastAPI, UploadFile, File, HTTPException\nimport os\nimport cv2\nimport numpy as np\nimport io\nfrom fastapi.responses import StreamingResponse, HTMLResponse\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.templating import Jinja2Templates\n\napp = FastAPI()\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\ntemplates = Jinja2Templates(directory=\"templates\")\n\ndef orb_feature_matching(img1, img2):\n    orb = cv2.ORB_create()\n    kp1, des1 = orb.detectAndCompute(img1, None)\n    kp2, des2 = orb.detectAndCompute(img2, None)\n    if des1 is None or des2 is None:\n        raise HTTPException(\n            status_code=400,\n            detail=\"No features can be matched in one or both images.\")\n    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n    matches = bf.match(des1, des2)\n    matches = sorted(matches, key=lambda x: x.distance)\n\n    img_matches = cv2.drawMatches(\n        img1,\n        kp1,\n        img2,\n        kp2,\n        matches[:30],\n        None,\n        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS |\n              cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n\n    for i, match in enumerate(matches[:30]):\n        color = tuple(np.random.randint(0, 255, 3).tolist())\n        img1_idx = match.queryIdx\n        img2_idx = match.trainIdx\n        (x1, y1) = kp1[img1_idx].pt\n        (x2, y2) = kp2[img2_idx].pt\n\n        cv2.circle(img_matches, (int(x1), int(y1)), 4, color, 2)\n        cv2.circle(img_matches, (int(x2) + img1.shape[1], int(y2)), 4, color, 2)\n        cv2.line(img_matches, (int(x1), int(y1)),\n                 (int(x2) + img1.shape[1], int(y2)), color, 2)\n\n    return img_matches\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def read_root():\n    html_content = \"\"\"\n    <html>\n        <head>\n            <title>ORB (Oriented FAST and Rotated BRIEF)</title>\n        </head>\n        <body>\n            <h1>Upload two images to match features using ORB</h1>\n            <form action=\"/match-features/\" enctype=\"multipart/form-data\" method=\"post\">\n                <input name=\"imageA\" type=\"file\" accept=\"image/*\" required>\n                <input name=\"imageB\" type=\"file\" accept=\"image/*\" required>\n                <input type=\"submit\">\n            </form>\n        </body>\n    </html>\n    \"\"\"\n    return HTMLResponse(content=html_content)\n\n@app.post(\"/match-features/\")\nasync def match_features(imageA: UploadFile = File(...),\n                         imageB: UploadFile = File(...)):\n    contentsA = await imageA.read()\n    contentsB = await imageB.read()\n    nparrA = np.frombuffer(contentsA, np.uint8)\n    nparrB = np.frombuffer(contentsB, np.uint8)\n    img1 = cv2.imdecode(nparrA, cv2.IMREAD_COLOR)\n    img2 = cv2.imdecode(nparrB, cv2.IMREAD_COLOR)\n    img_matches = orb_feature_matching(img1, img2)\n    _, encoded_img = cv2.imencode('.PNG', img_matches)\n    return StreamingResponse(io.BytesIO(encoded_img.tobytes()),\n                             media_type=\"image/png\")\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"}
{"type": "source_file", "path": "setup.py", "content": "from setuptools import setup, find_packages\n\nsetup(\n    name='pictrace',\n    version='1.0.12',\n    packages=find_packages(),\n    include_package_data=True,\n    install_requires=[\n        'fastapi>=0.106.0',\n        'uvicorn>=0.24.0',\n        'tensorflow>=2.16.1',\n        'pillow>=9.0.0',\n        'numpy>=1.21.0',\n        'jinja2>=3.0.0',\n        'python-multipart'\n    ],\n)\n"}
{"type": "source_file", "path": "assets/SSIM/main.py", "content": "from fastapi import FastAPI, HTTPException, UploadFile, File, Response\nfrom fastapi.responses import HTMLResponse\nfrom skimage.metrics import structural_similarity as compare_ssim\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nfrom io import BytesIO\nfrom PIL import Image\n\napp = FastAPI()\n\ndef read_imagefile(file) -> Image.Image:\n    image = Image.open(BytesIO(file))\n    return image\n\ndef convert_to_gray(image):\n    image = np.array(image)\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return gray\n\ndef resize_image(image, size=(256, 256)):\n    return cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n\ndef load_image(image_file):\n    image = read_imagefile(image_file)\n    if image is None:\n        raise IOError(\"Error loading image. Please check the file and try again.\")\n    gray = convert_to_gray(image)\n    resized_gray = resize_image(gray)\n    return resized_gray\n\n@app.post(\"/uploadfiles/\")\nasync def create_upload_files(imageA: UploadFile = File(...), imageB: UploadFile = File(...)):\n    try:\n        contentsA = await imageA.read()\n        contentsB = await imageB.read()\n        imageA = load_image(contentsA)\n        imageB = load_image(contentsB)\n\n        ssim, diff = compare_ssim(imageA, imageB, full=True)\n        diff = (diff * 255).astype(\"uint8\")\n\n        fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n\n        axs[0].imshow(imageA, cmap='gray')\n        axs[0].set_title('Image A')\n        axs[0].axis('off')\n\n        axs[1].imshow(imageB, cmap='gray')\n        axs[1].set_title('Image B')\n        axs[1].axis('off')\n\n        axs[2].imshow(diff, cmap='gray')\n        axs[2].set_title('Difference')\n        axs[2].axis('off')\n\n        plt.tight_layout()\n        img_buf = BytesIO()\n        plt.savefig(img_buf, format='png')\n        img_buf.seek(0)\n        plt.close(fig)\n\n        img_buf.seek(0)\n        return Response(content=img_buf.read(), media_type=\"image/png\")\n\n    except IOError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/\")\nasync def main():\n    content = \"\"\"\n<body>\n<form action=\"/uploadfiles/\" enctype=\"multipart/form-data\" method=\"post\">\n<input name=\"imageA\" type=\"file\">\n<input name=\"imageB\" type=\"file\">\n<input type=\"submit\">\n</form>\n</body>\n    \"\"\"\n    return HTMLResponse(content=content)"}
{"type": "source_file", "path": "main.py", "content": "import os\nimport zipfile\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom fastapi import FastAPI, UploadFile, File, Request\nfrom fastapi.responses import HTMLResponse\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.staticfiles import StaticFiles\nfrom io import BytesIO\nfrom PIL import Image, UnidentifiedImageError\n\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nSTATIC_DIR = os.path.join(BASE_DIR, \"static\")\nTEMPLATES_DIR = os.path.join(BASE_DIR, \"templates\")\nUPLOAD_FOLDER = os.path.join(BASE_DIR, \"uploads\")\nZIP_PATH = os.path.join(BASE_DIR, \"photos.zip\")\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\n\napp = FastAPI()\nmodel = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\ntemplates = Jinja2Templates(directory=TEMPLATES_DIR)\n\n@app.get(\"/gallery\")\nasync def get_gallery():\n    images = get_images_from_zip()\n    with zipfile.ZipFile(ZIP_PATH, \"r\") as archive:\n        saved_images = []\n        for image_key in images[:20]:  # Show first 20 images\n            try:\n                saved_name = extract_and_save_image(archive, image_key)\n                saved_images.append(saved_name)\n            except Exception as e:\n                print(f\"Error processing image {image_key}: {e}\")\n    return {\"photos\": saved_images}\n\napp.mount(\"/static\", StaticFiles(directory=STATIC_DIR), name=\"static\")\napp.mount(\"/uploads\", StaticFiles(directory=UPLOAD_FOLDER), name=\"uploads\")\n\ndef preprocess_image(image: Image.Image):\n    image = image.resize((224, 224))\n    image_array = np.array(image)\n    if image_array.shape[-1] == 4:\n        image_array = image_array[..., :3]\n    image_array = np.expand_dims(image_array, axis=0)\n    image_array = tf.keras.applications.resnet50.preprocess_input(image_array)\n    return image_array\n\ndef get_image_features(image: Image.Image):\n    return model.predict(preprocess_image(image))\n\ndef compare_images(image1_features, image2_features):\n    return np.linalg.norm(image1_features - image2_features)\n\ndef get_images_from_zip():\n    with zipfile.ZipFile(ZIP_PATH, \"r\") as archive:\n        return [name for name in archive.namelist() if name.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n\ndef extract_and_save_image(archive, image_key):\n    with archive.open(image_key) as image_file:\n        image = Image.open(image_file)\n        safe_image_name = os.path.basename(image_key)\n        image_path = os.path.join(UPLOAD_FOLDER, safe_image_name)\n        image.save(image_path)\n        return safe_image_name\n\n@app.get(\"/get_all_photos\")\nasync def get_all_photos():\n    images = get_images_from_zip()\n    with zipfile.ZipFile(ZIP_PATH, \"r\") as archive:\n        saved_images = []\n        for image_key in images:\n            try:\n                saved_name = extract_and_save_image(archive, image_key)\n                saved_images.append(saved_name)\n            except Exception as e:\n                print(f\"Error processing image {image_key}: {e}\")\n    return {\"photos\": saved_images}\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def read_root(request: Request):\n    return templates.TemplateResponse(\"upload_form.html\", {\"request\": request})\n\n@app.post(\"/find_similar/\")\nasync def find_similar_images(file: UploadFile = File(...)):\n    uploaded_image = Image.open(BytesIO(await file.read()))\n    uploaded_image_features = get_image_features(uploaded_image)\n    images = get_images_from_zip()\n    similarities = []\n    with zipfile.ZipFile(ZIP_PATH, \"r\") as archive:\n        for image_key in images:\n            try:\n                with archive.open(image_key) as image_file:\n                    image = Image.open(image_file).convert(\"RGB\")\n                    similarity = compare_images(uploaded_image_features, get_image_features(image))\n                    similarities.append((image_key, similarity))\n            except UnidentifiedImageError:\n                print(f\"Cannot identify image file: {image_key}\")\n            except Exception as e:\n                print(f\"Error processing image {image_key}: {e}\")\n    similarities.sort(key=lambda x: x[1])\n    similar_images = []\n    with zipfile.ZipFile(ZIP_PATH, \"r\") as archive:\n        for image_key, _ in similarities[:5]:\n            similar_images.append(extract_and_save_image(archive, image_key))\n    return {\"filename\": file.filename, \"similar_images\": similar_images}\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=3000)\n"}
