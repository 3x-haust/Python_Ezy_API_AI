{"repo_info": {"repo_name": "aidialer", "repo_owner": "akiani", "repo_url": "https://github.com/akiani/aidialer"}}
{"type": "source_file", "path": "functions/end_call.py", "content": "import os\nfrom twilio.rest import Client\nimport asyncio\n\nasync def end_call(context, args):\n    # Retrieve the Twilio credentials from environment variables\n    account_sid = os.environ['TWILIO_ACCOUNT_SID']\n    auth_token = os.environ['TWILIO_AUTH_TOKEN']\n    client = Client(account_sid, auth_token)\n    call_sid = context.call_sid\n\n    # Fetch the call\n    call = client.calls(call_sid).fetch()\n\n    # Check if the call is already completed\n    if call.status in ['completed', 'failed', 'busy', 'no-answer', 'canceled']:\n        return f\"Call already ended with status: {call.status}\"\n\n    # Wait for 5 seconds before ending the call to ensure the goodbye goes through\n    await asyncio.sleep(5)\n\n    # End the call\n    call = client.calls(call_sid).update(status='completed')\n\n    return f\"Call ended successfully. Final status: {call.status}\""}
{"type": "source_file", "path": "app.py", "content": "import asyncio\nimport base64\nimport json\nimport os\nfrom collections import deque\nfrom typing import Dict\n\nimport dotenv\nfrom fastapi import FastAPI, WebSocket, WebSocketDisconnect\nfrom fastapi.responses import HTMLResponse\nfrom twilio.rest import Client\nfrom twilio.twiml.voice_response import Connect, VoiceResponse\n\nfrom logger_config import get_logger\nfrom services.call_context import CallContext\nfrom services.llm_service import LLMFactory\nfrom services.stream_service import StreamService\nfrom services.transcription_service import TranscriptionService\nfrom services.tts_service import TTSFactory\n\ndotenv.load_dotenv()\napp = FastAPI()\nlogger = get_logger(\"App\")\n\n# Global dictionary to store call contexts for each server instance (should be replaced with a database in production)\nglobal call_contexts\ncall_contexts = {}\n\n# First route that gets called by Twilio when call is initiated\n@app.post(\"/incoming\")\nasync def incoming_call() -> HTMLResponse:\n    server = os.environ.get(\"SERVER\")\n    response = VoiceResponse()\n    connect = Connect()\n    connect.stream(url=f\"wss://{server}/connection\")\n    response.append(connect)\n    return HTMLResponse(content=str(response), status_code=200)\n\n\n@app.get(\"/call_recording/{call_sid}\")\nasync def get_call_recording(call_sid: str):\n    \"\"\"Get the recording URL for a specific call.\"\"\"\n    recording = get_twilio_client().calls(call_sid).recordings.list()\n    if recording:\n        print({\"recording_url\": f\"https://api.twilio.com/{recording[0].uri}\"})\n        return {\"recording_url\": f\"https://api.twilio.com/{recording[0].uri}\"}\n    if not recording:\n        return {\"error\": \"Recording not found\"}\n    \n# Websocket route for Twilio to get media stream\n@app.websocket(\"/connection\")\nasync def websocket_endpoint(websocket: WebSocket):\n    await websocket.accept()\n\n    llm_service_name = os.getenv(\"LLM_SERVICE\", \"openai\")\n    tts_service_name = os.getenv(\"TTS_SERVICE\", \"deepgram\")\n\n    logger.info(f\"Using LLM service: {llm_service_name}\")\n    logger.info(f\"Using TTS service: {tts_service_name}\")\n\n    llm_service = LLMFactory.get_llm_service(llm_service_name, CallContext())\n    stream_service = StreamService(websocket)\n    transcription_service = TranscriptionService()\n    tts_service = TTSFactory.get_tts_service(tts_service_name)\n    \n    marks = deque()\n    interaction_count = 0\n\n    await transcription_service.connect()\n\n    async def process_media(msg):\n        await transcription_service.send(base64.b64decode(msg['media']['payload']))\n\n    async def handle_transcription(text):\n        nonlocal interaction_count\n        if not text:\n            return\n        logger.info(f\"Interaction {interaction_count} â€“ STT -> LLM: {text}\")\n        await llm_service.completion(text, interaction_count)\n        interaction_count += 1\n\n    async def handle_llm_reply(llm_reply, icount):\n        logger.info(f\"Interaction {icount}: LLM -> TTS: {llm_reply['partialResponse']}\")\n        await tts_service.generate(llm_reply, icount)\n\n    async def handle_speech(response_index, audio, label, icount):\n        logger.info(f\"Interaction {icount}: TTS -> TWILIO: {label}\")\n        await stream_service.buffer(response_index, audio)\n\n    async def handle_audio_sent(mark_label):\n        marks.append(mark_label)\n\n    async def handle_utterance(text, stream_sid):\n        try:\n            if len(marks) > 0 and text.strip():\n                logger.info(\"Intruption detected, clearing system.\")\n                await websocket.send_json({\n                    \"streamSid\": stream_sid,\n                    \"event\": \"clear\"\n                })\n                \n                # reset states\n                stream_service.reset()\n                llm_service.reset()\n\n        except Exception as e:\n            logger.error(f\"Error while handling utterance: {e}\")\n            e.print_stack()\n\n    transcription_service.on('utterance', handle_utterance)\n    transcription_service.on('transcription', handle_transcription)\n    llm_service.on('llmreply', handle_llm_reply)\n    tts_service.on('speech', handle_speech)\n    stream_service.on('audiosent', handle_audio_sent)\n\n    # Queue for incoming WebSocket messages\n    message_queue = asyncio.Queue()\n\n    async def websocket_listener():\n        try:\n            while True:\n                data = await websocket.receive_text()\n                await message_queue.put(json.loads(data))\n        except WebSocketDisconnect:\n            logger.info(\"WebSocket disconnected\")\n\n    async def message_processor():\n        while True:\n            msg = await message_queue.get()\n            if msg['event'] == 'start':\n                stream_sid = msg['start']['streamSid']\n                call_sid = msg['start']['callSid']\n\n                call_context = CallContext()\n\n                if os.getenv(\"RECORD_CALLS\") == \"true\":\n                    get_twilio_client().calls(call_sid).recordings.create({\"recordingChannels\": \"dual\"})\n\n                # Decide if the call the call was initiated from the UI or is an inbound\n                if call_sid not in call_contexts:\n                    # Inbound call\n                    call_context.system_message = os.environ.get(\"SYSTEM_MESSAGE\")\n                    call_context.initial_message = os.environ.get(\"INITIAL_MESSAGE\")\n                    call_context.call_sid = call_sid\n                    call_contexts[call_sid] = call_context\n                else:\n                    # Call from UI, reuse the existing context\n                    call_context = call_contexts[call_sid]\n                \n                llm_service.set_call_context(call_context)\n\n                stream_service.set_stream_sid(stream_sid)\n                transcription_service.set_stream_sid(stream_sid)\n\n                logger.info(f\"Twilio -> Starting Media Stream for {stream_sid}\")\n                await tts_service.generate({\n                    \"partialResponseIndex\": None,\n                    \"partialResponse\": call_context.initial_message\n                }, 1)\n            elif msg['event'] == 'media':\n                asyncio.create_task(process_media(msg))\n            elif msg['event'] == 'mark':\n                label = msg['mark']['name']\n                if label in marks:\n                    marks.remove(label)\n            elif msg['event'] == 'stop':\n                logger.info(f\"Twilio -> Media stream {stream_sid} ended.\")\n                break\n            message_queue.task_done()\n\n    try:\n        listener_task = asyncio.create_task(websocket_listener())\n        processor_task = asyncio.create_task(message_processor())\n\n        await asyncio.gather(listener_task, processor_task)\n    except asyncio.CancelledError:\n        logger.info(\"Tasks cancelled\")\n    finally:\n        await transcription_service.disconnect()\n\ndef get_twilio_client():\n    return Client(os.getenv(\"TWILIO_ACCOUNT_SID\"), os.getenv(\"TWILIO_AUTH_TOKEN\"))\n\n# API route to initiate a call via UI\n@app.post(\"/start_call\")\nasync def start_call(request: Dict[str, str]):\n    \"\"\"Initiate a call using Twilio with optional system and initial messages.\"\"\"\n    to_number = request.get(\"to_number\")\n    system_message = request.get(\"system_message\")\n    initial_message = request.get(\"initial_message\")\n    logger.info(f\"Initiating call to {to_number}\")\n\n    service_url = f\"https://{os.getenv('SERVER')}/incoming\"\n\n    if not to_number:\n        return {\"error\": \"Missing 'to_number' in request\"}\n\n    try:\n        client = get_twilio_client()\n        logger.info(f\"Initiating call to {to_number} via {service_url}\")\n        call = client.calls.create(\n            to=to_number,\n            from_=os.getenv(\"APP_NUMBER\"),\n            url=f\"{service_url}\"\n        )\n        call_sid = call.sid\n        call_context = CallContext()\n        call_contexts[call_sid] = call_context\n        \n\n        # Set custom system and initial messages for this call if provided\n        call_context.system_message = system_message or os.getenv(\"SYSTEM_MESSAGE\")\n        call_context.initial_message = initial_message or os.getenv(\"Config.INITIAL_MESSAGE\")\n        call_context.call_sid = call_sid\n\n        return {\"call_sid\": call_sid}\n    except Exception as e:\n        logger.error(f\"Error initiating call: {str(e)}\")\n        return {\"error\": f\"Failed to initiate call: {str(e)}\"}\n\n# API route to get the status of a call\n@app.get(\"/call_status/{call_sid}\")\nasync def get_call_status(call_sid: str):\n    \"\"\"Get the status of a call.\"\"\"\n    try:\n        client = get_twilio_client()\n        call = client.calls(call_sid).fetch()\n        return {\"status\": call.status}\n    except Exception as e:\n        logger.error(f\"Error fetching call status: {str(e)}\")\n        return {\"error\": f\"Failed to fetch call status: {str(e)}\"}\n\n# API route to end a call\n@app.post(\"/end_call\")\nasync def end_call(request: Dict[str, str]):\n    \"\"\"Get the status of a call.\"\"\"\n    try:\n        call_sid = request.get(\"call_sid\")\n        client = get_twilio_client()\n        client.calls(call_sid).update(status='completed')\n        return {\"status\": \"success\"}\n    except Exception as e:\n        logger.error(f\"Error ending call {str(e)}\")\n        return {\"error\": f\"Failed to end requested call: {str(e)}\"}\n\n# API call to get the transcript for a specific call\n@app.get(\"/transcript/{call_sid}\")\nasync def get_transcript(call_sid: str):\n    \"\"\"Get the entire transcript for a specific call.\"\"\"\n    call_context = call_contexts.get(call_sid)\n\n    if not call_context:\n        logger.info(f\"[GET] Call not found for call SID: {call_sid}\")\n        return {\"error\": \"Call not found\"}\n\n    return {\"transcript\": call_context.user_context}\n\n# API route to get all call transcripts\n@app.get(\"/all_transcripts\")\nasync def get_all_transcripts():\n    \"\"\"Get a list of all current call transcripts.\"\"\"\n    try:\n        transcript_list = []\n        for call_sid, context in call_contexts.items():\n            transcript_list.append({\n                \"call_sid\": call_sid,\n                \"transcript\": context.user_context,\n            })\n        return {\"transcripts\": transcript_list}\n    except Exception as e:\n        logger.error(f\"Error fetching all transcripts: {str(e)}\")\n        return {\"error\": f\"Failed to fetch all transcripts: {str(e)}\"}\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n    logger.info(\"Starting server...\")\n    logger.info(f\"Backend server address set to: {os.getenv('SERVER')}\")\n    port = int(os.getenv(\"PORT\", 3000))\n    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n\n"}
{"type": "source_file", "path": "functions/function_manifest.py", "content": "tools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"transfer_call\",\n            \"description\": \"Transfer call to a human, only do this if the user insists on it.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {}\n            },\n            \"say\": \"Transferring your call, please wait.\"\n        }\n    },    \n    \n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"end_call\",\n            \"description\": \"End the current call but always ask for confirmation unless its a natural place in the conversation (and your intent is fullfilled) to end the call.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {}\n            },\n            \"say\": \"Goodbye.\"\n        }\n    }\n]\n"}
{"type": "source_file", "path": "logger_config.py", "content": "import sys\n\nfrom loguru import logger\n\n# Remove the default handler\nlogger.remove()\n\n# Add a new handler with INFO level\nlogger.add(\n    sys.stderr,\n    format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan> - <level>{message}</level>\",\n    level=\"INFO\",  \n    colorize=True\n)\n\ndef get_logger(name):\n    return logger.bind(name=name)"}
{"type": "source_file", "path": "functions/transfer_call.py", "content": "import os\nfrom twilio.rest import Client\nimport asyncio\n\nasync def transfer_call(context, args):\n    # Retrieve the active call using the CallSid\n    account_sid = os.environ['TWILIO_ACCOUNT_SID']\n    auth_token = os.environ['TWILIO_AUTH_TOKEN']\n    transfer_number = os.environ['TRANSFER_NUMBER']\n\n    client = Client(account_sid, auth_token)\n    call_sid = context.call_sid\n\n    # Wait for 10 seconds before transferring the call\n    await asyncio.sleep(8)\n\n    try:\n        call = client.calls(call_sid).fetch()\n        \n        # Update the call with the transfer number\n        call = client.calls(call_sid).update(\n            url=f'http://twimlets.com/forward?PhoneNumber={transfer_number}',\n            method='POST'\n        )\n            \n        return f\"Call transferred.\"\n\n    except Exception as e:\n        return f\"Error transferring call: {str(e)}\""}
{"type": "source_file", "path": "services/event_emmiter.py", "content": "import asyncio\nfrom typing import Any, Callable, Dict, List\n\n\nclass EventEmitter:\n    \"\"\"\n    A class that represents an event emitter.\n\n    An event emitter allows registering callbacks for specific events and emitting those events\n    with optional arguments and keyword arguments.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the EventEmitter class.\n        \"\"\"\n        self._events: Dict[str, List[Callable]] = {}\n\n    def on(self, event: str, callback: Callable):\n        \"\"\"\n        Registers a callback for a specific event.\n\n        Args:\n            event (str): The name of the event.\n            callback (Callable): The callback function to be executed when the event is emitted.\n        \"\"\"\n        if event not in self._events:\n            self._events[event] = []\n        self._events[event].append(callback)\n\n    async def emit(self, event: str, *args: Any, **kwargs: Any):\n        \"\"\"\n        Emits an event and executes all registered callbacks for that event.\n\n        Args:\n            event (str): The name of the event.\n            *args (Any): Optional positional arguments to be passed to the callbacks.\n            **kwargs (Any): Optional keyword arguments to be passed to the callbacks.\n        \"\"\"\n        if event in self._events:\n            for callback in self._events[event]:\n                await self._run_callback(callback, *args, **kwargs)\n\n    async def _run_callback(self, callback: Callable, *args: Any, **kwargs: Any):\n        \"\"\"\n        Runs a callback function with the provided arguments.\n\n        Args:\n            callback (Callable): The callback function to be executed.\n            *args (Any): Optional positional arguments to be passed to the callback.\n            **kwargs (Any): Optional keyword arguments to be passed to the callback.\n        \"\"\"\n        if asyncio.iscoroutinefunction(callback):\n            await callback(*args, **kwargs)\n        else:\n            callback(*args, **kwargs)"}
{"type": "source_file", "path": "services/llm_service.py", "content": "import importlib\nimport json\nimport os\nimport re\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List\n\nimport anthropic\nfrom openai import AsyncOpenAI\n\nfrom functions.function_manifest import tools\nfrom logger_config import get_logger\nfrom services.call_context import CallContext\nfrom services.event_emmiter import EventEmitter\n\nlogger = get_logger(\"LLMService\")\n\nclass AbstractLLMService(EventEmitter, ABC):\n    def __init__(self, context: CallContext):\n        super().__init__()\n        self.system_message = context.system_message\n        self.initial_message = context.initial_message\n        self.context = context\n        self.user_context = [\n            {\"role\": \"user\", \"content\": \"Hello\"},\n            {\"role\": \"assistant\", \"content\": self.initial_message}\n        ]\n        self.partial_response_index = 0\n        self.available_functions = {}\n        for tool in tools:\n            function_name = tool['function']['name']\n            module = importlib.import_module(f'functions.{function_name}')\n            self.available_functions[function_name] = getattr(module, function_name)\n        self.sentence_buffer = \"\"\n        context.user_context = self.user_context\n\n    def set_call_context(self, context: CallContext):\n        self.context = context\n        self.user_context = [\n            {\"role\": \"user\", \"content\": \"Hello\"},\n            {\"role\": \"assistant\", \"content\": context.initial_message}\n        ]\n        context.user_context = self.user_context\n        self.system_message = context.system_message\n        self.initial_message = context.initial_message\n\n\n    @abstractmethod\n    async def completion(self, text: str, interaction_count: int, role: str = 'user', name: str = 'user'):\n        pass\n\n    def reset(self):\n        self.partial_response_index = 0\n\n    def validate_function_args(self, args):\n        try:\n            return json.loads(args)\n        except json.JSONDecodeError:\n            logger.info('Warning: Invalid function arguments returned by LLM:', args)\n            return {}\n\n    @staticmethod\n    def convert_openai_tools_to_anthropic(openai_tools):\n        anthropic_tools = []\n        for tool in openai_tools:\n            if tool['type'] == 'function':\n                function = tool['function']\n                anthropic_tool = {\n                    \"name\": function['name'],\n                    \"description\": function.get('description', ''),\n                    \"input_schema\": {\n                        \"type\": \"object\",\n                        \"properties\": function.get('parameters', {}).get('properties', {}),\n                        \"required\": function.get('parameters', {}).get('required', [])\n                    }\n                }\n                \n                # Remove 'description' from individual properties if present\n                for prop in anthropic_tool['input_schema']['properties'].values():\n                    prop.pop('description', None)\n                \n                # If there are no properties, set an empty dict\n                if not anthropic_tool['input_schema']['properties']:\n                    anthropic_tool['input_schema']['properties'] = {}\n                \n                anthropic_tools.append(anthropic_tool)\n        \n        return anthropic_tools\n\n    def split_into_sentences(self, text):\n        # Split the text into sentences, keeping the separators\n        sentences = re.split(r'([.!?])', text)\n        # Pair the sentences with their separators\n        sentences = [''.join(sentences[i:i+2]) for i in range(0, len(sentences), 2)]\n        return sentences\n\n    async def emit_complete_sentences(self, text, interaction_count):\n        self.sentence_buffer += text\n        sentences = self.split_into_sentences(self.sentence_buffer)\n        \n        # Emit all complete sentences\n        for sentence in sentences[:-1]:\n            await self.emit('llmreply', {\n                \"partialResponseIndex\": self.partial_response_index,\n                \"partialResponse\": sentence.strip()\n            }, interaction_count)\n            self.partial_response_index += 1\n        \n        # Keep the last (potentially incomplete) sentence in the buffer\n        self.sentence_buffer = sentences[-1] if sentences else \"\"\n\nclass OpenAIService(AbstractLLMService):\n    def __init__(self, context: CallContext):\n        super().__init__(context)\n        self.openai = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n    async def completion(self, text: str, interaction_count: int, role: str = 'user', name: str = 'user'):\n        try:\n            self.user_context.append({\"role\": role, \"content\": text, \"name\": name})\n            messages = [{\"role\": \"system\", \"content\": self.system_message}] + self.user_context\n        \n            stream = await self.openai.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=messages,\n                tools=tools,\n                stream=True,\n            )\n\n            complete_response = \"\"\n            function_name = \"\"\n            function_args = \"\"\n\n            async for chunk in stream:\n                delta = chunk.choices[0].delta\n                content = delta.content or \"\"\n                tool_calls = delta.tool_calls\n\n                if tool_calls:\n                    for tool_call in tool_calls:\n                        if tool_call.function and tool_call.function.name:\n                            logger.info(f\"Function call detected: {tool_call.function.name}\")\n                            function_name = tool_call.function.name\n                            function_args += tool_call.function.arguments or \"\"\n                else:\n                    complete_response += content\n                    await self.emit_complete_sentences(content, interaction_count)\n\n                if chunk.choices[0].finish_reason == \"tool_calls\":\n                    logger.info(f\"Function call detected: {function_name}\")\n                    function_to_call = self.available_functions[function_name]\n                    function_args = self.validate_function_args(function_args)\n                    \n                    tool_data = next((tool for tool in tools if tool['function']['name'] == function_name), None)\n                    say = tool_data['function']['say']\n\n                    await self.emit('llmreply', {\n                        \"partialResponseIndex\": None,\n                        \"partialResponse\": say\n                    }, interaction_count)\n\n                    self.user_context.append({\"role\": \"assistant\", \"content\": say})\n                    \n                    function_response = await function_to_call(self.context, function_args)\n                                        \n                    logger.info(f\"Function {function_name} called with args: {function_args}\")\n\n                    if function_name != \"end_call\":\n                        await self.completion(function_response, interaction_count, 'function', function_name)\n\n            # Emit any remaining content in the buffer\n            if self.sentence_buffer.strip():\n                await self.emit('llmreply', {\n                    \"partialResponseIndex\": self.partial_response_index,\n                    \"partialResponse\": self.sentence_buffer.strip()\n                }, interaction_count)\n                self.sentence_buffer = \"\"\n\n            self.user_context.append({\"role\": \"assistant\", \"content\": complete_response})\n\n        except Exception as e:\n            logger.error(f\"Error in OpenAIService completion: {str(e)}\")\n\n\nclass AnthropicService(AbstractLLMService):\n    def __init__(self, context: CallContext):\n        super().__init__(context)\n        self.client = anthropic.AsyncAnthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n        # Add a dummy user message to ensure the first message is from the user\n        self.user_context = [\n            {\"role\": \"user\", \"content\": \"Hello\"},\n            {\"role\": \"assistant\", \"content\": self.initial_message}\n        ]\n\n    async def completion(self, text: str, interaction_count: int, role: str = 'user', name: str = 'user'):\n        try:\n            self.user_context.append({\"role\": role, \"content\": text})\n            \n            messages = [{\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in self.user_context]\n            \n            async with self.client.messages.stream(\n                model=\"claude-3-opus-20240229\",\n                max_tokens=300,\n                system=self.system_message,\n                messages=messages,\n                tools=self.convert_openai_tools_to_anthropic(tools),\n            ) as stream:\n                complete_response = \"\"\n                async for event in stream:\n                    if event.type == \"text\":\n                        content = event.text\n                        complete_response += content\n                        await self.emit_complete_sentences(content, interaction_count)\n                    elif event.type == \"tool_call\":\n                        function_name = event.tool_call.function.name\n                        function_args = event.tool_call.function.arguments\n                        logger.info(f\"Function call detected: {function_name}\")\n                        function_to_call = self.available_functions[function_name]\n                        function_args = self.validate_function_args(function_args)\n                        \n                        tool_data = next((tool for tool in tools if tool['function']['name'] == function_name), None)\n                        say = tool_data['function']['say']\n\n                        await self.emit('llmreply', {\n                            \"partialResponseIndex\": None,\n                            \"partialResponse\": say\n                        }, interaction_count)\n\n                        function_response = await function_to_call(function_args)\n                                            \n                        logger.info(f\"Function {function_name} called with args: {function_args}\")\n\n                        if function_name != \"end_call\":\n                            await self.completion(function_response, interaction_count, 'function', function_name)\n\n                # Emit any remaining content in the buffer\n                if self.sentence_buffer.strip():\n                    await self.emit('llmreply', {\n                        \"partialResponseIndex\": self.partial_response_index,\n                        \"partialResponse\": self.sentence_buffer.strip()\n                    }, interaction_count)\n                    self.sentence_buffer = \"\"\n\n                final_message = await stream.get_final_message()\n                self.user_context.append({\"role\": \"assistant\", \"content\": final_message.content[0].text})\n\n        except Exception as e:\n            logger.error(f\"Error in AnthropicService completion: {str(e)}\")\n\nclass LLMFactory:\n    @staticmethod\n    def get_llm_service(service_name: str, context: CallContext) -> AbstractLLMService:\n        if service_name.lower() == \"openai\":\n            return OpenAIService(context)\n        elif service_name.lower() == \"anthropic\":\n            return AnthropicService(context)\n        else:\n            raise ValueError(f\"Unsupported LLM service: {service_name}\")"}
{"type": "source_file", "path": "services/stream_service.py", "content": "import uuid\nfrom typing import Dict\n\nfrom fastapi import WebSocket\n\nfrom logger_config import get_logger\nfrom services.event_emmiter import EventEmitter\n\nlogger = get_logger(\"Stream\")\n\nclass StreamService(EventEmitter):\n    def __init__(self, websocket: WebSocket):\n        super().__init__()\n        self.ws = websocket\n        self.expected_audio_index = 0\n        self.audio_buffer: Dict[int, str] = {}\n        self.stream_sid = ''\n\n    def set_stream_sid(self, stream_sid: str):\n        self.stream_sid = stream_sid\n\n    async def buffer(self, index: int, audio: str):\n        if index is None:\n            await self.send_audio(audio)\n        elif index == self.expected_audio_index:\n            await self.send_audio(audio)\n            self.expected_audio_index += 1\n\n            while self.expected_audio_index in self.audio_buffer:\n                buffered_audio = self.audio_buffer[self.expected_audio_index]\n                await self.send_audio(buffered_audio)\n                del self.audio_buffer[self.expected_audio_index]\n                self.expected_audio_index += 1\n        else:\n            self.audio_buffer[index] = audio\n\n    def reset(self):\n        self.expected_audio_index = 0\n        self.audio_buffer = {}\n\n    async def send_audio(self, audio: str):\n        await self.ws.send_json({\n            \"streamSid\": self.stream_sid,\n            \"event\": \"media\",\n            \"media\": {\n                \"payload\": audio\n            }\n        })\n\n        mark_label = str(uuid.uuid4())\n\n        await self.ws.send_json({\n            \"streamSid\": self.stream_sid,\n            \"event\": \"mark\",\n            \"mark\": {\n                \"name\": mark_label\n            }\n        })\n\n        await self.emit('audiosent', mark_label)"}
{"type": "source_file", "path": "services/tts_service.py", "content": "\nimport base64\nimport os\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict\n\nimport aiohttp\nimport numpy as np\nfrom deepgram import DeepgramClient, LiveOptions\nfrom dotenv import load_dotenv\n\nfrom logger_config import get_logger\nfrom services.event_emmiter import EventEmitter\n\nload_dotenv()\nlogger = get_logger(\"TTS\")\n\n\nclass AbstractTTSService(EventEmitter, ABC):\n    @abstractmethod\n    async def generate(self, llm_reply: Dict[str, Any], interaction_count: int):\n        pass\n\n    @abstractmethod\n    async def set_voice(self, voice_id: str):\n        pass\n\n    @abstractmethod\n    async def disconnect(self):\n        pass\n\nclass ElevenLabsTTS(AbstractTTSService):\n    def __init__(self):\n        super().__init__()\n        self.voice_id = os.getenv(\"ELEVENLABS_VOICE_ID\")\n        self.api_key = os.getenv(\"ELEVENLABS_API_KEY\")\n        self.model_id = os.getenv(\"ELEVENLABS_MODEL_ID\")\n        self.speech_buffer = {}\n\n\n    def set_voice(self, voice_id):\n        self.voice_id = voice_id\n\n    async def disconnect(self):\n        # ElevenLabs client doesn't require explicit disconnection\n        return\n\n\n    async def generate(self, llm_reply: Dict[str, Any], interaction_count: int):\n        partial_response_index, partial_response = llm_reply['partialResponseIndex'], llm_reply['partialResponse']\n\n        if not partial_response:\n            return\n\n        try:\n            output_format = \"ulaw_8000\"            \n            url = f\"https://api.elevenlabs.io/v1/text-to-speech/{self.voice_id}/stream\"\n            headers = {\n                \"xi-api-key\": self.api_key,\n                \"Content-Type\": \"application/json\",\n                \"Accept\": \"audio/wav\"\n            }\n            params = {\n                \"output_format\": output_format,\n                \"optimize_streaming_latency\": 4\n            }\n            data = {\n                \"model_id\": self.model_id,\n                \"text\": partial_response\n            }\n\n            async with aiohttp.ClientSession() as session:\n                async with session.post(url, headers=headers, params=params, json=data) as response:\n                    if response.status == 200:\n                        audio_content = await response.read()\n                        audio_base64 = base64.b64encode(audio_content).decode('utf-8')\n                        await self.emit('speech', partial_response_index, audio_base64, partial_response, interaction_count)\n        except Exception as err:\n            logger.error(\"Error occurred in ElevenLabs TTS service\", exc_info=True)\n            logger.error(str(err))\n\n\nclass DeepgramTTS(AbstractTTSService):\n    def __init__(self):\n        super().__init__()\n        self.client = DeepgramClient(os.getenv(\"DEEPGRAM_API_KEY\"))\n\n    async def generate(self, llm_reply, interaction_count):\n        partial_response_index = llm_reply['partialResponseIndex']\n        partial_response = llm_reply['partialResponse']\n\n        if not partial_response:\n            return\n\n        try:\n            source = {\n                \"text\": partial_response\n            }\n\n            options = {\n                \"model\": \"aura-asteria-en\",\n                \"encoding\": \"mulaw\", \n                \"sample_rate\": 8000 \n            }\n            \n            response = await self.client.asyncspeak.v(\"1\").stream(\n                source={\"text\": partial_response},\n                options=options\n            )\n\n            if response.stream:\n                audio_content = response.stream.getvalue()\n                \n                # Convert audio to numpy array\n                audio_array = np.frombuffer(audio_content, dtype=np.uint8)\n                \n                # Trim the first 10ms (80 samples at 8000Hz) to remove the initial noise\n                trim_samples = 80\n                trimmed_audio = audio_array[trim_samples:]\n                \n                # Convert back to bytes\n                trimmed_audio_bytes = trimmed_audio.tobytes()\n\n                audio_base64 = base64.b64encode(trimmed_audio_bytes).decode('utf-8')\n                await self.emit('speech', partial_response_index, audio_base64, partial_response, interaction_count)\n            else:\n                logger.error(\"Error in TTS generation: No audio stream returned\")\n\n        except Exception as e:\n            logger.error(f\"Error in TTS generation: {str(e)}\")\n\n\n    async def set_voice(self, voice_id):\n        logger.info(f\"Attempting to set voice to {voice_id}, but Deepgram TTS doesn't support direct voice selection.\")\n        # TODO(akiani): Implement voice selection in Deepgram TTS\n\n    async def disconnect(self):\n        # Deepgram client doesn't require explicit disconnection\n        logger.info(\"DeepgramTTS service disconnected\")\n\n\nclass TTSFactory:\n    @staticmethod\n    def get_tts_service(service_name: str) -> AbstractTTSService:\n        if service_name.lower() == \"elevenlabs\":\n            return ElevenLabsTTS()\n        elif service_name.lower() == \"deepgram\":\n            return DeepgramTTS()\n        else:\n            raise ValueError(f\"Unsupported TTS service: {service_name}\")\n\n# Usage in your main application\ntts_service_name = os.getenv(\"TTS_SERVICE\", \"deepgram\")  # Default to deepgram if not specified\ntts_service = TTSFactory.get_tts_service(tts_service_name)"}
{"type": "source_file", "path": "services/transcription_service.py", "content": "import os\n\nfrom deepgram import DeepgramClient, LiveOptions, LiveTranscriptionEvents\n\nfrom logger_config import get_logger\nfrom services.event_emmiter import EventEmitter\n\nlogger = get_logger(\"Transcription\")\n\nclass TranscriptionService(EventEmitter):\n    def __init__(self):\n        super().__init__()\n        self.client = DeepgramClient(os.getenv(\"DEEPGRAM_API_KEY\"))\n        self.deepgram_live = None\n        self.final_result = \"\"\n        self.speech_final = False\n        self.stream_sid = None\n\n    def set_stream_sid(self, stream_id):\n        self.stream_sid = stream_id\n\n    def get_stream_sid(self):\n        return self.stream_sid\n\n    async def connect(self):\n        self.deepgram_live = self.client.listen.asynclive.v(\"1\")\n        await self.deepgram_live.start(LiveOptions(\n            model=\"nova-2\", \n            language=\"en-US\", \n            encoding=\"mulaw\",\n            sample_rate=8000,\n            channels=1,\n            punctuate=True,\n            interim_results=True,\n            endpointing=200,\n            utterance_end_ms=1000\n        ))\n\n        self.deepgram_live.on(LiveTranscriptionEvents.Transcript, self.handle_transcription)\n        self.deepgram_live.on(LiveTranscriptionEvents.Error, self.handle_error)\n        self.deepgram_live.on(LiveTranscriptionEvents.Close, self.handle_close)\n        self.deepgram_live.on(LiveTranscriptionEvents.Warning, self.handle_warning)\n        self.deepgram_live.on(LiveTranscriptionEvents.Metadata, self.handle_metadata)\n        self.deepgram_live.on(LiveTranscriptionEvents.UtteranceEnd, self.handle_utterance_end)\n\n    async def handle_utterance_end(self, self_obj, utterance_end):\n        try:\n            if not self.speech_final:\n                logger.info(f\"UtteranceEnd received before speech was final, emit the text collected so far: {self.final_result}\")\n                await self.emit('transcription', self.final_result)\n                self.final_result = ''\n                self.speech_final = True\n                return\n            else:\n                return\n        except Exception as e:\n            logger.error(f\"Error while handling utterance end: {e}\")\n            e.print_stack()\n\n    async def handle_transcription(self, self_obj, result):\n        try:\n            alternatives = result.channel.alternatives if hasattr(result, 'channel') else []\n            text = alternatives[0].transcript if alternatives else \"\"\n\n            if result.is_final and text.strip():\n                self.final_result += f\" {text}\"\n                if result.speech_final:\n                    self.speech_final = True\n                    await self.emit('transcription', self.final_result)\n                    self.final_result = ''\n                else:\n                    self.speech_final = False\n            else:\n                if text.strip():\n                    stream_sid = self.stream_sid\n                    await self.emit('utterance', text, stream_sid)\n        except Exception as e:\n            logger.error(f\"Error while handling transcription: {e}\")\n            e.print_stack()\n\n            \n    async def handle_error(self, self_obj, error):\n        logger.error(f\"Deepgram error: {error}\")\n        self.is_connected = False\n    \n    async def handle_warning(self, self_obj, warning):\n        logger.info('Deepgram warning:', warning)\n\n    async def handle_metadata(self, self_obj, metadata):\n        logger.info('Deepgram metadata:', metadata)\n\n    async def handle_close(self, self_obj, close):\n        logger.info(\"Deepgram connection closed\")\n        self.is_connected = False\n\n    async def send(self, payload: bytes):\n        if self.deepgram_live:            \n            await self.deepgram_live.send(payload)\n    \n    async def disconnect(self):\n        if self.deepgram_live:\n            await self.deepgram_live.finish()\n            self.deepgram_live = None\n        self.is_connected = False\n        logger.info(\"Disconnected from Deepgram\")"}
{"type": "source_file", "path": "services/call_context.py", "content": "from typing import List, Optional\n\n\nclass CallContext:\n    \"\"\"Store context for the current call.\"\"\"\n    def __init__(self):\n        self.stream_sid: Optional[str] = None\n        self.call_sid: Optional[str] = None\n        self.call_ended: bool = False\n        self.user_context: List = []\n        self.system_message: str = \"\"\n        self.initial_message: str = \"\"\n        self.start_time: Optional[str] = None\n        self.end_time: Optional[str] = None\n        self.final_status: Optional[str] = None\n        \n"}
{"type": "source_file", "path": "ui/streamlit_app.py", "content": "import os\nimport time\nimport requests\nimport streamlit as st\nimport dotenv\n\ndotenv.load_dotenv(verbose=True)\n\nst.set_page_config(page_title=\"AI Dialer\", page_icon=\"ðŸ“ž\", layout=\"wide\")\n\ndef display_call_interface():\n    return st.text_input(\"Phone Number (format: +1XXXXXXXXXX)\", value=os.getenv(\"YOUR_NUMBER\") or \"\")\n\ndef fetch_all_transcripts():\n    try:\n        response = requests.get(f\"https://{os.getenv('SERVER')}/all_transcripts\")\n        return response.json().get('transcripts', [])\n    except requests.RequestException as e:\n        st.error(f\"Error fetching call list: {str(e)}\")\n        return []\n\nif 'call_active' not in st.session_state:\n    st.session_state.call_active = False\n    st.session_state.call_sid = None\n    st.session_state.transcript = []\n    st.session_state.system_message = os.getenv(\"SYSTEM_MESSAGE\")\n    st.session_state.initial_message = os.getenv(\"INITIAL_MESSAGE\")\n    st.session_state.all_transcripts = fetch_all_transcripts()\n    st.session_state.recording_info = None\n    st.session_state.call_selector = \"Current Call\"\n\nwith st.sidebar:\n    st.markdown(\"<h2 style='text-align: center; font-size: 2.5em;'>ðŸ“ž AI Dialer</h2>\", unsafe_allow_html=True)\n    st.divider()\n    \n    phone_number = display_call_interface()\n    \n    st.session_state.system_message = st.text_area(\"System Message\", value=st.session_state.system_message, disabled=st.session_state.call_active)\n    st.session_state.initial_message = st.text_area(\"Initial Message\", value=st.session_state.initial_message, disabled=st.session_state.call_active)\n    \n    start_call = st.button(\"Start Call\", disabled=st.session_state.call_active)\n    end_call = st.button(\"End Call\", disabled=not st.session_state.call_active)\n\n    if start_call and phone_number:\n        with st.spinner(f\"Calling {phone_number}...\"):\n            try:\n                response = requests.post(f\"https://{os.getenv('SERVER')}/start_call\", json={\n                    \"to_number\": phone_number,\n                    \"system_message\": st.session_state.system_message,\n                    \"initial_message\": st.session_state.initial_message\n                }, timeout=10)\n                call_data = response.json()\n                if call_sid := call_data.get('call_sid'):\n                    st.session_state.call_sid = call_sid\n                    st.session_state.transcript = []\n                    st.success(f\"Call initiated. SID: {call_sid}\")\n                    for _ in range(60):\n                        time.sleep(1)\n                        status = requests.get(f\"https://{os.getenv('SERVER')}/call_status/{call_sid}\").json().get('status')\n                        if status == 'in-progress':\n                            st.session_state.call_active = True\n                            st.session_state.call_selector = \"Current Call\"\n                            break\n                        if status in ['completed', 'failed', 'busy', 'no-answer']:\n                            st.error(f\"Call ended: {status}\")\n                            break\n                    else:\n                        st.error(\"Timeout waiting for call to connect.\")\n                else:\n                    st.error(f\"Failed to initiate call: {call_data}\")\n            except requests.RequestException as e:\n                st.error(f\"Error: {str(e)}\")\n    elif start_call:\n        st.warning(\"Please enter a valid phone number.\")\n\n    if end_call:\n        try:\n            response = requests.post(f\"https://{os.getenv('SERVER')}/end_call\", json={\"call_sid\": st.session_state.call_sid})\n            if response.status_code == 200:\n                st.success(\"Call ended successfully.\")\n                st.session_state.call_active = False\n                st.session_state.call_sid = None\n                st.rerun()\n            else:\n                st.error(f\"Failed to end call: {response.text}\")\n        except requests.RequestException as e:\n            st.error(f\"Error ending call: {str(e)}\")\n\n    if st.session_state.call_active:\n        st.success(\"Call in progress\")\n    st.divider()\n\n# Call selection controls\ndef fetch_recording_info(call_sid):\n    try:\n        response = requests.get(f\"https://{os.getenv('SERVER')}/call_recording/{call_sid}\")\n        if media_url := response.json().get('recording_url'):\n            media_response = requests.get(media_url)\n            if media_response.status_code == 200:\n                media_data = media_response.json()\n                return {\n                    'url': f\"{media_data.get('media_url')}.mp3\",\n                    'duration': media_data.get('duration', 0)\n                }\n    except requests.RequestException as e:\n        st.error(f\"Error fetching recording info: {str(e)}\")\n    return None\n\ndef on_call_selector_change():\n    if st.session_state.call_selector != \"Current Call\":\n        selected_transcript = next((t for t in st.session_state.all_transcripts if f\"Call {t['call_sid']}\" == st.session_state.call_selector), None)\n        if selected_transcript:\n            st.session_state.recording_info = fetch_recording_info(selected_transcript['call_sid'])\n        else:\n            st.warning(\"No transcript found for the selected call.\")\n    else:\n        st.session_state.recording_info = None\n\nst.selectbox(\n    \"Select a call\",\n    options=[\"Current Call\"] + [f\"Call {t['call_sid']}\" for t in st.session_state.all_transcripts],\n    key=\"call_selector\",\n    index=0,\n    disabled=st.session_state.call_active,\n    on_change=on_call_selector_change\n)\n\nif st.button(\"Refresh Call List\"):\n    try:\n        response = requests.get(f\"https://{os.getenv('SERVER')}/all_transcripts\")\n        st.session_state.all_transcripts = response.json().get('transcripts', [])\n        on_call_selector_change()  # Refresh the recording URL after updating the call list\n    except requests.RequestException as e:\n        st.error(f\"Error fetching call list: {str(e)}\")\n    # Keep the existing system and initial messages (don't reset to env values)\n\nst.divider()\n\n# Call Recording and Transcript display\nwith st.spinner(\"Loading recording and transcript...\"):\n    # Call Recording display\n    if st.session_state.call_selector != \"Current Call\" and st.session_state.recording_info:\n        st.subheader(\"Call Recording\")\n        audio_url = st.session_state.recording_info['url']\n        st.audio(audio_url, format=\"audio/mp3\", start_time=0)\n        st.divider()\n\n    # Transcript display\n    if st.session_state.call_active and st.session_state.call_sid:\n        st.subheader(f\"Transcript for Current Call {st.session_state.call_sid}\")\n        for entry in st.session_state.transcript:\n            if entry['role'] == 'user':\n                st.chat_message(\"user\").write(entry['content'])\n            elif entry['role'] == 'assistant':\n                st.chat_message(\"assistant\").write(entry['content'])\n    elif st.session_state.call_selector != \"Current Call\":\n        if transcript := next((t for t in st.session_state.all_transcripts if f\"Call {t['call_sid']}\" == st.session_state.call_selector), None):\n            st.subheader(f\"Transcript for {st.session_state.call_selector}\")\n            for entry in transcript['transcript']:\n                if entry['role'] == 'user':\n                    st.chat_message(\"user\").write(entry['content'])\n                elif entry['role'] == 'assistant':\n                    st.chat_message(\"assistant\").write(entry['content'])\n\nif st.session_state.call_active:\n    def update_call_info():\n        try:\n            status = requests.get(f\"https://{os.getenv('SERVER')}/call_status/{st.session_state.call_sid}\").json().get('status')\n            if status not in ['in-progress', 'ringing']:\n                st.session_state.call_active = False\n                st.warning(f\"Call ended: {status}\")\n                return False\n            \n            transcript_data = requests.get(f\"https://{os.getenv('SERVER')}/transcript/{st.session_state.call_sid}\").json()\n            if transcript_data.get('call_ended', False):\n                st.session_state.call_active = False\n                st.info(f\"Call ended. Status: {transcript_data.get('final_status', 'Unknown')}\")\n                return False\n            \n            st.session_state.transcript = transcript_data.get('transcript', [])\n            return True\n        except requests.RequestException as e:\n            st.sidebar.error(f\"Error updating call info: {str(e)}\")\n            return False\n\n    if update_call_info():\n        time.sleep(1)\n        st.rerun()\n    else:\n        st.session_state.call_active = False\n        st.session_state.call_sid = None\n        st.sidebar.info(\"Call has ended. You can start a new call if needed.\")\n        st.rerun()\n"}
