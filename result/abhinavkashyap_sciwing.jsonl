{"repo_info": {"repo_name": "sciwing", "repo_owner": "abhinavkashyap", "repo_url": "https://github.com/abhinavkashyap/sciwing"}}
{"type": "test_file", "path": "tests/data/test_contextual_lines.py", "content": "import pytest\nfrom sciwing.data.contextual_lines import LineWithContext\n\n\n@pytest.fixture\ndef line_context():\n    line = \"This is a single line\"\n    context = [\"This is the first contextual line\", \"This is the second context\"]\n    return line, context\n\n\nclass TestLinesWithContext:\n    def test_namespaces(self, line_context):\n        line, context = line_context\n        line_with_context = LineWithContext(text=line, context=context)\n        namespaces = line_with_context.namespaces\n        assert \"tokens\" in namespaces\n        assert \"contextual_tokens\" in namespaces\n"}
{"type": "test_file", "path": "tests/data/test_dataset_manager.py", "content": "import pytest\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.utils.class_nursery import ClassNursery\n\n\n@pytest.fixture(scope=\"session\")\ndef clf_dataset_manager(tmpdir_factory, request):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train_file.txt\")\n    train_file.write(\"train_line1###label1\\ntrain_line2###label2\")\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev_file.txt\")\n    dev_file.write(\"dev_line1###label1\\ndev_line2###label2\")\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test_file.txt\")\n    test_file.write(\"dev_line1###label1\\ndev_line2###label2\")\n\n    clf_dataset_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    return clf_dataset_manager\n\n\nclass TestDatasetManager:\n    def test_namespaces(self, clf_dataset_manager):\n        namespaces = clf_dataset_manager.namespaces\n        assert set(namespaces) == {\"tokens\", \"char_tokens\", \"label\"}\n\n    def test_namespace_to_vocab(self, clf_dataset_manager):\n        namespace_to_vocab = clf_dataset_manager.namespace_to_vocab\n        assert namespace_to_vocab[\"tokens\"].get_vocab_len() == 2 + 4\n        # there is no special vocab here\n        assert namespace_to_vocab[\"label\"].get_vocab_len() == 2\n\n    def test_namespace_to_numericalizers(self, clf_dataset_manager):\n        namespace_to_numericalizer = clf_dataset_manager.namespace_to_numericalizer\n        assert set(namespace_to_numericalizer.keys()) == {\n            \"tokens\",\n            \"char_tokens\",\n            \"label\",\n        }\n\n    def test_label_namespace(self, clf_dataset_manager):\n        label_namespaces = clf_dataset_manager.label_namespaces\n        assert label_namespaces == [\"label\"]\n\n    def test_num_labels(self, clf_dataset_manager):\n        num_labels = clf_dataset_manager.num_labels[\"label\"]\n        assert num_labels == 2\n\n    def test_print_stats(self, clf_dataset_manager):\n        try:\n            clf_dataset_manager.print_stats()\n        except:\n            pytest.fail(f\"Print Stats fail to work in datasets manager\")\n\n    def test_texclassification_dataset_manager_in_nursery(self, clf_dataset_manager):\n        assert (\n            ClassNursery.class_nursery[\"TextClassificationDatasetManager\"] is not None\n        )\n"}
{"type": "test_file", "path": "tests/data/test_label.py", "content": "import pytest\nfrom sciwing.data.label import Label\n\n\nclass TestLabel:\n    def test_label_str_getter(self):\n        label = Label(text=\"Introduction\", namespace=\"label\")\n        tokens = label.tokens[\"label\"]\n        token_text = tokens[0].text\n        assert token_text == \"Introduction\"\n"}
{"type": "test_file", "path": "tests/data/test_line.py", "content": "import pytest\nfrom sciwing.data.line import Line\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\nfrom sciwing.tokenizers.character_tokenizer import CharacterTokenizer\n\n\nclass TestLine:\n    def test_line_word_tokenizers(self):\n        text = \"This is a single line\"\n        line = Line(text=text, tokenizers={\"tokens\": WordTokenizer()})\n        tokens = line.tokens\n        assert [token.text for token in tokens[\"tokens\"]] == [\n            \"This\",\n            \"is\",\n            \"a\",\n            \"single\",\n            \"line\",\n        ]\n\n    def test_line_char_tokenizer(self):\n        text = \"Word\"\n        line = Line(\n            text=text,\n            tokenizers={\"tokens\": WordTokenizer(), \"chars\": CharacterTokenizer()},\n        )\n        tokens = line.tokens\n        word_tokens = tokens[\"tokens\"]\n        char_tokens = tokens[\"chars\"]\n\n        word_tokens = [tok.text for tok in word_tokens]\n        char_tokens = [tok.text for tok in char_tokens]\n\n        assert word_tokens == [\"Word\"]\n        assert char_tokens == [\"W\", \"o\", \"r\", \"d\"]\n\n    def test_line_namespaces(self):\n        text = \"Single line\"\n        line = Line(text=text, tokenizers={\"tokens\": WordTokenizer()})\n        assert line.namespaces == [\"tokens\"]\n"}
{"type": "test_file", "path": "tests/data/test_seq_label.py", "content": "from sciwing.data.seq_label import SeqLabel\nimport pytest\n\n\n@pytest.fixture\ndef setup_seq_labels():\n    labels = [\"B-PER\", \"L-PER\"]\n    label = SeqLabel(labels={\"seq_label\": labels})\n    return label\n\n\nclass TestSeqLabel:\n    def test_labels_set(self, setup_seq_labels):\n        label = setup_seq_labels\n        tokens = label.tokens[\"seq_label\"]\n        for token in tokens:\n            assert len(token.text) > 1\n            assert isinstance(token.text, str)\n"}
{"type": "test_file", "path": "tests/data/test_seq_sentence.py", "content": "from sciwing.data.seq_sentence import SeqSentence\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\nfrom sciwing.tokenizers.character_tokenizer import CharacterTokenizer\nimport pytest\n\n\nclass TestSeqSentence:\n    def test_sents_word_tokenizers(self):\n        sents = [\"Nice people\", \"Great weather\"]\n        sent = SeqSentence(sents=sents, tokenizers={\"tokens\": WordTokenizer()})\n        tokens = sent.tokens\n        assert [\n            [token.text for token in sent_tokens] for sent_tokens in tokens[\"tokens\"]\n        ] == [[\"Nice\", \"people\"], [\"Great\", \"weather\"]]\n\n    def test_sents_char_tokenizer(self):\n        sents = [\"Hello\", \"World\"]\n        sent = SeqSentence(\n            sents=sents,\n            tokenizers={\"tokens\": WordTokenizer(), \"chars\": CharacterTokenizer()},\n        )\n        tokens = sent.tokens\n        word_tokens = tokens[\"tokens\"]\n        char_tokens = tokens[\"chars\"]\n\n        word_tokens = [\n            [tok.text for tok in sent_word_tokens] for sent_word_tokens in word_tokens\n        ]\n        char_tokens = [\n            [tok.text for tok in sent_char_tokens] for sent_char_tokens in char_tokens\n        ]\n\n        assert word_tokens == [[\"Hello\"], [\"World\"]]\n        assert char_tokens == [[\"H\", \"e\", \"l\", \"l\", \"o\"], [\"W\", \"o\", \"r\", \"l\", \"d\"]]\n\n    def test_line_namespaces(self):\n        sents = [\"Nice people\", \"Great weather\"]\n        sent = SeqSentence(sents=sents, tokenizers={\"tokens\": WordTokenizer()})\n        assert sent.namespaces == [\"tokens\"]\n"}
{"type": "test_file", "path": "tests/data/test_token.py", "content": "import pytest\nfrom sciwing.data.token import Token\nimport numpy as np\n\n\nclass TestToken:\n    def test_token_initialization(self):\n        token = Token(\"token\")\n        assert token.text == \"token\"\n\n    def test_token_len(self):\n        token = Token(\"token\")\n        assert token.len == 5\n\n    @pytest.mark.parametrize(\n        \"embedding_type, embedding\",\n        [(\"glove\", np.random.rand(100)), (\"bert\", np.random.rand(1000))],\n    )\n    def test_token_set_embedding(self, embedding_type, embedding):\n        token = Token(\"token\")\n        try:\n            token.set_embedding(name=embedding_type, value=embedding)\n        except:\n            pytest.fail(\"setting the embedding failed\")\n"}
{"type": "test_file", "path": "tests/datasets/classification/test_generic_sect_dataset.py", "content": "from sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nimport pytest\nimport sciwing.constants as constants\nimport pathlib\n\nFILES = constants.FILES\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nGENERIC_SECTION_TRAIN_FILE = FILES[\"GENERIC_SECTION_TRAIN_FILE\"]\n\n\n@pytest.fixture(scope=\"module\")\ndef setup_generic_sect_dataset_manager():\n    data_dir = pathlib.Path(DATA_DIR)\n    sect_label_train_file = data_dir.joinpath(\"genericSect.train\")\n    sect_label_dev_file = data_dir.joinpath(\"genericSect.dev\")\n    sect_label_test_file = data_dir.joinpath(\"genericSect.test\")\n\n    dataset_manager = TextClassificationDatasetManager(\n        train_filename=sect_label_train_file,\n        dev_filename=sect_label_dev_file,\n        test_filename=sect_label_test_file,\n    )\n\n    return dataset_manager\n\n\nclass TestGenericSectDataset:\n    def test_num_labels(self, setup_generic_sect_dataset_manager):\n        dataset_manager = setup_generic_sect_dataset_manager\n        train_dataset = dataset_manager.train_dataset\n        lines, labels = train_dataset.get_lines_labels()\n        labels = [label.text for label in labels]\n        num_labels = len(set(labels))\n        assert num_labels == 12\n\n    def test_no_line_empty(self, setup_generic_sect_dataset_manager):\n        dataset_manager = setup_generic_sect_dataset_manager\n        for dataset in [\n            dataset_manager.train_dataset,\n            dataset_manager.dev_dataset,\n            dataset_manager.test_dataset,\n        ]:\n            lines, labels = dataset.get_lines_labels()\n            assert all([bool(line.text.strip()) for line in lines])\n\n    def test_no_train_label_empty(self, setup_generic_sect_dataset_manager):\n        dataset_manager = setup_generic_sect_dataset_manager\n        for dataset in [\n            dataset_manager.train_dataset,\n            dataset_manager.dev_dataset,\n            dataset_manager.test_dataset,\n        ]:\n            lines, labels = dataset.get_lines_labels()\n            assert all([bool(label.text.strip()) for label in labels])\n"}
{"type": "test_file", "path": "tests/datasets/classification/test_sectlabel_dataset.py", "content": "import sciwing.constants as constants\nimport pytest\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nimport pathlib\n\nFILES = constants.PATHS\nDATA_DIR = FILES[\"DATA_DIR\"]\n\n\n@pytest.fixture(scope=\"module\")\ndef setup_sectlabel_dataset_manager():\n    data_dir = pathlib.Path(DATA_DIR)\n    sect_label_train_file = data_dir.joinpath(\"sectLabel.train\")\n    sect_label_dev_file = data_dir.joinpath(\"sectLabel.dev\")\n    sect_label_test_file = data_dir.joinpath(\"sectLabel.test\")\n\n    dataset_manager = TextClassificationDatasetManager(\n        train_filename=sect_label_train_file,\n        dev_filename=sect_label_dev_file,\n        test_filename=sect_label_test_file,\n    )\n\n    return dataset_manager\n\n\nclass TestSectLabelDataset:\n    def test_label_mapping_len(self, setup_sectlabel_dataset_manager):\n        dataset_manager = setup_sectlabel_dataset_manager\n        train_dataset = dataset_manager.train_dataset\n        lines, labels = train_dataset.get_lines_labels()\n        labels = [label.text for label in labels]\n        labels = list(set(labels))\n        assert len(labels) == 23\n\n    def test_no_line_empty(self, setup_sectlabel_dataset_manager):\n        dataset_manager = setup_sectlabel_dataset_manager\n        for dataset in [\n            dataset_manager.train_dataset,\n            dataset_manager.dev_dataset,\n            dataset_manager.test_dataset,\n        ]:\n            lines, labels = dataset.get_lines_labels()\n            assert all([bool(line.text.strip()) for line in lines])\n\n    def test_no_label_empty(self, setup_sectlabel_dataset_manager):\n        dataset_manager = setup_sectlabel_dataset_manager\n        for dataset in [\n            dataset_manager.train_dataset,\n            dataset_manager.dev_dataset,\n            dataset_manager.test_dataset,\n        ]:\n            lines, labels = dataset.get_lines_labels()\n            assert all([bool(label.text.strip()) for label in labels])\n"}
{"type": "test_file", "path": "tests/datasets/classification/test_text_classification_dataset.py", "content": "import pytest\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDataset,\n)\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\n\n\n@pytest.fixture(scope=\"session\")\ndef test_file(tmpdir_factory):\n    p = tmpdir_factory.mktemp(\"data\").join(\"test.txt\")\n    p.write(\"line1###label1\\nline2###label2\")\n    return p\n\n\nclass TestTextClassificationDataset:\n    def test_get_lines_labels(self, test_file):\n        classification_dataset = TextClassificationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        lines = classification_dataset.lines\n        assert len(lines) == 2\n\n    def test_len_dataset(self, test_file):\n        classification_dataset = TextClassificationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        assert len(classification_dataset) == 2\n\n    def test_get_item(self, test_file):\n        classification_dataset = TextClassificationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        num_instances = len(classification_dataset)\n        tokens = [\"line1\", \"line2\"]\n        line_tokens = []\n        for idx in range(num_instances):\n            line, label = classification_dataset[idx]\n            line_tokens.extend(line.tokens[\"tokens\"])\n\n        line_tokens = list(map(lambda token: token.text, line_tokens))\n\n        assert set(tokens) == set(line_tokens)\n"}
{"type": "test_file", "path": "tests/datasets/seq_labeling/test_conll_dataset.py", "content": "import pytest\nfrom sciwing.datasets.seq_labeling.conll_dataset import (\n    CoNLLDataset,\n    CoNLLDatasetManager,\n)\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\nfrom sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\n\n\n@pytest.fixture(scope=\"session\")\ndef test_file(tmpdir_factory):\n    p = tmpdir_factory.mktemp(\"data\").join(\"test.txt\")\n    p.write(\"word1 O-Task O-Process O-Material\\nword2 B-Task B-Process O-Material\")\n    return p\n\n\nclass TestCoNLLDataset:\n    def test_get_lines_labels_len(self, test_file):\n        dataset = CoNLLDataset(\n            filename=test_file, tokenizers={\"tokens\": WordTokenizer()}\n        )\n\n        lines, labels = dataset.get_lines_labels()\n        assert len(lines) == 1\n        assert len(labels) == 1\n\n    def test_labels_namespaces(self, test_file):\n        dataset = CoNLLDataset(\n            filename=test_file,\n            tokenizers={\"tokens\": WordTokenizer()},\n            column_names=[\"NER\", \"POS\", \"DEP\"],\n        )\n        lines, labels = dataset.get_lines_labels()\n        for label in labels:\n            namespaces = label.namespace\n            assert len(namespaces) == 3\n            assert \"NER\" in namespaces\n            assert \"POS\" in namespaces\n            assert \"DEP\" in namespaces\n\n    def test_len_lines_labels_equal(self, test_file):\n        dataset = CoNLLDataset(\n            filename=test_file,\n            tokenizers={\"tokens\": WordTokenizer()},\n            column_names=[\"NER\", \"POS\", \"DEP\"],\n        )\n        lines, labels = dataset.get_lines_labels()\n        for line, label in zip(lines, labels):\n            line_tokens = line.tokens[\"tokens\"]\n            labels_ner = label.tokens[\"NER\"]\n            labels_pos = label.tokens[\"POS\"]\n            labels_dep = label.tokens[\"DEP\"]\n            assert (\n                len(line_tokens)\n                == len(labels_ner)\n                == len(labels_pos)\n                == len(labels_dep)\n            )\n\n    @pytest.mark.parametrize(\"train_only\", [\"ner\", \"pos\", \"dep\"])\n    def test_restricted_namesapces(self, test_file, train_only):\n        dataset = CoNLLDataset(\n            filename=test_file,\n            tokenizers={\"tokens\": WordTokenizer()},\n            column_names=[\"POS\", \"DEP\", \"NER\"],\n            train_only=train_only,\n        )\n        lines, labels = dataset.get_lines_labels()\n\n        for label in labels:\n            namespaces = label.namespace\n            assert len(namespaces) == 1\n            assert train_only.upper() in namespaces\n\n    def test_conll_dataset_manager(self, test_file):\n        instance_preprocessing = InstancePreprocessing()\n        manager = CoNLLDatasetManager(\n            train_filename=test_file,\n            dev_filename=test_file,\n            test_filename=test_file,\n            namespace_vocab_options={\n                \"tokens\": {\n                    \"preprocessing_pipeline\": [instance_preprocessing.lowercase],\n                    \"include_special_vocab\": False,\n                }\n            },\n        )\n\n        token_vocab = manager.namespace_to_vocab[\"tokens\"].get_token2idx_mapping()\n\n        for token in token_vocab.keys():\n            assert token.islower()\n"}
{"type": "test_file", "path": "tests/datasets/seq_labeling/test_parscit_dataset.py", "content": "import sciwing.constants as constants\nimport pytest\nimport pathlib\nfrom sciwing.datasets.seq_labeling.seq_labelling_dataset import (\n    SeqLabellingDatasetManager,\n)\n\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\n@pytest.fixture\ndef setup_parscit_dataset_manager():\n    data_dir = pathlib.Path(DATA_DIR)\n    parscit_train_file = data_dir.joinpath(\"parscit.train\")\n    parscit_dev_file = data_dir.joinpath(\"parscit.dev\")\n    parscit_test_file = data_dir.joinpath(\"parscit.test\")\n\n    dataset_manager = SeqLabellingDatasetManager(\n        train_filename=str(parscit_train_file),\n        dev_filename=str(parscit_dev_file),\n        test_filename=str(parscit_test_file),\n    )\n    return dataset_manager\n\n\nclass TestParscitDataset:\n    def test_num_classes(self, setup_parscit_dataset_manager):\n        dataset_manager = setup_parscit_dataset_manager\n        train_dataset = dataset_manager.train_dataset\n        dev_dataset = dataset_manager.dev_dataset\n        test_dataset = dataset_manager.test_dataset\n\n        for dataset in [train_dataset, dev_dataset, test_dataset]:\n            lines, labels = dataset.get_lines_labels()\n            train_labels = []\n            for label in labels:\n                label_tokens = label.tokens[\"seq_label\"]\n                label_tokens = [tok.text for tok in label_tokens]\n                train_labels.extend(label_tokens)\n            train_labels = set(train_labels)\n            num_classes = len(train_labels)\n            assert num_classes == 14\n\n    def test_num_lines(self, setup_parscit_dataset_manager):\n        dataset_manager = setup_parscit_dataset_manager\n        train_dataset = dataset_manager.train_dataset\n        dev_dataset = dataset_manager.dev_dataset\n        test_dataset = dataset_manager.test_dataset\n        assert len(train_dataset) == 1245\n        assert len(dev_dataset) == 139\n        assert len(test_dataset) == 139\n\n    def test_lines_labels_not_empty(self, setup_parscit_dataset_manager):\n        dataset_manager = setup_parscit_dataset_manager\n        train_dataset = dataset_manager.train_dataset\n        dev_dataset = dataset_manager.dev_dataset\n        test_dataset = dataset_manager.test_dataset\n        datasets = [train_dataset, dev_dataset, test_dataset]\n        for dataset in datasets:\n            lines, labels = dataset.get_lines_labels()\n            for line, label in zip(lines, labels):\n                assert bool(line.text.strip())\n                assert len(label.labels) > 0\n\n    def test_lines_labels_equal_length(self, setup_parscit_dataset_manager):\n        dataset_manager = setup_parscit_dataset_manager\n        datasets = [\n            dataset_manager.train_dataset,\n            dataset_manager.dev_dataset,\n            dataset_manager.test_dataset,\n        ]\n        for dataset in datasets:\n            lines, labels = dataset.get_lines_labels()\n            for line, label in zip(lines, labels):\n                assert len(line.tokens[\"tokens\"]) == len(label.tokens[\"seq_label\"])\n\n    def test_idx2label_mapping(self, setup_parscit_dataset_manager):\n        dataset_manager = setup_parscit_dataset_manager\n        idx_label_mapping = dataset_manager.get_idx_label_mapping(\n            label_namespace=\"seq_label\"\n        )\n        assert len(idx_label_mapping) == 18\n\n    def test_label_namespace(self, setup_parscit_dataset_manager):\n        dataset_manager = setup_parscit_dataset_manager\n        label_namespaces = dataset_manager.label_namespaces\n        assert len(label_namespaces) == 1\n        assert label_namespaces == [\"seq_label\"]\n"}
{"type": "test_file", "path": "tests/datasets/seq_labeling/test_conll_yago_dataset.py", "content": "import pytest\nfrom sciwing.datasets.seq_labeling.conll_yago_dataset import ConllYagoDatasetsManager\nfrom sciwing.datasets.seq_labeling.conll_yago_dataset import ConllYagoDataset\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nDATA_DIR = pathlib.Path(DATA_DIR)\n\n\n@pytest.fixture(\n    params=[\"conll_yago_ner.train\", \"conll_yago_ner.dev\", \"conll_yago_ner.test\"],\n    scope=\"session\",\n)\ndef conll_yago_dataset(request):\n    train_filename = DATA_DIR.joinpath(request.param)\n    dataset = ConllYagoDataset(\n        filename=str(train_filename),\n        tokenizers={\"tokens\": WordTokenizer(tokenizer=\"vanilla\")},\n        column_names=[\"NER\"],\n    )\n\n    return dataset\n\n\n@pytest.fixture(scope=\"session\")\ndef conll_yago_dataset_manager():\n    train_filename = DATA_DIR.joinpath(\"conll_yago_ner.train\")\n    dev_filename = DATA_DIR.joinpath(\"conll_yago_ner.dev\")\n    test_filename = DATA_DIR.joinpath(\"conll_yago_ner.test\")\n\n    dataset_manager = ConllYagoDatasetsManager(\n        train_filename=str(train_filename),\n        dev_filename=str(dev_filename),\n        test_filename=str(test_filename),\n    )\n\n    return dataset_manager\n\n\nclass TestConllYagoDataset:\n    def test_get_lines_labels(self, conll_yago_dataset):\n        dataset = conll_yago_dataset\n        try:\n            lines, labels = dataset.get_lines_labels()\n            assert len(lines) > 0\n            assert len(labels) > 0\n        except:\n            pytest.fail(\"Getting Lines and Labels failed\")\n\n    def test_labels_namespace(self, conll_yago_dataset):\n        dataset = conll_yago_dataset\n        lines, labels = dataset.get_lines_labels()\n        for label in labels:\n            namespaces = label.namespace\n            assert len(namespaces) == 1\n            assert \"NER\" in namespaces\n\n    def test_lines_labels_length(self, conll_yago_dataset):\n        dataset = conll_yago_dataset\n        lines, labels = dataset.get_lines_labels()\n        for line, label in zip(lines, labels):\n            line_tokens = line.tokens[\"tokens\"]\n            labels_ner = label.tokens[\"NER\"]\n            assert len(line_tokens) == len(labels_ner)\n\n    def test_conll_yago_dataset_manager(self, conll_yago_dataset_manager):\n        dataset_manager = conll_yago_dataset_manager\n        tokens_vocab = dataset_manager.namespace_to_vocab[\"tokens\"]\n        assert tokens_vocab.get_vocab_len() > 0\n\n    def test_context_tokens_has_no_none(self, conll_yago_dataset):\n        dataset = conll_yago_dataset\n        lines, labels = dataset.get_lines_labels()\n        for line in lines:\n            context_tokens = line.tokens[\"contextual_tokens\"]\n            assert \"None\" not in context_tokens\n"}
{"type": "test_file", "path": "tests/datasets/seq_labeling/test_science_ie_dataset.py", "content": "import pytest\nimport sciwing.constants as constants\nfrom sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nfrom sciwing.utils.class_nursery import ClassNursery\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nDATA_DIR = pathlib.Path(DATA_DIR)\n\n\n@pytest.fixture\ndef setup_science_ie_dataset():\n    train_filename = DATA_DIR.joinpath(\"train_science_ie_conll.txt\")\n    dev_filename = DATA_DIR.joinpath(\"dev_science_ie_conll.txt\")\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=dev_filename,\n        column_names=[\"TASK\", \"PROCESS\", \"MATERIAL\"],\n    )\n    return data_manager\n\n\nclass TestScienceIE:\n    def test_label_namespaces(self, setup_science_ie_dataset):\n        data_manager = setup_science_ie_dataset\n        label_namespaces = data_manager.label_namespaces\n        assert \"TASK\" in label_namespaces\n        assert \"PROCESS\" in label_namespaces\n        assert \"MATERIAL\" in label_namespaces\n\n    def test_num_classes(self, setup_science_ie_dataset):\n        data_manager = setup_science_ie_dataset\n        label_namespaces = data_manager.label_namespaces\n        for namespace in label_namespaces:\n            assert data_manager.num_labels[namespace] == 9\n\n    def test_lines_labels_not_empty(self, setup_science_ie_dataset):\n        data_manager = setup_science_ie_dataset\n        lines, labels = data_manager.train_dataset.get_lines_labels()\n\n        for line, label in zip(lines, labels):\n            line_text = line.text\n            task_label_tokens = label.tokens[\"TASK\"]\n            process_label_tokens = label.tokens[\"PROCESS\"]\n            material_label_tokens = label.tokens[\"MATERIAL\"]\n\n            task_label_tokens = [tok.text for tok in task_label_tokens]\n            process_label_tokens = [tok.text for tok in process_label_tokens]\n            material_label_tokens = [tok.text for tok in material_label_tokens]\n\n            assert bool(line_text.strip())\n            assert all([bool(tok) for tok in task_label_tokens])\n            assert all([bool(tok) for tok in process_label_tokens])\n            assert all([bool(tok) for tok in material_label_tokens])\n\n    def test_lines_labels_are_equal_length(self, setup_science_ie_dataset):\n        data_manager = setup_science_ie_dataset\n        lines, labels = data_manager.train_dataset.get_lines_labels()\n\n        for line, label in zip(lines, labels):\n            line_tokens = line.tokens[\"tokens\"]\n            line_tokens = [tok.text for tok in line_tokens]\n            for namespace in [\"TASK\", \"PROCESS\", \"MATERIAL\"]:\n                label_tokens = label.tokens[namespace]\n                label_tokens = [tok.text for tok in label_tokens]\n                assert len(line_tokens) == len(label_tokens)\n\n    def test_science_ie_in_nursery(self):\n        assert ClassNursery.class_nursery.get(\"CoNLLDatasetManager\") is not None\n"}
{"type": "test_file", "path": "tests/datasets/seq_labeling/test_seq_labelling_dataset.py", "content": "import pytest\nfrom sciwing.datasets.seq_labeling.seq_labelling_dataset import SeqLabellingDataset\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\n\n\n@pytest.fixture(scope=\"session\")\ndef test_file(tmpdir_factory):\n    p = tmpdir_factory.mktemp(\"data\").join(\"test.txt\")\n    p.write(\n        \"word11###label1 word21###label2\\nword12###label1 word22###label2 word32###label3\"\n    )\n    return p\n\n\nclass TestSeqLabellingDataset:\n    def test_get_lines_labels(self, test_file):\n        dataset = SeqLabellingDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        lines, labels = dataset.get_lines_labels()\n        assert len(lines) == 2\n\n    def test_len(self, test_file):\n        dataset = SeqLabellingDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        assert len(dataset) == 2\n\n    def test_get_item(self, test_file):\n        dataset = SeqLabellingDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        num_instances = len(dataset)\n\n        for idx in range(num_instances):\n            line, label = dataset[idx]\n            word_tokens = line.tokens[\"tokens\"]\n            label_tokens = label.tokens[\"seq_label\"]\n            print(f\"label tokens {label.tokens}\")\n            assert len(word_tokens) == len(label_tokens)\n"}
{"type": "test_file", "path": "tests/datasets/summarization/test_abstractive_summarization.py", "content": "import pytest\nfrom sciwing.datasets.summarization.abstractive_text_summarization_dataset import (\n    AbstractiveSummarizationDataset,\n)\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\n\n\n@pytest.fixture(scope=\"session\")\ndef test_file(tmpdir_factory):\n    p = tmpdir_factory.mktemp(\"data\").join(\"test.txt\")\n    p.write(\n        \"word11_train word21_train###word11_label word12_label\\nword12_train word22_train word32_train###word21_label\"\n    )\n    return p\n\n\nclass TestAbstractSummarizationDataset:\n    def test_get_lines_labels(self, test_file):\n        summarization_dataset = AbstractiveSummarizationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        lines = summarization_dataset.lines\n        assert len(lines) == 2\n\n    def test_len_dataset(self, test_file):\n        summarization_dataset = AbstractiveSummarizationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        assert len(summarization_dataset) == 2\n\n    def test_get_item(self, test_file):\n        summarization_dataset = AbstractiveSummarizationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        num_instances = len(summarization_dataset)\n        defined_line_tokens = [\n            \"word11_train\",\n            \"word21_train\",\n            \"word12_train\",\n            \"word22_train\",\n            \"word32_train\",\n        ]\n        defined_label_tokens = [\"word11_label\", \"word12_label\", \"word21_label\"]\n        line_tokens = []\n        label_tokens = []\n        for idx in range(num_instances):\n            line, label = summarization_dataset[idx]\n            line_tokens.extend(line.tokens[\"tokens\"])\n            label_tokens.extend(label.tokens[\"tokens\"])\n\n        line_tokens = list(map(lambda token: token.text, line_tokens))\n        label_tokens = list(map(lambda token: token.text, label_tokens))\n\n        assert set(defined_line_tokens) == set(line_tokens)\n        assert set(defined_label_tokens) == set(label_tokens)\n"}
{"type": "test_file", "path": "tests/datasets/summarization/test_extractive_summarization.py", "content": "import pytest\nfrom sciwing.datasets.summarization.extractive_text_summarization_dataset import (\n    ExtractiveSummarizationDataset,\n    ExtractiveSummarizationDatasetManager,\n)\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\nfrom sciwing.utils.class_nursery import ClassNursery\n\n\n@pytest.fixture(scope=\"session\")\ndef test_file(tmpdir_factory):\n    p = tmpdir_factory.mktemp(\"data\").join(\"test.txt\")\n    p.write(\n        \"word111 word112\\tword121 word 122\\tword 131###label11,label12,label13###refword12 refword22\\n\"\n        \"word211 word212\\tword221###label21,label22###refword21\"\n    )\n    return p\n\n\nclass TestExtractiveSummarizationDataset:\n    def test_get_lines_labels_refs(self, test_file):\n        dataset = ExtractiveSummarizationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        doc, labels, ref = dataset.get_docs_labels_refs()\n        assert len(doc) == 2\n\n    def test_len(self, test_file):\n        dataset = ExtractiveSummarizationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n        assert len(dataset) == 2\n\n    def test_get_item(self, test_file):\n        dataset = ExtractiveSummarizationDataset(\n            filename=str(test_file), tokenizers={\"tokens\": WordTokenizer()}\n        )\n\n        doc0, label0, ref0 = dataset[0]\n        assert len(doc0) == len(label0.tokens[\"seq_label\"])\n\n\n@pytest.fixture(scope=\"session\")\ndef ext_sum_dataset_manager(tmpdir_factory, request):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train_file.txt\")\n    train_file.write(\n        \"trainword111 word112\\tword121 word 122\\tword 131###label11,label12,label13###refword12 refword22\\n\"\n        \"trainword211 word212\\tword221###label21,label22###refword21\"\n    )\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev_file.txt\")\n    dev_file.write(\n        \"devword111 word112\\tword121 word 122\\tword 131###label11,label12,label13###refword12 refword22\\n\"\n        \"devword211 word212\\tword221###label21,label22###refword21\"\n    )\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test_file.txt\")\n    test_file.write(\n        \"testword111 word112\\tword121 word 122\\tword 131###label11,label12,label13###refword12 refword22\\n\"\n        \"testword211 word212\\tword221###label21,label22###refword21\"\n    )\n\n    ext_sum_dataset_manager = ExtractiveSummarizationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    return ext_sum_dataset_manager\n\n\nclass TestDatasetManager:\n    def test_namespaces(self, ext_sum_dataset_manager):\n        namespaces = ext_sum_dataset_manager.namespaces\n        assert set(namespaces) == {\"tokens\", \"char_tokens\", \"label\"}\n\n    def test_namespace_to_vocab(self, ext_sum_dataset_manager):\n        namespace_to_vocab = ext_sum_dataset_manager.namespace_to_vocab\n        assert namespace_to_vocab[\"tokens\"].get_vocab_len() == 2 + 4\n        # there is no special vocab here\n        assert namespace_to_vocab[\"label\"].get_vocab_len() == 2\n\n    def test_namespace_to_numericalizers(self, ext_sum_dataset_manager):\n        namespace_to_numericalizer = ext_sum_dataset_manager.namespace_to_numericalizer\n        assert set(namespace_to_numericalizer.keys()) == {\n            \"tokens\",\n            \"char_tokens\",\n            \"label\",\n        }\n\n    def test_label_namespace(self, ext_sum_dataset_manager):\n        label_namespaces = ext_sum_dataset_manager.label_namespaces\n        assert label_namespaces == [\"label\"]\n\n    def test_num_labels(self, ext_sum_dataset_manager):\n        num_labels = ext_sum_dataset_manager.num_labels[\"label\"]\n        assert num_labels == 2\n\n    def test_print_stats(self, ext_sum_dataset_manager):\n        try:\n            ext_sum_dataset_manager.print_stats()\n        except:\n            pytest.fail(f\"Print Stats fail to work in datasets manager\")\n\n    def test_texclassification_dataset_manager_in_nursery(\n        self, ext_sum_dataset_manager\n    ):\n        assert (\n            ClassNursery.class_nursery[\"TextClassificationDatasetManager\"] is not None\n        )\n"}
{"type": "test_file", "path": "tests/engine/test_engine.py", "content": "from sciwing.engine.engine import Engine\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.data.line import Line\nfrom sciwing.data.label import Label\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport torch\nimport os\nfrom sciwing.utils.class_nursery import ClassNursery\n\nimport pytest\nimport sciwing.constants as constants\n\nFILES = constants.FILES\nSECT_LABEL_FILE = FILES[\"SECT_LABEL_FILE\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef clf_datasets_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train_file.txt\")\n    train_file.write(\"train_line1###label1\\ntrain_line2###label2\")\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev_file.txt\")\n    dev_file.write(\"dev_line1###label1\\ndev_line2###label2\")\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test_file.txt\")\n    test_file.write(\"test_line1###label1\\ntest_line2###label2\")\n\n    clf_dataset_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n        batch_size=1,\n    )\n\n    return clf_dataset_manager\n\n\n@pytest.fixture(scope=\"session\", params=[\"loss\", \"micro_fscore\", \"macro_fscore\"])\ndef setup_engine_test_with_simple_classifier(\n    request, clf_datasets_manager, tmpdir_factory\n):\n    track_for_best = request.param\n    sample_proportion = 0.5\n    datasets_manager = clf_datasets_manager\n    word_embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n    bow_encoder = BOW_Encoder(embedder=word_embedder)\n    classifier = SimpleClassifier(\n        encoder=bow_encoder,\n        encoding_dim=word_embedder.get_embedding_dimension(),\n        num_classes=2,\n        classification_layer_bias=True,\n        datasets_manager=datasets_manager,\n    )\n    train_metric = PrecisionRecallFMeasure(datasets_manager=datasets_manager)\n    validation_metric = PrecisionRecallFMeasure(datasets_manager=datasets_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=datasets_manager)\n\n    optimizer = torch.optim.Adam(params=classifier.parameters())\n    batch_size = 1\n    save_dir = tmpdir_factory.mktemp(\"experiment_1\")\n    num_epochs = 1\n    save_every = 1\n    log_train_metrics_every = 10\n\n    engine = Engine(\n        model=classifier,\n        datasets_manager=datasets_manager,\n        optimizer=optimizer,\n        batch_size=batch_size,\n        save_dir=save_dir,\n        num_epochs=num_epochs,\n        save_every=save_every,\n        log_train_metrics_every=log_train_metrics_every,\n        train_metric=train_metric,\n        validation_metric=validation_metric,\n        test_metric=test_metric,\n        track_for_best=track_for_best,\n        sample_proportion=sample_proportion,\n    )\n\n    return engine\n\n\nclass TestEngine:\n    def test_train_loader(self, setup_engine_test_with_simple_classifier):\n        engine = setup_engine_test_with_simple_classifier\n        train_dataset = engine.get_train_dataset()\n        train_loader = engine.get_loader(train_dataset)\n\n        for lines_labels in train_loader:\n            for line, label in lines_labels:\n                assert isinstance(line, Line)\n                assert isinstance(label, Label)\n\n    def test_one_train_epoch(self, setup_engine_test_with_simple_classifier):\n        # check whether you can run train_epoch without throwing an error\n        engine = setup_engine_test_with_simple_classifier\n        engine.train_epoch(0)\n\n    def test_save_model(self, setup_engine_test_with_simple_classifier):\n        engine = setup_engine_test_with_simple_classifier\n        engine.train_epoch_end(0)\n\n        # test for the file model_epoch_1.pt\n        assert os.path.isdir(engine.save_dir)\n        assert os.path.isfile(os.path.join(engine.save_dir, \"model_epoch_1.pt\"))\n\n    def test_runs(self, setup_engine_test_with_simple_classifier):\n        \"\"\"\n        Just tests runs without any errors\n        \"\"\"\n        engine = setup_engine_test_with_simple_classifier\n        try:\n            engine.run()\n        except:\n            pytest.fail(\"Engine failed to run\")\n\n    def test_load_model(self, setup_engine_test_with_simple_classifier):\n        \"\"\"\n        Test whether engine loads the model without any error.\n        \"\"\"\n        engine = setup_engine_test_with_simple_classifier\n        try:\n            engine.train_epoch_end(0)\n            engine.load_model_from_file(\n                os.path.join(engine.save_dir, \"model_epoch_{0}.pt\".format(1))\n            )\n        except:\n            pytest.fail(\"Engine train epoch end failed\")\n\n    def test_engine_in_class_nursery(self):\n        assert ClassNursery.class_nursery[\"Engine\"] is not None\n"}
{"type": "test_file", "path": "tests/infer/classification/test_classification_inference.py", "content": "import pytest\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.engine.engine import Engine\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport torch\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\n\nFILES = constants.FILES\nSECT_LABEL_FILE = FILES[\"SECT_LABEL_FILE\"]\nPATHS = constants.PATHS\n\nOUTPUT_DIR = PATHS[\"OUTPUT_DIR\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef clf_datasets_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train_file.txt\")\n    train_file.write(\"train_line1###label1\\ntrain_line2###label2\")\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev_file.txt\")\n    dev_file.write(\"dev_line1###label1\\ndev_line2###label2\")\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test_file.txt\")\n    test_file.write(\"test_line1###label1\\ntest_line2###label2\")\n\n    clf_dataset_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n        batch_size=1,\n    )\n\n    return clf_dataset_manager\n\n\n@pytest.fixture(scope=\"session\", params=[\"loss\", \"micro_fscore\", \"macro_fscore\"])\ndef setup_sectlabel_bow_glove_infer(request, clf_datasets_manager, tmpdir_factory):\n    track_for_best = request.param\n    sample_proportion = 0.5\n    datasets_manager = clf_datasets_manager\n    word_embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n    bow_encoder = BOW_Encoder(embedder=word_embedder)\n    classifier = SimpleClassifier(\n        encoder=bow_encoder,\n        encoding_dim=word_embedder.get_embedding_dimension(),\n        num_classes=2,\n        classification_layer_bias=True,\n        datasets_manager=datasets_manager,\n    )\n    train_metric = PrecisionRecallFMeasure(datasets_manager=datasets_manager)\n    validation_metric = PrecisionRecallFMeasure(datasets_manager=datasets_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=datasets_manager)\n\n    optimizer = torch.optim.Adam(params=classifier.parameters())\n    batch_size = 1\n    save_dir = tmpdir_factory.mktemp(\"experiment_1\")\n    num_epochs = 1\n    save_every = 1\n    log_train_metrics_every = 10\n\n    engine = Engine(\n        model=classifier,\n        datasets_manager=datasets_manager,\n        optimizer=optimizer,\n        batch_size=batch_size,\n        save_dir=save_dir,\n        num_epochs=num_epochs,\n        save_every=save_every,\n        log_train_metrics_every=log_train_metrics_every,\n        train_metric=train_metric,\n        validation_metric=validation_metric,\n        test_metric=test_metric,\n        track_for_best=track_for_best,\n        sample_proportion=sample_proportion,\n    )\n\n    engine.run()\n    model_filepath = pathlib.Path(save_dir).joinpath(\"best_model.pt\")\n    infer = ClassificationInference(\n        model=classifier,\n        model_filepath=str(model_filepath),\n        datasets_manager=datasets_manager,\n    )\n    return infer\n\n\nclass TestClassificationInference:\n    def test_run_inference_works(self, setup_sectlabel_bow_glove_infer):\n        inference_client = setup_sectlabel_bow_glove_infer\n        try:\n            inference_client.run_inference()\n        except:\n            pytest.fail(\"Run inference for classification dataset fails\")\n\n    def test_run_test_works(self, setup_sectlabel_bow_glove_infer):\n        inference_client = setup_sectlabel_bow_glove_infer\n        try:\n            inference_client.run_test()\n        except:\n            pytest.fail(\"Run test doest not work\")\n\n    def test_on_user_input_works(self, setup_sectlabel_bow_glove_infer):\n        inference_client = setup_sectlabel_bow_glove_infer\n        try:\n            inference_client.on_user_input(line=\"test input\")\n        except:\n            pytest.fail(\"On user input fails\")\n\n    def test_print_metrics_works(self, setup_sectlabel_bow_glove_infer):\n        inference_client = setup_sectlabel_bow_glove_infer\n        inference_client.run_test()\n        try:\n            inference_client.report_metrics()\n        except:\n            pytest.fail(\"Print metrics failed\")\n\n    def test_print_confusion_metrics_works(self, setup_sectlabel_bow_glove_infer):\n        inference_client = setup_sectlabel_bow_glove_infer\n        inference_client.run_test()\n        try:\n            inference_client.print_confusion_matrix()\n        except:\n            pytest.fail(\"Print confusion matrix fails\")\n\n    def test_get_misclassified_sentences(self, setup_sectlabel_bow_glove_infer):\n        inference_client = setup_sectlabel_bow_glove_infer\n        inference_client.run_test()\n        try:\n            inference_client.get_misclassified_sentences(\n                true_label_idx=0, pred_label_idx=1\n            )\n        except:\n            pytest.fail(\"Getting misclassified sentence fail\")\n"}
{"type": "test_file", "path": "tests/infer/seq_labeling/test_seq_label_inference.py", "content": "import pytest\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.datasets.seq_labeling.seq_labelling_dataset import (\n    SeqLabellingDatasetManager,\n)\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nfrom sciwing.metrics.token_cls_accuracy import TokenClassificationAccuracy\nfrom sciwing.engine.engine import Engine\nfrom sciwing.infer.seq_label_inference.seq_label_inference import (\n    SequenceLabellingInference,\n)\nimport torch\n\nPATHS = constants.PATHS\nOUTPUT_DIR = PATHS[\"OUTPUT_DIR\"]\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef seq_dataset_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train.txt\")\n    train_file.write(\n        \"word11_train###label1 word21_train###label2\\nword12_train###label1 word22_train###label2 word32_train###label3\"\n    )\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev.txt\")\n    dev_file.write(\n        \"word11_dev###label1 word21_dev###label2\\nword12_dev###label1 word22_dev###label2 word32_dev###label3\"\n    )\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test.txt\")\n    test_file.write(\n        \"word11_test###label1 word21_test###label2\\nword12_test###label1 word22_test###label2 word32_test###label3\"\n    )\n\n    data_manager = SeqLabellingDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    return data_manager\n\n\n@pytest.fixture(scope=\"session\")\ndef setup_parscit_inference(seq_dataset_manager, tmpdir_factory):\n    HIDDEN_DIM = 100\n    BIDIRECTIONAL = True\n    COMBINE_STRATEGY = \"concat\"\n    dataset_manager = seq_dataset_manager\n\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n\n    char_embedder = CharEmbedder(\n        char_embedding_dimension=10,\n        hidden_dimension=20,\n        datasets_manager=dataset_manager,\n    )\n    embedder = ConcatEmbedders([embedder, char_embedder])\n\n    encoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=0.0,\n        hidden_dim=HIDDEN_DIM,\n        bidirectional=BIDIRECTIONAL,\n        combine_strategy=COMBINE_STRATEGY,\n        rnn_bias=False,\n        add_projection_layer=False,\n    )\n\n    tagger = RnnSeqCrfTagger(\n        rnn2seqencoder=encoder,\n        encoding_dim=2 * HIDDEN_DIM\n        if BIDIRECTIONAL and COMBINE_STRATEGY == \"concat\"\n        else HIDDEN_DIM,\n        datasets_manager=dataset_manager,\n    )\n\n    train_metric = TokenClassificationAccuracy(datasets_manager=dataset_manager)\n    dev_metric = TokenClassificationAccuracy(datasets_manager=dataset_manager)\n    test_metric = TokenClassificationAccuracy(datasets_manager=dataset_manager)\n\n    optimizer = torch.optim.Adam(params=tagger.parameters())\n    batch_size = 1\n    save_dir = tmpdir_factory.mktemp(\"experiment_1\")\n    num_epochs = 1\n    save_every = 1\n    log_train_metrics_every = 10\n\n    engine = Engine(\n        model=tagger,\n        datasets_manager=dataset_manager,\n        optimizer=optimizer,\n        batch_size=batch_size,\n        save_dir=save_dir,\n        num_epochs=num_epochs,\n        save_every=save_every,\n        log_train_metrics_every=log_train_metrics_every,\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        track_for_best=\"macro_fscore\",\n    )\n\n    engine.run()\n    model_filepath = pathlib.Path(save_dir).joinpath(\"best_model.pt\")\n\n    inference_client = SequenceLabellingInference(\n        model=tagger, model_filepath=model_filepath, datasets_manager=dataset_manager\n    )\n\n    return inference_client\n\n\nclass TestParscitInference:\n    def test_run_inference_works(self, setup_parscit_inference):\n        inference_client = setup_parscit_inference\n        inference_client.run_test()\n        assert isinstance(inference_client.output_analytics, dict)\n\n    def test_print_prf_table_works(self, setup_parscit_inference):\n        inference = setup_parscit_inference\n        inference.run_test()\n        try:\n            inference.report_metrics()\n        except:\n            pytest.fail(\"Parscit print prf table does not work\")\n\n    def test_print_confusion_metrics_works(self, setup_parscit_inference):\n        inference = setup_parscit_inference\n        inference.run_test()\n        try:\n            inference.print_confusion_matrix()\n        except:\n            pytest.fail(\"Parscit print confusion metrics fails\")\n\n    def test_on_user_input(self, setup_parscit_inference):\n        inference = setup_parscit_inference\n        try:\n            inference.on_user_input(\"A.B. Abalone, Future Paper\")\n        except:\n            pytest.fail(\"Infer on single sentence does not work\")\n\n    def test_get_miscalssified_sentences(self, setup_parscit_inference):\n        inference = setup_parscit_inference\n        inference.run_test()\n        try:\n            inference.get_misclassified_sentences(true_label_idx=0, pred_label_idx=1)\n        except:\n            pytest.fail(\"Get misclassified sentences fails\")\n"}
{"type": "test_file", "path": "tests/integration/test_pipeline_till_numericalization.py", "content": "\"\"\"\nThis tests the pipeline till numericalizatio\n\"\"\"\nimport pytest\n\nimport sciwing.constants as constants\nfrom sciwing.utils.common import convert_sectlabel_to_json\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\nfrom sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\nfrom sciwing.vocab.vocab import Vocab\nfrom sciwing.numericalizers.numericalizer import Numericalizer\n\nFILES = constants.FILES\nSECT_LABEL_FILE = FILES[\"SECT_LABEL_FILE\"]\n\n\n# 1. Convert sciwing data to json\n@pytest.fixture()\ndef get_parsect_data():\n    parsect_json = convert_sectlabel_to_json(SECT_LABEL_FILE)\n    return parsect_json\n\n\n# 2. Convert the json to instances\n@pytest.fixture()\ndef get_tokenized_data(get_parsect_data):\n    parsect_json = get_parsect_data\n    parsect_lines = parsect_json[\"parse_sect\"]\n    parsect_lines = parsect_lines[:100]\n    tokenizer = WordTokenizer()\n\n    lines = []\n    labels = []\n\n    for line_json in parsect_lines:\n        text = line_json[\"text\"]\n        label = line_json[\"label\"]\n        lines.append(text)\n        labels.append(label)\n\n    instances = tokenizer.tokenize_batch(lines)\n\n    return instances, labels\n\n\n# 3. Perform pre-processing on instances\n@pytest.fixture()\ndef get_preprocessed_instances(get_tokenized_data):\n    instances, labels = get_tokenized_data\n    instance_preprocessing = InstancePreprocessing()\n    instances = list(map(instance_preprocessing.lowercase, instances))\n    return instances, labels\n\n\n# 4. Numericalization of tokens\n@pytest.fixture()\ndef get_numericalized_instances(get_preprocessed_instances):\n    instances, labels = get_preprocessed_instances\n    MAX_NUM_WORDS = 3000\n    MAX_LENGTH = 15\n    vocab = Vocab(instances=instances, max_num_tokens=MAX_NUM_WORDS)\n    vocab.build_vocab()\n    numericalizer = Numericalizer(vocabulary=vocab)\n    numericalized_instances = numericalizer.numericalize_batch_instances(instances[:32])\n    return {\n        \"numericalized_instances\": numericalized_instances,\n        \"labels\": labels,\n        \"max_length\": MAX_LENGTH,\n        \"max_num_words\": MAX_NUM_WORDS,\n        \"vocab\": vocab,\n    }\n\n\nclass TestPipeline:\n    def test_integers(self, get_numericalized_instances):\n        numericalized_instances = get_numericalized_instances[\"numericalized_instances\"]\n        for instance in numericalized_instances:\n            assert all([type(token) == int for token in instance])\n\n    def test_max_vocab(self, get_numericalized_instances):\n        vocab = get_numericalized_instances[\"vocab\"]\n        MAX_NUM_WORDS = get_numericalized_instances[\"max_num_words\"]\n        vocab_len = vocab.get_vocab_len()\n        assert vocab_len <= MAX_NUM_WORDS + len(vocab.special_vocab)\n"}
{"type": "test_file", "path": "tests/meters/test_loss_meter.py", "content": "import pytest\nfrom sciwing.meters.loss_meter import LossMeter\n\n\nclass TestLossMeter:\n    def test_loss_basic(self):\n        loss = 1\n        num_instances = 5\n        loss_meter = LossMeter()\n        loss_meter.add_loss(avg_batch_loss=loss, num_instances=num_instances)\n        assert loss_meter.get_average() == 1\n\n    def test_loss_two_batches(self):\n        loss_1 = 1.2\n        num_instances_1 = 5\n        loss_meter = LossMeter()\n        loss_2 = 1.4\n        num_instances_2 = 5\n        loss_meter.add_loss(avg_batch_loss=loss_1, num_instances=num_instances_1)\n        loss_meter.add_loss(avg_batch_loss=loss_2, num_instances=num_instances_2)\n        average_loss = loss_meter.get_average()\n        assert average_loss == 1.3\n\n    def test_average_with_empty_losses(self):\n        loss_meter = LossMeter()\n        assert loss_meter.get_average() is None\n"}
{"type": "test_file", "path": "tests/metrics/test_conll_2003_metric.py", "content": "import pytest\nfrom sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nimport sciwing.constants as constants\nfrom sciwing.metrics.conll_2003_metrics import ConLL2003Metrics\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef conll_dataset_manager():\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"eng.train\")\n    dev_filename = data_dir.joinpath(\"eng.testa\")\n    test_filename = data_dir.joinpath(\"eng.testb\")\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        train_only=\"ner\",\n        column_names=[\"POS\", \"DEP\", \"NER\"],\n    )\n    return data_manager\n\n\n@pytest.fixture(scope=\"session\")\ndef setup_metric(conll_dataset_manager):\n    data_manager = conll_dataset_manager\n    metric = ConLL2003Metrics(datasets_manager=data_manager)\n    lines, labels = data_manager.train_dataset.get_lines_labels()\n    lines = lines[:2]\n    labels = labels[:2]\n\n    # max_label_length\n    len_labels = [len(label.tokens[\"NER\"]) for label in labels]\n    max_label_len = max(len_labels)\n    i_per_label = data_manager.namespace_to_vocab[\"NER\"].get_idx_from_token(\"I-PER\")\n\n    # create dummy predictions\n    predictions = []\n    for i in range(len(lines)):\n        predictions.append([i_per_label] * max_label_len)\n\n    model_forward_dict = {\"predicted_tags_NER\": predictions}\n\n    return metric, lines, labels, model_forward_dict\n\n\nclass TestConll2003Metric:\n    def test_calc_metric(self, setup_metric):\n        metric, lines, labels, model_forward_dict = setup_metric\n        try:\n            metric.calc_metric(\n                lines=lines, labels=labels, model_forward_dict=model_forward_dict\n            )\n        except:\n            pytest.fail(\"Calc metric for conll2003 failed\")\n\n    def test_get_metric(self, setup_metric):\n        metric, lines, labels, model_forward_dict = setup_metric\n        try:\n            metric.calc_metric(\n                lines=lines, labels=labels, model_forward_dict=model_forward_dict\n            )\n            metrics = metric.get_metric()\n            assert \"NER\" in metrics.keys()\n        except:\n            pytest.fail(\"Get metric for conll2003 failed\")\n\n    def test_report_metric(self, setup_metric):\n        metric, lines, labels, model_forward_dict = setup_metric\n        try:\n            metric.calc_metric(\n                lines=lines, labels=labels, model_forward_dict=model_forward_dict\n            )\n            tables = metric.report_metrics()\n            for namespace, table in tables.items():\n                print(table)\n        except:\n            pytest.fail(\"Get metric for conll2003 failed\")\n"}
{"type": "test_file", "path": "tests/metrics/test_precision_recall_fmeasure.py", "content": "import pytest\nimport torch\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nfrom sciwing.utils.class_nursery import ClassNursery\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\n\n\n@pytest.fixture(scope=\"session\")\ndef clf_dataset_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train_file.txt\")\n    train_file.write(\"train_line1###label1\\ntrain_line2###label2\")\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev_file.txt\")\n    dev_file.write(\"dev_line1###label1\\ndev_line2###label2\")\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test_file.txt\")\n    test_file.write(\"test_line1###label1\\ntest_line2###label2\")\n\n    clf_dataset_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n        batch_size=1,\n    )\n\n    return clf_dataset_manager\n\n\n@pytest.fixture\ndef setup_data_basecase(clf_dataset_manager):\n    dataset_manager = clf_dataset_manager\n    prf_metric = PrecisionRecallFMeasure(dataset_manager)\n    predicted_probs = torch.FloatTensor([[0.1, 0.9], [0.7, 0.3]])\n    labels = torch.LongTensor([1, 0]).view(-1, 1)\n\n    expected_precision = {0: 1.0, 1: 1.0}\n    expected_recall = {0: 1.0, 1: 1.0}\n    expected_fmeasure = {0: 1.0, 1: 1.0}\n    expected_macro_precision = 1.0\n    expected_macro_recall = 1.0\n    expected_macro_fscore = 1.0\n    expected_num_tps = {0: 1.0, 1: 1.0}\n    expected_num_fps = {0: 0.0, 1: 0.0}\n    expected_num_fns = {0: 0.0, 1: 0.0}\n    expected_micro_precision = 1.0\n    expected_micro_recall = 1.0\n    expected_micro_fscore = 1.0\n\n    return (\n        predicted_probs,\n        labels,\n        prf_metric,\n        dataset_manager,\n        {\n            \"expected_precision\": expected_precision,\n            \"expected_recall\": expected_recall,\n            \"expected_fscore\": expected_fmeasure,\n            \"expected_macro_precision\": expected_macro_precision,\n            \"expected_macro_recall\": expected_macro_recall,\n            \"expected_macro_fscore\": expected_macro_fscore,\n            \"expected_num_tps\": expected_num_tps,\n            \"expected_num_fps\": expected_num_fps,\n            \"expected_num_fns\": expected_num_fns,\n            \"expected_micro_precision\": expected_micro_precision,\n            \"expected_micro_recall\": expected_micro_recall,\n            \"expected_micro_fscore\": expected_micro_fscore,\n        },\n    )\n\n\n@pytest.fixture\ndef setup_data_for_all_zeros(clf_dataset_manager):\n    predicted_probs = torch.FloatTensor([[0.9, 0.1], [0.3, 0.7]])\n    datasets_manager = clf_dataset_manager\n    labels = torch.LongTensor([1, 0]).view(-1, 1)\n\n    expected_precision = {0: 0.0, 1: 0.0}\n    expected_recall = {0: 0.0, 1: 0.0}\n    expected_fmeasure = {0: 0.0, 1: 0.0}\n    expected_macro_precision = 0.0\n    expected_macro_recall = 0.0\n    expected_macro_fscore = 0.0\n    expected_num_tps = {0: 0.0, 1: 0.0}\n    expected_num_fps = {0: 1.0, 1: 1.0}\n    expected_num_fns = {0: 1.0, 1: 1.0}\n    expected_micro_precision = 0.0\n    expected_micro_recall = 0.0\n    expected_micro_fscore = 0.0\n\n    prf_metric = PrecisionRecallFMeasure(datasets_manager=datasets_manager)\n    return (\n        predicted_probs,\n        labels,\n        prf_metric,\n        datasets_manager,\n        {\n            \"expected_precision\": expected_precision,\n            \"expected_recall\": expected_recall,\n            \"expected_fscore\": expected_fmeasure,\n            \"expected_macro_precision\": expected_macro_precision,\n            \"expected_macro_recall\": expected_macro_recall,\n            \"expected_macro_fscore\": expected_macro_fscore,\n            \"expected_num_tps\": expected_num_tps,\n            \"expected_num_fps\": expected_num_fps,\n            \"expected_num_fns\": expected_num_fns,\n            \"expected_micro_precision\": expected_micro_precision,\n            \"expected_micro_recall\": expected_micro_recall,\n            \"expected_micro_fscore\": expected_micro_fscore,\n        },\n    )\n\n\nclass TestAccuracy:\n    def test_print_confusion_matrix_works(self, setup_data_basecase):\n        predicted_probs, labels, metric, dataset_manager, expected = setup_data_basecase\n        labels_mask = torch.zeros_like(predicted_probs).type(torch.BoolTensor)\n        try:\n            metric.print_confusion_metrics(\n                predicted_probs=predicted_probs, labels=labels, labels_mask=labels_mask\n            )\n        except:\n            pytest.fail(\"Precision Recall and FMeasure print_confusion_metrics fails\")\n\n    def test_accuracy_basecase(self, setup_data_basecase):\n        predicted_probs, _, metric, dataset_manager, expected = setup_data_basecase\n        expected_precision = expected[\"expected_precision\"]\n        expected_recall = expected[\"expected_recall\"]\n        expected_fmeasure = expected[\"expected_fscore\"]\n\n        lines, labels = dataset_manager.train_dataset.get_lines_labels()\n        forward_dict = {\"normalized_probs\": predicted_probs}\n        metric.calc_metric(lines=lines, labels=labels, model_forward_dict=forward_dict)\n        accuracy_metrics = metric.get_metric()[\"label\"]\n\n        precision = accuracy_metrics[\"precision\"]\n        recall = accuracy_metrics[\"recall\"]\n        fscore = accuracy_metrics[\"fscore\"]\n\n        for class_label, precision_value in precision.items():\n            assert precision_value == expected_precision[class_label]\n\n        for class_label, recall_value in recall.items():\n            assert recall_value == expected_recall[class_label]\n\n        for class_label, fscore_value in fscore.items():\n            assert fscore_value == expected_fmeasure[class_label]\n\n    def test_macro_scores_basecase(self, setup_data_basecase):\n        predicted_probs, _, metric, dataset_manager, expected = setup_data_basecase\n        expected_macro_precision = expected[\"expected_macro_precision\"]\n        expected_macro_recall = expected[\"expected_macro_recall\"]\n        expected_macro_fscore = expected[\"expected_macro_fscore\"]\n        expected_num_tps = expected[\"expected_num_tps\"]\n        expected_num_fps = expected[\"expected_num_fps\"]\n        expected_num_fns = expected[\"expected_num_fns\"]\n        expected_micro_precision = expected[\"expected_micro_precision\"]\n        expected_micro_recall = expected[\"expected_micro_recall\"]\n        expected_micro_fscore = expected[\"expected_micro_fscore\"]\n\n        lines, labels = dataset_manager.train_dataset.get_lines_labels()\n        forward_dict = {\"normalized_probs\": predicted_probs}\n        metric.calc_metric(lines=lines, labels=labels, model_forward_dict=forward_dict)\n        metrics = metric.get_metric()[\"label\"]\n\n        macro_precision = metrics[\"macro_precision\"]\n        macro_recall = metrics[\"macro_recall\"]\n        macro_fscore = metrics[\"macro_fscore\"]\n        num_tps = metrics[\"num_tp\"]\n        num_fps = metrics[\"num_fp\"]\n        num_fn = metrics[\"num_fn\"]\n        micro_precision = metrics[\"micro_precision\"]\n        micro_recall = metrics[\"micro_recall\"]\n        micro_fscore = metrics[\"micro_fscore\"]\n\n        assert macro_precision == expected_macro_precision\n        assert macro_recall == expected_macro_recall\n        assert macro_fscore == expected_macro_fscore\n        assert num_tps == expected_num_tps\n        assert num_fps == expected_num_fps\n        assert num_fn == expected_num_fns\n        assert micro_precision == expected_micro_precision\n        assert micro_recall == expected_micro_recall\n        assert micro_fscore == expected_micro_fscore\n\n    def test_accuracy_all_zeros(self, setup_data_for_all_zeros):\n        (\n            predicted_probs,\n            labels,\n            metric,\n            dataset_manager,\n            expected,\n        ) = setup_data_for_all_zeros\n        expected_precision = expected[\"expected_precision\"]\n        expected_recall = expected[\"expected_recall\"]\n        expected_fmeasure = expected[\"expected_fscore\"]\n\n        lines, labels = dataset_manager.train_dataset.get_lines_labels()\n        forward_dict = {\"normalized_probs\": predicted_probs}\n        metric.calc_metric(lines=lines, labels=labels, model_forward_dict=forward_dict)\n        accuracy_metrics = metric.get_metric()[\"label\"]\n\n        precision = accuracy_metrics[\"precision\"]\n        recall = accuracy_metrics[\"recall\"]\n        fscore = accuracy_metrics[\"fscore\"]\n\n        for class_, precision_value in precision.items():\n            assert precision_value == expected_precision[class_]\n\n        for class_, recall_value in recall.items():\n            assert recall_value == expected_recall[class_]\n\n        for class_, fscore_value in fscore.items():\n            assert fscore_value == expected_fmeasure[class_]\n\n    def test_macro_scores_all_zeros(self, setup_data_for_all_zeros):\n        (\n            predicted_probs,\n            labels,\n            metric,\n            datasets_manager,\n            expected,\n        ) = setup_data_for_all_zeros\n        expected_macro_precision = expected[\"expected_macro_precision\"]\n        expected_macro_recall = expected[\"expected_macro_recall\"]\n        expected_macro_fscore = expected[\"expected_macro_fscore\"]\n        expected_micro_precision = expected[\"expected_micro_precision\"]\n        expected_micro_recall = expected[\"expected_micro_recall\"]\n        expected_micro_fscore = expected[\"expected_micro_fscore\"]\n        expected_num_tps = expected[\"expected_num_tps\"]\n        expected_num_fps = expected[\"expected_num_fps\"]\n        expected_num_fns = expected[\"expected_num_fns\"]\n\n        lines, labels = datasets_manager.train_dataset.get_lines_labels()\n        forward_dict = {\"normalized_probs\": predicted_probs}\n        metric.calc_metric(lines=lines, labels=labels, model_forward_dict=forward_dict)\n        accuracy_metrics = metric.get_metric()[\"label\"]\n\n        macro_precision = accuracy_metrics[\"macro_precision\"]\n        macro_recall = accuracy_metrics[\"macro_recall\"]\n        macro_fscore = accuracy_metrics[\"macro_fscore\"]\n        micro_precision = accuracy_metrics[\"micro_precision\"]\n        micro_recall = accuracy_metrics[\"micro_recall\"]\n        micro_fscore = accuracy_metrics[\"micro_fscore\"]\n        num_tps = accuracy_metrics[\"num_tp\"]\n        num_fp = accuracy_metrics[\"num_fp\"]\n        num_fn = accuracy_metrics[\"num_fn\"]\n\n        assert macro_precision == expected_macro_precision\n        assert macro_recall == expected_macro_recall\n        assert macro_fscore == expected_macro_fscore\n        assert micro_precision == expected_micro_precision\n        assert micro_recall == expected_micro_recall\n        assert micro_fscore == expected_micro_fscore\n        assert num_tps == expected_num_tps\n        assert num_fp == expected_num_fps\n        assert num_fn == expected_num_fns\n\n    def test_precision_recall_fmeasure_in_class_nursery(self):\n        assert ClassNursery.class_nursery.get(\"PrecisionRecallFMeasure\") is not None\n"}
{"type": "test_file", "path": "tests/metrics/test_summarization_metrics.py", "content": "import pytest\nfrom sciwing.metrics.summarization_metrics import SummarizationMetrics\nfrom sciwing.datasets.summarization.abstractive_text_summarization_dataset import (\n    AbstractiveSummarizationDatasetManager,\n)\nfrom sciwing.data.line import Line\n\n\n@pytest.fixture(scope=\"session\")\ndef abs_sum_dataset_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train.txt\")\n    train_file.write(\n        \"word11_train word21_train###word11_label word21_label\\nword12_train word22_train word32_train###word11_label word22_label\"\n    )\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev.txt\")\n    dev_file.write(\n        \"word11_dev word21_dev###word11_label word21_label\\nword12_dev word22_dev word32_dev###word11_label word22_label\"\n    )\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test.txt\")\n    test_file.write(\n        \"word11_test word21_test###word11_label word21_label\\nword12_test word22_test word32_test###word11_label word22_label\"\n    )\n\n    data_manager = AbstractiveSummarizationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    return data_manager\n\n\n@pytest.fixture\ndef setup_scorer(abs_sum_dataset_manager):\n    dataset_manager = abs_sum_dataset_manager\n    scorer = SummarizationMetrics(dataset_manager)\n\n    lines = [\n        Line(\"word11_train word21_train\"),\n        Line(\"word12_train word22_train word32_train\"),\n    ]\n    true_summary = [\n        Line(\"word11_label word21_label\"),\n        Line(\"word11_label word22_label\"),\n    ]\n    true_summary_tokens = [\"word11_label\", \"word22_label\", \"word33_label\"]\n    pred_summary_tokens = [\n        \"word11_label\",\n        \"word22_label\",\n        \"word23_label\",\n        \"word33_label\",\n    ]\n    predicted_tags = {\"predicted_tags_tokens\": [[0, 2], [1, 4, 5]]}\n    return (\n        scorer,\n        (lines, true_summary, predicted_tags),\n        (true_summary_tokens, pred_summary_tokens),\n    )\n\n\nclass TestSummarizationMetrics:\n    def test_rouge_n(self, setup_scorer):\n        scorer, _, (true_summary_tokens, pred_summary_tokens) = setup_scorer\n        rouge_1 = scorer._rouge_n(true_summary_tokens, pred_summary_tokens, 1)\n        rouge_2 = scorer._rouge_n(true_summary_tokens, pred_summary_tokens, 2)\n        rouge_l = scorer._rouge_l(true_summary_tokens, pred_summary_tokens)\n        print(rouge_l)\n        assert rouge_2 == 0.4\n        assert rouge_1 > 0.8\n        assert rouge_l > 0.8\n\n    def test_scorer(self, setup_scorer):\n        scorer, (lines, true_summary, predicted_tags), _ = setup_scorer\n        scorer.calc_metric(lines, true_summary, predicted_tags)\n        metrics = scorer.get_metric()\n        print(metrics)\n        assert False\n"}
{"type": "test_file", "path": "tests/metrics/test_token_cls_accuracy.py", "content": "import pytest\nfrom sciwing.metrics.token_cls_accuracy import TokenClassificationAccuracy\nfrom sciwing.datasets.seq_labeling.seq_labelling_dataset import (\n    SeqLabellingDatasetManager,\n)\nfrom sciwing.utils.class_nursery import ClassNursery\nimport sciwing.constants as constants\nimport pathlib\nimport numpy as np\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef seq_dataset_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train.txt\")\n    train_file.write(\"word11_train###label1 word21_train###label2\")\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev.txt\")\n    dev_file.write(\n        \"word11_dev###label1 word21_dev###label2\\nword12_dev###label1 word22_dev###label2 word32_dev###label3\"\n    )\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test.txt\")\n    test_file.write(\n        \"word11_test###label1 word21_test###label2\\nword12_test###label1 word22_test###label2 word32_test###label3\"\n    )\n\n    data_manager = SeqLabellingDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    return data_manager\n\n\n@pytest.fixture\ndef parscit_dataset_manager():\n    data_dir = pathlib.Path(DATA_DIR)\n    parscit_train_file = data_dir.joinpath(\"parscit.train\")\n    parscit_dev_file = data_dir.joinpath(\"parscit.dev\")\n    parscit_test_file = data_dir.joinpath(\"parscit.test\")\n\n    dataset_manager = SeqLabellingDatasetManager(\n        train_filename=str(parscit_train_file),\n        dev_filename=str(parscit_dev_file),\n        test_filename=str(parscit_test_file),\n    )\n    return dataset_manager\n\n\n@pytest.fixture\ndef setup_basecase(seq_dataset_manager):\n    predicted_tags = [[5, 4]]\n    data_manager = seq_dataset_manager\n    lines, labels = data_manager.train_dataset.get_lines_labels()\n\n    expected_precision = {5: 1.0, 4: 1.0}\n    expected_recall = {5: 1.0, 4: 1.0}\n    expected_fmeasure = {5: 1.0, 4: 1.0}\n    expected_macro_precision = 1.0\n    expected_macro_recall = 1.0\n    expected_macro_fscore = 1.0\n    expected_num_tps = {5: 1.0, 4: 1.0}\n    expected_num_fps = {5: 0.0, 4: 0.0}\n    expected_num_fns = {5: 0.0, 4: 0.0}\n    expected_micro_precision = 1.0\n    expected_micro_recall = 1.0\n    expected_micro_fscore = 1.0\n\n    token_cls_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n\n    model_forward_dict = {\"predicted_tags_seq_label\": predicted_tags}\n\n    return (\n        token_cls_metric,\n        lines,\n        labels,\n        model_forward_dict,\n        {\n            \"expected_precision\": expected_precision,\n            \"expected_recall\": expected_recall,\n            \"expected_fscore\": expected_fmeasure,\n            \"expected_macro_precision\": expected_macro_precision,\n            \"expected_macro_recall\": expected_macro_recall,\n            \"expected_macro_fscore\": expected_macro_fscore,\n            \"expected_num_tps\": expected_num_tps,\n            \"expected_num_fps\": expected_num_fps,\n            \"expected_num_fns\": expected_num_fns,\n            \"expected_micro_precision\": expected_micro_precision,\n            \"expected_micro_recall\": expected_micro_recall,\n            \"expected_micro_fscore\": expected_micro_fscore,\n        },\n    )\n\n\n@pytest.fixture\ndef setup_parscit_case(parscit_dataset_manager):\n    data_manager = parscit_dataset_manager\n    num_labels = data_manager.num_labels[\"seq_label\"]\n    print(f\"Parscit number of labels {num_labels}\")\n    train_dataset = data_manager.train_dataset\n    lines, labels = train_dataset.get_lines_labels()\n    max_len_labels = max([len(label.tokens[\"seq_label\"]) for label in labels])\n    # generate random predicted tags\n    predicted_tags = []\n    for label in labels:\n        predicted_tags_ = np.random.choice(\n            range(num_labels), size=max_len_labels\n        ).tolist()\n        predicted_tags.append(predicted_tags_)\n\n    model_forward_dict = {\"predicted_tags_seq_label\": predicted_tags}\n\n    return data_manager, lines, labels, model_forward_dict\n\n\nclass TestTokenClsAccuracy:\n    def test_base_case_get_metric(self, setup_basecase):\n        metric, lines, labels, model_forward_dict, expected = setup_basecase\n        metric.calc_metric(\n            lines=lines, labels=labels, model_forward_dict=model_forward_dict\n        )\n        accuracy_metrics = metric.get_metric()\n        accuracy_metrics = accuracy_metrics[\"seq_label\"]\n\n        expected_precision = expected[\"expected_precision\"]\n        expected_recall = expected[\"expected_recall\"]\n        expected_fmeasure = expected[\"expected_fscore\"]\n        expected_micro_precision = expected[\"expected_micro_precision\"]\n        expected_micro_recall = expected[\"expected_micro_recall\"]\n        expected_micro_fscore = expected[\"expected_micro_fscore\"]\n        expected_macro_precision = expected[\"expected_macro_precision\"]\n        expected_macro_recall = expected[\"expected_macro_recall\"]\n        expected_macro_fscore = expected[\"expected_macro_fscore\"]\n\n        precision = accuracy_metrics[\"precision\"]\n        recall = accuracy_metrics[\"recall\"]\n        fscore = accuracy_metrics[\"fscore\"]\n        micro_precision = accuracy_metrics[\"micro_precision\"]\n        micro_recall = accuracy_metrics[\"micro_recall\"]\n        micro_fscore = accuracy_metrics[\"micro_fscore\"]\n        macro_precision = accuracy_metrics[\"macro_precision\"]\n        macro_recall = accuracy_metrics[\"macro_recall\"]\n        macro_fscore = accuracy_metrics[\"macro_fscore\"]\n\n        for class_label, precision_value in precision.items():\n            assert precision_value == expected_precision[class_label]\n\n        for class_label, recall_value in recall.items():\n            assert recall_value == expected_recall[class_label]\n\n        for class_label, fscore_value in fscore.items():\n            assert fscore_value == expected_fmeasure[class_label]\n\n        assert micro_precision == expected_micro_precision\n        assert micro_recall == expected_micro_recall\n        assert micro_fscore == expected_micro_fscore\n        assert macro_precision == expected_macro_precision\n        assert macro_recall == expected_macro_recall\n        assert macro_fscore == expected_macro_fscore\n\n    @pytest.mark.parametrize(\"report_type\", [\"wasabi\"])\n    def test_report_metric_works(self, setup_basecase, report_type):\n        metric, lines, labels, model_forward_dict, expected = setup_basecase\n        try:\n            metric.report_metrics(report_type=report_type)\n        except:\n            pytest.fail(f\"report_metric(report_type={report_type}) failed\")\n\n    def test_confusion_mtrx_works(self, setup_basecase):\n        metric, lines, labels, model_forward_dict, expected = setup_basecase\n        try:\n            true_tag_indices = [[5, 4]]\n            predicted_tag_indices = model_forward_dict[\"predicted_tags_seq_label\"]\n            metric.print_confusion_metrics(\n                true_tag_indices=true_tag_indices,\n                predicted_tag_indices=predicted_tag_indices,\n                labels_mask=None,\n            )\n        except:\n            pytest.fail(\"print_counfusion_metric() failed\")\n\n    def test_token_cls_accuracy_in_class_nursery(self):\n        assert ClassNursery.class_nursery.get(\"TokenClassificationAccuracy\") is not None\n\n    def test_parscit_metrics_dont_have_special_tokens(self, setup_parscit_case):\n        data_manager, lines, labels, model_forward_dict = setup_parscit_case\n        metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n\n        metric.calc_metric(\n            lines=lines, labels=labels, model_forward_dict=model_forward_dict\n        )\n        label_vocab = data_manager.namespace_to_vocab[\"seq_label\"]\n\n        start_token_idx = label_vocab.get_idx_from_token(label_vocab.start_token)\n        end_token_idx = label_vocab.get_idx_from_token(label_vocab.end_token)\n        pad_token_idx = label_vocab.get_idx_from_token(label_vocab.pad_token)\n        unk_token_idx = label_vocab.get_idx_from_token(label_vocab.unk_token)\n\n        special_indices = [start_token_idx, end_token_idx, pad_token_idx, unk_token_idx]\n\n        tp_counter = metric.tp_counter[\"seq_label\"]\n        fp_counter = metric.fp_counter[\"seq_label\"]\n        fn_counter = metric.fn_counter[\"seq_label\"]\n\n        tp_counter_classes = tp_counter.keys()\n        fp_counter_classes = fp_counter.keys()\n        fn_counter_classes = fn_counter.keys()\n\n        assert len(set(special_indices).intersection(tp_counter_classes)) == 0\n        assert len(set(special_indices).intersection(fp_counter_classes)) == 0\n        assert len(set(special_indices).intersection(fn_counter_classes)) == 0\n"}
{"type": "test_file", "path": "tests/models/test_rnnseqcrftagger.py", "content": "import pytest\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.datasets.seq_labeling.seq_labelling_dataset import (\n    SeqLabellingDatasetManager,\n)\n\n\n@pytest.fixture(scope=\"session\")\ndef seq_dataset_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train.txt\")\n    train_file.write(\n        \"word11_train###label1 word21_train###label2\\nword12_train###label1 word22_train###label2 word32_train###label3\"\n    )\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev.txt\")\n    dev_file.write(\n        \"word11_dev###label1 word21_dev###label2\\nword12_dev###label1 word22_dev###label2 word32_dev###label3\"\n    )\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test.txt\")\n    test_file.write(\n        \"word11_test###label1 word21_test###label2\\nword12_test###label1 word22_test###label2 word32_test###label3\"\n    )\n\n    data_manager = SeqLabellingDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    return data_manager\n\n\n@pytest.fixture()\ndef setup_parscit_tagger(seq_dataset_manager):\n    EMBEDDING_DIM = 100\n    HIDDEN_DIM = 100\n    BIDIRECTIONAL = True\n    COMBINE_STRATEGY = \"concat\"\n    dataset_manager = seq_dataset_manager\n\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n\n    char_embedder = CharEmbedder(\n        char_embedding_dimension=10,\n        hidden_dimension=20,\n        datasets_manager=dataset_manager,\n    )\n    embedder = ConcatEmbedders([embedder, char_embedder])\n\n    encoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=0.0,\n        hidden_dim=HIDDEN_DIM,\n        bidirectional=BIDIRECTIONAL,\n        combine_strategy=COMBINE_STRATEGY,\n        rnn_bias=False,\n        add_projection_layer=False,\n    )\n\n    tagger = RnnSeqCrfTagger(\n        rnn2seqencoder=encoder,\n        encoding_dim=2 * HIDDEN_DIM\n        if BIDIRECTIONAL and COMBINE_STRATEGY == \"concat\"\n        else HIDDEN_DIM,\n        datasets_manager=dataset_manager,\n    )\n\n    return (\n        tagger,\n        dataset_manager,\n        {\n            \"EMBEDDING_DIM\": EMBEDDING_DIM,\n            \"HIDDEN_DIM\": 2 * HIDDEN_DIM\n            if BIDIRECTIONAL and COMBINE_STRATEGY == \"concat\"\n            else HIDDEN_DIM,\n            \"COMBINE_STRATEGY\": COMBINE_STRATEGY,\n            \"BIDIRECTIONAL\": BIDIRECTIONAL,\n            \"EXPECTED_HIDDEN_DIM\": 2 * HIDDEN_DIM\n            if COMBINE_STRATEGY == \"concat\" and BIDIRECTIONAL\n            else HIDDEN_DIM,\n        },\n    )\n\n\nclass TestParscitTagger:\n    def test_parscit_tagger_namespaces(self, setup_parscit_tagger, seq_dataset_manager):\n        tagger, dataset_manager, options = setup_parscit_tagger\n        dataset_manager = seq_dataset_manager\n        lines, labels = dataset_manager.train_dataset.get_lines_labels()\n\n        output_dict = tagger(\n            lines=lines,\n            labels=labels,\n            is_training=True,\n            is_validation=False,\n            is_test=False,\n        )\n\n        assert \"logits_seq_label\" in output_dict.keys()\n        assert \"predicted_tags_seq_label\" in output_dict.keys()\n        assert \"loss\" in output_dict.keys()\n\n    def test_parscit_tagger_dimensions(self, setup_parscit_tagger, seq_dataset_manager):\n        tagger, dataset_manager, options = setup_parscit_tagger\n        dataset_manager = seq_dataset_manager\n        lines, labels = dataset_manager.train_dataset.get_lines_labels()\n        output_dict = tagger(\n            lines=lines,\n            labels=labels,\n            is_training=True,\n            is_validation=False,\n            is_test=False,\n        )\n        assert output_dict[\"logits_seq_label\"].size() == (2, 3, 7)\n"}
{"type": "test_file", "path": "tests/models/test_simple_classifier.py", "content": "import pytest\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.utils.class_nursery import ClassNursery\n\n\n@pytest.fixture(scope=\"session\")\ndef clf_dataset_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train_file.txt\")\n    train_file.write(\"train_line1###label1\\ntrain_line2###label2\")\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev_file.txt\")\n    dev_file.write(\"dev_line1###label1\\ndev_line2###label2\")\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test_file.txt\")\n    test_file.write(\"test_line1###label1\\ntest_line2###label2\")\n\n    clf_dataset_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n        batch_size=1,\n    )\n\n    return clf_dataset_manager\n\n\n@pytest.fixture\ndef setup_simple_classifier(clf_dataset_manager):\n    datasets_manager = clf_dataset_manager\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n    encoder = BOW_Encoder(embedder=embedder)\n    classifier = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=50,\n        num_classes=2,\n        datasets_manager=datasets_manager,\n        classification_layer_bias=True,\n    )\n    train_dataset = datasets_manager.train_dataset\n    lines, labels = train_dataset.get_lines_labels()\n\n    return classifier, lines, labels\n\n\nclass TestSimpleClassifier:\n    def test_classifier_logits_shape(self, setup_simple_classifier):\n        classifier, lines, labels = setup_simple_classifier\n        output = classifier(\n            lines=lines,\n            labels=labels,\n            is_training=True,\n            is_validation=False,\n            is_test=False,\n        )\n        logits = output[\"logits\"]\n        assert logits.size(0) == 2\n        assert logits.size(1) == 2\n\n    def test_classifier_normalized_probs_shape(self, setup_simple_classifier):\n        classifier, lines, labels = setup_simple_classifier\n        output = classifier(\n            lines=lines,\n            labels=labels,\n            is_training=True,\n            is_validation=False,\n            is_test=False,\n        )\n        normalized_probs = output[\"normalized_probs\"]\n        assert normalized_probs.size(0) == 2 and normalized_probs.size(1) == 2\n\n    # def test_classifier_produces_equal_probs_for_0_embedding(\n    #     self, setup_simple_classifier\n    # ):\n    #     iter_dict, simple_classifier, batch_size, num_classes = setup_simple_classifier\n    #     output = simple_classifier(\n    #         iter_dict, is_training=True, is_validation=False, is_test=False\n    #     )\n    #     probs = output[\"normalized_probs\"]\n    #     expected_probs = torch.ones([batch_size, num_classes]) / num_classes\n    #     assert torch.allclose(probs, expected_probs)\n    #\n    # def test_classifier_produces_correct_initial_loss_for_0_embedding(\n    #     self, setup_simple_classifier\n    # ):\n    #     iter_dict, simple_classifier, batch_size, num_classes = setup_simple_classifier\n    #     output = simple_classifier(\n    #         iter_dict, is_training=True, is_validation=False, is_test=False\n    #     )\n    #     loss = output[\"loss\"].item()\n    #     correct_loss = -np.log(1 / num_classes)\n    #     assert torch.allclose(torch.Tensor([loss]), torch.Tensor([correct_loss]))\n\n    # def test_classifier_produces_correct_precision(self, setup_simple_classifier):\n    #     iter_dict, simple_classifier, batch_size, num_classes = setup_simple_classifier\n    #     output = simple_classifier(\n    #         iter_dict, is_training=True, is_validation=False, is_test=False\n    #     )\n    #     idx2labelname_mapping = {0: \"good class\", 1: \"bad class\", 2: \"average_class\"}\n    #     metrics_calc = PrecisionRecallFMeasure(\n    #         idx2labelname_mapping=idx2labelname_mapping\n    #     )\n    #\n    #     metrics_calc.calc_metric(iter_dict=iter_dict, model_forward_dict=output)\n    #     metrics = metrics_calc.get_metric()\n    #     precision = metrics[\"precision\"]\n    #\n    #     # NOTE: topk returns the last value in the dimension incase\n    #     # all the values are equal.\n    #     expected_precision = {1: 0, 2: 0}\n    #\n    #     assert len(precision) == 2\n    #\n    #     for class_label, precision_value in precision.items():\n    #         assert precision_value == expected_precision[class_label]\n\n    def test_simple_classifier_in_class_nursery(self):\n        assert ClassNursery.class_nursery.get(\"SimpleClassifier\") is not None\n"}
{"type": "test_file", "path": "tests/models/test_simple_seq2seq.py", "content": "import pytest\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.modules.lstm2seqdecoder import Lstm2SeqDecoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.datasets.summarization.abstractive_text_summarization_dataset import (\n    AbstractiveSummarizationDatasetManager,\n)\nfrom sciwing.models.simple_seq2seq import Seq2SeqModel\n\n\n@pytest.fixture(scope=\"session\")\ndef abs_sum_dataset_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train.txt\")\n    train_file.write(\n        \"word11_train word21_train###word11_label word21_label\\nword12_train word22_train word32_train###word11_label word22_label\"\n    )\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev.txt\")\n    dev_file.write(\n        \"word11_dev word21_dev###word11_label word21_label\\nword12_dev word22_dev word32_dev###word11_label word22_label\"\n    )\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test.txt\")\n    test_file.write(\n        \"word11_test word21_test###word11_label word21_label\\nword12_test word22_test word32_test###word11_label word22_label\"\n    )\n\n    data_manager = AbstractiveSummarizationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    return data_manager\n\n\n@pytest.fixture()\ndef setup_seq2seq_model(abs_sum_dataset_manager):\n    EMBEDDING_DIM = 100\n    HIDDEN_DIM = 100\n    BIDIRECTIONAL = True\n    COMBINE_STRATEGY = \"concat\"\n    NUM_LAYERS = 1\n    MAX_LENGTH = 4\n    datasets_manager = abs_sum_dataset_manager\n\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n\n    encoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=0.0,\n        hidden_dim=HIDDEN_DIM,\n        bidirectional=BIDIRECTIONAL,\n        combine_strategy=COMBINE_STRATEGY,\n        rnn_bias=False,\n        add_projection_layer=False,\n    )\n\n    decoder = Lstm2SeqDecoder(\n        embedder=embedder,\n        vocab=datasets_manager.namespace_to_vocab[\"tokens\"],\n        max_length=MAX_LENGTH,\n        dropout_value=0.0,\n        hidden_dim=HIDDEN_DIM,\n        bidirectional=BIDIRECTIONAL,\n        num_layers=NUM_LAYERS,\n        combine_strategy=COMBINE_STRATEGY,\n        rnn_bias=False,\n    )\n\n    model = Seq2SeqModel(\n        rnn2seqencoder=encoder,\n        rnn2seqdecoder=decoder,\n        datasets_manager=datasets_manager,\n        enc_hidden_dim=HIDDEN_DIM,\n        bidirectional=BIDIRECTIONAL,\n    )\n\n    return (\n        model,\n        datasets_manager,\n        {\n            \"EMBEDDING_DIM\": EMBEDDING_DIM,\n            \"MAX_LENGTH\": MAX_LENGTH,\n            \"HIDDEN_DIM\": 2 * HIDDEN_DIM\n            if BIDIRECTIONAL and COMBINE_STRATEGY == \"concat\"\n            else HIDDEN_DIM,\n            \"COMBINE_STRATEGY\": COMBINE_STRATEGY,\n            \"BIDIRECTIONAL\": BIDIRECTIONAL,\n            \"EXPECTED_HIDDEN_DIM\": 2 * HIDDEN_DIM\n            if COMBINE_STRATEGY == \"concat\" and BIDIRECTIONAL\n            else HIDDEN_DIM,\n        },\n    )\n\n\nclass TestSeq2SeqModel:\n    def test_seq2seq_model_namespaces(\n        self, setup_seq2seq_model, abs_sum_dataset_manager\n    ):\n        model, dataset_manager, options = setup_seq2seq_model\n        dataset_manager = abs_sum_dataset_manager\n        lines, labels = dataset_manager.train_dataset.get_lines_labels()\n\n        output_dict = model(\n            lines=lines,\n            labels=labels,\n            is_training=True,\n            is_validation=False,\n            is_test=False,\n        )\n\n        assert len(lines) == 2\n        assert \"predicted_tags_tokens\" in output_dict.keys()\n        assert \"loss\" in output_dict.keys()\n\n    def test_seq2seq_model_dimensions(\n        self, setup_seq2seq_model, abs_sum_dataset_manager\n    ):\n        model, dataset_manager, options = setup_seq2seq_model\n        dataset_manager = abs_sum_dataset_manager\n        VOCAB_SIZE = dataset_manager.namespace_to_vocab[\"tokens\"].get_vocab_len()\n        lines, labels = dataset_manager.train_dataset.get_lines_labels()\n        output_dict = model(\n            lines=lines,\n            labels=labels,\n            is_training=True,\n            is_validation=False,\n            is_test=False,\n        )\n        assert output_dict[\"predicted_probs_tokens\"].size() == (\n            2,\n            options[\"MAX_LENGTH\"],\n            VOCAB_SIZE,\n        )\n"}
{"type": "test_file", "path": "tests/modules/embedders/test_bert_embedder.py", "content": "import pytest\nfrom sciwing.modules.embedders.bert_embedder import BertEmbedder\nimport itertools\nfrom sciwing.utils.common import get_system_mem_in_gb\nfrom sciwing.data.line import Line\nimport torch\n\nbert_types = [\n    \"bert-base-uncased\",\n    \"bert-base-cased\",\n    \"scibert-base-cased\",\n    \"scibert-sci-cased\",\n    \"scibert-base-uncased\",\n    \"scibert-sci-uncased\",\n    \"bert-large-uncased\",\n    \"bert-large-cased\",\n]\n\naggregation_types = [\"sum\", \"average\"]\n\nbert_type_aggregation = list(itertools.product(bert_types, aggregation_types))\n\n\nsystem_memory = get_system_mem_in_gb()\nsystem_memory = int(system_memory)\n\n\n@pytest.fixture(params=bert_type_aggregation)\ndef setup_bert_embedder(request):\n    dropout_value = 0.0\n    bert_type, aggregation_type = request.param\n\n    bert_embedder = BertEmbedder(\n        dropout_value=dropout_value,\n        aggregation_type=aggregation_type,\n        bert_type=bert_type,\n    )\n    strings = [\n        \"Lets start by talking politics\",\n        \"there are radical ways to test your code\",\n    ]\n\n    lines = []\n    for string in strings:\n        line = Line(text=string)\n        lines.append(line)\n\n    return bert_embedder, lines\n\n\n@pytest.mark.skipif(\n    system_memory < 4, reason=\"System memory too small to run testing for BertEmbedder\"\n)\nclass TestBertEmbedder:\n    @pytest.mark.slow\n    def test_embedder_dimensions(self, setup_bert_embedder):\n        \"\"\"\n            The bow bert encoder should return a single instance\n            that is the sum of the word embeddings of the instance\n        \"\"\"\n        bert_embedder, lines = setup_bert_embedder\n        encoding = bert_embedder(lines)\n        lens = [len(line.tokens[\"tokens\"]) for line in lines]\n        max_word_len = max(lens)\n        assert encoding.size(0) == 2\n        assert encoding.size(2) == bert_embedder.get_embedding_dimension()\n        assert encoding.size(1) == max_word_len\n\n    @pytest.mark.slow\n    def test_bert_embedder_tokens(self, setup_bert_embedder):\n        bert_embedder, lines = setup_bert_embedder\n        _ = bert_embedder(lines)\n        emb_dim = bert_embedder.get_embedding_dimension()\n        emb_name = bert_embedder.embedder_name\n        for line in lines:\n            tokens = line.tokens[bert_embedder.word_tokens_namespace]\n            for token in tokens:\n                assert isinstance(token.get_embedding(emb_name), torch.FloatTensor)\n                assert token.get_embedding(emb_name).size(0) == emb_dim\n"}
{"type": "test_file", "path": "tests/modules/attentions/test_dot_product_attention.py", "content": "import pytest\nimport torch\nfrom sciwing.modules.attentions.dot_product_attention import DotProductAttention\n\nN = 1\nH = 100\nT = 10\n\n\n@pytest.fixture()\ndef zero_query():\n    query = torch.zeros(N, H)\n    return query\n\n\n@pytest.fixture()\ndef random_keys():\n    key = torch.randn(N, T, H)\n    return key\n\n\n@pytest.fixture\ndef attention():\n    attention = DotProductAttention()\n    return attention\n\n\nclass TestDotProductAttention:\n    def test_zero_query(self, zero_query, random_keys, attention):\n        \"\"\"\n        Zero query should give uninform distribution over the keys\n        \"\"\"\n        attentions = attention(query_matrix=zero_query, key_matrix=random_keys)\n        N, T = attentions.size()\n        ones = torch.ones(N, T)\n        ones = ones / T\n        assert torch.allclose(attentions, ones)\n\n    def test_attention_sums_to_one(sel, zero_query, random_keys, attention):\n        attentions = attention(query_matrix=zero_query, key_matrix=random_keys)\n        N, T = attentions.size()\n        ones = torch.ones(N, 1)\n        sum = torch.sum(attentions, dim=1)\n        assert torch.allclose(ones, sum)\n\n    def test_attention_size(self, zero_query, random_keys, attention):\n        attentions = attention(query_matrix=zero_query, key_matrix=random_keys)\n        assert attentions.size() == (N, T)\n"}
{"type": "test_file", "path": "tests/modules/embedders/test_bow_elmo_embedder.py", "content": "import pytest\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.data.line import Line\nfrom sciwing.utils.common import get_system_mem_in_gb\nimport torch\n\nmem_gb = get_system_mem_in_gb()\nmem_gb = int(mem_gb)\n\n\n@pytest.fixture(params=[\"sum\", \"average\", \"first\", \"last\"])\ndef setup_bow_elmo_encoder(request):\n    layer_aggregation = request.param\n    strings = [\"I like to eat carrot\", \"I like to go out on long drives in a car\"]\n\n    lines = []\n    for string in strings:\n        line = Line(text=string)\n        lines.append(line)\n\n    bow_elmo_embedder = BowElmoEmbedder(layer_aggregation=layer_aggregation)\n    return bow_elmo_embedder, lines\n\n\nclass TestBowElmoEncoder:\n    @pytest.mark.slow\n    def test_dimension(self, setup_bow_elmo_encoder):\n        bow_elmo_embedder, lines = setup_bow_elmo_encoder\n        embedding = bow_elmo_embedder(lines)\n        assert embedding.size(0) == 2\n        assert embedding.size(2) == 1024\n\n    @pytest.mark.slow\n    def test_token_embeddings(self, setup_bow_elmo_encoder):\n        bow_elmo_embedder, lines = setup_bow_elmo_encoder\n        _ = bow_elmo_embedder(lines)\n\n        for line in lines:\n            tokens = line.tokens[\"tokens\"]\n            for token in tokens:\n                assert isinstance(token.get_embedding(\"elmo\"), torch.FloatTensor)\n                assert token.get_embedding(\"elmo\").size(0) == 1024\n"}
{"type": "test_file", "path": "tests/modules/embedders/test_char_embedder.py", "content": "import pytest\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.data.line import Line\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\nfrom sciwing.tokenizers.character_tokenizer import CharacterTokenizer\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nimport torch\n\n\n@pytest.fixture(scope=\"session\")\ndef clf_dataset_manager(tmpdir_factory):\n    train_file = tmpdir_factory.mktemp(\"train_data\").join(\"train_file.txt\")\n    train_file.write(\"train_line1###label1\\ntrain_line2###label2\")\n\n    dev_file = tmpdir_factory.mktemp(\"dev_data\").join(\"dev_file.txt\")\n    dev_file.write(\"dev_line1###label1\\ndev_line2###label2\")\n\n    test_file = tmpdir_factory.mktemp(\"test_data\").join(\"test_file.txt\")\n    test_file.write(\"test_line1###label1\\ntest_line2###label2\")\n\n    clf_dataset_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n        batch_size=1,\n    )\n\n    return clf_dataset_manager\n\n\n@pytest.fixture(params=[(10, 100)])\ndef setup_char_embedder(request, clf_dataset_manager):\n    char_embedding_dim, hidden_dim = request.param\n    datset_manager = clf_dataset_manager\n    embedder = CharEmbedder(\n        char_embedding_dimension=char_embedding_dim,\n        hidden_dimension=hidden_dim,\n        datasets_manager=datset_manager,\n    )\n    texts = [\"This is sentence\", \"This is another sentence\"]\n    lines = []\n    for text in texts:\n        line = Line(\n            text=text,\n            tokenizers={\"tokens\": WordTokenizer(), \"char_tokens\": CharacterTokenizer()},\n        )\n        lines.append(line)\n\n    return embedder, lines\n\n\nclass TestCharEmbedder:\n    def test_encoding_dimension(self, setup_char_embedder):\n        embedder, lines = setup_char_embedder\n        embedded = embedder(lines)\n        assert embedded.size(0) == 2\n        assert embedded.size(2) == embedder.hidden_dimension * 2\n\n    def test_embedding_set_lines(self, setup_char_embedder):\n        embedder, lines = setup_char_embedder\n        _ = embedder(lines)\n        for line in lines:\n            tokens = line.tokens[\"tokens\"]\n            for token in tokens:\n                assert isinstance(\n                    token.get_embedding(\"char_embedding\"), torch.FloatTensor\n                )\n"}
{"type": "test_file", "path": "tests/modules/embedders/test_concat_embedders.py", "content": "import pytest\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.data.line import Line\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\nfrom sciwing.tokenizers.character_tokenizer import CharacterTokenizer\n\n\n@pytest.fixture\ndef setup_lines():\n    texts = [\"First sentence\", \"Second Sentence\"]\n    lines = []\n    for text in texts:\n        line = Line(\n            text=text,\n            tokenizers={\"tokens\": WordTokenizer(), \"char_tokens\": CharacterTokenizer()},\n        )\n        lines.append(line)\n    return lines\n\n\n@pytest.fixture\ndef setup_concat_vanilla_embedders():\n    word_embedder_1 = WordEmbedder(embedding_type=\"glove_6B_50\")\n    word_embedder_2 = WordEmbedder(embedding_type=\"glove_6B_100\")\n    embedder = ConcatEmbedders([word_embedder_1, word_embedder_2])\n    return embedder\n\n\nclass TestConcatEmbedders:\n    def test_concat_vanilla_embedders_dim(\n        self, setup_concat_vanilla_embedders, setup_lines\n    ):\n        concat_embedder = setup_concat_vanilla_embedders\n        lines = setup_lines\n        embedding = concat_embedder(lines)\n        assert embedding.size(0) == 2\n        assert embedding.size(2) == 150\n"}
{"type": "test_file", "path": "tests/modules/embedders/test_elmo_embedder.py", "content": "import pytest\nfrom sciwing.modules.embedders.elmo_embedder import ElmoEmbedder\nfrom sciwing.utils.common import get_system_mem_in_gb\nfrom sciwing.data.line import Line\n\nmem_gb = get_system_mem_in_gb()\nmem_gb = int(mem_gb)\n\n\n@pytest.fixture\ndef setup_elmo_embedder():\n    elmo_embedder = ElmoEmbedder()\n    texts = [\"I like to test elmo\", \"Elmo context embedder\"]\n    lines = []\n    for text in texts:\n        line = Line(text=text)\n        lines.append(line)\n    return elmo_embedder, lines\n\n\n@pytest.mark.skipif(\n    mem_gb < 16, reason=\"skipping ELMO embedder because system memory is low\"\n)\nclass TestElmoEmbedder:\n    @pytest.mark.slow\n    def test_elmo_embedder_dimensions(self, setup_elmo_embedder):\n        elmo_embedder, lines = setup_elmo_embedder\n        embedding = elmo_embedder(lines)\n        assert embedding.size() == (len(lines), 5, 1024)\n"}
{"type": "test_file", "path": "tests/modules/embedders/test_flair_embedder.py", "content": "import pytest\nfrom sciwing.modules.embedders.flair_embedder import FlairEmbedder\nfrom sciwing.data.line import Line\nfrom sciwing.tokenizers.word_tokenizer import WordTokenizer\n\n\n@pytest.fixture(params=[\"news\", \"en\"])\ndef flair_embedder(request):\n    embedding_type = request.param\n    embedder = FlairEmbedder(embedding_type=embedding_type, datasets_manager=None)\n\n    return embedder\n\n\n@pytest.fixture\ndef lines():\n    texts = [\"First line\", \"Second Line which is longer\"]\n    lines = []\n    for text in texts:\n        line = Line(\n            text=text, tokenizers={\"tokens\": WordTokenizer(tokenizer=\"vanilla\")}\n        )\n        lines.append(line)\n\n    return lines\n\n\nclass TestFlairEmbedder:\n    def test_embedding_dimension(self, flair_embedder, lines):\n        embedding = flair_embedder(lines)\n        assert embedding.dim() == 3\n\n    def test_embedding_length(self, flair_embedder, lines):\n        embedding = flair_embedder(lines)\n        assert embedding.size(1) == 5\n"}
{"type": "test_file", "path": "tests/modules/embedders/test_trainable_word_embedder.py", "content": "import pytest\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.datasets.seq_labeling.seq_labelling_dataset import (\n    SeqLabellingDatasetManager,\n)\nfrom sciwing.utils.common import chunks\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nimport torch\nfrom sciwing.utils.class_nursery import ClassNursery\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef setup_parscit_dataset_manager():\n    data_dir = pathlib.Path(DATA_DIR)\n    parscit_train_file = data_dir.joinpath(\"parscit.train\")\n    parscit_dev_file = data_dir.joinpath(\"parscit.dev\")\n    parscit_test_file = data_dir.joinpath(\"parscit.test\")\n\n    dataset_manager = SeqLabellingDatasetManager(\n        train_filename=str(parscit_train_file),\n        dev_filename=str(parscit_dev_file),\n        test_filename=str(parscit_test_file),\n    )\n    return dataset_manager\n\n\n@pytest.fixture(\n    scope=\"session\",\n    params=[\"glove_6B_50\", \"glove_6B_100\", \"glove_6B_200\", \"glove_6B_300\", \"parscit\"],\n)\ndef setup_embedder(setup_parscit_dataset_manager, request):\n    data_manager = setup_parscit_dataset_manager\n    embedding_type = request.param\n    embedder = TrainableWordEmbedder(\n        datasets_manager=data_manager, embedding_type=embedding_type\n    )\n    return embedder, data_manager\n\n\nclass TestTrainableWordEmbedder:\n    @pytest.mark.slow\n    def test_returns_float_tensors(self, setup_embedder):\n        embedder, data_manager = setup_embedder\n        train_dataset = data_manager.train_dataset\n        lines, labels = train_dataset.get_lines_labels()\n        for lines_batch in chunks(lines, 10):\n            embedding = embedder(lines_batch)\n            assert isinstance(embedding, torch.FloatTensor)\n\n    @pytest.mark.slow\n    def test_module_has_trainable_params(self, setup_embedder):\n        embedder, data_manager = setup_embedder\n        for param in embedder.parameters():\n            assert param.requires_grad\n\n    @pytest.mark.slow\n    def test_embedder_in_class_nursery(self):\n        assert ClassNursery.class_nursery[\"TrainableWordEmbedder\"] is not None\n\n    @pytest.mark.slow\n    def test_embedding_dimensions(self, setup_embedder):\n        embedder, data_manager = setup_embedder\n        train_dataset = data_manager.train_dataset\n        lines, labels = train_dataset.get_lines_labels()\n        for lines_batch in chunks(lines, 10):\n            embedding = embedder(lines_batch)\n            assert embedding.dim() == 3\n"}
{"type": "test_file", "path": "tests/modules/embedders/test_word_embedder.py", "content": "import pytest\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.data.line import Line\nfrom sciwing.utils.class_nursery import ClassNursery\nimport torch\nfrom sciwing.utils.common import get_system_mem_in_gb\n\nmem_in_gb = get_system_mem_in_gb()\n\n\n@pytest.fixture(\n    params=[\"glove_6B_50\", \"glove_6B_100\", \"glove_6B_200\", \"glove_6B_300\", \"parscit\"]\n)\ndef setup_embedder(request):\n    embedding_type = request.param\n    embedder = WordEmbedder(embedding_type)\n    return embedder\n\n\n@pytest.fixture\ndef setup_lines():\n    texts = [\"first line\", \"second line\"]\n    lines = []\n    for text in texts:\n        line = Line(text=text)\n        lines.append(line)\n    return lines\n\n\n@pytest.mark.skipif(\n    int(mem_in_gb) < 4, reason=\"Memory is too low to run bert tokenizers\"\n)\nclass TestWordEmbedder:\n    @pytest.mark.slow\n    def test_dimension(self, setup_embedder, setup_lines):\n        embedder = setup_embedder\n        lines = setup_lines\n        _ = embedder(lines)\n        for line in lines:\n            for token in line.tokens[\"tokens\"]:\n                embedding = token.get_embedding(name=embedder.embedding_type)\n                assert isinstance(embedding, torch.FloatTensor)\n\n    @pytest.mark.slow\n    def test_final_embedding_size(self, setup_embedder, setup_lines):\n        embedder = setup_embedder\n        lines = setup_lines\n        embeddings = embedder(lines)\n        assert embeddings.size(0) == 2\n\n    def test_vanilla_embedder_in_class_nursery(self):\n        assert ClassNursery.class_nursery[\"WordEmbedder\"] is not None\n"}
{"type": "test_file", "path": "tests/modules/test_bow_encoder.py", "content": "import numpy as np\nimport pytest\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.data.line import Line\nfrom sciwing.utils.class_nursery import ClassNursery\n\n\n@pytest.fixture(params=[\"sum\", \"average\"])\ndef setup_bow_encoder(request):\n    aggregation_type = request.param\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n    encoder = BOW_Encoder(embedder=embedder, aggregation_type=aggregation_type)\n    texts = [\"First sentence\", \"second sentence\"]\n    lines = []\n    for text in texts:\n        line = Line(text=text)\n        lines.append(line)\n\n    return encoder, lines\n\n\nclass TestBOWEncoder:\n    def test_bow_encoder_dimensions(self, setup_bow_encoder):\n        encoder, lines = setup_bow_encoder\n        encoded_lines = encoder(lines)\n        assert encoded_lines.size(0) == 2\n        assert encoded_lines.size(1) == 50\n\n    def test_bow_encoder_in_class_nursery(self):\n        assert ClassNursery.class_nursery.get(\"BOW_Encoder\") is not None\n"}
{"type": "test_file", "path": "tests/modules/test_lstm2seqdecoder.py", "content": "import pytest\nfrom sciwing.modules.lstm2seqdecoder import Lstm2SeqDecoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.attentions.dot_product_attention import DotProductAttention\nfrom sciwing.datasets.summarization.abstractive_text_summarization_dataset import (\n    AbstractiveSummarizationDatasetManager,\n)\nfrom sciwing.data.line import Line\nimport itertools\nimport torch\nfrom sciwing.vocab.vocab import Vocab\n\nlstm2decoder_options = itertools.product(\n    [1, 2], [True, False], [DotProductAttention(), None], [0, 1]\n)\nlstm2decoder_options = list(lstm2decoder_options)\n\n\n@pytest.fixture(params=lstm2decoder_options)\ndef setup_lstm2seqdecoder(request,):\n    HIDDEN_DIM = 1024\n    NUM_LAYERS = request.param[0]\n    BIDIRECTIONAL = request.param[1]\n    TEACHER_FORCING_RATIO = request.param[3]\n    MAX_LENGTH = 5\n\n    lines = []\n    words = []\n    # texts = [\"First\", \"second\", \"Third\"]\n    texts = [\"First sentence\", \"second sentence\", \"Third long sentence here\"]\n    for text in texts:\n        line = Line(text=text)\n        word = Line(text=text.split()[0])\n        lines.append(line)\n        words.append(word)\n    flat_texts = [[word for sentence in texts for word in sentence]]\n    vocab = Vocab(flat_texts)\n    vocab.build_vocab()\n\n    num_direction = 2 if BIDIRECTIONAL else 1\n    h0 = torch.ones(NUM_LAYERS, len(texts), num_direction * HIDDEN_DIM) * 0.1\n    c0 = torch.ones(NUM_LAYERS, len(texts), num_direction * HIDDEN_DIM) * 0.2\n\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n    encoder_outputs = (\n        torch.ones(len(texts), 5, num_direction * HIDDEN_DIM) * 0.5\n        if request.param[2]\n        else None\n    )\n    decoder = Lstm2SeqDecoder(\n        embedder=embedder,\n        vocab=vocab,\n        max_length=MAX_LENGTH,\n        attn_module=request.param[2],\n        dropout_value=0.0,\n        hidden_dim=HIDDEN_DIM,\n        bidirectional=BIDIRECTIONAL,\n        rnn_bias=False,\n        num_layers=NUM_LAYERS,\n    )\n\n    return (\n        decoder,\n        {\n            \"HIDDEN_DIM\": HIDDEN_DIM,\n            \"NUM_LAYERS\": NUM_LAYERS,\n            \"MAX_LENGTH\": MAX_LENGTH,\n            \"TEACHER_FORCING_RATIO\": TEACHER_FORCING_RATIO,\n            \"LINES\": lines,\n            \"WORDS\": words,\n            \"VOCAB_SIZE\": vocab.get_vocab_len(),\n            \"BIDIRECTIONAL\": BIDIRECTIONAL,\n        },\n        encoder_outputs,\n        (h0, c0),\n    )\n\n\nclass TestLstm2SeqDecoder:\n    def test_forward_step(self, setup_lstm2seqdecoder):\n        decoder, options, encoder_outputs, (h0, c0) = setup_lstm2seqdecoder\n        lines = options[\"WORDS\"]\n        num_time_steps = 1\n        batch_size = len(lines)\n        vocab_size = options[\"VOCAB_SIZE\"]\n        decoding, _, _ = decoder.forward_step(\n            lines=lines, h0=h0, c0=c0, encoder_outputs=encoder_outputs\n        )\n        assert decoding.size() == (batch_size, num_time_steps, vocab_size)\n\n    def test_forward(self, setup_lstm2seqdecoder):\n        decoder, options, encoder_outputs, (h0, c0) = setup_lstm2seqdecoder\n        lines = options[\"LINES\"]\n        teacher_forcing_ratio = options[\"TEACHER_FORCING_RATIO\"]\n        num_time_steps = (\n            max([len(line.tokens[\"tokens\"]) for line in lines])\n            if teacher_forcing_ratio > 0\n            else options[\"MAX_LENGTH\"]\n        )\n        batch_size = len(lines)\n\n        vocab_size = options[\"VOCAB_SIZE\"]\n        output = decoder.forward(\n            lines=lines,\n            h0=h0,\n            c0=c0,\n            encoder_outputs=encoder_outputs,\n            teacher_forcing_ratio=teacher_forcing_ratio,\n        )\n        assert output.size() == (batch_size, num_time_steps, vocab_size)\n"}
{"type": "test_file", "path": "tests/modules/test_lstm2seq_attncontext_encoder.py", "content": "import pytest\nfrom sciwing.modules.lstm2seq_attncontext_encoder import Lstm2SeqAttnContextEncoder\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.modules.attentions.dot_product_attention import DotProductAttention\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.data.contextual_lines import LineWithContext\n\n\n@pytest.fixture\ndef encoder():\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n    hidden_dim = 50\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder, hidden_dim=hidden_dim, bidirectional=False\n    )\n\n    attn_module = DotProductAttention()\n\n    context_embedder = WordEmbedder(\n        embedding_type=\"glove_6B_50\", word_tokens_namespace=\"tokens\"\n    )\n\n    encoder = Lstm2SeqAttnContextEncoder(\n        rnn2seqencoder=lstm2seqencoder,\n        attn_module=attn_module,\n        context_embedder=context_embedder,\n    )\n\n    return encoder\n\n\n@pytest.fixture\ndef data():\n    text = \"This is a string\"\n    context = [\"NULL\"]  # represents a null string\n    line = LineWithContext(text=text, context=context)\n    return [line, line]\n\n\nclass TestLSTM2SeqAttnContextEncoder:\n    def test_encoding_size(self, encoder, data):\n        encoding = encoder(data)\n        assert encoding.size(0) == 2\n        assert encoding.size(1) == 4\n        assert encoding.size(2) == 100\n"}
{"type": "test_file", "path": "tests/modules/test_lstm2seqencoder.py", "content": "import pytest\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.data.line import Line\nimport itertools\n\nadd_projection_layer = [True, False]\nlstm2encoder_options = itertools.product(\n    [True, False], [\"sum\", \"concat\"], [1, 2], add_projection_layer\n)\nlstm2encoder_options = list(lstm2encoder_options)\n\n\n@pytest.fixture(params=lstm2encoder_options)\ndef setup_lstm2seqencoder(request):\n    HIDDEN_DIM = 1024\n    BIDIRECTIONAL = request.param[0]\n    COMBINE_STRATEGY = request.param[1]\n    NUM_LAYERS = request.param[2]\n    ADD_PROJECTION_LAYER = request.param[3]\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n    encoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=0.0,\n        hidden_dim=HIDDEN_DIM,\n        bidirectional=BIDIRECTIONAL,\n        combine_strategy=COMBINE_STRATEGY,\n        rnn_bias=False,\n        num_layers=NUM_LAYERS,\n        add_projection_layer=ADD_PROJECTION_LAYER,\n    )\n\n    lines = []\n    texts = [\"First sentence\", \"second sentence\"]\n    for text in texts:\n        line = Line(text=text)\n        lines.append(line)\n\n    return (\n        encoder,\n        {\n            \"HIDDEN_DIM\": HIDDEN_DIM,\n            \"COMBINE_STRATEGY\": COMBINE_STRATEGY,\n            \"BIDIRECTIONAL\": BIDIRECTIONAL,\n            \"EXPECTED_HIDDEN_DIM\": 2 * HIDDEN_DIM\n            if COMBINE_STRATEGY == \"concat\"\n            and BIDIRECTIONAL\n            and not ADD_PROJECTION_LAYER\n            else HIDDEN_DIM,\n            \"NUM_LAYERS\": NUM_LAYERS,\n            \"LINES\": lines,\n            \"TIME_STEPS\": 2,\n        },\n    )\n\n\nclass TestLstm2SeqEncoder:\n    def test_hidden_dim(self, setup_lstm2seqencoder):\n        encoder, options = setup_lstm2seqencoder\n        lines = options[\"LINES\"]\n        num_time_steps = options[\"TIME_STEPS\"]\n        expected_hidden_size = options[\"EXPECTED_HIDDEN_DIM\"]\n        encoding, (hn, cn) = encoder(lines=lines)\n        batch_size = len(lines)\n        print(hn.size(), cn.size())\n        assert encoding.size() == (batch_size, num_time_steps, expected_hidden_size)\n"}
{"type": "test_file", "path": "tests/modules/test_lstm2vecencoder.py", "content": "import pytest\nimport torch\nimport torch.nn as nn\nfrom sciwing.modules.lstm2vecencoder import LSTM2VecEncoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.data.line import Line\nimport itertools\n\ndirections = [True, False]  # True for bi-directions\ncombination_strategy = [\"concat\", \"sum\"]\n\ndirections_combine_strategy = itertools.product(directions, combination_strategy)\ndirections_combine_strategy = list(directions_combine_strategy)\n\n\n@pytest.fixture(params=directions_combine_strategy)\ndef setup_lstm2vecencoder(request):\n    hidden_dimension = 1024\n    combine_strategy = request.param[1]\n    bidirectional = request.param[0]\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n\n    encoder = LSTM2VecEncoder(\n        embedder=embedder,\n        dropout_value=0.0,\n        hidden_dim=hidden_dimension,\n        bidirectional=bidirectional,\n        combine_strategy=combine_strategy,\n        rnn_bias=False,\n    )\n\n    texts = [\"First sentence\", \"second sentence\"]\n    lines = []\n    for text in texts:\n        line = Line(text=text)\n        lines.append(line)\n\n    return (\n        encoder,\n        {\n            \"hidden_dim\": 2 * hidden_dimension\n            if bidirectional and combine_strategy == \"concat\"\n            else hidden_dimension,\n            \"bidirectional\": False,\n            \"combine_strategy\": combine_strategy,\n            \"lines\": lines,\n        },\n    )\n\n\nclass TestLstm2VecEncoder:\n    def test_raises_error_on_wrong_combine_strategy(self, setup_lstm2vecencoder):\n        with pytest.raises(AssertionError):\n\n            encoder = LSTM2VecEncoder(\n                embedder=WordEmbedder(\"glove_6B_50\"), combine_strategy=\"add\"\n            )\n\n    def test_encoding_dimension(self, setup_lstm2vecencoder):\n        encoder, options = setup_lstm2vecencoder\n        hidden_dim = options[\"hidden_dim\"]\n        lines = options[\"lines\"]\n        batch_size = len(lines)\n        encoding = encoder(lines=lines)\n        assert encoding.size() == (batch_size, hidden_dim)\n"}
{"type": "test_file", "path": "tests/numericalizer/test_numericalizer.py", "content": "import pytest\nfrom sciwing.numericalizers.numericalizer import Numericalizer\nfrom sciwing.vocab.vocab import Vocab\nimport torch\n\n\n@pytest.fixture\ndef instances():\n    single_instance = [[\"i\", \"like\", \"nlp\", \"so\", \"much\"]]\n\n    return {\"single_instance\": single_instance}\n\n\n@pytest.fixture()\ndef single_instance_setup(instances):\n    single_instance = instances[\"single_instance\"]\n    MAX_NUM_WORDS = 100\n\n    vocabulary = Vocab(instances=single_instance, max_num_tokens=MAX_NUM_WORDS)\n\n    numericalizer = Numericalizer(vocabulary=vocabulary)\n\n    return single_instance, numericalizer, vocabulary\n\n\nclass TestNumericalizer:\n    def test_max_length_instance_has_less_tokens_than_max_length(\n        self, single_instance_setup\n    ):\n        single_instance, numericalizer, vocabulary = single_instance_setup\n\n        numerical_tokens = numericalizer.numericalize_instance(single_instance[0])\n\n        assert len(numerical_tokens) == len(single_instance[0])\n\n    def test_tokens_are_integers(self, single_instance_setup):\n        \"\"\"\n        Just to test that nothing untoward is  happening\n        \"\"\"\n        single_instance, numericalizer, vocabulary = single_instance_setup\n        numerical_tokens = numericalizer.numericalize_instance(single_instance[0])\n\n        for each_token in numerical_tokens:\n            assert type(each_token) == int\n\n    def test_pad_instances(self, single_instance_setup):\n        single_instance, numericalizer, vocab = single_instance_setup\n        numerical_tokens = numericalizer.numericalize_instance(single_instance[0])\n        padded_numerical_tokens = numericalizer.pad_instance(\n            numerical_tokens, max_length=10\n        )\n        assert [isinstance(token, int) for token in padded_numerical_tokens]\n        assert padded_numerical_tokens[0] == vocab.get_idx_from_token(vocab.start_token)\n        assert padded_numerical_tokens[-1] == vocab.get_idx_from_token(vocab.pad_token)\n\n    def test_pad_batch_instances(self, single_instance_setup):\n        single_instance, numericalizer, vocab = single_instance_setup\n        numerical_tokens = numericalizer.numericalize_batch_instances(single_instance)\n        for instance in numerical_tokens:\n            assert isinstance(instance, list)\n\n    def test_mask_instance(self, single_instance_setup):\n        single_instance, numericalizer, vocab = single_instance_setup\n        numerical_tokens = numericalizer.numericalize_instance(\n            instance=single_instance[0]\n        )\n        padded_numerical_tokens = numericalizer.pad_instance(\n            numericalized_text=numerical_tokens,\n            max_length=10,\n            add_start_end_token=False,\n        )\n        padding_length = 10 - len(numerical_tokens)\n        expected_mask = [0] * len(numerical_tokens) + [1] * padding_length\n        expected_mask = torch.ByteTensor(expected_mask)\n        mask = numericalizer.get_mask_for_instance(instance=padded_numerical_tokens)\n        assert torch.all(torch.eq(mask, expected_mask))\n"}
{"type": "test_file", "path": "tests/numericalizer/test_transformer_numericalizer.py", "content": "import pytest\nfrom sciwing.tokenizers.bert_tokenizer import TokenizerForBert\nfrom sciwing.numericalizers.transformer_numericalizer import NumericalizerForTransformer\nimport torch\nfrom sciwing.utils.common import get_system_mem_in_gb\n\n\n@pytest.fixture\ndef instances():\n    return [\"I  like transformers.\", \"I like python libraries.\"]\n\n\n@pytest.fixture(\n    params=[\n        \"bert-base-uncased\",\n        \"bert-base-cased\",\n        \"scibert-base-uncased\",\n        \"scibert-base-cased\",\n    ]\n)\ndef numericalizer(instances, request):\n    bert_type = request.param\n    tokenizer = TokenizerForBert(bert_type=bert_type)\n    numericalizer = NumericalizerForTransformer(tokenizer=tokenizer)\n    return numericalizer\n\n\nmem_in_gb = get_system_mem_in_gb()\n\n\n@pytest.mark.skipif(\n    int(mem_in_gb) < 10, reason=\"Memory is too low to run bert tokenizers\"\n)\nclass TestNumericalizeForTransformer:\n    @pytest.mark.slow\n    def test_token_types(self, numericalizer, instances):\n        tokenizer = numericalizer.tokenizer\n        for instance in instances:\n            tokens = tokenizer.tokenize(instance)\n            ids = numericalizer.numericalize_instance(tokens)\n            assert all([isinstance(token_id, int) for token_id in ids])\n\n    @pytest.mark.parametrize(\"padding_length\", [10, 100])\n    @pytest.mark.slow\n    def test_padding_length(self, numericalizer, instances, padding_length):\n        tokenizer = numericalizer.tokenizer\n        for instance in instances:\n            tokens = tokenizer.tokenize(instance)\n            ids = numericalizer.numericalize_instance(tokens)\n            padded_ids = numericalizer.pad_instance(\n                numericalized_text=ids, max_length=padding_length\n            )\n            assert len(padded_ids) == padding_length\n\n    @pytest.mark.slow\n    def test_get_mask(self, numericalizer, instances):\n        tokenizer = numericalizer.tokenizer\n        max_length = 10\n        for instance in instances:\n            tokens = tokenizer.tokenize(instance)\n            len_tokens = len(tokens)\n            ids = numericalizer.numericalize_instance(tokens)\n            padded_ids = numericalizer.pad_instance(\n                numericalized_text=ids, max_length=max_length, add_start_end_token=False\n            )\n            padding_length = max_length - len_tokens\n\n            mask = [0] * len_tokens + [1] * padding_length\n            expected_mask = torch.ByteTensor(mask)\n            mask = numericalizer.get_mask_for_instance(instance=padded_ids)\n            assert torch.all(torch.eq(expected_mask, mask))\n"}
{"type": "test_file", "path": "tests/pipelines/test_pipelines.py", "content": ""}
{"type": "test_file", "path": "tests/preprocessing/test_instance_preprocessing.py", "content": "from sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\nimport pytest\n\n\n@pytest.fixture()\ndef setup_lowercase_tests():\n    string = \"I LIKE TO MAKE THIS INTO LoWER CASE\"\n    instance = string.split(\" \")\n    instance_preprocessing = InstancePreprocessing()\n    return string, instance, instance_preprocessing\n\n\n@pytest.fixture()\ndef setup_stopwords_test():\n    string = \"a a but but but\"\n    return string\n\n\n@pytest.fixture(\n    scope=\"session\",\n    params=[\n        (\n            \"lower UPPER Capitalize 123 123a\".split(),\n            \"[LOWER] [UPPER] [CAPITALIZED] [NUMERIC] [ALNUM]\".split(),\n        ),\n        (\"UPPER 123-234\".split(), \"[UPPER] [OTHER]\".split()),\n        (\"(3) 123-234\".split(), \"[OTHER] [OTHER]\".split()),\n    ],\n)\ndef setup_tests_indicate_capitalization(request):\n    instance = request.param[0]\n    expected_instance = request.param[1]\n    instance_preprocessing = InstancePreprocessing()\n    return instance, expected_instance, instance_preprocessing\n\n\nclass TestInstancePreprocessing:\n    def test_lower_case_length(self, setup_lowercase_tests):\n        string, instance, instance_preprocessing = setup_lowercase_tests\n        lowercased_instance = instance_preprocessing.lowercase(instance)\n\n        assert len(lowercased_instance) == len(instance)\n\n    def test_lower_case(self, setup_lowercase_tests):\n        string, instance, instance_preprocessing = setup_lowercase_tests\n        lowercased_instance = instance_preprocessing.lowercase(instance)\n\n        for token in lowercased_instance:\n            assert token.islower()\n\n    def test_remove_stop_words(self, setup_stopwords_test):\n        string = setup_stopwords_test\n        instance = string.split()\n        instance_preprocess = InstancePreprocessing()\n\n        clean_instance = instance_preprocess.remove_stop_words(instance)\n        assert len(clean_instance) == 0\n\n    def test_is_capitalized(self, setup_tests_indicate_capitalization):\n        (\n            instance,\n            expected_instance,\n            instance_preprocessing,\n        ) = setup_tests_indicate_capitalization\n        processed_instance = instance_preprocessing.indicate_capitalization(instance)\n        assert len(instance) == len(processed_instance)\n        assert processed_instance == expected_instance\n"}
{"type": "test_file", "path": "tests/tokenizers/test_bert_tokenizer.py", "content": "from sciwing.tokenizers.bert_tokenizer import TokenizerForBert\nimport pytest\nfrom sciwing.utils.common import get_system_mem_in_gb\n\n\n@pytest.fixture()\ndef setup_bert_tokenizer():\n    def _setup_bert_tokenizer(bert_type):\n        return TokenizerForBert(bert_type)\n\n    return _setup_bert_tokenizer\n\n\n@pytest.fixture()\ndef setup_strings():\n    return [\"BERT and many other language models\", \"Introduction .\", \"123 abc frem\"]\n\n\nbert_types = [\n    \"bert-base-uncased\",\n    \"bert-large-uncased\",\n    \"bert-base-cased\",\n    \"bert-large-cased\",\n    \"scibert-base-cased\",\n    \"scibert-sci-cased\",\n    \"scibert-base-uncased\",\n    \"scibert-sci-uncased\",\n]\n\nmem_in_gb = get_system_mem_in_gb()\n\n\n@pytest.mark.skipif(\n    int(mem_in_gb) < 16, reason=\"Memory is too low to run bert tokenizers\"\n)\nclass TestTokenizerForBert:\n    @pytest.mark.slow\n    @pytest.mark.parametrize(\"bert_type\", bert_types)\n    def test_tokenizer_initializations(self, bert_type, setup_bert_tokenizer):\n        try:\n            tokenizer = setup_bert_tokenizer(bert_type)\n            assert tokenizer.tokenizer is not None\n        except:\n            pytest.fail(f\"Failed to setup tokenizer for bert type {bert_type}\")\n\n    @pytest.mark.slow\n    @pytest.mark.parametrize(\"bert_type\", bert_types)\n    def test_tokenizer_returns_string_list(\n        self, bert_type, setup_bert_tokenizer, setup_strings\n    ):\n        try:\n            tokenizer = setup_bert_tokenizer(bert_type)\n            strings = setup_strings\n            for string in strings:\n                assert type(tokenizer.tokenize(string)) == list\n        except:\n            pytest.fail(f\"Failed to setup tokenizer for bert type {bert_type}\")\n\n    @pytest.mark.slow\n    @pytest.mark.parametrize(\"bert_type\", bert_types)\n    def test_len_tokenization(self, bert_type, setup_bert_tokenizer, setup_strings):\n        tokenizer = setup_bert_tokenizer(bert_type)\n        strings = setup_strings\n        for string in strings:\n            assert len(tokenizer.tokenize(string)) > 0\n\n    @pytest.mark.parametrize(\"bert_type\", bert_types)\n    def test_sample_word_tokenization(self, bert_type, setup_bert_tokenizer):\n        sample_sentence = \"I like big apple.\"\n        tokenizer = setup_bert_tokenizer(bert_type)\n        tokens = tokenizer.tokenize(sample_sentence)\n        tokens = list(map(lambda token: token.lower(), tokens))\n        expected_tokens = [\"I\", \"like\", \"big\", \"apple\", \".\"]\n        expected_tokens = list(map(lambda token: token.lower(), expected_tokens))\n\n        assert tokens == expected_tokens\n\n    @pytest.mark.parametrize(\"bert_type\", bert_types)\n    def test_len_sample_batch(self, bert_type, setup_bert_tokenizer):\n        sample_sentences = [\"I like big apple.\", \"We process text\"]\n        tokenizer = setup_bert_tokenizer(bert_type)\n        tokenized = tokenizer.tokenize_batch(sample_sentences)\n        assert len(tokenized) == 2\n"}
{"type": "test_file", "path": "tests/tokenizers/test_character_tokenizer.py", "content": "import pytest\nfrom sciwing.tokenizers.character_tokenizer import CharacterTokenizer\n\n\n@pytest.fixture\ndef setup_character_tokenizer():\n    tokenizer = CharacterTokenizer()\n    return tokenizer\n\n\nclass TestCharacterTokenizer:\n    @pytest.mark.parametrize(\n        \"string, expected_len\", [(\"The\", 3), (\"The quick brown\", 15)]\n    )\n    def test_character_tokenizer_length(\n        self, string, expected_len, setup_character_tokenizer\n    ):\n        char_tokenizer = setup_character_tokenizer\n        tokenized = char_tokenizer.tokenize(string)\n        assert len(tokenized) == expected_len\n\n    @pytest.mark.parametrize(\n        \"string, expected_tokenization\",\n        [\n            (\"The\", [\"T\", \"h\", \"e\"]),\n            (\n                \"The quick @#\",\n                [\"T\", \"h\", \"e\", \" \", \"q\", \"u\", \"i\", \"c\", \"k\", \" \", \"@\", \"#\"],\n            ),\n        ],\n    )\n    def test_character_tokenizer(\n        self, string, expected_tokenization, setup_character_tokenizer\n    ):\n        tokenizer = setup_character_tokenizer\n        tokenized = tokenizer.tokenize(string)\n        assert tokenized == expected_tokenization\n\n    @pytest.mark.parametrize(\"batch, expected_len\", [([\"The\", \"The quick brown\"], 2)])\n    def test_batch_tokenization_len(\n        self, batch, expected_len, setup_character_tokenizer\n    ):\n        tokenizer = setup_character_tokenizer\n        tokenized = tokenizer.tokenize_batch(batch)\n        assert len(tokenized) == 2\n"}
{"type": "test_file", "path": "tests/tokenizers/test_tokenizer.py", "content": "from sciwing.tokenizers.word_tokenizer import WordTokenizer\nimport pytest\n\n\nclass TestWordTokenizer:\n    def test_sample_word_tokenization(self):\n        sample_sentence = \"I like big apple.\"\n        tokenizer = WordTokenizer()\n        tokens = tokenizer.tokenize(sample_sentence)\n\n        assert tokens == [\"I\", \"like\", \"big\", \"apple\", \".\"]\n\n    def test_sample_apostrophe_tokenization(self):\n        sample_sentence = \"I don't like apples.\"\n        tokenizer = WordTokenizer()\n        tokens = tokenizer.tokenize(sample_sentence)\n\n        assert tokens == [\"I\", \"do\", \"n't\", \"like\", \"apples\", \".\"]\n\n    def test_len_sample_batch(self):\n        sample_sentences = [\"I like big apple.\", \"We process text\"]\n        tokenizer = WordTokenizer()\n        tokenized = tokenizer.tokenize_batch(sample_sentences)\n        assert len(tokenized) == 2\n\n    def test_word_tokenization_types(self):\n        with pytest.raises(AssertionError):\n            tokenizer = WordTokenizer(tokenizer=\"moses\")\n\n    # TODO: Remove this after you have implemented nltk tokenization\n    def test_other_tokenizer(self):\n        tokenizer = WordTokenizer(tokenizer=\"nltk\")\n        assert tokenizer.tokenize(\"First string\") is None\n\n    def test_vanilla_tokenizer(self):\n        tokenizer = WordTokenizer(tokenizer=\"vanilla\")\n        tokenized = tokenizer.tokenize(\n            \"(1999). & P., W. The Control of Discrete Event Systems.\"\n        )\n        assert tokenized == [\n            \"(1999).\",\n            \"&\",\n            \"P.,\",\n            \"W.\",\n            \"The\",\n            \"Control\",\n            \"of\",\n            \"Discrete\",\n            \"Event\",\n            \"Systems.\",\n        ]\n\n    def test_spacy_whitespace_tokenizer(self):\n        tokenizer = WordTokenizer(tokenizer=\"spacy-whitespace\")\n        tokenized = tokenizer.tokenize(\n            \"(1999). & P., W. The Control of Discrete Event Systems.\"\n        )\n        assert tokenized == [\n            \"(1999).\",\n            \"&\",\n            \"P.,\",\n            \"W.\",\n            \"The\",\n            \"Control\",\n            \"of\",\n            \"Discrete\",\n            \"Event\",\n            \"Systems.\",\n        ]\n"}
{"type": "source_file", "path": "docs/source/conf.py", "content": "# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n\nsys.path.insert(0, os.path.abspath(\"../..\"))\n\n# -- Project information -----------------------------------------------------\n\nproject = \"SciWing (Swing)\"\ncopyright = \"2019, Abhinav Ramesh Kashyap\"\nauthor = \"Abhinav Ramesh Kashyap\"\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\"sphinx.ext.autodoc\", \"sphinx.ext.coverage\", \"sphinx.ext.napoleon\"]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"sphinx_rtd_theme\"\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\nhtml_css_files = [\"theme.css\", \"highlights.css\"]\nhtml_favicon = \"_static/img/favicon.png\"\n\n# html_style = \"theme.css\"\n\n# Napoleon settings\nnapoleon_include_init_with_doc = True\nmaster_doc = \"index\"\n\nautodoc_mock_imports = [\n    \"torch\",\n    \"allennlp\",\n    \"numpy\",\n    \"matplotlib\",\n    \"ntlk\",\n    \"spacy\",\n    \"pytorch_pretrained_bert\",\n    \"pytorch_crf\",\n    \"boto3\",\n    \"gensim\",\n    \"pandas\",\n    \"falcon\",\n    \"sklearn\",\n    \"tensorboardX\",\n    \"pytorch-crf\",\n    \"flair\",\n    \"networkx\",\n    \"fastapi\",\n]\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_seq_bert.py", "content": "from sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.embedders.bert_embedder import BertEmbedder\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nimport argparse\nimport wasabi\nimport torch\nimport torch.optim as optim\nfrom sciwing.metrics.conll_2003_metrics import ConLL2003Metrics\nfrom sciwing.engine.engine import Engine\nfrom sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"CoNLL 2003 NER\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n\n    parser.add_argument(\n        \"--add_projection_layer\",\n        help=\"Add projection layer in rnn2seq encoder\",\n        action=\"store_true\",\n    )\n\n    parser.add_argument(\"--bert_type\", help=\"Bert type\")\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"conll_bioul.train\")\n    dev_filename = data_dir.joinpath(\"conll_bioul.dev\")\n    test_filename = data_dir.joinpath(\"conll_bioul.test\")\n\n    instance_preprocessing = InstancePreprocessing()\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"POS\", \"DEP\", \"NER\"],\n        train_only=\"ner\",\n        namespace_vocab_options={\n            \"tokens\": {\"preprocessing_pipeline\": [instance_preprocessing.lowercase]}\n        },\n    )\n\n    embedder = WordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    bert_embedder = BertEmbedder(\n        datasets_manager=data_manager, device=args.device, bert_type=args.bert_type\n    )\n\n    embedder = ConcatEmbedders([embedder, bert_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=args.device,\n        num_layers=args.num_layers,\n        add_projection_layer=args.add_projection_layer,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=args.hidden_dim,\n        device=args.device,\n        tagging_type=\"BIOUL\",\n        datasets_manager=data_manager,\n        include_start_end_trainsitions=False,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n\n    train_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    dev_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    test_metric = ConLL2003Metrics(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer,\n        factor=0.1,\n        mode=\"max\",\n        patience=5,\n        verbose=True,\n        threshold=1e-3,\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n        lr_scheduler=scheduler,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/citation_intent_classification/citation_intent_clf.py", "content": "from sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.lstm2vecencoder import LSTM2VecEncoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.elmo_embedder import ElmoEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nimport sciwing.constants as constants\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport torch\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"LSTM encoder with linear classifier\"\n        \"with initial random word embeddings\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\n        \"--device\", help=\"Adding which device to run the experiment on\", type=str\n    )\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300, random\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the LSTM network\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion for the dataset\", type=float\n    )\n\n    args = parser.parse_args()\n\n    # saving the test dataset params\n    # lets save the test dataset params for the experiment\n\n    DATA_PATH = pathlib.Path(DATA_DIR)\n    train_file = DATA_PATH.joinpath(\"scicite.train\")\n    dev_file = DATA_PATH.joinpath(\"scicite.dev\")\n    test_file = DATA_PATH.joinpath(\"scicite.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    word_embedder = WordEmbedder(embedding_type=args.emb_type, device=args.device)\n    elmo_embedder = ElmoEmbedder(device=args.device)\n\n    embedder = ConcatEmbedders([word_embedder, elmo_embedder])\n    encoder = LSTM2VecEncoder(\n        embedder=embedder,\n        hidden_dim=args.hidden_dim,\n        combine_strategy=args.combine_strategy,\n        bidirectional=args.bidirectional,\n        device=torch.device(args.device),\n    )\n\n    classiier_encoding_dim = (\n        2 * args.hidden_dim if args.bidirectional else args.hidden_dim\n    )\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=classiier_encoding_dim,\n        num_classes=3,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n        sample_proportion=args.sample_proportion,\n        seeds={\"random_seed\": 17, \"numpy_seed\": 17, \"pytorch_seed\": 17},\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_seq_crf.py", "content": "from sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nimport argparse\nimport wasabi\nimport torch\nimport torch.optim as optim\nfrom sciwing.metrics.conll_2003_metrics import ConLL2003Metrics\nfrom sciwing.engine.engine import Engine\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"CoNLL 2003 NER\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n    parser.add_argument(\n        \"--add_projection_layer\",\n        help=\"If set to true, then projection layer will be added \"\n        \"after lstm2seq encoder with an activation function\",\n        action=\"store_true\",\n    )\n\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"conll_2003_small.train\")\n    dev_filename = data_dir.joinpath(\"conll_2003_small.dev\")\n    test_filename = data_dir.joinpath(\"conll_2003_small.test\")\n\n    instance_preprocessing = InstancePreprocessing()\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"POS\", \"DEP\", \"NER\"],\n        train_only=\"ner\",\n        namespace_vocab_options={\n            \"tokens\": {\"preprocessing_pipeline\": [instance_preprocessing.lowercase]}\n        },\n    )\n\n    word_embedder = WordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=word_embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=args.device,\n        num_layers=args.num_layers,\n        add_projection_layer=args.add_projection_layer,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=2 * args.hidden_dim,\n        device=args.device,\n        tagging_type=\"BIOUL\",\n        datasets_manager=data_manager,\n        include_start_end_trainsitions=False,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n\n    train_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    dev_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    test_metric = ConLL2003Metrics(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer,\n        factor=0.1,\n        mode=\"max\",\n        patience=25,\n        verbose=True,\n        threshold=1e-3,\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n        lr_scheduler=scheduler,\n        seeds={\"random_seed\": 17, \"numpy_seed\": 17, \"pytorch_seed\": 17},\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_seq_crf_bow_elmo.py", "content": "from sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nimport argparse\nimport wasabi\nimport torch\nimport torch.optim as optim\nfrom sciwing.metrics.conll_2003_metrics import ConLL2003Metrics\nfrom sciwing.engine.engine import Engine\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"CoNLL 2003 NER\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"eng.train\")\n    dev_filename = data_dir.joinpath(\"eng.testa\")\n    test_filename = data_dir.joinpath(\"eng.testb\")\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"POS\", \"DEP\", \"NER\"],\n        train_only=\"ner\",\n    )\n\n    embedder = WordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    elmo_embedder = BowElmoEmbedder(\n        datasets_manager=data_manager, layer_aggregation=\"average\", device=args.device\n    )\n\n    embedder = ConcatEmbedders([embedder, elmo_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=args.device,\n        num_layers=args.num_layers,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=2 * args.hidden_dim\n        if args.bidirectional and args.combine_strategy == \"concat\"\n        else args.hidden_dim,\n        device=args.device,\n        tagging_type=\"IOB1\",\n        datasets_manager=data_manager,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n\n    train_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    dev_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    test_metric = ConLL2003Metrics(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer,\n        factor=0.1,\n        mode=\"max\",\n        patience=5,\n        verbose=True,\n        threshold=1e-3,\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n        lr_scheduler=scheduler,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_seq_crf_elmo.py", "content": "from sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.embedders.elmo_embedder import ElmoEmbedder\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nimport argparse\nimport wasabi\nimport torch\nimport torch.optim as optim\nfrom sciwing.metrics.conll_2003_metrics import ConLL2003Metrics\nfrom sciwing.engine.engine import Engine\nfrom sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"CoNLL 2003 NER\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n\n    parser.add_argument(\n        \"--add_projection_layer\",\n        help=\"Add projection layer in rnn2seq encoder\",\n        action=\"store_true\",\n    )\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"conll_bioul.train\")\n    dev_filename = data_dir.joinpath(\"conll_bioul.dev\")\n    test_filename = data_dir.joinpath(\"conll_bioul.test\")\n\n    instance_preprocessing = InstancePreprocessing()\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"POS\", \"DEP\", \"NER\"],\n        train_only=\"ner\",\n        namespace_vocab_options={\n            \"tokens\": {\"preprocessing_pipeline\": [instance_preprocessing.lowercase]}\n        },\n    )\n\n    embedder = WordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    elmo_embedder = ElmoEmbedder(datasets_manager=data_manager, device=args.device)\n\n    embedder = ConcatEmbedders([embedder, elmo_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=args.device,\n        num_layers=args.num_layers,\n        add_projection_layer=args.add_projection_layer,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=args.hidden_dim,\n        device=args.device,\n        tagging_type=\"BIOUL\",\n        datasets_manager=data_manager,\n        include_start_end_trainsitions=False,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n\n    train_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    dev_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    test_metric = ConLL2003Metrics(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer,\n        factor=0.1,\n        mode=\"max\",\n        patience=5,\n        verbose=True,\n        threshold=1e-3,\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n        lr_scheduler=scheduler,\n        seeds={\"random_seed\": 127, \"numpy_seed\": 127, \"pytorch_seed\": 127},\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_seq_crf_flair.py", "content": "from sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.embedders.flair_embedder import FlairEmbedder\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nimport argparse\nimport wasabi\nimport torch\nimport torch.optim as optim\nfrom sciwing.metrics.conll_2003_metrics import ConLL2003Metrics\nfrom sciwing.engine.engine import Engine\nfrom sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"CoNLL 2003 NER\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n\n    parser.add_argument(\n        \"--add_projection_layer\",\n        help=\"Add projection layer in rnn2seq encoder\",\n        action=\"store_true\",\n    )\n\n    parser.add_argument(\"--flair_type\", help=\"Bert type\")\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"conll_bioul.train\")\n    dev_filename = data_dir.joinpath(\"conll_bioul.dev\")\n    test_filename = data_dir.joinpath(\"conll_bioul.test\")\n\n    instance_preprocessing = InstancePreprocessing()\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"POS\", \"DEP\", \"NER\"],\n        train_only=\"ner\",\n        namespace_vocab_options={\n            \"tokens\": {\"preprocessing_pipeline\": [instance_preprocessing.lowercase]}\n        },\n    )\n\n    embedder = WordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    flair_embedder = FlairEmbedder(\n        datasets_manager=data_manager,\n        device=args.device,\n        embedding_type=args.flair_type,\n    )\n\n    embedder = ConcatEmbedders([embedder, flair_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=args.device,\n        num_layers=args.num_layers,\n        add_projection_layer=args.add_projection_layer,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=2 * args.hidden_dim,\n        device=args.device,\n        tagging_type=\"BIOUL\",\n        datasets_manager=data_manager,\n        include_start_end_trainsitions=False,\n    )\n\n    optimizer = optim.SGD(params=model.parameters(), lr=args.lr)\n\n    train_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    dev_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    test_metric = ConLL2003Metrics(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer,\n        factor=0.1,\n        mode=\"max\",\n        patience=5,\n        verbose=True,\n        threshold=1e-3,\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n        lr_scheduler=scheduler,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_seq_crf_infer.py", "content": "from sciwing.infer.interface_client_base import BaseInterfaceClient\nfrom typing import Dict, Any\nimport wasabi\nimport sciwing.constants as constants\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nfrom sciwing.cli.sciwing_interact import SciWINGInteract\nimport pathlib\nfrom sciwing.infer.seq_label_inference.conll_inference import Conll2003Inference\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\nclass BuildConllNerSeqCrfInfer(BaseInterfaceClient):\n    def __init__(self, hparams: Dict[str, Any]):\n        self.hparams = hparams\n        data_dir = pathlib.Path(DATA_DIR)\n        self.train_filename = data_dir.joinpath(\"eng.train\")\n        self.dev_filename = data_dir.joinpath(\"eng.testa\")\n        self.test_filename = data_dir.joinpath(\"eng.testb\")\n        self.printer = wasabi.Printer()\n        self.data_manager = self.build_dataset()\n        self.model = self.build_model()\n        self.infer = self.build_infer()\n\n    def build_dataset(self):\n\n        data_manager = CoNLLDatasetManager(\n            train_filename=self.train_filename,\n            dev_filename=self.dev_filename,\n            test_filename=self.test_filename,\n            column_names=[\"POS\", \"DEP\", \"NER\"],\n            train_only=\"ner\",\n        )\n\n        return data_manager\n\n    def build_model(self):\n        embedder = TrainableWordEmbedder(\n            embedding_type=self.hparams.get(\"emb_type\"),\n            datasets_manager=self.data_manager,\n            device=self.hparams.get(\"device\"),\n        )\n\n        embedder = ConcatEmbedders([embedder])\n\n        lstm2seqencoder = Lstm2SeqEncoder(\n            embedder=embedder,\n            dropout_value=self.hparams.get(\"dropout\"),\n            hidden_dim=self.hparams.get(\"hidden_dim\"),\n            bidirectional=self.hparams.get(\"bidirectional\"),\n            combine_strategy=self.hparams.get(\"combine_strategy\"),\n            rnn_bias=True,\n            device=self.hparams.get(\"device\"),\n            num_layers=self.hparams.get(\"num_layers\"),\n        )\n        model = RnnSeqCrfTagger(\n            rnn2seqencoder=lstm2seqencoder,\n            encoding_dim=2 * self.hparams.get(\"hidden_dim\")\n            if self.hparams.get(\"bidirectional\")\n            and self.hparams.get(\"combine_strategy\") == \"concat\"\n            else self.hparams.get(\"hidden_dim\"),\n            device=self.hparams.get(\"device\"),\n            tagging_type=\"IOB1\",\n            datasets_manager=self.data_manager,\n        )\n        return model\n\n    def build_infer(self):\n        infer = Conll2003Inference(\n            model=self.model,\n            model_filepath=self.hparams.get(\"model_filepath\"),\n            datasets_manager=self.data_manager,\n        )\n        return infer\n\n    def generate_prediction_file(self, output_filename: str):\n        self.infer.generate_predictions_for(\n            task=\"ner\",\n            test_filename=str(self.test_filename),\n            output_filename=str(output_filename),\n        )\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    model_filepath = dirname.joinpath(\"checkpoints\", \"best_model.pt\")\n    hparams = {\n        \"emb_type\": \"glove_6B_100\",\n        \"hidden_dim\": 100,\n        \"bidirectional\": False,\n        \"combine_strategy\": \"concat\",\n        \"model_filepath\": str(model_filepath),\n        \"device\": \"cpu\",\n        \"dropout\": 0.5,\n        \"num_layers\": 1,\n    }\n    conll_inference = BuildConllNerSeqCrfInfer(hparams)\n\n    conll_inference.generate_prediction_file(\n        output_filename=pathlib.Path(\"conll_2003_ner_predictions.txt\")\n    )\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_seq_gazeteer_attention.py", "content": "from sciwing.datasets.seq_labeling.conll_yago_dataset import ConllYagoDatasetsManager\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.embedders.elmo_embedder import ElmoEmbedder\nfrom sciwing.modules.attentions.dot_product_attention import DotProductAttention\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.modules.lstm2seq_attncontext_encoder import Lstm2SeqAttnContextEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nimport argparse\nimport wasabi\nimport torch\nimport torch.optim as optim\nfrom sciwing.metrics.conll_2003_metrics import ConLL2003Metrics\nfrom sciwing.engine.engine import Engine\nfrom sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"CoNLL 2003 NER\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n\n    parser.add_argument(\n        \"--add_projection_layer\",\n        help=\"Add projection layer in rnn2seq encoder\",\n        action=\"store_true\",\n    )\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"conll_yago_ner.train\")\n    dev_filename = data_dir.joinpath(\"conll_yago_ner.dev\")\n    test_filename = data_dir.joinpath(\"conll_yago_ner.test\")\n\n    instance_preprocessing = InstancePreprocessing()\n\n    data_manager = ConllYagoDatasetsManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"NER\"],\n        namespace_vocab_options={\n            \"tokens\": {\"preprocessing_pipeline\": [instance_preprocessing.lowercase]}\n        },\n    )\n\n    embedder = WordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=args.device,\n        num_layers=args.num_layers,\n        add_projection_layer=args.add_projection_layer,\n    )\n\n    attn = DotProductAttention()\n    context_embedder = TrainableWordEmbedder(\n        embedding_type=\"glove_6B_300\", datasets_manager=data_manager, device=args.device\n    )\n    lstm2seq_attn_encoder = Lstm2SeqAttnContextEncoder(\n        rnn2seqencoder=lstm2seqencoder,\n        attn_module=attn,\n        context_embedder=context_embedder,\n        device=args.device,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seq_attn_encoder,\n        encoding_dim=600,\n        device=args.device,\n        tagging_type=\"BIOUL\",\n        datasets_manager=data_manager,\n        include_start_end_trainsitions=False,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n\n    train_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    dev_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    test_metric = ConLL2003Metrics(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer,\n        factor=0.1,\n        mode=\"max\",\n        patience=5,\n        verbose=True,\n        threshold=1e-3,\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n        lr_scheduler=scheduler,\n        seeds={\"random_seed\": 127, \"numpy_seed\": 127, \"pytorch_seed\": 127},\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_simple_tagger.py", "content": "from sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.simple_tagger import SimpleTagger\nimport argparse\nimport wasabi\nimport torch\nimport torch.optim as optim\nfrom sciwing.metrics.token_cls_accuracy import TokenClassificationAccuracy\nfrom sciwing.engine.engine import Engine\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"CoNLL 2003 NER\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"eng.train\")\n    dev_filename = data_dir.joinpath(\"eng.testa\")\n    test_filename = data_dir.joinpath(\"eng.testb\")\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"POS\", \"DEP\", \"NER\"],\n        train_only=\"ner\",\n    )\n\n    embedder = TrainableWordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    char_embedder = CharEmbedder(\n        char_embedding_dimension=args.char_emb_dim,\n        hidden_dimension=args.char_encoder_hidden_dim,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n    embedder = ConcatEmbedders([embedder, char_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=args.device,\n        num_layers=args.num_layers,\n    )\n    model = SimpleTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=2 * args.hidden_dim\n        if args.bidirectional and args.combine_strategy == \"concat\"\n        else args.hidden_dim,\n        device=args.device,\n        datasets_manager=data_manager,\n        label_namespace=\"NER\",\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr, weight_decay=args.reg)\n\n    train_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n    dev_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n    test_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"macro_fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/conll_2003/conll_small_elmo.py", "content": "from sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nimport sciwing.constants as constants\nimport pathlib\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.embedders.elmo_embedder import ElmoEmbedder\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nimport argparse\nimport wasabi\nimport torch\nimport torch.optim as optim\nfrom sciwing.metrics.conll_2003_metrics import ConLL2003Metrics\nfrom sciwing.engine.engine import Engine\nfrom sciwing.preprocessing.instance_preprocessing import InstancePreprocessing\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"CoNLL 2003 NER\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n\n    parser.add_argument(\n        \"--add_projection_layer\",\n        help=\"Add projection layer in rnn2seq encoder\",\n        action=\"store_true\",\n    )\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"conll_2003_small.train\")\n    dev_filename = data_dir.joinpath(\"conll_2003_small.dev\")\n    test_filename = data_dir.joinpath(\"conll_2003_small.test\")\n\n    instance_preprocessing = InstancePreprocessing()\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"POS\", \"DEP\", \"NER\"],\n        train_only=\"ner\",\n        namespace_vocab_options={\n            \"tokens\": {\"preprocessing_pipeline\": [instance_preprocessing.lowercase]}\n        },\n    )\n\n    embedder = WordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    elmo_embedder = ElmoEmbedder(datasets_manager=data_manager, device=args.device)\n\n    embedder = ConcatEmbedders([embedder, elmo_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=args.device,\n        num_layers=args.num_layers,\n        add_projection_layer=args.add_projection_layer,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=2 * args.hidden_dim,\n        device=args.device,\n        tagging_type=\"BIOUL\",\n        datasets_manager=data_manager,\n        include_start_end_trainsitions=False,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n\n    train_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    dev_metric = ConLL2003Metrics(datasets_manager=data_manager)\n    test_metric = ConLL2003Metrics(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer,\n        factor=0.1,\n        mode=\"max\",\n        patience=5,\n        verbose=True,\n        threshold=1e-3,\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n        lr_scheduler=scheduler,\n        seeds={\"random_seed\": 5123, \"numpy_seed\": 5123, \"pytorch_seed\": 5123},\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/genericsect_bilstm/__init__.py", "content": ""}
{"type": "source_file", "path": "examples/genericsect_bilstm/genericsect_bilstm.py", "content": "from sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.lstm2vecencoder import LSTM2VecEncoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nimport sciwing.constants as constants\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport pathlib\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport torch\n\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"LSTM encoder with linear classifier\"\n        \"with initial random word embeddings\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\n        \"--device\", help=\"Adding which device to run the experiment on\", type=str\n    )\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300, random\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the LSTM network\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    args = parser.parse_args()\n\n    DATA_DIR = pathlib.Path(DATA_DIR)\n    train_filename = DATA_DIR.joinpath(\"genericSect.train\")\n    dev_filename = DATA_DIR.joinpath(\"genericSect.dev\")\n    test_filename = DATA_DIR.joinpath(\"genericSect.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n    )\n\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\", device=args.device)\n    encoder = LSTM2VecEncoder(\n        embedder=embedder,\n        dropout_value=0.0,\n        hidden_dim=args.hidden_dim,\n        combine_strategy=args.combine_strategy,\n        bidirectional=args.bidirectional,\n        device=torch.device(args.device),\n    )\n\n    classiier_encoding_dim = (\n        2 * args.hidden_dim if args.bidirectional else args.hidden_dim\n    )\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=classiier_encoding_dim,\n        num_classes=12,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/genericsect_bilstm/genericsect_bilstm_infer.py", "content": "import os\nimport sciwing.constants as constants\nfrom sciwing.modules.lstm2vecencoder import LSTM2VecEncoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.infer.interface_client_base import BaseInterfaceClient\nfrom sciwing.cli.sciwing_interact import SciWINGInteract\nfrom typing import Dict, Any\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nDATA_DIR = pathlib.Path(DATA_DIR)\n\n\nclass BuildGenericSectBiLSTMInfer(BaseInterfaceClient):\n    def __init__(self, hparams: Dict[str, Any]):\n        self.hparams = hparams\n        self.data_manager = self.build_dataset()\n        self.model = self.build_model()\n\n    def build_model(self):\n        embedder = WordEmbedder(embedding_type=self.hparams.get(\"embedding_type\"))\n\n        encoder = LSTM2VecEncoder(\n            embedder=embedder,\n            hidden_dim=self.hparams.get(\"hidden_dim\"),\n            combine_strategy=self.hparams.get(\"combine_strategy\"),\n            bidirectional=self.hparams.get(\"bidirectional\"),\n        )\n\n        model = SimpleClassifier(\n            encoder=encoder,\n            encoding_dim=2 * self.hparams.get(\"hidden_dim\"),\n            num_classes=self.hparams.get(\"num_classes\"),\n            classification_layer_bias=True,\n            datasets_manager=self.data_manager,\n        )\n\n        return model\n\n    def build_dataset(self):\n        train_filename = DATA_DIR.joinpath(\"genericSect.train\")\n        dev_filename = DATA_DIR.joinpath(\"genericSect.dev\")\n        test_filename = DATA_DIR.joinpath(\"genericSect.test\")\n\n        data_manager = TextClassificationDatasetManager(\n            train_filename=train_filename,\n            dev_filename=dev_filename,\n            test_filename=test_filename,\n        )\n        return data_manager\n\n    def build_infer(self):\n        inference = ClassificationInference(\n            model=self.model,\n            model_filepath=self.hparams.get(\"model_filepath\"),\n            datasets_manager=self.data_manager,\n        )\n\n        return inference\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    model_filepath = dirname.joinpath(\"checkpoints\", \"best_model.pt\")\n    hparams = {\n        \"embedding_type\": \"glove_6B_50\",\n        \"hidden_dim\": 512,\n        \"bidirectional\": True,\n        \"combine_strategy\": \"concat\",\n        \"num_classes\": 12,\n        \"model_filepath\": model_filepath,\n    }\n    infer = BuildGenericSectBiLSTMInfer(hparams=hparams)\n    cli = SciWINGInteract(infer_client=infer)\n    cli.interact()\n"}
{"type": "source_file", "path": "examples/genericsect_bow_elmo/genericsect_bow_elmo.py", "content": "from sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport sciwing.constants as constants\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport torch\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"Bag of words linear classifier. \"\n        \"with initial elmo word embeddings\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--device\", help=\"device to run the models\", type=str)\n    parser.add_argument(\n        \"--layer_aggregation\", help=\"Layer aggregation strategy\", type=str\n    )\n\n    parser.add_argument(\n        \"--word_aggregation\", help=\"word aggregation strategy\", type=str\n    )\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\"--sample_proportion\", help=\"Sample data size\", type=float)\n\n    args = parser.parse_args()\n\n    DATA_DIR = pathlib.Path(DATA_DIR)\n    train_filename = DATA_DIR.joinpath(\"genericSect.train\")\n    dev_filename = DATA_DIR.joinpath(\"genericSect.dev\")\n    test_filename = DATA_DIR.joinpath(\"genericSect.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n    )\n\n    embedder = BowElmoEmbedder(\n        layer_aggregation=args.layer_aggregation, device=args.device\n    )\n\n    encoder = BOW_Encoder(\n        aggregation_type=args.word_aggregation, embedder=embedder, device=args.device\n    )\n\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=1024,\n        num_classes=12,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/genericsect_bow_elmo/genericsect_bow_elmo_infer.py", "content": "import re\nimport sciwing.constants as constants\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.infer.interface_client_base import BaseInterfaceClient\nfrom sciwing.cli.sciwing_interact import SciWINGInteract\nimport pathlib\nfrom typing import Dict, Any\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nDATA_DIR = pathlib.Path(DATA_DIR)\n\n\nclass BuildGenericSectBowElmo(BaseInterfaceClient):\n    def __init__(self, hparams: Dict[str, Any]):\n        self.hparams = hparams\n        self.data_manager = self.build_dataset()\n        self.model = self.build_model()\n\n    def build_model(self):\n        embedder = BowElmoEmbedder(\n            layer_aggregation=self.hparams.get(\"layer_aggregation\")\n        )\n\n        encoder = BOW_Encoder(\n            aggregation_type=self.hparams.get(\"word_aggregation\"), embedder=embedder\n        )\n\n        model = SimpleClassifier(\n            encoder=encoder,\n            encoding_dim=self.hparams.get(\"encoding_dim\"),\n            num_classes=self.hparams.get(\"num_classes\"),\n            classification_layer_bias=True,\n            datasets_manager=self.data_manager,\n        )\n        return model\n\n    def build_dataset(self):\n        train_filename = DATA_DIR.joinpath(\"genericSect.train\")\n        dev_filename = DATA_DIR.joinpath(\"genericSect.dev\")\n        test_filename = DATA_DIR.joinpath(\"genericSect.test\")\n\n        data_manager = TextClassificationDatasetManager(\n            train_filename=train_filename,\n            dev_filename=dev_filename,\n            test_filename=test_filename,\n        )\n        return data_manager\n\n    def build_infer(self):\n        parsect_inference = ClassificationInference(\n            model=self.model,\n            model_filepath=self.hparams.get(\"model_filepath\"),\n            datasets_manager=self.data_manager,\n        )\n        return parsect_inference\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    model_filepath = dirname.joinpath(\"checkpoints\", \"best_model.pt\")\n    hparams = {\n        \"layer_aggregation\": \"last\",\n        \"word_aggregation\": \"sum\",\n        \"encoding_dim\": 1024,\n        \"num_classes\": 12,\n        \"model_filepath\": model_filepath,\n    }\n    infer = BuildGenericSectBowElmo(hparams)\n    cli = SciWINGInteract(infer)\n    cli.interact()\n"}
{"type": "source_file", "path": "examples/genericsect_bow_random/genericsect_bow_infer.py", "content": "import sciwing.constants as constants\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\nfrom sciwing.infer.interface_client_base import BaseInterfaceClient\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.cli.sciwing_interact import SciWINGInteract\n\nimport pathlib\nfrom typing import Dict, Any\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\nDATA_DIR = pathlib.Path(DATA_DIR)\n\n\nclass BuildGenericSectBowRandom(BaseInterfaceClient):\n    def __init__(self, hparams: Dict[str, Any]):\n        self.hparams = hparams\n        self.data_manager = self.build_dataset()\n        self.model = self.build_model()\n\n    def build_model(self):\n        embedder = WordEmbedder(embedding_type=self.hparams.get(\"emb_type\"))\n        encoder = BOW_Encoder(embedder=embedder)\n\n        model = SimpleClassifier(\n            encoder=encoder,\n            encoding_dim=self.hparams.get(\"encoding_dim\"),\n            num_classes=self.hparams.get(\"num_classes\"),\n            classification_layer_bias=True,\n            datasets_manager=self.data_manager,\n        )\n\n        return model\n\n    def build_dataset(self):\n        data_dir = pathlib.Path(DATA_DIR)\n        train_filename = data_dir.joinpath(\"genericSect.train\")\n        dev_filename = data_dir.joinpath(\"genericSect.dev\")\n        test_filename = data_dir.joinpath(\"genericSect.test\")\n\n        data_manager = TextClassificationDatasetManager(\n            train_filename=train_filename,\n            dev_filename=dev_filename,\n            test_filename=test_filename,\n        )\n        return data_manager\n\n    def build_infer(self):\n        inference = ClassificationInference(\n            model=self.model,\n            model_filepath=self.hparams.get(\"model_filepath\"),\n            datasets_manager=self.data_manager,\n        )\n        return inference\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    model_filepath = dirname.joinpath(\"checkpoints\", \"best_model.pt\")\n    hparams = {\n        \"emb_type\": \"glove_6B_50\",\n        \"model_filepath\": str(model_filepath),\n        \"num_classes\": 12,\n        \"encoding_dim\": 50,\n    }\n    sectlabel_infer = BuildGenericSectBowRandom(hparams)\n    cli = SciWINGInteract(sectlabel_infer)\n    cli.interact()\n"}
{"type": "source_file", "path": "examples/genericsect_bow_random/genericsect_bow.py", "content": "from sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport sciwing.constants as constants\nimport os\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport json\nimport argparse\nimport torch.nn as nn\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"Bag of words linear classifier. \"\n        \"with initial random word embeddings\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\"--emb_type\", help=\"embedding type\", type=str)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion for the dataset\", type=float\n    )\n\n    args = parser.parse_args()\n\n    DATA_DIR = pathlib.Path(DATA_DIR)\n    train_filename = DATA_DIR.joinpath(\"genericSect.train\")\n    dev_filename = DATA_DIR.joinpath(\"genericSect.dev\")\n    test_filename = DATA_DIR.joinpath(\"genericSect.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n    )\n\n    embedder = WordEmbedder(embedding_type=args.emb_type)\n    encoder = BOW_Encoder(embedder=embedder)\n\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=50,\n        num_classes=12,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    engine = Engine(\n        datasets_manager=data_manager,\n        model=model,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/i2b2/i2b2.py", "content": "from sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nfrom sciwing.metrics.token_cls_accuracy import TokenClassificationAccuracy\nimport sciwing.constants as constants\nimport torch\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport wasabi\nimport pathlib\n\nFILES = constants.FILES\nPATHS = constants.PATHS\n\nOUTPUT_DIR = PATHS[\"OUTPUT_DIR\"]\nCONFIGS_DIR = PATHS[\"CONFIGS_DIR\"]\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"LSTM CRF Parscit tagger for reference string parsing\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--model_save_dir\", help=\"Model save directory\", type=str)\n\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300, parscit\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n    parser.add_argument(\n        \"--sample_proportion\",\n        help=\"Sampling proportion of dataset for debugging\",\n        type=float,\n    )\n\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"i2b2.train\")\n    dev_filename = data_dir.joinpath(\"i2b2.dev\")\n    test_filename = data_dir.joinpath(\"i2b2.dev\")\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"NER\", \"NER\", \"NER\"],\n        train_only=\"ner\",\n    )\n    word_embedder = TrainableWordEmbedder(\n        embedding_type=args.emb_type, device=args.device, datasets_manager=data_manager\n    )\n\n    elmo_embedder = BowElmoEmbedder(\n        datasets_manager=data_manager, layer_aggregation=\"sum\", device=args.device\n    )\n\n    embedder = ConcatEmbedders([word_embedder, elmo_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=torch.device(args.device),\n        dropout_value=0.5,\n        add_projection_layer=False,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=2 * args.hidden_dim\n        if args.bidirectional and args.combine_strategy == \"concat\"\n        else args.hidden_dim,\n        device=torch.device(args.device),\n        datasets_manager=data_manager,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n    dev_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n    test_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer, mode=\"max\", factor=0.1, patience=2\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        track_for_best=\"macro_fscore\",\n        lr_scheduler=scheduler,\n        sample_proportion=args.sample_proportion,\n        use_wandb=True,\n        experiment_hyperparams=vars(args),\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/parscit/parscit.py", "content": "from sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.datasets.seq_labeling.seq_labelling_dataset import (\n    SeqLabellingDatasetManager,\n)\nfrom sciwing.metrics.token_cls_accuracy import TokenClassificationAccuracy\nimport sciwing.constants as constants\nimport torch\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport wasabi\nimport pathlib\n\nFILES = constants.FILES\nPATHS = constants.PATHS\n\nCORA_FILE = FILES[\"CORA_FILE\"]\nOUTPUT_DIR = PATHS[\"OUTPUT_DIR\"]\nCONFIGS_DIR = PATHS[\"CONFIGS_DIR\"]\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"LSTM CRF Parscit tagger for reference string parsing\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--model_save_dir\", help=\"Model save directory\", type=str)\n\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300, parscit\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n    parser.add_argument(\n        \"--sample_proportion\",\n        help=\"Sampling proportion of dataset for debugging\",\n        type=float,\n    )\n\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"parscit.train\")\n    dev_filename = data_dir.joinpath(\"parscit.dev\")\n    test_filename = data_dir.joinpath(\"parscit.test\")\n    data_manager = SeqLabellingDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n    )\n    word_embedder = TrainableWordEmbedder(\n        embedding_type=args.emb_type, device=args.device, datasets_manager=data_manager\n    )\n\n    char_embedder = CharEmbedder(\n        char_embedding_dimension=args.char_emb_dim,\n        hidden_dimension=args.char_encoder_hidden_dim,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    elmo_embedder = BowElmoEmbedder(\n        datasets_manager=data_manager, layer_aggregation=\"sum\", device=args.device\n    )\n\n    embedder = ConcatEmbedders([word_embedder, char_embedder, elmo_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=torch.device(args.device),\n        dropout_value=0.1,\n        add_projection_layer=False,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=2 * args.hidden_dim\n        if args.bidirectional and args.combine_strategy == \"concat\"\n        else args.hidden_dim,\n        device=torch.device(args.device),\n        datasets_manager=data_manager,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n    dev_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n    test_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer, mode=\"max\", factor=0.1, patience=2\n    )\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        track_for_best=\"macro_fscore\",\n        lr_scheduler=scheduler,\n        sample_proportion=args.sample_proportion,\n        use_wandb=True,\n        experiment_hyperparams=vars(args),\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/parscit/parscit_infer.py", "content": "import sciwing.constants as constants\nimport pathlib\nfrom sciwing.datasets.seq_labeling.seq_labelling_dataset import (\n    SeqLabellingDatasetManager,\n)\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nfrom sciwing.infer.seq_label_inference.seq_label_inference import (\n    SequenceLabellingInference,\n)\nfrom sciwing.infer.interface_client_base import BaseInterfaceClient\nfrom sciwing.cli.sciwing_interact import SciWINGInteract\nfrom typing import Dict, Any\nimport wasabi\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\nclass BuildParscitInterference(BaseInterfaceClient):\n    def __init__(self, hparams: Dict[str, Any]):\n        self.hparams = hparams\n        self.printer = wasabi.Printer()\n        self.data_manager = self.build_dataset()\n        self.model = self.build_model()\n\n    def build_model(self):\n\n        word_embedder = TrainableWordEmbedder(\n            embedding_type=self.hparams.get(\"emb_type\"),\n            datasets_manager=self.data_manager,\n        )\n\n        char_embedder = CharEmbedder(\n            char_embedding_dimension=self.hparams.get(\"char_emb_dim\"),\n            hidden_dimension=self.hparams.get(\"char_encoder_hidden_dim\"),\n            datasets_manager=self.data_manager,\n        )\n\n        elmo_embedder = BowElmoEmbedder(datasets_manager=self.data_manager)\n\n        embedder = ConcatEmbedders([word_embedder, char_embedder, elmo_embedder])\n\n        lstm2seqencoder = Lstm2SeqEncoder(\n            embedder=embedder,\n            hidden_dim=self.hparams.get(\"hidden_dim\"),\n            bidirectional=self.hparams.get(\"bidirectional\"),\n            combine_strategy=self.hparams.get(\"combine_strategy\"),\n            rnn_bias=True,\n        )\n\n        model = RnnSeqCrfTagger(\n            rnn2seqencoder=lstm2seqencoder,\n            encoding_dim=2 * self.hparams.get(\"hidden_dim\")\n            if self.hparams.get(\"bidirectional\")\n            and self.hparams.get(\"combine_strategy\") == \"concat\"\n            else self.hparams.get(\"hidden_dim\"),\n            datasets_manager=self.data_manager,\n        )\n\n        self.printer.good(\"Finished Loading the Model\")\n        return model\n\n    def build_dataset(self):\n        data_dir = pathlib.Path(DATA_DIR)\n        train_filename = data_dir.joinpath(\"parscit.train\")\n        dev_filename = data_dir.joinpath(\"parscit.dev\")\n        test_filename = data_dir.joinpath(\"parscit.test\")\n        data_manager = SeqLabellingDatasetManager(\n            train_filename=train_filename,\n            dev_filename=dev_filename,\n            test_filename=test_filename,\n        )\n        return data_manager\n\n    def build_infer(self):\n        infer = SequenceLabellingInference(\n            model=self.model,\n            model_filepath=self.hparams.get(\"model_filepath\"),\n            datasets_manager=self.data_manager,\n        )\n        return infer\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    model_filepath = dirname.joinpath(\"checkpoints\", \"best_model.pt\")\n    hparams = {\n        \"emb_type\": \"parscit\",\n        \"char_emb_dim\": 25,\n        \"char_encoder_hidden_dim\": 50,\n        \"hidden_dim\": 256,\n        \"bidirectional\": True,\n        \"combine_strategy\": \"concat\",\n        \"model_filepath\": str(model_filepath),\n    }\n    parscit_inference = BuildParscitInterference(hparams)\n    cli = SciWINGInteract(parscit_inference)\n    cli.interact()\n"}
{"type": "source_file", "path": "examples/science_ie/science_ie_infer.py", "content": "import sciwing.constants as constants\nimport pathlib\nfrom sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nfrom sciwing.infer.seq_label_inference.seq_label_inference import (\n    SequenceLabellingInference,\n)\nfrom sciwing.utils.science_ie_eval import calculateMeasures\nimport torch\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\ndef build_science_ie_model(dirname: str):\n    exp_dirpath = pathlib.Path(dirname)\n    data_dir = pathlib.Path(DATA_DIR)\n    train_filename = data_dir.joinpath(\"train_science_ie_conll.txt\")\n    dev_filename = data_dir.joinpath(\"dev_science_ie_conll.txt\")\n    test_filename = data_dir.joinpath(\"dev_science_ie_conll.txt\")\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=test_filename,\n        column_names=[\"TASK\", \"PROCESS\", \"MATERIAL\"],\n    )\n\n    word_embedder = TrainableWordEmbedder(\n        embedding_type=\"glove_6B_100\", datasets_manager=data_manager\n    )\n    char_embedder = CharEmbedder(\n        char_embedding_dimension=20, hidden_dimension=25, datasets_manager=data_manager\n    )\n    embedder = ConcatEmbedders([word_embedder, char_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        hidden_dim=350,\n        bidirectional=True,\n        combine_strategy=\"concat\",\n        rnn_bias=True,\n        device=torch.device(\"cpu\"),\n        num_layers=2,\n    )\n\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=700,\n        datasets_manager=data_manager,\n        namespace_to_constraints=None,\n        tagging_type=\"BIOUL\",\n    )\n\n    infer = SequenceLabellingInference(\n        model=model,\n        model_filepath=str(exp_dirpath.joinpath(\"checkpoints\", \"best_model.pt\")),\n        datasets_manager=data_manager,\n    )\n\n    return infer\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    infer = build_science_ie_model(str(dirname))\n    # infer.run_inference()\n    # infer.report_metrics()\n    prediction_folder = pathlib.Path(\".\", \"science_ie_pred\")\n    FILES = constants.FILES\n    SCIENCE_IE_DEV_FOLDER = FILES[\"SCIENCE_IE_DEV_FOLDER\"]\n    SCIENCE_IE_DEV_FOLDER = pathlib.Path(SCIENCE_IE_DEV_FOLDER)\n    if not prediction_folder.is_dir():\n        prediction_folder.mkdir()\n\n    infer.generate_scienceie_prediction_folder(\n        dev_folder=SCIENCE_IE_DEV_FOLDER, pred_folder=prediction_folder\n    )\n\n    calculateMeasures(\n        folder_gold=str(SCIENCE_IE_DEV_FOLDER),\n        folder_pred=str(prediction_folder),\n        remove_anno=\"rel\",\n    )\n"}
{"type": "source_file", "path": "examples/science_ie/science_ie.py", "content": "from sciwing.datasets.seq_labeling.conll_dataset import CoNLLDatasetManager\nfrom sciwing.models.rnn_seq_crf_tagger import RnnSeqCrfTagger\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.modules.embedders.trainable_word_embedder import TrainableWordEmbedder\nfrom sciwing.modules.embedders.char_embedder import CharEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.metrics.token_cls_accuracy import TokenClassificationAccuracy\nimport sciwing.constants as constants\nimport torch\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport pathlib\nimport wasabi\n\nDATA_DIR = constants.PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(description=\"ScienceIE Tagger for ScienceIE task\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\"--emb_dim\", help=\"embedding dimension\", type=int)\n    parser.add_argument(\n        \"--char_emb_dim\", help=\"character embedding dimension\", type=int\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the lstm encoder\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--char_encoder_hidden_dim\",\n        help=\"Character encoder hidden dimension.\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\"--device\", help=\"Device on which the model is run\", type=str)\n\n    parser.add_argument(\"--reg\", help=\"Regularization strength\", type=float)\n    parser.add_argument(\n        \"--dropout\", help=\"Dropout added to multiple layer lstm\", type=float\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion of the dataset\", type=float\n    )\n\n    parser.add_argument(\n        \"--num_layers\", help=\"Number of layers in rnn2seq encoder\", type=int\n    )\n\n    args = parser.parse_args()\n    msg_printer = wasabi.Printer()\n\n    DATA_DIR = pathlib.Path(DATA_DIR)\n    train_filename = DATA_DIR.joinpath(\"train_science_ie_conll.txt\")\n    dev_filename = DATA_DIR.joinpath(\"dev_science_ie_conll.txt\")\n\n    data_manager = CoNLLDatasetManager(\n        train_filename=train_filename,\n        dev_filename=dev_filename,\n        test_filename=dev_filename,\n        column_names=[\"TASK\", \"PROCESS\", \"MATERIAL\"],\n    )\n\n    embedder = TrainableWordEmbedder(\n        embedding_type=args.emb_type, datasets_manager=data_manager, device=args.device\n    )\n\n    char_embedder = CharEmbedder(\n        char_embedding_dimension=args.char_emb_dim,\n        hidden_dimension=args.char_encoder_hidden_dim,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n    embedder = ConcatEmbedders([embedder, char_embedder])\n\n    lstm2seqencoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        dropout_value=args.dropout,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        rnn_bias=True,\n        device=torch.device(args.device),\n        num_layers=args.num_layers,\n        add_projection_layer=False,\n    )\n    model = RnnSeqCrfTagger(\n        rnn2seqencoder=lstm2seqencoder,\n        encoding_dim=2 * args.hidden_dim\n        if args.bidirectional and args.combine_strategy == \"concat\"\n        else args.hidden_dim,\n        device=torch.device(args.device),\n        tagging_type=\"BIOUL\",\n        datasets_manager=data_manager,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr, weight_decay=args.reg)\n\n    train_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n    dev_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n    test_metric = TokenClassificationAccuracy(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        track_for_best=\"macro_fscore\",\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/sectlabel_bow_bert/sectlabel_bow_bert.py", "content": "from sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.embedders.bert_embedder import BertEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport sciwing.constants as constants\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport pathlib\nimport argparse\nimport torch\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"Bag of words linear classifier. \"\n        \"with initial elmo word embeddings\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--device\", help=\"specify the device to run on.\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--bert_type\",\n        help=\"Specify the bert model to be used. One of bert-base-uncased, bert-base-cased, \"\n        \"bert-large-uncased, bert-large-cased can be used\",\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion for the dataset\", type=float\n    )\n\n    args = parser.parse_args()\n\n    DATA_PATH = pathlib.Path(DATA_DIR)\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    embedder = BertEmbedder(\n        dropout_value=0.0,\n        aggregation_type=\"average\",\n        bert_type=args.bert_type,\n        device=torch.device(args.device),\n    )\n\n    encoder = BOW_Encoder(\n        embedder=embedder, aggregation_type=\"average\", device=args.device\n    )\n\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=768,\n        num_classes=23,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/sectlabel_bow_random/sectlabel_bow_infer.py", "content": "import sciwing.constants as constants\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nimport pathlib\n\nPATHS = constants.PATHS\nFILES = constants.FILES\nOUTPUT_DIR = PATHS[\"OUTPUT_DIR\"]\nCONFIGS_DIR = PATHS[\"CONFIGS_DIR\"]\nSECT_LABEL_FILE = FILES[\"SECT_LABEL_FILE\"]\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\ndef build_sectlabel_bow_model(dirname: str):\n    \"\"\"\n\n    Parameters\n    ----------\n    dirname : The directory where sciwing stores your outputs for the model\n\n    Returns\n    -------\n\n\n    \"\"\"\n    exp_dirpath = pathlib.Path(dirname)\n    DATA_PATH = pathlib.Path(DATA_DIR)\n\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n    encoder = BOW_Encoder(embedder=embedder)\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=embedder.get_embedding_dimension(),\n        num_classes=data_manager.num_labels[\"label\"],\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n    )\n\n    infer = ClassificationInference(\n        model=model,\n        model_filepath=str(exp_dirpath.joinpath(\"checkpoints\", \"best_model.pt\")),\n        datasets_manager=data_manager,\n    )\n    return infer\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    infer = build_sectlabel_bow_model(str(dirname))\n    infer.run_inference()\n    infer.report_metrics()\n"}
{"type": "source_file", "path": "sciwing/api/routers/__init__.py", "content": ""}
{"type": "source_file", "path": "examples/sectlabel_bow_bert/sectlabel_bow_bert_infer.py", "content": "import json\nimport os\nimport sciwing.constants as constants\nfrom sciwing.modules.embedders.bert_embedder import BertEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\nimport torch\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\ndef build_sectlabel_bow_bert(dirname: str):\n    exp_dirpath = pathlib.Path(dirname)\n    DATA_PATH = pathlib.Path(DATA_DIR)\n\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    embedder = BertEmbedder(\n        dropout_value=0.0,\n        aggregation_type=\"average\",\n        bert_type=\"bert-base-uncased\",\n        device=torch.device(\"cpu\"),\n    )\n\n    encoder = BOW_Encoder(embedder=embedder, aggregation_type=\"average\")\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=768,\n        num_classes=23,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n    )\n\n    parsect_inference = ClassificationInference(\n        model=model,\n        model_filepath=str(exp_dirpath.joinpath(\"checkpoints\", \"best_model.pt\")),\n        datasets_manager=data_manager,\n    )\n\n    return parsect_inference\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    infer = build_sectlabel_bow_bert(str(dirname))\n    infer.run_inference()\n    infer.report_metrics()\n"}
{"type": "source_file", "path": "examples/sectlabel_bow_elmo/sectlabel_bow_elmo_infer.py", "content": "import sciwing.constants as constants\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\ndef build_sectlabel_bow_elmo_model(dirname: str):\n    exp_dirpath = pathlib.Path(dirname)\n    DATA_PATH = pathlib.Path(DATA_DIR)\n\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    embedder = BowElmoEmbedder(layer_aggregation=\"last\")\n    encoder = BOW_Encoder(aggregation_type=\"sum\", embedder=embedder)\n\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=1024,\n        num_classes=data_manager.num_labels[\"label\"],\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n    )\n\n    infer_client = ClassificationInference(\n        model=model,\n        model_filepath=str(exp_dirpath.joinpath(\"checkpoints\", \"best_model.pt\")),\n        datasets_manager=data_manager,\n    )\n\n    return infer_client\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    infer = build_sectlabel_bow_elmo_model(str(dirname))\n    infer.run_inference()\n    infer.report_metrics()\n"}
{"type": "source_file", "path": "sciwing/api/__init__.py", "content": ""}
{"type": "source_file", "path": "examples/sectlabel_bilstm/sectlabel_bilstm.py", "content": "from sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.lstm2vecencoder import LSTM2VecEncoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nimport sciwing.constants as constants\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport torch\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"LSTM encoder with linear classifier\"\n        \"with initial random word embeddings\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\n        \"--device\", help=\"Adding which device to run the experiment on\", type=str\n    )\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300, random\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the LSTM network\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion for the dataset\", type=float\n    )\n\n    args = parser.parse_args()\n\n    # saving the test dataset params\n    # lets save the test dataset params for the experiment\n\n    DATA_PATH = pathlib.Path(DATA_DIR)\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    embedder = WordEmbedder(embedding_type=args.emb_type, device=args.device)\n    encoder = LSTM2VecEncoder(\n        embedder=embedder,\n        hidden_dim=args.hidden_dim,\n        combine_strategy=args.combine_strategy,\n        bidirectional=args.bidirectional,\n        device=torch.device(args.device),\n    )\n\n    classiier_encoding_dim = (\n        2 * args.hidden_dim if args.bidirectional else args.hidden_dim\n    )\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=classiier_encoding_dim,\n        num_classes=23,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=False,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "sciwing/api/utils/__init__.py", "content": ""}
{"type": "source_file", "path": "sciwing/api/routers/i2b2.py", "content": "from fastapi import APIRouter\nfrom sciwing.models.i2b2 import I2B2NER\n\nrouter = APIRouter()\n\ni2b2_ner_model = None\n\n\n@router.get(\"/i2b2/{text}\")\ndef return_tags(text: str):\n    \"\"\" Tags the text that you send according to i2b2 model with\n    ``problem, treatment and tests``\n\n    Parameters\n    ----------\n    text: str\n        The text to be tagged\n\n    Returns\n    -------\n    JSON\n        ``{tags: Predicted tags, text_tokens: Tokens in the text }``\n\n    \"\"\"\n    global i2b2_ner_model\n    if i2b2_ner_model is None:\n        i2b2_ner_model = I2B2NER()\n\n    predictions = i2b2_ner_model.predict_for_text(text)\n    return {\"tags\": predictions, \"text_tokens\": text.split()}\n"}
{"type": "source_file", "path": "sciwing/api/routers/parscit.py", "content": "from fastapi import APIRouter\nfrom sciwing.models.neural_parscit import NeuralParscit\n\nrouter = APIRouter()\n\nparscit_model = None\n\n\n@router.get(\"/parscit/{citation}\")\ndef tag_citation_string(citation: str):\n    \"\"\" End point to tag parse a reference string to their constituent parts.\n\n    Parameters\n    ----------\n    citation: str\n        The reference string to be parsed.\n\n    Returns\n    -------\n    JSON\n        ``{\"tags\": Predicted tags, \"text_tokens\": Tokenized citation string}``\n\n    \"\"\"\n    global parscit_model\n    if parscit_model == None:\n        parscit_model = NeuralParscit()\n    predictions = parscit_model.predict_for_text(citation)\n    return {\"tags\": predictions, \"text_tokens\": citation.split()}\n"}
{"type": "source_file", "path": "examples/sectlabel_bow_elmo/sectlabel_bow_elmo.py", "content": "from sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport sciwing.constants as constants\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport pathlib\n\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"Bag of words linear classifier. \"\n        \"with initial elmo word embeddings\"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n\n    parser.add_argument(\n        \"--device\",\n        help=\"Specify the device on which models and tensors reside\",\n        type=str,\n    )\n\n    parser.add_argument(\n        \"--layer_aggregation\", help=\"Layer aggregation strategy\", type=str\n    )\n\n    parser.add_argument(\n        \"--word_aggregation\", help=\"word aggregation strategy\", type=str\n    )\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300\",\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--vocab_store_location\", help=\"File in which the vocab is stored\"\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion for debugging\", type=float\n    )\n\n    args = parser.parse_args()\n\n    DATA_PATH = pathlib.Path(DATA_DIR)\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    # BowElmoEmbedder embeds sentences using ELMO\n    embedder = BowElmoEmbedder(\n        layer_aggregation=args.layer_aggregation, device=args.device\n    )\n\n    encoder = BOW_Encoder(\n        embedder=embedder, aggregation_type=args.word_aggregation, device=args.device\n    )\n\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=1024,\n        num_classes=data_manager.num_labels[\"label\"],\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=args.device,\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/sectlabel_elmo_bilstm/sectlabel_elmo_bilstm_infer.py", "content": "import sciwing.constants as constants\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.modules.lstm2vecencoder import LSTM2VecEncoder\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\nimport torch\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\ndef build_sectlabel_elmobilstm_model(dirname: str):\n    exp_dirpath = pathlib.Path(dirname)\n    DATA_PATH = pathlib.Path(DATA_DIR)\n\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n    DEVICE = \"cpu\"\n    EMBEDDING_TYPE = \"glove_6B_50\"\n    HIDDEN_DIM = 512\n    BIDIRECTIONAL = True\n    COMBINE_STRATEGY = \"concat\"\n\n    elmo_embedder = BowElmoEmbedder(\n        cuda_device_id=-1 if DEVICE == \"cpu\" else int(DEVICE.split(\"cuda:\")[1])\n    )\n\n    vanilla_embedder = WordEmbedder(embedding_type=EMBEDDING_TYPE)\n\n    embedders = ConcatEmbedders([vanilla_embedder, elmo_embedder])\n\n    encoder = LSTM2VecEncoder(\n        embedder=embedders,\n        hidden_dim=HIDDEN_DIM,\n        bidirectional=BIDIRECTIONAL,\n        combine_strategy=COMBINE_STRATEGY,\n        device=torch.device(DEVICE),\n    )\n\n    encoding_dim = (\n        2 * HIDDEN_DIM if BIDIRECTIONAL and COMBINE_STRATEGY == \"concat\" else HIDDEN_DIM\n    )\n\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=encoding_dim,\n        num_classes=23,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n    )\n\n    inference = ClassificationInference(\n        model=model,\n        model_filepath=str(exp_dirpath.joinpath(\"checkpoints\", \"best_model.pt\")),\n        datasets_manager=data_manager,\n    )\n    return inference\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    infer = build_sectlabel_elmobilstm_model(str(dirname))\n    infer.run_inference()\n    infer.report_metrics()\n"}
{"type": "source_file", "path": "examples/sectlabel_bow_random/sectlabel_bow.py", "content": "from sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nimport sciwing.constants as constants\nfrom sciwing.modules.bow_encoder import BOW_Encoder\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport pathlib\nimport torch\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n\n    parser = argparse.ArgumentParser(\n        description=\"Bag of words linear classifier. \"\n        \"with initial random word embeddings\"\n    )\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--emb_type\", help=\"embedding type\", type=str)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--vocab_store_location\", help=\"File in which the vocab is stored\"\n    )\n    parser.add_argument(\"--device\", help=\"Device to run the models on\")\n\n    args = parser.parse_args()\n\n    DATA_PATH = pathlib.Path(DATA_DIR)\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    embedder = WordEmbedder(embedding_type=args.emb_type, device=args.device)\n\n    # initialize a bag of word emcoder\n    encoder = BOW_Encoder(embedder=embedder, device=args.device)\n\n    # Instantiate a simple classifier\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=embedder.get_embedding_dimension(),\n        classification_layer_bias=True,\n        num_classes=data_manager.num_labels[\"label\"],\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    # you get to use any optimizer from Pytorch\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n\n    # Instantiate the PrecisionRecallFMeasure\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    # Get the engine worked up\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        log_train_metrics_every=args.log_train_metrics_every,\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n        sample_proportion=0.01,\n        device=args.device,\n    )\n\n    # Run the engine\n    engine.run()\n"}
{"type": "source_file", "path": "sciwing/api/routers/citation_intent_clf.py", "content": "from fastapi import APIRouter\nfrom sciwing.models.citation_intent_clf import CitationIntentClassification\n\nrouter = APIRouter()\n\ncitation_intent_clf_model = None\n\n\n@router.get(\"/cit_int_clf/{citation}\")\ndef classify_citation_intent(citation: str):\n    \"\"\" End point to classify a citation intent into ```Background`, `Method`, `Result Comparison```\n\n    Parameters\n    ----------\n    citation : str\n        String containing the citation to another work\n\n    Returns\n    -------\n    JSON\n        ``{\"tags\": Predicted tag for the citation, \"citation\": the citation itself}``\n    \"\"\"\n    global citation_intent_clf_model\n    if citation_intent_clf_model is None:\n        citation_intent_clf_model = CitationIntentClassification()\n    predictions = citation_intent_clf_model.predict_for_text(citation)\n    return {\"tags\": predictions, \"citation\": citation}\n"}
{"type": "source_file", "path": "examples/summarization_abstractive/pubmed_summarization_bilstm_seq2seq.py", "content": "from sciwing.datasets.summarization.abstractive_text_summarization_dataset import (\n    AbstractiveSummarizationDatasetManager,\n)\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.lstm2seqencoder import Lstm2SeqEncoder\nfrom sciwing.modules.lstm2seqdecoder import Lstm2SeqDecoder\nfrom sciwing.models.simple_seq2seq import Seq2SeqModel\nimport pathlib\nfrom sciwing.metrics.summarization_metrics import SummarizationMetrics\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport torch\nimport sciwing.constants as constants\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(description=\"Glove with LSTM encoder and decoder\")\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n\n    parser.add_argument(\n        \"--device\", help=\"Specify the device where the model is run\", type=str\n    )\n\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300, random\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the LSTM network\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\n        \"--pred_max_length\", help=\"Maximum length of prediction\", type=int\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion for the dataset\", type=float\n    )\n\n    args = parser.parse_args()\n\n    DATA_PATH = pathlib.Path(DATA_DIR)\n    train_file = DATA_PATH.joinpath(\"pubmedSeq2seq.train\")\n    dev_file = DATA_PATH.joinpath(\"pubmedSeq2seq.dev\")\n    test_file = DATA_PATH.joinpath(\"pubmedSeq2seq.test\")\n\n    data_manager = AbstractiveSummarizationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    vocab = data_manager.build_vocab()[\"tokens\"]\n\n    # # instantiate the elmo embedder\n    # elmo_embedder = BowElmoEmbedder(layer_aggregation=\"sum\", device=args.device)\n    #\n    # # instantiate the vanilla embedder\n    # vanilla_embedder = WordEmbedder(embedding_type=args.emb_type, device=args.device)\n    #\n    # # concat the embeddings\n    # embedder = ConcatEmbedders([vanilla_embedder, elmo_embedder])\n\n    embedder = WordEmbedder(embedding_type=args.emb_type, device=args.device)\n\n    encoder = Lstm2SeqEncoder(\n        embedder=embedder,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        device=torch.device(args.device),\n    )\n\n    encoding_dim = (\n        2 * args.hidden_dim\n        if args.bidirectional and args.combine_strategy == \"concat\"\n        else args.hidden_dim\n    )\n\n    decoder = Lstm2SeqDecoder(\n        embedder=embedder,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        device=torch.device(args.device),\n        max_length=args.pred_max_length,\n        vocab=vocab,\n    )\n\n    model = Seq2SeqModel(\n        rnn2seqencoder=encoder,\n        rnn2seqdecoder=decoder,\n        enc_hidden_dim=args.hidden_dim,\n        datasets_manager=data_manager,\n        device=args.device,\n        bidirectional=args.bidirectional,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = SummarizationMetrics(datasets_manager=data_manager)\n    dev_metric = SummarizationMetrics(datasets_manager=data_manager)\n    test_metric = SummarizationMetrics(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"rouge_1\",\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "examples/sectlabel_bilstm/sectlabel_bilstm_infer.py", "content": "import os\nimport sciwing.constants as constants\nfrom sciwing.modules.lstm2vecencoder import LSTM2VecEncoder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nfrom sciwing.infer.classification.classification_inference import (\n    ClassificationInference,\n)\nfrom sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nimport pathlib\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\ndef build_sectlabel_bilstm_model(dirname: str):\n    exp_dirpath = pathlib.Path(dirname)\n    DATA_PATH = pathlib.Path(DATA_DIR)\n\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    HIDDEN_DIM = 512\n    BIDIRECTIONAL = True\n    COMBINE_STRATEGY = \"concat\"\n\n    classifier_encoding_dim = 2 * HIDDEN_DIM if BIDIRECTIONAL else HIDDEN_DIM\n\n    embedder = WordEmbedder(embedding_type=\"glove_6B_50\")\n\n    encoder = LSTM2VecEncoder(\n        embedder=embedder,\n        hidden_dim=HIDDEN_DIM,\n        combine_strategy=COMBINE_STRATEGY,\n        bidirectional=BIDIRECTIONAL,\n    )\n\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=classifier_encoding_dim,\n        num_classes=23,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n    )\n\n    inference = ClassificationInference(\n        model=model,\n        model_filepath=str(exp_dirpath.joinpath(\"checkpoints\", \"best_model.pt\")),\n        datasets_manager=data_manager,\n    )\n\n    return inference\n\n\nif __name__ == \"__main__\":\n    dirname = pathlib.Path(\".\", \"output\")\n    infer = build_sectlabel_bilstm_model(str(dirname))\n    infer.run_inference()\n    infer.report_metrics()\n"}
{"type": "source_file", "path": "sciwing/app/__init__.py", "content": ""}
{"type": "source_file", "path": "sciwing/api/conf.py", "content": "import pathlib\nimport sciwing.constants as constants\nimport os\n\nCURRENT_DIR = os.path.dirname(os.path.realpath(__file__))\nPATHS = constants.PATHS\nOUTPUT_DIR = PATHS[\"OUTPUT_DIR\"]\n\nPDF_STORE_LOCATION = pathlib.Path(\"/tmp/sciwing_pdf_cache\")\nBIN_FOLDER = pathlib.Path(CURRENT_DIR, \"bin\")\n"}
{"type": "source_file", "path": "sciwing/api/utils/pdf_store.py", "content": "import pathlib\n\n\nclass PdfStore:\n    def __init__(self, store_path: pathlib.Path):\n        \"\"\"Manages the storage, retrieval and deletion of pdf files. This is useful\n        when we have to manipulate pdf files and delete them eventually.\n\n        Parameters\n        ----------\n        store_path : pathlib.Path\n            The store path is where all the pdfs will be stored and deleted from\n        \"\"\"\n        self.store_path = store_path\n\n    def save_pdf_binary_string(\n        self, pdf_string: bytes, out_filename: str\n    ) -> pathlib.Path:\n        \"\"\" Save the binary string to the store using the out_filename\n\n        Parameters\n        ----------\n        pdf_string : str\n            String representing a pdf in binary format\n\n        out_filename: str\n            The name of the pdf file that will stored\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        pdf_filename = self.store_path.joinpath(out_filename)\n        with open(pdf_filename, \"wb\") as fp:\n            fp.write(pdf_string)\n\n        return pdf_filename\n\n    def retrieve_binary_string_from_store(self, filename: str):\n        \"\"\" Retrieve the contents of the pdf file as binary from the store\n\n        Parameters\n        ----------\n        filename : str\n            Filename from which the file should be read\n\n        Returns\n        -------\n        bytes\n            A binary string of the filename\n        \"\"\"\n        filepath = self.store_path.joinpath(filename)\n\n        if not filepath.is_file():\n            raise ValueError(\n                f\"Filename {filename} you requested is not present in the store\"\n            )\n\n        with open(filepath, \"rb\") as fp:\n            string = fp.read()\n\n        return string\n\n    def delete_file(self, filename: str):\n        \"\"\" Deletes the files from the store\n\n        Parameters\n        ----------\n        filename : str\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        filepath = self.store_path.joinpath(filename)\n\n        if not filepath.is_file():\n            raise ValueError(f\"File name {filepath.name} does not exist in the store\")\n\n        filepath.unlink()\n"}
{"type": "source_file", "path": "examples/sectlabel_elmo_bilstm/sectlabel_elmo_bilstm.py", "content": "from sciwing.datasets.classification.text_classification_dataset import (\n    TextClassificationDatasetManager,\n)\nfrom sciwing.modules.embedders.bow_elmo_embedder import BowElmoEmbedder\nfrom sciwing.modules.embedders.word_embedder import WordEmbedder\nfrom sciwing.modules.embedders.concat_embedders import ConcatEmbedders\nfrom sciwing.modules.lstm2vecencoder import LSTM2VecEncoder\nfrom sciwing.models.simpleclassifier import SimpleClassifier\nimport pathlib\nfrom sciwing.metrics.precision_recall_fmeasure import PrecisionRecallFMeasure\nimport torch.optim as optim\nfrom sciwing.engine.engine import Engine\nimport argparse\nimport torch\nimport sciwing.constants as constants\n\nPATHS = constants.PATHS\nDATA_DIR = PATHS[\"DATA_DIR\"]\n\n\nif __name__ == \"__main__\":\n    # read the hyperparams from config file\n    parser = argparse.ArgumentParser(\n        description=\"Elmo with LSTM encoder followed by linear classifier \"\n    )\n\n    parser.add_argument(\"--exp_name\", help=\"Specify an experiment name\", type=str)\n\n    parser.add_argument(\n        \"--device\", help=\"Specify the device where the model is run\", type=str\n    )\n\n    parser.add_argument(\"--bs\", help=\"batch size\", type=int)\n    parser.add_argument(\"--lr\", help=\"learning rate\", type=float)\n    parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int)\n    parser.add_argument(\n        \"--save_every\", help=\"Save the model every few epochs\", type=int\n    )\n    parser.add_argument(\n        \"--log_train_metrics_every\",\n        help=\"Log training metrics every few iterations\",\n        type=int,\n    )\n    parser.add_argument(\n        \"--emb_type\",\n        help=\"The type of glove embedding you want. The allowed types are glove_6B_50, glove_6B_100, \"\n        \"glove_6B_200, glove_6B_300, random\",\n    )\n    parser.add_argument(\n        \"--hidden_dim\", help=\"Hidden dimension of the LSTM network\", type=int\n    )\n    parser.add_argument(\n        \"--bidirectional\",\n        help=\"Specify Whether the lstm is bidirectional or uni-directional\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"--combine_strategy\",\n        help=\"How do you want to combine the hidden dimensions of the two \"\n        \"combinations\",\n    )\n\n    parser.add_argument(\n        \"--exp_dir_path\", help=\"Directory to store all experiment related information\"\n    )\n    parser.add_argument(\n        \"--model_save_dir\",\n        help=\"Directory where the checkpoints during model training are stored.\",\n    )\n    parser.add_argument(\n        \"--sample_proportion\", help=\"Sample proportion for the dataset\", type=float\n    )\n\n    args = parser.parse_args()\n\n    DATA_PATH = pathlib.Path(DATA_DIR)\n    train_file = DATA_PATH.joinpath(\"sectLabel.train\")\n    dev_file = DATA_PATH.joinpath(\"sectLabel.dev\")\n    test_file = DATA_PATH.joinpath(\"sectLabel.test\")\n\n    data_manager = TextClassificationDatasetManager(\n        train_filename=str(train_file),\n        dev_filename=str(dev_file),\n        test_filename=str(test_file),\n    )\n\n    # instantiate the elmo embedder\n    elmo_embedder = BowElmoEmbedder(layer_aggregation=\"sum\", device=args.device)\n\n    # instantiate the vanilla embedder\n    vanilla_embedder = WordEmbedder(embedding_type=args.emb_type, device=args.device)\n\n    # concat the embeddings\n    embedder = ConcatEmbedders([vanilla_embedder, elmo_embedder])\n\n    encoder = LSTM2VecEncoder(\n        embedder=embedder,\n        hidden_dim=args.hidden_dim,\n        bidirectional=args.bidirectional,\n        combine_strategy=args.combine_strategy,\n        device=torch.device(args.device),\n    )\n\n    encoding_dim = (\n        2 * args.hidden_dim\n        if args.bidirectional and args.combine_strategy == \"concat\"\n        else args.hidden_dim\n    )\n\n    model = SimpleClassifier(\n        encoder=encoder,\n        encoding_dim=encoding_dim,\n        num_classes=23,\n        classification_layer_bias=True,\n        datasets_manager=data_manager,\n        device=args.device,\n    )\n\n    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n    train_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    dev_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n    test_metric = PrecisionRecallFMeasure(datasets_manager=data_manager)\n\n    engine = Engine(\n        model=model,\n        datasets_manager=data_manager,\n        optimizer=optimizer,\n        batch_size=args.bs,\n        save_dir=args.model_save_dir,\n        num_epochs=args.epochs,\n        save_every=args.save_every,\n        train_metric=train_metric,\n        validation_metric=dev_metric,\n        test_metric=test_metric,\n        log_train_metrics_every=args.log_train_metrics_every,\n        device=torch.device(args.device),\n        use_wandb=True,\n        experiment_name=args.exp_name,\n        experiment_hyperparams=vars(args),\n        track_for_best=\"macro_fscore\",\n        sample_proportion=args.sample_proportion,\n    )\n\n    engine.run()\n"}
{"type": "source_file", "path": "sciwing/api/api.py", "content": "import sciwing.api.conf as config\nfrom fastapi import FastAPI\nfrom sciwing.api.routers import parscit\nfrom sciwing.api.routers import citation_intent_clf\nfrom sciwing.api.routers import sectlabel\nfrom sciwing.api.routers import i2b2\nfrom sciwing.api.routers import pdf_pipeline\n\napp = FastAPI()\n\n\n@app.get(\"/\")\ndef root():\n    return {\"message\": \"Welcome To SciWING API\"}\n\n\n# add the routers to the main app\napp.include_router(parscit.router)\napp.include_router(citation_intent_clf.router)\napp.include_router(sectlabel.router)\napp.include_router(i2b2.router)\napp.include_router(pdf_pipeline.router)\n"}
{"type": "source_file", "path": "sciwing/api/routers/pdf_pipeline.py", "content": "from fastapi import APIRouter, UploadFile, File\nfrom sciwing.pipelines.pipeline import pipeline\nimport sciwing.api.conf as config\nfrom sciwing.api.utils.pdf_store import PdfStore\nfrom sciwing.api.utils.pdf_reader import PdfReader\n\n\nPDF_CACHE_DIR = config.PDF_STORE_LOCATION\nBIN_FOLDER = config.BIN_FOLDER\n\nif not PDF_CACHE_DIR.is_dir():\n    PDF_CACHE_DIR.mkdir()\n\n\nrouter = APIRouter()\npdf_store = PdfStore(PDF_CACHE_DIR)\nPDF_BOX_JAR = BIN_FOLDER.joinpath(\"pdfbox-app-2.0.16.jar\")\nprocessing_pipeline = None\n\n\n@router.post(\"/pdf_pipeline/uploadfile\")\ndef pdf_pipeline(file: UploadFile = File(None)):\n    \"\"\" Parses the file and returns various analytics about the pdf\n\n    Parameters\n    ----------\n    file: File\n        A File stream\n\n    Returns\n    -------\n    JSON\n        Returns a JSON where the key can be a section in the document with value as the text of the document.\n        It can also be other information such as parsed reference strings in the document, or normalised\n        section headers of the document. This is a feature in development. Be careful in using this.\n    \"\"\"\n    file_handle = file.file\n    file_name = file.filename\n    file_contents = file_handle.read()\n    global processing_pipeline\n\n    pdf_save_location = pdf_store.save_pdf_binary_string(\n        pdf_string=file_contents, out_filename=file_name\n    )\n\n    if not processing_pipeline:\n        processing_pipeline = pipeline(\"pdf_pipeline\")\n\n    ents = processing_pipeline(pdf_save_location)\n    response = {}\n    for name, ent in ents[\"ents\"].items():\n        response[name] = ent\n    return response\n"}
{"type": "source_file", "path": "sciwing/api/utils/pdf_reader.py", "content": "import pathlib\nimport sciwing.api.conf as config\nimport subprocess\n\nBIN_FOLDER = config.BIN_FOLDER\nPDF_BOX_JAR = BIN_FOLDER.joinpath(\"pdfbox-app-2.0.16.jar\")\n\n\nclass PdfReader:\n    def __init__(self, filepath: pathlib.Path):\n        \"\"\" Reads the pdf file, performs cleaning and transformations\n\n        Parameters\n        ----------\n        filepath : pathlib.Path\n            The path to read the pdf file\n        \"\"\"\n        self.filepath = filepath\n        self.pdf_box_jar = PDF_BOX_JAR\n\n    def read_pdf(self):\n        text = subprocess.run(\n            [\"java\", \"-jar\", PDF_BOX_JAR, \"ExtractText\", \"-console\", self.filepath],\n            stdout=subprocess.PIPE,\n        )\n        text = text.stdout\n        text = text.decode(\"utf-8\")\n        text = text.split(\"\\n\")\n        return text\n"}
{"type": "source_file", "path": "sciwing/api/routers/sectlabel.py", "content": "from fastapi import APIRouter, UploadFile, File\nfrom sciwing.models.sectlabel import SectLabel\nfrom sciwing.api.utils.pdf_store import PdfStore\nfrom sciwing.api.utils.pdf_reader import PdfReader\nfrom sciwing.utils.common import chunks\nimport itertools\nimport sciwing.api.conf as config\n\nPDF_CACHE_DIR = config.PDF_STORE_LOCATION\nBIN_FOLDER = config.BIN_FOLDER\n\nif not PDF_CACHE_DIR.is_dir():\n    PDF_CACHE_DIR.mkdir(parents=True)\n\nrouter = APIRouter()\n\nsectlabel_model = None\npdf_store = PdfStore(PDF_CACHE_DIR)\nPDF_BOX_JAR = BIN_FOLDER.joinpath(\"pdfbox-app-2.0.16.jar\")\n\n\n@router.post(\"/sectlabel/uploadfile/\")\ndef process_pdf(file: UploadFile = File(None)):\n    \"\"\" Classifies every line in the document to the logical section of the document. The logical\n    section can be title, author, email, section header, subsection header etc\n\n    Parameters\n    ----------\n    file : File\n        The Bytestream of a file to be uploaded\n\n    Returns\n    -------\n    JSON\n        ``{\"labels\": [(line, label)]}``\n\n    \"\"\"\n    global sectlabel_model\n    if sectlabel_model is None:\n        sectlabel_model = SectLabel()\n\n    file_handle = file.file\n    file_name = file.filename\n    file_contents = file_handle.read()\n\n    pdf_save_location = pdf_store.save_pdf_binary_string(\n        pdf_string=file_contents, out_filename=file_name\n    )\n\n    # noinspection PyTypeChecker\n    pdf_reader = PdfReader(filepath=pdf_save_location)\n\n    # read pdf lines\n    lines = pdf_reader.read_pdf()\n    all_labels = []\n    all_lines = []\n\n    for batch_lines in chunks(lines, 64):\n        labels = sectlabel_model.predict_for_text_batch(texts=batch_lines)\n        all_labels.append(labels)\n        all_lines.append(batch_lines)\n\n    all_lines = itertools.chain.from_iterable(all_lines)\n    all_lines = list(all_lines)\n\n    all_labels = itertools.chain.from_iterable(all_labels)\n    all_labels = list(all_labels)\n\n    response_tuples = []\n    for line, label in zip(all_lines, all_labels):\n        response_tuples.append((line, label))\n\n    # remove the saved pdf\n    pdf_store.delete_file(str(pdf_save_location))\n\n    return {\"labels\": response_tuples}\n\n\n@router.post(\"/sectlabel/abstract/\")\ndef extract_pdf(file: UploadFile = File(None)):\n    \"\"\" Extracts the abstract from a scholarly article\n\n    Parameters\n    ----------\n    file : uploadFile\n        Byte Stream of a file uploaded.\n\n    Returns\n    -------\n    JSON\n        ``{\"abstract\": The abstract found in the scholarly document}``\n\n    \"\"\"\n\n    global sectlabel_model\n    if sectlabel_model is None:\n        sectlabel_model = SectLabel()\n\n    file_handle = file.file\n    file_name = file.filename\n    file_contents = file_handle.read()\n\n    pdf_save_location = pdf_store.save_pdf_binary_string(\n        pdf_string=file_contents, out_filename=file_name\n    )\n\n    print(f\"pdf save location {pdf_save_location}\")\n\n    # noinspection PyTypeChecker\n    pdf_reader = PdfReader(filepath=pdf_save_location)\n\n    # read pdf lines\n    lines = pdf_reader.read_pdf()\n    all_labels = []\n    all_lines = []\n\n    for batch_lines in chunks(lines, 64):\n        labels = sectlabel_model.predict_for_text_batch(texts=batch_lines)\n        all_labels.append(labels)\n        all_lines.append(batch_lines)\n\n    all_lines = itertools.chain.from_iterable(all_lines)\n    all_lines = list(all_lines)\n\n    all_labels = itertools.chain.from_iterable(all_labels)\n    all_labels = list(all_labels)\n\n    response_tuples = []\n    for line, label in zip(all_lines, all_labels):\n        response_tuples.append((line, label))\n\n    abstract_lines = []\n    found_abstract = False\n    for line, label in response_tuples:\n        if label == \"sectionHeader\" and line.strip().lower() == \"abstract\":\n            found_abstract = True\n            continue\n        if found_abstract and label == \"sectionHeader\":\n            break\n        if found_abstract:\n            abstract_lines.append(line.strip())\n\n    abstract = \" \".join(abstract_lines)\n\n    # remove the saved pdf\n    pdf_store.delete_file(str(pdf_save_location))\n\n    return {\"abstract\": abstract}\n"}
{"type": "source_file", "path": "sciwing/__init__.py", "content": "\"\"\"SciWING - A scientific Document Processing Toolkit from WING-NUS\n\"\"\"\n\n__version__ = \"0.0.1\"\n"}
{"type": "source_file", "path": "sciwing/app/all_apps.py", "content": "import streamlit as st\nimport os\nimport sys\nimport importlib.util\nimport pathlib\n\n\nif __name__ == \"__main__\":\n    # Parse command-line arguments.\n    folder = pathlib.Path(\".\").absolute()\n\n    # Get filenames for all files in this path, excluding this script.\n\n    this_file = os.path.abspath(__file__)\n    fnames = []\n\n    for basename in folder.iterdir():\n        fname = folder.joinpath(basename)\n        if (\n            fname.suffix == \".py\"\n            and \"__init__.py\" not in str(fname)\n            and fname.stem != \"all_apps\"\n            and fname.stem != \"pipeline_demo\"\n        ):\n            fnames.append(fname)\n    fnames = sorted(fnames)\n    # Make a UI to run different files.\n    fnames_options_mapping = {\n        \"citation_intent_demo\": \"Citation Intent Classification\",\n        \"scientific_articles_abstract\": \"Scientific Articles Abstract\",\n        \"ner_demo\": \"Named Entity Recognition\",\n    }\n\n    st.sidebar.image(\n        \"https://parsect-models.s3-ap-southeast-1.amazonaws.com/sciwing.png\", width=250\n    )\n    st.sidebar.header(\"A Scientific Document Processing Toolkit.\")\n\n    st.sidebar.subheader(\"Applications\")\n\n    fname_to_run = st.sidebar.radio(\n        \"Select An application\",\n        fnames,\n        format_func=lambda fname: fnames_options_mapping[fname.stem],\n    )\n    st.sidebar.markdown(\"---\")\n\n    # Create module from filepath and put in sys.modules, so Streamlit knows\n    # to watch it for changes.\n\n    fake_module_count = 0\n\n    def load_module(filepath):\n        global fake_module_count\n\n        modulename = \"_dont_care_%s\" % fake_module_count\n        spec = importlib.util.spec_from_file_location(modulename, filepath)\n        module = importlib.util.module_from_spec(spec)\n        sys.modules[modulename] = module\n\n        fake_module_count += 1\n\n    # Run the selected file.\n    with open(fname_to_run) as f:\n        load_module(fname_to_run)\n        filebody = f.read()\n\n    exec(filebody, {})\n\n    st.sidebar.subheader(\"Contributions\")\n    st.sidebar.info(\n        \"We are open to contributions and suggestions. The project is available on \"\n        \"[Github](https://github.com/abhinavkashyap/sciwing). Feel free to **contribute** by \"\n        \"submitting a pull request or raising a feature request.\"\n    )\n    st.sidebar.subheader(\"About\")\n    st.sidebar.info(\n        \"This app is maintained by **WING-NUS** at the *National University of Singapore.* \"\n        \"You can find more information about the app at [https://www.sciwing.io](https://www.sciwing.io)\"\n    )\n"}
{"type": "source_file", "path": "sciwing/app/citation_intent_demo.py", "content": "import streamlit as st\nimport requests\n\nst.title(\"Citation Intent Classification\")\n\nst.markdown(\n    \"Identify the intent behind citing another scholarly document helps \"\n    \"in fine-grain analysis of documents. Some citations refer to the \"\n    \"methodology in another document, some citations may refer to other works\"\n    \"for background knowledge and some might compare and contrast their methods with another work. \"\n    \"Citation Intent Classification models classify such intents.\"\n)\nst.markdown(\n    \"**MODEL DESCRIPTION: ** This model is similar to [Arman Cohan et al](https://arxiv.org/pdf/1904.01608.pdf). We do not perform multi-task learning, but include \"\n    \"ELMo Embeddings in the model.\"\n)\n\nst.markdown(\"---\")\n\nst.write(\"**The Labels can be one of: **\")\nst.write(\n    \"\"\"<span style=\"display:inline-block; border: 1px solid #0077B6; border-radius: 5px; padding: 5px; background-color: #0077B6; color: white; margin: 5px;\">\n        RESULT\n    </span>\n    <span style=\"display:inline-block; border: 1px solid #0077B6; border-radius: 5px; padding: 5px; background-color: #0077B6; color: white; margin: 5px;\">\n        BACKGROUND\n    </span>\n    <span style=\"display:inline-block; border: 1px solid #0077B6; border-radius: 5px; padding: 5px; background-color: #0077B6; color: white; margin: 5px;\">\n        METHOD\n    </span>\n    \"\"\",\n    unsafe_allow_html=True,\n)\n\ntext_selected = st.selectbox(\n    label=\"Select a Citation\",\n    options=[\n        \"These results are in contrast with the findings of Santos et al.(16), who reported a significant association between low sedentary time and healthy CVF among Portuguese\",\n        \"In order to improve ABM interventions and optimize symptom change, there has been a recent push to better understand the active ingredients and mechanisms that underlie post-ABM changes in symptoms (Beard 2011; Enock et al. 2014; Mogoae et al. 2014).\",\n    ],\n)\nuser_text = st.text_input(label=\"Enter a citation\", value=text_selected)\nparse_button_clicked = st.button(\"Classify Citation\")\n\nif parse_button_clicked:\n    text_selected = user_text\n\nHTML_WRAPPER = \"\"\"<div style=\"overflow-x: auto; border: 1px solid #e6e9ef; border-radius: 0.25rem; padding: 1rem; margin-bottom: 2.5rem\">{}</div>\"\"\"\n\nwith st.spinner(\"Please wait... Classifying the Citation Intent\"):\n    response = requests.get(f\"http://localhost:8000/cit_int_clf/{text_selected}\")\njson = response.json()\ntag = json[\"tags\"]\ncitation = json[\"citation\"]\noutput_string = f\"\"\"<em>{citation}</em> &#8594;\n<span style=\"display:inline-block; border: 1px solid #0077B6; border-radius: 5px; padding: 5px; background-color: #0077B6; color: white; margin: 5px;\">\n    Cites \n    <strong>{tag.upper()}</strong>\n</span>\"\"\"\nst.write(HTML_WRAPPER.format(output_string), unsafe_allow_html=True)\n"}
