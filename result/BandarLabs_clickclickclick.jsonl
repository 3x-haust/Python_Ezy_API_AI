{"repo_info": {"repo_name": "clickclickclick", "repo_owner": "BandarLabs", "repo_url": "https://github.com/BandarLabs/clickclickclick"}}
{"type": "source_file", "path": "api.py", "content": "from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom clickclickclick.planner.task import execute_with_timeout, execute_task\nfrom clickclickclick.executor.osx import MacExecutor\nfrom clickclickclick.executor.android import AndroidExecutor\nfrom clickclickclick.planner.gemini import GeminiPlanner\nfrom clickclickclick.finder.gemini import GeminiFinder\nfrom clickclickclick.planner.openai import ChatGPTPlanner\nfrom clickclickclick.finder.local_ollama import OllamaFinder\nfrom clickclickclick.finder.openai import OpenAIFinder\nfrom clickclickclick.planner.local_ollama import OllamaPlanner\nfrom clickclickclick.config import get_config\nimport uvicorn\n\n\napp = FastAPI()\n\n\nclass TaskRequest(BaseModel):\n    task_prompt: str\n    platform: str = \"android\"\n    planner_model: str = \"openai\"\n    finder_model: str = \"gemini\"\n\n\n@app.post(\"/execute\")\ndef execute_task_api(request: TaskRequest):\n    task_prompt = request.task_prompt\n    platform = request.platform\n    planner_model = request.planner_model\n    finder_model = request.finder_model\n\n    c = get_config(platform, planner_model, finder_model)\n\n    if platform == \"osx\":\n        executor = MacExecutor()\n    elif platform == \"android\":\n        executor = AndroidExecutor()\n    else:\n        raise HTTPException(status_code=400, detail=f\"Unsupported platform: {platform}\")\n\n    if planner_model == \"openai\":\n        executor.screenshot_as_base64 = True\n        planner = ChatGPTPlanner(c)\n    elif planner_model == \"gemini\":\n        executor.screenshot_as_tempfile = True\n        planner = GeminiPlanner(c)\n    elif planner_model == \"ollama\":\n        executor.screenshot_as_tempfile = True\n        planner = OllamaPlanner(c, executor)\n    else:\n        raise HTTPException(status_code=400, detail=f\"Unsupported planner model: {planner_model}\")\n\n    if finder_model == \"openai\":\n        finder = OpenAIFinder(c, executor)\n    elif finder_model == \"gemini\":\n        finder = GeminiFinder(c, executor)\n    elif finder_model == \"ollama\":\n        finder = OllamaFinder(\"llama3.2-vision\", executor)\n    else:\n        raise HTTPException(status_code=400, detail=f\"Unsupported finder model: {finder_model}\")\n\n    result = execute_with_timeout(\n        execute_task, c.TASK_TIMEOUT_IN_SECONDS, task_prompt, executor, planner, finder, c\n    )\n\n    if result is not None:\n        return {\"result\": result}\n    else:\n        raise HTTPException(status_code=500, detail=\"Task execution failed\")\n\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"}
{"type": "source_file", "path": "clickclickclick/__init__.py", "content": ""}
{"type": "source_file", "path": "clickclickclick/executor/__init__.py", "content": "from abc import ABC, abstractmethod\nfrom typing import List\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass Executor(ABC):\n\n    @abstractmethod\n    def move_mouse(self, x: int, y: int, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def press_key(self, key: List[str], observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def type_text(self, text: str, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def click_mouse(self, observation: str, button: str) -> bool:\n        pass\n\n    @abstractmethod\n    def double_click_mouse(self, button: str, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def scroll(self, clicks: int, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def swipe_right(self, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def swipe_left(self, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def swipe_up(self, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def swipe_down(self, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def volume_up(self, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def volume_down(self, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def navigate_back(self, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def minimize_app(self, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def screenshot(self, observation: str) -> str:\n        pass\n\n    @abstractmethod\n    def click_at_a_point(self, x: int, y: int, observation: str) -> bool:\n        pass\n\n    @abstractmethod\n    def long_press_at_a_point(self, x: int, y: int, observation: str) -> bool:\n        pass\n"}
{"type": "source_file", "path": "clickclickclick/config/__init__.py", "content": "# TODO: make a config  module\nimport logging\nimport logging.config\nfrom .conf_types import BaseConfig, ProductionConfig, DevelopmentConfig, TestingConfig\n\nlog_file_path = \"clickclickclick.log\"\nlog_level = \"DEBUG\"\n\nlogging_config = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"formatters\": {\n        \"standard\": {\"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"},\n    },\n    \"handlers\": {\n        \"console\": {\n            \"level\": log_level,\n            \"class\": \"logging.StreamHandler\",\n            \"formatter\": \"standard\",\n        },\n        \"file\": {\n            \"level\": log_level,\n            \"class\": \"logging.FileHandler\",\n            \"formatter\": \"standard\",\n            \"filename\": log_file_path,\n        },\n    },\n    \"loggers\": {\n        \"clickclickclick.finder\": {\n            \"handlers\": [\"console\", \"file\"],\n            \"level\": log_level,\n            \"propagate\": True,\n        },\n        \"clickclickclick.executor\": {\n            \"handlers\": [\"console\", \"file\"],\n            \"level\": log_level,\n            \"propagate\": True,\n        },\n        \"clickclickclick.planner\": {\n            \"handlers\": [\"console\", \"file\"],\n            \"level\": log_level,\n            \"propagate\": True,\n        },\n    },\n}\n\nlogging.config.dictConfig(logging_config)\n\n\ndef get_config(platform, planner_model, finder_model):\n    c = BaseConfig()\n    prompts_config = c.get_prompts(platform, planner_model, finder_model)\n    planner_model_config = c.get_config_for_platform(planner_model, \"planner\", platform)\n    finder_model_config = c.get_config_for_platform(finder_model, \"finder\", platform)\n    c.prompts = prompts_config\n    c.function_declarations = c.get_function_declarations(platform)\n\n    c.models = {\n        \"planner_config\": planner_model_config,\n        \"finder_config\": finder_model_config,\n    }\n    return c\n"}
{"type": "source_file", "path": "clickclickclick/finder/openai.py", "content": "import openai\nfrom . import BaseFinder, FinderResponseLLM\nfrom clickclickclick.config import BaseConfig\nfrom clickclickclick.executor import Executor\nfrom tempfile import NamedTemporaryFile\n\n\nclass OpenAIFinder(BaseFinder):\n\n    def __init__(self, c: BaseConfig, executor: Executor):\n        prompts = c.prompts\n        system_prompt = prompts[\"finder-system-prompt\"]\n        finder_config = c.models.get(\"finder_config\")\n        self.gemini_finder_prompt = c.gemini_finder_prompt\n        self.IMAGE_WIDTH = finder_config.get(\"image_width\")\n        self.IMAGE_HEIGHT = finder_config.get(\"image_height\")\n        self.OUTPUT_WIDTH = finder_config.get(\"output_width\")\n        self.OUTPUT_HEIGHT = finder_config.get(\"output_height\")\n        api_key = finder_config.get(\"api_key\")\n        model_name = finder_config.get(\"model_name\")\n        generation_config = finder_config.get(\"generation_config\")\n        super().__init__(api_key, model_name, generation_config, system_prompt, executor)\n        openai.api_key = api_key\n        openai.azure_endpoint = finder_config.get(\"azure_endpoint\")\n        openai.api_type = finder_config.get(\"api_type\")\n        openai.api_version = finder_config.get(\"api_version\")\n        base_url = finder_config.get(\"base_url\")\n        if base_url:\n            openai.base_url = base_url\n\n    def process_segment(self, segment, model_name, prompt):\n        segment_image, coordinates = segment\n\n        with NamedTemporaryFile(delete=False, suffix=\".png\") as temp_file:\n            segment_image.save(temp_file, format=\"PNG\")\n            temp_file_path = temp_file.name\n\n        encoded_image = self.encode_image_to_base64(temp_file_path)\n\n        response = openai.beta.chat.completions.parse(\n            model=model_name,\n            messages=[\n                {\"role\": \"system\", \"content\": self.system_prompt},\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"detail\": \"low\",\n                                \"url\": f\"data:image/png;base64,{encoded_image}\",\n                            },\n                        },\n                        {\"type\": \"text\", \"text\": self.gemini_finder_prompt(prompt)},\n                    ],\n                },\n            ],\n            response_format=FinderResponseLLM,\n        )\n        try:\n            response_text = response.choices[0].message.content\n            print(response_text, \" resp text\")\n            return (response_text, coordinates)\n        except Exception as e:\n            print(\"Error processing segment:\", e)\n            return (\"\", coordinates)\n"}
{"type": "source_file", "path": "clickclickclick/finder/gemini.py", "content": "import google.generativeai as genai\nfrom . import BaseFinder\nfrom clickclickclick.config import BaseConfig\nfrom clickclickclick.executor import Executor\nfrom tempfile import NamedTemporaryFile\nfrom PIL import Image\n\n\nclass GeminiFinder(BaseFinder):\n\n    def __init__(self, c: BaseConfig, executor: Executor):\n        prompts = c.prompts\n        system_prompt = prompts[\"finder-system-prompt\"]\n        finder_config = c.models.get(\"finder_config\")\n        self.gemini_finder_prompt = c.gemini_finder_prompt\n        self.IMAGE_WIDTH = finder_config.get(\"image_width\")\n        self.IMAGE_HEIGHT = finder_config.get(\"image_height\")\n        self.OUTPUT_WIDTH = finder_config.get(\"output_width\")\n        self.OUTPUT_HEIGHT = finder_config.get(\"output_height\")\n        api_key = finder_config.get(\"api_key\")\n        model_name = finder_config.get(\"model_name\")\n        generation_config = finder_config.get(\"generation_config\")\n        super().__init__(api_key, model_name, generation_config, system_prompt, executor)\n        genai.configure(api_key=api_key)\n        self.model = genai.GenerativeModel(\n            model_name=model_name,\n            generation_config=generation_config,\n            system_instruction=system_prompt,\n        )\n\n    def process_segment(self, segment, model, prompt, retries=3):\n        attempt = 0\n        segment_image, coordinates = segment\n        while attempt < retries:\n            try:\n                with NamedTemporaryFile(delete=False, suffix=\".png\") as temp_file:\n                    segment_image.save(temp_file, format=\"PNG\")\n                    temp_file_path = temp_file.name\n\n                with Image.open(temp_file_path) as segment_image:\n                    response = self.model.generate_content(\n                        [segment_image, self.gemini_finder_prompt(prompt)]\n                    )\n                    response_text = response.text\n                    print(response_text, \" resp text\")\n                    return (response_text, coordinates)\n            except Exception as e:\n                # Log the exception or handle it as necessary\n                print(f\"Attempt {attempt + 1} failed with exception: {e}\")\n\n                # Increment the attempt counter\n                attempt += 1\n        raise Exception(\"Failed to process segment after several retries\")\n"}
{"type": "source_file", "path": "clickclickclick/finder/mlx.py", "content": "from clickclickclick.config import BaseConfig\nfrom . import BaseFinder, logger\ntry:\n    from mlx_vlm import load, generate\n    from mlx_vlm.prompt_utils import apply_chat_template\n    from mlx_vlm.utils import load_config\nexcept Exception as e:\n    print(f\"warn: mlx-vlm import issue {e}\")\nfrom tempfile import NamedTemporaryFile\nimport re\nimport json\nimport os\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n\ndef extract_coordinates(response_text):\n    # Attempt to find key-value pairs first\n    pattern = r'(\\w+)\\s*[:=]\\s*\"?(\\d*\\.\\d+|\\d+)\"?'\n    matches = re.findall(pattern, response_text)\n\n    # If matches are found, process as key-value pairs\n    if matches:\n        coordinates_dict = {}\n        for match in matches:\n            key = match[0]\n            value = match[1]\n            coordinates_dict[key] = float(value)\n    else:\n        # Assume input is a comma-separated list of values in the order ymin,ymax,xmin,xmax\n        try:\n            values = [float(value.strip()) for value in response_text.split(',')]\n        except ValueError as e:\n            logger.info(e)\n            return json.dumps({\"ymin\": 0, \"ymax\": 0, \"xmin\": 0, \"xmax\": 0})\n        if len(values) == 4:\n            coordinates_dict = {\n                'ymin': values[0],\n                'ymax': values[1],\n                'xmin': values[2],\n                'xmax': values[3]\n            }\n        else:\n            # Handle error case where input doesn't match expected format\n            raise ValueError(\"Input does not contain valid key-value pairs or valid coordinate list.\")\n\n    # Define the normalization mapping\n    conversion_map = {\n        'x1': 'xmin',\n        'y1': 'ymin',\n        'x2': 'xmax',\n        'y2': 'ymax'\n    }\n\n    # Transform the extracted coordinates into a standardized format\n    standardized_coordinates = {conversion_map.get(key, key): value for key, value in coordinates_dict.items()}\n\n    # Convert the standardized dictionary to a JSON string\n    response_json = json.dumps(standardized_coordinates)\n\n    return response_json\n\nclass MLXFinder(BaseFinder):\n    def __init__(self, c: BaseConfig, executor):\n        self.executor = executor\n        finder_config = c.models.get(\"finder_config\")\n        model_path = finder_config.get(\"model_path\")\n        self.config = load_config(model_path)\n        self.model, self.processor = load(model_path, {\"trust_remote_code\": True})\n        # self.image_finder_prompt = c.prompts[\"image-finder-prompt\"]\n        self.system_prompt = c.prompts[\"finder-system-prompt\"]\n\n        self.IMAGE_WIDTH = finder_config.get(\"image_width\")\n        self.IMAGE_HEIGHT = finder_config.get(\"image_height\")\n        self.OUTPUT_WIDTH = finder_config.get(\"output_width\")\n        self.OUTPUT_HEIGHT = finder_config.get(\"output_height\")\n        self.model_name = finder_config.get(\"model_name\")\n\n    def process_image(self, image_path, prompt):\n        formatted_prompt = apply_chat_template(\n            self.processor, self.config, prompt, num_images=1\n        )\n        output = generate(self.model, self.processor, [image_path], formatted_prompt, verbose=False)\n        print(output)\n        try:\n            logger.debug(output)\n            return output\n        except Exception as e:\n            logger.error(\"Error processing image:\", e)\n            return \"\"\n\n    # Example usage\n    def process_segment(self, segment, model_name, prompt):\n        prompt = f'UI bounds of \"{prompt}\" as ymin=,ymax=,xmin=,xmax= format strictly.  '\n        segment_image, coordinates = segment\n        with NamedTemporaryFile(delete=False, suffix=\".png\") as temp_file:\n            segment_image.save(temp_file, format=\"PNG\")\n            temp_file_path = temp_file.name\n            response_text = self.process_image(temp_file_path, prompt)\n            response_json_str = extract_coordinates(response_text)\n\n            return (response_json_str, coordinates)\n\n# Example instantiation and usage would resemble how you manage the base classes and client interactions."}
{"type": "source_file", "path": "clickclickclick/planner/local_ollama.py", "content": "from ollama import Client\nfrom typing import Any\nfrom . import Planner, logger\nfrom clickclickclick.config import BaseConfig\nfrom clickclickclick.executor import Executor\n\n\nclass OllamaPlanner(Planner):\n    def __init__(self, c: BaseConfig, executor: Executor, host=None):\n        if host is None:\n            host = \"http://localhost:11434\"\n        prompts = c.prompts\n        system_prompt = f\"{prompts['common-planner-prompt']}\\n{prompts['specific-planner-prompt']}\"\n        planner_config = c.models.get(\"planner_config\")\n        self.client = Client(host=host)\n        self.model_name = planner_config.get(\"model_name\")\n        function_declarations = c.function_declarations\n        self.executor = executor\n        self.chat_history = [\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt,  # + \"\\nHere is a exact list of functions in JSON format that you can invoke.\\n\\n{functions}\\n , Make sure you do not use any other function.\".format(functions=function_declarations),\n            }\n        ]\n        # Create tool representations directly\n        self.tools = []\n        for func in function_declarations:\n            tool = {\"type\": \"function\", \"function\": func}\n            self.tools.append(tool)\n\n    def llm_response(self, prompt=None, screenshot=None) -> list[tuple[str, dict]]:\n        # Remove items with 'images' key from chat history\n        self.chat_history = [entry for entry in self.chat_history if \"images\" not in entry]\n\n        if screenshot:\n            self.chat_history.append(\n                {\n                    \"role\": \"user\",\n                    \"content\": prompt or \"New screenshot for the task attached\",\n                    \"images\": [screenshot],\n                }\n            )\n        else:\n            self.chat_history.append({\"role\": \"user\", \"content\": prompt})\n        import time\n\n        start_time = time.time()  # Record the start time\n        response = self.client.chat(\n            model=self.model_name, messages=self.chat_history, tools=self.tools\n        )\n        end_time = time.time()  # Record the end time\n        elapsed_time = end_time - start_time  # Calculate the elapsed time\n        print(f\"Time required to run the statement: {elapsed_time} seconds\")\n        print(response, \"all res[ponse]\")\n        tool_calls = response[\"message\"].get(\"tool_calls\", [])\n\n        if tool_calls:\n            print(tool_calls, \"tool calls\")\n            functions_list = []\n            for tool_call in tool_calls:\n                function_call = tool_call[\"function\"]\n                function_name = function_call[\"name\"]\n                args = function_call.get(\"arguments\", {})\n\n                self.chat_history.append(\n                    {\"role\": \"assistant\", \"content\": f\"Function: {function_name} with args: {args}\"}\n                )\n\n                print(f\"Function Call: {function_name} with args: {args}\")\n                if \"observation\" not in args:\n                    args[\"observation\"] = \"NA\"\n                functions_list.append((function_name, args))\n            return functions_list\n\n        # Log the response content when there's no function call\n        logger.info(response[\"message\"][\"content\"])\n        return response[\"message\"][\"content\"]\n\n    def add_finder_message(self, message):\n        self.chat_history.append({\"role\": \"user\", \"content\": message})\n\n    def task_finished(self, reason, observation: str):\n        logger.info(f\"Task finished, reason: {reason}\")\n"}
{"type": "source_file", "path": "clickclickclick/planner/openai.py", "content": "import openai\nfrom typing import Any\nfrom . import Planner, logger\nimport json\nfrom clickclickclick.config import BaseConfig\n\n\nclass ChatGPTPlanner(Planner):\n    def __init__(self, c: BaseConfig):\n        # Get the prompts\n        prompts = c.prompts\n        system_instruction = (\n            f\"{prompts['common-planner-prompt']}\\n{prompts['specific-planner-prompt']}\"\n        )\n        planner_config = c.models.get(\"planner_config\")\n        openai.api_key = planner_config.get(\"api_key\")\n        openai.azure_endpoint = planner_config.get(\"azure_endpoint\")\n        openai.api_type = planner_config.get(\"api_type\")\n        openai.api_version = planner_config.get(\"api_version\")\n        base_url = planner_config.get(\"base_url\")\n        if base_url:\n            openai.base_url = base_url\n        self.model_name = planner_config.get(\"model_name\")\n        self.functions = c.function_declarations\n\n        self.system_instruction = system_instruction\n        self.chat_history = [{\"role\": \"system\", \"content\": system_instruction}]\n\n    def build_prompt(self, query_text=None, base64_image=None):\n        if query_text is None:\n            return [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n                                \"detail\": \"low\",\n                            },\n                        }\n                    ],\n                }\n            ]\n        else:\n            return [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": query_text},\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n                                \"detail\": \"low\",\n                            },\n                        },\n                    ],\n                }\n            ]\n\n    def llm_response(self, prompt=None, screenshot=None) -> list[tuple[str, dict]]:\n        # Remove all prev screenshots\n        new_chat_history = []\n        for message in self.chat_history:\n            if message[\"role\"] == \"user\" and any(\n                item[\"type\"] == \"image_url\" for item in message[\"content\"]\n            ):\n\n                filtered_content = [\n                    item for item in message[\"content\"] if item[\"type\"] != \"image_url\"\n                ]\n                new_chat_history.append({\"role\": message[\"role\"], \"content\": filtered_content})\n\n            else:\n                new_chat_history.append(message)\n        # Append the current prompt to the chat history\n        if screenshot:\n            prompt_with_image = self.build_prompt(\n                prompt, f\"{screenshot}\"\n            )  # data:image/jpeg;base64,\n            new_chat_history.extend(prompt_with_image)\n        else:\n            new_chat_history.extend(self.build_prompt(prompt))\n        self.chat_history = new_chat_history\n\n        completion = openai.chat.completions.create(\n            model=self.model_name,\n            messages=self.chat_history,\n            tools=[\n                {\n                    \"type\": \"function\",\n                    \"function\": {\n                        **fn,\n                        \"parameters\": {**fn[\"parameters\"], \"additionalProperties\": False},\n                        \"strict\": True,\n                    },\n                }\n                for fn in self.functions\n            ],\n            tool_choice=\"required\"\n        )\n        print(completion)\n        response_message = completion.choices[0].message\n        function_name = None\n        function_args = None\n        list_of_functions_to_call = []\n        for tool in response_message.tool_calls:\n            function_name = tool.function.name\n            function_args = json.loads(tool.function.arguments)\n            self.chat_history.append(\n                {\n                    \"role\": \"assistant\",\n                    \"content\": [\n                        {\n                            \"type\": \"text\",\n                            \"text\": f\"Function: {function_name} with args: {function_args}\",\n                        }\n                    ],\n                }\n            )\n            list_of_functions_to_call.append((function_name, function_args))\n\n        print(list_of_functions_to_call)\n\n        if len(list_of_functions_to_call) == 0:\n            list_of_functions_to_call.append((None, None))\n        return list_of_functions_to_call\n\n    def add_finder_message(self, message):\n        self.chat_history.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": message}]})\n\n    def task_finished(self, reason: str, observation: str):\n        logger.info(f\"Task finished with reason: {reason}\")\n"}
{"type": "source_file", "path": "clickclickclick/finder/local_ollama.py", "content": "from clickclickclick.config import BaseConfig\nfrom . import BaseFinder, logger\nfrom ollama import Client\nfrom clickclickclick.executor import Executor\nfrom tempfile import NamedTemporaryFile\n\n\nclass OllamaFinder(BaseFinder):\n\n    def __init__(self, c: BaseConfig, executor: Executor, host=None):\n        if host is None:\n            host = \"http://localhost:11434\"\n        self.client = Client(host=host)\n\n        self.executor = executor\n        prompts = c.prompts\n        self.gemini_finder_prompt = c.gemini_finder_prompt\n        self.system_prompt = prompts[\"finder-system-prompt\"]\n        finder_config = c.models.get(\"finder_config\")\n        self.IMAGE_WIDTH = finder_config.get(\"image_width\")\n        self.IMAGE_HEIGHT = finder_config.get(\"image_height\")\n        self.OUTPUT_WIDTH = finder_config.get(\"output_width\")\n        self.OUTPUT_HEIGHT = finder_config.get(\"output_height\")\n        self.model_name = finder_config.get(\"model_name\")\n\n    def process_segment(self, segment, model_name, prompt):\n        segment_image, coordinates = segment\n\n        with NamedTemporaryFile(delete=False, suffix=\".png\") as temp_file:\n            segment_image.save(temp_file, format=\"PNG\")\n            temp_file_path = temp_file.name\n\n        response = self.client.chat(\n            model=self.model_name,\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": self.system_prompt,\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": self.gemini_finder_prompt(prompt),\n                    \"images\": [temp_file_path],\n                },\n            ],\n        )\n        try:\n            response_text = response[\"message\"][\"content\"]\n            logger.debug(response_text)\n            return (response_text, coordinates)\n        except Exception as e:\n            logger.error(\"Error processing segment:\", e)\n            return (\"\", coordinates)\n"}
{"type": "source_file", "path": "clickclickclick/config/yaml_loader.py", "content": "import os\nimport yaml\n\n\n# Custom constructor for environment variables\ndef env_constructor(loader, node):\n    env_var = loader.construct_scalar(node)\n    return os.getenv(env_var, \"\")\n\n\n# Register the !ENV tag in PyYAML to use the custom constructor\nyaml.SafeLoader.add_constructor(\"!ENV\", env_constructor)\n\n\n# Function to load the YAML file with environment variable processing\ndef load_yaml(file_path, loader=yaml.SafeLoader):\n    with open(file_path, \"r\") as file:\n        return yaml.load(file, Loader=loader)\n"}
{"type": "source_file", "path": "clickclickclick/config/conf_types.py", "content": "import os\nfrom dataclasses import dataclass\nfrom google.ai.generativelanguage_v1beta.types import content\nfrom .yaml_loader import load_yaml\n\n\n# Get the absolute path to the directory containing this script\nbase_dir = os.path.dirname(os.path.abspath(__file__))\n\n\n@dataclass\nclass BaseConfig:\n    prompts = {}\n    models = {}\n    function_declarations = []\n    models_config = load_yaml(os.path.join(base_dir, \"models.yaml\"))\n    GEMINI_API_KEY = models_config[\"gemini\"].get(\"api_key\")\n    SAMPLE_TASK_PROMPT = \"open google.com in safari and search for sharukh khan and click the first link in the result. Take a screenshot and save the screenshot.\"\n    TASK_TIMEOUT_IN_SECONDS = 330\n    TASK_DELAY = 1\n    DEBUG = True\n\n    def get_config_for_platform(self, model_name, section, platform=\"\"):\n        \"\"\"\n        Retrieves configuration for a specific model, section, and platform.\n        Fallbacks to section-specific or general configuration if platform-specific is not available.\n        \"\"\"\n        model_configs = self.models_config[model_name]\n        base_config = {k: v for k, v in model_configs.items() if k not in [\"planner\", \"finder\"]}\n        section_config = model_configs.get(section, {})\n        if section == \"finder\" and model_name == \"gemini\":\n            section_config[\"generation_config\"][\"response_schema\"] = content.Schema(\n                type=content.Type.OBJECT,\n                required=[\"ymin\", \"xmin\", \"ymax\", \"xmax\"],\n                properties={\n                    \"ymin\": content.Schema(\n                        type=content.Type.INTEGER,\n                    ),\n                    \"xmin\": content.Schema(\n                        type=content.Type.INTEGER,\n                    ),\n                    \"ymax\": content.Schema(\n                        type=content.Type.INTEGER,\n                    ),\n                    \"xmax\": content.Schema(\n                        type=content.Type.INTEGER,\n                    ),\n                },\n            )\n        platform_config = section_config.get(platform, {})\n\n        # Combine configurations with priority: platform > section > base\n        combined_config = {**base_config, **section_config, **platform_config}\n        return combined_config\n\n    def get_function_declarations(self, platform: str) -> list:\n        common_yaml_path = os.path.join(base_dir, \"function_declarations\", \"common.yaml\")\n        common_declarations = load_yaml(common_yaml_path).get(\"function_declarations\", [])\n\n        platform_yaml_path = os.path.join(base_dir, \"function_declarations\", f\"{platform}.yaml\")\n        platform_declarations = load_yaml(platform_yaml_path).get(\"function_declarations\", [])\n\n        return common_declarations + platform_declarations\n\n    def get_functions_list_as_prompt(self, function_declarations) -> str:\n        return \"\\n\".join(f\"{i + 1}. {fn['name']}\" for i, fn in enumerate(function_declarations))\n\n    def gemini_finder_prompt(self, element_name):\n        return f'If \"{element_name}\" is present then Return bounding box for the same, else 0 0 0 0 for all xmax xmin ymax ymin. Check again.'\n\n        # return f'Find if any bounding box of {element_name} in this format ymin,xmin,ymax,xmax. Really thats a \"{element_name}\"?'\n\n    def get_prompts(self, platform, planner_model, finder_model):\n        # Load the YAML file\n        yaml_path = os.path.join(base_dir, \"prompts.yaml\")\n        data = load_yaml(yaml_path)\n        result = {}\n\n        # Process platform-specific prompts and override with model-specific ones if available\n        for model_key in [None, planner_model]:\n            if model_key is None:\n                platform_data = data.get(platform, {})\n            else:\n                platform_data = data.get(platform, {}).get(model_key, {})\n\n            for key, value in platform_data.items():\n                if key not in result or model_key is not None:\n                    result[key] = value\n\n        # Add finder model specific prompts\n        finder_data = data.get(finder_model, {})\n        for key, value in finder_data.items():\n            if key not in result:\n                result[key] = value\n\n        return result\n\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Only add incremetal changes to BaseConfig here\"\"\"\n\n    DEBUG = False\n\n\nclass DevelopmentConfig(BaseConfig):\n    DEBUG = True\n    pass\n\n\nclass TestingConfig(BaseConfig):\n    TESTING = True\n    pass\n"}
{"type": "source_file", "path": "interface.py", "content": "from clickclickclick.config import get_config\nfrom clickclickclick.planner.task import execute_with_timeout, execute_task_with_generator\nfrom utils import get_executor, get_finder, get_planner\n\n\nimport gradio as gr\nfrom typing import Generator, List\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\ndef execute_task_prompt(\n    task_prompt: str, platform: str, planner_model: str, finder_model: str, state: List\n) -> Generator[List, None, bool]:\n    try:\n        config = get_config(platform, planner_model, finder_model)\n        executor = get_executor(platform)\n        planner = get_planner(planner_model, config, executor)\n        finder = get_finder(finder_model, config, executor)\n\n        result = execute_with_timeout(\n            execute_task_with_generator,\n            config.TASK_TIMEOUT_IN_SECONDS,\n            task_prompt,\n            executor,\n            planner,\n            finder,\n            config,\n        )\n        for output in result:\n            new_entries = []\n            for img_path, observation in output:\n                # Create a temporary file to copy the image into\n\n                # Append as a tuple (role, content)\n                new_entries.append(gr.ChatMessage(role=\"assistant\", content=observation))\n                new_entries.append(gr.ChatMessage(role=\"assistant\", content=gr.Image(img_path)))\n                # new_entries.append([None, gr.Image(img_path)])\n\n            state.extend(new_entries)\n\n            # Yield updated state for both chatbot display and state update\n            yield state, state\n    except Exception as e:\n        logger.exception(\"An error occurred during prompting.\")\n        yield state, state\n\n\ndef run_gradio():\n    with gr.Blocks() as gui:\n        state = gr.State(\n            [\n                gr.ChatMessage(role=\"assistant\", content=\"Step by step\"),\n            ]\n        )  # Initialize the state to keep track of chatbot history\n        examples = [\n            [\"Open gmail and compose mail to someone@gmail.com ask for lunch\"],\n            [\"Open google maps and find bus stops in Alanson\"],\n            [\"Find my rating in uber\"],\n        ]\n        with gr.Row():\n            with gr.Column():\n                task_prompt = gr.Textbox(\n                    lines=2, label=\"Task Prompt\", placeholder=\"Enter task prompt here...\"\n                )\n                platform = gr.Radio([\"android\", \"osx\"], label=\"Platform\", value=\"android\")\n                planner_model = gr.Radio(\n                    [\"openai\", \"gemini\", \"ollama\"], label=\"Planner Model\", value=\"openai\"\n                )\n                finder_model = gr.Radio(\n                    [\"openai\", \"gemini\", \"ollama\", \"mlx\"], label=\"Finder Model\", value=\"gemini\"\n                )\n                submit_btn = gr.Button(\"Submit\")\n\n                gr.Examples(examples, inputs=task_prompt)\n\n            with gr.Column():\n                chatbot = gr.Chatbot(type=\"messages\", label=\"Task Execution History\")\n\n        # Connect the submit button to execute_task_prompt function\n        submit_btn.click(\n            execute_task_prompt,\n            inputs=[task_prompt, platform, planner_model, finder_model, state],\n            outputs=[chatbot, state],\n        )\n\n        gui.launch(server_name=\"0.0.0.0\", server_port=8080)\n"}
{"type": "source_file", "path": "main.py", "content": "import click\nimport os\nfrom clickclickclick.config import get_config\nfrom clickclickclick.planner.task import execute_with_timeout, execute_task\nfrom utils import get_executor, get_finder, get_planner\nfrom interface import run_gradio\n\n@click.group()\ndef cli():\n    pass\n\n\ndef setup_environment_variables(planner=None, finder=None):\n    if planner and planner.lower() == \"gemini\":\n        os.environ[\"GEMINI_API_KEY\"] = click.prompt(\"Enter your Gemini API key\", hide_input=True)\n    elif planner and planner.lower() == \"4o\":\n        setup_openai_or_azure()\n    elif planner and planner.lower() == \"ollama\":\n        os.environ[\"OLLAMA_MODEL_NAME\"] = click.prompt(\n            \"Select the model name (press enter to use 'llama3.2:latest')\",\n            default=\"llama3.2:latest\",\n        )\n\n    if not finder:\n        finder = planner\n\n    if finder and finder.lower() == \"gemini\":\n        os.environ[\"GEMINI_API_KEY\"] = click.prompt(\n            \"Enter your Gemini API key (press enter to use existing)\",\n            hide_input=True,\n            default=os.getenv(\"GEMINI_API_KEY\", \"\"),\n        )\n    elif finder and finder.lower() == \"4o\":\n        setup_openai_or_azure(existing=True)\n    elif finder and finder.lower() == \"ollama\":\n        os.environ[\"OLLAMA_MODEL_NAME\"] = click.prompt(\n            \"Select the model name (press enter to use 'llama3.2:latest')\",\n            default=os.getenv(\"OLLAMA_MODEL_NAME\", \"llama3.2:latest\"),\n        )\n\n\ndef setup_openai_or_azure(existing=False):\n    version = click.prompt(\n        (\n            \"Is it OpenAI or Azure version? (press enter to use existing)\"\n            if existing\n            else \"Is it OpenAI or Azure version?\"\n        ),\n        type=str,\n        default=os.getenv(\"OPENAI_API_TYPE\", \"openai\"),\n    )\n    if version.lower() == \"openai\":\n        os.environ[\"AZURE_OPENAI_API_KEY\"] = click.prompt(\n            (\n                \"Enter your OpenAI API key (press enter to use existing)\"\n                if existing\n                else \"Enter your OpenAI API key\"\n            ),\n            hide_input=True,\n            default=os.getenv(\"AZURE_OPENAI_API_KEY\", \"\"),\n        )\n        os.environ[\"OPENAI_API_TYPE\"] = \"openai\"\n    elif version.lower() == \"azure\":\n        os.environ[\"AZURE_OPENAI_API_KEY\"] = click.prompt(\n            (\n                \"Enter your Azure API key (press enter to use existing)\"\n                if existing\n                else \"Enter your Azure API key\"\n            ),\n            hide_input=True,\n            default=os.getenv(\"AZURE_OPENAI_API_KEY\", \"\"),\n        )\n        os.environ[\"AZURE_OPENAI_MODEL_NAME\"] = click.prompt(\n            \"Enter your Azure model name (press enter to use existing)\",\n            type=str,\n            default=os.getenv(\"AZURE_OPENAI_MODEL_NAME\", \"\"),\n        )\n        os.environ[\"AZURE_OPENAI_ENDPOINT\"] = click.prompt(\n            \"Enter your Azure endpoint (press enter to use existing)\",\n            type=str,\n            default=os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n        )\n        os.environ[\"AZURE_OPENAI_API_VERSION\"] = click.prompt(\n            \"Enter your Azure API version (press enter to use existing)\",\n            type=str,\n            default=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\"),\n        )\n        os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n\n\n@click.command()\n@click.argument(\"task_prompt\", nargs=-1)\n@click.option(\"--platform\", default=\"android\", help=\"The platform to use, 'android' or 'osx'.\")\n@click.option(\n    \"--planner-model\",\n    default=\"openai\",\n    help=\"The planner model to use, 'openai', 'gemini', or 'ollama'.\",\n)\n@click.option(\n    \"--finder-model\",\n    default=\"gemini\",\n    help=\"The finder model to use, 'openai', 'gemini', or 'ollama'.\",\n)\ndef run(task_prompt, platform, planner_model, finder_model):\n    \"\"\"\n    Execute a task with the given TASK_PROMPT using the specified\n    platform, planner model, and finder model.\n    \"\"\"\n    task_prompt = \" \".join(task_prompt)\n    config = get_config(platform, planner_model, finder_model)\n\n    executor = get_executor(platform)\n    planner = get_planner(planner_model, config, executor)\n    finder = get_finder(finder_model, config, executor)\n\n    if not task_prompt:\n        task_prompt = config.SAMPLE_TASK_PROMPT\n\n    result = execute_with_timeout(\n        execute_task, config.TASK_TIMEOUT_IN_SECONDS, task_prompt, executor, planner, finder, config\n    )\n\n    if result is not None:\n        print(result)\n\n\n@click.command()\ndef setup():\n    \"\"\"Setup command to configure planner and finder\"\"\"\n    planner = click.prompt(\"Choose planner model ('gemini', '4o', or 'ollama')\", type=str)\n    finder = click.prompt(\n        \"Choose finder model ('gemini', '4o', or 'ollama') (press enter to use '{}')\".format(\n            planner\n        ),\n        type=str,\n        default=planner,\n    )\n\n    setup_environment_variables(planner, finder)\n\n@click.command()\ndef gradio():\n    \"\"\"Run the Gradio interface\"\"\"\n    run_gradio()\n\ncli.add_command(run)\ncli.add_command(setup)\ncli.add_command(gradio)\n\nif __name__ == \"__main__\":\n    cli()\n"}
{"type": "source_file", "path": "clickclickclick/planner/__init__.py", "content": "from abc import ABC, abstractmethod\nfrom typing import Any\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass Planner(ABC):\n    @abstractmethod\n    def llm_response(self, prompt, screenshot) -> str:\n        pass\n\n    @abstractmethod\n    def add_finder_message(self, message):\n        pass\n\n    @abstractmethod\n    def task_finished(self, reason):\n        pass\n"}
{"type": "source_file", "path": "utils.py", "content": "from clickclickclick.executor.osx import MacExecutor\nfrom clickclickclick.executor.android import AndroidExecutor\nfrom clickclickclick.planner.gemini import GeminiPlanner\nfrom clickclickclick.finder.gemini import GeminiFinder\nfrom clickclickclick.planner.openai import ChatGPTPlanner\nfrom clickclickclick.finder.local_ollama import OllamaFinder\nfrom clickclickclick.finder.openai import OpenAIFinder\nfrom clickclickclick.planner.local_ollama import OllamaPlanner\nfrom clickclickclick.finder.mlx import MLXFinder\n\ndef get_executor(platform):\n    if platform.lower() == \"osx\":\n        return MacExecutor()\n    return AndroidExecutor()\n\n\ndef get_planner(planner_model, config, executor):\n    if planner_model.lower() == \"openai\":\n        executor.screenshot_as_base64 = True\n        return ChatGPTPlanner(config)\n    elif planner_model.lower() == \"gemini\":\n        executor.screenshot_as_tempfile = True\n        return GeminiPlanner(config)\n    elif planner_model.lower() == \"ollama\":\n        executor.screenshot_as_tempfile = True\n        return OllamaPlanner(config, executor)\n    raise ValueError(f\"Unsupported planner model: {planner_model}\")\n\n\ndef get_finder(finder_model, config, executor):\n    if finder_model.lower() == \"openai\":\n        return OpenAIFinder(config, executor)\n    elif finder_model.lower() == \"gemini\":\n        return GeminiFinder(config, executor)\n    elif finder_model.lower() == \"ollama\":\n        return OllamaFinder(config, executor)\n    elif finder_model.lower() == \"mlx\":\n        return MLXFinder(config, executor)\n    raise ValueError(f\"Unsupported finder model: {finder_model}\")\n"}
{"type": "source_file", "path": "clickclickclick/executor/osx.py", "content": "from . import Executor\nfrom typing import List, Union\nimport logging\nimport io\nimport base64\nfrom PIL import Image\nfrom tempfile import NamedTemporaryFile\nfrom . import logger\n\ntry:\n    import pyautogui\n    import applescript\nexcept Exception as e:\n    print(f\"warn: import error in osx.py {e}\")\n\n\nclass MacExecutor(Executor):\n    def __init__(self):\n        super().__init__()\n        self.screenshot_as_base64 = False\n        self.screenshot_as_tempfile = False\n\n    def move_mouse(self, x: int, y: int, observation: str) -> bool:\n        try:\n            logger.debug(f\"move mouse x y {x} {y}\")\n            pyautogui.moveTo(y, x, 1)\n            return True\n        except Exception as e:\n            logger.exception(\"Error in move_mouse\")\n            return False\n\n    def press_key(self, keys: List[str], observation: str) -> bool:\n        try:\n            logger.debug(f\"press keys {keys}\")\n            pyautogui.hotkey(*[k.lower() for k in keys])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in press_key\")\n            return False\n\n    def type_text(self, text: str, observation: str) -> bool:\n        try:\n            logger.debug(f\"type text {text}\")\n            pyautogui.write(text)\n            return True\n        except Exception as e:\n            logger.exception(\"Error in type_text\")\n            return False\n\n    def click_mouse(self, observation: str, button: str = \"left\") -> bool:\n        try:\n            logger.debug(f\"click mouse {button}\")\n            pyautogui.click(button=button)\n            return True\n        except Exception as e:\n            logger.exception(\"Error in click_mouse\")\n            return False\n\n    def double_click_mouse(self, button: str, observation: str) -> bool:\n        try:\n            logger.debug(f\"doubleclick mouse {button}\")\n            pyautogui.doubleClick(button=button)\n            return True\n        except Exception as e:\n            logger.exception(\"Error in double_click_mouse\")\n            return False\n\n    def scroll(self, clicks: int, observation: str) -> bool:\n        try:\n            logger.debug(f\"scroll {clicks}\")\n            pyautogui.scroll(clicks)\n            return True\n        except Exception as e:\n            logger.exception(\"Error in scroll\")\n            return False\n\n    def click_at_a_point(self, x: int, y: int, observation: str) -> bool:\n        try:\n            logger.debug(f\"click at a point x y {x} {y}\")\n            pyautogui.click(x=y, y=x, duration=1)\n            return True\n        except Exception as e:\n            logger.exception(\"Error in click_at_a_point\")\n            return False\n\n    def long_press_at_a_point(self, x: int, y: int, observation: str, duration: int = 1000):\n        raise NotImplementedError(\"Long press is not implemented on Mac\")\n\n    def swipe_left(self, observation: str) -> bool:\n        raise NotImplementedError(\"Swipe left is not implemented on Mac\")\n\n    def swipe_right(self, observation: str) -> bool:\n        raise NotImplementedError(\"Swipe right is not implemented on Mac\")\n\n    def swipe_up(self, observation: str) -> bool:\n        raise NotImplementedError(\"Swipe up is not implemented on Mac\")\n\n    def swipe_down(self, observation: str) -> bool:\n        raise NotImplementedError(\"Swipe down is not implemented on Mac\")\n\n    def volume_up(self, observation: str) -> bool:\n        raise NotImplementedError(\"Volume up is not implemented on Mac\")\n\n    def volume_down(self, observation: str) -> bool:\n        raise NotImplementedError(\"Volume down is not implemented on Mac\")\n\n    def navigate_back(self, observation: str) -> bool:\n        raise NotImplementedError(\"Navigate back is not implemented on Mac\")\n\n    def minimize_app(self, observation: str) -> bool:\n        raise NotImplementedError(\"Minimize app is not implemented on Mac\")\n\n    def screenshot(\n        self, observation: str, as_base64: bool = False, use_tempfile: bool = False\n    ) -> Union[Image.Image, str, tuple]:\n        \"\"\"\n        Takes a screenshot.\n\n        Args:\n            as_base64 (bool): Whether to return the screenshot as a base64-encoded string. Defaults to False.\n            use_tempfile (bool): Whether to use a temporary file for storing the screenshot. Defaults to False.\n\n        Returns:\n            Union[Image.Image, str, tuple]: The screenshot as a PIL Image object, a base64-encoded string,\n                                             or a tuple containing the PIL Image object and the file path if use_tempfile is True.\n        \"\"\"\n        try:\n            logger.debug(f\"Take a screenshot use_tempfile={use_tempfile}\")\n            screenshot = pyautogui.screenshot()\n            if use_tempfile or self.screenshot_as_tempfile:\n                with NamedTemporaryFile(delete=False, suffix=\".png\") as temp_file:\n                    screenshot.save(temp_file, format=\"PNG\")\n                    temp_file_path = temp_file.name\n                return temp_file_path\n\n            if as_base64 or self.screenshot_as_base64:\n                buffered = io.BytesIO()\n                screenshot.save(buffered, format=\"PNG\")\n                base64_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n                return base64_str\n\n            return screenshot\n        except Exception as e:\n            logger.exception(\"Error in screenshot\")\n            return \"\" if as_base64 or use_tempfile else None\n\n    def apple_script(self, script: str, observation: str) -> bool:\n        try:\n            logger.debug(f\"Run apple script {script}\")\n            result = applescript.AppleScript(script).run()\n            logger.info(result)\n            return True\n        except Exception as e:\n            logger.exception(f\"Error in apple_script {e}\")\n            return False\n"}
{"type": "source_file", "path": "clickclickclick/planner/gemini.py", "content": "import google.generativeai as genai\nfrom google.generativeai.types import FunctionDeclaration, Tool, File\nfrom google.generativeai.protos import FunctionCallingConfig, ToolConfig\nfrom typing import Any\nfrom PIL import Image\nimport tempfile\nfrom clickclickclick.config import BaseConfig\nfrom . import Planner, logger\n\n\nclass GeminiPlanner(Planner):\n    def __init__(self, c: BaseConfig):\n        prompts = c.prompts\n        system_instruction = (\n            f\"{prompts['common-planner-prompt']}\\n{prompts['specific-planner-prompt']}\"\n        )\n        planner_config = c.models.get(\"planner_config\")\n        api_key = planner_config.get(\"api_key\")\n        model_name = planner_config.get(\"model_name\")\n        generation_config = planner_config.get(\"generation_config\")\n\n        function_declarations = c.function_declarations\n        logger.info(\"Gemini Planner init\")\n        genai.configure(api_key=api_key)\n        self.chat_history = []\n        # Create FunctionDeclaration objects\n        self.functions = []\n        for func in function_declarations:\n            parameters = func.get(\"parameters\")\n            if parameters is None:\n                function_declaration = FunctionDeclaration(\n                    name=func[\"name\"], description=func[\"description\"]\n                )\n            else:\n                function_declaration = FunctionDeclaration(\n                    name=func[\"name\"],\n                    description=func[\"description\"],\n                    parameters=func[\"parameters\"],\n                )\n            self.functions.append(function_declaration)\n        all_functions_tool = Tool(function_declarations=self.functions)\n        tool_config = ToolConfig(\n            function_calling_config=FunctionCallingConfig(\n                # ANY mode forces the model to predict only function calls\n                mode=FunctionCallingConfig.Mode.ANY,\n                # Allowed function calls to predict when the mode is ANY. If empty, any  of\n                # the provided function calls will be predicted.\n            )\n        )\n        self.model = genai.GenerativeModel(\n            model_name=model_name,\n            generation_config=generation_config,\n            system_instruction=system_instruction,\n            tools=[all_functions_tool],\n            tool_config=tool_config,\n        )\n\n    def llm_response(self, prompt=None, screenshot=None) -> list[tuple[str, dict]]:\n        # Remove any previous screenshots from the chat history\n        self.chat_history = [\n            message\n            for message in self.chat_history\n            if not (\n                message.get(\"role\") == \"user\" and isinstance(message.get(\"parts\", [{}])[0], File)\n            )\n        ]\n        # todo\n        assert screenshot.endswith(\".png\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as temp_file:\n            temp_file_path = temp_file.name\n\n        # Resize the image\n        with Image.open(screenshot) as img:\n            # Example resize operation, may need to adjust size\n            img = img.resize((768, 768))  # todo from config\n            img.save(temp_file_path)\n\n        file = genai.upload_file(temp_file_path, mime_type=\"image/png\")\n        # Append the current screenshot to the chat history\n        self.chat_history.append({\"role\": \"user\", \"parts\": [file]})\n\n        logger.info(self.chat_history)\n        self.chat_session = self.model.start_chat(history=self.chat_history)\n        response = self.chat_session.send_message(f\"{prompt}\")  # Adjust as needed\n        logger.info(response)\n        for i in range(len(response.candidates[0].content.parts)):\n            try:\n                function_call = response.candidates[0].content.parts[i].function_call\n                break\n            except Exception as e:\n                pass\n        function_name = function_call.name\n\n        # user prompt needs to be only inserted one time\n        if not any(\n            message.get(\"parts\", [None])[0] == prompt\n            for message in self.chat_history\n            if message.get(\"role\") == \"user\"\n        ):\n            self.chat_history.append({\"role\": \"user\", \"parts\": [prompt]})\n\n        args = function_call.args\n        d = {key: args[key] for key in args}\n        logger.info(f\"{d} args\")\n        self.chat_history.append(\n            {\"role\": \"model\", \"parts\": [f\"function name: {function_name} args: {d}\"]}\n        )\n\n        if function_name == \"task_finished\":\n            with open(\"planner.logs\", \"a\") as f:\n                f.write(\"\\n\".join(map(str, self.chat_history)))\n                f.write(\"\\n\\n\")\n        return [(function_name, {key: args[key] for key in args})]\n\n    def add_finder_message(self, message):\n        self.chat_history.append({\"role\": \"user\", \"parts\": [message]})\n\n    def task_finished(self, reason, observation: str):\n        logger.info(f\"Task finished, reason: {reason}\")\n"}
{"type": "source_file", "path": "clickclickclick/finder/__init__.py", "content": "from abc import ABC, abstractmethod\nfrom typing import List\nimport subprocess\nimport re\nimport base64\nimport json\nimport logging\nfrom clickclickclick.executor import Executor\nfrom PIL import Image\nfrom pydantic import BaseModel\n\nlogger = logging.getLogger(__name__)\n\n\nclass FinderResponseLLM(BaseModel):\n    ymin: int\n    ymax: int\n    xmin: int\n    xmax: int\n\n\nclass BaseFinder(ABC):\n    IMAGE_WIDTH = None\n    IMAGE_HEIGHT = None\n    OUTPUT_WIDTH = None\n    OUTPUT_HEIGHT = None\n\n    def __init__(self, api_key, model_name, generation_config, system_prompt, executor: Executor):\n        self.model_name = model_name\n        self.generation_config = generation_config\n        self.system_prompt = system_prompt\n        self.executor = executor\n\n    def encode_image_to_base64(self, image_path):\n        with open(image_path, \"rb\") as image_file:\n            encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n        return encoded_string\n\n    def resize(self, image, new_size):\n        if new_size:\n            target_width, target_height = new_size, new_size\n            resized_image = image.resize((target_width, target_height), Image.Resampling.LANCZOS)\n            segments = [(resized_image, (0, 0, target_width, target_height))]\n            total_width, total_height = target_width, target_height\n        return segments, total_width, total_height\n\n    @abstractmethod\n    def process_segment(self, segment, model, prompt):\n        pass\n\n    def find_element(self, prompt, observation: str) -> str:\n        new_size = self.IMAGE_WIDTH  # assuming square image size\n        logger.info(prompt)\n        screenshot = self.executor.screenshot(observation, False, True)\n        image = Image.open(screenshot)\n\n        segments, total_width, total_height = self.resize(image, new_size=new_size)\n\n        results = [self.process_segment(segments[0], self.model_name, prompt)]\n        i = 0\n        ans = \"0,0,0,0\"\n        for response, coordinates in results:\n            i += 1\n            print(coordinates, i)\n\n            try:\n                response_dict = json.loads(response)\n                ymin = int(response_dict[\"ymin\"])\n                xmin = int(response_dict[\"xmin\"])\n                ymax = int(response_dict[\"ymax\"])\n                xmax = int(response_dict[\"xmax\"])\n                if ymin == 0 and xmin == 0 and xmax == 0 and ymax == 0:\n                    continue\n                orig_left, orig_top, _, _ = coordinates\n\n                y_min_percent = (orig_top + ymin) / self.OUTPUT_HEIGHT * self.IMAGE_HEIGHT\n                x_min_percent = (orig_left + xmin) / self.OUTPUT_WIDTH * self.IMAGE_WIDTH\n                y_max_percent = (orig_top + ymax) / self.OUTPUT_HEIGHT * self.IMAGE_HEIGHT\n                x_max_percent = (orig_left + xmax) / self.OUTPUT_WIDTH * self.IMAGE_WIDTH\n                ans = \",\".join(\n                    map(\n                        str,\n                        map(\n                            int,\n                            [\n                                y_min_percent,\n                                x_min_percent,\n                                y_max_percent,\n                                x_max_percent,\n                            ],\n                        ),\n                    )\n                )\n                print(ans)\n            except json.JSONDecodeError:\n                print(\"Could not decode response\")\n\n        return ans\n\n    def scale_coordinates(self, coordinates: List[int]) -> List[int]:\n        try:\n            # Execute adb shell command to get the screen size\n            result = subprocess.run([\"adb\", \"shell\", \"wm\", \"size\"], stdout=subprocess.PIPE)\n            output = result.stdout.decode()\n            # Example output format: 'Physical size: 1080x1920'\n            match = re.search(r\"Physical size: (\\d+)x(\\d+)\", output)\n            if match:\n                screen_x, screen_y = map(int, match.groups())\n            else:\n                raise Exception(\"Failed to parse screen size from adb output.\")\n        except Exception as e:\n            # Attempt to get screen size using pyautogui (for desktops)\n            import pyautogui\n            screen_x, screen_y = pyautogui.size()\n\n        print(f\"Screen size: x y {screen_x} {screen_y}\")\n        scaling_x = screen_x / self.IMAGE_WIDTH\n        scaling_y = screen_y / self.IMAGE_HEIGHT\n        coordinates[0] = int(coordinates[0] * scaling_y)\n        coordinates[2] = int(coordinates[2] * scaling_y)\n        coordinates[1] = int(coordinates[1] * scaling_x)\n        coordinates[3] = int(coordinates[3] * scaling_x)\n\n        if scaling_x < scaling_y:\n            # For mobile: swap coordinates[0] with coordinates[1] and coordinates[2] with coordinates[3]\n            coordinates[0], coordinates[1] = coordinates[1], coordinates[0]\n            coordinates[2], coordinates[3] = coordinates[3], coordinates[2]\n\n        return coordinates\n"}
{"type": "source_file", "path": "clickclickclick/executor/android.py", "content": "from . import Executor\nfrom subprocess import CompletedProcess, run\nimport subprocess\nfrom typing import List, Union\nimport io\nimport base64\nfrom PIL import Image\nfrom tempfile import NamedTemporaryFile\nimport shlex\nfrom . import logger\n\n\ndef run_adb_command(command: List[str], text_mode: bool = True) -> CompletedProcess:\n    \"\"\"Runs adb command and returns the completed process.\"\"\"\n    result = run(\n        [\"adb\"] + command,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=text_mode,\n    )\n    if result.returncode != 0:\n        logger.error(\n            f\"adb command {' '.join(command)} failed: {result.stderr.decode('utf-8').strip()}\"\n        )\n    return result\n\n\ndef sanitize_for_adb(text: str) -> str:\n    # Replace spaces with %s\n    text = text.replace(\" \", \"%s\")\n    # Use shlex.quote to handle special shell characters\n    return shlex.quote(text)\n\n\nclass AndroidExecutor(Executor):\n    def __init__(self):\n        super().__init__()\n        self.screenshot_as_base64 = False\n        self.screenshot_as_tempfile = False\n\n    def click_mouse(observation: str):\n        raise NotImplementedError(\"click mouse is not available in android\")\n\n    def double_click_mouse(observation: str):\n        raise NotImplementedError(\"double click mouse is not available in android\")\n\n    def move_mouse(self, x: int, y: int, observation: str) -> bool:\n        try:\n            logger.debug(f\"move mouse x y {x} {y}\")\n            run_adb_command([\"shell\", \"input\", \"tap\", str(x), str(y)])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in move_mouse\")\n            return False\n\n    def press_key(self, keys: List[str], observation: str) -> bool:\n        try:\n            logger.debug(f\"press keys {keys}\")\n            for key in keys:\n                run_adb_command([\"shell\", \"input\", \"keyevent\", key.upper()])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in press_key\")\n            return False\n\n    def type_text(self, text: str, observation: str) -> bool:\n        try:\n            logger.debug(f\"type text {text}\")\n            multiline_texts = text.split(\"\\n\")\n            for text in multiline_texts:\n                if text == \"\":  # due to newline\n                    run_adb_command([\"shell\", \"input\", \"keyevent\", \"66\"])\n                else:\n                    sanitized_text = sanitize_for_adb(text)\n                    run_adb_command([\"shell\", \"input\", \"text\", sanitized_text])\n            # todo confirm if needed\n            run_adb_command([\"shell\", \"input\", \"keyevent\", \"66\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in type_text\")\n            return False\n\n    def scroll(self, clicks: int, observation: str) -> bool:\n        try:\n            logger.debug(f\"scroll {clicks}\")\n            # Perform swipe to simulate scroll\n            if clicks > 0:\n                # Scroll up\n                run_adb_command([\"shell\", \"input\", \"swipe\", \"500\", \"1500\", \"500\", \"500\"])\n            else:\n                # Scroll down\n                run_adb_command([\"shell\", \"input\", \"swipe\", \"500\", \"500\", \"500\", \"1500\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in scroll\")\n            return False\n\n    def swipe_left(self, observation: str) -> bool:\n        try:\n            logger.debug(\"swipe left\")\n            run_adb_command([\"shell\", \"input\", \"swipe\", \"700\", \"1000\", \"100\", \"1000\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in swipe_left\")\n            return False\n\n    def swipe_right(self, observation: str) -> bool:\n        try:\n            logger.debug(\"swipe right\")\n            run_adb_command([\"shell\", \"input\", \"swipe\", \"100\", \"1000\", \"700\", \"1000\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in swipe_right\")\n            return False\n\n    def volume_up(self, observation: str) -> bool:\n        try:\n            logger.debug(\"volume up\")\n            run_adb_command([\"shell\", \"input\", \"keyevent\", \"KEYCODE_VOLUME_UP\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in volume_up\")\n            return False\n\n    def volume_down(self, observation: str) -> bool:\n        try:\n            logger.debug(\"volume down\")\n            run_adb_command([\"shell\", \"input\", \"keyevent\", \"KEYCODE_VOLUME_DOWN\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in volume_down\")\n            return False\n\n    def swipe_up(self, observation: str) -> bool:\n        try:\n            logger.debug(\"swipe up\")\n            run_adb_command([\"shell\", \"input\", \"swipe\", \"500\", \"1500\", \"500\", \"500\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in swipe_up\")\n            return False\n\n    def swipe_down(self, observation: str) -> bool:\n        try:\n            logger.debug(\"swipe down\")\n            run_adb_command([\"shell\", \"input\", \"swipe\", \"500\", \"500\", \"500\", \"1500\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in swipe_down\")\n            return False\n\n    def navigate_back(self, observation: str) -> bool:\n        try:\n            logger.debug(\"navigate back\")\n            run_adb_command([\"shell\", \"input\", \"keyevent\", \"KEYCODE_BACK\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in navigate_back\")\n            return False\n\n    def minimize_app(self, observation: str) -> bool:\n        try:\n            logger.debug(\"minimize app\")\n            run_adb_command([\"shell\", \"input\", \"keyevent\", \"KEYCODE_HOME\"])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in minimize_app\")\n            return False\n\n    def click_at_a_point(self, x: int, y: int, observation: str) -> bool:\n        try:\n            logger.debug(f\"click at a point x y {x} {y}\")\n            run_adb_command([\"shell\", \"input\", \"tap\", str(x), str(y)])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in click_at_a_point\")\n            return False\n\n    def long_press_at_a_point(self, x: int, y: int, observation: str, duration: int = 1000) -> bool:\n        try:\n            logger.debug(f\"Long press at a point x y {x} {y} for duration {duration}\")\n            run_adb_command([\"shell\", \"input\", \"swipe\", str(x), str(y), str(x), str(y), str(duration)])\n            return True\n        except Exception as e:\n            logger.exception(\"Error in long_press_at_a_point\")\n            return False\n\n    def screenshot(\n        self, observation: str, as_base64: bool = False, use_tempfile: bool = False\n    ) -> Union[Image.Image, str, tuple]:\n        try:\n            logger.debug(f\"Take a screenshot use_tempfile={use_tempfile}\")\n            result = run_adb_command([\"exec-out\", \"screencap\", \"-p\"], text_mode=False)\n            if result.returncode != 0:\n                return \"\" if as_base64 or use_tempfile else None\n\n            screenshot = Image.open(io.BytesIO(result.stdout))\n\n            if use_tempfile or self.screenshot_as_tempfile:\n                with NamedTemporaryFile(delete=False, suffix=\".png\") as temp_file:\n                    screenshot.save(temp_file, format=\"PNG\")\n                    temp_file_path = temp_file.name\n                return temp_file_path\n\n            if as_base64 or self.screenshot_as_base64:\n                buffered = io.BytesIO()\n                screenshot.save(buffered, format=\"PNG\")\n                base64_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n                return base64_str\n\n            return screenshot\n        except Exception as e:\n            logger.exception(\"Error in screenshot\")\n            return \"\" if as_base64 or use_tempfile else None\n\n    def run_shell_command(self, command: str) -> bool:\n        try:\n            logger.debug(f\"Run shell command {command}\")\n            result = run_adb_command([\"shell\", command])\n            logger.info(result)\n            return True\n        except Exception as e:\n            logger.exception(f\"Error in run_shell_command {e}\")\n            return False\n"}
{"type": "source_file", "path": "clickclickclick/planner/task.py", "content": "import re\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, TimeoutError\nfrom typing import Callable, Any, Generator, List\n\nfrom . import logger\nfrom clickclickclick.config import BaseConfig\nfrom clickclickclick.executor import Executor\nfrom clickclickclick.finder import BaseFinder\nfrom . import Planner\nimport tempfile\nimport base64\n\ndef create_tempfile_from_base64(base64_string):\n    tmp = tempfile.NamedTemporaryFile(delete=False)\n    tmp.write(base64.b64decode(base64_string))\n    tmp.close()\n    return tmp.name\n\ndef save_screenshot(screenshot, is_base64):\n    if is_base64:\n        path = create_tempfile_from_base64(screenshot)\n        return path\n    return screenshot\n\ndef execute_task(\n    prompt: str, executor: Executor, planner: Planner, finder: BaseFinder, c: BaseConfig\n) -> bool:\n    try:\n\n        while True:\n            screenshot = executor.screenshot(\n                \"Planner took screenshot\",\n                executor.screenshot_as_base64,\n                executor.screenshot_as_tempfile,\n            )\n            logger.info(\"Generated screenshot\")\n            time.sleep(c.TASK_DELAY)\n\n            llm_responses = planner.llm_response(prompt, screenshot)\n            for func_name, func_args in llm_responses:\n                finder_output = None\n                logger.debug(f\"Executing {func_name} with {func_args}\")\n                (execution_output, executed_fn_name) = parse_and_execute(\n                    func_name, func_args, executor, planner, finder\n                )\n                if executed_fn_name == \"task_finished\":\n                    return True\n\n                if executed_fn_name == \"find_element_and_click\":\n                    logger.info(f\"Executed Finder with output: {execution_output}\")\n                    ui_element = func_args.get(\"prompt\", \"\")\n                    finder_output = execution_output\n\n                if executed_fn_name == \"find_element_and_long_press\":\n                    logger.info(f\"Executed Finder with output: {execution_output}\")\n                    ui_element = func_args.get(\"prompt\", \"\")\n                    finder_output = execution_output\n\n                if finder_output is not None:\n\n                    coordinates = list(map(int, finder_output.split(\",\")))\n                    scaled_coordinates = finder.scale_coordinates(coordinates)\n\n                    if executed_fn_name == \"find_element_and_click\":\n                        executor.click_at_a_point(\n                            (coordinates[0] + coordinates[2]) // 2,\n                            (coordinates[1] + coordinates[3]) // 2,\n                            \"Clicking center right away\",\n                        )\n                        message_text = \"and it has been clicked\"\n                    elif executed_fn_name == \"find_element_and_long_press\":\n\n                        executor.long_press_at_a_point(\n                            (coordinates[0] + coordinates[2]) // 2,\n                            (coordinates[1] + coordinates[3]) // 2,\n                            \"Clicking center right away\",\n                        )\n                        message_text = \"and it has been long pressed\"\n\n                    finder_output = \",\".join(map(str, scaled_coordinates))\n                    message = f\"The UI bounds of the {ui_element} is {finder_output} {message_text}\"\n                    planner.add_finder_message(message)\n\n                observation = func_args.get(\"observation\", \"\")\n\n    except Exception as e:\n        logger.exception(\"An error occurred during task execution.\")\n        return False\n        # raise e\n\ndef execute_task_with_generator(\n    prompt: str, executor: Executor, planner: Planner, finder: BaseFinder, c: BaseConfig\n) -> Generator[List[str], None, bool]:\n    try:\n        observation = \"\"\n        while True:\n            screenshot = executor.screenshot(\n                \"Planner took screenshot\",\n                executor.screenshot_as_base64,\n                executor.screenshot_as_tempfile,\n            )\n            logger.info(\"Generated screenshot\")\n            time.sleep(c.TASK_DELAY)\n\n            if executor.screenshot_as_base64:\n                yield [(create_tempfile_from_base64(screenshot), observation)]\n            else:\n                yield [(screenshot, observation)]\n            llm_responses = planner.llm_response(prompt, screenshot)\n            for func_name, func_args in llm_responses:\n                finder_output = None\n                logger.debug(f\"Executing {func_name} with {func_args}\")\n                (execution_output, executed_fn_name) = parse_and_execute(\n                    func_name, func_args, executor, planner, finder\n                )\n                if executed_fn_name == \"task_finished\":\n                    return True\n\n                if executed_fn_name == \"find_element_and_click\":\n                    logger.info(f\"Executed Finder with output: {execution_output}\")\n                    ui_element = func_args.get(\"prompt\", \"\")\n                    finder_output = execution_output\n\n                if executed_fn_name == \"find_element_and_long_press\":\n                    logger.info(f\"Executed Finder with output: {execution_output}\")\n                    ui_element = func_args.get(\"prompt\", \"\")\n                    finder_output = execution_output\n\n                if finder_output is not None:\n                    coordinates = list(map(int, finder_output.split(\",\")))\n                    scaled_coordinates = finder.scale_coordinates(coordinates)\n\n                    if executed_fn_name == \"find_element_and_click\":\n                        executor.click_at_a_point(\n                            (coordinates[0] + coordinates[2]) // 2,\n                            (coordinates[1] + coordinates[3]) // 2,\n                            \"Clicking center right away\",\n                        )\n                        message_text = \"and it has been clicked\"\n                    elif executed_fn_name == \"find_element_and_long_press\":\n                        executor.long_press_at_a_point(\n                            (coordinates[0] + coordinates[2]) // 2,\n                            (coordinates[1] + coordinates[3]) // 2,\n                            \"Clicking center right away\",\n                        )\n                        message_text = \"and it has been long pressed\"\n\n                    finder_output = \",\".join(map(str, scaled_coordinates))\n                    message = f\"The UI bounds of the {ui_element} is {finder_output} {message_text}\"\n                    planner.add_finder_message(message)\n\n                observation = func_args.get(\"observation\", \"\")\n\n    except Exception as e:\n        logger.exception(\"An error occurred during task execution.\")\n        raise e\n\n\n# TODO: move to utils\ndef execute_with_timeout(task, timeout, *args, **kwargs):\n    with ThreadPoolExecutor(max_workers=1) as executor:\n        future = executor.submit(task, *args, **kwargs)\n        try:\n            result = future.result(timeout=timeout)\n            return result\n        except TimeoutError:\n            logger.exception(\"Task did not complete within the timeout period.\")\n            return None\n\n\ndef parse_and_execute(\n    function_name: str, function_args: dict, executor: object, planner: object, finder: object\n) -> Any:\n    func_name = function_name\n    args = function_args if function_args is not None else []\n\n    func = get_function(func_name, executor, planner, finder)\n    return (func(**args), func_name)\n\n\ndef get_function(\n    name: str, executor: Executor, planner: Planner, finder: BaseFinder\n) -> Callable[..., Any]:\n    funcs = {\n        \"screenshot\": executor.screenshot,\n        \"find_element_and_click\": finder.find_element,\n        \"find_element_and_long_press\": finder.find_element,\n        \"move_mouse\": executor.move_mouse,\n        \"click_mouse\": executor.click_mouse,\n        \"type_text\": executor.type_text,\n        \"double_click_mouse\": executor.double_click_mouse,\n        \"right_click_mouse\": lambda: executor.click_mouse(button=\"right\"),\n        \"scroll_mouse\": executor.scroll,\n        \"press_key\": executor.press_key,\n        \"click_at_a_point\": executor.click_at_a_point,\n        \"long_press_at_a_point\": executor.long_press_at_a_point,\n        # \"apple_script\": executor.apple_script,\n        \"task_finished\": planner.task_finished,\n        \"swipe_right\": executor.swipe_right,\n        \"swipe_left\": executor.swipe_left,\n        \"swipe_up\": executor.swipe_up,\n        \"swipe_down\": executor.swipe_down,\n        \"navigate_back\": executor.navigate_back,\n        \"minimize_app\": executor.minimize_app,\n        \"volume_up\": executor.volume_up,\n        \"volume_down\": executor.volume_down,\n    }\n    func = funcs.get(name)\n    if func is None:\n        raise ValueError(f\"No such function: {name}\")\n    return func\n"}
