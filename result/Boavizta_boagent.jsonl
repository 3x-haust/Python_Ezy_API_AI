{"repo_info": {"repo_name": "boagent", "repo_owner": "Boavizta", "repo_url": "https://github.com/Boavizta/boagent"}}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/mocks/mocks.py", "content": "import os\n\ncurrent_dir = os.path.dirname(__file__)\nmock_power_data = os.path.join(f\"{current_dir}\", \"../mocks/power_data.json\")\nmock_hardware_data = os.path.join(f\"{current_dir}\", \"../mocks/hardware_data.json\")\nmock_boaviztapi_response_not_verbose = os.path.join(\n    f\"{current_dir}\", \"../mocks/boaviztapi_response_not_verbose.json\"\n)\nmock_boaviztapi_response_verbose = os.path.join(\n    f\"{current_dir}\", \"../mocks/boaviztapi_response_verbose.json\"\n)\nmock_formatted_scaphandre = os.path.join(\n    f\"{current_dir}\", \"../mocks/formatted_power_data_one_hour.json\"\n)\nmock_formatted_scaphandre_with_processes = os.path.join(\n    f\"{current_dir}\", \"../mocks/formatted_scaphandre.json\"\n)\nmock_get_metrics_not_verbose = os.path.join(\n    f\"{current_dir}\", \"../mocks/get_metrics_not_verbose.json\"\n)\nmock_get_metrics_verbose = os.path.join(\n    f\"{current_dir}\", \"../mocks/get_metrics_verbose.json\"\n)\nmock_get_metrics_verbose_no_hdd = os.path.join(\n    f\"{current_dir}\", \"../mocks/get_metrics_verbose_no_hdd.json\"\n)\nmock_lshw_data = os.path.join(f\"{current_dir}\", \"../mocks/lshw_data.json\")\nmock_lshw_data_disks = os.path.join(\n    f\"{current_dir}\", \"../mocks/sudo_lshw_data_disks.json\"\n)\nmock_sudo_lshw_data = os.path.join(f\"{current_dir}\", \"../mocks/sudo_lshw_data.json\")\nmock_nvme_data = os.path.join(f\"{current_dir}\", \"../mocks/nvme_data_sudo.json\")\nhardware_cli = os.path.join(f\"{current_dir}\", \"../../boagent/hardware/hardware_cli.py\")\nhardware_data = os.path.join(f\"{current_dir}\", \"../../boagent/api/hardware_data.json\")\n\n\nclass MockLshw:\n    def __init__(self):\n        self.cpus = {\n            \"cpus\": [\n                {\n                    \"units\": 1,\n                    \"name\": \"AMD Ryzen 5 5600H with Radeon Graphics\",\n                    \"manufacturer\": \"Advanced Micro Devices [AMD]\",\n                    \"core_units\": 6,\n                }\n            ]\n        }\n        self.memories = {\n            \"rams\": [\n                {\"units\": 1, \"manufacturer\": \"Samsung\", \"capacity\": 8},\n                {\"units\": 1, \"manufacturer\": \"Kingston\", \"capacity\": 16},\n            ]\n        }\n        self.disks = {\n            \"disks\": [\n                {\n                    \"units\": 1,\n                    \"logicalname\": \"/dev/nvme0n1\",\n                    \"manufacturer\": \"samsung\",\n                    \"type\": \"ssd\",\n                    \"capacity\": 476,\n                }\n            ],\n        }\n"}
{"type": "test_file", "path": "tests/api/test_api_unit.py", "content": "import os\nimport json\n\nfrom unittest import TestCase, TestSuite, TestLoader\nfrom unittest.mock import Mock, patch\n\nfrom boagent.api.api import (\n    build_hardware_data,\n    read_hardware_data,\n    get_hardware_data,\n    # query_machine_impact_data,\n    format_usage_request,\n    compute_average_consumption,\n    get_power_data,\n    get_metrics,\n)\nfrom boagent.api.utils import format_prometheus_output\nfrom tests.mocks.mocks import (\n    MockLshw,\n    hardware_data,\n    mock_power_data,\n    mock_hardware_data,\n    mock_boaviztapi_response_not_verbose,\n    mock_boaviztapi_response_verbose,\n    mock_formatted_scaphandre,\n    mock_get_metrics_verbose,\n    mock_get_metrics_not_verbose,\n)\n\nmocked_lshw = Mock()\nmocked_lshw.return_value = MockLshw()\n\n\n@patch(\"boagent.api.api.HARDWARE_FILE_PATH\", hardware_data)\n@patch(\"boagent.api.api.Lshw\", mocked_lshw)\nclass ReadHardwareDataTest(TestCase):\n    def test_build_hardware_data(self):\n\n        build_hardware_data()\n        assert os.path.exists(hardware_data) is True\n\n    def test_read_hardware_data(self):\n\n        build_hardware_data()\n        data = read_hardware_data()\n        assert type(data[\"cpus\"]) is dict\n        assert type(data[\"rams\"]) is dict\n        assert type(data[\"disks\"]) is dict\n\n    @patch(\"boagent.api.api.build_hardware_data\")\n    def test_get_hardware_data_with_fetch_hardware_false(self, mocked_build_hardware):\n\n        # Test case where hardware_data.json is already present on the\n        # filesystem through previous call to build_hardware_data\n\n        build_hardware_data()\n        data = get_hardware_data(fetch_hardware=False)\n        assert type(data) is dict\n        mocked_build_hardware.assert_not_called()\n\n    def test_get_hardware_data_with_fetch_hardware_true(self):\n\n        data = get_hardware_data(fetch_hardware=True)\n        assert type(data) is dict\n\n    def tearDown(self) -> None:\n        os.remove(hardware_data)\n\n\nclass FormatUsageRequestTest(TestCase):\n    def setUp(self) -> None:\n        self.start_time = 1710837858\n        self.end_time = 1710841458\n\n    def test_format_usage_request_with_start_and_end_times(self):\n\n        formatted_request = format_usage_request(\n            start_time=self.start_time,\n            end_time=self.end_time,\n        )\n\n        assert type(formatted_request) is dict\n        assert \"hours_use_time\" in formatted_request\n\n    def test_format_usage_request_with_host_avg_consumption_and_location(\n        self,\n    ):\n\n        location = \"FRA\"\n        avg_power = 120\n\n        formatted_request = format_usage_request(\n            start_time=self.start_time,\n            end_time=self.end_time,\n            location=location,\n            avg_power=avg_power,\n        )\n        assert type(formatted_request) is dict\n        assert \"avg_power\" in formatted_request\n        assert \"usage_location\" in formatted_request\n\n    def test_format_usage_request_with_time_workload_as_percentage(self):\n\n        time_workload = {\"time_workload\": 50.0}\n\n        formatted_request = format_usage_request(\n            start_time=self.start_time,\n            end_time=self.end_time,\n            time_workload=time_workload,\n        )\n\n        assert type(formatted_request) is dict\n        assert \"time_workload\" in formatted_request\n\n\nclass ComputeAvgConsumptionTest(TestCase):\n    def test_compute_average_consumption(self):\n\n        with open(mock_power_data, \"r\") as power_data_file:\n            # power_data = f\"[{power_data_file.read()}]\"\n            data = json.load(power_data_file)\n        avg_host = compute_average_consumption(data)\n\n        assert type(avg_host) is float\n\n\nclass FormatPrometheusOutput(TestCase):\n    def setUp(self):\n        self.get_metrics_response_not_verbose_path = mock_get_metrics_not_verbose\n        self.get_metrics_response_verbose_path = mock_get_metrics_verbose\n        self.components = [\n            \"assembly_1\",\n            \"cpu_1\",\n            \"ram_1\",\n            \"ssd_1\",\n            \"power_supply_1\",\n            \"case_1\",\n            \"motherboard_1\",\n        ]\n\n    def test_format_prometheus_output_with_get_metrics_not_verbose(self):\n\n        with open(mock_get_metrics_not_verbose, \"r\") as json_response:\n            response_to_format = json.load(json_response)\n\n        prometheus_output = format_prometheus_output(response_to_format, verbose=False)\n\n        assert type(prometheus_output) is str\n        assert len(prometheus_output) > 1\n        assert \"TYPE\" in prometheus_output\n        assert \"HELP\" in prometheus_output\n\n    def test_format_prometheus_output_with_get_metrics_verbose(self):\n\n        with open(mock_get_metrics_verbose, \"r\") as json_response:\n            response_to_format = json.load(json_response)\n\n        prometheus_output = format_prometheus_output(response_to_format, verbose=True)\n\n        assert type(prometheus_output) is str\n        assert len(prometheus_output) > 1\n        assert \"TYPE\" in prometheus_output\n        assert \"HELP\" in prometheus_output\n        assert all(component in prometheus_output for component in self.components)\n\n\nclass GetPowerDataTest(TestCase):\n    def setUp(self) -> None:\n        # One-hour interval\n        self.start_time = 1713776733\n        self.end_time = 1713780333\n        # Ten minutes interval\n        self.short_interval_start_time = 1713776733\n        self.short_interval_end_time = 1713777333\n\n        self.formatted_scaphandre = f\"{mock_formatted_scaphandre}\"\n\n    @patch(\"boagent.api.api.POWER_DATA_FILE_PATH\", mock_formatted_scaphandre)\n    def test_get_power_data(self):\n\n        power_data = get_power_data(self.start_time, self.end_time)\n\n        assert type(power_data) is dict\n        assert \"raw_data\" in power_data\n        assert \"avg_power\" in power_data\n        assert type(power_data[\"avg_power\"]) is float\n        assert power_data[\"avg_power\"] > 0\n\n    @patch(\"boagent.api.api.POWER_DATA_FILE_PATH\", mock_formatted_scaphandre)\n    def test_get_power_data_with_short_time_interval(self):\n\n        power_data = get_power_data(\n            self.short_interval_start_time, self.short_interval_end_time\n        )\n\n        assert type(power_data) is dict\n        assert \"raw_data\" in power_data\n        assert \"avg_power\" in power_data\n        assert \"warning\" in power_data\n\n\n@patch(\"boagent.api.api.read_hardware_data\")\n@patch(\"boagent.api.api.query_machine_impact_data\")\nclass GetMetricsNotVerboseNoScaphandreTest(TestCase):\n    def setUp(self) -> None:\n        self.time_workload_as_percentage = {\"time_workload\": 70.0}\n        self.time_workload_as_list_of_dicts = {\n            \"time_workload\": [\n                {\"time_percentage\": 50, \"load_percentage\": 0},\n                {\"time_percentage\": 25, \"load_percentage\": 60},\n                {\"time_percentage\": 25, \"load_percentage\": 100},\n            ]\n        }\n        self.start_time = 1710837858\n        self.end_time = 1710841458\n        self.verbose = False\n        self.location = \"FRA\"\n        self.measure_power = False\n        self.lifetime = 5.0\n        self.fetch_hardware = False\n\n        with open(mock_boaviztapi_response_not_verbose, \"r\") as file:\n            self.boaviztapi_data = json.load(file)\n\n        with open(mock_hardware_data, \"r\") as file:\n            self.hardware_data = json.load(file)\n\n    def test_get_metrics_with_time_workload_as_percentage(\n        self, mocked_read_hardware_data, mocked_query_machine_impact_data\n    ):\n\n        metrics = get_metrics(\n            self.start_time,\n            self.end_time,\n            self.verbose,\n            self.location,\n            self.measure_power,\n            self.lifetime,\n            self.fetch_hardware,\n            self.time_workload_as_percentage,\n        )\n\n        mocked_read_hardware_data.return_value = self.hardware_data\n        mocked_query_machine_impact_data.return_value = self.boaviztapi_data\n\n        assert type(metrics) is dict\n        assert \"emissions_calculation_data\" in metrics\n        assert \"embedded_emissions\" in metrics\n        assert \"embedded_abiotic_resources_depletion\" in metrics\n        assert \"embedded_primary_energy\" in metrics\n\n    def test_get_metrics_with_time_workload_as_list_of_dicts(\n        self, mocked_read_hardware_data, mocked_query_machine_impact_data\n    ):\n\n        metrics = get_metrics(\n            self.start_time,\n            self.end_time,\n            self.verbose,\n            self.location,\n            self.measure_power,\n            self.lifetime,\n            self.fetch_hardware,\n            self.time_workload_as_list_of_dicts,\n        )\n\n        mocked_read_hardware_data.return_value = self.hardware_data\n        mocked_query_machine_impact_data.return_value = self.boaviztapi_data\n\n        assert type(metrics) is dict\n        assert \"emissions_calculation_data\" in metrics\n        assert \"embedded_emissions\" in metrics\n        assert \"embedded_abiotic_resources_depletion\" in metrics\n        assert \"embedded_primary_energy\" in metrics\n\n    def test_get_metrics_with_default_location(\n        self, mocked_read_hardware_data, mocked_query_machine_impact_data\n    ):\n\n        metrics = get_metrics(\n            self.start_time,\n            self.end_time,\n            self.verbose,\n            \"EEE\",\n            self.measure_power,\n            self.lifetime,\n            self.fetch_hardware,\n            self.time_workload_as_list_of_dicts,\n        )\n\n        mocked_read_hardware_data.return_value = self.hardware_data\n        mocked_query_machine_impact_data.return_value = self.boaviztapi_data\n\n        assert type(metrics) is dict\n        assert \"location_warning\" in metrics\n\n    def test_get_metrics_with_no_set_location(\n        self, mocked_read_hardware_data, mocked_query_machine_impact_data\n    ):\n\n        empty_location = \"\"\n\n        metrics = get_metrics(\n            self.start_time,\n            self.end_time,\n            self.verbose,\n            empty_location,\n            self.measure_power,\n            self.lifetime,\n            self.fetch_hardware,\n            self.time_workload_as_list_of_dicts,\n        )\n\n        mocked_read_hardware_data.return_value = self.hardware_data\n        mocked_query_machine_impact_data.return_value = self.boaviztapi_data\n\n        print(len(empty_location))\n        assert type(metrics) is dict\n        assert \"location_warning\" in metrics\n\n\n@patch(\"boagent.api.api.read_hardware_data\")\n@patch(\"boagent.api.api.query_machine_impact_data\")\nclass GetMetricsVerboseNoScaphandreTest(TestCase):\n    def setUp(self) -> None:\n        self.time_workload_as_percentage = {\"time_workload\": 70.0}\n        self.time_workload_as_list_of_dicts = {\n            \"time_workload\": [\n                {\"time_percentage\": 50, \"load_percentage\": 0},\n                {\"time_percentage\": 25, \"load_percentage\": 60},\n                {\"time_percentage\": 25, \"load_percentage\": 100},\n            ]\n        }\n\n        self.start_time = 1710837858\n        self.end_time = 1710841458\n        self.verbose = True\n        self.location = \"FRA\"\n        self.measure_power = False\n        self.lifetime = 5.0\n        self.fetch_hardware = False\n\n        with open(mock_boaviztapi_response_verbose, \"r\") as file:\n            self.boaviztapi_data = json.load(file)\n\n        with open(mock_hardware_data, \"r\") as file:\n            self.hardware_data = json.load(file)\n\n    def test_get_metrics_verbose_with_time_workload_percentage(\n        self, mocked_read_hardware_data, mocked_query_machine_impact_data\n    ):\n\n        metrics = get_metrics(\n            self.start_time,\n            self.end_time,\n            self.verbose,\n            self.location,\n            self.measure_power,\n            self.lifetime,\n            self.fetch_hardware,\n            self.time_workload_as_percentage,\n        )\n\n        mocked_read_hardware_data.return_value = self.hardware_data\n        mocked_query_machine_impact_data.return_value = self.boaviztapi_data\n\n        assert type(metrics) is dict\n        assert \"emissions_calculation_data\" in metrics\n        assert \"embedded_emissions\" in metrics\n        assert \"embedded_abiotic_resources_depletion\" in metrics\n        assert \"embedded_primary_energy\" in metrics\n        assert \"raw_data\" in metrics\n        assert \"electricity_carbon_intensity\" in metrics\n\n    def test_get_metrics_verbose_with_time_workload_as_list_of_dicts(\n        self, mocked_read_hardware_data, mocked_query_machine_impact_data\n    ):\n\n        metrics = get_metrics(\n            self.start_time,\n            self.end_time,\n            self.verbose,\n            self.location,\n            self.measure_power,\n            self.lifetime,\n            self.fetch_hardware,\n            self.time_workload_as_list_of_dicts,\n        )\n\n        mocked_read_hardware_data.return_value = self.hardware_data\n        mocked_query_machine_impact_data.return_value = self.boaviztapi_data\n\n        assert type(metrics) is dict\n        assert \"emissions_calculation_data\" in metrics\n        assert \"embedded_emissions\" in metrics\n        assert \"embedded_abiotic_resources_depletion\" in metrics\n        assert \"embedded_primary_energy\" in metrics\n        assert \"raw_data\" in metrics\n        assert \"electricity_carbon_intensity\" in metrics\n\n\nclass GetMetricsVerboseWithScaphandreTest(TestCase):\n    def setUp(self) -> None:\n        self.start_time = 1710837858\n        self.end_time = 1710841458\n        self.verbose = True\n        self.location = \"FRA\"\n        self.measure_power = True\n        self.lifetime = 5.0\n        self.fetch_hardware = False\n\n        with open(mock_boaviztapi_response_verbose, \"r\") as file:\n            self.boaviztapi_data = json.load(file)\n\n        with open(mock_formatted_scaphandre, \"r\") as file:\n            power_data = {}\n            power_data[\"raw_data\"] = file.read()\n            power_data[\"avg_power\"] = 11.86\n            self.power_data = power_data\n\n        with open(mock_hardware_data, \"r\") as file:\n            self.hardware_data = json.load(file)\n\n    @patch(\"boagent.api.api.query_machine_impact_data\")\n    @patch(\"boagent.api.api.get_power_data\")\n    @patch(\"boagent.api.api.read_hardware_data\")\n    def test_get_metrics_verbose_with_scaphandre(\n        self,\n        mocked_read_hardware_data,\n        mocked_query_machine_impact_data,\n        mocked_power_data,\n    ):\n\n        metrics = get_metrics(\n            self.start_time,\n            self.end_time,\n            self.verbose,\n            self.location,\n            self.measure_power,\n            self.lifetime,\n            self.fetch_hardware,\n        )\n\n        mocked_read_hardware_data.return_value = self.hardware_data\n        mocked_query_machine_impact_data.return_value = self.boaviztapi_data\n        mocked_power_data.return_value = self.power_data\n\n        assert type(metrics) is dict\n        assert \"total_operational_emissions\" in metrics\n        assert \"total_operational_abiotic_resources_depletion\" in metrics\n        assert \"total_operational_primary_energy_consumed\" in metrics\n        assert \"start_time\" in metrics\n        assert \"end_time\" in metrics\n        assert \"average_power_measured\" in metrics\n        assert \"raw_data\" in metrics\n        assert \"electricity_carbon_intensity\" in metrics\n        assert \"power_data\" in metrics[\"raw_data\"]\n\n\nloader = TestLoader()\nsuite = TestSuite()\n\nsuite.addTests(loader.loadTestsFromTestCase(ReadHardwareDataTest))\nsuite.addTests(loader.loadTestsFromTestCase(FormatUsageRequestTest))\nsuite.addTests(loader.loadTestsFromTestCase(ComputeAvgConsumptionTest))\nsuite.addTests(loader.loadTestsFromTestCase(GetPowerDataTest))\nsuite.addTests(loader.loadTestsFromTestCase(GetMetricsNotVerboseNoScaphandreTest))\nsuite.addTests(loader.loadTestsFromTestCase(GetMetricsVerboseNoScaphandreTest))\nsuite.addTests(loader.loadTestsFromTestCase(GetMetricsVerboseWithScaphandreTest))\n"}
{"type": "test_file", "path": "tests/api/test_api_process.py", "content": "import json\nfrom unittest import TestCase, TestSuite, TestLoader\nfrom unittest.mock import patch\nfrom boagent.api.api import (\n    get_metrics,\n)\nfrom boagent.api.process import Process, InvalidPIDException\nfrom tests.mocks.mocks import (\n    mock_hardware_data,\n    mock_boaviztapi_response_not_verbose,\n    mock_get_metrics_verbose,\n    mock_get_metrics_verbose_no_hdd,\n)\n\n\n@patch(\"boagent.api.api.HARDWARE_FILE_PATH\", mock_hardware_data)\nclass AllocateEmbeddedImpactForProcess(TestCase):\n    def setUp(self):\n\n        self.start_time = 1710837858\n        self.end_time = 1710841458\n        self.verbose = False\n        self.location = \"EEE\"\n        self.measure_power = False\n        self.lifetime = 5.0\n        self.fetch_hardware = False\n        self.pid = 3099\n\n        with open(mock_boaviztapi_response_not_verbose, \"r\") as boaviztapi_data:\n            self.boaviztapi_data = json.load(boaviztapi_data)\n\n        with open(mock_get_metrics_verbose, \"r\") as get_metrics_verbose:\n            self.get_metrics_verbose = json.load(get_metrics_verbose)\n\n        with open(mock_get_metrics_verbose_no_hdd, \"r\") as get_metrics_verbose_no_hdd:\n            self.get_metrics_verbose_no_hdd = json.load(get_metrics_verbose_no_hdd)\n\n        self.process = Process(self.get_metrics_verbose, self.pid)\n\n    @patch(\"boagent.api.api.query_machine_impact_data\")\n    def test_get_total_embedded_impacts_for_host(\n        self, mocked_query_machine_impact_data\n    ):\n\n        mocked_query_machine_impact_data.return_value = self.boaviztapi_data\n\n        total_embedded_impacts_host = get_metrics(\n            self.start_time,\n            self.end_time,\n            self.verbose,\n            self.location,\n            self.measure_power,\n            self.lifetime,\n            self.fetch_hardware,\n        )\n\n        assert \"embedded_emissions\" in total_embedded_impacts_host\n        assert \"embedded_abiotic_resources_depletion\" in total_embedded_impacts_host\n        assert \"embedded_primary_energy\" in total_embedded_impacts_host\n\n    def test_get_process_info(self):\n\n        process_details = self.process.process_info\n        for process in process_details:\n            assert type(process) is dict\n            self.assertEqual(process[\"pid\"], 3099)\n            self.assertEqual(\n                process[\"exe\"], \"/snap/firefox/4336/usr/lib/firefox/firefox\"\n            )\n        assert type(process_details) is list\n\n    def test_get_process_name(self):\n\n        expected_process_name = \"firefox\"\n        process_name = self.process.process_name\n\n        self.assertEqual(expected_process_name, process_name)\n\n    def test_get_process_exe(self):\n\n        expected_process_exe = \"/snap/firefox/4336/usr/lib/firefox/firefox\"\n        process_exe = self.process.process_exe\n\n        self.assertEqual(expected_process_exe, process_exe)\n\n    def test_validate_pid_with_error_if_process_id_not_in_metrics(self):\n\n        expected_error_message = (\n            \"Process_id 1234 has not been found in metrics data. Check the queried PID.\"\n        )\n\n        with self.assertRaises(InvalidPIDException) as context_manager:\n            self.process = Process(self.get_metrics_verbose, 1234)\n\n        self.assertEqual(context_manager.exception.message, expected_error_message)\n\n        with self.assertRaises(InvalidPIDException) as context_manager:\n            self.process.pid = 1234\n\n        self.assertEqual(context_manager.exception.message, expected_error_message)\n\n    def test_get_total_ram_in_bytes(self):\n\n        expected_ram_total = 8589934592\n        total_ram_in_bytes = self.process.get_total_ram_in_bytes()\n        assert type(total_ram_in_bytes) is int\n        self.assertEqual(total_ram_in_bytes, expected_ram_total)\n\n    def test_get_process_ram_share_by_timestamp(self):\n\n        expected_ram_shares = [5.918979644775391, 0.0, 5.9177398681640625]\n        process_ram_shares = self.process.ram_shares\n        for index, ram_share in enumerate(process_ram_shares):\n            assert type(ram_share) is float\n            self.assertEqual(ram_share, expected_ram_shares[index])\n        assert type(process_ram_shares) is list\n\n    def test_get_disk_usage_in_bytes(self):\n        disk_total_bytes = int(\n            self.get_metrics_verbose[\"raw_data\"][\"power_data\"][\"raw_data\"][1][\"host\"][\n                \"components\"\n            ][\"disks\"][0][\"disk_total_bytes\"]\n        )\n        disk_available_bytes = int(\n            self.get_metrics_verbose[\"raw_data\"][\"power_data\"][\"raw_data\"][1][\"host\"][\n                \"components\"\n            ][\"disks\"][0][\"disk_available_bytes\"]\n        )\n        expected_disk_usage = disk_total_bytes - disk_available_bytes\n        disk_usage = self.process.get_disk_usage_in_bytes()\n        assert type(disk_usage) is int\n        self.assertEqual(expected_disk_usage, disk_usage)\n\n    def test_get_process_storage_share_by_timestamp(self):\n\n        expected_storage_shares = [0.0, 0.0, 0.0]\n        process_storage_shares = self.process.storage_shares\n        for index, storage_share in enumerate(process_storage_shares):\n            assert type(storage_share) is float\n            self.assertEqual(storage_share, expected_storage_shares[index])\n        assert type(process_storage_shares) is list\n\n    def test_get_embedded_impact_share_for_ssd_by_timestamp(self):\n\n        storage_embedded_impact_shares = (\n            self.process.get_component_embedded_impact_shares(\n                \"SSD\", self.process.storage_shares\n            )\n        )\n\n        for storage_embedded_impact_share in storage_embedded_impact_shares:\n            assert type(storage_embedded_impact_share) is tuple\n            for value in storage_embedded_impact_share:\n                assert type(storage_embedded_impact_share[1]) is float\n            assert type(storage_embedded_impact_shares)\n\n    def test_get_embedded_impact_share_for_hdd_by_timestamp(self):\n\n        storage_embedded_impact_shares = (\n            self.process.get_component_embedded_impact_shares(\n                \"HDD\", self.process.storage_shares\n            )\n        )\n\n        for storage_embedded_impact_share in storage_embedded_impact_shares:\n            assert type(storage_embedded_impact_share) is tuple\n            for value in storage_embedded_impact_share:\n                assert type(storage_embedded_impact_share[1]) is float\n            assert type(storage_embedded_impact_shares)\n\n    def test_get_embedded_impact_share_for_ram_by_timestamp(self):\n\n        ram_embedded_impact_shares = self.process.get_component_embedded_impact_shares(\n            \"RAM\", self.process.ram_shares\n        )\n\n        for ram_embedded_impact_share in ram_embedded_impact_shares:\n            assert type(ram_embedded_impact_share) is tuple\n            for value in ram_embedded_impact_share:\n                assert type(ram_embedded_impact_share[1]) is float\n        assert type(ram_embedded_impact_shares) is list\n\n    def test_get_process_cpu_load_shares_by_timestamp(self):\n\n        expected_cpu_load_shares = [5.9772415, 5.2776732, 2.9987452]\n        process_cpu_load_shares = self.process.cpu_load_shares\n\n        for index, cpu_load_share in enumerate(process_cpu_load_shares):\n            assert type(cpu_load_share) is float\n            self.assertEqual(cpu_load_share, expected_cpu_load_shares[index])\n        assert type(process_cpu_load_shares) is list\n\n    def test_get_embedded_impact_share_for_cpu_by_timestamp(self):\n\n        cpu_embedded_impact_shares = self.process.get_component_embedded_impact_shares(\n            \"CPU\", self.process.cpu_load_shares\n        )\n\n        for cpu_embedded_impact_share in cpu_embedded_impact_shares:\n            assert type(cpu_embedded_impact_share) is tuple\n        assert type(cpu_embedded_impact_shares) is list\n\n    def test_get_avg_min_max_embedded_impact_shares_for_cpu_and_ram(self):\n\n        impact_criterias = [\"gwp\", \"adp\", \"pe\"]\n        cpu_embedded_impact_values = self.process.get_component_embedded_impact_values(\n            \"cpu\"\n        )\n        ram_embedded_impact_values = self.process.get_component_embedded_impact_values(\n            \"ram\"\n        )\n\n        assert type(cpu_embedded_impact_values) is dict\n        assert type(ram_embedded_impact_values) is dict\n        for criteria in impact_criterias:\n            assert f\"{criteria}_cpu_average_impact\" in cpu_embedded_impact_values\n            assert f\"{criteria}_cpu_max_impact\" in cpu_embedded_impact_values\n            assert f\"{criteria}_cpu_min_impact\" in cpu_embedded_impact_values\n            assert f\"{criteria}_ram_average_impact\" in ram_embedded_impact_values\n            assert f\"{criteria}_ram_max_impact\" in ram_embedded_impact_values\n            assert f\"{criteria}_ram_min_impact\" in ram_embedded_impact_values\n\n    def test_get_embedded_impact_values_with_error_if_invalid_component_queried(self):\n\n        invalid_component_queried = self.process.get_component_embedded_impact_values(\n            \"invalid_component\"\n        )\n        assert (\n            invalid_component_queried\n            == \"Queried component is not available for evaluation.\"\n        )\n\n    def test_get_embedded_impact_values_for_ssd(self):\n\n        impact_criterias = [\"gwp\", \"adp\", \"pe\"]\n        ssd_embedded_impact_values = self.process.get_component_embedded_impact_values(\n            \"ssd\"\n        )\n\n        assert type(ssd_embedded_impact_values) is dict\n        for criteria in impact_criterias:\n            assert f\"{criteria}_ssd_average_impact\" in ssd_embedded_impact_values\n\n    def test_get_embedded_impact_values_for_hdd(self):\n\n        impact_criterias = [\"gwp\", \"adp\", \"pe\"]\n        hdd_embedded_impact_values = self.process.get_component_embedded_impact_values(\n            \"hdd\"\n        )\n\n        assert type(hdd_embedded_impact_values) is dict\n        for criteria in impact_criterias:\n            assert f\"{criteria}_hdd_average_impact\" in hdd_embedded_impact_values\n\n    def test_get_all_components_embedded_impact_values(self):\n\n        process_embedded_impacts = self.process.embedded_impact_values\n        self.assertIn(\"process_embedded_impacts\", process_embedded_impacts)\n        self.assertIn(\"pid\", process_embedded_impacts)\n        self.assertIn(\n            \"process_cpu_embedded_impact_values\",\n            process_embedded_impacts[\"process_embedded_impacts\"],\n        )\n        self.assertIn(\n            \"process_ram_embedded_impact_values\",\n            process_embedded_impacts[\"process_embedded_impacts\"],\n        )\n        self.assertIn(\n            \"process_ssd_embedded_impact_values\",\n            process_embedded_impacts[\"process_embedded_impacts\"],\n        )\n        self.assertIn(\n            \"process_hdd_embedded_impact_values\",\n            process_embedded_impacts[\"process_embedded_impacts\"],\n        )\n\n    def test_get_components_embedded_impact_values_with_hdd_absent_from_get_metrics(\n        self,\n    ):\n        self.process = Process(self.get_metrics_verbose_no_hdd, self.pid)\n        process_embedded_impacts = self.process.embedded_impact_values\n        self.assertIn(\"pid\", process_embedded_impacts)\n        self.assertIn(\"process_embedded_impacts\", process_embedded_impacts)\n        self.assertIn(\n            \"process_cpu_embedded_impact_values\",\n            process_embedded_impacts[\"process_embedded_impacts\"],\n        )\n        self.assertIn(\n            \"process_ram_embedded_impact_values\",\n            process_embedded_impacts[\"process_embedded_impacts\"],\n        )\n        self.assertIn(\n            \"process_ssd_embedded_impact_values\",\n            process_embedded_impacts[\"process_embedded_impacts\"],\n        )\n        self.assertNotIn(\n            \"process_hdd_embedded_impact_values\",\n            process_embedded_impacts[\"process_embedded_impacts\"],\n        )\n\n\nloader = TestLoader()\nsuite = TestSuite()\n\nsuite.addTests(loader.loadTestsFromTestCase(AllocateEmbeddedImpactForProcess))\n"}
{"type": "test_file", "path": "tests/hardware/test_hardwarecli.py", "content": "from json import load\nfrom unittest import TestCase\nfrom os.path import exists\nfrom unittest.mock import Mock, patch\nfrom hardware_cli import main\nfrom click.testing import CliRunner\nfrom tests.mocks.mocks import MockLshw, mock_lshw_data\n\n\n# Need to use a mock of `lshw` run without `sudo` to reproduce the error case\n# where hardware_cli is run without `sudo`.\nwith open(mock_lshw_data) as lshw_json:\n    lshw_data = load(lshw_json)\n\nmocked_lshw = Mock()\nmocked_lshw.return_value = MockLshw()\nmocked_is_tool = Mock()\nmocked_is_tool.return_value = True\nmocked_serialized_lshw_output = Mock()\nmocked_serialized_lshw_output.return_value = lshw_data\n\n\nclass HardwarecliTest(TestCase):\n    @patch(\"hardware_cli.Lshw\", mocked_lshw)\n    def test_write_hardware_json_file_from_hardware_cli_with_output_file_flag_on(self):\n\n        runner = CliRunner()\n        with runner.isolated_filesystem():\n            result_file_path = \"hardware_data.json\"\n\n            result = runner.invoke(main, [\"--output-file\", f\"./{result_file_path}\"])\n            assert exists(f\"./{result_file_path}\") is True\n\n        assert result.exit_code == 0\n\n    @patch(\"hardware_cli.Lshw\", mocked_lshw)\n    def test_read_stdout_from_hardware_cli(self):\n\n        runner = CliRunner()\n\n        result = runner.invoke(main)\n\n        assert result.exit_code == 0\n        assert result.output.count(\"disk\") >= 1\n        assert result.output.count(\"ram\") >= 1\n        assert result.output.count(\"cpu\") >= 1\n\n    @patch(\"boagent.hardware.lshw.is_tool\", mocked_is_tool)\n    @patch(\n        \"boagent.hardware.lshw.serialized_lshw_output\", mocked_serialized_lshw_output\n    )\n    def test_hardware_cli_returns_error_if_not_executed_with_sudo(self):\n        runner = CliRunner()\n        result = runner.invoke(main)\n        assert (\n            result.output.__contains__(\n                \"Hardware_cli was not executed with privileges, try `sudo ./hardware_cli.py`\"\n            )\n        ) is True\n"}
{"type": "test_file", "path": "tests/api/test_api_integration.py", "content": "import json\n\nfrom datetime import datetime, timedelta\nfrom fastapi.testclient import TestClient\nfrom unittest import TestCase\nfrom unittest.mock import patch\nfrom pytest import mark\nfrom boagent.api.config import Settings\nfrom tests.mocks.mocks import (\n    mock_boaviztapi_response_not_verbose,\n    mock_get_metrics_verbose,\n    mock_get_metrics_not_verbose,\n)\n\n# Mock settings for testing environment\nsettings = Settings(\n    hardware_file_path=\"./tests/mocks/hardware_data.json\",\n    db_path=\"./tests/mocks/boagent.db\",\n    power_file_path=\"./tests/mocks/power_data.json\",\n)\n\nfrom boagent.api.api import app  # noqa\n\nNOW_ISO8601 = datetime.now().isoformat()\nNOW_ISO8601_MINUS_ONE_MINUTE = datetime.fromisoformat(NOW_ISO8601) - timedelta(\n    minutes=1\n)\n\nclient = TestClient(app)\n\n\nclass ApiEndpointsTest(TestCase):\n    def setUp(self):\n        with open(\n            mock_boaviztapi_response_not_verbose, \"r\"\n        ) as boaviztapi_response_file:\n            self.boaviztapi_response_not_verbose = json.load(boaviztapi_response_file)\n\n        with open(mock_get_metrics_not_verbose, \"r\") as get_metrics_not_verbose_file:\n            self.get_metrics_not_verbose = json.load(get_metrics_not_verbose_file)\n        with open(mock_get_metrics_verbose, \"r\") as get_metrics_verbose_file:\n            self.get_metrics_verbose = json.load(get_metrics_verbose_file)\n\n    def test_read_info(self):\n        response = client.get(\"/info\")\n        assert response.status_code == 200\n\n    def test_read_web(self):\n        response = client.get(\"/web\")\n        assert response.status_code == 200\n\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_read_metrics_with_success(self, mocked_get_metrics):\n\n        mocked_get_metrics.return_value = self.get_metrics_not_verbose\n\n        params = {\n            \"start_time\": f\"{NOW_ISO8601_MINUS_ONE_MINUTE}\",\n            \"end_time\": f\"{NOW_ISO8601}\",\n            \"verbose\": \"false\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"false\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"false\",\n        }\n\n        response = client.get(\"/metrics\", params=params)\n        assert response.status_code == 200\n\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_read_metrics_with_verbose_with_success(self, mocked_get_metrics):\n\n        mocked_get_metrics.return_value = self.get_metrics_verbose\n\n        params = {\n            \"start_time\": f\"{NOW_ISO8601_MINUS_ONE_MINUTE}\",\n            \"end_time\": f\"{NOW_ISO8601}\",\n            \"verbose\": \"false\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"false\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"false\",\n        }\n\n        response = client.get(\"/metrics\", params=params)\n        assert response.status_code == 200\n\n    @mark.query\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_read_query_without_measure_power_and_fetch_hardware_with_success(\n        self, mocked_get_metrics\n    ):\n\n        mocked_get_metrics.return_value = self.boaviztapi_response_not_verbose\n\n        params = {\n            \"start_time\": f\"{NOW_ISO8601_MINUS_ONE_MINUTE}\",\n            \"end_time\": f\"{NOW_ISO8601}\",\n            \"verbose\": \"false\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"false\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"false\",\n        }\n\n        response = client.get(\"/query\", params=params)\n        assert response.status_code == 200\n\n    @mark.query\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_read_query_with_measure_power_with_success(self, mocked_get_metrics):\n\n        mocked_get_metrics.return_value = self.get_metrics_not_verbose\n\n        params = {\n            \"start_time\": f\"{NOW_ISO8601_MINUS_ONE_MINUTE}\",\n            \"end_time\": f\"{NOW_ISO8601}\",\n            \"verbose\": \"false\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"true\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"false\",\n        }\n\n        response = client.get(\"/query\", params=params)\n        assert response.status_code == 200\n\n    @mark.query\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_read_query_with_fetch_hardware_with_success(self, mocked_get_metrics):\n\n        mocked_get_metrics.return_value = self.get_metrics_not_verbose\n\n        params = {\n            \"start_time\": f\"{NOW_ISO8601_MINUS_ONE_MINUTE}\",\n            \"end_time\": f\"{NOW_ISO8601}\",\n            \"verbose\": \"false\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"false\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"true\",\n        }\n\n        response = client.get(\"query\", params=params)\n        assert response.status_code == 200\n\n    @mark.query\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_read_query_with_measure_power_and_fetch_hardware(self, mocked_get_metrics):\n\n        mocked_get_metrics.return_value = self.boaviztapi_response_not_verbose\n\n        params = {\n            \"start_time\": f\"{NOW_ISO8601_MINUS_ONE_MINUTE}\",\n            \"end_time\": f\"{NOW_ISO8601}\",\n            \"verbose\": \"false\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"true\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"true\",\n        }\n\n        response = client.get(\"/query\", params=params)\n        assert response.status_code == 200\n\n    @mark.query\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_read_query_with_measure_power_and_fetch_hardware_verbose(\n        self, mocked_get_metrics\n    ):\n\n        mocked_get_metrics.return_value = self.get_metrics_verbose\n\n        params = {\n            \"start_time\": f\"{NOW_ISO8601_MINUS_ONE_MINUTE}\",\n            \"end_time\": f\"{NOW_ISO8601}\",\n            \"verbose\": \"true\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"true\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"true\",\n        }\n\n        response = client.get(\"/query\", params=params)\n        assert response.status_code == 200\n\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_get_process_embedded_impacts_with_success(self, mocked_get_metrics):\n        mocked_get_metrics.return_value = self.get_metrics_verbose\n        params = {\n            \"process_id\": 3099,\n            \"start_time\": \"1717500637.2979465\",\n            \"end_time\": \"1717504237.2979465\",\n            \"verbose\": \"true\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"true\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"true\",\n        }\n        response = client.get(\"/process_embedded_impacts\", params=params)\n        assert response.status_code == 200\n        self.assertIn(\"pid\", response.json())\n        self.assertEqual(response.json()[\"pid\"], 3099)\n        self.assertIn(\"process_embedded_impacts\", response.json())\n        self.assertIn(\n            \"process_cpu_embedded_impact_values\",\n            response.json()[\"process_embedded_impacts\"],\n        )\n        self.assertIn(\n            \"process_ram_embedded_impact_values\",\n            response.json()[\"process_embedded_impacts\"],\n        )\n        self.assertIn(\n            \"process_ssd_embedded_impact_values\",\n            response.json()[\"process_embedded_impacts\"],\n        )\n        self.assertIn(\n            \"process_hdd_embedded_impact_values\",\n            response.json()[\"process_embedded_impacts\"],\n        )\n\n    @patch(\"boagent.api.api.get_metrics\")\n    def test_get_process_embedded_impacts_with_error_if_pid_not_found_in_metrics_data(\n        self, mocked_get_metrics\n    ):\n\n        mocked_get_metrics.return_value = self.get_metrics_verbose\n        params = {\n            \"process_id\": 1234,\n            \"start_time\": \"1717500637.2979465\",\n            \"end_time\": \"1717504237.2979465\",\n            \"verbose\": \"true\",\n            \"location\": \"FRA\",\n            \"measure_power\": \"true\",\n            \"lifetime\": 5,\n            \"fetch_hardware\": \"true\",\n        }\n\n        response = client.get(\"/process_embedded_impacts\", params=params)\n        error_message = (\n            \"Process_id 1234 has not been found in metrics data. Check the queried PID.\"\n        )\n        self.assertEqual(response.status_code, 400)\n        self.assertIs(error_message in response.text, True)\n"}
{"type": "test_file", "path": "tests/hardware/test_lshw.py", "content": "from unittest import TestCase\nfrom boagent.hardware.lshw import Lshw\nfrom unittest.mock import Mock, patch\nfrom json import load\n\nfrom tests.mocks.mocks import mock_sudo_lshw_data, mock_lshw_data_disks, mock_nvme_data\n\nwith open(mock_sudo_lshw_data) as lshw_json:\n    lshw_data = load(lshw_json)\nwith open(mock_nvme_data) as nvme_json:\n    nvme_data = load(nvme_json)\n\nmocked_is_tool = Mock()\nmocked_is_tool.return_value = True\nmocked_serialized_lshw_output = Mock()\nmocked_serialized_lshw_output.return_value = lshw_data\nmocked_serialized_nvme_output = Mock()\nmocked_serialized_nvme_output.return_value = nvme_data\n\n\nclass LshwTest(TestCase):\n    @patch(\"boagent.hardware.lshw.is_tool\", mocked_is_tool)\n    @patch(\n        \"boagent.hardware.lshw.serialized_lshw_output\", mocked_serialized_lshw_output\n    )\n    @patch(\n        \"boagent.hardware.lshw.serialized_nvme_output\", mocked_serialized_nvme_output\n    )\n    def setUp(self):\n        self.lshw = Lshw()\n        self.cpu_data = self.lshw.cpus\n        self.storage_data = self.lshw.disks\n        self.ram_data = self.lshw.memories\n\n    def test_read_get_hw_linux_cpu(self):\n        cpu_data = self.lshw.get_hw_linux(\"cpu\")\n\n        assert type(cpu_data) is list\n\n    def test_read_get_hw_linux_storage(self):\n        storage_data = self.lshw.get_hw_linux(\"storage\")\n\n        assert type(storage_data) is list\n\n    def test_read_get_hw_linux_memory(self):\n        memory_data = self.lshw.get_hw_linux(\"memory\")\n\n        assert type(memory_data) is list\n\n    def test_read_cpus_vendor(self):\n\n        for cpu in self.cpu_data:\n            assert \"manufacturer\" in cpu\n            assert type(cpu[\"manufacturer\"]) is str\n            assert cpu[\"manufacturer\"] == \"Advanced Micro Devices [AMD]\"\n\n    def test_read_cpus_name(self):\n\n        for cpu in self.cpu_data:\n            assert \"name\" in cpu\n            assert type(cpu[\"name\"]) is str\n            assert cpu[\"name\"] == \"AMD Ryzen 5 5600H with Radeon Graphics\"\n\n    def test_read_cpus_core_units(self):\n\n        for cpu in self.cpu_data:\n            assert \"core_units\" in cpu\n            assert type(cpu[\"core_units\"]) is int\n            assert cpu[\"core_units\"] == 6\n\n    def test_read_cpus_units(self):\n\n        for cpu in self.cpu_data:\n            assert \"units\" in cpu\n            assert type(cpu[\"units\"]) is int\n            assert cpu[\"units\"] == 1\n\n    def test_read_check_disk_vendor_with_correct_model(self):\n\n        model = \"LENOVO 123456154\"\n        result = self.lshw.check_disk_vendor(model)\n\n        assert result == \"LENOVO\"\n\n    def test_read_check_disk_vendor_with_incorrect_model(self):\n\n        model = \"12345121 LENOVO\"\n        result = self.lshw.check_disk_vendor(model)\n\n        assert result == \"LENOVO\"\n\n    def test_read_check_disk_vendor_with_one_correct_string_in_model(self):\n\n        model = \"LENOVO\"\n        result = self.lshw.check_disk_vendor(model)\n\n        assert result == \"LENOVO\"\n\n    def test_read_check_disk_vendor_with_one_incorrect_string_in_model(self):\n\n        model = \"12345211\"\n        with self.assertRaises(Exception):\n            self.lshw.check_disk_vendor(model)\n\n    def test_read_check_disk_vendor_with_multiple_strings_in_model(self):\n\n        model = \"LENOVO 123456 MODEL\"\n        result = self.lshw.check_disk_vendor(model)\n\n        assert result == \"LENOVO\"\n\n    def test_read_disks_type(self):\n\n        for disk in self.storage_data:\n            assert \"type\" in disk\n            assert type(disk[\"type\"]) is str\n            assert disk[\"type\"] == \"ssd\"\n\n    def test_read_disk_dev_name(self):\n\n        for disk in self.storage_data:\n            assert \"logicalname\" in disk\n            assert type(disk[\"logicalname\"]) is str\n            assert disk[\"logicalname\"] == \"/dev/nvme0n1\"\n\n    @patch(\"boagent.hardware.lshw.Lshw.get_rotational_int\")\n    def test_check_disk_type_is_ssd(self, mocked_get_rotational):\n\n        dev_logicalname = \"/dev/ssdonsata\"\n        mocked_get_rotational.return_value = 0\n\n        disk_type = self.lshw.get_disk_type(dev_logicalname)\n        assert disk_type == \"ssd\"\n\n    @patch(\"boagent.hardware.lshw.Lshw.get_rotational_int\")\n    def test_check_disk_type_is_hdd(self, mocked_get_rotational):\n\n        dev_logicalname = \"/dev/sdaex\"\n        mocked_get_rotational.return_value = 1\n\n        disk_type = self.lshw.get_disk_type(dev_logicalname)\n        assert disk_type == \"hdd\"\n\n    def test_int_for_get_rotational_int_when_file_not_found(self):\n\n        dev_erroneous_name = \"/dev/thisnameleadstonorotational\"\n        rotational_int = self.lshw.get_rotational_int(dev_erroneous_name)\n\n        self.assertEqual(rotational_int, 2)\n\n    def test_read_disk_type_when_dev_path_not_found(self):\n\n        dev_erroneous_name = \"/dev/thisnamedoesntexist\"\n        disk_type = self.lshw.get_disk_type(dev_erroneous_name)\n        assert disk_type == \"unknown\"\n\n    @patch(\"boagent.hardware.lshw.is_tool\")\n    def test_check_lshw_is_installed_to_parse_hardware_data_and_raises_error_if_not(\n        self, mocked_is_tool\n    ):\n        mocked_is_tool.return_value = False\n        with self.assertRaises(Exception) as context:\n            self.lshw.__init__()\n        self.assertTrue(\"lshw does not seem to be installed\" in str(context.exception))\n\n    @patch(\"boagent.hardware.lshw.is_tool\")\n    def test_check_nvme_cli_is_installed_to_find_storage_and_raises_error_if_not(\n        self, mocked_is_tool\n    ):\n        mocked_is_tool.return_value = False\n\n        with open(mock_lshw_data_disks, \"r\") as file, self.assertRaises(\n            Exception\n        ) as nvme_cli_exception:\n            data = load(file)\n            self.lshw.find_storage(data)\n\n        caught_exception = nvme_cli_exception.exception\n        assert str(caught_exception) == \"nvme-cli >= 1.0 does not seem to be installed\"\n\n    def test_read_disks_manufacturer(self):\n\n        for disk in self.storage_data:\n            assert \"manufacturer\" in disk\n            assert type(disk[\"manufacturer\"]) is str\n            assert disk[\"manufacturer\"] == \"toshiba\"\n\n    def test_read_disks_capacity(self):\n\n        for disk in self.storage_data:\n            assert \"capacity\" in disk\n            assert type(disk[\"capacity\"]) is int\n            assert disk[\"capacity\"] == 238\n\n    def test_read_disks_units(self):\n\n        for disk in self.storage_data:\n            assert \"units\" in disk\n            assert type(disk[\"units\"]) is int\n            assert disk[\"units\"] == 1\n\n    def test_read_ram_manufacturer(self):\n\n        for ram in self.ram_data:\n            assert \"manufacturer\" in ram\n            assert type(ram[\"manufacturer\"]) is str\n            assert ram[\"manufacturer\"] == \"Samsung\"\n\n    def test_read_ram_capacity(self):\n\n        for ram in self.ram_data:\n            assert \"capacity\" in ram\n            assert type(ram[\"capacity\"]) is int\n            assert ram[\"capacity\"] == 8\n\n    def test_read_ram_units(self):\n\n        for ram in self.ram_data:\n            assert \"units\" in ram\n            assert type(ram[\"units\"]) is int\n            assert ram[\"units\"] == 1\n"}
{"type": "source_file", "path": "boagent/__init__.py", "content": "\"\"\"\nBoagent\n\nMonitoring agent/framework for evaluating the environmental impacts of a machine and its applications, including several to all steps of the life cycle of the machine and service, plus multiple criterias of impacts (not just CO2eq metrics / Global Warming Potential). Part of the efforts of https://boavizta.org/en and https://sdialliance.org/.\n\"\"\"\n\n__version__ = \"0.1.0\"\n__author__ = \"Boavizta <open-source@boavizta.org>\"\n__credits__ = \"Boavizta contributors\"\n"}
{"type": "source_file", "path": "boagent/api/api.py", "content": "import json\nimport time\nfrom typing import Dict, Any, List, Union\nfrom fastapi import FastAPI, Response, Body, HTTPException\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import HTMLResponse\nfrom boaviztapi_sdk.api.server_api import ServerApi\nfrom boaviztapi_sdk.models.server import Server\nfrom boagent.api.exceptions import InvalidPIDException\nfrom boagent.hardware.lshw import Lshw\nfrom .utils import (\n    iso8601_or_timestamp_as_timestamp,\n    format_prometheus_output,\n    get_boavizta_api_client,\n    sort_ram,\n    sort_disks,\n)\n\nfrom .config import Settings\nfrom .process import Process\nfrom .models import WorkloadTime, time_workload_example\n\nsettings = Settings()\n\nHARDWARE_FILE_PATH = settings.hardware_file_path\nPOWER_DATA_FILE_PATH = settings.power_file_path\nPUBLIC_PATH = settings.public_path\nASSETS_PATH = settings.assets_path\nDB_PATH = settings.db_path\nDEFAULT_LIFETIME = settings.default_lifetime\nSECONDS_IN_ONE_YEAR = settings.seconds_in_one_year\nHARDWARE_CLI = settings.hardware_cli\nAZURE_LOCATION = settings.azure_location\nBOAVIZTAPI_ENDPOINT = settings.boaviztapi_endpoint\nCARBON_AWARE_API_ENDPOINT = settings.carbon_aware_api_endpoint\nCARBON_AWARE_API_TOKEN = settings.carbon_aware_api_token\nPROJECT_NAME = settings.project_name\nPROJECT_VERSION = settings.project_version\nPROJECT_DESCRIPTION = settings.project_description\nTAGS_METADATA = settings.tags_metadata\n\n\ndef configure_static(app):\n    app.mount(\"/assets\", StaticFiles(directory=ASSETS_PATH), name=\"assets\")\n\n\ndef configure_app():\n    app = FastAPI(\n        title=PROJECT_NAME,\n        version=PROJECT_VERSION,\n        description=PROJECT_DESCRIPTION,\n        contact={\"name\": \"Boavizta Members\", \"url\": \"https://boavizta.org/en\"},\n        license_info={\"name\": \"Apache-2.0\"},\n        openapi_tags=TAGS_METADATA,\n    )\n    configure_static(app)\n    return app\n\n\napp = configure_app()\n\n\n@app.get(\"/info\", tags=[\"info\"])\nasync def info():\n    return {\n        \"seconds_in_one_year\": SECONDS_IN_ONE_YEAR,\n        \"default_lifetime\": DEFAULT_LIFETIME,\n        \"hardware_file_path\": HARDWARE_FILE_PATH,\n        \"power_file_path\": POWER_DATA_FILE_PATH,\n        \"hardware_cli\": HARDWARE_CLI,\n        \"boaviztapi_endpoint\": BOAVIZTAPI_ENDPOINT,\n    }\n\n\n@app.get(\"/web\", tags=[\"web\"], response_class=HTMLResponse)\nasync def web():\n    res = \"\"\n    with open(\"{}/index.html\".format(PUBLIC_PATH), \"r\") as fd:\n        res = fd.read()\n    fd.close()\n    return res\n\n\n@app.get(\"/metrics\", tags=[\"metrics\"])\nasync def metrics(\n    start_time: str = \"0.0\",\n    end_time: str = \"0.0\",\n    verbose: bool = False,\n    location: str = \"\",\n    measure_power: bool = True,\n    lifetime: float = DEFAULT_LIFETIME,\n    fetch_hardware: bool = False,\n):\n    return Response(\n        content=format_prometheus_output(\n            get_metrics(\n                iso8601_or_timestamp_as_timestamp(start_time),\n                iso8601_or_timestamp_as_timestamp(end_time),\n                verbose,\n                location,\n                measure_power,\n                lifetime,\n                fetch_hardware,\n            ),\n            verbose,\n        ),\n        media_type=\"plain-text\",\n    )\n\n\n@app.get(\"/query\", tags=[\"query\"])\nasync def query(\n    start_time: str = \"0.0\",\n    end_time: str = \"0.0\",\n    verbose: bool = False,\n    location: str = \"EEE\",\n    measure_power: bool = True,\n    lifetime: float = DEFAULT_LIFETIME,\n    fetch_hardware: bool = False,\n):\n    \"\"\"\n    start_time: Start time for evaluation. Accepts either UNIX Timestamp or ISO8601 date format. \\n\n    end_time: End time for evaluation. Accepts either UNIX Timestamp or ISO8601 date format. \\n\n    verbose: Get detailled metrics with extra information.\\n\n    location: Country code to configure the local electricity grid to take into account.\\n\n    measure_power: Get electricity consumption metrics from Scaphandre or not.\\n\n    lifetime: Full lifetime of the machine to evaluate.\\n\n    fetch_hardware: Regenerate hardware.json file with current machine hardware or not.\\n\n    \"\"\"\n    return get_metrics(\n        iso8601_or_timestamp_as_timestamp(start_time),\n        iso8601_or_timestamp_as_timestamp(end_time),\n        verbose,\n        location,\n        measure_power,\n        lifetime,\n        fetch_hardware,\n    )\n\n\n@app.post(\"/query\", tags=[\"query\"])\nasync def query_with_time_workload(\n    start_time: str = \"0.0\",\n    end_time: str = \"0.0\",\n    verbose: bool = False,\n    location: str = \"EEE\",\n    measure_power: bool = True,\n    lifetime: float = DEFAULT_LIFETIME,\n    fetch_hardware: bool = False,\n    time_workload: Union[dict[str, float], dict[str, List[WorkloadTime]]] = Body(\n        None, example=time_workload_example\n    ),\n):\n    \"\"\"\n    start_time: Start time for evaluation. Accepts either UNIX Timestamp or ISO8601 date format. \\n\n    end_time: End time for evaluation. Accepts either UNIX Timestamp or ISO8601 date format. \\n\n    verbose: Get detailled metrics with extra information.\\n\n    location: Country code to configure the local electricity grid to take into account.\\n\n    measure_power: Get electricity consumption metrics from Scaphandre or not.\\n\n    lifetime: Full lifetime of the machine to evaluate.\\n\n    fetch_hardware: Regenerate hardware.json file with current machine hardware or not.\\n\n    time_workload: Workload percentage for CPU and RAM. Can be a float or a list of dictionaries with format\n    {\"time_percentage\": float, \"load_percentage\": float}\n    \"\"\"\n    return get_metrics(\n        iso8601_or_timestamp_as_timestamp(start_time),\n        iso8601_or_timestamp_as_timestamp(end_time),\n        verbose,\n        location,\n        measure_power,\n        lifetime,\n        fetch_hardware,\n        time_workload,\n    )\n\n\n@app.get(\"/process_embedded_impacts\", tags=[\"process\"])\nasync def process_embedded_impacts(\n    process_id: int = 0,\n    start_time: str = \"0.0\",\n    end_time: str = \"0.0\",\n    location: str = \"EEE\",\n    lifetime: float = DEFAULT_LIFETIME,\n    fetch_hardware: bool = False,\n):\n    \"\"\"\n    process_id: The process ID queried to be evaluated for embedded impacts for each available component. \\n\n    start_time: Start time for evaluation. Accepts either UNIX Timestamp or ISO8601 date format. \\n\n    end_time: End time for evaluation. Accepts either UNIX Timestamp or ISO8601 date format. \\n\n    location: Country code to configure the local electricity grid to take into account.\\n\n    lifetime: Full lifetime of the machine to evaluate.\\n\n    \"\"\"\n\n    verbose = True\n    measure_power = True\n\n    metrics_data = get_metrics(\n        iso8601_or_timestamp_as_timestamp(start_time),\n        iso8601_or_timestamp_as_timestamp(end_time),\n        verbose,\n        location,\n        measure_power,\n        lifetime,\n        fetch_hardware,\n    )\n    try:\n        queried_process = Process(metrics_data, process_id)\n    except InvalidPIDException as invalid_pid:\n        raise HTTPException(status_code=400, detail=invalid_pid.message)\n    else:\n        process_embedded_impact_values = queried_process.embedded_impact_values\n        json_content = json.dumps(process_embedded_impact_values)\n        return Response(status_code=200, content=json_content)\n\n\ndef get_metrics(\n    start_time: float,\n    end_time: float,\n    verbose: bool,\n    location: str,\n    measure_power: bool,\n    lifetime: float,\n    fetch_hardware: bool,\n    time_workload: Union[dict[str, float], dict[str, List[WorkloadTime]], None] = None,\n):\n\n    now: float = time.time()\n    if start_time and end_time:\n        ratio = (end_time - start_time) / (lifetime * SECONDS_IN_ONE_YEAR)\n    else:\n        ratio = 1.0\n    if start_time == 0.0:\n        start_time = now - 3600\n    if end_time == 0.0:\n        end_time = now\n    if end_time - start_time >= lifetime * SECONDS_IN_ONE_YEAR:\n        lifetime = (end_time - start_time) / float(SECONDS_IN_ONE_YEAR)\n\n    hardware_data = get_hardware_data(fetch_hardware)\n\n    res = {\"emissions_calculation_data\": {}}\n\n    avg_power = None\n\n    if len(location) < 3 or location == \"EEE\":\n        res[\"location_warning\"] = {\n            \"warning_message\": \"Location is either set as default, or has not been set, and is therefore set to the default BoaviztAPI location. \"\n            \"Be aware that the presented results can be drastically different due to location. \"\n            \"It is recommended that you set the asset location with the corresponding country code, see: https://doc.api.boavizta.org/Explanations/usage/countries/\"\n        }\n\n    if measure_power:\n        power_data = get_power_data(start_time, end_time)\n        avg_power = power_data[\"avg_power\"]\n        if \"warning\" in power_data:\n            res[\"emissions_calculation_data\"][\n                \"energy_consumption_warning\"\n            ] = power_data[\"warning\"]\n\n    boaviztapi_data = query_machine_impact_data(\n        model={},\n        configuration=hardware_data,\n        usage=format_usage_request(\n            start_time, end_time, avg_power, location, time_workload\n        ),\n    )\n\n    if measure_power:\n        res[\"total_operational_emissions\"] = {\n            \"value\": boaviztapi_data[\"impacts\"][\"gwp\"][\"use\"],\n            \"description\": \"GHG emissions related to usage, from start_time to end_time.\",\n            \"type\": \"gauge\",\n            \"unit\": \"kg CO2eq\",\n            \"long_unit\": \"kilograms CO2 equivalent\",\n        }\n        res[\"total_operational_abiotic_resources_depletion\"] = {\n            \"value\": boaviztapi_data[\"impacts\"][\"adp\"][\"use\"],\n            \"description\": \"Abiotic Resources Depletion (minerals & metals, ADPe) due to the usage phase.\",\n            \"type\": \"gauge\",\n            \"unit\": \"kgSbeq\",\n            \"long_unit\": \"kilograms Antimony equivalent\",\n        }\n        res[\"total_operational_primary_energy_consumed\"] = {\n            \"value\": boaviztapi_data[\"impacts\"][\"pe\"][\"use\"],\n            \"description\": \"Primary Energy consumed due to the usage phase.\",\n            \"type\": \"gauge\",\n            \"unit\": \"MJ\",\n            \"long_unit\": \"Mega Joules\",\n        }\n        res[\"start_time\"] = {\n            \"value\": start_time,\n            \"description\": \"Start time for the evaluation, in timestamp format (seconds since 1970)\",\n            \"type\": \"counter\",\n            \"unit\": \"s\",\n            \"long_unit\": \"seconds\",\n        }\n        res[\"end_time\"] = {\n            \"value\": end_time,\n            \"description\": \"End time for the evaluation, in timestamp format (seconds since 1970)\",\n            \"type\": \"counter\",\n            \"unit\": \"s\",\n            \"long_unit\": \"seconds\",\n        }\n        res[\"average_power_measured\"] = {\n            \"value\": avg_power,\n            \"description\": \"Average power measured from start_time to end_time\",\n            \"type\": \"gauge\",\n            \"unit\": \"W\",\n            \"long_unit\": \"Watts\",\n        }\n\n    \"\"\" res[\"calculated_emissions\"] = {\n        \"value\": boaviztapi_data[\"impacts\"][\"gwp\"][\"value\"] * ratio\n        + boaviztapi_data[\"impacts\"][\"gwp\"][\"use\"][\"value\"],\n        \"description\": \"Total Green House Gas emissions calculated for manufacturing and usage phases, between \"\n        \"start_time and end_time\",\n        \"type\": \"gauge\",\n        \"unit\": \"kg CO2eq\",\n        \"long_unit\": \"kilograms CO2 equivalent\",\n    } \"\"\"\n\n    res[\"embedded_emissions\"] = {\n        \"value\": boaviztapi_data[\"impacts\"][\"gwp\"][\"embedded\"][\"value\"] * ratio,\n        \"description\": \"Embedded carbon emissions (manufacturing phase)\",\n        \"type\": \"gauge\",\n        \"unit\": \"kg CO2eq\",\n        \"long_unit\": \"kilograms CO2 equivalent\",\n    }\n    res[\"embedded_abiotic_resources_depletion\"] = {\n        \"value\": boaviztapi_data[\"impacts\"][\"adp\"][\"embedded\"][\"value\"] * ratio,\n        \"description\": \"Embedded abiotic ressources consumed (manufacturing phase)\",\n        \"type\": \"gauge\",\n        \"unit\": \"kg Sbeq\",\n        \"long_unit\": \"kilograms ADP equivalent\",\n    }\n    res[\"embedded_primary_energy\"] = {\n        \"value\": boaviztapi_data[\"impacts\"][\"pe\"][\"embedded\"][\"value\"] * ratio,\n        \"description\": \"Embedded primary energy consumed (manufacturing phase)\",\n        \"type\": \"gauge\",\n        \"unit\": \"MJ\",\n        \"long_unit\": \"Mega Joules\",\n    }\n\n    if verbose:\n        res[\"raw_data\"] = {\n            \"hardware_data\": hardware_data,\n            \"resources_data\": \"not implemented yet\",\n            \"boaviztapi_data\": boaviztapi_data,\n            \"start_time\": start_time,\n            \"end_time\": end_time,\n        }\n        res[\"electricity_carbon_intensity\"] = {\n            \"value\": boaviztapi_data[\"verbose\"][\"gwp_factor\"][\"value\"],\n            \"description\": \"Carbon intensity of the electricity mix. Mix considered : {}\".format(\n                location\n            ),\n            \"type\": \"gauge\",\n            \"unit\": \"kg CO2eq / kWh\",\n            \"long_unit\": \"Kilograms CO2 equivalent per KiloWattHour\",\n        }\n\n        if measure_power:\n            res[\"raw_data\"][\"power_data\"] = power_data\n\n    return res\n\n\ndef format_usage_request(\n    start_time: float,\n    end_time: float,\n    avg_power: Union[float, None] = None,\n    location: str = \"EEE\",\n    time_workload: Union[dict[str, float], dict[str, List[WorkloadTime]], None] = None,\n):\n    hours_use_time = (end_time - start_time) / 3600.0\n    kwargs_usage = {\"hours_use_time\": hours_use_time}\n    if location:\n        kwargs_usage[\"usage_location\"] = location\n    if avg_power:\n        kwargs_usage[\"avg_power\"] = avg_power\n    if time_workload:\n        kwargs_usage[\"time_workload\"] = time_workload\n    return kwargs_usage\n\n\ndef get_power_data(start_time, end_time):\n    # Get all items of the json list where start_time <= host.timestamp <= end_time\n    power_data = {}\n    with open(POWER_DATA_FILE_PATH, \"r\") as power_data_file:\n        formatted_data = f\"{power_data_file.read()}]\"\n        data = json.loads(formatted_data)\n        queried_power_data = [\n            e for e in data if start_time <= float(e[\"host\"][\"timestamp\"]) <= end_time\n        ]\n        power_data[\"raw_data\"] = queried_power_data\n        power_data[\"avg_power\"] = compute_average_consumption(queried_power_data)\n        if end_time - start_time <= 3600:\n            power_data[\"warning\"] = (\n                \"The time window is lower than one hour, but the energy consumption estimate is in \"\n                \"Watt.Hour. So this is an extrapolation of the power usage profile on one hour. Be \"\n                \"careful with this data. \"\n            )\n        return power_data\n\n\ndef compute_average_consumption(power_data) -> float:\n    # Host energy consumption\n    total_host = 0.0\n    avg_host = 0.0\n    if len(power_data) > 0:\n        for r in power_data:\n            total_host += float(r[\"host\"][\"consumption\"])\n\n        avg_host = total_host / len(power_data) / 1000000.0  # from microwatts to watts\n\n    return avg_host\n\n\ndef get_hardware_data(fetch_hardware: bool):\n    data = {}\n    if fetch_hardware:\n        build_hardware_data()\n    try:\n        data = read_hardware_data()\n    except Exception:\n        build_hardware_data()\n        data = read_hardware_data()\n    return data\n\n\ndef read_hardware_data() -> Dict:\n    with open(HARDWARE_FILE_PATH, \"r\") as fd:\n        data = json.load(fd)\n    return data\n\n\ndef build_hardware_data():\n    lshw = Lshw()\n    with open(HARDWARE_FILE_PATH, \"w\") as hardware_file:\n        hardware_data = {}\n        hardware_data[\"disks\"] = lshw.disks\n        hardware_data[\"cpus\"] = lshw.cpus\n        hardware_data[\"rams\"] = lshw.memories\n        json.dump(hardware_data, hardware_file)\n\n\ndef query_machine_impact_data(\n    model: dict[str, str],\n    configuration: dict[str, dict[str, int]],\n    usage: dict[str, Any],\n) -> dict:\n    server_api = ServerApi(get_boavizta_api_client())\n\n    server_impact = None\n\n    if configuration:\n        server = Server(usage=usage, configuration=configuration)\n        server_impact = server_api.server_impact_from_configuration_v1_server_post(\n            server=server\n        )\n    elif model:\n        # server = Server(usage=usage, model=model)\n        # TO IMPLEMENT\n        # This conditional was based on a previous version of BoaviztAPI, where a server model could\n        # be sent to /v1/server through a GET method. BoaviztAPI now expects an archetype string to\n        # return a prerecorded impact from an asset.\n        server_impact = server_api.server_impact_from_model_v1_server_get(\n            archetype=\"dellR740\"\n        )\n\n    return server_impact\n\n\ndef generate_machine_configuration(hardware_data) -> Dict[str, Any]:\n    # Either delete or transfer this logic to hardware_cli / lshw\n    config = {\n        \"cpu\": {\n            \"units\": len(hardware_data[\"cpus\"]),\n            \"core_units\": hardware_data[\"cpus\"][1][\"core_units\"],\n            # \"family\": hardware_data['cpus'][1]['family']\n        },\n        \"ram\": sort_ram(hardware_data[\"rams\"]),\n        \"disk\": sort_disks(hardware_data[\"disks\"]),\n        \"power_supply\": (\n            hardware_data[\"power_supply\"]\n            if \"power_supply\" in hardware_data\n            else {\"units\": 1}\n        ),\n        # TODO: if cpu is a small one, guess that power supply is light/average weight of a laptops power supply ?\n    }\n    return config\n"}
{"type": "source_file", "path": "boagent/api/__init__.py", "content": "from .api import (\n    build_hardware_data,\n    format_usage_request,\n    read_hardware_data,\n    get_hardware_data,\n    query_machine_impact_data,\n    compute_average_consumption,\n    get_power_data,\n    get_metrics,\n)\n"}
{"type": "source_file", "path": "boagent/api/exceptions.py", "content": "class InvalidPIDException(Exception):\n    def __init__(self, pid):\n        self.pid = pid\n        self.message = f\"Process_id {self.pid} has not been found in metrics data. Check the queried PID.\"\n        super().__init__(self.message)\n"}
{"type": "source_file", "path": "boagent/api/models.py", "content": "from pydantic import BaseModel\n\n\nclass WorkloadTime(BaseModel):\n    time_percentage: float = 0.0\n    load_percentage: float = 0.0\n\n\ntime_workload_example = {\n    \"time_workload\": [\n        {\"time_percentage\": 50, \"load_percentage\": 0},\n        {\"time_percentage\": 25, \"load_percentage\": 60},\n        {\"time_percentage\": 25, \"load_percentage\": 100},\n    ]\n}\n"}
{"type": "source_file", "path": "boagent/hardware/__init__.py", "content": ""}
{"type": "source_file", "path": "boagent/api/config.py", "content": "from pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings):\n    project_name: str = \"boagent\"\n    project_version: str = \"0.1.0\"\n    project_description: str = \"Boagent is a local API and monitoring agent to help you estimate the environmental impact of your machine, including software activity and hardware embodied impacts.\"\n    tags_metadata: list = [\n        {\"name\": \"info\", \"description\": \"Returns runtime configuration of Boagent.\"},\n        {\"name\": \"web\", \"description\": \"Web UI to explore Boagent metrics.\"},\n        {\n            \"name\": \"csv\",\n            \"description\": \"Internal route. Generates and returns a CSV-formatted dataset with metrics needed by the webUI\",\n        },\n        {\n            \"name\": \"metrics\",\n            \"description\": \"Returns metrics as a Prometheus HTTP exporter.\",\n        },\n        {\n            \"name\": \"query\",\n            \"description\": \"This is the main route. Returns metrics in JSON format.\",\n        },\n    ]\n    seconds_in_one_year: int = 31536000\n    default_lifetime: float = 5.0\n    hardware_file_path: str = \"./hardware_data.json\"\n    power_file_path: str = \"./power_data.json\"\n    hardware_cli: str = \"./boagent/hardware/hardware_cli.py\"\n    boaviztapi_endpoint: str = \"http://localhost:5000\"\n    db_path: str = \"../../db/boagent.db\"\n    public_path: str = \"./boagent/public\"\n    assets_path: str = \"./boagent/public/assets/\"\n    carbon_aware_api_endpoint: str = \"https://carbon-aware-api.azurewebsites.net\"\n    carbon_aware_api_token: str = \"token\"\n    azure_location: str = \"northeurope\"\n"}
{"type": "source_file", "path": "boagent/api/process.py", "content": "from collections import defaultdict\nfrom .exceptions import InvalidPIDException\n\n\nclass Process:\n    def __init__(self, metrics_data, pid):\n        self.metrics_data = metrics_data\n        self.validate_pid(pid)\n        self._pid = pid\n        self.process_info = self.get_process_info()\n\n    def validate_pid(self, value):\n\n        timestamps = [\n            timestamp\n            for timestamp in self.metrics_data[\"raw_data\"][\"power_data\"][\"raw_data\"]\n        ]\n        consumers = [timestamp[\"consumers\"] for timestamp in timestamps]\n        pids = set([process[\"pid\"] for consumer in consumers for process in consumer])\n        if value in pids:\n            return value\n        else:\n            raise InvalidPIDException(value)\n\n    @property\n    def pid(self, pid):\n        \"\"\"The PID queried in data coming from Scaphandre.\"\"\"\n        return self._pid\n\n    @pid.setter\n    def pid(self, value):\n        self._pid = self.validate_pid(value)\n\n    def get_process_info(self):\n\n        timestamps = [\n            timestamp\n            for timestamp in self.metrics_data[\"raw_data\"][\"power_data\"][\"raw_data\"]\n        ]\n        consumers = [timestamp[\"consumers\"] for timestamp in timestamps]\n        process_info = [\n            process\n            for consumer in consumers\n            for process in consumer\n            if process[\"pid\"] == self._pid\n        ]\n        return process_info\n\n    @property\n    def process_name(self):\n        process_name = self.process_info[0][\"exe\"].split(\"/\")[-1]\n        return process_name\n\n    @property\n    def process_exe(self):\n        process_exe = self.process_info[0][\"exe\"]\n        return process_exe\n\n    def get_total_ram_in_bytes(self):\n\n        ram_data = self.metrics_data[\"raw_data\"][\"hardware_data\"][\"rams\"]\n        total_ram_in_bytes = (\n            sum(ram_unit[\"capacity\"] for ram_unit in ram_data) * 1073741824\n        )\n\n        return total_ram_in_bytes\n\n    def get_disk_usage_in_bytes(self):\n\n        # Data from Scaphandre can be empty on first returned element in the array\n        try:\n            key_for_disk_total_bytes = self.metrics_data[\"raw_data\"][\"power_data\"][\n                \"raw_data\"\n            ][0][\"host\"][\"components\"][\"disks\"][0][\"disk_total_bytes\"]\n        except IndexError:\n            key_for_disk_total_bytes = self.metrics_data[\"raw_data\"][\"power_data\"][\n                \"raw_data\"\n            ][1][\"host\"][\"components\"][\"disks\"][0][\"disk_total_bytes\"]\n\n        try:\n            key_for_disk_available_bytes = self.metrics_data[\"raw_data\"][\"power_data\"][\n                \"raw_data\"\n            ][0][\"host\"][\"components\"][\"disks\"][0][\"disk_available_bytes\"]\n        except IndexError:\n            key_for_disk_available_bytes = self.metrics_data[\"raw_data\"][\"power_data\"][\n                \"raw_data\"\n            ][1][\"host\"][\"components\"][\"disks\"][0][\"disk_available_bytes\"]\n\n        disk_total_bytes = int(key_for_disk_total_bytes)\n        disk_available_bytes = int(key_for_disk_available_bytes)\n        disk_usage_in_bytes = disk_total_bytes - disk_available_bytes\n        return disk_usage_in_bytes\n\n    @property\n    def ram_shares(self):\n\n        process_ram_shares = [\n            (\n                (\n                    int(timestamp[\"resources_usage\"][\"memory_usage\"])\n                    / self.get_total_ram_in_bytes()\n                )\n                * 100\n            )\n            for timestamp in self.process_info\n        ]\n\n        return process_ram_shares\n\n    @property\n    def cpu_load_shares(self):\n\n        process_cpu_load_shares = [\n            float(timestamp[\"resources_usage\"][\"cpu_usage\"])\n            for timestamp in self.process_info\n        ]\n        return process_cpu_load_shares\n\n    @property\n    def storage_shares(self):\n        process_storage_shares = [\n            (\n                (\n                    int(timestamp[\"resources_usage\"][\"disk_usage_write\"])\n                    / self.get_disk_usage_in_bytes()\n                )\n                * 100\n            )\n            for timestamp in self.process_info\n        ]\n        return process_storage_shares\n\n    def get_component_embedded_impact_shares(self, queried_component, component_shares):\n\n        component = f\"{queried_component}-1\"\n        component_impacts_data = self.metrics_data[\"raw_data\"][\"boaviztapi_data\"][\n            \"verbose\"\n        ][component][\"impacts\"]\n        component_embedded_impact_shares = list()\n        for impact in component_impacts_data:\n            impact_embedded_value = component_impacts_data[impact][\"embedded\"][\"value\"]\n            for process_component_share in component_shares:\n                if process_component_share == 0.0:\n                    component_embedded_impact = (\n                        f\"{impact}_embedded_share\",\n                        float(process_component_share),\n                    )\n                    component_embedded_impact_shares.append(component_embedded_impact)\n                else:\n                    component_embedded_impact_share = (\n                        float(impact_embedded_value) * float(process_component_share)\n                    ) / 100\n                    component_embedded_impact = (\n                        f\"{impact}_embedded_share\",\n                        float(component_embedded_impact_share),\n                    )\n                    component_embedded_impact_shares.append(component_embedded_impact)\n        return component_embedded_impact_shares\n\n    def get_component_embedded_impact_values(self, queried_component):\n        if queried_component == \"cpu\":\n            component_impact_shares = self.get_component_embedded_impact_shares(\n                \"CPU\", self.cpu_load_shares\n            )\n        elif queried_component == \"ram\":\n            component_impact_shares = self.get_component_embedded_impact_shares(\n                \"RAM\", self.ram_shares\n            )\n        elif queried_component == \"ssd\":\n            component_impact_shares = self.get_component_embedded_impact_shares(\n                \"SSD\", self.storage_shares\n            )\n        elif queried_component == \"hdd\":\n            component_impact_shares = self.get_component_embedded_impact_shares(\n                \"HDD\", self.storage_shares\n            )\n        else:\n            return \"Queried component is not available for evaluation.\"\n\n        gwp_list = defaultdict(list)\n        adp_list = defaultdict(list)\n        pe_list = defaultdict(list)\n\n        for impact_key, impact_value in component_impact_shares:\n            if impact_key == \"gwp_embedded_share\":\n                gwp_list[impact_key].append(impact_value)\n            if impact_key == \"adp_embedded_share\":\n                adp_list[impact_key].append(impact_value)\n            if impact_key == \"pe_embedded_share\":\n                pe_list[impact_key].append(impact_value)\n\n        gwp_average = sum(gwp_list[\"gwp_embedded_share\"]) / len(\n            gwp_list[\"gwp_embedded_share\"]\n        )\n        adp_average = sum(adp_list[\"adp_embedded_share\"]) / len(\n            adp_list[\"adp_embedded_share\"]\n        )\n        pe_average = sum(pe_list[\"pe_embedded_share\"]) / len(\n            pe_list[\"pe_embedded_share\"]\n        )\n\n        gwp_max = max(gwp_list[\"gwp_embedded_share\"])\n        adp_max = max(adp_list[\"adp_embedded_share\"])\n        pe_max = max(pe_list[\"pe_embedded_share\"])\n\n        gwp_min = min(gwp_list[\"gwp_embedded_share\"])\n        adp_min = min(adp_list[\"adp_embedded_share\"])\n        pe_min = min(pe_list[\"pe_embedded_share\"])\n\n        component_embedded_impact_values = {\n            f\"gwp_{queried_component}_average_impact\": gwp_average,\n            f\"adp_{queried_component}_average_impact\": adp_average,\n            f\"pe_{queried_component}_average_impact\": pe_average,\n            f\"gwp_{queried_component}_max_impact\": gwp_max,\n            f\"adp_{queried_component}_max_impact\": adp_max,\n            f\"pe_{queried_component}_max_impact\": pe_max,\n            f\"gwp_{queried_component}_min_impact\": gwp_min,\n            f\"adp_{queried_component}_min_impact\": adp_min,\n            f\"pe_{queried_component}_min_impact\": pe_min,\n        }\n        return component_embedded_impact_values\n\n    @property\n    def embedded_impact_values(self):\n        process_embedded_impact_values = {\n            \"pid\": self._pid,\n            \"process_embedded_impacts\": {},\n        }\n        components = [\"cpu\", \"ram\", \"hdd\", \"ssd\"]\n\n        for component in components:\n            try:\n                process_component_embedded_impact_values = (\n                    self.get_component_embedded_impact_values(component)\n                )\n                process_embedded_impact_values[\"process_embedded_impacts\"][\n                    f\"process_{component}_embedded_impact_values\"\n                ] = process_component_embedded_impact_values\n            except KeyError as absent_component:\n                print(\n                    f\"Queried component is not present in Boagent metrics: {absent_component}\"\n                )\n\n        return process_embedded_impact_values\n"}
{"type": "source_file", "path": "setup.py", "content": "import sys\n\nfrom setuptools import setup, find_packages\nfrom boagent import __version__\n\npy_version = sys.version_info[:2]\nif py_version < (3, 9):\n    raise Exception(\"api requires Python >= 3.9.\")\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetup(\n    name=\"boagent\",\n    maintainer=\"Benoit Petit\",\n    maintainer_email=\"bpetit@hubblo.org\",\n    version=__version__,\n    packages=find_packages(),\n    include_package_data=True,\n    description=\"Monitoring agent/framework for evaluating the environmental impacts of a machine and its applications, including several to all steps of the life cycle of the machine and service, plus multiple criterias of impacts (not just CO2eq metrics / Global Warming Potential). Part of the efforts of https://boavizta.org/en and https://sdialliance.org/.\",\n    use_pipfile=True,\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/Boavizta/boagent\",\n    test_suite=\"tests\",\n    setup_requires=[\"setuptools-pipfile\"],\n    keywords=[\n        \"carbon\",\n        \"footprint\",\n        \"environment\",\n        \"climate\",\n        \"co2\",\n        \"gwp\",\n        \"adp\",\n        \"pe\",\n        \"energy\",\n        \"boagent\",\n        \"scaphandre\",\n        \"boavizta\",\n        \"api\",\n    ],\n    classifiers=[\n        \"Programming Language :: Python :: 3.9\",\n        \"Intended Audience :: Developers\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires=\">=3.9\",\n    entry_points=\"\"\" \"\"\",\n)\n"}
{"type": "source_file", "path": "boagent/api/utils.py", "content": "from datetime import datetime\nfrom boaviztapi_sdk import ApiClient, Configuration\nfrom dateutil import parser\nfrom .config import Settings\nfrom os import PathLike\n\nsettings = Settings()\nBOAVIZTAPI_ENDPOINT = settings.boaviztapi_endpoint\n\n\ndef sort_ram(items: list):\n    hash_map = {}\n    for r in items:\n        if \"manufacturer\" in r:\n            if \"{}:{}\".format(r[\"capacity\"], r[\"manufacturer\"]) in hash_map:\n                hash_map[\"{}:{}\".format(r[\"capacity\"], r[\"manufacturer\"])][\"units\"] += 1\n            else:\n                hash_map[\"{}:{}\".format(r[\"capacity\"], r[\"manufacturer\"])] = {\n                    \"units\": 1,\n                    \"manufacturer\": r[\"manufacturer\"],\n                    \"capacity\": r[\"capacity\"],\n                }\n        else:\n            hash_map[\"{}\".format(r[\"capacity\"])] = {\n                \"units\": 1,\n                \"capacity\": r[\"capacity\"],\n            }\n    return [v for k, v in hash_map.items()]\n\n\ndef sort_disks(items: list):\n    hash_map = {}\n    for r in items:\n        if \"{}:{}:{}\".format(r[\"capacity\"], r[\"manufacturer\"], r[\"type\"]) in hash_map:\n            hash_map[\"{}:{}:{}\".format(r[\"capacity\"], r[\"manufacturer\"], r[\"type\"])][\n                \"units\"\n            ] += 1\n        else:\n            hash_map[\"{}:{}:{}\".format(r[\"capacity\"], r[\"manufacturer\"], r[\"type\"])] = {\n                \"units\": 1,\n                \"manufacturer\": r[\"manufacturer\"],\n                \"capacity\": r[\"capacity\"],\n                \"type\": r[\"type\"],\n            }\n    return [v for k, v in hash_map.items()]\n\n\ndef get_boavizta_api_client():\n    config = Configuration(\n        host=BOAVIZTAPI_ENDPOINT,\n    )\n    client = ApiClient(configuration=config)\n    return client\n\n\ndef iso8601_or_timestamp_as_timestamp(iso_time: str) -> float:\n    \"\"\"\n    Takes an str that's either a timestamp or an iso8601\n    time. Returns a float that represents a timestamp.\n    \"\"\"\n    if iso_time == \"0.0\" or iso_time == \"0\":\n        return float(iso_time)\n    else:\n        dt = None\n        try:\n            dt = parser.parse(iso_time)\n            print(\"{} is an iso 8601 datetime\".format(iso_time))\n        except Exception as e:\n            print(\"{} is not an iso 8601 datetime\".format(iso_time))\n            print(\"Exception : {}\".format(e))\n            try:\n                dt = datetime.fromtimestamp(int(round(float(iso_time))))\n                print(\"{} is a timestamp\".format(iso_time))\n            except Exception as e:\n                print(\"{} is not a timestamp\".format(iso_time))\n                print(\"Exception : {}\".format(e))\n                print(\"Parser would give : {}\".format(parser.parse(iso_time)))\n        finally:\n            if dt:\n                return dt.timestamp()\n            else:\n                return float(iso_time)\n\n\ndef format_prometheus_output(res, verbose: bool):\n    response = \"\"\n    for k, v in res.items():\n        if \"value\" in v and \"type\" in v:\n            if \"description\" not in v:\n                v[\"description\"] = \"TODO: define me\"\n            if type(v[\"value\"]) is float:\n                response += format_prometheus_metric(\n                    k,\n                    \"{}. {}\".format(\n                        v[\"description\"],\n                        \"In {} ({}).\".format(v[\"long_unit\"], v[\"unit\"]),\n                    ),\n                    v[\"type\"],\n                    v[\"value\"],\n                )\n            if type(v[\"value\"]) is dict:\n                response += format_prometheus_metric(\n                    k,\n                    \"{}. {}\".format(\n                        v[\"description\"],\n                        \"In {} ({}).\".format(v[\"long_unit\"], v[\"unit\"]),\n                    ),\n                    v[\"type\"],\n                    v[\"value\"][\"value\"],\n                )\n\n        else:\n            for x, y in v.items():\n                if type(y) is float:\n                    pass\n                else:\n                    if \"value\" in y and \"type\" in y:\n                        if \"description\" not in y:\n                            y[\"description\"] = \"TODO: define me\"\n                        response += format_prometheus_metric(\n                            \"{}_{}\".format(k, x),\n                            \"{}. {}\".format(\n                                y[\"description\"],\n                                \"In {} ({}).\".format(y[\"long_unit\"], y[\"unit\"]),\n                            ),\n                            y[\"type\"],\n                            y[\"value\"],\n                        )\n        if verbose:\n            if \"boaviztapi_data\" in v:\n                for impact_name, impact_items in v[\"boaviztapi_data\"][\n                    \"impacts\"\n                ].items():\n                    if \"unit\" in impact_items:\n                        for value in impact_items[\"embedded\"]:\n                            if value == \"warnings\":\n                                pass\n                            else:\n                                response += format_prometheus_metric(\n                                    \"{}\".format(f\"{impact_name}_total_impact_{value}\"),\n                                    \"{}. {}\".format(\n                                        impact_items[\"description\"],\n                                        \"In {}\".format(impact_items[\"unit\"]),\n                                    ),\n                                    \"{}\".format(\"gauge\"),\n                                    \"{}\".format(f\"{impact_items['embedded'][value]}\"),\n                                )\n\n                for component_name, component_impacts in v[\"boaviztapi_data\"][\n                    \"verbose\"\n                ].items():\n                    formatted_component_name = component_name.lower().replace(\"-\", \"_\")\n                    if \"impacts\" in component_impacts:\n                        for impact, items in component_impacts[\"impacts\"].items():\n                            for component_embedded_impact_metric, value in items[\n                                \"embedded\"\n                            ].items():\n                                if component_embedded_impact_metric == \"warnings\":\n                                    pass\n                                else:\n                                    response += format_prometheus_metric(\n                                        \"{}\".format(\n                                            f\"{formatted_component_name}_{impact}_embedded_impact_{component_embedded_impact_metric}\"\n                                        ),\n                                        \"{}. {}\".format(\n                                            items[\"description\"],\n                                            \"In {}\".format(items[\"unit\"]),\n                                        ),\n                                        \"{}\".format(\"gauge\"),\n                                        \"{}\".format(\n                                            f\"{value}\",\n                                        ),\n                                    )\n\n    return response\n\n\ndef format_prometheus_metric(\n    metric_name, metric_description, metric_type, metric_value\n):\n    response = \"\"\"# HELP {} {}\n# TYPE {} {}\n{} {}\n\"\"\".format(\n        metric_name,\n        metric_description,\n        metric_name,\n        metric_type,\n        metric_name,\n        metric_value,\n    )\n    return response\n\n\ndef filter_date_range(data: list, start_date: datetime, stop_date: datetime) -> list:\n\n    lower_index = 0\n    upper_index = 0\n\n    start = datetime.timestamp(start_date)\n    end = datetime.timestamp(stop_date)\n\n    for d in data:\n        if d[\"timestamp\"] < start:\n            lower_index += 1\n        if d[\"timestamp\"] < end:\n            upper_index += 1\n\n    return data[lower_index:upper_index]\n\n\ndef format_scaphandre_json(file: str | PathLike) -> str:\n    with open(file, \"r\") as fd:\n        formatted_scaphandre_json = f\"[{fd.read()}]\".replace(\n            '{\"host\"', ',{\"host\"'\n        ).replace(',{\"host\"', '{\"host\"', 1)\n    return formatted_scaphandre_json\n"}
{"type": "source_file", "path": "hardware_cli.py", "content": "#!/usr/bin/env python3\n\nimport json\nimport sys\n\nfrom boagent.hardware.lshw import Lshw\nfrom click import command, option, ClickException\n\n\n@command()\n@option(\"--output-file\", help=\"File to output the hardwate data to\")\ndef main(output_file):\n    try:\n        lshw = Lshw()\n\n        lshw_cpus = lshw.cpus\n        lshw_ram = lshw.memories\n        lshw_disks = lshw.disks\n    except KeyError:\n        error_message = \"Hardware_cli was not executed with privileges, try `sudo ./hardware_cli.py`.\"\n        exception = ClickException(error_message)\n        exception.show()\n    else:\n        hardware_data = {}\n        hardware_data[\"disks\"] = lshw_disks\n        hardware_data[\"cpus\"] = lshw_cpus\n        hardware_data[\"rams\"] = lshw_ram\n        if output_file is not None:\n            with open(output_file, \"w\") as fd:\n                json.dump(hardware_data, fd, indent=4)\n        else:\n            json.dump(hardware_data, sys.stdout, indent=4)\n        return 0\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "boagent/hardware/lshw.py", "content": "\"\"\"\nThis file is modified code issued from https://github.com/Solvik/netbox-agent/blob/master/netbox_agent/lshw.py,\ncopyright under Apache-2.0 licence.\n\"\"\"\n\nfrom shutil import which\nimport subprocess\nimport json\nimport sys\nimport re\nimport os\n\nSYS_BLOCK_PATH = \"/sys/block\"\n\n\ndef is_tool(name):\n    \"\"\"Check whether `name` is on PATH and marked as executable\"\"\"\n    return which(name) is not None\n\n\ndef serialized_lshw_output():\n    try:\n        lshw_output = subprocess.getoutput(\"lshw -quiet -json 2> /dev/null\")\n        serialized_lshw_output = json.loads(lshw_output)\n    except json.JSONDecodeError:\n        raise Exception(\"lshw does not seem do be executed as root.\")\n    else:\n        if isinstance(serialized_lshw_output, list):\n            return serialized_lshw_output[0]\n        else:\n            return serialized_lshw_output\n\n\ndef serialized_nvme_output():\n    nvme_output = subprocess.check_output(\n        [\"nvme\", \"-list\", \"-o\", \"json\"], encoding=\"utf8\"\n    )\n    serialized_nvme_output = json.loads(nvme_output)\n    return serialized_nvme_output\n\n\nclass Lshw:\n    def __init__(self):\n        if not is_tool(\"lshw\"):\n            raise Exception(\"lshw does not seem to be installed.\")\n        self.hw_info = serialized_lshw_output()\n        self.info = {}\n        self.memories = []\n        self.cpus = []\n        self.power = []\n        self.disks = []\n        self.gpus = []\n        self.motherboard_serial = self.hw_info[\"children\"][0].get(\"serial\", \"No S/N\")\n        self.motherboard = self.hw_info[\"children\"][0].get(\"product\", \"Motherboard\")\n\n        for k in self.hw_info[\"children\"]:\n            if k[\"class\"] == \"power\":\n                self.power.append(k)\n\n            if \"children\" in k:\n                for j in k[\"children\"]:\n                    if j[\"class\"] == \"generic\":\n                        continue\n\n                    if j[\"class\"] == \"storage\":\n                        self.find_storage(j)\n\n                    if j[\"class\"] == \"memory\":\n                        self.find_memories(j)\n\n                    if j[\"class\"] == \"processor\":\n                        self.find_cpus(j)\n\n                    if j[\"class\"] == \"bridge\":\n                        self.walk_bridge(j)\n\n    def get_hw_linux(self, hwclass):\n        if hwclass == \"cpu\":\n            return self.cpus\n        if hwclass == \"gpu\":\n            return self.gpus\n        \"\"\" if hwclass == \"network\":\n            return self.interfaces \"\"\"\n        if hwclass == \"storage\":\n            return self.disks\n        if hwclass == \"memory\":\n            return self.memories\n\n    \"\"\"\n    def find_network(self, obj):\n        # Some interfaces do not have device (logical) name (eth0, for\n        # instance), such as not connected network mezzanine cards in blade\n        # servers. In such situations, the card will be named `unknown[0-9]`.\n        unkn_intfs = []\n        for i in self.interfaces:\n            # newer versions of lshw can return a list of names, see issue #227\n            if not isinstance(i[\"name\"], list):\n                if i[\"name\"].startswith(\"unknown\"):\n                    unkn_intfs.push(i)\n            else:\n                for j in i[\"name\"]:\n                    if j.startswith(\"unknown\"):\n                        unkn_intfs.push(j)\n\n        unkn_name = \"unknown{}\".format(len(unkn_intfs))\n        self.interfaces.append(\n            {\n                \"name\": obj.get(\"logicalname\", unkn_name),\n                \"macaddress\": obj.get(\"serial\", \"\"),\n                \"serial\": obj.get(\"serial\", \"\"),\n                \"product\": obj[\"product\"],\n                \"vendor\": obj[\"vendor\"],\n                \"description\": obj[\"description\"],\n            }\n        )\n    \"\"\"\n\n    def find_storage(self, obj):\n        if \"children\" in obj:\n            for device in obj[\"children\"]:\n                if \"vendor\" in device and \"size\" in device:\n                    d = {\n                        \"units\": +1,\n                        \"manufacturer\": self.check_disk_vendor(\n                            device[\"vendor\"]\n                        ).lower(),\n                        \"capacity\": device[\"size\"],\n                        \"logicalname\": device[\"logicalname\"],\n                        \"type\": self.get_disk_type(device[\"logicalname\"]),\n                    }\n                    self.disks.append(d)\n        if \"configuration\" in obj:\n            if \"nvme\" in obj[\"configuration\"][\"driver\"]:\n                if not is_tool(\"nvme\"):\n                    raise Exception(\"nvme-cli >= 1.0 does not seem to be installed\")\n                try:\n                    nvme = serialized_nvme_output()\n                    for device in nvme[\"Devices\"]:\n                        d = {\n                            \"units\": +1,\n                            \"logicalname\": device[\"DevicePath\"],\n                            \"manufacturer\": self.check_disk_vendor(\n                                device[\"ModelNumber\"]\n                            ).lower(),\n                            \"type\": \"ssd\",\n                            \"capacity\": device[\"PhysicalSize\"] // 1073741824,\n                        }\n                        self.disks.append(d)\n                except Exception:\n                    pass\n\n    def find_cpus(self, obj):\n        if \"product\" in obj:\n            self.cpus.append(\n                {\n                    \"units\": +1,\n                    \"name\": obj[\"product\"],\n                    \"manufacturer\": obj[\"vendor\"],\n                    \"core_units\": int(obj[\"configuration\"][\"cores\"]),\n                }\n            )\n\n    def find_memories(self, obj):\n        if \"children\" not in obj:\n            # print(\"not a DIMM memory.\")\n            return\n\n        for dimm in obj[\"children\"]:\n            if \"empty\" in dimm[\"description\"]:\n                continue\n\n            self.memories.append(\n                {\n                    \"units\": +1,\n                    \"manufacturer\": dimm.get(\"vendor\", \"N/A\"),\n                    \"capacity\": dimm.get(\"size\", 0) // 2**20 // 1024,\n                }\n            )\n\n    def find_gpus(self, obj):\n        if \"product\" in obj:\n            self.gpus.append(\n                {\n                    \"product\": obj[\"product\"],\n                    \"vendor\": obj[\"vendor\"],\n                    \"description\": obj[\"description\"],\n                }\n            )\n\n    def walk_bridge(self, obj):\n        if \"children\" not in obj:\n            return\n\n        for bus in obj[\"children\"]:\n            if bus[\"class\"] == \"storage\":\n                self.find_storage(bus)\n            if bus[\"class\"] == \"display\":\n                self.find_gpus(bus)\n\n            if \"children\" in bus:\n                for b in bus[\"children\"]:\n                    if b[\"class\"] == \"storage\":\n                        self.find_storage(b)\n                    if b[\"class\"] == \"display\":\n                        self.find_gpus(b)\n\n    def check_disk_vendor(self, model_string: str) -> str:\n        split_model = model_string.split(\" \")\n        vendor = \"\"\n\n        if len(split_model) == 1:\n            check_string_for_numbers = bool(re.search(\"\\\\d\", model_string))\n            if check_string_for_numbers:\n                raise Exception(\n                    \"Lshw did not output a parsable manufacturer name for this device.\"\n                )\n            else:\n                return model_string\n\n        model_first_str = split_model[0]\n        model_second_str = split_model[1]\n        check_first_string_for_numbers = re.search(\"\\\\d\", model_first_str)\n        result = bool(check_first_string_for_numbers)\n\n        if result:\n            vendor = model_second_str\n            return vendor\n        else:\n            vendor = model_first_str\n            return vendor\n\n    def get_disk_type(self, dev_path: str) -> str:\n\n        rotational = self.get_rotational_int(dev_path)\n\n        if rotational == 0:\n            return \"ssd\"\n        if rotational == 1:\n            return \"hdd\"\n        if rotational == 2:\n            return \"unknown\"\n        return \"unknown\"\n\n    def get_rotational_int(self, dev_path: str) -> int:\n\n        device = dev_path.removeprefix(\"/dev\")\n\n        try:\n            rotational_fp = os.path.realpath(\n                f\"{SYS_BLOCK_PATH}{device}/queue/rotational\", strict=True\n            )\n\n        except OSError:\n            sys.stderr.write(\"Rotational file was not found\")\n            return 2\n        else:\n            with open(rotational_fp, \"r\") as file:\n                rotational_int = int(file.read())\n        return rotational_int\n"}
