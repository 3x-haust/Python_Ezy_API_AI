{"repo_info": {"repo_name": "HiYoyo", "repo_owner": "Ya-chunJen", "repo_url": "https://github.com/Ya-chunJen/HiYoyo"}}
{"type": "source_file", "path": "__init__.py", "content": ""}
{"type": "source_file", "path": "azurebot/azurebotmult.py", "content": "import os,json,sys,configparser\nimport copy\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom azurebot import azurebotsingle\nfrom azurebot import azurebotfunction\n\nazurebotsingleclass = azurebotsingle.AzureBotSingle()\nazurebotfunctionclass = azurebotfunction.AzureBotFunction()\n\nclass AzureBotMult:\n    def __init__(self):\n        pass\n\n    def chatmult(self,username,prompt,system_content=\"You are a helpful assistant\",functionname=[\"none\"],voice_name=\"zh-CN-XiaoxiaoNeural\"):\n        # 用户ID文件路径\n        username_fpath = f\"{username}.json\"\n        username_fpath = os.path.join(workdir,\"log\",username_fpath)\n        # 判断用户ID文件是不是存在，存在就读取，不存在就建立\n        if os.path.exists(username_fpath):\n            with open(username_fpath) as f:\n                message = json.load(f) \n        else:\n            message = []\n            system_dict = {\"role\":\"system\",\"content\": system_content}\n            message.append(system_dict)\n\n        # 构造本次问答的问题\n        prompt_dict = {\"role\":\"user\",\"content\": prompt}\n        \n        # 将本次的提问和历史记录整合\n        message.append(prompt_dict)\n\n        # 如果聊天记录很长，只选取system和最近两轮的会话\n        messages_thistime = copy.deepcopy(message)\n        if len(messages_thistime)>=5:\n            messages_thistime = [messages_thistime[0]] + messages_thistime[-4:]\n            # print(messages_thistime)\n\n        # 调用单轮会话的模块获取结果\n        # response_dit = chatgptsingle.chat(messages_thistime,voice_name) #使用Azure的接口\n        # 调用支持函数的单轮会话模块获取结果。\n        response_dit = azurebotfunctionclass.chat_with_funciton(messages_thistime,functionname,voice_name) \n        \n        # print(response_dit)\n        # 将本次的回答和历史记录整合\n        message.append(response_dit)\n\n        with open(username_fpath, \"w\",encoding='utf-8') as file:\n            json.dump(message, file)\n\n        # 单独获取结果并打印，并作为函数返回结果\n        response_content = response_dit[\"content\"]\n        # print(response_content)\n        return response_content\n\nif __name__ == '__main__':\n    username = \"1\"\n    prompt =  input(\"请输入你的问题：\")\n    system_content = \"你是一个有用的智能助手。\"\n    functionname = [\"none\"]\n    azurebotmult = AzureBotMult()\n    azurebotmult.chatmult(username,prompt,system_content,functionname)"}
{"type": "source_file", "path": "functionplugin/querytime.py", "content": "import os\nimport datetime\nimport pytz\nimport json\n\ndef querytime(function_args):\n    current_time = datetime.datetime.now()\n    tz = pytz.timezone('Asia/Shanghai')\n    # 获取周几\n    weekday_dict = {0: '星期一',1: '星期二',2: '星期三',3: '星期四',4: '星期五',5: '星期六',6: '星期天',}\n    weekday = weekday_dict[current_time.weekday()]\n    # 返回当前时间的文本格式\n    nowtime = '{} {} {}'.format(current_time.strftime('%Y-%m-%d %H:%M:%S'), weekday, tz.tzname(current_time))\n    # print(nowtime)\n    callback_json =  {\"request_gpt_again\":True,\"details\":f\"<参考信息>：现在的详细时间是：{nowtime}\"}\n    return callback_json"}
{"type": "source_file", "path": "azurebot/azurebotfunction.py", "content": "import os,json,sys,configparser\nimport openai\nimport importlib\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom azurebot import azurebotsingle\nfrom speechmodules import text2speech\n\nazurebotsingleclass = azurebotsingle.AzureBotSingle()\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['Azureopenai']\n\nopenai.api_type = \"azure\"\nopenai.api_version = configsection['openai_api_version']\nopenai.api_key = configsection['openai_api_key']\nopenai.api_base = configsection['openai_api_base']\nmodelname = configsection['gpt35_deployment_name']\n\ndef find_values_by_index(list1, list2, index):\n    # 两个元素数量一致的列表，列表元素均为字符串。已知一个列表的值，寻找另一个列表中，其下标一致的值。\n    result = \"\"\n    for i in range(len(list1)):\n        if list1[i] == index:\n            result = list2[i]\n    return result\n\ndef filter_dict_array(dict_array, key, val_array):\n    \"\"\"\n    过滤数组中key为指定值的字典元素\n    functions = filter_dict_array(functions,\"name\",function_call)\n    \"\"\"\n    result = []\n    for d in dict_array:\n        for v in  val_array:\n            if d.get(key) == v: # 精准匹配\n                result.append(d)\n    return result\n\n\nclass AzureBotFunction:\n    def __init__(self):\n        pass\n    def chat_with_funciton(self,prompt_messages,function_call=[\"none\"],voice_name=\"zh-CN-XiaoxiaoNeural\"):\n    # 从文件中读取已有的函数插件列表\n        funnctionpluginlist_file_path = os.path.join(workdir,\"functionplugin\",\"functionpluginlist.json\")\n        with open(funnctionpluginlist_file_path, 'r' ,encoding=\"UTF-8\") as f:\n            functions = json.load(f)\n            #print(functions)\n\n        if function_call[0] == \"none\":\n            # 如果function_call为none，那就调用一次简单的chatGPT函数，不带任何函数功能。\n            # print(\"不需要调用任何的插件。简单请求一次GPT\")\n            response_message = azurebotsingleclass.chat(prompt_messages,voice_name)\n            return response_message\n        elif function_call[0] == \"auto\":\n            # 如果function_call为auto，就使用全部的插件。一般不会使用。\n            function_call = \"auto\"\n            # print(\"调用的函数：\")\n            # print(functions)\n        else:\n            # 如果function_call为具体名字，就使用具体的插件。\n            functions = filter_dict_array(functions,\"name\",function_call)\n            function_call = \"auto\"\n            # print(\"调用的函数：\")\n            # print(functions)\n\n        # print(functions)\n        prompt_messages[0]['content'] = \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous\"\n        # print(\"调用函数前的prompt_message\")\n        # print(prompt_messages)\n        completion = openai.ChatCompletion.create(\n            deployment_id = modelname,\n            messages = prompt_messages,\n            functions = functions,\n            function_call = function_call,\n        )\n        response_message = completion['choices'][0]['message'].to_dict() # type: ignore\n        response_message.setdefault('content', None) # 如果调用了函数，返回值是没有content的。但是随后再次提交，还需要content值。所以需要插入一个空值。\n        # print(response_message)\n\n        if response_message.get(\"function_call\"):\n            # print(\"首次调用GPT，返回了JSON格式的数据。\")\n            response_message['function_call'] = response_message['function_call'].to_dict()\n            function_name = response_message['function_call']['name']\n            function_args_str = response_message['function_call']['arguments']\n            function_args = json.loads(function_args_str)\n\n            # 根据函数名称，加载同名模块下的同名函数。\n            module_name = function_name\n            module_path = os.path.join(workdir, 'functionplugin', module_name + '.py')\n            module = importlib.util.module_from_spec(spec:= importlib.util.spec_from_file_location(module_name, module_path)) # type: ignore\n            spec.loader.exec_module(module)\n            fuction_to_call = getattr(module, function_name)  # 获取函数对象\n\n            # 调用对应的函数，并将结果赋值给function_response\n            function_response = fuction_to_call(function_args)\n            \n            if function_response['request_gpt_again']:\n                # print(\"调用插件后，插件要求再调用一次GPT。\")\n                # 调用函数后，函数会返回是否再调用一次的字段，以下部分是需要再次调用GPT的场景。\n                # print(function_response['details'])\n                prompt_messages.append(response_message)\n                prompt_messages.append(\n                    {\n                        \"role\": \"function\",\n                        \"name\": function_name,\n                        \"content\": function_response,\n                    }\n                )\n                # print(\"再次调用插件时的，prompt_messages\")\n                prompt_messages[0][\"content\"] = \"你是一个有用的智能助手。\"\n                # print(prompt_messages)\n                # second_response = chatGPT(prompt_messages) #再次请求一次无函数调用功能的chatGPT\n                second_response = azurebotsingleclass.chat(prompt_messages,voice_name) #再次请求一次无函数调用功能的chatGPT\n                # print(\"再次调用一次GPT返回的结果。\")\n                # print(second_response)\n                return second_response\n            else:\n                # 调用函数后，函数会返回是否再调用一次的字段，以下部分是不需要再次调用GPT的场景，在这种条件下，可以将函数返回的内容直接返回给终端用户。\n                # print(\"调用插件后，插件不要求再次调用GPT，插件直接返回了结果。\")\n                tts = text2speech.AzureTTS(voice_name)\n                tts.text2speech_and_play(function_response['details'])\n                second_response= {\"role\":\"assistant\",\"content\":function_response['details']}\n                return second_response\n        else:\n            # 虽然明确要求使用函数插件，但是因为信息不足等原因，还是直接返回了面向终端用户的信息。\n            # print(\"虽然要求调用了插件，但是GPT还是返回了直接面向终端用户的信息，表示现有的信息不足以按插件要求返回JSON数据。\")\n            return response_message\n\nif __name__ == '__main__':\n    system_content = \"你是一个有用的智能助手！\"\n    function_call_name = input(\"请输入插件的名称：\")\n    function_call = [function_call_name]\n    prompt = input(\"请输入你的问题：\")\n    messages=[{\"role\":\"system\",\"content\":system_content},{\"role\": \"user\", \"content\":prompt}]\n    azurebotfunction = AzureBotFunction()\n    result = azurebotfunction.chat_with_funciton(messages,function_call)\n    print(result['content'])"}
{"type": "source_file", "path": "erniebot/erniebotsingle.py", "content": "import os,json,sys,configparser\nimport requests\nimport openai\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom speechmodules import text2speech\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['baiduernie']\nErnieApiVersion = configsection[\"ErnieApiVersion\"]\n\ndef get_access_token():\n    \"\"\"\n    使用 API Key，Secret Key 获取access_token，替换下列示例中的应用API Key、应用Secret Key\n    \"\"\"\n    ApiKey = configsection['ApiKey']\n    keySecret = configsection['keySecret']\n    url = f\"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={ApiKey}&client_secret={keySecret}\"\n    \n    payload = json.dumps(\"\")\n    headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n    \n    response = requests.request(\"POST\", url, headers=headers, data=payload)\n    return response.json().get(\"access_token\")\n\nclass ErnieBotSingle:\n    def __init__(self):\n        self.requesturl = ErnieApiVersion + \"?access_token=\" + get_access_token()\n        self.headers = {'Content-Type': 'application/json'}\n\n    def chat(self,prompt_messages,voice_name=\"zh-CN-XiaoxiaoNeural\"):\n        tts = text2speech.AzureTTS(voice_name)\n        # 组装请求的参数和数据\n        system = prompt_messages[0][\"content\"] # 文心一言的system不再messages中。需要从messages中获取。\n        prompt_messages.pop(0)  # 文心一言的system不再messages中。需要从messages中删除。\n        if len(prompt_messages) % 2 == 0:\n            # 文心一言的messages长度必须为奇数\n            prompt_messages.pop(0)\n        payload = json.dumps({\n            \"system\":system,\n            \"messages\": prompt_messages,\n            \"stream\": True\n        })\n        # 以下是发送请求的过程\n        response = requests.request(\"POST\", self.requesturl, headers=self.headers, data=payload)\n        # 以下是处理请求结果的过程\n        # print(response.text)\n        responseresult = \"\"\n        for line in response.iter_lines():\n            linetext = line.decode(encoding='utf-8')\n            if len(linetext) == 0:\n                continue\n            linetext = linetext.replace(\"data: \",\"\")\n            try:\n                linejson = json.loads(linetext)\n                lineresult = linejson['result']\n                print(lineresult, end='')\n                tts.text2speech_and_play(lineresult)\n                responseresult = responseresult + lineresult\n            except:\n                responseresult = \"服务请求异常！\"\n                print(responseresult)\n                tts.text2speech_and_play(responseresult)\n        return {\"role\": \"assistant\",\"content\": responseresult}\n\nif __name__ == '__main__':\n    system = \"You are a helpful assistant\"\n    prompt = input(\"请输入你的问题：\")\n    messages=[{\"role\":\"system\",\"content\": system},{\"role\": \"user\", \"content\":prompt}]\n    erniebotsingle = ErnieBotSingle()\n    post_message = erniebotsingle.chat(messages)[\"content\"]\n    print(post_message)"}
{"type": "source_file", "path": "functionplugin/sendemail.py", "content": "import os,json,sys,configparser\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom email.header import Header\nfrom email.mime.multipart import MIMEMultipart\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['QQsmtp']\n\ndef send(mail_to,mail_subject,message):\n    # 这是一个封装后的公共函数，第一个参数是发送的目标对象，第二个对象是邮件主题，第三参数邮件纯文本、html格式、附件等格式邮件在各自函数封装后传递的值，所以在本函数中值定义From\\to\\Subject即可\n    sender = configsection['sender']\n    password = configsection['password']\n    message['From'] = Header(sender) #定义邮件发送者的显示信息\n    message['To'] =  Header(mail_to)  #定义邮件接受者的显示信息\n    message['Subject'] = Header(mail_subject, 'utf-8') #定义邮件的主题\n\n    smtpobj = smtplib.SMTP_SSL(\"smtp.qq.com\",465) #链接邮件服务器\n    smtpobj.ehlo()\n    smtpobj.login(sender,password) # type: ignore #登录邮箱\n    smtpobj.sendmail(sender,mail_to,message.as_string()) #发送邮件\n    smtpobj.quit() #退出邮箱\n\ncontacts = [\n    {\"name\":\"任雅君\",\"email\":\"renyajun@xiajuzi.trade\"},\n    {\"name\":\"任亚军\",\"email\":\"renyajun@xiajuzi.trade\"},\n    {\"name\":\"张三\",\"email\":\"zhangsan@qq.cn\"},\n    {\"name\":\"李四\",\"email\":\"lisi@qq.cn\"}\n]\n\ndef sendemail(function_args):\n    # mailcontent = json.loads(mailcontent)\n    mail_to_name = function_args['mail_to_name']\n    mail_subject = function_args['mail_subject']\n    mail_body_text = function_args['mail_body_text']\n    message = MIMEText(mail_body_text, 'plain', 'utf-8')  #构建纯文本邮件的内容\n\n    contact_names = [contact['name'] for contact in contacts]\n    if mail_to_name not in contact_names:\n        callback_json =  {\"request_gpt_again\":False,\"details\":f\"在你的联系人列表中没有找到{mail_to_name}\"}\n        return callback_json\n    else:\n        for contact in contacts:\n            if contact['name'] == mail_to_name:\n                mail_to_address  = contact['email']\n                send(mail_to_address,mail_subject,message) # 调用公共发送函数\n                break\n    callback_json =  {\"request_gpt_again\":False,\"details\":f\"已将主题为《{mail_subject}》的邮件发送给了：{mail_to_name}。\"}\n    return callback_json\n\nif __name__ == '__main__':\n    message_body = {\n        \"mail_to_name\":\"张三\",\n        \"mail_subject\":\"我已安全到家！\",\n        \"mail_body_text\":\"我已安全到家，勿念。\"\n    }\n    \n    sendemail(message_body)"}
{"type": "source_file", "path": "functionplugin/aliyunossup.py", "content": "# -*- coding: utf-8 -*-\nimport os,json,sys,configparser\nimport oss2\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['aliyunoss']\n\n# 从配置文件中读取信息\nAccessKey = configsection[\"AccessKey\"]\nAccessScret = configsection[\"AccessScret\"]\nbucketname = configsection[\"bucketname\"]\nbucketdomain = configsection[\"bucketdomain\"]\n\n# 阿里云账号AccessKey拥有所有API的访问权限，风险很高。强烈建议您创建并使用RAM用户进行API访问或日常运维，请登录RAM控制台创建RAM用户。\nauth = oss2.Auth(AccessKey, AccessScret)\n\n# yourEndpoint填写Bucket所在地域对应的Endpoint。以华东1（杭州）为例，Endpoint填写为https://oss-cn-hangzhou.aliyuncs.com。\n# 填写Bucket名称。\nbucket = oss2.Bucket(auth, 'https://oss-cn-hangzhou.aliyuncs.com', bucketname)\n\n# 必须以二进制的方式打开文件。\n# 填写本地文件的完整路径。如果未指定本地路径，则默认从示例程序所属项目对应本地路径中上传文件。\n\ndef aliyunossup(function_args):\n    local_file_path = function_args['local_file_path']\n    oss_file_dir = function_args['oss_file_dir']\n    with open(local_file_path, 'rb') as fileobj:\n        # Seek方法用于指定从第1000个字节位置开始读写。上传时会从您指定的第1000个字节位置开始上传，直到文件结束。\n        fileobj.seek(0, os.SEEK_SET)\n        # Tell方法用于返回当前位置。\n        current = fileobj.tell()\n        file_name = local_file_path.split(\"/\", )[-1]  #根据文件路径获取文件名和后缀，仅适用于Mac\n\n        # 填写Object完整路径。Object完整路径中不能包含Bucket名称。\n        bucket.put_object(oss_file_dir+'/'+file_name,fileobj)\n        file_url = bucketdomain + oss_file_dir + '/' + file_name\n        return {\"request_gpt_again\":False,\"details\":file_url}\n\nif __name__ == '__main__':\n    local_file_path = input(\"请输入上传文件的路径：\")\n    oss_file_dir = input(\"请输入要上传到的目录：\")\n    function_args = {\"local_file_path\":local_file_path,\"oss_file_dir\":oss_file_dir}\n    aliyunossup(function_args)"}
{"type": "source_file", "path": "main_text.py", "content": "import os,json,sys,configparser\nimport readline\n\nworkdir = os.path.dirname(os.path.realpath(__file__))\nsys.path.append(workdir)\n\nfrom azurebot.azurebotmult import AzureBotMult\nfrom erniebot.erniebotmult import ErnieBotMult\nfrom openaibot.openaibotmult import OpenaiBotMult\n\ndef input_with_delete(prompt=''):\n    readline.parse_and_bind(\"set editing-mode vi\")  # 设置编辑模式为vi（可选）\n    line = input(prompt)\n    return line\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nrobot_info_file_path = os.path.join(workdir, \"robot_info.json\")\naimanufacturer = config[\"AI\"][\"aimanufacturer\"]\nif aimanufacturer == \"azurebot\":\n    chatmult = AzureBotMult()\nelif aimanufacturer == \"erniebot\":\n    chatmult = ErnieBotMult()\nelif aimanufacturer == \"openaibot\":\n    chatmult = OpenaiBotMult()\n\n# 增加程序启动时的开机广告，并且告知用户智能音箱的唤醒词。\n# print(f\"system:我是你的智能助手，欢迎开始和我对话。\")\n\n# 这是用于判断一个字符串中，是不是包含一个列表中的任意词，如果包含就会返回列表中的这个元素。\n# 实际业务上，是判断语音转为文字的内容，是不是包含任意一个智能语音助手的激活关键词。\ndef find_robot_keyword(s,lst):\n    for elem in lst:\n        if elem in s:\n            return elem\n    return None\n\nclass Yoyo:\n    def __init__(self):\n        with open(robot_info_file_path , 'r' ,encoding=\"UTF-8\") as f:\n            # 导入智能助手的配置文件。\n            self.robot_info = json.load(f)\n            self.robot_id_list = [d['robot_id'] for d in self.robot_info]\n            self.robot_keywords_list = [d['robot_keyword'] for d in self.robot_info]\n\n    def robot_model(self,robot_id=\"xiaozhushou\"):\n        # 主要用于判断加载哪一个智能语音助手。\n        try:\n            robot_index = self.robot_id_list.index(robot_id)\n        except ValueError:\n            raise SystemExit(\"没有此配置的机器人！\")\n\n        self.robot_name = self.robot_info[robot_index ]['robot_name']\n        self.robot_describe = self.robot_info[robot_index ]['robot_describe']\n        self.robot_reply_word = self.robot_info[robot_index ]['robot_reply_word']\n        self.robot_system_content = self.robot_info[robot_index ]['robot_system_content']\n        self.username = self.robot_info[robot_index ]['username']\n        self.robot_function_model = self.robot_info[robot_index ]['robot_function_model']\n        self.hotword_list = [\"模式切换\",\"打开对话文件\",\"语音对话模式\"]\n    \n    def hotword(self,wordtext):\n        if wordtext == \"模式切换\":\n            print(f\"现有智能助手如下，：\\n{self.robot_keywords_list}\")\n            input_robot_keyword = input_with_delete(\"请输入对应名称以切换：\")\n            switch_robot_index = self.robot_keywords_list.index(input_robot_keyword)\n            switch_robot_id = self.robot_info[switch_robot_index][\"robot_id\"] # 确定要切换到哪一个智能语音助手。\n            self.robot_model(switch_robot_id)   #切换智能语音助手。\n            print(f\"system:已切换到「{input_robot_keyword }」。\")  \n        elif wordtext == \"打开对话文件\":\n            username_path = os.path.join(workdir, \"log\",self.username+\".json\")\n            os.system(\"open \" + username_path)\n        elif wordtext == \"语音对话模式\":\n            from main import Yoyo\n            yoyo = Yoyo()\n            yoyo.loop()\n\n\n    def run(self):\n        print(f\"system:欢迎进入HiYoyo智能助手，你可以直接对话，也可以输入「模式切换」，切换到其他对话模式。\")  \n        print(f\"system:当前和你会话的是「{self.robot_name}」。智能助手介绍：{self.robot_describe}\")    \n        while True:\n            # 唤醒后，打印和播放当前智能语音助手的打招呼语。     \n            q = input_with_delete(f\"{self.username}：\") # 获取用户输入的内容。\n            robot_keyword = find_robot_keyword(q,self.robot_keywords_list) #判断用户录入的内容是不是包含任意一个智能语音助手的激活关键词。如果不包含，就请求ChatGPT的结果。如果包含，就切换到对应的智能语音助手。\n            hotword_keyword = find_robot_keyword(q,self.hotword_list)\n            if robot_keyword == None and hotword_keyword == None:\n                #print(f'{self.username}:{q}') # 打印用户录入的内容\n                print(f'{self.robot_name}(GPT)：',end='') \n                res = chatmult.chatmult(self.username,q,self.robot_system_content,self.robot_function_model,voice_name=\"\") # 请求ChatGPT的接口。\n                print(\"\")\n                # print(f'{self.robot_name}(GPT)：{res}')   # 打印返回的结果。\n            elif robot_keyword == None and hotword_keyword != None:\n                self.hotword(hotword_keyword)\n            else:\n                switch_robot_index = self.robot_keywords_list.index(robot_keyword)\n                switch_robot_id = self.robot_info[switch_robot_index][\"robot_id\"] # 确定要切换到哪一个智能语音助手。\n                self.robot_model(switch_robot_id)   #切换智能语音助手。\n                print(f\"system:已切换到「{robot_keyword}」。\")                                      \n\n    def loop(self,):\n        while True:\n            try:\n                self.robot_model()\n                self.run()\n            except KeyboardInterrupt:\n                break\n\nif __name__ == '__main__':\n    yoyo = Yoyo()\n    yoyo.loop()"}
{"type": "source_file", "path": "functionplugin/wjxanalysis.py", "content": "import json\nimport requests\nimport sys\n\n\nheaders = {'Content-Type': 'application/json'}\n\ndef wjxanalysis(function_args):\n    # 模块名称和模块中的函数，名称必须一致，这里均为plugindemo。必须接受function_args这个字段作为参数。\n    webhook_url = \"https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=c6434bc3-7ef0-4afc-9c20-f1ee4f822407\"\n    text_content = function_args['text']\n    payload_message = {\"msgtype\": \"text\",\"text\": {\"content\": text_content}}\n    response = requests.request(\"POST\", webhook_url, headers=headers, data=json.dumps(payload_message))\n    response = json.loads(response.text)\n    if not(response['errcode']):\n        callback_json = {\"request_gpt_again\":False,\"details\":f\"已将消息推送到企业微信群。\"}\n        return callback_json\n    else:\n        # 函数回调必须有request_gpt_again字段，用于判断是否需要继续调用gpt.details字段用于更加详细的信息。\n        callback_json = {\"request_gpt_again\":False,\"details\":f\"推送消息是出错，请检查。\"}\n        # 函数返回必须以字符串形式。\n        return callback_json\n\nif __name__ == '__main__':\n    function_args = {\"text\":\"你好\"}\n    wjxanalysis(function_args)"}
{"type": "source_file", "path": "openaibot/openaibotfunction.py", "content": "# 通过URL请求OpanAI的接口，主要用于函数调用。\nimport os,json,sys,configparser,requests\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nimport importlib\n\n# 读取openai的配置参数文件。\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['Openai']\n\nfrom speechmodules import text2speech\nfrom openaibot import openaibotsingle\nopenaibotsingleclass = openaibotsingle.OpenaiBotSingle()\n\ndef find_values_by_index(list1, list2, index):\n    # 两个元素数量一致的列表，列表元素均为字符串。已知一个列表的值，寻找另一个列表中，其下标一致的值。\n    result = \"\"\n    for i in range(len(list1)):\n        if list1[i] == index:\n            result = list2[i]\n    return result\n\ndef filter_dict_array(dict_array,key,key_array):\n    # 一个列表dict_array（其每个元素都为字典），另外一个列表key_array（其每个元素都是一个字典的值），通过此函数可以过滤dict_array中指定key为指定值的字典元素，形成一个新的列表。\n    # functions = filter_dict_array(functions,\"name\",function_call)\n    result = []\n    for d in dict_array:\n        for k in  key_array:\n            if d.get(key) == k: # 精准匹配\n                result.append(d)\n    return result\n\nclass OpenaiBotFunction:\n    def __init__(self):\n        self.openai_api_url = configsection['openai_api_domain'] + \"/v1/chat/completions\"\n        self.openai_api_key = configsection['openai_api_key']\n        self.headers = {\"Content-Type\": \"application/json\",\"Authorization\": \"Bearer \" + self.openai_api_key}\n        self.model = \"gpt-3.5-turbo\" \n\n    def chat_with_funciton(self,prompt_messages,function_call=[\"none\"],voice_name=\"zh-CN-XiaoxiaoNeural\"):\n        tools = []\n        # 从文件中读取已有的函数插件列表\n        funnctionpluginlist_file_path = os.path.join(workdir,\"functionplugin\",\"functionpluginlist.json\")\n        with open(funnctionpluginlist_file_path, 'r' ,encoding=\"UTF-8\") as f:\n            functions = json.load(f)\n\n        if function_call[0] == \"none\":\n            # 如果function_call为[\"none\"]，那就调用一次简单的chatGPT函数，不带任何函数功能。\n            # print(\"不需要调用任何的插件。简单请求一次GPT\")\n            ai_response_dict = openaibotsingleclass.chat(prompt_messages,voice_name)\n            return ai_response_dict\n        elif function_call[0] == \"auto\":\n            # 如果function_call为[\"auto\"]，就使用全部的插件。一般不会使用，因为带的内容太多了。\n            functions = functions\n        else:\n            # 如果function_call为具体函数名字的列表，就使用具体的插件。并把这些插件，插入到tools列表中。\n            functions = filter_dict_array(functions,\"name\",function_call)\n\n        # 组装tools字段类型，给tool_choice变量赋值。\n        for function in functions:\n            tools_item = {\"type\": \"function\",\"function\": function}\n            tools.append(tools_item)\n        tool_choice=\"auto\"\n        # print(f\"调用的函数：\\n {tools}\")\n\n        # 组装调用ChatgptFunction的messages。\n        function_prompt_messages = [{\"role\": \"system\",\"content\":\"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous\"}]\n        function_prompt_messages.append(prompt_messages[-1])\n        # print(\"调用函数前的function_prompt_messages\")\n        # print(function_prompt_messages)\n\n        # 组装请求ChatgptFunction的data\n        data = {\n            \"model\": \"gpt-3.5-turbo-1106\",\n            \"messages\": function_prompt_messages,\n            \"tools\":tools,\n            \"tool_choice\":tool_choice\n        }\n\n        # 发起ChatgptFunction的请求\n        ai_function_response = requests.post(self.openai_api_url, headers=self.headers, data=json.dumps(data))\n        # print(ai_function_response.text)\n\n        ai_function_response_dict = ai_function_response.json()['choices'][0]['message']\n        # print(ai_function_response_dict)\n        return_message = []\n        # return_message.append(ai_function_response_dict) #不将ChatGPT function和function本身的结果放入到聊天记录中。\n\n        if ai_function_response_dict.get(\"tool_calls\"):\n            # 判断ai_function_response_dict中是不是有名为tool_calls的键。\n            # print(\"首次调用GPT，返回了JSON格式的数据。\")\n            function_prompt_messages.append(ai_function_response_dict) # 将首次请求结果放入到prompt_message中，准备第二次请求。\n            tool_calls = ai_function_response_dict['tool_calls'] # 获取首次请求返回的函数调用信息。\n            for tool_call in tool_calls:\n                # 函数可能会需要调用多个函数，循环每个需要调用的函数。\n                if tool_call['type'] == \"function\":\n                    # tool_call中可能还是其他工具，需要判断一下，是不是fuction\n                    function_name = tool_call['function']['name']  # 获取要调用函数的名称\n                    function_args_str = tool_call['function']['arguments'] # 获取调用函数的参数信息\n                    function_args = json.loads(function_args_str) # 参数信息原来是字符串要转为json\n\n                    # 根据函数名称，加载同名模块下的同名函数。\n                    module_name = function_name\n                    module_path = os.path.join(workdir, 'functionplugin', module_name + '.py')\n                    module = importlib.util.module_from_spec(spec:= importlib.util.spec_from_file_location(module_name, module_path)) # type: ignore\n                    spec.loader.exec_module(module)\n                    fuction_to_call = getattr(module, function_name)  # 获取函数对象\n                    # 调用执行对应的函数，并将结果赋值给function_response，function_response为固定的json格式。\n                    function_response = fuction_to_call(function_args)\n                    # print(function_response)\n\n                    # 组装二次调用的message\n                    function_message = {\n                        \"tool_call_id\": tool_call[\"id\"],\n                        \"role\": \"tool\",\n                        \"name\": function_name,\n                        \"content\": function_response[\"details\"],\n                    }\n                    function_prompt_messages.append(function_message)\n                    # return_message.append(function_message) # 不将ChatGPT function和function本身的结果放入到聊天记录中。\n            \n            # print(f\"二次调用时的prompt message：{function_prompt_messages}\")\n            second_ai_response_dict = openaibotsingleclass.chat(function_prompt_messages,voice_name)\n            # print(f\"再次调用一次GPT返回的结果:{second_ai_response_dict}\")\n            return_message.append(second_ai_response_dict)\n            return return_message\n\n        else:\n            # 虽然明确要求使用函数插件，但是因为信息不足等原因，还是直接返回了面向终端用户的信息。\n            # print(\"虽然要求调用了插件，但是GPT还是返回了直接面向终端用户的信息，表示现有的信息不足以按插件要求返回JSON数据。\")\n            return return_message\n\nif __name__ == '__main__':\n    system_content = \"你是一个有用的智能助手！\"\n    function_call_name_1 = input(\"请输入插件1的名称：\") or \"sendemail\"\n    function_call_name_2 = input(\"请输入插件2的名称：\") or \"posttoqw\"\n    function_call = [function_call_name_1,function_call_name_2]\n    prompt = input(\"请输入你的问题：\") or \"将我中了500万大大奖这条消息,推送到企业微信。同时发邮件告诉任亚军，你可以躺平了。\"\n    messages=[{\"role\":\"system\",\"content\":system_content},{\"role\": \"user\", \"content\":prompt}]\n    openaibotfunction = OpenaiBotFunction()\n    result = openaibotfunction.chat_with_funciton(messages,function_call)\n    if isinstance(result, list):\n        response_content = result[-1][\"content\"]\n    else:\n        response_content = result[\"content\"]\n    print(response_content)"}
{"type": "source_file", "path": "erniebot/erniebotmult.py", "content": "import os,json,sys,configparser\nimport copy\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom erniebot import erniebotsingle\nfrom erniebot import erniebotfunction\n\nerniebotsingleclass = erniebotsingle.ErnieBotSingle()\nerniebotfunctionclass = erniebotfunction.ErnieBotFunction()\n\nclass ErnieBotMult:\n    def __init__(self):\n        pass\n\n    def chatmult(self,username,prompt,system_content=\"You are a helpful assistant\",functionname=[\"none\"],voice_name=\"zh-CN-XiaoxiaoNeural\"):\n        # 用户ID文件路径\n        username_fpath = f\"{username}.json\"\n        username_fpath = os.path.join(workdir,\"log\",username_fpath)\n        # 判断用户ID文件是不是存在，存在就读取，不存在就建立\n        if os.path.exists(username_fpath):\n            with open(username_fpath) as f:\n                message = json.load(f) \n        else:\n            message = []\n            system_dict = {\"role\":\"system\",\"content\": system_content}\n            message.append(system_dict)\n\n        # 构造本次问答的问题\n        prompt_dict = {\"role\":\"user\",\"content\": prompt}\n        \n        # 将本次的提问和历史记录整合\n        message.append(prompt_dict)\n\n        # 如果聊天记录很长，只选取system和最近两轮的会话\n        messages_thistime = copy.deepcopy(message)\n        if len(messages_thistime)>=5:\n            messages_thistime = [messages_thistime[0]] + messages_thistime[-4:]\n            # print(messages_thistime)\n\n        # 调用单轮会话的模块获取结果\n        #response_dit = erniebotsingleclass.chat(messages_thistime,voice_name) #使用Azure的接口\n        # 调用支持函数的单轮会话模块获取结果。\n        response_dit = erniebotfunctionclass.chat_with_funciton(messages_thistime,functionname,voice_name) \n        \n        # print(response_dit)\n        # 将本次的回答和历史记录整合\n        message.append(response_dit)\n\n        with open(username_fpath, \"w\",encoding='utf-8') as file:\n            json.dump(message, file)\n\n        # 单独获取结果并打印，并作为函数返回结果\n        response_content = response_dit[\"content\"]\n        # print(response_content)\n        return response_content\n\nif __name__ == '__main__':\n    username = \"1\"\n    prompt =  input(\"请输入你的问题：\")\n    system_content = \"你是一个有用的智能助手。\"\n    functionname = [\"none\"]\n    erniebotmult = ErnieBotMult()\n    erniebotmult.chatmult(username,prompt,system_content,functionname)"}
{"type": "source_file", "path": "functionplugin/videovison.py", "content": "import os,json,sys,configparser\nimport cv2\nfrom datetime import datetime\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom openaibot.openaibotsinglevison import OpenaiBotSingleVison\nfrom functionplugin import aliyunossup\n\nopanaibotsinglevisonclass = OpenaiBotSingleVison()\n\n# 获取当前时间\nnow = datetime.now()\n\n# 格式化为字符串\ntime_str = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n\ndef getimagepath():\n    # 打开默认摄像头，参数0表示设备编号，如果有多个摄像头，则可能需要选择不同的编号\n    camera = cv2.VideoCapture(0)\n    # 设置摄像头的分辨率\n    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n    # 读取一帧图像\n    success, frame = camera.read()\n    # 如果读取成功，则保存图像到本地文件\n    imagepath = f\"{workdir}/openaibot/image/photo{time_str}.jpg\"\n    if success:\n        cv2.imwrite(imagepath, frame)\n    # 释放摄像头\n    camera.release()\n    aliyunossup_args = {\"file_path\":imagepath,\"file_dir\":\"gpt4vison\"}\n    imageurl = aliyunossup.aliyunossup(aliyunossup_args)[\"details\"]\n    print(\"捕捉到的图像：\" + imageurl)\n    return imageurl\n\ndef videovison(function_args):\n    prompt = function_args['text']\n    imageurl = getimagepath()\n    images_list = [imageurl]\n\n    ai_image_response_content = opanaibotsinglevisonclass.chat_with_image(images_list,prompt)[\"content\"]\n    # print(ai_image_response_content)\n    callback_json = {\"request_gpt_again\":True,\"details\":f\"{ai_image_response_content}\"}\n    return callback_json\n\nif __name__ == '__main__':\n    function_args = {\"text\":\"你看到了什么？\"}\n    videovison(function_args)"}
{"type": "source_file", "path": "main.py", "content": "import os,json,sys,configparser\n\nworkdir = os.path.dirname(os.path.realpath(__file__))\nsys.path.append(workdir)\n\nfrom speechmodules.speech2text import AzureASR\nfrom speechmodules.text2speech import AzureTTS\nfrom azurebot.azurebotmult import AzureBotMult\nfrom erniebot.erniebotmult import ErnieBotMult\nfrom openaibot.openaibotmult import OpenaiBotMult\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nrobot_info_file_path = os.path.join(workdir, \"robot_info.json\")\naimanufacturer = config[\"AI\"][\"aimanufacturer\"]\nif aimanufacturer == \"azurebot\":\n    chatmult = AzureBotMult()\nelif aimanufacturer == \"erniebot\":\n    chatmult = ErnieBotMult()\nelif aimanufacturer == \"openaibot\":\n    chatmult = OpenaiBotMult()\n\n# 增加程序启动时的开机广告，并且告知用户智能音箱的唤醒词。\nprint(f\"system:叮叮当当！我的唤醒词是：{config['Wakeword']['wakewordtext']}\")\nAzureTTS(\"zh-CN-XiaoxiaoNeural\").text2speech_and_play(f\"叮叮当当！我的唤醒词是：{config['Wakeword']['wakewordtext']}\")\n\n# 这是用于判断一个字符串中，是不是包含一个列表中的任意词，如果包含就会返回列表中的这个元素。\n# 实际业务上，是判断语音转为文字的内容，是不是包含任意一个智能语音助手的激活关键词。\ndef find_robot_keyword(s,lst):\n    for elem in lst:\n        if elem in s:\n            return elem\n    return None\n\nclass Yoyo:\n    def __init__(self):\n        with open(robot_info_file_path , 'r' ,encoding=\"UTF-8\") as f:\n            # 导入智能助手的配置文件。\n            self.robot_info = json.load(f)\n            self.robot_id_list = [d['robot_id'] for d in self.robot_info]\n            self.robot_keywords_list = [d['robot_keyword'] for d in self.robot_info]\n\n    def robot_model(self,robot_id=\"xiaozhushou\"):\n        # 主要用于判断加载哪一个智能语音助手。\n        try:\n            robot_index = self.robot_id_list.index(robot_id)\n        except ValueError:\n            raise SystemExit(\"没有此配置的机器人！\")\n\n        self.robot_name = self.robot_info[robot_index ]['robot_name']\n        self.robot_describe = self.robot_info[robot_index ]['robot_describe']\n        self.robot_voice_name = self.robot_info[robot_index ]['robot_voice_name']\n        self.robot_reply_word = self.robot_info[robot_index ]['robot_reply_word']\n        self.robot_system_content = self.robot_info[robot_index ]['robot_system_content']\n        self.username = self.robot_info[robot_index ]['username']\n        self.robot_function_model = self.robot_info[robot_index ]['robot_function_model']\n\n        self.asr = AzureASR()\n        self.tts = AzureTTS(self.robot_voice_name)\n        self.stopword = config['Wakeword']['StopWord']\n        if config['Wakeword']['WakeUpScheme'] == \"Picovoice\":            \n            from picovoice.wakeword import PicoWakeWord\n            self.wakeword = PicoWakeWord()      \n        elif config['Wakeword']['WakeUpScheme'] == \"Snowboy\":\n            from snowboy.wakeword import SnowboyWakeWord\n            self.wakeword = SnowboyWakeWord()  \n        else:\n            raise SystemExit(\"config.ini配置文件中，WakeUpScheme可选值只有：Picovoice和 Snowboy\")\n\n    def run(self):\n        while True:\n            isdetected = self.wakeword.detect_wake_word() # 持续监测麦克风收录的声音是不是包含唤醒词，监测到后会返回大于0的整数。如果没有监测到就持续监测。\n            if isdetected >= 0:\n                # 唤醒后，打印和播放当前智能语音助手的打招呼语。\n                print(f'{self.robot_name}:{self.robot_reply_word}')  \n                self.tts.text2speech_and_play(self.robot_reply_word)\n                keepawake = True # 用于控制智能语音助手是不是保持持续对话模式，为假的话会进入睡眠模式，睡眠模式下需要用唤醒词重新唤醒。\n                while keepawake:         \n                    q = self.asr.speech2text() # 获取用户输入的内容，由录音转为文字。\n                    if q == None or self.stopword in q:\n                        # 判断录入的内容是不是空值，或者录入的录入的内容是不是包含“停止词”。如果为空或者包含停止词，则进入睡眠模式。\n                        print(f'{self.username}:{q}')\n                        print(f\"{self.robot_name}:拜拜，有事用唤醒词叫我。\")\n                        self.tts.text2speech_and_play(f\"拜拜，有事用唤醒词叫我。\")\n                        print(\"system:已经进入睡眠模式！\")                        \n                        keepawake = False\n                    else:\n                        robot_keyword = find_robot_keyword(q,self.robot_keywords_list) #判断用户录入的内容是不是包含任意一个智能语音助手的激活关键词。如果不包含，就请求ChatGPT的结果。如果包含，就切换到对应的智能语音助手。\n                        if robot_keyword == None:\n                            print(f'{self.username}:{q}') # 打印用户录入的内容\n                            res = chatmult.chatmult(self.username,q,self.robot_system_content,self.robot_function_model,self.robot_voice_name) # 请求ChatGPT的接口。\n                            print(f'{self.robot_name}(GPT)：{res}')   # 打印返回的结果。\n                            # self.tts.text2speech_and_play(res)   # 朗读返回的结果。\n                        else:\n                            switch_robot_index = self.robot_keywords_list.index(robot_keyword)\n                            switch_robot_id = self.robot_info[switch_robot_index][\"robot_id\"] # 确定要切换到哪一个智能语音助手。\n                            self.robot_model(switch_robot_id)   #切换智能语音助手。\n                            print(f\"system:已切换到「{robot_keyword}」。\")\n                            self.tts.text2speech_and_play(f\"已切换到「{robot_keyword}」\")\n                            # keepawake = False #原本切换智能语音助手后需要重新唤醒，现在应该不需要了。                                           \n\n    def loop(self,):\n        while True:\n            try:\n                self.robot_model()\n                self.run()\n            except KeyboardInterrupt:\n                break\n\nif __name__ == '__main__':\n    yoyo = Yoyo()\n    yoyo.loop()"}
{"type": "source_file", "path": "functionplugin/posttoqw.py", "content": "# Python 3.9\nimport json\nimport requests\nimport sys\n\n\nheaders = {'Content-Type': 'application/json'}\n\ndef posttoqw(function_args):\n    webhook_url = \"https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=c6434bc3-7ef0-4afc-9c20-f1ee4f822407\"\n    text_content = function_args['text']\n    payload_message = {\"msgtype\": \"text\",\"text\": {\"content\": text_content}}\n    response = requests.request(\"POST\", webhook_url, headers=headers, data=json.dumps(payload_message))\n    response = json.loads(response.text)\n    if not(response['errcode']):\n        callback_json = {\"request_gpt_again\":False,\"details\":f\"已将消息推送到企业微信群。\"}\n        return callback_json\n    else:\n        callback_json = {\"request_gpt_again\":False,\"details\":f\"推送消息是出错，请检查。\"}\n        return callback_json\n\nif __name__ == '__main__':\n    function_args = {\"text\":\"你好\"}\n    posttoqw(function_args)"}
{"type": "source_file", "path": "functionplugin/search.py", "content": "import os\nimport datetime\nimport pytz\nimport json\nimport requests\nimport configparser\nimport sys\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['serpapi']\n\ndef search(function_args):\n    q = function_args['q']\n    params = {\n        \"q\": q ,\n        \"engine\":\"baidu\",\n        \"api_key\": configsection[\"key\"]\n    }\n    url = f\"https://serpapi.com/search.json?engine=baidu&q={q}\"\n    response = requests.get(url, params=params)\n    if response.status_code == 200:\n        first_res = response.json()['organic_results'][0]\n        snippet = first_res.get(\"snippet\",\"\")\n        title = first_res.get(\"title\",\"\")\n        link = first_res.get(\"link\",\"\")\n        for i in range(5):\n            first_res = response.json()['organic_results'][i]\n            snippet = first_res.get(\"snippet\",\"\")\n            if snippet != \"\":\n                title = first_res.get(\"title\",\"\")\n                link = first_res.get(\"link\",\"\")\n                break\n        final_res = {\"title\":title,\"snippet\":snippet,\"link\":link}\n        # print(final_res)\n    else:\n        print(\"Error: \", response.status_code)\n\n    callback_json =  {\"request_gpt_again\":True,\"details\":final_res}\n    return callback_json\n\nif __name__ == '__main__':\n    q = input(\"要搜索的关键词：\")\n    function_args = {\"q\":q}\n    search(function_args)\n\n\n\n\n\n"}
{"type": "source_file", "path": "functionplugin/plugindemo.py", "content": "import json\nimport requests\nimport sys\n\n\nheaders = {'Content-Type': 'application/json'}\n\ndef plugindemo(function_args):\n    # 模块名称和模块中的函数，名称必须一致，这里均为plugindemo。必须接受function_args这个字段作为参数。\n    webhook_url = \"https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=c6434bc3-7ef0-4afc-9c20-f1ee4f822407\"\n    text_content = function_args['text']\n    payload_message = {\"msgtype\": \"text\",\"text\": {\"content\": text_content}}\n    response = requests.request(\"POST\", webhook_url, headers=headers, data=json.dumps(payload_message))\n    response = json.loads(response.text)\n    if not(response['errcode']):\n        callback_json = {\"request_gpt_again\":False,\"details\":f\"已将消息推送到企业微信群。\"}\n        return callback_json\n    else:\n        # 函数回调必须有request_gpt_again字段，用于判断是否需要继续调用gpt.details字段用于更加详细的信息。\n        callback_json = {\"request_gpt_again\":False,\"details\":f\"推送消息是出错，请检查。\"}\n        # 函数返回必须以字符串形式。\n        return callback_json\n\nif __name__ == '__main__':\n    function_args = {\"text\":\"你好\"}\n    plugindemo(function_args)"}
{"type": "source_file", "path": "erniebot/__init__.py", "content": ""}
{"type": "source_file", "path": "functionplugin/tank.py", "content": "import wiringpi\nimport time\nimport json\n\nwiringpi.wiringPiSetupPhys()   #设置GPIO编号为物理编码方式。\n# wiringpi.wiringPiSetup()        #设置GPIO编号为wPi方式。\n\ndef left_motor(direction=0,speed=100):\n\t# direction为0是停转，为1是正转，为2是反转。\n\tB_ENA,B_IN3,B_IN4 = 22,24,26\n\twiringpi.pinMode(B_ENA,1)\n\twiringpi.softPwmCreate(B_ENA, 0, 100) \n\twiringpi.pinMode(B_IN3,1) \n\twiringpi.pinMode(B_IN4,1)   \n\tif direction == 0:\t\t\n\t\twiringpi.digitalWrite(B_IN3,0)\n\t\twiringpi.digitalWrite(B_IN4,0)\n\telif direction == 1:\t\t\n\t\twiringpi.softPwmWrite(B_ENA, speed)\n\t\twiringpi.digitalWrite(B_IN3,0)\n\t\twiringpi.digitalWrite(B_IN4,1)\n\telif direction == 2:\t\n\t\twiringpi.softPwmWrite(B_ENA, speed)\n\t\twiringpi.digitalWrite(B_IN3,1)\n\t\twiringpi.digitalWrite(B_IN4,0)\n\ndef right_motor(direction=0,speed=100):\n\tA_ENA,A_IN1,A_IN2 = 11,13,15\n\twiringpi.pinMode(A_ENA,1)\n\twiringpi.softPwmCreate(A_ENA, 0, 100)\n\twiringpi.pinMode(A_IN1,1) \n\twiringpi.pinMode(A_IN2,1)\n\tif direction == 0:\n\t\twiringpi.digitalWrite(A_IN1,0)\n\t\twiringpi.digitalWrite(A_IN2,0)\n\telif direction == 1:\n\t\twiringpi.softPwmWrite(A_ENA, speed)\n\t\twiringpi.digitalWrite(A_IN1,1)\n\t\twiringpi.digitalWrite(A_IN2,0)\n\telif direction == 2:\n\t\twiringpi.softPwmWrite(A_ENA, speed)\n\t\twiringpi.digitalWrite(A_IN1,0)\n\t\twiringpi.digitalWrite(A_IN2,1)\n\ndef stop():\n\tleft_motor(0)\n\tright_motor(0)\n\ndef forward(speed=100,duration=2):\n\tright_motor(1,speed)\n\tleft_motor(1,speed)\n\ttime.sleep(duration)\n\tstop()\n\ndef backup(speed=100,duration=2):\n\tleft_motor(2,speed)\n\tright_motor(2,speed)\n\ttime.sleep(duration)\n\tstop()\n\t\ndef turnleft(speed=100,duration=0.3):\n\tleft_motor(0)\n\tright_motor(1,speed)\n\ttime.sleep(duration)\n\tstop()\n\t\ndef turnright(speed=100,duration=0.3):\n\tleft_motor(1,speed)\n\tright_motor(0)\n\ttime.sleep(duration)\n\tstop()\n\t\ndef circle(speed=100,duration=1):\n\tleft_motor(1,speed)\n\tright_motor(2,speed)\n\ttime.sleep(duration)\n\tstop()\n\ndef tank(function_args):\n    try:\n        action = function_args[\"action\"]\n        duration = function_args[\"duration\"]\n\t\t# 判断 duration 是否为0到10之间的数字，如果小于等于0 或不是数字，就将duration设置为0.5，如果duration大于10，就将duration设置为10\n        duration = float(duration)\n        if duration <= 0 or duration > 10:\n            duration = 10\n        else:\n            pass\n    except ValueError:\n        action = \"forward\"\n        duration = 0.5\n\n    try:\n        exec(f\"{action}(duration={duration})\")\n        callback_json = {\"request_gpt_again\":False,\"details\":\"OK\"} \n        return callback_json\n    except Exception as e:\n        callback_json = {\"request_gpt_again\":False,\"details\":\"命令解析错误！\"}\n        return callback_json\n\ndef loop():\n\twhile True:\n\t\tprint(\"1为前进，2为后退，3为左转，4为右转，5为转圈，6为停止。\")\n\t\tactionstr = input(\"要执行的动作：\")\n\t\tactionindex = int(actionstr)\n\t\t#speed = int(input(\"速度百分比：\"))\n\t\tspeed = 100\n\t\tduration = float(input(\"运行时间：\"))\n\t\taction = ''\n\t\tif actionindex == 1:\n\t\t\taction = \"forward\"\n\t\telif actionindex == 2:\n\t\t\taction = \"backup\"\n\t\telif actionindex == 3:\n\t\t\taction = \"turnleft\"\n\t\telif actionindex == 4:\n\t\t\taction = \"turnright\"\n\t\telif actionindex == 5:\n\t\t\taction = \"circle\"\n\t\telif actionindex == 6:\n\t\t\taction = \"stop\"\n\t\telse:\n\t\t\taction = actionstr\n\t\texec(f\"{action}({speed},{duration})\")\n\nif __name__ == '__main__':\n    loop()\n    # function_args = {\"action\":\"forward\",\"duration\":11}\n    # res = tank(function_args)\n    # res = json.loads(res)\n    # print(res[\"details\"])"}
{"type": "source_file", "path": "functionplugin/tankwebcontrol.py", "content": "from flask import Flask, render_template, Response\nfrom flask_socketio import SocketIO, emit\nimport tank\nimport cv2\nimport base64\n\napp = Flask(__name__)\n\nclass VideoCamera(object):\n    def __init__(self):\n        self.cap = cv2.VideoCapture(1) \n    \n    def __del__(self):\n        self.cap.release()\n    \n    def get_frame(self):\n        success, image = self.cap.read()\n        if success:\n            ret, jpeg = cv2.imencode('.jpg', image)\n            return jpeg.tobytes()\ndef gen(camera):\n    while True:\n        frame = camera.get_frame()\n        yield (b'--frame\\r\\n'\n               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n\\r\\n')\n      \n# 定义四个路由，与四个按钮对应，并将其连接到相应的函数\n@app.route('/forward', methods=['GET', 'POST'])\ndef forward():\n    tank.right_motor(1,100)\n    tank.left_motor(1,100)\n    return \"向前\"\n\n@app.route('/backup', methods=['GET', 'POST'])\ndef backup():\n    tank.right_motor(2,100)\n    tank.left_motor(2,100)\n    return \"向后\"\n\n@app.route('/turnleft', methods=['GET', 'POST'])\ndef turnleft():\n    tank.right_motor(1,100)\n    tank.left_motor(0,100)\n    return \"左转\"\n\n\n@app.route('/turnright', methods=['GET', 'POST'])\ndef turnright():\n    tank.right_motor(1,100)\n    tank.left_motor(0,100)\n    return \"右转\"\n\n@app.route('/stop', methods=['GET', 'POST'])\ndef stop():\n    tank.right_motor(0,100)\n    tank.left_motor(0,100)\n    return \"停止\"\n\n# 定义一个默认路由，将其连接到一个 HTML 文件，其中包含四个按钮和相应的 JavaScript 代码\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/video_feed')\ndef video_feed():\n    return Response(gen(VideoCamera()), mimetype='multipart/x-mixed-replace; boundary=frame')\n\nif __name__ == '__main__':\n    app.run()\n"}
{"type": "source_file", "path": "azurebot/azurebotsingle.py", "content": "import os,json,sys,configparser\nimport openai\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom speechmodules import text2speech\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['Azureopenai']\n\ndef streamresult(completion):\n    chunks_content = \"\"\n    for chunk in completion:\n        if chunk[\"choices\"]:\n            choices = chunk[\"choices\"][0]\n            delta = choices.get('delta', '')\n            content = delta.get('content', '')\n            chunks_content = chunks_content + content\n            splitword_list = [\"。\", \"！\",\"？\"]\n            if any(splitword in content for splitword in splitword_list):\n                print(chunks_content, end='', flush=True)  # 在纯文本对话模式下，可以将显示对话内容在终端中。\n                yield chunks_content\n                chunks_content = \"\"\n\nclass AzureBotSingle:\n    def __init__(self):\n        openai.api_type = \"azure\"\n        openai.api_version = configsection['openai_api_version']\n        openai.api_base = configsection['openai_api_base']\n        openai.api_key = configsection['openai_api_key']\n        self.gpt35_model = configsection['gpt35_deployment_name']\n\n    def chat(self,prompt_messages,voice_name=\"zh-CN-XiaoxiaoNeural\"):\n        tts = text2speech.AzureTTS(voice_name)\n        # if model is None:\n        #     model = self.gpt35_model\n        try:\n            completion = openai.ChatCompletion.create(\n                engine = self.gpt35_model,\n                messages=prompt_messages,\n                temperature=0.8,\n                stream=True\n                )\n            stream_chunks = streamresult(completion)\n            stream_content = \"\"\n            while True:\n                try:\n                    stream_chunk = next(stream_chunks)\n                    stream_content = stream_content + stream_chunk\n                    #print(stream_content)\n                except StopIteration:\n                    break\n                tts.text2speech_and_play(stream_chunk)\n            return {\"role\": \"assistant\",\"content\": stream_content}\n            # response_message = completion.choices[0].message\n            # print(response_message)\n            # return response_message\n        except openai.error.RateLimitError: # type: ignore\n            response_message = {\n                \"role\": \"assistant\",\n                \"content\": \"抱歉，服务器繁忙，请稍后重试!\"\n                }\n            # print(response_message)\n            return response_message\n\nif __name__ == '__main__':\n    system = \"You are a helpful assistant\"\n    prompt = input(\"请输入你的问题：\")\n    messages=[{\"role\":\"system\",\"content\": system},{\"role\": \"user\", \"content\":prompt}]\n    azurebotsingle = AzureBotSingle()\n    post_message = azurebotsingle.chat(messages)[\"content\"]\n    print(post_message)"}
{"type": "source_file", "path": "functionplugin/wjxwjlist.py", "content": "import os\nimport smtplib\nimport json\nimport time\nimport hashlib\nimport configparser\nimport requests\nimport sys\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['WJX']\n\nappkey = configsection['appkey']\nheaders = {'Content-Type': 'application/json'}\nurl = \"https://www.wjx.cn/openapi/default.aspx\"\n\ntable = PrettyTable()\ntable.field_names = [\"id\", \"标题\", \"答卷数\"]\n\ndef calculateSign(params, appkey):\n    # 1. 对参数名按ASCII码排序\n    sorted_params = sorted(params.items())\n    # print(sorted_params)\n    # 2. 拼接所有参数名的值\n    encoded_str = \"\"\n    for key, value in sorted_params:\n        if value:\n            encoded_str +=  str(value)\n    # print(encoded_str)\n    # 3. 将appkey加上拼接字符串，得到加密原串\n    \n    encrypted_str =  encoded_str + appkey\n    # 4. 进行SHA1加密\n    sha1 = hashlib.sha1()\n    sha1.update(encrypted_str.encode('utf8'))\n    sign = sha1.hexdigest()\n    # 5. 返回计算得到的签名\n    return sign\n\ndef wjxwjlist(function_args):\n    days = function_args[\"days\"]\n    params = {\n        'appid' : configsection['appid'],\n        'ts' : int(time.time()),\n        'encode' : \"sha1\",\n        'action' : \"1000002\",\n        'creater' : \"renyajun\",\n        'time_type' : 2,\n        'sort' : 1,\n        'begin_time' : int(time.time()*1000) - days*86400000,\n        'end_time' :int(time.time()*1000)\n\n    }\n    sign = calculateSign(params, appkey)\n    params['sign'] = sign\n    response = requests.post(url, params=params, headers=headers)\n    if json.loads(response.text)['result']:\n        activitys_list_json = json.loads(response.text)['data']['activitys']\n        for name, info in activitys_list_json.items():\n            title = info[\"title\"]\n            answer_total = info[\"answer_total\"]\n            table.add_row([name, title, answer_total])\n        \n    print(table)\n    table_str = str(table)\n    callback_json = {\"request_gpt_again\":True,\"details\":table_str}\n    return callback_json\n\nif __name__ == '__main__':\n    function_args = {\"days\":5}\n    wjxwjlist(function_args)"}
{"type": "source_file", "path": "erniebot/erniebotfunction.py", "content": "import os,json,sys,configparser\nimport requests\nimport importlib\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom erniebot import erniebotsingle\nfrom speechmodules import text2speech\n\nerniebotsingleclass = erniebotsingle.ErnieBotSingle()\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['baiduernie']\nErnieApiVersion = configsection[\"ErnieApiVersion\"]\n\ndef get_access_token():\n    \"\"\"\n    使用 API Key，Secret Key 获取access_token，替换下列示例中的应用API Key、应用Secret Key\n    \"\"\"\n    ApiKey = configsection['ApiKey']\n    keySecret = configsection['keySecret']\n    url = f\"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={ApiKey}&client_secret={keySecret}\"\n    \n    payload = json.dumps(\"\")\n    headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n    \n    response = requests.request(\"POST\", url, headers=headers, data=payload)\n    return response.json().get(\"access_token\")\n\ndef find_values_by_index(list1, list2, index):\n    # 两个元素数量一致的列表，列表元素均为字符串。已知一个列表的值，寻找另一个列表中，其下标一致的值。\n    result = \"\"\n    for i in range(len(list1)):\n        if list1[i] == index:\n            result = list2[i]\n    return result\n\ndef filter_dict_array(dict_array, key, val_array):\n    \"\"\"\n    过滤数组中key为指定值的字典元素\n    functions = filter_dict_array(functions,\"name\",function_call)\n    \"\"\"\n    result = []\n    for d in dict_array:\n        for v in  val_array:\n            if d.get(key) == v: # 精准匹配\n                result.append(d)\n    return result\n\nclass ErnieBotFunction:\n    def __init__(self):\n        pass\n    def chat_with_funciton(self,prompt_messages,function_call=[\"none\"],voice_name=\"zh-CN-XiaoxiaoNeural\"):\n    # 从文件中读取已有的函数插件列表\n        funnctionpluginlist_file_path = os.path.join(workdir,\"functionplugin\",\"functionpluginlist.json\")\n        with open(funnctionpluginlist_file_path, 'r' ,encoding=\"UTF-8\") as f:\n            functions = json.load(f)  \n\n        if function_call[0] == \"none\":\n            # 如果function_call为none，那就调用一次简单的erniebot函数，不带任何函数功能。\n            # print(\"不需要调用任何的插件。简单请求一次GPT\")\n            response_message = erniebotsingleclass.chat(prompt_messages,voice_name)\n            return response_message\n        elif function_call[0] == \"auto\":\n            # 如果function_call为auto，就使用全部的插件。\n            pass\n            # print(\"调用的函数：\")\n            # print(functions)\n        else:\n            # 如果function_call为具体名字，就使用具体的插件。\n            functions = filter_dict_array(functions,\"name\",function_call)\n            # print(\"调用的函数：\")\n            # print(functions)\n\n        requesturl = ErnieApiVersion + \"?access_token=\" + get_access_token()\n        headers = {'Content-Type': 'application/json'}\n        system = prompt_messages[0][\"content\"] # 文心一言的system不再messages中。需要从messages中获取。\n        prompt_messages.pop(0)  # 文心一言的system不再messages中。需要从messages中删除。\n        # print(\"调用函数前的prompt_message\")\n        # print(prompt_messages)\n\n        if len(prompt_messages) % 2 == 0:\n            # 文心一言的messages长度必须为奇数\n            prompt_messages.pop(0)\n        payload = json.dumps({\n            \"functions\":functions,\n            \"messages\": prompt_messages\n        })\n        response = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n        response_json = json.loads(response.text)\n\n        if \"error_code\" in response_json:\n            responseresult = f'服务出错，错误码：{response_json[\"error_code\"]}'\n            print(responseresult)\n            response_message = {\"role\": \"assistant\",\"content\": responseresult}\n            return response_message\n        elif \"function_call\" in response_json:\n            print(\"首次调用reniebot，返回了JSON格式的数据。\")\n            print(response_json[\"function_call\"])\n            function_name = response_json['function_call']['name']\n            function_args_str = response_json['function_call']['arguments']\n            function_args = json.loads(function_args_str)\n            function_thoughts = response_json['function_call']['thoughts']\n\n            # 组装第二次请求时的message\n            response_message = {\"role\": \"assistant\", \"content\": response_json[\"result\"], \"function_call\": {\"name\": function_name, \"arguments\": function_args_str}}\n            prompt_messages.append(response_message)\n\n            # 根据函数名称，加载同名模块下的同名函数。\n            module_name = function_name\n            module_path = os.path.join(workdir,'functionplugin', module_name + '.py')\n            module = importlib.util.module_from_spec(spec:= importlib.util.spec_from_file_location(module_name, module_path)) # type: ignore\n            spec.loader.exec_module(module)\n            fuction_to_call = getattr(module, function_name)  # 获取函数对象\n\n            # 调用对应的函数，并将结果赋值给function_response\n            function_response = fuction_to_call(function_args)\n\n            if function_response['request_gpt_again']:\n                # print(\"调用插件后，插件要求再调用一次GPT。\")\n                # 调用函数后，函数会返回是否再调用一次的字段，以下部分是需要再次调用GPT的场景。\n                # print(function_response['details'])\n                prompt_messages.append(\n                    {\n                        \"role\": \"function\",\n                        \"name\": function_name,\n                        \"content\": function_response,\n                    }\n                )\n                # print(\"再次调用插件时的，prompt_messages\")\n                # print(prompt_messages)\n                second_response = erniebotsingleclass.chat(prompt_messages,voice_name) #再次请求一次无函数调用功能的reniebot\n                # print(\"再次调用一次reniebot返回的结果。\")\n                print(second_response[\"content\"])\n                return second_response\n            else:\n                # 调用函数后，函数会返回是否再调用一次的字段，以下部分是不需要再次调用GPT的场景，在这种条件下，可以将函数返回的内容直接返回给终端用户。\n                # print(\"调用插件后，插件不要求再次调用GPT，插件直接返回了结果。\")\n                print(function_response['details'])\n                tts = text2speech.AzureTTS(voice_name)\n                tts.text2speech_and_play(function_response['details'])\n                second_response= {\"role\":\"assistant\",\"content\":function_response['details']}\n                return second_response\n        else:\n            # 虽然明确要求使用函数插件，但是因为信息不足等原因，还是直接返回了面向终端用户的信息。\n            # print(\"虽然要求调用了插件，但是GPT还是返回了直接面向终端用户的信息，表示现有的信息不足以按插件要求返回JSON数据。\")\n            responseresult = response_json[\"result\"]\n            print(responseresult)\n            response_message = {\"role\": \"assistant\",\"content\": responseresult}\n            return response_message\n\nif __name__ == '__main__':\n    system_content = \"你是一个有用的智能助手。\"\n    function_call_name = input(\"请输入插件的名称：\")\n    function_call = [function_call_name]\n    prompt = input(\"请输入你的问题：\")\n    messages=[{\"role\":\"system\",\"content\":system_content},{\"role\": \"user\", \"content\":prompt}]\n    erniebotfunction = ErnieBotFunction()\n    result = erniebotfunction.chat_with_funciton(messages,function_call)\n    print(result['content'])"}
{"type": "source_file", "path": "functionplugin/macshell.py", "content": "import os\nimport json\n\ndef macshell(function_args):\n    commands = function_args[\"commands\"]\n    print(commands)\n    os.system(f'{commands}')\n    callback_json = {\"request_gpt_again\":False,\"details\":\"终端命令已执行。\"} \n    return callback_json"}
{"type": "source_file", "path": "openaibot/openaimodel.py", "content": "# 罗列目前这个openai账号支持的model列表。\n\nimport os,json,sys,configparser\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nimport requests\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['Openai']\n\nopenai_api_url = configsection['openai_api_domain'] + \"/v1/models\"\nopenai_api_key = configsection['openai_api_key']\n\nheaders = {\"Content-Type\": \"application/json\",\"Authorization\": \"Bearer \" + openai_api_key}\n\nresponse = requests.get(openai_api_url, headers=headers) \n\nmodel_list = response.json()[\"data\"]\n\nfor model_dict in model_list:\n    model_id = model_dict[\"id\"]\n    print(model_id)\n"}
{"type": "source_file", "path": "openaibot/openaibotsinglevison.py", "content": "# 通过URL请求GPT4的多模态接口，即视觉识别接口。\nimport os,json,sys,configparser,requests\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\nfrom speechmodules import text2speech\n\n# 读取openai的配置参数文件。\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['Openai']\n\nfrom functionplugin import aliyunossup\nimport base64\n\n# 定义一个函数，可以将本地图片进行base64编码。\ndef encode_image_base64(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\nclass OpenaiBotSingleVison:\n    def __init__(self):\n        # 从配置文件中，读取openai的api域名和key，并构造URL请求的头部。\n        self.openai_api_url = configsection['openai_api_domain'] + \"/v1/chat/completions\"\n        self.openai_api_key = configsection['openai_api_key']\n        self.headers = {\"Content-Type\": \"application/json\",\"Authorization\": \"Bearer \" + self.openai_api_key}\n        self.model = \"gpt-4-vision-preview\" # 定义模型的名称，可能会随着时间而更新。\n\n    def chat_with_image(self,images_list:list,prompt:str=\"这张图片包含了什么内容？\"):\n        # 构造请求的message\n        messages_content = [{\"type\": \"text\",\"text\": prompt}]\n        messages = [{\"role\": \"user\", \"content\":messages_content}]\n\n        for image_item in images_list:\n            # 循环图片列表中的图片。\n            if not(image_item.startswith(\"http\") or image_item.startswith(\"https\")):\n                # 判断是不是url图片，如果是本地图片的话，就调用另外一个函数，上传到阿里云oss，返回图片的URL。\n                aliyunossup_function_args = {\"local_file_path\":image_item,\"oss_file_dir\":\"gpt4vison\"}\n                image_item = aliyunossup.aliyunossup(aliyunossup_function_args)[\"details\"]\n            messages_content_image = {\"type\": \"image_url\",\"image_url\": {\"url\":image_item,\"detail\": \"low\"}}\n            messages_content.append(messages_content_image)\n\n        # 构造URL请求的数据部分。\n        print(messages)\n        data = {\n            \"model\": self.model,\n            \"messages\": messages,\n            \"max_tokens\": 500 # 需要搞清楚这个参数的含义。\n        }\n\n        try:\n            # 发起api请求\n            ai_image_response = requests.post(self.openai_api_url, headers=self.headers, data=json.dumps(data)) \n            try:\n                # 使用try处理异常情况，因为api的请求返回的数据，可能会由于内容过滤等原因，返回\n                ai_image_response_dict = ai_image_response.json()['choices'][0]['message']\n            except Exception as e:\n                # 如果返回的是异常数据，就打印一下返回的文本内容。并且构造一个相同字典结构的返回数据，以使程序正确运行。\n                print(ai_image_response.text) \n                ai_image_response_dict = {\"role\": \"assistant\",\"content\":\"singlevison模块：Ai返回数据异常，图片解析错误。\"}\n        except requests.exceptions.RequestException as e:\n            print(\"请求发生异常：\", e)\n            ai_image_response_dict = {\"role\": \"assistant\",\"content\":\"singlevison模块：Ai接口请求异常，请依据打印内容进行检查。\"}\n\n        # 获取ai返回的文本数据，使用tts播放出来，并且打印出来。\n        ai_image_response_content = ai_image_response_dict[\"content\"]\n        print(ai_image_response_content) # 先打印结果\n\n        return ai_image_response_dict # 函数返回的数据是字典类型的数据，而不是文本数据。\n\nif __name__ == '__main__':\n    image_url  = input(\"请输入图片1的URL：\") or \"https://helpimage.paperol.cn/20231121160216.png\"\n    prompt = input(\"请输入你针对图片的提问：\") or \"这张图片内包含了什么内容？\"\n    images_list = [image_url]\n    openaibotsinglevison = OpenaiBotSingleVison()\n    ai_image_response_content = openaibotsinglevison.chat_with_image(images_list,prompt)[\"content\"]\n    # print(ai_image_response_content) # 函数中打印了结果，这里就不打印了。"}
{"type": "source_file", "path": "openaibot/openaibotsingle.py", "content": "# 通过URL请求OpanAI的接口。\nimport os,json,sys,configparser,requests\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\nfrom speechmodules import text2speech\n\n# 读取openai的配置参数文件。\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['Openai']\n\nclass OpenaiBotSingle:\n    def __init__(self,modelname = \"gpt-3.5-turbo-1106\"):\n        # 从配置文件中，读取openai的api域名和key，并构造URL请求的头部。\n        self.openai_api_url = configsection['openai_api_domain'] + \"/v1/chat/completions\"\n        self.openai_api_key = configsection['openai_api_key']\n        self.headers = {\"Content-Type\": \"application/json\",\"Authorization\": \"Bearer \" + self.openai_api_key}\n        self.model = modelname # 定义模型的名称，可能会随着时间而更新。\n\n    def chat(self,prompt_messages,voice_name=\"zh-CN-XiaoxiaoNeural\"):\n        # 定义对话的函数，并初始化tts,如果初始化tts时，没有音色的配置，tts就不会生效。\n        tts = text2speech.AzureTTS(voice_name)\n        # 构造URL请求的数据部分。\n        data = {\n            \"model\": self.model,\n            \"messages\": prompt_messages\n        }\n        \n        try:\n            # 发起api请求。\n            ai_response = requests.post(self.openai_api_url, headers=self.headers, data=json.dumps(data))\n            try:         \n                # 使用try处理异常情况，因为api的请求返回的数据，可能会由于内容过滤等原因，返回\n                ai_response_dict = ai_response.json()['choices'][0]['message']\n\n                # 打印一下token用量的信息\n                # ai_response_usage = ai_response.json()[\"usage\"]\n                # print(ai_response_usage)\n\n            except Exception as e:\n                # 如果返回的是异常数据，就打印一下返回的文本内容。并且构造一个相同字典结构的返回数据，以使程序正确运行。\n                print(ai_response.text) \n                ai_response_dict = {\"role\": \"assistant\",\"content\":\"single模块：Ai返回数据异常，请依据打印内容进行检查。\"}          \n        except requests.exceptions.RequestException as e:\n            print(\"请求发生异常：\", e)\n            ai_response_dict = {\"role\": \"assistant\",\"content\":\"single模块：Ai接口请求异常，请依据打印内容进行检查。\"}\n        \n        # 获取ai返回的文本数据，使用tts播放出来，并且打印出来。\n        ai_response_content = ai_response_dict[\"content\"]\n        print(ai_response_content) # 先打印结果\n        tts.text2speech_and_play(ai_response_content)  # 再播放声音。\n        return ai_response_dict # 函数返回的数据是字典类型的数据，而不是文本数据。\n\nif __name__ == '__main__':\n    system = input(\"请输入system的内容：\") or \"You are a helpful assistant\"\n    prompt = input(\"请输入你给ai的问题：\") or \"现在的日期是？\"\n    messages=[\n        {\"role\":\"system\",\"content\": system},\n        {\"role\": \"user\", \"content\":prompt}\n        ]\n    openaibotsingle = OpenaiBotSingle()\n    ai_response_content = openaibotsingle.chat(messages)[\"content\"]\n    # print(ai_response_content) # 函数中打印了结果，这里就不打印了。"}
{"type": "source_file", "path": "speechmodules/speech2text.py", "content": "import os,json,sys,configparser\nimport azure.cognitiveservices.speech as speechsdk\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\naudio_file_path = os.path.join(workdir, \"speechfile/speech.wav\")\n\nclass AzureASR:\n    def __init__(self):\n        self.AZURE_API_KEY = config['AzureSpeech']['AZURE_API_KEY']\n        self.AZURE_REGION = config['AzureSpeech']['AZURE_REGION']\n        self.speech_config = speechsdk.SpeechConfig(\n            subscription=self.AZURE_API_KEY,\n            region=self.AZURE_REGION\n            )\n        #self.speech_config.speech_recognition_language = \"zh-CN\"\n\n    def speech2text(self, audio_path: str = audio_file_path, if_microphone: bool = True):       \n        audio_config_recognizer = speechsdk.audio.AudioConfig(use_default_microphone=True)\n        auto_detect_source_language_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(languages=[\"zh-CN\",\"en-US\", \"ja-JP\"])\n        speech_recognizer = speechsdk.SpeechRecognizer(\n            speech_config=self.speech_config,\n            audio_config=audio_config_recognizer,\n            auto_detect_source_language_config=auto_detect_source_language_config,\n            )             \n        print(\"system:正在聆听...\")\n        speech_recognition_result = speech_recognizer.recognize_once_async().get()\n\n        if speech_recognition_result.reason == speechsdk.ResultReason.RecognizedSpeech:\n            # print(\"You:{}\".format(speech_recognition_result.text))\n            return speech_recognition_result.text\n        elif speech_recognition_result.reason == speechsdk.ResultReason.NoMatch:\n            print(\"system:未侦测到语音,已退出监听。如需使用，请用唤醒词重新唤醒。\")\n            # print(\"system:未侦测到语音，详细信息 :{}\".format(speech_recognition_result.no_match_details))\n        elif speech_recognition_result.reason == speechsdk.ResultReason.Canceled:\n            cancellation_details = speech_recognition_result.cancellation_details\n            print(\"system:未侦测到语音,已退出监听。如需使用，请用唤醒词重新唤醒。\")\n            # print(\"system:未侦测到语音，详细信息:{}\".format(cancellation_details.reason))\n            if cancellation_details.reason == speechsdk.CancellationReason.Error:\n                print(\"Error details:{}\".format(cancellation_details.error_details))\n                print(\"Did you set the speech resource key and region values?\")\n        # os.remove(audio_file_path)\n        return None\n\nif __name__ == \"__main__\":\n    asr = AzureASR()\n    result = asr.speech2text()\n    print(result)"}
{"type": "source_file", "path": "snowboy/snowboydecoder.py", "content": "#!/usr/bin/env python\n\nimport collections\nimport pyaudio\nfrom . import snowboydetect\nimport time\nimport wave\nimport os\nimport logging\nfrom ctypes import *\nfrom contextlib import contextmanager\n\nlogging.basicConfig()\nlogger = logging.getLogger(\"snowboy\")\nlogger.setLevel(logging.INFO)\nTOP_DIR = os.path.dirname(os.path.abspath(__file__))\n\nRESOURCE_FILE = os.path.join(TOP_DIR, \"resources/common.res\")\nDETECT_DING = os.path.join(TOP_DIR, \"resources/ding.wav\")\nDETECT_DONG = os.path.join(TOP_DIR, \"resources/dong.wav\")\n\ndef py_error_handler(filename, line, function, err, fmt):\n    pass\n\nERROR_HANDLER_FUNC = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)\n\nc_error_handler = ERROR_HANDLER_FUNC(py_error_handler)\n\n@contextmanager\ndef no_alsa_error():\n    try:\n        asound = cdll.LoadLibrary('libasound.so')\n        asound.snd_lib_error_set_handler(c_error_handler)\n        yield\n        asound.snd_lib_error_set_handler(None)\n    except:\n        yield\n        pass\n\nclass RingBuffer(object):\n    \"\"\"Ring buffer to hold audio from PortAudio\"\"\"\n\n    def __init__(self, size=4096):\n        self._buf = collections.deque(maxlen=size)\n\n    def extend(self, data):\n        \"\"\"Adds data to the end of buffer\"\"\"\n        self._buf.extend(data)\n\n    def get(self):\n        \"\"\"Retrieves data from the beginning of buffer and clears it\"\"\"\n        tmp = bytes(bytearray(self._buf))\n        self._buf.clear()\n        return tmp\n\n\ndef play_audio_file(fname=DETECT_DING):\n    \"\"\"Simple callback function to play a wave file. By default it plays\n    a Ding sound.\n\n    :param str fname: wave file name\n    :return: None\n    \"\"\"\n    ding_wav = wave.open(fname, 'rb')\n    ding_data = ding_wav.readframes(ding_wav.getnframes())\n    with no_alsa_error():\n        audio = pyaudio.PyAudio()\n    stream_out = audio.open(\n        format=audio.get_format_from_width(ding_wav.getsampwidth()),\n        channels=ding_wav.getnchannels(),\n        rate=ding_wav.getframerate(), input=False, output=True)\n    stream_out.start_stream()\n    stream_out.write(ding_data)\n    time.sleep(0.2)\n    stream_out.stop_stream()\n    stream_out.close()\n    audio.terminate()\n\n\nclass HotwordDetector(object):\n    \"\"\"\n    Snowboy decoder to detect whether a keyword specified by `decoder_model`\n    exists in a microphone input stream.\n\n    :param decoder_model: decoder model file path, a string or a list of strings\n    :param resource: resource file path.\n    :param sensitivity: decoder sensitivity, a float of a list of floats.\n                              The bigger the value, the more senstive the\n                              decoder. If an empty list is provided, then the\n                              default sensitivity in the model will be used.\n    :param audio_gain: multiply input volume by this factor.\n    :param apply_frontend: applies the frontend processing algorithm if True.\n    \"\"\"\n\n    def __init__(self, decoder_model,\n                 resource=RESOURCE_FILE,\n                 sensitivity=[],\n                 audio_gain=1,\n                 apply_frontend=False):\n\n        tm = type(decoder_model)\n        ts = type(sensitivity)\n        if tm is not list:\n            decoder_model = [decoder_model]\n        if ts is not list:\n            sensitivity = [sensitivity]\n        model_str = \",\".join(decoder_model)\n\n        self.detector = snowboydetect.SnowboyDetect(\n            resource_filename=resource.encode(), model_str=model_str.encode())\n        self.detector.SetAudioGain(audio_gain)\n        self.detector.ApplyFrontend(apply_frontend)\n        self.num_hotwords = self.detector.NumHotwords()\n\n        if len(decoder_model) > 1 and len(sensitivity) == 1:\n            sensitivity = sensitivity * self.num_hotwords\n        if len(sensitivity) != 0:\n            assert self.num_hotwords == len(sensitivity), \\\n                \"number of hotwords in decoder_model (%d) and sensitivity \" \\\n                \"(%d) does not match\" % (self.num_hotwords, len(sensitivity))\n        sensitivity_str = \",\".join([str(t) for t in sensitivity])\n        if len(sensitivity) != 0:\n            self.detector.SetSensitivity(sensitivity_str.encode())\n\n        self.ring_buffer = RingBuffer(\n            self.detector.NumChannels() * self.detector.SampleRate() * 5)\n\n    def start(self, detected_callback=play_audio_file,\n              interrupt_check=lambda: False,\n              sleep_time=0.03,\n              audio_recorder_callback=None,\n              silent_count_threshold=15,\n              recording_timeout=100):\n        \"\"\"\n        Start the voice detector. For every `sleep_time` second it checks the\n        audio buffer for triggering keywords. If detected, then call\n        corresponding function in `detected_callback`, which can be a single\n        function (single model) or a list of callback functions (multiple\n        models). Every loop it also calls `interrupt_check` -- if it returns\n        True, then breaks from the loop and return.\n\n        :param detected_callback: a function or list of functions. The number of\n                                  items must match the number of models in\n                                  `decoder_model`.\n        :param interrupt_check: a function that returns True if the main loop\n                                needs to stop.\n        :param float sleep_time: how much time in second every loop waits.\n        :param audio_recorder_callback: if specified, this will be called after\n                                        a keyword has been spoken and after the\n                                        phrase immediately after the keyword has\n                                        been recorded. The function will be\n                                        passed the name of the file where the\n                                        phrase was recorded.\n        :param silent_count_threshold: indicates how long silence must be heard\n                                       to mark the end of a phrase that is\n                                       being recorded.\n        :param recording_timeout: limits the maximum length of a recording.\n        :return: None\n        \"\"\"\n        self._running = True\n\n        def audio_callback(in_data, frame_count, time_info, status):\n            self.ring_buffer.extend(in_data)\n            play_data = chr(0) * len(in_data)\n            return play_data, pyaudio.paContinue\n\n        with no_alsa_error():\n            self.audio = pyaudio.PyAudio()\n        self.stream_in = self.audio.open(\n            input=True, output=False,\n            format=self.audio.get_format_from_width(\n                self.detector.BitsPerSample() / 8),\n            channels=self.detector.NumChannels(),\n            rate=self.detector.SampleRate(),\n            frames_per_buffer=2048,\n            stream_callback=audio_callback)\n\n        if interrupt_check():\n            logger.debug(\"detect voice return\")\n            return\n\n        tc = type(detected_callback)\n        if tc is not list:\n            detected_callback = [detected_callback]\n        if len(detected_callback) == 1 and self.num_hotwords > 1:\n            detected_callback *= self.num_hotwords\n\n        assert self.num_hotwords == len(detected_callback), \\\n            \"Error: hotwords in your models (%d) do not match the number of \" \\\n            \"callbacks (%d)\" % (self.num_hotwords, len(detected_callback))\n\n        logger.debug(\"detecting...\")\n\n        state = \"PASSIVE\"\n        while self._running is True:\n            if interrupt_check():\n                logger.debug(\"detect voice break\")\n                break\n            data = self.ring_buffer.get()\n            if len(data) == 0:\n                time.sleep(sleep_time)\n                continue\n\n            status = self.detector.RunDetection(data)\n            if status == -1:\n                logger.warning(\"Error initializing streams or reading audio data\")\n\n            #small state machine to handle recording of phrase after keyword\n            if state == \"PASSIVE\":\n                if status > 0: #key word found\n                    self.recordedData = []\n                    self.recordedData.append(data)\n                    silentCount = 0\n                    recordingCount = 0\n                    message = \"Keyword \" + str(status) + \" detected at time: \"\n                    message += time.strftime(\"%Y-%m-%d %H:%M:%S\",\n                                         time.localtime(time.time()))\n                    logger.info(message)\n                    callback = detected_callback[status-1]\n                    if callback is not None:\n                        callback()\n\n                    if audio_recorder_callback is not None:\n                        state = \"ACTIVE\"\n                    continue\n\n            elif state == \"ACTIVE\":\n                stopRecording = False\n                if recordingCount > recording_timeout:\n                    stopRecording = True\n                elif status == -2: #silence found\n                    if silentCount > silent_count_threshold:\n                        stopRecording = True\n                    else:\n                        silentCount = silentCount + 1\n                elif status == 0: #voice found\n                    silentCount = 0\n\n                if stopRecording == True:\n                    fname = self.saveMessage()\n                    audio_recorder_callback(fname)\n                    state = \"PASSIVE\"\n                    continue\n\n                recordingCount = recordingCount + 1\n                self.recordedData.append(data)\n\n        logger.debug(\"finished.\")\n\n    def saveMessage(self):\n        \"\"\"\n        Save the message stored in self.recordedData to a timestamped file.\n        \"\"\"\n        filename = 'output' + str(int(time.time())) + '.wav'\n        data = b''.join(self.recordedData)\n\n        #use wave to save data\n        wf = wave.open(filename, 'wb')\n        wf.setnchannels(1)\n        wf.setsampwidth(self.audio.get_sample_size(\n            self.audio.get_format_from_width(\n                self.detector.BitsPerSample() / 8)))\n        wf.setframerate(self.detector.SampleRate())\n        wf.writeframes(data)\n        wf.close()\n        logger.debug(\"finished saving: \" + filename)\n        return filename\n\n    def terminate(self):\n        \"\"\"\n        Terminate audio stream. Users can call start() again to detect.\n        :return: None\n        \"\"\"\n        self.stream_in.stop_stream()\n        self.stream_in.close()\n        self.audio.terminate()\n        self._running = False\n"}
{"type": "source_file", "path": "picovoice/wakeword.py", "content": "import os,json,sys,configparser\nimport pvporcupine\nimport pyaudio\nimport struct\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\n\nclass PicoWakeWord:\n    def __init__(self):\n        self.PICOVOICE_API_KEY = config['Wakeword']['Picovoice_Api_Key']\n        self.keyword_path = os.path.join(workdir,\"picovice\",config['Wakeword']['Picovoice_Model_Path'])\n\n        if config['Wakeword']['Picovoice_Model_Path'] != \"\":\n            self.keyword_paths = [self.keyword_path]\n        else:\n            self.keyword_paths = None\n\n        try:\n            self.porcupine = pvporcupine.create(\n                access_key=self.PICOVOICE_API_KEY,\n                keyword_paths = self.keyword_paths,\n                keywords= ['picovoice', 'hey barista', 'ok google', 'porcupine', 'pico clock', 'blueberry', 'terminator', 'hey siri', 'grapefruit', 'hey google', 'jarvis', 'computer', 'alexa', 'grasshopper', 'americano', 'bumblebee']\n                # sensitivities = [float(config['Wakeword']['Sensitivity'])]\n            )\n        except ValueError:\n            raise SystemExit(\"配件文件中没有配置Picovoice_Api_Key！\")\n        self.myaudio = pyaudio.PyAudio()\n        self.stream = self.myaudio.open(\n            rate=self.porcupine.sample_rate,\n            channels=1,\n            format=pyaudio.paInt16,\n            input=True,\n            frames_per_buffer=self.porcupine.frame_length\n        )\n\n    def detect_wake_word(self):\n        # print('正在检测唤醒词... 按 Ctrl+C 退出') \n        audio_obj = self.stream.read(self.porcupine.frame_length, exception_on_overflow=False)\n        audio_obj_unpacked = struct.unpack_from(\"h\" * self.porcupine.frame_length, audio_obj)\n        keyword_idx = self.porcupine.process(audio_obj_unpacked)\n        return keyword_idx\n\nif __name__ == '__main__':\n    picowakeword = PicoWakeWord()\n    while True:\n        audio_obj = picowakeword.stream.read(picowakeword.porcupine.frame_length, exception_on_overflow=False)\n        audio_obj_unpacked = struct.unpack_from(\"h\" * picowakeword.porcupine.frame_length, audio_obj)\n\n        keyword_idx = picowakeword.porcupine.process(audio_obj_unpacked)\n        if keyword_idx >= 0:\n            print(\"我听到了！\")"}
{"type": "source_file", "path": "speechmodules/__init___.py", "content": ""}
{"type": "source_file", "path": "snowboy/wakeword.py", "content": "import os,json,sys,configparser\nimport pyaudio\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom snowboy import snowboydecoder\nimport configparser\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\n\nclass SnowboyWakeWord:\n    def __init__(self):\n        self.model_path = os.path.join(workdir,\"snowboy\",config['Wakeword']['Snowboy_Model_Path'])\n        self.sensitivity = float(config['Wakeword']['Sensitivity'])\n        self.wake_word_detected = False\n        self.detector = snowboydecoder.HotwordDetector(self.model_path, sensitivity=self.sensitivity)\n\n    def detected(self):\n        self.wake_word_detected = True   \n        self.detector.terminate()\n\n    def detect_wake_word(self):\n        print('正在检测唤醒词... 按 Ctrl+C 退出')\n        self.detector.start(detected_callback=self.detected, \n                      sleep_time=0.03)\n        keyword_num = self.detector.num_hotwords\n        # print('唤醒词已检测到')\n        return keyword_num\n    \n    def audiodevice(self):\n        p = pyaudio.PyAudio()\n        print(\"可用的输入设备：\")\n        for i in range(p.get_device_count()):\n            dev = p.get_device_info_by_index(i)\n            if dev['maxInputChannels'] > 0:\n                print(f\"  设备 {i}: {dev['name']}\")\n\n        print(\"可用的输出设备：\")\n        for i in range(p.get_device_count()):\n            dev = p.get_device_info_by_index(i)\n            if dev['maxOutputChannels'] > 0:\n                print(f\"  设备 {i}: {dev['name']}\")\n\n\nif __name__ == \"__mian__\":\n    snowboywakeword = SnowboyWakeWord()\n    snowboywakeword.detect_wake_word()"}
{"type": "source_file", "path": "snowboy/__init__.py", "content": ""}
{"type": "source_file", "path": "openaibot/openaibotsinglejson.py", "content": "# 通过URL请求OpanAI的接口。\nimport os,json,sys,configparser,requests\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\nfrom speechmodules import text2speech\n\n# 读取openai的配置参数文件。\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['Openai']\n\nclass OpenaiBotSingle:\n    def __init__(self):\n        # 从配置文件中，读取openai的api域名和key，并构造URL请求的头部。\n        self.openai_api_url = configsection['openai_api_domain'] + \"/v1/chat/completions\"\n        self.openai_api_key = configsection['openai_api_key']\n        self.headers = {\"Content-Type\": \"application/json\",\"Authorization\": \"Bearer \" + self.openai_api_key}\n        self.model = \"gpt-3.5-turbo-1106\" # 定义模型的名称，可能会随着时间而更新。\n\n    def chat(self,prompt_messages,voice_name=\"zh-CN-XiaoxiaoNeural\"):\n        # 定义对话的函数，并初始化tts,如果初始化tts时，没有音色的配置，tts就不会生效。\n        tts = text2speech.AzureTTS(voice_name)\n        # 构造URL请求的数据部分。\n        data = {\n            \"model\": self.model,\n            \"response_format\":{\"type\":\"json_object\"},\n            \"messages\": prompt_messages\n        }\n        \n        try:\n            # 发起api请求。\n            ai_response = requests.post(self.openai_api_url, headers=self.headers, data=json.dumps(data))\n            try:         \n                # 使用try处理异常情况，因为api的请求返回的数据，可能会由于内容过滤等原因，返回\n                ai_response_dict = ai_response.json()['choices'][0]['message']\n            except Exception as e:\n                # 如果返回的是异常数据，就打印一下返回的文本内容。并且构造一个相同字典结构的返回数据，以使程序正确运行。\n                print(ai_response.text) \n                ai_response_dict = {\"role\": \"assistant\",\"content\":\"single模块：Ai返回数据异常，请依据打印内容进行检查。\"}          \n        except requests.exceptions.RequestException as e:\n            print(\"请求发生异常：\", e)\n            ai_response_dict = {\"role\": \"assistant\",\"content\":\"single模块：Ai接口请求异常，请依据打印内容进行检查。\"}\n        \n        # 获取ai返回的文本数据，使用tts播放出来，并且打印出来。\n        ai_response_content = ai_response_dict[\"content\"]\n        print(ai_response_content) # 先打印结果\n        tts.text2speech_and_play(ai_response_content)  # 再播放声音。\n        return ai_response_dict # 函数返回的数据是字典类型的数据，而不是文本数据。\n\nif __name__ == '__main__':\n    system = input(\"请输入system的内容：\") or \"你是一个有用的智能助手，请返回JSON格式数据。\"\n    prompt = input(\"请输入你给ai的问题：\") or \"现在的日期是？\"\n    messages=[\n        {\"role\":\"system\",\"content\": system},\n        {\"role\": \"user\", \"content\":prompt}\n        ]\n    openaibotsingle = OpenaiBotSingle()\n    ai_response_content = openaibotsingle.chat(messages,\"\")[\"content\"]\n    # print(ai_response_content) # 函数中打印了结果，这里就不打印了。"}
{"type": "source_file", "path": "speechmodules/text2speech.py", "content": "import os,json,sys,configparser\nimport azure.cognitiveservices.speech as speechsdk\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\n\nclass AzureTTS:\n    def __init__(self,Azure_Voice_Name=\"zh-CN-XiaoshuangNeural\"): \n        self.Azure_API_KEY = config['AzureSpeech']['AZURE_API_KEY']\n        self.Azure_REGION = config['AzureSpeech']['AZURE_REGION']\n        self.Azure_Voice_Name = Azure_Voice_Name\n        self.speech_config = speechsdk.SpeechConfig(subscription = self.Azure_API_KEY, region = self.Azure_REGION)\n        self.audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n        self.speech_config.speech_synthesis_voice_name = self.Azure_Voice_Name\n        self.speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=self.speech_config, audio_config=self.audio_config)\n\n    def text2speech_and_play(self,text):\n        # 如果嗓音文件为空的话，就不调用文本转语音模块，用于在纯文本的对话模式。\n        if self.Azure_Voice_Name == \"\":\n            return \"\"\n        speech_synthesis_result = self.speech_synthesizer.speak_text_async(text).get()\n\n        if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n            # print(\"Speech synthesized for text [{}]\".format(text))\n            print(\"system:已经播放完毕！\")\n        elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n            cancellation_details = speech_synthesis_result.cancellation_details\n            print(\"Speech synthesis canceled:{}\".format(cancellation_details.reason))\n            if cancellation_details.reason == speechsdk.CancellationReason.Error:\n                if cancellation_details.error_details:\n                    print(\"Error details :{}\".format(cancellation_details.error_details))\n                    print(\"Didy you set the speech resource key and region values?\")\n\nif __name__ == '__main__':\n    azuretts = AzureTTS(\"zh-CN-YunzeNeural\")\n    azuretts.text2speech_and_play(\"嗯，你好，我是你的智能小伙伴，我的名字叫Yoyo，你可以和我畅所欲言，我是很会聊天的哦！\")"}
{"type": "source_file", "path": "speechmodules/text2speechedgev2.py", "content": "# 此方案，不需要讲生成的语音保存为文件，而是可以直接讲音频字节流，进行播放，但是每段音频开头都有一个爆破音\nimport os,json,sys,configparser\nimport asyncio\nimport edge_tts\nimport pyaudio\nfrom pydub import AudioSegment\nfrom io import BytesIO\n\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\n\n# https://github.com/rany2/edge-tts/blob/master/examples/streaming_with_subtitles.py\n\nFORMAT = pyaudio.paInt16\nCHANNELS = 1\nRATE = 16000\n\ndef byte2file(data_byte):\n    # data_str = data_byte.decode('utf-8')\n    with open('audio_data_wav.bin', 'wb') as f:\n        f.write(data_byte)\n\ndef mp3towav(mp3_data):\n    with BytesIO(mp3_data) as buffer:\n        # 1、加载 MP3 格式的音频数据（data 为 MP3 格式的字节流）\n        audio = AudioSegment.from_file(buffer, format='mp3')\n        # 2. 使用 AudioSegment 对象的 export() 函数将音频数据转换为 WAV 格式的字节流。\n        wav_data = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2).export(format='wav').read()\n    return wav_data\n\nclass EdgeTTS:\n    def __init__(self,Azure_Voice_Name=\"zh-CN-XiaoshuangNeural\"): \n        self.Azure_Voice_Name = Azure_Voice_Name\n\n    async def text2speech_and_play(self,text) -> None:\n        # 如果嗓音文件为空的话，就不调用文本转语音模块，用于在纯文本的对话模式。\n        if self.Azure_Voice_Name == \"\":\n            return \"\"\n        \n        communicate = edge_tts.Communicate(text, self.Azure_Voice_Name)\n        audio_data = b\"\" \n\n        async for chunk in communicate.stream():\n            if chunk[\"type\"] == \"audio\":\n                audio_data = audio_data + chunk[\"data\"]\n            elif chunk[\"type\"] == \"WordBoundary\":\n                pass\n        # print(audio_data)\n        audio_data_wav = mp3towav(audio_data)\n        byte2file(audio_data_wav)\n        # print(audio_data_wav)\n        # 初始化 PyAudio\n        p = pyaudio.PyAudio()\n        # 打开音频流并开始播放\n        stream=p.open(format=FORMAT,\n                      channels=CHANNELS,\n                      rate=RATE,\n                      output=True)\n        stream.write(audio_data_wav)\n        stream.start_stream()\n        stream.close()\n        p.terminate()\n    \n\nif __name__ == '__main__':\n    azuretts = EdgeTTS(\"zh-CN-XiaoxiaoNeural\")\n    loop = asyncio.get_event_loop_policy().get_event_loop()\n    try:\n        loop.run_until_complete(azuretts.text2speech_and_play(\"你好\"))\n    finally:\n        loop.close()\n    \n    "}
{"type": "source_file", "path": "speechmodules/text2speechedge.py", "content": "# 此语音方案，需要先把生成的语音文件保存为文件，然后在读取文件并播放。\n\nimport os,json,sys,configparser\nimport asyncio\nimport edge_tts\nfrom pydub import AudioSegment\nfrom pydub.playback import play\nimport random\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\n\n# https://github.com/rany2/edge-tts/blob/master/examples/streaming_with_subtitles.py\n\nfilename = str(random.randint(1000,9999)) + \".wav\"\ntepfile = os.path.join(workdir, \"speechmodules\",\"tepfile\",filename)\n\nclass EdgeTTS:\n    def __init__(self,Azure_Voice_Name=\"zh-CN-XiaoshuangNeural\"): \n        self.Azure_Voice_Name = Azure_Voice_Name\n\n    async def text2speech_and_play(self,text) -> None:\n        # 如果嗓音文件为空的话，就不调用文本转语音模块，用于在纯文本的对话模式。\n        if self.Azure_Voice_Name == \"\":\n            return \"\"\n        communicate = edge_tts.Communicate(text, self.Azure_Voice_Name)\n        await communicate.save(tepfile)\n\n        # 加载 MP3 文件\n        audio = AudioSegment.from_file(tepfile, format='mp3')\n        play(audio)\n\n        # 删除临时文件\n        # os.remove(tepfile)\n\nif __name__ == '__main__':\n    azuretts = EdgeTTS(\"zh-CN-XiaoxiaoNeural\")\n    loop = asyncio.get_event_loop_policy().get_event_loop()\n    try:\n        loop.run_until_complete(azuretts.text2speech_and_play(\"嗯，你好，我是你的智能小伙伴，我的名字叫Yoyo，你可以和我畅所欲言，我是很会聊天的哦！\"))\n    finally:\n        loop.close()"}
{"type": "source_file", "path": "openaibot/openaiimage.py", "content": "import datetime,time\nimport os,json,sys,configparser,requests\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nconfig = configparser.ConfigParser()\nconfig.read(os.path.join(workdir, \"config.ini\"),encoding=\"UTF-8\")\nconfigsection = config['Openai']\n\nfrom functionplugin import aliyunossup\nfrom functionplugin import posttoqw\n\nclass OpenaiBotImage:\n    def __init__(self):\n        self.openai_api_url = configsection['openai_api_domain'] + \"/v1/images/generations\"\n        self.openai_api_key = configsection['openai_api_key']\n        self.headers = {\"Content-Type\": \"application/json\",\"Authorization\": \"Bearer \" + self.openai_api_key}\n        self.model = \"dall-e-3\"\n\n    def getandpost_image(self,ai_image_url):\n        # 请求图片url下载保存到本地\n        image_data = requests.get(ai_image_url)\n        if image_data.status_code == 200:\n            current_time = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n            image_path = os.path.join(workdir, f'openaibot/image/aicreate/{current_time}.png')\n            with open(image_path, \"wb\") as f:\n                f.write(image_data.content)\n            # 再上传到阿里云OSS上\n            aliyunossup_function_args = {\"local_file_path\":image_path,\"oss_file_dir\":\"images/aicreate\"}\n            oss_image_url = aliyunossup.aliyunossup(aliyunossup_function_args)[\"details\"]\n            posttoqw_function_args = {\"text\":oss_image_url}\n            posttoqw.posttoqw(posttoqw_function_args)\n            return oss_image_url\n        else:\n            print(\"图片下载失败。\")\n            return None\n\n    def create_image(self,prompt_messages):\n        size_list  = ['1024x1024', '1024x1792', '1792x1024']\n        if \"竖版\" in prompt_messages:\n            sizeindex = 1\n            prompt_messages = prompt_messages.replace(\"竖版\", \"\")\n        elif \"横版\" in prompt_messages:\n            sizeindex = 2\n            prompt_messages = prompt_messages.replace(\"横版\", \"\")\n        else:\n            sizeindex = 0\n        data = {\n            \"model\": self.model,\n            \"prompt\": prompt_messages,\n            \"n\": 1,\n            \"size\": size_list[sizeindex]\n        }\n        ai_image_response = requests.post(self.openai_api_url, headers=self.headers, data=json.dumps(data)) \n\n        # print(ai_image_response.json())\n        try:\n            ai_image_url = ai_image_response.json()['data'][0]['url'] # 限制只返回一张图片\n            # 将获取到的图片下载、上传、推送\n            ai_oss_image_url = self.getandpost_image(ai_image_url)\n            return ai_oss_image_url\n        except:\n            return \"获取图片失败!请检查！\"\n\nif __name__ == '__main__':\n    if len(sys.argv) > 1:\n        prompt = sys.argv[1]\n    else:\n        prompt = input(\"请输入你的问题：\") or \"玩具酒桶\"\n        \n    openaibotimage = OpenaiBotImage()\n    post_message = openaibotimage.create_image(prompt)\n    print(post_message)"}
{"type": "source_file", "path": "snowboy/snowboydetect.py", "content": "# This file was automatically generated by SWIG (http://www.swig.org).\n# Version 4.0.2\n#\n# Do not make changes to this file unless you know what you are doing--modify\n# the SWIG interface file instead.\n\nfrom sys import version_info as _swig_python_version_info\nif _swig_python_version_info < (2, 7, 0):\n    raise RuntimeError(\"Python 2.7 or later required\")\n\n# Import the low-level C/C++ module\nif __package__ or \".\" in __name__:\n    from . import _snowboydetect\nelse:\n    import _snowboydetect\n\ntry:\n    import builtins as __builtin__\nexcept ImportError:\n    import __builtin__\n\ndef _swig_repr(self):\n    try:\n        strthis = \"proxy of \" + self.this.__repr__()\n    except __builtin__.Exception:\n        strthis = \"\"\n    return \"<%s.%s; %s >\" % (self.__class__.__module__, self.__class__.__name__, strthis,)\n\n\ndef _swig_setattr_nondynamic_instance_variable(set):\n    def set_instance_attr(self, name, value):\n        if name == \"thisown\":\n            self.this.own(value)\n        elif name == \"this\":\n            set(self, name, value)\n        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):\n            set(self, name, value)\n        else:\n            raise AttributeError(\"You cannot add instance attributes to %s\" % self)\n    return set_instance_attr\n\n\ndef _swig_setattr_nondynamic_class_variable(set):\n    def set_class_attr(cls, name, value):\n        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):\n            set(cls, name, value)\n        else:\n            raise AttributeError(\"You cannot add class attributes to %s\" % cls)\n    return set_class_attr\n\n\ndef _swig_add_metaclass(metaclass):\n    \"\"\"Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass\"\"\"\n    def wrapper(cls):\n        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())\n    return wrapper\n\n\nclass _SwigNonDynamicMeta(type):\n    \"\"\"Meta class to enforce nondynamic attributes (no new attributes) for a class\"\"\"\n    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)\n\n\nclass SnowboyDetect(object):\n    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=\"The membership flag\")\n    __repr__ = _swig_repr\n\n    def __init__(self, resource_filename, model_str):\n        _snowboydetect.SnowboyDetect_swiginit(self, _snowboydetect.new_SnowboyDetect(resource_filename, model_str))\n\n    def Reset(self):\n        return _snowboydetect.SnowboyDetect_Reset(self)\n\n    def RunDetection(self, *args):\n        return _snowboydetect.SnowboyDetect_RunDetection(self, *args)\n\n    def SetSensitivity(self, sensitivity_str):\n        return _snowboydetect.SnowboyDetect_SetSensitivity(self, sensitivity_str)\n\n    def SetHighSensitivity(self, high_sensitivity_str):\n        return _snowboydetect.SnowboyDetect_SetHighSensitivity(self, high_sensitivity_str)\n\n    def GetSensitivity(self):\n        return _snowboydetect.SnowboyDetect_GetSensitivity(self)\n\n    def SetAudioGain(self, audio_gain):\n        return _snowboydetect.SnowboyDetect_SetAudioGain(self, audio_gain)\n\n    def UpdateModel(self):\n        return _snowboydetect.SnowboyDetect_UpdateModel(self)\n\n    def NumHotwords(self):\n        return _snowboydetect.SnowboyDetect_NumHotwords(self)\n\n    def ApplyFrontend(self, apply_frontend):\n        return _snowboydetect.SnowboyDetect_ApplyFrontend(self, apply_frontend)\n\n    def SampleRate(self):\n        return _snowboydetect.SnowboyDetect_SampleRate(self)\n\n    def NumChannels(self):\n        return _snowboydetect.SnowboyDetect_NumChannels(self)\n\n    def BitsPerSample(self):\n        return _snowboydetect.SnowboyDetect_BitsPerSample(self)\n    __swig_destroy__ = _snowboydetect.delete_SnowboyDetect\n\n# Register SnowboyDetect in _snowboydetect:\n_snowboydetect.SnowboyDetect_swigregister(SnowboyDetect)\n\nclass SnowboyVad(object):\n    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=\"The membership flag\")\n    __repr__ = _swig_repr\n\n    def __init__(self, resource_filename):\n        _snowboydetect.SnowboyVad_swiginit(self, _snowboydetect.new_SnowboyVad(resource_filename))\n\n    def Reset(self):\n        return _snowboydetect.SnowboyVad_Reset(self)\n\n    def RunVad(self, *args):\n        return _snowboydetect.SnowboyVad_RunVad(self, *args)\n\n    def SetAudioGain(self, audio_gain):\n        return _snowboydetect.SnowboyVad_SetAudioGain(self, audio_gain)\n\n    def ApplyFrontend(self, apply_frontend):\n        return _snowboydetect.SnowboyVad_ApplyFrontend(self, apply_frontend)\n\n    def SampleRate(self):\n        return _snowboydetect.SnowboyVad_SampleRate(self)\n\n    def NumChannels(self):\n        return _snowboydetect.SnowboyVad_NumChannels(self)\n\n    def BitsPerSample(self):\n        return _snowboydetect.SnowboyVad_BitsPerSample(self)\n    __swig_destroy__ = _snowboydetect.delete_SnowboyVad\n\n# Register SnowboyVad in _snowboydetect:\n_snowboydetect.SnowboyVad_swigregister(SnowboyVad)\n\n\n\n"}
{"type": "source_file", "path": "openaibot/openaibotmult.py", "content": "import os,json,sys,configparser\nimport copy\n\nworkdir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\nsys.path.append(workdir)\n\nfrom openaibot import openaibotsingle\nfrom openaibot import openaibotfunction\n\nopenaibotsingleclass = openaibotsingle.OpenaiBotSingle()\nopenaibotfunctionclass = openaibotfunction.OpenaiBotFunction()\n\nclass OpenaiBotMult:\n    def __init__(self):\n        pass\n\n    def chatmult(self,username,prompt,system_content=\"You are a helpful assistant\",functionname=[\"none\"],voice_name=\"zh-CN-XiaoxiaoNeural\"):\n        # 用户ID文件路径\n        username_fpath = f\"{username}.json\"\n        username_fpath = os.path.join(workdir,\"log\",username_fpath)\n        # 判断用户ID文件是不是存在，存在就读取，不存在就建立\n        if os.path.exists(username_fpath):\n            with open(username_fpath) as f:\n                message = json.load(f) \n        else:\n            message = []\n            system_dict = {\"role\":\"system\",\"content\": system_content}\n            message.append(system_dict)\n\n        # 构造本次问答的问题\n        prompt_dict = {\"role\":\"user\",\"content\": prompt}\n        \n        # 将本次的提问和历史记录整合\n        message.append(prompt_dict)\n\n        # 如果聊天记录很长，只选取system和最近两轮的会话\n        messages_thistime = copy.deepcopy(message)\n        if len(messages_thistime)>=5:\n            messages_thistime = [messages_thistime[0]] + messages_thistime[-4:]\n            # print(messages_thistime)\n\n        # 调用单轮会话的模块获取结果\n        # response_dit = chatgptsingle.chat(messages_thistime,voice_name) #使用Azure的接口\n        # 调用支持函数的单轮会话模块获取结果。\n        response_dit = openaibotfunctionclass.chat_with_funciton(messages_thistime,functionname,voice_name) \n        \n        # print(response_dit)\n        # 将本次的回答和历史记录整合\n        if isinstance(response_dit, list):\n            for response_dit_item in response_dit:\n                message.append(response_dit_item)\n            response_content = response_dit[-1][\"content\"]\n        else:\n            message.append(response_dit)\n            response_content = response_dit[\"content\"]\n\n        with open(username_fpath, \"w\",encoding='utf-8') as file:\n            json.dump(message, file)\n\n        # 单独获取结果并打印，并作为函数返回结果\n        # print(response_content)\n        return response_content\n\nif __name__ == '__main__':\n    username = \"You\"\n    prompt =  input(\"请输入你的问题：\") or \"将「我爱你」这条消息推送到企业微信中。\"\n    system_content = \"你的名字叫Yoyo，是一个智能助手。和我对话时，你可以通过调用videovison插件，看到外部世界。回答字数控制在100个字以内。\"\n    functionname = [\"posttoqw\"]\n    openaibotmult = OpenaiBotMult()\n    openaibotmult.chatmult(username,prompt,system_content,functionname)\n"}
