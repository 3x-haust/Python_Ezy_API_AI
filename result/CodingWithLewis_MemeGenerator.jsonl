{"repo_info": {"repo_name": "MemeGenerator", "repo_owner": "CodingWithLewis", "repo_url": "https://github.com/CodingWithLewis/MemeGenerator"}}
{"type": "test_file", "path": "tests/packages.py", "content": "import os\n\n\ndef get_size(start_path):\n    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(start_path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            if os.path.exists(fp):\n                total_size += os.path.getsize(fp)\n    return total_size\n\n\nsite_packages_path = \"/home/lewismenelaws/MemeGenerator/.venv/lib/python3.10/site-packages\"  # Update this path\npackages = [\n    os.path.join(site_packages_path, d)\n    for d in os.listdir(site_packages_path)\n    if os.path.isdir(os.path.join(site_packages_path, d))\n]\n\nsizes = {pkg.split(\"/\")[-1]: get_size(pkg) for pkg in packages}\nsorted_sizes = sorted(sizes.items(), key=lambda x: x[1], reverse=True)\n\nfor package, size in sorted_sizes[:10]:  # prints top 10 largest packages\n    print(f\"{package}: {size / (1024 * 1024)} MB\")\n"}
{"type": "test_file", "path": "tests/testing.py", "content": "import gradio_client\nfrom dotenv import load_dotenv\nfrom gradio_client import Client\n\nload_dotenv()\n\n\n# Define your desired output structure\n\n\ndef detect_objects(image):\n    client = Client(\"http://127.0.0.1:7860/\")\n    result = client.predict(\n        gradio_client.file(\"tests/dax.png\"),\n        \"man with beard\",  # str  in 'text_queries' Textbox component\n        0.15,  # float (numeric value between 0 and 1) in 'score_threshold' Slider component\n        api_name=\"/predict\",\n    )\n\n    return result[1]\n\n\nwith open(\"tests/dax.png\", \"rb\") as f:\n    image = f.read()\n\n    detect_objects(image)\n"}
{"type": "test_file", "path": "tests/test_endpoint.py", "content": "import requests\n\nurl = \"http://localhost:8000/uploadimage/\"\nfile = {\"image\": open(\"tests/image.jpg\", \"rb\")}\nresp = requests.post(url, files=file)\nprint(resp.json())\n"}
{"type": "source_file", "path": "data/batcher.py", "content": "import json\nfrom dotenv import load_dotenv\n\nload_dotenv()\nimport os\n\n# {\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n# {\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n\nwith open(\"meme_templates_azure.json\") as f:\n    memes = json.load(f)\n\nbatched_memes = []\n\nfor meme in memes:\n    batched_memes.append({\n        \"custom_id\": meme['id'],\n        \"method\": \"POST\",\n        \"url\": \"/v1/chat/completions\",\n        \"body\": {\n            \"model\": \"gpt-4-turbo\",\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are looking at memes. You need to describe the meme in as much detail as possible \"\n                               \"and explain why it is funny. Explain also what is in the picture in great detail. \"\n                               \"Also read out what the meme says if text is on screen.\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"text\",\n                            \"text\": \"Please explain this meme in as much detail as possible. Why is it considered funny? \"\n                        },\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                 \"url\": f\"{meme['photo_url']}?{os.getenv('AZURE_BLOB_SAS_TOKEN')}\"\n                            }\n                         }\n                    ]\n                }\n            ]\n        }\n    })\n\n\n# save as jsonl\nwith open(\"batched_memes.jsonl\", \"w\") as f:\n    for meme in batched_memes:\n        f.write(json.dumps(meme))\n        f.write(\"\\n\")\n"}
{"type": "source_file", "path": "data/datafetch.py", "content": "from sqlalchemy import select\nfrom sqlalchemy.orm import Session\n\nfrom meme_database.models import MemeEntry, MemeImage\nimport openai\nfrom dotenv import load_dotenv\nimport os\nfrom sqlalchemy.engine import create_engine\n\n\nload_dotenv()\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\nclient = openai.Client()\n\n\ndef retrieve_relevant_meme(meme_description: str):\n\n    embedding = client.embeddings.create(\n        model=\"text-embedding-3-small\",\n        input=meme_description\n    )\n    # Query postgres database with SQLAlchemy\n    engine = create_engine(os.getenv(\"NEON_POSTGRES\"))\n\n    with Session(engine) as session:\n        query = session.scalars(select(MemeEntry).order_by(MemeEntry.content_embedding.l2_distance(embedding.data[0].embedding)).limit(5))\n\n        meme = query.first()\n\n        # retrieve images\n        images = session.scalars(select(MemeImage).where(MemeImage.meme_entry == meme.id))\n\n        image_captions = []\n        for caption in images:\n            if caption.caption_text != \"No text detected\":\n                image_captions.append(caption.caption_text)\n        nl = \"\\n\"\n        random_choice = f\"\"\"\n            Meme Name: {meme.name}\n            \n            Meme Description: {meme.content}\n            \n            Meme Caption Samples: {nl} {nl.join(image_captions)}\n        \"\"\"\n\n    return random_choice\n\n\nif __name__ == \"__main__\":\n    relevant_meme = retrieve_relevant_meme(\n        \"2 spiderman looking at each other and pointing\")\n\n\n    print(relevant_meme)"}
{"type": "source_file", "path": "meme_database/init.py", "content": ""}
{"type": "source_file", "path": "meme_database/models.py", "content": "import uuid\nfrom datetime import datetime\nfrom typing import Optional, List\n\nfrom dotenv import load_dotenv\nfrom pgvector.sqlalchemy import Vector\nfrom sqlalchemy import String, Text, DateTime, ForeignKey, Uuid, text, INTEGER\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship\n\nload_dotenv()\n\n\nclass Base(DeclarativeBase):\n    pass\n\n\nclass MemeEntry(Base):\n    __tablename__ = \"meme_entry\"\n    id: Mapped[uuid.UUID] = mapped_column(\n        Uuid, primary_key=True, server_default=text(\"gen_random_uuid()\")\n    )\n    name: Mapped[str] = mapped_column(String(200))\n    url: Mapped[str]\n    content: Mapped[str] = mapped_column(Text)\n    images: Mapped[List[\"MemeImage\"]] = relationship()\n    meme_added: Mapped[datetime] = mapped_column(\n        DateTime(timezone=False), nullable=True\n    )\n    title_embedding: Mapped[Vector] = mapped_column(Vector(1536), nullable=True)\n    content_embedding = mapped_column(Vector(1536))\n    vector_id = mapped_column(INTEGER, nullable=True)\n    meme_template: Mapped[str] = mapped_column(String(1000), nullable=True)\n    meme_template_description = mapped_column(String(8000), nullable=True)\n    meme_template_embedding: Mapped[Vector] = mapped_column(Vector(1536), nullable=True)\n\n\nclass MemeImage(Base):\n    __tablename__ = \"meme_image\"\n    id: Mapped[int] = mapped_column(primary_key=True)\n    meme_entry: Mapped[uuid.UUID] = mapped_column(ForeignKey(\"meme_entry.id\"))\n    source_url: Mapped[str]\n    caption_text: Mapped[Optional[str]] = mapped_column(String(8000), nullable=True)\n"}
{"type": "source_file", "path": "scraper/knowyourmeme.py", "content": "import asyncio\nfrom playwright.async_api import async_playwright\nfrom tinydb import TinyDB, Query\n\n\nSBR_WS_CDP = 'wss://brd-customer-hl_4a5981ec-zone-marketdatascrape:0ypz3p358tae@brd.superproxy.io:9222'\n\n# https://knowyourmeme.com/categories/meme\nasync def main():\n    async with async_playwright() as p:\n        # Get highest number of pages\n        db = TinyDB('db.json')\n        pages = []\n        q = Query()\n        for item in db.search(q.page > 1):\n            pages.append(item['page'])\n\n\n\n        browser = await p.chromium.connect_over_cdp(SBR_WS_CDP)\n        # browser = await p.chromium.launch(headless=False)\n\n        context = await browser.new_context()\n        # Block unnecessary requests\n        await context.route(\"**/*.{png,jpg,jpeg,gif,webp,svg,ico,css,ttf,woff,woff2,js}\", lambda route: route.abort())\n\n        page = await context.new_page()\n        page_num = max(pages) + 1 if pages else 1\n        await page.goto(f\"https://knowyourmeme.com/categories/meme/page/{page_num}\")\n        print(f\"Scraping page {page_num}\")\n        while True:\n            meme_links = []\n            # Get all the links to meme pages on the current page\n            links = await page.query_selector_all(\".entry-grid-body a\")\n            for link in links:\n                href = await link.get_attribute(\"href\")\n                if href and \"/memes/\" in href:\n                    meme_links.append(href)\n\n            # Scroll to the bottom of the page to load more memes\n            await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n            await page.wait_for_timeout(2000)  # Wait for new memes to load\n\n            for meme in meme_links:\n                db.insert({\n                    'meme': meme,\n                    'page': page_num\n                })\n\n            # Check if there are more memes to load\n            has_more = await page.query_selector(\".next_page\") is not None\n\n            # Move to the next page\n            await page.click(\".next_page\")\n\n            await page.wait_for_url(f\"https://knowyourmeme.com/categories/meme/page/{page_num + 1}\")\n            page_num += 1\n            print(f\"Moving to page {page_num}\")\n            if not has_more:\n                break\n\n        print(f\"Found {len(meme_links)} meme links:\")\n        for link in meme_links:\n            print(link)\n\n        await browser.close()\n\nasyncio.run(main())"}
{"type": "source_file", "path": "scraper/save_images.py", "content": "import asyncio\nimport json\nfrom pathlib import Path\n\nimport aiohttp\nimport ijson\nfrom azure.core.exceptions import ResourceNotFoundError\nfrom sqlalchemy.ext.asyncio import AsyncSession, create_async_engine\nimport aiofiles\nimport requests\nfrom azure.storage.blob.aio import BlobServiceClient, ContainerClient\nfrom dotenv import load_dotenv\nfrom sqlalchemy.orm import sessionmaker\nfrom tqdm import tqdm\n\nfrom meme_database.models import MemeEntry, MemeImage\nfrom scraper.downloadimages import upload_to_azure, azure_blob_check\nimport os\nload_dotenv()\naccount_url = \"https://aimemes.blob.core.windows.net\"\n\nblob_service_client = BlobServiceClient(account_url, credential=os.getenv(\"AZURE_STORAGE_KEY\"))\nproxies = {'http': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225',\n               'https': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225'}\n\n\nengine = create_async_engine(os.getenv(\"NEON_POSTGRES\"), echo=True)\nSessionLocal = sessionmaker(bind=engine, class_=AsyncSession, expire_on_commit=False)\n\n\nasync def save_image_to_database(session, meme_entry_id, source_url, blob_url):\n    new_image = MemeImage(meme_entry=meme_entry_id, source_url=blob_url)\n    session.add(new_image)\n\nasync def download_and_save_image(session, meme_entry_id, image_link):\n    if image_link is None or image_link == \"None\":\n        return\n    async with aiohttp.ClientSession() as http_session:\n        async with http_session.get(image_link) as response:\n            if response.status != 200:\n                print(\"error\")\n                return\n            try:\n\n                content = await response.read()\n                filename = image_link.split(\"/\")[-1]\n                # Ensure upload_to_azure function is async or adjust accordingly\n                blob_url = await upload_to_azure(content, blob_service_client, \"memes\", meme_entry_id, filename)\n\n                await save_image_to_database(session, meme_entry_id, image_link, blob_url)\n            except Exception as e:\n                return\n\nasync def process_batch(session, batch, pbar):\n    tasks = []\n\n    for meme in batch:\n        task = download_and_save_image(session, meme['id'], meme['source_url'])\n        tasks.append(task)\n\n\n    \n    if not tasks:\n        return\n    # Create a tqdm progress bar for tasks\n    for f in asyncio.as_completed(tasks):\n        await f  # Awaiting completion here, ensures we track each task\n\n\n    pbar.update(1)\n\nasync def check_if_exists(meme, container):\n    blob_client = container.get_blob_client(f'{meme[\"id\"]}/{meme[\"source_url\"].split(\"/\")[-1]}')\n\n    try:\n        await blob_client.get_blob_properties()  # Ensure to use await here\n\n        return True, meme\n    except ResourceNotFoundError:\n        return False, meme\n    except Exception as e:\n        print(f\"Error checking blob existence: {e}\")\n        return False, meme\n\nasync def process_meme_file_batch(batch, non_used_memes, container, pbar):\n    tasks = [asyncio.create_task(check_if_exists(meme, container)) for meme in batch]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n    await asyncio.sleep(1)  # Add a small delay to avoid rate limiting\n    for result in results:\n        if isinstance(result, Exception):\n            print(f\"Error processing meme: {result}\")\n        else:\n            exists, meme = result\n            if not exists:\n                non_used_memes.append(meme)\n\n    pbar.update(1)  # Update the progress bar each time a batch is processed\n    await asyncio.sleep(2)\nasync def main():\n\n    # try:\n    #     async with aiofiles.open('meme_photo_links.json', mode='r') as file:\n    #         memes = json.loads(await file.read())\n    #\n    #     non_used_memes = []\n    #     memes = [meme for meme in memes if meme['source_url'] is not None]\n    #\n    #     batch_size = 300  # Adjust based on your environment and resources\n    #     batches = [memes[i:i + batch_size] for i in range(0, len(memes), batch_size)]\n    #\n    #     print(f\"Scanning {len(memes)} memes in {len(batches)} batches.\")\n    #\n    #     # Create tqdm progress bar\n    #     pbar = tqdm(total=len(batches), desc=\"Processing Batches\")\n    #     sem = asyncio.Semaphore(10)  # Adjust based on your environment and Azure's rate limits\n    #\n    #     async def limited_process_batch(batch, non_used_memes, container, pbar):\n    #         async with sem:\n    #             await process_meme_file_batch(batch, non_used_memes, container, pbar)\n    #\n    #     tasks = [asyncio.create_task(limited_process_batch(batch, non_used_memes, container, pbar)) for batch in\n    #              batches]\n    #     await asyncio.gather(*tasks)\n    #     pbar.close()  # Make sure to close the progress bar after all batches are processed\n    #\n    #     print(f\"Found {len(non_used_memes)} memes that haven't been uploaded\")\n    #\n    # finally:\n    #     await container.close()  # Ensure the container client is closed properly\n    # # Save to json file outside the loop\n    # async with aiofiles.open('non_used_memes.json', mode='w') as f:\n    #     await f.write(json.dumps(non_used_memes))\n\n    container = ContainerClient.from_connection_string(os.getenv(\"AZURE_STORAGE_CONN_KEY\"), container_name=\"memes\")\n    async with aiofiles.open('non_used_memes.json', mode='r') as file:\n        memes = json.loads(await file.read())  # Consider using ijson for large files\n        # remove all memes with none\n        memes = [meme for meme in memes if meme['source_url'] is not None]\n        batch_size = 20\n        batches = [memes[i:i + batch_size] for i in range(0, len(memes), batch_size)]\n        sem = asyncio.Semaphore(3)  # Adjust based on your environment and Azure's rate limits\n        pbar = tqdm(total=len(batches), desc=\"Processing Batches\", position=0, leave=True)\n        async with SessionLocal() as session:\n            async def limited_process_batch(session, batch, pbar):\n                async with sem:\n                    await process_batch(session, batch, pbar)\n\n            tasks = [asyncio.create_task(limited_process_batch(session, batch, pbar)) for batch in\n                     batches]\n            await asyncio.gather(*tasks)\n            await session.commit()\nasyncio.run(main())"}
{"type": "source_file", "path": "scraper/captioner.py", "content": "from concurrent.futures import ThreadPoolExecutor, as_completed\nfrom typing import List\n\nimport easyocr\nimport requests\nfrom azure.storage.blob import BlobClient\nfrom dotenv import load_dotenv\nimport os\nfrom sqlalchemy import create_engine, func\nfrom sqlalchemy.orm import Session\nfrom azure.cognitiveservices.vision.computervision import ComputerVisionClient\nfrom azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\nfrom azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\nfrom msrest.authentication import CognitiveServicesCredentials\n\nfrom array import array\nimport os\nfrom PIL import Image\nimport sys\nimport time\n\nfrom tqdm import tqdm\n\nfrom meme_database.models import MemeImage\n\nload_dotenv()\n\nsubscription_key = os.environ[\"AZURE_VISION_KEY\"]\nendpoint = os.environ[\"AZURE_VISION_ENDPOINT\"]\n\ncomputervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\nengine = create_engine(os.getenv(\"NEON_POSTGRES\"), pool_pre_ping=True)\n\n\ndef read_image(meme: MemeImage, session: Session):\n    read_response = computervision_client.read(f\"{meme.source_url}?{os.getenv('AZURE_BLOB_SAS_TOKEN')}\", raw=True)\n    read_operation_location = read_response.headers[\"Operation-Location\"]\n    operation_id = read_operation_location.split(\"/\")[-1]\n    while True:\n        read_result = computervision_client.get_read_result(operation_id)\n        if read_result.status == OperationStatusCodes.succeeded:\n            text = \"\"\n            for text_result in read_result.analyze_result.read_results:\n                for line in text_result.lines:\n                    text += line.text + \" \"\n            meme.caption_text = text\n            return\n\n        time.sleep(1)\n\n\ndef read_image_locally(meme: MemeImage, session: Session, reader: easyocr.Reader):\n    try:\n\n        image_data = requests.get(f\"{meme.source_url}?{os.getenv('AZURE_BLOB_SAS_TOKEN')}\").content\n        result = reader.readtext(image_data)\n        text = ''\n        for detection in result:\n            text += f\"'{detection[1]}' \\n\"\n        if len(text) > 8000:\n            text = text[:8000]\n        if text == '':\n            text = \"No text detected\"\n        meme.caption_text = text\n    except Exception as e:\n        meme.caption_text = \"No text detected\"\n\ndef process_images_concurrently(meme_images: List[MemeImage], session: Session):\n    reader = easyocr.Reader(['en'])\n    with ThreadPoolExecutor() as executor:\n        futures = [executor.submit(read_image_locally, meme, session, reader) for meme in meme_images]\n        for future in list(tqdm(as_completed(futures), total=len(futures))):\n            try:\n                future.result()\n            except Exception as e:\n                pass\n    session.commit()\n\n\nsession = Session(engine)\ni = 1\nwhile True:\n    print(f\"Starting iteration {i}\")\n    query = session.query(MemeImage).filter(MemeImage.caption_text == None).order_by(func.random()).limit(100)\n    if len(query.all()) > 0:\n        process_images_concurrently(query.all(), session)\n        i += 1\n    else:\n        break\n"}
{"type": "source_file", "path": "scraper/get_meme_data.py", "content": "import asyncio\nfrom playwright.async_api import async_playwright\nfrom tinydb import TinyDB, Query\n\n\nSBR_WS_CDP = 'wss://brd-customer-hl_4a5981ec-zone-marketdatascrape:0ypz3p358tae@brd.superproxy.io:9222'\n\n# https://knowyourmeme.com/categories/meme\n# Database we are saving to\ndb = TinyDB('memes.json')\n\nlinks_db = TinyDB('db.json')\nLinks = Query()\n\ntexts = [link.get('meme') for link in links_db.search(Links.meme.exists())]\n\nurls = set(texts)\n\n\ndef clear_unsuccessful_db_entries(db):\n    Memes = Query()\n    db.remove(Memes.success == False)\n\n\ndef get_existing_meme_urls(db):\n    Memes = Query()\n    return set([meme['url'] for meme in db.search(Memes.success == True)])\n\nasync def get_image_links(page, url):\n    photos_page_num = 1\n    await page.goto(f\"{url}/photos/page/{photos_page_num}\", timeout=2*60*1000)\n    # https://knowyourmeme.com/photos/2795320-wifejak\n    photo_links = []\n    while True:\n        links = await page.query_selector_all(\"#photo_gallery a\")\n        for link in links:\n            href = await link.get_attribute(\"href\")\n            photo_links.append(href)\n\n        # Scroll to the bottom of the page to load more memes\n        await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n        await page.wait_for_timeout(2000)  # Wait for new memes to load\n\n        # Check if there are more memes to load\n        has_more = await page.query_selector(\".next_page\") is not None\n        # Move to the next page\n        if has_more:\n            if await page.query_selector(\".next_page.disabled\") is not None:\n                # element is there but not clickable. We are at the last page\n                break\n            await page.click(\".next_page\")\n            photos_page_num += 1\n            await page.wait_for_url(f\"{url}/photos/page/{photos_page_num}\")\n        else:\n            break\n    return photo_links\n\n\nasync def scrape_page(url):\n    async with async_playwright() as p:\n        try:\n\n            browser = await p.chromium.connect_over_cdp(SBR_WS_CDP)\n            context = await browser.new_context()\n\n            await context.route(\"**/*.{png,jpg,jpeg,gif,webp,svg,ico,css,ttf,woff,woff2,js}\", lambda route: route.abort())\n            page = await context.new_page()\n            await page.goto(url, timeout=2*60*1000)\n            await page.wait_for_timeout(3000)\n            # Extract data from the page using Playwright selectors\n            title = await page.title()\n            # Extract other relevant data from the page\n            posted = page.locator(\".timeago\").first\n            posted_date = await posted.get_attribute(\"title\")\n            body_selector = \"#content\"\n            if await page.query_selector(body_selector) is None:\n                body_selector = \"article\"\n\n            content_element = page.locator(body_selector).first\n            content = await content_element.inner_text()\n\n            photo_links = await get_image_links(page, url)\n\n            db.insert({\n                'url': url,\n                'success': True,\n                'title': title,\n                'content': content,\n                'photo_links': photo_links,\n                \"posted_date\": posted_date\n            })\n        except Exception as e:\n            print(e)\n            db.insert({\n                'url': url,\n                'success': False,\n                'error': str(e)\n            })\n        finally:\n            await browser.close()\n\n\nasync def worker(queue):\n    while True:\n        url = await queue.get()\n        await scrape_page(url)\n        queue.task_done()\n\n\nasync def scrape_urls(urls, batch_size=100):\n    queue = asyncio.Queue()\n    workers = []\n\n    # Create worker tasks\n    for _ in range(batch_size):\n        worker_task = asyncio.create_task(worker(queue))\n        workers.append(worker_task)\n\n    # Put URLs into the queue\n    for url in urls:\n        await queue.put(url)\n\n    # Wait for all URLs to be processed\n    await queue.join()\n\n    # Cancel worker tasks\n    for worker_task in workers:\n        worker_task.cancel()\n\n    # Wait for worker tasks to finish\n    await asyncio.gather(*workers, return_exceptions=True)\n\nclear_unsuccessful_db_entries(db)\n\nsuccessful_urls = get_existing_meme_urls(db)\nurls = list(urls)\nfor link in urls:\n    if link in successful_urls:\n        urls.remove(link)\n\n\nprint(f\"Found {len(successful_urls)} successful URLs in the database\")\nprint(f\"Scraping {len(urls)} URLs\")\n# Run the scraper\nscraped_data = asyncio.run(scrape_urls(urls))\n"}
{"type": "source_file", "path": "scraper/downloadimages.py", "content": "import asyncio\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom pathlib import Path\nimport json\nimport multiprocessing\nfrom typing import Union\nimport itertools\n\nimport aiofiles\nimport aiohttp\nfrom aiohttp.client import ClientSession\nfrom sqlalchemy.orm import Session\nfrom tinydb import TinyDB, Query\nfrom tqdm.auto import tqdm\nfrom uuid import uuid4\nfrom meme_database.models import MemeEntry, MemeImage\nfrom sqlalchemy import create_engine\nfrom dotenv import load_dotenv\nimport os\nfrom azure.storage.blob.aio import BlobClient\nfrom azure.storage.blob import BlobServiceClient\nimport requests\nfrom pyquery import PyQuery as pq\n\nload_dotenv()\naccount_url = \"https://aimemes.blob.core.windows.net\"\n\n\nblob_service_client = BlobServiceClient(account_url, credential=os.getenv(\"AZURE_STORAGE_KEY\"))\n\nmeme_entries = []\nmeme_photo_links = []\n\n\nasync def azure_blob_check(meme_id, file_name) -> bool:\n    try:\n\n        async with BlobClient.from_connection_string(os.getenv(\"AZURE_STORAGE_CONN_KEY\"), container_name=\"memes\", blob_name=f\"{meme_id}/{file_name}\") as blob:\n            exists = await blob.exists()\n            return exists\n    except Exception as e:\n        print(e)\n        return False\n\n\nexecutor = ThreadPoolExecutor()\nasync def upload_to_azure(content, service_client: BlobServiceClient, container_name: str, meme_id: str, filename: str) -> str:\n\n    blob_client = service_client.get_blob_client(container=container_name, blob=f\"{meme_id}/{filename}\")\n\n    def upload_action():\n        blob_client.upload_blob(content, overwrite=True)\n\n    loop = asyncio.get_running_loop()\n    await loop.run_in_executor(executor, upload_action)\n\n    return blob_client.url\n\n\nasync def fetch(session: ClientSession, url: str, proxies, retries=3, backoff_factor=0.5):\n    for attempt in range(retries):\n        try:\n            async with session.get(url, proxy=proxies['https']) as response:\n                return await response.text()\n        except aiohttp.ServerDisconnectedError:\n            if attempt < retries - 1:\n                sleep_time = backoff_factor * (2 ** attempt)\n                await asyncio.sleep(sleep_time)\n            else:\n                return None\n        except Exception as e:\n            return None  # Reraising the exception after logging it\n\nasync def scrape_image(url, session):\n    proxies = {'http': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225',\n               'https': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225'}\n    response_text = await fetch(session, f\"https://knowyourmeme.com{url}\", proxies)\n\n    if response_text is None:\n        return \"None\"\n\n    site = pq(response_text)\n    image_link = site(\"#photo_wrapper a\").attr(\"href\")\n\n\n    # r = requests.get(image_link, proxies=proxies)\n    #\n    # # Get filename from https://i.kym-cdn.com/photos/images/original/002/738/807/55e.jpg\n    # filename = image_link.split(\"/\")[-1]\n    # Path(\"images/\").mkdir(exist_ok=True)\n    # with open(f\"images/{filename}\", \"wb\") as f:\n    #     f.write(r.content)\n    #\n    # blob_url = upload_to_azure(Path(f\"images/{filename}\"), blob_service_client, \"memes\")\n    #\n    # # delete file after upload\n    # Path(f\"images/{filename}\").unlink()\n    return image_link\n\nasync def process_photo_link(photo_link, meme_id, session):\n    if not photo_link:\n        return\n    image_url = await scrape_image(photo_link, session)\n    # meme_image = MemeImage(\n    #     meme_entry=meme_id,\n    #     source_url=image_url,\n    # )\n    meme_photo_links.append({\n        \"id\": str(meme_id),\n        \"source_url\": image_url,\n        \"meme_entry\": meme_id,\n    })\n\n\nasync def process_meme(meme, pbar, session):\n    # Create a uuid for the meme\n    meme_id = str(uuid4())\n    meme_name = meme['title'].replace(\" | Know Your Meme\", \"\")\n    # Process meme details\n    meme_entries.append({\n        \"id\": str(meme_id),\n        \"name\": meme_name,\n        \"url\": meme['url'],\n        \"content\": meme['content'],\n        \"meme_added\": meme['posted_date'],\n    })\n    if meme['photo_links']:\n\n        for idx, photo_link in enumerate(meme['photo_links']):\n            await process_photo_link(photo_link, meme_id, session)\n            pbar.update(1)\n            pbar.set_description(f\"Successfully processed {pbar.n} memes\")\n    pbar.update(1)\n\n\nasync def main():\n    engine = create_engine(os.getenv(\"NEON_POSTGRES\"), pool_pre_ping=True)\n    db = TinyDB('memes.json')\n    Memes = Query()\n    successful_memes = db.search(Memes.photo_links != [])\n    photo_links = len(list(itertools.chain.from_iterable([s['photo_links'] for s in successful_memes])))\n    err_count = 1\n    async with aiohttp.ClientSession() as session:\n        with tqdm(total=len(successful_memes) + photo_links, leave=True) as pbar:\n            tasks = [process_meme(meme, pbar, session) for meme in successful_memes]\n            results = []\n\n            for task in asyncio.as_completed(tasks):\n                try:\n                    result = await task\n                    results.append(result)\n                except Exception as e:\n                    pbar.display(msg=\"Errors: {}\".format(err_count), pos=1)\n                    err_count += 1\n                    pbar.update(1)\n\n\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n    # with open(\"meme_entries.json\", \"w\") as f:\n    #     json.dump(meme_entries, f)\n    #\n    # with open(\"meme_photo_links.json\", \"w\") as f:\n    #     json.dump(meme_photo_links, f)"}
{"type": "source_file", "path": "utils/llm_queries.py", "content": "import random\nimport tempfile\nfrom typing import List\n\nimport gradio_client\nimport instructor\nimport requests\nfrom dotenv import load_dotenv\nfrom gradio_client import Client\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\nfrom datatypes.types import (\n    MemeInformation,\n    Descriptions,\n    Owlv2Classification,\n    FinalMetaphorImageLabel,\n    MetaphorLabel,\n    Scenario,\n)\n\nload_dotenv()\n\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"create_scenarios\",\n            \"description\": \"Creates many scenarios that is relatable to a human being in a funny and crude way\"\n            \"given a description of the image and the backstory of the meme. Use the news article given to reference and relate. Use those as primary subjects of interest.\"\n            \"This is for memes, so make it funny and follow the prompt / caption given.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"scenarios\": {\n                        \"type\": \"array\",\n                        \"items\": {\n                            \"type\": \"string\",\n                            \"description\": \"A scenario that the objects in the image can be compared to. Very relatable to\"\n                            \"the person that would be reading the meme. Relate this to the news article that was given and use proper nouns within it.\",\n                            \"maxLength\": 40,\n                            \"uniqueItems\": True,\n                        },\n                        \"minContains\": 1,\n                        \"maxContains\": 5,\n                    }\n                },\n                \"required\": [\"metaphor\"],\n            },\n        },\n    },\n]\n\n\n# litellm.add_function_to_prompt = True\ndef different_scenarios(\n    meme_information: MemeInformation, relevant_meme_history: str, news_information: str\n) -> Scenario:\n    client = instructor.from_openai(OpenAI())\n    scenarios = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        response_model=Scenario,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You create funny scenarios based off of the news article that is given.\"\n                \"In the scenarios use the subjects of interest in the news article to determine.\"\n                \"\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"\"\"\n             Give me a list of funny scenarios based off of the news article given. Take into account the theme of the image when thinking of what these funyn scenarios might look like.\n             The theme for this meme will be {meme_information.funny_theme}. Follow this as closely as possible. Use the news source\n             as context for the meme. Use as many subjects of interest as possible so that the meme is relatable to the viewer.\n            Be as crude and strange as possible and make it relatable to human beings in a funny and clever way.\n            \n            Use context of this news article to help you form these scenarios. Be specific and try to use proper nouns.\n            \n            Image Description: {meme_information.image_description}\n            Funny Theme: {meme_information.funny_theme}\n            News Article: {news_information}\n             \"\"\",\n            },\n        ],\n    )\n\n    return scenarios\n\n\ndef detect_objects_in_image(\n    image: bytes, items_to_detect: List[str]\n) -> List[Owlv2Classification]:\n    # save the image to a file\n\n    with tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\") as temp_image:\n        temp_image.write(image)\n        temp_image_path = temp_image.name\n    client = Client(\"https://codingwithlewis-owlv2.hf.space\")\n    result = client.predict(\n        gradio_client.file(temp_image_path),\n        \",\".join(items_to_detect),  # str  in 'text_queries' Textbox component\n        0.15,  # float (numeric value between 0 and 1) in 'score_threshold' Slider component\n        api_name=\"/predict\",\n    )\n    retrieved_items = []\n    items = []\n    for res in result[1]:\n        # Check to see if the object is in the list of items to detect\n        # if res[\"object\"] in retrieved_items:\n        #     continue\n        items.append(Owlv2Classification(object=res[\"object\"], pos=res[\"pos\"]))\n        retrieved_items.append(res[\"object\"])\n    return items\n\n\ndef get_type_of_humor(base64_image):\n    # Patch the OpenAI client\n    client = instructor.from_openai(OpenAI())\n\n    # Extract structured data from natural language\n    descriptions = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        response_model=Descriptions,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Explain why this meme is funny and suggest a reason how it can be used as a meme to be captioned.\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Based on what is in this image, what would be the best way to describe why this is funny? \",\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n                    },\n                ],\n            },\n        ],\n    )\n\n    return descriptions.theme\n\n\ndef create_metaphor_labels(\n    boxes: List[Owlv2Classification],\n    initial_image,\n    metaphor_list: list[str],\n    news_information: str,\n    meme_information: MemeInformation,\n) -> List[FinalMetaphorImageLabel]:\n    client = instructor.from_openai(OpenAI())\n    metaphor_list = [x for x in metaphor_list if x]  # Remove duds\n    labels = []\n    chosen_metaphor = random.choice(metaphor_list)\n\n    characters = []\n    for box in boxes:\n        metaphor_label = client.chat.completions.create(\n            model=\"gpt-4-turbo\",\n            response_model=MetaphorLabel,\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"Based off of the image and reasoning/scenario provided. Think of a label that could be\"\n                    \"applied to the image in bounding boxes.\",\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"text\",\n                            \"text\": f\"Use this Scenario to think of labels for each object that will be going into a meme. The label should be a {meme_information.funny_theme}\"\n                            f\"way of relating the items to the viewer in a meme. Use the news information characters as the metaphor/representation of the meme. Avoid terms like: 'me' or 'I'.\"\n                            f\"Use Proper nouns of the most relevant people in the news article \"\n                            f\"Please use the news information provided and the subjects of interest within it to create something people will recognize.\"\n                            f\"Object you are labelling: {box.object}\"\n                            f\"Scenario: {chosen_metaphor}\"\n                            f\"Image Description: {meme_information.image_description}\"\n                            f\"News Article: {news_information}\"\n                            f\"Why It's Funny: {meme_information.funny_reason}\"\n                            f\"Previous Character Labels: {characters}\",\n                        },\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": f\"data:image/jpeg;base64,{initial_image}\",\n                            },\n                        },\n                    ],\n                },\n            ],\n        )\n        characters.append(f\"Character: {box.object} Label: {metaphor_label.metaphor}\")\n        labels.append(\n            FinalMetaphorImageLabel.parse_obj(\n                {\n                    \"box\": box.pos,\n                    \"label\": metaphor_label.metaphor,\n                    \"object\": box.object,\n                }\n            )\n        )\n\n    return labels\n\n\ndef get_image_caption_from_llm(image: str) -> MemeInformation:\n    client = instructor.from_openai(OpenAI())\n\n    meme_response = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        response_model=MemeInformation,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a humor bot. Based on the image given, give me the reason something is funny,\"\n                \"an extremely detailed description of the image, a funny theme that can work well with the\"\n                \"image, as well as a list of subjects of interest within the image that can be used to relate\"\n                \"to the viewer so we can label it.\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Please give me a detailed description, reason that it's funny, a funny theme and the subjects\"\n                        \"of interest\",\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n                    },\n                ],\n            },\n        ],\n    )\n\n    print(meme_response)\n\n    return meme_response\n\n\ndef create_meme_caption():\n    url = \"https://app.openpipe.ai/api/v1/chat/completions\"\n\n    headers = {\n        \"Authorization\": \"Bearer opk_ac45d39119f0e9cb3c4d7f49c02f2a369ffb7a412d\",\n        \"Content-Type\": \"application/json\",\n        \"op-log-request\": \"true\",\n    }\n\n    data = {\n        \"model\": \"openpipe:cold-socks-say\",\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": \"Write a caption for this meme based on the description and tone of the image. Be as obscure, silly and funny as possible. You will be given Metaphors, image descriptions and more.\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": \"Image Description: Joker is looking playful at a old man in a bar.\\n\"\n                \"Metaphor: The metaphor of Joker is Meme poster.\\n\"\n                \"Metaphor: The metaphor of a old man is Meme poster. \\n\"\n                \"Metaphor: The metaphor of a bar is Meme poster. \\n\"\n                \"Metaphor: The metaphor of looking is Meme poster.\",\n            },\n        ],\n        \"temperature\": 0,\n    }\n\n    response = requests.post(url, headers=headers, json=data)\n\n    print(response.json())\n    return \"HI\"\n\n\nclass NewsMemeData(BaseModel):\n    meme_caption: str = Field(\n        description=\"A one sentence caption for the meme. \"\n        \"The caption should be in the point of view of one of the subjects in the article. Don't use words like 'I' or 'Me'. Only proper nouns of the items in the article \"\n        \"For example: <SUBJECT> when....\"\n        \"Be Crude and abrupt.\"\n        \"Make grammar mistakes for fun. Use the description of the image as a juxtaposition\"\n    )\n\n\ndef create_meme_based_off_news(news: str, image: str):\n    client = instructor.from_openai(OpenAI())\n    meme_response = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        response_model=NewsMemeData,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You make memes based off of the image and news article provided. \"\n                \"You are putting a caption on the image. Use one of the subjects in the news articles as a point of view. for example: <subject> when... Use the proper nouns within the news article to\"\n                \"use as the joke within the image caption.\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Use the proper nouns within the news article to\"\n                        \"use as the joke within the image caption.\"\n                        f\"News Article: {news}\",\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n                    },\n                ],\n            },\n        ],\n    )\n    return meme_response.meme_caption.lower()\n"}
{"type": "source_file", "path": "scraper/template_images.py", "content": "import os\nfrom concurrent.futures import ThreadPoolExecutor\n\nimport requests\nfrom sqlalchemy.orm import Session\nfrom tqdm import tqdm\n\nfrom meme_database.models import MemeEntry\nfrom sqlalchemy import create_engine, select\nfrom dotenv import load_dotenv\nfrom pyquery import PyQuery as pq\nimport json\n\nload_dotenv()\nimage_links = []\ndef fetch_and_process_meme(meme: MemeEntry):\n    try:\n        response = requests.get(meme.url, proxies=proxies)\n        d = pq(response.text)\n        # Assuming the header element with class 'photo' contains an href attribute\n        href = d(\"header .photo\").attr('href')\n        if href:\n            image_links.append({\n                \"id\": str(meme.id),\n                \"template_url\": href\n            })\n    except Exception as e:\n        print(f\"Error processing {meme.url}: {e}\")\n\n\nproxies = {'http': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225',\n               'https': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225'}\n\n\nengine = create_engine(os.getenv(\"NEON_POSTGRES\"))\n\n\ndef main():\n    with Session(engine) as session:\n        memes = session.scalars(select(MemeEntry)).all()\n\n    # Use a ThreadPoolExecutor to manage multiple threads\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        list(tqdm(executor.map(fetch_and_process_meme, memes), total=len(memes)))\n\n    with open(\"template_memes.json\", 'w') as f:\n        json.dump(image_links, f)\n\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "source_file", "path": "scraper/get_news_source.py", "content": "import requests\nfrom newspaper import Article\nfrom newspaper.configuration import Configuration\ndef get_news_article(url):\n\n    proxies = {'http': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225',\n               'https': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225'}\n    USER_AGENT = \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0\"\n\n    config = Configuration()\n\n    config.proxies = proxies\n\n    # response = requests.get(url, proxies=proxies)\n\n    article = Article(url, config=config)\n    article.download()\n    article.parse()\n    if not article.text:\n        return None\n    return article.text\n\n\nif __name__ == \"__main__\":\n    get_news_article(\n        \"https://www.cnn.com/2024/04/24/tech/tiktok-ban-bytedance-split-the-world-further-intl-hnk/index.html\")\n"}
{"type": "source_file", "path": "main.py", "content": "from dotenv import load_dotenv\n\nfrom data.datafetch import retrieve_relevant_meme\nfrom scraper.get_news_source import get_news_article\nfrom utils.image import (\n    convert_to_base_64_string,\n    add_captions_to_image,\n)\nfrom utils.llm_queries import (\n    different_scenarios,\n    get_image_caption_from_llm,\n    create_metaphor_labels,\n    detect_objects_in_image,\n)\n\nload_dotenv()\n\n\ndef send_to_logs(log, log_area, completed=None):\n    if completed:\n        log_area.update(label=log)\n    log_area.update(label=log)\n\n\ndef create_upload_file(image: bytes, news_url: str, log_area):\n    send_to_logs(\"grabbing news article...\", log_area)\n    news_information = get_news_article(news_url)\n    if news_information is None:\n        return\n\n    send_to_logs(\"grabbing image descriptions and captions...\", log_area)\n    image_text = convert_to_base_64_string(image)\n    meme_information = get_image_caption_from_llm(image_text)\n    relevant_meme_description = retrieve_relevant_meme(\n        meme_information.image_description\n    )\n    send_to_logs(\"Grabbing Metaphors...\", log_area)\n    scenarios = different_scenarios(\n        meme_information, relevant_meme_description, news_information\n    )\n\n    send_to_logs(\"Looking for objects\", log_area)\n    object_coordinates = detect_objects_in_image(\n        image, meme_information.physical_items_in_image\n    )\n\n    send_to_logs(\"Creating labels...\", log_area)\n\n    metaphor_labels = create_metaphor_labels(\n        object_coordinates,\n        image_text,\n        scenarios.funny_scenarios,\n        news_information,\n        meme_information,\n    )\n    print(metaphor_labels)\n    send_to_logs(\"Finishing up...\", log_area)\n    final_image_path = add_captions_to_image(metaphor_labels, image)\n    return final_image_path\n"}
{"type": "source_file", "path": "utils/image.py", "content": "import base64\nimport io\nimport textwrap\nfrom io import BytesIO\nfrom pathlib import Path\nfrom typing import List\n\nfrom PIL import Image, ImageDraw, ImageFont\nfrom pydantic import conlist\n\nfrom datatypes.types import FinalMetaphorImageLabel\n\n\ndef convert_to_base_64_string(image: bytes) -> str:\n    return base64.b64encode(image).decode(\"utf-8\")\n\n\ndef image_2_b64(image):\n    buff = BytesIO()\n    image.save(buff, format=\"JPEG\")\n    img_str = base64.b64encode(buff.getvalue()).decode(\"utf-8\")\n    return img_str\n\n\ndef create_bounding_box_in_image(\n    image: bytes, box_coords: conlist(int, min_length=4, max_length=4)\n) -> Path:\n    from PIL import Image, ImageDraw\n    import random\n\n    # Open the image\n    img = Image.open(io.BytesIO(image)).convert(\"L\")\n    img.save(\"gray_image.jpg\")\n\n    img = Image.open(\"gray_image.jpg\").convert(\"RGB\")\n\n    # Create a drawing object\n    draw = ImageDraw.Draw(img)\n\n    # Draw the bounding boxes\n    draw.rectangle(box_coords, outline=\"red\", width=5)\n\n    file_name = Path(f\"outputs/boxed_image_{random.randint(0, 1000)}.jpg\", mkdir=True)\n\n    # Save the image with the bounding boxes\n    img.save(file_name)\n\n    return Path(file_name)\n\n\ndef add_captions_to_image(boxes: List[FinalMetaphorImageLabel], original_image: bytes):\n    original_image = io.BytesIO(original_image)\n    img = Image.open(original_image)\n    draw = ImageDraw.Draw(img)\n    font_size = 24\n    font = ImageFont.load_default(font_size)  # Ensure you have the correct font path\n\n    for box in boxes:\n        bbox = box.box\n        text = box.label\n\n        # Calculate bounding box dimensions\n        box_width = bbox[2] - bbox[0]\n        box_height = bbox[3] - bbox[1]\n        max_line_length = int(\n            box_width / (font_size * 0.2)\n        )  # Adjust multiplier as needed\n\n        # Wrap text to fit within bounding box width\n        lines = textwrap.wrap(text, width=max_line_length)\n\n        # Calculate the total text height\n        text_height = len(lines) * font_size\n\n        # Calculate initial y position to center text vertically\n        y_text = bbox[1] + (box_height - text_height) / 2\n\n        for line in lines:\n            # Measure text size for each line\n            text_size = draw.textlength(line, font=font)\n\n            # Calculate text position to center it horizontally\n            text_x = bbox[0] + (box_width - text_size) / 2\n\n            # Draw each line of text\n            draw.text(\n                (text_x, y_text),\n                line,\n                font=font,\n                fill=(255, 255, 255),\n                stroke_width=2,\n                stroke_fill=(0, 0, 0),\n            )\n            y_text += font_size  # Move y coordinate for next line\n\n    img.save(\"image_with_text_stroke.jpg\")\n    return Path(\"image_with_text_stroke.jpg\")\n"}
{"type": "source_file", "path": "run_ui.py", "content": "import streamlit as st\n\nfrom main import create_upload_file\n\nst.markdown(\"\"\"\n# Meme Generator\n\nGenerate memes using AI! Upload an image and add text to it.\n\"\"\")\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.subheader(\"Create Meme\")\n    with st.form(\"meme_form\"):\n        news_article = st.text_input(\"News Article\")\n        meme_image = st.file_uploader(\n            \"Upload an image. This will be used to caption.\",\n            accept_multiple_files=False,\n            type=[\"png\", \"jpg\", \"jpeg\"],\n        )\n\n        submit = st.form_submit_button(\"Generate Meme!\")\nwith col2:\n    st.subheader(\"Meme will show up here\")\n\nif submit:\n    if meme_image is None:\n        st.error(\"Please upload an image!\")\n        st.stop()\n    bytes_data = meme_image.getvalue()\n    with st.status(\"Starting...\", state=\"running\") as status:\n        image_path = create_upload_file(bytes_data, news_article, status)\n        status.write(\"Finished!\")\n    with col2:\n        st.image(str(image_path.absolute()))\n\nst.divider()\nwith st.container():\n    st.write(\"Data retrieval powered by:\")\n    st.image(\n        \"https://www.enterprisetimes.co.uk/wp-content/uploads/2044/05/Bright-Data-Logo-Copy.png\",\n        width=200,\n    )\n"}
{"type": "source_file", "path": "scraper/image_downloader.py", "content": "import asyncio\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom pathlib import Path\nimport json\nimport multiprocessing\nfrom typing import Union, List\nimport itertools\nfrom urllib.parse import urlparse\n\nimport aiofiles\nimport aiohttp\nfrom aiohttp.client import ClientSession\nfrom pydantic import BaseModel, RootModel, ValidationError\nfrom sqlalchemy.orm import Session\nfrom tinydb import TinyDB, Query\nfrom tqdm.auto import tqdm\nfrom uuid import uuid4\nfrom meme_database.models import MemeEntry, MemeImage\nfrom sqlalchemy import create_engine, select\nfrom dotenv import load_dotenv\nimport os\nfrom azure.storage.blob.aio import BlobClient\nfrom azure.storage.blob import BlobServiceClient\nimport requests\nfrom pyquery import PyQuery as pq\n\nload_dotenv()\naccount_url = \"https://aimemes.blob.core.windows.net\"\n\nblob_service_client = BlobServiceClient(account_url, credential=os.getenv(\"AZURE_STORAGE_KEY\"))\n\nazure_uploaded_links = []\n\n\nasync def azure_blob_check(meme_id, file_name) -> bool:\n    try:\n\n        async with BlobClient.from_connection_string(os.getenv(\"AZURE_STORAGE_CONN_KEY\"), container_name=\"memes\",\n                                                     blob_name=f\"{meme_id}/{file_name}\") as blob:\n            exists = await blob.exists()\n            return exists\n    except Exception as e:\n        print(e)\n        return False\n\n\nexecutor = ThreadPoolExecutor()\n\n\nasync def upload_to_azure(content, service_client: BlobServiceClient, container_name: str, meme_id: str,\n                          filename: str) -> str:\n    blob_client = service_client.get_blob_client(container=container_name, blob=f\"{meme_id}/{filename}\")\n\n    def upload_action():\n        blob_client.upload_blob(content, overwrite=True)\n\n    loop = asyncio.get_running_loop()\n    await loop.run_in_executor(executor, upload_action)\n\n    return blob_client.url\n\n\nasync def fetch(session: ClientSession, url: str, proxies, retries=3, backoff_factor=0.5):\n    for attempt in range(retries):\n        try:\n            async with session.get(url, proxy=proxies['https']) as response:\n\n                return await response.read()\n        except aiohttp.ServerDisconnectedError:\n            if attempt < retries - 1:\n                sleep_time = backoff_factor * (2 ** attempt)\n                await asyncio.sleep(sleep_time)\n            else:\n                return None\n        except Exception as e:\n            print(e)\n            return None  # Reraising the exception after logging it\n\n\nasync def scrape_image(url, session):\n    proxies = {'http': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225',\n               'https': 'http://brd-customer-hl_4a5981ec-zone-business:lgw3i1br1nkx@brd.superproxy.io:22225'}\n    response_text = await fetch(session, url, proxies)\n\n    return response_text\n\n\nasync def get_file_extension(url):\n    parsed_url = urlparse(url)\n    _, file_extension = os.path.splitext(parsed_url.path)\n    return file_extension.lstrip('.')\n\n\nasync def process_photo_link(photo_link: str, meme_id: str, session: ClientSession):\n\n    if not photo_link:\n        return\n    image_content = await scrape_image(photo_link, session)\n    # get file extension from url\n    file_extension = await get_file_extension(photo_link)\n\n    template_image_url = await upload_to_azure(image_content, blob_service_client, \"memes\", meme_id,\n                                         f\"{meme_id}_template.{file_extension}\")\n\n    azure_uploaded_links.append({\n        \"id\": str(meme_id),\n        \"azure_url\": photo_link,\n        \"photo_url\": template_image_url,\n    })\n\n\nclass MemeLink(BaseModel):\n    id: str\n    template_url: str\n\n\nclass MemeLinkList(RootModel):\n    root: List[MemeLink]\n\n\nasync def process_meme(meme: MemeLink, pbar: tqdm, client_session: ClientSession):\n\n    if not meme.template_url:\n        return\n\n    await process_photo_link(meme.template_url, meme.id, client_session)\n    pbar.update(1)\n\n\nasync def main():\n    engine = create_engine(os.getenv(\"NEON_POSTGRES\"), pool_pre_ping=True)\n\n    err_count = 1\n    memes = []\n    async with aiofiles.open(\"template_memes.json\", \"r\") as fout:\n        memes_json = json.loads(await fout.read())\n        memes_len = len(memes_json)\n    try:\n        for meme in memes_json:\n            memes.append(MemeLink.parse_obj(\n                meme\n            ))\n\n    except ValidationError as e:\n        print(traceback.format_exc())\n\n    async with aiohttp.ClientSession() as client_session:\n        with tqdm(total=memes_len, leave=True) as pbar:\n            tasks = [process_meme(meme, pbar, client_session) for meme in memes]\n            results = []\n\n            for task in asyncio.as_completed(tasks):\n                try:\n                    result = await task\n                    results.append(result)\n                except Exception as e:\n                    print(traceback.format_exc())\n                    pbar.display(msg=\"Errors: {}\".format(err_count), pos=1)\n                    err_count += 1\n                    pbar.update(1)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n    with open(\"meme_templates_azure.json\", \"w\") as f:\n        json.dump(azure_uploaded_links, f)\n    #\n    # with open(\"meme_photo_links.json\", \"w\") as f:\n    #     json.dump(meme_photo_links, f)\n"}
{"type": "source_file", "path": "run_news_app.py", "content": "import streamlit as st\n\nfrom video import get_news_meme\n\nst.markdown(\"\"\"\n# Meme Generator\n\nGenerate memes using AI! Upload an image and add text to it.\n\"\"\")\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.subheader(\"Create Meme\")\n    with st.form(\"meme_form\"):\n        news_article = st.text_input(\"News Article\")\n        meme_image = st.file_uploader(\n            \"Upload an image. This will be used to caption.\",\n            accept_multiple_files=False,\n            type=[\"png\", \"jpg\", \"jpeg\"],\n        )\n\n        submit = st.form_submit_button(\"Generate Meme!\")\nwith col2:\n    st.subheader(\"Meme will show up here\")\n\nif submit:\n    if meme_image is None:\n        st.error(\"Please upload an image!\")\n        st.stop()\n    bytes_data = meme_image.getvalue()\n    with st.status(\"Starting...\", state=\"running\") as status:\n        meme_caption = get_news_meme(news_article, meme_image.getvalue())\n        status.write(\"Finished!\")\n    with col2:\n        st.text_area(str(meme_caption))\n\nst.divider()\nwith st.container():\n    st.write(\"Data retrieval powered by:\")\n    st.image(\n        \"https://www.enterprisetimes.co.uk/wp-content/uploads/2044/05/Bright-Data-Logo-Copy.png\",\n        width=200,\n    )\n"}
{"type": "source_file", "path": "video.py", "content": "from scraper.get_news_source import get_news_article\nfrom utils.image import convert_to_base_64_string\nfrom utils.llm_queries import create_meme_based_off_news\n\n\ndef get_news_meme(url: str, image: bytes):\n    news_source = get_news_article(url)\n    image = convert_to_base_64_string(image)\n    meme = create_meme_based_off_news(news_source, image)\n\n    return meme\n"}
{"type": "source_file", "path": "datatypes/types.py", "content": "from enum import Enum\n\nfrom pydantic import BaseModel, Field, conlist\n\n\nclass Owlv2Classification(BaseModel):\n    object: str\n    pos: conlist(int, min_length=4, max_length=4)\n\n\nclass MetaphorLabel(BaseModel):\n    metaphor: str = Field(\n        description=\"A literal definition of what the object/character can represent\"\n        \"Don't make up anything. Just use the items that are specifically in the article. Use proper nouns to describe.\"\n        \"Ideally understand what the other metaphor is saying and use that as a basis for the metaphor.\",\n        max_length=18,\n    )\n\n\nclass FinalMetaphorImageLabel(BaseModel):\n    box: conlist(int, min_length=4, max_length=4)\n    label: str\n    object: str\n\n\nclass Theme(Enum):\n    unexpected = \"Unexpectedness\"\n    exaggeration = \"Exaggeration\"\n    absurdity = \"Absurdity\"\n    wordplay = \"Wordplay\"\n    juxtaposition = \"Juxtaposition\"\n    incongruity = \"Incongruity\"\n\n\nclass Descriptions(BaseModel):\n    theme: Theme\n    image_description: str\n\n\nclass MemeInformation(BaseModel):\n    image_description: str\n    funny_reason: str\n    funny_theme: Theme\n    physical_items_in_image: conlist(str, max_length=2) = Field(\n        description=\"Subjects of interest in the image.\"\n        \"Use only things that can explicitly be\"\n        \"seen or labelled. Try to do the most recognizable objects in the image.\"\n        \"or abstract concepts. only animals, people, characters or\"\n        \"objects that are easily recognizable. Keep each description as 1 or 2 words max. Use labels that \"\n        \"can uniquely identify humans (young, old, child)\"\n    )\n\n\nclass Scenario(BaseModel):\n    funny_scenarios: conlist(str, max_length=8, min_length=2) = Field(\n        description=\"Scenarios that can be used to make light of the news article\"\n        \"only use facts from the news article. Don't make up anything. Be realistic. use proper nouns\"\n        \"it's important to use the exact names of the people, places or company names.\"\n        \"Use proper nouns as well as identifying characteristics of the theme of the news article.\"\n    )\n"}
