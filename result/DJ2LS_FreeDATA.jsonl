{"repo_info": {"repo_name": "FreeDATA", "repo_owner": "DJ2LS", "repo_url": "https://github.com/DJ2LS/FreeDATA"}}
{"type": "test_file", "path": "tests/test_arq_session.py", "content": "import sys\nimport time\nsys.path.append('freedata_server')\n\nimport unittest\nimport unittest.mock\nfrom config import CONFIG\nimport helpers\nimport queue\nimport threading\nimport base64\nfrom command_arq_raw import ARQRawCommand\nfrom state_manager import StateManager\nfrom frame_dispatcher import DISPATCHER\nimport random\nimport structlog\nimport numpy as np\nfrom event_manager import EventManager\nfrom state_manager import StateManager\nfrom data_frame_factory import DataFrameFactory\nimport codec2\nimport arq_session_irs\nclass TestModem:\n    def __init__(self, event_q, state_q):\n        self.data_queue_received = queue.Queue()\n        self.demodulator = unittest.mock.Mock()\n        self.event_manager = EventManager([event_q])\n        self.logger = structlog.get_logger('Modem')\n        self.states = StateManager(state_q)\n\n    def getFrameTransmissionTime(self, mode):\n        samples = 0\n        c2instance = codec2.open_instance(mode.value)\n        samples += codec2.api.freedv_get_n_tx_preamble_modem_samples(c2instance)\n        samples += codec2.api.freedv_get_n_tx_modem_samples(c2instance)\n        samples += codec2.api.freedv_get_n_tx_postamble_modem_samples(c2instance)\n        time = samples / 8000\n        #print(mode)\n        #if mode == codec2.FREEDV_MODE.signalling:\n        #    time = 0.69\n        #print(time)\n        return time\n\n    def transmit(self, mode, repeats: int, repeat_delay: int, frames: bytearray) -> bool:\n\n        # Simulate transmission time\n        tx_time = self.getFrameTransmissionTime(mode) + 0.1 # PTT\n        self.logger.info(f\"TX {tx_time} seconds...\")\n        threading.Event().wait(tx_time)\n\n        transmission = {\n            'mode': mode,\n            'bytes': frames,\n        }\n        self.data_queue_received.put(transmission)\n\nclass TestARQSession(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        config_manager = CONFIG('freedata_server/config.ini.example')\n        cls.config = config_manager.read()\n        cls.logger = structlog.get_logger(\"TESTS\")\n        cls.frame_factory = DataFrameFactory(cls.config)\n\n        # ISS\n        cls.iss_state_manager = StateManager(queue.Queue())\n        cls.iss_state_manager.set_channel_busy_condition_codec2(False)\n\n        cls.iss_event_manager = EventManager([queue.Queue()])\n        cls.iss_event_queue = queue.Queue()\n        cls.iss_state_queue = queue.Queue()\n        cls.iss_modem = TestModem(cls.iss_event_queue, cls.iss_state_queue)\n        cls.iss_frame_dispatcher = DISPATCHER(cls.config, \n                                          cls.iss_event_manager,\n                                          cls.iss_state_manager, \n                                          cls.iss_modem)\n\n        # IRS\n        cls.irs_state_manager = StateManager(queue.Queue())\n        cls.iss_state_manager.set_channel_busy_condition_codec2(False)\n\n        cls.irs_event_manager = EventManager([queue.Queue()])\n        cls.irs_event_queue = queue.Queue()\n        cls.irs_state_queue = queue.Queue()\n        cls.irs_modem = TestModem(cls.irs_event_queue, cls.irs_state_queue)\n        cls.irs_frame_dispatcher = DISPATCHER(cls.config, \n                                          cls.irs_event_manager,\n                                          cls.irs_state_manager, \n                                          cls.irs_modem)\n\n        # simulate a busy condition\n        cls.irs_state_manager.channel_busy_slot = [True, False, False, False, False]\n        # Frame loss probability in %\n        cls.loss_probability = 0\n\n        cls.channels_running = True\n\n    def channelWorker(self, modem_transmit_queue: queue.Queue, frame_dispatcher: DISPATCHER):\n        while self.channels_running:\n            # Transfer data between both parties\n            try:\n                transmission = modem_transmit_queue.get(timeout=1)\n                transmission[\"bytes\"] += bytes(2) # simulate 2 bytes crc checksum\n                if random.randint(0, 100) < self.loss_probability:\n                    self.logger.info(f\"[{threading.current_thread().name}] Frame lost...\")\n                    continue\n\n                frame_bytes = transmission['bytes']\n\n                if len(frame_bytes) == 5:\n                    mode_name = \"SIGNALLING_ACK\"\n                else:\n                    mode_name = None\n                frame_dispatcher.process_data(frame_bytes, None, len(frame_bytes), 15, 0, mode_name=mode_name)\n            except queue.Empty:\n                continue\n        self.logger.info(f\"[{threading.current_thread().name}] Channel closed.\")\n\n    def waitForSession(self, q, outbound = False):\n            key = 'arq-transfer-outbound' if outbound else 'arq-transfer-inbound'\n            while True and self.channels_running:\n                ev = q.get()\n                if key in ev and ('success' in ev[key] or 'ABORTED' in ev[key]):\n                    self.logger.info(f\"[{threading.current_thread().name}] {key} session ended.\")\n                    break\n\n    def establishChannels(self):\n        self.channels_running = True\n        self.iss_to_irs_channel = threading.Thread(target=self.channelWorker, \n                                                    args=[self.iss_modem.data_queue_received, \n                                                    self.irs_frame_dispatcher],\n                                                    name = \"ISS to IRS channel\")\n        self.iss_to_irs_channel.start()\n\n        self.irs_to_iss_channel = threading.Thread(target=self.channelWorker, \n                                                    args=[self.irs_modem.data_queue_received, \n                                                    self.iss_frame_dispatcher],\n                                                    name = \"IRS to ISS channel\")\n        self.irs_to_iss_channel.start()\n\n    def waitAndCloseChannels(self):\n        self.waitForSession(self.iss_event_queue, True)\n        self.channels_running = False\n        self.waitForSession(self.irs_event_queue, False)\n        self.channels_running = False\n\n    def DisabledtestARQSessionSmallPayload(self):\n        # set Packet Error Rate (PER) / frame loss probability\n        self.loss_probability = 30\n\n        self.establishChannels()\n        params = {\n            'dxcall': \"AA1AAA-1\",\n            'data': base64.b64encode(bytes(\"Hello world!\", encoding=\"utf-8\")),\n            'type': \"raw_lzma\"\n        }\n        cmd = ARQRawCommand(self.config, self.iss_state_manager, self.iss_event_queue, params)\n        cmd.run(self.iss_event_queue, self.iss_modem)\n        self.waitAndCloseChannels()\n        del cmd\n\n    def testARQSessionLargePayload(self):\n        # set Packet Error Rate (PER) / frame loss probability\n        self.loss_probability = 0\n\n        self.establishChannels()\n        params = {\n            'dxcall': \"AA1AAA-1\",\n            'data': base64.b64encode(np.random.bytes(1000)),\n            'type': \"raw_lzma\"\n        }\n        cmd = ARQRawCommand(self.config, self.iss_state_manager, self.iss_event_queue, params)\n        cmd.run(self.iss_event_queue, self.iss_modem)\n\n        self.waitAndCloseChannels()\n        del cmd\n\n    def DisabledtestARQSessionAbortTransmissionISS(self):\n        # set Packet Error Rate (PER) / frame loss probability\n        self.loss_probability = 0\n\n        self.establishChannels()\n        params = {\n            'dxcall': \"AA1AAA-1\",\n            'data': base64.b64encode(np.random.bytes(100)),\n        }\n        cmd = ARQRawCommand(self.config, self.iss_state_manager, self.iss_event_queue, params)\n        cmd.run(self.iss_event_queue, self.iss_modem)\n\n        threading.Event().wait(np.random.randint(10,10))\n        for id in self.iss_state_manager.arq_iss_sessions:\n            self.iss_state_manager.arq_iss_sessions[id].abort_transmission()\n\n        self.waitAndCloseChannels()\n        del cmd\n\n    def DisabledtestARQSessionAbortTransmissionIRS(self):\n        # set Packet Error Rate (PER) / frame loss probability\n        self.loss_probability = 0\n\n        self.establishChannels()\n        params = {\n            'dxcall': \"AA1AAA-1\",\n            'data': base64.b64encode(np.random.bytes(100)),\n        }\n        cmd = ARQRawCommand(self.config, self.iss_state_manager, self.iss_event_queue, params)\n        cmd.run(self.iss_event_queue, self.iss_modem)\n\n        threading.Event().wait(np.random.randint(1,10))\n        for id in self.irs_state_manager.arq_irs_sessions:\n            self.irs_state_manager.arq_irs_sessions[id].abort_transmission()\n\n        self.waitAndCloseChannels()\n        del cmd\n\n    def DisabledtestSessionCleanupISS(self):\n\n        params = {\n            'dxcall': \"AA1AAA-1\",\n            'data': base64.b64encode(np.random.bytes(100)),\n        }\n        cmd = ARQRawCommand(self.config, self.iss_state_manager, self.iss_event_queue, params)\n        cmd.run(self.iss_event_queue, self.iss_modem)\n        for session_id in self.iss_state_manager.arq_iss_sessions:\n            session = self.iss_state_manager.arq_iss_sessions[session_id]\n            ISS_States = session.state_enum\n            session.state = ISS_States.FAILED\n            session.session_ended = time.time() - 1000\n            if session.is_session_outdated():\n                self.logger.info(f\"session [{session_id}] outdated - deleting it\")\n                self.iss_state_manager.remove_arq_iss_session(session_id)\n                break\n        del cmd\n\n    def DisabledtestSessionCleanupIRS(self):\n        session = arq_session_irs.ARQSessionIRS(self.config,\n                            self.irs_modem,\n                            'AA1AAA-1',\n                            random.randint(0, 255),\n                            self.irs_state_manager\n                                                )\n        self.irs_state_manager.register_arq_irs_session(session)\n        for session_id in self.irs_state_manager.arq_irs_sessions:\n            session = self.irs_state_manager.arq_irs_sessions[session_id]\n            irs_States = session.state_enum\n            session.state = irs_States.FAILED\n            session.session_ended = time.time() - 1000\n            if session.is_session_outdated():\n                self.logger.info(f\"session [{session_id}] outdated - deleting it\")\n                self.irs_state_manager.remove_arq_irs_session(session_id)\n                break\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_message_p2p.py", "content": "import sys\nsys.path.append('freedata_server')\nimport numpy as np\n\nimport unittest\nfrom config import CONFIG\nfrom message_p2p import MessageP2P\nfrom message_system_db_messages import DatabaseManagerMessages\nfrom event_manager import EventManager\nimport queue\nimport base64\n\nclass TestDataFrameFactory(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        config_manager = CONFIG('freedata_server/config.ini.example')\n        cls.config = config_manager.read()\n\n        cls.event_queue = queue.Queue()\n        cls.event_manager = EventManager([cls.event_queue])\n        cls.mycall = f\"{cls.config['STATION']['mycall']}-{cls.config['STATION']['myssid']}\"\n        cls.database_manager = DatabaseManagerMessages(cls.event_manager)\n\n    def testFromApiParams(self):\n        api_params = {\n            'destination': 'DJ2LS-3',\n            'body': 'Hello World!',\n        }\n        message = MessageP2P.from_api_params(self.mycall, api_params)\n        self.assertEqual(message.destination, api_params['destination'])\n        self.assertEqual(message.body, api_params['body'])\n\n    def testToPayloadWithAttachment(self):\n        attachment = {\n            'name': 'test.gif',\n            'type': 'image/gif',\n            'data': str(base64.b64encode(np.random.bytes(1024)), 'utf-8')\n        }\n        apiParams = {'destination': 'DJ2LS-3', 'body': 'Hello World!', 'attachments': [attachment]}\n        message = MessageP2P.from_api_params(self.mycall, apiParams)\n\n        payload = message.to_payload()\n        received_message = MessageP2P.from_payload(payload)\n        self.assertEqual(message.origin, received_message.origin)\n        self.assertEqual(message.destination, received_message.destination)\n        self.assertCountEqual(message.attachments, received_message.attachments)\n        # FIXME...\n        #self.assertEqual(attachment['data'], received_message.attachments[0]['data'])\n\n    def testToPayloadWithAttachmentAndDatabase(self):\n        attachment = {\n            'name': 'test.gif',\n            'type': 'image/gif',\n            'data': str(base64.b64encode(np.random.bytes(1024)), 'utf-8')\n        }\n        apiParams = {'destination': 'DJ2LS-3', 'body': 'Hello World!', 'attachments': [attachment]}\n        message = MessageP2P.from_api_params(self.mycall, apiParams)\n\n        payload = message.to_payload()\n        received_message = MessageP2P.from_payload(payload)\n        received_message_dict = MessageP2P.to_dict(received_message)\n        self.database_manager.add_message(received_message_dict, statistics={})\n\n        self.assertEqual(message.origin, received_message.origin)\n        self.assertEqual(message.destination, received_message.destination)\n        self.assertCountEqual(message.attachments, received_message.attachments)\n        result = self.database_manager.get_message_by_id(message.id)\n        self.assertEqual(result[\"is_read\"], True)\n        self.assertEqual(result[\"destination\"], message.destination)\n\n\n\n\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_data_frame_factory.py", "content": "import sys\nsys.path.append('freedata_server')\n\nimport unittest\nfrom config import CONFIG\nfrom data_frame_factory import DataFrameFactory\nfrom codec2 import FREEDV_MODE\nimport helpers\nfrom modem_frametypes import FRAME_TYPE\n\nclass TestDataFrameFactory(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        config_manager = CONFIG('freedata_server/config.ini.example')\n        config = config_manager.read()\n        cls.factory = DataFrameFactory(config)\n\n    def testBeacon(self):\n        beacon_frame = self.factory.build_beacon()\n        beacon_data = self.factory.deconstruct(beacon_frame)\n        self.assertEqual(beacon_data['origin'], self.factory.myfullcall.upper())\n        self.assertEqual(beacon_data['gridsquare'], self.factory.mygrid.upper())\n\n    def testPing(self):\n        dxcall = \"DJ2LS-3\"\n        ping_frame = self.factory.build_ping(dxcall)\n        ping_data = self.factory.deconstruct(ping_frame)\n        self.assertEqual(ping_data['origin'], self.factory.myfullcall)\n        self.assertEqual(ping_data['destination_crc'], helpers.get_crc_24(dxcall).hex())\n\n    def testARQConnect(self):\n        dxcall = \"DJ2LS-4\"\n        session_id = 123\n        frame = self.factory.build_arq_session_open(dxcall, session_id, 1700, 1)\n        frame_data = self.factory.deconstruct(frame)\n\n        self.assertEqual(frame_data['origin'], self.factory.myfullcall)\n        self.assertEqual(frame_data['session_id'] , session_id)\n\n    def testCQ(self):\n        frame = self.factory.build_cq()\n        frame_data = self.factory.deconstruct(frame)\n        self.assertEqual(frame_data['origin'], self.factory.myfullcall)\n        self.assertEqual(frame_data['gridsquare'], self.factory.mygrid.upper())\n\n    def testBurstDataFrames(self):\n        session_id = 123\n        offset = 40\n        payload = b'Hello World!'\n        frame = self.factory.build_arq_burst_frame(FREEDV_MODE.datac3, \n                                                session_id, offset, payload, 0)\n        frame_data = self.factory.deconstruct(frame)\n        self.assertEqual(frame_data['session_id'], session_id)\n        self.assertEqual(frame_data['offset'], offset)\n        data = frame_data['data'][:len(payload)]\n        self.assertEqual(data, payload)\n\n        payload = payload * 1000\n        self.assertRaises(OverflowError, self.factory.build_arq_burst_frame,\n            FREEDV_MODE.datac3, session_id, offset, payload, 0)\n        \n    def testAvailablePayload(self):\n        avail = self.factory.get_available_data_payload_for_mode(FRAME_TYPE.ARQ_BURST_FRAME, FREEDV_MODE.datac3)\n        self.assertEqual(avail, 119) # 128 bytes datac3 frame payload - BURST frame overhead\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_server.py", "content": "import unittest\nfrom subprocess import Popen, PIPE\nimport shlex, os\nimport requests\nimport time\nimport json\n\n# API Server integration testst\nclass TestIntegration(unittest.TestCase):\n\n    process = None\n    url = \"http://127.0.0.1:5000\"\n\n    @classmethod\n    def setUpClass(cls):\n        cmd = \"python3 freedata_server/server.py\"\n        my_env = os.environ.copy()\n        my_env[\"FREEDATA_CONFIG\"] = \"freedata_server/config.ini.example\"\n        cls.process = Popen(shlex.split(cmd), stdin=PIPE, env=my_env)\n        cls.wait_for_server(cls.url)\n        time.sleep(5)\n\n    @classmethod\n    def wait_for_server(cls, url, timeout=30):\n        \"\"\"Wait for the server to start\"\"\"\n        start_time = time.time()\n        while time.time() - start_time < timeout:\n            try:\n                r = requests.get(url)\n                if r.status_code == 200:\n                    return True\n            except requests.exceptions.ConnectionError:\n                time.sleep(1)\n        raise RuntimeError(\"Server not ready after waiting for 30 seconds\")\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.process.stdin.close()\n        cls.process.terminate()\n        cls.process.wait()\n\n    def test_index(self):\n        r = requests.get(self.url)\n        self.assertEqual(r.status_code, 200)\n\n        data = r.json()\n        self.assertEqual(data['api_version'], 3)\n\n    def test_config_get(self):\n        r = requests.get(self.url + '/config')\n        self.assertEqual(r.status_code, 200)\n\n        config = r.json()\n        self.assertIsInstance(config, dict)\n\n        self.assertIn('NETWORK', config)\n        self.assertIn('STATION', config)\n        self.assertIn('AUDIO', config)\n        self.assertIn('MODEM', config)\n        self.assertIn('TCI', config)\n        self.assertIn('RADIO', config)\n\n    def test_config_post(self):\n        config = {'STATION': {'mygrid' : 'JN48ea'}}\n        r = requests.post(self.url + '/config', \n                          headers={'Content-type': 'application/json'},\n                          data = json.dumps(config))\n        self.assertEqual(r.status_code, 200)\n\n        r = requests.get(self.url + '/config')\n        self.assertEqual(r.status_code, 200)\n        config = r.json()\n        self.assertEqual(config['NETWORK']['modemport'], 5000)\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_protocols.py", "content": "import sys\nsys.path.append('freedata_server')\n\nimport unittest\nfrom config import CONFIG\nfrom frame_dispatcher import DISPATCHER\nimport helpers\nimport queue\nfrom state_manager import StateManager\nfrom event_manager import EventManager\nfrom command_ping import PingCommand\nfrom command_cq import CQCommand\nimport modem\nimport frame_handler\nfrom radio_manager import RadioManager\n\nclass TestProtocols(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        config_manager = CONFIG('freedata_server/config.ini.example')\n        cls.config = config_manager.read()\n\n        cls.state_manager_queue = queue.Queue()\n        cls.state_manager = StateManager(cls.state_manager_queue)\n\n        cls.event_queue = queue.Queue()\n        cls.event_manager = EventManager([cls.event_queue])\n\n        cls.radio_manager = RadioManager(cls.config, cls.state_manager, cls.event_manager)\n        cls.modem_transmit_queue = queue.Queue()\n\n        cls.modem = modem.RF(cls.config, cls.event_queue, queue.Queue(), queue.Queue(), cls.state_manager, cls.radio_manager)\n        modem.TESTMODE = True\n        frame_handler.TESTMODE = True\n\n        #cls.freedata_server.start_modem()\n        cls.frame_dispatcher = DISPATCHER(cls.config, \n                                          cls.event_manager,\n                                          cls.state_manager,\n                                          cls.modem)\n\n    def shortcutTransmission(self, frame_bytes):\n        self.frame_dispatcher.process_data(frame_bytes, None, len(frame_bytes), 0, 0, mode_name=\"TEST\")\n\n    def assertEventReceivedType(self, event_type):\n        ev = self.event_queue.get()\n        self.assertIn('type', ev)\n        self.assertIn('received', ev)\n        self.assertEqual(ev['received'], event_type)\n\n    def testPingWithAck(self):\n        # Run ping command\n        api_params = { \"dxcall\": \"AA1AAA-1\"}\n        ping_cmd = PingCommand(self.config, self.state_manager, self.event_manager, api_params)\n        #ping_cmd.run(self.event_queue, self.freedata_server)\n        frame = ping_cmd.test(self.event_queue)\n        # Shortcut the transmit queue directly to the frame dispatcher\n        self.shortcutTransmission(frame)\n        self.assertEventReceivedType('PING')\n\n        event_frame = self.event_queue.get()\n        # Check ACK\n        self.shortcutTransmission(event_frame)\n        self.assertEventReceivedType('PING_ACK')\n        print(\"PING/PING ACK CHECK SUCCESSFULLY\")\n\n    def testCQWithQRV(self):\n        self.config['STATION']['respond_to_cq'] = True\n        self.state_manager.set_channel_busy_condition_codec2(False)\n\n        api_params = {}\n        cmd = CQCommand(self.config, self.state_manager, self.event_manager, api_params)\n        #cmd.run(self.event_queue, self.freedata_server)\n        frame = cmd.test(self.event_queue)\n\n        self.shortcutTransmission(frame)\n        self.assertEventReceivedType('CQ')\n\n        event_frame = self.event_queue.get()\n        # Check QRV\n        self.shortcutTransmission(event_frame)\n        self.assertEventReceivedType('QRV')\n        print(\"CQ/QRV CHECK SUCCESSFULLY\")\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_message_database.py", "content": "import sys\nsys.path.append('freedata_server')\nimport numpy as np\n\nimport unittest\nfrom config import CONFIG\nfrom message_p2p import MessageP2P\nfrom message_system_db_manager import DatabaseManager\nfrom message_system_db_messages import DatabaseManagerMessages\nfrom message_system_db_attachments import DatabaseManagerAttachments\n\nfrom event_manager import EventManager\nimport queue\nimport base64\n\nclass TestDataFrameFactory(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        config_manager = CONFIG('freedata_server/config.ini.example')\n        cls.config = config_manager.read()\n\n        cls.event_queue = queue.Queue()\n        cls.event_manager = EventManager([cls.event_queue])\n        cls.mycall = f\"{cls.config['STATION']['mycall']}-{cls.config['STATION']['myssid']}\"\n        cls.database_manager = DatabaseManagerMessages(cls.event_manager)\n        cls.database_manager_attachments = DatabaseManagerAttachments(cls.event_manager)\n\n    def testAddToDatabase(self):\n        attachment = {\n            'name': 'test.gif',\n            'type': 'image/gif',\n            'data': str(base64.b64encode(np.random.bytes(1024)), 'utf-8')\n        }\n        apiParams = {'destination': 'DJ2LS-3', 'body': 'Hello World!', 'attachments': [attachment]}\n        message = MessageP2P.from_api_params(self.mycall, apiParams)\n        payload = message.to_payload()\n        received_message = MessageP2P.from_payload(payload)\n        received_message_dict = MessageP2P.to_dict(received_message)\n        self.database_manager.add_message(received_message_dict, statistics={})\n        result = self.database_manager.get_message_by_id(message.id)\n\n        self.assertEqual(result[\"destination\"], message.destination)\n\n    def testDeleteFromDatabase(self):\n        attachment = {\n            'name': 'test.gif',\n            'type': 'image/gif',\n            'data': str(base64.b64encode(np.random.bytes(1024)), 'utf-8')\n        }\n        apiParams = {'destination': 'DJ2LS-3', 'body': 'Hello World!', 'attachments': [attachment]}\n        message = MessageP2P.from_api_params(self.mycall, apiParams)\n        payload = message.to_payload()\n        received_message = MessageP2P.from_payload(payload)\n        received_message_dict = MessageP2P.to_dict(received_message)\n        self.database_manager.add_message(received_message_dict, statistics={})\n\n        result = self.database_manager.get_all_messages()\n        message_id = result[0][\"id\"]\n        self.database_manager.delete_message(message_id)\n\n        result = self.database_manager.get_all_messages()\n        self.assertNotIn(message_id, result)\n\n    def testUpdateMessage(self):\n        attachment = {\n            'name': 'test.gif',\n            'type': 'image/gif',\n            'data': str(base64.b64encode(np.random.bytes(1024)), 'utf-8')\n        }\n\n        apiParams = {'destination': 'DJ2LS-3', 'body': 'Hello World!', 'attachments': [attachment]}\n        message = MessageP2P.from_api_params(self.mycall, apiParams)\n        payload = message.to_payload()\n        received_message = MessageP2P.from_payload(payload)\n        received_message_dict = MessageP2P.to_dict(received_message)\n        print(received_message_dict)\n        message_id = self.database_manager.add_message(received_message_dict, statistics={}, direction='receive')\n        print(message_id)\n        self.database_manager.update_message(message_id, {'body' : 'hello123'})\n\n        result = self.database_manager.get_message_by_id(message_id)\n        self.assertIn('hello123', result['body'])\n\n    def testGetAttachments(self):\n        attachment1 = {\n            'name': 'test1.gif',\n            'type': 'image/gif',\n            'data': str(base64.b64encode(np.random.bytes(1024)), 'utf-8')\n        }\n        attachment2 = {\n            'name': 'test2.gif',\n            'type': 'image/gif',\n            'data': str(base64.b64encode(np.random.bytes(1024)), 'utf-8')\n        }\n        attachment3 = {\n            'name': 'test3.gif',\n            'type': 'image/gif',\n            'data': str(base64.b64encode(np.random.bytes(1024)), 'utf-8')\n        }\n        apiParams = {'destination': 'DJ2LS-3', 'body': 'Hello World!', 'attachments': [attachment1, attachment2, attachment3]}\n        message = MessageP2P.from_api_params(self.mycall, apiParams)\n        payload = message.to_payload()\n        received_message = MessageP2P.from_payload(payload)\n        received_message_dict = MessageP2P.to_dict(received_message)\n        message_id = self.database_manager.add_message(received_message_dict, statistics={})\n        result = self.database_manager_attachments.get_attachments_by_message_id(message_id)\n        attachment_names = [attachment['name'] for attachment in result]\n        self.assertIn('test1.gif', attachment_names)\n        self.assertIn('test2.gif', attachment_names)\n        self.assertIn('test3.gif', attachment_names)\n\n    def testIncrementAttempts(self):\n        apiParams = {'destination': 'DJ2LS-3', 'body': 'Hello World!', 'attachments': []}\n        message = MessageP2P.from_api_params(self.mycall, apiParams)\n        payload = message.to_payload()\n        received_message = MessageP2P.from_payload(payload)\n        received_message_dict = MessageP2P.to_dict(received_message)\n        message_id = self.database_manager.add_message(received_message_dict,statistics={},)\n        self.database_manager.increment_message_attempts(message_id)\n        result = self.database_manager.get_message_by_id(message_id)\n        self.assertEqual(result[\"attempt\"], 1)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_data_type_handler.py", "content": "import sys\nsys.path.append('freedata_server')\n\nimport unittest\nimport queue\nfrom arq_data_type_handler import ARQDataTypeHandler, ARQ_SESSION_TYPES\nfrom event_manager import EventManager\nfrom state_manager import StateManager\n\nclass TestDispatcher(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        cls.event_queue = queue.Queue()\n        cls.state_queue = queue.Queue()\n        cls.event_manager = EventManager([cls.event_queue])\n        cls.state_manager = StateManager([cls.state_queue])\n        cls.arq_data_type_handler = ARQDataTypeHandler(cls.event_manager, cls.state_manager)\n\n\n    def testDataTypeHevent_managerandlerRaw(self):\n        # Example usage\n        example_data = b\"Hello FreeDATA!\"\n        formatted_data, type_byte = self.arq_data_type_handler.prepare(example_data, ARQ_SESSION_TYPES.raw)\n        dispatched_data = self.arq_data_type_handler.dispatch(type_byte, formatted_data, statistics={})\n        self.assertEqual(example_data, dispatched_data)\n\n    def testDataTypeHandlerLZMA(self):\n        # Example usage\n        example_data = b\"Hello FreeDATA!\"\n        formatted_data, type_byte = self.arq_data_type_handler.prepare(example_data, ARQ_SESSION_TYPES.raw_lzma)\n        dispatched_data = self.arq_data_type_handler.dispatch(type_byte, formatted_data, statistics={})\n        self.assertEqual(example_data, dispatched_data)\n\n    def testDataTypeHandlerGZIP(self):\n        # Example usage\n        example_data = b\"Hello FreeDATA!\"\n        formatted_data, type_byte = self.arq_data_type_handler.prepare(example_data, ARQ_SESSION_TYPES.raw_gzip)\n        dispatched_data = self.arq_data_type_handler.dispatch(type_byte, formatted_data, statistics={})\n        self.assertEqual(example_data, dispatched_data)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_message_protocol.py", "content": "import sys\nimport time\n\nsys.path.append('freedata_server')\n\nimport unittest\nimport unittest.mock\nfrom config import CONFIG\nimport helpers\nimport queue\nimport threading\nimport base64\nfrom command_arq_raw import ARQRawCommand\nfrom state_manager import StateManager\nfrom frame_dispatcher import DISPATCHER\nimport random\nimport structlog\nimport numpy as np\nfrom event_manager import EventManager\nfrom state_manager import StateManager\nfrom data_frame_factory import DataFrameFactory\nimport codec2\nimport arq_session_irs\nfrom api.command_helpers import enqueue_tx_command\nimport command_message_send\n\n\nclass TestModem:\n    def __init__(self, event_q, state_q):\n        self.data_queue_received = queue.Queue()\n        self.demodulator = unittest.mock.Mock()\n        self.event_manager = EventManager([event_q])\n        self.logger = structlog.get_logger('Modem')\n        self.states = StateManager(state_q)\n\n    def getFrameTransmissionTime(self, mode):\n        samples = 0\n        c2instance = codec2.open_instance(mode.value)\n        samples += codec2.api.freedv_get_n_tx_preamble_modem_samples(c2instance)\n        samples += codec2.api.freedv_get_n_tx_modem_samples(c2instance)\n        samples += codec2.api.freedv_get_n_tx_postamble_modem_samples(c2instance)\n        time = samples / 8000\n        return time\n\n    def transmit(self, mode, repeats: int, repeat_delay: int, frames: bytearray) -> bool:\n        # Simulate transmission time\n        tx_time = self.getFrameTransmissionTime(mode) + 0.1  # PTT\n        self.logger.info(f\"TX {tx_time} seconds...\")\n        threading.Event().wait(tx_time)\n\n        transmission = {\n            'mode': mode,\n            'bytes': frames,\n        }\n        self.data_queue_received.put(transmission)\n\n\nclass TestMessageProtocol(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        config_manager = CONFIG('freedata_server/config.ini.example')\n        cls.config = config_manager.read()\n        cls.logger = structlog.get_logger(\"TESTS\")\n        cls.frame_factory = DataFrameFactory(cls.config)\n\n        # ISS\n        cls.iss_state_manager = StateManager(queue.Queue())\n        cls.iss_state_manager.set_channel_busy_condition_codec2(False)\n\n        cls.iss_event_manager = EventManager([queue.Queue()])\n        cls.iss_event_queue = queue.Queue()\n        cls.iss_state_queue = queue.Queue()\n        cls.iss_modem = TestModem(cls.iss_event_queue, cls.iss_state_queue)\n        cls.iss_frame_dispatcher = DISPATCHER(cls.config,\n                                              cls.iss_event_manager,\n                                              cls.iss_state_manager,\n                                              cls.iss_modem)\n\n        # IRS\n        cls.irs_state_manager = StateManager(queue.Queue())\n        cls.irs_event_manager = EventManager([queue.Queue()])\n        cls.irs_event_queue = queue.Queue()\n        cls.irs_state_queue = queue.Queue()\n        cls.irs_modem = TestModem(cls.irs_event_queue, cls.irs_state_queue)\n        cls.irs_frame_dispatcher = DISPATCHER(cls.config,\n                                              cls.irs_event_manager,\n                                              cls.irs_state_manager,\n                                              cls.irs_modem)\n\n        # Frame loss probability in %\n        cls.loss_probability = 30\n\n        cls.channels_running = True\n\n    def channelWorker(self, modem_transmit_queue: queue.Queue, frame_dispatcher: DISPATCHER):\n        while self.channels_running:\n            # Transfer data between both parties\n            try:\n                transmission = modem_transmit_queue.get(timeout=1)\n                transmission[\"bytes\"] += bytes(2)  # simulate 2 bytes crc checksum\n                if random.randint(0, 100) < self.loss_probability:\n                    self.logger.info(f\"[{threading.current_thread().name}] Frame lost...\")\n                    continue\n\n                frame_bytes = transmission['bytes']\n                if len(frame_bytes) == 5:\n                    mode_name = \"SIGNALLING_ACK\"\n                else:\n                    mode_name = None\n                frame_dispatcher.process_data(frame_bytes, None, len(frame_bytes), 0, 0, mode_name=mode_name)\n            except queue.Empty:\n                continue\n        self.logger.info(f\"[{threading.current_thread().name}] Channel closed.\")\n\n    def waitForSession(self, q, outbound=False):\n        key = 'arq-transfer-outbound' if outbound else 'arq-transfer-inbound'\n        while True and self.channels_running:\n            ev = q.get()\n            if key in ev and ('success' in ev[key] or 'ABORTED' in ev[key]):\n                self.logger.info(f\"[{threading.current_thread().name}] {key} session ended.\")\n                break\n\n    def establishChannels(self):\n        self.channels_running = True\n        self.iss_to_irs_channel = threading.Thread(target=self.channelWorker,\n                                                   args=[self.iss_modem.data_queue_received,\n                                                         self.irs_frame_dispatcher],\n                                                   name=\"ISS to IRS channel\")\n        self.iss_to_irs_channel.start()\n\n        self.irs_to_iss_channel = threading.Thread(target=self.channelWorker,\n                                                   args=[self.irs_modem.data_queue_received,\n                                                         self.iss_frame_dispatcher],\n                                                   name=\"IRS to ISS channel\")\n        self.irs_to_iss_channel.start()\n\n    def waitAndCloseChannels(self):\n        self.waitForSession(self.iss_event_queue, True)\n        self.channels_running = False\n        self.waitForSession(self.irs_event_queue, False)\n        self.channels_running = False\n\n    def testMessageViaSession(self):\n        # set Packet Error Rate (PER) / frame loss probability\n        self.loss_probability = 0\n\n        self.establishChannels()\n        params = {\n            'destination': \"AA1AAA-1\",\n            'body': 'Hello World',\n        }\n\n        cmd_class = command_message_send.SendMessageCommand\n        command = cmd_class(self.config, self.iss_state_manager, self.iss_event_manager, params)\n        command.run(self.iss_event_manager, self.iss_modem)\n\n        self.waitAndCloseChannels()\n\n\n\n"}
{"type": "test_file", "path": "tests/test_config.py", "content": "import sys\nsys.path.append('freedata_server')\nimport unittest\nimport config\n\nclass TestConfigMethods(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        cls.config = config.CONFIG('freedata_server/config.ini.example')\n\n    def test_config_exists(self):\n        c = config.CONFIG('freedata_server/config.ini.example')\n        self.assertTrue(c.config_exists())\n\n        #c = config.CONFIG('freedata_server/nonexistant')\n        #self.assertFalse(c.config_exists())\n\n    def test_read(self):\n        data = self.config.read()\n        self.assertIsInstance(data, dict)\n\n        self.assertIn('STATION', data.keys())\n        self.assertIn('AUDIO', data.keys())\n        self.assertIn('RADIO', data.keys())\n\n    def test_write(self):\n        c = self.config.read()       \n        oldcall = c['STATION']['mycall']\n        newcall = 'T1CALL'\n        self.assertNotEqual(oldcall, newcall)\n\n        c['STATION']['mycall'] = newcall\n        new_conf = self.config.write(c)        \n        self.assertEqual(new_conf['STATION']['mycall'], newcall)\n        c = self.config.read()       \n        self.assertEqual(c['STATION']['mycall'], newcall)\n\n        # put it back as it was\n        c['STATION']['mycall'] = oldcall\n        last_conf = self.config.write(c)\n        self.assertEqual(last_conf['STATION']['mycall'], oldcall)\n\n    def test_validate_data(self):\n        data = {'STATION': {'ssid_list': \"abc\"}}\n        with self.assertRaises(ValueError):\n            self.config.validate_data(data)\n\n        data = {'STATION': {'ssid_list': [1, 2, 3]}}\n        self.assertIsNone(self.config.validate_data(data))\n        \n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/test_p2p_connection.py", "content": "import sys\nimport time\n\nsys.path.append('freedata_server')\n\nimport unittest\nimport unittest.mock\nfrom config import CONFIG\nimport helpers\nimport queue\nimport threading\nimport base64\nfrom command_p2p_connection import P2PConnectionCommand\nfrom state_manager import StateManager\nfrom frame_dispatcher import DISPATCHER\nimport random\nimport structlog\nimport numpy as np\nfrom event_manager import EventManager\nfrom state_manager import StateManager\nfrom data_frame_factory import DataFrameFactory\nimport codec2\nimport p2p_connection\n\nfrom socket_interface_commands import SocketCommandHandler\n\nclass TestModem:\n    def __init__(self, event_q, state_q):\n        self.data_queue_received = queue.Queue()\n        self.demodulator = unittest.mock.Mock()\n        self.event_manager = EventManager([event_q])\n        self.logger = structlog.get_logger('Modem')\n        self.states = StateManager(state_q)\n\n    def getFrameTransmissionTime(self, mode):\n        samples = 0\n        c2instance = codec2.open_instance(mode.value)\n        samples += codec2.api.freedv_get_n_tx_preamble_modem_samples(c2instance)\n        samples += codec2.api.freedv_get_n_tx_modem_samples(c2instance)\n        samples += codec2.api.freedv_get_n_tx_postamble_modem_samples(c2instance)\n        time = samples / 8000\n        return time\n\n    def transmit(self, mode, repeats: int, repeat_delay: int, frames: bytearray) -> bool:\n        # Simulate transmission time\n        tx_time = self.getFrameTransmissionTime(mode) + 0.1  # PTT\n        self.logger.info(f\"TX {tx_time} seconds...\")\n        threading.Event().wait(tx_time)\n\n        transmission = {\n            'mode': mode,\n            'bytes': frames,\n        }\n        self.data_queue_received.put(transmission)\n\n\nclass TestP2PConnectionSession(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        config_manager = CONFIG('freedata_server/config.ini.example')\n        cls.config = config_manager.read()\n        cls.logger = structlog.get_logger(\"TESTS\")\n        cls.frame_factory = DataFrameFactory(cls.config)\n\n        # ISS\n        cls.iss_config_manager = config_manager\n        cls.iss_state_manager = StateManager(queue.Queue())\n        cls.iss_event_manager = EventManager([queue.Queue()])\n        cls.iss_event_queue = queue.Queue()\n        cls.iss_state_queue = queue.Queue()\n        cls.iss_p2p_data_queue = queue.Queue()\n\n\n        cls.iss_modem = TestModem(cls.iss_event_queue, cls.iss_state_queue)\n        cls.iss_frame_dispatcher = DISPATCHER(cls.config,\n                                              cls.iss_event_manager,\n                                              cls.iss_state_manager,\n                                              cls.iss_modem)\n\n        #cls.iss_socket_interface_handler = SocketInterfaceHandler(cls.iss_modem, cls.iss_config_manager, cls.iss_state_manager, cls.iss_event_manager)\n        #cls.iss_socket_command_handler = CommandSocket(TestSocket(), '127.0.0.1', 51234)\n\n        # IRS\n        cls.irs_state_manager = StateManager(queue.Queue())\n        cls.irs_event_manager = EventManager([queue.Queue()])\n        cls.irs_event_queue = queue.Queue()\n        cls.irs_state_queue = queue.Queue()\n        cls.irs_p2p_data_queue = queue.Queue()\n        cls.irs_modem = TestModem(cls.irs_event_queue, cls.irs_state_queue)\n        cls.irs_frame_dispatcher = DISPATCHER(cls.config,\n                                              cls.irs_event_manager,\n                                              cls.irs_state_manager,\n                                              cls.irs_modem)\n\n        # Frame loss probability in %\n        cls.loss_probability = 30\n\n        cls.channels_running = True\n\n        cls.disconnect_received = False\n\n    def channelWorker(self, modem_transmit_queue: queue.Queue, frame_dispatcher: DISPATCHER):\n        while self.channels_running:\n            # Transfer data between both parties\n            try:\n                transmission = modem_transmit_queue.get(timeout=1)\n                if random.randint(0, 100) < self.loss_probability:\n                    self.logger.info(f\"[{threading.current_thread().name}] Frame lost...\")\n                    continue\n\n                frame_bytes = transmission['bytes']\n                frame_dispatcher.new_process_data(frame_bytes, None, len(frame_bytes), 0, 0)\n            except queue.Empty:\n                continue\n        self.logger.info(f\"[{threading.current_thread().name}] Channel closed.\")\n\n    def waitForSession(self, q, outbound=False):\n        while True and self.channels_running:\n            ev = q.get()\n            print(ev)\n            if 'P2P_CONNECTION_DISCONNECT_ACK' in ev or self.disconnect_received:\n                self.logger.info(f\"[{threading.current_thread().name}] session ended.\")\n                break\n\n    def establishChannels(self):\n        self.channels_running = True\n        self.iss_to_irs_channel = threading.Thread(target=self.channelWorker,\n                                                   args=[self.iss_modem.data_queue_received,\n                                                         self.irs_frame_dispatcher],\n                                                   name=\"ISS to IRS channel\")\n        self.iss_to_irs_channel.start()\n\n        self.irs_to_iss_channel = threading.Thread(target=self.channelWorker,\n                                                   args=[self.irs_modem.data_queue_received,\n                                                         self.iss_frame_dispatcher],\n                                                   name=\"IRS to ISS channel\")\n        self.irs_to_iss_channel.start()\n\n    def waitAndCloseChannels(self):\n        self.waitForSession(self.iss_event_queue, True)\n        self.channels_running = False\n        self.waitForSession(self.irs_event_queue, False)\n        self.channels_running = False\n\n    def generate_random_string(self, min_length, max_length):\n        import string\n        length = random.randint(min_length, max_length)\n        return ''.join(random.choices(string.ascii_letters, k=length))#\n\n    def DisabledtestARQSessionSmallPayload(self):\n        # set Packet Error Rate (PER) / frame loss probability\n        self.loss_probability = 0\n\n        self.establishChannels()\n\n        handler = SocketCommandHandler(TestSocket(self), self.iss_modem, self.iss_config_manager, self.iss_state_manager, self.iss_event_manager)\n        handler.handle_connect([\"AA1AAA-1\", \"BB2BBB-2\"])\n\n        self.connected_event = threading.Event()\n        self.connected_event.wait()\n\n        for session_id in self.iss_state_manager.p2p_connection_sessions:\n            session = self.iss_state_manager.get_p2p_connection_session(session_id)\n            session.ENTIRE_CONNECTION_TIMEOUT = 15\n            # Generate and add 5 random entries to the queue\n            for _ in range(3):\n                min_length = (30 * _ ) + 1\n                max_length = (30 * _ ) + 1\n                print(min_length)\n                print(max_length)\n                random_entry = self.generate_random_string(min_length, max_length)\n                session.p2p_data_tx_queue.put(random_entry)\n\n            session.p2p_data_tx_queue.put('12345')\n        self.waitAndCloseChannels()\n\n\nclass TestSocket:\n    def __init__(self, test_class):\n        self.sent_data = []  # To capture data sent through this socket\n        self.test_class = test_class\n    def sendall(self, data):\n        print(f\"Mock sendall called with data: {data}\")\n        self.sent_data.append(data)\n        self.event_handler(data)\n\n    def event_handler(self, data):\n        if b'CONNECTED AA1AAA-1 BB2BBB-2 0\\r\\n' in self.sent_data:\n            self.test_class.connected_event.set()\n\n        if b'DISCONNECTED\\r\\n' in self.sent_data:\n            self.disconnect_received = True\n            self.test_class.assertEqual(b'DISCONNECTED\\r\\n', b'DISCONNECTED\\r\\n')\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "source_file", "path": "freedata_server/arq_session_irs.py", "content": "import threading\nimport arq_session\nimport helpers\nfrom modem_frametypes import FRAME_TYPE\nfrom codec2 import FREEDV_MODE\nfrom enum import Enum\nimport time\n\n\nclass IRS_State(Enum):\n    NEW = 0\n    OPEN_ACK_SENT = 1\n    INFO_ACK_SENT = 2\n    BURST_REPLY_SENT = 3\n    ENDED = 4\n    FAILED = 5\n    ABORTED = 6\n    RESUME = 7 # State, which allows resuming of a transmission - will be set after some waiting time, higher than TIMEOUT_DATA for ensuring clean states\n\nclass ARQSessionIRS(arq_session.ARQSession):\n\n    TIMEOUT_CONNECT = 55 #14.2\n    TIMEOUT_DATA = 90\n\n    STATE_TRANSITION = {\n        IRS_State.NEW: { \n            FRAME_TYPE.ARQ_SESSION_OPEN.value : 'send_open_ack',\n            FRAME_TYPE.ARQ_STOP.value: 'send_stop_ack'\n        },\n        IRS_State.OPEN_ACK_SENT: { \n            FRAME_TYPE.ARQ_SESSION_OPEN.value: 'send_open_ack',\n            FRAME_TYPE.ARQ_SESSION_INFO.value: 'send_info_ack',\n            FRAME_TYPE.ARQ_STOP.value: 'send_stop_ack'\n\n        },\n        IRS_State.INFO_ACK_SENT: {\n            FRAME_TYPE.ARQ_SESSION_INFO.value: 'send_info_ack',\n            FRAME_TYPE.ARQ_BURST_FRAME.value: 'receive_data',\n            FRAME_TYPE.ARQ_STOP.value: 'send_stop_ack'\n\n        },\n        IRS_State.BURST_REPLY_SENT: {\n            FRAME_TYPE.ARQ_BURST_FRAME.value: 'receive_data',\n            FRAME_TYPE.ARQ_STOP.value: 'send_stop_ack'\n\n        },\n        IRS_State.ENDED: {\n            FRAME_TYPE.ARQ_BURST_FRAME.value: 'receive_data',\n            FRAME_TYPE.ARQ_STOP.value: 'send_stop_ack'\n\n        },\n        IRS_State.FAILED: {\n            FRAME_TYPE.ARQ_BURST_FRAME.value: 'receive_data',\n            #FRAME_TYPE.ARQ_SESSION_OPEN.value: 'send_open_ack',\n        },\n        IRS_State.ABORTED: {\n            FRAME_TYPE.ARQ_STOP.value: 'send_stop_ack',\n            #FRAME_TYPE.ARQ_SESSION_OPEN.value: 'send_open_ack',\n            #FRAME_TYPE.ARQ_SESSION_INFO.value: 'send_info_ack',\n            #FRAME_TYPE.ARQ_BURST_FRAME.value: 'receive_data',\n        },\n        IRS_State.RESUME: {\n            FRAME_TYPE.ARQ_SESSION_OPEN.value: 'send_open_ack',\n        }\n\n\n\n    }\n\n    def __init__(self, config: dict, modem, dxcall: str, session_id: int, state_manager):\n        super().__init__(config, modem, dxcall, state_manager)\n\n        self.id = session_id\n        self.dxcall = dxcall\n        self.version = 1\n        self.is_IRS = True\n\n        self.state = IRS_State.NEW\n        self.state_enum = IRS_State  # needed for access State enum from outside\n\n        self.type_byte = None\n        self.total_length = 0\n        self.total_crc = ''\n        self.received_data = None\n        self.received_bytes = 0\n        self.received_crc = None\n\n        self.maximum_bandwidth = 0\n\n        self.abort = False\n\n    def all_data_received(self):\n        print(f\"{self.total_length} vs {self.received_bytes}\")\n        return self.total_length == self.received_bytes\n\n    def final_crc_matches(self) -> bool:\n        return self.total_crc == helpers.get_crc_32(bytes(self.received_data)).hex()\n\n    def transmit_and_wait(self, frame, timeout, mode):\n        self.event_frame_received.clear()\n        self.transmit_frame(frame, mode)\n        self.log(f\"Waiting {timeout} seconds...\")\n        if not self.event_frame_received.wait(timeout) and self.state not in [IRS_State.ABORTED, IRS_State.FAILED]:\n            self.log(\"Timeout waiting for ISS. Session failed.\")\n            self.transmission_failed()\n\n    def launch_transmit_and_wait(self, frame, timeout, mode):\n        thread_wait = threading.Thread(target = self.transmit_and_wait, \n                                       args = [frame, timeout, mode], daemon=True)\n        thread_wait.start()\n    \n    def send_open_ack(self, open_frame):\n        # check for maximum bandwidth. If ISS bandwidth is higher than own, then use own\n        if open_frame['maximum_bandwidth'] > self.config['MODEM']['maximum_bandwidth']:\n            self.maximum_bandwidth = self.config['MODEM']['maximum_bandwidth']\n        else:\n            self.maximum_bandwidth = open_frame['maximum_bandwidth']\n        self.log(f\"Negotiated transmission bandwidth {self.maximum_bandwidth}Hz\")\n\n        self.event_manager.send_arq_session_new(\n            False, self.id, self.dxcall, 0, self.state.name)\n\n        if open_frame['protocol_version'] not in [self.protocol_version]:\n            self.abort = True\n            self.log(f\"Protocol version mismatch! Setting disconnect flag!\", isWarning=True)\n            self.set_state(IRS_State.ABORTED)\n\n        ack_frame = self.frame_factory.build_arq_session_open_ack(\n            self.id,\n            self.dxcall, \n            self.version,\n            self.snr, flag_abort=self.abort)\n\n        self.launch_transmit_and_wait(ack_frame, self.TIMEOUT_CONNECT, mode=FREEDV_MODE.signalling)\n        if not self.abort:\n            self.set_state(IRS_State.OPEN_ACK_SENT)\n        return None, None\n\n    def send_info_ack(self, info_frame):\n        # Get session info from ISS\n        if self.received_bytes == 0:\n            self.received_data = bytearray(info_frame['total_length'])\n        self.total_length = info_frame['total_length']\n        self.total_crc = info_frame['total_crc']\n        self.dx_snr.append(info_frame['snr'])\n        self.type_byte = info_frame['type']\n\n        self.calibrate_speed_settings()\n\n        self.log(f\"New transfer of {self.total_length} bytes, received_bytes: {self.received_bytes}\")\n        self.event_manager.send_arq_session_new(False, self.id, self.dxcall, self.total_length, self.state.name)\n\n        info_ack = self.frame_factory.build_arq_session_info_ack(\n            self.id, self.received_bytes, self.snr,\n            self.speed_level, self.frames_per_burst, flag_abort=self.abort)\n        self.launch_transmit_and_wait(info_ack, self.TIMEOUT_CONNECT, mode=FREEDV_MODE.signalling)\n        if not self.abort:\n            self.set_state(IRS_State.INFO_ACK_SENT)\n        return None, None\n\n    def process_incoming_data(self, frame):\n        if frame['offset'] != self.received_bytes:\n            # TODO: IF WE HAVE AN OFFSET BECAUSE OF A SPEED LEVEL CHANGE FOR EXAMPLE,\n            # TODO: WE HAVE TO DISCARD THE LAST BYTES, BUT NOT returning False!!\n            # CASE: ACK is going lost.\n            self.log(f\"Discarding data offset: Offset = {frame['offset']} | Already received: {self.received_bytes}\", isWarning=True)\n            self.received_bytes = frame['offset']\n\n            #return False\n\n        remaining_data_length = self.total_length - self.received_bytes\n        self.log(f\"Remaining data: {remaining_data_length}\", isWarning=True)\n        # Is this the last data part?\n        if remaining_data_length <= len(frame['data']):\n            # we only want the remaining length, not the entire frame data\n            data_part = frame['data'][:remaining_data_length]\n        else:\n            # we want the entire frame data\n            data_part = frame['data']\n\n        self.received_data[frame['offset']:] = data_part\n        #self.received_bytes += len(data_part)\n        self.received_bytes = len(self.received_data)\n        self.log(f\"Received {self.received_bytes}/{self.total_length} bytes\")\n        self.event_manager.send_arq_session_progress(\n            False, self.id, self.dxcall, self.received_bytes, self.total_length, self.state.name, self.speed_level, self.calculate_session_statistics(self.received_bytes, self.total_length))\n\n        return True\n\n    def receive_data(self, burst_frame):\n        self.process_incoming_data(burst_frame)\n        # update statistics\n        self.update_histograms(self.received_bytes, self.total_length)\n        \n        if not self.all_data_received():\n            self.calibrate_speed_settings(burst_frame=burst_frame)\n            ack = self.frame_factory.build_arq_burst_ack(\n                self.id,\n                self.speed_level,\n                flag_abort=self.abort\n            )\n\n            self.set_state(IRS_State.BURST_REPLY_SENT)\n            self.event_manager.send_arq_session_progress(False, self.id, self.dxcall, self.received_bytes,\n                                                         self.total_length, self.state.name, self.speed_level,\n                                                         statistics=self.calculate_session_statistics(\n                                                             self.received_bytes, self.total_length))\n\n            self.launch_transmit_and_wait(ack, self.TIMEOUT_DATA, mode=FREEDV_MODE.signalling_ack)\n            return None, None\n\n        if self.final_crc_matches():\n            self.log(\"All data received successfully!\")\n            ack = self.frame_factory.build_arq_burst_ack(self.id,\n                                                         self.speed_level,\n                                                         flag_final=True,\n                                                         flag_checksum=True)\n            self.transmit_frame(ack, mode=FREEDV_MODE.signalling_ack)\n            self.log(\"ACK sent\")\n            self.session_ended = time.time()\n            self.set_state(IRS_State.ENDED)\n\n            return self.received_data, self.type_byte\n        else:\n            ack = self.frame_factory.build_arq_burst_ack(self.id,\n                                                         self.speed_level,\n                                                         flag_final=True,\n                                                         flag_checksum=False)\n            self.transmit_frame(ack, mode=FREEDV_MODE.signalling_ack)\n            self.log(\"CRC fail at the end of transmission!\")\n            return self.transmission_failed()\n\n    def calibrate_speed_settings(self, burst_frame=None):\n        if burst_frame:\n            received_speed_level = burst_frame['speed_level']\n        else:\n            received_speed_level = 0\n\n        latest_snr = self.snr if self.snr else -10\n        appropriate_speed_level = self.get_appropriate_speed_level(latest_snr, self.maximum_bandwidth)\n        modes_to_decode = {}\n\n        # Log the latest SNR, current, appropriate speed levels, and the previous speed level\n        self.log(\n            f\"Latest SNR: {latest_snr}, Current Speed Level: {self.speed_level}, Appropriate Speed Level: {appropriate_speed_level}, Previous Speed Level: {self.previous_speed_level}\",\n            isWarning=True)\n\n        # Adjust the speed level by one step towards the appropriate level, if needed\n        #if appropriate_speed_level > self.speed_level and self.speed_level < len(self.SPEED_LEVEL_DICT) - 1:\n        #    # we need to ensure, the received data is equal to our speed level before changing it\n        #    if received_speed_level == self.speed_level:\n        #        self.speed_level += 1\n        #elif appropriate_speed_level < self.speed_level and self.speed_level > 0:\n        #    #if received_speed_level == self.speed_level:\n        #    #    self.speed_level -= 1\n\n        # Always decode the current mode\n        current_mode = self.get_mode_by_speed_level(self.speed_level).value\n        modes_to_decode[current_mode] = True\n\n        # Update previous speed level\n        if self.previous_speed_level != self.speed_level:\n            self.previous_speed_level = self.speed_level  # Update the previous speed level\n\n        # Ensure, previous mode is decoded as well\n        previous_mode = self.get_mode_by_speed_level(self.previous_speed_level).value\n        modes_to_decode[previous_mode] = True\n\n        # Ensure, appropriate mode is decoded as well\n        appropriate_mode = self.get_mode_by_speed_level(appropriate_speed_level).value\n        modes_to_decode[appropriate_mode] = True\n\n        self.log(f\"Modes to Decode: {list(modes_to_decode.keys())}\", isWarning=True)\n        # Apply the new decode mode based on the updated and previous speed levels\n        self.modem.demodulator.set_decode_mode(modes_to_decode)\n\n        # finally update the speed level to the appropriate one\n        self.speed_level = appropriate_speed_level\n\n        return self.speed_level\n\n    def abort_transmission(self):\n        self.log(\"Aborting transmission... setting abort flag\")\n        self.abort = True\n\n    def send_stop_ack(self, stop_frame):\n        stop_ack = self.frame_factory.build_arq_stop_ack(self.id)\n        self.launch_transmit_and_wait(stop_ack, self.TIMEOUT_CONNECT, mode=FREEDV_MODE.signalling_ack)\n        self.set_state(IRS_State.ABORTED)\n        self.states.setARQ(False)\n        session_stats = self.calculate_session_statistics(self.received_bytes, self.total_length)\n\n        self.event_manager.send_arq_session_finished(\n                False, self.id, self.dxcall, False, self.state.name, statistics=session_stats)\n        if self.config['STATION']['enable_stats']:\n            self.statistics.push(self.state.name, session_stats, self.dxcall)\n\n        return None, None\n\n    def transmission_failed(self, irs_frame=None):\n        # final function for failed transmissions\n        self.session_ended = time.time()\n        self.set_state(IRS_State.FAILED)\n        self.log(\"Transmission failed!\")\n        #self.modem.demodulator.set_decode_mode()\n        session_stats = self.calculate_session_statistics(self.received_bytes, self.total_length)\n\n        self.event_manager.send_arq_session_finished(True, self.id, self.dxcall,False, self.state.name, statistics=session_stats)\n        if self.config['STATION']['enable_stats']:\n            self.statistics.push(self.state.name, session_stats, self.dxcall)\n\n        self.states.setARQ(False)\n        return None, None\n\n    def transmission_aborted(self):\n        self.log(\"session aborted\")\n        self.session_ended = time.time()\n        self.set_state(IRS_State.ABORTED)\n        # break actual retries\n        self.event_frame_received.set()\n\n\n        #self.modem.demodulator.set_decode_mode()\n        self.event_manager.send_arq_session_finished(\n            True, self.id, self.dxcall, False, self.state.name, statistics=self.calculate_session_statistics(self.received_bytes, self.total_length))\n        self.states.setARQ(False)\n        return None, None"}
{"type": "source_file", "path": "freedata_gui/src/assets/waterfall/make_colormap.py", "content": "#!/usr/bin/env python\n\nimport matplotlib.pyplot as plt\n\ncolormaps = ('viridis', 'inferno', 'magma', 'jet', 'binary')\nfor c in colormaps:\n    cmap_name = c\n    cmap = plt.get_cmap(cmap_name)\n\n    colors = [[int(round(255 * x)) for x in cmap(i)[:3]] for i in range(256)]\n    print(f'var {c} = {colors}')\n\nprint(f'var colormaps = [{\", \".join(colormaps)}];')\n"}
{"type": "source_file", "path": "freedata_server/api/common.py", "content": "from fastapi import HTTPException\nfrom fastapi.responses import JSONResponse\n\n# Returns a standard API response\ndef api_response(data, status=200):\n    return JSONResponse(content=data, status_code=status)\n\n\ndef api_abort(message, code):\n    print(message)\n    raise HTTPException(status_code=code, detail={\"error\": message})\n\n\ndef api_ok(message=\"ok\"):\n    return api_response({'message': message})\n\n\n# Validates a parameter\ndef validate(req, param, validator, is_required=True):\n    if param not in req:\n        if is_required:\n            api_abort(f\"Required parameter '{param}' is missing.\", 400)\n        else:\n            return True\n    if not validator(req[param]):\n        api_abort(f\"Value of '{param}' is invalid.\", 400)\n"}
{"type": "source_file", "path": "freedata_server/api/config.py", "content": "from fastapi import APIRouter, Request\nfrom api.common import api_response, api_abort, api_ok, validate\nimport api_validations as validations\nrouter = APIRouter()\n\n@router.get(\"/\", summary=\"Get Modem Configuration\", tags=[\"Configuration\"], responses={\n    200: {\n        \"description\": \"Current modem configuration settings.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"AUDIO\": {\n                        \"input_device\": \"2fc0\",\n                        \"output_device\": \"3655\",\n                        \"rx_audio_level\": 0,\n                        \"tx_audio_level\": 2\n                    },\n                    \"MESSAGES\": {\n                        \"enable_auto_repeat\": True\n                    },\n                    \"MODEM\": {\n                        \"enable_morse_identifier\": False,\n                        \"enable_socket_interface\": False,\n                        \"maximum_bandwidth\": 2438,\n                        \"tx_delay\": 200\n                    },\n                    \"NETWORK\": {\n                        \"modemaddress\": \"\",\n                        \"modemport\": 5000\n                    },\n                    \"RADIO\": {\n                        \"control\": \"rigctld\",\n                        \"data_bits\": 8,\n                        \"model_id\": 1001,\n                        \"ptt_port\": \"ignore\",\n                        \"ptt_type\": \"USB\",\n                        \"serial_dcd\": \"NONE\",\n                        \"serial_dtr\": \"OFF\",\n                        \"serial_handshake\": \"ignore\",\n                        \"serial_port\": \"/dev/cu.Bluetooth-Incoming-Port\",\n                        \"serial_speed\": 38400,\n                        \"stop_bits\": 1\n                    },\n                    \"RIGCTLD\": {\n                        \"arguments\": \"\",\n                        \"command\": \"\",\n                        \"ip\": \"127.0.0.1\",\n                        \"path\": \"\",\n                        \"port\": 4532\n                    },\n                    \"SOCKET_INTERFACE\": {\n                        \"cmd_port\": 0,\n                        \"data_port\": 0,\n                        \"enable\": False,\n                        \"host\": \"\"\n                    },\n                    \"STATION\": {\n                        \"enable_explorer\": True,\n                        \"enable_stats\": True,\n                        \"mycall\": \"LA3QMA\",\n                        \"mygrid\": \"JP20ql\",\n                        \"myssid\": 0,\n                        \"ssid_list\": [0,1,2,3,4,5,6,7,8,9],\n                        \"respond_to_cq\": True,\n                    },\n                    \"TCI\": {\n                        \"tci_ip\": \"127.0.0.1\",\n                        \"tci_port\": 50001\n                    }\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    }\n})\nasync def get_config(request: Request):\n    \"\"\"\n    Retrieve the current modem configuration.\n\n    Returns:\n        dict: The modem configuration settings.\n    \"\"\"\n    return request.app.config_manager.read()\n\n\n@router.post(\"/\", summary=\"Update Modem Configuration\", tags=[\"Configuration\"], responses={\n    200: {\n        \"description\": \"Modem configuration updated successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"AUDIO\": {\n                        \"input_device\": \"2fc0\",\n                        \"output_device\": \"3655\",\n                        \"rx_audio_level\": 0,\n                        \"tx_audio_level\": 2\n                    },\n                    # ...\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Invalid configuration data.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid config\"\n                }\n            }\n        }\n    },\n    500: {\n        \"description\": \"Error writing configuration.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Error writing config\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    }\n})\nasync def post_config(request: Request):\n    \"\"\"\n    Update the modem configuration with new settings.\n\n    Parameters:\n        request (Request): The HTTP request containing the new configuration in JSON format.\n\n    Returns:\n        dict: The updated modem configuration.\n\n    Raises:\n        HTTPException: If the provided configuration is invalid or an error occurs while writing the config.\n    \"\"\"\n    config = await request.json()\n    print(config)\n    if not validations.validate_remote_config(config):\n        api_abort(\"Invalid config\", 400)\n    if request.app.config_manager.read() == config:\n        return config\n    set_config = request.app.config_manager.write(config)\n    if not set_config:\n        api_abort(\"Error writing config\", 500)\n    request.app.modem_service.put(\"restart\")\n    return set_config\n"}
{"type": "source_file", "path": "freedata_server/api/general.py", "content": "import platform\n\nfrom fastapi import APIRouter, Request\nimport platform\n\n\n\n\nrouter = APIRouter()\n\n@router.get(\"/\", summary=\"API Root\", tags=[\"General\"], responses={\n    200: {\n        \"description\": \"API information.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"name\": \"FreeDATA API\",\n                    \"description\": \"A sample API that provides free data services\",\n                    \"api_version\": 3,\n                    \"modem_version\": \"0.16.8-alpha\",\n                    \"license\": \"GPL3.0\",\n                    \"documentation\": \"https://wiki.freedata.app\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Service unavailable.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Service unavailable.\"\n                }\n            }\n        }\n    }\n})\nasync def index(request: Request):\n    \"\"\"\n    Retrieve API metadata.\n\n    Returns:\n        dict: A JSON object containing API metadata.\n    \"\"\"\n    return {\n        'name': 'FreeDATA API',\n        'description': 'A sample API that provides free data services',\n        'api_version': request.app.API_VERSION,\n        'modem_version': request.app.MODEM_VERSION,\n        'license': \"GPL3.0\",\n        'documentation': \"https://wiki.freedata.app\",\n    }\n\n@router.get(\"/version\", summary=\"Get Modem Version\", tags=[\"General\"], responses={\n    200: {\n        \"description\": \"Successful Response\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"api_version\": 3,\n                    \"modem_version\": \"0.16.8-alpha\",\n                    \"os_info\": {\n                        \"system\": \"Linux\",\n                        \"node\": \"my-node\",\n                        \"release\": \"5.4.0-74-generic\",\n                        \"version\": \"#83-Ubuntu SMP Mon May 10 16:30:51 UTC 2021\",\n                        \"machine\": \"x86_64\",\n                        \"processor\": \"x86_64\"\n                    },\n                    \"python_info\": {\n                        \"build\": [\"default\", \"May  3 2021 19:12:05\"],\n                        \"compiler\": \"GCC 9.3.0\",\n                        \"branch\": \"\",\n                        \"implementation\": \"CPython\",\n                        \"revision\": \"\",\n                        \"version\": \"3.8.5\"\n                    }\n                }\n            }\n        }\n    }\n})\nasync def get_modem_version(request: Request):\n    \"\"\"\n    Retrieve the modem version, API version, OS information, and Python information.\n\n    Returns:\n        dict: A JSON object containing version information.\n    \"\"\"\n    os_info = {\n        'system': platform.system(),\n        'node': platform.node(),\n        'release': platform.release(),\n        'version': platform.version(),\n        'machine': platform.machine(),\n        'processor': platform.processor(),\n    }\n\n    python_info = {\n        'build': platform.python_build(),\n        'compiler': platform.python_compiler(),\n        'branch': platform.python_branch(),\n        'implementation': platform.python_implementation(),\n        'revision': platform.python_revision(),\n        'version': platform.python_version()\n    }\n\n    return {\n        'api_version': request.app.API_VERSION,\n        'modem_version': request.app.MODEM_VERSION,\n        'os_info': os_info,\n        'python_info': python_info\n    }\n"}
{"type": "source_file", "path": "freedata_server/api_validations.py", "content": "import re\n\ndef validate_remote_config(config):\n    if not config:\n        return\n    return True\n\ndef validate_freedata_callsign(callsign):\n    #regexp = \"^[a-zA-Z]+\\d+\\w+-\\d{1,2}$\"\n    regexp = \"^[A-Za-z0-9]{1,7}-[0-9]{1,3}$\" # still broken - we need to allow all ssids form 0 - 255\n    return re.compile(regexp).match(callsign) is not None\n\ndef validate_message_attachment(attachment):\n    for field in ['name', 'type', 'data']:\n        if field not in attachment:\n            raise ValueError(f\"Attachment missing '{field}'\")\n\n        # check for content length, except type\n        # there are some files out there, don't having a mime type\n        if len(attachment[field]) < 1 and field not in [\"type\"]:\n            raise ValueError(f\"Attachment has empty '{field}'\")\n"}
{"type": "source_file", "path": "freedata_server/api/websocket.py", "content": "from fastapi import APIRouter, Request, WebSocket\nrouter = APIRouter()\n\n# WebSocket Event Handlers\n@router.websocket(\"/events\")\nasync def websocket_events(websocket: WebSocket):\n    await websocket.accept()\n    await websocket.app.wsm.handle_connection(websocket, websocket.app.wsm.events_client_list, websocket.app.modem_events)\n\n@router.websocket(\"/fft\")\nasync def websocket_fft(websocket: WebSocket):\n    await websocket.accept()\n    await websocket.app.wsm.handle_connection(websocket, websocket.app.wsm.fft_client_list, websocket.app.modem_fft)\n\n@router.websocket(\"/states\")\nasync def websocket_states(websocket: WebSocket):\n    await websocket.accept()\n    await websocket.app.wsm.handle_connection(websocket, websocket.app.wsm.states_client_list, websocket.app.state_queue)\n"}
{"type": "source_file", "path": "freedata_server/arq_session.py", "content": "import datetime\nimport threading\nimport codec2\nimport data_frame_factory\nimport structlog\nfrom event_manager import EventManager\nfrom modem_frametypes import FRAME_TYPE\nimport time\nfrom arq_data_type_handler import ARQDataTypeHandler\nfrom codec2 import FREEDV_MODE_USED_SLOTS, FREEDV_MODE\nimport stats\nclass ARQSession:\n    SPEED_LEVEL_DICT = {\n        0: {\n            'mode': FREEDV_MODE.datac4,\n            'min_snr': -10,\n            'duration_per_frame': 5.17,\n            'bandwidth': 250,\n            'slots': FREEDV_MODE_USED_SLOTS.datac4,\n        },\n        1: {\n            'mode': FREEDV_MODE.data_ofdm_500,\n            'min_snr': 0,\n            'duration_per_frame': 3.19,\n            'bandwidth': 500,\n            'slots': FREEDV_MODE_USED_SLOTS.data_ofdm_500,\n        },\n        2: {\n            'mode': FREEDV_MODE.datac1,\n            'min_snr': 3,\n            'duration_per_frame': 4.18,\n            'bandwidth': 1700,\n            'slots': FREEDV_MODE_USED_SLOTS.datac1,\n        },\n        3: {\n            'mode': FREEDV_MODE.data_ofdm_2438,\n            'min_snr': 8.5,\n            'duration_per_frame': 5.5,\n            'bandwidth': 2438,\n            'slots': FREEDV_MODE_USED_SLOTS.data_ofdm_2438,\n        },\n        # 4: {\n        #    'mode': FREEDV_MODE.qam16c2,\n        #    'min_snr': 11,\n        #    'duration_per_frame': 2.8,\n        #    'bandwidth': 2438,\n        #    'slots': FREEDV_MODE_USED_SLOTS.qam16c2,\n        # },\n    }\n\n    def __init__(self, config: dict, modem, dxcall: str, state_manager):\n        self.logger = structlog.get_logger(type(self).__name__)\n        self.config = config\n\n        self.event_manager: EventManager = modem.event_manager\n        #self.states = freedata_server.states\n        self.states = state_manager\n        self.states.setARQ(True)\n\n        self.is_IRS = False # state for easy check \"is IRS\" or is \"ISS\"\n\n        self.protocol_version = 1\n\n        self.snr = []\n\n        self.dxcall = dxcall\n        self.dx_snr = []\n\n        self.modem = modem\n        self.speed_level = 0\n        self.previous_speed_level = 0\n\n        self.frames_per_burst = 1\n\n        self.frame_factory = data_frame_factory.DataFrameFactory(self.config)\n        self.event_frame_received = threading.Event()\n\n        self.arq_data_type_handler = ARQDataTypeHandler(self.event_manager, self.states)\n        self.id = None\n        self.session_started = time.time()\n        self.session_ended = 0\n        self.session_max_age = 500\n\n        # this timestamp is updated by \"set_state\", everytime we have a state change.\n        # we will use the schedule manager, for checking, how old is the state change for deciding, how we continue with the message\n        self.last_state_change_timestamp = time.time()\n\n        self.statistics = stats.stats(self.config, self.event_manager, self.states)\n\n        # histogram lists for storing statistics\n        self.snr_histogram = []\n        self.bpm_histogram = []\n        self.bps_histogram = []\n        self.time_histogram = []\n\n    def log(self, message, isWarning=False):\n        msg = f\"[{type(self).__name__}][id={self.id}][state={self.state}]: {message}\"\n        logger = self.logger.warn if isWarning else self.logger.info\n        logger(msg)\n\n    def get_mode_by_speed_level(self, speed_level):\n        return self.SPEED_LEVEL_DICT[speed_level][\"mode\"]\n\n    def transmit_frame(self, frame: bytearray, mode='auto'):\n        self.log(\"Transmitting frame\")\n        if mode in ['auto']:\n            mode = self.get_mode_by_speed_level(self.speed_level)\n\n        self.modem.transmit(mode, 1, 1, frame)\n\n    def set_state(self, state):\n        self.last_state_change_timestamp = time.time()\n        if self.state == state:\n            self.log(f\"{type(self).__name__} state {self.state.name} unchanged.\")\n        else:\n            self.log(f\"{type(self).__name__} state change from {self.state.name} to {state.name} at {self.last_state_change_timestamp}\")\n        self.state = state\n\n    def get_data_payload_size(self):\n        return self.frame_factory.get_available_data_payload_for_mode(\n            FRAME_TYPE.ARQ_BURST_FRAME,\n            self.SPEED_LEVEL_DICT[self.speed_level][\"mode\"]\n            )\n\n    def set_details(self, snr, frequency_offset):\n        self.snr = snr\n        self.frequency_offset = frequency_offset\n\n    def on_frame_received(self, frame):\n        self.event_frame_received.set()\n        self.log(f\"Received {frame['frame_type']}\")\n        frame_type = frame['frame_type_int']\n        if self.state in self.STATE_TRANSITION and frame_type in self.STATE_TRANSITION[self.state]:\n            action_name = self.STATE_TRANSITION[self.state][frame_type]\n            received_data, type_byte = getattr(self, action_name)(frame)\n\n            if isinstance(received_data, bytearray) and isinstance(type_byte, int):\n                self.arq_data_type_handler.dispatch(type_byte, received_data, self.update_histograms(len(received_data), len(received_data)))\n            return\n        \n        self.log(f\"Ignoring unknown transition from state {self.state.name} with frame {frame['frame_type']}\")\n\n    def is_session_outdated(self):\n        session_alivetime = time.time() - self.session_max_age\n        return self.session_ended < session_alivetime and self.state.name in [\n            'FAILED',\n            'ENDED',\n            'ABORTED',\n        ]\n\n    def calculate_session_duration(self):\n        if self.session_ended == 0:\n            return time.time() - self.session_started\n\n        return self.session_ended - self.session_started\n\n    def calculate_session_statistics(self, confirmed_bytes, total_bytes):\n        duration = self.calculate_session_duration()\n        # total_bytes = self.total_length\n        # self.total_length\n        duration_in_minutes = duration / 60  # Convert duration from seconds to minutes\n\n        # Calculate bytes per minute\n        if duration_in_minutes > 0:\n            bytes_per_minute = int(confirmed_bytes / duration_in_minutes)\n        else:\n            bytes_per_minute = 0\n\n        # Calculate bits per second\n        bits_per_second = int((confirmed_bytes * 8) / duration)\n\n\n        # Convert histograms lists to dictionaries\n        time_histogram_dict = dict(enumerate(self.time_histogram))\n        snr_histogram_dict = dict(enumerate(self.snr_histogram))\n        bpm_histogram_dict = dict(enumerate(self.bpm_histogram))\n        bps_histogram_dict = dict(enumerate(self.bps_histogram))\n\n        return {\n            'total_bytes': total_bytes,\n            'duration': duration,\n            'bytes_per_minute': bytes_per_minute,\n            'bits_per_second': bits_per_second,\n            'time_histogram': time_histogram_dict,\n            'snr_histogram': snr_histogram_dict,\n            'bpm_histogram': bpm_histogram_dict,\n            'bps_histogram': bps_histogram_dict,\n        }\n\n    def update_histograms(self, confirmed_bytes, total_bytes):\n\n        stats = self.calculate_session_statistics(confirmed_bytes, total_bytes)\n        self.snr_histogram.append(self.snr)\n        self.bpm_histogram.append(stats['bytes_per_minute'])\n        self.bps_histogram.append(stats['bits_per_second'])\n        self.time_histogram.append(datetime.datetime.now().isoformat())\n\n        # Limit the size of each histogram to the last 20 entries\n        self.snr_histogram = self.snr_histogram[-20:]\n        self.bpm_histogram = self.bpm_histogram[-20:]\n        self.bps_histogram = self.bps_histogram[-20:]\n        self.time_histogram = self.time_histogram[-20:]\n\n        return stats\n\n    def check_channel_busy(self, channel_busy_slot, mode_slot):\n        for busy, mode in zip(channel_busy_slot, mode_slot):\n            if busy and mode:\n                return False\n        return True\n\n    def get_appropriate_speed_level(self, snr, maximum_bandwidth=None):\n        \"\"\"\n        Determines the appropriate speed level based on the SNR, channel busy slot, and maximum bandwidth.\n\n        Parameters:\n        - snr (float): The signal-to-noise ratio.\n        - channel_busy_slot (list of bool): The busy condition of the channels.\n        - maximum_bandwidth (float, optional): The maximum bandwidth. If None, uses the default from the configuration.\n\n        Returns:\n        - int: The appropriate speed level.\n        \"\"\"\n        # Use default maximum bandwidth from configuration if not provided\n        if maximum_bandwidth is None:\n            maximum_bandwidth = self.config['MODEM']['maximum_bandwidth']\n\n        # Adjust maximum_bandwidth if set to 0 (use maximum available bandwidth from speed levels)\n        if maximum_bandwidth == 0:\n            maximum_bandwidth = max(details['bandwidth'] for details in self.SPEED_LEVEL_DICT.values())\n\n        # Iterate through speed levels in reverse order to find the highest appropriate one\n        for level in sorted(self.SPEED_LEVEL_DICT.keys(), reverse=True):\n            details = self.SPEED_LEVEL_DICT[level]\n            mode_slots = details['slots'].value\n            if (snr >= details['min_snr'] and\n                details['bandwidth'] <= maximum_bandwidth and\n                self.check_channel_busy(self.states.channel_busy_slot, mode_slots)):\n                return level\n\n        # Return the lowest level if no higher level is found\n        return min(self.SPEED_LEVEL_DICT.keys())\n    \n    def reset_session(self):\n        self.received_bytes = 0\n        self.snr_histogram = []\n        self.bpm_histogram = []\n        self.bps_histogram = []\n        self.time_histogram = []\n        self.type_byte = None\n        self.total_length = 0\n        self.total_crc = ''\n        self.received_data = None\n        self.received_bytes = 0\n        self.received_crc = None\n        self.maximum_bandwidth = 0\n        self.abort = False"}
{"type": "source_file", "path": "freedata_server/adif_udp_logger.py", "content": "import socket\nimport re\nimport structlog\n\n\ndef send_adif_qso_data(config, adif_data):\n    \"\"\"\n    Sends ADIF QSO data to the specified server via UDP.\n\n    Parameters:\n    server_ip (str): IP address of the server.\n    server_port (int): Port of the server.\n    adif_data (str): ADIF-formatted QSO data.\n    \"\"\"\n\n    log = structlog.get_logger()\n\n    # If False then exit the function\n    adif = config['QSO_LOGGING'].get('enable_adif_udp', 'False')\n\n    if not adif:\n        return  # exit as we don't want to log ADIF UDP\n\n    adif_log_host = config['QSO_LOGGING'].get('adif_udp_host', '127.0.0.1')\n    adif_log_port = int(config['QSO_LOGGING'].get('adif_udp_port', '2237'))\n\n    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    try:\n\n        # Send the ADIF data to the server\n        sock.sendto(adif_data.encode('utf-8'), (adif_log_host, adif_log_port))\n        log.info(f\"[CHAT] ADIF QSO data sent to: {adif_log_host}:{adif_log_port} {adif_data.encode('utf-8')}\")\n    except Exception as e:\n        log.info(f\"[CHAT] Error sending ADIF data: {e}\")\n    finally:\n        sock.close()\n"}
{"type": "source_file", "path": "freedata_server/api/devices.py", "content": "from fastapi import APIRouter, Request\nfrom api.common import api_response, api_abort, api_ok, validate\nrouter = APIRouter()\nimport audio\nimport serial_ports\n\n\n@router.get(\"/audio\", summary=\"Get Audio Devices\", tags=[\"Devices\"], responses={\n    200: {\n        \"description\": \"List of available audio input and output devices.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"in\": [\n                        {\n                            \"api\": \"ALSA\",\n                            \"id\": \"8eb1\",\n                            \"name\": \"pipewire\",\n                            \"native_index\": 4\n                        },\n                        {\n                            \"api\": \"ALSA\",\n                            \"id\": \"8e7a\",\n                            \"name\": \"default\",\n                            \"native_index\": 5\n                        }\n                    ],\n                    \"out\": [\n                        {\n                            \"api\": \"ALSA\",\n                            \"id\": \"ae79\",\n                            \"name\": \"HDA Intel HDMI: 0 (hw:0,3)\",\n                            \"native_index\": 0\n                        },\n                        {\n                            \"api\": \"ALSA\",\n                            \"id\": \"67fd\",\n                            \"name\": \"HDA Intel HDMI: 1 (hw:0,7)\",\n                            \"native_index\": 1\n                        },\n                        {\n                            \"api\": \"ALSA\",\n                            \"id\": \"b68c\",\n                            \"name\": \"HDA Intel HDMI: 2 (hw:0,8)\",\n                            \"native_index\": 2\n                        },\n                        {\n                            \"api\": \"ALSA\",\n                            \"id\": \"ba84\",\n                            \"name\": \"hdmi\",\n                            \"native_index\": 3\n                        },\n                        {\n                            \"api\": \"ALSA\",\n                            \"id\": \"8eb1\",\n                            \"name\": \"pipewire\",\n                            \"native_index\": 4\n                        },\n                        {\n                            \"api\": \"ALSA\",\n                            \"id\": \"8e7a\",\n                            \"name\": \"default\",\n                            \"native_index\": 5\n                        }\n                    ]\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def get_audio_devices():\n    \"\"\"\n    Retrieve a list of available audio input and output devices.\n\n    Returns:\n        dict: A JSON object containing lists of input and output audio devices.\n    \"\"\"\n    # Uncomment the following line if using the actual function\n    # dev_in, dev_out = audio.get_audio_devices()\n    dev_in, dev_out = audio.fetch_audio_devices([], [])\n    return {'in': dev_in, 'out': dev_out}\n\n\n@router.get(\"/serial\", summary=\"Get Serial Devices\", tags=[\"Devices\"], responses={\n    200: {\n        \"description\": \"List of available serial devices (COM ports).\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": [\n                    {\n                        \"description\": \"n/a [26a9]\",\n                        \"port\": \"/dev/ttyS4\"\n                    }\n                ]\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def get_serial_devices():\n    \"\"\"\n    Retrieve a list of available serial devices (COM ports).\n\n    Returns:\n        list: A list of dictionaries containing serial port information.\n    \"\"\"\n    devices = serial_ports.get_ports()\n    return devices\n"}
{"type": "source_file", "path": "freedata_server/__init__.py", "content": ""}
{"type": "source_file", "path": "freedata_server/api/command_helpers.py", "content": "# api/command_helpers.py\nimport asyncio\n\n\nasync def enqueue_tx_command(app, cmd_class, params={}):\n    \"\"\"\n    Enqueue a transmit command using the app's managers.\n\n    Args:\n        app: The FastAPI app instance (e.g., request.app) containing config_manager, state_manager, etc.\n        cmd_class: The command class to instantiate and run.\n        params: A dict of parameters for the command.\n\n    Returns:\n        True if the command was successfully enqueued and ran, False otherwise.\n    \"\"\"\n    try:\n        # Create an instance of the command using app components.\n        command = cmd_class(app.config_manager.read(), app.state_manager, app.event_manager, params)\n        print(f\"Command {command.get_name()} running...\")\n        # Run the command in a separate thread to avoid blocking the event loop.\n        result = await asyncio.to_thread(command.run, app.modem_events, app.service_manager.modem)\n        if result:\n            return True\n    except Exception as e:\n        print(f\"Command failed: {e}\")\n    return False\n"}
{"type": "source_file", "path": "freedata_server/api/freedata.py", "content": "from fastapi import APIRouter, Request\nfrom api.common import api_response, api_abort, api_ok, validate\nfrom api.command_helpers import enqueue_tx_command\nfrom message_system_db_messages import DatabaseManagerMessages\nfrom message_system_db_attachments import DatabaseManagerAttachments\nfrom message_system_db_beacon import DatabaseManagerBeacon\nfrom message_system_db_station import DatabaseManagerStations\nimport command_message_send\nimport adif_udp_logger\nimport wavelog_api_logger\n\n\nrouter = APIRouter()\n\n\n@router.get(\"/messages/{message_id}\", summary=\"Get Message by ID\", tags=[\"FreeDATA\"], responses={\n    200: {\"description\": \"Message found and returned.\"},\n    404: {\"description\": \"Message not found.\"}\n})\nasync def get_freedata_message(message_id: str, request: Request):\n    message = DatabaseManagerMessages(request.app.event_manager).get_message_by_id_json(message_id)\n    return api_response(message)\n\n\n@router.post(\"/messages\", summary=\"Transmit Message\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"Message transmitted successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"destination\": \"XX1XXX-6\",\n                    \"body\": \"Hello FreeDATA\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running or busy.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_freedata_message(request: Request):\n    \"\"\"\n    Transmit a FreeDATA message.\n\n    Parameters:\n        request (Request): The HTTP request containing the message data in JSON format.\n\n    Returns:\n        dict: A JSON object containing the transmitted message details.\n    \"\"\"\n    data = await request.json()\n    await enqueue_tx_command(request.app, command_message_send.SendMessageCommand, data)\n    return api_response(data)\n\n@router.post(\"/messages/{message_id}/adif\", summary=\"Send Message ADIF Log\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"ADIF log sent successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"adif_output\": \"ADIF data...\"\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid message ID.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Message not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_freedata_message_adif_log(message_id: str, request:Request):\n    adif_output = DatabaseManagerMessages(request.app.event_manager).get_message_by_id_adif(message_id)\n\n    # if message not found do not send adif as the return then is not valid\n    if not adif_output:\n        return\n\n    # Send the ADIF data via UDP\n    adif_udp_logger.send_adif_qso_data(request.app.config_manager.read(), adif_output)\n    wavelog_api_logger.send_wavelog_qso_data(request.app.config_manager.read(), adif_output)\n    return api_response(adif_output)\n\n@router.patch(\"/messages/{message_id}\", summary=\"Update Message by ID\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"Message updated successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"is_read\": True\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid parameters.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"Message not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Message not found.\"\n                }\n            }\n        }\n    }\n})\nasync def patch_freedata_message(message_id: str, request: Request):\n    \"\"\"\n    Update a FreeDATA message by its ID.\n\n    Parameters:\n        message_id (str): The ID of the message to update.\n        request (Request): The HTTP request containing the update data in JSON format.\n\n    Returns:\n        dict: A JSON object containing the updated message details.\n    \"\"\"\n    data = await request.json()\n\n    if data.get(\"action\") == \"retransmit\":\n        result = DatabaseManagerMessages(request.app.event_manager).update_message(message_id, update_data={'status': 'queued'})\n        DatabaseManagerMessages(request.app.event_manager).increment_message_attempts(message_id)\n    else:\n        result = DatabaseManagerMessages(request.app.event_manager).update_message(message_id, update_data=data)\n\n    return api_response(result)\n\n\n@router.get(\"/messages\", summary=\"Get All Messages\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"List of all messages.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"total_messages\": 1,\n                    \"messages\": [\n                        {\n                            \"id\": \"DXCALL-6_MYCALL-0_2024-04-12T20:39:05.302479\",\n                            \"timestamp\": \"2024-04-12T20:39:05.302479\",\n                            \"origin\": \"DXCALL-6\",\n                            \"via\": None,\n                            \"destination\": \"MYCALL-0\",\n                            \"direction\": \"receive\",\n                            \"body\": \"Hello !\",\n                            \"attachments\": [],\n                            \"status\": \"received\",\n                            \"priority\": 10,\n                            \"is_read\": False,\n                            \"statistics\": {\n                                \"total_bytes\": 120,\n                                \"duration\": 29.76698660850525,\n                                \"bytes_per_minute\": 241,\n                                \"time_histogram\": {\n                                    \"0\": \"2024-04-12T20:39:23.423169\",\n                                    \"1\": \"2024-04-12T20:39:30.504638\",\n                                    \"2\": \"2024-04-12T20:39:37.745075\"\n                                },\n                                \"snr_histogram\": {\n                                    \"0\": -6,\n                                    \"1\": -6,\n                                    \"2\": -6\n                                },\n                                \"bpm_histogram\": {\n                                    \"0\": 198,\n                                    \"1\": 265,\n                                    \"2\": 252\n                                }\n                            }\n                        }\n                    ]\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    }\n})\nasync def get_freedata_messages(request: Request):\n    filters = {k: v for k, v in request.query_params.items() if v}\n    result = DatabaseManagerMessages(request.app.event_manager).get_all_messages_json(filters=filters)\n    return api_response(result)\n\n\n@router.post(\"/messages\", summary=\"Transmit Message\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"Message transmitted successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"destination\": \"XX1XXX-6\",\n                    \"body\": \"Hello FreeDATA\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    }\n})\nasync def post_freedata_message(request: Request):\n    \"\"\"\n    Transmit a FreeDATA message.\n\n    Parameters:\n        request (Request): The HTTP request containing the message data in JSON format.\n\n    Returns:\n        dict: A JSON object containing the transmitted message details.\n    \"\"\"\n    data = await request.json()\n    await enqueue_tx_command(request.app, command_message_send.SendMessageCommand, data)\n    return api_response(data)\n\n\n\n@router.delete(\"/messages/{message_id}\", summary=\"Delete Message by ID\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"Message deleted successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"message\": \"DXCALL-0_MYCALL-5_2024-04-04T17:22:14.002502 deleted\",\n                    \"status\": \"success\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"Message not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"message\": \"Message not found\",\n                    \"status\": \"failure\"\n                }\n            }\n        }\n    }\n})\nasync def delete_freedata_message(message_id: str, request:Request):\n    result = DatabaseManagerMessages(request.app.event_manager).delete_message(message_id)\n    if result:\n        return api_response({\"message\": f\"{message_id} deleted\", \"status\": \"success\"})\n    else:\n        return api_response({\"message\": \"Message not found\", \"status\": \"failure\"}, status_code=404)\n\n\n@router.get(\"/messages/{message_id}/attachments\", summary=\"Get Attachments by Message ID\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"List of attachments for the specified message.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"attachments\": [\n                        {\n                            \"id\": \"attachment1\",\n                            \"filename\": \"file1.txt\",\n                            \"file_size\": 1024,\n                            \"file_type\": \"text/plain\",\n                            \"data_sha512\": \"abcdef1234567890...\"\n                        },\n                        {\n                            \"id\": \"attachment2\",\n                            \"filename\": \"image.png\",\n                            \"file_size\": 2048,\n                            \"file_type\": \"image/png\",\n                            \"data_sha512\": \"123456abcdef7890...\"\n                        }\n                    ]\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def get_message_attachments(message_id: str, request:Request):\n    attachments = DatabaseManagerAttachments(request.app.event_manager).get_attachments_by_message_id_json(message_id)\n    return api_response(attachments)\n\n\n@router.get(\"/messages/attachment/{data_sha512}\", summary=\"Get Attachment by SHA512\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"Retrieve a specific attachment by its SHA512 hash.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"id\": \"attachment1\",\n                    \"filename\": \"file1.txt\",\n                    \"file_size\": 1024,\n                    \"file_type\": \"text/plain\",\n                    \"data_sha512\": \"abcdef1234567890...\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested attachment was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Attachment not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def get_message_attachment(data_sha512: str, request:Request):\n    attachment = DatabaseManagerAttachments(request.app.event_manager).get_attachment_by_sha512(data_sha512)\n    return api_response(attachment)\n\n\n@router.get(\"/beacons\", summary=\"Get Received Beacons\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"List of received beacons.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"total_beacons\": 2,\n                    \"beacons\": [\n                        {\n                            \"id\": \"DXCALL-0_MYCALL-5_2024-04-04T17:22:14.002502\",\n                            \"timestamp\": \"2024-04-04T17:22:14.002502\",\n                            \"origin\": \"DXCALL-0\",\n                            \"via\": None,\n                            \"destination\": \"MYCALL-5\",\n                            \"direction\": \"receive\",\n                            \"body\": \"Hello FreeDATA\",\n                            \"attachments\": [],\n                            \"status\": \"received\",\n                            \"priority\": 10,\n                            \"is_read\": False,\n                            \"statistics\": {\n                                \"total_bytes\": 120,\n                                \"duration\": 29.77,\n                                \"bytes_per_minute\": 241,\n                                \"time_histogram\": {\n                                    \"0\": \"2024-04-04T17:22:23.423169\",\n                                    \"1\": \"2024-04-04T17:22:30.504638\",\n                                    \"2\": \"2024-04-04T17:22:37.745075\"\n                                },\n                                \"snr_histogram\": {\n                                    \"0\": -6,\n                                    \"1\": -6,\n                                    \"2\": -6\n                                },\n                                \"bpm_histogram\": {\n                                    \"0\": 198,\n                                    \"1\": 265,\n                                    \"2\": 252\n                                }\n                            }\n                        }\n                    ]\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid request.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    500: {\n        \"description\": \"Internal Server Error: An unexpected error occurred on the server.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Internal server error.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def get_all_beacons(request:Request):\n    beacons = DatabaseManagerBeacon(request.app.event_manager).get_all_beacons()\n    return api_response(beacons)\n\n\n@router.get(\"/beacons/{callsign}\", summary=\"Get Beacon by Callsign\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"List of beacons from the specified callsign.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"beacons\": [\n                        {\n                            \"id\": \"DXCALL-0_MYCALL-5_2024-04-04T17:22:14.002502\",\n                            \"timestamp\": \"2024-04-04T17:22:14.002502\",\n                            \"origin\": \"DXCALL-0\",\n                            \"via\": None,\n                            \"destination\": \"MYCALL-5\",\n                            \"direction\": \"receive\",\n                            \"body\": \"Hello FreeDATA\",\n                            \"attachments\": [],\n                            \"status\": \"received\",\n                            \"priority\": 10,\n                            \"is_read\": False,\n                            \"statistics\": {\n                                \"total_bytes\": 120,\n                                \"duration\": 29.77,\n                                \"bytes_per_minute\": 241,\n                                \"time_histogram\": {\n                                    \"0\": \"2024-04-04T17:22:23.423169\",\n                                    \"1\": \"2024-04-04T17:22:30.504638\",\n                                    \"2\": \"2024-04-04T17:22:37.745075\"\n                                },\n                                \"snr_histogram\": {\n                                    \"0\": -6,\n                                    \"1\": -6,\n                                    \"2\": -6\n                                },\n                                \"bpm_histogram\": {\n                                    \"0\": 198,\n                                    \"1\": 265,\n                                    \"2\": 252\n                                }\n                            }\n                        }\n                    ]\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid request.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    500: {\n        \"description\": \"Internal Server Error: An unexpected error occurred on the server.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Internal server error.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def get_beacons_by_callsign(callsign: str, request:Request):\n    beacons = DatabaseManagerBeacon(request.app.event_manager).get_beacons_by_callsign(callsign)\n    return api_response(beacons)\n\n\n@router.get(\"/station/{callsign}\", summary=\"Get Station Info\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"Retrieve station information by callsign.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"callsign\": \"MYCALL-0\",\n                    \"location\": \"Springfield\",\n                    \"frequency\": \"14093000\",\n                    \"mode\": \"PKTUSB\",\n                    \"status\": \"active\",\n                    \"additional_info\": \"Station details here.\"\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid callsign parameter.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested station was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Station not found.\"\n                }\n            }\n        }\n    },\n    500: {\n        \"description\": \"Internal Server Error: An unexpected error occurred on the server.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Internal server error.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def get_station_info(callsign: str, request: Request):\n    station = DatabaseManagerStations(request.app.event_manager).get_station(callsign)\n    return api_response(station)\n\n\n@router.post(\"/station/{callsign}\", summary=\"Set Station Info\", tags=[\"FreeDATA\"], responses={\n    200: {\n        \"description\": \"Station information updated successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"callsign\": \"MYCALL-0\",\n                    \"location\": \"Springfield\",\n                    \"frequency\": \"14093000\",\n                    \"mode\": \"PKTUSB\",\n                    \"status\": \"active\",\n                    \"additional_info\": \"Updated station details.\"\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid input data.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested station was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Station not found.\"\n                }\n            }\n        }\n    },\n    500: {\n        \"description\": \"Internal Server Error: An unexpected error occurred on the server.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Internal server error.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def set_station_info(callsign: str, request: Request):\n    data = await request.json()\n    result = DatabaseManagerStations(request.app.event_manager).update_station_info(callsign, new_info=data[\"info\"])\n    return api_response(result)"}
{"type": "source_file", "path": "freedata_server/arq_data_type_handler.py", "content": "# File: arq_data_type_handler.py\n\nimport structlog\nimport lzma\nimport gzip\nimport zlib\nfrom message_p2p import message_received, message_failed, message_transmitted\nfrom enum import Enum\n\nclass ARQ_SESSION_TYPES(Enum):\n    raw = 0\n    raw_lzma = 10\n    raw_gzip = 11\n    p2pmsg_zlib = 20\n    p2p_connection = 30\n\nclass ARQDataTypeHandler:\n    def __init__(self, event_manager, state_manager):\n        self.logger = structlog.get_logger(type(self).__name__)\n        self.event_manager = event_manager\n        self.state_manager = state_manager\n\n        self.handlers = {\n            ARQ_SESSION_TYPES.raw: {\n                'prepare': self.prepare_raw,\n                'handle': self.handle_raw,\n                'failed': self.failed_raw,\n                'transmitted': self.transmitted_raw,\n            },\n            ARQ_SESSION_TYPES.raw_lzma: {\n                'prepare': self.prepare_raw_lzma,\n                'handle': self.handle_raw_lzma,\n                'failed': self.failed_raw_lzma,\n                'transmitted': self.transmitted_raw_lzma,\n            },\n            ARQ_SESSION_TYPES.raw_gzip: {\n                'prepare': self.prepare_raw_gzip,\n                'handle': self.handle_raw_gzip,\n                'failed': self.failed_raw_gzip,\n                'transmitted': self.transmitted_raw_gzip,\n            },\n            ARQ_SESSION_TYPES.p2pmsg_zlib: {\n                'prepare': self.prepare_p2pmsg_zlib,\n                'handle': self.handle_p2pmsg_zlib,\n                'failed' : self.failed_p2pmsg_zlib,\n                'transmitted': self.transmitted_p2pmsg_zlib,\n            },\n            ARQ_SESSION_TYPES.p2p_connection: {\n                'prepare': self.prepare_p2p_connection,\n                'handle': self.handle_p2p_connection,\n                'failed': self.failed_p2p_connection,\n                'transmitted': self.transmitted_p2p_connection,\n            },\n        }\n\n    @staticmethod\n    def get_session_type_from_value(value):\n        for session_type in ARQ_SESSION_TYPES:\n            if session_type.value == value:\n                return session_type\n        return None\n\n    def dispatch(self, type_byte: int, data: bytearray, statistics: dict):\n        session_type = self.get_session_type_from_value(type_byte)\n\n        self.state_manager.setARQ(False)\n\n        if session_type and session_type in self.handlers and 'handle' in self.handlers[session_type]:\n            return self.handlers[session_type]['handle'](data, statistics)\n        else:\n            self.log(f\"Unknown handling endpoint for type: {type_byte}\", isWarning=True)\n\n    def failed(self, type_byte: int, data: bytearray, statistics: dict):\n        session_type = self.get_session_type_from_value(type_byte)\n\n        self.state_manager.setARQ(False)\n\n        if session_type in self.handlers and 'failed' in self.handlers[session_type]:\n            return self.handlers[session_type]['failed'](data, statistics)\n        else:\n            self.log(f\"Unknown handling endpoint: {session_type}\", isWarning=True)\n\n    def prepare(self, data: bytearray, session_type=ARQ_SESSION_TYPES.raw):\n        if session_type in self.handlers and 'prepare' in self.handlers[session_type]:\n            return self.handlers[session_type]['prepare'](data), session_type.value\n        else:\n            self.log(f\"Unknown preparation endpoint: {session_type}\", isWarning=True)\n\n    def transmitted(self, type_byte: int, data: bytearray, statistics: dict):\n        session_type = self.get_session_type_from_value(type_byte)\n\n        self.state_manager.setARQ(False)\n\n        if session_type in self.handlers and 'transmitted' in self.handlers[session_type]:\n            return self.handlers[session_type]['transmitted'](data, statistics)\n        else:\n            self.log(f\"Unknown handling endpoint: {session_type}\", isWarning=True)\n\n    def log(self, message, isWarning=False):\n        msg = f\"[{type(self).__name__}]: {message}\"\n        logger = self.logger.warn if isWarning else self.logger.info\n        logger(msg)\n\n    def prepare_raw(self, data):\n        self.log(f\"Preparing uncompressed data: {len(data)} Bytes\")\n        return data\n\n    def handle_raw(self, data, statistics):\n        self.log(f\"Handling uncompressed data: {len(data)} Bytes\")\n        return data\n\n    def failed_raw(self, data, statistics):\n        return\n\n    def transmitted_raw(self, data, statistics):\n        return data\n\n    def prepare_raw_lzma(self, data):\n        compressed_data = lzma.compress(data)\n        self.log(f\"Preparing LZMA compressed data: {len(data)} Bytes >>> {len(compressed_data)} Bytes\")\n        return compressed_data\n\n    def handle_raw_lzma(self, data, statistics):\n        decompressed_data = lzma.decompress(data)\n        self.log(f\"Handling LZMA compressed data: {len(decompressed_data)} Bytes from {len(data)} Bytes\")\n        return decompressed_data\n\n    def failed_raw_lzma(self, data, statistics):\n        return\n\n    def transmitted_raw_lzma(self, data, statistics):\n        decompressed_data = lzma.decompress(data)\n        return decompressed_data\n\n    def prepare_raw_gzip(self, data):\n        compressed_data = gzip.compress(data)\n        self.log(f\"Preparing GZIP compressed data: {len(data)} Bytes >>> {len(compressed_data)} Bytes\")\n        return compressed_data\n\n    def handle_raw_gzip(self, data, statistics):\n        decompressed_data = gzip.decompress(data)\n        self.log(f\"Handling GZIP compressed data: {len(decompressed_data)} Bytes from {len(data)} Bytes\")\n        return decompressed_data\n\n    def failed_raw_gzip(self, data, statistics):\n        return\n\n    def transmitted_raw_gzip(self, data, statistics):\n        decompressed_data = gzip.decompress(data)\n        return decompressed_data\n\n    def prepare_p2pmsg_zlib(self, data):\n        compressed_data = lzma.compress(data)\n\n        compressor = zlib.compressobj(level=6, wbits=-zlib.MAX_WBITS, strategy=zlib.Z_FILTERED)\n        compressed_data = compressor.compress(data) + compressor.flush()\n\n        self.log(f\"Preparing ZLIB compressed P2PMSG data: {len(data)} Bytes >>> {len(compressed_data)} Bytes\")\n        return compressed_data\n\n    def handle_p2pmsg_zlib(self, data, statistics):\n        decompressor = zlib.decompressobj(wbits=-zlib.MAX_WBITS)\n        decompressed_data = decompressor.decompress(data)\n        decompressed_data += decompressor.flush()\n\n        self.log(f\"Handling ZLIB compressed P2PMSG data: {len(decompressed_data)} Bytes from {len(data)} Bytes\")\n        message_received(self.event_manager, self.state_manager, decompressed_data, statistics)\n        return decompressed_data\n\n    def failed_p2pmsg_zlib(self, data, statistics):\n        decompressor = zlib.decompressobj(wbits=-zlib.MAX_WBITS)\n        decompressed_data = decompressor.decompress(data)\n        decompressed_data += decompressor.flush()\n\n        self.log(f\"Handling failed ZLIB compressed P2PMSG data: {len(decompressed_data)} Bytes from {len(data)} Bytes\", isWarning=True)\n        message_failed(self.event_manager, self.state_manager, decompressed_data, statistics)\n        return decompressed_data\n\n    def transmitted_p2pmsg_zlib(self, data, statistics):\n        # Create a decompression object with the same wbits setting used for compression\n        decompressor = zlib.decompressobj(wbits=-zlib.MAX_WBITS)\n        decompressed_data = decompressor.decompress(data)\n        decompressed_data += decompressor.flush()\n\n        message_transmitted(self.event_manager, self.state_manager, decompressed_data, statistics)\n        return decompressed_data\n    \n    \n    def prepare_p2p_connection(self, data):\n        compressed_data = gzip.compress(data)\n        self.log(f\"Preparing gzip compressed P2P_CONNECTION data: {len(data)} Bytes >>> {len(compressed_data)} Bytes\")\n        print(self.state_manager.p2p_connection_sessions)\n        return compressed_data\n\n    def handle_p2p_connection(self, data, statistics):\n        decompressed_data = gzip.decompress(data)\n        self.log(f\"Handling gzip compressed P2P_CONNECTION data: {len(decompressed_data)} Bytes from {len(data)} Bytes\")\n        print(self.state_manager.p2p_connection_sessions)\n        print(decompressed_data)\n        print(self.state_manager.p2p_connection_sessions)\n        for session_id in self.state_manager.p2p_connection_sessions:\n            print(session_id)\n            self.state_manager.p2p_connection_sessions[session_id].received_arq(decompressed_data)\n\n    def failed_p2p_connection(self, data, statistics):\n        decompressed_data = gzip.decompress(data)\n        self.log(f\"Handling failed gzip compressed P2P_CONNECTION data: {len(decompressed_data)} Bytes from {len(data)} Bytes\", isWarning=True)\n        print(self.state_manager.p2p_connection_sessions)\n        return decompressed_data\n\n    def transmitted_p2p_connection(self, data, statistics):\n\n        decompressed_data = gzip.decompress(data)\n        print(decompressed_data)\n        print(self.state_manager.p2p_connection_sessions)\n        for session_id in self.state_manager.p2p_connection_sessions:\n            print(session_id)\n            self.state_manager.p2p_connection_sessions[session_id].transmitted_arq()"}
{"type": "source_file", "path": "freedata_server/api/modem.py", "content": "from fastapi import APIRouter, Request\nfrom api.common import api_response, api_abort, api_ok, validate\nfrom api.command_helpers import enqueue_tx_command\nimport command_cq\nimport command_beacon\nimport command_ping\nimport command_fec\nimport command_test\nimport command_arq_raw\nimport api_validations as validations\n\nrouter = APIRouter()\n\n\n@router.get(\"/state\", summary=\"Get Modem State\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"Current modem state information.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"activities\": {\n                        \"161dd75ef3b5847a\": {\n                            \"activity_type\": \"ARQ_BURST_ACK\",\n                            \"direction\": \"received\",\n                            \"frequency\": \"14093000\",\n                            \"frequency_offset\": 0,\n                            \"session_id\": 105,\n                            \"snr\": 4,\n                            \"timestamp\": 1713034266\n                        },\n                        \"168e90799d13b7b4\": {\n                            \"activity_type\": \"ARQ_SESSION_INFO_ACK\",\n                            \"direction\": \"received\",\n                            \"frequency\": \"14093000\",\n                            \"frequency_offset\": 0,\n                            \"session_id\": 105,\n                            \"snr\": -3,\n                            \"timestamp\": 1713034248\n                        },\n                        \"2218b849e937d36d\": {\n                            \"activity_type\": \"QRV\",\n                            \"direction\": \"received\",\n                            \"frequency\": \"14093000\",\n                            \"frequency_offset\": 0,\n                            \"gridsquare\": \"JP15OW\",\n                            \"origin\": \"SOMECALL-1\",\n                            \"snr\": 2,\n                            \"timestamp\": 1713034200\n                        },\n                        \"3fb424827f4632ab\": {\n                            \"activity_type\": \"BEACON\",\n                            \"direction\": \"received\",\n                            \"frequency\": \"14093000\",\n                            \"frequency_offset\": 0,\n                            \"gridsquare\": \"JP22AI\",\n                            \"origin\": \"CALLSIGN-1\",\n                            \"snr\": -8,\n                            \"timestamp\": 1713034455\n                        },\n                        \"743222d1dd64ce9d\": {\n                            \"activity_type\": \"ARQ_SESSION_OPEN_ACK\",\n                            \"direction\": \"received\",\n                            \"frequency\": \"14093000\",\n                            \"frequency_offset\": 0,\n                            \"origin\": \"CALL-1\",\n                            \"session_id\": 105,\n                            \"snr\": -2,\n                            \"timestamp\": 1713034243\n                        },\n                        \"7589edf6bf23ceed\": {\n                            \"activity_type\": \"ARQ_BURST_ACK\",\n                            \"direction\": \"received\",\n                            \"frequency\": \"14093000\",\n                            \"frequency_offset\": 0,\n                            \"session_id\": 105,\n                            \"snr\": 2,\n                            \"timestamp\": 1713034275\n                        },\n                        \"9d2c5a98fe0f9894\": {\n                            \"activity_type\": \"QRV\",\n                            \"direction\": \"received\",\n                            \"frequency\": \"14093000\",\n                            \"frequency_offset\": 0,\n                            \"gridsquare\": \"JP12AW\",\n                            \"origin\": \"CALLME-1\",\n                            \"snr\": 5,\n                            \"timestamp\": 1713034178\n                        },\n                        \"f85609dced4ea40a\": {\n                            \"activity_type\": \"ARQ_BURST_ACK\",\n                            \"direction\": \"received\",\n                            \"frequency\": \"14093000\",\n                            \"frequency_offset\": 0,\n                            \"session_id\": 105,\n                            \"snr\": 0,\n                            \"timestamp\": 1713034257\n                        }\n                    },\n                    \"audio_dbfs\": -7.915304862713354,\n                    \"channel_busy_slot\": [False, False, True, False, False],\n                    \"is_away_from_key\": False,\n                    \"is_beacon_running\": True,\n                    \"is_modem_busy\": False,\n                    \"is_modem_running\": True,\n                    \"radio_frequency\": \"14093000\",\n                    \"radio_mode\": \"PKTUSB\",\n                    \"radio_status\": True,\n                    \"s_meter_strength\": \"20\",\n                    \"type\": \"state\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    }\n})\nasync def get_modem_state(request:Request):\n    \"\"\"\n    Retrieve the current state of the modem.\n\n    Returns:\n        dict: A JSON object containing modem state information.\n    \"\"\"\n    return request.app.state_manager.sendState()\n\n\n@router.post(\"/cqcqcq\", summary=\"Send CQ Command\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"CQ command sent successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"message\": \"ok\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_cqcqcq(request:Request):\n    \"\"\"\n    Trigger the modem to send a CQ.\n\n    Returns:\n        dict: A JSON object indicating success.\n\n    Raises:\n        HTTPException: If the modem is not running.\n    \"\"\"\n    if not request.app.state_manager.is_modem_running:\n        api_abort(\"Modem not running\", 503)\n    await enqueue_tx_command(request.app, command_cq.CQCommand)\n    return api_ok()\n\n\n@router.post(\"/beacon\", summary=\"Enable/Disable Modem Beacon\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"Beacon status updated successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"enabled\": True,\n                    \"away_from_key\": False\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Invalid input parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Incorrect value for 'enabled' or 'away_from_key'. Should be bool.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_beacon(request: Request):\n    \"\"\"\n    Enable or disable the modem beacon.\n\n    Parameters:\n        request (Request): The HTTP request containing the following JSON keys:\n            - 'enabled' (bool): True to enable the beacon, False to disable.\n            - 'away_from_key' (bool): True if away from key, False otherwise.\n\n    Returns:\n        dict: A JSON object indicating the beacon status.\n\n    Raises:\n        HTTPException: If parameters are invalid or modem is not running.\n    \"\"\"\n    data = await request.json()\n    if not isinstance(data.get('enabled'), bool) or not isinstance(data.get('away_from_key'), bool):\n        api_abort(\"Incorrect value for 'enabled' or 'away_from_key'. Should be bool.\", 400)\n    if not request.app.state_manager.is_modem_running:\n        api_abort(\"Modem not running\", 503)\n    request.app.state_manager.set('is_beacon_running', data['enabled'])\n    request.app.state_manager.set('is_away_from_key', data['away_from_key'])\n    if not request.app.state_manager.getARQ() and data['enabled']:\n        await enqueue_tx_command(request.app, command_beacon.BeaconCommand, data)\n    return api_response({\"enabled\": data['enabled'], \"away_from_key\": data['away_from_key']})\n\n\n@router.post(\"/ping_ping\", summary=\"Trigger Modem to PING a Station\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"Ping command sent successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"message\": True\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Invalid input parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid 'dxcall' parameter.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_ping(request: Request):\n    \"\"\"\n    Trigger the modem to send a PING to a station.\n\n    Parameters:\n        request (Request): The HTTP request containing the following JSON key:\n            - 'dxcall' (str): Callsign of the station to ping.\n\n    Returns:\n        dict: A JSON object indicating success.\n\n    Raises:\n        HTTPException: If parameters are invalid or modem is not running.\n    \"\"\"\n    data = await request.json()\n    if not request.app.state_manager.is_modem_running:\n        api_abort(\"Modem not running\", 503)\n    dxcall = data.get('dxcall')\n    if not dxcall or not validations.validate_freedata_callsign(dxcall):\n        api_abort(\"Invalid 'dxcall' parameter.\", 400)\n    await enqueue_tx_command(request.app, command_ping.PingCommand, data)\n    return api_response({\"message\": True})\n\n\n@router.post(\"/send_test_frame\", summary=\"Send Test Frame\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"Test frame sent successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"message\": \"ok\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_send_test_frame(request:Request):\n    \"\"\"\n    Trigger the modem to send a test frame.\n\n    Returns:\n        dict: A JSON object indicating success.\n\n    Raises:\n        HTTPException: If the modem is not running.\n    \"\"\"\n    if not request.app.state_manager.is_modem_running:\n        api_abort(\"Modem not running\", 503)\n    await enqueue_tx_command(request.app, command_test.TestCommand)\n    return api_ok()\n\n@router.post(\"/fec_transmit\", summary=\"FEC Transmit\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"FEC frame transmitted successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"message\": \"FEC transmission started.\"\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid parameters.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    500: {\n        \"description\": \"Internal Server Error: An unexpected error occurred on the server.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Internal server error.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_send_fec_frame(request: Request):\n    \"\"\"\n    Trigger the modem to transmit a Forward Error Correction (FEC) frame.\n\n    Parameters:\n        request (Request): The HTTP request containing transmission parameters in JSON format.\n\n    Returns:\n        dict: A JSON object indicating success.\n\n    Raises:\n        HTTPException: If the modem is not running, the request is malformed, or an internal error occurs.\n    \"\"\"\n    if not request.app.state_manager.is_modem_running:\n        api_abort(\"Modem not running\", 503)\n\n    try:\n        data = await request.json()\n    except Exception:\n        api_abort(\"Invalid parameters.\", 400)\n\n    # Validate required parameters (adjust based on actual requirements)\n    if 'message' not in data:\n        api_abort(\"Invalid parameters: 'message' field is required.\", 400)\n\n    # Enqueue the FEC transmission command\n    try:\n        await enqueue_tx_command(request.app, command_fec.FecCommand, data)\n        return api_response({\"message\": \"FEC transmission started.\"})\n    except Exception as e:\n        # Log the exception if necessary\n        api_abort(\"Internal server error.\", 500)\n\n\nfrom fastapi import HTTPException\n\n@router.get(\"/fec_is_writing\", summary=\"Indicate User is Typing (FEC)\", tags=[\"Modem\"], responses={\n    501: {\n        \"description\": \"Feature not implemented.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Feature not implemented yet.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def get_fec_is_writing(request:Request):\n    \"\"\"\n    Trigger the modem to inform over RF that the user is typing a message.\n\n    Returns:\n        dict: A JSON object indicating that the feature is not implemented.\n\n    Raises:\n        HTTPException: If the modem is not running or the feature is not implemented.\n    \"\"\"\n    if not request.app.state_manager.is_modem_running:\n        api_abort(\"Modem not running\", 503)\n\n    # Since the feature is not implemented yet, return a 501 Not Implemented error\n    raise HTTPException(status_code=501, detail=\"Feature not implemented yet.\")\n\n\n@router.post(\"/start\", summary=\"Start Modem\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"Modem started successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"examples\": {\n                    \"modem_started\": {\n                        \"summary\": \"Modem Started\",\n                        \"value\": {\n                            \"modem\": \"started\"\n                        }\n                    },\n                    \"message_ok\": {\n                        \"summary\": \"Message OK\",\n                        \"value\": {\n                            \"message\": \"ok\"\n                        }\n                    }\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid parameters.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    500: {\n        \"description\": \"Internal Server Error: An unexpected error occurred on the server.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Internal server error.\"\n                }\n            }\n        }\n    }\n})\nasync def post_modem_start(request: Request):\n    \"\"\"\n    Trigger the modem to start.\n\n    Parameters:\n        request (Request): The HTTP request\n    Returns:\n        dict: A JSON object indicating the modem has started.\n\n    Raises:\n        HTTPException: If parameters are invalid or an error occurs.\n    \"\"\"\n\n    try:\n        if not request.app.state_manager.is_modem_running:\n            request.app.modem_service.put(\"start\")\n            return api_response({\"modem\": \"started\"})\n        else:\n            api_abort(\"Modem already running\", 503)\n    except Exception as e:\n        api_abort(f\"Internal server error. {e}\", 500)\n\n\n@router.post(\"/stop\", summary=\"Stop Modem\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"Modem stopped successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"examples\": {\n                    \"modem_stopped\": {\n                        \"summary\": \"Modem Stopped\",\n                        \"value\": {\n                            \"modem\": \"stopped\"\n                        }\n                    },\n                    \"message_ok\": {\n                        \"summary\": \"Message OK\",\n                        \"value\": {\n                            \"message\": \"ok\"\n                        }\n                    }\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_modem_stop(request:Request):\n    \"\"\"\n    Trigger the modem to stop.\n\n    Returns:\n        dict: A JSON object indicating the modem has stopped.\n\n    Raises:\n        HTTPException: If the modem is not running or an error occurs.\n    \"\"\"\n    #if not request.app.state_manager.is_modem_running:\n    #    api_abort(\"Modem not running\", 503)\n\n    try:\n        request.app.modem_service.put(\"stop\")\n        return api_response({\"modem\": \"stopped\"})\n    except Exception as e:\n        api_abort(f\"Internal server error. {e}\", 500)\n\n\n\n@router.post(\"/send_arq_raw\", summary=\"Send ARQ Raw Data\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"ARQ raw data sent successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"data\": \"RnJlZURBVEEgaXMgdGhlIGJlc3Qh\",\n                    \"dxcall\": \"XX1XXX-6\",\n                    \"type\": \"raw\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running or busy.\",\n        \"content\": {\n            \"application/json\": {\n                \"examples\": {\n                    \"modem_not_running\": {\n                        \"summary\": \"Modem Not Running\",\n                        \"value\": {\n                            \"error\": \"Modem not running.\"\n                        }\n                    },\n                    \"modem_busy\": {\n                        \"summary\": \"Modem Busy\",\n                        \"value\": {\n                            \"error\": \"Modem Busy.\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n})\nasync def post_send_arq_raw(request: Request):\n    \"\"\"\n    Send ARQ raw data to a specified station.\n\n    Parameters:\n        request (Request): The HTTP request containing the following JSON keys:\n            - 'dxcall' (str): Callsign of the station to send data to.\n            - 'type' (str): Data type ('raw', 'raw_lzma', 'raw_gzip').\n            - 'data' (str): Base64 encoded data to send.\n\n    Returns:\n        dict: A JSON object echoing the sent data.\n\n    Raises:\n        HTTPException: If parameters are invalid or modem is not running/busy.\n    \"\"\"\n    if not request.app.state_manager.is_modem_running:\n        api_abort(\"Modem not running.\", 503)\n    if request.app.state_manager.is_modem_busy:\n        api_abort(\"Modem Busy.\", 503)\n    data = await request.json()\n    dxcall = data.get('dxcall')\n    data_type = data.get('type')\n    raw_data = data.get('data')\n    if not dxcall or not validations.validate_freedata_callsign(dxcall):\n        api_abort(\"Invalid 'dxcall' parameter.\", 400)\n    if data_type not in ['raw', 'raw_lzma', 'raw_gzip']:\n        api_abort(\"Invalid 'type' parameter.\", 400)\n    if not raw_data:\n        api_abort(\"Missing 'data' parameter.\", 400)\n    await enqueue_tx_command(request.app, command_arq_raw.SendARQRawCommand, data)\n    return api_response({\n        \"data\": raw_data,\n        \"dxcall\": dxcall,\n        \"type\": data_type\n    })\n\n\n@router.post(\"/stop_transmission\", summary=\"Stop Transmission\", tags=[\"Modem\"], responses={\n    200: {\n        \"description\": \"Transmission stopped successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"message\": \"ok\"\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid request.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    500: {\n        \"description\": \"Internal Server Error: An unexpected error occurred on the server.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Internal server error.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Modem not running.\"\n                }\n            }\n        }\n    }\n})\nasync def post_modem_stop_transmission(request:Request):\n    \"\"\"\n    Stop the current transmission.\n\n    Returns:\n        dict: A JSON object indicating success.\n\n    Raises:\n        HTTPException: If the modem is not running or an error occurs.\n    \"\"\"\n    if not request.app.state_manager.is_modem_running:\n        api_abort(\"Modem not running\", 503)\n    if request.app.state_manager.getARQ():\n        try:\n            for session in request.app.state_manager.arq_irs_sessions.values():\n                # session.abort_transmission()\n                session.transmission_aborted()\n            for session in request.app.state_manager.arq_iss_sessions.values():\n                session.abort_transmission(send_stop=False)\n                session.transmission_aborted()\n        except Exception as e:\n            print(f\"Error during transmission stopping: {e}\")\n    return api_ok()\n\n\n\n"}
{"type": "source_file", "path": "freedata_server/api/radio.py", "content": "from fastapi import APIRouter, Request\nfrom api.common import api_response, api_abort, api_ok, validate\nfrom api.command_helpers import enqueue_tx_command\nimport command_transmit_sine\n\nrouter = APIRouter()\n\n\n\n@router.get(\"/\", summary=\"Get Radio Parameters\", tags=[\"Radio\"], responses={\n    200: {\n        \"description\": \"Current radio parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"radio_frequency\": \"14093000\",\n                    \"radio_mode\": \"PKTUSB\",\n                    \"radio_rf_level\": 100,\n                    \"radio_status\": True,\n                    \"radio_swr\": 0,\n                    \"radio_tuner\": False,\n                    \"s_meter_strength\": \"20\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    }\n})\nasync def get_radio(request: Request):\n    \"\"\"\n    Retrieve current radio parameters.\n\n    Returns:\n        dict: A JSON object containing radio parameters.\n    \"\"\"\n    return request.app.state_manager.get_radio_status()\n\n\n@router.post(\"/\", summary=\"Set Radio Parameters\", tags=[\"Radio\"], responses={\n    200: {\n        \"description\": \"Radio parameters updated successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"radio_frequency\": \"14093000\",\n                    \"radio_mode\": \"PKTUSB\",\n                    \"radio_rf_level\": 100,\n                    \"radio_status\": True,\n                    \"radio_swr\": 0,\n                    \"radio_tuner\": True,\n                    \"s_meter_strength\": \"20\"\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid parameters.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    }\n})\nasync def post_radio(request: Request):\n    \"\"\"\n    Set radio parameters.\n\n    Parameters:\n        request (Request): The HTTP request containing the radio parameters in JSON format.\n\n    Returns:\n        dict: A JSON object containing the updated radio parameters.\n    \"\"\"\n    data = await request.json()\n    radio_manager = request.app.radio_manager\n    if \"radio_frequency\" in data:\n        radio_manager.set_frequency(data['radio_frequency'])\n    if \"radio_mode\" in data:\n        radio_manager.set_mode(data['radio_mode'])\n    if \"radio_rf_level\" in data:\n        radio_manager.set_rf_level(int(data['radio_rf_level']))\n    if \"radio_tuner\" in data:\n        radio_manager.set_tuner(data['radio_tuner'])\n    return api_response(data)\n\n\n@router.post(\"/tune\", summary=\"Enable/Disable Radio Tuning\", tags=[\"Radio\"], responses={\n    200: {\n        \"description\": \"Radio tuning status updated successfully.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"enable_tuning\": True\n                }\n            }\n        }\n    },\n    400: {\n        \"description\": \"Bad Request: The request was malformed or missing required parameters.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Invalid parameters.\"\n                }\n            }\n        }\n    },\n    404: {\n        \"description\": \"The requested resource was not found.\",\n        \"content\": {\n            \"application/json\": {\n                \"example\": {\n                    \"error\": \"Resource not found.\"\n                }\n            }\n        }\n    },\n    503: {\n        \"description\": \"Modem not running or busy.\",\n        \"content\": {\n            \"application/json\": {\n                \"examples\": {\n                    \"modem_not_running\": {\n                        \"summary\": \"Modem Not Running\",\n                        \"value\": {\n                            \"error\": \"Modem not running.\"\n                        }\n                    },\n                    \"modem_busy\": {\n                        \"summary\": \"Modem Busy\",\n                        \"value\": {\n                            \"error\": \"Modem Busy.\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n})\nasync def post_radio_tune(request: Request):\n    \"\"\"\n    Trigger the modem to inform over RF that the user is typing a message.\n\n    Parameters:\n        request (Request): The HTTP request containing the following JSON key:\n            - 'enable_tuning' (bool): True to enable tuning, False to disable.\n\n    Returns:\n        dict: A JSON object echoing the tuning status.\n\n    Raises:\n        HTTPException: If the modem is not running/busy or if parameters are invalid.\n    \"\"\"\n    data = await request.json()\n    if \"enable_tuning\" in data:\n        if data['enable_tuning']:\n            if not request.app.state_manager.is_modem_running:\n                api_abort(\"Modem not running\", 503)\n            await enqueue_tx_command(request.app, command_transmit_sine.TransmitSine)\n        else:\n            request.app.service_manager.modem.stop_sine()\n    else:\n        request.app.service_manager.modem.stop_sine()\n\n    return api_response(data)\n"}
{"type": "source_file", "path": "freedata_server/api/__init__.py", "content": ""}
{"type": "source_file", "path": "freedata_server/command.py", "content": "from data_frame_factory import DataFrameFactory\nimport queue\nfrom codec2 import FREEDV_MODE\nimport structlog\nfrom state_manager import StateManager\nfrom arq_data_type_handler import ARQDataTypeHandler\n\n\nclass TxCommand():\n\n    def __init__(self, config: dict, state_manager: StateManager, event_manager, apiParams:dict = {}, socket_command_handler=None):\n        self.config = config\n        self.logger = structlog.get_logger(type(self).__name__)\n        self.state_manager = state_manager\n        self.event_manager = event_manager\n        self.set_params_from_api(apiParams)\n        self.frame_factory = DataFrameFactory(config)\n        self.arq_data_type_handler = ARQDataTypeHandler(event_manager, state_manager)\n        self.socket_command_handler = socket_command_handler\n\n    def log(self, message, isWarning = False):\n        msg = f\"[{type(self).__name__}]: {message}\"\n        logger = self.logger.warn if isWarning else self.logger.info\n        logger(msg)\n\n    def set_params_from_api(self, apiParams):\n        pass\n\n    def get_name(self):\n        return type(self).__name__\n\n    def emit_event(self, event_queue):\n        pass\n\n    def log_message(self):\n        return f\"Running {self.get_name()}\"\n\n    def build_frame(self):\n        pass\n\n    def get_tx_mode(self):\n        return FREEDV_MODE.signalling\n    \n    def make_modem_queue_item(self, mode, repeat, repeat_delay, frame):\n        return {\n            'mode': mode,\n            'repeat': repeat,\n            'repeat_delay': repeat_delay,\n            'frame': frame,\n        }\n\n    def transmit(self, modem):\n        frame = self.build_frame()\n        modem.transmit(self.get_tx_mode(), 1, 0, frame)\n\n    def run(self, event_queue: queue.Queue, modem):\n        self.emit_event(event_queue)\n        self.logger.info(self.log_message())\n        self.transmit(modem)\n\n    def test(self, event_queue: queue.Queue):\n        self.emit_event(event_queue)\n        self.logger.info(self.log_message())\n        return self.build_frame()\n"}
{"type": "source_file", "path": "freedata_server/codec2_filter_coeff.py", "content": "import numpy as np\n#from scipy.signal import freqz\nimport ctypes\n\ntestFilter = (ctypes.c_float * 3)(1.000000,1.000000,1.000000)\n\ndef generate_filter_coefficients(Fs_Hz, bandwidth_Hz, taps):\n    # ported from https://github.com/drowe67/misc/blob/master/radio_ae/rx.py#L73\n    B = bandwidth_Hz / Fs_Hz\n    Ntap = taps\n    h = np.zeros(Ntap, dtype=np.csingle)\n\n    # Generating filter coefficients\n    for i in range(Ntap):\n        n = i - (Ntap - 1) / 2\n        h[i] = B * np.sinc(n * B)\n\n    # Convert to ctypes array (interleaved real and imaginary)\n    CArrayType = ctypes.c_float * (len(h) * 2)\n    return CArrayType(*(np.hstack([np.real(h), np.imag(h)]).tolist()))\n\n\"\"\"\ndef plot_filter():\n\n    Fs = 8000  # Sampling frequency\n    bandwidth = 2438  # Bandwidth in Hz\n    centre_freq = 1500  # Centre frequency in Hz\n\n    # Generate filter coefficients\n    h = generate_filter_coefficients(Fs, bandwidth, centre_freq)\n    print(h)\n\n    # Frequency response\n    w, H = freqz(h, worN=8000, fs=Fs)\n\n    # Plotting\n    plt.figure(figsize=(12, 6))\n    plt.plot(w, 20 * np.log10(np.abs(H)), 'b')\n    plt.title('Frequency Response')\n    plt.ylabel('Magnitude [dB]')\n    plt.grid(True)\n    plt.show()\n\n\"\"\""}
{"type": "source_file", "path": "freedata_server/audio.py", "content": "\"\"\"\nGather information about audio devices.\n\"\"\"\nimport multiprocessing\nimport sounddevice as sd\nimport structlog\nimport numpy as np\nimport queue\nimport helpers\n\nlog = structlog.get_logger(\"audio\")\n\n\ndef get_audio_devices():\n    \"\"\"\n    return list of input and output audio devices in own process to avoid crashes of portaudio on raspberry pi\n\n    also uses a process data manager\n    \"\"\"\n    # we need to run this on Windows for multiprocessing support\n    # multiprocessing.freeze_support()\n    # multiprocessing.get_context(\"spawn\")\n\n    # we need to reset and initialize sounddevice before running the multiprocessing part.\n    # If we are not doing this at this early point, not all devices will be displayed\n    #sd._terminate()\n    #sd._initialize()\n\n    # log.debug(\"[AUD] get_audio_devices\")\n    with multiprocessing.Manager() as manager:\n        proxy_input_devices = manager.list()\n        proxy_output_devices = manager.list()\n        # print(multiprocessing.get_start_method())\n        proc = multiprocessing.Process(\n            target=fetch_audio_devices, args=(proxy_input_devices, proxy_output_devices)\n        )\n        proc.start()\n        proc.join(3)\n\n        # additional logging for audio devices\n        # log.debug(\"[AUD] get_audio_devices: input_devices:\", list=f\"{proxy_input_devices}\")\n        # log.debug(\"[AUD] get_audio_devices: output_devices:\", list=f\"{proxy_output_devices}\")\n        return list(proxy_input_devices), list(proxy_output_devices)\n\n\ndef device_crc(device) -> str:\n    crc_hwid = helpers.get_crc_16(bytes(f\"{device['name']}.{device['hostapi']}\", encoding=\"utf-8\"))\n    crc_hwid = crc_hwid.hex()\n    return crc_hwid\n\ndef fetch_audio_devices(input_devices, output_devices):\n    \"\"\"\n    get audio devices from portaudio\n\n    Args:\n      input_devices: proxy variable for input devices\n      output_devices: proxy variable for output devices\n\n    Returns:\n\n    \"\"\"\n    devices = sd.query_devices(device=None, kind=None)\n\n    for index, device in enumerate(devices):\n        # Use a try/except block because Windows doesn't have an audio device range\n        try:\n            name = device[\"name\"]\n            # Ignore some Flex Radio devices to make device selection simpler\n            if name.startswith(\"DAX RESERVED\") or name.startswith(\"DAX IQ\"):\n                continue\n\n            max_output_channels = device[\"max_output_channels\"]\n            max_input_channels = device[\"max_input_channels\"]\n\n        except KeyError:\n            continue\n        except Exception as err:\n            print(err)\n            max_input_channels = 0\n            max_output_channels = 0\n\n        if max_input_channels > 0:\n            hostapi_name = sd.query_hostapis(device['hostapi'])['name']\n\n            new_input_device = {\"id\": device_crc(device), \n                                \"name\": device['name'], \n                                \"api\": hostapi_name,\n                                \"native_index\":index}\n            # check if device not in device list\n            if new_input_device not in input_devices:\n                input_devices.append(new_input_device)\n\n        if max_output_channels > 0:\n            hostapi_name = sd.query_hostapis(device['hostapi'])['name']\n            new_output_device = {\"id\": device_crc(device), \n                                 \"name\": device['name'], \n                                 \"api\": hostapi_name,\n                                 \"native_index\":index}\n            # check if device not in device list\n            if new_output_device not in output_devices:\n                output_devices.append(new_output_device)\n\n    return input_devices, output_devices\n\n\n# FreeData uses the crc as id inside the configuration\n# SD lib uses a numerical id which is essentially an \n# index of the device within the list\n# returns (id, name)\ndef get_device_index_from_crc(crc, isInput: bool):\n    try:\n        in_devices = []\n        out_devices = []\n\n        fetch_audio_devices(in_devices, out_devices)\n\n        if isInput:\n            detected_devices = in_devices\n        else:\n            detected_devices = out_devices\n\n        for i, dev in enumerate(detected_devices):\n            if dev['id'] == crc:\n                return (dev['native_index'], dev['name'])\n\n    except Exception as e:\n        log.warning(f\"Audio device {crc} not detected \", devices=detected_devices, isInput=isInput)\n        return [None, None]\n\ndef test_audio_devices(input_id: str, output_id: str) -> list:\n    test_result = [False, False]\n    try:\n        result = get_device_index_from_crc(input_id, True)\n        if result is None:\n            # in_dev_index, in_dev_name = None, None\n            raise ValueError(f\"[Audio-Test] Invalid input device index {input_id}.\")\n        else:\n            in_dev_index, in_dev_name = result\n            sd.check_input_settings(\n                device=in_dev_index,\n                channels=1,\n                dtype=\"int16\",\n                samplerate=48000,\n            )\n            test_result[0] = True\n    except (sd.PortAudioError, ValueError) as e:\n        log.warning(f\"[Audio-Test] Input device error ({input_id}):\", e=e)\n        test_result[0] = False\n    try:\n        result = get_device_index_from_crc(output_id, False)\n        if result is None:\n            # out_dev_index, out_dev_name = None, None\n            raise ValueError(f\"[Audio-Test] Invalid output device index {output_id}.\")\n        else:\n            out_dev_index, out_dev_name = result\n            sd.check_output_settings(\n                device=out_dev_index,\n                channels=1,\n                dtype=\"int16\",\n                samplerate=48000,\n            )\n            test_result[1] = True\n\n\n    except (sd.PortAudioError, ValueError) as e:\n        log.warning(f\"[Audio-Test] Output device error ({output_id}):\", e=e)\n        test_result[1] = False\n\n    sd._terminate()\n    sd._initialize()\n    return test_result\n\ndef set_audio_volume(datalist: np.ndarray, dB: float) -> np.ndarray:\n    \"\"\"\n    Scale values for the provided audio samples by dB.\n\n    :param datalist: Audio samples to scale\n    :type datalist: np.ndarray\n    :param dB: Decibels to scale samples, constrained to the range [-50, 50]\n    :type dB: float\n    :return: Scaled audio samples\n    :rtype: np.ndarray\n    \"\"\"\n    try:\n        dB = float(dB)\n    except ValueError as e:\n        print(f\"[MDM] Changing audio volume failed with error: {e}\")\n        dB = 0.0  # 0 dB means no change\n\n    # Clip dB value to the range [-50, 50]\n    dB = np.clip(dB, -30, 20)\n\n    # Ensure datalist is an np.ndarray\n    if not isinstance(datalist, np.ndarray):\n        print(\"[MDM] Invalid data type for datalist. Expected np.ndarray.\")\n        return datalist\n\n    # Convert dB to linear scale\n    scale_factor = 10 ** (dB / 20)\n\n    # Scale samples\n    scaled_data = datalist * scale_factor\n\n    # Clip values to int16 range and convert data type\n    return np.clip(scaled_data, -32768, 32767).astype(np.int16)\n\n\ndef normalize_audio(datalist: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Normalize the audio samples so the loudest value reaches 95% of the maximum possible value for np.int16\n    :param datalist: Audio samples to normalize\n    :type datalist: np.ndarray\n    :return: Normalized audio samples, clipped to the range of int16\n    :rtype: np.ndarray\n    \"\"\"\n    if not isinstance(datalist, np.ndarray):\n        print(\"[MDM] Invalid datalist type. Expected np.ndarray.\")\n        return datalist\n\n    # Ensure datalist is not empty\n    if datalist.size == 0:\n        print(\"[MDM] Datalist is empty. Returning unmodified.\")\n        return datalist\n\n    # Find the maximum absolute value in the data\n    max_value = np.max(np.abs(datalist))\n\n    # If max_value is 0, return the datalist (avoid division by zero)\n    if max_value == 0:\n        print(\"[MDM] Max value is zero. Cannot normalize. Returning unmodified.\")\n        return datalist\n\n    # Define the target max value as 95% of the maximum for np.int16\n    target_max_value = int(32767 * 0.95)\n\n    # Compute the normalization factor\n    normalization_factor = target_max_value / max_value\n\n    # Normalize the audio data\n    normalized_data = datalist * normalization_factor\n\n    # Clip to the int16 range and cast\n    normalized_data = np.clip(normalized_data, -32768, 32767).astype(np.int16)\n\n    # Debug information: normalization factor, loudest value before, and after normalization\n    loudest_before = max_value\n    loudest_after = np.max(np.abs(normalized_data))\n    print(f\"[AUDIO] Normalization factor: {normalization_factor:.6f}, Loudest before: {loudest_before}, Loudest after: {loudest_after}\")\n\n    return normalized_data\n\n\n\nRMS_COUNTER = 0\nCHANNEL_BUSY_DELAY = 0\nSLOT_DELAY = [0, 0, 0, 0, 0]\n\n\ndef prepare_data_for_fft(data, target_length_samples=400):\n    \"\"\"\n    Prepare data array for FFT by padding if necessary to match the target length.\n    Center the data if it's shorter than the target length.\n\n    Parameters:\n    - data: numpy array of np.int16, representing the input data.\n    - target_length_samples: int, the target length of the data in samples.\n\n    Returns:\n    - numpy array of np.int16, padded and/or centered if necessary.\n    \"\"\"\n    # Calculate the current length in samples\n    current_length_samples = data.size\n\n    # Check if padding is needed\n    if current_length_samples < target_length_samples:\n        # Calculate total padding needed\n        total_pad_length = target_length_samples - current_length_samples\n        # Calculate padding on each side\n        pad_before = total_pad_length // 2\n        pad_after = total_pad_length - pad_before\n        # Pad the data to center it\n        data_padded = np.pad(data, (pad_before, pad_after), 'constant', constant_values=(0,))\n        return data_padded\n    else:\n        # No padding needed, return original data\n        return data\n\ndef calculate_fft(data, fft_queue, states) -> None:\n    \"\"\"\n    Calculate an average signal strength of the channel to assess\n    whether the channel is \"busy.\"\n    \"\"\"\n    # Initialize dbfs counter\n    # rms_counter = 0\n\n    # https://gist.github.com/ZWMiller/53232427efc5088007cab6feee7c6e4c\n    # Fast Fourier Transform, 10*log10(abs) is to scale it to dB\n    # and make sure it's not imaginary\n\n    global RMS_COUNTER, CHANNEL_BUSY_DELAY\n\n    try:\n        data = prepare_data_for_fft(data, target_length_samples=800)\n        fftarray = np.fft.rfft(data)\n\n        # Set value 0 to 1 to avoid division by zero\n        fftarray[fftarray == 0] = 1\n        dfft = 10.0 * np.log10(abs(fftarray))\n\n        # get average of dfft\n        avg = np.mean(dfft)\n\n        # Detect signals which are higher than the\n        # average + 10 (+10 smoothes the output).\n        # Data higher than the average must be a signal.\n        # Therefore we are setting it to 100 so it will be highlighted\n        # Have to do this when we are not transmitting so our\n        # own sending data will not affect this too much\n        if not states.isTransmitting():\n            dfft[dfft > avg + 15] = 100\n\n            # Calculate audio dbfs\n            # https://stackoverflow.com/a/9763652\n            # calculate dbfs every 50 cycles for reducing CPU load\n            RMS_COUNTER += 1\n            if RMS_COUNTER > 5:\n                d = np.frombuffer(data, np.int16).astype(np.float32)\n                # calculate RMS and then dBFS\n                # https://dsp.stackexchange.com/questions/8785/how-to-compute-dbfs\n                # try except for avoiding runtime errors by division/0\n                try:\n                    rms = int(np.sqrt(np.max(d ** 2)))\n                    if rms == 0:\n                        raise ZeroDivisionError\n                    audio_dbfs = 20 * np.log10(rms / 32768)\n                    states.set(\"audio_dbfs\", audio_dbfs)\n                except Exception as e:\n                    states.set(\"audio_dbfs\", -100)\n\n                RMS_COUNTER = 0\n\n        # Convert data to int to decrease size\n        dfft = dfft.astype(int)\n\n        # Create list of dfft\n        dfftlist = dfft.tolist()\n\n        # Reduce area where the busy detection is enabled\n        # We want to have this in correlation with mode bandwidth\n        # TODO This is not correctly and needs to be checked for correct maths\n        # dfftlist[0:1] = 10,15Hz\n        # Bandwidth[Hz] / 10,15\n        # narrowband = 563Hz = 56\n        # wideband = 1700Hz = 167\n        # 1500Hz = 148\n        # 2700Hz = 266\n        # 3200Hz = 315\n        # Initialize slot delay counters\n        DELAY_INCREMENT = 2\n        MAX_DELAY = 200\n\n        # Main logic\n        slot = 0\n        slot1 = [0, 65]\n        slot2 = [65, 120]\n        slot3 = [120, 176]\n        slot4 = [176, 231]\n        slot5 = [231, len(dfftlist)]\n        slotbusy = [False, False, False, False, False]\n\n        # Set to true if we should increment delay count; else false to decrement\n        addDelay = False\n\n        for range in [slot1, slot2, slot3, slot4, slot5]:\n            range_start = range[0]\n            range_end = range[1]\n            # define the area, we are detecting busy state\n            slotdfft = dfft[range_start:range_end]\n            # Check for signals higher than average by checking for \"100\"\n            # If we have a signal, increment our channel_busy delay counter\n            # so we have a smoother state toggle\n            if np.sum(slotdfft[slotdfft > avg + 15]) >= 200 and not states.isTransmitting() and not states.is_receiving_codec2_signal():\n                addDelay = True\n                slotbusy[slot] = True\n                SLOT_DELAY[slot] = min(SLOT_DELAY[slot] + DELAY_INCREMENT, MAX_DELAY)\n            else:\n                SLOT_DELAY[slot] = max(SLOT_DELAY[slot] - 1, 0)\n\n                if SLOT_DELAY[slot] == 0:\n                    slotbusy[slot] = False\n                else:\n                    slotbusy[slot] = True\n\n            # increment slot\n            slot += 1\n        states.set_channel_slot_busy(slotbusy)\n\n        if addDelay:\n            # Limit delay counter to a maximum of 200. The higher this value,\n            # the longer we will wait until releasing state\n            states.set_channel_busy_condition_traffic(True)\n            CHANNEL_BUSY_DELAY = min(CHANNEL_BUSY_DELAY + DELAY_INCREMENT, MAX_DELAY)\n        else:\n            # Decrement channel busy counter if no signal has been detected.\n            CHANNEL_BUSY_DELAY = max(CHANNEL_BUSY_DELAY - 1, 0)\n            # When our channel busy counter reaches 0, toggle state to False\n            if CHANNEL_BUSY_DELAY == 0:\n                states.set_channel_busy_condition_traffic(False)\n\n        # erase queue if greater than 3\n        if fft_queue.qsize() >= 1:\n            fft_queue = queue.Queue()\n\n        fft_queue.put(dfftlist[:315])  # 315 --> bandwidth 3200\n\n    except Exception as err:\n        print(f\"[MDM] calculate_fft: Exception: {err}\")\n\ndef terminate():\n    log.warning(\"[SHUTDOWN] terminating audio instance...\")\n    if sd._initialized:\n        sd._terminate()\n"}
{"type": "source_file", "path": "freedata_server/codec2.py", "content": "\"\"\"\nPython interface to the C-language codec2 library.\n\"\"\"\n# -*- coding: utf-8 -*-\n\n# pylint: disable=invalid-name, line-too-long, c-extension-no-member\n# pylint: disable=import-outside-toplevel, attribute-defined-outside-init\n\nimport ctypes\nfrom ctypes import *\nimport hashlib\nimport glob\nimport os\nimport sys\nfrom enum import Enum\nfrom threading import Lock\nimport codec2_filter_coeff\nimport numpy as np\nimport structlog\n\nlog = structlog.get_logger(\"codec2\")\n\n\n# Enum for codec2 modes\nclass FREEDV_MODE(Enum):\n    \"\"\"\n    Enumeration for codec2 modes and names\n    \"\"\"\n    signalling = 19\n    signalling_ack = 20\n    datac0 = 14\n    datac1 = 10\n    datac3 = 12\n    datac4 = 18\n    datac13 = 19\n    datac14 = 20\n    data_ofdm_200 = 21200\n    data_ofdm_250 = 21250\n    data_ofdm_500 = 21500\n    data_ofdm_1700 = 211700\n    data_ofdm_2438 = 2124381\n    #data_qam_2438 = 2124382\n    #qam16c2 = 22\n\nclass FREEDV_MODE_USED_SLOTS(Enum):\n    \"\"\"\n    Enumeration for codec2 used slots\n    \"\"\"\n    sig0 = [False, False, True, False, False]\n    sig1 = [False, False, True, False, False]\n    datac0 = [False, False, True, False, False]\n    datac1 = [False, True, True, True, False]\n    datac3 = [False, False, True, False, False]\n    datac4 = [False, False, True, False, False]\n    datac13 = [False, False, True, False, False]\n    datac14 = [False, False, True, False, False]\n    data_ofdm_200 = [False, False, True, False, False]\n    data_ofdm_250 = [False, False, True, False, False]\n    data_ofdm_500 = [False, False, True, False, False]\n    data_ofdm_1700 = [False, True, True, True, False]\n    data_ofdm_2438 = [True, True, True, True, True]\n    data_qam_2438 = [True, True, True, True, True]\n    qam16c2 = [True, True, True, True, True]\n\n# Function for returning the mode value\ndef freedv_get_mode_value_by_name(mode: str) -> int:\n    \"\"\"\n    Get the codec2 mode by entering its string\n\n    Args:\n        mode: String representation of the codec2 mode.\n\n    Returns:\n        int\n    \"\"\"\n    return FREEDV_MODE[mode.lower()].value\n\n\n# Function for returning the mode name\ndef freedv_get_mode_name_by_value(mode: int) -> str:\n    \"\"\"\n    Get the codec2 mode name as string\n    Args:\n        mode: Integer value of the codec2 mode.\n\n    Returns:\n        string\n    \"\"\"\n    return FREEDV_MODE(mode).name\n\n# Get the directory of the current script file\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(script_dir)\n\n# Use script_dir to construct the paths for file search\nif sys.platform == \"linux\":\n    files = glob.glob(os.path.join(script_dir, \"**/*libcodec2*\"), recursive=True)\n    #files.append(os.path.join(script_dir, \"libcodec2.so\"))\nelif sys.platform == \"darwin\":\n    if hasattr(sys, \"_MEIPASS\"):\n        files = glob.glob(os.path.join(getattr(sys, \"_MEIPASS\"), '**/*libcodec2*'), recursive=True)\n    else:\n        files = glob.glob(os.path.join(script_dir, \"**/*libcodec2*.dylib\"), recursive=True)\nelif sys.platform in [\"win32\", \"win64\"]:\n    files = glob.glob(os.path.join(script_dir, \"**\\\\*libcodec2*.dll\"), recursive=True)\nelse:\n    files = []\napi = None\n\nfor file in files:\n    try:\n        api = ctypes.CDLL(file)\n        log.info(\"[C2 ] Libcodec2 loaded\", path=file)\n        break\n    except OSError as err:\n        pass\n        #log.info(\"[C2 ] Error:  Libcodec2 found but not loaded\", path=file, e=err)\n\n# Quit module if codec2 cant be loaded\nif api is None or \"api\" not in locals():\n    log.critical(\"[C2 ] Error:  Libcodec2 not loaded - Exiting\")\n    sys.exit(1)\n\n#log.info(\"[C2 ] Libcodec2 loaded...\", path=file)\n# ctypes function init\n\n# api.freedv_set_tuning_range.restype = ctypes.c_int\n# api.freedv_set_tuning_range.argype = [ctypes.c_void_p, ctypes.c_float, ctypes.c_float]\n\napi.freedv_open.argype = [ctypes.c_int]  # type: ignore\napi.freedv_open.restype = ctypes.c_void_p\n\napi.freedv_set_sync.argype = [ctypes.c_void_p, ctypes.c_int]  # type: ignore\napi.freedv_set_sync.restype = ctypes.c_void_p\n\napi.freedv_open_advanced.argtype = [ctypes.c_int, ctypes.c_void_p]  # type: ignore\napi.freedv_open_advanced.restype = ctypes.c_void_p\n\napi.freedv_get_bits_per_modem_frame.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_get_bits_per_modem_frame.restype = ctypes.c_int\n\napi.freedv_get_modem_extended_stats.argtype = [ctypes.c_void_p, ctypes.c_void_p]\napi.freedv_get_modem_extended_stats.restype = ctypes.c_int\n\napi.freedv_nin.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_nin.restype = ctypes.c_int\n\napi.freedv_rawdatarx.argtype = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_char_p]  # type: ignore\napi.freedv_rawdatarx.restype = ctypes.c_int\n\napi.freedv_rawdatatx.argtype = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_char_p]  # type: ignore\napi.freedv_rawdatatx.restype = ctypes.c_int\n\napi.freedv_rawdatapostambletx.argtype = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_char_p]  # type: ignore\napi.freedv_rawdatapostambletx.restype = ctypes.c_int\n\napi.freedv_rawdatapreambletx.argtype = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_char_p]  # type: ignore\napi.freedv_rawdatapreambletx.restype = ctypes.c_int\n\napi.freedv_get_n_max_modem_samples.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_get_n_max_modem_samples.restype = ctypes.c_int\n\napi.freedv_set_frames_per_burst.argtype = [ctypes.c_void_p, ctypes.c_int]  # type: ignore\napi.freedv_set_frames_per_burst.restype = ctypes.c_void_p\n\napi.freedv_get_rx_status.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_get_rx_status.restype = ctypes.c_int\n\napi.freedv_get_modem_stats.argtype = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]  # type: ignore\napi.freedv_get_modem_stats.restype = ctypes.c_int\n\napi.freedv_get_n_tx_postamble_modem_samples.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_get_n_tx_postamble_modem_samples.restype = ctypes.c_int\n\napi.freedv_get_n_tx_preamble_modem_samples.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_get_n_tx_preamble_modem_samples.restype = ctypes.c_int\n\napi.freedv_get_n_tx_modem_samples.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_get_n_tx_modem_samples.restype = ctypes.c_int\n\napi.freedv_get_n_max_modem_samples.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_get_n_max_modem_samples.restype = ctypes.c_int\n\napi.freedv_ofdm_print_info.argtype = [ctypes.c_void_p]  # type: ignore\napi.freedv_ofdm_print_info.restype = ctypes.c_void_p\n\napi.FREEDV_FS_8000 = 8000  # type: ignore\n\n\n# ------- MODEM STATS STRUCTURES\nMODEM_STATS_NC_MAX = 50 + 1 * 2\nMODEM_STATS_NR_MAX = 320 * 2\nMODEM_STATS_ET_MAX = 8\nMODEM_STATS_EYE_IND_MAX = 160\nMODEM_STATS_NSPEC = 512\nMODEM_STATS_MAX_F_HZ = 4000\nMODEM_STATS_MAX_F_EST = 4\n\n\nclass MODEMSTATS(ctypes.Structure):\n    \"\"\"Modem statistics structure\"\"\"\n\n    _fields_ = [\n        (\"Nc\", ctypes.c_int),\n        (\"snr_est\", ctypes.c_float),\n        (\"rx_symbols\", (ctypes.c_float * MODEM_STATS_NR_MAX) * MODEM_STATS_NC_MAX),\n        (\"nr\", ctypes.c_int),\n        (\"sync\", ctypes.c_int),\n        (\"foff\", ctypes.c_float),\n        (\"rx_timing\", ctypes.c_float),\n        (\"clock_offset\", ctypes.c_float),\n        (\"sync_metric\", ctypes.c_float),\n        (\"pre\", ctypes.c_int),\n        (\"post\", ctypes.c_int),\n        (\"uw_fails\", ctypes.c_int),\n        (\"rx_eye\", (ctypes.c_float * MODEM_STATS_ET_MAX) * MODEM_STATS_EYE_IND_MAX),\n        (\"neyetr\", ctypes.c_int),  # How many eye traces are plotted\n        (\"neyesamp\", ctypes.c_int),  # How many samples in the eye diagram\n        (\"f_est\", (ctypes.c_float * MODEM_STATS_MAX_F_EST)),\n        (\"fft_buf\", (ctypes.c_float * MODEM_STATS_NSPEC * 2)),\n        (\"fft_cfg\", ctypes.c_void_p)\n    ]\n\n\n# Return code flags for freedv_get_rx_status() function\napi.FREEDV_RX_TRIAL_SYNC = 0x1  # type: ignore # demodulator has trial sync\napi.FREEDV_RX_SYNC = 0x2  # type: ignore # demodulator has sync\napi.FREEDV_RX_BITS = 0x4  # type: ignore # data bits have been returned\napi.FREEDV_RX_BIT_ERRORS = 0x8  # type: ignore # FEC may not have corrected all bit errors (not all parity checks OK)\n\napi.rx_sync_flags_to_text = [  # type: ignore\n    \"----\",\n    \"---T\",\n    \"--S-\",\n    \"--ST\",\n    \"-B--\",\n    \"-B-T\",\n    \"-BS-\",\n    \"-BST\",\n    \"E---\",\n    \"E--T\",\n    \"E-S-\",\n    \"E-ST\",\n    \"EB--\",\n    \"EB-T\",\n    \"EBS-\",\n    \"EBST\",\n]\n\n# Audio buffer ---------------------------------------------------------\nclass audio_buffer:\n    \"\"\"\n    Thread-safe audio buffer, which fits the needs of codec2\n\n    made by David Rowe, VK5DGR\n    \"\"\"\n\n    # A buffer of int16 samples, using a fixed length numpy array self.buffer for storage\n    # self.nbuffer is the current number of samples in the buffer\n    def __init__(self, size):\n        log.debug(\"[C2 ] Creating audio buffer\", size=size)\n        self.size = size\n        self.buffer = np.zeros(size, dtype=np.int16)\n        self.nbuffer = 0\n        self.mutex = Lock()\n\n    def push(self, samples):\n        \"\"\"\n        Push new data to buffer\n\n        Args:\n            samples:\n\n        Returns:\n            Nothing\n        \"\"\"\n        self.mutex.acquire()\n        # Add samples at the end of the buffer\n        assert self.nbuffer + len(samples) <= self.size\n        self.buffer[self.nbuffer : self.nbuffer + len(samples)] = samples\n        self.nbuffer += len(samples)\n        self.mutex.release()\n\n    def pop(self, size):\n        \"\"\"\n        get data from buffer in size of NIN\n        Args:\n          size:\n\n        Returns:\n            Nothing\n        \"\"\"\n        self.mutex.acquire()\n        # Remove samples from the start of the buffer\n        self.nbuffer -= size\n        self.buffer[: self.nbuffer] = self.buffer[size : size + self.nbuffer]\n        assert self.nbuffer >= 0\n        self.mutex.release()\n\n\n# Resampler ---------------------------------------------------------\n\n# Oversampling rate\napi.FDMDV_OS_48 = 6  # type: ignore\n# Number of oversampling taps at 48kHz\napi.FDMDV_OS_TAPS_48K = 48  # type: ignore\n# Number of oversampling filter taps at 8kHz\napi.FDMDV_OS_TAPS_48_8K = api.FDMDV_OS_TAPS_48K // api.FDMDV_OS_48  # type: ignore\napi.fdmdv_8_to_48_short.argtype = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int]  # type: ignore\napi.fdmdv_48_to_8_short.argtype = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int]  # type: ignore\n\n\nclass resampler:\n    \"\"\"\n    Re-sampler class\n    \"\"\"\n\n    # Re-sample an array of variable length, we just store the filter memories here\n    MEM8 = api.FDMDV_OS_TAPS_48_8K\n    MEM48 = api.FDMDV_OS_TAPS_48K\n\n    def __init__(self):\n        log.debug(\"[C2 ] Create 48<->8 kHz resampler\")\n        self.filter_mem8 = np.zeros(self.MEM8, dtype=np.int16)\n        self.filter_mem48 = np.zeros(self.MEM48)\n\n    def resample48_to_8(self, in48):\n        \"\"\"\n        Audio resampler integration from codec2\n        Downsample audio from 48000Hz to 8000Hz\n        Args:\n            in48: input data as np.int16\n\n        Returns:\n            Downsampled 8000Hz data as np.int16\n        \"\"\"\n        assert in48.dtype == np.int16\n        # Length of input vector must be an integer multiple of api.FDMDV_OS_48\n        assert len(in48) % api.FDMDV_OS_48 == 0  # type: ignore\n\n        # Concatenate filter memory and input samples\n        in48_mem = np.zeros(self.MEM48 + len(in48), dtype=np.int16)\n        in48_mem[: self.MEM48] = self.filter_mem48\n        in48_mem[self.MEM48 :] = in48\n\n        # In C: pin48=&in48_mem[MEM48]\n        pin48 = ctypes.byref(np.ctypeslib.as_ctypes(in48_mem), 2 * self.MEM48)\n        n8 = int(len(in48) / api.FDMDV_OS_48)  # type: ignore\n        out8 = np.zeros(n8, dtype=np.int16)\n        api.fdmdv_48_to_8_short(out8.ctypes, pin48, n8)  # type: ignore\n\n        # Store memory for next time\n        self.filter_mem48 = in48_mem[: self.MEM48]\n\n        return out8\n\n    def resample8_to_48(self, in8):\n        \"\"\"\n        Audio resampler integration from codec2\n        Re-sample audio from 8000Hz to 48000Hz\n        Args:\n            in8: input data as np.int16\n\n        Returns:\n            48000Hz audio as np.int16\n        \"\"\"\n        assert in8.dtype == np.int16\n\n        # Concatenate filter memory and input samples\n        in8_mem = np.zeros(self.MEM8 + len(in8), dtype=np.int16)\n        in8_mem[: self.MEM8] = self.filter_mem8\n        in8_mem[self.MEM8 :] = in8\n\n        # In C: pin8=&in8_mem[MEM8]\n        pin8 = ctypes.byref(np.ctypeslib.as_ctypes(in8_mem), 2 * self.MEM8)\n        out48 = np.zeros(api.FDMDV_OS_48 * len(in8), dtype=np.int16)  # type: ignore\n        api.fdmdv_8_to_48_short(out48.ctypes, pin8, len(in8))  # type: ignore\n\n        # Store memory for next time\n        self.filter_mem8 = in8_mem[: self.MEM8]\n\n        return out48\n\ndef open_instance(mode: int) -> ctypes.c_void_p:\n    data_custom = 21\n    if mode in [FREEDV_MODE.data_ofdm_200.value, FREEDV_MODE.data_ofdm_250.value, FREEDV_MODE.data_ofdm_500.value, FREEDV_MODE.data_ofdm_1700.value, FREEDV_MODE.data_ofdm_2438.value]:\n    #if mode in [FREEDV_MODE.data_ofdm_500.value, FREEDV_MODE.data_ofdm_2438.value, FREEDV_MODE.data_qam_2438]:\n        custom_params = ofdm_configurations[mode]\n        return ctypes.cast(\n                    api.freedv_open_advanced(\n                        data_custom,\n                        ctypes.byref(custom_params),\n                    ),\n                    ctypes.c_void_p,\n                )\n    else:\n        if mode not in [data_custom]:\n            return ctypes.cast(api.freedv_open(mode), ctypes.c_void_p)\n\n\ndef get_bytes_per_frame(mode: int) -> int:\n    \"\"\"\n    Provide bytes per frame information for accessing from data handler\n\n    :param mode: Codec2 mode to query\n    :type mode: int or str\n    :return: Bytes per frame of the supplied codec2 data mode\n    :rtype: int\n    \"\"\"\n    freedv = open_instance(mode)\n    # TODO add close session\n    # get number of bytes per frame for mode\n    return int(api.freedv_get_bits_per_modem_frame(freedv) / 8)\n\n\nMAX_UW_BITS = 64#192\n\nclass OFDM_CONFIG(ctypes.Structure):\n    _fields_ = [\n        (\"tx_centre\", ctypes.c_float),  # TX Centre Audio Frequency\n        (\"rx_centre\", ctypes.c_float),  # RX Centre Audio Frequency\n        (\"fs\", ctypes.c_float),  # Sample Frequency\n        (\"rs\", ctypes.c_float),  # Symbol Rate\n        (\"ts\", ctypes.c_float),  # Symbol duration\n        (\"tcp\", ctypes.c_float),  # Cyclic Prefix duration\n        (\"timing_mx_thresh\", ctypes.c_float),  # Threshold for timing metrics\n        (\"nc\", ctypes.c_int),  # Number of carriers\n        (\"ns\", ctypes.c_int),  # Number of Symbol frames\n        (\"np\", ctypes.c_int),  # Number of freedata_server frames per packet\n        (\"bps\", ctypes.c_int),  # Bits per Symbol\n        (\"txtbits\", ctypes.c_int),  # Number of auxiliary data bits\n        (\"nuwbits\", ctypes.c_int),  # Number of unique word bits\n        (\"bad_uw_errors\", ctypes.c_int),  # Threshold for bad unique word detection\n        (\"ftwindowwidth\", ctypes.c_int),  # Filter window width\n        (\"edge_pilots\", ctypes.c_int),  # Edge pilots configuration\n        (\"state_machine\", ctypes.c_char_p),  # Name of sync state machine used\n        (\"codename\", ctypes.c_char_p),  # LDPC codename\n        (\"tx_uw\", ctypes.c_uint8 * MAX_UW_BITS),  # User defined unique word\n        (\"amp_est_mode\", ctypes.c_int),  # Amplitude estimator algorithm mode\n        (\"tx_bpf_en\", ctypes.c_bool),  # TX BPF enable flag\n        (\"rx_bpf_en\", ctypes.c_bool),  # RX BPF enable flag\n        (\"tx_bpf_proto\", ctypes.POINTER(ctypes.c_float)),  # low pass prototype for complex BPF\n        (\"tx_bpf_proto_n\", ctypes.c_int),  # number of taps in low pass prototype\n        (\"foff_limiter\", ctypes.c_bool),  # Frequency offset limiter enable flag\n        (\"amp_scale\", ctypes.c_float),  # Amplitude scale factor\n        (\"clip_gain1\", ctypes.c_float),  # Pre-clipping gain\n        (\"clip_gain2\", ctypes.c_float),  # Post-clipping gain\n        (\"clip_en\", ctypes.c_bool),  # Clipping enable flag\n        (\"mode\", ctypes.c_char * 16),  # OFDM mode in string form\n        (\"data_mode\", ctypes.c_char_p),  # Data mode (\"streaming\", \"burst\", etc.)\n        (\"fmin\", ctypes.c_float),  # Minimum frequency for tuning range\n        (\"fmax\", ctypes.c_float),  # Maximum frequency for tuning range\n\n    ]\n\nclass FREEDV_ADVANCED(ctypes.Structure):\n    \"\"\"Advanced structure for fsk and ofdm modes\"\"\"\n    _fields_ = [\n        (\"interleave_frames\", ctypes.c_int),\n        (\"M\", ctypes.c_int),\n        (\"Rs\", ctypes.c_int),\n        (\"Fs\", ctypes.c_int),\n        (\"first_tone\", ctypes.c_int),\n        (\"tone_spacing\", ctypes.c_int),\n        (\"codename\", ctypes.c_char_p),\n        (\"config\", ctypes.POINTER(OFDM_CONFIG))\n    ]\n\n\napi.freedv_open_advanced.argtypes = [ctypes.c_int, ctypes.POINTER(FREEDV_ADVANCED)]\napi.freedv_open_advanced.restype = ctypes.c_void_p\n\ndef create_default_ofdm_config():\n\n    ofdm_default_config = OFDM_CONFIG(\n        tx_centre=1500.0,\n        rx_centre=1500.0,\n        fs=8000.0,\n        rs=62.5,\n        ts=0.016,\n        tcp=0.006,\n        timing_mx_thresh=0.10,\n        nc=9,\n        ns=5,\n        np=29,\n        bps=2,\n        txtbits=0,\n        nuwbits=40,\n        bad_uw_errors=10,\n        ftwindowwidth=80,\n        edge_pilots=False,\n        state_machine=\"data\".encode('utf-8'),\n        codename=\"H_1024_2048_4f\".encode('utf-8'),\n        tx_uw=(c_uint8 * MAX_UW_BITS)(*([0] * MAX_UW_BITS)),\n        amp_est_mode=1,\n        tx_bpf_en=False,\n        rx_bpf_en=False,\n        tx_bpf_proto=codec2_filter_coeff.testFilter,\n        tx_bpf_proto_n=int(ctypes.sizeof(codec2_filter_coeff.testFilter) / ctypes.sizeof(ctypes.c_float)),\n        foff_limiter=False,\n        amp_scale=300E3,\n        clip_gain1=2.2,\n        clip_gain2=0.8,\n        clip_en=False,\n        mode=\"CUSTOM\".encode('utf-8'),\n        data_mode=\"streaming\".encode('utf-8'),\n        fmin=-50.0,\n        fmax=50.0,\n    )\n\n    return FREEDV_ADVANCED(\n        interleave_frames = 0,\n        M = 2,\n        Rs = 100,\n        Fs = 8000,\n        first_tone = 1000,\n        tone_spacing = 200,\n        codename = \"H_256_512_4\".encode(\"utf-8\"),\n        config = ctypes.pointer(ofdm_default_config),\n    )\n\n\ndef create_tx_uw(nuwbits, uw_sequence):\n    \"\"\"\n    Creates a tx_uw ctypes array filled with the uw_sequence up to nuwbits.\n    If uw_sequence is shorter than nuwbits, the rest of the array is filled with zeros.\n\n    :param nuwbits: The number of bits for the tx_uw array, should not exceed MAX_UW_BITS.\n    :param uw_sequence: List of integers representing the unique word sequence.\n    :return: A ctypes array representing the tx_uw.\n    \"\"\"\n    # Ensure nuwbits does not exceed MAX_UW_BITS\n    if nuwbits > MAX_UW_BITS:\n        raise ValueError(f\"nuwbits exceeds MAX_UW_BITS: {MAX_UW_BITS}\")\n\n    tx_uw_array = (ctypes.c_uint8 * MAX_UW_BITS)(*([0] * MAX_UW_BITS))\n    for i in range(min(len(uw_sequence), MAX_UW_BITS)):\n        tx_uw_array[i] = uw_sequence[i]\n    return tx_uw_array\n\n# ---------------- OFDM 500 Hz Bandwidth ---------------#\n\n# DATAC13 # OFDM 200\ndata_ofdm_200_config = create_default_ofdm_config()\ndata_ofdm_200_config.config.contents.ns = 5\ndata_ofdm_200_config.config.contents.np = 18\ndata_ofdm_200_config.config.contents.tcp = 0.006\ndata_ofdm_200_config.config.contents.ts = 0.016\ndata_ofdm_200_config.config.contents.rs = 1.0 / data_ofdm_200_config.config.contents.ts\ndata_ofdm_200_config.config.contents.nc = 3\ndata_ofdm_200_config.config.contents.timing_mx_thresh = 0.45\ndata_ofdm_200_config.config.contents.bad_uw_errors = 18\ndata_ofdm_200_config.config.contents.codename = \"H_256_512_4\".encode('utf-8')\ndata_ofdm_200_config.config.contents.amp_scale = 2.5*300E3\ndata_ofdm_200_config.config.contents.nuwbits = 48\ndata_ofdm_200_config.config.contents.tx_uw = create_tx_uw(data_ofdm_200_config.config.contents.nuwbits, [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\ndata_ofdm_200_config.config.contents.clip_gain1 = 1.2\ndata_ofdm_200_config.config.contents.clip_gain2 = 1.0\ndata_ofdm_200_config.config.contents.tx_bpf_en = False\ndata_ofdm_200_config.config.contents.tx_bpf_proto = codec2_filter_coeff.generate_filter_coefficients(8000, 400, 101)\ndata_ofdm_200_config.config.contents.tx_bpf_proto_n = 101 # TODO sizeof(filtP200S400) / sizeof(float);\n\n\n# DATAC4 # OFDM 250\ndata_ofdm_250_config = create_default_ofdm_config()\ndata_ofdm_250_config.config.contents.ns = 5\ndata_ofdm_250_config.config.contents.np = 47\ndata_ofdm_250_config.config.contents.tcp = 0.006\ndata_ofdm_250_config.config.contents.ts = 0.016\ndata_ofdm_250_config.config.contents.rs = 1.0 / data_ofdm_250_config.config.contents.ts\ndata_ofdm_250_config.config.contents.nc = 4\ndata_ofdm_250_config.config.contents.timing_mx_thresh = 0.5\ndata_ofdm_250_config.config.contents.bad_uw_errors = 12\ndata_ofdm_250_config.config.contents.codename = \"H_1024_2048_4f\".encode('utf-8')\ndata_ofdm_250_config.config.contents.amp_scale = 2*300E3\ndata_ofdm_250_config.config.contents.nuwbits = 32\ndata_ofdm_250_config.config.contents.tx_uw = create_tx_uw(data_ofdm_250_config.config.contents.nuwbits, [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\ndata_ofdm_250_config.config.contents.clip_gain1 = 1.2\ndata_ofdm_250_config.config.contents.clip_gain2 = 1.0\ndata_ofdm_250_config.config.contents.tx_bpf_en = True\ndata_ofdm_250_config.config.contents.tx_bpf_proto = codec2_filter_coeff.generate_filter_coefficients(8000, 400, 101)\ndata_ofdm_250_config.config.contents.tx_bpf_proto_n = 101 # TODO sizeof(filtP200S400) / sizeof(float);\n\n\n# OFDM 500\ndata_ofdm_500_config = create_default_ofdm_config()\ndata_ofdm_500_config.config.contents.ns = 5\ndata_ofdm_500_config.config.contents.np = 32\ndata_ofdm_500_config.config.contents.tcp = 0.006\ndata_ofdm_500_config.config.contents.ts = 0.016\ndata_ofdm_500_config.config.contents.rs = 1.0 / data_ofdm_500_config.config.contents.ts\ndata_ofdm_500_config.config.contents.nc = 8\ndata_ofdm_500_config.config.contents.timing_mx_thresh = 0.1\ndata_ofdm_500_config.config.contents.bad_uw_errors = 18\ndata_ofdm_500_config.config.contents.codename = \"H_1024_2048_4f\".encode('utf-8')\ndata_ofdm_500_config.config.contents.amp_scale = 300E3 # 290E3\ndata_ofdm_500_config.config.contents.nuwbits = 56\ndata_ofdm_500_config.config.contents.tx_uw = create_tx_uw(data_ofdm_500_config.config.contents.nuwbits, [0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1])\ndata_ofdm_500_config.config.contents.clip_gain1 = 2.5 # 2.8\ndata_ofdm_500_config.config.contents.clip_gain2 = 1.0 #0.9\ndata_ofdm_500_config.config.contents.tx_bpf_en = True\ndata_ofdm_500_config.config.contents.tx_bpf_proto = codec2_filter_coeff.generate_filter_coefficients(8000, 600, 100)\ndata_ofdm_500_config.config.contents.tx_bpf_proto_n = 100\n\n\n# DATAC1 # OFDM1700\ndata_ofdm_1700_config = create_default_ofdm_config()\ndata_ofdm_1700_config.config.contents.ns = 5\ndata_ofdm_1700_config.config.contents.np = 38\ndata_ofdm_1700_config.config.contents.tcp = 0.006\ndata_ofdm_1700_config.config.contents.ts = 0.016\ndata_ofdm_1700_config.config.contents.nc = 27\ndata_ofdm_1700_config.config.contents.nuwbits = 16\ndata_ofdm_1700_config.config.contents.timing_mx_thresh = 0.10\ndata_ofdm_1700_config.config.contents.bad_uw_errors = 6\ndata_ofdm_1700_config.config.contents.codename = b\"H_4096_8192_3d\"\ndata_ofdm_1700_config.config.contents.clip_gain1 = 2.7\ndata_ofdm_1700_config.config.contents.clip_gain2 = 0.8\ndata_ofdm_1700_config.config.contents.amp_scale = 145E3\ndata_ofdm_1700_config.config.contents.tx_bpf_en = False\ndata_ofdm_1700_config.config.contents.tx_bpf_proto = codec2_filter_coeff.generate_filter_coefficients(8000, 2000, 100)\ndata_ofdm_1700_config.config.contents.tx_bpf_proto_n = 100\ndata_ofdm_1700_config.config.contents.tx_uw = create_tx_uw(data_ofdm_1700_config.config.contents.nuwbits, [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n\n\n\"\"\"\n# DATAC3\ndata_ofdm_500_config = create_default_ofdm_config()\ndata_ofdm_500_config.config.contents.ns = 5\ndata_ofdm_500_config.config.contents.np = 29\ndata_ofdm_500_config.config.contents.tcp = 0.006\ndata_ofdm_500_config.config.contents.ts = 0.016\ndata_ofdm_500_config.config.contents.rs = 1.0 / data_ofdm_500_config.config.contents.ts\ndata_ofdm_500_config.config.contents.nc = 9\ndata_ofdm_500_config.config.contents.nuwbits = 40\ndata_ofdm_500_config.config.contents.timing_mx_thresh = 0.10\ndata_ofdm_500_config.config.contents.bad_uw_errors = 10\ndata_ofdm_500_config.config.contents.codename = b\"H_1024_2048_4f\"\ndata_ofdm_500_config.config.contents.clip_gain1 = 2.2\ndata_ofdm_500_config.config.contents.clip_gain2 = 0.8\ndata_ofdm_500_config.config.contents.tx_uw = create_tx_uw(data_ofdm_500_config.config.contents.nuwbits, [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n\"\"\"\n\n# ---------------- OFDM 2438 Hz Bandwidth 16200,9720 ---------------#\ndata_ofdm_2438_config = create_default_ofdm_config()\ndata_ofdm_2438_config.config.contents.ns = 5\ndata_ofdm_2438_config.config.contents.np = 52\ndata_ofdm_2438_config.config.contents.tcp = 0.004\ndata_ofdm_2438_config.config.contents.ts = 0.016\ndata_ofdm_2438_config.config.contents.rs = 1.0 / data_ofdm_2438_config.config.contents.ts\ndata_ofdm_2438_config.config.contents.nc = 39\ndata_ofdm_2438_config.config.contents.nuwbits = 24\ndata_ofdm_2438_config.config.contents.timing_mx_thresh = 0.10\ndata_ofdm_2438_config.config.contents.bad_uw_errors = 8\ndata_ofdm_2438_config.config.contents.amp_est_mode = 0\ndata_ofdm_2438_config.config.contents.amp_scale = 106E3\ndata_ofdm_2438_config.config.contents.codename = \"H_16200_9720\".encode('utf-8')\ndata_ofdm_2438_config.config.contents.clip_gain1 = 3.3\ndata_ofdm_2438_config.config.contents.clip_gain2 = 0.8\ndata_ofdm_2438_config.config.contents.timing_mx_thresh = 0.10\ndata_ofdm_2438_config.config.contents.tx_uw = create_tx_uw(data_ofdm_2438_config.config.contents.nuwbits, [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1])\ndata_ofdm_2438_config.config.contents.tx_bpf_en = True\ndata_ofdm_2438_config.config.contents.tx_bpf_proto = codec2_filter_coeff.generate_filter_coefficients(8000, 2500, 100)\ndata_ofdm_2438_config.config.contents.tx_bpf_proto_n = 100\n\n# ---------------- QAM 2438 Hz Bandwidth ---------------#\n\"\"\"\ndata_qam_2438_config = create_default_ofdm_config()\ndata_qam_2438_config.config.contents.bps = 4\ndata_qam_2438_config.config.contents.ns = 5\ndata_qam_2438_config.config.contents.np = 26\ndata_qam_2438_config.config.contents.tcp = 0.005\ndata_qam_2438_config.config.contents.ts = 0.018\ndata_qam_2438_config.config.contents.rs = 1.0 / data_qam_2438_config.config.contents.ts\ndata_qam_2438_config.config.contents.nc = 39\ndata_qam_2438_config.config.contents.nuwbits = 162\ndata_qam_2438_config.config.contents.timing_mx_thresh = 0.10\ndata_qam_2438_config.config.contents.bad_uw_errors = 50\ndata_qam_2438_config.config.contents.amp_est_mode = 0\ndata_qam_2438_config.config.contents.amp_scale = 145E3\ndata_qam_2438_config.config.contents.codename = b\"H_16200_9720\"\ndata_qam_2438_config.config.contents.clip_gain1 = 2.7\ndata_qam_2438_config.config.contents.clip_gain2 = 0.8\ndata_qam_2438_config.config.contents.timing_mx_thresh = 0.10\ndata_qam_2438_config.config.contents.tx_uw = create_tx_uw(162, [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n\"\"\"\n\nofdm_configurations = {\n    FREEDV_MODE.data_ofdm_200.value: data_ofdm_200_config,\n    FREEDV_MODE.data_ofdm_250.value: data_ofdm_250_config,\n    FREEDV_MODE.data_ofdm_500.value: data_ofdm_500_config,\n    FREEDV_MODE.data_ofdm_1700.value: data_ofdm_1700_config,\n    FREEDV_MODE.data_ofdm_2438.value: data_ofdm_2438_config,\n    #FREEDV_MODE.data_qam_2438.value: data_qam_2438_config\n\n}\n"}
{"type": "source_file", "path": "freedata_server/command_p2p_connection.py", "content": "import queue\nfrom command import TxCommand\nimport api_validations\nimport base64\nfrom queue import Queue\nfrom p2p_connection import P2PConnection\n\nclass P2PConnectionCommand(TxCommand):\n\n    def set_params_from_api(self, apiParams):\n        self.origin = apiParams['origin']\n        if not api_validations.validate_freedata_callsign(self.origin):\n            self.origin = f\"{self.origin}-0\"\n\n        self.destination = apiParams['destination']\n        if not api_validations.validate_freedata_callsign(self.destination):\n            self.destination = f\"{self.destination}-0\"\n\n\n    def connect(self, event_queue: Queue, modem):\n        pass\n\n    def run(self, event_queue: Queue, modem):\n        try:\n            self.emit_event(event_queue)\n            session = P2PConnection(self.config, modem, self.origin, self.destination, self.state_manager, self.event_manager, self.socket_command_handler)\n            print(session)\n            if session.session_id:\n                self.state_manager.register_p2p_connection_session(session)\n                session.connect()\n                return session\n            return False\n\n        except Exception as e:\n            self.log(f\"Error starting P2P Connection session: {e}\", isWarning=True)\n\n        return False"}
{"type": "source_file", "path": "freedata_server/command_beacon.py", "content": "from command import TxCommand\n\nclass BeaconCommand(TxCommand):\n\n    def build_frame(self):\n        beacon_state = self.state_manager.is_away_from_key\n        return self.frame_factory.build_beacon(beacon_state)\n\n\n    #def transmit(self, freedata_server):\n    #    super().transmit(freedata_server)\n    #    if self.config['MODEM']['enable_morse_identifier']:\n    #        mycall = f\"{self.config['STATION']['mycall']}-{self.config['STATION']['myssid']}\"\n    #        freedata_server.transmit_morse(\"morse\", 1, 0, mycall)\n"}
{"type": "source_file", "path": "freedata_server/command_arq_raw.py", "content": "import queue\nfrom command import TxCommand\nimport api_validations\nimport base64\nfrom queue import Queue\nfrom arq_session_iss import ARQSessionISS\nfrom arq_data_type_handler import ARQ_SESSION_TYPES\nimport numpy as np\nimport threading\n\nclass ARQRawCommand(TxCommand):\n\n    def set_params_from_api(self, apiParams):\n        self.dxcall = apiParams['dxcall']\n        if not api_validations.validate_freedata_callsign(self.dxcall):\n            self.dxcall = f\"{self.dxcall}-0\"\n\n        try:\n            self.type = ARQ_SESSION_TYPES[apiParams['type']]\n        except KeyError:\n            self.type = ARQ_SESSION_TYPES.raw\n\n        self.data = base64.b64decode(apiParams['data'])\n\n    def run(self, event_queue: Queue, modem):\n        try:\n            self.emit_event(event_queue)\n            self.logger.info(self.log_message())\n\n            # wait some random time and wait if we have an ongoing codec2 transmission\n            # on our channel. This should prevent some packet collision\n            random_delay = np.random.randint(0, 6)\n            threading.Event().wait(random_delay)\n            self.state_manager.channel_busy_condition_codec2.wait(5)\n\n            prepared_data, type_byte = self.arq_data_type_handler.prepare(self.data, self.type)\n\n            iss = ARQSessionISS(self.config, modem, self.dxcall, self.state_manager, prepared_data, type_byte)\n            if iss.id:\n                self.state_manager.register_arq_iss_session(iss)\n                iss.start()\n                return iss\n        except Exception as e:\n            self.log(f\"Error starting ARQ session: {e}\", isWarning=True)\n\n        return False"}
{"type": "source_file", "path": "freedata_server/data_frame_factory.py", "content": "from modem_frametypes import FRAME_TYPE as FR_TYPE\nimport helpers\nimport codec2\nimport maidenhead\n\nclass DataFrameFactory:\n\n    LENGTH_SIG0_FRAME = 14\n    LENGTH_SIG1_FRAME = 14\n    LENGTH_ACK_FRAME = 3\n\n    \"\"\"\n        helpers.set_flag(byte, 'DATA-ACK-NACK', True, FLAG_POSITIONS)\n        helpers.get_flag(byte, 'DATA-ACK-NACK', FLAG_POSITIONS)    \n    \"\"\"\n    ARQ_FLAGS = {\n        'FINAL': 0,  # Bit-position for indicating the FINAL state\n        'ABORT': 1, # Bit-position for indicating the ABORT request\n        'CHECKSUM': 2,  # Bit-position for indicating the CHECKSUM is correct or not\n    }\n\n    BEACON_FLAGS = {\n        'AWAY_FROM_KEY': 0,  # Bit-position for indicating the AWAY FROM KEY state\n    }\n\n    def __init__(self, config):\n\n        self.myfullcall = f\"{config['STATION']['mycall']}-{config['STATION']['myssid']}\"\n        self.mygrid = maidenhead.generate_full_maidenhead(config[\"STATION\"][\"mygrid\"])\n\n        # table for holding our frame templates\n        self.template_list = {}\n\n        self._load_broadcast_templates()\n        self._load_ping_templates()\n        self._load_arq_templates()\n        self._load_p2p_connection_templates()\n\n    def _load_broadcast_templates(self):\n        # cq frame\n        self.template_list[FR_TYPE.CQ.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"origin\": 6,\n            \"gridsquare\": 4\n        }\n\n        # qrv frame\n        self.template_list[FR_TYPE.QRV.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"origin\": 6,\n            \"gridsquare\": 4,\n            \"snr\": 1\n        }\n\n        # beacon frame\n        self.template_list[FR_TYPE.BEACON.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"origin\": 6,\n            \"gridsquare\": 4,\n            \"flag\": 1\n        }\n\n    def _load_ping_templates(self):\n        # ping frame\n        self.template_list[FR_TYPE.PING.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"destination_crc\": 3,\n            \"origin_crc\": 3,\n            \"origin\": 6\n        }\n\n        # ping ack\n        self.template_list[FR_TYPE.PING_ACK.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"destination_crc\": 3,\n            \"origin_crc\": 3,\n            \"gridsquare\": 4,\n            \"snr\": 1,\n        }\n\n\n    def _load_arq_templates(self):\n\n        self.template_list[FR_TYPE.ARQ_SESSION_OPEN.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"destination_crc\": 3,\n            \"origin\": 6,\n            \"session_id\": 1,\n            \"maximum_bandwidth\": 2,\n            \"protocol_version\" : 1\n        }\n\n        self.template_list[FR_TYPE.ARQ_SESSION_OPEN_ACK.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"session_id\": 1,\n            \"origin\": 6,\n            \"destination_crc\": 3,\n            \"version\": 1,\n            \"snr\": 1,\n            \"flag\": 1,\n        }\n\n        self.template_list[FR_TYPE.ARQ_SESSION_INFO.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"session_id\": 1,\n            \"total_length\": 4,\n            \"total_crc\": 4,\n            \"snr\": 1,\n            \"flag\": 1,\n            \"type\": 1,\n        }\n\n        self.template_list[FR_TYPE.ARQ_SESSION_INFO_ACK.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"session_id\": 1,\n            \"offset\": 4,\n            \"snr\": 1,\n            \"speed_level\": 1,\n            \"frames_per_burst\": 1,\n            \"flag\": 1,\n        }\n\n        self.template_list[FR_TYPE.ARQ_STOP.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"session_id\": 1,\n        }\n\n        self.template_list[FR_TYPE.ARQ_STOP_ACK.value] = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"session_id\": 1,\n        }\n\n        # arq burst frame\n        self.template_list[FR_TYPE.ARQ_BURST_FRAME.value] = {\n            \"frame_length\": None,\n            \"session_id\": 1,\n            \"speed_level\": 1,\n            \"offset\": 4,\n            \"data\": \"dynamic\",\n        }\n\n        # arq burst ack\n        self.template_list[FR_TYPE.ARQ_BURST_ACK.value] = {\n            \"frame_length\": self.LENGTH_ACK_FRAME,\n            \"session_id\": 1,\n            #\"offset\":4,\n            \"speed_level\": 1,\n            #\"frames_per_burst\": 1,\n            #\"snr\": 1,\n            \"flag\": 1,\n        }\n    \n    def _load_p2p_connection_templates(self):\n        # p2p connect request\n        self.template_list[FR_TYPE.P2P_CONNECTION_CONNECT.value] = {\n            \"frame_length\": self.LENGTH_SIG1_FRAME,\n            \"destination_crc\": 3,\n            \"origin\": 6,\n            \"session_id\": 1,\n        }\n        \n        # connect ACK\n        self.template_list[FR_TYPE.P2P_CONNECTION_CONNECT_ACK.value] = {\n            \"frame_length\": self.LENGTH_SIG1_FRAME,\n            \"destination_crc\": 3,\n            \"origin\": 6,\n            \"session_id\": 1,\n        }\n        \n        # heartbeat for \"is alive\"\n        self.template_list[FR_TYPE.P2P_CONNECTION_HEARTBEAT.value] = {\n            \"frame_length\": self.LENGTH_SIG1_FRAME,\n            \"session_id\": 1,\n        }\n\n        # ack heartbeat\n        self.template_list[FR_TYPE.P2P_CONNECTION_HEARTBEAT_ACK.value] = {\n            \"frame_length\": self.LENGTH_SIG1_FRAME,\n            \"session_id\": 1,\n        }\n\n        # p2p payload frames\n        self.template_list[FR_TYPE.P2P_CONNECTION_PAYLOAD.value] = {\n            \"frame_length\": None,\n            \"session_id\": 1,\n            \"sequence_id\": 1,\n            \"data\": \"dynamic\",\n        }\n\n        # p2p payload frame ack\n        self.template_list[FR_TYPE.P2P_CONNECTION_PAYLOAD_ACK.value] = {\n            \"frame_length\": self.LENGTH_SIG1_FRAME,\n            \"session_id\": 1,\n            \"sequence_id\": 1,\n        }\n        \n        # heartbeat for \"is alive\"\n        self.template_list[FR_TYPE.P2P_CONNECTION_DISCONNECT.value] = {\n            \"frame_length\": self.LENGTH_SIG1_FRAME,\n            \"session_id\": 1,\n        }\n\n        # ack heartbeat\n        self.template_list[FR_TYPE.P2P_CONNECTION_DISCONNECT_ACK.value] = {\n            \"frame_length\": self.LENGTH_SIG1_FRAME,\n            \"session_id\": 1,\n        }\n\n\n\n    def construct(self, frametype, content, frame_length = LENGTH_SIG1_FRAME):\n        frame_template = self.template_list[frametype.value]\n\n        if isinstance(frame_template[\"frame_length\"], int):\n            frame_length = frame_template[\"frame_length\"]\n        else:\n            frame_length -= 2\n\n        frame = bytearray(frame_length)\n        if frametype in [FR_TYPE.ARQ_BURST_ACK]:\n            buffer_position = 0\n        else:\n            frame[:1] = bytes([frametype.value])\n            buffer_position = 1\n        for key, item_length in frame_template.items():\n            if key == \"frame_length\":\n                continue\n\n            if not isinstance(item_length, int):\n                item_length = len(content[key])\n            if buffer_position + item_length > frame_length:\n                raise OverflowError(\"Frame data overflow!\")\n            frame[buffer_position: buffer_position + item_length] = content[key]\n            buffer_position += item_length\n\n        return frame\n\n    def deconstruct(self, frame, mode_name=None):\n\n        buffer_position = 1\n        # Handle the case where the frame type is not recognized\n        #raise ValueError(f\"Unknown frame type: {frametype}\")\n        if mode_name in [\"SIGNALLING_ACK\"]:\n            frametype = FR_TYPE.ARQ_BURST_ACK.value\n            frame_template = self.template_list.get(frametype)\n            frame = bytes([frametype]) + frame\n        else:\n            # Extract frametype and get the corresponding template\n            frametype = int.from_bytes(frame[:1], \"big\")\n            frame_template = self.template_list.get(frametype)\n\n        extracted_data = {\"frame_type\": FR_TYPE(frametype).name, \"frame_type_int\": frametype}\n\n        for key, item_length in frame_template.items():\n            if key == \"frame_length\":\n                continue\n\n            # data is always on the last payload slots\n            if item_length in [\"dynamic\"] and key in[\"data\"]:\n                print(len(frame))\n                data = frame[buffer_position:-2]\n                item_length = len(data)\n            else:\n                data = frame[buffer_position: buffer_position + item_length]\n\n            # Process the data based on the key\n            if key in [\"origin\", \"destination\"]:\n                extracted_data[key] = helpers.bytes_to_callsign(data).decode()\n\n            elif key in [\"origin_crc\", \"destination_crc\", \"total_crc\"]:\n                extracted_data[key] = data.hex()\n\n            elif key == \"gridsquare\":\n                extracted_data[key] = helpers.decode_grid(data)\n\n            elif key in [\"session_id\", \"speed_level\", \n                            \"frames_per_burst\", \"version\",\n                            \"offset\", \"total_length\", \"state\", \"type\", \"maximum_bandwidth\", \"protocol_version\"]:\n                extracted_data[key] = int.from_bytes(data, 'big')\n\n            elif key in [\"snr\"]:\n                extracted_data[key] = helpers.snr_from_bytes(data)\n\n            elif key == \"flag\":\n\n                data = int.from_bytes(data, \"big\")\n                extracted_data[key] = {}\n                # check for frametype for selecting the correspinding flag dictionary\n                if frametype in [FR_TYPE.ARQ_SESSION_OPEN_ACK.value, FR_TYPE.ARQ_SESSION_INFO_ACK.value, FR_TYPE.ARQ_BURST_ACK.value]:\n                    flag_dict = self.ARQ_FLAGS\n                    for flag in flag_dict:\n                        # Update extracted_data with the status of each flag\n                        # get_flag returns True or False based on the bit value at the flag's position\n                        extracted_data[key][flag] = helpers.get_flag(data, flag, flag_dict)\n\n                if frametype in [FR_TYPE.BEACON.value]:\n                    flag_dict = self.BEACON_FLAGS\n                    for flag in flag_dict:\n                        # Update extracted_data with the status of each flag\n                        # get_flag returns True or False based on the bit value at the flag's position\n                        extracted_data[key][flag] = helpers.get_flag(data, flag, flag_dict)\n\n\n            else:\n                extracted_data[key] = data\n\n            buffer_position += item_length\n\n        return extracted_data\n\n    def get_bytes_per_frame(self, mode: codec2.FREEDV_MODE) -> int:\n        freedv = codec2.open_instance(mode.value)\n        bytes_per_frame = int(codec2.api.freedv_get_bits_per_modem_frame(freedv) / 8)\n        return bytes_per_frame\n    \n    def get_available_data_payload_for_mode(self, type: FR_TYPE, mode:codec2.FREEDV_MODE):\n        whole_frame_length = self.get_bytes_per_frame(mode)\n        available = whole_frame_length - 2 # 2Bytes CRC16\n        available -= 1 # Frame Type\n        for field, length in self.template_list[type.value].items():\n            if field != 'frame_length' and isinstance(length, int):\n                available -= length\n        return available\n\n    def build_ping(self, destination):\n        payload = {\n            \"destination_crc\": helpers.get_crc_24(destination),\n            \"origin_crc\": helpers.get_crc_24(self.myfullcall),\n            \"origin\": helpers.callsign_to_bytes(self.myfullcall),\n        }\n        return self.construct(FR_TYPE.PING, payload)\n\n    def build_ping_ack(self, destination, snr):\n        payload = {\n            \"destination_crc\": helpers.get_crc_24(destination),\n            \"origin_crc\": helpers.get_crc_24(self.myfullcall),\n            \"gridsquare\": helpers.encode_grid(self.mygrid),\n            \"snr\": helpers.snr_to_bytes(snr)\n        }\n        return self.construct(FR_TYPE.PING_ACK, payload)\n\n    def build_cq(self):\n        payload = {\n            \"origin\": helpers.callsign_to_bytes(self.myfullcall),\n            \"gridsquare\": helpers.encode_grid(self.mygrid)\n        }\n        return self.construct(FR_TYPE.CQ, payload)\n\n    def build_qrv(self, snr):\n        payload = {\n            \"origin\": helpers.callsign_to_bytes(self.myfullcall),\n            \"gridsquare\": helpers.encode_grid(self.mygrid),\n            \"snr\": helpers.snr_to_bytes(snr)\n        }\n        return self.construct(FR_TYPE.QRV, payload)\n\n    def build_beacon(self, flag_away_from_key=False):\n        flag = 0b00000000\n        if flag_away_from_key:\n            flag = helpers.set_flag(flag, 'AWAY_FROM_KEY', True, self.BEACON_FLAGS)\n\n        payload = {\n            \"origin\": helpers.callsign_to_bytes(self.myfullcall),\n            \"gridsquare\": helpers.encode_grid(self.mygrid),\n            \"flag\": flag.to_bytes(1, 'big'),\n\n        }\n        return self.construct(FR_TYPE.BEACON, payload)\n\n    def build_fec_is_writing(self):\n        payload = {\n            \"origin\": helpers.callsign_to_bytes(self.myfullcall),\n        }\n        return self.construct(FR_TYPE.IS_WRITING, payload)\n\n    def build_fec_wakeup(self, mode):\n        mode_int = codec2.freedv_get_mode_value_by_name(mode)\n\n        payload = {\n            \"origin\": helpers.callsign_to_bytes(self.myfullcall),\n            \"mode\": bytes([mode_int]),\n            \"n_bursts\": bytes([1]) # n payload bursts,\n\n        }\n        return self.construct(FR_TYPE.FEC_WAKEUP, payload)\n\n    def build_fec(self, mode, payload):\n        mode_int = codec2.freedv_get_mode_value_by_name(mode)\n        payload_per_frame = codec2.get_bytes_per_frame(mode_int) - 2\n        fec_payload_length = payload_per_frame - 1\n        fec_frame = bytearray(payload_per_frame)\n        fec_frame[:1] = bytes([FR_TYPE.FEC.value])\n        fec_frame[1:payload_per_frame] = bytes(payload[:fec_payload_length])\n        return fec_frame\n\n    def build_test(self, mode):\n        mode_int = codec2.freedv_get_mode_value_by_name(mode)\n        payload_per_frame = codec2.get_bytes_per_frame(mode_int) - 2\n        test_frame = bytearray(payload_per_frame)\n        test_frame[:1] = bytes([FR_TYPE.TEST_FRAME.value])\n        return test_frame\n\n    def build_arq_session_open(self, destination, session_id, maximum_bandwidth, protocol_version):\n        payload = {\n            \"destination_crc\": helpers.get_crc_24(destination),\n            \"origin\": helpers.callsign_to_bytes(self.myfullcall),\n            \"session_id\": session_id.to_bytes(1, 'big'),\n            \"maximum_bandwidth\": maximum_bandwidth.to_bytes(2, 'big'),\n            \"protocol_version\": protocol_version.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.ARQ_SESSION_OPEN, payload)\n\n    def build_arq_session_open_ack(self, session_id, destination, version, snr, flag_abort=False):\n        flag = 0b00000000\n        if flag_abort:\n            flag = helpers.set_flag(flag, 'ABORT', True, self.ARQ_FLAGS)\n\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n            \"origin\": helpers.callsign_to_bytes(self.myfullcall),\n            \"destination_crc\": helpers.get_crc_24(destination),\n            \"version\": bytes([version]),\n            \"snr\": helpers.snr_to_bytes(1),\n            \"flag\": flag.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.ARQ_SESSION_OPEN_ACK, payload)\n    \n    def build_arq_session_info(self, session_id: int, total_length: int, total_crc: bytes, snr, type):\n        flag = 0b00000000\n\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n            \"total_length\": total_length.to_bytes(4, 'big'),\n            \"total_crc\": total_crc,\n            \"snr\": helpers.snr_to_bytes(1),\n            \"flag\": flag.to_bytes(1, 'big'),\n            \"type\": type.to_bytes(1, 'big'),\n\n        }\n        return self.construct(FR_TYPE.ARQ_SESSION_INFO, payload)\n\n    def build_arq_stop(self, session_id: int):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.ARQ_STOP, payload)\n\n    def build_arq_stop_ack(self, session_id: int):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.ARQ_STOP_ACK, payload)\n\n    def build_arq_session_info_ack(self, session_id, offset, snr, speed_level, frames_per_burst, flag_final=False, flag_abort=False):\n        flag = 0b00000000\n        if flag_final:\n            flag = helpers.set_flag(flag, 'FINAL', True, self.ARQ_FLAGS)\n        if flag_abort:\n            flag = helpers.set_flag(flag, 'ABORT', True, self.ARQ_FLAGS)\n\n        payload = {\n            \"frame_length\": self.LENGTH_SIG0_FRAME,\n            \"session_id\": session_id.to_bytes(1, 'big'),\n            \"offset\": offset.to_bytes(4, 'big'),\n            \"snr\": helpers.snr_to_bytes(1),\n            \"speed_level\": speed_level.to_bytes(1, 'big'),\n            \"frames_per_burst\": frames_per_burst.to_bytes(1, 'big'),\n            \"flag\": flag.to_bytes(1, 'big'),\n        }        \n        return self.construct(FR_TYPE.ARQ_SESSION_INFO_ACK, payload)\n\n    def build_arq_burst_frame(self, freedv_mode: codec2.FREEDV_MODE, session_id: int, offset: int, data: bytes, speed_level: int):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n            \"speed_level\": speed_level.to_bytes(1, 'big'),\n            \"offset\": offset.to_bytes(4, 'big'),\n            \"data\": data,\n        }\n        return self.construct(\n            FR_TYPE.ARQ_BURST_FRAME, payload, self.get_bytes_per_frame(freedv_mode)\n        )\n\n    def build_arq_burst_ack(self, session_id: bytes, speed_level: int, flag_final=False, flag_checksum=False, flag_abort=False):\n        flag = 0b00000000\n        if flag_final:\n            flag = helpers.set_flag(flag, 'FINAL', True, self.ARQ_FLAGS)\n\n        if flag_checksum:\n            flag = helpers.set_flag(flag, 'CHECKSUM', True, self.ARQ_FLAGS)\n\n        if flag_abort:\n            flag = helpers.set_flag(flag, 'ABORT', True, self.ARQ_FLAGS)\n\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n            \"speed_level\": speed_level.to_bytes(1, 'big'),\n            \"flag\": flag.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.ARQ_BURST_ACK, payload)\n    \n    def build_p2p_connection_connect(self, destination, origin, session_id):\n        payload = {\n            \"destination_crc\": helpers.get_crc_24(destination),\n            \"origin\": helpers.callsign_to_bytes(origin),\n            \"session_id\": session_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.P2P_CONNECTION_CONNECT, payload)\n    \n    def build_p2p_connection_connect_ack(self, destination, origin, session_id):\n        payload = {\n            \"destination_crc\": helpers.get_crc_24(destination),\n            \"origin\": helpers.callsign_to_bytes(origin),\n            \"session_id\": session_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.P2P_CONNECTION_CONNECT_ACK, payload)\n    \n    def build_p2p_connection_heartbeat(self, session_id):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.P2P_CONNECTION_HEARTBEAT, payload)\n    \n    def build_p2p_connection_heartbeat_ack(self, session_id):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.P2P_CONNECTION_HEARTBEAT_ACK, payload)\n    \n    def build_p2p_connection_payload(self, freedv_mode: codec2.FREEDV_MODE, session_id: int, sequence_id: int, data: bytes):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n            \"sequence_id\": sequence_id.to_bytes(1, 'big'),\n            \"data\": data,\n        }\n        return self.construct(\n            FR_TYPE.P2P_CONNECTION_PAYLOAD,\n            payload,\n            self.get_bytes_per_frame(freedv_mode),\n        )\n    \n    def build_p2p_connection_payload_ack(self, session_id, sequence_id):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n            \"sequence_id\": sequence_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.P2P_CONNECTION_PAYLOAD_ACK, payload)\n\n    def build_p2p_connection_disconnect(self, session_id):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.P2P_CONNECTION_DISCONNECT, payload)\n\n    def build_p2p_connection_disconnect_ack(self, session_id):\n        payload = {\n            \"session_id\": session_id.to_bytes(1, 'big'),\n        }\n        return self.construct(FR_TYPE.P2P_CONNECTION_DISCONNECT_ACK, payload)\n"}
{"type": "source_file", "path": "freedata_server/command_transmit_sine.py", "content": "from command import TxCommand\n\nclass TransmitSine(TxCommand):\n    def transmit(self, modem):\n        modem.transmit_sine()\n        # Code for debugging morse stuff...\n        #modem.transmit_morse(0,0,[b''])"}
{"type": "source_file", "path": "freedata_server/command_qrv.py", "content": "from command import TxCommand\n\nclass QRVCommand(TxCommand):\n\n    def build_frame(self):\n        return self.frame_factory.build_qrv()\n"}
{"type": "source_file", "path": "freedata_server/demodulator.py", "content": "import numpy as np\nimport codec2\nimport ctypes\nimport structlog\nimport threading\nimport audio\nimport itertools\n\nTESTMODE = False\n\nclass Demodulator():\n\n    MODE_DICT = {}\n    # Iterate over the FREEDV_MODE enum members\n    for mode in codec2.FREEDV_MODE:\n            MODE_DICT[mode.value] = {\n                'decode': False,\n                'bytes_per_frame': None,\n                'bytes_out': None,\n                'audio_buffer': None,\n                'nin': None,\n                'instance': None,\n                'state_buffer': [],\n                'name': mode.name.upper(),\n                'decoding_thread': None\n            }\n\n    def __init__(self, config, audio_rx_q, data_q_rx, states, event_manager, service_queue, fft_queue):\n        self.log = structlog.get_logger(\"Demodulator\")\n        self.config = config\n\n        self.shutdown_flag = threading.Event()\n\n        self.service_queue = service_queue\n        self.AUDIO_FRAMES_PER_BUFFER_RX = 4800\n        self.buffer_overflow_counter = [0] * len(codec2.FREEDV_MODE)\n        self.is_codec2_traffic_counter = 0\n        self.is_codec2_traffic_cooldown = 5\n\n        self.audio_received_queue = audio_rx_q\n        self.data_queue_received = data_q_rx\n\n        self.states = states\n        self.event_manager = event_manager\n\n        self.fft_queue = fft_queue\n\n        # Audio Stream object\n        self.stream = None\n\n        # init codec2 resampler\n        self.resampler = codec2.resampler()\n\n        self.init_codec2()\n        self.init_tci()\n\n        # enable decoding of signalling modes\n        self.MODE_DICT[codec2.FREEDV_MODE.signalling.value][\"decode\"] = True\n        self.MODE_DICT[codec2.FREEDV_MODE.signalling_ack.value][\"decode\"] = True\n\n\n    def init_codec2(self):\n        # Open codec2 instances\n        for mode in codec2.FREEDV_MODE:\n            self.init_codec2_mode(mode.value)\n\n    def init_tci(self):\n        if self.config['RADIO']['control'] == \"tci\":\n            tci_rx_callback_thread = threading.Thread(\n                target=self.tci_rx_callback,\n                name=\"TCI RX CALLBACK THREAD\",\n                daemon=True,\n            )\n            tci_rx_callback_thread.start()\n\n\n    def init_codec2_mode(self, mode):\n        \"\"\"\n        Init codec2 and return some important parameters\n        \"\"\"\n\n        # create codec2 instance\n        #c2instance = ctypes.cast(\n        c2instance = codec2.open_instance(mode)\n\n        # get bytes per frame\n        bytes_per_frame = int(\n            codec2.api.freedv_get_bits_per_modem_frame(c2instance) / 8\n        )\n        # create byte out buffer\n        bytes_out = ctypes.create_string_buffer(bytes_per_frame)\n\n        # set initial frames per burst\n        codec2.api.freedv_set_frames_per_burst(c2instance, 1)\n\n        # init audio buffer\n        audio_buffer = codec2.audio_buffer(2 * self.AUDIO_FRAMES_PER_BUFFER_RX)\n\n        # get initial nin\n        nin = codec2.api.freedv_nin(c2instance)\n\n        # Additional Datac0-specific information - these are not referenced anywhere else.\n        # self.signalling_datac0_payload_per_frame = self.signalling_datac0_bytes_per_frame - 2\n        # self.signalling_datac0_n_nom_modem_samples = codec2.api.freedv_get_n_nom_modem_samples(\n        #     self.signalling_datac0_freedv\n        # )\n        # self.signalling_datac0_n_tx_modem_samples = codec2.api.freedv_get_n_tx_modem_samples(\n        #     self.signalling_datac0_freedv\n        # )\n        # self.signalling_datac0_n_tx_preamble_modem_samples = (\n        #     codec2.api.freedv_get_n_tx_preamble_modem_samples(self.signalling_datac0_freedv)\n        # )\n        # self.signalling_datac0_n_tx_postamble_modem_samples = (\n        #     codec2.api.freedv_get_n_tx_postamble_modem_samples(self.signalling_datac0_freedv)\n        # )\n\n        self.MODE_DICT[mode][\"instance\"] = c2instance\n        self.MODE_DICT[mode][\"bytes_per_frame\"] = bytes_per_frame\n        self.MODE_DICT[mode][\"bytes_out\"] = bytes_out\n        self.MODE_DICT[mode][\"audio_buffer\"] = audio_buffer\n        self.MODE_DICT[mode][\"nin\"] = nin\n\n    def start(self, stream):\n        self.stream = stream\n\n        for mode in self.MODE_DICT:\n            # Start decoder threads\n            self.MODE_DICT[mode]['decoding_thread'] = threading.Thread(\n                target=self.demodulate_audio,args=[mode], name=self.MODE_DICT[mode]['name'], daemon=True\n            )\n            self.MODE_DICT[mode]['decoding_thread'].start()\n\n    def get_frequency_offset(self, freedv: ctypes.c_void_p) -> float:\n        \"\"\"\n        Ask codec2 for the calculated (audio) frequency offset of the received signal.\n\n        :param freedv: codec2 instance to query\n        :type freedv: ctypes.c_void_p\n        :return: Offset of audio frequency in Hz\n        :rtype: float\n        \"\"\"\n        modemStats = codec2.MODEMSTATS()\n        codec2.api.freedv_get_modem_extended_stats(freedv, ctypes.byref(modemStats))\n        offset = round(modemStats.foff) * (-1)\n        return offset\n\n    def demodulate_audio(self, mode) -> int:\n        \"\"\"\n        De-modulate supplied audio stream with supplied codec2 instance.\n        Decoded audio is placed into `bytes_out`.\n        \"\"\"\n\n        audiobuffer = self.MODE_DICT[mode][\"audio_buffer\"]\n        nin = self.MODE_DICT[mode][\"nin\"]\n        freedv = self.MODE_DICT[mode][\"instance\"]\n        bytes_out = self.MODE_DICT[mode][\"bytes_out\"]\n        bytes_per_frame= self.MODE_DICT[mode][\"bytes_per_frame\"]\n        state_buffer = self.MODE_DICT[mode][\"state_buffer\"]\n        mode_name = self.MODE_DICT[mode][\"name\"]\n        try:\n            while self.stream and self.stream.active and not self.shutdown_flag.is_set():\n                threading.Event().wait(0.01)\n                if audiobuffer.nbuffer >= nin and not self.shutdown_flag.is_set():\n                    # demodulate audio\n                    nbytes = codec2.api.freedv_rawdatarx(\n                        freedv, bytes_out, audiobuffer.buffer.ctypes\n                    )\n                    # get current freedata_server states and write to list\n                    # 1 trial\n                    # 2 sync\n                    # 3 trial sync\n                    # 6 decoded\n                    # 10 error decoding == NACK\n                    rx_status = codec2.api.freedv_get_rx_status(freedv)\n\n                    if rx_status not in [0]:\n                        self.is_codec2_traffic_counter = self.is_codec2_traffic_cooldown\n                        self.log.debug(\n                            \"[MDM] [demod_audio] freedata_server state\", mode=mode_name, rx_status=rx_status,\n                            sync_flag=codec2.api.rx_sync_flags_to_text[rx_status]\n                        )\n\n                    # decrement codec traffic counter for making state smoother\n                    if self.is_codec2_traffic_counter > 0:\n                        self.is_codec2_traffic_counter -= 1\n                        self.states.set_channel_busy_condition_codec2(True)\n                    else:\n                        self.states.set_channel_busy_condition_codec2(False)\n                    if rx_status == 10:\n                        state_buffer.append(rx_status)\n\n                    audiobuffer.pop(nin)\n                    nin = codec2.api.freedv_nin(freedv)\n                    if nbytes == bytes_per_frame:\n                        self.log.debug(\n                            \"[MDM] [demod_audio] Pushing received data to received_queue\", nbytes=nbytes, mode_name=mode_name\n                        )\n                        snr = self.calculate_snr(freedv)\n                        self.get_scatter(freedv)\n\n                        item = {\n                            'payload': bytes_out,\n                            'freedv': freedv,\n                            'bytes_per_frame': bytes_per_frame,\n                            'snr': snr,\n                            'frequency_offset': self.get_frequency_offset(freedv),\n                            'mode_name': mode_name\n                        }\n\n                        self.data_queue_received.put(item)\n\n\n                        state_buffer = []\n        except Exception as e:\n            error_message = str(e)\n            # we expect this error when shutdown\n            if error_message in [\"PortAudio not initialized [PaErrorCode -10000]\", \"Invalid stream pointer [PaErrorCode -9988]\"]:\n                return\n            else:\n                self.log.warning(\n                    \"[MDM] [demod_audio] demod loop ended\", mode=mode_name, e=e\n                )\n                audio.sd._terminate()\n\n    def tci_rx_callback(self) -> None:\n        \"\"\"\n        Callback for TCI RX\n\n        data_in48k must be filled with 48000Hz audio raw data\n\n        \"\"\"\n\n        while True and not self.shutdown_flag.is_set():\n\n            audio_48k = self.audio_received_queue.get()\n            audio_48k = np.frombuffer(audio_48k, dtype=np.int16)\n\n            audio.calculate_fft(audio_48k, self.fft_queue, self.states)\n\n            length_audio_48k = len(audio_48k)\n            index = 0\n            for mode in self.MODE_DICT:\n                mode_data = self.MODE_DICT[mode]\n                audiobuffer = mode_data['audio_buffer']\n                decode = mode_data['decode']\n                index += 1\n                if audiobuffer:\n                    if (audiobuffer.nbuffer + length_audio_48k) > audiobuffer.size:\n                        self.buffer_overflow_counter[index] += 1\n                        self.event_manager.send_buffer_overflow(self.buffer_overflow_counter)\n                    elif decode:\n                        audiobuffer.push(audio_48k)\n\n    def set_frames_per_burst(self, frames_per_burst: int) -> None:\n        \"\"\"\n        Configure codec2 to send the configured number of frames per burst.\n\n        :param frames_per_burst: Number of frames per burst requested\n        :type frames_per_burst: int\n        \"\"\"\n        # Limit frames per burst to acceptable values\n        frames_per_burst = min(frames_per_burst, 1)\n        frames_per_burst = max(frames_per_burst, 5)\n\n        # FIXME\n        frames_per_burst = 1\n\n        codec2.api.freedv_set_frames_per_burst(self.dat0_datac1_freedv, frames_per_burst)\n        codec2.api.freedv_set_frames_per_burst(self.dat0_datac3_freedv, frames_per_burst)\n        codec2.api.freedv_set_frames_per_burst(self.dat0_datac4_freedv, frames_per_burst)\n\n    def calculate_snr(self, freedv: ctypes.c_void_p) -> float:\n        \"\"\"\n        Ask codec2 for data about the received signal and calculate\n        the signal-to-noise ratio.\n\n        :param freedv: codec2 instance to query\n        :type freedv: ctypes.c_void_p\n        :return: Signal-to-noise ratio of the decoded data\n        :rtype: float\n        \"\"\"\n        try:\n            modem_stats_snr = ctypes.c_float()\n            modem_stats_sync = ctypes.c_int()\n\n            codec2.api.freedv_get_modem_stats(\n                freedv, ctypes.byref(modem_stats_sync), ctypes.byref(modem_stats_snr)\n            )\n            modem_stats_snr = modem_stats_snr.value\n            modem_stats_sync = modem_stats_sync.value\n\n            snr = round(modem_stats_snr, 1)\n            self.log.info(\"[MDM] calculate_snr: \", snr=snr)\n            # snr = np.clip(\n            #    snr, -127, 127\n            # )  # limit to max value of -128/128 as a possible fix of #188\n            return int(snr)\n        except Exception as err:\n            self.log.error(f\"[MDM] calculate_snr: Exception: {err}\")\n            return 0\n\n    def get_scatter(self, freedv: ctypes.c_void_p) -> None:\n        \"\"\"\n        Ask codec2 for data about the received signal and calculate the scatter plot.\n\n        :param freedv: codec2 instance to query\n        :type freedv: ctypes.c_void_p\n        \"\"\"\n       \n        modemStats = codec2.MODEMSTATS()\n        ctypes.cast(\n            codec2.api.freedv_get_modem_extended_stats(freedv, ctypes.byref(modemStats)),\n            ctypes.c_void_p,\n        )\n\n        scatterdata = []\n        # original function before itertool\n        # for i in range(codec2.MODEM_STATS_NC_MAX):\n        #    for j in range(1, codec2.MODEM_STATS_NR_MAX, 2):\n        #        # print(f\"{modemStats.rx_symbols[i][j]} - {modemStats.rx_symbols[i][j]}\")\n        #        xsymbols = round(modemStats.rx_symbols[i][j - 1] // 1000)\n        #        ysymbols = round(modemStats.rx_symbols[i][j] // 1000)\n        #        if xsymbols != 0.0 and ysymbols != 0.0:\n        #            scatterdata.append({\"x\": str(xsymbols), \"y\": str(ysymbols)})\n\n        for i, j in itertools.product(range(codec2.MODEM_STATS_NC_MAX), range(1, codec2.MODEM_STATS_NR_MAX, 2)):\n            # print(f\"{modemStats.rx_symbols[i][j]} - {modemStats.rx_symbols[i][j]}\")\n            xsymbols = round(modemStats.rx_symbols[i][j - 1] // 1000)\n            ysymbols = round(modemStats.rx_symbols[i][j] // 1000)\n            if xsymbols != 0.0 and ysymbols != 0.0:\n                scatterdata.append({\"x\": str(xsymbols), \"y\": str(ysymbols)})\n\n        # Send all the data if we have too-few samples, otherwise send a sampling\n        if 150 > len(scatterdata) > 0:\n            self.event_manager.send_scatter_change(scatterdata)\n\n        else:\n            # only take every tenth data point\n            self.event_manager.send_scatter_change(scatterdata[::10])\n\n    def reset_data_sync(self) -> None:\n        \"\"\"\n        reset sync state for modes\n\n        :param frames_per_burst: Number of frames per burst requested\n        :type frames_per_burst: int\n        \"\"\"\n        for mode in self.MODE_DICT:\n            codec2.api.freedv_set_sync(self.MODE_DICT[mode][\"instance\"], 0)\n\n    def set_decode_mode(self, modes_to_decode=None, is_irs=False):\n        # Reset all modes to not decode\n        for m in self.MODE_DICT:\n            self.MODE_DICT[m][\"decode\"] = False\n\n        # signalling is always true\n        self.MODE_DICT[codec2.FREEDV_MODE.signalling.value][\"decode\"] = True\n        # we only need to decode signalling ack as ISS\n        if is_irs:\n            self.MODE_DICT[codec2.FREEDV_MODE.signalling_ack.value][\"decode\"] = False\n        else:\n            self.MODE_DICT[codec2.FREEDV_MODE.signalling_ack.value][\"decode\"] = True\n\n\n        # lowest speed level is always true\n        self.MODE_DICT[codec2.FREEDV_MODE.datac4.value][\"decode\"] = True\n\n        # Enable specified modes\n        if modes_to_decode:\n            for mode, decode in modes_to_decode.items():\n                if mode in self.MODE_DICT:\n                    self.MODE_DICT[mode][\"decode\"] = decode\n\n    def shutdown(self):\n        print(\"shutting down demodulators...\")\n        self.shutdown_flag.set()\n        for mode in self.MODE_DICT:\n            self.MODE_DICT[mode]['decoding_thread'].join(3)"}
{"type": "source_file", "path": "freedata_server/event_manager.py", "content": "import base64\nimport json\nimport structlog\n\nclass EventManager:\n\n    def __init__(self, queues):\n        self.queues = queues\n        self.logger = structlog.get_logger('Event Manager')\n        self.lastpttstate = False\n\n    def broadcast(self, data):\n        for q in self.queues:\n            self.logger.debug(f\"Event: \", ev=data)\n            if q.qsize() > 10:\n                q.queue.clear()\n            q.put(data)\n\n    def send_ptt_change(self, on:bool = False):\n        if (on == self.lastpttstate):\n            return\n        self.lastpttstate= on\n        self.broadcast({\"ptt\": bool(on)})\n\n    def send_scatter_change(self, data):\n        self.broadcast({\"scatter\": json.dumps(data)})\n\n    def send_buffer_overflow(self, data):\n        self.broadcast({\"buffer-overflow\": str(data)})\n\n    def send_custom_event(self, **event_data):\n        self.broadcast(event_data)\n\n    def send_arq_session_new(self, outbound: bool, session_id, dxcall, total_bytes, state):\n        direction = 'outbound' if outbound else 'inbound'\n        event = {\n                \"type\": \"arq\",\n                f\"arq-transfer-{direction}\": {\n                'session_id': session_id,\n                'dxcall': dxcall,\n                'total_bytes': total_bytes,\n                'state': state,\n            }\n        }\n        self.broadcast(event)\n\n    def send_arq_session_progress(self, outbound: bool, session_id, dxcall, received_bytes, total_bytes, state, speed_level, statistics=None):\n        if statistics is None:\n            statistics = {}\n\n        direction = 'outbound' if outbound else 'inbound'\n        event = {\n                \"type\": \"arq\",\n                f\"arq-transfer-{direction}\": {\n                'session_id': session_id,\n                'dxcall': dxcall,\n                'received_bytes': received_bytes,\n                'total_bytes': total_bytes,\n                'state': state,\n                'speed_level': speed_level,\n                'statistics': statistics,\n            }\n        }\n        self.broadcast(event)\n\n    def send_arq_session_finished(self, outbound: bool, session_id, dxcall, success: bool, state: bool, data=False, statistics=None):\n        if statistics is None:\n            statistics = {}\n        if data:\n            if isinstance(data, dict):\n                data = json.dumps(data).encode('utf-8')\n                # Base64 encode the bytes-like object\n            data = base64.b64encode(data).decode(\"UTF-8\")\n        direction = 'outbound' if outbound else 'inbound'\n        event = {\n                \"type\" : \"arq\",\n                f\"arq-transfer-{direction}\": {\n                'session_id': session_id,\n                'dxcall': dxcall,\n                'statistics': statistics,\n                'success': bool(success),\n                'state': state,\n                'data': data\n            }\n        }\n        self.broadcast(event)\n\n    def modem_started(self):\n        event = {\"freedata_server\": \"started\"}\n        self.broadcast(event)\n\n    def modem_restarted(self):\n        event = {\"freedata_server\": \"restarted\"}\n        self.broadcast(event)\n\n    def modem_stopped(self):\n        event = {\"freedata_server\": \"stopped\"}\n        self.broadcast(event)\n\n    def modem_failed(self):\n        event = {\"freedata_server\": \"failed\"}\n        self.broadcast(event)\n\n    def freedata_message_db_change(self, message_id=None):\n        self.broadcast({\"message-db\": \"changed\", \"message_id\": message_id})"}
{"type": "source_file", "path": "freedata_server/exceptions.py", "content": "\"\"\"\nCustom exceptions for FreeDATA Python code\n\"\"\"\n\n\nclass NoCallsign(UserWarning):\n    \"\"\"Raised when a required callsign is not provided\"\"\"\n"}
{"type": "source_file", "path": "freedata_server/command_message_send.py", "content": "from command import TxCommand\nimport api_validations\nimport base64\nfrom queue import Queue\nfrom arq_session_iss import ARQSessionISS\nfrom message_p2p import MessageP2P\nfrom arq_data_type_handler import ARQ_SESSION_TYPES\nfrom message_system_db_manager import DatabaseManager\nfrom message_system_db_messages import DatabaseManagerMessages\nimport threading\nimport numpy as np\n\n\nclass SendMessageCommand(TxCommand):\n    \"\"\"Command to send a P2P message using an ARQ transfer session\n    \"\"\"\n\n    def set_params_from_api(self, apiParams):\n        origin = f\"{self.config['STATION']['mycall']}-{self.config['STATION']['myssid']}\"\n        self.message = MessageP2P.from_api_params(origin, apiParams)\n        DatabaseManagerMessages(self.event_manager).add_message(self.message.to_dict(), statistics={}, direction='transmit', status='queued', frequency=self.state_manager.radio_frequency)\n\n    def transmit(self, modem):\n\n        if self.state_manager.getARQ():\n            self.log(\"Modem busy, waiting until ready...\")\n            return\n\n        if not modem:\n            self.log(\"Modem not running...\", isWarning=True)\n            return\n\n\n        first_queued_message = DatabaseManagerMessages(self.event_manager).get_first_queued_message()\n        if not first_queued_message:\n            self.log(\"No queued message in database.\")\n            return\n        try:\n            self.log(f\"Queued message found: {first_queued_message['id']}\")\n            DatabaseManagerMessages(self.event_manager).update_message(first_queued_message[\"id\"], update_data={'status': 'transmitting'}, frequency=self.state_manager.radio_frequency)\n            message_dict = DatabaseManagerMessages(self.event_manager).get_message_by_id(first_queued_message[\"id\"])\n            message = MessageP2P.from_api_params(message_dict['origin'], message_dict)\n\n            # wait some random time and wait if we have an ongoing codec2 transmission\n            # on our channel. This should prevent some packet collision\n            random_delay = np.random.randint(0, 6)\n            threading.Event().wait(random_delay)\n            while self.state_manager.is_receiving_codec2_signal():\n                threading.Event().wait(0.1)\n\n            # Convert JSON string to bytes (using UTF-8 encoding)\n            payload = message.to_payload().encode('utf-8')\n            json_bytearray = bytearray(payload)\n            data, data_type = self.arq_data_type_handler.prepare(json_bytearray, ARQ_SESSION_TYPES.p2pmsg_zlib)\n            iss = ARQSessionISS(self.config,\n                                modem,\n                                self.message.destination,\n                                self.state_manager,\n                                data,\n                                data_type\n                                )\n            self.state_manager.register_arq_iss_session(iss)\n            iss.start()\n        except Exception as e:\n            self.log(f\"Error starting ARQ session: {e}\", isWarning=True)\n"}
{"type": "source_file", "path": "freedata_server/command_fec.py", "content": "from command import TxCommand\nimport base64\n\nclass FecCommand(TxCommand):\n\n    def set_params_from_api(self, apiParams):\n        self.mode = apiParams['mode']\n        self.wakeup = apiParams['wakeup']\n        payload_b64 = apiParams['payload']\n    \n        if len(payload_b64) % 4:\n            raise TypeError\n        self.payload = base64.b64decode(payload_b64)\n\n        return super().set_params_from_api(apiParams)\n\n    def build_wakeup_frame(self):\n        return self.frame_factory.build_fec_wakeup(self.mode)\n\n    def build_frame(self):\n        return self.frame_factory.build_fec(self. mode, self.payload)\n    \n    def transmit(self, tx_frame_queue):\n        if self.wakeup:\n            tx_queue_item = self.make_modem_queue_item(self.get_c2_mode(), 1, 0, self.build_wakeup_frame())\n            tx_frame_queue.put(tx_queue_item)\n\n        tx_queue_item = self.make_modem_queue_item(self.get_c2_mode(), 1, 0, self.build_frame())\n        tx_frame_queue.put(tx_queue_item)\n"}
{"type": "source_file", "path": "freedata_server/command_ping.py", "content": "from command import TxCommand\nimport api_validations\nfrom message_system_db_manager import DatabaseManager\n\n\nclass PingCommand(TxCommand):\n\n    def set_params_from_api(self, apiParams):\n        self.dxcall = apiParams['dxcall']\n        if not api_validations.validate_freedata_callsign(self.dxcall):\n            self.dxcall = f\"{self.dxcall}-0\"\n\n        # update callsign database...\n        DatabaseManager(self.event_manager).get_or_create_station(self.dxcall)\n\n        return super().set_params_from_api(apiParams)\n\n    def build_frame(self):\n        return self.frame_factory.build_ping(self.dxcall)\n"}
{"type": "source_file", "path": "freedata_server/arq_session_iss.py", "content": "import threading\nimport data_frame_factory\nimport random\nfrom codec2 import FREEDV_MODE\nfrom modem_frametypes import FRAME_TYPE\nimport arq_session\nimport helpers\nfrom enum import Enum\nimport time\nimport stats\n\nclass ISS_State(Enum):\n    NEW = 0\n    OPEN_SENT = 1\n    INFO_SENT = 2\n    BURST_SENT = 3\n    ENDED = 4\n    FAILED = 5\n    ABORTING = 6 # state while running abort sequence and waiting for stop ack\n    ABORTED = 7 # stop ack received\n\nclass ARQSessionISS(arq_session.ARQSession):\n\n    RETRIES_CONNECT = 5\n    RETRIES_INFO = 10\n    RETRIES_DATA = 25\n    RETRIES_STOP = 5\n\n    # DJ2LS: 3 seconds seems to be too small for radios with a too slow PTT toggle time\n    # DJ2LS: 3.5 seconds is working well WITHOUT a channel busy detection delay\n    TIMEOUT_CHANNEL_BUSY = 0\n    TIMEOUT_CONNECT_ACK = 3.5 + TIMEOUT_CHANNEL_BUSY\n    TIMEOUT_TRANSFER = 2.5 + TIMEOUT_CHANNEL_BUSY\n    TIMEOUT_STOP_ACK = 3.5 + TIMEOUT_CHANNEL_BUSY\n\n    STATE_TRANSITION = {\n        ISS_State.OPEN_SENT: { \n            FRAME_TYPE.ARQ_SESSION_OPEN_ACK.value: 'send_info',\n        },\n        ISS_State.INFO_SENT: {\n            FRAME_TYPE.ARQ_SESSION_OPEN_ACK.value: 'send_info',\n            FRAME_TYPE.ARQ_SESSION_INFO_ACK.value: 'send_data',\n        },\n        ISS_State.BURST_SENT: {\n            FRAME_TYPE.ARQ_SESSION_INFO_ACK.value: 'send_data',\n            FRAME_TYPE.ARQ_BURST_ACK.value: 'send_data',\n        },\n        ISS_State.FAILED:{\n            FRAME_TYPE.ARQ_STOP_ACK.value: 'transmission_aborted'\n        },\n        ISS_State.ABORTING: {\n            FRAME_TYPE.ARQ_STOP_ACK.value: 'transmission_aborted',\n\n        },\n        ISS_State.ABORTED: {\n            FRAME_TYPE.ARQ_STOP_ACK.value: 'transmission_aborted',\n        }\n    }\n\n    def __init__(self, config: dict, modem, dxcall: str, state_manager, data: bytearray, type_byte: bytes):\n        super().__init__(config, modem, dxcall, state_manager)\n        self.state_manager = state_manager\n        self.data = data\n        self.total_length = len(data)\n        self.data_crc = helpers.get_crc_32(self.data)\n        self.type_byte = type_byte\n        self.confirmed_bytes = 0\n        self.expected_byte_offset = 0\n\n        self.state = ISS_State.NEW\n        self.state_enum = ISS_State # needed for access State enum from outside\n        self.id = self.generate_id()\n\n        self.is_IRS = False\n\n        # enable decoder for signalling ACK bursts\n        self.modem.demodulator.set_decode_mode(modes_to_decode=None, is_irs=False)\n\n        self.frame_factory = data_frame_factory.DataFrameFactory(self.config)\n\n    def generate_id(self):\n\n        # Iterate through existing sessions to find a matching CRC\n        for session_id, session_data in self.state_manager.arq_iss_sessions.items():\n            if session_data.data_crc == self.data_crc and session_data.state in [ISS_State.FAILED, ISS_State.ABORTED]:\n                # If a matching CRC is found, use this session ID\n                self.log(f\"Matching CRC found, deleting existing session and resuming transmission\", isWarning=True)\n                self.states.remove_arq_iss_session(session_id)\n                return session_id\n        self.log(f\"No matching CRC found, creating new session id\", isWarning=False)\n\n        # Compute 8-bit integer from the 32-bit CRC\n        # Convert the byte sequence to a 32-bit integer (little-endian)\n        checksum_int = int.from_bytes(self.data_crc, byteorder='little')\n        random_int = checksum_int % 256\n\n        # Check if the generated 8-bit integer can be used\n        if random_int not in self.state_manager.arq_iss_sessions:\n            return random_int\n\n        # If the generated ID is already used, generate a new random ID\n        while True:\n            random_int = random.randint(1, 255)\n            if random_int not in self.state_manager.arq_iss_sessions:\n                return random_int\n            if len(self.state_manager.arq_iss_sessions) >= 255:\n                # Return False if all possible session IDs are exhausted\n                return False\n\n    def transmit_wait_and_retry(self, frame_or_burst, timeout, retries, mode, isARQBurst=False):\n        while retries > 0 and self.state not in [ISS_State.ABORTED, ISS_State.ABORTING]:\n            self.event_frame_received = threading.Event()\n            if isinstance(frame_or_burst, list): burst = frame_or_burst\n            else: burst = [frame_or_burst]\n            for f in burst:\n                self.transmit_frame(f, mode)\n            self.event_frame_received.clear()\n            self.log(f\"Waiting {timeout} seconds...\")\n            if self.event_frame_received.wait(timeout):\n                return\n            self.log(\"Timeout!\")\n            retries = retries - 1\n\n            # TODO TEMPORARY TEST FOR SENDING IN LOWER SPEED LEVEL IF WE HAVE TWO FAILED TRANSMISSIONS!!!\n            if retries == self.RETRIES_DATA - 2 and isARQBurst and self.speed_level > 0 and self.state not in [ISS_State.ABORTED, ISS_State.ABORTING]:\n                self.log(\"SENDING IN FALLBACK SPEED LEVEL\", isWarning=True)\n                self.speed_level = 0\n                print(f\" CONFIRMED BYTES: {self.confirmed_bytes}\")\n                self.send_data({'flag':{'ABORT': False, 'FINAL': False}, 'speed_level': self.speed_level}, fallback=True)\n\n                return\n\n        self.set_state(ISS_State.FAILED)\n        self.transmission_failed()\n\n    def launch_twr(self, frame_or_burst, timeout, retries, mode, isARQBurst=False):\n        twr = threading.Thread(target = self.transmit_wait_and_retry, args=[frame_or_burst, timeout, retries, mode, isARQBurst], daemon=True)\n        twr.start()\n\n    def start(self):\n        maximum_bandwidth = self.config['MODEM']['maximum_bandwidth']\n        print(maximum_bandwidth)\n        self.event_manager.send_arq_session_new(\n            True, self.id, self.dxcall, self.total_length, self.state.name)\n        session_open_frame = self.frame_factory.build_arq_session_open(self.dxcall, self.id, maximum_bandwidth, self.protocol_version)\n        self.launch_twr(session_open_frame, self.TIMEOUT_CONNECT_ACK, self.RETRIES_CONNECT, mode=FREEDV_MODE.signalling)\n        self.set_state(ISS_State.OPEN_SENT)\n\n    def update_speed_level(self, frame):\n        self.log(\"---------------------------------------------------------\", isWarning=True)\n\n        # Log the received frame for debugging\n        self.log(f\"Received frame: {frame}\", isWarning=True)\n\n        # Extract the speed_level directly from the frame\n        if 'speed_level' in frame:\n            new_speed_level = frame['speed_level']\n            # Ensure the new speed level is within the allowable range\n            if 0 <= new_speed_level < len(self.SPEED_LEVEL_DICT):\n                # Log the speed level change if it's different from the current speed level\n                if new_speed_level != self.speed_level:\n                    self.log(f\"Changing speed level from {self.speed_level} to {new_speed_level}\", isWarning=True)\n                    self.speed_level = new_speed_level  # Update the current speed level\n                else:\n                    self.log(\"Received speed level is the same as the current speed level.\", isWarning=True)\n            else:\n                self.log(f\"Received speed level {new_speed_level} is out of allowable range.\", isWarning=True)\n        else:\n            self.log(\"No speed level specified in the received frame.\", isWarning=True)\n\n    def send_info(self, irs_frame):\n        # check if we received an abort flag\n        if irs_frame[\"flag\"][\"ABORT\"]:\n            return self.transmission_aborted(irs_frame=irs_frame)\n\n        info_frame = self.frame_factory.build_arq_session_info(self.id, self.total_length,\n                                                               self.data_crc,\n                                                               self.snr, self.type_byte)\n\n        self.launch_twr(info_frame, self.TIMEOUT_CONNECT_ACK, self.RETRIES_INFO, mode=FREEDV_MODE.signalling)\n        self.set_state(ISS_State.INFO_SENT)\n\n        return None, None\n\n    def send_data(self, irs_frame, fallback=None):\n        if 'offset' in irs_frame:\n            self.log(f\"received data offset: {irs_frame['offset']}\", isWarning=True)\n            self.expected_byte_offset = irs_frame['offset']\n\n        # interrupt transmission when aborting\n        if self.state in [ISS_State.ABORTED, ISS_State.ABORTING]:\n            #self.event_frame_received.set()\n            #self.send_stop()\n            return\n\n        # update statistics\n        self.update_histograms(self.confirmed_bytes, self.total_length)\n        self.update_speed_level(irs_frame)\n\n        if self.expected_byte_offset > self.total_length:\n            self.confirmed_bytes = self.total_length\n        elif not fallback:\n            self.confirmed_bytes = self.expected_byte_offset\n\n        self.log(f\"IRS confirmed {self.confirmed_bytes}/{self.total_length} bytes\")\n        self.event_manager.send_arq_session_progress(True, self.id, self.dxcall, self.confirmed_bytes, self.total_length, self.state.name, self.speed_level, statistics=self.calculate_session_statistics(self.confirmed_bytes, self.total_length))\n\n        # check if we received an abort flag\n        if irs_frame[\"flag\"][\"ABORT\"]:\n            self.transmission_aborted(irs_frame=irs_frame)\n            return None, None\n\n        if irs_frame[\"flag\"][\"FINAL\"]:\n            if self.confirmed_bytes == self.total_length and irs_frame[\"flag\"][\"CHECKSUM\"]:\n                self.transmission_ended(irs_frame)\n\n            else:\n                self.transmission_failed()\n            return None, None\n\n        payload_size = self.get_data_payload_size()\n        burst = []\n        for _ in range(0, self.frames_per_burst):\n            offset = self.confirmed_bytes\n            #self.expected_byte_offset = offset\n            payload = self.data[offset : offset + payload_size]\n            #self.expected_byte_offset = offset + payload_size\n            self.expected_byte_offset = offset + len(payload)\n            #print(f\"EXPECTED----------------------{self.expected_byte_offset}\")\n            data_frame = self.frame_factory.build_arq_burst_frame(\n                self.SPEED_LEVEL_DICT[self.speed_level][\"mode\"],\n                self.id, offset, payload, self.speed_level)\n            burst.append(data_frame)\n        self.launch_twr(burst, self.TIMEOUT_TRANSFER, self.RETRIES_DATA, mode='auto', isARQBurst=True)\n        self.set_state(ISS_State.BURST_SENT)\n        return None, None\n\n    def transmission_ended(self, irs_frame):\n        # final function for sucessfully ended transmissions\n        self.session_ended = time.time()\n        self.set_state(ISS_State.ENDED)\n        self.log(f\"All data transfered! flag_final={irs_frame['flag']['FINAL']}, flag_checksum={irs_frame['flag']['CHECKSUM']}\")\n        self.event_manager.send_arq_session_finished(True, self.id, self.dxcall,True, self.state.name, statistics=self.calculate_session_statistics(self.confirmed_bytes, self.total_length))\n\n        #print(self.state_manager.p2p_connection_sessions)\n        #print(self.arq_data_type_handler.state_manager.p2p_connection_sessions)\n        session_stats = self.calculate_session_statistics(self.confirmed_bytes, self.total_length)\n        self.arq_data_type_handler.transmitted(self.type_byte, self.data, session_stats)\n\n        self.state_manager.remove_arq_iss_session(self.id)\n        self.states.setARQ(False)\n        return None, None\n\n    def transmission_failed(self, irs_frame=None):\n        # final function for failed transmissions\n        self.session_ended = time.time()\n        self.set_state(ISS_State.FAILED)\n        self.log(\"Transmission failed!\")\n        session_stats=self.calculate_session_statistics(self.confirmed_bytes, self.total_length)\n        self.event_manager.send_arq_session_finished(True, self.id, self.dxcall,False, self.state.name, session_stats)\n\n        self.states.setARQ(False)\n\n        self.arq_data_type_handler.failed(self.type_byte, self.data, statistics=self.calculate_session_statistics(self.confirmed_bytes, self.total_length))\n        return None, None\n\n    def abort_transmission(self, send_stop=False, irs_frame=None):\n        # function for starting the abort sequence\n        self.log(\"aborting transmission...\")\n        self.set_state(ISS_State.ABORTING)\n\n        self.event_manager.send_arq_session_finished(\n            True, self.id, self.dxcall, False, self.state.name, statistics=self.calculate_session_statistics(self.confirmed_bytes, self.total_length))\n\n        # clear audio out queue\n        self.modem.audio_out_queue.queue.clear()\n\n        # break actual retries\n        self.event_frame_received.set()\n\n        # wait for transmit function to be ready before setting event\n        while self.states.isTransmitting():\n            threading.Event().wait(0.100)\n\n        # break actual retries\n        self.event_frame_received.set()\n\n        if send_stop:\n            # sleep some time for avoiding packet collission\n            threading.Event().wait(self.TIMEOUT_STOP_ACK)\n            self.send_stop()\n\n        self.states.setARQ(False)\n\n    def send_stop(self):\n        stop_frame = self.frame_factory.build_arq_stop(self.id)\n        self.launch_twr(stop_frame, self.TIMEOUT_STOP_ACK, self.RETRIES_STOP, mode=FREEDV_MODE.signalling)\n\n    def transmission_aborted(self, irs_frame=None):\n        self.log(\"session aborted\")\n        self.session_ended = time.time()\n        self.set_state(ISS_State.ABORTED)\n        # break actual retries\n        self.event_frame_received.set()\n\n        self.event_manager.send_arq_session_finished(\n            True, self.id, self.dxcall, False, self.state.name, statistics=self.calculate_session_statistics(self.confirmed_bytes, self.total_length))\n        #self.state_manager.remove_arq_iss_session(self.id)\n        self.states.setARQ(False)\n        return None, None\n"}
{"type": "source_file", "path": "freedata_server/frame_dispatcher.py", "content": "\"\"\"\nFRAME DISPATCHER - We are dispatching the received frames to the needed functions\n\n\n\"\"\"\nimport threading\nimport structlog\nfrom modem_frametypes import FRAME_TYPE as FR_TYPE\nimport event_manager\nfrom data_frame_factory import DataFrameFactory\n\nfrom frame_handler import FrameHandler\nfrom frame_handler_ping import PingFrameHandler\nfrom frame_handler_cq import CQFrameHandler\nfrom frame_handler_arq_session import ARQFrameHandler\nfrom frame_handler_p2p_connection import P2PConnectionFrameHandler\nfrom frame_handler_beacon import BeaconFrameHandler\n\n\n\nclass DISPATCHER():\n\n    FRAME_HANDLER = {\n        FR_TYPE.ARQ_SESSION_OPEN_ACK.value: {\"class\": ARQFrameHandler, \"name\": \"ARQ OPEN ACK\"},\n        FR_TYPE.ARQ_SESSION_OPEN.value: {\"class\": ARQFrameHandler, \"name\": \"ARQ Data Channel Open\"},\n        FR_TYPE.ARQ_SESSION_INFO_ACK.value: {\"class\": ARQFrameHandler, \"name\": \"ARQ INFO ACK\"},\n        FR_TYPE.ARQ_SESSION_INFO.value: {\"class\": ARQFrameHandler, \"name\": \"ARQ Data Channel Info\"},\n        FR_TYPE.P2P_CONNECTION_CONNECT.value: {\"class\": P2PConnectionFrameHandler, \"name\": \"P2P Connection CONNECT\"},\n        FR_TYPE.P2P_CONNECTION_CONNECT_ACK.value: {\"class\": P2PConnectionFrameHandler, \"name\": \"P2P Connection CONNECT ACK\"},\n        FR_TYPE.P2P_CONNECTION_DISCONNECT.value: {\"class\": P2PConnectionFrameHandler, \"name\": \"P2P Connection DISCONNECT\"},\n        FR_TYPE.P2P_CONNECTION_DISCONNECT_ACK.value: {\"class\": P2PConnectionFrameHandler,\n                                                   \"name\": \"P2P Connection DISCONNECT ACK\"},\n        FR_TYPE.P2P_CONNECTION_PAYLOAD.value: {\"class\": P2PConnectionFrameHandler,\n                                                   \"name\": \"P2P Connection PAYLOAD\"},\n        FR_TYPE.P2P_CONNECTION_PAYLOAD_ACK.value: {\"class\": P2PConnectionFrameHandler,\n                                                   \"name\": \"P2P Connection PAYLOAD ACK\"},\n\n        #FR_TYPE.ARQ_CONNECTION_HB.value: {\"class\": ARQFrameHandler, \"name\": \"ARQ HEARTBEAT\"},\n        #FR_TYPE.ARQ_CONNECTION_OPEN.value: {\"class\": ARQFrameHandler, \"name\": \"ARQ OPEN SESSION\"},\n        FR_TYPE.ARQ_STOP.value: {\"class\": ARQFrameHandler, \"name\": \"ARQ STOP\"},\n        FR_TYPE.ARQ_STOP_ACK.value: {\"class\": ARQFrameHandler, \"name\": \"ARQ STOP ACK\"},\n        FR_TYPE.BEACON.value: {\"class\": BeaconFrameHandler, \"name\": \"BEACON\"},\n        FR_TYPE.ARQ_BURST_FRAME.value:{\"class\": ARQFrameHandler, \"name\": \"BURST FRAME\"},\n        FR_TYPE.ARQ_BURST_ACK.value: {\"class\": ARQFrameHandler, \"name\":  \"BURST ACK\"},\n        FR_TYPE.CQ.value: {\"class\": CQFrameHandler, \"name\":  \"CQ\"},\n        FR_TYPE.PING_ACK.value: {\"class\": FrameHandler, \"name\":  \"PING ACK\"},\n        FR_TYPE.PING.value: {\"class\": PingFrameHandler, \"name\":  \"PING\"},\n        FR_TYPE.QRV.value: {\"class\": FrameHandler, \"name\":  \"QRV\"},\n        #FR_TYPE.IS_WRITING.value: {\"class\": FrameHandler, \"name\": \"IS_WRITING\"},\n        #FR_TYPE.FEC.value: {\"class\": FrameHandler, \"name\":  \"FEC\"},\n        #FR_TYPE.FEC_WAKEUP.value: {\"class\": FrameHandler, \"name\":  \"FEC WAKEUP\"},\n    }\n\n    def __init__(self, config, event_manager, states, modem):\n        self.log = structlog.get_logger(\"frame_dispatcher\")\n\n        self.log.info(\"loading frame dispatcher.....\\n\")\n        self.config = config\n        self.states = states\n        self.event_manager = event_manager\n\n        self.stop_event = threading.Event()\n\n        self._initialize_handlers(config, states)\n\n        self.modem = modem\n        self.data_queue_received = modem.data_queue_received\n\n        self.arq_sessions = []\n\n\n    def _initialize_handlers(self, config, states):\n        \"\"\"Initializes various data handlers.\"\"\"\n\n        self.frame_factory = DataFrameFactory(config)\n\n    def start(self):\n        \"\"\"Starts worker threads for transmit and receive operations.\"\"\"\n        threading.Thread(target=self.worker_receive, name=\"Receive Worker\", daemon=True).start()\n\n    def stop(self):\n        self.stop_event.set()\n\n    def worker_receive(self) -> None:\n        \"\"\"Queue received data for processing\"\"\"\n        while not self.stop_event.is_set():\n            try:\n                data = self.data_queue_received.get(timeout=1)\n                if data:\n                    self.process_data(\n                        data['payload'],\n                        data['freedv'],\n                        data['bytes_per_frame'],\n                        data['snr'],\n                        data['frequency_offset'],\n                        data['mode_name'],\n                    )\n            except Exception:\n                continue\n\n    def process_data(self, bytes_out, freedv, bytes_per_frame: int, snr, frequency_offset, mode_name) -> None:\n        # get frame as dictionary\n        deconstructed_frame = self.frame_factory.deconstruct(bytes_out, mode_name=mode_name)\n        frametype = deconstructed_frame[\"frame_type_int\"]\n        if frametype not in self.FRAME_HANDLER:\n            self.log.warning(\n                \"[DISPATCHER] ARQ - other frame type\", frametype=FR_TYPE(frametype).name)\n            return\n        \n        # instantiate handler\n        handler_class = self.FRAME_HANDLER[frametype]['class']\n        handler: FrameHandler = handler_class(self.FRAME_HANDLER[frametype]['name'],\n                                self.config,\n                                self.states,\n                                self.event_manager,\n                                self.modem)\n        handler.handle(deconstructed_frame, snr, frequency_offset, freedv, bytes_per_frame)\n\n    def get_id_from_frame(self, data):\n        if data[:1] == FR_TYPE.ARQ_SESSION_OPEN:\n            return data[13:14]\n        return None\n"}
{"type": "source_file", "path": "freedata_server/cw.py", "content": "import numpy as np\n\n\"\"\"\n morse code generator\n MorseCodePlayer().text_to_signal(\"DJ2LS-1\")\n\n \n \"\"\"\n\n\nclass MorseCodePlayer:\n    def __init__(self, wpm=25, f=1500, fs=48000):\n        self.wpm = wpm\n        self.f0 = f\n        self.fs = fs\n        self.dot_duration = 1.2/(self.wpm)\n        self.dash_duration = 3*self.dot_duration\n        self.pause_duration = self.dot_duration\n        self.word_pause_duration = 7*self.dot_duration\n        self.morse_alphabet = {\n            'A': '.-', 'B': '-...', 'C': '-.-.', 'D': '-..', 'E': '.', 'F': '..-.', 'G': '--.', 'H': '....',\n            'I': '..', 'J': '.---', 'K': '-.-', 'L': '.-..', 'M': '--', 'N': '-.', 'O': '---', 'P': '.--.',\n            'Q': '--.-', 'R': '.-.', 'S': '...', 'T': '-', 'U': '..-', 'V': '...-', 'W': '.--', 'X': '-..-',\n            'Y': '-.--', 'Z': '--..', '0': '-----', '1': '.----', '2': '..---', '3': '...--', '4': '....-',\n            '5': '.....', '6': '-....', '7': '--...', '8': '---..', '9': '----.', '.': '.-.-.-', ',': '--..--',\n            '?': '..--..', \"'\": '.----.', '!': '-.-.--', '/': '-..-.', '(': '-.--.', ')': '-.--.-', '&': '.-...',\n            ':': '---...', ';': '-.-.-.', '=': '-...-', '+': '.-.-.', '-': '-....-', '_': '..--.-', '\"': '.-..-.',\n            '$': '...-..-', '@': '.--.-.'\n        }\n\n    def text_to_morse(self, text):\n        morse = ''\n        for char in text:\n            if char.upper() in self.morse_alphabet:\n                morse += self.morse_alphabet[char.upper()] + ' '\n            elif char == ' ':\n                morse += ' '\n        return morse\n\n    def morse_to_signal(self, morse):\n        signal = np.array([], dtype=np.int16)\n        for char in morse:\n            if char == '.':\n                duration = self.dot_duration  # Using class-defined duration\n                t = np.linspace(0, duration, int(self.fs * duration), endpoint=False)\n                s = 0.5 * np.sin(2 * np.pi * self.f0 * t)\n                signal = np.concatenate((signal, np.int16(s * 32767)))\n                pause_samples = int(self.pause_duration * self.fs)\n                signal = np.concatenate((signal, np.zeros(pause_samples, dtype=np.int16)))\n\n            elif char == '-':\n                duration = self.dash_duration  # Using class-defined duration\n                t = np.linspace(0, duration, int(self.fs * duration), endpoint=False)\n                s = 0.5 * np.sin(2 * np.pi * self.f0 * t)\n                signal = np.concatenate((signal, np.int16(s * 32767)))\n                pause_samples = int(self.pause_duration * self.fs)\n                signal = np.concatenate((signal, np.zeros(pause_samples, dtype=np.int16)))\n\n            elif char == ' ':\n                pause_samples = int(self.word_pause_duration * self.fs)\n                signal = np.concatenate((signal, np.zeros(pause_samples, dtype=np.int16)))\n                pause_samples = int(self.pause_duration * self.fs)\n                signal = np.concatenate((signal, np.zeros(pause_samples, dtype=np.int16)))\n\n        return signal\n\n    def text_to_signal(self, text):\n        morse = self.text_to_morse(text)\n        return self.morse_to_signal(morse)\n\n"}
{"type": "source_file", "path": "freedata_server/config.py", "content": "import configparser\nimport structlog\nimport json\n\n\nclass CONFIG:\n    \"\"\"\n    CONFIG class for handling with config files\n\n    \"\"\"\n\n    config_types = {\n        'NETWORK': {\n            'modemaddress': str,\n            'modemport': int,\n        },\n        'STATION': {\n            'mycall': str,\n            'mygrid': str,\n            'myssid': int,\n            'ssid_list': list,\n            'enable_explorer': bool,\n            'enable_stats': bool,\n            'respond_to_cq': bool,\n            'enable_callsign_blacklist': bool,\n            'callsign_blacklist': list\n\n        },\n        'AUDIO': {\n            'input_device': str,\n            'output_device': str,\n            'rx_audio_level': int,\n            'tx_audio_level': int,\n        },\n        'RADIO': {\n            'control': str,\n            'serial_port': str,\n            'model_id': int,\n            'serial_speed': int,\n            'data_bits': int,\n            'stop_bits': int,\n            'serial_handshake': str,\n            'ptt_port': str,\n            'ptt_type': str,\n            'serial_dcd': str,\n            'serial_dtr': str,\n            'serial_rts': str,\n        },\n        'RIGCTLD': {\n            'ip': str,\n            'port': int,\n            'path': str,\n            'command': str,\n            'arguments': str,\n            'enable_vfo': bool,\n        },\n        'TCI': {\n            'tci_ip': str,\n            'tci_port': int,\n        },\n        'MODEM': {\n            'enable_morse_identifier': bool,\n            'maximum_bandwidth': int,\n            'tx_delay': int,\n        },\n        'SOCKET_INTERFACE': {\n            'enable': bool,\n            'host': str,\n            'cmd_port': int,\n            'data_port': int,\n        },\n        'MESSAGES': {\n            'enable_auto_repeat': bool,\n        },\n        'QSO_LOGGING': {\n            'enable_adif_udp': bool,\n            'adif_udp_host': str,\n            'adif_udp_port': int,\n            'enable_adif_wavelog': bool,\n            'adif_wavelog_host': str,\n            'adif_wavelog_api_key': str,\n        },\n\n        'GUI': {\n            'auto_run_browser': bool,\n        }\n    }\n\n    default_values = {\n        list: '[]',\n        bool: 'False',\n        int: '0',\n        str: '',\n    }\n\n    def __init__(self, configfile: str):\n\n        # set up logger\n        self.log = structlog.get_logger(type(self).__name__)\n\n        # init configparser\n        self.parser = configparser.ConfigParser(inline_comment_prefixes=\"#\", allow_no_value=True)\n        \n        try:\n            self.config_name = configfile\n        except Exception:\n            self.config_name = \"config.ini\"\n\n        # self.log.info(\"[CFG] config init\", file=self.config_name)\n\n        # check if config file exists\n        self.config_exists()\n\n        # validate config structure\n        self.validate_config()\n\n    def config_exists(self):\n        \"\"\"\n        check if config file exists\n        \"\"\"\n        try:\n            return bool(self.parser.read(self.config_name, None))\n        except Exception as configerror:\n            self.log.error(\"[CFG] logfile init error\", e=configerror)\n            return False\n\n    # Validates config data\n    def validate_data(self, data):\n        for section in data:\n            for setting in data[section]:\n                if not isinstance(data[section][setting], self.config_types[section][setting]):\n                    message = (f\"{section}.{setting} must be {self.config_types[section][setting]}.\"\n                               f\" '{data[section][setting]}' {type(data[section][setting])} given.\")\n                    raise ValueError(message)\n\n    def validate_config(self):\n        \"\"\"\n        Updates the configuration file to match exactly what is defined in self.config_types.\n        It removes sections and settings not defined there and adds missing sections and settings.\n        \"\"\"\n        existing_sections = self.parser.sections()\n\n        # Remove sections and settings not defined in self.config_types\n        for section in existing_sections:\n            if section not in self.config_types:\n                self.parser.remove_section(section)\n                self.log.info(f\"[CFG] Removing undefined section: {section}\")\n                continue\n            existing_settings = self.parser.options(section)\n            for setting in existing_settings:\n                if setting not in self.config_types[section]:\n                    self.parser.remove_option(section, setting)\n                    self.log.info(f\"[CFG] Removing undefined setting: {section}.{setting}\")\n\n        # Add missing sections and settings from self.config_types\n        for section, settings in self.config_types.items():\n            if section not in existing_sections:\n                self.parser.add_section(section)\n                self.log.info(f\"[CFG] Adding missing section: {section}\")\n            for setting, value_type in settings.items():\n                if not self.parser.has_option(section, setting):\n                    default_value = self.default_values.get(value_type, None)\n\n                    self.parser.set(section, setting, str(default_value))\n                    self.log.info(f\"[CFG] Adding missing setting: {section}.{setting}\")\n\n        return self.write_to_file()\n\n    # Handle special setting data type conversion\n    # is_writing means data from a dict being writen to the config file\n    # if False, it means the opposite direction\n    def handle_setting(self, section, setting, value, is_writing=False):\n        try:\n            if self.config_types[section][setting] == list:\n                if is_writing:\n                    # When writing, ensure the value is a list and then convert it to JSON\n                    if isinstance(value, str):\n                        value = json.loads(value)  # Convert JSON string to list\n                    return json.dumps(value)  # Convert list to JSON string\n                else:\n                    # When reading, convert the JSON string back to a list\n                    if isinstance(value, str):\n                        return json.loads(value)\n                    return value  # Return as-is if already a list\n\n            elif self.config_types[section][setting] == bool and not is_writing:\n                return self.parser.getboolean(section, setting)\n\n            elif self.config_types[section][setting] == int and not is_writing:\n                return self.parser.getint(section, setting)\n\n            else:\n                return value\n        except KeyError as key:\n            self.log.error(\"[CFG] key error in logfile, please check 'config.ini.example' for help\", key=key)\n\n    # Sets and writes config data from a dict containing data settings\n    def write(self, data):\n        # Validate config data before writing\n        print(data)\n        self.validate_data(data)\n        for section in data:\n            # init section if it doesn't exist yet\n            if not section.upper() in self.parser.keys():\n                self.parser[section] = {}\n\n            for setting in data[section]:\n                new_value = self.handle_setting(\n                    section, setting, data[section][setting], True)\n                try:\n                    self.parser[section][setting] = str(new_value)\n                except Exception as e:\n                    self.log.error(\"[CFG] error setting config key\", e=e)\n        return self.write_to_file()\n\n    def write_to_file(self):\n        # Write config data to file\n        try:\n            with open(self.config_name, 'w') as configfile:\n                self.parser.write(configfile)\n                return self.read()\n        except Exception as conferror:\n            self.log.error(\"[CFG] reading logfile\", e=conferror)\n            return False\n\n    def read(self):\n        \"\"\"\n        read config file\n        \"\"\"\n        # self.log.info(\"[CFG] reading...\")\n        if not self.config_exists():\n            return False\n        \n        # at first just copy the config as read from file\n        result = {s: dict(self.parser.items(s)) for s in self.parser.sections()}\n\n        # handle the special settings\n        for section in result:\n            for setting in result[section]:\n                result[section][setting] = self.handle_setting(\n                   section, setting, result[section][setting], False)\n\n        return result\n"}
{"type": "source_file", "path": "freedata_server/command_cq.py", "content": "from command import TxCommand\nfrom codec2 import FREEDV_MODE\nclass CQCommand(TxCommand):\n\n    def build_frame(self):\n        return self.frame_factory.build_cq()\n"}
{"type": "source_file", "path": "freedata_server/log_handler.py", "content": "import logging.config\nimport structlog\n\n# https://www.structlog.org/en/stable/standard-library.html\ndef setup_logging(filename: str = \"\", level: str = \"DEBUG\"):\n    \"\"\"\n    Args:\n      filename:\n      level:str: Log level to output, possible values are:\n        \"CRITICAL\", \"FATAL\", \"ERROR\", \"WARNING\", \"WARN\", \"INFO\", \"DEBUG\"\n    \"\"\"\n\n    timestamper = structlog.processors.TimeStamper(fmt=\"iso\")\n    pre_chain = [\n        structlog.stdlib.add_log_level,\n        timestamper,\n    ]\n\n    config_dict = {\n        \"version\": 1,\n        \"disable_existing_loggers\": False,\n        \"formatters\": {\n            \"plain\": {\n                \"()\": structlog.stdlib.ProcessorFormatter,\n                \"processor\": structlog.dev.ConsoleRenderer(colors=False),\n                \"foreign_pre_chain\": pre_chain,\n            },\n            \"colored\": {\n                \"()\": structlog.stdlib.ProcessorFormatter,\n                \"processor\": structlog.dev.ConsoleRenderer(colors=True),\n                \"foreign_pre_chain\": pre_chain,\n            },\n        },\n        \"handlers\": {\n            \"default\": {\n                \"level\": level,\n                \"class\": \"logging.StreamHandler\",\n                \"formatter\": \"colored\",\n            },\n        },\n        \"loggers\": {\n            \"\": {\n                \"handlers\": [\"default\"],\n                \"level\": level,\n                \"propagate\": True,\n            },\n        },\n    }\n\n    if filename:\n        config_dict[\"handlers\"][\"file\"] = {\n            \"level\": level,\n            \"class\": \"logging.handlers.WatchedFileHandler\",\n            \"filename\": f\"{filename}.log\",\n            \"formatter\": \"plain\",\n        }\n        config_dict[\"loggers\"][\"\"][\"handlers\"].append(\"file\")\n\n    logging.config.dictConfig(config_dict)\n    structlog.configure(\n        processors=[\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.PositionalArgumentsFormatter(),\n            timestamper,\n            structlog.processors.StackInfoRenderer(),\n            structlog.processors.format_exc_info,\n            structlog.stdlib.ProcessorFormatter.wrap_for_formatter,\n        ],\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n        cache_logger_on_first_use=True,\n    )\n"}
{"type": "source_file", "path": "freedata_server/frame_handler_cq.py", "content": "import threading\n\nimport frame_handler_ping\nimport helpers\nimport data_frame_factory\nimport frame_handler\nfrom message_system_db_messages import DatabaseManagerMessages\nimport numpy as np\n\nclass CQFrameHandler(frame_handler.FrameHandler):\n\n    #def should_respond(self):\n    #    self.logger.debug(f\"Respond to CQ: {self.config['MODEM']['respond_to_cq']}\")\n    #    return bool(self.config['MODEM']['respond_to_cq'] and not self.states.getARQ())\n\n    def follow_protocol(self):\n\n        if self.states.getARQ():\n            return\n\n        self.logger.debug(\n            f\"[Modem] Responding to request from [{self.details['frame']['origin']}]\",\n            snr=self.details['snr'],\n        )\n\n        self.send_ack()\n\n    def send_ack(self):\n        factory = data_frame_factory.DataFrameFactory(self.config)\n        qrv_frame = factory.build_qrv(self.details['snr'])\n\n        # wait some random time and wait if we have an ongoing codec2 transmission\n        # on our channel. This should prevent some packet collision\n        random_delay = np.random.randint(0, 6)\n        threading.Event().wait(random_delay)\n        self.states.channel_busy_condition_codec2.wait(5)\n\n        self.transmit(qrv_frame)\n\n        if self.config[\"MESSAGES\"][\"enable_auto_repeat\"]:\n            # set message to queued if CQ received\n            DatabaseManagerMessages(self.event_manager).set_message_to_queued_for_callsign(self.details['frame'][\"origin\"])\n"}
{"type": "source_file", "path": "freedata_server/message_system_db_attachments.py", "content": "from message_system_db_manager import DatabaseManager\nfrom message_system_db_model import MessageAttachment, Attachment, P2PMessage\nimport json\nimport hashlib\nimport os\n\n\nclass DatabaseManagerAttachments(DatabaseManager):\n    def __init__(self, event_manager):\n        super().__init__(event_manager)\n\n\n    def add_attachment(self, session, message, attachment_data):\n        hash_sha512 = hashlib.sha512(attachment_data['data'].encode()).hexdigest()\n        existing_attachment = session.query(Attachment).filter_by(hash_sha512=hash_sha512).first()\n\n        if not existing_attachment:\n            attachment = Attachment(\n                name=attachment_data['name'],\n                data_type=attachment_data['type'],\n                data=attachment_data['data'],\n                checksum_crc32=attachment_data.get('checksum_crc32', ''),\n                hash_sha512=hash_sha512\n            )\n            session.add(attachment)\n            session.flush()  # Ensure the attachment is persisted and has an ID\n            self.log(f\"Added attachment to database: {attachment.name}\")\n        else:\n            attachment = existing_attachment\n            self.log(f\"Attachment {attachment.name} already exists in database\")\n\n        # Link the message and the attachment through MessageAttachment\n        link = MessageAttachment(message=message, attachment=attachment)\n        session.add(link)\n        self.log(f\"Linked message with attachment: {attachment.name}\")\n\n        return attachment\n\n    def get_attachments_by_message_id(self, message_id):\n        session = self.get_thread_scoped_session()\n        try:\n            # Fetch the message by its ID\n            message = session.query(P2PMessage).filter_by(id=message_id).first()\n            if message:\n                # Navigate through the association to get attachments\n                attachments = [ma.attachment.to_dict() for ma in message.message_attachments]\n                return attachments\n            else:\n                return []\n        except Exception as e:\n            self.log(f\"Error fetching attachments for message ID {message_id}: {e}\", isWarning=True)\n            return []\n        finally:\n            session.remove()\n\n    def get_attachments_by_message_id_json(self, message_id):\n        attachments = self.get_attachments_by_message_id(message_id)\n        return json.dumps(attachments)\n\n    def get_attachment_by_sha512(self, hash_sha512):\n        session = self.get_thread_scoped_session()\n        try:\n            attachment = session.query(Attachment).filter_by(hash_sha512=hash_sha512).first()\n            if attachment:\n                return attachment.to_dict()\n            else:\n                self.log(f\"No attachment found with SHA-512 hash: {hash_sha512}\")\n                return None\n        except Exception as e:\n            self.log(f\"Error fetching attachment with SHA-512 hash {hash_sha512}: {e}\", isWarning=True)\n            return None\n        finally:\n            session.remove()"}
{"type": "source_file", "path": "freedata_server/frame_handler_p2p_connection.py", "content": "from queue import Queue\nimport frame_handler\nfrom event_manager import EventManager\nfrom state_manager import StateManager\nfrom modem_frametypes import FRAME_TYPE as FR\nfrom p2p_connection import P2PConnection\n\nclass P2PConnectionFrameHandler(frame_handler.FrameHandler):\n\n    def follow_protocol(self):\n\n        if not self.should_respond():\n            return\n\n        frame = self.details['frame']\n        session_id = frame['session_id']\n        snr = self.details[\"snr\"]\n        frequency_offset = self.details[\"frequency_offset\"]\n\n        if frame['frame_type_int'] == FR.P2P_CONNECTION_CONNECT.value:\n\n            # Lost OPEN_ACK case .. ISS will retry opening a session\n            if session_id in self.states.arq_irs_sessions:\n                session = self.states.p2p_connection_sessions[session_id]\n\n            # Normal case when receiving a SESSION_OPEN for the first time\n            else:\n            #    if self.states.check_if_running_arq_session():\n            #        self.logger.warning(\"DISCARDING SESSION OPEN because of ongoing ARQ session \", frame=frame)\n            #        return\n                print(frame)\n                session = P2PConnection(self.config,\n                                        self.modem,\n                                        frame['origin'],\n                                        frame['destination_crc'],\n                                        self.states, self.event_manager)\n                session.session_id = session_id\n                self.states.register_p2p_connection_session(session)\n\n        elif frame['frame_type_int'] in [\n            FR.P2P_CONNECTION_CONNECT_ACK.value,\n            FR.P2P_CONNECTION_DISCONNECT.value,\n            FR.P2P_CONNECTION_DISCONNECT_ACK.value,\n            FR.P2P_CONNECTION_PAYLOAD.value,\n            FR.P2P_CONNECTION_PAYLOAD_ACK.value,\n        ]:\n            session = self.states.get_p2p_connection_session(session_id)\n\n        else:\n            self.logger.warning(\"DISCARDING FRAME\", frame=frame)\n            return\n\n        session.set_details(snr, frequency_offset)\n        session.on_frame_received(frame)\n"}
{"type": "source_file", "path": "freedata_server/frame_handler.py", "content": "import helpers\nfrom event_manager import EventManager\nfrom state_manager import StateManager\nimport structlog\nimport time\nfrom codec2 import FREEDV_MODE\nfrom message_system_db_manager import DatabaseManager\nfrom message_system_db_station import DatabaseManagerStations\n\nimport maidenhead\n\nTESTMODE = False\n\n\nclass FrameHandler():\n\n    def __init__(self, name: str, config, states: StateManager, event_manager: EventManager, \n                 modem) -> None:\n        \n        self.name = name\n        self.config = config\n        self.states = states\n        self.event_manager = event_manager\n        self.modem = modem\n        self.logger = structlog.get_logger(\"Frame Handler\")\n\n        self.details = {\n            'frame' : None, \n            'snr' : 0, \n            'frequency_offset': 0,\n            'freedv_inst': None, \n            'bytes_per_frame': 0\n        }\n\n    def is_frame_for_me(self):\n        call_with_ssid = self.config['STATION']['mycall'] + \"-\" + str(self.config['STATION']['myssid'])\n        ft = self.details['frame']['frame_type']\n        valid = False\n                \n        # Check for callsign checksum\n        if ft in ['ARQ_SESSION_OPEN', 'ARQ_SESSION_OPEN_ACK', 'PING', 'PING_ACK', 'P2P_CONNECTION_CONNECT']:\n            valid, mycallsign = helpers.check_callsign(\n                call_with_ssid,\n                self.details[\"frame\"][\"destination_crc\"],\n                self.config['STATION']['ssid_list'])\n\n        # Check for session id on IRS side\n        elif ft in ['ARQ_SESSION_INFO', 'ARQ_BURST_FRAME', 'ARQ_STOP']:\n            session_id = self.details['frame']['session_id']\n            if session_id in self.states.arq_irs_sessions:\n                valid = True\n\n        # Check for session id on ISS side\n        elif ft in ['ARQ_SESSION_INFO_ACK', 'ARQ_BURST_ACK', 'ARQ_STOP_ACK']:\n            session_id = self.details['frame']['session_id']\n            if session_id in self.states.arq_iss_sessions:\n                valid = True\n\n        # check for p2p connection\n        elif ft in ['P2P_CONNECTION_CONNECT']:\n            valid, mycallsign = helpers.check_callsign(\n                call_with_ssid,\n                self.details[\"frame\"][\"destination_crc\"],\n                self.config['STATION']['ssid_list'])\n\n        #check for p2p connection\n        elif ft in ['P2P_CONNECTION_CONNECT_ACK', 'P2P_CONNECTION_PAYLOAD', 'P2P_CONNECTION_PAYLOAD_ACK', 'P2P_CONNECTION_DISCONNECT', 'P2P_CONNECTION_DISCONNECT_ACK']:\n            session_id = self.details['frame']['session_id']\n            if session_id in self.states.p2p_connection_sessions:\n                valid = True\n\n        else:\n            valid = False\n\n        if not valid:\n            self.logger.info(f\"[Frame handler] {ft} received but not for us.\")\n\n        return valid\n\n    def should_respond(self):\n        return self.is_frame_for_me()\n\n    def is_origin_on_blacklist(self):\n        origin_callsign = self.details[\"frame\"][\"origin\"]\n\n        # Remove the suffix after the hyphen if it exists\n        if '-' in origin_callsign:\n            origin_callsign = origin_callsign.split('-')[0]\n\n        for blacklist_callsign in self.config[\"STATION\"][\"callsign_blacklist\"]:\n\n            # Check if both callsigns have the same length and then check for an exact match\n            if len(origin_callsign) == len(blacklist_callsign) and origin_callsign == blacklist_callsign:\n                return True\n        return False\n\n\n    def add_to_activity_list(self):\n        frame = self.details['frame']\n\n        activity = {\n            \"direction\": \"received\",\n            \"snr\": self.details['snr'],\n            \"frequency_offset\": self.details['frequency_offset'],\n            \"activity_type\": frame[\"frame_type\"]\n        }\n        if \"origin\" in frame:\n            activity[\"origin\"] = frame[\"origin\"]\n\n        if \"destination\" in frame:\n            activity[\"destination\"] = frame[\"destination\"]\n\n        if \"gridsquare\" in frame:\n            activity[\"gridsquare\"] = frame[\"gridsquare\"]\n\n        if \"session_id\" in frame:\n            activity[\"session_id\"] = frame[\"session_id\"]\n\n        if \"flag\" in frame:\n            if \"AWAY_FROM_KEY\" in frame[\"flag\"]:\n                activity[\"away_from_key\"] = frame[\"flag\"][\"AWAY_FROM_KEY\"]\n\n        self.states.add_activity(activity)\n\n    def add_to_heard_stations(self):\n        frame = self.details['frame']\n\n        if 'origin' not in frame:\n            return\n\n        dxgrid = frame.get('gridsquare', \"------\")\n\n\n        # Initialize distance values\n        distance_km = None\n        distance_miles = None\n        if dxgrid != \"------\":\n            distance_dict = maidenhead.distance_between_locators(self.config['STATION']['mygrid'], dxgrid)\n            distance_km = distance_dict['kilometers']\n            distance_miles = distance_dict['miles']\n\n        away_from_key = False\n        if \"flag\" in self.details['frame']:\n            if \"AWAY_FROM_KEY\" in self.details['frame'][\"flag\"]:\n                away_from_key = self.details['frame'][\"flag\"][\"AWAY_FROM_KEY\"]\n\n        helpers.add_to_heard_stations(\n            frame['origin'],\n            dxgrid,\n            self.name,\n            self.details['snr'],\n            self.details['frequency_offset'],\n            self.states.radio_frequency,\n            self.states.heard_stations,\n            distance_km=distance_km,  # Pass the kilometer distance\n            distance_miles=distance_miles,  # Pass the miles distance\n            away_from_key=away_from_key\n        )\n    def make_event(self):\n\n        event = {\n            \"type\": \"frame-handler\",\n            \"received\": self.details['frame']['frame_type'],\n            \"timestamp\": int(time.time()),\n            \"mycallsign\": self.config['STATION']['mycall'],\n            \"myssid\": self.config['STATION']['myssid'],\n            \"snr\": str(self.details['snr']),\n        }\n        if 'origin' in self.details['frame']:\n            event['dxcallsign'] = self.details['frame']['origin']\n\n        if 'gridsquare' in self.details['frame']:\n            event['gridsquare'] = self.details['frame']['gridsquare']\n            if event['gridsquare'] != \"------\":\n                distance = maidenhead.distance_between_locators(self.config['STATION']['mygrid'], self.details['frame']['gridsquare'])\n                event['distance_kilometers'] = distance['kilometers']\n                event['distance_miles'] = distance['miles']\n            else:\n                event['distance_kilometers'] = 0\n                event['distance_miles'] = 0\n\n        if \"flag\" in self.details['frame'] and \"AWAY_FROM_KEY\" in self.details['frame'][\"flag\"]:\n            event['away_from_key'] = self.details['frame'][\"flag\"][\"AWAY_FROM_KEY\"]\n\n        return event\n\n    def emit_event(self):\n        event_data = self.make_event()\n        print(event_data)\n        self.event_manager.broadcast(event_data)\n\n    def get_tx_mode(self):\n        return FREEDV_MODE.signalling\n\n    def transmit(self, frame):\n        if not TESTMODE:\n            self.modem.transmit(self.get_tx_mode(), 1, 0, frame)\n        else:\n            self.event_manager.broadcast(frame)\n\n    def follow_protocol(self):\n        pass\n\n    def log(self):\n        self.logger.info(f\"[Frame Handler] Handling frame {self.details['frame']['frame_type']}\")\n\n    def handle(self, frame, snr, frequency_offset, freedv_inst, bytes_per_frame):\n        self.details['frame'] = frame\n        self.details['snr'] = snr\n        self.details['frequency_offset'] = frequency_offset\n        self.details['freedv_inst'] = freedv_inst\n        self.details['bytes_per_frame'] = bytes_per_frame\n\n        print(self.details)\n\n        if 'origin' not in self.details['frame'] and 'session_id' in self.details['frame']:\n            dxcall = self.states.get_dxcall_by_session_id(self.details['frame']['session_id'])\n            if dxcall:\n                self.details['frame']['origin'] = dxcall\n\n        # look in database for a full callsign if only crc is present\n        if 'origin' not in self.details['frame'] and 'origin_crc' in self.details['frame']:\n            self.details['frame']['origin'] = DatabaseManager(self.event_manager).get_callsign_by_checksum(frame['origin_crc'])\n\n        if \"location\" in self.details['frame'] and \"gridsquare\" in self.details['frame']['location']:\n            DatabaseManagerStations(self.event_manager).update_station_location(self.details['frame']['origin'], frame['gridsquare'])\n\n\n        if 'origin' in self.details['frame']:\n            # try to find station info in database\n            try:\n                station = DatabaseManagerStations(self.event_manager).get_station(self.details['frame']['origin'])\n                if station and station[\"location\"] and \"gridsquare\" in station[\"location\"]:\n                    dxgrid = station[\"location\"][\"gridsquare\"]\n                else:\n                    dxgrid = \"------\"\n\n                # overwrite gridsquare only if not provided by frame\n                if \"gridsquare\" not in self.details['frame']:\n                    self.details['frame']['gridsquare'] = dxgrid\n\n            except Exception as e:\n                self.logger.info(f\"[Frame Handler] Error getting gridsquare from callsign info: {e}\")\n\n        # check if callsign is blacklisted\n        if self.config[\"STATION\"][\"enable_callsign_blacklist\"]:\n            if self.is_origin_on_blacklist():\n                self.logger.info(f\"[Frame Handler] Callsign blocked: {self.details['frame']['origin']}\")\n                return False\n\n        self.log()\n        self.add_to_heard_stations()\n        self.add_to_activity_list()\n        self.emit_event()\n        self.follow_protocol()\n"}
{"type": "source_file", "path": "freedata_server/frame_handler_arq_session.py", "content": "from queue import Queue\nimport frame_handler\nfrom event_manager import EventManager\nfrom state_manager import StateManager\nfrom modem_frametypes import FRAME_TYPE as FR\nfrom arq_session_irs import ARQSessionIRS\nfrom arq_session_iss import ARQSessionISS\nfrom arq_session_irs import IRS_State\n\n\nclass ARQFrameHandler(frame_handler.FrameHandler):\n\n    def follow_protocol(self):\n\n        if not self.should_respond():\n            return\n\n        frame = self.details['frame']\n        session_id = frame['session_id']\n        snr = self.details[\"snr\"]\n        frequency_offset = self.details[\"frequency_offset\"]\n\n        if frame['frame_type_int'] == FR.ARQ_SESSION_OPEN.value:\n            print(\"Received ARQ_SESSION_OPEN frame\")\n            print(f\"Session ID: {session_id}\")\n\n            # Handle cases where the session_id is already present in arq_irs_sessions\n            if session_id in self.states.arq_irs_sessions:\n                print(f\"ARQ session already in memory: {session_id}\")\n                session = self.states.arq_irs_sessions[session_id]\n                current_state = session.state\n                print(f\"ARQ session state: {current_state}\")\n\n\n                # Lost OPEN_ACK case .. ISS will retry opening a session\n                if current_state in [IRS_State.NEW, IRS_State.OPEN_ACK_SENT]:\n                    print(\"Lost OPEN_ACK case: ISS will retry opening a session.\")\n                # Case where a transmission has failed, we want to continue the transmission\n                elif current_state in [IRS_State.FAILED, IRS_State.ABORTED]:\n                    print(\"Transmission failed: Will continue the transmission.\")\n                    # TODO Lets consider adding an additional state here\n                    session.state = IRS_State.NEW\n\n                # Case where we just want to retransmit an already transmitted message\n                elif current_state == IRS_State.ENDED:\n                    print(\"Retransmitting an already transmitted message.\")\n                    session.reset_session()\n                    session.state = IRS_State.NEW\n\n            # Normal case when receiving a SESSION_OPEN for the first time\n            else:\n                print(\"First-time reception of SESSION_OPEN frame.\")\n                if self.states.check_if_running_arq_session():\n                    self.logger.warning(\"DISCARDING SESSION OPEN because of ongoing ARQ session \", frame=frame)\n                    return\n                session = ARQSessionIRS(self.config,\n                                        self.modem,\n                                        frame['origin'],\n                                        session_id,\n                                        self.states)\n                self.states.register_arq_irs_session(session)\n\n        elif frame['frame_type_int'] in [\n            FR.ARQ_SESSION_INFO.value,\n            FR.ARQ_BURST_FRAME.value,\n            FR.ARQ_STOP.value,\n        ]:\n            print(\"Received ARQ frame of type: INFO, BURST, or STOP.\")\n            session = self.states.get_arq_irs_session(session_id)\n\n        elif frame['frame_type_int'] in [\n            FR.ARQ_SESSION_OPEN_ACK.value,\n            FR.ARQ_SESSION_INFO_ACK.value,\n            FR.ARQ_BURST_ACK.value,\n            FR.ARQ_STOP_ACK.value\n        ]:\n            print(\"Received ARQ ACK frame of type: OPEN_ACK, INFO_ACK, BURST_ACK, or STOP_ACK.\")\n            session = self.states.get_arq_iss_session(session_id)\n\n        else:\n            self.logger.warning(\"DISCARDING FRAME\", frame=frame)\n            return\n\n        session.set_details(snr, frequency_offset)\n        session.on_frame_received(frame)\n"}
{"type": "source_file", "path": "freedata_server/helpers.py", "content": "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Dec 25 21:25:14 2020\n\n@author: DJ2LS\n\"\"\"\nimport time\nfrom datetime import datetime,timezone\nimport structlog\nimport numpy as np\nimport threading\nimport hashlib\nimport hmac\nimport os\nimport sys\nfrom pathlib import Path\nimport platform\nimport subprocess\nimport psutil\nimport glob\n\n\nlog = structlog.get_logger(\"helpers\")\n\n\ndef wait(seconds: float) -> bool:\n    \"\"\"\n\n    Args:\n        seconds:\n\n    Returns:\n    \"\"\"\n    timeout = time.time() + seconds\n\n    while time.time() < timeout:\n        threading.Event().wait(0.01)\n    return True\n\n\ndef get_crc_8(data: str) -> bytes:\n    \"\"\"\n    Calculate CRC-8-CCITT checksum for the given data using the ITU I.432.1 specification.\n\n    Args:\n        data (str): Input data as a string.\n\n    Returns:\n        bytes: CRC-8-CCITT checksum of the provided data.\n    \"\"\"\n    crc = 0x00\n    polynomial = 0x07\n    xor_out = 0x55\n\n    if not isinstance(data, (bytes, bytearray)):\n        data = bytes(data, \"utf-8\")\n\n    for byte in data:\n        crc ^= byte\n        for _ in range(8):\n            if crc & 0x80:\n                crc = (crc << 1) ^ polynomial\n            else:\n                crc <<= 1\n            crc &= 0xFF\n\n    # Final XOR value\n    crc ^= xor_out\n    return crc.to_bytes(1, byteorder=\"big\")\n\n\ndef get_crc_16(data: str) -> bytes:\n    \"\"\"\n    Calculate CRC-16-CCITT-FALSE checksum for the given data using the provided specification.\n\n    Args:\n        data (str): Input data as a string.\n\n    Returns:\n        bytes: CRC-16-CCITT-FALSE checksum of the provided data.\n    \"\"\"\n    crc = 0xFFFF\n    polynomial = 0x1021\n    xor_out = 0\n    if not isinstance(data, (bytes, bytearray)):\n        data = bytes(data, \"utf-8\")\n\n    for byte in data:\n        crc ^= byte << 8\n        for _ in range(8):\n            if crc & 0x8000:\n                crc = (crc << 1) ^ polynomial\n            else:\n                crc <<= 1\n            crc &= 0xFFFF\n\n    # Final XOR value\n    crc ^= xor_out\n    return crc.to_bytes(2, byteorder=\"big\")\n\n\ndef get_crc_24(data: str) -> bytes:\n    \"\"\"\n    Calculate CRC-24-OPENPGP checksum for the given data using the provided specification.\n\n    Args:\n        data (str): Input data as a string.\n\n    Returns:\n        bytes: CRC-24-OPENPGP checksum of the provided data.\n    \"\"\"\n    crc = 0xB704CE\n    polynomial = 0x864CFB\n    xor_out = 0\n\n    if not isinstance(data, (bytes, bytearray)):\n        data = bytes(data, \"utf-8\")\n\n    for byte in data:\n        crc ^= byte << 16\n        for _ in range(8):\n            if crc & 0x800000:\n                crc = (crc << 1) ^ polynomial\n            else:\n                crc <<= 1\n            crc &= 0xFFFFFF\n\n    # Final XOR value\n    crc ^= xor_out\n    return crc.to_bytes(3, byteorder=\"big\")\n\n\ndef get_crc_32(data: str) -> bytes:\n    \"\"\"\n    Calculate CRC-32 checksum for the given data using the Ethernet specification.\n\n    Args:\n        data (str): Input data as a string.\n\n    Returns:\n        bytes: CRC-32 checksum of the provided data.\n    \"\"\"\n\n    def reflect(data, width):\n        \"\"\"\n        Reflects the bits in the given data.\n\n        Args:\n            data (int): The data to reflect.\n            width (int): The bit width of the data.\n\n        Returns:\n            int: The reflected data.\n        \"\"\"\n        reflected_data = 0\n        for i in range(width):\n            if data & (1 << i):\n                reflected_data |= (1 << (width - 1 - i))\n        return reflected_data\n\n    crc = 0xFFFFFFFF\n    polynomial = 0x04C11DB7\n    xor_out = 0\n\n    if not isinstance(data, (bytes, bytearray)):\n        data = bytes(data, \"utf-8\")\n\n    for byte in data:\n        byte = reflect(byte, 8)\n        crc ^= byte << 24\n        for _ in range(8):\n            if crc & 0x80000000:\n                crc = (crc << 1) ^ polynomial\n            else:\n                crc <<= 1\n            crc &= 0xFFFFFFFF\n\n    crc = reflect(crc, 32)\n    crc ^= 0xFFFFFFFF\n    crc ^= xor_out\n    return crc.to_bytes(4, byteorder=\"big\")\n\n\nfrom datetime import datetime, timezone\nimport time\n\n\ndef add_to_heard_stations(dxcallsign, dxgrid, datatype, snr, offset, frequency, heard_stations_list, distance_km=None,\n                          distance_miles=None, away_from_key=False):\n    \"\"\"\n    Args:\n        dxcallsign (str): The callsign of the DX station.\n        dxgrid (str): The Maidenhead grid square of the DX station.\n        datatype (str): The type of data received (e.g., FT8, CW).\n        snr (int): Signal-to-noise ratio of the received signal.\n        offset (float): Frequency offset.\n        frequency (float): Base frequency of the received signal.\n        heard_stations_list (list): List containing heard stations.\n        distance_km (float): Distance to the DX station in kilometers.\n        distance_miles (float): Distance to the DX station in miles.\n        away_from_key (bool): Away from key indicator\n\n    Returns:\n        Nothing. The function updates the heard_stations_list in-place.\n    \"\"\"\n    # Convert current timestamp to an integer\n    current_timestamp = int(datetime.now(timezone.utc).timestamp())\n\n    # Initialize the new entry\n    new_entry = [\n        dxcallsign, dxgrid, current_timestamp, datatype, snr, offset, frequency, distance_km, distance_miles, away_from_key\n    ]\n\n    # Check if the buffer is empty or if the callsign is not already in the list\n    if not any(dxcallsign == station[0] for station in heard_stations_list):\n        heard_stations_list.append(new_entry)\n    else:\n        # Search for the existing entry and update\n        for i, entry in enumerate(heard_stations_list):\n            if entry[0] == dxcallsign:\n                heard_stations_list[i] = new_entry\n                break\n\n\ndef callsign_to_bytes(callsign: str) -> bytes:\n    \"\"\"\n\n    Args:\n        callsign:\n\n    Returns:\n\n    \"\"\"\n    # http://www.aprs.org/aprs11/SSIDs.txt\n    # -0 Your primary station usually fixed and message capable\n    # -1 generic additional station, digi, mobile, wx, etc\n    # -2 generic additional station, digi, mobile, wx, etc\n    # -3 generic additional station, digi, mobile, wx, etc\n    # -4 generic additional station, digi, mobile, wx, etc\n    # -5 Other networks (Dstar, Iphones, Androids, Blackberry's etc)\n    # -6 Special activity, Satellite ops, camping or 6 meters, etc\n    # -7 walkie talkies, HT's or other human portable\n    # -8 boats, sailboats, RV's or second main mobile\n    # -9 Primary Mobile (usually message capable)\n    # -10 internet, Igates, echolink, winlink, AVRS, APRN, etc\n    # -11 balloons, aircraft, spacecraft, etc\n    # -12 APRStt, DTMF, RFID, devices, one-way trackers*, etc\n    # -13 Weather stations\n    # -14 Truckers or generally full time drivers\n    # -15 generic additional station, digi, mobile, wx, etc\n\n    # Try converting to bytestring if possible type string\n    try:\n        callsign = callsign.encode(\"utf-8\")\n    except TypeError:\n        # This is expected depending on the type of the `callsign` argument.\n        # log.debug(\"[HLP] callsign_to_bytes: Error converting callsign to bytes:\", e=err)\n        pass\n    except Exception as err:\n        log.debug(\"[HLP] callsign_to_bytes: Error converting callsign to bytes:\", e=err, data=callsign)\n\n    # Need this step to reduce the needed payload by the callsign\n    # (stripping \"-\" out of the callsign)\n    callsign = callsign.split(b\"-\")\n    ssid = 0\n    try:\n        ssid = int(callsign[1])\n    except IndexError:\n        # This is expected when callsign doesn't have a dash.\n        # log.debug(\"[HLP] callsign_to_bytes: Error callsign SSID to integer:\", e=err)\n        pass\n    except Exception as err:\n        log.debug(\"[HLP] callsign_to_bytes: Error splitting callsign/ssid:\", e=err)\n\n    # callsign = callsign[0]\n    # bytestring = bytearray(8)\n    # bytestring[:len(callsign)] = callsign\n    # bytestring[7:8] = bytes([ssid])\n\n    # ---- callsign with encoding always 6 bytes long\n    callsign = callsign[0].decode(\"utf-8\")\n    ssid = bytes([ssid]).decode(\"utf-8\")\n    return encode_call(callsign + ssid)\n    # return bytes(bytestring)\n\n\ndef bytes_to_callsign(bytestring: bytes) -> bytes:\n    \"\"\"\n    Convert our callsign, received by a frame to a callsign in a human readable format\n\n    Args:\n        bytestring:\n\n    Returns:\n        bytes\n    \"\"\"\n    # http://www.aprs.org/aprs11/SSIDs.txt\n    # -0 Your primary station usually fixed and message capable\n    # -1 generic additional station, digi, mobile, wx, etc\n    # -2 generic additional station, digi, mobile, wx, etc\n    # -3 generic additional station, digi, mobile, wx, etc\n    # -4 generic additional station, digi, mobile, wx, etc\n    # -5 Other networks (Dstar, Iphones, Androids, Blackberry's etc)\n    # -6 Special activity, Satellite ops, camping or 6 meters, etc\n    # -7 walkie talkies, HT's or other human portable\n    # -8 boats, sailboats, RV's or second main mobile\n    # -9 Primary Mobile (usually message capable)\n    # -10 internet, Igates, echolink, winlink, AVRS, APRN, etc\n    # -11 balloons, aircraft, spacecraft, etc\n    # -12 APRStt, DTMF, RFID, devices, one-way trackers*, etc\n    # -13 Weather stations\n    # -14 Truckers or generally full time drivers\n    # -15 generic additional station, digi, mobile, wx, etc\n\n    # we need to do this step to reduce the needed paypload by the callsign ( stripping \"-\" out of the callsign )\n    \"\"\"\n    callsign = bytes(bytestring[:7])\n    callsign = callsign.rstrip(b\"\\x00\")\n    ssid = int.from_bytes(bytes(bytestring[7:8]), \"big\")\n\n    callsign = callsign + b\"-\"\n    callsign = callsign.decode(\"utf-8\")\n    callsign = callsign + str(ssid)\n    callsign = callsign.encode(\"utf-8\")\n\n    return bytes(callsign)\n    \"\"\"\n    decoded = decode_call(bytestring)\n    callsign = decoded[:-1]\n    ssid = ord(bytes(decoded[-1], \"utf-8\"))\n    return bytes(f\"{callsign}-{ssid}\", \"utf-8\")\n\n\ndef check_callsign(callsign: str, crc_to_check: bytes, ssid_list):\n    \"\"\"\n    Function to check a crc against a callsign to calculate the\n    ssid by generating crc until we find the correct SSID\n\n    Args:\n        callsign: Callsign which we want to check\n        crc_to_check: The CRC which we want the callsign to check against\n\n    Returns:\n        [True, Callsign + SSID]\n        False\n    \"\"\"\n    print(callsign)\n    if not isinstance(callsign, (bytes)):\n        callsign = bytes(callsign,'utf-8')\n\n    try:\n        # We want the callsign without SSID\n        splitted_callsign = callsign.split(b\"-\")\n        callsign = splitted_callsign[0]\n        ssid = splitted_callsign[1].decode()\n\n    except IndexError:\n        # This is expected when `callsign` doesn't have a dash.\n        ssid = 0\n    except Exception as err:\n        log.debug(\"[HLP] check_callsign: Error converting to bytes:\", e=err)\n\n    # ensure, we are always have the own ssid in ssid_list even if it is empty\n    if ssid not in ssid_list:\n        ssid_list.append(str(ssid))\n\n    for ssid in ssid_list:\n        call_with_ssid = callsign + b'-' + (str(ssid)).encode('utf-8')\n        callsign_crc = get_crc_24(call_with_ssid)\n        callsign_crc = callsign_crc.hex()\n\n        if callsign_crc == crc_to_check:\n            log.debug(\"[HLP] check_callsign matched:\", call_with_ssid=call_with_ssid, checksum=crc_to_check)\n            return [True, call_with_ssid.decode()]\n\n    log.debug(\"[HLP] check_callsign: Checking:\", callsign=callsign, crc_to_check=crc_to_check, own_crc=callsign_crc)\n    return [False, b'']\n\n\ndef check_session_id(id: bytes, id_to_check: bytes):\n    \"\"\"\n    Funktion to check if we received the correct session id\n\n    Args:\n        id: our own session id\n        id_to_check: The session id byte we want to check\n\n    Returns:\n        True\n        False\n    \"\"\"\n    if id_to_check == b'\\x00':\n        return False\n    log.debug(\"[HLP] check_sessionid: Checking:\", ownid=id, check=id_to_check)\n    return id == id_to_check\n\n\ndef encode_grid(grid):\n    \"\"\"\n    @author: DB1UJ\n    Args:\n        grid:string: maidenhead QTH locater [a-r][a-r][0-9][0-9][a-x][a-x]\n    Returns:\n        4 bytes contains 26 bit valid data with encoded grid locator\n    \"\"\"\n    out_code_word = 0\n\n    grid = grid.upper()  # upper case to be save\n\n    int_first = ord(grid[0]) - 65  # -65 offset for \"A\" become zero, utf8 table\n    int_sec = ord(grid[1]) - 65  # -65 offset for \"A\" become zero, utf8 table\n\n    int_val = (int_first * 18) + int_sec  # encode for modulo devision, 2 numbers in 1\n\n    out_code_word = int_val & 0b111111111  # only 9 bit LSB A - R * A - R is needed\n    out_code_word <<= 9  # shift 9 bit left having space next bits, letter A-R * A-R\n\n    int_val = int(grid[2:4])  # number string to number int, highest value 99\n    out_code_word |= int_val & 0b1111111  # using bit OR to add new value\n    out_code_word <<= 7  # shift 7 bit left having space next bits, letter A-X\n\n    int_val = ord(grid[4]) - 65  # -65 offset for 'A' become zero, utf8 table\n    out_code_word |= int_val & 0b11111  # using bit OR to add new value\n    out_code_word <<= 5  # shift 5 bit left having space next bits, letter A-X\n\n    int_val = ord(grid[5]) - 65  # -65 offset for 'A' become zero, utf8 table\n    out_code_word |= int_val & 0b11111  # using bit OR to add new value\n\n    return out_code_word.to_bytes(length=4, byteorder=\"big\")\n\n\ndef decode_grid(b_code_word: bytes):\n    \"\"\"\n    @author: DB1UJ\n    Args:\n        b_code_word:bytes: 4 bytes with 26 bit valid data LSB\n    Returns:\n        grid:str: upper case maidenhead QTH locater [A-R][A-R][0-9][0-9][A-X][A-X]\n    \"\"\"\n    code_word = int.from_bytes(b_code_word, byteorder=\"big\", signed=False)\n\n    grid = chr((code_word & 0b11111) + 65)\n    code_word >>= 5\n\n    grid = chr((code_word & 0b11111) + 65) + grid\n    code_word >>= 7\n\n    grid = str(int(code_word & 0b1111111)) + grid\n    if (code_word & 0b1111111) < 10:\n        grid = f\"0{grid}\"\n    code_word >>= 9\n\n    int_val = int(code_word & 0b111111111)\n    int_first, int_sec = divmod(int_val, 18)\n    return chr(int(int_first) + 65) + chr(int(int_sec) + 65) + grid\n\n\ndef encode_call(call):\n    \"\"\"\n    @author: DB1UJ\n    Args:\n        call:string: ham radio call sign [A-Z,0-9], last char SSID 0-63\n\n    Returns:\n        6 bytes contains 6 bits/sign encoded 8 char call sign with binary SSID\n        (only upper letters + numbers, SSID)\n    \"\"\"\n    out_code_word = 0\n\n    call = call.upper()  # upper case to be save\n\n    for char in call:\n        int_val = ord(char) - 48  # -48 reduce bits, begin with first number utf8 table\n        out_code_word <<= 6  # shift left 6 bit, making space for a new char\n        out_code_word |= (\n            int_val & 0b111111\n        )  # bit OR adds the new char, masked with AND 0b111111\n    out_code_word >>= 6  # clean last char\n    out_code_word <<= 6  # make clean space\n    out_code_word |= ord(call[-1]) & 0b111111  # add the SSID uncoded only 0 - 63\n\n    return out_code_word.to_bytes(length=6, byteorder=\"big\")\n\n\ndef decode_call(b_code_word: bytes):\n    \"\"\"\n    @author: DB1UJ\n    Args:\n        b_code_word:bytes: 6 bytes with 6 bits/sign valid data char signs LSB\n\n    Returns:\n        call:str: upper case ham radio call sign [A-Z,0-9] + binary SSID\n    \"\"\"\n    code_word = int.from_bytes(b_code_word, byteorder=\"big\", signed=False)\n    ssid = chr(code_word & 0b111111)  # save the uncoded binary SSID\n\n    call = str()\n    while code_word != 0:\n        call = chr((code_word & 0b111111) + 48) + call\n        code_word >>= 6\n\n    call = call[:-1] + ssid  # remove the last char from call and replace with SSID\n\n    return call\n\n\ndef snr_to_bytes(snr):\n    \"\"\"create a byte from snr value \"\"\"\n    # make sure we have onl 1 byte snr\n    # min max = -12.7 / 12.7\n    # enough for detecting if a channel is good or bad\n    snr = snr * 10\n    snr = np.clip(snr, -127, 127)\n    snr = int(snr).to_bytes(1, byteorder='big', signed=True)\n    return snr\n\n\ndef snr_from_bytes(snr):\n    \"\"\"create int from snr byte\"\"\"\n    snr = int.from_bytes(snr, byteorder='big', signed=True)\n    snr = snr / 10\n    return snr\n\n\ndef safe_execute(default, exception, function, *args):\n    \"\"\"\n    https://stackoverflow.com/a/36671208\n    from json import loads\n    safe_execute(\"Oh no, explosions occurred!\", TypeError, loads, None)\n\n    \"\"\"\n    try:\n        return function(*args)\n    except exception:\n        return default\n\n\ndef return_key_from_object(default, obj, key):\n\n    try:\n        return obj[key]\n    except KeyError:\n        return default\n\n\ndef bool_to_string(state):\n    return \"True\" if state else \"False\"\n\n\n\n\ndef get_hmac_salt(dxcallsign: bytes, mycallsign: bytes):\n    filename = f\"freedata_hmac_STATION_{mycallsign.decode('utf-8')}_REMOTE_{dxcallsign.decode('utf-8')}.txt\"\n    if sys.platform in [\"linux\"]:\n\n        if hasattr(sys, \"_MEIPASS\"):\n            filepath = getattr(sys, \"_MEIPASS\") + '/hmac/' + filename\n        else:\n            subfolder = Path('hmac')\n            filepath = subfolder / filename\n\n\n    elif sys.platform in [\"darwin\"]:\n        if hasattr(sys, \"_MEIPASS\"):\n            filepath = getattr(sys, \"_MEIPASS\") + '/hmac/' + filename\n        else:\n            subfolder = Path('hmac')\n            filepath = subfolder / filename\n\n    elif sys.platform in [\"win32\", \"win64\"]:\n        if hasattr(sys, \"_MEIPASS\"):\n            filepath = getattr(sys, \"_MEIPASS\") + '/hmac/' + filename\n        else:\n            subfolder = Path('hmac')\n            filepath = subfolder / filename\n    else:\n        try:\n            subfolder = Path('hmac')\n            filepath = subfolder / filename\n        except Exception as e:\n            log.error(\n                \"[Modem] [HMAC] File lookup error\", file=filepath,\n            )\n\n    # check if file exists else return false\n    if not check_if_file_exists(filepath):\n        return False\n\n    log.info(\"[SCK] [HMAC] File lookup\", file=filepath)\n\n    try:\n        with open(filepath, \"r\") as file:\n            line = file.readlines()\n            hmac_salt = bytes(line[-1], \"utf-8\").split(b'\\n')\n            hmac_salt = hmac_salt[0]\n            return hmac_salt if delete_last_line_from_hmac_list(filepath, -1) else False\n    except Exception as e:\n        log.warning(\"[SCK] [HMAC] File lookup failed\", file=filepath, e=e)\n        return False\n\ndef search_hmac_salt(dxcallsign: bytes, mycallsign: bytes, search_token, data_frame, token_iters):\n\n    filename = f\"freedata_hmac_STATION_{mycallsign.decode('utf-8')}_REMOTE_{dxcallsign.decode('utf-8')}.txt\"\n    if sys.platform in [\"linux\"]:\n\n        if hasattr(sys, \"_MEIPASS\"):\n            filepath = getattr(sys, \"_MEIPASS\") + '/hmac/' + filename\n        else:\n            subfolder = Path('hmac')\n            filepath = subfolder / filename\n\n\n    elif sys.platform in [\"darwin\"]:\n        if hasattr(sys, \"_MEIPASS\"):\n            filepath = getattr(sys, \"_MEIPASS\") + '/hmac/' + filename\n        else:\n            subfolder = Path('hmac')\n            filepath = subfolder / filename\n\n    elif sys.platform in [\"win32\", \"win64\"]:\n        if hasattr(sys, \"_MEIPASS\"):\n            filepath = getattr(sys, \"_MEIPASS\") + '/hmac/' + filename\n        else:\n            subfolder = Path('hmac')\n            filepath = subfolder / filename\n    else:\n        try:\n            subfolder = Path('hmac')\n            filepath = subfolder / filename\n        except Exception as e:\n            log.error(\n                \"[Modem] [HMAC] File lookup error\", file=filepath,\n            )\n\n    # check if file exists else return false\n    if not check_if_file_exists(filepath):\n        log.warning(\n            \"[Modem] [HMAC] Token file not found\", file=filepath,\n        )\n        return False\n\n    try:\n        with open(filepath, \"r\") as file:\n            token_list = file.readlines()\n\n            token_iters = min(token_iters, len(token_list))\n            for _ in range(1, token_iters + 1):\n                key = token_list[len(token_list) - _][:-1]\n                key = bytes(key, \"utf-8\")\n                search_digest = hmac.new(key, data_frame, hashlib.sha256).digest()[:4]\n                # TODO Remove this debugging information if not needed anymore\n                # print(\"-----------------------------------------\")\n                # print(_)\n                # print(f\" key-------------{key}\")\n                # print(f\" key-------------{token_list[len(token_list) - _][:-1]}\")\n                # print(f\" key-------------{key.hex()}\")\n                # print(f\" search token----{search_token.hex()}\")\n                # print(f\" search digest---{search_digest.hex()}\")\n                if search_token.hex() == search_digest.hex():\n                    token_position = len(token_list) - _\n                    delete_last_line_from_hmac_list(filepath, token_position)\n                    log.info(\n                        \"[Modem] [HMAC] Signature found\", expected=search_token.hex(),\n                    )\n                    return True\n\n\n        log.warning(\n            \"[Modem] [HMAC] Signature not found\", expected=search_token.hex(), filepath=filepath,\n        )\n        return False\n\n    except Exception as e:\n        log.warning(\n            \"[Modem] [HMAC] Lookup failed\", e=e, expected=search_token,\n        )\n        return False\n\n\ndef delete_last_line_from_hmac_list(filepath, position):\n    # check if file exists else return false\n    if not check_if_file_exists(filepath):\n        return False\n\n    try:\n        linearray = []\n        with open(filepath, \"r\") as file:\n            linearray = file.readlines()[:position]\n            #print(linearray)\n\n        with open(filepath, \"w\") as file:\n            #print(linearray)\n            for line in linearray:\n                file.write(line)\n\n        return True\n\n    except Exception:\n        return False\n\ndef check_if_file_exists(path):\n    try:\n        # check if file size is present and filesize > 0\n        if os.path.isfile(path):\n            filesize = os.path.getsize(path)\n            if filesize > 0:\n                return True\n            else:\n                return False\n        else:\n            return False\n    except Exception as e:\n        log.warning(\n            \"[Modem] [FILE] Lookup failed\", e=e, path=path,\n        )\n        return False\n\n\ndef set_bit(byte, position, value):\n    \"\"\"Set the bit at 'position' to 'value' in the given byte.\"\"\"\n    if not 0 <= position <= 7:\n        raise ValueError(\"Position must be between 0 and 7\")\n\n    if value:\n        return byte | (1 << position)\n    else:\n        return byte & ~(1 << position)\n\ndef get_bit(byte, position):\n    \"\"\"Get the boolean value of the bit at 'position' in the given byte.\"\"\"\n    if not 0 <= position <= 7:\n        raise ValueError(\"Position must be between 0 and 7\")\n\n    return (byte & (1 << position)) != 0\n\ndef set_flag(byte, flag_name, value, flag_dict):\n    \"\"\"Set the flag in the byte according to the flag dictionary.\n\n    # Define a dictionary mapping flag names to their bit positions\n        flag_dict = {\n            'FLAG1': 0,  # Bit position for FLAG1\n            'FLAG2': 1,  # Bit position for FLAG2, etc.\n            'FLAG3': 2\n        }\n\n    \"\"\"\n    if flag_name not in flag_dict:\n        raise ValueError(f\"Unknown flag name: {flag_name}\")\n    position = flag_dict[flag_name]\n    return set_bit(byte, position, value)\n\n\ndef get_flag(byte, flag_name, flag_dict):\n    \"\"\"Get the value of the flag from the byte according to the flag dictionary.\"\"\"\n    if flag_name not in flag_dict:\n        raise ValueError(f\"Unknown flag name: {flag_name}\")\n    position = flag_dict[flag_name]\n    return get_bit(byte, position)\n\n\ndef find_binary_paths(binary_name=\"rigctld\", search_system_wide=False):\n    \"\"\"\n    Search for a binary within the current working directory, its subdirectories, and optionally,\n    system-wide locations and the PATH environment variable.\n\n    :param binary_name: The base name of the binary to search for, without extension.\n    :param search_system_wide: Boolean flag to enable or disable system-wide search.\n    :return: A list of full paths to the binary if found, otherwise an empty list.\n    \"\"\"\n    binary_paths = []  # Initialize an empty list to store found paths\n    # Adjust binary name for Windows\n    if platform.system() == 'Windows':\n        binary_name += \".exe\"\n\n    # Search in the current working directory and subdirectories\n    root_path = os.getcwd()\n    for dirpath, dirnames, filenames in os.walk(root_path):\n        if binary_name in filenames:\n            binary_paths.append(os.path.join(dirpath, binary_name))\n\n    # If system-wide search is enabled, look in system locations and PATH\n    if search_system_wide:\n        system_paths = os.environ.get('PATH', '').split(os.pathsep)\n        # Optionally add common binary locations for Unix-like and Windows systems\n        if platform.system() != 'Windows':\n            system_paths.extend(['/usr/bin', '/usr/local/bin', '/bin'])\n        else:\n            system_paths.extend(glob.glob(\"C:\\\\Program Files\\\\Hamlib*\\\\bin\"))\n            system_paths.extend(glob.glob(\"C:\\\\Program Files (x86)\\\\Hamlib*\\\\bin\"))\n\n        for path in system_paths:\n            potential_path = os.path.join(path, binary_name)\n            if os.path.isfile(potential_path):\n                binary_paths.append(potential_path)\n\n    return binary_paths\n\n\n\ndef kill_and_execute(binary_path, additional_args=None):\n    \"\"\"\n    Kills any running instances of the binary across Linux, macOS, and Windows, then starts a new one non-blocking.\n\n    :param binary_path: The full path to the binary to execute.\n    :param additional_args: A list of additional arguments to pass to the binary.\n    :return: subprocess.Popen object of the started process\n    \"\"\"\n    # Kill any existing instances of the binary\n    for proc in psutil.process_iter(attrs=['pid', 'name', 'cmdline']):\n        try:\n            cmdline = proc.info['cmdline']\n            # Ensure cmdline is iterable and not None\n            if cmdline and binary_path in ' '.join(cmdline):\n                proc.kill()\n                print(f\"Killed running instance with PID: {proc.info['pid']}\")\n        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n            pass  # Process no longer exists or no permission to kill\n\n    # Execute the binary with additional arguments non-blocking\n    command = [binary_path] + (additional_args if additional_args else [])\n    return subprocess.Popen(command)\n\ndef kill_process(proc):\n    try:\n        ps_proc = psutil.Process(proc.pid)\n        ps_proc.kill()\n        print(f\"Killed running instance with PID: {proc.pid}\")\n    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess) as e:\n        print(f\"Failed to kill process: {e}\")\n"}
{"type": "source_file", "path": "freedata_server/message_p2p.py", "content": "from datetime import datetime, timezone\nimport api_validations\nimport base64\nimport json\nfrom message_system_db_manager import DatabaseManager\nfrom message_system_db_messages import DatabaseManagerMessages\n#import command_message_send\n\n\ndef message_received(event_manager, state_manager, data, statistics):\n    decompressed_json_string = data.decode('utf-8')\n    received_message_obj = MessageP2P.from_payload(decompressed_json_string)\n    received_message_dict = MessageP2P.to_dict(received_message_obj)\n    DatabaseManagerMessages(event_manager).add_message(received_message_dict, statistics, direction='receive', status='received', is_read=False, frequency=state_manager.radio_frequency)\n\ndef message_transmitted(event_manager, state_manager, data, statistics):\n    decompressed_json_string = data.decode('utf-8')\n    payload_message_obj = MessageP2P.from_payload(decompressed_json_string)\n    payload_message = MessageP2P.to_dict(payload_message_obj)\n    # Todo we need to optimize this - WIP\n    DatabaseManagerMessages(event_manager).update_message(payload_message[\"id\"], update_data={'status': 'transmitted'})\n    DatabaseManagerMessages(event_manager).update_message(payload_message[\"id\"], update_data={'statistics': statistics}, frequency=state_manager.radio_frequency)\n\n\ndef message_failed(event_manager, state_manager, data, statistics):\n    decompressed_json_string = data.decode('utf-8')\n    payload_message_obj = MessageP2P.from_payload(decompressed_json_string)\n    payload_message = MessageP2P.to_dict(payload_message_obj)\n    # Todo we need to optimize this - WIP\n    DatabaseManagerMessages(event_manager).update_message(payload_message[\"id\"], update_data={'status': 'failed'})\n    DatabaseManagerMessages(event_manager).update_message(payload_message[\"id\"], update_data={'statistics': statistics}, frequency=state_manager.radio_frequency)\n\nclass MessageP2P:\n    def __init__(self, id: str, origin: str, destination: str, body: str, attachments: list) -> None:\n        self.id = id\n        self.timestamp = datetime.now(timezone.utc).isoformat()\n        self.origin = origin\n        self.destination = destination\n        self.body = body\n        self.attachments = attachments\n\n    @classmethod\n    def from_api_params(cls, origin: str, params: dict):\n\n        destination = params['destination']\n        if not api_validations.validate_freedata_callsign(destination):\n            destination = f\"{destination}-0\"\n\n        if not api_validations.validate_freedata_callsign(destination):\n            raise ValueError(f\"Invalid destination given ({params['destination']})\")\n\n        body = params['body']\n\n        attachments = []\n        if 'attachments' in params: \n            for a in params['attachments']:\n                api_validations.validate_message_attachment(a)\n                attachments.append(cls.__decode_attachment__(a))\n\n        timestamp = datetime.now(timezone.utc).isoformat()\n        if 'id' not in params:\n            msg_id = f\"{origin}_{destination}_{timestamp}\"\n        else:\n            msg_id = params[\"id\"]\n\n        return cls(msg_id, origin, destination, body, attachments)\n        \n    @classmethod\n    def from_payload(cls, payload):\n        payload_message = json.loads(payload)\n        attachments = list(map(cls.__decode_attachment__, payload_message['attachments']))\n        return cls(payload_message['id'], payload_message['origin'], payload_message['destination'],\n                   payload_message['body'], attachments)\n\n    def get_id(self) -> str:\n        return f\"{self.origin}_{self.destination}_{self.timestamp}\"\n\n    def __encode_attachment__(self, binary_attachment: dict):\n        encoded_attachment = binary_attachment.copy()\n        encoded_attachment['data'] = str(base64.b64encode(binary_attachment['data']), 'utf-8')\n        return encoded_attachment\n    \n    def __decode_attachment__(encoded_attachment: dict):\n        decoded_attachment = encoded_attachment.copy()\n        decoded_attachment['data'] = base64.b64decode(encoded_attachment['data'])\n        return decoded_attachment\n\n    def to_dict(self):\n        \"\"\"Make a dictionary out of the message data\n        \"\"\"\n\n        return {\n            'id': self.id,\n            'origin': self.origin,\n            'destination': self.destination,\n            'body': self.body,\n            'attachments': list(map(self.__encode_attachment__, self.attachments)),\n        }\n    \n    def to_payload(self):\n        \"\"\"Make a byte array ready to be sent out of the message data\"\"\"\n        json_string = json.dumps(self.to_dict())\n        return json_string\n\n"}
{"type": "source_file", "path": "freedata_server/explorer.py", "content": "# -*- coding: UTF-8 -*-\n\"\"\"\nCreated on 05.11.23\n\n@author: DJ2LS\n\"\"\"\n# pylint: disable=invalid-name, line-too-long, c-extension-no-member\n# pylint: disable=import-outside-toplevel, attribute-defined-outside-init\n\nimport requests\nimport threading\nimport json\nimport structlog\nimport sched\nimport time\n\nlog = structlog.get_logger(\"explorer\")\n\nclass Explorer:\n    def __init__(self, modem_version, config_manager, states):\n        self.modem_version = modem_version\n        self.config_manager = config_manager\n        self.config = self.config_manager.read()\n        self.states = states\n        self.explorer_url = \"https://api.freedata.app/explorer.php\"\n\n    def push(self):\n        self.config = self.config_manager.read()\n\n        frequency = 0 if self.states.radio_frequency is None else self.states.radio_frequency\n        band = \"USB\"\n        callsign = f\"{self.config['STATION']['mycall']}-{self.config['STATION']['myssid']}\"\n        gridsquare = str(self.config['STATION']['mygrid'])\n        version = str(self.modem_version)\n        bandwidth = str(self.config['MODEM']['maximum_bandwidth'])\n        beacon = str(self.states.is_beacon_running)\n        strength = str(self.states.s_meter_strength)\n        away_from_key = str(self.states.is_away_from_key)\n\n        # Stop pushing if default callsign\n        if callsign in ['AA1AAA-1', 'XX1XXX-6']:\n            return\n\n        headers = {\"Content-Type\": \"application/json\"}\n        station_data = {\n            'callsign': callsign,\n            'gridsquare': gridsquare,\n            'frequency': frequency,\n            'strength': strength,\n            'band': band,\n            'version': version,\n            'bandwidth': bandwidth,\n            'beacon': beacon,\n            \"lastheard\": [],\n            \"away_from_key\": away_from_key\n        }\n\n        for i in self.states.heard_stations:\n            try:\n                callsign = i[0]\n                grid = i[1]\n                timestamp = i[2]\n                frequency = i[6]\n                try:\n                    snr = i[4].split(\"/\")[1] if isinstance(i[4], str) and \"/\" in i[4] else str(i[4])\n                except Exception as e:\n                    snr = \"N/A\"\n                    log.warning(\"[EXPLORER] SNR parsing failed\", e=e)\n                station_data[\"lastheard\"].append({\n                    \"callsign\": callsign,\n                    \"grid\": grid,\n                    \"snr\": snr,\n                    \"timestamp\": timestamp,\n                    \"frequency\": frequency\n                })\n            except Exception as e:\n                log.debug(\"[EXPLORER] not publishing station\", e=e)\n        station_data = json.dumps(station_data)\n        try:\n            response = requests.post(self.explorer_url, json=station_data, headers=headers)\n            if response.status_code == 200:\n                log.info(\"[EXPLORER] Data pushed successfully\")\n            else:\n                log.error(\"[EXPLORER] Failed to push data\", status_code=response.status_code, response_text=response.text)\n        except requests.exceptions.RequestException as e:\n            log.warning(\"[EXPLORER] Connection lost\", e=e)\n"}
{"type": "source_file", "path": "freedata_server/maidenhead.py", "content": "import math\nimport random\n\ndef haversine(lat1, lon1, lat2, lon2):\n    \"\"\"\n    Calculate the great circle distance in kilometers between two points\n    on the Earth (specified in decimal degrees).\n\n    Parameters:\n    lat1, lon1: Latitude and longitude of point 1.\n    lat2, lon2: Latitude and longitude of point 2.\n\n    Returns:\n    float: Distance between the two points in kilometers.\n    \"\"\"\n    # Radius of the Earth in kilometers. Use 3956 for miles\n    R = 6371.0\n\n    # Convert latitude and longitude from degrees to radians\n    lat1 = math.radians(lat1)\n    lon1 = math.radians(lon1)\n    lat2 = math.radians(lat2)\n    lon2 = math.radians(lon2)\n\n    # Difference in coordinates\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    # Haversine formula\n    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n\n    distance = R * c\n\n    return distance\n\n\ndef maidenhead_to_latlon(grid_square):\n    \"\"\"\n    Convert a Maidenhead locator to latitude and longitude coordinates.\n    The output coordinates represent the southwestern corner of the grid square.\n\n    Parameters:\n    grid_square (str): The Maidenhead locator.\n\n    Returns:\n    tuple: A tuple containing the latitude and longitude (in that order) of the grid square's center.\n    \"\"\"\n\n    grid_square = generate_full_maidenhead(grid_square)\n\n    grid_square = grid_square.upper()\n    lon = -180 + (ord(grid_square[0]) - ord('A')) * 20\n    lat = -90 + (ord(grid_square[1]) - ord('A')) * 10\n    lon += (int(grid_square[2]) * 2)\n    lat += int(grid_square[3])\n\n    if len(grid_square) >= 6:\n        lon += (ord(grid_square[4]) - ord('A')) * (5 / 60)\n        lat += (ord(grid_square[5]) - ord('A')) * (2.5 / 60)\n\n    # not needed now as we always have 6 digits\n    if len(grid_square) == 8:\n        lon += int(grid_square[6]) * (5 / 600)\n        lat += int(grid_square[7]) * (2.5 / 600)\n\n    # Adjust to the center of the grid square\n    # not needed now as we always have 6 digits\n    if len(grid_square) <= 4:\n        lon += 1\n        lat += 0.5\n    elif len(grid_square) == 6:\n        lon += 2.5 / 60\n        lat += 1.25 / 60\n    else:\n        lon += 2.5 / 600\n        lat += 1.25 / 600\n\n    return lat, lon\n\n\ndef distance_between_locators(locator1, locator2):\n    \"\"\"\n    Calculate the distance between two Maidenhead locators and return the result as a dictionary.\n\n    Parameters:\n    locator1 (str): The first Maidenhead locator.\n    locator2 (str): The second Maidenhead locator.\n\n    Returns:\n    dict: A dictionary containing the distances in kilometers and miles.\n    \"\"\"\n    lat1, lon1 = maidenhead_to_latlon(locator1)\n    lat2, lon2 = maidenhead_to_latlon(locator2)\n    km = haversine(lat1, lon1, lat2, lon2)\n    miles = km * 0.621371\n    return {'kilometers': km, 'miles': miles}\n\n\nimport random\n\n\nimport random\nimport string\n\ndef generate_full_maidenhead(grid_square):\n    \"\"\"\n    Convert a Maidenhead locator of 2 or 4 characters to a 6-character locator\n    by generating random characters for the missing positions, while ensuring the correct format:\n    1-2: Uppercase letters (A-R)\n    3-4: Digits (0-9)\n    5-6: Lowercase letters (a-r)\n\n    Parameters:\n    grid_square (str): A 2, 4, or 6 character Maidenhead locator.\n\n    Returns:\n    str: A 6-character Maidenhead locator.\n    \"\"\"\n\n    grid_square = grid_square.upper()\n\n    # If the grid square is longer than 6 characters, strip it to 6 characters\n    if len(grid_square) > 6:\n        grid_square = grid_square[:6]\n\n    if len(grid_square) == 2:\n        # Generate random digits for positions 3 and 4\n        grid_square += f\"{random.randint(0, 9)}{random.randint(0, 9)}\"\n        # Generate random lowercase letters from 'a' to 'r' for positions 5 and 6\n        grid_square += random.choice(\"abcdefghijklmnopqr\")\n        grid_square += random.choice(\"abcdefghijklmnopqr\")\n\n    elif len(grid_square) == 4:\n        # Generate random lowercase letters from 'a' to 'r' for positions 5 and 6\n        grid_square += random.choice(\"abcdefghijklmnopqr\")\n        grid_square += random.choice(\"abcdefghijklmnopqr\")\n\n    elif len(grid_square) == 6:\n        # If grid square is valid and already 6 characters, enforce format\n        grid_square = grid_square[:2].upper() + grid_square[2:4] + grid_square[4:6].lower()\n        return grid_square\n\n    else:\n        raise ValueError(\"Grid square must be 2, 4, or 6 characters long.\")\n\n    # Adjust the case for the last two characters\n    grid_square = grid_square[:4] + grid_square[4:].lower()\n    return grid_square\n\n\n"}
{"type": "source_file", "path": "freedata_server/frame_handler_beacon.py", "content": "import frame_handler\nimport datetime\nfrom message_system_db_beacon import DatabaseManagerBeacon\nfrom message_system_db_messages import DatabaseManagerMessages\n\n\nfrom message_system_db_manager import DatabaseManager\nclass BeaconFrameHandler(frame_handler.FrameHandler):\n\n    def follow_protocol(self):\n        DatabaseManagerBeacon(self.event_manager).add_beacon(datetime.datetime.now(),\n                                                             self.details['frame'][\"origin\"],\n                                                             self.details[\"snr\"],\n                                                             self.details['frame'][\"gridsquare\"]\n                                                             )\n\n        # only check for queued messages, if we have enabled this and if we have a minimum snr received\n        if self.config[\"MESSAGES\"][\"enable_auto_repeat\"] and self.details[\"snr\"] >= -2:\n            # set message to queued if beacon received\n            DatabaseManagerMessages(self.event_manager).set_message_to_queued_for_callsign(self.details['frame'][\"origin\"])\n"}
{"type": "source_file", "path": "freedata_server/frame_handler_ping.py", "content": "import frame_handler\nimport helpers\nimport data_frame_factory\nfrom message_system_db_messages import DatabaseManagerMessages\n\n\nclass PingFrameHandler(frame_handler.FrameHandler):\n\n    #def is_frame_for_me(self):\n    #    call_with_ssid = self.config['STATION']['mycall'] + \"-\" + str(self.config['STATION']['myssid'])\n    #    valid, mycallsign = helpers.check_callsign(\n    #        call_with_ssid,\n    #        self.details[\"frame\"][\"destination_crc\"],\n    #        self.config['STATION']['ssid_list'])\n\n    #    if not valid:\n    #        ft = self.details['frame']['frame_type']\n    #        self.logger.info(f\"[Modem] {ft} received but not for us.\")\n    #    return valid\n\n    def follow_protocol(self):\n        if not bool(self.is_frame_for_me() and not self.states.getARQ()):\n            return\n        self.logger.debug(\n            f\"[Modem] Responding to request from [{self.details['frame']['origin']}]\",\n            snr=self.details['snr'],\n        )\n\n        self.send_ack()\n\n        self.check_for_queued_message()\n\n    def send_ack(self):\n        factory = data_frame_factory.DataFrameFactory(self.config)\n        ping_ack_frame = factory.build_ping_ack(\n            self.details['frame']['origin_crc'], \n            self.details['snr']\n        )\n        self.transmit(ping_ack_frame)\n\n    def check_for_queued_message(self):\n\n        # only check for queued messages, if we have enabled this and if we have a minimum snr received\n        if self.config[\"MESSAGES\"][\"enable_auto_repeat\"] and self.details[\"snr\"] >= -2:\n            # set message to queued if beacon received\n            DatabaseManagerMessages(self.event_manager).set_message_to_queued_for_callsign(\n                self.details['frame'][\"origin\"])"}
