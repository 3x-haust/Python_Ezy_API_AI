{"repo_info": {"repo_name": "docflow", "repo_owner": "jiisanda", "repo_url": "https://github.com/jiisanda/docflow"}}
{"type": "source_file", "path": "__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/dependencies/auth_utils.py", "content": "from datetime import datetime, timedelta\nfrom typing import Any, Dict\n\nfrom fastapi import Depends\nfrom fastapi.security import OAuth2PasswordBearer\nfrom jose import jwt, JWTError\nfrom passlib.context import CryptContext\n\nfrom app.core.config import settings\nfrom app.core.exceptions import http_401\nfrom app.schemas.auth.bands import TokenData\n\n\n# Password Hashing\npassword_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n# oauth2 scheme\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"api/u/login\", scheme_name=\"JWT\")\n\n\ndef get_hashed_password(password: str) -> str:\n    return password_context.hash(password)\n\n\ndef verify_password(password: str, hashed_password: str) -> bool:\n    return password_context.verify(password, hashed_password)\n\n\ndef create_access_token(\n    subject: Dict[str, Any], expires_delta: timedelta = None\n) -> str:\n    if expires_delta is not None:\n        expires_delta = datetime.utcnow() + expires_delta\n    else:\n        expires_delta = datetime.utcnow() + timedelta(\n            minutes=settings.access_token_expire_min\n        )\n\n    to_encode = {\n        \"exp\": expires_delta,\n        \"id\": subject.get(\"id\"),\n        \"username\": subject.get(\"username\"),\n    }\n\n    return jwt.encode(to_encode, settings.jwt_secret_key, settings.algorithm)\n\n\ndef create_refresh_token(\n    subject: Dict[str, Any], expires_delta: timedelta = None\n) -> str:\n    if expires_delta is not None:\n        expires_delta = datetime.utcnow() + expires_delta\n    else:\n        expires_delta = datetime.utcnow() + timedelta(\n            minutes=settings.refresh_token_expire_min\n        )\n\n    to_encode = {\n        \"exp\": expires_delta,\n        \"id\": subject.get(\"id\"),\n        \"username\": subject.get(\"username\"),\n    }\n\n    return jwt.encode(to_encode, settings.jwt_secret_key, settings.algorithm)\n\n\ndef verify_access_token(token: str, credentials_exception):\n    try:\n        payload = jwt.decode(\n            token, settings.jwt_secret_key, algorithms=[settings.algorithm]\n        )\n        uid = payload.get(\"id\")\n        username = payload.get(\"username\")\n        if username is None:\n            raise credentials_exception\n        token_data = TokenData(id=uid, username=username)\n    except JWTError as e:\n        raise credentials_exception from e\n\n    return token_data\n\n\ndef get_current_user(token: str = Depends(oauth2_scheme)):\n    credentials_exception = http_401(\n        msg=\"Could not validate credentials\", headers={\"WWW-Authenticate\": \"Bearer\"}\n    )\n\n    return verify_access_token(token=token, credentials_exception=credentials_exception)\n"}
{"type": "source_file", "path": "app/api/routes/documents/__init__.py", "content": ""}
{"type": "source_file", "path": "app/core/exceptions.py", "content": "from typing import Dict\n\nfrom fastapi.exceptions import HTTPException\nfrom starlette import status\n\n\ndef http_400(msg: str = \"Bad Request...\") -> HTTPException:\n    \"\"\"Invalid Input\"\"\"\n    return HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=msg)\n\n\ndef http_401(\n    msg: str = \"Unauthorized\", headers: Dict[str, str] = None\n) -> HTTPException:\n    \"\"\"Unauthorized Access\"\"\"\n    return HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED, detail=msg, headers=headers\n    )\n\n\ndef http_403(msg: str = \"Forbidden\") -> HTTPException:\n    \"\"\"Forbidden access\"\"\"\n    return HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=msg)\n\n\ndef http_404(msg: str = \"Entity does not exists...\") -> HTTPException:\n    \"\"\"Raised when entity was not found on database.\"\"\"\n    return HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=msg)\n\n\ndef http_409(msg: str = \"Entity already exists...\") -> HTTPException:\n    \"\"\"Raised when entity already exists on database.\"\"\"\n    return HTTPException(status_code=status.HTTP_409_CONFLICT, detail=msg)\n\n\ndef http_500(msg: str = \"Internal Server Error\") -> HTTPException:\n    \"\"\"Raised when error caused due to internal server\"\"\"\n    return HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=msg)\n"}
{"type": "source_file", "path": "app/api/routes/documents/document_organization.py", "content": "from fastapi import APIRouter, Depends, status, Query\n\nfrom app.api.dependencies.repositories import get_repository\nfrom app.api.dependencies.auth_utils import get_current_user\nfrom app.db.repositories.documents.documents_metadata import DocumentMetadataRepository\nfrom app.db.repositories.documents.document_organization import DocumentOrgRepository\nfrom app.schemas.auth.bands import TokenData\n\nrouter = APIRouter(tags=[\"Document Search\"])\n\n\n@router.get(\n    \"\",\n    # response_model=List[DocumentMetadataRead],\n    status_code=status.HTTP_200_OK,\n    name=\"search_document\",\n)\nasync def search_document(\n    limit: int = Query(default=10, lt=100),\n    offset: int = Query(default=0),\n    tag: str = None,\n    category: str = None,\n    file_types: str = None,\n    doc_status: str = None,\n    repository: DocumentOrgRepository = Depends(DocumentOrgRepository),\n    repository_metadata: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n):\n    \"\"\"\n    Searches for documents based on specified criteria.\n\n    Args:\n        limit (int): The maximum number of documents to retrieve. Defaults to 10.\n        offset (int): The number of documents to skip. Defaults to 0.\n        tag (str, optional): The tag to filter documents by. Defaults to None.\n        category (str, optional): The category to filter documents by. Defaults to None.\n        file_types (str, optional): The file types to filter documents by. Defaults to None.\n        doc_status (str, optional): The status of documents to filter by. Defaults to None.\n        repository (DocumentOrgRepository): The repository for managing document organization.\n        repository_metadata (DocumentMetadataRepository): The repository for managing\n            document metadata.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        List[DocumentMetadataRead] or List[Dict[str, Any]]: The list of matching documents.\n    \"\"\"\n\n    doc_list = await repository_metadata.doc_list(\n        limit=limit, offset=offset, owner=user\n    )\n    doc_list = doc_list[f\"documents of {user.username}\"]\n    if tag is None and category is None and file_types is None and doc_status is None:\n        return doc_list\n\n    return await repository.search_doc(\n        docs=doc_list,\n        tags=tag,\n        categories=category,\n        file_types=file_types,\n        status=doc_status,\n    )\n"}
{"type": "source_file", "path": "app/core/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/dependencies/repositories.py", "content": "import os.path\nimport re\nimport ulid\n\nfrom fastapi import Depends\nfrom fastapi.responses import FileResponse\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core.config import settings\nfrom app.db.models import async_session\n\n\nclass TempFileResponse(FileResponse):\n    def __init__(self, path, *args, **kwargs):\n        super().__init__(path, *args, **kwargs)\n        self.file_path = path\n\n    def __del__(self):\n        if os.path.exists(self.file_path):\n            os.remove(self.file_path)\n\n\nasync def get_db() -> AsyncSession:\n    async with async_session() as session:\n        yield session\n        await session.commit()\n\n\ndef get_repository(repository):\n    def _get_repository(session: AsyncSession = Depends(get_db)):\n        return repository(session)\n\n    return _get_repository\n\n\nasync def get_s3_url(key: str) -> str:\n    return f\"https://{settings.s3_bucket}.s3.{settings.aws_region}.amazonaws.com/{key}\"\n\n\nasync def get_key(s3_url: str) -> str:\n\n    pattern = (\n        f\"https://{settings.s3_bucket}\"\n        + r\"\\.s3\\.\"\n        + settings.aws_region\n        + r\"\\.amazonaws\\.com/\"\n        + r\"(.+)\"\n    )\n    if match := re.search(pattern, s3_url):\n        return match[1]\n\n\ndef get_ulid():\n    return str(ulid.ULID())\n"}
{"type": "source_file", "path": "app/api/routes/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/dependencies/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/dependencies/constants.py", "content": "SUPPORTED_FILE_TYPES = {\n    \"image/jpeg\": \"jpg\",\n    \"image/png\": \"png\",\n    \"image/gif\": \"gif\",\n    \"image/bmp\": \"bmp\",\n    \"image/tiff\": \"tiff\",\n    \"application/pdf\": \"pdf\",\n    \"text/plain\": \"txt\",\n    \"application/msword\": \"doc\",\n    \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\": \"docx\",\n    \"application/vnd.ms-excel\": \"xls\",\n    \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\": \"xlsx\",\n    \"application/vnd.ms-powerpoint\": \"ppt\",\n    \"application/vnd.openxmlformats-officedocument.presentationml.presentation\": \"pptx\",\n    \"application/zip\": \"zip\",\n    \"application/x-gzip\": \"gzip\",\n    \"application/x-tar\": \"tar\",\n    \"application/x-bzip2\": \"bz2\",\n    \"application/x-7z-compressed\": \"7z\",\n    \"application/xml\": \"xml\",\n    \"application/json\": \"json\",\n    \"video/mp4\": \"mp4\",\n    \"video/mpeg\": \"mpeg\",\n    \"video/quicktime\": \"mov\",\n    \"audio/mpeg\": \"mp3\",\n    \"audio/wav\": \"wav\",\n    \"audio/x-ms-wma\": \"wma\",\n}\n"}
{"type": "source_file", "path": "app/api/router.py", "content": "from fastapi import APIRouter\n\nfrom app.api.routes.auth.auth import router as auth_router\nfrom app.api.routes.documents.documents_metadata import (\n    router as documents_metadata_router,\n)\nfrom app.api.routes.documents.document import router as documents_router\nfrom app.api.routes.documents.document_organization import (\n    router as document_organization_router,\n)\nfrom app.api.routes.documents.document_sharing import router as document_sharing_router\nfrom app.api.routes.documents.notify import router as notify_router\n\nrouter = APIRouter()\n\nrouter.include_router(auth_router, prefix=\"/u\")\nrouter.include_router(documents_router, prefix=\"\")\nrouter.include_router(notify_router, prefix=\"/notifications\")\nrouter.include_router(documents_metadata_router, prefix=\"/metadata\")\nrouter.include_router(document_organization_router, prefix=\"/filter\")\nrouter.include_router(document_sharing_router)\n"}
{"type": "source_file", "path": "app/db/repositories/documents/document_sharing.py", "content": "import hashlib\nimport os\nimport tempfile\nfrom datetime import datetime, timedelta, timezone\nfrom random import randint\nfrom typing import Dict, Any, Union, List\n\nimport boto3\nfrom botocore.exceptions import NoCredentialsError\nfrom sqlalchemy import select, update, delete\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api.dependencies.mail_service import mail_service\nfrom app.api.dependencies.repositories import get_key\nfrom app.core.config import settings\nfrom app.core.exceptions import http_404, http_500\nfrom app.db.tables.auth.auth import User\nfrom app.db.tables.documents.document_sharing import DocumentSharing\nfrom app.db.repositories.auth.auth import AuthRepository\nfrom app.db.repositories.documents.notify import NotifyRepo\nfrom app.schemas.auth.bands import TokenData\nfrom app.schemas.documents.document_sharing import SharingRequest\n\n\nclass DocumentSharingRepository:\n    \"\"\"\n    Repository for managing document sharing.\n    \"\"\"\n\n    def __init__(self, session: AsyncSession) -> None:\n        self.client = boto3.client(\"s3\")\n\n        self.session = session\n\n    async def get_user_mail(self, user: TokenData):\n\n        stmt = select(User).where(User.id == user.id)\n\n        execute = await self.session.execute(stmt)\n\n        return execute.scalar_one_or_none().__dict__[\"email\"]\n\n    @staticmethod\n    async def _generate_id(url: str) -> str:\n        hash_object = hashlib.md5()\n        hash_object.update(url.encode(\"utf-8\"))\n\n        n = randint(0, 25)\n\n        return hash_object.hexdigest()[n : n + 6]\n\n    async def _get_saved_links(self, filename: str) -> Dict[str, Any]:\n\n        stmt = select(DocumentSharing).where(DocumentSharing.filename == filename)\n\n        result = await self.session.execute(stmt)\n        return result.scalar_one_or_none()\n\n    async def update_visits(self, filename: str, visits_left: int):\n        if visits_left > 1:\n            await self.session.execute(\n                update(DocumentSharing)\n                .where(DocumentSharing.filename == filename)\n                .values(visits=visits_left - 1)\n            )\n        elif visits_left == 1:\n            await self.session.execute(\n                delete(DocumentSharing).where(DocumentSharing.filename == filename)\n            )\n\n    async def cleanup_expired_links(self):\n\n        now = datetime.now(timezone.utc)\n\n        stmt = delete(DocumentSharing).where(DocumentSharing.expires_at <= now)\n        try:\n            await self.session.execute(stmt)\n        except Exception as e:\n            raise http_500() from e\n\n    async def get_presigned_url(\n        self, doc: Dict[str, Any]\n    ) -> Union[str, Dict[str, str]]:\n        try:\n            params = {\n                \"Bucket\": settings.s3_bucket,\n                \"Key\": await get_key(s3_url=doc[\"s3_url\"]),\n            }\n            response = self.client.generate_presigned_url(\n                \"get_object\", Params=params, ExpiresIn=3600\n            )\n        except NoCredentialsError as e:\n            return {\"error\": f\"Invalid AWS Credentials: {e}\"}\n\n        return response\n\n    async def get_shareable_link(\n        self, owner_id: str, url: str, visits: int, filename: str, share_to: List[str]\n    ):\n\n        # task to clean uo the database for expired links\n        await self.cleanup_expired_links()\n\n        if ans := await self._get_saved_links(filename=filename):\n            ans = ans.__dict__\n            return {\n                \"note\": f\"Links already shared... valid Till {ans['expires_at']}\",\n                \"response\": {\n                    \"shareable_link\": f\"{settings.host_url}{settings.api_prefix}/doc/{ans['url_id']}\",\n                    \"visits_left\": ans[\"visits\"],\n                },\n            }\n\n        url_id = await self._generate_id(url=url)\n        share_entry = DocumentSharing(\n            url_id=url_id,\n            owner_id=owner_id,\n            filename=filename,\n            url=url,\n            expires_at=datetime.now(timezone.utc) + timedelta(seconds=3599),\n            visits=visits,\n            share_to=share_to,\n        )\n        try:\n            self.session.add(share_entry)\n            await self.session.commit()\n            await self.session.refresh(share_entry)\n\n            response = share_entry.__dict__\n            return {\n                \"shareable_link\": f\"{settings.host_url}{settings.api_prefix}/doc/{response['url_id']}\",\n                \"visits\": response[\"visits\"],\n            }\n        except Exception as e:\n            raise http_500() from e\n\n    async def get_redirect_url(self, url_id: str):\n\n        stmt = select(DocumentSharing).where(DocumentSharing.url_id == url_id)\n\n        result = await self.session.execute(stmt)\n        try:\n            result = result.scalar_one_or_none().__dict__\n\n            await self.update_visits(\n                filename=result[\"filename\"], visits_left=result[\"visits\"]\n            )\n\n            return result[\"url\"]\n        except AttributeError as e:\n            raise http_404(\n                msg=\"Shared URL link either expired or reached the limit of visits...\"\n            ) from e\n\n    async def send_mail(\n        self, user: TokenData, mail_to: Union[List[str], None], link: str\n    ) -> None:\n\n        if mail_to:\n\n            user_mail = await self.get_user_mail(user)\n            subj = f\"DocFlow: {user.username} share a document\"\n            content = f\"\"\"\n                    Visit the link: {link}, to access the document\n                    shared by {user.username} | {user_mail}.\n                    \"\"\"\n\n            for mails in mail_to:\n                mail_service(\n                    mail_to=mails, subject=subj, content=content, file_path=None\n                )\n\n    async def confirm_access(self, user: TokenData, url_id: str | None) -> bool:\n        # check if login user is owner or to whom it is shared\n        stmt = select(DocumentSharing).where(DocumentSharing.url_id == url_id)\n\n        result = await self.session.execute(stmt)\n        try:\n            result = result.scalar_one_or_none().__dict__\n            user_mail = await self.get_user_mail(user)\n\n            return (\n                result.get(\"owner_id\") == user.id\n                or user_mail in result.get(\"share_to\")\n                or user.username in result.get(\"share_to\")\n            )\n        except Exception as e:\n            raise http_404(msg=\"The link has expired...\") from e\n\n    async def share_document(\n        self,\n        filename: str,\n        document_key: str,\n        file: Any,\n        share_request: SharingRequest,\n        notify: bool,\n        owner: TokenData,\n        notify_repo: NotifyRepo,\n        auth_repo: AuthRepository,\n    ) -> None:\n\n        user_mail = await self.get_user_mail(owner)\n        share_to = share_request.share_to\n\n        # Determining extension\n        _, extension = os.path.splitext(document_key)\n\n        # Creating temp file to share\n        with tempfile.NamedTemporaryFile(delete=True, suffix=extension) as temp:\n            temp.write(file)\n            temp_path = temp.name\n\n            subject = f\"{owner.username} shared a file with you using DocFlow\"\n            for mails in share_to:\n                content = f\"\"\"\n                Hello {mails}!\n                \n                Hope you are well? {owner.username} | {user_mail} shared a file\n                with you as an attachment.\n\n                Regards,\n                DocFlow\n                \"\"\"\n                mail_service(\n                    mail_to=mails, subject=subject, content=content, file_path=temp_path\n                )\n\n        if notify:\n            return await notify_repo.notify(\n                user=owner, receivers=share_to, filename=filename, auth_repo=auth_repo\n            )\n"}
{"type": "source_file", "path": "app/api/routes/documents/document.py", "content": "from typing import Dict, List, Optional, Union\nfrom uuid import UUID\n\nfrom fastapi import APIRouter, status, File, UploadFile, Depends\nfrom fastapi.responses import FileResponse\nfrom sqlalchemy.engine import Row\n\nfrom app.api.dependencies.auth_utils import get_current_user\nfrom app.api.dependencies.repositories import get_repository\nfrom app.core.exceptions import http_400, http_404\nfrom app.db.repositories.auth.auth import AuthRepository\nfrom app.db.repositories.documents.documents import (\n    DocumentRepository,\n    perm_delete as perm_delete_file,\n)\nfrom app.db.repositories.documents.documents_metadata import DocumentMetadataRepository\nfrom app.schemas.auth.bands import TokenData\nfrom app.schemas.documents.documents_metadata import DocumentMetadataRead\n\n\nrouter = APIRouter(tags=[\"Document\"])\n\n\n@router.post(\n    \"/upload\",\n    response_model=None,\n    status_code=status.HTTP_201_CREATED,\n    name=\"upload_document\",\n)\nasync def upload(\n    files: List[UploadFile] = File(...),\n    folder: Optional[str] = None,\n    repository: DocumentRepository = Depends(DocumentRepository),\n    metadata_repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user_repository: AuthRepository = Depends(get_repository(AuthRepository)),\n    user: TokenData = Depends(get_current_user),\n) -> Union[List[DocumentMetadataRead], List[Dict[str, str]]]:\n    \"\"\"\n    Uploads a document to the specified folder.\n\n    Args:\n        files (List[UploadFile]): The files to be uploaded.\n        folder (Optional[str]): The folder where the document will be stored. Defaults to None.\n        repository (DocumentRepository): The repository for managing documents.\n        metadata_repository (DocumentMetadataRepository): The repository for managing document\n            metadata.\n        user_repository (AuthRepository): The repository for managing user authentication.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        Union[DocumentMetadataRead, Dict[str, str]]: If the file is added, returns the\n            uploaded document metadata.\n            If the file is updated, returns the patched document metadata.\n            Otherwise, returns a response dictionary.\n\n    Raises:\n        HTTP_400: If no input file is provided.\n    \"\"\"\n\n    if not files:\n        raise http_400(msg=\"No input files provided...\")\n\n    responses = []\n    for file in files:\n        response = await repository.upload(\n            metadata_repo=metadata_repository,\n            user_repo=user_repository,\n            file=file,\n            folder=folder,\n            user=user,\n        )\n        if response[\"response\"] == \"file_added\":\n            responses.append(\n                await metadata_repository.upload(document_upload=response[\"upload\"])\n            )\n        elif response[\"response\"] == \"file_updated\":\n            responses.append(\n                await metadata_repository.patch(\n                    document=response[\"upload\"][\"name\"],\n                    document_patch=response[\"upload\"],\n                    owner=user,\n                    user_repo=user_repository,\n                    is_owner=response[\"is_owner\"],\n                )\n            )\n    return responses\n\n\n@router.get(\n    \"/file/{file_name}/download\",\n    status_code=status.HTTP_200_OK,\n    name=\"download_document\",\n)\nasync def download(\n    file_name: str,\n    repository: DocumentRepository = Depends(DocumentRepository),\n    metadata_repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> object:\n    \"\"\"\n    Downloads a document with the specified file name.\n\n    Args:\n        file_name (str): The name of the file to be downloaded.\n        repository (DocumentRepository): The repository for managing documents.\n        metadata_repository (DocumentMetadataRepository): The repository for managing document metadata.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        object: The downloaded document.\n\n    Raises:\n        HTTP_400: If no file name is provided.\n        HTTP_404: If no file with the specified name is found.\n    \"\"\"\n\n    if not file_name:\n        raise http_400(msg=\"No file name...\")\n    try:\n        get_document_metadata = dict(\n            await metadata_repository.get(document=file_name, owner=user)\n        )\n\n        return await repository.download(\n            s3_url=get_document_metadata[\"s3_url\"], name=get_document_metadata[\"name\"]\n        )\n    except Exception as e:\n        raise http_404(msg=f\"No file with {file_name}\") from e\n\n\n@router.delete(\n    \"/{file_name}\", status_code=status.HTTP_204_NO_CONTENT, name=\"add_to_bin\"\n)\nasync def add_to_bin(\n    file_name: str,\n    metadata_repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> None:\n    \"\"\"\n    Adds a document to the bin for deletion.\n\n    Args:\n        file_name (str): The name of the file to be added to the bin.\n        metadata_repository (DocumentMetadataRepository): The repository for managing document metadata.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        None: If the file is added to the bin.\n    \"\"\"\n\n    return await metadata_repository.delete(document=file_name, owner=user)\n\n\n@router.get(\n    \"/trash\",\n    status_code=status.HTTP_200_OK,\n    response_model=None,\n    name=\"list_of_bin\",\n)\nasync def list_bin(\n    metadata_repo: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    owner: TokenData = Depends(get_current_user),\n) -> Dict[str, List[Row | Row] | int]:\n    \"\"\"\n    List bin.\n\n    Args:\n        metadata_repo: The document metadata repository.\n        owner: The token data of the owner.\n\n    Returns:\n        Dict[str, List[Row | Row] | int]: The list of bin.\n\n    \"\"\"\n\n    return await metadata_repo.bin_list(owner=owner)\n\n\n@router.delete(\n    \"/trash/{file_name}\",\n    status_code=status.HTTP_204_NO_CONTENT,\n    name=\"permanently_delete_doc\",\n)\nasync def perm_delete(\n    file_name: str = None,\n    delete_all: bool = False,\n    metadata_repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> None:\n    \"\"\"\n    Permanently deletes a document.\n\n    Args:\n        file_name (str, optional): The name of the file to be permanently deleted. Defaults to None.\n        delete_all (bool): Flag indicating whether to delete all documents in the bin. Defaults to False.\n        metadata_repository (DocumentMetadataRepository): The repository for managing document metadata.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        None: If the file is permanently deleted.\n\n    Raises:\n        HTTP_404: If no file with the specified name is found.\n    \"\"\"\n\n    try:\n        get_documents_metadata = dict(await metadata_repository.bin_list(owner=user))\n        if len(get_documents_metadata[\"response\"]) > 0:\n            return await perm_delete_file(\n                file=file_name,\n                delete_all=delete_all,\n                meta_repo=metadata_repository,\n                user=user,\n            )\n\n    except Exception as e:\n        raise http_404(msg=f\"No file with {file_name}\") from e\n\n\n@router.post(\n    \"/restore/{file}\",\n    status_code=status.HTTP_200_OK,\n    response_model=DocumentMetadataRead,\n    name=\"restore_from_bin\",\n)\nasync def restore_bin(\n    file: str,\n    metadata_repo: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> DocumentMetadataRead:\n    \"\"\"\n    Restore bin.\n\n    Args:\n        file: The file to restore.\n        metadata_repo: The document metadata repository.\n        user: The token data of the user.\n\n    Returns:\n        DocumentMetadataRead: The restored document metadata.\n\n    \"\"\"\n\n    return await metadata_repo.restore(file=file, owner=user)\n\n\n@router.delete(\n    \"/trash\",\n    status_code=status.HTTP_204_NO_CONTENT,\n    name=\"empty_trash\",\n)\nasync def empty_trash(\n    metadata_repo: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> None:\n    \"\"\"\n    Deletes all documents in the trash bin for the authenticated user.\n\n    Args:\n        metadata_repo (DocumentMetadataRepository): The repository for accessing document metadata.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        None\n    \"\"\"\n\n    return await metadata_repo.empty_bin(owner=user)\n\n\n@router.get(\n    \"/preview/{document}\",\n    status_code=status.HTTP_204_NO_CONTENT,\n    name=\"preview_document\",\n)\nasync def get_document_preview(\n    document: Union[str, UUID],\n    repository: DocumentRepository = Depends(DocumentRepository),\n    metadata_repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> FileResponse:\n    \"\"\"\n    Get the preview of a document.\n\n    Args:\n        document (Union[str, UUID]): The ID or name of the document.\n        repository (DocumentRepository): The repository for accessing document data.\n        metadata_repository (DocumentMetadataRepository): The repository for accessing document metadata.\n        user (TokenData): The user token data.\n\n    Returns:\n        FileResponse: The file response containing the document preview.\n\n    Raises:\n        HTTP_404: If the document ID or name is not provided or if the document does not exist.\n        HTTP_400: If the file type is not supported for preview.\n    \"\"\"\n\n    if not document:\n        raise http_404(msg=\"Enter document id or name.\")\n    try:\n        get_document_metadata = dict(\n            await metadata_repository.get(document=document, owner=user)\n        )\n        return await repository.preview(document=get_document_metadata)\n    except TypeError as e:\n        raise http_404(msg=\"Document does not exists.\") from e\n    except ValueError as e:\n        raise http_400(msg=\"File type is not supported for preview\") from e\n"}
{"type": "source_file", "path": "app/__init__.py", "content": ""}
{"type": "source_file", "path": "app/db/repositories/__init__.py", "content": ""}
{"type": "source_file", "path": "app/db/repositories/auth/auth.py", "content": "from typing import Any, Coroutine\n\nfrom sqlalchemy import select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api.dependencies.auth_utils import (\n    get_hashed_password,\n    verify_password,\n    create_access_token,\n    create_refresh_token,\n)\nfrom app.core.exceptions import http_400, http_403\nfrom app.db.tables.auth.auth import User\nfrom app.schemas.auth.bands import UserOut, UserAuth\n\n\nclass AuthRepository:\n    def __init__(self, session: AsyncSession) -> None:\n        self.session = session\n\n    async def _check_user_or_none(\n        self, userdata: UserAuth\n    ) -> Coroutine[Any, Any, Any | None]:\n        stmt = select(User).where(\n            User.username == userdata.username or User.email == userdata.email\n        )\n        result = await self.session.execute(stmt)\n        return result.scalar_one_or_none()\n\n    async def get_user(self, field: str, detail: str):\n        stmt = \"\"\n        if field == \"username\":\n            stmt = select(User).where(User.username == detail)\n        elif field == \"email\":\n            stmt = select(User).where(User.email == detail)\n        result = await self.session.execute(stmt)\n        return result.scalar_one_or_none()\n\n    async def signup(self, userdata: UserAuth) -> UserOut:\n        # Checking if the user already exists\n        if await self._check_user_or_none(userdata) is not None:\n            raise http_400(msg=\"User with details already exists\")\n\n        # hashing the password\n        hashed_password = get_hashed_password(password=userdata.password)\n        userdata.password = hashed_password\n\n        new_user = User(**userdata.model_dump())\n\n        self.session.add(new_user)\n        await self.session.commit()\n        await self.session.refresh(new_user)\n\n        return new_user\n\n    async def login(self, ipdata):\n        user = await self.get_user(field=\"username\", detail=ipdata.username)\n        if user is None:\n            raise http_403(msg=\"Recheck the credentials\")\n        user = user.__dict__\n        hashed_password = user.get(\"password\")\n        if not verify_password(\n            password=ipdata.password, hashed_password=hashed_password\n        ):\n            raise http_403(\"Incorrect Password\")\n\n        return {\n            \"token_type\": \"bearer\",\n            \"access_token\": create_access_token(\n                subject={\"id\": user.get(\"id\"), \"username\": user.get(\"username\")}\n            ),\n            \"refresh_token\": create_refresh_token(\n                subject={\"id\": user.get(\"id\"), \"username\": user.get(\"username\")}\n            ),\n        }\n"}
{"type": "source_file", "path": "app/core/config.py", "content": "import os\n\nfrom dotenv import load_dotenv\nfrom pydantic_settings import BaseSettings\n\nload_dotenv()\n\n\nclass GlobalConfig(BaseSettings):\n    \"\"\"\n    Global Configuration for the FastAPI application.\n    \"\"\"\n\n    title: str = os.environ.get(\"TITLE\")\n    version: str = \"1.0.0\"\n    description: str = os.environ.get(\"DESCRIPTION\")\n    host_url: str = \"http://localhost:8000\"\n    docs_url: str = \"/docs\"\n    redoc_url: str = \"/redoc\"\n    openapi_url: str = \"/openapi.json\"\n    api_prefix: str = \"/v2\"\n    debug: bool = str(os.environ.get(\"DEBUG\", \"False\")).lower() == \"true\"\n    postgres_user: str = os.environ.get(\"POSTGRES_USER\")\n    postgres_password: str = os.environ.get(\"POSTGRES_PASSWORD\")\n    postgres_hostname: str = os.environ.get(\"DATABASE_HOSTNAME\")\n    postgres_port: int = int(os.environ.get(\"POSTGRES_PORT\"))\n    postgres_db: str = os.environ.get(\"POSTGRES_DB\")\n    db_echo_log: bool = str(os.environ.get(\"DEBUG\", \"False\")).lower() == \"true\"\n    aws_access_key_id: str = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n    aws_secret_key: str = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n    aws_region: str = os.environ.get(\"AWS_REGION\")\n    s3_bucket: str = os.environ.get(\"S3_BUCKET\")\n    s3_test_bucket: str = os.environ.get(\"S3_TEST_BUCKET\")\n    # user config\n    access_token_expire_min: int = os.environ.get(\"ACCESS_TOKEN_EXPIRE_MIN\")\n    refresh_token_expire_min: int = os.environ.get(\"REFRESH_TOKEN_EXPIRE_MIN\")\n    algorithm: str = os.environ.get(\"ALGORITHM\")\n    jwt_secret_key: str = os.environ.get(\"JWT_SECRET_KEY\")\n    jwt_refresh_secret_key: str = os.environ.get(\"JWT_REFRESH_SECRET_KEY\")\n    # Email Service\n    smtp_server: str = os.environ.get(\"SMTP_SERVER\")\n    smtp_port: int = os.environ.get(\"SMTP_PORT\")\n    email: str = os.environ.get(\"EMAIL\")\n    app_pw: str = os.environ.get(\"APP_PASSWORD\")\n\n    @property\n    def sync_database_url(self) -> str:\n        return (\n            f\"postgresql://{self.postgres_user}:{self.postgres_password}@\"\n            f\"{self.postgres_hostname}:{self.postgres_port}/{self.postgres_db}\"\n        )\n\n    @property\n    def async_database_url(self) -> str:\n        return (\n            f\"postgresql+asyncpg://{self.postgres_user}:{self.postgres_password}@\"\n            f\"{self.postgres_hostname}:{self.postgres_port}/{self.postgres_db}\"\n        )\n\n\nsettings = GlobalConfig()\n"}
{"type": "source_file", "path": "app/api/routes/documents/notify.py", "content": "from typing import List, Union\nfrom uuid import UUID\n\nfrom fastapi import APIRouter, status, Depends\n\nfrom app.api.dependencies.auth_utils import get_current_user\nfrom app.api.dependencies.repositories import get_repository\nfrom app.core.exceptions import http_404\nfrom app.db.repositories.documents.notify import NotifyRepo\nfrom app.schemas.auth.bands import TokenData\nfrom app.schemas.documents.bands import Notification, NotifyPatchStatus\n\nrouter = APIRouter(tags=[\"Notification\"])\n\n\n@router.get(\"\", status_code=status.HTTP_200_OK, name=\"get_notifications\")\nasync def get_notifications(\n    repository: NotifyRepo = Depends(get_repository(NotifyRepo)),\n    user: TokenData = Depends(get_current_user),\n) -> List[Notification]:\n    \"\"\"\n    Get notifications for a user.\n\n    Args:\n        repository (NotifyRepo): The repository for accessing notification data.\n        user (TokenData): The authenticated user.\n\n    Returns:\n        List[Notification]: A list of notifications for the user.\n    \"\"\"\n\n    return await repository.get_notifications(user=user)\n\n\n@router.put(\n    path=\"/{notification_id}\",\n    status_code=status.HTTP_200_OK,\n    name=\"patch_status\",\n)\nasync def patch_status(\n    updated_status: NotifyPatchStatus = None,\n    notification_id: UUID = None,\n    repository: NotifyRepo = Depends(get_repository(NotifyRepo)),\n    user: TokenData = Depends(get_current_user),\n) -> Union[List[Notification], Notification]:\n    \"\"\"\n    Patch the status of a notification or mark all notifications as read.\n\n    Args:\n        updated_status (NotifyPatchStatus, optional): The updated status for the notification. Defaults to None.\n        notification_id (UUID, optional): The ID of the notification to update. Defaults to None.\n        repository (NotifyRepo): The repository for accessing notification data.\n        user (TokenData): The authenticated user.\n\n    Returns:\n        Union[List[Notification], Notification]: If `mark_as_all_read` is True, returns a list of all notifications\n            marked as read. If `notification_id` is provided, returns the updated notification.\n            Otherwise, raises an HTTP_404 exception.\n\n    Raises:\n        HTTP_404: If 'notification_id' is not provided and update_status.mark_all is set to False.\n    \"\"\"\n\n    if updated_status.mark_all:\n        return await repository.mark_all_read(user=user)\n    if notification_id:\n        return await repository.update_status(\n            n_id=notification_id, updated_status=updated_status, user=user\n        )\n    raise http_404(\n        msg=\"Bad Request: Make sure to either flag mark_all \"\n        \"or enter notification_id along with correct status as payload.\"\n    )\n\n\n@router.delete(\n    path=\"\",\n    status_code=status.HTTP_204_NO_CONTENT,\n    name=\"clear_all_notifications\",\n)\nasync def clear_all_notifications(\n    repository: NotifyRepo = Depends(get_repository(NotifyRepo)),\n    user: TokenData = Depends(get_current_user),\n) -> None:\n    \"\"\"\n    Clear all notifications for a user.\n\n    Args:\n        repository (NotifyRepo): The repository for accessing notification data.\n        user (TokenData): The authenticated user.\n\n    Returns:\n        None\n    \"\"\"\n\n    return await repository.clear_notification(user=user)\n"}
{"type": "source_file", "path": "app/db/repositories/documents/__init__.py", "content": ""}
{"type": "source_file", "path": "app/db/repositories/auth/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/routes/documents/documents_metadata.py", "content": "from typing import Any, Dict, List, Union\nfrom uuid import UUID\n\nfrom fastapi import APIRouter, status, Body, Depends, Query, HTTPException\n\nfrom app.api.dependencies.repositories import get_repository\nfrom app.api.dependencies.auth_utils import get_current_user\nfrom app.core.exceptions import http_404\nfrom app.db.repositories.auth.auth import AuthRepository\nfrom app.db.repositories.documents.documents_metadata import DocumentMetadataRepository\nfrom app.schemas.auth.bands import TokenData\nfrom app.schemas.documents.bands import DocumentMetadataPatch\nfrom app.schemas.documents.documents_metadata import (\n    DocumentMetadataCreate,\n    DocumentMetadataRead,\n)\n\n\nrouter = APIRouter(tags=[\"Document MetaData\"])\n\n\n@router.post(\n    \"/upload\",\n    response_model=DocumentMetadataRead,\n    status_code=status.HTTP_201_CREATED,\n    name=\"upload_documents_metadata\",\n)\nasync def upload_document_metadata(\n    document_upload: DocumentMetadataCreate = Body(...),\n    repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> DocumentMetadataRead:\n    \"\"\"\n    Uploads document metadata.\n\n    Args:\n        document_upload (DocumentMetadataCreate): The document metadata to be uploaded.\n        repository (DocumentMetadataRepository): The repository for managing document metadata.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        DocumentMetadataRead: The uploaded document metadata.\n    \"\"\"\n\n    document_upload.owner_id = user.id\n    return await repository.upload(document_upload=document_upload)\n\n\n@router.get(\n    \"\",\n    response_model=Dict[str, Union[List[DocumentMetadataRead], Any]],\n    status_code=status.HTTP_200_OK,\n    name=\"get_documents_metadata\",\n)\nasync def get_documents_metadata(\n    limit: int = Query(default=10, lt=100),\n    offset: int = Query(default=0),\n    repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> Dict[str, Union[List[DocumentMetadataRead], Any]]:\n    \"\"\"\n    Retrieves a list of document metadata.\n\n    Args:\n        limit (int): The maximum number of documents to retrieve. Defaults to 10.\n        offset (int): The number of documents to skip. Defaults to 0.\n        repository (DocumentMetadataRepository): The repository for managing document metadata.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        Dict[str, Union[List[DocumentMetadataRead], Any]]: A dictionary containing the list of document metadata.\n    \"\"\"\n\n    return await repository.doc_list(limit=limit, offset=offset, owner=user)\n\n\n@router.get(\n    \"/{document}/detail\",\n    response_model=None,\n    status_code=status.HTTP_200_OK,\n    name=\"get_document-metadata\",\n)\nasync def get_document_metadata(\n    document: Union[str, UUID],\n    repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> Union[DocumentMetadataRead, HTTPException]:\n    \"\"\"\n    Retrieves the metadata of a specific document.\n\n    Args:\n        document (Union[str, UUID]): The ID or name of the document.\n        repository (DocumentMetadataRepository): The repository for managing document metadata.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        Union[DocumentMetadataRead, HTTPException]: The document metadata if found, otherwise an HTTPException.\n    \"\"\"\n\n    return await repository.get(document=document, owner=user)\n\n\n@router.put(\n    \"/{document}\",\n    response_model=None,\n    status_code=status.HTTP_200_OK,\n    name=\"update_doc_metadata_details\",\n)\nasync def update_doc_metadata_details(\n    document: Union[str, UUID],\n    document_patch: DocumentMetadataPatch = Body(...),\n    repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user_repository: AuthRepository = Depends(get_repository(AuthRepository)),\n    user: TokenData = Depends(get_current_user),\n) -> Union[DocumentMetadataRead, HTTPException]:\n    \"\"\"\n    Updates the details of a document's metadata.\n\n    Args:\n        document (Union[str, UUID]): The ID or name of the document.\n        document_patch (DocumentMetadataPatch): The document metadata patch containing the updated details.\n        repository (DocumentMetadataRepository): The repository for managing document metadata.\n        user_repository (AuthRepository): The repository for managing user authentication.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        Union[DocumentMetadataRead, HTTPException]: The updated document metadata if successful,\n        otherwise an HTTPException.\n\n    Raises:\n        HTTP_404: If no document with the specified ID or name is found.\n    \"\"\"\n\n    try:\n        await repository.get(document=document, owner=user)\n    except Exception as e:\n        raise http_404(msg=f\"No Document with: {document}\") from e\n\n    return await repository.patch(\n        document=document,\n        document_patch=document_patch,\n        owner=user,\n        user_repo=user_repository,\n        is_owner=True,\n    )\n\n\n@router.delete(\n    \"/{document}\",\n    status_code=status.HTTP_204_NO_CONTENT,\n    name=\"delete_document_metadata\",\n)\nasync def delete_document_metadata(\n    document: Union[str, UUID],\n    repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> None:\n    \"\"\"\n    Deletes the metadata of a document and moves it to the bin.\n\n    Args:\n        document (Union[str, UUID]): The identifier of the document to delete.\n        repository (DocumentMetadataRepository): The repository for accessing document metadata.\n            Defaults to the result of the `get_repository` function with `DocumentMetadataRepository` as the argument.\n        user (TokenData): The token data of the current user. Defaults to the result of the `get_current_user` function.\n\n    Returns:\n        None (204_NO_CONTENT)\n\n    Raises:\n        HTTP_404: If no document with the specified identifier is found.\n    \"\"\"\n\n    try:\n        await repository.get(document=document, owner=user)\n    except Exception as e:\n        raise http_404(msg=f\"No document with the detail: {document}.\") from e\n\n    return await repository.delete(document=document, owner=user)\n\n\n# Archiving\n\n\n@router.post(\n    \"/archive/{file_name)\",\n    response_model=DocumentMetadataRead,\n    status_code=status.HTTP_200_OK,\n    name=\"archive_a_document\",\n)\nasync def archive(\n    file_name: str,\n    repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> DocumentMetadataRead:\n    \"\"\"\n    Archive a document.\n\n    Args:\n        file_name (str): The name of the file to be archived.\n        repository (DocumentMetadataRepository): The repository for document metadata.\n        user (TokenData): The user token data.\n\n    Returns:\n        DocumentMetadataRead: The archived document metadata.\n\n    \"\"\"\n\n    return await repository.archive(file=file_name, user=user)\n\n\n@router.get(\n    \"/archive/list\",\n    response_model=None,\n    status_code=status.HTTP_200_OK,\n    name=\"archived_doc_list\",\n)\nasync def archive_list(\n    repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> Dict[str, List[str] | int]:\n    \"\"\"\n    Get the list of archived documents.\n\n    Args:\n        repository (DocumentMetadataRepository): The repository for document metadata.\n        user (TokenData): The user token data.\n\n    Returns:\n        Dict[str, List[str] | int]: A dictionary containing the list of archived documents.\n\n    \"\"\"\n\n    return await repository.archive_list(user=user)\n\n\n@router.post(\n    \"/un-archive/{file}\",\n    response_model=DocumentMetadataRead,\n    status_code=status.HTTP_200_OK,\n    name=\"remove_doc_from_archive\",\n)\nasync def un_archive(\n    file: str,\n    repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n) -> DocumentMetadataRead:\n    \"\"\"\n    Un-archive a document.\n\n    Args:\n        file (str): The name of the file to be un-archived.\n        repository (DocumentMetadataRepository): The repository for document metadata.\n        user (TokenData): The user token data.\n\n    Returns:\n        DocumentMetadataRead: The un-archived document metadata.\n\n    \"\"\"\n\n    return await repository.un_archive(file=file, user=user)\n"}
{"type": "source_file", "path": "app/api/routes/documents/document_sharing.py", "content": "from typing import Union\nfrom uuid import UUID\n\nfrom fastapi import APIRouter, Depends, status\nfrom fastapi.responses import RedirectResponse\n\nfrom app.api.dependencies.auth_utils import get_current_user\nfrom app.api.dependencies.repositories import get_repository, get_key\nfrom app.core.exceptions import http_404\nfrom app.db.repositories.auth.auth import AuthRepository\nfrom app.db.repositories.documents.documents import DocumentRepository\nfrom app.db.repositories.documents.documents_metadata import DocumentMetadataRepository\nfrom app.db.repositories.documents.document_sharing import DocumentSharingRepository\nfrom app.db.repositories.documents.notify import NotifyRepo\nfrom app.schemas.auth.bands import TokenData\nfrom app.schemas.documents.document_sharing import SharingRequest\n\n\nrouter = APIRouter(tags=[\"Document Sharing\"])\n\n\n@router.post(\n    \"/share-link/{document}\", status_code=status.HTTP_200_OK, name=\"share_document_link\"\n)\nasync def share_link_document(\n    document: Union[str, UUID],\n    share_request: SharingRequest,\n    repository: DocumentSharingRepository = Depends(\n        get_repository(DocumentSharingRepository)\n    ),\n    auth_repository: AuthRepository = Depends(get_repository(AuthRepository)),\n    metadata_repository: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    notify_repository: NotifyRepo = Depends(get_repository(NotifyRepo)),\n    user: TokenData = Depends(get_current_user),\n):\n    \"\"\"\n    Shares a document link with another user, sends mail and notifies the receiver.\n\n    Args:\n        document (Union[str, UUID]): The ID or name of the document to be shared.\n        share_request (SharingRequest): The sharing request containing the\n                details of the sharing operation.\n        repository (DocumentSharingRepository): The repository for managing document sharing.\n        auth_repository (AuthRepository): The repository for managing User-related queries.\n        metadata_repository (DocumentMetadataRepository): The repository for managing\n            document metadata.\n        notify_repository (NotifyRepo): The repository for managing notification\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        Dict[str, str]: A dictionary containing the personal URL and shareable link.\n\n    Raises:\n        HTTP_404: If no document with the specified ID or name is found.\n    \"\"\"\n\n    try:\n        doc = await metadata_repository.get(document=document, owner=user)\n\n        visits = share_request.visits\n        share_to = share_request.share_to\n        pre_signed_url = await repository.get_presigned_url(doc=doc.__dict__)\n        shareable_link = await repository.get_shareable_link(\n            owner_id=user.id,\n            url=pre_signed_url,\n            visits=visits,\n            filename=doc.__dict__[\"name\"],\n            share_to=share_to,\n        )\n\n        if len(share_to) > 0:\n            # Send email to the receiver\n            await repository.send_mail(user=user, mail_to=share_to, link=shareable_link)\n\n            # send a notification to the receiver\n            await notify_repository.notify(\n                user=user,\n                receivers=share_to,\n                filename=doc.__dict__[\"name\"],\n                auth_repo=auth_repository,\n            )\n\n        return {\"personal_url\": pre_signed_url, \"share_this\": shareable_link}\n\n    except KeyError as e:\n        raise http_404(msg=f\"No doc: {document}\") from e\n\n\n@router.get(\"/doc/{url_id}\", tags=[\"Document Sharing\"])\nasync def redirect_to_share(\n    url_id: str,\n    repository: DocumentSharingRepository = Depends(\n        get_repository(DocumentSharingRepository)\n    ),\n    user: TokenData = Depends(get_current_user),\n):\n    \"\"\"\n    Redirects to a shared document URL.\n\n    Args:\n        url_id (str): The ID of the shared document URL.\n        repository (DocumentSharingRepository): The repository for managing document sharing.\n        user (TokenData): The token data of the authenticated user.\n\n    Returns:\n        RedirectResponse: A redirect response to the shared document URL.\n    \"\"\"\n\n    if await repository.confirm_access(user=user, url_id=url_id):\n        redirect_url = await repository.get_redirect_url(url_id=url_id)\n\n        return RedirectResponse(redirect_url)\n\n\n@router.post(\"/share/{document}\", status_code=status.HTTP_200_OK, name=\"share_document\")\nasync def share_document(\n    document: Union[str, UUID],\n    share_request: SharingRequest,\n    notify: bool = True,\n    repository: DocumentSharingRepository = Depends(\n        get_repository(DocumentSharingRepository)\n    ),\n    document_repo: DocumentRepository = Depends(DocumentRepository),\n    metadata_repo: DocumentMetadataRepository = Depends(\n        get_repository(DocumentMetadataRepository)\n    ),\n    notify_repo: NotifyRepo = Depends(get_repository(NotifyRepo)),\n    auth_repo: AuthRepository = Depends(get_repository(AuthRepository)),\n    user: TokenData = Depends(get_current_user),\n) -> None:\n    \"\"\"\n    Share a document with other users, and notifies if notify is set to True (default).\n\n    Args:\n    document (Union[str, UUID]): The ID or UUID of the document to be shared.\n    share_request (SharingRequest): The sharing request containing the recipients and permissions.\n    notify (bool, optional): Whether to send notifications to the recipients. Defaults to True.\n    repository (DocumentSharingRepository, optional): The repository for document sharing\n        operations.\n    document_repo (DocumentRepository, optional): The repository for document operations.\n    metadata_repo (DocumentMetadataRepository, optional): The repository for document metadata\n        operations.\n    notify_repo (NotifyRepo, optional): The repository for notification operations.\n    auth_repo (AuthRepository, optional): The repository for authentication operations.\n    user (TokenData, optional): The authenticated user.\n\n    Raises:\n        HTTP_404: If the document is not found.\n\n    Returns:\n        None\n    \"\"\"\n\n    if not document:\n        raise http_404(msg=\"Enter document id or UUID.\")\n    try:\n        get_document_metadata = dict(\n            await metadata_repo.get(document=document, owner=user)\n        )\n        key = await get_key(s3_url=get_document_metadata[\"s3_url\"])\n\n        file = await document_repo.get_s3_file_object_body(key=key)\n\n        return await repository.share_document(\n            filename=get_document_metadata[\"name\"],\n            document_key=key,\n            file=file,\n            share_request=share_request,\n            notify=notify,\n            owner=user,\n            notify_repo=notify_repo,\n            auth_repo=auth_repo,\n        )\n    except Exception as e:\n        raise http_404() from e\n"}
{"type": "source_file", "path": "app/api/dependencies/mail_service.py", "content": "import os.path\nimport smtplib\nimport ssl\n\nfrom email import encoders\nfrom email.mime.base import MIMEBase\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\nfrom app.core.config import settings\nfrom app.core.exceptions import http_500\n\n\ndef mail_service(\n    mail_to: str, subject: str, content: str, file_path: str = None\n) -> None:\n    port = settings.smtp_port  # For starttls\n    smtp_server = settings.smtp_server\n    sender_email = settings.email\n    receiver_email = mail_to\n    password = settings.app_pw\n\n    # Creating Multipart message and headers\n    message = MIMEMultipart()\n    message[\"Subject\"] = subject\n    message.attach(MIMEText(content, _subtype=\"plain\"))\n\n    # Open file in binary mode\n    if file_path is not None:\n        with open(file_path, \"rb\") as attachment:\n            # Below line adds file as application/octet_stream\n            part = MIMEBase(\"application\", \"octet_stream\")\n            part.set_payload(attachment.read())\n\n        # Encoding file in ASCII characters for sending emails\n        encoders.encode_base64(part)\n\n        # header as attachment\n        part.add_header(\n            \"Content-Disposition\",\n            f\"attachment; filename= {os.path.basename(file_path)}\",\n        )\n\n        message.attach(part)\n\n    try:\n        context = ssl.create_default_context()\n        with smtplib.SMTP(smtp_server, port) as server:\n            server.ehlo()\n            server.starttls(context=context)\n            server.ehlo()\n            server.login(sender_email, password)\n            server.sendmail(sender_email, receiver_email, message.as_string())\n    except Exception as e:\n        raise http_500(msg=\"There was some error sending email...\") from e\n"}
{"type": "source_file", "path": "app/db/__init__.py", "content": ""}
{"type": "source_file", "path": "app/db/repositories/documents/document_organization.py", "content": "from typing import Any, Dict, List, Union\n\nfrom app.api.dependencies.constants import SUPPORTED_FILE_TYPES\nfrom app.schemas.documents.documents_metadata import DocumentMetadataRead\n\n\nclass DocumentOrgRepository:\n    \"\"\"\n    Repository for managing document organization.\n    \"\"\"\n\n    def __init__(self): ...\n\n    @staticmethod\n    async def _search_tags(\n        docs: List[DocumentMetadataRead], tags: List[str]\n    ) -> List[Dict[str, str]]:\n\n        result = []\n        for doc in docs:\n            doc = doc.__dict__\n            result.extend(\n                doc\n                for tag in tags\n                if doc[\"tags\"] and \"\".join(tag.split()) in doc[\"tags\"]\n            )\n\n        return result or None\n\n    @staticmethod\n    async def _search_category(\n        docs: List[DocumentMetadataRead], categories: List[str]\n    ) -> List[Dict[str, str]]:\n\n        result = []\n        for doc in docs:\n            doc = doc.__dict__\n            result.extend(\n                doc\n                for category in categories\n                if doc[\"categories\"] and \"\".join(category.split()) in doc[\"categories\"]\n            )\n\n        return result or None\n\n    @staticmethod\n    async def _search_file_type(\n        docs: List[DocumentMetadataRead], file_types: List[str]\n    ) -> List[Dict[str, str]]:\n\n        result = []\n        for doc in docs:\n            doc = doc.__dict__\n            for ftype in file_types:\n                ftype = \"\".join(ftype.split())\n                result.extend(\n                    doc\n                    for key, val in SUPPORTED_FILE_TYPES.items()\n                    if val == ftype and key == doc[\"file_type\"]\n                )\n\n        return result or None\n\n    @staticmethod\n    async def _search_by_status(\n        docs: List[DocumentMetadataRead], status: List[str]\n    ) -> List[Dict[str, str]]:\n\n        result = []\n        for doc in docs:\n            doc = doc.__dict__\n            result.extend(\n                doc for stat in status if str(doc[\"status\"]) == f\"StatusEnum.{stat}\"\n            )\n\n        return result or None\n\n    async def search_doc(\n        self,\n        docs: List[DocumentMetadataRead],\n        tags: str,\n        categories: str,\n        file_types: str,\n        status: str,\n    ) -> Union[List[List[Dict[str, Any]]], None]:\n\n        results = []\n\n        if tags:\n            tags = tags.split(\",\")\n            results.append(await self._search_tags(docs=docs, tags=tags))\n\n        if categories:\n            categories = categories.split(\",\")\n            results.append(\n                await self._search_category(docs=docs, categories=categories)\n            )\n\n        if file_types:\n            file_type = file_types.split(\",\")\n            results.append(\n                await self._search_file_type(docs=docs, file_types=file_type)\n            )\n\n        if status:\n            _status = status.split(\",\")\n            results.append(await self._search_by_status(docs=docs, status=_status))\n\n        return results\n"}
{"type": "source_file", "path": "app/db/models.py", "content": "import logging\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.exc import OperationalError\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session\n\nfrom app.core.config import settings\nfrom app.core.exceptions import http_500\n\nlogger = logging.getLogger(\"sqlalchemy\")\n\nengine = create_engine(\n    url=settings.sync_database_url,\n    echo=settings.db_echo_log,\n)\n\nasync_engine = create_async_engine(\n    url=settings.async_database_url,\n    echo=settings.db_echo_log,\n    query_cache_size=0,\n)\n\nsession = sessionmaker(bind=engine, autocommit=False, autoflush=False)\n\nasync_session = sessionmaker(\n    bind=async_engine,\n    class_=AsyncSession,\n    autocommit=False,\n    autoflush=False,\n    expire_on_commit=False,\n)\n\nBase = declarative_base()\nmetadata = Base.metadata\n\n\nasync def check_tables():\n    try:\n        with Session(engine) as _session:\n            # Create tables\n            metadata.create_all(engine)\n            _session.commit()\n            logger.info(\"Tables created if they didn't already exist.\")\n    except OperationalError as e:\n        logger.error(\"Error Creating table: %s\", e)\n        raise http_500(msg=\"An error occurred while creating tables.\") from e\n"}
{"type": "source_file", "path": "app/db/repositories/documents/documents.py", "content": "import hashlib\nimport os\nimport tempfile\nfrom typing import Dict, Any\n\nimport boto3\nfrom botocore.exceptions import ClientError\nfrom fastapi import File\nfrom starlette.responses import FileResponse\nfrom ulid import ULID\n\nfrom app.api.dependencies.constants import SUPPORTED_FILE_TYPES\nfrom app.api.dependencies.repositories import TempFileResponse, get_key, get_s3_url\nfrom app.core.config import settings\nfrom app.core.exceptions import http_400, http_404\nfrom app.db.repositories.documents.documents_metadata import DocumentMetadataRepository\nfrom app.schemas.auth.bands import TokenData\n\n\nasync def perm_delete(\n    file: str, delete_all: bool, meta_repo: DocumentMetadataRepository, user: TokenData\n) -> None:\n\n    if delete_all:\n        await meta_repo.empty_bin(owner=user)\n    else:\n        doc = await meta_repo.bin_list(owner=user)\n        for docs in doc.get(\"response\"):\n            if docs.DocumentMetadata.name == file:\n                doc_id = docs.DocumentMetadata.id\n                await meta_repo.perm_delete_a_doc(document=doc_id, owner=user)\n\n\nclass DocumentRepository:\n\n    def __init__(self):\n        self.s3_client = boto3.resource(\"s3\")\n        self.client = boto3.client(\"s3\")\n        self.s3_bucket = self.s3_client.Bucket(settings.s3_bucket)\n        self.client.put_bucket_versioning(\n            Bucket=settings.s3_bucket, VersioningConfiguration={\"Status\": \"Enabled\"}\n        )\n\n    @staticmethod\n    async def _calculate_file_hash(file: File) -> str:\n\n        file.file.seek(0)\n        contents = file.file.read()\n        file.file.seek(0)\n\n        return hashlib.sha256(contents).hexdigest()\n\n    async def get_s3_file_object_body(self, key: str):\n        s3_object = self.client.get_object(Bucket=settings.s3_bucket, Key=key)\n        file = s3_object[\"Body\"].read()\n\n        return file\n\n    async def _delete_object(self, key: str) -> None:\n\n        try:\n            self.client.delete_object(Bucket=settings.s3_bucket, Key=key)\n        except Exception as e:\n            raise e\n\n    async def _upload_new_file(\n        self, file: File, folder: str, contents, file_type: str, user: TokenData\n    ) -> Dict[str, Any]:\n\n        if folder is None:\n            key = f\"{user.id}/{str(ULID())}.{SUPPORTED_FILE_TYPES[file_type]}\"\n        else:\n            key = f\"{user.id}/{folder}/{str(ULID())}.{SUPPORTED_FILE_TYPES[file_type]}\"\n\n        self.s3_bucket.put_object(Bucket=settings.s3_bucket, Key=key, Body=contents)\n\n        return {\n            \"response\": \"file_added\",\n            \"upload\": {\n                \"owner_id\": user.id,\n                \"name\": file.filename,\n                \"s3_url\": await get_s3_url(key=key),\n                \"size\": len(contents),\n                \"file_type\": file_type,\n                \"file_hash\": await self._calculate_file_hash(file=file),\n            },\n        }\n\n    async def _upload_new_version(\n        self,\n        doc: dict,\n        file: File,\n        contents,\n        file_type: str,\n        new_file_hash: str,\n        is_owner: bool,\n    ) -> Dict[str, Any]:\n\n        key = await get_key(s3_url=doc[\"s3_url\"])\n\n        self.s3_bucket.put_object(Bucket=settings.s3_bucket, Key=key, Body=contents)\n\n        return {\n            \"response\": \"file_updated\",\n            \"is_owner\": is_owner,\n            \"upload\": {\n                \"name\": file.filename,\n                \"s3_url\": await get_s3_url(key=key),\n                \"size\": len(contents),\n                \"file_type\": file_type,\n                \"file_hash\": new_file_hash,\n            },\n        }\n\n    async def upload(\n        self, metadata_repo, user_repo, file: File, folder: str, user: TokenData\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Uploads a file to the specified folder in the document repository.\n\n        Args:\n            metadata_repo: The repository for accessing metadata.\n            user_repo: The repository for accessing user information.\n            file: The file to be uploaded.\n            folder: The folder in which the file should be uploaded.\n            user: The token data of the user.\n\n        Returns:\n            @return: A dictionary containing the response and upload information.\n\n        Raises:\n            HTTP_400: If the file type is not supported.\n        \"\"\"\n\n        file_type = file.content_type\n        if file_type not in SUPPORTED_FILE_TYPES:\n            raise http_400(msg=f\"File type {file_type} not supported.\")\n\n        contents = await file.read()\n\n        doc = (await metadata_repo.get(document=file.filename, owner=user)).__dict__\n        # hash of the file uploaded to check if change in file\n        new_file_hash: str = await self._calculate_file_hash(file=file)\n        try:\n            if \"status_code\" in doc.keys():\n                # getting document irrespective of user\n                if get_doc := await metadata_repo.get_doc(filename=file.filename):\n                    get_doc = get_doc.__dict__\n                    # Check if logged-in user has update access\n                    logged_in_user = (\n                        await user_repo.get_user(field=\"username\", detail=user.username)\n                    ).__dict__\n                    if (get_doc[\"access_to\"] is not None) and logged_in_user[\n                        \"email\"\n                    ] in get_doc[\"access_to\"]:\n                        if get_doc[\"file_hash\"] != new_file_hash:\n                            # can upload a version to a file...\n                            print(\n                                f\"Have update access, to a file... owner: {get_doc['owner_id']}\"\n                            )\n                            return await self._upload_new_version(\n                                doc=get_doc,\n                                file=file,\n                                contents=contents,\n                                file_type=file_type,\n                                new_file_hash=await self._calculate_file_hash(\n                                    file=file\n                                ),\n                                is_owner=False,\n                            )\n                    else:\n                        return await self._upload_new_file(\n                            file=file,\n                            folder=folder,\n                            contents=contents,\n                            file_type=file_type,\n                            user=user,\n                        )\n                return await self._upload_new_file(\n                    file=file,\n                    folder=folder,\n                    contents=contents,\n                    file_type=file_type,\n                    user=user,\n                )\n\n            print(\n                f\"File {file.filename} already present, checking if there is an update...\"\n            )\n\n            if doc[\"file_hash\"] != new_file_hash:\n                print(\"File has been updated, uploading new version...\")\n                return await self._upload_new_version(\n                    doc=doc,\n                    file=file,\n                    contents=contents,\n                    file_type=file_type,\n                    new_file_hash=new_file_hash,\n                    is_owner=True,\n                )\n\n            return {\n                \"response\": \"File already present and no changes detected.\",\n                \"upload\": \"Noting to update...\",\n            }\n        except Exception as e:\n            raise http_404(msg=\"Error uploading the file...\") from e\n\n    async def download(self, s3_url: str, name: str) -> Dict[str, str]:\n\n        key = get_key(s3_url=s3_url)\n\n        try:\n            self.s3_client.meta.client.download_file(\n                Bucket=settings.s3_bucket,\n                Key=await key,\n                Filename=r\"/app/downloads/docflow_\" + f\"{name}\",\n            )\n        except ClientError as e:\n            raise http_404(msg=f\"File not found: {e}\") from e\n\n        return {\"message\": f\"successfully downloaded {name} in downloads folder.\"}\n\n    async def preview(self, document: Dict[str, Any]) -> FileResponse:\n\n        key = await get_key(s3_url=document[\"s3_url\"])\n\n        file = await self.get_s3_file_object_body(key)\n\n        # Determining the file extension from the key and media type for File Response\n        _, extension = os.path.splitext(key)\n        if extension.lower() in [\".jpg\", \".jpeg\", \".png\", \".gif\"]:\n            media_type = \"image/\" + extension.lower().lstrip(\".\")\n        elif extension.lower() == \".pdf\":\n            media_type = \"application/pdf\"\n        else:\n            raise ValueError(\"Unsupported file type.\")\n\n        # Creating a temp file\n        with tempfile.NamedTemporaryFile(delete=False, suffix=extension) as temp:\n            temp.write(file)\n            temp_path = temp.name\n\n        return TempFileResponse(temp_path, media_type=media_type)\n"}
{"type": "source_file", "path": "app/api/routes/auth/__init__.py", "content": ""}
{"type": "source_file", "path": "app/api/routes/auth/auth.py", "content": "from fastapi import APIRouter, status, Depends\nfrom fastapi.security import OAuth2PasswordRequestForm\n\nfrom app.api.dependencies.auth_utils import get_current_user\nfrom app.api.dependencies.repositories import get_repository\nfrom app.schemas.auth.bands import UserOut, UserAuth, TokenData\nfrom app.db.repositories.auth.auth import AuthRepository\n\nrouter = APIRouter(tags=[\"User Auth\"])\n\n\n@router.post(\n    \"/signup\",\n    response_model=UserOut,\n    status_code=status.HTTP_201_CREATED,\n    name=\"signup\",\n    summary=\"Create new user\",\n)\nasync def signup(\n    data: UserAuth, repository: AuthRepository = Depends(get_repository(AuthRepository))\n):\n\n    return await repository.signup(userdata=data)\n\n\n@router.post(\n    \"/login\",\n    status_code=status.HTTP_200_OK,\n    name=\"login\",\n    summary=\"Create access and refresh tokens for user\",\n)\nasync def login(\n    form_data: OAuth2PasswordRequestForm = Depends(),\n    repository: AuthRepository = Depends(get_repository(AuthRepository)),\n):\n\n    return await repository.login(ipdata=form_data)\n\n\n@router.get(\n    \"/me\",\n    status_code=status.HTTP_200_OK,\n    response_model=TokenData,\n    name=\"get_user_data\",\n    summary=\"Get details of currently logged in user\",\n)\nasync def get_me(user: TokenData = Depends(get_current_user)):\n\n    return user\n"}
{"type": "source_file", "path": "app/db/tables/auth/__init__.py", "content": ""}
{"type": "source_file", "path": "app/logs/logger.py", "content": "from os.path import join, abspath, dirname\nimport logging\nimport logging.config\n\n\nLOGGER_NAME: str = \"docflow\"\nLOG_FORMAT: str = (\n    \"%(asctime)s [%(levelname)s] | %(name)s | %(filename)s | %(funcName)s | %(lineno)d | %(message)s\"\n)\nLOG_LEVEL: int = logging.DEBUG\n\nBASE_DIR = abspath(dirname(__file__))\n\nLOG_FILE: str = join(BASE_DIR, \"docflow.log\")\n\nLOGGING = {\n    \"version\": 1,\n    \"disable_existing_logger\": False,\n    \"formatters\": {\n        \"standard\": {\n            \"format\": LOG_FORMAT,\n            \"datefmt\": \"%Y-%m-%d %H:%M:%S\",\n        },\n    },\n    \"handlers\": {\n        \"default\": {\n            \"level\": \"INFO\",\n            \"formatter\": \"standard\",\n            \"class\": \"logging.StreamHandler\",\n            \"stream\": \"ext://sys.stderr\",\n        },\n        \"file\": {\n            \"class\": \"logging.handlers.RotatingFileHandler\",\n            \"formatter\": \"standard\",\n            \"level\": \"DEBUG\",\n            \"filename\": \"docflow.log\",\n            \"mode\": \"a\",\n            \"encoding\": \"utf-8\",\n            \"maxBytes\": 500000,\n            \"backupCount\": 4,\n        },\n    },\n    \"loggers\": {\n        \"\": {\"handlers\": [\"default\"], \"level\": \"INFO\", \"propagate\": True},\n        LOGGER_NAME: {\n            \"handlers\": [\"default\", \"file\"],\n            \"level\": LOG_LEVEL,\n            \"propagate\": False,\n        },\n        \"sqlalchemy\": {\"handlers\": [\"file\"], \"level\": \"WARNING\"},\n        \"s3\": {\"handlers\": [\"file\"], \"level\": \"WARNING\"},\n        \"uvicorn.error\": {\"level\": \"INFO\", \"handlers\": [\"default\"], \"propagate\": False},\n        \"uvicorn.access\": {\"level\": \"INFO\", \"handlers\": [\"default\"], \"propagate\": True},\n        \"uvicorn.asgi\": {\"level\": \"INFO\", \"handlers\": [\"default\"], \"propagate\": True},\n    },\n}\n\nlogging.config.dictConfig(LOGGING)\n\n# loggers\ndocflow_logger = logging.getLogger(\"docflow\")\ns3_logger = logging.getLogger(\"s3\")\nsqlalchemy_logger = logging.getLogger(\"sqlalchemy\")\n"}
{"type": "source_file", "path": "app/db/tables/base_class.py", "content": "import enum\n\n\nclass StatusEnum(enum.Enum):\n    \"\"\"\n    Enum for status of document\n    \"\"\"\n\n    public = \"public\"\n    private = \"private\"\n    shared = \"shared\"\n    deleted = \"deleted\"\n    archived = \"archived\"\n\n\nclass NotifyEnum(enum.Enum):\n    \"\"\"\n    Enum for status of notification\n    \"\"\"\n\n    read = \"read\"\n    unread = \"unread\"\n\n    @classmethod\n    def has_value(cls, value):\n        return value in cls._value2member_map_\n"}
{"type": "source_file", "path": "app/db/repositories/documents/documents_metadata.py", "content": "from datetime import datetime, timezone, timedelta\nfrom typing import Any, Dict, List, Union\nfrom uuid import UUID\n\nfrom fastapi import HTTPException\nfrom sqlalchemy import select, update, insert, delete\nfrom sqlalchemy.engine import Row\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.orm import aliased\n\nfrom app.core.exceptions import http_409, http_404\nfrom app.db.repositories.auth.auth import AuthRepository\nfrom app.db.tables.documents.documents_metadata import DocumentMetadata, doc_user_access\nfrom app.db.tables.base_class import StatusEnum\nfrom app.schemas.auth.bands import TokenData\nfrom app.schemas.documents.bands import DocumentMetadataPatch\nfrom app.schemas.documents.documents_metadata import (\n    DocumentMetadataCreate,\n    DocumentMetadataRead,\n)\n\n\nclass DocumentMetadataRepository:\n\n    def __init__(self, session: AsyncSession) -> None:\n        self.session = session\n        self.doc_cls = aliased(DocumentMetadata, name=\"doc_cls\")\n\n    async def _get_instance(self, document: Union[str, UUID], owner: TokenData):\n\n        try:\n            UUID(str(document))\n            stmt = (\n                select(self.doc_cls)\n                .where(self.doc_cls.owner_id == owner.id)\n                .where(self.doc_cls.id == document)\n                .where(self.doc_cls.status != StatusEnum.deleted)\n            )\n        except ValueError:\n            stmt = (\n                select(self.doc_cls)\n                .where(self.doc_cls.owner_id == owner.id)\n                .where(self.doc_cls.name == document)\n                .where(self.doc_cls.status != StatusEnum.deleted)\n            )\n\n        result = await self.session.execute(stmt)\n\n        return result.scalar_one_or_none()\n\n    @staticmethod\n    async def _extract_changes(document_patch: DocumentMetadataPatch) -> dict:\n\n        if isinstance(document_patch, dict):\n            return document_patch\n        return document_patch.model_dump(exclude_unset=True)\n\n    async def _execute_update(\n        self, db_document: DocumentMetadata | Dict[str, Any], changes: dict\n    ) -> None:\n\n        if isinstance(db_document, dict):\n            stmt = (\n                update(DocumentMetadata)\n                .where(DocumentMetadata.id == db_document.get(\"id\"))\n                .values(changes)\n            )\n            doc_name = db_document.get(\"name\")\n        else:\n            stmt = (\n                update(DocumentMetadata)\n                .where(DocumentMetadata.id == db_document.id)\n                .values(changes)\n            )\n            doc_name = db_document.name\n\n        try:\n            await self.session.execute(stmt)\n        except Exception as e:\n            raise http_409(msg=f\"Error while updating document: {doc_name}\") from e\n\n    async def _update_access_and_permission(self, db_document, changes, user_repo):\n\n        access_given_to = changes.get(\"access_to\", [])\n        # if access_to has email ids, update doc_user_access table with doc_id and user_id\n        for user_email in access_given_to:\n            try:\n                user_id = (\n                    await user_repo.get_user(field=\"email\", detail=user_email)\n                ).__dict__[\"id\"]\n                # update doc_user_access table with doc_id and user_id\n                await self._update_doc_user_access(db_document, user_id)\n\n            except IntegrityError as e:\n                raise http_409(msg=f\"User '{user_email}' already has access...\") from e\n            except AttributeError as e:\n                raise http_404(\n                    msg=f\"The user with '{user_email}' does not exists, make sure user has account in DocFlow.\"\n                ) from e\n\n    async def _update_doc_user_access(self, db_document, user_id):\n\n        stmt = insert(doc_user_access).values(\n            doc_id=db_document.__dict__[\"id\"], user_id=user_id\n        )\n        await self.session.execute(stmt)\n        await self.session.commit()\n\n    async def _delete_access(self, document) -> None:\n        await self.session.execute(\n            doc_user_access.delete().where(doc_user_access.c.doc_id == document.id)\n        )\n\n    async def _auto_delete(self, bin_items: List) -> bool | None:\n\n        for item in bin_items:\n            if item.DocumentMetadata.created_at <= datetime.now(timezone.utc):\n                stmt = delete(DocumentMetadata).where(\n                    DocumentMetadata.id == item.DocumentMetadata.id\n                )\n                await self.session.execute(stmt)\n                return True\n\n    async def get_doc(self, filename: str) -> Dict[str, Any]:\n        \"\"\"\n        Get document by filename irrespective of logged-in user.\n\n        Args:\n            self: The instance of the class.\n            filename (str): The name of the document.\n\n        Returns:\n            Dict[str, Any]: The document metadata.\n        \"\"\"\n\n        stmt = (\n            select(DocumentMetadata)\n            .where(DocumentMetadata.name == filename)\n            .where(self.doc_cls.status != StatusEnum.deleted)\n        )\n        result = await self.session.execute(stmt)\n        result.fetchall()\n\n        return result.scalar_one_or_none()\n\n    async def upload(\n        self, document_upload: DocumentMetadataCreate\n    ) -> DocumentMetadataRead:\n\n        if not isinstance(document_upload, dict):\n            db_document = DocumentMetadata(**document_upload.model_dump())\n        else:\n            db_document = DocumentMetadata(**document_upload)\n\n        try:\n            self.session.add(db_document)\n            await self.session.commit()\n            await self.session.refresh(db_document)\n        except IntegrityError as e:\n            raise http_404(\n                msg=f\"Document with name: {document_upload.name} already exists.\",\n            ) from e\n\n        return DocumentMetadataRead(**db_document.__dict__)\n\n    async def doc_list(\n        self, owner: TokenData, limit: int = 10, offset: int = 0\n    ) -> Dict[str, Union[List[DocumentMetadataRead], Any]]:\n\n        stmt = (\n            select(self.doc_cls)\n            .join(DocumentMetadata, DocumentMetadata.id == self.doc_cls.id)\n            .where(DocumentMetadata.owner_id == owner.id)\n            .where(DocumentMetadata.status != StatusEnum.deleted)\n            .offset(offset)\n            .limit(limit)\n        )\n\n        try:\n            result = await self.session.execute(stmt)\n            result_list = result.fetchall()\n\n            for row in result_list:\n                row.doc_cls.__dict__.pop(\"_sa_instance_state\", None)\n\n            result = [\n                DocumentMetadataRead(**row.doc_cls.__dict__) for row in result_list\n            ]\n            return {f\"documents of {owner.username}\": result, \"no_of_docs\": len(result)}\n        except Exception as e:\n            raise http_404(msg=\"No Documents found\") from e\n\n    async def get(\n        self, document: Union[str, UUID], owner: TokenData\n    ) -> Union[DocumentMetadataRead, HTTPException]:\n\n        db_document = await self._get_instance(document=document, owner=owner)\n        if db_document is None:\n            return http_409(msg=f\"No Document with {document}\")\n\n        return DocumentMetadataRead(**db_document.__dict__)\n\n    async def patch(\n        self,\n        document: Union[str, UUID],\n        document_patch: DocumentMetadataPatch,\n        owner: TokenData,\n        user_repo: AuthRepository,\n        is_owner: bool,\n    ) -> Union[DocumentMetadataRead, HTTPException]:\n\n        if is_owner:\n            db_document = await self._get_instance(document=document, owner=owner)\n            changes = await self._extract_changes(document_patch)\n\n            await self._update_access_and_permission(db_document, changes, user_repo)\n\n            await self._execute_update(db_document, changes)\n\n        else:\n            # This condition will be activated when, the new version of file is added by a privileged member\n            # here privileged member is one who have access to update the document.\n            db_document = await self.get_doc(filename=document)\n            changes = await self._extract_changes(document_patch)\n\n            if changes:\n                await self._execute_update(db_document, changes)\n\n        return DocumentMetadataRead(**db_document.__dict__)\n\n    async def delete(self, document: Union[str, UUID], owner: TokenData) -> None:\n\n        try:\n            db_document = await self._get_instance(document=document, owner=owner)\n\n            setattr(db_document, \"status\", StatusEnum.deleted)\n            setattr(db_document, \"tags\", None)\n            setattr(db_document, \"access_to\", None)\n            setattr(db_document, \"file_type\", None)\n            setattr(db_document, \"categories\", None)\n            # considering created_at as delete_at to delete it after 30 days\n            setattr(\n                db_document,\n                \"created_at\",\n                datetime.now(timezone.utc) + timedelta(days=30),\n            )\n\n            # delete entry from doc_user_access table\n            await self._delete_access(document=db_document)\n\n            self.session.add(db_document)\n\n            await self.session.commit()\n        except Exception as e:\n            raise http_404(msg=f\"No file with {document}\") from e\n\n    async def bin_list(self, owner: TokenData) -> Dict[str, List[Row | Row] | int]:\n\n        stmt = (\n            select(DocumentMetadata)\n            .where(DocumentMetadata.owner_id == owner.id)\n            .where(DocumentMetadata.status == StatusEnum.deleted)\n        )\n\n        result = (await self.session.execute(stmt)).fetchall()\n        # delete documents that lived 30 days in bin\n        if await self._auto_delete(result):\n            result = (await self.session.execute(stmt)).fetchall()\n\n        return {\"response\": result, \"no_of_docs\": len(result)}\n\n    async def restore(self, file: str, owner: TokenData) -> DocumentMetadataRead:\n\n        doc_list = await self.bin_list(owner=owner)\n\n        if doc_list[\"no_of_docs\"] > 0:\n            for doc in doc_list[\"response\"]:\n                if doc.DocumentMetadata.name == file:\n                    change = {\"status\": StatusEnum.private}\n                    await self._execute_update(\n                        db_document=doc.DocumentMetadata, changes=change\n                    )\n                    return DocumentMetadataRead(**doc.DocumentMetadata.__dict__)\n            raise http_409(msg=\"Doc is not deleted\")\n        raise http_404(msg=\"Doc does not exists\")\n\n    async def perm_delete_a_doc(self, document: UUID | None, owner: TokenData) -> None:\n\n        stmt = (\n            delete(DocumentMetadata)\n            .where(DocumentMetadata.owner_id == owner.id)\n            .where(DocumentMetadata.id == document)\n            .where(DocumentMetadata.status == StatusEnum.deleted)\n        )\n\n        await self.session.execute(stmt)\n\n    async def empty_bin(self, owner: TokenData):\n\n        stmt = (\n            delete(DocumentMetadata)\n            .where(DocumentMetadata.owner_id == owner.id)\n            .where(DocumentMetadata.status == StatusEnum.deleted)\n        )\n\n        await self.session.execute(stmt)\n\n    async def archive(self, file: str, user: TokenData):\n\n        doc = await self._get_instance(document=file, owner=user)\n\n        if doc and doc.status != StatusEnum.archived:\n            change = {\"status\": StatusEnum.archived}\n            await self._execute_update(db_document=doc, changes=change)\n            return DocumentMetadataRead(**doc.__dict__)\n\n        if doc and doc.status == StatusEnum.archived:\n            raise http_409(msg=\"Doc is already archived\")\n\n        raise http_404(msg=\"Doc does not exist\")\n\n    async def archive_list(self, user: TokenData) -> Dict[str, List[str] | int]:\n\n        stmt = (\n            select(DocumentMetadata)\n            .where(DocumentMetadata.owner_id == user.id)\n            .where(DocumentMetadata.status == StatusEnum.archived)\n        )\n\n        result = (await self.session.execute(stmt)).fetchall()\n        return {\"response\": result, \"no_of_docs\": len(result)}\n\n    async def un_archive(self, file: str, user: TokenData) -> DocumentMetadataRead:\n\n        doc = await self._get_instance(document=file, owner=user)\n\n        if doc and doc.status == StatusEnum.archived:\n            change = {\"status\": \"private\"}\n            await self._execute_update(db_document=doc, changes=change)\n            return DocumentMetadataRead(**doc.__dict__)\n        if doc and doc.status != StatusEnum.archived:\n            raise http_409(msg=\"Doc is not archived\")\n        raise http_404(msg=\"Doc does not exits\")\n"}
{"type": "source_file", "path": "app/db/tables/auth/auth.py", "content": "from sqlalchemy import Column, String, Text, TIMESTAMP\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql.expression import text\n\nfrom app.api.dependencies.repositories import get_ulid\nfrom app.db.models import Base\n\n\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(\n        String(26),\n        primary_key=True,\n        default=get_ulid,\n        unique=True,\n        index=True,\n        nullable=False,\n    )\n    username: str = Column(String, unique=True, nullable=False)\n    email = Column(String, unique=True, nullable=False)\n    password = Column(Text, nullable=False)\n    user_since = Column(\n        TIMESTAMP(timezone=True), nullable=False, server_default=text(\"now()\")\n    )\n\n    owner_of = relationship(\"DocumentMetadata\", back_populates=\"owner\")\n"}
{"type": "source_file", "path": "app/db/tables/__init__.py", "content": ""}
{"type": "source_file", "path": "app/schemas/documents/__init__.py", "content": ""}
{"type": "source_file", "path": "app/main.py", "content": "from fastapi import FastAPI\nfrom fastapi.responses import FileResponse\n\nfrom app.api.router import router\nfrom app.core.config import settings\nfrom app.db.models import check_tables\n\n\napp = FastAPI(\n    title=settings.title,\n    version=settings.version,\n    description=settings.description,\n    docs_url=settings.docs_url,\n    openapi_url=settings.openapi_url,\n)\n\napp.include_router(router=router, prefix=settings.api_prefix)\n\n\nFAVICON_PATH = \"favicon.ico\"\n\n\n@app.get(FAVICON_PATH, include_in_schema=False, tags=[\"Default\"])\nasync def favicon():\n    return FileResponse(FAVICON_PATH)\n\n\n@app.get(\"/\", tags=[\"Default\"])\nasync def root():\n    return {\n        \"API\": \"Document Management API... Docker's up!!! is it? or not... Yes it is!!!\"\n    }\n\n\n@app.on_event(\"startup\")\nasync def app_startup() -> None:\n    return await check_tables()\n"}
{"type": "source_file", "path": "app/logs/__init__.py", "content": ""}
{"type": "source_file", "path": "app/db/tables/documents/__init__.py", "content": ""}
{"type": "source_file", "path": "app/db/tables/documents/notify.py", "content": "from datetime import datetime, timezone\nfrom uuid import uuid4\n\nfrom sqlalchemy import Column, String, Text, Enum, DateTime, text\nfrom sqlalchemy.dialects.postgresql import UUID\n\nfrom app.db.tables.base_class import NotifyEnum\nfrom app.db.models import Base\n\n\nclass Notify(Base):\n    __tablename__ = \"notify\"\n\n    id: UUID = Column(\n        UUID(as_uuid=True), default=uuid4, primary_key=True, index=True, nullable=False\n    )\n    receiver_id: str = Column(String, nullable=False)\n    message: str = Column(Text, nullable=False)\n    status: Enum = Column(Enum(NotifyEnum), default=NotifyEnum.unread)\n    notified_at = Column(\n        DateTime(timezone=True),\n        default=datetime.now(timezone.utc),\n        nullable=False,\n        server_default=text(\"NOW()\"),\n    )\n"}
{"type": "source_file", "path": "app/schemas/documents/bands.py", "content": "from datetime import datetime\nfrom typing import Optional, List\nfrom uuid import UUID\n\nfrom pydantic import BaseModel\n\nfrom app.db.tables.base_class import StatusEnum, NotifyEnum\n\n\n# Document Metadata\nclass DocumentMetadataBase(BaseModel):\n    _id: UUID\n    owner_id: str\n    name: str\n    s3_url: str\n    created_at: datetime\n    size: Optional[int]\n    file_type: Optional[str]\n    tags: Optional[List[str]]\n    categories: Optional[List[str]]\n    status: StatusEnum\n    file_hash: Optional[str]\n    access_to: Optional[List[str]]\n\n\nclass DocumentMetadataPatch(BaseModel):\n    name: str = None\n    tags: Optional[List[str]] = None\n    categories: Optional[List[str]] = None\n    access_to: Optional[List[str]] = None\n\n\n# Document Sharing\nclass DocumentSharingBase(BaseModel):\n    url_id: str\n    owner_id: str\n    filename: str\n    url: str\n    expires_at: datetime\n    visits: int\n    share_to: Optional[List[str]] = None\n\n\nclass DocUserAccess(BaseModel):\n    id: str\n    doc_id: UUID\n    user_id: str\n\n    class Config:\n        from_attribute = True\n\n\nclass DocUserAccessCreate(BaseModel):\n    doc_id: str\n    user_id: str\n\n\n# Notifications\nclass Notification(BaseModel):\n    id: UUID\n    receiver_id: str\n    message: str\n    status: NotifyEnum\n    notified_at: datetime\n\n\nclass NotifyPatchStatus(BaseModel):\n    status: NotifyEnum = NotifyEnum.unread\n    mark_all: bool = False\n"}
{"type": "source_file", "path": "app/schemas/auth/__init__.py", "content": ""}
{"type": "source_file", "path": "app/db/tables/documents/documents_metadata.py", "content": "from datetime import datetime, timezone\nfrom uuid import uuid4\n\nfrom typing import List, Optional\nfrom sqlalchemy import (\n    Column,\n    String,\n    Integer,\n    ARRAY,\n    text,\n    DateTime,\n    Enum,\n    ForeignKey,\n    Table,\n    UniqueConstraint,\n)\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.orm import Mapped, relationship\n\nfrom app.db.models import Base\nfrom app.db.tables.base_class import StatusEnum\n\n\ndoc_user_access = Table(\n    \"doc_user_access\",\n    Base.metadata,\n    Column(\n        \"doc_id\",\n        UUID(as_uuid=True),\n        ForeignKey(\"document_metadata.id\", ondelete=\"CASCADE\"),\n    ),\n    Column(\"user_id\", String(26), ForeignKey(\"users.id\")),\n    UniqueConstraint(\"doc_id\", \"user_id\", name=\"uq_doc_user_access_doc_user\"),\n)\n\n\nclass DocumentMetadata(Base):\n    __tablename__ = \"document_metadata\"\n\n    id: UUID = Column(\n        UUID(as_uuid=True), default=uuid4, primary_key=True, index=True, nullable=False\n    )\n    owner_id: Mapped[str] = Column(String, ForeignKey(\"users.id\"), nullable=False)\n    name: str = Column(String)\n    s3_url: str = Column(String, unique=True)\n    created_at = Column(\n        DateTime(timezone=True),\n        default=datetime.now(timezone.utc),\n        nullable=False,\n        server_default=text(\"NOW()\"),\n    )\n    size: Optional[int] = Column(Integer)\n    file_type: Optional[str] = Column(String)\n    tags: Optional[List[str]] = Column(ARRAY(String))\n    categories: Optional[List[str]] = Column(ARRAY(String))\n    status: Enum = Column(Enum(StatusEnum), default=StatusEnum.private)\n    file_hash: Optional[str] = Column(String)\n    access_to: Optional[List[str]] = Column(ARRAY(String))\n\n    update_access = relationship(\n        \"User\", secondary=doc_user_access, passive_deletes=True\n    )\n    owner = relationship(\"User\", back_populates=\"owner_of\")\n"}
{"type": "source_file", "path": "app/schemas/auth/bands.py", "content": "from datetime import datetime\nfrom typing import Annotated, Optional\nfrom ulid import ULID\n\nfrom pydantic import BaseModel, EmailStr, Field\n\n\nPydanticULID = Annotated[str, ULID]\n\n\nclass UserAuth(BaseModel):\n    username: str = Field(...)\n    email: EmailStr = Field(..., description=\"Email ID\")\n    password: str = Field(..., min_length=5, max_length=14, description=\"Password\")\n\n\nclass UserOut(BaseModel):\n    id: PydanticULID\n    email: EmailStr\n    user_since: datetime\n\n    class Config:\n        from_attributes = True\n\n\nclass Token(BaseModel):\n    access_token: str\n    token_type: str\n\n\nclass TokenData(BaseModel):\n    id: Optional[str] = None\n    username: Optional[str] = None\n"}
{"type": "source_file", "path": "app/schemas/__init__.py", "content": ""}
{"type": "source_file", "path": "app/schemas/documents/document_sharing.py", "content": "from typing import List, Optional\n\nfrom pydantic import BaseModel\n\nfrom app.schemas.documents.bands import DocumentSharingBase\n\n\nclass DocumentSharingCreate(DocumentSharingBase): ...\n\n\nclass DocumentSharingRead(DocumentSharingBase):\n    url_id: str\n    visits: int\n\n    class Config:\n        from_attributes = True\n\n\nclass SharingRequest(BaseModel):\n    visits: int = 1  # default value of visits (1)\n    share_to: Optional[List[str]] = None  # emails, or usernames of users to share.\n"}
{"type": "source_file", "path": "app/db/repositories/documents/notify.py", "content": "from typing import List\nfrom uuid import UUID\n\nfrom sqlalchemy import select, update, delete\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core.exceptions import http_500, http_409, http_404\nfrom app.db.repositories.auth.auth import AuthRepository\nfrom app.db.tables.base_class import NotifyEnum\nfrom app.db.tables.documents.notify import Notify\nfrom app.schemas.auth.bands import TokenData\nfrom app.schemas.documents.bands import Notification, NotifyPatchStatus\n\n\nclass NotifyRepo:\n\n    def __init__(self, session: AsyncSession) -> None:\n        self.session = session\n\n    async def notify(\n        self,\n        user: TokenData,\n        receivers: List[str],\n        filename: str,\n        auth_repo: AuthRepository,\n    ) -> None:\n        \"\"\"\n        Notify users about a shared file.\n\n        Args:\n            user (TokenData): The authenticated user who shared the file.\n            receivers (List[str]): The list of email addresses of the users to be notified.\n            filename (str): The name of the shared file.\n            auth_repo (AuthRepository): The repository for accessing user authentication data.\n\n        Returns:\n            None\n\n        Raises:\n            HTTP_500: If an error occurs while adding the notification entry.\n        \"\"\"\n\n        for receiver in receivers:\n\n            receiver_details = await auth_repo.get_user(field=\"email\", detail=receiver)\n            try:\n                notify_entry = Notify(\n                    receiver_id=receiver_details.__dict__[\"id\"],\n                    message=f\"{user.username} shared {filename} with you! Access the shared file via mail...\",\n                    status=NotifyEnum.unread,\n                )\n\n                try:\n                    self.session.add(notify_entry)\n                    await self.session.commit()\n                    await self.session.refresh(notify_entry)\n                except Exception as e:\n                    raise http_500(\n                        msg=\"Error notifying the user, but the mail has been sent successfully.\"\n                    ) from e\n            except Exception as e:\n                raise http_404(\n                    msg=\"The user does not exists, make sure the user has an account on docflow...\"\n                ) from e\n\n    async def get_notification_by_id(self, n_id: UUID, user: TokenData) -> Notification:\n        \"\"\"\n        Get a notification by its ID for a specific user.\n\n        Args:\n            n_id (UUID): The ID of the notification.\n            user (TokenData): The authenticated user.\n\n        Returns:\n            Notification: The notification object.\n\n        Raises:\n            HTTP_404: If no notification with the given ID is found.\n        \"\"\"\n\n        stmt = select(Notify).where(Notify.receiver_id == user.id and Notify.id == n_id)\n\n        try:\n            result = (await self.session.execute(stmt)).scalar_one_or_none()\n            return Notification(**result.__dict__)\n        except Exception as e:\n            raise http_404(msg=f\"No notification with id: {n_id}\") from e\n\n    async def get_notifications(self, user: TokenData) -> List[Notification]:\n        \"\"\"\n        Get all notifications for a specific user.\n\n        Args:\n            user (TokenData): The authenticated user.\n\n        Returns:\n            List[Notification]: A list of notification objects.\n        \"\"\"\n\n        stmt = select(Notify).where(Notify.receiver_id == user.id)\n\n        notifications = (await self.session.execute(stmt)).fetchall()\n\n        return [\n            Notification(**notification.Notify.__dict__)\n            for notification in notifications\n        ]\n\n    async def mark_all_read(self, user: TokenData) -> List[Notification]:\n        \"\"\"\n        Mark all notifications as read for a specific user.\n\n        Args:\n            user (TokenData): The authenticated user.\n\n        Returns:\n            List[Notification]: A list of notification objects that have been marked as read.\n\n        Raises:\n            HTTP_409: If an error occurs while updating the notification status.\n        \"\"\"\n\n        stmt = (\n            update(Notify)\n            .where(Notify.receiver_id == user.id and Notify.status != NotifyEnum.read)\n            .values({Notify.status: NotifyEnum.read})\n        )\n\n        try:\n            await self.session.execute(stmt)\n            return await self.get_notifications(user=user)\n        except Exception as e:\n            raise http_409(msg=\"Error updating marking notification read...\") from e\n\n    async def update_status(\n        self, n_id: UUID, updated_status: NotifyPatchStatus, user: TokenData\n    ):\n        \"\"\"\n        Update the status of a notification for a specific user.\n\n        Args:\n            n_id (UUID): The ID of the notification to update.\n            updated_status (NotifyPatchStatus): The updated status for the notification.\n            user (TokenData): The authenticated user.\n\n        Returns:\n            Notification: The updated notification object.\n\n        Raises:\n            HTTP_409: If an error occurs while updating the notification status.\n        \"\"\"\n        stmt = (\n            update(Notify)\n            .where(\n                Notify.receiver_id == user.id\n                and Notify.id == n_id\n                and Notify.status != updated_status.status\n            )\n            .values({Notify.status: updated_status.status})\n        )\n\n        try:\n            await self.session.execute(stmt)\n            return await self.get_notification_by_id(n_id=n_id, user=user)\n        except Exception as e:\n            raise http_409(msg=\"Error updating notification status...\") from e\n\n    async def clear_notification(self, user: TokenData) -> None:\n        \"\"\"\n        Clear all notifications for a specific user.\n\n        Args:\n            user (TokenData): The authenticated user.\n\n        Returns:\n            None\n\n        Raises:\n            Exception: If an error occurs while clearing the notifications.\n        \"\"\"\n\n        stmt = delete(Notify).where(Notify.receiver_id == user.id)\n\n        try:\n            await self.session.execute(stmt)\n        except Exception as e:\n            raise e\n"}
{"type": "source_file", "path": "app/schemas/auth/auth.py", "content": "from app.schemas.auth.bands import UserOut\n\n\nclass SystemUser(UserOut):\n    password: str\n"}
{"type": "source_file", "path": "app/db/tables/documents/document_sharing.py", "content": "from typing import List, Optional\n\nfrom datetime import datetime, timezone\nfrom sqlalchemy import Column, Integer, String, DateTime, ARRAY, ForeignKey\nfrom sqlalchemy.orm import Mapped\n\nfrom app.db.models import Base\n\n\nclass DocumentSharing(Base):\n    __tablename__ = \"share_url\"\n\n    url_id: str = Column(String, primary_key=True, nullable=False, unique=True)\n    filename: str = Column(String, unique=True, nullable=False)\n    owner_id: Mapped[str] = Column(String, ForeignKey(\"users.id\"), nullable=False)\n    url: str = Column(String, unique=True)\n    expires_at = Column(\n        DateTime(timezone=True),\n        default=datetime.now(timezone.utc),\n    )\n    visits: int = Column(Integer)\n    share_to: Optional[List[str]] = Column(ARRAY(String))\n"}
