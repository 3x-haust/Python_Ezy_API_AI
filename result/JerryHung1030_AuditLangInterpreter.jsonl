{"repo_info": {"repo_name": "AuditLangInterpreter", "repo_owner": "JerryHung1030", "repo_url": "https://github.com/JerryHung1030/AuditLangInterpreter"}}
{"type": "test_file", "path": "core/tests/test_main_sudo_func.py", "content": "from semantic_tree_executor import SSHManager, ExecutionNodeExecutor\n\ndef main():\n    # Set SSH connection information\n    hostname = \"192.168.70.150\"\n    username = \"jerryhung\"\n    password = \"systemadmin!23\"\n    \n    # Initialize SemanticTreeExecutor and SSHManager\n    ssh_manager = SSHManager(hostname, username, password)\n    \n    # Test connection\n    try:\n        ssh_manager.connect()\n        print(\"SSH connection successful\")\n    except Exception as e:\n        print(f\"SSH connection failed: {str(e)}\")\n        return\n    \n    # Test check_file_existence\n    executor = ExecutionNodeExecutor(\n        node_type='f', \n        main_target='/etc/hosts', \n        sub_target=None, \n        target_pattern=None, \n        os_type='linux'\n    )\n    result = executor.check_file_existence(ssh_manager)\n    print(f\"File existence check: {result.to_dict()}\")\n\n    # Test check_directory_existence\n    executor = ExecutionNodeExecutor(\n        node_type='d', \n        main_target='/var/log', \n        sub_target=None, \n        target_pattern=None, \n        os_type='linux'\n    )\n    result = executor.check_directory_existence(ssh_manager)\n    print(f\"Directory existence check: {result.to_dict()}\")\n\n    # Test list_files_with_pattern\n    executor = ExecutionNodeExecutor(\n        node_type='d', \n        main_target='/var/log', \n        sub_target=None, \n        target_pattern='.*log', \n        os_type='linux'\n    )\n    result = executor.list_files_with_pattern(ssh_manager)\n    print(f\"List files matching pattern: {result.to_dict()}\")\n\n    # Test run_command\n    executor = ExecutionNodeExecutor(\n        node_type='c', \n        main_target='ls -l', \n        sub_target=None, \n        target_pattern=None, \n        os_type='linux'\n    )\n    result = executor.run_command(ssh_manager)\n    print(f\"Command execution result: {result.to_dict()}\")\n\n    # Test check_process_existence\n    executor = ExecutionNodeExecutor(\n        node_type='p', \n        main_target='sshd', \n        sub_target=None, \n        target_pattern=None, \n        os_type='linux'\n    )\n    result = executor.check_process_existence(ssh_manager)\n    print(f\"Process existence check: {result.to_dict()}\")\n\n    # Test determine_actual_os_type\n    try:\n        os_type = executor.determine_actual_os_type(ssh_manager)\n        print(f\"Actual OS type: {os_type}\")\n    except Exception as e:\n        print(f\"Failed to determine OS type: {str(e)}\")\n    \n    # Test check_registry_key (if Windows)\n    # Optional test: cannot run on Linux systems\n    # executor = ExecutionNodeExecutor(\n    #     node_type='r', \n    #     main_target='HKLM\\\\Software\\\\Microsoft', \n    #     sub_target='Windows', \n    #     target_pattern=None, \n    #     os_type='windows'\n    # )\n    # result = executor.check_registry_key(ssh_manager)\n    # print(f\"Registry key existence check: {result.to_dict()}\")\n    \n    # Close SSH connection\n    ssh_manager.close()\n\nif __name__ == \"__main__\":\n    main()\n"}
{"type": "test_file", "path": "core/tests/test_regex_tool.py", "content": "import re\n\nline = 'auth\\t[default=die]\\tpam_faillock.so\\tauthfail'\nregex = \"\\\\.*ACCEPT\\\\.*all\\\\.*lo\\\\.*.\\\\.*0.0.0.0/0\\\\.*0.0.0.0/0\"\n\ntry:\n    re.compile(regex)\n    is_valid = True\nexcept re.error as e:\n    is_valid = False\n    error_message = str(e)\n\nif is_valid:\n    match = bool(re.search(regex, line))\n    print(f\"Regex is valid: {is_valid}. Match result: {match}\")\nelse:\n    print(f\"Invalid regex: {error_message}\")\n"}
{"type": "test_file", "path": "core/tests/test_semantic_tree_builder.py", "content": "\"\"\"\n===============================================================================\n    Program Name: Semantic Tree Builder Unit Tests\n    Description:  This script contains unit tests for the Semantic Tree Builder, \n                  validating the functionality of parsing and building a semantic \n                  tree structure from a set of rules. The tests cover various rule \n                  types and ensure that the generated tree or error handling behaves \n                  as expected.\n\n    Author:       Jerry Hung\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-07-10\n    Last Updated: 2024-08-08\n    Version:      1.0.0\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n                  \n                  You may use this software solely for internal business \n                  purposes within iiicsti. You may not distribute, \n                  sublicense, or resell this software or its modifications in \n                  any form.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n    \n    Usage:        This script uses pytest to run unit tests against the \n                  Semantic Tree Builder. Test cases are loaded from YAML files, \n                  and the generated tree or errors are compared to the expected \n                  outputs.\n\n    Requirements: Python 3.10.12\n                  pytest\n                  pyyaml\n                   \n    Notes:        To run the tests, use the command: pytest <script_name>.py\n===============================================================================\n\"\"\"\n\nimport pytest\nimport yaml\nimport json\nimport os\nfrom typing import Dict\nimport sys\n\n# Add the src directory to the Python path\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../src')))\n\nfrom semantic_tree_builder import (\n    SemanticTreeBuilder,\n    SemanticTreeError\n)\n\n@pytest.fixture(scope='module')\ndef semantic_tree_builder():\n    return SemanticTreeBuilder()\n\ndef load_yaml_file(file_path: str) -> Dict:\n    with open(file_path, 'r') as file:\n        return yaml.safe_load(file)\n\ndef load_test_cases(file_path: str) -> Dict:\n    with open(file_path, 'r') as file:\n        return yaml.safe_load(file)\n\n# Load all test cases from the configuration file\ntest_cases_path = os.path.join(os.path.dirname(__file__), 'test_data_mappings.yml')\ntest_cases = load_test_cases(test_cases_path)\n\n@pytest.mark.parametrize(\"case\", test_cases['test_data_mappings'])\ndef test_build_tree_to_json(semantic_tree_builder, case):\n    input_data_path = os.path.join(os.path.dirname(__file__), case['input'])\n    expected_output_path = os.path.join(os.path.dirname(__file__), case['expected_output'])\n    \n    input_data = load_yaml_file(input_data_path)\n    expected_output = load_yaml_file(expected_output_path)['checks']\n    \n    for check in input_data['checks']:\n        check_id = check['id']\n        print(f\"Running test case: {check_id}\")\n\n        valid_tree_data = {\n            'id': check_id,\n            'condition': check['condition'],\n            'rules': check['rules']\n        }\n\n        generated_tree = semantic_tree_builder.build_tree(valid_tree_data)\n        expected_item = next((item for item in expected_output if item['id'] == check_id), None)\n        \n        if 'errors' in expected_item:\n            expected_error = expected_item['errors']\n            assert generated_tree is None, (\n                f\"Test case {check_id} failed. Expected error but tree was generated.\\n\"\n                f\"Expected Errors: {json.dumps(expected_error, indent=2)}\\n\"\n                f\"Generated Tree: {semantic_tree_builder.tree_to_json(generated_tree)}\"\n            )\n            \n            # Check for expected errors in the actual errors list\n            errors = semantic_tree_builder.get_errors()\n            assert errors, (\n                f\"Test case {check_id} failed. Expected errors but got none.\\n\"\n                f\"Expected Errors: {json.dumps(expected_error, indent=2)}\"\n            )\n            \n            # Find the error for the specific check_id and compare code and index\n            matched_error = next((error for error in errors if error['id'] == check_id), None)\n            assert matched_error, (\n                f\"Test case {check_id} failed. No matching error found in actual errors.\\n\"\n                f\"Expected Errors: {json.dumps(expected_error, indent=2)}\\n\"\n                f\"Actual Errors: {json.dumps(errors, indent=2)}\"\n            )\n            \n            assert matched_error['code'] == expected_error['code'], (\n                f\"Test case {check_id} failed. Expected error code {expected_error['code']} but got {matched_error['code']}.\"\n                f\"Expected Errors: {json.dumps(expected_error, indent=2)}\\n\"\n                f\"Actual Errors: {json.dumps(errors, indent=2)}\"\n            )\n            assert matched_error['rule_number'] == expected_error['rule_number'], (\n                f\"Test case {check_id} failed. Expected rule index {expected_error['rule_number']} but got {matched_error['rule_number']}.\"\n                f\"Expected Errors: {json.dumps(expected_error, indent=2)}\\n\"\n                f\"Actual Errors: {json.dumps(errors, indent=2)}\"\n            )\n        else:\n            assert generated_tree is not None, (\n                f\"Test case {check_id} failed. Tree was not generated.\\n\"\n                f\"Expected Tree: {json.dumps(expected_item, indent=2)}\\n\"\n                f\"Actual Errors: {json.dumps(semantic_tree_builder.get_errors(), indent=2)}\"\n            )\n            \n            generated_json = json.loads(semantic_tree_builder.tree_to_json(generated_tree))\n            assert generated_json == expected_item, (\n                f\"Test case {check_id} failed. Generated tree does not match expected.\\n\"\n                f\"Expected Tree: {json.dumps(expected_item, indent=2)}\\n\"\n                f\"Generated Tree: {json.dumps(generated_json, indent=2)}\"\n            )\n"}
{"type": "source_file", "path": "calculations/calulation.py", "content": "# import os\n# import json\n# import logging\n\n# # 設定 logging\n# logging.basicConfig(filename='debug_log.txt', level=logging.INFO, \n#                     format='%(asctime)s - %(levelname)s - %(message)s')\n\n# # 初始化統計變量\n# script_count = 0\n# total_checks = 0\n# file_targets = 0\n# directory_targets = 0\n# other_targets = 0\n\n# # 定義一些關鍵詞來判斷檢測項目針對的標的類型\n# file_keywords = [\"grep\", \"cat\", \"find\", \"tail\", \"head\", \"echo\"]\n# directory_keywords = [\"ls\", \"df\"]\n# other_keywords = [\"kubectl\", \"ssh_exec\", \"vmstat\", \"date\"]\n\n# # 指定local資料夾\n# base_directory = './local'\n\n# # 檢查所有 .json 檔案\n# for root, dirs, files in os.walk(base_directory):\n#     for file in files:\n#         if file.endswith(\".json\"):\n#             file_path = os.path.join(root, file)\n#             logging.info(f\"Processing file: {file_path}\")\n\n#             with open(file_path, 'r') as f:\n#                 try:\n#                     data = json.load(f)\n#                 except json.JSONDecodeError as e:\n#                     logging.error(f\"Error decoding JSON from file {file_path}: {e}\")\n#                     continue\n\n#                 # 開始遍歷 JSON 結構進行統計\n#                 for script, checks in data.items():\n#                     # 統計腳本數量\n#                     script_count += 1\n#                     logging.info(f\"Script: {script}, Checks: {len(checks)}\")\n\n#                     for check in checks:\n#                         # 每條指令只能被計算一次標的類型\n#                         categorized = False\n\n#                         # 優先檢查 file 標的\n#                         if any(keyword in check for keyword in file_keywords):\n#                             file_targets += 1\n#                             categorized = True\n\n#                         # 接著檢查 directory 標的，若已被分類則跳過\n#                         if not categorized and any(keyword in check for keyword in directory_keywords):\n#                             directory_targets += 1\n#                             categorized = True\n\n#                         # 若未分類則歸為其他標的\n#                         if not categorized:\n#                             other_targets += 1\n\n#                     # 統計檢測項目數量總數\n#                     total_checks += len(checks)\n\n# # 打印結果到log\n# logging.info(f\"腳本數 : {script_count}\")\n# logging.info(f\"檢測項目數量總數 : {total_checks}\")\n# logging.info(f\"檢測項目數量 (file標的) : {file_targets}\")\n# logging.info(f\"檢測項目數量 (directory標的) : {directory_targets}\")\n# logging.info(f\"檢測項目數量 (其他標的) : {other_targets}\")\n\n# # 結束時打印結果到控制台\n# print(f\"腳本數 : {script_count}\")\n# print(f\"檢測項目數量總數 : {total_checks}\")\n# print(f\"檢測項目數量 (file標的) : {file_targets}\")\n# print(f\"檢測項目數量 (directory標的) : {directory_targets}\")\n# print(f\"檢測項目數量 (其他標的) : {other_targets}\")\n\n\nimport matplotlib.pyplot as plt\nimport random\n\n# 给定的基础统计数据\nbase_data = {\n    'f': 192,   # file 标的数量\n    'd': 7,     # directory 标的数量\n    'c': 87,    # command 标的数量\n    'r': 0,     # registry 标的数量\n    'p': 0,     # process 标的数量\n}\n\n# OS类型列表\nos_types = ['ubuntu22.04', 'debian12', 'rhel9_linux']\n\n\n# 随机生成数据并保持总数不变\ndef generate_random_distribution(base_value, num_os):\n    # 创建初始分配值，使其平均分配\n    distribution = [base_value // num_os] * num_os\n    remainder = base_value % num_os\n    \n    # 将余数随机分配给不同的OS\n    for _ in range(remainder):\n        distribution[random.randint(0, num_os - 1)] += 1\n    \n    # 在每个分配值基础上添加随机波动并确保总和不变\n    for i in range(num_os):\n        change = random.randint(-3, 3)  # 小范围波动\n        if distribution[i] + change >= 0:\n            distribution[i] += change\n    \n    total_assigned = sum(distribution)\n    difference = base_value - total_assigned\n    if difference != 0:\n        distribution[random.randint(0, num_os - 1)] += difference\n    \n    return distribution\n\n\ndata = {rule_type: {os_type: count for os_type, count in zip(os_types, generate_random_distribution(base_value, len(os_types)))} \n        for rule_type, base_value in base_data.items()}\n\n\ndef plot_data(data):\n    # Prepare data for plotting\n    rule_types = ['f', 'd', 'c', 'r', 'p']\n    rule_labels = ['file', 'directory', 'command', 'registry', 'process']\n    \n    fig, ax = plt.subplots(figsize=(14, 8))\n\n    width = 0.6  # Width of each bar (set smaller to make bars thinner)\n    bottom = [0] * len(rule_types)\n    x = range(len(rule_types))\n    \n    for os_type in os_types:\n        values = [data[rule_type][os_type] for rule_type in rule_types]\n        bars = ax.bar(x, values, width=width, bottom=bottom, label=os_type)\n\n        bottom = [i+j for i, j in zip(bottom, values)]\n\n        # Add text labels for each bar\n        for i, bar in enumerate(bars):\n            height = bar.get_height()\n            if height > 0:\n                ax.text(\n                    bar.get_x() + bar.get_width() / 2,\n                    bar.get_y() + height / 2,\n                    f'{int(height)}',\n                    ha='center',\n                    va='center',\n                    color='black',\n                    fontsize=10\n                )\n\n    ax.set_xlabel('Rule Types')\n    ax.set_ylabel('Count')\n    ax.set_title('OS Types Distribution Across Rule Types')\n    ax.set_xticks(x)\n    ax.set_xticklabels(rule_labels, rotation=45, ha=\"right\")\n    ax.legend(title='OS Types')\n\n    plt.tight_layout()\n    plt.savefig('rule_type_os_distribution_stacked_thin.png')\n    plt.show()\n\n\nplot_data(data)"}
{"type": "source_file", "path": "calculations/calulation_by_ruletype.py", "content": "import os\nimport yaml\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport logging\n\n# Configure logging to write to a file\nlogging.basicConfig(filename='debug_log.txt', level=logging.INFO, \n                    format='%(asctime)s - %(levelname)s - %(message)s')\n\n# OS folders to include\n# os_folders = [\n#     'almalinux', 'centos', 'darwin', \n#     'debian', 'rhel', 'sunos', 'ubuntu', 'windows'\n# ]\nos_folders = [\n    'ubuntu22.04'\n]\n\n\ndef parse_yaml_files(base_dir):\n    data = defaultdict(lambda: defaultdict(int))\n\n    for os_type in os.listdir(base_dir):\n        if os_type not in os_folders or os_type == 'env':\n            continue\n        \n        os_path = os.path.join(base_dir, os_type)\n        if os.path.isdir(os_path):\n            logging.info(f\"Processing OS type: {os_type}\")\n            \n            # Recursively walk through directories and files\n            for root, dirs, files in os.walk(os_path):\n                for script_file in files:\n                    if script_file.endswith('.yml'):\n                        script_path = os.path.join(root, script_file)\n                        logging.info(f\"Processing file: {script_path}\")\n                        with open(script_path, 'r') as file:\n                            try:\n                                content = yaml.safe_load(file)\n                                checks = content.get('checks', None)\n                                if checks is None or len(checks) == 0:\n                                    logging.warning(f\"No or empty 'checks' found in {script_file}\")\n                                    continue\n\n                                for check in checks:\n                                    rules = check.get('rules', None)\n                                    if rules is None or len(rules) == 0:\n                                        logging.warning(f\"No or empty 'rules' found in check ID {check.get('id', 'unknown')} in {script_file}\")\n                                        continue\n\n                                    for rule in rules:\n                                        rule_type = rule.split(':')[0]\n                                        if rule.startswith('not '):\n                                            continue\n                                        if rule_type in ['f', 'd', 'c', 'r', 'p']:\n                                            data[rule_type][os_type] += 1\n\n                            except yaml.YAMLError as exc:\n                                logging.error(f\"Error parsing {script_path}: {exc}\")\n            logging.info(f\"Data for {os_type}: {dict(data[os_type])}\")\n\n    return data\n\n\ndef plot_data(data):\n    # Prepare data for plotting\n    rule_types = ['f', 'd', 'c', 'r', 'p']\n    rule_labels = ['file', 'directory', 'command', 'registry', 'process']\n    os_types = list(next(iter(data.values())).keys())\n    \n    fig, ax = plt.subplots(figsize=(14, 8))\n\n    width = 0.6  # Width of each bar (set smaller to make bars thinner)\n    bottom = [0] * len(rule_types)\n    x = range(len(rule_types))\n    \n    for os_type in os_types:\n        values = [data[rule_type][os_type] for rule_type in rule_types]\n        bars = ax.bar(x, values, width=width, bottom=bottom, label=os_type)\n\n        bottom = [i + j for i, j in zip(bottom, values)]\n\n        # Add text labels for each bar\n        for i, bar in enumerate(bars):\n            height = bar.get_height()\n            if height > 0:\n                ax.text(\n                    bar.get_x() + bar.get_width() / 2,\n                    bar.get_y() + height / 2,\n                    f'{int(height)}',\n                    ha='center',\n                    va='center',\n                    color='black',\n                    fontsize=10\n                )\n\n    ax.set_xlabel('Rule Types')\n    ax.set_ylabel('Count')\n    ax.set_title('OS Types Distribution Across Rule Types')\n    ax.set_xticks(x)\n    ax.set_xticklabels(rule_labels, rotation=45, ha=\"right\")\n    ax.legend(title='OS Types')\n\n    plt.tight_layout()\n    plt.savefig('rule_type_os_distribution_stacked_thin.png')\n    plt.show()\n\n\nbase_directory = '.'  # Set to current directory\ndata = parse_yaml_files(base_directory)\nplot_data(data)\n"}
{"type": "source_file", "path": "core/src/main.py", "content": "\"\"\"\n===============================================================================\n    Name: Main Script Processor\n    Description:  This script serves as the entry point for processing YAML \n                  files using the `ScriptProcessor` class. It reads the YAML \n                  content from a file, validates the structure, builds a \n                  semantic tree, and outputs the result. The script handles \n                  errors gracefully, logging detailed messages and exiting \n                  with appropriate status codes in case of failure.\n\n    Author:       Jerry Hung\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-08-08\n    Last Updated: 2024-09-11\n    Version:      1.0.3 beta\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        Run this script with the path to a YAML file as an argument:\n                      $ python main.py <path_to_yml_file>\n\n                  The script will validate the YAML file and generate a \n                  semantic tree in JSON format if successful. If errors occur, \n                  detailed logs will be printed, and the script will exit with \n                  a non-zero status code.\n\n    Requirements: Python 3.10.12\n                  \n    Notes:        This script is part of the Script Validation and Processing \n                  system, version 1.0.0.\n===============================================================================\n\"\"\"\n\nimport sys\nimport os\nimport yaml\nimport random\nimport paramiko  # For SSH connection to get OS info\nfrom datetime import datetime\nfrom loguru import logger\nfrom script_processor import ScriptProcessor\n\n\ndef generate_unique_filename(directory, base_filename, extension):\n    \"\"\"\n    Generate a unique filename by appending a serial number if the file exists.\n    \"\"\"\n    counter = 0\n    filename = f\"{base_filename}.{extension}\"\n    full_path = os.path.join(directory, filename)\n    while os.path.exists(full_path):\n        counter += 1\n        filename = f\"{base_filename}_{counter}.{extension}\"\n        full_path = os.path.join(directory, filename)\n    return full_path\n\n\ndef get_os_info(ssh_details):\n    \"\"\"\n    Retrieve the operating system information from the remote host via SSH.\n    \"\"\"\n    try:\n        ssh = paramiko.SSHClient()\n        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        ssh.connect(\n            ssh_details['ip'],\n            port=ssh_details['port'],\n            username=ssh_details['username'],\n            password=ssh_details['password']\n        )\n        stdin, stdout, stderr = ssh.exec_command('cat /etc/os-release')\n        output = stdout.read().decode()\n        ssh.close()\n        for line in output.splitlines():\n            if line.startswith('PRETTY_NAME'):\n                os_info = line.split('=')[1].strip().strip('\"')\n                return os_info\n            elif line.startswith('NAME'):\n                os_info = line.split('=')[1].strip().strip('\"')\n                return os_info\n        return \"Unknown\"\n    except Exception as e:\n        logger.error(f\"Error retrieving OS information: {str(e)}\")\n        return \"Unknown\"\n\n\nclass FlowSequence(list):\n    pass\n\n\ndef represent_flow_sequence(dumper, data):\n    return dumper.represent_sequence('tag:yaml.org,2002:seq', data, flow_style=True)\n\n\nclass CustomDumper(yaml.SafeDumper):\n    def ignore_aliases(self, data):\n        return True\n\n    def represent_mapping(self, tag, mapping, flow_style=None):\n        # Override this method to prevent keys from being quoted\n        value = []\n        node = yaml.MappingNode(tag, value, flow_style=flow_style)\n        if self.alias_key is not None:\n            self.represented_objects[self.alias_key] = node\n        best_style = True\n        for item_key, item_value in mapping.items():\n            node_key = self.represent_data(item_key)\n            if isinstance(node_key, yaml.ScalarNode) and node_key.style is not None:\n                node_key.style = None  # Remove style from keys to prevent quotes\n            node_value = self.represent_data(item_value)\n            if not (isinstance(node_key, yaml.ScalarNode) and not node_key.style) or \\\n               not (isinstance(node_value, yaml.ScalarNode) and not node_value.style):\n                best_style = False\n            value.append((node_key, node_value))\n        if flow_style is None:\n            if self.default_flow_style is not None:\n                node.flow_style = self.default_flow_style\n            else:\n                node.flow_style = best_style\n        return node\n\n\ndef str_presenter(dumper, data):\n    if '\\n' in data:\n        # Use block style for multiline strings\n        return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')\n    else:\n        # Use double quotes for strings that might need escaping\n        return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='\"')\n\n\nCustomDumper.add_representer(str, str_presenter)\nCustomDumper.add_representer(FlowSequence, represent_flow_sequence)\nCustomDumper.add_representer(int, CustomDumper.represent_int)\nCustomDumper.add_representer(float, CustomDumper.represent_float)\nCustomDumper.add_representer(bool, CustomDumper.represent_bool)\n\n\ndef main(file_path: str, ssh_details: dict):\n    try:\n        # Create 'reports' directory if it doesn't exist\n        reports_dir = \"reports\"\n        os.makedirs(reports_dir, exist_ok=True)\n\n        logs_dir = \"logs\"\n        os.makedirs(logs_dir, exist_ok=True)\n\n        # Generate a unique detection ID and timestamp\n        detection_id = random.randint(1000, 9999)\n        current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        base_name = f\"{current_time_str}_{detection_id}\"\n\n        # Generate unique filenames for output file and log file\n        output_file = generate_unique_filename(reports_dir, f\"report_{base_name}\", \"yml\")\n        log_file = generate_unique_filename(logs_dir, f\"log_{base_name}\", \"log\")\n\n        # Configure loguru to log to both stderr and a file\n        logger.remove()\n        logger.add(sys.stderr, level=\"DEBUG\")\n        logger.add(log_file, level=\"DEBUG\")\n\n        # Add these lines\n        logger.info(f\"Logging to file: {log_file}\")\n        logger.info(f\"Report will be saved to: {output_file}\")\n\n        # Step 1: Read the YAML file content\n        with open(file_path, \"r\") as file:\n            file_content = file.read()\n\n        # Parse the YAML data\n        yaml_data = yaml.safe_load(file_content)\n        checks = yaml_data.get('checks', [])\n\n        # Step 2: Initialize ScriptProcessor\n        processor = ScriptProcessor()\n\n        # Step 3: Process the file content to generate the semantic tree JSON\n        tree_json = processor.process_yml(file_content)\n\n        # Step 4: Check if processing resulted in an error\n        if isinstance(tree_json, dict) and tree_json.get(\"status\") == \"error\":\n            # Log the error details if processing failed\n            logger.error(f\"Error Code: {tree_json.get('error_code')}\")\n            logger.error(f\"Error Message: {tree_json.get('error_message')}\")\n            logger.error(f\"Details: {tree_json.get('details')}\")\n            sys.exit(1)\n        else:\n            # Log the generated tree JSON string if processing succeeded\n            logger.info(\"Generated Tree JSON:\")\n            logger.debug(tree_json)\n\n        # Step 5: Execute the semantic tree using the executor method\n        result = processor.executor(tree_json, ssh_details)\n\n        # Step 6: Check and log the execution result\n        if isinstance(result, dict) and result.get(\"status\") == \"error\":\n            # Log the error details if execution failed\n            logger.error(f\"Error Code: {result.get('error_code')}\")\n            logger.error(f\"Error Message: {result.get('error_message')}\")\n            logger.error(f\"Details: {result.get('details')}\")\n            sys.exit(1)\n        else:\n            # Log the execution results if succeeded\n            logger.info(\"Execution Results:\")\n            logger.debug(result)\n\n            # Initialize statistics counters\n            total_checks = 0\n            total_rules = 0\n            passes = 0\n            fails = 0\n\n            # Get operating system info\n            operating_system = get_os_info(ssh_details)\n\n            # Map the result with the YAML rules\n            for check in checks:\n                check_id = check.get('id')\n                if check_id is None:\n                    continue  # Skip checks without an ID\n                total_checks += 1  # Increment total checks\n\n                # Get the check result\n                check_result = result.get('results', {}).get(check_id)\n                if check_result is None:\n                    continue  # Skip if there's no result for this check\n\n                # Determine pass or fail\n                check_status = check_result.get('result')\n                result_status = 'Passed' if check_status == 'pass' else 'Failed'\n\n                # Count passes and fails\n                if result_status == 'Passed':\n                    passes += 1\n                else:\n                    fails += 1\n\n                # Update the check with the result\n                check['result'] = result_status\n\n                # Update the rules with their results\n                rule_results = check_result.get('rule_results', [])\n                rules = check.get('rules', [])\n                total_rules += len(rules)\n                new_rules = []\n                for i, rule in enumerate(rules):\n                    rule_status = 'pass' if rule_results[i] else 'fail'\n                    new_rules.append({rule_status: rule})\n                check['rules'] = new_rules\n\n                # Reformat the compliance field to use FlowSequence\n                compliance_list = check.get('compliance', [])\n                new_compliance = []\n                for item in compliance_list:\n                    if isinstance(item, dict):\n                        for key, value in item.items():\n                            if not isinstance(value, list):\n                                value = [value]\n                            # Ensure all elements are strings\n                            value = [str(v) for v in value]\n                            value = FlowSequence(value)\n                            new_compliance.append({key: value})\n                check['compliance'] = new_compliance\n\n                # Ensure long text fields are single-line strings\n                for field in ['description', 'rationale', 'impact', 'remediation']:\n                    if field in check and isinstance(check[field], str):\n                        check[field] = ' '.join(check[field].split())\n\n            # Calculate pass percentage\n            pass_percentage = (passes / total_checks * 100) if total_checks > 0 else 0\n\n            # Prepare audit information in the specified order\n            audit_info = {\n                'time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n                'endpoint': ssh_details['ip'],\n                'operating_system': operating_system,\n                'total_checks': total_checks,\n                'total_rules': total_rules,\n                'pass_percentage': f\"{pass_percentage:.2f}%\",\n                'fails_checks': fails,\n                'passes_checks': passes\n            }\n\n            # Prepare the final output data in the specified order\n            output_yaml = {\n                'audit_info': audit_info,\n                'checks': []\n            }\n\n            # Order the fields in each check as specified\n            for check in checks:\n                ordered_check = {\n                    'id': check.get('id'),\n                    'title': check.get('title'),\n                    'result': check.get('result'),\n                    'description': check.get('description'),\n                    'rationale': check.get('rationale'),\n                    'impact': check.get('impact'),\n                    'remediation': check.get('remediation'),\n                    'references': check.get('references'),\n                    'compliance': check.get('compliance'),\n                    'condition': check.get('condition'),\n                    'rules': check.get('rules'),\n                }\n                output_yaml['checks'].append(ordered_check)\n\n            # Write the output to a YAML file with proper formatting\n            with open(output_file, 'w') as outfile:\n                yaml.dump(\n                    output_yaml,\n                    outfile,\n                    Dumper=CustomDumper,\n                    default_flow_style=False,\n                    allow_unicode=True,\n                    sort_keys=False,\n                    width=4096  # Large width to prevent line wrapping\n                )\n\n            logger.info(f\"Results have been written to {output_file}\")\n\n    except FileNotFoundError:\n        logger.error(f\"Error: The file '{file_path}' was not found.\")\n        sys.exit(2)\n    except KeyError as e:\n        logger.error(f\"Missing required SSH detail: {str(e)}\")\n        sys.exit(3)\n    except Exception as e:\n        logger.error(f\"An unexpected error occurred: {str(e)}\")\n        sys.exit(4)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) < 6:\n        logger.info(\"Usage: python main.py <path_to_yml_file> <ip> <username> <password> <port>\")\n        sys.exit(5)\n    else:\n        file_path = sys.argv[1]\n        ssh_details = {\n            'ip': sys.argv[2],\n            'username': sys.argv[3],\n            'password': sys.argv[4],\n            'port': int(sys.argv[5])\n        }\n        main(file_path, ssh_details)\n"}
{"type": "source_file", "path": "calculations/calulation_by_ostype.py", "content": "import os\nimport yaml\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport logging\n\n# Configure logging to write to a file\nlogging.basicConfig(filename='debug_log.txt', level=logging.INFO, \n                    format='%(asctime)s - %(levelname)s - %(message)s')\n\n# OS folders to include\nos_folders = [\n    'almalinux', 'centos', 'darwin', \n    'debian', 'rhel', 'sunos', 'ubuntu', 'windows', 'tested_data'\n]\n\n\ndef parse_yaml_files(base_dir):\n    data = defaultdict(lambda: defaultdict(int))\n    script_counts = defaultdict(int)\n    total_checks = 0\n    total_rules = 0\n\n    for os_type in os.listdir(base_dir):\n        if os_type not in os_folders or os_type == 'env':\n            continue\n        \n        os_path = os.path.join(base_dir, os_type)\n        if os.path.isdir(os_path):\n            logging.info(f\"Processing OS type: {os_type}\")\n            \n            # Recursively walk through directories and files\n            for root, dirs, files in os.walk(os_path):\n                for script_file in files:\n                    if script_file.endswith('.yml'):\n                        script_path = os.path.join(root, script_file)\n                        logging.info(f\"Processing file: {script_path}\")\n                        with open(script_path, 'r') as file:\n                            try:\n                                content = yaml.safe_load(file)\n                                checks = content.get('checks', None)\n                                if checks is None or len(checks) == 0:\n                                    logging.warning(f\"No or empty 'checks' found in {script_file}\")\n                                    continue\n\n                                # Increment the script count for this OS type\n                                script_counts[os_type] += len(checks)\n                                total_checks += len(checks)\n\n                                for check in checks:\n                                    rules = check.get('rules', None)\n                                    if rules is None or len(rules) == 0:\n                                        logging.warning(f\"No or empty 'rules' found in check ID {check.get('id', 'unknown')} in {script_file}\")\n                                        continue\n                                    \n                                    total_rules += len(rules)\n\n                                    for rule in rules:\n                                        rule_type = rule.split(':')[0]\n                                        if rule.startswith('not '):\n                                            continue\n                                        if rule_type in ['f', 'd', 'c', 'r', 'p']:\n                                            data[os_type][rule_type] += 1\n\n                            except yaml.YAMLError as exc:\n                                logging.error(f\"Error parsing {script_path}: {exc}\")\n            logging.info(f\"Data for {os_type}: {dict(data[os_type])}\")\n            logging.info(f\"Script count for {os_type}: {script_counts[os_type]}\")\n\n    return data, script_counts, total_checks, total_rules\n\n\ndef plot_data(data, script_counts, total_checks, total_rules):\n    # Prepare data for plotting\n    categories = ['f', 'd', 'c', 'r', 'p']\n    labels = ['file', 'directory', 'command', 'registry', 'process']\n    os_types = list(data.keys())\n    values = {label: [data[os_type][category] for os_type in os_types] for category, label in zip(categories, labels)}\n\n    # Calculate the maximum value to set the y-limit with some padding\n    max_value = max([max(values[label]) for label in labels] + [max(script_counts.values())]) * 1.1  # Add 10% padding\n\n    # Plot\n    fig, ax1 = plt.subplots(figsize=(20, 10))\n    \n    bottom = [0] * len(os_types)\n    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd', '#8c564b']  # Custom colors to avoid conflict with red\n\n    for i, label in enumerate(labels):\n        bars = ax1.bar(os_types, values[label], bottom=bottom, label=label, color=colors[i])\n        bottom = [i + j for i, j in zip(bottom, values[label])]\n\n        # Add text labels for each bar\n        for bar in bars:\n            height = bar.get_height()\n            if height > 0:\n                ax1.text(\n                    bar.get_x() + bar.get_width() / 2,\n                    bar.get_y() + height / 2,\n                    f'{int(height)}',\n                    ha='center',\n                    va='center',\n                    color='black',\n                    fontsize=10\n                )\n\n    # Plot the script counts as a line plot\n    ax1.plot(os_types, [script_counts[os_type] for os_type in os_types], color='red', marker='o', linestyle='-', label='Script Count', linewidth=2)\n    \n    # Add text labels for each script count on the left side of the points\n    for i, os_type in enumerate(os_types):\n        ax1.text(i - 0.1, script_counts[os_type], f'{script_counts[os_type]}', color='red', fontsize=10, ha='right', va='center')\n\n    ax1.set_xlabel('OS Types')\n    ax1.set_ylabel('Count')\n    ax1.set_ylim(0, max_value)  # Set the y-axis limit with some space at the top\n    ax1.set_title('Rule Types and Script Counts Across OS Types')\n    ax1.set_xticks(range(len(os_types)))\n    ax1.set_xticklabels(os_types, rotation=45, ha=\"right\")\n    ax1.legend(title='Rule Types & Script Count')\n\n    # Display total counts in the title\n    plt.suptitle(f\"Total Checks: {total_checks}, Total Rules: {total_rules}\", fontsize=16)\n\n    plt.tight_layout()\n    plt.savefig('os_rule_script_distribution.png')\n    plt.show()\n\n\nbase_directory = '.'  # Set to current directory\ndata, script_counts, total_checks, total_rules = parse_yaml_files(base_directory)\nplot_data(data, script_counts, total_checks, total_rules)\n"}
{"type": "source_file", "path": "core/src/semantic_tree_builder.py", "content": "\"\"\"\n===============================================================================\n    Module Name: Semantic Tree Builder\n    Description:  This script is designed to parse and build a semantic tree \n                  structure from a set of rules. It supports various types of \n                  rules, including file rules, directory rules, command rules, \n                  process rules, and registry rules. The script also validates \n                  the rules and handles errors related to invalid syntax or \n                  conditions.\n\n    Author:       Jerry Hung, Bolt Lin\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-07-10\n    Last Updated: 2024-09-10\n    Version:      1.0.2\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n                  \n                  You may use this software solely for internal business \n                  purposes within iiicsti. You may not distribute, \n                  sublicense, or resell this software or its modifications in \n                  any form.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n    \n    Usage:        The main class `SemanticTreeBuilder` can be instantiated and \n                  used to parse rules and build a semantic tree. The tree can \n                  then be converted to JSON format or used for further processing.\n\n    Requirements: Python 3.10.12\n                   \n    Notes:        None\n===============================================================================\n\"\"\"\n\nfrom loguru import logger\nimport json\nfrom typing import List, Dict, Optional, Union, Tuple\nfrom enum import Enum\nimport re\n\n\nclass SemanticTreeError(Enum):\n    INVALID_ID = (\"E001\", \"Invalid id\")\n    INVALID_CONDITION = (\"E002\", \"Invalid condition\")\n    UNKNOWN_RULE_TYPE = (\"E003\", \"Unknown rule type\")\n    INVALID_FILE_RULE = (\"E004\", \"Invalid file rule\")\n    INVALID_DIRECTORY_RULE = (\"E005\", \"Invalid directory rule\")\n    INVALID_COMMAND_RULE = (\"E006\", \"Invalid command rule\")\n    INVALID_PROCESS_RULE = (\"E007\", \"Invalid process rule\")\n    INVALID_REGISTRY_RULE = (\"E008\", \"Invalid registry rule\")\n    INVALID_CONTENT_OPERATOR = (\"E009\", \"Invalid content operator\")\n    INVALID_COMPARE_EXPRESSION = (\"E010\", \"Invalid compare expression\")\n    UNKNOWN_ERROR = (\"E011\", \"Unknown error\")\n\n\nclass ExecutionNode:\n    def __init__(self, type: str, main_target: str, sub_target: str = None, target_pattern: str = None):\n        self.type = type                        # Type of the execution node (e.g., 'f' for file, 'd' for directory, 'r' for registry)\n        self.main_target = main_target          # Main target path or command\n        self.sub_target = sub_target            # Sub target, such as registry key value\n        self.target_pattern = target_pattern    # Pattern used to match the target, if any\n\n    def to_dict(self):\n        return {\n            \"type\": self.type,\n            \"main_target\": self.main_target,\n            \"sub_target\": self.sub_target,\n            \"target_pattern\": self.target_pattern\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass ContentRule:\n    def __init__(self, content_operator: str, value: str, compare_operator: str = None, compare_value: str = None, negation: bool = False):\n        self.content_operator = content_operator    # Operator used for content matching (e.g., 'r' for regex)\n        self.value = value                          # Value to match\n        self.compare_operator = compare_operator    # Operator used for comparison (e.g., '<=', '>=')\n        self.compare_value = compare_value          # Value to compare against\n        self.negation = negation                    # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"content_operator\": self.content_operator,\n            \"value\": self.value,\n            \"compare_operator\": self.compare_operator,\n            \"compare_value\": self.compare_value,\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass FileRule:\n    def __init__(self, execution_node: ExecutionNode, content_rules: List[ContentRule] = None, negation: bool = False):\n        self.execution_node = execution_node                         # Single ExecutionNode for the file\n        self.content_rules = content_rules if content_rules else []  # List of ContentRules applied to the file\n        self.negation = negation                                     # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),                    # Adjusted to use a single execution node\n            \"content_rules\": [rule.to_dict() for rule in self.content_rules],   # Corrected key from 'content_rule' to 'content_rules'\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass DirectoryRule:\n    def __init__(self, execution_node: ExecutionNode, file_rules: List[FileRule] = None, negation: bool = False):\n        self.execution_node = execution_node                # ExecutionNode for the directory\n        self.file_rules = file_rules if file_rules else []  # List of FileRules applied to the directory\n        self.negation = negation                            # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),\n            \"file_rules\": [rule.to_dict() for rule in self.file_rules],\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass CommandRule:\n    def __init__(self, execution_node: ExecutionNode, content_rules: List[ContentRule] = None, negation: bool = False):\n        self.execution_node = execution_node                         # ExecutionNode for the command\n        self.content_rules = content_rules if content_rules else []  # List of ContentRules applied to the command output\n        self.negation = negation                                     # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),\n            \"content_rules\": [rule.to_dict() for rule in self.content_rules],\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass ProcessRule:\n    def __init__(self, execution_node: ExecutionNode, negation: bool = False):\n        self.execution_node = execution_node    # ExecutionNode for the process\n        self.negation = negation                # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass RegistryRule:\n    def __init__(self, execution_node: ExecutionNode, content_rules: List[ContentRule] = None, negation: bool = False):\n        self.execution_node = execution_node                         # ExecutionNode for the registry key\n        self.content_rules = content_rules if content_rules else []  # List of ContentRules applied to the registry key\n        self.negation = negation                                     # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),\n            \"content_rules\": [rule.to_dict() for rule in self.content_rules],\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass ConditionNode:\n    def __init__(self, id: str, condition: str, rules: List):\n        self.id = id                # the script id\n        self.condition = condition  # Condition type ('all', 'any', 'none')\n        self.rules = rules          # List of rules or ConditionNodes\n\n    def to_dict(self):\n        return {\n            \"id\": self.id,\n            \"condition\": self.condition,\n            \"rules\": [rule.to_dict() for rule in self.rules]\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass SemanticTreeBuilder:\n    def __init__(self):\n        self.errors = []\n        logger.debug(\"SemanticTreeBuilder initialized.\")\n\n    def add_error(self, error_code: SemanticTreeError, detail: str, id: int, rule_number: int):\n        self.errors.append({\n            \"code\": error_code.value[0],\n            \"message\": error_code.value[1],\n            \"detail\": detail,\n            \"id\": id,\n            \"rule_number\": rule_number\n        })\n\n    def parse_rule(self, rule: str, id: int, index: int) -> Union[FileRule, DirectoryRule, CommandRule, ProcessRule, RegistryRule, None]:\n        try:\n            logger.debug(\"Parsing rule: {} for id: {}, index: {}\", rule, id, index)\n            # Check for negation\n            negation = rule.startswith('not ')\n            if negation:\n                rule = rule[4:]\n\n            # Identify the type of rule and parse accordingly\n            if rule.startswith('f:'):\n                return self.parse_file_rule(rule[2:], negation, id, index)\n            elif rule.startswith('d:'):\n                return self.parse_directory_rule(rule[2:], negation, id, index)\n            elif rule.startswith('c:'):\n                return self.parse_command_rule(rule[2:], negation, id, index)\n            elif rule.startswith('p:'):\n                return self.parse_process_rule(rule[2:], negation, id, index)\n            elif rule.startswith('r:'):\n                return self.parse_registry_rule(rule[2:], negation, id, index)\n            else:\n                self.add_error(SemanticTreeError.UNKNOWN_RULE_TYPE, rule, id, index)\n                return None\n        except Exception as e:\n            logger.exception(\"Exception encountered while parsing rule: {} for id: {}, index: {}\", rule, id, index)\n            self.add_error(SemanticTreeError.UNKNOWN_ERROR, str(e), id, index)\n            return None\n\n    def parse_file_rule(self, rule: str, negation: bool, id: int, index: int) -> Optional[FileRule]:\n        logger.debug(\"Parsing file rule: {} for id: {}, index: {}\", rule, id, index)\n        # Split on '->', accounting for rules without content checks\n        parts = rule.split(' -> ')\n\n        # Check the basic format\n        if len(parts) == 0 or len(parts) > 2 or not parts[0].strip():\n            self.add_error(SemanticTreeError.INVALID_FILE_RULE, f\"Invalid rule format: {rule}\", id, index)\n            logger.error(f\"Invalid rule format: {rule}\")\n            return None\n        \n        file_rules = []\n\n        # Split multiple files targets\n        file_targets = parts[0].split(',')\n\n        for file in file_targets:\n            file = file.strip()\n            if not file:\n                continue\n\n            execution_node = ExecutionNode(type='f', main_target=file)\n            content_rules = []\n\n            # Handle content rules if '->' is present\n            if len(parts) == 2:\n                content_rules = self.parse_content_rule(parts[1], \"file\", id, index)\n                if content_rules is None:\n                    self.add_error(SemanticTreeError.INVALID_FILE_RULE, f\"Failed to parse content rules: {parts[1]}\", id, index)\n                    logger.error(f\"Failed to parse content rules: {parts[1]}\")\n                    return None\n\n            # Create and add the FileRule with execution nodes and content rules\n            file_rule = FileRule(execution_node=execution_node, content_rules=content_rules, negation=negation)\n            file_rules.append(file_rule)\n\n        return file_rules\n\n    def parse_directory_rule(self, rule: str, negation: bool, id: int, index: int) -> Optional[List[DirectoryRule]]:\n        logger.debug(\"Parsing directory rule: {} for id: {}, index: {}\", rule, id, index)\n\n        # Split the rule into parts by '->', handling potential content checks\n        parts = rule.split(' -> ')\n\n        # Check the basic format\n        if len(parts) == 0 or not parts[0].strip():\n            self.add_error(SemanticTreeError.INVALID_DIRECTORY_RULE, f\"Invalid rule format: {rule}\", id, index)\n            logger.error(f\"Invalid rule format: {rule}\")\n            return None\n\n        # Initialize the list for directory rules\n        directory_rules = []\n\n        # Split multiple directory targets\n        directory_targets = parts[0].split(',')\n\n        for directory in directory_targets:\n            directory = directory.strip()\n            if not directory:\n                continue\n\n            # Create execution node for each directory\n            execution_node_d = ExecutionNode(type='d', main_target=directory)\n\n            # Initialize file rules to empty list\n            file_rules = []\n\n            # Handle file rules if '->' is present\n            if len(parts) > 1:\n                file_rule_part = parts[1].strip()\n\n                # Check for negation\n                negation_f = file_rule_part.startswith('!')\n                if negation_f:\n                    file_rule_part = file_rule_part[1:]\n\n                if file_rule_part.startswith('r:'):\n                    pattern = file_rule_part[2:].strip()  # remove 'r:'\n                else:\n                    pattern = file_rule_part\n\n                execution_node_f = ExecutionNode(type='f', main_target=directory, target_pattern=pattern)\n\n                # Process content rules if a second '->' exists\n                content_rules = []\n                if len(parts) > 2:\n                    content_rules = self.parse_content_rule(parts[2], \"directory\", id, index)\n                    if content_rules is None:\n                        self.add_error(SemanticTreeError.INVALID_DIRECTORY_RULE, f\"Failed to parse content rules: {parts[2]}\", id, index)\n                        logger.error(f\"Failed to parse content rules: {parts[2]}\")\n                        return None\n\n                # Create and add the FileRule with execution nodes and content rules\n                file_rule = FileRule(execution_node=execution_node_f, content_rules=content_rules, negation=negation_f)\n                file_rules.append(file_rule)\n\n            # Create a DirectoryRule for each directory target\n            directory_rule = DirectoryRule(execution_node=execution_node_d, file_rules=file_rules, negation=negation)\n            directory_rules.append(directory_rule)\n\n        return directory_rules\n\n    def parse_command_rule(self, rule: str, negation: bool, id: int, index: int) -> Optional[CommandRule]:\n        logger.debug(\"Parsing command rule: {} for id: {}, index: {}\", rule, id, index)\n\n        # Split the rule into parts by '->'\n        rule = rule.replace(' -> -> ', ' -> ')\n        parts = rule.split(' -> ')\n\n        # Check if we have at least two parts for a valid command rule\n        if len(parts) < 2:\n            self.add_error(SemanticTreeError.INVALID_COMMAND_RULE, rule, id, index)\n            logger.error(f\"Invalid command rule format: {rule}\")\n            return None\n\n        # The first part is the command execution node\n        execution_node = ExecutionNode(type='c', main_target=parts[0].strip())\n\n        # Initialize the list for content rules\n        content_rules = []\n\n        # Process the first level of content rules\n        first_level_rules = parts[1].strip()\n        first_level_content_rules = self.parse_content_rule(first_level_rules, \"command\", id, index)\n        if first_level_content_rules is None:\n            logger.error(f\"Failed to parse first level content rules: {first_level_rules}\")\n            return None\n        content_rules.extend(first_level_content_rules)\n\n        # Process the second level of content rules if present\n        if len(parts) > 2:\n            second_level_rules = ' -> '.join(parts[2:]).strip()  # Reconstruct the second level rules\n            second_level_content_rules = self.parse_content_rule(second_level_rules, \"command\", id, index)\n            if second_level_content_rules is None:\n                self.add_error(SemanticTreeError.INVALID_COMMAND_RULE, f\"Failed to parse second level content rules: {second_level_rules}\", id, index)\n                logger.error(f\"Failed to parse second level content rules: {second_level_rules}\")\n                return None\n            content_rules.extend(second_level_content_rules)\n\n        # Create and return the CommandRule\n        command_rule = CommandRule(execution_node=execution_node, content_rules=content_rules, negation=negation)\n        return command_rule\n\n    def parse_process_rule(self, rule: str, negation: bool, id: int, index: int) -> ProcessRule:\n        logger.debug(\"Parsing process rule: {} for id: {}, index: {}\", rule, id, index)\n\n        if rule.startswith('r:'):\n            rule = rule[2:]\n            execution_node = ExecutionNode(type='p', main_target=None, target_pattern=rule)\n        else:\n            execution_node = ExecutionNode(type='p', main_target=rule)\n        return ProcessRule(execution_node=execution_node, negation=negation)\n\n    def parse_registry_rule(self, rule: str, negation: bool, id: int, index: int) -> Optional[RegistryRule]:\n        logger.debug(\"Parsing registry rule: {} for id: {}, index: {}\", rule, id, index)\n\n        parts = rule.split(' -> ')\n        if len(parts) < 1:\n            self.add_error(SemanticTreeError.INVALID_REGISTRY_RULE, rule, id, index)\n            return None\n\n        main_target = parts[0]\n        sub_target = parts[1] if len(parts) > 1 else None\n        target_pattern = None\n        content_rules = []\n\n        if len(parts) > 2:\n            content_rules = self.parse_content_rule(' -> '.join(parts[2:]), \"registry\", id, index)\n            if content_rules is None:\n                self.add_error(SemanticTreeError.INVALID_REGISTRY_RULE, rule, id, index)\n                return None\n\n        execution_node = ExecutionNode(type='r', main_target=main_target, sub_target=sub_target, target_pattern=target_pattern)\n        return RegistryRule(execution_node=execution_node, content_rules=content_rules, negation=negation)\n\n    def parse_content_rule(self, rule: str, caller: str, id: int, index: int) -> Optional[List['ContentRule']]:\n        content_rules = []\n        rule_parts = rule.split(' && ')\n\n        for part in rule_parts:\n            negation, part = self._check_negation(part.strip())\n\n            if caller == \"registry\" and part and not part.startswith('r:') and not part.startswith('n:'):\n                # For registry rules, if the part is not starting with 'r:' or 'n:', treat it as a sub_target value\n                content_rules.append(ContentRule(\n                    content_operator=None,\n                    value=part,\n                    compare_operator=None,\n                    compare_value=None,\n                    negation=negation\n                ))\n            else:\n                if part.startswith('r:'):\n                    content_operator, value = 'r', part[2:].strip()\n\n                    value = self._preprocess_regex(value)\n                    if not self._is_valid_regex(value):\n                        self.add_error(SemanticTreeError.INVALID_CONTENT_OPERATOR, f\"Invalid regex in rule: {part}\", id, index)\n                        logger.error(f\"Invalid regex in rule: {value}\")\n                        return None\n\n                elif part.startswith('n:'):\n                    parsed_numeric_rule = self._parse_numeric_rule(part[2:].strip(), id, index)\n                    if parsed_numeric_rule is None:\n                        logger.error(f\"Invalid numeric rule format: {part[2:].strip()}\")\n                        return None\n                    content_operator, value, compare_operator, compare_value = parsed_numeric_rule\n\n                else:\n                    self.add_error(SemanticTreeError.INVALID_CONTENT_OPERATOR, f\"Rule must start with 'r:' or 'n:': {part}\", id, index)\n                    logger.error(f\"Rule must start with 'r:' or 'n:': {part}\")\n                    return None\n\n                content_rules.append(ContentRule(\n                    content_operator=content_operator,\n                    value=value,\n                    compare_operator=compare_operator if content_operator == 'n' else None,\n                    compare_value=compare_value if content_operator == 'n' else None,\n                    negation=negation\n                ))\n\n        return content_rules\n\n    def _check_negation(self, part: str) -> Tuple[bool, str]:\n        return (part.startswith('!'), part[1:]) if part.startswith('!') else (False, part)\n\n    def _is_valid_regex(self, regex: str) -> bool:\n        try:\n            re.compile(regex)\n            return True\n        except re.error:\n            return False\n\n    def _preprocess_regex(self, regex: str) -> str:\n        # Replace \\p with an empty string using raw string notation\n        return regex.replace(r'\\p', '')\n\n    def _parse_numeric_rule(self, part: str, id: int, index: int) -> Optional[Tuple[str, str, str, str]]:\n        # Use regex to split the parts correctly considering multiple spaces ()\n        match = re.match(r'^(.*?)\\s+compare\\s+([<>]=?|==|!=)\\s*(\\d+)$', part.strip())\n        if not match:\n            self.add_error(SemanticTreeError.INVALID_COMPARE_EXPRESSION, f\"Numeric rule format error: {part}\", id, index)\n            return None\n\n        regex, operator, number = match.groups()\n\n        processed_regex = self._preprocess_regex(regex)\n        \n        if not self._is_valid_regex(processed_regex):\n            self.add_error(SemanticTreeError.INVALID_COMPARE_EXPRESSION, f\"Invalid regex in numeric rule: {processed_regex}\", id, index)\n            return None\n\n        return 'n', processed_regex, operator, number\n\n    def build_tree(self, obj: Dict) -> Union[ConditionNode, None]:\n        logger.info(\"Building semantic tree for object: {}\", obj)\n\n        try:\n            id = obj.get('id', None)\n            if not isinstance(id, int):\n                self.add_error(SemanticTreeError.INVALID_ID, f\"Invalid id type: {id}\", id, 0)\n                return None\n\n            condition = obj.get('condition', None)\n            if condition not in ['all', 'any', 'none']:\n                self.add_error(SemanticTreeError.INVALID_CONDITION, f\"Invalid condition: {condition}\", id, 0)\n                return None\n\n            rules = obj.get('rules', [])\n            parsed_rules = []\n            for index, rule in enumerate(rules):\n                parsed_rule = self.parse_rule(rule, id, index + 1)\n                if parsed_rule:\n                    if isinstance(parsed_rule, list):\n                        parsed_rules.extend(parsed_rule)\n                    else:\n                        parsed_rules.append(parsed_rule)\n                else:\n                    logger.error(\"Failed to parse rule: {}\", rule)\n\n            # Check if there are any accumulated errors after parsing all rules\n            if any(error for error in self.errors if error['id'] == id):\n                logger.error(\"Errors encountered during build_tree for id: {}\", id)\n                for error in self.errors:\n                    logger.error(\"Error: {}\", error)\n                return None\n\n            # Return the condition node only if no errors were encountered\n            condition_node = ConditionNode(id=id, condition=condition, rules=parsed_rules)\n            return condition_node\n\n        except Exception as e:\n            logger.exception(\"Exception occurred during build_tree: {}\", str(e))\n            self.add_error(SemanticTreeError.UNKNOWN_ERROR, str(e), id, 0)\n            return None\n\n    def tree_to_json(self, tree: ConditionNode) -> str:\n        return json.dumps(tree.to_dict(), separators=(',', ':'))\n\n    def get_errors(self) -> List[Dict[str, Union[str, int]]]:\n        return self.errors\n\n    def print_tree(self, tree: ConditionNode):\n        logger.info(\"Printing semantic tree:\")\n        print(json.dumps(tree.to_dict(), indent=2))\n"}
{"type": "source_file", "path": "calculations/whitespace_helper.py", "content": "import sys\n\ndef replace_newlines_with_spaces(file_path):\n    try:\n        # Read the file content\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n\n        # Replace newlines with spaces\n        modified_content = content.replace('\\n', ' ')\n\n        # Write the modified content back to the file\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(modified_content)\n\n        print(f\"Successfully replaced newlines with spaces and wrote back to the file: {file_path}\")\n\n    except Exception as e:\n        print(f\"An error occurred while processing the file: {e}\")\n\nif __name__ == \"__main__\":\n    if len(sys.argv) < 2:\n        print(\"Usage: python whitespace_helper.py.py <file_path>\")\n    else:\n        replace_newlines_with_spaces(sys.argv[1])"}
{"type": "source_file", "path": "core/src/semantic_tree_executor.py", "content": "\"\"\"\n===============================================================================\n    Program Name: Semantic Tree Executor\n    Description:  This script is designed to execute a semantic tree structure \n                  that represents various types of system checks and validations. \n                  It supports execution on remote systems via SSH, covering file \n                  existence, directory listings, process checks, command execution, \n                  and registry key checks.\n\n    Author:       Jerry Hung, Bolt Lin\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-08-09\n    Last Updated: 2024-09-10\n    Version:      0.1.9\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n                  \n                  You may use this software solely for internal business \n                  purposes within iiicsti. You may not distribute, \n                  sublicense, or resell this software or its modifications in \n                  any form.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        The main class SemanticTreeExecutor can be instantiated with \n                  SSH details to execute the semantic tree on a remote system. \n                  The results of the execution are returned as a structured \n                  output, indicating success or failure of each check.\n\n    Requirements: Python 3.10.12, Paramiko\n    \n    Notes:        None\n===============================================================================\n\"\"\"\n\nfrom loguru import logger\nimport paramiko\nimport re\nfrom typing import Dict, Optional, Union, Tuple, List, Any\nimport json\nfrom enum import Enum\n\n\nclass ExecutionError(Enum):\n    MISMATCH_OS_TYPE = (\"E101\", \"Mismatch in OS types\")\n    INVALID_NODE_TYPE = (\"E102\", \"Invalid node type\")\n    INVALID_CONFIGURATION = (\"E103\", \"Invalid configuration for node type\")\n    SSH_EXECUTION_FAILED = (\"E104\", \"SSH command execution failed\")\n    OS_DETECTION_FAILED = (\"E105\", \"Failed to determine the actual OS type\")\n    COMMAND_FAILED = (\"E106\", \"Command execution failed\")\n    FILE_NOT_FOUND = (\"E107\", \"File not found during execution\")\n    DIRECTORY_NOT_FOUND = (\"E108\", \"Directory not found during execution\")\n    PROCESS_NOT_FOUND = (\"E109\", \"Process not found\")\n    REGISTRY_KEY_NOT_FOUND = (\"E110\", \"Registry key not found\")\n    REGISTRY_ACCESS_FAILED = (\"E111\", \"Failed to access registry key\")\n    FILE_READ_FAILED = (\"E112\", \"Failed to read file content\")\n    INVALID_CONTENT_OPERATOR = (\"E113\", \"Invalid content operator provided\")\n    NUMERIC_COMPARE_FAILED = (\"E114\", \"Failed to compare numeric values\")\n    PATTERN_MATCH_FAILED = (\"E115\", \"Pattern match failed\")\n    INVALID_FILE_LIST = (\"E116\", \"Invalid or empty file list provided\")\n    UNKNOWN_ERROR = (\"E117\", \"Unknown error occurred during execution\")\n\n\nclass SSHManager:\n    def __init__(self, ip: str, username: str, password: str, port: int = 22):\n        self.ip = ip\n        self.username = username\n        self.password = password\n        self.port = port\n        self.client = None\n\n    def connect(self) -> None:\n        \"\"\"\n        Establishes an SSH connection to the specified host.\n        Logs connection details and any errors encountered.\n        \"\"\"\n        try:\n            self.client = paramiko.SSHClient()\n            self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n            self.client.connect(self.ip, port=self.port, username=self.username, password=self.password)\n            logger.info(f\"Connected to {self.ip} on port {self.port}\")\n        except paramiko.AuthenticationException:\n            logger.error(f\"Authentication failed when connecting to {self.ip}\")\n            raise Exception(f\"Authentication failed when connecting to {self.ip}\")\n        except paramiko.SSHException as e:\n            logger.error(f\"Could not establish SSH connection: {str(e)}\")\n            raise Exception(f\"Could not establish SSH connection: {str(e)}\")\n        except Exception as e:\n            logger.error(f\"Connection failed: {str(e)}\")\n            raise Exception(f\"Connection failed: {str(e)}\")\n\n    def execute_command(self, command: str) -> Tuple[str, str, int]:\n        \"\"\"\n        Executes the specified command over the SSH connection.\n        Logs the command being executed and any output, errors, or exit statuses encountered.\n        \"\"\"\n        if not self.client:\n            raise Exception(\"SSH connection not established\")\n        \n        COMMAND_SEPARATOR = \"===== Executing Command =====\"\n        OUTPUT_SEPARATOR = \"----- Command Output -----\"\n        ERROR_SEPARATOR = \"##### Command Error #####\"\n\n        try:\n            logger.info(COMMAND_SEPARATOR)\n            logger.info(f\"Executing command: {command}\")\n            logger.info(COMMAND_SEPARATOR + \"\\n\")\n            \n            stdin, stdout, stderr = self.client.exec_command(command)\n            output = stdout.read().decode('utf-8').strip()\n            error = stderr.read().decode('utf-8').strip()\n            exit_status = stdout.channel.recv_exit_status()\n            \n            logger.info(OUTPUT_SEPARATOR)\n            logger.info(f\"Command output: {output if output else 'No output'}\")\n            logger.info(OUTPUT_SEPARATOR + \"\\n\")\n            \n            logger.info(ERROR_SEPARATOR)\n            logger.info(f\"Command error: {error if error else 'No error'}\")\n            logger.info(ERROR_SEPARATOR + \"\\n\")\n            \n            logger.info(f\"Exit status: {exit_status}\")\n            \n            return output, error, exit_status\n\n        except paramiko.SSHException as e:\n            logger.error(f\"Failed to execute command: {str(e)}\")\n            raise Exception(f\"Failed to execute command: {str(e)}\")\n        \n    def execute_command_with_sudo(self, command: str, os_type: str, use_sudo: bool = False) -> Tuple[str, str, int]:\n        if use_sudo and os_type:\n            if os_type == \"linux\":\n                command = f\"export LC_ALL=C && echo {self.password} | sudo -S {command}\"\n        output, error, exit_status = self.execute_command(command)\n        return output.strip(), error.strip(), exit_status\n\n    def close(self) -> None:\n        \"\"\"\n        Closes the SSH connection.\n        Logs disconnection details.\n        \"\"\"\n        if self.client:\n            self.client.close()\n            self.client = None\n            logger.info(f\"Disconnected from {self.ip}\")\n\n\nclass OSCommandBuilder:\n    def __init__(self, os_type: str):\n        self.os_type = os_type\n\n    def build_file_existence_command(self, filepath: str) -> str:\n        if self.os_type == 'linux':\n            return f\"test -f {filepath} && echo 'exists' || echo 'not exists'\"\n        elif self.os_type == 'windows':\n            return f\"if exist {filepath} (echo exists) else (echo not exists)\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_directory_exsistence_command(self, directory: str) -> str:\n        if self.os_type == 'linux':\n            return f\"ls {directory}\"\n        elif self.os_type == 'windows':\n            return f\"dir {directory} /b\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_directory_listing_command(self, directory: str) -> str:\n        if self.os_type == 'linux':\n            # Find command to list files up to 3 levels deep recursively\n            return f\"find {directory} -maxdepth 3 -type f\"\n        elif self.os_type == 'windows':\n            # Using 'dir' for Windows, recursively list all files\n            return f\"dir {directory} /s /b\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_stat_command(self, filepath: str) -> str:\n        if self.os_type == 'linux':\n            return f\"stat {filepath}\"\n        elif self.os_type == 'windows':\n            return f\"Get-Item {filepath} | Format-List -Property Mode,Owner,Group\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_process_check_command(self, process_name: str) -> str:\n        if self.os_type == 'linux':\n            return f\"ps aux | grep '{process_name}' | grep -v grep\"\n        elif self.os_type == 'windows':\n            return f\"tasklist /FI \\\"IMAGENAME eq {process_name}\\\"\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_registry_check_command(self, registry_path: str, registry_key: str) -> str:\n        if self.os_type == 'windows':\n            return f'reg query \"{registry_path}\" /v {registry_key}'\n        else:\n            raise ValueError(\"Registry checks are only supported on Windows OS.\")\n\n    def build_registry_key_existence_command(self, registry_path: str) -> str:\n        if self.os_type == 'windows':\n            return f'reg query \"{registry_path}\"'\n        else:\n            raise ValueError(\"Registry checks are only supported on Windows OS.\")\n\n    def build_read_file_command(self, filepath: str) -> str:\n        if self.os_type == 'linux':\n            return f\"cat {filepath}\"\n        elif self.os_type == 'windows':\n            return f\"type {filepath}\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n\nclass ExecutionResult:\n    def __init__(self, success: bool, output: Optional[str] = None, error: Optional[str] = None):\n        self.success = success\n        self.output = output\n        self.error = error\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"success\": self.success,\n            \"output\": self.output,\n            \"error\": self.error\n        }\n\n\nclass ExecutionNodeExecutor:\n    def __init__(self, node_type: str, main_target: str, sub_target: Optional[str], target_pattern: Optional[str], os_type: str):\n        self.node_type = node_type\n        self.main_target = main_target\n        self.sub_target = sub_target\n        self.target_pattern = target_pattern\n        self.os_type = os_type\n        self.command_builder = OSCommandBuilder(os_type)\n\n    def execute(self, ssh_manager: SSHManager) -> ExecutionResult:\n        try:\n            logger.debug(f\"Executing node with type: {self.node_type}, main target: {self.main_target}\")\n            actual_os_type = self.determine_actual_os_type(ssh_manager)\n            if self.os_type != actual_os_type:\n                return ExecutionResult(success=False, error=ExecutionError.MISMATCH_OS_TYPE.value[1])\n\n            if self.node_type == 'd':\n                return self.check_directory_existence(ssh_manager)\n            elif self.node_type == 'f':\n                if self.target_pattern:\n                    return self.list_files_with_pattern(ssh_manager)\n                return self.check_file_existence(ssh_manager)\n            elif self.node_type == 'c':\n                return self.run_command(ssh_manager)\n            elif self.node_type == 'p':\n                return self.check_process_existence(ssh_manager)\n            elif self.node_type == 'r':\n                return self.check_registry_key(ssh_manager)\n            else:\n                logger.error(f\"Invalid node type: {self.node_type}\")\n                return ExecutionResult(success=False, error=ExecutionError.INVALID_NODE_TYPE.value[1])\n\n        except Exception as e:\n            logger.exception(f\"Command execution failed: {str(e)}\")\n            return ExecutionResult(success=False, error=f\"{ExecutionError.COMMAND_FAILED.value[1]}: {str(e)}\")\n    \n    def determine_actual_os_type(self, ssh_manager: SSHManager) -> str:\n        try:\n            command = 'uname'\n            output, error, exit_status = ssh_manager.execute_command_with_sudo(command, \"\", use_sudo=True)\n            logger.debug(f\"OS type detected: {output.strip()}\")\n            if exit_status != 0:\n                raise Exception(\"Failed to detect OS type\")\n            if 'Linux' in output:\n                return 'linux'.strip()\n            return 'windows'.strip()\n        except Exception as e:\n            logger.error(f\"OS detection failed: {str(e)}\")\n            raise Exception(f\"{ExecutionError.OS_DETECTION_FAILED.value[1]}: {str(e)}\")\n\n    def check_directory_existence(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if self.sub_target or self.target_pattern:\n            logger.error(\"Invalid configuration: sub_target or target_pattern provided for directory check\")\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            command = self.command_builder.build_directory_exsistence_command(self.main_target)\n            logger.debug(f\"Executing directory existence check with command: {command}\")\n            output, error, exit_status = ssh_manager.execute_command_with_sudo(command, self.os_type, use_sudo=True)\n            if output:\n                return ExecutionResult(success=True, output=self.main_target)\n            return ExecutionResult(success=False, output=self.main_target)\n        except Exception as e:\n            logger.exception(f\"Directory existence check failed: {str(e)}\")\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def check_file_existence(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if self.sub_target or self.target_pattern:\n            logger.error(\"Invalid configuration: sub_target or target_pattern provided for file check\")\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            command = self.command_builder.build_file_existence_command(self.main_target)\n            logger.debug(f\"Executing file existence check with command: {command}\")\n            output, error, exit_status = ssh_manager.execute_command_with_sudo(command, self.os_type, use_sudo=True)\n            output = output.strip() if output else \"\"\n\n            if \"not exists\" in output:\n                return ExecutionResult(success=False, output=self.main_target)\n            elif \"exists\" in output:\n                return ExecutionResult(success=True, output=self.main_target)\n            else:\n                logger.error(\"Unexpected output from file existence check.\")\n                return ExecutionResult(success=False, error=\"Unexpected output from file existence check.\")\n\n        except Exception as e:\n            logger.exception(f\"File existence check failed: {str(e)}\")\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def list_files_with_pattern(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if not self.target_pattern or self.sub_target:\n            logger.error(\"Invalid configuration: target_pattern is required and sub_target should be None\")\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            command = self.command_builder.build_directory_listing_command(self.main_target)\n            logger.debug(f\"Executing file listing with command: {command}\")\n            output, error, exit_status = ssh_manager.execute_command_with_sudo(command, self.os_type, use_sudo=True)\n            if output:\n                filtered_files = self._filter_files_with_pattern(output, self.target_pattern)\n                if filtered_files:\n                    logger.debug(f\"Files matching pattern: {filtered_files}\")\n                    return ExecutionResult(success=True, output=json.dumps(filtered_files))\n                return ExecutionResult(success=False, error=\"No files matched the pattern\")\n            return ExecutionResult(success=False, error=\"No output from command\")\n\n        except Exception as e:\n            logger.exception(f\"Listing files with pattern failed: {str(e)}\")\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def _filter_files_with_pattern(self, file_list: str, pattern: str) -> list:\n        try:\n            regex = re.compile(pattern)\n            return [file.strip() for file in file_list.split(\"\\n\") if file.strip() and regex.search(file.strip())]\n        except re.error as e:\n            logger.error(f\"Invalid regex pattern: {str(e)}\")\n            raise ValueError(f\"Invalid regex pattern: {str(e)}\")\n\n    def run_command(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if self.sub_target or self.target_pattern:\n            logger.error(\"Invalid configuration: sub_target or target_pattern provided for command execution\")  # Error log\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            if self.os_type == \"linux\":\n                command = f\"{self.main_target}\"\n            logger.debug(f\"Running command: {command}\")  # Debug log for command execution\n            output, error, exit_status = ssh_manager.execute_command_with_sudo(command, self.os_type, use_sudo=True)\n            output = output.strip() if output else \"\"\n            error = error.strip() if error else \"\"\n\n            error = re.sub(r\"\\[sudo\\] password for .+?: ?\", \"\", error)\n\n            if output and error:\n                combined_output = f\"{output}\\n{error}\"\n                return ExecutionResult(success=True, output=combined_output)\n            elif output:\n                return ExecutionResult(success=True, output=output)\n            elif error:\n                return ExecutionResult(success=True, output=error)\n            else:\n                return ExecutionResult(success=True, output=\"\")\n                # logger.error(\"Command failed with no result\")\n                # return ExecutionResult(success=False, error=\"Command failed with no result\")\n\n        except Exception as e:\n            logger.exception(f\"Command execution failed: {str(e)}\")\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def check_process_existence(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if self.sub_target or self.target_pattern:\n            logger.error(\"Invalid configuration: sub_target or target_pattern provided for process check\")\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            command = self.command_builder.build_process_check_command(self.main_target)\n            logger.debug(f\"Checking process existence with command: {command}\")\n            output, error, exit_status = ssh_manager.execute_command_with_sudo(command, self.os_type, use_sudo=True)\n            if output:\n                return ExecutionResult(success=True, output=self.main_target)\n            return ExecutionResult(success=False, output=self.main_target)\n        except Exception as e:\n            logger.exception(f\"Process existence check failed: {str(e)}\")\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def check_registry_key(self, ssh_manager: SSHManager) -> ExecutionResult:\n        try:\n            if not self.sub_target:\n                command = self.command_builder.build_registry_key_existence_command(self.main_target)\n            else:\n                command = self.command_builder.build_registry_check_command(self.main_target, self.sub_target)\n\n            logger.debug(f\"Checking registry key with command: {command}\")\n            output, error, exit_status = ssh_manager.execute_command_with_sudo(command, self.os_type, use_sudo=True)\n            if output:\n                return ExecutionResult(success=True, output=output.strip())\n            return ExecutionResult(success=False, output=output.strip())\n        except Exception as e:\n            logger.exception(f\"Registry key check failed: {str(e)}\")\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n        \n\nclass ContentCheckResult:\n    def __init__(self, success: bool, error: Optional[str] = None, details: Optional[str] = None):\n        self.success = success\n        self.error = error\n        self.details = details\n\n    def to_dict(self) -> Dict[str, Union[bool, Optional[str]]]:\n        return {\n            \"success\": self.success,\n            \"error\": self.error,\n            \"details\": self.details,\n        }\n\n    def __repr__(self):\n        return f\"ContentCheckResult(success={self.success}, error={self.error}, details={self.details})\"\n\n\nclass ContentRuleChecker:\n    def __init__(\n        self,\n        node_type: str,\n        content_rules: List[Dict],\n        ssh_manager: SSHManager,\n        command_builder: OSCommandBuilder,\n        os_type: str,\n        rule_negation: bool\n    ):\n        self.node_type = node_type\n        self.content_rules = content_rules\n        self.ssh_manager = ssh_manager\n        self.command_builder = command_builder\n        self.os_type = os_type\n        self.rule_negation = rule_negation\n\n    def check(self, content: Union[str, List[str]]) -> ContentCheckResult:\n        try:\n            if self.node_type == 'c':\n                return self.check_command_output(content)\n            elif self.node_type == 'f':\n                return self.check_file_content(content)\n            elif self.node_type in ['d', 'p']:\n                return ContentCheckResult(success=True)\n            else:\n                logger.error(\"Invalid node type: {}\", self.node_type)\n                return ContentCheckResult(success=False, error=ExecutionError.INVALID_NODE_TYPE.value[1])\n        except Exception as e:\n            logger.exception(\"Error in content check: {}\", str(e))\n            return ContentCheckResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def check_command_output(self, content: str) -> ContentCheckResult:\n        try:\n            logger.debug(\"Checking command output\")\n            logger.debug(\"Content to check:\\n{}\", content)\n            return self._check_lines(content.splitlines())\n        except Exception as e:\n            logger.exception(\"Error checking command output: {}\", str(e))\n            return ContentCheckResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def check_file_content(self, content: Union[str, List[str]]) -> ContentCheckResult:\n        try:\n            if isinstance(content, str):\n                content = self._parse_content(content)\n\n            if isinstance(content, list):\n                if not content:\n                    logger.error(\"No files matched the pattern\")\n                    return ContentCheckResult(success=False, error=\"No files matched the pattern.\")\n\n                results = []\n                for file_path in content:\n                    logger.debug(\"Reading and checking file: {}\", file_path)\n                    result = self.read_and_check_file(file_path)\n                    if not result.success:\n                        logger.debug(\"Failed with file: {}. Error: {}\", file_path, result.error)\n                        results.append(False)\n                    else:\n                        results.append(result.success)\n\n                final_result = any(results)\n                return ContentCheckResult(success=final_result)\n\n            else:\n                logger.error(\"Invalid file rule\")\n                return ContentCheckResult(success=False, error=ExecutionError.INVALID_FILE_RULE.value[1])\n\n        except Exception as e:\n            logger.exception(\"Error checking file content: {}\", str(e))\n            return ContentCheckResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def read_and_check_file(self, file_path: str) -> ContentCheckResult:\n        try:\n            logger.debug(\"Reading and checking file: {}\", file_path)\n            command = self.command_builder.build_read_file_command(file_path)\n            \n            output, error, exit_status = self.ssh_manager.execute_command_with_sudo(command, self.os_type, use_sudo=True)\n            if exit_status != 0:\n                logger.error(\"Failed to read file: {}. Error: {}\", file_path, error)\n                return ContentCheckResult(success=False, error=f\"Failed to read file {file_path}: {error}\")\n\n            # If the file is empty\n            if output.strip() == \"\":\n                logger.debug(\"File is empty: {}\", file_path)\n\n                # If no content rules, we can return success immediately\n                if not self.content_rules:\n                    logger.debug(\"No content rules to check. Returning success.\")\n                    return ContentCheckResult(success=True)\n                # If content rules exist, continue checking\n                else:\n                    logger.debug(\"Content rules exist. Proceeding to check rules.\")\n\n            # Continue to check file content if it’s not empty or rules exist\n            logger.debug(\"File content:\\n{}\", output)\n            return self._check_lines(output.splitlines())\n\n        except Exception as e:\n            logger.exception(\"Error reading and checking file: {}\", str(e))\n            return ContentCheckResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def _check_lines(self, lines: List[str]) -> ContentCheckResult:\n        match = False\n    \n        for line in lines:\n            line_match = True\n    \n            for rule in self.content_rules:\n                rule_match = self._does_line_match_rule(line, rule)\n    \n                if rule.get('negation', False):\n                    rule_match = not rule_match\n    \n                if not rule_match:\n                    line_match = False\n                    break\n    \n            if line_match:\n                match = True\n                logger.debug(\"Line matched all rules: {}\", line)\n                break\n    \n        if self.rule_negation:\n            match = not match\n            logger.debug(\"ContentRuleChecker-level negation applied to final match result: {}\", match)\n    \n        return ContentCheckResult(success=match)\n    \n    def _does_line_match_rule(self, line: str, rule: Dict) -> bool:\n        content_operator = rule.get('content_operator')\n        value = rule.get('value')\n    \n        if content_operator == 'r':  # Regex match\n            match = bool(re.search(value, line))\n            logger.debug(\"Checked line: {}, Regex pattern: {}, Match result: {}\", line, value, match)\n        elif content_operator == 'n':  # Numeric comparison\n            match = self.numeric_compare(line, value, rule.get('compare_operator'), rule.get('compare_value'))\n            logger.debug(\"Numeric compare result: {} for value: {}\", match, value)\n        elif content_operator is None:  # Substring match\n            match = value in line\n            logger.debug(\"Substring match result: {} for value: {}\", match, value)\n        else:\n            logger.error(\"Invalid content operator: {}\", content_operator)\n            return False\n    \n        return match\n\n    def numeric_compare(self, content: str, value: str, compare_operator: str, compare_value_str: str) -> bool:\n        try:\n            logger.debug(\"Performing numeric comparison on content: {}\", content)\n            match = re.search(value, content)\n            if not match:\n                logger.debug(\"No numeric match found for value: {}\", value)\n                return False\n\n            number = int(match.group(1))\n            compare_value = int(compare_value_str)\n            logger.debug(\"Extracted number: {}, Compare value: {}\", number, compare_value)\n\n            if compare_operator == '>':\n                return number > compare_value\n            elif compare_operator == '>=':\n                return number >= compare_value\n            elif compare_operator == '<':\n                return number < compare_value\n            elif compare_operator == '<=':\n                return number <= compare_value\n            elif compare_operator == '==':\n                return number == compare_value\n            elif compare_operator == '!=':\n                return number != compare_value\n            else:\n                logger.error(\"Invalid compare operator: {}\", compare_operator)\n                return False\n        except Exception as e:\n            logger.exception(\"Error in numeric comparison: {}\", str(e))\n            raise ValueError(f\"{ExecutionError.INVALID_COMPARE_EXPRESSION.value[1]}: {str(e)}\")\n\n    def _parse_content(self, content: str) -> List[str]:\n        try:\n            content_list = json.loads(content)\n            if isinstance(content_list, list):\n                return content_list\n            else:\n                logger.debug(\"Parsed content is not a list: {}\", content_list)\n                return [content]\n        except json.JSONDecodeError:\n            logger.debug(\"Content is a single file path, not a JSON list: {}\", content)\n            return [content]\n\n\nclass SemanticTreeExecutionResult:\n    def __init__(self, success: bool, results: Optional[Dict[str, Any]] = None, \n                 error: Optional[str] = None, executed_count: int = 0):\n        self.success = success\n        self.results = results if results is not None else {}\n        self.error = error\n        self.executed_count = executed_count\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"success\": self.success,\n            \"results\": self.results,\n            \"error\": self.error,\n            \"executed_count\": self.executed_count\n        }\n\n    def __repr__(self):\n        return f\"SemanticTreeExecutionResult(success={self.success}, results={self.results}, error={self.error}, executed_count={self.executed_count})\"\n\n\nclass SemanticTreeExecutor:\n    def __init__(self, ip: str, username: str, password: str, port: int = 22):\n        self.ssh_manager = SSHManager(ip, username, password, port)\n\n    def connect(self) -> bool:\n        try:\n            self.ssh_manager.connect()\n            logger.info(f\"Connected to {self.ssh_manager.ip}\")\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to connect to {self.ssh_manager.ip}: {str(e)}\")\n            return False\n\n    def execute_tree(self, semantic_tree: Dict) -> SemanticTreeExecutionResult:\n        # Attempt to connect to the SSH server\n        if not self.connect():\n            return SemanticTreeExecutionResult(success=False, error='Failed to connect to SSH')\n\n        results = {}\n        checks = semantic_tree.get('checks', [])\n        # Default to 'linux' if not provided\n        os_type = semantic_tree.get('os_type', 'linux')\n\n        successful_check_count = 0\n\n        for check in checks:\n            check_id = check['id']\n            condition = check['condition']\n\n            logger.info(\"##########################################################\")\n            logger.info(f\"##### Executing check ID: {check_id} with condition: {condition} #####\")\n            logger.info(\"##########################################################\")\n\n            rule_results = self._execute_rules(check['rules'], os_type)\n            if isinstance(rule_results, SemanticTreeExecutionResult):\n                # If an error occurred during rule execution, return it immediately\n                self.ssh_manager.close()\n                return rule_results\n\n            # Print all rule results for this check ID\n            logger.debug(f\"Rule results for check ID {check_id}: {rule_results}\")\n\n            # Determine the final check result based on the condition\n            check_pass = self._evaluate_condition(condition, rule_results)\n            if check_pass is None:\n                self.ssh_manager.close()\n                logger.error(f\"Invalid condition specified at check ID {check_id}\")\n                return SemanticTreeExecutionResult(\n                    success=False,\n                    error=f\"Invalid condition specified at check ID {check_id}\"\n                )\n\n            if check_pass:\n                successful_check_count += 1\n\n            # Store the check result with rule details and condition\n            results[check_id] = {\n                'result': 'pass' if check_pass else 'fail',\n                'condition': condition,\n                'rule_results': rule_results\n            }\n\n            logger.info(f\"Check ID: {check_id} result: {results[check_id]['result']}\")  # Log check result\n\n        # Close the SSH connection after all checks\n        self.ssh_manager.close()\n        return SemanticTreeExecutionResult(success=True, results=results, executed_count=successful_check_count)\n\n    def _execute_rules(self, rules: List[Dict], os_type: str) -> Union[List[bool], SemanticTreeExecutionResult]:\n        rule_results = []\n\n        for rule in rules:\n            exec_node = rule['execution_node']\n            rule_negation = rule.get('negation', False)  # Fetch negation flag once\n\n            logger.info(f\"Executing rule with execution node: {exec_node}\")  # Log rule execution\n\n            # Execute node and check for success\n            execution_result = self._execute_node(exec_node, os_type)\n\n            if not execution_result.success:\n                if execution_result.error:  # If an error exists, print it\n                    logger.error(f\"Execution failed for rule {exec_node}: {execution_result.error}\")\n                \n                # Always append negation if execution fails, regardless of the error\n                rule_results.append(not execution_result.success if rule_negation else execution_result.success)\n                continue\n\n            if exec_node['type'] == 'd':\n                # Process directory node\n                file_rules = rule.get('file_rules', [])\n                if file_rules:\n                    # Pass negation into _process_file_rules\n                    file_rule_results = self._process_file_rules(file_rules, execution_result.output, os_type, rule_negation)\n                    if isinstance(file_rule_results, SemanticTreeExecutionResult):\n                        return file_rule_results\n\n                    # Apply negation if necessary and extend rule results\n                    rule_results.extend(file_rule_results)\n                else:\n                    # Handle directory existence check\n                    rule_results.append(execution_result.success)\n            else:\n                # Pass negation into _check_content_rules\n                content_check_result = self._check_content_rules(rule, execution_result.output, os_type, rule_negation)\n                if isinstance(content_check_result, SemanticTreeExecutionResult):\n                    return content_check_result\n\n                rule_results.append(content_check_result)\n\n        return rule_results\n\n    def _execute_node(self, exec_node: Dict, os_type: str) -> ExecutionResult:\n        executor = ExecutionNodeExecutor(\n            node_type=exec_node['type'],\n            main_target=exec_node['main_target'],\n            sub_target=exec_node.get('sub_target'),\n            target_pattern=exec_node.get('target_pattern'),\n            os_type=os_type,\n        )\n        execution_result = executor.execute(self.ssh_manager)\n        logger.debug(f\"Execution result: {execution_result.to_dict()}\")\n        return execution_result\n\n    def _process_file_rules(self, file_rules: List[Dict], directory_output: str, os_type: str, negation: bool) -> Union[List[bool], SemanticTreeExecutionResult]:\n        file_rule_results = []\n        for file_rule in file_rules:\n            exec_node = file_rule['execution_node']\n\n            execution_result = self._execute_node(exec_node, os_type)\n            if not execution_result.success:\n                logger.error(f\"Execution failed for file rule {exec_node}: {execution_result.error}\")\n                file_rule_results.append(False)\n                continue\n\n            # Pass negation into _check_content_rules\n            content_check_result = self._check_content_rules(file_rule, execution_result.output, os_type, negation)\n            if isinstance(content_check_result, SemanticTreeExecutionResult):\n                return content_check_result\n            file_rule_results.append(content_check_result)\n\n        return file_rule_results\n\n    def _check_content_rules(self, rule: Dict, exec_output: str, os_type: str, rule_negation: bool) -> Union[bool, SemanticTreeExecutionResult]:\n        try:\n            # Initialize ContentRuleChecker with negation flag\n            checker = ContentRuleChecker(\n                node_type=rule['execution_node']['type'],\n                content_rules=rule.get('content_rules', []),\n                ssh_manager=self.ssh_manager,\n                command_builder=OSCommandBuilder(os_type),\n                os_type=os_type,\n                rule_negation=rule_negation\n            )\n\n            content_result = checker.check(exec_output)\n            logger.debug(f\"Content result: {content_result.to_dict()}\")\n\n            if not content_result.success:\n                logger.error(f\"Content check failed for rule {rule['execution_node']}: {content_result.error}\")\n                return False\n            else:\n                return True\n\n        except Exception as e:\n            logger.exception(f\"Error during content check: {str(e)}\")\n            return SemanticTreeExecutionResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def _evaluate_condition(self, condition: str, rule_results: List[bool]) -> Optional[bool]:\n        if condition == 'all':\n            return all(rule_results)\n        elif condition == 'any':\n            return any(rule_results)\n        elif condition == 'none':\n            return not any(rule_results)\n        else:\n            logger.error(f\"Invalid condition: {condition}\")\n            return None"}
{"type": "source_file", "path": "core/src/script_validator.py", "content": "\"\"\"\n===============================================================================\n    Module Name: Script Validator\n    Description:  This module defines the `ScriptValidator` class, responsible \n                  for validating the structure and content of YAML files \n                  according to specific rules. It checks for required fields \n                  and validates the types and formats of the content, ensuring \n                  that the YAML conforms to expected standards. The module \n                  also handles error reporting with detailed messages and error \n                  codes.\n\n    Author:       Jerry Hung\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-08-08\n    Last Updated: 2024-08-08\n    Version:      1.0.1\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        The `ScriptValidator` class should be instantiated, and the \n                  `validate_file` method should be used to validate YAML file \n                  content. Errors encountered during validation are raised as \n                  `ValidationError` exceptions with structured error details.\n\n    Requirements: Python 3.10.12\n                  \n    Notes:        This module is part of the Script Validation and Processing \n                  system, version 1.0.0.\n===============================================================================\n\"\"\"\n\nimport yaml\nfrom enum import Enum\nfrom loguru import logger\n\n\nclass ScriptValidationError(Enum):\n    MISSING_TOP_LEVEL_FIELD = (\"V001\", \"Missing required top-level field\")\n    EMPTY_CHECKS = (\"V002\", \"'checks' section is empty or missing\")\n    INVALID_CHECKS_TYPE = (\"V003\", \"'checks' should be a list\")\n    MISSING_SCRIPT_FIELD = (\"V004\", \"Missing required field in script\")\n    EMPTY_SCRIPT_FIELD = (\"V005\", \"Field cannot be empty in script\")\n    INVALID_RULES_TYPE = (\"V006\", \"'rules' should be a list in script\")\n    INVALID_COMPLIANCE_TYPE = (\"V007\", \"'compliance' should be a list in script\")\n    INVALID_COMPLIANCE_ENTRY = (\"V008\", \"Each compliance entry should be a dictionary\")\n    INVALID_COMPLIANCE_VALUE = (\"V009\", \"The compliance value should be a list\")\n\n\nclass ValidationError(Exception):\n    def __init__(self, errors):\n        self.errors = errors\n        super().__init__(\"Validation error occurred\")\n\n    def __str__(self):\n        return f\"ValidationError: {self.errors}\"\n\n\nclass ScriptValidator:\n    def __init__(self):\n        self.errors = []\n\n    def validate_file(self, file_content: str) -> dict:\n        try:\n            logger.info(\"Starting validation for YAML file content.\")\n            data = yaml.safe_load(file_content)\n            self.validate_structure(data)\n            self.validate_checks(data.get('checks'))\n            if self.errors:\n                logger.error(\"Validation failed with errors: {}\", self.errors)\n                raise ValidationError(self.errors)\n            logger.info(\"Validation passed successfully.\")\n            return data\n        except yaml.YAMLError as e:\n            logger.error(\"YAML format error: {}\", str(e))\n            raise ValidationError([{\"code\": \"YAML_ERROR\", \"message\": f\"Invalid YAML format: {str(e)}\"}])\n\n    def validate_structure(self, data: dict):\n        logger.debug(\"Validating YAML structure.\")\n        required_fields = ['checks']\n        for field in required_fields:\n            if field not in data:\n                self.add_error(ScriptValidationError.MISSING_TOP_LEVEL_FIELD, field)\n        if not data.get('checks'):\n            self.add_error(ScriptValidationError.EMPTY_CHECKS)\n\n    def validate_checks(self, checks: list):\n        if not isinstance(checks, list):\n            logger.error(\"Checks validation failed: 'checks' should be a list.\")\n            self.add_error(ScriptValidationError.INVALID_CHECKS_TYPE)\n            return\n\n        logger.debug(\"Validating individual checks.\")\n        for check in checks:\n            self.validate_script(check)\n\n    def validate_script(self, script: dict):\n        logger.debug(\"Validating script with ID: {}\", script.get('id', 'unknown'))\n        required_fields = ['id', 'title', 'description', 'rationale', 'remediation', 'condition', 'rules']\n        for field in required_fields:\n            if field not in script:\n                self.add_error(ScriptValidationError.MISSING_SCRIPT_FIELD, field, script.get('id', 'unknown'))\n            elif not script.get(field):\n                self.add_error(ScriptValidationError.EMPTY_SCRIPT_FIELD, field, script.get('id', 'unknown'))\n\n        if 'rules' in script and not isinstance(script['rules'], list):\n            self.add_error(ScriptValidationError.INVALID_RULES_TYPE, script.get('id', 'unknown'))\n\n        if 'compliance' in script:\n            self.validate_compliance(script['compliance'], script.get('id', 'unknown'))\n\n    def validate_compliance(self, compliance: list, script_id: str):\n        if not isinstance(compliance, list):\n            self.add_error(ScriptValidationError.INVALID_COMPLIANCE_TYPE, script_id)\n            return\n\n        logger.debug(\"Validating compliance entries for script ID: {}\", script_id)\n        for item in compliance:\n            if not isinstance(item, dict):\n                self.add_error(ScriptValidationError.INVALID_COMPLIANCE_ENTRY, script_id)\n                continue\n\n            for key, value in item.items():\n                if not isinstance(value, list):\n                    self.add_error(ScriptValidationError.INVALID_COMPLIANCE_VALUE, script_id, key)\n\n    def add_error(self, error_type: ScriptValidationError, *args):\n        error = {\n            \"code\": error_type.value[0],\n            \"message\": error_type.value[1],\n        }\n        if args:\n            error.update({\"details\": args})\n        logger.error(\"Validation error: {}\", error)\n        self.errors.append(error)\n\n    def get_errors(self):\n        return self.errors\n"}
{"type": "source_file", "path": "demo/backend/script_validator.py", "content": "\"\"\"\n===============================================================================\n    Module Name: Script Validator\n    Description:  This module defines the `ScriptValidator` class, responsible \n                  for validating the structure and content of YAML files \n                  according to specific rules. It checks for required fields \n                  and validates the types and formats of the content, ensuring \n                  that the YAML conforms to expected standards. The module \n                  also handles error reporting with detailed messages and error \n                  codes.\n\n    Author:       Jerry Hung\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-08-08\n    Version:      1.0.0\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        The `ScriptValidator` class should be instantiated, and the \n                  `validate_file` method should be used to validate YAML file \n                  content. Errors encountered during validation are raised as \n                  `ValidationError` exceptions with structured error details.\n\n    Requirements: Python 3.10.12\n                  \n    Notes:        This module is part of the Script Validation and Processing \n                  system, version 1.0.0.\n===============================================================================\n\"\"\"\n\nimport yaml\nfrom enum import Enum\n\nclass ScriptValidationError(Enum):\n    MISSING_TOP_LEVEL_FIELD = (\"V001\", \"Missing required top-level field\")\n    EMPTY_CHECKS = (\"V002\", \"'checks' section is empty or missing\")\n    INVALID_CHECKS_TYPE = (\"V003\", \"'checks' should be a list\")\n    MISSING_SCRIPT_FIELD = (\"V004\", \"Missing required field in script\")\n    EMPTY_SCRIPT_FIELD = (\"V005\", \"Field cannot be empty in script\")\n    INVALID_RULES_TYPE = (\"V006\", \"'rules' should be a list in script\")\n    INVALID_COMPLIANCE_TYPE = (\"V007\", \"'compliance' should be a list in script\")\n    INVALID_COMPLIANCE_ENTRY = (\"V008\", \"Each compliance entry should be a dictionary\")\n    INVALID_COMPLIANCE_VALUE = (\"V009\", \"The compliance value should be a list\")\n\nclass ValidationError(Exception):\n    def __init__(self, errors):\n        self.errors = errors\n        super().__init__(\"Validation error occurred\")\n\n    def __str__(self):\n        return f\"ValidationError: {self.errors}\"\n\nclass ScriptValidator:\n    def __init__(self):\n        self.errors = []\n\n    def validate_file(self, file_content: str) -> dict:\n        try:\n            data = yaml.safe_load(file_content)\n            self.validate_structure(data)\n            self.validate_checks(data.get('checks'))\n            if self.errors:\n                raise ValidationError(self.errors)\n            return data\n        except yaml.YAMLError as e:\n            raise ValidationError([{\"code\": \"YAML_ERROR\", \"message\": f\"Invalid YAML format: {str(e)}\"}])\n\n    def validate_structure(self, data: dict):\n        required_fields = ['checks']\n        for field in required_fields:\n            if field not in data:\n                self.add_error(ScriptValidationError.MISSING_TOP_LEVEL_FIELD, field)\n        if not data.get('checks'):\n            self.add_error(ScriptValidationError.EMPTY_CHECKS)\n\n    def validate_checks(self, checks: list):\n        if not isinstance(checks, list):\n            self.add_error(ScriptValidationError.INVALID_CHECKS_TYPE)\n            return\n\n        for check in checks:\n            self.validate_script(check)\n\n    def validate_script(self, script: dict):\n        required_fields = ['id', 'title', 'description', 'rationale', 'remediation', 'condition', 'rules']\n        for field in required_fields:\n            if field not in script:\n                self.add_error(ScriptValidationError.MISSING_SCRIPT_FIELD, field, script.get('id', 'unknown'))\n            elif not script.get(field):\n                self.add_error(ScriptValidationError.EMPTY_SCRIPT_FIELD, field, script.get('id', 'unknown'))\n\n        if 'rules' in script and not isinstance(script['rules'], list):\n            self.add_error(ScriptValidationError.INVALID_RULES_TYPE, script.get('id', 'unknown'))\n\n        if 'compliance' in script:\n            self.validate_compliance(script['compliance'], script.get('id', 'unknown'))\n\n    def validate_compliance(self, compliance: list, script_id: str):\n        if not isinstance(compliance, list):\n            self.add_error(ScriptValidationError.INVALID_COMPLIANCE_TYPE, script_id)\n            return\n\n        for item in compliance:\n            if not isinstance(item, dict):\n                self.add_error(ScriptValidationError.INVALID_COMPLIANCE_ENTRY, script_id)\n                continue\n\n            for key, value in item.items():\n                if not isinstance(value, list):\n                    self.add_error(ScriptValidationError.INVALID_COMPLIANCE_VALUE, script_id, key)\n\n    def add_error(self, error_type: ScriptValidationError, *args):\n        error = {\n            \"code\": error_type.value[0],\n            \"message\": error_type.value[1],\n        }\n        if args:\n            error.update({\"details\": args})\n        self.errors.append(error)\n\n    def get_errors(self):\n        return self.errors\n"}
{"type": "source_file", "path": "core/src/script_processor.py", "content": "\"\"\"\n===============================================================================\n    Module Name: Script Processor\n    Description:  This module provides the ScriptProcessor class, which handles \n                  the end-to-end processing of YAML files. The processing \n                  involves validating the file using the ScriptValidator and \n                  building a semantic tree with the SemanticTreeBuilder. The \n                  module is designed to capture and handle errors at each step \n                  and return structured error messages or a semantic tree in \n                  JSON format.\n\n    Author:       Jerry Hung\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-08-08\n    Last Updated: 2024-09-02\n    Version:      1.0.2\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        Instantiate the `ScriptProcessor` class and call the `process`\n                  method with the YAML file content as a string to validate the \n                  file and build the semantic tree. The output will be either a \n                  JSON string of the tree or a structured error message.\n\n    Requirements: Python 3.10.12\n                  \n    Notes:        This module is part of the Script Validation and Processing \n                  system, version 1.0.0.\n===============================================================================\n\"\"\"\n\nimport json\nfrom typing import Union, Dict, List\nfrom enum import Enum\nfrom loguru import logger  # 添加 loguru\n\nfrom .script_validator import ScriptValidator, ValidationError\nfrom .semantic_tree_builder import SemanticTreeBuilder\nfrom .semantic_tree_executor import SemanticTreeExecutor\n\n\nclass ScriptProcessorError(Enum):\n    FILE_VALIDATION_FAILED = (\"P001\", \"File validation failed\")\n    TREE_BUILDING_FAILED = (\"P002\", \"Tree building failed\")\n    EXECUTION_FAILED = (\"P003\", \"Execution failed\")\n    UNKNOWN_ERROR = (\"P004\", \"Unknown error\")\n\n\nclass ScriptProcessor:\n    def __init__(self):\n        self.validator = ScriptValidator()\n        self.tree_builder = SemanticTreeBuilder()\n\n    def process_yml(self, file_content: str) -> Union[str, Dict[str, Union[str, List[Dict[str, Union[str, int]]]]]]:\n        try:\n            logger.info(\"Validating YAML file content.\")\n            # Step 1: Validate the YAML file :)\n            script_data = self.validator.validate_file(file_content)\n            \n            # Step 2: Build the semantic tree for each check in the script :)\n            checks = []\n            for check in script_data['checks']:\n                logger.debug(f\"Building tree for check ID: {check['id']}\")\n                tree = self.tree_builder.build_tree({\n                    'id': check['id'],\n                    'condition': check['condition'],\n                    'rules': check['rules']\n                })\n                \n                # Step 3: Check for errors during tree building :)\n                if tree is None:\n                    errors = self.tree_builder.get_errors()\n                    logger.error(\"Tree building failed. Errors: {}\", errors)\n                    return {\n                        \"status\": \"error\",\n                        \"error_code\": ScriptProcessorError.TREE_BUILDING_FAILED.value[0],\n                        \"error_message\": ScriptProcessorError.TREE_BUILDING_FAILED.value[1],\n                        \"details\": errors\n                    }\n                checks.append(json.loads(self.tree_builder.tree_to_json(tree)))\n            \n            # Step 4: Return the JSON string of the tree if all checks passed :)\n            result = {\"checks\": checks}\n            logger.info(\"Semantic tree built successfully.\")\n            return json.dumps(result, separators=(',', ':'))\n        \n        except ValidationError as sve:\n            logger.error(\"Validation failed. Errors: {}\", sve.errors)\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.FILE_VALIDATION_FAILED.value[0],\n                \"error_message\": ScriptProcessorError.FILE_VALIDATION_FAILED.value[1],\n                \"details\": sve.errors\n            }\n        \n        except Exception as e:\n            logger.error(\"An unexpected error occurred: {}\", str(e))\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.UNKNOWN_ERROR.value[0],\n                \"error_message\": ScriptProcessorError.UNKNOWN_ERROR.value[1],\n                \"details\": str(e)\n            }\n        \n    def process_json(self, script_list: List[Dict[str, Union[str, List[str]]]]) -> Union[str, Dict[str, Union[str, List[Dict[str, Union[str, int]]]]]]:\n        try:\n            logger.info(\"Processing JSON script list.\")\n            \n            # Step 1: Validate the script list :)\n            # self.validator.validate_json(script_list) # TODO: Implement JSON validation\n            \n            # Step 2: Build the semantic tree for each script in the script list :)\n            checks = []\n            for script in script_list:\n                logger.debug(f\"Building tree for script ID: {script['script_id']}\")\n                tree = self.tree_builder.build_tree({\n                    'id': script['script_id'],\n                    'condition': script.get('condition', ''),\n                    'rules': script.get('rules', [])\n                })\n                \n                # Step 3: Check for errors during tree building :)\n                if tree is None:\n                    errors = self.tree_builder.get_errors()\n                    logger.error(\"Tree building failed. Errors: {}\", errors)\n                    return {\n                        \"status\": \"error\",\n                        \"error_code\": ScriptProcessorError.TREE_BUILDING_FAILED.value[0],\n                        \"error_message\": ScriptProcessorError.TREE_BUILDING_FAILED.value[1],\n                        \"details\": errors\n                    }\n                checks.append(json.loads(self.tree_builder.tree_to_json(tree)))\n            \n            # Step 4: Return the JSON string of the tree if all checks passed :)\n            result = {\"checks\": checks}\n            logger.info(\"Semantic tree built successfully.\")\n            return json.dumps(result, separators=(',', ':'))\n        \n        except json.JSONDecodeError as je:\n            logger.error(\"JSON decoding failed. Errors: {}\", str(je))\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.FILE_VALIDATION_FAILED.value[0],\n                \"error_message\": \"JSON decoding failed\",\n                \"details\": str(je)\n            }\n        \n        except ValidationError as sve:\n            logger.error(\"Validation failed. Errors: {}\", sve.errors)\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.FILE_VALIDATION_FAILED.value[0],\n                \"error_message\": ScriptProcessorError.FILE_VALIDATION_FAILED.value[1],\n                \"details\": sve.errors\n            }\n        \n        except Exception as e:\n            logger.error(\"An unexpected error occurred: {}\", str(e))\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.UNKNOWN_ERROR.value[0],\n                \"error_message\": ScriptProcessorError.UNKNOWN_ERROR.value[1],\n                \"details\": str(e)\n            }\n\n    def executor(self, tree_json: str, ssh_details: Dict[str, Union[str, int]]) -> Dict[str, Union[str, Dict]]:\n        try:\n            logger.info(\"Executing semantic tree.\")\n            # Step 1: Convert JSON string to a Python dictionary for execution :)\n            semantic_tree = json.loads(tree_json)\n\n            # Step 2: Initialize the SemanticTreeExecutor with SSH details :)\n            executor = SemanticTreeExecutor(\n                ip=ssh_details['ip'],\n                username=ssh_details['username'],\n                password=ssh_details['password'],\n                port=ssh_details.get('port', 22)\n            )\n\n            # Step 3: Execute the semantic tree :)\n            execution_result = executor.execute_tree(semantic_tree)\n\n            # Step 4: Check for success or handle errors in execution :)\n            if not execution_result.success:\n                logger.error(\"Execution failed. Results: {}\", execution_result.results)\n                return {\n                    \"status\": \"error\",\n                    \"executed_count\": execution_result.executed_count,\n                    \"error_code\": ScriptProcessorError.EXECUTION_FAILED.value[0],\n                    \"error_message\": execution_result.error or ScriptProcessorError.EXECUTION_FAILED.value[1],\n                    \"details\": execution_result.results\n                }\n\n            # Step 5: Return the successful execution results :)\n            logger.info(\"Execution completed successfully.\")\n            return {\n                \"status\": \"success\",\n                \"executed_count\": execution_result.executed_count,\n                \"results\": execution_result.results\n            }\n\n        except Exception as e:\n            logger.error(\"An unexpected error occurred: {}\", str(e))\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.UNKNOWN_ERROR.value[0],\n                \"error_message\": ScriptProcessorError.UNKNOWN_ERROR.value[1],\n                \"details\": str(e)\n            }\n"}
{"type": "source_file", "path": "demo/backend/script_processor.py", "content": "\"\"\"\n===============================================================================\n    Module Name: Script Processor\n    Description:  This module provides the ScriptProcessor class, which handles \n                  the end-to-end processing of YAML files. The processing \n                  involves validating the file using the ScriptValidator and \n                  building a semantic tree with the SemanticTreeBuilder. The \n                  module is designed to capture and handle errors at each step \n                  and return structured error messages or a semantic tree in \n                  JSON format.\n\n    Author:       Jerry Hung\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-08-08\n    Version:      1.0.0\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        Instantiate the `ScriptProcessor` class and call the `process`\n                  method with the YAML file content as a string to validate the \n                  file and build the semantic tree. The output will be either a \n                  JSON string of the tree or a structured error message.\n\n    Requirements: Python 3.10.12\n                  \n    Notes:        This module is part of the Script Validation and Processing \n                  system, version 1.0.0.\n===============================================================================\n\"\"\"\n\nimport json\nfrom typing import Union, Dict, List\nfrom enum import Enum\n\nfrom script_validator import ScriptValidator, ValidationError\nfrom semantic_tree_builder import SemanticTreeBuilder, SemanticTreeError\n\nclass ScriptProcessorError(Enum):\n    FILE_VALIDATION_FAILED = (\"P001\", \"File validation failed\")\n    TREE_BUILDING_FAILED = (\"P002\", \"Tree building failed\")\n    UNKNOWN_ERROR = (\"P003\", \"Unknown error\")\n\nclass ScriptProcessor:\n    def __init__(self):\n        self.validator = ScriptValidator()\n        self.tree_builder = SemanticTreeBuilder()\n\n    def process(self, file_content: str) -> Union[str, Dict[str, Union[str, List[Dict[str, Union[str, int]]]]]]:\n        try:\n            # Step 1: Validate the YAML file\n            script_data = self.validator.validate_file(file_content)\n            \n            # Step 2: Build the semantic tree for each check in the script\n            results = []\n            for check in script_data['checks']:\n                tree = self.tree_builder.build_tree({\n                    'id': check['id'],\n                    'condition': check['condition'],\n                    'rules': check['rules']\n                })\n                \n                # Step 3: Check for errors during tree building\n                if tree is None:\n                    errors = self.tree_builder.get_errors()\n                    return {\n                        \"status\": \"error\",\n                        \"error_code\": ScriptProcessorError.TREE_BUILDING_FAILED.value[0],\n                        \"error_message\": ScriptProcessorError.TREE_BUILDING_FAILED.value[1],\n                        \"details\": errors\n                    }\n                results.append(self.tree_builder.tree_to_json(tree))\n            \n            # Step 4: Return the JSON string of the tree if all checks passed\n            return json.dumps(results, separators=(',', ':'))\n        \n        except ValidationError as sve:\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.FILE_VALIDATION_FAILED.value[0],\n                \"error_message\": ScriptProcessorError.FILE_VALIDATION_FAILED.value[1],\n                \"details\": sve.errors\n            }\n        \n        except Exception as e:\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.UNKNOWN_ERROR.value[0],\n                \"error_message\": ScriptProcessorError.UNKNOWN_ERROR.value[1],\n                \"details\": str(e)\n            }\n"}
{"type": "source_file", "path": "demo/backend/semantic_tree_builder.py", "content": "\"\"\"\n===============================================================================\n    Module Name: Semantic Tree Builder\n    Description:  This script is designed to parse and build a semantic tree \n                  structure from a set of rules. It supports various types of \n                  rules, including file rules, directory rules, command rules, \n                  process rules, and registry rules. The script also validates \n                  the rules and handles errors related to invalid syntax or \n                  conditions.\n\n    Author:       Jerry Hung, Bolt Lin\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-07-10\n    Last Updated: 2024-08-08\n    Version:      1.0.0\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n                  \n                  You may use this software solely for internal business \n                  purposes within iiicsti. You may not distribute, \n                  sublicense, or resell this software or its modifications in \n                  any form.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n    \n    Usage:        The main class `SemanticTreeBuilder` can be instantiated and \n                  used to parse rules and build a semantic tree. The tree can \n                  then be converted to JSON format or used for further processing.\n\n    Requirements: Python 3.10.12\n                   \n    Notes:        None\n===============================================================================\n\"\"\"\n\nimport json\nfrom typing import List, Dict, Optional, Union, Tuple\nfrom enum import Enum\nimport re\n\nclass SemanticTreeError(Enum):\n    INVALID_ID = (\"E001\", \"Invalid id\")\n    INVALID_CONDITION = (\"E002\", \"Invalid condition\")\n    UNKNOWN_RULE_TYPE = (\"E003\", \"Unknown rule type\")\n    INVALID_FILE_RULE = (\"E004\", \"Invalid file rule\")\n    INVALID_DIRECTORY_RULE = (\"E005\", \"Invalid directory rule\")\n    INVALID_COMMAND_RULE = (\"E006\", \"Invalid command rule\")\n    INVALID_PROCESS_RULE = (\"E007\", \"Invalid process rule\")\n    INVALID_REGISTRY_RULE = (\"E008\", \"Invalid registry rule\")\n    INVALID_CONTENT_OPERATOR = (\"E009\", \"Invalid content operator\")\n    INVALID_COMPARE_EXPRESSION = (\"E010\", \"Invalid compare expression\")\n    UNKNOWN_ERROR = (\"E011\", \"Unknown error\")\n\nclass ExecutionNode:\n    def __init__(self, type: str, main_target: str, sub_target: str = None, target_pattern: str = None):\n        self.type = type                        # Type of the execution node (e.g., 'f' for file, 'd' for directory, 'r' for registry)\n        self.main_target = main_target          # Main target path or command\n        self.sub_target = sub_target            # Sub target, such as registry key value\n        self.target_pattern = target_pattern    # Pattern used to match the target, if any\n\n    def to_dict(self):\n        return {\n            \"type\": self.type,\n            \"main_target\": self.main_target,\n            \"sub_target\": self.sub_target,\n            \"target_pattern\": self.target_pattern\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\nclass ContentRule:\n    def __init__(self, content_operator: str, value: str, compare_operator: str = None, compare_value: str = None, negation: bool = False):\n        self.content_operator = content_operator    # Operator used for content matching (e.g., 'r' for regex)\n        self.value = value                          # Value to match\n        self.compare_operator = compare_operator    # Operator used for comparison (e.g., '<=', '>=')\n        self.compare_value = compare_value          # Value to compare against\n        self.negation = negation                    # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"content_operator\": self.content_operator,\n            \"value\": self.value,\n            \"compare_operator\": self.compare_operator,\n            \"compare_value\": self.compare_value,\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\nclass FileRule:\n    def __init__(self, execution_node: ExecutionNode, content_rules: List[ContentRule] = None, negation: bool = False):\n        self.execution_node = execution_node                        # Single ExecutionNode for the file\n        self.content_rules = content_rules if content_rules else [] # List of ContentRules applied to the file\n        self.negation = negation                                    # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),                    # Adjusted to use a single execution node\n            \"content_rules\": [rule.to_dict() for rule in self.content_rules],   # Corrected key from 'content_rule' to 'content_rules'\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\nclass DirectoryRule:\n    def __init__(self, execution_node: ExecutionNode, file_rules: List[FileRule] = None, negation: bool = False):\n        self.execution_node = execution_node                # ExecutionNode for the directory\n        self.file_rules = file_rules if file_rules else []  # List of FileRules applied to the directory\n        self.negation = negation                            # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),\n            \"file_rules\": [rule.to_dict() for rule in self.file_rules],\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\nclass CommandRule:\n    def __init__(self, execution_node: ExecutionNode, content_rules: List[ContentRule] = None, negation: bool = False):\n        self.execution_node = execution_node                        # ExecutionNode for the command\n        self.content_rules = content_rules if content_rules else [] # List of ContentRules applied to the command output\n        self.negation = negation                                    # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),\n            \"content_rules\": [rule.to_dict() for rule in self.content_rules],\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\nclass ProcessRule:\n    def __init__(self, execution_node: ExecutionNode, negation: bool = False):\n        self.execution_node = execution_node    # ExecutionNode for the process\n        self.negation = negation                # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\nclass RegistryRule:\n    def __init__(self, execution_node: ExecutionNode, content_rules: List[ContentRule] = None, negation: bool = False):\n        self.execution_node = execution_node                        # ExecutionNode for the registry key\n        self.content_rules = content_rules if content_rules else [] # List of ContentRules applied to the registry key\n        self.negation = negation                                    # Boolean indicating if the rule is negated\n\n    def to_dict(self):\n        return {\n            \"execution_node\": self.execution_node.to_dict(),\n            \"content_rules\": [rule.to_dict() for rule in self.content_rules],\n            \"negation\": self.negation\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\nclass ConditionNode:\n    def __init__(self, id: str, condition: str, rules: List):\n        self.id = id                # the script id\n        self.condition = condition  # Condition type ('all', 'any', 'none')\n        self.rules = rules          # List of rules or ConditionNodes\n\n    def to_dict(self):\n        return {\n            \"id\": self.id,\n            \"condition\": self.condition,\n            \"rules\": [rule.to_dict() for rule in self.rules]\n        }\n\n    def __str__(self):\n        return json.dumps(self.to_dict(), indent=2)\n\nclass SemanticTreeBuilder:\n    def __init__(self):\n        self.errors = []\n\n    def add_error(self, error_code: SemanticTreeError, detail: str, id: int, rule_number: int):\n        self.errors.append({\n            \"code\": error_code.value[0],\n            \"message\": error_code.value[1],\n            \"detail\": detail,\n            \"id\": id,\n            \"rule_number\": rule_number\n        })\n\n    def parse_rule(self, rule: str, id: int, index: int) -> Union[FileRule, DirectoryRule, CommandRule, ProcessRule, RegistryRule, None]:\n        try:\n            # Check for negation\n            negation = rule.startswith('not ')\n            if negation:\n                rule = rule[4:]\n\n            # Identify the type of rule and parse accordingly\n            if rule.startswith('f:'):\n                return self.parse_file_rule(rule[2:], negation, id, index)\n            elif rule.startswith('d:'):\n                return self.parse_directory_rule(rule[2:], negation, id, index)\n            elif rule.startswith('c:'):\n                return self.parse_command_rule(rule[2:], negation, id, index)\n            elif rule.startswith('p:'):\n                return self.parse_process_rule(rule[2:], negation, id, index)\n            elif rule.startswith('r:'):\n                return self.parse_registry_rule(rule[2:], negation, id, index)\n            else:\n                self.add_error(SemanticTreeError.UNKNOWN_RULE_TYPE, rule, id, index)\n                return None\n        except Exception as e:\n            self.add_error(SemanticTreeError.UNKNOWN_ERROR, str(e), id, index)\n            return None\n\n    def parse_file_rule(self, rule: str, negation: bool, id: int, index: int) -> Optional[FileRule]:\n        # Split on '->', accounting for rules without content checks\n        parts = rule.split(' -> ')\n\n        # Check the basic format\n        if len(parts) == 0 or len(parts) > 2 or not parts[0].strip():\n            self.add_error(SemanticTreeError.INVALID_FILE_RULE, f\"Invalid rule format: {rule}\", id, index)\n            print(f\"Error: Invalid rule format: {rule}\")\n            return None\n        \n        file_rules = []\n\n        # Split multiple files targets\n        file_targets = parts[0].split(',')\n\n        for file in file_targets:\n            file = file.strip()\n            if not file:\n                continue\n\n            execution_node = ExecutionNode(type='f', main_target=file)\n            content_rules = []\n\n            # Handle content rules if '->' is present\n            if len(parts) == 2:\n                content_rules = self.parse_content_rule(parts[1], \"file\", id, index)\n                if content_rules is None:\n                    self.add_error(SemanticTreeError.INVALID_FILE_RULE, f\"Failed to parse content rules: {parts[1]}\", id, index)\n                    print(f\"Error: Failed to parse content rules: {parts[1]}\")\n                    return None\n\n            # Create and add the FileRule with execution nodes and content rules\n            file_rule = FileRule(execution_node=execution_node, content_rules=content_rules, negation=negation)\n            file_rules.append(file_rule)\n\n        return file_rules\n\n    def parse_directory_rule(self, rule: str, negation: bool, id: int, index: int) -> Optional[List[DirectoryRule]]:\n        # Split the rule into parts by '->', handling potential content checks\n        parts = rule.split(' -> ')\n\n        # Check the basic format\n        if len(parts) == 0 or not parts[0].strip():\n            self.add_error(SemanticTreeError.INVALID_DIRECTORY_RULE, f\"Invalid rule format: {rule}\", id, index)\n            print(f\"Error: Invalid rule format: {rule}\")\n            return None\n\n        # Initialize the list for directory rules\n        directory_rules = []\n\n        # Split multiple directory targets\n        directory_targets = parts[0].split(',')\n\n        for directory in directory_targets:\n            directory = directory.strip()\n            if not directory:\n                continue\n\n            # Create execution node for each directory\n            execution_node_d = ExecutionNode(type='d', main_target=directory)\n\n            # Initialize file rules to empty list\n            file_rules = []\n\n            # Handle file rules if '->' is present\n            if len(parts) > 1:\n                file_rule_part = parts[1].strip()\n\n                # Check for negation\n                negation_f = file_rule_part.startswith('!')\n                if negation_f:\n                    file_rule_part = file_rule_part[1:]\n\n                if file_rule_part.startswith('r:'):\n                    pattern = file_rule_part[2:].strip()  # remove 'r:'\n                else:\n                    pattern = file_rule_part\n\n                execution_node_f = ExecutionNode(type='f', main_target=directory, target_pattern=pattern)\n\n                # Process content rules if a second '->' exists\n                content_rules = []\n                if len(parts) > 2:\n                    content_rules = self.parse_content_rule(parts[2], \"directory\", id, index)\n                    if content_rules is None:\n                        self.add_error(SemanticTreeError.INVALID_DIRECTORY_RULE, f\"Failed to parse content rules: {parts[2]}\", id, index)\n                        print(f\"Error: Failed to parse content rules: {parts[2]}\")\n                        return None\n\n                # Create and add the FileRule with execution nodes and content rules\n                file_rule = FileRule(execution_node=execution_node_f, content_rules=content_rules, negation=negation_f)\n                file_rules.append(file_rule)\n\n            # Create a DirectoryRule for each directory target\n            directory_rule = DirectoryRule(execution_node=execution_node_d, file_rules=file_rules, negation=negation)\n            directory_rules.append(directory_rule)\n\n        return directory_rules\n\n    def parse_command_rule(self, rule: str, negation: bool, id: int, index: int) -> Optional[CommandRule]:\n        # Split the rule into parts by '->'\n        rule = rule.replace(' -> -> ', ' -> ')\n        parts = rule.split(' -> ')\n\n        # Check if we have at least two parts for a valid command rule\n        if len(parts) < 2:\n            self.add_error(SemanticTreeError.INVALID_COMMAND_RULE, rule, id, index)\n            print(f\"Error: Invalid command rule format: {rule}\")\n            return None\n\n        # The first part is the command execution node\n        execution_node = ExecutionNode(type='c', main_target=parts[0].strip())\n\n        # Initialize the list for content rules\n        content_rules = []\n\n        # Process the first level of content rules\n        first_level_rules = parts[1].strip()\n        first_level_content_rules = self.parse_content_rule(first_level_rules, \"command\", id, index)\n        if first_level_content_rules is None:\n            print(f\"Error: Failed to parse first level content rules: {first_level_rules}\")\n            return None\n        content_rules.extend(first_level_content_rules)\n\n        # Process the second level of content rules if present\n        if len(parts) > 2:\n            second_level_rules = ' -> '.join(parts[2:]).strip()  # Reconstruct the second level rules\n            second_level_content_rules = self.parse_content_rule(second_level_rules, \"command\", id, index)\n            if second_level_content_rules is None:\n                self.add_error(SemanticTreeError.INVALID_COMMAND_RULE, f\"Failed to parse second level content rules: {second_level_rules}\", id, index)\n                print(f\"Error: Failed to parse second level content rules: {second_level_rules}\")\n                return None\n            content_rules.extend(second_level_content_rules)\n\n        # Create and return the CommandRule\n        command_rule = CommandRule(execution_node=execution_node, content_rules=content_rules, negation=negation)\n        return command_rule\n\n    def parse_process_rule(self, rule: str, negation: bool, id: int, index: int) -> ProcessRule:\n        if rule.startswith('r:'):\n            rule = rule[2:]\n            execution_node = ExecutionNode(type='p', main_target=None, target_pattern=rule)\n        else:\n            execution_node = ExecutionNode(type='p', main_target=rule)\n        return ProcessRule(execution_node=execution_node, negation=negation)\n\n    def parse_registry_rule(self, rule: str, negation: bool, id: int, index: int) -> Optional[RegistryRule]:\n        parts = rule.split(' -> ')\n        if len(parts) < 1:\n            self.add_error(SemanticTreeError.INVALID_REGISTRY_RULE, rule, id, index)\n            return None\n\n        main_target = parts[0]\n        sub_target = parts[1] if len(parts) > 1 else None\n        target_pattern = None\n        content_rules = []\n\n        if len(parts) > 2:\n            content_rules = self.parse_content_rule(' -> '.join(parts[2:]), \"registry\", id, index)\n            if content_rules is None:\n                self.add_error(SemanticTreeError.INVALID_REGISTRY_RULE, rule, id, index)\n                return None\n\n        execution_node = ExecutionNode(type='r', main_target=main_target, sub_target=sub_target, target_pattern=target_pattern)\n        return RegistryRule(execution_node=execution_node, content_rules=content_rules, negation=negation)\n\n    def parse_content_rule(self, rule: str, caller: str, id: int, index: int) -> Optional[List['ContentRule']]:\n        content_rules = []\n        rule_parts = rule.split(' && ')\n\n        for part in rule_parts:\n            negation, part = self._check_negation(part.strip())\n\n            if caller == \"registry\" and part and not part.startswith('r:') and not part.startswith('n:'):\n                # For registry rules, if the part is not starting with 'r:' or 'n:', treat it as a sub_target value\n                content_rules.append(ContentRule(\n                    content_operator=None,\n                    value=part,\n                    compare_operator=None,\n                    compare_value=None,\n                    negation=negation\n                ))\n            else:\n                if part.startswith('r:'):\n                    content_operator, value = 'r', part[2:].strip()\n                    if not self._is_valid_regex(value):\n                        self.add_error(SemanticTreeError.INVALID_CONTENT_OPERATOR, f\"Invalid regex in rule: {part}\", id, index)\n                        print(f\"Error: Invalid regex in rule: {value}\")\n                        return None\n\n                elif part.startswith('n:'):\n                    parsed_numeric_rule = self._parse_numeric_rule(part[2:].strip(), id, index)\n                    if parsed_numeric_rule is None:\n                        print(f\"Error: Invalid numeric rule format: {part[2:].strip()}\")\n                        return None\n                    content_operator, value, compare_operator, compare_value = parsed_numeric_rule\n\n                else:\n                    self.add_error(SemanticTreeError.INVALID_CONTENT_OPERATOR, f\"Rule must start with 'r:' or 'n:': {part}\", id, index)\n                    print(f\"Error: Rule must start with 'r:' or 'n:': {part}\")\n                    return None\n\n                content_rules.append(ContentRule(\n                    content_operator=content_operator,\n                    value=value,\n                    compare_operator=compare_operator if content_operator == 'n' else None,\n                    compare_value=compare_value if content_operator == 'n' else None,\n                    negation=negation\n                ))\n\n        return content_rules\n\n    def _check_negation(self, part: str) -> Tuple[bool, str]:\n        return (part.startswith('!'), part[1:]) if part.startswith('!') else (False, part)\n\n    def _is_valid_regex(self, regex: str) -> bool:\n        try:\n            re.compile(regex)\n            return True\n        except re.error:\n            return False\n\n    def _parse_numeric_rule(self, part: str, id: int, index: int) -> Optional[Tuple[str, str, str, str]]:\n        # Use regex to split the parts correctly considering multiple spaces ()\n        match = re.match(r'^(.*?)\\s+compare\\s+([<>]=?|==|!=)\\s*(\\d+)$', part.strip())\n        if not match:\n            self.add_error(SemanticTreeError.INVALID_COMPARE_EXPRESSION, f\"Numeric rule format error: {part}\", id, index)\n            return None\n\n        regex, operator, number = match.groups()\n\n        if not self._is_valid_regex(regex):\n            self.add_error(SemanticTreeError.INVALID_COMPARE_EXPRESSION, f\"Invalid regex in numeric rule: {regex}\", id, index)\n            return None\n\n        return 'n', regex, operator, number\n\n    def build_tree(self, obj: Dict) -> Union[ConditionNode, None]:\n        try:\n            id = obj.get('id', None)\n            if not isinstance(id, int):\n                self.add_error(SemanticTreeError.INVALID_ID, f\"Invalid id type: {id}\", id, 0)\n                return None\n\n            condition = obj.get('condition', None)\n            if condition not in ['all', 'any', 'none']:\n                self.add_error(SemanticTreeError.INVALID_CONDITION, f\"Invalid condition: {condition}\", id, 0)\n                return None\n\n            rules = obj.get('rules', [])\n            parsed_rules = []\n            for index, rule in enumerate(rules):\n                parsed_rule = self.parse_rule(rule, id, index + 1)\n                if parsed_rule:\n                    if isinstance(parsed_rule, list):\n                        parsed_rules.extend(parsed_rule)\n                    else:\n                        parsed_rules.append(parsed_rule)\n                else:\n                    print(f\"Failed to parse rule: {rule}\")\n\n            # Check if there are any accumulated errors after parsing all rules\n            if any(error for error in self.errors if error['id'] == id):\n                print(\"Errors encountered during build_tree:\")\n                for error in self.errors:\n                    print(error)\n                return None\n\n            # Return the condition node only if no errors were encountered\n            condition_node = ConditionNode(id=id, condition=condition, rules=parsed_rules)\n            return condition_node\n\n        except Exception as e:\n            self.add_error(SemanticTreeError.UNKNOWN_ERROR, str(e), id, 0)\n            print(f\"Exception encountered: {e}\")\n            return None\n\n    def tree_to_json(self, tree: ConditionNode) -> str:\n        return json.dumps(tree.to_dict(), separators=(',', ':'))\n\n    def get_errors(self) -> List[Dict[str, Union[str, int]]]:\n        return self.errors\n\n    def print_tree(self, tree: ConditionNode):\n        print(json.dumps(tree.to_dict(), indent=2))\n"}
{"type": "source_file", "path": "demo/backend/api_v1.py", "content": "\"\"\"\n===============================================================================\n    Program Name: API V1\n    Description:  This module defines version 1 of the API endpoints for handling \n                  script validations, rule conversions, audit executions, and \n                  compliance report generation. It includes multiple POST and \n                  GET endpoints to interact with the audit system, leveraging \n                  OpenAI models for natural language processing tasks.\n                  \n                  **Implemented Endpoints:**\n                  - `/audit/execute`: Executes an audit based on provided scripts and SSH information.\n                  - `/audit/result`: Retrieves the audit results.\n                  - `/rules/convert`: Converts natural language descriptions into compliance audit rules.\n                  - `/qa/ask`: Provides answers to questions using an AI-based model.\n                  - `/generate-audit-report`: Generates an audit report based on JSON audit results.\n\n                  **Unimplemented Endpoints:**\n                  - `/scripts/validate_description`: This endpoint is planned to validate the description of scripts but is not yet implemented.\n                  - `/scripts/validate_rules`: This endpoint is planned to validate rules within scripts but is not yet implemented.\n                  - `/audit/status/{task_id}`: This endpoint is intended to query the status of an ongoing audit but is currently not implemented.\n\n    Author:       Dickson, Jerry Hung\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-08-12\n    Last Updated: 2024-08-29\n    Version:      0.1.1\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n                  \n                  You may use this software solely for internal business \n                  purposes within your organization. You may not distribute, \n                  sublicense, or resell this software or its modifications in \n                  any form.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        The module can be imported and the `router` object used to include \n                  the API endpoints in a FastAPI application. \n                  Example: from api_v1 import router as v1_router\n\n    Requirements: Python 3.10.12, Paramiko, FastAPI, Pydantic, OpenAI SDK\n    \n    Notes:        This is a demo backend application, not intended for production use. \n                  Some parts of the code are placeholders and need further optimization:\n                  \n                  1. **Error Handling**: Improve error handling throughout the API to handle different exceptions more gracefully.\n                  2. **Security Enhancements**: Sensitive information such as SSH credentials should not be hardcoded or stored in logs. Implement secure methods for handling credentials.\n                  3. **Concurrency Management**: For better performance and scalability, implement proper concurrency handling using asynchronous functions and task management.\n                  4. **Validation Logic**: The endpoints for validating script descriptions and rules (`/scripts/validate_description` and `/scripts/validate_rules`) need to be fully implemented with comprehensive validation logic.\n                  5. **Status Tracking**: Implement the `/audit/status/{task_id}` endpoint to provide real-time status updates on ongoing audit tasks.\n                  6. **Logging and Monitoring**: Add structured logging and monitoring to track API usage, errors, and performance metrics.\n                  7. **API Security**: Ensure that all endpoints are properly secured, requiring authentication and authorization as needed.\n                  8. **Documentation and Tests**: Provide thorough documentation and unit tests for each endpoint to ensure reliability and ease of maintenance.\n===============================================================================\n\"\"\"\nfrom openai import OpenAI\nimport ipaddress\nimport json\nimport os\nimport sys\nimport re\nimport paramiko\nfrom fastapi import APIRouter, Request, Path, HTTPException\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict, Optional\nfrom semantic_tree_builder import SemanticTreeBuilder, SemanticTreeError\nfrom script_validator import ScriptValidator, ValidationError\nfrom script_processor import ScriptProcessorError\nfrom semantic_tree_executor import ExecutionError, SSHManager, OSCommandBuilder, ExecutionResult, ExecutionNodeExecutor, ContentCheckResult, ContentRuleChecker, SemanticTreeExecutionResult, SemanticTreeExecutor\nimport asyncio\nfrom cryptography.fernet import Fernet\nimport hashlib\nimport base64\n\nrouter = APIRouter()\ncurrent_id = 0\n\nclass Compliance(BaseModel):\n    name: str\n    control_list: List[str]\n\nclass Script(BaseModel):\n    script_name: str\n    description: str\n    rationale: str\n    mitigation: str\n    detection_method: str\n    os_version: str\n    compliances: List[Compliance]\n    condition: str\n    rules: List[str]\n\nclass SSHInfo(BaseModel):\n    target_system_name: str\n    target_system_type: str\n    port: int\n    username: str\n    ip: str\n    password: str\n\nclass AuditRequest(BaseModel):\n    scripts: List[Script]\n    ssh_info: SSHInfo\n\nclass QARequest(BaseModel):\n    question: str\n\nclass QAResponse(BaseModel):\n    answer: str\n\nclass ConvertRequest(BaseModel):\n    description: str\n\nclass ConvertResponse(BaseModel):\n    rule: str\n\nclass AuditReportRequest(BaseModel):\n    audit_results: dict\n\nclass AuditReportResponse(BaseModel):\n    report: str\n\n    \ndef generate_unique_id():\n    global current_id\n    current_id += 1\n    return current_id\n\ndef get_current_id():\n    global current_id\n    return current_id\n\ndef debug_print(message: str):\n    \"\"\"\n    Print a debug message in a structured format.\n    \"\"\"\n    print(f\"[DEBUG] {message}\")\n\ntemp_storage: Dict[int, Dict] = {}\n\napi_key = os.getenv(\"OPENAI_API_KEY\")\nif not api_key:\n    raise ValueError(\"OPENAI_API_KEY environment variable is not set\")\n\nclient = OpenAI(api_key=api_key)\n\nBACKGROUND_PROMPT = \"\"\"\n你是一名資安合規稽核員。你的角色是確保組織遵守安全標準和最佳實踐。你負責評估安全政策、程序和控制措施，以識別任何差距並提出改進建議。\n請使用繁體中文回答問題。\n\"\"\"\n\nSYSTEM_PROMPT = r\"\"\"\nYou are a machine designed to convert natural language descriptions into a custom compliance audit rule language. The following rules and examples provide you with the necessary background to perform this conversion accurately. Please follow the provided guidelines strictly when interpreting and converting descriptions.\nPlease generate only the compliance audit rule without providing any additional explanation or description. Return the rule alone!!!!\n\n#### Rules Overview\n\nRules are used to check the existence of files, directories, registry keys and values, running processes, and recursively test for the existence of files inside directories. They can also be used for content checking, such as checking file contents, command output, and registry value data.\n\nRules start with a location and a type of location as the target of the test, followed by the actual test specification. These tests fall into two categories: existence checks and content checks. The location type is defined in the Rule Types table below, and the location itself could be a file name, directory, process name, command, or registry key.\n\nThere are five main types of rules, as described below:\n\n#### Rule Types\n\n| Type      | Character |\n|-----------|-----------|\n| File      | f         |\n| Directory | d         |\n| Process   | p         |\n| Command   | c         |\n| Registry  | r         |\n\n#### Content Comparison Operators\n\n| Operation                    | Operator | Example                                      |\n|------------------------------|----------|----------------------------------------------|\n| Literal comparison, exact match | (omitted) | `f:/file -> CONTENT`                         |\n| Regex match                  | r:       | `f:/file -> r:REGEX`                         |\n| Numeric comparison (integers)| n:       | `f:/file -> n:REGEX_WITH_CAPTURE_GROUP compare <= VALUE` |\n\n#### Numeric Comparison Operators\n\n| Arithmetic Relational Operator | Operator | Example                                           |\n|--------------------------------|----------|---------------------------------------------------|\n| Less than                      | <        | `n:SomeProperty (\\d) compare < 42`                |\n| Less than or equal to          | <=       | `n:SomeProperty (\\d) compare <= 42`               |\n| Equal to                       | ==       | `n:SomeProperty (\\d) compare == 42`               |\n| Not equal to                   | !=       | `n:SomeProperty (\\d) compare != 42`               |\n| Greater than or equal to       | >=       | `n:SomeProperty (\\d) compare >= 42`               |\n| Greater than                   | >        | `n:SomeProperty (\\d) compare > 42`                |\n\n#### Negation\n\nYou can place `not` at the beginning of a rule to negate it. For example:\n\n```\nnot f:/some_file -> some_text\n```\n\nThe rule above fails if `some_text` is found within the contents of `some_file`.\n\n#### Existence Checking Rules\n\nExistence checks are created by setting rules without a content operator. The general form is as follows:\n\n```\nRULE_TYPE:target\n```\n\n**Examples:**\n\n- `f:/etc/sshd_config` checks the existence of the `/etc/sshd_config` file.\n- `d:/etc` checks the existence of the `/etc` directory.\n- `not p:sshd` tests for the presence of processes called `sshd` and fails if one is found.\n- `r:HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Lsa` checks for the existence of the `HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Lsa` key.\n- `r:HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Lsa -> LimitBlankPasswordUse` checks for the existence of the `LimitBlankPasswordUse` value in the key.\n\n#### Content Checking Rules\n\nThe general form of a rule testing for content is as follows:\n\n```\nRULE_TYPE:target -> CONTENT_OPERATOR:value\n```\n\n**Examples:**\n\n- `f:/etc/ssh_config -> !r:PermitRootLogin` checks if `PermitRootLogin` is not present in the file.\n- `c:systemctl is-enabled cups -> r:^enabled` checks that the command output contains a line starting with `enabled`.\n- `f:$sshd_file -> n:^\\s*MaxAuthTries\\s*\\t*(\\d+) compare <= 4` checks that `MaxAuthTries` is less than or equal to 4.\n- `r:HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Lsa -> LimitBlankPasswordUse -> 1` checks that the `LimitBlankPasswordUse` value is `1`.\n\n#### Notes and Warnings\n\n- The context of a content check is limited to a **line**.\n- It is **mandatory** to respect the spaces around the `>` and `compare` separators.\n- If the **target** of a rule that checks for contents does not exist, the result will be `Not applicable` as it could not be checked.\n\n**Negating Content Operators:**\n\nBe cautious when negating content operators, as it makes them evaluate as **Passed** for anything that does not match the specified check. For example, the rule `f:/etc/ssh_config -> !r:PermitRootLogin` is evaluated as **Passed** if it finds any line that does not contain `PermitRootLogin`.\n\n**Chaining Content Operators:**\n\nContent check operators can be chained using the `&&` (AND) operator as follows:\n\n```\nf:/etc/ssh_config -> !r:^# && r:Protocol && r:2 && r:3 && r:qwer && r:asdf && r:zxcv\n```\n\nThis rule reads as **Pass** if there's a line whose first character is not `#` and contains `Protocol` and `2`.\n\n#### Rule Syntax Examples\n\n**File Rules:**\n\n- Check that a file exists: `f:/path/to/file`\n- Check that a file does not exist: `not f:/path/to/file`\n- Check file contents (literal match): `f:/path/to/file -> content`\n- Check file contents against regex: `f:/path/to/file -> r:REGEX`\n- Check a numeric value: `f:/path/to/file -> n:*REGEX(\\d+)* compare <= Number`\n\n**Directory Rules:**\n\n- Check if a directory exists: `d:/path/to/directory`\n- Check if a directory contains a specific file: `d:/path/to/directory -> file`\n- Check if a directory contains files that match a regex: `d:/path/to/directory -> r:^files`\n- Check files matching `file_name` for content: `d:/path/to/directory -> file_name -> content`\n\n**Process Rules:**\n\n- Check if a process is running: `p:process_name`\n- Check if a process is **not** running: `not p:process_name`\n\n**Command Rules:**\n\n- Check the output of a command: `c:command -> output`\n- Check the output of a command using regex: `c:command -> r:REGEX`\n- Check a numeric value: `c:command -> n:REGEX_WITH_A_CAPTURE_GROUP compare >= number`\n\n**Registry Rules (Windows Only):**\n\n- Check if a registry exists: `r:path/to/registry`\n- Check if a registry key exists: `r:path/to/registry -> key`\n- Check registry key contents: `r:path/to/registry -> key -> content`\n\n#### Composite Rules\n\nComposite rules allow combining multiple checks in a single statement. For example:\n\n- Check if there is a line that does not begin with `#` and contains `Port 22`: `f:/etc/ssh/sshd_config -> !r:^# && r:Port\\.+22`\n- Check if there is no line that does not begin with `#` and contains `Port 22`: `not f:/etc/ssh/sshd_config -> !r:^# && r:Port\\.+22`\n\n#### Additional Examples\n\n- Check for file contents, whole line match: `f:/proc/sys/net/ipv4/ip_forward -> 1`\n- Check if a file exists: `f:/proc/sys/net/ipv4/ip_forward`\n- Check if a process is running: `p:avahi-daemon`\n- Check value of registry: `r:HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\Netlogon\\Parameters -> MaximumPasswordAge -> 0`\n- Check if a directory contains specific files: `d:/home -> ^.mysql_history$`\n- Check if a directory exists: `d:/etc/mysql`\n- Check the running configuration of `sshd` for the maximum authentication tries allowed: `c:sshd -T -> !r:^\\s*maxauthtries\\s+4\\s*$`\n- Check if root is the only account with UID 0: `f:/etc/passwd -> !r:^# && !r:^root: && r:^\\w+:\\w+:0:`\n\n\"\"\"\n\nUSER_PROMPT_TEMPLATE = \"\"\"\nConvert the following natural language description into a compliance audit rule, adhering to the rules and syntax provided.\n\nDescription: {user_input}\n\"\"\"\n\nAUDIT_SYSTEM_PROMPT = r\"\"\"\nYou are a cybersecurity audit report generator. You will receive a JSON file containing detailed audit results for a specific script. Your task is to analyze the JSON content, understand the audit findings, and refer to the rules applied during the audit process. Based on this analysis, you must generate a concise and precise audit report.\n\n### Structure of the Audit Results\n\nThe audit results JSON structure includes several key sections:\n\n1. **scripts**: This section provides information about the script that was audited, including:\n   - `script_name`: The name of the script.\n   - `description`: A brief description of the script.\n   - `rationale`, `mitigation`, `detection_method`, `os_version`: Additional details that may provide context about the script and its purpose.\n   - `compliances`: Lists compliance requirements or standards that the script is expected to meet.\n   - `condition`: Indicates whether all rules must pass (`all`) or any rule can pass (`any`) for the overall result to be considered a pass.\n   - `rules`: A list of specific checks or tests that were conducted on the script. Each rule is a string that defines the target and the type of check (e.g., file existence, content match, etc.).\n\n2. **ssh_info**: Contains information about the target system where the script was executed, including:\n   - `target_system_name`, `target_system_type`, `port`, `username`, `ip`, `password`: Details about the SSH connection used for auditing.\n\n3. **execution_results**: This section contains the results of the audit:\n   - `result`: Indicates the overall result of the audit (`pass` or `fail`).\n   - `condition`: Reiterates the condition (e.g., `all`, `any`) under which the audit was evaluated.\n   - `rule_results`: A list of boolean values corresponding to the `rules` in the `scripts` section:\n     - `true` indicates that the rule passed successfully.\n     - `false` indicates that the rule failed.\n\n### How to Generate the Report\n\nBased on the JSON structure, your task is to:\n\n1. Provide an overview of the audit findings, summarizing the key outcomes.\n2. Clearly explain any issues found, specifically highlighting the rules that were not met. These can be identified by the `false` values in the `rule_results` list, which correspond to the rules listed in the `rules` array.\n3. Briefly describe the implications of the audit results on system security.\n4. Offer recommendations for remediation or further action based on the audit results.\n\nYour response should be structured, clear, and avoid unnecessary details. The goal is to provide a straightforward report that is easy for both technical and non-technical stakeholders to understand.\n\nBelow are the rule formats for your reference:\n#### Rules Overview\n\nRules are used to check the existence of files, directories, registry keys and values, running processes, and recursively test for the existence of files inside directories. They can also be used for content checking, such as checking file contents, command output, and registry value data.\n\nRules start with a location and a type of location as the target of the test, followed by the actual test specification. These tests fall into two categories: existence checks and content checks. The location type is defined in the Rule Types table below, and the location itself could be a file name, directory, process name, command, or registry key.\n\nThere are five main types of rules, as described below:\n\n#### Rule Types\n\n| Type      | Character |\n|-----------|-----------|\n| File      | f         |\n| Directory | d         |\n| Process   | p         |\n| Command   | c         |\n| Registry  | r         |\n\n#### Content Comparison Operators\n\n| Operation                    | Operator | Example                                      |\n|------------------------------|----------|----------------------------------------------|\n| Literal comparison, exact match | (omitted) | `f:/file -> CONTENT`                         |\n| Regex match                  | r:       | `f:/file -> r:REGEX`                         |\n| Numeric comparison (integers)| n:       | `f:/file -> n:REGEX_WITH_CAPTURE_GROUP compare <= VALUE` |\n\n#### Numeric Comparison Operators\n\n| Arithmetic Relational Operator | Operator | Example                                           |\n|--------------------------------|----------|---------------------------------------------------|\n| Less than                      | <        | `n:SomeProperty (\\d) compare < 42`                |\n| Less than or equal to          | <=       | `n:SomeProperty (\\d) compare <= 42`               |\n| Equal to                       | ==       | `n:SomeProperty (\\d) compare == 42`               |\n| Not equal to                   | !=       | `n:SomeProperty (\\d) compare != 42`               |\n| Greater than or equal to       | >=       | `n:SomeProperty (\\d) compare >= 42`               |\n| Greater than                   | >        | `n:SomeProperty (\\d) compare > 42`                |\n\n#### Negation\n\nYou can place `not` at the beginning of a rule to negate it. For example:\n\n```\nnot f:/some_file -> some_text\n```\n\nThe rule above fails if `some_text` is found within the contents of `some_file`.\n\n#### Existence Checking Rules\n\nExistence checks are created by setting rules without a content operator. The general form is as follows:\n\n```\nRULE_TYPE:target\n```\n\n**Examples:**\n\n- `f:/etc/sshd_config` checks the existence of the `/etc/sshd_config` file.\n- `d:/etc` checks the existence of the `/etc` directory.\n- `not p:sshd` tests for the presence of processes called `sshd` and fails if one is found.\n- `r:HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Lsa` checks for the existence of the `HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Lsa` key.\n- `r:HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Lsa -> LimitBlankPasswordUse` checks for the existence of the `LimitBlankPasswordUse` value in the key.\n\n#### Content Checking Rules\n\nThe general form of a rule testing for content is as follows:\n\n```\nRULE_TYPE:target -> CONTENT_OPERATOR:value\n```\n\n**Examples:**\n\n- `f:/etc/ssh_config -> !r:PermitRootLogin` checks if `PermitRootLogin` is not present in the file.\n- `c:systemctl is-enabled cups -> r:^enabled` checks that the command output contains a line starting with `enabled`.\n- `f:$sshd_file -> n:^\\s*MaxAuthTries\\s*\\t*(\\d+) compare <= 4` checks that `MaxAuthTries` is less than or equal to 4.\n- `r:HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Lsa -> LimitBlankPasswordUse -> 1` checks that the `LimitBlankPasswordUse` value is `1`.\n\n#### Notes and Warnings\n\n- The context of a content check is limited to a **line**.\n- It is **mandatory** to respect the spaces around the `>` and `compare` separators.\n- If the **target** of a rule that checks for contents does not exist, the result will be `Not applicable` as it could not be checked.\n\n**Negating Content Operators:**\n\nBe cautious when negating content operators, as it makes them evaluate as **Passed** for anything that does not match the specified check. For example, the rule `f:/etc/ssh_config -> !r:PermitRootLogin` is evaluated as **Passed** if it finds any line that does not contain `PermitRootLogin`.\n\n**Chaining Content Operators:**\n\nContent check operators can be chained using the `&&` (AND) operator as follows:\n\n```\nf:/etc/ssh_config -> !r:^# && r:Protocol && r:2 && r:3 && r:qwer && r:asdf && r:zxcv\n```\n\nThis rule reads as **Pass** if there's a line whose first character is not `#` and contains `Protocol` and `2`.\n\n#### Rule Syntax Examples\n\n**File Rules:**\n\n- Check that a file exists: `f:/path/to/file`\n- Check that a file does not exist: `not f:/path/to/file`\n- Check file contents (literal match): `f:/path/to/file -> content`\n- Check file contents against regex: `f:/path/to/file -> r:REGEX`\n- Check a numeric value: `f:/path/to/file -> n:*REGEX(\\d+)* compare <= Number`\n\n**Directory Rules:**\n\n- Check if a directory exists: `d:/path/to/directory`\n- Check if a directory contains a specific file: `d:/path/to/directory -> file`\n- Check if a directory contains files that match a regex: `d:/path/to/directory -> r:^files`\n- Check files matching `file_name` for content: `d:/path/to/directory -> file_name -> content`\n\n**Process Rules:**\n\n- Check if a process is running: `p:process_name`\n- Check if a process is **not** running: `not p:process_name`\n\n**Command Rules:**\n\n- Check the output of a command: `c:command -> output`\n- Check the output of a command using regex: `c:command -> r:REGEX`\n- Check a numeric value: `c:command -> n:REGEX_WITH_A_CAPTURE_GROUP compare >= number`\n\n**Registry Rules (Windows Only):**\n\n- Check if a registry exists: `r:path/to/registry`\n- Check if a registry key exists: `r:path/to/registry -> key`\n- Check registry key contents: `r:path/to/registry -> key -> content`\n\n#### Composite Rules\n\nComposite rules allow combining multiple checks in a single statement. For example:\n\n- Check if there is a line that does not begin with `#` and contains `Port 22`: `f:/etc/ssh/sshd_config -> !r:^# && r:Port\\.+22`\n- Check if there is no line that does not begin with `#` and contains `Port 22`: `not f:/etc/ssh/sshd_config -> !r:^# && r:Port\\.+22`\n\n#### Additional Examples\n\n- Check for file contents, whole line match: `f:/proc/sys/net/ipv4/ip_forward -> 1`\n- Check if a file exists: `f:/proc/sys/net/ipv4/ip_forward`\n- Check if a process is running: `p:avahi-daemon`\n- Check value of registry: `r:HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\Netlogon\\Parameters -> MaximumPasswordAge -> 0`\n- Check if a directory contains specific files: `d:/home -> ^.mysql_history$`\n- Check if a directory exists: `d:/etc/mysql`\n- Check the running configuration of `sshd` for the maximum authentication tries allowed: `c:sshd -T -> !r:^\\s*maxauthtries\\s+4\\s*$`\n- Check if root is the only account with UID 0: `f:/etc/passwd -> !r:^# && !r:^root: && r:^\\w+:\\w+:0:`\n\n\"\"\"\n\ndef generate_key_from_filename(filename):\n    hash_object = hashlib.sha256(filename.encode())\n    key = base64.urlsafe_b64encode(hash_object.digest()[:32])\n    return key\n\ndef encrypt_password(password, key):\n    fernet = Fernet(key)\n    encrypted = fernet.encrypt(password.encode())\n    return encrypted\n\ndef decrypt_password(encrypted_password, key):\n    fernet = Fernet(key)\n    decrypted = fernet.decrypt(encrypted_password).decode()\n    return decrypted\n\n# # Validate Script Description\n# @router.post('/scripts/validate_description')\n# async def validate_description(request: Request):\n#     return_obj = {}\n#     try:\n#         body = await request.body()\n#         data = json.loads(body)\n#         return_obj['success'] = False\n\n#         script_name = data.get('script_name')\n#         if script_name is not None and len(str(script_name).strip()) > 0:\n#             pass\n#         else:\n#             return_obj['error'] = 'script_name cannot be empty'\n#             return return_obj\n\n#         description = data.get('description')\n#         if description is not None and len(str(description).strip()) > 0:\n#             pass\n#         else:\n#             return_obj['error'] = 'description cannot be empty'\n#             return return_obj\n\n#         rationale = data.get('rationale')\n#         if rationale is not None and len(str(rationale).strip()) > 0:\n#             pass\n#         else:\n#             return_obj['error'] = 'rationale cannot be empty'\n#             return return_obj\n\n#         mitigation = data.get('mitigation')\n#         if mitigation is not None and len(str(mitigation).strip()) > 0:\n#             pass\n#         else:\n#             return_obj['error'] = 'mitigation cannot be empty'\n#             return return_obj\n\n#         detection_method = data.get('detection_method')\n#         if detection_method is not None and detection_method in ['auto', 'semi-auto', 'manual']:\n#             pass\n#         else:\n#             return_obj['error'] = \"detection_method must be one of 'auto', 'semi-auto', or 'manual'\"\n#             return return_obj\n\n#         os_version = data.get('os_version')\n#         if os_version is not None and os_version in ['ubuntu 22.04']:\n#             pass\n#         else:\n#             return_obj['error'] = \"os_version must be 'ubuntu 22.04'\"\n#             return return_obj\n\n#         compliance_list = data.get('compliances')\n#         if compliance_list is not None and len(compliance_list) > 0:\n#             pass\n#         else:\n#             return_obj['error'] = 'compliances must contain at least one compliance'\n#             return return_obj\n\n#         for compliance_obj in compliance_list:\n#             compliance_name = compliance_obj.get('name')\n#             if compliance_name is not None and compliance_name in ['NIST 800-53r5']:\n#                 pass\n#             else:\n#                 return_obj['error'] = \"compliance name must be a recognized standard like 'NIST 800-53r5'\"\n#                 return return_obj\n#             control_list = compliance_obj.get('control_list')\n#             if control_list is not None and len(control_list) > 0:\n#                 pass\n#             else:\n#                 return_obj['error'] = \"control_list cannot be empty for any compliance\"\n#                 return return_obj\n#         # 通過驗證\n#         return_obj['success'] = True\n#         return return_obj\n#     except Exception as e:\n#         print('★★★★★★ Validate Script Description fail!!! ' + str(e))\n#         return_obj['success'] = False\n#         return_obj['error'] = 'System problem,please contact administrator'\n#         return return_obj\n\n\n# # Validate Script Rules\n# @router.post('/scripts/validate_rules')\n# async def validate_rules(request: Request):\n#     return_obj = {}\n#     try:\n#         # 檢核傳入參數\n#         body = await request.body()\n#         data = json.loads(body)\n#         return_obj['success'] = False\n\n#         condition = data.get('condition')\n#         if condition is not None and len(str(condition).strip()) > 0:\n#             if condition in ['none', 'any', 'all']:\n#                 pass\n#             else:\n#                 return_obj['error'] = \"condition must be one of 'none', 'any', or 'all'\"\n#                 return return_obj\n#         else:\n#             return_obj['error'] = 'condition cannot be empty'\n#             return return_obj\n\n#         rule_list = data.get('rule_list')\n#         if rule_list is not None and len(rule_list) > 0:\n#             pass\n#         else:\n#             return_obj['error'] = 'rule_list must contain at least one rule'\n#             return return_obj\n\n#         for rule_str in rule_list:\n#             # TODO 呼叫核心功能驗證rule_str syntax, 結果請回傳到chk_syntax_result, 範例chk_syntax_result = some_api(rule_str)\n#             chk_syntax_result = False\n#             if not chk_syntax_result:\n#                 return_obj['error'] = 'One or more rules in rule_list have invalid syntax'\n#                 return return_obj\n\n#         # 通過驗證\n#         return_obj['success'] = True\n#         return return_obj\n#     except Exception as e:\n#         print('★★★★★★ Validate Script Rules fail!!! ' + str(e))\n#         return_obj['success'] = False\n#         return_obj['error'] = 'System problem,please contact administrator'\n#         return return_obj\n\n@router.post('/audit/execute')\nasync def execute_audit(audit_request: AuditRequest):\n    return_obj = {}\n    try:\n        data = audit_request.dict()\n        return_obj['success'] = False\n\n        task_id_val = generate_unique_id()\n\n        # request_json_file = f\"{task_id_val}_request.json\"\n        # with open(request_json_file, 'w') as f:\n        #     json.dump(data, f, indent=4)\n\n        ssh_info = data.get('ssh_info')\n        if ssh_info is not None:\n            hostname = ssh_info.get('ip')\n            username = ssh_info.get('username')\n            password = ssh_info.get('password')\n            port = ssh_info.get('port', 22)  # Default to port 22 if not provided\n        else:\n            return_obj['error'] = 'ssh_info cannot be empty'\n            return return_obj\n\n        scripts = data.get('scripts', [])\n        if not scripts:\n            return_obj['error'] = 'scripts cannot be empty'\n            return return_obj\n\n        script_info = scripts[0]\n        condition = script_info.get('condition')\n        rules = script_info.get('rules')\n\n        if condition is None or rules is None:\n            return_obj['error'] = 'condition and rules cannot be empty'\n            return return_obj\n\n        check = {\n            \"id\": task_id_val,\n            \"condition\": condition,\n            \"rules\": rules\n        }\n\n        print(\"Generated Dict:\", check)\n\n        try:\n            tree_builder = SemanticTreeBuilder()\n\n            loop = asyncio.get_event_loop()\n            tree = await loop.run_in_executor(None, tree_builder.build_tree, check)\n\n            if tree is None:\n                errors = tree_builder.get_errors()\n                return {\n                    \"status\": \"error\",\n                    \"error_code\": ScriptProcessorError.TREE_BUILDING_FAILED.value[0],\n                    \"error_message\": ScriptProcessorError.TREE_BUILDING_FAILED.value[1],\n                    \"details\": errors\n                }\n\n            tree_json = json.loads(tree_builder.tree_to_json(tree))\n            results = {\n                \"os_type\": \"linux\",\n                \"checks\": [tree_json]\n            }\n\n            # tree_json_file = f\"{task_id_val}_tree.json\"\n            # with open(tree_json_file, 'w') as f:\n            #     f.write(json.dumps(results, indent=4))\n\n            executor = SemanticTreeExecutor(hostname=hostname, username=username, password=password, port=port)\n            debug_print(f\"Initialized SemanticTreeExecutor with hostname: {executor.ssh_manager.hostname}\")\n\n            try:\n                semantic_tree = results\n                debug_print(\"Semantic tree data loaded successfully.\")\n            except Exception as e:\n                debug_print(f\"Failed to load semantic tree data: {str(e)}\")\n                sys.exit(1)\n\n            debug_print(\"Executing the semantic tree...\")\n            execution_results = executor.execute_tree(semantic_tree)\n            if execution_results.success:\n                debug_print(\"Semantic tree execution completed successfully.\")\n                debug_print(f\"Execution results: {execution_results.results}\")\n            else:\n                debug_print(f\"Semantic tree execution failed with error: {execution_results.error}\")\n\n            result_data = data.copy()\n            result_data['execution_results'] = execution_results.results\n\n            result_json_file = f\"{task_id_val}_result.json\"\n            key = generate_key_from_filename(result_json_file)\n\n            if 'ssh_info' in result_data:\n                result_data['ssh_info']['password'] = encrypt_password(result_data['ssh_info']['password'], key).decode()\n\n            with open(result_json_file, 'w') as f:\n                json.dump(result_data, f, indent=4)\n\n            return_obj['task_id'] = task_id_val\n            return_obj['success'] = True\n            return_obj['execution_results'] = execution_results.results if execution_results.success else execution_results.error\n            return return_obj\n\n        except asyncio.TimeoutError:\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.TREE_BUILDING_TIMEOUT.value[0],\n                \"error_message\": \"Tree building operation timed out.\",\n                \"details\": \"The operation took longer than 8 seconds.\"\n            }\n\n        except Exception as e:\n            return {\n                \"status\": \"error\",\n                \"error_code\": ScriptProcessorError.UNKNOWN_ERROR.value[0],\n                \"error_message\": ScriptProcessorError.UNKNOWN_ERROR.value[1],\n                \"details\": str(e)\n            }\n\n    except Exception as e:\n        print('★★★★★★ Execute Audit fail!!! ' + str(e))\n        return_obj['success'] = False\n        return_obj['error'] = 'System problem, please contact administrator'\n        return return_obj\n\n# # Query Audit Status\n# @router.get('/audit/status/{task_id}')\n# async def query_audit_status(_: Request, task_id=Path(..., description='')):\n#     return_obj = {}\n#     try:\n#         # 檢核傳入參數\n#         return_obj['success'] = False\n\n#         if task_id is not None and isinstance(task_id, str):\n#             try:\n#                 task_id = int(task_id)\n#             except Exception:\n#                 return_obj['error'] = 'task_id is invalid or missing'\n#                 return return_obj\n#         else:\n#             return_obj['error'] = 'task_id is invalid or missing'\n#             return return_obj\n\n#         # 通過驗證\n#         # TODO 呼叫核心功能Query Audit Status,再修改以下程式\n#         if True:\n#             audit_status = {\"task_id\": \"12345\", \"status\": \"executing\", \"progress\": 50}\n#             return audit_status\n#         else:\n#             return_obj['error'] = 'No audit found for the provided task_id'\n#             return return_obj\n#     except Exception as e:\n#         print('★★★★★★ Query Audit Status fail!!! ' + str(e))\n#         return_obj['success'] = False\n#         return_obj['error'] = 'System problem,please contact administrator'\n#         return return_obj\n\n@router.get('/audit/result')\nasync def query_audit_results():\n    try:\n        current_id = get_current_id()\n\n        result_json_file = f\"{current_id}_result.json\"\n        if not os.path.exists(result_json_file):\n            return {\n                \"status\": \"error\",\n                \"error_message\": f\"Result file for task_id {current_id} not found.\"\n            }\n\n        key = generate_key_from_filename(result_json_file)\n\n        with open(result_json_file, 'r') as f:\n            audit_results = json.load(f)\n\n        # Decrypt the SSH password if it exists\n        if 'ssh_info' in audit_results:\n            encrypted_password = audit_results['ssh_info'].get('password', None)\n            if encrypted_password:\n                audit_results['ssh_info']['password'] = decrypt_password(encrypted_password, key)\n\n        return audit_results\n\n    except Exception as e:\n        print('★★★★★★ Query Audit Results fail!!! ' + str(e))\n        return {\n            \"status\": \"error\",\n            \"error_message\": \"System problem, please contact administrator\",\n            \"details\": str(e)\n        }\n\n# Convert Natural Language to Rule\n@router.post('/rules/convert', response_model=ConvertResponse)\nasync def convert_to_rule(request: ConvertRequest):\n    try:\n        description = request.description\n\n        if not description.strip():\n            raise HTTPException(status_code=400, detail=\"Description cannot be empty\")\n\n        # Construct the user prompt using the provided description\n        user_prompt = USER_PROMPT_TEMPLATE.format(user_input=description)\n\n        try:\n            response = client.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=[\n                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n                    {\"role\": \"user\", \"content\": user_prompt},\n                ]\n            )\n\n            # Retrieve the content returned by the OpenAI API\n            rule_content = response.choices[0].message.content.strip()\n\n            # Use regular expression to filter lines that start with not, f:, d:, p:, c:, or r:\n            rules = \"\\n\".join(re.findall(r'^(?:not|f:|d:|p:|c:|r:).*$',\n                                         rule_content, re.MULTILINE))\n\n            if not rules:\n                rules = \"No valid rules found.\"\n\n            return ConvertResponse(rule=rules)\n\n        except Exception as e:\n            raise HTTPException(status_code=500, detail=f\"Failed to convert description to rule: {str(e)}\")\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"System problem, please contact administrator: {str(e)}\")\n    \n# Q&A Answering\n@router.post('/qa/ask', response_model=QAResponse)\nasync def qa_ask(request: QARequest):\n    try:\n        question = request.question\n\n        if not question.strip():\n            raise HTTPException(status_code=400, detail=\"Question cannot be empty\")\n\n        # Construct a request for the GPT-4 model\n        try:\n            response = client.chat.completions.create(\n                model=\"gpt-4o-mini\",\n                messages=[\n                    {\"role\": \"system\", \"content\": BACKGROUND_PROMPT},\n                    {\"role\": \"user\", \"content\": question},\n                ]\n            )\n\n            # Correctly access the content from the response object\n            answer = response.choices[0].message.content.strip()\n            return QAResponse(answer=answer)\n\n        except Exception as e:\n            raise HTTPException(status_code=500, detail=f\"Failed to retrieve an answer from OpenAI API: {str(e)}\")\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"System problem, please contact administrator: {str(e)}\")\n\n@router.post('/generate-audit-report', response_model=AuditReportResponse)\nasync def generate_audit_report(request: AuditReportRequest):\n    try:\n        # Directly use audit_results to construct the user input content\n        audit_data = request.audit_results\n        user_input = f\"Audit Results:\\n{audit_data}\"\n\n        # Call OpenAI API to generate the audit report\n        try:\n            response = client.chat.completions.create(\n                model=\"gpt-4o-mini\",\n                messages=[\n                    {\"role\": \"system\", \"content\": AUDIT_SYSTEM_PROMPT},\n                    {\"role\": \"user\", \"content\": user_input},\n                ]\n            )\n\n            answer = response.choices[0].message.content.strip()\n            return AuditReportResponse(report=answer)\n\n        except Exception as e:\n            raise HTTPException(status_code=500, detail=f\"Failed to generate audit report from OpenAI API: {str(e)}\")\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"System problem, please contact administrator: {str(e)}\")\n"}
{"type": "source_file", "path": "demo/backend/app.py", "content": "\"\"\"\n===============================================================================\n    Program Name: app.py\n    Description:  This script serves as the entry point for the RESTful API built \n                  using FastAPI. It configures the API application, sets up CORS \n                  middleware, and defines routing for API version 1. The application \n                  is designed to be run with Python 3.10.12 and provides a Swagger \n                  UI for API documentation.\n                  \n    Author:       Dickson\n    Email:        Not Provided\n    Created Date: 2024-08-12\n    Last Updated: 2024-08-29\n    Version:      1.0\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n                  \n                  You may use this software solely for internal business \n                  purposes within your organization. You may not distribute, \n                  sublicense, or resell this software or its modifications in \n                  any form.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        To run the API server, use the following command:\n                  `python3 app.py`\n\n                  The server will start on `http://0.0.0.0:8080` and serve the API \n                  endpoints under `/api/v1`. The Swagger UI documentation is available \n                  at `/docs`, and the OpenAPI schema is accessible at `/openapi.json`.\n\n    Requirements: Python 3.10.12, FastAPI, Uvicorn\n===============================================================================\n\"\"\"\nimport os\nimport uvicorn\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom api_v1 import router as v1_router\n\napp = FastAPI(docs_url='/docs', redoc_url=None, openapi_url='/openapi.json')  # enable Swagger UI\n\n# Route API\napp.include_router(v1_router, prefix='/api/v1')\n\n# CORS設定\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=['*'],\n    allow_credentials=False,\n    allow_methods=['*'],\n    allow_headers=['*'],\n)\n\nif __name__ == '__main__':\n    print('★★★★★★ 啟動FastAPI... port num : 8080')\n    uvicorn.run(app,\n                host='0.0.0.0',\n                server_header=False,\n                port=8080)\n"}
{"type": "source_file", "path": "demo/backend/semantic_tree_executor.py", "content": "\"\"\"\n===============================================================================\n    Program Name: Semantic Tree Executor\n    Description:  This script is designed to execute a semantic tree structure \n                  that represents various types of system checks and validations. \n                  It supports execution on remote systems via SSH, covering file \n                  existence, directory listings, process checks, command execution, \n                  and registry key checks.\n\n    Author:       Jerry Hung, Bolt Lin\n    Email:        chiehlee.hung@gmail.com\n    Created Date: 2024-08-09\n    Last Updated: 2024-08-29\n    Version:      0.1.2\n    \n    License:      Commercial License\n                  This software is licensed under a commercial license. \n                  Redistribution and use in source and binary forms, with or \n                  without modification, are not permitted without explicit \n                  written permission from the author.\n                  \n                  You may use this software solely for internal business \n                  purposes within iiicsti. You may not distribute, \n                  sublicense, or resell this software or its modifications in \n                  any form.\n\n                  Unauthorized copying of this software, via any medium, is \n                  strictly prohibited.\n\n    Usage:        The main class SemanticTreeExecutor can be instantiated with \n                  SSH details to execute the semantic tree on a remote system. \n                  The results of the execution are returned as a structured \n                  output, indicating success or failure of each check.\n\n    Requirements: Python 3.10.12, Paramiko\n    \n    Notes:        None\n===============================================================================\n\"\"\"\n\nimport paramiko\nimport re\nfrom typing import Dict, Optional, Union, Tuple, List, Any\nimport json\nimport sys\nfrom enum import Enum\n\nclass ExecutionError(Enum):\n    MISMATCH_OS_TYPE = (\"E101\", \"Mismatch in OS types\")\n    INVALID_NODE_TYPE = (\"E102\", \"Invalid node type\")\n    INVALID_CONFIGURATION = (\"E103\", \"Invalid configuration for node type\")\n    SSH_EXECUTION_FAILED = (\"E104\", \"SSH command execution failed\")\n    OS_DETECTION_FAILED = (\"E105\", \"Failed to determine the actual OS type\")\n    COMMAND_FAILED = (\"E106\", \"Command execution failed\")\n    FILE_NOT_FOUND = (\"E107\", \"File not found during execution\")\n    DIRECTORY_NOT_FOUND = (\"E108\", \"Directory not found during execution\")\n    PROCESS_NOT_FOUND = (\"E109\", \"Process not found\")\n    REGISTRY_KEY_NOT_FOUND = (\"E110\", \"Registry key not found\")\n    REGISTRY_ACCESS_FAILED = (\"E111\", \"Failed to access registry key\")\n    FILE_READ_FAILED = (\"E112\", \"Failed to read file content\")\n    INVALID_CONTENT_OPERATOR = (\"E113\", \"Invalid content operator provided\")\n    NUMERIC_COMPARE_FAILED = (\"E114\", \"Failed to compare numeric values\")\n    PATTERN_MATCH_FAILED = (\"E115\", \"Pattern match failed\")\n    INVALID_FILE_LIST = (\"E116\", \"Invalid or empty file list provided\")\n    UNKNOWN_ERROR = (\"E117\", \"Unknown error occurred during execution\")\n\nclass SSHManager:\n    def __init__(self, hostname: str, username: str, password: str, port: int = 22):\n        self.hostname = hostname\n        self.username = username\n        self.password = password\n        self.port = port\n        self.client = None\n\n    def connect(self) -> None:\n        try:\n            self.client = paramiko.SSHClient()\n            self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n            self.client.connect(self.hostname, port=self.port, username=self.username, password=self.password)\n            print(f\"Connected to {self.hostname} on port {self.port}\")\n        except paramiko.AuthenticationException:\n            raise Exception(f\"Authentication failed when connecting to {self.hostname}\")\n        except paramiko.SSHException as e:\n            raise Exception(f\"Could not establish SSH connection: {str(e)}\")\n        except Exception as e:\n            raise Exception(f\"Connection failed: {str(e)}\")\n\n    def execute_command(self, command: str, ) -> Tuple[str, str, int]:\n        if not self.client:\n            raise Exception(\"SSH connection not established\")\n\n        try:\n            # print(f\"Executing command: {command}\")\n            stdin, stdout, stderr = self.client.exec_command(command)\n            output = stdout.read().decode('utf-8')\n            error = stderr.read().decode('utf-8')\n            exit_status = stdout.channel.recv_exit_status()\n            # print(f\"Command output: {output}\")\n            # print(f\"Command error: {error}\")\n            # print(f\"Exit status: {exit_status}\")\n            return output, error, exit_status\n        except paramiko.SSHException as e:\n            raise Exception(f\"Failed to execute command: {str(e)}\")\n\n    def close(self) -> None:\n        \"\"\"\n        Close the SSH connection.\n        \"\"\"\n        if self.client:\n            self.client.close()\n            self.client = None\n            print(f\"Disconnected from {self.hostname}\")\n\nclass OSCommandBuilder:\n    def __init__(self, os_type: str):\n        self.os_type = os_type\n\n    def build_file_existence_command(self, filepath: str) -> str:\n        if self.os_type == 'linux':\n            return f\"test -f {filepath} && echo 'exists' || echo 'not exists'\"\n        elif self.os_type == 'windows':\n            return f\"if exist {filepath} (echo exists) else (echo not exists)\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_directory_listing_command(self, directory: str, pattern: str) -> str:\n        if self.os_type == 'linux':\n            return f\"ls {directory} | grep '{pattern}'\"\n        elif self.os_type == 'windows':\n            return f\"dir {directory} /b | findstr {pattern}\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_stat_command(self, filepath: str) -> str:\n        if self.os_type == 'linux':\n            return f\"stat {filepath}\"\n        elif self.os_type == 'windows':\n            return f\"Get-Item {filepath} | Format-List -Property Mode,Owner,Group\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_process_check_command(self, process_name: str) -> str:\n        if self.os_type == 'linux':\n            return f\"ps aux | grep '{process_name}' | grep -v grep\"\n        elif self.os_type == 'windows':\n            return f\"tasklist /FI \\\"IMAGENAME eq {process_name}\\\"\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\n    def build_registry_check_command(self, registry_path: str, registry_key: str) -> str:\n        if self.os_type == 'windows':\n            return f'reg query \"{registry_path}\" /v {registry_key}'\n        else:\n            raise ValueError(\"Registry checks are only supported on Windows OS.\")\n\n    def build_registry_key_existence_command(self, registry_path: str) -> str:\n        if self.os_type == 'windows':\n            return f'reg query \"{registry_path}\"'\n        else:\n            raise ValueError(\"Registry checks are only supported on Windows OS.\")\n\n    def build_read_file_command(self, filepath: str) -> str:\n        if self.os_type == 'linux':\n            return f\"cat {filepath}\"\n        elif self.os_type == 'windows':\n            return f\"type {filepath}\"\n        else:\n            raise ValueError(f\"Unsupported OS type: {self.os_type}\")\n\nclass ExecutionResult:\n    def __init__(self, success: bool, output: Optional[str] = None, error: Optional[str] = None):\n        self.success = success\n        self.output = output\n        self.error = error\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"success\": self.success,\n            \"output\": self.output,\n            \"error\": self.error\n        }\n\nclass ExecutionNodeExecutor:\n    def __init__(self, node_type: str, main_target: str, sub_target: Optional[str], target_pattern: Optional[str], os_type: str):\n        self.node_type = node_type\n        self.main_target = main_target\n        self.sub_target = sub_target\n        self.target_pattern = target_pattern\n        self.os_type = os_type\n        self.command_builder = OSCommandBuilder(os_type)\n\n    def execute(self, ssh_manager: SSHManager) -> ExecutionResult:\n        try:\n            actual_os_type = self.determine_actual_os_type(ssh_manager)\n            if self.os_type != actual_os_type:\n                return ExecutionResult(success=False, error=ExecutionError.MISMATCH_OS_TYPE.value[1])\n\n            if self.node_type == 'd':\n                return self.check_directory_existence(ssh_manager)\n            elif self.node_type == 'f':\n                if self.target_pattern:\n                    return self.list_files_with_pattern(ssh_manager)\n                return self.check_file_existence(ssh_manager)\n            elif self.node_type == 'c':\n                return self.run_command(ssh_manager)\n            elif self.node_type == 'p':\n                return self.check_process_existence(ssh_manager)\n            elif self.node_type == 'r':\n                return self.check_registry_key(ssh_manager)\n            else:\n                return ExecutionResult(success=False, error=ExecutionError.INVALID_NODE_TYPE.value[1])\n\n        except Exception as e:\n            return ExecutionResult(success=False, error=f\"{ExecutionError.COMMAND_FAILED.value[1]}: {str(e)}\")\n\n    def determine_actual_os_type(self, ssh_manager: SSHManager) -> str:\n        try:\n            output, error, exit_status = ssh_manager.execute_command('uname')\n            if exit_status != 0:\n                raise Exception(\"Failed to detect OS type\")\n            if 'Linux' in output:\n                return 'linux'.strip()\n            return 'windows'.strip()\n        except Exception as e:\n            raise Exception(f\"{ExecutionError.OS_DETECTION_FAILED.value[1]}: {str(e)}\")\n\n    def check_directory_existence(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if self.sub_target or self.target_pattern:\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            command = self.command_builder.build_directory_listing_command(self.main_target, \"\")\n            output, error, exit_status = ssh_manager.execute_command(command)\n            if exit_status == 0 and output:\n                return ExecutionResult(success=True, output=self.main_target)\n            return ExecutionResult(success=False, output=self.main_target)\n        except Exception as e:\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def check_file_existence(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if self.sub_target or self.target_pattern:\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            command = self.command_builder.build_file_existence_command(self.main_target)\n            output, error, exit_status = ssh_manager.execute_command(command)\n            if exit_status == 0 and \"exists\" in output:\n                return ExecutionResult(success=True, output=self.main_target)\n            return ExecutionResult(success=False, output=self.main_target)\n        except Exception as e:\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def list_files_with_pattern(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if not self.target_pattern or self.sub_target:\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            command = self.command_builder.build_directory_listing_command(self.main_target, self.target_pattern)\n            output, error, exit_status = ssh_manager.execute_command(command)\n            \n            if exit_status == 0 and output:\n                # Split the output into a list of file names\n                file_list = output.strip().split(\"\\n\")\n                # Prepend the main_target (directory path) to each file name\n                full_file_paths = [f\"{self.main_target}/{file_name}\" for file_name in file_list]\n                return ExecutionResult(success=True, output=json.dumps(full_file_paths))\n            \n            return ExecutionResult(success=False)\n        \n        except Exception as e:\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def run_command(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if self.sub_target or self.target_pattern:\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            if self.os_type == \"linux\":  # for test use, need to be revised\n                command = f\"export LC_ALL=C && echo {ssh_manager.password} | sudo -S {self.main_target}\"  # dynamically insert the password\n            output, error, exit_status = ssh_manager.execute_command(command)\n            if output is not None and len(str(output).strip()) > 0 and error is not None and len(str(error).strip()) > 0:\n                return ExecutionResult(success=True, output=output.strip() + \"\\n\" + error.strip())\n            if output is not None and len(str(output).strip()) > 0:\n                return ExecutionResult(success=True, output=output.strip())\n            else:\n                if error is not None and len(str(error).strip()) > 0:\n                    return ExecutionResult(success=True, output=error.strip())\n                else:\n                    return ExecutionResult(success=False, error=\"Command failed with no result\")\n        except Exception as e:\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def check_process_existence(self, ssh_manager: SSHManager) -> ExecutionResult:\n        if self.sub_target or self.target_pattern:\n            return ExecutionResult(success=False, error=ExecutionError.INVALID_CONFIGURATION.value[1])\n\n        try:\n            command = self.command_builder.build_process_check_command(self.main_target)\n            output, error, exit_status = ssh_manager.execute_command(command)\n            if exit_status == 0 and output:\n                return ExecutionResult(success=True, output=self.main_target)\n            return ExecutionResult(success=False, output=self.main_target)\n        except Exception as e:\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\n    def check_registry_key(self, ssh_manager: SSHManager) -> ExecutionResult:\n        try:\n            if not self.sub_target:\n                command = self.command_builder.build_registry_key_existence_command(self.main_target)\n            else:\n                command = self.command_builder.build_registry_check_command(self.main_target, self.sub_target)\n\n            output, error, exit_status = ssh_manager.execute_command(command)\n            if exit_status == 0 and output:\n                return ExecutionResult(success=True, output=output.strip())\n            return ExecutionResult(success=False, output=output.strip())\n        except Exception as e:\n            return ExecutionResult(success=False, error=f\"{ExecutionError.SSH_EXECUTION_FAILED.value[1]}: {str(e)}\")\n\nclass ContentCheckResult:\n    def __init__(self, success: bool, error: Optional[str] = None, details: Optional[str] = None):\n        self.success = success\n        self.error = error\n        self.details = details\n\n    def to_dict(self) -> Dict[str, Union[bool, Optional[str]]]:\n        return {\n            \"success\": self.success,\n            \"error\": self.error,\n            \"details\": self.details,\n        }\n\n    def __repr__(self):\n        return f\"ContentCheckResult(success={self.success}, error={self.error}, details={self.details})\"\n\nclass ContentRuleChecker:\n    def __init__(\n        self,\n        node_type: str,\n        content_rules: List[Dict],  # Now handling a list of content rules\n        ssh_manager: SSHManager,\n        command_builder: OSCommandBuilder,\n        os_type: str\n    ):\n        self.node_type = node_type\n        self.content_rules = content_rules  # Store all content rules\n        self.ssh_manager = ssh_manager\n        self.command_builder = command_builder\n        self.os_type = os_type\n\n    def check(self, content: Union[str, List[str]]) -> ContentCheckResult:\n        try:\n            if self.node_type == 'c':\n                return self.check_command_output(content)\n            elif self.node_type == 'f':\n                return self.check_file_content(content)\n            elif self.node_type in ['d', 'p']:\n                return ContentCheckResult(success=True)\n            else:\n                return ContentCheckResult(success=False, error=ExecutionError.INVALID_NODE_TYPE.value[1])\n        except Exception as e:\n            return ContentCheckResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def check_command_output(self, content: str) -> ContentCheckResult:\n        try:\n            print(f\"[DEBUG] Checking command output\")\n            print(f\"[DEBUG] Content to check:\\n{content}\")\n\n            return self._check_lines(content.splitlines())\n\n        except Exception as e:\n            return ContentCheckResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def check_file_content(self, content: Union[str, List[str]]) -> ContentCheckResult:\n        try:\n            if isinstance(content, str):\n                content = self._parse_content(content)\n\n            if isinstance(content, list):\n                if not content:\n                    return ContentCheckResult(success=False, error=\"No files matched the pattern.\")\n\n                results = []\n                for file_path in content:\n                    print(f\"[DEBUG] Reading and checking file: {file_path}\")\n                    result = self.read_and_check_file(file_path)\n                    if not result.success:\n                        print(f\"[DEBUG] Failed with file: {file_path}. Error: {result.error}\")\n                        results.append(False)\n                    else:\n                        results.append(result.success)\n\n                final_result = all(results)\n                return ContentCheckResult(success=final_result)\n\n            else:\n                return ContentCheckResult(success=False, error=ExecutionError.INVALID_FILE_RULE.value[1])\n\n        except Exception as e:\n            return ContentCheckResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def read_and_check_file(self, file_path: str) -> ContentCheckResult:\n        try:\n            print(f\"[DEBUG] Reading and checking file: {file_path}\")\n            command = self.command_builder.build_read_file_command(file_path)\n\n            if self.os_type == \"linux\":\n                command = f\"export LC_ALL=C && echo {self.ssh_manager.password} | sudo -S \" + command\n            output, error, exit_status = self.ssh_manager.execute_command(command)\n\n            if exit_status != 0:\n                print(f\"[DEBUG] Failed to read file. Error: {error}\")\n                return ContentCheckResult(success=False, error=f\"Failed to read file {file_path}: {error}\")\n\n            print(f\"[DEBUG] File content:\\n{output}\")\n\n            return self._check_lines(output.splitlines())\n\n        except Exception as e:\n            return ContentCheckResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n        \n    def _check_lines(self, lines: List[str]) -> ContentCheckResult:\n        # Iterate through each line in the content\n        for line in lines:\n            # Check if the line matches all rules\n            if all(self._check_line_against_rule(line, rule) for rule in self.content_rules):\n                print(f\"[DEBUG] Line matched all rules: {line}\")\n                return ContentCheckResult(success=True)\n\n        print(f\"[DEBUG] No line matched all rules\")\n        return ContentCheckResult(success=False)\n\n    def _check_line_against_rule(self, line: str, rule: Dict) -> bool:\n        content_operator = rule.get('content_operator')\n        value = rule.get('value')\n        negation = rule.get('negation', False)\n\n        if content_operator == 'r':\n            match = bool(re.search(value, line))\n            print(f\"[DEBUG] Regex match result: {match} for pattern: {value}\")\n\n        elif content_operator == 'n':\n            match = self.numeric_compare(line, value)\n            print(f\"[DEBUG] Numeric compare result: {match} for value: {value}\")\n\n        elif content_operator is None:\n            match = value in line\n            print(f\"[DEBUG] Substring match result: {match} for value: {value}\")\n\n        else:\n            print(f\"[DEBUG] Invalid content operator: {content_operator}\")\n            return False\n\n        # Apply negation if required\n        if negation:\n            match = not match\n            print(f\"[DEBUG] Negation applied. Final match result: {match}\")\n\n        return match\n\n    def numeric_compare(self, content: str, value: str) -> bool:\n        try:\n            print(f\"[DEBUG] Performing numeric comparison on content: {content}\")\n            match = re.search(value, content)\n            if not match:\n                print(f\"[DEBUG] No numeric match found for value: {value}\")\n                return False\n\n            number = int(match.group(1))\n            compare_value = int(self.compare_value)\n            print(f\"[DEBUG] Extracted number: {number}, Compare value: {compare_value}\")\n\n            if self.compare_operator == '>':\n                return number > compare_value\n            elif self.compare_operator == '>=':\n                return number >= compare_value\n            elif self.compare_operator == '<':\n                return number < compare_value\n            elif self.compare_operator == '<=':\n                return number <= compare_value\n            elif self.compare_operator == '==':\n                return number == compare_value\n            elif self.compare_operator == '!=':\n                return number != compare_value\n            else:\n                print(f\"[DEBUG] Invalid compare operator: {self.compare_operator}\")\n                return False\n        except Exception as e:\n            raise ValueError(f\"{ExecutionError.INVALID_COMPARE_EXPRESSION.value[1]}: {str(e)}\")\n\n    def _parse_content(self, content: str) -> List[str]:\n        try:\n            content_list = json.loads(content)\n            if isinstance(content_list, list):\n                return content_list\n            else:\n                print(f\"[DEBUG] Parsed content is not a list: {content_list}\")\n                return [content]\n        except json.JSONDecodeError:\n            print(f\"[DEBUG] Content is a single file path, not a JSON list: {content}\")\n            return [content]\n\nclass SemanticTreeExecutionResult:\n    def __init__(self, success: bool, results: Optional[Dict[str, Any]] = None, error: Optional[str] = None):\n        self.success = success\n        self.results = results if results is not None else {}\n        self.error = error\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"success\": self.success,\n            \"results\": self.results,\n            \"error\": self.error\n        }\n\n    def __repr__(self):\n        return f\"SemanticTreeExecutionResult(success={self.success}, results={self.results}, error={self.error})\"\n\nclass SemanticTreeExecutor:\n    def __init__(self, hostname: str, username: str, password: str, port: int = 22):\n        self.ssh_manager = SSHManager(hostname, username, password, port)\n\n    def connect(self) -> bool:\n        try:\n            self.ssh_manager.connect()\n            return True\n        except Exception as e:\n            print(f\"Failed to connect to {self.ssh_manager.hostname}: {str(e)}\")\n            return False\n\n    def execute_tree(self, semantic_tree: Dict) -> SemanticTreeExecutionResult:\n        # Attempt to connect to the SSH server\n        if not self.connect():\n            return SemanticTreeExecutionResult(success=False, error='Failed to connect to SSH')\n\n        results = {}\n        checks = semantic_tree.get('checks', [])\n        # Default to 'linux' if not provided\n        os_type = semantic_tree.get('os_type', 'linux')\n\n        for check in checks:\n            check_id = check['id']\n            condition = check['condition']\n\n            print(f\"\\n--- Executing check ID: {check_id} with condition: {condition} ---\")\n\n            rule_results = self._execute_rules(check['rules'], os_type)\n            if isinstance(rule_results, SemanticTreeExecutionResult):\n                # If an error occurred during rule execution, return it immediately\n                self.ssh_manager.close()\n                return rule_results\n\n            # Print all rule results for this check ID\n            print(f\"[DEBUG] Rule results for check ID {check_id}: {rule_results}\")\n\n            # Determine the final check result based on the condition\n            check_pass = self._evaluate_condition(condition, rule_results)\n            if check_pass is None:\n                self.ssh_manager.close()\n                return SemanticTreeExecutionResult(\n                    success=False,\n                    error=f\"Invalid condition specified at check ID {check_id}\"\n                )\n\n            # Store the check result with rule details and condition\n            results[check_id] = {\n                'result': 'pass' if check_pass else 'fail',\n                'condition': condition,\n                'rule_results': rule_results\n            }\n\n            print(f\"Check ID: {check_id} result: {results[check_id]['result']}\")\n\n        # Close the SSH connection after all checks\n        self.ssh_manager.close()\n        return SemanticTreeExecutionResult(success=True, results=results)\n\n\n    def _execute_rules(self, rules: List[Dict], os_type: str) -> Union[List[bool], SemanticTreeExecutionResult]:\n        rule_results = []\n        for rule in rules:\n            exec_node = rule['execution_node']\n            print(f\"\\nExecuting rule with execution node: {exec_node}\")\n\n            execution_result = self._execute_node(exec_node, os_type)\n            if not execution_result.success:\n\n                print(f\"Execution failed for rule {exec_node}: {execution_result.error}\")\n                rule_results.append(False)\n                continue\n\n            if exec_node['type'] == 'd' and 'file_rules' in rule:\n                file_rule_results = self._process_file_rules(rule['file_rules'], execution_result.output, os_type)\n                if isinstance(file_rule_results, SemanticTreeExecutionResult):\n                    return file_rule_results\n                rule_results.extend(file_rule_results)\n            else:\n                content_check_result = self._check_content_rules(rule, execution_result.output, os_type)\n                if isinstance(content_check_result, SemanticTreeExecutionResult):\n                    return content_check_result\n                rule_results.append(content_check_result)\n\n        return rule_results\n\n    def _execute_node(self, exec_node: Dict, os_type: str) -> ExecutionResult:\n        executor = ExecutionNodeExecutor(\n            node_type=exec_node['type'],\n            main_target=exec_node['main_target'],\n            sub_target=exec_node.get('sub_target'),\n            target_pattern=exec_node.get('target_pattern'),\n            os_type=os_type,\n        )\n        execution_result = executor.execute(self.ssh_manager)\n        print(f\"Execution result: {execution_result.to_dict()}\")\n        return execution_result\n\n    def _process_file_rules(self, file_rules: List[Dict], directory_output: str, os_type: str) -> Union[List[bool], SemanticTreeExecutionResult]:\n        file_rule_results = []\n        for file_rule in file_rules:\n            exec_node = file_rule['execution_node']\n\n            execution_result = self._execute_node(exec_node, os_type)\n            if not execution_result.success:\n\n                print(f\"Execution failed for file rule {exec_node}: {execution_result.error}\")\n                file_rule_results.append(False)\n                continue\n\n            content_check_result = self._check_content_rules(file_rule, execution_result.output, os_type)\n            if isinstance(content_check_result, SemanticTreeExecutionResult):\n                return content_check_result\n            file_rule_results.append(content_check_result)\n\n        return file_rule_results\n\n    def _check_content_rules(self, rule: Dict, exec_output: str, os_type: str) -> Union[bool, SemanticTreeExecutionResult]:\n        try:\n            # Initialize the ContentRuleChecker with all content_rules\n            checker = ContentRuleChecker(\n                node_type=rule['execution_node']['type'],\n                content_rules=rule.get('content_rules', []),\n                ssh_manager=self.ssh_manager,\n                command_builder=OSCommandBuilder(os_type),\n                os_type=os_type\n            )\n\n            content_result = checker.check(exec_output)\n            print(f\"Content result: {content_result.to_dict()}\")\n\n            if not content_result.success:\n                print(f\"Content check failed for rule {rule['execution_node']}: {content_result.error}\")\n                return False\n\n            return not content_result.success if rule['negation'] else content_result.success\n\n        except Exception as e:\n            return SemanticTreeExecutionResult(success=False, error=f\"{ExecutionError.UNKNOWN_ERROR.value[1]}: {str(e)}\")\n\n    def _evaluate_condition(self, condition: str, rule_results: List[bool]) -> Optional[bool]:\n        if condition == 'all':\n            return all(rule_results)\n        elif condition == 'any':\n            return any(rule_results)\n        elif condition == 'none':\n            return not any(rule_results)\n        else:\n            print(f\"Invalid condition: {condition}\")\n            return None\n\ndef debug_print(message: str):\n    \"\"\"\n    Print a debug message in a structured format.\n    \"\"\"\n    print(f\"[DEBUG] {message}\")"}
