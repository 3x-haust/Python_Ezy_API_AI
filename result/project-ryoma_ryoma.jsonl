{"repo_info": {"repo_name": "ryoma", "repo_owner": "project-ryoma", "repo_url": "https://github.com/project-ryoma/ryoma"}}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/test_catalog.py", "content": "from ryoma_ai.datasource.metadata import Catalog\n\ndata = {\n    \"catalog_name\": \"main\",\n    \"schemas\": [\n        {\n            \"schema_name\": \"\",\n            \"tables\": [\n                {\n                    \"table_name\": \"author\",\n                    \"columns\": [\n                        {\"name\": \"aid\", \"type\": \"INT\", \"nullable\": 1},\n                        {\"name\": \"homepage\", \"type\": \"TEXT\", \"nullable\": 1},\n                        {\"name\": \"name\", \"type\": \"TEXT\", \"nullable\": 1},\n                        {\"name\": \"oid\", \"type\": \"INT\", \"nullable\": 1},\n                    ],\n                }\n            ],\n        }\n    ],\n}\n\n\ndef test_catalog_model():\n    catalog = Catalog(**data)\n    assert catalog.catalog_name == \"main\"\n    assert len(catalog.schemas) == 1\n    assert catalog.schemas[0].schema_name == \"\"\n    assert len(catalog.schemas[0].tables) == 1\n"}
{"type": "test_file", "path": "tests/unit_tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/test_agent.py", "content": "import os\n\nimport openai\nimport openai_responses\nimport pytest\nfrom openai_responses import OpenAIMock\nfrom ryoma_ai.agent.base import BaseAgent\n\nfrom tests.unit_tests.test_utils import (\n    create_chat_completion_response_stream,\n    mock_chat_response,\n)\n\n\n@pytest.fixture(autouse=True)\ndef mock_openai_api_key(monkeypatch):\n    monkeypatch.setenv(\"OPENAI_API_KEY\", \"foo\")\n\n\n@openai_responses.mock()\ndef test_create_chat_completion_stream(openai_mock: OpenAIMock):\n    openai_mock.chat.completions.create.response = (\n        create_chat_completion_response_stream\n    )\n\n    client = openai.Client(api_key=\"sk-fake123\")\n    completion = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\"role\": \"user\", \"content\": \"Hello!\"},\n        ],\n        stream=True,\n    )\n\n    received_chunks = 0\n\n    for chunk in completion:\n        received_chunks += 1\n        assert chunk.id\n\n    assert received_chunks == 3\n\n\n@pytest.fixture\ndef agent():\n    return BaseAgent(\"gpt-3.5-turbo\")\n\n\n@openai_responses.mock()\ndef test_chat(agent, openai_mock: OpenAIMock):\n    openai_mock.chat.completions.create.response = mock_chat_response(\"Hello, world!\")\n    chat_response = agent.invoke(\"Hello, world!\", display=False)\n    assert chat_response.content == \"Hello, world!\"\n"}
{"type": "test_file", "path": "tests/unit_tests/datasource/test_duckdb.py", "content": "import pandas as pd\nimport pytest\nfrom ryoma_ai.datasource.duckdb import DuckDBDataSource\n\n\n@pytest.fixture\ndef test_pandas_df():\n    return pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n\n\ndef test_query_with_register(test_pandas_df):\n    data_source = DuckDBDataSource()\n    data_source.register(\"pdf\", test_pandas_df)\n    query = \"SELECT * FROM pdf\"\n    result = data_source.query(query)\n    assert result.shape == test_pandas_df.shape\n\n\ndef test_query(test_pandas_df):\n    data_source = DuckDBDataSource()\n    pdf = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n    result = data_source.query(\"SELECT * FROM pdf\", pdf=pdf)\n    assert result.shape == test_pandas_df.shape\n"}
{"type": "test_file", "path": "tests/e2e/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/test_tool.py", "content": "from unittest.mock import patch\n\nimport pandas as pd\nimport pytest\nfrom pyspark.sql import SparkSession\nfrom ryoma_ai.tool.pandas_tool import PandasTool\nfrom ryoma_ai.tool.spark_tool import SparkTool\nfrom ryoma_ai.tool.sql_tool import SqlQueryTool\n\nfrom tests.unit_tests.test_datasource import MockSqlDataSource\n\n\n@pytest.fixture\ndef pandas_dataframe():\n    df = pd.DataFrame(\n        {\n            \"year\": [2020, 2022, 2019, 2021],\n            \"n_legs\": [2, 4, 5, 100],\n            \"animals\": [\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"],\n        }\n    )\n    return df\n\n\n@pytest.fixture\ndef mock_sql_data_source():\n    data_source = MockSqlDataSource()\n    return data_source\n\n\n@pytest.fixture\ndef pyspark_session():\n    return SparkSession.builder.appName(\"pytest\").getOrCreate()\n\n\ndef test_pyspark_tool(pyspark_session, pandas_dataframe):\n    pyspark_tool = SparkTool()\n    pyspark_tool.update_script_context(\n        {\"spark_session\": pyspark_session, \"df\": pandas_dataframe}\n    )\n    script = \"\"\"\n    spark_session.createDataFrame(df).show()\n    \"\"\"\n    result = pyspark_tool._run(script)\n    assert result.success is True\n\n\ndef test_sql_tool(mock_sql_data_source):\n    with patch(\"ryoma_ai.datasource.base.SqlDataSource.query\") as mock_execute:\n        mock_execute.return_value = \"success\"\n        sql_tool = SqlQueryTool(datasource=mock_sql_data_source)\n        query = \"SELECT * FROM customers LIMIT 4\"\n        result, _ = sql_tool._run(query)\n        assert result == \"success\"\n\n\ndef test_pandas_tool(pandas_dataframe):\n    pandas_tool = PandasTool()\n    pandas_tool.update_script_context({\"df\": pandas_dataframe})\n    script = \"\"\"\n    df[\"year\"] = df[\"year\"] + 1\n    df\n    \"\"\"\n    result = pandas_tool._run(script)\n    assert result.success is True\n    assert result.result[\"year\"].tolist() == [2021, 2023, 2020, 2022]\n"}
{"type": "test_file", "path": "tests/unit_tests/test_datasource.py", "content": "from typing import Any\nfrom unittest.mock import MagicMock, patch\n\nimport pytest\nfrom ryoma_ai.datasource.base import SqlDataSource\nfrom ryoma_ai.datasource.metadata import Catalog\n\n\nclass MockSqlDataSource(SqlDataSource):\n    def get_query_plan(self, query: str) -> Any:\n        pass\n\n    def crawl_metadata(self, **kwargs):\n        pass\n\n    def _connect(self) -> Any:\n        mock_connection = MagicMock()\n        mock_cursor = MagicMock()\n        mock_cursor.fetchall.return_value = [(\"result1\",), (\"result2\",)]\n        mock_cursor.execute.return_value = None\n        mock_connection.cursor.return_value = mock_cursor\n        return mock_connection\n\n    def get_catalog(self, **kwargs) -> Catalog:\n        return Catalog()\n\n\n@pytest.fixture\ndef mock_sql_data_source():\n    data_source = MockSqlDataSource()\n    return data_source\n\n\ndef test_execute_query(mock_sql_data_source):\n    with patch(\"ryoma_ai.datasource.base.SqlDataSource.query\") as mock_execute:\n        mock_execute.return_value = \"success\"\n        results = mock_sql_data_source.query(\"SELECT * FROM table\")\n    assert results == \"success\"\n\n\ndef test_sql_datasource_field_exists(mock_sql_data_source):\n    assert hasattr(mock_sql_data_source, \"database\")\n    assert hasattr(mock_sql_data_source, \"db_schema\")\n"}
{"type": "test_file", "path": "tests/e2e/test_datasource.py", "content": "import pytest\nfrom ryoma_ai.datasource.postgres import PostgresDataSource\nfrom sqlalchemy import create_engine\n\n\n@pytest.fixture\ndef postgres():\n    return PostgresDataSource(\n        user=\"\",\n        password=\"\",\n        host=\"localhost\",\n        port=5432,\n        database=\"postgres\",\n        db_schema=\"public\",\n    )\n\n\ndef test_postgres_connection(postgres):\n    conn = postgres.connect()\n    assert conn is not None\n\n\ndef test_postgres_get_metadata(postgres):\n    metadata = postgres.get_catalog()\n    assert metadata is not None\n    assert len(metadata.tables) > 0\n\n\ndef test_postgres_connection_string(postgres):\n    conn_str = postgres.connection_string()\n    engine = create_engine(conn_str)\n    conn = engine.connect()\n    assert conn is not None\n    conn.close()\n"}
{"type": "test_file", "path": "tests/e2e/test_agent.py", "content": "import os\n\nimport pytest\nfrom ryoma_ai.agent.base import BaseAgent\nfrom ryoma_ai.agent.sql import SqlAgent\n\n\n@pytest.fixture(autouse=True)\ndef setup_openai_api_key():\n    # Check if OPENAI_API_KEY is set in the environment\n    if \"OPENAI_API_KEY\" not in os.environ:\n        pytest.skip(\"OPENAI_API_KEY not set in environment variables\")\n\n\ndef test_base_agent():\n    # Create an simple ryoma_ai Agent with GPT-3.5-turbo model\n    ryoma_agent = BaseAgent(\"gpt-3.5-turbo\")\n    result = ryoma_agent.stream(\n        \"I want to get the top 5 customers which making the most purchases\"\n    )\n    assert result is not None\n\n\ndef test_workflow_agent():\n    # Create an simple ryoma_ai Agent with GPT-3.5-turbo model\n    ryoma_agent = SqlAgent(\"gpt-3.5-turbo\")\n    result = ryoma_agent.stream(\n        \"I want to get the top 5 customers which making the most purchases\"\n    )\n    assert result is not None\n"}
{"type": "test_file", "path": "tests/unit_tests/test_utils.py", "content": "import os\nfrom datetime import datetime\nfrom typing import Dict, Generator\n\nfrom openai.types.chat import ChatCompletionChunk, ChatCompletionMessage\nfrom openai.types.chat.chat_completion import ChatCompletion, Choice\nfrom openai_responses.ext.httpx import Request, Response\nfrom openai_responses.streaming import EventStream\nfrom typing_extensions import override\n\nos.environ[\"OPENAI_API_KEY\"] = \"foo\"\n\n\ndef mock_chat_response(content: str, additional_kwargs: Dict = None):\n    if additional_kwargs is None:\n        additional_kwargs = {}\n    return ChatCompletion(\n        id=\"foo\",\n        model=\"gpt-4\",\n        object=\"chat.completion\",\n        choices=[\n            Choice(\n                finish_reason=\"stop\",\n                index=0,\n                message=ChatCompletionMessage(\n                    content=content,\n                    role=\"assistant\",\n                ),\n            )\n        ],\n        created=int(datetime.now().timestamp()),\n        additional_kwargs=additional_kwargs,\n    )\n\n\nclass CreateChatCompletionEventStream(EventStream):  #\n    @override\n    def generate(self) -> Generator[ChatCompletionChunk, None, None]:  #\n        yield ChatCompletionChunk.model_validate(\n            {\n                \"id\": \"chatcmpl-123\",\n                \"object\": \"chat.completion.chunk\",\n                \"created\": 1694268190,\n                \"model\": \"gpt-4o\",\n                \"system_fingerprint\": \"fp_44709d6fcb\",\n                \"choices\": [\n                    {\n                        \"index\": 0,\n                        \"delta\": {\"role\": \"assistant\", \"content\": \"\"},\n                        \"logprobs\": None,\n                        \"finish_reason\": None,\n                    }\n                ],\n            }\n        )\n\n        yield ChatCompletionChunk.model_validate(\n            {\n                \"id\": \"chatcmpl-123\",\n                \"object\": \"chat.completion.chunk\",\n                \"created\": 1694268190,\n                \"model\": \"gpt-4o\",\n                \"system_fingerprint\": \"fp_44709d6fcb\",\n                \"choices\": [\n                    {\n                        \"index\": 0,\n                        \"delta\": {\"content\": \"Hello\"},\n                        \"logprobs\": None,\n                        \"finish_reason\": None,\n                    }\n                ],\n            }\n        )\n\n        yield ChatCompletionChunk.model_validate(\n            {\n                \"id\": \"chatcmpl-123\",\n                \"object\": \"chat.completion.chunk\",\n                \"created\": 1694268190,\n                \"model\": \"gpt-4o\",\n                \"system_fingerprint\": \"fp_44709d6fcb\",\n                \"choices\": [\n                    {\"index\": 0, \"delta\": {}, \"logprobs\": None, \"finish_reason\": \"stop\"}\n                ],\n            }\n        )\n\n\nclass CreateChatCompletionEventStreamWithToolCall(EventStream):\n    @override\n    def generate(self) -> Generator[ChatCompletionChunk, None, None]:\n        yield ChatCompletionChunk.model_validate(\n            {\n                \"id\": \"chatcmpl-123\",\n                \"object\": \"chat.completion.chunk\",\n                \"created\": 1694268190,\n                \"model\": \"gpt-4o\",\n                \"system_fingerprint\": \"fp_44709d6fcb\",\n                \"choices\": [\n                    {\n                        \"index\": 0,\n                        \"delta\": {\"role\": \"assistant\", \"content\": \"\"},\n                        \"logprobs\": None,\n                        \"finish_reason\": None,\n                    }\n                ],\n                \"additional_kwargs\": {\n                    \"tool_calls\": [\n                        {\n                            \"function\": {\n                                \"name\": \"sql_database_query\",\n                                \"arguments\": {\n                                    \"query\": \"SELECT * FROM customers LIMIT 4\"\n                                },\n                            }\n                        }\n                    ]\n                },\n            }\n        )\n\n\ndef create_chat_completion_response_stream(request: Request) -> Response:\n    stream = CreateChatCompletionEventStream()\n    return Response(201, content=stream)\n\n\ndef create_chat_completion_response_with_tool_call(request: Request) -> Response:\n    stream = CreateChatCompletionEventStreamWithToolCall()\n    return Response(201, content=stream)\n"}
{"type": "test_file", "path": "tests/unit_tests/test_prompt_template.py", "content": "from ryoma_ai.prompt.prompt_template import PromptTemplateFactory\n\n\ndef test_base_prompt_template():\n    ryoma_prompt = PromptTemplateFactory()\n    ryoma_prompt.set_base_prompt(\"This is a test prompt.\")\n    template = ryoma_prompt.build_prompt()\n    messages = template.format_messages()\n    assert messages[0].content == \"This is a test prompt.\"\n\n\ndef test_prompt_template():\n    ryoma_prompt = PromptTemplateFactory()\n    ryoma_prompt.add_context_prompt(\n        \"You are provided with the following context: {prompt_context}\"\n    )\n    template = ryoma_prompt.build_prompt()\n    messages = template.format_messages(prompt_context=\"This is a test context.\")\n    assert (\n        messages[1].content\n        == \"You are provided with the following context: This is a test context.\"\n    )\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/bigquery.py", "content": "import logging\nfrom typing import Optional\n\nimport ibis\nfrom databuilder.job.job import DefaultJob\nfrom databuilder.loader.base_loader import Loader\nfrom databuilder.task.task import DefaultTask\nfrom ibis import BaseBackend\nfrom langchain_core.pydantic_v1 import Field\nfrom pyhocon import ConfigFactory\nfrom ryoma_ai.datasource.base import SqlDataSource\n\n\nclass BigqueryDataSource(SqlDataSource):\n    project_id: str = Field(..., description=\"Bigquery current_store ID\")\n    dataset_id: str = Field(..., description=\"Bigquery dataset ID\")\n    credentials: Optional[str] = Field(None, description=\"Path to the credentials file\")\n\n    def _connect(self, **kwargs) -> BaseBackend:\n        return ibis.bigquery.connect(\n            project_id=self.project_id,\n            dataset_id=self.dataset_id,\n            credentials=self.credentials,\n            **kwargs,\n        )\n\n    def crawl_metadata(self, loader: Loader, where_clause_suffix: Optional[str] = \"\"):\n        from databuilder.extractor.bigquery_metadata_extractor import (\n            BigQueryMetadataExtractor,\n        )\n\n        logging.info(\"Crawling data catalog from Bigquery\")\n        job_config = ConfigFactory.from_dict(\n            {\n                \"extractor.bigquery_table_metadata.{}\".format(\n                    BigQueryMetadataExtractor.PROJECT_ID_KEY\n                )\n            }\n        )\n        job = DefaultJob(\n            conf=job_config,\n            task=DefaultTask(extractor=BigQueryMetadataExtractor(), loader=loader),\n        )\n\n        job.launch()\n"}
{"type": "source_file", "path": "example/example_arrow.py", "content": "# write an arrow ADBC connect to postgresql and ingest data into it\n\nimport pyarrow as pa\n\n# create a table\ntable = pa.table({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n\n# adbc connection\nfrom adbc_driver_postgres.dbapi import connect\n\nconnection = connect(\"postgresql://localhost:5432/postgres\")\n\n# ingest data\ncursor = connection.cursor()\ncursor.adbc_ingest(\"table_name\", table)\nconnection.commit()\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/__init__.py", "content": ""}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/embedding.py", "content": "import logging\nfrom typing import Dict, List, Optional, Union\n\nfrom langchain_core.documents import Document\nfrom langchain_core.embeddings import Embeddings\nfrom ryoma_ai.agent.base import RyomaAgent\nfrom ryoma_ai.agent.utils import load_model_provider\nfrom ryoma_ai.models.agent import AgentType\n\n\nclass EmbeddingAgent(RyomaAgent):\n    type: str = AgentType.embedding\n    description: str = \"Simple Embedding Agent\"\n\n    def __init__(self, model, model_parameters: Optional[Dict] = None):\n        logging.info(f\"Initializing Embedding Agent with model: {model}\")\n        self.embedding: Embeddings = load_model_provider(\n            model, \"embedding\", model_parameters=model_parameters\n        )\n\n    def embed_documents(self, texts: List[Document]) -> List[List[float]]:\n        return self.embedding.embed_documents([text.page_content for text in texts])\n\n    def embed_query(self, text: Union[Document, str]) -> List[float]:\n        text = text.page_content if isinstance(text, Document) else text\n        return self.embedding.embed_query(text)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/base.py", "content": "import logging\nimport uuid\nfrom typing import Any, Dict, Optional, Union\n\nfrom langchain_core.exceptions import OutputParserException\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langchain_core.output_parsers import PydanticOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate\nfrom langchain_core.runnables import RunnableSerializable\nfrom pydantic import BaseModel\nfrom ryoma_ai.agent.utils import load_model_provider\nfrom ryoma_ai.datasource.base import DataSource\nfrom ryoma_ai.datasource.metadata import Catalog\nfrom ryoma_ai.models.agent import AgentType\nfrom ryoma_ai.prompt.prompt_template import PromptTemplateFactory\n\n\nclass RyomaAgent:\n    \"\"\"\n    Base class for all agents in Ryoma. Inherits from this class can be used to create custom agents.\n    \"\"\"\n\n    type: AgentType = AgentType.ryoma\n    description: str = \"Ryoma Agent is your best friend!\"\n\n\nclass BaseAgent(RyomaAgent):\n    type: AgentType = AgentType.base\n    description: str = (\n        \"Base Agent supports all the basic functionalities of a chat agent.\"\n    )\n    config: Dict[str, Any]\n    model: RunnableSerializable\n    model_parameters: Optional[Dict]\n    prompt_template_factory: PromptTemplateFactory\n    final_prompt_template: Optional[Union[PromptTemplate, ChatPromptTemplate]]\n    output_parser: Optional[PydanticOutputParser]\n\n    def __init__(\n        self,\n        model: Union[str, RunnableSerializable],\n        model_parameters: Optional[Dict] = None,\n        base_prompt_template: Optional[PromptTemplate] = None,\n        context_prompt_templates: Optional[list[PromptTemplate]] = None,\n        output_prompt_template: Optional[PromptTemplate] = None,\n        output_parser: Optional[BaseModel] = None,\n        **kwargs,\n    ):\n        logging.info(f\"Initializing Agent with model: {model}\")\n\n        # configs\n        self.config = {\n            \"configurable\": {\n                \"user_id\": kwargs.get(\"user_id\", str(uuid.uuid4())),\n                \"thread_id\": kwargs.get(\"thread_id\", str(uuid.uuid4())),\n            }\n        }\n\n        # model\n        self.model_parameters = model_parameters\n        if isinstance(model, str):\n            self.model: RunnableSerializable = load_model_provider(\n                model, model_parameters=model_parameters\n            )\n        else:\n            self.model = model\n\n        # prompt\n        self.prompt_template_factory = PromptTemplateFactory(\n            base_prompt_template,\n            context_prompt_templates,\n            output_prompt_template,\n        )\n        self.final_prompt_template = self.prompt_template_factory.build_prompt()\n        self.output_parser = output_parser\n\n    def _build_chain(self, **kwargs) -> RunnableSerializable:\n        if not self.model:\n            raise ValueError(\n                f\"Unable to initialize model, please ensure you have valid configurations.\"\n            )\n        self.final_prompt_template = self.prompt_template_factory.build_prompt()\n        if self.output_parser:\n            return self.output_prompt | self.model | self.output_parser\n        return self.final_prompt_template | self.model\n\n    def set_base_prompt(\n        self, base_prompt: Optional[Union[str, ChatPromptTemplate]] = None\n    ):\n        self.prompt_template_factory.set_base_prompt(base_prompt)\n        return self\n\n    def set_context_prompt(\n        self, context: Optional[Union[str, ChatPromptTemplate]] = None\n    ):\n        self.prompt_template_factory.add_context_prompt(context)\n        return self\n\n    def add_prompt_context(self, prompt_context: str):\n        self.prompt_template_factory.add_context_prompt(prompt_context)\n        return self\n\n    def add_datasource(self, datasource: DataSource):\n        self.add_prompt_context(str(datasource.get_catalog()))\n        self.final_prompt_template = self.prompt_template_factory.build_prompt()\n        return self\n\n    def add_data_catalog(self, catalog: Catalog):\n        self.add_prompt_context(str(catalog))\n        self.final_prompt_template = self.prompt_template_factory.build_prompt()\n        return self\n\n    def _format_messages(self, messages: str):\n        return {\"messages\": [HumanMessage(content=messages)]}\n\n    def stream(self, question: Optional[str] = \"\", display: Optional[bool] = True):\n        messages = self._format_messages(question)\n        chain = self._build_chain()\n        events = chain.stream(messages, self.config)\n        if display:\n            for event in events:\n                print(event.content, end=\"\", flush=True)\n        if self.output_parser:\n            chain = self.output_prompt | self.model | self.output_parser\n            events = self._parse_output(chain, events)\n        return events\n\n    def invoke(self, question: Optional[str] = \"\", display: Optional[bool] = True):\n        messages = self._format_messages(question)\n        chain = self._build_chain()\n        results = chain.invoke(messages, self.config)\n        if display:\n            for result in results:\n                print(result.content, end=\"\", flush=True)\n        if self.output_parser:\n            chain = self.output_prompt | self.model | self.output_parser\n            results = self._parse_output(chain, results)\n        return results\n\n    def get_current_state(self) -> None:\n        return None\n\n    def _parse_output(self, chain, result: dict, max_iterations=10):\n        iteration = 0\n        while iteration < max_iterations:\n            iteration += 1\n            try:\n                return chain.invoke({\"messages\": result[\"messages\"]}, self.config)\n            except OutputParserException as e:\n                result[\"messages\"] += [\n                    AIMessage(\n                        content=f\"Error: {repr(e)}\\n please fix your mistakes.\",\n                    )\n                ]\n        return result\n\n    def set_output_parser(self, output_parser: BaseModel):\n        self.output_parser = PydanticOutputParser(pydantic_object=output_parser)\n        self.output_prompt = PromptTemplate(\n            template=\"Return output in required format with given messages.\\n{format_instructions}\\n{messages}\\n\",\n            input_variables=[\"messages\"],\n            partial_variables={\n                \"format_instructions\": self.output_parser.get_format_instructions()\n            },\n        )\n        return self\n"}
{"type": "source_file", "path": "example/file_example.py", "content": "from ryoma_ai.datasource.file import FileDataSource\n\nf = FileDataSource(\"./creditcard.csv\")\n\nds = f.to_arrow(format=\"csv\")\n\nds.to_table()\n"}
{"type": "source_file", "path": "alembic/env.py", "content": "from logging.config import fileConfig\n\nfrom sqlalchemy import engine_from_config, pool\n\nfrom alembic import context\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\ntarget_metadata = None\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section, {}),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n    )\n\n    with connectable.connect() as connection:\n        context.configure(connection=connection, target_metadata=target_metadata)\n\n        with context.begin_transaction():\n            context.run_migrations()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/pandas_agent.py", "content": "from typing import Dict\n\nfrom pandas import DataFrame\nfrom ryoma_ai.agent.workflow import WorkflowAgent\nfrom ryoma_ai.tool.pandas_tool import PandasTool\nfrom ryoma_ai.tool.python_tool import PythonTool\n\n\nclass PandasAgent(WorkflowAgent):\n    description: str = (\n        \"A pandas agent that can use pandas tools to interact with pandas DataFrames.\"\n    )\n\n    def __init__(self, model: str, model_parameters: Dict = None):\n        super().__init__(\n            [\n                PandasTool(),\n            ],\n            model,\n            model_parameters,\n        )\n\n    def add_dataframe(self, dataframe: DataFrame):\n        df_id = f\"df_{id(dataframe)}\"\n        self.add_prompt_context(\n            f\"\"\"\n        dataframe name: {df_id}\n        dataframe metadata: {dataframe.info}\n        \"\"\"\n        )\n        for tool in self.tools:\n            if isinstance(tool, PythonTool):\n                tool.update_script_context(script_context={df_id: dataframe})\n        return self\n"}
{"type": "source_file", "path": "example/example_langgraph.py", "content": "# from typing import Literal\n# from langchain_community.tools.tavily_search import TavilySearchResults\n# from langchain_core.runnables import ConfigurableField\n# from langchain_core.tools import tool\n# from langchain_openai import ChatOpenAI\n# from langgraph.prebuilt import create_react_agent\n# import asyncio\n#\n# @tool\n# def get_weather(city: Literal[\"nyc\", \"sf\"]):\n#     \"\"\"Use this to get weather information.\"\"\"\n#     if city == \"nyc\":\n#         return \"It might be cloudy in nyc\"\n#     elif city == \"sf\":\n#         return \"It's always sunny in sf\"\n#     else:\n#         raise AssertionError(\"Unknown city\")\n#\n#\n# tools = [get_weather]\n#\n# model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0, streaming=True)\n# graph = create_react_agent(model, tools)\n#\n# inputs = {\"messages\": [(\"human\", \"what's the weather in sf\")]}\n#\n#\n# async def main():\n#     async for event in graph.astream_events(inputs, version=\"v1\"):\n#         kind = event[\"event\"]\n#         if kind == \"on_chat_model_stream\":\n#             content = event[\"data\"][\"chunk\"].content\n#             if content:\n#                 # Empty content in the context of OpenAI or Anthropic usually means\n#                 # that the model is asking for a tool to be invoked.\n#                 # So we only print non-empty content\n#                 print(content, end=\"|\")\n#         elif kind == \"on_tool_start\":\n#             print(\"--\")\n#             print(\n#                 f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n#             )\n#         elif kind == \"on_tool_end\":\n#             print(f\"Done tool: {event['name']}\")\n#             print(f\"Tool output was: {event['data'].get('output')}\")\n#             print(\"--\")\n#\n# asyncio.run(main())\n\na = \"\"\"\nHere are the first 10 rows of the order data:\n\n| O_ORDERKEY | O_CUSTKEY | O_ORDERSTATUS | O_TOTALPRICE | O_ORDERDATE | O_ORDERPRIORITY | O_CLERK | O_SHIPPRIORITY | O_COMMENT |\n|------------|-----------|---------------|--------------|-------------|-----------------|---------|----------------|-----------|\n| 3000001 | 145618 | F | 30175.88 | 1992-12-17 | 4-NOT SPECIFIED | Clerk#000000141 | 0 | l packages. furiously careful instructions gro... |\n| 3000002 | 1481 | O | 297999.63 | 1995-07-28 | 1-URGENT | Clerk#000000547 | 0 | carefully unusual dependencie |\n| 3000003 | 127432 | O | 345438.38 | 1997-11-04 | 5-LOW | Clerk#000000488 | 0 | n packages boost slyly bold deposits. deposits... |\n| 3000004 | 47423 | O | 135965.53 | 1996-06-13 | 4-NOT SPECIFIED | Clerk#000000004 | 0 | nts wake carefully final decoys. quickly final... |\n| 3000005 | 84973 | F | 209937.09 | 1992-09-12 | 5-LOW | Clerk#000000030 | 0 | yly after the quickly unusual ide |\n| 3000006 | 135136 | O | 140186.32 | 1996-09-26 | 1-URGENT | Clerk#000000726 | 0 | ronic pinto beans use furiously final, slow no... |\n| 3000007 | 78841 | F | 298655.07 | 1992-04-13 | 5-LOW | Clerk#000000871 | 0 | ses eat. deposits wake |\n| 3000032 | 124576 | F | 175973.90 | 1992-03-02 | 1-URGENT | Clerk#000000460 | 0 | lar deposits mold carefully against the dep |\n| 3000033 | 30247 | F | 4635.38 | 1993-11-10 | 1-URGENT | Clerk#000000923 | 0 | mes special packages nag quickly. |\n| 3000034 | 5498 | F | 348308.79 | 1992-04-21 | 1-URGENT | Clerk#000000418 | 0 | lly final packages are slyly beyond the reques... |\n\"\"\"\nb = \"\"\nfor c in a:\n    b += c\n    print(b)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/__init__.py", "content": ""}
{"type": "source_file", "path": "alembic/versions/32c47e486eed_.py", "content": "\"\"\"empty message\n\nRevision ID: 32c47e486eed\nRevises: \nCreate Date: 2024-09-17 21:49:08.704108\n\n\"\"\"\n\nfrom typing import Sequence, Union\n\nimport sqlalchemy as sa\nimport sqlmodel\n\nfrom alembic import op\n\n# revision identifiers, used by Alembic.\nrevision: str = \"32c47e486eed\"\ndown_revision: Union[str, None] = None\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\n\ndef upgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table(\n        \"agent\",\n        sa.Column(\"id\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"description\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\n            \"type\",\n            sa.Enum(\n                \"ryoma\", \"base\", \"embedding\", \"workflow\", \"custom\", name=\"agenttype\"\n            ),\n            nullable=True,\n        ),\n        sa.Column(\"workflow\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"catalog\",\n        sa.Column(\"id\", sqlmodel.sql.sqltypes.AutoString(length=36), nullable=False),\n        sa.Column(\"datasource\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"catalog_name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"chat\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"title\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"user\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"question\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"answer\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"description\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"created_at\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"updated_at\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"datasource\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"type\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"connection_url\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"attributes\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"catalog_id\", sa.Integer(), nullable=True),\n        sa.Column(\"index_id\", sa.Integer(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"kernel\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"datasource\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"type\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"tool\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"output\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"prompttemplate\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"prompt_repr\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"k_shot\", sa.Integer(), nullable=False),\n        sa.Column(\"example_format\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"selector_type\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\n            \"prompt_template_name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False\n        ),\n        sa.Column(\"prompt_lines\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\n            \"prompt_template_type\", sqlmodel.sql.sqltypes.AutoString(), nullable=True\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"user\",\n        sa.Column(\"id\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"anonymous\", sa.Boolean(), nullable=False),\n        sa.Column(\"username\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"display_name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"initials\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"color\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"avatar_url\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"workspace\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"settings\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"permissions\", sa.JSON(), nullable=True),\n        sa.Column(\"email\", sa.String(length=320), nullable=False),\n        sa.Column(\"hashed_password\", sa.String(length=1024), nullable=False),\n        sa.Column(\"is_active\", sa.Boolean(), nullable=False),\n        sa.Column(\"is_superuser\", sa.Boolean(), nullable=False),\n        sa.Column(\"is_verified\", sa.Boolean(), nullable=False),\n        sa.PrimaryKeyConstraint(\"id\"),\n        sa.UniqueConstraint(\"username\"),\n    )\n    with op.batch_alter_table(\"user\", schema=None) as batch_op:\n        batch_op.create_index(batch_op.f(\"ix_user_email\"), [\"email\"], unique=True)\n\n    op.create_table(\n        \"vectorstore\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"project_name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"online_store\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\n            \"online_store_configs\", sqlmodel.sql.sqltypes.AutoString(), nullable=True\n        ),\n        sa.Column(\"offline_store\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\n            \"offline_store_configs\", sqlmodel.sql.sqltypes.AutoString(), nullable=True\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"oauth_account\",\n        sa.Column(\"id\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"user_id\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"oauth_name\", sa.String(length=100), nullable=False),\n        sa.Column(\"access_token\", sa.String(length=1024), nullable=False),\n        sa.Column(\"expires_at\", sa.Integer(), nullable=True),\n        sa.Column(\"refresh_token\", sa.String(length=1024), nullable=True),\n        sa.Column(\"account_id\", sa.String(length=320), nullable=False),\n        sa.Column(\"account_email\", sa.String(length=320), nullable=False),\n        sa.ForeignKeyConstraint(\n            [\"user_id\"],\n            [\"user.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    with op.batch_alter_table(\"oauth_account\", schema=None) as batch_op:\n        batch_op.create_index(\n            batch_op.f(\"ix_oauth_account_account_id\"), [\"account_id\"], unique=False\n        )\n        batch_op.create_index(\n            batch_op.f(\"ix_oauth_account_oauth_name\"), [\"oauth_name\"], unique=False\n        )\n\n    op.create_table(\n        \"schema\",\n        sa.Column(\"id\", sqlmodel.sql.sqltypes.AutoString(length=36), nullable=False),\n        sa.Column(\"schema_name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"catalog_id\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"catalog_id\"],\n            [\"catalog.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"table\",\n        sa.Column(\"id\", sqlmodel.sql.sqltypes.AutoString(length=36), nullable=False),\n        sa.Column(\"table_name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"description\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"is_view\", sa.Boolean(), nullable=True),\n        sa.Column(\"attrs\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"schema_id\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"schema_id\"],\n            [\"schema.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_table(\n        \"column\",\n        sa.Column(\"id\", sqlmodel.sql.sqltypes.AutoString(length=36), nullable=False),\n        sa.Column(\"name\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"type\", sqlmodel.sql.sqltypes.AutoString(), nullable=False),\n        sa.Column(\"description\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.Column(\"table_id\", sqlmodel.sql.sqltypes.AutoString(), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"table_id\"],\n            [\"table.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    # ### end Alembic commands ###\n\n\ndef downgrade() -> None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table(\"column\")\n    op.drop_table(\"table\")\n    op.drop_table(\"schema\")\n    with op.batch_alter_table(\"oauth_account\", schema=None) as batch_op:\n        batch_op.drop_index(batch_op.f(\"ix_oauth_account_oauth_name\"))\n        batch_op.drop_index(batch_op.f(\"ix_oauth_account_account_id\"))\n\n    op.drop_table(\"oauth_account\")\n    op.drop_table(\"vectorstore\")\n    with op.batch_alter_table(\"user\", schema=None) as batch_op:\n        batch_op.drop_index(batch_op.f(\"ix_user_email\"))\n\n    op.drop_table(\"user\")\n    op.drop_table(\"prompttemplate\")\n    op.drop_table(\"kernel\")\n    op.drop_table(\"datasource\")\n    op.drop_table(\"chat\")\n    op.drop_table(\"catalog\")\n    op.drop_table(\"agent\")\n    # ### end Alembic commands ###\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/utils.py", "content": "import logging\nfrom typing import Dict, Optional\n\nfrom jupyter_ai_magics.utils import (\n    AnyProvider,\n    decompose_model_id,\n    get_em_providers,\n    get_lm_providers,\n)\n\n\ndef load_model_provider(\n    model_id: str,\n    model_type: Optional[str] = \"chat\",\n    model_parameters: Optional[Dict] = None,\n) -> Optional[AnyProvider]:\n    \"\"\"\n    Get a model instance from a model_id string. This is using the jupyter ai magic library to load the\n    chat and embedding models dynamically.\n    @param model_id: str: The model id string.\n    @param model_type: model type can be either \"chat\" and \"embedding\".\n    @param model_parameters: Optional[Dict]: Additional parameters to pass to the model.\n    @return: Optional[AnyProvider]: The model instance.\n    \"\"\"\n    logging.info(\n        f\"Loading model provider with model id: {model_id}, model type: {model_type}\"\n    )\n    providers = get_lm_providers() if model_type == \"chat\" else get_em_providers()\n    provider_id, local_model_id = decompose_model_id(model_id, providers)\n\n    if provider_id is None or provider_id not in providers:\n        logging.info(f\"Provider id: {provider_id} not found in providers.\")\n        return None\n    Provider = providers[provider_id]\n    provider_params = {\"model_id\": local_model_id}\n    model_parameters = model_parameters or {}\n    return Provider(**provider_params, **model_parameters)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/sql.py", "content": "from typing import Dict, Optional\n\nfrom ryoma_ai.agent.workflow import WorkflowAgent\nfrom ryoma_ai.tool.sql_tool import CreateTableTool, QueryProfileTool, SqlQueryTool\n\n\nclass SqlAgent(WorkflowAgent):\n    description: str = (\n        \"A SQL agent that can use SQL Tools to interact with SQL schemas.\"\n    )\n\n    def __init__(\n        self,\n        model: str,\n        model_parameters: Optional[Dict] = None,\n    ):\n        super().__init__(\n            [SqlQueryTool(), CreateTableTool(), QueryProfileTool()],\n            model,\n            model_parameters,\n        )\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/factory.py", "content": "from enum import Enum\nfrom typing import Union\n\nfrom ryoma_ai.agent.arrow_agent import ArrowAgent\nfrom ryoma_ai.agent.base import BaseAgent\nfrom ryoma_ai.agent.embedding import EmbeddingAgent\nfrom ryoma_ai.agent.pandas_agent import PandasAgent\nfrom ryoma_ai.agent.python_agent import PythonAgent\nfrom ryoma_ai.agent.spark_agent import SparkAgent\nfrom ryoma_ai.agent.sql import SqlAgent\nfrom ryoma_ai.agent.workflow import WorkflowAgent\n\n\nclass AgentProvider(Enum):\n    base = BaseAgent\n    sql = SqlAgent\n    pandas = PandasAgent\n    pyarrow = ArrowAgent\n    pyspark = SparkAgent\n    python = PythonAgent\n    embedding = EmbeddingAgent\n\n\ndef get_builtin_agents():\n    return list(AgentProvider)\n\n\nclass AgentFactory:\n    @staticmethod\n    def create_agent(\n        agent_type: str, *args, **kwargs\n    ) -> Union[EmbeddingAgent, BaseAgent, WorkflowAgent]:\n        if not agent_type or not hasattr(AgentProvider, agent_type):\n            agent_class = BaseAgent\n        else:\n            agent_class = AgentProvider[agent_type].value\n        return agent_class(*args, **kwargs)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/spark_agent.py", "content": "import pandas as pd\nfrom ryoma_ai.agent.workflow import WorkflowAgent\nfrom ryoma_ai.tool.python_tool import PythonTool\nfrom ryoma_ai.tool.spark_tool import ConvertPandasToSparkTool, SparkTool\n\n\nclass SparkAgent(WorkflowAgent):\n    description: str = (\n        \"A PySpark agent that can use PySpark tools to run PySpark scripts.\"\n    )\n\n    def __init__(\n        self, spark_configs: dict[str, str], model: str, model_parameters=None\n    ):\n        self.spark_session = None\n        self.init_session(spark_configs)\n        super().__init__(\n            [\n                SparkTool(),\n                ConvertPandasToSparkTool(),\n            ],\n            model,\n            model_parameters,\n        )\n        for tool in self.tools:\n            if isinstance(tool, PythonTool):\n                tool.update_script_context(\n                    script_context={\"spark_session\": self.spark_session}\n                )\n\n    def init_session(self, spark_configs: dict[str, str]):\n        self.spark_session = self.create_spark_session(spark_configs)\n        self.spark_session.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n\n    @staticmethod\n    def create_spark_session(spark_configs: dict[str, str]):\n        assert \"master\" in spark_configs, \"master is required in spark_configs\"\n        assert \"app_name\" in spark_configs, \"app_name is required in spark_configs\"\n\n        # TODO refactor to use ibis spark backend\n        import findspark\n        from pyspark.sql import SparkSession\n\n        findspark.init()\n\n        return (\n            SparkSession.builder.master(spark_configs.get(\"master\"))\n            .appName(spark_configs.get(\"app_name\"))\n            .getOrCreate()\n        )\n\n    def add_pandas_dataframe(self, dataframe: pd.DataFrame):\n        df_id = f\"df_{id(dataframe)}\"\n        self.add_prompt_context(\n            f\"\"\"\n        dataframe name: {df_id}\n        dataframe metadata: {dataframe.info}\n        \"\"\"\n        )\n        for tool in self.tools:\n            if isinstance(tool, PythonTool):\n                tool.update_script_context(script_context={df_id: dataframe})\n        return self\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/arrow_agent.py", "content": "from typing import Dict\n\nimport pyarrow as pa\nfrom ryoma_ai.agent.workflow import WorkflowAgent\nfrom ryoma_ai.tool.pyarrow_tool import ArrowTool\nfrom ryoma_ai.tool.python_tool import PythonTool\n\n\nclass ArrowAgent(WorkflowAgent):\n    description: str = (\n        \"An Arrow agent that can use Arrow tools to interact with Arrow Tables.\"\n    )\n\n    def __init__(self, model: str, model_parameters: Dict = None):\n        super().__init__([ArrowTool()], model, model_parameters)\n\n    def add_table(self, table: pa.Table):\n        table_id = f\"table_{id(table)}\"\n        self.add_prompt_context(\n            f\"\"\"\n        pyarrow table name: {table_id}\n        pyarrow table metadata: {table.schema}\n        \"\"\"\n        )\n        for tool in self.tools:\n            if isinstance(tool, PythonTool):\n                tool.update_script_context(script_context={table_id: table})\n        return self\n"}
{"type": "source_file", "path": "example/e2e_example.py", "content": "import os\n\nfrom ryoma_ai.agent.pandas import PandasAgent\nfrom ryoma_ai.agent.python import PythonAgent\nfrom ryoma_ai.agent.sql import SqlAgent\nfrom ryoma_ai.datasource.postgres import PostgresDataSource\nfrom ryoma_ai.datasource.snowflake import SnowflakeDataSource\n\n# Snowflake\n\n# Snowflake connection parameters\nuser = os.getenv(\"SNOWFLAKE_USER\")\npassword = os.getenv(\"SNOWFLAKE_PASSWORD\")\naccount = os.getenv(\"SNOWFLAKE_ACCOUNT\")\nwarehouse = os.getenv(\"SNOWFLAKE_WAREHOUSE\")\nrole = os.getenv(\"SNOWFLAKE_ROLE\")\ndatabase = os.getenv(\"SNOWFLAKE_DATABASE\")\nschema = os.getenv(\"SNOWFLAKE_SCHEMA\")\n\n# Create a SnowflakeDataSource object\nsnowflake_datasource = SnowflakeDataSource(\n    user=user,\n    password=password,\n    account=account,\n    warehouse=warehouse,\n    role=role,\n    database=database,\n    schema=schema,\n)\n\nsql_agent = SqlAgent(\"gpt-3.5-turbo\").add_datasource(snowflake_datasource)\nsql_agent.stream(\"I want to get the top 5 customers which making the most purchases\")\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/kernel_node.py", "content": "import asyncio\nfrom typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n\nfrom langchain_core.messages import AIMessage, AnyMessage, ToolCall, ToolMessage\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain_core.runnables.config import get_config_list, get_executor_for_config\nfrom langchain_core.tools import BaseTool\nfrom langgraph.prebuilt import ToolNode\n\n\nclass KernelNode(ToolNode):\n    \"\"\"A ToolNode that can use a custom executor for running the tool.\"\"\"\n\n    def __init__(\n        self,\n        tools: Sequence[Union[BaseTool, Callable]],\n        executor: Callable,\n        *,\n        name: str = \"kernel_tools\",\n        tags: Optional[List[str]] = None,\n        handle_tool_errors: bool = True,\n    ):\n        super().__init__(\n            tools, name=name, tags=tags, handle_tool_errors=handle_tool_errors\n        )\n        self.executor = executor\n\n    def _run_one(self, call: ToolCall, config: RunnableConfig) -> ToolMessage:\n        if invalid_tool_message := self._validate_tool_call(call):\n            return invalid_tool_message\n\n        try:\n            input = {**call, **{\"type\": \"tool_call\"}}\n            tool = self.tools_by_name[call[\"name\"]]\n            result = self.executor(tool, input, config)\n            tool_message = ToolMessage(\n                content=str(result), name=call[\"name\"], tool_call_id=call[\"id\"]\n            )\n            return tool_message\n        except Exception as e:\n            if not self.handle_tool_errors:\n                raise e\n            content = f\"Error: {repr(e)}\\n Please fix your mistakes.\"\n            return ToolMessage(content, name=call[\"name\"], tool_call_id=call[\"id\"])\n\n    async def _arun_one(self, call: ToolCall, config: RunnableConfig) -> ToolMessage:\n        if invalid_tool_message := self._validate_tool_call(call):\n            return invalid_tool_message\n\n        try:\n            input = {**call, **{\"type\": \"tool_call\"}}\n            tool = self.tools_by_name[call[\"name\"]]\n            result = await self.executor(tool, input, config)\n            tool_message = ToolMessage(\n                content=str(result), name=call[\"name\"], tool_call_id=call[\"id\"]\n            )\n            return tool_message\n        except Exception as e:\n            if not self.handle_tool_errors:\n                raise e\n            content = f\"Error: {repr(e)}\\n Please fix your mistakes.\"\n            return ToolMessage(content, name=call[\"name\"], tool_call_id=call[\"id\"])\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/__init__.py", "content": "\"\"\"AI Powered Data Platform\"\"\"\n\nimport sys\nfrom importlib import metadata as importlib_metadata\n\n\ndef get_version() -> str:\n    try:\n        return importlib_metadata.version(__name__)\n    except importlib_metadata.PackageNotFoundError:  # pragma: no cover\n        return \"unknown\"\n\n\nversion: str = get_version()\n"}
{"type": "source_file", "path": "docs/source/conf.py", "content": "# Configuration file for the Sphinx documentation builder.\n#\n# For the full list of built-in configuration values, see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Project information -----------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\n\nimport os\nimport sys\nimport warnings\n\nsys.path.append(os.path.abspath(os.path.dirname(__file__)))\n\nproject = \"Ryoma\"\ncopyright = \"2024, WuHen-Li\"\nauthor = \"WuHen-Li\"\nrelease = \"v1.0.0-beta\"\n\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\n\nextensions = [\n    \"myst_parser\",\n    \"sphinx_copybutton\",\n    \"sphinx_exec_code\",\n    \"sphinx_tabs.tabs\",\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.autosummary\",\n    \"sphinx.ext.coverage\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.githubpages\",\n    \"sphinx.ext.graphviz\",\n    \"sphinx.ext.ifconfig\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.mathjax\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.viewcode\",\n]\n\nmyst_enable_extensions = [\n    \"amsmath\",\n    \"attrs_inline\",\n    \"colon_fence\",\n    \"deflist\",\n    \"dollarmath\",\n    \"fieldlist\",\n    \"html_admonition\",\n    \"html_image\",\n    \"linkify\",\n    \"replacements\",\n    \"smartquotes\",\n    \"strikethrough\",\n    \"substitution\",\n    \"tasklist\",\n]\n\ncoverage_show_missing_items = True\nexclude_patterns = []\ngraphviz_output_format = \"svg\"\nhtml_css_files = [\"css/custom.css\"]\nhtml_favicon = \"modelinfer.png\"\nhtml_sidebars = {}\nhtml_static_path = [\"_static\"]\nhtml_theme = \"furo\"\nlanguage = \"en\"\nmathdef_link_only = True\nmaster_doc = \"index\"\npygments_style = \"default\"\nsource_suffix = [\".rst\", \".md\"]\ntemplates_path = [\"_templates\"]\n\nhtml_context = {\n    \"default_mode\": \"auto\",  # auto: the documentation theme will follow the system default that you have set (light or dark)\n}\n\nhtml_theme_options = {\n    \"light_logo\": \"ryoma.png\",\n    \"dark_logo\": \"ryoma.png\",\n}\n\nintersphinx_mapping = {\n    \"numpy\": (\"https://numpy.org/doc/stable/\", None),\n    \"python\": (f\"https://docs.python.org/{3.10}/\", None),\n    \"scipy\": (\"https://docs.scipy.org/doc/scipy/\", None),\n    \"torch\": (\"https://pytorch.org/docs/stable/\", None),\n}\n\nsphinx_gallery_conf = {\n    \"examples_dirs\": [\"examples\"],\n    \"gallery_dirs\": [\"auto_examples\", \"auto_tutorial\"],\n    \"capture_repr\": (\"_repr_html_\", \"__repr__\"),\n    \"ignore_repr_types\": r\"matplotlib.text|matplotlib.axes\",\n}\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/python_agent.py", "content": "from typing import Dict, Optional\n\nfrom ryoma_ai.agent.workflow import WorkflowAgent\nfrom ryoma_ai.tool.python_tool import PythonTool\n\n\nclass PythonAgent(WorkflowAgent):\n    description: str = \"A Python agent that can use Python tools to run python scripts.\"\n\n    def __init__(\n        self,\n        model: str,\n        model_parameters: Optional[Dict] = None,\n    ):\n        super().__init__([PythonTool()], model, model_parameters)\n\n    def add_script_context(self, script_context):\n        for tool in self.tools:\n            if isinstance(tool, PythonTool):\n                tool.update_script_context(script_context=script_context)\n        return self\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/validator.py", "content": "from typing import Dict, Literal, Optional, Union\n\nfrom langchain_core.messages import ToolMessage\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.pydantic_v1 import BaseModel, ValidationError\nfrom langchain_core.runnables import RunnableSerializable\nfrom langchain_core.runnables.config import RunnableConfig\nfrom langgraph.graph import END, StateGraph\nfrom ryoma_ai.agent.workflow import WorkflowAgent\nfrom ryoma_ai.states import MessageState\n\n\nclass ValidatorAgent(WorkflowAgent):\n    validator: BaseModel\n    validator_chain: RunnableSerializable\n\n    def __int__(\n        self,\n        validator: BaseModel,\n        model: Union[RunnableSerializable, str],\n        model_parameters: Optional[Dict] = None,\n        **kwargs,\n    ):\n        self.validator_tool = validator\n\n        self.base_prompt_template = PromptTemplate(\n            template=\"Please return the output given messages and following the feature validation\\n{messages}\",\n            input_variables=[\"messages\"],\n        )\n\n        super().__init__([self.validator_tool], model, model_parameters, **kwargs)\n\n    def call_model(self, state: list, config: RunnableConfig):\n        messages = {**state, \"user_info\": config.get(\"user_id\", None)}\n        response = self.chain.invoke(messages, config)\n        return {\"messages\": [response]}\n\n    def validate(self, state: list, config: RunnableConfig):\n        messages = state[\"messages\"][-1]\n        try:\n            response = self.validator.invoke(messages)\n            return {\"messages\": [response]}\n        except ValidationError as e:\n            state = state + [\n                ToolMessage(\n                    content=f\"{repr(e)}\\n\\nPay close attention to the function feature.\\n\\n\"\n                    + self.validator.schema_json()\n                    + \" Respond by fixing all validation errors.\",\n                    tool_call_id=response.tool_calls[0][\"id\"],\n                ),\n            ]\n            return state\n\n    def _build_workflow(self):\n        workflow = StateGraph(MessageState)\n\n        workflow.add_node(\"agent\", self.call_model)\n        workflow.add_node(\"tools\", self.build_tool_node(self.tools))\n        workflow.add_node(\"validator\", self.call_model)\n        workflow.add_node(\"validation\", self._validate)\n\n        workflow.add_conditional_edges(\"agent\", self._should_call_tool)\n        workflow.add_conditional_edges(\"validator\", self._should_validate)\n        workflow.add_edge(\"tools\", \"agent\")\n        workflow.add_edge(\"validation\", \"validator\")\n\n        workflow.set_entry_point(\"agent\")\n        return workflow.compile(\n            checkpointer=self.memory, interrupt_before=[\"validator\", \"tools\"]\n        )\n\n    def _validate(self, state: list, config: RunnableConfig):\n        message = state[\"messages\"][-1]\n        try:\n            validator = PydanticToolsParser(tools=[self.validator])\n            validator.invoke(message)\n            response = self.validator_chain.invoke(config)\n            response.additional_kwargs[\"validated\"] = True\n            return {\"messages\": [response]}\n        except ValidationError as e:\n            return {\n                \"messages\": [\n                    ToolMessage(\n                        content=f\"{repr(e)}\\n\\nPay close attention to the function feature.\\n\\n\"\n                        + \" Respond by fixing all validation errors.\",\n                        tool_call_id=message.tool_calls[0][\"id\"],\n                    )\n                ]\n            }\n\n    def _should_call_tool(self, state: list) -> Literal[\"tools\", \"validator\"]:\n        if isinstance(state, list):\n            ai_message = state[-1]\n        elif messages := state.get(\"messages\", []):\n            ai_message = messages[-1]\n        else:\n            raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n        if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n            return \"tools\"\n        return \"validator\"\n\n    def _should_validate(\n        self, state: list\n    ) -> Literal[\"agent\", \"validation\", \"__end__\"]:\n        if (\n            state[\"messages\"][-1].tool_calls\n            and \"validated\" not in state[\"messages\"][-1].additional_kwargs\n        ):\n            return \"validation\"\n        return END\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/agent/workflow.py", "content": "import logging\nfrom enum import Enum\nfrom typing import Callable\n\nfrom IPython.display import Image, display\nfrom jupyter_ai_magics.providers import *\nfrom langchain.tools.render import render_text_description\nfrom langchain_core.messages import HumanMessage, ToolCall, ToolMessage\nfrom langchain_core.runnables import (\n    RunnableConfig,\n    RunnableLambda,\n    RunnableSerializable,\n)\nfrom langchain_core.tools import BaseTool\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.graph import StateGraph\nfrom langgraph.graph.graph import CompiledGraph\nfrom langgraph.prebuilt import ToolNode, tools_condition\nfrom langgraph.pregel import StateSnapshot\nfrom ryoma_ai.agent.base import BaseAgent\nfrom ryoma_ai.datasource.base import DataSource\nfrom ryoma_ai.models.agent import AgentType\nfrom ryoma_ai.states import MessageState\n\n\nclass ToolMode(str, Enum):\n    \"\"\"The mode of the tool call.\"\"\"\n\n    DISALLOWED = \"disallowed\"\n    CONTINUOUS = \"continuous\"\n    ONCE = \"once\"\n\n\ndef handle_tool_error(state) -> dict:\n    error = state.get(\"error\")\n    tool_calls = state[\"messages\"][-1].tool_calls\n    return {\n        \"messages\": [\n            ToolMessage(\n                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n                tool_call_id=tc[\"id\"],\n            )\n            for tc in tool_calls\n        ]\n    }\n\n\nclass WorkflowAgent(BaseAgent):\n    tools: List[BaseTool]\n    graph: StateGraph\n    workflow: CompiledGraph\n    type: AgentType = AgentType.workflow\n\n    def __init__(\n        self,\n        tools: List[BaseTool],\n        model: Union[RunnableSerializable, str],\n        model_parameters: Optional[Dict] = None,\n        graph: Optional[StateGraph] = None,\n        base_prompt_template: Optional[PromptTemplate] = None,\n        context_prompt_templates: Optional[list[PromptTemplate]] = None,\n        output_prompt_template: Optional[PromptTemplate] = None,\n        output_parser: Optional[BaseModel] = None,\n        **kwargs,\n    ):\n        logging.info(f\"Initializing Workflow Agent with model: {model}\")\n        super().__init__(\n            model,\n            model_parameters,\n            base_prompt_template,\n            context_prompt_templates,\n            output_prompt_template,\n            output_parser,\n            **kwargs,\n        )\n\n        self.tools = tools\n        if self.tools:\n            self.model = self._bind_tools()\n\n        self.memory = MemorySaver()\n        self.workflow = self._build_workflow(graph)\n\n    def _bind_tools(self):\n        logging.info(f\"Binding tools {self.tools} to model\")\n        if hasattr(self.model, \"bind_tools\"):\n            return self.model.bind_tools(self.tools)\n        else:\n            rendered_tools = render_text_description(self.tools)\n            tool_prompt = f\"\"\"\n            You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n\n            {rendered_tools}\n\n            \"\"\"\n            tool_prompt_template = ChatPromptTemplate.from_messages(\n                [(\"system\", tool_prompt)]\n            )\n            self.prompt_template_factory.add_context_prompt(tool_prompt_template)\n            return self.model\n\n    def _build_workflow(self, graph: StateGraph) -> CompiledGraph:\n        if graph:\n            return graph.compile(checkpointer=self.memory, interrupt_before=[\"tools\"])\n        workflow = StateGraph(MessageState)\n\n        workflow.add_node(\"agent\", self.call_model)\n        workflow.add_node(\"tools\", self.build_tool_node(self.tools))\n\n        workflow.add_conditional_edges(\n            \"agent\",\n            tools_condition,\n        )\n\n        workflow.set_entry_point(\"agent\")\n        workflow.add_edge(\"tools\", \"agent\")\n        return workflow.compile(checkpointer=self.memory, interrupt_before=[\"tools\"])\n\n    @staticmethod\n    def init_state():\n        return StateGraph(MessageState)\n\n    def get_graph(self):\n        return self.workflow.get_graph(self.config)\n\n    def get_current_state(self) -> Optional[StateSnapshot]:\n        return self.workflow.get_state(self.config)\n\n    def get_current_state_messages(self):\n        current_state = self.get_current_state()\n        if current_state:\n            return current_state.values.get(\"messages\")\n        return []\n\n    def get_current_tool_calls(self) -> List[ToolCall]:\n        current_state_messages = self.get_current_state().values.get(\"messages\")\n        if current_state_messages and current_state_messages[-1].tool_calls:\n            return current_state_messages[-1].tool_calls\n        return []\n\n    def add_datasource(self, datasource: DataSource):\n        super().add_datasource(datasource)\n        for tool in self.tools:\n            if hasattr(tool, \"type\"):\n                tool.datasource = datasource\n        return self\n\n    def _format_messages(self, question: str):\n        current_state = self.get_current_state()\n        if current_state.next and current_state.next[0] == \"tools\":\n            # We are in the tool node, but the user has asked a new question\n            # We need to deny the tool call and continue with the user's question\n            tool_calls = self.get_current_tool_calls()\n            return {\n                \"messages\": [\n                    ToolMessage(\n                        tool_call_id=tool_calls[0][\"id\"],\n                        content=f\"Tool call denied by user. Reasoning: '{question}'. Continue assisting, accounting for the user's input.\",\n                    )\n                ]\n            }\n        else:\n            return {\"messages\": [HumanMessage(content=question)]}\n\n    def stream(\n        self,\n        question: Optional[str] = \"\",\n        tool_mode: str = ToolMode.DISALLOWED,\n        max_iterations: int = 10,\n        display=True,\n    ):\n        if (\n            not question\n            and tool_mode != ToolMode.DISALLOWED\n            and self.get_current_tool_calls()\n        ):\n            messages = None\n        else:\n            messages = self._format_messages(question)\n        events = self.workflow.stream(\n            messages, config=self.config, stream_mode=\"values\"\n        )\n        if display:\n            _printed = set()\n            self._print_graph_events(events, _printed)\n\n        if tool_mode == ToolMode.CONTINUOUS:\n            current_state = self.get_current_state()\n            iterations = 0\n            while current_state.next and iterations < max_iterations:\n                iterations += 1\n                events = self.workflow.stream(None, config=self.config)\n                if display:\n                    logging.info(f\"Iteration {iterations}\")\n                    self._print_graph_events(events, _printed)\n                current_state = self.get_current_state()\n        if self.output_parser:\n            chain = self.output_prompt | self.model | self.output_parser\n            events = self._parse_output(chain, events, max_iterations=max_iterations)\n        return events\n\n    def invoke(\n        self,\n        question: Optional[str] = \"\",\n        tool_mode: str = ToolMode.DISALLOWED,\n        max_iterations: int = 10,\n        display=True,\n    ):\n        if (\n            not question\n            and tool_mode != ToolMode.DISALLOWED\n            and self.get_current_tool_calls()\n        ):\n            messages = None\n        else:\n            messages = self._format_messages(question)\n        result = self.workflow.invoke(messages, config=self.config)\n        if display:\n            _printed = set()\n            self._print_graph_events(result, _printed)\n\n        if tool_mode == ToolMode.CONTINUOUS:\n            logging.info(\"Starting the iterative invocation process.\")\n            current_state = self.get_current_state()\n            iterations = 0\n            while current_state.next and iterations < max_iterations:\n                iterations += 1\n                result = self.workflow.invoke(None, config=self.config)\n                if display:\n                    logging.info(f\"Iteration {iterations}\")\n                    self._print_graph_events(result, _printed)\n                current_state = self.get_current_state()\n        if self.output_parser:\n            chain = self.output_prompt | self.model | self.output_parser\n            result = self._parse_output(chain, result, max_iterations=max_iterations)\n        return result\n\n    @staticmethod\n    def build_tool_node(tools):\n        return ToolNode(tools).with_fallbacks(\n            [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n        )\n\n    def call_tool(self, tool_id: str, **kwargs):\n        if not tool_id:\n            raise ValueError(\"Tool id is required.\")\n        curr_tool_calls = self.get_current_tool_calls()\n        tool_call = next((tc for tc in curr_tool_calls if tc[\"id\"] == tool_id), None)\n        if not tool_call:\n            raise ValueError(\n                f\"Unable to find tool call {tool_id} in the current state.\"\n            )\n        tool = next((t for t in self.tools if t.name == tool_call[\"name\"]), None)\n        if kwargs.get(\"args\"):\n            tool_call[\"args\"].update(kwargs[\"args\"])\n        res = tool.invoke(tool_call[\"args\"], self.config)\n        return res\n\n    def update_tool(self, tool_id: str, tool_args: dict):\n        if not tool_id:\n            raise ValueError(\"Tool id is required.\")\n        current_state_messages = self.get_current_state_messages()\n        curr_tool_calls = self.get_current_tool_calls()\n        tool_call_index = next(\n            (\n                index\n                for (index, tc) in enumerate(curr_tool_calls)\n                if tc[\"id\"] == tool_id\n            ),\n            None,\n        )\n        if tool_call_index is None:\n            raise ValueError(f\"Tool call {tool_id} not found in current state.\")\n        current_state_messages[-1].tool_calls[tool_call_index][\"args\"] = tool_args\n        new_state = {\"messages\": [current_state_messages[-1]]}\n        self.workflow.update_state(self.config, new_state)\n\n    def cancel_tool(self, tool_id: str):\n        pass\n\n    def _build_chain(self):\n        if not self.model:\n            raise ValueError(\n                f\"Unable to initialize model, please ensure you have valid configurations.\"\n            )\n        self.final_prompt_template.append(\n            MessagesPlaceholder(variable_name=\"messages\", optional=True)\n        )\n        return self.final_prompt_template | self.model\n\n    def call_model(self, state: MessageState, config: RunnableConfig):\n        chain = self._build_chain()\n        response = chain.invoke(state, self.config)\n        return {\"messages\": [response]}\n\n    def _print_graph_events(self, events, printed, max_length=1500):\n        if isinstance(events, dict):\n            events = [events]\n        for event in events:\n            messages = self._get_event_message(event)\n            for message in messages:\n                if message.id not in printed:\n                    msg_repr = message.pretty_repr(html=True)\n                    if len(msg_repr) > max_length:\n                        msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n                    print(msg_repr)\n                    printed.add(message.id)\n\n    def _get_event_message(self, event):\n        if \"tools\" in event:\n            return event[\"tools\"][\"messages\"]\n        if \"agent\" in event:\n            return event[\"agent\"][\"messages\"]\n        if \"messages\" in event:\n            return event[\"messages\"]\n        return event\n\n    def display_graph(self):\n        display(Image(self.workflow.get_graph().draw_mermaid_png()))\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/prompt_template.py", "content": "from typing import Optional, Union\n\nfrom langchain_core.prompts import (\n    ChatPromptTemplate,\n    FewShotPromptTemplate,\n    PromptTemplate,\n)\nfrom ryoma_ai.prompt.base import BasePromptTemplate, BasicContextPromptTemplate\n\n\nclass PromptTemplateFactory:\n    prompt_templates: list[ChatPromptTemplate]\n\n    def __init__(\n        self,\n        base_prompt_template: Optional[ChatPromptTemplate] = None,\n        context_prompt_templates: Optional[list[ChatPromptTemplate]] = None,\n        output_prompt_template: Optional[ChatPromptTemplate] = None,\n    ):\n        if base_prompt_template is None:\n            self.prompt_templates = [BasePromptTemplate]\n        else:\n            self.prompt_templates = [base_prompt_template]\n        if context_prompt_templates:\n            self.prompt_templates.extend(context_prompt_templates)\n        if output_prompt_template:\n            self.prompt_templates.append(output_prompt_template)\n\n    def set_base_prompt(self, base_prompt_template: Union[str, ChatPromptTemplate]):\n        if isinstance(base_prompt_template, str):\n            base_prompt_template = ChatPromptTemplate.from_messages(\n                [(\"system\", base_prompt_template)]\n            )\n        self.prompt_templates[0] = base_prompt_template\n\n    def add_context_prompt(\n        self, context_prompt_template: Union[str, ChatPromptTemplate]\n    ):\n        if isinstance(context_prompt_template, str):\n            context_prompt_template = ChatPromptTemplate.from_messages(\n                [(\"system\", context_prompt_template)]\n            )\n        self.prompt_templates.append(context_prompt_template)\n\n    def build_prompt(self) -> ChatPromptTemplate:\n        return ChatPromptTemplate.from_messages(self.prompt_templates)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/mysql.py", "content": "import logging\nfrom typing import Any, Optional, Union\n\nimport ibis\nfrom databuilder.extractor.sql_alchemy_extractor import SQLAlchemyExtractor\nfrom databuilder.job.job import DefaultJob\nfrom databuilder.loader.base_loader import Loader\nfrom databuilder.task.task import DefaultTask\nfrom ibis import BaseBackend\nfrom pyhocon import ConfigFactory\nfrom ryoma_ai.datasource.base import SqlDataSource\n\n\nclass MySqlDataSource(SqlDataSource):\n    def get_query_plan(self, query: str) -> Any:\n        pass\n\n    def __init__(\n        self,\n        database: Optional[str] = None,\n        db_schema: Optional[str] = None,\n        connection_url: Optional[str] = None,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        host: Optional[str] = None,\n        port: Optional[int] = None,\n    ):\n        super().__init__(database=database, db_schema=db_schema)\n        self.username = username\n        self.password = password\n        self.host = host\n        self.port = port\n        self.connection_url = connection_url\n\n    def _connect(self, **kwargs) -> BaseBackend:\n        return ibis.mysql.connect(\n            user=self.username,\n            password=self.password,\n            host=self.host,\n            port=self.port,\n            database=self.database,\n            **kwargs,\n        )\n\n    def connection_string(self):\n        return f\"mysql+mysqlconnector://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}\"\n\n    def crawl_metadata(self, loader: Loader, where_clause_suffix: Optional[str] = \"\"):\n        from databuilder.extractor.mysql_metadata_extractor import (\n            MysqlMetadataExtractor,\n        )\n\n        logging.info(\"Crawling data catalog from Mysql\")\n        job_config = ConfigFactory.from_dict(\n            {\n                \"extractor.mysql_metadata.{}\".format(\n                    MysqlMetadataExtractor.WHERE_CLAUSE_SUFFIX_KEY\n                ): where_clause_suffix,\n                \"extractor.mysql_metadata.{}\".format(\n                    MysqlMetadataExtractor.USE_CATALOG_AS_CLUSTER_NAME\n                ): True,\n                \"extractor.mysql_metadata.extractor.sqlalchemy.{}\".format(\n                    SQLAlchemyExtractor.CONN_STRING\n                ): self.connection_string(),\n            }\n        )\n        job = DefaultJob(\n            conf=job_config,\n            task=DefaultTask(extractor=MysqlMetadataExtractor(), loader=loader),\n        )\n        job.launch()\n\n\nclass MySqlConfig:\n    pass\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/snowflake.py", "content": "import logging\nfrom typing import Any, Optional, Union\n\nimport ibis\nfrom databuilder.extractor.sql_alchemy_extractor import SQLAlchemyExtractor\nfrom databuilder.job.job import DefaultJob\nfrom databuilder.loader.base_loader import Loader\nfrom databuilder.task.task import DefaultTask\nfrom ibis import BaseBackend\nfrom ibis.backends.sql import SQLBackend\nfrom pydantic import BaseModel, Field\nfrom pyhocon import ConfigFactory\nfrom ryoma_ai.datasource.base import SqlDataSource\nfrom ryoma_ai.datasource.metadata import Catalog, Column, Schema, Table\n\n\nclass SnowflakeConfig(BaseModel):\n    user: str = Field(..., description=\"Snowflake user name\")\n    password: str = Field(..., description=\"Snowflake password\")\n    account: str = Field(..., description=\"Snowflake account\")\n    database: str = Field(..., description=\"Database name\")\n    warehouse: Optional[str] = Field(None, description=\"Snowflake warehouse name\")\n    role: Optional[str] = Field(None, description=\"Snowflake role name\")\n    db_schema: Optional[str] = Field(None, description=\"Database schema\")\n\n\nclass SnowflakeDataSource(SqlDataSource):\n    def __init__(\n        self,\n        user: Optional[str] = None,\n        password: Optional[str] = None,\n        account: Optional[str] = None,\n        database: Optional[str] = None,\n        warehouse: Optional[str] = None,\n        role: Optional[str] = None,\n        db_schema: Optional[str] = None,\n        connection_url: Optional[str] = None,\n    ):\n        super().__init__(database=database, db_schema=db_schema)\n        self.user = user\n        self.password = password\n        self.account = account\n        self.warehouse = warehouse or \"COMPUTE_WH\"\n        self.role = role or \"PUBLIC_ROLE\"\n        self.connection_url = connection_url\n\n    def _connect(self, **kwargs) -> Union[BaseBackend, SQLBackend]:\n        if self.connection_url:\n            logging.info(\"Connection URL provided, using it to connect\")\n            return ibis.connect(self.connection_url)\n        logging.info(\"Connection URL not provided, using individual parameters\")\n        try:\n            return ibis.snowflake.connect(\n                user=self.user,\n                password=self.password,\n                account=self.account,\n                warehouse=self.warehouse,\n                role=self.role,\n                database=self.database,\n                schema=self.db_schema,\n                **kwargs,\n            )\n        except Exception as e:\n            raise Exception(f\"Failed to connect to Snowflake: {e}\")\n\n    def connection_string(self):\n        return \"\"\"\n        snowflake://{user}:{password}@{account}/{database}/{schema}?warehouse={warehouse}&role={role}\n        \"\"\".format(\n            user=self.user,\n            password=self.password,\n            account=self.account,\n            database=self.database,\n            schema=self.db_schema,\n            warehouse=self.warehouse,\n            role=self.role,\n        )\n\n    def crawl_metadata(self, loader: Loader, where_clause_suffix: Optional[str] = \"\"):\n        from databuilder.extractor.snowflake_metadata_extractor import (\n            SnowflakeMetadataExtractor,\n        )\n\n        logging.info(\"Running Snowflake metadata extraction job\")\n        job_config = ConfigFactory.from_dict(\n            {\n                \"extractor.snowflake.{}\".format(\n                    SnowflakeMetadataExtractor.SNOWFLAKE_DATABASE_KEY\n                ): self.database,\n                \"extractor.snowflake.{}\".format(\n                    SnowflakeMetadataExtractor.WHERE_CLAUSE_SUFFIX_KEY\n                ): where_clause_suffix,\n                \"extractor.snowflake.{}\".format(\n                    SnowflakeMetadataExtractor.USE_CATALOG_AS_CLUSTER_NAME\n                ): True,\n                \"extractor.snowflake.extractor.sqlalchemy.{}\".format(\n                    SQLAlchemyExtractor.CONN_STRING\n                ): self.connection_string(),\n            }\n        )\n\n        job = DefaultJob(\n            conf=job_config,\n            task=DefaultTask(extractor=SnowflakeMetadataExtractor(), loader=loader),\n        )\n\n        job.launch()\n\n    def get_query_plan(self, query: str) -> Any:\n        conn = self.connect()\n        explain_query = f\"EXPLAIN USING JSON {query}\"\n        return conn.sql(explain_query)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/ExampleFormatTemplate.py", "content": "class SqlExampleStyle:\n    \"\"\"Only show sqls as examples\"\"\"\n\n    def get_example_prefix(self):\n        return \"/* Some SQL examples are provided based on similar problems: */\\n\"\n\n    def format_example(self, example: dict):\n        return example[\"query\"]\n\n\nclass QuestionSqlExampleStyle:\n    \"\"\"Provide QA pair as examples\"\"\"\n\n    def get_example_prefix(self):\n        return \"/* Some SQL examples are provided based on similar problems: */\\n\"\n\n    def format_example(self, example: dict):\n        template_qa = \"/* Answer the following: {} */\\n{}\"\n        return template_qa.format(example[\"question\"], example[\"query\"])\n\n\nclass QuestionSqlWithRuleExampleStyle:\n    \"\"\"Provide QA pair as examples\"\"\"\n\n    def get_example_prefix(self):\n        return \"/* Some SQL examples are provided based on similar problems: */\\n\"\n\n    def format_example(self, example: dict):\n        template_qa = \"/* Answer the following with no explanation: {} */\\n{}\"\n        return template_qa.format(example[\"question\"], example[\"query\"])\n\n\nclass CompleteExampleStyle:\n    \"\"\"Examples are in the same format as target question\"\"\"\n\n    def get_example_prefix(self):\n        return \"\"\n\n    def format_example(self, example: dict):\n        return f\"{self.format_question(example)}\\n{example['query']}\"\n\n\nclass NumberSignQuestionSqlExampleStyle:\n    \"\"\"\n    Provide QA pair as examples\n    \"\"\"\n\n    def get_example_prefix(self):\n        return \"### Some example pairs of question and corresponding SQL query are provided based on similar problems:\\n\\n\"\n\n    def format_example(self, example: dict):\n        template_qa = \"### {}\\n{}\"\n        return template_qa.format(example[\"question\"], example[\"query\"])\n\n\nclass BaselineQuestionSqlExampleStyle:\n    \"\"\"\n    Provide QA pair as examples\n    \"\"\"\n\n    def get_example_prefix(self):\n        return \"\"\n\n    def format_example(self, example: dict):\n        template_qa = \"Example Q: {}\\nExample A: {}\"\n        return template_qa.format(example[\"question\"], example[\"query\"])\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/__init__.py", "content": ""}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/metadata.py", "content": "from typing import List, Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass Column(BaseModel):\n    name: str = Field(..., description=\"Name of the column\")\n    type: Optional[str] = Field(\n        None, description=\"Type of the column\", alias=\"column_type\"\n    )\n    nullable: Optional[bool] = Field(\n        None, description=\"Whether the column is nullable\", alias=\"nullable\"\n    )\n    primary_key: Optional[bool] = Field(\n        None, description=\"Whether the column is a primary key\"\n    )\n\n    class Config:\n        populate_by_name = True\n\n\nclass Table(BaseModel):\n    table_name: str = Field(..., description=\"Name of the table\")\n    columns: List[Column] = Field(..., description=\"List of columns in the table\")\n\n    class Config:\n        populate_by_name = True\n\n\nclass Schema(BaseModel):\n    schema_name: str = Field(..., description=\"Name of the schema\")\n    tables: Optional[List[Table]] = Field(\n        None, description=\"List of tables in the schema\"\n    )\n\n    class Config:\n        populate_by_name = True\n\n\nclass Catalog(BaseModel):\n    catalog_name: str = Field(\n        ..., description=\"Name of the catalog, also known as the database name\"\n    )\n    schemas: Optional[List[Schema]] = Field(\n        None, description=\"List of catalog schemas in the catalog\"\n    )\n\n    class Config:\n        populate_by_name = True\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/nosql.py", "content": "from typing import List\n\ntry:\n    import boto3\nexcept ImportError:\n    boto3 = None\n\nfrom ryoma_ai.datasource.base import DataSource\nfrom ryoma_ai.datasource.metadata import Catalog\n\n\nclass DynamodbDataSource(DataSource):\n    def __init__(self, region_name: str = None, **kwargs):\n        super().__init__(\"nosql\", **kwargs)\n        self.region_name = region_name\n        self.client = boto3.client(\"dynamodb\", region_name=region_name)\n\n    def get_catalog(self, table_name: str) -> List[Catalog]:\n        response = self.client.describe_table(TableName=table_name)\n        return response[\"Table\"]\n\n\nclass DynamodbConfig:\n    pass\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/PromptReprTemplate.py", "content": "from ryoma_ai.prompt.utils import get_sql_for_database\n\n\nclass BasicPrompt:\n    def __init__(self, *args, **kwargs):\n        # used to avoid empty init function in 0-shot prompt\n        pass\n\n    def format_target(self, example: dict):\n        return self.format_question(example) + \"\\nSELECT \"\n\n    def format_question(self, example: dict):\n        raise NotImplementedError()\n\n    def get_extra_info(self, db_id):\n        return None\n\n\nclass SQLPrompt(BasicPrompt):\n    template_info = \"/* Given the following catalog feature: */\\n\" \"{}\"\n    template_question = \"/* Answer the following: {} */\"\n\n    def format_question(self, example: dict):\n        sqls = get_sql_for_database(example[\"path_db\"])\n\n        prompt_info = self.template_info.format(\"\\n\\n\".join(sqls))\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\\n\".join(prompt_components)\n        return prompt\n\n\nclass TextPrompt(BasicPrompt):\n    template_info = \"Given the following catalog feature:\\n\" \"{}\"\n    template_question = \"Answer the following: {}\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"{_.name}: {', '.join(_.feature)}\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass NumberSignPrompt(BasicPrompt):\n    template_info = (\n        \"### Complete sqlite SQL query only and with no explanation\\n\"\n        \"### SQLite SQL tables, with their properties:\\n\"\n        \"#\\n\"\n        \"{}\\n\"\n        \"#\"\n    )\n    template_question = \"### {}\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"# {_.name}({', '.join(_.feature)})\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass BaselinePrompt(BasicPrompt):\n    template_info = \"{}\\nForeign_keys={}\\n\"\n    template_question = 'Q: \"{}\"'\n\n    def format_question(self, example: dict):\n        # schemas\n        schemas = \"\\n\".join(\n            [f\"Table {_.name}, columns = {_.feature}\" for _ in example[\"tables\"]]\n        ).replace(\"'\", \"\")\n        # foreign_keys\n        foreign_keys = list()\n        for table in example[\"tables\"]:\n            for pair_str in table[\"table_info\"][\"foreign_key\"]:\n                a, b = (_.strip() for _ in pair_str[1:-1].split(\",\"))\n                foreign_keys.append(f\"{a}={b}\")\n\n        # format prompt\n        prompt_info = self.template_info.format(\n            schemas, str(foreign_keys).replace(\"'\", \"\")\n        )\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\".join(prompt_components)\n        return prompt\n\n    def format_target(self, example: dict):\n        return self.format_question(example) + \"\\nA: SELECT \"\n\n\nclass InstructionPrompt(BasicPrompt):\n    template_info = (\n        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        '### Instruction:\\nWrite a sql to answer the question \"{}\"\\n\\n### Input:\\n{}\\n'\n    )\n    template_question = \"### Response:\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"{_.name}({', '.join(_.feature)})\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(example[\"question\"], schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            # TODO: extra_info should be after info\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass TextWithForeignKeyPrompt(BasicPrompt):\n    template_info = (\n        \"Given the following catalog feature:\\n\"\n        \"{} \\n\"\n        \"And their foreign keys:\\n\"\n        \"{}\"\n    )\n    template_question = \"Answer the following: {}\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"{_.name}: {', '.join(_.feature)}\" for _ in example[\"tables\"]]\n        )\n        # foreign_keys\n        foreign_keys = list()\n        for table in example[\"tables\"]:\n            for pair_str in table[\"table_info\"][\"foreign_key\"]:\n                a, b = (_.strip() for _ in pair_str[1:-1].split(\",\"))\n                foreign_keys.append(f\"{a}={b}\")\n        foreign_keys = f\"{', '.join(foreign_keys)}\"\n\n        prompt_info = self.template_info.format(schemas, foreign_keys)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass NumberSignWithForeignKeyPrompt(BasicPrompt):\n    template_info = (\n        \"### Complete sqlite SQL query only and with no explanation\\n\"\n        \"### SQLite SQL tables, with their properties:\\n\"\n        \"#\\n\"\n        \"{}\\n\"\n        \"#\\n\"\n        \"### Their foreign keys:\\n\"\n        \"#\\n\"\n        \"{}\\n\"\n        \"#\"\n    )\n    template_question = \"### {}\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"# {_.name}({', '.join(_.feature)})\" for _ in example[\"tables\"]]\n        )\n        # foreign_keys\n        foreign_keys = list()\n        for table in example[\"tables\"]:\n            for pair_str in table[\"table_info\"][\"foreign_key\"]:\n                a, b = (_.strip() for _ in pair_str[1:-1].split(\",\"))\n                foreign_keys.append(f\"{a}={b}\")\n        foreign_keys = f\"# Foreign_keys=({', '.join(foreign_keys)})\"\n\n        prompt_info = self.template_info.format(schemas, foreign_keys)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass BaselineWithoutForeignKeyPrompt(BasicPrompt):\n    template_info = \"{}\\n\"\n    template_question = 'Q: \"{}\"'\n\n    def format_question(self, example: dict):\n        # schemas\n        schemas = \"\\n\".join(\n            [f\"Table {_.name}, columns = {_.feature}\" for _ in example[\"tables\"]]\n        ).replace(\"'\", \"\")\n\n        # format prompt\n        prompt_info = self.template_info.format(schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\".join(prompt_components)\n        return prompt\n\n    def format_target(self, example: dict):\n        return self.format_question(example) + \"\\nA: SELECT \"\n\n\nclass InstructionWithForeignKeyPrompt(BasicPrompt):\n    template_info = (\n        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        '### Instruction:\\nWrite a sql to answer the question \"{}\"\\n\\n### Input:\\n{}\\nForeign Keys:{}\\n'\n    )\n    template_question = \"### Response:\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"{_.name}({', '.join(_.feature)})\" for _ in example[\"tables\"]]\n        )\n        # foreign_keys\n        foreign_keys = list()\n        for table in example[\"tables\"]:\n            for pair_str in table[\"table_info\"][\"foreign_key\"]:\n                a, b = (_.strip() for _ in pair_str[1:-1].split(\",\"))\n                foreign_keys.append(f\"{a}={b}\")\n        foreign_keys = f\"{', '.join(foreign_keys)}\"\n\n        prompt_info = self.template_info.format(\n            example[\"question\"], schemas, foreign_keys\n        )\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            # TODO: extra_info should be after info\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass SQLWithRulePrompt(BasicPrompt):\n    template_info = \"/* Given the following catalog feature: */\\n\" \"{}\"\n    template_question = \"/* Answer the following with no explanation: {} */\"\n\n    def format_question(self, example: dict):\n        sqls = get_sql_for_database(example[\"path_db\"])\n\n        prompt_info = self.template_info.format(\"\\n\\n\".join(sqls))\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\\n\".join(prompt_components)\n        return prompt\n\n\nclass TextWithRulePrompt(BasicPrompt):\n    template_info = \"Given the following catalog feature:\\n\" \"{}\"\n    template_question = \"Answer the following with no explanation: {}\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"{_.name}: {', '.join(_.feature)}\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass NumberSignWithoutRulePrompt(BasicPrompt):\n    template_info = (\n        \"### Complete sqlite SQL query\\n\"\n        \"### SQLite SQL tables, with their properties:\\n\"\n        \"#\\n\"\n        \"{}\\n\"\n        \"#\"\n    )\n    template_question = \"### {}\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"# {_.name}({', '.join(_.feature)})\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass InstructionWithRulePrompt(BasicPrompt):\n    template_info = (\n        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        '### Instruction:\\nWrite a sql only and with no explanation to answer the question \"{}\"\\n\\n### Input:\\n{}\\n'\n    )\n    template_question = \"### Response:\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"{_.name}({', '.join(_.feature)})\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(example[\"question\"], schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            # TODO: extra_info should be after info\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n\nclass SQLCOTPrompt(BasicPrompt):\n    template_info = \"/* Given the following catalog feature: */\\n\" \"{}\"\n    template_question = \"/* Let's think step by step. Answer the following: {} */\"\n\n    def format_question(self, example: dict):\n        sqls = get_sql_for_database(example[\"path_db\"])\n\n        prompt_info = self.template_info.format(\"\\n\\n\".join(sqls))\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\\n\".join(prompt_components)\n        return prompt\n\n    def format_target(self, example: dict):\n        return self.format_question(example)\n\n\nclass TextCOTPrompt(BasicPrompt):\n    template_info = \"Given the following catalog feature:\\n\" \"{}\"\n    template_question = \"Let's think step by step. Answer the following: {}\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"{_.name}: {', '.join(_.feature)}\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n    def format_target(self, example: dict):\n        return self.format_question(example)\n\n\nclass NumberSignCOTPrompt(BasicPrompt):\n    template_info = (\n        \"### Let's think step by step. Complete sqlite SQL query only and with no explanation\\n\"\n        \"### SQLite SQL tables, with their properties:\\n\"\n        \"#\\n\"\n        \"{}\\n\"\n        \"#\"\n    )\n    template_question = \"### {}\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"# {_.name}({', '.join(_.feature)})\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n    def format_target(self, example: dict):\n        return self.format_question(example)\n\n\nclass InstructionCOTPrompt(BasicPrompt):\n    template_info = (\n        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        '### Instruction:\\nLet\\'s think step by step. Write a sql to answer the question \"{}\"\\n\\n### Input:\\n{}\\n'\n    )\n    template_question = \"### Response:\"\n\n    def format_question(self, example: dict):\n        schemas = \"\\n\".join(\n            [f\"{_.name}({', '.join(_.feature)})\" for _ in example[\"tables\"]]\n        )\n\n        prompt_info = self.template_info.format(example[\"question\"], schemas)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            # TODO: extra_info should be after info\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n\n    def format_target(self, example: dict):\n        return self.format_question(example)\n\n\nclass CBRPrompt(BasicPrompt):\n    template_info = (\n        \"# The following are the table names and column names needed to generate SQL:\\n\"\n        \"Tables: {}\\n\"\n        \"Columns: *, {}\\n\"\n        \"Foreign keys: {}\"\n    )\n    template_question = '# translate \"{}\" into SQL query only and with no explanation:'\n\n    def format_question(self, example: dict):\n        tables = \", \".join([f\"{_.name}\" for _ in example[\"tables\"]])\n        columns = \", \".join(\n            [f\"{_.name}.{col}\" for _ in example[\"tables\"] for col in _.feature]\n        )\n        # foreign_keys\n        foreign_keys = list()\n        for table in example[\"tables\"]:\n            for pair_str in table[\"table_info\"][\"foreign_key\"]:\n                a, b = (_.strip() for _ in pair_str[1:-1].split(\",\"))\n                foreign_keys.append(f\"{a}={b}\")\n        foreign_keys = f\"{', '.join(foreign_keys)}\"\n\n        prompt_info = self.template_info.format(tables, columns, foreign_keys)\n        prompt_extra_info = self.get_extra_info(example[\"db_id\"])\n        prompt_question = self.template_question.format(example[\"question\"])\n\n        if prompt_extra_info is None or prompt_extra_info == \"\":\n            prompt_components = [prompt_info, prompt_question]\n        else:\n            prompt_components = [prompt_info, prompt_extra_info, prompt_question]\n\n        prompt = \"\\n\".join(prompt_components)\n        return prompt\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/sqlite.py", "content": "from typing import Any\n\nimport ibis\nfrom ibis import BaseBackend\nfrom pydantic import BaseModel, Field\nfrom ryoma_ai.datasource.base import SqlDataSource\n\n\nclass SqliteConfig(BaseModel):\n    connection_url: str = Field(..., description=\"Sqlite connection URL\")\n\n\nclass SqliteDataSource(SqlDataSource):\n    def get_query_plan(self, query: str) -> Any:\n        pass\n\n    def crawl_metadata(self, **kwargs):\n        pass\n\n    def __init__(self, connection_url: str):\n        super().__init__()\n        self.connection_url = connection_url\n\n    def _connect(self) -> BaseBackend:\n        return ibis.sqlite.connect(self.connection_url)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/base.py", "content": "import logging\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Optional\n\nfrom ibis import Table as IbisTable\nfrom ibis.backends import CanListCatalog, CanListDatabase\nfrom ibis.backends.sql import SQLBackend\nfrom ryoma_ai.datasource.metadata import Catalog, Column, Schema, Table\n\n\nclass DataSource(ABC):\n    def __init__(self, type: str, **kwargs):\n        self.type = type\n\n    @abstractmethod\n    def get_catalog(self, **kwargs):\n        raise NotImplementedError(\"get_catalog is not implemented for this data source\")\n\n\nclass SqlDataSource(DataSource):\n    def __init__(self, database: Optional[str] = None, db_schema: Optional[str] = None):\n        super().__init__(type=\"sql\")\n        self.database = database\n        self.db_schema = db_schema\n        self.__connection = None\n\n    def connect(self, **kwargs) -> Any:\n        if not self.__connection:\n            self.__connection = self._connect()\n        return self.__connection\n\n    @abstractmethod\n    def _connect(self, **kwargs) -> Any:\n        raise NotImplementedError(\"connect is not implemented for this data source\")\n\n    def query(self, query, result_format=\"pandas\", **kwargs) -> IbisTable:\n        logging.info(f\"Executing query: {query}\")\n        conn = self.connect()\n        if not isinstance(conn, SQLBackend):\n            raise Exception(\"Ibis connection is not a SQLBackend\")\n        result = conn.sql(query)\n        if result_format == \"arrow\":\n            result = result.to_pyarrow()\n        elif result_format == \"polars\":\n            result = result.to_polars()\n        else:\n            result = result.to_pandas()\n        return result\n\n    def get_catalog(\n        self,\n        catalog: Optional[str] = None,\n    ):\n        catalog = self.database if not catalog else catalog\n        return self.list_schemas(catalog=catalog, with_table=True, with_columns=True)\n\n    def list_catalogs(\n        self,\n        like: Optional[str] = None,\n        with_schema: bool = False,\n        with_table: bool = False,\n        with_columns: bool = False,\n    ) -> list[Catalog]:\n        conn: CanListCatalog = self.connect()\n        if not hasattr(conn, \"list_catalogs\"):\n            raise Exception(\"This data source does not support listing catalogs\")\n        catalogs = [\n            Catalog(catalog_name=catalog) for catalog in conn.list_catalogs(like=like)\n        ]\n        if with_schema:\n            for catalog in catalogs:\n                catalog.schemas = self.list_schemas(catalog=catalog.catalog_name)\n        if with_table:\n            for catalog in catalogs:\n                for schema in catalog.schemas:\n                    schema.tables = self.list_tables(\n                        catalog=catalog.catalog_name,\n                        schema=schema.schema_name,\n                        with_columns=with_columns,\n                    )\n        return catalogs\n\n    def list_schemas(\n        self,\n        catalog: Optional[str] = None,\n        with_table: bool = False,\n        with_columns: bool = False,\n    ) -> list[Schema]:\n        conn: CanListDatabase = self.connect()\n        if not hasattr(conn, \"list_schemas\"):\n            raise Exception(\"This data source does not support listing schemas\")\n        catalog = catalog or self.database or conn.current_database\n        schemas = [\n            Schema(schema_name=schema)\n            for schema in conn.list_databases(catalog=catalog)\n        ]\n        if with_table:\n            for schema in schemas:\n                schema.tables = self.list_tables(\n                    catalog=catalog,\n                    schema=schema.schema_name,\n                    with_columns=with_columns,\n                )\n        return schemas\n\n    def list_tables(\n        self,\n        catalog: Optional[str] = None,\n        schema: Optional[str] = None,\n        with_columns: bool = False,\n    ) -> list[Table]:\n        conn = self.connect()\n        catalog = catalog or self.database or conn.current_database\n        if schema is not None:\n            catalog = (catalog, schema)\n        tables = [\n            Table(table_name=table, columns=[])\n            for table in conn.list_tables(database=catalog)\n        ]\n        if with_columns:\n            for table in tables:\n                table_schema = conn.get_schema(table, catalog=catalog)\n                table.columns = [\n                    Column(\n                        name=name,\n                        type=table_schema[name].name,\n                        nullable=table_schema[name].nullable,\n                    )\n                    for name in table_schema\n                ]\n        return tables\n\n    @abstractmethod\n    def get_query_plan(self, query: str) -> Any:\n        raise NotImplementedError(\n            \"get_query_plan is not implemented for this data source.\"\n        )\n\n    @abstractmethod\n    def crawl_metadata(self, **kwargs):\n        raise NotImplementedError(\n            \"crawl_metadata is not implemented for this data source.\"\n        )\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/base.py", "content": "from langchain_core.prompts import ChatPromptTemplate\n\nBasePromptTemplate = ChatPromptTemplate.from_messages(\n    messages=[\n        (\n            \"system\",\n            \"\"\"\nYou are an expert in the field of data science, analysis, and data engineering.\n\"\"\",\n        )\n    ]\n)\n\nBasicContextPromptTemplate = ChatPromptTemplate.from_messages(\n    messages=[\n        (\n            \"system\",\n            \"\"\"\nYou are provided with the following context:\n{prompt_context}\n\n\"\"\",\n        )\n    ]\n)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/templates/templates_parser.py", "content": "import json\n\ndataset1 = json.load(open(\"./dataset1.json\"))\ndataset2 = json.load(open(\"./dataset2.json\"))\n\nformatted_data = {\n    \"question\": \"What are the average and minimum price (in Euro) of all products?\",\n    \"templates\": [],\n}\n\n\ndef convert(data):\n    d = {\n        \"args\": data[\"args\"],\n        \"costs\": data[\"costs\"],\n    }\n\n    for question in data[\"questions\"]:\n        if (\n            question[\"response\"]\n            == \"avg(age) , min(age) , max(age) FROM singer WHERE country = 'France'\"\n        ):\n            d[\"formatted_question\"] = question\n\n    return d\n\n\nfor data in [dataset1, dataset2]:\n    formatted_data[\"templates\"].append(convert(data))\njson.dump(formatted_data, open(\"./formatted_data.json\", \"w\"), indent=4)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/models/agent.py", "content": "from enum import Enum\n\n\nclass AgentType(Enum):\n    ryoma = \"ryoma_ai\"\n    base = \"base\"\n    embedding = \"embedding\"\n    workflow = \"workflow\"\n    custom = \"custom\"\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/utils.py", "content": "import collections\nimport os\nimport re\nimport sqlite3\n\nfrom sql_metadata import Parser\nfrom transformers import AutoTokenizer\n\n\nclass SqliteTable(dict):\n    __getattr__ = dict.__getitem__\n    __setattr__ = dict.__setitem__\n\n\ndef get_tables(path_db):\n    if not os.path.exists(path_db):\n        raise RuntimeError(f\"{path_db} not exists\")\n\n    # init sqlite connection\n    connection = sqlite3.connect(path_db)\n    cur = connection.cursor()\n\n    # extract table information\n    table_info = parse_db(path_db, cur)\n    # TODO: ! add here\n    table_names = get_table_names(cur=cur)\n\n    res = list()\n    for table_name in table_names:\n        # feature\n        schema = [_[1] for _ in cur.execute(f'PRAGMA table_info(\"{table_name}\")')]\n\n        # data\n        data = None\n        # data = cur.query(f\"SELECT * FROM {table_name} LIMIT 5\").fetchall()\n\n        # append table\n        res.append(\n            SqliteTable(\n                name=table_name,\n                schema=schema,\n                data=data,\n                table_info=table_info.get(table_name, dict()),\n            )\n        )\n\n    cur.close()\n    return res\n\n\ndef parse_db(path_db, cur=None):\n    \"\"\"Parse the sql file and extract primary and foreign keys\n\n    :param path_file:\n    :return:\n    \"\"\"\n    table_info = dict()\n    table_names = get_table_names(path_db, cur)\n\n    for table_name in table_names:\n        pks = get_primary_key(table_name, path_db, cur)\n        fks = get_foreign_key(table_name, path_db, cur)\n\n        table_info[table_name] = {\"primary_key\": pks, \"foreign_key\": fks}\n    return table_info\n\n\ndef execute_query(queries, path_db=None, cur=None):\n    \"\"\"Execute queries and return results. Reuse cur if it's not None.\"\"\"\n    assert not (\n        path_db is None and cur is None\n    ), \"path_db and cur cannot be NoneType at the same time\"\n\n    close_in_func = False\n    if cur is None:\n        con = sqlite3.connect(path_db)\n        cur = con.cursor()\n        close_in_func = True\n\n    if isinstance(queries, str):\n        results = cur.execute(queries).fetchall()\n    elif isinstance(queries, list):\n        results = list()\n        for query in queries:\n            res = cur.execute(query).fetchall()\n            results.append(res)\n    else:\n        raise TypeError(f\"queries cannot be {type(queries)}\")\n\n    # close the connection if needed\n    if close_in_func:\n        con.close()\n\n    return results\n\n\ndef format_foreign_key(table_name: str, res: list):\n    # FROM: self key | TO: target key\n    res_clean = list()\n    for row in res:\n        table, source, to = row[2:5]\n        row_clean = f\"({table_name}.{source}, {table}.{to})\"\n        res_clean.append(row_clean)\n    return res_clean\n\n\ndef get_foreign_key(table_name, path_db=None, cur=None):\n    res_raw = execute_query(f'PRAGMA foreign_key_list(\"{table_name}\")', path_db, cur)\n    res = format_foreign_key(table_name, res_raw)\n    return res\n\n\ndef get_primary_key(table_name, path_db=None, cur=None):\n    res_raw = execute_query(f'PRAGMA table_info(\"{table_name}\")', path_db, cur)\n    pks = list()\n    for row in res_raw:\n        if row[5] == 1:\n            pks.append(row[1])\n    return pks\n\n\ndef get_table_names(path_db=None, cur=None):\n    \"\"\"Get names of all tables within the catalog, and reuse cur if it's not None\"\"\"\n    table_names = execute_query(\n        queries=\"SELECT name FROM sqlite_master WHERE type='table'\",\n        path_db=path_db,\n        cur=cur,\n    )\n    table_names = [_[0] for _ in table_names]\n    return table_names\n\n\ndef filter_json(raw_response: str) -> str:\n    try:\n        id_s = raw_response.index(\"{\")\n        id_e = raw_response.rindex(\"}\")\n        if id_s > id_e:\n            raise ValueError(\"Wrong json format\")\n        else:\n            return raw_response[id_s : id_e + 1]\n    except ValueError:\n        raise ValueError(\"Wrong json format\")\n\n\ndef get_sql_for_database(path_db=None, cur=None):\n    close_in_func = False\n    if cur is None:\n        con = sqlite3.connect(path_db)\n        cur = con.cursor()\n        close_in_func = True\n\n    table_names = get_table_names(path_db, cur)\n\n    queries = [\n        f\"SELECT sql FROM sqlite_master WHERE tbl_name='{name}'\" for name in table_names\n    ]\n\n    sqls = execute_query(queries, path_db, cur)\n\n    if close_in_func:\n        cur.close()\n\n    return [_[0][0] for _ in sqls]\n\n\ndef get_tokenizer(tokenizer_type: str):\n    return 0\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_type, use_fast=False)\n    return tokenizer\n\n\ndef count_tokens(string: str, tokenizer_type: str = None, tokenizer=None):\n    return 0\n    # if tokenizer is None:\n    #     tokenizer = get_tokenizer(tokenizer_type)\n    #\n    # n_tokens = len(tokenizer.encode(string))\n    # return n_tokens\n\n\ndef sql_normalization(sql):\n    sql = sql.strip()\n\n    def white_space_fix(s):\n        parsed_s = Parser(s)\n        s = \" \".join([token.value for token in parsed_s.tokens])\n\n        return s\n\n    # convert everything except text between single quotation marks to lower case\n    def lower(s):\n        in_quotation = False\n        out_s = \"\"\n        for char in s:\n            if in_quotation:\n                out_s += char\n            else:\n                out_s += char.lower()\n\n            if char == \"'\":\n                if in_quotation:\n                    in_quotation = False\n                else:\n                    in_quotation = True\n\n        return out_s\n\n    # remove \";\"\n    def remove_semicolon(s):\n        if s.endswith(\";\"):\n            s = s[:-1]\n        return s\n\n    # double quotation -> single quotation\n    def double2single(s):\n        return s.replace('\"', \"'\")\n\n    def add_asc(s):\n        pattern = re.compile(\n            r\"order by (?:\\w+ \\( \\S+ \\)|\\w+\\.\\w+|\\w+)(?: (?:\\+|\\-|\\<|\\<\\=|\\>|\\>\\=) (?:\\w+ \\( \\S+ \\)|\\w+\\.\\w+|\\w+))*\"\n        )\n        if \"order by\" in s and \"asc\" not in s and \"desc\" not in s:\n            for p_str in pattern.findall(s):\n                s = s.replace(p_str, p_str + \" asc\")\n\n        return s\n\n    def sql_split(s):\n        while \"  \" in s:\n            s = s.replace(\"  \", \" \")\n        s = s.strip()\n        i = 0\n        toks = []\n        while i < len(s):\n            tok = \"\"\n            if s[i] == \"'\":\n                tok = tok + s[i]\n                i += 1\n                while i < len(s) and s[i] != \"'\":\n                    tok = tok + s[i]\n                    i += 1\n                if i < len(s):\n                    tok = tok + s[i]\n                    i += 1\n            else:\n                while i < len(s) and s[i] != \" \":\n                    tok = tok + s[i]\n                    i += 1\n                while i < len(s) and s[i] == \" \":\n                    i += 1\n            toks.append(tok)\n        return toks\n\n    def remove_table_alias(s):\n        tables_aliases = Parser(s).tables_aliases\n        new_tables_aliases = {}\n        for i in range(1, 11):\n            if f\"t{i}\" in tables_aliases.keys():\n                new_tables_aliases[f\"t{i}\"] = tables_aliases[f\"t{i}\"]\n        table_names = []\n        for tok in sql_split(s):\n            if \".\" in tok:\n                table_names.append(tok.split(\".\")[0])\n        for table_name in table_names:\n            if table_name in tables_aliases.keys():\n                new_tables_aliases[table_name] = tables_aliases[table_name]\n        tables_aliases = new_tables_aliases\n\n        new_s = []\n        pre_tok = \"\"\n        for tok in sql_split(s):\n            if tok in tables_aliases.keys():\n                if pre_tok == \"as\":\n                    new_s = new_s[:-1]\n                elif pre_tok != tables_aliases[tok]:\n                    new_s.append(tables_aliases[tok])\n            elif \".\" in tok:\n                split_toks = tok.split(\".\")\n                for i in range(len(split_toks)):\n                    if (\n                        len(split_toks[i]) > 2\n                        and split_toks[i][0] == \"'\"\n                        and split_toks[i][-1] == \"'\"\n                    ):\n                        split_toks[i] = split_toks[i].replace(\"'\", \"\")\n                        split_toks[i] = split_toks[i].lower()\n                    if split_toks[i] in tables_aliases.keys():\n                        split_toks[i] = tables_aliases[split_toks[i]]\n                new_s.append(\".\".join(split_toks))\n            else:\n                new_s.append(tok)\n            pre_tok = tok\n\n        # remove as\n        s = new_s\n        new_s = []\n        for i in range(len(s)):\n            if s[i] == \"as\":\n                continue\n            if i > 0 and s[i - 1] == \"as\":\n                continue\n            new_s.append(s[i])\n        new_s = \" \".join(new_s)\n\n        # for k, v in tables_aliases.items():\n        #     s = s.replace(\"as \" + k + \" \", \"\")\n        #     s = s.replace(k, v)\n\n        return new_s\n\n    processing_func = lambda x: remove_table_alias(\n        add_asc(lower(white_space_fix(double2single(remove_semicolon(x)))))\n    )\n\n    return processing_func(sql.strip())\n\n\ndef sql2skeleton(sql: str, db_schema):\n    sql = sql_normalization(sql)\n\n    table_names_original, table_dot_column_names_original, column_names_original = (\n        [],\n        [],\n        [],\n    )\n    column_names_original.append(\"*\")\n    for table_id, table_name_original in enumerate(db_schema[\"table_names_original\"]):\n        table_names_original.append(table_name_original.lower())\n        table_dot_column_names_original.append(table_name_original + \".*\")\n        for column_id_and_name in db_schema[\"column_names_original\"]:\n            column_id = column_id_and_name[0]\n            column_name_original = column_id_and_name[1]\n            table_dot_column_names_original.append(\n                table_name_original.lower() + \".\" + column_name_original.lower()\n            )\n            column_names_original.append(column_name_original.lower())\n\n    parsed_sql = Parser(sql)\n    new_sql_tokens = []\n    for token in parsed_sql.tokens:\n        # mask table names\n        if token.value in table_names_original:\n            new_sql_tokens.append(\"_\")\n        # mask column names\n        elif (\n            token.value in column_names_original\n            or token.value in table_dot_column_names_original\n        ):\n            new_sql_tokens.append(\"_\")\n        # mask string values\n        elif token.value.startswith(\"'\") and token.value.endswith(\"'\"):\n            new_sql_tokens.append(\"_\")\n        # mask positive int number\n        elif token.value.isdigit():\n            new_sql_tokens.append(\"_\")\n        # mask negative int number\n        elif isNegativeInt(token.value):\n            new_sql_tokens.append(\"_\")\n        # mask float number\n        elif isFloat(token.value):\n            new_sql_tokens.append(\"_\")\n        else:\n            new_sql_tokens.append(token.value.strip())\n\n    sql_skeleton = \" \".join(new_sql_tokens)\n\n    # remove JOIN ON keywords\n    sql_skeleton = sql_skeleton.replace(\"on _ = _ and _ = _\", \"on _ = _\")\n    sql_skeleton = sql_skeleton.replace(\"on _ = _ or _ = _\", \"on _ = _\")\n    sql_skeleton = sql_skeleton.replace(\" on _ = _\", \"\")\n    pattern3 = re.compile(\"_ (?:join _ ?)+\")\n    sql_skeleton = re.sub(pattern3, \"_ \", sql_skeleton)\n\n    # \"_ , _ , ..., _\" -> \"_\"\n    while \"_ , _\" in sql_skeleton:\n        sql_skeleton = sql_skeleton.replace(\"_ , _\", \"_\")\n\n    # remove clauses in WHERE keywords\n    ops = [\"=\", \"!=\", \">\", \">=\", \"<\", \"<=\"]\n    for op in ops:\n        if f\"_ {op} _\" in sql_skeleton:\n            sql_skeleton = sql_skeleton.replace(f\"_ {op} _\", \"_\")\n    while \"where _ and _\" in sql_skeleton or \"where _ or _\" in sql_skeleton:\n        if \"where _ and _\" in sql_skeleton:\n            sql_skeleton = sql_skeleton.replace(\"where _ and _\", \"where _\")\n        if \"where _ or _\" in sql_skeleton:\n            sql_skeleton = sql_skeleton.replace(\"where _ or _\", \"where _\")\n\n    # remove additional spaces in the skeleton\n    while \"  \" in sql_skeleton:\n        sql_skeleton = sql_skeleton.replace(\"  \", \" \")\n\n    # double check for order by\n    split_skeleton = sql_skeleton.split(\" \")\n    for i in range(2, len(split_skeleton)):\n        if (\n            split_skeleton[i - 2] == \"order\"\n            and split_skeleton[i - 1] == \"by\"\n            and split_skeleton[i] != \"_\"\n        ):\n            split_skeleton[i] = \"_\"\n    sql_skeleton = \" \".join(split_skeleton)\n\n    return sql_skeleton\n\n\ndef isNegativeInt(string):\n    if string.startswith(\"-\") and string[1:].isdigit():\n        return True\n    else:\n        return False\n\n\ndef isFloat(string):\n    if string.startswith(\"-\"):\n        string = string[1:]\n\n    s = string.split(\".\")\n    if len(s) > 2:\n        return False\n    else:\n        for s_i in s:\n            if not s_i.isdigit():\n                return False\n        return True\n\n\ndef jaccard_similarity(skeleton1, skeleton2):\n    tokens1 = skeleton1.strip().split(\" \")\n    tokens2 = skeleton2.strip().split(\" \")\n    total = len(tokens1) + len(tokens2)\n\n    def list_to_dict(tokens):\n        token_dict = collections.defaultdict(int)\n        for t in tokens:\n            token_dict[t] += 1\n        return token_dict\n\n    token_dict1 = list_to_dict(tokens1)\n    token_dict2 = list_to_dict(tokens2)\n\n    intersection = 0\n    for t in token_dict1:\n        if t in token_dict2:\n            intersection += min(token_dict1[t], token_dict2[t])\n    union = (len(tokens1) + len(tokens2)) - intersection\n    return float(intersection) / union\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/ExampleSelectorTemplate.py", "content": "import random\n\nimport numpy as np\nfrom ryoma_ai.prompt.utils import jaccard_similarity\n\n\nclass BasicExampleSelector:\n    def __init__(self, data, *args, **kwargs):\n        self.data = data\n        self.train_json = self.data.get_train_json()\n        self.db_ids = [d[\"db_id\"] for d in self.train_json]\n        self.train_questions = self.data.get_train_questions()\n\n    def get_examples(self, question, num_example, cross_domain=False):\n        pass\n\n    def domain_mask(self, candidates: list, db_id):\n        cross_domain_candidates = [\n            candidates[i] for i in range(len(self.db_ids)) if self.db_ids[i] != db_id\n        ]\n        return cross_domain_candidates\n\n    def retrieve_index(self, indexes: list, db_id):\n        cross_domain_indexes = [\n            i for i in range(len(self.db_ids)) if self.db_ids[i] != db_id\n        ]\n        retrieved_indexes = [cross_domain_indexes[i] for i in indexes]\n        return retrieved_indexes\n\n\nclass RandomExampleSelector(BasicExampleSelector):\n    def __init__(self, data, *args, **kwargs):\n        super().__init__(data)\n        random.seed(0)\n\n    def get_examples(self, target, num_example, cross_domain=False):\n        train_json = self.train_json\n        indexes = list(range(len(train_json)))\n        if cross_domain:\n            indexes = self.domain_mask(indexes, target[\"db_id\"])\n        selected_indexes = random.sample(indexes, num_example)\n        if cross_domain:\n            selected_indexes = self.retrieve_index(selected_indexes, target[\"db_id\"])\n        return [train_json[index] for index in selected_indexes]\n\n\nclass CosineSimilarExampleSelector(BasicExampleSelector):\n    def __init__(self, data, *args, **kwargs):\n        super().__init__(data)\n\n        self.SELECT_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n        # self.SELECT_MODEL = \"sentence-transformers/bert-base-nli-mean-tokens\"\n\n        from sentence_transformers import SentenceTransformer\n\n        self.bert_model = SentenceTransformer(self.SELECT_MODEL, device=\"cpu\")\n        self.train_embeddings = self.bert_model.encode(self.train_questions)\n\n    def get_examples(self, target, num_example, cross_domain=False):\n        target_embedding = self.bert_model.encode([target[\"question\"]])\n        # target_embedding = self.bert_model.embed_text([target[\"question\"]]).cpu().detach().numpy()\n\n        # find the most similar question in train dataset\n        from sklearn.metrics.pairwise import cosine_similarity\n\n        similarities = np.squeeze(\n            cosine_similarity(target_embedding, self.train_embeddings)\n        ).tolist()\n        pairs = [\n            (similarity, index)\n            for similarity, index in zip(similarities, range(len(similarities)))\n        ]\n\n        train_json = self.train_json\n        pairs_sorted = sorted(pairs, key=lambda x: x[0], reverse=True)\n        top_pairs = list()\n        for s, index in pairs_sorted:\n            similar_db_id = train_json[index][\"db_id\"]\n            if cross_domain and similar_db_id == target[\"db_id\"]:\n                continue\n            if train_json[index][\"question\"] == target[\"question\"]:\n                continue\n            top_pairs.append((index, s))\n            if len(top_pairs) >= num_example:\n                break\n\n        return [train_json[index] for (index, s) in top_pairs]\n\n\nclass EuclideanDistanceExampleSelector(BasicExampleSelector):\n    def __init__(self, data, *args, **kwargs):\n        super().__init__(data)\n\n        self.SELECT_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n\n        from sentence_transformers import SentenceTransformer\n\n        self.bert_model = SentenceTransformer(self.SELECT_MODEL, device=\"cpu\")\n        self.train_embeddings = self.bert_model.encode(self.train_questions)\n\n    def get_examples(self, target, num_example, cross_domain=False):\n        target_embedding = self.bert_model.encode([target[\"question\"]])\n\n        # find the most similar question in train dataset\n        from sklearn.metrics.pairwise import euclidean_distances\n\n        distances = np.squeeze(\n            euclidean_distances(target_embedding, self.train_embeddings)\n        ).tolist()\n        pairs = [\n            (distance, index)\n            for distance, index in zip(distances, range(len(distances)))\n        ]\n\n        train_json = self.train_json\n        pairs_sorted = sorted(pairs, key=lambda x: x[0])\n        top_pairs = list()\n        for d, index in pairs_sorted:\n            similar_db_id = train_json[index][\"db_id\"]\n            if cross_domain and similar_db_id == target[\"db_id\"]:\n                continue\n            top_pairs.append((index, d))\n            if len(top_pairs) >= num_example:\n                break\n\n        return [train_json[index] for (index, d) in top_pairs]\n\n\nclass EuclideanDistanceThresholdExampleSelector(BasicExampleSelector):\n    def __init__(self, data, *args, **kwargs):\n        super().__init__(data)\n\n        self.SELECT_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n        # self.top_distances = list()\n        self.threshold = 0.85\n\n        from sentence_transformers import SentenceTransformer\n\n        self.bert_model = SentenceTransformer(self.SELECT_MODEL, device=\"cpu\")\n        self.train_embeddings = self.bert_model.encode(self.train_questions)\n\n    def get_examples(self, target, num_example, cross_domain=False):\n        target_embedding = self.bert_model.encode([target[\"question\"]])\n\n        # find the most similar question in train dataset\n        from sklearn.metrics.pairwise import euclidean_distances\n\n        distances = np.squeeze(\n            euclidean_distances(target_embedding, self.train_embeddings)\n        ).tolist()\n        pairs = [\n            (distance, index)\n            for distance, index in zip(distances, range(len(distances)))\n        ]\n\n        train_json = self.train_json\n        pairs_sorted = sorted(pairs, key=lambda x: x[0])\n        top_pairs = list()\n        for d, index in pairs_sorted:\n            similar_db_id = train_json[index][\"db_id\"]\n            if (\n                cross_domain and similar_db_id == target[\"db_id\"]\n            ) or d > self.threshold:\n                continue\n            top_pairs.append((index, d))\n            # self.top_distances.append(d)\n            if len(top_pairs) >= num_example:\n                break\n        # print(\"mean\", np.mean(self.top_distances))    # 0.822\n        # print(\"std\", np.std(self.top_distances, ddof=1))  # 0.144\n        # print(\"max\", max(self.top_distances)) # 1.166\n\n        return [train_json[index] for (index, d) in top_pairs]\n\n\nclass EuclideanDistancePreSkeletonSimilarThresholdSelector(BasicExampleSelector):\n    def __init__(self, data, *args, **kwargs):\n        super().__init__(data)\n\n        self.SELECT_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n        self.threshold = 0.85\n\n        from sentence_transformers import SentenceTransformer\n\n        self.bert_model = SentenceTransformer(self.SELECT_MODEL, device=\"cpu\")\n        self.train_embeddings = self.bert_model.encode(self.train_questions)\n\n    def get_examples(self, target, num_example, cross_domain=False):\n        target_embedding = self.bert_model.encode([target[\"question\"]])\n\n        # find the most similar question in train dataset\n        from sklearn.metrics.pairwise import euclidean_distances\n\n        distances = np.squeeze(\n            euclidean_distances(target_embedding, self.train_embeddings)\n        ).tolist()\n        pairs = [\n            (distance, index)\n            for distance, index in zip(distances, range(len(distances)))\n        ]\n\n        train_json = self.train_json\n        pairs_sorted = sorted(pairs, key=lambda x: x[0])\n        top_pairs = list()\n        for d, index in pairs_sorted:\n            similar_db_id = train_json[index][\"db_id\"]\n            if cross_domain and similar_db_id == target[\"db_id\"]:\n                continue\n            # Skeleton similarity\n            if (\n                jaccard_similarity(\n                    train_json[index][\"pre_skeleton\"], target[\"pre_skeleton\"]\n                )\n                < self.threshold\n            ):\n                continue\n            top_pairs.append((index, d))\n            if len(top_pairs) >= num_example:\n                break\n\n        if len(top_pairs) < num_example:\n            for d, index in pairs_sorted:\n                similar_db_id = train_json[index][\"db_id\"]\n                if cross_domain and similar_db_id == target[\"db_id\"]:\n                    continue\n                # Skeleton similarity\n                if (\n                    jaccard_similarity(\n                        train_json[index][\"pre_skeleton\"], target[\"pre_skeleton\"]\n                    )\n                    >= self.threshold\n                ):\n                    continue\n                top_pairs.append((index, d))\n                if len(top_pairs) >= num_example:\n                    break\n\n        return [train_json[index] for (index, d) in top_pairs]\n\n\nclass EuclideanDistancePreSkeletonSimilarPlusSelector(BasicExampleSelector):\n    def __init__(self, data, *args, **kwargs):\n        super().__init__(data)\n\n        self.SELECT_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n\n        from sentence_transformers import SentenceTransformer\n\n        self.bert_model = SentenceTransformer(self.SELECT_MODEL, device=\"cpu\")\n        self.train_embeddings = self.bert_model.encode(self.train_questions)\n\n    def get_examples(self, target, num_example, cross_domain=False):\n        target_embedding = self.bert_model.encode([target[\"question\"]])\n\n        # find the most similar question in train dataset\n        from sklearn.metrics.pairwise import euclidean_distances\n\n        distances = np.squeeze(\n            euclidean_distances(target_embedding, self.train_embeddings)\n        ).tolist()\n        train_json = self.train_json\n        for i in range(len(train_json)):\n            distances[i] -= jaccard_similarity(\n                train_json[i][\"pre_skeleton\"], target[\"pre_skeleton\"]\n            )\n        pairs = [\n            (distance, index)\n            for distance, index in zip(distances, range(len(distances)))\n        ]\n        pairs_sorted = sorted(pairs, key=lambda x: x[0])\n        top_pairs = list()\n        for d, index in pairs_sorted:\n            similar_db_id = train_json[index][\"db_id\"]\n            if cross_domain and similar_db_id == target[\"db_id\"]:\n                continue\n            top_pairs.append((index, d))\n            if len(top_pairs) >= num_example:\n                break\n\n        return [train_json[index] for (index, d) in top_pairs]\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/duckdb.py", "content": "import inspect\nfrom typing import Any, Optional\n\nimport duckdb\nfrom ryoma_ai.datasource.base import SqlDataSource\n\n\nclass DuckDBConfig:\n    database: Optional[str] = \":memory:\"\n    read_only: Optional[bool] = False\n    temp_directory: Optional[str] = None\n    extensions: Optional[list] = None\n    config: Optional[dict] = None\n\n\nclass DuckDBDataSource(SqlDataSource):\n\n    def get_query_plan(self, query: str) -> Any:\n        pass\n\n    def crawl_metadata(self, **kwargs):\n        pass\n\n    def __init__(\n        self,\n        database: str = \":memory:\",\n        read_only: bool = False,\n        temp_directory: Optional[str] = None,\n        extensions: Optional[list] = None,\n        config: Optional[dict] = None,\n        **kwargs,\n    ):\n        super().__init__(database=database, **kwargs)\n        self.read_only = read_only\n        self.config = config or {}\n        if temp_directory:\n            self.config[\"temp_directory\"] = temp_directory\n        self.extensions = extensions\n\n    def _connect(self, **kwargs) -> Any:\n        conn = duckdb.connect(\n            database=self.database,\n            read_only=self.read_only,\n            config=self.config,\n        )\n        if self.extensions:\n            for extension in self.extensions:\n                conn.load_extension(extension)\n        return conn\n\n    def query(self, query, result_format=\"pandas\", **kwargs) -> Any:\n        conn = self.connect()\n        # TODO: Should we abstract this to support other backends?\n        inspect.currentframe().f_locals.update(**kwargs)\n        return conn.sql(query).execute().fetchdf()\n\n    def register(self, name: str, data: Any, **kwargs):\n        conn = self.connect()\n        conn.register(name, data)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/file.py", "content": "from typing import Any, Optional\n\nimport pyarrow as pa\nfrom ryoma_ai.datasource.base import DataSource\nfrom ryoma_ai.datasource.metadata import Table\n\n\nclass FileConfig:\n    pass\n\n\nclass FileDataSource(DataSource):\n    type: str = \"file\"\n    file_path: str\n    file_format: str\n    file_name: str\n\n    def __init__(\n        self,\n        file_path: str,\n        file_format: str,\n        file_name: Optional[str] = None,\n        **kwargs,\n    ):\n        super().__init__(\n            type=\"file\",\n        )\n        if not file_name:\n            file_name = file_path\n        self.file_path = file_path\n        self.file_format = file_format\n        self.file_name = file_name\n\n    def get_catalog(self, **kwargs) -> Table:\n        table_schema = self.to_arrow(**kwargs).schema\n        return Table(\n            table_name=self.file_name,\n            table_columns=[\n                {\"column_name\": name, \"column_type\": str(table_schema.field(name))}\n                for name in table_schema.names\n            ],\n        )\n\n    def to_arrow(self, **kwargs) -> pa.Table:\n        if self.file_format == \"csv\":\n            from pyarrow.csv import read_csv\n\n            return read_csv(self.file_path, **kwargs)\n        elif self.file_format == \"parquet\":\n            from pyarrow.parquet import read_table\n\n            return read_table(self.file_path, **kwargs)\n        elif self.file_format == \"json\":\n            from pyarrow.json import read_json\n\n            return read_json(self.file_path, **kwargs)\n        else:\n            raise NotImplementedError(f\"FileFormat is unsupported: {self.file_format}\")\n\n    def to_pandas(self, **kwargs):\n        return self.to_arrow().to_pandas()\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/postgres.py", "content": "import logging\nfrom typing import Optional, Union\n\nimport ibis\nfrom databuilder.extractor.sql_alchemy_extractor import SQLAlchemyExtractor\nfrom databuilder.job.job import DefaultJob\nfrom databuilder.loader.base_loader import Loader\nfrom databuilder.task.task import DefaultTask\nfrom ibis import BaseBackend\nfrom ibis.backends.sql import SQLBackend\nfrom pydantic import BaseModel, Field\nfrom pyhocon import ConfigFactory\nfrom ryoma_ai.datasource.base import SqlDataSource\nfrom ryoma_ai.datasource.metadata import Table\n\n\nclass PostgresConfig(BaseModel):\n    user: Optional[str] = Field(None, description=\"Postgres user name\")\n    password: Optional[str] = Field(None, description=\"Postgres password\")\n    host: str = Field(..., description=\"Postgres host\")\n    port: int = Field(..., description=\"Postgres port\")\n    database: str = Field(..., description=\"Database name\")\n    db_schema: Optional[str] = Field(None, description=\"Database schema\")\n\n\nclass PostgresDataSource(SqlDataSource):\n    def __init__(\n        self,\n        user: Optional[str] = \"\",\n        password: Optional[str] = \"\",\n        host: Optional[str] = None,\n        port: Optional[int] = None,\n        database: Optional[str] = None,\n        db_schema: Optional[str] = None,\n        connection_url: Optional[str] = None,\n    ):\n        super().__init__(database=database, db_schema=db_schema)\n        self.user = user\n        self.password = password\n        self.host = host\n        self.port = port\n        self.connection_url = connection_url\n\n    def _connect(self, **kwargs) -> Union[BaseBackend, SQLBackend]:\n        logging.info(\"Connecting to Postgres\")\n        if self.connection_url:\n            logging.info(\"Connection URL provided, using it to connect\")\n            return ibis.connect(self.connection_url, **kwargs)\n        logging.info(\"Connection URL not provided, using individual parameters\")\n        conn = ibis.postgres.connect(\n            user=self.user,\n            password=self.password,\n            host=self.host,\n            port=self.port,\n            database=self.database,\n            schema=self.db_schema,\n            **kwargs,\n        )\n        logging.info(\"Connected to Postgres\")\n        return conn\n\n    def connection_string(self):\n        auth_part = (\n            f\"{self.user}:{self.password}@\" if self.user and self.password else \"\"\n        )\n        return (\n            f\"postgresql+psycopg2://{auth_part}{self.host}:{self.port}/{self.database}\"\n        )\n\n    def crawl_metadata(self, loader: Loader, where_clause_suffix: Optional[str] = None):\n        from databuilder.extractor.postgres_metadata_extractor import (\n            PostgresMetadataExtractor,\n        )\n\n        logging.info(\"Start crawling metadata from Postgres database\")\n        job_config = ConfigFactory.from_dict(\n            {\n                f\"extractor.postgres_metadata.st.schemaname = '{self.db_schema or 'public'}'\": where_clause_suffix,\n                PostgresMetadataExtractor.USE_CATALOG_AS_CLUSTER_NAME: True,\n                f\"extractor.postgres_metadata.extractor.sqlalchemy.{SQLAlchemyExtractor.CONN_STRING}\": self.connection_string(),\n            }\n        )\n        job = DefaultJob(\n            conf=job_config,\n            task=DefaultTask(extractor=PostgresMetadataExtractor(), loader=loader),\n        )\n        job.launch()\n\n    def get_query_plan(self, query: str) -> Table:\n        conn = self.connect()\n        explain_query = f\"EXPLAIN {query}\"\n        return conn.sql(explain_query)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/tool/python_tool.py", "content": "import logging\nfrom typing import Any, Dict, Sequence, Type, Union\n\nfrom IPython import get_ipython\nfrom IPython.core.interactiveshell import ExecutionResult, InteractiveShell\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom langchain_core.tools import BaseTool\n\nlog = logging.getLogger(__name__)\n\n\nclass PythonInput(BaseModel):\n    script: str = Field(description=\"python script\")\n\n\nclass PythonTool(BaseTool):\n    \"\"\"Tool for running python script in an IPython environment.\"\"\"\n\n    name: str = \"run_ipython_script_tool\"\n    description: str = \"\"\"\n    Execute a python script in an IPython environment and return the result of the last expression.\n    If the script is not correct, an error message will be returned.\n    \"\"\"\n    args_schema: Type[BaseModel] = PythonInput\n\n    ipython: InteractiveShell = None\n\n    def __init__(self, /, **data: Any):\n        super().__init__(**data)\n        self.ipython = get_ipython()\n        if not self.ipython:\n            self.ipython = InteractiveShell()\n\n    def _run(\n        self,\n        script,\n    ) -> Union[str, Sequence[Dict[str, Any]], ExecutionResult]:\n        \"\"\"Execute the script, return the result or an error message.\"\"\"\n        try:\n            result = self.ipython.run_cell(script)\n            return result\n        except Exception as e:\n            return str(e)\n\n    def update_script_context(self, script_context: Any):\n        try:\n            self.ipython.user_ns.update(script_context)\n        except Exception as e:\n            return str(e)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/PromptICLTemplate.py", "content": "import numpy as np\nfrom ryoma_ai.prompt.utils import count_tokens, get_tokenizer, jaccard_similarity\n\n\nclass BasicICLPrompt:\n    NUM_EXAMPLE = None\n    SEP_EXAMPLE = \"\\n\\n\"\n\n    def __init__(self, tokenizer: str, *args, **kwargs):\n        self.tokenizer = get_tokenizer(tokenizer)\n        self.example_qualities = []\n        self.pattern_similarities = []\n\n    def record_example_quality(self, examples, target):\n        quality_list = []\n        for example in examples:\n            quality_list.append(\n                jaccard_similarity(example[\"query_skeleton\"], target[\"query_skeleton\"])\n            )\n        self.example_qualities.append(quality_list)\n\n    def get_example_quality(self):\n        if self.example_qualities:\n            return np.mean([num for row in self.example_qualities for num in row])\n        else:\n            return 1\n\n    def get_example_quality_for_each(self):\n        if self.example_qualities:\n            return [np.mean(row) for row in self.example_qualities]\n        else:\n            return []\n\n    def record_pattern_similarity(self, examples, target):\n        similarity_list = []\n        for example in examples:\n            similarity_list.append(\n                jaccard_similarity(\n                    example[\"question_pattern\"], target[\"question_pattern\"]\n                )\n            )\n        self.pattern_similarities.append(similarity_list)\n\n    def get_pattern_similarity(self):\n        if self.pattern_similarities:\n            return np.mean([num for row in self.pattern_similarities for num in row])\n        else:\n            return 1\n\n    def format(\n        self,\n        target: dict,\n        max_seq_len: int,\n        max_ans_len: int,\n        scope_factor: int,\n        cross_domain=False,\n        *args,\n        **kwargs,\n    ):\n        # target question\n        prompt_target = self.format_target(target)\n        sum_tokens = count_tokens(prompt_target, tokenizer=self.tokenizer)\n\n        if self.NUM_EXAMPLE != 0:\n            # example questions\n            examples = self.get_examples(\n                target, self.NUM_EXAMPLE * scope_factor, cross_domain=cross_domain\n            )\n            prompt_example = list()\n            question = target[\"question\"]\n            example_prefix = self.get_example_prefix()\n            selected_examples = []\n            for example in examples:\n                example_question = example[\"question\"]\n                # assert example_question != question, f\"Example is the same with target question: {question}!, \\n{target}\\n{example}\"\n                if cross_domain:\n                    assert target[\"db_id\"] != example[\"db_id\"]\n\n                example_format = self.format_example(example)\n\n                # count tokens and drop the example if exceed max_len\n                forward_tokens = count_tokens(\n                    example_prefix\n                    + self.SEP_EXAMPLE.join(\n                        prompt_example + [example_format, prompt_target]\n                    ),\n                    tokenizer=self.tokenizer,\n                )\n\n                if forward_tokens + max_ans_len <= max_seq_len:\n                    # add an example\n                    prompt_example.append(example_format)\n                    # update tokens\n                    sum_tokens = forward_tokens\n                    # record the selected examples\n                    selected_examples.append(example)\n\n                    if len(prompt_example) >= self.NUM_EXAMPLE:\n                        break\n\n            self.record_example_quality(selected_examples, target)\n            self.record_pattern_similarity(selected_examples, target)\n\n            n_valid_example = len(prompt_example)\n            if len(prompt_example) > 0:\n                prompt = example_prefix + self.SEP_EXAMPLE.join(\n                    prompt_example + [prompt_target]\n                )\n            else:\n                prompt = self.SEP_EXAMPLE.join(prompt_example + [prompt_target])\n        else:\n            n_valid_example = 0\n            prompt = prompt_target\n\n        response_clean = \" \".join(target[\"query\"].split())[len(\"SELECT \") :]\n        return {\n            \"prompt_tokens\": sum_tokens,\n            \"prompt\": prompt,\n            \"response\": response_clean,\n            \"n_examples\": n_valid_example,\n            \"db_id\": target[\"db_id\"],\n        }\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/tool/__init__.py", "content": "from ryoma_ai.tool.pandas_tool import PandasTool\nfrom ryoma_ai.tool.pyarrow_tool import ArrowTool\nfrom ryoma_ai.tool.python_tool import PythonTool\nfrom ryoma_ai.tool.spark_tool import ConvertPandasToSparkTool, SparkTool\nfrom ryoma_ai.tool.sql_tool import QueryProfileTool, SqlQueryTool\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/tool/pyarrow_tool.py", "content": "from typing import Type\n\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom ryoma_ai.tool.python_tool import PythonTool\n\n\nclass ArrowInput(BaseModel):\n    script: str = Field(description=\"PyArrow analysis script\")\n\n\nclass ArrowTool(PythonTool):\n    \"\"\"Tool for using Apache Arrow in Python.\"\"\"\n\n    name: str = \"pyarrow_tool\"\n    description: str = \"\"\"\n    Apache Arrow is a cross-language development platform for in-memory data analysis.\n    This tool allows you to run PyArrow script in Python.\n\n    PyArrow Table is available in the script context.\n    \"\"\"\n    args_schema: Type[BaseModel] = ArrowInput\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/tool/pandas_tool.py", "content": "from typing import Optional, Type\n\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom ryoma_ai.datasource.base import SqlDataSource\nfrom ryoma_ai.tool.python_tool import PythonTool\n\n\nclass PandasInput(BaseModel):\n    script: str = Field(description=\"pandas script\")\n\n\nclass PandasTool(PythonTool):\n    \"\"\"Tool for running Pandas analysis.\"\"\"\n\n    name: str = \"pandas_tool\"\n    description: str = \"\"\"\n    Run a python script by using the Pandas library.\n    If the script is not correct, an error message will be returned.\n\n    Pandas dataframes are stored in the script context.\n    \"\"\"\n    datasource: Optional[SqlDataSource] = Field(\n        None, exclude=True, description=\"SQL data source\"\n    )\n\n    args_schema: Type[BaseModel] = PandasInput\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/enums.py", "content": "class ReprType:\n    CODE_REPRESENTATION = \"SQL\"\n    TEXT_REPRESENTATION = \"TEXT\"\n    OPENAI_DEMOSTRATION = \"NUMBERSIGN\"\n    BASIC = \"BASELINE\"\n    ALPACA_SFT = \"INSTRUCTION\"\n    OPENAI_DEMOSTRATION_WFK = \"NUMBERSIGNWFK\"\n    BASIC_WOFK = \"BASELINEWOFK\"\n    TEXT_REPRESENTATION_WFK = \"TEXTWFK\"\n    ALPACA_SFT_WFK = \"INSTRUCTIONWFK\"\n    OPENAI_DEMOSTRATION_WORULE = \"NUMBERSIGNWORULE\"\n    CODE_REPRESENTATION_WRULE = \"SQLWRULE\"\n    ALPACA_SFT_WRULE = \"INSTRUCTIONWRULE\"\n    TEXT_REPRESENTATION_WRULE = \"TEXTWRULE\"\n    CODE_REPRESENTATION_COT = \"SQLCOT\"\n    TEXT_REPRESENTATION_COT = \"TEXTCOT\"\n    OPENAI_DEMOSTRATION_COT = \"NUMBERSIGNCOT\"\n    ALPACA_SFT_COT = \"INSTRUCTIONCOT\"\n    CBR = \"CBR\"\n\n\nclass ExampleFormat:\n    ONLY_SQL = \"ONLYSQL\"\n    QA = \"QA\"\n    COMPLETE = \"COMPLETE\"\n    QAWRULE = \"QAWRULE\"\n    OPENAI_DEMOSTRATION_QA = \"NUMBERSIGNQA\"\n    BASIC_QA = \"BASELINEQA\"\n\n\nclass SelectorType:\n    COS_SIMILAR = \"COSSIMILAR\"\n    RANDOM = \"RANDOM\"\n    EUC_DISTANCE = \"EUCDISTANCE\"\n    EUC_DISTANCE_THRESHOLD = \"EUCDISTANCETHRESHOLD\"\n    EUC_DISTANCE_SKELETON_SIMILARITY_THRESHOLD = \"EUCDISSKLSIMTHR\"\n    EUC_DISTANCE_QUESTION_MASK = \"EUCDISQUESTIONMASK\"\n    EUC_DISTANCE_PRE_SKELETON_SIMILARITY_THRESHOLD = \"EUCDISPRESKLSIMTHR\"\n    EUC_DISTANCE_PRE_SKELETON_SIMILARITY_PLUS = \"EUCDISPRESKLSIMPLUS\"\n    EUC_DISTANCE_MASK_PRE_SKELETON_SIMILARITY_THRESHOLD = \"EUCDISMASKPRESKLSIMTHR\"\n    EUC_DISTANCE_MASK_PRE_SKELETON_SIMILARITY_THRESHOLD_SHIFT = (\n        \"EUCDISMASKPRESKLSIMTHRSHIFT\"\n    )\n    # TODO: from the same catalog\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/datasource/factory.py", "content": "from enum import Enum\n\nfrom pydantic import BaseModel\nfrom ryoma_ai.datasource.base import DataSource, SqlDataSource\nfrom ryoma_ai.datasource.bigquery import BigqueryDataSource\nfrom ryoma_ai.datasource.duckdb import DuckDBConfig, DuckDBDataSource\nfrom ryoma_ai.datasource.file import FileConfig, FileDataSource\nfrom ryoma_ai.datasource.mysql import MySqlConfig, MySqlDataSource\nfrom ryoma_ai.datasource.nosql import DynamodbConfig, DynamodbDataSource\nfrom ryoma_ai.datasource.postgres import PostgresConfig, PostgresDataSource\nfrom ryoma_ai.datasource.snowflake import SnowflakeConfig, SnowflakeDataSource\nfrom ryoma_ai.datasource.sqlite import SqliteConfig, SqliteDataSource\n\n\nclass DataSourceProvider(Enum):\n    mysql = MySqlDataSource\n    postgres = PostgresDataSource\n    bigquery = BigqueryDataSource\n    snowflake = SnowflakeDataSource\n    file = FileDataSource\n    dynamodb = DynamodbDataSource\n    sqlite = SqliteDataSource\n    duckdb = DuckDBDataSource\n\n\nclass DataSourceConfigProvider(Enum):\n    postgres = PostgresConfig\n    snowflake = SnowflakeConfig\n    file = FileConfig\n    mysql = MySqlConfig\n    dynamodb = DynamodbConfig\n    sqlite = SqliteConfig\n    duckdb = DuckDBConfig\n\n\ndef get_supported_datasources():\n    return list(DataSourceProvider)\n\n\nclass DataSourceFactory:\n    @staticmethod\n    def create_datasource(datasource: str, *args, **kwargs) -> SqlDataSource:\n        if not hasattr(DataSourceProvider, datasource):\n            raise ValueError(f\"Unsupported datasource: {datasource}\")\n\n        datasource_class = DataSourceProvider[datasource].value\n        return datasource_class(*args, **kwargs)\n\n    @staticmethod\n    def get_model_fields(model: BaseModel):\n        return model.model_fields.copy()\n\n    @staticmethod\n    def get_datasource_config(datasource: str):\n        if not hasattr(DataSourceProvider, datasource):\n            raise ValueError(f\"Unsupported datasource: {datasource}\")\n\n        config_class = DataSourceConfigProvider[datasource].value\n        return DataSourceFactory.get_model_fields(config_class)\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/prompt/prompt_builder.py", "content": "from ryoma_ai.prompt.enums import ExampleFormat, ReprType, SelectorType\nfrom ryoma_ai.prompt.ExampleFormatTemplate import *\nfrom ryoma_ai.prompt.ExampleSelectorTemplate import *\nfrom ryoma_ai.prompt.PromptICLTemplate import BasicICLPrompt\nfrom ryoma_ai.prompt.PromptReprTemplate import *\n\n\ndef get_repr_cls(repr_type: str):\n    if repr_type == ReprType.CODE_REPRESENTATION:\n        repr_cls = SQLPrompt\n    elif repr_type == ReprType.TEXT_REPRESENTATION:\n        repr_cls = TextPrompt\n    elif repr_type == ReprType.OPENAI_DEMOSTRATION:\n        repr_cls = NumberSignPrompt\n    elif repr_type == ReprType.BASIC:\n        repr_cls = BaselinePrompt\n    elif repr_type == ReprType.ALPACA_SFT:\n        repr_cls = InstructionPrompt\n    elif repr_type == ReprType.OPENAI_DEMOSTRATION_WFK:\n        repr_cls = NumberSignWithForeignKeyPrompt\n    elif repr_type == ReprType.BASIC_WOFK:\n        repr_cls = BaselineWithoutForeignKeyPrompt\n    elif repr_type == ReprType.TEXT_REPRESENTATION_WFK:\n        repr_cls = TextWithForeignKeyPrompt\n    elif repr_type == ReprType.ALPACA_SFT_WFK:\n        repr_cls = InstructionWithForeignKeyPrompt\n    elif repr_type == ReprType.OPENAI_DEMOSTRATION_WORULE:\n        repr_cls = NumberSignWithoutRulePrompt\n    elif repr_type == ReprType.CODE_REPRESENTATION_WRULE:\n        repr_cls = SQLWithRulePrompt\n    elif repr_type == ReprType.ALPACA_SFT_WRULE:\n        repr_cls = InstructionWithRulePrompt\n    elif repr_type == ReprType.TEXT_REPRESENTATION_WRULE:\n        repr_cls = TextWithRulePrompt\n    elif repr_type == ReprType.CODE_REPRESENTATION_COT:\n        repr_cls = SQLCOTPrompt\n    elif repr_type == ReprType.TEXT_REPRESENTATION_COT:\n        repr_cls = TextCOTPrompt\n    elif repr_type == ReprType.OPENAI_DEMOSTRATION_COT:\n        repr_cls = NumberSignCOTPrompt\n    elif repr_type == ReprType.ALPACA_SFT_COT:\n        repr_cls = InstructionCOTPrompt\n    elif repr_type == ReprType.CBR:\n        repr_cls = CBRPrompt\n    else:\n        raise ValueError(f\"{repr_type} is not supported yet\")\n    return repr_cls\n\n\ndef get_example_format_cls(example_format: str):\n    if example_format == ExampleFormat.ONLY_SQL:\n        example_format_cls = SqlExampleStyle\n    elif example_format == ExampleFormat.QA:\n        example_format_cls = QuestionSqlExampleStyle\n    elif example_format == ExampleFormat.QAWRULE:\n        example_format_cls = QuestionSqlWithRuleExampleStyle\n    elif example_format == ExampleFormat.COMPLETE:\n        example_format_cls = CompleteExampleStyle\n    elif example_format == ExampleFormat.OPENAI_DEMOSTRATION_QA:\n        example_format_cls = NumberSignQuestionSqlExampleStyle\n    elif example_format == ExampleFormat.BASIC_QA:\n        example_format_cls = BaselineQuestionSqlExampleStyle\n    else:\n        raise ValueError(f\"{example_format} is not supported yet!\")\n    return example_format_cls\n\n\ndef get_example_selector(selector_type: str):\n    if selector_type == SelectorType.COS_SIMILAR:\n        selector_cls = CosineSimilarExampleSelector\n    elif selector_type == SelectorType.RANDOM:\n        selector_cls = RandomExampleSelector\n    elif selector_type == SelectorType.EUC_DISTANCE:\n        selector_cls = EuclideanDistanceExampleSelector\n    elif selector_type == SelectorType.EUC_DISTANCE_THRESHOLD:\n        selector_cls = EuclideanDistanceThresholdExampleSelector\n    elif selector_type == SelectorType.EUC_DISTANCE_PRE_SKELETON_SIMILARITY_THRESHOLD:\n        selector_cls = EuclideanDistancePreSkeletonSimilarThresholdSelector\n    elif selector_type == SelectorType.EUC_DISTANCE_PRE_SKELETON_SIMILARITY_PLUS:\n        selector_cls = EuclideanDistancePreSkeletonSimilarPlusSelector\n    else:\n        raise ValueError(f\"{selector_type} is not supported yet!\")\n    return selector_cls\n\n\ndef prompt_factory(\n    repr_type: str, k_shot: int, example_format: str, selector_type: str\n):\n    repr_cls = get_repr_cls(repr_type)\n\n    if k_shot == 0:\n        assert repr_cls is not None\n        cls_name = f\"{repr_type}_{k_shot}-SHOT\"\n\n        class PromptClass(repr_cls, BasicICLPrompt):\n            name = cls_name\n            NUM_EXAMPLE = k_shot\n\n            def __init__(self, *args, **kwargs):\n                repr_cls.__init__(self, *args, **kwargs)\n                # init tokenizer\n                BasicICLPrompt.__init__(self, *args, **kwargs)\n\n    else:\n        example_format_cls = get_example_format_cls(example_format)\n        selector_cls = get_example_selector(selector_type)\n        cls_name = f\"{repr_type}_{k_shot}-SHOT_{selector_type}_{example_format}-EXAMPLE\"\n\n        class PromptClass(selector_cls, example_format_cls, repr_cls, BasicICLPrompt):\n            name = cls_name\n            NUM_EXAMPLE = k_shot\n\n            def __init__(self, *args, **kwargs):\n                selector_cls.__init__(self, *args, **kwargs)\n                # init tokenizer\n                BasicICLPrompt.__init__(self, *args, **kwargs)\n\n    return PromptClass\n"}
{"type": "source_file", "path": "packages/ryoma_ai/ryoma_ai/states.py", "content": "from typing import Annotated\n\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langgraph.graph.message import add_messages\nfrom typing_extensions import TypedDict\n\n\nclass MessageState(TypedDict):\n    messages: Annotated[list, add_messages]\n\n    def human_message(self, content: str):\n        return [\n            message for message in self.messages if isinstance(message, HumanMessage)\n        ]\n\n    def ai_message(self, content: str):\n        return [message for message in self.messages if isinstance(message, AIMessage)]\n"}
