{"repo_info": {"repo_name": "MarketAgents", "repo_owner": "marketagents-ai", "repo_url": "https://github.com/marketagents-ai/MarketAgents"}}
{"type": "test_file", "path": "market_agents/agents/db/test_pgvector.py", "content": "import psycopg2\nimport psycopg2.extras\nimport os\nimport numpy as np\n\ndef test_pgvector():\n    conn = psycopg2.connect(\n        dbname=os.environ.get('DB_NAME', 'market_simulation'),\n        user=os.environ.get('DB_USER', 'db_user'),\n        password=os.environ.get('DB_PASSWORD', 'db_pwd@123'),\n        host=os.environ.get('DB_HOST', 'localhost'),\n        port=os.environ.get('DB_PORT', '5433')\n    )\n    cursor = conn.cursor()\n\n    # Create vector extension if it doesn't exist\n    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n    conn.commit()\n\n    # Test vector similarity search\n    query_vector = np.random.rand(1536).tolist()\n    cursor.execute(\"\"\"\n    SELECT id, memory_data, embedding <-> %s::vector AS distance\n    FROM memory_embeddings\n    ORDER BY distance\n    LIMIT 3\n    \"\"\", (query_vector,))\n\n    results = cursor.fetchall()\n    print(\"Top 3 similar vectors:\")\n    for result in results:\n        print(f\"ID: {result[0]}, Memory: {result[1]}, Distance: {result[2]}\")\n\n    cursor.close()\n    conn.close()\n\nif __name__ == \"__main__\":\n    test_pgvector()"}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/test_market_agent.py", "content": "import asyncio\nimport logging\nfrom pathlib import Path\nfrom unittest import IsolatedAsyncioTestCase\nimport unittest\n\nfrom market_agents.agents.cognitive_schemas import ReActSchema\nfrom market_agents.agents.market_agent import MarketAgent\nfrom market_agents.agents.personas.persona import Persona\nfrom market_agents.environments.environment import MultiAgentEnvironment\nfrom market_agents.environments.mechanisms.group_chat import GroupChat\nfrom market_agents.memory.agent_storage.agent_storage_api_utils import AgentStorageAPIUtils\nfrom market_agents.memory.config import load_config_from_yaml\nfrom minference.lite.models import LLMConfig, ResponseFormat\nfrom market_agents.agents.protocols.acl_message import ACLMessage\nfrom market_agents.economics.econ_agent import EconomicAgent\nfrom market_agents.agents.cognitive_steps import (\n    PerceptionStep, ActionStep, ReflectionStep, CognitiveEpisode\n)\nfrom colorama import Fore, Style\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass TestMarketAgent(IsolatedAsyncioTestCase):\n    async def asyncSetUp(self):\n        # Initialize test environment\n        self.chat_env = MultiAgentEnvironment(\n            name=\"TestGroupChat\",\n            address=\"test_chat_1\",\n            max_steps=5,\n            mechanism=GroupChat(\n                max_rounds=5,\n                sequential=False,\n                topics={\"1\": \"Market Analysis\", \"2\": \"Trading Strategy\"}\n            )\n        )\n\n        # Configure LLM\n        llm_config = LLMConfig(\n            client=\"openai\",\n            model=\"gpt-4o-mini\",\n            temperature=0.7,\n            max_tokens=1024,\n            response_format=ResponseFormat.auto_tools\n        )\n\n        # Initialize economic agent with holdings\n        econ_agent = EconomicAgent(\n            initial_holdings={\"USDC\": 1000.0, \"ETH\": 5},\n            generate_wallet=True\n        )\n\n        # Create persona\n        persona = Persona(\n            name=\"Warren Buffet\",\n            role=\"market_analyst\",\n            persona=\"Well-known investor with a multi-billion dollar fund\",\n            objectives=[\"maximize stock returns\", \"investment influencer\"],\n            trader_type=[\"Risk Averse\", \"value stocks\"],\n            communication_style=\"diplomatic\",\n            routines=[\"breakfast at mcdonalds\", \"start trading day\"],\n            skills=[\"trading\", \"investment\"]\n        )\n\n        # Load storage config and initialize agent\n        storage_config_path = Path(\"market_agents/memory/storage_config.yaml\")\n        storage_config = load_config_from_yaml(str(storage_config_path))\n        storage_utils = AgentStorageAPIUtils(config=storage_config)\n\n        # Create MarketAgent with test environment\n        self.agent = await MarketAgent.create(\n            storage_utils=storage_utils,\n            agent_id=\"agent_007\",\n            econ_agent=econ_agent,\n            environments={\"chat\": self.chat_env},\n            llm_config=llm_config,\n            protocol=ACLMessage\n        )\n\n    async def test_perception_step(self):\n        \"\"\"Test running perception step individually\"\"\"\n        self.chat_env.current_step = 2\n\n        perception_result = await self.agent.run_step(\n            step=PerceptionStep(\n                agent_id=self.agent.id,\n                environment_name=\"chat\",\n                environment_info=self.chat_env.get_global_state(),\n                structured_tool=True\n            )\n        )\n        \n        print(f\"{Fore.GREEN}Perception result: {perception_result}{Style.RESET_ALL}\")\n        self.assertIsNotNone(perception_result)\n        self.assertIsInstance(perception_result, dict)\n        self.assertIn(\"monologue\", perception_result)\n        self.assertIn(\"key_observations\", perception_result)\n\n    async def test_action_step_react(self):\n        \"\"\"Test running action step with ReAct schema\"\"\"\n        self.chat_env.current_step = 2\n        action_result = await self.agent.run_step(\n            step=ActionStep(\n                agent_id=self.agent.id,\n                environment_name=\"chat\",\n                environment_info=self.chat_env.get_global_state(),\n                structured_tool=True,\n                action_schema=ReActSchema.model_json_schema()\n            )\n        )\n        \n        print(f\"{Fore.BLUE}Action result (ReAct): {action_result}{Style.RESET_ALL}\")\n        self.assertIsNotNone(action_result)\n        self.assertIsInstance(action_result, dict)\n        self.assertIn(\"thought\", action_result)\n        self.assertIn(\"action\", action_result)\n\n    async def test_reflection_step(self):\n        \"\"\"Test running reflection step individually\"\"\"\n        self.chat_env.current_step = 2\n\n        reflection_result = await self.agent.run_step(\n            step=ReflectionStep(\n                agent_id=self.agent.id,\n                environment_name=\"chat\",\n                environment_info=self.chat_env.get_global_state(),\n                structured_tool=True\n            )\n        )\n        \n        print(f\"{Fore.YELLOW}Reflection result: {reflection_result}{Style.RESET_ALL}\")\n        self.assertIsNotNone(reflection_result)\n        self.assertIsInstance(reflection_result, dict)\n        self.assertIn(\"reflection\", reflection_result)\n        self.assertIn(\"self_critique\", reflection_result)\n\n    async def test_default_episode(self):\n        \"\"\"Test running default cognitive episode\"\"\"\n        self.chat_env.current_step = 2\n\n        self.agent.task = \"Discuss the current topic in group chat\"\n        self.agent._refresh_prompts()\n\n        results = await self.agent.run_episode(environment_name=\"chat\")\n        \n        print(f\"{Fore.CYAN}Default Episode Results:{Style.RESET_ALL}\")\n        for i, result in enumerate([\"Perception\", \"Action\", \"Reflection\"]):\n            print(f\"{Fore.CYAN}{result}: {results[i]}{Style.RESET_ALL}\")\n        \n        self.assertEqual(len(results), 3)\n        self.assertTrue(all(result is not None for result in results))\n\n    async def test_custom_schema_episode(self):\n        \"\"\"Test running episode with custom schemas\"\"\"\n        self.chat_env.current_step = 2\n\n        self.agent.task = \"Discuss current topic in group chat\"\n        self.agent._refresh_prompts()\n\n        custom_episode = CognitiveEpisode(\n            steps=[PerceptionStep, ActionStep, ReflectionStep],\n            environment_name=\"chat\"\n        )\n\n        results = await self.agent.run_episode(episode=custom_episode)\n        \n        print(f\"{Fore.MAGENTA}Custom Schema Episode Results:{Style.RESET_ALL}\")\n        for i, result in enumerate(results):\n            print(f\"{Fore.MAGENTA}Step {i+1}: {result}{Style.RESET_ALL}\")\n        \n        self.assertEqual(len(results), 3)\n        self.assertIsInstance(results[0], dict)\n        self.assertIsInstance(results[1], dict)\n        self.assertIsInstance(results[2], dict)\n\nif __name__ == '__main__':\n    asyncio.run(unittest.main())"}
{"type": "test_file", "path": "tests/test_group_chat.py", "content": "import unittest\nfrom market_agents.environments.mechanisms.group_chat import (\n    GroupChat,\n    GroupChatAction,\n    GroupChatGlobalAction,\n    GroupChatMessage\n)\n\n\nclass TestGroupChatMechanism(unittest.TestCase):\n    def setUp(self):\n        \"\"\"\n        Create two GroupChat instances:\n        1) Non-sequential mode (expects GroupChatGlobalAction).\n        2) Sequential mode (expects GroupChatAction).\n        \"\"\"\n        self.mechanism_non_sequential = GroupChat(\n            max_rounds=2,\n            # 'sequential' inherited from Mechanism, so specifying here for clarity\n            sequential=False\n        )\n        self.mechanism_sequential = GroupChat(\n            max_rounds=2,\n            sequential=True\n        )\n        # Provide speaker_order and current_speaker_index for sequential mode\n        self.mechanism_sequential.speaker_order = [\"agent-1\", \"agent-2\"]\n        self.mechanism_sequential.current_speaker_index = 0\n\n    def test_step_with_global_action_non_sequential(self):\n        \"\"\"\n        In non-sequential mode, the mechanism expects a GroupChatGlobalAction.\n        This test verifies that passing a valid GlobalAction with agent_id keys\n        and corresponding action dicts works correctly.\n        \"\"\"\n        actions_dict = {\n            \"agent-1\": {\n                \"agent_id\": \"agent-1\",\n                \"action\": {\"content\": \"Hello from agent-1\"}\n            },\n            \"agent-2\": {\n                \"agent_id\": \"agent-2\",\n                \"action\": {\"content\": \"Greetings from agent-2\"}\n            }\n        }\n        global_action = GroupChatGlobalAction(actions=actions_dict)\n        step_result = self.mechanism_non_sequential.step(global_action)\n\n        # Basic checks\n        self.assertIsNotNone(step_result)\n        self.assertFalse(step_result.done, \"Should not be done after the first step.\")\n        self.assertIn(\"agent_rewards\", step_result.info)\n        self.assertEqual(step_result.info[\"agent_rewards\"].get(\"agent-1\"), 1.0)\n        self.assertEqual(step_result.info[\"agent_rewards\"].get(\"agent-2\"), 1.0)\n\n        self.assertEqual(len(self.mechanism_non_sequential.messages), 2)\n        self.assertEqual(self.mechanism_non_sequential.messages[0].content, \"Hello from agent-1\")\n        self.assertEqual(self.mechanism_non_sequential.messages[1].content, \"Greetings from agent-2\")\n\n    def test_step_with_dict_for_global_action(self):\n        \"\"\"\n        If someone passes a pure dictionary to step() in non-sequential mode,\n        the mechanism attempts to parse it as a GroupChatGlobalAction.\n        \"\"\"\n        actions_dict = {\n            \"actions\": {\n                \"agent-10\": {\n                    \"agent_id\": \"agent-10\",\n                    \"action\": {\"content\": \"A random message for testing\"}\n                }\n            }\n        }\n        step_result = self.mechanism_non_sequential.step(actions_dict)\n        self.assertIsNotNone(step_result)\n        self.assertFalse(step_result.done)\n        self.assertEqual(len(self.mechanism_non_sequential.messages), 1)\n        self.assertEqual(\n            self.mechanism_non_sequential.messages[0].content,\n            \"A random message for testing\"\n        )\n\n    def test_step_with_local_action_sequential(self):\n        \"\"\"\n        In sequential mode, the mechanism expects a single GroupChatAction each time step.\n        Because our speaker_order is ['agent-1', 'agent-2'], the first action must come\n        from 'agent-1'. Then it auto-advances to the next speaker.\n        \"\"\"\n        action_obj = GroupChatAction(\n            agent_id=\"agent-1\",\n            action=GroupChatMessage(content=\"Hello from the first agent\")\n        )\n        step_result = self.mechanism_sequential.step(action_obj)\n\n        self.assertIsNotNone(step_result)\n        # Confirm speaker_order advanced to 'agent-2'\n        self.assertEqual(\n            self.mechanism_sequential.speaker_order[self.mechanism_sequential.current_speaker_index],\n            \"agent-2\"\n        )\n        self.assertIn(\"agent_rewards\", step_result.info)\n        self.assertEqual(len(self.mechanism_sequential.messages), 1)\n        self.assertEqual(self.mechanism_sequential.messages[0].content, \"Hello from the first agent\")\n\n    def test_step_with_incorrect_action_non_seq(self):\n        \"\"\"\n        If we pass a GroupChatAction directly in non-sequential mode,\n        it will raise an error because the code explicitly expects\n        GroupChatGlobalAction in non-sequential mode.\n        \"\"\"\n        invalid_action = GroupChatAction(\n            agent_id=\"agent-oops\",\n            action=GroupChatMessage(content=\"I'm incorrectly formatted!\")\n        )\n        with self.assertRaises(TypeError) as context:\n            self.mechanism_non_sequential.step(invalid_action)\n        self.assertIn(\"Expected GroupChatGlobalAction\", str(context.exception))\n\n    def test_step_with_incorrect_agent_turn_sequential(self):\n        \"\"\"\n        In sequential mode, if we pass an action from the wrong speaker\n        (agent-2 when it's still agent-1's turn), it should raise an error.\n        \"\"\"\n        invalid_action = GroupChatAction(\n            agent_id=\"agent-2\",\n            action=GroupChatMessage(content=\"I'm out of turn!\")\n        )\n        with self.assertRaises(ValueError) as context:\n            self.mechanism_sequential.step(invalid_action)\n        self.assertIn(\"It's not agent-2's turn\", str(context.exception))\n\n\nif __name__ == \"__main__\":\n    unittest.main()"}
{"type": "test_file", "path": "tests/test_setup_db.py", "content": "import os\nimport pytest\nimport pytest_asyncio\nfrom asyncpg import PostgresError\n\nfrom market_agents.memory.agent_storage.setup_db import AsyncDatabase\nfrom market_agents.memory.config import load_config_from_yaml\n\n@pytest.fixture\ndef db_config():\n    yaml_path = os.path.join(\n        os.path.dirname(__file__),\n        \"../market_agents/memory/memory_config.yaml\"\n    )\n    return load_config_from_yaml(yaml_path)\n\n@pytest_asyncio.fixture\nasync def db_connection(db_config):\n    db = AsyncDatabase(db_config)\n    await db.initialize()\n    yield db\n    await db.close()\n\n\n@pytest.mark.asyncio\nasync def test_database_connection(db_connection):\n    \"\"\"Test basic database connectivity and simple query execution\"\"\"\n    try:\n        # Test simple query execution\n        result = await db_connection.fetch(\"SELECT 1\")\n        assert len(result) == 1, \"Should return one row\"\n        assert result[0][0] == 1, \"Should return value 1\"\n    except Exception as e:\n        pytest.fail(f\"Database connection test failed: {e}\")\n\n@pytest.mark.asyncio\nasync def test_extension_verification(db_connection):\n    \"\"\"Verify required PostgreSQL extensions are installed\"\"\"\n    result = await db_connection.fetch(\n        \"SELECT * FROM pg_extension WHERE extname = 'vector'\"\n    )\n    assert len(result) == 1, \"Vector extension should be installed\"\n\n\n@pytest.mark.asyncio\nasync def test_transaction_rollback(db_connection):\n    \"\"\"Test transaction rollback on error\"\"\"\n    await db_connection.execute(\n        \"CREATE TEMPORARY TABLE test_table (id SERIAL PRIMARY KEY, data TEXT)\"\n    )\n\n    try:\n        async with db_connection.transaction() as conn:\n            await conn.execute(\"INSERT INTO test_table (data) VALUES ('test')\")\n            raise Exception(\"Simulated error for rollback\")\n    except Exception:\n        pass\n\n    # Verify rollback occurred\n    result = await db_connection.fetch(\"SELECT * FROM test_table\")\n    assert len(result) == 0, \"Transaction should have rolled back\"\n\n\n@pytest.mark.asyncio\nasync def test_transaction_commit(db, setup_test_tables):\n    \"\"\"Test successful transaction commit\"\"\"\n    async with db.transaction() as conn:\n        await conn.execute(\n            \"INSERT INTO users (name, email) VALUES ($1, $2)\",\n            \"Test User\", \"test@example.com\"\n        )\n\n    result = await db.fetch(\"SELECT * FROM users WHERE email = $1\", \"test@example.com\")\n    assert len(result) == 1\n    assert result[0]['name'] == \"Test User\"\n\n@pytest.mark.asyncio\nasync def test_execute_in_transaction(db_connection):\n    \"\"\"Test atomic execution of multiple queries in a transaction\"\"\"\n    await db_connection.execute(\n        \"CREATE TEMPORARY TABLE test_table (id SERIAL PRIMARY KEY, data TEXT)\"\n    )\n\n    queries = [\n        (\"INSERT INTO test_table (data) VALUES ($1)\", (\"first\",)),\n        (\"INSERT INTO test_table (data) VALUES ($1)\", (\"second\",)),\n    ]\n\n    await db_connection.execute_in_transaction(queries)\n\n    result = await db_connection.fetch(\"SELECT * FROM test_table\")\n    assert len(result) == 2, \"Both inserts should be committed\"\n\n\n@pytest.mark.asyncio\nasync def test_safe_transaction_retry(db, setup_test_tables):\n    \"\"\"Test transaction retry mechanism\"\"\"\n    retry_count = 0\n\n    async def insert_with_retry():\n        nonlocal retry_count\n        async with db.safe_transaction(max_retries=3) as conn:\n            retry_count += 1\n            if retry_count < 2:  # Fail first attempt\n                raise PostgresError(\"Simulated deadlock\")\n            await conn.execute(\n                \"INSERT INTO users (name, email) VALUES ($1, $2)\",\n                \"Retry User\", \"retry@example.com\"\n            )\n\n    await insert_with_retry()\n    assert retry_count == 2, \"Should have retried once\"\n\n    result = await db.fetch(\"SELECT * FROM users WHERE email = $1\", \"retry@example.com\")\n    assert len(result) == 1, \"Insert should have succeeded after retry\"\n\n\nif __name__ == \"__main__\":\n    pytest.main([__file__])"}
{"type": "test_file", "path": "tests/test_prompter.py", "content": "from pathlib import Path\nfrom market_agents.agents.base_agent.prompter import PromptManager\nimport logging\n\nlogger = logging.getLogger(\"test_agent\")\nlogger.setLevel(logging.DEBUG)\n\ndef test_prompt_formatting():\n    \"\"\"Test that prompts are formatted correctly with all components.\"\"\"\n    \n    # Test variables\n    system_variables = {\n        \"role\": \"financial analyst\",\n        \"persona\": \"You are an experienced financial analyst with expertise in market analysis.\",\n        \"objectives\": \"Analyze market trends and provide actionable insights.\"\n    }\n    \n    task_variables = {\n        \"task\": \"Review recent market data and generate analysis report\",\n        \"output_schema\": \"\"\"\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"analysis\": {\"type\": \"string\"},\n        \"confidence\": {\"type\": \"number\"}\n    }\n}\n\"\"\",\n        \"output_format\": \"json_object\"\n    }\n    \n    # Initialize prompt manager with default template path\n    prompt_manager = PromptManager()\n    \n    # Generate prompts\n    system_prompt = prompt_manager.get_system_prompt(system_variables)\n    task_prompt = prompt_manager.get_task_prompt(task_variables)\n    \n    # Print prompts for debugging\n    print(\"\\n=== System Prompt ===\")\n    print(system_prompt)\n    print(\"\\n=== Task Prompt ===\")\n    print(task_prompt)\n    print(\"\\n=== Task Variables ===\")\n    print(task_variables)\n    \n    # Basic assertions to verify prompt generation\n    assert \"financial analyst\" in system_prompt, \"Role not found in system prompt\"\n    assert \"Review recent market data\" in task_prompt, \"Task not found in task prompt\"\n    assert isinstance(task_prompt, str), f\"Task prompt is not a string, got {type(task_prompt)}\"\n    \n    # Check if the schema content is in the prompt (not the variable name)\n    assert '\"type\": \"object\"' in task_prompt, \"JSON schema not found in task prompt\"\n    assert '\"properties\"' in task_prompt, \"JSON schema not found in task prompt\"\n    assert '\"analysis\"' in task_prompt, \"Expected output fields not found in task prompt\"\n\n\nif __name__ == \"__main__\":\n    test_prompt_formatting()"}
{"type": "test_file", "path": "tests/test_agent.py", "content": "import unittest\nimport logging\nimport asyncio\nfrom uuid import uuid4\n\nfrom market_agents.agents.cognitive_schemas import (\n    ChainOfThoughtSchema, \n    ReActSchema, \n    PerceptionSchema, \n    ReflectionSchema,\n    Action\n)\nfrom minference.enregistry import EntityRegistry\nfrom minference.lite.models import (\n    LLMConfig,\n    LLMClient,\n    ResponseFormat,\n    StructuredTool\n)\n\nfrom market_agents.agents.base_agent.agent import Agent\n\n# Set up test logging\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\nEntityRegistry()._logger = logger\n\nclass TestAgent(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        \"\"\"Set up test fixtures that should be shared across all tests.\"\"\"\n        cls.loop = asyncio.get_event_loop()\n\n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        # Default config for text responses\n        self.text_config = LLMConfig(\n            client=LLMClient.openai,\n            model=\"gpt-4o\",\n            response_format=ResponseFormat.text,\n            max_tokens=250\n        )\n        \n        # Config for structured/schema responses\n        self.structured_config = LLMConfig(\n            client=LLMClient.openai,\n            model=\"gpt-4o\",\n            response_format=ResponseFormat.auto_tools,\n            max_tokens=1024\n        )\n\n        # Create structured tools from schema models\n        self.cot_tool = StructuredTool(\n            json_schema=ChainOfThoughtSchema.model_json_schema(),\n            name=\"chain_of_thought\",\n            description=\"Generate step-by-step reasoning with final answer\"\n        )\n\n        # Create structured tools from schema models\n        self.cot_tool = StructuredTool(\n            json_schema=ChainOfThoughtSchema.model_json_schema(),\n            name=\"chain_of_thought\",\n            description=\"Generate step-by-step reasoning with final answer\"\n        )\n\n        self.react_tool = StructuredTool(\n            json_schema=ReActSchema.model_json_schema(),\n            name=\"react_reasoning\",\n            description=\"Generate thought-action-observation cycle\"\n        )\n\n        self.perception_tool = StructuredTool(\n            json_schema=PerceptionSchema.model_json_schema(),\n            name=\"perception\",\n            description=\"Analyze environment and generate perceptions\"\n        )\n\n        self.reflection_tool = StructuredTool(\n            json_schema=ReflectionSchema.model_json_schema(),\n            name=\"reflection\",\n            description=\"Reflect on actions and generate insights\"\n        )\n    def test_agent_text_response(self):\n        \"\"\"Test agent with plain text response.\"\"\"\n        agent = Agent(\n            role=\"text_agent\",\n            task=\"Write a one sentence summary of what an LLM is.\",\n            llm_config=self.text_config,\n            tools=[]\n        )\n        \n        result = self.loop.run_until_complete(agent.execute())\n        print(f\"\\nText Response: {result}\")\n        self.assertIsInstance(result, str)\n        self.assertTrue(len(result) > 0)\n\n    def test_agent_chain_of_thought(self):\n        \"\"\"Test agent with chain of thought reasoning.\"\"\"\n        agent = Agent(\n            role=\"reasoning_agent\",\n            task=\"Calculate the sum of numbers from 1 to 5 step by step.\",\n            llm_config=self.structured_config,\n            tools=[self.cot_tool]\n        )\n        \n        result = self.loop.run_until_complete(agent.execute())\n        print(f\"\\nChain of Thought Response: {result}\")\n        cot_output = ChainOfThoughtSchema(**result)\n        \n        self.assertTrue(len(cot_output.thoughts) > 0)\n        self.assertTrue(len(cot_output.final_answer) > 0)\n\n    def test_agent_react_reasoning(self):\n        \"\"\"Test agent with ReAct reasoning pattern.\"\"\"\n        agent = Agent(\n            role=\"react_agent\",\n            task=\"Find the sum of the first 3 prime numbers. Show your work.\",\n            llm_config=self.structured_config,\n            tools=[self.react_tool]\n        )\n        \n        result = self.loop.run_until_complete(agent.execute())\n        print(f\"\\nReAct Response: {result}\")\n        react_output = ReActSchema(**result)\n        \n        self.assertTrue(len(react_output.thought) > 0)\n        if react_output.action:\n            self.assertIsInstance(react_output.action, Action)\n\n    def test_agent_perception(self):\n        \"\"\"Test agent with perception schema.\"\"\"\n        agent = Agent(\n            role=\"perceptive_agent\",\n            task=\"Analyze the current market conditions: high inflation, rising interest rates, and volatile stock market.\",\n            llm_config=self.structured_config,\n            tools=[self.perception_tool]\n        )\n        \n        result = self.loop.run_until_complete(agent.execute())\n        print(f\"\\nPerception Response: {result}\")\n        perception_output = PerceptionSchema(**result)\n        \n        self.assertTrue(len(perception_output.monologue) > 0)\n        self.assertTrue(len(perception_output.key_observations) > 0)\n        self.assertTrue(len(perception_output.strategy) > 0)\n        self.assertTrue(0 <= perception_output.confidence <= 1)\n\n    def test_agent_reflection(self):\n        \"\"\"Test agent with reflection schema.\"\"\"\n        agent = Agent(\n            role=\"reflective_agent\",\n            task=\"Reflect on a trading strategy that resulted in a 10% loss due to unexpected market volatility.\",\n            llm_config=self.structured_config,\n            tools=[self.reflection_tool]\n        )\n        \n        result = self.loop.run_until_complete(agent.execute())\n        print(f\"\\nReflection Response: {result}\")\n        reflection_output = ReflectionSchema(**result)\n        \n        self.assertTrue(len(reflection_output.reflection) > 0)\n        self.assertTrue(len(reflection_output.self_critique) > 0)\n        self.assertTrue(isinstance(reflection_output.self_reward, float))\n        self.assertTrue(len(reflection_output.strategy_update) > 0)\n\n    def test_schema_validation(self):\n        \"\"\"Test schema validation for various cognitive schemas.\"\"\"\n        # Test ChainOfThoughtSchema\n        cot_data = {\n            \"thoughts\": [{\"reasoning\": \"First step\"}, {\"reasoning\": \"Second step\"}],\n            \"final_answer\": \"The answer is 42\"\n        }\n        cot = ChainOfThoughtSchema(**cot_data)\n        self.assertEqual(len(cot.thoughts), 2)\n        \n        # Test ReActSchema\n        react_data = {\n            \"thought\": \"I should calculate this\",\n            \"action\": {\"name\": \"calculate\", \"input\": \"1 + 1\"},\n            \"observation\": \"The result is 2\",\n            \"final_answer\": \"2\"\n        }\n        react = ReActSchema(**react_data)\n        self.assertEqual(react.action.name, \"calculate\")\n        \n        # Test PerceptionSchema\n        perception_data = {\n            \"monologue\": \"Analyzing market conditions\",\n            \"key_observations\": [\"High volatility\", \"Increasing rates\"],\n            \"strategy\": [\"Reduce risk\", \"Increase cash position\"],\n            \"confidence\": 0.8\n        }\n        perception = PerceptionSchema(**perception_data)\n        self.assertEqual(len(perception.key_observations), 2)\n        \n        # Test ReflectionSchema\n        reflection_data = {\n            \"reflection\": \"The strategy was too aggressive\",\n            \"self_critique\": [\"Ignored market signals\", \"Poor timing\"],\n            \"self_reward\": 0.3,\n            \"strategy_update\": [\"Implement stricter stop-loss\", \"Better risk management\"]\n        }\n        reflection = ReflectionSchema(**reflection_data)\n        self.assertEqual(len(reflection.strategy_update), 2)\n\nif __name__ == '__main__':\n    unittest.main()"}
{"type": "test_file", "path": "market_agents/agents/db/test_pgvector_tei.py", "content": "import os\nimport psycopg2\nimport requests\nimport json\nimport numpy as np\n\n# Configuration\nSERVER_URL = 'http://38.128.232.35:8080/embed'\nDB_CONFIG = {\n    'dbname': os.environ.get('DB_NAME', 'market_simulation'),\n    'user': os.environ.get('DB_USER', 'db_user'),\n    'password': os.environ.get('DB_PASSWORD', 'db_pwd@123'),\n    'host': os.environ.get('DB_HOST', 'localhost'),\n    'port': os.environ.get('DB_PORT', '5433')\n}\n\n# Sample documents\ndocuments = [\n    \"Artificial Intelligence is transforming the world in unprecedented ways. From healthcare to transportation, AI systems are revolutionizing how we live and work. The rapid advancement of AI technologies has sparked both excitement and ethical debates about their impact on society.\",\n    \"Machine Learning enables computers to learn from data and improve their performance over time. By analyzing patterns in large datasets, ML algorithms can make predictions and decisions with increasing accuracy. This technology has found applications in recommendation systems, fraud detection, and autonomous vehicles.\",\n    \"Deep Learning is a subset of Machine Learning that uses multi-layered neural networks. These deep neural networks can automatically learn hierarchical representations of data, making them particularly effective for complex tasks like image and speech recognition. The field has seen remarkable breakthroughs in recent years.\",\n    \"Natural Language Processing allows machines to understand human language and interact with humans naturally. NLP systems can perform tasks like translation, sentiment analysis, and question answering. The technology has enabled virtual assistants and chatbots that can engage in meaningful conversations.\",\n    \"Neural networks are the foundation of Deep Learning, mimicking the structure and function of biological brains. They consist of interconnected layers of artificial neurons that process and transform input data. The architecture of neural networks can be optimized for specific tasks through training.\",\n    \"Transformers have revolutionized natural language processing with their attention mechanism. This architecture allows models to process input sequences in parallel and capture long-range dependencies effectively. The self-attention mechanism has become a cornerstone of modern NLP.\",\n    \"BERT (Bidirectional Encoder Representations from Transformers) introduced powerful pre-training techniques for language understanding. By training on massive amounts of text data, BERT models develop rich contextual representations that can be fine-tuned for specific tasks.\",\n    \"GPT (Generative Pre-trained Transformer) models demonstrate remarkable text generation capabilities. These autoregressive models can generate coherent and contextually relevant text across various domains and styles. Each new version has shown significant improvements in performance.\",\n    \"The Vision Transformer (ViT) successfully adapted the Transformer architecture for computer vision tasks. By treating images as sequences of patches, ViT models achieve state-of-the-art performance on image classification and other vision tasks.\",\n    \"T5 (Text-to-Text Transfer Transformer) unified various NLP tasks into a single text-to-text framework. This versatile architecture can handle multiple tasks like translation, summarization, and question answering using the same model architecture.\"\n]\n\n# Function to get embedding for a document\ndef get_embedding(text):\n    response = requests.post(\n        SERVER_URL,\n        headers={'Content-Type': 'application/json'},\n        data=json.dumps({'inputs': text})\n    )\n    print(f\"Response Status: {response.status_code}\")\n    print(f\"Response Content: {response.text}\")\n    \n    if response.status_code == 200:\n        try:\n            embedding = response.json()\n            if isinstance(embedding, list):\n                return embedding[0]  \n            elif isinstance(embedding, dict) and 'embedding' in embedding:\n                return embedding['embedding']\n            else:\n                print(\"Unexpected response format:\", embedding)\n                return None\n        except ValueError as e:\n            print(f\"Failed to parse JSON response: {e}\")\n            return None\n    else:\n        print(f\"Error: {response.status_code}, {response.text}\")\n        return None\n\n# Connect to the database\nconn = psycopg2.connect(**DB_CONFIG)\ncursor = conn.cursor()\n\n# Ensure the vector extension is enabled\ncursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\nconn.commit()\n\n# Create the new table with vector(768)\ncursor.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS memory_embeddings_768 (\n    id SERIAL PRIMARY KEY,\n    agent_id UUID,\n    embedding vector(768),\n    memory_data JSONB,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n);\n\"\"\")\nconn.commit()\n\n# Insert documents and their embeddings into the new table\nfor doc in documents:\n    embedding = get_embedding(doc)\n    if embedding and len(embedding) == 768:\n        agent_id = '00000000-0000-0000-0000-000000000000'\n        memory_data = {'text': doc}\n        cursor.execute(\"\"\"\n            INSERT INTO memory_embeddings_768 (agent_id, embedding, memory_data)\n            VALUES (%s, %s, %s::jsonb)\n        \"\"\", (agent_id, embedding, json.dumps(memory_data)))\n        conn.commit()\n    else:\n        print(\"Embedding size mismatch or retrieval error.\")\n\n# Query for similar documents\nquery_text = \"What is Deep Learning\"\nquery_embedding = get_embedding(query_text)\n\nif query_embedding and len(query_embedding) == 768:\n    cursor.execute(\"\"\"\n    SELECT id, memory_data, embedding <=> %s::vector AS cosine_distance\n    FROM memory_embeddings_768\n    ORDER BY cosine_distance\n    LIMIT 3\n    \"\"\", (query_embedding,))\n    results = cursor.fetchall()\n    print(\"\\nTop 3 similar documents:\")\n    for result in results:\n        print(f\"ID: {result[0]}, Memory: {result[1]['text']}, Distance: {result[2]}\")\n\n# Clean up\ncursor.close()\nconn.close()\n"}
{"type": "source_file", "path": "market_agents/agents/__init__.py", "content": ""}
{"type": "source_file", "path": "market_agents/__init__.py", "content": "import logging\n\n# Set up logging for the entire market_agents package\nlogging.getLogger(\"market_agents\").setLevel(logging.INFO)\n"}
{"type": "source_file", "path": "market_agents/agents/base_agent/__init__.py", "content": ""}
{"type": "source_file", "path": "examples/hedge_fund_team.py", "content": "from market_agents.agents.market_agent import MarketAgent\nfrom market_agents.orchestrators.market_team import MarketAgentTeam\nfrom market_agents.memory.agent_storage.agent_storage_api_utils import AgentStorageAPIUtils\nfrom market_agents.memory.config import load_config_from_yaml\nfrom market_agents.economics.econ_agent import EconomicAgent\nfrom market_agents.agents.personas.persona import Persona\nfrom minference.lite.models import LLMConfig, ResponseFormat\nfrom typing import Dict, Any\n\nasync def create_hedge_fund_team() -> MarketAgentTeam:\n    \"\"\"Create a hierarchical hedge fund team with specialized agents.\"\"\"\n    \n    # Load storage config\n    storage_config = load_config_from_yaml(\"market_agents/memory/storage_config.yaml\")\n    storage_utils = AgentStorageAPIUtils(config=storage_config)\n\n    # Create Portfolio Manager Persona\n    portfolio_manager_persona = Persona(\n        name=\"Sarah Chen\",\n        role=\"Portfolio Manager\",\n        persona=\"Experienced investment professional with strong risk management background\",\n        objectives=[\n            \"Analyze team insights and make final investment decisions\",\n            \"Manage portfolio risk and allocation\",\n            \"Coordinate team analysis efforts\"\n        ],\n        trader_type=[\"Expert\", \"Moderate\", \"Rational\"],\n        communication_style=\"Direct\",\n        routines=[\n            \"Review team analyses\",\n            \"Make portfolio decisions\",\n            \"Monitor risk metrics\"\n        ],\n        skills=[\n            \"Portfolio management\",\n            \"Risk assessment\",\n            \"Team leadership\"\n        ]\n    )\n\n    # Create Portfolio Manager\n    portfolio_manager = await MarketAgent.create(\n        storage_utils=storage_utils,\n        agent_id=\"portfolio_manager\",\n        use_llm=True,\n        llm_config=LLMConfig(\n            model=\"gpt-4o\",\n            client=\"openai\",\n            response_format=ResponseFormat.tool,\n            temperature=0.3,\n            use_cache=True\n        ),\n        persona=portfolio_manager_persona,\n        econ_agent=EconomicAgent(\n            generate_wallet=True,\n            initial_holdings={\"USDC\": 10000000.0}\n        )\n    )\n\n    # Create Fundamental Analyst Persona\n    fundamental_analyst_persona = Persona(\n        name=\"Michael Wong\",\n        role=\"Fundamental Analysis Specialist\",\n        persona=\"Detail-oriented financial analyst focused on company fundamentals\",\n        objectives=[\n            \"Analyze financial statements and metrics\",\n            \"Evaluate business models and competitive positions\",\n            \"Assess company valuations and fair value estimates\"\n        ],\n        trader_type=[\"Expert\", \"Conservative\", \"Rational\"],\n        communication_style=\"Formal\",\n        routines=[\n            \"Review financial statements\",\n            \"Conduct company research\",\n            \"Build valuation models\"\n        ],\n        skills=[\n            \"Financial analysis\",\n            \"Valuation modeling\",\n            \"Industry research\"\n        ]\n    )\n\n    # Create Fundamental Analyst\n    fundamental_analyst = await MarketAgent.create(\n        storage_utils=storage_utils,\n        agent_id=\"fundamental_analyst\",\n        use_llm=True,\n        llm_config=LLMConfig(\n            model=\"gpt-4o\",\n            client=\"openai\",\n            response_format=ResponseFormat.tool,\n            temperature=0.2,\n            use_cache=True\n        ),\n        persona=fundamental_analyst_persona\n    )\n\n    # Create Technical Analyst Persona\n    technical_analyst_persona = Persona(\n        name=\"Alex Rodriguez\",\n        role=\"Technical Analysis Specialist\",\n        persona=\"Experienced technical trader focused on price patterns\",\n        objectives=[\n            \"Analyze price trends and patterns\",\n            \"Identify key support/resistance levels\",\n            \"Generate trading signals based on technical indicators\"\n        ],\n        trader_type=[\"Expert\", \"Aggressive\", \"Impulsive\"],\n        communication_style=\"Direct\",\n        routines=[\n            \"Monitor price charts\",\n            \"Update technical indicators\",\n            \"Track market momentum\"\n        ],\n        skills=[\n            \"Technical analysis\",\n            \"Pattern recognition\",\n            \"Momentum trading\"\n        ]\n    )\n\n    # Create Technical Analyst\n    technical_analyst = await MarketAgent.create(\n        storage_utils=storage_utils,\n        agent_id=\"technical_analyst\",\n        use_llm=True,\n        llm_config=LLMConfig(\n            model=\"gpt-4o\",\n            client=\"openai\",\n            response_format=ResponseFormat.tool,\n            temperature=0.2,\n            use_cache=True\n        ),\n        persona=technical_analyst_persona\n    )\n\n    # Create Macro Analyst Persona\n    macro_analyst_persona = Persona(\n        name=\"Emma Thompson\",\n        role=\"Macro Research Specialist\",\n        persona=\"Global macro analyst focused on economic trends\",\n        objectives=[\n            \"Monitor global economic indicators\",\n            \"Analyze central bank policies and implications\",\n            \"Assess geopolitical risks and market impacts\"\n        ],\n        trader_type=[\"Expert\", \"Moderate\", \"Rational\"],\n        communication_style=\"Formal\",\n        routines=[\n            \"Review economic data\",\n            \"Monitor policy changes\",\n            \"Analyze global trends\"\n        ],\n        skills=[\n            \"Economic analysis\",\n            \"Policy research\",\n            \"Geopolitical assessment\"\n        ]\n    )\n\n    # Create Macro Analyst\n    macro_analyst = await MarketAgent.create(\n        storage_utils=storage_utils,\n        agent_id=\"macro_analyst\",\n        use_llm=True,\n        llm_config=LLMConfig(\n            model=\"gpt-4o\",\n            client=\"openai\",\n            response_format=ResponseFormat.tool,\n            temperature=0.2,\n            use_cache=True\n        ),\n        persona=macro_analyst_persona\n    )\n\n    # Create Risk Analyst Persona\n    risk_analyst_persona = Persona(\n        name=\"David Kumar\",\n        role=\"Risk Management Specialist\",\n        persona=\"Risk-focused analyst specializing in portfolio risk assessment\",\n        objectives=[\n            \"Monitor portfolio risk metrics\",\n            \"Analyze position sizing and leverage\",\n            \"Assess market volatility and correlation risks\"\n        ],\n        trader_type=[\"Expert\", \"Conservative\", \"Rational\"],\n        communication_style=\"Direct\",\n        routines=[\n            \"Calculate risk metrics\",\n            \"Monitor exposures\",\n            \"Update risk models\"\n        ],\n        skills=[\n            \"Risk modeling\",\n            \"Portfolio analysis\",\n            \"Quantitative methods\"\n        ]\n    )\n\n    # Create Risk Analyst\n    risk_analyst = await MarketAgent.create(\n        storage_utils=storage_utils,\n        agent_id=\"risk_analyst\",\n        use_llm=True,\n        llm_config=LLMConfig(\n            model=\"gpt-4o\",\n            client=\"openai\",\n            response_format=ResponseFormat.tool,\n            temperature=0.2,\n            use_cache=True\n        ),\n        persona=risk_analyst_persona\n    )\n\n    # Define environment orchestrators\n    mcp_finance = {\n        \"name\": \"mcp_finance\",\n        \"mechanism\": \"mcp_server\",\n        \"api_url\": \"local://mcp_server\",\n        \"mcp_server_module\": \"market_agents.orchestrators.mcp_server.finance_mcp_server\",\n        \"mcp_server_class\": \"mcp\",\n        \"form_cohorts\": False,\n        \"sub_rounds\": 2,\n        \"group_size\": 5,\n        \"task_prompt\": \"\"\n    }\n\n    # Create the hedge fund team with environments\n    hedge_fund_team = MarketAgentTeam(\n        name=\"Quantum Hedge Fund\",\n        manager=portfolio_manager,\n        agents=[\n            fundamental_analyst,\n            technical_analyst,\n            macro_analyst,\n            risk_analyst\n        ],\n        mode=\"hierarchical\",\n        use_group_chat=False,\n        shared_context={\n            \"investment_coverage\": {\n                \"focus_areas\": [\"Technology\", \"AI/ML\", \"Cloud Computing\", \"Digital Platforms\", \"Semiconductors\"],\n                \"investment_thesis\": \"Focus on market-leading tech companies with strong moats, sustainable growth, and exposure to AI transformation\",\n                \"selection_criteria\": \"Companies with robust cash flows, high R&D investment, and dominant market positions\",\n                \"strategic_approach\": \"Identify companies benefiting from digital transformation and AI adoption trends\"\n            },\n            \"risk_management_strategy\": {\n                \"position_sizing\": \"Maintain moderate position sizes, never exceeding one-fifth of portfolio for any single investment\",\n                \"sector_diversification\": \"Ensure broad exposure across sectors while allowing strategic overweighting in high-conviction areas\",\n                \"downside_protection\": \"Implement disciplined exit strategies when investments move against thesis beyond acceptable thresholds\"\n            },\n            \"portfolio_strategy\": {\n                \"diversification_approach\": \"Maintain a focused but diversified portfolio of 5-15 high-conviction positions\",\n                \"capital_efficiency\": \"Employ modest leverage selectively to enhance returns while preserving capital protection\",\n                \"rebalancing_discipline\": \"Regularly reassess position weights to maintain alignment with risk tolerance and market conditions\"\n            }\n        },\n        environments=[ \n            mcp_finance,\n        ]\n    )\n\n    return hedge_fund_team \n\nasync def run_investment_analysis(team: MarketAgentTeam, ticker: str):\n    \"\"\"Run a comprehensive investment analysis using the hedge fund team.\"\"\"\n    \n    task = f\"\"\"\n    Conduct a comprehensive investment analysis for {ticker} to determine position sizing and timing.\n    \n    Required Analysis Components:\n    1. Fundamental Analysis\n       - Use MCP Finance tools to gather financial metrics and ratios\n       - Analyze company financials and competitive position\n       - Develop valuation models using available data\n    \n    2. Technical Analysis\n       - Utilize MCP Finance for price data and technical indicators\n       - Identify key chart patterns and levels\n       - Analyze volume and momentum metrics\n    \n    3. Macro Context\n       - Research economic indicators and sector trends\n       - Analyze policy impacts using research tools\n       - Evaluate market sentiment and sector correlations\n    \n    4. Risk Assessment\n       - Calculate position risk metrics using MCP Finance\n       - Analyze portfolio impact and correlations\n       - Determine risk-adjusted position sizing\n    \n    Collaboration Guidelines:\n    - Use group chat for coordinating analysis and sharing insights\n    - Leverage MCP Finance tools for data-driven analysis\n    - Access research environment for deeper context\n    - Share findings and discuss implications\n    \n    The Portfolio Manager will synthesize all analyses and tools' outputs into a final investment decision\n    including position size, entry timing, and risk parameters.\n    \"\"\"\n    \n    result = await team.execute(task)\n    return result\n\nasync def main():\n    # Create the hedge fund team\n    team = await create_hedge_fund_team()\n    \n    # Run analysis for NVDA\n    result = await run_investment_analysis(team, \"NVDA\")\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())"}
{"type": "source_file", "path": "main.py", "content": "# main.py\n\nimport asyncio\nfrom importlib import import_module\nimport logging\nimport pkgutil\nimport random\nimport uuid\nfrom pathlib import Path\nfrom typing import List, Optional, Type\n\nfrom market_agents.agents.market_agent import MarketAgent\nfrom market_agents.agents.personas.persona import load_or_generate_personas\nfrom market_agents.economics.econ_agent import EconomicAgent\nfrom market_agents.memory.knowledge_base import MarketKnowledgeBase\nfrom market_agents.memory.knowledge_base_agent import KnowledgeBaseAgent\nfrom market_agents.memory.config import AgentStorageConfig, load_config_from_yaml\nfrom market_agents.orchestrators.config import load_config\nfrom market_agents.orchestrators.meta_orchestrator import MetaOrchestrator\nfrom market_agents.agents.protocols.acl_message import ACLMessage\nfrom market_agents.memory.agent_storage.agent_storage_api_utils import AgentStorageAPIUtils\nfrom market_agents.environments.environment import MultiAgentEnvironment\n\nfrom minference.lite.models import LLMConfig, ResponseFormat\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\nlogging.getLogger(\"EntityRegistry\").setLevel(logging.CRITICAL)\n\nasync def create_kb_agent(\n    config: AgentStorageConfig,\n    kb_name: str\n) -> Optional[KnowledgeBaseAgent]:\n    \"\"\"\n    Create and initialize a KnowledgeBaseAgent if kb_name is provided and\n    the storage API passes the health check. Returns None if creation fails.\n    \"\"\"\n    if not kb_name:\n        logger.info(\"No knowledge base specified in config\")\n        return None\n\n    try:\n        storage_utils = AgentStorageAPIUtils(\n            config=config,\n            logger=logging.getLogger(\"storage_api\")\n        )\n        is_healthy = await storage_utils.check_api_health()\n        if not is_healthy:\n            logger.error(\"Storage API health check failed\")\n            return None\n\n        logger.info(f\"Creating MarketKnowledgeBase with prefix '{kb_name}'\")\n\n        market_kb = MarketKnowledgeBase(\n            config=config,\n            table_prefix=kb_name\n        )\n        \n        logger.info(f\"Initializing knowledge base '{kb_name}'\")\n        await market_kb.initialize()\n        \n        logger.info(f\"Checking if knowledge base '{kb_name}' exists\")\n        exists = await market_kb.check_table_exists()\n        if not exists:\n            logger.warning(f\"Knowledge base '{kb_name}' tables not found or empty\")\n            return None\n\n        kb_agent = KnowledgeBaseAgent(market_kb=market_kb)\n        kb_agent.id = f\"{kb_name}_agent\"\n\n        logger.info(f\"Successfully initialized knowledge base agent '{kb_name}_agent'\")\n        return kb_agent\n        \n    except Exception as e:\n        logger.error(f\"Failed to initialize knowledge base '{kb_name}': {str(e)}\")\n        return None\n\nasync def create_agents(\n    config,\n    storage_config: AgentStorageConfig,\n    environment_name: str\n) -> List[MarketAgent]:\n    \"\"\"Create market agents using the updated MarketAgent framework.\"\"\"\n    agents = []\n    num_agents = config.num_agents\n    storage_utils = AgentStorageAPIUtils(config=storage_config)\n\n    kb_agent = await create_kb_agent(storage_config, config.agent_config.knowledge_base)\n    if not kb_agent and config.agent_config.knowledge_base:\n        logger.warning(\"Failed to initialize knowledge base agent, continuing without it\")\n\n    personas_dir = Path(\"./market_agents/agents/personas/generated_personas\")\n    personas = load_or_generate_personas(personas_dir, num_agents)\n\n    if config.tool_mode:\n        response_format = ResponseFormat.tool\n    else:\n        response_format = ResponseFormat.json_object\n\n    llm_confs = config.llm_configs\n    if not llm_confs:\n        raise ValueError(\"No LLM configurations found in config\")\n\n    for i, persona in enumerate(personas):\n        agent_id = f\"agent_{i}\"\n        llm_c = llm_confs[i % len(llm_confs)]\n\n        econ_agent = EconomicAgent(\n            generate_wallet=True,\n            initial_holdings={\n                \"ETH\": 1.0,\n                \"USDC\": 1000.0\n            }\n        )\n\n        try:\n            agent = await MarketAgent.create(\n                storage_utils=storage_utils,\n                agent_id=agent_id,\n                use_llm=True,\n                llm_config=LLMConfig(\n                    model=llm_c.model,\n                    client=llm_c.client,\n                    temperature=llm_c.temperature,\n                    max_tokens=llm_c.max_tokens,\n                    use_cache=llm_c.use_cache,\n                    response_format=response_format\n                ),\n                protocol=ACLMessage,\n                persona=persona,\n                econ_agent=econ_agent,\n                knowledge_agent=kb_agent\n            )\n            agents.append(agent)\n\n        except Exception as e:\n            logger.error(f\"Failed to create agent {agent_id}: {str(e)}\")\n            continue\n\n    if not agents:\n        raise RuntimeError(\"Failed to create any agents\")\n\n    return agents\n\nasync def main():\n    logging.basicConfig(level=logging.INFO)\n    config = load_config(\"market_agents/orchestrators/orchestrator_config.yaml\")\n    storage_config = load_config_from_yaml(\"market_agents/memory/storage_config.yaml\")\n\n    all_agents = {}\n    for env_name in config.environment_order:\n        agents = await create_agents(config, storage_config, env_name)\n        all_agents[env_name] = agents\n\n    # Create orchestrator with loaded environment\n    orchestrator = MetaOrchestrator(\n        config=config,\n        agents=agents\n    )\n    await orchestrator.run_orchestration()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"}
{"type": "source_file", "path": "market_agents/agents/db/setup_database.py", "content": "import psycopg2\nimport psycopg2.extras\nfrom psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n\ndef create_database(db_params):\n    # Connect to PostgreSQL server\n    conn = psycopg2.connect(\n        dbname='postgres',  # Connect to default 'postgres' database initially\n        user=db_params['user'],\n        password=db_params['password'],\n        host=db_params['host'],\n        port=db_params['port']\n    )\n    conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n    cursor = conn.cursor()\n\n    # Create database if it doesn't exist\n    cursor.execute(\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = %s\", (db_params['dbname'],))\n    exists = cursor.fetchone()\n    if not exists:\n        cursor.execute(f\"CREATE DATABASE {db_params['dbname']}\")\n        print(f\"Database '{db_params['dbname']}' created successfully.\")\n    else:\n        print(f\"Database '{db_params['dbname']}' already exists.\")\n\n    cursor.close()\n    conn.close()\n\ndef create_tables(db_params):\n    # Connect to the specified database\n    conn = psycopg2.connect(\n        dbname=db_params['dbname'],\n        user=db_params['user'],\n        password=db_params['password'],\n        host=db_params['host'],\n        port=db_params['port']\n    )\n    cursor = conn.cursor()\n\n    # Create pgvector extension\n    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n\n    # Create tables with correct UUID types\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS agents (\n        id UUID PRIMARY KEY,\n        role VARCHAR(10) NOT NULL CHECK (role IN ('buyer', 'seller')),\n        is_llm BOOLEAN NOT NULL,\n        max_iter INTEGER NOT NULL,\n        llm_config JSONB,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS agent_memories (\n        id SERIAL PRIMARY KEY,\n        agent_id UUID REFERENCES agents(id),\n        step_id INTEGER NOT NULL,\n        memory_data JSONB,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    # Create other tables\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS preference_schedules (\n        id SERIAL PRIMARY KEY,\n        agent_id UUID REFERENCES agents(id),\n        is_buyer BOOLEAN NOT NULL,\n        values JSONB,\n        costs JSONB,\n        initial_endowment JSONB,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS allocations (\n        id SERIAL PRIMARY KEY,\n        agent_id UUID REFERENCES agents(id),\n        goods INTEGER NOT NULL,\n        cash DECIMAL(15, 2) NOT NULL,\n        locked_goods INTEGER NOT NULL,\n        locked_cash DECIMAL(15, 2) NOT NULL,\n        initial_goods INTEGER NOT NULL,\n        initial_cash DECIMAL(15, 2) NOT NULL,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS orders (\n        id SERIAL PRIMARY KEY,\n        agent_id UUID REFERENCES agents(id),\n        is_buy BOOLEAN NOT NULL,\n        quantity INTEGER NOT NULL,\n        price DECIMAL(15, 2) NOT NULL,\n        base_value DECIMAL(15, 2),\n        base_cost DECIMAL(15, 2),\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS trades (\n        id SERIAL PRIMARY KEY,\n        buyer_id UUID REFERENCES agents(id),\n        seller_id UUID REFERENCES agents(id),\n        quantity INTEGER NOT NULL,\n        price DECIMAL(15, 2) NOT NULL,\n        buyer_surplus DECIMAL(15, 2) NOT NULL,\n        seller_surplus DECIMAL(15, 2) NOT NULL,\n        total_surplus DECIMAL(15, 2) NOT NULL,\n        round INTEGER NOT NULL,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS interactions (\n        id SERIAL PRIMARY KEY,\n        agent_id UUID REFERENCES agents(id),\n        round INTEGER NOT NULL,\n        task TEXT NOT NULL,\n        response TEXT NOT NULL,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS auctions (\n        id SERIAL PRIMARY KEY,\n        max_rounds INTEGER NOT NULL,\n        current_round INTEGER NOT NULL,\n        total_surplus_extracted DECIMAL(15, 2) NOT NULL,\n        average_prices JSONB,\n        order_book JSONB,\n        trade_history JSONB,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS environments (\n        id SERIAL PRIMARY KEY,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS environment_agents (\n        id SERIAL PRIMARY KEY,\n        environment_id INTEGER REFERENCES environments(id),\n        agent_id UUID REFERENCES agents(id),\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS perceptions (\n        id SERIAL PRIMARY KEY,\n        memory_id UUID REFERENCES agents(id),\n        environment_name TEXT NOT NULL,\n        monologue TEXT,\n        strategy TEXT,\n        confidence FLOAT,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS actions (\n        id SERIAL PRIMARY KEY,\n        memory_id UUID REFERENCES agents(id),\n        environment_name TEXT NOT NULL,\n        action JSONB,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS reflections (\n        id SERIAL PRIMARY KEY,\n        memory_id UUID REFERENCES agents(id),\n        environment_name TEXT NOT NULL,\n        reflection TEXT,\n        self_reward FLOAT,\n        environment_reward FLOAT,\n        total_reward FLOAT,\n        strategy_update TEXT,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS observations (\n        id SERIAL PRIMARY KEY,\n        memory_id UUID REFERENCES agents(id),\n        environment_name TEXT NOT NULL,\n        observation JSONB,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS groupchat (\n        message_id UUID PRIMARY KEY,\n        agent_id UUID REFERENCES agents(id),\n        round INTEGER NOT NULL,\n        sub_round INTEGER,\n        cohort_id TEXT NOT NULL,\n        content TEXT NOT NULL,\n        timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n        topic TEXT\n    )\n    \"\"\")\n    # Create a new table for vector embeddings\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS memory_embeddings (\n        id SERIAL PRIMARY KEY,\n        agent_id UUID REFERENCES agents(id),\n        embedding vector(1536),\n        memory_data JSONB,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS requests (\n        id SERIAL PRIMARY KEY,\n        prompt_context_id TEXT,\n        start_time TIMESTAMP WITH TIME ZONE,\n        end_time TIMESTAMP WITH TIME ZONE,\n        total_time FLOAT,\n        model TEXT,\n        max_tokens INTEGER,\n        temperature FLOAT,\n        messages JSONB,\n        system TEXT,\n        tools JSONB,\n        tool_choice JSONB,\n        raw_response JSONB,\n        completion_tokens INTEGER,\n        prompt_tokens INTEGER,\n        total_tokens INTEGER,\n        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n    )\n    \"\"\")\n\n    # Create indexes\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_requests_prompt_context_id ON requests(prompt_context_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_memory_embeddings_embedding ON memory_embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_trades_auction_id ON trades(id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_orders_agent_id ON orders(agent_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_agent_allocations_agent_id ON allocations(agent_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_interactions_agent_id ON interactions(agent_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_agent_memories_agent_id ON agent_memories(agent_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_agent_memories_step_id ON agent_memories(step_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_perceptions_memory_id ON perceptions(memory_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_actions_memory_id ON actions(memory_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_reflections_memory_id ON reflections(memory_id)\")\n    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_observations_memory_id ON observations(memory_id)\")\n\n    conn.commit()\n    print(\"Tables, indexes, and pgvector extension created successfully.\")\n\n    cursor.close()\n    conn.close()\n\ndef insert_test_data(db_params):\n    conn = psycopg2.connect(\n        dbname=db_params['dbname'],\n        user=db_params['user'],\n        password=db_params['password'],\n        host=db_params['host'],\n        port=db_params['port']\n    )\n    cursor = conn.cursor()\n\n    # Insert a test agent\n    cursor.execute(\"\"\"\n    INSERT INTO agents (id, role, is_llm, max_iter, llm_config)\n    VALUES (gen_random_uuid(), 'buyer', true, 10, '{\"model\": \"gpt-3.5-turbo\"}')\n    RETURNING id\n    \"\"\")\n    agent_id = cursor.fetchone()[0]\n\n    # Insert test memory embeddings\n    for _ in range(5):\n        embedding = [0.0] * 1536  # Create a list of 1536 zeros\n        memory_data = {\"text\": f\"Test memory {_}\", \"timestamp\": \"2023-04-01T12:00:00Z\"}\n        cursor.execute(\"\"\"\n        INSERT INTO memory_embeddings (agent_id, embedding, memory_data)\n        VALUES (%s, %s, %s)\n        \"\"\", (agent_id, embedding, psycopg2.extras.Json(memory_data)))\n\n    conn.commit()\n    print(\"Test data inserted successfully.\")\n\n    cursor.close()\n    conn.close()\n\nif __name__ == \"__main__\":\n    # Example usage with default parameters\n    db_params = {\n        'dbname': 'market_simulation',\n        'user': 'db_user',\n        'password': 'db_pwd@123',\n        'host': 'localhost',\n        'port': '5433'\n    }\n    create_database(db_params)\n    create_tables(db_params)\n    # Optionally insert test data\n    # insert_test_data(db_params)\n"}
{"type": "source_file", "path": "market_agents/agents/protocols/protocol.py", "content": "from abc import ABC, abstractmethod\nfrom typing import Dict, Any\nfrom pydantic import BaseModel\n\nclass Protocol(BaseModel, ABC):\n    @abstractmethod\n    def parse_action(self, action: Dict[str, Any]) -> Dict[str, Any]:\n        pass\n\n    @abstractmethod\n    def generate_message(self, *args, **kwargs) -> 'Protocol':\n        pass\n\n    @classmethod\n    @abstractmethod\n    def create_message(cls, *args, **kwargs) -> 'Protocol':\n        pass"}
{"type": "source_file", "path": "market_agents/agents/personas/weighted_personas/persona_weighted.py", "content": "import yaml\nfrom pydantic import BaseModel\nfrom typing import List, Dict, Any, Union\nimport random\nfrom pathlib import Path\nimport names\n\nclass Persona(BaseModel):\n    name: str\n    role: str\n    persona: str\n    objectives: List[str]\n\nclass AttributeOptions:\n    def __init__(self, yaml_file: str):\n        with open(yaml_file, 'r') as file:\n            self.options = yaml.safe_load(file)\n\n    def get_random_option(self, attribute: str, persona_data: Dict[str, Any]) -> Any:\n        attr_config = self.options[attribute]\n        if 'options' in attr_config:\n            options = attr_config['options']\n            valid_options = self.filter_options(attribute, options, persona_data)\n            if not valid_options:\n                # If no valid options, return a random option without filtering\n                return random.choice(options)\n            if isinstance(valid_options[0], dict):\n                values = [opt['value'] for opt in valid_options]\n                weights = [opt.get('distribution', 1) for opt in valid_options]\n                return random.choices(values, weights=weights)[0]\n            return random.choice(valid_options)\n        elif 'range' in attr_config:\n            min_val, max_val = map(float, attr_config['range'].split('-'))\n            if attribute in ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']:\n                return self.generate_personality_trait(min_val, max_val)\n            return self.generate_ranged_value(attribute, min_val, max_val, persona_data)\n        return None\n\n    def filter_options(self, attribute: str, options: List[Any], persona_data: Dict[str, Any]) -> List[Any]:\n        if attribute == 'occupation':\n            valid_occupations = [opt for opt in options if self.is_valid_occupation(opt, persona_data)]\n            if not valid_occupations:\n                # If no valid occupations, return all options\n                return options\n            return valid_occupations\n        return options\n\n    def is_valid_occupation(self, occupation: Dict[str, Any], persona_data: Dict[str, Any]) -> bool:\n        age = persona_data.get('age', 0)\n        education = persona_data.get('education_level', '')\n        income = persona_data.get('income', 0)\n\n        age_valid = age >= occupation.get('min_age', 0)\n        education_valid = education in occupation.get('valid_education', [])\n        income_valid = occupation['valid_income_range'][0] <= income <= occupation['valid_income_range'][1]\n\n        # Return True if at least two out of three conditions are met\n        return sum([age_valid, education_valid, income_valid]) >= 2\n\n    def generate_personality_trait(self, min_val: float, max_val: float) -> float:\n        mean = (min_val + max_val) / 2\n        std_dev = (max_val - min_val) / 6\n        value = random.gauss(mean, std_dev)\n        return round(max(min_val, min(max_val, value)), 2)\n\n    def generate_ranged_value(self, attribute: str, min_val: float, max_val: float, persona_data: Dict[str, Any]) -> Union[int, float]:\n        if attribute == 'age':\n            return int(min_val + (max_val - min_val) * (random.random() ** 1.5))\n        return random.randint(int(min_val), int(max_val))\n\nclass AttributeRelationships:\n    def __init__(self, yaml_file: str):\n        with open(yaml_file, 'r') as file:\n            self.relationships = yaml.safe_load(file)\n\n    def get_weighted_value(self, primary_attr: str, primary_value: Any, secondary_attr: str, persona_data: Dict[str, Any]) -> List[Union[str, float]]:\n        if primary_attr in self.relationships and 'relationships' in self.relationships[primary_attr]:\n            for relation in self.relationships[primary_attr]['relationships']:\n                if relation['secondary_attribute'] == secondary_attr:\n                    if self.check_conditions(relation.get('conditions', []), persona_data):\n                        weight = relation['weight']\n                        if 'value' in relation:\n                            return [relation['value'], abs(weight)]\n                        return [primary_value, weight]\n        return [primary_value, 1.0]\n\n    def check_conditions(self, conditions: List[str], persona_data: Dict[str, Any]) -> bool:\n        return all(self.check_condition(cond, persona_data) for cond in conditions)\n\n    def check_condition(self, condition: str, persona_data: Dict[str, Any]) -> bool:\n        operators = ['>=', '<=', '>', '<', '==']\n        for op in operators:\n            if op in condition:\n                attr, value = condition.split(op)\n                attr, value = attr.strip(), value.strip()\n                attr_value = persona_data.get(attr)\n                if attr_value is None:\n                    return False\n                return eval(f\"{float(attr_value)} {op} {float(value)}\")\n        return True\n\nclass PersonaGenerator:\n    def __init__(self, relationships: AttributeRelationships, options: AttributeOptions):\n        self.relationships = relationships\n        self.options = options\n        self.attributes = list(options.options.keys())\n\n    def generate_persona(self) -> Persona:\n        persona_data = {}\n        \n        # Generate attributes in a specific order to maintain consistency\n        attribute_order = ['age', 'gender', 'education_level', 'occupation', 'income'] + [attr for attr in self.attributes if attr not in ['age', 'gender', 'education_level', 'occupation', 'income']]\n        \n        for attribute in attribute_order:\n            if attribute in ['hobbies_and_interests', 'life_events', 'short_term_goals', 'long_term_goals', 'investment_preferences']:\n                persona_data[attribute] = [self.generate_attribute(attribute, persona_data) for _ in range(min(3, len(self.options.options[attribute].get('options', []))))]\n            else:\n                persona_data[attribute] = self.generate_attribute(attribute, persona_data)\n\n        name = names.get_full_name(gender=persona_data['gender'].lower())\n        role = persona_data['role']\n\n        persona = self.format_persona(persona_data, name)\n        \n        objectives = [\n            f\"{'Purchase' if role == 'Buyer' else 'Sell'} goods at favorable prices\",\n            f\"Your goal is to {'maximize utility' if role == 'Buyer' else 'maximize profits'}\"\n        ]\n        \n        return Persona(name=name, role=role, persona=persona, objectives=objectives)\n\n    def generate_attribute(self, attribute: str, persona_data: Dict[str, Any]) -> Any:\n        value = self.options.get_random_option(attribute, persona_data)\n        if value is None:\n            return None  # Or some default value\n\n        if attribute in self.relationships.relationships and 'relationships' in self.relationships.relationships[attribute]:\n            for relation in self.relationships.relationships[attribute]['relationships']:\n                secondary_attr = relation['secondary_attribute']\n                weighted_value, weight = self.relationships.get_weighted_value(\n                    attribute, value, secondary_attr, persona_data\n                )\n                if random.random() < abs(weight):\n                    if isinstance(weighted_value, str):\n                        value = weighted_value\n                    elif weight < 0:\n                        # Inverse relationship\n                        options = self.options.options[attribute].get('options', [])\n                        if options:\n                            opposite_index = (options.index(weighted_value) + len(options) // 2) % len(options)\n                            value = options[opposite_index]\n                        elif isinstance(weighted_value, (int, float)):\n                            attr_config = self.options.options[attribute]\n                            if 'range' in attr_config:\n                                min_val, max_val = map(float, attr_config['range'].split('-'))\n                                value = min_val + max_val - weighted_value\n                    else:\n                        value = weighted_value\n\n        # Ensure integer values for non-personality traits\n        if isinstance(value, float) and attribute not in ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']:\n            value = int(round(value))\n        elif isinstance(value, float):\n            value = round(value, 2)\n\n        return value\n\n    def format_persona(self, persona_data: Dict[str, Any], name: str) -> str:\n        with open('config/03/persona_template.yaml', 'r', encoding='utf-8') as file:\n            template = file.read()\n        return template.format(name=name, **persona_data)\n\ndef str_presenter(dumper, data):\n    if '\\n' in data:\n        return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')\n    return dumper.represent_scalar('tag:yaml.org,2002:str', data)\n\nyaml.add_representer(str, str_presenter)\n\ndef save_persona_to_file(persona: Persona, output_dir: Path):\n    output_dir.mkdir(parents=True, exist_ok=True)\n    with open(output_dir / f\"{persona.name.replace(' ', '_')}.yaml\", \"w\", encoding='utf-8') as f:\n        yaml.dump(\n            persona.dict(),\n            f,\n            default_flow_style=False,\n            allow_unicode=True\n        )\n\ndef generate_and_save_personas(num_personas: int, output_dir: Path, generator: PersonaGenerator):\n    for _ in range(num_personas):\n        persona = generator.generate_persona()\n        save_persona_to_file(persona, output_dir)\n\nif __name__ == \"__main__\":\n    relationships = AttributeRelationships('config/03/attribute_relationships.yaml')\n    options = AttributeOptions('config/03/attribute_options.yaml')\n    generator = PersonaGenerator(relationships, options)\n    output_dir = Path(\"output\")\n    num_personas = 100\n    generate_and_save_personas(num_personas, output_dir, generator)\n    print(f\"Generated {num_personas} personas in {output_dir}\")"}
{"type": "source_file", "path": "market_agents/economics/__init__.py", "content": ""}
{"type": "source_file", "path": "market_agents/agents/base_agent/prompter.py", "content": "from typing import Dict, Any, Optional, Union, List\nfrom pydantic import BaseModel, Field\nfrom datetime import datetime\nfrom pathlib import Path\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\nimport yaml\nimport importlib.resources as ires\n\nclass BasePromptVariables(BaseModel):\n    \"\"\"Base class for prompt variables with common utility methods.\"\"\"\n    \n    def format_value(self, value: Any) -> str:\n        \"\"\"Format a value for template insertion.\"\"\"\n        if value is None:\n            return \"N/A\"\n        elif isinstance(value, (dict, list)):\n            return yaml.dump(value, default_flow_style=False).strip() or \"No entries\"\n        return str(value)\n\n    def get_template_vars(self) -> Dict[str, str]:\n        \"\"\"Get formatted variables for template substitution.\"\"\"\n        return {\n            key: self.format_value(value)\n            for key, value in self.model_dump().items()\n        }\n\nclass SystemPromptVariables(BasePromptVariables):\n    \"\"\"Variables for system prompt template.\"\"\"\n    role: str = Field(\n        ...,\n        description=\"Functional role of the agent\")\n    persona: Optional[str] = Field(\n        default=None,\n        description=\"Agent's persona\")\n    objectives: Optional[List[str]] = Field(\n        default=None,\n        description=\"Agent's objectives\")\n    datetime: str = Field(\n        default_factory=lambda: datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        description=\"Current timestamp\"\n    )\n\nclass TaskPromptVariables(BasePromptVariables):\n    \"\"\"Variables for task prompt template.\"\"\"\n    task: Union[str, List[str]] = Field(\n        ...,\n        description=\"Task instructions\")\n    output_schema: Optional[str] = Field(\n        default=None,\n        description=\"Output schema\")\n    output_format: str = Field(\n        default=\"text\",\n        description=\"Expected output format ('text' or 'json_object')\"\n    )\n\nclass BasePromptTemplate(BaseSettings):\n    \"\"\"Base class for loading and managing prompt templates.\"\"\"\n    \n    template_paths: List[Path] = Field(\n        default_factory=lambda: [\n            Path(ires.files(\"market_agents.agents.configs.prompts\") / \"default_prompt.yaml\")\n        ],\n        description=\"Paths to the YAML template files.\"\n    )\n    templates: Dict[str, str] = Field(\n        default_factory=dict,\n        description=\"Dictionary of loaded prompt templates.\"\n    )\n    \n    model_config = SettingsConfigDict(\n        env_prefix=\"PROMPT_\",\n        arbitrary_types_allowed=True\n    )\n    \n    def model_post_init(self, _) -> None:\n        \"\"\"Load and merge templates from all template paths.\"\"\"\n        self.templates = {}\n        for path in self.template_paths:\n            try:\n                with open(path) as f:\n                    new_templates = yaml.safe_load(f)\n                    if new_templates:\n                        self.templates.update(new_templates)\n            except FileNotFoundError:\n                raise FileNotFoundError(f\"Prompt template file not found: {path}\")\n\n    def format_prompt(self, prompt_type: str, variables: BasePromptVariables) -> str:\n        \"\"\"Format a specific prompt type with variables.\"\"\"\n        if not self.templates:\n            raise ValueError(\"No templates loaded. Check template file path and contents.\")\n            \n        if prompt_type not in self.templates:\n            raise ValueError(f\"Unknown prompt type: {prompt_type}. Available types: {list(self.templates.keys())}\")\n        \n        template = self.templates[prompt_type]\n        return template.format(**variables.get_template_vars())\n\nclass PromptTemplate(BasePromptTemplate):\n    \"\"\"Template loader for default agent prompts.\"\"\"\n    template_paths: List[Path] = Field(\n        default_factory=lambda: [\n            Path(ires.files(\"market_agents.agents.configs.prompts\") / \"default_prompt.yaml\")\n        ],\n        description=\"Default path to prompt template file.\"\n    )\n    \nclass PromptManager:\n    \"\"\"Manages prompts for agents with template-based generation.\"\"\"\n    \n    def __init__(self, template_paths: Optional[List[Path]] = None):\n        self.template = PromptTemplate(\n            template_paths=template_paths if template_paths else [\n                Path(ires.files(\"market_agents.agents.configs.prompts\") / \"default_prompt.yaml\")\n            ]\n        )\n\n    def get_system_prompt(self, variables: Dict[str, Any]) -> str:\n        \"\"\"Generate system prompt.\"\"\"\n        vars_model = SystemPromptVariables(**variables)\n        return self.template.format_prompt('system', vars_model)\n\n    def get_task_prompt(self, variables: Dict[str, Any]) -> str:\n        \"\"\"Generate task prompt.\"\"\"\n        vars_model = TaskPromptVariables(**variables)\n        return self.template.format_prompt('task', vars_model)"}
{"type": "source_file", "path": "market_agents/agents/db/dashboard/dashboard.py", "content": "from fastapi import FastAPI, HTTPException, Query\nfrom fastapi.responses import FileResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom pydantic import create_model\nfrom typing import Optional, List, Any, Dict\nimport os\nimport psycopg2\nfrom psycopg2 import sql\nfrom psycopg2.extras import RealDictCursor, Json\nfrom dotenv import load_dotenv\nfrom datetime import datetime\nimport json\nimport re\nimport argparse\n\n# Load environment variables\nload_dotenv()\n\napp = FastAPI()\n\n# Mount the static files directory\nbase_dir = os.path.dirname(os.path.abspath(__file__))\nstatic_dir = os.path.join(base_dir, 'static')\napp.mount(\"/static\", StaticFiles(directory=static_dir), name=\"static\")\n\n# Database connection parameters\nDB_PARAMS = {\n    \"dbname\": os.getenv(\"DB_NAME\"),\n    \"user\": os.getenv(\"DB_USER\"),\n    \"password\": os.getenv(\"DB_PASSWORD\"),\n    \"host\": os.getenv(\"DB_HOST\"),\n    \"port\": os.getenv(\"DB_PORT\")\n}\n\ndef get_db_connection():\n    try:\n        return psycopg2.connect(**DB_PARAMS)\n    except psycopg2.Error as e:\n        print(f\"Unable to connect to the database: {e}\")\n        raise\n\ndef get_json_paths(obj, parent_path='', paths=None):\n    if paths is None:\n        paths = {}\n    \n    if isinstance(obj, dict):\n        for key, value in obj.items():\n            new_path = f\"{parent_path}.{key}\" if parent_path else key\n            if isinstance(value, (dict, list)):\n                get_json_paths(value, new_path, paths)\n            else:\n                # Determine the type of the leaf value\n                if isinstance(value, bool):\n                    paths[new_path] = 'boolean'\n                elif isinstance(value, int):\n                    paths[new_path] = 'integer'\n                elif isinstance(value, float):\n                    paths[new_path] = 'numeric'\n                elif isinstance(value, str):\n                    # Try to detect if it's a date\n                    try:\n                        datetime.fromisoformat(value.replace('Z', '+00:00'))\n                        paths[new_path] = 'timestamp'\n                    except ValueError:\n                        paths[new_path] = 'text'\n                else:\n                    paths[new_path] = 'text'\n    \n    elif isinstance(obj, list):\n        for i, item in enumerate(obj[:5]):\n            new_path = f\"{parent_path}[{i}]\" if parent_path else str(i)\n            if isinstance(item, (dict, list)):\n                get_json_paths(item, new_path, paths)\n            else:\n                paths[new_path] = type(item).__name__\n    \n    return paths\n\ndef build_json_selector(column_path):\n    parts = column_path.split('.')\n    if len(parts) == 1:\n        return sql.Identifier(parts[0])\n    \n    base = sql.Identifier(parts[0])\n    path_parts = []\n    \n    for part in parts[1:]:\n        if '[' in part and ']' in part:\n            array_path = part.split('[')\n            path_parts.append(sql.Literal(array_path[0]))\n            index = array_path[1].rstrip(']')\n            path_parts.append(sql.Literal(int(index)))\n        else:\n            path_parts.append(sql.Literal(part))\n    \n    result = base\n    for part in path_parts[:-1]:\n        result = sql.SQL('->').join([result, part])\n    \n    return sql.SQL('->>').join([result, path_parts[-1]])\n\ndef get_column_types(cursor, table_name):\n    query = \"\"\"\n    SELECT column_name, data_type, is_nullable\n    FROM information_schema.columns\n    WHERE table_schema = 'public' AND table_name = %s\n    \"\"\"\n    cursor.execute(query, (table_name,))\n    columns = cursor.fetchall()\n    \n    result = {}\n    \n    for column in columns:\n        column_name = column['column_name']\n        data_type = column['data_type']\n        is_nullable = column['is_nullable']\n        \n        result[column_name] = {\n            'type': data_type,\n            'nullable': is_nullable\n        }\n        \n        if data_type in ('json', 'jsonb'):\n            sample_query = sql.SQL(\"\"\"\n                SELECT DISTINCT {}\n                FROM {}\n                WHERE {} IS NOT NULL\n                LIMIT 100\n            \"\"\").format(\n                sql.Identifier(column_name),\n                sql.Identifier(table_name),\n                sql.Identifier(column_name)\n            )\n            \n            cursor.execute(sample_query)\n            samples = cursor.fetchall()\n            \n            for row in samples:\n                if row[column_name]:\n                    try:\n                        data = json.loads(row[column_name]) if isinstance(row[column_name], str) else row[column_name]\n                        json_paths = get_json_paths(data)\n                        for path, path_type in json_paths.items():\n                            full_path = f\"{column_name}.{path}\"\n                            result[full_path] = {\n                                'type': path_type,\n                                'nullable': 'YES',\n                                'is_json_field': True,\n                                'parent_column': column_name,\n                                'json_path': path\n                            }\n                    except (json.JSONDecodeError, AttributeError):\n                        continue\n    \n    return result\n\ndef build_json_path_query(column):\n    parts = column.split('.')\n    if len(parts) == 1:\n        return sql.Identifier(column)\n    else:\n        base = sql.Identifier(parts[0])\n        path = [sql.Literal(part) for part in parts[1:]]\n        return sql.SQL('->').join([base] + path[:-1]) + sql.SQL('->>') + path[-1]\n\ndef flatten_json(data):\n    flattened = {}\n    if isinstance(data, dict):\n        for key, value in data.items():\n            if isinstance(value, (dict, list)):\n                flattened.update(flatten_json(value))\n            else:\n                flattened[key] = value\n    elif isinstance(data, list):\n        for i, item in enumerate(data):\n            if isinstance(item, (dict, list)):\n                flattened.update(flatten_json(item))\n            else:\n                flattened[str(i)] = item\n    else:\n        flattened = data\n    return flattened\n\n# Update argparse\nparser = argparse.ArgumentParser(description=\"SQL Dashboard with JSON handling options\")\nparser.add_argument(\"--flatten-json\", action=\"store_true\", help=\"Flatten JSON columns into separate columns. If false, format as line-separated JSON.\")\nargs = parser.parse_args()\n\ndef process_json_data(value, flatten=False):\n    if value is None:\n        return value\n    \n    try:\n        json_data = json.loads(value) if isinstance(value, str) else value\n        if flatten:\n            return flatten_json(json_data)\n        else:\n            return json.dumps(json_data, indent=2)  # Use indent=2 for pretty formatting\n    except json.JSONDecodeError:\n        return value\n\n@app.get(\"/api/get-tables\")\nasync def get_tables():\n    conn = None\n    cursor = None\n    try:\n        conn = get_db_connection()\n        cursor = conn.cursor()\n        \n        query = \"\"\"\n        SELECT table_name\n        FROM information_schema.tables\n        WHERE table_schema = 'public'\n        AND table_type = 'BASE TABLE'\n        ORDER BY table_name\n        \"\"\"\n        cursor.execute(query)\n        all_tables = [row[0] for row in cursor.fetchall()]\n        \n        non_empty_tables = []\n        for table in all_tables:\n            count_query = sql.SQL(\"SELECT EXISTS(SELECT 1 FROM {} LIMIT 1)\").format(sql.Identifier(table))\n            cursor.execute(count_query)\n            has_rows = cursor.fetchone()[0]\n            if has_rows:\n                non_empty_tables.append(table)\n        \n        return non_empty_tables\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        raise HTTPException(status_code=500, detail=\"An unexpected error occurred while fetching table names.\")\n    finally:\n        if cursor:\n            cursor.close()\n        if conn:\n            conn.close()\n\n@app.get(\"/api/column-names\")\nasync def get_column_names(table_name: str = Query(..., min_length=1)):\n    conn = None\n    cursor = None\n    try:\n        conn = get_db_connection()\n        cursor = conn.cursor(cursor_factory=RealDictCursor)\n\n        column_types = get_column_types(cursor, table_name)\n        if not column_types:\n            raise HTTPException(status_code=404, detail=\"Table not found or has no columns.\")\n\n        columns = []\n        for col, info in column_types.items():\n            column_info = {\n                \"name\": col,\n                \"type\": info['type'],\n                \"is_json\": info['type'] in ('json', 'jsonb')\n            }\n            columns.append(column_info)\n\n        return columns\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        if cursor:\n            cursor.execute(\"ROLLBACK\")\n        raise HTTPException(status_code=500, detail=\"An unexpected error occurred while fetching column names.\")\n    finally:\n        if cursor:\n            cursor.close()\n        if conn:\n            conn.close()\n\n@app.get(\"/api/metrics-data\")\nasync def get_metrics_data(\n    table_name: str = Query(..., min_length=1),\n    x_column: str = Query(None),\n    y_column: str = Query(None),\n    full_table: bool = Query(False),\n    page: int = Query(1, ge=1),\n    page_size: int = Query(100, ge=1, le=1000)\n):\n    conn = None\n    cursor = None\n    try:\n        conn = get_db_connection()\n        cursor = conn.cursor(cursor_factory=RealDictCursor)\n\n        column_types = get_column_types(cursor, table_name)\n        if not column_types:\n            raise HTTPException(status_code=404, detail=\"Table not found or has no columns.\")\n\n        json_columns = [col for col, info in column_types.items() if info['type'] in ('json', 'jsonb')]\n\n        # Calculate offset\n        offset = (page - 1) * page_size\n\n        if full_table:\n            select_parts = []\n            for col, info in column_types.items():\n                if info.get('is_json_field'):\n                    select_parts.append(\n                        sql.SQL(\"{} as {}\").format(\n                            build_json_selector(col),\n                            sql.Identifier(col.replace('.', '_'))\n                        )\n                    )\n                else:\n                    select_parts.append(sql.Identifier(col))\n\n            query = sql.SQL(\"SELECT {} FROM {} OFFSET {} LIMIT {}\").format(\n                sql.SQL(', ').join(select_parts),\n                sql.Identifier(table_name),\n                sql.Literal(offset),\n                sql.Literal(page_size)\n            )\n        else:\n            if not x_column or not y_column:\n                raise HTTPException(status_code=400, detail=\"X and Y columns must be specified when not fetching full table.\")\n            \n            x_select = build_json_selector(x_column)\n            y_select = build_json_selector(y_column)\n\n            query = sql.SQL(\"SELECT {} as x_value, {} as y_value FROM {} OFFSET {} LIMIT {}\").format(\n                x_select,\n                y_select,\n                sql.Identifier(table_name),\n                sql.Literal(offset),\n                sql.Literal(page_size)\n            )\n\n        # Get total count\n        count_query = sql.SQL(\"SELECT COUNT(*) FROM {}\").format(sql.Identifier(table_name))\n        cursor.execute(count_query)\n        total_count = cursor.fetchone()['count']\n\n        cursor.execute(query)\n        rows = cursor.fetchall()\n\n        # Process the rows (keep existing processing logic)\n        processed_rows = []\n        for row in rows:\n            processed_row = {}\n            for key, value in row.items():\n                if key in json_columns and value is not None:\n                    processed_row[key] = process_json_data(value, flatten=args.flatten_json)\n                elif isinstance(value, datetime):\n                    processed_row[key] = value.isoformat()\n                else:\n                    processed_row[key] = value\n            \n            if args.flatten_json:\n                processed_row = flatten_json(processed_row)\n            \n            processed_rows.append(processed_row)\n\n        return {\n            \"data\": processed_rows,\n            \"total_count\": total_count,\n            \"page\": page,\n            \"page_size\": page_size,\n            \"total_pages\": (total_count + page_size - 1) // page_size\n        }\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        if cursor:\n            cursor.execute(\"ROLLBACK\")\n        raise HTTPException(status_code=500, detail=f\"An unexpected error occurred: {str(e)}\")\n    finally:\n        if cursor:\n            cursor.close()\n        if conn:\n            conn.close()\n\n@app.get(\"/api/search\")\nasync def search_database(\n    table_name: str = Query(..., min_length=1),\n    search_term: str = Query(..., min_length=1),\n    columns: Optional[List[str]] = Query(None),\n    page: int = Query(1, ge=1),\n    page_size: int = Query(100, ge=1, le=1000)\n):\n    conn = None\n    cursor = None\n    try:\n        conn = get_db_connection()\n        cursor = conn.cursor(cursor_factory=RealDictCursor)\n\n        # Get column types\n        column_types = get_column_types(cursor, table_name)\n        if not column_types:\n            raise HTTPException(status_code=404, detail=\"Table not found or has no columns.\")\n\n        # If no columns specified, only use base columns\n        if not columns:\n            columns = [col for col in column_types.keys() if '.' not in col]\n\n        # Construct the WHERE clause\n        where_clauses = []\n        for col in columns:\n            if col in column_types:\n                if column_types[col]['type'] in ('json', 'jsonb'):\n                    # Simple JSON text search\n                    where_clauses.append(\n                        sql.SQL(\"CAST({} AS TEXT) ILIKE {}\").format(\n                            sql.Identifier(col),\n                            sql.Literal(f'%{search_term}%')\n                        )\n                    )\n                else:\n                    where_clauses.append(\n                        sql.SQL(\"CAST({} AS TEXT) ILIKE {}\").format(\n                            sql.Identifier(col),\n                            sql.Literal(f'%{search_term}%')\n                        )\n                    )\n\n        if not where_clauses:\n            return {\"data\": [], \"total_count\": 0, \"page\": page, \"page_size\": page_size, \"total_pages\": 0}\n\n        # Calculate offset\n        offset = (page - 1) * page_size\n\n        # Construct the query\n        query = sql.SQL(\"SELECT * FROM {} WHERE {} OFFSET {} LIMIT {}\").format(\n            sql.Identifier(table_name),\n            sql.SQL(\" OR \").join(where_clauses),\n            sql.Literal(offset),\n            sql.Literal(page_size)\n        )\n\n        # Construct the count query\n        count_query = sql.SQL(\"SELECT COUNT(*) FROM {} WHERE {}\").format(\n            sql.Identifier(table_name),\n            sql.SQL(\" OR \").join(where_clauses)\n        )\n\n        # Execute the count query\n        cursor.execute(count_query)\n        total_count = cursor.fetchone()['count']\n\n        # Execute the main query\n        cursor.execute(query)\n        results = cursor.fetchall()\n\n        # Process the results\n        processed_results = []\n        for row in results:\n            processed_row = {}\n            for key, value in row.items():\n                if column_types[key]['type'] in ('json', 'jsonb') and value is not None:\n                    processed_row[key] = process_json_data(value, flatten=args.flatten_json)\n                elif isinstance(value, datetime):\n                    processed_row[key] = value.isoformat()\n                else:\n                    processed_row[key] = value\n            \n            if args.flatten_json:\n                processed_row = flatten_json(processed_row)\n            \n            processed_results.append(processed_row)\n\n        return {\n            \"data\": processed_results,\n            \"total_count\": total_count,\n            \"page\": page,\n            \"page_size\": page_size,\n            \"total_pages\": (total_count + page_size - 1) // page_size\n        }\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        raise HTTPException(status_code=500, detail=f\"An unexpected error occurred: {str(e)}\")\n    finally:\n        if cursor:\n            cursor.close()\n        if conn:\n            conn.close()\n\n@app.get(\"/\")\nasync def read_root():\n    return FileResponse(os.path.join(static_dir, \"index.html\"))\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"}
{"type": "source_file", "path": "market_agents/agents/cognitive_tools.py", "content": "from minference.lite.models import StructuredTool\nfrom market_agents.agents.cognitive_schemas import (\n    PerceptionSchema, \n    ChainOfThoughtSchema,\n    ReflectionSchema,\n    ReActSchema,\n)\n\nperception_tool = StructuredTool.from_pydantic(\n    model=PerceptionSchema,\n    name=\"perception_tool\",\n    description=\"Analyze environment and generate perceptions\"\n)\n\nreflection_tool = StructuredTool.from_pydantic(\n    model=ReflectionSchema,\n    name=\"reflection_tool\",\n    description=\"Reflect on previous steps and strategy\"\n)\n\nchain_of_thought_tool = StructuredTool.from_pydantic(\n    model=ChainOfThoughtSchema,\n    name=\"chain_of_thought\",\n    description=\"Generate step-by-step reasoning with final answer\"\n)\n\nreact_tool = StructuredTool.from_pydantic(\n    model=ReActSchema,\n    name=\"react_reasoning\",\n    description=\"Generate thought-action-observation cycle\"\n)"}
{"type": "source_file", "path": "market_agents/memory/__init__.py", "content": ""}
{"type": "source_file", "path": "market_agents/agents/protocols/__init__.py", "content": ""}
{"type": "source_file", "path": "market_agents/agents/cognitive_steps.py", "content": "from typing import Dict, Any, Optional, Type, Union, List\nfrom datetime import datetime, timezone\nimport json\nimport asyncio\n\nfrom pydantic import BaseModel, Field\n\nfrom market_agents.environments.environment import StrAction\nfrom market_agents.memory.memory import MemoryObject\nfrom market_agents.agents.market_agent_prompter import MarketAgentPromptVariables\nfrom minference.lite.models import CallableTool, ResponseFormat, StructuredTool\nfrom market_agents.agents.cognitive_tools import (\n    perception_tool,\n    reflection_tool\n)\n\nclass CognitiveStep(BaseModel):\n    \"\"\"\n    Base class for cognitive steps in the market agent's cognitive cycle.\n    \"\"\"\n    step_name: str = Field(\n        ..., \n        description=\"Name identifier for this cognitive step\"\n    )\n    agent_id: str = Field(\n        ...,\n        description=\"ID of the agent executing this step\"\n    )\n    environment_name: str = Field(\n        ...,\n        description=\"Name of the environment being interacted with\"\n    )\n    environment_info: Any = Field(\n        ...,\n        description=\"Information about the current environment state\"\n    )\n    structured_tool: bool = Field(\n        default=True,\n        description=\"Whether to use structured output schema\"\n    )\n    return_prompt: bool = Field(\n        default=False,\n        description=\"Whether to return the prompt instead of executing\"\n    )\n\n    async def execute(self, agent: BaseModel) -> Union[str, Dict[str, Any]]:\n        \"\"\"\n        Execute the cognitive step and return the result.\n        This must be overridden in subclasses (PerceptionStep, ActionStep, ReflectionStep).\n        \"\"\"\n        raise NotImplementedError\n\n    async def store_memory(\n        self, \n        agent: BaseModel,\n        content: Any,\n        metadata: Dict[str, Any]\n    ) -> None:\n        \"\"\"\n        Store the step's result in agent memory.\n        \"\"\"\n        memory = MemoryObject(\n            agent_id=self.agent_id,\n            cognitive_step=self.step_name,\n            metadata=metadata,\n            content=json.dumps(content),\n            created_at=datetime.now(timezone.utc)\n        )\n        agent.episode_steps.append(memory)\n        await agent.short_term_memory.store_memory(memory)\n\nclass CognitiveEpisode(BaseModel):\n    \"\"\"\n    A sequence of cognitive steps forming an episode.\n    \"\"\"\n    steps: List[Type[CognitiveStep]] = Field(\n        ...,\n        description=\"Ordered list of cognitive step classes to execute\"\n    )\n    environment_name: str = Field(\n        ...,\n        description=\"Name of the environment for this episode\"\n    )\n    metadata: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=\"Optional metadata for the episode\"\n    )\n    \n    class Config:\n        arbitrary_types_allowed = True\n\n\nclass PerceptionStep(CognitiveStep):\n    step_name: str = \"perception\"\n\n    async def execute(self, agent: BaseModel) -> Union[str, Dict[str, Any]]:\n        stm_cognitive = await agent.short_term_memory.retrieve_recent_memories(\n            limit=2,\n            cognitive_step=\"action\"\n        )\n        short_term_memories = [\n            {\n                \"cognitive_step\": mem.cognitive_step,\n                \"content\": mem.content,\n                \"metadata\": mem.metadata\n            }\n            for mem in stm_cognitive\n        ]\n\n        print(\"\\nShort-term Memory Results:\")\n        memory_strings = [f\"Memory {i+1}:\\n{mem['content']}\" for i, mem in enumerate(short_term_memories)]\n        print(\"\\033[94m\" + \"\\n\\n\".join(memory_strings) + \"\\033[0m\")\n\n        task_str = f\"Task: {agent.task}\" if agent.task else \"\"\n        env_state_str = f\"Environment state: {str(self.environment_info)}\"\n        agent_state = f\"Agent state: {str(agent.last_action)} {str(agent.last_observation)}\"\n        query_str = (task_str + \"\\n\" + env_state_str + \"\\n\" + agent_state).strip()\n\n        ltm_episodes = await agent.long_term_memory.retrieve_episodic_memories(\n            agent_id=self.agent_id,\n            query=query_str,\n            top_k=1\n        )\n\n        print(\"\\nLong-term Memory Results:\")\n        memory_strings = [f\"Memory {i+1}:\\n{episode.model_dump()}\" for i, episode in enumerate(ltm_episodes)]\n        print(\"\\033[92m\" + \"\\n\\n\".join(memory_strings) + \"\\033[0m\")\n\n        retrieved_documents = []\n        if agent.knowledge_agent:\n            retrieved_documents = await agent.knowledge_agent.retrieve(\n                query=query_str,\n                top_k=1\n            )\n\n        if retrieved_documents:\n            print(\"\\nRetrieved Documents:\")\n            doc_strings = [f\"Document {i+1}:\\n{doc.model_dump()}\" for i, doc in enumerate(retrieved_documents)]\n            print(\"\\033[93m\" + \"\\n\\n\".join(doc_strings) + \"\\033[0m\")\n\n        variables = MarketAgentPromptVariables(\n            environment_name=self.environment_name,\n            environment_info=self.environment_info,\n            short_term_memory=short_term_memories,\n            long_term_memory=[episode.model_dump() for episode in ltm_episodes],\n            documents=[doc.model_dump() for doc in retrieved_documents],\n            observation=agent.last_observation,\n            last_action=agent.last_action\n        )\n\n        perception_prompt = agent.prompt_manager.get_perception_prompt(variables.model_dump())\n\n        if agent.chat_thread and self.structured_tool:\n            agent.chat_thread.tools = [perception_tool]\n            agent.chat_thread.forced_output = perception_tool\n\n        if agent.task:\n            agent._refresh_prompts()\n\n        if agent.chat_thread.new_message:\n            agent.chat_thread.new_message += perception_prompt\n        else:\n            agent.chat_thread.new_message = perception_prompt\n\n        if self.return_prompt:\n            return agent.chat_thread\n        \n        result = await agent.execute()\n        await self.store_memory(\n            agent,\n            content=result,\n            metadata={\n                \"environment_name\": self.environment_name,\n                \"environment_info\": self.environment_info,\n                \"observation\": agent.last_observation,\n                \"last_action\": agent.last_action\n            }\n        )\n        agent.last_perception = result\n        return result\n\nclass ActionStep(CognitiveStep):\n    step_name: str = \"action\"\n    action_space: Optional[\n        Union[\n            Type[BaseModel],\n            StructuredTool,\n            CallableTool,\n            List[Union[Type[BaseModel], StructuredTool, CallableTool]]\n        ]\n    ] = Field(\n        default=None,\n        description=\"Either a single or list of action schema(s)/tool(s)\"\n    )\n\n    async def execute(self, agent: BaseModel) -> Union[str, Dict[str, Any]]:\n        environment = agent.environments[self.environment_name]\n        action_space = environment.action_space if environment else None\n\n        print(f\"ActionSpace type: {type(action_space)}\")\n            # Debug: Print available tools\n        if hasattr(environment, 'action_space') and hasattr(environment.action_space, 'allowed_actions'):\n            print(f\"ActionStep: Found {len(environment.action_space.allowed_actions)} tools in action_space\")\n            for tool in environment.action_space.allowed_actions:\n                if hasattr(tool, 'name'):\n                    print(f\"  - Tool: {tool.name}\")\n        else:\n            print(\"ActionStep: No tools found in action_space\")\n        print(f\"ActionSpace has workflow attr: {hasattr(action_space, 'workflow')}\")\n        if hasattr(action_space, 'workflow'):\n            print(f\"ActionSpace workflow value: {action_space.workflow}\")\n\n        tools = getattr(action_space, \"tools\", [])\n        allowed_actions = getattr(action_space, \"allowed_actions\", [])\n    \n        if agent.chat_thread:\n            print(f\"Chat thread before setup: format={agent.chat_thread.llm_config.response_format}, tools={[t.name for t in agent.chat_thread.tools if t]}\")\n            \n            # Check action space's workflow flag\n            if hasattr(action_space, \"workflow\") and action_space.workflow:\n                print(\"Setting up workflow mode\")\n                agent.chat_thread.tools = tools or allowed_actions\n                print(f\"#tools: {len(allowed_actions)}\")\n                agent.chat_thread.llm_config.response_format = ResponseFormat.workflow\n                agent.chat_thread.workflow_step = 0\n                print(f\"Chat thread after setup: format={agent.chat_thread.llm_config.response_format}, workflow_step={agent.chat_thread.workflow_step}, tools={[t.name for t in agent.chat_thread.tools if t]}\")\n            elif len(allowed_actions) > 1:\n                print(f\"Setting up multiple tools mode with {len(allowed_actions)} tools\")\n                agent.chat_thread.tools = tools or allowed_actions\n                agent.chat_thread.llm_config.response_format = ResponseFormat.auto_tools\n                print(f\"Chat thread after setup: format={agent.chat_thread.llm_config.response_format}, tools={[t.name for t in agent.chat_thread.tools if t]}\")\n            # Single tool mode\n            elif len(tools) == 1:\n                agent.chat_thread.tools = tools\n                agent.chat_thread.forced_output = tools[0]\n            elif allowed_actions and isinstance(allowed_actions[0], CallableTool):\n                agent.chat_thread.forced_output = allowed_actions[0]\n                agent.chat_thread.tools = allowed_actions\n            # String action mode\n            elif not allowed_actions or (len(allowed_actions) == 1 and allowed_actions[0] == StrAction):\n                agent.chat_thread.llm_config.response_format = ResponseFormat.text\n                agent.chat_thread.forced_output = None\n                agent.chat_thread.tools = []\n            # Structured output mode\n            elif allowed_actions and isinstance(allowed_actions[0], type) and issubclass(allowed_actions[0], BaseModel):\n                action_tool = StructuredTool(\n                    json_schema=action_space.get_action_schema(),\n                    name=\"react_reasoning\",\n                    description=\"Generate thought-action-observation cycle\"\n                )\n                agent.chat_thread.forced_output = action_tool\n\n        serialized_actions = []\n        for action in allowed_actions:\n            if isinstance(action, CallableTool):\n                serialized_actions.append(action.name)\n            elif isinstance(action, type):\n                serialized_actions.append(action.__name__)\n            else:\n                serialized_actions.append(str(action))\n\n        variables = MarketAgentPromptVariables(\n            environment_name=self.environment_name,\n            environment_info=self.environment_info,\n            perception=agent.last_perception,\n            action_space={\n                \"tools\": [tool.name for tool in tools] if tools else [],\n                \"allowed_actions\": serialized_actions,\n                \"constraints\": getattr(action_space, \"get_constraints\", lambda: {})()\n            },\n            last_action=agent.last_action,\n            observation=agent.last_observation\n        )\n        \n        action_prompt = agent.prompt_manager.get_action_prompt(variables.model_dump())\n        \n        if agent.chat_thread:\n            agent.chat_thread.new_message = action_prompt\n\n        if self.return_prompt:\n            return agent.chat_thread\n\n        result = await agent.execute()\n\n        if isinstance(result, str) and (not allowed_actions or \n            (len(allowed_actions) == 1 and \n             (allowed_actions[0] == StrAction or \n              (isinstance(allowed_actions[0], type) and allowed_actions[0].__name__ == \"StrAction\")))):\n            result = {\"agent_id\": agent.id, \"action\": result}\n\n        await self.store_memory(\n            agent,\n            content=result,\n            metadata={\n                \"action_space\": variables.action_space,\n                \"perception\": agent.last_perception,\n                \"last_action\": agent.last_action,\n                \"observation\": agent.last_observation,\n                \"environment_name\": self.environment_name,\n                \"environment_info\": self.environment_info,\n                \"tools_used\": [tool.name for tool in tools] if tools else []\n            }\n        )\n\n        agent.last_action = result\n        return result\n    \nclass ReflectionStep(CognitiveStep):\n    step_name: str = \"reflection\"\n\n    async def execute(self, agent: BaseModel) -> Union[str, Dict[str, Any]]:\n        environment = agent.environments[self.environment_name]\n        last_step = (\n            environment.history.steps[-1][1] \n            if environment.history.steps else None\n        )\n\n        if last_step:\n            environment_reward = (\n                last_step.info.get('agent_rewards', {}).get(self.agent_id, 0.0) or 0.0\n            )\n            local_observation = last_step.global_observation.observations.get(self.agent_id)\n            observation = local_observation.observation if local_observation else {}\n        else:\n            observation = {}\n            environment_reward = 0.0\n\n        previous_strategy = \"No previous strategy available\"\n        try:\n            previous_reflection = await agent.short_term_memory.retrieve_recent_memories(\n                cognitive_step='reflection',\n                limit=1\n            )\n            if previous_reflection:\n                last_reflection_obj = previous_reflection[0]\n                previous_strategy = last_reflection_obj.metadata.get(\"strategy_update\", \"\")\n                if isinstance(previous_strategy, list):\n                    previous_strategy = \" \".join(previous_strategy)\n        except Exception as e:\n            previous_strategy = f\"Error retrieving previous strategy: {str(e)}\"\n\n        variables = MarketAgentPromptVariables(\n            environment_name=self.environment_name,\n            environment_info=self.environment_info,\n            observation=observation,\n            last_action=agent.last_action,\n            reward=environment_reward,\n            previous_strategy=previous_strategy,\n            perception=agent.last_perception\n        )\n\n        reflection_prompt = agent.prompt_manager.get_reflection_prompt(\n            variables.model_dump()\n        )\n\n        if agent.chat_thread and self.structured_tool:\n            agent.chat_thread.tools = [reflection_tool]\n            agent.chat_thread.forced_output = reflection_tool\n\n        if agent.chat_thread:\n            agent.chat_thread.new_message = reflection_prompt\n\n        if self.return_prompt:\n            return agent.chat_thread\n\n        result = await agent.execute()\n        \n        if isinstance(result, dict):\n            reward_data = agent.rl_agent.reward_function.compute(\n                environment_reward=environment_reward,\n                reflection_data=result,\n                economic_value=agent.economic_agent.get_portfolio_value()\n                              if agent.economic_agent else None\n            )\n            \n            await agent.rl_agent.store_experience(\n                state=agent.last_perception,\n                action=agent.last_action,\n                reward_data=reward_data,\n                next_state=agent.last_observation,\n                exploration_rate=agent.rl_agent.policy[\"exploration_rate\"],\n                created_at=datetime.now(timezone.utc)\n            )\n            \n            agent.rl_agent.update_policy(reward_data[\"total_reward\"])\n\n            await self.store_memory(\n                agent,\n                content=result.get(\"reflection\", \"\"),\n                metadata={\n                    **reward_data,\n                    \"last_action\": agent.last_action,\n                    \"observation\": agent.last_observation,\n                    \"self_critique\": result.get(\"self_critique\", []),\n                    \"strategy_update\": result.get(\"strategy_update\", \"\"),\n                    \"self_reward\": result.get(\"self_reward\", 0.0)\n                }\n            )\n\n            await agent.long_term_memory.store_episode(\n                task_query=agent.task if agent.task else None,\n                steps=agent.episode_steps,\n                total_reward=reward_data[\"total_reward\"],\n                strategy_update=result.get(\"strategy_update\", \"\"),\n                metadata={\n                    \"environemnt_state\": self.environment_info,\n                    \"environment_name\": self.environment_name\n                }\n            )\n            agent.episode_steps.clear()\n\n        return result"}
{"type": "source_file", "path": "market_agents/inference/parallel_inference.py", "content": "import asyncio\nimport json\nfrom typing import List, Dict, Any, Optional, Literal\nfrom pydantic import BaseModel, Field, ValidationError\nfrom .message_models import LLMPromptContext, LLMOutput\nfrom .clients_models import AnthropicRequest, OpenAIRequest, VLLMRequest\nfrom .oai_parallel import process_api_requests_from_file, OAIApiFromFileConfig\nimport os\nfrom dotenv import load_dotenv\nimport time\nfrom openai.types.chat import ChatCompletionToolParam\nfrom anthropic.types.beta.prompt_caching import PromptCachingBetaToolParam\nfrom anthropic.types.message_create_params import ToolChoiceToolChoiceTool\n\nimport openai\nimport anthropic\n\n\nclass RequestLimits(BaseModel):\n    max_requests_per_minute: int = Field(default=50,description=\"The maximum number of requests per minute for the API\")\n    max_tokens_per_minute: int = Field(default=100000,description=\"The maximum number of tokens per minute for the API\")\n    provider: Literal[\"openai\", \"anthropic\", \"vllm\", \"litellm\"] = Field(default=\"openai\",description=\"The provider of the API\")\n\nclass ParallelAIUtilities:\n    def __init__(self, oai_request_limits: Optional[RequestLimits] = None, \n                 anthropic_request_limits: Optional[RequestLimits] = None, \n                 vllm_request_limits: Optional[RequestLimits] = None,\n                 litellm_request_limits: Optional[RequestLimits] = None,\n                 local_cache: bool = True,\n                 cache_folder: Optional[str] = None):\n        load_dotenv()\n        self.openai_key = os.getenv(\"OPENAI_KEY\")\n        self.anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n        self.vllm_key = os.getenv(\"VLLM_API_KEY\")\n        self.vllm_endpoint = os.getenv(\"VLLM_ENDPOINT\", \"http://localhost:8000/v1/chat/completions\")\n        self.litellm_endpoint = os.getenv(\"LITELLM_ENDPOINT\", \"http://localhost:8000/v1/chat/completions\")\n        self.litellm_key = os.getenv(\"LITELLM_API_KEY\")\n        self.oai_request_limits = oai_request_limits if oai_request_limits else RequestLimits(max_requests_per_minute=500,max_tokens_per_minute=200000,provider=\"openai\")\n        self.anthropic_request_limits = anthropic_request_limits if anthropic_request_limits else RequestLimits(max_requests_per_minute=50,max_tokens_per_minute=40000,provider=\"anthropic\")\n        self.vllm_request_limits = vllm_request_limits if vllm_request_limits else RequestLimits(max_requests_per_minute=500,max_tokens_per_minute=200000,provider=\"vllm\")\n        self.litellm_request_limits = litellm_request_limits if litellm_request_limits else RequestLimits(max_requests_per_minute=500,max_tokens_per_minute=200000,provider=\"litellm\")\n        self.local_cache = local_cache\n        self.cache_folder = self._setup_cache_folder(cache_folder)\n        self.all_requests = []\n\n    def _setup_cache_folder(self, cache_folder: Optional[str]) -> str:\n        if cache_folder:\n            full_path = os.path.abspath(cache_folder)\n        else:\n            # Go up two levels from the current file's directory to reach the project root\n            repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n            full_path = os.path.join(repo_root, 'outputs', 'inference_cache')\n        \n        os.makedirs(full_path, exist_ok=True)\n        return full_path\n\n    def _create_prompt_hashmap(self, prompts: List[LLMPromptContext]) -> Dict[str, LLMPromptContext]:\n        return {p.id: p for p in prompts}\n    \n    def _update_prompt_history(self, prompts: List[LLMPromptContext], llm_outputs: List[LLMOutput]):\n        prompt_hashmap = self._create_prompt_hashmap(prompts)\n        for output in llm_outputs:\n            prompt_hashmap[output.source_id].add_chat_turn_history(output)\n        return list(prompt_hashmap.values())\n\n    async def run_parallel_ai_completion(self, prompts: List[LLMPromptContext], update_history:bool=True) -> List[LLMOutput]:\n        openai_prompts = [p for p in prompts if p.llm_config.client == \"openai\"]\n        anthropic_prompts = [p for p in prompts if p.llm_config.client == \"anthropic\"]\n        vllm_prompts = [p for p in prompts if p.llm_config.client == \"vllm\"] \n        litellm_prompts = [p for p in prompts if p.llm_config.client == \"litellm\"]\n        tasks = []\n        if openai_prompts:\n            tasks.append(self._run_openai_completion(openai_prompts))\n        if anthropic_prompts:\n            tasks.append(self._run_anthropic_completion(anthropic_prompts))\n        if vllm_prompts:\n            tasks.append(self._run_vllm_completion(vllm_prompts))\n        if litellm_prompts:\n            tasks.append(self._run_litellm_completion(litellm_prompts))\n\n        results = await asyncio.gather(*tasks)\n        flattened_results = [item for sublist in results for item in sublist]\n        \n        # Track  requests\n        self.all_requests.extend(flattened_results)\n        \n        if update_history:\n            prompts = self._update_prompt_history(prompts, flattened_results)\n        \n        return flattened_results\n    \n    def get_all_requests(self):\n        requests = self.all_requests\n        self.all_requests = []  \n        return requests\n\n    async def _run_openai_completion(self, prompts: List[LLMPromptContext]) -> List[LLMOutput]:\n        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n        requests_file = os.path.join(self.cache_folder, f'openai_requests_{timestamp}.jsonl')\n        results_file = os.path.join(self.cache_folder, f'openai_results_{timestamp}.jsonl')\n        self._prepare_requests_file(prompts, \"openai\", requests_file)\n        config = self._create_oai_completion_config(prompts[0], requests_file, results_file)\n        if config:\n            try:\n                await process_api_requests_from_file(config)\n                return self._parse_results_file(results_file,client=\"openai\")\n            finally:\n                if not self.local_cache:\n                    self._delete_files(requests_file, results_file)\n        return []\n\n    async def _run_anthropic_completion(self, prompts: List[LLMPromptContext]) -> List[LLMOutput]:\n        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n        requests_file = os.path.join(self.cache_folder, f'anthropic_requests_{timestamp}.jsonl')\n        results_file = os.path.join(self.cache_folder, f'anthropic_results_{timestamp}.jsonl')\n        self._prepare_requests_file(prompts, \"anthropic\", requests_file)\n        config = self._create_anthropic_completion_config(prompts[0], requests_file, results_file)\n        if config:\n            try:\n                await process_api_requests_from_file(config)\n                return self._parse_results_file(results_file,client=\"anthropic\")\n            finally:\n                if not self.local_cache:\n                    self._delete_files(requests_file, results_file)\n        return []\n    \n    async def _run_vllm_completion(self, prompts: List[LLMPromptContext]) -> List[LLMOutput]:\n        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n        requests_file = os.path.join(self.cache_folder, f'vllm_requests_{timestamp}.jsonl')\n        results_file = os.path.join(self.cache_folder, f'vllm_results_{timestamp}.jsonl')\n        self._prepare_requests_file(prompts, \"vllm\", requests_file)\n        config = self._create_vllm_completion_config(prompts[0], requests_file, results_file)\n        if config:\n            try:\n                await process_api_requests_from_file(config)\n                return self._parse_results_file(results_file,client=\"vllm\")\n            finally:\n                if not self.local_cache:\n                    self._delete_files(requests_file, results_file)\n        return []\n    \n    async def _run_litellm_completion(self, prompts: List[LLMPromptContext]) -> List[LLMOutput]:\n        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n        requests_file = os.path.join(self.cache_folder, f'litellm_requests_{timestamp}.jsonl')\n        results_file = os.path.join(self.cache_folder, f'litellm_results_{timestamp}.jsonl')\n        self._prepare_requests_file(prompts, \"litellm\", requests_file)\n        config = self._create_litellm_completion_config(prompts[0], requests_file, results_file)\n        if config:\n            try:\n                await process_api_requests_from_file(config)\n                return self._parse_results_file(results_file,client=\"litellm\")\n            finally:\n                if not self.local_cache:\n                    self._delete_files(requests_file, results_file)\n        return []\n\n    \n\n    def _prepare_requests_file(self, prompts: List[LLMPromptContext], client: str, filename: str):\n        requests = []\n        for prompt in prompts:\n            request = self._convert_prompt_to_request(prompt, client)\n            if request:\n                metadata = {\n                    \"prompt_context_id\": prompt.id,\n                    \"start_time\": time.time(),\n                    \"end_time\": None,\n                    \"total_time\": None\n                }\n                requests.append([metadata, request])\n        \n        with open(filename, 'w') as f:\n            for request in requests:\n                json.dump(request, f)\n                f.write('\\n')\n\n    def _validate_anthropic_request(self, request: Dict[str, Any]) -> bool:\n        try:\n            anthropic_request = AnthropicRequest(**request)\n            return True\n        except Exception as e:\n            raise ValidationError(f\"Error validating Anthropic request: {e} with request: {request}\")\n    \n    def _validate_openai_request(self, request: Dict[str, Any]) -> bool:\n        try:\n            openai_request = OpenAIRequest(**request)\n            return True\n        except Exception as e:\n            raise ValidationError(f\"Error validating OpenAI request: {e} with request: {request}\")\n        \n    def _validate_vllm_request(self, request: Dict[str, Any]) -> bool:\n        try:\n            vllm_request = VLLMRequest(**request)\n            return True\n        except Exception as e:\n            # Instead of raising ValidationError, we'll return False\n            raise ValidationError(f\"Error validating VLLM request: {e} with request: {request}\")\n        \n\n    \n    def _get_openai_request(self, prompt: LLMPromptContext) -> Optional[Dict[str, Any]]:\n        messages = prompt.oai_messages\n        request = {\n            \"model\": prompt.llm_config.model,\n            \"messages\": messages,\n            \"max_tokens\": prompt.llm_config.max_tokens,\n            \"temperature\": prompt.llm_config.temperature,\n        }\n        if prompt.oai_response_format:\n            request[\"response_format\"] = prompt.oai_response_format\n\n        if prompt.llm_config.response_format == \"tool\" and prompt.structured_output:\n            tool = prompt.get_tool()\n            if tool:\n                request[\"tools\"] = [tool]\n                request[\"tool_choice\"] = {\"type\": \"function\", \"function\": {\"name\": prompt.structured_output.schema_name}}\n        else:\n            tools = prompt.get_openai_tools()\n            if tools:\n                request[\"tools\"] = tools\n                request[\"tool_choice\"] = \"auto\"\n\n        if self._validate_openai_request(request):\n            return request\n        else:\n            return None\n    \n    def _get_anthropic_request(self, prompt: LLMPromptContext) -> Optional[Dict[str, Any]]:\n        system_content, messages = prompt.anthropic_messages    \n        request = {\n            \"model\": prompt.llm_config.model,\n            \"max_tokens\": prompt.llm_config.max_tokens,\n            \"temperature\": prompt.llm_config.temperature,\n            \"messages\": messages,\n            \"system\": system_content if system_content else None\n        }\n        if prompt.llm_config.response_format == \"tool\" and prompt.structured_output:\n            tool = prompt.get_tool()\n            if tool:\n                request[\"tools\"] = [tool]\n                request[\"tool_choice\"] = ToolChoiceToolChoiceTool(name=prompt.structured_output.schema_name, type=\"tool\")\n\n        if self._validate_anthropic_request(request):\n            return request\n        else:\n            return None\n        \n    def _get_vllm_request(self, prompt: LLMPromptContext) -> Optional[Dict[str, Any]]:\n        messages = prompt.vllm_messages  # Use vllm_messages instead of oai_messages\n        request = {\n            \"model\": prompt.llm_config.model,\n            \"messages\": messages,\n            \"max_tokens\": prompt.llm_config.max_tokens,\n            \"temperature\": prompt.llm_config.temperature,\n        }\n        if prompt.llm_config.response_format == \"json_object\":\n            raise ValueError(\"VLLM does not support json_object response format otherwise infinite whitespaces are returned\")\n        if prompt.oai_response_format and prompt.oai_response_format:\n            request[\"response_format\"] = prompt.oai_response_format\n        if prompt.llm_config.response_format == \"tool\" and prompt.structured_output:\n            tool = prompt.get_tool()\n            if tool:\n                request[\"tools\"] = [tool]\n                request[\"tool_choice\"] = {\"type\": \"function\", \"function\": {\"name\": prompt.structured_output.schema_name}}\n        else:\n            tools = prompt.get_openai_tools()\n            if tools:\n                request[\"tools\"] = tools\n                request[\"tool_choice\"] = \"auto\"\n        if self._validate_vllm_request(request):\n            return request\n        else:\n            return None\n        \n    def _get_litellm_request(self, prompt: LLMPromptContext) -> Optional[Dict[str, Any]]:\n        if prompt.llm_config.response_format == \"json_object\":\n            raise ValueError(\"VLLM does not support json_object response format otherwise infinite whitespaces are returned\")\n        return self._get_openai_request(prompt)\n        \n    def _convert_prompt_to_request(self, prompt: LLMPromptContext, client: str) -> Optional[Dict[str, Any]]:\n        if client == \"openai\":\n            return self._get_openai_request(prompt)\n        elif client == \"anthropic\":\n            return self._get_anthropic_request(prompt)\n        elif client == \"vllm\":\n            return self._get_vllm_request(prompt)\n        elif client ==\"litellm\":\n            return self._get_litellm_request(prompt)\n        else:\n            raise ValueError(f\"Invalid client: {client}\")\n\n\n    def _create_oai_completion_config(self, prompt: LLMPromptContext, requests_file: str, results_file: str) -> Optional[OAIApiFromFileConfig]:\n        if prompt.llm_config.client == \"openai\" and self.openai_key:\n            return OAIApiFromFileConfig(\n                requests_filepath=requests_file,\n                save_filepath=results_file,\n                request_url=\"https://api.openai.com/v1/chat/completions\",\n                api_key=self.openai_key,\n                max_requests_per_minute=self.oai_request_limits.max_requests_per_minute,\n                max_tokens_per_minute=self.oai_request_limits.max_tokens_per_minute,\n                token_encoding_name=\"cl100k_base\",\n                max_attempts=5,\n                logging_level=20,\n            )\n        return None\n\n    def _create_anthropic_completion_config(self, prompt: LLMPromptContext, requests_file: str, results_file: str) -> Optional[OAIApiFromFileConfig]:\n        if prompt.llm_config.client == \"anthropic\" and self.anthropic_key:\n            return OAIApiFromFileConfig(\n                requests_filepath=requests_file,\n                save_filepath=results_file,\n                request_url=\"https://api.anthropic.com/v1/messages\",\n                api_key=self.anthropic_key,\n                max_requests_per_minute=self.anthropic_request_limits.max_requests_per_minute,\n                max_tokens_per_minute=self.anthropic_request_limits.max_tokens_per_minute,\n                token_encoding_name=\"cl100k_base\",\n                max_attempts=5,\n                logging_level=20,\n            )\n        return None\n    \n    def _create_vllm_completion_config(self, prompt: LLMPromptContext, requests_file: str, results_file: str) -> Optional[OAIApiFromFileConfig]:\n        if prompt.llm_config.client == \"vllm\":\n            return OAIApiFromFileConfig(\n                requests_filepath=requests_file,\n                save_filepath=results_file,\n                request_url=self.vllm_endpoint,\n                api_key=self.vllm_key if self.vllm_key else \"\",\n                max_requests_per_minute=self.vllm_request_limits.max_requests_per_minute,\n                max_tokens_per_minute=self.vllm_request_limits.max_tokens_per_minute,\n                token_encoding_name=\"cl100k_base\",\n                max_attempts=5,\n                logging_level=20,\n            )\n        return None\n    \n    def _create_litellm_completion_config(self, prompt: LLMPromptContext, requests_file: str, results_file: str) -> Optional[OAIApiFromFileConfig]:\n        if prompt.llm_config.client == \"litellm\":\n            return OAIApiFromFileConfig(\n                requests_filepath=requests_file,\n                save_filepath=results_file,\n                request_url=self.litellm_endpoint,\n                api_key=self.litellm_key if self.litellm_key else \"\",\n                max_requests_per_minute=self.litellm_request_limits.max_requests_per_minute,\n                max_tokens_per_minute=self.litellm_request_limits.max_tokens_per_minute,\n                token_encoding_name=\"cl100k_base\",\n                max_attempts=5,\n                logging_level=20,\n            )\n        return None\n    \n\n    def _parse_results_file(self, filepath: str,client: Literal[\"openai\", \"anthropic\", \"vllm\", \"litellm\"]) -> List[LLMOutput]:\n        results = []\n        with open(filepath, 'r') as f:\n            for line in f:\n                try:\n                    result = json.loads(line)\n                    llm_output = self._convert_result_to_llm_output(result,client)\n                    results.append(llm_output)\n                except json.JSONDecodeError:\n                    print(f\"Error decoding JSON: {line}\")\n                    results.append(LLMOutput(raw_result={\"error\": \"JSON decode error\"}, completion_kwargs={}, start_time=time.time(), end_time=time.time(), source_id=\"error\"))\n                except Exception as e:\n                    print(f\"Error processing result: {e}\")\n                    results.append(LLMOutput(raw_result={\"error\": str(e)}, completion_kwargs={}, start_time=time.time(), end_time=time.time(), source_id=\"error\"))\n        return results\n\n    def _convert_result_to_llm_output(self, result: List[Dict[str, Any]],client: Literal[\"openai\", \"anthropic\", \"vllm\", \"litellm\"]) -> LLMOutput:\n        metadata, request_data, response_data = result\n        \n        return LLMOutput(\n            raw_result=response_data,\n            completion_kwargs=request_data,\n            start_time=metadata[\"start_time\"],\n            end_time=metadata[\"end_time\"] or time.time(),\n            source_id=metadata[\"prompt_context_id\"],\n            client=client\n        )\n\n    def _delete_files(self, *files):\n        for file in files:\n            try:\n                os.remove(file)\n            except OSError as e:\n                print(f\"Error deleting file {file}: {e}\")"}
{"type": "source_file", "path": "market_agents/agents/market_agent_prompter.py", "content": "from typing import Dict, Any, Optional, List\nimport importlib.resources as ires\nfrom pydantic import Field\nfrom pathlib import Path\n\nfrom market_agents.agents.base_agent.prompter import (\n    BasePromptVariables,\n    BasePromptTemplate,\n    PromptManager\n)\n\nclass MarketAgentPromptVariables(BasePromptVariables):\n    \"\"\"Variables specific to market agent prompts.\"\"\"\n    environment_name: str = Field(\n        ...,\n        description=\"Name of the market environment\")\n    environment_info: Any = Field(\n        ...,\n        description=\"Information about the market environment\")\n    short_term_memory: Optional[List[Dict[str, Any]]] = Field(\n        default=None, \n        description=\"Recent observations and actions\"\n    )\n    long_term_memory: Optional[List[Dict[str, Any]]] = Field(\n        default=None,\n        description=\"Historical market data and patterns\"\n    )\n    documents: Optional[List[Dict[str, Any]]] = Field(\n        default=None,\n        description=\"Reference documents and market analysis\"\n    )\n    perception: Optional[Any] = Field(\n        default=None,\n        description=\"Current market perception\"\n    )\n    observation: Optional[Any] = Field(\n        default=None,\n        description=\"Latest market observation\"\n    )\n    action_space: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Available market actions\"\n    )\n    last_action: Optional[Any] = Field(\n        default=None,\n        description=\"Previously taken action\"\n    )\n    reward: Optional[float] = Field(\n        default=None,\n        description=\"Reward from last action\"\n    )\n    previous_strategy: Optional[str] = Field(\n        default=None,\n        description=\"Previously used trading strategy\"\n    )\n\n    class Config:\n        arbitrary_types_allowed = True\n\nclass MarketAgentPromptTemplate(BasePromptTemplate):\n    \"\"\"Template loader for market agent prompts.\"\"\"\n    template_path: Path = Field(\n        default_factory=lambda: Path(ires.files(\"market_agents.agents.configs.prompts\") / \"market_agent_prompt.yaml\"),\n        description=\"Path to market agent prompt templates\"\n    )\n\nclass MarketAgentPromptManager(PromptManager):\n    \"\"\"Manages prompts for market agents with specialized template handling.\"\"\"\n    \n    def __init__(self, template_paths: Optional[List[Path]] = None):\n        default_paths = [\n            Path(ires.files(\"market_agents.agents.configs.prompts\") / \"default_prompt.yaml\"),\n            Path(ires.files(\"market_agents.agents.configs.prompts\") / \"market_agent_prompt.yaml\")\n        ]\n        super().__init__(template_paths=template_paths if template_paths else default_paths)\n\n    def get_perception_prompt(self, variables: Dict[str, Any]) -> str:\n        \"\"\"Generate perception analysis prompt.\"\"\"\n        vars_model = MarketAgentPromptVariables(**variables)\n        return self.template.format_prompt('perception', vars_model)\n\n    def get_action_prompt(self, variables: Dict[str, Any]) -> str:\n        \"\"\"Generate action selection prompt.\"\"\"\n        vars_model = MarketAgentPromptVariables(**variables)\n        return self.template.format_prompt('action', vars_model)\n\n    def get_reflection_prompt(self, variables: Dict[str, Any]) -> str:\n        \"\"\"Generate strategy reflection prompt.\"\"\"\n        vars_model = MarketAgentPromptVariables(**variables)\n        return self.template.format_prompt('reflection', vars_model)"}
{"type": "source_file", "path": "market_agents/agents/personas/weighted_personas/utils/processBCS.py", "content": "import csv\nfrom fuzzywuzzy import fuzz\nimport pandas as pd\n\ndef extract_occupation_details(employment_csv_path, education_csv_path, threshold=80):\n    occupations = []\n    \n    # Read education data\n    education_df = pd.read_csv(education_csv_path)\n    education_df.set_index('2023 National Employment Matrix title', inplace=True)\n    education_df = education_df.drop('2023 National Employment Matrix code', axis=1)\n\n    with open(employment_csv_path, 'r', newline='') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            # Fuzzy match OCC_TITLE with education data\n            best_match = None\n            best_score = 0\n            for title in education_df.index:\n                score = fuzz.ratio(row['OCC_TITLE'], title)\n                if score > best_score:\n                    best_score = score\n                    best_match = title\n\n            if best_score >= threshold:\n                education_data = education_df.loc[best_match].to_dict()\n                occupation = {\n                    'name': row['OCC_TITLE'],\n                    'annual_income': row['A_MEDIAN'],\n                    'hourly_wage': row['H_MEDIAN'],\n                    'employment': row['TOT_EMP'],\n                    'code': row['OCC_CODE'],\n                    'percentile_10': row['A_PCT10'],\n                    'percentile_25': row['A_PCT25'],\n                    'percentile_75': row['A_PCT75'],\n                    'percentile_90': row['A_PCT90'],\n                    'education': education_data,\n                    'matched_title': best_match,\n                    'match_score': best_score\n                }\n                occupations.append(occupation)\n\n    return occupations\n\ndef deduplicate_occupations(occupations, threshold=90):\n    deduplicated = []\n    for occupation in occupations:\n        if not any(fuzz.ratio(occupation['name'], existing['name']) >= threshold for existing in deduplicated):\n            deduplicated.append(occupation)\n    return deduplicated\n\ndef format_occupation_details(occupations):\n    formatted_output = \"\"\n    for occupation in occupations:\n        formatted_output += f\"## {occupation['name']}\\n\\n\"\n        formatted_output += f\"- Annual median income: ${occupation['annual_income']}\\n\"\n        formatted_output += f\"- Hourly median wage: ${occupation['hourly_wage']}\\n\"\n        formatted_output += f\"- Number employed: {occupation['employment']}\\n\"\n        #formatted_output += f\"- Occupation code: {occupation['code']}\\n\"\n        #formatted_output += f\"- 10th percentile wage: ${occupation['percentile_10']}\\n\"\n        #formatted_output += f\"- 25th percentile wage: ${occupation['percentile_25']}\\n\"\n        #formatted_output += f\"- 75th percentile wage: ${occupation['percentile_75']}\\n\"\n        #formatted_output += f\"- 90th percentile wage: ${occupation['percentile_90']}\\n\"\n        #formatted_output += f\"- Matched education title: {occupation['matched_title']}\\n\"\n        #formatted_output += f\"- Match score: {occupation['match_score']}\\n\"\n        formatted_output += \"\\n\"\n        formatted_output += \"- Education levels:\\n\"\n        for level, percentage in occupation['education'].items():\n            formatted_output += f\"  - {level}: {percentage}%\\n\"\n        \n        formatted_output += \"\\n\"\n    \n    return formatted_output\n\n# Use local CSV files\nemployment_csv_path = r'national_M2023_dl.csv'\neducation_csv_path = r'education_2023.csv'\n\noccupations = extract_occupation_details(employment_csv_path, education_csv_path)\ndeduplicated_occupations = deduplicate_occupations(occupations)\nformatted_output = format_occupation_details(deduplicated_occupations)\n\n# Save as a markdown file\nwith open('occupations.md', 'w') as file:\n    file.write(formatted_output)\n\nprint(\"Occupations data has been saved to occupations.md\")"}
{"type": "source_file", "path": "market_agents/inference/oai_parallel.py", "content": "\"\"\"\nThis script is adapted from work found at:\nhttps://github.com/tiny-rawr/parallel_process_gpt,\nwhich itself is based on examples provided by OpenAI at:\nhttps://github.com/openai/openai-cookbook/blob/main/examples/api_request_parallel_processor.py\n\nMIT License\n\nCopyright (c) 2023 OpenAI\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\"\"\"\n\n\nimport aiohttp  # for making API calls concurrently\nimport argparse  # for running script from command line\nimport asyncio  # for running API calls concurrently\nimport json  # for saving results to a jsonl file\nimport logging  # for logging rate limit warnings and other messages\nimport os  # for reading API key\nimport re  # for matching endpoint from request URL\nimport tiktoken  # for counting tokens\nimport time  # for sleeping after rate limit is hit\nfrom dataclasses import (\n    dataclass,\n    field,\n)  # for storing API inputs, outputs, and metadata\nfrom typing import List  # for type hints in functions\nfrom pydantic import BaseModel, Field\n\nclass OAIApiFromFileConfig(BaseModel):\n requests_filepath: str\n save_filepath: str\n api_key: str\n request_url:str =  Field(\"https://api.openai.com/v1/embeddings\",description=\"The url to use for generating embeddings\")\n max_requests_per_minute: float = Field(100,description=\"The maximum number of requests per minute\")\n max_tokens_per_minute: float = Field(1_000_000,description=\"The maximum number of tokens per minute\")\n max_attempts:int = Field(5,description=\"The maximum number of attempts to make for each request\")\n logging_level:int = Field(20,description=\"The logging level to use for the request\")\n token_encoding_name: str = Field(\"cl100k_base\",description=\"The token encoding scheme to use for calculating request sizes\")\n\nasync def process_api_requests_from_file(\n        api_cfg: OAIApiFromFileConfig\n):\n    \"\"\"\n    Asynchronously processes API requests from a given file, executing them in parallel\n    while adhering to specified rate limits for requests and tokens per minute.\n    \n    This function reads a file containing JSONL-formatted API requests, sends these requests\n    concurrently to the specified API endpoint, and handles retries for failed attempts,\n    all the while ensuring that the execution does not exceed the given rate limits.\n    \n    Parameters:\n    - requests_filepath: Path to the file containing the JSONL-formatted API requests.\n    - save_filepath: Path to the file where results or logs should be saved.\n    - request_url: The API endpoint URL to which the requests will be sent.\n    - api_key: The API key for authenticating requests to the endpoint.\n    - max_requests_per_minute: The maximum number of requests allowed per minute.\n    - max_tokens_per_minute: The maximum number of tokens (for rate-limited APIs) that can be used per minute.\n    - token_encoding_name: Name of the token encoding scheme used for calculating request sizes.\n    - max_attempts: The maximum number of attempts for each request in case of failures.\n    - logging_level: The logging level to use for reporting the process's progress and issues.\n    \n    The function initializes necessary tracking structures, sets up asynchronous HTTP sessions,\n    and manages request retries and rate limiting. It logs the progress and any issues encountered\n    during the process to facilitate monitoring and debugging.\n    \"\"\"\n    #extract variables from config\n    requests_filepath = api_cfg.requests_filepath\n    save_filepath = api_cfg.save_filepath\n    request_url = api_cfg.request_url\n    api_key = api_cfg.api_key\n    max_requests_per_minute = api_cfg.max_requests_per_minute\n    max_tokens_per_minute = api_cfg.max_tokens_per_minute\n    token_encoding_name = api_cfg.token_encoding_name\n    max_attempts = api_cfg.max_attempts\n    logging_level = api_cfg.logging_level\n    # constants\n    seconds_to_pause_after_rate_limit_error = 15\n    seconds_to_sleep_each_loop = (\n        0.001  # 1 ms limits max throughput to 1,000 requests per second\n    )\n\n    # initialize logging\n    logging.basicConfig(level=logging_level)\n    logging.debug(f\"Logging initialized at level {logging_level}\")\n\n    # infer API endpoint and construct request header\n    api_endpoint = api_endpoint_from_url(request_url)\n    request_header = {\"Authorization\": f\"Bearer {api_key}\"}\n    # use api-key header for Azure deployments\n    if '/deployments' in request_url:\n        request_header = {\"api-key\": f\"{api_key}\"}\n    # Add Anthropic-specific headers\n    if 'anthropic.com' in request_url:\n        request_header = {\n            \"x-api-key\": api_key,\n            \"anthropic-version\": \"2023-06-01\",\n            \"content-type\": \"application/json\",\n            \"anthropic-beta\": \"prompt-caching-2024-07-31\"\n        }\n\n    # initialize trackers\n    queue_of_requests_to_retry = asyncio.Queue()\n    task_id_generator = (\n        task_id_generator_function()\n    )  # generates integer IDs of 1, 2, 3, ...\n    status_tracker = (\n        StatusTracker()\n    )  # single instance to track a collection of variables\n    next_request = None  # variable to hold the next request to call\n\n    # initialize available capacity counts\n    available_request_capacity = max_requests_per_minute\n    available_token_capacity = max_tokens_per_minute\n    last_update_time = time.time()\n\n    # initialize flags\n    file_not_finished = True  # after file is empty, we'll skip reading it\n    logging.debug(f\"Initialization complete.\")\n\n    # initialize file reading\n    with open(requests_filepath) as file:\n        # `requests` will provide requests one at a time\n        requests = file.__iter__()\n        logging.debug(f\"File opened. Entering main loop\")\n        async with aiohttp.ClientSession() as session:  # Initialize ClientSession here\n            while True:\n                # get next request (if one is not already waiting for capacity)\n                if next_request is None:\n                    if not queue_of_requests_to_retry.empty():\n                        next_request = queue_of_requests_to_retry.get_nowait()\n                        logging.debug(\n                            f\"Retrying request {next_request.task_id}: {next_request}\"\n                        )\n                    elif file_not_finished:\n                        try:\n                            # get new request\n                            request_json = json.loads(next(requests))\n                            metadata, actual_request = request_json  # Unpack the list\n                            next_request = APIRequest(\n                                task_id=next(task_id_generator),\n                                request_json=actual_request,\n                                token_consumption=num_tokens_consumed_from_request(\n                                    actual_request, api_endpoint, token_encoding_name\n                                ),\n                                attempts_left=max_attempts,\n                                metadata=metadata,\n                            )\n                            status_tracker.num_tasks_started += 1\n                            status_tracker.num_tasks_in_progress += 1\n                            logging.debug(\n                                f\"Reading request {next_request.task_id}: {next_request}\"\n                            )\n                        except StopIteration:\n                            # if file runs out, set flag to stop reading it\n                            logging.debug(\"Read file exhausted\")\n                            file_not_finished = False\n\n                # update available capacity\n                current_time = time.time()\n                seconds_since_update = current_time - last_update_time\n                available_request_capacity = min(\n                    available_request_capacity\n                    + max_requests_per_minute * seconds_since_update / 60.0,\n                    max_requests_per_minute,\n                )\n                available_token_capacity = min(\n                    available_token_capacity\n                    + max_tokens_per_minute * seconds_since_update / 60.0,\n                    max_tokens_per_minute,\n                )\n                last_update_time = current_time\n\n                # if enough capacity available, call API\n                if next_request:\n                    next_request_tokens = next_request.token_consumption\n                    if (\n                        available_request_capacity >= 1\n                        and available_token_capacity >= next_request_tokens\n                    ):\n                        # update counters\n                        available_request_capacity -= 1\n                        available_token_capacity -= next_request_tokens\n                        next_request.attempts_left -= 1\n\n                        # call API\n                        asyncio.create_task(\n                            next_request.call_api(\n                                session=session,\n                                request_url=request_url,\n                                request_header=request_header,\n                                retry_queue=queue_of_requests_to_retry,\n                                save_filepath=save_filepath,\n                                status_tracker=status_tracker,\n                            )\n                        )\n                        next_request = None  # reset next_request to empty\n\n                # if all tasks are finished, break\n                if status_tracker.num_tasks_in_progress == 0:\n                    break\n\n                # main loop sleeps briefly so concurrent tasks can run\n                await asyncio.sleep(seconds_to_sleep_each_loop)\n\n                # if a rate limit error was hit recently, pause to cool down\n                seconds_since_rate_limit_error = (\n                    time.time() - status_tracker.time_of_last_rate_limit_error\n                )\n                if (\n                    seconds_since_rate_limit_error\n                    < seconds_to_pause_after_rate_limit_error\n                ):\n                    remaining_seconds_to_pause = (\n                        seconds_to_pause_after_rate_limit_error\n                        - seconds_since_rate_limit_error\n                    )\n                    await asyncio.sleep(remaining_seconds_to_pause)\n                    # ^e.g., if pause is 15 seconds and final limit was hit 5 seconds ago\n                    logging.warn(\n                        f\"Pausing to cool down until {time.ctime(status_tracker.time_of_last_rate_limit_error + seconds_to_pause_after_rate_limit_error)}\"\n                    )\n\n        # after finishing, log final status\n        logging.info(\n            f\"\"\"Parallel processing complete. Results saved to {save_filepath}\"\"\"\n        )\n        if status_tracker.num_tasks_failed > 0:\n            logging.warning(\n                f\"{status_tracker.num_tasks_failed} / {status_tracker.num_tasks_started} requests failed. Errors logged to {save_filepath}.\"\n            )\n        if status_tracker.num_rate_limit_errors > 0:\n            logging.warning(\n                f\"{status_tracker.num_rate_limit_errors} rate limit errors received. Consider running at a lower rate.\"\n            )\n\n\n# dataclasses\n\n\n@dataclass\nclass StatusTracker:\n    \"\"\"\n    A data class that tracks the progress and status of API request processing.\n    \n    This class is designed to hold counters for various outcomes of API requests\n    (such as successes, failures, and specific types of errors) and other relevant\n    metadata to manage and monitor the execution flow of the script.\n    \n    Attributes:\n    - num_tasks_started: The total number of tasks that have been started.\n    - num_tasks_in_progress: The current number of tasks that are in progress.\n      The script continues running as long as this number is greater than 0.\n    - num_tasks_succeeded: The total number of tasks that have completed successfully.\n    - num_tasks_failed: The total number of tasks that have failed.\n    - num_rate_limit_errors: The count of errors received due to hitting the API's rate limits.\n    - num_api_errors: The count of API-related errors excluding rate limit errors.\n    - num_other_errors: The count of errors that are neither API errors nor rate limit errors.\n    - time_of_last_rate_limit_error: A timestamp (as an integer) of the last time a rate limit error was encountered,\n      used to implement a cooling-off period before making subsequent requests.\n    \n    The class is initialized with all counters set to 0, and the `time_of_last_rate_limit_error`\n    set to 0 indicating no rate limit errors have occurred yet.\n    \"\"\"\n\n    num_tasks_started: int = 0\n    num_tasks_in_progress: int = 0  # script ends when this reaches 0\n    num_tasks_succeeded: int = 0\n    num_tasks_failed: int = 0\n    num_rate_limit_errors: int = 0\n    num_api_errors: int = 0  # excluding rate limit errors, counted above\n    num_other_errors: int = 0\n    time_of_last_rate_limit_error: float = 0  # used to cool off after hitting rate limits\n\n\n@dataclass\nclass APIRequest:\n    \"\"\"\n    Represents an individual API request with associated metadata and the capability to asynchronously call an API.\n    \n    Attributes:\n    - task_id (int): A unique identifier for the task.\n    - request_json (dict): The JSON payload to be sent with the request.\n    - token_consumption (int): Estimated number of tokens consumed by the request, used for rate limiting.\n    - attempts_left (int): The number of retries left if the request fails.\n    - metadata (dict): Additional metadata associated with the request.\n    - result (list): A list to store the results or errors from the API call.\n    \n    This class encapsulates the data and actions related to making an API request, including\n    retry logic and error handling.\n    \"\"\"\n\n    task_id: int\n    request_json: dict\n    token_consumption: int\n    attempts_left: int\n    metadata: dict\n    result: list = field(default_factory=list)\n\n    async def call_api(\n        self,\n        session: aiohttp.ClientSession,\n        request_url: str,\n        request_header: dict,\n        retry_queue: asyncio.Queue,\n        save_filepath: str,\n        status_tracker: StatusTracker,\n    ):\n        \"\"\"\n        Asynchronously sends the API request using aiohttp, handles errors, and manages retries.\n        \n        Parameters:\n        - session (aiohttp.ClientSession): The session object used for HTTP requests.\n        - request_url (str): The URL to which the request is sent.\n        - request_header (dict): Headers for the request, including authorization.\n        - retry_queue (asyncio.Queue): A queue for requests that need to be retried.\n        - save_filepath (str): The file path where results or errors should be logged.\n        - status_tracker (StatusTracker): A shared object for tracking the status of all API requests.\n        \n        This method attempts to post the request to the given URL. If the request encounters an error,\n        it determines whether to retry based on the remaining attempts and updates the status tracker\n        accordingly. Successful requests or final failures are logged to the specified file.\n        \"\"\"\n        logging.info(f\"Starting request #{self.task_id}\")\n        error = None\n        try:\n            async with session.post(\n                url=request_url, headers=request_header, json=self.request_json\n            ) as response:\n                response = await response.json()\n            if \"error\" in response:\n                logging.warning(\n                    f\"Request {self.task_id} failed with error {response['error']}\"\n                )\n                status_tracker.num_api_errors += 1\n                error = response\n                if \"Rate limit\" in response[\"error\"].get(\"message\", \"\"):\n                    status_tracker.time_of_last_rate_limit_error = time.time()\n                    status_tracker.num_rate_limit_errors += 1\n                    status_tracker.num_api_errors -= (\n                        1  # rate limit errors are counted separately\n                    )\n\n        except (\n            Exception\n        ) as e:  # catching naked exceptions is bad practice, but in this case we'll log & save them\n            logging.warning(f\"Request {self.task_id} failed with Exception {e}\")\n            status_tracker.num_other_errors += 1\n            error = e\n\n        if error:\n            self.result.append(error)\n            if self.attempts_left:\n                retry_queue.put_nowait(self)\n            else:\n                logging.error(\n                    f\"Request {self.request_json} failed after all attempts. Saving errors: {self.result}\"\n                )\n                self.metadata[\"end_time\"] = time.time()\n                self.metadata[\"total_time\"] = self.metadata[\"end_time\"] - self.metadata[\"start_time\"]\n                data = [self.metadata, self.request_json, {\"error\": str(error)}]\n                append_to_jsonl(data, save_filepath)\n                status_tracker.num_tasks_in_progress -= 1\n                status_tracker.num_tasks_failed += 1\n        else:\n            self.metadata[\"end_time\"] = time.time()\n            self.metadata[\"total_time\"] = self.metadata[\"end_time\"] - self.metadata[\"start_time\"]\n            data = [self.metadata, self.request_json, response]\n            append_to_jsonl(data, save_filepath)\n            status_tracker.num_tasks_in_progress -= 1\n            status_tracker.num_tasks_succeeded += 1\n            logging.debug(f\"Request {self.task_id} saved to {save_filepath}\")\n\n\n# functions\n\ndef api_endpoint_from_url(request_url: str) -> str:\n    \"\"\"\n    Extracts the API endpoint from a given request URL.\n\n    This function applies a regular expression search to find the API endpoint pattern within the provided URL.\n    It supports extracting endpoints from standard OpenAI API URLs, custom Azure OpenAI deployment URLs,\n    vLLM endpoints, OpenRouter endpoints, and other API endpoints with custom ports.\n\n    Parameters:\n    - request_url (str): The full URL of the API request.\n\n    Returns:\n    - str: The extracted endpoint from the URL. If the URL does not match expected patterns,\n      this function may raise an IndexError for accessing a non-existing match group.\n\n    Example:\n    - Input: \"https://api.openai.com/v1/completions\"\n      Output: \"completions\"\n    - Input: \"https://custom.azurewebsites.net/openai/deployments/my-model/completions\"\n      Output: \"completions\"\n    - Input: \"http://localhost:8000/v1/completions\"\n      Output: \"completions\"\n    - Input: \"http://00.000.000.00:8000/v1/completions\"\n      Output: \"completions\"\n    - Input: \"http://00.000.000.00:4000/chat/completions\"\n      Output: \"chat/completions\"\n    - Input: \"https://openrouter.ai/api/v1/chat/completions\"\n      Output: \"chat/completions\"\n    \"\"\"\n    match = re.search(\"^https://[^/]+/v\\\\d+/(.+)$\", request_url)\n    if match is None:\n        # for OpenRouter and similar APIs with /api/v1 path\n        match = re.search(\"^https://[^/]+/api/v\\\\d+/(.+)$\", request_url)\n        if match is None:\n            # for Azure OpenAI deployment urls\n            match = re.search(r\"^https://[^/]+/openai/deployments/[^/]+/(.+?)(\\?|$)\", request_url)\n            if match is None:\n                # for vLLM endpoints with localhost or IP address and v1 path\n                match = re.search(r\"^http://(?:localhost|\\d+\\.\\d+\\.\\d+\\.\\d+):\\d+/v\\d+/(.+)$\", request_url)\n                if match is None:\n                    # for endpoints with direct chat/completions path\n                    match = re.search(r\"^http://(?:localhost|\\d+\\.\\d+\\.\\d+\\.\\d+):\\d+/(.+)$\", request_url)\n                    if match is None:\n                        raise ValueError(f\"Invalid URL: {request_url}\")\n    return match[1]\n\n\ndef append_to_jsonl(data, filename: str) -> None:\n    \"\"\"\n    Appends a given JSON payload to the end of a JSON Lines (.jsonl) file.\n\n    Parameters:\n    - data: The JSON-serializable Python object (e.g., dict, list) to be appended.\n    - filename (str): The path to the .jsonl file to which the data will be appended.\n\n    The function converts `data` into a JSON string and appends it to the specified file,\n    ensuring that each entry is on a new line, consistent with the JSON Lines format.\n\n    Note:\n    - If the specified file does not exist, it will be created.\n    - This function does not return any value.\n    \"\"\"\n    json_string = json.dumps(data)\n    with open(filename, \"a\") as f:\n        f.write(json_string + \"\\n\")\n\n\ndef num_tokens_consumed_from_request(\n    request_json: dict,\n    api_endpoint: str,\n    token_encoding_name: str,\n):\n    \"\"\"Count the number of tokens in the request. Supports completion, embedding, and Anthropic message requests.\"\"\"\n    encoding = tiktoken.get_encoding(token_encoding_name)\n    \n    if api_endpoint.endswith(\"completions\"):\n        max_tokens = request_json.get(\"max_tokens\", 15)\n        n = request_json.get(\"n\", 1)\n        completion_tokens = n * max_tokens\n\n        # chat completions\n        if api_endpoint.startswith(\"chat/\"):\n            num_tokens = 0\n            for message in request_json[\"messages\"]:\n                num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n                for key, value in message.items():\n                    num_tokens += len(encoding.encode(value))\n                    if key == \"name\":  # if there's a name, the role is omitted\n                        num_tokens -= 1  # role is always required and always 1 token\n            num_tokens += 2  # every reply is primed with <im_start>assistant\n            return num_tokens + completion_tokens\n        # normal completions\n        else:\n            prompt = request_json[\"prompt\"]\n            if isinstance(prompt, str):  # single prompt\n                prompt_tokens = len(encoding.encode(prompt))\n                num_tokens = prompt_tokens + completion_tokens\n                return num_tokens\n            elif isinstance(prompt, list):  # multiple prompts\n                prompt_tokens = sum([len(encoding.encode(p)) for p in prompt])\n                num_tokens = prompt_tokens + completion_tokens * len(prompt)\n                return num_tokens\n            else:\n                raise TypeError(\n                    'Expecting either string or list of strings for \"prompt\" field in completion request'\n                )\n    elif api_endpoint == \"embeddings\":\n        input = request_json[\"input\"]\n        if isinstance(input, str):  # single input\n            num_tokens = len(encoding.encode(input))\n            return num_tokens\n        elif isinstance(input, list):  # multiple inputs\n            num_tokens = sum([len(encoding.encode(i)) for i in input])\n            return num_tokens\n        else:\n            raise TypeError(\n                'Expecting either string or list of strings for \"inputs\" field in embedding request'\n            )\n    elif api_endpoint == \"messages\":  # Anthropic API\n        messages = request_json.get(\"messages\", [])\n        num_tokens = 0\n        for message in messages:\n            content = message.get(\"content\", \"\")\n            if isinstance(content, str):\n                num_tokens += len(encoding.encode(content))\n            elif isinstance(content, list):\n                for item in content:\n                    if isinstance(item, dict) and \"text\" in item:\n                        num_tokens += len(encoding.encode(item[\"text\"]))\n        \n        max_tokens = request_json.get(\"max_tokens\", 0)\n        num_tokens += max_tokens  # Add the max_tokens to account for the response\n        return num_tokens\n    \n    else:\n        raise NotImplementedError(\n            f'API endpoint \"{api_endpoint}\" not implemented in this script'\n        )\n\n\ndef task_id_generator_function():\n    \"\"\"\n    Generates a sequence of integer task IDs, starting from 0 and incrementing by 1 each time.\n\n    Yields:\n    - An integer representing the next task ID in the sequence.\n\n    This generator function is useful for assigning unique identifiers to tasks or requests\n    in a sequence, ensuring each has a distinct ID for tracking and reference purposes.\n    \"\"\"\n    task_id = 0\n    while True:\n        yield task_id\n        task_id += 1\n\n\n# run script\n\n\nif __name__ == \"__main__\":\n    # parse command line arguments\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--requests_filepath\")\n    parser.add_argument(\"--save_filepath\", default=None)\n    parser.add_argument(\"--request_url\", default=\"https://api.openai.com/v1/embeddings\")\n    parser.add_argument(\"--api_key\", default=os.getenv(\"OPENAI_API_KEY\"))\n    parser.add_argument(\"--max_requests_per_minute\", type=int, default=3_000 * 0.5)\n    parser.add_argument(\"--max_tokens_per_minute\", type=int, default=250_000 * 0.5)\n    parser.add_argument(\"--token_encoding_name\", default=\"cl100k_base\")\n    parser.add_argument(\"--max_attempts\", type=int, default=5)\n    parser.add_argument(\"--logging_level\", default=logging.INFO)\n    args = parser.parse_args()\n\n    if args.save_filepath is None:\n        args.save_filepath = args.requests_filepath.replace(\".jsonl\", \"_results.jsonl\")\n\n    # run script\n    config = OAIApiFromFileConfig(\n        requests_filepath=args.requests_filepath,\n        save_filepath=args.save_filepath,\n        request_url=args.request_url,\n        api_key=args.api_key,\n        max_requests_per_minute=float(args.max_requests_per_minute),\n        max_tokens_per_minute=float(args.max_tokens_per_minute),\n        token_encoding_name=args.token_encoding_name,\n        max_attempts=int(args.max_attempts),\n        logging_level=int(args.logging_level),\n    )\n    asyncio.run(process_api_requests_from_file(api_cfg=config))"}
{"type": "source_file", "path": "market_agents/agents/personas/persona.py", "content": "from pydantic import BaseModel\nfrom typing import List, Dict, Union\nimport yaml\nimport random\nfrom pathlib import Path\nimport names\n\nclass Persona(BaseModel):\n    name: str\n    role: str\n    persona: str\n    objectives: List[str]\n    trader_type: List[str]\n    communication_style: str\n    routines: List[str]\n    skills: List[str]\n\ndef generate_persona() -> Persona:\n    # Gender and Name\n    gender = random.choice([\"Male\", \"Female\", \"Non-binary\"])\n    name = names.get_full_name(gender=gender.lower())\n\n    # Pronouns with verb forms\n    if gender == \"Male\":\n        pronouns = {\n            \"subject\": \"he\",\n            \"object\": \"him\",\n            \"possessive\": \"his\",\n            \"be\": \"is\",\n            \"has\": \"has\"\n        }\n    elif gender == \"Female\":\n        pronouns = {\n            \"subject\": \"she\",\n            \"object\": \"her\",\n            \"possessive\": \"her\",\n            \"be\": \"is\",\n            \"has\": \"has\"\n        }\n    else:  # Non-binary\n        pronouns = {\n            \"subject\": \"they\",\n            \"object\": \"them\",\n            \"possessive\": \"their\",\n            \"be\": \"are\",\n            \"has\": \"have\"\n        }\n\n    # Capitalize pronouns for sentence beginnings\n    pronouns_cap = {\n        k: v.capitalize() if k not in [\"be\", \"has\"] else v\n        for k, v in pronouns.items()\n    }\n\n    # Role\n    role = random.choice([\"Researcher\", \"Speculator\", \"Trader\", \"Investor\", \"Analyst\", \"Entreprenuer\"])\n\n    # Occupation Mapping with Routines and Skills\n    occupation_data = {\n        'Doctor': {\n            'education_levels': [\"Master's\", \"PhD\"],\n            'income_brackets': [\"High\"],\n            'routines': ['Review patient charts', 'Perform surgeries', 'Attend medical conferences', 'Consult with patients', 'Supervise medical staff'],\n            'skills': ['Medical diagnosis', 'Surgery', 'Patient care', 'Medical research', 'Team management']\n        },\n        'Engineer': {\n            'education_levels': [\"Bachelor's\", \"Master's\", \"PhD\"],\n            'income_brackets': [\"Medium\", \"High\"],\n            'routines': ['Design systems', 'Write code', 'Attend team meetings', 'Debug software', 'Review code'],\n            'skills': ['Programming', 'Systems design', 'Problem-solving', 'Software development', 'Code optimization']\n        },\n        'Teacher': {\n            'education_levels': [\"Bachelor's\", \"Master's\"],\n            'income_brackets': [\"Low\", \"Medium\"],\n            'routines': ['Prepare lesson plans', 'Teach classes', 'Grade assignments', 'Meet with parents', 'Attend workshops'],\n            'skills': ['Instruction', 'Curriculum development', 'Classroom management', 'Communication', 'Assessment']\n        },\n        'Artist': {\n            'education_levels': [\"High School\", \"Bachelor's\"],\n            'income_brackets': [\"Low\", \"Medium\"],\n            'routines': ['Create artworks', 'Attend exhibitions', 'Market artwork', 'Collaborate with other artists', 'Research new techniques'],\n            'skills': ['Creativity', 'Artistic skills', 'Marketing', 'Networking', 'Critical thinking']\n        },\n        'Mechanic': {\n            'education_levels': [\"High School\", \"Associate's\"],\n            'income_brackets': [\"Low\", \"Medium\"],\n            'routines': ['Inspect vehicles', 'Repair engines', 'Order parts', 'Maintain equipment', 'Provide customer service'],\n            'skills': ['Mechanical knowledge', 'Problem-solving', 'Technical skills', 'Customer service', 'Attention to detail']\n        },\n        'Scientist': {\n            'education_levels': [\"Master's\", \"PhD\"],\n            'income_brackets': [\"Medium\", \"High\"],\n            'routines': ['Conduct experiments', 'Analyze data', 'Publish papers', 'Attend conferences', 'Collaborate with peers'],\n            'skills': ['Research', 'Data analysis', 'Scientific writing', 'Critical thinking', 'Collaboration']\n        },\n        'Nurse': {\n            'education_levels': [\"Associate's\", \"Bachelor's\"],\n            'income_brackets': [\"Low\", \"Medium\"],\n            'routines': ['Monitor patient health', 'Administer medications', 'Update records', 'Assist doctors', 'Educate patients'],\n            'skills': ['Patient care', 'Medical knowledge', 'Compassion', 'Attention to detail', 'Communication']\n        },\n        'Lawyer': {\n            'education_levels': [\"Master's\", \"PhD\"],\n            'income_brackets': [\"High\"],\n            'routines': ['Meet clients', 'Prepare legal documents', 'Represent clients in court', 'Research case law', 'Negotiate settlements'],\n            'skills': ['Legal knowledge', 'Negotiation', 'Analytical thinking', 'Public speaking', 'Writing']\n        },\n        'Salesperson': {\n            'education_levels': [\"High School\", \"Associate's\", \"Bachelor's\"],\n            'income_brackets': [\"Low\", \"Medium\"],\n            'routines': ['Contact potential clients', 'Present products', 'Negotiate deals', 'Follow up with customers', 'Meet sales targets'],\n            'skills': ['Communication', 'Persuasion', 'Negotiation', 'Customer service', 'Time management']\n        },\n        'Entrepreneur': {\n            'education_levels': [\"High School\", \"Bachelor's\", \"Master's\"],\n            'income_brackets': [\"Medium\", \"High\"],\n            'routines': ['Develop business strategies', 'Meet with investors', 'Manage team', 'Oversee operations', 'Analyze market trends'],\n            'skills': ['Leadership', 'Strategic planning', 'Risk management', 'Networking', 'Financial literacy']\n        }\n    }\n\n    # Select occupation and corresponding data\n    occupation = random.choice(list(occupation_data.keys()))\n    occupation_info = occupation_data[occupation]\n    education_level = random.choice(occupation_info['education_levels'])\n    income_bracket = random.choice(occupation_info['income_brackets'])\n\n    # Determine minimum age based on education level\n    def get_min_age_for_education(education_level):\n        education_age = {\n            \"High School\": 18,\n            \"Associate's\": 20,\n            \"Bachelor's\": 22,\n            \"Master's\": 24,\n            \"PhD\": 27\n        }\n        return education_age.get(education_level, 18)\n\n    min_age = get_min_age_for_education(education_level)\n    age = random.randint(min_age, 100)\n\n    # Investment Experience and Risk Appetite\n    investment_experience = random.choice(['Novice', 'Intermediate', 'Expert'])\n    risk_appetite = random.choice(['Conservative', 'Moderate', 'Aggressive'])\n\n    # Demographic Characteristics\n    demographic_characteristics = {\n        \"age\": age,\n        \"gender\": gender,\n        \"education_level\": education_level,\n        \"occupation\": occupation,\n        \"income_bracket\": income_bracket,\n        \"geographic_location\": random.choice([\"Urban\", \"Suburban\", \"Rural\"])\n    }\n\n    # Economic Attributes\n    economic_attributes = {\n        \"spending_habits\": random.choice([\"Frugal\", \"Moderate\", \"Lavish\"]),\n        \"saving_preferences\": random.choice([\"Low\", \"Medium\", \"High\"]),\n        \"risk_tolerance\": round(random.uniform(0.0, 1.0), 2),\n        \"investment_experience\": investment_experience\n    }\n\n    # Personality Traits\n    personality_traits = {\n        \"decision_making_style\": random.choice([\"Rational\", \"Emotional\", \"Impulsive\", \"Collaborative\"]),\n        \"openness\": round(random.uniform(0.0, 1.0), 2),\n        \"conscientiousness\": round(random.uniform(0.0, 1.0), 2),\n        \"extraversion\": round(random.uniform(0.0, 1.0), 2),\n        \"agreeableness\": round(random.uniform(0.0, 1.0), 2),\n        \"neuroticism\": round(random.uniform(0.0, 1.0), 2)\n    }\n\n    # Hobbies and Interests\n    hobbies_list = [\"Reading\", \"Sports\", \"Cooking\", \"Travel\", \"Music\", \"Art\", \"Gardening\", \"Photography\", \"Technology\"]\n    hobbies_and_interests = random.sample(hobbies_list, k=3)\n    hobbies_and_interests_str = \", \".join(hobbies_and_interests)\n\n    # Dynamic Attributes\n    recent_life_events_list = random.sample(\n        [\"Got a promotion\", \"Moved to a new city\", \"Started a new hobby\", \"Graduated\", \"Retired\"],\n        k=2\n    )\n    dynamic_attributes = {\n        \"current_mood\": random.choice([\"Happy\", \"Sad\", \"Neutral\", \"Excited\"]),\n        \"recent_life_events\": recent_life_events_list\n    }\n    recent_life_events_str = \", \".join(dynamic_attributes[\"recent_life_events\"])\n\n    # Financial Objectives\n    short_term_goals_list = random.sample(\n        [\"Build emergency fund\", \"Pay off credit card debt\", \"Save for vacation\"],\n        k=2\n    )\n    long_term_goals_list = random.sample(\n        [\"Save for retirement\", \"Buy a house\", \"Start a business\"],\n        k=2\n    )\n    investment_preferences_list = random.sample(\n        [\"Stocks\", \"Bonds\", \"Real Estate\", \"Cryptocurrency\", \"Commodities\"],\n        k=3\n    )\n    financial_objectives = {\n        \"short_term_goals\": short_term_goals_list,\n        \"long_term_goals\": long_term_goals_list,\n        \"risk_appetite\": risk_appetite,\n        \"investment_preferences\": investment_preferences_list\n    }\n    short_term_goals_str = \", \".join(financial_objectives[\"short_term_goals\"])\n    long_term_goals_str = \", \".join(financial_objectives[\"long_term_goals\"])\n    investment_preferences_str = \", \".join(financial_objectives[\"investment_preferences\"])\n\n    # Routines and Skills\n    routines_list = occupation_info['routines']\n    skills_list = occupation_info['skills']\n\n    routines = random.sample(routines_list, k=3) if len(routines_list) >= 3 else routines_list\n    skills = random.sample(skills_list, k=3) if len(skills_list) >= 3 else skills_list\n\n    routines_str = \", \".join(routines)\n    skills_str = \", \".join(skills)\n\n    # Communication Style\n    decision_making_to_communication = {\n        \"Rational\": [\"Direct\", \"Formal\"],\n        \"Emotional\": [\"Persuasive\", \"Friendly\", \"Informal\"],\n        \"Impulsive\": [\"Informal\", \"Direct\"],\n        \"Collaborative\": [\"Friendly\", \"Persuasive\"]\n    }\n\n    communication_styles = [\"Direct\", \"Persuasive\", \"Reserved\", \"Friendly\", \"Formal\", \"Informal\"]\n    decision_making_style = personality_traits[\"decision_making_style\"]\n    communication_style_options = decision_making_to_communication.get(decision_making_style, communication_styles)\n    communication_style = random.choice(communication_style_options)\n\n    # Read Persona Template as YAML and extract content under 'persona'\n    with open('./market_agents/agents/personas/persona_template.yaml', 'r') as file:\n        template_yaml = yaml.safe_load(file)\n    template_content = template_yaml.get('persona', '')\n\n    # Format Persona Description\n    persona_description = template_content.format(\n        name=name,\n        age=age,\n        gender=gender,\n        pronoun_subject=pronouns[\"subject\"],\n        pronoun_object=pronouns[\"object\"],\n        pronoun_possessive=pronouns[\"possessive\"],\n        pronoun_be=pronouns[\"be\"],\n        has=pronouns[\"has\"],\n        pronoun_subject_cap=pronouns_cap[\"subject\"],\n        pronoun_object_cap=pronouns_cap[\"object\"],\n        pronoun_possessive_cap=pronouns_cap[\"possessive\"],\n        education_level=education_level,\n        occupation=occupation,\n        income_bracket=income_bracket,\n        geographic_location=demographic_characteristics[\"geographic_location\"],\n        spending_habits=economic_attributes[\"spending_habits\"],\n        saving_preferences=economic_attributes[\"saving_preferences\"],\n        risk_tolerance=economic_attributes[\"risk_tolerance\"],\n        investment_experience=investment_experience,\n        decision_making_style=personality_traits[\"decision_making_style\"],\n        openness=personality_traits[\"openness\"],\n        conscientiousness=personality_traits[\"conscientiousness\"],\n        extraversion=personality_traits[\"extraversion\"],\n        agreeableness=personality_traits[\"agreeableness\"],\n        neuroticism=personality_traits[\"neuroticism\"],\n        hobbies_and_interests=hobbies_and_interests_str,\n        current_mood=dynamic_attributes[\"current_mood\"],\n        recent_life_events=recent_life_events_str,\n        short_term_goals=short_term_goals_str,\n        long_term_goals=long_term_goals_str,\n        risk_appetite=risk_appetite,\n        investment_preferences=investment_preferences_str,\n        communication_style=communication_style,\n        routines=routines_str,\n        skills=skills_str\n    )\n\n    # Objectives\n    objectives = [\n        #f\"{'Purchase' if role == 'Buyer' else 'Sell'} goods at favorable prices\",\n        #f\"Your goal is to {'maximize utility' if role == 'Buyer' else 'maximize profits'}\"\n        f\"Your primary objective is to make rational decisions\",\n        f\"You are a utility maximizing agent\", \n        f\"You will maximize rewards from environments\"\n    ]\n\n    # Trader Type\n    trader_type = [investment_experience, risk_appetite, personality_traits[\"decision_making_style\"]]\n\n    return Persona(\n        name=name,\n        role=role,\n        persona=persona_description,\n        objectives=objectives,\n        trader_type=trader_type,\n        communication_style=communication_style,\n        routines=routines,\n        skills=skills\n    )\n\ndef save_persona_to_file(persona: Persona, output_dir: Path):\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Prepare the persona dictionary\n    persona_dict = {\n        'name': persona.name,\n        'role': persona.role,\n        'persona': persona.persona,\n        'objectives': persona.objectives,\n        'trader_type': persona.trader_type,\n        'communication_style': persona.communication_style,\n        'routines': persona.routines,\n        'skills': persona.skills\n    }\n\n    # Custom YAML dumper to force literal block style for the persona field\n    class LiteralDumper(yaml.SafeDumper):\n        def represent_scalar(self, tag, value, style=None):\n            if tag == 'tag:yaml.org,2002:str' and '\\n' in value:\n                style = '|'\n            return super().represent_scalar(tag, value, style)\n\n    with open(output_dir / f\"{persona.name.replace(' ', '_')}.yaml\", \"w\") as f:\n        yaml.dump(\n            persona_dict,\n            f,\n            default_flow_style=False,\n            sort_keys=False,\n            allow_unicode=True,\n            width=1000,\n            indent=2,\n            Dumper=LiteralDumper\n        )\n\ndef generate_and_save_personas(num_personas: int, output_dir: Path):\n    for _ in range(num_personas):\n        persona = generate_persona()\n        save_persona_to_file(persona, output_dir)\n\ndef load_persona_from_file(filepath: Union[str, Path]) -> Persona:\n    \"\"\"Load a persona from a YAML file.\"\"\"\n    with open(filepath, 'r') as file:\n        persona_data = yaml.safe_load(file)\n        return Persona(**persona_data)\n    \ndef load_or_generate_personas(personas_dir: Path, num: int) -> List[Persona]:\n    \"\"\"\n    Load existing personas from 'personas_dir' or generate/generate new ones if needed.\n    \"\"\"\n    personas_dir.mkdir(parents=True, exist_ok=True)\n    existing_personas = list(personas_dir.rglob(\"*.yaml\"))\n    personas = []\n    \n    for p_file in existing_personas:\n        if len(personas) >= num:\n            break\n        persona = load_persona_from_file(p_file)\n        personas.append(persona)\n\n    while len(personas) < num:\n        persona = generate_persona()\n        folder_name = f\"{persona.role.replace(' ', '_')}\"\n        save_persona_to_file(persona, personas_dir / folder_name)\n        personas.append(persona)\n\n    return personas[:num]\n\nif __name__ == \"__main__\":\n    output_dir = Path(\"./market_agents/agents/personas/generated_personas\")\n    generate_and_save_personas(10, output_dir)\n    print(f\"Generated 10 personas in {output_dir}\")\n"}
{"type": "source_file", "path": "market_agents/environments/config.py", "content": "\nfrom pydantic import Field\nfrom pydantic_settings import BaseSettings\n\nclass EnvironmentConfig(BaseSettings):\n    name: str = Field(\n        ...,\n        description=\"Name of the group chat environment\"\n    )\n    api_url: str = Field(\n        ...,\n        description=\"API endpoint for the environment\"\n    )\n    model_config = {\n        \"extra\": \"allow\"\n    }"}
{"type": "source_file", "path": "market_agents/inference/clients_models.py", "content": "from pydantic import BaseModel, Field\nfrom typing import  Optional, Union, Dict, List, Any\n\nfrom openai.types.chat import (\n    ChatCompletionMessageParam,\n    ChatCompletionToolParam,\n    ChatCompletionToolChoiceOptionParam\n)\nfrom openai.types.shared_params import (\n\n    FunctionDefinition\n)\nfrom openai.types.chat.completion_create_params import (\n    ResponseFormat,\n    FunctionCall\n)\nfrom openai.types.shared_params.response_format_json_schema import ResponseFormatJSONSchema\n\n\nfrom anthropic.types.beta.prompt_caching import (\n    PromptCachingBetaToolParam,\n    PromptCachingBetaMessageParam,\n    PromptCachingBetaTextBlockParam,\n    message_create_params\n)\nfrom anthropic.types.model_param import ModelParam\n\n\nclass OpenAIRequest(BaseModel):\n    messages: List[ChatCompletionMessageParam]\n    model: str\n    frequency_penalty: Optional[float] = Field(default=None)\n    function_call: Optional[FunctionCall] = Field(default=None)\n    functions: Optional[List[FunctionDefinition]] = Field(default=None)\n    logit_bias: Optional[Dict[str, int]] = Field(default=None)\n    max_tokens: Optional[int] = Field(default=None)\n    n: Optional[int] = Field(default=None)\n    presence_penalty: Optional[float] = Field(default=None)\n    response_format: Optional[ResponseFormat] = Field(default=None)\n    seed: Optional[int] = Field(default=None)\n    stop: Optional[Union[str, List[str]]] = Field(default=None)\n    stream: Optional[bool] = Field(default=None)\n    temperature: Optional[float] = Field(default=None)\n    tool_choice: Optional[ChatCompletionToolChoiceOptionParam] = Field(default=None)\n    tools: Optional[List[ChatCompletionToolParam]] = Field(default=None)\n    top_p: Optional[float] = Field(default=None)\n    user: Optional[str] = Field(default=None)\n\n    class Config:\n        extra = 'forbid'\n\n\nclass AnthropicRequest(BaseModel):\n    max_tokens: int\n    messages: List[PromptCachingBetaMessageParam]\n    model: ModelParam\n    metadata: message_create_params.Metadata | None = Field(default=None)\n    stop_sequences: List[str] | None = Field(default=None)\n    stream: bool | None = Field(default=None)\n    system: Union[str, List[PromptCachingBetaTextBlockParam]] | None = Field(default=None)\n    temperature: float | None = Field(default=None)\n    tool_choice: message_create_params.ToolChoice | None = Field(default=None)\n    tools: List[PromptCachingBetaToolParam] | None = Field(default=None)\n    top_k: int | None = Field(default=None)\n    top_p: float | None = Field(default=None)\n\nclass VLLMConfig(BaseModel):\n    echo: bool = Field(\n        default=False,\n        description=(\n            \"If true, the new message will be prepended with the last message \"\n            \"if they belong to the same role.\"),\n    )\n    add_generation_prompt: bool = Field(\n        default=True,\n        description=\n        (\"If true, the generation prompt will be added to the chat template. \"\n         \"This is a parameter used by chat template in tokenizer config of the \"\n         \"model.\"),\n    )\n    add_special_tokens: bool = Field(\n        default=False,\n        description=(\n            \"If true, special tokens (e.g. BOS) will be added to the prompt \"\n            \"on top of what is added by the chat template. \"\n            \"For most models, the chat template takes care of adding the \"\n            \"special tokens so this should be set to false (as is the \"\n            \"default).\"),\n    )\n    documents: Optional[List[Dict[str, str]]] = Field(\n        default=None,\n        description=\n        (\"A list of dicts representing documents that will be accessible to \"\n         \"the model if it is performing RAG (retrieval-augmented generation).\"\n         \" If the template does not support RAG, this argument will have no \"\n         \"effect. We recommend that each document should be a dict containing \"\n         \"\\\"title\\\" and \\\"text\\\" keys.\"),\n    )\n    chat_template: Optional[str] = Field(\n        default=None,\n        description=(\n            \"A Jinja template to use for this conversion. \"\n            \"As of transformers v4.44, default chat template is no longer \"\n            \"allowed, so you must provide a chat template if the tokenizer \"\n            \"does not define one.\"),\n    )\n    chat_template_kwargs: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=(\"Additional kwargs to pass to the template renderer. \"\n                     \"Will be accessible by the chat template.\"),\n    )\n    guided_json: Optional[Union[str, dict, BaseModel]] = Field(\n        default=None,\n        description=(\"If specified, the output will follow the JSON schema.\"),\n    )\n    guided_regex: Optional[str] = Field(\n        default=None,\n        description=(\n            \"If specified, the output will follow the regex pattern.\"),\n    )\n    guided_choice: Optional[List[str]] = Field(\n        default=None,\n        description=(\n            \"If specified, the output will be exactly one of the choices.\"),\n    )\n    guided_grammar: Optional[str] = Field(\n        default=None,\n        description=(\n            \"If specified, the output will follow the context free grammar.\"),\n    )\n    guided_decoding_backend: Optional[str] = Field(\n        default=None,\n        description=(\n            \"If specified, will override the default guided decoding backend \"\n            \"of the server for this specific request. If set, must be either \"\n            \"'outlines' / 'lm-format-enforcer'\"))\n    guided_whitespace_pattern: Optional[str] = Field(\n        default=None,\n        description=(\n            \"If specified, will override the default whitespace pattern \"\n            \"for guided json decoding.\"))\n    \nclass VLLMRequest(OpenAIRequest,VLLMConfig):\n    pass"}
{"type": "source_file", "path": "market_agents/economics/econ_models.py", "content": "from abc import ABC, abstractmethod\nimport logging\nfrom typing import List, Dict, Any, Optional\nfrom pydantic import BaseModel, Field\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nfrom eth_account import Account\n\nclass BaseWallet(BaseModel, ABC):\n    \"\"\"\n    Abstract wallet class for a chain identity:\n      - chain: e.g. 'ethereum', 'solana'\n      - address, private_key: user-supplied or auto-generated\n    \"\"\"\n    chain: Optional[str] = None\n    address: Optional[str] = None\n    private_key: Optional[str] = None\n\n    @abstractmethod\n    def ensure_valid_wallet(self) -> None:\n        \"\"\"\n        Subclasses handle auto-generation or validation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def sign_transaction(self, tx_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Subclasses handle real chain transaction signing.\n        \"\"\"\n        pass\n\n\nclass AgentWallet(BaseWallet):\n    \"\"\"\n    Agent wallet that auto-generates an Ethereum address/private_key if\n    chain='ethereum' and none is provided.\n    \"\"\"\n    def ensure_valid_wallet(self) -> None:\n        if self.chain and self.chain.lower() == \"ethereum\":\n            if not self.address or not self.private_key:\n                logger.info(\"[AgentWallet] Auto-generating Ethereum wallet.\")\n                self._generate_ethereum_wallet()\n\n    def _generate_ethereum_wallet(self):\n        Account.enable_unaudited_hdwallet_features()\n        acct = Account.create()\n        self.address = acct.address\n        self.private_key = acct.key.hex()\n        logger.info(f\"[AgentWallet] Generated Ethereum wallet: {self.address}\")\n\n    def sign_transaction(self, tx_data: Dict[str, Any]) -> Dict[str, Any]:\n        logger.info(f\"[AgentWallet] sign_transaction with tx_data={tx_data}\")\n        return {\"signed_tx\": \"dummy_signature\", \"tx_data\": tx_data}\n\n\nclass BaseHoldings(BaseModel, ABC):\n    \"\"\"\n    Abstract holdings class\n    \"\"\"\n    @abstractmethod\n    def record_transaction(self, tx: Dict[str, Any]) -> None:\n        pass\n\n    @abstractmethod\n    def get_total_value(\n        self, price_feeds: Optional[Dict[str, float]] = None, default_price: float = 0.0\n    ) -> float:\n        pass\n\n\nclass Portfolio(BaseHoldings):\n    \"\"\"\n    A multi-token dictionary-based portfolio:\n      token_balances = {'ETH': 2.0, 'USDC': 500.0, ...}\n      transaction_history logs local deposit/trade events, etc.\n    \"\"\"\n    token_balances: Dict[str, float] = Field(default_factory=dict)\n    transaction_history: List[Dict[str, Any]] = Field(default_factory=list)\n\n    def record_transaction(self, tx: Dict[str, Any]) -> None:\n        self.transaction_history.append(tx)\n        logger.info(f\"[Portfolio] Recorded transaction: {tx}\")\n\n    def get_token_balance(self, symbol: str) -> float:\n        \"\"\"Get the balance of a specific token. Returns 0.0 if token not found.\"\"\"\n        return self.token_balances.get(symbol, 0.0)\n\n    def get_total_value(\n        self, \n        price_feeds: Optional[Dict[str, float]] = None, \n        default_price: float = 0.0\n    ) -> float:\n        if not price_feeds:\n            return 0.0\n        total = 0.0\n        for symbol, qty in self.token_balances.items():\n            price = price_feeds.get(symbol, default_price)\n            total += qty * price\n        return total\n\n    def adjust_token_balance(self, symbol: str, delta: float) -> None:\n        old_balance = self.token_balances.get(symbol, 0.0)\n        new_balance = old_balance + delta\n        self.token_balances[symbol] = new_balance\n        logger.info(f\"[Portfolio] {symbol} balance changed: {old_balance} -> {new_balance}\")\n"}
{"type": "source_file", "path": "market_agents/agents/cognitive_schemas.py", "content": "from pydantic import BaseModel, Field\nfrom typing import Literal, Optional, List, Dict, Any\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass ThoughtStep(BaseModel):\n    reasoning: str = Field(description=\"The agent's reasoning for this step\")\n\nclass ChainOfThoughtSchema(BaseModel):\n    thoughts: List[ThoughtStep] = Field(description=\"The agent's step-by-step reasoning process\")\n    final_answer: str = Field(description=\"The final answer after the reasoning process\")\n\nclass Action(BaseModel):\n    name: str = Field(description=\"The name of the action to take\")\n    input: Optional[str] = Field(description=\"The input for the specified action, if any\")\n\nclass ReActSchema(BaseModel):\n    thought: str = Field(description=\"The agent's reasoning about the current state and what to do next\")\n    action: Optional[Action] = Field(description=\"The action to take, if any\")\n    observation: Optional[str] = Field(description=\"The result of the action taken\")\n    final_answer: Optional[str] = Field(description=\"The final answer, if the task is complete\")\n\nclass PerceptionSchema(BaseModel):\n    monologue: str = Field(..., description=\"Agent's internal monologue about the perceived environment\")\n    key_observations: List[str] = Field(..., description=\"Agent's key observations from the environment\")\n    strategy: List[str] = Field(..., description=\"Agent's strategies given the current environment\")\n    confidence: float = Field(..., ge=0.0, le=1.0, description=\"Confidence score between 0.0 and 1.0\")\n\nclass ReflectionSchema(BaseModel):\n    reflection: str = Field(..., description=\"Reflection on the observation and actions\")\n    self_critique: List[str]= Field(..., description=\"Self-critique of agent's strategies and actions on the environment\")\n    self_reward: float = Field(..., description=\"Self-assigned reward between 0.0 and 1.0\")\n    strategy_update: List[str] = Field(..., description=\"Updated strategies based on the reflection and previous strategy\")\n"}
{"type": "source_file", "path": "market_agents/agents/protocols/acl_message.py", "content": "from enum import Enum\nfrom typing import Optional, Dict, Any, List, Generic, TypeVar\nfrom pydantic import BaseModel, Field\nfrom datetime import datetime\nfrom market_agents.agents.protocols.protocol import Protocol\n\nT = TypeVar('T')\n\nclass Performative(Enum):\n    \"\"\"Enumeration of ACL message performatives.\"\"\"\n    ACCEPT_PROPOSAL = \"accept-proposal\"\n    CALL_FOR_PROPOSAL = \"cfp\"\n    PROPOSE = \"propose\"\n    REJECT_PROPOSAL = \"reject-proposal\"\n    INFORM = \"inform\"\n    REQUEST = \"request\"\n    QUERY_IF = \"query-if\"\n    NOT_UNDERSTOOD = \"not-understood\"\n\nclass AgentID(BaseModel):\n    \"\"\"Represents the identity of an agent.\"\"\"\n    name: str\n    address: Optional[str] = None\n\nclass ACLMessage(Protocol, BaseModel, Generic[T]):\n    \"\"\"Represents an ACL message with various attributes and creation methods.\"\"\"\n    performative: Optional[Performative] = None\n    sender: Optional[AgentID] = None\n    receivers: Optional[List[AgentID]] = None\n    content: Optional[T] = None\n    reply_with: Optional[str] = None\n    in_reply_to: Optional[str] = None\n    conversation_id: Optional[str] = None\n    protocol: str = \"double-auction\"\n    language: str = \"JSON\"\n    ontology: str = \"market-ontology\"\n    reply_by: Optional[datetime] = None\n\n    class Config:\n        use_enum_values = True\n\n    @classmethod\n    def create_observation(cls, sender: str, agent_id: str, content: Any, step: int):\n        \"\"\"Create an observation message.\"\"\"\n        return cls(\n            performative=Performative.INFORM,  # Use the enum value directly\n            sender=AgentID(name=sender),\n            receivers=[AgentID(name=agent_id)],\n            content=content,\n            protocol=\"double-auction\",\n            ontology=\"market-ontology\",\n            conversation_id=f\"observation-{step}-{agent_id}\"\n        )\n\n    def parse_action(self) -> Dict[str, Any]:\n        \"\"\"Parse the ACL message content into a market action.\"\"\"\n        if self.performative not in [Performative.PROPOSE, Performative.REQUEST]:\n            return {\"type\": \"hold\", \"price\": 0, \"quantity\": 0}\n        \n        content = self.content\n        if not isinstance(content, dict):\n            return {\"type\": \"hold\", \"price\": 0, \"quantity\": 0}\n        \n        action_type = content.get(\"type\", \"hold\")\n        if action_type not in [\"bid\", \"ask\", \"hold\"]:\n            return {\"type\": \"hold\", \"price\": 0, \"quantity\": 0}\n        \n        return {\n            \"type\": action_type,\n            \"price\": float(content.get(\"price\", 0)),\n            \"quantity\": int(content.get(\"quantity\", 0))\n        }\n\n    def generate_message(self, *args, **kwargs) -> 'ACLMessage':\n        \"\"\"\n        Generate a new ACLMessage based on the provided arguments.\n\n        Args:\n            *args: Variable length argument list.\n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            ACLMessage: A new ACLMessage instance.\n        \"\"\"\n        return self.create_message(*args, **kwargs)\n\n    @classmethod\n    def create_bid(cls, sender: AgentID, receiver: AgentID, bid_price: float, bid_quantity: int) -> 'ACLMessage':\n        \"\"\"\n        Create a bid message.\n\n        Args:\n            sender (AgentID): The agent sending the bid.\n            receiver (AgentID): The agent receiving the bid.\n            bid_price (float): The price of the bid.\n            bid_quantity (int): The quantity of the bid.\n\n        Returns:\n            ACLMessage: A new ACLMessage instance representing a bid.\n        \"\"\"\n        content = {\n            \"type\": \"bid\",\n            \"price\": bid_price,\n            \"quantity\": bid_quantity\n        }\n        return cls(\n            performative=Performative.PROPOSE,\n            sender=sender,\n            receivers=[receiver],\n            content=content,\n            conversation_id=f\"bid-{datetime.now().isoformat()}\"\n        )\n\n    @classmethod\n    def create_ask(cls, sender: AgentID, receiver: AgentID, ask_price: float, ask_quantity: int) -> 'ACLMessage':\n        \"\"\"\n        Create an ask message.\n\n        Args:\n            sender (AgentID): The agent sending the ask.\n            receiver (AgentID): The agent receiving the ask.\n            ask_price (float): The price of the ask.\n            ask_quantity (int): The quantity of the ask.\n\n        Returns:\n            ACLMessage: A new ACLMessage instance representing an ask.\n        \"\"\"\n        content = {\n            \"type\": \"ask\",\n            \"price\": ask_price,\n            \"quantity\": ask_quantity\n        }\n        return cls(\n            performative=Performative.PROPOSE,\n            sender=sender,\n            receivers=[receiver],\n            content=content,\n            conversation_id=f\"ask-{datetime.now().isoformat()}\"\n        )\n\n    @classmethod\n    def create_accept(cls, sender: AgentID, receiver: AgentID, original_message_id: str) -> 'ACLMessage':\n        \"\"\"\n        Create an accept message in response to a proposal.\n\n        Args:\n            sender (AgentID): The agent sending the accept message.\n            receiver (AgentID): The agent receiving the accept message.\n            original_message_id (str): The ID of the original proposal being accepted.\n\n        Returns:\n            ACLMessage: A new ACLMessage instance representing an acceptance.\n        \"\"\"\n        return cls(\n            performative=Performative.ACCEPT_PROPOSAL,\n            sender=sender,\n            receivers=[receiver],\n            content={\"accepted\": True},\n            in_reply_to=original_message_id\n        )\n\n    @classmethod\n    def create_reject(cls, sender: AgentID, receiver: AgentID, original_message_id: str, reason: str) -> 'ACLMessage':\n        \"\"\"\n        Create a reject message in response to a proposal.\n\n        Args:\n            sender (AgentID): The agent sending the reject message.\n            receiver (AgentID): The agent receiving the reject message.\n            original_message_id (str): The ID of the original proposal being rejected.\n            reason (str): The reason for rejection.\n\n        Returns:\n            ACLMessage: A new ACLMessage instance representing a rejection.\n        \"\"\"\n        return cls(\n            performative=Performative.REJECT_PROPOSAL,\n            sender=sender,\n            receivers=[receiver],\n            content={\"accepted\": False, \"reason\": reason},\n            in_reply_to=original_message_id\n        )\n\n    @classmethod\n    def create_inform(cls, sender: AgentID, receiver: AgentID, info_type: str, info_content: Any) -> 'ACLMessage':\n        \"\"\"\n        Create an inform message.\n\n        Args:\n            sender (AgentID): The agent sending the inform message.\n            receiver (AgentID): The agent receiving the inform message.\n            info_type (str): The type of information being sent.\n            info_content (Any): The content of the information.\n\n        Returns:\n            ACLMessage: A new ACLMessage instance representing an inform message.\n        \"\"\"\n        return cls(\n            performative=Performative.INFORM,\n            sender=sender,\n            receivers=[receiver],\n            content={\"type\": info_type, \"content\": info_content}\n        )\n\n    @classmethod\n    def create_message(cls, performative: Performative, sender: str, receiver: str, content: Any, **kwargs) -> 'ACLMessage':\n        \"\"\"\n        Create a generic ACL message.\n\n        Args:\n            performative (Performative): The performative of the message.\n            sender (str): The name of the sender agent.\n            receiver (str): The name of the receiver agent.\n            content (Any): The content of the message.\n            **kwargs: Additional keyword arguments for the message.\n\n        Returns:\n            ACLMessage: A new ACLMessage instance.\n        \"\"\"\n        return cls(\n            performative=performative,\n            sender=AgentID(name=sender),\n            receivers=[AgentID(name=receiver)],\n            content=content,\n            **kwargs\n        )\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Convert the ACLMessage to a dictionary.\n\n        Returns:\n            Dict[str, Any]: A dictionary representation of the ACLMessage.\n        \"\"\"\n        return self.dict(exclude_none=True)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'ACLMessage':\n        \"\"\"\n        Create an ACLMessage instance from a dictionary.\n\n        Args:\n            data (Dict[str, Any]): A dictionary containing ACLMessage data.\n\n        Returns:\n            ACLMessage: A new ACLMessage instance created from the dictionary data.\n        \"\"\"\n        return cls(**data)\n    \n    def parse_to_market_action(self) -> Dict[str, Any]:\n        \"\"\"Parse the ACL message content into a market action.\"\"\"\n        if self.performative not in [Performative.PROPOSE, Performative.REQUEST]:\n            return {\"type\": \"hold\", \"price\": 0, \"quantity\": 0}\n        \n        content = self.content\n        if not isinstance(content, dict):\n            return {\"type\": \"hold\", \"price\": 0, \"quantity\": 0}\n        \n        action_type = content.get(\"type\", \"hold\")\n        if action_type not in [\"bid\", \"ask\", \"hold\"]:\n            return {\"type\": \"hold\", \"price\": 0, \"quantity\": 0}\n        \n        return {\n            \"type\": action_type,\n            \"price\": float(content.get(\"price\", 0)),\n            \"quantity\": int(content.get(\"quantity\", 0))\n        }"}
{"type": "source_file", "path": "market_agents/environments/__init__.py", "content": ""}
{"type": "source_file", "path": "market_agents/agents/base_agent/agent.py", "content": "import uuid\nimport logging\nfrom typing import Optional, List, Union, Dict, Any\nfrom pydantic import BaseModel, Field\n\nfrom minference.lite.models import (\n    EntityRegistry,\n    ChatThread,\n    SystemPrompt,\n    LLMConfig,\n    ProcessedOutput,\n    CallableTool,\n    StructuredTool\n)\nfrom minference.lite.inference import InferenceOrchestrator\n\nfrom market_agents.agents.base_agent.prompter import PromptManager\n\nEntityRegistry()\nagent_logger = logging.getLogger(__name__)\n\nclass Agent(BaseModel):\n    \"\"\"\n    Base LLM-driven agent using ChatThread-based inference.\n    \"\"\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        description=\"Unique string identifier for the agent instance.\"\n    )\n    role: str = Field(\n        ...,\n        description=\"Functional role of the agent (e.g., 'financial analyst').\"\n    )\n    persona: Optional[str] = Field(\n        default=None,\n        description=\"Additional persona or background info for the agent.\"\n    )\n    objectives: Optional[List[str]] = Field(\n        default=None,\n        description=\"High-level goals or objectives for the agent.\"\n    )\n    task: Optional[str] = Field(\n        default=None,\n        description=\"Primary tasks or instructions for the agent.\"\n    )\n    tools: List[Union[CallableTool, StructuredTool]] = Field(\n        default_factory=list,\n        description=\"List of callable or structured tools the agent can invoke.\"\n    )\n    llm_config: Optional[LLMConfig] = Field(\n        default=None,\n        description=\"LLM configuration (model, client, response format, etc.).\"\n    )\n    llm_orchestrator: InferenceOrchestrator = Field(\n        ...,\n        description=\"Inference orchestrator for parallel LLM requests.\"\n    )\n    prompt_manager: Optional[PromptManager] = Field(\n        default=None,\n        description=\"Manages YAML-based prompt assembly for system/user messages.\"\n    )\n    chat_thread: Optional[ChatThread] = Field(\n        default=None,\n        description=\"Holds conversation state, system prompt, and message history.\"\n    )\n\n    class Config:\n        arbitrary_types_allowed = True\n\n    def __init__(self, **data: Any) -> None:\n        \"\"\"Initialize the agent and set up ChatThread from the prompt manager.\"\"\"\n        super().__init__(**data)\n\n        if not self.llm_config:\n            raise ValueError(\n                \"Agent requires an `llm_config` to specify which model/client to use.\"\n            )\n\n        if not self.prompt_manager:\n            self.prompt_manager = PromptManager()\n\n        system_str = self.prompt_manager.get_system_prompt({\n            \"role\": self.role,\n            \"persona\": self.persona,\n            \"objectives\": self.objectives\n        })\n        system_prompt = SystemPrompt(\n            name=f\"SystemPrompt_{self.id}\",\n            content=system_str\n        )\n\n        initial_message = self.prompt_manager.get_task_prompt({\n            \"task\": self.task or \"observe environment\",\n            \"output_schema\": None,\n            \"output_format\": \"text\"\n        })\n\n        self.chat_thread = ChatThread(\n            name=f\"ChatThread_{self.id}\",\n            system_prompt=system_prompt,\n            llm_config=self.llm_config,\n            tools=self.tools,\n            new_message=initial_message\n        )\n\n    def _refresh_prompts(self) -> None:\n        \"\"\"\n        Re-generate system and user prompts from PromptManager,\n        and place the user prompt into `chat_thread.new_message`.\n        \"\"\"\n        agent_logger.debug(\"Refreshing prompts via PromptManager.\")\n\n        if not self.prompt_manager or not self.chat_thread:\n            agent_logger.warning(\"PromptManager or ChatThread not properly initialized.\")\n            return\n\n        system_str = self.prompt_manager.get_system_prompt({\n            \"role\": self.role,\n            \"persona\": self.persona,\n            \"objectives\": self.objectives\n        })\n        if self.chat_thread.system_prompt:\n            self.chat_thread.system_prompt.content = system_str\n\n        if self.task:\n            task_str = self.prompt_manager.get_task_prompt({\n                \"task\": self.task,\n                \"output_schema\": None,\n                \"output_format\": \"text\"\n            })\n            self.chat_thread.new_message = task_str\n\n    async def execute(self) -> Union[str, Dict[str, Any]]:\n        \"\"\"\n        Generate a new user prompt from tasks/persona and run an LLM completion.\n        Returns either plain text (if LLM not forced to structured output)\n        or a JSON object if the LLM yields a parsed structure.\n        \"\"\"\n        if not self.chat_thread:\n            raise RuntimeError(\"No ChatThread is available to run inference.\")\n\n        results = await self.llm_orchestrator.run_parallel_ai_completion([self.chat_thread])\n        if not results:\n            raise RuntimeError(\"No LLM outputs returned from orchestrator.\")\n\n        last_output: ProcessedOutput = results[-1]\n        agent_logger.info(f\"Agent {self.id} received LLM output from {self.llm_config.client}.\")\n\n        if last_output.json_object:\n            return last_output.json_object.object\n        else:\n            return last_output.content or \"\""}
{"type": "source_file", "path": "market_agents/economics/econ_agent.py", "content": "import uuid\nimport logging\nfrom typing import List, Dict, Any, Optional\nfrom market_agents.economics.econ_models import AgentWallet, BaseHoldings, BaseWallet, Portfolio\nfrom pydantic import BaseModel, Field\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\n\nclass EconomicAgent(BaseModel):\n    id: Optional[str] = None \n    rewards: List[float] = Field(default_factory=list)\n    total_reward: float = 0.0\n    wallet: Optional[BaseWallet] = None\n    holdings: Optional[BaseHoldings] = None\n    generate_wallet: bool = Field(default=False, exclude=True)\n\n    def __init__(self, initial_holdings: Optional[Dict[str, float]] = None, **data):\n        super().__init__(**data)\n        if self.wallet is not None or self.generate_wallet:\n            if self.wallet is None:\n                self.wallet = AgentWallet(chain=\"ethereum\")\n            self.wallet.ensure_valid_wallet()\n            if self.holdings is None:\n                self.holdings = Portfolio(token_balances=initial_holdings or {})\n            else:\n                if initial_holdings and isinstance(self.holdings, Portfolio):\n                    self.holdings.token_balances.update(initial_holdings)\n        else:\n            self.wallet = None\n            self.holdings = None\n\n    def add_reward(self, reward: float) -> None:\n        self.rewards.append(reward)\n        self.total_reward += reward\n        logger.info(f\"[EconomicAgent] {self.id} +reward={reward}, total={self.total_reward}\")\n\n    def add_transaction(self, tx: Dict[str, Any]) -> None:\n        if not self.holdings:\n            logger.warning(f\"[EconomicAgent] No holdings => cannot record transaction: {tx}\")\n            return\n        self.holdings.record_transaction(tx)\n    \n    def get_token_balance(self, symbol: str) -> float:\n        \"\"\"Get the balance of a specific token. Returns 0.0 if no holdings or token not found.\"\"\"\n        if not self.holdings:\n            logger.warning(f\"[EconomicAgent] No holdings => cannot get balance: symbol={symbol}\")\n            return 0.0\n            \n        if hasattr(self.holdings, \"get_token_balance\"):\n            return self.holdings.get_token_balance(symbol)\n        else:\n            logger.warning(\n                f\"[EconomicAgent] Holdings type {type(self.holdings).__name__} does not support get_token_balance\"\n            )\n            return 0.0\n\n    def adjust_token_balance(self, symbol: str, delta: float) -> None:\n        if not self.holdings:\n            logger.warning(\n                f\"[EconomicAgent] No holdings => cannot adjust balance: symbol={symbol}, delta={delta}\"\n            )\n            return\n        \n        if hasattr(self.holdings, \"adjust_token_balance\"):\n            self.holdings.adjust_token_balance(symbol, delta)\n        else:\n            logger.warning(\n                f\"[EconomicAgent] Holdings type {type(self.holdings).__name__} does not support adjust_token_balance\"\n            )\n\n    def get_portfolio_value(\n        self, \n        price_feeds: Optional[Dict[str, float]] = None, \n        default_price: float = 0.0\n    ) -> float:\n        if not self.holdings:\n            return 0.0\n        return self.holdings.get_total_value(price_feeds, default_price)\n\n    # --- Wallet / Chain usage stubs ---\n    def sign_transaction(self, tx_data: Dict[str, Any]) -> Dict[str, Any]:\n        if not self.wallet:\n            logger.warning(\"[EconomicAgent] No wallet => cannot sign transaction.\")\n            return {}\n        return self.wallet.sign_transaction(tx_data)\n    \n    def serialize(self) -> Dict[str, Any]:\n        return {\n            'id': self.id,\n            'rewards': self.rewards,\n            'total_reward': self.total_reward,\n            'wallet': self.wallet.dict() if self.wallet else None,\n            'holdings': self.holdings.dict() if self.holdings else None\n        }\n\n    def __str__(self):\n        w_str = \"No wallet\"\n        if self.wallet:\n            pk_str = (\n                self.wallet.private_key[:10] + \"...\"\n            ) if self.wallet.private_key else \"None\"\n            w_str = f\"chain={self.wallet.chain}, address={self.wallet.address}, pk={pk_str}\"\n\n        h_str = \"No holdings\"\n        if self.holdings:\n            if isinstance(self.holdings, Portfolio):\n                h_str = f\"tokens={self.holdings.token_balances}, tx_count={len(self.holdings.transaction_history)}\"\n            elif isinstance(self.holdings, MyCustomHoldings):\n                h_str = f\"points={self.holdings.points}\"\n            else:\n                h_str = f\"custom holdings type: {type(self.holdings).__name__}\"\n\n        return (\n            f\"EconomicAgent(id={self.id}, total_reward={self.total_reward})\\n\"\n            f\"Wallet: {w_str}\\n\"\n            f\"Holdings: {h_str}\\n\"\n            f\"Rewards: {self.rewards}\"\n        )\n\nif __name__ == \"__main__\":\n    # Agent with NO wallet -> no holdings\n    agent_none = EconomicAgent()\n    agent_none.add_reward(10.0)\n    agent_none.adjust_token_balance(\"ETH\", 2.0)\n    agent_none.add_transaction({\"type\": \"deposit\", \"symbol\": \"ETH\", \"amount\": 2.0})\n    print(\"\\n-- Agent with NO WALLET --\")\n    print(agent_none)\n\n    # Agent with auto-generated wallet -> auto-creates a Portfolio\n    agent_auto = EconomicAgent(generate_wallet=True)\n    agent_auto.add_reward(20.0)\n    agent_auto.adjust_token_balance(\"ETH\", 2.0)\n    agent_auto.add_transaction({\"type\": \"faucet\", \"symbol\": \"ETH\", \"amount\": 2.0})\n    # sign a transaction\n    signed_tx = agent_auto.sign_transaction({\"action\": \"transfer\", \"amount\": 50, \"symbol\": \"ETH\"})\n    print(\"\\n-- Agent with AUTO wallet --\")\n    print(agent_auto)\n    print(\"Signed TX =>\", signed_tx)\n\n    # Agent with user-supplied wallet -> needs holdings (auto if not given)\n    custom_wallet = AgentWallet(chain=\"ethereum\", address=\"0xMyAddr\", private_key=\"0xMyPrivKey\")\n    agent_with_wallet = EconomicAgent(wallet=custom_wallet)\n    agent_with_wallet.adjust_token_balance(\"USDC\", 500.0)\n    agent_with_wallet.add_transaction({\"type\": \"deposit\", \"symbol\": \"USDC\", \"amount\": 500.0})\n    print(\"\\n-- Agent with user-supplied WALLET --\")\n    print(agent_with_wallet)\n\n    # Provide your own custom holdings\n    class MyCustomHoldings(BaseHoldings):\n        \"\"\"Example user-defined holdings with a single 'points' field.\"\"\"\n        points: float = 0.0\n\n        def record_transaction(self, tx: Dict[str, Any]) -> None:\n            logger.info(f\"[MyCustomHoldings] transaction={tx} (just logging, no effect)\")\n\n        def get_total_value(\n            self, price_feeds: Optional[Dict[str, float]] = None, default_price: float = 0.0\n        ) -> float:\n            return self.points\n\n        def add_points(self, amt: float) -> None:\n            self.points += amt\n\n    # we can pass both a wallet and a custom holdings\n    custom_holdings = MyCustomHoldings(points=100)\n    agent_custom = EconomicAgent(wallet=custom_wallet, holdings=custom_holdings)\n    agent_custom.add_transaction({\"type\": \"test_tx\"})\n\n    if isinstance(agent_custom.holdings, MyCustomHoldings):\n        agent_custom.holdings.add_points(50)\n\n    print(\"\\n-- Agent with custom holdings + user-supplied wallet --\")\n    print(agent_custom)\n    val_custom = agent_custom.get_portfolio_value()\n    print(f\"Custom holdings value => {val_custom}\")"}
{"type": "source_file", "path": "market_agents/agents/market_agent.py", "content": "from typing import Type, List, Union, Dict, Any, Optional\nfrom pydantic import Field, validator\nimport logging\n\nfrom market_agents.agents.base_agent.agent import Agent\nfrom market_agents.agents.cognitive_steps import (\n    CognitiveEpisode,\n    CognitiveStep,\n    PerceptionStep,\n    ActionStep,\n    ReflectionStep\n)\nfrom market_agents.agents.market_agent_prompter import MarketAgentPromptManager\nfrom market_agents.agents.personas.persona import Persona\nfrom market_agents.economics.econ_agent import EconomicAgent\nfrom minference.lite.inference import InferenceOrchestrator\nfrom minference.lite.models import LLMConfig\nfrom market_agents.memory.agent_storage.agent_storage_api_utils import AgentStorageAPIUtils\nfrom market_agents.memory.knowledge_base_agent import KnowledgeBaseAgent\nfrom market_agents.memory.memory import LongTermMemory, MemoryObject, ShortTermMemory\nfrom market_agents.environments.environment import LocalObservation, MultiAgentEnvironment\nfrom market_agents.agents.protocols.protocol import Protocol\nfrom market_agents.verbal_rl.rl_agent import VerbalRLAgent\nfrom market_agents.verbal_rl.rl_models import BaseRewardFunction\n\nlogger = logging.getLogger(__name__)\n\nclass MarketAgent(Agent):\n    \"\"\"Market agent with cognitive capabilities and memory management.\"\"\"\n    \n    short_term_memory: ShortTermMemory = Field(\n        default=None,\n        description=\"Short-term memory storage for recent cognitive stps\"\n    )\n    long_term_memory: LongTermMemory = Field(\n        default=None,\n        description=\"Long-term memory storage for episodic memories\"\n    )\n    environments: Dict[str, MultiAgentEnvironment] = Field(\n        default_factory=dict,\n        description=\"Dictionary of environments the agent can interact with\"\n    )\n    last_perception: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=\"Most recent perception output from cognitive episode\"\n    )\n    last_action: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=\"Most recent action taken by the agent\"\n    )\n    last_observation: Optional[LocalObservation] = Field(\n        default_factory=dict,\n        description=\"Most recent observation received from environment\"\n    )\n    episode_steps: List[MemoryObject] = Field(\n        default_factory=list,\n        description=\"List of memory objects from current cognitive episode\"\n    )\n    current_episode: Optional[CognitiveEpisode] = Field(\n        default=None,\n        description=\"Currently executing cognitive episode\"\n    )\n    protocol: Optional[Type[Protocol]] = Field(\n        default=None,\n        description=\"Communication protocol used by the agent\"\n    )\n    address: str = Field(\n        default=\"\",\n        description=\"Agent's address for communication purposes\"\n    )\n    knowledge_agent: Optional[KnowledgeBaseAgent] = Field(\n        default=None,\n        description=\"Knowledge base agent for accessing external information\"\n    )\n    economic_agent: Optional[EconomicAgent] = Field(\n        default=None,\n        description=\"Economic agent component for market interactions\"\n    )\n    rl_agent: VerbalRLAgent = Field(\n        default_factory=VerbalRLAgent,\n        description=\"Verbal RL subsystem for learning & adaption\"\n    )\n    prompt_manager: MarketAgentPromptManager = Field(\n        default_factory=MarketAgentPromptManager,\n        description=\"Manager for handling agent prompts and templates\"\n    )\n\n    @classmethod\n    async def create(\n        cls,\n        storage_utils: AgentStorageAPIUtils,\n        agent_id: str,\n        ai_utils: Optional[InferenceOrchestrator] = None, \n        use_llm: bool = True,\n        llm_config: Optional[LLMConfig] = None,\n        environments: Optional[Dict[str, MultiAgentEnvironment]] = None,\n        protocol: Optional[Type[Protocol]] = None,\n        persona: Optional[Persona] = None,\n        econ_agent: Optional[EconomicAgent] = None,\n        knowledge_agent: Optional[KnowledgeBaseAgent] = None,\n        reward_function: Optional[BaseRewardFunction] = None,\n    ) -> 'MarketAgent':\n        stm = ShortTermMemory(\n            agent_id=agent_id,\n            agent_storage_utils=storage_utils\n        )\n        await stm.initialize()\n        \n        ltm = LongTermMemory(\n            agent_id=agent_id,\n            agent_storage_utils=storage_utils\n        )\n        await ltm.initialize()\n\n        agent = cls(\n            id=agent_id,\n            short_term_memory=stm,\n            long_term_memory=ltm,\n            llm_orchestrator=ai_utils or InferenceOrchestrator(),\n            role=persona.role if persona else \"AI agent\",\n            persona=persona.persona if persona else None,\n            objectives=persona.objectives if persona else None,\n            llm_config=llm_config or LLMConfig(),\n            environments=environments or {},\n            protocol=protocol,\n            address=f\"agent_{agent_id}_address\",\n            use_llm=use_llm,\n            economic_agent=econ_agent,\n            knowledge_agent=knowledge_agent,\n            rl_agent=VerbalRLAgent(reward_function=reward_function) if reward_function else VerbalRLAgent()\n        )\n\n        if agent.economic_agent:\n            agent.economic_agent.id = agent_id\n\n        if agent.knowledge_agent:\n            agent.knowledge_agent.id = agent_id\n\n        return agent\n    \n    async def run_step(\n        self,\n        step: Optional[Union[CognitiveStep, Type[CognitiveStep]]] = None,\n        environment_name: Optional[str] = None,\n        **kwargs\n    ) -> Union[str, Dict[str, Any]]:\n        \"\"\"\n        Execute a single cognitive step.\n        \n        Args:\n            step: CognitiveStep instance or class (defaults to ActionStep)\n            environment_name: Optional environment context\n            **kwargs: Additional parameters for step initialization\n        \"\"\"\n        if environment_name and environment_name not in self.environments:\n            raise ValueError(f\"Environment {environment_name} not found\")\n        \n        env_name = environment_name or next(iter(self.environments.keys()))\n        environment = self.environments[env_name]\n        \n        if step is None:\n            step = ActionStep(\n                agent_id=self.id,\n                environment_name=env_name,\n                environment_info=environment.get_global_state(agent_id=self.id),\n                **kwargs\n            )\n        elif isinstance(step, type):\n            step = step(\n                agent_id=self.id,\n                environment_name=env_name,\n                environment_info=environment.get_global_state(agent_id=self.id),\n                **kwargs\n            )\n        else:\n            step.environment_name = env_name\n            step.environment_info = environment.get_global_state(agent_id=self.id)\n            step.agent_id = self.id\n        \n        logger.info(f\"Executing cognitive step: {step.step_name}\")\n        \n        result = await step.execute(self)\n\n        return result\n\n    async def run_episode(\n        self,\n        episode: Optional[CognitiveEpisode] = None,\n        environment_name: Optional[str] = None,\n        **kwargs\n    ) -> List[Union[str, Dict[str, Any]]]:\n        \"\"\"\n        Run a complete cognitive episode.\n        \n        Args:\n            episode: CognitiveEpisode instance (defaults to Perception->Action[Observation]->Reflection)\n            environment_name: Optional environment to use\n            **kwargs: Additional parameters passed to each step\n        \"\"\"\n        self._refresh_prompts()\n        \n        if episode is None:\n            episode = CognitiveEpisode(\n                steps=[PerceptionStep, ActionStep, ReflectionStep],\n                environment_name=environment_name or next(iter(self.environments.keys()))\n            )\n        elif environment_name:\n            episode.environment_name = environment_name\n\n        results = []\n        for step_class in episode.steps:\n            result = await self.run_step(\n                step=step_class,\n                environment_name=episode.environment_name,\n                **kwargs\n            )\n            results.append(result)\n            \n        return results"}
{"type": "source_file", "path": "market_agents/inference/utils.py", "content": "import os\nfrom openai.types.chat import ChatCompletionMessageParam\n\nfrom anthropic.types import MessageParam\nfrom anthropic.types.beta.prompt_caching.prompt_caching_beta_cache_control_ephemeral_param import PromptCachingBetaCacheControlEphemeralParam\nfrom anthropic.types.beta.prompt_caching.prompt_caching_beta_text_block_param import PromptCachingBetaTextBlockParam\nfrom anthropic.types.beta.prompt_caching.prompt_caching_beta_message_param import PromptCachingBetaMessageParam\nfrom openai.types.chat import (\n    ChatCompletionSystemMessageParam,\n    ChatCompletionUserMessageParam,\n    ChatCompletionAssistantMessageParam,\n    ChatCompletionToolMessageParam,\n    ChatCompletionFunctionMessageParam,\n    ChatCompletionMessageParam,\n)\n\n\nfrom typing import Union, Optional, List, Tuple, Literal, Dict, Any\nimport json\nimport re\nimport tiktoken\nimport ast\n\ndef parse_json_string(content: str) -> Optional[Dict[str, Any]]:\n    # Remove any leading/trailing whitespace and newlines\n    cleaned_content = content.strip()\n    \n    # Remove markdown code block syntax if present\n    cleaned_content = re.sub(r'^```(?:json)?\\s*|\\s*```$', '', cleaned_content, flags=re.MULTILINE)\n    \n    try:\n        # First, try to parse as JSON\n        return json.loads(cleaned_content)\n    except json.JSONDecodeError:\n        try:\n            # If JSON parsing fails, try to evaluate as a Python literal\n            return ast.literal_eval(cleaned_content)\n        except (SyntaxError, ValueError):\n            # If both methods fail, try to find and parse a JSON-like structure\n            json_match = re.search(r'(\\{[^{}]*\\{.*?\\}[^{}]*\\}|\\{.*?\\})', cleaned_content, re.DOTALL)\n            if json_match:\n                try:\n                    # Normalize newlines, replace single quotes with double quotes, and unescape quotes\n                    json_str = json_match.group(1).replace('\\n', '').replace(\"'\", '\"').replace('\\\\\"', '\"')\n                    return json.loads(json_str)\n                except json.JSONDecodeError:\n                    pass\n    \n    # If all parsing attempts fail, return None\n    return None\n\ndef get_ai_context_length(ai_vendor: Literal[\"openai\", \"azure_openai\", \"anthropic\"]):\n        if ai_vendor == \"openai\":\n            return os.getenv(\"OPENAI_CONTEXT_LENGTH\")\n        if ai_vendor == \"azure_openai\":\n            return os.getenv(\"AZURE_OPENAI_CONTEXT_LENGTH\")\n        elif ai_vendor == \"anthropic\":\n            return os.getenv(\"ANTHROPIC_CONTEXT_LENGTH\")\n\n\ndef msg_dict_to_oai(messages: List[Dict[str, Any]]) -> List[ChatCompletionMessageParam]:\n        def convert_message(msg: Dict[str, Any]) -> ChatCompletionMessageParam:\n            role = msg[\"role\"]\n            if role == \"system\":\n                return ChatCompletionSystemMessageParam(role=role, content=msg[\"content\"])\n            elif role == \"user\":\n                return ChatCompletionUserMessageParam(role=role, content=msg[\"content\"])\n            elif role == \"assistant\":\n                assistant_msg = ChatCompletionAssistantMessageParam(role=role, content=msg.get(\"content\"))\n                if \"function_call\" in msg:\n                    assistant_msg[\"function_call\"] = msg[\"function_call\"]\n                if \"tool_calls\" in msg:\n                    assistant_msg[\"tool_calls\"] = msg[\"tool_calls\"]\n                return assistant_msg\n            elif role == \"tool\":\n                return ChatCompletionToolMessageParam(role=role, content=msg[\"content\"], tool_call_id=msg[\"tool_call_id\"])\n            elif role == \"function\":\n                return ChatCompletionFunctionMessageParam(role=role, content=msg[\"content\"], name=msg[\"name\"])\n            else:\n                raise ValueError(f\"Unknown role: {role}\")\n\n        return [convert_message(msg) for msg in messages]\n\ndef msg_dict_to_anthropic(messages: List[Dict[str, Any]],use_cache:bool=True,use_prefill:bool=False) -> Tuple[List[PromptCachingBetaTextBlockParam],List[MessageParam]]:\n        def create_anthropic_system_message(system_message: Optional[Dict[str, Any]],use_cache:bool=True) -> List[PromptCachingBetaTextBlockParam]:\n            if system_message and system_message[\"role\"] == \"system\":\n                text = system_message[\"content\"]\n                if use_cache:\n                    return [PromptCachingBetaTextBlockParam(type=\"text\", text=text, cache_control=PromptCachingBetaCacheControlEphemeralParam(type=\"ephemeral\"))]\n                else:\n                    return [PromptCachingBetaTextBlockParam(type=\"text\", text=text)]\n            return []\n\n        def convert_message(msg: Dict[str, Any],use_cache:bool=False) -> Union[PromptCachingBetaMessageParam, None]:\n            role = msg[\"role\"]\n            content = msg[\"content\"]\n            if role == \"system\":\n                return None\n            \n            if isinstance(content, str):\n                if not use_cache:\n                    content = [PromptCachingBetaTextBlockParam(type=\"text\", text=content)]\n                else:\n                    content = [PromptCachingBetaTextBlockParam(type=\"text\", text=content,cache_control=PromptCachingBetaCacheControlEphemeralParam(type='ephemeral'))]\n            elif isinstance(content, list):\n                if not use_cache:\n                    content = [\n                        PromptCachingBetaTextBlockParam(type=\"text\", text=block) if isinstance(block, str)\n                        else PromptCachingBetaTextBlockParam(type=\"text\", text=block[\"text\"]) for block in content\n                    ]\n                else:\n                    content = [\n                        PromptCachingBetaTextBlockParam(type=\"text\", text=block, cache_control=PromptCachingBetaCacheControlEphemeralParam(type='ephemeral')) if isinstance(block, str)\n                        else PromptCachingBetaTextBlockParam(type=\"text\", text=block[\"text\"], cache_control=PromptCachingBetaCacheControlEphemeralParam(type='ephemeral')) for block in content\n                    ]\n            else:\n                raise ValueError(\"Invalid content type\")\n            \n            return PromptCachingBetaMessageParam(role=role, content=content)\n        converted_messages = []\n        system_message = []\n        num_messages = len(messages)\n        if use_cache:\n            use_cache_ids = set([num_messages - 1, max(0, num_messages - 3)])\n        else:\n            use_cache_ids = set()\n        for i,message in enumerate(messages):\n            if message[\"role\"] == \"system\":\n                system_message= create_anthropic_system_message(message,use_cache=use_cache)\n            else:\n                \n                use_cache_final = use_cache if  i in use_cache_ids else False\n                converted_messages.append(convert_message(message,use_cache= use_cache_final))\n\n        \n        return system_message, [msg for msg in converted_messages if msg is not None]\n"}
{"type": "source_file", "path": "market_agents/memory/agent_storage/setup_db.py", "content": "import asyncio\nimport random\n\nimport asyncpg\nfrom asyncpg import Pool, create_pool\nfrom asyncpg.exceptions import DuplicateDatabaseError\nimport logging\nimport re\nfrom typing import Optional, List, Dict, AsyncIterator\nfrom contextlib import asynccontextmanager\n\n\nclass AsyncDatabase:\n    def __init__(self, config):\n        self.config = config\n        self.pool: Optional[Pool] = None\n        self.logger = logging.getLogger(\"async_db\")\n        self._lock = asyncio.Lock()\n        self._is_initialized = False\n        self.retry_config = {\n            'initial_delay': self.config.retry_delay,\n            'max_delay': self.config.retry_max_delay,\n            'backoff_factor': self.config.retry_backoff_factor,\n            'jitter': self.config.retry_jitter\n        }\n\n    async def initialize(self):\n        \"\"\"Initialize connection pool and verify database setup\"\"\"\n        if not self._is_initialized:\n            async with self._lock:\n                if not self._is_initialized:\n                    await self._ensure_database_exists()\n                    self.pool = await create_pool(\n                        min_size=self.config.pool_min,\n                        max_size=self.config.pool_max,\n                        host=self.config.host,\n                        port=self.config.port,\n                        user=self.config.user,\n                        password=self.config.password,\n                        database=self.config.db_name,\n                        timeout=30,\n                        command_timeout=60,\n                    )\n                    await self._verify_extensions()\n                    self._is_initialized = True\n    \n    async def is_connected(self) -> bool:\n        \"\"\"Check if database connection is alive.\"\"\"\n        try:\n            if not self.pool:\n                return False\n            \n            async with self.pool.acquire() as conn:\n                await conn.execute(\"SELECT 1\")\n                return True\n        except Exception as e:\n            self.logger.error(f\"Database connection check failed: {e}\")\n            return False\n\n    async def close(self):\n        \"\"\"Close all connections in the pool\"\"\"\n        if self.pool:\n            await self.pool.close()\n\n    @asynccontextmanager\n    async def transaction(self, isolation: str = \"repeatable_read\") -> AsyncIterator[asyncpg.Connection]:\n        \"\"\"Transaction context manager with retry support\"\"\"\n        async with self.pool.acquire() as conn:\n            async with conn.transaction(isolation=isolation):\n                yield conn\n\n    @asynccontextmanager\n    async def safe_transaction(self, max_retries: int = 3) -> AsyncIterator[asyncpg.Connection]:\n        \"\"\"Retryable transaction with error classification.\"\"\"\n        last_error = None\n        for attempt in range(max_retries):\n            try:\n                async with self.transaction() as conn:\n                    yield conn\n                    return\n            except Exception as e:\n                last_error = e\n                self.logger.error(f\"Transaction failed (attempt {attempt + 1}/{max_retries}): {e}\")\n                if attempt < max_retries - 1:\n                    await asyncio.sleep(self._calculate_backoff(attempt))\n                else:\n                    raise last_error\n\n    async def execute_in_transaction(self, queries: list[tuple[str, tuple]]):\n        \"\"\"Execute multiple queries in single transaction\"\"\"\n        async with self.safe_transaction() as conn:\n            for query, params in queries:\n                await conn.execute(query, *params)\n\n    async def _ensure_database_exists(self):\n        \"\"\"Create database if it doesn't exist\"\"\"\n        try:\n            # Connect to maintenance database to check/create target DB\n            temp_conn = await asyncpg.connect(\n                host=self.config.host,\n                port=self.config.port,\n                user=self.config.user,\n                password=self.config.password,\n                database='postgres'\n            )\n\n            try:\n                await temp_conn.execute(\n                    f\"CREATE DATABASE {self.config.db_name}\"\n                )\n                self.logger.info(f\"Created database {self.config.db_name}\")\n            except DuplicateDatabaseError:\n                pass\n            finally:\n                await temp_conn.close()\n        except Exception as e:\n            self.logger.error(f\"Database creation failed: {e}\")\n            raise\n\n    async def _verify_extensions(self):\n        \"\"\"Ensure required PostgreSQL extensions are installed\"\"\"\n        async with self.pool.acquire() as conn:\n            await conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n\n    async def execute(self, query: str, *args) -> str:\n        \"\"\"Execute a SQL command and return status\"\"\"\n        async with self.pool.acquire() as conn:\n            return await conn.execute(query, *args)\n\n    async def fetch(self, query: str, *args) -> List[Dict]:\n        \"\"\"Execute a query and return results\"\"\"\n        async with self.pool.acquire() as conn:\n            return await conn.fetch(query, *args)\n\n    async def ensure_connection(self):\n        \"\"\"Verify database connectivity\"\"\"\n        try:\n            async with self.pool.acquire() as conn:\n                await conn.fetch(\"SELECT 1\")\n        except Exception as e:\n            self.logger.error(\"Connection verification failed: %s\", e)\n            await self.initialize()\n\n    def _calculate_backoff(self, attempt: int) -> float:\n        \"\"\"Calculate exponential backoff with jitter\"\"\"\n        current_delay = self.retry_config['initial_delay'] * \\\n                        (self.retry_config['backoff_factor'] ** attempt)\n\n        # Apply jitter\n        jitter_amount = current_delay * self.retry_config['jitter'] * random.uniform(-1, 1)\n        next_delay = int(current_delay + jitter_amount)\n\n        # Enforce bounds\n        return max(0, min(next_delay, self.retry_config['max_delay']))\n    \n    def _sanitize_table_name(self, name: str) -> str:\n        \"\"\"Safely sanitize table names using regex\"\"\"\n        return re.sub(r'[^a-zA-Z0-9_]', '_', name)\n    \n    async def fetch_one(self, query: str, *args) -> Optional[asyncpg.Record]:\n        \"\"\"Execute a query and return a single result\"\"\"\n        async with self.pool.acquire() as conn:\n            return await conn.fetchrow(query, *args)"}
{"type": "source_file", "path": "market_agents/memory/document_reader.py", "content": "from abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom typing import List, Optional, Dict, Any, Union\nimport re\nfrom uuid import UUID\nfrom PyPDF2 import PdfReader\n\nclass DocumentReader(ABC):\n    \"\"\"Base class for document readers that process different file formats.\"\"\"\n    \n    @abstractmethod\n    def read(self, file_path: Union[str, Path]) -> str:\n        \"\"\"\n        Read and process content from a document file.\n        \n        Args:\n            file_path: Path to the document file\n            \n        Returns:\n            str: Processed text content from the document\n            \n        Raises:\n            ValueError: If file format is not supported\n        \"\"\"\n        pass\n\nclass PDFReader(DocumentReader):\n    \"\"\"Reader for PDF documents.\"\"\"\n    \n    def read(self, file_path: Union[str, Path]) -> str:\n        file_path = Path(file_path)\n        if not file_path.suffix.lower() == '.pdf':\n            raise ValueError(\"File must be a PDF document\")\n            \n        text_content = \"\"\n        pdf_reader = PdfReader(str(file_path))\n        \n        for page in pdf_reader.pages:\n            page_text = page.extract_text()\n            cleaned_text = re.sub(r'FTLN \\d+', '', page_text)\n            cleaned_text = re.sub(r'^\\d+\\s*', '', cleaned_text, flags=re.MULTILINE)\n            text_content += cleaned_text\n            \n        return text_content\n\nclass TXTReader(DocumentReader):\n    \"\"\"Reader for plain text documents.\"\"\"\n    \n    def read(self, file_path: Union[str, Path]) -> str:\n        file_path = Path(file_path)\n        if not file_path.suffix.lower() == '.txt':\n            raise ValueError(\"File must be a TXT document\")\n            \n        with open(file_path, 'r', encoding='utf-8') as f:\n            return f.read()\n\nclass DocumentReaderFactory:\n    \"\"\"Factory for creating appropriate document readers based on file type.\"\"\"\n    \n    _readers = {\n        '.pdf': PDFReader(),\n        '.txt': TXTReader()\n    }\n    \n    @classmethod\n    def get_reader(cls, file_path: Union[str, Path]) -> DocumentReader:\n        \"\"\"\n        Get appropriate reader for the given file type.\n        \n        Args:\n            file_path: Path to the document file\n            \n        Returns:\n            DocumentReader: Appropriate reader instance for the file type\n            \n        Raises:\n            ValueError: If file format is not supported\n        \"\"\"\n        file_path = Path(file_path)\n        reader = cls._readers.get(file_path.suffix.lower())\n        \n        if reader is None:\n            supported_formats = \", \".join(cls._readers.keys())\n            raise ValueError(f\"Unsupported file format. Supported formats are: {supported_formats}\")\n            \n        return reader"}
{"type": "source_file", "path": "market_agents/memory/agent_storage/__init__.py", "content": ""}
{"type": "source_file", "path": "market_agents/memory/config.py", "content": "import yaml\nfrom pydantic_settings import BaseSettings\nfrom pydantic import Field\n\nclass AgentStorageConfig(BaseSettings):\n    storage_api_url: str = Field(default=\"http://localhost:8001\")\n    db_name: str = Field(default=\"market_agents\")\n    user: str = Field(default=\"db_user\")\n    password: str = Field(default=\"db_pwd@123\")\n    host: str = Field(default=\"localhost\")\n    port: str = Field(default=\"5433\")\n    pool_min: int = Field(default=1)\n    pool_max: int = Field(default=10)\n    index_method: str = Field(default=\"ivfflat\")\n    lists: int = Field(default=100)\n    embedding_api_url: str = Field(default=\"http://38.128.232.35:8080/embed\")\n    model: str = Field(default=\"jinaai/jina-embeddings-v2-base-en\")\n    batch_size: int = Field(default=32)\n    timeout: int = Field(default=10)\n    retry_attempts: int = Field(default=3)\n    retry_delay: float = Field(default=1.0)\n    retry_max_delay: int = Field(default=60)\n    retry_backoff_factor: float = Field(default=2.0)\n    retry_jitter: float = Field(default=0.1)\n    min_chunk_size: int = Field(default=512)\n    max_chunk_size: int = Field(default=1024)\n    vector_dim: int = Field(default=768, description=\"Options: 768, 1536, etc.\")\n    max_input: int = Field(default=4096)\n    top_k: int = Field(default=3)\n    similarity_threshold: float = Field(default=0.7)\n    encoding_format: str = Field(default=\"float\")\n    embedding_provider: str = Field(default=\"tei\", description=\"Options: tei, openai, etc.\")\n\ndef load_config_from_yaml(yaml_path: str = \"config.yaml\") -> AgentStorageConfig:\n    with open(yaml_path, 'r') as f:\n        data = yaml.safe_load(f)\n    return AgentStorageConfig(**data)\n"}
{"type": "source_file", "path": "market_agents/memory/agent_storage/storage_service.py", "content": "import json\nimport logging\nimport time\nfrom typing import List, Optional, Dict, Any, Union\nfrom uuid import UUID\nfrom datetime import datetime, timezone\nimport uuid\n\nfrom market_agents.memory.agent_storage.setup_db import AsyncDatabase\nfrom market_agents.memory.config import AgentStorageConfig\nfrom market_agents.memory.embedding import MemoryEmbedder\nfrom market_agents.memory.knowledge_base import KnowledgeChunk, SemanticChunker\nfrom market_agents.memory.storage_models import (\n    EpisodicMemoryObject,\n    MemoryObject,\n    CognitiveStep,\n    RetrievedMemory\n)\n\nclass StorageService:\n    def __init__(self, db: AsyncDatabase, embedding_service: MemoryEmbedder, config: AgentStorageConfig):\n        self.db = db\n        self.embedder = embedding_service\n        self.config = config\n        self.logger = logging.getLogger(\"storage_service\")\n\n    async def create_tables(self, table_type: str, agent_id: Optional[str] = None, table_prefix: Optional[str] = None):\n        \"\"\"Creates tables based on the specified type.\"\"\"\n        try:\n            # Verify database connection\n            if not self.db.pool:\n                await self.db.initialize()\n\n            # Add validation\n            if table_type in [\"cognitive\", \"episodic\"] and not agent_id:\n                raise ValueError(f\"agent_id is required for {table_type} tables\")\n            if table_type == \"knowledge\" and not table_prefix:\n                raise ValueError(\"table_prefix is required for knowledge tables\")\n\n            self.logger.info(f\"Creating {table_type} tables with agent_id={agent_id}, prefix={table_prefix}\")\n\n            # Create pgvector extension first\n            async with self.db.safe_transaction() as conn:\n                await conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n                self.logger.info(\"Created pgvector extension\")\n\n            # Then create the specific tables\n            if table_type == \"cognitive\":\n                await self.create_agent_cognitive_memory_table(agent_id)\n            elif table_type == \"episodic\":\n                await self.create_agent_episodic_memory_table(agent_id)\n            elif table_type == \"knowledge\":\n                await self.create_knowledge_base_tables(table_prefix)\n            elif table_type == \"ai_requests\":\n                await self.create_ai_requests_table()\n            else:\n                raise ValueError(f\"Invalid table type: {table_type}\")\n                \n            self.logger.info(f\"Successfully created {table_type} tables\")\n        except Exception as e:\n            self.logger.error(f\"Error creating {table_type} tables: {str(e)}\")\n            raise\n\n    async def create_ai_requests_table(self) -> None:\n        \"\"\"Create the AI requests table.\"\"\"\n        try:\n            async with self.db.safe_transaction() as conn:\n                # Create AI requests table\n                await conn.execute(\"\"\"\n                    CREATE TABLE IF NOT EXISTS ai_requests (\n                        id SERIAL PRIMARY KEY,\n                        request_id TEXT NOT NULL,\n                        agent_id TEXT,\n                        prompt TEXT NOT NULL,\n                        response JSONB,\n                        metadata JSONB DEFAULT '{}',\n                        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n                        UNIQUE(request_id)\n                    )\n                \"\"\")\n                \n                # Create indexes\n                await conn.execute(\"\"\"\n                    CREATE INDEX IF NOT EXISTS idx_ai_requests_request_id ON ai_requests(request_id);\n                    CREATE INDEX IF NOT EXISTS idx_ai_requests_agent_id ON ai_requests(agent_id);\n                    CREATE INDEX IF NOT EXISTS idx_ai_requests_created_at ON ai_requests(created_at);\n                \"\"\")\n        except Exception as e:\n            self.logger.error(f\"Error creating AI requests table: {str(e)}\")\n            raise\n\n    async def create_knowledge_base_tables(self, table_prefix: str) -> None:\n        \"\"\"Create separate tables for a specific knowledge base.\"\"\"\n        try:\n            knowledge_objects_table = f\"{table_prefix}_knowledge_objects\"\n            knowledge_chunks_table = f\"{table_prefix}_knowledge_chunks\"\n\n            # Use a transaction to execute all queries atomically\n            async with self.db.safe_transaction() as conn:\n                # Create knowledge objects table\n                await conn.execute(f\"\"\"\n                    CREATE TABLE IF NOT EXISTS {knowledge_objects_table} (\n                        knowledge_id UUID PRIMARY KEY,\n                        content TEXT,\n                        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n                        metadata JSONB DEFAULT '{{}}'::jsonb\n                    );\n                \"\"\")\n\n                # Create knowledge chunks table\n                await conn.execute(f\"\"\"\n                    CREATE TABLE IF NOT EXISTS {knowledge_chunks_table} (\n                        id SERIAL PRIMARY KEY,\n                        knowledge_id UUID REFERENCES {knowledge_objects_table}(knowledge_id),\n                        text TEXT,\n                        start_pos INTEGER,\n                        end_pos INTEGER,\n                        embedding vector({self.config.vector_dim}),\n                        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n                    );\n                \"\"\")\n\n                # Add vector index for the chunks\n                await conn.execute(f\"\"\"\n                    CREATE INDEX IF NOT EXISTS {table_prefix}_chunks_index\n                    ON {knowledge_chunks_table} USING ivfflat (embedding vector_cosine_ops)\n                    WITH (lists = {self.config.lists});\n                \"\"\")\n\n        except Exception as e:\n            self.logger.error(f\"Error creating knowledge base tables: {str(e)}\")\n            raise\n\n    async def create_agent_cognitive_memory_table(self, agent_id: str) -> None:\n        \"\"\"\n        Create a separate cognitive memory table for a specific agent.\n        This can store single-step or short-horizon items (akin to 'STM').\n        \"\"\"\n        try:\n            # Sanitize the agent_id to create a valid table name\n            sanitized_agent_id = self.db._sanitize_table_name(agent_id)\n            cognitive_table = f\"agent_{sanitized_agent_id}_cognitive\"\n            index_name = f\"agent_{sanitized_agent_id}_cognitive_index\"\n\n            # Use a transaction to ensure atomic execution\n            async with self.db.safe_transaction() as conn:\n                # Create cognitive memory table\n                await conn.execute(f\"\"\"\n                    CREATE TABLE IF NOT EXISTS {cognitive_table} (\n                        memory_id UUID PRIMARY KEY,\n                        cognitive_step TEXT,\n                        content TEXT,\n                        embedding vector({self.config.vector_dim}),\n                        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n                        metadata JSONB DEFAULT '{{}}'::jsonb\n                    );\n                \"\"\")\n\n                # Create index for cognitive memory table\n                await conn.execute(f\"\"\"\n                    CREATE INDEX IF NOT EXISTS {index_name}\n                    ON {cognitive_table} USING ivfflat (embedding vector_cosine_ops)\n                    WITH (lists = {self.config.lists});\n                \"\"\")\n\n        except Exception as e:\n            self.logger.error(f\"Error creating agent cognitive memory table: {str(e)}\")\n            raise\n\n    async def create_agent_episodic_memory_table(self, agent_id: str) -> None:\n        \"\"\"\n        Create a separate episodic memory table for a specific agent.\n        Each row will store an entire 'episode' (cognitive_steps in JSON),\n        plus other relevant episodic info (task_query, total_reward, etc.).\n        \"\"\"\n        try:\n            # Sanitize the agent_id to create a valid table name\n            sanitized_agent_id = self.db._sanitize_table_name(agent_id)\n            episodic_table = f\"agent_{sanitized_agent_id}_episodic\"\n            index_name = f\"agent_{sanitized_agent_id}_episodic_index\"\n\n            # Use a transaction to ensure atomic execution\n            async with self.db.safe_transaction() as conn:\n                # Create episodic memory table\n                await conn.execute(f\"\"\"\n                    CREATE TABLE IF NOT EXISTS {episodic_table} (\n                        memory_id UUID PRIMARY KEY,\n                        task_query TEXT,\n                        cognitive_steps JSONB,\n                        total_reward DOUBLE PRECISION,\n                        strategy_update JSONB,\n                        embedding vector({self.config.vector_dim}),\n                        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n                        metadata JSONB DEFAULT '{{}}'::jsonb\n                    );\n                \"\"\")\n\n                # Create index for episodic memory table\n                await conn.execute(f\"\"\"\n                    CREATE INDEX IF NOT EXISTS {index_name}\n                    ON {episodic_table} USING ivfflat (embedding vector_cosine_ops)\n                    WITH (lists = {self.config.lists});\n                \"\"\")\n\n        except Exception as e:\n            self.logger.error(f\"Error creating agent episodic memory table: {str(e)}\")\n            raise\n\n    async def store_cognitive_memory(self, memory_object: MemoryObject) -> datetime:\n        \"\"\"Store a cognitive memory and return its creation timestamp.\"\"\"\n        try:\n            if memory_object.embedding is None:\n                memory_object.embedding = await self.embedder.get_embeddings(memory_object.content)\n            \n            # Convert embedding list to PostgreSQL vector string format\n            vector_str = f\"[{','.join(map(str, memory_object.embedding))}]\"\n\n            cognitive_table = f\"agent_{memory_object.agent_id}_cognitive\"\n            now = datetime.now(timezone.utc)\n\n            result = await self.db.execute(\n                f\"\"\"\n                INSERT INTO {cognitive_table}\n                (memory_id, cognitive_step, content, embedding, created_at, metadata)\n                VALUES ($1, $2, $3, $4::vector, $5, $6)\n                RETURNING created_at\n                \"\"\",\n                str(memory_object.memory_id),\n                memory_object.cognitive_step,\n                memory_object.content,\n                vector_str,\n                now,\n                json.dumps(memory_object.metadata)\n            )\n\n            return result[0] if result else now\n        except Exception as e:\n            self.logger.error(f\"Error storing cognitive memory: {str(e)}\")\n            raise\n\n    async def store_episodic_memory(self, episode: EpisodicMemoryObject) -> None:\n        \"\"\"Store an episodic memory.\"\"\"\n        try:\n            if episode.embedding is None:\n                concat_str = f\"Task:{episode.task_query} + Steps:{episode.cognitive_steps}\"\n                episode.embedding = await self.embedder.get_embeddings(concat_str)\n            \n            # Convert embedding list to PostgreSQL vector string format\n            vector_str = f\"[{','.join(map(str, episode.embedding))}]\"\n\n            episodic_table = f\"agent_{episode.agent_id}_episodic\"\n\n            await self.db.execute(\n                f\"\"\"\n                INSERT INTO {episodic_table}\n                (memory_id, task_query, cognitive_steps, total_reward,\n                 strategy_update, embedding, created_at, metadata)\n                VALUES ($1, $2, $3, $4, $5, $6::vector, $7, $8)\n                \"\"\",\n                str(episode.memory_id),\n                episode.task_query,\n                json.dumps([step.model_dump() for step in episode.cognitive_steps]),\n                episode.total_reward,\n                json.dumps(episode.strategy_update or []),\n                vector_str,\n                episode.created_at or datetime.now(timezone.utc),\n                json.dumps(episode.metadata or {})\n            )\n        except Exception as e:\n            self.logger.error(f\"Error storing episodic memory: {str(e)}\")\n            raise\n\n    async def get_cognitive_memory(\n            self,\n            agent_id: str,\n            limit: int = 10,\n            cognitive_step: Optional[Union[str, List[str]]] = None,\n            metadata_filters: Optional[Dict] = None,\n            start_time: Optional[datetime] = None,\n            end_time: Optional[datetime] = None\n    ) -> List[MemoryObject]:\n        \"\"\"Retrieve cognitive memories based on filters.\"\"\"\n        try:\n            conditions = []\n            params = []\n            cognitive_table = f\"agent_{agent_id}_cognitive\"\n\n            # Build query conditions\n            if cognitive_step:\n                if isinstance(cognitive_step, str):\n                    conditions.append(\"cognitive_step = $\" + str(len(params) + 1))\n                    params.append(cognitive_step)\n                else:\n                    placeholders = \", \".join([f\"${i + 1}\" for i in range(len(params), len(params) + len(cognitive_step))])\n                    conditions.append(f\"cognitive_step IN ({placeholders})\")\n                    params.extend(cognitive_step)\n\n            if metadata_filters:\n                for k, v in metadata_filters.items():\n                    conditions.append(f\"metadata->>{k} = ${len(params) + 1}\")\n                    params.append(str(v))\n\n            if start_time:\n                conditions.append(f\"created_at >= ${len(params) + 1}\")\n                params.append(start_time)\n\n            if end_time:\n                conditions.append(f\"created_at <= ${len(params) + 1}\")\n                params.append(end_time)\n\n            where_clause = \" AND \".join(conditions) if conditions else \"TRUE\"\n            params.append(limit)\n\n            query = f\"\"\"\n                WITH recent_memories AS (\n                    SELECT \n                        memory_id::text,\n                        cognitive_step,\n                        content,\n                        embedding, \n                        created_at, \n                        metadata\n                    FROM {cognitive_table}\n                    WHERE {where_clause}\n                    ORDER BY created_at DESC\n                    LIMIT ${len(params)}\n                )\n                SELECT * FROM recent_memories\n                ORDER BY created_at ASC;\n            \"\"\"\n\n            rows = await self.db.fetch(query, *params)\n            \n            items = []\n            for row in rows:\n                mem_id, step, content, embedding, created_at, meta = row\n                \n                # Parse embedding if it's a string\n                if isinstance(embedding, str):\n                    embedding = [float(x) for x in embedding.strip('[]').split(',')]\n\n                # Parse metadata if it's a string\n                if isinstance(meta, str):\n                    try:\n                        metadata = json.loads(meta)\n                    except json.JSONDecodeError:\n                        metadata = {}\n                else:\n                    metadata = meta if meta else {}\n\n                # Create MemoryObject instance\n                mo = MemoryObject(\n                    memory_id=UUID(mem_id),\n                    agent_id=agent_id,\n                    cognitive_step=step,\n                    content=content,\n                    embedding=embedding,\n                    created_at=created_at,\n                    metadata=metadata\n                )\n                items.append(mo)\n            return items\n\n        except Exception as e:\n            self.logger.error(f\"Error retrieving cognitive memory: {str(e)}\")\n            raise\n\n    async def get_episodic_memory(\n            self,\n            agent_id: str,\n            limit: int = 5,\n            metadata_filters: Optional[Dict] = None,\n            start_time: Optional[datetime] = None,\n            end_time: Optional[datetime] = None\n    ) -> List[EpisodicMemoryObject]:\n        \"\"\"Retrieve episodic memories based on filters.\"\"\"\n        try:\n            episodic_table = f\"agent_{agent_id}_episodic\"\n            conditions = []\n            params = []\n\n            if metadata_filters:\n                for k, v in metadata_filters.items():\n                    conditions.append(f\"metadata->>{k} = ${len(params) + 1}\")\n                    params.append(str(v))\n\n            if start_time:\n                conditions.append(f\"created_at >= ${len(params) + 1}\")\n                params.append(start_time)\n\n            if end_time:\n                conditions.append(f\"created_at <= ${len(params) + 1}\")\n                params.append(end_time)\n\n            where_clause = \" AND \".join(conditions) if conditions else \"TRUE\"\n            params.append(limit)\n\n            query = f\"\"\"\n                SELECT \n                    memory_id, \n                    task_query, \n                    cognitive_steps, \n                    total_reward,\n                    strategy_update, \n                    embedding, \n                    created_at, \n                    metadata\n                FROM {episodic_table}\n                WHERE {where_clause}\n                ORDER BY created_at DESC\n                LIMIT ${len(params)};\n            \"\"\"\n\n            rows = await self.db.fetch(query, *params)\n            episodes = []\n            \n            for row in rows:\n                mem_id, task_query, steps_json, reward, strategy_json, embedding, created_at, meta = row\n\n                # Parse JSON fields\n                steps_list = json.loads(steps_json) if isinstance(steps_json, str) else steps_json or []\n                strategy_list = json.loads(strategy_json) if isinstance(strategy_json, str) else strategy_json or []\n\n                # Parse embedding if it's a string\n                if isinstance(embedding, str):\n                    embedding = [float(x) for x in embedding.strip('[]').split(',')]\n\n                # Convert cognitive steps to CognitiveStep objects\n                csteps = [CognitiveStep(**step) for step in steps_list]\n\n                episode_obj = EpisodicMemoryObject(\n                    memory_id=UUID(mem_id),\n                    agent_id=agent_id,\n                    task_query=task_query,\n                    cognitive_steps=csteps,\n                    total_reward=reward,\n                    strategy_update=strategy_list,\n                    embedding=embedding,\n                    created_at=created_at,\n                    metadata=meta if meta else {}\n                )\n                episodes.append(episode_obj)\n\n            return episodes\n\n        except Exception as e:\n            self.logger.error(f\"Error retrieving episodic memory: {str(e)}\")\n            raise\n\n    async def clear_agent_memory(self, agent_id: str, memory_type: Optional[str] = None) -> int:\n        \"\"\"Clear agent memories of specified type(s).\"\"\"\n        try:\n            deleted_count = 0\n            if memory_type in (None, \"cognitive\"):\n                deleted_count += await self.db.execute(\n                    f\"TRUNCATE TABLE agent_{agent_id}_cognitive;\"\n                )\n            if memory_type in (None, \"episodic\"):\n                deleted_count += await self.db.execute(\n                    f\"TRUNCATE TABLE agent_{agent_id}_episodic;\"\n                )\n            return deleted_count\n        except Exception as e:\n            self.logger.error(f\"Error clearing agent memory: {str(e)}\")\n            raise\n\n    # Knowledge base methods...\n    async def ingest_knowledge(self, text: str, metadata: Optional[Dict] = None, table_prefix: str = \"default\") -> UUID:\n        \"\"\"Ingest knowledge into the specified knowledge base.\"\"\"\n        try:\n            self.logger.debug(\"Starting knowledge ingestion...\")\n            # Get chunks\n            chunks = self._chunk_text(text)\n            chunk_texts = [c.text for c in chunks]\n            \n            # Get embeddings in batches and assign to chunks\n            all_embeddings = []\n            all_embeddings = await self.embedder.get_embeddings(chunk_texts)\n\n            for chunk, embedding in zip(chunks, all_embeddings):\n                chunk.embedding = embedding\n\n            knowledge_id = uuid.uuid4()\n\n            # Use a transaction for database operations\n            async with self.db.safe_transaction() as conn:\n                # Insert knowledge object\n                await conn.execute(\n                    f\"\"\"\n                    INSERT INTO {table_prefix}_knowledge_objects \n                    (knowledge_id, content, metadata)\n                    VALUES ($1, $2, $3)\n                    \"\"\",\n                    str(knowledge_id),\n                    text,\n                    json.dumps(metadata or {})\n                )\n\n                # Insert chunks with their embeddings\n                for chunk in chunks:\n                    # Convert embedding list to PostgreSQL vector format\n                    vector_str = f\"[{','.join(map(str, chunk.embedding))}]\"\n                    await conn.execute(\n                        f\"\"\"\n                        INSERT INTO {table_prefix}_knowledge_chunks\n                        (knowledge_id, text, start_pos, end_pos, embedding)\n                        VALUES ($1, $2, $3, $4, $5::vector)\n                        \"\"\",\n                        str(knowledge_id),\n                        chunk.text,\n                        chunk.start,\n                        chunk.end,\n                        vector_str\n                    )\n\n            return knowledge_id\n        except Exception as e:\n            self.logger.error(f\"Error in ingest_knowledge: {str(e)}\", exc_info=True)\n            raise\n    \n    def _chunk_text(self, text: str) -> List[KnowledgeChunk]:\n        \"\"\"Internal method to chunk text using configured chunking method.\"\"\"\n        chunker = SemanticChunker(\n            min_size=self.config.min_chunk_size,\n            max_size=self.config.max_chunk_size\n        )\n        result = chunker.chunk(text)\n        return result\n\n    async def search_knowledge(\n            self,\n            query: str,\n            table_prefix: str = \"default\",\n            top_k: int = 5\n    ) -> List[RetrievedMemory]:\n        \"\"\"Search knowledge base using semantic similarity.\"\"\"\n        try:\n            # Get query embedding\n            query_embedding = await self.embedder.get_embeddings(query)\n            vector_str = f\"[{','.join(map(str, query_embedding))}]\"\n\n            chunks_table = f\"{table_prefix}_knowledge_chunks\"\n            objects_table = f\"{table_prefix}_knowledge_objects\"\n\n            rows = await self.db.fetch(f\"\"\"\n                WITH ranked_chunks AS (\n                    SELECT DISTINCT ON (c.text)\n                        c.text, \n                        c.start_pos, \n                        c.end_pos, \n                        k.content,\n                        (1 - (c.embedding <=> $1::vector)) AS similarity\n                    FROM {chunks_table} c\n                    JOIN {objects_table} k ON c.knowledge_id = k.knowledge_id\n                    WHERE (1 - (c.embedding <=> $1::vector)) >= $2\n                    ORDER BY c.text, similarity DESC\n                )\n                SELECT * FROM ranked_chunks\n                ORDER BY similarity DESC\n                LIMIT $3;\n            \"\"\", vector_str, self.config.similarity_threshold, top_k)\n\n            results = []\n            for row in rows:\n                # Create RetrievedMemory object with proper fields\n                retrieved = RetrievedMemory(\n                    text=row['text'],\n                    similarity=float(row['similarity']),\n                    context=self._get_context(row['start_pos'], row['end_pos'], row['content'])\n                )\n                results.append(retrieved)\n\n            return results\n\n        except Exception as e:\n            self.logger.error(f\"Error searching knowledge base: {str(e)}\")\n            raise\n\n    async def search_cognitive_memory(\n            self,\n            query: str,\n            agent_id: str,\n            top_k: int = 5\n    ) -> List[RetrievedMemory]:\n        query_embedding = self.embedding_service.get_embeddings(query)\n        top_k = top_k or self.config.top_k\n\n        safe_id = self.db._sanitize_table_name(agent_id)\n        agent_cognitive_table = f\"agent_{safe_id}_cognitive\"\n\n        rows = await self.db.fetch(f\"\"\"\n            SELECT content,\n                   (1 - (embedding <=> %s::vector)) AS similarity\n            FROM {agent_cognitive_table}\n            ORDER BY similarity DESC\n            LIMIT %s;\n        \"\"\", query_embedding, top_k)\n\n        results = []\n        for row in rows:\n            content, sim = row\n            results.append(RetrievedMemory(text=content, similarity=sim))\n        return results\n\n    async def search_episodic_memory(\n        self,\n        agent_id: str,\n        query: str,\n        top_k: int = 5\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Search episodic memory (vector/embedding mode).\"\"\"\n        try:\n            # Get query embedding first\n            query_embedding = await self.embedder.get_embeddings(query)\n            \n            # Format the embedding vector for PostgreSQL\n            vector_str = f\"[{','.join(map(str, query_embedding))}]\"\n            \n            safe_id = self.db._sanitize_table_name(agent_id)\n            episodic_table = f\"agent_{safe_id}_episodic\"\n\n            # Use the vector_str in the query\n            results = await self.db.fetch(f\"\"\"\n                SELECT \n                    memory_id,\n                    task_query,\n                    cognitive_steps,\n                    total_reward,\n                    strategy_update,\n                    metadata,\n                    created_at,\n                    (1 - (embedding <=> $1::vector)) as similarity\n                FROM {episodic_table}\n                WHERE (1 - (embedding <=> $1::vector)) > $2\n                ORDER BY similarity DESC\n                LIMIT $3;\n            \"\"\", vector_str, self.config.similarity_threshold, top_k)\n\n            return [\n                {\n                    \"text\": json.dumps({\n                        \"memory_id\": str(row[\"memory_id\"]),\n                        \"task_query\": row[\"task_query\"],\n                        \"cognitive_steps\": row[\"cognitive_steps\"],\n                        \"total_reward\": row[\"total_reward\"],\n                        \"strategy_update\": row[\"strategy_update\"],\n                        \"metadata\": row[\"metadata\"],\n                        \"created_at\": row[\"created_at\"].isoformat()\n                    }),\n                    \"similarity\": float(row[\"similarity\"])\n                }\n                for row in results\n            ]\n\n        except Exception as e:\n            self.logger.error(f\"Error searching episodic memory: {str(e)}\")\n            raise\n\n\n    async def delete_knowledge(\n            self,\n            knowledge_id: UUID,\n            table_prefix: Optional[str] = None\n    ) -> bool:\n        \"\"\"\n        Delete a knowledge entry and its associated chunks.\n        Returns True if successful.\n        \"\"\"\n        try:\n            prefix = table_prefix or \"default\"\n            chunks_table = f\"{prefix}_knowledge_chunks\"\n            objects_table = f\"{prefix}_knowledge_objects\"\n\n            async with self.db.safe_transaction() as conn:\n                await conn.execute(\n                    f\"DELETE FROM {chunks_table} WHERE knowledge_id = $1\",\n                    str(knowledge_id)\n                )\n\n                # Delete the main knowledge object\n                result = await conn.execute(\n                    f\"DELETE FROM {objects_table} WHERE knowledge_id = $1\",\n                    str(knowledge_id)\n                )\n\n                return result == \"DELETE 1\"\n        except Exception as e:\n            self.logger.error(f\"Error deleting knowledge: {str(e)}\")\n            raise\n\n    def _build_memory_query(self, table: str, conditions: List[str], params: List[Any], limit: int) -> str:\n        \"\"\"Helper to build memory query with conditions.\"\"\"\n        where_clause = \" AND \".join(conditions) if conditions else \"TRUE\"\n        return f\"\"\"\n            WITH recent_memories AS (\n                SELECT *\n                FROM {table}\n                WHERE {where_clause}\n                ORDER BY created_at DESC\n                LIMIT ${len(params) + 1}\n            )\n            SELECT * FROM recent_memories\n            ORDER BY created_at ASC;\n        \"\"\"\n\n    def _build_memory_object(self, row: Dict[str, Any], agent_id: str) -> MemoryObject:\n        \"\"\"Convert a database row to a MemoryObject.\"\"\"\n        try:\n            memory_id = UUID(row[\"memory_id\"])\n            cognitive_step = row[\"cognitive_step\"]\n            content = row[\"content\"]\n            embedding = row[\"embedding\"]\n            created_at = row[\"created_at\"]\n            metadata = json.loads(row[\"metadata\"]) if row[\"metadata\"] else {}\n\n            return MemoryObject(\n                memory_id=memory_id,\n                agent_id=agent_id,\n                cognitive_step=cognitive_step,\n                content=content,\n                embedding=embedding,\n                created_at=created_at,\n                metadata=metadata\n            )\n        except KeyError as e:\n            self.logger.error(f\"Missing expected column in cognitive memory row: {e}\")\n            raise\n        except Exception as e:\n            self.logger.error(f\"Error building MemoryObject: {str(e)}\")\n            raise\n\n    def _build_episodic_object(self, row: Dict[str, Any], agent_id: str) -> EpisodicMemoryObject:\n        \"\"\"Convert a database row to an EpisodicMemoryObject.\"\"\"\n        try:\n            memory_id = UUID(row[\"memory_id\"])\n            task_query = row[\"task_query\"]\n            cognitive_steps = json.loads(row[\"cognitive_steps\"])\n            total_reward = row[\"total_reward\"]\n            strategy_update = json.loads(row[\"strategy_update\"]) if row[\"strategy_update\"] else []\n            embedding = row[\"embedding\"]\n            created_at = row[\"created_at\"]\n            metadata = json.loads(row[\"metadata\"]) if row[\"metadata\"] else {}\n\n            # Construct and return the EpisodicMemoryObject\n            return EpisodicMemoryObject(\n                memory_id=memory_id,\n                agent_id=agent_id,\n                task_query=task_query,\n                cognitive_steps=cognitive_steps,\n                total_reward=total_reward,\n                strategy_update=strategy_update,\n                embedding=embedding,\n                created_at=created_at,\n                metadata=metadata\n            )\n        except KeyError as e:\n            self.logger.error(f\"Missing expected column in episodic memory row: {e}\")\n            raise\n        except Exception as e:\n            self.logger.error(f\"Error building EpisodicMemoryObject: {str(e)}\")\n            raise\n\n    def _get_context(self, start: int, end: int, full_text: str) -> str:\n        \"\"\"\n        Extracts context around a specific text chunk within a full document.\n        \"\"\"\n        start_idx = max(0, start - self.config.max_input)\n        end_idx = min(len(full_text), end + self.config.max_input)\n        context = full_text[start_idx:end_idx].strip()\n        if start_idx > 0:\n            context = \"...\" + context\n        if end_idx < len(full_text):\n            context = context + \"...\"\n        return context\n\n    def uuid_encoder(self, obj):\n        \"\"\"JSON encoder function for handling UUIDs and datetimes.\"\"\"\n        if isinstance(obj, UUID):\n            return str(obj)\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        raise TypeError(f'Object of type {type(obj)} is not JSON serializable')\n\n    async def store_ai_requests(self, requests: List[Dict[str, Any]]):\n        \"\"\"Store AI requests in the database.\"\"\"\n        try:\n            values = []\n            self.logger.info(f\"Processing {len(requests)} requests\")\n            \n            for req in requests:\n                try:\n                    self.logger.debug(f\"Processing request: {req}\")\n                    \n                    chat_thread = req.get('chat_thread')\n                    if not chat_thread:\n                        self.logger.warning(\"Skipping request - no chat thread found\")\n                        continue\n                        \n                    output = req.get('output')\n                    if not output:\n                        self.logger.warning(\"Skipping request - no output found\")\n                        continue\n                        \n                    timestamp = req.get('timestamp', time.time())\n\n                    # Generate new unique request ID\n                    request_id = str(uuid.uuid4())\n                    self.logger.info(f\"Generated new request ID: {request_id} for chat thread: {chat_thread.id}\")\n\n                    messages = []\n                    #if chat_thread.system_prompt:\n                    #    messages.append({\n                    #        'role': 'system',\n                    #        'content': chat_thread.system_prompt.content\n                    #    })\n                    #for msg in chat_thread.messages:\n                    #    if isinstance(msg, dict):\n                    #        messages.append(msg)\n                    #    else:\n                    #        messages.append({\n                    #            'role': msg.role,\n                    #            'content': msg.content\n                    #        })\n                    #if chat_thread.new_message:\n                    #    messages.append({\n                    #        'role': 'user',\n                    #        'content': chat_thread.new_message\n                    #    })\n#\n                    response = output.raw_output.raw_result if output and output.raw_output else None\n                    \n                    request_data = (\n                        request_id,\n                        str(chat_thread.id),\n                        json.dumps(chat_thread.messages, default=self.uuid_encoder),\n                        json.dumps(response, default=self.uuid_encoder),\n                        json.dumps({\n                            'chat_thread_id': str(chat_thread.id),\n                            'model': chat_thread.llm_config.model if chat_thread.llm_config else None,\n                            'client': chat_thread.llm_config.client if chat_thread.llm_config else None,\n                            'start_time': output.raw_output.start_time if output and output.raw_output else None,\n                            'end_time': output.raw_output.end_time if output and output.raw_output else None,\n                            'completion_kwargs': chat_thread.llm_config.model_dump() if chat_thread.llm_config else None,\n                            'usage': response.get('usage') if response else None\n                        }, default=self.uuid_encoder),\n                        datetime.fromtimestamp(timestamp, tz=timezone.utc)\n                    )\n                    values.append(request_data)\n                    self.logger.debug(f\"Successfully processed request ID: {request_id} for chat thread: {chat_thread.id}\")\n                    \n                except Exception as e:\n                    self.logger.error(f\"Error processing request: {e}\")\n                    self.logger.error(f\"Problematic request: {req}\")\n                    continue\n\n            if not values:\n                self.logger.warning(\"No valid requests to insert\")\n                return\n\n            self.logger.info(f\"Attempting to store {len(values)} AI requests\")\n            async with self.db.safe_transaction() as conn:\n                await conn.executemany(\"\"\"\n                    INSERT INTO ai_requests \n                    (request_id, agent_id, prompt, response, metadata, created_at)\n                    VALUES ($1, $2, $3, $4, $5, $6)\n                \"\"\", values)\n                self.logger.info(f\"Successfully stored {len(values)} AI requests\")\n\n        except Exception as e:\n            self.logger.error(f\"Failed to store AI requests: {e}\")\n            self.logger.error(f\"Request data sample: {requests[0] if requests else None}\")\n            raise"}
{"type": "source_file", "path": "market_agents/memory/agent_storage/agent_storage_api.py", "content": "import asyncio\nfrom fastapi import APIRouter, Depends, FastAPI, HTTPException\nfrom contextlib import asynccontextmanager\nimport uvicorn\nfrom typing import Optional\nfrom uuid import UUID\nimport logging\n\nfrom market_agents.memory.agent_storage.storage_service import StorageService\nfrom market_agents.memory.storage_models import (\n    MemoryObject,\n    EpisodicMemoryObject,\n    CognitiveMemoryParams,\n    EpisodicMemoryParams,\n    KnowledgeQueryParams,\n    IngestKnowledgeRequest,\n    CreateTablesRequest\n)\n\n\nclass AgentStorageAPI:\n    def __init__(self, storage_service: StorageService):\n        self.router = APIRouter()\n        self.storage_service = storage_service\n        self.logger = logging.getLogger(\"agent_storage_api\")\n        self._register_routes()\n\n    def _register_routes(self):\n        @self.router.get(\"/health\")\n        async def health_check():\n            \"\"\"Check API health status.\"\"\"\n            try:\n                # First check if database is initialized\n                if not self.storage_service.db.pool:\n                    raise HTTPException(\n                        status_code=503,\n                        detail=\"Database not initialized\"\n                    )\n                \n                # Then check connection\n                is_connected = await self.storage_service.db.is_connected()\n                if not is_connected:\n                    raise HTTPException(\n                        status_code=503,\n                        detail=\"Database connection failed\"\n                    )\n                return {\"status\": \"healthy\", \"database\": \"connected\"}\n            except HTTPException:\n                raise\n            except Exception as e:\n                self.logger.error(f\"Health check failed: {str(e)}\")\n                raise HTTPException(\n                    status_code=503,\n                    detail=f\"Service unhealthy: {str(e)}\"\n                )\n\n        @self.router.post(\"/memory/cognitive\")\n        async def store_cognitive_memory(memory: MemoryObject):\n            \"\"\"Store a single-step (cognitive) memory item.\"\"\"\n            try:\n                created_at = await self.storage_service.store_cognitive_memory(memory)\n                return {\"status\": \"success\", \"created_at\": created_at}\n            except Exception as e:\n                self.logger.error(f\"Error storing cognitive memory: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.post(\"/memory/episodic\")\n        async def store_episodic_memory(episode: EpisodicMemoryObject):\n            \"\"\"Store an entire (episodic) memory.\"\"\"\n            try:\n                await self.storage_service.store_episodic_memory(episode)\n                return {\"status\": \"success\"}\n            except Exception as e:\n                self.logger.error(f\"Error storing episodic memory: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.get(\"/memory/cognitive/sql/{agent_id}\")\n        async def get_cognitive_memory_sql(\n            agent_id: str,\n            params: CognitiveMemoryParams = Depends()\n        ):\n            \"\"\"\n            Retrieve cognitive memories (SQL/relational mode) for an agent,\n            using time range, metadata filters, etc.\n            \"\"\"\n            try:\n                memories = await self.storage_service.get_cognitive_memory(\n                    agent_id=agent_id,\n                    limit=params.limit,\n                    cognitive_step=params.cognitive_step,\n                    metadata_filters=params.metadata_filters,\n                    start_time=params.start_time,\n                    end_time=params.end_time\n                )\n                return {\"memories\": [mem.model_dump() for mem in memories]}\n            except Exception as e:\n                self.logger.error(f\"Error retrieving cognitive memory: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.get(\"/memory/episodic/sql/{agent_id}\")\n        async def get_episodic_memory_sql(\n            agent_id: str,\n            params: EpisodicMemoryParams = Depends()\n        ):\n            \"\"\"\n            Retrieve episodic memories (SQL/relational mode) for an agent,\n            using time range, metadata filters, etc.\n            \"\"\"\n            try:\n                episodes = await self.storage_service.get_episodic_memory(\n                    agent_id=agent_id,\n                    limit=params.limit,\n                    metadata_filters=params.metadata_filters,\n                    start_time=params.start_time,\n                    end_time=params.end_time\n                )\n                return {\"episodes\": [ep.model_dump() for ep in episodes]}\n            except Exception as e:\n                self.logger.error(f\"Error retrieving episodic memory: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.get(\"/memory/cognitive/vector/{agent_id}\")\n        async def search_cognitive_memory_vector(\n            agent_id: str,\n            query: str,\n            top_k: int = 5\n        ):\n            \"\"\"Search cognitive memory (vector/embedding mode).\"\"\"\n            try:\n                results = await self.storage_service.search_cognitive_memory(\n                    agent_id=agent_id,\n                    top_k=top_k,\n                    query=query\n                )\n                return {\"matches\": results}\n            except Exception as e:\n                self.logger.error(f\"Error searching cognitive memory: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.get(\"/memory/episodic/vector/{agent_id}\")\n        async def search_episodic_memory_vector(\n            agent_id: str,\n            query: str,\n            top_k: int = 5\n        ):\n            \"\"\"Search episodic memory (vector/embedding mode).\"\"\"\n            try:\n                results = await self.storage_service.search_episodic_memory(\n                    agent_id=agent_id,\n                    query=query,\n                    top_k=top_k\n                )\n                return {\"matches\": results}\n            except Exception as e:\n                self.logger.error(f\"Error searching episodic memory: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.delete(\"/memory/{agent_id}\")\n        async def clear_agent_memory(\n            agent_id: str,\n            memory_type: Optional[str] = None\n        ):\n            \"\"\"Clear agent's memory of specified type (cognitive/episodic).\"\"\"\n            try:\n                deleted_count = await self.storage_service.clear_agent_memory(\n                    agent_id=agent_id,\n                    memory_type=memory_type\n                )\n                return {\n                    \"status\": \"success\",\n                    \"agent_id\": agent_id,\n                    \"memory_type\": memory_type or \"all\",\n                    \"deleted_count\": deleted_count\n                }\n            except Exception as e:\n                self.logger.error(f\"Error clearing agent memory: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.post(\"/knowledge/ingest\")\n        async def ingest_knowledge(request: IngestKnowledgeRequest):\n            \"\"\"Ingest text into the knowledge base.\"\"\"\n            try:\n                knowledge_id = await self.storage_service.ingest_knowledge(\n                    text=request.text,\n                    metadata=request.metadata,\n                    table_prefix=request.table_prefix or \"default\"\n                )\n                return {\n                    \"status\": \"success\",\n                    \"knowledge_id\": knowledge_id\n                }\n            except Exception as e:\n                self.logger.error(f\"Error ingesting knowledge: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.get(\"/knowledge/search\")\n        async def search_knowledge(params: KnowledgeQueryParams = Depends()):\n            \"\"\"Search the knowledge base using semantic similarity.\"\"\"\n            try:\n                results = await self.storage_service.search_knowledge(\n                    query=params.query,\n                    top_k=params.top_k,\n                    table_prefix=params.table_prefix\n                )\n                return {\"matches\": results}\n            except Exception as e:\n                self.logger.error(f\"Error searching knowledge base: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.delete(\"/knowledge/{knowledge_id}\")\n        async def delete_knowledge(\n            knowledge_id: UUID,\n            table_prefix: Optional[str] = None\n        ):\n            \"\"\"Delete a specific knowledge entry and its chunks.\"\"\"\n            try:\n                deleted = await self.storage_service.delete_knowledge(\n                    knowledge_id=knowledge_id,\n                    table_prefix=table_prefix or \"default\"\n                )\n                return {\n                    \"status\": \"success\",\n                    \"knowledge_id\": knowledge_id,\n                    \"deleted\": deleted\n                }\n            except Exception as e:\n                self.logger.error(f\"Error deleting knowledge: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self.router.post(\"/tables/create\")\n        async def create_tables(request: CreateTablesRequest):\n            \"\"\"Create database tables.\"\"\"\n            try:\n                if request.table_type in [\"cognitive\", \"episodic\"] and not request.agent_id:\n                    raise HTTPException(\n                        status_code=400,\n                        detail=f\"agent_id is required for {request.table_type} tables\"\n                    )\n                if request.table_type == \"knowledge\" and not request.table_prefix:\n                    raise HTTPException(\n                        status_code=400,\n                        detail=\"table_prefix is required for knowledge tables\"\n                    )\n\n                self.logger.info(f\"Creating tables with params: {request.model_dump()}\")\n                \n                await self.storage_service.create_tables(\n                    table_type=request.table_type,\n                    agent_id=request.agent_id,\n                    table_prefix=request.table_prefix\n                )\n                \n                return {\n                    \"status\": \"success\",\n                    \"table_type\": request.table_type,\n                    \"agent_id\": request.agent_id,\n                    \"table_prefix\": request.table_prefix\n                }\n            except Exception as e:\n                self.logger.error(f\"Error creating tables: {str(e)}\")\n                raise HTTPException(status_code=500, detail=str(e))\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Lifespan context manager for database connection.\"\"\"\n    # Startup: initialize database\n    try:\n        await app.state.storage_service.db.initialize()\n    except Exception as e:\n        raise\n    yield\n    # Shutdown: cleanup\n    await app.state.storage_service.db.close()\n\n\ndef create_app(storage_service: StorageService) -> FastAPI:\n    app = FastAPI(\n        title=\"Agent Storage API\",\n        lifespan=lifespan\n    )\n\n    app.state.storage_service = storage_service\n    api = AgentStorageAPI(storage_service)\n    app.include_router(api.router)\n\n    return app\n\n\nif __name__ == \"__main__\":\n    from market_agents.memory.embedding import MemoryEmbedder\n    from market_agents.memory.config import load_config_from_yaml\n    from market_agents.memory.agent_storage.setup_db import AsyncDatabase\n    from pathlib import Path\n\n    # Load config\n    config_path = Path(__file__).parent.parent / \"storage_config.yaml\"\n    config = load_config_from_yaml(str(config_path))\n\n    # Initialize embedding service\n    embedding_service = MemoryEmbedder(config)\n\n    # Create database instance (but don't initialize connection yet)\n    db = AsyncDatabase(config)\n\n    # Initialize storage service\n    storage_service = StorageService(\n        db=db,\n        embedding_service=embedding_service,\n        config=config\n    )\n\n    app = create_app(storage_service)\n    uvicorn.run(\n        app,\n        host=\"0.0.0.0\",\n        port=8001,\n        log_level=\"info\"\n    )"}
{"type": "source_file", "path": "market_agents/memory/agent_storage/agent_storage_api_utils.py", "content": "import json\nimport uuid\nimport aiohttp\nimport logging\nfrom uuid import UUID\nfrom datetime import datetime, timezone\nfrom typing import Optional, Dict, Any, List\n\nfrom market_agents.memory.storage_models import (\n    AIRequest,\n    CognitiveMemoryParams,\n    EpisodicMemoryParams,\n    KnowledgeQueryParams,\n    IngestKnowledgeRequest,\n    CreateTablesRequest,\n    EpisodicMemoryObject,\n    MemoryObject\n)\nfrom market_agents.memory.config import AgentStorageConfig, load_config_from_yaml\n\nclass CustomJSONEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, UUID):\n            return str(obj)\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        return super().default(obj)\n\nclass AgentStorageAPIUtils:\n    def __init__(\n        self,\n        config: AgentStorageConfig | str,\n        logger: Optional[logging.Logger] = None\n    ):\n        if isinstance(config, str):\n            self.config = load_config_from_yaml(config)\n        elif isinstance(config, AgentStorageConfig):\n            self.config = config\n        else:\n            raise ValueError(\"config must be either a path or AgentStorageConfig instance\")\n        \n        self.api_url = self.config.storage_api_url\n        self.logger = logger or logging.getLogger(__name__)\n        self.logger.info(f\"Initializing Agent Storage API Utils with URL: {self.api_url}\")\n        self.json_encoder = CustomJSONEncoder\n\n    async def check_api_health(self) -> bool:\n        \"\"\"Check if the Agent Storage API is healthy.\"\"\"\n        try:\n            self.logger.info(f\"Checking Agent Storage API health at {self.api_url}/api/health\")\n            async with aiohttp.ClientSession() as session:\n                async with session.get(f\"{self.api_url}/api/health\", timeout=5) as resp:\n                    if resp.status == 200:\n                        self.logger.info(\"Agent Storage API is healthy\")\n                        return True\n                    else:\n                        self.logger.error(f\"Agent Storage API health check failed: {resp.status}\")\n                        return False\n        except aiohttp.ClientError as e:\n            self.logger.error(f\"Connection error to Agent Storage API: {e}\")\n            return False\n        except Exception as e:\n            self.logger.error(f\"Could not connect to Agent Storage API: {e}\")\n            return False\n\n    async def store_cognitive_memory(self, memory: MemoryObject) -> Dict[str, Any]:\n        try:\n            memory_dict = memory.model_dump(exclude_none=True)\n            async with aiohttp.ClientSession(json_serialize=lambda x: json.dumps(x, cls=self.json_encoder)) as session:\n                async with session.post(\n                    f\"{self.api_url}/memory/cognitive\",\n                    json=memory_dict\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error storing cognitive memory: {e}\")\n            raise\n\n    async def store_episodic_memory(self, episode: EpisodicMemoryObject) -> Dict[str, Any]:\n        try:\n            episode_dict = episode.model_dump(exclude_none=True)\n            async with aiohttp.ClientSession(json_serialize=lambda x: json.dumps(x, cls=self.json_encoder)) as session:\n                async with session.post(\n                    f\"{self.api_url}/memory/episodic\",\n                    json=episode_dict\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error storing episodic memory: {e}\")\n            raise\n\n    async def get_cognitive_memory_sql(\n        self,\n        agent_id: str,\n        params: CognitiveMemoryParams\n    ) -> List[MemoryObject]:\n        \"\"\"Get cognitive memories using SQL query.\"\"\"\n        try:\n            query_params = {\n                \"limit\": params.limit,\n                \"cognitive_step\": params.cognitive_step,\n                \"metadata_filters\": json.dumps(params.metadata_filters) if params.metadata_filters else None,\n                \"start_time\": params.start_time.isoformat() if params.start_time else None,\n                \"end_time\": params.end_time.isoformat() if params.end_time else None\n            }\n            query_params = {k: v for k, v in query_params.items() if v is not None}\n\n            async with aiohttp.ClientSession() as session:\n                async with session.get(\n                    f\"{self.api_url}/memory/cognitive/sql/{agent_id}\",\n                    params=query_params\n                ) as resp:\n                    resp.raise_for_status()\n                    data = await resp.json()\n                    memories_data = data.get(\"memories\", [])\n                    return [MemoryObject.model_validate(mem_dict) for mem_dict in memories_data]\n        except Exception as e:\n            self.logger.error(f\"Error getting cognitive memory: {e}\")\n            raise\n\n    async def get_episodic_memory_sql(self, agent_id: str, params: EpisodicMemoryParams) -> Dict[str, Any]:\n        \"\"\"\n        Calls GET /memory/episodic/sql/{agent_id} for standard SQL retrieval\n        using time range, metadata filters, etc.\n        \"\"\"\n        try:\n            query_params = params.model_dump(exclude_unset=True)\n            # Possibly convert start/end times, metadata here if needed\n            if query_params.get('start_time'):\n                query_params['start_time'] = query_params['start_time'].isoformat()\n            if query_params.get('end_time'):\n                query_params['end_time'] = query_params['end_time'].isoformat()\n            if query_params.get('metadata_filters'):\n                query_params['metadata_filters'] = json.dumps(query_params['metadata_filters'])\n\n            async with aiohttp.ClientSession() as session:\n                async with session.get(\n                    f\"{self.api_url}/memory/episodic/sql/{agent_id}\",\n                    params=query_params\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error retrieving episodic memory (SQL): {e}\")\n            raise\n\n    async def get_cognitive_memory_vector(self, agent_id: str, query: str, top_k: int = 5) -> Dict[str, Any]:\n        \"\"\"Calls GET /memory/cognitive/vector/{agent_id} for embedding-based retrieval.\"\"\"\n        try:\n            params = {\"query\": query, \"top_k\": top_k}\n            async with aiohttp.ClientSession() as session:\n                async with session.get(\n                    f\"{self.api_url}/memory/cognitive/vector/{agent_id}\",\n                    params=params\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error searching cognitive memory (vector): {e}\")\n            raise\n\n    async def get_episodic_memory_vector(self, agent_id: str, query: str, top_k: int = 5) -> Dict[str, Any]:\n        \"\"\"Calls GET /memory/episodic/vector/{agent_id} for embedding-based retrieval.\"\"\"\n        try:\n            params = {\"query\": query, \"top_k\": top_k}\n            async with aiohttp.ClientSession() as session:\n                async with session.get(\n                    f\"{self.api_url}/memory/episodic/vector/{agent_id}\",\n                    params=params\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error searching episodic memory (vector): {e}\")\n            raise\n\n    async def ingest_knowledge(self, request: IngestKnowledgeRequest) -> Dict[str, Any]:\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.api_url}/knowledge/ingest\",\n                    json=request.model_dump()\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error ingesting knowledge: {e}\")\n            raise\n\n    async def search_knowledge(self, params: KnowledgeQueryParams) -> Dict[str, Any]:\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(\n                    f\"{self.api_url}/knowledge/search\",\n                    params=params.model_dump(exclude_unset=True)\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error searching knowledge: {e}\")\n            raise\n\n    async def delete_knowledge(self, knowledge_id: UUID, table_prefix: Optional[str] = None) -> Dict[str, Any]:\n        try:\n            params = {\"table_prefix\": table_prefix}\n            async with aiohttp.ClientSession() as session:\n                async with session.delete(\n                    f\"{self.api_url}/knowledge/{knowledge_id}\",\n                    params=params\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error deleting knowledge: {e}\")\n            raise\n\n    async def create_tables(self, request: CreateTablesRequest) -> Dict[str, Any]:\n        \"\"\"Create database tables.\"\"\"\n        try:\n            payload = request.model_dump()\n            self.logger.info(f\"Sending create tables request with payload: {payload}\")\n            \n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.api_url}/tables/create\",\n                    json=payload\n                ) as resp:\n                    if resp.status != 200:\n                        error_text = await resp.text()\n                        self.logger.error(f\"Failed to create tables. Status: {resp.status}, Response: {error_text}\")\n                        resp.raise_for_status()\n                    return await resp.json()\n        except aiohttp.ClientError as e:\n            self.logger.error(f\"HTTP error creating tables: {str(e)}\")\n            raise\n        except Exception as e:\n            self.logger.error(f\"Error creating tables: {str(e)}\")\n            raise\n\n    async def clear_agent_memory(self, agent_id: str, memory_type: Optional[str] = None) -> Dict[str, Any]:\n        try:\n            params = {\"memory_type\": memory_type}\n            async with aiohttp.ClientSession() as session:\n                async with session.delete(\n                    f\"{self.api_url}/memory/{agent_id}\",\n                    params=params\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error clearing agent memory: {e}\")\n            raise\n    \n    async def store_ai_requests(self, requests: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Store AI requests in the database.\"\"\"\n        try:\n            # Convert requests to AIRequest models\n            ai_requests = [\n                AIRequest(\n                    request_id=req.get('request_id', str(uuid.uuid4())),\n                    agent_id=req.get('agent_id'),\n                    prompt=req.get('prompt', ''),\n                    response=req.get('response'),\n                    metadata=req.get('metadata', {}),\n                    created_at=req.get('created_at', datetime.now(timezone.utc))\n                ) for req in requests\n            ]\n            \n            async with aiohttp.ClientSession(json_serialize=lambda x: json.dumps(x, cls=self.json_encoder)) as session:\n                async with session.post(\n                    f\"{self.api_url}/ai/requests\",\n                    json=[req.model_dump(exclude_none=True) for req in ai_requests]\n                ) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n        except Exception as e:\n            self.logger.error(f\"Error storing AI requests: {e}\")\n            raise\n    "}
{"type": "source_file", "path": "market_agents/memory/embedding.py", "content": "import asyncio\nimport logging\nimport os\nimport aiohttp\nfrom dotenv import load_dotenv\nimport tiktoken\n\n\nclass MemoryEmbedder:\n    \"\"\"\n    MemoryEmbedder embeds given text inputs from a specified embedding model.\n    \"\"\"\n    def __init__(self, config):\n        self.config = config\n        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n        self.max_input = self.config.max_input - 1000\n        logging.info(f\"Initialized MemoryEmbedder with {config.embedding_provider} provider\")\n\n    def _truncate_text(self, text: str) -> str:\n        \"\"\"Truncate text to max_input tokens using tiktoken.\"\"\"\n        tokens = self.encoding.encode(text)\n        if len(tokens) > self.max_input:\n            logging.warning(f\"Text truncated from {len(tokens)} to {self.max_input} tokens\")\n            tokens = tokens[:self.max_input]\n            text = self.encoding.decode(tokens)\n        return text\n\n    async def get_embeddings(self, texts):\n        \"\"\"Get embeddings with retry logic and batch processing.\"\"\"\n        single_input = isinstance(texts, str)\n        texts = [texts] if single_input else texts\n\n        texts = [self._truncate_text(text) for text in texts]\n\n        if self.config.embedding_provider == \"openai\":\n            all_embeddings = await self._get_openai_embeddings(texts)\n        elif self.config.embedding_provider == \"tei\":\n            all_embeddings = await self._get_tei_embeddings(texts)\n        else:\n            raise NotImplementedError(\n                f\"Unknown embedding provider: {self.config.embedding_provider}\"\n            )\n\n        return all_embeddings[0] if single_input else all_embeddings\n\n    async def _get_openai_embeddings(self, texts):\n        print(\"DEBUG: Actually inside the real get_embeddings in MemoryEmbedder:\", self)\n\n        \"\"\"Embeddings from OpenAI API.\"\"\"\n        load_dotenv()\n        self.openai_key = os.getenv(\"OPENAI_KEY\")\n        headers = {\n            \"Authorization\": f\"Bearer {self.openai_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        all_embeddings = []\n\n        for i in range(0, len(texts), self.config.batch_size):\n            batch = texts[i : i + self.config.batch_size]\n            payload = {\n                \"input\": batch,\n                \"model\": self.config.model\n            }\n            response_json = await self._send_embedding_request(payload, headers)\n            batch_embeddings = [item[\"embedding\"] for item in response_json.get(\"data\", [])]\n            all_embeddings.extend(batch_embeddings)\n\n        return all_embeddings\n\n    async def _get_tei_embeddings(self, texts):\n        \"\"\"Embeddings for local embedding model (TEI).\"\"\"\n        headers = {\"Content-Type\": \"application/json\"}\n        all_embeddings = []\n\n        for i in range(0, len(texts), self.config.batch_size):\n            batch = texts[i : i + self.config.batch_size]\n            payload = {\n                \"inputs\": batch,\n                \"model\": self.config.model\n            }\n            response_json = await self._send_embedding_request(payload, headers)\n            all_embeddings.extend(response_json)\n\n        return all_embeddings\n\n    async def _send_embedding_request(self, payload, headers):\n        \"\"\"Sends POST request to the embedding API with retry logic.\"\"\"\n        for attempt in range(self.config.retry_attempts):\n            try:\n                async with aiohttp.ClientSession() as session:\n                    async with session.post(\n                        self.config.embedding_api_url,\n                        headers=headers,\n                        json=payload,\n                        timeout=self.config.timeout\n                    ) as response:\n                        response.raise_for_status()\n                        return await response.json()\n            except Exception as e:\n                if attempt == self.config.retry_attempts - 1:\n                    raise e\n                await asyncio.sleep(self.config.retry_delay)\n\n        raise RuntimeError(\"Unexpected error in _send_embedding_request\")"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/auction.py", "content": "# double_auction.py\n\nfrom datetime import datetime\nimport json\nimport logging\nfrom typing import Any, List, Dict, Union, Type, Optional, Tuple\nfrom pydantic import BaseModel, Field, field_validator\nfrom market_agents.environments.environment import (\n    Mechanism, LocalAction, GlobalAction, LocalObservation, GlobalObservation,\n    EnvironmentStep, ActionSpace, ObservationSpace, MultiAgentEnvironment\n)\nfrom market_agents.economics.econ_models import Bid, Ask, MarketAction, Trade\nimport random\nlogger = logging.getLogger(__name__)\n\nclass MarketSummary(BaseModel):\n    trades_count: int = Field(default=0, description=\"Number of trades executed\")\n    average_price: float = Field(default=0.0, description=\"Average price of trades\")\n    total_volume: int = Field(default=0, description=\"Total volume of trades\")\n    price_range: Tuple[float, float] = Field(default=(0.0, 0.0), description=\"Range of prices\")\n\nclass AuctionAction(LocalAction):\n    action: Union[Bid, Ask]\n\n    @field_validator('action')\n    def validate_quantity(cls, v):\n        if v.quantity != 1:\n            raise ValueError(\"Quantity must be 1\")\n        return v\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'AuctionAction':\n        is_buyer = random.choice([True, False])\n        random_price = random.uniform(0, 100)\n        action = Bid(price=random_price, quantity=1) if is_buyer else Ask(price=random_price, quantity=1)\n        return cls(agent_id=agent_id, action=action)\n    \n    @classmethod\n    def action_schema(cls) -> Dict[str, Any]:\n        return MarketAction.model_json_schema()\n\nclass GlobalAuctionAction(GlobalAction):\n    actions: Dict[str, AuctionAction]\n\nclass AuctionObservation(BaseModel):\n    trades: List[Trade] = Field(default_factory=list, description=\"List of trades the agent participated in\")\n    market_summary: MarketSummary = Field(default_factory=MarketSummary, description=\"Summary of market activity\")\n    waiting_orders: List[Union[Bid, Ask]] = Field(default_factory=list, description=\"List of orders waiting to be executed\")\n\n    def serialize_json(self) -> str:\n        \"\"\"Serialize the observation to JSON string, handling datetime objects\"\"\"\n        return json.dumps(self.model_dump(), default=lambda x: x.isoformat() if isinstance(x, datetime) else x.model_dump() if hasattr(x, 'model_dump') else x)\n\nclass AuctionLocalObservation(LocalObservation):\n    observation: AuctionObservation\n\n    def serialize_json(self) -> str:\n        \"\"\"Serialize the local observation to JSON string\"\"\"\n        return json.dumps({\n            \"agent_id\": self.agent_id,\n            \"observation\": json.loads(self.observation.serialize_json())\n        })\n\nclass AuctionGlobalObservation(GlobalObservation):\n    observations: Dict[str, AuctionLocalObservation]\n    all_trades: List[Trade]\n    market_summary: MarketSummary\n\n    def serialize_json(self) -> str:\n        \"\"\"Serialize the global observation to JSON string\"\"\"\n        return json.dumps({\n            \"observations\": {\n                agent_id: json.loads(obs.serialize_json())\n                for agent_id, obs in self.observations.items()\n            },\n            \"all_trades\": [trade.model_dump() for trade in self.all_trades],\n            \"market_summary\": self.market_summary.model_dump()\n        })\n\n\nclass AuctionActionSpace(ActionSpace):\n    allowed_actions: List[Type[LocalAction]] = [AuctionAction]\n\n    @classmethod\n    def get_action_schema(cls) -> Dict[str, Any]:\n        return MarketAction.model_json_schema()\n\nclass AuctionObservationSpace(ObservationSpace):\n    allowed_observations: List[Type[LocalObservation]] = [AuctionLocalObservation]\n\n\nclass DoubleAuction(Mechanism):\n    max_rounds: int = Field(default=10, description=\"Maximum number of auction rounds\")\n    current_round: int = Field(default=0, description=\"Current round number\")\n    trades: List[Trade] = Field(default_factory=list, description=\"List of executed trades\")\n    waiting_bids: List[AuctionAction] = Field(default_factory=list, description=\"List of waiting bids\")\n    waiting_asks: List[AuctionAction] = Field(default_factory=list, description=\"List of waiting asks\")\n    good_name: str = Field(default=\"apple\", description=\"Name of the good being traded\")\n\n    sequential: bool = Field(default=False, description=\"Whether the mechanism is sequential\")\n\n    def step(self, action: GlobalAuctionAction) -> EnvironmentStep:\n        self.current_round += 1\n        self._update_waiting_orders(action.actions)\n        new_trades = self._match_orders()\n        self.trades.extend(new_trades)\n\n        market_summary = self._create_market_summary(new_trades)\n        observations = self._create_observations(new_trades, market_summary)\n        done = self.current_round >= self.max_rounds\n\n        return EnvironmentStep(\n            global_observation=AuctionGlobalObservation(\n                observations=observations,\n                all_trades=new_trades,\n                market_summary=market_summary\n            ),\n            done=done,\n            info={\"current_round\": self.current_round}\n        )\n\n    def _update_waiting_orders(self, actions: Dict[str, AuctionAction]):\n        for agent_id, auction_action in actions.items():\n            action = auction_action.action\n            if isinstance(action, Bid):\n                # print(f\"Bid from agent {agent_id}: {action}\")\n                self.waiting_bids.append(auction_action)\n            elif isinstance(action, Ask):\n                # print(f\"Ask from agent {agent_id}: {action}\")\n                self.waiting_asks.append(auction_action)\n            else:\n                logger.error(f\"Invalid action type from agent {agent_id}: {type(action)}\")\n\n    def _match_orders(self) -> List[Trade]:\n        trades = []\n        trade_id = len(self.trades)\n\n        # Sort bids and asks\n        self.waiting_bids.sort(key=lambda x: x.action.price, reverse=True)\n        self.waiting_asks.sort(key=lambda x: x.action.price)\n\n        while self.waiting_bids and self.waiting_asks:\n            bid = self.waiting_bids[0]\n            ask = self.waiting_asks[0]\n\n            if bid.action.price >= ask.action.price:\n                trade_price = (bid.action.price + ask.action.price) / 2\n\n                trade = Trade(\n                    trade_id=trade_id,\n                    buyer_id=bid.agent_id,\n                    seller_id=ask.agent_id,\n                    price=trade_price,\n                    quantity=1,\n                    good_name=self.good_name,\n                    bid_price=bid.action.price,\n                    ask_price=ask.action.price\n                )\n                trades.append(trade)\n                trade_id += 1\n\n                # Remove matched bid and ask\n                self.waiting_bids.pop(0)\n                self.waiting_asks.pop(0)\n            else:\n                # No more matches possible\n                break\n\n        return trades\n\n    def _create_observations(self, new_trades: List[Trade], market_summary: MarketSummary) -> Dict[str, AuctionLocalObservation]:\n        observations = {}\n\n        # Agents with trades in this round\n        participant_ids = set([trade.buyer_id for trade in new_trades] + [trade.seller_id for trade in new_trades])\n\n        # Agents with waiting orders\n        waiting_order_agents = set([bid.agent_id for bid in self.waiting_bids] + [ask.agent_id for ask in self.waiting_asks])\n\n        all_agent_ids = participant_ids.union(waiting_order_agents)\n\n        for agent_id in all_agent_ids:\n            agent_trades = [trade for trade in new_trades if trade.buyer_id == agent_id or trade.seller_id == agent_id]\n            agent_waiting_bids = [bid.action for bid in self.waiting_bids if bid.agent_id == agent_id]\n            agent_waiting_asks = [ask.action for ask in self.waiting_asks if ask.agent_id == agent_id]\n            agent_waiting_orders = agent_waiting_bids + agent_waiting_asks\n\n            observation = AuctionObservation(\n                trades=agent_trades,\n                market_summary=market_summary,\n                waiting_orders=agent_waiting_orders\n            )\n\n            observations[agent_id] = AuctionLocalObservation(\n                agent_id=agent_id,\n                observation=observation\n            )\n\n        return observations\n\n    def get_global_state(self) -> Dict[str, Any]:\n        return {\n            \"current_round\": self.current_round,\n            \"trades\": [trade.model_dump() for trade in self.trades],\n            \"waiting_bids\": [{ \"agent_id\": bid.agent_id, **bid.action.model_dump() } for bid in self.waiting_bids],\n            \"waiting_asks\": [{ \"agent_id\": ask.agent_id, **ask.action.model_dump() } for ask in self.waiting_asks]\n        }\n\n    def reset(self) -> None:\n        self.current_round = 0\n        self.trades = []\n        self.waiting_bids = []\n        self.waiting_asks = []\n\n    def _create_market_summary(self, trades: List[Trade]) -> MarketSummary:\n        if not trades:\n            return MarketSummary()\n\n        prices = [trade.price for trade in trades]\n        return MarketSummary(\n            trades_count=len(trades),\n            average_price=sum(prices) / len(prices),\n            total_volume=len(trades),\n            price_range=(min(prices), max(prices))\n        )\n\nclass AuctionMarket(MultiAgentEnvironment):\n    name: str = Field(default=\"Auction Market\", description=\"Name of the auction market\")\n    \n    action_space : AuctionActionSpace = Field(default_factory=AuctionActionSpace, description=\"Action space of the auction market\")\n    observation_space : AuctionObservationSpace = Field(default_factory=AuctionObservationSpace, description=\"Observation space of the auction market\")\n    mechanism : DoubleAuction = Field(default_factory=DoubleAuction, description=\"Mechanism of the auction market\")\n\n"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/chat.py", "content": "from datetime import datetime\nfrom typing import Dict, Any, List, Type\nfrom pydantic import BaseModel, Field\nfrom market_agents.agents.cognitive_schemas import ChainOfThoughtSchema, ThoughtStep\nfrom market_agents.environments.environment import (\n    Mechanism, LocalAction, LocalObservation, ActionSpace, \n    ObservationSpace, MultiAgentEnvironment, LocalEnvironmentStep\n)\n\nclass ChatMessage(BaseModel):\n    content: str\n    timestamp: str\n    role: str = \"user\"\n\nclass ChatAction(LocalAction):\n    \"\"\"Response action for chat using ChainOfThoughtSchema\"\"\"\n    agent_id: str\n    action: ChainOfThoughtSchema = Field(\n        description=\"Response containing thought process and actual response\"\n    )\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'ChatAction':\n        return cls(\n            agent_id=agent_id,\n            action=ChainOfThoughtSchema(\n                thoughts=[ThoughtStep(reasoning=\"Sample thinking\")],\n                final_answer=\"Sample response\"\n            )\n        )\n\nclass ChatObservation(LocalObservation):\n    \"\"\"Message observation for chat\"\"\"\n    agent_id: str\n    observation: ChatMessage\n    chat_history: List[ChatMessage] = Field(default_factory=list)\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'ChatObservation':\n        return cls(\n            agent_id=agent_id,\n            observation=ChatMessage(\n                content=\"Sample message\",\n                timestamp=\"2024-01-01\",\n                role=\"user\"\n            ),\n            chat_history=[]\n        )\n\nclass ChatMechanism(Mechanism):\n    chat_history: List[ChatMessage] = Field(default_factory=list)\n    sequential: bool = Field(default=True)\n    \n    def step(self, action: LocalAction) -> LocalEnvironmentStep:\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        \n        self.chat_history.append(ChatMessage(\n            content=action.action.final_answer,\n            timestamp=timestamp,\n            role=\"assistant\"\n        ))\n        \n        last_user_message = next(\n            (msg for msg in reversed(self.chat_history) \n             if msg.role == \"user\"), \n            ChatMessage(content=\"No user message found\", timestamp=timestamp, role=\"user\")\n        )\n        \n        observation = ChatObservation(\n            agent_id=action.agent_id,\n            observation=last_user_message,\n            chat_history=self.chat_history.copy()\n        )\n        \n        return LocalEnvironmentStep(\n            observation=observation,\n            done=False,\n            info={\"chat_history\": self.chat_history}\n        )\n\n    def get_global_state(self) -> List[ChatMessage]:\n        return self.chat_history\n\n    def add_user_message(self, content: str):\n        \"\"\"Add a user message to the chat history\"\"\"\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        self.chat_history.append(ChatMessage(\n            content=content,\n            timestamp=timestamp,\n            role=\"user\"\n        ))\n\nclass ChatActionSpace(ActionSpace):\n    allowed_actions: List[Type[LocalAction]] = [ChatAction]\n\nclass ChatObservationSpace(ObservationSpace):\n    allowed_observations: List[Type[LocalObservation]] = [ChatObservation]\n\nclass ChatEnvironment(MultiAgentEnvironment):\n    name: str = \"chat_environment\"\n    action_space: ActionSpace = Field(default_factory=ChatActionSpace)\n    observation_space: ObservationSpace = Field(default_factory=ChatObservationSpace)\n    mechanism: Mechanism = Field(default_factory=ChatMechanism)"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/research.py", "content": "# research.py\n\nfrom datetime import datetime\nfrom importlib import import_module\nimport json\nimport random\nfrom typing import Any, Dict, List, Optional, Type, Union\nfrom pydantic import BaseModel, Field\nfrom pydantic_settings import SettingsConfigDict\n\nfrom market_agents.environments.config import EnvironmentConfig\nfrom market_agents.environments.environment import (\n    EnvironmentHistory,\n    Mechanism,\n    LocalAction,\n    GlobalAction,\n    LocalObservation,\n    GlobalObservation,\n    EnvironmentStep,\n    ActionSpace,\n    ObservationSpace,\n    MultiAgentEnvironment,\n    LocalEnvironmentStep,\n)\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass ResearchEnvironmentConfig(EnvironmentConfig):\n    \"\"\"Configuration for research environment orchestration\"\"\"\n    name: str = Field(\n        default=\"research\",\n        description=\"Name of the research environment\"\n    )\n    api_url: str = Field(\n        default=\"http://localhost:8003\",\n        description=\"API endpoint for research environment\"\n    )\n    sub_rounds: int = Field(\n        default=2,\n        description=\"Number of sub-rounds within each main round\"\n    )\n    initial_topic: str = Field(\n        default=\"Market Analysis\",\n        description=\"Initial research topic\"\n    )\n    group_size: int = Field(\n        default=4,\n        description=\"Number of agents in research group\"\n    )\n    schema_model: str = Field(\n        default=\"LiteraryAnalysis\",\n        description=\"Name of Pydantic model defining research output schema\"\n    )\n    form_cohorts: bool = Field(\n        default=False,\n        description=\"Whether to organize agents into cohorts\"\n    )\n\n    model_config = SettingsConfigDict(\n        extra=\"allow\"\n    )\n\nclass ResearchAction(LocalAction):\n    action: BaseModel\n\n    @classmethod\n    def sample(cls, agent_id: str, summary_model: Type[BaseModel]) -> 'ResearchAction':\n        demo_instance = summary_model.construct()\n        return cls(agent_id=agent_id, action=demo_instance)\n\n\nclass ResearchGlobalAction(GlobalAction):\n    \"\"\"Global container of local ResearchActions for each agent.\"\"\"\n    actions: Dict[str, ResearchAction]\n\n\nclass ResearchObservation(BaseModel):\n    \"\"\"Individual observation containing research summary data\"\"\"\n    current_topic: str = \"\"\n    own_summary: Optional[BaseModel] = None\n    aggregator_notes: str = \"\"\n\n    def dict(self, *args, **kwargs):\n        \"\"\"Custom dict method to handle BaseModel serialization\"\"\"\n        d = super().dict(*args, **kwargs)\n        if self.own_summary:\n            d['own_summary'] = self.own_summary.dict()\n        return d\n\n\nclass ResearchLocalObservation(LocalObservation):\n    \"\"\"Local observation for a specific agent\"\"\"\n    agent_id: str\n    observation: ResearchObservation\n\n    def dict(self, *args, **kwargs):\n        \"\"\"Custom dict method to handle nested observation\"\"\"\n        d = super().dict(*args, **kwargs)\n        if self.observation:\n            d['observation'] = self.observation.dict()\n        return d\n\n\nclass ResearchGlobalObservation(GlobalObservation):\n    \"\"\"Global observation containing all agent observations\"\"\"\n    observations: Dict[str, ResearchLocalObservation]\n    all_actions_this_round: Optional[Dict[str, Any]] = None\n    final_all_summaries: Optional[List[Dict[str, Any]]] = None\n    current_topic: str = \"\"\n    aggregator_notes: str = \"\"\n\n    def dict(self, *args, **kwargs):\n        \"\"\"Custom dict method to handle nested observations\"\"\"\n        d = super().dict(*args, **kwargs)\n        if self.observations:\n            d['observations'] = {\n                k: v.dict() for k, v in self.observations.items()\n            }\n        return d\n\n    @property\n    def global_obs(self) -> Optional[Any]:\n        \"\"\"Get the global observation for all agents.\"\"\"\n        return {\n            'all_actions_this_round': self.all_actions_this_round,\n            'final_all_summaries': self.final_all_summaries,\n            'aggregator_notes': self.aggregator_notes\n        }\n    \nclass ResearchActionSpace(ActionSpace):\n    allowed_actions: List[Type[LocalAction]] = [ResearchAction]\n    summary_model: Type[BaseModel]\n\n    def get_action_schema(self) -> Dict[str, Any]:\n        \"\"\"\n        Return JSON schema for whichever summary_model is used.\n        \"\"\"\n        return self.summary_model.model_json_schema()\n\n    def sample(self, agent_id: str) -> LocalAction:\n        \"\"\"\n        For debugging or random testing; create a sample instance of the\n        user-defined summary model.\n        \"\"\"\n        return ResearchAction.sample(agent_id, self.summary_model)\n\n\nclass ResearchObservationSpace(ObservationSpace):\n    \"\"\"\n    Observations revolve around local/global research data.\n    \"\"\"\n    allowed_observations: List[Type[LocalObservation]] = [ResearchLocalObservation]\n\n\nclass ResearchMechanism(Mechanism):\n    \"\"\"Mechanism that manages research rounds and agent summaries.\"\"\"\n    sequential: bool = Field(\n        default=False,\n        description=\"Whether the mechanism is sequential (one agent at a time).\"\n    )\n    current_round: int = Field(\n        default=0, \n        description=\"Current step or round.\"\n    )\n    max_rounds: int = Field(\n        default=0,\n        description=\"Max steps or rounds\"\n    )\n    current_topic: str = Field(\n        default=\"\", \n        description=\"Current research topic\"\n    )\n    round_summaries: Dict[str, List[Dict[str, Any]]] = Field(\n        default_factory=dict,\n        description=\"History of all round summaries, organized by cohort when form_cohorts=True\"\n    )\n    last_step: Optional[EnvironmentStep] = Field(\n        default=None, \n        description=\"Last environment step\"\n    )\n    summary_model: Type[BaseModel] = Field(\n        default=BaseModel, \n        description=\"Model for validating research summaries\"\n    )\n    form_cohorts: bool = Field(\n        default=False,\n        description=\"Whether to organize agents into cohorts\"\n    )\n    group_size: Optional[int] = Field(\n        default=None,\n        description=\"Size of research cohorts when form_cohorts is True\"\n    )\n    cohorts: Dict[str, List[Any]] = Field(\n        default_factory=dict,\n        description=\"Mapping of cohort IDs to lists of agents\"\n    )\n\n    def __init__(\n        self,\n        initial_topic: str = \"\",\n        summary_model: Type[BaseModel] = BaseModel,\n        form_cohorts: bool = False,\n        group_size: int = 4,\n        max_rounds: int = 2,\n        **kwargs\n    ):\n        \"\"\"Initialize the research mechanism with proper Pydantic model validation.\"\"\"\n        super().__init__(\n            current_topic=initial_topic,\n            summary_model=summary_model,\n            form_cohorts=form_cohorts,\n            group_size=group_size,\n            max_rounds=max_rounds,\n            **kwargs\n        )\n        logger.info(f\"Initialized ResearchMechanism with topic: {initial_topic}, form_cohorts: {form_cohorts}\")\n\n    async def form_agent_cohorts(self, agents: List[Any]) -> None:\n        \"\"\"Form research cohorts based on group size from config.\"\"\"\n        if not self.form_cohorts or not self.group_size:\n            return\n\n        self.cohorts.clear()\n        \n        current_cohort = []\n        cohort_count = 1\n\n        for agent in agents:\n            current_cohort.append(agent)\n            if len(current_cohort) >= self.group_size:\n                self.cohorts[f\"research_cohort_{cohort_count}\"] = current_cohort\n                current_cohort = []\n                cohort_count += 1\n\n        if current_cohort:\n            self.cohorts[f\"research_cohort_{cohort_count}\"] = current_cohort\n\n        logger.info(f\"Formed {len(self.cohorts)} research cohorts\")\n        for cohort_id, cohort_agents in self.cohorts.items():\n            logger.info(f\"{cohort_id}: {[agent.id for agent in cohort_agents]}\")\n\n    def step(\n        self, \n        action: Union[LocalAction, GlobalAction],\n        cohort_id: Optional[str] = None\n    ) -> Union[LocalEnvironmentStep, EnvironmentStep]:\n        \"\"\"Execute one step of the research process.\"\"\"\n        # Check if we're done before incrementing\n        done = self.current_round >= self.max_rounds\n\n        # Use provided cohort_id or default\n        effective_cohort = cohort_id if cohort_id else \"default\"\n        \n        # Initialize cohort's round_summaries if needed\n        if effective_cohort not in self.round_summaries:\n            self.round_summaries[effective_cohort] = []\n            \n        # Add new round if needed\n        while len(self.round_summaries[effective_cohort]) <= self.current_round:\n            self.round_summaries[effective_cohort].append({})\n\n        # Handle single agent action\n        if isinstance(action, LocalAction):\n            action_dict = action.action\n            try:\n                validated_content = self.summary_model.model_validate(action_dict)\n            except Exception as e:\n                logger.error(f\"Failed to validate action content against {self.summary_model.__name__}: {e}\")\n                raise\n\n            # Store the validated content\n            self.round_summaries[effective_cohort][self.current_round][action.agent_id] = validated_content.model_dump()\n\n            # Create and return local step\n            obs = ResearchObservation(\n                current_topic=self.current_topic,\n                own_summary=validated_content,\n                aggregator_notes=f\"Round {self.current_round}\"\n            )\n            local_obs = ResearchLocalObservation(\n                agent_id=action.agent_id,\n                observation=obs\n            )\n            local_step = LocalEnvironmentStep(\n                observation=local_obs,\n                done=done,\n                info={\n                    \"round\": self.current_round,\n                    \"cohort_id\": effective_cohort\n                }\n            )\n            \n            # Increment round counter after processing\n            self.current_round += 1\n            return local_step\n\n        # Handle global actions\n        else:\n            research_actions = {}\n            observations = {}\n\n            for agent_id, local_action in action.actions.items():\n                action_dict = local_action.action\n                try:\n                    validated_content = self.summary_model.model_validate(action_dict)\n                    research_actions[agent_id] = validated_content.model_dump()\n\n                    # Store the validated content\n                    self.round_summaries[effective_cohort][self.current_round][agent_id] = validated_content.model_dump()\n\n                    # Create observation for this agent\n                    obs = ResearchObservation(\n                        current_topic=self.current_topic,\n                        own_summary=validated_content,\n                        aggregator_notes=f\"Round {self.current_round}\"\n                    )\n                    observations[agent_id] = ResearchLocalObservation(\n                        agent_id=agent_id,\n                        observation=obs\n                    )\n\n                except Exception as e:\n                    logger.error(f\"Failed to validate action content for agent {agent_id}: {e}\")\n                    raise\n\n            # Create global step\n            global_obs = ResearchGlobalObservation(\n                observations=observations,\n                all_actions_this_round=research_actions,\n                current_topic=self.current_topic,\n                aggregator_notes=f\"Round {self.current_round} complete\"\n            )\n            \n            global_step = EnvironmentStep(\n                global_observation=global_obs,\n                done=done,\n                info={\n                    \"round\": self.current_round,\n                    \"cohort_id\": effective_cohort\n                }\n            )\n            self.last_step = global_step\n            \n            # Increment round counter after processing\n            self.current_round += 1\n            return global_step\n\n    def get_global_state(self, agent_id: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Get global state, optionally filtered for agent's cohort\"\"\"\n        state = {\n            \"current_round\": self.current_round,\n            \"current_topic\": self.current_topic,\n            \"form_cohorts\": self.form_cohorts,\n            \"max_rounds\": self.max_rounds\n        }\n\n        if self.form_cohorts:\n            if agent_id:\n                # Get agent's specific cohort\n                cohort_id = next(\n                    (cid for cid, agents in self.cohorts.items() \n                    if any(a.id == agent_id for a in agents)),\n                    None\n                )\n                if cohort_id:\n                    state.update({\n                        \"round_summaries\": self.round_summaries.get(cohort_id, []),\n                        \"round_summaries_count\": len(self.round_summaries.get(cohort_id, [])),\n                        \"cohort_id\": cohort_id,\n                        \"cohort_agents\": [a.id for a in self.cohorts[cohort_id]]\n                    })\n            else:\n                # Return all cohorts' data\n                state.update({\n                    \"cohorts\": {\n                        cid: [a.id for a in agents] \n                        for cid, agents in self.cohorts.items()\n                    },\n                    \"round_summaries\": self.round_summaries,\n                    \"round_summaries_count\": {\n                        cid: len(summaries) \n                        for cid, summaries in self.round_summaries.items()\n                    }\n                })\n        else:\n            # Not using cohorts, return all summaries from default cohort\n            state.update({\n                \"round_summaries\": self.round_summaries.get(\"default\", []),\n                \"round_summaries_count\": len(self.round_summaries.get(\"default\", []))\n            })\n\n        if self.last_step:\n            state[\"last_step\"] = self.last_step.dict()\n\n        return state\n\n    def reset(self) -> None:\n        \"\"\"Reset mechanism for a new run.\"\"\"\n        self.current_round = 0\n        self.round_summaries.clear()\n        self.last_step = None\n        self.cohorts.clear()\n        logger.info(\"ResearchMechanism reset complete.\")\n\nclass ResearchEnvironment(MultiAgentEnvironment):\n    \"\"\"\n    Multi-agent environment that orchestrates a research session.\n    It references a ResearchMechanism that collects agent actions.\n    \"\"\"\n    name: str = Field(default=\"research\", description=\"Name of the environment\")\n    action_space: ResearchActionSpace = Field(\n        default_factory=lambda: ResearchActionSpace(summary_model=BaseModel),\n        description=\"Defines the Pydantic model for agent's research summaries\"\n    )\n    observation_space: ResearchObservationSpace = Field(\n        default_factory=ResearchObservationSpace,\n        description=\"Observation space\"\n    )\n    mechanism: ResearchMechanism = Field(default_factory=ResearchMechanism)\n    initial_topic: Optional[str] = Field(default=None, description=\"Initial research topic\")\n\n    def __init__(self, **config):\n        \"\"\"Initialize environment with config parameters.\"\"\"\n        try:\n            # Parse and validate config\n            env_config = ResearchEnvironmentConfig(**config)\n            \n            # Get the schema model\n            summary_model = self._get_schema_model(env_config.schema_model)\n            \n            # Initialize action space with the schema model\n            action_space = ResearchActionSpace(summary_model=summary_model)\n            \n            # Initialize mechanism with relevant config\n            mechanism = ResearchMechanism(\n                initial_topic=env_config.initial_topic,\n                summary_model=summary_model,\n                form_cohorts=env_config.form_cohorts,\n                group_size=env_config.group_size,\n                max_rounds=env_config.sub_rounds\n            )\n\n            # Initialize parent class with processed config\n            super().__init__(\n                name=env_config.name,\n                action_space=action_space,\n                observation_space=ResearchObservationSpace(),\n                mechanism=mechanism,\n                initial_topic=env_config.initial_topic\n            )\n            self._global_state: Dict[str, Any] = {}\n            \n            # Form cohorts during initialization if enabled\n            if env_config.form_cohorts and hasattr(self, 'agents'):\n                self.mechanism.form_agent_cohorts(self.agents)\n                \n        except Exception as e:\n            raise ValueError(f\"Failed to initialize ResearchEnvironment: {e}\")\n\n    def _get_schema_model(self, schema_name: str) -> Type[BaseModel]:\n        \"\"\"Dynamically import and return the schema model class.\"\"\"\n        try:\n            schemas_module = import_module('market_agents.orchestrators.research_schemas')\n            \n            if not hasattr(schemas_module, schema_name):\n                raise ValueError(f\"Schema model '{schema_name}' not found in research_schemas\")\n                \n            model_class = getattr(schemas_module, schema_name)\n            \n            if not issubclass(model_class, BaseModel):\n                raise ValueError(f\"Schema model {schema_name} must be a Pydantic model\")\n                \n            return model_class\n        except ImportError as e:\n            raise ValueError(f\"Could not import research_schemas module: {e}\")\n        except Exception as e:\n            raise ValueError(f\"Could not load schema model '{schema_name}': {e}\")\n\n    def get_global_state(self, agent_id: str = None) -> Dict[str, Any]:\n        \"\"\"Return the environment's global state with filtered mechanism state.\"\"\"\n        # Get the mechanism's state with agent_id\n        mechanism_state = self.mechanism.get_global_state(agent_id) if agent_id else self.mechanism.get_global_state()\n        \n        # Filter to include only the last round's summaries\n        if \"round_summaries\" in mechanism_state and mechanism_state[\"round_summaries\"]:\n            mechanism_state[\"round_summaries\"] = mechanism_state[\"round_summaries\"][-1:]\n\n        return {\n            **mechanism_state,\n            \"current_step\": self.mechanism.current_round,\n            \"max_steps\": self.mechanism.max_rounds\n        }\n\n    def reset(self) -> GlobalObservation:\n        \"\"\"Override reset to handle our own state management\"\"\"\n        self.current_step = 0\n        self._global_state = {}\n        self.history = EnvironmentHistory()\n        self.mechanism.reset()\n        \n        if self.initial_topic:\n            self.mechanism.current_topic = self.initial_topic\n            \n        return GlobalObservation(observations={})"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/information_board.py", "content": "from fastapi import FastAPI, HTTPException, Query\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\nfrom datetime import datetime\nfrom enum import Enum\nimport asyncio\n\n# Initialize FastAPI app\napp = FastAPI()\n\nclass PostType(str, Enum):\n    \"\"\"\n    Enum for the type of post. Currrently\n\n    - Cooperative: A post that is cooperative in nature, meaning it is \n    could be a proposal or suggestion to other agents to cooperate with the agent.\n    - Informative: A post that is informative in nature, meaning it \n    provides information that is beneficial to other agents.\n    - Deceptive: A post that is deceptive in nature, meaning the agent\n    aims to gain something at the expense of other agents.\n    \"\"\"\n    COOPERATIVE = \"Cooperative\"\n    INFORMATIVE = \"Informative\"\n    DECEPTIVE = \"Deceptive\"\n\nclass User(BaseModel):\n    \"\"\"\n    User class for the information board.\n\n    - id: The id of the user.\n    - name: The name of the user.\n    - karma: The karma of the user.\n    \"\"\"\n    id: int\n    name: str\n    karma: int = 0\n\nclass Post(BaseModel):\n    \"\"\"\n    Post class for the information board.\n\n    - id: The id of the post.\n    - title: The title of the post.\n    - content: The content of the post.\n    - user_id: The id of the poster agent.\n    - karma: The karma of the post.\n    - date_posted: The date the post was posted.\n    - categories: The categories the post is filed under.\n    - post_type: The type of post.\n    \"\"\"\n    id: int\n    title: str\n    content: str\n    user_id: int\n    date_posted: datetime = Field(default_factory=datetime.now)\n    categories: List[str] = []\n    post_type: PostType\n\nclass Category(BaseModel):\n    \"\"\"\n    Category class for the information board.\n\n    - name: The name of the category.\n    \"\"\"\n    name: str\n\n# Mock database\nusers = [\n    User(id=1, name=\"Alice\", karma=10),\n    User(id=2, name=\"Bob\", karma=-5)\n]\nposts = [\n    Post(id=1, title=\"Good Post\", content=\"This is a good post\", user_id=1, karma=5, categories=[\"Test Category 1\", \"Test Category 2\"], post_type=PostType.INFORMATIVE),\n    Post(id=2, title=\"Bad Post\", content=\"This is a bad post\", user_id=1, karma=-3, categories=[\"Test Category 2\"], post_type=PostType.DECEPTIVE),\n    Post(id=3, title=\"Another Good Post\", content=\"This is another good post\", user_id=2, karma=2, categories=[\"Test Category 3\"], post_type=PostType.COOPERATIVE),\n    Post(id=4, title=\"Another Bad Post\", content=\"This is another bad post\", user_id=2, karma=-1, categories=[\"Test Category 1\"], post_type=PostType.DECEPTIVE)\n]\ncategories = [Category(name=\"Test Category 1\"), Category(name=\"Test Category 2\"), Category(name=\"Test Category 3\")]\n\n@app.post(\"/posts/\")\nasync def add_post(post: Post):\n    \"\"\"\n    Add a post to the information board.\n\n    Args:\n        post: The post to add.\n    \"\"\"\n    # Mock implementation on mock db\n    post.id = len(posts) + 1\n    posts.append(post)\n    return {\"message\": \"Post added successfully\", \"post_id\": post.id}\n\n@app.get(\"/posts/\")\nasync def get_all_posts(\n    count: Optional[int] = Query(None, description=\"Number of posts to return\"),\n    title: Optional[str] = Query(None, description=\"Filter posts by title\"),\n    categories: Optional[List[str]] = Query(None, description=\"Filter posts by categories\"),\n    order_by: str = Query(\"karma\", description=\"Order posts by 'karma' or 'date'\")\n):\n    \"\"\"\n    Get all posts from the information board\n    with various filters and sorting options.\n\n    Args:\n        count: The number of posts to return.\n        title: The title of the posts to return.\n        categories: The categories of the posts to return.\n        order_by: The order of the posts to return.\n    \"\"\"\n    filtered_posts = posts\n\n    if title:\n        filtered_posts = [post for post in filtered_posts if title.lower() in post.title.lower()]\n\n    if categories:\n        filtered_posts = [post for post in filtered_posts if any(cat in post.categories for cat in categories)]\n\n    if order_by == \"karma\":\n        filtered_posts.sort(key=lambda x: x.karma, reverse=True)\n    elif order_by == \"date\":\n        filtered_posts.sort(key=lambda x: x.date_posted, reverse=True)\n    else:\n        raise HTTPException(status_code=400, detail=\"Invalid order_by parameter\")\n\n    if count:\n        filtered_posts = filtered_posts[:count]\n\n    return filtered_posts\n\n@app.put(\"/posts/{post_id}/upvote\")\nasync def upvote_post(post_id: int):\n    \"\"\"\n    Upvote a post on the information board.\n\n    Args:\n        post_id: The id of the post to upvote.\n    \"\"\"\n    post = next((post for post in posts if post.id == post_id), None)\n    if post:\n        post.karma += 1\n        return {\"message\": \"Post upvoted successfully\", \"new_karma\": post.karma}\n    raise HTTPException(status_code=404, detail=\"Post not found\")\n\n@app.put(\"/posts/{post_id}/downvote\")\nasync def downvote_post(post_id: int):\n    \"\"\"\n    Downvote a post on the information board.\n\n    Args:\n        post_id: The id of the post to downvote.\n    \"\"\"\n    post = next((post for post in posts if post.id == post_id), None)\n    if post:\n        post.karma -= 1\n        return {\"message\": \"Post downvoted successfully\", \"new_karma\": post.karma}\n    raise HTTPException(status_code=404, detail=\"Post not found\")\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/mcp_server.py", "content": "from datetime import datetime\nimport sys\nimport asyncio\nimport subprocess\nimport logging\nfrom typing import Dict, Any, List, Union, Optional, Type\nfrom market_agents.environments.config import EnvironmentConfig\nfrom mcp.client.stdio import stdio_client\nfrom mcp import StdioServerParameters\nfrom mcp import ClientSession\n\nimport sys\n\nfrom pydantic import Field, BaseModel\n\nfrom market_agents.environments.environment import (\n    EnvironmentHistory,\n    MultiAgentEnvironment, \n    Mechanism,\n    LocalAction,\n    LocalObservation,\n    GlobalAction,\n    GlobalObservation,\n    LocalEnvironmentStep,\n    EnvironmentStep,\n    ActionSpace,\n    ObservationSpace,\n    StrAction\n)\nfrom minference.lite.models import CallableMCPTool, CallableTool, StructuredTool\nfrom minference.caregistry import CallableRegistry\n\nlogger = logging.getLogger(__name__)\nCallableRegistry._logger = logger\n\nclass MCPServerEnvironmentConfig(EnvironmentConfig):\n    \"\"\"Configuration for MCP server environment\"\"\"\n    name: str = Field(\n        ...,\n        description=\"Domain-specific name for this instance (e.g., mcp_finance)\"\n    )\n    mechanism: str = Field(\n        default=\"mcp_server\",\n        description=\"Type of mechanism (always mcp_server for this class)\"\n    )\n    mcp_server_module: str = Field(\n        ...,\n        description=\"Module path to the MCP server\"\n    )\n    mcp_server_class: str = Field(\n        default=\"mcp\",\n        description=\"Variable name of MCP server instance\"\n    )\n    sub_rounds: int = Field(\n        default=1,\n        description=\"Number of sub-rounds per main round\"\n    )\n    form_cohorts: bool = Field(\n        default=False,\n        description=\"Whether to organize agents into cohorts\"\n    )\n    group_size: int = Field(\n        default=4,\n        description=\"Size of agent groups when using cohorts\"\n    )\n    task_prompt: str = Field(\n        default=\"\",\n        description=\"Initial task prompt\"\n    )\n\n    model_config = {\n        \"extra\": \"allow\"\n    }\n\nclass MCPServerResult(BaseModel):\n    \"\"\"Structure for a single MCP server tool result\"\"\"\n    tool_name: str\n    result: Any\n    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())\n\nclass MCPServerLocalObservation(LocalObservation):\n    \"\"\"Local observation for a specific agent\"\"\"\n    agent_id: str\n    observation: Dict[str, Any]\n    status: str = \"pending\"\n    tool_results: Optional[List[MCPServerResult]] = None\n\n    def dict(self, *args, **kwargs):\n        \"\"\"Custom dict method to handle nested observation\"\"\"\n        d = super().dict(*args, **kwargs)\n        if self.observation:\n            d['observation'] = self.observation\n        return d\n\nclass MCPServerGlobalObservation(GlobalObservation):\n    \"\"\"Global observation containing all agent observations\"\"\"\n    observations: Dict[str, MCPServerLocalObservation]\n\nclass MCPToolAction(LocalAction):\n    \"\"\"Action for invoking an MCP server tool\"\"\"\n    tool_name: str = Field(..., description=\"Name of the tool to invoke\")\n    tool_args: Dict[str, Any] = Field(default_factory=dict, description=\"Arguments for the tool\")\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'MCPToolAction':\n        \"\"\"Sample a random tool action (not implemented)\"\"\"\n        # This would require knowledge of the available tools and their parameters\n        # For now, just return a placeholder\n        return cls(agent_id=agent_id, tool_name=\"sample_tool\", tool_args={})\n\nclass MCPServerMechanism(Mechanism):\n    \"\"\"Mechanism that manages MCP server tool interactions\"\"\"\n    sequential: bool = Field(\n        default=False,\n        description=\"Whether the mechanism is sequential (one agent at a time)\"\n    )\n    current_round: int = Field(default=0, description=\"Current interaction round\")\n    max_rounds: int = Field(\n        default=0,\n        description=\"Max steps or rounds\"\n    )\n    tool_history: Dict[str, List[Dict[str, Any]]] = Field(\n        default_factory=lambda: {\"default\": []},\n        description=\"History of tool invocations, organized by cohort when form_cohorts=True\"\n    )\n    available_tools: Dict[str, Dict[str, Any]] = Field(\n        default_factory=dict,\n        description=\"Available tools from the MCP server\"\n    )\n    form_cohorts: bool = Field(\n        default=False,\n        description=\"Whether to organize agents into cohorts\"\n    )\n    group_size: Optional[int] = Field(\n        default=None,\n        description=\"Size of agent cohorts when form_cohorts is True\"\n    )\n    cohorts: Dict[str, List[Any]] = Field(\n        default_factory=dict,\n        description=\"Mapping of cohort IDs to lists of agents\"\n    )\n    task_prompt: Optional[str] = Field(\n        default=None,\n        description=\"Initial task prompt\"\n    )\n\n    model_config = {\n        \"arbitrary_types_allowed\": True,\n        \"extra\": \"allow\"\n    }\n\n    def __init__(\n        self,\n        server_path: str = None,\n        form_cohorts: bool = False,\n        group_size: int = 4,\n        **data\n    ):\n        \"\"\"Initialize with both MCP server and cohort support\"\"\"\n        super().__init__(**data)\n        \n        # Initialize cohort-related attributes\n        self.form_cohorts = form_cohorts\n        self.group_size = group_size if form_cohorts else None\n        \n        # Initialize logger\n        self.logger = logging.getLogger(__name__)\n        \n        # Initialize session-related attributes\n        self._active_session = None\n        self._session = None\n        self._read_write = None\n        self.client_initialized = False\n        \n        # Handle MCP server initialization\n        if \"mcp_server\" in data:\n            self.mcp_server = data[\"mcp_server\"]\n            self.server_process = None\n            self.is_external_server = True\n        elif server_path:\n            self.server_path = server_path\n            self.server_process = None\n            self.is_external_server = False\n            self._start_server_process()\n            self._initialize_client_connection()\n        else:\n            raise ValueError(\"Either mcp_server or server_path must be provided\")\n        \n        self.available_tools = {}\n\n    async def form_agent_cohorts(self, agents: List[Any]) -> None:\n        \"\"\"Form agent cohorts based on group size from config.\"\"\"\n        if not self.form_cohorts or not self.group_size:\n            return\n\n        self.cohorts.clear()\n        self.tool_history.clear()\n        \n        current_cohort = []\n        cohort_count = 1\n\n        for agent in agents:\n            current_cohort.append(agent)\n            if len(current_cohort) >= self.group_size:\n                cohort_id = f\"mcp_cohort_{cohort_count}\"\n                self.cohorts[cohort_id] = current_cohort\n                self.tool_history[cohort_id] = []  # Initialize tool history for cohort\n                current_cohort = []\n                cohort_count += 1\n\n        if current_cohort:\n            cohort_id = f\"mcp_cohort_{cohort_count}\"\n            self.cohorts[cohort_id] = current_cohort\n            self.tool_history[cohort_id] = []  # Initialize tool history for cohort\n\n        self.logger.info(f\"Formed {len(self.cohorts)} MCP server cohorts\")\n        for cohort_id, cohort_agents in self.cohorts.items():\n            self.logger.info(f\"{cohort_id}: {[agent.id for agent in cohort_agents]}\")\n    \n    def _start_server_process(self):\n        \"\"\"Start the MCP server as a subprocess\"\"\"\n        try:\n            # Check if we should use mcp run or direct python execution\n            if self.server_path.endswith('.py'):\n                # Use direct Python execution\n                self.server_process = subprocess.Popen(\n                    [sys.executable, self.server_path],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    text=True\n                )\n                print(f\"Started MCP server process with PID: {self.server_process.pid}\")\n            else:\n                # Use mcp run command\n                self.server_process = subprocess.Popen(\n                    [\"mcp\", \"run\", self.server_path],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    text=True\n                )\n                print(f\"Started MCP server with mcp run, PID: {self.server_process.pid}\")\n                \n            # Give the server a moment to start up\n            import time\n            time.sleep(2)\n        except Exception as e:\n            print(f\"Error starting MCP server: {str(e)}\")\n            raise\n\n    def _initialize_client_connection(self):\n        \"\"\"Initialize client connection to the MCP server\"\"\"\n        \n        try:\n            # Create server parameters for the client\n            self.server_params = StdioServerParameters(\n                command=sys.executable,\n                args=[self.server_path],\n                env=None\n            )\n            print(f\"Initialized client connection parameters for server: {self.server_path}\")\n            \n            \n            # Set the mcp_server attribute to the server parameters\n            # This will be used to create sessions when needed\n            self.mcp_server = self.server_params\n            print(\"Client connection parameters initialized\")\n            \n        except Exception as e:\n            print(f\"Error initializing client connection: {str(e)}\")\n            raise\n\n    async def execute_tool(self, tool_name: str, arguments: Dict[str, Any], chat_thread_id: Optional[str] = None) -> Any:\n        \"\"\"Execute a tool using a fresh MCP client session\"\"\"\n        max_retries = 3\n        retry_count = 0\n        last_error = None\n        \n        while retry_count < max_retries:\n            try:\n                async with asyncio.timeout(30):  # 30 second timeout\n                    async with stdio_client(self.server_params) as (read, write):\n                        async with ClientSession(read, write) as session:\n                            await session.initialize()\n                            result = await session.call_tool(tool_name, arguments=arguments)\n                            \n                            # Convert result if needed\n                            if hasattr(result, 'model_dump'):\n                                result = result.model_dump()\n                            elif hasattr(result, 'dict'):\n                                result = result.dict()\n                            elif hasattr(result, '__dict__'):\n                                result = result.__dict__\n\n                            logger.info(f\"tool name: {tool_name}\\ntool result:\\n{result}\")\n\n                            # Record tool execution history\n                            self.record_tool_history(\n                                tool_name=tool_name,\n                                arguments=arguments,\n                                result=result,\n                                chat_thread_id=chat_thread_id\n                            )\n                            \n                            return result\n\n            except (asyncio.TimeoutError, asyncio.CancelledError) as e:\n                logger.error(f\"Tool execution timed out or was cancelled: {str(e)}\")\n                last_error = e\n                if isinstance(e, asyncio.CancelledError):\n                    break\n            except Exception as e:\n                logger.error(f\"Error executing tool {tool_name}: {str(e)}\")\n                last_error = e\n                if \"unhandled errors in a TaskGroup\" not in str(e):\n                    last_error = e\n                else:\n                    return None\n\n            retry_count += 1\n            if retry_count < max_retries:\n                await asyncio.sleep(1)\n        \n        # If we've exhausted retries or got cancelled, raise the last error\n        if isinstance(last_error, asyncio.CancelledError):\n            raise last_error\n        raise last_error or Exception(f\"Failed to execute tool {tool_name} after {max_retries} retries\")\n\n    def record_tool_history(\n        self, \n        tool_name: str,\n        arguments: Dict[str, Any],\n        result: Any,\n        chat_thread_id: Optional[str] = None\n    ) -> None:\n        \"\"\"Record tool execution history in appropriate cohort.\"\"\"\n        # Find agent from chat_thread_id\n        agent_id = None\n        cohort_id = None\n\n        # Find agent (and cohort if enabled)\n        if chat_thread_id:\n            for cid, agents in self.cohorts.items():\n                for agent in agents:\n                    if (hasattr(agent, 'chat_thread') and \n                        agent.chat_thread and \n                        str(agent.chat_thread.id) == str(chat_thread_id)):\n                        agent_id = agent.id\n                        if self.form_cohorts:\n                            cohort_id = cid\n                        break\n                if agent_id:\n                    break\n\n        if not agent_id:\n            raise ValueError(f\"Could not find agent for chat_thread_id: {chat_thread_id}\")\n\n        # Determine where to store the history\n        history_key = cohort_id if self.form_cohorts else \"default\"\n        if history_key not in self.tool_history:\n            self.tool_history[history_key] = []\n\n        # Create and record the history entry\n        history_entry = {\n            \"agent_id\": agent_id,\n            \"tool_name\": tool_name,\n            \"arguments\": arguments,\n            \"result\": result,\n            \"round\": self.current_round,\n            \"timestamp\": datetime.now().isoformat()\n        }\n\n        self.tool_history[history_key].append(history_entry)\n        log_msg = f\"Recorded tool execution in round {self.current_round} for agent {agent_id}\"\n        if self.form_cohorts:\n            log_msg += f\" in cohort {cohort_id}\"\n        logger.debug(log_msg)\n\n    async def initialize(self):\n        \"\"\"Initialize the mechanism by extracting available tools\"\"\"\n        try:\n            logger.info(\"Connecting to MCP Server...\")\n            async with stdio_client(self.mcp_server) as (read, write):\n                async with ClientSession(read, write) as session:\n                    await session.initialize()\n                    logger.info(\"Connected to MCP Server\")\n                    \n                    tools_result = await session.list_tools()\n                    \n                    if hasattr(tools_result, 'tools'):\n                        self.available_tools = {}\n                        logger.info(\"Found tools:\")\n                        for tool_info in tools_result.tools:\n                            self.available_tools[tool_info.name] = {\n                                \"name\": tool_info.name,\n                                \"description\": tool_info.description,\n                                \"input_schema\": tool_info.inputSchema\n                            }\n                            logger.debug(f\"  - {tool_info.name}\")\n                        logger.info(f\"Successfully loaded {len(self.available_tools)} tools\")\n                    else:\n                        logger.warning(\"No tools attribute found in result\")\n                        self.available_tools = {}\n                        \n        except Exception as e:\n            logger.error(f\"Error initializing mechanism: {str(e)}\")\n            import traceback\n            logger.error(f\"Traceback: {traceback.format_exc()}\")\n            self.available_tools = {}\n            \n    def step(\n        self,\n        action: Union[GlobalAction, LocalAction],\n        cohort_id: Optional[str] = None\n    ) -> Union[LocalEnvironmentStep, EnvironmentStep]:\n        \"\"\"Process actions with cohort support\"\"\"\n        # Use provided cohort_id or default\n        effective_cohort = cohort_id if cohort_id else \"default\"\n        \n        # Initialize cohort's tool history if needed\n        if effective_cohort not in self.tool_history:\n            self.tool_history[effective_cohort] = []\n\n        self.current_round += 1\n        done = (self.current_round >= self.max_rounds)\n\n        if isinstance(action, GlobalAction):\n            observations = {}\n            \n            for agent_id, agent_action in action.actions.items():\n                obs_data = {\n                    \"action\": agent_action.model_dump() if hasattr(agent_action, 'model_dump') else str(agent_action),\n                    \"round\": self.current_round,\n                    \"status\": \"success\"\n                }\n                \n                # Create the local observation\n                observations[agent_id] = MCPServerLocalObservation(\n                    agent_id=agent_id,\n                    observation=obs_data,\n                    status=obs_data[\"status\"]\n                )\n            \n            # Create global observation\n            global_obs = MCPServerGlobalObservation(observations=observations)\n            \n            # Return environment step with required info field\n            return EnvironmentStep(\n                global_action=action,\n                global_observation=global_obs,\n                done=done,\n                info={  # Add the required info field\n                    \"round\": self.current_round,\n                    \"max_rounds\": self.max_rounds,\n                    \"tool_history\": self.tool_history,\n                    \"available_tools\": list(self.available_tools.keys())\n                }\n            )\n        \n        elif isinstance(action, LocalAction):\n            # Handle single agent action\n            agent_id = action.agent_id\n            obs_data = {\n                \"action\": action.model_dump() if hasattr(action, 'model_dump') else str(action),\n                \"round\": self.current_round,\n                \"status\": \"success\"\n            }\n            \n            # Create the local observation\n            local_obs = MCPServerLocalObservation(\n                agent_id=agent_id,\n                observation=obs_data,\n                status=obs_data[\"status\"]\n            )\n            \n            # Return local environment step with required info field\n            return LocalEnvironmentStep(\n                observation=local_obs,\n                done=done,\n                info={  # Add the required info field\n                    \"round\": self.current_round,\n                    \"max_rounds\": self.max_rounds,\n                    \"tool_history\": self.tool_history,\n                    \"available_tools\": list(self.available_tools.keys())\n                }\n            )\n        \n        else:\n            # Handle string actions or other types\n            return LocalEnvironmentStep(\n                observation=MCPServerLocalObservation(\n                    agent_id=\"system\",\n                    observation={\"action\": str(action), \"round\": self.current_round},\n                    status=\"success\"\n                ),\n                done=done,\n                info={  # Add the required info field\n                    \"round\": self.current_round,\n                    \"max_rounds\": self.max_rounds,\n                    \"tool_history\": self.tool_history,\n                    \"available_tools\": list(self.available_tools.keys())\n                }\n            )\n    \n    def get_global_state(self, agent_id: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Return the environment's global state from mechanism\"\"\"\n        state = {\n            \"current_step\": self.current_round,\n            \"max_steps\": self.max_rounds,\n            \"task_prompt\": self.task_prompt,\n            \"available_tools\": self.available_tools\n        }\n\n        if self.form_cohorts:\n            # Add cohort-specific information\n            if agent_id:\n                cohort_id = next(\n                    (cid for cid, agents in self.cohorts.items() \n                    if any(a.id == agent_id for a in agents)),\n                    None\n                )\n                if cohort_id:\n                    state.update({\n                        \"tool_history\": self.tool_history.get(cohort_id, []),\n                        \"cohort_id\": cohort_id,\n                        \"cohort_agents\": [a.id for a in self.cohorts[cohort_id]]\n                    })\n            else:\n                state.update({\n                    \"cohorts\": {cid: [a.id for a in agents] for cid, agents in self.cohorts.items()},\n                    \"tool_history\": self.tool_history\n                })\n        else:\n            state[\"tool_history\"] = self.tool_history.get(\"default\", [])\n\n        return state\n\nclass MCPServerActionSpace(ActionSpace):\n    \"\"\"Action space that handles MCP server tool invocations\"\"\"\n    mechanism: MCPServerMechanism = Field(\n        ..., \n        description=\"Mechanism that handles MCP server operations\"\n    )\n    \n    def __init__(self, mechanism: MCPServerMechanism, **data):\n        logger.info(\"Initializing MCPServerActionSpace...\")\n        \n        data.update({\n            \"mechanism\": mechanism\n        })\n        super().__init__(**data)\n        \n        self.allowed_actions = []\n        \n        logger.info(f\"Available tools in mechanism: {list(mechanism.available_tools.keys())}\")\n        \n        # Create a tool for each available MCP server tool\n        for tool_name, tool_info in mechanism.available_tools.items():\n            logger.info(f\"\\nProcessing tool: {tool_name}\")\n            logger.info(f\"Tool info: {tool_info}\")\n            \n            try:\n                from minference.lite.models import CallableMCPTool\n                \n                # Check if we have the function object\n                if \"input_schema\" in tool_info and tool_info[\"input_schema\"] is not None:\n                    logger.info(f\"Creating CallableMCPTool with schema: {tool_info['input_schema']}\")\n                    \n                    # Create the tool from the function\n                    mcp_tool = CallableMCPTool.from_callable(\n                        name=tool_name,\n                        description=tool_info.get(\"description\"),\n                        input_schema=tool_info.get(\"input_schema\")\n                    )\n                    \n                    # Set the MCP server\n                    mcp_tool.mcp_mechanism = mechanism\n                    \n                    self.allowed_actions.append(mcp_tool)\n                    logger.info(f\"Successfully created and added tool: {tool_name}\")\n                else:\n                    logger.warning(f\"Skipping tool {tool_name} - no input schema provided\")\n                    logger.warning(f\"Tool info available: {tool_info}\")\n                    continue\n                \n            except Exception as e:\n                logger.error(f\"Error creating tool {tool_name}: {str(e)}\")\n                logger.error(f\"Tool info that caused error: {tool_info}\")\n                import traceback\n                logger.error(f\"Traceback: {traceback.format_exc()}\")\n        \n        logger.info(f\"Total allowed_actions: {len(self.allowed_actions)}\")\n\n    def get_action_schema(self):\n        \"\"\"Return JSON schema for all available tools\"\"\"\n        schemas = {}\n        for tool in self.allowed_actions:\n            schemas[tool.name] = tool.json_schema()\n        return schemas\n\n    \n    def get_action_schema(self):\n        \"\"\"Return JSON schema for all available tools\"\"\"\n        schemas = {}\n        for tool in self.allowed_actions:\n            schemas[tool.name] = tool.json_schema()\n        return schemas\n\nclass MCPServerEnvironment(MultiAgentEnvironment):\n    \"\"\"Environment that manages MCP server operations\"\"\"\n    name: str = Field(\n        default=\"MCP Server Environment\",\n        description=\"Name of the environment\"\n    )\n    mechanism: MCPServerMechanism = Field(\n        ...,\n        description=\"Mechanism that handles MCP server operations\"\n    )\n    action_space: Optional[MCPServerActionSpace] = Field(\n        default=None,\n        description=\"Action space for MCP server tools\"\n    )\n    observation_space: ObservationSpace = Field(\n        default_factory=ObservationSpace,\n        description=\"Observation space for MCP server\"\n    )\n\n    model_config = {\n        \"arbitrary_types_allowed\": True,\n        \"extra\": \"allow\"\n    }\n\n    def __init__(self, **config):\n        \"\"\"Initialize environment with config parameters.\"\"\"\n        try:\n            # Parse and validate config\n            env_config = MCPServerEnvironmentConfig(**config)\n            \n            # Import the MCP server module\n            import importlib\n            try:\n                spec = importlib.util.find_spec(env_config.mcp_server_module)\n                if spec is None:\n                    raise ImportError(f\"Could not find module {env_config.mcp_server_module}\")\n                server_path = spec.origin\n                if not server_path:\n                    raise ValueError(f\"Could not determine file path for module {env_config.mcp_server_module}\")\n            except Exception as e:\n                raise ValueError(f\"Error resolving server path: {e}\")\n\n            # Initialize mechanism with config parameters\n            mechanism = MCPServerMechanism(\n                server_path=server_path,\n                form_cohorts=env_config.form_cohorts,\n                group_size=env_config.group_size,\n                server_class=env_config.mcp_server_class,\n                task_prompt=env_config.task_prompt\n            )\n\n            # Create a base config dict for parent initialization\n            base_config = {\n                \"name\": env_config.name,\n                \"mechanism\": mechanism,\n                \"observation_space\": ObservationSpace()            }\n\n            # Initialize parent class\n            super().__init__(**base_config)\n                \n        except Exception as e:\n            raise ValueError(f\"Failed to initialize MCPServerEnvironment: {e}\")\n\n    async def initialize(self):\n        \"\"\"Initialize the environment by setting up mechanism and action space\"\"\"\n        logger.info(\"Initializing MCPServerEnvironment...\")\n        \n        # Initialize mechanism first to get available tools\n        logger.info(\"Initializing mechanism...\")\n        await self.mechanism.initialize()\n        logger.info(f\"Mechanism initialized with {len(self.mechanism.available_tools)} tools\")\n        \n        # Create action space with initialized mechanism\n        logger.info(\"Creating action space...\")\n        self.action_space = MCPServerActionSpace(mechanism=self.mechanism)\n        logger.info(f\"Action space created with {len(self.action_space.allowed_actions)} tools\")\n        \n        # Form cohorts if enabled\n        if self.mechanism.form_cohorts and hasattr(self, 'agents'):\n            await self.mechanism.form_agent_cohorts(self.agents)\n            \n        logger.info(\"MCPServerEnvironment initialization complete\")\n\n    def get_global_state(self, agent_id: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Return the environment's global state from mechanism\"\"\"\n        return self.mechanism.get_global_state(agent_id)\n\n    def reset(self) -> GlobalObservation:\n        \"\"\"Reset environment state\"\"\"\n        self.current_step = 0\n        self.history = EnvironmentHistory()\n        self.mechanism.reset()\n        \n        return MCPServerGlobalObservation(observations={})"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/beauty.py", "content": "from typing import Dict, Any, List, Optional, Type\nfrom pydantic import BaseModel, Field, computed_field\nfrom market_agents.environments.environment import (\n    Mechanism, LocalAction, GlobalAction, LocalObservation, GlobalObservation,\n    LocalEnvironmentStep, EnvironmentStep, ActionSpace, ObservationSpace,\n    FloatAction\n)\nfrom statistics import mean\n\nclass BeautyContestAction(FloatAction):\n    action: float = Field(..., description=\"Value of the guess in between 0 and 100\", ge=0, le=100)\n\nclass Prize(BaseModel):\n    is_winner: bool = Field(..., description=\"Whether this agent is the winner\")\n    prize_type: str = Field(default=\"Dollars\", description=\"The prize type\")\n    quantity: int = Field(default=100, description=\"The prize quantity\")\n\nclass BeautyContestLocalObservation(LocalObservation):\n    observation: Prize\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'BeautyContestLocalObservation':\n        return cls(\n            agent_id=agent_id,\n            observation=Prize(is_winner=False, prize_type=\"Dollars\", quantity=100)\n        )\n\nclass BeautyContestGlobalObservation(GlobalObservation):\n    observations: Dict[str, BeautyContestLocalObservation]\n    all_actions: Dict[str, float] = Field(..., description=\"All agents' actions\")\n    average: float = Field(..., description=\"Average of all guesses\")\n    target: float = Field(..., description=\"Target value (2/3 of average)\")\n    winner_id: str = Field(..., description=\"ID of the winning agent\")\n    winner_value: float = Field(..., description=\"Winning guess\")\n\nclass BeautyContestActionSpace(ActionSpace):\n    allowed_actions: List[Type[LocalAction]] = [BeautyContestAction]\n\nclass BeautyContestObservationSpace(ObservationSpace):\n    allowed_observations: List[Type[LocalObservation]] = [BeautyContestLocalObservation]\n\nclass BeautyContestMechanism(Mechanism):\n    target_factor: float = Field(default=2/3, description=\"The factor to multiply the average by\")\n    last_actions: Dict[str, float] = Field(default_factory=dict, description=\"The last actions taken by each agent\")\n    last_target: float = Field(default=0, description=\"The last target number\")\n    last_winner: str = Field(default=\"\", description=\"The last winner's agent ID\")\n    last_winner_value: float = Field(default=0, description=\"The last winner's guess\")\n    action_space: BeautyContestActionSpace = Field(default_factory=BeautyContestActionSpace)\n    observation_space: BeautyContestObservationSpace = Field(default_factory=BeautyContestObservationSpace)\n\n    sequential: bool = Field(default=False, description=\"Whether the mechanism is sequential\")\n\n    def step(self, action: GlobalAction) -> EnvironmentStep:\n        # Extract the float values from the actions\n        self.last_actions = {agent_id: float(local_action.action) for agent_id, local_action in action.actions.items()}\n        \n        # Calculate the target number\n        average = mean(self.last_actions.values())\n        self.last_target = self.target_factor * average\n\n        # Determine the winner\n        self.last_winner = min(self.last_actions, key=lambda x: abs(self.last_actions[x] - self.last_target))\n        self.last_winner_value = self.last_actions[self.last_winner]\n\n        # Prepare observations\n        local_observations = {}\n        for agent_id, action_value in self.last_actions.items():\n            is_winner = agent_id == self.last_winner\n            local_observations[agent_id] = BeautyContestLocalObservation(\n                agent_id=agent_id,\n                observation=Prize(\n                    is_winner=is_winner,\n                    prize_type=\"Dollars\",\n                    quantity=100 if is_winner else 0\n                )\n            )\n\n        global_observation = BeautyContestGlobalObservation(\n            observations=local_observations,\n            all_actions=self.last_actions,\n            average=average,\n            target=self.last_target,\n            winner_id=self.last_winner,\n            winner_value=self.last_winner_value\n        )\n\n        return EnvironmentStep(\n            global_observation=global_observation,\n            done=False,  # The beauty contest can continue indefinitely\n            info={\"current_round\": getattr(self, 'current_round', 0) + 1}\n        )\n\n    def get_global_state(self) -> Dict[str, Any]:\n        return {\n            \"last_actions\": self.last_actions,\n            \"last_target\": self.last_target,\n            \"last_winner\": self.last_winner,\n            \"last_winner_value\": self.last_winner_value\n        }\n\n    def reset(self) -> None:\n        self.last_actions = {}\n        self.last_target = 0\n        self.last_winner = \"\"\n        self.last_winner_value = 0"}
{"type": "source_file", "path": "market_agents/inference/__init__.py", "content": ""}
{"type": "source_file", "path": "market_agents/inference/message_models.py", "content": "from market_agents.agents.tool_caller.utils import function_to_json\nfrom pydantic import BaseModel, Field, computed_field, ValidationError, model_validator\nfrom typing import Callable, Literal, Optional, Union, Dict, Any, List, Iterable, Tuple\nimport json\nimport time\nfrom typing_extensions import Self\n\n\nfrom openai.types.chat import (\n    ChatCompletionMessageParam,\n    ChatCompletionToolParam,\n    ChatCompletionToolChoiceOptionParam,\n    ChatCompletion\n)\nfrom openai.types.shared_params import (\n    ResponseFormatText,\n    ResponseFormatJSONObject,\n    FunctionDefinition\n)\nfrom openai.types.chat.completion_create_params import (\n    ResponseFormat,\n    CompletionCreateParams,\n    FunctionCall\n)\nfrom openai.types.shared_params.response_format_json_schema import ResponseFormatJSONSchema, JSONSchema\n\nfrom anthropic.types import (\n    MessageParam,\n    TextBlock,\n    ToolUseBlock,\n    ToolParam,\n    Message as AnthropicMessage\n)\nfrom anthropic.types.beta.prompt_caching import (\n    PromptCachingBetaMessage,\n    PromptCachingBetaToolParam,\n    PromptCachingBetaMessageParam,\n    PromptCachingBetaTextBlockParam,\n    message_create_params\n)\nfrom anthropic.types.beta.prompt_caching.prompt_caching_beta_cache_control_ephemeral_param import PromptCachingBetaCacheControlEphemeralParam\nfrom anthropic.types.model_param import ModelParam\n\nfrom market_agents.inference.utils import msg_dict_to_oai, msg_dict_to_anthropic, parse_json_string\n\n\n\n\nclass StructuredTool(BaseModel):\n    \"\"\" Supported type by OpenAI Structured Output:\n    String, Number, Boolean, Integer, Object, Array, Enum, anyOf\n    Root must be Object, not anyOf\n    Not supported by OpenAI Structured Output: \n    For strings: minLength, maxLength, pattern, format\n    For numbers: minimum, maximum, multipleOf\n    For objects: patternProperties, unevaluatedProperties, propertyNames, minProperties, maxProperties\n    For arrays: unevaluatedItems, contains, minContains, maxContains, minItems, maxItems, uniqueItems\n    oai_reference: https://platform.openai.com/docs/guides/structured-outputs/how-to-use \"\"\"\n\n    json_schema: Optional[Dict[str, Any]] = None\n    schema_name: str = Field(default = \"generate_structured_output\")\n    schema_description: str = Field(default =\"Generate a structured output based on the provided JSON schema.\")\n    instruction_string: str = Field(default = \"Please follow this JSON schema for your response:\")\n    strict_schema: bool = True\n\n    @computed_field\n    @property\n    def schema_instruction(self) -> str:\n        return f\"{self.instruction_string}: {self.json_schema}\"\n\n    def get_openai_tool(self) -> Optional[ChatCompletionToolParam]:\n        if self.json_schema:\n            return ChatCompletionToolParam(\n                type=\"function\",\n                function=FunctionDefinition(\n                    name=self.schema_name,\n                    description=self.schema_description,\n                    parameters=self.json_schema\n                )\n            )\n        return None\n\n    def get_anthropic_tool(self) -> Optional[PromptCachingBetaToolParam]:\n        if self.json_schema:\n            return PromptCachingBetaToolParam(\n                name=self.schema_name,\n                description=self.schema_description,\n                input_schema=self.json_schema,\n                cache_control=PromptCachingBetaCacheControlEphemeralParam(type='ephemeral')\n            )\n        return None\n    def get_openai_json_schema_response(self) -> Optional[ResponseFormatJSONSchema]:\n\n        if self.json_schema:\n            schema = JSONSchema(name=self.schema_name,description=self.schema_description,schema=self.json_schema,strict=self.strict_schema)\n            return ResponseFormatJSONSchema(type=\"json_schema\", json_schema=schema)\n        return None\n    \nclass LLMConfig(BaseModel):\n    client: Literal[\"openai\", \"azure_openai\", \"anthropic\", \"vllm\", \"litellm\"]\n    model: Optional[str] = None\n    max_tokens: int = Field(default=400)\n    temperature: float = 0\n    response_format: Literal[\"json_beg\", \"text\",\"json_object\",\"structured_output\",\"tool\"] = \"text\"\n    use_cache: bool = True\n\n    @model_validator(mode=\"after\")\n    def validate_response_format(self) -> Self:\n        if self.response_format == \"json_object\" and self.client in [\"vllm\", \"litellm\",\"anthropic\"]:\n            raise ValueError(f\"{self.client} does not support json_object response format\")\n        elif self.response_format == \"structured_output\" and self.client == \"anthropic\":\n            raise ValueError(f\"Anthropic does not support structured_output response format use json_beg or tool instead\")\n        return self\n\n\n  \n\nclass LLMPromptContext(BaseModel):\n    id: str\n    system_string: Optional[str] = None\n    history: Optional[List[Dict[str, str]]] = None\n    new_message: str\n    prefill: str = Field(default=\"Here's the valid JSON object response:```json\", description=\"prefill assistant response with an instruction\")\n    postfill: str = Field(default=\"\\n\\nPlease provide your response in JSON format.\", description=\"postfill user response with an instruction\")\n    structured_output : Optional[StructuredTool] = None\n    use_schema_instruction: bool = Field(default=False, description=\"Whether to use the schema instruction\")\n    tools: Optional[List[Callable]] = None\n    llm_config: LLMConfig\n    use_history: bool = Field(default=True, description=\"Whether to use the history\")\n    \n    @computed_field\n    @property\n    def oai_response_format(self) -> Optional[ResponseFormat]:\n        if self.llm_config.response_format == \"text\":\n            return ResponseFormatText(type=\"text\")\n        elif self.llm_config.response_format == \"json_object\":\n            return ResponseFormatJSONObject(type=\"json_object\")\n        elif self.llm_config.response_format == \"structured_output\":\n            assert self.structured_output is not None, \"Structured output is not set\"\n            return self.structured_output.get_openai_json_schema_response()\n        else:\n            return None\n\n\n    @computed_field\n    @property\n    def use_prefill(self) -> bool:\n        if self.llm_config.client in ['anthropic','vllm','litellm'] and  self.llm_config.response_format in [\"json_beg\"]:\n\n            return True\n        else:\n            return False\n        \n    @computed_field\n    @property\n    def use_postfill(self) -> bool:\n        if self.llm_config.client == 'openai' and 'json' in self.llm_config.response_format and not self.use_schema_instruction:\n            return True\n\n        else:\n            return False\n        \n    @computed_field\n    @property\n    def system_message(self) -> Optional[Dict[str, str]]:\n        content= self.system_string if self.system_string  else \"\"\n        if self.use_schema_instruction and self.structured_output:\n            content = \"\\n\".join([content,self.structured_output.schema_instruction])\n        return {\"role\":\"system\",\"content\":content} if len(content)>0 else None\n    \n    @computed_field\n    @property\n    def messages(self)-> List[Dict[str, Any]]:\n        messages = [self.system_message] if self.system_message is not None else []\n        if  self.use_history and self.history:\n            messages+=self.history\n        messages.append({\"role\":\"user\",\"content\":self.new_message})\n        if self.use_prefill:\n            prefill_message = {\"role\":\"assistant\",\"content\":self.prefill}\n            messages.append(prefill_message)\n        elif self.use_postfill:\n            messages[-1][\"content\"] = messages[-1][\"content\"] + self.postfill\n        return messages\n    \n    @computed_field\n    @property\n    def oai_messages(self)-> List[ChatCompletionMessageParam]:\n        return msg_dict_to_oai(self.messages)\n    \n    @computed_field\n    @property\n    def anthropic_messages(self) -> Tuple[List[PromptCachingBetaTextBlockParam],List[MessageParam]]:\n        return msg_dict_to_anthropic(self.messages, use_cache=self.llm_config.use_cache)\n    \n    @computed_field\n    @property\n    def vllm_messages(self) -> List[ChatCompletionMessageParam]:\n        return msg_dict_to_oai(self.messages)\n        \n    def update_llm_config(self,llm_config:LLMConfig) -> 'LLMPromptContext':\n        \n        return self.model_copy(update={\"llm_config\":llm_config})\n       \n    \n\n        \n    def add_chat_turn_history(self, llm_output:'LLMOutput'):\n        \"\"\" add a chat turn to the history without safely model copy just normal append \"\"\"\n        if llm_output.source_id != self.id:\n            raise ValueError(f\"LLMOutput source_id {llm_output.source_id} does not match the prompt context id {self.id}\")\n        if self.history is None:\n            self.history = []\n        self.history.append({\"role\": \"user\", \"content\": self.new_message})\n        self.history.append({\"role\": \"assistant\", \"content\": llm_output.str_content or json.dumps(llm_output.json_object.object) if llm_output.json_object else \"{}\"})\n    \n    def get_tool(self) -> Union[ChatCompletionToolParam, PromptCachingBetaToolParam, None]:\n        if not self.structured_output:\n            return None\n        if self.llm_config.client in [\"openai\",\"vllm\",\"litellm\"]:\n            return self.structured_output.get_openai_tool()\n        elif self.llm_config.client == \"anthropic\":\n            return self.structured_output.get_anthropic_tool()\n        else:\n            return None\n            \n    def get_openai_tools(self) -> Optional[List[ChatCompletionToolParam]]:\n        \"\"\"Convert the tools into OpenAI function signatures.\"\"\"\n        if not self.tools:\n            return None\n        return [function_to_json(tool) for tool in self.tools]\n    \nclass Usage(BaseModel):\n    prompt_tokens: int\n    completion_tokens: int\n    total_tokens: int\n    cache_creation_input_tokens: Optional[int] = None\n    cache_read_input_tokens: Optional[int] = None\n\nclass GeneratedJsonObject(BaseModel):\n    name: str\n    object: Dict[str, Any]\n\nclass LLMOutput(BaseModel):\n    raw_result: Union[str, dict, ChatCompletion, AnthropicMessage, PromptCachingBetaMessage]\n    completion_kwargs: Optional[Dict[str, Any]] = None\n    start_time: float\n    end_time: float\n    source_id: str\n    client: Optional[Literal[\"openai\", \"anthropic\",\"vllm\",\"litellm\"]] = Field(default=None)\n\n    @property\n    def time_taken(self) -> float:\n        return self.end_time - self.start_time\n\n    @computed_field\n    @property\n    def str_content(self) -> Optional[str]:\n        return self._parse_result()[0]\n\n    @computed_field\n    @property\n    def json_object(self) -> Optional[GeneratedJsonObject]:\n        return self._parse_result()[1]\n    \n    @computed_field\n    @property\n    def tool_calls(self) -> Optional[List[GeneratedJsonObject]]:\n        return self._parse_result()[4]\n    \n    @computed_field\n    @property\n    def error(self) -> Optional[str]:\n        return self._parse_result()[3]\n\n    @computed_field\n    @property\n    def contains_object(self) -> bool:\n        return self._parse_result()[1] is not None\n    \n    @computed_field\n    @property\n    def usage(self) -> Optional[Usage]:\n        return self._parse_result()[2]\n\n    @computed_field\n    @property\n    def result_provider(self) -> Optional[Literal[\"openai\", \"anthropic\",\"vllm\",\"litellm\"]]:\n        return self.search_result_provider() if self.client is None else self.client\n    \n    @model_validator(mode=\"after\")\n    def validate_provider_and_client(self) -> Self:\n        if self.client is not None and self.result_provider != self.client:\n            raise ValueError(f\"The inferred result provider '{self.result_provider}' does not match the specified client '{self.client}'\")\n        return self\n    \n    \n    def search_result_provider(self) -> Optional[Literal[\"openai\", \"anthropic\"]]:\n        try:\n            oai_completion = ChatCompletion.model_validate(self.raw_result)\n            return \"openai\"\n        except ValidationError:\n            try:\n                anthropic_completion = AnthropicMessage.model_validate(self.raw_result)\n                return \"anthropic\"\n            except ValidationError:\n                try:\n                    antrhopic_beta_completion = PromptCachingBetaMessage.model_validate(self.raw_result)\n                    return \"anthropic\"\n                except ValidationError:\n                    return None\n\n    def _parse_json_string(self, content: str) -> Optional[Dict[str, Any]]:\n        return parse_json_string(content)\n    \n    \n\n    def _parse_oai_completion(self,chat_completion:ChatCompletion) -> Tuple[Optional[str], Optional[List[GeneratedJsonObject]], Optional[Usage], None]:\n        message = chat_completion.choices[0].message\n        content = message.content\n\n        json_object = None\n        tool_calls = []\n        usage = None\n\n        if message.tool_calls:\n            for tool_call in message.tool_calls:\n                name = tool_call.function.name\n                arguments = tool_call.function.arguments\n                try:\n                    object_dict = json.loads(arguments)\n                    tool_call_object = GeneratedJsonObject(name=name, object=object_dict)\n                except json.JSONDecodeError:\n                    tool_call_object = GeneratedJsonObject(name=name, object={\"raw\": arguments})\n                tool_calls.append(tool_call_object)\n            if tool_calls:\n                json_object = tool_calls[0]\n        elif content is not None:\n            if self.completion_kwargs:\n                name = self.completion_kwargs.get(\"response_format\",{}).get(\"json_schema\",{}).get(\"name\",None)\n            else:\n                name = None\n            parsed_json = self._parse_json_string(content)\n            if parsed_json:\n                \n                json_object = GeneratedJsonObject(name=\"parsed_content\" if name is None else name,\n                                                   object=parsed_json)\n                content = None  # Set content to None when we have a parsed JSON object\n                #print(f\"parsed_json: {parsed_json} with name\")\n        if chat_completion.usage:\n            usage = Usage(\n                prompt_tokens=chat_completion.usage.prompt_tokens,\n                completion_tokens=chat_completion.usage.completion_tokens,\n                total_tokens=chat_completion.usage.total_tokens\n            )\n\n        return content, json_object, usage, None, tool_calls\n\n    def _parse_anthropic_message(self, message: Union[AnthropicMessage, PromptCachingBetaMessage]) -> Tuple[Optional[str], Optional[GeneratedJsonObject], Optional[Usage],None]:\n        content = None\n        json_object = None\n        usage = None\n\n        if message.content:\n            first_content = message.content[0]\n            if isinstance(first_content, TextBlock):\n                content = first_content.text\n                parsed_json = self._parse_json_string(content)\n                if parsed_json:\n                    json_object = GeneratedJsonObject(name=\"parsed_content\", object=parsed_json)\n                    content = None  # Set content to None when we have a parsed JSON object\n            elif isinstance(first_content, ToolUseBlock):\n                name = first_content.name\n                input_dict : Dict[str,Any] = first_content.input # type: ignore  # had to ignore due to .input being of object class\n                json_object = GeneratedJsonObject(name=name, object=input_dict)\n\n        if hasattr(message, 'usage'):\n            usage = Usage(\n                prompt_tokens=message.usage.input_tokens,\n                completion_tokens=message.usage.output_tokens,\n                total_tokens=message.usage.input_tokens + message.usage.output_tokens,\n                cache_creation_input_tokens=getattr(message.usage, 'cache_creation_input_tokens', None),\n                cache_read_input_tokens=getattr(message.usage, 'cache_read_input_tokens', None)\n            )\n\n        return content, json_object, usage, None\n    \n\n    def _parse_result(self) -> Tuple[Optional[str], Optional[GeneratedJsonObject], Optional[Usage],Optional[str]]:\n        provider = self.result_provider\n        if getattr(self.raw_result, \"error\", None):\n            return None, None, None,  getattr(self.raw_result, \"error\", None)\n        if provider == \"openai\":\n            return self._parse_oai_completion(ChatCompletion.model_validate(self.raw_result))\n        elif provider == \"anthropic\":\n            try: #beta first\n                return self._parse_anthropic_message(PromptCachingBetaMessage.model_validate(self.raw_result))\n            except ValidationError:\n                return self._parse_anthropic_message(AnthropicMessage.model_validate(self.raw_result))\n        elif provider == \"vllm\":\n             return self._parse_oai_completion(ChatCompletion.model_validate(self.raw_result))\n        elif provider == \"litellm\":\n            return self._parse_oai_completion(ChatCompletion.model_validate(self.raw_result))\n        else:\n            raise ValueError(f\"Unsupported result provider: {provider}\")\n\n    class Config:\n        arbitrary_types_allowed = True"}
{"type": "source_file", "path": "market_agents/environments/environment.py", "content": "from typing import Dict, Any, List, Optional, Type, Union, Tuple\nfrom pydantic import BaseModel, Field, computed_field\nfrom datetime import datetime\nimport random\nimport string\nfrom statistics import mean\nfrom abc import ABC, abstractmethod\nimport json\n\nclass LocalAction(BaseModel, ABC):\n    \"\"\"Represents an action for a single agent.\"\"\"\n    agent_id: str\n    action: Any\n\n    @classmethod\n    @abstractmethod\n    def sample(cls, agent_id: str) -> 'LocalAction':\n        \"\"\"Sample a random action for the given agent_id.\"\"\"\n        pass\n\nclass GlobalAction(BaseModel):\n    \"\"\"Represents actions for all agents.\"\"\"\n    actions: Dict[str, LocalAction]\n\n    def locals(self) -> Dict[str, LocalAction]:\n        \"\"\"Get the local actions for all agents.\"\"\"\n        return self.actions\n\n    @classmethod\n    def from_local_actions(cls, local_actions: Dict[str, LocalAction]) -> \"GlobalAction\":\n        \"\"\"Create a global action from local actions.\"\"\"\n        return cls(actions=local_actions)\n\nclass LocalObservation(BaseModel, ABC):\n    \"\"\"Represents an observation for a single agent.\"\"\"\n    agent_id: str\n    observation: BaseModel\n\n\nclass GlobalObservation(BaseModel):\n    \"\"\"Represents observations for all agents.\"\"\"\n    observations: Dict[str, LocalObservation]\n    \n\n    def locals(self) -> Dict[str, LocalObservation]:\n        \"\"\"Get the local observations for all agents.\"\"\"\n        return self.observations\n    \n    @property\n    @computed_field\n    def global_obs(self) -> Optional[Any]:\n        \"\"\"Get the global observation for all agents.\"\"\"\n        return None\n\n    @classmethod\n    def from_local_observations(cls, local_observations: Dict[str, LocalObservation]) -> \"GlobalObservation\":\n        \"\"\"Create a global observation from local observations.\"\"\"\n        return cls(observations=local_observations)\n\n    def to_local(self, agent_id: str) -> LocalObservation:\n        \"\"\"Convert global observation to local observation for a specific agent.\"\"\"\n        return self.observations[agent_id]\n\nclass StrObservation(LocalObservation):\n    observation: str\n\n    @classmethod\n    def sample(cls, agent_id: str, min_length: int = 1, max_length: int = 100) -> 'StrObservation':\n        content = ''.join(random.choices(string.ascii_letters + string.digits + string.punctuation + ' ', k=random.randint(min_length, max_length)))\n        return cls(agent_id=agent_id, observation=content)\n\nclass LocalEnvironmentStep(BaseModel):\n    \"\"\"Represents the output of a single environment step for a single agent.\"\"\"\n    observation: LocalObservation\n    reward: Optional[float] = Field(default=None, description=\"Reward for the agent at this step\")\n    done: bool\n    info: Dict[str, Any]\n\nclass EnvironmentStep(BaseModel):\n    \"\"\"Represents the output of a single environment step.\"\"\"\n    global_observation: GlobalObservation\n    done: bool\n    info: Dict[str, Any]\n\n    @classmethod\n    def from_local_steps(cls, local_steps: Dict[str, LocalEnvironmentStep]) -> \"EnvironmentStep\":\n        \"\"\"Create a global environment step from local steps.\"\"\"\n        observations = {agent_id: step.observation for agent_id, step in local_steps.items()}\n        done = all(step.done for step in local_steps.values())\n        info = {}\n        return cls(\n            global_observation=GlobalObservation.from_local_observations(observations),\n            done=done,\n            info=info\n        )\n\n    def get_local_step(self, agent_id: str) -> LocalEnvironmentStep:\n        \"\"\"Get the local step for a single agent.\"\"\"\n        return LocalEnvironmentStep(\n            observation=self.global_observation.to_local(agent_id),\n            done=self.done,\n            info=self.info\n        )\n\nclass EnvironmentHistory(BaseModel):\n    \"\"\"Represents the history of environment steps.\"\"\"\n    steps: List[Tuple[GlobalAction, EnvironmentStep]] = Field(default_factory=list)\n\n    def add_step(self, action: GlobalAction, step: EnvironmentStep):\n        \"\"\"Add a step to the history.\"\"\"\n        self.steps.append((action, step))\n\nclass StrAction(LocalAction):\n    action: str = Field(..., description=\"Content of the string action\")\n\n    @classmethod\n    def sample(cls, agent_id: str, min_length: int = 1, max_length: int = 10) -> 'StrAction':\n        content = ''.join(random.choices(string.ascii_letters + string.digits, k=random.randint(min_length, max_length)))\n        return cls(agent_id=agent_id, action=content)\n\nclass IntAction(LocalAction):\n    action: int = Field(..., description=\"Value of the integer action\")\n    ge: Optional[int] = Field(default=None, description=\"Minimum allowed value (inclusive)\")\n    le: Optional[int] = Field(default=None, description=\"Maximum allowed value (inclusive)\")\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'IntAction':\n        ge = cls.model_fields['ge'].default\n        le = cls.model_fields['le'].default\n        min_val = ge if ge is not None else 0\n        max_val = le if le is not None else 100\n        return cls(agent_id=agent_id, action=random.randint(min_val, max_val), ge=ge, le=le)\n\nclass FloatAction(LocalAction):\n    action: float = Field(..., description=\"Value of the float action\")\n    ge: Optional[float] = Field(default=None, description=\"Minimum allowed value (inclusive)\")\n    le: Optional[float] = Field(default=None, description=\"Maximum allowed value (inclusive)\")\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'FloatAction':\n        ge = cls.model_fields['ge'].default\n        le = cls.model_fields['le'].default\n        min_val = ge if ge is not None else 0.0\n        max_val = le if le is not None else 1.0\n        return cls(agent_id=agent_id, action=random.uniform(min_val, max_val), ge=ge, le=le)\n\nclass ActionSpace(BaseModel):\n    allowed_actions: List[Type[LocalAction]] = Field(default_factory=list, description=\"List of allowed action types\")\n\n    def sample(self, agent_id: str) -> LocalAction:\n        \"\"\"Sample a random action from the allowed actions.\"\"\"\n        if not self.allowed_actions:\n            raise ValueError(\"No allowed actions defined\")\n        action_type = random.choice(self.allowed_actions)\n        return action_type.sample(agent_id)\n    \n    def get_action_schema(self) -> Dict[str, Any]:\n        \"\"\"Get the schema for the allowed actions.\"\"\"\n        if not self.allowed_actions:\n            raise ValueError(\"No allowed actions defined\")\n        # Assuming all allowed actions have the same schema\n        return self.allowed_actions[0].model_json_schema() \n\nclass ObservationSpace(BaseModel):\n    allowed_observations: List[Type[LocalObservation]] = Field(default_factory=list)\n\nclass Mechanism(BaseModel, ABC):\n    sequential: bool = Field(default=False, description=\"Whether the mechanism is sequential\")\n    @abstractmethod\n    def step(self, action: Union[LocalAction, GlobalAction], cohort_id: Optional[str] = None) -> Union[LocalEnvironmentStep, EnvironmentStep]:\n        \"\"\"Execute a step in the mechanism.\"\"\"\n        pass\n\n\n    @abstractmethod\n    def get_global_state(self) -> Any:\n        \"\"\"Get the global state of the mechanism.\"\"\"\n        pass\n\nclass Notebook(Mechanism):\n    text: str = Field(default=\"\", description=\"The notebook's text content\")\n    \n    sequential: bool = Field(default=True, description=\"Whether the mechanism is sequential\")\n\n    def step(self, action: LocalAction) -> LocalEnvironmentStep:\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        header = f\"\\n[{timestamp}] Agent {action.agent_id}:\"\n        self.text += f\"{header}\\n{action.action}\\n\"\n        \n        observation = StrObservation(agent_id=action.agent_id, observation=self.text)\n        done = False  # The notebook never ends\n        info = {}\n\n        return LocalEnvironmentStep(\n            observation=observation,\n            done=done,\n            info=info\n        )\n\n    def get_global_state(self) -> str:\n        return self.text\n\nclass NotebookActionSpace(ActionSpace):\n    allowed_actions: List[Type[LocalAction]] = [StrAction]\n\n    def sample(self, agent_id: str) -> StrAction:\n        content = ''.join(random.choices(string.ascii_letters + string.digits, k=random.randint(5, 20)))\n        return StrAction(agent_id=agent_id, action=content)\n\nclass NotebookObservationSpace(ObservationSpace):\n    allowed_observations: List[Type[LocalObservation]] = [StrObservation]\n\n    def sample(self, agent_id: str) -> LocalObservation:\n        return StrObservation.sample(agent_id)\n\nclass MultiAgentEnvironment(BaseModel):\n    \"\"\"\n    Base class for multi-agent environments. With batched or sequential actions.\n    \"\"\"\n    name: str = Field(..., description=\"Name of the environment\")\n    address: Optional[str] = Field(default=None, description=\"Address of the environment for orchestrator linking\")\n    current_step: int = Field(default=0, description=\"Current step/round of the simulation\")\n    max_steps: int = Field(default=10, description=\"Maximum number of steps/rounds for this environment\")\n    action_space: ActionSpace = Field(default_factory=NotebookActionSpace, description=\"Action space of the environment\")\n    observation_space: ObservationSpace = Field(default_factory=NotebookObservationSpace, description=\"Observation space of the environment\")\n    history: EnvironmentHistory = Field(default_factory=EnvironmentHistory, description=\"History of environment steps\")\n    mechanism: Mechanism = Field(default_factory=Notebook, description=\"Mechanism of the environment that determines the rules of the game P(s, a, s')\")\n\n    def step(self, actions: GlobalAction, cohort_id: Optional[str] = None) -> EnvironmentStep:\n        \"\"\"\n        Run one timestep of the environment's dynamics using the batched agent actions.\n        \n        Args:\n            actions (GlobalAction): A batched action containing actions for each agent.\n            cohort_id (Optional[str]): Identifier for the cohort when using cohort-based processing.\n\n        Returns:\n            EnvironmentStep: The result of taking a step in the environment.\n        \"\"\"\n        if self.mechanism.sequential:\n            # if it is sequential, we need to run the mechanism for each agent\n            local_steps: Dict[str, LocalEnvironmentStep] = {}\n            for agent_id, local_action in actions.locals().items():\n                local_step = self.mechanism.step(local_action, cohort_id=cohort_id)\n                assert isinstance(local_step, LocalEnvironmentStep)\n                local_steps[agent_id] = local_step\n            global_step = EnvironmentStep.from_local_steps(local_steps)\n        else:\n            global_step = self.mechanism.step(actions, cohort_id=cohort_id)\n            assert isinstance(global_step, EnvironmentStep)\n        \n        self.current_step += 1\n        self.update_history(actions, global_step)\n        return global_step\n\n    def reset(self) -> GlobalObservation:\n        \"\"\"\n        Reset the environment and return the initial global observation.\n\n        Returns:\n            GlobalObservation: Initial global observation of the environment.\n        \"\"\"\n        self.current_step = 0\n        self.global_state = {}\n        self.history = EnvironmentHistory()\n        if isinstance(self.mechanism, Notebook):\n            self.mechanism.text = \"\"\n        return GlobalObservation(observations={})\n\n    def render(self):\n        \"\"\"\n        Render the environment.\n        \"\"\"\n        print(self.get_global_state())\n\n    def close(self):\n        \"\"\"\n        Close the environment, do any necessary cleanup.\n        \"\"\"\n        pass  # No specific cleanup needed for the basic environment\n\n    def get_global_state(self) -> Any:\n        \"\"\"\n        Return a summary of the global state.\n\n        Returns:\n            Any: The global state.\n        \"\"\"\n        return self.mechanism.get_global_state()\n\n    def get_current_step(self) -> int:\n        \"\"\"\n        Return the current step/round of the simulation.\n\n        Returns:\n            int: The current step.\n        \"\"\"\n        return self.current_step\n\n    def update_history(self, action: GlobalAction, step: EnvironmentStep):\n        \"\"\"\n        Update the environment history with the latest step.\n        \"\"\"\n        self.history.add_step(action, step)\n\n    def random_action_test(self, num_agents: int, num_steps: int):\n        \"\"\"\n        Run a test with random actions for the specified number of agents and steps.\n        \"\"\"\n        agent_ids = [f\"Agent{i}\" for i in range(num_agents)]\n\n        print(f\"\\n=== Random Action Test for {self.name} ===\\n\")\n\n        for step in range(num_steps):\n            print(f\"\\nStep {step + 1}:\")\n\n            actions = {}\n            for agent_id in agent_ids:\n                action_type = random.choice(self.action_space.allowed_actions)\n                actions[agent_id] = action_type.sample(agent_id)\n\n            global_action = GlobalAction(actions=actions)\n            step_result = self.step(global_action)\n            self._print_step_results(step_result, actions, agent_ids)\n\n        print(\"\\nTest completed.\")\n        self.close()\n\n    def _print_step_results(self, step_result: EnvironmentStep, actions: Dict[str, LocalAction], agent_ids: List[str]):\n        \"\"\"\n        Print the results of a single step. This method can be overridden in subclasses for custom output.\n        \"\"\"\n        for agent_id in agent_ids:\n            local_step = step_result.get_local_step(agent_id)\n            print(f\"{agent_id} action: {actions[agent_id].action}\")\n            print(f\"{agent_id} observation: {step_result.global_observation.observations[agent_id].observation}\")\n\n        print(\"\\nGlobal state:\")\n        print(self.get_global_state())\n        print(\"\\n\" + \"=\"*50)"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/group_chat.py", "content": "import asyncio\nfrom enum import Enum\nfrom typing import List, Dict, Any, Union, Type, Optional\nfrom pydantic import BaseModel, Field, PrivateAttr, field_validator\nfrom datetime import datetime\nimport logging\n\nfrom market_agents.orchestrators.group_chat.groupchat_api_utils import GroupChatAPIUtils\nfrom market_agents.agents.cognitive_steps import ActionStep\nfrom market_agents.environments.environment import (\n    Mechanism, LocalAction, GlobalAction, LocalObservation, GlobalObservation,\n    EnvironmentStep, ActionSpace, MultiAgentEnvironment, ObservationSpace, LocalEnvironmentStep\n)\nfrom market_agents.orchestrators.parallel_cognitive_steps import ParallelCognitiveProcessor\n\nlogger = logging.getLogger(__name__)\n\nfrom typing import List, Dict, Any, Union, Type, Optional\nfrom pydantic import BaseModel, Field\nimport logging\n\nfrom market_agents.environments.environment import (\n    Mechanism, LocalAction, GlobalAction, LocalObservation, GlobalObservation,\n    EnvironmentStep, ActionSpace, ObservationSpace, LocalEnvironmentStep\n)\n\nlogger = logging.getLogger(__name__)\n\nclass MessageType(str, Enum):\n    CHAT = \"chat_message\"\n    TOPIC_PROPOSAL = \"propose_topic\"\n\nclass GroupChatMessage(BaseModel):\n    content: str\n    message_type: MessageType = MessageType.CHAT\n\n    def dict(self, *args, **kwargs) -> Dict[str, Any]:\n        \"\"\"Custom serialization to handle Enum type.\"\"\"\n        return {\n            \"content\": self.content,\n            \"message_type\": self.message_type.value\n        }\n\n    def model_dump(self, *args, **kwargs) -> Dict[str, Any]:\n        \"\"\"Ensure consistent serialization with newer Pydantic versions.\"\"\"\n        return self.dict(*args, **kwargs)\n\n    @classmethod\n    def set_topic_proposal_phase(cls, is_proposal_phase: bool):\n        \"\"\"Control when topic proposals are allowed and set message type.\"\"\"\n        cls._is_topic_proposal_phase = is_proposal_phase\n        # Set the default message type based on the phase\n        cls.model_fields['message_type'].default = MessageType.TOPIC_PROPOSAL if is_proposal_phase else MessageType.CHAT\n\nclass GroupChatAction(LocalAction):\n    action: GroupChatMessage = Field(\n        description=\"The message action taken by the agent\"\n    )\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'GroupChatAction':\n        return cls(\n            agent_id=agent_id,\n            action=GroupChatMessage(content=\"Sample message\")\n        )\n\n    @classmethod\n    def action_schema(cls) -> Dict[str, Any]:\n        return GroupChatMessage.model_json_schema()\n\nclass GroupChatGlobalAction(GlobalAction):\n    actions: Dict[str, GroupChatAction] = Field(\n        description=\"Dictionary of actions by agent\"\n    )\n\nclass GroupChatObservation(BaseModel):\n    current_topic: str = Field(\n        default=\"\",\n        description=\"Current topic of discussion\"\n    )\n    agent_message: Optional[GroupChatMessage] = Field(\n        default=None,\n        description=\"Agent's own message from this round\"\n    )\n\nclass GroupChatLocalObservation(LocalObservation):\n    observation: GroupChatObservation = Field(\n        description=\"Local observation for a specific agent\"\n    )\n\nclass GroupChatGlobalObservation(GlobalObservation):\n    observations: Dict[str, GroupChatLocalObservation] = Field(\n        description=\"Dictionary of local observations by agent\"\n    )\n    round_messages: List[GroupChatMessage] = Field(\n        default_factory=list,\n        description=\"Messages from the current round\"\n    )\n    current_topic: str = Field(\n        default=\"\",\n        description=\"Current topic of discussion\"\n    )\n\nclass GroupChatActionSpace(ActionSpace):\n    allowed_actions: List[Type[LocalAction]] = Field(\n        default=[GroupChatAction],\n        description=\"Allowed actions in the group chat\"\n    )\n\nclass GroupChatObservationSpace(ObservationSpace):\n    allowed_observations: List[Type[LocalObservation]] = Field(\n        default=[GroupChatLocalObservation],\n        description=\"Allowed observations in the group chat\"\n    )\n\nclass GroupChat(Mechanism):\n    \"\"\"Mechanism that manages group chat interactions with API integration.\"\"\"\n    sequential: bool = Field(\n        default=False,\n        description=\"Whether agents speak in sequential order\"\n    )\n    current_round: int = Field(\n        default=0,\n        description=\"Current round number\"\n    )\n    max_rounds: int = Field(\n        default=3,\n        description=\"Maximum number of rounds\"\n    )\n    initial_topic: str = Field(\n        default=\"\",\n        description=\"Initial topic for discussion\"\n    )\n    form_cohorts: bool = Field(\n        default=False,\n        description=\"Whether to organize agents into cohorts\"\n    )\n    group_size: Optional[int] = Field(\n        default=None,\n        description=\"Size of chat cohorts when form_cohorts is True\"\n    )\n    api_url: str = Field(\n        default=\"http://localhost:8002\",\n        description=\"URL for the GroupChat API\"\n    )\n    cohorts: Dict[str, List[Any]] = Field(\n        default_factory=dict,\n        description=\"Mapping of cohort IDs to lists of agents\"\n    )\n    round_messages: Dict[str, List[GroupChatMessage]] = Field(\n        default_factory=lambda: {\"default\": []},\n        description=\"Messages from current round by cohort\"\n    )\n    api_utils: GroupChatAPIUtils = Field(\n        default=None,\n        description=\"API utilities for group chat\",\n        exclude=True\n    )\n    _cognitive_processor: Optional[ParallelCognitiveProcessor] = PrivateAttr(\n        default=None\n    )\n\n\n    class Config:\n        arbitrary_types_allowed = True\n\n    def model_post_init(self, __context) -> None:\n        \"\"\"Initialize API utils after model initialization.\"\"\"\n        super().model_post_init(__context)\n        if not self.api_utils:\n            self.api_utils = GroupChatAPIUtils(self.api_url, logger)\n\n    async def form_agent_cohorts(self, agents: List[Any]) -> None:\n        \"\"\"Form cohorts and initialize topics.\"\"\"\n        if not self.form_cohorts or not self.group_size:\n            return\n\n        # Register agents with API first\n        await self.api_utils.register_agents(agents)\n        \n        # Get cohort assignments from API\n        agent_ids = [agent.id for agent in agents]\n        cohorts_info = await self.api_utils.form_cohorts(agent_ids, self.group_size)\n        \n        # Store cohort information locally\n        self.cohorts.clear()\n        self.round_messages.clear()\n        \n        for cohort in cohorts_info:\n            cohort_id = cohort[\"cohort_id\"]\n            cohort_agent_ids = cohort[\"agent_ids\"]\n            cohort_agents = [agent for agent in agents if agent.id in cohort_agent_ids]\n            self.cohorts[cohort_id] = cohort_agents\n            self.round_messages[cohort_id] = []\n\n        # Initialize topics if processor is available\n        if self._cognitive_processor:\n            logger.info(\"Starting topic proposals for cohorts...\")\n            await self._initialize_cohort_topics()\n        else:\n            logger.warning(\"No cognitive processor available for topic proposals\")\n\n    async def _initialize_cohort_topics(self) -> None:\n        \"\"\"Initialize topics for all cohorts using parallel processing.\"\"\"\n        if not self.cohorts:\n            logger.warning(\"No cohorts available for topic initialization\")\n            return\n\n        # Prepare proposer agents\n        proposer_agents = []\n        proposer_info = []\n\n        for cohort_id, cohort_agents in self.cohorts.items():\n            # First select a proposer through the API\n            proposer_id = await self.api_utils.select_proposer(\n                cohort_id=cohort_id,\n                agent_ids=[agent.id for agent in cohort_agents]\n            )\n            if not proposer_id:\n                logger.error(f\"Failed to select proposer for cohort {cohort_id}\")\n                continue\n\n            # Find the proposer agent\n            proposer = next((agent for agent in cohort_agents if agent.id == proposer_id), None)\n            if not proposer:\n                logger.error(f\"Selected proposer {proposer_id} not found in cohort {cohort_id}\")\n                continue\n\n            logger.info(f\"Setting up topic proposer {proposer.id} for cohort {cohort_id}\")\n            proposer.task = (\n                f\"You are the group chat topic proposer. \"\n                f\"Propose a topic related to {self.initial_topic}, explaining why it matters.\"\n            )\n            proposer_agents.append(proposer)\n            proposer_info.append((cohort_id, proposer.id))\n\n        # Run parallel action for all proposers\n        GroupChatMessage.set_topic_proposal_phase(True)\n        if proposer_agents and self._cognitive_processor:\n            try:\n                logger.info(f\"Running parallel topic proposals for {len(proposer_agents)} cohorts\")\n                outputs = await self._cognitive_processor.run_parallel_action(\n                    agents=proposer_agents,\n                    environment_name=\"group_chat\"\n                )\n                \n                # Process results and update topics\n                for (cohort_id, proposer_id), output in zip(proposer_info, outputs):\n                    topic = self._extract_topic_from_proposal(output)\n                    if topic:\n                        await self.api_utils.propose_topic(\n                            agent_id=proposer_id,\n                            cohort_id=cohort_id,\n                            topic=topic,\n                            round_num=0\n                        )\n                        # Use the logger utility instead of direct logging\n                        from market_agents.orchestrators.logger_utils import log_topic_proposal\n                        log_topic_proposal(logger, cohort_id, proposer_id.replace('agent_', ''), topic)\n                    else:\n                        logger.warning(f\"Failed to extract topic from proposal for cohort {cohort_id}\")\n            except Exception as e:\n                logger.error(f\"Error during topic proposal: {str(e)}\", exc_info=True)\n                raise\n            finally:\n                GroupChatMessage.set_topic_proposal_phase(False)\n\n    def _extract_topic_from_proposal(self, proposal) -> Optional[str]:\n        \"\"\"Extract topic from LLM response.\"\"\"\n        try:\n            if proposal and proposal.json_object:\n                root_obj = proposal.json_object.object\n                if \"action\" in root_obj and \"content\" in root_obj[\"action\"]:\n                    return root_obj[\"action\"][\"content\"]\n            return proposal.str_content.strip() if proposal.str_content else None\n        except Exception as e:\n            logger.error(f\"Error extracting topic: {e}\")\n            return None\n\n    def step(\n        self,\n        action: Union[GroupChatAction, GroupChatGlobalAction, GlobalAction],\n        cohort_id: Optional[str] = None\n    ) -> Union[LocalEnvironmentStep, EnvironmentStep]:\n        \"\"\"Execute a step in the environment.\"\"\"\n        # Check if we're done before incrementing\n        done = self.current_round >= self.max_rounds - 1\n\n        # Use provided cohort_id or default\n        effective_cohort = cohort_id if cohort_id else \"default\"\n        \n        # Initialize cohort's round_messages if needed\n        if effective_cohort not in self.round_messages:\n            self.round_messages[effective_cohort] = []\n\n        # Handle single agent action (sequential mode)\n        if isinstance(action, LocalAction):\n            # Extract message from action\n            if isinstance(action.action, dict):\n                content = action.action.get('action', {}).get('content', '')\n                message_type = action.action.get('action', {}).get('message_type', MessageType.CHAT)\n            elif isinstance(action.action, GroupChatMessage):\n                content = action.action.content\n                message_type = action.action.message_type\n            else:\n                content = str(action.action)\n                message_type = MessageType.CHAT\n\n            # Create message\n            action_content = GroupChatMessage(\n                content=content,\n                message_type=message_type\n            )\n\n            # Store the message in a format that matches what we're logging\n            self.round_messages[effective_cohort].append({\n                \"content\": content,\n                \"message_type\": message_type,\n                \"agent_id\": action.agent_id\n            })\n\n            # Post message to API if cohort_id provided\n            if cohort_id:\n                asyncio.create_task(\n                    self.api_utils.post_message(\n                        agent_id=action.agent_id,\n                        cohort_id=cohort_id,\n                        content=action_content.content,\n                        round_num=self.current_round,\n                        sub_round_num=0\n                    )\n                )\n\n            # Create and return local step\n            obs = GroupChatObservation(\n                current_topic=self.initial_topic,\n                agent_message=action_content\n            )\n            local_obs = GroupChatLocalObservation(\n                agent_id=action.agent_id,\n                observation=obs\n            )\n            local_step = LocalEnvironmentStep(\n                observation=local_obs,\n                done=done,\n                info={\n                    \"round\": self.current_round,\n                    \"cohort_id\": effective_cohort\n                }\n            )\n            \n            # Increment round counter after processing if sequential\n            if self.sequential:\n                self.current_round += 1\n            return local_step\n\n        # Handle global actions (batch mode)\n        else:\n            # Convert action to GroupChatGlobalAction if needed\n            if isinstance(action, GlobalAction):\n                chat_actions = {}\n                for agent_id, local_action in action.actions.items():\n                    # Extract message from action\n                    if isinstance(local_action.action, dict):\n                        content = local_action.action.get('action', {}).get('content', '')\n                        message_type = local_action.action.get('action', {}).get('message_type', MessageType.CHAT)\n                    elif isinstance(local_action.action, GroupChatMessage):\n                        content = local_action.action.content\n                        message_type = local_action.action.message_type\n                    else:\n                        content = str(local_action.action)\n                        message_type = MessageType.CHAT\n\n                    chat_actions[agent_id] = GroupChatAction(\n                        agent_id=agent_id,\n                        action=GroupChatMessage(\n                            content=content,\n                            message_type=message_type\n                        )\n                    )\n                action = GroupChatGlobalAction(actions=chat_actions)\n\n            # Store messages for this round\n            for agent_id, local_action in action.actions.items():\n                self.round_messages[effective_cohort].append({\n                    \"content\": local_action.action.content,\n                    \"message_type\": local_action.action.message_type,\n                    \"agent_id\": agent_id\n                })\n\n            # Post messages to API if cohort_id provided\n            if cohort_id:\n                for agent_id, local_action in action.actions.items():\n                    asyncio.create_task(\n                        self.api_utils.post_message(\n                            agent_id=agent_id,\n                            cohort_id=cohort_id,\n                            content=local_action.action.content,\n                            round_num=self.current_round,\n                            sub_round_num=0\n                        )\n                    )\n\n            # Create observations for each agent\n            observations = {}\n            for agent_id, local_action in action.actions.items():\n                observations[agent_id] = GroupChatLocalObservation(\n                    agent_id=agent_id,\n                    observation=GroupChatObservation(\n                        current_topic=self.initial_topic,\n                        agent_message=local_action.action\n                    )\n                )\n\n            # Create global observation\n            global_obs = GroupChatGlobalObservation(\n                observations=observations,\n                round_messages=self.round_messages[effective_cohort],\n                current_topic=self.initial_topic\n            )\n\n            # Create global step\n            global_step = EnvironmentStep(\n                global_observation=global_obs,\n                done=done,\n                info={\n                    \"round\": self.current_round,\n                    \"cohort_id\": effective_cohort\n                }\n            )\n\n            # Increment round counter after processing batch\n            self.current_round += 1\n            return global_step\n\n    def get_global_state(self, agent_id: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Get global state, filtered by agent's cohort if specified.\"\"\"\n        state = {\n            \"current_round\": self.current_round,\n            \"current_topic\": self.initial_topic,\n            \"max_rounds\": self.max_rounds\n        }\n\n        if self.form_cohorts:\n            if agent_id:\n                # Find agent's cohort\n                cohort_id = next(\n                    (cid for cid, agents in self.cohorts.items() \n                    if any(a.id == agent_id for a in agents)),\n                    None\n                )\n                if cohort_id:\n                    state.update({\n                        \"cohort_id\": cohort_id,\n                        \"cohort_agents\": [a.id for a in self.cohorts[cohort_id]],\n                        \"round_messages\": self.round_messages.get(cohort_id, [])\n                    })\n            else:\n                # Return all cohorts' information\n                state.update({\n                    \"cohorts\": {\n                        cid: [a.id for a in agents] \n                        for cid, agents in self.cohorts.items()\n                    },\n                    \"round_messages\": self.round_messages\n                })\n        else:\n            # Not using cohorts, return all messages\n            state[\"round_messages\"] = self.round_messages.get(\"default\", [])\n\n        return state\n\n    def reset(self) -> None:\n        \"\"\"Reset the chat state.\"\"\"\n        self.current_round = 0\n        self.round_messages = {\"default\": []}\n        self.cohorts.clear()\n        logger.info(\"GroupChat mechanism has been reset\")\n\nclass GroupChatEnvironment(MultiAgentEnvironment):\n    \"\"\"Multi-agent environment that orchestrates a group chat session.\"\"\"\n    name: str = Field(default=\"group_chat\", description=\"Name of the environment\")\n    address: str = Field(default=\"group_chat\", description=\"Address of the environment\")\n    max_steps: int = Field(default=3, description=\"Maximum number of steps\")\n    action_space: GroupChatActionSpace = Field(\n        default_factory=GroupChatActionSpace,\n        description=\"Defines the action space for chat messages\"\n    )\n    observation_space: GroupChatObservationSpace = Field(\n        default_factory=GroupChatObservationSpace,\n        description=\"Observation space\"\n    )\n    mechanism: GroupChat = Field(\n        default_factory=lambda: GroupChat(max_rounds=3, sequential=False),\n        description=\"The group chat mechanism\"\n    )\n\n    class Config:\n        arbitrary_types_allowed = True\n\n    def __init__(self, **config):\n        try:\n            # Extract mechanism-specific config\n            mechanism_config = {\n                'sequential': config.get('sequential', False),\n                'max_rounds': config.get('max_rounds', 3),\n                'form_cohorts': config.get('form_cohorts', False),\n                'group_size': config.get('group_size'),\n                'api_url': config.get('api_url', 'http://localhost:8002'),\n                'initial_topic': config.get('initial_topic', '')\n            }\n\n            # Initialize mechanism\n            mechanism = GroupChat(**mechanism_config)\n\n            # Initialize parent class with required fields\n            parent_config = {\n                'name': config.get('name', 'group_chat'),\n                'address': config.get('address', 'group_chat'),\n                'max_steps': config.get('max_steps', 3),\n                'action_space': GroupChatActionSpace(),\n                'observation_space': GroupChatObservationSpace(),\n                'mechanism': mechanism\n            }\n            super().__init__(**parent_config)\n\n            # Initialize cognitive processor if ai_utils provided\n            if 'ai_utils' in config and 'storage_service' in config:\n                self.mechanism._cognitive_processor = ParallelCognitiveProcessor(\n                    ai_utils=config['ai_utils'],\n                    storage_service=config['storage_service'],\n                    logger=logging.getLogger(__name__),\n                    tool_mode=config.get('tool_mode', False)\n                )\n\n        except Exception as e:\n            raise ValueError(f\"Failed to initialize GroupChatEnvironment: {e}\")\n\n    def step(self, action: GlobalAction, cohort_id: Optional[str] = None) -> EnvironmentStep:\n        \"\"\"Execute a step in the environment with optional cohort_id.\"\"\"\n        return self.mechanism.step(action, cohort_id=cohort_id)\n\n    def reset(self) -> GlobalObservation:\n        \"\"\"Reset the environment.\"\"\"\n        self.mechanism.reset()\n        if self.initial_topic:\n            self.mechanism.initial_topic = self.initial_topic\n        return GlobalObservation(observations={})\n\n    def get_global_state(self, agent_id: str = None) -> Dict[str, Any]:\n        \"\"\"Return the environment's global state with filtered mechanism state.\"\"\"\n        mechanism_state = self.mechanism.get_global_state(agent_id) if agent_id else self.mechanism.get_global_state()\n        \n        return {\n            **mechanism_state,\n            \"current_step\": self.mechanism.current_round,\n            \"max_steps\": self.mechanism.max_rounds\n        }"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/crypto.py", "content": "# crypto_market.py\n\nfrom datetime import datetime\nimport logging\nimport random\nfrom typing import Any, List, Dict, Type, Optional, Tuple\nimport uuid\nfrom pydantic import BaseModel, Field, field_validator, ConfigDict\nfrom market_agents.environments.environment import (\n    EnvironmentHistory, Mechanism, LocalAction, GlobalAction, LocalObservation, GlobalObservation,\n    EnvironmentStep, ActionSpace, ObservationSpace, MultiAgentEnvironment\n)\nfrom market_agents.memecoin_orchestrators.crypto_models import OrderType, MarketAction, Trade\nfrom market_agents.memecoin_orchestrators.crypto_agent import CryptoEconomicAgent\nfrom agent_evm_interface.agent_evm_interface import EthereumInterface\nlogger = logging.getLogger(__name__)\n\n\nclass MarketSummary(BaseModel):\n    \"\"\"Summary of market activity for multiple tokens\"\"\"\n    trades_count: int = Field(default=0, description=\"Total number of trades across all tokens\")\n    token_summaries: Dict[str, Dict[str, Any]] = Field(\n        default_factory=dict,\n        description=\"Summary statistics for each token\"\n    )\n\nclass CryptoMarketAction(LocalAction):\n    action: MarketAction\n\n    @field_validator('action')\n    def validate_action(cls, v):\n        if v.order_type in [OrderType.BUY, OrderType.SELL]:\n            if v.quantity <= 0:\n                raise ValueError(\"Quantity must be positive for buy and sell orders\")\n            if v.price <= 0:\n                raise ValueError(\"Price must be positive for buy and sell orders\")\n        return v\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'CryptoMarketAction':\n        order_type = random.choice(list(OrderType))\n        if order_type == OrderType.HOLD:\n            action = MarketAction(order_type=order_type)\n        else:\n            random_price = random.uniform(0.01, 1.0)\n            random_quantity = random.randint(1, 1000)\n            action = MarketAction(\n                order_type=order_type,\n                price=random_price,\n                quantity=random_quantity,\n                token=\"USDC\")\n        return cls(agent_id=agent_id, action=action)\n\n    @classmethod\n    def action_schema(cls) -> Dict[str, Any]:\n        return MarketAction.model_json_schema()\n\n\nclass GlobalCryptoMarketAction(GlobalAction):\n    actions: Dict[str, CryptoMarketAction]\n\n\nclass CryptoMarketObservation(BaseModel):\n    \"\"\"Observation of the crypto market state for an agent\"\"\"\n    trades: List[Trade] = Field(\n        default_factory=list, \n        description=\"List of trades the agent participated in\"\n    )\n    market_summary: MarketSummary = Field(\n        default_factory=MarketSummary, \n        description=\"Summary of market activity\"\n    )\n    current_prices: Dict[str, float] = Field(\n        default_factory=dict,\n        description=\"Current prices for each supported token\"\n    )\n    portfolio_value: float = Field(\n        default=0.0, \n        description=\"Total value of the agent's portfolio in USDC\"\n    )\n    eth_balance: int = Field(\n        default=0, \n        description=\"Agent's ETH balance in wei\"\n    )\n    token_balances: Dict[str, float] = Field(\n        default_factory=dict,\n        description=\"Map of token symbol to balance\"\n    )\n    price_histories: Dict[str, List[float]] = Field(\n        default_factory=dict,\n        description=\"Historical prices for each supported token\"\n    )\n\n\nclass CryptoMarketLocalObservation(BaseModel):\n    \"\"\"Local observation for an individual agent in the crypto market\"\"\"\n    agent_id: str\n    observation: CryptoMarketObservation\n\n\nclass CryptoMarketGlobalObservation(GlobalObservation):\n    observations: Dict[str, CryptoMarketLocalObservation]\n    all_trades: List[Trade] = Field(default_factory=list, description=\"All trades executed in this round\")\n    market_summary: MarketSummary = Field(default_factory=MarketSummary, description=\"Summary of market activity\")\n    current_prices: Dict[str, float] = Field(default_factory=dict, description=\"Current market prices\")\n    price_histories: Dict[str, List[float]] = Field(default_factory=dict, description=\"Historical prices\")\n\nclass CryptoMarketActionSpace(ActionSpace):\n    allowed_actions: List[Type[LocalAction]] = [CryptoMarketAction]\n\n    @classmethod\n    def get_action_schema(cls) -> Dict[str, Any]:\n        return MarketAction.model_json_schema()\n\n\nclass CryptoMarketObservationSpace(ObservationSpace):\n    allowed_observations: List[Type[LocalObservation]] = [CryptoMarketLocalObservation]\n\n\nclass CryptoMarketMechanism(Mechanism):\n    max_rounds: int = Field(default=100, description=\"Maximum number of trading rounds\")\n    current_round: int = Field(default=0, description=\"Current round number\")\n    trades: List[Trade] = Field(default_factory=list, description=\"List of executed trades\")\n    tokens: List[str] = Field(default=[\"DOGE\"], description=\"List of supported tokens\")\n    current_prices: Dict[str, float] = Field(\n        default_factory=lambda: {\"DOGE\": 0.1},\n        description=\"Current market prices for each token\"\n    )\n    price_histories: Dict[str, List[float]] = Field(\n        default_factory=lambda: {\"DOGE\": [0.1]},\n        description=\"Price history for each token\"\n    )\n    \n    sequential: bool = Field(default=False, description=\"Whether the mechanism is sequential\")\n    agent_registry: Dict[str, Any] = Field(default_factory=dict, description=\"Registry of agents\")\n    ethereum_interface: EthereumInterface = Field(\n        default_factory=EthereumInterface,\n        description=\"Ethereum Interface\"\n    )\n    token_addresses: Dict[str, str] = Field(\n        default_factory=dict,\n        description=\"Mapping of token symbols to addresses\"\n    )\n    orderbook_address: str = Field(default=\"\", description=\"Orderbook contract address\")\n    minter_private_key: str = Field(default=\"\", description=\"Private key of the minter account\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def register_agent(self, agent_id: str, agent: CryptoEconomicAgent):\n        \"\"\"Register an agent with the mechanism.\"\"\"\n        if not isinstance(agent, CryptoEconomicAgent):\n            raise ValueError(f\"Agent must be a CryptoEconomicAgent, got {type(agent)}\")\n        \n        self.agent_registry[str(agent_id)] = agent\n        logger.info(f\"Registered agent {agent_id} with address {agent.ethereum_address}\")\n\n    def setup(self):\n        \"\"\"Initialize token addresses, blockchain parameters, and current prices.\"\"\"\n        self.token_addresses = self.ethereum_interface.testnet_data['token_addresses']\n        self.orderbook_address = self.ethereum_interface.testnet_data['orderbook_address']\n        self.minter_private_key = self.ethereum_interface.accounts[0]['private_key']\n        \n        # Initialize prices for all supported tokens\n        quote_address = self.ethereum_interface.get_token_address('USDC')\n        \n        for token in self.tokens:\n            try:\n                token_address = self.ethereum_interface.get_token_address(token)\n                if not token_address:\n                    logger.warning(f\"Address not found for token {token}\")\n                    continue\n                    \n                pair_info = self.ethereum_interface.get_pair_info(\n                    token_address,\n                    quote_address\n                )\n                \n                base_unit_price = pair_info['token0_price_in_token1']\n                self.current_prices[token] = base_unit_price / 1e18\n                if self.current_prices[token] == 0:\n                    self.current_prices[token] = 0.1\n                    \n                # Initialize price history\n                if token not in self.price_histories:\n                    self.price_histories[token] = [self.current_prices[token]]\n                    \n            except Exception as e:\n                logger.warning(f\"Failed to get initial price for {token}: {str(e)}. Using default price of 0.1\")\n                self.current_prices[token] = 0.1\n                self.price_histories[token] = [0.1]\n\n    def step(self, action: GlobalCryptoMarketAction) -> EnvironmentStep:\n        \"\"\"Execute one step in the mechanism\"\"\"\n        self.current_round += 1\n\n        # Process actions and collect new trades\n        new_trades = self._process_actions(action.actions)\n        \n        # Update prices based on new trades\n        self._update_price(new_trades)\n        \n        # Create market summary and observations\n        market_summary = self._create_market_summary(new_trades)\n        observations = self._create_observations(market_summary)\n        \n        # Store trades in mechanism history\n        self.trades.extend(new_trades)\n\n        # Check if simulation is done\n        done = self.current_round >= self.max_rounds\n\n        return EnvironmentStep(\n            global_observation=CryptoMarketGlobalObservation(\n                observations=observations,\n                all_trades=new_trades,\n                market_summary=market_summary,\n                current_prices=self.current_prices.copy(),\n                price_histories=self.price_histories.copy()\n            ),\n            done=done,\n            current_round=self.current_round,  # Pass the current round\n            info={\n                \"market_prices\": self.current_prices\n            }\n        )\n    \n    def _process_actions(self, actions: Dict[str, MarketAction]) -> List[Trade]:\n        \"\"\"Process all market actions and return list of executed trades.\"\"\"\n        trades = []\n        \n        for agent_id, market_action in actions.items():\n            try:\n                agent = self.agent_registry.get(agent_id)\n                if not agent:\n                    logger.error(f\"Agent {agent_id} not found in registry\")\n                    continue\n\n                if market_action.action.order_type == OrderType.BUY:\n                    trade = self._execute_buy(agent, market_action.action)\n                    if trade:\n                        trades.append(trade)\n                        self.trades.append(trade)\n                        \n                elif market_action.action.order_type == OrderType.SELL:\n                    trade = self._execute_sell(agent, market_action.action)\n                    if trade:\n                        trades.append(trade)\n                        self.trades.append(trade)\n                        \n                # HOLD orders require no execution\n                \n            except Exception as e:\n                logger.error(f\"Error processing action for agent {agent_id}: {str(e)}\")\n                logger.error(\"Exception details:\", exc_info=True)\n                continue\n\n        return trades\n    \n    def _create_market_summary(self, trades: List[Trade]) -> MarketSummary:\n        \"\"\"Create market summary from trades, supporting multiple tokens\"\"\"\n        if not trades:\n            # Create empty summary with current prices for all tokens\n            token_summaries = {}\n            for token in self.tokens:\n                current_price = self.current_prices.get(token, 0.1)\n                token_summaries[token] = {\n                    'trades_count': 0,\n                    'average_price': current_price,\n                    'total_volume': 0,\n                    'price_range': (current_price, current_price)\n                }\n            return MarketSummary(\n                trades_count=0,\n                token_summaries=token_summaries\n            )\n\n        # Group trades by token\n        trades_by_token = {}\n        for trade in trades:\n            if trade.coin not in trades_by_token:\n                trades_by_token[trade.coin] = []\n            trades_by_token[trade.coin].append(trade)\n\n        # Calculate summary for each token\n        token_summaries = {}\n        for token in self.tokens:\n            token_trades = trades_by_token.get(token, [])\n            if token_trades:\n                prices = [t.price for t in token_trades]\n                volumes = [t.quantity for t in token_trades]\n                token_summaries[token] = {\n                    'trades_count': len(token_trades),\n                    'average_price': sum(prices) / len(prices),\n                    'total_volume': sum(volumes),\n                    'price_range': (min(prices), max(prices))\n                }\n            else:\n                current_price = self.current_prices.get(token, 0.1)\n                token_summaries[token] = {\n                    'trades_count': 0,\n                    'average_price': current_price,\n                    'total_volume': 0,\n                    'price_range': (current_price, current_price)\n                }\n\n        # Create overall summary\n        return MarketSummary(\n            trades_count=len(trades),\n            token_summaries=token_summaries\n        )\n\n    def _create_observations(self, market_summary: MarketSummary) -> Dict[str, CryptoMarketLocalObservation]:\n        \"\"\"Create observations for all agents, including multi-token balances\"\"\"\n        observations = {}\n        \n        for agent_id, agent in self.agent_registry.items():\n            # Get balances for all supported tokens\n            token_balances = {}\n            portfolio_value = 0.0\n            \n            # Get USDC balance first\n            usdc_address = self.ethereum_interface.get_token_address('USDC')\n            usdc_info = self.ethereum_interface.get_erc20_info(usdc_address)\n            usdc_balance = self.ethereum_interface.get_erc20_balance(\n                agent.ethereum_address,\n                usdc_address\n            ) / (10 ** usdc_info['decimals'])\n            token_balances['USDC'] = usdc_balance\n            portfolio_value += usdc_balance\n\n            # Get balances for all trading tokens\n            for token in self.tokens:\n                token_address = self.ethereum_interface.get_token_address(token)\n                if not token_address:\n                    continue\n                    \n                token_info = self.ethereum_interface.get_erc20_info(token_address)\n                balance = self.ethereum_interface.get_erc20_balance(\n                    agent.ethereum_address,\n                    token_address\n                ) / (10 ** token_info['decimals'])\n                \n                current_price = self.current_prices.get(token, 0)\n                token_balances[token] = balance\n                portfolio_value += balance * current_price\n\n            base_observation = CryptoMarketObservation(\n                trades=self.trades,\n                market_summary=market_summary,\n                current_prices=self.current_prices.copy(),\n                portfolio_value=portfolio_value,\n                eth_balance=self.ethereum_interface.get_eth_balance(agent.ethereum_address),\n                token_balances=token_balances,\n                price_histories=self.price_histories.copy()\n            )\n\n            observations[agent_id] = CryptoMarketLocalObservation(\n                agent_id=agent_id,\n                observation=base_observation\n            )\n\n        return observations\n\n    def _update_price(self, trades: List[Trade]) -> None:\n        \"\"\"Update prices for all tokens based on recent trades\"\"\"\n        if not trades:\n            return\n\n        # Group trades by token\n        trades_by_token = {}\n        for trade in trades:\n            if trade.coin not in trades_by_token:\n                trades_by_token[trade.coin] = []\n            trades_by_token[trade.coin].append(trade)\n\n        # Update prices for each token\n        for token, token_trades in trades_by_token.items():\n            if token not in self.current_prices:\n                self.current_prices[token] = 0.1\n                self.price_histories[token] = [0.1]\n\n            # Calculate volume-weighted average price\n            total_volume = sum(t.quantity for t in token_trades)\n            if total_volume > 0:\n                vwap = sum(t.price * t.quantity for t in token_trades) / total_volume\n                self.current_prices[token] = vwap\n                self.price_histories[token].append(vwap)\n\n    def _execute_p2p_trade(self, buyer: CryptoEconomicAgent, seller: CryptoEconomicAgent, \n                          price: float, quantity: int) -> None:\n        \"\"\"Execute a peer-to-peer trade between two agents.\"\"\"\n        # Get token addresses\n        token_address = self.ethereum_interface.get_token_address(self.coin_name)\n        usdc_address = self.ethereum_interface.get_token_address('USDC')\n        \n        # Get decimals\n        token_decimals = self.ethereum_interface.get_erc20_info(token_address)['decimals']\n        usdc_decimals = self.ethereum_interface.get_erc20_info(usdc_address)['decimals']\n        \n        # Convert amounts to proper decimals\n        usdc_amount = int(price * quantity * (10 ** usdc_decimals))\n        token_amount = int(quantity * (10 ** token_decimals))\n\n        # Verify balances\n        if not self._verify_balances(buyer, seller, usdc_amount, token_amount, usdc_address, token_address):\n            raise ValueError(\"Insufficient balance for trade\")\n\n        # Execute the transfers\n        self._transfer_tokens(buyer, seller, usdc_amount, token_amount, usdc_address, token_address)\n\n    def _verify_balances(self, buyer: CryptoEconomicAgent, seller: CryptoEconomicAgent,\n                    usdc_amount: int, token_amount: int,\n                    usdc_address: str, token_address: str, token: str) -> bool:\n        \"\"\"Verify that both parties have sufficient balances for the trade.\"\"\"\n        try:\n            # Check buyer's USDC balance\n            buyer_usdc_balance = self.ethereum_interface.get_erc20_balance(\n                buyer.ethereum_address,\n                usdc_address\n            )\n            if buyer_usdc_balance < usdc_amount:\n                logger.error(f\"Buyer {buyer.id} has insufficient USDC balance. \" +\n                           f\"Has: {buyer_usdc_balance}, Needs: {usdc_amount}\")\n                return False\n\n            # Check seller's token balance\n            seller_token_balance = self.ethereum_interface.get_erc20_balance(\n                seller.ethereum_address,\n                token_address\n            )\n            if seller_token_balance < token_amount:\n                logger.error(f\"Seller {seller.id} has insufficient {self.coin_name} balance. \" +\n                           f\"Has: {seller_token_balance}, Needs: {token_amount}\")\n                return False\n\n            # Check allowances\n            buyer_usdc_allowance = self.ethereum_interface.get_erc20_allowance(\n                owner=buyer.ethereum_address,\n                spender=self.orderbook_address,\n                contract_address=usdc_address\n            )\n            if buyer_usdc_allowance < usdc_amount:\n                tx_hash = self.ethereum_interface.approve_erc20(\n                    spender=self.orderbook_address,\n                    amount=usdc_amount,\n                    contract_address=usdc_address,\n                    private_key=buyer.private_key\n                )\n                logger.info(f\"Buyer {buyer.id} approved {usdc_amount} USDC. TxHash: {tx_hash}\")\n\n            seller_token_allowance = self.ethereum_interface.get_erc20_allowance(\n                owner=seller.ethereum_address,\n                spender=self.orderbook_address,\n                contract_address=token_address\n            )\n            if seller_token_allowance < token_amount:\n                tx_hash = self.ethereum_interface.approve_erc20(\n                    spender=self.orderbook_address,\n                    amount=token_amount,\n                    contract_address=token_address,\n                    private_key=seller.private_key\n                )\n                logger.info(f\"Seller {seller.id} approved {token_amount} {token}. TxHash: {tx_hash}\")\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Error verifying balances: {str(e)}\")\n            return False\n\n    def _transfer_tokens(self, buyer, seller, usdc_amount, token_amount, usdc_address, token_address):\n        try:\n            # Transfer USDC from buyer to seller\n            tx_hash = self.ethereum_interface.send_erc20(\n                to=seller.ethereum_address,\n                amount=usdc_amount,\n                contract_address=usdc_address,\n                private_key=buyer.private_key\n            )\n            logger.info(f\"USDC transfer tx hash: {tx_hash}\")\n\n            # Transfer tokens from seller to buyer\n            tx_hash = self.ethereum_interface.send_erc20(\n                to=buyer.ethereum_address,\n                amount=token_amount,\n                contract_address=token_address,\n                private_key=seller.private_key\n            )\n            logger.info(f\"Token transfer tx hash: {tx_hash}\")\n        except Exception as e:\n            logger.error(f\"Error executing transfers: {str(e)}\")\n            raise\n\n    def _execute_buy(self, agent: CryptoEconomicAgent, market_action: MarketAction) -> Optional[Trade]:\n        \"\"\"Agent buys tokens using USDC.\"\"\"\n        source_token_address = self.ethereum_interface.get_token_address('USDC')\n        target_token_address = self.ethereum_interface.get_token_address(market_action.token)\n        \n        if not target_token_address:\n            logger.error(f\"Token address not found for {market_action.token}\")\n            return None\n\n        try:\n            # Get token decimals\n            usdc_decimals = self.ethereum_interface.get_erc20_info(source_token_address)['decimals']\n            token_decimals = self.ethereum_interface.get_erc20_info(target_token_address)['decimals']\n\n            # Convert amounts to proper decimals\n            usdc_amount = int(market_action.price * market_action.quantity * (10 ** usdc_decimals))\n            token_amount = int(market_action.quantity * (10 ** token_decimals))\n\n            # Check USDC balance\n            usdc_balance = self.ethereum_interface.get_erc20_balance(\n                agent.ethereum_address,\n                source_token_address\n            )\n            if usdc_balance < usdc_amount:\n                logger.error(f\"Agent {agent.id} has insufficient USDC balance. \" + \n                            f\"Has: {usdc_balance / 10**usdc_decimals}, \" +\n                            f\"Needs: {market_action.price * market_action.quantity}\")\n                return None\n\n            # Check and update allowance if needed\n            allowance = self.ethereum_interface.get_erc20_allowance(\n                owner=agent.ethereum_address,\n                spender=self.orderbook_address,\n                contract_address=source_token_address\n            )\n            \n            if allowance < usdc_amount:\n                tx_hash = self.ethereum_interface.approve_erc20(\n                    spender=self.orderbook_address,\n                    amount=usdc_amount,\n                    contract_address=source_token_address,\n                    private_key=agent.private_key\n                )\n                logger.info(f\"Agent {agent.id} approved {usdc_amount/(10**usdc_decimals)} USDC. TxHash: {tx_hash}\")\n\n            # Execute the swap\n            tx_hash = self.ethereum_interface.swap(\n                source_token_address=source_token_address,\n                source_token_amount=usdc_amount,\n                target_token_address=target_token_address,\n                private_key=agent.private_key\n            )\n            logger.info(f\"Agent {agent.id} executed buy {market_action.quantity} {market_action.token} \" +\n                    f\"for {usdc_amount/(10**usdc_decimals)} USDC. TxHash: {tx_hash}\")\n\n            return Trade(\n                trade_id=len(self.trades),\n                buyer_id=agent.id,\n                seller_id=\"MARKET_MAKER\",\n                price=market_action.price,\n                bid_price=market_action.price,\n                ask_price=market_action.price,\n                quantity=market_action.quantity,\n                coin=market_action.token,\n                tx_hash=tx_hash,\n                timestamp=datetime.now(),\n                action_type=\"BUY\"\n            )\n\n        except Exception as e:\n            logger.error(f\"Error executing buy for agent {agent.id}: {str(e)}\")\n            return None\n\n    def _execute_sell(self, agent: CryptoEconomicAgent, market_action: MarketAction) -> Optional[Trade]:\n        \"\"\"Agent sells tokens for USDC.\"\"\"\n        source_token_address = self.ethereum_interface.get_token_address(market_action.token)\n        target_token_address = self.ethereum_interface.get_token_address('USDC')\n        \n        if not source_token_address:\n            logger.error(f\"Token address not found for {market_action.token}\")\n            return None\n\n        try:\n            # Get token decimals\n            token_decimals = self.ethereum_interface.get_erc20_info(source_token_address)['decimals']\n            usdc_decimals = self.ethereum_interface.get_erc20_info(target_token_address)['decimals']\n\n            # Convert quantity to proper decimals\n            token_amount = int(market_action.quantity * (10 ** token_decimals))\n\n            # Check token balance\n            token_balance = self.ethereum_interface.get_erc20_balance(\n                agent.ethereum_address,\n                source_token_address\n            )\n            if token_balance < token_amount:\n                logger.error(f\"Agent {agent.id} has insufficient {market_action.token} balance. \" +\n                            f\"Has: {token_balance/(10**token_decimals)}, \" +\n                            f\"Needs: {market_action.quantity}\")\n                return None\n\n            # Check and update allowance if needed\n            allowance = self.ethereum_interface.get_erc20_allowance(\n                owner=agent.ethereum_address,\n                spender=self.orderbook_address,\n                contract_address=source_token_address\n            )\n            \n            if allowance < token_amount:\n                tx_hash = self.ethereum_interface.approve_erc20(\n                    spender=self.orderbook_address,\n                    amount=token_amount,\n                    contract_address=source_token_address,\n                    private_key=agent.private_key\n                )\n                logger.info(f\"Agent {agent.id} approved {market_action.quantity} {market_action.token}. TxHash: {tx_hash}\")\n\n            # Execute the swap\n            tx_hash = self.ethereum_interface.swap(\n                source_token_address=source_token_address,\n                source_token_amount=token_amount,\n                target_token_address=target_token_address,\n                private_key=agent.private_key\n            )\n            logger.info(f\"Agent {agent.id} executed sell {market_action.quantity} {market_action.token} \" +\n                    f\"for {market_action.price * market_action.quantity} USDC. TxHash: {tx_hash}\")\n\n            return Trade(\n                trade_id=len(self.trades),\n                buyer_id=\"MARKET_MAKER\",\n                seller_id=agent.id,\n                price=market_action.price,\n                bid_price=market_action.price,\n                ask_price=market_action.price,\n                quantity=market_action.quantity,\n                coin=market_action.token,\n                tx_hash=tx_hash,\n                timestamp=datetime.now(),\n                action_type=\"SELL\"\n            )\n\n        except Exception as e:\n            logger.error(f\"Error executing sell for agent {agent.id}: {str(e)}\")\n            return None\n    \n    def _convert_to_decimal_price(self, base_unit_price: int, decimals: int = 18) -> float:\n        return base_unit_price / (10 ** decimals)\n\n    def _convert_to_base_units(self, decimal_price: float, decimals: int = 18) -> int:\n        return int(decimal_price * (10 ** decimals))\n\n    def get_global_state(self) -> Dict[str, Any]:\n        \"\"\"Get the current global state of the mechanism\"\"\"\n        return {\n            \"trades\": self.trades,\n            \"current_prices\": self.current_prices,\n            \"price_histories\": self.price_histories,\n            \"current_round\": self.current_round,\n            \"max_rounds\": self.max_rounds,\n            \"tokens\": self.tokens,\n            \"market_summary\": self._create_market_summary(self.trades)\n        }\n\n    def reset(self) -> None:\n        \"\"\"Reset the mechanism state\"\"\"\n        self.current_round = 0\n        self.trades = []\n        \n        # Reset prices for all tokens\n        for token in self.tokens:\n            self.current_prices[token] = 0.1\n            self.price_histories[token] = [0.1]\n\nclass CryptoMarket(MultiAgentEnvironment):\n    name: str = Field(default=\"Crypto Market\", description=\"Name of the crypto market\")\n    action_space: CryptoMarketActionSpace = Field(default_factory=CryptoMarketActionSpace, description=\"Action space of the crypto market\")\n    observation_space: CryptoMarketObservationSpace = Field(default_factory=CryptoMarketObservationSpace, description=\"Observation space of the crypto market\")\n    mechanism: CryptoMarketMechanism = Field(default_factory=CryptoMarketMechanism, description=\"Mechanism of the crypto market\")\n    agents: Dict[str, CryptoEconomicAgent] = Field(default_factory=dict, description=\"Dictionary of agents in the market\")\n\n    def __init__(self, agents: Dict[str, CryptoEconomicAgent], **kwargs):\n        super().__init__(**kwargs)\n        self.agents = agents\n        self.mechanism.agent_registry = {}\n        \n        # Fix: Properly register agents with string IDs\n        for agent_id, agent in agents.items():\n            str_id = str(agent_id)\n            if hasattr(agent, 'economic_agent'):\n                # If agent is wrapped, register the economic agent\n                self.mechanism.agent_registry[str_id] = agent.economic_agent\n            else:\n                # If agent is direct CryptoEconomicAgent instance\n                self.mechanism.agent_registry[str_id] = agent\n            \n            # Ensure agent has its ID set\n            if hasattr(agent, 'economic_agent'):\n                agent.economic_agent.id = str_id\n            else:\n                agent.id = str_id\n\n        # Setup mechanism after registry is populated\n        self.mechanism.setup()\n\n    def reset(self) -> GlobalObservation:\n        self.current_step = 0\n        self.history = EnvironmentHistory()\n        self.mechanism.reset()\n        observations = self.mechanism._create_observations(MarketSummary())\n\n        return CryptoMarketGlobalObservation(\n            observations=observations,\n            all_trades=[],\n            market_summary=MarketSummary(),\n            current_price=self.mechanism.current_price,\n            price_history=self.mechanism.price_history.copy()\n        )\n\n    def step(self, actions: GlobalAction) -> EnvironmentStep:\n        step_result = self.mechanism.step(actions)\n        self.current_step += 1\n        self.update_history(actions, step_result)\n        return step_result\n\n    def render(self):\n        pass\n"}
{"type": "source_file", "path": "market_agents/environments/mechanisms/stock_market.py", "content": "# stock_market.py\n\nimport logging\nimport random\nfrom typing import Any, List, Dict, Union, Type, Optional, Tuple\nfrom market_agents.stock_market.stock_agent import StockEconomicAgent\nfrom pydantic import BaseModel, Field, field_validator\nfrom market_agents.environments.environment import (\n    EnvironmentHistory, Mechanism, LocalAction, GlobalAction, LocalObservation, GlobalObservation,\n    EnvironmentStep, ActionSpace, ObservationSpace, MultiAgentEnvironment\n)\nfrom market_agents.stock_market.stock_models import OrderType, MarketAction, StockOrder, Trade\nlogger = logging.getLogger(__name__)\n\n\nclass MarketSummary(BaseModel):\n    trades_count: int = Field(default=0, description=\"Number of trades executed\")\n    average_price: float = Field(default=0.0, description=\"Average price of trades\")\n    total_volume: int = Field(default=0, description=\"Total volume of trades\")\n    price_range: Tuple[float, float] = Field(default=(0.0, 0.0), description=\"Range of prices\")\n\n\nclass StockMarketAction(LocalAction):\n    action: MarketAction\n\n    @field_validator('action')\n    def validate_action(cls, v):\n        if v.order_type in [OrderType.BUY, OrderType.SELL] and (v.quantity <= 0 or v.price <= 0):\n            raise ValueError(\"Quantity and price must be positive for buy and sell orders\")\n        return v\n\n    @classmethod\n    def sample(cls, agent_id: str) -> 'StockMarketAction':\n        order_type = random.choice(list(OrderType))\n        if order_type == OrderType.HOLD:\n            action = MarketAction(order_type=order_type)\n        else:\n            random_price = random.uniform(50, 150)\n            random_quantity = random.randint(1, 10)\n            action = MarketAction(order_type=order_type, price=random_price, quantity=random_quantity)\n        return cls(agent_id=agent_id, action=action)\n\n    @classmethod\n    def action_schema(cls) -> Dict[str, Any]:\n        return MarketAction.model_json_schema()\n\n\nclass GlobalStockMarketAction(GlobalAction):\n    actions: Dict[str, StockMarketAction]\n\n\nclass StockMarketObservation(BaseModel):\n    trades: List[Trade] = Field(default_factory=list, description=\"List of trades the agent participated in\")\n    market_summary: MarketSummary = Field(default_factory=MarketSummary, description=\"Summary of market activity\")\n    order_book_summary: Dict[str, List[Tuple[float, int]]] = Field(default_factory=dict, description=\"Summary of order book\")\n    current_price: float = Field(default=100.0, description=\"Current market price\")\n    portfolio_value: float = Field(default=0.0, description=\"Total value of the agent's portfolio\")\n\n\nclass StockMarketLocalObservation(LocalObservation):\n    observation: StockMarketObservation\n\n\nclass StockMarketGlobalObservation(GlobalObservation):\n    observations: Dict[str, StockMarketLocalObservation]\n    all_trades: List[Trade] = Field(default_factory=list, description=\"All trades executed in this round\")\n    market_summary: MarketSummary = Field(default_factory=MarketSummary, description=\"Summary of market activity\")\n    order_book_summary: Dict[str, List[Tuple[float, int]]] = Field(default_factory=dict, description=\"Summary of order book\")\n    current_price: float = Field(default=100.0, description=\"Current market price\")\n\n\nclass StockMarketActionSpace(ActionSpace):\n    allowed_actions: List[Type[LocalAction]] = [StockMarketAction]\n\n    @classmethod\n    def get_action_schema(cls) -> Dict[str, Any]:\n        return MarketAction.model_json_schema()\n\n\nclass StockMarketObservationSpace(ObservationSpace):\n    allowed_observations: List[Type[LocalObservation]] = [StockMarketLocalObservation]\n\n\nclass StockMarketMechanism(Mechanism):\n    max_rounds: int = Field(default=100, description=\"Maximum number of trading rounds\")\n    current_round: int = Field(default=0, description=\"Current round number\")\n    trades: List[Trade] = Field(default_factory=list, description=\"List of executed trades\")\n    order_book_buy: List[StockOrder] = Field(default_factory=list, description=\"List of buy orders\")\n    order_book_sell: List[StockOrder] = Field(default_factory=list, description=\"List of sell orders\")\n    stock_symbol: str = Field(default=\"AAPL\", description=\"Stock symbol being traded\")\n    current_price: float = Field(default=100.0, description=\"Current market price\")\n    price_history: List[float] = Field(default_factory=lambda: [100.0])\n    sequential: bool = Field(default=False, description=\"Whether the mechanism is sequential\")\n    agent_registry: Dict[str, Any] = Field(default_factory=dict, description=\"Registry of agents\")\n\n    def step(self, action: GlobalStockMarketAction) -> EnvironmentStep:\n        self.current_round += 1\n        self._update_order_book(action.actions)\n        new_trades = self._match_orders()\n        self.trades.extend(new_trades)\n        self._update_price(new_trades)\n\n        market_summary = self._create_market_summary(new_trades)\n        order_book_summary = self._get_order_book_summary()\n        observations = self._create_observations(new_trades, market_summary, order_book_summary)\n        done = self.current_round >= self.max_rounds\n\n        return EnvironmentStep(\n            global_observation=StockMarketGlobalObservation(\n                observations=observations,\n                all_trades=new_trades,\n                market_summary=market_summary,\n                order_book_summary=order_book_summary,\n                current_price=self.current_price\n            ),\n            done=done,\n            info={\"current_round\": self.current_round}\n        )\n\n    def _update_order_book(self, actions: Dict[str, StockMarketAction]):\n        for agent_id, action in actions.items():\n            order = StockOrder(\n                agent_id=agent_id,\n                order_type=action.action.order_type,\n                price=action.action.price,\n                quantity=action.action.quantity\n            )\n            if order.is_buy_order:\n                self.order_book_buy.append(order)\n            elif order.order_type == OrderType.SELL:\n                self.order_book_sell.append(order)\n\n    def _match_orders(self) -> List[Trade]:\n        trades = []\n        trade_id = len(self.trades)\n\n        # Sort buy and sell orders\n        self.order_book_buy.sort(key=lambda x: (-x.price, x.agent_id))\n        self.order_book_sell.sort(key=lambda x: (x.price, x.agent_id))\n\n        while self.order_book_buy and self.order_book_sell:\n            best_buy = self.order_book_buy[0]\n            best_sell = self.order_book_sell[0]\n\n            if best_buy.price >= best_sell.price:\n                trade_price = (best_buy.price + best_sell.price) / 2\n                trade_quantity = min(best_buy.quantity, best_sell.quantity)\n\n                trade = Trade(\n                    trade_id=trade_id,\n                    buyer_id=best_buy.agent_id,\n                    seller_id=best_sell.agent_id,\n                    price=trade_price,\n                    bid_price=best_buy.price,\n                    ask_price=best_sell.price,\n                    quantity=trade_quantity,\n                    stock_symbol=self.stock_symbol\n                )\n                trades.append(trade)\n                trade_id += 1\n\n                # Update order quantities\n                best_buy.quantity -= trade_quantity\n                best_sell.quantity -= trade_quantity\n\n                if best_buy.quantity == 0:\n                    self.order_book_buy.pop(0)\n                if best_sell.quantity == 0:\n                    self.order_book_sell.pop(0)\n            else:\n                break\n\n        return trades\n\n    def _get_order_book_summary(self) -> Dict[str, List[Tuple[float, int]]]:\n        buy_orders = {}\n        for order in self.order_book_buy:\n            price = order.price\n            quantity = order.quantity\n            buy_orders[price] = buy_orders.get(price, 0) + quantity\n        sell_orders = {}\n        for order in self.order_book_sell:\n            price = order.price\n            quantity = order.quantity\n            sell_orders[price] = sell_orders.get(price, 0) + quantity\n        return {\n            'buy': sorted(buy_orders.items(), key=lambda x: -x[0]),\n            'sell': sorted(sell_orders.items(), key=lambda x: x[0])\n        }\n\n    def _update_price(self, trades: List[Trade]):\n        if trades:\n            prices = [trade.price for trade in trades]\n            self.current_price = sum(prices) / len(prices)\n            self.price_history.append(self.current_price)\n\n    def _create_observations(self, new_trades: List[Trade], market_summary: MarketSummary, order_book_summary: Dict[str, List[Tuple[float, int]]]) -> Dict[str, StockMarketLocalObservation]:\n        observations = {}\n        agent_ids = set([trade.buyer_id for trade in new_trades] + [trade.seller_id for trade in new_trades])\n\n        for agent_id in agent_ids:\n            agent_trades = [trade for trade in new_trades if trade.buyer_id == agent_id or trade.seller_id == agent_id]\n            agent = self.agent_registry.get(agent_id)\n            if agent:\n                portfolio_value = agent.calculate_portfolio_value(self.current_price)\n            else:\n                portfolio_value = 0.0\n\n            observation = StockMarketObservation(\n                trades=agent_trades,\n                market_summary=market_summary,\n                order_book_summary=order_book_summary,\n                current_price=self.current_price,\n                portfolio_value=portfolio_value\n            )\n\n            observations[agent_id] = StockMarketLocalObservation(\n                agent_id=agent_id,\n                observation=observation\n            )\n\n        return observations\n\n    def _create_market_summary(self, trades: List[Trade]) -> MarketSummary:\n        if not trades:\n            return MarketSummary()\n\n        prices = [trade.price for trade in trades]\n        total_volume = sum(trade.quantity for trade in trades)\n        return MarketSummary(\n            trades_count=len(trades),\n            average_price=sum(prices) / len(prices),\n            total_volume=total_volume,\n            price_range=(min(prices), max(prices))\n        )\n\n    def get_global_state(self) -> Dict[str, Any]:\n        return {\n            \"current_round\": self.current_round,\n            \"current_price\": self.current_price,\n            \"price_history\": self.price_history,\n            \"trades\": [trade.model_dump() for trade in self.trades],\n            \"order_book_summary\": self._get_order_book_summary()\n        }\n\n    def reset(self) -> None:\n        self.current_round = 0\n        self.trades = []\n        self.order_book_buy = []\n        self.order_book_sell = []\n        self.current_price = 100.0\n        self.price_history = [self.current_price]\n\n\nclass StockMarket(MultiAgentEnvironment):\n    name: str = Field(default=\"Stock Market\", description=\"Name of the stock market\")\n    action_space: StockMarketActionSpace = Field(default_factory=StockMarketActionSpace, description=\"Action space of the stock market\")\n    observation_space: StockMarketObservationSpace = Field(default_factory=StockMarketObservationSpace, description=\"Observation space of the stock market\")\n    mechanism: StockMarketMechanism = Field(default_factory=StockMarketMechanism, description=\"Mechanism of the stock market\")\n    agents: Dict[str, StockEconomicAgent] = Field(default_factory=dict, description=\"Dictionary of agents in the market\")\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self.mechanism.agent_registry = self.agents\n\n    def __init__(self, agents: Dict[str, StockEconomicAgent], **kwargs):\n        super().__init__(**kwargs)\n        self.agents = agents\n        self.mechanism.agent_registry = self.agents\n\n    def reset(self) -> GlobalObservation:\n        self.current_step = 0\n        self.history = EnvironmentHistory()\n        self.mechanism.reset()\n        observations = {}\n\n        for agent_id, agent in self.agents.items():\n            portfolio_value = agent.calculate_portfolio_value(self.mechanism.current_price)\n            observation = StockMarketObservation(\n                trades=[],\n                market_summary=MarketSummary(),\n                order_book_summary=self.mechanism._get_order_book_summary(),\n                current_price=self.mechanism.current_price,\n                portfolio_value=portfolio_value\n            )\n            observations[agent_id] = StockMarketLocalObservation(\n                agent_id=agent_id,\n                observation=observation\n            )\n\n        return StockMarketGlobalObservation(\n            observations=observations,\n            all_trades=[],\n            market_summary=MarketSummary(),\n            order_book_summary=self.mechanism._get_order_book_summary(),\n            current_price=self.mechanism.current_price\n        )\n\n    def step(self, actions: GlobalAction) -> EnvironmentStep:\n        step_result = self.mechanism.step(actions)\n        self.current_step += 1\n        self.update_history(actions, step_result)\n        return step_result\n\n    def render(self):\n        pass\n"}
