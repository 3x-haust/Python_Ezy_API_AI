{"repo_info": {"repo_name": "AutoSpark", "repo_owner": "iflytek", "repo_url": "https://github.com/iflytek/AutoSpark"}}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/DuckDuckGo/tests/test_duckduckgo_toolkit.py", "content": "import pytest\nfrom duck_duck_go_search_toolkit import DuckDuckGoToolkit\nfrom duck_duck_go_search import DuckDuckGoSearchTool\n\nclass TestDuckDuckGoSearchToolKit:\n    def setup_method(self):\n        \"\"\"\n        Set up the test fixture.\n\n        This method is called before each test method is executed to prepare the test environment.\n\n        Returns:\n            None\n        \"\"\"\n        self.toolkit = DuckDuckGoToolkit()\n\n    def test_get_tools(self):\n        \"\"\"\n        Test the `get_tools` method of the `DuckDuckGoToolkit` class.\n\n        It should return a list of tools, containing one instance of `DuckDuckGoSearchTool`.\n\n        Returns:\n            None\n        \"\"\"\n        tools = self.toolkit.get_tools()\n        assert len(tools) == 1\n        assert isinstance(tools[0], DuckDuckGoSearchTool)\n\n    def test_get_env_keys(self):\n        \"\"\"\n        Test the `get_env_keys` method of the `DuckDuckGoToolkit` class.\n\n        It should return an empty list of environment keys.\n\n        Returns:\n            None\n        \"\"\"\n        env_keys = self.toolkit.get_env_keys()\n        assert len(env_keys) == 0"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/duck_duck_go/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "superagi/tools/external_tools/docker_tools/tests/test.py", "content": "from pyartifactory import Artifactory\nfrom pyartifactory.exception import RepositoryNotFoundException\n\nart = Artifactory(url=\"https://artifacts.iflytek.com\",\n                  auth=('', ''),\n                  api_version=2)\n\ntry:\n    repo = art.repositories.get_repo(\"docker-private/atp\")\nexcept RepositoryNotFoundException as e:\n    print('not find')\n\nartifacts = art.artifacts.list(\"docker-private/atp\")\nfor a in artifacts.files:\n    if a.uri.endswith(\"manifest.json\"):\n        items = a.uri.split(\"/\")\n        repo_path =  '/'.join(items[0:-2]) + \":\" + items[-2]\n        print(repo_path.lstrip(\"/\"))\n"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/DuckDuckGo/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/duck_duck_go/tests/test_duckduckgo_toolkit.py", "content": "import pytest\nfrom duck_duck_go_search_toolkit import DuckDuckGoToolkit\nfrom duck_duck_go_search import DuckDuckGoSearchTool\n\nclass TestDuckDuckGoSearchToolKit:\n    def setup_method(self):\n        \"\"\"\n        Set up the test fixture.\n\n        This method is called before each test method is executed to prepare the test environment.\n\n        Returns:\n            None\n        \"\"\"\n        self.toolkit = DuckDuckGoToolkit()\n\n    def test_get_tools(self):\n        \"\"\"\n        Test the `get_tools` method of the `DuckDuckGoToolkit` class.\n\n        It should return a list of tools, containing one instance of `DuckDuckGoSearchTool`.\n\n        Returns:\n            None\n        \"\"\"\n        tools = self.toolkit.get_tools()\n        assert len(tools) == 1\n        assert isinstance(tools[0], DuckDuckGoSearchTool)\n\n    def test_get_env_keys(self):\n        \"\"\"\n        Test the `get_env_keys` method of the `DuckDuckGoToolkit` class.\n\n        It should return an empty list of environment keys.\n\n        Returns:\n            None\n        \"\"\"\n        env_keys = self.toolkit.get_env_keys()\n        assert len(env_keys) == 0"}
{"type": "test_file", "path": "superagi/tools/external_tools/docker_tools/tests/test_greetings_tool.py", "content": "import unittest\n\nfrom artifacts_docker_tool import DockerImageListTool, ListImageTagsInput\n\n\nclass DockerImageListToolTestCase(unittest.TestCase):\n    def setUp(self):\n        self.tool = DockerImageListTool()\n\n    def test_tool_name(self):\n        self.assertEqual(self.tool.name, \"Greetings Tool\")\n\n    def test_tool_args_schema(self):\n        self.assertEqual(self.tool.args_schema, ListImageTagsInput)\n\n    def test_tool_description(self):\n        self.assertEqual(self.tool.description, \"Sends List Image Input\")\n\n    def test_execute_method(self):\n        list_input = ListImageTagsInput(repo_path=\"docker-private/atp\")\n        output = self.tool._execute(repo_path=list_input.repo_path)\n        print(output)\n        #self.assertEqual(output, expected_output)\n"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/DuckDuckGo/tests/test_duckduckgo_results.py", "content": "import pytest\nfrom duck_duck_go_search import DuckDuckGoSearchTool\n\nclass TestDuckDuckGoSearchTool:\n    def setup_method(self):\n        self.your_obj = DuckDuckGoSearchTool()  # Create an instance of DuckDuckGoSearchTool\n\n    def test_get_raw_duckduckgo_results_empty_query(self):\n        query = \"\"\n        expected_result = \"[]\"\n        result = self.your_obj.get_raw_duckduckgo_results(query)\n        assert result == expected_result\n\n    def test_get_raw_duckduckgo_results_valid_query(self):\n        query = \"python\"\n        expected_result_length = 10\n        result = self.your_obj.get_raw_duckduckgo_results(query)\n        assert len(result) == expected_result_length\n\n    def test_get_formatted_webpages(self):\n        search_results = [\n            {\"title\": \"Result 1\", \"href\": \"https://example.com/1\"},\n            {\"title\": \"Result 2\", \"href\": \"https://example.com/2\"},\n            {\"title\": \"Result 3\", \"href\": \"https://example.com/3\"},\n        ]\n        webpages = [\"Webpage 1\", \"Webpage 2\", \"Webpage 3\"]\n\n        expected_results = [\n            {\"title\": \"Result 1\", \"body\": \"Webpage 1\", \"links\": \"https://example.com/1\"},\n            {\"title\": \"Result 2\", \"body\": \"Webpage 2\", \"links\": \"https://example.com/2\"},\n            {\"title\": \"Result 3\", \"body\": \"Webpage 3\", \"links\": \"https://example.com/3\"},\n        ]\n\n        results = self.your_obj.get_formatted_webpages(search_results, webpages)\n        assert results == expected_results\n\n    def test_get_content_from_url_with_empty_links(self):\n        links = []\n        expected_webpages = []\n\n        webpages = self.your_obj.get_content_from_url(links)\n        assert webpages == expected_webpages\n\n    def test_get_formatted_webpages_with_empty_webpages(self):\n        search_results = [\n            {\"title\": \"Result 1\", \"href\": \"https://example.com/1\"},\n            {\"title\": \"Result 2\", \"href\": \"https://example.com/2\"},\n            {\"title\": \"Result 3\", \"href\": \"https://example.com/3\"},\n        ]\n        webpages = []\n        expected_results = []\n\n        results = self.your_obj.get_formatted_webpages(search_results, webpages)\n        assert results == expected_results"}
{"type": "test_file", "path": "superagi/tools/external_tools/docker_tools/tests/test_greetings_toolkit.py", "content": "import unittest\n\nfrom artifacts_docker_tool import GreetingsTool\nfrom docker_toolkit import IflytekArtifactoryToolkit\n\n\nclass GreetingsToolkitTests(unittest.TestCase):\n    def setUp(self):\n        self.toolkit = IflytekArtifactoryToolkit()\n\n    def test_get_tools_returns_list_of_tools(self):\n        tools = self.toolkit.get_tools()\n        self.assertIsInstance(tools, list)\n        self.assertTrue(all(isinstance(tool, GreetingsTool) for tool in tools))\n\n    def test_get_env_keys_returns_list_of_strings(self):\n        env_keys = self.toolkit.get_env_keys()\n        self.assertIsInstance(env_keys, list)\n        self.assertTrue(all(isinstance(key, str) for key in env_keys))\n\n    def test_toolkit_has_name_and_description(self):\n        self.assertEqual(self.toolkit.name, \"Greetings Toolkit\")\n        self.assertEqual(self.toolkit.description, \"Greetings Tool kit contains all tools related to Greetings\")\n"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/duck_duck_go/tests/test_duckduckgo_results.py", "content": "import pytest\nfrom duck_duck_go_search import DuckDuckGoSearchTool\n\nclass TestDuckDuckGoSearchTool:\n    def setup_method(self):\n        self.your_obj = DuckDuckGoSearchTool()  # Create an instance of DuckDuckGoSearchTool\n\n    def test_get_raw_duckduckgo_results_empty_query(self):\n        query = \"\"\n        expected_result = \"[]\"\n        result = self.your_obj.get_raw_duckduckgo_results(query)\n        assert result == expected_result\n\n    def test_get_raw_duckduckgo_results_valid_query(self):\n        query = \"python\"\n        expected_result_length = 10\n        result = self.your_obj.get_raw_duckduckgo_results(query)\n        assert len(result) == expected_result_length\n\n    def test_get_formatted_webpages(self):\n        search_results = [\n            {\"title\": \"Result 1\", \"href\": \"https://example.com/1\"},\n            {\"title\": \"Result 2\", \"href\": \"https://example.com/2\"},\n            {\"title\": \"Result 3\", \"href\": \"https://example.com/3\"},\n        ]\n        webpages = [\"Webpage 1\", \"Webpage 2\", \"Webpage 3\"]\n\n        expected_results = [\n            {\"title\": \"Result 1\", \"body\": \"Webpage 1\", \"links\": \"https://example.com/1\"},\n            {\"title\": \"Result 2\", \"body\": \"Webpage 2\", \"links\": \"https://example.com/2\"},\n            {\"title\": \"Result 3\", \"body\": \"Webpage 3\", \"links\": \"https://example.com/3\"},\n        ]\n\n        results = self.your_obj.get_formatted_webpages(search_results, webpages)\n        assert results == expected_results\n\n    def test_get_content_from_url_with_empty_links(self):\n        links = []\n        expected_webpages = []\n\n        webpages = self.your_obj.get_content_from_url(links)\n        assert webpages == expected_webpages\n\n    def test_get_formatted_webpages_with_empty_webpages(self):\n        search_results = [\n            {\"title\": \"Result 1\", \"href\": \"https://example.com/1\"},\n            {\"title\": \"Result 2\", \"href\": \"https://example.com/2\"},\n            {\"title\": \"Result 3\", \"href\": \"https://example.com/3\"},\n        ]\n        webpages = []\n        expected_results = []\n\n        results = self.your_obj.get_formatted_webpages(search_results, webpages)\n        assert results == expected_results"}
{"type": "test_file", "path": "tests/unit_tests/agent/test_agent_prompt_builder.py", "content": "from unittest.mock import MagicMock\n\nimport pytest\nfrom unittest.mock import patch, MagicMock\nimport json\nfrom autospark.agent.agent_prompt_builder import AgentPromptBuilder\nfrom autospark.helper.prompt_reader import PromptReader\nfrom autospark_kit.tools.base_tool import BaseTool\nfrom autospark.tools.email.send_email import SendEmailTool\nfrom autospark.types.model_source_types import ModelSourceType\n\ndef test_add_list_items_to_string():\n    items = ['apple', 'banana', 'cherry']\n    result = AgentPromptBuilder.add_list_items_to_string(items)\n    expected_result = \"1. apple\\n2. banana\\n3. cherry\\n\"\n    assert result == expected_result\n\n\ndef test_clean_prompt():\n    prompt = \"  This is a   prompt with    unnecessary spaces   .  \"\n    result = AgentPromptBuilder.clean_prompt(prompt)\n    expected_result = \"This is a prompt with unnecessary spaces .\"\n    assert result == expected_result\n\n\nclass MockTool(BaseTool):\n    name: str = \"Mock Tool\"\n    description: str = \"This is a mock tool.\"\n\n    def _execute(self):\n        pass\n\n\ndef test_replace_main_variables():\n    goals = [\"goal1\", \"goal2\"]\n    instructions = [\"instruction1\", \"instruction2\"]\n    constraints = [\"constraint1\", \"constraint2\"]\n\n    mock_tool = MockTool()\n\n    tool1 = mock_tool\n    tool2 = mock_tool\n    tools = [tool1, tool2]\n\n    as_prompt = \"Goals:\\n{goals}\\nInstructions:\\n{instructions}\\nConstraints:\\n{constraints}\\nTools:\\n{tools}\"\n\n    result = AgentPromptBuilder.replace_main_variables(as_prompt, goals, instructions, constraints, tools,ModelSourceType.OpenAI )\n\n    assert \"instruction1\" in result\n    assert \"instruction2\" in result\n    assert \"constraint1\" in result\n    assert \"constraint2\" in result\n    assert \"Mock Tool\" in result\n\n\ndef test__generate_command_string():\n    tool = SendEmailTool(name=\"Mock Tool\", description=\"This is a mock tool.\")\n    result = AgentPromptBuilder._generate_command_string(tool)\n    expected_result = \"\\\"Mock Tool\\\": This is a mock tool.\"\n    assert (expected_result in result)\n\n\ndef test_get_auto_spark_single_prompt():\n    # Arrange\n    prompt_mock = \"Mocked prompt with {response_format}\"\n    with patch('autospark.helper.prompt_reader.PromptReader.read_agent_prompt', return_value=prompt_mock):\n        # Act\n        result = AgentPromptBuilder.get_auto_spark_single_prompt()\n\n        # Assert\n        expected_response_format = {\n            \"thoughts\": {\n                \"text\": \"thought\",\n                \"reasoning\": \"short reasoning\",\n                \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n                \"criticism\": \"constructive self-criticism\",\n                \"speak\": \"thoughts summary to say to user\",\n            },\n            \"tool\": {\"name\": \"tool name/task name\",\n                     \"args\": {\"arg name\": \"arg value(escape in case of string)\"}}\n        }\n        formatted_response_format = json.dumps(expected_response_format, indent=4)\n\n        expected_prompt = \"Mocked prompt with \" + formatted_response_format\n        expected_result = {\"prompt\": expected_prompt, \"variables\": [\"goals\", \"instructions\", \"constraints\", \"tools\"]}\n\n        assert result == expected_result\n\n\ndef test_analyse_task():\n    # Arrange\n    mock_prompt = \"Mocked prompt with {constraints}\"\n    mock_read_agent_prompt = MagicMock(return_value=mock_prompt)\n    with patch.object(PromptReader, 'read_agent_prompt', new=mock_read_agent_prompt):\n        constraints = ['Exclusively use the tools listed in double quotes e.g. \"tool name\"']\n\n        # Act\n        result = AgentPromptBuilder.analyse_task()\n\n        # Assert\n        expected_prompt = AgentPromptBuilder.clean_prompt(mock_prompt).replace(\n            \"{constraints}\", AgentPromptBuilder.add_list_items_to_string(constraints))\n\n        assert result == {\"prompt\": expected_prompt, \"variables\": [\"goals\", \"instructions\", \"tools\", \"current_task\"]}\n\n\n@pytest.fixture\ndef base_tool():\n    return MockTool(name=\"base_tool\", description=\"description\", args_schema=None, permission_required=True)\n\n\n@pytest.mark.parametrize(\"completed_tasks, expected_output\", [\n    ([], \"\"),\n    ([{'task': 'task1', 'response': 'response1'}], \"Task: task1\\nResult: response1\\n\")\n])\ndef test_replace_task_based_variables(base_tool, completed_tasks, expected_output):\n    current_task = \"current_task\"\n    last_task = \"last_task\"\n    last_task_result = \"last_task_result\"\n    pending_tasks = [\"task1\", \"task2\"]\n    token_limit = 1000\n    as_prompt = \"{current_task} {last_task} {last_task_result} {pending_tasks} {completed_tasks} {task_history}\"\n    replaced_prompt = AgentPromptBuilder.replace_task_based_variables(\n        as_prompt, current_task, last_task, last_task_result, pending_tasks, completed_tasks, token_limit)\n\n    assert \"{current_task}\" not in replaced_prompt\n    assert \"{last_task}\" not in replaced_prompt\n    assert \"{last_task_result}\" not in replaced_prompt\n    assert \"{pending_tasks}\" not in replaced_prompt\n    assert \"{completed_tasks}\" not in replaced_prompt\n    assert \"{task_history}\" not in replaced_prompt\n\n    assert current_task in replaced_prompt\n    assert last_task in replaced_prompt\n    assert last_task_result in replaced_prompt\n    assert str(pending_tasks) in replaced_prompt\n    assert str([task['task'] for task in completed_tasks]) in replaced_prompt\n    assert expected_output in replaced_prompt\n\n\ndef test_create_tasks():\n    as_prompt = AgentPromptBuilder.create_tasks()\n    assert isinstance(as_prompt, dict)\n    assert \"prompt\" in as_prompt\n    assert \"variables\" in as_prompt\n    assert as_prompt[\"variables\"] == [\"goals\", \"instructions\", \"last_task\", \"last_task_result\", \"pending_tasks\"]\n\n    # Now we validate the prompt\n    prompt = as_prompt[\"prompt\"]\n    assert \"{goals}\" in prompt\n    assert \"{task_instructions}\" in prompt\n    assert \"{completed_tasks}\" in prompt\n\ndef test_start_task_based():\n    as_prompt = AgentPromptBuilder.start_task_based()\n    assert isinstance(as_prompt, dict)\n    assert \"prompt\" in as_prompt\n    assert \"variables\" in as_prompt\n    assert as_prompt[\"variables\"] == [\"goals\", \"instructions\"]\n\n    # Now we validate the prompt\n    prompt = as_prompt[\"prompt\"]\n    assert \"{goals}\" in prompt\n    assert \"{instructions}\" not in prompt\n\ndef test_prioritize_tasks():\n    as_prompt = AgentPromptBuilder.prioritize_tasks()\n    assert isinstance(as_prompt, dict)\n    assert \"prompt\" in as_prompt\n    assert \"variables\" in as_prompt\n    assert as_prompt[\"variables\"] == [\"goals\", \"instructions\", \"last_task\", \"last_task_result\", \"pending_tasks\"]\n\n    # Now we validate the prompt\n    prompt = as_prompt[\"prompt\"]\n    assert \"{goals}\" in prompt\n    assert \"{pending_tasks}\" in prompt"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/google_analytics/tests/test_google_analytics_report_tool.py", "content": "import unittest\nfrom unittest.mock import patch, Mock, call\nfrom pydantic import ValidationError\nimport json\nfrom superagi.tools.marketplace_tools.googleanalytics.google_analytics_report_tool import GoogleAnalyticsReportTool, GoogleAnalyticsReportToolInput\nfrom google.analytics.data_v1beta.types import RunReportRequest\n\nclass TestGoogleAnalyticsReportTool(unittest.TestCase):\n\n\n    @patch(\"superagi.tools.marketplace_tools.googleanalytics.google_analytics_report_tool.json\")\n    @patch(\"builtins.open\", new_callable=unittest.mock.mock_open)\n    @patch(\"superagi.tools.marketplace_tools.googleanalytics.google_analytics_report_tool.os\")\n    @patch(\"superagi.tools.marketplace_tools.googleanalytics.google_analytics_report_tool.BetaAnalyticsDataClient\") \n    def test_set_google_credentials(self, mock_beta_cli, mock_os, mock_open, mock_json):\n        tool = GoogleAnalyticsReportTool()\n        \n        mock_json.loads.side_effect = ['credentials', {\"PROPERTY_ID\":\"value1\", \"GOOGLE_CREDENTIALS_FILE\":\"value2\"}]\n        tool._set_google_credentials('credentials')\n            \n        calls = [call('credentials'), call('credentials')]\n        mock_json.loads.assert_has_calls(calls)\n        mock_open.assert_called_once_with(\"credentials.json\", \"w\")\n        mock_json.dump.assert_called_once_with({\"PROPERTY_ID\":\"value1\", \"GOOGLE_CREDENTIALS_FILE\":\"value2\"}, mock_open.return_value.__enter__.return_value)\n        mock_os.environ.__setitem__.assert_called_once_with('GOOGLE_APPLICATION_CREDENTIALS', \"credentials.json\")\n\n    def test_args_schema(self):\n        with self.assertRaises(ValidationError):\n            GoogleAnalyticsReportToolInput()\n\n    @patch(\"superagi.tools.marketplace_tools.googleanalytics.google_analytics_report_tool.BetaAnalyticsDataClient\")\n    def test_create_run_report_request(self, mock_client):\n        tool = GoogleAnalyticsReportTool()\n        request = tool._create_run_report_request(\n            12345,\n            ['dimension1', 'dimension2'],\n            ['metric1', 'metric2'],\n            '2021-07-01',\n            '2021-07-31'\n        )\n        self.assertIsInstance(request, RunReportRequest)\n        self.assertEqual(request.property, \"properties/12345\")\n        self.assertEqual(len(request.dimensions), 2)\n        self.assertEqual(len(request.metrics), 2)\n\n    def test_generate_report(self):\n        tool = GoogleAnalyticsReportTool()\n        mock_response = Mock(\n            dimension_headers=[Mock(name=\"dimension1\"), Mock(name=\"dimension2\")],\n            metric_headers=[Mock(name=\"metric1\"), Mock(name=\"metric2\")],\n            rows=[\n                Mock(\n                    dimension_values=[Mock(value=\"dvalue1\"), Mock(value=\"dvalue2\")],\n                    metric_values=[Mock(value=\"mvalue1\"), Mock(value=\"mvalue2\")]\n                )\n            ]\n        )\n        mock_response.dimension_headers[0].name = \"dimension1\"\n        mock_response.dimension_headers[1].name = \"dimension2\"\n        mock_response.metric_headers[0].name = \"metric1\"\n        mock_response.metric_headers[1].name = \"metric2\"\n        mock_response.rows[0].dimension_values[0].value = \"dvalue1\"\n        mock_response.rows[0].dimension_values[1].value = \"dvalue2\"\n        mock_response.rows[0].metric_values[0].value = \"mvalue1\"\n        mock_response.rows[0].metric_values[1].value = \"mvalue2\"\n\n        report = tool._generate_report(mock_response)\n        expected_report = \"dimension1 dimension2 metric1 metric2 \\ndvalue1 dvalue2 mvalue1 mvalue2 \\n\"\n        self.assertEqual(report, expected_report)\n\n\n    def test_generate_filename(self):\n        tool = GoogleAnalyticsReportTool()\n        filename = tool._generate_filename(['dimension1'], ['metric1'], ['report.txt'])\n        expected_filename = \"dimension1metric1.txt\"\n        self.assertEqual(filename, expected_filename)\n\n    @patch(\"superagi.tools.marketplace_tools.googleanalytics.google_analytics_report_tool.yaml\")\n    @patch(\"builtins.open\")\n    def test_get_dimensions_and_metrics(self, mock_open, mock_yaml):\n        tool = GoogleAnalyticsReportTool()\n        mock_yaml.load.return_value = {'GOOGLE_ANALYTICS_VARIABLES': [{'Dimension': '1', 'Metric': '2'}]}\n        result = tool.get_dimensions_and_metrics()\n        expected_result = [['1', '2']]\n        self.assertEqual(result, expected_result)\n\n\nif __name__ == '__main__':\n    unittest.main()"}
{"type": "test_file", "path": "tests/unit_tests/controllers/test_agent_execution.py", "content": "from unittest.mock import patch\nfrom unittest import mock\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom main import app\nfrom autospark.models.agent_schedule import AgentSchedule\nfrom datetime import datetime\n\nclient = TestClient(app)\n\n@pytest.fixture\ndef mock_patch_schedule_input():\n    return {\n        \"agent_id\": 1,\n        \"start_time\": \"2023-02-02 01:00:00\",\n        \"recurrence_interval\": \"2 Hours\",\n        \"expiry_date\": \"2023-12-30 01:00:00\",\n        \"expiry_runs\": -1\n    }\n\n@pytest.fixture\ndef mock_schedule():\n    # Mock schedule data for testing\n    return AgentSchedule(id=1, agent_id=1, status=\"SCHEDULED\")\n\n# An agent is already scheduled and is simply being updated, we assert for the updated values here\ndef test_schedule_existing_agent_already_scheduled(mock_patch_schedule_input, mock_schedule):\n    with patch('autospark.controllers.agent_execution.db') as mock_db:\n        mock_db.session.query.return_value.filter.return_value.first.return_value = mock_schedule \n\n        response = client.post(\"agentexecutions/schedule\", json=mock_patch_schedule_input)\n\n        assert response.status_code == 201\n        assert mock_schedule.start_time == datetime.strptime(mock_patch_schedule_input['start_time'], '%Y-%m-%d %H:%M:%S')\n        assert mock_schedule.recurrence_interval == mock_patch_schedule_input['recurrence_interval']\n        assert mock_schedule.expiry_date == datetime.strptime(mock_patch_schedule_input['expiry_date'], '%Y-%m-%d %H:%M:%S')\n        assert mock_schedule.expiry_runs == mock_patch_schedule_input['expiry_runs']\n\n# The agent isn't scheduled yet and we are scheduling it, we simply assert for a 201 status code and non-null schedule id.\ndef test_schedule_existing_agent_new_schedule(mock_patch_schedule_input, mock_schedule):\n    with patch('autospark.controllers.agent_execution.db') as mock_db:\n        mock_db.session.query.return_value.filter.return_value.first.return_value = mock_schedule\n\n        response = client.post(\"agentexecutions/schedule\", json=mock_patch_schedule_input)\n\n        assert response.status_code == 201\n        assert response.json()[\"schedule_id\"] is not None"}
{"type": "test_file", "path": "tests/unit_tests/controllers/test_agent_execution_config.py", "content": "from unittest.mock import patch\n\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom main import app\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent_execution_config import AgentExecutionConfiguration\n\nclient = TestClient(app)\n\n\n@pytest.fixture\ndef mocks():\n    # Mock tool kit data for testing\n    mock_execution_config = [AgentExecutionConfiguration(id=1, key=\"test_key\", value=\"['test']\")]\n    mock_execution = AgentExecution(id=1,name=\"test_execution\")\n    return mock_execution,mock_execution_config\n\n\ndef test_get_agent_execution_configuration_success(mocks):\n    with patch('autospark.controllers.agent_execution_config.db') as mock_db:\n        _,mock_execution_config = mocks\n        mock_db.session.query.return_value.filter.return_value.all.return_value = mock_execution_config\n\n        response = client.get(\"/agent_executions_configs/details/agent/1/agent_execution/1\")\n\n        assert response.status_code == 200\n        assert response.json() == {\"test_key\": ['test']}\n\n\ndef test_get_agent_execution_configuration_not_found_failure():\n    with patch('autospark.controllers.agent_execution_config.db') as mock_db:\n        mock_db.session.query.return_value.filter.return_value.all.return_value = []\n        mock_db.session.query.return_value.filter.return_value.first.return_value = None\n        response = client.get(\"/agent_executions_configs/details/agent/1/agent_execution/1\")\n\n        assert response.status_code == 404\n        assert response.json() == {\"detail\": \"Agent Configuration not found\"}\n\n\ndef test_get_agent_execution_configuration_not_found_success(mocks):\n    with patch('autospark.controllers.agent_execution_config.db') as mock_db:\n        mock_execution,mock_execution_config = mocks\n        mock_db.session.query.return_value.filter.return_value.all.side_effect = [[], mock_execution_config]\n        mock_db.session.query.return_value.filter.return_value.first.return_value = mock_execution\n        response = client.get(\"/agent_executions_configs/details/agent/1/agent_execution/1\")\n\n        assert response.status_code == 200\n"}
{"type": "test_file", "path": "tests/unit_tests/agent/test_output_parser.py", "content": "import pytest\n\nfrom autospark.agent.output_parser import AgentGPTAction, AgentSchemaOutputParser\n\n\ndef test_parse():\n    parser = AgentSchemaOutputParser()\n\n    # test with valid input\n    valid_text = '{\"thoughts\": {\"text\": \"some thought\", \"reasoning\": \"some reasoning\", \"plan\": \"some plan\", \"criticism\": \"some criticism\"}, \"tool\": {\"name\": \"some tool\", \"args\": {\"arg1\": \"value1\"}}}'\n    output = parser.parse(valid_text)\n    assert isinstance(output, AgentGPTAction)\n    assert output.name == \"some tool\"\n    assert output.args == {\"arg1\": \"value1\"}\n\n"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/google_analytics/tests/test_google_analytics_toolkit.py", "content": "import unittest\nfrom unittest.mock import Mock\nfrom superagi.tools.base_tool import BaseTool, ToolConfiguration\nfrom superagi.tools.marketplace_tools.googleanalytics.google_analytics_toolkit import GoogleAnalyticsToolkit\n\nclass TestGoogleAnalyticsToolkit(unittest.TestCase):\n    def setUp(self):\n        self.toolkit = GoogleAnalyticsToolkit()\n\n    def test_name(self):\n        self.assertEqual(self.toolkit.name, \"Google Analytics Toolkit\")\n     \n    def test_description(self):\n        self.assertEqual(self.toolkit.description, \"Google Analytics Toolkit returns google analytics reports requested by the user\")\n    \n    def test_get_tools(self):\n        tools = self.toolkit.get_tools()\n        self.assertTrue(any(isinstance(tool, BaseTool) for tool in tools))\n\n    def test_get_env_keys(self):\n        env_keys = self.toolkit.get_env_keys()\n        self.assertTrue(all(isinstance(env_key, ToolConfiguration) for env_key in env_keys))\n        \n        # check required values are present in env_keys\n        keys = [k.key for k in env_keys]\n        self.assertIn(\"PROPERTY_ID\", keys)\n        self.assertIn(\"GOOGLE_CREDENTIALS_FILE\", keys)\n\n        \nif __name__ == \"__main__\":\n    unittest.main()"}
{"type": "test_file", "path": "tests/unit_tests/agent/test_task_queue.py", "content": "import unittest\nfrom unittest.mock import patch\n\nfrom autospark.agent.task_queue import TaskQueue\n\n\nclass TaskQueueTests(unittest.TestCase):\n    def setUp(self):\n        self.queue_name = \"test_queue\"\n        self.queue = TaskQueue(self.queue_name)\n\n    @patch.object(TaskQueue, 'add_task')\n    def test_add_task(self, mock_add_task):\n        task = \"Do something\"\n        self.queue.add_task(task)\n        mock_add_task.assert_called_with(task)\n\n    @patch.object(TaskQueue, 'complete_task')\n    def test_complete_task(self, mock_complete_task):\n        task = \"Do something\"\n        response = \"Task completed\"\n        self.queue.complete_task(response)\n        mock_complete_task.assert_called_with(response)\n\n    @patch.object(TaskQueue, 'get_first_task')\n    def test_get_first_task(self, mock_get_first_task):\n        self.queue.get_first_task()\n        mock_get_first_task.assert_called()\n\n    @patch.object(TaskQueue, 'get_tasks')\n    def test_get_tasks(self, mock_get_tasks):\n        self.queue.get_tasks()\n        mock_get_tasks.assert_called()\n\n    @patch.object(TaskQueue, 'get_completed_tasks')\n    def test_get_completed_tasks(self, mock_get_completed_tasks):\n        self.queue.get_completed_tasks()\n        mock_get_completed_tasks.assert_called()\n\n    @patch.object(TaskQueue, 'clear_tasks')\n    def test_clear_tasks(self, mock_clear_tasks):\n        self.queue.clear_tasks()\n        mock_clear_tasks.assert_called()\n\n    @patch.object(TaskQueue, 'get_last_task_details')\n    def test_get_last_task_details(self, mock_get_last_task_details):\n        self.queue.get_last_task_details()\n        mock_get_last_task_details.assert_called()\n\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/notion/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/controllers/test_analytics.py", "content": "from unittest.mock import patch\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom main import app\n\nclient = TestClient(app)\n\ndef test_get_metrics_success():\n    with patch('autospark.controllers.analytics.AnalyticsHelper') as mock_helper:\n        mock_helper().calculate_run_completed_metrics.return_value = {'total_tokens': 10, 'total_calls': 5, 'runs_completed': 2}\n        response = client.get(\"analytics/metrics\")\n        assert response.status_code == 200\n        assert response.json() == {'total_tokens': 10, 'total_calls': 5, 'runs_completed': 2}\n\ndef test_get_agents_success():\n    with patch('autospark.controllers.analytics.AnalyticsHelper') as mock_helper:\n        mock_helper().fetch_agent_data.return_value = {\"agent_details\": \"mock_details\", \"model_info\": \"mock_info\"}\n        response = client.get(\"analytics/agents/all\")\n        assert response.status_code == 200\n        assert response.json() == {\"agent_details\": \"mock_details\", \"model_info\": \"mock_info\"}\n\ndef test_get_agent_runs_success():\n    with patch('autospark.controllers.analytics.AnalyticsHelper') as mock_helper:\n        mock_helper().fetch_agent_runs.return_value = \"mock_agent_runs\"\n        response = client.get(\"analytics/agents/1\")\n        assert response.status_code == 200\n        assert response.json() == \"mock_agent_runs\"\n\ndef test_get_active_runs_success():\n    with patch('autospark.controllers.analytics.AnalyticsHelper') as mock_helper:\n        mock_helper().get_active_runs.return_value = [\"mock_run_1\", \"mock_run_2\"]\n        response = client.get(\"analytics/runs/active\")\n        assert response.status_code == 200\n        assert response.json() == [\"mock_run_1\", \"mock_run_2\"]\n\ndef test_get_tools_user_success():\n    with patch('autospark.controllers.analytics.ToolsHandler') as mock_handler:\n        mock_handler().calculate_tool_usage.return_value = [\"tool1\", \"tool2\"]\n        response = client.get(\"analytics/tools/used\")\n        assert response.status_code == 200\n        assert response.json() == [\"tool1\", \"tool2\"]"}
{"type": "test_file", "path": "tests/tools/google_calendar/event_details_test.py", "content": "import unittest\nfrom unittest.mock import MagicMock, patch\nfrom pydantic import ValidationError\nfrom autospark.tools.google_calendar.event_details_calendar import EventDetailsCalendarInput, EventDetailsCalendarTool\nfrom autospark.helper.google_calendar_creds import GoogleCalendarCreds\n\nclass TestEventDetailsCalendarInput(unittest.TestCase):\n    def test_invalid_input(self):\n        with self.assertRaises(ValidationError):\n            EventDetailsCalendarInput(event_id=None)\n    \n    def test_valid_input(self):\n        input_data = EventDetailsCalendarInput(event_id=\"test_event_id\")\n        self.assertEqual(input_data.event_id, \"test_event_id\")\n\nclass TestEventDetailsCalendarTool(unittest.TestCase):\n    def setUp(self):\n        self.tool = EventDetailsCalendarTool()\n\n    def test_no_credentials(self):\n        with patch.object(GoogleCalendarCreds, 'get_credentials') as mock_get_credentials:\n            mock_get_credentials.return_value = {\"success\": False}\n            result = self.tool._execute(event_id=\"test_event_id\")\n            self.assertEqual(result, \"Kindly connect to Google Calendar\")\n\n    def test_no_event_id(self):\n        with patch.object(GoogleCalendarCreds, 'get_credentials') as mock_get_credentials:\n            mock_get_credentials.return_value = {\"success\": True}\n            result = self.tool._execute(event_id=\"None\")\n            self.assertEqual(result, \"Add Event ID to fetch details of an event from Google Calendar\")\n\n    def test_valid_event(self):\n        event_data = {\n            'summary': 'Test Meeting',\n            'start': {'dateTime': '2022-01-01T09:00:00'},\n            'end': {'dateTime': '2022-01-01T10:00:00'},\n            'attendees': [{'email': 'attendee1@example.com'},\n                          {'email': 'attendee2@example.com'}]\n        }\n        with patch.object(GoogleCalendarCreds, 'get_credentials') as mock_get_credentials:\n            with patch('your_module.base64.b64decode') as mock_b64decode:\n                mock_get_credentials.return_value = {\"success\": True, \"service\": MagicMock()}\n                service = mock_get_credentials.return_value[\"service\"]\n                service.events().get.return_value.execute.return_value = event_data\n                mock_b64decode.return_value.decode.return_value = \"decoded_event_id\"\n                result = self.tool._execute(event_id=\"test_event_id\")\n                mock_b64decode.assert_called_once_with(\"test_event_id\")\n                service.events().get.assert_called_once_with(calendarId=\"primary\", eventId=\"decoded_event_id\")\n                expected_output = (\"Event details for the event id 'test_event_id' is - \\n\"\n                                   \"Summary : Test Meeting\\n\"\n                                   \"Start Date and Time : 2022-01-01T09:00:00\\n\"\n                                   \"End Date and Time : 2022-01-01T10:00:00\\n\"\n                                   \"Attendees : attendee1@example.com,attendee2@example.com\")\n                self.assertEqual(result, expected_output)\n\nif __name__ == '__main__':\n    unittest.main()"}
{"type": "test_file", "path": "tests/integration_tests/vector_store/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/helper/test_json_cleaner.py", "content": "from autospark.helper.json_cleaner import JsonCleaner\nimport pytest\n\ndef test_preprocess_json_input():\n    test_str = r'This is a test\\ string'\n    result = JsonCleaner.preprocess_json_input(test_str)\n    assert result == r'This is a test\\\\ string'\n\ndef test_extract_json_section():\n    test_str = 'Before json {\"key\":\"value\"} after json'\n    result = JsonCleaner.extract_json_section(test_str)\n    assert result == '{\"key\":\"value\"}'\n\ndef test_remove_escape_sequences():\n    test_str = r'This is a test\\nstring'\n    result = JsonCleaner.remove_escape_sequences(test_str)\n    assert result == 'This is a test\\nstring'\n\ndef test_add_quotes_to_property_names():\n    test_str = '{key: \"value\"}'\n    result = JsonCleaner.add_quotes_to_property_names(test_str)\n    assert result == '{\"key\": \"value\"}'\n\ndef test_balance_braces():\n    test_str = '{{{{\"key\":\"value\"}}'\n    result = JsonCleaner.balance_braces(test_str)\n    assert result == '{{{{\"key\":\"value\"}}}}'\n\ndef test_check_and_clean_json():\n    test_str = r'{key: \"value\"\\n}'\n    result = JsonCleaner.check_and_clean_json(test_str)\n    assert result == '{key: \"value\"}'\n\n\ndef test_clean_newline_spaces_json():\n    test_str = r'{key: \"value\"\\n    \\n}'\n    result = JsonCleaner.check_and_clean_json(test_str)\n    assert result == '{key: \"value\"}'\n\ndef test_has_newline_in_string():\n    test_str = r'{key: \"value\\n\"\\n    \\n}'\n    result = JsonCleaner.check_and_clean_json(test_str)\n    assert result == '{key: \"value\"}'\n"}
{"type": "test_file", "path": "tests/unit_tests/helper/test_github_helper.py", "content": "import base64\nimport unittest\nfrom unittest.mock import patch, MagicMock\n\nfrom autospark.helper.github_helper import GithubHelper\n\nclass TestGithubHelper(unittest.TestCase):\n    @patch('requests.get')\n    def test_check_repository_visibility(self, mock_get):\n        # Create response mock\n        mock_resp = MagicMock()\n        mock_resp.status_code = 200\n        mock_resp.json.return_value = {'private': False}\n        mock_get.return_value = mock_resp\n\n        gh = GithubHelper('access_token', 'username')\n        visibility = gh.check_repository_visibility('owner', 'repo')\n\n        self.assertEqual(visibility, False)\n        mock_get.assert_called_once_with(\n            \"https://api.github.com/repos/owner/repo\",\n            headers={\"Authorization\": \"Token access_token\", \"Accept\": \"application/vnd.github.v3+json\"}\n        )\n\n    @patch('requests.get')\n    def test_get_file_path(self, mock_get):\n        gh = GithubHelper('access_token', 'username')\n        path = gh.get_file_path('test.txt', 'dir')\n        self.assertEqual(path, 'dir/test.txt')\n\n\n    @patch('requests.get')\n    def test_search_repo(self, mock_get):\n        # Create response mock\n        mock_resp = MagicMock()\n        mock_resp.raise_for_status.return_value = None\n        mock_resp.json.return_value = 'data'\n        mock_get.return_value = mock_resp\n\n        gh = GithubHelper('access_token', 'username')\n        data = gh.search_repo('owner', 'repo', 'test.txt', '')\n\n        self.assertEqual(data, 'data')\n        mock_get.assert_called_once_with(\n            'https://api.github.com/repos/owner/repo/contents/test.txt',\n            headers={\"Authorization\": \"token access_token\", \"Content-Type\": \"application/vnd.github+json\"}\n        )\n\n    @patch('requests.get')\n    @patch('requests.patch')\n    def test_sync_branch(self, mock_patch, mock_get):\n        # Create response mocks\n        mock_get_resp = MagicMock()\n        mock_get_resp.json.return_value = {'commit': {'sha': 'sha'}}\n        mock_get.return_value = mock_get_resp\n        mock_patch_resp = MagicMock()\n        mock_patch_resp.status_code = 200\n        mock_patch.return_value = mock_patch_resp\n\n        gh = GithubHelper('access_token', 'username')\n        gh.sync_branch('owner', 'repo', 'base', 'head', {'header': 'value'})\n\n        mock_get.assert_called_once_with(\n            'https://api.github.com/repos/owner/repo/branches/base',\n            headers={'header': 'value'}\n        )\n        mock_patch.assert_called_once_with(\n            'https://api.github.com/repos/username/repo/git/refs/heads/head',\n            json={'sha': 'sha', 'force': True},\n            headers={'header': 'value'}\n        )\n\n    @patch('requests.get')\n    @patch('requests.post')\n    def test_create_branch(self, mock_post, mock_get):\n        # Create response mocks\n        mock_get_resp = MagicMock()\n        mock_get_resp.json.return_value = {'object': {'sha': 'sha'}}\n        mock_get.return_value = mock_get_resp\n        mock_post_resp = MagicMock()\n        mock_post_resp.status_code = 201\n        mock_post.return_value = mock_post_resp\n\n        gh = GithubHelper('access_token', 'username')\n        status_code = gh.create_branch('repo', 'base', 'head', {'header': 'value'})\n\n        self.assertEqual(status_code, 201)\n        mock_get.assert_called_once_with(\n            'https://api.github.com/repos/username/repo/git/refs/heads/base',\n            headers={'header': 'value'}\n        )\n        mock_post.assert_called_once_with(\n            'https://api.github.com/repos/username/repo/git/refs',\n            json={'ref': 'refs/heads/head', 'sha': 'sha'},\n            headers={'header': 'value'}\n        )\n\n    @patch('requests.post')\n    def test_make_fork(self, mock_post):\n        # Create response mock\n        mock_resp = MagicMock()\n        mock_resp.status_code = 202\n        mock_post.return_value = mock_resp\n\n        gh = GithubHelper('access_token', 'username')\n        with patch.object(GithubHelper, 'sync_branch') as mock_sync:\n            status_code = gh.make_fork('owner', 'repo', 'base', {'header': 'value'})\n\n        self.assertEqual(status_code, 202)\n        mock_post.assert_called_once_with(\n            'https://api.github.com/repos/owner/repo/forks',\n            headers={'header': 'value'}\n        )\n        mock_sync.assert_called_once_with('owner', 'repo', 'base', 'base', {'header': 'value'})\n\n    @patch('requests.delete')\n    def test_delete_file(self, mock_delete):\n        # Create response mock\n        mock_resp = MagicMock()\n        mock_resp.status_code = 200\n        mock_delete.return_value = mock_resp\n\n        gh = GithubHelper('access_token', 'username')\n        with patch.object(GithubHelper, 'get_sha', return_value='sha') as mock_sha:\n            status_code = gh.delete_file('repo', 'test.txt', 'path', 'message', 'head', {'header': 'value'})\n\n        self.assertEqual(status_code, 200)\n        mock_sha.assert_called_once_with('username', 'repo', 'test.txt', 'path')\n        mock_delete.assert_called_once_with(\n            'https://api.github.com/repos/username/repo/contents/path/test.txt',\n            json={'message': 'message', 'sha': 'sha', 'branch': 'head'},\n            headers={'header': 'value'}\n        )\n\n    @patch('requests.put')\n    def test_add_file(self, mock_put):\n        # Create response mock\n        mock_resp = MagicMock()\n        mock_resp.status_code = 201\n        mock_put.return_value = mock_resp\n\n        gh = GithubHelper('access_token', 'username')\n        status_code = gh.add_file('owner', 'repo', 'test.txt', 'path', 'head', 'base', {'header': 'value'}, 'body',\n                                  'message')\n\n        self.assertEqual(status_code, 201)\n        mock_put.assert_called_once_with(\n            'https://api.github.com/repos/username/repo/contents/path/test.txt',\n            json={\n                'message': 'message',\n                'content': base64.b64encode('body'.encode(\"ascii\")).decode(\"ascii\"),\n                'branch': 'head'\n            },\n            headers={'header': 'value'}\n        )\n\n    @patch('requests.post')\n    def test_create_pull_request(self, mock_post):\n        # Create response mock\n        mock_resp = MagicMock()\n        mock_resp.status_code = 201\n        mock_post.return_value = mock_resp\n\n        gh = GithubHelper('access_token', 'username')\n        status_code = gh.create_pull_request('owner', 'repo', 'head', 'base', {'header': 'value'})\n\n        self.assertEqual(status_code, 201)\n        mock_post.assert_called_once_with(\n            'https://api.github.com/repos/owner/repo/pulls',\n            json={\n                'title': 'Pull request by username',\n                'body': 'Please review and merge this change.',\n                'head': 'username:head',\n                'head_repo': 'repo',\n                'base': 'base'\n            },\n            headers={'header': 'value'}\n        )\n\n    # ... more tests for other methods\n\nif __name__ == '__main__':\n    unittest.main()"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/notion/tests/test_notion_toolkit.py", "content": "import pytest\nfrom unittest.mock import patch, Mock\n\nfrom ..notion_create_page import NotionCreatePageTool\nfrom ..notion_fetch_page import NotionfetchPageTool\nfrom ..notion_toolkit import NotionToolkit\n\ndef test_notion_toolkit_properties():\n    toolkit = NotionToolkit()\n    assert toolkit.name == \"Notion Toolkit\"\n    assert toolkit.description == \"Toolkit containing tools for performing notion operations\"\n\ndef test_get_tools():\n    toolkit = NotionToolkit()\n    tools = toolkit.get_tools()\n    assert isinstance(tools, list)\n    assert len(tools) == 2\n    print(type(tools[0]))\n    print(type(NotionCreatePageTool))\n    assert isinstance(tools[0], NotionCreatePageTool)\n    assert isinstance(tools[1], NotionfetchPageTool)\n\ndef test_get_env_keys():\n    toolkit = NotionToolkit()\n    keys = toolkit.get_env_keys()\n    assert isinstance(keys, list)\n    assert len(keys) == 2\n    assert keys == [\"NOTION_TOKEN\", \"NOTION_DATABASE_ID\"]"}
{"type": "test_file", "path": "tests/integration_tests/vector_store/test_weaviate.py", "content": "import numpy as np\nimport pytest\n\nfrom autospark.vector_store import weaviate\nfrom autospark.vector_store.document import Document\nfrom autospark.vector_store.embedding.openai import OpenAiEmbedding\n\n\n@pytest.fixture\ndef client():\n    client = weaviate.create_weaviate_client(use_embedded=True)\n    yield client\n    client.schema.delete_all()\n\n\n@pytest.fixture\ndef mock_openai_embedding(monkeypatch):\n    monkeypatch.setattr(\n        OpenAiEmbedding,\n        \"get_embedding\",\n        lambda self, text: np.random.random(3).tolist(),\n    )\n\n\n@pytest.fixture\ndef store(client, mock_openai_embedding):\n    client.schema.delete_all()\n    yield weaviate.Weaviate(\n        client, OpenAiEmbedding(api_key=\"test_api_key\"), \"Test_index\", \"text\"\n    )\n\n\n@pytest.fixture\ndef dataset():\n    book_titles = [\n        \"The Great Gatsby\",\n        \"To Kill a Mockingbird\",\n        \"1984\",\n        \"Pride and Prejudice\",\n        \"The Catcher in the Rye\",\n    ]\n\n    documents = []\n    for i, title in enumerate(book_titles):\n        author = f\"Author {i}\"\n        description = f\"A summary of {title}\"\n        text_content = f\"This is the text for {title}\"\n        metadata = {\"author\": author, \"description\": description}\n        document = Document(text_content=text_content, metadata=metadata)\n\n        documents.append(document)\n\n    return documents\n\n\n@pytest.fixture\ndef dataset_no_metadata():\n    book_titles = [\n        \"The Lord of the Rings\",\n        \"The Hobbit\",\n        \"The Chronicles of Narnia\",\n    ]\n\n    documents = []\n    for title in book_titles:\n        text_content = f\"This is the text for {title}\"\n        document = Document(text_content=text_content)\n        documents.append(document)\n\n    return documents\n\n\n@pytest.mark.parametrize(\n    \"data, results\",\n    [\n        (\"dataset\", (5, 2)),\n        (\"dataset_no_metadata\", (3, 0)),\n    ],\n)\ndef test_add_texts(store, data, results, request):\n    dataset = request.getfixturevalue(data)\n    count, num_metadata = results\n    ids = store.add_documents(dataset)\n    metadata_fields = store._get_metadata_fields()\n    assert len(ids) == count\n    assert len(metadata_fields) == num_metadata\n\n    # manual cleanup because you will upload to the same index again\n    store.client.schema.delete_all()\n\n\ndef test_get_matching_text(store, dataset):\n    store.add_documents(dataset)\n    results = store.get_matching_text(\"The Great Gatsby\", top_k=2)\n    assert len(results) == 2\n    assert results[0] == dataset[0]\n"}
{"type": "test_file", "path": "tests/unit_tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/tools/google_calendar/list_events_test.py", "content": "import unittest\nfrom datetime import datetime\nfrom unittest.mock import MagicMock, patch\nfrom pydantic import ValidationError\nfrom autospark.tools.google_calendar.list_calendar_events import ListCalendarEventsInput, ListCalendarEventsTool\nfrom autospark.helper.google_calendar_creds import GoogleCalendarCreds\nfrom autospark.helper.calendar_date import CalendarDate\n\nclass TestListCalendarEventsInput(unittest.TestCase):\n    \n    def test_valid_input(self):\n        input_data = {\n            \"start_time\": \"20:00:00\",\n            \"start_date\": \"2022-11-10\",\n            \"end_date\": \"2022-11-11\",\n            \"end_time\": \"22:00:00\",\n        }\n        try:\n            ListCalendarEventsInput(**input_data)\n            validation_passed = True\n        except ValidationError:\n            validation_passed = False\n        self.assertEqual(validation_passed, True)\n    \n    def test_invalid_input(self):\n        input_data = {\n            \"start_time\": \"invalid time\",\n            \"start_date\": \"invalid date\",\n            \"end_date\": \"another invalid date\",\n            \"end_time\": \"another invalid time\",\n        }\n        with self.assertRaises(ValidationError):\n            ListCalendarEventsInput(**input_data)\n\nclass TestListCalendarEventsTool(unittest.TestCase):\n    @patch.object(GoogleCalendarCreds, 'get_credentials')\n    @patch.object(CalendarDate, 'get_date_utc')\n    \n    def test_without_events(self, mock_get_date_utc, mock_get_credentials):\n        tool = ListCalendarEventsTool()\n        mock_get_credentials.return_value = {\n            \"success\": True,\n            \"service\": MagicMock()\n        }\n        mock_service = mock_get_credentials()[\"service\"]\n        mock_service.events().list().execute.return_value = {}\n        mock_get_date_utc.return_value = {\n            'start_datetime_utc': datetime.now().isoformat(),\n            'end_datetime_utc': datetime.now().isoformat()\n        }\n        result = tool._execute('20:00:00', '2022-11-10', '2022-11-11', '22:00:00')\n        self.assertEqual(result, \"No events found for the given date and time range.\")\n\nif __name__ == \"__main__\":\n    unittest.main()\n\n\n\n\n\n\n\n\n\n"}
{"type": "test_file", "path": "tests/unit_tests/agent/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/tools/google_calendar/delete_event_test.py", "content": "import unittest\nfrom unittest.mock import Mock, patch\nfrom pydantic import ValidationError\nfrom autospark.tools.google_calendar.delete_calendar_event import DeleteCalendarEventInput, DeleteCalendarEventTool\n\nclass TestDeleteCalendarEventInput(unittest.TestCase):\n    def test_valid_input(self):\n        input_data = {\"event_id\": \"123456\"}\n        input_obj = DeleteCalendarEventInput(**input_data)\n        self.assertEqual(input_obj.event_id, \"123456\")\n\n    def test_invalid_input(self):\n        input_data = {\"event_id\": \"\"}\n        with self.assertRaises(ValidationError):\n            DeleteCalendarEventInput(**input_data)\n\nclass TestDeleteCalendarEventTools(unittest.TestCase):\n    def setUp(self):\n        self.delete_tool = DeleteCalendarEventTool()\n    @patch(\"your_module.GoogleCalendarCreds\")\n\n    def test_execute_delete_event_with_valid_id(self, mock_google_calendar_creds):\n        credentials_obj = Mock()\n        credentials_obj.get_credentials.return_value = {\"success\": True, \"service\": Mock()}\n        mock_google_calendar_creds.return_value = credentials_obj\n        self.assertEqual(self.delete_tool._execute(\"123456\"), \"Event Successfully deleted from your Google Calendar\")\n    @patch(\"your_module.GoogleCalendarCreds\")\n\n    def test_execute_delete_event_with_no_id(self, mock_google_calendar_creds):\n        self.assertEqual(self.delete_tool._execute(\"None\"), \"Add Event ID to delete an event from Google Calendar\")\n    @patch(\"your_module.GoogleCalendarCreds\")\n\n    def test_execute_delete_event_with_no_credentials(self, mock_google_calendar_creds):\n        credentials_obj = Mock()\n        credentials_obj.get_credentials.return_value = {\"success\": False}\n        mock_google_calendar_creds.return_value = credentials_obj\n        self.assertEqual(self.delete_tool._execute(\"123456\"), \"Kindly connect to Google Calendar\")\n\nif __name__ == \"__main__\":\n    unittest.main()"}
{"type": "test_file", "path": "tests/integration_tests/vector_store/test_qdrant.py", "content": "import pytest\nimport numpy as np\n\nfrom autospark.vector_store import qdrant\nfrom autospark.vector_store.embedding.openai import OpenAiEmbedding\nfrom qdrant_client.models import Distance, VectorParams\nfrom qdrant_client import QdrantClient\n\n\n@pytest.fixture\ndef client():\n    client = QdrantClient(\":memory:\")\n    yield client\n\n\n@pytest.fixture\ndef mock_openai_embedding(monkeypatch):\n    monkeypatch.setattr(\n        OpenAiEmbedding,\n        \"get_embedding\",\n        lambda self, text: np.random.random(3).tolist(),\n    )\n\n\n@pytest.fixture\ndef store(client, mock_openai_embedding):\n    client.create_collection(\n        collection_name=\"Test_collection\",\n        vectors_config=VectorParams(size=3, distance=Distance.COSINE),\n    )\n    yield qdrant.Qdrant(client, OpenAiEmbedding(api_key=\"test_api_key\"), \"Test_collection\")\n    client.delete_collection(\"Test_collection\")\n\n\ndef test_add_texts(store):\n    car_companies = [\n        \"Rolls-Royce\",\n        \"Bentley\",\n        \"Ferrari\",\n        \"Lamborghini\",\n        \"Aston Martin\",\n        \"Porsche\",\n        \"Bugatti\",\n        \"Maserati\",\n        \"McLaren\",\n        \"Mercedes-Benz\"\n    ]\n    assert len(store.add_texts(car_companies)) == len(car_companies)\n\n\ndef test_get_matching_text(store):\n    car_companies = [\n        \"Rolls-Royce\",\n        \"Bentley\",\n        \"Ferrari\",\n        \"Lamborghini\",\n        \"Aston Martin\",\n        \"Porsche\",\n        \"Bugatti\",\n        \"Maserati\",\n        \"McLaren\",\n        \"Mercedes-Benz\"\n    ]\n    store.add_texts(car_companies)\n    assert len(store.get_matching_text(k=2, text=\"McLaren\")) == 2\n"}
{"type": "test_file", "path": "tests/tools/google_calendar/create_event_test.py", "content": "import unittest\nfrom unittest.mock import MagicMock, patch\nfrom pydantic import ValidationError\nfrom datetime import datetime, timedelta\nfrom autospark.tools.google_calendar.create_calendar_event import CreateEventCalendarInput, CreateEventCalendarTool\nfrom autospark.helper.google_calendar_creds import GoogleCalendarCreds\nfrom autospark.helper.calendar_date import CalendarDate\n\nclass TestCreateEventCalendarInput(unittest.TestCase):\n    def test_create_event_calendar_input_valid(self):\n        input_data = {\n            \"event_name\": \"Test Event\",\n            \"description\": \"A test event.\",\n            \"start_date\": \"2022-01-01\",\n            \"start_time\": \"12:00:00\",\n            \"end_date\": \"2022-01-01\",\n            \"end_time\": \"13:00:00\",\n            \"attendees\": [\"test@example.com\"],\n            \"location\": \"London\"\n        }\n        try:\n            CreateEventCalendarInput(**input_data)\n        except ValidationError:\n            self.fail(\"ValidationError raised with valid input_data\")\n\n    def test_create_event_calendar_input_invalid(self):\n        input_data = {\n            \"event_name\": \"Test Event\",\n            \"description\": \"A test event.\",\n            \"start_date\": \"2022-99-99\",\n            \"start_time\": \"12:60:60\",\n            \"end_date\": \"2022-99-99\",\n            \"end_time\": \"13:60:60\",\n            \"attendees\": [\"test@example.com\"],\n            \"location\": \"London\"\n        }\n        with self.assertRaises(ValidationError):\n            CreateEventCalendarInput(**input_data)\n\nclass TestCreateEventCalendarTool(unittest.TestCase):\n    def setUp(self):\n        self.create_event_tool = CreateEventCalendarTool()\n    @patch.object(GoogleCalendarCreds, \"get_credentials\")\n    @patch.object(CalendarDate, \"create_event_dates\")\n\n    def test_execute(self, mock_create_event_dates, mock_get_credentials):\n        mock_get_credentials.return_value = {\n            \"success\": True,\n            \"service\": MagicMock()\n        }\n        mock_date_utc = {\n            \"start_datetime_utc\": (datetime.utcnow() + timedelta(hours=1)).isoformat(),\n            \"end_datetime_utc\": (datetime.utcnow() + timedelta(hours=2)).isoformat(),\n            \"timeZone\": \"UTC\"\n        }\n        mock_create_event_dates.return_value = mock_date_utc\n        mock_service = MagicMock()\n        mock_service.events.return_value = MagicMock()\n        output_str_expected = f\"Event Test Event at {mock_date_utc['start_datetime_utc']} created successfully, link for the event {'https://somerandomlink'}\"\n        output_str = self.create_event_tool._execute(\"Test Event\", \"A test event\", [\"test@example.com\"], start_date=\"2022-01-01\", start_time=\"12:00:00\", end_date=\"2022-01-01\", end_time=\"13:00:00\", location=\"London\")\n        self.assertEqual(output_str, output_str_expected)\n        event = {\n            \"summary\": \"Test Event\",\n            \"description\": \"A test event\",\n            \"start\": {\n                \"dateTime\": mock_date_utc[\"start_datetime_utc\"],\n                \"timeZone\": mock_date_utc[\"timeZone\"]\n            },\n            \"end\": {\n                \"dateTime\": mock_date_utc[\"end_datetime_utc\"],\n                \"timeZone\": mock_date_utc[\"timeZone\"]\n            },\n            \"attendees\": [{\"email\": \"test@example.com\"}],\n            \"location\": \"London\"\n        }\n        mock_get_credentials.assert_called_once()\n        mock_create_event_dates.assert_called_once_with(mock_service, \"2022-01-01\", \"12:00:00\", \"2022-01-01\", \"13:00:00\")\n        mock_service.events().insert.assert_called_once_with(calendarId=\"primary\", body=event, conferenceDataVersion=1)\n\nif __name__ == \"__main__\":\n    unittest.main()"}
{"type": "test_file", "path": "tests/unit_tests/apm/test_event_handler.py", "content": "import pytest\nfrom sqlalchemy.exc import SQLAlchemyError\nfrom autospark.models.events import Event\nfrom unittest.mock import MagicMock\n\nfrom autospark.apm.event_handler import EventHandler\n\n@pytest.fixture\ndef mock_session():\n    return MagicMock()\n\n@pytest.fixture\ndef event_handler(mock_session):\n    return EventHandler(mock_session)\n\ndef test_create_event_success(event_handler, mock_session):\n    mock_session.add = MagicMock()\n    mock_session.commit = MagicMock()\n    event = event_handler.create_event('test', {}, 1, 1, 100)\n\n    assert isinstance(event, Event)\n    mock_session.add.assert_called_once()\n    mock_session.commit.assert_called_once()\n\ndef test_create_event_failure(event_handler, mock_session):\n    mock_session.commit = MagicMock(side_effect=SQLAlchemyError())\n    event = event_handler.create_event('test', {}, 1, 1, 100)\n    assert event is None"}
{"type": "test_file", "path": "tests/unit_tests/controllers/test_toolkit.py", "content": "from unittest.mock import patch\n\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom main import app\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.tool import Tool\nfrom autospark.models.tool_config import ToolConfig\nfrom autospark.models.toolkit import Toolkit\n\nclient = TestClient(app)\n\n\n@pytest.fixture\ndef mocks():\n    # Mock tool kit data for testing\n    user_organisation = Organisation(id=1)\n    toolkit_1 = Toolkit(\n        id=1,\n        name=\"toolkit_1\",\n        description=\"None\",\n        show_toolkit=None,\n        organisation_id=1\n    )\n    toolkit_2 = Toolkit(\n        id=1,\n        name=\"toolkit_2\",\n        description=\"None\",\n        show_toolkit=None,\n        organisation_id=1\n    )\n    user_toolkits = [toolkit_1, toolkit_2]\n    tool_1 = Tool(\n        id=1,\n        name=\"tool_1\",\n        description=\"Test Tool\",\n        folder_name=\"test folder\",\n        file_name=\"test file\",\n        toolkit_id=1\n    )\n    tool_2 = Tool(\n        id=1,\n        name=\"tool_2\",\n        description=\"Test Tool\",\n        folder_name=\"test folder\",\n        file_name=\"test file\",\n        toolkit_id=1\n    )\n    tool_3 = Tool(\n        id=1,\n        name=\"tool_3\",\n        description=\"Test Tool\",\n        folder_name=\"test folder\",\n        file_name=\"test file\",\n        toolkit_id=2\n    )\n    tools = [tool_1, tool_2, tool_3]\n    return user_organisation, user_toolkits, tools, toolkit_1, toolkit_2, tool_1, tool_2, tool_3\n\n\ndef test_handle_marketplace_operations_list(mocks):\n    # Unpack the fixture data\n    user_organisation, user_toolkits, tools, toolkit_1, toolkit_2, tool_1, tool_2, tool_3 = mocks\n\n    # Mock the database session and query functions\n    with patch('autospark.helper.auth.get_user_organisation') as mock_get_user_org, \\\n            patch('autospark.controllers.toolkit.db') as mock_db, \\\n            patch('autospark.models.toolkit.Toolkit.fetch_marketplace_list') as mock_fetch_marketplace_list, \\\n            patch('autospark.helper.auth.db') as mock_auth_db:\n\n        # Set up mock data\n        mock_db.session.query.return_value.filter.return_value.all.side_effect = [user_toolkits]\n        mock_fetch_marketplace_list.return_value = [toolkit_1.to_dict(), toolkit_2.to_dict()]\n\n        # Call the function\n        response = client.get(\"/toolkits/get/list\", params={\"page\": 0})\n\n        # Assertions\n        assert response.status_code == 200\n        assert response.json() == [\n            {\n                \"id\": 1,\n                \"name\": \"toolkit_1\",\n                \"description\": \"None\",\n                \"show_toolkit\": None,\n                \"organisation_id\": 1,\n                \"is_installed\": True\n            },\n            {\n                \"id\": 1,\n                \"name\": \"toolkit_2\",\n                \"description\": \"None\",\n                \"show_toolkit\": None,\n                \"organisation_id\": 1,\n                \"is_installed\": True\n            }\n        ]\n"}
{"type": "test_file", "path": "tests/unit_tests/controllers/test_tool_config.py", "content": "from unittest.mock import MagicMock, patch\n\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom main import app\nfrom autospark.controllers.tool_config import update_tool_config\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.tool_config import ToolConfig\nfrom autospark.models.toolkit import Toolkit\n\nclient = TestClient(app)\n\n\n@pytest.fixture\ndef mocks():\n    # Mock tool kit data for testing\n    user_organisation = Organisation(id=1)\n    toolkit_1 = Toolkit(\n        id=1,\n        name=\"toolkit_1\",\n        description=\"None\",\n        show_toolkit=None,\n        organisation_id=1\n    )\n    toolkit_2 = Toolkit(\n        id=1,\n        name=\"toolkit_2\",\n        description=\"None\",\n        show_toolkit=None,\n        organisation_id=1\n    )\n    user_toolkits = [toolkit_1, toolkit_2]\n    tool_config = ToolConfig(\n        id=1,\n        key=\"test_key\",\n        value=\"test_value\",\n        toolkit_id=1\n    )\n    return user_organisation, user_toolkits, tool_config, toolkit_1, toolkit_2\n\n\n# Test cases\ndef test_update_tool_configs_success():\n    # Test data\n    toolkit_name = \"toolkit_1\"\n    configs = [\n        {\"key\": \"config_1\", \"value\": \"value_1\"},\n        {\"key\": \"config_2\", \"value\": \"value_2\"},\n    ]\n\n    with patch('autospark.models.toolkit.Toolkit.get_toolkit_from_name') as get_toolkit_from_name, \\\n            patch('autospark.controllers.tool_config.db') as mock_db:\n        mock_db.query.return_value.filter_by.return_value.first.side_effect = [\n            # First call to query\n            MagicMock(\n                toolkit_id=1, key=\"config_1\", value=\"old_value_1\"\n            ),\n            # Second call to query\n            MagicMock(\n                toolkit_id=1, key=\"config_2\", value=\"old_value_2\"\n            ),\n        ]\n\n        result = update_tool_config(toolkit_name, configs)\n\n        assert result == {\"message\": \"Tool configs updated successfully\"}\n\n\ndef test_get_all_tool_configs_success(mocks):\n    user_organisation, user_toolkits, tool_config, toolkit_1, toolkit_2 = mocks\n\n    with patch('autospark.helper.auth.get_user_organisation') as mock_get_user_org, \\\n            patch('autospark.controllers.tool_config.db') as mock_db, \\\n            patch('autospark.helper.auth.db') as mock_auth_db:\n        mock_db.session.query.return_value.filter_by.return_value.first.return_value = toolkit_1\n        mock_db.session.query.return_value.filter.return_value.all.side_effect = [\n            [tool_config]\n        ]\n        response = client.get(f\"/tool_configs/get/toolkit/test_toolkit_1\")\n\n        # Assertions\n        assert response.status_code == 200\n        assert response.json() == [\n            {\n                'id': 1,\n                'key': tool_config.key,\n                'value': tool_config.value,\n                'toolkit_id': tool_config.toolkit_id\n            }\n        ]\n\n\ndef test_get_all_tool_configs_toolkit_not_found(mocks):\n    user_organisation, _, _, _, _ = mocks\n\n    with patch('autospark.helper.auth.get_user_organisation') as mock_get_user_org, \\\n            patch('autospark.controllers.tool_config.db') as mock_db, \\\n            patch('autospark.helper.auth.db') as mock_auth_db:\n        mock_db.session.query.return_value.filter.return_value.first.return_value = None\n        response = client.get(f\"/tool_configs/get/toolkit/nonexistent_toolkit\")\n\n        # Assertions\n        assert response.status_code == 404\n        assert response.json() == {'detail': 'ToolKit not found'}\n\ndef test_get_tool_config_success(mocks):\n    # Unpack the fixture data\n    user_organisation, user_toolkits, tool_config, toolkit_1, toolkit_2 = mocks\n\n    # Mock the database session and query functions\n    with patch('autospark.helper.auth.get_user_organisation') as mock_get_user_org, \\\n            patch('autospark.controllers.tool_config.db') as mock_db, \\\n            patch('autospark.helper.auth.db') as mock_auth_db:\n        mock_db.session.query.return_value.filter.return_value.all.return_value = user_toolkits\n        mock_db.session.query.return_value.filter_by.return_value = toolkit_1\n        mock_db.session.query.return_value.filter.return_value.first.return_value = tool_config\n\n        # Call the function\n        response = client.get(f\"/tool_configs/get/toolkit/{toolkit_1.name}/key/{tool_config.key}\")\n\n        # Assertions\n        assert response.status_code == 200\n        assert response.json() == {\n            \"id\": tool_config.id,\n            \"key\": tool_config.key,\n            \"value\": tool_config.value,\n            \"toolkit_id\": tool_config.toolkit_id\n        }\n\n\ndef test_get_tool_config_unauthorized(mocks):\n    # Unpack the fixture data\n    user_organisation, user_toolkits, tool_config, toolkit_1, toolkit_2 = mocks\n\n    # Mock the database session and query functions\n    with patch('autospark.helper.auth.get_user_organisation') as mock_get_user_org, \\\n            patch('autospark.controllers.tool_config.db') as mock_db, \\\n            patch('autospark.helper.auth.db') as mock_auth_db:\n        # Mock the toolkit filtering\n        mock_db.session.query.return_value.filter.return_value.all.return_value = user_toolkits\n\n        response = client.get(f\"/tool_configs/get/toolkit/{toolkit_2.name}/key/{tool_config.key}\")\n\n        # Assertions\n        assert response.status_code == 403\n        assert response.json() == {\"detail\": \"Unauthorized\"}\n\n\ndef test_get_tool_config_not_found(mocks):\n    # Unpack the fixture data\n    user_organisation, user_toolkits, tool_config, toolkit_1, toolkit_2 = mocks\n\n    # Mock the database session and query functions\n    with patch('autospark.helper.auth.get_user_organisation') as mock_get_user_org, \\\n            patch('autospark.controllers.tool_config.db') as mock_db, \\\n            patch('autospark.helper.auth.db') as mock_auth_db:\n        # Mock the toolkit filtering\n        mock_db.session.query.return_value.filter.return_value.all.return_value = user_toolkits\n        mock_db.session.query.return_value.filter_by.return_value = toolkit_1\n        mock_db.session.query.return_value.filter.return_value.first.return_value = None\n\n        # Call the function with a non-existent toolkit\n        response = client.get(f\"/tool_configs/get/toolkit/{toolkit_1.name}/key/{tool_config.key}\")\n\n        # Assertions\n        assert response.status_code == 404\n        assert response.json() == {\"detail\": \"Tool configuration not found\"}\n"}
{"type": "test_file", "path": "tests/unit_tests/helper/test_agent_schedule_helper.py", "content": "import pytest\nfrom unittest.mock import patch, MagicMock, call\nfrom autospark.helper.agent_schedule_helper import AgentScheduleHelper\nfrom autospark.models.agent_schedule import AgentSchedule\nfrom datetime import datetime, timedelta\n\n@patch('autospark.helper.agent_schedule_helper.parse_interval_to_seconds')\n@patch('autospark.models.agent_schedule.AgentSchedule')\n@patch('autospark.helper.agent_schedule_helper.Session')\n@patch('autospark.helper.agent_schedule_helper.datetime')\ndef test_update_next_scheduled_time(mock_datetime, mock_session, mock_agent_schedule, mock_parse_interval_to_seconds):\n    \n    mock_datetime.now.return_value = datetime(2022, 1, 1, 10, 0)\n\n    # Mock agent object\n    mock_agent = MagicMock()\n    mock_agent.start_time = datetime(2022, 1, 1, 1, 0)\n    mock_agent.next_scheduled_time = datetime(2022, 1, 1, 1, 0)\n    mock_agent.recurrence_interval = '5 Minutes'\n    mock_agent.status = 'SCHEDULED'\n\n    mock_agent_schedule.return_value = mock_agent\n\n    # Mock the return value of the session query\n    mock_session.return_value.query.return_value.filter.return_value.all.return_value = [mock_agent]\n    mock_parse_interval_to_seconds.return_value = 300\n\n    # Call the method\n    helperObj = AgentScheduleHelper()\n    helperObj.update_next_scheduled_time()\n\n    # Assert that the mocks were called as expected\n    mock_session.assert_called_once()\n    mock_session.return_value.query.assert_called_once()\n    mock_session.return_value.query.return_value.filter.assert_called()\n    mock_session.return_value.query.return_value.filter.return_value.all.assert_called_once()\n    mock_parse_interval_to_seconds.assert_called_once_with('5 Minutes')\n    assert mock_agent.status == 'SCHEDULED'\n\n\n@patch('autospark.helper.agent_schedule_helper.AgentScheduleHelper._AgentScheduleHelper__create_execution_name_for_scheduling')\n@patch('autospark.helper.agent_schedule_helper.AgentScheduleHelper._AgentScheduleHelper__should_execute_agent')\n@patch('autospark.helper.agent_schedule_helper.AgentScheduleHelper._AgentScheduleHelper__can_remove_agent')\n@patch('autospark.helper.agent_schedule_helper.AgentScheduleHelper._AgentScheduleHelper__execute_schedule')\n@patch('autospark.helper.agent_schedule_helper.parse_interval_to_seconds')\n@patch('autospark.helper.agent_schedule_helper.AgentSchedule')\n@patch('autospark.helper.agent_schedule_helper.Session')\n@patch('autospark.helper.agent_schedule_helper.datetime')\ndef test_run_scheduled_agents(\n    mock_datetime, \n    mock_session, \n    mock_agent_schedule, \n    mock_parse_interval_to_seconds, \n    mock_execute_schedule, \n    mock_can_remove_agent, \n    mock_should_execute_agent, \n    mock_create_execution_name_for_scheduling\n):\n\n    # Mocking current datetime\n    mock_datetime.now.return_value = datetime(2022, 1, 1, 10, 0)\n\n    # Mocking agent object\n    mock_agent = MagicMock(spec=AgentSchedule)\n    mock_agent.next_scheduled_time = datetime(2022, 1, 1, 9, 55)\n    mock_agent.status = 'SCHEDULED'\n    mock_agent.recurrence_interval = '5 Minutes'\n    mock_agent.agent_id = 'agent_1'\n\n    # Mocking the return value of the session query\n    mock_session.return_value.query.return_value.filter.return_value.all.return_value = [mock_agent]\n    mock_parse_interval_to_seconds.return_value = 300\n    \n    mock_should_execute_agent.return_value = True\n    mock_can_remove_agent.return_value = False\n    mock_create_execution_name_for_scheduling.return_value = 'Run 01 January 2022 10:00'\n\n    # Call the method\n    helper = AgentScheduleHelper()\n    helper.run_scheduled_agents()\n\n    # Assert that the mocks were called as expected\n    mock_session.assert_called_once_with()\n    mock_session.return_value.query.assert_called_once_with(mock_agent_schedule)\n    mock_session.return_value.query.return_value.filter.assert_called_once()\n    mock_session.return_value.query.return_value.filter.return_value.all.assert_called_once()\n    \n    mock_parse_interval_to_seconds.assert_has_calls([call('5 Minutes')])\n\n    mock_should_execute_agent.assert_called_once_with(mock_agent, mock_agent.recurrence_interval)\n    mock_can_remove_agent.assert_called_once_with(mock_agent, mock_agent.recurrence_interval)\n    \n    mock_execute_schedule.assert_has_calls([call(\n        mock_should_execute_agent.return_value, \n        mock_parse_interval_to_seconds.return_value, \n        mock_session(), \n        mock_agent, \n        mock_create_execution_name_for_scheduling.return_value\n    )])\n    \n    mock_create_execution_name_for_scheduling.assert_called_once_with(mock_agent.agent_id)\n"}
{"type": "test_file", "path": "tests/unit_tests/agent_permissions/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/apm/test_analytics_helper.py", "content": "import pytest\nfrom unittest.mock import MagicMock\nfrom autospark.apm.analytics_helper import AnalyticsHelper\nfrom sqlalchemy.orm import Session\n\n@pytest.fixture\ndef mock_session():\n    return MagicMock(spec=Session)\n\n@pytest.fixture\ndef organisation_id():\n    return 1\n\n@pytest.fixture\ndef analytics_helper(mock_session, organisation_id):\n    return AnalyticsHelper(mock_session, organisation_id)\n\ndef test_calculate_run_completed_metrics(analytics_helper, mock_session):\n    analytics_helper.calculate_run_completed_metrics = MagicMock(return_value = {})\n    result = analytics_helper.calculate_run_completed_metrics()\n    assert isinstance(result, dict)\n    analytics_helper.calculate_run_completed_metrics.assert_called()\n\ndef test_fetch_agent_data(analytics_helper, mock_session):\n    analytics_helper.fetch_agent_data = MagicMock(return_value = {})\n    result = analytics_helper.fetch_agent_data()\n    assert isinstance(result, dict)\n    analytics_helper.fetch_agent_data.assert_called()\n\ndef test_fetch_agent_runs(analytics_helper, mock_session):\n    agent_id = 1\n    analytics_helper.fetch_agent_runs = MagicMock(return_value = [])\n    result = analytics_helper.fetch_agent_runs(agent_id)\n    assert isinstance(result, list)\n    analytics_helper.fetch_agent_runs.assert_called_with(agent_id)\n\ndef test_get_active_runs(analytics_helper, mock_session):\n    analytics_helper.get_active_runs = MagicMock(return_value = [])\n    result = analytics_helper.get_active_runs()\n    assert isinstance(result, list)\n    analytics_helper.get_active_runs.assert_called()"}
{"type": "test_file", "path": "tests/unit_tests/helper/test_calendar_date.py", "content": "import unittest\nfrom unittest.mock import MagicMock\nfrom datetime import datetime, timezone\nimport pytz\n\nfrom autospark.helper.calendar_date import CalendarDate\n\n\nclass TestCalendarDate(unittest.TestCase):\n    def setUp(self):\n        self.cd = CalendarDate()\n        self.service = MagicMock()\n        self.service.calendars().get().execute.return_value = {'timeZone': 'Asia/Kolkata'}\n\n    def test_get_time_zone(self):\n        time_zone = self.cd._get_time_zone(self.service)\n        self.assertEqual(time_zone, 'Asia/Kolkata')\n\n    def test_convert_to_utc(self):\n        # Create a datetime object for midnight of January 1st, 2023.\n        local_datetime = datetime(2023, 1, 1)\n\n        # Use the 'US/Pacific' timezone for this example.\n        local_tz = pytz.timezone('US/Pacific')\n\n        # Call the function to convert the local datetime to UTC.\n        utc_datetime = self.cd._convert_to_utc(local_datetime, local_tz)\n\n        # Check that the converted datetime is correct.\n        # Note: The 'US/Pacific' timezone is 8 hours behind UTC during standard time.\n        expected_utc_datetime = datetime(2023, 1, 1, 8, 0)\n        expected_utc_datetime = pytz.timezone('GMT').localize(expected_utc_datetime)\n        assert utc_datetime == expected_utc_datetime\n\n    def test_string_to_datetime(self):\n        date_str = '2022-01-01'\n        date_format = '%Y-%m-%d'\n        date_obj = datetime.strptime(date_str, date_format)\n        self.assertEqual(date_obj, self.cd._string_to_datetime(date_str, date_format))\n\n    def test_localize_daterange(self):\n        start_date, end_date = '2022-01-01', '2022-01-02'\n        start_time, end_time = '10:00:00', '12:00:00'\n        local_tz = pytz.timezone('Asia/Kolkata')\n        start_datetime_utc, end_datetime_utc = self.cd._localize_daterange(start_date, end_date, start_time, end_time,\n                                                                           local_tz)\n\n        self.assertEqual(start_datetime_utc, datetime(2022, 1, 1, 4, 30, tzinfo=timezone.utc))\n        self.assertEqual(end_datetime_utc, datetime(2022, 1, 2, 6, 30, tzinfo=timezone.utc))\n\n    def test_datetime_to_string(self):\n        date_time = datetime(2022, 1, 1, 0, 0, 0)\n        date_format = '%Y-%m-%d'\n        date_str = '2022-01-01'\n        self.assertEqual(date_str, self.cd._datetime_to_string(date_time, date_format))\n\n    def test_get_date_utc(self):\n        start_date, end_date = '2022-01-01', '2022-01-02'\n        start_time, end_time = '10:00:00', '12:00:00'\n        date_utc = {\n            \"start_datetime_utc\": \"2022-01-01T04:30:00.000000Z\",\n            \"end_datetime_utc\": \"2022-01-02T06:30:00.000000Z\"\n        }\n        result = self.cd.get_date_utc(start_date, end_date, start_time, end_time, self.service)\n        self.assertEqual(date_utc, result)\n\n    def test_create_event_dates(self):\n        start_date, end_date = '2022-01-01', '2022-01-02'\n        start_time, end_time = '10:00:00', '12:00:00'\n        date_utc = {\n            \"start_datetime_utc\": \"2022-01-01T04:30:00.000000Z\",\n            \"end_datetime_utc\": \"2022-01-02T06:30:00.000000Z\",\n            \"timeZone\": \"Asia/Kolkata\"\n        }\n        result = self.cd.create_event_dates(self.service, start_date, start_time, end_date, end_time)\n        self.assertEqual(date_utc, result)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"}
{"type": "test_file", "path": "tests/unit_tests/agent_permissions/test_check_permission_in_restricted_mode.py", "content": "import pytest\nfrom unittest.mock import MagicMock, Mock\nfrom autospark.agent.output_parser import AgentOutputParser\nfrom autospark.agent.auto_spark import AutoSpark\nfrom autospark.llms.base_llm import BaseLlm\nfrom autospark_kit.tools.base_tool import BaseTool\nfrom autospark.vector_store.base import VectorStore\n\n\nclass MockTool(BaseTool):\n    def __init__(self, name, permission_required=False):\n        super().__init__(name=name, permission_required=permission_required, description=\"Mock tool\")\n\n    def _execute(self, *args, **kwargs):\n        pass\n\n\nclass MockSession:\n    def add(self, instance):\n        pass\n\n    def commit(self):\n        pass\n\n@pytest.fixture\ndef auto_spark():\n    ai_name = \"test_ai\"\n    ai_role = \"test_role\"\n    llm = Mock(spec=BaseLlm)\n    memory = Mock(spec=VectorStore)\n    tools = [MockTool(name=\"NotRestrictedTool\", permission_required=False),\n             MockTool(name=\"RestrictedTool\", permission_required=True)]\n    agent_config = {\"permission_type\": \"RESTRICTED\", \"agent_execution_id\": 1, \"agent_id\": 2}\n    output_parser = AgentOutputParser()\n\n    auto_spark = AutoSpark(ai_name, ai_role, llm, memory, tools, agent_config, output_parser)\n    return auto_spark\n\n\ndef test_check_permission_in_restricted_mode_not_required(auto_spark):\n    assistant_reply = \"Test reply\"\n\n    auto_spark.output_parser.parse = MagicMock(\n        return_value=MockTool(name=\"NotRestrictedTool\", permission_required=False))\n    result, output = auto_spark.check_permission_in_restricted_mode(assistant_reply, MockSession())\n    assert not result\n    assert output is None\n\n\ndef test_check_permission_in_restricted_mode_permission_required(auto_spark, monkeypatch):\n    assistant_reply = \"Test reply\"\n\n    mock_tool_requiring_permission = MockTool(name=\"RestrictedTool\", permission_required=True)\n    mock_tool_requiring_permission.permission_required = True\n    auto_spark.output_parser.parse = MagicMock(\n        return_value=mock_tool_requiring_permission)\n\n\n    # monkeypatch.setattr(\"autospark.agent.auto_spark.session\", MockSession())\n\n    result, output = auto_spark.check_permission_in_restricted_mode(assistant_reply, MockSession())\n    assert result\n    assert output[\"result\"] == \"WAITING_FOR_PERMISSION\"\n"}
{"type": "test_file", "path": "tests/integration_tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/controllers/test_tool.py", "content": "from unittest.mock import patch\n\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom main import app\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.tool import Tool\nfrom autospark.models.toolkit import Toolkit\n\nclient = TestClient(app)\n\n\n@pytest.fixture\ndef mocks():\n    # Mock tool kit data for testing\n    user_organisation = Organisation(id=1)\n    toolkit_1 = Toolkit(\n        id=1,\n        name=\"toolkit_1\",\n        description=\"None\",\n        show_toolkit=None,\n        organisation_id=1\n    )\n    toolkit_2 = Toolkit(\n        id=1,\n        name=\"toolkit_2\",\n        description=\"None\",\n        show_toolkit=None,\n        organisation_id=1\n    )\n    user_toolkits = [toolkit_1, toolkit_2]\n    tool_1 = Tool(\n        id=1,\n        name=\"tool_1\",\n        description=\"Test Tool\",\n        folder_name=\"test folder\",\n        file_name=\"test file\",\n        toolkit_id=1\n    )\n    tool_2 = Tool(\n        id=1,\n        name=\"tool_2\",\n        description=\"Test Tool\",\n        folder_name=\"test folder\",\n        file_name=\"test file\",\n        toolkit_id=1\n    )\n    tool_3 = Tool(\n        id=1,\n        name=\"tool_3\",\n        description=\"Test Tool\",\n        folder_name=\"test folder\",\n        file_name=\"test file\",\n        toolkit_id=2\n    )\n    tools = [tool_1, tool_2, tool_3]\n    return user_organisation, user_toolkits, tools, toolkit_1, toolkit_2, tool_1, tool_2, tool_3\n\n\ndef test_get_tools_success(mocks):\n    # Unpack the fixture data\n    user_organisation, user_toolkits, tools, toolkit_1, toolkit_2, tool_1, tool_2, tool_3 = mocks\n\n    # Mock the database session and query functions\n    with patch('autospark.helper.auth.get_user_organisation') as mock_get_user_org, \\\n            patch('autospark.controllers.tool.db') as mock_db, \\\n            patch('autospark.helper.auth.db') as mock_auth_db:\n\n        # Mock the toolkit filtering\n        mock_db.session.query.return_value.filter.return_value.all.side_effect = [user_toolkits, [tool_1, tool_2],\n                                                                                  [tool_3]]\n\n        # Call the function\n        response = client.get(\"/tools/list\")\n\n        # Assertions\n        assert response.status_code == 200\n        assert response.json() == [{'id': 1, 'name': 'tool_1', 'description': 'Test Tool', 'folder_name': 'test folder',\n                                    'file_name': 'test file', 'toolkit_id': 1},\n                                   {'id': 1, 'name': 'tool_2', 'description': 'Test Tool', 'folder_name': 'test folder',\n                                    'file_name': 'test file', 'toolkit_id': 1},\n                                   {'id': 1, 'name': 'tool_3', 'description': 'Test Tool', 'folder_name': 'test folder',\n                                    'file_name': 'test file', 'toolkit_id': 2}]\n"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/notion/tests/test_notion_fetch_page.py", "content": "import pytest\nfrom unittest.mock import patch, MagicMock\nfrom notion_fetch_page import NotionfetchPageTool, NotionfetchPageSchema\nfrom ..helper.notion_helper import NotionHelper\n\nnotion_tool = NotionfetchPageTool()\n\n\n@patch.object(NotionfetchPageTool, 'get_tool_config')\n@patch.object(NotionHelper, 'get_page_ids')\ndef test_no_page_exists(mock_get_page_ids, mock_get_tool_config):\n    mock_get_tool_config.return_value = 'TOKEN'\n    mock_get_page_ids.return_value = []\n    \n    result = notion_tool._execute('title')\n    \n    assert result == \"No such page exists.\"\n\n\t\n@patch.object(NotionfetchPageTool, 'get_tool_config')\n@patch.object(NotionHelper, 'get_page_ids')\n@patch.object(NotionHelper, 'get_page_content')\ndef test_successful_page_fetch(mock_get_page_content, mock_get_page_ids, mock_get_tool_config):\n    mock_get_tool_config.return_value = 'TOKEN'\n    mock_get_page_ids.return_value = ['id1', 'id2', 'id3']\n    mock_get_page_content.return_value = 'content'\n    result = notion_tool._execute('title')\n    assert result == \"Pages fetched successfully:\\npage 1:\\n\\ncontent\\npage 2:\\n\\ncontent\\npage 3:\\n\\ncontent\"\n\n\n@patch.object(NotionfetchPageTool, 'get_tool_config')\n@patch.object(NotionHelper, 'get_page_ids')\n@patch.object(NotionHelper, 'get_page_content')\ndef test_get_page_content_error(mock_get_page_content, mock_get_page_ids, mock_get_tool_config):\n    mock_get_tool_config.return_value = 'TOKEN'\n    mock_get_page_ids.return_value = ['id1']\n    mock_get_page_content.side_effect = Exception('Unable to fetch')\n\n    result = notion_tool._execute('title')\n\n    assert result == \"Error: Unable to fetch page Unable to fetch\"\n"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/google_analytics/tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/controllers/test_agent.py", "content": "from unittest.mock import patch, Mock\nfrom unittest import mock\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom main import app\nfrom autospark.models.agent_schedule import AgentSchedule\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.agent import Agent\nfrom datetime import datetime, timedelta\nfrom pytz import timezone\n\nclient = TestClient(app)\n\n@pytest.fixture\ndef mock_patch_schedule_input():\n    return{\n        \"agent_id\": 1,\n        \"start_time\": \"2023-02-02 01:00:00\",\n        \"recurrence_interval\": \"2 Hours\",\n        \"expiry_date\": \"2023-12-30 01:00:00\",\n        \"expiry_runs\": -1\n    }\n\n@pytest.fixture\ndef mock_schedule():\n    # Mock schedule data for testing\n    return AgentSchedule(id=1, agent_id=1, status=\"SCHEDULED\")\n\n@pytest.fixture\ndef mock_agent_config():\n    return AgentConfiguration(key=\"user_timezone\", agent_id=1, value='GMT')\n\n@pytest.fixture\ndef mock_schedule_get():\n    return AgentSchedule(\n        id=1, \n        agent_id=1, \n        status=\"SCHEDULED\",\n        start_time= datetime(2022, 1, 1, 10, 30),\n        recurrence_interval=\"5 Minutes\",\n        expiry_date=datetime(2022, 1, 1, 10, 30) + timedelta(days=10),\n        expiry_runs=5 \n    )\n\n'''Test for Stopping Agent Scheduling'''\ndef test_stop_schedule_success(mock_schedule):\n    with patch('autospark.controllers.agent.db') as mock_db:\n        # Set up the database query result\n        mock_db.session.query.return_value.filter.return_value.first.return_value = mock_schedule \n\n        # Call the endpoint\n        response = client.post(\"agents/stop/schedule?agent_id=1\")\n\n        # Verify the HTTP response\n        assert response.status_code == 200\n\n        # Verify changes in the mock agent schedule\n        assert mock_schedule.status == \"STOPPED\"\n\n\ndef test_stop_schedule_not_found():\n    with patch('autospark.controllers.agent.db') as mock_db:\n        # Set up the database query result\n        mock_db.session.query.return_value.filter.return_value.first.return_value = None\n\n        # Call the endpoint\n        response = client.post(\"agents/stop/schedule?agent_id=1\")\n\n        # Verify the HTTP response\n        assert response.status_code == 404\n        assert response.json() == {\"detail\": \"Schedule not found\"}\n\n\n'''Test for editing agent schedule'''\ndef test_edit_schedule_success(mock_schedule, mock_patch_schedule_input):\n    with patch('autospark.controllers.agent.db') as mock_db:\n        # Set up the database query result\n        mock_db.session.query.return_value.filter.return_value.first.return_value = mock_schedule\n\n        # Call the endpoint\n        response = client.put(\"agents/edit/schedule\", json=mock_patch_schedule_input)\n\n        # Verify the HTTP response\n        assert response.status_code == 200\n        start_time = datetime.strptime(mock_patch_schedule_input[\"start_time\"], \"%Y-%m-%d %H:%M:%S\")\n        expiry_date = datetime.strptime(mock_patch_schedule_input[\"expiry_date\"], \"%Y-%m-%d %H:%M:%S\")\n\n        # Verify changes in the mock agent schedule\n        assert mock_schedule.start_time == start_time\n        assert mock_schedule.recurrence_interval == mock_patch_schedule_input[\"recurrence_interval\"]\n        assert mock_schedule.expiry_date == expiry_date\n        assert mock_schedule.expiry_runs == mock_patch_schedule_input[\"expiry_runs\"]\n\n\ndef test_edit_schedule_not_found(mock_patch_schedule_input):\n    with patch('autospark.controllers.agent.db') as mock_db:\n        # Set up the database query result\n        mock_db.session.query.return_value.filter.return_value.first.return_value = None\n\n        # Call the endpoint\n        response = client.put(\"agents/edit/schedule\", json=mock_patch_schedule_input)\n\n        # Verify the HTTP response\n        assert response.status_code == 404\n        assert response.json() == {\"detail\": \"Schedule not found\"}\n\n'''Test for getting agent schedule'''\ndef test_get_schedule_data_success(mock_schedule_get, mock_agent_config):\n    with patch('autospark.controllers.agent.db') as mock_db:\n        mock_db.session.query.return_value.filter.return_value.first.side_effect = [mock_schedule_get, mock_agent_config]\n        response = client.get(\"agents/get/schedule_data/1\")\n        assert response.status_code == 200\n\n        time_gmt = mock_schedule_get.start_time.astimezone(timezone('GMT'))\n\n        expected_data = {\n            \"current_datetime\": mock.ANY,\n            \"start_date\": time_gmt.strftime(\"%d %b %Y\"),\n            \"start_time\": time_gmt.strftime(\"%I:%M %p\"),\n            \"recurrence_interval\": mock_schedule_get.recurrence_interval,\n            \"expiry_date\": mock_schedule_get.expiry_date.astimezone(timezone('GMT')).strftime(\"%d/%m/%Y\"),\n            \"expiry_runs\": mock_schedule_get.expiry_runs,\n        }\n        assert response.json() == expected_data\n\n\ndef test_get_schedule_data_not_found():\n    with patch('autospark.controllers.agent.db') as mock_db:\n        # Set up the database query result\n        mock_db.session.query.return_value.filter.return_value.first.return_value = None\n\n        # Call the endpoint\n        response = client.get(\"agents/get/schedule_data/1\")\n\n        # Verify the HTTP response\n        assert response.status_code == 404\n        assert response.json() == {\"detail\": \"Agent Schedule not found\"}\n\n\n@pytest.fixture\ndef mock_agent_config_schedule():\n    return {\n        \"agent_config\": {\n            \"name\": \"SmartAGI\", \n            \"project_id\": 1,\n            \"description\": \"AI assistant to solve complex problems\",\n            \"goal\": [\"Share research on latest google news in fashion\"],\n            \"agent_type\": \"Don't Maintain Task Queue\",\n            \"constraints\": [\n                \"~4000 word limit for short term memory.\",\n                \"No user assistance\",\n                \"Exclusively use the commands listed in double quotes\"\n            ],\n            \"instruction\": [],\n            \"exit\": \"Exit strategy\",\n            \"iteration_interval\": 500,\n            \"model\": \"gpt-4\",\n            \"permission_type\": \"Type 1\",\n            \"LTM_DB\": \"Database Pinecone\",\n            \"toolkits\": [1],\n            \"tools\": [],\n            \"memory_window\": 10,\n            \"max_iterations\": 25,\n            \"user_timezone\": \"Asia/Kolkata\"\n        },\n        \"schedule\": {\n            \"start_time\": \"2023-07-04 11:13:00\",\n            \"expiry_runs\": -1,\n            \"recurrence_interval\": None,\n            \"expiry_date\": None\n        }\n    }\n\n@pytest.fixture\ndef mock_agent():\n    agent = Agent(id=1, name=\"SmartAGI\", project_id=1)\n    return agent\n\n\ndef test_create_and_schedule_agent_success(mock_agent_config_schedule, mock_agent, mock_schedule):\n    \n    with patch('autospark.models.agent.Agent') as AgentMock,\\\n         patch('autospark.controllers.agent.Project') as ProjectMock,\\\n         patch('autospark.controllers.agent.Tool') as ToolMock,\\\n         patch('autospark.controllers.agent.Toolkit') as ToolkitMock,\\\n         patch('autospark.controllers.agent.AgentSchedule') as AgentScheduleMock,\\\n         patch('autospark.controllers.agent.db') as db_mock:\n\n        project_mock = Mock()\n        ProjectMock.get.return_value = project_mock\n\n        # AgentMock.create_agent_with_config.return_value = mock_agent\n        AgentMock.return_value =  mock_agent\n\n        tool_mock = Mock()\n        ToolMock.get_invalid_tools.return_value = []\n\n        toolkit_mock = Mock()\n        ToolkitMock.fetch_tool_ids_from_toolkit.return_value = []\n        \n        agent_schedule_mock = Mock()\n        agent_schedule_mock.id = None  # id is None before commit\n        AgentScheduleMock.return_value = mock_schedule\n        \n        db_mock.session.query.return_value.get.return_value = project_mock\n        db_mock.session.add.return_value = None\n        db_mock.session.commit.side_effect = lambda: setattr(agent_schedule_mock, 'id', 1)  # id is set after commit\n        db_mock.session.query.return_value.get.return_value = project_mock\n\n        response = client.post(\"agents/schedule\", json=mock_agent_config_schedule)\n\n        assert response.status_code == 201\n        assert response.json() == {\n            \"id\": mock_agent.id,\n            \"name\": mock_agent.name,\n            \"contentType\": \"Agents\",\n            \"schedule_id\": 1\n        }\n\n\ndef test_create_and_schedule_agent_project_not_found(mock_agent_config_schedule):\n    with patch('autospark.controllers.agent.db') as mock_db:\n        # Set up the database query result\n        mock_db.session.query.return_value.get.return_value = None\n\n        # Call the endpoint\n        response = client.post(\"agents/schedule\", json=mock_agent_config_schedule)\n\n        # Verify the HTTP response\n        assert response.status_code == 404\n        assert response.json() == {\"detail\": \"Project not found\"}"}
{"type": "test_file", "path": "tests/unit_tests/controllers/__init__.py", "content": ""}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/notion/tests/test_notion_helper.py", "content": "import pytest\nimport requests\nimport json\nfrom unittest.mock import patch\nfrom ..helper.notion_helper import NotionHelper\n\n@patch('requests.post')\ndef test_get_page_ids(mock_post):\n    # Mock the response from requests.post\n    mock_response = mock_post.return_value\n    mock_response.json.return_value = {\n        \"results\": [{\n            \"properties\": {\n                \"Title\": {\n                    \"title\": [{\n                        \"plain_text\": \"Testing Title\"\n                    }]\n                }\n            },\n            \"id\": \"12345\"\n        }]\n    }\n\n    notion_helper = NotionHelper(\"token\")\n    ids = notion_helper.get_page_ids(\"Testing Title\", \"page\")\n\n    assert ids == [\"12345\"]\n\n@patch('requests.request')\ndef test_get_page_content(mock_request):\n    mock_response = mock_request.return_value\n    mock_response.json.return_value = {\n        \"results\": [{\n            \"type\": \"text\",\n            \"text\": [{\"plain_text\": \"Mock Content\"}]\n        }]\n    }\n    \ndef test_create_page_children():\n    notion_helper = NotionHelper(\"token\")\n\n    content = [{'type': 'text', 'content': 'This is some test content'}]\n\n    expected_output = [{\n        \"object\": \"block\",\n        \"type\": 'text',\n        'text': {\n            \"rich_text\": [{\"text\": {\"content\": 'This is some test content'}}]\n        }\n    }]\n\n    assert notion_helper.create_page_children(content) == expected_output\n\n\n@patch('requests.post')\ndef test_create_page(mock_post):\n    mock_response = mock_post.return_value\n    mock_response.json.return_value = {\"object\": \"page\"}\n\n    # Initialize NotionHelper and get page ids\n    notion_helper = NotionHelper(\"token\")\n    content = [{\"type\": \"text\", \"content\": \"Mock Content\"}]\n    resp = notion_helper.create_page(content, \"Test Page\", \"12345\", [\"TestTag1\", \"TestTag2\"])\n    \n    assert resp.json() == {\"object\": \"page\"}\n\n@pytest.mark.parametrize('text,expected', [('some test text', 7), ('', 4), ('one word', 6)])\ndef test_count_text_tokens(text, expected):\n    notion_helper = NotionHelper(\"token\")\n    assert notion_helper.count_text_tokens(text) == expected"}
{"type": "test_file", "path": "tests/unit_tests/apm/test_tools_handler.py", "content": "import pytest\nfrom unittest.mock import MagicMock\nfrom sqlalchemy.orm import Session\nfrom autospark.apm.tools_handler import ToolsHandler\n\n@pytest.fixture\ndef mock_session():\n    return MagicMock(spec=Session)\n\n@pytest.fixture\ndef organisation_id():\n    return 1\n\n@pytest.fixture\ndef tools_handler(mock_session, organisation_id):\n    return ToolsHandler(mock_session, organisation_id)\n\ndef test_calculate_tool_usage(tools_handler):\n    tools_handler.calculate_tool_usage = MagicMock(return_value=[])\n    result = tools_handler.calculate_tool_usage()\n    assert isinstance(result, list)\n    tools_handler.calculate_tool_usage.assert_called()"}
{"type": "test_file", "path": "tests/unit_tests/helper/test_feed_parser.py", "content": "import unittest\nfrom datetime import datetime\n\nfrom autospark.helper.feed_parser import parse_feed\nfrom autospark.models.agent_execution_feed import AgentExecutionFeed\n\n\nclass TestParseFeed(unittest.TestCase):\n\n    def test_parse_feed_system(self):\n        current_time = datetime.now()\n\n        # Create a sample AgentExecutionFeed object with a system role\n        sample_feed = AgentExecutionFeed(id=2, agent_execution_id=100, agent_id=200, role=\"assistant\",\n                                         feed='System message',\n                                         updated_at=current_time)\n\n        # Call the parse_feed function with the sample_feed object\n        result = parse_feed(sample_feed)\n\n        # In this test case, we only ensure that the parse_feed function doesn't modify the given feed\n        self.assertEqual(result, sample_feed, \"Incorrect output from parse_feed function for system role\")\n"}
{"type": "test_file", "path": "superagi/tools/marketplace_tools/notion/tests/test_notion_create_page.py", "content": "from unittest.mock import patch, Mock\nimport requests\nimport pytest\n\nfrom notion_create_page import NotionCreatePageTool\n\n\n@patch(\"requests.post\")\n@patch.object(NotionCreatePageTool, 'get_tool_config')\ndef test_notion_create_page_tool(mock_get_config, mock_post):\n    # Data\n    content_list = [{\"type\": \"text\", \"content\": \"Test content\", \"language\": \"English\"}]\n    title = \"Test Page\"\n    tags = [\"tag1\", \"tag2\"]\n\n    # Here we are mocking the function call to get_tool_config to return test values.\n    mock_get_config.side_effect = [\"test_token\", \"test_database_id\"]  # notion_token, notation_database_id in order\n\n    # Response\n    response_data = {\n        \"id\": \"test_id\",\n    }\n    response = requests.Response()\n    response.status_code = 200\n    response.json = lambda: response_data    \n    mock_post.return_value = response\n\n    # Configure NotionCreatePageTool\n    tool = NotionCreatePageTool()  # Now it is a no-arg constructor\n\n    # Call 'execute' method\n    result = tool._execute(content_list, title, tags)\n\n    # Assertions\n    assert result == \"Page created successfully. Page ID: test_id\"\n    mock_post.assert_called_once_with(\n        \"https://api.notion.com/v1/pages\",\n        headers={\"Authorization\": \"Bearer test_token\", \"Content-Type\": \"application/json\", \"Notion-Version\": \"2022-06-28\"},\n        data='{\"parent\": {\"database_id\": \"test_database_id\"}, \"properties\": {\"title\": {\"title\": [{\"text\": {\"content\": \"Test Page\"}}]}, \"Tags\": {\"multi_select\": [{\"name\": \"tag1\"}, {\"name\": \"tag2\"}]}}, \"children\": [{\"object\": \"block\", \"type\": \"text\", \"text\": {\"rich_text\": [{\"text\": {\"content\": \"Test content\"}}]}}]}'\n    )"}
{"type": "test_file", "path": "tests/__init__.py", "content": ""}
{"type": "test_file", "path": "tests/unit_tests/helper/__init__.py", "content": ""}
{"type": "source_file", "path": "autospark/agent/__init__.py", "content": ""}
{"type": "source_file", "path": "autospark/agent/agent_tool_step_handler.py", "content": "import json\n\nfrom autospark.agent.agent_message_builder import AgentLlmMessageBuilder\nfrom autospark.agent.agent_prompt_builder import AgentPromptBuilder\nfrom autospark.agent.output_handler import ToolOutputHandler\nfrom autospark.agent.output_parser import AgentSchemaToolOutputParser\nfrom autospark.agent.queue_step_handler import QueueStepHandler\nfrom autospark.agent.tool_builder import ToolBuilder\nfrom autospark.helper.prompt_reader import PromptReader\nfrom autospark.helper.token_counter import TokenCounter\nfrom autospark.lib.logger import logger\nfrom autospark.models.agent import Agent\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent_execution_config import AgentExecutionConfiguration\nfrom autospark.models.agent_execution_feed import AgentExecutionFeed\nfrom autospark.models.agent_execution_permission import AgentExecutionPermission\nfrom autospark.models.tool import Tool\nfrom autospark.models.workflows.agent_workflow_step import AgentWorkflowStep\nfrom autospark.models.workflows.agent_workflow_step_tool import AgentWorkflowStepTool\nfrom autospark.resource_manager.resource_summary import ResourceSummarizer\nfrom autospark.tools.base_tool import BaseTool\n\n\nclass AgentToolStepHandler:\n    \"\"\"Handles the tools steps in the agent workflow\"\"\"\n    def __init__(self, session, llm, agent_id: int, agent_execution_id: int, memory=None):\n        self.session = session\n        self.llm = llm\n        self.agent_execution_id = agent_execution_id\n        self.agent_id = agent_id\n        self.memory = memory\n\n    def execute_step(self):\n        execution = AgentExecution.get_agent_execution_from_id(self.session, self.agent_execution_id)\n        workflow_step = AgentWorkflowStep.find_by_id(self.session, execution.current_agent_step_id)\n        step_tool = AgentWorkflowStepTool.find_by_id(self.session, workflow_step.action_reference_id)\n        agent_config = Agent.fetch_configuration(self.session, self.agent_id)\n        agent_execution_config = AgentExecutionConfiguration.fetch_configuration(self.session, self.agent_execution_id)\n        # print(agent_execution_config)\n\n        if not self._handle_wait_for_permission(execution, workflow_step):\n            return\n\n        if step_tool.tool_name == \"TASK_QUEUE\":\n            step_response = QueueStepHandler(self.session, self.llm, self.agent_id, self.agent_execution_id).execute_step()\n            next_step = AgentWorkflowStep.fetch_next_step(self.session, workflow_step.id, step_response)\n            self._handle_next_step(next_step)\n            return\n\n        if step_tool.tool_name == \"WAIT_FOR_PERMISSION\":\n            self._create_permission_request(execution, step_tool)\n            return\n\n        assistant_reply = self._process_input_instruction(agent_config, agent_execution_config, step_tool,\n                                                          workflow_step)\n        tool_obj = self._build_tool_obj(agent_config, agent_execution_config, step_tool.tool_name)\n        tool_output_handler = ToolOutputHandler(self.agent_execution_id, agent_config, [tool_obj],\n                                                output_parser=AgentSchemaToolOutputParser())\n        final_response = tool_output_handler.handle(self.session, assistant_reply)\n        step_response = \"default\"\n        if step_tool.output_instruction:\n            step_response = self._process_output_instruction(final_response.result, step_tool, workflow_step)\n\n        next_step = AgentWorkflowStep.fetch_next_step(self.session, workflow_step.id, step_response)\n        self._handle_next_step(next_step)\n        self.session.flush()\n\n    def _create_permission_request(self, execution, step_tool: AgentWorkflowStepTool):\n        new_agent_execution_permission = AgentExecutionPermission(\n            agent_execution_id=self.agent_execution_id,\n            status=\"PENDING\",\n            agent_id=self.agent_id,\n            tool_name=\"WAIT_FOR_PERMISSION\",\n            question=step_tool.input_instruction,\n            assistant_reply=\"\")\n        self.session.add(new_agent_execution_permission)\n        self.session.commit()\n        self.session.flush()\n        execution.permission_id = new_agent_execution_permission.id\n        execution.status = \"WAITING_FOR_PERMISSION\"\n        self.session.commit()\n\n    def _handle_next_step(self, next_step):\n        if str(next_step) == \"COMPLETE\":\n            agent_execution = AgentExecution.get_agent_execution_from_id(self.session, self.agent_execution_id)\n            agent_execution.current_agent_step_id = -1\n            agent_execution.status = \"COMPLETED\"\n        else:\n            AgentExecution.assign_next_step_id(self.session, self.agent_execution_id, next_step.id)\n        self.session.commit()\n\n    def _process_input_instruction(self, agent_config, agent_execution_config, step_tool, workflow_step):\n        tool_obj = self._build_tool_obj(agent_config, agent_execution_config, step_tool.tool_name)\n        prompt = self._build_tool_input_prompt(step_tool, tool_obj, agent_execution_config)\n        logger.info(\"Prompt: \", prompt)\n        agent_feeds = AgentExecutionFeed.fetch_agent_execution_feeds(self.session, self.agent_execution_id)\n        messages = AgentLlmMessageBuilder(self.session, self.llm, self.agent_id, self.agent_execution_id) \\\n            .build_agent_messages(prompt, agent_feeds, history_enabled=step_tool.history_enabled,\n                                  completion_prompt=step_tool.completion_prompt)\n        # print(messages)\n        current_tokens = TokenCounter.count_message_tokens(messages, self.llm.get_model())\n        response = self.llm.chat_completion(messages, TokenCounter.token_limit(self.llm.get_model()) - current_tokens)\n        if 'content' not in response or response['content'] is None:\n            raise RuntimeError(f\"Failed to get response from llm\")\n        total_tokens = current_tokens + TokenCounter.count_message_tokens(response, self.llm.get_model())\n        AgentExecution.update_tokens(self.session, self.agent_execution_id, total_tokens)\n        assistant_reply = response['content']\n        return assistant_reply\n\n    def _build_tool_obj(self, agent_config, agent_execution_config, tool_name: str):\n        model_api_key = AgentConfiguration.get_model_api_key(self.session, self.agent_id, agent_config[\"model\"])\n        model_api_secret = AgentConfiguration.get_model_api_secret(self.session, self.agent_id, agent_config[\"model\"])\n        model_app_id = AgentConfiguration.get_model_app_id(self.session, self.agent_id, agent_config[\"model\"])\n\n\n        tool_builder = ToolBuilder(self.session, self.agent_id, self.agent_execution_id)\n        resource_summary = \"\"\n        if tool_name == \"QueryResourceTool\":\n            resource_summary = ResourceSummarizer(session=self.session,\n                                                  agent_id=self.agent_id).fetch_or_create_agent_resource_summary(\n                default_summary=agent_config.get(\"resource_summary\"))\n        tool = self.session.query(Tool).filter(Tool.name == tool_name).first()\n        tool_obj = tool_builder.build_tool(tool)\n        tool_obj = tool_builder.set_default_params_tool(tool_obj, agent_config, agent_execution_config, model_api_key,\n                                                        resource_summary, model_app_id=model_app_id, model_api_secret=model_api_secret)\n        return tool_obj\n\n    def _process_output_instruction(self, final_response: str, step_tool: AgentWorkflowStepTool,\n                                    workflow_step: AgentWorkflowStep):\n        prompt = self._build_tool_output_prompt(step_tool, final_response, workflow_step)\n        messages = [{\"role\": \"system\", \"content\": prompt}]\n        current_tokens = TokenCounter.count_message_tokens(messages, self.llm.get_model())\n        response = self.llm.chat_completion(messages,\n                                            TokenCounter.token_limit(self.llm.get_model()) - current_tokens)\n        if 'content' not in response or response['content'] is None:\n            raise RuntimeError(f\"ToolWorkflowStepHandler: Failed to get output response from llm\")\n        total_tokens = current_tokens + TokenCounter.count_message_tokens(response, self.llm.get_model())\n        AgentExecution.update_tokens(self.session, self.agent_execution_id, total_tokens)\n        step_response = response['content']\n        step_response = step_response.replace(\"'\", \"\").replace(\"\\\"\", \"\")\n        return step_response\n\n\n    def _build_tool_input_prompt(self, step_tool: AgentWorkflowStepTool, tool: BaseTool, agent_execution_config: dict):\n        super_agi_prompt = PromptReader.read_agent_prompt(__file__, \"agent_tool_input.txt\")\n        super_agi_prompt = super_agi_prompt.replace(\"{goals}\", AgentPromptBuilder.add_list_items_to_string(\n            agent_execution_config[\"goal\"]))\n        super_agi_prompt = super_agi_prompt.replace(\"{tool_name}\", step_tool.tool_name)\n        super_agi_prompt = super_agi_prompt.replace(\"{instruction}\", step_tool.input_instruction)\n\n        tool_schema = f\"\\\"{tool.name}\\\": {tool.description}, args json schema: {json.dumps(tool.args)}\"\n        super_agi_prompt = super_agi_prompt.replace(\"{tool_schema}\", tool_schema)\n        return super_agi_prompt\n\n    def _get_step_responses(self, workflow_step: AgentWorkflowStep):\n        return [step[\"step_response\"] for step in workflow_step.next_steps]\n\n    def _build_tool_output_prompt(self, step_tool: AgentWorkflowStepTool, tool_output: str,\n                                  workflow_step: AgentWorkflowStep):\n        super_agi_prompt = PromptReader.read_agent_prompt(__file__, \"agent_tool_output.txt\")\n        super_agi_prompt = super_agi_prompt.replace(\"{tool_output}\", tool_output)\n        super_agi_prompt = super_agi_prompt.replace(\"{tool_name}\", step_tool.tool_name)\n        super_agi_prompt = super_agi_prompt.replace(\"{instruction}\", step_tool.output_instruction)\n\n        step_responses = self._get_step_responses(workflow_step)\n        if \"default\" in step_responses:\n            step_responses.remove(\"default\")\n        super_agi_prompt = super_agi_prompt.replace(\"{output_options}\", str(step_responses))\n        return super_agi_prompt\n\n    def _handle_wait_for_permission(self, agent_execution, workflow_step: AgentWorkflowStep):\n        \"\"\"\n        Handles the wait for permission when the agent execution is waiting for permission.\n\n        Args:\n            agent_execution (AgentExecution): The agent execution.\n            workflow_step (AgentWorkflowStep): The workflow step.\n\n        Raises:\n            Returns permission success or failure\n        \"\"\"\n        if agent_execution.status != \"WAITING_FOR_PERMISSION\":\n            return True\n        agent_execution_permission = self.session.query(AgentExecutionPermission).filter(\n            AgentExecutionPermission.id == agent_execution.permission_id).first()\n        if agent_execution_permission.status == \"PENDING\":\n            logger.error(\"handle_wait_for_permission: Permission is still pending\")\n            return False\n        if agent_execution_permission.status == \"APPROVED\":\n            next_step = AgentWorkflowStep.fetch_next_step(self.session, workflow_step.id, \"YES\")\n        else:\n            next_step = AgentWorkflowStep.fetch_next_step(self.session, workflow_step.id, \"NO\")\n            result = f\"{' User has given the following feedback : ' + agent_execution_permission.user_feedback if agent_execution_permission.user_feedback else ''}\"\n\n\n            agent_execution_feed = AgentExecutionFeed(agent_execution_id=agent_execution_permission.agent_execution_id,\n                                                      agent_id=agent_execution_permission.agent_id,\n                                                      feed=result, role=\"user\",\n                                                      feed_group_id=agent_execution.current_feed_group_id)\n            self.session.add(agent_execution_feed)\n\n        agent_execution.status = \"RUNNING\"\n        agent_execution.permission_id = -1\n        self.session.commit()\n        self._handle_next_step(next_step)\n        self.session.commit()\n        return False\n"}
{"type": "source_file", "path": "autospark/controllers/agent_execution_permission.py", "content": "from datetime import datetime\nfrom typing import Annotated\n\nfrom fastapi.security import HTTPBearer\nfrom fastapi_sqlalchemy import db\nfrom fastapi import HTTPException, Depends, Body\nfrom fastapi_jwt_auth import AuthJWT\nfrom pydantic import BaseModel\n\nfrom autospark.models.agent_execution_permission import AgentExecutionPermission\nfrom autospark.worker import execute_agent\nfrom fastapi import APIRouter\n\nfrom autospark.helper.auth import check_auth\n# from autospark.types.db import AgentExecutionPermissionOut, AgentExecutionPermissionIn\n\nrouter = APIRouter()\n\n\nclass AgentExecutionPermissionOut(BaseModel):\n    id: int\n    agent_execution_id: int\n    agent_id: int\n    status: str\n    tool_name: str\n    user_feedback: str\n    assistant_reply: str\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass AgentExecutionPermissionIn(BaseModel):\n    agent_execution_id: int\n    agent_id: int\n    status: str\n    tool_name: str\n    user_feedback: str\n    assistant_reply: str\n\n    class Config:\n        orm_mode = True\n\n\n@router.get(\"/get/{agent_execution_permission_id}\",dependencies=[Depends(HTTPBearer())])\ndef get_agent_execution_permission(agent_execution_permission_id: int,\n                                   Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get an agent execution permission by its ID.\n\n    Args:\n        agent_execution_permission_id (int): The ID of the agent execution permission.\n        Authorize (AuthJWT, optional): Authentication object. Defaults to Depends(check_auth).\n\n    Raises:\n        HTTPException: If the agent execution permission is not found.\n\n    Returns:\n        AgentExecutionPermission: The requested agent execution permission.\n    \"\"\"\n\n    db_agent_execution_permission = db.session.query(AgentExecutionPermission).get(agent_execution_permission_id)\n    if not db_agent_execution_permission:\n        raise HTTPException(status_code=404, detail=\"Agent execution permission not found\")\n    return db_agent_execution_permission\n\n\n@router.post(\"/add\", dependencies=[Depends(HTTPBearer())],response_model=AgentExecutionPermissionOut)\ndef create_agent_execution_permission(\n        agent_execution_permission: AgentExecutionPermissionIn\n        , Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new agent execution permission.\n\n    Args:\n        agent_execution_permission : An instance of AgentExecutionPermission model as json.\n        Authorize (AuthJWT, optional): Authorization token, by default depends on the check_auth function.\n\n    Returns:\n        new_agent_execution_permission: A newly created agent execution permission instance.\n    \"\"\"\n    new_agent_execution_permission = AgentExecutionPermission(**agent_execution_permission.dict())\n    db.session.add(new_agent_execution_permission)\n    db.session.commit()\n    return new_agent_execution_permission\n\n\n@router.patch(\"/update/{agent_execution_permission_id}\",dependencies=[Depends(HTTPBearer())],\n              response_model=AgentExecutionPermissionIn)\ndef update_agent_execution_permission(agent_execution_permission_id: int,\n                                      agent_execution_permission: AgentExecutionPermissionIn,\n                                      Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Update an AgentExecutionPermission in the database.\n\n    Given an agent_execution_permission_id and the updated agent_execution_permission, this function updates the\n    corresponding AgentExecutionPermission in the database. If the AgentExecutionPermission is not found, an HTTPException\n    is raised.\n\n    Args:\n        agent_execution_permission_id (int): The ID of the AgentExecutionPermission to update.\n        agent_execution_permission : The updated AgentExecutionPermission object as json.\n        Authorize (AuthJWT, optional): Dependency to authenticate the user.\n\n    Returns:\n        db_agent_execution_permission (AgentExecutionPermission): The updated AgentExecutionPermission in the database.\n\n    Raises:\n        HTTPException: If the AgentExecutionPermission is not found in the database.\n    \"\"\"\n    db_agent_execution_permission = db.session.query(AgentExecutionPermission).get(agent_execution_permission_id)\n    if not db_agent_execution_permission:\n        raise HTTPException(status_code=404, detail=\"Agent execution permission not found\")\n\n    for key, value in agent_execution_permission.dict().items():\n        setattr(db_agent_execution_permission, key, value)\n\n    db.session.commit()\n    return db_agent_execution_permission\n\n\n@router.put(\"/update/status/{agent_execution_permission_id}\",dependencies=[Depends(HTTPBearer())])\ndef update_agent_execution_permission_status(agent_execution_permission_id: int,\n                                             status: Annotated[bool, Body(embed=True)],\n                                             user_feedback: Annotated[str, Body(embed=True)] = \"\",\n                                             Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Update the execution permission status of an agent in the database.\n\n    This function updates the execution permission status of an agent in the database. The status can be\n    either \"APPROVED\" or \"REJECTED\". The function also updates the user feedback if provided,\n    commits the changes to the database, and enqueues the agent for execution.\n\n    :params:\n    - agent_execution_permission_id (int): The ID of the agent execution permission\n    - status (bool): The status of the agent execution permission, True for \"APPROVED\", False for \"REJECTED\"\n    - user_feedback (str): Optional user feedback on the status update\n    - Authorize (AuthJWT): Dependency function to check user authorization\n\n    :return:\n    - A dictionary containing a \"success\" key with the value True to indicate a successful update.\n    \"\"\"\n\n    agent_execution_permission = db.session.query(AgentExecutionPermission).get(agent_execution_permission_id)\n    print(agent_execution_permission)\n    if agent_execution_permission is None:\n        raise HTTPException(status_code=400, detail=\"Invalid Request\")\n    if status is None:\n        raise HTTPException(status_code=400, detail=\"Invalid Request status is required\")\n    agent_execution_permission.status = \"APPROVED\" if status else \"REJECTED\"\n    agent_execution_permission.user_feedback = user_feedback.strip() if len(user_feedback.strip()) > 0 else None\n    db.session.commit()\n\n    execute_agent.delay(agent_execution_permission.agent_execution_id, datetime.now())\n\n    return {\"success\": True}\n"}
{"type": "source_file", "path": "autospark/agent/auto_spark.py", "content": "# agent has a master prompt\n# agent executes the master prompt along with long term memory\n# agent can run the task queue as well with long term memory\nfrom __future__ import annotations\n\nimport time\nfrom typing import Any\nfrom typing import Tuple\n\nimport numpy as np\nfrom pydantic import ValidationError\nfrom pydantic.types import List\nfrom sqlalchemy import asc\nfrom sqlalchemy.orm import sessionmaker\n\nfrom autospark.agent.agent_prompt_builder import AgentPromptBuilder\nfrom autospark.agent.output_parser import BaseOutputParser, AgentSchemaOutputParser\nfrom autospark.agent.task_queue import TaskQueue\nfrom autospark.apm.event_handler import EventHandler\nfrom autospark.helper.token_counter import TokenCounter\nfrom autospark.lib.logger import logger\nfrom autospark.llms.base_llm import BaseLlm\nfrom autospark.types.model_source_types import ModelSourceType\nfrom autospark.models.agent import Agent\nfrom autospark.models.agent_execution import AgentExecution\n# from autospark.models.types.agent_with_config import AgentWithConfig\nfrom autospark.models.agent_execution_feed import AgentExecutionFeed\nfrom autospark.models.agent_execution_permission import AgentExecutionPermission\nfrom autospark.models.workflows.agent_workflow_step import AgentWorkflowStep\nfrom autospark.models.db import connect_db\nfrom autospark_kit.tools.base_tool import BaseTool\nfrom autospark.types.common import BaseMessage\nfrom autospark.vector_store.base import VectorStore\n\nFINISH = \"finish\"\nWRITE_FILE = \"Write File\"\nFILE = \"FILE\"\nS3 = \"S3\"\n# print(\"\\033[91m\\033[1m\"\n#         + \"\\nA bit about me....\"\n#         + \"\\033[0m\\033[0m\")\n\n\nengine = connect_db()\nSession = sessionmaker(bind=engine)\n\n\nclass AutoSpark:\n    def __init__(self,\n                 ai_name: str,\n                 ai_role: str,\n                 llm: BaseLlm,\n                 memory: VectorStore,\n                 tools: List[BaseTool],\n                 agent_config: Any,\n                 agent_execution_config: Any,\n                 output_parser: BaseOutputParser = AgentSchemaOutputParser(),\n                 ):\n        self.ai_name = ai_name\n        self.ai_role = ai_role\n        self.full_message_history: List[BaseMessage] = []\n        self.llm = llm\n        self.memory = memory\n        self.output_parser = output_parser\n        self.tools = tools\n        self.agent_config = agent_config\n        self.agent_execution_config = agent_execution_config\n\n\n    def fetch_agent_feeds(self, session, agent_execution_id):\n        agent_feeds = session.query(AgentExecutionFeed.role, AgentExecutionFeed.feed) \\\n            .filter(AgentExecutionFeed.agent_execution_id == agent_execution_id) \\\n            .order_by(asc(AgentExecutionFeed.created_at)) \\\n            .all()\n        return agent_feeds[2:]\n\n    def split_history(self, history: List, pending_token_limit: int) -> Tuple[List[BaseMessage], List[BaseMessage]]:\n        hist_token_count = 0\n        i = len(history)\n        for message in reversed(history):\n            token_count = TokenCounter.count_message_tokens([{\"role\": message[\"role\"], \"content\": message[\"content\"]}],\n                                                            self.llm.get_model())\n            hist_token_count += token_count\n            if hist_token_count > pending_token_limit:\n                return history[:i], history[i:]\n            i -= 1\n        return [], history\n\n    def execute(self, workflow_step: AgentWorkflowStep):\n\n        session = Session()\n        agent_execution_id = self.agent_config[\"agent_execution_id\"]\n        task_queue = TaskQueue(str(agent_execution_id))\n\n        token_limit = TokenCounter.token_limit()\n        agent_feeds = self.fetch_agent_feeds(session, self.agent_config[\"agent_execution_id\"])\n        current_calls = 0\n        if len(agent_feeds) <= 0:\n            task_queue.clear_tasks()\n        messages = []\n        max_token_limit = 600\n        # llm model type\n        model_source_type = ModelSourceType.get_model_source_from_model(self.llm.get_model())\n\n        # adding history to the messages\n        if workflow_step.history_enabled:\n            prompt = self.build_agent_prompt(workflow_step.prompt, task_queue=task_queue,\n                                             max_token_limit=max_token_limit,model_source_type=model_source_type)\n            messages.append({\"role\": \"system\", \"content\": prompt})\n            messages.append({\"role\": \"system\", \"content\": f\"The current time and date is {time.strftime('%c')}\"})\n            base_token_limit = TokenCounter.count_message_tokens(messages, self.llm.get_model())\n            full_message_history = [{'role': role, 'content': feed} for role, feed in agent_feeds]\n            past_messages, current_messages = self.split_history(full_message_history,\n                                                                 token_limit - base_token_limit - max_token_limit)\n            for history in current_messages:\n                messages.append({\"role\": history[\"role\"], \"content\": history[\"content\"]})\n            messages.append({\"role\": \"user\", \"content\": workflow_step.completion_prompt})\n        else:\n\n            prompt = self.build_agent_prompt(workflow_step.prompt, task_queue=task_queue,\n                                             max_token_limit=max_token_limit,model_source_type=model_source_type)\n            messages.append({\"role\": \"system\", \"content\": prompt})\n            # agent_execution_feed = AgentExecutionFeed(agent_execution_id=self.agent_config[\"agent_execution_id\"],\n            #                                           agent_id=self.agent_config[\"agent_id\"], feed=template_step.prompt,\n            #                                           role=\"user\")\n\n        logger.debug(\"Prompt messages:\", messages)\n        if len(agent_feeds) <= 0:\n            for message in messages:\n                agent_execution_feed = AgentExecutionFeed(agent_execution_id=self.agent_config[\"agent_execution_id\"],\n                                                          agent_id=self.agent_config[\"agent_id\"],\n                                                          feed=message[\"content\"],\n                                                          role=message[\"role\"])\n                session.add(agent_execution_feed)\n                session.commit()\n\n        current_tokens = TokenCounter.count_message_tokens(messages, self.llm.get_model())\n        response = self.llm.chat_completion(messages, token_limit - current_tokens)\n        current_calls = current_calls + 1\n        total_tokens = current_tokens + TokenCounter.count_message_tokens(response, self.llm.get_model())\n\n        self.update_agent_execution_tokens(current_calls, total_tokens, session)\n\n        if 'content' not in response or response['content'] is None:\n            raise RuntimeError(f\"Failed to get response from llm\")\n        assistant_reply = response['content']\n\n        final_response = {\"result\": \"PENDING\", \"retry\": False, \"completed_task_count\": 0}\n        if workflow_step.output_type == \"tools\":\n            # check if permission is required for the tool in restricted mode\n            is_permission_required, response = self.check_permission_in_restricted_mode(assistant_reply, session)\n            if is_permission_required:\n                return response\n\n            tool_response = self.handle_tool_response(session, assistant_reply)\n\n            agent_execution_feed = AgentExecutionFeed(agent_execution_id=self.agent_config[\"agent_execution_id\"],\n                                                      agent_id=self.agent_config[\"agent_id\"],\n                                                      feed=assistant_reply,\n                                                      role=\"assistant\")\n            session.add(agent_execution_feed)\n            tool_response_feed = AgentExecutionFeed(agent_execution_id=self.agent_config[\"agent_execution_id\"],\n                                                    agent_id=self.agent_config[\"agent_id\"],\n                                                    feed=tool_response[\"result\"],\n                                                    role=\"system\"\n                                                    )\n            session.add(tool_response_feed)\n            final_response = tool_response\n            final_response[\"pending_task_count\"] = len(task_queue.get_tasks())\n            final_response[\"completed_task_count\"] = len(task_queue.get_completed_tasks())\n        elif workflow_step.output_type == \"replace_tasks\":\n            tasks = eval(assistant_reply)\n            task_queue.clear_tasks()\n            for task in reversed(tasks):\n                task_queue.add_task(task)\n            if len(tasks) > 0:\n                logger.info(\"Tasks reprioritized in order: \" + str(tasks))\n            current_tasks = task_queue.get_tasks()\n            if len(current_tasks) == 0:\n                final_response = {\"result\": \"COMPLETE\", \"pending_task_count\": 0}\n            else:\n                final_response = {\"result\": \"PENDING\", \"pending_task_count\": len(current_tasks)}\n        elif workflow_step.output_type == \"tasks\":\n            tasks = eval(assistant_reply)\n            tasks = np.array(tasks).flatten().tolist()\n            for task in reversed(tasks):\n                task_queue.add_task(task)\n            if len(tasks) > 0:\n                logger.info(\"Adding task to queue: \" + str(tasks))\n            for task in tasks:\n                agent_execution_feed = AgentExecutionFeed(agent_execution_id=self.agent_config[\"agent_execution_id\"],\n                                                          agent_id=self.agent_config[\"agent_id\"],\n                                                          feed=\": \" + task,\n                                                          role=\"system\")\n                session.add(agent_execution_feed)\n            current_tasks = task_queue.get_tasks()\n            if len(current_tasks) == 0:\n                final_response = {\"result\": \"COMPLETE\", \"pending_task_count\": 0}\n            else:\n                final_response = {\"result\": \"PENDING\", \"pending_task_count\": len(current_tasks)}\n        if workflow_step.output_type == \"tools\" and final_response[\"retry\"] == False:\n            task_queue.complete_task(final_response[\"result\"])\n            current_tasks = task_queue.get_tasks()\n            if final_response[\"completed_task_count\"] > 0 and len(current_tasks) == 0:\n                final_response[\"result\"] = \"COMPLETE\"\n            if len(current_tasks) > 0 and final_response[\"result\"] == \"COMPLETE\":\n                final_response[\"result\"] = \"PENDING\"\n        session.commit()\n\n        logger.info(\"Iteration completed moving to next iteration!\")\n        session.close()\n        return final_response\n\n    def handle_tool_response(self, session, assistant_reply):\n        action = self.output_parser.parse(assistant_reply)\n        tools = {t.name.lower().replace(\" \", \"\"): t for t in self.tools}\n        action_name = action.name.lower().replace(\" \", \"\")\n        agent = session.query(Agent).filter(Agent.id == self.agent_config[\"agent_id\"], ).first()\n        organisation = agent.get_agent_organisation(session)\n        if action_name == FINISH or action.name == \"\":\n            logger.info(\"\\nTask Finished :) \\n\")\n            output = {\"result\": \"COMPLETE\", \"retry\": False}\n            EventHandler(session=session).create_event('tool_used', {'tool_name': action.name},\n                                                       self.agent_config[\"agent_id\"], organisation.id),\n            return output\n        if action_name in tools:\n            tool = tools[action_name]\n            retry = False\n            EventHandler(session=session).create_event('tool_used', {'tool_name': action.name},\n                                                       self.agent_config[\"agent_id\"], organisation.id),\n            try:\n                parsed_args = self.clean_tool_args(action.args)\n                observation = tool.execute(parsed_args)\n            except ValidationError as e:\n                retry = True\n                observation = (\n                    f\"Validation Error in args: {str(e)}, args: {action.args}\"\n                )\n            except Exception as e:\n                retry = True\n                observation = (\n                    f\"Error1: {str(e)}, {type(e).__name__}, args: {action.args}\"\n                )\n            result = f\"Tool {tool.name} returned: {observation}\"\n            output = {\"result\": result, \"retry\": retry}\n        elif action.name == \"ERROR\":\n            result = f\"Error2: {action.args}. \"\n            output = {\"result\": result, \"retry\": False}\n        else:\n            result = (\n                f\"Unknown tool '{action.name}'. \"\n                f\"Please refer to the 'TOOLS' list for available \"\n                f\"tools and only respond in the specified JSON format.\"\n            )\n            output = {\"result\": result, \"retry\": True}\n\n        logger.info(\"Tool Response : \" + str(output) + \"\\n\")\n        return output\n\n    def clean_tool_args(self, args):\n        parsed_args = {}\n        for key in args.keys():\n            parsed_args[key] = args[key]\n            if type(args[key]) is dict and \"value\" in args[key]:\n                parsed_args[key] = args[key][\"value\"]\n        return parsed_args\n\n    def update_agent_execution_tokens(self, current_calls, total_tokens, session):\n        agent_execution = session.query(AgentExecution).filter(\n            AgentExecution.id == self.agent_config[\"agent_execution_id\"]).first()\n        agent_execution.num_of_calls += current_calls\n        agent_execution.num_of_tokens += total_tokens\n        session.commit()\n\n    def build_agent_prompt(self, prompt: str, task_queue: TaskQueue, max_token_limit: int, model_source_type: ModelSourceType):\n        pending_tasks = task_queue.get_tasks()\n        completed_tasks = task_queue.get_completed_tasks()\n        add_finish_tool = True\n        if len(pending_tasks) > 0 or len(completed_tasks) > 0:\n            add_finish_tool = False\n\n        prompt = AgentPromptBuilder.replace_main_variables(prompt, self.agent_execution_config[\"goal\"],\n                                                           self.agent_execution_config[\"instruction\"],\n                                                           self.agent_config[\"constraints\"], self.tools,\n                                                           add_finish_tool,model_source_type)\n\n        response = task_queue.get_last_task_details()\n\n        last_task = \"\"\n        last_task_result = \"\"\n        # pending_tasks = []\n        # current_task = \"\"\n        if response is not None:\n            last_task = response[\"task\"]\n            last_task_result = response[\"response\"]\n        current_task = task_queue.get_first_task() or \"\"\n        token_limit = TokenCounter.token_limit() - max_token_limit\n        prompt = AgentPromptBuilder.replace_task_based_variables(prompt, current_task, last_task, last_task_result,\n                                                                 pending_tasks, completed_tasks, token_limit)\n        return prompt\n\n    def check_permission_in_restricted_mode(self, assistant_reply: str, session):\n        action = self.output_parser.parse(assistant_reply)\n        tools = {t.name: t for t in self.tools}\n\n        excluded_tools = [FINISH, '', None]\n\n        if self.agent_config[\"permission_type\"].upper() == \"RESTRICTED\" and action.name not in excluded_tools and \\\n                tools.get(action.name) and tools[action.name].permission_required:\n            new_agent_execution_permission = AgentExecutionPermission(\n                agent_execution_id=self.agent_config[\"agent_execution_id\"],\n                status=\"PENDING\",\n                agent_id=self.agent_config[\"agent_id\"],\n                tool_name=action.name,\n                assistant_reply=assistant_reply)\n\n            session.add(new_agent_execution_permission)\n            session.commit()\n            return True, {\"result\": \"WAITING_FOR_PERMISSION\", \"permission_id\": new_agent_execution_permission.id}\n        return False, None\n"}
{"type": "source_file", "path": "autospark/controllers/agent_workflow_step.py", "content": "from fastapi import HTTPException, Depends\n\n\nfrom fastapi import APIRouter\nfrom fastapi import Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_sqlalchemy import db\nfrom datetime import datetime\n\nfrom autospark.helper.auth import get_user_organisation, get_current_user\nfrom autospark.models.workflows.agent_workflow_step import AgentWorkflowStep\nfrom sqlalchemy import or_\nfrom pydantic import BaseModel\nfrom autospark.helper.auth import check_auth, get_user_organisation\nfrom fastapi_jwt_auth import AuthJWT\n\nrouter = APIRouter()\n\n\nclass AgentWorkflowStepOut(BaseModel):\n    id: int\n    agent_workflow_id: int\n    unique_id: int\n    prompt: str\n    variables: str\n    output_type: str\n    step_type: str\n    next_step_id: int\n    history_enabled: bool\n    completion_prompt: str\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass AgentWorkflowStepIn(BaseModel):\n    def __init__(self, *args, **kwargs):\n        super().__init__(args, kwargs)\n\n    agent_workflow_id: int\n    unique_id: int\n    prompt: str\n    variables: str\n    output_type: str\n    step_type: str\n    next_step_id: int\n    history_enabled: bool\n    completion_prompt: str\n\n    class Config:\n        orm_mode = True\n\n\n@router.get(\"/list/{workflow_id}\", dependencies=[Depends(HTTPBearer())],status_code=201)\ndef list_workflow_steps(workflow_id: int, organisation=Depends(get_user_organisation), user=Depends(get_current_user)):\n    \"\"\"\n    Lists agent workflow_steps.\n\n    Args:\n        organisation: User's organisation.\n        user: Current User.\n    Returns:\n        list: A list of dictionaries representing the agent workflow_steps.\n\n    \"\"\"\n    workflow_steps = db.session.query(AgentWorkflowStep).filter(\n        or_(AgentWorkflowStep.agent_workflow_id == workflow_id)).all()\n\n    output_json = []\n    for workflow_step in workflow_steps:\n        output_json.append(workflow_step.to_dict())\n    return output_json\n\n\n@router.post(\"/create\", status_code=201,dependencies=[Depends(HTTPBearer())], response_model=AgentWorkflowStepOut)\ndef create_workflow_step(workflow_template: AgentWorkflowStepIn):\n    \"\"\"\n\n    Args:\n    agent_workflow_id = Column(Integer)\n    unique_id = Column(String)\n    prompt = Column(Text)\n    variables = Column(Text)\n    output_type = Column(String)\n    step_type = Column(String) # TRIGGER, NORMAL\n    next_step_id = Column(Integer)\n    history_enabled = Column(Boolean)\n    completion_prompt = Column(Text)\n\n    Returns:\n\n    \"\"\"\n    wf = AgentWorkflowStep(agent_workflow_id=workflow_template.agent_workflow_id,\n                           prompt=workflow_template.prompt,\n                           unique_id=workflow_template.unique_id,\n                           variables=workflow_template.variables,\n                           output_type=workflow_template.output_type,\n                           step_type=workflow_template.step_type,\n                           next_step_id=workflow_template.next_step_id,\n                           history_enabled=workflow_template.history_enabled,\n                           completion_prompt=workflow_template.completion_prompt)\n    db.session.add(wf)\n    db.session.commit()\n\n    return wf\n\n\n@router.put(\"/update/{workflow_step_id}\", dependencies=[Depends(HTTPBearer())],status_code=201, response_model=AgentWorkflowStepOut)\ndef update_workflow_step(workflow_step_id: int, workflow_template: AgentWorkflowStepIn):\n    workflowstep = db.session.query(AgentWorkflowStep).filter(AgentWorkflowStep.id == workflow_step_id).first()\n    if not workflowstep:\n        raise HTTPException(status_code=404, detail=\"WorkflowStep ot found\")\n    workflowstep.agent_workflow_id = workflow_template.agent_workflow_id\n    workflowstep.prompt = workflow_template.prompt\n    workflowstep.unique_id = workflow_template.unique_id\n    workflowstep.variables = workflow_template.variables\n    workflowstep.output_type = workflow_template.output_type\n    workflowstep.step_type = workflow_template.step_type\n    workflowstep.next_step_id = workflow_template.next_step_id\n    workflowstep.history_enabled = workflow_template.history_enabled\n    workflowstep.completion_prompt = workflow_template.completion_prompt\n    db.session.add(workflowstep)\n    db.session.commit()\n\n\n@router.get(\"/get/{workflow_step_id}\",dependencies=[Depends(HTTPBearer())],)\ndef get_workflow_step(workflow_step_id: int):\n    \"\"\"\n        Get the details of a specific workflow_step\n\n        Args:\n            workflow_step_id (int): The ID of the workflow step .\n\n        Returns:\n            dict: The details of the agent template.\n\n        Raises:\n            HTTPException (status_code=404): If the agent template is not found.\n    \"\"\"\n    workflowstep = db.session.query(AgentWorkflowStep).filter(AgentWorkflowStep.id == workflow_step_id).first()\n    if not workflowstep:\n        raise HTTPException(status_code=404, detail=\"WorkflowStep   not found\")\n    wf = workflowstep.to_dict()\n    return wf\n\n\n@router.delete(\"/{workflow_step_id}\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef delete_step(workflow_step_id: int, Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n        Args:\n            agent_id (int): Identifier of the Agent to delete\n        Returns:\n            A dictionary containing a \"success\" key with the value True to indicate a successful delete.\n        Raises:\n            HTTPException (Status Code=404): If the Agent or associated Project is not found or deleted already.\n    \"\"\"\n\n    workflow_step = db.session.query(AgentWorkflowStep).filter(AgentWorkflowStep.id == workflow_step_id).first()\n\n    if not workflow_step:\n        raise HTTPException(status_code=404, detail=\"step not found\")\n    # Deletion Procedure\n    db.session.delete(workflow_step)\n    db.session.commit()\n"}
{"type": "source_file", "path": "autospark/controllers/types/agent_execution_config.py", "content": "import datetime\nfrom typing import List, Optional\nfrom pydantic import BaseModel\nfrom datetime import datetime\n\n\nclass AgentRunIn(BaseModel):\n    status: Optional[str]\n    name: Optional[str]\n    agent_id: Optional[int]\n    last_execution_time: Optional[datetime]\n    num_of_calls: Optional[int]\n    num_of_tokens: Optional[int]\n    current_step_id: Optional[int]\n    permission_id: Optional[int]\n    goal: Optional[List[str]]\n    instruction: Optional[List[str]]\n    agent_workflow: str\n    constraints: List[str]\n    toolkits: List[int]\n    tools: List[int]\n    exit: str\n    iteration_interval: int\n    model: str\n    permission_type: str\n    LTM_DB: str\n    max_iterations: int\n    user_timezone: Optional[str]\n    knowledge: Optional[int]\n\n    class Config:\n        orm_mode = True"}
{"type": "source_file", "path": "autospark/agent/common_types.py", "content": "from pydantic import BaseModel\n\n\nclass ToolExecutorResponse(BaseModel):\n    status: str\n    result: str = None\n    retry: bool = False\n    is_permission_required: bool = False\n    permission_id: int = None\n\n\nclass TaskExecutorResponse(BaseModel):\n    status: str\n    retry: bool\n"}
{"type": "source_file", "path": "autospark/controllers/types/agent_schedule.py", "content": "from pydantic import BaseModel\nfrom typing import Optional\nfrom datetime import datetime\n\nclass AgentScheduleInput(BaseModel):\n    agent_id: Optional[int]\n    start_time: datetime\n    recurrence_interval: Optional[str] = None\n    expiry_date: Optional[datetime] = None\n    expiry_runs: Optional[int] = -1\n"}
{"type": "source_file", "path": "autospark/agent/output_handler.py", "content": "from autospark.agent.common_types import TaskExecutorResponse, ToolExecutorResponse\nfrom autospark.agent.output_parser import AgentSchemaOutputParser\nfrom autospark.agent.task_queue import TaskQueue\nfrom autospark.agent.tool_executor import ToolExecutor\nfrom autospark.helper.json_cleaner import JsonCleaner\nfrom autospark.lib.logger import logger\nfrom autospark.models.agent import Agent\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent_execution_feed import AgentExecutionFeed\nimport numpy as np\n\nfrom autospark.models.agent_execution_permission import AgentExecutionPermission\n\n\nclass ToolOutputHandler:\n    \"\"\"Handles the tool output response from the thinking step\"\"\"\n\n    def __init__(self, agent_execution_id: int, agent_config: dict,\n                 tools: list, output_parser=AgentSchemaOutputParser()):\n        self.agent_execution_id = agent_execution_id\n        self.task_queue = TaskQueue(str(agent_execution_id))\n        self.agent_config = agent_config\n        self.tools = tools\n        self.output_parser = output_parser\n\n    def handle(self, session, assistant_reply):\n        \"\"\"Handles the tool output response from the thinking step.\n        Step takes care of permission control as well at tool level.\n\n        Args:\n            session (Session): The database session.\n            assistant_reply (str): The assistant reply.\n        \"\"\"\n        response = self._check_permission_in_restricted_mode(session, assistant_reply)\n        if response.is_permission_required:\n            return response\n\n        tool_response = self.handle_tool_response(session, assistant_reply)\n        # print(tool_response)\n\n        agent_execution = AgentExecution.find_by_id(session, self.agent_execution_id)\n        agent_execution_feed = AgentExecutionFeed(agent_execution_id=self.agent_execution_id,\n                                                  agent_id=self.agent_config[\"agent_id\"],\n                                                  feed=assistant_reply,\n                                                  role=\"assistant\",\n                                                  feed_group_id=agent_execution.current_feed_group_id)\n        session.add(agent_execution_feed)\n        tool_response_feed = AgentExecutionFeed(agent_execution_id=self.agent_execution_id,\n                                                agent_id=self.agent_config[\"agent_id\"],\n                                                feed=tool_response.result,\n                                                role=\"system\",\n                                                feed_group_id=agent_execution.current_feed_group_id)\n        session.add(tool_response_feed)\n        session.commit()\n        if not tool_response.retry:\n            tool_response = self._check_for_completion(tool_response)\n        # print(\"Tool Response:\", tool_response)\n        return tool_response\n\n    def handle_tool_response(self, session, assistant_reply):\n        \"\"\"Only handle processing of tool response\"\"\"\n        action = self.output_parser.parse(assistant_reply, session=session, agent_id=self.agent_config[\"agent_id\"],\n                                          agent_execution_id=self.agent_execution_id)\n        agent = session.query(Agent).filter(Agent.id == self.agent_config[\"agent_id\"]).first()\n        organisation = agent.get_agent_organisation(session)\n        tool_executor = ToolExecutor(organisation_id=organisation.id, agent_id=agent.id, tools=self.tools)\n        return tool_executor.execute(session, action.name, action.args)\n\n    def _check_permission_in_restricted_mode(self, session, assistant_reply: str):\n        action = self.output_parser.parse(assistant_reply, session=session, agent_id=self.agent_config[\"agent_id\"],\n                                          agent_execution_id=self.agent_execution_id)\n        tools = {t.name: t for t in self.tools}\n\n        excluded_tools = [ToolExecutor.FINISH, '', None]\n\n        if self.agent_config[\"permission_type\"].upper() == \"RESTRICTED\" and action.name not in excluded_tools and \\\n                tools.get(action.name) and tools[action.name].permission_required:\n            new_agent_execution_permission = AgentExecutionPermission(\n                agent_execution_id=self.agent_execution_id,\n                status=\"PENDING\",\n                agent_id=self.agent_config[\"agent_id\"],\n                tool_name=action.name,\n                assistant_reply=assistant_reply)\n\n            session.add(new_agent_execution_permission)\n            session.commit()\n            return ToolExecutorResponse(is_permission_required=True, status=\"WAITING_FOR_PERMISSION\",\n                                        permission_id=new_agent_execution_permission.id)\n        return ToolExecutorResponse(status=\"PENDING\", is_permission_required=False)\n\n    def _check_for_completion(self, tool_response):\n        self.task_queue.complete_task(tool_response.result)\n        current_tasks = self.task_queue.get_tasks()\n        if self.task_queue.get_completed_tasks() and len(current_tasks) == 0:\n            tool_response.status = \"COMPLETE\"\n        if current_tasks and tool_response.status == \"COMPLETE\":\n            tool_response.status = \"PENDING\"\n        return tool_response\n\n\nclass TaskOutputHandler:\n    \"\"\"Handles the task output from the LLM. Output is mostly in the array of tasks and\n    handler adds every task to the task queue.\n    \"\"\"\n\n    def __init__(self, agent_execution_id: int, agent_config: dict):\n        self.agent_execution_id = agent_execution_id\n        self.task_queue = TaskQueue(str(agent_execution_id))\n        self.agent_config = agent_config\n\n    def handle(self, session, assistant_reply):\n        assistant_reply = JsonCleaner.extract_json_array_section(assistant_reply)\n        tasks = eval(assistant_reply)\n        tasks = np.array(tasks).flatten().tolist()\n        for task in reversed(tasks):\n            self.task_queue.add_task(task)\n        if len(tasks) > 0:\n            logger.info(\"Adding task to queue: \" + str(tasks))\n        agent_execution = AgentExecution.find_by_id(session, self.agent_execution_id)\n        for task in tasks:\n            agent_execution_feed = AgentExecutionFeed(agent_execution_id=self.agent_execution_id,\n                                                      agent_id=self.agent_config[\"agent_id\"],\n                                                      feed=\"New Task Added: \" + task,\n                                                      role=\"system\",\n                                                      feed_group_id=agent_execution.current_feed_group_id)\n            session.add(agent_execution_feed)\n        status = \"COMPLETE\" if len(self.task_queue.get_tasks()) == 0 else \"PENDING\"\n        session.commit()\n        return TaskExecutorResponse(status=status, retry=False)\n\n\nclass ReplaceTaskOutputHandler:\n    \"\"\"Handles the replace/prioritize task output type.\n    Output is mostly in the array of tasks and handler adds every task to the task queue.\n    \"\"\"\n\n    def __init__(self, agent_execution_id: int, agent_config: dict):\n        self.agent_execution_id = agent_execution_id\n        self.task_queue = TaskQueue(str(agent_execution_id))\n        self.agent_config = agent_config\n\n    def handle(self, session, assistant_reply):\n        assistant_reply = JsonCleaner.extract_json_array_section(assistant_reply)\n        tasks = eval(assistant_reply)\n        self.task_queue.clear_tasks()\n        for task in reversed(tasks):\n            self.task_queue.add_task(task)\n        if len(tasks) > 0:\n            logger.info(\"Tasks reprioritized in order: \" + str(tasks))\n        status = \"COMPLETE\" if len(self.task_queue.get_tasks()) == 0 else \"PENDING\"\n        session.commit()\n        return TaskExecutorResponse(status=status, retry=False)\n\n\ndef get_output_handler(llm, output_type: str, agent_execution_id: int, agent_config: dict, agent_tools: list = []):\n    if output_type == \"tools\":\n        return ToolOutputHandler(agent_execution_id, agent_config, agent_tools,\n                                 output_parser=AgentSchemaOutputParser(llm=llm))\n    elif output_type == \"replace_tasks\":\n        return ReplaceTaskOutputHandler(agent_execution_id, agent_config,\n                                        )\n    elif output_type == \"tasks\":\n        return TaskOutputHandler(agent_execution_id, agent_config)\n    return ToolOutputHandler(agent_execution_id, agent_config, agent_tools,\n                             output_parser=AgentSchemaOutputParser(llm=llm))\n"}
{"type": "source_file", "path": "autospark/agent/output_parser.py", "content": "import json\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, NamedTuple, List\nimport re\nimport ast\nimport json5\n\nfrom autospark.agent.agent_message_builder import AgentLlmMessageBuilder\nfrom autospark.agent.agent_prompt_builder import AgentPromptBuilder\nfrom autospark.helper.json_cleaner import JsonCleaner\nfrom autospark.helper.spark_result_helper import SparkResultParser\nfrom autospark.helper.token_counter import TokenCounter\nfrom autospark.lib.logger import logger\n\nfrom signal import signal, SIGPIPE, SIG_DFL, SIG_IGN\nsignal(SIGPIPE, SIG_IGN)\n\n\nclass AgentGPTAction(NamedTuple):\n    name: str\n    args: Dict\n\n\nclass AgentTasks(NamedTuple):\n    tasks: List[Dict] = []\n    error: str = \"\"\n\n\nclass BaseOutputParser(ABC):\n    @abstractmethod\n    def parse(self, text: str) -> AgentGPTAction:\n        \"\"\"Return AgentGPTAction\"\"\"\n\n\nclass AgentSchemaOutputParser(BaseOutputParser):\n    def __init__(self, llm=None):\n        self.llm = llm\n\n    def fix_json_by_llm(self, session, agent_id, agent_execution_id, jsonStr: str) -> str:\n\n        if not self.llm or not session:\n            return jsonStr\n        else:\n            prompt = AgentPromptBuilder.get_json_fixer_prompt(jsonStr)\n            messages = AgentLlmMessageBuilder(session, self.llm, agent_id, agent_execution_id) \\\n                .build_agent_messages(prompt, [], history_enabled=False,\n                                      completion_prompt=None)\n            current_tokens = TokenCounter.count_message_tokens(messages, self.llm.get_model())\n\n            response = self.llm.chat_completion(messages,\n                                                TokenCounter.token_limit(self.llm.get_model()) - current_tokens)\n            content = response['content']\n            if content.startswith(\"```\") and content.endswith(\"```\"):\n                content = \"```\".join(content.split(\"```\")[1:-1])\n                content = JsonCleaner.extract_json_section(content)\n\n            return content\n\n    def fix_json_according_schema(self, j, schema) -> str:\n        '''  code_description schemashcema\n        {\n            \"thoughts\": {\n                \"reasoning\": \"\"\n            },\n            \"tool\": {\n                \"name\": \"CodingTool\",\n                \"args\": {\n                    \"code_description\": {\n                        \"title\": \"\",\n                        \"description\": \"\",\n                        \"type\": \"string\"\n                    },\n                    \"spec_file_name\": \"snake_game.py\"\n                }\n            }\n        }\n        '''\n        try:\n            js = json.loads(j)\n        except Exception:\n            return j\n\n        if not 'tool' in js:\n            return j\n\n        if not \"args\" in js.get(\"tool\"):\n            return j\n\n        args = js.get('tool').get(\"args\")\n        for k, v in args.items():\n            if type(v) == dict:\n                if 'title' in v and 'description' in v and 'type' in v:\n                    args[k] = v['description']\n                else:\n                    args[k] = ''\n        js.get(\"tool\")['args'] = args\n        return json.dumps(js)\n\n    def parse(self, response: str, session=None, agent_id: str = '', agent_execution_id: str = '') -> AgentGPTAction:\n        if response.startswith(\"```\") and response.endswith(\"```\"):\n            response = \"```\".join(response.split(\"```\")[1:-1])\n            response = JsonCleaner.extract_json_section(response)\n\n        # json v2.1 json schemafix\n        response = self.fix_json_according_schema(response, \"\")\n        # OpenAI returns `str(content_dict)`, literal_eval reverses this\n        try:\n            logger.debug(\"AgentSchemaOutputParser: %s\" % response)\n\n            response_obj = ast.literal_eval(response)\n            return AgentGPTAction(\n                name=response_obj['tool']['name'],\n                args=response_obj['tool']['args'],\n            )\n        except BaseException as e:\n            st = self.fix_json_by_llm(session, agent_id, agent_execution_id, response)\n            response_obj = ast.literal_eval(st)\n            return AgentGPTAction(\n                name=response_obj['tool']['name'],\n                args=response_obj['tool']['args'],\n            )\n\n\nclass AgentSchemaToolOutputParser(BaseOutputParser):\n    \"\"\"Parses the output from the agent schema for the tool\"\"\"\n\n    def parse(self, response: str) -> AgentGPTAction:\n        if response.startswith(\"```\") and response.endswith(\"```\"):\n            response = \"```\".join(response.split(\"```\")[1:-1])\n        response = JsonCleaner.extract_json_section(response)\n        # ast throws error if true/false params passed in json\n        response = JsonCleaner.clean_boolean(response)\n        # json v2.1 json schemafix\n        response = self.fix_json_according_schema(response, \"\")\n        # OpenAI returns `str(content_dict)`, literal_eval reverses this\n        try:\n            logger.debug(\"AgentSchemaOutputParser: \", response)\n            response_obj = ast.literal_eval(response)\n            args = response_obj['args'] if 'args' in response_obj else {}\n            return AgentGPTAction(\n                name=response_obj['name'],\n                args=args,\n            )\n        except BaseException as e:\n            logger.info(f\"AgentSchemaToolOutputParser: Error parsing JSON respons {e}\")\n            raise e\n\n    def fix_json_according_schema(self, j, schema) -> str:\n        '''  code_description schemashcema\n        {\n            \"thoughts\": {\n                \"reasoning\": \"\"\n            },\n            \"tool\": {\n                \"name\": \"CodingTool\",\n                \"args\": {\n                    \"code_description\": {\n                        \"title\": \"\",\n                        \"description\": \"\",\n                        \"type\": \"string\"\n                    },\n                    \"spec_file_name\": \"snake_game.py\"\n                }\n            }\n        }\n        '''\n        try:\n            js = json.loads(j)\n        except Exception:\n            return j\n\n        if not 'tool' in js:\n            return j\n\n        if not \"args\" in js.get(\"tool\"):\n            return j\n\n        args = js.get('tool').get(\"args\")\n        for k, v in args.items():\n            if type(v) == dict:\n                if 'title' in v and 'description' in v and 'type' in v:\n                    args[k] = v['description']\n                else:\n                    args[k] = ''\n        js.get(\"tool\")['args'] = args\n        return json.dumps(js)\n"}
{"type": "source_file", "path": "autospark/controllers/types/agent_with_config.py", "content": "from pydantic import BaseModel\nfrom typing import List, Optional\n\n\nclass AgentConfigInput(BaseModel):\n    name: str\n    project_id: int\n    description: str\n    goal: List[str]\n    instruction: List[str]\n    agent_workflow: str\n    constraints: List[str]\n    toolkits: List[int]\n    tools: List[int]\n    exit: str\n    iteration_interval: int\n    model: str\n    permission_type: str\n    LTM_DB: str\n    max_iterations: int\n    user_timezone: Optional[str]\n    knowledge: Optional[int]\n"}
{"type": "source_file", "path": "autospark/controllers/twitter_oauth.py", "content": "from fastapi import Depends, Query\nfrom fastapi import APIRouter\nfrom fastapi.responses import RedirectResponse\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom sqlalchemy.orm import sessionmaker\n\nimport autospark\nimport json\nfrom autospark.models.db import connect_db\nimport http.client as http_client\nfrom autospark.helper.twitter_tokens import TwitterTokens\nfrom autospark.helper.auth import get_current_user\nfrom autospark.models.tool_config import ToolConfig\nfrom autospark.models.toolkit import Toolkit\nfrom autospark.models.oauth_tokens import OauthTokens\n\nrouter = APIRouter()\n\n@router.get('/oauth-tokens')\nasync def twitter_oauth(oauth_token: str = Query(...),oauth_verifier: str = Query(...), Authorize: AuthJWT = Depends()):\n    token_uri = f'https://api.twitter.com/oauth/access_token?oauth_verifier={oauth_verifier}&oauth_token={oauth_token}'\n    conn = http_client.HTTPSConnection(\"api.twitter.com\")\n    conn.request(\"POST\", token_uri, \"\")\n    res = conn.getresponse()\n    response_data = res.read().decode('utf-8')\n    frontend_url = autospark.config.config.get_config(\"FRONTEND_URL\", \"http://localhost:3000\")\n    redirect_url_success = f\"{frontend_url}/twitter_creds/?{response_data}\"\n    return RedirectResponse(url=redirect_url_success)\n\n@router.post(\"/send_twitter_creds/{twitter_creds}\")\ndef send_twitter_tool_configs(twitter_creds: str, Authorize: AuthJWT = Depends()):\n    current_user = get_current_user()\n    user_id = current_user.id\n    credentials = json.loads(twitter_creds)\n    credentials[\"user_id\"] = user_id\n    toolkit = db.session.query(Toolkit).filter(Toolkit.id == credentials[\"toolkit_id\"]).first()\n    api_key = db.session.query(ToolConfig).filter(ToolConfig.key == \"TWITTER_API_KEY\", ToolConfig.toolkit_id == credentials[\"toolkit_id\"]).first()\n    api_key_secret = db.session.query(ToolConfig).filter(ToolConfig.key == \"TWITTER_API_SECRET\", ToolConfig.toolkit_id == credentials[\"toolkit_id\"]).first()\n    final_creds = {\n        \"api_key\": api_key.value,\n        \"api_key_secret\": api_key_secret.value,\n        \"oauth_token\": credentials[\"oauth_token\"],\n        \"oauth_token_secret\": credentials[\"oauth_token_secret\"]\n    }\n    tokens = OauthTokens().add_or_update(db.session, credentials[\"toolkit_id\"], user_id, toolkit.organisation_id, \"TWITTER_OAUTH_TOKENS\", str(final_creds))\n    if tokens:\n        success = True\n    else:\n        success = False\n    return success\n\n@router.get(\"/get_twitter_creds/toolkit_id/{toolkit_id}\")\ndef get_twitter_tool_configs(toolkit_id: int):\n    twitter_config_key = db.session.query(ToolConfig).filter(ToolConfig.toolkit_id == toolkit_id,ToolConfig.key == \"TWITTER_API_KEY\").first()\n    twitter_config_secret = db.session.query(ToolConfig).filter(ToolConfig.toolkit_id == toolkit_id,ToolConfig.key == \"TWITTER_API_SECRET\").first()\n    api_data =  {\n        \"api_key\": twitter_config_key.value,\n        \"api_secret\": twitter_config_secret.value\n    }\n    response = TwitterTokens(db.session).get_request_token(api_data)\n    return response"}
{"type": "source_file", "path": "autospark/controllers/tool.py", "content": "from datetime import datetime\n\nfrom fastapi import APIRouter\nfrom fastapi import HTTPException, Depends\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi.security import HTTPBearer\nfrom fastapi_sqlalchemy import db\nfrom pydantic import BaseModel\n\nfrom autospark.helper.auth import check_auth, get_user_organisation\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.tool import Tool\nfrom autospark.models.toolkit import Toolkit\n\nrouter = APIRouter()\n\n\nclass ToolOut(BaseModel):\n    id: int\n    name: str\n    folder_name: str\n    class_name: str\n    file_name: str\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass ToolIn(BaseModel):\n    name: str\n    folder_name: str\n    class_name: str\n    file_name: str\n\n    class Config:\n        orm_mode = True\n\n# CRUD Operations\n@router.post(\"/add\", dependencies=[Depends(HTTPBearer())],response_model=ToolOut, status_code=201)\ndef create_tool(\n        tool: ToolIn,\n        Authorize: AuthJWT = Depends(check_auth),\n):\n    \"\"\"\n    Create a new tool.\n\n    Args:\n        tool (ToolIn): Tool data.\n\n    Returns:\n        Tool: The created tool.\n\n    Raises:\n        HTTPException (status_code=400): If there is an issue creating the tool.\n\n    \"\"\"\n\n    db_tool = Tool(\n        name=tool.name,\n        folder_name=tool.folder_name,\n        class_name=tool.class_name,\n        file_name=tool.file_name,\n    )\n    db.session.add(db_tool)\n    db.session.commit()\n    return db_tool\n\n\n@router.get(\"/get/{tool_id}\", dependencies=[Depends(HTTPBearer())],response_model=ToolOut)\ndef get_tool(\n        tool_id: int,\n        Authorize: AuthJWT = Depends(check_auth),\n):\n    \"\"\"\n    Get a particular tool details.\n\n    Args:\n        tool_id (int): ID of the tool.\n\n    Returns:\n        Tool: The tool details.\n\n    Raises:\n        HTTPException (status_code=404): If the tool with the specified ID is not found.\n\n    \"\"\"\n\n    db_tool = db.session.query(Tool).filter(Tool.id == tool_id).first()\n    if not db_tool:\n        raise HTTPException(status_code=404, detail=\"Tool not found\")\n    return db_tool\n\n\n@router.get(\"/list\",dependencies=[Depends(HTTPBearer())])\ndef get_tools(\n        organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"Get all tools\"\"\"\n    toolkits = db.session.query(Toolkit).filter(Toolkit.organisation_id == organisation.id).all()\n    tools = []\n    for toolkit in toolkits:\n        db_tools = db.session.query(Tool).filter(Tool.toolkit_id == toolkit.id).all()\n        tools.extend(db_tools)\n    return tools\n\n\n@router.put(\"/update/{tool_id}\", dependencies=[Depends(HTTPBearer())],response_model=ToolOut)\ndef update_tool(\n        tool_id: int,\n        tool: ToolIn,\n        Authorize: AuthJWT = Depends(check_auth),\n):\n    \"\"\"\n    Update a particular tool.\n\n    Args:\n        tool_id (int): ID of the tool.\n        tool (ToolIn): Updated tool data.\n\n    Returns:\n        Tool: The updated tool details.\n\n    Raises:\n        HTTPException (status_code=404): If the tool with the specified ID is not found.\n\n    \"\"\"\n\n    db_tool = db.session.query(Tool).filter(Tool.id == tool_id).first()\n    if not db_tool:\n        raise HTTPException(status_code=404, detail=\"Tool not found\")\n\n    db_tool.name = tool.name\n    db_tool.folder_name = tool.folder_name\n    db_tool.class_name = tool.class_name\n    db_tool.file_name = tool.file_name\n\n    db.session.add(db_tool)\n    db.session.commit()\n    return db_tool\n"}
{"type": "source_file", "path": "autospark/controllers/__init__.py", "content": ""}
{"type": "source_file", "path": "autospark/controllers/analytics.py", "content": "from fastapi import APIRouter, Depends, HTTPException\nfrom fastapi.security import HTTPBearer\n\nfrom autospark.helper.auth import check_auth, get_user_organisation\nfrom autospark.apm.analytics_helper import AnalyticsHelper\nfrom autospark.apm.event_handler import EventHandler\nfrom autospark.apm.tools_handler import ToolsHandler\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nimport logging\n\nrouter = APIRouter()\n\n@router.get(\"/metrics\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef get_metrics(organisation=Depends(get_user_organisation)):\n    \"\"\"\n    Get the total tokens, total calls, and the number of run completed.\n\n    Returns:\n        metrics: dictionary containing total tokens, total calls, and the number of runs completed.\n\n    \"\"\"\n    try:\n        return AnalyticsHelper(session=db.session, organisation_id=organisation.id).calculate_run_completed_metrics()\n    except Exception as e:\n        logging.error(f\"Error while calculating metrics: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@router.get(\"/agents/all\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef get_agents(organisation=Depends(get_user_organisation)):\n    try:\n        return AnalyticsHelper(session=db.session, organisation_id=organisation.id).fetch_agent_data()\n    except Exception as e:\n        logging.error(f\"Error while fetching agent data: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@router.get(\"/agents/{agent_id}\",dependencies=[Depends(HTTPBearer())], status_code=200)\ndef get_agent_runs(agent_id: int, organisation=Depends(get_user_organisation)):\n    try:\n        return AnalyticsHelper(session=db.session, organisation_id=organisation.id).fetch_agent_runs(agent_id)\n    except Exception as e:\n        logging.error(f\"Error while fetching agent runs: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@router.get(\"/runs/active\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef get_active_runs(organisation=Depends(get_user_organisation)):\n    try:\n        return AnalyticsHelper(session=db.session, organisation_id=organisation.id).get_active_runs()\n    except Exception as e:\n        logging.error(f\"Error while getting active runs: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@router.get(\"/tools/used\",dependencies=[Depends(HTTPBearer())], status_code=200)\ndef get_tools_used(organisation=Depends(get_user_organisation)):\n    try:\n        return ToolsHandler(session=db.session, organisation_id=organisation.id).calculate_tool_usage()\n    except Exception as e:\n        logging.error(f\"Error while calculating tool usage: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n"}
{"type": "source_file", "path": "autospark/controllers/agent_execution.py", "content": "from datetime import datetime\nfrom typing import Optional\nfrom fastapi.security import HTTPBearer\n\nfrom fastapi_sqlalchemy import db\nfrom fastapi import HTTPException, Depends\nfrom fastapi_jwt_auth import AuthJWT\nfrom pydantic import BaseModel\nfrom pydantic.fields import List\n\nfrom autospark.helper.time_helper import get_time_difference\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.agent_execution_config import AgentExecutionConfiguration\nfrom autospark.models.workflows.agent_workflow import AgentWorkflow\nfrom autospark.models.agent_schedule import AgentSchedule\nfrom autospark.models.workflows.iteration_workflow import IterationWorkflow\nfrom autospark.worker import execute_agent\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent import Agent\nfrom fastapi import APIRouter\nfrom sqlalchemy import desc\nfrom autospark.helper.auth import check_auth\nfrom autospark.controllers.types.agent_schedule import AgentScheduleInput\n# from autospark.types.db import AgentExecutionOut, AgentExecutionIn\nfrom autospark.apm.event_handler import EventHandler\n\nrouter = APIRouter()\n\n\nclass AgentExecutionOut(BaseModel):\n    id: int\n    status: str\n    name: str\n    agent_id: int\n    last_execution_time: datetime\n    num_of_calls: int\n    num_of_tokens: int\n    current_agent_step_id: int\n    permission_id: Optional[int]\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass AgentExecutionIn(BaseModel):\n    status: Optional[str]\n    name: Optional[str]\n    agent_id: Optional[int]\n    last_execution_time: Optional[datetime]\n    num_of_calls: Optional[int]\n    num_of_tokens: Optional[int]\n    current_agent_step_id: Optional[int]\n    permission_id: Optional[int]\n    goal: Optional[List[str]]\n    instruction: Optional[List[str]]\n\n    class Config:\n        orm_mode = True\n\n# CRUD Operations\n@router.post(\"/add\", dependencies=[Depends(HTTPBearer())],response_model=AgentExecutionOut, status_code=201)\ndef create_agent_execution(agent_execution: AgentExecutionIn,\n                           Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new agent execution/run.\n\n    Args:\n        agent_execution (AgentExecution): The agent execution data.\n\n    Returns:\n        AgentExecution: The created agent execution.\n\n    Raises:\n        HTTPException (Status Code=404): If the agent is not found.\n    \"\"\"\n\n    agent = db.session.query(Agent).filter(Agent.id == agent_execution.agent_id, Agent.is_deleted == False).first()\n    if not agent:\n        raise HTTPException(status_code=404, detail=\"Agent not found\")\n\n    start_step = AgentWorkflow.fetch_trigger_step_id(db.session, agent.agent_workflow_id)\n    iteration_step_id = IterationWorkflow.fetch_trigger_step_id(db.session,\n                                                                start_step.action_reference_id).id if start_step.action_type == \"ITERATION_WORKFLOW\" else -1\n\n    db_agent_execution = AgentExecution(status=\"RUNNING\", last_execution_time=datetime.now(),\n                                        agent_id=agent_execution.agent_id, name=agent_execution.name, num_of_calls=0,\n                                        num_of_tokens=0,\n                                        current_agent_step_id=start_step.id,\n                                        iteration_workflow_step_id=iteration_step_id)\n    agent_execution_configs = {\n        \"goal\": agent_execution.goal,\n        \"instruction\": agent_execution.instruction\n    }\n    agent_configs = db.session.query(AgentConfiguration).filter(AgentConfiguration.agent_id == agent_execution.agent_id).all()\n    keys_to_exclude = [\"goal\", \"instruction\"]\n    for agent_config in agent_configs:\n        if agent_config.key not in keys_to_exclude:\n            if agent_config.key == \"toolkits\":\n                if agent_config.value:\n                    toolkits = [int(item) for item in agent_config.value.strip('{}').split(',') if item.strip() and item != '[]']\n                    agent_execution_configs[agent_config.key] = toolkits\n                else:\n                    agent_execution_configs[agent_config.key] = []\n            elif agent_config.key == \"constraints\":\n                if agent_config.value:\n                    constraints = [item.strip('\"') for item in agent_config.value.strip('{}').split(',')]\n                    agent_execution_configs[agent_config.key] = constraints\n                else:\n                    agent_execution_configs[agent_config.key] = []\n            else:\n                agent_execution_configs[agent_config.key] = agent_config.value\n\n    db.session.add(db_agent_execution)\n    db.session.commit()\n    db.session.flush()\n    AgentExecutionConfiguration.add_or_update_agent_execution_config(session=db.session, execution=db_agent_execution,\n                                                                     agent_execution_configs=agent_execution_configs)\n\n    organisation = agent.get_agent_organisation(db.session)\n    EventHandler(session=db.session).create_event('run_created', {'agent_execution_id': db_agent_execution.id,'agent_execution_name':db_agent_execution.name},\n                                 agent_execution.agent_id, organisation.id if organisation else 0)\n\n    if db_agent_execution.status == \"RUNNING\":\n      execute_agent.delay(db_agent_execution.id, datetime.now())\n\n    return db_agent_execution\n\n\n@router.post(\"/schedule\",dependencies=[Depends(HTTPBearer())], status_code=201)\ndef schedule_existing_agent(agent_schedule: AgentScheduleInput,\n                            Authorize: AuthJWT = Depends(check_auth)):\n\n    \"\"\"\n    Schedules an already existing agent.\n\n    Args:\n        agent_schedule (AgentScheduleInput): Data for creating a scheduling for an existing agent.\n            agent_id (Integer): The ID of the agent being scheduled.\n            start_time (DateTime): The date and time from which the agent is scheduled.\n            recurrence_interval (String): Stores \"none\" if not recurring, \n            or a time interval like '2 Weeks', '1 Month', '2 Minutes' based on input.\n            expiry_date (DateTime): The date and time when the agent is scheduled to stop runs.\n            expiry_runs (Integer): The number of runs before the agent expires.\n\n    Returns:\n        Schedule ID: Unique Schedule ID of the Agent.\n\n    Raises:\n        HTTPException (Status Code=500): If the agent fails to get scheduled.\n    \"\"\"\n\n    # Check if the agent is already scheduled\n    scheduled_agent = db.session.query(AgentSchedule).filter(AgentSchedule.agent_id == agent_schedule.agent_id,\n                                                             AgentSchedule.status == \"SCHEDULED\").first()\n\n    if scheduled_agent:\n        # Update the old record with new data\n        scheduled_agent.start_time = agent_schedule.start_time\n        scheduled_agent.next_scheduled_time = agent_schedule.start_time\n        scheduled_agent.recurrence_interval = agent_schedule.recurrence_interval\n        scheduled_agent.expiry_date = agent_schedule.expiry_date\n        scheduled_agent.expiry_runs = agent_schedule.expiry_runs\n\n        db.session.commit()\n    else:                      \n        # Schedule the agent\n        scheduled_agent = AgentSchedule(\n            agent_id=agent_schedule.agent_id,\n            start_time=agent_schedule.start_time,\n            next_scheduled_time=agent_schedule.start_time,\n            recurrence_interval=agent_schedule.recurrence_interval,\n            expiry_date=agent_schedule.expiry_date,\n            expiry_runs=agent_schedule.expiry_runs,\n            current_runs=0,\n            status=\"SCHEDULED\"\n        )\n\n    db.session.add(scheduled_agent)\n    db.session.commit()\n\n    schedule_id = scheduled_agent.id\n\n    if schedule_id is None:\n        raise HTTPException(status_code=500, detail=\"Failed to schedule agent\")\n        \n    return {\n        \"schedule_id\": schedule_id\n    }\n\n\n@router.get(\"/get/{agent_execution_id}\",dependencies=[Depends(HTTPBearer())], response_model=AgentExecutionOut)\ndef get_agent_execution(agent_execution_id: int,\n                        Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get an agent execution by agent_execution_id.\n\n    Args:\n        agent_execution_id (int): The ID of the agent execution.\n\n    Returns:\n        AgentExecution: The requested agent execution.\n\n    Raises:\n        HTTPException (Status Code=404): If the agent execution is not found.\n    \"\"\"\n\n    if (\n        db_agent_execution := db.session.query(AgentExecution)\n        .filter(AgentExecution.id == agent_execution_id)\n        .first()\n    ):\n        return db_agent_execution\n    else:\n        raise HTTPException(status_code=404, detail=\"Agent execution not found\")\n\n\n@router.put(\"/update/{agent_execution_id}\", dependencies=[Depends(HTTPBearer())],response_model=AgentExecutionOut)\ndef update_agent_execution(agent_execution_id: int,\n                           agent_execution: AgentExecutionIn,\n                           Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"Update details of particular agent_execution by agent_execution_id\"\"\"\n\n    db_agent_execution = db.session.query(AgentExecution).filter(AgentExecution.id == agent_execution_id).first()\n    if agent_execution.status == \"COMPLETED\":\n        raise HTTPException(status_code=400, detail=\"Invalid Request\")\n\n    if not db_agent_execution:\n        raise HTTPException(status_code=404, detail=\"Agent Execution not found\")\n\n    if agent_execution.agent_id:\n        if agent := db.session.query(Agent).get(agent_execution.agent_id):\n            db_agent_execution.agent_id = agent.id\n        else:\n            raise HTTPException(status_code=404, detail=\"Agent not found\")\n    if agent_execution.status not in [\n        \"CREATED\",\n        \"RUNNING\",\n        \"PAUSED\",\n        \"COMPLETED\",\n        \"TERMINATED\",\n    ]:\n        raise HTTPException(status_code=400, detail=\"Invalid Request\")\n    db_agent_execution.status = agent_execution.status\n\n    db_agent_execution.last_execution_time = datetime.now()\n    db.session.commit()\n\n    if db_agent_execution.status == \"RUNNING\":\n        execute_agent.delay(db_agent_execution.id, datetime.now())\n\n    return db_agent_execution\n\n\n@router.get(\"/get/agents/status/{status}\",dependencies=[Depends(HTTPBearer())],)\ndef agent_list_by_status(status: str,\n                         Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"Get list of all agent_ids for a given status\"\"\"\n\n    running_agent_ids = db.session.query(AgentExecution.agent_id).filter(\n        AgentExecution.status == status.upper()).distinct().all()\n    agent_ids = [agent_id for (agent_id) in running_agent_ids]\n    return agent_ids\n\n\n@router.get(\"/get/agent/{agent_id}\",dependencies=[Depends(HTTPBearer())])\ndef list_running_agents(agent_id: str,\n                        Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"Get all running state agents\"\"\"\n\n    executions = db.session.query(AgentExecution).filter(AgentExecution.agent_id == agent_id).order_by(\n        desc(AgentExecution.status == 'RUNNING'), desc(AgentExecution.last_execution_time)).all()\n    for execution in executions:\n        execution.time_difference = get_time_difference(execution.last_execution_time,str(datetime.now()))\n    return executions\n\n\n@router.get(\"/get/latest/agent/project/{project_id}\",dependencies=[Depends(HTTPBearer())])\ndef get_agent_by_latest_execution(project_id: int,\n                                  Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"Get latest executing agent details\"\"\"\n\n    latest_execution = (\n        db.session.query(AgentExecution)\n        .join(Agent, AgentExecution.agent_id == Agent.id)\n        .filter(Agent.project_id == project_id)\n        .order_by(desc(AgentExecution.last_execution_time))\n        .first()\n    )\n    isRunning = False\n    if latest_execution.status == \"RUNNING\":\n        isRunning = True\n    agent = db.session.query(Agent).filter(Agent.id == latest_execution.agent_id).first()\n    return {\n        \"agent_id\": latest_execution.agent_id,\n        \"project_id\": project_id,\n        \"created_at\": agent.created_at,\n        \"description\": agent.description,\n        \"updated_at\": agent.updated_at,\n        \"name\": agent.name,\n        \"id\": agent.id,\n        \"status\": isRunning,\n        \"contentType\": \"Agents\"\n    }\n"}
{"type": "source_file", "path": "autospark/agent/agent_prompt_template.py", "content": "import re\n\nfrom pydantic.types import List\n\nfrom autospark.helper.prompt_reader import PromptReader\n\nFINISH_NAME = \"finish\"\n\n\nclass AgentPromptTemplate:\n\n    @staticmethod\n    def add_list_items_to_string(items: List[str]) -> str:\n        list_string = \"\"\n        for i, item in enumerate(items):\n            list_string += f\"{i + 1}. {item}\\n\"\n        return list_string\n\n    @classmethod\n    def clean_prompt(cls, prompt):\n        prompt = re.sub('[ \\t]+', ' ', prompt)\n        return prompt.strip()\n\n    @classmethod\n    def get_super_agi_single_prompt(cls):\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"autospark.txt\")\n\n        return {\"prompt\": autospark_prompt, \"variables\": [\"goals\", \"instructions\", \"constraints\", \"tools\"]}\n\n    @classmethod\n    def start_task_based(cls):\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"initialize_autospark_tasks.txt\")\n\n        return {\"prompt\": AgentPromptTemplate.clean_prompt(autospark_prompt), \"variables\": [\"goals\", \"instructions\"]}\n        # autospark_prompt = autospark_prompt.replace(\"{goals}\", AgentPromptBuilder.add_list_items_to_string(goals))\n\n    @classmethod\n    def analyse_task(cls):\n        constraints = [\n            'Exclusively use the tools listed in double quotes e.g. \"tool name\"'\n        ]\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"analyse_autospark_task.txt\")\n        autospark_prompt = AgentPromptTemplate.clean_prompt(autospark_prompt) \\\n            .replace(\"{constraints}\", AgentPromptTemplate.add_list_items_to_string(constraints))\n        return {\"prompt\": autospark_prompt, \"variables\": [\"goals\", \"instructions\", \"tools\", \"current_task\"]}\n\n    @classmethod\n    def create_tasks(cls):\n        # just executed task `{last_task}` and got the result `{last_task_result}`\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"create_autospark_tasks.txt\")\n        return {\"prompt\": AgentPromptTemplate.clean_prompt(autospark_prompt),\n                \"variables\": [\"goals\", \"instructions\", \"last_task\", \"last_task_result\", \"pending_tasks\"]}\n\n    @classmethod\n    def prioritize_tasks(cls):\n        # just executed task `{last_task}` and got the result `{last_task_result}`\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"prioritize_autospark_tasks.txt\")\n        return {\"prompt\": AgentPromptTemplate.clean_prompt(autospark_prompt),\n                \"variables\": [\"goals\", \"instructions\", \"last_task\", \"last_task_result\", \"pending_tasks\"]}\n"}
{"type": "source_file", "path": "autospark/controllers/google_oauth.py", "content": "from fastapi import Depends, Query\nfrom fastapi import APIRouter\nfrom fastapi.responses import RedirectResponse\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom sqlalchemy.orm import sessionmaker\n\nimport autospark\nimport json\nimport requests\nfrom datetime import datetime, timedelta\nfrom autospark.models.db import connect_db\nimport http.client as http_client\nfrom autospark.helper.auth import get_current_user\nfrom autospark.models.tool_config import ToolConfig\nfrom autospark.models.toolkit import Toolkit\nfrom autospark.models.oauth_tokens import OauthTokens\nfrom autospark.config.config import get_config\n\nrouter = APIRouter()\n\n@router.get('/oauth-tokens')\nasync def google_auth_calendar(code: str = Query(...), Authorize: AuthJWT = Depends()):\n    client_id = db.session.query(ToolConfig).filter(ToolConfig.key == \"GOOGLE_CLIENT_ID\").first()\n    client_id = client_id.value\n    client_secret = db.session.query(ToolConfig).filter(ToolConfig.key == \"GOOGLE_CLIENT_SECRET\").first()\n    client_secret = client_secret.value\n    token_uri = 'https://oauth2.googleapis.com/token'\n    scope = 'https://www.googleapis.com/auth/calendar'\n    env = get_config(\"ENV\", \"DEV\")\n    if env == \"DEV\":\n        redirect_uri = \"http://localhost:3000/api/google/oauth-tokens\"\n    else:\n        redirect_uri = \"https://app.superagi.com/api/google/oauth-tokens\"\n    params = {\n        'client_id': client_id,\n        'client_secret': client_secret,\n        'redirect_uri': redirect_uri,\n        'scope': scope,\n        'grant_type': 'authorization_code',\n        'code': code,\n        'access_type': 'offline'\n    }\n    response = requests.post(token_uri, data=params)\n    response = response.json()\n    expire_time = datetime.utcnow() + timedelta(seconds=response['expires_in'])\n    expire_time = expire_time - timedelta(minutes=5)\n    response['expiry'] = expire_time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n    response_data = json.dumps(response)\n    frontend_url = autospark.config.config.get_config(\"FRONTEND_URL\", \"http://localhost:3000\")\n    redirect_url_success = f\"{frontend_url}/google_calendar_creds/?{response_data}\"\n    return RedirectResponse(url=redirect_url_success)\n\n@router.post(\"/send_google_creds/toolkit_id/{toolkit_id}\")\ndef send_google_calendar_configs(google_creds: dict, toolkit_id: int, Authorize: AuthJWT = Depends()):\n    engine = connect_db()\n    Session = sessionmaker(bind=engine)\n    session = Session()\n    current_user = get_current_user()\n    user_id = current_user.id\n    toolkit = db.session.query(Toolkit).filter(Toolkit.id == toolkit_id).first()\n    google_creds = json.dumps(google_creds)\n    print(google_creds)\n    tokens = OauthTokens().add_or_update(session, toolkit_id, user_id, toolkit.organisation_id, \"GOOGLE_CALENDAR_OAUTH_TOKENS\", google_creds)\n    if tokens:\n        success = True\n    else:\n        success = False\n    return success\n\n\n@router.get(\"/get_google_creds/toolkit_id/{toolkit_id}\")\ndef get_google_calendar_tool_configs(toolkit_id: int):\n    google_calendar_config = db.session.query(ToolConfig).filter(ToolConfig.toolkit_id == toolkit_id,\n                                                                 ToolConfig.key == \"GOOGLE_CLIENT_ID\").first()\n    return {\n        \"client_id\": google_calendar_config.value\n    }\n"}
{"type": "source_file", "path": "autospark/__init__.py", "content": ""}
{"type": "source_file", "path": "autospark/controllers/toolkit.py", "content": "from typing import Optional\n\nimport requests\nfrom fastapi import APIRouter, Body\nfrom fastapi import HTTPException, Depends, Query\nfrom fastapi.security import HTTPBearer\nfrom fastapi_sqlalchemy import db\nfrom autospark.config.config import get_config\nfrom autospark.helper.auth import get_user_organisation\nfrom autospark.helper.tool_helper import get_readme_content_from_code_link, download_tool,process_files,add_tool_to_json\nfrom autospark.helper.github_helper import GithubHelper\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.tool import Tool\nfrom autospark.models.toolkit import Toolkit\nfrom autospark.types.common import GitHubLinkRequest\n\nfrom autospark.models.tool_config import ToolConfig\nfrom autospark.helper.tool_helper import compare_toolkit\nfrom autospark.helper.encyption_helper import decrypt_data, is_encrypted\n\nrouter = APIRouter()\n\n\n# marketplace_url = \"https://app.superagi.com/api\"\n# marketplace_url = \"http://localhost:8001/\"\n\n\n#For internal use\n@router.get(\"/marketplace/list/{page}\",dependencies=[Depends(HTTPBearer())])\ndef get_marketplace_toolkits(\n        page: int = 0,\n):\n    \"\"\"\n    Get marketplace tool kits.\n\n    Args:\n        page (int): The page number for pagination.\n\n    Returns:\n        list: A list of tool kits in the marketplace.\n\n    \"\"\"\n\n    organisation_id = int(get_config(\"MARKETPLACE_ORGANISATION_ID\"))\n    page_size = 30\n\n    # Apply search filter if provided\n    query = db.session.query(Toolkit).filter(Toolkit.organisation_id == organisation_id)\n\n    # Paginate the results\n    toolkits = query.offset(page * page_size).limit(page_size).all()\n\n    # Fetch tools for each tool kit\n    for toolkit in toolkits:\n        toolkit.tools = db.session.query(Tool).filter(Tool.toolkit_id == toolkit.id).all()\n        toolkit.updated_at = toolkit.updated_at.strftime('%d-%b-%Y').upper()\n    return toolkits\n\n#For internal use\n@router.get(\"/marketplace/details/{toolkit_name}\",dependencies=[Depends(HTTPBearer())])\ndef get_marketplace_toolkit_detail(toolkit_name: str):\n    \"\"\"\n    Get tool kit details from the marketplace.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n\n    Returns:\n        Toolkit: The tool kit details from the marketplace.\n\n    \"\"\"\n\n    organisation_id = int(get_config(\"MARKETPLACE_ORGANISATION_ID\"))\n    toolkit = db.session.query(Toolkit).filter(Toolkit.organisation_id == organisation_id, Toolkit.name == toolkit_name).first()\n    toolkit.tools = db.session.query(Tool).filter(Tool.toolkit_id == toolkit.id).all()\n    toolkit.configs = db.session.query(ToolConfig).filter(ToolConfig.toolkit_id == toolkit.id).all()\n    for tool_configs in toolkit.configs:\n        if is_encrypted(tool_configs.value):\n            tool_configs.value = decrypt_data(tool_configs.value)\n    return toolkit\n\n#For internal use\n@router.get(\"/marketplace/readme/{toolkit_name}\",dependencies=[Depends(HTTPBearer())])\ndef get_marketplace_toolkit_readme(toolkit_name: str):\n    \"\"\"\n    Get tool kit readme from the marketplace.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n\n    Returns:\n        str: The content of the tool kit's readme file.\n\n    Raises:\n        HTTPException (status_code=404): If the specified tool kit is not found.\n\n    \"\"\"\n\n    organisation_id = int(get_config(\"MARKETPLACE_ORGANISATION_ID\"))\n    toolkit = db.session.query(Toolkit).filter(Toolkit.name == toolkit_name,\n                                               Toolkit.organisation_id == organisation_id).first()\n    if not toolkit:\n        raise HTTPException(status_code=404, detail='ToolKit not found')\n    return get_readme_content_from_code_link(toolkit.tool_code_link)\n\n#For internal use\n@router.get(\"/marketplace/tools/{toolkit_name}\")\ndef get_marketplace_toolkit_tools(toolkit_name: str):\n    \"\"\"\n    Get tools of a specific tool kit from the marketplace.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n\n    Returns:\n        Tool: The tools associated with the tool kit.\n\n    Raises:\n        HTTPException (status_code=404): If the specified tool kit is not found.\n\n    \"\"\"\n\n    organisation_id = int(get_config(\"MARKETPLACE_ORGANISATION_ID\"))\n    toolkit = db.session.query(Toolkit).filter(Toolkit.name == toolkit_name, Toolkit.organisation_id == organisation_id).first()\n    if not toolkit:\n        raise HTTPException(status_code=404, detail=\"ToolKit not found\")\n    tools = db.session.query(Tool).filter(Tool.toolkit_id == toolkit.id).first()\n    return tools\n\n\n@router.get(\"/get/install/{toolkit_name}\",dependencies=[Depends(HTTPBearer())])\ndef install_toolkit_from_marketplace(toolkit_name: str,\n                                     organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Download and install a tool kit from the marketplace.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n        organisation (Organisation): The user's organisation.\n\n    Returns:\n        dict: A message indicating the successful installation of the tool kit.\n\n    \"\"\"\n\n    # Check if the tool kit exists\n    toolkit = Toolkit.fetch_marketplace_detail(search_str=\"details\",\n                                               toolkit_name=toolkit_name)\n    db_toolkit = Toolkit.add_or_update(session=db.session, name=toolkit['name'], description=toolkit['description'],\n                                       tool_code_link=toolkit['tool_code_link'], organisation_id=organisation.id,\n                                       show_toolkit=toolkit['show_toolkit'])\n    for tool in toolkit['tools']:\n        Tool.add_or_update(session=db.session, tool_name=tool['name'], description=tool['description'],\n                           folder_name=tool['folder_name'], class_name=tool['class_name'], file_name=tool['file_name'],\n                           toolkit_id=db_toolkit.id)\n    for config in toolkit['configs']:\n        ToolConfig.add_or_update(session=db.session, toolkit_id=db_toolkit.id, key=config['key'], value=config['value'])\n    return {\"message\": \"ToolKit installed successfully\"}\n\n\n@router.get(\"/get/toolkit_name/{toolkit_name}\",dependencies=[Depends(HTTPBearer())])\ndef get_installed_toolkit_details(toolkit_name: str,\n                                  organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Get details of a locally installed tool kit by its name, including the details of its tools.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n        organisation (Organisation): The user's organisation.\n\n    Returns:\n        Toolkit: The tool kit object with its associated tools.\n\n    Raises:\n        HTTPException (status_code=404): If the specified tool kit is not found.\n\n    \"\"\"\n\n    # Fetch the tool kit by its ID\n    toolkit = db.session.query(Toolkit).filter(Toolkit.name == toolkit_name,\n                                               Organisation.id == organisation.id).first()\n\n    if not toolkit:\n        # Return an appropriate response if the tool kit doesn't exist\n        raise HTTPException(status_code=404, detail='ToolKit not found')\n\n    # Fetch the tools associated with the tool kit\n    tools = db.session.query(Tool).filter(Tool.toolkit_id == toolkit.id).all()\n    # Add the tools to the tool kit object\n    toolkit.tools = tools\n    # readme_content = get_readme(toolkit.tool_code_link)\n    return toolkit\n\n\n@router.post(\"/get/local/install\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef download_and_install_tool(github_link_request: GitHubLinkRequest = Body(...),\n                              organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Install a tool locally from a GitHub link.\n\n    Args:\n        github_link_request (GitHubLinkRequest): The GitHub link request object.\n        organisation (Organisation): The user's organisation.\n\n    Returns:\n        None\n\n    Raises:\n        HTTPException (status_code=400): If the GitHub link is invalid.\n\n    \"\"\"\n    github_link = github_link_request.github_link\n    if not GithubHelper.validate_github_link(github_link):\n        raise HTTPException(status_code=400, detail=\"Invalid Github link\")\n    # download_folder = get_config(\"TOOLS_DIR\")\n    # download_tool(github_link, download_folder)\n    # process_files(download_folder, db.session, organisation, code_link=github_link)\n    add_tool_to_json(github_link)\n\n\n@router.get(\"/get/readme/{toolkit_name}\",dependencies=[Depends(HTTPBearer())])\ndef get_installed_toolkit_readme(toolkit_name: str, organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Get the readme content of a toolkit.\n\n    Args:\n        toolkit_name (str): The name of the toolkit.\n        organisation (Organisation): The user's organisation.\n\n    Returns:\n        str: The readme content of the toolkit.\n\n    Raises:\n        HTTPException (status_code=404): If the toolkit is not found.\n\n    \"\"\"\n\n    toolkit = db.session.query(Toolkit).filter(Toolkit.name == toolkit_name,\n                                               Organisation.id == organisation.id).first()\n    if not toolkit:\n        raise HTTPException(status_code=404, detail='ToolKit not found')\n    readme_content = get_readme_content_from_code_link(toolkit.tool_code_link)\n    return readme_content\n\n# Following APIs will be used to get marketplace related information\n@router.get(\"/get\",dependencies=[Depends(HTTPBearer())])\ndef handle_marketplace_operations(\n        search_str: str = Query(None, title=\"Search String\"),\n        toolkit_name: str = Query(None, title=\"Tool Kit Name\")\n):\n    \"\"\"\n    Handle marketplace operations.\n\n    Args:\n        search_str (str, optional): The search string to filter toolkits. Defaults to None.\n        toolkit_name (str, optional): The name of the toolkit. Defaults to None.\n\n    Returns:\n        dict: The response containing the marketplace details.\n\n    \"\"\"\n    response = Toolkit.fetch_marketplace_detail(search_str, toolkit_name)\n    return response\n\n\n@router.get(\"/get/list\",dependencies=[Depends(HTTPBearer())])\ndef handle_marketplace_operations_list(\n        page: int = Query(None, title=\"Page Number\"),\n        organisation: Organisation = Depends(get_user_organisation)\n):\n    \"\"\"\n    Handle marketplace operation list.\n\n    Args:\n        page (int, optional): The page number for pagination. Defaults to None.\n\n    Returns:\n        dict: The response containing the marketplace list.\n\n    \"\"\"\n\n    marketplace_toolkits = Toolkit.fetch_marketplace_list(page=page)\n    marketplace_toolkits_with_install = Toolkit.get_toolkit_installed_details(db.session, marketplace_toolkits,\n                                                                              organisation)\n    return marketplace_toolkits_with_install\n\n\n@router.get(\"/get/local/list\",dependencies=[Depends(HTTPBearer())])\ndef get_installed_toolkit_list(organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Get the list of installed tool kits.\n\n    Args:\n        organisation (Organisation): The organisation associated with the tool kits.\n\n    Returns:\n        list: The list of installed tool kits.\n\n    \"\"\"\n\n    toolkits = db.session.query(Toolkit).filter(Toolkit.organisation_id == organisation.id).all()\n    for toolkit in toolkits:\n        toolkit_tools = db.session.query(Tool).filter(Tool.toolkit_id == toolkit.id).all()\n        toolkit.tools = toolkit_tools\n\n    return toolkits\n\n\n@router.get(\"/check_update/{toolkit_name}\",dependencies=[Depends(HTTPBearer())])\ndef check_toolkit_update(toolkit_name: str, organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Check if there is an update available for the installed tool kits.\n\n    Returns:\n        dict: The response containing the update details.\n\n    \"\"\"\n    marketplace_toolkit = Toolkit.fetch_marketplace_detail(search_str=\"details\",\n                                                           toolkit_name=toolkit_name)\n    if marketplace_toolkit is None:\n        raise HTTPException(status_code=404, detail=\"Toolkit not found in marketplace\")\n    installed_toolkit = Toolkit.get_toolkit_from_name(db.session, toolkit_name, organisation)\n    if installed_toolkit is None:\n        return True\n    installed_toolkit = installed_toolkit.to_dict()\n    tools = Tool.get_toolkit_tools(db.session, installed_toolkit[\"id\"])\n    configs = ToolConfig.get_toolkit_tool_config(db.session, installed_toolkit[\"id\"])\n    installed_toolkit[\"configs\"] = []\n    installed_toolkit[\"tools\"] = []\n\n    for config in configs:\n        installed_toolkit[\"configs\"].append(config.to_dict())\n    for tool in tools:\n        installed_toolkit[\"tools\"].append(tool.to_dict())\n\n    return compare_toolkit(marketplace_toolkit, installed_toolkit)\n\n\n@router.put(\"/update/{toolkit_name}\",dependencies=[Depends(HTTPBearer())])\ndef update_toolkit(toolkit_name: str, organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n        Update the toolkit with the latest version from the marketplace.\n    \"\"\"\n    marketplace_toolkit = Toolkit.fetch_marketplace_detail(search_str=\"details\",\n                                                           toolkit_name=toolkit_name)\n\n    update_toolkit = Toolkit.add_or_update(\n        db.session,\n        name=marketplace_toolkit[\"name\"],\n        description=marketplace_toolkit[\"description\"],\n        show_toolkit=True if len(marketplace_toolkit[\"tools\"]) > 1 else False,\n        organisation_id=organisation.id,\n        tool_code_link=marketplace_toolkit[\"tool_code_link\"]\n    )\n\n    for tool in marketplace_toolkit[\"tools\"]:\n        Tool.add_or_update(db.session, tool_name=tool[\"name\"], folder_name=tool[\"folder_name\"],\n                           class_name=tool[\"class_name\"], file_name=tool[\"file_name\"],\n                           toolkit_id=update_toolkit.id, description=tool[\"description\"])\n\n    for tool_config_key in marketplace_toolkit[\"configs\"]:\n        ToolConfig.add_or_update(db.session, toolkit_id=update_toolkit.id,\n                                 key=tool_config_key[\"key\"])\n"}
{"type": "source_file", "path": "autospark/controllers/agent_config.py", "content": "from typing import Union, List\n\nfrom fastapi import APIRouter\nfrom fastapi import HTTPException, Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom pydantic import BaseModel\n\nfrom autospark.helper.auth import check_auth\nfrom autospark.models.agent import Agent\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.types.agent_config import AgentConfig\n# from autospark.types.db import AgentConfigurationIn, AgentConfigurationOut\nfrom datetime import datetime\n\n\nrouter = APIRouter()\n\n\nclass AgentConfigurationOut(BaseModel):\n    id: int\n    agent_id: int\n    key: str\n    value: str\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass AgentConfigurationIn(BaseModel):\n    agent_id: int\n    key: str\n    value: Union[str, List[str]]\n\n    class Config:\n        orm_mode = True\n\n\n# CRUD Operations\n@router.post(\"/add\", dependencies=[Depends(HTTPBearer())],response_model=AgentConfigurationOut, status_code=201)\ndef create_agent_config(agent_config: AgentConfigurationIn,\n                        Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new agent configuration by setting a new key and value related to the agent.\n\n    Args:\n        agent_config (AgentConfiguration): The agent configuration data.\n\n    Returns:\n        AgentConfiguration: The created agent configuration.\n\n    Raises:\n        HTTPException (Status Code=404): If the associated agent is not found or deleted.\n    \"\"\"\n\n    agent = db.session.query(Agent).filter(Agent.id == agent_config.agent_id, Agent.is_deleted == False).first()\n\n    if not agent:\n        raise HTTPException(status_code=404, detail=\"Agent not found\")\n\n    db_agent_config = AgentConfiguration(agent_id=agent_config.agent_id, key=agent_config.key, value=agent_config.value)\n    db.session.add(db_agent_config)\n    db.session.commit()\n    return db_agent_config\n\n\n@router.get(\"/get/{agent_config_id}\", response_model=AgentConfigurationOut)\ndef get_agent(agent_config_id: int,\n              Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get a particular agent configuration by agent_config_id.\n\n    Args:\n        agent_config_id (int): The identifier of the agent configuration.\n\n    Returns:\n        AgentConfiguration: The retrieved agent configuration.\n\n    Raises:\n        HTTPException (Status Code=404): If the agent configuration is not found.\n    \"\"\"\n\n    if (\n        db_agent_config := db.session.query(AgentConfiguration)\n        .filter(AgentConfiguration.id == agent_config_id)\n        .first()\n    ):\n        return db_agent_config\n    else:\n        raise HTTPException(status_code=404, detail=\"Agent Configuration not found\")\n\n\n@router.put(\"/update\",dependencies=[Depends(HTTPBearer())], response_model=AgentConfigurationOut)\ndef update_agent(agent_config: AgentConfigurationIn,\n                 Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n        Update a particular agent configuration value for the given agent_id and agent_config key.\n\n        Args:\n            agent_config (AgentConfig): The updated agent configuration data.\n\n        Returns:\n            AgentConfiguration: The updated agent configuration.\n\n        Raises:\n            HTTPException (Status Code=404): If the agent configuration is not found.\n    \"\"\"\n\n    db_agent_config = db.session.query(AgentConfiguration).filter(AgentConfiguration.key == agent_config.key,\n                                                                  AgentConfiguration.agent_id == agent_config.agent_id).first()\n    if not db_agent_config:\n        raise HTTPException(status_code=404, detail=\"Agent Configuration not found\")\n\n    db_agent_config.key = agent_config.key\n    if isinstance(agent_config.value, list):\n        # Convert the list to a string using the str() function\n        db_agent_config.value = str(agent_config.value)\n    else:\n        db_agent_config.value = agent_config.value\n    db.session.commit()\n    db.session.flush()\n    return db_agent_config\n\n\n@router.get(\"/get/agent/{agent_id}\",dependencies=[Depends(HTTPBearer())],)\ndef get_agent_configurations(agent_id: int,\n                             Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get all agent configurations for a given agent_id.\n\n    Args:\n        agent_id (int): The identifier of the agent.\n\n    Returns:\n        dict: The parsed response containing agent configurations.\n\n    Raises:\n        HTTPException (Status Code=404): If the agent or agent configurations are not found or deleted.\n    \"\"\"\n\n    agent = db.session.query(Agent).filter(Agent.id == agent_id, Agent.is_deleted == False).first()\n    if not agent:\n        raise HTTPException(status_code=404, detail=\"agent not found\")\n\n    agent_configurations = db.session.query(AgentConfiguration).filter_by(agent_id=agent_id).all()\n    if not agent_configurations:\n        raise HTTPException(status_code=404, detail=\"Agent configurations not found\")\n\n    parsed_response = {\n        \"agent_id\": agent_id,\n        \"name\": agent.name,\n        \"project_id\": agent.project_id,\n        \"description\": agent.description,\n        \"goal\": [],\n        \"instruction\": [],\n        \"agent_type\": None,\n        \"constraints\": None,\n        \"tools\": [],\n        \"exit\": None,\n        \"iteration_interval\": None,\n        \"model\": None,\n        \"permission_type\": None,\n        \"LTM_DB\": None,\n    }\n\n    for item in agent_configurations:\n        key = item.key\n        value = item.value\n\n        if key == \"name\":\n            parsed_response[\"name\"] = value\n        elif key == \"project_id\":\n            parsed_response[\"project_id\"] = int(value)\n        elif key == \"description\":\n            parsed_response[\"description\"] = value\n        elif key == \"goal\":\n            parsed_response[\"goal\"] = eval(value)  # Using eval to parse the list of strings\n        elif key == \"instruction\":\n            parsed_response[\"instruction\"] = eval(value)\n        elif key == \"agent_type\":\n            parsed_response[\"agent_type\"] = value\n        elif key == \"constraints\":\n            parsed_response[\"constraints\"] = eval(value)  # Using eval to parse the list of strings\n        elif key == \"tools\":\n            parsed_response[\"tools\"] = eval(value)  # Using eval to parse the list of strings\n        elif key == \"exit\":\n            parsed_response[\"exit\"] = value\n        elif key == \"iteration_interval\":\n            parsed_response[\"iteration_interval\"] = int(value)\n        elif key == \"model\":\n            parsed_response[\"model\"] = value\n        elif key == \"permission_type\":\n            parsed_response[\"permission_type\"] = value\n        elif key == \"LTM_DB\":\n            parsed_response[\"LTM_DB\"] = value\n\n    return parsed_response\n"}
{"type": "source_file", "path": "autospark/controllers/agent.py", "content": "import json\nfrom datetime import datetime\n\nfrom fastapi import APIRouter\nfrom fastapi import HTTPException, Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom pydantic import BaseModel\n\nfrom jsonmerge import merge\nfrom pytz import timezone\nfrom sqlalchemy import func, or_\nfrom autospark.models.agent_execution_permission import AgentExecutionPermission\nfrom autospark.models.workflows.iteration_workflow import IterationWorkflow\nfrom autospark.worker import execute_agent\nfrom autospark.helper.auth import check_auth\nfrom autospark.models.agent import Agent\nfrom autospark.models.agent_execution_config import AgentExecutionConfiguration\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.agent_schedule import AgentSchedule\nfrom autospark.models.agent_template import AgentTemplate\nfrom autospark.models.project import Project\nfrom autospark.models.workflows.agent_workflow import AgentWorkflow\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.tool import Tool\nfrom autospark.lib.logger import logger\nfrom autospark.controllers.types.agent_schedule import AgentScheduleInput\nfrom autospark.controllers.types.agent_with_config import AgentConfigInput\nfrom autospark.controllers.types.agent_with_config_schedule import AgentConfigSchedule\nfrom jsonmerge import merge\nfrom datetime import datetime\nimport json\n\nfrom autospark.models.toolkit import Toolkit\n\nfrom sqlalchemy import func\n# from autospark.types.db import AgentOut, AgentIn\nfrom autospark.helper.auth import check_auth, get_user_organisation\nfrom autospark.apm.event_handler import EventHandler\n\nrouter = APIRouter()\n\n\nclass AgentOut(BaseModel):\n    id: int\n    name: str\n    project_id: int\n    description: str\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass AgentIn(BaseModel):\n    name: str\n    project_id: int\n    description: str\n\n    class Config:\n        orm_mode = True\n\n\n# CRUD Operations\n@router.post(\"/add\", response_model=AgentOut, dependencies=[Depends(HTTPBearer())],status_code=201)\ndef create_agent(agent: AgentIn,\n                 Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n        Creates a new Agent\n\n        Args:\n            agent (Agent): An object representing the Agent to be created.\n                Contains the following attributes:\n                - name (str): Name of the Agent\n                - project_id (int): Identifier of the associated project\n                - description (str): Description of the Agent\n                - agent_workflow_id (int): Identifier of the Agent Workflow in use\n\n        Returns:\n            Agent: An object of Agent representing the created Agent.\n\n        Raises:\n            HTTPException (Status Code=404): If the associated project is not found.\n    \"\"\"\n\n    project = db.session.query(Project).get(agent.project_id)\n\n    if not project:\n        raise HTTPException(status_code=404, detail=\"Project not found\")\n\n    db_agent = Agent(name=agent.name, description=agent.description, project_id=agent.project_id)\n    db.session.add(db_agent)\n    db.session.commit()\n    return db_agent\n\n\n@router.get(\"/get/{agent_id}\",dependencies=[Depends(HTTPBearer())], response_model=AgentOut)\ndef get_agent(agent_id: int,\n              Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n        Get an Agent by ID\n\n        Args:\n            agent_id (int): Identifier of the Agent to retrieve\n\n        Returns:\n            Agent: An object of Agent representing the retrieved Agent.\n\n        Raises:\n            HTTPException (Status Code=404): If the Agent is not found.\n    \"\"\"\n\n    if (db_agent := db.session.query(Agent)\n            .filter(Agent.id == agent_id, or_(Agent.is_deleted == False, Agent.is_deleted is None))\n            .first()):\n        return db_agent\n    else:\n        raise HTTPException(status_code=404, detail=\"agent not found\")\n\n\n@router.put(\"/update/{agent_id}\", dependencies=[Depends(HTTPBearer())],response_model=AgentOut)\ndef update_agent(agent_id: int, agent: AgentIn,\n                 Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n        Update an existing Agent\n\n        Args:\n            agent_id (int): Identifier of the Agent to update\n            agent (Agent):  Updated Agent data\n                Contains the following attributes:\n                - name (str): Name of the Agent\n                - project_id (int): Identifier of the associated project\n                - description (str): Description of the Agent\n                - agent_workflow_id (int): Identifier of the Agent Workflow in use\n\n        Returns:\n            Agent: An object of Agent representing the updated Agent.\n\n        Raises:\n            HTTPException (Status Code=404): If the Agent or associated Project is not found.\n    \"\"\"\n\n    db_agent = db.session.query(Agent).filter(Agent.id == agent_id, or_(Agent.is_deleted == False, Agent.is_deleted is None)).first()\n    if not db_agent:\n        raise HTTPException(status_code=404, detail=\"agent not found\")\n\n    if agent.project_id:\n        if project := db.session.query(Project).get(agent.project_id):\n            db_agent.project_id = project.id\n        else:\n            raise HTTPException(status_code=404, detail=\"Project not found\")\n    db_agent.name = agent.name\n    db_agent.description = agent.description\n\n    db.session.commit()\n    return db_agent\n\n\n@router.post(\"/create\", dependencies=[Depends(HTTPBearer())],status_code=201)\ndef create_agent_with_config(agent_with_config: AgentConfigInput,\n                             Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new agent with configurations.\n\n    Args:\n        agent_with_config (AgentConfigInput): Data for creating a new agent with configurations.\n            - name (str): Name of the agent.\n            - project_id (int): Identifier of the associated project.\n            - description (str): Description of the agent.\n            - goal (List[str]): List of goals for the agent.\n            - agent_workflow (str): Type of the agent.\n            - constraints (List[str]): List of constraints for the agent.\n            - tools (List[int]): List of tool identifiers associated with the agent.\n            - exit (str): Exit condition for the agent.\n            - iteration_interval (int): Interval between iterations for the agent.\n            - model (str): Model information for the agent.\n            - permission_type (str): Permission type for the agent.\n            - LTM_DB (str): LTM database for the agent.\n            - max_iterations (int): Maximum number of iterations for the agent.\n            - user_timezone (string): Timezone of the user\n\n    Returns:\n        dict: Dictionary containing the created agent's ID, execution ID, name, and content type.\n\n    Raises:\n        HTTPException (status_code=404): If the associated project or any of the tools is not found.\n    \"\"\"\n\n    project = db.session.query(Project).get(agent_with_config.project_id)\n    if not project:\n        raise HTTPException(status_code=404, detail=\"Project not found\")\n\n    invalid_tools = Tool.get_invalid_tools(agent_with_config.tools, db.session)\n    if len(invalid_tools) > 0:  # If the returned value is not True (then it is an invalid tool_id)\n        raise HTTPException(status_code=404,\n                            detail=f\"Tool with IDs {str(invalid_tools)} does not exist. 404 Not Found.\")\n\n    agent_toolkit_tools = Toolkit.fetch_tool_ids_from_toolkit(session=db.session,\n                                                              toolkit_ids=agent_with_config.toolkits)\n    agent_with_config.tools.extend(agent_toolkit_tools)\n    db_agent = Agent.create_agent_with_config(db, agent_with_config)\n\n    start_step = AgentWorkflow.fetch_trigger_step_id(db.session, db_agent.agent_workflow_id)\n    iteration_step_id = IterationWorkflow.fetch_trigger_step_id(db.session,\n                                                                start_step.action_reference_id).id if start_step.action_type == \"ITERATION_WORKFLOW\" else -1\n\n    # Creating an execution with RUNNING status\n    execution = AgentExecution(status='CREATED', last_execution_time=datetime.now(), agent_id=db_agent.id,\n                               name=\"New Run\", current_agent_step_id=start_step.id,iteration_workflow_step_id=iteration_step_id)\n\n    agent_execution_configs = {\n        \"goal\": agent_with_config.goal,\n        \"instruction\": agent_with_config.instruction,\n        \"constraints\": agent_with_config.constraints,\n        \"toolkits\": agent_with_config.toolkits,\n        \"exit\": agent_with_config.exit,\n        \"tools\": agent_with_config.tools,\n        \"iteration_interval\": agent_with_config.iteration_interval,\n        \"model\": agent_with_config.model,\n        \"permission_type\": agent_with_config.permission_type,\n        \"LTM_DB\": agent_with_config.LTM_DB,\n        \"max_iterations\": agent_with_config.max_iterations,\n        \"user_timezone\": agent_with_config.user_timezone,\n    }\n    db.session.add(execution)\n    db.session.commit()\n    db.session.flush()\n    AgentExecutionConfiguration.add_or_update_agent_execution_config(session=db.session, execution=execution,\n                                                                     agent_execution_configs=agent_execution_configs)\n\n    agent = db.session.query(Agent).filter(Agent.id == db_agent.id, ).first()\n    organisation = agent.get_agent_organisation(db.session)\n    EventHandler(session=db.session).create_event('run_created', {'agent_execution_id': execution.id,\n                                                                  'agent_execution_name': execution.name}, db_agent.id,\n                                                  organisation.id if organisation else 0),\n    EventHandler(session=db.session).create_event('agent_created', {'agent_name': agent_with_config.name,\n                                                                    'model': agent_with_config.model}, db_agent.id,\n                                                  organisation.id if organisation else 0)\n\n    # execute_agent.delay(execution.id, datetime.now())\n\n    db.session.commit()\n\n    return {\n        \"id\": db_agent.id,\n        \"execution_id\": execution.id,\n        \"name\": db_agent.name,\n        \"contentType\": \"Agents\"\n    }\n\n@router.post(\"/schedule\", dependencies=[Depends(HTTPBearer())],status_code=201)\ndef create_and_schedule_agent(agent_config_schedule: AgentConfigSchedule,\n                              Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new agent with configurations and scheduling.\n\n    Args:\n        agent_with_config_schedule (AgentConfigSchedule): Data for creating a new agent with configurations and scheduling.\n\n    Returns:\n        dict: Dictionary containing the created agent's ID, name, content type and schedule ID of the agent.\n\n    Raises:\n        HTTPException (status_code=500): If the associated agent fails to get scheduled.\n    \"\"\"\n\n    project = db.session.query(Project).get(agent_config_schedule.agent_config.project_id)\n    if not project:\n        raise HTTPException(status_code=404, detail=\"Project not found\")\n    agent_config = agent_config_schedule.agent_config\n    invalid_tools = Tool.get_invalid_tools(agent_config.tools, db.session)\n    if len(invalid_tools) > 0:  # If the returned value is not True (then it is an invalid tool_id)\n        raise HTTPException(status_code=404,\n                            detail=f\"Tool with IDs {str(invalid_tools)} does not exist. 404 Not Found.\")\n\n    agent_toolkit_tools = Toolkit.fetch_tool_ids_from_toolkit(session=db.session,\n                                                              toolkit_ids=agent_config.toolkits)\n    agent_config.tools.extend(agent_toolkit_tools)\n    db_agent = Agent.create_agent_with_config(db, agent_config)\n\n    # Update the agent_id of schedule before scheduling the agent\n    agent_schedule = agent_config_schedule.schedule\n\n    # Create a new agent schedule\n    agent_schedule = AgentSchedule(\n        agent_id=db_agent.id,\n        start_time=agent_schedule.start_time,\n        next_scheduled_time=agent_schedule.start_time,\n        recurrence_interval=agent_schedule.recurrence_interval,\n        expiry_date=agent_schedule.expiry_date,\n        expiry_runs=agent_schedule.expiry_runs,\n        current_runs=0,\n        status=\"SCHEDULED\"\n    )\n\n    agent_schedule.agent_id = db_agent.id\n    db.session.add(agent_schedule)\n    db.session.commit()\n\n    if agent_schedule.id is None:\n        raise HTTPException(status_code=500, detail=\"Failed to schedule agent\")\n\n    return {\n        \"id\": db_agent.id,\n        \"name\": db_agent.name,\n        \"contentType\": \"Agents\",\n        \"schedule_id\": agent_schedule.id\n    }\n\n@router.post(\"/stop/schedule\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef stop_schedule(agent_id: int, Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Stopping the scheduling for a given agent.\n\n    Args:\n        agent_id (int): Identifier of the Agent\n        Authorize (AuthJWT, optional): Authorization dependency. Defaults to Depends(check_auth).\n\n    Raises:\n        HTTPException (status_code=404): If the agent schedule is not found.\n    \"\"\"\n\n    agent_to_delete = db.session.query(AgentSchedule).filter(AgentSchedule.agent_id == agent_id,\n                                                             AgentSchedule.status == \"SCHEDULED\").first()\n    if not agent_to_delete:\n        raise HTTPException(status_code=404, detail=\"Schedule not found\")\n    agent_to_delete.status = \"STOPPED\"\n    db.session.commit()\n\n\n@router.put(\"/edit/schedule\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef edit_schedule(schedule: AgentScheduleInput,\n                  Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Edit the scheduling for a given agent.\n\n    Args:\n        agent_id (int): Identifier of the Agent\n        schedule (AgentSchedule): New schedule data\n        Authorize (AuthJWT, optional): Authorization dependency. Defaults to Depends(check_auth).\n\n    Raises:\n        HTTPException (status_code=404): If the agent schedule is not found.\n    \"\"\"\n\n    agent_to_edit = db.session.query(AgentSchedule).filter(AgentSchedule.agent_id == schedule.agent_id,\n                                                           AgentSchedule.status == \"SCHEDULED\").first()\n    if not agent_to_edit:\n        raise HTTPException(status_code=404, detail=\"Schedule not found\")\n\n    # Update agent schedule with new data\n    agent_to_edit.start_time = schedule.start_time\n    agent_to_edit.next_scheduled_time = schedule.start_time\n    agent_to_edit.recurrence_interval = schedule.recurrence_interval\n    agent_to_edit.expiry_date = schedule.expiry_date\n    agent_to_edit.expiry_runs = schedule.expiry_runs\n\n    db.session.commit()\n\n\n@router.get(\"/get/schedule_data/{agent_id}\",dependencies=[Depends(HTTPBearer())])\ndef get_schedule_data(agent_id: int, Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get the scheduling data for a given agent.\n\n    Args:\n        agent_id (int): Identifier of the Agent\n\n    Raises:\n        HTTPException (status_code=404): If the agent schedule is not found.\n\n    Returns:\n        current_datetime (DateTime): Current Date and Time.\n        recurrence_interval (String): Time interval for recurring schedule run.\n        expiry_date (DateTime): The date and time when the agent is scheduled to stop runs.\n        expiry_runs (Integer): The number of runs before the agent expires.\n    \"\"\"\n    agent = db.session.query(AgentSchedule).filter(AgentSchedule.agent_id == agent_id,\n                                                   AgentSchedule.status == \"SCHEDULED\").first()\n\n    if not agent:\n        raise HTTPException(status_code=404, detail=\"Agent Schedule not found\")\n\n    user_timezone = db.session.query(AgentConfiguration).filter(AgentConfiguration.key == \"user_timezone\",\n                                                                AgentConfiguration.agent_id == agent_id).first()\n\n    if user_timezone and user_timezone.value != \"None\":\n        tzone = timezone(user_timezone.value)\n    else:\n        tzone = timezone('GMT')\n\n    current_datetime = datetime.now(tzone).strftime(\"%d/%m/%Y %I:%M %p\")\n\n    return {\n        \"current_datetime\": current_datetime,\n        \"start_date\": agent.start_time.astimezone(tzone).strftime(\"%d %b %Y\"),\n        \"start_time\": agent.start_time.astimezone(tzone).strftime(\"%I:%M %p\"),\n        \"recurrence_interval\": agent.recurrence_interval if agent.recurrence_interval else None,\n        \"expiry_date\": agent.expiry_date.astimezone(tzone).strftime(\"%d/%m/%Y\") if agent.expiry_date else None,\n        \"expiry_runs\": agent.expiry_runs if agent.expiry_runs != -1 else None\n    }\n\n\n@router.get(\"/get/project/{project_id}\",dependencies=[Depends(HTTPBearer())])\ndef get_agents_by_project_id(project_id: int,\n                             Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get all agents by project ID.\n\n    Args:\n        project_id (int): Identifier of the project.\n        Authorize (AuthJWT, optional): Authorization dependency. Defaults to Depends(check_auth).\n\n    Returns:\n        list: List of agents associated with the project, including their status and scheduling information.\n\n    Raises:\n        HTTPException (status_code=404): If the project is not found.\n    \"\"\"\n\n    # Checking for project\n    project = db.session.query(Project).get(project_id)\n    if not project:\n        raise HTTPException(status_code=404, detail=\"Project not found\")\n\n    agents = db.session.query(Agent).filter(Agent.project_id == project_id, or_(Agent.is_deleted == False, Agent.is_deleted is None)).all()\n\n    new_agents, new_agents_sorted = [], []\n    for agent in agents:\n        agent_dict = vars(agent)\n        agent_id = agent.id\n\n        # Query the AgentExecution table using the agent ID\n        executions = db.session.query(AgentExecution).filter_by(agent_id=agent_id).all()\n        is_running = False\n        for execution in executions:\n            if execution.status == \"RUNNING\":\n                is_running = True\n                break\n        # Check if the agent is scheduled\n        is_scheduled = db.session.query(AgentSchedule).filter_by(agent_id=agent_id,\n                                                                 status=\"SCHEDULED\").first() is not None\n\n        new_agent = {\n            **agent_dict,\n            'is_running': is_running,\n            'is_scheduled': is_scheduled\n        }\n        new_agents.append(new_agent)\n        new_agents_sorted = sorted(new_agents, key=lambda agent: agent['is_running'] == True, reverse=True)\n    return new_agents_sorted\n\n\n@router.get(\"/get/details/{agent_id}\",dependencies=[Depends(HTTPBearer())])\ndef get_agent_configuration(agent_id: int,\n                            Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get the agent configuration using the agent ID.\n\n    Args:\n        agent_id (int): Identifier of the agent.\n        Authorize (AuthJWT, optional): Authorization dependency. Defaults to Depends(check_auth).\n\n    Returns:\n        dict: Agent configuration including its details.\n\n    Raises:\n        HTTPException (status_code=404): If the agent is not found or deleted.\n    \"\"\"\n\n    # Define the agent_config keys to fetch\n    keys_to_fetch = AgentTemplate.main_keys()\n    agent = db.session.query(Agent).filter(agent_id == Agent.id,or_(Agent.is_deleted == False, Agent.is_deleted is None)).first()\n\n    if not agent:\n        raise HTTPException(status_code=404, detail=\"Agent not found\")\n\n    # Query the AgentConfiguration table for the specified keys\n    results = db.session.query(AgentConfiguration).filter(AgentConfiguration.key.in_(keys_to_fetch),\n                                                          AgentConfiguration.agent_id == agent_id).all()\n    total_calls = db.session.query(func.sum(AgentExecution.num_of_calls)).filter(\n        AgentExecution.agent_id == agent_id).scalar()\n    total_tokens = db.session.query(func.sum(AgentExecution.num_of_tokens)).filter(\n        AgentExecution.agent_id == agent_id).scalar()\n\n    # Construct the JSON response\n    response = {result.key: result.value for result in results}\n    logger.info(str(response))\n    response = merge(response, {\"name\": agent.name, \"description\": agent.description,\n                                # Query the AgentConfiguration table for the speci\n                                \"goal\": eval(response[\"goal\"]),\n                                \"instruction\": eval(response.get(\"instruction\", '[]')),\n                                \"calls\": total_calls,\n                                \"tokens\": total_tokens,\n                                \"constraints\": eval(response.get(\"constraints\")),\n                                \"tools\": [int(x) for x in json.loads(response[\"tools\"])]})\n    tools = db.session.query(Tool).filter(Tool.id.in_(response[\"tools\"])).all()\n    response[\"tools\"] = tools\n\n    # Close the session\n    db.session.close()\n\n    return response\n\n\n@router.put(\"/delete/{agent_id}\",dependencies=[Depends(HTTPBearer())], status_code=200)\ndef delete_agent(agent_id: int, Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n        Delete an existing Agent\n            - Updates the is_deleted flag: Executes a soft delete\n            - AgentExecutions are updated to: \"TERMINATED\" if agentexecution is created, All the agent executions are updated\n            - AgentExecutionPermission is set to: \"REJECTED\" if agentexecutionpersmision is created\n\n        Args:\n            agent_id (int): Identifier of the Agent to delete\n\n        Returns:\n            A dictionary containing a \"success\" key with the value True to indicate a successful delete.\n\n        Raises:\n            HTTPException (Status Code=404): If the Agent or associated Project is not found or deleted already.\n    \"\"\"\n\n    db_agent = db.session.query(Agent).filter(Agent.id == agent_id).first()\n    db_agent_executions = db.session.query(AgentExecution).filter(AgentExecution.agent_id == agent_id).all()\n\n    if not db_agent or db_agent.is_deleted:\n        raise HTTPException(status_code=404, detail=\"agent not found\")\n\n    # Deletion Procedure\n    db_agent.is_deleted = True\n    if db_agent_executions:\n        # Updating all the RUNNING executions to TERMINATED\n        for db_agent_execution in db_agent_executions:\n            db_agent_execution.status = \"TERMINATED\"\n\n    db.session.commit()\n"}
{"type": "source_file", "path": "autospark/controllers/project.py", "content": "from fastapi.security import HTTPBearer\nfrom fastapi_sqlalchemy import db\nfrom fastapi import HTTPException, Depends\nfrom fastapi_jwt_auth import AuthJWT\nfrom pydantic import BaseModel\n\nfrom autospark.models.project import Project\nfrom autospark.models.organisation import Organisation\nfrom fastapi import APIRouter\nfrom autospark.helper.auth import check_auth\nfrom autospark.lib.logger import logger\n# from autospark.types.db import ProjectIn, ProjectOut\n\nrouter = APIRouter()\n\n\nclass ProjectOut(BaseModel):\n    id: int\n    name: str\n    organisation_id: int\n    description: str\n\n    class Config:\n        orm_mode = True\n\n\nclass ProjectIn(BaseModel):\n    name: str\n    organisation_id: int\n    description: str\n\n    class Config:\n        orm_mode = True\n\n# CRUD Operations\n@router.post(\"/add\", dependencies=[Depends(HTTPBearer())],response_model=ProjectOut, status_code=201)\ndef create_project(project: ProjectIn,\n                   Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new project.\n\n    Args:\n        project (Project): Project data.\n\n    Returns:\n        dict: Dictionary containing the created project.\n\n    Raises:\n        HTTPException (status_code=404): If the organization with the specified ID is not found.\n\n    \"\"\"\n\n    logger.info(\"Organisation_id : \", project.organisation_id)\n    organisation = db.session.query(Organisation).get(project.organisation_id)\n\n    if not organisation:\n        raise HTTPException(status_code=404, detail=\"Organisation not found\")\n\n    project = Project(\n        name=project.name,\n        organisation_id=organisation.id,\n        description=project.description\n    )\n\n    db.session.add(project)\n    db.session.commit()\n\n    return project\n\n\n@router.get(\"/get/{project_id}\", dependencies=[Depends(HTTPBearer())],response_model=ProjectOut)\ndef get_project(project_id: int, Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get project details by project_id.\n\n    Args:\n        project_id (int): ID of the project.\n\n    Returns:\n        dict: Dictionary containing the project details.\n\n    Raises:\n        HTTPException (status_code=404): If the project with the specified ID is not found.\n\n    \"\"\"\n\n    db_project = db.session.query(Project).filter(Project.id == project_id).first()\n    if not db_project:\n        raise HTTPException(status_code=404, detail=\"project not found\")\n    return db_project\n\n\n@router.put(\"/update/{project_id}\", dependencies=[Depends(HTTPBearer())], response_model=ProjectOut)\ndef update_project(project_id: int, project: ProjectIn,\n                   Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Update a project detail by project_id.\n\n    Args:\n        project_id (int): ID of the project.\n        project (Project): Updated project data.\n\n    Returns:\n        dict: Dictionary containing the updated project details.\n\n    Raises:\n        HTTPException (status_code=404): If the project with the specified ID is not found.\n        HTTPException (status_code=404): If the organization with the specified ID is not found.\n\n    \"\"\"\n\n    db_project = db.session.query(Project).get(project_id)\n    if not db_project:\n        raise HTTPException(status_code=404, detail=\"Project not found\")\n\n    if project.organisation_id:\n        organisation = db.session.query(Organisation).get(project.organisation_id)\n        if not organisation:\n            raise HTTPException(status_code=404, detail=\"Organisation not found\")\n        db_project.organisation_id = organisation.id\n    db_project.name = project.name\n    db_project.description = project.description\n    db.session.add(db_project)\n    db.session.commit()\n    return db_project\n\n\n@router.get(\"/get/organisation/{organisation_id}\",dependencies=[Depends(HTTPBearer())])\ndef get_projects_organisation(organisation_id: int,\n                              Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get all projects by organisation_id and create default if no project.\n\n    Args:\n        organisation_id (int): ID of the organisation.\n\n    Returns:\n        List[Project]: List of projects belonging to the organisation.\n\n    Raises:\n        HTTPException (status_code=404): If the organization with the specified ID is not found.\n\n    \"\"\"\n\n    Project.find_or_create_default_project(db.session, organisation_id)\n    projects = db.session.query(Project).filter(Project.organisation_id == organisation_id).all()\n    if len(projects) <= 0:\n        default_project = Project.find_or_create_default_project(db.session, organisation_id)\n        projects.append(default_project)\n\n    return projects\n"}
{"type": "source_file", "path": "autospark/controllers/agent_workflow.py", "content": "from fastapi import APIRouter, HTTPException\nfrom fastapi import Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_sqlalchemy import db\nfrom datetime import datetime\n\nfrom autospark.helper.auth import get_user_organisation, get_current_user\nfrom autospark.models.workflows.agent_workflow import AgentWorkflow\nfrom sqlalchemy import or_, and_\nfrom pydantic import BaseModel\n\nrouter = APIRouter()\n\n\nclass AgentWorkflowOut(BaseModel):\n    id: int\n    organisation_id: int\n    user_id: int\n    name: str\n    description: str\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass AgentWorkflowIn(BaseModel):\n    organisation_id: int\n    user_id: int\n    name: str\n    description: str\n    marketplace_template_id: int\n\n    class Config:\n        orm_mode = True\n\n\n@router.get(\"/list\", dependencies=[Depends(HTTPBearer())],status_code=201)\ndef list_workflows(organisation=Depends(get_user_organisation), user=Depends(get_current_user)):\n    \"\"\"\n    Lists agent workflows.\n\n    Args:\n        organisation: User's organisation.\n        user: Current User.\n    Returns:\n        list: A list of dictionaries representing the agent workflows.\n\n    \"\"\"\n    workflows = db.session.query(AgentWorkflow).filter(\n        or_(AgentWorkflow.user_id == \"system\", AgentWorkflow.user_id == user.id, )).all()\n\n    output_json = []\n    for workflow in workflows:\n        output_json.append(workflow.to_dict())\n    return output_json\n\n\n@router.post(\"/create\", status_code=201,dependencies=[Depends(HTTPBearer())], response_model=AgentWorkflowOut)\ndef create_workflow(workflow_template: AgentWorkflowIn, user=Depends(get_current_user)):\n    \"\"\"\n\n    Args:\n        user:\n\n    Returns:\n\n    \"\"\"\n    wf = AgentWorkflow(user_id=user.id,\n                       name=workflow_template.name,\n                       organisation_id=workflow_template.organisation_id,\n                       description=workflow_template.description)\n    db.session.add(wf)\n    db.session.commit()\n\n    return wf\n\n\n@router.put(\"/update/{workflow_id}\", dependencies=[Depends(HTTPBearer())],status_code=201, response_model=AgentWorkflowOut)\ndef update_workflow(workflow_id: int, workflow_template: AgentWorkflowIn, user=Depends(get_current_user)):\n    \"\"\"\n\n    Args:\n        user:\n\n    Returns:\n\n    \"\"\"\n    workflow = db.session.query(AgentWorkflow).filter(\n        and_(AgentWorkflow.id == workflow_id, AgentWorkflow.user_id == user.id)).first()\n    if not workflow:\n        raise HTTPException(status_code=404, detail=\"WorkflowStep ot found\")\n    if workflow_template.organisation_id:\n        workflow.organisation_id = workflow_template.organisation_id\n    if workflow_template.name:\n        workflow.name = workflow_template.name\n    if workflow_template.description:\n        workflow.description = workflow_template.description\n\n    db.session.add(workflow)\n    db.session.commit()\n    return workflow\n\n\n@router.delete(\"/{workflow_id}\",dependencies=[Depends(HTTPBearer())], status_code=201)\ndef delete_workflow(workflow_id: int, user=Depends(get_current_user)):\n    \"\"\"\n\n    Args:\n        user:\n\n    Returns:\n\n    \"\"\"\n    workflow = db.session.query(AgentWorkflow).filter(\n        and_(AgentWorkflow.id == workflow_id,AgentWorkflow.user_id== user.id)).first()\n    if not workflow:\n        raise HTTPException(status_code=404, detail=\"Workflow not found\")\n    if workflow.user_id != user.id:\n        raise HTTPException(status_code=401, detail=\"No permssion to delete\")\n\n    db.session.delete(workflow)\n    db.session.commit()\n"}
{"type": "source_file", "path": "autospark/controllers/agent_execution_config.py", "content": "import ast\n\nfrom fastapi import APIRouter\nfrom fastapi import HTTPException, Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom typing import Optional, Union\nfrom sqlalchemy import func, or_\nfrom sqlalchemy import desc\nfrom autospark.helper.auth import check_auth\nfrom autospark.models.agent import Agent\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent_execution_config import AgentExecutionConfiguration\n\nrouter = APIRouter()\n\n\n@router.get(\"/details/agent_id/{agent_id}/agent_execution_id/{agent_execution_id}\")\ndef get_agent_execution_configuration(agent_id: Union[int, None, str],\n                                      agent_execution_id: Union[int, None, str],\n                                      Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get the agent configuration using the agent ID and the agent execution ID.\n\n    Args:\n        agent_id (int): Identifier of the agent.\n        agent_execution_id (int): Identifier of the agent execution.\n        Authorize (AuthJWT, optional): Authorization dependency. Defaults to Depends(check_auth).\n\n    Returns:\n        dict: Agent configuration including its details.\n\n    Raises:\n        HTTPException (status_code=404): If the agent is not found or deleted.\n        HTTPException (status_code=404): If the agent_id or the agent_execution_id is undefined.\n    \"\"\"\n\n    # Check\n    if isinstance(agent_id, str):\n        raise HTTPException(status_code=404, detail=\"Agent Id undefined\")\n    if isinstance(agent_execution_id, str):\n        raise HTTPException(status_code=404, detail=\"Agent Execution Id undefined\")\n\n    # Define the agent_config keys to fetch\n    agent = db.session.query(Agent).filter(agent_id == Agent.id, or_(Agent.is_deleted == False)).first()\n    if not agent:\n        raise HTTPException(status_code=404, detail=\"Agent not found\")\n\n    # If the agent_execution_id received is -1 then the agent_execution_id is set as the most recent execution\n    if agent_execution_id == -1:\n        agent_execution = db.session.query(AgentExecution).filter(AgentExecution.agent_id == agent_id).order_by(\n            desc(AgentExecution.created_at)).first()\n        if agent_execution: agent_execution_id = agent_execution.id\n\n    # Fetch agent id from agent execution id and check whether the agent_id received is correct or not.\n    if agent_execution_id != -1:\n        agent_execution_config = AgentExecution.get_agent_execution_from_id(db.session, agent_execution_id)\n        if agent_execution_config is None:\n            raise HTTPException(status_code=404, detail=\"Agent Execution not found\")\n        agent_id_from_execution_id = agent_execution_config.agent_id\n        if agent_id != agent_id_from_execution_id:\n            raise HTTPException(status_code=404, detail=\"Wrong agent id\")\n\n    # Query the AgentConfiguration table and the AgentExecuitonConfiguration table for all the keys\n    results_agent = db.session.query(AgentConfiguration).filter(AgentConfiguration.agent_id == agent_id).all()\n    if agent_execution_id != -1: results_agent_execution = db.session.query(AgentExecutionConfiguration).filter(\n        AgentExecutionConfiguration.agent_execution_id == agent_execution_id).all()\n\n    total_calls = db.session.query(func.sum(AgentExecution.num_of_calls)).filter(\n        AgentExecution.agent_id == agent_id).scalar()\n    total_tokens = db.session.query(func.sum(AgentExecution.num_of_tokens)).filter(\n        AgentExecution.agent_id == agent_id).scalar()\n\n    response = {}\n    if agent_execution_id != -1:\n        response = AgentExecutionConfiguration.build_agent_execution_config(db.session, agent, results_agent,\n                                                                            results_agent_execution, total_calls,\n                                                                            total_tokens)\n    else:\n        response = AgentExecutionConfiguration.build_scheduled_agent_execution_config(db.session, agent, results_agent,\n                                                                                      total_calls, total_tokens)\n\n    # Close the session\n    db.session.close()\n\n    return response"}
{"type": "source_file", "path": "autospark/agent/agent_iteration_step_handler.py", "content": "from datetime import datetime\n\nfrom sqlalchemy import asc\nfrom sqlalchemy.sql.operators import and_\n\nimport autospark\nfrom autospark.agent.agent_message_builder import AgentLlmMessageBuilder\nfrom autospark.agent.agent_prompt_builder import AgentPromptBuilder\nfrom autospark.agent.output_handler import ToolOutputHandler, get_output_handler\nfrom autospark.agent.task_queue import TaskQueue\nfrom autospark.agent.tool_builder import ToolBuilder\nfrom autospark.apm.event_handler import EventHandler\nfrom autospark.config.config import get_config\nfrom autospark.helper.token_counter import TokenCounter\nfrom autospark.lib.logger import logger\nfrom autospark.models.agent import Agent\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent_execution_config import AgentExecutionConfiguration\nfrom autospark.models.agent_execution_feed import AgentExecutionFeed\nfrom autospark.models.agent_execution_permission import AgentExecutionPermission\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.tool import Tool\nfrom autospark.models.workflows.agent_workflow import AgentWorkflow\nfrom autospark.models.workflows.agent_workflow_step import AgentWorkflowStep\nfrom autospark.models.workflows.iteration_workflow import IterationWorkflow\nfrom autospark.models.workflows.iteration_workflow_step import IterationWorkflowStep\nfrom autospark.resource_manager.resource_summary import ResourceSummarizer\nfrom autospark.tools.resource.query_resource import QueryResourceTool\nfrom autospark.tools.thinking.tools import ThinkingTool\n\n\nclass AgentIterationStepHandler:\n    \"\"\" Handles iteration workflow steps in the agent workflow.\"\"\"\n\n    def __init__(self, session, llm, agent_id: int, agent_execution_id: int, memory=None):\n        self.session = session\n        self.llm = llm\n        self.agent_execution_id = agent_execution_id\n        self.agent_id = agent_id\n        self.memory = memory\n        self.task_queue = TaskQueue(str(self.agent_execution_id))\n\n    def execute_step(self):\n        agent_config = Agent.fetch_configuration(self.session, self.agent_id)\n        execution = AgentExecution.get_agent_execution_from_id(self.session, self.agent_execution_id)\n        iteration_workflow_step = IterationWorkflowStep.find_by_id(self.session, execution.iteration_workflow_step_id)\n        agent_execution_config = AgentExecutionConfiguration.fetch_configuration(self.session, self.agent_execution_id)\n\n        if not self._handle_wait_for_permission(execution, agent_config, agent_execution_config,\n                                                iteration_workflow_step):\n            return\n\n        workflow_step = AgentWorkflowStep.find_by_id(self.session, execution.current_agent_step_id)\n        organisation = Agent.find_org_by_agent_id(self.session, agent_id=self.agent_id)\n        iteration_workflow = IterationWorkflow.find_by_id(self.session, workflow_step.action_reference_id)\n\n        agent_feeds = AgentExecutionFeed.fetch_agent_execution_feeds(self.session, self.agent_execution_id)\n        if not agent_feeds:\n            self.task_queue.clear_tasks()\n\n        agent_tools = self._build_tools(agent_config, agent_execution_config)\n        prompt = self._build_agent_prompt(iteration_workflow=iteration_workflow,\n                                          agent_config=agent_config,\n                                          agent_execution_config=agent_execution_config,\n                                          prompt=iteration_workflow_step.prompt,\n                                          agent_tools=agent_tools)\n\n        messages = AgentLlmMessageBuilder(self.session, self.llm, self.agent_id, self.agent_execution_id) \\\n            .build_agent_messages(prompt, agent_feeds, history_enabled=iteration_workflow_step.history_enabled,\n                                  completion_prompt=iteration_workflow_step.completion_prompt)\n\n        logger.debug(\"Prompt messages:\", messages)\n        current_tokens = TokenCounter.count_message_tokens(messages, self.llm.get_model())\n        response = self.llm.chat_completion(messages, TokenCounter.token_limit(self.llm.get_model()) - current_tokens)\n\n        if 'content' not in response or response['content'] is None:\n            raise RuntimeError(f\"Failed to get response from llm\")\n\n        total_tokens = current_tokens + TokenCounter.count_message_tokens(response['content'], self.llm.get_model())\n        AgentExecution.update_tokens(self.session, self.agent_execution_id, total_tokens)\n\n        assistant_reply = response['content']\n        output_handler = get_output_handler(self.llm, iteration_workflow_step.output_type,\n                                            agent_execution_id=self.agent_execution_id,\n                                            agent_config=agent_config, agent_tools=agent_tools)\n        response = output_handler.handle(self.session, assistant_reply)\n        if response.status == \"COMPLETE\":\n            execution.status = \"COMPLETED\"\n            self.session.commit()\n\n            self._update_agent_execution_next_step(execution, iteration_workflow_step.next_step_id, \"COMPLETE\")\n            EventHandler(session=self.session).create_event('run_completed',\n                                                            {'agent_execution_id': execution.id,\n                                                             'name': execution.name,\n                                                             'tokens_consumed': execution.num_of_tokens,\n                                                             \"calls\": execution.num_of_calls},\n                                                            execution.agent_id, organisation.id)\n        elif response.status == \"WAITING_FOR_PERMISSION\":\n            execution.status = \"WAITING_FOR_PERMISSION\"\n            execution.permission_id = response.permission_id\n            self.session.commit()\n        else:\n            # moving to next step of iteration or workflow\n            self._update_agent_execution_next_step(execution, iteration_workflow_step.next_step_id)\n            logger.info(f\"Starting next job for agent execution id: {self.agent_execution_id}\")\n\n        self.session.flush()\n\n    def _update_agent_execution_next_step(self, execution, next_step_id, step_response: str = \"default\"):\n        if next_step_id == -1:\n            next_step = AgentWorkflowStep.fetch_next_step(self.session, execution.current_agent_step_id, step_response)\n            if str(next_step) == \"COMPLETE\":\n                execution.current_agent_step_id = -1\n                execution.status = \"COMPLETED\"\n            else:\n                AgentExecution.assign_next_step_id(self.session, self.agent_execution_id, next_step.id)\n        else:\n            execution.iteration_workflow_step_id = next_step_id\n        self.session.commit()\n\n    def _build_agent_prompt(self, iteration_workflow: IterationWorkflow, agent_config: dict,\n                            agent_execution_config: dict,\n                            prompt: str, agent_tools: list):\n        max_token_limit = int(get_config(\"MAX_TOOL_TOKEN_LIMIT\", 600))\n        prompt = AgentPromptBuilder.replace_main_variables(prompt, agent_execution_config[\"goal\"],\n                                                           agent_execution_config[\"instruction\"],\n                                                           agent_config[\"constraints\"], agent_tools,\n                                                           (not iteration_workflow.has_task_queue))\n\n        if iteration_workflow.has_task_queue:\n            response = self.task_queue.get_last_task_details()\n            last_task, last_task_result = (response[\"task\"], response[\"response\"]) if response is not None else (\"\", \"\")\n            current_task = self.task_queue.get_first_task() or \"\"\n            token_limit = TokenCounter.token_limit() - max_token_limit\n            prompt = AgentPromptBuilder.replace_task_based_variables(prompt, current_task, last_task, last_task_result,\n                                                                     self.task_queue.get_tasks(),\n                                                                     self.task_queue.get_completed_tasks(), token_limit)\n        return prompt\n\n    def _build_tools(self, agent_config: dict, agent_execution_config: dict):\n        agent_tools = [ThinkingTool()]\n\n        model_api_key = AgentConfiguration.get_model_api_key(self.session, self.agent_id, agent_config[\"model\"])\n        model_app_id = AgentConfiguration.get_model_app_id(self.session, self.agent_id, agent_config[\"model\"])\n        model_api_secret = AgentConfiguration.get_model_api_secret(self.session, self.agent_id, agent_config[\"model\"])\n        tool_builder = ToolBuilder(self.session, self.agent_id, self.agent_execution_id)\n        resource_summary = ResourceSummarizer(session=self.session,\n                                              agent_id=self.agent_id).fetch_or_create_agent_resource_summary(\n            default_summary=agent_config.get(\"resource_summary\"))\n        if resource_summary is not None:\n            agent_tools.append(QueryResourceTool())\n        user_tools = self.session.query(Tool).filter(\n            and_(Tool.id.in_(agent_config[\"tools\"]), Tool.file_name is not None)).all()\n        for tool in user_tools:\n            agent_tools.append(tool_builder.build_tool(tool))\n\n        agent_tools = [tool_builder.set_default_params_tool(tool, agent_config, agent_execution_config,\n                                                            model_api_key, resource_summary, model_app_id=model_app_id,\n                                                            model_api_secret=model_api_secret) for tool in agent_tools]\n        return agent_tools\n\n    def _handle_wait_for_permission(self, agent_execution, agent_config: dict, agent_execution_config: dict,\n                                    iteration_workflow_step: IterationWorkflowStep):\n        \"\"\"\n        Handles the wait for permission when the agent execution is waiting for permission.\n\n        Args:\n            agent_execution (AgentExecution): The agent execution.\n            agent_config (dict): The agent configuration.\n            agent_execution_config (dict): The agent execution configuration.\n            iteration_workflow_step (IterationWorkflowStep): The iteration workflow step.\n\n        Raises:\n            Returns permission success or failure\n        \"\"\"\n        if agent_execution.status != \"WAITING_FOR_PERMISSION\":\n            return True\n        agent_execution_permission = self.session.query(AgentExecutionPermission).filter(\n            AgentExecutionPermission.id == agent_execution.permission_id).first()\n        if agent_execution_permission.status == \"PENDING\":\n            logger.error(\"handle_wait_for_permission: Permission is still pending\")\n            return False\n        if agent_execution_permission.status == \"APPROVED\":\n            agent_tools = self._build_tools(agent_config, agent_execution_config)\n            tool_output_handler = ToolOutputHandler(self.agent_execution_id, agent_config, agent_tools)\n            tool_result = tool_output_handler.handle_tool_response(self.session,\n                                                                   agent_execution_permission.assistant_reply)\n            result = tool_result.result\n        else:\n            result = f\"User denied the permission to run the tool {agent_execution_permission.tool_name}\" \\\n                     f\"{' and has given the following feedback : ' + agent_execution_permission.user_feedback if agent_execution_permission.user_feedback else ''}\"\n\n        agent_execution_feed = AgentExecutionFeed(agent_execution_id=agent_execution_permission.agent_execution_id,\n                                                  agent_id=agent_execution_permission.agent_id,\n                                                  feed=agent_execution_permission.assistant_reply,\n                                                  role=\"assistant\",\n                                                  feed_group_id=agent_execution.current_feed_group_id)\n        self.session.add(agent_execution_feed)\n        agent_execution_feed1 = AgentExecutionFeed(agent_execution_id=agent_execution_permission.agent_execution_id,\n                                                   agent_id=agent_execution_permission.agent_id,\n                                                   feed=result, role=\"user\",\n                                                   feed_group_id=agent_execution.current_feed_group_id)\n        self.session.add(agent_execution_feed1)\n        agent_execution.status = \"RUNNING\"\n        execution = AgentExecution.find_by_id(self.session, agent_execution_permission.agent_execution_id)\n        self._update_agent_execution_next_step(execution, iteration_workflow_step.next_step_id)\n        self.session.commit()\n\n        return True\n"}
{"type": "source_file", "path": "autospark/controllers/resources.py", "content": "import datetime\nimport os\nfrom pathlib import Path\n\nimport boto3\nfrom botocore.exceptions import NoCredentialsError\nfrom fastapi import APIRouter\nfrom fastapi import File, Form, UploadFile\nfrom fastapi import HTTPException, Depends\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.security import HTTPBearer\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\n\nfrom autospark.config.config import get_config\nfrom autospark.helper.auth import check_auth\nfrom autospark.helper.resource_helper import ResourceHelper\nfrom autospark.lib.logger import logger\nfrom autospark.models.agent import Agent\nfrom autospark.models.resource import Resource\nfrom autospark.worker import summarize_resource\nfrom autospark.types.storage_types import StorageType\n\nrouter = APIRouter()\n\ns3 = boto3.client(\n    's3',\n    aws_access_key_id=get_config(\"AWS_ACCESS_KEY_ID\"),\n    aws_secret_access_key=get_config(\"AWS_SECRET_ACCESS_KEY\"),\n)\n\n\n@router.post(\"/add/{agent_id}\",dependencies=[], status_code=201)\nasync def upload(agent_id: int, file: UploadFile = File(...), name=Form(...), size=Form(...), type=Form(...),\n                 Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Upload a file as a resource for an agent.\n\n    Args:\n        agent_id (int): ID of the agent.\n        file (UploadFile): Uploaded file.\n        name (str): Name of the resource.\n        size (str): Size of the resource.\n        type (str): Type of the resource.\n\n    Returns:\n        Resource: Uploaded resource.\n\n    Raises:\n        HTTPException (status_code=400): If the agent with the specified ID does not exist.\n        HTTPException (status_code=400): If the file type is not supported.\n        HTTPException (status_code=500): If AWS credentials are not found or if there is an issue uploading to S3.\n\n    \"\"\"\n\n    agent = db.session.query(Agent).filter(Agent.id == agent_id).first()\n    if agent is None:\n        raise HTTPException(status_code=400, detail=\"Agent does not exists\")\n\n    # accepted_file_types is a tuple because endswith() expects a tuple\n    accepted_file_types = (\".pdf\", \".docx\", \".pptx\", \".csv\", \".txt\", \".epub\")\n    if not name.endswith(accepted_file_types):\n        raise HTTPException(status_code=400, detail=\"File type not supported!\")\n\n    storage_type = StorageType.get_storage_type(get_config(\"STORAGE_TYPE\", StorageType.FILE.value))\n    save_directory = ResourceHelper.get_root_input_dir()\n    if \"{agent_id}\" in save_directory:\n        save_directory = ResourceHelper.get_formatted_agent_level_path(agent=Agent\n                                                                       .get_agent_from_id(session=db.session,\n                                                                                    agent_id=agent_id),\n                                                                       path=save_directory)\n    file_path = os.path.join(save_directory, file.filename)\n    if storage_type == StorageType.FILE:\n        os.makedirs(save_directory, exist_ok=True)\n        with open(file_path, \"wb\") as f:\n            contents = await file.read()\n            f.write(contents)\n            file.file.close()\n    elif storage_type == StorageType.S3:\n        bucket_name = get_config(\"BUCKET_NAME\")\n        file_path = 'resources' + file_path\n        try:\n            s3.upload_fileobj(file.file, bucket_name, file_path)\n            logger.info(\"File uploaded successfully!\")\n        except NoCredentialsError:\n            raise HTTPException(status_code=500, detail=\"AWS credentials not found. Check your configuration.\")\n\n    resource = Resource(name=name, path=file_path, storage_type=storage_type.value, size=size, type=type, channel=\"INPUT\",\n                        agent_id=agent.id)\n\n    db.session.add(resource)\n    db.session.commit()\n    db.session.flush()\n\n    summarize_resource.delay(agent_id, resource.id)\n    logger.info(resource)\n\n    return resource\n\n\n@router.get(\"/get/all/{agent_id}\", dependencies=[],status_code=200)\ndef get_all_resources(agent_id: int,\n                      Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get all resources for an agent.\n\n    Args:\n        agent_id (int): ID of the agent.\n\n    Returns:\n        List[Resource]: List of resources belonging to the agent.\n\n    \"\"\"\n\n    resources = db.session.query(Resource).filter(Resource.agent_id == agent_id).all()\n    return resources\n\n\n@router.get(\"/get/{resource_id}\",dependencies=[], status_code=200)\ndef download_file_by_id(resource_id: int,\n                        Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Download a particular resource by resource_id.\n\n    Args:\n        resource_id (int): ID of the resource.\n        Authorize (AuthJWT, optional): Authorization dependency.\n\n    Returns:\n        StreamingResponse: Streaming response for downloading the resource.\n\n    Raises:\n        HTTPException (status_code=400): If the resource with the specified ID is not found.\n        HTTPException (status_code=404): If the file is not found.\n\n    \"\"\"\n\n    resource = db.session.query(Resource).filter(Resource.id == resource_id).first()\n    download_file_path = resource.path\n    file_name = resource.name\n\n    if not resource:\n        raise HTTPException(status_code=400, detail=\"Resource Not found!\")\n\n    if resource.storage_type == StorageType.S3.value:\n        bucket_name = get_config(\"BUCKET_NAME\")\n        file_key = resource.path\n        response = s3.get_object(Bucket=bucket_name, Key=file_key)\n        content = response[\"Body\"]\n    else:\n        abs_file_path = Path(download_file_path).resolve()\n        if not abs_file_path.is_file():\n            raise HTTPException(status_code=404, detail=\"File not found\")\n        content = open(str(abs_file_path), \"rb\")\n\n    return StreamingResponse(\n        content,\n        media_type=\"application/octet-stream\",\n        headers={\n            \"Content-Disposition\": f\"attachment; filename={file_name}\"\n        }\n    )\n"}
{"type": "source_file", "path": "autospark/controllers/tool_config.py", "content": "from fastapi import APIRouter, HTTPException, Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom pydantic import BaseModel\n\nfrom autospark.helper.auth import check_auth\nfrom autospark.helper.auth import get_user_organisation\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.tool_config import ToolConfig\nfrom autospark.models.toolkit import Toolkit\nfrom autospark.helper.encyption_helper import encrypt_data\nfrom autospark.helper.encyption_helper import decrypt_data, is_encrypted\nfrom autospark.types.key_type import ToolConfigKeyType\nimport json\n\nrouter = APIRouter()\n\nclass ToolConfigOut(BaseModel):\n    id = int\n    key = str\n    value = str\n    toolkit_id = int\n\n    class Config:\n        orm_mode = True\n\n@router.post(\"/add/{toolkit_name}\", dependencies=[Depends(HTTPBearer())],status_code=201)\ndef update_tool_config(toolkit_name: str, configs: list, organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Update tool configurations for a specific tool kit.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n        configs (list): A list of dictionaries containing the tool configurations.\n            Each dictionary should have the following keys:\n            - \"key\" (str): The key of the configuration.\n            - \"value\" (str): The new value for the configuration.\n\n    Returns:\n        dict: A dictionary with the message \"Tool configs updated successfully\".\n\n    Raises:\n        HTTPException (status_code=404): If the specified tool kit is not found.\n        HTTPException (status_code=500): If an unexpected error occurs during the update process.\n    \"\"\"\n\n    try:\n        # Check if the tool kit exists\n        toolkit = Toolkit.get_toolkit_from_name(db.session, toolkit_name,organisation)\n        if toolkit is None:\n            raise HTTPException(status_code=404, detail=\"Tool kit not found\")\n\n        # Update existing tool configs\n        for config in configs:\n            key = config.get(\"key\")\n            value = config.get(\"value\")\n            if value is None: \n                continue\n            if key is not None:\n                tool_config = db.session.query(ToolConfig).filter_by(toolkit_id=toolkit.id, key=key).first()\n                if tool_config:\n                    if tool_config.key_type ==  ToolConfigKeyType.FILE.value:\n                        value = json.dumps(value)\n                    # Update existing tool config\n                    # added encryption\n                    tool_config.value = encrypt_data(value)\n                    db.session.commit()\n\n        return {\"message\": \"Tool configs updated successfully\"}\n\n    except Exception as e:\n        # db.session.rollback()\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@router.post(\"/create-or-update/{toolkit_name}\", dependencies=[Depends(HTTPBearer())],status_code=201, response_model=ToolConfigOut)\ndef create_or_update_tool_config(toolkit_name: str, tool_configs,\n                                 Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create or update tool configurations for a specific tool kit.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n        tool_configs (list): A list of tool configuration objects.\n\n    Returns:\n        Toolkit: The updated tool kit object.\n\n    Raises:\n        HTTPException (status_code=404): If the specified tool kit is not found.\n    \"\"\"\n\n    toolkit = db.session.query(Toolkit).filter_by(name=toolkit_name).first()\n    if not toolkit:\n        raise HTTPException(status_code=404, detail='ToolKit not found')\n\n    # Iterate over the tool_configs list\n    for tool_config in tool_configs:\n        existing_tool_config = db.session.query(ToolConfig).filter(\n            ToolConfig.toolkit_id == toolkit.id,\n            ToolConfig.key == tool_config.key\n        ).first()\n\n        if existing_tool_config.value:\n            # Update the existing tool config\n            if existing_tool_config.key_type == ToolConfigKeyType.FILE.value:\n                existing_tool_config.value = json.dumps(existing_tool_config.value)\n            existing_tool_config.value = encrypt_data(tool_config.value)\n        else:\n            # Create a new tool config\n            new_tool_config = ToolConfig(key=tool_config.key, value=encrypt_data(tool_config.value), toolkit_id=toolkit.id)\n            db.session.add(new_tool_config)\n\n    db.session.commit()\n    db.session.refresh(toolkit)\n\n    return toolkit\n\n\n@router.get(\"/get/toolkit/{toolkit_name}\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef get_all_tool_configs(toolkit_name: str, organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Get all tool configurations by Tool Kit Name.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n        organisation (Organisation): The organization associated with the user.\n\n    Returns:\n        list: A list of tool configurations for the specified tool kit.\n\n    Raises:\n        HTTPException (status_code=404): If the specified tool kit is not found.\n        HTTPException (status_code=403): If the user is not authorized to access the tool kit.\n    \"\"\"\n\n    toolkit = db.session.query(Toolkit).filter(Toolkit.name == toolkit_name,\n                                               Toolkit.organisation_id == organisation.id).first()\n    if not toolkit:\n        raise HTTPException(status_code=404, detail='ToolKit not found')\n\n    tool_configs = db.session.query(ToolConfig).filter(ToolConfig.toolkit_id == toolkit.id).all()\n    for tool_config in tool_configs:\n        if tool_config.value:\n            if(is_encrypted(tool_config.value)):\n                tool_config.value = decrypt_data(tool_config.value)\n            if tool_config.key_type == ToolConfigKeyType.FILE.value:\n                tool_config.value = json.loads(tool_config.value)\n    \n    return tool_configs\n\n\n@router.get(\"/get/toolkit/{toolkit_name}/key/{key}\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef get_tool_config(toolkit_name: str, key: str, organisation: Organisation = Depends(get_user_organisation)):\n    \"\"\"\n    Get a specific tool configuration by tool kit name and key.\n\n    Args:\n        toolkit_name (str): The name of the tool kit.\n        key (str): The key of the tool configuration.\n        organisation (Organisation): The organization associated with the user.\n\n    Returns:\n        ToolConfig: The tool configuration with the specified key.\n\n    Raises:\n        HTTPException (status_code=403): If the user is not authorized to access the tool kit.\n        HTTPException (status_code=404): If the specified tool kit or tool configuration is not found.\n    \"\"\"\n\n    user_toolkits = db.session.query(Toolkit).filter(Toolkit.organisation_id == organisation.id).all()\n\n    toolkit = db.session.query(Toolkit).filter_by(name=toolkit_name)\n    if toolkit not in user_toolkits:\n        raise HTTPException(status_code=403, detail='Unauthorized')\n\n    tool_config = db.session.query(ToolConfig).filter(\n        ToolConfig.toolkit_id == toolkit.id,\n        ToolConfig.key == key\n    ).first()\n\n    if not tool_config:\n        raise HTTPException(status_code=404, detail=\"Tool configuration not found\")\n    if(is_encrypted(tool_config.value)):\n        tool_config.value = decrypt_data(tool_config.value)\n    if tool_config.key_type == ToolConfigKeyType.FILE.value:\n        tool_config.value = json.loads(tool_config.value)\n\n    return tool_config\n"}
{"type": "source_file", "path": "autospark/agent/agent_message_builder.py", "content": "import time\nfrom typing import Tuple, List\nfrom sqlalchemy import asc\n\nfrom autospark.config.config import get_config\nfrom autospark.helper.prompt_reader import PromptReader\nfrom autospark.helper.token_counter import TokenCounter\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent_execution_feed import AgentExecutionFeed\nfrom autospark.types.common import BaseMessage\nfrom autospark.models.agent_execution_config import AgentExecutionConfiguration\n\n\nclass AgentLlmMessageBuilder:\n    \"\"\"Agent message builder for LLM agent.\"\"\"\n    def __init__(self, session, llm, agent_id: int, agent_execution_id: int):\n        self.session = session\n        self.llm = llm\n        self.llm_model = llm.get_model()\n        self.agent_id = agent_id\n        self.agent_execution_id = agent_execution_id\n\n    def build_agent_messages(self, prompt: str, agent_feeds: list, history_enabled=False,\n                             completion_prompt: str = None):\n        \"\"\" Build agent messages for LLM agent.\n\n        Args:\n            prompt (str): The prompt to be used for generating the agent messages.\n            agent_feeds (list): The list of agent feeds.\n            history_enabled (bool): Whether to use history or not.\n            completion_prompt (str): The completion prompt to be used for generating the agent messages.\n        \"\"\"\n        token_limit = TokenCounter.token_limit(self.llm_model)\n        max_output_token_limit = int(get_config(\"MAX_TOOL_TOKEN_LIMIT\", 800))\n        messages = [{\"role\": \"system\", \"content\": prompt}]\n\n        if history_enabled:\n            messages.append({\"role\": \"system\", \"content\": f\"The current time and date is {time.strftime('%c')}\"})\n            base_token_limit = TokenCounter.count_message_tokens(messages, self.llm_model)\n            full_message_history = [{'role': agent_feed.role, 'content': agent_feed.feed, 'chat_id': agent_feed.id}\n                                    for agent_feed in agent_feeds]\n            past_messages, current_messages = self._split_history(full_message_history,\n                                                  ((token_limit - base_token_limit - max_output_token_limit) // 4) * 3)\n            if past_messages:\n                ltm_summary = self._build_ltm_summary(past_messages=past_messages,\n                                                                   output_token_limit=(token_limit - base_token_limit - max_output_token_limit) // 4)\n                messages.append({\"role\": \"assistant\", \"content\": ltm_summary})\n\n            for history in current_messages:\n                messages.append({\"role\": history[\"role\"], \"content\": history[\"content\"]})\n            messages.append({\"role\": \"user\", \"content\": completion_prompt})\n\n        # insert initial agent feeds\n        self._add_initial_feeds(agent_feeds, messages)\n        return messages\n\n    def _split_history(self, history: List, pending_token_limit: int) -> Tuple[List[BaseMessage], List[BaseMessage]]:\n        hist_token_count = 0\n        i = len(history)\n        for message in reversed(history):\n            token_count = TokenCounter.count_message_tokens([{\"role\": message[\"role\"], \"content\": message[\"content\"]}],\n                                                            self.llm_model)\n            hist_token_count += token_count\n            if hist_token_count > pending_token_limit:\n                self._add_or_update_last_agent_feed_ltm_summary_id(str(history[i-1]['chat_id']))\n                return history[:i], history[i:]\n            i -= 1\n        return [], history\n\n    def _add_initial_feeds(self, agent_feeds: list, messages: list):\n        if agent_feeds:\n            return\n        for message in messages:\n            agent_execution_feed = AgentExecutionFeed(agent_execution_id=self.agent_execution_id,\n                                                      agent_id=self.agent_id,\n                                                      feed=message[\"content\"],\n                                                      role=message[\"role\"],\n                                                      feed_group_id=\"DEFAULT\")\n            self.session.add(agent_execution_feed)\n            self.session.commit()\n\n    def _add_or_update_last_agent_feed_ltm_summary_id(self, last_agent_feed_ltm_summary_id):\n        execution = AgentExecution(id=self.agent_execution_id)\n        agent_execution_configs = {\"last_agent_feed_ltm_summary_id\": last_agent_feed_ltm_summary_id}\n        AgentExecutionConfiguration.add_or_update_agent_execution_config(self.session, execution,\n                                                                         agent_execution_configs)\n\n\n    def _build_ltm_summary(self, past_messages, output_token_limit) -> str:\n        ltm_prompt = self._build_prompt_for_ltm_summary(past_messages=past_messages,\n                                                        token_limit=output_token_limit)\n\n        summary = AgentExecutionConfiguration.fetch_value(self.session, self.agent_execution_id, \"ltm_summary\")\n        previous_ltm_summary = summary.value if summary is not None else \"\"\n\n        ltm_summary_base_token_limit = 10\n        if ((TokenCounter.count_text_tokens(ltm_prompt) + ltm_summary_base_token_limit + output_token_limit)\n            - TokenCounter.token_limit()) > 0:\n            last_agent_feed_ltm_summary_id = AgentExecutionConfiguration.fetch_value(self.session,\n                                                       self.agent_execution_id, \"last_agent_feed_ltm_summary_id\")\n            last_agent_feed_ltm_summary_id = int(last_agent_feed_ltm_summary_id.value)\n\n            past_messages = self.session.query(AgentExecutionFeed.role, AgentExecutionFeed.feed,\n                                               AgentExecutionFeed.id) \\\n                .filter(AgentExecutionFeed.agent_execution_id == self.agent_execution_id,\n                        AgentExecutionFeed.id > last_agent_feed_ltm_summary_id) \\\n                .order_by(asc(AgentExecutionFeed.created_at)) \\\n                .all()\n\n            past_messages = [\n                {'role': past_message.role, 'content': past_message.feed, 'chat_id': past_message.id}\n                for past_message in past_messages]\n\n            ltm_prompt = self._build_prompt_for_recursive_ltm_summary_using_previous_ltm_summary(\n                previous_ltm_summary=previous_ltm_summary, past_messages=past_messages, token_limit=output_token_limit)\n\n        msgs = [{\"role\": \"system\", \"content\": \"You are GPT Prompt writer\"},\n                {\"role\": \"assistant\", \"content\": ltm_prompt}]\n        ltm_summary = self.llm.chat_completion(msgs)\n\n        execution = AgentExecution(id=self.agent_execution_id)\n        agent_execution_configs = {\"ltm_summary\": ltm_summary[\"content\"]}\n        AgentExecutionConfiguration.add_or_update_agent_execution_config(session=self.session, execution=execution,\n                                                                 agent_execution_configs=agent_execution_configs)\n\n        return ltm_summary[\"content\"]\n\n    def _build_prompt_for_ltm_summary(self, past_messages: List[BaseMessage], token_limit: int):\n        ltm_summary_prompt = PromptReader.read_agent_prompt(__file__, \"agent_summary.txt\")\n\n        past_messages_prompt = \"\"\n        for past_message in past_messages:\n            past_messages_prompt += past_message[\"role\"] + \": \" + past_message[\"content\"] + \"\\n\"\n        ltm_summary_prompt = ltm_summary_prompt.replace(\"{past_messages}\", past_messages_prompt)\n\n        ltm_summary_prompt = ltm_summary_prompt.replace(\"{char_limit}\", str(token_limit*4))\n\n        return ltm_summary_prompt\n\n    def _build_prompt_for_recursive_ltm_summary_using_previous_ltm_summary(self, previous_ltm_summary: str,\n                                                                    past_messages: List[BaseMessage], token_limit: int):\n        ltm_summary_prompt = PromptReader.read_agent_prompt(__file__, \"agent_recursive_summary.txt\")\n\n        ltm_summary_prompt = ltm_summary_prompt.replace(\"{previous_ltm_summary}\", previous_ltm_summary)\n\n        past_messages_prompt = \"\"\n        for past_message in past_messages:\n            past_messages_prompt += past_message[\"role\"] + \": \" + past_message[\"content\"] + \"\\n\"\n        ltm_summary_prompt = ltm_summary_prompt.replace(\"{past_messages}\", past_messages_prompt)\n\n        ltm_summary_prompt = ltm_summary_prompt.replace(\"{char_limit}\", str(token_limit*4))\n\n        return ltm_summary_prompt\n"}
{"type": "source_file", "path": "autospark/controllers/agent_template.py", "content": "from datetime import datetime\n\nfrom fastapi import APIRouter\nfrom fastapi import HTTPException, Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_sqlalchemy import db\nfrom pydantic import BaseModel\n\nfrom main import get_config\nfrom autospark.helper.auth import get_user_organisation\nfrom autospark.models.agent import Agent\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.agent_template import AgentTemplate\nfrom autospark.models.agent_template_config import AgentTemplateConfig\nfrom autospark.models.workflows.agent_workflow import AgentWorkflow\nfrom autospark.models.tool import Tool\n# from autospark.types.db import AgentTemplateIn, AgentTemplateOut\n\nrouter = APIRouter()\n\n\nclass AgentTemplateOut(BaseModel):\n    id: int\n    organisation_id: int\n    agent_workflow_id: int\n    name: str\n    description: str\n    marketplace_template_id: int\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass AgentTemplateIn(BaseModel):\n    organisation_id: int\n    agent_workflow_id: int\n    name: str\n    description: str\n    marketplace_template_id: int\n\n    class Config:\n        orm_mode = True\n\n@router.post(\"/create\", status_code=201,dependencies=[Depends(HTTPBearer())], response_model=AgentTemplateOut)\ndef create_agent_template(agent_template: AgentTemplateIn,\n                          organisation=Depends(get_user_organisation)):\n    \"\"\"\n    Create an agent template.\n\n    Args:\n        agent_template (AgentTemplate): Data for creating an agent template.\n        organisation (Depends): Dependency to get the user organisation.\n\n    Returns:\n        AgentTemplate: The created agent template.\n\n    Raises:\n        HTTPException (status_code=404): If the associated agent workflow is not found.\n    \"\"\"\n\n    agent_workflow = db.session.query(AgentWorkflow).get(agent_template.agent_workflow_id)\n\n    if not agent_workflow:\n        raise HTTPException(status_code=404, detail=\"Agent Workflow not found\")\n    db_agent_template = AgentTemplate(agent_workflow_id=agent_template.agent_workflow_id,\n                                      name=agent_template.name,\n                                      organisation_id=organisation.id,\n                                      description=agent_template.description)\n    db.session.add(db_agent_template)\n    db.session.commit()\n\n    return db_agent_template\n\n\n@router.get(\"/get/{agent_template_id}\",dependencies=[Depends(HTTPBearer())])\ndef get_agent_template(template_source, agent_template_id: int, organisation=Depends(get_user_organisation)):\n    \"\"\"\n        Get the details of a specific agent template.\n\n        Args:\n            template_source (str): The source of the agent template (\"local\" or \"marketplace\").\n            agent_template_id (int): The ID of the agent template.\n            organisation (Depends): Dependency to get the user organisation.\n\n        Returns:\n            dict: The details of the agent template.\n\n        Raises:\n            HTTPException (status_code=404): If the agent template is not found.\n    \"\"\"\n    if template_source == \"local\":\n        db_agent_template = db.session.query(AgentTemplate).filter(AgentTemplate.organisation_id == organisation.id,\n                                                                   AgentTemplate.id == agent_template_id).first()\n        if not db_agent_template:\n            raise HTTPException(status_code=404, detail=\"Agent execution not found\")\n        template = db_agent_template.to_dict()\n        configs = {}\n        agent_template_configs = db.session.query(AgentTemplateConfig).filter(\n            AgentTemplateConfig.agent_template_id == agent_template_id).all()\n        for agent_template_config in agent_template_configs:\n            config_value = AgentTemplate.eval_agent_config(agent_template_config.key, agent_template_config.value)\n            configs[agent_template_config.key] = {\"value\": config_value}\n        template[\"configs\"] = configs\n    else:\n        template = AgentTemplate.fetch_marketplace_detail(agent_template_id)\n\n    return template\n\n\n@router.post(\"/update_details/{agent_template_id}\",dependencies=[Depends(HTTPBearer())], response_model=AgentTemplateOut)\ndef update_agent_template(agent_template_id: int,\n                          agent_configs: dict,\n                          organisation=Depends(get_user_organisation)):\n    \"\"\"\n    Update the details of an agent template.\n\n    Args:\n        agent_template_id (int): The ID of the agent template to update.\n        agent_configs (dict): The updated agent configurations.\n        organisation (Depends): Dependency to get the user organisation.\n\n    Returns:\n        dict: The updated agent template.\n\n    Raises:\n        HTTPException (status_code=404): If the agent template is not found.\n    \"\"\"\n\n    db_agent_template = db.session.query(AgentTemplate).filter(AgentTemplate.organisation_id == organisation.id,\n                                                               AgentTemplate.id == agent_template_id).first()\n    if db_agent_template is None:\n        raise HTTPException(status_code=404, detail=\"Agent Template not found\")\n\n    for key, value in agent_configs.items():\n        agent_template_config = db.session.query(AgentTemplateConfig).filter(\n            AgentTemplateConfig.agent_template_id == agent_template_id, AgentTemplateConfig.key == key).first()\n        if agent_template_config is None:\n            # create the template config\n            agent_template_config = AgentTemplateConfig(agent_template_id=agent_template_id, key=key)\n        agent_template_config.value = value[\"value\"]\n        db.session.add(agent_template_config)\n    db.session.commit()\n\n    return db_agent_template\n\n\n@router.post(\"/save_agent_as_template/{agent_id}\",dependencies=[Depends(HTTPBearer())])\ndef save_agent_as_template(agent_id: str,\n                           organisation=Depends(get_user_organisation)):\n    \"\"\"\n    Save an agent as a template.\n\n    Args:\n        agent_id (str): The ID of the agent to save as a template.\n        organisation (Depends): Dependency to get the user organisation.\n\n    Returns:\n        dict: The saved agent template.\n\n    Raises:\n        HTTPException (status_code=404): If the agent or agent configurations are not found.\n    \"\"\"\n\n    agent = db.session.query(Agent).filter(Agent.id == agent_id).first()\n    if agent is None:\n        raise HTTPException(status_code=404, detail=\"Agent not found\")\n    agent_configurations = db.session.query(AgentConfiguration).filter_by(agent_id=agent_id).all()\n    if not agent_configurations:\n        raise HTTPException(status_code=404, detail=\"Agent configurations not found\")\n    agent_template = AgentTemplate(name=agent.name, description=agent.description,\n                                   agent_workflow_id=agent.agent_workflow_id,\n                                   organisation_id=organisation.id)\n    db.session.add(agent_template)\n    db.session.commit()\n    main_keys = AgentTemplate.main_keys()\n    for agent_configuration in agent_configurations:\n        config_value = agent_configuration.value\n        if agent_configuration.key not in main_keys:\n            continue\n        if agent_configuration.key == \"tools\":\n            config_value = str(Tool.convert_tool_ids_to_names(db, eval(agent_configuration.value)))\n        agent_template_config = AgentTemplateConfig(agent_template_id=agent_template.id, key=agent_configuration.key,\n                                                    value=config_value)\n        db.session.add(agent_template_config)\n    db.session.commit()\n    db.session.flush()\n    return agent_template.to_dict()\n\n\n@router.get(\"/list\",dependencies=[Depends(HTTPBearer())])\ndef list_agent_templates(template_source=\"local\", search_str=\"\", page=0, organisation=Depends(get_user_organisation)):\n    \"\"\"\n        List agent templates.\n\n        Args:\n            template_source (str, optional): The source of the templates (\"local\" or \"marketplace\"). Defaults to \"local\".\n            search_str (str, optional): The search string to filter templates. Defaults to \"\".\n            page (int, optional): The page number for paginated results. Defaults to 0.\n            organisation (Depends): Dependency to get the user organisation.\n\n        Returns:\n            list: A list of agent templates.\n    \"\"\"\n\n    output_json = []\n    if template_source == \"local\":\n        templates = db.session.query(AgentTemplate).filter(AgentTemplate.organisation_id == organisation.id).all()\n        for template in templates:\n            template.updated_at = template.updated_at.strftime('%d-%b-%Y').upper()\n            output_json.append(template)\n    else:\n        local_templates = db.session.query(AgentTemplate).filter(AgentTemplate.organisation_id == organisation.id,\n                                                                 AgentTemplate.marketplace_template_id != None).all()\n        local_templates_hash = {}\n        for local_template in local_templates:\n            local_templates_hash[local_template.marketplace_template_id] = True\n        templates = AgentTemplate.fetch_marketplace_list(search_str, page)\n\n        for template in templates:\n            template[\"is_installed\"] = local_templates_hash.get(template[\"id\"], False)\n            template[\"organisation_id\"] = organisation.id\n            output_json.append(template)\n\n    return output_json\n\n\n@router.get(\"/marketplace/list\",dependencies=[Depends(HTTPBearer())])\ndef list_marketplace_templates(page=0):\n    \"\"\"\n    Get all marketplace agent templates.\n\n    Args:\n        page (int, optional): The page number for paginated results. Defaults to 0.\n\n    Returns:\n        list: A list of marketplace agent templates.\n\n    \"\"\"\n\n    organisation_id = int(get_config(\"MARKETPLACE_ORGANISATION_ID\"))\n    page_size = 30\n    templates = db.session.query(AgentTemplate).filter(AgentTemplate.organisation_id == organisation_id).offset(\n        page * page_size).limit(page_size).all()\n    output_json = []\n    for template in templates:\n        template.updated_at = template.updated_at.strftime('%d-%b-%Y').upper()\n        output_json.append(template)\n    return output_json\n\n\n@router.get(\"/marketplace/template_details/{agent_template_id}\",dependencies=[Depends(HTTPBearer())])\ndef marketplace_template_detail(agent_template_id):\n    \"\"\"\n    Get marketplace template details.\n\n    Args:\n        agent_template_id (int): The ID of the marketplace agent template.\n\n    Returns:\n        dict: A dictionary containing the marketplace template details.\n\n    \"\"\"\n\n    organisation_id = int(get_config(\"MARKETPLACE_ORGANISATION_ID\"))\n    template = db.session.query(AgentTemplate).filter(AgentTemplate.organisation_id == organisation_id,\n                                                      AgentTemplate.id == agent_template_id).first()\n    template_configs = db.session.query(AgentTemplateConfig).filter(\n        AgentTemplateConfig.agent_template_id == template.id).all()\n\n    workflow = db.session.query(AgentWorkflow).filter(AgentWorkflow.id == template.agent_workflow_id).first()\n    tool_configs = {}\n    for template_config in template_configs:\n        config_value = AgentTemplate.eval_agent_config(template_config.key, template_config.value)\n        tool_configs[template_config.key] = {\"value\": config_value}\n    output_json = {\n        \"id\": template.id,\n        \"name\": template.name,\n        \"description\": template.description,\n        \"agent_workflow_id\": template.agent_workflow_id,\n        \"agent_workflow_name\": workflow.name,\n        \"configs\": tool_configs\n    }\n    return output_json\n\n\n@router.post(\"/download\", status_code=201,dependencies=[Depends(HTTPBearer())])\ndef download_template(agent_template_id: int,\n                      organisation=Depends(get_user_organisation)):\n    \"\"\"\n    Create a new agent with configurations.\n\n    Args:\n        agent_template_id (int): The ID of the agent template.\n        organisation: User's organisation.\n\n    Returns:\n        dict: A dictionary containing the details of the downloaded template.\n    \"\"\"\n    template = AgentTemplate.clone_agent_template_from_marketplace(db, organisation.id, agent_template_id)\n    return template.to_dict()\n\n\n@router.get(\"/agent_config\", dependencies=[Depends(HTTPBearer())],status_code=201)\ndef fetch_agent_config_from_template(agent_template_id: int,\n                                     organisation=Depends(get_user_organisation)):\n    \"\"\"\n    Fetches agent configuration from a template.\n\n    Args:\n        agent_template_id (int): The ID of the agent template.\n        organisation: User's organisation.\n\n    Returns:\n        dict: A dictionary containing the agent configuration fetched from the template.\n\n    Raises:\n        HTTPException: If the template is not found.\n    \"\"\"\n\n    agent_template = db.session.query(AgentTemplate).filter(AgentTemplate.id == agent_template_id,\n                                                            AgentTemplate.organisation_id == organisation.id).first()\n    if not agent_template:\n        raise HTTPException(status_code=404, detail=\"Template not found\")\n\n    template_config = db.session.query(AgentTemplateConfig).filter(\n        AgentTemplateConfig.agent_template_id == agent_template_id).all()\n    template_config_dict = {}\n    main_keys = AgentTemplate.main_keys()\n    for config in template_config:\n        if config.key in main_keys:\n            template_config_dict[config.key] = AgentTemplate.eval_agent_config(config.key, config.value)\n    if \"instruction\" not in template_config_dict:\n        template_config_dict[\"instruction\"] = []\n    template_config_dict[\"agent_template_id\"] = agent_template.id\n\n    return template_config_dict\n"}
{"type": "source_file", "path": "autospark/controllers/config.py", "content": "from datetime import datetime\nfrom typing import Optional\n\nfrom fastapi import APIRouter\nfrom fastapi.security import HTTPBearer\nfrom pydantic import BaseModel\n\nfrom autospark.models.configuration import Configuration\nfrom autospark.models.organisation import Organisation\nfrom fastapi_sqlalchemy import db\nfrom fastapi import HTTPException, Depends, Request\nfrom autospark.config.config import get_config\nfrom autospark.helper.auth import check_auth\nfrom fastapi_jwt_auth import AuthJWT\nfrom autospark.helper.encyption_helper import encrypt_data, decrypt_data\nfrom autospark.lib.logger import logger\n\n# from autospark.types.db import ConfigurationIn, ConfigurationOut\n\nrouter = APIRouter()\n\n\nclass ConfigurationOut(BaseModel):\n    id: int\n    organisation_id: int\n    key: str\n    value: str\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass ConfigurationIn(BaseModel):\n    organisation_id: Optional[int]\n    key: str\n    value: str\n\n    class Config:\n        orm_mode = True\n\n\n# CRUD Operations\n@router.post(\"/add/organisation/{organisation_id}\",dependencies=[Depends(HTTPBearer())], status_code=201,\n             response_model=ConfigurationOut)\ndef create_config(config: ConfigurationIn, organisation_id: int,\n                  Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Creates a new Organisation level config.\n\n    Args:\n        config (Configuration): Configuration details.\n        organisation_id (int): ID of the organisation.\n\n    Returns:\n        Configuration: Created configuration.\n\n    \"\"\"\n\n    db_organisation = db.session.query(Organisation).filter(Organisation.id == organisation_id).first()\n    if not db_organisation:\n        raise HTTPException(status_code=404, detail=\"Organisation not found\")\n\n    existing_config = (\n        db.session.query(Configuration)\n        .filter(Configuration.organisation_id == organisation_id, Configuration.key == config.key)\n        .first()\n    )\n\n    # Encrypt the API key\n    if config.key == \"model_api_key\":\n        encrypted_value = encrypt_data(config.value)\n        config.value = encrypted_value\n    if config.key == \"model_api_secret\":\n        encrypted_value = encrypt_data(config.value)\n        config.value = encrypted_value\n    if config.key == \"model_app_id\":\n        encrypted_value = encrypt_data(config.value)\n        config.value = encrypted_value\n\n    if existing_config:\n        existing_config.value = config.value\n        db.session.commit()\n        db.session.flush()\n        return existing_config\n\n    logger.info(\"NEW CONFIG\")\n    new_config = Configuration(organisation_id=organisation_id, key=config.key, value=config.value)\n    logger.info(new_config)\n    logger.info(\"ORGANISATION ID : \", organisation_id)\n    db.session.add(new_config)\n    db.session.commit()\n    db.session.flush()\n    return new_config\n\n\n@router.get(\"/get/organisation/{organisation_id}/key/{key}\", dependencies=[Depends(HTTPBearer())],status_code=200)\ndef get_config_by_organisation_id_and_key(organisation_id: int, key: str,\n                                          Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get a configuration by organisation ID and key.\n\n    Args:\n        organisation_id (int): ID of the organisation.\n        key (str): Key of the configuration.\n        Authorize (AuthJWT, optional): Authorization JWT token. Defaults to Depends(check_auth).\n\n    Returns:\n        Configuration: Retrieved configuration.\n\n    \"\"\"\n\n    db_organisation = db.session.query(Organisation).filter(Organisation.id == organisation_id).first()\n    if not db_organisation:\n        raise HTTPException(status_code=404, detail=\"Organisation not found\")\n\n    config = db.session.query(Configuration).filter(Configuration.organisation_id == organisation_id,\n                                                    Configuration.key == key).first()\n    if config is None and key == \"model_api_key\":\n        api_key = get_config(\"OPENAI_API_KEY\") or get_config(\"PALM_API_KEY\")\n        if (api_key is not None and api_key != \"YOUR_OPEN_API_KEY\") or (\n                api_key is not None and api_key != \"YOUR_PALM_API_KEY\"):\n            encrypted_data = encrypt_data(api_key)\n            new_config = Configuration(organisation_id=organisation_id, key=\"model_api_key\", value=encrypted_data)\n            db.session.add(new_config)\n            db.session.commit()\n            db.session.flush()\n            return new_config\n        return config\n\n    # Decrypt the API key\n    if config is not None and config.key == \"model_api_key\":\n        if config.value is not None:\n            decrypted_data = decrypt_data(config.value)\n            config.value = decrypted_data\n\n    return config\n\n\n@router.get(\"/get/organisation/{organisation_id}\", dependencies=[Depends(HTTPBearer())],status_code=201)\ndef get_config_by_organisation_id(organisation_id: int,\n                                  Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get all configurations for a given organisation ID.\n\n    Args:\n        organisation_id (int): ID of the organisation.\n        Authorize (AuthJWT, optional): Authorization JWT token. Defaults to Depends(check_auth).\n\n    Returns:\n        List[Configuration]: List of configurations for the organisation.\n\n    \"\"\"\n\n    db_organisation = db.session.query(Organisation).filter(Organisation.id == organisation_id).first()\n    if not db_organisation:\n        raise HTTPException(status_code=404, detail=\"Organisation not found\")\n\n    configs = db.session.query(Configuration).filter(Configuration.organisation_id == organisation_id).all()\n\n    # Decrypt the API key if the key is \"model_api_key\"\n    for config in configs:\n        if config.key == \"model_api_key\":\n            decrypted_value = decrypt_data(config.value)\n            config.value = decrypted_value\n\n    return configs\n\n\n@router.get(\"/get/env\", status_code=200)\ndef current_env():\n    \"\"\"\n    Get the current environment.\n\n    Returns:\n        dict: Dictionary containing the current environment.\n\n    \"\"\"\n\n    env = get_config(\"ENV\", \"DEV\")\n    return {\n        \"env\": env\n    }\n"}
{"type": "source_file", "path": "autospark/config/config.py", "content": "import os\nfrom pydantic import BaseSettings\nfrom pathlib import Path\nimport yaml\nfrom autospark.lib.logger import logger\n\nCONFIG_FILE = \"config.yaml\"\n\n\nclass Config(BaseSettings):\n    class Config:\n        env_file_encoding = \"utf-8\"\n        extra = \"allow\"  # Allow extra fields\n\n    @classmethod\n    def load_config(cls, config_file: str) -> dict:\n        # If config file exists, read it\n        if os.path.exists(config_file):\n            with open(config_file, \"r\") as file:\n                config_data = yaml.safe_load(file)\n            if config_data is None:\n                config_data = {}\n        else:\n            # If config file doesn't exist, prompt for credentials and create new file\n            logger.info(\"\\033[91m\\033[1m\"\n        + \"\\nConfig file not found. Enter required keys and values.\"\n        + \"\\033[0m\\033[0m\")\n            config_data = {}\n            with open(config_file, \"w\") as file:\n                yaml.dump(config_data, file, default_flow_style=False)\n\n        # Merge environment variables and config data\n        env_vars = dict(os.environ)\n        config_data = {**config_data, **env_vars}\n\n        return config_data\n\n    def __init__(self, config_file: str, **kwargs):\n        config_data = self.load_config(config_file)\n        super().__init__(**config_data, **kwargs)\n\n    def get_config(self, key: str, default: str = None) -> str:\n        return self.dict().get(key, default)\n\n\nROOT_DIR = os.path.dirname(Path(__file__).parent.parent)\n_config_instance = Config(ROOT_DIR + \"/\" + CONFIG_FILE)\n\n\ndef get_config(key: str, default: str = None) -> str:\n    return _config_instance.get_config(key, default)"}
{"type": "source_file", "path": "autospark/agent/agent_prompt_builder.py", "content": "import json\nimport re\n\nfrom pydantic.types import List\n\nfrom autospark.helper.prompt_reader import PromptReader\nfrom autospark.helper.token_counter import TokenCounter\nfrom autospark.lib.logger import logger\nfrom autospark_kit.tools.base_tool import BaseTool\nfrom autospark.types.model_source_types import ModelSourceType\n\nFINISH_NAME = \"finish\"\n\n\nclass AgentPromptBuilder:\n\n    @staticmethod\n    def add_list_items_to_string(items: List[str]) -> str:\n        list_string = \"\"\n        for i, item in enumerate(items):\n            list_string += f\"{i + 1}. {item}\\n\"\n        return list_string\n\n    @classmethod\n    def add_tools_to_prompt(cls, tools: List[BaseTool], add_finish: bool = True, model_source_type:ModelSourceType=ModelSourceType.OpenAI) -> str:\n        final_string = \"\"\n        print(tools)\n        for i, item in enumerate(tools):\n            if model_source_type != ModelSourceType.SparkAI:\n                final_string += f\"{i + 1}. {cls._generate_command_string(item)}\\n\"\n            else:\n                #final_string += f\"{i + 1}. {cls._generate_command_string_spark(item)}\\n\"\n                final_string += f\"{i + 1}. {cls._generate_command_string(item)}\\n\"\n\n        finish_description = (\n            \"use this to signal that you have finished all your objectives\"\n        )\n        finish_args = (\n            '\"response\": \"final response to let '\n            'people know you have finished your objectives\"'\n        )\n        finish_string = (\n            f\"{len(tools) + 1}. \\\"{FINISH_NAME}\\\": \"\n            f\"{finish_description}, args: {finish_args}\"\n        )\n        if add_finish:\n            final_string = final_string + finish_string + \"\\n\\n\"\n        else:\n            final_string = final_string + \"\\n\"\n\n        return final_string\n\n    @classmethod\n    def _generate_command_string(cls, tool: BaseTool) -> str:\n        output = f\"\\\"{tool.name}\\\": {tool.description}\"\n        # print(tool.args)\n        output += f\", args json schema: {json.dumps(tool.args)}\"\n        return output\n\n    @classmethod\n    def _generate_command_string_spark(cls, tool: BaseTool) -> str:\n        output = f\"\\\"{tool.name}\\\": {tool.description}\"\n\n        # print(tool.args)\n        def build_spark_tool(kargs: dict):\n            o = \"\"\n            for key, v in kargs.items():\n                o += f\"{key}: \\\"<{key}>\\\",\"\n            return o\n\n        output += f\", args : {build_spark_tool(tool.args)}\"\n        return output\n\n    @classmethod\n    def clean_prompt(cls, prompt):\n        prompt = re.sub('[ \\t]+', ' ', prompt)\n        return prompt.strip()\n\n    @classmethod\n    def get_auto_spark_single_prompt(cls):\n        response_format = {\n            \"thoughts\": {\n                \"text\": \"thought\",\n                \"reasoning\": \"short reasoning\",\n                \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n                \"criticism\": \"constructive self-criticism\",\n                \"speak\": \"thoughts summary to say to user\",\n            },\n            \"tool\": {\"name\": \"tool name/task name\", \"args\": {\"arg name\": \"arg value(escape in case of string)\"}}\n        }\n        formatted_response_format = json.dumps(response_format, indent=4)\n\n        as_prompt = PromptReader.read_agent_prompt(__file__, \"autospark.txt\")\n\n        as_prompt = AgentPromptBuilder.clean_prompt(as_prompt).replace(\"{response_format}\",\n                                                                       formatted_response_format)\n        return {\"prompt\": as_prompt, \"variables\": [\"goals\", \"instructions\", \"constraints\", \"tools\"]}\n\n    @classmethod\n    def start_watcher_based(cls):\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"initialize_autospark_tasks.txt\")\n        return {\"prompt\": AgentPromptBuilder.clean_prompt(autospark_prompt), \"variables\": [\"goals\", \"instructions\"]}\n\n    @classmethod\n    def analyse_autospark_task(cls):\n        constraints = [\n            'Exclusively use the tools listed in double quotes e.g. \"tool name\"'\n        ]\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"analyse_autospark_task.txt\")\n        autospark_prompt = AgentPromptBuilder.clean_prompt(autospark_prompt) \\\n            .replace(\"{constraints}\", AgentPromptBuilder.add_list_items_to_string(constraints))\n        return {\"prompt\": autospark_prompt, \"variables\": [\"goals\", \"instructions\", \"tools\", \"current_task\"]}\n\n    @classmethod\n    def create_autospark_tasks(cls):\n        # just executed task `{last_task}` and got the result `{last_task_result}`\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"create_autospark_tasks.txt\")\n        return {\"prompt\": AgentPromptBuilder.clean_prompt(autospark_prompt),\n                \"variables\": [\"goals\", \"instructions\", \"last_task\", \"last_task_result\", \"pending_tasks\"]}\n\n    @classmethod\n    def prioritize_autospark_tasks(cls):\n        # just executed task `{last_task}` and got the result `{last_task_result}`\n        autospark_prompt = PromptReader.read_agent_prompt(__file__, \"prioritize_autospark_tasks.txt\")\n        return {\"prompt\": AgentPromptBuilder.clean_prompt(autospark_prompt),\n                \"variables\": [\"goals\", \"instructions\", \"last_task\", \"last_task_result\", \"pending_tasks\"]}\n\n    @classmethod\n    def start_task_based(cls):\n        as_prompt = PromptReader.read_agent_prompt(__file__, \"initialize_tasks.txt\")\n\n        return {\"prompt\": AgentPromptBuilder.clean_prompt(as_prompt), \"variables\": [\"goals\", \"instructions\"]}\n        # as_prompt = as_prompt.replace(\"{goals}\", AgentPromptBuilder.add_list_items_to_string(goals))\n\n    @classmethod\n    def analyse_task(cls):\n        constraints = [\n            'Exclusively use the tools listed in double quotes e.g. \"tool name\"'\n        ]\n        as_prompt = PromptReader.read_agent_prompt(__file__, \"analyse_task.txt\")\n        as_prompt = AgentPromptBuilder.clean_prompt(as_prompt) \\\n            .replace(\"{constraints}\", AgentPromptBuilder.add_list_items_to_string(constraints))\n        return {\"prompt\": as_prompt, \"variables\": [\"goals\", \"instructions\", \"tools\", \"current_task\"]}\n\n    @classmethod\n    def create_tasks(cls):\n        # just executed task `{last_task}` and got the result `{last_task_result}`\n        as_prompt = PromptReader.read_agent_prompt(__file__, \"create_tasks.txt\")\n        return {\"prompt\": AgentPromptBuilder.clean_prompt(as_prompt),\n                \"variables\": [\"goals\", \"instructions\", \"last_task\", \"last_task_result\", \"pending_tasks\"]}\n\n    @classmethod\n    def prioritize_tasks(cls):\n        # just executed task `{last_task}` and got the result `{last_task_result}`\n        as_prompt = PromptReader.read_agent_prompt(__file__, \"prioritize_tasks.txt\")\n        return {\"prompt\": AgentPromptBuilder.clean_prompt(as_prompt),\n                \"variables\": [\"goals\", \"instructions\", \"last_task\", \"last_task_result\", \"pending_tasks\"]}\n\n    @classmethod\n    def get_json_fixer_prompt(cls, json_str):\n        # just executed task `{last_task}` and got the result `{last_task_result}`\n        as_prompt = PromptReader.read_agent_prompt(__file__, \"json_fix_spark.txt\")\n        return as_prompt.replace(\"{json_str}\",json_str)\n\n\n    @classmethod\n    def replace_main_variables(cls, as_prompt: str, goals: List[str], instructions: List[str],\n                               constraints: List[str],\n                               tools: List[BaseTool], add_finish_tool: bool = True, model_source_type: ModelSourceType=ModelSourceType.OpenAI):\n        as_prompt = as_prompt.replace(\"{goals}\", AgentPromptBuilder.add_list_items_to_string(goals))\n        if len(instructions) > 0 and len(instructions[0]) > 0:\n            task_str = \"INSTRUCTION(Follow these instruction to decide the flow of execution and decide the next steps for achieving the task):\"\n            as_prompt = as_prompt.replace(\"{instructions}\",\n                                                        \"INSTRUCTION: \" + '\\n' + AgentPromptBuilder.add_list_items_to_string(\n                                                            instructions))\n            as_prompt = as_prompt.replace(\"{task_instructions}\",\n                                                        task_str + '\\n' + AgentPromptBuilder.add_list_items_to_string(\n                                                            instructions))\n        else:\n            as_prompt = as_prompt.replace(\"{instructions}\", '')\n        as_prompt = as_prompt.replace(\"{task_instructions}\", \"\")\n        as_prompt = as_prompt.replace(\"{constraints}\",\n                                                    AgentPromptBuilder.add_list_items_to_string(constraints))\n\n        # logger.info(tools)\n        tools_string = AgentPromptBuilder.add_tools_to_prompt(tools, add_finish_tool, model_source_type)\n        as_prompt = as_prompt.replace(\"{tools}\", tools_string)\n        return as_prompt\n\n    @classmethod\n    def replace_task_based_variables(cls, as_prompt: str, current_task: str, last_task: str,\n                                     last_task_result: str, pending_tasks: List[str], completed_tasks: list,\n                                     token_limit: int):\n        if \"{current_task}\" in as_prompt:\n            as_prompt = as_prompt.replace(\"{current_task}\", current_task)\n        if \"{last_task}\" in as_prompt:\n            as_prompt = as_prompt.replace(\"{last_task}\", last_task)\n        if \"{last_task_result}\" in as_prompt:\n            as_prompt = as_prompt.replace(\"{last_task_result}\", last_task_result)\n        if \"{pending_tasks}\" in as_prompt:\n            as_prompt = as_prompt.replace(\"{pending_tasks}\", str(pending_tasks))\n\n        completed_tasks.reverse()\n        if \"{completed_tasks}\" in as_prompt:\n            completed_tasks_arr = []\n            for task in completed_tasks:\n                completed_tasks_arr.append(task['task'])\n            as_prompt = as_prompt.replace(\"{completed_tasks}\", str(completed_tasks_arr))\n\n        base_token_limit = TokenCounter.count_message_tokens([{\"role\": \"user\", \"content\": as_prompt}])\n        pending_tokens = token_limit - base_token_limit\n        final_output = \"\"\n        if \"{task_history}\" in as_prompt:\n            for task in reversed(completed_tasks[-10:]):\n                final_output = f\"Task: {task['task']}\\nResult: {task['response']}\\n\" + final_output\n                token_count = TokenCounter.count_message_tokens([{\"role\": \"user\", \"content\": final_output}])\n                # giving buffer of 100 tokens\n                if token_count > min(600, pending_tokens):\n                    break\n            as_prompt = as_prompt.replace(\"{task_history}\", \"\\n\" + final_output + \"\\n\")\n        return as_prompt\n"}
{"type": "source_file", "path": "autospark/controllers/organisation.py", "content": "from datetime import datetime\n\nfrom fastapi import APIRouter\nfrom fastapi import HTTPException, Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom pydantic import BaseModel\n\nfrom autospark.helper.auth import get_user_organisation\nfrom autospark.helper.auth import check_auth\nfrom autospark.helper.encyption_helper import decrypt_data\nfrom autospark.helper.tool_helper import register_toolkits\nfrom autospark.llms.google_palm import GooglePalm\nfrom autospark.llms.openai import OpenAi\nfrom autospark.llms.sparkai import SparkAI\nfrom autospark.models.configuration import Configuration\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.project import Project\nfrom autospark.models.user import User\nfrom autospark.lib.logger import logger\n\n# from autospark.types.db import OrganisationIn, OrganisationOut\nfrom autospark.models.workflows.agent_workflow import AgentWorkflow\n\nrouter = APIRouter()\n\n\nclass OrganisationOut(BaseModel):\n    id: int\n    name: str\n    description: str\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass OrganisationIn(BaseModel):\n    name: str\n    description: str\n\n    class Config:\n        orm_mode = True\n\n\n# CRUD Operations\n@router.post(\"/add\", dependencies=[Depends(HTTPBearer())],response_model=OrganisationOut, status_code=201)\ndef create_organisation(organisation: OrganisationIn,\n                        Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new organisation.\n\n    Args:\n        organisation: Organisation data.\n\n    Returns:\n        dict: Dictionary containing the created organisation.\n\n    Raises:\n        HTTPException (status_code=400): If there is an issue creating the organisation.\n\n    \"\"\"\n\n    new_organisation = Organisation(\n        name=organisation.name,\n        description=organisation.description,\n    )\n    db.session.add(new_organisation)\n    db.session.commit()\n    db.session.flush()\n    register_toolkits(session=db.session, organisation=new_organisation)\n    logger.info(new_organisation)\n\n    return new_organisation\n\n\n@router.get(\"/get/{organisation_id}\",dependencies=[Depends(HTTPBearer())], response_model=OrganisationOut)\ndef get_organisation(organisation_id: int, Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get organisation details by organisation_id.\n\n    Args:\n        organisation_id: ID of the organisation.\n\n    Returns:\n        dict: Dictionary containing the organisation details.\n\n    Raises:\n        HTTPException (status_code=404): If the organisation with the specified ID is not found.\n\n    \"\"\"\n\n    db_organisation = db.session.query(Organisation).filter(Organisation.id == organisation_id).first()\n    if not db_organisation:\n        raise HTTPException(status_code=404, detail=\"organisation not found\")\n    return db_organisation\n\n\n@router.put(\"/update/{organisation_id}\",dependencies=[Depends(HTTPBearer())], response_model=OrganisationOut)\ndef update_organisation(organisation_id: int, organisation: OrganisationIn,\n                        Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Update organisation details by organisation_id.\n\n    Args:\n        organisation_id: ID of the organisation.\n        organisation: Updated organisation data.\n\n    Returns:\n        dict: Dictionary containing the updated organisation details.\n\n    Raises:\n        HTTPException (status_code=404): If the organisation with the specified ID is not found.\n\n    \"\"\"\n\n    db_organisation = db.session.query(Organisation).filter(Organisation.id == organisation_id).first()\n    if not db_organisation:\n        raise HTTPException(status_code=404, detail=\"Organisation not found\")\n\n    db_organisation.name = organisation.name\n    db_organisation.description = organisation.description\n    db.session.commit()\n\n    return db_organisation\n\n\n@router.get(\"/get/user/{user_id}\", dependencies=[Depends(HTTPBearer())], response_model=OrganisationOut, status_code=201)\ndef get_organisations_by_user(user_id: int):\n    \"\"\"\n    Get organisations associated with a user.If Organisation does not exists a new organisation is created\n\n    Args:\n        user_id: ID of the user.\n\n    Returns:\n        dict: Dictionary containing the organisation details.\n\n    Raises:\n        HTTPException (status_code=400): If the user with the specified ID is not found.\n\n    \"\"\"\n\n    user = db.session.query(User).filter(User.id == user_id).first()\n    if user is None:\n        raise HTTPException(status_code=400,\n                            detail=\"User not found\")\n\n    organisation = Organisation.find_or_create_organisation(db.session, user)\n    Project.find_or_create_default_project(db.session, organisation.id)\n    return organisation\n\n\n@router.get(\"/llm_models\", dependencies=[Depends(HTTPBearer())])\ndef get_llm_models(organisation=Depends(get_user_organisation)):\n    \"\"\"\n    Get all the llm models associated with an organisation.\n\n    Args:\n        organisation: Organisation data.\n    \"\"\"\n\n    model_api_key = db.session.query(Configuration).filter(Configuration.organisation_id == organisation.id,\n                                                           Configuration.key == \"model_api_key\").first()\n    model_api_secret = db.session.query(Configuration).filter(Configuration.organisation_id == organisation.id,\n                                                              Configuration.key == \"model_api_secret\").first()\n    model_app_id = db.session.query(Configuration).filter(Configuration.organisation_id == organisation.id,\n                                                          Configuration.key == \"model_app_id\").first()\n\n    model_source = db.session.query(Configuration).filter(Configuration.organisation_id == organisation.id,\n                                                          Configuration.key == \"model_source\").first()\n\n    if model_api_key is None or model_source is None:\n        raise HTTPException(status_code=400,\n                            detail=\"Organisation not found\")\n\n    decrypted_api_key = decrypt_data(model_api_key.value)\n\n    models = []\n    if model_source.value == \"OpenAi\":\n        models = OpenAi(api_key=decrypted_api_key).get_models()\n    elif model_source.value == \"Google Palm\":\n        models = GooglePalm(api_key=decrypted_api_key).get_models()\n    elif model_source.value == \"SparkAI\":\n        decrypted_api_key = decrypt_data(model_api_key.value)\n\n        decrypted_api_secret = decrypt_data(model_api_secret.value)\n        decrypted_app_id = decrypt_data(model_app_id.value)\n        models = SparkAI(api_key=decrypted_api_key, api_secret=decrypted_api_secret,\n                         app_id=decrypted_app_id).get_models()\n\n    return models\n\n\n@router.get(\"/agent_workflows\")\ndef agent_workflows(organisation=Depends(get_user_organisation)):\n    \"\"\"\n    Get all the agent workflows\n\n    Args:\n        organisation: Organisation data.\n    \"\"\"\n\n    agent_workflows = db.session.query(AgentWorkflow).all()\n    workflows = [workflow.name for workflow in agent_workflows]\n\n    return workflows"}
{"type": "source_file", "path": "autospark/controllers/agent_execution_feed.py", "content": "from datetime import datetime\nfrom typing import Optional\nfrom fastapi.security import HTTPBearer\n\nfrom fastapi import APIRouter\nfrom fastapi import HTTPException, Depends\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom pydantic import BaseModel\n\nfrom sqlalchemy.sql import asc\n\nfrom autospark.agent.task_queue import TaskQueue\nfrom autospark.helper.auth import check_auth\nfrom autospark.helper.time_helper import get_time_difference\nfrom autospark.models.agent_execution_permission import AgentExecutionPermission\nfrom autospark.helper.feed_parser import parse_feed\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent_execution_feed import AgentExecutionFeed\n\nimport re\n# from autospark.types.db import AgentExecutionFeedOut, AgentExecutionFeedIn\n\nrouter = APIRouter()\n\n\nclass AgentExecutionFeedOut(BaseModel):\n    id: int\n    agent_execution_id: int\n    agent_id: int\n    feed: str\n    role: str\n    extra_info: Optional[str]\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass AgentExecutionFeedIn(BaseModel):\n    id: int\n    agent_execution_id: int\n    agent_id: int\n    feed: str\n    role: str\n    extra_info: str\n\n    class Config:\n        orm_mode = True\n\n# CRUD Operations\n@router.post(\"/add\", response_model=AgentExecutionFeedOut,dependencies=[Depends(HTTPBearer())], status_code=201)\ndef create_agent_execution_feed(agent_execution_feed: AgentExecutionFeedIn,\n                                Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Add a new agent execution feed.\n\n    Args:\n        agent_execution_feed (AgentExecutionFeed): The data for the agent execution feed.\n\n    Returns:\n        AgentExecutionFeed: The newly created agent execution feed.\n\n    Raises:\n        HTTPException (Status Code=404): If the associated agent execution is not found.\n    \"\"\"\n\n    agent_execution = db.session.query(AgentExecution).get(agent_execution_feed.agent_execution_id)\n\n    if not agent_execution:\n        raise HTTPException(status_code=404, detail=\"Agent Execution not found\")\n\n    db_agent_execution_feed = AgentExecutionFeed(agent_execution_id=agent_execution_feed.agent_execution_id,\n                                                 feed=agent_execution_feed.feed, type=agent_execution_feed.type,\n                                                 extra_info=agent_execution_feed.extra_info)\n    db.session.add(db_agent_execution_feed)\n    db.session.commit()\n    return db_agent_execution_feed\n\n\n@router.get(\"/get/{agent_execution_feed_id}\", dependencies=[Depends(HTTPBearer())],response_model=AgentExecutionFeedOut)\ndef get_agent_execution_feed(agent_execution_feed_id: int,\n                             Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get an agent execution feed by agent_execution_feed_id.\n\n    Args:\n        agent_execution_feed_id (int): The ID of the agent execution feed.\n\n    Returns:\n        AgentExecutionFeed: The agent execution feed with the specified ID.\n\n    Raises:\n        HTTPException (Status Code=404): If the agent execution feed is not found.\n    \"\"\"\n\n    db_agent_execution_feed = db.session.query(AgentExecutionFeed).filter(\n        AgentExecutionFeed.id == agent_execution_feed_id).first()\n    if not db_agent_execution_feed:\n        raise HTTPException(status_code=404, detail=\"agent_execution_feed not found\")\n    return db_agent_execution_feed\n\n\n@router.put(\"/update/{agent_execution_feed_id}\",dependencies=[Depends(HTTPBearer())], response_model=AgentExecutionFeedOut)\ndef update_agent_execution_feed(agent_execution_feed_id: int,\n                                agent_execution_feed: AgentExecutionFeedIn,\n                                Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Update a particular agent execution feed.\n\n    Args:\n        agent_execution_feed_id (int): The ID of the agent execution feed to update.\n        agent_execution_feed (AgentExecutionFeed): The updated agent execution feed.\n\n    Returns:\n        AgentExecutionFeed: The updated agent execution feed.\n\n    Raises:\n        HTTPException (Status Code=404): If the agent execution feed or agent execution is not found.\n    \"\"\"\n\n    db_agent_execution_feed = db.session.query(AgentExecutionFeed).filter(\n        AgentExecutionFeed.id == agent_execution_feed_id).first()\n    if not db_agent_execution_feed:\n        raise HTTPException(status_code=404, detail=\"Agent Execution Feed not found\")\n\n    if agent_execution_feed.agent_execution_id:\n        agent_execution = db.session.query(AgentExecution).get(agent_execution_feed.agent_execution_id)\n        if not agent_execution:\n            raise HTTPException(status_code=404, detail=\"Agent Execution not found\")\n        db_agent_execution_feed.agent_execution_id = agent_execution.id\n\n    if agent_execution_feed.type is not None:\n        db_agent_execution_feed.type = agent_execution_feed.type\n    if agent_execution_feed.feed is not None:\n        db_agent_execution_feed.feed = agent_execution_feed.feed\n    # if agent_execution_feed.extra_info is not None:\n    #     db_agent_execution_feed.extra_info = agent_execution_feed.extra_info\n\n    db.session.commit()\n    return db_agent_execution_feed\n\n\n@router.get(\"/get/execution/{agent_execution_id}\")\ndef get_agent_execution_feed(agent_execution_id: int,\n                             Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get agent execution feed with other execution details.\n\n    Args:\n        agent_execution_id (int): The ID of the agent execution.\n\n    Returns:\n        dict: The agent execution status and feeds.\n\n    Raises:\n        HTTPException (Status Code=400): If the agent run is not found.\n    \"\"\"\n\n    agent_execution = db.session.query(AgentExecution).filter(AgentExecution.id == agent_execution_id).first()\n    if agent_execution is None:\n        raise HTTPException(status_code=400, detail=\"Agent Run not found!\")\n    feeds = db.session.query(AgentExecutionFeed).filter_by(agent_execution_id=agent_execution_id).order_by(\n        asc(AgentExecutionFeed.created_at)).all()\n    # # parse json\n    final_feeds = []\n    for feed in feeds:\n        if feed.feed != \"\" and re.search(r\"The current time and date is\\s(\\w{3}\\s\\w{3}\\s\\s?\\d{1,2}\\s\\d{2}:\\d{2}:\\d{2}\\s\\d{4})\",feed.feed) == None :\n            final_feeds.append(parse_feed(feed))\n\n    # get all permissions\n    execution_permissions = db.session.query(AgentExecutionPermission).\\\n        filter_by(agent_execution_id=agent_execution_id). \\\n        order_by(asc(AgentExecutionPermission.created_at)).all()\n\n    permissions = [\n        {\n                \"id\": permission.id,\n                \"created_at\": permission.created_at,\n                \"response\": permission.user_feedback,\n                \"status\": permission.status,\n                \"tool_name\": permission.tool_name,\n                \"user_feedback\": permission.user_feedback,\n                \"time_difference\":get_time_difference(permission.created_at,str(datetime.now()))\n        } for permission in execution_permissions\n    ]\n    return {\n        \"status\": agent_execution.status,\n        \"feeds\": final_feeds,\n        \"permissions\": permissions\n    }\n\n\n@router.get(\"/get/tasks/{agent_execution_id}\")\ndef get_execution_tasks(agent_execution_id: int,\n                        Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get agent execution tasks and completed tasks.\n\n    Args:\n        agent_execution_id (int): The ID of the agent execution.\n\n    Returns:\n        dict: The tasks and completed tasks for the agent execution.\n    \"\"\"\n    task_queue = TaskQueue(str(agent_execution_id))\n    tasks = []\n    for task in task_queue.get_tasks():\n        tasks.append({\"name\": task})\n    completed_tasks = []\n    for task in reversed(task_queue.get_completed_tasks()):\n        completed_tasks.append({\"name\": task['task']})\n\n    return {\n        \"tasks\": tasks,\n        \"completed_tasks\": completed_tasks\n    }"}
{"type": "source_file", "path": "autospark/controllers/budget.py", "content": "from fastapi import APIRouter\nfrom fastapi import HTTPException, Depends\nfrom fastapi.security import HTTPBearer\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\nfrom pydantic import BaseModel\n\nfrom autospark.helper.auth import check_auth\nfrom autospark.models.budget import Budget\n# from autospark.types.db import BudgetIn, BudgetOut\n\nrouter = APIRouter()\n\n\nclass BudgetOut(BaseModel):\n    id: int\n    budget: float\n    cycle: str\n\n    class Config:\n        orm_mode = True\n\n\nclass BudgetIn(BaseModel):\n    budget: float\n    cycle: str\n\n    class Config:\n        orm_mode = True\n\n@router.post(\"/add\", response_model=BudgetOut, status_code=201)\ndef create_budget(budget: BudgetIn,\n                  Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new budget.\n\n    Args:\n        budget: Budget details.\n\n    Returns:\n        Budget: Created budget.\n\n    \"\"\"\n\n    new_budget = Budget(\n        budget=budget.budget,\n        cycle=budget.cycle\n    )\n    db.session.add(new_budget)\n    db.session.commit()\n\n    return new_budget\n\n\n@router.get(\"/get/{budget_id}\",dependencies=[Depends(HTTPBearer())], response_model=BudgetOut)\ndef get_budget(budget_id: int,\n               Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get a budget by budget_id.\n\n    Args:\n        budget_id: Budget ID.\n\n    Returns:\n        Budget: Retrieved budget.\n\n    \"\"\"\n\n    db_budget = db.session.query(Budget).filter(Budget.id == budget_id).first()\n    if not db_budget:\n        raise HTTPException(status_code=404, detail=\"budget not found\")\n    return db_budget\n\n\n@router.put(\"/update/{budget_id}\", dependencies=[Depends(HTTPBearer())],response_model=BudgetOut)\ndef update_budget(budget_id: int, budget: BudgetIn,\n                  Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Update budget details by budget_id.\n\n    Args:\n        budget_id: Budget ID.\n        budget: Updated budget details.\n\n    Returns:\n        Budget: Updated budget.\n\n    \"\"\"\n\n    db_budget = db.session.query(Budget).filter(Budget.id == budget_id).first()\n    if not db_budget:\n        raise HTTPException(status_code=404, detail=\"budget not found\")\n\n    db_budget.budget = budget.budget\n    db_budget.cycle = budget.cycle\n    db.session.commit()\n\n    return db_budget\n"}
{"type": "source_file", "path": "autospark/agent/queue_step_handler.py", "content": "import time\n\nimport numpy as np\n\nfrom autospark.agent.agent_message_builder import AgentLlmMessageBuilder\nfrom autospark.agent.task_queue import TaskQueue\nfrom autospark.helper.json_cleaner import JsonCleaner\nfrom autospark.helper.prompt_reader import PromptReader\nfrom autospark.helper.token_counter import TokenCounter\nfrom autospark.lib.logger import logger\nfrom autospark.models.agent_execution import AgentExecution\nfrom autospark.models.agent_execution_feed import AgentExecutionFeed\nfrom autospark.models.workflows.agent_workflow_step import AgentWorkflowStep\nfrom autospark.models.workflows.agent_workflow_step_tool import AgentWorkflowStepTool\nfrom autospark.types.queue_status import QueueStatus\n\n\nclass QueueStepHandler:\n    \"\"\"Handles the queue step of the agent workflow\"\"\"\n    def __init__(self, session, llm, agent_id: int, agent_execution_id: int):\n        self.session = session\n        self.llm = llm\n        self.agent_execution_id = agent_execution_id\n        self.agent_id = agent_id\n\n    def _queue_identifier(self, step_tool):\n        return step_tool.unique_id + \"_\" + str(self.agent_execution_id)\n\n    def _build_task_queue(self, step_tool):\n        return TaskQueue(self._queue_identifier(step_tool))\n\n    def execute_step(self):\n        execution = AgentExecution.get_agent_execution_from_id(self.session, self.agent_execution_id)\n        workflow_step = AgentWorkflowStep.find_by_id(self.session, execution.current_agent_step_id)\n        step_tool = AgentWorkflowStepTool.find_by_id(self.session, workflow_step.action_reference_id)\n        task_queue = self._build_task_queue(step_tool)\n\n        if not task_queue.get_status() or task_queue.get_status() == QueueStatus.COMPLETE.value:\n            task_queue.set_status(QueueStatus.INITIATED.value)\n\n        if task_queue.get_status() == QueueStatus.INITIATED.value:\n            self._add_to_queue(task_queue, step_tool)\n            execution.current_feed_group_id = \"DEFAULT\"\n            task_queue.set_status(QueueStatus.PROCESSING.value)\n\n        if not task_queue.get_tasks():\n            task_queue.set_status(QueueStatus.COMPLETE.value)\n            return \"COMPLETE\"\n        self._consume_from_queue(task_queue)\n        return \"default\"\n\n    def _add_to_queue(self, task_queue: TaskQueue, step_tool: AgentWorkflowStepTool):\n        assistant_reply = self._process_input_instruction(step_tool)\n        self._process_reply(task_queue, assistant_reply)\n\n    def _consume_from_queue(self, task_queue: TaskQueue):\n        tasks = task_queue.get_tasks()\n        agent_execution = AgentExecution.find_by_id(self.session, self.agent_execution_id)\n        if tasks:\n            task = task_queue.get_first_task()\n            # generating the new feed group id\n            agent_execution.current_feed_group_id = \"GROUP_\" + str(int(time.time()))\n            self.session.commit()\n            task_response_feed = AgentExecutionFeed(agent_execution_id=self.agent_execution_id,\n                                                    agent_id=self.agent_id,\n                                                    feed=\"Input: \" + task,\n                                                    role=\"assistant\",\n                                                    feed_group_id=agent_execution.current_feed_group_id)\n            self.session.add(task_response_feed)\n            self.session.commit()\n            task_queue.complete_task(\"PROCESSED\")\n\n    def _process_reply(self, task_queue: TaskQueue, assistant_reply: str):\n        assistant_reply = JsonCleaner.extract_json_array_section(assistant_reply)\n        print(\"Queue reply:\", assistant_reply)\n        task_array = np.array(eval(assistant_reply)).flatten().tolist()\n        for task in task_array:\n            task_queue.add_task(str(task))\n            logger.info(\"RAMRAM: Added task to queue: \", task)\n\n    def _process_input_instruction(self, step_tool):\n        prompt = self._build_queue_input_prompt(step_tool)\n        logger.info(\"Prompt: \", prompt)\n        agent_feeds = AgentExecutionFeed.fetch_agent_execution_feeds(self.session, self.agent_execution_id)\n        messages = AgentLlmMessageBuilder(self.session, self.llm, self.agent_id, self.agent_execution_id) \\\n            .build_agent_messages(prompt, agent_feeds, history_enabled=step_tool.history_enabled,\n                                  completion_prompt=step_tool.completion_prompt)\n        current_tokens = TokenCounter.count_message_tokens(messages, self.llm.get_model())\n        response = self.llm.chat_completion(messages, TokenCounter.token_limit(self.llm.get_model()) - current_tokens)\n        if 'content' not in response or response['content'] is None:\n            raise RuntimeError(f\"Failed to get response from llm\")\n        total_tokens = current_tokens + TokenCounter.count_message_tokens(response, self.llm.get_model())\n        AgentExecution.update_tokens(self.session, self.agent_execution_id, total_tokens)\n        assistant_reply = response['content']\n        return assistant_reply\n\n    def _build_queue_input_prompt(self, step_tool: AgentWorkflowStepTool):\n        queue_input_prompt = PromptReader.read_agent_prompt(__file__, \"agent_queue_input.txt\")\n        queue_input_prompt = queue_input_prompt.replace(\"{instruction}\", step_tool.input_instruction)\n\n        return queue_input_prompt\n"}
{"type": "source_file", "path": "autospark/agent/tool_builder.py", "content": "import importlib\n\nfrom autospark.config.config import get_config\nfrom autospark.llms.llm_model_factory import get_model\nfrom autospark.models.tool import Tool\nfrom autospark.models.tool_config import ToolConfig\nfrom autospark.resource_manager.file_manager import FileManager\nfrom autospark.tools.base_tool import BaseToolkitConfiguration\nfrom autospark.tools.tool_response_query_manager import ToolResponseQueryManager\nfrom autospark.helper.encyption_helper import decrypt_data, is_encrypted\n\n\nclass DBToolkitConfiguration(BaseToolkitConfiguration):\n    session = None\n    toolkit_id: int\n\n    def __init__(self, session=None, toolkit_id=None):\n        self.session = session\n        self.toolkit_id = toolkit_id\n\n    def get_tool_config(self, key: str):\n        tool_config = self.session.query(ToolConfig).filter_by(key=key, toolkit_id=self.toolkit_id).first()\n        if tool_config and tool_config.value:\n            if is_encrypted(tool_config.value):\n                return decrypt_data(tool_config.value)\n            else:\n                return tool_config.value\n        return super().get_tool_config(key=key)\n\n\nclass ToolBuilder:\n    def __init__(self, session, agent_id: int, agent_execution_id: int = None):\n        self.session = session\n        self.agent_id = agent_id\n        self.agent_execution_id = agent_execution_id\n\n    def __validate_filename(self, filename):\n        \"\"\"\n        Validate the filename by removing the last three characters if the filename ends with \".py\".\n\n        Args:\n            filename (str): The filename.\n\n        Returns:\n            str: The validated filename.\n        \"\"\"\n        if filename.endswith(\".py\"):\n            return filename[:-3]  # Remove the last three characters (i.e., \".py\")\n        return filename\n\n    def build_tool(self, tool: Tool):\n        \"\"\"\n        Create an object of a agent usable tool dynamically.\n\n        Args:\n            tool (Tool) : Tool object from which agent tool would be made.\n\n        Returns:\n            object: The object of the agent usable tool.\n        \"\"\"\n        file_name = self.__validate_filename(filename=tool.file_name)\n\n        tools_dir = get_config(\"TOOLS_DIR\")\n        if tools_dir is None:\n            tools_dir = \"autospark/tools\"\n        parsed_tools_dir = tools_dir.rstrip(\"/\")\n        module_name = \".\".join(parsed_tools_dir.split(\"/\") + [tool.folder_name, file_name])\n\n        # module_name = f\"autospark.tools.{folder_name}.{file_name}\"\n\n        # Load the module dynamically\n        module = importlib.import_module(module_name)\n\n        # Get the class from the loaded module\n        obj_class = getattr(module, tool.class_name)\n\n        # Create an instance of the class\n        new_object = obj_class()\n        new_object.toolkit_config = DBToolkitConfiguration(session=self.session, toolkit_id=tool.toolkit_id)\n        return new_object\n\n    def set_default_params_tool(self, tool, agent_config, agent_execution_config, model_api_key: str,\n                                resource_summary: str = \"\", model_api_secret: str = \"\", model_app_id: str = \"\"):\n        \"\"\"\n        Set the default parameters for the tools.\n\n        Args:\n            tool : Tool object.\n            agent_config (dict): Parsed agent configuration.\n            agent_execution_config (dict): Parsed execution configuration\n            agent_id (int): The ID of the agent.\n            model_api_key (str): The API key of the model\n\n        Returns:\n            list: The list of tools with default parameters.\n        \"\"\"\n        if hasattr(tool, 'goals'):\n            tool.goals = agent_execution_config[\"goal\"]\n        if hasattr(tool, 'instructions'):\n            tool.instructions = agent_execution_config[\"instruction\"]\n        if hasattr(tool, 'llm') and (agent_config[\"model\"] == \"gpt4\" or agent_config[\n            \"model\"] == \"gpt-3.5-turbo\") and tool.name != \"QueryResource\":\n            tool.llm = get_model(model=\"gpt-3.5-turbo\", api_key=model_api_key, temperature=0.4)\n        elif hasattr(tool, 'llm'):\n            tool.llm = get_model(model=agent_config[\"model\"], api_key=model_api_key, app_id=model_app_id,\n                                 api_secret=model_api_secret, temperature=0.4)\n        if hasattr(tool, 'agent_id'):\n            tool.agent_id = self.agent_id\n        if hasattr(tool, 'agent_execution_id'):\n            tool.agent_execution_id = self.agent_execution_id\n        if hasattr(tool, 'resource_manager'):\n            tool.resource_manager = FileManager(session=self.session, agent_id=self.agent_id,\n                                                agent_execution_id=self.agent_execution_id)\n        if hasattr(tool, 'tool_response_manager'):\n            tool.tool_response_manager = ToolResponseQueryManager(session=self.session,\n                                                                  agent_execution_id=self.agent_execution_id)\n\n        if tool.name == \"QueryResourceTool\":\n            tool.description = tool.description.replace(\"{summary}\", resource_summary)\n\n        return tool\n"}
{"type": "source_file", "path": "autospark/helper/auth.py", "content": "from fastapi import Depends, HTTPException\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_sqlalchemy import db\n\nfrom autospark.config.config import get_config\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.user import User\n\n\ndef check_auth(Authorize: AuthJWT = Depends()):\n    \"\"\"\n    Function to check if the user is authenticated or not based on the environment.\n\n    Args:\n        Authorize (AuthJWT, optional): Instance of AuthJWT class to authorize the user. Defaults to Depends().\n\n    Returns:\n        AuthJWT: Instance of AuthJWT class if the user is authenticated.\n    \"\"\"\n    env = get_config(\"ENV\", \"DEV\")\n    if env == \"PROD\":\n        Authorize.jwt_required()\n    return Authorize\n\n\ndef get_user_organisation(Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Function to get the organisation of the authenticated user based on the environment.\n\n    Args:\n        Authorize (AuthJWT, optional): Instance of AuthJWT class to authorize the user. Defaults to Depends on check_auth().\n\n    Returns:\n        Organisation: Instance of Organisation class to which the authenticated user belongs.\n    \"\"\"\n    user = get_current_user(Authorize)\n    if user is None:\n        raise HTTPException(status_code=401, detail=\"Unauthenticated\")\n    organisation = db.session.query(Organisation).filter(Organisation.id == user.organisation_id).first()\n    return organisation\n\ndef get_current_user(Authorize: AuthJWT = Depends(check_auth)):\n    env = get_config(\"ENV\", \"DEV\")\n\n    if env == \"DEV\":\n        email = \"autospark@iflytek.com\"\n    else:\n        # Retrieve the email of the logged-in user from the JWT token payload\n        email = Authorize.get_jwt_subject()\n\n    # Query the User table to find the user by their email\n    user = db.session.query(User).filter(User.email == email).first()\n    return user"}
{"type": "source_file", "path": "autospark/apm/analytics_helper.py", "content": "from typing import List, Dict, Union, Any\n\nfrom sqlalchemy import text, func, and_\nfrom sqlalchemy.orm import Session\n\nfrom autospark.models.events import Event\n\n\nclass AnalyticsHelper:\n\n    def __init__(self, session: Session, organisation_id: int):\n        self.session = session\n        self.organisation_id = organisation_id\n\n    def calculate_run_completed_metrics(self) -> Dict[str, Dict[str, Union[int, List[Dict[str, int]]]]]:\n\n        agent_model_query = self.session.query(\n            Event.event_property['model'].label('model'),\n            Event.agent_id\n        ).filter_by(event_name=\"agent_created\", org_id=self.organisation_id).subquery()\n\n        agent_runs_query = self.session.query(\n            agent_model_query.c.model,\n            func.count(Event.id).label('runs')\n        ).join(Event, and_(Event.agent_id == agent_model_query.c.agent_id, Event.org_id == self.organisation_id)).filter(Event.event_name.in_(['run_completed', 'run_iteration_limit_crossed'])).group_by(agent_model_query.c.model).subquery()\n\n        agent_tokens_query = self.session.query(\n            agent_model_query.c.model,\n            func.sum(text(\"(event_property->>'tokens_consumed')::int\")).label('tokens')\n        ).join(Event, and_(Event.agent_id == agent_model_query.c.agent_id, Event.org_id == self.organisation_id)).filter(Event.event_name.in_(['run_completed', 'run_iteration_limit_crossed'])).group_by(agent_model_query.c.model).subquery()\n\n        agent_count_query = self.session.query(\n            agent_model_query.c.model,\n            func.count(agent_model_query.c.agent_id).label('agents')\n        ).group_by(agent_model_query.c.model).subquery()\n\n        agents = self.session.query(agent_count_query).all()\n        runs = self.session.query(agent_runs_query).all()\n        tokens = self.session.query(agent_tokens_query).all()\n\n        metrics = {\n            'agent_details': {\n                'total_agents': sum([item.agents for item in agents]),\n                'model_metrics': [{'name': item.model, 'value': item.agents} for item in agents]\n            },\n            'run_details': {\n                'total_runs': sum([item.runs for item in runs]),\n                'model_metrics': [{'name': item.model, 'value': item.runs} for item in runs]\n            },\n            'tokens_details': {\n                'total_tokens': sum([item.tokens for item in tokens]),\n                'model_metrics': [{'name': item.model, 'value': item.tokens} for item in tokens]\n            },\n        }\n\n        return metrics\n\n    def fetch_agent_data(self) -> Dict[str, List[Dict[str, Any]]]:\n        agent_subquery = self.session.query(\n            Event.agent_id,\n            Event.event_property['agent_name'].label('agent_name'),\n            Event.event_property['model'].label('model')\n        ).filter_by(event_name=\"agent_created\", org_id=self.organisation_id).subquery()\n\n        run_subquery = self.session.query(\n            Event.agent_id,\n            func.sum(text(\"(event_property->>'tokens_consumed')::int\")).label('total_tokens'),\n            func.sum(text(\"(event_property->>'calls')::int\")).label('total_calls'),\n            func.count(Event.id).label('runs_completed'),\n        ).filter(and_(Event.event_name.in_(['run_completed', 'run_iteration_limit_crossed']), Event.org_id == self.organisation_id)).group_by(Event.agent_id).subquery()\n\n        tool_subquery = self.session.query(\n            Event.agent_id,\n            func.array_agg(Event.event_property['tool_name'].distinct()).label('tools_used'),\n        ).filter_by(event_name=\"tool_used\", org_id=self.organisation_id).group_by(Event.agent_id).subquery()\n\n        start_time_subquery = self.session.query(\n            Event.agent_id,\n            Event.event_property['agent_execution_id'].label('agent_execution_id'),\n            func.min(func.extract('epoch', Event.created_at)).label('start_time')\n        ).filter_by(event_name=\"run_created\", org_id=self.organisation_id).group_by(Event.agent_id, Event.event_property['agent_execution_id']).subquery()\n\n        end_time_subquery = self.session.query(\n            Event.agent_id,\n            Event.event_property['agent_execution_id'].label('agent_execution_id'),\n            func.max(func.extract('epoch', Event.created_at)).label('end_time')\n        ).filter(and_(Event.event_name.in_(['run_completed', 'run_iteration_limit_crossed']), Event.org_id == self.organisation_id)).group_by(Event.agent_id, Event.event_property['agent_execution_id']).subquery()\n\n        time_diff_subquery = self.session.query(\n            start_time_subquery.c.agent_id,\n            (func.avg(end_time_subquery.c.end_time - start_time_subquery.c.start_time)).label('avg_run_time')\n        ).join(end_time_subquery, start_time_subquery.c.agent_execution_id == end_time_subquery.c.agent_execution_id). \\\n            group_by(start_time_subquery.c.agent_id).subquery()\n\n        query = self.session.query(\n            agent_subquery.c.agent_id,\n            agent_subquery.c.agent_name,\n            agent_subquery.c.model,\n            run_subquery.c.total_tokens,\n            run_subquery.c.total_calls,\n            run_subquery.c.runs_completed,\n            tool_subquery.c.tools_used,\n            time_diff_subquery.c.avg_run_time\n        ).outerjoin(run_subquery, run_subquery.c.agent_id == agent_subquery.c.agent_id) \\\n            .outerjoin(tool_subquery, tool_subquery.c.agent_id == agent_subquery.c.agent_id) \\\n            .outerjoin(time_diff_subquery, time_diff_subquery.c.agent_id == agent_subquery.c.agent_id)\n\n        result = query.all()\n\n        agent_details = [{\n            \"name\": row.agent_name,\n            \"agent_id\": row.agent_id,\n            \"runs_completed\": row.runs_completed if row.runs_completed else 0,\n            \"total_calls\": row.total_calls if row.total_calls else 0,\n            \"total_tokens\": row.total_tokens if row.total_tokens else 0,\n            \"tools_used\": row.tools_used,\n            \"model_name\": row.model,\n            \"avg_run_time\": row.avg_run_time if row.avg_run_time else 0,\n        } for row in result]\n\n        return {'agent_details': agent_details}\n\n\n    def fetch_agent_runs(self, agent_id: int) -> List[Dict[str, int]]:\n        agent_runs = []\n        completed_subquery = self.session.query(\n            Event.event_property['agent_execution_id'].label('completed_agent_execution_id'),\n            Event.event_property['tokens_consumed'].label('tokens_consumed'),\n            Event.event_property['calls'].label('calls'),\n            Event.updated_at\n        ).filter(Event.event_name.in_(['run_completed','run_iteration_limit_crossed']), Event.agent_id == agent_id, Event.org_id == self.organisation_id).subquery()\n\n        created_subquery = self.session.query(\n            Event.event_property['agent_execution_id'].label('created_agent_execution_id'),\n            Event.event_property['agent_execution_name'].label('agent_execution_name'),\n            Event.created_at\n        ).filter(Event.event_name == \"run_created\", Event.agent_id == agent_id, Event.org_id == self.organisation_id).subquery()\n\n        query = self.session.query(\n            created_subquery.c.agent_execution_name,\n            completed_subquery.c.tokens_consumed,\n            completed_subquery.c.calls,\n            created_subquery.c.created_at,\n            completed_subquery.c.updated_at\n        ).join(completed_subquery, completed_subquery.c.completed_agent_execution_id == created_subquery.c.created_agent_execution_id)\n\n        result = query.all()\n\n        agent_runs = [{\n            'name': row.agent_execution_name,\n            'tokens_consumed': int(row.tokens_consumed) if row.tokens_consumed else 0,\n            'calls': int(row.calls) if row.calls else 0,\n            'created_at': row.created_at,\n            'updated_at': row.updated_at\n        } for row in result]\n\n        return agent_runs\n\n\n    def get_active_runs(self) -> List[Dict[str, str]]:\n        running_executions = []\n\n        end_event_subquery = self.session.query(\n            Event.event_property['agent_execution_id'].label('agent_execution_id'),\n        ).filter(\n            Event.event_name.in_(['run_completed', 'run_iteration_limit_crossed']),\n            Event.org_id == self.organisation_id\n        ).subquery()\n\n        start_subquery = self.session.query(\n            Event.event_property['agent_execution_id'].label('agent_execution_id'),\n            Event.event_property['agent_execution_name'].label('agent_execution_name'),\n            Event.created_at,\n            Event.agent_id\n        ).filter_by(event_name=\"run_created\", org_id = self.organisation_id).subquery()\n\n        agent_created_subquery = self.session.query(\n            Event.event_property['agent_name'].label('agent_name'),\n            Event.agent_id\n        ).filter_by(event_name=\"agent_created\", org_id = self.organisation_id).subquery()\n\n        query = self.session.query(\n            start_subquery.c.agent_execution_name,\n            start_subquery.c.created_at,\n            agent_created_subquery.c.agent_name\n        ).select_from(start_subquery)\n\n        query = query.outerjoin(end_event_subquery, start_subquery.c.agent_execution_id == end_event_subquery.c.agent_execution_id).filter(end_event_subquery.c.agent_execution_id == None)\n\n        query = query.join(agent_created_subquery, start_subquery.c.agent_id == agent_created_subquery.c.agent_id)\n\n        result = query.all()\n\n        running_executions = [{\n            'name': row.agent_execution_name,\n            'created_at': row.created_at,\n            'agent_name': row.agent_name or 'Unknown',\n        } for row in result]\n\n        return running_executions\n"}
{"type": "source_file", "path": "autospark/apm/event_handler.py", "content": "import logging\nfrom typing import Optional, Dict\nfrom sqlalchemy.exc import SQLAlchemyError\nfrom sqlalchemy.orm import Session\n\nfrom autospark.models.events import Event\n\nclass EventHandler:\n\n    def __init__(self, session: Session):\n        self.session = session\n\n    def create_event(self, event_name: str, event_property: Dict, agent_id: int,\n                     org_id: int, event_value: int = 1) -> Optional[Event]:\n        try:\n            event = Event(\n                event_name=event_name,\n                event_value=event_value,\n                event_property=event_property,\n                agent_id=agent_id,\n                org_id=org_id,\n            )\n            self.session.add(event)\n            self.session.commit()\n            return event\n        except SQLAlchemyError as err:\n            logging.error(f\"Error while creating event: {str(err)}\")\n            return None"}
{"type": "source_file", "path": "autospark/agent/workflow_seed.py", "content": "from autospark.agent.agent_prompt_builder import AgentPromptBuilder\nfrom autospark.agent.agent_prompt_template import AgentPromptTemplate\nfrom autospark.models.workflows.agent_workflow import AgentWorkflow\nfrom autospark.models.workflows.agent_workflow_step import AgentWorkflowStep\nfrom autospark.models.workflows.iteration_workflow import IterationWorkflow\nfrom autospark.models.workflows.iteration_workflow_step import IterationWorkflowStep\nfrom autospark.tools.apollo.apollo_search import ApolloSearchTool\nfrom autospark.tools.code.write_code import CodingTool\nfrom autospark.tools.code.write_spec import WriteSpecTool\nfrom autospark.tools.code.write_test import WriteTestTool\nfrom autospark.tools.email.read_email import ReadEmailTool\nfrom autospark.tools.email.send_email import SendEmailTool\nfrom autospark.tools.file.append_file import AppendFileTool\nfrom autospark.tools.file.list_files import ListFileTool\nfrom autospark.tools.file.read_file import ReadFileTool\nfrom autospark.tools.file.write_file import WriteFileTool\nfrom autospark.tools.github.add_file import GithubAddFileTool\nfrom autospark.tools.google_search.google_search import GoogleSearchTool\nfrom autospark.tools.slack.send_message import SlackMessageTool\nfrom autospark.tools.thinking.tools import ThinkingTool\nfrom autospark.tools.webscaper.tools import WebScraperTool\n\n\nclass AgentWorkflowSeed:\n    @classmethod\n    def build_sales_workflow(cls, session):\n        agent_workflow = AgentWorkflow.find_or_create_by_name(session, \"Sales Engagement Workflow\",\n                                                              \"Sales Engagement Workflow\")\n        step1 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step1\",\n                                                                    ApolloSearchTool().name,\n                                                                    \"Search for leads based on the given goals\",\n                                                                    step_type=\"TRIGGER\")\n\n        step2 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step2\",\n                                                                    WriteFileTool().name,\n                                                                    \"Write the leads to a csv file\")\n\n        step3 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step3\",\n                                                                    ReadFileTool().name,\n                                                                    \"Read the leads from the file generated in the previous run\")\n\n        # task queue ends when the elements gets over\n        step4 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step4\",\n                                                                    \"TASK_QUEUE\",\n                                                                    \"Break the above response array of items\",\n                                                                    completion_prompt=\"Get array of items from the above response. Array should suitable utilization of JSON.parse().\")\n\n        step5 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step5\",\n                                                                    GoogleSearchTool().name,\n                                                                    \"Search about the company in which the lead is working\")\n\n        step6 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step6\",\n                                                                    \"WAIT_FOR_PERMISSION\",\n                                                                    \"Email will be based on this content. Do you want send the email?\")\n\n        step7 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step7\",\n                                                                    GoogleSearchTool().name,\n                                                                    \"Search about the company given in the high-end goal only\")\n\n        step8 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step8\",\n                                                                    SendEmailTool().name,\n                                                                    \"Customize the Email according to the company information in the mail\")\n\n        AgentWorkflowStep.add_next_workflow_step(session, step1.id, step2.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step2.id, step3.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step3.id, step4.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step4.id, -1, \"COMPLETE\")\n        AgentWorkflowStep.add_next_workflow_step(session, step4.id, step5.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step5.id, step6.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step6.id, step7.id, \"YES\")\n        AgentWorkflowStep.add_next_workflow_step(session, step6.id, step5.id, \"NO\")\n        AgentWorkflowStep.add_next_workflow_step(session, step7.id, step8.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step8.id, step4.id)\n        session.commit()\n\n    @classmethod\n    def build_app_traversal_test(cls, session):\n        agent_workflow = AgentWorkflow.find_or_create_by_name(session, \"App Traversal Test Workflow\",\n                                                              \"App Traversal Test Workflow\")\n        cp = 'Respond with only valid JSON conforming to the given json schema. Response should contain tool name and tool arguments to achieve the given instruction.'\n        step1 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step1\",\n                                                                    ListFileTool().name,\n                                                                    \"Read files from the resource manager\",\n                                                                    step_type=\"TRIGGER\",\n                                                                    completion_prompt=cp)\n\n    @classmethod\n    def build_recruitment_workflow(cls, session):\n        agent_workflow = AgentWorkflow.find_or_create_by_name(session, \"Recruitment Workflow\",\n                                                              \"Recruitment Workflow\")\n        step1 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step1\",\n                                                                    ListFileTool().name,\n                                                                    \"Read files from the resource manager\",\n                                                                    step_type=\"TRIGGER\")\n\n        # task queue ends when the elements gets over\n        step2 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step2\",\n                                                                    \"TASK_QUEUE\",\n                                                                    \"Break the above response array of items\",\n                                                                    completion_prompt=\"Get array of items from the above response. Array should suitable utilization of JSON.parse().\")\n\n        step3 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step3\",\n                                                                    ReadFileTool().name,\n                                                                    \"Read the resume from above input\")\n\n        step4 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step4\",\n                                                                    ReadFileTool().name,\n                                                                    \"Read the job description from job description file\",\n                                                                    \"Check if the resume matches the job description in goal\")\n\n        step5 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step4\",\n                                                                    SendEmailTool().name,\n                                                                    \"Write a custom Email the candidates for job profile based on their experience\")\n\n        AgentWorkflowStep.add_next_workflow_step(session, step1.id, step2.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step2.id, step3.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step2.id, -1, \"COMPLETE\")\n        AgentWorkflowStep.add_next_workflow_step(session, step3.id, step4.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step4.id, step5.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step5.id, step2.id)\n        session.commit()\n\n    @classmethod\n    def build_coding_workflow(cls, session):\n        agent_workflow = AgentWorkflow.find_or_create_by_name(session, \"SuperCoder\", \"SuperCoder\")\n        step1 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step1\",\n                                                                    WriteSpecTool().name,\n                                                                    \"Spec description\",\n                                                                    step_type=\"TRIGGER\")\n\n        step2 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step2\",\n                                                                    WriteTestTool().name,\n                                                                    \"Test description\")\n\n        step3 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step3\",\n                                                                    CodingTool().name,\n                                                                    \"Code description\")\n\n        step4 = AgentWorkflowStep.find_or_create_tool_workflow_step(session, agent_workflow.id,\n                                                                    str(agent_workflow.id) + \"_step4\",\n                                                                    \"WAIT_FOR_PERMISSION\",\n                                                                    \"Your code is ready. Do you want end?\")\n\n        AgentWorkflowStep.add_next_workflow_step(session, step1.id, step2.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step2.id, step3.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step3.id, step4.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step4.id, -1, \"YES\")\n        AgentWorkflowStep.add_next_workflow_step(session, step4.id, step3.id, \"NO\")\n\n    @classmethod\n    def build_goal_based_agent(cls, session):\n        agent_workflow = AgentWorkflow.find_or_create_by_name(session, \"Goal Based Workflow\", \"Goal Based Workflow\")\n        step1 = AgentWorkflowStep.find_or_create_iteration_workflow_step(session, agent_workflow.id,\n                                                                         str(agent_workflow.id) + \"_step1\",\n                                                                         \"Goal Based Agent-I\", step_type=\"TRIGGER\")\n        AgentWorkflowStep.add_next_workflow_step(session, step1.id, step1.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step1.id, -1, \"COMPLETE\")\n\n    @classmethod\n    def build_task_based_agent(cls, session):\n        agent_workflow = AgentWorkflow.find_or_create_by_name(session, \"\", \"\")\n        step1 = AgentWorkflowStep.find_or_create_iteration_workflow_step(session, agent_workflow.id,\n                                                                         str(agent_workflow.id) + \"_step1\",\n                                                                         \"Initialize Tasks-I\", step_type=\"TRIGGER\")\n        step2 = AgentWorkflowStep.find_or_create_iteration_workflow_step(session, agent_workflow.id,\n                                                                         str(agent_workflow.id) + \"_step2\",\n                                                                         \"Dynamic Task Queue-I\", step_type=\"NORMAL\")\n        AgentWorkflowStep.add_next_workflow_step(session, step1.id, step2.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step2.id, step2.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step2.id, -1, \"COMPLETE\")\n\n    @classmethod\n    def build_fixed_task_based_agent(cls, session):\n        agent_workflow = AgentWorkflow.find_or_create_by_name(session, \"Fixed Task Workflow\", \"Fixed Task Workflow\")\n        step1 = AgentWorkflowStep.find_or_create_iteration_workflow_step(session, agent_workflow.id,\n                                                                         str(agent_workflow.id) + \"_step1\",\n                                                                         \"Initialize Tasks-I\", step_type=\"TRIGGER\")\n        step2 = AgentWorkflowStep.find_or_create_iteration_workflow_step(session, agent_workflow.id,\n                                                                         str(agent_workflow.id) + \"_step2\",\n                                                                         \"Fixed Task Queue-I\", step_type=\"NORMAL\")\n        AgentWorkflowStep.add_next_workflow_step(session, step1.id, step2.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step2.id, step2.id)\n        AgentWorkflowStep.add_next_workflow_step(session, step2.id, -1, \"COMPLETE\")\n\n\nclass IterationWorkflowSeed:\n    @classmethod\n    def build_single_step_agent(cls, session):\n        iteration_workflow = IterationWorkflow.find_or_create_by_name(session, \"Goal Based Agent-I\", \"Goal Based Agent\")\n        output = AgentPromptTemplate.get_super_agi_single_prompt()\n        IterationWorkflowStep.find_or_create_step(session, iteration_workflow.id, \"gb1\",\n                                                  output[\"prompt\"],\n                                                  str(output[\"variables\"]), \"TRIGGER\", \"tools\",\n                                                  history_enabled=True,\n                                                  completion_prompt=\"Determine which next tool to use, and respond using the format specified above:\")\n\n    @classmethod\n    def build_task_based_agents(cls, session):\n        iteration_workflow = IterationWorkflow.find_or_create_by_name(session, \"Dynamic Task Queue-I\",\n                                                                      \"Dynamic Task Queue\", has_task_queue=True)\n\n        output = AgentPromptTemplate.analyse_task()\n        workflow_step1 = IterationWorkflowStep.find_or_create_step(session, iteration_workflow.id, \"tb1\",\n                                                                   output[\"prompt\"],\n                                                                   str(output[\"variables\"]), \"TRIGGER\", \"tools\")\n\n        output = AgentPromptTemplate.create_tasks()\n        workflow_step2 = IterationWorkflowStep.find_or_create_step(session, iteration_workflow.id, \"tb2\",\n                                                                   output[\"prompt\"],\n                                                                   str(output[\"variables\"]), \"NORMAL\", \"tasks\")\n\n        output = AgentPromptTemplate.prioritize_tasks()\n        workflow_step3 = IterationWorkflowStep.find_or_create_step(session, iteration_workflow.id, \"tb3\",\n                                                                   output[\"prompt\"],\n                                                                   str(output[\"variables\"]), \"NORMAL\", \"replace_tasks\")\n\n        workflow_step1.next_step_id = workflow_step2.id\n        workflow_step2.next_step_id = workflow_step3.id\n\n        session.commit()\n\n    @classmethod\n    def build_initialize_task_workflow(cls, session):\n        iteration_workflow = IterationWorkflow.find_or_create_by_name(session, \"Initialize Tasks-I\", \"Initialize Tasks\",\n                                                                      has_task_queue=True)\n        output = AgentPromptTemplate.start_task_based()\n\n        IterationWorkflowStep.find_or_create_step(session, iteration_workflow.id, \"init_task1\",\n                                                  output[\"prompt\"], str(output[\"variables\"]), \"TRIGGER\", \"tasks\")\n\n    @classmethod\n    def build_action_based_agents(cls, session):\n        iteration_workflow = IterationWorkflow.find_or_create_by_name(session, \"Fixed Task Queue-I\", \"Fixed Task Queue\",\n                                                                      has_task_queue=True)\n        output = AgentPromptTemplate.analyse_task()\n        IterationWorkflowStep.find_or_create_step(session, iteration_workflow.id, \"ab1\",\n                                                  output[\"prompt\"], str(output[\"variables\"]), \"TRIGGER\", \"tools\")\n"}
{"type": "source_file", "path": "autospark/config/__init__.py", "content": ""}
{"type": "source_file", "path": "autospark/apm/tools_handler.py", "content": "from typing import List, Dict\n\nfrom sqlalchemy import func\nfrom sqlalchemy.orm import Session\n\nfrom autospark.models.events import Event\nfrom autospark.models.tool import Tool\nfrom autospark.models.toolkit import Toolkit\n\n\nclass ToolsHandler:\n\n    def __init__(self, session: Session, organisation_id: int):\n        self.session = session\n        self.organisation_id = organisation_id\n\n    def get_tool_and_toolkit(self):\n        tools_and_toolkits = self.session.query(\n            Tool.name.label('tool_name'), Toolkit.name.label('toolkit_name')).join(\n            Toolkit, Tool.toolkit_id == Toolkit.id).all()\n\n        return {item.tool_name: item.toolkit_name for item in tools_and_toolkits}\n\n    def calculate_tool_usage(self) -> List[Dict[str, int]]:\n        tool_usage = []\n        tool_used_subquery = self.session.query(\n            Event.event_property['tool_name'].label('tool_name'),\n            Event.agent_id\n        ).filter_by(event_name=\"tool_used\", org_id=self.organisation_id).subquery()\n\n        agent_count = self.session.query(\n            tool_used_subquery.c.tool_name,\n            func.count(func.distinct(tool_used_subquery.c.agent_id)).label('unique_agents')\n        ).group_by(tool_used_subquery.c.tool_name).subquery()\n\n        total_usage = self.session.query(\n            tool_used_subquery.c.tool_name,\n            func.count(tool_used_subquery.c.tool_name).label('total_usage')\n        ).group_by(tool_used_subquery.c.tool_name).subquery()\n\n        query = self.session.query(\n            agent_count.c.tool_name,\n            agent_count.c.unique_agents,\n            total_usage.c.total_usage,\n        ).join(total_usage, total_usage.c.tool_name == agent_count.c.tool_name)\n\n        tool_and_toolkit = self.get_tool_and_toolkit()\n        result = query.all()\n\n        tool_usage = [{\n            'tool_name': row.tool_name,\n            'unique_agents': row.unique_agents,\n            'total_usage': row.total_usage,\n            'toolkit': tool_and_toolkit.get(row.tool_name, None)\n        } for row in result]\n\n        return tool_usage"}
{"type": "source_file", "path": "autospark/helper/agent_schedule_helper.py", "content": "from autospark.models.db import connect_db\nfrom sqlalchemy.orm import sessionmaker\nfrom autospark.models.agent_config import AgentConfiguration\nfrom autospark.models.agent_schedule import AgentSchedule\nfrom datetime import datetime, timedelta\nfrom autospark.helper.time_helper import parse_interval_to_seconds\nimport pytz\n\nengine = connect_db()\nSession = sessionmaker(bind=engine)\n\n\nclass AgentScheduleHelper:\n    AGENT_SCHEDULE_TIME_INTERVAL = 300\n\n    def run_scheduled_agents(self):\n        \"\"\"\n        Execute all eligible scheduled agent tasks since last five minutes.\n        \"\"\"\n\n        now = datetime.now()\n        last_five_minutes = now - timedelta(minutes=5)\n\n        session = Session()\n        scheduled_agents = session.query(AgentSchedule).filter(\n            AgentSchedule.next_scheduled_time.between(last_five_minutes, now), AgentSchedule.status == \"SCHEDULED\").all()\n\n        for agent in scheduled_agents:\n            interval = agent.recurrence_interval\n            interval_in_seconds = 0  # default value\n            if interval is not None:\n                interval_in_seconds = parse_interval_to_seconds(interval)\n            agent_id = agent.agent_id\n            agent_execution_name = self.__create_execution_name_for_scheduling(agent_id)\n\n            should_execute_agent = self.__should_execute_agent(agent, interval)\n\n            self.__execute_schedule(should_execute_agent, interval_in_seconds, session, agent,\n                                   agent_execution_name)\n\n        for agent in scheduled_agents:\n            if self.__can_remove_agent(agent, interval):\n                agent.status = \"COMPLETED\"\n                session.commit()\n\n        session.close()\n\n    def update_next_scheduled_time(self):\n        \"\"\"\n        Update the next scheduled time of each agent and terminate those who have finished their schedule, in case of any miss.\n        \"\"\"\n        now = datetime.now()\n\n        session = Session()\n        scheduled_agents = session.query(AgentSchedule).filter(\n            AgentSchedule.start_time <= now, AgentSchedule.next_scheduled_time <= now,\n            AgentSchedule.status == \"SCHEDULED\").all()\n\n        for agent in scheduled_agents:\n            if (now - agent.next_scheduled_time).total_seconds() < AgentScheduleHelper.AGENT_SCHEDULE_TIME_INTERVAL:\n                continue\n            if agent.recurrence_interval is not None:\n                interval_in_seconds = parse_interval_to_seconds(agent.recurrence_interval)\n                time_diff = now - agent.start_time\n                num_intervals_passed = time_diff.total_seconds() // interval_in_seconds\n                updated_next_scheduled_time = agent.start_time + timedelta(\n                    seconds=(interval_in_seconds * (num_intervals_passed + 1)))\n                agent.next_scheduled_time = updated_next_scheduled_time\n            else:\n                agent.status = \"TERMINATED\"\n            session.commit()\n        session.close()\n        \n    def __create_execution_name_for_scheduling(self, agent_id) -> str:\n        \"\"\"\n        Create name for an agent execution based on current time.\n\n        Args:\n            agent_id (str): The id of the agent job to be scheduled.\n\n        Returns:\n            str: Execution name of the agent in the format \"Run <timestamp>\"\n        \"\"\"\n        session = Session()\n        user_timezone = session.query(AgentConfiguration).filter(AgentConfiguration.key == \"user_timezone\",\n                                                                 AgentConfiguration.agent_id == agent_id).first()\n\n        if user_timezone and user_timezone.value != \"None\":\n            current_time = datetime.now().astimezone(pytz.timezone(user_timezone.value))\n        else:\n            current_time = datetime.now().astimezone(pytz.timezone('GMT'))\n\n        timestamp = current_time.strftime(\" %d %B %Y %H:%M\")\n        return f\"Run{timestamp}\"\n\n    def __should_execute_agent(self, agent, interval):\n        \"\"\"\n        Determine if an agent should be executed based on its scheduling.\n\n        Args:\n            agent (object): The agent job to evaluate.\n            interval (int): Recurrence interval of the scheduled agent in seconds.\n\n        Returns:\n            bool: True if the agent should be executed, False otherwise.\n        \"\"\"\n        expiry_date = agent.expiry_date\n        expiry_runs = agent.expiry_runs\n        current_runs = agent.current_runs\n\n        # If there's no interval or there are no restrictions on when or how many times an agent can run\n        if not interval or (expiry_date is None and expiry_runs == -1):\n            return True\n\n        # Check if the agent's expiry date has not passed yet\n        if expiry_date and datetime.now() < expiry_date:\n            return True\n\n        # Check if the agent has not yet run as many times as allowed\n        if expiry_runs != -1 and current_runs < expiry_runs:\n            return True\n\n        # If none of the conditions to run the agent is met, return False (i.e., do not run the agent)\n        return False\n\n\n    def __can_remove_agent(self, agent, interval):\n        \"\"\"\n        Determine if an agent can be removed based on its scheduled expiry.\n\n        Args:\n            agent (object): The agent job to evaluate.\n            interval (int): Recurrence interval of the scheduled agent in seconds.\n\n        Returns:\n            bool: True if the agent can be removed, False otherwise.\n        \"\"\"\n        expiry_date = agent.expiry_date\n        expiry_runs = agent.expiry_runs\n        current_runs = agent.current_runs\n\n        # Calculate the next scheduled time only if an interval exists.\n        next_scheduled = agent.next_scheduled_time + timedelta(seconds=parse_interval_to_seconds(interval)) if interval else None\n\n        # If there's no interval, the agent can be removed\n        if not interval:\n            return True\n\n        # If the agent's expiry date has not come yet and next schedule is before expiry date, it cannot be removed\n        if expiry_date and datetime.now() < expiry_date and (next_scheduled is None or next_scheduled <= expiry_date):\n            return False\n\n        # If agent has not yet run as many times as allowed, it cannot be removed\n        if expiry_runs != -1 and current_runs < expiry_runs:\n            return False\n\n        # If there are no restrictions on when or how many times an agent can run, it cannot be removed\n        if expiry_date is None and expiry_runs == -1:\n            return False\n\n        # If none of the conditions to keep the agent is met, we return True (i.e., the agent can be removed)\n        return True\n\n    def __execute_schedule(self, should_execute_agent, interval_in_seconds, session, agent, agent_execution_name):\n        \"\"\"\n        Executes a scheduled job, if it should be executed.\n        Args:\n            should_execute_agent (bool): Whether agent should be executed.\n            interval_in_seconds (int): The interval in seconds for the schedule.\n            session (Session): The database session.\n            agent (object): The agent to be scheduled.\n            agent_execution_name (str): The name for the execution.\n        \"\"\"\n        from autospark.jobs.scheduling_executor import ScheduledAgentExecutor\n        if should_execute_agent:\n            executor = ScheduledAgentExecutor()\n            executor.execute_scheduled_agent(agent.agent_id, agent_execution_name)\n            agent.current_runs = agent.current_runs + 1\n\n            if agent.recurrence_interval:\n                next_scheduled_time = agent.next_scheduled_time + timedelta(seconds=interval_in_seconds)\n                agent.next_scheduled_time = next_scheduled_time\n\n            session.commit()"}
{"type": "source_file", "path": "autospark/helper/calendar_date.py", "content": "from datetime import datetime, timedelta, timezone\n\nimport pytz\n\n\nclass CalendarDate:\n    def create_event_dates(self, service, start_date, start_time, end_date, end_time):\n        local_tz = pytz.timezone(self._get_time_zone(service))\n        start_datetime, end_datetime = self._localize_daterange(start_date, end_date, start_time, end_time, local_tz)\n        date_utc = {\n            \"start_datetime_utc\": self._datetime_to_string(start_datetime, \"%Y-%m-%dT%H:%M:%S.%fZ\"),\n            \"end_datetime_utc\": self._datetime_to_string(end_datetime, \"%Y-%m-%dT%H:%M:%S.%fZ\"),\n            \"timeZone\": self._get_time_zone(service)\n        }\n        return date_utc\n\n    def get_date_utc(self, start_date, end_date, start_time, end_time, service):\n        local_tz = pytz.timezone(self._get_time_zone(service))\n        start_datetime, end_datetime = self._localize_daterange(start_date, end_date, start_time, end_time, local_tz)\n        date_utc = {\n            \"start_datetime_utc\": self._datetime_to_string(start_datetime, \"%Y-%m-%dT%H:%M:%S.%fZ\"),\n            \"end_datetime_utc\": self._datetime_to_string(end_datetime, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n        }\n        return date_utc\n\n    def _get_time_zone(self, service):\n        calendar = service.calendars().get(calendarId='primary').execute()\n        time_detail = calendar['timeZone']\n        return time_detail\n\n    def _convert_to_utc(self, date_time, local_tz):\n        local_datetime = local_tz.localize(date_time)\n        gmt_tz = pytz.timezone(\"GMT\")\n        return local_datetime.astimezone(gmt_tz)\n\n    def _string_to_datetime(self, date_str, date_format):\n        return datetime.strptime(date_str, date_format) if date_str else None\n\n    def _localize_daterange(self, start_date, end_date, start_time, end_time, local_tz):\n        start_datetime = self._string_to_datetime(start_date, \"%Y-%m-%d\") if start_date != 'None' else datetime.now(\n            timezone.utc)\n        end_datetime = self._string_to_datetime(end_date,\n                                                \"%Y-%m-%d\") if end_date != 'None' else start_datetime + timedelta(\n            days=30) - timedelta(microseconds=1)\n        time_obj_start = self._string_to_datetime(start_time, \"%H:%M:%S\")\n        time_obj_end = self._string_to_datetime(end_time, \"%H:%M:%S\")\n        start_datetime = start_datetime.replace(hour=time_obj_start.hour, minute=time_obj_start.minute,\n                                                second=time_obj_start.second,\n                                                microsecond=0) if time_obj_start else start_datetime.replace(hour=0,\n                                                                                                             minute=0,\n                                                                                                             second=0,\n                                                                                                             microsecond=0)\n        end_datetime = end_datetime.replace(hour=time_obj_end.hour, minute=time_obj_end.minute,\n                                            second=time_obj_end.second) if time_obj_end else end_datetime.replace(\n            hour=23, minute=59, second=59, microsecond=999999)\n        return self._convert_to_utc(start_datetime, local_tz), self._convert_to_utc(end_datetime, local_tz)\n\n    def _datetime_to_string(self, date_time, date_format):\n        return date_time.strftime(date_format) if date_time else None\n"}
{"type": "source_file", "path": "autospark/agent/tool_executor.py", "content": "from pydantic import ValidationError\n\nfrom autospark.agent.common_types import ToolExecutorResponse\nfrom autospark.apm.event_handler import EventHandler\nfrom autospark.lib.logger import logger\n\n\nclass ToolExecutor:\n    \"\"\"Executes the tool with the given args.\"\"\"\n    FINISH = \"finish\"\n\n    def __init__(self, organisation_id: int, agent_id: int, tools: list):\n        self.organisation_id = organisation_id\n        self.agent_id = agent_id\n        self.tools = tools\n\n    def execute(self, session, tool_name, tool_args):\n        \"\"\"Executes the tool with the given args.\n\n        Args:\n            session (Session): The database session.\n            tool_name (str): The name of the tool to execute.\n            tool_args (dict): The arguments to pass to the tool.\n        \"\"\"\n        tools = {t.name.lower().replace(\" \", \"\"): t for t in self.tools}\n        tool_name = tool_name.lower().replace(\" \", \"\")\n        if tool_name == ToolExecutor.FINISH or tool_name == \"\":\n            logger.info(\"\\nTask Finished :) \\n\")\n            return ToolExecutorResponse(status=\"COMPLETE\", result=\"\")\n        if tool_name in tools.keys():\n            status = \"SUCCESS\"\n            tool = tools[tool_name]\n            retry = False\n            EventHandler(session=session).create_event('tool_used', {'tool_name': tool_name}, self.agent_id,\n                                                       self.organisation_id),\n            try:\n                parsed_args = self.clean_tool_args(tool_args)\n                observation = tool.execute(parsed_args)\n            except ValidationError as e:\n                status = \"ERROR\"\n                retry = True\n                observation = (\n                    f\"Validation Error in args: {str(e)}, args: {tool_args}\"\n                )\n            except Exception as e:\n                status = \"ERROR\"\n                retry = True\n                observation = (\n                    f\"Error1: {str(e)}, {type(e).__name__}, args: {tool_args}\"\n                )\n            output = ToolExecutorResponse(status=status, result=f\"Tool {tool.name} returned: {observation}\",\n                                          retry=retry)\n        elif tool_name == \"ERROR\":\n            output = ToolExecutorResponse(status=\"ERROR\", result=f\"Error Tool Name: {tool_args}. \", retry=False)\n        else:\n            result = (\n                f\"Unknown tool '{tool_name}'. \"\n                f\"Please refer to the 'TOOLS' list for available \"\n                f\"tools and only respond in the specified JSON format.\"\n            )\n            output = ToolExecutorResponse(status=\"ERROR\", result=result, retry=True)\n\n        logger.info(\"Tool Response : \" + str(output) + \"\\n\")\n        return output\n\n    def clean_tool_args(self, args):\n        parsed_args = {}\n        for key in args.keys():\n            parsed_args[key] = args[key]\n            if type(args[key]) is dict and \"value\" in args[key]:\n                parsed_args[key] = args[key][\"value\"]\n        return parsed_args\n"}
{"type": "source_file", "path": "autospark/controllers/types/agent_with_config_schedule.py", "content": "from pydantic import BaseModel\nfrom autospark.controllers.types.agent_schedule import AgentScheduleInput\nfrom autospark.controllers.types.agent_with_config import AgentConfigInput\n\n\nclass AgentConfigSchedule(BaseModel):\n    agent_config: AgentConfigInput\n    schedule: AgentScheduleInput"}
{"type": "source_file", "path": "autospark/agent/task_queue.py", "content": "import json\n\nimport redis\n\nfrom autospark.config.config import get_config\n\nredis_url = get_config('REDIS_URL') or \"localhost:6379\"\n\"\"\"TaskQueue manages current tasks and past tasks in Redis \"\"\"\nclass TaskQueue:\n    def __init__(self, queue_name: str):\n        self.queue_name = queue_name + \"_q\"\n        self.completed_tasks = queue_name + \"_q_completed\"\n        self.db = redis.Redis.from_url(\"redis://\" + redis_url + \"/0\", decode_responses=True)\n\n    def add_task(self, task: str):\n        self.db.lpush(self.queue_name, task)\n        # print(\"Added task. New tasks:\", str(self.get_tasks()))\n\n    def complete_task(self, response):\n        if len(self.get_tasks()) <= 0:\n            return\n        task = self.db.lpop(self.queue_name)\n        self.db.lpush(self.completed_tasks, str({\"task\": task, \"response\": response}))\n\n    def get_first_task(self):\n        return self.db.lindex(self.queue_name, 0)\n\n    def get_tasks(self):\n        return self.db.lrange(self.queue_name, 0, -1)\n\n    def get_completed_tasks(self):\n        tasks = self.db.lrange(self.completed_tasks, 0, -1)\n        return [eval(task) for task in tasks]\n\n    def clear_tasks(self):\n        self.db.delete(self.queue_name)\n\n    def get_last_task_details(self):\n        response = self.db.lindex(self.completed_tasks, 0)\n        if response is None:\n            return None\n\n        return eval(response)\n\n    def set_status(self, status):\n        self.db.set(self.queue_name + \"_status\", status)\n\n    def get_status(self):\n        return self.db.get(self.queue_name + \"_status\")\n\n"}
{"type": "source_file", "path": "autospark/controllers/user.py", "content": "from datetime import datetime\nfrom typing import Optional\n\nfrom fastapi.security import HTTPBearer\nfrom fastapi_sqlalchemy import db\nfrom fastapi import HTTPException, Depends, Request\nfrom fastapi_jwt_auth import AuthJWT\nfrom pydantic import BaseModel\n\nfrom autospark.models.organisation import Organisation\nfrom autospark.models.project import Project\nfrom autospark.models.user import User\nfrom fastapi import APIRouter\n\nfrom autospark.helper.auth import check_auth\nfrom autospark.lib.logger import logger\n# from autospark.types.db import UserBase, UserIn, UserOut\n\nrouter = APIRouter()\n\nclass UserBase(BaseModel):\n    name: str\n    email: str\n    password: str\n\n    class Config:\n        orm_mode = True\n\n\nclass UserOut(UserBase):\n    id: int\n    organisation_id: int\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        orm_mode = True\n\n\nclass UserIn(UserBase):\n    organisation_id: Optional[int]\n\n    class Config:\n        orm_mode = True\n\n# CRUD Operations\n@router.post(\"/add\", response_model=UserOut, dependencies=[Depends(HTTPBearer())],status_code=201)\ndef create_user(user: UserIn,\n                Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Create a new user.\n\n    Args:\n        user (UserIn): User data.\n\n    Returns:\n        User: The created user.\n\n    Raises:\n        HTTPException (status_code=400): If there is an issue creating the user.\n\n    \"\"\"\n\n    db_user = db.session.query(User).filter(User.email == user.email).first()\n    if db_user:\n        return db_user\n    db_user = User(name=user.name, email=user.email, password=user.password, organisation_id=user.organisation_id)\n    db.session.add(db_user)\n    db.session.commit()\n    db.session.flush()\n    organisation = Organisation.find_or_create_organisation(db.session, db_user)\n    Project.find_or_create_default_project(db.session, organisation.id)\n    logger.info(\"User created\", db_user)\n    return db_user\n\n\n@router.get(\"/get/{user_id}\", dependencies=[Depends(HTTPBearer())], response_model=UserOut)\ndef get_user(user_id: int,\n             Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Get a particular user details.\n\n    Args:\n        user_id (int): ID of the user.\n\n    Returns:\n        User: The user details.\n\n    Raises:\n        HTTPException (status_code=404): If the user with the specified ID is not found.\n\n    \"\"\"\n\n    # Authorize.jwt_required()\n    db_user = db.session.query(User).filter(User.id == user_id).first()\n    if not db_user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return db_user\n\n\n@router.put(\"/update/{user_id}\",dependencies=[Depends(HTTPBearer())], response_model=UserOut)\ndef update_user(user_id: int,\n                user: UserBase,\n                Authorize: AuthJWT = Depends(check_auth)):\n    \"\"\"\n    Update a particular user.\n\n    Args:\n        user_id (int): ID of the user.\n        user (UserIn): Updated user data.\n\n    Returns:\n        User: The updated user details.\n\n    Raises:\n        HTTPException (status_code=404): If the user with the specified ID is not found.\n\n    \"\"\"\n\n    db_user = db.session.query(User).filter(User.id == user_id).first()\n    if not db_user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    db_user.name = user.name\n    db_user.email = user.email\n    db_user.password = user.password\n\n    db.session.commit()\n    return db_user\n"}
